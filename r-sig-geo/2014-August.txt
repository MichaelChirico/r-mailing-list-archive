From jon.skoien at jrc.ec.europa.eu  Fri Aug  1 08:47:13 2014
From: jon.skoien at jrc.ec.europa.eu (Jon Skoien)
Date: Fri, 01 Aug 2014 08:47:13 +0200
Subject: [R-sig-Geo] question about autoKrige anis1 and anis2
In-Reply-To: <FF9DB805FC41CC4E95825A50F68063021AA56A5B@columbia.uhd.campus>
References: <FF9DB805FC41CC4E95825A50F68063021AA56A5B@columbia.uhd.campus>
Message-ID: <53DB37F1.6000505@jrc.ec.europa.eu>

The result you got is the same as for a variogram model from vgm with a 
nugget effect. This is the ratio of anisotropy, which is one both for 
the nugget and for the correlated part of the model. See:

str(vgm(10, "Exp", 300))
str(vgm(10, "Exp", 300, 3))

I guess you see something like the second one as autofitVariogram is not 
able to fit the anisotropy parameters. For that you could have a look at 
estimateParameters in the intamap package, which can fit a variogram 
model of the vgm-type with anisotropy parameters.

Cheers,
Jon


On 7/29/2014 6:56 PM, Hodgess, Erin wrote:
> Hello again!
>
>
>
> I was using autoKrige (finally successfully!) and was looking at the model results.  I got anis1 of 1,1 and anis2 of 1,1.
>
>
>
> How does this relate to the anis in the vgm function, please?
>
>
>
> Thanks,
>
> Erin
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From janka.vanschoenwinkel at uhasselt.be  Fri Aug  1 10:43:39 2014
From: janka.vanschoenwinkel at uhasselt.be (Janka VANSCHOENWINKEL)
Date: Fri, 1 Aug 2014 10:43:39 +0200
Subject: [R-sig-Geo] Spatial partitioning of direct,
	indirect and total impacts
Message-ID: <CAHymut+jq+=2c8-4RKsBxbESz-6EtEupCyb-uT7pi+QjsWQTrw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140801/08937d76/attachment.pl>

From sam_l_cruickshank at hotmail.com  Fri Aug  1 10:57:35 2014
From: sam_l_cruickshank at hotmail.com (HallS)
Date: Fri, 1 Aug 2014 01:57:35 -0700 (PDT)
Subject: [R-sig-Geo] Merging shapefiles and csv
In-Reply-To: <1406809933918-7586839.post@n2.nabble.com>
References: <1406809933918-7586839.post@n2.nabble.com>
Message-ID: <1406883455312-7586852.post@n2.nabble.com>

Hi all,

Thanks for all your help, Roger you were right!  The merge function looked
like it had done it fine but when I came to plot it the shapefile clearly
hadn't joined correctly.  I think this is some kind of bodge, but I've
managed to use the match() function to join the csv with the shapefile, then
use an if function along with gunioncascade to join the internal polygons
according to col_2.

Match code:
frame at data=gc[match(shape at data[,"Col_1"], csv[,"Col_1"]),]

Then for each higher level (Col_2):

TERRITORY1 <- gUnionCascaded(frame[ which(frame$TERR=='1'), ])
plot(TERRITORY1)

TERRITORY2 <- gUnionCascaded(frame[ which(frame$TERR=='2'), ])
plot(TERRITORY2)

I'm hoping I can now use a concatenation of "TERRITORY1", "TERRITORY2" etc.
to map all of it, or single ones if I want.  Just hoping the rest of my data
from the csv is all joined on correctly.  Working on ggplot2 map now. 
Thanks for everyone's help, just thought I'd update this!



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Merging-shapefiles-and-csv-tp7586839p7586852.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From sam_l_cruickshank at hotmail.com  Fri Aug  1 13:46:44 2014
From: sam_l_cruickshank at hotmail.com (HallS)
Date: Fri, 1 Aug 2014 04:46:44 -0700 (PDT)
Subject: [R-sig-Geo] Choropleth maps using matched csv/shp files
Message-ID: <1406893604143-7586853.post@n2.nabble.com>

as my data is confidential I've tried to make an anonymous data set. I
started with a shp file, and csv with a matching ID column and further data,
including "Col_2" which is a higher level region of an aggregate of the
shapefile region. At first I merged these but it jumbled the data so I
managed to do it via match() and then gUnionCascaded. I have now retrieved
aggregated polygons without the internal boundaries, but I'm a bit lost as
to how I begin to utilise these in a choropleth map. All the instructions I
read seem out of context and being new to R I don't know how to start. I've
had a few abortive efforts with ggplot2 but all failed. Any help or pointers
to useful articles would be appreciated. Dummy code below.

install.packages("sp")
install.packages("rgdal")
install.packages("maptools") #read in shape files
install.packages("rgeos") # needed by maptools
install.packages("RColorBrewer")
install.packages("scales")
install.packages("gridExtra")

library("sp")
library("rgdal")
library("maptools")
library("ggplot2")
library("rgeos")
library("RColorBrewer")
library("scales")
library("gridExtra")

##Shapefile from http://www.sharegeo.ac.uk/handle/10672/50

##Working matched code
setwd("...")
gc<-read.csv("...dummy.csv", header=TRUE) 
str(gc)

##'data.frame':  9 obs. of  3 variables:
##$ NAME : Factor w/ 9 levels "East Midlands",..: 4 5 3 8 9 7 1 6 2
##$ Col_2: int  1 1 1 1 3 3 3 3 3
##$ Data : int  8 7 6 5 2 0 1 5 0

#Shape File and match file 
frame<-readOGR(dsn=".../Regions",
               layer="Regions")
str(frame)
plot(frame)

frame at data=gc[match(frame at data[,"NAME"], gc[,"NAME"]),]

##Successfully merged, now to concatenate by territory

##Region 1 
#With internal boundaries
REGION1 <- frame[ which(frame$Col_2=='1'), ]
plot(REGION1)
#Joined so no internal boundaries
REGIONA <- gUnionCascaded(frame[ which(frame$Col_2=='1'), ])
plot(REGIONA)

##Region 3
#With internal boundaries
REGION3 <- frame[ which(frame$Col_2=='3'), ]
plot(REGION3)
#Joined so no internal boundaries
REGIONC <- gUnionCascaded(frame[ which(frame$Col_2=='3'), ])
plot(REGIONC)



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Choropleth-maps-using-matched-csv-shp-files-tp7586853.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From janka.vanschoenwinkel at uhasselt.be  Fri Aug  1 13:58:33 2014
From: janka.vanschoenwinkel at uhasselt.be (Janka VANSCHOENWINKEL)
Date: Fri, 1 Aug 2014 13:58:33 +0200
Subject: [R-sig-Geo] Choropleth maps using matched csv/shp files
In-Reply-To: <1406893604143-7586853.post@n2.nabble.com>
References: <1406893604143-7586853.post@n2.nabble.com>
Message-ID: <CAHymut+rsZqfzfdMRr5yvxNpjE-a91SuYF9hKA+z6Xn4D1JbBw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140801/427ab461/attachment.pl>

From HodgessE at uhd.edu  Fri Aug  1 18:54:03 2014
From: HodgessE at uhd.edu (Hodgess, Erin)
Date: Fri, 1 Aug 2014 16:54:03 +0000
Subject: [R-sig-Geo] parallel version of krige or krigeST please
Message-ID: <FF9DB805FC41CC4E95825A50F68063021AA604A8@columbia.uhd.campus>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140801/c331415e/attachment.pl>

From edzer.pebesma at uni-muenster.de  Sun Aug  3 00:03:33 2014
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Sun, 03 Aug 2014 00:03:33 +0200
Subject: [R-sig-Geo] parallel version of krige or krigeST please
In-Reply-To: <FF9DB805FC41CC4E95825A50F68063021AA604A8@columbia.uhd.campus>
References: <FF9DB805FC41CC4E95825A50F68063021AA604A8@columbia.uhd.campus>
Message-ID: <53DD6035.4010106@uni-muenster.de>

Erin, for an example try:

library(gstat)
demo(snow)

https://r-forge.r-project.org/scm/viewvc.php/pkg/demo/snow.R?view=markup&revision=89&root=gstat

contains an update of it, using parallel.

The script parallelizes the prediction step, and so only helps if that
is the bottle neck.


On 08/01/2014 06:54 PM, Hodgess, Erin wrote:
> Hello again!
> 
> 
> 
> Is there a parallel version of krige or krigeST, please?
> 
> 
> 
> Thanks in advance,
> 
> Sincerely,
> 
> Erin
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Heisenbergstra?e 2, 48149 M?nster, Germany. Phone: +49 251
83 33081 http://ifgi.uni-muenster.de GPG key ID 0xAC227795

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140803/f343c2e2/attachment.bin>

From edzer.pebesma at uni-muenster.de  Sun Aug  3 11:14:52 2014
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Sun, 03 Aug 2014 11:14:52 +0200
Subject: [R-sig-Geo] Error gstat function krigeST
In-Reply-To: <53DA6498.6010606@gmail.com>
References: <53DA6498.6010606@gmail.com>
Message-ID: <53DDFD8C.7020506@uni-muenster.de>

Dear Francesco, there are several reasons why this could happen. The
first one I would look at is whether you have duplicate observations,
meaning observations that share exactly the same spatial and temporal
coordinate. Let me know if it helped,

On 07/31/2014 05:45 PM, Francesco Tonini wrote:
> Dear all,
> 
> I am working with an hourly dataset of air temperature, recorded at ~200
> stations over a relatively small area. I chose a space-time variogram
> (e.g. sum-metric) to fit my data and am now trying to make predictions
> over my same stations in order to fill NA (missing value) gaps. When
> using the krigeST() function over daily aggregated data everything seems
> to go smooth but when I use it at the original hourly resolution I
> always get the following error:
> 
> Error in chol.default(A)
> the leading minor of order 68 is not positive definite
> 
> I googled it and found that it is related to a matrix not being
> completely positive-definite. However, I am not sure why this happens
> and was wondering if any of you know a way of fixing this (a workaround
> to avoid it).
> 
> Thanks!
> Francesco
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Heisenbergstra?e 2, 48149 M?nster, Germany. Phone: +49 251
83 33081 http://ifgi.uni-muenster.de GPG key ID 0xAC227795

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140803/4706ce51/attachment.bin>

From edzer.pebesma at uni-muenster.de  Sun Aug  3 11:36:37 2014
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Sun, 03 Aug 2014 11:36:37 +0200
Subject: [R-sig-Geo] Copulas and spatial modeling
In-Reply-To: <CAGGwnOBhJHcpzPwgwfSgv44mNVfxRDrqN=b2q4-ERBd6pEN06w@mail.gmail.com>
References: <CAGGwnOBhJHcpzPwgwfSgv44mNVfxRDrqN=b2q4-ERBd6pEN06w@mail.gmail.com>
Message-ID: <53DE02A5.2000907@uni-muenster.de>

Ben Graeler is about to hand in his PhD thesis on copulas for
spatio-temporal data, see

http://ifgi.uni-muenster.de/~b_grae02/

Ben (co-)organizes a workshop on spatial copulas, see
http://blogs.ifgi.de/spatialcopulaworkshop/

Earlier work on spatial copula's: Andras Bardossy, Salvatore Grimaldi,
Hannes Kazianka; Hannes contributed R code to CRAN package intamap,
which includes a copula method.

On 07/30/2014 09:18 PM, Dave Leighton wrote:
> We are interested in using copulas for spatial modeling of environmental
> data. We are new to R and new to copulas. We???re looking for some guidance
> on how to use copulas for this application. I've searched the r-help
> archives and I have not found the information I need to get started. Can
> anyone point me to information or examples of how to apply copulas to
> spatial modeling of environmental data using R?
> 
> Thanks.
> 
> 
> *Dave Leighton*
> 
> *HydroFocus, Inc. 530-759-2484*
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Heisenbergstra?e 2, 48149 M?nster, Germany. Phone: +49 251
83 33081 http://ifgi.uni-muenster.de GPG key ID 0xAC227795

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140803/6ece6976/attachment.bin>

From edzer.pebesma at uni-muenster.de  Sun Aug  3 11:40:19 2014
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Sun, 03 Aug 2014 11:40:19 +0200
Subject: [R-sig-Geo] space time error message
In-Reply-To: <91BE0E35-083C-4206-A032-DDBDF13893E4@gmail.com>
References: <91BE0E35-083C-4206-A032-DDBDF13893E4@gmail.com>
Message-ID: <53DE0383.1030702@uni-muenster.de>

Please provide a small, reproducible example.

Wbr,

On 07/26/2014 08:29 PM, Abdoulaye SARR wrote:
> 
> Hello list,
> 
> I am creating a space time full data frame but having this error message:
> 
> Joining by: staid
> Error in ST(sp, time, endTime) : time is not a time based class
> 
> the data frame 10 days average precip used looks like this:
> 
>      staid       time prec
> 1 38007200 1984-01-01  0.0
> 2 38008400 1984-01-01  0.8
> 3 38014000 1984-01-01  0.0
> 4 38008100 1984-01-01  0.0
> 5 38008700 1984-01-01  0.0
> 6 38009200 1984-01-01  0.0
> 
> 
> The next date 1984-01-11 etc..
> 
> could someone help solve this urgent issue.
> 
> Best regards,
> 
> eus
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Heisenbergstra?e 2, 48149 M?nster, Germany. Phone: +49 251
83 33081 http://ifgi.uni-muenster.de GPG key ID 0xAC227795

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140803/6ea0ca26/attachment.bin>

From abdoulayesar at gmail.com  Sun Aug  3 16:20:03 2014
From: abdoulayesar at gmail.com (Abdoulaye Sarr)
Date: Sun, 3 Aug 2014 14:20:03 +0000
Subject: [R-sig-Geo] space time error message
In-Reply-To: <53DE0383.1030702@uni-muenster.de>
References: <91BE0E35-083C-4206-A032-DDBDF13893E4@gmail.com>
	<53DE0383.1030702@uni-muenster.de>
Message-ID: <CAN=6O0JSg1NnAmFN08yHxbk9Q6Eumiu_ZQJePLMWnHAehNf8OQ@mail.gmail.com>

I think the problem could be related to dates in precip, in fact here I am
using dekadal precip( 10 days average therefor for each month you have 01,
11 and 21 as you can see in the date in sample dataframes dprec84.rda and
the stations1.rda.

After creating these dataframes I am trying to use use meteo to create a
STFDF (I guess other packaged could do it?) using the command below:

> prec <- meteo2STFDF(dprec84,stations1, crs= CRS('+proj=longlat
+datum=WGS84'))
Joining by: staid, date
Joining by: staid
Error in  ST(sp, time, endTime) : time is not a time based class

If doable with other package also will be fine for me.

asarr


On Sun, Aug 3, 2014 at 9:40 AM, Edzer Pebesma <edzer.pebesma at uni-muenster.de
> wrote:

> Please provide a small, reproducible example.
>
> Wbr,
>
> On 07/26/2014 08:29 PM, Abdoulaye SARR wrote:
> >
> > Hello list,
> >
> > I am creating a space time full data frame but having this error message:
> >
> > Joining by: staid
> > Error in ST(sp, time, endTime) : time is not a time based class
> >
> > the data frame 10 days average precip used looks like this:
> >
> >      staid       time prec
> > 1 38007200 1984-01-01  0.0
> > 2 38008400 1984-01-01  0.8
> > 3 38014000 1984-01-01  0.0
> > 4 38008100 1984-01-01  0.0
> > 5 38008700 1984-01-01  0.0
> > 6 38009200 1984-01-01  0.0
> >
> >
> > The next date 1984-01-11 etc..
> >
> > could someone help solve this urgent issue.
> >
> > Best regards,
> >
> > eus
> >
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
> --
> Edzer Pebesma
> Institute for Geoinformatics (ifgi), University of M?nster
> Heisenbergstra?e 2, 48149 M?nster, Germany. Phone: +49 251
> 83 33081 http://ifgi.uni-muenster.de GPG key ID 0xAC227795
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140803/2253d685/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: dprec84.rda
Type: application/octet-stream
Size: 852 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140803/2253d685/attachment.obj>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: stations1.rda
Type: application/octet-stream
Size: 455 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140803/2253d685/attachment-0001.obj>

From ftonini84 at gmail.com  Sun Aug  3 18:38:28 2014
From: ftonini84 at gmail.com (Gmail)
Date: Sun, 3 Aug 2014 12:38:28 -0400
Subject: [R-sig-Geo] Error gstat function krigeST
In-Reply-To: <53DDFD8C.7020506@uni-muenster.de>
References: <53DA6498.6010606@gmail.com> <53DDFD8C.7020506@uni-muenster.de>
Message-ID: <D453DD6B-A70C-46D4-8BD4-B701B6ED9924@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140803/0a76b5ce/attachment.pl>

From abidi.zineb at gmail.com  Mon Aug  4 14:31:54 2014
From: abidi.zineb at gmail.com (az14)
Date: Mon, 4 Aug 2014 05:31:54 -0700 (PDT)
Subject: [R-sig-Geo] power index
Message-ID: <1407155514784-7586862.post@n2.nabble.com>

Dear list, 
 
I'm trying to calculate  Banzhaf power index for a set of 1260
municipalities. 
 My data is as below, where the insee variable is the municipalities, the
variable "nbrseat" is the number of seat in the CM of each municipalities
and the "numeroc" is the groupes ( numeroc takes the value of 1 for the
group 1 ans 2 for the group 2....group 119) 
The program i used is :
data<-read.csv("bzh.csv",header=TRUE,sep=";",dec=',')
attach(data)
data<-as.matrix(data)
summary(data)
for (numeroc in 1 :119) {nbseat<-Delegreel  
                         #Banzhaf power index  
                         #Length of the group : 2^m 
                         subsets<-length(numeroc)-1
                         subs<-matrix(FALSE,2^subsets,subsets)
                         for (i in 1:subsets) {
                               subs[,i] <- rep(c(rep(FALSE, 2 ^ (i - 1)),
                                                   +                      
rep(TRUE, 2 ^ (i - 1))),
                                                 +                     2 ^
(subsets - i))
                            }
                         q<-sum(nbseat)/2
                         banzhaf <- function(i) {
                           other <- nbseat[-i]
                           part.sum <- apply(subs, 1, function(x)
{sum(other[x]) } )
                           sum((part.sum < q) & ((part.sum + nbseat[i]) >q))
                         }}
BZH <- prop.table(sapply(1:length(Delegreel), banzhaf))

but it did not work. 
i will be very grateful for any help. 
Thank you. 
Sincerely. 

Zineb 


data:
insee	nbrseat	numeroc
22001	5	1
22300	3	1
22384	8	1
22047	6	2
22074	4	2
22244	2	2
22313	2	2
22316	2	2
22033	2	3
22158	9	3
22285	2	3
22295	2	3
22298	3	3
29007	4	4
29012	1	4
29081	8	4
29129	1	4
29275	4	4
22097	3	5
22104	2	5
22180	8	5
22315	1	5
22317	1	5
22318	1	5
22342	2	5
22078	1	6
22101	5	6
22247	6	6
22253	1	6
22264	5	6
22383	1	6
29013	1	7
29016	5	7
29018	2	7
29054	3	7
29139	3	7
29141	1	7
29211	3	7
29261	1	7
56009	4	8
56114	3	8
56152	11	8
56241	4	8
35098	5	9
35124	10	9
35249	4	9
35316	3	9
56056	1	10
56080	6	10
56129	7	10
56134	4	10
56227	2	10
56257	3	10
56025	1	11
56043	4	11
56127	12	11
56145	5	11
56208	1	11
56225	1	11
56256	1	11
22005	4	12
22037	1	12
22072	1	12
22129	1	12
22135	9	12
22216	3	12
22354	4	12
22018	1	13
22204	5	13
22212	4	13
22250	4	13
22256	4	13
22269	1	13
22283	3	13
22032	10	14
22036	1	14
22069	1	14
22071	2	14
22239	4	14
22240	4	14
22305	2	14
22312	1	14
22013	10	15
22040	2	15
22088	1	15
22092	1	15
22139	1	15
22156	2	15
22189	2	15
22249	2	15
22271	1	15
22335	1	15
22035	4	16
22056	6	16
22208	5	16
22263	1	16
22274	1	16
22306	2	16
22308	2	16
22352	1	16
22006	1	17
22030	3	17
22034	5	17
22041	1	17
22245	4	17
22254	4	17
22257	1	17
22340	4	17
22023	2	18
22024	1	18
22025	9	18
22031	3	18
22052	1	18
22132	1	18
22138	1	18
22231	1	18
22243	2	18
22320	1	18
22328	1	18
22046	3	19
22066	4	19
22102	2	19
22191	7	19
22292	1	19
22297	2	19
22303	3	19
56046	11	20
56116	6	20
56233	5	20
29033	2	21
29062	4	21
29115	1	21
29123	3	21
29142	1	21
29162	11	21
29053	5	22
29240	3	22
29263	3	22
29302	11	22
22062	2	23
22083	2	23
22122	2	23
22133	2	23
22147	9	23
22148	1	23
22309	1	23
22333	2	23
22371	3	23
35035	1	24
35046	1	24
35048	1	24
35057	3	24
35084	2	24
35160	1	24
35168	10	24
35175	3	24
35311	1	24
22119	1	25
22131	3	25
22207	7	25
22217	1	25
22227	2	25
22228	4	25
22359	1	25
22387	3	25
22009	1	26
22080	2	26
22171	11	26
22203	9	26
22051	1	27
22084	5	27
22175	3	27
22185	7	27
22193	4	27
22341	2	27
56034	11	28
56168	6	28
56258	5	28
22103	2	29
22190	10	29
22213	9	29
22368	1	29
35034	3	30
35044	1	30
35222	6	30
35247	3	30
35248	1	30
35259	3	30
35270	1	30
35291	1	30
35329	2	30
35339	1	30
35354	1	30
35008	2	31
35102	1	31
35125	12	31
35198	2	31
35199	1	31
35200	2	31
35325	1	31
35359	3	31
22085	1	32
22111	1	32
22127	4	32
22195	7	32
22196	3	32
22199	3	32
22347	3	32
56126	5	33
56147	10	33
56195	2	33
56212	5	33

-- 




--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/power-index-tp7586862.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From bogdan.antonescu at manchester.ac.uk  Mon Aug  4 16:02:08 2014
From: bogdan.antonescu at manchester.ac.uk (Adrian Antonescu)
Date: Mon, 4 Aug 2014 14:02:08 +0000
Subject: [R-sig-Geo] Kernel density map of severe weather events
Message-ID: <3CB2260786D64F44BA62080EE73E2395BFF8CC@MBXP14.ds.man.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140804/bc015449/attachment.pl>

From ftonini84 at gmail.com  Mon Aug  4 16:38:21 2014
From: ftonini84 at gmail.com (Francesco Tonini)
Date: Mon, 04 Aug 2014 10:38:21 -0400
Subject: [R-sig-Geo] Error gstat function krigeST
In-Reply-To: <53DDFD8C.7020506@uni-muenster.de>
References: <53DA6498.6010606@gmail.com> <53DDFD8C.7020506@uni-muenster.de>
Message-ID: <53DF9ADD.5000808@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140804/6d299aa0/attachment.pl>

From Philip.Haines at rms.com  Mon Aug  4 18:23:45 2014
From: Philip.Haines at rms.com (Philip Haines)
Date: Mon, 4 Aug 2014 17:23:45 +0100
Subject: [R-sig-Geo] maptools/kmlPolygons not outputting all Polygon objects
Message-ID: <FDA6B65298E3664FACCCD6F34EB939E4160C9FF796@MAILUK2.rms.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140804/a04fbd2b/attachment.pl>

From rodaromero at gmail.com  Tue Aug  5 00:25:01 2014
From: rodaromero at gmail.com (David Romero)
Date: Mon, 4 Aug 2014 17:25:01 -0500
Subject: [R-sig-Geo] Anisotropy variogram
Message-ID: <CAJx8RnEscQWOSBNfPF2gEmeHdrcCxDbRFOM_-yEC3g7n2FRP9Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140804/5cff571f/attachment.pl>

From r.turner at auckland.ac.nz  Tue Aug  5 00:27:51 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 05 Aug 2014 10:27:51 +1200
Subject: [R-sig-Geo] Kernel density map of severe weather events
In-Reply-To: <3CB2260786D64F44BA62080EE73E2395BFF8CC@MBXP14.ds.man.ac.uk>
References: <3CB2260786D64F44BA62080EE73E2395BFF8CC@MBXP14.ds.man.ac.uk>
Message-ID: <53E008E7.4030007@auckland.ac.nz>

On 05/08/14 02:02, Adrian Antonescu wrote:
> Hi all,
>
> I am trying to create a kernel density estimation map of points
> representing locations of severe weather events (attached script). The
> map and the event (point) data are imported from .shp files with LongLat
> projection. First the map and the point data were converted to a Albers
> Equal-Area Conic projection and then the kernel density was calculated
> using: density.ppp(ppp.regular, kernel = "gaussian",
> sigma=bw.diggle(ppp.regular)). The resulting map looks OK, but I have
> one question: what are the units of the density plot? Since I am using
> Albers Equal-Area Conic with units in meter, the resulting density
> should be events per square meters, but I am not sure if this is right.

The units will be events per square "unit" where "unit" is whatever the 
unit designation is for the pattern to which density.ppp() is being 
applied.  So if the units of "ppp.regular" are metres, then density 
estimate produced by density.ppp() will be in events (points) per square 
metre.

The only assumption made by density.ppp() is that the distance metric 
for the points under study is Euclidean.

cheers,

Rolf Turner

P. S. You can save yourself a few key strokes by typing

     density(ppp.regular,sigma=bw.diggle)

* density() dispatches to (the method) density.ppp()
* sigma can be a *function* (such as bw.diggle)
* the Gaussian kernel is the default

R. T.

-- 
Rolf Turner
Technical Editor ANZJS


From wqx1976 at zjut.edu.cn  Tue Aug  5 11:55:47 2014
From: wqx1976 at zjut.edu.cn (Õı«Ïœ≤)
Date: Tue, 05 Aug 2014 17:55:47 +0800
Subject: [R-sig-Geo] Auto-Re: R-sig-Geo Digest, Vol 132, Issue 5
Message-ID: <HLXALERCPFSGESSTINBALDPQBVGS.wqx1976@zjut.edu.cn>

??????


From josh.london at noaa.gov  Tue Aug  5 19:02:13 2014
From: josh.london at noaa.gov (Josh London)
Date: Tue, 5 Aug 2014 10:02:13 -0700
Subject: [R-sig-Geo] GeoJSON errors when reading/writing with rgdal
In-Reply-To: <alpine.LRH.2.03.1407282032230.32714@reclus.nhh.no>
References: <CA+wRd=U55=TyrfsiqK4U23gwbY_zS2mkg8EhBfa7-gupO9je2Q@mail.gmail.com>
	<CA+wRd=U=KaOjDt0xSRXpNG7HpEU7fsaLVjPV4T=UYgS6D1bbLQ@mail.gmail.com>
	<alpine.LRH.2.03.1407282032230.32714@reclus.nhh.no>
Message-ID: <CA+wRd=Wo2ryof=u0iZwmGXfaYnYJ9_VbCnuz_8nBhPinLum70w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140805/48fe701b/attachment.pl>

From rodaromero at gmail.com  Tue Aug  5 19:52:13 2014
From: rodaromero at gmail.com (David Romero)
Date: Tue, 5 Aug 2014 12:52:13 -0500
Subject: [R-sig-Geo] Anisotropy variogram and R squared
Message-ID: <CAJx8RnGZOvT_NDb+8ufw=P6R=+RtHBrzQZw4gRSbdR89vr4CFw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140805/74c12cad/attachment.pl>

From stevenhuyi at gmail.com  Wed Aug  6 09:42:06 2014
From: stevenhuyi at gmail.com (stevenhuyi)
Date: Wed, 6 Aug 2014 00:42:06 -0700 (PDT)
Subject: [R-sig-Geo] spatio-temporal simultaneous autoregression model
Message-ID: <1407310926028-7586871.post@n2.nabble.com>

Hi everyone,

It seems that there is no specific R package to implement the space-time SAR
model. I happend to find an article entitled "Spatio-temporal regression
models for deforestation in the Brazilian Amazon" (literature information:
STDM 2011, The International Symposium on Spatial-Temporal Analysis and Data
Mining, University College London - 18th-20th July 2011), in which
spatio-temporal SAR models were implemented by package spautolm.
Unfortunately, the codes were not provided. Has anyone ever used this
package or any other package to implement the space-time SAR model? Any
response will be much appreciated!

With regards

Yi Hu

Assistant Professor 
Department of Epidemiology 
Fudan University



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/spatio-temporal-simultaneous-autoregression-model-tp7586871.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From Roger.Bivand at nhh.no  Wed Aug  6 10:30:33 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 6 Aug 2014 10:30:33 +0200
Subject: [R-sig-Geo] spatio-temporal simultaneous autoregression model
In-Reply-To: <1407310926028-7586871.post@n2.nabble.com>
References: <1407310926028-7586871.post@n2.nabble.com>
Message-ID: <alpine.LRH.2.03.1408061027390.16887@reclus.nhh.no>

On Wed, 6 Aug 2014, stevenhuyi wrote:

> Hi everyone,
>
> It seems that there is no specific R package to implement the space-time SAR
> model. I happend to find an article entitled "Spatio-temporal regression
> models for deforestation in the Brazilian Amazon" (literature information:
> STDM 2011, The International Symposium on Spatial-Temporal Analysis and Data
> Mining, University College London - 18th-20th July 2011), in which
> spatio-temporal SAR models were implemented by package spautolm.

spautolm is a function in the spdep package, and fits cross-sectional 
simultaneous autoregressive models. Its use with the spatial weights 
matrix multiplied by Kronecker product corresponds to the use of the splm 
package to fit a spatial panel error model. Try that package and its 
accompanying JSS paper if your space-time data are balanced.

Roger

> Unfortunately, the codes were not provided. Has anyone ever used this
> package or any other package to implement the space-time SAR model? Any
> response will be much appreciated!
>
> With regards
>
> Yi Hu
>
> Assistant Professor
> Department of Epidemiology
> Fudan University
>
>
>
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/spatio-temporal-simultaneous-autoregression-model-tp7586871.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From dschlaep at uwyo.edu  Wed Aug  6 11:11:24 2014
From: dschlaep at uwyo.edu (Daniel Rodolphe Schlaepfer)
Date: Wed, 6 Aug 2014 09:11:24 +0000
Subject: [R-sig-Geo] maptools/SpatialPolygons2PolySet produces ascending
 instead of descending POS numbers for polygons with holes
Message-ID: <0CC04A5E-EE37-4207-859B-9D0403B20F4C@uwyo.edu>

Hello all,

I try to convert a sp SpatialPolygons object with a hole to a PBS PolySet object - my ultimate goal is to plot the polygon with hatching considering the hole.

My problem is that maptools/SpatialPolygons2PolySet only produces PolySet objects with increasing POS even for polygons with holes; however, the documentation of PolySet indicates that ?We adopt the convention that POS goes from 1 to n along an outer boundary, but from n to 1 along an inner boundary, regardless of rotational direction.? 


#Create simple doughnut-shaped polygon
library(sp)
library(maptools)

coords1 <- matrix(c(108, -54, -108, -54, -108, 54, 108, 54, 108, -54), ncol=2, byrow=TRUE)
coords2 <- matrix(c(36, -18, -36, -18, -36, 18, 36, 18, 36, -18), ncol=2, byrow=TRUE)

polySP <- SpatialPolygons(list(Polygons(list(Polygon(coords1, hole=FALSE), Polygon(coords2, hole=TRUE)), ID=1)), proj4string=CRS("+proj=longlat +datum=WGS84"))

#Convert sp-SpatialPolygons to PBS-PolySet with maptools function
polyPBS <- SpatialPolygons2PolySet(polySP)

#-> POS for SID == 2 are increasing and thus do not reflect PBS standards for a polygon with a hole
   PID SID POS    X   Y
1    1   1   1  108 -54
2    1   1   2 -108 -54
3    1   1   3 -108  54
4    1   1   4  108  54
5    1   1   5  108 -54
6    1   2   1   36 -18
7    1   2   2   36  18
8    1   2   3  -36  18
9    1   2   4  -36 -18
10   1   2   5   36 -18

I believe that it would require only a small change to maptools/SpatialPolygons2PolySet to produce PolySet objects that meet the PBS standards also for polygons with holes, i.e., replace the line
	POS <- c(POS, 1:k)
with
	POS <- if(slot(srs[[j]], "hole")) c(POS, k:1) else c(POS, 1:k)
inside the loops: for (i in 1:n) ? for (j in 1:m) ?



Sincerely,
Daniel Schlaepfer


My session infos:
sessionInfo()
	R version 3.1.1 (2014-07-10)
	Platform: x86_64-apple-darwin13.3.0 (64-bit)

	locale:
	[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

	attached base packages:
	[1] stats     graphics  grDevices
	[4] utils     datasets  methods  
	[7] base     

	other attached packages:
	[1] PBSmapping_2.67.60 maptools_0.8-30   
	[3] sp_1.0-15         

	loaded via a namespace (and not attached):
	[1] foreign_0.8-61  grid_3.1.1     
	[3] lattice_0.20-29


-------------------------------------------------------
Daniel Schlaepfer, PhD
University of Wyoming
Laramie, WY 82071


From stevenhuyi at gmail.com  Wed Aug  6 11:13:28 2014
From: stevenhuyi at gmail.com (stevenhuyi)
Date: Wed, 6 Aug 2014 02:13:28 -0700 (PDT)
Subject: [R-sig-Geo] spatio-temporal simultaneous autoregression model
In-Reply-To: <alpine.LRH.2.03.1408061027390.16887@reclus.nhh.no>
References: <1407310926028-7586871.post@n2.nabble.com>
	<alpine.LRH.2.03.1408061027390.16887@reclus.nhh.no>
Message-ID: <1407316408751-7586874.post@n2.nabble.com>

Thanks, Roger. I will try.
It's my fault to mistakenly write the spautolm function as a package.
what do mean by saying "if your space-time data are balanced". My data is
multiple years of prevalence data of schistosomiasis at the county level,
combined with data of environmental determinants.






> Hi everyone, 
> 
> It seems that there is no specific R package to implement the space-time
> SAR 
> model. I happend to find an article entitled "Spatio-temporal regression 
> models for deforestation in the Brazilian Amazon" (literature information: 
> STDM 2011, The International Symposium on Spatial-Temporal Analysis and
> Data 
> Mining, University College London - 18th-20th July 2011), in which 
> spatio-temporal SAR models were implemented by package spautolm. 

spautolm is a function in the spdep package, and fits cross-sectional 
simultaneous autoregressive models. Its use with the spatial weights 
matrix multiplied by Kronecker product corresponds to the use of the splm 
package to fit a spatial panel error model. Try that package and its 
accompanying JSS paper if your space-time data are balanced. 

Roger 




--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/spatio-temporal-simultaneous-autoregression-model-tp7586871p7586874.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From mervynl at hotmail.com  Wed Aug  6 11:58:15 2014
From: mervynl at hotmail.com (=?iso-8859-1?B?TWVydnluINMnIEz6aW5n?=)
Date: Wed, 6 Aug 2014 05:58:15 -0400
Subject: [R-sig-Geo] algorithm to compare a building in two different
	datasets
Message-ID: <COL127-W23D6E2355CD9290AD8CE32B8E00@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140806/7c91685d/attachment.pl>

From wqx1976 at zjut.edu.cn  Wed Aug  6 11:55:55 2014
From: wqx1976 at zjut.edu.cn (Õı«Ïœ≤)
Date: Wed, 06 Aug 2014 17:55:55 +0800
Subject: [R-sig-Geo] Auto-Re: R-sig-Geo Digest, Vol 132, Issue 6
Message-ID: <VPDRQRWGHWGVXDWTCNJWKRKXLSBO.wqx1976@zjut.edu.cn>

??????


From rgenevest at free.fr  Wed Aug  6 12:38:04 2014
From: rgenevest at free.fr (Remi Genevest)
Date: Wed, 6 Aug 2014 03:38:04 -0700 (PDT)
Subject: [R-sig-Geo] spTransform() error : "load package rgdal for
	spTransform methods"
Message-ID: <1407321484913-7586877.post@n2.nabble.com>

Hi,
I am facing a recurrent problem associated with spTransform() function from
rgdal package.
While I try to change the CRS of a SpatialGrid, I get the following error : 

Error in spTransform(grd, CRS("+init=epsg:3857")) : 
  load package rgdal for spTransform methods

Does anybody know how to solve it?

Here is my code : 

> library(rgdal)
> # create the SpatialGrid
> cc<-c(10,20)
> cs<-c(0.1,0.1)
> cd<-c(200,200)
> grd<-GridTopology(cellcentre.offset=cc,cellsize=cs,cells.dim=cd)
> grd<-SpatialGrid(grd)
> # set the CRS :
> proj4string(grd)<-CRS("+proj=longlat +datum=WGS84")
> # transform the CRS : 
> grd<-spTransform(grd,CRS("+init=epsg:3857"))
Error in spTransform(grd, CRS("+init=epsg:3857")) : 
  load package rgdal for spTransform methods
> 
> ###################################################### R info session 
> sessionInfo()
R version 3.1.1 (2014-07-10)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_GB.UTF-8       LC_NUMERIC=C              
LC_TIME=en_GB.UTF-8        LC_COLLATE=en_GB.UTF-8    
LC_MONETARY=en_GB.UTF-8   
 [6] LC_MESSAGES=en_GB.UTF-8    LC_PAPER=en_GB.UTF-8       LC_NAME=C                 
LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] grid      stats     graphics  grDevices utils     datasets  methods  
base     

other attached packages:
[1] rgdal_0.8-16    raster_2.2-31   hexbin_1.26.3   lattice_0.20-29
sp_1.0-15      

loaded via a namespace (and not attached):
 [1] colorspace_1.2-4 digest_0.6.4     ggplot2_1.0.0    gtable_0.1.2    
MASS_7.3-33      munsell_0.4.2    plyr_1.8.1       proto_0.3-10    
Rcpp_0.11.2     
[10] reshape2_1.4     scales_0.2.4     stringr_0.6.2    tools_3.1.1     



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/spTransform-error-load-package-rgdal-for-spTransform-methods-tp7586877.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From Roger.Bivand at nhh.no  Wed Aug  6 12:52:30 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 6 Aug 2014 12:52:30 +0200
Subject: [R-sig-Geo] maptools/SpatialPolygons2PolySet produces ascending
 instead of descending POS numbers for polygons with holes
In-Reply-To: <0CC04A5E-EE37-4207-859B-9D0403B20F4C@uwyo.edu>
References: <0CC04A5E-EE37-4207-859B-9D0403B20F4C@uwyo.edu>
Message-ID: <alpine.LRH.2.03.1408061247290.17497@reclus.nhh.no>

On Wed, 6 Aug 2014, Daniel Rodolphe Schlaepfer wrote:

> Hello all,
>
> I try to convert a sp SpatialPolygons object with a hole to a PBS 
> PolySet object - my ultimate goal is to plot the polygon with hatching 
> considering the hole.

The problem is not that you need a PolySet representation, but that you 
need to set the polygon background explicitly to a value other than 
"transparent" using the pbg= argument:

plot(polySP, density=10, angle=45, pbg="white")

or adjust par("bg") to suit. When hatching is used, polypath is not used, 
so automatic handling of holes in the plot method is not available.

Roger

>
> My problem is that maptools/SpatialPolygons2PolySet only produces 
> PolySet objects with increasing POS even for polygons with holes; 
> however, the documentation of PolySet indicates that ?We adopt the 
> convention that POS goes from 1 to n along an outer boundary, but from n 
> to 1 along an inner boundary, regardless of rotational direction.?
>
>
> #Create simple doughnut-shaped polygon
> library(sp)
> library(maptools)
>
> coords1 <- matrix(c(108, -54, -108, -54, -108, 54, 108, 54, 108, -54), ncol=2, byrow=TRUE)
> coords2 <- matrix(c(36, -18, -36, -18, -36, 18, 36, 18, 36, -18), ncol=2, byrow=TRUE)
>
> polySP <- SpatialPolygons(list(Polygons(list(Polygon(coords1, hole=FALSE), Polygon(coords2, hole=TRUE)), ID=1)), proj4string=CRS("+proj=longlat +datum=WGS84"))
>
> #Convert sp-SpatialPolygons to PBS-PolySet with maptools function
> polyPBS <- SpatialPolygons2PolySet(polySP)
>
> #-> POS for SID == 2 are increasing and thus do not reflect PBS standards for a polygon with a hole
>   PID SID POS    X   Y
> 1    1   1   1  108 -54
> 2    1   1   2 -108 -54
> 3    1   1   3 -108  54
> 4    1   1   4  108  54
> 5    1   1   5  108 -54
> 6    1   2   1   36 -18
> 7    1   2   2   36  18
> 8    1   2   3  -36  18
> 9    1   2   4  -36 -18
> 10   1   2   5   36 -18
>
> I believe that it would require only a small change to maptools/SpatialPolygons2PolySet to produce PolySet objects that meet the PBS standards also for polygons with holes, i.e., replace the line
> 	POS <- c(POS, 1:k)
> with
> 	POS <- if(slot(srs[[j]], "hole")) c(POS, k:1) else c(POS, 1:k)
> inside the loops: for (i in 1:n) ? for (j in 1:m) ?
>
>
>
> Sincerely,
> Daniel Schlaepfer
>
>
> My session infos:
> sessionInfo()
> 	R version 3.1.1 (2014-07-10)
> 	Platform: x86_64-apple-darwin13.3.0 (64-bit)
>
> 	locale:
> 	[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> 	attached base packages:
> 	[1] stats     graphics  grDevices
> 	[4] utils     datasets  methods
> 	[7] base
>
> 	other attached packages:
> 	[1] PBSmapping_2.67.60 maptools_0.8-30
> 	[3] sp_1.0-15
>
> 	loaded via a namespace (and not attached):
> 	[1] foreign_0.8-61  grid_3.1.1
> 	[3] lattice_0.20-29
>
>
> -------------------------------------------------------
> Daniel Schlaepfer, PhD
> University of Wyoming
> Laramie, WY 82071
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no

From Roger.Bivand at nhh.no  Wed Aug  6 12:58:58 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 6 Aug 2014 12:58:58 +0200
Subject: [R-sig-Geo] spTransform() error : "load package rgdal for
 spTransform methods"
In-Reply-To: <1407321484913-7586877.post@n2.nabble.com>
References: <1407321484913-7586877.post@n2.nabble.com>
Message-ID: <alpine.LRH.2.03.1408061255090.17497@reclus.nhh.no>

On Wed, 6 Aug 2014, Remi Genevest wrote:

> Hi,
> I am facing a recurrent problem associated with spTransform() function from
> rgdal package.
> While I try to change the CRS of a SpatialGrid, I get the following error :
>
> Error in spTransform(grd, CRS("+init=epsg:3857")) :
>  load package rgdal for spTransform methods

Thanks for the example. You cannot use spTransform on SpatialGrid objects 
- this is known as warping, and does not return a regular grid in general. 
You can do:

grd<-spTransform(as(grd, "SpatialPoints"), CRS("+init=epsg:3857"))

but:

gridded(grd) <- TRUE
#suggested tolerance minimum: 0.223608
#Error in points2grid(points, tolerance, round) :
#  dimension 2 : coordinate intervals are not constant

Try warping instead.

Hope this clarifies,

Roger

>
> Does anybody know how to solve it?
>
> Here is my code :
>
>> library(rgdal)
>> # create the SpatialGrid
>> cc<-c(10,20)
>> cs<-c(0.1,0.1)
>> cd<-c(200,200)
>> grd<-GridTopology(cellcentre.offset=cc,cellsize=cs,cells.dim=cd)
>> grd<-SpatialGrid(grd)
>> # set the CRS :
>> proj4string(grd)<-CRS("+proj=longlat +datum=WGS84")
>> # transform the CRS :
>> grd<-spTransform(grd,CRS("+init=epsg:3857"))
> Error in spTransform(grd, CRS("+init=epsg:3857")) :
>  load package rgdal for spTransform methods
>>
>> ###################################################### R info session
>> sessionInfo()
> R version 3.1.1 (2014-07-10)
> Platform: x86_64-pc-linux-gnu (64-bit)
>
> locale:
> [1] LC_CTYPE=en_GB.UTF-8       LC_NUMERIC=C
> LC_TIME=en_GB.UTF-8        LC_COLLATE=en_GB.UTF-8
> LC_MONETARY=en_GB.UTF-8
> [6] LC_MESSAGES=en_GB.UTF-8    LC_PAPER=en_GB.UTF-8       LC_NAME=C
> LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] grid      stats     graphics  grDevices utils     datasets  methods
> base
>
> other attached packages:
> [1] rgdal_0.8-16    raster_2.2-31   hexbin_1.26.3   lattice_0.20-29
> sp_1.0-15
>
> loaded via a namespace (and not attached):
> [1] colorspace_1.2-4 digest_0.6.4     ggplot2_1.0.0    gtable_0.1.2
> MASS_7.3-33      munsell_0.4.2    plyr_1.8.1       proto_0.3-10
> Rcpp_0.11.2
> [10] reshape2_1.4     scales_0.2.4     stringr_0.6.2    tools_3.1.1
>
>
>
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/spTransform-error-load-package-rgdal-for-spTransform-methods-tp7586877.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From janka.vanschoenwinkel at uhasselt.be  Wed Aug  6 13:02:04 2014
From: janka.vanschoenwinkel at uhasselt.be (Janka VANSCHOENWINKEL)
Date: Wed, 6 Aug 2014 13:02:04 +0200
Subject: [R-sig-Geo] Spatial partitioning of direct,
	indirect and total impacts (2)
Message-ID: <CAHymutLwG08SMWdtOmdyY8x8n3bVEbCgkjYz-9YM4P9HvM0aGw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140806/60841220/attachment.pl>

From mdsumner at gmail.com  Wed Aug  6 13:04:55 2014
From: mdsumner at gmail.com (Michael Sumner)
Date: Wed, 6 Aug 2014 21:04:55 +1000
Subject: [R-sig-Geo] spTransform() error : "load package rgdal for
 spTransform methods"
In-Reply-To: <1407321484913-7586877.post@n2.nabble.com>
References: <1407321484913-7586877.post@n2.nabble.com>
Message-ID: <CAAcGz9-h5kytt47+MOgGXJCUQKWww422nrmEdNg66v_UTnYHMA@mail.gmail.com>

It's an ill-targeted error message. But, you aren't supposed to
reproject a SpatialGrid, both because sp/rgdal cannot do that without
low-level usage and since it's really an empty container (that can be
a SpatialGridDataFrame)

Use raster::projectRaster after conversion to raster objects (or
probably rethink whether you really need to reproject a grid in the
first place, often it's totally unnecessary and done rather than other
simpler tasks to achieve the same end).

Cheers, Mike.

On Wed, Aug 6, 2014 at 8:38 PM, Remi Genevest <rgenevest at free.fr> wrote:
> Hi,
> I am facing a recurrent problem associated with spTransform() function from
> rgdal package.
> While I try to change the CRS of a SpatialGrid, I get the following error :
>
> Error in spTransform(grd, CRS("+init=epsg:3857")) :
>   load package rgdal for spTransform methods
>
> Does anybody know how to solve it?
>
> Here is my code :
>
>> library(rgdal)
>> # create the SpatialGrid
>> cc<-c(10,20)
>> cs<-c(0.1,0.1)
>> cd<-c(200,200)
>> grd<-GridTopology(cellcentre.offset=cc,cellsize=cs,cells.dim=cd)
>> grd<-SpatialGrid(grd)
>> # set the CRS :
>> proj4string(grd)<-CRS("+proj=longlat +datum=WGS84")
>> # transform the CRS :
>> grd<-spTransform(grd,CRS("+init=epsg:3857"))
> Error in spTransform(grd, CRS("+init=epsg:3857")) :
>   load package rgdal for spTransform methods
>>
>> ###################################################### R info session
>> sessionInfo()
> R version 3.1.1 (2014-07-10)
> Platform: x86_64-pc-linux-gnu (64-bit)
>
> locale:
>  [1] LC_CTYPE=en_GB.UTF-8       LC_NUMERIC=C
> LC_TIME=en_GB.UTF-8        LC_COLLATE=en_GB.UTF-8
> LC_MONETARY=en_GB.UTF-8
>  [6] LC_MESSAGES=en_GB.UTF-8    LC_PAPER=en_GB.UTF-8       LC_NAME=C
> LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] grid      stats     graphics  grDevices utils     datasets  methods
> base
>
> other attached packages:
> [1] rgdal_0.8-16    raster_2.2-31   hexbin_1.26.3   lattice_0.20-29
> sp_1.0-15
>
> loaded via a namespace (and not attached):
>  [1] colorspace_1.2-4 digest_0.6.4     ggplot2_1.0.0    gtable_0.1.2
> MASS_7.3-33      munsell_0.4.2    plyr_1.8.1       proto_0.3-10
> Rcpp_0.11.2
> [10] reshape2_1.4     scales_0.2.4     stringr_0.6.2    tools_3.1.1
>
>
>
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/spTransform-error-load-package-rgdal-for-spTransform-methods-tp7586877.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



-- 
Michael Sumner
Software and Database Engineer
Australian Antarctic Division
Hobart, Australia
e-mail: mdsumner at gmail.com


From Roger.Bivand at nhh.no  Wed Aug  6 13:08:26 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 6 Aug 2014 13:08:26 +0200
Subject: [R-sig-Geo] Spatial partitioning of direct,
 indirect and total impacts (2)
In-Reply-To: <CAHymutLwG08SMWdtOmdyY8x8n3bVEbCgkjYz-9YM4P9HvM0aGw@mail.gmail.com>
References: <CAHymutLwG08SMWdtOmdyY8x8n3bVEbCgkjYz-9YM4P9HvM0aGw@mail.gmail.com>
Message-ID: <alpine.LRH.2.03.1408061306290.17497@reclus.nhh.no>

On Wed, 6 Aug 2014, Janka VANSCHOENWINKEL wrote:

> Dear list members,
>
> I am sorry that I am going to repeat my question. I do not want to insist,
> but since I sent it right before the weekend, the timing was probably not
> so good and I thought it would be good to give it a second chance.
>
> I am trying to reproduce table 2.1 (p. 41) of LeSage and Pace (2009).
>
> This is a table containing the direct, indirect and total impacts of a SAR
> model (since the regression coefficients cannot be interpreted directly
> because of spillovers), *partitioned by W-order*.
>
> I am able to produce the first part of the table ( impacts() in R ), but
> for the moment I don't have a clue on *how to split these impacts per power
> of W*. I would like to do this both for a SAR and for a SDM model.
>

Please see the Q= argument in ?impacts. Setting Q=# should give # splits 
for the first # powers.

Roger

> Please, could somebody give me a hint on how to do this? I would be very
> grateful!
>
> Thank you very much in advance,
>
> Janka
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From dschlaep at uwyo.edu  Wed Aug  6 13:47:16 2014
From: dschlaep at uwyo.edu (Daniel Rodolphe Schlaepfer)
Date: Wed, 6 Aug 2014 11:47:16 +0000
Subject: [R-sig-Geo] maptools/SpatialPolygons2PolySet produces ascending
 instead of descending POS numbers for polygons with holes
In-Reply-To: <alpine.LRH.2.03.1408061247290.17497@reclus.nhh.no>
References: <0CC04A5E-EE37-4207-859B-9D0403B20F4C@uwyo.edu>
	<alpine.LRH.2.03.1408061247290.17497@reclus.nhh.no>
Message-ID: <A7EA724F-1ACC-4A21-ACF7-8C29BAC99592@uwyo.edu>

Thank you for the suggestion. Unfortunately, this does not work for my application: I plot the polygon on top of other another plot where I need the holes of the polygon to be transparent. For instance, I don?t want the African countries in the following examples to be covered by white:

library(maps)
map()
plot(polySP, density=10, angle=45, pbg=?white")

However, this was not the point that I try to ask about. My point is that maptools/SpatialPolygons2PolySet does not translate into correct PolySet objects as illustrated in my previous example.

Thanks,
Daniel

On Aug 6, 2014, at 12:52 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:

> On Wed, 6 Aug 2014, Daniel Rodolphe Schlaepfer wrote:
> 
>> Hello all,
>> 
>> I try to convert a sp SpatialPolygons object with a hole to a PBS PolySet object - my ultimate goal is to plot the polygon with hatching considering the hole.
> 
> The problem is not that you need a PolySet representation, but that you need to set the polygon background explicitly to a value other than "transparent" using the pbg= argument:
> 
> plot(polySP, density=10, angle=45, pbg="white")
> 
> or adjust par("bg") to suit. When hatching is used, polypath is not used, so automatic handling of holes in the plot method is not available.
> 
> Roger
> 
>> 
>> My problem is that maptools/SpatialPolygons2PolySet only produces PolySet objects with increasing POS even for polygons with holes; however, the documentation of PolySet indicates that ?We adopt the convention that POS goes from 1 to n along an outer boundary, but from n to 1 along an inner boundary, regardless of rotational direction.?
>> 
>> 
>> #Create simple doughnut-shaped polygon
>> library(sp)
>> library(maptools)
>> 
>> coords1 <- matrix(c(108, -54, -108, -54, -108, 54, 108, 54, 108, -54), ncol=2, byrow=TRUE)
>> coords2 <- matrix(c(36, -18, -36, -18, -36, 18, 36, 18, 36, -18), ncol=2, byrow=TRUE)
>> 
>> polySP <- SpatialPolygons(list(Polygons(list(Polygon(coords1, hole=FALSE), Polygon(coords2, hole=TRUE)), ID=1)), proj4string=CRS("+proj=longlat +datum=WGS84"))
>> 
>> #Convert sp-SpatialPolygons to PBS-PolySet with maptools function
>> polyPBS <- SpatialPolygons2PolySet(polySP)
>> 
>> #-> POS for SID == 2 are increasing and thus do not reflect PBS standards for a polygon with a hole
>>  PID SID POS    X   Y
>> 1    1   1   1  108 -54
>> 2    1   1   2 -108 -54
>> 3    1   1   3 -108  54
>> 4    1   1   4  108  54
>> 5    1   1   5  108 -54
>> 6    1   2   1   36 -18
>> 7    1   2   2   36  18
>> 8    1   2   3  -36  18
>> 9    1   2   4  -36 -18
>> 10   1   2   5   36 -18
>> 
>> I believe that it would require only a small change to maptools/SpatialPolygons2PolySet to produce PolySet objects that meet the PBS standards also for polygons with holes, i.e., replace the line
>> 	POS <- c(POS, 1:k)
>> with
>> 	POS <- if(slot(srs[[j]], "hole")) c(POS, k:1) else c(POS, 1:k)
>> inside the loops: for (i in 1:n) ? for (j in 1:m) ?
>> 
>> 
>> 
>> Sincerely,
>> Daniel Schlaepfer
>> 
>> 
>> My session infos:
>> sessionInfo()
>> 	R version 3.1.1 (2014-07-10)
>> 	Platform: x86_64-apple-darwin13.3.0 (64-bit)
>> 
>> 	locale:
>> 	[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>> 
>> 	attached base packages:
>> 	[1] stats     graphics  grDevices
>> 	[4] utils     datasets  methods
>> 	[7] base
>> 
>> 	other attached packages:
>> 	[1] PBSmapping_2.67.60 maptools_0.8-30
>> 	[3] sp_1.0-15
>> 
>> 	loaded via a namespace (and not attached):
>> 	[1] foreign_0.8-61  grid_3.1.1
>> 	[3] lattice_0.20-29
>> 
>> 
>> -------------------------------------------------------
>> Daniel Schlaepfer, PhD
>> University of Wyoming
>> Laramie, WY 82071
>> 
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> 
> 
> -- 
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Wed Aug  6 15:02:03 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 6 Aug 2014 15:02:03 +0200
Subject: [R-sig-Geo] maptools/SpatialPolygons2PolySet produces ascending
 instead of descending POS numbers for polygons with holes
In-Reply-To: <A7EA724F-1ACC-4A21-ACF7-8C29BAC99592@uwyo.edu>
References: <0CC04A5E-EE37-4207-859B-9D0403B20F4C@uwyo.edu>
	<alpine.LRH.2.03.1408061247290.17497@reclus.nhh.no>
	<A7EA724F-1ACC-4A21-ACF7-8C29BAC99592@uwyo.edu>
Message-ID: <alpine.LRH.2.03.1408061455420.17497@reclus.nhh.no>

On Wed, 6 Aug 2014, Daniel Rodolphe Schlaepfer wrote:

> Thank you for the suggestion. Unfortunately, this does not work for my 
> application: I plot the polygon on top of other another plot where I 
> need the holes of the polygon to be transparent. For instance, I don?t 
> want the African countries in the following examples to be covered by 
> white:
>
> library(maps)
> map()
> plot(polySP, density=10, angle=45, pbg=?white")

Obviously not, these are base graphics, and you have to consider the 
plotting order:

plot(polySP, density=10, angle=45, pbg="white", axes=TRUE)
map(add=TRUE)

>
> However, this was not the point that I try to ask about. My point is 
> that maptools/SpatialPolygons2PolySet does not translate into correct 
> PolySet objects as illustrated in my previous example.

Since you no longer need PolySet objects, why? Maybe the coercion method 
can be fixed, but it is not a priority - patch welcomed.

Roger

>
> Thanks,
> Daniel
>
> On Aug 6, 2014, at 12:52 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>
>> On Wed, 6 Aug 2014, Daniel Rodolphe Schlaepfer wrote:
>>
>>> Hello all,
>>>
>>> I try to convert a sp SpatialPolygons object with a hole to a PBS PolySet object - my ultimate goal is to plot the polygon with hatching considering the hole.
>>
>> The problem is not that you need a PolySet representation, but that you need to set the polygon background explicitly to a value other than "transparent" using the pbg= argument:
>>
>> plot(polySP, density=10, angle=45, pbg="white")
>>
>> or adjust par("bg") to suit. When hatching is used, polypath is not used, so automatic handling of holes in the plot method is not available.
>>
>> Roger
>>
>>>
>>> My problem is that maptools/SpatialPolygons2PolySet only produces PolySet objects with increasing POS even for polygons with holes; however, the documentation of PolySet indicates that ?We adopt the convention that POS goes from 1 to n along an outer boundary, but from n to 1 along an inner boundary, regardless of rotational direction.?
>>>
>>>
>>> #Create simple doughnut-shaped polygon
>>> library(sp)
>>> library(maptools)
>>>
>>> coords1 <- matrix(c(108, -54, -108, -54, -108, 54, 108, 54, 108, -54), ncol=2, byrow=TRUE)
>>> coords2 <- matrix(c(36, -18, -36, -18, -36, 18, 36, 18, 36, -18), ncol=2, byrow=TRUE)
>>>
>>> polySP <- SpatialPolygons(list(Polygons(list(Polygon(coords1, hole=FALSE), Polygon(coords2, hole=TRUE)), ID=1)), proj4string=CRS("+proj=longlat +datum=WGS84"))
>>>
>>> #Convert sp-SpatialPolygons to PBS-PolySet with maptools function
>>> polyPBS <- SpatialPolygons2PolySet(polySP)
>>>
>>> #-> POS for SID == 2 are increasing and thus do not reflect PBS standards for a polygon with a hole
>>>  PID SID POS    X   Y
>>> 1    1   1   1  108 -54
>>> 2    1   1   2 -108 -54
>>> 3    1   1   3 -108  54
>>> 4    1   1   4  108  54
>>> 5    1   1   5  108 -54
>>> 6    1   2   1   36 -18
>>> 7    1   2   2   36  18
>>> 8    1   2   3  -36  18
>>> 9    1   2   4  -36 -18
>>> 10   1   2   5   36 -18
>>>
>>> I believe that it would require only a small change to maptools/SpatialPolygons2PolySet to produce PolySet objects that meet the PBS standards also for polygons with holes, i.e., replace the line
>>> 	POS <- c(POS, 1:k)
>>> with
>>> 	POS <- if(slot(srs[[j]], "hole")) c(POS, k:1) else c(POS, 1:k)
>>> inside the loops: for (i in 1:n) ? for (j in 1:m) ?
>>>
>>>
>>>
>>> Sincerely,
>>> Daniel Schlaepfer
>>>
>>>
>>> My session infos:
>>> sessionInfo()
>>> 	R version 3.1.1 (2014-07-10)
>>> 	Platform: x86_64-apple-darwin13.3.0 (64-bit)
>>>
>>> 	locale:
>>> 	[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>>
>>> 	attached base packages:
>>> 	[1] stats     graphics  grDevices
>>> 	[4] utils     datasets  methods
>>> 	[7] base
>>>
>>> 	other attached packages:
>>> 	[1] PBSmapping_2.67.60 maptools_0.8-30
>>> 	[3] sp_1.0-15
>>>
>>> 	loaded via a namespace (and not attached):
>>> 	[1] foreign_0.8-61  grid_3.1.1
>>> 	[3] lattice_0.20-29
>>>
>>>
>>> -------------------------------------------------------
>>> Daniel Schlaepfer, PhD
>>> University of Wyoming
>>> Laramie, WY 82071
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics,
>> Helleveien 30, N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>> e-mail: Roger.Bivand at nhh.no
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no

From dschlaep at uwyo.edu  Wed Aug  6 15:44:44 2014
From: dschlaep at uwyo.edu (Daniel Rodolphe Schlaepfer)
Date: Wed, 6 Aug 2014 13:44:44 +0000
Subject: [R-sig-Geo] maptools/SpatialPolygons2PolySet produces ascending
 instead of descending POS numbers for polygons with holes
In-Reply-To: <alpine.LRH.2.03.1408061455420.17497@reclus.nhh.no>
References: <0CC04A5E-EE37-4207-859B-9D0403B20F4C@uwyo.edu>
	<alpine.LRH.2.03.1408061247290.17497@reclus.nhh.no>
	<A7EA724F-1ACC-4A21-ACF7-8C29BAC99592@uwyo.edu>
	<alpine.LRH.2.03.1408061455420.17497@reclus.nhh.no>
Message-ID: <C7CB5627-EE99-438A-9FD1-DB7CB5DD81D0@uwyo.edu>

Unfortunately, your suggestion to consider plotting order doesn?t work in general and not in my case; for instance, if I need my underlaying map to show filled polygons:

plot(polySP, density=10, angle=45, pbg="white", axes=TRUE)
map(add=TRUE, fill=TRUE, col=rainbow(n=5))

-the hatched polygon is overplotted by the map with this plotting order; if I reverse the plotting order, then the underlaying map is overplotted:

map(fill=TRUE, col=rainbow(n=5))
plot(polySP, density=10, angle=45, pbg="white", add=TRUE)

Thus, I still think this issue is not resolved. I can understand that fixing maptools/SpatialPolygons2PolySet may have a low priority. However, I already suggested a patch in my original email. Here, again, as the complete function (only one line needs to be changed, see second instance of POS <- ):

SpatialPolygons2PolySet <- function (SpP) 
{
    require(PBSmapping)
    pls <- slot(SpP, "polygons")
    n <- length(pls)
    PID <- NULL
    SID <- NULL
    POS <- NULL
    X <- NULL
    Y <- NULL
    for (i in 1:n) {
        srs <- slot(pls[[i]], "Polygons")
        m <- length(srs)
        for (j in 1:m) {
            crds <- slot(srs[[j]], "coords")
            k <- nrow(crds)
            PID <- c(PID, rep(i, k))
            SID <- c(SID, rep(j, k))
#POS <- c(POS, 1:k)
            POS <- if(slot(srs[[j]], "hole")) c(POS, k:1) else c(POS, 1:k) #Suggested fix
            X <- c(X, crds[, 1])
            Y <- c(Y, crds[, 2])
        }
    }
    PID <- as.integer(PID)
    SID <- as.integer(SID)
    POS <- as.integer(POS)
    storage.mode(X) <- "double"
    storage.mode(Y) <- "double"
    pj <- .pbsproj(SpP)
    zn <- NULL
    if (pj == "UTM") {
        zn <- attr(pj, "zone")
        attr(pj, "zone") <- NULL
    }
    res <- as.PolySet(data.frame(PID = PID, SID = SID, POS = POS, 
        X = X, Y = Y), projection = pj, zone = zn)
    res
}

Thanks,
Daniel


On Aug 6, 2014, at 3:02 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:

> On Wed, 6 Aug 2014, Daniel Rodolphe Schlaepfer wrote:
> 
>> Thank you for the suggestion. Unfortunately, this does not work for my application: I plot the polygon on top of other another plot where I need the holes of the polygon to be transparent. For instance, I don?t want the African countries in the following examples to be covered by white:
>> 
>> library(maps)
>> map()
>> plot(polySP, density=10, angle=45, pbg=?white")
> 
> Obviously not, these are base graphics, and you have to consider the plotting order:
> 
> plot(polySP, density=10, angle=45, pbg="white", axes=TRUE)
> map(add=TRUE)
> 
>> 
>> However, this was not the point that I try to ask about. My point is that maptools/SpatialPolygons2PolySet does not translate into correct PolySet objects as illustrated in my previous example.
> 
> Since you no longer need PolySet objects, why? Maybe the coercion method can be fixed, but it is not a priority - patch welcomed.
> 
> Roger
> 
>> 
>> Thanks,
>> Daniel
>> 
>> On Aug 6, 2014, at 12:52 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>> 
>>> On Wed, 6 Aug 2014, Daniel Rodolphe Schlaepfer wrote:
>>> 
>>>> Hello all,
>>>> 
>>>> I try to convert a sp SpatialPolygons object with a hole to a PBS PolySet object - my ultimate goal is to plot the polygon with hatching considering the hole.
>>> 
>>> The problem is not that you need a PolySet representation, but that you need to set the polygon background explicitly to a value other than "transparent" using the pbg= argument:
>>> 
>>> plot(polySP, density=10, angle=45, pbg="white")
>>> 
>>> or adjust par("bg") to suit. When hatching is used, polypath is not used, so automatic handling of holes in the plot method is not available.
>>> 
>>> Roger
>>> 
>>>> 
>>>> My problem is that maptools/SpatialPolygons2PolySet only produces PolySet objects with increasing POS even for polygons with holes; however, the documentation of PolySet indicates that ?We adopt the convention that POS goes from 1 to n along an outer boundary, but from n to 1 along an inner boundary, regardless of rotational direction.?
>>>> 
>>>> 
>>>> #Create simple doughnut-shaped polygon
>>>> library(sp)
>>>> library(maptools)
>>>> 
>>>> coords1 <- matrix(c(108, -54, -108, -54, -108, 54, 108, 54, 108, -54), ncol=2, byrow=TRUE)
>>>> coords2 <- matrix(c(36, -18, -36, -18, -36, 18, 36, 18, 36, -18), ncol=2, byrow=TRUE)
>>>> 
>>>> polySP <- SpatialPolygons(list(Polygons(list(Polygon(coords1, hole=FALSE), Polygon(coords2, hole=TRUE)), ID=1)), proj4string=CRS("+proj=longlat +datum=WGS84"))
>>>> 
>>>> #Convert sp-SpatialPolygons to PBS-PolySet with maptools function
>>>> polyPBS <- SpatialPolygons2PolySet(polySP)
>>>> 
>>>> #-> POS for SID == 2 are increasing and thus do not reflect PBS standards for a polygon with a hole
>>>> PID SID POS    X   Y
>>>> 1    1   1   1  108 -54
>>>> 2    1   1   2 -108 -54
>>>> 3    1   1   3 -108  54
>>>> 4    1   1   4  108  54
>>>> 5    1   1   5  108 -54
>>>> 6    1   2   1   36 -18
>>>> 7    1   2   2   36  18
>>>> 8    1   2   3  -36  18
>>>> 9    1   2   4  -36 -18
>>>> 10   1   2   5   36 -18
>>>> 
>>>> I believe that it would require only a small change to maptools/SpatialPolygons2PolySet to produce PolySet objects that meet the PBS standards also for polygons with holes, i.e., replace the line
>>>> 	POS <- c(POS, 1:k)
>>>> with
>>>> 	POS <- if(slot(srs[[j]], "hole")) c(POS, k:1) else c(POS, 1:k)
>>>> inside the loops: for (i in 1:n) ? for (j in 1:m) ?
>>>> 
>>>> 
>>>> 
>>>> Sincerely,
>>>> Daniel Schlaepfer
>>>> 
>>>> 
>>>> My session infos:
>>>> sessionInfo()
>>>> 	R version 3.1.1 (2014-07-10)
>>>> 	Platform: x86_64-apple-darwin13.3.0 (64-bit)
>>>> 
>>>> 	locale:
>>>> 	[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>>> 
>>>> 	attached base packages:
>>>> 	[1] stats     graphics  grDevices
>>>> 	[4] utils     datasets  methods
>>>> 	[7] base
>>>> 
>>>> 	other attached packages:
>>>> 	[1] PBSmapping_2.67.60 maptools_0.8-30
>>>> 	[3] sp_1.0-15
>>>> 
>>>> 	loaded via a namespace (and not attached):
>>>> 	[1] foreign_0.8-61  grid_3.1.1
>>>> 	[3] lattice_0.20-29
>>>> 
>>>> 
>>>> -------------------------------------------------------
>>>> Daniel Schlaepfer, PhD
>>>> University of Wyoming
>>>> Laramie, WY 82071
>>>> 
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at r-project.org
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>> 
>>> 
>>> --
>>> Roger Bivand
>>> Department of Economics, Norwegian School of Economics,
>>> Helleveien 30, N-5045 Bergen, Norway.
>>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>>> e-mail: Roger.Bivand at nhh.no
>> 
>> 
> 
> -- 
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no


From corey.sparks at UTSA.EDU  Wed Aug  6 16:45:22 2014
From: corey.sparks at UTSA.EDU (Corey Sparks)
Date: Wed, 6 Aug 2014 07:45:22 -0700 (PDT)
Subject: [R-sig-Geo] spatio-temporal simultaneous autoregression model
In-Reply-To: <1407310926028-7586871.post@n2.nabble.com>
References: <1407310926028-7586871.post@n2.nabble.com>
Message-ID: <1407336322247-7586886.post@n2.nabble.com>

You need to be careful with the incidence data if the Gaussian model isn't
appropriate, I assume that many counties have very low prevalence, so a
count data model may be more appropriate. I would check out INLA, it will do
Bayesian models over space and time, there are some tutorials/examples here: 
http://www.r-inla.org/examples <http://www.r-inla.org/examples>  

My 2 cents
Corey



-----
Corey Sparks
Assistant professor
Department of Demography
The University of Texas at San Antonio
501 West Cesar E Chavez Blvd
San Antonio TX 78207
Corey.sparks 'at' utsa.edu
210 458 3166 &lt;tel:210%20458%203166&gt;
Latitude: 29.423614  /  Longitude: -98.504282
--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/spatio-temporal-simultaneous-autoregression-model-tp7586871p7586886.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From stevenhuyi at gmail.com  Wed Aug  6 17:20:36 2014
From: stevenhuyi at gmail.com (stevenhuyi)
Date: Wed, 6 Aug 2014 08:20:36 -0700 (PDT)
Subject: [R-sig-Geo] spatio-temporal simultaneous autoregression model
In-Reply-To: <1407336322247-7586886.post@n2.nabble.com>
References: <1407310926028-7586871.post@n2.nabble.com>
	<1407336322247-7586886.post@n2.nabble.com>
Message-ID: <1407338436417-7586887.post@n2.nabble.com>

Thanks Corey. Yeah, what you mentioned is indeed the problem. However, does
INLA can deal with the problem of many "zero" values if a count data model
is assumed?



>You need to be careful with the incidence data if the Gaussian model isn't
appropriate, I assume that many >counties have very low prevalence, so a
count data model may be more appropriate. I would check out INLA, >it will
do Bayesian models over space and time, there are some tutorials/examples
here: http://www.r->inla.org/examples

>My 2 cents 
>Corey



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/spatio-temporal-simultaneous-autoregression-model-tp7586871p7586887.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From corey.sparks at UTSA.EDU  Wed Aug  6 20:44:54 2014
From: corey.sparks at UTSA.EDU (Corey Sparks)
Date: Wed, 6 Aug 2014 11:44:54 -0700 (PDT)
Subject: [R-sig-Geo] spatio-temporal simultaneous autoregression model
In-Reply-To: <1407338436417-7586887.post@n2.nabble.com>
References: <1407310926028-7586871.post@n2.nabble.com>
	<1407336322247-7586886.post@n2.nabble.com>
	<1407338436417-7586887.post@n2.nabble.com>
Message-ID: <1407350694995-7586888.post@n2.nabble.com>

Yes, you can choose a zero inflated poisson or negative binomial likelihood.



-----
Corey Sparks
Associate professor
Department of Demography
The University of Texas at San Antonio
501 West Cesar E Chavez Blvd
San Antonio TX 78207
coreysparks.weebly.com
210 458 3166 &lt;tel:210%20458%203166&gt;
Latitude: 29.423614  /  Longitude: -98.504282
--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/spatio-temporal-simultaneous-autoregression-model-tp7586871p7586888.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From Roger.Bivand at nhh.no  Wed Aug  6 20:54:46 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 6 Aug 2014 20:54:46 +0200
Subject: [R-sig-Geo] maptools/SpatialPolygons2PolySet produces ascending
 instead of descending POS numbers for polygons with holes
In-Reply-To: <C7CB5627-EE99-438A-9FD1-DB7CB5DD81D0@uwyo.edu>
References: <0CC04A5E-EE37-4207-859B-9D0403B20F4C@uwyo.edu>
	<alpine.LRH.2.03.1408061247290.17497@reclus.nhh.no>
	<A7EA724F-1ACC-4A21-ACF7-8C29BAC99592@uwyo.edu>
	<alpine.LRH.2.03.1408061455420.17497@reclus.nhh.no>
	<C7CB5627-EE99-438A-9FD1-DB7CB5DD81D0@uwyo.edu>
Message-ID: <alpine.LRH.2.03.1408062032250.18827@reclus.nhh.no>

On Wed, 6 Aug 2014, Daniel Rodolphe Schlaepfer wrote:

> Unfortunately, your suggestion to consider plotting order doesn?t work 
> in general and not in my case; for instance, if I need my underlaying 
> map to show filled polygons:
>
> plot(polySP, density=10, angle=45, pbg="white", axes=TRUE)
> map(add=TRUE, fill=TRUE, col=rainbow(n=5))
>
> -the hatched polygon is overplotted by the map with this plotting order; 
> if I reverse the plotting order, then the underlaying map is 
> overplotted:
>
> map(fill=TRUE, col=rainbow(n=5))
> plot(polySP, density=10, angle=45, pbg="white", add=TRUE)
>
> Thus, I still think this issue is not resolved.

Given the graphics devices at out disposal, one has to operate within the 
posibilities available. By the way, polypath does not support hatching, so 
the plot method in sp is as good as it gets. Had you considered using the 
alpha channel to add colour fills over a hatched background?

> I can understand that fixing maptools/SpatialPolygons2PolySet may have a 
> low priority. However, I already suggested a patch in my original email. 
> Here, again, as the complete function (only one line needs to be 
> changed, see second instance of POS <- ):

Yes, but from there no indication of how PBSmapping::plotMap() gets around 
the same problem.

I've committed your suggestion to R-forge, maptools revision 283. Please 
report whether this is what you wanted.

Roger

>
> SpatialPolygons2PolySet <- function (SpP)
> {
>    require(PBSmapping)
>    pls <- slot(SpP, "polygons")
>    n <- length(pls)
>    PID <- NULL
>    SID <- NULL
>    POS <- NULL
>    X <- NULL
>    Y <- NULL
>    for (i in 1:n) {
>        srs <- slot(pls[[i]], "Polygons")
>        m <- length(srs)
>        for (j in 1:m) {
>            crds <- slot(srs[[j]], "coords")
>            k <- nrow(crds)
>            PID <- c(PID, rep(i, k))
>            SID <- c(SID, rep(j, k))
> #POS <- c(POS, 1:k)
>            POS <- if(slot(srs[[j]], "hole")) c(POS, k:1) else c(POS, 1:k) #Suggested fix
>            X <- c(X, crds[, 1])
>            Y <- c(Y, crds[, 2])
>        }
>    }
>    PID <- as.integer(PID)
>    SID <- as.integer(SID)
>    POS <- as.integer(POS)
>    storage.mode(X) <- "double"
>    storage.mode(Y) <- "double"
>    pj <- .pbsproj(SpP)
>    zn <- NULL
>    if (pj == "UTM") {
>        zn <- attr(pj, "zone")
>        attr(pj, "zone") <- NULL
>    }
>    res <- as.PolySet(data.frame(PID = PID, SID = SID, POS = POS,
>        X = X, Y = Y), projection = pj, zone = zn)
>    res
> }
>
> Thanks,
> Daniel
>
>
> On Aug 6, 2014, at 3:02 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>
>> On Wed, 6 Aug 2014, Daniel Rodolphe Schlaepfer wrote:
>>
>>> Thank you for the suggestion. Unfortunately, this does not work for my application: I plot the polygon on top of other another plot where I need the holes of the polygon to be transparent. For instance, I don?t want the African countries in the following examples to be covered by white:
>>>
>>> library(maps)
>>> map()
>>> plot(polySP, density=10, angle=45, pbg=?white")
>>
>> Obviously not, these are base graphics, and you have to consider the plotting order:
>>
>> plot(polySP, density=10, angle=45, pbg="white", axes=TRUE)
>> map(add=TRUE)
>>
>>>
>>> However, this was not the point that I try to ask about. My point is that maptools/SpatialPolygons2PolySet does not translate into correct PolySet objects as illustrated in my previous example.
>>
>> Since you no longer need PolySet objects, why? Maybe the coercion method can be fixed, but it is not a priority - patch welcomed.
>>
>> Roger
>>
>>>
>>> Thanks,
>>> Daniel
>>>
>>> On Aug 6, 2014, at 12:52 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>>>
>>>> On Wed, 6 Aug 2014, Daniel Rodolphe Schlaepfer wrote:
>>>>
>>>>> Hello all,
>>>>>
>>>>> I try to convert a sp SpatialPolygons object with a hole to a PBS PolySet object - my ultimate goal is to plot the polygon with hatching considering the hole.
>>>>
>>>> The problem is not that you need a PolySet representation, but that you need to set the polygon background explicitly to a value other than "transparent" using the pbg= argument:
>>>>
>>>> plot(polySP, density=10, angle=45, pbg="white")
>>>>
>>>> or adjust par("bg") to suit. When hatching is used, polypath is not used, so automatic handling of holes in the plot method is not available.
>>>>
>>>> Roger
>>>>
>>>>>
>>>>> My problem is that maptools/SpatialPolygons2PolySet only produces PolySet objects with increasing POS even for polygons with holes; however, the documentation of PolySet indicates that ?We adopt the convention that POS goes from 1 to n along an outer boundary, but from n to 1 along an inner boundary, regardless of rotational direction.?
>>>>>
>>>>>
>>>>> #Create simple doughnut-shaped polygon
>>>>> library(sp)
>>>>> library(maptools)
>>>>>
>>>>> coords1 <- matrix(c(108, -54, -108, -54, -108, 54, 108, 54, 108, -54), ncol=2, byrow=TRUE)
>>>>> coords2 <- matrix(c(36, -18, -36, -18, -36, 18, 36, 18, 36, -18), ncol=2, byrow=TRUE)
>>>>>
>>>>> polySP <- SpatialPolygons(list(Polygons(list(Polygon(coords1, hole=FALSE), Polygon(coords2, hole=TRUE)), ID=1)), proj4string=CRS("+proj=longlat +datum=WGS84"))
>>>>>
>>>>> #Convert sp-SpatialPolygons to PBS-PolySet with maptools function
>>>>> polyPBS <- SpatialPolygons2PolySet(polySP)
>>>>>
>>>>> #-> POS for SID == 2 are increasing and thus do not reflect PBS standards for a polygon with a hole
>>>>> PID SID POS    X   Y
>>>>> 1    1   1   1  108 -54
>>>>> 2    1   1   2 -108 -54
>>>>> 3    1   1   3 -108  54
>>>>> 4    1   1   4  108  54
>>>>> 5    1   1   5  108 -54
>>>>> 6    1   2   1   36 -18
>>>>> 7    1   2   2   36  18
>>>>> 8    1   2   3  -36  18
>>>>> 9    1   2   4  -36 -18
>>>>> 10   1   2   5   36 -18
>>>>>
>>>>> I believe that it would require only a small change to maptools/SpatialPolygons2PolySet to produce PolySet objects that meet the PBS standards also for polygons with holes, i.e., replace the line
>>>>> 	POS <- c(POS, 1:k)
>>>>> with
>>>>> 	POS <- if(slot(srs[[j]], "hole")) c(POS, k:1) else c(POS, 1:k)
>>>>> inside the loops: for (i in 1:n) ? for (j in 1:m) ?
>>>>>
>>>>>
>>>>>
>>>>> Sincerely,
>>>>> Daniel Schlaepfer
>>>>>
>>>>>
>>>>> My session infos:
>>>>> sessionInfo()
>>>>> 	R version 3.1.1 (2014-07-10)
>>>>> 	Platform: x86_64-apple-darwin13.3.0 (64-bit)
>>>>>
>>>>> 	locale:
>>>>> 	[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>>>>
>>>>> 	attached base packages:
>>>>> 	[1] stats     graphics  grDevices
>>>>> 	[4] utils     datasets  methods
>>>>> 	[7] base
>>>>>
>>>>> 	other attached packages:
>>>>> 	[1] PBSmapping_2.67.60 maptools_0.8-30
>>>>> 	[3] sp_1.0-15
>>>>>
>>>>> 	loaded via a namespace (and not attached):
>>>>> 	[1] foreign_0.8-61  grid_3.1.1
>>>>> 	[3] lattice_0.20-29
>>>>>
>>>>>
>>>>> -------------------------------------------------------
>>>>> Daniel Schlaepfer, PhD
>>>>> University of Wyoming
>>>>> Laramie, WY 82071
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-Geo mailing list
>>>>> R-sig-Geo at r-project.org
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>
>>>>
>>>> --
>>>> Roger Bivand
>>>> Department of Economics, Norwegian School of Economics,
>>>> Helleveien 30, N-5045 Bergen, Norway.
>>>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>>>> e-mail: Roger.Bivand at nhh.no
>>>
>>>
>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics,
>> Helleveien 30, N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>> e-mail: Roger.Bivand at nhh.no
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no

From jeanyves.barnagaud at gmail.com  Thu Aug  7 09:40:53 2014
From: jeanyves.barnagaud at gmail.com (jybarnagaud)
Date: Thu, 7 Aug 2014 00:40:53 -0700 (PDT)
Subject: [R-sig-Geo] spgwr: Invalid weights for i: 1
Message-ID: <1407397253564-7586890.post@n2.nabble.com>

Dear all; 

I'm trying to run a gwr to show local estimates of a linear temporal trend
in a continuous variable on 806 data points sampled at least 8 times on a
1966-2011 period:

I got the following error while trying to select a bandwith with spgwr:

<http://r-sig-geo.2731867.n2.nabble.com/file/n7586890/Capture.png> 

Below is a short summary of my data object: 

<http://r-sig-geo.2731867.n2.nabble.com/file/n7586890/map.jpeg> 

shape of the response variable:

<http://r-sig-geo.2731867.n2.nabble.com/file/n7586890/histo.jpeg> 

Any idea of why it happens and any obvious solution, or any tips to find
where's the issue ?

A cheap alternative might be to select a manual bandwidth based on our
knowledge of the study system, but I couldn't find exactly how it should be
specified: is it expressed as a radius in km or something other?

Many Thanks!

JY Barnagaud



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/spgwr-Invalid-weights-for-i-1-tp7586890.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From dschlaep at uwyo.edu  Thu Aug  7 09:52:39 2014
From: dschlaep at uwyo.edu (Daniel Rodolphe Schlaepfer)
Date: Thu, 7 Aug 2014 07:52:39 +0000
Subject: [R-sig-Geo] maptools/SpatialPolygons2PolySet produces ascending
 instead of descending POS numbers for polygons with holes
In-Reply-To: <alpine.LRH.2.03.1408062032250.18827@reclus.nhh.no>
References: <0CC04A5E-EE37-4207-859B-9D0403B20F4C@uwyo.edu>
	<alpine.LRH.2.03.1408061247290.17497@reclus.nhh.no>
	<A7EA724F-1ACC-4A21-ACF7-8C29BAC99592@uwyo.edu>
	<alpine.LRH.2.03.1408061455420.17497@reclus.nhh.no>
	<C7CB5627-EE99-438A-9FD1-DB7CB5DD81D0@uwyo.edu>
	<alpine.LRH.2.03.1408062032250.18827@reclus.nhh.no>
Message-ID: <7F9D769C-4E82-435E-8FFF-448E011C8D93@uwyo.edu>

Since polypath does not support hatching, I had to resort to using PBSmapping. However, I don?t know how PBSmapping is getting around the problem of correctly plotting of hatching for polygons with holes, but it does it correctly and that is why I use it, e.g.,

if(packageVersion(?maptools?) >= ?0.8.31"){
	polyPBS <- SpatialPolygons2PolySet(polySP)

	map(fill=TRUE, col=rainbow(n=5))
	addPolys(polyPBS, xlim=c(-180, 180), ylim=c(-90, 90), density=10, angle=45, col="black") 
}

Thank you for including the fix for SpatialPolygons2PolySet to maptools revision 283. My question is solved.

Best
-Daniel

On Aug 6, 2014, at 8:54 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:

> On Wed, 6 Aug 2014, Daniel Rodolphe Schlaepfer wrote:
> 
>> Unfortunately, your suggestion to consider plotting order doesn?t work in general and not in my case; for instance, if I need my underlaying map to show filled polygons:
>> 
>> plot(polySP, density=10, angle=45, pbg="white", axes=TRUE)
>> map(add=TRUE, fill=TRUE, col=rainbow(n=5))
>> 
>> -the hatched polygon is overplotted by the map with this plotting order; if I reverse the plotting order, then the underlaying map is overplotted:
>> 
>> map(fill=TRUE, col=rainbow(n=5))
>> plot(polySP, density=10, angle=45, pbg="white", add=TRUE)
>> 
>> Thus, I still think this issue is not resolved.
> 
> Given the graphics devices at out disposal, one has to operate within the posibilities available. By the way, polypath does not support hatching, so the plot method in sp is as good as it gets. Had you considered using the alpha channel to add colour fills over a hatched background?
> 
>> I can understand that fixing maptools/SpatialPolygons2PolySet may have a low priority. However, I already suggested a patch in my original email. Here, again, as the complete function (only one line needs to be changed, see second instance of POS <- ):
> 
> Yes, but from there no indication of how PBSmapping::plotMap() gets around the same problem.
> 
> I've committed your suggestion to R-forge, maptools revision 283. Please report whether this is what you wanted.
> 
> Roger
> 
>> 
>> SpatialPolygons2PolySet <- function (SpP)
>> {
>>   require(PBSmapping)
>>   pls <- slot(SpP, "polygons")
>>   n <- length(pls)
>>   PID <- NULL
>>   SID <- NULL
>>   POS <- NULL
>>   X <- NULL
>>   Y <- NULL
>>   for (i in 1:n) {
>>       srs <- slot(pls[[i]], "Polygons")
>>       m <- length(srs)
>>       for (j in 1:m) {
>>           crds <- slot(srs[[j]], "coords")
>>           k <- nrow(crds)
>>           PID <- c(PID, rep(i, k))
>>           SID <- c(SID, rep(j, k))
>> #POS <- c(POS, 1:k)
>>           POS <- if(slot(srs[[j]], "hole")) c(POS, k:1) else c(POS, 1:k) #Suggested fix
>>           X <- c(X, crds[, 1])
>>           Y <- c(Y, crds[, 2])
>>       }
>>   }
>>   PID <- as.integer(PID)
>>   SID <- as.integer(SID)
>>   POS <- as.integer(POS)
>>   storage.mode(X) <- "double"
>>   storage.mode(Y) <- "double"
>>   pj <- .pbsproj(SpP)
>>   zn <- NULL
>>   if (pj == "UTM") {
>>       zn <- attr(pj, "zone")
>>       attr(pj, "zone") <- NULL
>>   }
>>   res <- as.PolySet(data.frame(PID = PID, SID = SID, POS = POS,
>>       X = X, Y = Y), projection = pj, zone = zn)
>>   res
>> }
>> 
>> Thanks,
>> Daniel
>> 
>> 
>> On Aug 6, 2014, at 3:02 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>> 
>>> On Wed, 6 Aug 2014, Daniel Rodolphe Schlaepfer wrote:
>>> 
>>>> Thank you for the suggestion. Unfortunately, this does not work for my application: I plot the polygon on top of other another plot where I need the holes of the polygon to be transparent. For instance, I don?t want the African countries in the following examples to be covered by white:
>>>> 
>>>> library(maps)
>>>> map()
>>>> plot(polySP, density=10, angle=45, pbg=?white")
>>> 
>>> Obviously not, these are base graphics, and you have to consider the plotting order:
>>> 
>>> plot(polySP, density=10, angle=45, pbg="white", axes=TRUE)
>>> map(add=TRUE)
>>> 
>>>> 
>>>> However, this was not the point that I try to ask about. My point is that maptools/SpatialPolygons2PolySet does not translate into correct PolySet objects as illustrated in my previous example.
>>> 
>>> Since you no longer need PolySet objects, why? Maybe the coercion method can be fixed, but it is not a priority - patch welcomed.
>>> 
>>> Roger
>>> 
>>>> 
>>>> Thanks,
>>>> Daniel
>>>> 
>>>> On Aug 6, 2014, at 12:52 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>>>> 
>>>>> On Wed, 6 Aug 2014, Daniel Rodolphe Schlaepfer wrote:
>>>>> 
>>>>>> Hello all,
>>>>>> 
>>>>>> I try to convert a sp SpatialPolygons object with a hole to a PBS PolySet object - my ultimate goal is to plot the polygon with hatching considering the hole.
>>>>> 
>>>>> The problem is not that you need a PolySet representation, but that you need to set the polygon background explicitly to a value other than "transparent" using the pbg= argument:
>>>>> 
>>>>> plot(polySP, density=10, angle=45, pbg="white")
>>>>> 
>>>>> or adjust par("bg") to suit. When hatching is used, polypath is not used, so automatic handling of holes in the plot method is not available.
>>>>> 
>>>>> Roger
>>>>> 
>>>>>> 
>>>>>> My problem is that maptools/SpatialPolygons2PolySet only produces PolySet objects with increasing POS even for polygons with holes; however, the documentation of PolySet indicates that ?We adopt the convention that POS goes from 1 to n along an outer boundary, but from n to 1 along an inner boundary, regardless of rotational direction.?
>>>>>> 
>>>>>> 
>>>>>> #Create simple doughnut-shaped polygon
>>>>>> library(sp)
>>>>>> library(maptools)
>>>>>> 
>>>>>> coords1 <- matrix(c(108, -54, -108, -54, -108, 54, 108, 54, 108, -54), ncol=2, byrow=TRUE)
>>>>>> coords2 <- matrix(c(36, -18, -36, -18, -36, 18, 36, 18, 36, -18), ncol=2, byrow=TRUE)
>>>>>> 
>>>>>> polySP <- SpatialPolygons(list(Polygons(list(Polygon(coords1, hole=FALSE), Polygon(coords2, hole=TRUE)), ID=1)), proj4string=CRS("+proj=longlat +datum=WGS84"))
>>>>>> 
>>>>>> #Convert sp-SpatialPolygons to PBS-PolySet with maptools function
>>>>>> polyPBS <- SpatialPolygons2PolySet(polySP)
>>>>>> 
>>>>>> #-> POS for SID == 2 are increasing and thus do not reflect PBS standards for a polygon with a hole
>>>>>> PID SID POS    X   Y
>>>>>> 1    1   1   1  108 -54
>>>>>> 2    1   1   2 -108 -54
>>>>>> 3    1   1   3 -108  54
>>>>>> 4    1   1   4  108  54
>>>>>> 5    1   1   5  108 -54
>>>>>> 6    1   2   1   36 -18
>>>>>> 7    1   2   2   36  18
>>>>>> 8    1   2   3  -36  18
>>>>>> 9    1   2   4  -36 -18
>>>>>> 10   1   2   5   36 -18
>>>>>> 
>>>>>> I believe that it would require only a small change to maptools/SpatialPolygons2PolySet to produce PolySet objects that meet the PBS standards also for polygons with holes, i.e., replace the line
>>>>>> 	POS <- c(POS, 1:k)
>>>>>> with
>>>>>> 	POS <- if(slot(srs[[j]], "hole")) c(POS, k:1) else c(POS, 1:k)
>>>>>> inside the loops: for (i in 1:n) ? for (j in 1:m) ?
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> Sincerely,
>>>>>> Daniel Schlaepfer
>>>>>> 
>>>>>> 
>>>>>> My session infos:
>>>>>> sessionInfo()
>>>>>> 	R version 3.1.1 (2014-07-10)
>>>>>> 	Platform: x86_64-apple-darwin13.3.0 (64-bit)
>>>>>> 
>>>>>> 	locale:
>>>>>> 	[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>>>>> 
>>>>>> 	attached base packages:
>>>>>> 	[1] stats     graphics  grDevices
>>>>>> 	[4] utils     datasets  methods
>>>>>> 	[7] base
>>>>>> 
>>>>>> 	other attached packages:
>>>>>> 	[1] PBSmapping_2.67.60 maptools_0.8-30
>>>>>> 	[3] sp_1.0-15
>>>>>> 
>>>>>> 	loaded via a namespace (and not attached):
>>>>>> 	[1] foreign_0.8-61  grid_3.1.1
>>>>>> 	[3] lattice_0.20-29
>>>>>> 
>>>>>> 
>>>>>> -------------------------------------------------------
>>>>>> Daniel Schlaepfer, PhD
>>>>>> University of Wyoming
>>>>>> Laramie, WY 82071
>>>>>> 
>>>>>> _______________________________________________
>>>>>> R-sig-Geo mailing list
>>>>>> R-sig-Geo at r-project.org
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>> 
>>>>> 
>>>>> --
>>>>> Roger Bivand
>>>>> Department of Economics, Norwegian School of Economics,
>>>>> Helleveien 30, N-5045 Bergen, Norway.
>>>>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>>>>> e-mail: Roger.Bivand at nhh.no
>>>> 
>>>> 
>>> 
>>> --
>>> Roger Bivand
>>> Department of Economics, Norwegian School of Economics,
>>> Helleveien 30, N-5045 Bergen, Norway.
>>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>>> e-mail: Roger.Bivand at nhh.no
>> 
>> 
> 
> -- 
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no


From stevenhuyi at gmail.com  Thu Aug  7 16:59:18 2014
From: stevenhuyi at gmail.com (stevenhuyi)
Date: Thu, 7 Aug 2014 07:59:18 -0700 (PDT)
Subject: [R-sig-Geo] spatio-temporal simultaneous autoregression model
In-Reply-To: <1407350694995-7586888.post@n2.nabble.com>
References: <1407310926028-7586871.post@n2.nabble.com>
	<1407336322247-7586886.post@n2.nabble.com>
	<1407338436417-7586887.post@n2.nabble.com>
	<1407350694995-7586888.post@n2.nabble.com>
Message-ID: <1407423558990-7586892.post@n2.nabble.com>

Thanks, Corey, that's really helpful. By the way, do u get the R codes from
Edzer? :)


Yes, you can choose a zero inflated poisson or negative binomial likelihood. 
Also, I had asked about a similar question a while back and Edzer replied
with this: 

http://r-sig-geo.2731867.n2.nabble.com/Question-about-space-time-analysis-routines-tp7581537p7581549.html



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/spatio-temporal-simultaneous-autoregression-model-tp7586871p7586892.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From stevenhuyi at gmail.com  Thu Aug  7 17:01:04 2014
From: stevenhuyi at gmail.com (stevenhuyi)
Date: Thu, 7 Aug 2014 08:01:04 -0700 (PDT)
Subject: [R-sig-Geo] spatio-temporal simultaneous autoregression model
In-Reply-To: <1407350694995-7586888.post@n2.nabble.com>
References: <1407310926028-7586871.post@n2.nabble.com>
	<1407336322247-7586886.post@n2.nabble.com>
	<1407338436417-7586887.post@n2.nabble.com>
	<1407350694995-7586888.post@n2.nabble.com>
Message-ID: <1407423664880-7586894.post@n2.nabble.com>

Thanks, Corey. That's really helpful. By the way, have u got the R codes from
Edzer? :)

Yi



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/spatio-temporal-simultaneous-autoregression-model-tp7586871p7586894.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From alessandrosamuel at yahoo.com.br  Thu Aug  7 17:44:11 2014
From: alessandrosamuel at yahoo.com.br (Alessandro Samuel Rosa)
Date: Thu, 7 Aug 2014 08:44:11 -0700
Subject: [R-sig-Geo] Nested spatial sampling
Message-ID: <1407426251.22516.YahooMailNeo@web141503.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140807/74a362d7/attachment.pl>

From janka.vanschoenwinkel at uhasselt.be  Thu Aug  7 20:25:28 2014
From: janka.vanschoenwinkel at uhasselt.be (Janka VANSCHOENWINKEL)
Date: Thu, 7 Aug 2014 20:25:28 +0200
Subject: [R-sig-Geo] Spatial partitioning of direct,
 indirect and total impacts (2)
In-Reply-To: <alpine.LRH.2.03.1408061306290.17497@reclus.nhh.no>
References: <CAHymutLwG08SMWdtOmdyY8x8n3bVEbCgkjYz-9YM4P9HvM0aGw@mail.gmail.com>
	<alpine.LRH.2.03.1408061306290.17497@reclus.nhh.no>
Message-ID: <CAHymutJmmvcgzADjzdpnksLfJ0QNH=1qXCq7Hh-4yhcPvx=pxA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140807/37d5004b/attachment.pl>

From dmarvin at carnegiescience.edu  Thu Aug  7 21:02:47 2014
From: dmarvin at carnegiescience.edu (Dave Marvin)
Date: Thu, 7 Aug 2014 12:02:47 -0700
Subject: [R-sig-Geo] Using 'raster' package functions with rasterEngine
Message-ID: <CAC4xYR5uqrSbXtjHFCPLkqBU0D3umxt8WF5YCoFa-s5v8OiuKg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140807/cc9c71e3/attachment.pl>

From abdoulayesar at gmail.com  Fri Aug  8 13:55:00 2014
From: abdoulayesar at gmail.com (Abdoulaye Sarr)
Date: Fri, 8 Aug 2014 11:55:00 +0000
Subject: [R-sig-Geo] space time error message
In-Reply-To: <CAN=6O0JSg1NnAmFN08yHxbk9Q6Eumiu_ZQJePLMWnHAehNf8OQ@mail.gmail.com>
References: <91BE0E35-083C-4206-A032-DDBDF13893E4@gmail.com>
	<53DE0383.1030702@uni-muenster.de>
	<CAN=6O0JSg1NnAmFN08yHxbk9Q6Eumiu_ZQJePLMWnHAehNf8OQ@mail.gmail.com>
Message-ID: <CAN=6O0+5rN_NnPedTJ6F62kyFLsctrBRsEKeWK8=cMihk4Xirw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140808/caff05aa/attachment.pl>

From milan.kili11 at gmail.com  Fri Aug  8 15:07:21 2014
From: milan.kili11 at gmail.com (Milan Kilibarda)
Date: Fri, 8 Aug 2014 15:07:21 +0200
Subject: [R-sig-Geo] space time error message
In-Reply-To: <CAN=6O0+5rN_NnPedTJ6F62kyFLsctrBRsEKeWK8=cMihk4Xirw@mail.gmail.com>
References: <91BE0E35-083C-4206-A032-DDBDF13893E4@gmail.com>
	<53DE0383.1030702@uni-muenster.de>
	<CAN=6O0JSg1NnAmFN08yHxbk9Q6Eumiu_ZQJePLMWnHAehNf8OQ@mail.gmail.com>
	<CAN=6O0+5rN_NnPedTJ6F62kyFLsctrBRsEKeWK8=cMihk4Xirw@mail.gmail.com>
Message-ID: <CAPSaU-88p4JSVEi0bZdqJJJNCG6RuwcQ8rMkSmz08GEczxExdg@mail.gmail.com>

Dear Abdoulaye,

Regarding to your Error message, I guess you should check if the time
format in your observation set was appropriate. In spacetime package
POSIXct is preferable. See  ? as.POSIXct, for easy converting from
string to POSIX* format. If you still have problem, than you should
send at least  str(dprec84) and str(stations1), or even better make
small subset in mail of your data, then people from the list could try
to reproduce the problem; try to find solution; and it can help
someone with a similar problem.
Best,
Milan

> prec <- meteo2STFDF(dprec84,stations1, crs= CRS('+proj=longlat +datum=WGS84'))
Joining by: staid, date

Joining by: staid
Error in  ST(sp, time, endTime) : time is not a time based class

On Fri, Aug 8, 2014 at 1:55 PM, Abdoulaye Sarr <abdoulayesar at gmail.com> wrote:
> I am still hoping to have a quick explanation on what is causing the error
> or a suggestion on another way to do it?
>
> Cheers,
> eus
>
>
> On Sun, Aug 3, 2014 at 2:20 PM, Abdoulaye Sarr <abdoulayesar at gmail.com>
> wrote:
>
>> I think the problem could be related to dates in precip, in fact here I am
>> using dekadal precip( 10 days average therefor for each month you have 01,
>> 11 and 21 as you can see in the date in sample dataframes dprec84.rda and
>> the stations1.rda.
>>
>> After creating these dataframes I am trying to use use meteo to create a
>> STFDF (I guess other packaged could do it?) using the command below:
>>
>> > prec <- meteo2STFDF(dprec84,stations1, crs= CRS('+proj=longlat
>> +datum=WGS84'))
>> Joining by: staid, date
>>
>> Joining by: staid
>> Error in  ST(sp, time, endTime) : time is not a time based class
>>
>> If doable with other package also will be fine for me.
>>
>> asarr
>>
>>
>> On Sun, Aug 3, 2014 at 9:40 AM, Edzer Pebesma <
>> edzer.pebesma at uni-muenster.de> wrote:
>>
>>> Please provide a small, reproducible example.
>>>
>>> Wbr,
>>>
>>> On 07/26/2014 08:29 PM, Abdoulaye SARR wrote:
>>> >
>>> > Hello list,
>>> >
>>> > I am creating a space time full data frame but having this error
>>> message:
>>> >
>>> > Joining by: staid
>>> > Error in ST(sp, time, endTime) : time is not a time based class
>>> >
>>> > the data frame 10 days average precip used looks like this:
>>> >
>>> >      staid       time prec
>>> > 1 38007200 1984-01-01  0.0
>>> > 2 38008400 1984-01-01  0.8
>>> > 3 38014000 1984-01-01  0.0
>>> > 4 38008100 1984-01-01  0.0
>>> > 5 38008700 1984-01-01  0.0
>>> > 6 38009200 1984-01-01  0.0
>>> >
>>> >
>>> > The next date 1984-01-11 etc..
>>> >
>>> > could someone help solve this urgent issue.
>>> >
>>> > Best regards,
>>> >
>>> > eus
>>> >
>>> >
>>> >       [[alternative HTML version deleted]]
>>> >
>>> > _______________________________________________
>>> > R-sig-Geo mailing list
>>> > R-sig-Geo at r-project.org
>>> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>> >
>>>
>>> --
>>> Edzer Pebesma
>>> Institute for Geoinformatics (ifgi), University of M?nster
>>> Heisenbergstra?e 2, 48149 M?nster, Germany. Phone: +49 251
>>> 83 33081 http://ifgi.uni-muenster.de GPG key ID 0xAC227795
>>>
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>
>>
>
>         [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
Dr. Milan Kilibarda
Assistant professor
University of Belgrade,
Faculty of Civil Engineering,
Department of Geodesy and Geoinformatics,
Address: Bulevar kralja Aleksandra 73  11000 Belgrade, Serbia,
Mail:  kili at grf.bg.ac.rs
Web: http://www.grf.bg.ac.rs/fakultet/pro/e?nid=168 ;  http://dailymeteo.org/
Pub: http://scholar.google.com/citations?user=Zl2MZ3AAAAAJ&hl=en
tel:+381 11 3218630


From sarah.goslee at gmail.com  Fri Aug  8 15:07:33 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 8 Aug 2014 09:07:33 -0400
Subject: [R-sig-Geo] space time error message
In-Reply-To: <CAN=6O0+5rN_NnPedTJ6F62kyFLsctrBRsEKeWK8=cMihk4Xirw@mail.gmail.com>
References: <91BE0E35-083C-4206-A032-DDBDF13893E4@gmail.com>
	<53DE0383.1030702@uni-muenster.de>
	<CAN=6O0JSg1NnAmFN08yHxbk9Q6Eumiu_ZQJePLMWnHAehNf8OQ@mail.gmail.com>
	<CAN=6O0+5rN_NnPedTJ6F62kyFLsctrBRsEKeWK8=cMihk4Xirw@mail.gmail.com>
Message-ID: <CAM_vju=ObyaQSgFLOj9TxGy_XV0LqdhW5Rbejz1dQWLo3QZ7og@mail.gmail.com>

On Fri, Aug 8, 2014 at 7:55 AM, Abdoulaye Sarr <abdoulayesar at gmail.com> wrote:
> I am still hoping to have a quick explanation on what is causing the error
> or a suggestion on another way to do it?

Then you need to provide the small reproducible example that has
already been requested.

This may help:
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

Sarah

>
> Cheers,
> eus
>
>
> On Sun, Aug 3, 2014 at 2:20 PM, Abdoulaye Sarr <abdoulayesar at gmail.com>
> wrote:
>
>> I think the problem could be related to dates in precip, in fact here I am
>> using dekadal precip( 10 days average therefor for each month you have 01,
>> 11 and 21 as you can see in the date in sample dataframes dprec84.rda and
>> the stations1.rda.
>>
>> After creating these dataframes I am trying to use use meteo to create a
>> STFDF (I guess other packaged could do it?) using the command below:
>>
>> > prec <- meteo2STFDF(dprec84,stations1, crs= CRS('+proj=longlat
>> +datum=WGS84'))
>> Joining by: staid, date
>>
>> Joining by: staid
>> Error in  ST(sp, time, endTime) : time is not a time based class
>>
>> If doable with other package also will be fine for me.
>>
>> asarr
>>
>>
>> On Sun, Aug 3, 2014 at 9:40 AM, Edzer Pebesma <
>> edzer.pebesma at uni-muenster.de> wrote:
>>
>>> Please provide a small, reproducible example.
>>>
>>> Wbr,
>>>
>>> On 07/26/2014 08:29 PM, Abdoulaye SARR wrote:
>>> >
>>> > Hello list,
>>> >
>>> > I am creating a space time full data frame but having this error
>>> message:
>>> >
>>> > Joining by: staid
>>> > Error in ST(sp, time, endTime) : time is not a time based class
>>> >
>>> > the data frame 10 days average precip used looks like this:
>>> >
>>> >      staid       time prec
>>> > 1 38007200 1984-01-01  0.0
>>> > 2 38008400 1984-01-01  0.8
>>> > 3 38014000 1984-01-01  0.0
>>> > 4 38008100 1984-01-01  0.0
>>> > 5 38008700 1984-01-01  0.0
>>> > 6 38009200 1984-01-01  0.0
>>> >
>>> >
>>> > The next date 1984-01-11 etc..
>>> >
>>> > could someone help solve this urgent issue.
>>> >
>>> > Best regards,
>>> >
>>> > eus
>>> >
-- 
Sarah Goslee
http://www.functionaldiversity.org


From dicko.ahmadou at gmail.com  Fri Aug  8 15:32:34 2014
From: dicko.ahmadou at gmail.com (Ahmadou Dicko)
Date: Fri, 8 Aug 2014 13:32:34 +0000
Subject: [R-sig-Geo] space time error message
In-Reply-To: <CAPSaU-88p4JSVEi0bZdqJJJNCG6RuwcQ8rMkSmz08GEczxExdg@mail.gmail.com>
References: <91BE0E35-083C-4206-A032-DDBDF13893E4@gmail.com>
	<53DE0383.1030702@uni-muenster.de>
	<CAN=6O0JSg1NnAmFN08yHxbk9Q6Eumiu_ZQJePLMWnHAehNf8OQ@mail.gmail.com>
	<CAN=6O0+5rN_NnPedTJ6F62kyFLsctrBRsEKeWK8=cMihk4Xirw@mail.gmail.com>
	<CAPSaU-88p4JSVEi0bZdqJJJNCG6RuwcQ8rMkSmz08GEczxExdg@mail.gmail.com>
Message-ID: <CAP8THHVg-hJj_HXGCD8=PdKFmvNvR6agL+50P4cJiT=gWbj9DA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140808/ded789ac/attachment.pl>

From edzer.pebesma at uni-muenster.de  Fri Aug  8 18:29:50 2014
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Fri, 08 Aug 2014 18:29:50 +0200
Subject: [R-sig-Geo] Error gstat function krigeST
In-Reply-To: <53DF9ADD.5000808@gmail.com>
References: <53DA6498.6010606@gmail.com> <53DDFD8C.7020506@uni-muenster.de>
	<53DF9ADD.5000808@gmail.com>
Message-ID: <53E4FAFE.3050908@uni-muenster.de>



On 08/04/2014 04:38 PM, Francesco Tonini wrote:
> Dear Dr. Pebesma,
> 
> The exponential ST variogram did not solve the error. However, I 
> manually set the lower bound for the nugget parameter to be equal to 1 
> for both space and time. Even though the automatic optim() routine would 
> estimate these to be 0, I decided to add a nugget variance to avoid the 
> matrix singularity issue you mentioned. I am not sure why it would 
> estimate a nugget of 0 (=no measurement error) on my data. Any idea why 
> this could be?
> 
> Once I manually add a nugget variance, I now get this error when running 
> the krigeST():
> 
> Error in cbind(v0, X) : number of rows of matrices must match (see arg 2)
> 
> The parameters of this krigeST function are unchanged, and the only 
> thing that is modified is the variogram model described above.
> 
> Any help is much appreciated.

As usual: a small, reproducible example might help; if data are large,
please send them off-list.


> 
> Thank you,
> Francesco
> 
> 
> 
> 
> On 8/3/2014 5:14 AM, Edzer Pebesma wrote:
>> Dear Francesco, there are several reasons why this could happen. The
>> first one I would look at is whether you have duplicate observations,
>> meaning observations that share exactly the same spatial and temporal
>> coordinate. Let me know if it helped,
>>
>> On 07/31/2014 05:45 PM, Francesco Tonini wrote:
>>> Dear all,
>>>
>>> I am working with an hourly dataset of air temperature, recorded at ~200
>>> stations over a relatively small area. I chose a space-time variogram
>>> (e.g. sum-metric) to fit my data and am now trying to make predictions
>>> over my same stations in order to fill NA (missing value) gaps. When
>>> using the krigeST() function over daily aggregated data everything seems
>>> to go smooth but when I use it at the original hourly resolution I
>>> always get the following error:
>>>
>>> Error in chol.default(A)
>>> the leading minor of order 68 is not positive definite
>>>
>>> I googled it and found that it is related to a matrix not being
>>> completely positive-definite. However, I am not sure why this happens
>>> and was wondering if any of you know a way of fixing this (a workaround
>>> to avoid it).
>>>
>>> Thanks!
>>> Francesco
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Heisenbergstra?e 2, 48149 M?nster, Germany. Phone: +49 251
83 33081 http://ifgi.uni-muenster.de GPG key ID 0xAC227795

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140808/1184207d/attachment.bin>

From edzer.pebesma at uni-muenster.de  Fri Aug  8 18:39:52 2014
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Fri, 08 Aug 2014 18:39:52 +0200
Subject: [R-sig-Geo] space time error message
In-Reply-To: <CAP8THHVg-hJj_HXGCD8=PdKFmvNvR6agL+50P4cJiT=gWbj9DA@mail.gmail.com>
References: <91BE0E35-083C-4206-A032-DDBDF13893E4@gmail.com>	<53DE0383.1030702@uni-muenster.de>	<CAN=6O0JSg1NnAmFN08yHxbk9Q6Eumiu_ZQJePLMWnHAehNf8OQ@mail.gmail.com>	<CAN=6O0+5rN_NnPedTJ6F62kyFLsctrBRsEKeWK8=cMihk4Xirw@mail.gmail.com>	<CAPSaU-88p4JSVEi0bZdqJJJNCG6RuwcQ8rMkSmz08GEczxExdg@mail.gmail.com>
	<CAP8THHVg-hJj_HXGCD8=PdKFmvNvR6agL+50P4cJiT=gWbj9DA@mail.gmail.com>
Message-ID: <53E4FD58.3090009@uni-muenster.de>

Thanks; mentioning which packages provide the commands you mention in
your requests for help is another absolute requirement to get people to
help you.

In particular in this case, as it concerned a non-cran packge: meteo, on
r-forge; http://r-forge.r-project.org/projects/meteo/ .

On 08/08/2014 03:32 PM, Ahmadou Dicko wrote:
> I agree with everyone, you need to provide a reproducible example if you
> want people to help you.
> I don't know where you found the meteo2STFDF function, but you can use the
> spacetime package to build a STFDF
> 
> library(spacetime)
> library(rgdal)
> 
> load("dprec84.rda")
> load("stations1.rda")
> 
> coordinates(stations1) <- c("lon", "lat")
> proj4string(stations1) <- CRS("+init=epsg:4326")
> 
> time <- as.POSIXct(unique(dprec84$date))
> stfdf <- STFDF(stations1, time, data = dprec84[, "prec", drop = FALSE])
> 
> Feel free to read the vignette (vignette("jss816")) to know more about the
> spacetime package.
> 
> Just a quick question, though is this source of precipitation data publicly
> available for researcher (Senegal) ?
> 
> Hope it helps
> 
> 
> 
> 
> On Fri, Aug 8, 2014 at 1:07 PM, Milan Kilibarda <milan.kili11 at gmail.com>
> wrote:
> 
>> Dear Abdoulaye,
>>
>> Regarding to your Error message, I guess you should check if the time
>> format in your observation set was appropriate. In spacetime package
>> POSIXct is preferable. See  ? as.POSIXct, for easy converting from
>> string to POSIX* format. If you still have problem, than you should
>> send at least  str(dprec84) and str(stations1), or even better make
>> small subset in mail of your data, then people from the list could try
>> to reproduce the problem; try to find solution; and it can help
>> someone with a similar problem.
>> Best,
>> Milan
>>
>>> prec <- meteo2STFDF(dprec84,stations1, crs= CRS('+proj=longlat
>> +datum=WGS84'))
>> Joining by: staid, date
>>
>> Joining by: staid
>> Error in  ST(sp, time, endTime) : time is not a time based class
>>
>> On Fri, Aug 8, 2014 at 1:55 PM, Abdoulaye Sarr <abdoulayesar at gmail.com>
>> wrote:
>>> I am still hoping to have a quick explanation on what is causing the
>> error
>>> or a suggestion on another way to do it?
>>>
>>> Cheers,
>>> eus
>>>
>>>
>>> On Sun, Aug 3, 2014 at 2:20 PM, Abdoulaye Sarr <abdoulayesar at gmail.com>
>>> wrote:
>>>
>>>> I think the problem could be related to dates in precip, in fact here I
>> am
>>>> using dekadal precip( 10 days average therefor for each month you have
>> 01,
>>>> 11 and 21 as you can see in the date in sample dataframes dprec84.rda
>> and
>>>> the stations1.rda.
>>>>
>>>> After creating these dataframes I am trying to use use meteo to create a
>>>> STFDF (I guess other packaged could do it?) using the command below:
>>>>
>>>>> prec <- meteo2STFDF(dprec84,stations1, crs= CRS('+proj=longlat
>>>> +datum=WGS84'))
>>>> Joining by: staid, date
>>>>
>>>> Joining by: staid
>>>> Error in  ST(sp, time, endTime) : time is not a time based class
>>>>
>>>> If doable with other package also will be fine for me.
>>>>
>>>> asarr
>>>>
>>>>
>>>> On Sun, Aug 3, 2014 at 9:40 AM, Edzer Pebesma <
>>>> edzer.pebesma at uni-muenster.de> wrote:
>>>>
>>>>> Please provide a small, reproducible example.
>>>>>
>>>>> Wbr,
>>>>>
>>>>> On 07/26/2014 08:29 PM, Abdoulaye SARR wrote:
>>>>>>
>>>>>> Hello list,
>>>>>>
>>>>>> I am creating a space time full data frame but having this error
>>>>> message:
>>>>>>
>>>>>> Joining by: staid
>>>>>> Error in ST(sp, time, endTime) : time is not a time based class
>>>>>>
>>>>>> the data frame 10 days average precip used looks like this:
>>>>>>
>>>>>>      staid       time prec
>>>>>> 1 38007200 1984-01-01  0.0
>>>>>> 2 38008400 1984-01-01  0.8
>>>>>> 3 38014000 1984-01-01  0.0
>>>>>> 4 38008100 1984-01-01  0.0
>>>>>> 5 38008700 1984-01-01  0.0
>>>>>> 6 38009200 1984-01-01  0.0
>>>>>>
>>>>>>
>>>>>> The next date 1984-01-11 etc..
>>>>>>
>>>>>> could someone help solve this urgent issue.
>>>>>>
>>>>>> Best regards,
>>>>>>
>>>>>> eus
>>>>>>
>>>>>>
>>>>>>       [[alternative HTML version deleted]]
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-Geo mailing list
>>>>>> R-sig-Geo at r-project.org
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>>
>>>>>
>>>>> --
>>>>> Edzer Pebesma
>>>>> Institute for Geoinformatics (ifgi), University of M??nster
>>>>> Heisenbergstra??e 2, 48149 M??nster, Germany. Phone: +49 251
>>>>> 83 33081 http://ifgi.uni-muenster.de GPG key ID 0xAC227795
>>>>>
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-Geo mailing list
>>>>> R-sig-Geo at r-project.org
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>
>>>>>
>>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>>
>>
>> --
>> Dr. Milan Kilibarda
>> Assistant professor
>> University of Belgrade,
>> Faculty of Civil Engineering,
>> Department of Geodesy and Geoinformatics,
>> Address: Bulevar kralja Aleksandra 73  11000 Belgrade, Serbia,
>> Mail:  kili at grf.bg.ac.rs
>> Web: http://www.grf.bg.ac.rs/fakultet/pro/e?nid=168 ;
>> http://dailymeteo.org/
>> Pub: http://scholar.google.com/citations?user=Zl2MZ3AAAAAJ&hl=en
>> tel:+381 11 3218630
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
> 
> 
> 
> 
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Heisenbergstra?e 2, 48149 M?nster, Germany. Phone: +49 251
83 33081 http://ifgi.uni-muenster.de GPG key ID 0xAC227795

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140808/ee740d05/attachment.bin>

From abdoulayesar at gmail.com  Fri Aug  8 19:32:41 2014
From: abdoulayesar at gmail.com (Abdoulaye Sarr)
Date: Fri, 8 Aug 2014 17:32:41 +0000
Subject: [R-sig-Geo] space time error message
In-Reply-To: <53E4FD58.3090009@uni-muenster.de>
References: <91BE0E35-083C-4206-A032-DDBDF13893E4@gmail.com>
	<53DE0383.1030702@uni-muenster.de>
	<CAN=6O0JSg1NnAmFN08yHxbk9Q6Eumiu_ZQJePLMWnHAehNf8OQ@mail.gmail.com>
	<CAN=6O0+5rN_NnPedTJ6F62kyFLsctrBRsEKeWK8=cMihk4Xirw@mail.gmail.com>
	<CAPSaU-88p4JSVEi0bZdqJJJNCG6RuwcQ8rMkSmz08GEczxExdg@mail.gmail.com>
	<CAP8THHVg-hJj_HXGCD8=PdKFmvNvR6agL+50P4cJiT=gWbj9DA@mail.gmail.com>
	<53E4FD58.3090009@uni-muenster.de>
Message-ID: <CAN=6O0+odnfAomg1vVWxuyQiW_Sd0g-DgnZNbrs4hq02P3R8eA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140808/da0337b0/attachment.pl>

From cswingle at swingleydev.com  Sat Aug  9 20:22:01 2014
From: cswingle at swingleydev.com (Christopher Swingley)
Date: Sat, 9 Aug 2014 10:22:01 -0800
Subject: [R-sig-Geo] Properly closing GDAL datasets
Message-ID: <CAHsw448BT=aO9uymEn7vO_BaCm9Fts9_pAPVqtcS_HKAdTf92A@mail.gmail.com>

Greetings!

I'm trying to figure out the proper way to close GDAL datasets in a
long-running script.  I think the issue is in this block of code
(versions of which run hundreds of times during the run of the
script):

raster <- readGDAL(tiffs[1], band=1)
raster$band1 <- best_threshold
writeGDAL(raster, fname = output_filename_rpart_best_threshold, driver
= 'GTiff',
                type = 'Int16', mvFlag = 32767,
                options = c('COMPRESS=LZW','INTERLEAVE=BAND'))

I'm reading in band 1 of a raster, populating it with new data, then
dumping it back out elsewhere.  But when this operation finishes,
there's a filehandle open to what looks like a temporary raster in the
/tmp/Rtmp..../ directory, even though the temporary directory is
empty.

I've tried 'rm(raster)' (which doesn't seem to do anything) and
'GDAL.close(raster)', which gives an error that there's no "handle"
slot in a SpatialGridDataFrame.

How does one properly clean up after a readGDAL / writeGDAL operation?
 Or do I need to perform this step differently?

Thanks!

Chris
-- 
Christopher Swingley
Fairbanks, Alaska
http://swingleydev.com/
cswingle at swingleydev.com


From Roger.Bivand at nhh.no  Sat Aug  9 21:25:38 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 9 Aug 2014 21:25:38 +0200
Subject: [R-sig-Geo] Properly closing GDAL datasets
In-Reply-To: <CAHsw448BT=aO9uymEn7vO_BaCm9Fts9_pAPVqtcS_HKAdTf92A@mail.gmail.com>
References: <CAHsw448BT=aO9uymEn7vO_BaCm9Fts9_pAPVqtcS_HKAdTf92A@mail.gmail.com>
Message-ID: <alpine.LRH.2.03.1408092122520.622@reclus.nhh.no>

You need to provide full information from sessionInfo() such as platform 
and rgdal version, the messages displayed when rgdal is loaded, and how 
you installed GDAL. The answer will depend on these, not least because 
recent rgdal versions clean up better than earlier versions.

Roger

On Sat, 9 Aug 2014, Christopher Swingley wrote:

> Greetings!
>
> I'm trying to figure out the proper way to close GDAL datasets in a
> long-running script.  I think the issue is in this block of code
> (versions of which run hundreds of times during the run of the
> script):
>
> raster <- readGDAL(tiffs[1], band=1)
> raster$band1 <- best_threshold
> writeGDAL(raster, fname = output_filename_rpart_best_threshold, driver
> = 'GTiff',
>                type = 'Int16', mvFlag = 32767,
>                options = c('COMPRESS=LZW','INTERLEAVE=BAND'))
>
> I'm reading in band 1 of a raster, populating it with new data, then
> dumping it back out elsewhere.  But when this operation finishes,
> there's a filehandle open to what looks like a temporary raster in the
> /tmp/Rtmp..../ directory, even though the temporary directory is
> empty.
>
> I've tried 'rm(raster)' (which doesn't seem to do anything) and
> 'GDAL.close(raster)', which gives an error that there's no "handle"
> slot in a SpatialGridDataFrame.
>
> How does one properly clean up after a readGDAL / writeGDAL operation?
> Or do I need to perform this step differently?
>
> Thanks!
>
> Chris
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From cswingle at swingleydev.com  Sat Aug  9 22:50:50 2014
From: cswingle at swingleydev.com (Christopher Swingley)
Date: Sat, 9 Aug 2014 12:50:50 -0800
Subject: [R-sig-Geo] Properly closing GDAL datasets
In-Reply-To: <alpine.LRH.2.03.1408092122520.622@reclus.nhh.no>
References: <CAHsw448BT=aO9uymEn7vO_BaCm9Fts9_pAPVqtcS_HKAdTf92A@mail.gmail.com>
	<alpine.LRH.2.03.1408092122520.622@reclus.nhh.no>
Message-ID: <CAHsw44-UaTNErLLTKHb0=JFzQBDUY4ypoCfkn9PqB9TQym9XRA@mail.gmail.com>

Roger,

On Sat, Aug 9, 2014 at 11:25 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> You need to provide full information from sessionInfo() such as platform and
> rgdal version, the messages displayed when rgdal is loaded, and how you
> installed GDAL. The answer will depend on these, not least because recent
> rgdal versions clean up better than earlier versions.

Sorry about that.  I figured it was something more general I was doing
incorrectly.  Based on your suggestion, I upgraded rgdal to the latest
version (0.8-16), and I'm not seeing extra file descriptors, which
makes me think that this has solved the problem.

Does that mean my method of reading, overwriting and writing is an
acceptable method for what I'm trying to do, which is write a new
raster with all the same parameters but new data?

For reference, here's my old environment, where I had the problem.

> sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

> library(rgdal)
Loading required package: sp
rgdal: version: 0.8-11, (SVN revision 479M)
Geospatial Data Abstraction Library extensions to R successfully loaded
Loaded GDAL runtime: GDAL 1.7.3, released 2010/11/10
Path to GDAL shared files: /usr/share/gdal/1.7
GDAL does not use iconv for recoding strings.
Loaded PROJ.4 runtime: Rel. 4.8.0, 6 March 2012, [PJ_VERSION: 470]
Path to PROJ.4 shared files: (autodetected)

The server has GDAL 1.11.0 and 1.9.1 installed in /usr/local, in
addition to 1.7.3, which is the system-level Ubuntu package that is
installed, and which appears to be what rgdal linked against.  I might
see some benefit to linking against a newer version, I expect.

Thanks,

Chris
-- 
Christopher Swingley
Fairbanks, Alaska
http://swingleydev.com/
cswingle at swingleydev.com


From Roger.Bivand at nhh.no  Sun Aug 10 19:18:19 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 10 Aug 2014 19:18:19 +0200
Subject: [R-sig-Geo] Properly closing GDAL datasets
In-Reply-To: <CAHsw44-UaTNErLLTKHb0=JFzQBDUY4ypoCfkn9PqB9TQym9XRA@mail.gmail.com>
References: <CAHsw448BT=aO9uymEn7vO_BaCm9Fts9_pAPVqtcS_HKAdTf92A@mail.gmail.com>
	<alpine.LRH.2.03.1408092122520.622@reclus.nhh.no>
	<CAHsw44-UaTNErLLTKHb0=JFzQBDUY4ypoCfkn9PqB9TQym9XRA@mail.gmail.com>
Message-ID: <alpine.LRH.2.03.1408101911590.17132@reclus.nhh.no>

On Sat, 9 Aug 2014, Christopher Swingley wrote:

> Roger,
>
> On Sat, Aug 9, 2014 at 11:25 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>> You need to provide full information from sessionInfo() such as platform and
>> rgdal version, the messages displayed when rgdal is loaded, and how you
>> installed GDAL. The answer will depend on these, not least because recent
>> rgdal versions clean up better than earlier versions.
>
> Sorry about that.  I figured it was something more general I was doing
> incorrectly.  Based on your suggestion, I upgraded rgdal to the latest
> version (0.8-16), and I'm not seeing extra file descriptors, which
> makes me think that this has solved the problem.
>
> Does that mean my method of reading, overwriting and writing is an
> acceptable method for what I'm trying to do, which is write a new
> raster with all the same parameters but new data?

Well, if it works, that suggests that it is OK, but whether it is the most 
efficient way of doing it is a different question.

>
> For reference, here's my old environment, where I had the problem.
>
>> sessionInfo()
> R version 3.0.2 (2013-09-25)
> Platform: x86_64-pc-linux-gnu (64-bit)
>
> locale:
> [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
> [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
> [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
> [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
>> library(rgdal)
> Loading required package: sp
> rgdal: version: 0.8-11, (SVN revision 479M)
> Geospatial Data Abstraction Library extensions to R successfully loaded
> Loaded GDAL runtime: GDAL 1.7.3, released 2010/11/10
> Path to GDAL shared files: /usr/share/gdal/1.7
> GDAL does not use iconv for recoding strings.
> Loaded PROJ.4 runtime: Rel. 4.8.0, 6 March 2012, [PJ_VERSION: 470]
> Path to PROJ.4 shared files: (autodetected)
>
> The server has GDAL 1.11.0 and 1.9.1 installed in /usr/local, in
> addition to 1.7.3, which is the system-level Ubuntu package that is
> installed, and which appears to be what rgdal linked against.  I might
> see some benefit to linking against a newer version, I expect.
>

It is typical of Debian/Ubuntu that multiple GDAL are installed because 
some other binary packages depend on aged versions. You would do best to 
remove all older than the most recent, to be sure that bug fixes are 
applied, that drivers are up to date, and that metadata are the most 
recent (for example the EPSG files used by GTiff). However, this may mean 
that you have to re-install other software from source, which takes time. 
Do look at the ordering of the GDAL versions on the LD library path, and 
if possible adjust this so that 1.11.0 is both the one found when 
installing rgdal and the one loaded when rgdal loads.

Roger

> Thanks,
>
> Chris
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From markpayneatwork at gmail.com  Mon Aug 11 16:26:31 2014
From: markpayneatwork at gmail.com (Mark Payne)
Date: Mon, 11 Aug 2014 16:26:31 +0200
Subject: [R-sig-Geo] writeRaster does not preserve names when writing to
	NetCDF
Message-ID: <CAGBzUO8nkr3xUYyaG_xaFa5n3uoLMRT3W5Qnm2bPUgLA4DAY9A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140811/24486219/attachment.pl>

From jgrn at illinois.edu  Mon Aug 11 17:55:19 2014
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Mon, 11 Aug 2014 08:55:19 -0700
Subject: [R-sig-Geo] Using 'raster' package functions with rasterEngine
In-Reply-To: <CAC4xYR5uqrSbXtjHFCPLkqBU0D3umxt8WF5YCoFa-s5v8OiuKg@mail.gmail.com>
References: <CAC4xYR5uqrSbXtjHFCPLkqBU0D3umxt8WF5YCoFa-s5v8OiuKg@mail.gmail.com>
Message-ID: <CABG0rfuTFwkKVPq4V47apbV46doY4uZ4OLmaXttqvcQ0JxgH_A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140811/7a3bf6c8/attachment.pl>

From rgenevest at free.fr  Mon Aug 11 19:00:04 2014
From: rgenevest at free.fr (Remi Genevest)
Date: Mon, 11 Aug 2014 10:00:04 -0700 (PDT)
Subject: [R-sig-Geo] using lapply() with Spatial Objects
Message-ID: <1407776404274-7586911.post@n2.nabble.com>

I have a list of coordinates that each corresponds to the center of polygon.
My purpose is to create the polygons using lapply() and plot them on the
same device.

And actually I have 2 questions : 
  - How can I create some polygons using lapply() with a
SpatialPointsDataFrame ?
  - How can I plot this list of polygons on the same device ? (still using
lapply())

Here a little example of I want to do (based on a simple dataframe) : 

## Setting a dataframe with coordinates of the centers of the polygons I
want to plot : 
df<-data.frame(Lat=c(3,4),Lon=2,value=0.1)

## Using lists for creating polygons : 
cc<-list()
disc<-list()
for (i in 1:nrow(df)) 
{
  cc[[i]]<-cbind(df[i,1],df[i,2])  
  disc[[i]]<-disc(radius=0.1,centre=cc[[i]])
}

## plot the polygons
lapply(disc,FUN=plot)

This works, but do not plot the polygones on the same device.
So I thought about doing this, without success :

lapply(disc,function(x) {plot(x,add=TRUE)})

Error in (function (x, y = NULL, density = NULL, angle = 45, border = NULL, 
: 
plot.new has not been called yet  

So, what would you do to simplify this code and make it possible to use the
'add' parameters of the plot() function in a lapply() ?

As I am not used to handle apply() functions, I do appreciate your help...
Just to let you know, my original idea was to do something like this,
considering 'spdf' as a SpatialPointsDataframe :

lapply(spdf, function(x) {disc(radius=0.1,centre=coordinates(x))})
Error in as.list.default(X) : 
  no method for coercing this S4 class to a vector

Thanks for help



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/using-lapply-with-Spatial-Objects-tp7586911.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From mdsumner at gmail.com  Tue Aug 12 01:05:42 2014
From: mdsumner at gmail.com (Michael Sumner)
Date: Tue, 12 Aug 2014 09:05:42 +1000
Subject: [R-sig-Geo] writeRaster does not preserve names when writing to
	NetCDF
In-Reply-To: <CAGBzUO8nkr3xUYyaG_xaFa5n3uoLMRT3W5Qnm2bPUgLA4DAY9A@mail.gmail.com>
References: <CAGBzUO8nkr3xUYyaG_xaFa5n3uoLMRT3W5Qnm2bPUgLA4DAY9A@mail.gmail.com>
Message-ID: <CAAcGz9-rYXab4Ry07d94Q2=PVDs69OdLm+AYAXSs78kyrq-gLQ@mail.gmail.com>

Hi,

I don't think that NetCDF has the capacity to store these names in a
natural way. Internally your brick is stored as a NetCDF variable, in
this case a 3d array. To do this it would need to define a 'dimension"
and include a lookup map to the names. A NetCDF dimension variable
must be populated with numbers I believe, so you would need another
variable to store those and then add in features to raster to use
them.

There's at least two blockers here:
- the NetCDF model is not designed for storing tabular data (a RGB
image is a table of records in one sense, not a 3d array of integers)
- gridded data storage usually conflates "dimension" with
"attributes", which is unfortunate.

If you have a time series of RGB images, the three attributes Red,
Green and Blue do not belong in the 3rd dimension. In practice we see
separate files for a time series of multi-attribute "images". If you
explore the sp gridded and raster gridded data structures they are
stored as a 2D array with the first two dimensions of the grid
"flattened" down the columns. This raster brick image uses the 2nd
dimension of the storage for multiple attributes, but in another case
(time series SST) it uses this dimension for the 3rd dimension of the
grid.

That leaves no wriggle room for consistent extension to higher
dimensions, or even 3D-multiple-attribute data. It's not just for
colour images, the same problem exists for vector/velocity data
(storing horizontal and vertical components of velocity) and NetCDF
shares the limiation.  Strictly I would say you store the Red, Green
and Blue data as separate variables in NetCDF as it would for time
series current velocity but still you need extra work applied to get
the "obvious" interpretation.

I think the only easy solution is to use raster's own native format.
I've seen discussions on this for R and for GDAL, which I'll include
if I can find them again. GDAL would store these names in its
auxiliary files, since many formats just don't have the ability to do
it. It's the same for mixing data types - sp's classes can do this as
it is a data.frame, but raster cannot (it's a matrix), and some GDAL
formats can but it's pretty obscure and generally frowned upon I
think.

Cheers, Mike.





On Tue, Aug 12, 2014 at 12:26 AM, Mark Payne <markpayneatwork at gmail.com> wrote:
> Hi,
>
> I have a problem with writeRaster when writing a brick to NetCDF - the
> names of the layers are not preserved. Here is a minimum example to
> demonstrate the point:
>
> #Create an arbitrary brick and write it out
> b <- brick(system.file("external/rlogo.grd", package="raster"))
> fname <- file.path( tempdir(),"test.nc")
> dmp <- writeRaster(b,file=fname)
>
> #Now read it back in
> a <- brick(fname)
>
> #However, names are not preserved
>> names(b)
> [1] "red"   "green" "blue"
>> names(a)
> [1] "X1" "X2" "X3"
>>
>
> I realise this is a touch tricky, as NetCDF isn't exactly made for storing
> character strings, which is how raster stores the layer names. However,
> there are many cases where the string is just a representation of a number
> anyway.... e.g. when working with time or depth levels as the layers in the
> brick. One solution could therefore be to allow the writeRaster function to
> take an argument "zvals", in the same way that it takes "zname" and "zunit"
> when working with netcdf files - this argument would let you specify the
> numeric values of the z-axis. Everything else would then work ok I think,
> as brick() picks up the values of the z-axis, converts them to strings and
> assigns them to layer names.
>
> Cheers,
>
> Mark
>
> raster version: 2.2-31
> R version 3.0.3
> ncdf4 version: 1.10
> Platform: Linux Mint 16, 64 bit
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



-- 
Michael Sumner
Software and Database Engineer
Australian Antarctic Division
Hobart, Australia
e-mail: mdsumner at gmail.com


From philip.greenwood at unimelb.edu.au  Tue Aug 12 08:13:10 2014
From: philip.greenwood at unimelb.edu.au (Philip Greenwood)
Date: Tue, 12 Aug 2014 06:13:10 +0000
Subject: [R-sig-Geo] WriteOGR to GeoJSON loses CRS
Message-ID: <3CAE56C9-22FB-48D2-A61F-10B83FE01BB4@unimelb.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140812/28089342/attachment.pl>

From frtog at vestas.com  Tue Aug 12 08:19:12 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Tue, 12 Aug 2014 08:19:12 +0200
Subject: [R-sig-Geo] WriteOGR to GeoJSON loses CRS
In-Reply-To: <3CAE56C9-22FB-48D2-A61F-10B83FE01BB4@unimelb.edu.au>
References: <3CAE56C9-22FB-48D2-A61F-10B83FE01BB4@unimelb.edu.au>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C7619800@DKRDSEXC016.vestas.net>

Hi

Google points me to http://geojson.org/geojson-spec.html. See Section 3 about CRSs.

Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 


> -----Original Message-----
> From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-
> project.org] On Behalf Of Philip Greenwood
> Sent: 12. august 2014 08:13
> To: r-sig-geo at r-project.org
> Subject: [R-sig-Geo] WriteOGR to GeoJSON loses CRS
> 
> Hi I am using WriteOGR to write a SpatialPolygonsDataFrame to a temporary
> GeoJSON file. However the CRS seems to be lost in the resulting file.
> Does the GeoJSON driver support CRSs?
> 
> Thanks
> Phil
> 
> ---
> Philip Greenwood
> Product Manager
> Australian Urban Research Infrastructure Network (AURIN)
> Level 2 West, Alice Hoy Building, University of Melbourne
> T: +61-(0)3-9035-8549
> E:
> philip.greenwood at unimelb.edu.au<mailto:philip.greenwood at unimelb.edu
> .au>
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From philip.greenwood at unimelb.edu.au  Tue Aug 12 08:23:55 2014
From: philip.greenwood at unimelb.edu.au (Philip Greenwood)
Date: Tue, 12 Aug 2014 06:23:55 +0000
Subject: [R-sig-Geo] WriteOGR to GeoJSON loses CRS
In-Reply-To: <B078CDF40DFE4045AF172A8B4F68FC4857C7619800@DKRDSEXC016.vestas.net>
References: <3CAE56C9-22FB-48D2-A61F-10B83FE01BB4@unimelb.edu.au>
	<B078CDF40DFE4045AF172A8B4F68FC4857C7619800@DKRDSEXC016.vestas.net>
Message-ID: <61981292-BBE1-42E4-85D4-5963C1E5399E@unimelb.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140812/f5adef21/attachment.pl>

From frtog at vestas.com  Tue Aug 12 08:35:18 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Tue, 12 Aug 2014 08:35:18 +0200
Subject: [R-sig-Geo] WriteOGR to GeoJSON loses CRS
In-Reply-To: <B078CDF40DFE4045AF172A8B4F68FC4857C7619828@DKRDSEXC016.vestas.net>
References: <3CAE56C9-22FB-48D2-A61F-10B83FE01BB4@unimelb.edu.au>
	<B078CDF40DFE4045AF172A8B4F68FC4857C7619800@DKRDSEXC016.vestas.net>
	<B078CDF40DFE4045AF172A8B4F68FC4857C7619828@DKRDSEXC016.vestas.net>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C7619833@DKRDSEXC016.vestas.net>

Dooh, it must be Monday morning and not Tuesday. A copy and paste error: http://www.gdal.org/drv_geojson.html points to http://wiki.geojson.org/GeoJSON_draft_version_5. 

Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 


> -----Original Message-----
> From: Frede Aakmann T?gersen
> Sent: 12. august 2014 08:32
> To: Frede Aakmann T?gersen; Philip Greenwood; r-sig-geo at r-project.org
> Subject: RE: WriteOGR to GeoJSON loses CRS
> 
> Sorry. I was too hasty. I suppose that your problem is with the GDAL drivers. I
> see that http://www.gdal.org/drv_geojson.html points to
> http://www.gdal.org/drv_geojson.html.
> 
> Which package belong writeOGR to. What is the version of the package?
> What is the version of your GDAL installation. What does e.g. 'gdalinfo --
> formats' show?
> 
> Yours sincerely / Med venlig hilsen
> 
> 
> Frede Aakmann T?gersen
> Specialist, M.Sc., Ph.D.
> Plant Performance & Modeling
> 
> Technology & Service Solutions
> T +45 9730 5135
> M +45 2547 6050
> frtog at vestas.com
> http://www.vestas.com
> 
> Company reg. name: Vestas Wind Systems A/S
> This e-mail is subject to our e-mail disclaimer statement.
> Please refer to www.vestas.com/legal/notice
> If you have received this e-mail in error please contact the sender.
> 
> 
> > -----Original Message-----
> > From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-
> > project.org] On Behalf Of Frede Aakmann T?gersen
> > Sent: 12. august 2014 08:19
> > To: Philip Greenwood; r-sig-geo at r-project.org
> > Subject: Re: [R-sig-Geo] WriteOGR to GeoJSON loses CRS
> >
> > Hi
> >
> > Google points me to http://geojson.org/geojson-spec.html. See Section 3
> > about CRSs.
> >
> > Yours sincerely / Med venlig hilsen
> >
> >
> > Frede Aakmann T?gersen
> > Specialist, M.Sc., Ph.D.
> > Plant Performance & Modeling
> >
> > Technology & Service Solutions
> > T +45 9730 5135
> > M +45 2547 6050
> > frtog at vestas.com
> > http://www.vestas.com
> >
> > Company reg. name: Vestas Wind Systems A/S
> > This e-mail is subject to our e-mail disclaimer statement.
> > Please refer to www.vestas.com/legal/notice
> > If you have received this e-mail in error please contact the sender.
> >
> >
> > > -----Original Message-----
> > > From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-
> > > project.org] On Behalf Of Philip Greenwood
> > > Sent: 12. august 2014 08:13
> > > To: r-sig-geo at r-project.org
> > > Subject: [R-sig-Geo] WriteOGR to GeoJSON loses CRS
> > >
> > > Hi I am using WriteOGR to write a SpatialPolygonsDataFrame to a
> > temporary
> > > GeoJSON file. However the CRS seems to be lost in the resulting file.
> > > Does the GeoJSON driver support CRSs?
> > >
> > > Thanks
> > > Phil
> > >
> > > ---
> > > Philip Greenwood
> > > Product Manager
> > > Australian Urban Research Infrastructure Network (AURIN)
> > > Level 2 West, Alice Hoy Building, University of Melbourne
> > > T: +61-(0)3-9035-8549
> > > E:
> > >
> >
> philip.greenwood at unimelb.edu.au<mailto:philip.greenwood at unimelb.edu
> > > .au>
> > >
> > >
> > >
> > > 	[[alternative HTML version deleted]]
> > >
> > > _______________________________________________
> > > R-sig-Geo mailing list
> > > R-sig-Geo at r-project.org
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From frtog at vestas.com  Tue Aug 12 08:32:16 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Tue, 12 Aug 2014 08:32:16 +0200
Subject: [R-sig-Geo] WriteOGR to GeoJSON loses CRS
In-Reply-To: <B078CDF40DFE4045AF172A8B4F68FC4857C7619800@DKRDSEXC016.vestas.net>
References: <3CAE56C9-22FB-48D2-A61F-10B83FE01BB4@unimelb.edu.au>
	<B078CDF40DFE4045AF172A8B4F68FC4857C7619800@DKRDSEXC016.vestas.net>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C7619828@DKRDSEXC016.vestas.net>

Sorry. I was too hasty. I suppose that your problem is with the GDAL drivers. I see that http://www.gdal.org/drv_geojson.html points to http://www.gdal.org/drv_geojson.html.

Which package belong writeOGR to. What is the version of the package? What is the version of your GDAL installation. What does e.g. 'gdalinfo --formats' show?

Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 


> -----Original Message-----
> From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-
> project.org] On Behalf Of Frede Aakmann T?gersen
> Sent: 12. august 2014 08:19
> To: Philip Greenwood; r-sig-geo at r-project.org
> Subject: Re: [R-sig-Geo] WriteOGR to GeoJSON loses CRS
> 
> Hi
> 
> Google points me to http://geojson.org/geojson-spec.html. See Section 3
> about CRSs.
> 
> Yours sincerely / Med venlig hilsen
> 
> 
> Frede Aakmann T?gersen
> Specialist, M.Sc., Ph.D.
> Plant Performance & Modeling
> 
> Technology & Service Solutions
> T +45 9730 5135
> M +45 2547 6050
> frtog at vestas.com
> http://www.vestas.com
> 
> Company reg. name: Vestas Wind Systems A/S
> This e-mail is subject to our e-mail disclaimer statement.
> Please refer to www.vestas.com/legal/notice
> If you have received this e-mail in error please contact the sender.
> 
> 
> > -----Original Message-----
> > From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-
> > project.org] On Behalf Of Philip Greenwood
> > Sent: 12. august 2014 08:13
> > To: r-sig-geo at r-project.org
> > Subject: [R-sig-Geo] WriteOGR to GeoJSON loses CRS
> >
> > Hi I am using WriteOGR to write a SpatialPolygonsDataFrame to a
> temporary
> > GeoJSON file. However the CRS seems to be lost in the resulting file.
> > Does the GeoJSON driver support CRSs?
> >
> > Thanks
> > Phil
> >
> > ---
> > Philip Greenwood
> > Product Manager
> > Australian Urban Research Infrastructure Network (AURIN)
> > Level 2 West, Alice Hoy Building, University of Melbourne
> > T: +61-(0)3-9035-8549
> > E:
> >
> philip.greenwood at unimelb.edu.au<mailto:philip.greenwood at unimelb.edu
> > .au>
> >
> >
> >
> > 	[[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From philip.greenwood at unimelb.edu.au  Tue Aug 12 08:45:14 2014
From: philip.greenwood at unimelb.edu.au (Philip Greenwood)
Date: Tue, 12 Aug 2014 06:45:14 +0000
Subject: [R-sig-Geo] WriteOGR to GeoJSON loses CRS
In-Reply-To: <B078CDF40DFE4045AF172A8B4F68FC4857C7619828@DKRDSEXC016.vestas.net>
References: <3CAE56C9-22FB-48D2-A61F-10B83FE01BB4@unimelb.edu.au>
	<B078CDF40DFE4045AF172A8B4F68FC4857C7619800@DKRDSEXC016.vestas.net>
	<B078CDF40DFE4045AF172A8B4F68FC4857C7619828@DKRDSEXC016.vestas.net>
Message-ID: <D128872B-C86E-468E-959E-3D765DB7FC54@unimelb.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140812/62fbc54d/attachment.pl>

From Roger.Bivand at nhh.no  Tue Aug 12 09:33:58 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 12 Aug 2014 09:33:58 +0200
Subject: [R-sig-Geo] WriteOGR to GeoJSON loses CRS
In-Reply-To: <D128872B-C86E-468E-959E-3D765DB7FC54@unimelb.edu.au>
References: <3CAE56C9-22FB-48D2-A61F-10B83FE01BB4@unimelb.edu.au>
	<B078CDF40DFE4045AF172A8B4F68FC4857C7619800@DKRDSEXC016.vestas.net>
	<B078CDF40DFE4045AF172A8B4F68FC4857C7619828@DKRDSEXC016.vestas.net>
	<D128872B-C86E-468E-959E-3D765DB7FC54@unimelb.edu.au>
Message-ID: <alpine.LRH.2.03.1408120911290.27656@reclus.nhh.no>

On Tue, 12 Aug 2014, Philip Greenwood wrote:

> Thanks very much for you help. My writeOGR belongs to rgdal version 0.8-5.

Which is from February 2013, current is 0.8-16. More importantly, we don't 
know which version of GDAL is loaded when rgdal loads - messages are 
printed on-screen to tell you - nor do we know how you installed rgdal.

With GDAL 1.11.0, released 2014/04/16, I see:

dsn <- system.file("vectors", package = "rgdal")[1]
cities <- readOGR(dsn=dsn, layer="cities")
summary(cities)
#...
#[+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0]
#...
td <- tempdir()
writeOGR(cities, paste(td, ".geojson", sep=.Platform$file.sep),
  "OGRGeoJSON", driver="GeoJSON")
summary(readOGR(paste(td, ".geojson", sep=.Platform$file.sep),
  "OGRGeoJSON"))
#...
#[+proj=longlat +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +no_defs]
#...

with the head of:

file.show(paste(td, ".geojson", sep=.Platform$file.sep))

"crs": { "type": "name", "properties": { "name": 
"urn:ogc:def:crs:OGC:1.3:CRS84" } },

where urn:ogc:def:crs:OGC:1.3:CRS84 is WGS 84 longitude-latitude on p. 18 
of https://portal.opengeospatial.org/files/?artifact_id=24045.

Not quite the same CRS, but a CRS is recorded. I think that your problem 
is related to the version of GDAL loaded into rgdal. The driver page on 
www.gdal.org relates to the current release and may include information 
for the development version. Your version seems to be old.

>
> gdalinfo --formats returns:

ogrinfo --formats, or equivalently ogrDrivers() in R with rgdal loaded.

Hope this clarifies,

Roger

>
> Supported Formats:
>  VRT (rw+v): Virtual Raster
>  GTiff (rw+v): GeoTIFF
>  NITF (rw+v): National Imagery Transmission Format
>  RPFTOC (ro): Raster Product Format TOC format
>  HFA (rw+v): Erdas Imagine Images (.img)
>  SAR_CEOS (ro): CEOS SAR Image
>  CEOS (ro): CEOS Image
>  JAXAPALSAR (ro): JAXA PALSAR Product Reader (Level 1.1/1.5)
>  GFF (rov): Ground-based SAR Applications Testbed File Format (.gff)
>  ELAS (rw+): ELAS
>  AIG (ro): Arc/Info Binary Grid
>  AAIGrid (rwv): Arc/Info ASCII Grid
>  SDTS (ro): SDTS Raster
>  OGDI (ro): OGDI Bridge
>  DTED (rwv): DTED Elevation Raster
>  PNG (rwv): Portable Network Graphics
>  JPEG (rwv): JPEG JFIF
>  MEM (rw+): In Memory Raster
>  JDEM (ro): Japanese DEM (.mem)
>  GIF (rwv): Graphics Interchange Format (.gif)
>  BIGGIF (rov): Graphics Interchange Format (.gif)
>  ESAT (ro): Envisat Image Format
>  BSB (ro): Maptech BSB Nautical Charts
>  XPM (rw): X11 PixMap Format
>  BMP (rw+v): MS Windows Device Independent Bitmap
>  DIMAP (ro): SPOT DIMAP
>  AirSAR (ro): AirSAR Polarimetric Image
>  RS2 (ro): RadarSat 2 XML Product
>  PCIDSK (rw+v): PCIDSK Database File
>  PCRaster (rw): PCRaster Raster File
>  ILWIS (rw+v): ILWIS Raster Map
>  SGI (rw+): SGI Image File Format 1.0
>  SRTMHGT (rwv): SRTMHGT File Format
>  Leveller (rw+): Leveller heightfield
>  Terragen (rw+): Terragen heightfield
>  GMT (rw): GMT NetCDF Grid Format
>  netCDF (rw): Network Common Data Format
>  HDF4 (ro): Hierarchical Data Format Release 4
>  HDF4Image (rw+): HDF4 Dataset
>  ISIS3 (ro): USGS Astrogeology ISIS cube (Version 3)
>  ISIS2 (ro): USGS Astrogeology ISIS cube (Version 2)
>  PDS (ro): NASA Planetary Data System
>  TIL (ro): EarthWatch .TIL
>  ERS (rw+): ERMapper .ers Labelled
>  JPEG2000 (rwv): JPEG-2000 part 1 (ISO/IEC 15444-1)
>  L1B (ro): NOAA Polar Orbiter Level 1b Data Set
>  FIT (rw): FIT Image
>  GRIB (ro): GRIdded Binary (.grb)
>  RMF (rw+): Raster Matrix Format
>  WCS (ro): OGC Web Coverage Service
>  WMS (ro): OGC Web Map Service
>  MSGN (ro): EUMETSAT Archive native (.nat)
>  RST (rw+): Idrisi Raster A.1
>  INGR (rw+): Intergraph Raster
>  GSAG (rw): Golden Software ASCII Grid (.grd)
>  GSBG (rw+): Golden Software Binary Grid (.grd)
>  GS7BG (ro): Golden Software 7 Binary Grid (.grd)
>  COSAR (ro): COSAR Annotated Binary Matrix (TerraSAR-X)
>  TSX (ro): TerraSAR-X Product
>  COASP (ro): DRDC COASP SAR Processor Raster
>  R (rwv): R Object Data Store
>  PNM (rw+): Portable Pixmap Format (netpbm)
>  DOQ1 (ro): USGS DOQ (Old Style)
>  DOQ2 (ro): USGS DOQ (New Style)
>  ENVI (rw+v): ENVI .hdr Labelled
>  EHdr (rw+v): ESRI .hdr Labelled
>  GenBin (ro): Generic Binary (.hdr Labelled)
>  PAux (rw+): PCI .aux Labelled
>  MFF (rw+): Vexcel MFF Raster
>  MFF2 (rw+): Vexcel MFF2 (HKV) Raster
>  FujiBAS (ro): Fuji BAS Scanner Image
>  GSC (ro): GSC Geogrid
>  FAST (ro): EOSAT FAST Format
>  BT (rw+): VTP .bt (Binary Terrain) 1.3 Format
>  LAN (ro): Erdas .LAN/.GIS
>  CPG (ro): Convair PolGASP
>  IDA (rw+): Image Data and Analysis
>  NDF (ro): NLAPS Data Format
>  EIR (ro): Erdas Imagine Raw
>  DIPEx (ro): DIPEx
>  LCP (rov): FARSITE v.4 Landscape File (.lcp)
>  RIK (ro): Swedish Grid RIK (.rik)
>  USGSDEM (rw): USGS Optional ASCII DEM (and CDED)
>  GXF (ro): GeoSoft Grid Exchange Format
>  DODS (ro): DAP 3.x servers
>  HTTP (ro): HTTP Fetching Wrapper
>  BAG (ro): Bathymetry Attributed Grid
>  HDF5 (ro): Hierarchical Data Format Release 5
>  HDF5Image (ro): HDF5 Dataset
>  NWT_GRD (ro): Northwood Numeric Grid Format .grd/.tab
>  NWT_GRC (ro): Northwood Classified Grid Format .grc/.tab
>  ADRG (rw+v): ARC Digitized Raster Graphics
>  SRP (rov): Standard Raster Product (ASRP/USRP)
>  BLX (rw): Magellan topo (.blx)
>  Rasterlite (rw): Rasterlite
>  EPSILON (rwv): Epsilon wavelets
>  WKTRaster (ro): PostGIS WKT Raster driver
>  SAGA (rw+v): SAGA GIS Binary Grid (.sdat)
>
>
>
> On 12/08/2014, at 4:32 PM, Frede Aakmann T?gersen <frtog at vestas.com<mailto:frtog at vestas.com>>
> wrote:
>
> Sorry. I was too hasty. I suppose that your problem is with the GDAL drivers. I see that http://www.gdal.org/drv_geojson.html points to http://www.gdal.org/drv_geojson.html.
>
> Which package belong writeOGR to. What is the version of the package? What is the version of your GDAL installation. What does e.g. 'gdalinfo --formats' show?
>
> Yours sincerely / Med venlig hilsen
>
>
> Frede Aakmann T?gersen
> Specialist, M.Sc., Ph.D.
> Plant Performance & Modeling
>
> Technology & Service Solutions
> T +45 9730 5135
> M +45 2547 6050
> frtog at vestas.com<mailto:frtog at vestas.com>
> http://www.vestas.com
>
> Company reg. name: Vestas Wind Systems A/S
> This e-mail is subject to our e-mail disclaimer statement.
> Please refer to www.vestas.com/legal/notice
> If you have received this e-mail in error please contact the sender.
>
>
> -----Original Message-----
> From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-
> project.org] On Behalf Of Frede Aakmann T?gersen
> Sent: 12. august 2014 08:19
> To: Philip Greenwood; r-sig-geo at r-project.org
> Subject: Re: [R-sig-Geo] WriteOGR to GeoJSON loses CRS
>
> Hi
>
> Google points me to http://geojson.org/geojson-spec.html. See Section 3
> about CRSs.
>
> Yours sincerely / Med venlig hilsen
>
>
> Frede Aakmann T?gersen
> Specialist, M.Sc., Ph.D.
> Plant Performance & Modeling
>
> Technology & Service Solutions
> T +45 9730 5135
> M +45 2547 6050
> frtog at vestas.com
> http://www.vestas.com
>
> Company reg. name: Vestas Wind Systems A/S
> This e-mail is subject to our e-mail disclaimer statement.
> Please refer to www.vestas.com/legal/notice
> If you have received this e-mail in error please contact the sender.
>
>
> -----Original Message-----
> From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-
> project.org] On Behalf Of Philip Greenwood
> Sent: 12. august 2014 08:13
> To: r-sig-geo at r-project.org
> Subject: [R-sig-Geo] WriteOGR to GeoJSON loses CRS
>
> Hi I am using WriteOGR to write a SpatialPolygonsDataFrame to a
> temporary
> GeoJSON file. However the CRS seems to be lost in the resulting file.
> Does the GeoJSON driver support CRSs?
>
> Thanks
> Phil
>
> ---
> Philip Greenwood
> Product Manager
> Australian Urban Research Infrastructure Network (AURIN)
> Level 2 West, Alice Hoy Building, University of Melbourne
> T: +61-(0)3-9035-8549
> E:
>
> philip.greenwood at unimelb.edu.au<mailto:philip.greenwood at unimelb.edu
> .au>
>
>
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> ---
> Philip Greenwood
> Product Manager
> Australian Urban Research Infrastructure Network (AURIN)
> Level 2 West, Alice Hoy Building, University of Melbourne
> T: +61-(0)3-9035-8549
> E: philip.greenwood at unimelb.edu.au<mailto:philip.greenwood at unimelb.edu.au>
>
>
>
> 	[[alternative HTML version deleted]]
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From b.rowlingson at lancaster.ac.uk  Tue Aug 12 09:53:49 2014
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 12 Aug 2014 08:53:49 +0100
Subject: [R-sig-Geo] writeRaster does not preserve names when writing to
	NetCDF
In-Reply-To: <36b84c5138514a07b8a93891132eb9a4@EX-0-HT0.lancs.local>
References: <CAGBzUO8nkr3xUYyaG_xaFa5n3uoLMRT3W5Qnm2bPUgLA4DAY9A@mail.gmail.com>
	<36b84c5138514a07b8a93891132eb9a4@EX-0-HT0.lancs.local>
Message-ID: <CANVKczOsi_FQu=maNYmwvUJWabCnpGd9b8fHRoqdEa2C1rNxBg@mail.gmail.com>

On Tue, Aug 12, 2014 at 12:05 AM, Michael Sumner <mdsumner at gmail.com> wrote:
> Hi,
>
> I don't think that NetCDF has the capacity to store these names in a
> natural way. Internally your brick is stored as a NetCDF variable, in
> this case a 3d array. To do this it would need to define a 'dimension"
> and include a lookup map to the names. A NetCDF dimension variable
> must be populated with numbers I believe, so you would need another
> variable to store those and then add in features to raster to use
> them.
>
> There's at least two blockers here:
> - the NetCDF model is not designed for storing tabular data (a RGB
> image is a table of records in one sense, not a 3d array of integers)
> - gridded data storage usually conflates "dimension" with
> "attributes", which is unfortunate.

 Ummmm....

 NetCDF can store just about anything. Its that flexibility that makes
it hard for one piece of software that writes a raster brick totally
compatible with another piece of software that writes a raster brick.
The NetCDF format itself has no convention for how to store it.

 So people have developed conventions!

http://www.unidata.ucar.edu/software/netcdf/docs/BestPractices.html
http://www.unidata.ucar.edu/software/netcdf/conventions.html
http://cfconventions.org/Data/cf-convetions/cf-conventions-1.7/build/cf-conventions-multi.html

[yes there's a typo in that last one - "convetions" - that's how it is.]

 You can see which convention a NetCDF file claims to be by dumping it
with ncdump on the command line:

 // global attributes:
        :Conventions = "CF-1.4" ;
        :created_by = "R, packages ncdf and raster (version 2.1-49)" ;
        :date = "2014-08-11 17:17:01" ;

[note this also dumps the data, you might want to pipe it to | more]

The exact convention used by raster and rgdal seems to vary depending
on whether ncdf is loaded when raster saves it, or something. At least
in my blurry morning fumblings I seem to have reached contradictory
examples which need clearing up once the coffee IV hits. The varname
argument to writeRaster doesn't seem to do anything, but I'm probably
looking at the wrong file or have an old package:raster or something.

Anyway, the two main ways of storing multi-layer raster appear to be,
and these are files with CF-1.4/5 convention markers, as a 3d cube
with dimension (Nx,Ny,Nz) or as a set of 2d named variables. The names
of these 2d variables should be settable at write time and recoverable
at read-time. However, If the data is a 3d cube then I don't think the
dimensions can have names, although I've not really understood the CF
standards yet (and that page has links to some awful documentation and
missing links...).

It would be quite simple to add another variable, of characters, to
the NetCDF file, but I suspect keeping to a given NetCDF Convention
would be a good idea assuming it can do it.

End-of-ramble...

Barry





>
>
>
> On Tue, Aug 12, 2014 at 12:26 AM, Mark Payne <markpayneatwork at gmail.com> wrote:
>> Hi,
>>
>> I have a problem with writeRaster when writing a brick to NetCDF - the
>> names of the layers are not preserved. Here is a minimum example to
>> demonstrate the point:
>>
>> #Create an arbitrary brick and write it out
>> b <- brick(system.file("external/rlogo.grd", package="raster"))
>> fname <- file.path( tempdir(),"test.nc")
>> dmp <- writeRaster(b,file=fname)
>>
>> #Now read it back in
>> a <- brick(fname)
>>
>> #However, names are not preserved
>>> names(b)
>> [1] "red"   "green" "blue"
>>> names(a)
>> [1] "X1" "X2" "X3"
>>>
>>
>> I realise this is a touch tricky, as NetCDF isn't exactly made for storing
>> character strings, which is how raster stores the layer names. However,
>> there are many cases where the string is just a representation of a number
>> anyway.... e.g. when working with time or depth levels as the layers in the
>> brick. One solution could therefore be to allow the writeRaster function to
>> take an argument "zvals", in the same way that it takes "zname" and "zunit"
>> when working with netcdf files - this argument would let you specify the
>> numeric values of the z-axis. Everything else would then work ok I think,
>> as brick() picks up the values of the z-axis, converts them to strings and
>> assigns them to layer names.
>>
>> Cheers,
>>
>> Mark
>>
>> raster version: 2.2-31
>> R version 3.0.3
>> ncdf4 version: 1.10
>> Platform: Linux Mint 16, 64 bit
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>
> --
> Michael Sumner
> Software and Database Engineer
> Australian Antarctic Division
> Hobart, Australia
> e-mail: mdsumner at gmail.com
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From frtog at vestas.com  Tue Aug 12 10:08:41 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Tue, 12 Aug 2014 10:08:41 +0200
Subject: [R-sig-Geo] WriteOGR to GeoJSON loses CRS
In-Reply-To: <alpine.LRH.2.03.1408120911290.27656@reclus.nhh.no>
References: <3CAE56C9-22FB-48D2-A61F-10B83FE01BB4@unimelb.edu.au>
	<B078CDF40DFE4045AF172A8B4F68FC4857C7619800@DKRDSEXC016.vestas.net>
	<B078CDF40DFE4045AF172A8B4F68FC4857C7619828@DKRDSEXC016.vestas.net>
	<D128872B-C86E-468E-959E-3D765DB7FC54@unimelb.edu.au>
	<alpine.LRH.2.03.1408120911290.27656@reclus.nhh.no>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C761990D@DKRDSEXC016.vestas.net>

Hi

I can get your example (SpatialPointsDataFrame) to work. On my windows box I have:

> library(rgdal)
Loading required package: sp
rgdal: version: 0.8-16, (SVN revision 498)
Geospatial Data Abstraction Library extensions to R successfully loaded
Loaded GDAL runtime: GDAL 1.11.0, released 2014/04/16
Path to GDAL shared files: c:/Programmer/R/R-3.1.0/library/rgdal/gdal
GDAL does not use iconv for recoding strings.
Loaded PROJ.4 runtime: Rel. 4.8.0, 6 March 2012, [PJ_VERSION: 480]
Path to PROJ.4 shared files: c:/Programmer/R/R-3.1.0/library/rgdal/proj

However I cannot get this (using SpatialPolygonsDataFrame) to work:

> library(maptools)
Checking rgeos availability: TRUE

> xx <- readShapePoly(system.file("shapes/sids.shp", package="maptools")[1],
                    IDvar="FIPSNO", proj4string=CRS("+proj=longlat +ellps=clrk66"))

> summary(xx)
Object of class SpatialPolygonsDataFrame
Coordinates:
        min       max
x -84.32385 -75.45698
y  33.88199  36.58965
Is projected: FALSE 
proj4string : [+proj=longlat +ellps=clrk66]
Data attributes:
      AREA          PERIMETER         CNTY_         CNTY_ID            NAME   
 Min.   :0.0420   Min.   :0.999   Min.   :1825   Min.   :1825   Alamance : 1  


> writeOGR(xx, "./.geojson", "xx", "GeoJSON")


No crs information at top of file.

Tried this giving no crs information in xx.geojson:

ogr2ogr -f GeoJSON c:\Users\frtog\xx.geojson c:\\Programmer\\R\\R-3.1.0\\library\\maptools\\shapes\\sids.shp

But this gave crs information:

ogr2ogr -f GeoJSON  -s_srs EPSG:4008 -t_srs EPSG:4008 c:\Users\frtog\xx.geojson c:\\Programmer\\R\\R-3.1.0\\library\\maptools\\shapes\\sids.shp

Had to include both -s_srs and -t_srs to get it to work. EPSG:4008 specifies "+proj=longlat +ellps=clrk66" as the shape file was read with. 

Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 


> -----Original Message-----
> From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-
> project.org] On Behalf Of Roger Bivand
> Sent: 12. august 2014 09:34
> To: Philip Greenwood
> Cc: r-sig-geo at r-project.org
> Subject: Re: [R-sig-Geo] WriteOGR to GeoJSON loses CRS
> 
> On Tue, 12 Aug 2014, Philip Greenwood wrote:
> 
> > Thanks very much for you help. My writeOGR belongs to rgdal version 0.8-
> 5.
> 
> Which is from February 2013, current is 0.8-16. More importantly, we don't
> know which version of GDAL is loaded when rgdal loads - messages are
> printed on-screen to tell you - nor do we know how you installed rgdal.
> 
> With GDAL 1.11.0, released 2014/04/16, I see:
> 
> dsn <- system.file("vectors", package = "rgdal")[1]
> cities <- readOGR(dsn=dsn, layer="cities")
> summary(cities)
> #...
> #[+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0]
> #...
> td <- tempdir()
> writeOGR(cities, paste(td, ".geojson", sep=.Platform$file.sep),
>   "OGRGeoJSON", driver="GeoJSON")
> summary(readOGR(paste(td, ".geojson", sep=.Platform$file.sep),
>   "OGRGeoJSON"))
> #...
> #[+proj=longlat +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +no_defs]
> #...
> 
> with the head of:
> 
> file.show(paste(td, ".geojson", sep=.Platform$file.sep))
> 
> "crs": { "type": "name", "properties": { "name":
> "urn:ogc:def:crs:OGC:1.3:CRS84" } },
> 
> where urn:ogc:def:crs:OGC:1.3:CRS84 is WGS 84 longitude-latitude on p. 18
> of https://portal.opengeospatial.org/files/?artifact_id=24045.
> 
> Not quite the same CRS, but a CRS is recorded. I think that your problem
> is related to the version of GDAL loaded into rgdal. The driver page on
> www.gdal.org relates to the current release and may include information
> for the development version. Your version seems to be old.
> 
> >
> > gdalinfo --formats returns:
> 
> ogrinfo --formats, or equivalently ogrDrivers() in R with rgdal loaded.
> 
> Hope this clarifies,
> 
> Roger
> 
> >
> > Supported Formats:
> >  VRT (rw+v): Virtual Raster
> >  GTiff (rw+v): GeoTIFF
> >  NITF (rw+v): National Imagery Transmission Format
> >  RPFTOC (ro): Raster Product Format TOC format
> >  HFA (rw+v): Erdas Imagine Images (.img)
> >  SAR_CEOS (ro): CEOS SAR Image
> >  CEOS (ro): CEOS Image
> >  JAXAPALSAR (ro): JAXA PALSAR Product Reader (Level 1.1/1.5)
> >  GFF (rov): Ground-based SAR Applications Testbed File Format (.gff)
> >  ELAS (rw+): ELAS
> >  AIG (ro): Arc/Info Binary Grid
> >  AAIGrid (rwv): Arc/Info ASCII Grid
> >  SDTS (ro): SDTS Raster
> >  OGDI (ro): OGDI Bridge
> >  DTED (rwv): DTED Elevation Raster
> >  PNG (rwv): Portable Network Graphics
> >  JPEG (rwv): JPEG JFIF
> >  MEM (rw+): In Memory Raster
> >  JDEM (ro): Japanese DEM (.mem)
> >  GIF (rwv): Graphics Interchange Format (.gif)
> >  BIGGIF (rov): Graphics Interchange Format (.gif)
> >  ESAT (ro): Envisat Image Format
> >  BSB (ro): Maptech BSB Nautical Charts
> >  XPM (rw): X11 PixMap Format
> >  BMP (rw+v): MS Windows Device Independent Bitmap
> >  DIMAP (ro): SPOT DIMAP
> >  AirSAR (ro): AirSAR Polarimetric Image
> >  RS2 (ro): RadarSat 2 XML Product
> >  PCIDSK (rw+v): PCIDSK Database File
> >  PCRaster (rw): PCRaster Raster File
> >  ILWIS (rw+v): ILWIS Raster Map
> >  SGI (rw+): SGI Image File Format 1.0
> >  SRTMHGT (rwv): SRTMHGT File Format
> >  Leveller (rw+): Leveller heightfield
> >  Terragen (rw+): Terragen heightfield
> >  GMT (rw): GMT NetCDF Grid Format
> >  netCDF (rw): Network Common Data Format
> >  HDF4 (ro): Hierarchical Data Format Release 4
> >  HDF4Image (rw+): HDF4 Dataset
> >  ISIS3 (ro): USGS Astrogeology ISIS cube (Version 3)
> >  ISIS2 (ro): USGS Astrogeology ISIS cube (Version 2)
> >  PDS (ro): NASA Planetary Data System
> >  TIL (ro): EarthWatch .TIL
> >  ERS (rw+): ERMapper .ers Labelled
> >  JPEG2000 (rwv): JPEG-2000 part 1 (ISO/IEC 15444-1)
> >  L1B (ro): NOAA Polar Orbiter Level 1b Data Set
> >  FIT (rw): FIT Image
> >  GRIB (ro): GRIdded Binary (.grb)
> >  RMF (rw+): Raster Matrix Format
> >  WCS (ro): OGC Web Coverage Service
> >  WMS (ro): OGC Web Map Service
> >  MSGN (ro): EUMETSAT Archive native (.nat)
> >  RST (rw+): Idrisi Raster A.1
> >  INGR (rw+): Intergraph Raster
> >  GSAG (rw): Golden Software ASCII Grid (.grd)
> >  GSBG (rw+): Golden Software Binary Grid (.grd)
> >  GS7BG (ro): Golden Software 7 Binary Grid (.grd)
> >  COSAR (ro): COSAR Annotated Binary Matrix (TerraSAR-X)
> >  TSX (ro): TerraSAR-X Product
> >  COASP (ro): DRDC COASP SAR Processor Raster
> >  R (rwv): R Object Data Store
> >  PNM (rw+): Portable Pixmap Format (netpbm)
> >  DOQ1 (ro): USGS DOQ (Old Style)
> >  DOQ2 (ro): USGS DOQ (New Style)
> >  ENVI (rw+v): ENVI .hdr Labelled
> >  EHdr (rw+v): ESRI .hdr Labelled
> >  GenBin (ro): Generic Binary (.hdr Labelled)
> >  PAux (rw+): PCI .aux Labelled
> >  MFF (rw+): Vexcel MFF Raster
> >  MFF2 (rw+): Vexcel MFF2 (HKV) Raster
> >  FujiBAS (ro): Fuji BAS Scanner Image
> >  GSC (ro): GSC Geogrid
> >  FAST (ro): EOSAT FAST Format
> >  BT (rw+): VTP .bt (Binary Terrain) 1.3 Format
> >  LAN (ro): Erdas .LAN/.GIS
> >  CPG (ro): Convair PolGASP
> >  IDA (rw+): Image Data and Analysis
> >  NDF (ro): NLAPS Data Format
> >  EIR (ro): Erdas Imagine Raw
> >  DIPEx (ro): DIPEx
> >  LCP (rov): FARSITE v.4 Landscape File (.lcp)
> >  RIK (ro): Swedish Grid RIK (.rik)
> >  USGSDEM (rw): USGS Optional ASCII DEM (and CDED)
> >  GXF (ro): GeoSoft Grid Exchange Format
> >  DODS (ro): DAP 3.x servers
> >  HTTP (ro): HTTP Fetching Wrapper
> >  BAG (ro): Bathymetry Attributed Grid
> >  HDF5 (ro): Hierarchical Data Format Release 5
> >  HDF5Image (ro): HDF5 Dataset
> >  NWT_GRD (ro): Northwood Numeric Grid Format .grd/.tab
> >  NWT_GRC (ro): Northwood Classified Grid Format .grc/.tab
> >  ADRG (rw+v): ARC Digitized Raster Graphics
> >  SRP (rov): Standard Raster Product (ASRP/USRP)
> >  BLX (rw): Magellan topo (.blx)
> >  Rasterlite (rw): Rasterlite
> >  EPSILON (rwv): Epsilon wavelets
> >  WKTRaster (ro): PostGIS WKT Raster driver
> >  SAGA (rw+v): SAGA GIS Binary Grid (.sdat)
> >
> >
> >
> > On 12/08/2014, at 4:32 PM, Frede Aakmann T?gersen
> <frtog at vestas.com<mailto:frtog at vestas.com>>
> > wrote:
> >
> > Sorry. I was too hasty. I suppose that your problem is with the GDAL
> drivers. I see that http://www.gdal.org/drv_geojson.html points to
> http://www.gdal.org/drv_geojson.html.
> >
> > Which package belong writeOGR to. What is the version of the package?
> What is the version of your GDAL installation. What does e.g. 'gdalinfo --
> formats' show?
> >
> > Yours sincerely / Med venlig hilsen
> >
> >
> > Frede Aakmann T?gersen
> > Specialist, M.Sc., Ph.D.
> > Plant Performance & Modeling
> >
> > Technology & Service Solutions
> > T +45 9730 5135
> > M +45 2547 6050
> > frtog at vestas.com<mailto:frtog at vestas.com>
> > http://www.vestas.com
> >
> > Company reg. name: Vestas Wind Systems A/S
> > This e-mail is subject to our e-mail disclaimer statement.
> > Please refer to www.vestas.com/legal/notice
> > If you have received this e-mail in error please contact the sender.
> >
> >
> > -----Original Message-----
> > From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-
> > project.org] On Behalf Of Frede Aakmann T?gersen
> > Sent: 12. august 2014 08:19
> > To: Philip Greenwood; r-sig-geo at r-project.org
> > Subject: Re: [R-sig-Geo] WriteOGR to GeoJSON loses CRS
> >
> > Hi
> >
> > Google points me to http://geojson.org/geojson-spec.html. See Section 3
> > about CRSs.
> >
> > Yours sincerely / Med venlig hilsen
> >
> >
> > Frede Aakmann T?gersen
> > Specialist, M.Sc., Ph.D.
> > Plant Performance & Modeling
> >
> > Technology & Service Solutions
> > T +45 9730 5135
> > M +45 2547 6050
> > frtog at vestas.com
> > http://www.vestas.com
> >
> > Company reg. name: Vestas Wind Systems A/S
> > This e-mail is subject to our e-mail disclaimer statement.
> > Please refer to www.vestas.com/legal/notice
> > If you have received this e-mail in error please contact the sender.
> >
> >
> > -----Original Message-----
> > From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-
> > project.org] On Behalf Of Philip Greenwood
> > Sent: 12. august 2014 08:13
> > To: r-sig-geo at r-project.org
> > Subject: [R-sig-Geo] WriteOGR to GeoJSON loses CRS
> >
> > Hi I am using WriteOGR to write a SpatialPolygonsDataFrame to a
> > temporary
> > GeoJSON file. However the CRS seems to be lost in the resulting file.
> > Does the GeoJSON driver support CRSs?
> >
> > Thanks
> > Phil
> >
> > ---
> > Philip Greenwood
> > Product Manager
> > Australian Urban Research Infrastructure Network (AURIN)
> > Level 2 West, Alice Hoy Building, University of Melbourne
> > T: +61-(0)3-9035-8549
> > E:
> >
> >
> philip.greenwood at unimelb.edu.au<mailto:philip.greenwood at unimelb.edu
> > .au>
> >
> >
> >
> > [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
> > ---
> > Philip Greenwood
> > Product Manager
> > Australian Urban Research Infrastructure Network (AURIN)
> > Level 2 West, Alice Hoy Building, University of Melbourne
> > T: +61-(0)3-9035-8549
> > E:
> philip.greenwood at unimelb.edu.au<mailto:philip.greenwood at unimelb.edu
> .au>
> >
> >
> >
> > 	[[alternative HTML version deleted]]
> >
> >
> 
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From Roger.Bivand at nhh.no  Tue Aug 12 10:44:47 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 12 Aug 2014 10:44:47 +0200
Subject: [R-sig-Geo] WriteOGR to GeoJSON loses CRS
In-Reply-To: <B078CDF40DFE4045AF172A8B4F68FC4857C761990D@DKRDSEXC016.vestas.net>
References: <3CAE56C9-22FB-48D2-A61F-10B83FE01BB4@unimelb.edu.au>
	<B078CDF40DFE4045AF172A8B4F68FC4857C7619800@DKRDSEXC016.vestas.net>
	<B078CDF40DFE4045AF172A8B4F68FC4857C7619828@DKRDSEXC016.vestas.net>
	<D128872B-C86E-468E-959E-3D765DB7FC54@unimelb.edu.au>
	<alpine.LRH.2.03.1408120911290.27656@reclus.nhh.no>
	<B078CDF40DFE4045AF172A8B4F68FC4857C761990D@DKRDSEXC016.vestas.net>
Message-ID: <alpine.LRH.2.03.1408121034590.27656@reclus.nhh.no>

On Tue, 12 Aug 2014, Frede Aakmann T?gersen wrote:

> Hi
>
> I can get your example (SpatialPointsDataFrame) to work. On my windows 
> box I have:
>
>> library(rgdal)
> Loading required package: sp
> rgdal: version: 0.8-16, (SVN revision 498)
> Geospatial Data Abstraction Library extensions to R successfully loaded
> Loaded GDAL runtime: GDAL 1.11.0, released 2014/04/16
> Path to GDAL shared files: c:/Programmer/R/R-3.1.0/library/rgdal/gdal
> GDAL does not use iconv for recoding strings.
> Loaded PROJ.4 runtime: Rel. 4.8.0, 6 March 2012, [PJ_VERSION: 480]
> Path to PROJ.4 shared files: c:/Programmer/R/R-3.1.0/library/rgdal/proj
>
> However I cannot get this (using SpatialPolygonsDataFrame) to work:

The definition is clearly not being recognised by the OGR driver, possibly 
needing a +towgs84= key or +datum= defintion:

proj4string(xx) <- CRS("+proj=longlat +ellps=clrk66 +datum=NAD27")

gives:

"crs": { "type": "name", "properties": { "name": 
"urn:ogc:def:crs:EPSG::4267" } },

which is: +proj=longlat +ellps=clrk66 +datum=NAD27 +no_defs

Without a +towgs84= or +datum=, it appears that the driver is choosing to 
omit an incomplete description.

Roger

>
>> library(maptools)
> Checking rgeos availability: TRUE
>
>> xx <- readShapePoly(system.file("shapes/sids.shp", package="maptools")[1],
>                    IDvar="FIPSNO", proj4string=CRS("+proj=longlat +ellps=clrk66"))
>
>> summary(xx)
> Object of class SpatialPolygonsDataFrame
> Coordinates:
>        min       max
> x -84.32385 -75.45698
> y  33.88199  36.58965
> Is projected: FALSE
> proj4string : [+proj=longlat +ellps=clrk66]
> Data attributes:
>      AREA          PERIMETER         CNTY_         CNTY_ID            NAME
> Min.   :0.0420   Min.   :0.999   Min.   :1825   Min.   :1825   Alamance : 1
>
>
>> writeOGR(xx, "./.geojson", "xx", "GeoJSON")
>
>
> No crs information at top of file.
>
> Tried this giving no crs information in xx.geojson:
>
> ogr2ogr -f GeoJSON c:\Users\frtog\xx.geojson c:\\Programmer\\R\\R-3.1.0\\library\\maptools\\shapes\\sids.shp
>
> But this gave crs information:
>
> ogr2ogr -f GeoJSON  -s_srs EPSG:4008 -t_srs EPSG:4008 c:\Users\frtog\xx.geojson c:\\Programmer\\R\\R-3.1.0\\library\\maptools\\shapes\\sids.shp
>
> Had to include both -s_srs and -t_srs to get it to work. EPSG:4008 specifies "+proj=longlat +ellps=clrk66" as the shape file was read with.
>
> Yours sincerely / Med venlig hilsen
>
>
> Frede Aakmann T?gersen
> Specialist, M.Sc., Ph.D.
> Plant Performance & Modeling
>
> Technology & Service Solutions
> T +45 9730 5135
> M +45 2547 6050
> frtog at vestas.com
> http://www.vestas.com
>
> Company reg. name: Vestas Wind Systems A/S
> This e-mail is subject to our e-mail disclaimer statement.
> Please refer to www.vestas.com/legal/notice
> If you have received this e-mail in error please contact the sender.
>
>
>> -----Original Message-----
>> From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-
>> project.org] On Behalf Of Roger Bivand
>> Sent: 12. august 2014 09:34
>> To: Philip Greenwood
>> Cc: r-sig-geo at r-project.org
>> Subject: Re: [R-sig-Geo] WriteOGR to GeoJSON loses CRS
>>
>> On Tue, 12 Aug 2014, Philip Greenwood wrote:
>>
>>> Thanks very much for you help. My writeOGR belongs to rgdal version 0.8-
>> 5.
>>
>> Which is from February 2013, current is 0.8-16. More importantly, we don't
>> know which version of GDAL is loaded when rgdal loads - messages are
>> printed on-screen to tell you - nor do we know how you installed rgdal.
>>
>> With GDAL 1.11.0, released 2014/04/16, I see:
>>
>> dsn <- system.file("vectors", package = "rgdal")[1]
>> cities <- readOGR(dsn=dsn, layer="cities")
>> summary(cities)
>> #...
>> #[+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0]
>> #...
>> td <- tempdir()
>> writeOGR(cities, paste(td, ".geojson", sep=.Platform$file.sep),
>>   "OGRGeoJSON", driver="GeoJSON")
>> summary(readOGR(paste(td, ".geojson", sep=.Platform$file.sep),
>>   "OGRGeoJSON"))
>> #...
>> #[+proj=longlat +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +no_defs]
>> #...
>>
>> with the head of:
>>
>> file.show(paste(td, ".geojson", sep=.Platform$file.sep))
>>
>> "crs": { "type": "name", "properties": { "name":
>> "urn:ogc:def:crs:OGC:1.3:CRS84" } },
>>
>> where urn:ogc:def:crs:OGC:1.3:CRS84 is WGS 84 longitude-latitude on p. 18
>> of https://portal.opengeospatial.org/files/?artifact_id=24045.
>>
>> Not quite the same CRS, but a CRS is recorded. I think that your problem
>> is related to the version of GDAL loaded into rgdal. The driver page on
>> www.gdal.org relates to the current release and may include information
>> for the development version. Your version seems to be old.
>>
>>>
>>> gdalinfo --formats returns:
>>
>> ogrinfo --formats, or equivalently ogrDrivers() in R with rgdal loaded.
>>
>> Hope this clarifies,
>>
>> Roger
>>
>>>
>>> Supported Formats:
>>>  VRT (rw+v): Virtual Raster
>>>  GTiff (rw+v): GeoTIFF
>>>  NITF (rw+v): National Imagery Transmission Format
>>>  RPFTOC (ro): Raster Product Format TOC format
>>>  HFA (rw+v): Erdas Imagine Images (.img)
>>>  SAR_CEOS (ro): CEOS SAR Image
>>>  CEOS (ro): CEOS Image
>>>  JAXAPALSAR (ro): JAXA PALSAR Product Reader (Level 1.1/1.5)
>>>  GFF (rov): Ground-based SAR Applications Testbed File Format (.gff)
>>>  ELAS (rw+): ELAS
>>>  AIG (ro): Arc/Info Binary Grid
>>>  AAIGrid (rwv): Arc/Info ASCII Grid
>>>  SDTS (ro): SDTS Raster
>>>  OGDI (ro): OGDI Bridge
>>>  DTED (rwv): DTED Elevation Raster
>>>  PNG (rwv): Portable Network Graphics
>>>  JPEG (rwv): JPEG JFIF
>>>  MEM (rw+): In Memory Raster
>>>  JDEM (ro): Japanese DEM (.mem)
>>>  GIF (rwv): Graphics Interchange Format (.gif)
>>>  BIGGIF (rov): Graphics Interchange Format (.gif)
>>>  ESAT (ro): Envisat Image Format
>>>  BSB (ro): Maptech BSB Nautical Charts
>>>  XPM (rw): X11 PixMap Format
>>>  BMP (rw+v): MS Windows Device Independent Bitmap
>>>  DIMAP (ro): SPOT DIMAP
>>>  AirSAR (ro): AirSAR Polarimetric Image
>>>  RS2 (ro): RadarSat 2 XML Product
>>>  PCIDSK (rw+v): PCIDSK Database File
>>>  PCRaster (rw): PCRaster Raster File
>>>  ILWIS (rw+v): ILWIS Raster Map
>>>  SGI (rw+): SGI Image File Format 1.0
>>>  SRTMHGT (rwv): SRTMHGT File Format
>>>  Leveller (rw+): Leveller heightfield
>>>  Terragen (rw+): Terragen heightfield
>>>  GMT (rw): GMT NetCDF Grid Format
>>>  netCDF (rw): Network Common Data Format
>>>  HDF4 (ro): Hierarchical Data Format Release 4
>>>  HDF4Image (rw+): HDF4 Dataset
>>>  ISIS3 (ro): USGS Astrogeology ISIS cube (Version 3)
>>>  ISIS2 (ro): USGS Astrogeology ISIS cube (Version 2)
>>>  PDS (ro): NASA Planetary Data System
>>>  TIL (ro): EarthWatch .TIL
>>>  ERS (rw+): ERMapper .ers Labelled
>>>  JPEG2000 (rwv): JPEG-2000 part 1 (ISO/IEC 15444-1)
>>>  L1B (ro): NOAA Polar Orbiter Level 1b Data Set
>>>  FIT (rw): FIT Image
>>>  GRIB (ro): GRIdded Binary (.grb)
>>>  RMF (rw+): Raster Matrix Format
>>>  WCS (ro): OGC Web Coverage Service
>>>  WMS (ro): OGC Web Map Service
>>>  MSGN (ro): EUMETSAT Archive native (.nat)
>>>  RST (rw+): Idrisi Raster A.1
>>>  INGR (rw+): Intergraph Raster
>>>  GSAG (rw): Golden Software ASCII Grid (.grd)
>>>  GSBG (rw+): Golden Software Binary Grid (.grd)
>>>  GS7BG (ro): Golden Software 7 Binary Grid (.grd)
>>>  COSAR (ro): COSAR Annotated Binary Matrix (TerraSAR-X)
>>>  TSX (ro): TerraSAR-X Product
>>>  COASP (ro): DRDC COASP SAR Processor Raster
>>>  R (rwv): R Object Data Store
>>>  PNM (rw+): Portable Pixmap Format (netpbm)
>>>  DOQ1 (ro): USGS DOQ (Old Style)
>>>  DOQ2 (ro): USGS DOQ (New Style)
>>>  ENVI (rw+v): ENVI .hdr Labelled
>>>  EHdr (rw+v): ESRI .hdr Labelled
>>>  GenBin (ro): Generic Binary (.hdr Labelled)
>>>  PAux (rw+): PCI .aux Labelled
>>>  MFF (rw+): Vexcel MFF Raster
>>>  MFF2 (rw+): Vexcel MFF2 (HKV) Raster
>>>  FujiBAS (ro): Fuji BAS Scanner Image
>>>  GSC (ro): GSC Geogrid
>>>  FAST (ro): EOSAT FAST Format
>>>  BT (rw+): VTP .bt (Binary Terrain) 1.3 Format
>>>  LAN (ro): Erdas .LAN/.GIS
>>>  CPG (ro): Convair PolGASP
>>>  IDA (rw+): Image Data and Analysis
>>>  NDF (ro): NLAPS Data Format
>>>  EIR (ro): Erdas Imagine Raw
>>>  DIPEx (ro): DIPEx
>>>  LCP (rov): FARSITE v.4 Landscape File (.lcp)
>>>  RIK (ro): Swedish Grid RIK (.rik)
>>>  USGSDEM (rw): USGS Optional ASCII DEM (and CDED)
>>>  GXF (ro): GeoSoft Grid Exchange Format
>>>  DODS (ro): DAP 3.x servers
>>>  HTTP (ro): HTTP Fetching Wrapper
>>>  BAG (ro): Bathymetry Attributed Grid
>>>  HDF5 (ro): Hierarchical Data Format Release 5
>>>  HDF5Image (ro): HDF5 Dataset
>>>  NWT_GRD (ro): Northwood Numeric Grid Format .grd/.tab
>>>  NWT_GRC (ro): Northwood Classified Grid Format .grc/.tab
>>>  ADRG (rw+v): ARC Digitized Raster Graphics
>>>  SRP (rov): Standard Raster Product (ASRP/USRP)
>>>  BLX (rw): Magellan topo (.blx)
>>>  Rasterlite (rw): Rasterlite
>>>  EPSILON (rwv): Epsilon wavelets
>>>  WKTRaster (ro): PostGIS WKT Raster driver
>>>  SAGA (rw+v): SAGA GIS Binary Grid (.sdat)
>>>
>>>
>>>
>>> On 12/08/2014, at 4:32 PM, Frede Aakmann T?gersen
>> <frtog at vestas.com<mailto:frtog at vestas.com>>
>>> wrote:
>>>
>>> Sorry. I was too hasty. I suppose that your problem is with the GDAL
>> drivers. I see that http://www.gdal.org/drv_geojson.html points to
>> http://www.gdal.org/drv_geojson.html.
>>>
>>> Which package belong writeOGR to. What is the version of the package?
>> What is the version of your GDAL installation. What does e.g. 'gdalinfo --
>> formats' show?
>>>
>>> Yours sincerely / Med venlig hilsen
>>>
>>>
>>> Frede Aakmann T?gersen
>>> Specialist, M.Sc., Ph.D.
>>> Plant Performance & Modeling
>>>
>>> Technology & Service Solutions
>>> T +45 9730 5135
>>> M +45 2547 6050
>>> frtog at vestas.com<mailto:frtog at vestas.com>
>>> http://www.vestas.com
>>>
>>> Company reg. name: Vestas Wind Systems A/S
>>> This e-mail is subject to our e-mail disclaimer statement.
>>> Please refer to www.vestas.com/legal/notice
>>> If you have received this e-mail in error please contact the sender.
>>>
>>>
>>> -----Original Message-----
>>> From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-
>>> project.org] On Behalf Of Frede Aakmann T?gersen
>>> Sent: 12. august 2014 08:19
>>> To: Philip Greenwood; r-sig-geo at r-project.org
>>> Subject: Re: [R-sig-Geo] WriteOGR to GeoJSON loses CRS
>>>
>>> Hi
>>>
>>> Google points me to http://geojson.org/geojson-spec.html. See Section 3
>>> about CRSs.
>>>
>>> Yours sincerely / Med venlig hilsen
>>>
>>>
>>> Frede Aakmann T?gersen
>>> Specialist, M.Sc., Ph.D.
>>> Plant Performance & Modeling
>>>
>>> Technology & Service Solutions
>>> T +45 9730 5135
>>> M +45 2547 6050
>>> frtog at vestas.com
>>> http://www.vestas.com
>>>
>>> Company reg. name: Vestas Wind Systems A/S
>>> This e-mail is subject to our e-mail disclaimer statement.
>>> Please refer to www.vestas.com/legal/notice
>>> If you have received this e-mail in error please contact the sender.
>>>
>>>
>>> -----Original Message-----
>>> From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-
>>> project.org] On Behalf Of Philip Greenwood
>>> Sent: 12. august 2014 08:13
>>> To: r-sig-geo at r-project.org
>>> Subject: [R-sig-Geo] WriteOGR to GeoJSON loses CRS
>>>
>>> Hi I am using WriteOGR to write a SpatialPolygonsDataFrame to a
>>> temporary
>>> GeoJSON file. However the CRS seems to be lost in the resulting file.
>>> Does the GeoJSON driver support CRSs?
>>>
>>> Thanks
>>> Phil
>>>
>>> ---
>>> Philip Greenwood
>>> Product Manager
>>> Australian Urban Research Infrastructure Network (AURIN)
>>> Level 2 West, Alice Hoy Building, University of Melbourne
>>> T: +61-(0)3-9035-8549
>>> E:
>>>
>>>
>> philip.greenwood at unimelb.edu.au<mailto:philip.greenwood at unimelb.edu
>>> .au>
>>>
>>>
>>>
>>> [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>> ---
>>> Philip Greenwood
>>> Product Manager
>>> Australian Urban Research Infrastructure Network (AURIN)
>>> Level 2 West, Alice Hoy Building, University of Melbourne
>>> T: +61-(0)3-9035-8549
>>> E:
>> philip.greenwood at unimelb.edu.au<mailto:philip.greenwood at unimelb.edu
>> .au>
>>>
>>>
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>>
>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics,
>> Helleveien 30, N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>> e-mail: Roger.Bivand at nhh.no
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no

From markpayneatwork at gmail.com  Tue Aug 12 12:56:31 2014
From: markpayneatwork at gmail.com (Mark Payne)
Date: Tue, 12 Aug 2014 12:56:31 +0200
Subject: [R-sig-Geo] writeRaster does not preserve names when writing to
	NetCDF
In-Reply-To: <CANVKczOsi_FQu=maNYmwvUJWabCnpGd9b8fHRoqdEa2C1rNxBg@mail.gmail.com>
References: <CAGBzUO8nkr3xUYyaG_xaFa5n3uoLMRT3W5Qnm2bPUgLA4DAY9A@mail.gmail.com>
	<36b84c5138514a07b8a93891132eb9a4@EX-0-HT0.lancs.local>
	<CANVKczOsi_FQu=maNYmwvUJWabCnpGd9b8fHRoqdEa2C1rNxBg@mail.gmail.com>
Message-ID: <CAGBzUO_XMSa3L6ug++LBGscr1a65CjnR+Aua13=SfxewhRqFpg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140812/9f8feb76/attachment.pl>

From mdsumner at gmail.com  Tue Aug 12 13:18:08 2014
From: mdsumner at gmail.com (Michael Sumner)
Date: Tue, 12 Aug 2014 21:18:08 +1000
Subject: [R-sig-Geo] writeRaster does not preserve names when writing to
	NetCDF
In-Reply-To: <53E9E5C7.7040409@aqua.dtu.dk>
References: <CAGBzUO8nkr3xUYyaG_xaFa5n3uoLMRT3W5Qnm2bPUgLA4DAY9A@mail.gmail.com>
	<36b84c5138514a07b8a93891132eb9a4@EX-0-HT0.lancs.local>
	<CANVKczOsi_FQu=maNYmwvUJWabCnpGd9b8fHRoqdEa2C1rNxBg@mail.gmail.com>
	<53E9E5C7.7040409@aqua.dtu.dk>
Message-ID: <CAAcGz9-_JFUhR6VnErgjjemdZK0hHV+EQApeFD36ZD26XCHSRA@mail.gmail.com>

I'm sure you could find a way to do this with NetCDF/4 *if* the model
allows it, and add the required modifications to raster to handle it.

I'm just saying "it's complicated" for the reasons I outlined. I don't
see a natural way for this to happen.

Also - I've never seen text in a NetCDF variable, it's always in the
attributes (that I've seen) - maybe it's different with NetCDF4.

As Barry points out, to get names on dimension slices (or bundle
multiple NetCDF variables into a single data set) you effectively have
to write a new convention/API for dealing with this  file format that
"can (nearly but not quite) do everything ".

Cheers, Mike

On Tue, Aug 12, 2014 at 8:00 PM, Mark Payne <mpay at aqua.dtu.dk> wrote:
> Hi Barry, Michael,
>
> Thanks for the replies. Maybe I should clarify my point a bit more.  As
> Barry says, NetCDF is well suited for storing high-dimensional data. For
> example, at the bottom is the header description from a netcdf file written
> with writeRaster(). Note that the variable is stored as a 3-D array with
> dimensions "value", "easting" and "northing". The values of the eastings and
> northings are written appropriately, but the value dimension/variable is
> just filled with a numeric value. This dimensions is used by brick() when
> reading a netcdf to populate the layer names.
>
> My proposed solution would be to add an argument to writeRaster() called
> zvalues (or similar), which would be written to the value
> dimension/variable. Initially this could be a numeric vector, (e.g. the
> depths that this variable corresponds to: 6, 12, 18, 30, 40, 50...) but I
> believe it may be possible to make this a string as well e.g. with NetCDF
> v4.
>
> Does that make sense?
>
> Mark
>
>
>
> netcdf EP_1992 {
> dimensions:
>         easting = 23 ;
>         northing = 37 ;
>         value = UNLIMITED ; // (6 currently)
> variables:
>         double easting(easting) ;
>                 easting:units = "meter" ;
>                 easting:long_name = "easting" ;
>         double northing(northing) ;
>                 northing:units = "meter" ;
>                 northing:long_name = "northing" ;
>         int value(value) ;
>                 value:units = "unknown" ;
>                 value:long_name = "value" ;
>         float variable(value, northing, easting) ;
>                 variable:_FillValue = -3.4e+38 ;
>                 variable:missing_value = -3.4e+38 ;
>                 variable:long_name = "variable" ;
>                 variable:projection = "+proj=utm +zone=29 +datum=WGS84
> +units=km +ellps=WGS84 +towgs84=0,0,0" ;
>                 variable:projection_format = "PROJ.4" ;
>                 variable:min = -2.26894027129976, -4.60561400334956,
> -3.66937747634895, -5.97212100926874, -6.12123420979669, -3.44363500443944 ;
>                 variable:max = 3.11489873186157, 3.39906242513969,
> 3.3160419018914, 2.74477652780673, 1.8108377756661, 0.70816760511994 ;
>
>
> // global attributes:
>                 :Conventions = "CF-1.4" ;
>                 :created_by = "R, packages ncdf and raster (version 2.2-31)"
> ;
>                 :date = "2014-08-11 15:37:25" ;
> data:
>
>  easting = 25, 75, 125, 175, 225, 275, 325, 375, 425, 475, 525, 575, 625,
>     675, 725, 775, 825, 875, 925, 975, 1025, 1075, 1125 ;
>
>  northing = 6425, 6375, 6325, 6275, 6225, 6175, 6125, 6075, 6025, 5975,
> 5925,
>     5875, 5825, 5775, 5725, 5675, 5625, 5575, 5525, 5475, 5425, 5375, 5325,
>     5275, 5225, 5175, 5125, 5075, 5025, 4975, 4925, 4875, 4825, 4775, 4725,
>     4675, 4625 ;
>
>  value = 1, 2, 3, 4, 5, 6 ;
>
> }
>
>
>
> On 12/08/14 09:53, Barry Rowlingson wrote:
>>
>> On Tue, Aug 12, 2014 at 12:05 AM, Michael Sumner <mdsumner at gmail.com>
>> wrote:
>>>
>>> Hi,
>>>
>>> I don't think that NetCDF has the capacity to store these names in a
>>> natural way. Internally your brick is stored as a NetCDF variable, in
>>> this case a 3d array. To do this it would need to define a 'dimension"
>>> and include a lookup map to the names. A NetCDF dimension variable
>>> must be populated with numbers I believe, so you would need another
>>> variable to store those and then add in features to raster to use
>>> them.
>>>
>>> There's at least two blockers here:
>>> - the NetCDF model is not designed for storing tabular data (a RGB
>>> image is a table of records in one sense, not a 3d array of integers)
>>> - gridded data storage usually conflates "dimension" with
>>> "attributes", which is unfortunate.
>>
>>
>>   Ummmm....
>>
>>   NetCDF can store just about anything. Its that flexibility that makes
>> it hard for one piece of software that writes a raster brick totally
>> compatible with another piece of software that writes a raster brick.
>> The NetCDF format itself has no convention for how to store it.
>>
>>   So people have developed conventions!
>>
>> http://www.unidata.ucar.edu/software/netcdf/docs/BestPractices.html
>> http://www.unidata.ucar.edu/software/netcdf/conventions.html
>>
>> http://cfconventions.org/Data/cf-convetions/cf-conventions-1.7/build/cf-conventions-multi.html
>>
>> [yes there's a typo in that last one - "convetions" - that's how it is.]
>>
>>   You can see which convention a NetCDF file claims to be by dumping it
>> with ncdump on the command line:
>>
>>   // global attributes:
>>          :Conventions = "CF-1.4" ;
>>          :created_by = "R, packages ncdf and raster (version 2.1-49)" ;
>>          :date = "2014-08-11 17:17:01" ;
>>
>> [note this also dumps the data, you might want to pipe it to | more]
>>
>> The exact convention used by raster and rgdal seems to vary depending
>> on whether ncdf is loaded when raster saves it, or something. At least
>> in my blurry morning fumblings I seem to have reached contradictory
>> examples which need clearing up once the coffee IV hits. The varname
>> argument to writeRaster doesn't seem to do anything, but I'm probably
>> looking at the wrong file or have an old package:raster or something.
>>
>> Anyway, the two main ways of storing multi-layer raster appear to be,
>> and these are files with CF-1.4/5 convention markers, as a 3d cube
>> with dimension (Nx,Ny,Nz) or as a set of 2d named variables. The names
>> of these 2d variables should be settable at write time and recoverable
>> at read-time. However, If the data is a 3d cube then I don't think the
>> dimensions can have names, although I've not really understood the CF
>> standards yet (and that page has links to some awful documentation and
>> missing links...).
>>
>> It would be quite simple to add another variable, of characters, to
>> the NetCDF file, but I suspect keeping to a given NetCDF Convention
>> would be a good idea assuming it can do it.
>>
>> End-of-ramble...
>>
>> Barry
>>
>>
>>
>>
>>
>>>
>>>
>>>
>>> On Tue, Aug 12, 2014 at 12:26 AM, Mark Payne <markpayneatwork at gmail.com>
>>> wrote:
>>>>
>>>> Hi,
>>>>
>>>> I have a problem with writeRaster when writing a brick to NetCDF - the
>>>> names of the layers are not preserved. Here is a minimum example to
>>>> demonstrate the point:
>>>>
>>>> #Create an arbitrary brick and write it out
>>>> b <- brick(system.file("external/rlogo.grd", package="raster"))
>>>> fname <- file.path( tempdir(),"test.nc")
>>>> dmp <- writeRaster(b,file=fname)
>>>>
>>>> #Now read it back in
>>>> a <- brick(fname)
>>>>
>>>> #However, names are not preserved
>>>>>
>>>>> names(b)
>>>>
>>>> [1] "red"   "green" "blue"
>>>>>
>>>>> names(a)
>>>>
>>>> [1] "X1" "X2" "X3"
>>>>>
>>>>>
>>>>
>>>> I realise this is a touch tricky, as NetCDF isn't exactly made for
>>>> storing
>>>> character strings, which is how raster stores the layer names. However,
>>>> there are many cases where the string is just a representation of a
>>>> number
>>>> anyway.... e.g. when working with time or depth levels as the layers in
>>>> the
>>>> brick. One solution could therefore be to allow the writeRaster function
>>>> to
>>>> take an argument "zvals", in the same way that it takes "zname" and
>>>> "zunit"
>>>> when working with netcdf files - this argument would let you specify the
>>>> numeric values of the z-axis. Everything else would then work ok I
>>>> think,
>>>> as brick() picks up the values of the z-axis, converts them to strings
>>>> and
>>>> assigns them to layer names.
>>>>
>>>> Cheers,
>>>>
>>>> Mark
>>>>
>>>> raster version: 2.2-31
>>>> R version 3.0.3
>>>> ncdf4 version: 1.10
>>>> Platform: Linux Mint 16, 64 bit
>>>>
>>>>          [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at r-project.org
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>
>>>
>>>
>>> --
>>> Michael Sumner
>>> Software and Database Engineer
>>> Australian Antarctic Division
>>> Hobart, Australia
>>> e-mail: mdsumner at gmail.com
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



-- 
Michael Sumner
Software and Database Engineer
Australian Antarctic Division
Hobart, Australia
e-mail: mdsumner at gmail.com


From b.rowlingson at lancaster.ac.uk  Tue Aug 12 17:26:50 2014
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 12 Aug 2014 16:26:50 +0100
Subject: [R-sig-Geo] writeRaster does not preserve names when writing to
	NetCDF
In-Reply-To: <9ad07ff88b594ef18a96adf35de2386d@EX-1-HT0.lancs.local>
References: <CAGBzUO8nkr3xUYyaG_xaFa5n3uoLMRT3W5Qnm2bPUgLA4DAY9A@mail.gmail.com>
	<36b84c5138514a07b8a93891132eb9a4@EX-0-HT0.lancs.local>
	<CANVKczOsi_FQu=maNYmwvUJWabCnpGd9b8fHRoqdEa2C1rNxBg@mail.gmail.com>
	<53E9E5C7.7040409@aqua.dtu.dk>
	<9ad07ff88b594ef18a96adf35de2386d@EX-1-HT0.lancs.local>
Message-ID: <CANVKczMa+8dDdoeMueHus2VV6gS0Oet0kBs08h6om0iog0+XnQ@mail.gmail.com>

This chunk of code writes a character vector to a file.  It needs two
dimensions, one that has to be big enough for the longest character
string, and one which has to be the length of the vector.

writeChars <- function(fn){
    nameDim = dim.def.ncdf("NamesDim","", 1:3)
    charDim = dim.def.ncdf("CharsDim","", 1:10)
    nameVar = var.def.ncdf("Names","",list(charDim,nameDim),"NA")
    nc = create.ncdf(fn, list(nameVar))
    v = c("red  ","green","blue ")
    for(i in 1:length(v)){
        put.var.ncdf(nc, nameVar, v[i], start=c(1,i), count=c(-1,1))
    }
    close.ncdf(nc)
}

Dumping the NetCDF gives:

data:
 CharsDim = 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 ;
 NamesDim = 1, 2, 3 ;
 Names =
  "red  ",
  "green",
  "blue " ;
}

Whether this is a good idea or not... Hmmmm....

I've noticed if you use `writeRaster` with format="CDF" you get the
data in one variable called "value", but if you use format="netCDF"
you get one named variable for each layer. I'm pretty sure these names
could be set and recovered, but currently they seem to be called Band1
etc. I think thats the GDAL driver at work:

"""
   This driver supports creation of netCDF file following the CF-1
convention. You may create set of 2D
   datasets. Each variable array is named Band1, Band2, ... BandN.
""" http://www.gdal.org/frmt_netcdf.html

Also, this section in writeRaster:

          NetCDF files have the following additional, optional,
          arguments: ?varname?, ?varunit?, ?longname?, ?xname?,
          ?yname?, ?zname?, ?zunit?

only seems to apply to format="CDF" and not "NetCDF", which seems to
ignore at least the ones I've tried. The "NetCDF" format seems to be
done via GDAL.

Is it worth putting any effort into this? I mean, is it worth *Robert*
putting any effort into this?

Barry


From sarah_crabbe at yahoo.com  Tue Aug 12 17:45:24 2014
From: sarah_crabbe at yahoo.com (sarah crabbe)
Date: Tue, 12 Aug 2014 08:45:24 -0700
Subject: [R-sig-Geo] histogram matching of cloud masked Landsat 8 messages
Message-ID: <1407858324.70260.YahooMailNeo@web125702.mail.ne1.yahoo.com>

Dear all,

We are trying to apply a histogram matching on cloudmasked landsat 8 images, with the intention to fill the clouds. 
Therefore we want to use the package "Landsat"

We tried to import two bands with the package "raster":

image1<-raster("LC82280562013211LGN00_B1.tif") 
image2<-raster("LC82280562013227LGN00_B1.tif") 

whereafter we try to apply a histogram matching with the landsat package:

histmatch(image1, image2, minval=0, maxval= 65535, by=1)

And we get following error:

Error in as.vector(data) : 
no method for coercing this S4 class to a vector

This might be easy to solve, but we just started to learn how to work with R for image processing, So could we please get some advice on this..
Many thanks
Sarah
	[[alternative HTML version deleted]]


From b.rowlingson at lancaster.ac.uk  Tue Aug 12 18:25:17 2014
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 12 Aug 2014 17:25:17 +0100
Subject: [R-sig-Geo] histogram matching of cloud masked Landsat 8
	messages
In-Reply-To: <e9603700f6364cfd83af35d7d1b5097d@EX-1-HT0.lancs.local>
References: <e9603700f6364cfd83af35d7d1b5097d@EX-1-HT0.lancs.local>
Message-ID: <CANVKczMFo4v+0hPp9V2MSvyASKN-ph5PkMCf-cr+=HE6K4RcQw@mail.gmail.com>

Instructions say (help(histmatch))


Arguments:

  master: The target image, in SpatialGridDataFrame, data frame, matrix
          or vector format.

   tofix: The image to be normalized, in any format.

but what you have is a *raster* object, not a SpatialGridDataFrame, or
any other of those.

 You can convert a raster, r, to a SpatialGridDataFrame, rg:

 > rg = as(r,"SpatialGridDataFrame")

and then feed those to histmatch. You probably have to convert both arguments.

Barry



On Tue, Aug 12, 2014 at 4:45 PM, sarah crabbe <sarah_crabbe at yahoo.com> wrote:
> Dear all,
>
> We are trying to apply a histogram matching on cloudmasked landsat 8 images, with the intention to fill the clouds.
> Therefore we want to use the package "Landsat"
>
> We tried to import two bands with the package "raster":
>
> image1<-raster("LC82280562013211LGN00_B1.tif")
> image2<-raster("LC82280562013227LGN00_B1.tif")
>
> whereafter we try to apply a histogram matching with the landsat package:
>
> histmatch(image1, image2, minval=0, maxval= 65535, by=1)
>
> And we get following error:
>
> Error in as.vector(data) :
> no method for coercing this S4 class to a vector
>
> This might be easy to solve, but we just started to learn how to work with R for image processing, So could we please get some advice on this..
> Many thanks
> Sarah
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From sarah.goslee at gmail.com  Tue Aug 12 18:32:15 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 12 Aug 2014 12:32:15 -0400
Subject: [R-sig-Geo] histogram matching of cloud masked Landsat 8
	messages
In-Reply-To: <CANVKczMFo4v+0hPp9V2MSvyASKN-ph5PkMCf-cr+=HE6K4RcQw@mail.gmail.com>
References: <e9603700f6364cfd83af35d7d1b5097d@EX-1-HT0.lancs.local>
	<CANVKczMFo4v+0hPp9V2MSvyASKN-ph5PkMCf-cr+=HE6K4RcQw@mail.gmail.com>
Message-ID: <CAM_vju=yYsB_0em5V5UT4ANT+uFbosmpbO7uKkkBxjhffmsT2A@mail.gmail.com>

What Barry says is completely correct: the landsat package (not
Landsat), is not currently compatible with the format used by the
raster package, only with sp classes or base R object types. You can
convert the raster objects, or use the rgdal package to import your
tifs as SGDFs.

And as I told you in private email, the landsat package was developed
pre-Landsat 8, and has not been updated for the new data source.

Both raster compatibility and Landsat 8 support are in the works, but
will not be available in the very near future.

Sarah

On Tue, Aug 12, 2014 at 12:25 PM, Barry Rowlingson
<b.rowlingson at lancaster.ac.uk> wrote:
> Instructions say (help(histmatch))
>
>
> Arguments:
>
>   master: The target image, in SpatialGridDataFrame, data frame, matrix
>           or vector format.
>
>    tofix: The image to be normalized, in any format.
>
> but what you have is a *raster* object, not a SpatialGridDataFrame, or
> any other of those.
>
>  You can convert a raster, r, to a SpatialGridDataFrame, rg:
>
>  > rg = as(r,"SpatialGridDataFrame")
>
> and then feed those to histmatch. You probably have to convert both arguments.
>
> Barry
>
>
>
> On Tue, Aug 12, 2014 at 4:45 PM, sarah crabbe <sarah_crabbe at yahoo.com> wrote:
>> Dear all,
>>
>> We are trying to apply a histogram matching on cloudmasked landsat 8 images, with the intention to fill the clouds.
>> Therefore we want to use the package "Landsat"
>>
>> We tried to import two bands with the package "raster":
>>
>> image1<-raster("LC82280562013211LGN00_B1.tif")
>> image2<-raster("LC82280562013227LGN00_B1.tif")
>>
>> whereafter we try to apply a histogram matching with the landsat package:
>>
>> histmatch(image1, image2, minval=0, maxval= 65535, by=1)
>>
>> And we get following error:
>>
>> Error in as.vector(data) :
>> no method for coercing this S4 class to a vector
>>
>> This might be easy to solve, but we just started to learn how to work with R for image processing, So could we please get some advice on this..
>> Many thanks
>> Sarah

-- 
Sarah Goslee
http://www.functionaldiversity.org


From dave.gregovich at alaska.gov  Tue Aug 12 18:48:59 2014
From: dave.gregovich at alaska.gov (Gregovich, Dave P (DFG))
Date: Tue, 12 Aug 2014 16:48:59 +0000
Subject: [R-sig-Geo] +no_uoff flag in proj4string, epsg 26931
Message-ID: <174524AB15B8E6478D6F927B2131B09B5F0FF704@SOAJNUEXMB4.soa.alaska.gov>

Hello,
I would like to project data in epsg 26931 (NAD83 Alaska State Plane zone 1 meters), variant A. There are two variants to the projection:
--variant A has its origin on the central line of the projection, on the 'aposphere equator'
--variant B has its origin at the projection center
Apparently, variant A should be specifiable via a '+no_uoff' flag
I can specify variant B in this way...

#create a test point, and convert to SPDF
xy<-c(775082.505359,720337.454359)
test.pt<-data.frame(x=xy[1],y=xy[2],id=1)
coordinates(test.pt)<-c('x','y')

#Assign projection
proj4string(test.pt)<- '+proj=omerc +lat_0=57 +lonc=-133.6666666666667 +alpha=323.1301023611111
                                                                +k=0.9999 +x_0=5000000 +y_0=-5000000 +gamma=323.1301023611111 +datum=NAD83
                                                                +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0'

# the above is the same as using proj4string(test.pt)<-'+init = epsg:26931',
# it is also identical to the proj4string obtained for a shapefile created in ArcGIS and imported to R
# using 'readOGR', that is originally projected in the 26931

#But when I try to specify variant A, the +no_uoff flag is ignored...
proj4string(test.pt)<- '+proj=omerc +lat_0=57 +lonc=-133.6666666666667 +alpha=323.1301023611111 +no_uoff
                                                                +k=0.9999 +x_0=5000000 +y_0=-5000000 +gamma=323.1301023611111 +datum=NAD83
                                                                +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0'
proj4string(test.pt)
#just to verify, I also try using spTransform...
test.pt<-spTransform(test.pt,CRS('+proj=omerc +lat_0=57 +lonc=-133.6666666666667 +alpha=323.1301023611111 +no_uoff
                                                                                    +k=0.9999 +x_0=5000000 +y_0=-5000000 +gamma=323.1301023611111 +datum=NAD83
                                                                                    +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0'))
proj4string(test.pt)

I would report to the os.geo list on this, but I only know the R syntax to this point, so it is difficult to formulate an example for them.

Thanks kindly for any advice you can lend, I appreciate it.

Dave.

________________________________________________
sessionInfo()
R version 3.0.3 (2014-03-06)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252    LC_MONETARY=English_United States.1252 LC_NUMERIC=C                           LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] rgdal_0.8-16  raster_2.2-31 sp_1.0-15

loaded via a namespace (and not attached):
[1] grid_3.0.3      lattice_0.20-27 tools_3.0.3

> library(rgdal)
rgdal: version: 0.8-16, (SVN revision 498)
Geospatial Data Abstraction Library extensions to R successfully loaded
Loaded GDAL runtime: GDAL 1.11.0, released 2014/04/16
Path to GDAL shared files: C:/Program Files/R/R-3.0.3/library/rgdal/gdal
GDAL does not use iconv for recoding strings.
Loaded PROJ.4 runtime: Rel. 4.8.0, 6 March 2012, [PJ_VERSION: 480]
Path to PROJ.4 shared files: C:/Program Files/R/R-3.0.3/library/rgdal/proj
_____________________________________________

__________________________________
Dave Gregovich
Research Analyst
Alaska Department of Fish and Game
Wildlife Conservation Division
Douglas, AK 99821
(907) 465-4291
dave.gregovich at alaska.gov
__________________________________


	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Tue Aug 12 21:40:08 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 12 Aug 2014 21:40:08 +0200
Subject: [R-sig-Geo] +no_uoff flag in proj4string, epsg 26931
In-Reply-To: <174524AB15B8E6478D6F927B2131B09B5F0FF704@SOAJNUEXMB4.soa.alaska.gov>
References: <174524AB15B8E6478D6F927B2131B09B5F0FF704@SOAJNUEXMB4.soa.alaska.gov>
Message-ID: <alpine.LRH.2.03.1408122103580.32581@reclus.nhh.no>

On Tue, 12 Aug 2014, Gregovich, Dave P (DFG) wrote:

> Hello,

> I would like to project data in epsg 26931 (NAD83 Alaska State Plane 
> zone 1 meters), variant A. There are two variants to the projection:
> --variant A has its origin on the central line of the projection, on the 
> 'aposphere equator'
> --variant B has its origin at the projection center

> Apparently, variant A should be specifiable via a '+no_uoff' flag
> I can specify variant B in this way...

This is a complex topic, see also:

http://trac.osgeo.org/proj/ticket/104
http://trac.osgeo.org/proj/ticket/128
https://trac.osgeo.org/gdal/ticket/4910

On my system running PROJ4 4.9.0 (development version, unreleased), and 
using the example from the proj trac ticket 104, I see:

mat <- matrix(c(-(133+(40/60)), 57), ncol=2)
project(mat, '+proj=omerc +lat_0=57 +lonc=-133.6666666666667 
+alpha=323.1301023611111 +k=0.9999 +x_0=5000000 +y_0=-5000000 
+gamma=323.1301023611111 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m 
+no_defs')

       [,1]   [,2]
[1,] 5e+06 -5e+06

project(mat, '+proj=omerc +lat_0=57 +lonc=-133.6666666666667 
+alpha=323.1301023611111 +k=0.9999 +x_0=5000000 +y_0=-5000000 
+gamma=323.1301023611111 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m 
+no_uoff +no_defs')

          [,1]     [,2]
[1,] 818676.7 575097.7

but

SPpt <- SpatialPoints(mat, proj4string=CRS("+proj=longlat +datum=WGS84"))
spTransform(SPpt, CRS("+proj=omerc +lat_0=57 +lonc=-133.6666666666667 
+alpha=323.1301023611111 +k=0.9999 +x_0=5000000 +y_0=-5000000 
+gamma=323.1301023611111 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m 
+no_defs"))


SpatialPoints:
      coords.x1 coords.x2
[1,]     5e+06    -5e+06

spTransform(SPpt, CRS("+proj=omerc +lat_0=57 +lonc=-133.6666666666667 
+alpha=323.1301023611111 +k=0.9999 +x_0=5000000 +y_0=-5000000 
+gamma=323.1301023611111 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m 
+no_uoff +no_defs"))

SpatialPoints:
      coords.x1 coords.x2
[1,]     5e+06    -5e+06

with +no_uoff removed. Indeed:

> CRS("+proj=omerc +lat_0=57 +lonc=-133.6666666666667 
+alpha=323.1301023611111 +k=0.9999 +x_0=5000000 +y_0=-5000000 
+gamma=323.1301023611111 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m 
+no_uoff +no_defs")
CRS arguments:
  +proj=omerc +lat_0=57 +lonc=-133.6666666666667 +alpha=323.1301023611111
+k=0.9999 +x_0=5000000 +y_0=-5000000 +gamma=323.1301023611111
+ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs

removes +no_uoff.

CRS sends the string out to PROJ4 for checking, via:

> checkCRSArgs("+proj=omerc +lat_0=57 +lonc=-133.6666666666667 
+alpha=323.1301023611111 +k=0.9999 +x_0=5000000 +y_0=-5000000 
+gamma=323.1301023611111 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m 
+no_uoff +no_defs")
[[1]]
[1] TRUE

[[2]]
[1] "+proj=omerc +lat_0=57 +lonc=-133.6666666666667 
+alpha=323.1301023611111 +k=0.9999 +x_0=5000000 +y_0=-5000000 
+gamma=323.1301023611111 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m 
+no_defs"

which drops +no_uoff. The function is:

checkCRSArgs <- function(uprojargs) {
   res <- .Call("checkCRSArgs", uprojargs, PACKAGE="rgdal")
   res[[2]] <- sub("^\\s+", "", res[[2]])
   res
}

and calls the C function:

         pj = pj_init_plus(CHAR(STRING_ELT(args, 0)));

then

         strcpy(cbuf, pj_get_def(pj, 0));

to get the definition back out. I'm not sure whether pj_get_def is not 
dropping this on the way out.

Even subverting the CRS object:

myCRS <- CRS("+proj=omerc +lat_0=57 +lonc=-133.6666666666667 
+alpha=323.1301023611111 +k=0.9999 +x_0=5000000 +y_0=-5000000 
+gamma=323.1301023611111 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m 
+no_uoff +no_defs")
myCRS at projargs <- "+proj=omerc +lat_0=57 +lonc=-133.6666666666667 
+alpha=323.1301023611111 +k=0.9999 +x_0=5000000 +y_0=-5000000 
+gamma=323.1301023611111 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m 
+no_uoff +no_defs"
> spTransform(SPpt, myCRS)
SpatialPoints:
      coords.x1 coords.x2
[1,]     5e+06    -5e+06
Coordinate Reference System (CRS) arguments: +proj=omerc +lat_0=57
+lonc=-133.6666666666667 +alpha=323.1301023611111 +k=0.9999
+x_0=5000000 +y_0=-5000000 +gamma=323.1301023611111 +ellps=GRS80
+towgs84=0,0,0,0,0,0,0 +units=m +no_uoff +no_defs

doesn't get the correct value.

Using proj and cs2cs at the command line give the correct results:

$ proj +proj=omerc +lat_0=57 +lonc=-133.6666666666667 
+alpha=323.1301023611111 +k=0.9999 +x_0=5000000 +y_0=-5000000 
+gamma=323.1301023611111 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m 
+no_defs
133d40'W 57N
5000000.00	-5000000.00
$ proj +proj=omerc +lat_0=57 +lonc=-133.6666666666667 
+alpha=323.1301023611111 +k=0.9999 +x_0=5000000 +y_0=-5000000 
+gamma=323.1301023611111 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m 
+no_off +no_defs
133d40'W 57N
818676.73	575097.69

$ cs2cs +proj=longlat +datum=WGS84 +to +proj=omerc +lat_0=57 
+lonc=-133.6666666666667 +alpha=323.1301023611111 +k=0.9999 +x_0=5000000 
+y_0=-5000000 +gamma=323.1301023611111 +ellps=GRS80 
+towgs84=0,0,0,0,0,0,0 +units=m +no_defs
133d40'W 57N
5000000.00	-5000000.00 0.00
$ cs2cs +proj=longlat +datum=WGS84 +to +proj=omerc +lat_0=57 
+lonc=-133.6666666666667 +alpha=323.1301023611111 +k=0.9999 +x_0=5000000 
+y_0=-5000000 +gamma=323.1301023611111 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 
+units=m +no_uoff +no_defs
133d40'W 57N
818676.73	575097.69 0.00

Does anyone else have any insights?

Roger

>
> #create a test point, and convert to SPDF
> xy<-c(775082.505359,720337.454359)
> test.pt<-data.frame(x=xy[1],y=xy[2],id=1)
> coordinates(test.pt)<-c('x','y')
>
> #Assign projection
> proj4string(test.pt)<- '+proj=omerc +lat_0=57 +lonc=-133.6666666666667 +alpha=323.1301023611111
>                                                                +k=0.9999 +x_0=5000000 +y_0=-5000000 +gamma=323.1301023611111 +datum=NAD83
>                                                                +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0'
>
> # the above is the same as using proj4string(test.pt)<-'+init = epsg:26931',
> # it is also identical to the proj4string obtained for a shapefile created in ArcGIS and imported to R
> # using 'readOGR', that is originally projected in the 26931
>
> #But when I try to specify variant A, the +no_uoff flag is ignored...
> proj4string(test.pt)<- '+proj=omerc +lat_0=57 +lonc=-133.6666666666667 +alpha=323.1301023611111 +no_uoff
>                                                                +k=0.9999 +x_0=5000000 +y_0=-5000000 +gamma=323.1301023611111 +datum=NAD83
>                                                                +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0'
> proj4string(test.pt)
> #just to verify, I also try using spTransform...
> test.pt<-spTransform(test.pt,CRS('+proj=omerc +lat_0=57 +lonc=-133.6666666666667 +alpha=323.1301023611111 +no_uoff
>                                                                                    +k=0.9999 +x_0=5000000 +y_0=-5000000 +gamma=323.1301023611111 +datum=NAD83
>                                                                                    +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0'))
> proj4string(test.pt)
>
> I would report to the os.geo list on this, but I only know the R syntax to this point, so it is difficult to formulate an example for them.
>
> Thanks kindly for any advice you can lend, I appreciate it.
>
> Dave.
>
> ________________________________________________
> sessionInfo()
> R version 3.0.3 (2014-03-06)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252    LC_MONETARY=English_United States.1252 LC_NUMERIC=C                           LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] rgdal_0.8-16  raster_2.2-31 sp_1.0-15
>
> loaded via a namespace (and not attached):
> [1] grid_3.0.3      lattice_0.20-27 tools_3.0.3
>
>> library(rgdal)
> rgdal: version: 0.8-16, (SVN revision 498)
> Geospatial Data Abstraction Library extensions to R successfully loaded
> Loaded GDAL runtime: GDAL 1.11.0, released 2014/04/16
> Path to GDAL shared files: C:/Program Files/R/R-3.0.3/library/rgdal/gdal
> GDAL does not use iconv for recoding strings.
> Loaded PROJ.4 runtime: Rel. 4.8.0, 6 March 2012, [PJ_VERSION: 480]
> Path to PROJ.4 shared files: C:/Program Files/R/R-3.0.3/library/rgdal/proj
> _____________________________________________
>
> __________________________________
> Dave Gregovich
> Research Analyst
> Alaska Department of Fish and Game
> Wildlife Conservation Division
> Douglas, AK 99821
> (907) 465-4291
> dave.gregovich at alaska.gov
> __________________________________
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From dave.gregovich at alaska.gov  Tue Aug 12 22:20:55 2014
From: dave.gregovich at alaska.gov (Dave Gregovich)
Date: Tue, 12 Aug 2014 13:20:55 -0700 (PDT)
Subject: [R-sig-Geo] +no_uoff flag in proj4string, epsg 26931
In-Reply-To: <alpine.LRH.2.03.1408122103580.32581@reclus.nhh.no>
References: <174524AB15B8E6478D6F927B2131B09B5F0FF704@SOAJNUEXMB4.soa.alaska.gov>
	<alpine.LRH.2.03.1408122103580.32581@reclus.nhh.no>
Message-ID: <1407874855419-7586933.post@n2.nabble.com>

On Tue, 12 Aug 2014, Gregovich, Dave P (DFG) wrote:

Thanks kindly Roger. 
I would like to note, for those who may be considering this issue, that a 
a prior version of rgdal retained the +no_uoff flag. The version is detailed
below:

> library(rgdal)
Geospatial Data Abstraction Library extensions to R successfully loaded
Loaded GDAL runtime: GDAL 1.7.2, released 2010/04/23
Path to GDAL shared files: C:/Program Files/R/R-2.13.1/library/rgdal/gdal
Loaded PROJ.4 runtime: Rel. 4.7.1, 23 September 2009, [PJ_VERSION: 470]
Path to PROJ.4 shared files: C:/Program Files/R/R-2.13.1/library/rgdal/proj

I do have a number of versions of the rgdal package installed, so I will
later today go through and check when the +no_uoff flag appears to start to
be dropped.




--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/no-uoff-flag-in-proj4string-epsg-26931-tp7586931p7586933.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From Roger.Bivand at nhh.no  Wed Aug 13 14:51:27 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 13 Aug 2014 14:51:27 +0200
Subject: [R-sig-Geo] +no_uoff flag in proj4string, epsg 26931
In-Reply-To: <1407874855419-7586933.post@n2.nabble.com>
References: <174524AB15B8E6478D6F927B2131B09B5F0FF704@SOAJNUEXMB4.soa.alaska.gov>
	<alpine.LRH.2.03.1408122103580.32581@reclus.nhh.no>
	<1407874855419-7586933.post@n2.nabble.com>
Message-ID: <alpine.LRH.2.03.1408131438110.7372@reclus.nhh.no>

On Tue, 12 Aug 2014, Dave Gregovich wrote:

> On Tue, 12 Aug 2014, Gregovich, Dave P (DFG) wrote:
>
> Thanks kindly Roger.
> I would like to note, for those who may be considering this issue, that a
> a prior version of rgdal retained the +no_uoff flag. The version is detailed
> below:

The problem appears to be in PROJ.4, introduced possibly in 4.8 (not 
checked in earlier versions). Because spTransform was trying to be 
careful, it was expanding the projection arguments through pj_get_def(). 
In pj_get_def(), the +no_uoff and +no_off parameters are seen as unused 
and not returned - I've added a code example to the proj trac report 128 
to attempt to get it fixed.

In rgdal revision 508 I've added a temporary work-around to put +no_uoff 
or +no_off back into the projection parameters if pj_get_def() removes 
them, tried with PROJ.4 4.8.0 and trunk. If you can install rgdal from 
source from R-forge: https://r-forge.r-project.org/scm/?group_id=884, 
please do so and try with a recent PROJ.4. If you would prefer a tarball 
for a source install, or a Windows binary, please ask. There are other 
pending revisions in this version, so it isn't yet ready for release, but 
your feedback on this particular issue would be helpful.

Best wishes,

Roger

>
>> library(rgdal)
> Geospatial Data Abstraction Library extensions to R successfully loaded
> Loaded GDAL runtime: GDAL 1.7.2, released 2010/04/23
> Path to GDAL shared files: C:/Program Files/R/R-2.13.1/library/rgdal/gdal
> Loaded PROJ.4 runtime: Rel. 4.7.1, 23 September 2009, [PJ_VERSION: 470]
> Path to PROJ.4 shared files: C:/Program Files/R/R-2.13.1/library/rgdal/proj
>
> I do have a number of versions of the rgdal package installed, so I will
> later today go through and check when the +no_uoff flag appears to start to
> be dropped.
>
>
>
>
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/no-uoff-flag-in-proj4string-epsg-26931-tp7586931p7586933.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From Dave.Chagaris at MyFWC.com  Wed Aug 13 18:26:53 2014
From: Dave.Chagaris at MyFWC.com (Chagaris, Dave)
Date: Wed, 13 Aug 2014 12:26:53 -0400
Subject: [R-sig-Geo] raster brick error cells are not equally spaced
Message-ID: <2F09C501769D914983129DD4812457203623AA424F@FWC-TLEX10.fwc.state.fl.us>

I am trying to read netcdf files into R using the brick function.  I have many netcdf files and want to process them on a 64bit workstation instead my 32bit laptop.  The code    I'm using works fine on my 32 bit laptop, but on the workstation I get an error "Error in .rasterObjectFromCDF(x, type = objecttype, band = band, ...) :
  cells are not equally spaced; you should extract values as points".

Any  help is appreciated.

On Laptop...
> library(raster)

> library(ncdf)

> windows(record=T)

> sessionInfo()
R version 2.15.0 (2012-03-30)
Platform: i386-pc-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252    LC_MONETARY=English_United States.1252 LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] grDevices datasets  splines   graphics  stats     tcltk     utils     methods   base

other attached packages:
[1] ncdf_1.6.6       raster_2.0-41    sp_1.0-11        svSocket_0.9-53  TinnR_1.0-5      R2HTML_2.2       Hmisc_3.9-3      survival_2.36-12

loaded via a namespace (and not attached):
[1] cluster_1.14.2 grid_2.15.0    lattice_0.20-6 svMisc_0.9-65  tools_2.15.0

> i = "expt_31.0_20130226.nc"

> open.ncdf(paste(getwd(),i,sep='/'))
[1] "file C:/dave.chagaris/HYCOM/expt_31.0_20130226.nc has 4 dimensions:"
[1] "MT   Size: 1"
[1] "Depth   Size: 40"
[1] "Latitude   Size: 213"
[1] "Longitude   Size: 290"
[1] "------------------------"
[1] "file C:/dave.chagaris/HYCOM/expt_31.0_20130226.nc has 8 variables:"
[1] "float ssh[Longitude,Latitude,MT]  Longname: sea surf. height  [31.0H] Missval:1.26765060022823e+30"
[1] "float u[Longitude,Latitude,Depth,MT]  Longname: u-veloc. [31.0H] Missval:1.26765060022823e+30"
[1] "float v[Longitude,Latitude,Depth,MT]  Longname: v-veloc. [31.0H] Missval:1.26765060022823e+30"
[1] "float w_velocity[Longitude,Latitude,Depth,MT]  Longname: w-veloc. [31.0H] Missval:1.26765060022823e+30"
[1] "float temperature[Longitude,Latitude,Depth,MT]  Longname:  temp [31.0H] Missval:1.26765060022823e+30"
[1] "float salinity[Longitude,Latitude,Depth,MT]  Longname: salinity [31.0H] Missval:1.26765060022823e+30"
[1] "float mld[Longitude,Latitude,MT]  Longname: MLT (0.20 degC)   [31.0H] Missval:1.26765060022823e+30"
[1] "float mlp[Longitude,Latitude,MT]  Longname: MLT (0.03 kg/m3)  [31.0H] Missval:1.26765060022823e+30"

> salt = brick(paste(getwd(),i,sep='/'),varname='salinity',lvar=4,level=2)
Warning messages:
1: In rm(.SavedPlots) : object '.SavedPlots' not found
2: In .rasterObjectFromCDF(x, type = objecttype, band = band, ...) :
  level set to: 1

on workstation...

> setwd('E:\\work\\data\\HYCOM')

> .libPaths('C:\\Users\\dave.chagaris\\Documents\\R\\win-library\\3.1')

> library(raster)

> library(ncdf)

> sessionInfo()

R version 2.15.1 (2012-06-22)

Platform: x86_64-pc-mingw32/x64 (64-bit)



locale:

[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252

[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C

[5] LC_TIME=English_United States.1252



attached base packages:

[1] stats     graphics  grDevices utils     datasets  methods   base



other attached packages:

[1] ncdf_1.6.6    raster_2.2-31 sp_1.0-15



loaded via a namespace (and not attached):

[1] grid_2.15.1    lattice_0.20-6 tools_2.15.1

> i = "expt_31.0_20130226.nc"

> open.ncdf(paste(getwd(),i,sep='/'))

[1] "file E:/work/data/HYCOM/expt_31.0_20130226.nc has 4 dimensions:"

[1] "MT   Size: 1"

[1] "Depth   Size: 40"

[1] "Latitude   Size: 213"

[1] "Longitude   Size: 290"

[1] "------------------------"

[1] "file E:/work/data/HYCOM/expt_31.0_20130226.nc has 8 variables:"

[1] "float ssh[Longitude,Latitude,MT]  Longname: sea surf. height  [31.0H] Missval:1.26765060022823e+30"

[1] "float u[Longitude,Latitude,Depth,MT]  Longname: u-veloc. [31.0H] Missval:1.26765060022823e+30"

[1] "float v[Longitude,Latitude,Depth,MT]  Longname: v-veloc. [31.0H] Missval:1.26765060022823e+30"

[1] "float w_velocity[Longitude,Latitude,Depth,MT]  Longname: w-veloc. [31.0H] Missval:1.26765060022823e+30"

[1] "float temperature[Longitude,Latitude,Depth,MT]  Longname:  temp [31.0H] Missval:1.26765060022823e+30"

[1] "float salinity[Longitude,Latitude,Depth,MT]  Longname: salinity [31.0H] Missval:1.26765060022823e+30"

[1] "float mld[Longitude,Latitude,MT]  Longname: MLT (0.20 degC)   [31.0H] Missval:1.26765060022823e+30"

[1] "float mlp[Longitude,Latitude,MT]  Longname: MLT (0.03 kg/m3)  [31.0H] Missval:1.26765060022823e+30"

> salt = brick(paste(getwd(),i,sep='/'),varname='salinity',lvar=4,level=2)

Error in .rasterObjectFromCDF(x, type = objecttype, band = band, ...) :

  cells are not equally spaced; you should extract values as points

In addition: Warning message:

In .rasterObjectFromCDF(x, type = objecttype, band = band, ...) :

  level set to: 1



David Chagaris, PhD
Associate Research Scientist
Florida Fish and Wildlife Conservation Commission
Fish and Wildlife Research Institute
100 8th Ave SE
St. Petersburg, FL  33701
727-502-4959
fax: 727-893-1374


	[[alternative HTML version deleted]]


From arnold_salvacion at yahoo.com  Thu Aug 14 02:27:01 2014
From: arnold_salvacion at yahoo.com (Arnold Salvacion)
Date: Thu, 14 Aug 2014 08:27:01 +0800
Subject: [R-sig-Geo] Converting .hdf file to raster layer
Message-ID: <1407976021.54447.YahooMailNeo@web192705.mail.sg3.yahoo.com>

Dear Colleagues,

Does any here have already experience converting NOAA AVHRR VHP Product in .hdf (ftp://ftp.star.nesdis.noaa.gov/pub/corp/scsb/wguo/data/VHP_16km/VH/ ) format to a raster layer in R??


Best regards,

Arnold
	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Thu Aug 14 02:59:24 2014
From: mdsumner at gmail.com (Michael Sumner)
Date: Thu, 14 Aug 2014 10:59:24 +1000
Subject: [R-sig-Geo] raster brick error cells are not equally spaced
In-Reply-To: <2F09C501769D914983129DD4812457203623AA424F@FWC-TLEX10.fwc.state.fl.us>
References: <2F09C501769D914983129DD4812457203623AA424F@FWC-TLEX10.fwc.state.fl.us>
Message-ID: <CAAcGz9_N4LSMxTRrAmRZwGzWNwHiegmx49k0rQ4s3f+s0cHE=w@mail.gmail.com>

Hello, can you point to or share one of the files? Sometimes these
things are just a regular grid under the hood but that has been
forgotten in favour of longitude/latitude arrays.

If that's the case you can reconstruct the original grid and all is
well, there's not really any precedent for this but I have a lot of
examples that work well.  (Also sometimes there's only a small amount
of numeric fuzz that you can ignore).

The raster types cannot take grids that have irregular (rectilinear or
curvilinear) coordinates. There's no way around this except some
combination of these:

- read the data in the raw using ncdf/ncdf4 or RNetCDF and use base
graphics with image() (which can deal with rectilinear grids), or
points() or maybe polygons (which with care can  deal with curvilinear
grids).
- use the hidden argument "stopIfNotEqualSpaced=FALSE" to raster() to
get the data out and deal with the arrays as "index-only" grids


Cheers, Mike.



On Thu, Aug 14, 2014 at 2:26 AM, Chagaris, Dave <Dave.Chagaris at myfwc.com> wrote:
> I am trying to read netcdf files into R using the brick function.  I have many netcdf files and want to process them on a 64bit workstation instead my 32bit laptop.  The code    I'm using works fine on my 32 bit laptop, but on the workstation I get an error "Error in .rasterObjectFromCDF(x, type = objecttype, band = band, ...) :
>   cells are not equally spaced; you should extract values as points".
>
> Any  help is appreciated.
>
> On Laptop...
>> library(raster)
>
>> library(ncdf)
>
>> windows(record=T)
>
>> sessionInfo()
> R version 2.15.0 (2012-03-30)
> Platform: i386-pc-mingw32/i386 (32-bit)
>
> locale:
> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252    LC_MONETARY=English_United States.1252 LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] grDevices datasets  splines   graphics  stats     tcltk     utils     methods   base
>
> other attached packages:
> [1] ncdf_1.6.6       raster_2.0-41    sp_1.0-11        svSocket_0.9-53  TinnR_1.0-5      R2HTML_2.2       Hmisc_3.9-3      survival_2.36-12
>
> loaded via a namespace (and not attached):
> [1] cluster_1.14.2 grid_2.15.0    lattice_0.20-6 svMisc_0.9-65  tools_2.15.0
>
>> i = "expt_31.0_20130226.nc"
>
>> open.ncdf(paste(getwd(),i,sep='/'))
> [1] "file C:/dave.chagaris/HYCOM/expt_31.0_20130226.nc has 4 dimensions:"
> [1] "MT   Size: 1"
> [1] "Depth   Size: 40"
> [1] "Latitude   Size: 213"
> [1] "Longitude   Size: 290"
> [1] "------------------------"
> [1] "file C:/dave.chagaris/HYCOM/expt_31.0_20130226.nc has 8 variables:"
> [1] "float ssh[Longitude,Latitude,MT]  Longname: sea surf. height  [31.0H] Missval:1.26765060022823e+30"
> [1] "float u[Longitude,Latitude,Depth,MT]  Longname: u-veloc. [31.0H] Missval:1.26765060022823e+30"
> [1] "float v[Longitude,Latitude,Depth,MT]  Longname: v-veloc. [31.0H] Missval:1.26765060022823e+30"
> [1] "float w_velocity[Longitude,Latitude,Depth,MT]  Longname: w-veloc. [31.0H] Missval:1.26765060022823e+30"
> [1] "float temperature[Longitude,Latitude,Depth,MT]  Longname:  temp [31.0H] Missval:1.26765060022823e+30"
> [1] "float salinity[Longitude,Latitude,Depth,MT]  Longname: salinity [31.0H] Missval:1.26765060022823e+30"
> [1] "float mld[Longitude,Latitude,MT]  Longname: MLT (0.20 degC)   [31.0H] Missval:1.26765060022823e+30"
> [1] "float mlp[Longitude,Latitude,MT]  Longname: MLT (0.03 kg/m3)  [31.0H] Missval:1.26765060022823e+30"
>
>> salt = brick(paste(getwd(),i,sep='/'),varname='salinity',lvar=4,level=2)
> Warning messages:
> 1: In rm(.SavedPlots) : object '.SavedPlots' not found
> 2: In .rasterObjectFromCDF(x, type = objecttype, band = band, ...) :
>   level set to: 1
>
> on workstation...
>
>> setwd('E:\\work\\data\\HYCOM')
>
>> .libPaths('C:\\Users\\dave.chagaris\\Documents\\R\\win-library\\3.1')
>
>> library(raster)
>
>> library(ncdf)
>
>> sessionInfo()
>
> R version 2.15.1 (2012-06-22)
>
> Platform: x86_64-pc-mingw32/x64 (64-bit)
>
>
>
> locale:
>
> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252
>
> [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
>
> [5] LC_TIME=English_United States.1252
>
>
>
> attached base packages:
>
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
>
>
> other attached packages:
>
> [1] ncdf_1.6.6    raster_2.2-31 sp_1.0-15
>
>
>
> loaded via a namespace (and not attached):
>
> [1] grid_2.15.1    lattice_0.20-6 tools_2.15.1
>
>> i = "expt_31.0_20130226.nc"
>
>> open.ncdf(paste(getwd(),i,sep='/'))
>
> [1] "file E:/work/data/HYCOM/expt_31.0_20130226.nc has 4 dimensions:"
>
> [1] "MT   Size: 1"
>
> [1] "Depth   Size: 40"
>
> [1] "Latitude   Size: 213"
>
> [1] "Longitude   Size: 290"
>
> [1] "------------------------"
>
> [1] "file E:/work/data/HYCOM/expt_31.0_20130226.nc has 8 variables:"
>
> [1] "float ssh[Longitude,Latitude,MT]  Longname: sea surf. height  [31.0H] Missval:1.26765060022823e+30"
>
> [1] "float u[Longitude,Latitude,Depth,MT]  Longname: u-veloc. [31.0H] Missval:1.26765060022823e+30"
>
> [1] "float v[Longitude,Latitude,Depth,MT]  Longname: v-veloc. [31.0H] Missval:1.26765060022823e+30"
>
> [1] "float w_velocity[Longitude,Latitude,Depth,MT]  Longname: w-veloc. [31.0H] Missval:1.26765060022823e+30"
>
> [1] "float temperature[Longitude,Latitude,Depth,MT]  Longname:  temp [31.0H] Missval:1.26765060022823e+30"
>
> [1] "float salinity[Longitude,Latitude,Depth,MT]  Longname: salinity [31.0H] Missval:1.26765060022823e+30"
>
> [1] "float mld[Longitude,Latitude,MT]  Longname: MLT (0.20 degC)   [31.0H] Missval:1.26765060022823e+30"
>
> [1] "float mlp[Longitude,Latitude,MT]  Longname: MLT (0.03 kg/m3)  [31.0H] Missval:1.26765060022823e+30"
>
>> salt = brick(paste(getwd(),i,sep='/'),varname='salinity',lvar=4,level=2)
>
> Error in .rasterObjectFromCDF(x, type = objecttype, band = band, ...) :
>
>   cells are not equally spaced; you should extract values as points
>
> In addition: Warning message:
>
> In .rasterObjectFromCDF(x, type = objecttype, band = band, ...) :
>
>   level set to: 1
>
>
>
> David Chagaris, PhD
> Associate Research Scientist
> Florida Fish and Wildlife Conservation Commission
> Fish and Wildlife Research Institute
> 100 8th Ave SE
> St. Petersburg, FL  33701
> 727-502-4959
> fax: 727-893-1374
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



-- 
Michael Sumner
Software and Database Engineer
Australian Antarctic Division
Hobart, Australia
e-mail: mdsumner at gmail.com


From mdsumner at gmail.com  Thu Aug 14 10:52:30 2014
From: mdsumner at gmail.com (Michael Sumner)
Date: Thu, 14 Aug 2014 18:52:30 +1000
Subject: [R-sig-Geo] Converting .hdf file to raster layer
In-Reply-To: <1407976021.54447.YahooMailNeo@web192705.mail.sg3.yahoo.com>
References: <1407976021.54447.YahooMailNeo@web192705.mail.sg3.yahoo.com>
Message-ID: <CAAcGz9_O7cE6bC22NBww9kRuyVoLC-Ooj21G+WP9Ata+J70G2Q@mail.gmail.com>

Just had a look, the file has subdatasets and seemingly raster can't
handle those. (I haven't explored this much but might have a chance
to).

library(raster)
library(rgdal)  ## built with HDF4, HDF5 and NetCDF4

fsrc <- "ftp://ftp.star.nesdis.noaa.gov/pub/corp/scsb/wguo/data/VHP_16km/VH/VHP.G16.C07.NC.P1981035.ND.hdf"
f <- basename(fsrc)
if (!file.exists(f)) download.file(fsrc, f, mode = "wb")

## found with system GDAL, see below
sds <- c('HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":0',
         'HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":1',
         'HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":2'
         )

##r <- brick(sds)
##Error in GDALinfo(filename, silent = silent, returnRAT = RAT,
returnCategoryNames = RAT) :
 ## object 'RATlist' not found
##Error in .rasterObjectFromFile(x, band = band, objecttype = "RasterLayer",  :
 ##                                Cannot create a RasterLayer object
from this file.
  ##                             In addition: Warning message:
 ##                                In dim(x) : no bands in dataset


## try with rgdal directly, so far so good but
## no spatial-reference (again see gdalinfo output below)
raster(readGDAL(sds[1])  )

 raster(readGDAL(sds[1])  )
HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":0 has GDAL driver HDF4Image
and has 904 rows and 2500 columns
class       : RasterLayer
dimensions  : 904, 2500, 2260000  (nrow, ncol, ncell)
resolution  : 1, 1  (x, y)
extent      : 0, 2500, 0, 904  (xmin, xmax, ymin, ymax)
coord. ref. : NA
data source : in memory
names       : band1
values      : -99.9, 322  (min, max)

Warning message:
In readGDAL(sds[1]) : GeoTransform values not available


## proceed without caution, again values from gdalinfo
b <- brick(stack(sapply(sds, function(x) raster(readGDAL(x)))))
proj4string(b) <-  CRS(" +proj=longlat +ellps=WGS84 +datum=WGS84
+no_defs +towgs84=0,0,0")
extent(b) <- c(-180, 180, -55.15200043, 75.02400208)

library(maptools
data(wrld_simpl)
plot(b, addfun = function() plot(wrld_simpl, add = TRUE))

That looks ok to me, I don't know if it's WGS84 or the sphere or
something else.

Cheers, Mike.





system(sprintf("gdalinfo %s", f))

Driver: HDF4/Hierarchical Data Format Release 4
Files: VHP.G16.C07.NC.P1981035.ND.hdf
Size is 512, 512
Coordinate System is `'
Metadata:
  ANCILLARY_FILES=FILE_CONFIGURE:vh.config
FILE_PRELAUNCH_CALIBRATION:../ancillary/AVHRR_calibration_prelaunch.txt
FILE_POSTLAUNCH_CALIBRATION:../ancillary/AVHRR_calibration_postlaunch.txt
FILE_IGBP_LANDTYPE:../ancillary/igbp_landtype_GVIx.hdf
FILE_METADATA_REGIONS:../ancillary/regions_for_metadata.txt
FILE_EDF_NDVI:../ancillary/NVI_counts_ByLine_G04.hdf
FILE_EDF_BT4:../ancillary/BT4_counts_ByLine_G04.hdf

  CITATION_TO_DOCUMENTS=User Guide of Vegetation Health(VH) system
(version 1.3, March 21 2012)
  CONFIGURE_FILE_CONTENT=[Options for vh.exe]
DIR_Ancillary=                 ../ancillary
DIR_GVI=                       data/VH_unitTest1/weekly
DIR_VH=                        data/VH_unitTest1/G04
DIR_VH_META=                   data/VH_unitTest1/G04/meta
DIR_CLIMAT=                    data/VH_EDF_v2/climate_G04
DIR_CLIMAT_META=               data/VH_EDF_v2/climate_G04/meta
FILE_PREFIX=       VHP
Input_Data_Type=       VHP
ResolutionString=              G04
Days_Per_Period=               7
FilterSize=                    15
applyEDFonNDVI=                1     # 0: none, 1: linebyline for NVI;
applyEDFonBT=                  1
Instrument=                    AVHRR # so far AVHRR is the only option
FORMAT_GVI=                   NETCDF #or HDF4
FORMAT_CLIMAT=                HDF4
FORMAT_ND=                    NETCDF
FORMAT_SM=                    NETCDF
FORMAT_VH=                    NETCDF

[Periods of GVI data used for VH]
# this section control which satellite will be used for calculating
ND, SM and VH
#satID satNumber yearWeek1 yearWeek2
NC 07 198135 198449
NF 09 198509 198844
NH 11 198846 199436
NJ 14 199504 200052
NL 16 200101 200401
NL 16 200405 200410
NL 16 200425 200428
NL 16 200430 200523
NN 18 200524 201052
NP 19 201101 399999

[Periods of AVHRR data used for GVI climatology]
#this section controls which satellite will be used for creating VH climatology
#satID satNumber yearWeek1 yearWeek2
NC 07 198142 198450
NF 09 198515 198752
NH 11 198920 199252
NJ 14 199520 199952
NL 16 200120 200252

[END]


  CONTACT=NOAA/NESDIS/STAR/EMB
  DATE_BEGIN=239
  DATE_END=245
  DAYS_PER_PERIOD=7
  END_LATITUDE_RANGE=-55.15200043
  END_LONGITUDE_RANGE=180
  INPUT_FILENAMES=data/VH_unitTest1/weekly/VHP.G04.C07.NC.P1981035.S239.E245.nc

  INPUT_FILES=1
  INSTRUMENT=AVHRR
  PERIOD_OF_YEAR=35
  PRODUCT_NAME=Vegetation Health
  PROJECTION=Plate_Carree
  SATELLITE=NC
  START_LATITUDE_RANGE=75.02400208
  START_LONGITUDE_RANGE=-180
  TIME_BEGIN=00:00 UTC (use day time data only)
  TIME_END=23:59 UTC (use day time data only)
  VERSION=VH (vh.exe,version 1.3, March 21 2012)
  YEAR=1981
Subdatasets:
  SUBDATASET_1_NAME=HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":0
  SUBDATASET_1_DESC=[904x2500] BT4 (16-bit integer)
  SUBDATASET_2_NAME=HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":1
  SUBDATASET_2_DESC=[904x2500] NDVI (16-bit integer)
  SUBDATASET_3_NAME=HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":2
  SUBDATASET_3_DESC=[904x2500] QA (8-bit unsigned integer)
Corner Coordinates:
Upper Left  (    0.0,    0.0)
Lower Left  (    0.0,  512.0)
Upper Right (  512.0,    0.0)
Lower Right (  512.0,  512.0)
Center      (  256.0,  256.0)

On Thu, Aug 14, 2014 at 10:27 AM, Arnold Salvacion
<arnold_salvacion at yahoo.com> wrote:
> Dear Colleagues,
>
> Does any here have already experience converting NOAA AVHRR VHP Product in .hdf (ftp://ftp.star.nesdis.noaa.gov/pub/corp/scsb/wguo/data/VHP_16km/VH/ ) format to a raster layer in R?
>
>
> Best regards,
>
> Arnold
>         [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
Michael Sumner
Software and Database Engineer
Australian Antarctic Division
Hobart, Australia
e-mail: mdsumner at gmail.com


From arnold_salvacion at yahoo.com  Thu Aug 14 17:30:19 2014
From: arnold_salvacion at yahoo.com (Arnold Salvacion)
Date: Thu, 14 Aug 2014 23:30:19 +0800
Subject: [R-sig-Geo] Converting .hdf file to raster layer
In-Reply-To: <CAAcGz9_O7cE6bC22NBww9kRuyVoLC-Ooj21G+WP9Ata+J70G2Q@mail.gmail.com>
References: <1407976021.54447.YahooMailNeo@web192705.mail.sg3.yahoo.com>
	<CAAcGz9_O7cE6bC22NBww9kRuyVoLC-Ooj21G+WP9Ata+J70G2Q@mail.gmail.com>
Message-ID: <1408030219.59613.YahooMailNeo@web192705.mail.sg3.yahoo.com>

Hi Mike,

Thanks. I tried you code? but got the error message below:

Arnold


R version 3.0.3 (2014-03-06) -- "Warm Puppy"
Copyright (C) 2014 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit) R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details. R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications. Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R. > fsrc <- + "ftp://ftp.star.nesdis.noaa.gov/pub/corp/scsb/wguo/data/VHP_16km/VH/VHP.G16.C07.NC.P1981035.ND.hdf"; > f <- basename(fsrc) > if (!file.exists(f)) download.file(fsrc, f, mode = "wb") trying URL 'ftp://ftp.star.nesdis.noaa.gov/pub/corp/scsb/wguo/data/VHP_16km/VH/VHP.G16.C07.NC.P1981035.ND.hdf' using Synchronous WinInet calls opened URL downloaded 2.1 Mb > sds <- c('HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":0', + 'HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":1', + 'HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":2' + ) > raster(readGDAL(sds[1])  ) Error in raster(readGDAL(sds[1])) :  error in evaluating the argument 'x' in selecting a method for function 'raster': Error in .local(.Object, ...) :  `C:\Users\Owner\Documents\HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":0' does not exist in the file system,
and is not recognised as a supported dataset name.?



On Thursday, August 14, 2014 4:52 PM, Michael Sumner <mdsumner at gmail.com> wrote:
 


Just had a look, the file has subdatasets and seemingly raster can't
handle those. (I haven't explored this much but might have a chance
to).

library(raster)
library(rgdal)? ## built with HDF4, HDF5 and NetCDF4

fsrc <- "ftp://ftp.star.nesdis.noaa.gov/pub/corp/scsb/wguo/data/VHP_16km/VH/VHP.G16.C07.NC.P1981035.ND.hdf"
f <- basename(fsrc)
if (!file.exists(f)) download.file(fsrc, f, mode = "wb")

## found with system GDAL, see below
sds <- c('HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":0',
? ? ? ?  'HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":1',
? ? ? ?  'HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":2'
? ? ? ?  )

##r <- brick(sds)
##Error in GDALinfo(filename, silent = silent, returnRAT = RAT,
returnCategoryNames = RAT) :
## object 'RATlist' not found
##Error in .rasterObjectFromFile(x, band = band, objecttype = "RasterLayer",? :
##? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Cannot create a RasterLayer object
from this file.
? ##? ? ? ? ? ? ? ? ? ? ? ? ? ?  In addition: Warning message:
##? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? In dim(x) : no bands in dataset


## try with rgdal directly, so far so good but
## no spatial-reference (again see gdalinfo output below)
raster(readGDAL(sds[1])? )

raster(readGDAL(sds[1])? )
HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":0 has GDAL driver HDF4Image
and has 904 rows and 2500 columns
class? ? ?  : RasterLayer
dimensions? : 904, 2500, 2260000? (nrow, ncol, ncell)
resolution? : 1, 1? (x, y)
extent? ? ? : 0, 2500, 0, 904? (xmin, xmax, ymin, ymax)
coord. ref. : NA
data source : in memory
names? ? ?  : band1
values? ? ? : -99.9, 322? (min, max)

Warning message:
In readGDAL(sds[1]) : GeoTransform values not available


## proceed without caution, again values from gdalinfo
b <- brick(stack(sapply(sds, function(x) raster(readGDAL(x)))))
proj4string(b) <-? CRS(" +proj=longlat +ellps=WGS84 +datum=WGS84
+no_defs +towgs84=0,0,0")
extent(b) <- c(-180, 180, -55.15200043, 75.02400208)

library(maptools
data(wrld_simpl)
plot(b, addfun = function() plot(wrld_simpl, add = TRUE))

That looks ok to me, I don't know if it's WGS84 or the sphere or
something else.

Cheers, Mike.





system(sprintf("gdalinfo %s", f))

Driver: HDF4/Hierarchical Data Format Release 4
Files: VHP.G16.C07.NC.P1981035.ND.hdf
Size is 512, 512
Coordinate System is `'
Metadata:
? ANCILLARY_FILES=FILE_CONFIGURE:vh.config
FILE_PRELAUNCH_CALIBRATION:../ancillary/AVHRR_calibration_prelaunch.txt
FILE_POSTLAUNCH_CALIBRATION:../ancillary/AVHRR_calibration_postlaunch.txt
FILE_IGBP_LANDTYPE:../ancillary/igbp_landtype_GVIx.hdf
FILE_METADATA_REGIONS:../ancillary/regions_for_metadata.txt
FILE_EDF_NDVI:../ancillary/NVI_counts_ByLine_G04.hdf
FILE_EDF_BT4:../ancillary/BT4_counts_ByLine_G04.hdf

? CITATION_TO_DOCUMENTS=User Guide of Vegetation Health(VH) system
(version 1.3, March 21 2012)
? CONFIGURE_FILE_CONTENT=[Options for vh.exe]
DIR_Ancillary=? ? ? ? ? ? ? ?  ../ancillary
DIR_GVI=? ? ? ? ? ? ? ? ? ? ?  data/VH_unitTest1/weekly
DIR_VH=? ? ? ? ? ? ? ? ? ? ? ? data/VH_unitTest1/G04
DIR_VH_META=? ? ? ? ? ? ? ? ?  data/VH_unitTest1/G04/meta
DIR_CLIMAT=? ? ? ? ? ? ? ? ? ? data/VH_EDF_v2/climate_G04
DIR_CLIMAT_META=? ? ? ? ? ? ?  data/VH_EDF_v2/climate_G04/meta
FILE_PREFIX=? ? ?  VHP
Input_Data_Type=? ? ?  VHP
ResolutionString=? ? ? ? ? ? ? G04
Days_Per_Period=? ? ? ? ? ? ?  7
FilterSize=? ? ? ? ? ? ? ? ? ? 15
applyEDFonNDVI=? ? ? ? ? ? ? ? 1? ?  # 0: none, 1: linebyline for NVI;
applyEDFonBT=? ? ? ? ? ? ? ? ? 1
Instrument=? ? ? ? ? ? ? ? ? ? AVHRR # so far AVHRR is the only option
FORMAT_GVI=? ? ? ? ? ? ? ? ?  NETCDF #or HDF4
FORMAT_CLIMAT=? ? ? ? ? ? ? ? HDF4
FORMAT_ND=? ? ? ? ? ? ? ? ? ? NETCDF
FORMAT_SM=? ? ? ? ? ? ? ? ? ? NETCDF
FORMAT_VH=? ? ? ? ? ? ? ? ? ? NETCDF

[Periods of GVI data used for VH]
# this section control which satellite will be used for calculating
ND, SM and VH
#satID satNumber yearWeek1 yearWeek2
NC 07 198135 198449
NF 09 198509 198844
NH 11 198846 199436
NJ 14 199504 200052
NL 16 200101 200401
NL 16 200405 200410
NL 16 200425 200428
NL 16 200430 200523
NN 18 200524 201052
NP 19 201101 399999

[Periods of AVHRR data used for GVI climatology]
#this section controls which satellite will be used for creating VH climatology
#satID satNumber yearWeek1 yearWeek2
NC 07 198142 198450
NF 09 198515 198752
NH 11 198920 199252
NJ 14 199520 199952
NL 16 200120 200252

[END]


? CONTACT=NOAA/NESDIS/STAR/EMB
? DATE_BEGIN=239
? DATE_END=245
? DAYS_PER_PERIOD=7
? END_LATITUDE_RANGE=-55.15200043
? END_LONGITUDE_RANGE=180
? INPUT_FILENAMES=data/VH_unitTest1/weekly/VHP.G04.C07.NC.P1981035.S239.E245.nc

? INPUT_FILES=1
? INSTRUMENT=AVHRR
? PERIOD_OF_YEAR=35
? PRODUCT_NAME=Vegetation Health
? PROJECTION=Plate_Carree
? SATELLITE=NC
? START_LATITUDE_RANGE=75.02400208
? START_LONGITUDE_RANGE=-180
? TIME_BEGIN=00:00 UTC (use day time data only)
? TIME_END=23:59 UTC (use day time data only)
? VERSION=VH (vh.exe,version 1.3, March 21 2012)
? YEAR=1981
Subdatasets:
? SUBDATASET_1_NAME=HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":0
? SUBDATASET_1_DESC=[904x2500] BT4 (16-bit integer)
? SUBDATASET_2_NAME=HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":1
? SUBDATASET_2_DESC=[904x2500] NDVI (16-bit integer)
? SUBDATASET_3_NAME=HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":2
? SUBDATASET_3_DESC=[904x2500] QA (8-bit unsigned integer)
Corner Coordinates:
Upper Left? (? ? 0.0,? ? 0.0)
Lower Left? (? ? 0.0,? 512.0)
Upper Right (? 512.0,? ? 0.0)
Lower Right (? 512.0,? 512.0)
Center? ? ? (? 256.0,? 256.0)


On Thu, Aug 14, 2014 at 10:27 AM, Arnold Salvacion
<arnold_salvacion at yahoo.com> wrote:
> Dear Colleagues,
>
> Does any here have already experience converting NOAA AVHRR VHP Product in .hdf (ftp://ftp.star.nesdis.noaa.gov/pub/corp/scsb/wguo/data/VHP_16km/VH/ ) format to a raster layer in R?
>
>
> Best regards,
>
> Arnold
>? ? ? ?  [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
Michael Sumner
Software and Database Engineer
Australian Antarctic Division
Hobart, Australia
e-mail: mdsumner at gmail.com
	[[alternative HTML version deleted]]


From dicko.ahmadou at gmail.com  Thu Aug 14 20:33:15 2014
From: dicko.ahmadou at gmail.com (Ahmadou Dicko)
Date: Thu, 14 Aug 2014 18:33:15 +0000
Subject: [R-sig-Geo] Converting .hdf file to raster layer
In-Reply-To: <CAAcGz9_O7cE6bC22NBww9kRuyVoLC-Ooj21G+WP9Ata+J70G2Q@mail.gmail.com>
References: <1407976021.54447.YahooMailNeo@web192705.mail.sg3.yahoo.com>
	<CAAcGz9_O7cE6bC22NBww9kRuyVoLC-Ooj21G+WP9Ata+J70G2Q@mail.gmail.com>
Message-ID: <CAP8THHW2HDXkOqsyDeaHWqoPDoETskjSCP6wZTPtsmjK8X9vNQ@mail.gmail.com>

You can use the gdalUtils package to get information on datasets inside
your hdf file and then stack them using the raster package

library(raster)
library(rgdal)  ## built with HDF4 support
library(gdalUtils)

fsrc <- "
ftp://ftp.star.nesdis.noaa.gov/pub/corp/scsb/wguo/data/VHP_16km/VH/VHP.G16.C07.NC.P1981035.ND.hdf
"
f <- file.path("/tmp", basename(fsrc))
if (!file.exists(f)) download.file(fsrc, f, mode = "wb")

info <- gdalinfo(f)
data <- grep("HDF4_SDS", info, value = TRUE)
data <- gsub("SUBDATASET_\\d+_NAME=|\\s+", "", data)


sds <- stack(data)
sds
## class       : RasterStack
## dimensions  : 904, 2500, 2260000, 3  (nrow, ncol, ncell, nlayers)
## resolution  : 1, 1  (x, y)
## extent      : 0, 2500, 0, 904  (xmin, xmax, ymin, ymax)
## coord. ref. : NA
## names       : VHP.G16.C07.NC.P1981035.ND.1,
VHP.G16.C07.NC.P1981035.ND.2, VHP.G16.C07.NC.P1981035.ND.3
## min values  :                       -32768,
-32768,                            0
## max values  :                        32767,
32767,                          255

##You can use RasterBrick too, by doing `brick(sds)`

sessionInfo()
## R version 3.1.1 Patched (2014-08-12 r66349)
## Platform: x86_64-unknown-linux-gnu (64-bit)

## locale:
##  [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C
##  [3] LC_TIME=en_US.utf8        LC_COLLATE=en_US.utf8
##  [5] LC_MONETARY=en_US.utf8    LC_MESSAGES=en_US.utf8
##  [7] LC_PAPER=en_US.utf8       LC_NAME=C
##  [9] LC_ADDRESS=C              LC_TELEPHONE=C
## [11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C

## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods
## [7] base

## other attached packages:
## [1] gdalUtils_0.3.2 rgdal_0.8-16    raster_2.2-32
## [4] sp_1.0-15

## loaded via a namespace (and not attached):
##  [1] codetools_0.2-8   compiler_3.1.1    foreach_1.4.2
##  [4] grid_3.1.1        iterators_1.0.7   lattice_0.20-29
##  [7] R.methodsS3_1.6.1 R.oo_1.18.0       R.utils_1.32.4
## [10] tools_3.1.1

grep("hdf4", gdalDrivers()$name, ignore.case = TRUE, value = TRUE)
## [1] "HDF4"      "HDF4Image"



On Thu, Aug 14, 2014 at 8:52 AM, Michael Sumner <mdsumner at gmail.com> wrote:

> Just had a look, the file has subdatasets and seemingly raster can't
> handle those. (I haven't explored this much but might have a chance
> to).
>
> library(raster)
> library(rgdal)  ## built with HDF4, HDF5 and NetCDF4
>
> fsrc <- "
> ftp://ftp.star.nesdis.noaa.gov/pub/corp/scsb/wguo/data/VHP_16km/VH/VHP.G16.C07.NC.P1981035.ND.hdf
> "
> f <- basename(fsrc)
> if (!file.exists(f)) download.file(fsrc, f, mode = "wb")
>
> ## found with system GDAL, see below
> sds <- c('HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":0',
>          'HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":1',
>          'HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":2'
>          )
>
> ##r <- brick(sds)
> ##Error in GDALinfo(filename, silent = silent, returnRAT = RAT,
> returnCategoryNames = RAT) :
>  ## object 'RATlist' not found
> ##Error in .rasterObjectFromFile(x, band = band, objecttype =
> "RasterLayer",  :
>  ##                                Cannot create a RasterLayer object
> from this file.
>   ##                             In addition: Warning message:
>  ##                                In dim(x) : no bands in dataset
>
>
> ## try with rgdal directly, so far so good but
> ## no spatial-reference (again see gdalinfo output below)
> raster(readGDAL(sds[1])  )
>
>  raster(readGDAL(sds[1])  )
> HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":0 has GDAL driver
> HDF4Image
> and has 904 rows and 2500 columns
> class       : RasterLayer
> dimensions  : 904, 2500, 2260000  (nrow, ncol, ncell)
> resolution  : 1, 1  (x, y)
> extent      : 0, 2500, 0, 904  (xmin, xmax, ymin, ymax)
> coord. ref. : NA
> data source : in memory
> names       : band1
> values      : -99.9, 322  (min, max)
>
> Warning message:
> In readGDAL(sds[1]) : GeoTransform values not available
>
>
> ## proceed without caution, again values from gdalinfo
> b <- brick(stack(sapply(sds, function(x) raster(readGDAL(x)))))
> proj4string(b) <-  CRS(" +proj=longlat +ellps=WGS84 +datum=WGS84
> +no_defs +towgs84=0,0,0")
> extent(b) <- c(-180, 180, -55.15200043, 75.02400208)
>
> library(maptools
> data(wrld_simpl)
> plot(b, addfun = function() plot(wrld_simpl, add = TRUE))
>
> That looks ok to me, I don't know if it's WGS84 or the sphere or
> something else.
>
> Cheers, Mike.
>
>
>
>
>
> system(sprintf("gdalinfo %s", f))
>
> Driver: HDF4/Hierarchical Data Format Release 4
> Files: VHP.G16.C07.NC.P1981035.ND.hdf
> Size is 512, 512
> Coordinate System is `'
> Metadata:
>   ANCILLARY_FILES=FILE_CONFIGURE:vh.config
> FILE_PRELAUNCH_CALIBRATION:../ancillary/AVHRR_calibration_prelaunch.txt
> FILE_POSTLAUNCH_CALIBRATION:../ancillary/AVHRR_calibration_postlaunch.txt
> FILE_IGBP_LANDTYPE:../ancillary/igbp_landtype_GVIx.hdf
> FILE_METADATA_REGIONS:../ancillary/regions_for_metadata.txt
> FILE_EDF_NDVI:../ancillary/NVI_counts_ByLine_G04.hdf
> FILE_EDF_BT4:../ancillary/BT4_counts_ByLine_G04.hdf
>
>   CITATION_TO_DOCUMENTS=User Guide of Vegetation Health(VH) system
> (version 1.3, March 21 2012)
>   CONFIGURE_FILE_CONTENT=[Options for vh.exe]
> DIR_Ancillary=                 ../ancillary
> DIR_GVI=                       data/VH_unitTest1/weekly
> DIR_VH=                        data/VH_unitTest1/G04
> DIR_VH_META=                   data/VH_unitTest1/G04/meta
> DIR_CLIMAT=                    data/VH_EDF_v2/climate_G04
> DIR_CLIMAT_META=               data/VH_EDF_v2/climate_G04/meta
> FILE_PREFIX=       VHP
> Input_Data_Type=       VHP
> ResolutionString=              G04
> Days_Per_Period=               7
> FilterSize=                    15
> applyEDFonNDVI=                1     # 0: none, 1: linebyline for NVI;
> applyEDFonBT=                  1
> Instrument=                    AVHRR # so far AVHRR is the only option
> FORMAT_GVI=                   NETCDF #or HDF4
> FORMAT_CLIMAT=                HDF4
> FORMAT_ND=                    NETCDF
> FORMAT_SM=                    NETCDF
> FORMAT_VH=                    NETCDF
>
> [Periods of GVI data used for VH]
> # this section control which satellite will be used for calculating
> ND, SM and VH
> #satID satNumber yearWeek1 yearWeek2
> NC 07 198135 198449
> NF 09 198509 198844
> NH 11 198846 199436
> NJ 14 199504 200052
> NL 16 200101 200401
> NL 16 200405 200410
> NL 16 200425 200428
> NL 16 200430 200523
> NN 18 200524 201052
> NP 19 201101 399999
>
> [Periods of AVHRR data used for GVI climatology]
> #this section controls which satellite will be used for creating VH
> climatology
> #satID satNumber yearWeek1 yearWeek2
> NC 07 198142 198450
> NF 09 198515 198752
> NH 11 198920 199252
> NJ 14 199520 199952
> NL 16 200120 200252
>
> [END]
>
>
>   CONTACT=NOAA/NESDIS/STAR/EMB
>   DATE_BEGIN=239
>   DATE_END=245
>   DAYS_PER_PERIOD=7
>   END_LATITUDE_RANGE=-55.15200043
>   END_LONGITUDE_RANGE=180
>   INPUT_FILENAMES=data/VH_unitTest1/weekly/
> VHP.G04.C07.NC.P1981035.S239.E245.nc
>
>   INPUT_FILES=1
>   INSTRUMENT=AVHRR
>   PERIOD_OF_YEAR=35
>   PRODUCT_NAME=Vegetation Health
>   PROJECTION=Plate_Carree
>   SATELLITE=NC
>   START_LATITUDE_RANGE=75.02400208
>   START_LONGITUDE_RANGE=-180
>   TIME_BEGIN=00:00 UTC (use day time data only)
>   TIME_END=23:59 UTC (use day time data only)
>   VERSION=VH (vh.exe,version 1.3, March 21 2012)
>   YEAR=1981
> Subdatasets:
>   SUBDATASET_1_NAME=HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":0
>   SUBDATASET_1_DESC=[904x2500] BT4 (16-bit integer)
>   SUBDATASET_2_NAME=HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":1
>   SUBDATASET_2_DESC=[904x2500] NDVI (16-bit integer)
>   SUBDATASET_3_NAME=HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":2
>   SUBDATASET_3_DESC=[904x2500] QA (8-bit unsigned integer)
> Corner Coordinates:
> Upper Left  (    0.0,    0.0)
> Lower Left  (    0.0,  512.0)
> Upper Right (  512.0,    0.0)
> Lower Right (  512.0,  512.0)
> Center      (  256.0,  256.0)
>
> On Thu, Aug 14, 2014 at 10:27 AM, Arnold Salvacion
> <arnold_salvacion at yahoo.com> wrote:
> > Dear Colleagues,
> >
> > Does any here have already experience converting NOAA AVHRR VHP Product
> in .hdf (
> ftp://ftp.star.nesdis.noaa.gov/pub/corp/scsb/wguo/data/VHP_16km/VH/ )
> format to a raster layer in R?
> >
> >
> > Best regards,
> >
> > Arnold
> >         [[alternative HTML version deleted]]
> >
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
>
>
> --
> Michael Sumner
> Software and Database Engineer
> Australian Antarctic Division
> Hobart, Australia
> e-mail: mdsumner at gmail.com
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
Ahmadou H. DICKO
statistician economist (Ing?nieur Statisticien ?conomiste)
PhD candidate in Climate change economics
Faculty of economics and managment - Cheikh Anta Diop University
West African Science Service Center on Climate Change and Adaptated Land
Use (WASCAL)
Center for Development Research (ZEF) - University of Bonn
email : ahmadou.dicko at ucad.edu.sn
twitter : @dickoah
github : github/dickoa <https://github.com/dickoa>
tel : +221 33 827 55 16
portable: +221 77 123 81 69

	[[alternative HTML version deleted]]


From smiledongwook at gmail.com  Thu Aug 14 20:37:16 2014
From: smiledongwook at gmail.com (nahm)
Date: Thu, 14 Aug 2014 11:37:16 -0700 (PDT)
Subject: [R-sig-Geo] Levelplot(RasterVis) two marginal plot scale?
In-Reply-To: <1407859787783-7586928.post@n2.nabble.com>
References: <1407859787783-7586928.post@n2.nabble.com>
Message-ID: <1408041436493-7586942.post@n2.nabble.com>

marginal plot in a levelplot gives very nice row and clo. mean value profile
on a top and right side.
How can I add two little scales top/right to marginal plot?

here is my codes.

Thanks,

Nahm

RAD1998.all <- stack(list.ras)

list.files <- mixedsort(list.files(paste(getwd(), "/1998bil/", sep = ""),
full.names = F, pattern = ".asc.bil"))
#list.files

outlist <- substr(list.files, 31, 43)
#outlist

png(paste("1998",outlist[[1]],".png",sep=""))
levelplot(RAD1998.all[[1]])
dev.off() 



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Levelplot-RasterVis-two-marginal-plot-scale-tp7586928p7586942.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From kristin.graves at gmail.com  Sat Aug 16 21:08:50 2014
From: kristin.graves at gmail.com (Kristin Graves)
Date: Sat, 16 Aug 2014 15:08:50 -0400
Subject: [R-sig-Geo] spatstat inverse-distance-weighted plot - change the
	axis range
Message-ID: <CABQqjO+LEfFbHpJ2T1Di5C0LMzAfVO_uo-fe69gipqVjsjJh6g@mail.gmail.com>

Hello --

I am pretty new to R and to spatstat, so apologize for any ignorance.

I have a dataset with three variables:  x, y, and avgidw where x and y are
UTM coordinates and avgidw is a numeric mask of type "double".  My x range
is (585000,610000) and my y range is (4473000,4523000).

My end goal is to create an IDW plot that limits the plot to the (x,y)
range.  I am able to obtain the plot, but the y-axis origin is zero, not
4473000 as desired.  My code is below.

> library(spatstat)

spatstat 1.38-0       (nickname: ?Wicked Plot?)
For an introduction to spatstat, type ?beginner?
Warning message:
package ?spatstat? was built under R version 3.1.1
> idw_df <- read.table(idw_input, header=TRUE)
> attach(idw_df)
> idw_pp <- ppp(x, y, c(585000,610000), c(4473000,4523000), marks=avgidw)
> idw_win <- owin(c(585000,610000), c(4473000,4523000))
> idw_chop <- idw_pp[idw_win]
> x=585000:610000
> y=4473000:4523000
> idw_mask <- as.mask(idw_win,xy=list(x=x, y=y))
> idw_pix2 <- idw(idw_chop, power=2, at="pixels", idw_mask)
Error in ensure2vector(eps) : eps is not numeric
>


On the other hand, if I run this code I do obtain a plot (albeit with the
wrong axes):
> idw_pix2 <- idw(idw_chop, power=2, at="pixels")
> plot(idw_pix2)


Thanks in advance for any help you can provide!
Kristin Graves

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Sun Aug 17 03:13:10 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 17 Aug 2014 13:13:10 +1200
Subject: [R-sig-Geo] spatstat inverse-distance-weighted plot - change
 the axis range
In-Reply-To: <CABQqjO+LEfFbHpJ2T1Di5C0LMzAfVO_uo-fe69gipqVjsjJh6g@mail.gmail.com>
References: <CABQqjO+LEfFbHpJ2T1Di5C0LMzAfVO_uo-fe69gipqVjsjJh6g@mail.gmail.com>
Message-ID: <53F001A6.7030206@auckland.ac.nz>

On 17/08/14 07:08, Kristin Graves wrote:
> Hello --
>
> I am pretty new to R and to spatstat, so apologize for any ignorance.
>
> I have a dataset with three variables:  x, y, and avgidw where x and y are
> UTM coordinates and avgidw is a numeric mask of type "double".  My x range
> is (585000,610000) and my y range is (4473000,4523000).
>
> My end goal is to create an IDW plot that limits the plot to the (x,y)
> range.  I am able to obtain the plot, but the y-axis origin is zero, not
> 4473000 as desired.  My code is below.
>
>> library(spatstat)
>
> spatstat 1.38-0       (nickname: ?Wicked Plot?)
> For an introduction to spatstat, type ?beginner?
> Warning message:
> package ?spatstat? was built under R version 3.1.1
>> idw_df <- read.table(idw_input, header=TRUE)
>> attach(idw_df)
>> idw_pp <- ppp(x, y, c(585000,610000), c(4473000,4523000), marks=avgidw)
>> idw_win <- owin(c(585000,610000), c(4473000,4523000))
>> idw_chop <- idw_pp[idw_win]
>> x=585000:610000
>> y=4473000:4523000
>> idw_mask <- as.mask(idw_win,xy=list(x=x, y=y))
>> idw_pix2 <- idw(idw_chop, power=2, at="pixels", idw_mask)
> Error in ensure2vector(eps) : eps is not numeric
>>
>
>
> On the other hand, if I run this code I do obtain a plot (albeit with the
> wrong axes):
>> idw_pix2 <- idw(idw_chop, power=2, at="pixels")
>> plot(idw_pix2)
>
>
> Thanks in advance for any help you can provide!

Basically the problem arises from supply "idw_mask" as the final 
argument to idw().  The help for idw() (clearly!) states:

> ... Arguments passed to as.mask to control the pixel resolution of the result.


That is, you don't pass a mask as a "..." argument, you pass arguments 
that are needed by as.mask(), e.g. "dimyx" or "eps".  RTFM.

A few other comments:

(1) What do you think you are accomplishing by:

>>> idw_win <- owin(c(585000,610000), c(4473000,4523000))
>>> idw_chop <- idw_pp[idw_win]

???

You are not chopping anything.  The window "idw_win" already is the 
window of idw_pp, as you specified in the call to ppp() which created
idw_pp.  Thus idw_chop and idw_pp will be identical.

(2) Your pixellation for idw_mask is 25000 x 50000 which is 
***ridiculously*** fine.  I cannot imagine why you would want such a
fine pixellation.

(3) What do you mean by "with the wrong axes" in your last comment?  The 
*axes* won't change with the fineness of the pixellation. Your assertion

> but the y-axis origin is zero, not 4473000

is simply nonsense.  And incorrect too!  Where on earth did you get the 
idea the y-axis origin of your image was 0?

(4) If you want a finer pixellation, then pass dimyx or eps to idw() as 
the "..." argument.  E.g.

     idw_pix2 <- idw(idw_chop, power=2, at="pixels", dimyx=c(500,250))

or
     idw_pix2 <- idw(idw_chop, power=2, at="pixels", eps=100)

or (probably better)

     idw_pix2 <- idw(idw_chop, power=2, at="pixels", dimyx=c(512,256))  .

(5) Using huge numbers in your coordinates (order of hundreds of 
thousands) as you do is fraught with peril.  There can be numerical 
issues, the output is hard to read, and it's easy to get zeroes out of 
sync.  I suggest that you rescale your point pattern by a factor of 
1000.  Either:

     idw_df$x <- idw_df$x/1000
     idw_df$y <- idw_df$y/1000

before you form idw_pp, or

     idw_pp <- rescale(idw_pp,1000)

after you have formed idw_pp from the original idw_df.

(6) It is inadvisable to use attach(); all sorts of confusion can 
result.  Use with() instead:

     idw_pp <- with(idw_df,ppp(...))

(7) Saying `avgidw is a numeric mask of type "double"' is just plain 
bafflegab.  It (i.e. avgidw) is a numeric variate.  There is no "mask" 
involved and all real variates are stored to double precision in R.

cheers,

Rolf Turner


-- 
Rolf Turner
Technical Editor ANZJS


From kristin.graves at gmail.com  Sun Aug 17 19:23:48 2014
From: kristin.graves at gmail.com (Kristin Graves)
Date: Sun, 17 Aug 2014 13:23:48 -0400
Subject: [R-sig-Geo] spatstat inverse-distance-weighted plot - change
 the axis range
In-Reply-To: <53F001A6.7030206@auckland.ac.nz>
References: <CABQqjO+LEfFbHpJ2T1Di5C0LMzAfVO_uo-fe69gipqVjsjJh6g@mail.gmail.com>
	<53F001A6.7030206@auckland.ac.nz>
Message-ID: <CABQqjO+iOYgYMX5r3G8VKHQ3a_OqoreR27f8D26ntFjoWjvTuw@mail.gmail.com>

Rolf --

Thanks for your help!  As I mentioned, I am new to R and spatstat.  But
your detailed response helped me figure out what I was doing wrong.

Kristin

	[[alternative HTML version deleted]]


From fgarciapapani at gmail.com  Tue Aug 19 15:29:30 2014
From: fgarciapapani at gmail.com (Fabiana garcia papani)
Date: Tue, 19 Aug 2014 10:29:30 -0300
Subject: [R-sig-Geo] Fwd: Cut map
In-Reply-To: <CAG5cAq+zRzOUKjc-ZZSFCKKQaj9UWXf3xo392L9Xsz1Li=m8NQ@mail.gmail.com>
References: <CAG5cAq+zRzOUKjc-ZZSFCKKQaj9UWXf3xo392L9Xsz1Li=m8NQ@mail.gmail.com>
Message-ID: <CAG5cAqLFrXf=Hz5EvnYEn_SmcUWsGM4_Wvmz-KOcfRUTtysnww@mail.gmail.com>

---------- Forwarded message ----------
From: Fabiana garcia papani <fgarciapapani at gmail.com>
Date: 2014-08-19 10:23 GMT-03:00
Subject: Cut map
To: r-sig-geo at r-project.org


I have a regular grid of points. I have a border. How to determine only the
points inside  the border?

	[[alternative HTML version deleted]]


From edzer.pebesma at uni-muenster.de  Tue Aug 19 15:55:26 2014
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 19 Aug 2014 15:55:26 +0200
Subject: [R-sig-Geo] Fwd: Cut map
In-Reply-To: <CAG5cAqLFrXf=Hz5EvnYEn_SmcUWsGM4_Wvmz-KOcfRUTtysnww@mail.gmail.com>
References: <CAG5cAq+zRzOUKjc-ZZSFCKKQaj9UWXf3xo392L9Xsz1Li=m8NQ@mail.gmail.com>
	<CAG5cAqLFrXf=Hz5EvnYEn_SmcUWsGM4_Wvmz-KOcfRUTtysnww@mail.gmail.com>
Message-ID: <53F3574E.70009@uni-muenster.de>



On 08/19/2014 03:29 PM, Fabiana garcia papani wrote:
> ---------- Forwarded message ----------
> From: Fabiana garcia papani <fgarciapapani at gmail.com>
> Date: 2014-08-19 10:23 GMT-03:00
> Subject: Cut map
> To: r-sig-geo at r-project.org
> 
> 
> I have a regular grid of points. I have a border. How to determine only the
> points inside  the border?

# assuming points is SpatialPoints and border is SpatialPolygons, then

# Determine which points:

require(sp)
which(!is.na(over(points, border)))

# Select them:

points[border,]


> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Heisenbergstra?e 2, 48149 M?nster, Germany. Phone: +49 251
83 33081 http://ifgi.uni-muenster.de GPG key ID 0xAC227795

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140819/82a2fe67/attachment.bin>

From luis.miguel.royo at gmail.com  Tue Aug 19 15:59:15 2014
From: luis.miguel.royo at gmail.com (=?windows-1252?Q?Luis_Miguel_Royo_P=E9rez?=)
Date: Tue, 19 Aug 2014 15:59:15 +0200
Subject: [R-sig-Geo] Fwd: Cut map
In-Reply-To: <CAG5cAqLFrXf=Hz5EvnYEn_SmcUWsGM4_Wvmz-KOcfRUTtysnww@mail.gmail.com>
References: <CAG5cAq+zRzOUKjc-ZZSFCKKQaj9UWXf3xo392L9Xsz1Li=m8NQ@mail.gmail.com>
	<CAG5cAqLFrXf=Hz5EvnYEn_SmcUWsGM4_Wvmz-KOcfRUTtysnww@mail.gmail.com>
Message-ID: <53F35833.70300@gmail.com>

Hi Fabiana,

_1st. Option:_
I would convert the border in a polygon and then I would cut the points 
with this layer.

_2nd. Option:_
You can add polygons attributes to points with the SAGA algorithm 
avaible in the processor: "Add polygon attributes to points", and then 
select only the points wich have the attribute that you want.

I hope it helps.


El 19/08/14 a las #4, Fabiana garcia papani escribi?:
> ---------- Forwarded message ----------
> From: Fabiana garcia papani <fgarciapapani at gmail.com>
> Date: 2014-08-19 10:23 GMT-03:00
> Subject: Cut map
> To: r-sig-geo at r-project.org
>
>
> I have a regular grid of points. I have a border. How to determine only the
> points inside  the border?
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


	[[alternative HTML version deleted]]


From dmarvin at carnegiescience.edu  Tue Aug 19 19:21:50 2014
From: dmarvin at carnegiescience.edu (Dave Marvin)
Date: Tue, 19 Aug 2014 10:21:50 -0700
Subject: [R-sig-Geo] Using 'raster' package functions with rasterEngine
In-Reply-To: <CABG0rfuTFwkKVPq4V47apbV46doY4uZ4OLmaXttqvcQ0JxgH_A@mail.gmail.com>
References: <CAC4xYR5uqrSbXtjHFCPLkqBU0D3umxt8WF5YCoFa-s5v8OiuKg@mail.gmail.com>
	<CABG0rfuTFwkKVPq4V47apbV46doY4uZ4OLmaXttqvcQ0JxgH_A@mail.gmail.com>
Message-ID: <CAC4xYR5-PcYrFNCQBg4SC0+QbzYdaS8d_s1SQFhFZt41etCBQQ@mail.gmail.com>

Thank you for the comments Jonathan. I coerced the output from my
function to an array, and that got it working. As you said the
dimensions need to be ordered as (col, row). However, as you will see,
there is an issue with the output in parallel mode:

test_input=raster(system.file("external/tahoe_lidar_highesthit.tif",
package="spatial.tools"))
test_input=test_input>2535 #create distinct tree canopy objects.
plot(test_input)

clump_fun=function(raster_layer,...){
     clump_raster=clump(raster_layer,directions=8)
     clump_array=array(getValues(clump_raster),dim=c(dim(raster_layer)[c(2:1)],1))
     return(clump_array)
}

cpus=3
cl=makeCluster(spec = cpus, type = "PSOCK", methods = FALSE)
registerDoParallel(cl)

test_raster_out_a=rasterEngine(raster_layer=test_input,fun=clump_fun,chunk_format="raster",debugmode=FALSE)

stopCluster(cl)

**While this gives me an output, it is quite different from running
the same function in either sequential mode or outside rasterEngine
entirely:

registerDoSEQ()
test_raster_out_b=rasterEngine(raster_layer=test_input,fun=clump_fun,chunk_format="raster",debugmode=FALSE)
test_raster_out_c=clump(test_input,directions=8)

dim(freq(test_raster_out_a)$layer) #parallel output
dim(freq(test_raster_out_b)$layer) #sequential mode output
dim(freq(test_raster_out_c)) #non-rasterEngine output (same as "b")

In fact, the number of clumps varies depending on the number of cores
I use in parallel mode. Any idea what is happening here?

Thank you,
-Dave

----
Dave Marvin | davidcmarvin.org
Postdoctoral Research Fellow
Department of Global Ecology
Carnegie Institution for Science


On Mon, Aug 11, 2014 at 8:55 AM, Jonathan Greenberg <jgrn at illinois.edu> wrote:
> Hi Dave:
>
> If you can provide some code examples that would be easier, but I can give
> you a couple of hints.  First, use debugmode=TRUE when you are testing your
> function -- this will save you a lot of headaches down the line.  R will
> enter its debugmode inside of the rasterEngine function so you can track
> what is happening.
>
> The first issue is that clump only works on raster objects.  rasterEngine,
> in its default mode, sends "chunks" of the image to your function formatted
> as *arrays*, not raster objects.  When you did chunk_format to raster, it
> did, indeed, send the chunk as a small, cropped raster so clump worked, BUT:
> all *outputs* from rasterEngine (at present) MUST be coerced to an array
> that has the same number of columns and rows as the input (in that order).
> I might mod this down the road to allow raster outputs, but for now you'll
> need to make sure the output is of type array.  I suspect you are trying to
> return the chunk from your function as a raster, which is why it isn't
> working.
>
> Again: debugmode=TRUE, and track your function down to just before your
> return the output -- check the type of the to-be-returned object and confirm
> it is an array with dim()[1:2] equal to the input raster.
>
> Good luck!
>
> --j
>
>
> On Thu, Aug 7, 2014 at 12:02 PM, Dave Marvin <dmarvin at carnegiescience.edu>
> wrote:
>>
>> Hi,
>> I am able to set up functions and apply them to a raster dataset in
>> parallel using the rasterEngine function of the spatial.tools package, but
>> only if the function performs just a numerical operation on the raster.
>> When I try to incorporate a function from the raster package, such as
>> clump(), the rasterEngine fails and I get an error:
>>
>> > Error in (function (classes, fdef, mtable): unable to find an inherited
>> method for function ?clump? for signature ?"array"?
>>
>> If I change "chunk_format" to "raster" in the rasterEngine function, then
>> i
>> get an error:
>>
>> > chunk processing units require array vector outputs.  Please check your
>> function.
>>
>> 1) Am I doing doing something wrong, or does this particular function just
>> not work with rasterEngine?
>>
>> 2) If it is the latter, which of the raster package functions are
>> available
>> for use in parallel processing with rasterEngine?
>>
>> Thank you.
>> -Dave
>>
>>         [[alternative HTML version deleted]]
>>
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>
>
> --
> Jonathan A. Greenberg, PhD
> Assistant Professor
> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
> Department of Geography and Geographic Information Science
> University of Illinois at Urbana-Champaign
> 259 Computing Applications Building, MC-150
> 605 East Springfield Avenue
> Champaign, IL  61820-6371
> Phone: 217-300-1924
> http://www.geog.illinois.edu/~jgrn/
> AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007


From Dave.Chagaris at MyFWC.com  Tue Aug 19 21:42:41 2014
From: Dave.Chagaris at MyFWC.com (Chagaris, Dave)
Date: Tue, 19 Aug 2014 15:42:41 -0400
Subject: [R-sig-Geo] raster brick error cells are not equally spaced
In-Reply-To: <CAAcGz98LAkOQSX78b2JpiaJjaP_i7nBb=sBjwmeVff5gS8eA_w@mail.gmail.com>
References: <2F09C501769D914983129DD4812457203623AA424F@FWC-TLEX10.fwc.state.fl.us>
	<CAAcGz9_N4LSMxTRrAmRZwGzWNwHiegmx49k0rQ4s3f+s0cHE=w@mail.gmail.com>
	<2F09C501769D914983129DD4812457203623AA456F@FWC-TLEX10.fwc.state.fl.us>
	<CAAcGz98LAkOQSX78b2JpiaJjaP_i7nBb=sBjwmeVff5gS8eA_w@mail.gmail.com>
Message-ID: <2F09C501769D914983129DD4812457203623B3FCBA@FWC-TLEX10.fwc.state.fl.us>

Thanks Mike.  That appears to be the problem.  I was able to install all the libraries from my laptop onto the workstation and the code now works on both machines (with older version of raster). 

Dave 

-----Original Message-----
From: Michael Sumner [mailto:mdsumner at gmail.com] 
Sent: Thursday, August 14, 2014 10:19 AM
To: Chagaris, Dave
Subject: Re: [R-sig-Geo] raster brick error cells are not equally spaced

On Thu, Aug 14, 2014 at 11:58 PM, Chagaris, Dave <Dave.Chagaris at myfwc.com> wrote:
> [deleted].  Any reason why it would work on one computer and not on the other?  Is it possible I don't have all the required packages (or wrong versions) on the workstation?
>

Only if you had a more recent version of raster on one computer that predated checks for these irregular axes.

(Please use the list in public).

Cheers, Mike.

>
>
> -----Original Message-----
> From: Michael Sumner [mailto:mdsumner at gmail.com]
> Sent: Wednesday, August 13, 2014 8:59 PM
> To: Chagaris, Dave
> Cc: r-sig-geo at r-project.org
> Subject: Re: [R-sig-Geo] raster brick error cells are not equally 
> spaced
>
> Hello, can you point to or share one of the files? Sometimes these things are just a regular grid under the hood but that has been forgotten in favour of longitude/latitude arrays.
>
> If that's the case you can reconstruct the original grid and all is well, there's not really any precedent for this but I have a lot of examples that work well.  (Also sometimes there's only a small amount of numeric fuzz that you can ignore).
>
> The raster types cannot take grids that have irregular (rectilinear or
> curvilinear) coordinates. There's no way around this except some combination of these:
>
> - read the data in the raw using ncdf/ncdf4 or RNetCDF and use base 
> graphics with image() (which can deal with rectilinear grids), or
> points() or maybe polygons (which with care can  deal with curvilinear grids).
> - use the hidden argument "stopIfNotEqualSpaced=FALSE" to raster() to 
> get the data out and deal with the arrays as "index-only" grids
>
>
> Cheers, Mike.
>
>
>
> On Thu, Aug 14, 2014 at 2:26 AM, Chagaris, Dave <Dave.Chagaris at myfwc.com> wrote:
>> I am trying to read netcdf files into R using the brick function.  I have many netcdf files and want to process them on a 64bit workstation instead my 32bit laptop.  The code    I'm using works fine on my 32 bit laptop, but on the workstation I get an error "Error in .rasterObjectFromCDF(x, type = objecttype, band = band, ...) :
>>   cells are not equally spaced; you should extract values as points".
>>
>> Any  help is appreciated.
>>
>> On Laptop...
>>> library(raster)
>>
>>> library(ncdf)
>>
>>> windows(record=T)
>>
>>> sessionInfo()
>> R version 2.15.0 (2012-03-30)
>> Platform: i386-pc-mingw32/i386 (32-bit)
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252    LC_MONETARY=English_United States.1252 LC_NUMERIC=C
>> [5] LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] grDevices datasets  splines   graphics  stats     tcltk     utils     methods   base
>>
>> other attached packages:
>> [1] ncdf_1.6.6       raster_2.0-41    sp_1.0-11        svSocket_0.9-53  TinnR_1.0-5      R2HTML_2.2       Hmisc_3.9-3      survival_2.36-12
>>
>> loaded via a namespace (and not attached):
>> [1] cluster_1.14.2 grid_2.15.0    lattice_0.20-6 svMisc_0.9-65  tools_2.15.0
>>
>>> i = "expt_31.0_20130226.nc"
>>
>>> open.ncdf(paste(getwd(),i,sep='/'))
>> [1] "file C:/dave.chagaris/HYCOM/expt_31.0_20130226.nc has 4 dimensions:"
>> [1] "MT   Size: 1"
>> [1] "Depth   Size: 40"
>> [1] "Latitude   Size: 213"
>> [1] "Longitude   Size: 290"
>> [1] "------------------------"
>> [1] "file C:/dave.chagaris/HYCOM/expt_31.0_20130226.nc has 8 variables:"
>> [1] "float ssh[Longitude,Latitude,MT]  Longname: sea surf. height  [31.0H] Missval:1.26765060022823e+30"
>> [1] "float u[Longitude,Latitude,Depth,MT]  Longname: u-veloc. [31.0H] Missval:1.26765060022823e+30"
>> [1] "float v[Longitude,Latitude,Depth,MT]  Longname: v-veloc. [31.0H] Missval:1.26765060022823e+30"
>> [1] "float w_velocity[Longitude,Latitude,Depth,MT]  Longname: w-veloc. [31.0H] Missval:1.26765060022823e+30"
>> [1] "float temperature[Longitude,Latitude,Depth,MT]  Longname:  temp [31.0H] Missval:1.26765060022823e+30"
>> [1] "float salinity[Longitude,Latitude,Depth,MT]  Longname: salinity [31.0H] Missval:1.26765060022823e+30"
>> [1] "float mld[Longitude,Latitude,MT]  Longname: MLT (0.20 degC)   [31.0H] Missval:1.26765060022823e+30"
>> [1] "float mlp[Longitude,Latitude,MT]  Longname: MLT (0.03 kg/m3)  [31.0H] Missval:1.26765060022823e+30"
>>
>>> salt =
>>> brick(paste(getwd(),i,sep='/'),varname='salinity',lvar=4,level=2)
>> Warning messages:
>> 1: In rm(.SavedPlots) : object '.SavedPlots' not found
>> 2: In .rasterObjectFromCDF(x, type = objecttype, band = band, ...) :
>>   level set to: 1
>>
>> on workstation...
>>
>>> setwd('E:\\work\\data\\HYCOM')
>>
>>> .libPaths('C:\\Users\\dave.chagaris\\Documents\\R\\win-library\\3.1'
>>> )
>>
>>> library(raster)
>>
>>> library(ncdf)
>>
>>> sessionInfo()
>>
>> R version 2.15.1 (2012-06-22)
>>
>> Platform: x86_64-pc-mingw32/x64 (64-bit)
>>
>>
>>
>> locale:
>>
>> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
>> States.1252
>>
>> [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
>>
>> [5] LC_TIME=English_United States.1252
>>
>>
>>
>> attached base packages:
>>
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>>
>>
>> other attached packages:
>>
>> [1] ncdf_1.6.6    raster_2.2-31 sp_1.0-15
>>
>>
>>
>> loaded via a namespace (and not attached):
>>
>> [1] grid_2.15.1    lattice_0.20-6 tools_2.15.1
>>
>>> i = "expt_31.0_20130226.nc"
>>
>>> open.ncdf(paste(getwd(),i,sep='/'))
>>
>> [1] "file E:/work/data/HYCOM/expt_31.0_20130226.nc has 4 dimensions:"
>>
>> [1] "MT   Size: 1"
>>
>> [1] "Depth   Size: 40"
>>
>> [1] "Latitude   Size: 213"
>>
>> [1] "Longitude   Size: 290"
>>
>> [1] "------------------------"
>>
>> [1] "file E:/work/data/HYCOM/expt_31.0_20130226.nc has 8 variables:"
>>
>> [1] "float ssh[Longitude,Latitude,MT]  Longname: sea surf. height  [31.0H] Missval:1.26765060022823e+30"
>>
>> [1] "float u[Longitude,Latitude,Depth,MT]  Longname: u-veloc. [31.0H] Missval:1.26765060022823e+30"
>>
>> [1] "float v[Longitude,Latitude,Depth,MT]  Longname: v-veloc. [31.0H] Missval:1.26765060022823e+30"
>>
>> [1] "float w_velocity[Longitude,Latitude,Depth,MT]  Longname: w-veloc. [31.0H] Missval:1.26765060022823e+30"
>>
>> [1] "float temperature[Longitude,Latitude,Depth,MT]  Longname:  temp [31.0H] Missval:1.26765060022823e+30"
>>
>> [1] "float salinity[Longitude,Latitude,Depth,MT]  Longname: salinity [31.0H] Missval:1.26765060022823e+30"
>>
>> [1] "float mld[Longitude,Latitude,MT]  Longname: MLT (0.20 degC)   [31.0H] Missval:1.26765060022823e+30"
>>
>> [1] "float mlp[Longitude,Latitude,MT]  Longname: MLT (0.03 kg/m3)  [31.0H] Missval:1.26765060022823e+30"
>>
>>> salt =
>>> brick(paste(getwd(),i,sep='/'),varname='salinity',lvar=4,level=2)
>>
>> Error in .rasterObjectFromCDF(x, type = objecttype, band = band, ...) :
>>
>>   cells are not equally spaced; you should extract values as points
>>
>> In addition: Warning message:
>>
>> In .rasterObjectFromCDF(x, type = objecttype, band = band, ...) :
>>
>>   level set to: 1
>>
>>
>>
>> David Chagaris, PhD
>> Associate Research Scientist
>> Florida Fish and Wildlife Conservation Commission Fish and Wildlife 
>> Research Institute
>> 100 8th Ave SE
>> St. Petersburg, FL  33701
>> 727-502-4959
>> fax: 727-893-1374
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>
> --
> Michael Sumner
> Software and Database Engineer
> Australian Antarctic Division
> Hobart, Australia
> e-mail: mdsumner at gmail.com



--
Michael Sumner
Software and Database Engineer
Australian Antarctic Division
Hobart, Australia
e-mail: mdsumner at gmail.com

From trichter at uni-bremen.de  Wed Aug 20 17:58:07 2014
From: trichter at uni-bremen.de (Tim Richter-Heitmann)
Date: Wed, 20 Aug 2014 17:58:07 +0200
Subject: [R-sig-Geo] Beginner's question on choosing the correct test
Message-ID: <53F4C58F.5000506@uni-bremen.de>

Hi there,

i am new to the spatial statistics, so please bear with me.

My dataset consists of 60 plots, semi-randomly distributed on a 10x6m 
area. We measured species data on  6 sampling dates, so i ended up with 
six different sample by species matrices.
My first task should be to evaluate the spatial autocorrelation for each 
of the species we have found. I am also going to do variogramming and 
kriging based on the moran I results (is that a feasible approach? or 
are correlograms and variograms redundant? - i would like to have a 
single number to decide if each of my species is SACed or not).

I got very basic R code running from the spdep package:

#my species data
data <- read.table("species.txt", header = TRUE, sep = "\t", dec = ".")
#x,y coordinates
apr.D <- read.table("xy_april.txt", row.names=1, header = TRUE, sep = 
"\t", dec = ",")
#april only (only 59 plots!)
ap<-data[1:59,]

library(spdep)
nb <- tri2nb(apr.D)
list <- nb2listw(nb)
moran.test(ap$Ac2, list)
moran.mc(ap$Ac2, list, nsim=999)

For now, i have omitted every single option spdep is giving me. 
Everything is on default.
Do you have any suggestions that really should be done during the 
process (for example, should the neighbor list made differently?). As 
this particular species ("Ac2") is normally distributed, i end up with 
the same results for the moran statistic.
Another question would be, if all attempts of transformation fail to 
normalize a data series, can i even work with moran and variograms at 
all for this particular data series?

The problem is, i tried also another package "ape".
#create an inverse distance matrix (as suggested from some internet site)
apr.Dis <- as.matrix(dist(apr.D))
apr.Dis.Inv <- 1/as.matrix(dist(apr.D))
diag(apr.Dis.Inv) <- 0
library(ape)
Moran.I(ap$Ac2, apr.Dis.Inv)

And i get a different test statistic:

_Output spdep_

Moran's I test under randomisation

data:  ap[, 1]
weights: list

Moran I statistic standard deviate = 11.7323, p-value < 2.2e-16
alternative hypothesis: greater
sample estimates:
Moran I statistic       Expectation          Variance
        0.89241144       -0.01724138        0.00601157



_Output ape:_

$observed
[1] -0.003425159

$expected
[1] -0.01724138

$sd
[1] 0.02363168

$p.value
[1] 0.5587843



I understand that both coordinate matrices seem to be different, but as 
a beginner i have very hard times to decide what is wrong or right.
Curiously, the value for expected is the same, so i guess the calculus 
is correct, but maybe i am not aware of different approaches of the two 
packages? Either way, sdpep makes me reject the null 
(alternative=greater), so i think there is a non-random spatial process 
underlying the data. On the other hand, ape makes me accept the hull 
hypothesis of random spatial processes.

Any help on this matter is highly appreciated!

-- 
Tim Richter-Heitmann (M.Sc.)
PhD Candidate



International Max-Planck Research School for Marine Microbiology
University of Bremen
Microbial Ecophysiology Group (AG Friedrich)
FB02 - Biologie/Chemie
Leobener Stra?e (NW2 A2130)
D-28359 Bremen
Tel.: 0049(0)421 218-63062
Fax: 0049(0)421 218-63069


	[[alternative HTML version deleted]]


From gbl1 at hi.is  Wed Aug 20 18:16:49 2014
From: gbl1 at hi.is (Gilles Benjamin Leduc)
Date: Wed, 20 Aug 2014 16:16:49 +0000
Subject: [R-sig-Geo] Beginner's question on choosing the correct test
In-Reply-To: <53F4C58F.5000506@uni-bremen.de>
Message-ID: <105f-53f4ca00-135-b144fc0@142849589>

Hi, 

I read your post and I am not sure of understanding? 

What is your actual objective? What is you question? Maybe if I saw your dataset I may have a better idea? 

I just see you made a strange thing? You "Accept the null hypothesis" ? that is a bad thing to do, Null hypothesis is to be rejected, never accepted? 
Either you reject it, then there is a significatif difference, or you cannot reject it, and that does not allow you to said anything, in that case it may mean that H0 is true, or you cannot see how it is different ? Should I make you a stupid exemple to tell you case H0 cannot be rejected, but being obviously false? 
Best Regards
Benjamin 
 
 
 
Le Mercredi 20 Ao?t 2014 15:58 GMT, Tim Richter-Heitmann <trichter at uni-bremen.de> a ?crit: 
 
> Hi there,
> 
> i am new to the spatial statistics, so please bear with me.
> 
> My dataset consists of 60 plots, semi-randomly distributed on a 10x6m 
> area. We measured species data on  6 sampling dates, so i ended up with 
> six different sample by species matrices.
> My first task should be to evaluate the spatial autocorrelation for each 
> of the species we have found. I am also going to do variogramming and 
> kriging based on the moran I results (is that a feasible approach? or 
> are correlograms and variograms redundant? - i would like to have a 

> single number to decide if each of my species is SACed or not).
> 
> I got very basic R code running from the spdep package:
> 
> #my species data
> data <- read.table("species.txt", header = TRUE, sep = "\t", dec = ".")
> #x,y coordinates
> apr.D <- read.table("xy_april.txt", row.names=1, header = TRUE, sep = 
> "\t", dec = ",")
> #april only (only 59 plots!)
> ap<-data[1:59,]
> 
> library(spdep)
> nb <- tri2nb(apr.D)
> list <- nb2listw(nb)
> moran.test(ap$Ac2, list)
> moran.mc(ap$Ac2, list, nsim=999)
> 
> For now, i have omitted every single option spdep is giving me. 
> Everything is on default.
> Do you have any suggestions that really should be done during the 
> process (for example, should the neighbor list made differently?). As 
> this particular species ("Ac2") is normally distributed, i end up with 
> the same results for the moran statistic.
> Another question would be, if all attempts of transformation fail to 
> normalize a data series, can i even work with moran and variograms at 
> all for this particular data series?
> 
> The problem is, i tried also another package "ape".
> #create an inverse distance matrix (as suggested from some internet site)
> apr.Dis <- as.matrix(dist(apr.D))
> apr.Dis.Inv <- 1/as.matrix(dist(apr.D))
> diag(apr.Dis.Inv) <- 0
> library(ape)
> Moran.I(ap$Ac2, apr.Dis.Inv)
> 
> And i get a different test statistic:
> 
> _Output spdep_
> 
> Moran's I test under randomisation
> 
> data:  ap[, 1]
> weights: list
> 
> Moran I statistic standard deviate = 11.7323, p-value < 2.2e-16
> alternative hypothesis: greater
> sample estimates:
> Moran I statistic       Expectation          Variance
>         0.89241144       -0.01724138        0.00601157
> 
> 
> 
> _Output ape:_
> 
> $observed
> [1] -0.003425159
> 
> $expected
> [1] -0.01724138
> 
> $sd
> [1] 0.02363168
> 
> $p.value
> [1] 0.5587843
> 
> 
> 
> I understand that both coordinate matrices seem to be different, but as 
> a beginner i have very hard times to decide what is wrong or right.
> Curiously, the value for expected is the same, so i guess the calculus 
> is correct, but maybe i am not aware of different approaches of the two 
> packages? Either way, sdpep makes me reject the null 
> (alternative=greater), so i think there is a non-random spatial process 
> underlying the data. On the other hand, ape makes me accept the hull 
> hypothesis of random spatial processes.
> 
> Any help on this matter is highly appreciated!
> 
> -- 
> Tim Richter-Heitmann (M.Sc.)
> PhD Candidate
> 
> 
> 
> International Max-Planck Research School for Marine Microbiology
> University of Bremen
> Microbial Ecophysiology Group (AG Friedrich)
> FB02 - Biologie/Chemie
> Leobener Stra?e (NW2 A2130)
> D-28359 Bremen
> Tel.: 0049(0)421 218-63062
> Fax: 0049(0)421 218-63069
> 
> 
> 	[[alternative HTML version deleted]]
>


From Roger.Bivand at nhh.no  Wed Aug 20 22:02:16 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 20 Aug 2014 22:02:16 +0200
Subject: [R-sig-Geo] Beginner's question on choosing the correct test
In-Reply-To: <53F4C58F.5000506@uni-bremen.de>
References: <53F4C58F.5000506@uni-bremen.de>
Message-ID: <alpine.LRH.2.03.1408202122130.31901@reclus.nhh.no>

On Wed, 20 Aug 2014, Tim Richter-Heitmann wrote:

> Hi there,
>
> i am new to the spatial statistics, so please bear with me.
>
> My dataset consists of 60 plots, semi-randomly distributed on a 10x6m
> area. We measured species data on  6 sampling dates, so i ended up with
> six different sample by species matrices.
> My first task should be to evaluate the spatial autocorrelation for each
> of the species we have found. I am also going to do variogramming and
> kriging based on the moran I results (is that a feasible approach? or
> are correlograms and variograms redundant? - i would like to have a
> single number to decide if each of my species is SACed or not).
>
> I got very basic R code running from the spdep package:
>
> #my species data
> data <- read.table("species.txt", header = TRUE, sep = "\t", dec = ".")
> #x,y coordinates
> apr.D <- read.table("xy_april.txt", row.names=1, header = TRUE, sep =
> "\t", dec = ",")
> #april only (only 59 plots!)
> ap<-data[1:59,]
>
> library(spdep)
> nb <- tri2nb(apr.D)
> list <- nb2listw(nb)
> moran.test(ap$Ac2, list)
> moran.mc(ap$Ac2, list, nsim=999)
>
> For now, i have omitted every single option spdep is giving me.
> Everything is on default.
> Do you have any suggestions that really should be done during the
> process (for example, should the neighbor list made differently?). As
> this particular species ("Ac2") is normally distributed, i end up with
> the same results for the moran statistic.
> Another question would be, if all attempts of transformation fail to
> normalize a data series, can i even work with moran and variograms at
> all for this particular data series?
>
> The problem is, i tried also another package "ape".
> #create an inverse distance matrix (as suggested from some internet site)
> apr.Dis <- as.matrix(dist(apr.D))
> apr.Dis.Inv <- 1/as.matrix(dist(apr.D))
> diag(apr.Dis.Inv) <- 0
> library(ape)
> Moran.I(ap$Ac2, apr.Dis.Inv)
>
> And i get a different test statistic:
>
> _Output spdep_
>
> Moran's I test under randomisation
>
> data:  ap[, 1]
> weights: list
>
> Moran I statistic standard deviate = 11.7323, p-value < 2.2e-16
> alternative hypothesis: greater
> sample estimates:
> Moran I statistic       Expectation          Variance
>        0.89241144       -0.01724138        0.00601157
>
>
>
> _Output ape:_
>
> $observed
> [1] -0.003425159
>
> $expected
> [1] -0.01724138
>
> $sd
> [1] 0.02363168
>
> $p.value
> [1] 0.5587843
>

Using the example in the ape vignette:

body <- c(4.09434, 3.61092, 2.37024, 2.02815, -1.469)
longevity <- c(4.74493, 3.3322, 3.3673, 2.89037, 2.302)
names(body) <- names(longevity) <- c("Homo", "Pongo", "Macaca", "Ateles",
  "Gala")
library(ape)
trnwk <- "((((Homo:0.21,Pongo:0.21):0.28,Macaca:0.49):0.13,Ateles:0.6)"
trnwk[2] <- ":0.38,Galago:1.00);"
tr <- read.tree(text = trnwk)
w <- 1/cophenetic(tr)
diag(w) <- 0
unlist(Moran.I(body, w, alternative="greater"))
library(spdep)
moran.test(body, mat2listw(w, style="W"), alternative="greater",
  randomisation=TRUE)

are the same. The data set is too restricted to show the consequences of 
changing the spatial weights - as you see, the consequences are not 
infrequently large, depending on the assumed underlying spatial process. 
In one case you are using sparse graph neighbours, in the other inverse 
distances, which reflect very different choices with reference to the 
assumed underlying spatial process. In general parsimonious (sparse) 
representations are preferable to dense representations (inverse 
distances).

data(eire)
moran.test(eire.df$OWNCONS, nb2listw(eire.nb, style="W"),
  randomisation=TRUE,  alternative="greater")
unlist(Moran.I(eire.df$OWNCONS, nb2mat(eire.nb, style="B"),
  alternative="greater"))

are the same, as are:

crds <- do.call("cbind", eire.coords.utm)
tnb <- tri2nb(crds)
moran.test(eire.df$OWNCONS, nb2listw(tnb, style="W"),
  randomisation=TRUE,  alternative="greater")
unlist(Moran.I(eire.df$OWNCONS, nb2mat(tnb, style="B"),
  alternative="greater"))

and:

t(apply(crds, 2, range))
dnb <- dnearneigh(crds, 0, 350)
dnb
distnb <- nbdists(dnb, crds)
idw <- lapply(distnb, function(x) 1/x)
moran.test(eire.df$OWNCONS, nb2listw(dnb, glist=idw, style="W"),
  randomisation=TRUE,  alternative="greater")
unlist(Moran.I(eire.df$OWNCONS, nb2mat(dnb, glist=idw, style="B"),
  alternative="greater"))

are effectively the same too. However, each variant of the spatial weights 
has different results.

Hope this clarifies,

Roger

>
>
> I understand that both coordinate matrices seem to be different, but as
> a beginner i have very hard times to decide what is wrong or right.
> Curiously, the value for expected is the same, so i guess the calculus
> is correct, but maybe i am not aware of different approaches of the two
> packages? Either way, sdpep makes me reject the null
> (alternative=greater), so i think there is a non-random spatial process
> underlying the data. On the other hand, ape makes me accept the hull
> hypothesis of random spatial processes.
>
> Any help on this matter is highly appreciated!
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From pickering at penguin.kobe-u.ac.jp  Thu Aug 21 02:25:30 2014
From: pickering at penguin.kobe-u.ac.jp (Steve Pickering)
Date: Thu, 21 Aug 2014 09:25:30 +0900
Subject: [R-sig-Geo] Spatial lags using gridded data
Message-ID: <CAEdPBsGcPNazXJbV-BWxFZPARP1NGa6Vou9oKmNXiyUn3Qqm5Q@mail.gmail.com>

Hello, all,

Sorry for the silly question.

I'm struggling to apply spatial lags to a data grid.  I've been
working through the notes on Luc Anselin's spdep, but just can't
figure out how to apply it to gridded data.

Consider the following very simple 5 x 5 grid:

ids <- c(1:25)
lats <- c(30,30,30,30,30,31,31,31,31,31,32,32,32,32,32,33,33,33,33,33,34,34,34,34,34)
lngs <- c(10,11,12,13,14,10,11,12,13,14,10,11,12,13,14,10,11,12,13,14,10,11,12,13,14)
conflict <- c(0,0,0,0,0,0,0,0,1,0,0,0,1,1,0,0,1,0,0,0,0,0,0,0,0)
conflictLag <- c(0,0,0.125,0.125,0.125,0,0.125,0.375,0.25,0.25,0.125,0.25,0.375,0.25,0.25,0.125,0.125,0.375,0.25,0.125,0.125,0.125,0.125,0,0)
pop <- sample(100, 25)

newGrid = data.frame(ids, lats, lngs, conflict, conflictLag, pop)

Here, I have a conflict dummy, to determine whether there was some
sort of conflict or war in that grid cell.  I also have a population
variable (for the purposes of this exercise, determined at random).

If I wanted to run a regression on this without including spatial
lags, I could do something very simple, like this:

model1 = lm(newGrid$conflict ~ newGrid$pop)
summary(model1)

However, I know that I am supposed to include a spatial lag.  As you
can see in the code, I have also created a spatial lag variable based
on whether there was conflict in adjacent cells (Queen's move, hence a
fraction of eight).

What I'm struggling with is the correct way to include the spatial lag
in my model.

Thanks, and sorry for the simple question.

 - Steve.


From sandeep.pulla at gmail.com  Thu Aug 21 08:12:03 2014
From: sandeep.pulla at gmail.com (Sandeep Pulla)
Date: Thu, 21 Aug 2014 11:42:03 +0530
Subject: [R-sig-Geo] gstat trend beta ignored?
Message-ID: <CAPGZjC=k5fndSVfAQzODU6PODKY2Vj+yDmeqqozAB1FYGRJEoQ@mail.gmail.com>

?There appear to be couple of problems in specifying known trend
coefficients in gstat. Specifically,
1. The 'beta' parameter seems to be ignored when the 'gls' parameter is 1.
2. The 'beta' parameter is ignored by predict.gstat() (regardless of the
'gls' parameter).

Here's a full example:

library(gstat)
library(sp) # for coordinates()
library(geoR) # for grf()
n = 20 ^ 2 # number of observations
xmin = ymin = 0; xmax = ymax = 2 # rectangular domain
trend.beta = c(pi, exp(1), -exp(1)) # linear trend-surface coefficients
trend.surf = cbind(1, as.matrix(expand.grid(x = seq(xmin, xmax, len =
sqrt(n)),
  y = seq(xmin, ymax, len = sqrt(n))))) %*% trend.beta
set.seed(100)
field = grf(n, "reg", xlims = c(xmin, xmax), ylims = c(ymin, ymax),
cov.model = "mat",
  cov.pars = c(1, .1), kappa = 1, nugget = .5, mean = trend.surf)
dat = data.frame(var = field$data, field$coords, intercept = 1)
coordinates(dat) = ~ x + y
vgm.mod = vgm(1, "Mat", .5, 1)
# Trend surface predictions to retrieve beta (see demo(blue))
pred.grid = data.frame(intercept = c(1, 0, 0), x = c(0, 1, 0), y = c(0, 0,
1))
coordinates(pred.grid) = ~ x + y
# OK: Trend beta are estimated using OLS
plot(plot(variogram(gstat(NULL, "var", var ~ x + y, data = dat,
  model = vgm.mod, set = list(gls = 0))), main = "OLS"))
# OK: Predefined trend beta are used
plot(plot(variogram(gstat(NULL, "var", var ~ x + y, data = dat,
  model = vgm.mod, set = list(gls = 0), beta = c(20, 10, -10))),
  main = "OLS + predefined"))
# OK: Trend beta are estimated using GLS
plot(plot(variogram(gstat(NULL, "var", var ~ x + y, data = dat,
  model = vgm.mod, set = list(gls = 1))), main = "GLS"))
# BUG: Predefined trend beta are ignored
plot(plot(variogram(gstat(NULL, "var", var ~ x + y, data = dat,
  model = vgm.mod, set = list(gls = 1), beta = c(20, 10, -10))),
  main = "GLS + predefined"))
# BUG: Predefined trend beta are ignored
print(predict(gstat(NULL, "var", var ~ x + y + intercept - 1, data = dat,
    model = vgm.mod, set = list(gls = 1), beta = c(20, 10, -10)),
  pred.grid, BLUE = T)@data$var.pred)
# BUG: 'gls' option is ignored (uses GLS instead of OLS for trend
estimation)
print(predict(gstat(NULL, "var", var ~ x + y + intercept - 1, data = dat,
    model = vgm.mod, set = list(gls = 0)),
  pred.grid, BLUE = T)@data$var.pred)

Are these known bugs?

Thanks,
Sandeep

	[[alternative HTML version deleted]]


From arnold_salvacion at yahoo.com  Thu Aug 21 09:52:43 2014
From: arnold_salvacion at yahoo.com (Arnold Salvacion)
Date: Thu, 21 Aug 2014 15:52:43 +0800
Subject: [R-sig-Geo] Converting .hdf file to raster layer
In-Reply-To: <CAP8THHW2HDXkOqsyDeaHWqoPDoETskjSCP6wZTPtsmjK8X9vNQ@mail.gmail.com>
References: <1407976021.54447.YahooMailNeo@web192705.mail.sg3.yahoo.com>	<CAAcGz9_O7cE6bC22NBww9kRuyVoLC-Ooj21G+WP9Ata+J70G2Q@mail.gmail.com>
	<CAP8THHW2HDXkOqsyDeaHWqoPDoETskjSCP6wZTPtsmjK8X9vNQ@mail.gmail.com>
Message-ID: <1408607563.65589.YahooMailNeo@web192702.mail.sg3.yahoo.com>

Hi Ahmadou,

Have tried your code but still no success. However, I have actually tried to download the .hdf file directly from net. What I did is import the data from local folder. Below is the error that I got:

Error in .local(.Object, ...) :  `C:\Users\Owner\Documents\VHP.G16.C07.NC.P1982006.VH.hdf' not recognised as a supported file format.

Best regards,

Arnold





On Friday, August 15, 2014 2:33 AM, Ahmadou Dicko <dicko.ahmadou at gmail.com> wrote:
 


You can use the gdalUtils package to get information on datasets inside your hdf file and then stack them using the raster package

library(raster)
library(rgdal)? ## built with HDF4 support
library(gdalUtils)

fsrc <- "ftp://ftp.star.nesdis.noaa.gov/pub/corp/scsb/wguo/data/VHP_16km/VH/VHP.G16.C07.NC.P1981035.ND.hdf"
f <- file.path("/tmp", basename(fsrc))
if (!file.exists(f)) download.file(fsrc, f, mode = "wb")

info <- gdalinfo(f)
data <- grep("HDF4_SDS", info, value = TRUE)
data <- gsub("SUBDATASET_\\d+_NAME=|\\s+", "", data)


sds <- stack(data)
sds
## class?????? : RasterStack
## dimensions? : 904, 2500, 2260000, 3? (nrow, ncol, ncell, nlayers)
## resolution? : 1, 1? (x, y)
## extent????? : 0, 2500, 0, 904? (xmin, xmax, ymin, ymax)
## coord. ref. : NA
## names?????? : VHP.G16.C07.NC.P1981035.ND.1, VHP.G16.C07.NC.P1981035.ND.2, VHP.G16.C07.NC.P1981035.ND.3
## min values? :?????????????????????? -32768,?????????????????????? -32768,??????????????????????????? 0
## max values? :??????????????????????? 32767,??????????????????????? 32767,????????????????????????? 255

##You can use RasterBrick too, by doing `brick(sds)`


sessionInfo()
## R version 3.1.1 Patched (2014-08-12 r66349)
## Platform: x86_64-unknown-linux-gnu (64-bit)

## locale:
##? [1] LC_CTYPE=en_US.utf8?????? LC_NUMERIC=C
##? [3] LC_TIME=en_US.utf8??????? LC_COLLATE=en_US.utf8
##? [5] LC_MONETARY=en_US.utf8??? LC_MESSAGES=en_US.utf8
##? [7] LC_PAPER=en_US.utf8?????? LC_NAME=C
##? [9] LC_ADDRESS=C????????????? LC_TELEPHONE=C
## [11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C

## attached base packages:
## [1] stats???? graphics? grDevices utils???? datasets? methods
## [7] base

## other attached packages:
## [1] gdalUtils_0.3.2 rgdal_0.8-16??? raster_2.2-32
## [4] sp_1.0-15

## loaded via a namespace (and not attached):
##? [1] codetools_0.2-8?? compiler_3.1.1??? foreach_1.4.2
##? [4] grid_3.1.1??????? iterators_1.0.7?? lattice_0.20-29
##? [7] R.methodsS3_1.6.1 R.oo_1.18.0?????? R.utils_1.32.4
## [10] tools_3.1.1

grep("hdf4", gdalDrivers()$name, ignore.case = TRUE, value = TRUE)
## [1] "HDF4"????? "HDF4Image"





On Thu, Aug 14, 2014 at 8:52 AM, Michael Sumner <mdsumner at gmail.com> wrote:

Just had a look, the file has subdatasets and seemingly raster can't
>handle those. (I haven't explored this much but might have a chance
>to).
>
>library(raster)
>library(rgdal) ?## built with HDF4, HDF5 and NetCDF4
>
>fsrc <- "ftp://ftp.star.nesdis.noaa.gov/pub/corp/scsb/wguo/data/VHP_16km/VH/VHP.G16.C07.NC.P1981035.ND.hdf"
>f <- basename(fsrc)
>if (!file.exists(f)) download.file(fsrc, f, mode = "wb")
>
>## found with system GDAL, see below
>sds <- c('HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":0',
>? ? ? ? ?'HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":1',
>? ? ? ? ?'HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":2'
>? ? ? ? ?)
>
>##r <- brick(sds)
>##Error in GDALinfo(filename, silent = silent, returnRAT = RAT,
>returnCategoryNames = RAT) :
>?## object 'RATlist' not found
>##Error in .rasterObjectFromFile(x, band = band, objecttype = "RasterLayer", ?:
>?## ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Cannot create a RasterLayer object
>from this file.
>? ## ? ? ? ? ? ? ? ? ? ? ? ? ? ? In addition: Warning message:
>?## ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?In dim(x) : no bands in dataset
>
>
>## try with rgdal directly, so far so good but
>## no spatial-reference (again see gdalinfo output below)
>raster(readGDAL(sds[1]) ?)
>
>?raster(readGDAL(sds[1]) ?)
>HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":0 has GDAL driver HDF4Image
>and has 904 rows and 2500 columns
>class ? ? ? : RasterLayer
>dimensions ?: 904, 2500, 2260000 ?(nrow, ncol, ncell)
>resolution ?: 1, 1 ?(x, y)
>extent ? ? ?: 0, 2500, 0, 904 ?(xmin, xmax, ymin, ymax)
>coord. ref. : NA
>data source : in memory
>names ? ? ? : band1
>values ? ? ?: -99.9, 322 ?(min, max)
>
>Warning message:
>In readGDAL(sds[1]) : GeoTransform values not available
>
>
>## proceed without caution, again values from gdalinfo
>b <- brick(stack(sapply(sds, function(x) raster(readGDAL(x)))))
>proj4string(b) <- ?CRS(" +proj=longlat +ellps=WGS84 +datum=WGS84
>+no_defs +towgs84=0,0,0")
>extent(b) <- c(-180, 180, -55.15200043, 75.02400208)
>
>library(maptools
>data(wrld_simpl)
>plot(b, addfun = function() plot(wrld_simpl, add = TRUE))
>
>That looks ok to me, I don't know if it's WGS84 or the sphere or
>something else.
>
>Cheers, Mike.
>
>
>
>
>
>system(sprintf("gdalinfo %s", f))
>
>Driver: HDF4/Hierarchical Data Format Release 4
>Files: VHP.G16.C07.NC.P1981035.ND.hdf
>Size is 512, 512
>Coordinate System is `'
>Metadata:
>? ANCILLARY_FILES=FILE_CONFIGURE:vh.config
>FILE_PRELAUNCH_CALIBRATION:../ancillary/AVHRR_calibration_prelaunch.txt
>FILE_POSTLAUNCH_CALIBRATION:../ancillary/AVHRR_calibration_postlaunch.txt
>FILE_IGBP_LANDTYPE:../ancillary/igbp_landtype_GVIx.hdf
>FILE_METADATA_REGIONS:../ancillary/regions_for_metadata.txt
>FILE_EDF_NDVI:../ancillary/NVI_counts_ByLine_G04.hdf
>FILE_EDF_BT4:../ancillary/BT4_counts_ByLine_G04.hdf
>
>? CITATION_TO_DOCUMENTS=User Guide of Vegetation Health(VH) system
>(version 1.3, March 21 2012)
>? CONFIGURE_FILE_CONTENT=[Options for vh.exe]
>DIR_Ancillary= ? ? ? ? ? ? ? ? ../ancillary
>DIR_GVI= ? ? ? ? ? ? ? ? ? ? ? data/VH_unitTest1/weekly
>DIR_VH= ? ? ? ? ? ? ? ? ? ? ? ?data/VH_unitTest1/G04
>DIR_VH_META= ? ? ? ? ? ? ? ? ? data/VH_unitTest1/G04/meta
>DIR_CLIMAT= ? ? ? ? ? ? ? ? ? ?data/VH_EDF_v2/climate_G04
>DIR_CLIMAT_META= ? ? ? ? ? ? ? data/VH_EDF_v2/climate_G04/meta
>FILE_PREFIX= ? ? ? VHP
>Input_Data_Type= ? ? ? VHP
>ResolutionString= ? ? ? ? ? ? ?G04
>Days_Per_Period= ? ? ? ? ? ? ? 7
>FilterSize= ? ? ? ? ? ? ? ? ? ?15
>applyEDFonNDVI= ? ? ? ? ? ? ? ?1 ? ? # 0: none, 1: linebyline for NVI;
>applyEDFonBT= ? ? ? ? ? ? ? ? ?1
>Instrument= ? ? ? ? ? ? ? ? ? ?AVHRR # so far AVHRR is the only option
>FORMAT_GVI= ? ? ? ? ? ? ? ? ? NETCDF #or HDF4
>FORMAT_CLIMAT= ? ? ? ? ? ? ? ?HDF4
>FORMAT_ND= ? ? ? ? ? ? ? ? ? ?NETCDF
>FORMAT_SM= ? ? ? ? ? ? ? ? ? ?NETCDF
>FORMAT_VH= ? ? ? ? ? ? ? ? ? ?NETCDF
>
>[Periods of GVI data used for VH]
># this section control which satellite will be used for calculating
>ND, SM and VH
>#satID satNumber yearWeek1 yearWeek2
>NC 07 198135 198449
>NF 09 198509 198844
>NH 11 198846 199436
>NJ 14 199504 200052
>NL 16 200101 200401
>NL 16 200405 200410
>NL 16 200425 200428
>NL 16 200430 200523
>NN 18 200524 201052
>NP 19 201101 399999
>
>[Periods of AVHRR data used for GVI climatology]
>#this section controls which satellite will be used for creating VH climatology
>#satID satNumber yearWeek1 yearWeek2
>NC 07 198142 198450
>NF 09 198515 198752
>NH 11 198920 199252
>NJ 14 199520 199952
>NL 16 200120 200252
>
>[END]
>
>
>? CONTACT=NOAA/NESDIS/STAR/EMB
>? DATE_BEGIN=239
>? DATE_END=245
>? DAYS_PER_PERIOD=7
>? END_LATITUDE_RANGE=-55.15200043
>? END_LONGITUDE_RANGE=180
>? INPUT_FILENAMES=data/VH_unitTest1/weekly/VHP.G04.C07.NC.P1981035.S239.E245.nc
>
>? INPUT_FILES=1
>? INSTRUMENT=AVHRR
>? PERIOD_OF_YEAR=35
>? PRODUCT_NAME=Vegetation Health
>? PROJECTION=Plate_Carree
>? SATELLITE=NC
>? START_LATITUDE_RANGE=75.02400208
>? START_LONGITUDE_RANGE=-180
>? TIME_BEGIN=00:00 UTC (use day time data only)
>? TIME_END=23:59 UTC (use day time data only)
>? VERSION=VH (vh.exe,version 1.3, March 21 2012)
>? YEAR=1981
>Subdatasets:
>? SUBDATASET_1_NAME=HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":0
>? SUBDATASET_1_DESC=[904x2500] BT4 (16-bit integer)
>? SUBDATASET_2_NAME=HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":1
>? SUBDATASET_2_DESC=[904x2500] NDVI (16-bit integer)
>? SUBDATASET_3_NAME=HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":2
>? SUBDATASET_3_DESC=[904x2500] QA (8-bit unsigned integer)
>Corner Coordinates:
>Upper Left ?( ? ?0.0, ? ?0.0)
>Lower Left ?( ? ?0.0, ?512.0)
>Upper Right ( ?512.0, ? ?0.0)
>Lower Right ( ?512.0, ?512.0)
>Center ? ? ?( ?256.0, ?256.0)
>
>
>On Thu, Aug 14, 2014 at 10:27 AM, Arnold Salvacion
><arnold_salvacion at yahoo.com> wrote:
>> Dear Colleagues,
>>
>> Does any here have already experience converting NOAA AVHRR VHP Product in .hdf (ftp://ftp.star.nesdis.noaa.gov/pub/corp/scsb/wguo/data/VHP_16km/VH/ ) format to a raster layer in R?
>>
>>
>> Best regards,
>>
>> Arnold
>> ? ? ? ? [[alternative HTML version deleted]]
>>
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>
>
>--
>Michael Sumner
>Software and Database Engineer
>Australian Antarctic Division
>Hobart, Australia
>e-mail: mdsumner at gmail.com
>
>_______________________________________________
>R-sig-Geo mailing list
>R-sig-Geo at r-project.org
>https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


-- 

Ahmadou H. DICKO
statistician economist (Ing?nieur Statisticien ?conomiste)
PhD candidate in Climate change economics
Faculty of economics and managment - Cheikh Anta Diop University
West African Science Service Center on Climate Change and Adaptated Land Use (WASCAL)
Center for Development Research (ZEF) - University of Bonn 

email : ahmadou.dicko at ucad.edu.sn
twitter : @dickoah
github : github/dickoa
tel : +221 33 827 55 16
portable: +221 77 123 81 69
	[[alternative HTML version deleted]]


From edzer.pebesma at uni-muenster.de  Thu Aug 21 10:14:11 2014
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 21 Aug 2014 10:14:11 +0200
Subject: [R-sig-Geo] gstat trend beta ignored?
In-Reply-To: <CAPGZjC=k5fndSVfAQzODU6PODKY2Vj+yDmeqqozAB1FYGRJEoQ@mail.gmail.com>
References: <CAPGZjC=k5fndSVfAQzODU6PODKY2Vj+yDmeqqozAB1FYGRJEoQ@mail.gmail.com>
Message-ID: <53F5AA53.8060502@uni-muenster.de>

Sandeep, before you ask whether certain bugs are known it is often more
constructive to start the discussion about whether there is agreement
that your findings point to bugs.

As of your point 2, this is according to documentation: beta is not in
the parameter list of predict.gstat, hence is absorbed by ..., and ...
according to the documentation is ignored. If you expect, or wished for
other behaviour, that would be a feature request.

As of point 1, in the call to variogram() specifying gls=1 asks for
generalized least squares _estimation_ of the trend coefficients,
specifying beta means that you know, hence don't want to estimate these
coefficients. This indicates some misunderstanding of what you could do,
or what you expect the software to do. The right behaviour would be to
generate an error message.

If you could point me to the relevant sections in the documentation that
made you believe that something useful should happen ("GLS + beta
specified") then I would be happy to learn about that.


On 08/21/2014 08:12 AM, Sandeep Pulla wrote:
> ?There appear to be couple of problems in specifying known trend
> coefficients in gstat. Specifically,
> 1. The 'beta' parameter seems to be ignored when the 'gls' parameter is 1.
> 2. The 'beta' parameter is ignored by predict.gstat() (regardless of the
> 'gls' parameter).
> 
> Here's a full example:
> 
> library(gstat)
> library(sp) # for coordinates()
> library(geoR) # for grf()
> n = 20 ^ 2 # number of observations
> xmin = ymin = 0; xmax = ymax = 2 # rectangular domain
> trend.beta = c(pi, exp(1), -exp(1)) # linear trend-surface coefficients
> trend.surf = cbind(1, as.matrix(expand.grid(x = seq(xmin, xmax, len =
> sqrt(n)),
>   y = seq(xmin, ymax, len = sqrt(n))))) %*% trend.beta
> set.seed(100)
> field = grf(n, "reg", xlims = c(xmin, xmax), ylims = c(ymin, ymax),
> cov.model = "mat",
>   cov.pars = c(1, .1), kappa = 1, nugget = .5, mean = trend.surf)
> dat = data.frame(var = field$data, field$coords, intercept = 1)
> coordinates(dat) = ~ x + y
> vgm.mod = vgm(1, "Mat", .5, 1)
> # Trend surface predictions to retrieve beta (see demo(blue))
> pred.grid = data.frame(intercept = c(1, 0, 0), x = c(0, 1, 0), y = c(0, 0,
> 1))
> coordinates(pred.grid) = ~ x + y
> # OK: Trend beta are estimated using OLS
> plot(plot(variogram(gstat(NULL, "var", var ~ x + y, data = dat,
>   model = vgm.mod, set = list(gls = 0))), main = "OLS"))
> # OK: Predefined trend beta are used
> plot(plot(variogram(gstat(NULL, "var", var ~ x + y, data = dat,
>   model = vgm.mod, set = list(gls = 0), beta = c(20, 10, -10))),
>   main = "OLS + predefined"))
> # OK: Trend beta are estimated using GLS
> plot(plot(variogram(gstat(NULL, "var", var ~ x + y, data = dat,
>   model = vgm.mod, set = list(gls = 1))), main = "GLS"))
> # BUG: Predefined trend beta are ignored
> plot(plot(variogram(gstat(NULL, "var", var ~ x + y, data = dat,
>   model = vgm.mod, set = list(gls = 1), beta = c(20, 10, -10))),
>   main = "GLS + predefined"))
> # BUG: Predefined trend beta are ignored
> print(predict(gstat(NULL, "var", var ~ x + y + intercept - 1, data = dat,
>     model = vgm.mod, set = list(gls = 1), beta = c(20, 10, -10)),
>   pred.grid, BLUE = T)@data$var.pred)
> # BUG: 'gls' option is ignored (uses GLS instead of OLS for trend
> estimation)
> print(predict(gstat(NULL, "var", var ~ x + y + intercept - 1, data = dat,
>     model = vgm.mod, set = list(gls = 0)),
>   pred.grid, BLUE = T)@data$var.pred)
> 
> Are these known bugs?
> 
> Thanks,
> Sandeep
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Heisenbergstra?e 2, 48149 M?nster, Germany. Phone: +49 251
83 33081 http://ifgi.uni-muenster.de GPG key ID 0xAC227795

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140821/fe6680fa/attachment.bin>

From dicko.ahmadou at gmail.com  Thu Aug 21 11:31:34 2014
From: dicko.ahmadou at gmail.com (Ahmadou Dicko)
Date: Thu, 21 Aug 2014 09:31:34 +0000
Subject: [R-sig-Geo] Converting .hdf file to raster layer
In-Reply-To: <1408607563.65589.YahooMailNeo@web192702.mail.sg3.yahoo.com>
References: <1407976021.54447.YahooMailNeo@web192705.mail.sg3.yahoo.com>
	<CAAcGz9_O7cE6bC22NBww9kRuyVoLC-Ooj21G+WP9Ata+J70G2Q@mail.gmail.com>
	<CAP8THHW2HDXkOqsyDeaHWqoPDoETskjSCP6wZTPtsmjK8X9vNQ@mail.gmail.com>
	<1408607563.65589.YahooMailNeo@web192702.mail.sg3.yahoo.com>
Message-ID: <CAP8THHWd4uPiNzev540eu4zKMT8vh-5kdwbhi61aEOv-Tsq0xw@mail.gmail.com>

I suspect that your GDAL was not build with the HDF4 driver.

What is the output of :
grep("hdf4", gdalDrivers()$name, ignore.case = TRUE, value = TRUE)



On Thu, Aug 21, 2014 at 7:52 AM, Arnold Salvacion <
arnold_salvacion at yahoo.com> wrote:

> Hi Ahmadou,
>
> Have tried your code but still no success. However, I have actually tried
> to download the .hdf file directly from net. What I did is import the data
> from local folder. Below is the error that I got:
>
> Error in .local(.Object, ...) :
>  `C:\Users\Owner\Documents\VHP.G16.C07.NC.P1982006.VH.hdf' not recognised as a supported file format.
>
>
> Best regards,
>
> Arnold
>
>
>
>
>   On Friday, August 15, 2014 2:33 AM, Ahmadou Dicko <
> dicko.ahmadou at gmail.com> wrote:
>
>
> You can use the gdalUtils package to get information on datasets inside
> your hdf file and then stack them using the raster package
>
> library(raster)
> library(rgdal)  ## built with HDF4 support
> library(gdalUtils)
>
> fsrc <- "
> ftp://ftp.star.nesdis.noaa.gov/pub/corp/scsb/wguo/data/VHP_16km/VH/VHP.G16.C07.NC.P1981035.ND.hdf
> "
> f <- file.path("/tmp", basename(fsrc))
> if (!file.exists(f)) download.file(fsrc, f, mode = "wb")
>
> info <- gdalinfo(f)
> data <- grep("HDF4_SDS", info, value = TRUE)
> data <- gsub("SUBDATASET_\\d+_NAME=|\\s+", "", data)
>
>
> sds <- stack(data)
> sds
> ## class       : RasterStack
> ## dimensions  : 904, 2500, 2260000, 3  (nrow, ncol, ncell, nlayers)
> ## resolution  : 1, 1  (x, y)
> ## extent      : 0, 2500, 0, 904  (xmin, xmax, ymin, ymax)
> ## coord. ref. : NA
> ## names       : VHP.G16.C07.NC.P1981035.ND.1,
> VHP.G16.C07.NC.P1981035.ND.2, VHP.G16.C07.NC.P1981035.ND.3
> ## min values  :                       -32768,
> -32768,                            0
> ## max values  :                        32767,
> 32767,                          255
>
> ##You can use RasterBrick too, by doing `brick(sds)`
>
> sessionInfo()
> ## R version 3.1.1 Patched (2014-08-12 r66349)
> ## Platform: x86_64-unknown-linux-gnu (64-bit)
>
> ## locale:
> ##  [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C
> ##  [3] LC_TIME=en_US.utf8        LC_COLLATE=en_US.utf8
> ##  [5] LC_MONETARY=en_US.utf8    LC_MESSAGES=en_US.utf8
> ##  [7] LC_PAPER=en_US.utf8       LC_NAME=C
> ##  [9] LC_ADDRESS=C              LC_TELEPHONE=C
> ## [11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C
>
> ## attached base packages:
> ## [1] stats     graphics  grDevices utils     datasets  methods
> ## [7] base
>
> ## other attached packages:
> ## [1] gdalUtils_0.3.2 rgdal_0.8-16    raster_2.2-32
> ## [4] sp_1.0-15
>
> ## loaded via a namespace (and not attached):
> ##  [1] codetools_0.2-8   compiler_3.1.1    foreach_1.4.2
> ##  [4] grid_3.1.1        iterators_1.0.7   lattice_0.20-29
> ##  [7] R.methodsS3_1.6.1 R.oo_1.18.0       R.utils_1.32.4
> ## [10] tools_3.1.1
>
> grep("hdf4", gdalDrivers()$name, ignore.case = TRUE, value = TRUE)
> ## [1] "HDF4"      "HDF4Image"
>
>
>
> On Thu, Aug 14, 2014 at 8:52 AM, Michael Sumner <mdsumner at gmail.com>
> wrote:
>
> Just had a look, the file has subdatasets and seemingly raster can't
> handle those. (I haven't explored this much but might have a chance
> to).
>
> library(raster)
> library(rgdal)  ## built with HDF4, HDF5 and NetCDF4
>
> fsrc <- "
> ftp://ftp.star.nesdis.noaa.gov/pub/corp/scsb/wguo/data/VHP_16km/VH/VHP.G16.C07.NC.P1981035.ND.hdf
> "
> f <- basename(fsrc)
> if (!file.exists(f)) download.file(fsrc, f, mode = "wb")
>
> ## found with system GDAL, see below
> sds <- c('HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":0',
>          'HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":1',
>          'HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":2'
>          )
>
> ##r <- brick(sds)
> ##Error in GDALinfo(filename, silent = silent, returnRAT = RAT,
> returnCategoryNames = RAT) :
>  ## object 'RATlist' not found
> ##Error in .rasterObjectFromFile(x, band = band, objecttype =
> "RasterLayer",  :
>  ##                                Cannot create a RasterLayer object
> from this file.
>   ##                             In addition: Warning message:
>  ##                                In dim(x) : no bands in dataset
>
>
> ## try with rgdal directly, so far so good but
> ## no spatial-reference (again see gdalinfo output below)
> raster(readGDAL(sds[1])  )
>
>  raster(readGDAL(sds[1])  )
> HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":0 has GDAL driver
> HDF4Image
> and has 904 rows and 2500 columns
> class       : RasterLayer
> dimensions  : 904, 2500, 2260000  (nrow, ncol, ncell)
> resolution  : 1, 1  (x, y)
> extent      : 0, 2500, 0, 904  (xmin, xmax, ymin, ymax)
> coord. ref. : NA
> data source : in memory
> names       : band1
> values      : -99.9, 322  (min, max)
>
> Warning message:
> In readGDAL(sds[1]) : GeoTransform values not available
>
>
> ## proceed without caution, again values from gdalinfo
> b <- brick(stack(sapply(sds, function(x) raster(readGDAL(x)))))
> proj4string(b) <-  CRS(" +proj=longlat +ellps=WGS84 +datum=WGS84
> +no_defs +towgs84=0,0,0")
> extent(b) <- c(-180, 180, -55.15200043, 75.02400208)
>
> library(maptools
> data(wrld_simpl)
> plot(b, addfun = function() plot(wrld_simpl, add = TRUE))
>
> That looks ok to me, I don't know if it's WGS84 or the sphere or
> something else.
>
> Cheers, Mike.
>
>
>
>
>
> system(sprintf("gdalinfo %s", f))
>
> Driver: HDF4/Hierarchical Data Format Release 4
> Files: VHP.G16.C07.NC.P1981035.ND.hdf
> Size is 512, 512
> Coordinate System is `'
> Metadata:
>   ANCILLARY_FILES=FILE_CONFIGURE:vh.config
> FILE_PRELAUNCH_CALIBRATION:../ancillary/AVHRR_calibration_prelaunch.txt
> FILE_POSTLAUNCH_CALIBRATION:../ancillary/AVHRR_calibration_postlaunch.txt
> FILE_IGBP_LANDTYPE:../ancillary/igbp_landtype_GVIx.hdf
> FILE_METADATA_REGIONS:../ancillary/regions_for_metadata.txt
> FILE_EDF_NDVI:../ancillary/NVI_counts_ByLine_G04.hdf
> FILE_EDF_BT4:../ancillary/BT4_counts_ByLine_G04.hdf
>
>   CITATION_TO_DOCUMENTS=User Guide of Vegetation Health(VH) system
> (version 1.3, March 21 2012)
>   CONFIGURE_FILE_CONTENT=[Options for vh.exe]
> DIR_Ancillary=                 ../ancillary
> DIR_GVI=                       data/VH_unitTest1/weekly
> DIR_VH=                        data/VH_unitTest1/G04
> DIR_VH_META=                   data/VH_unitTest1/G04/meta
> DIR_CLIMAT=                    data/VH_EDF_v2/climate_G04
> DIR_CLIMAT_META=               data/VH_EDF_v2/climate_G04/meta
> FILE_PREFIX=       VHP
> Input_Data_Type=       VHP
> ResolutionString=              G04
> Days_Per_Period=               7
> FilterSize=                    15
> applyEDFonNDVI=                1     # 0: none, 1: linebyline for NVI;
> applyEDFonBT=                  1
> Instrument=                    AVHRR # so far AVHRR is the only option
> FORMAT_GVI=                   NETCDF #or HDF4
> FORMAT_CLIMAT=                HDF4
> FORMAT_ND=                    NETCDF
> FORMAT_SM=                    NETCDF
> FORMAT_VH=                    NETCDF
>
> [Periods of GVI data used for VH]
> # this section control which satellite will be used for calculating
> ND, SM and VH
> #satID satNumber yearWeek1 yearWeek2
> NC 07 198135 198449
> NF 09 198509 198844
> NH 11 198846 199436
> NJ 14 199504 200052
> NL 16 200101 200401
> NL 16 200405 200410
> NL 16 200425 200428
> NL 16 200430 200523
> NN 18 200524 201052
> NP 19 201101 399999
>
> [Periods of AVHRR data used for GVI climatology]
> #this section controls which satellite will be used for creating VH
> climatology
> #satID satNumber yearWeek1 yearWeek2
> NC 07 198142 198450
> NF 09 198515 198752
> NH 11 198920 199252
> NJ 14 199520 199952
> NL 16 200120 200252
>
> [END]
>
>
>   CONTACT=NOAA/NESDIS/STAR/EMB
>   DATE_BEGIN=239
>   DATE_END=245
>   DAYS_PER_PERIOD=7
>   END_LATITUDE_RANGE=-55.15200043
>   END_LONGITUDE_RANGE=180
>   INPUT_FILENAMES=data/VH_unitTest1/weekly/
> VHP.G04.C07.NC.P1981035.S239.E245.nc
> <http://vhp.g04.c07.nc.p1981035.s239.e245.nc/>
>
>   INPUT_FILES=1
>   INSTRUMENT=AVHRR
>   PERIOD_OF_YEAR=35
>   PRODUCT_NAME=Vegetation Health
>   PROJECTION=Plate_Carree
>   SATELLITE=NC
>   START_LATITUDE_RANGE=75.02400208
>   START_LONGITUDE_RANGE=-180
>   TIME_BEGIN=00:00 UTC (use day time data only)
>   TIME_END=23:59 UTC (use day time data only)
>   VERSION=VH (vh.exe,version 1.3, March 21 2012)
>   YEAR=1981
> Subdatasets:
>   SUBDATASET_1_NAME=HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":0
>   SUBDATASET_1_DESC=[904x2500] BT4 (16-bit integer)
>   SUBDATASET_2_NAME=HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":1
>   SUBDATASET_2_DESC=[904x2500] NDVI (16-bit integer)
>   SUBDATASET_3_NAME=HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":2
>   SUBDATASET_3_DESC=[904x2500] QA (8-bit unsigned integer)
> Corner Coordinates:
> Upper Left  (    0.0,    0.0)
> Lower Left  (    0.0,  512.0)
> Upper Right (  512.0,    0.0)
> Lower Right (  512.0,  512.0)
> Center      (  256.0,  256.0)
>
> On Thu, Aug 14, 2014 at 10:27 AM, Arnold Salvacion
> <arnold_salvacion at yahoo.com> wrote:
> > Dear Colleagues,
> >
> > Does any here have already experience converting NOAA AVHRR VHP Product
> in .hdf (
> ftp://ftp.star.nesdis.noaa.gov/pub/corp/scsb/wguo/data/VHP_16km/VH/ )
> format to a raster layer in R?
> >
> >
> > Best regards,
> >
> > Arnold
> >         [[alternative HTML version deleted]]
> >
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
>
>
> --
> Michael Sumner
> Software and Database Engineer
> Australian Antarctic Division
> Hobart, Australia
> e-mail: mdsumner at gmail.com
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>
>
> --
> Ahmadou H. DICKO
> statistician economist (Ing?nieur Statisticien ?conomiste)
> PhD candidate in Climate change economics
> Faculty of economics and managment - Cheikh Anta Diop University
> West African Science Service Center on Climate Change and Adaptated Land
> Use (WASCAL)
> Center for Development Research (ZEF) - University of Bonn
>
> email :
> ahmadou.dicko at ucad.edu.sn
> twitter : @dickoah
> github : github/dickoa <https://github.com/dickoa>
> tel : +221 33 827 55 16
> portable: +221 77 123 81 69
>
>
>
>


-- 
Ahmadou H. DICKO
statistician economist (Ing?nieur Statisticien ?conomiste)
PhD candidate in Climate change economics
Faculty of economics and managment - Cheikh Anta Diop University
West African Science Service Center on Climate Change and Adaptated Land
Use (WASCAL)
Center for Development Research (ZEF) - University of Bonn
email : ahmadou.dicko at ucad.edu.sn
twitter : @dickoah
github : github/dickoa <https://github.com/dickoa>
tel : +221 33 827 55 16
portable: +221 77 123 81 69

	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Thu Aug 21 12:15:28 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 21 Aug 2014 12:15:28 +0200
Subject: [R-sig-Geo] Spatial lags using gridded data
In-Reply-To: <CAEdPBsGcPNazXJbV-BWxFZPARP1NGa6Vou9oKmNXiyUn3Qqm5Q@mail.gmail.com>
References: <CAEdPBsGcPNazXJbV-BWxFZPARP1NGa6Vou9oKmNXiyUn3Qqm5Q@mail.gmail.com>
Message-ID: <alpine.LRH.2.03.1408211150020.1807@reclus.nhh.no>

On Thu, 21 Aug 2014, Steve Pickering wrote:

> Hello, all,
>
> Sorry for the silly question.
>
> I'm struggling to apply spatial lags to a data grid.  I've been
> working through the notes on Luc Anselin's spdep, but just can't
> figure out how to apply it to gridded data.
>
> Consider the following very simple 5 x 5 grid:
>
> ids <- c(1:25)
> lats <- c(30,30,30,30,30,31,31,31,31,31,32,32,32,32,32,33,33,33,33,33,34,34,34,34,34)
> lngs <- c(10,11,12,13,14,10,11,12,13,14,10,11,12,13,14,10,11,12,13,14,10,11,12,13,14)
> conflict <- c(0,0,0,0,0,0,0,0,1,0,0,0,1,1,0,0,1,0,0,0,0,0,0,0,0)
> conflictLag <- c(0,0,0.125,0.125,0.125,0,0.125,0.375,0.25,0.25,0.125,0.25,0.375,0.25,0.25,0.125,0.125,0.375,0.25,0.125,0.125,0.125,0.125,0,0)
> pop <- sample(100, 25)
>
> newGrid = data.frame(ids, lats, lngs, conflict, conflictLag, pop)
>
> Here, I have a conflict dummy, to determine whether there was some
> sort of conflict or war in that grid cell.  I also have a population
> variable (for the purposes of this exercise, determined at random).
>
> If I wanted to run a regression on this without including spatial
> lags, I could do something very simple, like this:
>
> model1 = lm(newGrid$conflict ~ newGrid$pop)
> summary(model1)

Thanks for the toy example:

set.seed(1)
pop <- sample(100, 25)
newGrid = data.frame(ids, lats, lngs, conflict, conflictLag, pop)
model1 = lm(conflict ~ pop, data=newGrid)
summary(model1)

Then make a spatial object:

library(sp)
coordinates(newGrid) <- c("lngs", "lats")
gridded(newGrid) <- TRUE
image(newGrid, "conflict")

Create a list of neighbours (here ignoring the possibility that the grid 
is in geographical, not projected coordinates:

library(spdep)
nb <- dnearneigh(newGrid, 0, sqrt(2))
summary(nb)
plot(nb, coordinates(newGrid), add=TRUE)

Choose a model and fitting function:

model2 <- spautolm(conflict ~ pop, data=newGrid, listw=nb2listw(nb,
  style="W"), family="SAR")
summary(model2)

but note that conflict is not a continuous variable, so:

model1a = glm(conflict ~ pop, data=newGrid, family=binomial(link=probit))
summary(model1a)

and

library(spatialprobit)
W <- as(as_dgRMatrix_listw(nb2listw(nb, style="W")), "CsparseMatrix")
model2a <- semprobit(conflict ~ pop, W=W, data=newGrid)
summary(model2a)

which uses MCMC, so is slow. Alternatively, but for the spatially 
lagged response, not for the spatially lagged error term:

model2b <- sarprobit(conflict ~ pop, W=W, data=newGrid)
summary(model2b)

This object includes effects/impacts (see LeSage & Pace 2009, or Ward & 
Gleditsch 2008).

library(McSpatial)
model2c <- spprobit(conflict ~ pop, wmat=nb2mat(nb), data=newGrid)
model2d <- spprobitml(conflict ~ pop, wmat=nb2mat(nb), data=newGrid)

use GMM and ML respectively and do not provide impacts. A recent paper in 
Journal of Regional Science compares spatial probit estimation approaches. 
In addition, the tally of 0 conflicts is 4 of 25, so your data may well 
also be zero-inflated.

Spatial misspecification is possibly only a minor problem, really.

Hope this helps,

Roger


>
> However, I know that I am supposed to include a spatial lag.  As you
> can see in the code, I have also created a spatial lag variable based
> on whether there was conflict in adjacent cells (Queen's move, hence a
> fraction of eight).
>
> What I'm struggling with is the correct way to include the spatial lag
> in my model.
>
> Thanks, and sorry for the simple question.
>
> - Steve.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From loic.dutrieux at wur.nl  Thu Aug 21 12:56:07 2014
From: loic.dutrieux at wur.nl (=?UTF-8?B?TG/Dr2M=?=)
Date: Thu, 21 Aug 2014 12:56:07 +0200
Subject: [R-sig-Geo] Converting .hdf file to raster layer
In-Reply-To: <CAP8THHWd4uPiNzev540eu4zKMT8vh-5kdwbhi61aEOv-Tsq0xw@mail.gmail.com>
References: <1407976021.54447.YahooMailNeo@web192705.mail.sg3.yahoo.com>
	<CAAcGz9_O7cE6bC22NBww9kRuyVoLC-Ooj21G+WP9Ata+J70G2Q@mail.gmail.com>
	<CAP8THHW2HDXkOqsyDeaHWqoPDoETskjSCP6wZTPtsmjK8X9vNQ@mail.gmail.com>
	<1408607563.65589.YahooMailNeo@web192702.mail.sg3.yahoo.com>
	<CAP8THHWd4uPiNzev540eu4zKMT8vh-5kdwbhi61aEOv-Tsq0xw@mail.gmail.com>
Message-ID: <53F5D047.6070406@wur.nl>

Hi Arnold,

GDAL provided with the rgdal binaries for windows isn't built with the 
hdf4 driver. Theoretically it is possible to build rgdal from source 
against GDAL contained in OSGeo4W or QGIS but from what I've heard it is 
not trivial at all.

One alternative for reading hdf layer into R when working in windows is 
by converting it to another format (e.g.: GeoTiff) using gdal_translate 
(either from command line or via gdalUtils) and reading that new layer 
into R.

The lines below illustrate briefly the two step process.

library(raster)
library(gdalUtils)

sds <- get_subdatasets('/full/path/to/file.hdf')
# translate first subdataset of hdf file to tiff
gdal_translate(sds[1], dst_dataset = 'out.tif')
r <- raster('out.tif')

Cheers,
Lo?c

On 21/08/2014 11:31, Ahmadou Dicko wrote:
> I suspect that your GDAL was not build with the HDF4 driver.
>
> What is the output of :
> grep("hdf4", gdalDrivers()$name, ignore.case = TRUE, value = TRUE)
>
>
>
> On Thu, Aug 21, 2014 at 7:52 AM, Arnold Salvacion <
> arnold_salvacion at yahoo.com> wrote:
>
>> Hi Ahmadou,
>>
>> Have tried your code but still no success. However, I have actually tried
>> to download the .hdf file directly from net. What I did is import the data
>> from local folder. Below is the error that I got:
>>
>> Error in .local(.Object, ...) :
>>   `C:\Users\Owner\Documents\VHP.G16.C07.NC.P1982006.VH.hdf' not recognised as a supported file format.
>>
>>
>> Best regards,
>>
>> Arnold
>>
>>
>>
>>
>>    On Friday, August 15, 2014 2:33 AM, Ahmadou Dicko <
>> dicko.ahmadou at gmail.com> wrote:
>>
>>
>> You can use the gdalUtils package to get information on datasets inside
>> your hdf file and then stack them using the raster package
>>
>> library(raster)
>> library(rgdal)  ## built with HDF4 support
>> library(gdalUtils)
>>
>> fsrc <- "
>> ftp://ftp.star.nesdis.noaa.gov/pub/corp/scsb/wguo/data/VHP_16km/VH/VHP.G16.C07.NC.P1981035.ND.hdf
>> "
>> f <- file.path("/tmp", basename(fsrc))
>> if (!file.exists(f)) download.file(fsrc, f, mode = "wb")
>>
>> info <- gdalinfo(f)
>> data <- grep("HDF4_SDS", info, value = TRUE)
>> data <- gsub("SUBDATASET_\\d+_NAME=|\\s+", "", data)
>>
>>
>> sds <- stack(data)
>> sds
>> ## class       : RasterStack
>> ## dimensions  : 904, 2500, 2260000, 3  (nrow, ncol, ncell, nlayers)
>> ## resolution  : 1, 1  (x, y)
>> ## extent      : 0, 2500, 0, 904  (xmin, xmax, ymin, ymax)
>> ## coord. ref. : NA
>> ## names       : VHP.G16.C07.NC.P1981035.ND.1,
>> VHP.G16.C07.NC.P1981035.ND.2, VHP.G16.C07.NC.P1981035.ND.3
>> ## min values  :                       -32768,
>> -32768,                            0
>> ## max values  :                        32767,
>> 32767,                          255
>>
>> ##You can use RasterBrick too, by doing `brick(sds)`
>>
>> sessionInfo()
>> ## R version 3.1.1 Patched (2014-08-12 r66349)
>> ## Platform: x86_64-unknown-linux-gnu (64-bit)
>>
>> ## locale:
>> ##  [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C
>> ##  [3] LC_TIME=en_US.utf8        LC_COLLATE=en_US.utf8
>> ##  [5] LC_MONETARY=en_US.utf8    LC_MESSAGES=en_US.utf8
>> ##  [7] LC_PAPER=en_US.utf8       LC_NAME=C
>> ##  [9] LC_ADDRESS=C              LC_TELEPHONE=C
>> ## [11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C
>>
>> ## attached base packages:
>> ## [1] stats     graphics  grDevices utils     datasets  methods
>> ## [7] base
>>
>> ## other attached packages:
>> ## [1] gdalUtils_0.3.2 rgdal_0.8-16    raster_2.2-32
>> ## [4] sp_1.0-15
>>
>> ## loaded via a namespace (and not attached):
>> ##  [1] codetools_0.2-8   compiler_3.1.1    foreach_1.4.2
>> ##  [4] grid_3.1.1        iterators_1.0.7   lattice_0.20-29
>> ##  [7] R.methodsS3_1.6.1 R.oo_1.18.0       R.utils_1.32.4
>> ## [10] tools_3.1.1
>>
>> grep("hdf4", gdalDrivers()$name, ignore.case = TRUE, value = TRUE)
>> ## [1] "HDF4"      "HDF4Image"
>>
>>
>>
>> On Thu, Aug 14, 2014 at 8:52 AM, Michael Sumner <mdsumner at gmail.com>
>> wrote:
>>
>> Just had a look, the file has subdatasets and seemingly raster can't
>> handle those. (I haven't explored this much but might have a chance
>> to).
>>
>> library(raster)
>> library(rgdal)  ## built with HDF4, HDF5 and NetCDF4
>>
>> fsrc <- "
>> ftp://ftp.star.nesdis.noaa.gov/pub/corp/scsb/wguo/data/VHP_16km/VH/VHP.G16.C07.NC.P1981035.ND.hdf
>> "
>> f <- basename(fsrc)
>> if (!file.exists(f)) download.file(fsrc, f, mode = "wb")
>>
>> ## found with system GDAL, see below
>> sds <- c('HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":0',
>>           'HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":1',
>>           'HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":2'
>>           )
>>
>> ##r <- brick(sds)
>> ##Error in GDALinfo(filename, silent = silent, returnRAT = RAT,
>> returnCategoryNames = RAT) :
>>   ## object 'RATlist' not found
>> ##Error in .rasterObjectFromFile(x, band = band, objecttype =
>> "RasterLayer",  :
>>   ##                                Cannot create a RasterLayer object
>> from this file.
>>    ##                             In addition: Warning message:
>>   ##                                In dim(x) : no bands in dataset
>>
>>
>> ## try with rgdal directly, so far so good but
>> ## no spatial-reference (again see gdalinfo output below)
>> raster(readGDAL(sds[1])  )
>>
>>   raster(readGDAL(sds[1])  )
>> HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":0 has GDAL driver
>> HDF4Image
>> and has 904 rows and 2500 columns
>> class       : RasterLayer
>> dimensions  : 904, 2500, 2260000  (nrow, ncol, ncell)
>> resolution  : 1, 1  (x, y)
>> extent      : 0, 2500, 0, 904  (xmin, xmax, ymin, ymax)
>> coord. ref. : NA
>> data source : in memory
>> names       : band1
>> values      : -99.9, 322  (min, max)
>>
>> Warning message:
>> In readGDAL(sds[1]) : GeoTransform values not available
>>
>>
>> ## proceed without caution, again values from gdalinfo
>> b <- brick(stack(sapply(sds, function(x) raster(readGDAL(x)))))
>> proj4string(b) <-  CRS(" +proj=longlat +ellps=WGS84 +datum=WGS84
>> +no_defs +towgs84=0,0,0")
>> extent(b) <- c(-180, 180, -55.15200043, 75.02400208)
>>
>> library(maptools
>> data(wrld_simpl)
>> plot(b, addfun = function() plot(wrld_simpl, add = TRUE))
>>
>> That looks ok to me, I don't know if it's WGS84 or the sphere or
>> something else.
>>
>> Cheers, Mike.
>>
>>
>>
>>
>>
>> system(sprintf("gdalinfo %s", f))
>>
>> Driver: HDF4/Hierarchical Data Format Release 4
>> Files: VHP.G16.C07.NC.P1981035.ND.hdf
>> Size is 512, 512
>> Coordinate System is `'
>> Metadata:
>>    ANCILLARY_FILES=FILE_CONFIGURE:vh.config
>> FILE_PRELAUNCH_CALIBRATION:../ancillary/AVHRR_calibration_prelaunch.txt
>> FILE_POSTLAUNCH_CALIBRATION:../ancillary/AVHRR_calibration_postlaunch.txt
>> FILE_IGBP_LANDTYPE:../ancillary/igbp_landtype_GVIx.hdf
>> FILE_METADATA_REGIONS:../ancillary/regions_for_metadata.txt
>> FILE_EDF_NDVI:../ancillary/NVI_counts_ByLine_G04.hdf
>> FILE_EDF_BT4:../ancillary/BT4_counts_ByLine_G04.hdf
>>
>>    CITATION_TO_DOCUMENTS=User Guide of Vegetation Health(VH) system
>> (version 1.3, March 21 2012)
>>    CONFIGURE_FILE_CONTENT=[Options for vh.exe]
>> DIR_Ancillary=                 ../ancillary
>> DIR_GVI=                       data/VH_unitTest1/weekly
>> DIR_VH=                        data/VH_unitTest1/G04
>> DIR_VH_META=                   data/VH_unitTest1/G04/meta
>> DIR_CLIMAT=                    data/VH_EDF_v2/climate_G04
>> DIR_CLIMAT_META=               data/VH_EDF_v2/climate_G04/meta
>> FILE_PREFIX=       VHP
>> Input_Data_Type=       VHP
>> ResolutionString=              G04
>> Days_Per_Period=               7
>> FilterSize=                    15
>> applyEDFonNDVI=                1     # 0: none, 1: linebyline for NVI;
>> applyEDFonBT=                  1
>> Instrument=                    AVHRR # so far AVHRR is the only option
>> FORMAT_GVI=                   NETCDF #or HDF4
>> FORMAT_CLIMAT=                HDF4
>> FORMAT_ND=                    NETCDF
>> FORMAT_SM=                    NETCDF
>> FORMAT_VH=                    NETCDF
>>
>> [Periods of GVI data used for VH]
>> # this section control which satellite will be used for calculating
>> ND, SM and VH
>> #satID satNumber yearWeek1 yearWeek2
>> NC 07 198135 198449
>> NF 09 198509 198844
>> NH 11 198846 199436
>> NJ 14 199504 200052
>> NL 16 200101 200401
>> NL 16 200405 200410
>> NL 16 200425 200428
>> NL 16 200430 200523
>> NN 18 200524 201052
>> NP 19 201101 399999
>>
>> [Periods of AVHRR data used for GVI climatology]
>> #this section controls which satellite will be used for creating VH
>> climatology
>> #satID satNumber yearWeek1 yearWeek2
>> NC 07 198142 198450
>> NF 09 198515 198752
>> NH 11 198920 199252
>> NJ 14 199520 199952
>> NL 16 200120 200252
>>
>> [END]
>>
>>
>>    CONTACT=NOAA/NESDIS/STAR/EMB
>>    DATE_BEGIN=239
>>    DATE_END=245
>>    DAYS_PER_PERIOD=7
>>    END_LATITUDE_RANGE=-55.15200043
>>    END_LONGITUDE_RANGE=180
>>    INPUT_FILENAMES=data/VH_unitTest1/weekly/
>> VHP.G04.C07.NC.P1981035.S239.E245.nc
>> <http://vhp.g04.c07.nc.p1981035.s239.e245.nc/>
>>
>>    INPUT_FILES=1
>>    INSTRUMENT=AVHRR
>>    PERIOD_OF_YEAR=35
>>    PRODUCT_NAME=Vegetation Health
>>    PROJECTION=Plate_Carree
>>    SATELLITE=NC
>>    START_LATITUDE_RANGE=75.02400208
>>    START_LONGITUDE_RANGE=-180
>>    TIME_BEGIN=00:00 UTC (use day time data only)
>>    TIME_END=23:59 UTC (use day time data only)
>>    VERSION=VH (vh.exe,version 1.3, March 21 2012)
>>    YEAR=1981
>> Subdatasets:
>>    SUBDATASET_1_NAME=HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":0
>>    SUBDATASET_1_DESC=[904x2500] BT4 (16-bit integer)
>>    SUBDATASET_2_NAME=HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":1
>>    SUBDATASET_2_DESC=[904x2500] NDVI (16-bit integer)
>>    SUBDATASET_3_NAME=HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":2
>>    SUBDATASET_3_DESC=[904x2500] QA (8-bit unsigned integer)
>> Corner Coordinates:
>> Upper Left  (    0.0,    0.0)
>> Lower Left  (    0.0,  512.0)
>> Upper Right (  512.0,    0.0)
>> Lower Right (  512.0,  512.0)
>> Center      (  256.0,  256.0)
>>
>> On Thu, Aug 14, 2014 at 10:27 AM, Arnold Salvacion
>> <arnold_salvacion at yahoo.com> wrote:
>>> Dear Colleagues,
>>>
>>> Does any here have already experience converting NOAA AVHRR VHP Product
>> in .hdf (
>> ftp://ftp.star.nesdis.noaa.gov/pub/corp/scsb/wguo/data/VHP_16km/VH/ )
>> format to a raster layer in R?
>>>
>>>
>>> Best regards,
>>>
>>> Arnold
>>>          [[alternative HTML version deleted]]
>>>
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>>
>>
>> --
>> Michael Sumner
>> Software and Database Engineer
>> Australian Antarctic Division
>> Hobart, Australia
>> e-mail: mdsumner at gmail.com
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
>>
>>
>> --
>> Ahmadou H. DICKO
>> statistician economist (Ing?nieur Statisticien ?conomiste)
>> PhD candidate in Climate change economics
>> Faculty of economics and managment - Cheikh Anta Diop University
>> West African Science Service Center on Climate Change and Adaptated Land
>> Use (WASCAL)
>> Center for Development Research (ZEF) - University of Bonn
>>
>> email :
>> ahmadou.dicko at ucad.edu.sn
>> twitter : @dickoah
>> github : github/dickoa <https://github.com/dickoa>
>> tel : +221 33 827 55 16
>> portable: +221 77 123 81 69
>>
>>
>>
>>
>
>


From jgrn at illinois.edu  Thu Aug 21 19:22:36 2014
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Thu, 21 Aug 2014 12:22:36 -0500
Subject: [R-sig-Geo] Using 'raster' package functions with rasterEngine
In-Reply-To: <CAC4xYR5-PcYrFNCQBg4SC0+QbzYdaS8d_s1SQFhFZt41etCBQQ@mail.gmail.com>
References: <CAC4xYR5uqrSbXtjHFCPLkqBU0D3umxt8WF5YCoFa-s5v8OiuKg@mail.gmail.com>
	<CABG0rfuTFwkKVPq4V47apbV46doY4uZ4OLmaXttqvcQ0JxgH_A@mail.gmail.com>
	<CAC4xYR5-PcYrFNCQBg4SC0+QbzYdaS8d_s1SQFhFZt41etCBQQ@mail.gmail.com>
Message-ID: <CABG0rfueCX32SoJzgfmVErY5sn6Q2ogwh-i4byCSg12Bgicbuw@mail.gmail.com>

Ah, ok, I see what is going on.  The reason you are having this issue is
because clump is a focal window analysis, not a pixel-based analysis.  On
top of that, this is also a more complicated algorithm then you might think
since it deals with connectivity.  In this case, rasterEngine is almost
certainly not going to work the way you want it to without a lot of
tweaking.  You might want to open up the code of clump and see how Robert
does chunking (you also might see if Robert already built in parallel
processing to clump) -- you may be able to use this function inside of
rasterEngine.

--j


On Tue, Aug 19, 2014 at 12:21 PM, Dave Marvin <dmarvin at carnegiescience.edu>
wrote:

> Thank you for the comments Jonathan. I coerced the output from my
> function to an array, and that got it working. As you said the
> dimensions need to be ordered as (col, row). However, as you will see,
> there is an issue with the output in parallel mode:
>
> test_input=raster(system.file("external/tahoe_lidar_highesthit.tif",
> package="spatial.tools"))
> test_input=test_input>2535 #create distinct tree canopy objects.
> plot(test_input)
>
> clump_fun=function(raster_layer,...){
>      clump_raster=clump(raster_layer,directions=8)
>
>  clump_array=array(getValues(clump_raster),dim=c(dim(raster_layer)[c(2:1)],1))
>      return(clump_array)
> }
>
> cpus=3
> cl=makeCluster(spec = cpus, type = "PSOCK", methods = FALSE)
> registerDoParallel(cl)
>
>
> test_raster_out_a=rasterEngine(raster_layer=test_input,fun=clump_fun,chunk_format="raster",debugmode=FALSE)
>
> stopCluster(cl)
>
> **While this gives me an output, it is quite different from running
> the same function in either sequential mode or outside rasterEngine
> entirely:
>
> registerDoSEQ()
>
> test_raster_out_b=rasterEngine(raster_layer=test_input,fun=clump_fun,chunk_format="raster",debugmode=FALSE)
> test_raster_out_c=clump(test_input,directions=8)
>
> dim(freq(test_raster_out_a)$layer) #parallel output
> dim(freq(test_raster_out_b)$layer) #sequential mode output
> dim(freq(test_raster_out_c)) #non-rasterEngine output (same as "b")
>
> In fact, the number of clumps varies depending on the number of cores
> I use in parallel mode. Any idea what is happening here?
>
> Thank you,
> -Dave
>
> ----
> Dave Marvin | davidcmarvin.org
> Postdoctoral Research Fellow
> Department of Global Ecology
> Carnegie Institution for Science
>
>
> On Mon, Aug 11, 2014 at 8:55 AM, Jonathan Greenberg <jgrn at illinois.edu>
> wrote:
> > Hi Dave:
> >
> > If you can provide some code examples that would be easier, but I can
> give
> > you a couple of hints.  First, use debugmode=TRUE when you are testing
> your
> > function -- this will save you a lot of headaches down the line.  R will
> > enter its debugmode inside of the rasterEngine function so you can track
> > what is happening.
> >
> > The first issue is that clump only works on raster objects.
> rasterEngine,
> > in its default mode, sends "chunks" of the image to your function
> formatted
> > as *arrays*, not raster objects.  When you did chunk_format to raster, it
> > did, indeed, send the chunk as a small, cropped raster so clump worked,
> BUT:
> > all *outputs* from rasterEngine (at present) MUST be coerced to an array
> > that has the same number of columns and rows as the input (in that
> order).
> > I might mod this down the road to allow raster outputs, but for now
> you'll
> > need to make sure the output is of type array.  I suspect you are trying
> to
> > return the chunk from your function as a raster, which is why it isn't
> > working.
> >
> > Again: debugmode=TRUE, and track your function down to just before your
> > return the output -- check the type of the to-be-returned object and
> confirm
> > it is an array with dim()[1:2] equal to the input raster.
> >
> > Good luck!
> >
> > --j
> >
> >
> > On Thu, Aug 7, 2014 at 12:02 PM, Dave Marvin <
> dmarvin at carnegiescience.edu>
> > wrote:
> >>
> >> Hi,
> >> I am able to set up functions and apply them to a raster dataset in
> >> parallel using the rasterEngine function of the spatial.tools package,
> but
> >> only if the function performs just a numerical operation on the raster.
> >> When I try to incorporate a function from the raster package, such as
> >> clump(), the rasterEngine fails and I get an error:
> >>
> >> > Error in (function (classes, fdef, mtable): unable to find an
> inherited
> >> method for function ?clump? for signature ?"array"?
> >>
> >> If I change "chunk_format" to "raster" in the rasterEngine function,
> then
> >> i
> >> get an error:
> >>
> >> > chunk processing units require array vector outputs.  Please check
> your
> >> function.
> >>
> >> 1) Am I doing doing something wrong, or does this particular function
> just
> >> not work with rasterEngine?
> >>
> >> 2) If it is the latter, which of the raster package functions are
> >> available
> >> for use in parallel processing with rasterEngine?
> >>
> >> Thank you.
> >> -Dave
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >>
> >> _______________________________________________
> >> R-sig-Geo mailing list
> >> R-sig-Geo at r-project.org
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>
> >
> >
> >
> > --
> > Jonathan A. Greenberg, PhD
> > Assistant Professor
> > Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
> > Department of Geography and Geographic Information Science
> > University of Illinois at Urbana-Champaign
> > 259 Computing Applications Building, MC-150
> > 605 East Springfield Avenue
> > Champaign, IL  61820-6371
> > Phone: 217-300-1924
> > http://www.geog.illinois.edu/~jgrn/
> > AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007
>



-- 
Jonathan A. Greenberg, PhD
Assistant Professor
Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
Department of Geography and Geographic Information Science
University of Illinois at Urbana-Champaign
259 Computing Applications Building, MC-150
605 East Springfield Avenue
Champaign, IL  61820-6371
Phone: 217-300-1924
http://www.geog.illinois.edu/~jgrn/
AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007

	[[alternative HTML version deleted]]


From pickering at penguin.kobe-u.ac.jp  Fri Aug 22 04:07:35 2014
From: pickering at penguin.kobe-u.ac.jp (Steve Pickering)
Date: Fri, 22 Aug 2014 11:07:35 +0900
Subject: [R-sig-Geo] Spatial lags using gridded data
In-Reply-To: <alpine.LRH.2.03.1408211150020.1807@reclus.nhh.no>
References: <CAEdPBsGcPNazXJbV-BWxFZPARP1NGa6Vou9oKmNXiyUn3Qqm5Q@mail.gmail.com>
	<alpine.LRH.2.03.1408211150020.1807@reclus.nhh.no>
Message-ID: <CAEdPBsFuOtQD5DQYsQj6ust5WvHVYbhdfT4yw3wXtwA-47KkmQ@mail.gmail.com>

Many thanks for this, Roger.  Answers my question; raises a few more.
Life's like that sometimes!

 - Steve.
Steve Pickering
Assistant Professor
Graduate School of Law
Kobe University
2-1 Rokkodai-cho
Nada-ku, Kobe
657-8501 Japan
pickering at penguin.kobe-u.ac.jp
http://www.stevepickering.net
*** This year's Conflict Research Society Conference is at the
University of Leeds, from 2-4 September, and you should go to it.
http://www.crsconference.net  ***


On 21 August 2014 19:15, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> On Thu, 21 Aug 2014, Steve Pickering wrote:
>
>> Hello, all,
>>
>> Sorry for the silly question.
>>
>> I'm struggling to apply spatial lags to a data grid.  I've been
>> working through the notes on Luc Anselin's spdep, but just can't
>> figure out how to apply it to gridded data.
>>
>> Consider the following very simple 5 x 5 grid:
>>
>> ids <- c(1:25)
>> lats <-
>> c(30,30,30,30,30,31,31,31,31,31,32,32,32,32,32,33,33,33,33,33,34,34,34,34,34)
>> lngs <-
>> c(10,11,12,13,14,10,11,12,13,14,10,11,12,13,14,10,11,12,13,14,10,11,12,13,14)
>> conflict <- c(0,0,0,0,0,0,0,0,1,0,0,0,1,1,0,0,1,0,0,0,0,0,0,0,0)
>> conflictLag <-
>> c(0,0,0.125,0.125,0.125,0,0.125,0.375,0.25,0.25,0.125,0.25,0.375,0.25,0.25,0.125,0.125,0.375,0.25,0.125,0.125,0.125,0.125,0,0)
>> pop <- sample(100, 25)
>>
>> newGrid = data.frame(ids, lats, lngs, conflict, conflictLag, pop)
>>
>> Here, I have a conflict dummy, to determine whether there was some
>> sort of conflict or war in that grid cell.  I also have a population
>> variable (for the purposes of this exercise, determined at random).
>>
>> If I wanted to run a regression on this without including spatial
>> lags, I could do something very simple, like this:
>>
>> model1 = lm(newGrid$conflict ~ newGrid$pop)
>> summary(model1)
>
>
> Thanks for the toy example:
>
> set.seed(1)
>
> pop <- sample(100, 25)
> newGrid = data.frame(ids, lats, lngs, conflict, conflictLag, pop)
> model1 = lm(conflict ~ pop, data=newGrid)
> summary(model1)
>
> Then make a spatial object:
>
> library(sp)
> coordinates(newGrid) <- c("lngs", "lats")
> gridded(newGrid) <- TRUE
> image(newGrid, "conflict")
>
> Create a list of neighbours (here ignoring the possibility that the grid is
> in geographical, not projected coordinates:
>
> library(spdep)
> nb <- dnearneigh(newGrid, 0, sqrt(2))
> summary(nb)
> plot(nb, coordinates(newGrid), add=TRUE)
>
> Choose a model and fitting function:
>
> model2 <- spautolm(conflict ~ pop, data=newGrid, listw=nb2listw(nb,
>  style="W"), family="SAR")
> summary(model2)
>
> but note that conflict is not a continuous variable, so:
>
> model1a = glm(conflict ~ pop, data=newGrid, family=binomial(link=probit))
> summary(model1a)
>
> and
>
> library(spatialprobit)
> W <- as(as_dgRMatrix_listw(nb2listw(nb, style="W")), "CsparseMatrix")
> model2a <- semprobit(conflict ~ pop, W=W, data=newGrid)
> summary(model2a)
>
> which uses MCMC, so is slow. Alternatively, but for the spatially lagged
> response, not for the spatially lagged error term:
>
> model2b <- sarprobit(conflict ~ pop, W=W, data=newGrid)
> summary(model2b)
>
> This object includes effects/impacts (see LeSage & Pace 2009, or Ward &
> Gleditsch 2008).
>
> library(McSpatial)
> model2c <- spprobit(conflict ~ pop, wmat=nb2mat(nb), data=newGrid)
> model2d <- spprobitml(conflict ~ pop, wmat=nb2mat(nb), data=newGrid)
>
> use GMM and ML respectively and do not provide impacts. A recent paper in
> Journal of Regional Science compares spatial probit estimation approaches.
> In addition, the tally of 0 conflicts is 4 of 25, so your data may well also
> be zero-inflated.
>
> Spatial misspecification is possibly only a minor problem, really.
>
> Hope this helps,
>
> Roger
>
>
>>
>> However, I know that I am supposed to include a spatial lag.  As you
>> can see in the code, I have also created a spatial lag variable based
>> on whether there was conflict in adjacent cells (Queen's move, hence a
>> fraction of eight).
>>
>> What I'm struggling with is the correct way to include the spatial lag
>> in my model.
>>
>> Thanks, and sorry for the simple question.
>>
>> - Steve.
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no
>


From sandeep.pulla at gmail.com  Fri Aug 22 07:44:05 2014
From: sandeep.pulla at gmail.com (Sandeep Pulla)
Date: Fri, 22 Aug 2014 11:14:05 +0530
Subject: [R-sig-Geo] gstat trend beta ignored?
In-Reply-To: <53F5AA53.8060502@uni-muenster.de>
References: <CAPGZjC=k5fndSVfAQzODU6PODKY2Vj+yDmeqqozAB1FYGRJEoQ@mail.gmail.com>
	<53F5AA53.8060502@uni-muenster.de>
Message-ID: <CAPGZjC=tHXG=enJ2aSj=vUnHvd4m3=B5pXmFngWkb=QX68mVJA@mail.gmail.com>

Thanks for the clarifications, Edzer.

Actually I was passing the parameters ('beta' and 'gls'; the latter
inside 'set') to create gstat objects that are then passed on to
variogram() and predict(). Because variogram() respects 'set', I
assumed that would also be the case with predict() (the idea here was
to retrieve the trend predictions and beta that were used internally
by gstat prior to variogram estimation). If it is working as designed,
perhaps a note can be added to the documentation for predict()
indicating that GLS is always used? Alternately, and especially if
there is no other way to retrieve OLS trend predictions, perhaps
predict() could switch between using OLS/GLS depending on the 'gls'
flag?

Regarding documentation, I'm using gstat 1.0-19 for R. For 'set', the
user is referred to the gstat standalone user's manual (I'm using
v2.5.1 April 2014). I had interpreted the following to mean that
estimation by GLS or OLS is overridden when trend beta are specified:
   "set gls=1; use generalised least squares residuals instead of the
default ordinary least squares (OLS) residuals for sample variograms
or covariograms [0, use OLS or WLS residuals]"
   "trend.beta - vector with trend coefficients, in case they are
known. By default, trend coefficients are estimated from the data"
A minor change to the documentation would eliminate any doubt,
although it *could* be argued that always letting any specified beta
override trend estimation (regardless of GLS/OLS) would be less
surprising to a user.

Thanks,
Sandeep

On Thu, Aug 21, 2014 at 1:44 PM, Edzer Pebesma
<edzer.pebesma at uni-muenster.de> wrote:
>
> Sandeep, before you ask whether certain bugs are known it is often more
> constructive to start the discussion about whether there is agreement
> that your findings point to bugs.
>
> As of your point 2, this is according to documentation: beta is not in
> the parameter list of predict.gstat, hence is absorbed by ..., and ...
> according to the documentation is ignored. If you expect, or wished for
> other behaviour, that would be a feature request.
>
> As of point 1, in the call to variogram() specifying gls=1 asks for
> generalized least squares _estimation_ of the trend coefficients,
> specifying beta means that you know, hence don't want to estimate these
> coefficients. This indicates some misunderstanding of what you could do,
> or what you expect the software to do. The right behaviour would be to
> generate an error message.
>
> If you could point me to the relevant sections in the documentation that
> made you believe that something useful should happen ("GLS + beta
> specified") then I would be happy to learn about that.
>
>
> On 08/21/2014 08:12 AM, Sandeep Pulla wrote:
> > There appear to be couple of problems in specifying known trend
> > coefficients in gstat. Specifically,
> > 1. The 'beta' parameter seems to be ignored when the 'gls' parameter is 1.
> > 2. The 'beta' parameter is ignored by predict.gstat() (regardless of the
> > 'gls' parameter).
> >
> > Here's a full example:
> >
> > library(gstat)
> > library(sp) # for coordinates()
> > library(geoR) # for grf()
> > n = 20 ^ 2 # number of observations
> > xmin = ymin = 0; xmax = ymax = 2 # rectangular domain
> > trend.beta = c(pi, exp(1), -exp(1)) # linear trend-surface coefficients
> > trend.surf = cbind(1, as.matrix(expand.grid(x = seq(xmin, xmax, len =
> > sqrt(n)),
> >   y = seq(xmin, ymax, len = sqrt(n))))) %*% trend.beta
> > set.seed(100)
> > field = grf(n, "reg", xlims = c(xmin, xmax), ylims = c(ymin, ymax),
> > cov.model = "mat",
> >   cov.pars = c(1, .1), kappa = 1, nugget = .5, mean = trend.surf)
> > dat = data.frame(var = field$data, field$coords, intercept = 1)
> > coordinates(dat) = ~ x + y
> > vgm.mod = vgm(1, "Mat", .5, 1)
> > # Trend surface predictions to retrieve beta (see demo(blue))
> > pred.grid = data.frame(intercept = c(1, 0, 0), x = c(0, 1, 0), y = c(0, 0,
> > 1))
> > coordinates(pred.grid) = ~ x + y
> > # OK: Trend beta are estimated using OLS
> > plot(plot(variogram(gstat(NULL, "var", var ~ x + y, data = dat,
> >   model = vgm.mod, set = list(gls = 0))), main = "OLS"))
> > # OK: Predefined trend beta are used
> > plot(plot(variogram(gstat(NULL, "var", var ~ x + y, data = dat,
> >   model = vgm.mod, set = list(gls = 0), beta = c(20, 10, -10))),
> >   main = "OLS + predefined"))
> > # OK: Trend beta are estimated using GLS
> > plot(plot(variogram(gstat(NULL, "var", var ~ x + y, data = dat,
> >   model = vgm.mod, set = list(gls = 1))), main = "GLS"))
> > # BUG: Predefined trend beta are ignored
> > plot(plot(variogram(gstat(NULL, "var", var ~ x + y, data = dat,
> >   model = vgm.mod, set = list(gls = 1), beta = c(20, 10, -10))),
> >   main = "GLS + predefined"))
> > # BUG: Predefined trend beta are ignored
> > print(predict(gstat(NULL, "var", var ~ x + y + intercept - 1, data = dat,
> >     model = vgm.mod, set = list(gls = 1), beta = c(20, 10, -10)),
> >   pred.grid, BLUE = T)@data$var.pred)
> > # BUG: 'gls' option is ignored (uses GLS instead of OLS for trend
> > estimation)
> > print(predict(gstat(NULL, "var", var ~ x + y + intercept - 1, data = dat,
> >     model = vgm.mod, set = list(gls = 0)),
> >   pred.grid, BLUE = T)@data$var.pred)
> >
> > Are these known bugs?
> >
> > Thanks,
> > Sandeep
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
> --
> Edzer Pebesma
> Institute for Geoinformatics (ifgi), University of M?nster
> Heisenbergstra?e 2, 48149 M?nster, Germany. Phone: +49 251
> 83 33081 http://ifgi.uni-muenster.de GPG key ID 0xAC227795
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From paul.ziyu.ma at gmail.com  Fri Aug 22 09:15:28 2014
From: paul.ziyu.ma at gmail.com (Ziyu Ma)
Date: Fri, 22 Aug 2014 09:15:28 +0200
Subject: [R-sig-Geo] Question with spplot for publication
Message-ID: <CAK3B57jPuCKS3rHW4+srik_Hsx+7qGas+KYZ4hpjE5xn+iAe=w@mail.gmail.com>

Dear all,

I miss you guys from GEOSTAT Bergen!

Here's my question: I want to make a map directly from R for my manuscript,
using a raster layer overlaid with spatial polygons as outlines.

Please see the attachment for what I mean: http://1drv.ms/1sYYqPg

I did the upper plot in the attachement using these codes:

NRI = stack(NRI.A,NRI.G)  # NRI.A and NRI.G are raster layer names
names(NRI) = c("Angiosperms NRI", "Gymnosperms NRI")
spplot(NRI)


I need to put two rasters together in spplot because I want to use the same
legend scale.

I also want to add the outlines, so that it can look like the Photoshopped
plot in the attachment.

Normally, if not using spplot, I can do this:

plot(NRI.G) # NRI.G is a raster layer
plot(Outlines)  # Outlines is a SpatialPolygons object


But how can I do it for both panels in spplot? I think the panels and
titles in spplot are very neat, so it is preferred if there is a straight
forward way to tweak the settings.

Or should I use other functions than spplot? (e.g. try coding the color
scheme of the 2 plots and place them side by side?)

Thank you for the help. I really appreciate those who made R able to
produce publication quality plots.

Cheers,
Ma?

Ziyu Ma
PhD Student
Ecoinformatics & Biodiversity,
Department of Bioscience, Aarhus University
Ny Munkegade 114, DK-8000 Aarhus C, Denmark

	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Fri Aug 22 09:38:21 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 22 Aug 2014 09:38:21 +0200
Subject: [R-sig-Geo] Question with spplot for publication
In-Reply-To: <CAK3B57jPuCKS3rHW4+srik_Hsx+7qGas+KYZ4hpjE5xn+iAe=w@mail.gmail.com>
References: <CAK3B57jPuCKS3rHW4+srik_Hsx+7qGas+KYZ4hpjE5xn+iAe=w@mail.gmail.com>
Message-ID: <alpine.LRH.2.03.1408220920500.14362@reclus.nhh.no>

On Fri, 22 Aug 2014, Ziyu Ma wrote:

> Dear all,
>
> I miss you guys from GEOSTAT Bergen!
>
> Here's my question: I want to make a map directly from R for my manuscript,
> using a raster layer overlaid with spatial polygons as outlines.

Typically, you use the sp.layout= argument to spplot. This takes a list of 
extra information to be plotted. However, spatial polygons are thought of 
as filled, so you should coerce then to SpatialLines first:

spl <- list("sp.lines", as(my_polys, "SpatialLines"), lwd=2, col="white")

then

spplot(..., sp.layout=spl)

or a list of lists if there are other kinds of information to add.

Hope this helps,

Roger

>
> Please see the attachment for what I mean: http://1drv.ms/1sYYqPg
>
> I did the upper plot in the attachement using these codes:
>
> NRI = stack(NRI.A,NRI.G)  # NRI.A and NRI.G are raster layer names
> names(NRI) = c("Angiosperms NRI", "Gymnosperms NRI")
> spplot(NRI)
>
>
> I need to put two rasters together in spplot because I want to use the same
> legend scale.
>
> I also want to add the outlines, so that it can look like the Photoshopped
> plot in the attachment.
>
> Normally, if not using spplot, I can do this:
>
> plot(NRI.G) # NRI.G is a raster layer
> plot(Outlines)  # Outlines is a SpatialPolygons object
>
>
> But how can I do it for both panels in spplot? I think the panels and
> titles in spplot are very neat, so it is preferred if there is a straight
> forward way to tweak the settings.
>
> Or should I use other functions than spplot? (e.g. try coding the color
> scheme of the 2 plots and place them side by side?)
>
> Thank you for the help. I really appreciate those who made R able to
> produce publication quality plots.
>
> Cheers,
> Ma?
>
> Ziyu Ma
> PhD Student
> Ecoinformatics & Biodiversity,
> Department of Bioscience, Aarhus University
> Ny Munkegade 114, DK-8000 Aarhus C, Denmark
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no

From jon.skoien at jrc.ec.europa.eu  Fri Aug 22 09:45:25 2014
From: jon.skoien at jrc.ec.europa.eu (Jon Skoien)
Date: Fri, 22 Aug 2014 09:45:25 +0200
Subject: [R-sig-Geo] Question with spplot for publication
In-Reply-To: <CAK3B57jPuCKS3rHW4+srik_Hsx+7qGas+KYZ4hpjE5xn+iAe=w@mail.gmail.com>
References: <CAK3B57jPuCKS3rHW4+srik_Hsx+7qGas+KYZ4hpjE5xn+iAe=w@mail.gmail.com>
Message-ID: <53F6F515.50909@jrc.ec.europa.eu>

Hi Ma,

You should be able to plot the polygon on top of your raster with a 
panel function. Here is an example with the meuse data:

r <- raster(system.file("external/test.grd", package="raster"))
s <- stack(r, r*2)
names(s) <- c('meuse', 'meuse x 2')
spplot(s)
data(meuse.riv)

meuse.sr = 
SpatialPolygons(list(Polygons(list(Polygon(meuse.riv)),"meuse.riv")))

spplot(s,
   panel = function(x, y, ...) {
     panel.gridplot(x, y, ...)
     sp.polygons(meuse.sr)
   }
)

Is this more or less how you want it?

Cheers,
Jon


On 8/22/2014 9:15 AM, Ziyu Ma wrote:
> Dear all,
>
> I miss you guys from GEOSTAT Bergen!
>
> Here's my question: I want to make a map directly from R for my manuscript,
> using a raster layer overlaid with spatial polygons as outlines.
>
> Please see the attachment for what I mean: http://1drv.ms/1sYYqPg
>
> I did the upper plot in the attachement using these codes:
>
> NRI = stack(NRI.A,NRI.G)  # NRI.A and NRI.G are raster layer names
> names(NRI) = c("Angiosperms NRI", "Gymnosperms NRI")
> spplot(NRI)
>
>
> I need to put two rasters together in spplot because I want to use the same
> legend scale.
>
> I also want to add the outlines, so that it can look like the Photoshopped
> plot in the attachment.
>
> Normally, if not using spplot, I can do this:
>
> plot(NRI.G) # NRI.G is a raster layer
> plot(Outlines)  # Outlines is a SpatialPolygons object
>
>
> But how can I do it for both panels in spplot? I think the panels and
> titles in spplot are very neat, so it is preferred if there is a straight
> forward way to tweak the settings.
>
> Or should I use other functions than spplot? (e.g. try coding the color
> scheme of the 2 plots and place them side by side?)
>
> Thank you for the help. I really appreciate those who made R able to
> produce publication quality plots.
>
> Cheers,
> Ma?
>
> Ziyu Ma
> PhD Student
> Ecoinformatics & Biodiversity,
> Department of Bioscience, Aarhus University
> Ny Munkegade 114, DK-8000 Aarhus C, Denmark
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From paul.ziyu.ma at gmail.com  Fri Aug 22 10:50:12 2014
From: paul.ziyu.ma at gmail.com (Ziyu Ma)
Date: Fri, 22 Aug 2014 10:50:12 +0200
Subject: [R-sig-Geo] Question with spplot for publication
In-Reply-To: <53F6F515.50909@jrc.ec.europa.eu>
References: <CAK3B57jPuCKS3rHW4+srik_Hsx+7qGas+KYZ4hpjE5xn+iAe=w@mail.gmail.com>
	<53F6F515.50909@jrc.ec.europa.eu>
Message-ID: <CAK3B57gbjcJUkkYgCDk-3mq0QKkxsVWMbZwRkUQ2v2BhiaR1Xw@mail.gmail.com>

Thanks Jon and Roger!

The panel function worked effortlessly!
And I learned a lot from your codes.

Cheers,
Ma

Ziyu Ma
PhD Student
Ecoinformatics & Biodiversity,
Department of Bioscience, Aarhus University
Ny Munkegade 114, DK-8000 Aarhus C, Denmark



On Fri, Aug 22, 2014 at 9:45 AM, Jon Skoien <jon.skoien at jrc.ec.europa.eu>
wrote:

> Hi Ma,
>
> You should be able to plot the polygon on top of your raster with a panel
> function. Here is an example with the meuse data:
>
> r <- raster(system.file("external/test.grd", package="raster"))
> s <- stack(r, r*2)
> names(s) <- c('meuse', 'meuse x 2')
> spplot(s)
> data(meuse.riv)
>
> meuse.sr = SpatialPolygons(list(Polygons(list(Polygon(meuse.riv)),"
> meuse.riv")))
>
> spplot(s,
>   panel = function(x, y, ...) {
>     panel.gridplot(x, y, ...)
>     sp.polygons(meuse.sr)
>   }
> )
>
> Is this more or less how you want it?
>
> Cheers,
> Jon
>
>
>
> On 8/22/2014 9:15 AM, Ziyu Ma wrote:
>
>> Dear all,
>>
>> I miss you guys from GEOSTAT Bergen!
>>
>> Here's my question: I want to make a map directly from R for my
>> manuscript,
>> using a raster layer overlaid with spatial polygons as outlines.
>>
>> Please see the attachment for what I mean: http://1drv.ms/1sYYqPg
>>
>> I did the upper plot in the attachement using these codes:
>>
>> NRI = stack(NRI.A,NRI.G)  # NRI.A and NRI.G are raster layer names
>> names(NRI) = c("Angiosperms NRI", "Gymnosperms NRI")
>> spplot(NRI)
>>
>>
>> I need to put two rasters together in spplot because I want to use the
>> same
>> legend scale.
>>
>> I also want to add the outlines, so that it can look like the Photoshopped
>> plot in the attachment.
>>
>> Normally, if not using spplot, I can do this:
>>
>> plot(NRI.G) # NRI.G is a raster layer
>> plot(Outlines)  # Outlines is a SpatialPolygons object
>>
>>
>> But how can I do it for both panels in spplot? I think the panels and
>> titles in spplot are very neat, so it is preferred if there is a straight
>> forward way to tweak the settings.
>>
>> Or should I use other functions than spplot? (e.g. try coding the color
>> scheme of the 2 plots and place them side by side?)
>>
>> Thank you for the help. I really appreciate those who made R able to
>> produce publication quality plots.
>>
>> Cheers,
>> Ma?
>>
>> Ziyu Ma
>> PhD Student
>> Ecoinformatics & Biodiversity,
>> Department of Bioscience, Aarhus University
>> Ny Munkegade 114, DK-8000 Aarhus C, Denmark
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>
>

	[[alternative HTML version deleted]]


From potts.a at gmail.com  Fri Aug 22 13:12:36 2014
From: potts.a at gmail.com (Alastair Potts)
Date: Fri, 22 Aug 2014 13:12:36 +0200
Subject: [R-sig-Geo] Randomly moving a locality (within set limits)
Message-ID: <CAG_8N1YkczrHxWi6skkNJqwt6Uy6MmKNYxRUbySz163_x_dFAw@mail.gmail.com>

Hi all,

I was wondering if someone could help point me in the right direction here
- I can't seem to find a function or post that focuses on this.

I have localities around the world. I want to be able to randomly move a
given locality within a set radius (defined by km). So, I have a point at
xy and want it to be shifted to some other locality within, say, 15 km of
of its current locality.

This is simple enough using something like runif(1,-15,15), but it's the
lat-long conversion that is confusing me (how to work out how many decimal
degrees this might be around the point at different global localities).

Any help or pointers would be greatly appreciated.

Thanks in advance,

Cheers,
Alastair

	[[alternative HTML version deleted]]


From trichter at uni-bremen.de  Fri Aug 22 15:25:03 2014
From: trichter at uni-bremen.de (Tim Richter-Heitmann)
Date: Fri, 22 Aug 2014 15:25:03 +0200
Subject: [R-sig-Geo] Beginner's question on choosing the correct test, part.2
In-Reply-To: <53F60AED.7060509@uni-bremen.de>
References: <53F60AED.7060509@uni-bremen.de>
Message-ID: <53F744AF.6040909@uni-bremen.de>

Excuse my beginner level-questions.
I am stuck at the beginning, i.e. choosing the correct neighbor lists. I 
tried knearneigh (with several "k"s), tri2nb, and dnearneigh. Yesterday, 
i was nicely shown that in some datasets the nblist creation process is 
not always impactful, but it seems
for my data, it does matter.


My original plot consists of 59 points semi-regularily distributed on a 
10x10m area. Points are allocated, that some points have two absolute 
nearest neighbours, others just one.
The min distance is 50 cm, the highest is about 12m.
My question is if bacterial communities sampled at these plots follow 
non-random spatial processes. I will repeat that for every abundant 
species in each population.

Here are nb plots (from top to bottom):

http://s2.postimg.org/tkxqw82ih/image.jpg

1. Original coords list
2. *from tri2nb* from non-randomised x,y matrix
3. *from tri2nb* from a randomised coordinates list
4. *from dnearneigh* from the original coordinates list
5. from knearneigh with k=10


The help file on tri2nb recommended to do a row randomisation for some 
data, so i did that, although i assume that my first three x,y points 
should be easily triangled:

>coords[1:3,]
           x    y
  [1,] 0.835 8.75
  [2,] 0.835 8.25
  [3,] 2.505 8.75


knn plots totally varied depending on the chosen "k". I just cannot 
"feel" what the correct the k is for my purpose. I tested severals k 
between 2 and 30, and the moran.mc yielded all significant test 
statistics approaching 1 with decreasing neighbours
(which makes sense, i guess).

So, the question is, what it is the most approbiate neighbor list? The 
same question goes to the next step, the nb2listw and the style 
selection. Because pre-hoc, i cannot say if i want to weight something. 
All points are equally important.
I also do not know (yet) the underlying spatial process here. In the 
end, i need a robust indicator if my species data shows spatial 
autocorrelation or not.

Here is the code i used:

library(spdep)

/#apr.D is my x,y list; ap is my species matrix/

coords <- coordinates(apr.D)
coords.rand <-coords[sample(nrow(coords)),]

/#distances for dnearneigh/
ap.dis <- dist(coords)
min.dist <- min(unlist(dist(coords)))
max.dist <-  max(unlist(dist(coords)))

/#creating nb lists/
tri <- tri2nb(coords)
tri.rand <- tri2nb(coords.rand)
dnn <- dnearneigh(coords, min.dist, max.dist)
knn10 <- knearneigh(coords, k=10)

*I carried out a nb2listw  for each of the methods above with default 
options, and then a permutated moran I test on the first species in 
dataset, as it is not normally distributed:*

list1 <- nb2listw(tri)
list2 <- nb2listw(tri.rand)
list3 <- nb2listw(dnn)
list4 <- nb2listw(knn2nb(knn10))

moran.mc(ap[,1], list1, nsim=999)
moran.mc(ap[,1], list2, nsim=999)
moran.mc(ap[,1], list3, nsim=999)
moran.mc(ap[,1], list4, nsim=999)

*Here is the output*

>moran.mc(ap[,1], list1, nsim=999)

	Monte-Carlo simulation of Moran's I

data:  ap[, 1]
weights: list1  (tri)
number of simulations + 1: 1000

statistic = 0.8924, observed rank = 1000, p-value = 0.001
alternative hypothesis: greater

>moran.mc(ap[,1], list2, nsim=999)

	Monte-Carlo simulation of Moran's I

data:  ap[, 1]
weights: list2  (tri.rand)
number of simulations + 1: 1000

statistic = 0.0598, observed rank = 859, p-value = 0.141
alternative hypothesis: greater

>moran.mc(ap[,1], list3, nsim=999)

	Monte-Carlo simulation of Moran's I

data:  ap[, 1]
weights: list3  (dnn)
number of simulations + 1: 1000

statistic = -0.0358, observed rank = 1, p-value = 0.999
alternative hypothesis: greater

>moran.mc(ap[,1], list4, nsim=999)

	Monte-Carlo simulation of Moran's I

data:  ap[, 1]
weights: list4  (knn, k=10)
number of simulations + 1: 1000

statistic = 0.8194, observed rank = 1000, p-value = 0.001
alternative hypothesis: greater




As you can see, the results are different, and the randomisation had 
much impact on the triangled neighbour list. tir2nb and knn seem to be 
in agreement. Judging from the plots, the dnn-derived list seems to do 
many different distances, which might clog the analysis.  I tried all 
possible options of style to the nb2listw, and they didnt impact the 
effective result. So, the biggest question is, what would be the most 
approbiate
approach to create a nblist?


I really need some expert advise here. Thank you very much!

Tim





-


	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Fri Aug 22 17:58:14 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 22 Aug 2014 15:58:14 +0000
Subject: [R-sig-Geo] Randomly moving a locality (within set limits)
In-Reply-To: <CAG_8N1YkczrHxWi6skkNJqwt6Uy6MmKNYxRUbySz163_x_dFAw@mail.gmail.com>
References: <CAG_8N1YkczrHxWi6skkNJqwt6Uy6MmKNYxRUbySz163_x_dFAw@mail.gmail.com>
Message-ID: <D01CB44F.10828B%macqueen1@llnl.gov>

My first thought would be to use spTransform() to convert to a (local)
cartesian coordinate system, do the shift [perhaps using
maptools::elide()], and then convert back.

Identifying appropriate (local) coordinate systems for each locality could
be a chore, but other than that it looks to me like a conceptually simple
process.

elide() will, I believe, remove the proj4string from the elided object so
you?d have to put it back in afterwards. Maybe calculating on the
coordinates would be easier, but that would depend on what kind of Spatial
objects your localities are.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 8/22/14, 4:12 AM, "Alastair Potts" <potts.a at gmail.com> wrote:

>Hi all,
>
>I was wondering if someone could help point me in the right direction here
>- I can't seem to find a function or post that focuses on this.
>
>I have localities around the world. I want to be able to randomly move a
>given locality within a set radius (defined by km). So, I have a point at
>xy and want it to be shifted to some other locality within, say, 15 km of
>of its current locality.
>
>This is simple enough using something like runif(1,-15,15), but it's the
>lat-long conversion that is confusing me (how to work out how many decimal
>degrees this might be around the point at different global localities).
>
>Any help or pointers would be greatly appreciated.
>
>Thanks in advance,
>
>Cheers,
>Alastair
>
>	[[alternative HTML version deleted]]
>
>_______________________________________________
>R-sig-Geo mailing list
>R-sig-Geo at r-project.org
>https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From b.rowlingson at lancaster.ac.uk  Fri Aug 22 18:59:24 2014
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 22 Aug 2014 17:59:24 +0100
Subject: [R-sig-Geo] Randomly moving a locality (within set limits)
In-Reply-To: <232e5dbae9014a48b3f1a292063b4251@EX-1-HT0.lancs.local>
References: <CAG_8N1YkczrHxWi6skkNJqwt6Uy6MmKNYxRUbySz163_x_dFAw@mail.gmail.com>
	<232e5dbae9014a48b3f1a292063b4251@EX-1-HT0.lancs.local>
Message-ID: <CANVKczNL+wrV=OtHbatcy1k_J-MieuHSUNxSze98-UsAtG+vDw@mail.gmail.com>

On Fri, Aug 22, 2014 at 4:58 PM, MacQueen, Don <macqueen1 at llnl.gov> wrote:
> My first thought would be to use spTransform() to convert to a (local)
> cartesian coordinate system, do the shift [perhaps using
> maptools::elide()], and then convert back.
>
> Identifying appropriate (local) coordinate systems for each locality could
> be a chore, but other than that it looks to me like a conceptually simple
> process.

This SO question:
http://stackoverflow.com/questions/9186496/determining-utm-zone-to-convert-from-longitude-latitude

has a simple formula for computing the UTM longitude zone:

long2UTM <- function(long) {
    (floor((long + 180)/6) %% 60) + 1
}

SFlong <- -122.4192
long2UTM(SFlong)
# [1] 10

So San Francisco (at that longitude) is in UTM 10 zone, which is epsg
code 32600 + 10 (for WGS84 spheroids). So the CRS string is
"+init=epsg:32610". You can construct this in R with a bit of
paste-fu.

For things in the southern hemisphere its 32700+zone number. See here:

http://spatialreference.org/ref/epsg/32610/
http://spatialreference.org/ref/epsg/32710/

That gets you a coordinate system in metres, don't forget to multiply
by 1000 to get km!

Here's a complete and slightly untested function (surely this exists
somewhere..):

 UTMzone = function(lat,long){
z = (floor((long + 180)/6) %% 60) + 1
 ns = ifelse(lat>=0,32600,32700)
 paste("+init=epsg:",ns+z,sep="")
 }

Here's the UTM zones it thinks are for a bunch of +10degree latitude
points across the globe:

> UTMzone(10,seq(-180,180,len=20))
 [1] "+init=epsg:32601" "+init=epsg:32604" "+init=epsg:32607" "+init=epsg:32610"
 [5] "+init=epsg:32613" "+init=epsg:32616" "+init=epsg:32619" "+init=epsg:32623"
 [9] "+init=epsg:32626" "+init=epsg:32629" "+init=epsg:32632" "+init=epsg:32635"
[13] "+init=epsg:32638" "+init=epsg:32642" "+init=epsg:32645" "+init=epsg:32648"
[17] "+init=epsg:32651" "+init=epsg:32654" "+init=epsg:32657" "+init=epsg:32601"

they look plausible, but may or may not be right, I've not checked...

Barry


From Roger.Bivand at nhh.no  Fri Aug 22 21:31:01 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 22 Aug 2014 21:31:01 +0200
Subject: [R-sig-Geo] Beginner's question on choosing the correct test,
 part.2
In-Reply-To: <53F744AF.6040909@uni-bremen.de>
References: <53F60AED.7060509@uni-bremen.de> <53F744AF.6040909@uni-bremen.de>
Message-ID: <alpine.LRH.2.03.1408222104290.26874@reclus.nhh.no>

On Fri, 22 Aug 2014, Tim Richter-Heitmann wrote:

> Excuse my beginner level-questions.
> I am stuck at the beginning, i.e. choosing the correct neighbor lists. I
> tried knearneigh (with several "k"s), tri2nb, and dnearneigh. Yesterday,
> i was nicely shown that in some datasets the nblist creation process is
> not always impactful, but it seems
> for my data, it does matter.
>

You really need to consider more carefully which spatial processes are 
thought of as being present. Your assumption that using lattice-based 
approaches to possible spatial autocorrelation is sensible needs more 
thought.

>
> My original plot consists of 59 points semi-regularily distributed on a
> 10x10m area.

The area in question is 10x10m. What is the support of the observations 
(see Gotway & Young 2002 for definitions)? Are the observation points 
chosen by sampling, or are they representative points for a tesselation of 
the area? If they can be seen as a tesselation, they represent spatial 
objects, each with different observed levels of the variables of interest 
(are these counts of bacteria)? If the tesselation view is relevant, then 
a lattice-based view of autocorrelation using neighbours may make sense.

If, on the other hand, the observation points are locations from which 
samples have been taken (and samples could have been taken at other 
locations), we may rather be looking not at spatial objects but at a 
spatial field, with continuous spatial processes for which the idea of 
neighbours is less "natural". In this case, examining a variogram of the 
variable of interest, possibly qualified by background variables (a mean 
model) - this consideration applies to the lattice case too, may be more 
sensible.

If your data are more like observations from a field, where their placing 
across that continuous field could have been different, a geostatistical 
approach may make more sense. If they are lattice based with a tesselated 
form - think trial plots - then it is much easier to conceptualise 
neighbours.

A further open question is whether your variables of interest are 
presence/absence, count, or well-behaved hump-shaped continuous values.

Thw question of spatially structured random effects in modelling can be 
addressed in many ways, but I'm not convinced here that you cannot choose 
another approach, given that there is no obvious "neighbour" relationship. 
In addition, you have a time component, which I think suggests that the 
lattice approach may not be very helpful, especially as I think you 
said that the observed locations may change over time. I don't think that 
there is a quick fix for this.

Roger

> Points are allocated, that some points have two absolute
> nearest neighbours, others just one.
> The min distance is 50 cm, the highest is about 12m.
> My question is if bacterial communities sampled at these plots follow
> non-random spatial processes. I will repeat that for every abundant
> species in each population.
>
> Here are nb plots (from top to bottom):
>
> http://s2.postimg.org/tkxqw82ih/image.jpg
>
> 1. Original coords list
> 2. *from tri2nb* from non-randomised x,y matrix
> 3. *from tri2nb* from a randomised coordinates list
> 4. *from dnearneigh* from the original coordinates list
> 5. from knearneigh with k=10
>
>
> The help file on tri2nb recommended to do a row randomisation for some
> data, so i did that, although i assume that my first three x,y points
> should be easily triangled:
>
>> coords[1:3,]
>           x    y
>  [1,] 0.835 8.75
>  [2,] 0.835 8.25
>  [3,] 2.505 8.75
>
>
> knn plots totally varied depending on the chosen "k". I just cannot
> "feel" what the correct the k is for my purpose. I tested severals k
> between 2 and 30, and the moran.mc yielded all significant test
> statistics approaching 1 with decreasing neighbours
> (which makes sense, i guess).
>
> So, the question is, what it is the most approbiate neighbor list? The
> same question goes to the next step, the nb2listw and the style
> selection. Because pre-hoc, i cannot say if i want to weight something.
> All points are equally important.
> I also do not know (yet) the underlying spatial process here. In the
> end, i need a robust indicator if my species data shows spatial
> autocorrelation or not.
>
> Here is the code i used:
>
> library(spdep)
>
> /#apr.D is my x,y list; ap is my species matrix/
>
> coords <- coordinates(apr.D)
> coords.rand <-coords[sample(nrow(coords)),]
>
> /#distances for dnearneigh/
> ap.dis <- dist(coords)
> min.dist <- min(unlist(dist(coords)))
> max.dist <-  max(unlist(dist(coords)))
>
> /#creating nb lists/
> tri <- tri2nb(coords)
> tri.rand <- tri2nb(coords.rand)
> dnn <- dnearneigh(coords, min.dist, max.dist)
> knn10 <- knearneigh(coords, k=10)
>
> *I carried out a nb2listw  for each of the methods above with default
> options, and then a permutated moran I test on the first species in
> dataset, as it is not normally distributed:*
>
> list1 <- nb2listw(tri)
> list2 <- nb2listw(tri.rand)
> list3 <- nb2listw(dnn)
> list4 <- nb2listw(knn2nb(knn10))
>
> moran.mc(ap[,1], list1, nsim=999)
> moran.mc(ap[,1], list2, nsim=999)
> moran.mc(ap[,1], list3, nsim=999)
> moran.mc(ap[,1], list4, nsim=999)
>
> *Here is the output*
>
>> moran.mc(ap[,1], list1, nsim=999)
>
> 	Monte-Carlo simulation of Moran's I
>
> data:  ap[, 1]
> weights: list1  (tri)
> number of simulations + 1: 1000
>
> statistic = 0.8924, observed rank = 1000, p-value = 0.001
> alternative hypothesis: greater
>
>> moran.mc(ap[,1], list2, nsim=999)
>
> 	Monte-Carlo simulation of Moran's I
>
> data:  ap[, 1]
> weights: list2  (tri.rand)
> number of simulations + 1: 1000
>
> statistic = 0.0598, observed rank = 859, p-value = 0.141
> alternative hypothesis: greater
>
>> moran.mc(ap[,1], list3, nsim=999)
>
> 	Monte-Carlo simulation of Moran's I
>
> data:  ap[, 1]
> weights: list3  (dnn)
> number of simulations + 1: 1000
>
> statistic = -0.0358, observed rank = 1, p-value = 0.999
> alternative hypothesis: greater
>
>> moran.mc(ap[,1], list4, nsim=999)
>
> 	Monte-Carlo simulation of Moran's I
>
> data:  ap[, 1]
> weights: list4  (knn, k=10)
> number of simulations + 1: 1000
>
> statistic = 0.8194, observed rank = 1000, p-value = 0.001
> alternative hypothesis: greater
>
>
>
>
> As you can see, the results are different, and the randomisation had
> much impact on the triangled neighbour list. tir2nb and knn seem to be
> in agreement. Judging from the plots, the dnn-derived list seems to do
> many different distances, which might clog the analysis.  I tried all
> possible options of style to the nb2listw, and they didnt impact the
> effective result. So, the biggest question is, what would be the most
> approbiate
> approach to create a nblist?
>
>
> I really need some expert advise here. Thank you very much!
>
> Tim
>
>
>
>
>
> -
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From hengl at spatial-analyst.net  Sun Aug 24 13:17:09 2014
From: hengl at spatial-analyst.net (Tomislav Hengl)
Date: Sun, 24 Aug 2014 13:17:09 +0200
Subject: [R-sig-Geo] maptools/kmlPolygons not outputting all Polygon
	objects
In-Reply-To: <FDA6B65298E3664FACCCD6F34EB939E4160C9FF796@MAILUK2.rms.com>
References: <FDA6B65298E3664FACCCD6F34EB939E4160C9FF796@MAILUK2.rms.com>
Message-ID: <53F9C9B5.9010305@spatial-analyst.net>


I've tried creating a KML file using the plotKML package and I did not 
notice anything strange with Alaska:

 > data(wrld_simpl)
 > library(plotKML)
plotKML version 0.4-5 (2014-07-30)
URL: http://plotkml.r-forge.r-project.org/
 > kml(wrld_simpl, colour=NAME)

You can write KML file anyway you prefer also directly by using the XML 
package (and by using the "base::sprintf" command as in 
https://r-forge.r-project.org/scm/viewvc.php/pkg/R/layer.SpatialPolygons.R?view=markup&root=plotkml).

HTH,

T. Hengl

On 4-8-2014 18:23, Philip Haines wrote:
> Dear List,
>
> I am trying to output a a SpatialPolygonsDataFrame using the maptools:::kmlPolygons function. However, I am only able to get this function to output the first Polygon from each Polygons object.
>
> If I try the example given in the documentation
>
> library(maptools)
> data(wrld_simpl)
> kmlPolygons(wrld_simpl, kmlfile = "worldPolitical.kml", name = "KML Polygons",
>             description = "the world", col = "red",
>             visibility = 1, lwd = 1, border = "white", kmlname = "R Test",
>             kmldescription = "This is <b>only</b> a <a
> href='http://www.r-project.org'>R</a> test.")
>
> I notice that it contains an outline for the lower 48 states but does not contain an outline for Alaska (say).
>
> If this is not the correct place to post this query I would be grateful if you would both accept my apologies and point me in a more favourable direction. The world of spatial data objects remains a very new one to me!
>
> Thanks,
> Phil Haines
>
> Below is my output from the sessionInfo() command.
>
>> sessionInfo()
> R version 3.1.0 (2014-04-10)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United Kingdom.1252
> [3] LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C
> [5] LC_TIME=English_United Kingdom.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] maptools_0.8-30 sp_1.0-15
>
> loaded via a namespace (and not attached):
> [1] foreign_0.8-61  grid_3.1.0      lattice_0.20-29 tools_3.1.0
>
>
>
> This message and any attachments contain information that may be RMS Inc. confidential and/or privileged.  If you are not the intended recipient (or authorized to receive for the intended recipient), and have received this message in error, any use, disclosure or distribution is strictly prohibited.   If you have received this message in error, please notify the sender immediately by replying to the e-mail and permanently deleting the message from your computer and/or storage system.
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From frtog at vestas.com  Mon Aug 25 10:26:52 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Mon, 25 Aug 2014 10:26:52 +0200
Subject: [R-sig-Geo] Randomly moving a locality (within set limits)
In-Reply-To: <CAG_8N1YkczrHxWi6skkNJqwt6Uy6MmKNYxRUbySz163_x_dFAw@mail.gmail.com>
References: <CAG_8N1YkczrHxWi6skkNJqwt6Uy6MmKNYxRUbySz163_x_dFAw@mail.gmail.com>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C78D0354@DKRDSEXC016.vestas.net>


Hi

The following is based on http://www.movable-type.co.uk/scripts/latlong.html. 

foo <- function(origin, bearing, distance){
    ## origin (lat, lon) is the point to randomly move
    ## bearing (in degrees) is the direction in which to move
    ## the distance to move origin
    
    R = 6378.1 #Radius of the Earth in km

    bearing <- bearing/180 * pi
    
    lat1 = origin[1]/180 * pi #Current lat point converted to radians
    lon1 = origin[2]/180 * pi  #Current long point converted to radians
    
    lat2 = asin( sin(lat1)*cos(distance/R) +
        cos(lat1)*sin(distance/R)*cos(bearing))
    
    lon2 = lon1 + atan2(sin(bearing)*sin(distance/R)*cos(lat1),
        cos(distance/R)-sin(lat1)*sin(lat2))

    ## destination in degrees decimal
    destination <- c(Latitude = lat2/pi*180, Longitude = lon2/pi*180)
    
    return(destination)
}

> foo(c(52.20472, 0.14056), 90, 15)
  Latitude  Longitude 
52.2045157  0.3604334 
>

Now choose

bearing <- runif(1, 0, 360)

and

distance <- runif(1, 0, 15)

Please check the formulas against the homepage above.

Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 


> -----Original Message-----
> From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-
> project.org] On Behalf Of Alastair Potts
> Sent: 22. august 2014 13:13
> To: r-sig-geo at r-project.org
> Subject: [R-sig-Geo] Randomly moving a locality (within set limits)
> 
> Hi all,
> 
> I was wondering if someone could help point me in the right direction here
> - I can't seem to find a function or post that focuses on this.
> 
> I have localities around the world. I want to be able to randomly move a
> given locality within a set radius (defined by km). So, I have a point at
> xy and want it to be shifted to some other locality within, say, 15 km of
> of its current locality.
> 
> This is simple enough using something like runif(1,-15,15), but it's the
> lat-long conversion that is confusing me (how to work out how many decimal
> degrees this might be around the point at different global localities).
> 
> Any help or pointers would be greatly appreciated.
> 
> Thanks in advance,
> 
> Cheers,
> Alastair
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From b.rowlingson at lancaster.ac.uk  Mon Aug 25 10:48:09 2014
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon, 25 Aug 2014 09:48:09 +0100
Subject: [R-sig-Geo] Randomly moving a locality (within set limits)
In-Reply-To: <0ad0475eec1c48bbb095863a1bc8e238@EX-1-HT0.lancs.local>
References: <CAG_8N1YkczrHxWi6skkNJqwt6Uy6MmKNYxRUbySz163_x_dFAw@mail.gmail.com>
	<0ad0475eec1c48bbb095863a1bc8e238@EX-1-HT0.lancs.local>
Message-ID: <CANVKczPnpeZAF=9tXy8P4wGj4viQLfP4Q9bBdSzyoQ2=AmqV-w@mail.gmail.com>

> Now choose
>
> bearing <- runif(1, 0, 360)
>
> and
>
> distance <- runif(1, 0, 15)
>
> Please check the formulas against the homepage above.

 Note: choosing a random bearing U(0,360) and a random U(0,N) distance
 DOESNT generate a uniform distribution over the disk of radius N!
You get more points near the centre!

 Barry


From md.franklin at gmail.com  Mon Aug 25 10:59:13 2014
From: md.franklin at gmail.com (frankma)
Date: Mon, 25 Aug 2014 01:59:13 -0700 (PDT)
Subject: [R-sig-Geo] Error message when dissolving polygons
In-Reply-To: <1408956118252-7586977.post@n2.nabble.com>
References: <3C605470-14BA-4C5E-B15D-6C37C1F3CACC@gmail.com>
	<1408956118252-7586977.post@n2.nabble.com>
Message-ID: <1408957153972-7586979.post@n2.nabble.com>

Hi, 

I'm having the same issue. Did you manage to solve this? 

Thanks, 
Matt



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Error-message-when-dissolving-polygons-tp7586109p7586979.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From Roger.Bivand at nhh.no  Mon Aug 25 11:22:45 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 25 Aug 2014 11:22:45 +0200
Subject: [R-sig-Geo] Error message when dissolving polygons
In-Reply-To: <1408957153972-7586979.post@n2.nabble.com>
References: <3C605470-14BA-4C5E-B15D-6C37C1F3CACC@gmail.com>
	<1408956118252-7586977.post@n2.nabble.com>
	<1408957153972-7586979.post@n2.nabble.com>
Message-ID: <alpine.LRH.2.03.1408251103580.17748@reclus.nhh.no>

On Mon, 25 Aug 2014, frankma wrote:

> Hi,
>
> I'm having the same issue. Did you manage to solve this?

Please always quote the problem verbatim, providing a reproducible 
example. Even if anyone cares to open nabble to find the link, nobody can 
actually know whether your problem is the same. The reason we ask for 
reproducible examples is that the effort needed by the questioner to 
create a reproducible example means that he/she has to look more closely 
at - here "I?m following a tutorial found in the web" - what they are 
trying to do, and very often see their mistake themselves. Learning to 
debug one's own work is not easy, takes time, but wastes less of other 
peoples' time than asking lazy questions - see the posting guide:

http://www.r-project.org/posting-guide.html

It is also very helpful to see an affiliation, so that anyone caring to 
answer knows where to start. This is especially important when the 
sender's address is non-institutional.

In the original question:

https://stat.ethz.ch/pipermail/r-sig-geo/2014-April/020764.html

the obvious error was to think that the PolySet class in PBSmapping 
understands other projections than UTM:

# library(maptools)
# zm.* not available
> input = readShapePoly("zm.shp", proj4string=CRS("+proj=lcc +ellps=GRS80 
+datum=WGS84"))
> projectedpolygons = spTransform(input, CRS("+proj=lcc +ellps=GRS80 
+datum=WGS84"))
> zmprojPS = SpatialPolygons2PolySet(projectedpolygons)
> attr(zmprojPS, "projection") <- "LL"

I assume that no answer was posted because the error message was totally 
obvious, that is that lcc is Lambert conformal conic, but LL is the code 
for geographical, unprojected, coordinates, so PBSmapping could not 
project to UTM to calculate areas as:

"the mean longitude falls outside the range -180 < x <= 180."

If you are also mixing up projections, then this also explains what you 
are seeing.

Hope this clarifies,

Roger

>
> Thanks,
> Matt
>
>
>
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Error-message-when-dissolving-polygons-tp7586109p7586979.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no

From md.franklin at gmail.com  Mon Aug 25 11:50:40 2014
From: md.franklin at gmail.com (frankma)
Date: Mon, 25 Aug 2014 02:50:40 -0700 (PDT)
Subject: [R-sig-Geo] Error message when dissolving polygons
In-Reply-To: <alpine.LRH.2.03.1408251103580.17748@reclus.nhh.no>
References: <3C605470-14BA-4C5E-B15D-6C37C1F3CACC@gmail.com>
	<1408956118252-7586977.post@n2.nabble.com>
	<1408957153972-7586979.post@n2.nabble.com>
	<alpine.LRH.2.03.1408251103580.17748@reclus.nhh.no>
Message-ID: <1408960240976-7586981.post@n2.nabble.com>

My apologies Roger, thank you for letting me know the mailing list etiquette. 

I understand the gist of what you are saying but I'm still unsure which
projections I am mixing up. I am using the shapefile available here:
http://www.cso.ie/en/census/census2011boundaryfiles/

My code and error are below. I realise that it may seem obvious to you but
it isn't to me, I've spent hours trying to "dissolve polygons" and there is
something I am not understanding here, I am sorry for this. Appreciate your
response so far and any further help is very much appreciated, thank you. In
terms of affiliations I am currently trying to complete an MSc dissertation
at the University of Sheffield (UK) - I also work full time.


library(maptools)   # for geospatial services; also loads foreign and sp
library(gpclib)     # General Polygon Clipping library 
library(rgdal)      # for map projection work; also loads sp
library(PBSmapping) # for GIS_like geospatial object manipulation / anslysis
iIRLluding poly
# 
# Part 1:
# First example, derived from the maptools unionSpatialPolygon() method
documentation in the R 
# maptools user manual: We calculate and sum the area of each polygon in the
Ireland map. 
# Then, use unionSpatialPolygons() to dissolve the county polygon boundries,
and assign each
# polygon's area to one of four regions, based on longitude thresholds.
#
print("start of demo. Hit key...")
browser()
print("reading and transforming Ireland Shapefile...")
#
IRLBase <- readShapePoly("Shape/counties.shp",proj4string=CRS("+proj=aea
+ellps=GRS80 +datum=WGS84"))

#
# Transform the polygons (which were read in as unprojected geographic
coordinates)
# to an Albers Equal Area projection.
#
IRLProj = spTransform(IRLBase,CRS("+proj=aea +ellps=GRS80 +datum=WGS84"))
#
# Convert to a PolygonSet for compatability with PBSmapping package
routines.
#
IRLProjPS = SpatialPolygons2PolySet(IRLProj)
#
plotPolys(IRLProjPS, proj =
TRUE,col="wheat1",xlab="longitude",ylab="latitude")
#
# polygon area calculations
#
print("Calculating Ireland polygon areas...")
attr(IRLProjPS, "projection") <- "LL"
IRLPolyAreas = calcArea(IRLProjPS,rollup=1)

*Error in calcArea(IRLProjPS, rollup = 1) : 
  To calculate the areas of polygons defined by longitude-latitude
coordinates, this routine first projects them in UTM.

Attempted to automatically calculate the missing 'zone' attribute, but
that failed because the mean longitude falls outside the range
-180 < x <= 180.*

Thanks,
Matt



Roger Bivand wrote
> On Mon, 25 Aug 2014, frankma wrote:
> 
>> Hi,
>>
>> I'm having the same issue. Did you manage to solve this?
> 
> Please always quote the problem verbatim, providing a reproducible 
> example. Even if anyone cares to open nabble to find the link, nobody can 
> actually know whether your problem is the same. The reason we ask for 
> reproducible examples is that the effort needed by the questioner to 
> create a reproducible example means that he/she has to look more closely 
> at - here "I?m following a tutorial found in the web" - what they are 
> trying to do, and very often see their mistake themselves. Learning to 
> debug one's own work is not easy, takes time, but wastes less of other 
> peoples' time than asking lazy questions - see the posting guide:
> 
> http://www.r-project.org/posting-guide.html
> 
> It is also very helpful to see an affiliation, so that anyone caring to 
> answer knows where to start. This is especially important when the 
> sender's address is non-institutional.
> 
> In the original question:
> 
> https://stat.ethz.ch/pipermail/r-sig-geo/2014-April/020764.html
> 
> the obvious error was to think that the PolySet class in PBSmapping 
> understands other projections than UTM:
> 
> # library(maptools)
> # zm.* not available
>> input = readShapePoly("zm.shp", proj4string=CRS("+proj=lcc +ellps=GRS80 
> +datum=WGS84"))
>> projectedpolygons = spTransform(input, CRS("+proj=lcc +ellps=GRS80 
> +datum=WGS84"))
>> zmprojPS = SpatialPolygons2PolySet(projectedpolygons)
>> attr(zmprojPS, "projection") <- "LL"
> 
> I assume that no answer was posted because the error message was totally 
> obvious, that is that lcc is Lambert conformal conic, but LL is the code 
> for geographical, unprojected, coordinates, so PBSmapping could not 
> project to UTM to calculate areas as:
> 
> "the mean longitude falls outside the range -180 < x <= 180."
> 
> If you are also mixing up projections, then this also explains what you 
> are seeing.
> 
> Hope this clarifies,
> 
> Roger
> 
>>
>> Thanks,
>> Matt
>>
>>
>>
>> --
>> View this message in context:
>> http://r-sig-geo.2731867.n2.nabble.com/Error-message-when-dissolving-polygons-tp7586109p7586979.html
>> Sent from the R-sig-geo mailing list archive at Nabble.com.
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> 

> R-sig-Geo@

>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
> 
> -- 
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: 

> Roger.Bivand@

> 
> _______________________________________________
> R-sig-Geo mailing list

> R-sig-Geo@

> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


Roger Bivand wrote
> On Mon, 25 Aug 2014, frankma wrote:
> 
>> Hi,
>>
>> I'm having the same issue. Did you manage to solve this?
> 
> Please always quote the problem verbatim, providing a reproducible 
> example. Even if anyone cares to open nabble to find the link, nobody can 
> actually know whether your problem is the same. The reason we ask for 
> reproducible examples is that the effort needed by the questioner to 
> create a reproducible example means that he/she has to look more closely 
> at - here "I?m following a tutorial found in the web" - what they are 
> trying to do, and very often see their mistake themselves. Learning to 
> debug one's own work is not easy, takes time, but wastes less of other 
> peoples' time than asking lazy questions - see the posting guide:
> 
> http://www.r-project.org/posting-guide.html
> 
> It is also very helpful to see an affiliation, so that anyone caring to 
> answer knows where to start. This is especially important when the 
> sender's address is non-institutional.
> 
> In the original question:
> 
> https://stat.ethz.ch/pipermail/r-sig-geo/2014-April/020764.html
> 
> the obvious error was to think that the PolySet class in PBSmapping 
> understands other projections than UTM:
> 
> # library(maptools)
> # zm.* not available
>> input = readShapePoly("zm.shp", proj4string=CRS("+proj=lcc +ellps=GRS80 
> +datum=WGS84"))
>> projectedpolygons = spTransform(input, CRS("+proj=lcc +ellps=GRS80 
> +datum=WGS84"))
>> zmprojPS = SpatialPolygons2PolySet(projectedpolygons)
>> attr(zmprojPS, "projection") <- "LL"
> 
> I assume that no answer was posted because the error message was totally 
> obvious, that is that lcc is Lambert conformal conic, but LL is the code 
> for geographical, unprojected, coordinates, so PBSmapping could not 
> project to UTM to calculate areas as:
> 
> "the mean longitude falls outside the range -180 < x <= 180."
> 
> If you are also mixing up projections, then this also explains what you 
> are seeing.
> 
> Hope this clarifies,
> 
> Roger
> 
>>
>> Thanks,
>> Matt
>>
>>
>>
>> --
>> View this message in context:
>> http://r-sig-geo.2731867.n2.nabble.com/Error-message-when-dissolving-polygons-tp7586109p7586979.html
>> Sent from the R-sig-geo mailing list archive at Nabble.com.
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> 

> R-sig-Geo@

>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
> 
> -- 
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: 

> Roger.Bivand@

> 
> _______________________________________________
> R-sig-Geo mailing list

> R-sig-Geo@

> https://stat.ethz.ch/mailman/listinfo/r-sig-geo





--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Error-message-when-dissolving-polygons-tp7586109p7586981.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From potts.a at gmail.com  Mon Aug 25 12:03:59 2014
From: potts.a at gmail.com (Alastair Potts)
Date: Mon, 25 Aug 2014 12:03:59 +0200
Subject: [R-sig-Geo] Randomly moving a locality (within set limits)
In-Reply-To: <CANVKczPnpeZAF=9tXy8P4wGj4viQLfP4Q9bBdSzyoQ2=AmqV-w@mail.gmail.com>
References: <CAG_8N1YkczrHxWi6skkNJqwt6Uy6MmKNYxRUbySz163_x_dFAw@mail.gmail.com>
	<0ad0475eec1c48bbb095863a1bc8e238@EX-1-HT0.lancs.local>
	<CANVKczPnpeZAF=9tXy8P4wGj4viQLfP4Q9bBdSzyoQ2=AmqV-w@mail.gmail.com>
Message-ID: <CAG_8N1a6zOx0ZBt37n9S9HBirChcCbQxnUnPS75tGzAw=SFuxA@mail.gmail.com>

Dear Frede, Barry and Don,

Thanks very for your thoughts!

Frede's function looks perfect! Thanks very much!!!

Barry, would not setting random U(-N,N) distance deal with the uniform
distance problem [i.e. distance <- runif(1,-15,15)].

Cheers,
Alastair




On 25 August 2014 10:48, Barry Rowlingson <b.rowlingson at lancaster.ac.uk>
wrote:

> > Now choose
> >
> > bearing <- runif(1, 0, 360)
> >
> > and
> >
> > distance <- runif(1, 0, 15)
> >
> > Please check the formulas against the homepage above.
>
>  Note: choosing a random bearing U(0,360) and a random U(0,N) distance
>  DOESNT generate a uniform distribution over the disk of radius N!
> You get more points near the centre!
>
>  Barry
>



-- 
Dr. Alastair J. Potts
-----------------------------------------------------------------------------------------------------------------
NRF Research Career Award Fellow
Botany Department, Nelson Mandela Metropolitan University
C: 082 491-7275
O: 041 504-4375
W: https://sites.google.com/site/dralastairpotts/home
-----------------------------------------------------------------------------------------------------------------
"Research presumes dissatisfaction with existing descriptions of reality
and explanations of our experience of it - it rests on the desire to do
better than the current consensus. Research, therefore, requires freedom to
question received wisdom and some background knowledge of why we think we
know what we think we know." John F. Allen (2003; Future Med. Chem,
2:15-20)
-----------------------------------------------------------------------------------------------------------------

	[[alternative HTML version deleted]]


From b.rowlingson at lancaster.ac.uk  Mon Aug 25 12:09:09 2014
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon, 25 Aug 2014 11:09:09 +0100
Subject: [R-sig-Geo] Randomly moving a locality (within set limits)
In-Reply-To: <6ec445c6c23640f8a41d175e7aec1ca7@EX-0-HT0.lancs.local>
References: <CAG_8N1YkczrHxWi6skkNJqwt6Uy6MmKNYxRUbySz163_x_dFAw@mail.gmail.com>
	<0ad0475eec1c48bbb095863a1bc8e238@EX-1-HT0.lancs.local>
	<CANVKczPnpeZAF=9tXy8P4wGj4viQLfP4Q9bBdSzyoQ2=AmqV-w@mail.gmail.com>
	<6ec445c6c23640f8a41d175e7aec1ca7@EX-0-HT0.lancs.local>
Message-ID: <CANVKczOT-rHEWd8a+P5fThsiOXiEjJnsd5FyAhbrh=Orq1x0RA@mail.gmail.com>

On Mon, Aug 25, 2014 at 11:03 AM, Alastair Potts <potts.a at gmail.com> wrote:
> Dear Frede, Barry and Don,
>
> Thanks very for your thoughts!
>
> Frede's function looks perfect! Thanks very much!!!
>
> Barry, would not setting random U(-N,N) distance deal with the uniform
> distance problem [i.e. distance <- runif(1,-15,15)].
>

 No, that would just be the same!

Its all explained here:

http://mathworld.wolfram.com/DiskPointPicking.html

>
>
> On 25 August 2014 10:48, Barry Rowlingson <b.rowlingson at lancaster.ac.uk>
> wrote:
>>
>> > Now choose
>> >
>> > bearing <- runif(1, 0, 360)
>> >
>> > and
>> >
>> > distance <- runif(1, 0, 15)
>> >
>> > Please check the formulas against the homepage above.
>>
>>  Note: choosing a random bearing U(0,360) and a random U(0,N) distance
>>  DOESNT generate a uniform distribution over the disk of radius N!
>> You get more points near the centre!
>>
>>  Barry
>
>
>
>
> --
> Dr. Alastair J. Potts
> -----------------------------------------------------------------------------------------------------------------
> NRF Research Career Award Fellow
> Botany Department, Nelson Mandela Metropolitan University
> C: 082 491-7275
> O: 041 504-4375
> W: https://sites.google.com/site/dralastairpotts/home
> -----------------------------------------------------------------------------------------------------------------
> "Research presumes dissatisfaction with existing descriptions of reality
> and explanations of our experience of it ? it rests on the desire to do
> better than the current consensus. Research, therefore, requires freedom to
> question received wisdom and some background knowledge of why we think we
> know what we think we know." John F. Allen (2003; Future Med. Chem,
> 2:15-20)
> -----------------------------------------------------------------------------------------------------------------
>


From md.franklin at gmail.com  Mon Aug 25 12:12:47 2014
From: md.franklin at gmail.com (frankma)
Date: Mon, 25 Aug 2014 03:12:47 -0700 (PDT)
Subject: [R-sig-Geo] Error message when dissolving polygons
In-Reply-To: <1408960240976-7586981.post@n2.nabble.com>
References: <3C605470-14BA-4C5E-B15D-6C37C1F3CACC@gmail.com>
	<1408956118252-7586977.post@n2.nabble.com>
	<1408957153972-7586979.post@n2.nabble.com>
	<alpine.LRH.2.03.1408251103580.17748@reclus.nhh.no>
	<1408960240976-7586981.post@n2.nabble.com>
Message-ID: <1408961567485-7586984.post@n2.nabble.com>

OK you were right I was being stupid, I have changed LL to UTM and that
works. Do you know of a way to dissolve polygons by explicitly defineing
which ones you wish to dissolve?

Thanks,
Matt



frankma wrote
> My apologies Roger, thank you for letting me know the mailing list
> etiquette. 
> 
> I understand the gist of what you are saying but I'm still unsure which
> projections I am mixing up. I am using the shapefile available here:
> http://www.cso.ie/en/census/census2011boundaryfiles/
> 
> My code and error are below. I realise that it may seem obvious to you but
> it isn't to me, I've spent hours trying to "dissolve polygons" and there
> is something I am not understanding here, I am sorry for this. Appreciate
> your response so far and any further help is very much appreciated, thank
> you. In terms of affiliations I am currently trying to complete an MSc
> dissertation at the University of Sheffield (UK) - I also work full time.
> 
> 
> library(maptools)   # for geospatial services; also loads foreign and sp
> library(gpclib)     # General Polygon Clipping library 
> library(rgdal)      # for map projection work; also loads sp
> library(PBSmapping) # for GIS_like geospatial object manipulation /
> anslysis iIRLluding poly
> # 
> # Part 1:
> # First example, derived from the maptools unionSpatialPolygon() method
> documentation in the R 
> # maptools user manual: We calculate and sum the area of each polygon in
> the Ireland map. 
> # Then, use unionSpatialPolygons() to dissolve the county polygon
> boundries, and assign each
> # polygon's area to one of four regions, based on longitude thresholds.
> #
> print("start of demo. Hit key...")
> browser()
> print("reading and transforming Ireland Shapefile...")
> #
> IRLBase <- readShapePoly("Shape/counties.shp",proj4string=CRS("+proj=aea
> +ellps=GRS80 +datum=WGS84"))
> 
> #
> # Transform the polygons (which were read in as unprojected geographic
> coordinates)
> # to an Albers Equal Area projection.
> #
> IRLProj = spTransform(IRLBase,CRS("+proj=aea +ellps=GRS80 +datum=WGS84"))
> #
> # Convert to a PolygonSet for compatability with PBSmapping package
> routines.
> #
> IRLProjPS = SpatialPolygons2PolySet(IRLProj)
> #
> plotPolys(IRLProjPS, proj =
> TRUE,col="wheat1",xlab="longitude",ylab="latitude")
> #
> # polygon area calculations
> #
> print("Calculating Ireland polygon areas...")
> attr(IRLProjPS, "projection") <- "LL"
> IRLPolyAreas = calcArea(IRLProjPS,rollup=1)
*
> Error in calcArea(IRLProjPS, rollup = 1) : 
>   To calculate the areas of polygons defined by longitude-latitude
> coordinates, this routine first projects them in UTM.
> 
> Attempted to automatically calculate the missing 'zone' attribute, but
> that failed because the mean longitude falls outside the range
> -180 < x <= 180.
*
> 
> Thanks,
> Matt
> 
> Roger Bivand wrote
>> On Mon, 25 Aug 2014, frankma wrote:
>> 
>>> Hi,
>>>
>>> I'm having the same issue. Did you manage to solve this?
>> 
>> Please always quote the problem verbatim, providing a reproducible 
>> example. Even if anyone cares to open nabble to find the link, nobody can 
>> actually know whether your problem is the same. The reason we ask for 
>> reproducible examples is that the effort needed by the questioner to 
>> create a reproducible example means that he/she has to look more closely 
>> at - here "I?m following a tutorial found in the web" - what they are 
>> trying to do, and very often see their mistake themselves. Learning to 
>> debug one's own work is not easy, takes time, but wastes less of other 
>> peoples' time than asking lazy questions - see the posting guide:
>> 
>> http://www.r-project.org/posting-guide.html
>> 
>> It is also very helpful to see an affiliation, so that anyone caring to 
>> answer knows where to start. This is especially important when the 
>> sender's address is non-institutional.
>> 
>> In the original question:
>> 
>> https://stat.ethz.ch/pipermail/r-sig-geo/2014-April/020764.html
>> 
>> the obvious error was to think that the PolySet class in PBSmapping 
>> understands other projections than UTM:
>> 
>> # library(maptools)
>> # zm.* not available
>>> input = readShapePoly("zm.shp", proj4string=CRS("+proj=lcc +ellps=GRS80 
>> +datum=WGS84"))
>>> projectedpolygons = spTransform(input, CRS("+proj=lcc +ellps=GRS80 
>> +datum=WGS84"))
>>> zmprojPS = SpatialPolygons2PolySet(projectedpolygons)
>>> attr(zmprojPS, "projection") <- "LL"
>> 
>> I assume that no answer was posted because the error message was totally 
>> obvious, that is that lcc is Lambert conformal conic, but LL is the code 
>> for geographical, unprojected, coordinates, so PBSmapping could not 
>> project to UTM to calculate areas as:
>> 
>> "the mean longitude falls outside the range -180 < x <= 180."
>> 
>> If you are also mixing up projections, then this also explains what you 
>> are seeing.
>> 
>> Hope this clarifies,
>> 
>> Roger
>> 
>>>
>>> Thanks,
>>> Matt
>>>
>>>
>>>
>>> --
>>> View this message in context:
>>> http://r-sig-geo.2731867.n2.nabble.com/Error-message-when-dissolving-polygons-tp7586109p7586979.html
>>> Sent from the R-sig-geo mailing list archive at Nabble.com.
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> 

>> R-sig-Geo@

>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>> 
>> -- 
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics,
>> Helleveien 30, N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>> e-mail: 

>> Roger.Bivand@

>> 
>> _______________________________________________
>> R-sig-Geo mailing list

>> R-sig-Geo@

>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> Roger Bivand wrote
>> On Mon, 25 Aug 2014, frankma wrote:
>> 
>>> Hi,
>>>
>>> I'm having the same issue. Did you manage to solve this?
>> 
>> Please always quote the problem verbatim, providing a reproducible 
>> example. Even if anyone cares to open nabble to find the link, nobody can 
>> actually know whether your problem is the same. The reason we ask for 
>> reproducible examples is that the effort needed by the questioner to 
>> create a reproducible example means that he/she has to look more closely 
>> at - here "I?m following a tutorial found in the web" - what they are 
>> trying to do, and very often see their mistake themselves. Learning to 
>> debug one's own work is not easy, takes time, but wastes less of other 
>> peoples' time than asking lazy questions - see the posting guide:
>> 
>> http://www.r-project.org/posting-guide.html
>> 
>> It is also very helpful to see an affiliation, so that anyone caring to 
>> answer knows where to start. This is especially important when the 
>> sender's address is non-institutional.
>> 
>> In the original question:
>> 
>> https://stat.ethz.ch/pipermail/r-sig-geo/2014-April/020764.html
>> 
>> the obvious error was to think that the PolySet class in PBSmapping 
>> understands other projections than UTM:
>> 
>> # library(maptools)
>> # zm.* not available
>>> input = readShapePoly("zm.shp", proj4string=CRS("+proj=lcc +ellps=GRS80 
>> +datum=WGS84"))
>>> projectedpolygons = spTransform(input, CRS("+proj=lcc +ellps=GRS80 
>> +datum=WGS84"))
>>> zmprojPS = SpatialPolygons2PolySet(projectedpolygons)
>>> attr(zmprojPS, "projection") <- "LL"
>> 
>> I assume that no answer was posted because the error message was totally 
>> obvious, that is that lcc is Lambert conformal conic, but LL is the code 
>> for geographical, unprojected, coordinates, so PBSmapping could not 
>> project to UTM to calculate areas as:
>> 
>> "the mean longitude falls outside the range -180 < x <= 180."
>> 
>> If you are also mixing up projections, then this also explains what you 
>> are seeing.
>> 
>> Hope this clarifies,
>> 
>> Roger
>> 
>>>
>>> Thanks,
>>> Matt
>>>
>>>
>>>
>>> --
>>> View this message in context:
>>> http://r-sig-geo.2731867.n2.nabble.com/Error-message-when-dissolving-polygons-tp7586109p7586979.html
>>> Sent from the R-sig-geo mailing list archive at Nabble.com.
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> 

>> R-sig-Geo@

>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>> 
>> -- 
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics,
>> Helleveien 30, N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>> e-mail: 

>> Roger.Bivand@

>> 
>> _______________________________________________
>> R-sig-Geo mailing list

>> R-sig-Geo@

>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo





-----
Matthew Franklin
School of Mathematics and Statistics
University of Sheffield
--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Error-message-when-dissolving-polygons-tp7586109p7586984.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From frtog at vestas.com  Mon Aug 25 14:19:10 2014
From: frtog at vestas.com (=?utf-8?B?RnJlZGUgQWFrbWFubiBUw7hnZXJzZW4=?=)
Date: Mon, 25 Aug 2014 14:19:10 +0200
Subject: [R-sig-Geo] Randomly moving a locality (within set limits)
In-Reply-To: <CANVKczOT-rHEWd8a+P5fThsiOXiEjJnsd5FyAhbrh=Orq1x0RA@mail.gmail.com>
References: <CAG_8N1YkczrHxWi6skkNJqwt6Uy6MmKNYxRUbySz163_x_dFAw@mail.gmail.com>
	<0ad0475eec1c48bbb095863a1bc8e238@EX-1-HT0.lancs.local>
	<CANVKczPnpeZAF=9tXy8P4wGj4viQLfP4Q9bBdSzyoQ2=AmqV-w@mail.gmail.com>
	<6ec445c6c23640f8a41d175e7aec1ca7@EX-0-HT0.lancs.local>
	<CANVKczOT-rHEWd8a+P5fThsiOXiEjJnsd5FyAhbrh=Orq1x0RA@mail.gmail.com>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C78D0577@DKRDSEXC016.vestas.net>

Sorry, I didn't really think about what kind of distribution is most suitable for distance. My suggestion of using runif() gives the problem of more points around origin as pointed out my Barry (see attached uniformDistance.png).

However according to the link Barry provided you just need to take the distance as 15 * sqrt(runif(n, 0, 1)). This gives the distribution of the distances as in attached distanceDistribution.png. And the distribution of points is shown in sqrt_uniformDistribution.png.

Also the number of points in 0.05x0.05 cells ( at Equator so the cells have approx. the same area) is like this (formatting will probably not survive through the mail server):

		lons			
	                          (-0.1,-0.05]	(-0.05,0]	(0,0.05] 	(0.05,0.1]
lats	(-0.1,-0.05]	47	42	42	42
	(-0.05,0]	48	52	49	40
	(0,0.05]		51	47	44	41
	(0.05,0.1]	45	37	41	35




Here is the R code for reference:


Ds <- 15
N <- 1000

bears <- runif(N, 0, 360)

lensU <- runif(N, 0, Ds)
sqrtlensU <- sqrt(runif(N, 0, 1))*Ds

png("distanceDistribution.png")
hist(sqrtlensU)
dev.off()

dests00 <- NULL
for (i in 1:N) dests00 <- rbind(dests00, foo(c(0, 0), bears[i], lensU[i]))

png("uniformDistance.png")
xyplot(Latitude ~ Longitude, data = as.data.frame(dests00), aspect = "iso") + 
    xyplot(0 ~ 0, col = "red", pch = 13, cex = 2)
dev.off()

sqrtdests00 <- NULL
for (i in 1:N) sqrtdests00 <- rbind(sqrtdests00, foo(c(0, 0), bears[i], sqrtlensU[i]))

png("sqrt_uniformDistance.png")
xyplot(Latitude ~ Longitude, data = as.data.frame(sqrtdests00), aspect = "iso") + 
    xyplot(0 ~ 0, col = "red", pch = 13, cex = 2)
dev.off()

lats <- cut(sqrtdests00[, "Latitude"], seq(-0.1, 0.1, by = 0.05)) 
lons <- cut(sqrtdests00[, "Longitude"], seq(-0.1, 0.1, by = 0.05)) 
table(lats, lons)

  

Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 


> -----Original Message-----
> From: b.rowlingson at gmail.com [mailto:b.rowlingson at gmail.com] On Behalf
> Of Barry Rowlingson
> Sent: 25. august 2014 12:09
> To: Alastair Potts
> Cc: Frede Aakmann T?gersen; r-sig-geo at r-project.org
> Subject: Re: [R-sig-Geo] Randomly moving a locality (within set limits)
> 
> On Mon, Aug 25, 2014 at 11:03 AM, Alastair Potts <potts.a at gmail.com>
> wrote:
> > Dear Frede, Barry and Don,
> >
> > Thanks very for your thoughts!
> >
> > Frede's function looks perfect! Thanks very much!!!
> >
> > Barry, would not setting random U(-N,N) distance deal with the uniform
> > distance problem [i.e. distance <- runif(1,-15,15)].
> >
> 
>  No, that would just be the same!
> 
> Its all explained here:
> 
> http://mathworld.wolfram.com/DiskPointPicking.html
> 
> >
> >
> > On 25 August 2014 10:48, Barry Rowlingson
> <b.rowlingson at lancaster.ac.uk>
> > wrote:
> >>
> >> > Now choose
> >> >
> >> > bearing <- runif(1, 0, 360)
> >> >
> >> > and
> >> >
> >> > distance <- runif(1, 0, 15)
> >> >
> >> > Please check the formulas against the homepage above.
> >>
> >>  Note: choosing a random bearing U(0,360) and a random U(0,N) distance
> >>  DOESNT generate a uniform distribution over the disk of radius N!
> >> You get more points near the centre!
> >>
> >>  Barry
> >
> >
> >
> >
> > --
> > Dr. Alastair J. Potts
> > -------------------------------------------------------------------------------------------
> ----------------------
> > NRF Research Career Award Fellow
> > Botany Department, Nelson Mandela Metropolitan University
> > C: 082 491-7275
> > O: 041 504-4375
> > W: https://sites.google.com/site/dralastairpotts/home
> > -------------------------------------------------------------------------------------------
> ----------------------
> > "Research presumes dissatisfaction with existing descriptions of reality
> > and explanations of our experience of it ? it rests on the desire to do
> > better than the current consensus. Research, therefore, requires freedom
> to
> > question received wisdom and some background knowledge of why we
> think we
> > know what we think we know." John F. Allen (2003; Future Med. Chem,
> > 2:15-20)
> > -------------------------------------------------------------------------------------------
> ----------------------
> >
-------------- next part --------------
A non-text attachment was scrubbed...
Name: uniformDistance.png
Type: image/png
Size: 9346 bytes
Desc: uniformDistance.png
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140825/20157040/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: distanceDistribution.png
Type: image/png
Size: 3795 bytes
Desc: distanceDistribution.png
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140825/20157040/attachment-0001.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: sqrt_uniformDistance.png
Type: image/png
Size: 10248 bytes
Desc: sqrt_uniformDistance.png
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140825/20157040/attachment-0002.png>

From Roger.Bivand at nhh.no  Mon Aug 25 14:39:06 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 25 Aug 2014 14:39:06 +0200
Subject: [R-sig-Geo] Error message when dissolving polygons
In-Reply-To: <1408960240976-7586981.post@n2.nabble.com>
References: <3C605470-14BA-4C5E-B15D-6C37C1F3CACC@gmail.com>
	<1408956118252-7586977.post@n2.nabble.com>
	<1408957153972-7586979.post@n2.nabble.com>
	<alpine.LRH.2.03.1408251103580.17748@reclus.nhh.no>
	<1408960240976-7586981.post@n2.nabble.com>
Message-ID: <alpine.LRH.2.03.1408251408010.17748@reclus.nhh.no>

In your subsequent message, you claim that by setting LL to UTM, you 
resolve the problem. This is wrong, as I'll show below. You have not said 
what you mean by "dissolve" either, the help pages of both 
maptools::unionSpatialPolygons and equivalently rgeos::gUnaryUnion show 
exactly what to do, but I don't think that this is what you actually mean.

On Mon, 25 Aug 2014, frankma wrote:

> My apologies Roger, thank you for letting me know the mailing list etiquette. 
>
> I understand the gist of what you are saying but I'm still unsure which
> projections I am mixing up. I am using the shapefile available here:
> http://www.cso.ie/en/census/census2011boundaryfiles/

The files at this source are:

"The shapefiles are available in the Irish Grid Reference System (TM65 / 
Irish Grid - EPSG Projection 29902)"

so are projected, but not UTM.

>
> My code and error are below. I realise that it may seem obvious to you but
> it isn't to me, I've spent hours trying to "dissolve polygons" and there is
> something I am not understanding here, I am sorry for this. Appreciate your
> response so far and any further help is very much appreciated, thank you. In
> terms of affiliations I am currently trying to complete an MSc dissertation
> at the University of Sheffield (UK) - I also work full time.
>
>
> library(maptools)   # for geospatial services; also loads foreign and sp
> library(gpclib)     # General Polygon Clipping library

Neither of maptools nor gpclib are needed. The gpclib package should 
never, ever be used - use polyclip instead, or rgeos if your objects 
inherit sp classes.

> library(rgdal)      # for map projection work; also loads sp

Good!

> library(PBSmapping) # for GIS_like geospatial object manipulation / anslysis
> iIRLluding poly
> #

Not needed.

> # Part 1:
> # First example, derived from the maptools unionSpatialPolygon() method
> documentation in the R 
> # maptools user manual: We calculate and sum the area of each polygon in the
> Ireland map. 
> # Then, use unionSpatialPolygons() to dissolve the county polygon boundries,
> and assign each
> # polygon's area to one of four regions, based on longitude thresholds.
> #
> print("start of demo. Hit key...")
> browser()
> print("reading and transforming Ireland Shapefile...")
> #
> IRLBase <- readShapePoly("Shape/counties.shp",proj4string=CRS("+proj=aea
> +ellps=GRS80 +datum=WGS84"))

Here you are setting the projection (coordinate reference system, CRS) to 
AEA when in all probability the input was as the data source says. All the 
proj4string= argument does is to insert the given CRS into the object; it 
says - I know that this is correct; it does not project, because that 
needs a from CRS and a to CRS.

>

The example in maptools uses readShapePoly() to avoid depending on rgdal, 
but only rgdal should be used in real work (rgdal reads the prj file in 
shapefiles to set the CRS directly); the maptools functions will probably 
be disabled shortly tooblige users to make the right choices:

> IRLBase <- readOGR(".", "Census2011_Admin_Counties_generalised20m")
OGR data source with driver: ESRI Shapefile
Source: ".", layer: "Census2011_Admin_Counties_generalised20m"
with 34 features and 20 fields
Feature type: wkbPolygon with 2 dimensions
> proj4string(IRLBase)
[1] "+proj=tmerc +lat_0=53.5 +lon_0=-8 +k=1.000035 +x_0=200000 +y_0=250000 
+datum=ire65 +units=m +no_defs +ellps=mod_airy 
+towgs84=482.530,-130.596,564.557,-1.042,-0.214,-0.631,8.15"
> library(rgeos)
rgeos version: 0.3-6, (SVN revision 450)
  GEOS runtime version: 3.4.2-CAPI-1.8.2 r3921
  Polygon checking: TRUE
> gA <- gArea(IRLBase, byid=TRUE)

gives the entity areas in square metres; note that the actual areas will 
depend on the degree of line generalisation.

With this file, which may not be the one you are using, you may also need 
to use the encoding="latin1" argument in readOGR() to get from D\xfan 
Laoghaire-Rathdown to D?n Laoghaire-Rathdown.

> #
> # Transform the polygons (which were read in as unprojected geographic
> coordinates)
> # to an Albers Equal Area projection.
> #
> IRLProj = spTransform(IRLBase,CRS("+proj=aea +ellps=GRS80 +datum=WGS84"))

You've set the CRS to AEA on reading, so this is a no-op.

> #
> # Convert to a PolygonSet for compatability with PBSmapping package
> routines.
> #
> IRLProjPS = SpatialPolygons2PolySet(IRLProj)
> #
> plotPolys(IRLProjPS, proj =
> TRUE,col="wheat1",xlab="longitude",ylab="latitude")
> #
> # polygon area calculations
> #
> print("Calculating Ireland polygon areas...")
> attr(IRLProjPS, "projection") <- "LL"

But you set the CRS to AEA, which is neither UTM not LL - this is simply 
wrong.

> IRLPolyAreas = calcArea(IRLProjPS,rollup=1)
>
> *Error in calcArea(IRLProjPS, rollup = 1) :
>  To calculate the areas of polygons defined by longitude-latitude
> coordinates, this routine first projects them in UTM.
>
> Attempted to automatically calculate the missing 'zone' attribute, but
> that failed because the mean longitude falls outside the range
> -180 < x <= 180.*

As I said before, the coordinates in the data object are already 
projected. By your setting the PolySet to UTM, you get some numbers out 
(effectively the same as by doing it properly, because PBSmapping then 
calculates planar areas in the metric of the coordinates, rather than 
projecting on the fly from LL to UTM and then grapping planar areas). But 
it is certainly not UTM.

Which leaves the muddle about what you mean by dissolving; I can guess 
that you need to define the longitude thresholds as polygons in the same 
projection as the polygons, intersect the two using
rgeos::gIntersection(..., byid=TRUE), take rgeos::gArea(..., byid=TRUE) of 
the output, and pick apart the row.names() of the output object to see how 
many square metres of each county belongs to each longitude threshold.

Hope this clarifies,

Roger

>
> Thanks,
> Matt
>
>
>
> Roger Bivand wrote
>> On Mon, 25 Aug 2014, frankma wrote:
>> 
>>> Hi,
>>>
>>> I'm having the same issue. Did you manage to solve this?
>> 
>> Please always quote the problem verbatim, providing a reproducible 
>> example. Even if anyone cares to open nabble to find the link, nobody can 
>> actually know whether your problem is the same. The reason we ask for 
>> reproducible examples is that the effort needed by the questioner to 
>> create a reproducible example means that he/she has to look more closely 
>> at - here "I?m following a tutorial found in the web" - what they are 
>> trying to do, and very often see their mistake themselves. Learning to 
>> debug one's own work is not easy, takes time, but wastes less of other 
>> peoples' time than asking lazy questions - see the posting guide:
>> 
>> http://www.r-project.org/posting-guide.html
>> 
>> It is also very helpful to see an affiliation, so that anyone caring to 
>> answer knows where to start. This is especially important when the 
>> sender's address is non-institutional.
>> 
>> In the original question:
>> 
>> https://stat.ethz.ch/pipermail/r-sig-geo/2014-April/020764.html
>> 
>> the obvious error was to think that the PolySet class in PBSmapping 
>> understands other projections than UTM:
>> 
>> # library(maptools)
>> # zm.* not available
>>> input = readShapePoly("zm.shp", proj4string=CRS("+proj=lcc +ellps=GRS80 
>> +datum=WGS84"))
>>> projectedpolygons = spTransform(input, CRS("+proj=lcc +ellps=GRS80 
>> +datum=WGS84"))
>>> zmprojPS = SpatialPolygons2PolySet(projectedpolygons)
>>> attr(zmprojPS, "projection") <- "LL"
>> 
>> I assume that no answer was posted because the error message was totally 
>> obvious, that is that lcc is Lambert conformal conic, but LL is the code 
>> for geographical, unprojected, coordinates, so PBSmapping could not 
>> project to UTM to calculate areas as:
>> 
>> "the mean longitude falls outside the range -180 < x <= 180."
>> 
>> If you are also mixing up projections, then this also explains what you 
>> are seeing.
>> 
>> Hope this clarifies,
>> 
>> Roger
>> 
>>>
>>> Thanks,
>>> Matt
>>>
>>>
>>>
>>> --
>>> View this message in context:
>>> http://r-sig-geo.2731867.n2.nabble.com/Error-message-when-dissolving-polygons-tp7586109p7586979.html
>>> Sent from the R-sig-geo mailing list archive at Nabble.com.
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> 
>
>> R-sig-Geo@
>
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>> 
>> -- 
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics,
>> Helleveien 30, N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>> e-mail: 
>
>> Roger.Bivand@
>
>> 
>> _______________________________________________
>> R-sig-Geo mailing list
>
>> R-sig-Geo@
>
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
> Roger Bivand wrote
>> On Mon, 25 Aug 2014, frankma wrote:
>> 
>>> Hi,
>>>
>>> I'm having the same issue. Did you manage to solve this?
>> 
>> Please always quote the problem verbatim, providing a reproducible 
>> example. Even if anyone cares to open nabble to find the link, nobody can 
>> actually know whether your problem is the same. The reason we ask for 
>> reproducible examples is that the effort needed by the questioner to 
>> create a reproducible example means that he/she has to look more closely 
>> at - here "I?m following a tutorial found in the web" - what they are 
>> trying to do, and very often see their mistake themselves. Learning to 
>> debug one's own work is not easy, takes time, but wastes less of other 
>> peoples' time than asking lazy questions - see the posting guide:
>> 
>> http://www.r-project.org/posting-guide.html
>> 
>> It is also very helpful to see an affiliation, so that anyone caring to 
>> answer knows where to start. This is especially important when the 
>> sender's address is non-institutional.
>> 
>> In the original question:
>> 
>> https://stat.ethz.ch/pipermail/r-sig-geo/2014-April/020764.html
>> 
>> the obvious error was to think that the PolySet class in PBSmapping 
>> understands other projections than UTM:
>> 
>> # library(maptools)
>> # zm.* not available
>>> input = readShapePoly("zm.shp", proj4string=CRS("+proj=lcc +ellps=GRS80 
>> +datum=WGS84"))
>>> projectedpolygons = spTransform(input, CRS("+proj=lcc +ellps=GRS80 
>> +datum=WGS84"))
>>> zmprojPS = SpatialPolygons2PolySet(projectedpolygons)
>>> attr(zmprojPS, "projection") <- "LL"
>> 
>> I assume that no answer was posted because the error message was totally 
>> obvious, that is that lcc is Lambert conformal conic, but LL is the code 
>> for geographical, unprojected, coordinates, so PBSmapping could not 
>> project to UTM to calculate areas as:
>> 
>> "the mean longitude falls outside the range -180 < x <= 180."
>> 
>> If you are also mixing up projections, then this also explains what you 
>> are seeing.
>> 
>> Hope this clarifies,
>> 
>> Roger
>> 
>>>
>>> Thanks,
>>> Matt
>>>
>>>
>>>
>>> --
>>> View this message in context:
>>> http://r-sig-geo.2731867.n2.nabble.com/Error-message-when-dissolving-polygons-tp7586109p7586979.html
>>> Sent from the R-sig-geo mailing list archive at Nabble.com.
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> 
>
>> R-sig-Geo@
>
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>> 
>> -- 
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics,
>> Helleveien 30, N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>> e-mail: 
>
>> Roger.Bivand@
>
>> 
>> _______________________________________________
>> R-sig-Geo mailing list
>
>> R-sig-Geo@
>
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>
>
>
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Error-message-when-dissolving-polygons-tp7586109p7586981.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no

From ftonini84 at gmail.com  Mon Aug 25 14:50:53 2014
From: ftonini84 at gmail.com (Francesco Tonini)
Date: Mon, 25 Aug 2014 08:50:53 -0400
Subject: [R-sig-Geo] Point in Polygon Overlay Memory Error
In-Reply-To: <CANVKczMa+8dDdoeMueHus2VV6gS0Oet0kBs08h6om0iog0+XnQ@mail.gmail.com>
References: <CAGBzUO8nkr3xUYyaG_xaFa5n3uoLMRT3W5Qnm2bPUgLA4DAY9A@mail.gmail.com>	<36b84c5138514a07b8a93891132eb9a4@EX-0-HT0.lancs.local>	<CANVKczOsi_FQu=maNYmwvUJWabCnpGd9b8fHRoqdEa2C1rNxBg@mail.gmail.com>	<53E9E5C7.7040409@aqua.dtu.dk>	<9ad07ff88b594ef18a96adf35de2386d@EX-1-HT0.lancs.local>
	<CANVKczMa+8dDdoeMueHus2VV6gS0Oet0kBs08h6om0iog0+XnQ@mail.gmail.com>
Message-ID: <53FB312D.2000002@gmail.com>

Dear all,

I keep getting a memory error (vector too big) when overlaying hundreds 
of thousands of points with a polygon layer. The computer I am running 
this on is quite powerful, thus the error is just internal to R because 
of reaching a vector allocation too big in size. Is there any workaround 
to execute this operation? My goal is to overlay several point onto a 
habitat polygon layer, and remove all points falling outside that polygon.

Any help is much appreciated.

Thank you,
Francesco


From Roger.Bivand at nhh.no  Mon Aug 25 14:59:32 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 25 Aug 2014 14:59:32 +0200
Subject: [R-sig-Geo] Point in Polygon Overlay Memory Error
In-Reply-To: <53FB312D.2000002@gmail.com>
References: <CAGBzUO8nkr3xUYyaG_xaFa5n3uoLMRT3W5Qnm2bPUgLA4DAY9A@mail.gmail.com>
	<36b84c5138514a07b8a93891132eb9a4@EX-0-HT0.lancs.local>
	<CANVKczOsi_FQu=maNYmwvUJWabCnpGd9b8fHRoqdEa2C1rNxBg@mail.gmail.com>
	<53E9E5C7.7040409@aqua.dtu.dk>
	<9ad07ff88b594ef18a96adf35de2386d@EX-1-HT0.lancs.local>
	<CANVKczMa+8dDdoeMueHus2VV6gS0Oet0kBs08h6om0iog0+XnQ@mail.gmail.com>
	<53FB312D.2000002@gmail.com>
Message-ID: <alpine.LRH.2.03.1408251455180.17748@reclus.nhh.no>

On Mon, 25 Aug 2014, Francesco Tonini wrote:

> Dear all,
>
> I keep getting a memory error (vector too big) when overlaying hundreds of 
> thousands of points with a polygon layer. The computer I am running this on 
> is quite powerful, thus the error is just internal to R because of reaching a 
> vector allocation too big in size. Is there any workaround to execute this 
> operation? My goal is to overlay several point onto a habitat polygon layer, 
> and remove all points falling outside that polygon.

Please recall that nobody can see over your shoulder. Always state the 
output of sessionInfo(), the code causing the error, the output of 
traceback() after the error, and some details of the objects concerned 
(counts of points, for example). Are you for example using over() methods 
from the sp package?

Powerful may also be misconfigured, so available RAM and any adjustments 
you have made to R defaults should be declared.

Do read the posting guide!

Roger

>
> Any help is much appreciated.
>
> Thank you,
> Francesco
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From sdthomps at uvic.ca  Tue Aug 26 02:57:39 2014
From: sdthomps at uvic.ca (Shanley Thompson)
Date: Mon, 25 Aug 2014 17:57:39 -0700
Subject: [R-sig-Geo] How do I calculate neighborhood contiguity in R?
Message-ID: <001301cfc0c8$bc27f080$3477d180$@uvic.ca>

Hello,
My end goal is to calculate join counts, using the function
joincounts.multi() from the R package spdep. I understand that first I need
to calculate the nb object, then the spatial weights matrix, then I can do
the join counts. 

I have a very large raster file (nrows = 19663, ncols = 34073), with cell
size of 30 m, in integer format. I read it in using the raster() function
from the Raster package.

For the first part (creating a "nb" object), I have tried using the cell2nb
file but it keeps crashing - a quick search tells me others have had the
same problem due to large files.  

I read that one can use "dnearneigh" function in the spdep package instead,
but I do not understand how to do so. Can someone provide a detailed
example?  Alternatively, would it be better to convert my raster layer to a
polygon layer then use the function poly2nb? 

I am relatively new to R so the simpler the better!

Thank you so much! 


Shanley Thompson, MSc, PhD Candidate
Department of Geography, University of Victoria, Canada


From srinivasv at feralindia.org  Tue Aug 26 11:55:38 2014
From: srinivasv at feralindia.org (Srinivas V)
Date: Tue, 26 Aug 2014 15:25:38 +0530
Subject: [R-sig-Geo] Subsetting Raster Time Series
Message-ID: <53FC599A.20101@feralindia.org>

Hi,

I would like to subset the CRU dataset to a particular time period 
(1980-2013) is there an option to do this within package raster? I can 
manually specifiy the layers to drop, but I would like to drop them 
based on a time period. I'm doing this to ensure two datasets are of the 
same time period.

I would appreciate any advice on dealing with this issue. Thanks!

library(raster)
library(rgdal)
library(ncdf)
library(zoo)

temp<-brick("/media/data/data_cru/tmp/cru_ts3.22.1901.2013.tmp.dat.nc")
temp
temp at z

output
+++++
 > temp
class       : RasterBrick
dimensions  : 360, 720, 259200, 1356  (nrow, ncol, ncell, nlayers)
resolution  : 0.5, 0.5  (x, y)
extent      : -180, 180, -90, 90  (xmin, xmax, ymin, ymax)
coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
data source : /media/data/data_cru/tmp/cru_ts3.22.1901.2013.tmp.dat.nc
names       : X1901.01.16, X1901.02.15, X1901.03.16, X1901.04.16, 
X1901.05.16, X1901.06.16, X1901.07.16, X1901.08.16, X1901.09.16, 
X1901.10.16, X1901.11.16, X1901.12.16, X1902.01.16, X1902.02.15, 
X1902.03.16, ...
Date        : 1901-01-16, 2013-12-16 (min, max)
varname     : tmp

 > temp at z
$Date
  [1] "1901-01-16" "1901-02-15" "1901-03-16" "1901-04-16" "1901-05-16" 
"1901-06-16" "1901-07-16" "1901-08-16" "1901-09-16" "1901-10-16"

[1351] "2013-07-16" "2013-08-16" "2013-09-16" "2013-10-16" "2013-11-16" 
"2013-12-16"



-- 

Srinivas Vaidyanathan
Senior Research Fellow
Foundation for Ecological Research, Advocacy & Learning
Web: www.feralindia.org


	[[alternative HTML version deleted]]


From jan.verbesselt at wur.nl  Tue Aug 26 13:46:27 2014
From: jan.verbesselt at wur.nl (Verbesselt, Jan)
Date: Tue, 26 Aug 2014 11:46:27 +0000
Subject: [R-sig-Geo] Subsetting Raster Time Series
In-Reply-To: <53FC599A.20101@feralindia.org>
References: <53FC599A.20101@feralindia.org>
Message-ID: <D0223DF7.19850%jan.verbesselt@wur.nl>

You could use the calc() environment and define your own function where
you create a ts() object and then subset the ts() using window() to your
time period.

f_subset <- function(x) {
 x <- ts(x, start = c(1901, 1), frequency = 12)  # fill in the right values
 sx <- window(x, start = c(?,?), end = c(?,?)) ## fill in the right values
 return(sx)
}
result <- calc(temp, fun = f_subset)


Jan
www.wageningenur.nl/changemonitor


On 26/08/14 11:55, "Srinivas V" <srinivasv at feralindia.org> wrote:

>Hi,
>
>I would like to subset the CRU dataset to a particular time period
>(1980-2013) is there an option to do this within package raster? I can
>manually specifiy the layers to drop, but I would like to drop them
>based on a time period. I'm doing this to ensure two datasets are of the
>same time period.
>
>I would appreciate any advice on dealing with this issue. Thanks!
>
>library(raster)
>library(rgdal)
>library(ncdf)
>library(zoo)
>
>temp<-brick("/media/data/data_cru/tmp/cru_ts3.22.1901.2013.tmp.dat.nc")
>temp
>temp at z
>
>output
>+++++
> > temp
>class       : RasterBrick
>dimensions  : 360, 720, 259200, 1356  (nrow, ncol, ncell, nlayers)
>resolution  : 0.5, 0.5  (x, y)
>extent      : -180, 180, -90, 90  (xmin, xmax, ymin, ymax)
>coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
>data source : /media/data/data_cru/tmp/cru_ts3.22.1901.2013.tmp.dat.nc
>names       : X1901.01.16, X1901.02.15, X1901.03.16, X1901.04.16,
>X1901.05.16, X1901.06.16, X1901.07.16, X1901.08.16, X1901.09.16,
>X1901.10.16, X1901.11.16, X1901.12.16, X1902.01.16, X1902.02.15,
>X1902.03.16, ...
>Date        : 1901-01-16, 2013-12-16 (min, max)
>varname     : tmp
>
> > temp at z
>$Date
>  [1] "1901-01-16" "1901-02-15" "1901-03-16" "1901-04-16" "1901-05-16"
>"1901-06-16" "1901-07-16" "1901-08-16" "1901-09-16" "1901-10-16"
>
>[1351] "2013-07-16" "2013-08-16" "2013-09-16" "2013-10-16" "2013-11-16"
>"2013-12-16"
>
>
>
>-- 
>
>Srinivas Vaidyanathan
>Senior Research Fellow
>Foundation for Ecological Research, Advocacy & Learning
>Web: www.feralindia.org
>
>
>	[[alternative HTML version deleted]]
>
>_______________________________________________
>R-sig-Geo mailing list
>R-sig-Geo at r-project.org
>https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From loic.dutrieux at wur.nl  Tue Aug 26 13:54:22 2014
From: loic.dutrieux at wur.nl (Dutrieux, Loic)
Date: Tue, 26 Aug 2014 11:54:22 +0000
Subject: [R-sig-Geo] Subsetting Raster Time Series
In-Reply-To: <53FC599A.20101@feralindia.org>
References: <53FC599A.20101@feralindia.org>
Message-ID: <A83620D4CC4762448EFB789FD6E9BBB7429D1E78@SCOMP0937.wurnet.nl>

Hi Srinivas,

You can access the time dimension of these raster object using the getZ and setZ functions; both from the raster package (avoid when possible accessing objects' slots by using @). Following that it is mostly vector arithmetic, which can be achieved in several ways.

Using the example in the help of getZ.

library(raster)
# Create a rasterStack object with time written to z dimension.
r <- raster(ncol=10, nrow=10)
s <- stack(lapply(1:3, function(x) setValues(r, runif(ncell(r)))))
s <- setZ(s, as.Date('2000-1-1') + 0:2)
s

# Extract time vector
time <- getZ(s)
# You can get the indices which fit your subset criteria using which() and inject them into raster::subset()
id <- which(time < as.Date('2000-1-3'))
subset(s, id)

# Nested
subset(s, which(getZ(s) < as.Date('2000-1-3')))

Best regards,

--
Lo?c Dutrieux
Laboratory of Geo-Information sciences and remote sensing
Wageningen University
The Netherlands




-----Original Message-----
From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of Srinivas V
Sent: Tuesday, August 26, 2014 11:56
To: r-sig-geo at r-project.org
Subject: [R-sig-Geo] Subsetting Raster Time Series

Hi,

I would like to subset the CRU dataset to a particular time period
(1980-2013) is there an option to do this within package raster? I can manually specifiy the layers to drop, but I would like to drop them based on a time period. I'm doing this to ensure two datasets are of the same time period.

I would appreciate any advice on dealing with this issue. Thanks!

library(raster)
library(rgdal)
library(ncdf)
library(zoo)

temp<-brick("/media/data/data_cru/tmp/cru_ts3.22.1901.2013.tmp.dat.nc")
temp
temp at z

output
+++++
 > temp
class       : RasterBrick
dimensions  : 360, 720, 259200, 1356  (nrow, ncol, ncell, nlayers) resolution  : 0.5, 0.5  (x, y)
extent      : -180, 180, -90, 90  (xmin, xmax, ymin, ymax)
coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0 data source : /media/data/data_cru/tmp/cru_ts3.22.1901.2013.tmp.dat.nc
names       : X1901.01.16, X1901.02.15, X1901.03.16, X1901.04.16, 
X1901.05.16, X1901.06.16, X1901.07.16, X1901.08.16, X1901.09.16, X1901.10.16, X1901.11.16, X1901.12.16, X1902.01.16, X1902.02.15, X1902.03.16, ...
Date        : 1901-01-16, 2013-12-16 (min, max)
varname     : tmp

 > temp at z
$Date
  [1] "1901-01-16" "1901-02-15" "1901-03-16" "1901-04-16" "1901-05-16" 
"1901-06-16" "1901-07-16" "1901-08-16" "1901-09-16" "1901-10-16"

[1351] "2013-07-16" "2013-08-16" "2013-09-16" "2013-10-16" "2013-11-16" 
"2013-12-16"



-- 

Srinivas Vaidyanathan
Senior Research Fellow
Foundation for Ecological Research, Advocacy & Learning
Web: www.feralindia.org


	[[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From nature.aseem at gmail.com  Wed Aug 27 01:48:40 2014
From: nature.aseem at gmail.com (Aseem Sharma)
Date: Tue, 26 Aug 2014 16:48:40 -0700
Subject: [R-sig-Geo] Clip smaller domain from large domain netCDF file
Message-ID: <CAPB42UyySZ-3iXx-wSwL9ZxH9PO6WhpsCDy=p9_3Sq30z11NeA@mail.gmail.com>

Hi,
I have this huge ( ~30GB) .nc file (NC_FORMAT_NETCDF4_CLASSIC)) for the
whole country 141.00 to 52.00 W, 41.00 to 84.00 N".
I am trying to clip this big dataset for a small region specific domain
(120.00 to 130.00 W, 50.00 to 60.00 N).
I am trying to do using netCDF4 r package but could not figure out how to
do so.
Kindly please suggest me how should i proceed.


Thank you,

	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Wed Aug 27 01:59:45 2014
From: mdsumner at gmail.com (Michael Sumner)
Date: Wed, 27 Aug 2014 09:59:45 +1000
Subject: [R-sig-Geo] Clip smaller domain from large domain netCDF file
In-Reply-To: <CAPB42UyySZ-3iXx-wSwL9ZxH9PO6WhpsCDy=p9_3Sq30z11NeA@mail.gmail.com>
References: <CAPB42UyySZ-3iXx-wSwL9ZxH9PO6WhpsCDy=p9_3Sq30z11NeA@mail.gmail.com>
Message-ID: <CAAcGz98QYpdWi57mEwnTY5q3_cdXWf+PWpDeH58jWdLyZ=vAFg@mail.gmail.com>

First see if raster can open it:

library(raster)
r <- raster("/path/to/hugefile.nc")
r

That will require you have the ncdf4 package installed (I don't know
of any such package "netCDF4").

If that works, try to crop with

rc <- crop(r, extent(-130, -120, 50, 60))

possibly with an added filename argument, e.g.

rc <- crop(r, extent(-130, -120, 50, 60), filename =
"/different/physical/disk/out.grd")

But, this assumes you are only reading one slice in a possibly 3D or
even 4D data set. 30Gb suggests that you are dealing with at least a
time series here, so please report on the first attempt with raster.
You must also have some idea of what is in there so please include
that in your queries here.

If raster can't deal with it you'll need to use the general NetCDF
tools in ncdf4, so start with its documentation.

And please read the posting guide.

Cheers, Mike.


On Wed, Aug 27, 2014 at 9:48 AM, Aseem Sharma <nature.aseem at gmail.com> wrote:
> Hi,
> I have this huge ( ~30GB) .nc file (NC_FORMAT_NETCDF4_CLASSIC)) for the
> whole country 141.00 to 52.00 W, 41.00 to 84.00 N".
> I am trying to clip this big dataset for a small region specific domain
> (120.00 to 130.00 W, 50.00 to 60.00 N).
> I am trying to do using netCDF4 r package but could not figure out how to
> do so.
> Kindly please suggest me how should i proceed.
>
>
> Thank you,
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



-- 
Michael Sumner
Software and Database Engineer
Australian Antarctic Division
Hobart, Australia
e-mail: mdsumner at gmail.com


From nature.aseem at gmail.com  Wed Aug 27 02:18:38 2014
From: nature.aseem at gmail.com (Aseem Sharma)
Date: Tue, 26 Aug 2014 17:18:38 -0700
Subject: [R-sig-Geo] Clip smaller domain from large domain netCDF file
In-Reply-To: <CAAcGz98QYpdWi57mEwnTY5q3_cdXWf+PWpDeH58jWdLyZ=vAFg@mail.gmail.com>
References: <CAPB42UyySZ-3iXx-wSwL9ZxH9PO6WhpsCDy=p9_3Sq30z11NeA@mail.gmail.com>
	<CAAcGz98QYpdWi57mEwnTY5q3_cdXWf+PWpDeH58jWdLyZ=vAFg@mail.gmail.com>
Message-ID: <CAPB42UwBmB_kMDyKE8r6ocFV1S19A4ejVFcGeHYbapD1eg_csw@mail.gmail.com>

Hi Michael, Thank you and regrets for poor questioning and typo. I mean
ncdf4.
Yes the .nc file has three variables namely precipitation, Tmin and Tmax
with their time series. I can read it using raster.
the print function give details of data as below.
(NC_FORMAT_NETCDF4_CLASSIC):"
[1] ""
[1] "     3 variables (excluding dimension variables):"
[1] "        float pr[lon,lat,time]   "
[1] "            standard_name: precipitation_flux"
[1] "            long_name: Precipitation"
[1] "            units: mm day-1"
[1] "            _FillValue: -32768"
[1] "            cell_methods: time: mean"
[1] "        float tasmax[lon,lat,time]   "
[1] "            standard_name: air_temperature"
[1] "            long_name: Daily Maximum Near-Surface Air Temperature"
[1] "            units: degC"
[1] "            _FillValue: -32768"
[1] "            cell_methods: time: maximum"
[1] "        float tasmin[lon,lat,time]   "
[1] "            standard_name: air_temperature"
[1] "            long_name: Daily Minimum Near-Surface Air Temperature"
[1] "            units: degC"
[1] "            _FillValue: -32768"
[1] "            cell_methods: time: minimum"
[1] ""
[1] "     3 dimensions:"
[1] "        lon  Size:1068"
[1] "            standard_name: longitude"
[1] "            long_name: longitude"
[1] "            units: degrees_east"
[1] "            axis: X"
[1] "        lat  Size:510"
[1] "            standard_name: latitude"
[1] "            long_name: latitude"
[1] "            units: degrees_north"
[1] "            axis: Y"
[1] "        time  Size:22280   *** is unlimited ***"
[1] "            standard_name: time"
[1] "            long_name: time"
[1] "            units: days since 1950-01-01 00:00:00"
[1] "            calendar: standard"

I am trying to using netCDf tools in ncdf4 but not figure out how to do so.
Thank you,



------------------

"Namaste ??????"

Aseem Sharma

Graduate Research Assistant

Northern Hydrometeorology Group(NHG)

Natural Resources and Environmental Studies Institute(NRESi)

University of Northern British Columbia

Prince George, BC, V2N 4Z9, Canada

Tel: 250-960-5427

Web: http://www.unbc.ca/


 "All know the Way, but few actually walk it."
"????? ?????? ???? ?"




On Tue, Aug 26, 2014 at 4:59 PM, Michael Sumner <mdsumner at gmail.com> wrote:

> First see if raster can open it:
>
> library(raster)
> r <- raster("/path/to/hugefile.nc")
> r
>
> That will require you have the ncdf4 package installed (I don't know
> of any such package "netCDF4").
>
> If that works, try to crop with
>
> rc <- crop(r, extent(-130, -120, 50, 60))
>
> possibly with an added filename argument, e.g.
>
> rc <- crop(r, extent(-130, -120, 50, 60), filename =
> "/different/physical/disk/out.grd")
>
> But, this assumes you are only reading one slice in a possibly 3D or
> even 4D data set. 30Gb suggests that you are dealing with at least a
> time series here, so please report on the first attempt with raster.
> You must also have some idea of what is in there so please include
> that in your queries here.
>
> If raster can't deal with it you'll need to use the general NetCDF
> tools in ncdf4, so start with its documentation.
>
> And please read the posting guide.
>
> Cheers, Mike.
>
>
> On Wed, Aug 27, 2014 at 9:48 AM, Aseem Sharma <nature.aseem at gmail.com>
> wrote:
> > Hi,
> > I have this huge ( ~30GB) .nc file (NC_FORMAT_NETCDF4_CLASSIC)) for the
> > whole country 141.00 to 52.00 W, 41.00 to 84.00 N".
> > I am trying to clip this big dataset for a small region specific domain
> > (120.00 to 130.00 W, 50.00 to 60.00 N).
> > I am trying to do using netCDF4 r package but could not figure out how to
> > do so.
> > Kindly please suggest me how should i proceed.
> >
> >
> > Thank you,
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>
> --
> Michael Sumner
> Software and Database Engineer
> Australian Antarctic Division
> Hobart, Australia
> e-mail: mdsumner at gmail.com
>

	[[alternative HTML version deleted]]


From sanctavega at gmail.com  Wed Aug 27 17:30:43 2014
From: sanctavega at gmail.com (Sancta Vega)
Date: Wed, 27 Aug 2014 15:30:43 +0000
Subject: [R-sig-Geo] RGEOS error
Message-ID: <CAHy2=VKb2b-UnFruBafsadUbk=TW6GWcN1+wdEBsssPqCPzejQ@mail.gmail.com>

HI,
Just for dissolving I use the rgeos package with "gUnaryUnion".
But I get this error :" No UnaryUnion in this version of GEOS".
I remove the package and install it again but I get the same error.
Is it linked to my version of R  or something else?
Thank you in advance.

	[[alternative HTML version deleted]]


From rundel at gmail.com  Wed Aug 27 18:20:43 2014
From: rundel at gmail.com (Colin Rundel)
Date: Wed, 27 Aug 2014 12:20:43 -0400
Subject: [R-sig-Geo] RGEOS error
In-Reply-To: <CAHy2=VKb2b-UnFruBafsadUbk=TW6GWcN1+wdEBsssPqCPzejQ@mail.gmail.com>
References: <CAHy2=VKb2b-UnFruBafsadUbk=TW6GWcN1+wdEBsssPqCPzejQ@mail.gmail.com>
Message-ID: <21814CDF-30E5-4FED-B59D-1738AD6E40EB@gmail.com>

Hi Sancta,

The issue is likely occurring due to the version of the geos C library you have installed on your system. You will need to provide us with a few more detail on what operating system you are running. Additionally, if you are on a unix/linux or mac system try running `geos-config ?version` in your terminal and report back to us what version you get, anything with a major version 3 should support the unary union.

-Colin

On Aug 27, 2014, at 11:30 AM, Sancta Vega <sanctavega at gmail.com> wrote:

> HI,
> Just for dissolving I use the rgeos package with "gUnaryUnion".
> But I get this error :" No UnaryUnion in this version of GEOS".
> I remove the package and install it again but I get the same error.
> Is it linked to my version of R  or something else?
> Thank you in advance.
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From jbaldwin at fs.fed.us  Wed Aug 27 18:21:47 2014
From: jbaldwin at fs.fed.us (Baldwin, Jim -FS)
Date: Wed, 27 Aug 2014 16:21:47 +0000
Subject: [R-sig-Geo] RGEOS error
In-Reply-To: <CAHy2=VKb2b-UnFruBafsadUbk=TW6GWcN1+wdEBsssPqCPzejQ@mail.gmail.com>
References: <CAHy2=VKb2b-UnFruBafsadUbk=TW6GWcN1+wdEBsssPqCPzejQ@mail.gmail.com>
Message-ID: <DDC5EC9B78340042B0D5A0C3789D456919B14482@001FSN2MPN1-062.001f.mgd2.msft.net>

When you also simultaneously post the question elsewhere (http://stackoverflow.com/questions/25531430/rgeos-error-when-using-gunaryunion), please note that to both lists.

And that post has more useful information included than the post to this list:

    Just for dissolving I use the rgeos package with gUnaryUnion. But I get this error :No UnaryUnion in this version of GEOS.
    I remove the package and install it again but I get the same error. Is it linked to my version of R or something else? This my code:

         require("rgeos")
         summary(utah) #
         regional= gUnaryUnion(utah,utah$region)

    Thank you in advance.

-----Original Message-----
From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of Sancta Vega
Sent: Wednesday, August 27, 2014 8:31 AM
To: r-sig-geo at r-project.org
Subject: [R-sig-Geo] RGEOS error

HI,
Just for dissolving I use the rgeos package with "gUnaryUnion".
But I get this error :" No UnaryUnion in this version of GEOS".
I remove the package and install it again but I get the same error.
Is it linked to my version of R  or something else?
Thank you in advance.

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo




This electronic message contains information generated by the USDA solely for the intended recipients. Any unauthorized interception of this message or the use or disclosure of the information it contains may violate the law and subject the violator to civil or criminal penalties. If you believe you have received this message in error, please notify the sender and delete the email immediately.


From Roger.Bivand at nhh.no  Wed Aug 27 18:23:26 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 27 Aug 2014 18:23:26 +0200
Subject: [R-sig-Geo] RGEOS error
In-Reply-To: <CAHy2=VKb2b-UnFruBafsadUbk=TW6GWcN1+wdEBsssPqCPzejQ@mail.gmail.com>
References: <CAHy2=VKb2b-UnFruBafsadUbk=TW6GWcN1+wdEBsssPqCPzejQ@mail.gmail.com>
Message-ID: <alpine.LRH.2.03.1408271804270.811@reclus.nhh.no>

On Wed, 27 Aug 2014, Sancta Vega wrote:

> HI,
> Just for dissolving I use the rgeos package with "gUnaryUnion".
> But I get this error :" No UnaryUnion in this version of GEOS".
> I remove the package and install it again but I get the same error.
> Is it linked to my version of R  or something else?
> Thank you in advance.
>
> 	[[alternative HTML version deleted]]
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Please only post plain text, HTML may carry unwanted payloads.

Please do provide the output of sessionInfo() and the messages shown on 
the console when rgeos is loaded.

Most likely your platform is Linux, probably old Debian or Ubuntu, and 
that your installed GEOS is version < 3.3.0; version_GEOS0() also returns 
your GEOS version directly.

On the help page ?gUnaryUnion you see that you should use gUnionCascaded() 
instead:

     "gUnionCascaded expects a single sp object of class SpatialPolygons
      with subgeometries which it unions together. gUnionCascaded can
      only dissolve MultiPolygon objects, so GeometryCollection objects
      to be dissolved, here a SpatialPolygons object, must be flattened
      a Polygons object; if GEOS version 3.3.0 is available, use
      gUnaryUnion."

I.e. fortunes::fortune(14) applies.

Version 3.3.0 was released in May 2011, so very few users are still 
suffering such old components, but in Debian, squeeze still has 3.2.0, 
wheezy 3.3.3, and newer at 3.4.2 (current release).

I doubt Windows or OSX, to be honest, but if so, you've installed rgeos 
from source linking to an ancient version of GEOS.

Hope this clarifies,

Roger

>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From sanctavega at gmail.com  Wed Aug 27 19:06:43 2014
From: sanctavega at gmail.com (Sancta Vega)
Date: Wed, 27 Aug 2014 17:06:43 +0000
Subject: [R-sig-Geo] Error with RGEOS
Message-ID: <CAHy2=VLYTnExgj-Xt_bwxPznUR78KFCtkTdASh=kWn6GYXCcMA@mail.gmail.com>

Just for dissolving I use the rgeos package with gUnaryUnion. But I get
this error :No UnaryUnion in this version of GEOS. I remove the package and
install it again but I get the same error. Is it linked to my version of R
or something else? This my code:

     require("rgeos")
     summary(utah) #
     regional= gUnaryUnion(utah,utah$region)


According to your suggestion I ask my question with more details:

For my R version:
R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
Copyright (C) 2013 The R Foundation for Statistical Computing
Platform: i686-pc-linux-gnu (32-bit)


>From library (rgeos) I get this warning :
rgeos version: 0.3-6, (SVN revision 450)
 GEOS runtime version: 3.2.2-CAPI-1.6.2
 Polygon checking: TRUE


Thank you

	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Wed Aug 27 19:21:19 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 27 Aug 2014 19:21:19 +0200
Subject: [R-sig-Geo] Error with RGEOS
In-Reply-To: <CAHy2=VLYTnExgj-Xt_bwxPznUR78KFCtkTdASh=kWn6GYXCcMA@mail.gmail.com>
References: <CAHy2=VLYTnExgj-Xt_bwxPznUR78KFCtkTdASh=kWn6GYXCcMA@mail.gmail.com>
Message-ID: <alpine.LRH.2.03.1408271909060.811@reclus.nhh.no>

DO NOT SEND HTML!!!

DO REPLY IN-THREAD - IF YOU DO NOT; NOBODY SEEING YOUR FIRST QUESTION WILL 
FIND ANY RESPONSES TO YOUR SECOND QUESTION.

On Wed, 27 Aug 2014, Sancta Vega wrote:

> Just for dissolving I use the rgeos package with gUnaryUnion. But I get
> this error :No UnaryUnion in this version of GEOS. I remove the package and
> install it again but I get the same error. Is it linked to my version of R
> or something else? This my code:
>
>     require("rgeos")
>     summary(utah) #
>     regional= gUnaryUnion(utah,utah$region)
>
>
> According to your suggestion I ask my question with more details:
>
> For my R version:
> R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
> Copyright (C) 2013 The R Foundation for Statistical Computing
> Platform: i686-pc-linux-gnu (32-bit)
>
>
>> From library (rgeos) I get this warning :
> rgeos version: 0.3-6, (SVN revision 450)
> GEOS runtime version: 3.2.2-CAPI-1.6.2

So your GEOS is 3.2.2, released March 2010, and as I wrote before, 
gUnaryUnion() is only available from GEOS 3.3.0.

Did you yourself install GEOS, or did someone else? Do you have multiple 
copies of GEOS installed to match other applications (PostGIS, QGIS), and 
have muddle in the search order of shared objects? Which GEOS was fould 
when rgeos was installed (it is reported to the console during 
installation)?

Did you try what I suggested, gUnionCascaded()? It does the same as 
gUnaryUnion(), but less efficiently. If you need gUnaryUnion(), upgrade 
GEOS to at least 3.3.0, and re-install rgeos.

Please do try to adhere to the instructions and posting guide for R 
lists, linked from the list page whose address is appended to every 
message published.

Roger

> Polygon checking: TRUE
>
>
> Thank you
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From jwm302 at gmail.com  Thu Aug 28 14:44:48 2014
From: jwm302 at gmail.com (Justin Michell)
Date: Thu, 28 Aug 2014 14:44:48 +0200
Subject: [R-sig-Geo] Verify units of distance between coordinates
Message-ID: <0D665D1E-F2F9-4846-B424-6F97FCA93A6B@gmail.com>

Dear geo R group

I have a data frame like this:

df <- data.frame(Lon = c(29.6000,29.7333,30.3887,30.6667,30.6833,30.8667), Lat = c(-4.9000,-4.6000,-5.1280,-1.0667,-2.7500,-3.3833),  
                  LonWater = c(29.63333,29.63333,30.25000,30.65000,30.35444,30.83278), LatWater = c(-4.31667,-4.31667,-4.76667,-1.35000,-2.46667,-3.57000), DstClW = c(0.5842815,0.3004491,0.3870362,0.2837918,0.4340793,0.1897561) )

At these locations (Lon, Lat pairs) I calculated the shortest distance to a water source (DstClW) and where that source is (LonWater, LatWater).

I want to now determine what units DstClW is in, and also verify that these distances make sense and were calculated correctly. 

Any suggestions as to how this might be done?

Regards
Justin Michell

 


From sarah.goslee at gmail.com  Thu Aug 28 14:50:49 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 28 Aug 2014 08:50:49 -0400
Subject: [R-sig-Geo] Verify units of distance between coordinates
In-Reply-To: <0D665D1E-F2F9-4846-B424-6F97FCA93A6B@gmail.com>
References: <0D665D1E-F2F9-4846-B424-6F97FCA93A6B@gmail.com>
Message-ID: <CAM_vjukf3+f2r3ui2nvQxpa6mWzYf0i8QnkeSUyAcL-ArvbxAQ@mail.gmail.com>

They don't make sense.

Best: convert them into a projection where the distances are in meters
already, like UTM. Then distances calculated on your new coordinates
are in meters.

Latitude and longitude don't translate neatly into distances on their own.

Second best: find and use a great circle distance function that can
determine the correct distances for where those lat/lon coordinates
are on the earth's surface. There's been discussion on this list
before about calculating distances from geographic coordinates; google
should find them.

Sarah

On Thu, Aug 28, 2014 at 8:44 AM, Justin Michell <jwm302 at gmail.com> wrote:
> Dear geo R group
>
> I have a data frame like this:
>
> df <- data.frame(Lon = c(29.6000,29.7333,30.3887,30.6667,30.6833,30.8667), Lat = c(-4.9000,-4.6000,-5.1280,-1.0667,-2.7500,-3.3833),
>                   LonWater = c(29.63333,29.63333,30.25000,30.65000,30.35444,30.83278), LatWater = c(-4.31667,-4.31667,-4.76667,-1.35000,-2.46667,-3.57000), DstClW = c(0.5842815,0.3004491,0.3870362,0.2837918,0.4340793,0.1897561) )
>
> At these locations (Lon, Lat pairs) I calculated the shortest distance to a water source (DstClW) and where that source is (LonWater, LatWater).
>
> I want to now determine what units DstClW is in, and also verify that these distances make sense and were calculated correctly.
>
> Any suggestions as to how this might be done?
>
> Regards
> Justin Michell
>
>
>
-- 
Sarah Goslee
http://www.functionaldiversity.org


From mdsumner at gmail.com  Thu Aug 28 15:32:20 2014
From: mdsumner at gmail.com (Michael Sumner)
Date: Thu, 28 Aug 2014 23:32:20 +1000
Subject: [R-sig-Geo] Verify units of distance between coordinates
In-Reply-To: <CAM_vjukf3+f2r3ui2nvQxpa6mWzYf0i8QnkeSUyAcL-ArvbxAQ@mail.gmail.com>
References: <0D665D1E-F2F9-4846-B424-6F97FCA93A6B@gmail.com>
	<CAM_vjukf3+f2r3ui2nvQxpa6mWzYf0i8QnkeSUyAcL-ArvbxAQ@mail.gmail.com>
Message-ID: <CAAcGz9_bOSzLT1jyNdW_M=UeM+BSRDoaxrC8VLrDUu9rfcksKQ@mail.gmail.com>

On Thu, Aug 28, 2014 at 10:50 PM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
> They don't make sense.
>
> Best: convert them into a projection where the distances are in meters
> already, like UTM. Then distances calculated on your new coordinates
> are in meters.

However great circle from lat/lon is arguably the best since you can
really do get distance along a great circle (on the ellipsoid or the
sphere). (There are several algorithms, and also other methods for
e.g. loxodromes, and even other definitions of "straight".)

No projection has the property that any straight line is a great
circle, and most certainly *not* any of UTM family.

Cheers, Mike.


>
> Latitude and longitude don't translate neatly into distances on their own.
>
> Second best: find and use a great circle distance function that can
> determine the correct distances for where those lat/lon coordinates
> are on the earth's surface. There's been discussion on this list
> before about calculating distances from geographic coordinates; google
> should find them.
>
> Sarah
>
> On Thu, Aug 28, 2014 at 8:44 AM, Justin Michell <jwm302 at gmail.com> wrote:
>> Dear geo R group
>>
>> I have a data frame like this:
>>
>> df <- data.frame(Lon = c(29.6000,29.7333,30.3887,30.6667,30.6833,30.8667), Lat = c(-4.9000,-4.6000,-5.1280,-1.0667,-2.7500,-3.3833),
>>                   LonWater = c(29.63333,29.63333,30.25000,30.65000,30.35444,30.83278), LatWater = c(-4.31667,-4.31667,-4.76667,-1.35000,-2.46667,-3.57000), DstClW = c(0.5842815,0.3004491,0.3870362,0.2837918,0.4340793,0.1897561) )
>>
>> At these locations (Lon, Lat pairs) I calculated the shortest distance to a water source (DstClW) and where that source is (LonWater, LatWater).
>>
>> I want to now determine what units DstClW is in, and also verify that these distances make sense and were calculated correctly.
>>
>> Any suggestions as to how this might be done?
>>
>> Regards
>> Justin Michell
>>
>>
>>
> --
> Sarah Goslee
> http://www.functionaldiversity.org
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



-- 
Michael Sumner
Software and Database Engineer
Australian Antarctic Division
Hobart, Australia
e-mail: mdsumner at gmail.com


From sarah.goslee at gmail.com  Thu Aug 28 15:55:37 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 28 Aug 2014 09:55:37 -0400
Subject: [R-sig-Geo] Verify units of distance between coordinates
In-Reply-To: <CAAcGz9_bOSzLT1jyNdW_M=UeM+BSRDoaxrC8VLrDUu9rfcksKQ@mail.gmail.com>
References: <0D665D1E-F2F9-4846-B424-6F97FCA93A6B@gmail.com>
	<CAM_vjukf3+f2r3ui2nvQxpa6mWzYf0i8QnkeSUyAcL-ArvbxAQ@mail.gmail.com>
	<CAAcGz9_bOSzLT1jyNdW_M=UeM+BSRDoaxrC8VLrDUu9rfcksKQ@mail.gmail.com>
Message-ID: <CAM_vjunE_fjiFc7qOW3y4ciCn+QODHRo_FbFde4auCVyWW0zVw@mail.gmail.com>

On Thu, Aug 28, 2014 at 9:32 AM, Michael Sumner <mdsumner at gmail.com> wrote:
> On Thu, Aug 28, 2014 at 10:50 PM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>> They don't make sense.
>>
>> Best: convert them into a projection where the distances are in meters
>> already, like UTM. Then distances calculated on your new coordinates
>> are in meters.
>
> However great circle from lat/lon is arguably the best since you can
> really do get distance along a great circle (on the ellipsoid or the
> sphere). (There are several algorithms, and also other methods for
> e.g. loxodromes, and even other definitions of "straight".)
>
> No projection has the property that any straight line is a great
> circle, and most certainly *not* any of UTM family.

True, but as long as your points are reasonably close together,
something like UTM is a very useful approximation. And even great
circle is an approximation. The best answer depends on the data and
the objectives (as always!).

> Cheers, Mike.
>
>
>>
>> Latitude and longitude don't translate neatly into distances on their own.
>>
>> Second best: find and use a great circle distance function that can
>> determine the correct distances for where those lat/lon coordinates
>> are on the earth's surface. There's been discussion on this list
>> before about calculating distances from geographic coordinates; google
>> should find them.
>>
>> Sarah
>>
>> On Thu, Aug 28, 2014 at 8:44 AM, Justin Michell <jwm302 at gmail.com> wrote:
>>> Dear geo R group
>>>
>>> I have a data frame like this:
>>>
>>> df <- data.frame(Lon = c(29.6000,29.7333,30.3887,30.6667,30.6833,30.8667), Lat = c(-4.9000,-4.6000,-5.1280,-1.0667,-2.7500,-3.3833),
>>>                   LonWater = c(29.63333,29.63333,30.25000,30.65000,30.35444,30.83278), LatWater = c(-4.31667,-4.31667,-4.76667,-1.35000,-2.46667,-3.57000), DstClW = c(0.5842815,0.3004491,0.3870362,0.2837918,0.4340793,0.1897561) )
>>>
>>> At these locations (Lon, Lat pairs) I calculated the shortest distance to a water source (DstClW) and where that source is (LonWater, LatWater).
>>>
>>> I want to now determine what units DstClW is in, and also verify that these distances make sense and were calculated correctly.
>>>
>>> Any suggestions as to how this might be done?
>>>
>>> Regards
>>> Justin Michell
>>>
>>>


-- 
Sarah Goslee
http://www.functionaldiversity.org


From Roger.Bivand at nhh.no  Thu Aug 28 16:58:29 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 28 Aug 2014 16:58:29 +0200
Subject: [R-sig-Geo] Verify units of distance between coordinates
In-Reply-To: <CAM_vjunE_fjiFc7qOW3y4ciCn+QODHRo_FbFde4auCVyWW0zVw@mail.gmail.com>
References: <0D665D1E-F2F9-4846-B424-6F97FCA93A6B@gmail.com>
	<CAM_vjukf3+f2r3ui2nvQxpa6mWzYf0i8QnkeSUyAcL-ArvbxAQ@mail.gmail.com>
	<CAAcGz9_bOSzLT1jyNdW_M=UeM+BSRDoaxrC8VLrDUu9rfcksKQ@mail.gmail.com>
	<CAM_vjunE_fjiFc7qOW3y4ciCn+QODHRo_FbFde4auCVyWW0zVw@mail.gmail.com>
Message-ID: <alpine.LRH.2.03.1408281632570.4825@reclus.nhh.no>

On Thu, 28 Aug 2014, Sarah Goslee wrote:

> On Thu, Aug 28, 2014 at 9:32 AM, Michael Sumner <mdsumner at gmail.com> wrote:
>> On Thu, Aug 28, 2014 at 10:50 PM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>>> They don't make sense.
>>>
>>> Best: convert them into a projection where the distances are in meters
>>> already, like UTM. Then distances calculated on your new coordinates
>>> are in meters.
>>
>> However great circle from lat/lon is arguably the best since you can
>> really do get distance along a great circle (on the ellipsoid or the
>> sphere). (There are several algorithms, and also other methods for
>> e.g. loxodromes, and even other definitions of "straight".)
>>
>> No projection has the property that any straight line is a great
>> circle, and most certainly *not* any of UTM family.
>
> True, but as long as your points are reasonably close together,
> something like UTM is a very useful approximation. And even great
> circle is an approximation. The best answer depends on the data and
> the objectives (as always!).

The OP didn't say how the distances were computed:

library(sp)
locs <- SpatialPoints(cbind(Lon = c(29.6000, 29.7333, 30.3887, 30.6667,
  30.6833, 30.8667), Lat = c(-4.9000, -4.6000, -5.1280, -1.0667, -2.7500,
  -3.3833)), proj4string=CRS("+proj=longlat +datum=WGS84") )
src <- SpatialPoints(cbind(LonWater = c(29.63333, 29.63333, 30.25000,
  30.65000, 30.35444, 30.83278), LatWater = c(-4.31667, -4.31667, -4.76667,
  -1.35000, -2.46667, -3.57000)),
  proj4string=CRS("+proj=longlat +datum=WGS84"))

plot(locs)
plot(src, add=TRUE, col="red")

Naively using spDistsN1 appears to replicate the distances the OP got:

D0 <- lapply(1:length(locs), function(i) spDistsN1(src, locs[i],
  longlat=FALSE))

which is wrong.

D0 <- lapply(1:length(locs), function(i) spDistsN1(src, locs[i],
  longlat=TRUE))

is in km, but the minimum criterion is met by multiple pairs of points:

D1 <- lapply(D, function(x) x-min(x))
D1

so finding out which source is closest still isn't well-defined. To get 
minimum distances by location:

D2 <- sapply(D, min)

The spDists* functions use GC distances on a WGS84 ellipsoid, so are 
closer than a spheroid (many online shortcuts use spheroids), and will be 
OK if the input coordinates are also WGS84.

Hope this helps,

Roger

>
>> Cheers, Mike.
>>
>>
>>>
>>> Latitude and longitude don't translate neatly into distances on their own.
>>>
>>> Second best: find and use a great circle distance function that can
>>> determine the correct distances for where those lat/lon coordinates
>>> are on the earth's surface. There's been discussion on this list
>>> before about calculating distances from geographic coordinates; google
>>> should find them.
>>>
>>> Sarah
>>>
>>> On Thu, Aug 28, 2014 at 8:44 AM, Justin Michell <jwm302 at gmail.com> wrote:
>>>> Dear geo R group
>>>>
>>>> I have a data frame like this:
>>>>
>>>> df <- data.frame(Lon = 
>>>> c(29.6000,29.7333,30.3887,30.6667,30.6833,30.8667), Lat = 
>>>> c(-4.9000,-4.6000,-5.1280,-1.0667,-2.7500,-3.3833),
>>>>                   LonWater = 
>>>> c(29.63333,29.63333,30.25000,30.65000,30.35444,30.83278), LatWater = 
>>>> c(-4.31667,-4.31667,-4.76667,-1.35000,-2.46667,-3.57000), DstClW = 
>>>> c(0.5842815,0.3004491,0.3870362,0.2837918,0.4340793,0.1897561) )
>>>>
>>>> At these locations (Lon, Lat pairs) I calculated the shortest 
>>>> distance to a water source (DstClW) and where that source is 
>>>> (LonWater, LatWater).
>>>>
>>>> I want to now determine what units DstClW is in, and also verify that 
>>>> these distances make sense and were calculated correctly.
>>>>
>>>> Any suggestions as to how this might be done?
>>>>
>>>> Regards
>>>> Justin Michell
>>>>
>>>>
>
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Thu Aug 28 17:02:26 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 28 Aug 2014 17:02:26 +0200
Subject: [R-sig-Geo] Verify units of distance between coordinates
In-Reply-To: <alpine.LRH.2.03.1408281632570.4825@reclus.nhh.no>
References: <0D665D1E-F2F9-4846-B424-6F97FCA93A6B@gmail.com>
	<CAM_vjukf3+f2r3ui2nvQxpa6mWzYf0i8QnkeSUyAcL-ArvbxAQ@mail.gmail.com>
	<CAAcGz9_bOSzLT1jyNdW_M=UeM+BSRDoaxrC8VLrDUu9rfcksKQ@mail.gmail.com>
	<CAM_vjunE_fjiFc7qOW3y4ciCn+QODHRo_FbFde4auCVyWW0zVw@mail.gmail.com>
	<alpine.LRH.2.03.1408281632570.4825@reclus.nhh.no>
Message-ID: <alpine.LRH.2.03.1408281701520.4825@reclus.nhh.no>

On Thu, 28 Aug 2014, Roger Bivand wrote:

> On Thu, 28 Aug 2014, Sarah Goslee wrote:
>
>> On Thu, Aug 28, 2014 at 9:32 AM, Michael Sumner <mdsumner at gmail.com> wrote:
>>> On Thu, Aug 28, 2014 at 10:50 PM, Sarah Goslee <sarah.goslee at gmail.com> 
>>> wrote:
>>>> They don't make sense.
>>>> 
>>>> Best: convert them into a projection where the distances are in meters
>>>> already, like UTM. Then distances calculated on your new coordinates
>>>> are in meters.
>>> 
>>> However great circle from lat/lon is arguably the best since you can
>>> really do get distance along a great circle (on the ellipsoid or the
>>> sphere). (There are several algorithms, and also other methods for
>>> e.g. loxodromes, and even other definitions of "straight".)
>>> 
>>> No projection has the property that any straight line is a great
>>> circle, and most certainly *not* any of UTM family.
>> 
>> True, but as long as your points are reasonably close together,
>> something like UTM is a very useful approximation. And even great
>> circle is an approximation. The best answer depends on the data and
>> the objectives (as always!).
>
> The OP didn't say how the distances were computed:
>
> library(sp)
> locs <- SpatialPoints(cbind(Lon = c(29.6000, 29.7333, 30.3887, 30.6667,
> 30.6833, 30.8667), Lat = c(-4.9000, -4.6000, -5.1280, -1.0667, -2.7500,
> -3.3833)), proj4string=CRS("+proj=longlat +datum=WGS84") )
> src <- SpatialPoints(cbind(LonWater = c(29.63333, 29.63333, 30.25000,
> 30.65000, 30.35444, 30.83278), LatWater = c(-4.31667, -4.31667, -4.76667,
> -1.35000, -2.46667, -3.57000)),
> proj4string=CRS("+proj=longlat +datum=WGS84"))
>
> plot(locs)
> plot(src, add=TRUE, col="red")
>
> Naively using spDistsN1 appears to replicate the distances the OP got:
>
> D0 <- lapply(1:length(locs), function(i) spDistsN1(src, locs[i],
> longlat=FALSE))
>
> which is wrong.
>
> D0 <- lapply(1:length(locs), function(i) spDistsN1(src, locs[i],
> longlat=TRUE))

Sorry:

D <- lapply(1:length(locs), function(i) spDistsN1(src, locs[i],
  longlat=TRUE))

of course.

>
> is in km, but the minimum criterion is met by multiple pairs of points:
>
> D1 <- lapply(D, function(x) x-min(x))
> D1
>
> so finding out which source is closest still isn't well-defined. To get 
> minimum distances by location:
>
> D2 <- sapply(D, min)
>
> The spDists* functions use GC distances on a WGS84 ellipsoid, so are closer 
> than a spheroid (many online shortcuts use spheroids), and will be OK if the 
> input coordinates are also WGS84.
>
> Hope this helps,
>
> Roger
>
>> 
>>> Cheers, Mike.
>>> 
>>> 
>>>> 
>>>> Latitude and longitude don't translate neatly into distances on their 
>>>> own.
>>>> 
>>>> Second best: find and use a great circle distance function that can
>>>> determine the correct distances for where those lat/lon coordinates
>>>> are on the earth's surface. There's been discussion on this list
>>>> before about calculating distances from geographic coordinates; google
>>>> should find them.
>>>> 
>>>> Sarah
>>>> 
>>>> On Thu, Aug 28, 2014 at 8:44 AM, Justin Michell <jwm302 at gmail.com> wrote:
>>>>> Dear geo R group
>>>>> 
>>>>> I have a data frame like this:
>>>>> 
>>>>> df <- data.frame(Lon = 
>>>>> c(29.6000,29.7333,30.3887,30.6667,30.6833,30.8667), Lat = 
>>>>> c(-4.9000,-4.6000,-5.1280,-1.0667,-2.7500,-3.3833),
>>>>>                   LonWater = 
>>>>> c(29.63333,29.63333,30.25000,30.65000,30.35444,30.83278), LatWater = 
>>>>> c(-4.31667,-4.31667,-4.76667,-1.35000,-2.46667,-3.57000), DstClW = 
>>>>> c(0.5842815,0.3004491,0.3870362,0.2837918,0.4340793,0.1897561) )
>>>>> 
>>>>> At these locations (Lon, Lat pairs) I calculated the shortest distance 
>>>>> to a water source (DstClW) and where that source is (LonWater, 
>>>>> LatWater).
>>>>> 
>>>>> I want to now determine what units DstClW is in, and also verify that 
>>>>> these distances make sense and were calculated correctly.
>>>>> 
>>>>> Any suggestions as to how this might be done?
>>>>> 
>>>>> Regards
>>>>> Justin Michell
>>>>> 
>>>>> 
>> 
>> 
>> 
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From hengl at spatial-analyst.net  Thu Aug 28 17:10:22 2014
From: hengl at spatial-analyst.net (Tomislav Hengl)
Date: Thu, 28 Aug 2014 17:10:22 +0200
Subject: [R-sig-Geo] Comparison of prediction performance (mapping accuracy)
 - how to test if a method B is significantly more accurate than method A?
Message-ID: <53FF465E.9000009@spatial-analyst.net>


Dear list,

I'm trying to standardize a procedure to compare performance of 
competing spatial prediction methods. I know that this has been 
discussed in various literature and on various mailing lists, but I 
would be interested in any opinion I could get.

I am comparing (see below) 2 spatial prediction methods 
(regression-kriging and inverse distance interpolation) using 5-fold 
cross-validation and then testing if the difference between the two is 
significant. What I concluded is that there are two possible tests for 
the final residuals:
1. F-test to compare variances (cross-validation residuals),
2. t-test to compare mean values,

Both tests might be important, nevertheless the F-test ("var.test") 
seems to be more interesting to really be able to answer "is the method 
B significantly more accurate than method A?". It appears that the 
second test ("t.test") is only important if it fails -> which would mean 
that one of the methods systematically over or under-estimates the mean 
value (which should be 0). Did I maybe miss some important test?

Thank you!

R> library(GSIF)
R> library(gstat)
R> library(sp)
R> set.seed(2419)
R> demo(meuse, echo=FALSE)
R> omm1 <- fit.gstatModel(meuse, log1p(om)~dist+soil, meuse.grid)
Fitting a linear model...
Fitting a 2D variogram...
Saving an object of class 'gstatModel'...
R> rk1 <- predict(omm1, meuse.grid)
R> meuse.s <- meuse[!is.na(meuse$om),]
R> ok1 <- krige.cv(log1p(om)~1, meuse.s, nfold=5)
R> var.test(ok1$residual, rk1 at validation$residual, alternative = "greater")

         F test to compare two variances

data:  ok1$residual and rk1 at validation$residual
F = 1.2283, num df = 152, denom df = 152, p-value =
0.103
alternative hypothesis: true ratio of variances is greater than 1
95 percent confidence interval:
  0.9398662       Inf
sample estimates:
ratio of variances
           1.228322
R> ## No significant difference
R> t.test(ok1$residual, rk1 at validation$residual)

         Welch Two Sample t-test

data:  ok1$residual and rk1 at validation$residual
t = -0.0204, df = 300.842, p-value = 0.9837
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
  -0.07084667  0.06939220
sample estimates:
    mean of x    mean of y
0.0004766718 0.0012039089
R> ## Again, no significant difference

R> sessionInfo()
R version 3.0.3 (2014-03-06)
Platform: x86_64-w64-mingw32/x64 (64-bit)
other attached packages:
[1] randomForest_4.6-7 nortest_1.0-2
[3] gstat_1.0-19       GSIF_0.4-2
[5] sp_1.0-15          gap_1.1-12


From tim.appelhans at gmail.com  Thu Aug 28 17:28:30 2014
From: tim.appelhans at gmail.com (Tim Appelhans)
Date: Thu, 28 Aug 2014 17:28:30 +0200
Subject: [R-sig-Geo] Comparison of prediction performance (mapping
 accuracy) - how to test if a method B is significantly more accurate than
 method A?
In-Reply-To: <53FF465E.9000009@spatial-analyst.net>
References: <53FF465E.9000009@spatial-analyst.net>
Message-ID: <53FF4A9E.2080008@gmail.com>


On 08/28/2014 05:10 PM, Tomislav Hengl wrote:
>
> Dear list,
>
> I'm trying to standardize a procedure to compare performance of 
> competing spatial prediction methods. I know that this has been 
> discussed in various literature and on various mailing lists, but I 
> would be interested in any opinion I could get.
>
> I am comparing (see below) 2 spatial prediction methods 
> (regression-kriging and inverse distance interpolation) using 5-fold 
> cross-validation and then testing if the difference between the two is 
> significant. What I concluded is that there are two possible tests for 
> the final residuals:
> 1. F-test to compare variances (cross-validation residuals),
> 2. t-test to compare mean values,
If you think in terms of accuracy vs. precision, I'd say both tests are 
equally important. Ideally you want your method to be precise (low 
variance) and accurate (low deviation around mean). What I usually tend 
to do is repeated random sub-sampling with 100+ runs.
>
> Both tests might be important, nevertheless the F-test ("var.test") 
> seems to be more interesting to really be able to answer "is the 
> method B significantly more accurate than method A?". It appears that 
> the second test ("t.test") is only important if it fails -> which 
> would mean that one of the methods systematically over or 
> under-estimates the mean value (which should be 0). Did I maybe miss 
> some important test?
>
> Thank you!
>
> R> library(GSIF)
> R> library(gstat)
> R> library(sp)
> R> set.seed(2419)
> R> demo(meuse, echo=FALSE)
> R> omm1 <- fit.gstatModel(meuse, log1p(om)~dist+soil, meuse.grid)
> Fitting a linear model...
> Fitting a 2D variogram...
> Saving an object of class 'gstatModel'...
> R> rk1 <- predict(omm1, meuse.grid)
> R> meuse.s <- meuse[!is.na(meuse$om),]
> R> ok1 <- krige.cv(log1p(om)~1, meuse.s, nfold=5)
> R> var.test(ok1$residual, rk1 at validation$residual, alternative = 
> "greater")
>
>         F test to compare two variances
>
> data:  ok1$residual and rk1 at validation$residual
> F = 1.2283, num df = 152, denom df = 152, p-value =
> 0.103
> alternative hypothesis: true ratio of variances is greater than 1
> 95 percent confidence interval:
>  0.9398662       Inf
> sample estimates:
> ratio of variances
>           1.228322
> R> ## No significant difference
> R> t.test(ok1$residual, rk1 at validation$residual)
>
>         Welch Two Sample t-test
>
> data:  ok1$residual and rk1 at validation$residual
> t = -0.0204, df = 300.842, p-value = 0.9837
> alternative hypothesis: true difference in means is not equal to 0
> 95 percent confidence interval:
>  -0.07084667  0.06939220
> sample estimates:
>    mean of x    mean of y
> 0.0004766718 0.0012039089
> R> ## Again, no significant difference
>
> R> sessionInfo()
> R version 3.0.3 (2014-03-06)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> other attached packages:
> [1] randomForest_4.6-7 nortest_1.0-2
> [3] gstat_1.0-19       GSIF_0.4-2
> [5] sp_1.0-15          gap_1.1-12
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
#####################################
Tim Appelhans
Department of Geography
Environmental Informatics
Philipps Universit?t Marburg
Deutschhausstra?e 12
35032 Marburg (Paketpost: 35037 Marburg)
Germany

Tel +49 (0) 6421 28-25957

http://environmentalinformatics-marburg.de/


	[[alternative HTML version deleted]]


From phil.haines82 at gmail.com  Thu Aug 28 18:45:19 2014
From: phil.haines82 at gmail.com (Phil Haines)
Date: Thu, 28 Aug 2014 16:45:19 +0000
Subject: [R-sig-Geo]
	=?utf-8?q?maptools/kmlPolygons_not_outputting_all_Pol?=
	=?utf-8?q?ygon=09objects?=
References: <FDA6B65298E3664FACCCD6F34EB939E4160C9FF796@MAILUK2.rms.com>
	<53F9C9B5.9010305@spatial-analyst.net>
Message-ID: <loom.20140828T184450-337@post.gmane.org>

> Tomislav Hengl <hengl <at> spatial-analyst.net> writes:

> I've tried creating a KML file using the plotKML package and I did not 
> notice anything strange with Alaska:

Hi Tomislav,

Thank you for your reply, I was not previously aware of the plotKML 
package but am finding it very helpful. 

I did not mean to suggest a fault in the wrld_simpl data. I think my 
issue lies with the maptools:::kmlPolygons function which appears to 
access only the first Polygon within each Polygons object.

As far as I can tell this function
-Loops over the list of spatialPolygons
 -Loops over the list of Polygons for each spatialPolygon
  -Accesses only the first Polygon for each Polygons object

I believe that the final part should be a loop whereas currently it is 
of the form

polygon <- spatialPolygons at polygons[[i]]@Polygons[[1]]

I hope that this is of some help. I am very new to both R and these 
mailing lists but am trying to follow the rules as well as I can!

Thanks,
Phil Haines (RMS)

p.s. As an aside I have had to change the email address I subscribe with 
as my work email was filtering out all messages from this list. This has 
made it very hard to reply without breaking the thread so I am hoping 
that posting this message via 
http://news.gmane.org/gmane.comp.lang.r.geo will work.

I wondered if anyone had any advice for others in this situation? The 
only relevant post I've found on google is the following:

https://stat.ethz.ch/pipermail/r-help/2006-August/111039.html


From bitlavinit at gmail.com  Thu Aug 28 19:43:46 2014
From: bitlavinit at gmail.com (Vinit Bitla)
Date: Thu, 28 Aug 2014 12:43:46 -0500
Subject: [R-sig-Geo] Converting .hdf file to raster layer
In-Reply-To: <CAAcGz9_O7cE6bC22NBww9kRuyVoLC-Ooj21G+WP9Ata+J70G2Q@mail.gmail.com>
References: <1407976021.54447.YahooMailNeo@web192705.mail.sg3.yahoo.com>
	<CAAcGz9_O7cE6bC22NBww9kRuyVoLC-Ooj21G+WP9Ata+J70G2Q@mail.gmail.com>
Message-ID: <CAJjwQNdRr1p7if6NN1uCL9EPYnUBUqkJCfVBWSWkMQfQ9mcScQ@mail.gmail.com>

Hello All,

Can any one can help me to convert this Lidar data latitude and longitude
in Degree Decimal format using R.

  latitude longitude elevation intensity

1 204140.7   4733835    334.14       6.4
2 204150.1   4733849    334.86      11.4

Appreciate your help.


Vinit



On Thu, Aug 14, 2014 at 3:52 AM, Michael Sumner <mdsumner at gmail.com> wrote:

> Just had a look, the file has subdatasets and seemingly raster can't
> handle those. (I haven't explored this much but might have a chance
> to).
>
> library(raster)
> library(rgdal)  ## built with HDF4, HDF5 and NetCDF4
>
> fsrc <- "
> ftp://ftp.star.nesdis.noaa.gov/pub/corp/scsb/wguo/data/VHP_16km/VH/VHP.G16.C07.NC.P1981035.ND.hdf
> "
> f <- basename(fsrc)
> if (!file.exists(f)) download.file(fsrc, f, mode = "wb")
>
> ## found with system GDAL, see below
> sds <- c('HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":0',
>          'HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":1',
>          'HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":2'
>          )
>
> ##r <- brick(sds)
> ##Error in GDALinfo(filename, silent = silent, returnRAT = RAT,
> returnCategoryNames = RAT) :
>  ## object 'RATlist' not found
> ##Error in .rasterObjectFromFile(x, band = band, objecttype =
> "RasterLayer",  :
>  ##                                Cannot create a RasterLayer object
> from this file.
>   ##                             In addition: Warning message:
>  ##                                In dim(x) : no bands in dataset
>
>
> ## try with rgdal directly, so far so good but
> ## no spatial-reference (again see gdalinfo output below)
> raster(readGDAL(sds[1])  )
>
>  raster(readGDAL(sds[1])  )
> HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":0 has GDAL driver
> HDF4Image
> and has 904 rows and 2500 columns
> class       : RasterLayer
> dimensions  : 904, 2500, 2260000  (nrow, ncol, ncell)
> resolution  : 1, 1  (x, y)
> extent      : 0, 2500, 0, 904  (xmin, xmax, ymin, ymax)
> coord. ref. : NA
> data source : in memory
> names       : band1
> values      : -99.9, 322  (min, max)
>
> Warning message:
> In readGDAL(sds[1]) : GeoTransform values not available
>
>
> ## proceed without caution, again values from gdalinfo
> b <- brick(stack(sapply(sds, function(x) raster(readGDAL(x)))))
> proj4string(b) <-  CRS(" +proj=longlat +ellps=WGS84 +datum=WGS84
> +no_defs +towgs84=0,0,0")
> extent(b) <- c(-180, 180, -55.15200043, 75.02400208)
>
> library(maptools
> data(wrld_simpl)
> plot(b, addfun = function() plot(wrld_simpl, add = TRUE))
>
> That looks ok to me, I don't know if it's WGS84 or the sphere or
> something else.
>
> Cheers, Mike.
>
>
>
>
>
> system(sprintf("gdalinfo %s", f))
>
> Driver: HDF4/Hierarchical Data Format Release 4
> Files: VHP.G16.C07.NC.P1981035.ND.hdf
> Size is 512, 512
> Coordinate System is `'
> Metadata:
>   ANCILLARY_FILES=FILE_CONFIGURE:vh.config
> FILE_PRELAUNCH_CALIBRATION:../ancillary/AVHRR_calibration_prelaunch.txt
> FILE_POSTLAUNCH_CALIBRATION:../ancillary/AVHRR_calibration_postlaunch.txt
> FILE_IGBP_LANDTYPE:../ancillary/igbp_landtype_GVIx.hdf
> FILE_METADATA_REGIONS:../ancillary/regions_for_metadata.txt
> FILE_EDF_NDVI:../ancillary/NVI_counts_ByLine_G04.hdf
> FILE_EDF_BT4:../ancillary/BT4_counts_ByLine_G04.hdf
>
>   CITATION_TO_DOCUMENTS=User Guide of Vegetation Health(VH) system
> (version 1.3, March 21 2012)
>   CONFIGURE_FILE_CONTENT=[Options for vh.exe]
> DIR_Ancillary=                 ../ancillary
> DIR_GVI=                       data/VH_unitTest1/weekly
> DIR_VH=                        data/VH_unitTest1/G04
> DIR_VH_META=                   data/VH_unitTest1/G04/meta
> DIR_CLIMAT=                    data/VH_EDF_v2/climate_G04
> DIR_CLIMAT_META=               data/VH_EDF_v2/climate_G04/meta
> FILE_PREFIX=       VHP
> Input_Data_Type=       VHP
> ResolutionString=              G04
> Days_Per_Period=               7
> FilterSize=                    15
> applyEDFonNDVI=                1     # 0: none, 1: linebyline for NVI;
> applyEDFonBT=                  1
> Instrument=                    AVHRR # so far AVHRR is the only option
> FORMAT_GVI=                   NETCDF #or HDF4
> FORMAT_CLIMAT=                HDF4
> FORMAT_ND=                    NETCDF
> FORMAT_SM=                    NETCDF
> FORMAT_VH=                    NETCDF
>
> [Periods of GVI data used for VH]
> # this section control which satellite will be used for calculating
> ND, SM and VH
> #satID satNumber yearWeek1 yearWeek2
> NC 07 198135 198449
> NF 09 198509 198844
> NH 11 198846 199436
> NJ 14 199504 200052
> NL 16 200101 200401
> NL 16 200405 200410
> NL 16 200425 200428
> NL 16 200430 200523
> NN 18 200524 201052
> NP 19 201101 399999
>
> [Periods of AVHRR data used for GVI climatology]
> #this section controls which satellite will be used for creating VH
> climatology
> #satID satNumber yearWeek1 yearWeek2
> NC 07 198142 198450
> NF 09 198515 198752
> NH 11 198920 199252
> NJ 14 199520 199952
> NL 16 200120 200252
>
> [END]
>
>
>   CONTACT=NOAA/NESDIS/STAR/EMB
>   DATE_BEGIN=239
>   DATE_END=245
>   DAYS_PER_PERIOD=7
>   END_LATITUDE_RANGE=-55.15200043
>   END_LONGITUDE_RANGE=180
>   INPUT_FILENAMES=data/VH_unitTest1/weekly/
> VHP.G04.C07.NC.P1981035.S239.E245.nc
>
>   INPUT_FILES=1
>   INSTRUMENT=AVHRR
>   PERIOD_OF_YEAR=35
>   PRODUCT_NAME=Vegetation Health
>   PROJECTION=Plate_Carree
>   SATELLITE=NC
>   START_LATITUDE_RANGE=75.02400208
>   START_LONGITUDE_RANGE=-180
>   TIME_BEGIN=00:00 UTC (use day time data only)
>   TIME_END=23:59 UTC (use day time data only)
>   VERSION=VH (vh.exe,version 1.3, March 21 2012)
>   YEAR=1981
> Subdatasets:
>   SUBDATASET_1_NAME=HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":0
>   SUBDATASET_1_DESC=[904x2500] BT4 (16-bit integer)
>   SUBDATASET_2_NAME=HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":1
>   SUBDATASET_2_DESC=[904x2500] NDVI (16-bit integer)
>   SUBDATASET_3_NAME=HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":2
>   SUBDATASET_3_DESC=[904x2500] QA (8-bit unsigned integer)
> Corner Coordinates:
> Upper Left  (    0.0,    0.0)
> Lower Left  (    0.0,  512.0)
> Upper Right (  512.0,    0.0)
> Lower Right (  512.0,  512.0)
> Center      (  256.0,  256.0)
>
> On Thu, Aug 14, 2014 at 10:27 AM, Arnold Salvacion
> <arnold_salvacion at yahoo.com> wrote:
> > Dear Colleagues,
> >
> > Does any here have already experience converting NOAA AVHRR VHP Product
> in .hdf (
> ftp://ftp.star.nesdis.noaa.gov/pub/corp/scsb/wguo/data/VHP_16km/VH/ )
> format to a raster layer in R?
> >
> >
> > Best regards,
> >
> > Arnold
> >         [[alternative HTML version deleted]]
> >
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
>
>
> --
> Michael Sumner
> Software and Database Engineer
> Australian Antarctic Division
> Hobart, Australia
> e-mail: mdsumner at gmail.com
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From koen.hufkens at gmail.com  Thu Aug 28 20:02:18 2014
From: koen.hufkens at gmail.com (Koen Hufkens)
Date: Thu, 28 Aug 2014 14:02:18 -0400
Subject: [R-sig-Geo] Converting .hdf file to raster layer
In-Reply-To: <CAJjwQNdRr1p7if6NN1uCL9EPYnUBUqkJCfVBWSWkMQfQ9mcScQ@mail.gmail.com>
References: <1407976021.54447.YahooMailNeo@web192705.mail.sg3.yahoo.com>
	<CAAcGz9_O7cE6bC22NBww9kRuyVoLC-Ooj21G+WP9Ata+J70G2Q@mail.gmail.com>
	<CAJjwQNdRr1p7if6NN1uCL9EPYnUBUqkJCfVBWSWkMQfQ9mcScQ@mail.gmail.com>
Message-ID: <CAHDtqq=jkVd-XQ=5+BLpKOnD6QK6Sv46wUz3PJmyMwh2bPig0g@mail.gmail.com>

Hi Vinti,

Have a look here:

http://gis.stackexchange.com/questions/20018/how-can-i-convert-data-in-the-form-of-lat-lon-value-into-a-raster-file-using-r

This should get you on your way.

Cheers,
K


On Thu, Aug 28, 2014 at 1:43 PM, Vinit Bitla <bitlavinit at gmail.com> wrote:

> Hello All,
>
> Can any one can help me to convert this Lidar data latitude and longitude
> in Degree Decimal format using R.
>
>   latitude longitude elevation intensity
>
> 1 204140.7   4733835    334.14       6.4
> 2 204150.1   4733849    334.86      11.4
>
> Appreciate your help.
>
>
> Vinit
>
>
>
> On Thu, Aug 14, 2014 at 3:52 AM, Michael Sumner <mdsumner at gmail.com>
> wrote:
>
> > Just had a look, the file has subdatasets and seemingly raster can't
> > handle those. (I haven't explored this much but might have a chance
> > to).
> >
> > library(raster)
> > library(rgdal)  ## built with HDF4, HDF5 and NetCDF4
> >
> > fsrc <- "
> >
> ftp://ftp.star.nesdis.noaa.gov/pub/corp/scsb/wguo/data/VHP_16km/VH/VHP.G16.C07.NC.P1981035.ND.hdf
> > "
> > f <- basename(fsrc)
> > if (!file.exists(f)) download.file(fsrc, f, mode = "wb")
> >
> > ## found with system GDAL, see below
> > sds <- c('HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":0',
> >          'HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":1',
> >          'HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":2'
> >          )
> >
> > ##r <- brick(sds)
> > ##Error in GDALinfo(filename, silent = silent, returnRAT = RAT,
> > returnCategoryNames = RAT) :
> >  ## object 'RATlist' not found
> > ##Error in .rasterObjectFromFile(x, band = band, objecttype =
> > "RasterLayer",  :
> >  ##                                Cannot create a RasterLayer object
> > from this file.
> >   ##                             In addition: Warning message:
> >  ##                                In dim(x) : no bands in dataset
> >
> >
> > ## try with rgdal directly, so far so good but
> > ## no spatial-reference (again see gdalinfo output below)
> > raster(readGDAL(sds[1])  )
> >
> >  raster(readGDAL(sds[1])  )
> > HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":0 has GDAL driver
> > HDF4Image
> > and has 904 rows and 2500 columns
> > class       : RasterLayer
> > dimensions  : 904, 2500, 2260000  (nrow, ncol, ncell)
> > resolution  : 1, 1  (x, y)
> > extent      : 0, 2500, 0, 904  (xmin, xmax, ymin, ymax)
> > coord. ref. : NA
> > data source : in memory
> > names       : band1
> > values      : -99.9, 322  (min, max)
> >
> > Warning message:
> > In readGDAL(sds[1]) : GeoTransform values not available
> >
> >
> > ## proceed without caution, again values from gdalinfo
> > b <- brick(stack(sapply(sds, function(x) raster(readGDAL(x)))))
> > proj4string(b) <-  CRS(" +proj=longlat +ellps=WGS84 +datum=WGS84
> > +no_defs +towgs84=0,0,0")
> > extent(b) <- c(-180, 180, -55.15200043, 75.02400208)
> >
> > library(maptools
> > data(wrld_simpl)
> > plot(b, addfun = function() plot(wrld_simpl, add = TRUE))
> >
> > That looks ok to me, I don't know if it's WGS84 or the sphere or
> > something else.
> >
> > Cheers, Mike.
> >
> >
> >
> >
> >
> > system(sprintf("gdalinfo %s", f))
> >
> > Driver: HDF4/Hierarchical Data Format Release 4
> > Files: VHP.G16.C07.NC.P1981035.ND.hdf
> > Size is 512, 512
> > Coordinate System is `'
> > Metadata:
> >   ANCILLARY_FILES=FILE_CONFIGURE:vh.config
> > FILE_PRELAUNCH_CALIBRATION:../ancillary/AVHRR_calibration_prelaunch.txt
> > FILE_POSTLAUNCH_CALIBRATION:../ancillary/AVHRR_calibration_postlaunch.txt
> > FILE_IGBP_LANDTYPE:../ancillary/igbp_landtype_GVIx.hdf
> > FILE_METADATA_REGIONS:../ancillary/regions_for_metadata.txt
> > FILE_EDF_NDVI:../ancillary/NVI_counts_ByLine_G04.hdf
> > FILE_EDF_BT4:../ancillary/BT4_counts_ByLine_G04.hdf
> >
> >   CITATION_TO_DOCUMENTS=User Guide of Vegetation Health(VH) system
> > (version 1.3, March 21 2012)
> >   CONFIGURE_FILE_CONTENT=[Options for vh.exe]
> > DIR_Ancillary=                 ../ancillary
> > DIR_GVI=                       data/VH_unitTest1/weekly
> > DIR_VH=                        data/VH_unitTest1/G04
> > DIR_VH_META=                   data/VH_unitTest1/G04/meta
> > DIR_CLIMAT=                    data/VH_EDF_v2/climate_G04
> > DIR_CLIMAT_META=               data/VH_EDF_v2/climate_G04/meta
> > FILE_PREFIX=       VHP
> > Input_Data_Type=       VHP
> > ResolutionString=              G04
> > Days_Per_Period=               7
> > FilterSize=                    15
> > applyEDFonNDVI=                1     # 0: none, 1: linebyline for NVI;
> > applyEDFonBT=                  1
> > Instrument=                    AVHRR # so far AVHRR is the only option
> > FORMAT_GVI=                   NETCDF #or HDF4
> > FORMAT_CLIMAT=                HDF4
> > FORMAT_ND=                    NETCDF
> > FORMAT_SM=                    NETCDF
> > FORMAT_VH=                    NETCDF
> >
> > [Periods of GVI data used for VH]
> > # this section control which satellite will be used for calculating
> > ND, SM and VH
> > #satID satNumber yearWeek1 yearWeek2
> > NC 07 198135 198449
> > NF 09 198509 198844
> > NH 11 198846 199436
> > NJ 14 199504 200052
> > NL 16 200101 200401
> > NL 16 200405 200410
> > NL 16 200425 200428
> > NL 16 200430 200523
> > NN 18 200524 201052
> > NP 19 201101 399999
> >
> > [Periods of AVHRR data used for GVI climatology]
> > #this section controls which satellite will be used for creating VH
> > climatology
> > #satID satNumber yearWeek1 yearWeek2
> > NC 07 198142 198450
> > NF 09 198515 198752
> > NH 11 198920 199252
> > NJ 14 199520 199952
> > NL 16 200120 200252
> >
> > [END]
> >
> >
> >   CONTACT=NOAA/NESDIS/STAR/EMB
> >   DATE_BEGIN=239
> >   DATE_END=245
> >   DAYS_PER_PERIOD=7
> >   END_LATITUDE_RANGE=-55.15200043
> >   END_LONGITUDE_RANGE=180
> >   INPUT_FILENAMES=data/VH_unitTest1/weekly/
> > VHP.G04.C07.NC.P1981035.S239.E245.nc
> >
> >   INPUT_FILES=1
> >   INSTRUMENT=AVHRR
> >   PERIOD_OF_YEAR=35
> >   PRODUCT_NAME=Vegetation Health
> >   PROJECTION=Plate_Carree
> >   SATELLITE=NC
> >   START_LATITUDE_RANGE=75.02400208
> >   START_LONGITUDE_RANGE=-180
> >   TIME_BEGIN=00:00 UTC (use day time data only)
> >   TIME_END=23:59 UTC (use day time data only)
> >   VERSION=VH (vh.exe,version 1.3, March 21 2012)
> >   YEAR=1981
> > Subdatasets:
> >   SUBDATASET_1_NAME=HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":0
> >   SUBDATASET_1_DESC=[904x2500] BT4 (16-bit integer)
> >   SUBDATASET_2_NAME=HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":1
> >   SUBDATASET_2_DESC=[904x2500] NDVI (16-bit integer)
> >   SUBDATASET_3_NAME=HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":2
> >   SUBDATASET_3_DESC=[904x2500] QA (8-bit unsigned integer)
> > Corner Coordinates:
> > Upper Left  (    0.0,    0.0)
> > Lower Left  (    0.0,  512.0)
> > Upper Right (  512.0,    0.0)
> > Lower Right (  512.0,  512.0)
> > Center      (  256.0,  256.0)
> >
> > On Thu, Aug 14, 2014 at 10:27 AM, Arnold Salvacion
> > <arnold_salvacion at yahoo.com> wrote:
> > > Dear Colleagues,
> > >
> > > Does any here have already experience converting NOAA AVHRR VHP Product
> > in .hdf (
> > ftp://ftp.star.nesdis.noaa.gov/pub/corp/scsb/wguo/data/VHP_16km/VH/ )
> > format to a raster layer in R?
> > >
> > >
> > > Best regards,
> > >
> > > Arnold
> > >         [[alternative HTML version deleted]]
> > >
> > >
> > > _______________________________________________
> > > R-sig-Geo mailing list
> > > R-sig-Geo at r-project.org
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> > >
> >
> >
> >
> > --
> > Michael Sumner
> > Software and Database Engineer
> > Australian Antarctic Division
> > Hobart, Australia
> > e-mail: mdsumner at gmail.com
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
Dr. Koen Hufkens

Harvard University
Department of Organismic & Evolutionary Biology
Richardson Lab <http://www.oeb.harvard.edu/faculty/richardson/>
~
Ghent University
Faculty of Bioscience Engineering
Isotope Bioscience Laboratory <http://www.isofys.be>

	[[alternative HTML version deleted]]


From incorpld at onda.com.br  Thu Aug 28 20:56:36 2014
From: incorpld at onda.com.br (Felinto COSTA)
Date: Thu, 28 Aug 2014 15:56:36 -0300
Subject: [R-sig-Geo] Spatiotemporal analysis of real estate market data
Message-ID: <53FF7B64.2080109@onda.com.br>

Hello all.

I graduated in 1985 ( in engineering ) and this year I'm
about to finish my graduate studies ( geostatistic ).

My field of work  is related to real estate market and I think spatio-temporal statistics  would be very interesting to analyze land prices evolution in different points of my city over time.

Specifically I'm focusing in suitable models that consider simultaneously the spatial distribution of land price and its variability over the last 15 years,  in order to use them to predict unsampled points ( in time and space ) and to plot isovalues surfaces of different time periods ( as snapshots ).
   
My sample consists of more 3.500 points dispersed ( in time and space ), collected over 15 years of real estate transactions, having UTMX, UTMY ( as coordinates ), V ( land value per square meter ) and D ( date in MM/DD/YYY - from 1999 to 2014 ).

There are some R packages that seem to be adequate to this purpose, but I'm a little confused in establishing the basics of an workflow for the analysis.

Appreciate any help.

  


Com os melhores cumprimentos

  
INCORP Londrina/PR
Felinto COSTA, eng?
incorpld at onda.com.br


From Roger.Bivand at nhh.no  Thu Aug 28 21:08:13 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 28 Aug 2014 21:08:13 +0200
Subject: [R-sig-Geo] Converting .hdf file to raster layer
In-Reply-To: <CAHDtqq=jkVd-XQ=5+BLpKOnD6QK6Sv46wUz3PJmyMwh2bPig0g@mail.gmail.com>
References: <1407976021.54447.YahooMailNeo@web192705.mail.sg3.yahoo.com>
	<CAAcGz9_O7cE6bC22NBww9kRuyVoLC-Ooj21G+WP9Ata+J70G2Q@mail.gmail.com>
	<CAJjwQNdRr1p7if6NN1uCL9EPYnUBUqkJCfVBWSWkMQfQ9mcScQ@mail.gmail.com>
	<CAHDtqq=jkVd-XQ=5+BLpKOnD6QK6Sv46wUz3PJmyMwh2bPig0g@mail.gmail.com>
Message-ID: <alpine.LRH.2.03.1408282040120.5373@reclus.nhh.no>

On Thu, 28 Aug 2014, Koen Hufkens wrote:

> Hi Vinti,
>
> Have a look here:
>
> http://gis.stackexchange.com/questions/20018/how-can-i-convert-data-in-the-form-of-lat-lon-value-into-a-raster-file-using-r

No, the question was how to go from a 3D projected data set to 
geographical coordinates when the projection is unknown - this is the 
opposite direction to the SO thread. I'm also interpreting "in" to mean 
"into", as the values are most likely in metres.

This question has no answer unless the exact projection and datum are 
provided. Indeed, saying that the desired operation is to go to 
geographical coordinates without specifying the target datum is also 
fraught with uncertainties (someone has to assume a datum, probably 
messing up the Z value totally).

So the correct first step is to find out the coordinate reference system 
specification for the input data. Once that is known, everything else 
follows.

See for example:

http://www.asprs.org/a/resources/grids/03-2014-India.pdf

(guessed as the OP did not provide an affiliation, but searching shows a 
possible location in Pune). As Cliff Mugnier writes, because of secrecy, 
the CRS may be hard to decipher. If you reversed lat/long, maybe this is 
UTM, but we don't know the datum. Your data source should know.

Roger

PS. The OP has also hijacked an existing thread for this different 
question - please read list instructions and the posting guide.

>
> This should get you on your way.
>
> Cheers,
> K
>
>
> On Thu, Aug 28, 2014 at 1:43 PM, Vinit Bitla <bitlavinit at gmail.com> wrote:
>
>> Hello All,
>>
>> Can any one can help me to convert this Lidar data latitude and longitude
>> in Degree Decimal format using R.
>>
>>   latitude longitude elevation intensity
>>
>> 1 204140.7   4733835    334.14       6.4
>> 2 204150.1   4733849    334.86      11.4
>>
>> Appreciate your help.
>>
>>
>> Vinit
>>
>>
>>
>> On Thu, Aug 14, 2014 at 3:52 AM, Michael Sumner <mdsumner at gmail.com>
>> wrote:
>>
>>> Just had a look, the file has subdatasets and seemingly raster can't
>>> handle those. (I haven't explored this much but might have a chance
>>> to).
>>>
>>> library(raster)
>>> library(rgdal)  ## built with HDF4, HDF5 and NetCDF4
>>>
>>> fsrc <- "
>>>
>> ftp://ftp.star.nesdis.noaa.gov/pub/corp/scsb/wguo/data/VHP_16km/VH/VHP.G16.C07.NC.P1981035.ND.hdf
>>> "
>>> f <- basename(fsrc)
>>> if (!file.exists(f)) download.file(fsrc, f, mode = "wb")
>>>
>>> ## found with system GDAL, see below
>>> sds <- c('HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":0',
>>>          'HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":1',
>>>          'HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":2'
>>>          )
>>>
>>> ##r <- brick(sds)
>>> ##Error in GDALinfo(filename, silent = silent, returnRAT = RAT,
>>> returnCategoryNames = RAT) :
>>>  ## object 'RATlist' not found
>>> ##Error in .rasterObjectFromFile(x, band = band, objecttype =
>>> "RasterLayer",  :
>>>  ##                                Cannot create a RasterLayer object
>>> from this file.
>>>   ##                             In addition: Warning message:
>>>  ##                                In dim(x) : no bands in dataset
>>>
>>>
>>> ## try with rgdal directly, so far so good but
>>> ## no spatial-reference (again see gdalinfo output below)
>>> raster(readGDAL(sds[1])  )
>>>
>>>  raster(readGDAL(sds[1])  )
>>> HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":0 has GDAL driver
>>> HDF4Image
>>> and has 904 rows and 2500 columns
>>> class       : RasterLayer
>>> dimensions  : 904, 2500, 2260000  (nrow, ncol, ncell)
>>> resolution  : 1, 1  (x, y)
>>> extent      : 0, 2500, 0, 904  (xmin, xmax, ymin, ymax)
>>> coord. ref. : NA
>>> data source : in memory
>>> names       : band1
>>> values      : -99.9, 322  (min, max)
>>>
>>> Warning message:
>>> In readGDAL(sds[1]) : GeoTransform values not available
>>>
>>>
>>> ## proceed without caution, again values from gdalinfo
>>> b <- brick(stack(sapply(sds, function(x) raster(readGDAL(x)))))
>>> proj4string(b) <-  CRS(" +proj=longlat +ellps=WGS84 +datum=WGS84
>>> +no_defs +towgs84=0,0,0")
>>> extent(b) <- c(-180, 180, -55.15200043, 75.02400208)
>>>
>>> library(maptools
>>> data(wrld_simpl)
>>> plot(b, addfun = function() plot(wrld_simpl, add = TRUE))
>>>
>>> That looks ok to me, I don't know if it's WGS84 or the sphere or
>>> something else.
>>>
>>> Cheers, Mike.
>>>
>>>
>>>
>>>
>>>
>>> system(sprintf("gdalinfo %s", f))
>>>
>>> Driver: HDF4/Hierarchical Data Format Release 4
>>> Files: VHP.G16.C07.NC.P1981035.ND.hdf
>>> Size is 512, 512
>>> Coordinate System is `'
>>> Metadata:
>>>   ANCILLARY_FILES=FILE_CONFIGURE:vh.config
>>> FILE_PRELAUNCH_CALIBRATION:../ancillary/AVHRR_calibration_prelaunch.txt
>>> FILE_POSTLAUNCH_CALIBRATION:../ancillary/AVHRR_calibration_postlaunch.txt
>>> FILE_IGBP_LANDTYPE:../ancillary/igbp_landtype_GVIx.hdf
>>> FILE_METADATA_REGIONS:../ancillary/regions_for_metadata.txt
>>> FILE_EDF_NDVI:../ancillary/NVI_counts_ByLine_G04.hdf
>>> FILE_EDF_BT4:../ancillary/BT4_counts_ByLine_G04.hdf
>>>
>>>   CITATION_TO_DOCUMENTS=User Guide of Vegetation Health(VH) system
>>> (version 1.3, March 21 2012)
>>>   CONFIGURE_FILE_CONTENT=[Options for vh.exe]
>>> DIR_Ancillary=                 ../ancillary
>>> DIR_GVI=                       data/VH_unitTest1/weekly
>>> DIR_VH=                        data/VH_unitTest1/G04
>>> DIR_VH_META=                   data/VH_unitTest1/G04/meta
>>> DIR_CLIMAT=                    data/VH_EDF_v2/climate_G04
>>> DIR_CLIMAT_META=               data/VH_EDF_v2/climate_G04/meta
>>> FILE_PREFIX=       VHP
>>> Input_Data_Type=       VHP
>>> ResolutionString=              G04
>>> Days_Per_Period=               7
>>> FilterSize=                    15
>>> applyEDFonNDVI=                1     # 0: none, 1: linebyline for NVI;
>>> applyEDFonBT=                  1
>>> Instrument=                    AVHRR # so far AVHRR is the only option
>>> FORMAT_GVI=                   NETCDF #or HDF4
>>> FORMAT_CLIMAT=                HDF4
>>> FORMAT_ND=                    NETCDF
>>> FORMAT_SM=                    NETCDF
>>> FORMAT_VH=                    NETCDF
>>>
>>> [Periods of GVI data used for VH]
>>> # this section control which satellite will be used for calculating
>>> ND, SM and VH
>>> #satID satNumber yearWeek1 yearWeek2
>>> NC 07 198135 198449
>>> NF 09 198509 198844
>>> NH 11 198846 199436
>>> NJ 14 199504 200052
>>> NL 16 200101 200401
>>> NL 16 200405 200410
>>> NL 16 200425 200428
>>> NL 16 200430 200523
>>> NN 18 200524 201052
>>> NP 19 201101 399999
>>>
>>> [Periods of AVHRR data used for GVI climatology]
>>> #this section controls which satellite will be used for creating VH
>>> climatology
>>> #satID satNumber yearWeek1 yearWeek2
>>> NC 07 198142 198450
>>> NF 09 198515 198752
>>> NH 11 198920 199252
>>> NJ 14 199520 199952
>>> NL 16 200120 200252
>>>
>>> [END]
>>>
>>>
>>>   CONTACT=NOAA/NESDIS/STAR/EMB
>>>   DATE_BEGIN=239
>>>   DATE_END=245
>>>   DAYS_PER_PERIOD=7
>>>   END_LATITUDE_RANGE=-55.15200043
>>>   END_LONGITUDE_RANGE=180
>>>   INPUT_FILENAMES=data/VH_unitTest1/weekly/
>>> VHP.G04.C07.NC.P1981035.S239.E245.nc
>>>
>>>   INPUT_FILES=1
>>>   INSTRUMENT=AVHRR
>>>   PERIOD_OF_YEAR=35
>>>   PRODUCT_NAME=Vegetation Health
>>>   PROJECTION=Plate_Carree
>>>   SATELLITE=NC
>>>   START_LATITUDE_RANGE=75.02400208
>>>   START_LONGITUDE_RANGE=-180
>>>   TIME_BEGIN=00:00 UTC (use day time data only)
>>>   TIME_END=23:59 UTC (use day time data only)
>>>   VERSION=VH (vh.exe,version 1.3, March 21 2012)
>>>   YEAR=1981
>>> Subdatasets:
>>>   SUBDATASET_1_NAME=HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":0
>>>   SUBDATASET_1_DESC=[904x2500] BT4 (16-bit integer)
>>>   SUBDATASET_2_NAME=HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":1
>>>   SUBDATASET_2_DESC=[904x2500] NDVI (16-bit integer)
>>>   SUBDATASET_3_NAME=HDF4_SDS:UNKNOWN:"VHP.G16.C07.NC.P1981035.ND.hdf":2
>>>   SUBDATASET_3_DESC=[904x2500] QA (8-bit unsigned integer)
>>> Corner Coordinates:
>>> Upper Left  (    0.0,    0.0)
>>> Lower Left  (    0.0,  512.0)
>>> Upper Right (  512.0,    0.0)
>>> Lower Right (  512.0,  512.0)
>>> Center      (  256.0,  256.0)
>>>
>>> On Thu, Aug 14, 2014 at 10:27 AM, Arnold Salvacion
>>> <arnold_salvacion at yahoo.com> wrote:
>>>> Dear Colleagues,
>>>>
>>>> Does any here have already experience converting NOAA AVHRR VHP Product
>>> in .hdf (
>>> ftp://ftp.star.nesdis.noaa.gov/pub/corp/scsb/wguo/data/VHP_16km/VH/ )
>>> format to a raster layer in R?
>>>>
>>>>
>>>> Best regards,
>>>>
>>>> Arnold
>>>>         [[alternative HTML version deleted]]
>>>>
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at r-project.org
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>
>>>
>>>
>>>
>>> --
>>> Michael Sumner
>>> Software and Database Engineer
>>> Australian Antarctic Division
>>> Hobart, Australia
>>> e-mail: mdsumner at gmail.com
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From agg18 at pitt.edu  Fri Aug 29 01:54:05 2014
From: agg18 at pitt.edu (alannie)
Date: Thu, 28 Aug 2014 16:54:05 -0700 (PDT)
Subject: [R-sig-Geo] ENFA: Contrasting Scores between species
Message-ID: <1409270045263-7587015.post@n2.nabble.com>

Hi All!

Interested in contrasting the marginality and specificity scores from ENFA
for a group of closely related species that live in the same general region.
They contrast with each other based on breeding system. 

I have the following questions:
1) If marginality for the species is above 1, how would you interpret the
value?

I realize that in the Hirzel et al. 2002 paper it states "A large value
(close to one) means that the species lives in a very particular habitat
relative to the reference set."  

However, I am not sure if a value of 1.2 is less marginal than a value of
4.5. 

In this example, 4.5 is large, but it is further from one than 1.2.

Would any value closest to 1 be the least marginalized?

2)Whichever the result, what would be the best way to analyze a set of data
contrasting marginality scores of different groups? I have been using a z
test. But, perhaps there is better way you can enlighten me to!

I am looking at species that evolved from one another, by the way.
Something like: green species that evolved from yellow species and seeing if
the marginality is different. 

Thanks!

Alannie



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/ENFA-Contrasting-Scores-between-species-tp7587015.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From macqueen1 at llnl.gov  Fri Aug 29 01:57:49 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 28 Aug 2014 23:57:49 +0000
Subject: [R-sig-Geo] Using spTransform() to reproduce another software
 package's transformation
Message-ID: <10CAD6CB-3271-4A3E-BFF0-3C71C3A79317@llnl.gov>

The program I work for has specified the use of a local coordinate reference system and a method for transforming and projecting from WGS84 long/lat to the local system. They use ESRI products to convert from long/lat to the local system.

Since I do everything in R, naturally I wish to use spTransform() to replicate their conversion. I?ve been using spTransform() for a number of years now, and thought I understood what I?ve been doing.

But I have run into trouble. I would appreciate any advice.

I believe I have a reproducible example. Toward the end of this email are R expressions (based on dput) that will create two SpatialPoints objects that are used in the example. They need to be created first, before running the example.

####
## before adding further detail and the example, here are some references
####

(1) http://downloads2.esri.com/support/TechArticles/Geographic_Transformations_10.1.zip
(2) http://resources.arcgis.com/en/help/main/10.2/index.html#/Equation_based_methods/003r00000012000000/
(3) http://resources.arcgis.com/en/help/main/10.2/index.html#/Grid_based_methods/003r00000013000000/



The programs?s specified CRS is epsg 26743 = California State Plane Zone 3 NAD27 US feet (out of my control!)

The specified method for transforming and projecting from WGS84 long/lat to the local CRS consists of two steps:
 1) transform and project to epsg 2227 = California State Plane Zone 3 NAD83 US feet
 2) transform to epsg 26743 = California State Plane Zone 3 NAD27 US feet

When doing the steps in the ESRI software's projection tool:
 step 1) use what ESRI calls "NAD_1983_To_WGS_1984_5"  (wkid 1515 in reference 1)
 step 2) use what ESRI calls "NAD_1927_To_NAD_1983_NADCON"  (wkid 1241 in reference 1)

According to reference 1 "NAD_1983_To_WGS_1984_5" is a "coordinate frame" transformation.
Based on reference 2, this means it is a 7 parameter Bursa-Wolf method
Also based on reference 1, "NAD_1927_To_NAD_1983_NADCON" is a grid-based method


As I hope you will see, a naive use of spTransform() produces coordinates that differ from the ESRI two-step process by approximately 3.7 ft (x) and -1.9 ft (y). This is too large for our use case. I also believe as a matter of principle that it should be possible to do better (I?d like to believe that any transformation possible in ESRI is also possible using PROJ.4).


##
## reproducible example begins
##

## define two example points in WGS84 long/lat
locs.xy <- cbind(
             c(-121.524764291826,-121.523480804667),
             c(37.6600366036405,37.6543604613483)
             )

locs.ll <- SpatialPoints(locs.xy, proj4string=CRS("+proj=longlat +datum=WGS84") )

## source the expressions near the bottom of this email to create
##    locs.ref
##    locs.step1.esri

## use spTransform to go from WGS84 to the local system in one step:
locs.26743 <- spTransform(locs.ll, CRS("+init=epsg:26743"))

## not close enough:
coordinates(locs.ref)-coordinates(locs.26743)
##      coords.x1 coords.x2
## [1,]  3.746539 -1.876668
## [2,]  3.746607 -1.876466


## spTransform equivalent of ESRI step 1
locs.step1.proj4 <- spTransform(locs.ll, CRS("+init=epsg:2227"))

## not close enough, essentially the same difference as above
coordinates(locs.step1.esri)-coordinates(locs.step1.proj4)
##      coords.x1 coords.x2
## [1,]  3.746244 -1.877057
## [2,]  3.746315 -1.876856


## next, try the spTransform equivalent of ESRI step 1, but specifying the seven parameters
## note, had to reverse the sign of the rotation args from wkid 1515 in reference 1;
## evidently the PROJ.4 default is the "position vector" method (reference 2)

crs.step1.cf <- CRS('+proj=lcc +lat_1=38.43333333333333 +lat_2=37.06666666666667 +lat_0=36.5 +lon_0=-120.5\
 +x_0=2000000.0 +y_0=500000.0 +ellps=GRS80 +datum=NAD83\
 +units=us-ft +no_defs\
 +towgs84=-0.991,1.9072,0.5129,0.025789908,0.0096501,0.0116599,0.0?)

## by the way, this alternative to specifying the CRS gives the same result
##  crs.step1.cf <- CRS("+init=epsg:2227 +towgs84=-0.991,1.9072,0.5129,0.025789908,0.0096501,0.0116599,0.0?)

locs.step1.cf <- spTransform(locs.ll, crs.step1.cf)

## good enough (hooray!)
coordinates(locs.step1.esri)-coordinates(locs.step1.cf)
##          coords.x1     coords.x2
## [1,] -3.469177e-06 -5.122274e-08
## [2,] -3.418885e-06 -7.380731e-08



## now try for step 2 using spTranform()
locs.step2.cf <- spTransform(locs.step1.cf, CRS("+init=epsg:26743"))

## the original difference is back!
coordinates(locs.ref)-coordinates(locs.step2.cf)
##      coords.x1 coords.x2
## [1,]  3.746539 -1.876668
## [2,]  3.746608 -1.876466

## the implication is that in doing the transformation to epsg 26743, it reversed the effect of the 7-parameter method

## attempt to prevent that:

locs.tmp <- locs.step1.cf
proj4string(locs.tmp) <- CRS("+init=epsg:2227")
## Warning message:
## In `proj4string<-`(`*tmp*`, value = <S4 object of class "CRS">) :
##   A new CRS was assigned to an object with an existing CRS:
## +proj=lcc +lat_1=38.43333333333333 +lat_2=37.06666666666667 +lat_0=36.5 +lon_0=-120.5 +x_0=2000000.0 +y_0=500000.0 +ellps=GRS80 +datum=NAD83 +units=us-ft +no_defs +towgs84=-0.991,1.9072,0.5129,0.025789908,0.0096501,0.0116599,0.0
## without reprojecting.
## For reprojection, use function spTransform in package rgdal

locs.step2.cfb <- spTransform(locs.tmp, CRS("+init=epsg:26743?))

## This actually works; the difference is now acceptably small
coordinates(locs.ref)-coordinates(locs.step2.cfb)
##         coords.x1    coords.x2
## [1,] 0.0003266879 0.0006651825
## [2,] 0.0003261503 0.0006651356


## Another way, perhaps more appropriate (and with no warning message) is recreate the SpatialPoints
## object instead of modifying it:
locs.tmp <- SpatialPoints(coordinates(locs.step1.cf), proj4string=CRS("+init=epsg:2227"))
locs.step2.cfb <- spTransform(locs.tmp, CRS("+init=epsg:26743"))

coordinates(locs.ref)-coordinates(locs.step2.cfb)
##         coords.x1    coords.x2
## [1,] 0.0003266879 0.0006651825
## [2,] 0.0003261503 0.0006651356



This suggests to me that in PROJ.4 the specifications for the CRS are in some way mixed in with the specifications for how the geographic transformation is performed. Apparently, one cannot specify the transformation method independent of the CRS specification. To put it another way, I have two ways of converting from the original CRS to the first step?s target CRS. The target CRS is the same either way. But a second conversion to another CRS is affected by the method of the first one. 

Have I interpreted correctly? If so, I guess it doesn?t seem appropriate?the conversion from one CRS to another should depend only on what the CRS is, not on how it got there.

Is there something I don?t understand so that this kind of dependency is appropriate?

In the end, I guess I do have a solution, but I kind of don?t like it. I have to insert a ?correction? to the CRS. Is there a better way?




#####
### source the following to create objects used by the reproducible example above
#####

## the two points converted from long/lat using the complete ESRI "two-step process"
## saved as a shapefile, loaded into R using readOGR(). Then just the coordinates
## were ?dput"
locs.ref <- new(
              "SpatialPoints",
              coords = structure(c(1703671.30566227, 1704020.20113366,
                424014.398045834, 421943.708664294), .Dim = c(2L, 2L),
                .Dimnames = list(NULL, c("coords.x1", "coords.x2")))
              , bbox = structure(
                  c(1703671.30566227, 421943.708664294,
                    1704020.20113366, 424014.398045834),
                  .Dim = c(2L, 2L),
                  .Dimnames = list(c("coords.x1",  "coords.x2"), c("min", "max")))
              , proj4string =
              new("CRS",
                  projargs = "+proj=lcc +lat_1=37.06666666666667 +lat_2=38.43333333333333 +lat_0=36.5 +lon_0=-120.5 +x_0=609601.2192024384 +y_0=0 +datum=NAD27 +units=us-ft +no_defs +ellps=clrk66 +nadgrids=@conus, at alaska, at ntv2_0.gsb, at ntv1_can.dat"
                  )
              )


## the points converted to epsg 2227 using ESRI's step 1
## saved as a shapefile, loaded into R using readOGR
## Then just the coordinates were ?dput?
locs.step1.esri <- new(
                     "SpatialPoints",
                     coords = structure(c(6265039.1378244, 6265388.04257557,
                       2064418.92932968, 2062348.22239488), .Dim = c(2L, 2L),
                       .Dimnames = list(NULL, c("coords.x1", "coords.x2")))
                     , bbox = structure(
                         c(6265039.1378244, 2062348.22239488,
                           6265388.04257557, 2064418.92932968),
                         .Dim = c(2L, 2L),
                         .Dimnames = list(c("coords.x1", "coords.x2"), c("min", "max")))
                     , proj4string = new("CRS",
                         projargs = "+proj=lcc +lat_1=37.06666666666667 +lat_2=38.43333333333333 +lat_0=36.5 +lon_0=-120.5 +x_0=2000000 +y_0=500000.0000000001 +datum=NAD83 +units=us-ft +no_defs +ellps=GRS80 +towgs84=0,0,0"
                         )
                     )


#####
###package and session information
#####


Loading required package: sp
Checking rgeos availability: TRUE

Loading required package: rgdal
rgdal: version: 0.8-16, (SVN revision 498)
Geospatial Data Abstraction Library extensions to R successfully loaded
Loaded GDAL runtime: GDAL 1.11.0, released 2014/04/16
Path to GDAL shared files: /Users/macqueen1/Library/R/3.1/library/rgdal/gdal
Loaded PROJ.4 runtime: Rel. 4.8.0, 6 March 2012, [PJ_VERSION: 480]
Path to PROJ.4 shared files: /Users/macqueen1/Library/R/3.1/library/rgdal/proj


> sessionInfo()
R version 3.1.1 (2014-07-10)
Platform: x86_64-apple-darwin13.1.0 (64-bit)

locale:
[1] C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] sp_1.0-15       rgdal_0.8-16    maptools_0.8-30 xlsx_0.5.5     
[5] xlsxjars_0.6.0  rJava_0.9-6     rmacq_1.3-1    

loaded via a namespace (and not attached):
[1] foreign_0.8-61  grid_3.1.1      lattice_0.20-29 tools_3.1.1    

????
two final comments:

I understand that this is really a PROJ.4 question, so I hope that R-sig-geo folks don?t mind too much; apologies in advance if so.

I hope my email software truly sends a plain text email like it claims. But I?m not sure I trust it!


From dan.rosauer at anu.edu.au  Fri Aug 29 03:03:49 2014
From: dan.rosauer at anu.edu.au (Dan Rosauer)
Date: Fri, 29 Aug 2014 01:03:49 +0000
Subject: [R-sig-Geo] function gbm.perspec() in package dismo
Message-ID: <b23d22620bb14189add0cf10f04dd533@SIXPR06MB319.apcprd06.prod.outlook.com>

Hello

Can anyone explain use of the 'smooth' parameter in the function dismo::gbm.perspec()  ?

It sounds like just what I need.  The help says:

smooth             controls smoothing of the predicted surface

and the default value is "none"

But what values can be used, other than none?

thanks
Dan

~~~~~~~~~~~~~~~~~~~~~~
Dan Rosauer
Postdoctoral Researcher
Moritz Lab
Ecology, Evolution & Genetics
Research School of Biology
Gould Building, Daley Road
Australian National University
Canberra ACT 0200

+61 413 950 275 (mobile)
+61 2 6125 1028 (office)
dan.rosauer at anu.edu.au

sites.google.com/site/danielrosauer


	[[alternative HTML version deleted]]


From helen at rams.colostate.edu  Fri Aug 29 06:52:11 2014
From: helen at rams.colostate.edu (Helen Sofaer)
Date: Thu, 28 Aug 2014 22:52:11 -0600
Subject: [R-sig-Geo] raster to dataframe with xy=TRUE, na.rm=TRUE
Message-ID: <CAOckJBO=uS5fL=G4akfsMtcQ4Npfx3qSYFH+C15fyfWuwPrHcg@mail.gmail.com>

Hi all,

I?m trying to convert a RasterBrick to a dataframe while adding the
coordinates and while dropping cells that were masked to NA. This
combination of options gives me an error when the mask is done with an sp
object.



Some reproducible code:



usa = getData('GADM', country = 'USA', level = 0)



r1 = raster()

values(r1) = 1:ncell(r1)

r1.b = brick(r1, r1, r1, r1)

r1.b.mask = mask(r1.b, usa)

plot(r1.b.mask)

r1.b.df = as.data.frame(r1.b.mask, xy = TRUE, na.rm = TRUE)



The error is:

Error in data.frame(..., check.names = FALSE) :

  arguments imply differing number of rows: 64800, 1109



Looks like it wants to combine all the coordinates with just the subset of
the data.



I surprised myself further by looking at what happens if the NAs are in
random locations, rather than masked out:



# random NAs:

r2 = raster()

vals = 1:ncell(r2)

vals[sample(1:ncell(r2), .5*ncell(r2))] = NA

values(r2) = vals

plot(r2)

r2.b = brick(r2, r2, r2, r2)

r2.b.df = as.data.frame(r2.b, xy = TRUE, na.rm = TRUE)

str(r2.b.df) # 64800 obs; same as ncell in each layer; further inspection
shows all locations are there and some values are repeated



Any advice/interpretation is appreciated. In practice I have already
cropped but still have a lot of NAs within my extent. Of course, I can drop
the rows afterwards, but thought I?d ask. Also, I see the same thing if
it?s a single layer, rather than a brick.



FYI, I?m running 3.1.1 and raster version 2.2-31 and a Mavericks OSX (and I
also tried it on a Fedora linux machine running 3.1.0 to make sure it
wasn?t a Mavericks thing).



Thanks for your time!

Helen

-- 
Helen Sofaer
Postdoctoral Fellow
Fish Wildlife and Conservation Biology
Colorado State University

	[[alternative HTML version deleted]]


From kridox at ymail.com  Fri Aug 29 07:17:27 2014
From: kridox at ymail.com (Pascal Oettli)
Date: Fri, 29 Aug 2014 14:17:27 +0900
Subject: [R-sig-Geo] raster to dataframe with xy=TRUE, na.rm=TRUE
In-Reply-To: <CAOckJBO=uS5fL=G4akfsMtcQ4Npfx3qSYFH+C15fyfWuwPrHcg@mail.gmail.com>
References: <CAOckJBO=uS5fL=G4akfsMtcQ4Npfx3qSYFH+C15fyfWuwPrHcg@mail.gmail.com>
Message-ID: <CAAcyNCzG54=hiFhsi0GURfo1XnrnLKAzZNUwyBaJCuksW+2x-A@mail.gmail.com>

Hello,

Did you try with the "rasterToPoints" function?

Something like:

r1.b.df <- as.data.frame(rasterToPoints(r1.b.mask))
coordinates(r1.b.df) <- ~x+y
plot(r1.b.df)

Regards,
Pascal

On Fri, Aug 29, 2014 at 1:52 PM, Helen Sofaer <helen at rams.colostate.edu> wrote:
> Hi all,
>
> I?m trying to convert a RasterBrick to a dataframe while adding the
> coordinates and while dropping cells that were masked to NA. This
> combination of options gives me an error when the mask is done with an sp
> object.
>
>
>
> Some reproducible code:
>
>
>
> usa = getData('GADM', country = 'USA', level = 0)
>
>
>
> r1 = raster()
>
> values(r1) = 1:ncell(r1)
>
> r1.b = brick(r1, r1, r1, r1)
>
> r1.b.mask = mask(r1.b, usa)
>
> plot(r1.b.mask)
>
> r1.b.df = as.data.frame(r1.b.mask, xy = TRUE, na.rm = TRUE)
>
>
>
> The error is:
>
> Error in data.frame(..., check.names = FALSE) :
>
>   arguments imply differing number of rows: 64800, 1109
>
>
>
> Looks like it wants to combine all the coordinates with just the subset of
> the data.
>
>
>
> I surprised myself further by looking at what happens if the NAs are in
> random locations, rather than masked out:
>
>
>
> # random NAs:
>
> r2 = raster()
>
> vals = 1:ncell(r2)
>
> vals[sample(1:ncell(r2), .5*ncell(r2))] = NA
>
> values(r2) = vals
>
> plot(r2)
>
> r2.b = brick(r2, r2, r2, r2)
>
> r2.b.df = as.data.frame(r2.b, xy = TRUE, na.rm = TRUE)
>
> str(r2.b.df) # 64800 obs; same as ncell in each layer; further inspection
> shows all locations are there and some values are repeated
>
>
>
> Any advice/interpretation is appreciated. In practice I have already
> cropped but still have a lot of NAs within my extent. Of course, I can drop
> the rows afterwards, but thought I?d ask. Also, I see the same thing if
> it?s a single layer, rather than a brick.
>
>
>
> FYI, I?m running 3.1.1 and raster version 2.2-31 and a Mavericks OSX (and I
> also tried it on a Fedora linux machine running 3.1.0 to make sure it
> wasn?t a Mavericks thing).
>
>
>
> Thanks for your time!
>
> Helen
>
> --
> Helen Sofaer
> Postdoctoral Fellow
> Fish Wildlife and Conservation Biology
> Colorado State University
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From frtog at vestas.com  Fri Aug 29 08:53:36 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Fri, 29 Aug 2014 08:53:36 +0200
Subject: [R-sig-Geo] Using spTransform() to reproduce another software
 package's transformation
In-Reply-To: <10CAD6CB-3271-4A3E-BFF0-3C71C3A79317@llnl.gov>
References: <10CAD6CB-3271-4A3E-BFF0-3C71C3A79317@llnl.gov>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C79B8226@DKRDSEXC016.vestas.net>

Hi

It seems to me that you think that ESRI performs the "correct" transformation.

>From http://help.arcgis.com/en/arcgisdesktop/10.0/help/index.html#//003r00000010000000:

<quote start>
Converting between NAD 1983 and WGS 1984

Originally, NAD 1983 and WGS 1984 were considered coincident. To minimize coordinate changes, NAD 1983 is tied to the North American and Pacific (for Hawaii, and so on) plates. WGS 1984 is tied to the International Terrestrial Reference System (ITRF), which is independent of the tectonic plates. Over time, the two coordinate systems have become increasingly different.

NAD_1983_To_WGS_1984_1: Published accuracy from EPSG is 2 meters. This transformation applies to the entire North American continent. This transformation uses the geocentric translation method, with the transformation's parameters (dx, dy, and dz) all equal to zeroes. This transformation treats the NAD 1983 and WGS 1984 datums as though they are equivalent.
NAD_1983_To_WGS_1984_2: Calculated by the U. S. Defence Mapping Agency (DMA), now known as the National Geospatial Intelligence Agency (NGA), for the Aleutian islands. Accuracy is listed by EPSG at +/-8 m.
NAD_1983_To_WGS_1984_3: Calculated by the NGA for Hawaii. Accuracy is listed by EPSG at +/-4 m.
NAD_1983_To_WGS_1984_4: Formerly applied within the 48 contiguous states, but is superseded by _5. This transformation method should no longer be used.
NAD_1983_To_WGS_1984_5: Transformation parameters calculated by the U.S. National Geodetic Survey (NGS) using CORS stations, and ties WGS 1984 to ITRF96. Accuracy according to EPSG is +/- 1 meter.
NAD_1983_To_WGS_1984_6, _7, and _8: Canadian NTv2 transformations, for the Quebec, Saskatchewan, and Alberta provinces, respectively.
<quote end>

So the precision of NAD_1983_To_WGS_1984_5 according to EPSG is +- 1 meter so if your results are in feet then they are within that limit.

In R the parameters for PROJ.4 are:

> CRS("+init=epsg:26743")
CRS arguments:
 +init=epsg:26743 +proj=lcc +lat_1=38.43333333333333
+lat_2=37.06666666666667 +lat_0=36.5 +lon_0=-120.5
+x_0=609601.2192024384 +y_0=0 +datum=NAD27 +units=us-ft +no_defs
+ellps=clrk66 +nadgrids=@conus, at alaska, at ntv2_0.gsb, at ntv1_can.dat +towgs=-3.746315,1.876856  

This corresponds to what you can find on www.epsg-registry.org 

Is there a corresponding EPSG code for the ESRI NAD_1983_To_WGS_1984_5 transformation? Or can you by any other means find something similar to the CRS arguments? If so we can compare the CRS arguments from R and ESRI.




Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 


> -----Original Message-----
> From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-
> project.org] On Behalf Of MacQueen, Don
> Sent: 29. august 2014 01:58
> To: r-sig-geo at r-project.org
> Subject: [R-sig-Geo] Using spTransform() to reproduce another software
> package's transformation
> 
> The program I work for has specified the use of a local coordinate reference
> system and a method for transforming and projecting from WGS84 long/lat
> to the local system. They use ESRI products to convert from long/lat to the
> local system.
> 
> Since I do everything in R, naturally I wish to use spTransform() to replicate
> their conversion. I've been using spTransform() for a number of years now,
> and thought I understood what I've been doing.
> 
> But I have run into trouble. I would appreciate any advice.
> 
> I believe I have a reproducible example. Toward the end of this email are R
> expressions (based on dput) that will create two SpatialPoints objects that
> are used in the example. They need to be created first, before running the
> example.
> 
> ####
> ## before adding further detail and the example, here are some references
> ####
> 
> (1)
> http://downloads2.esri.com/support/TechArticles/Geographic_Transformati
> ons_10.1.zip
> (2)
> http://resources.arcgis.com/en/help/main/10.2/index.html#/Equation_base
> d_methods/003r00000012000000/
> (3)
> http://resources.arcgis.com/en/help/main/10.2/index.html#/Grid_based_m
> ethods/003r00000013000000/
> 
> 
> 
> The programs's specified CRS is epsg 26743 = California State Plane Zone 3
> NAD27 US feet (out of my control!)
> 
> The specified method for transforming and projecting from WGS84 long/lat
> to the local CRS consists of two steps:
>  1) transform and project to epsg 2227 = California State Plane Zone 3 NAD83
> US feet
>  2) transform to epsg 26743 = California State Plane Zone 3 NAD27 US feet
> 
> When doing the steps in the ESRI software's projection tool:
>  step 1) use what ESRI calls "NAD_1983_To_WGS_1984_5"  (wkid 1515 in
> reference 1)
>  step 2) use what ESRI calls "NAD_1927_To_NAD_1983_NADCON"  (wkid 1241
> in reference 1)
> 
> According to reference 1 "NAD_1983_To_WGS_1984_5" is a "coordinate
> frame" transformation.
> Based on reference 2, this means it is a 7 parameter Bursa-Wolf method
> Also based on reference 1, "NAD_1927_To_NAD_1983_NADCON" is a grid-
> based method
> 
> 
> As I hope you will see, a naive use of spTransform() produces coordinates
> that differ from the ESRI two-step process by approximately 3.7 ft (x) and -
> 1.9 ft (y). This is too large for our use case. I also believe as a matter of
> principle that it should be possible to do better (I'd like to believe that any
> transformation possible in ESRI is also possible using PROJ.4).
> 
> 
> ##
> ## reproducible example begins
> ##
> 
> ## define two example points in WGS84 long/lat
> locs.xy <- cbind(
>              c(-121.524764291826,-121.523480804667),
>              c(37.6600366036405,37.6543604613483)
>              )
> 
> locs.ll <- SpatialPoints(locs.xy, proj4string=CRS("+proj=longlat
> +datum=WGS84") )
> 
> ## source the expressions near the bottom of this email to create
> ##    locs.ref
> ##    locs.step1.esri
> 
> ## use spTransform to go from WGS84 to the local system in one step:
> locs.26743 <- spTransform(locs.ll, CRS("+init=epsg:26743"))
> 
> ## not close enough:
> coordinates(locs.ref)-coordinates(locs.26743)
> ##      coords.x1 coords.x2
> ## [1,]  3.746539 -1.876668
> ## [2,]  3.746607 -1.876466
> 
> 
> ## spTransform equivalent of ESRI step 1
> locs.step1.proj4 <- spTransform(locs.ll, CRS("+init=epsg:2227"))
> 
> ## not close enough, essentially the same difference as above
> coordinates(locs.step1.esri)-coordinates(locs.step1.proj4)
> ##      coords.x1 coords.x2
> ## [1,]  3.746244 -1.877057
> ## [2,]  3.746315 -1.876856
> 
> 
> ## next, try the spTransform equivalent of ESRI step 1, but specifying the
> seven parameters
> ## note, had to reverse the sign of the rotation args from wkid 1515 in
> reference 1;
> ## evidently the PROJ.4 default is the "position vector" method (reference 2)
> 
> crs.step1.cf <- CRS('+proj=lcc +lat_1=38.43333333333333
> +lat_2=37.06666666666667 +lat_0=36.5 +lon_0=-120.5\
>  +x_0=2000000.0 +y_0=500000.0 +ellps=GRS80 +datum=NAD83\
>  +units=us-ft +no_defs\
>  +towgs84=-0.991,1.9072,0.5129,0.025789908,0.0096501,0.0116599,0.0')
> 
> ## by the way, this alternative to specifying the CRS gives the same result
> ##  crs.step1.cf <- CRS("+init=epsg:2227 +towgs84=-
> 0.991,1.9072,0.5129,0.025789908,0.0096501,0.0116599,0.0")
> 
> locs.step1.cf <- spTransform(locs.ll, crs.step1.cf)
> 
> ## good enough (hooray!)
> coordinates(locs.step1.esri)-coordinates(locs.step1.cf)
> ##          coords.x1     coords.x2
> ## [1,] -3.469177e-06 -5.122274e-08
> ## [2,] -3.418885e-06 -7.380731e-08
> 
> 
> 
> ## now try for step 2 using spTranform()
> locs.step2.cf <- spTransform(locs.step1.cf, CRS("+init=epsg:26743"))
> 
> ## the original difference is back!
> coordinates(locs.ref)-coordinates(locs.step2.cf)
> ##      coords.x1 coords.x2
> ## [1,]  3.746539 -1.876668
> ## [2,]  3.746608 -1.876466
> 
> ## the implication is that in doing the transformation to epsg 26743, it
> reversed the effect of the 7-parameter method
> 
> ## attempt to prevent that:
> 
> locs.tmp <- locs.step1.cf
> proj4string(locs.tmp) <- CRS("+init=epsg:2227")
> ## Warning message:
> ## In `proj4string<-`(`*tmp*`, value = <S4 object of class "CRS">) :
> ##   A new CRS was assigned to an object with an existing CRS:
> ## +proj=lcc +lat_1=38.43333333333333 +lat_2=37.06666666666667
> +lat_0=36.5 +lon_0=-120.5 +x_0=2000000.0 +y_0=500000.0 +ellps=GRS80
> +datum=NAD83 +units=us-ft +no_defs +towgs84=-
> 0.991,1.9072,0.5129,0.025789908,0.0096501,0.0116599,0.0
> ## without reprojecting.
> ## For reprojection, use function spTransform in package rgdal
> 
> locs.step2.cfb <- spTransform(locs.tmp, CRS("+init=epsg:26743"))
> 
> ## This actually works; the difference is now acceptably small
> coordinates(locs.ref)-coordinates(locs.step2.cfb)
> ##         coords.x1    coords.x2
> ## [1,] 0.0003266879 0.0006651825
> ## [2,] 0.0003261503 0.0006651356
> 
> 
> ## Another way, perhaps more appropriate (and with no warning message)
> is recreate the SpatialPoints
> ## object instead of modifying it:
> locs.tmp <- SpatialPoints(coordinates(locs.step1.cf),
> proj4string=CRS("+init=epsg:2227"))
> locs.step2.cfb <- spTransform(locs.tmp, CRS("+init=epsg:26743"))
> 
> coordinates(locs.ref)-coordinates(locs.step2.cfb)
> ##         coords.x1    coords.x2
> ## [1,] 0.0003266879 0.0006651825
> ## [2,] 0.0003261503 0.0006651356
> 
> 
> 
> This suggests to me that in PROJ.4 the specifications for the CRS are in some
> way mixed in with the specifications for how the geographic transformation
> is performed. Apparently, one cannot specify the transformation method
> independent of the CRS specification. To put it another way, I have two ways
> of converting from the original CRS to the first step's target CRS. The target
> CRS is the same either way. But a second conversion to another CRS is
> affected by the method of the first one.
> 
> Have I interpreted correctly? If so, I guess it doesn't seem appropriate-the
> conversion from one CRS to another should depend only on what the CRS is,
> not on how it got there.
> 
> Is there something I don't understand so that this kind of dependency is
> appropriate?
> 
> In the end, I guess I do have a solution, but I kind of don't like it. I have to
> insert a "correction" to the CRS. Is there a better way?
> 
> 
> 
> 
> #####
> ### source the following to create objects used by the reproducible example
> above
> #####
> 
> ## the two points converted from long/lat using the complete ESRI "two-
> step process"
> ## saved as a shapefile, loaded into R using readOGR(). Then just the
> coordinates
> ## were "dput"
> locs.ref <- new(
>               "SpatialPoints",
>               coords = structure(c(1703671.30566227, 1704020.20113366,
>                 424014.398045834, 421943.708664294), .Dim = c(2L, 2L),
>                 .Dimnames = list(NULL, c("coords.x1", "coords.x2")))
>               , bbox = structure(
>                   c(1703671.30566227, 421943.708664294,
>                     1704020.20113366, 424014.398045834),
>                   .Dim = c(2L, 2L),
>                   .Dimnames = list(c("coords.x1",  "coords.x2"), c("min", "max")))
>               , proj4string =
>               new("CRS",
>                   projargs = "+proj=lcc +lat_1=37.06666666666667
> +lat_2=38.43333333333333 +lat_0=36.5 +lon_0=-120.5
> +x_0=609601.2192024384 +y_0=0 +datum=NAD27 +units=us-ft +no_defs
> +ellps=clrk66 +nadgrids=@conus, at alaska, at ntv2_0.gsb, at ntv1_can.dat"
>                   )
>               )
> 
> 
> ## the points converted to epsg 2227 using ESRI's step 1
> ## saved as a shapefile, loaded into R using readOGR
> ## Then just the coordinates were "dput"
> locs.step1.esri <- new(
>                      "SpatialPoints",
>                      coords = structure(c(6265039.1378244, 6265388.04257557,
>                        2064418.92932968, 2062348.22239488), .Dim = c(2L, 2L),
>                        .Dimnames = list(NULL, c("coords.x1", "coords.x2")))
>                      , bbox = structure(
>                          c(6265039.1378244, 2062348.22239488,
>                            6265388.04257557, 2064418.92932968),
>                          .Dim = c(2L, 2L),
>                          .Dimnames = list(c("coords.x1", "coords.x2"), c("min", "max")))
>                      , proj4string = new("CRS",
>                          projargs = "+proj=lcc +lat_1=37.06666666666667
> +lat_2=38.43333333333333 +lat_0=36.5 +lon_0=-120.5 +x_0=2000000
> +y_0=500000.0000000001 +datum=NAD83 +units=us-ft +no_defs
> +ellps=GRS80 +towgs84=0,0,0"
>                          )
>                      )
> 
> 
> #####
> ###package and session information
> #####
> 
> 
> Loading required package: sp
> Checking rgeos availability: TRUE
> 
> Loading required package: rgdal
> rgdal: version: 0.8-16, (SVN revision 498)
> Geospatial Data Abstraction Library extensions to R successfully loaded
> Loaded GDAL runtime: GDAL 1.11.0, released 2014/04/16
> Path to GDAL shared files:
> /Users/macqueen1/Library/R/3.1/library/rgdal/gdal
> Loaded PROJ.4 runtime: Rel. 4.8.0, 6 March 2012, [PJ_VERSION: 480]
> Path to PROJ.4 shared files:
> /Users/macqueen1/Library/R/3.1/library/rgdal/proj
> 
> 
> > sessionInfo()
> R version 3.1.1 (2014-07-10)
> Platform: x86_64-apple-darwin13.1.0 (64-bit)
> 
> locale:
> [1] C
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] sp_1.0-15       rgdal_0.8-16    maptools_0.8-30 xlsx_0.5.5
> [5] xlsxjars_0.6.0  rJava_0.9-6     rmacq_1.3-1
> 
> loaded via a namespace (and not attached):
> [1] foreign_0.8-61  grid_3.1.1      lattice_0.20-29 tools_3.1.1
> 
> ----
> two final comments:
> 
> I understand that this is really a PROJ.4 question, so I hope that R-sig-geo
> folks don't mind too much; apologies in advance if so.
> 
> I hope my email software truly sends a plain text email like it claims. But I'm
> not sure I trust it!
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From Roger.Bivand at nhh.no  Fri Aug 29 09:26:25 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 29 Aug 2014 09:26:25 +0200
Subject: [R-sig-Geo] Using spTransform() to reproduce another software
 package's transformation
In-Reply-To: <B078CDF40DFE4045AF172A8B4F68FC4857C79B8226@DKRDSEXC016.vestas.net>
References: <10CAD6CB-3271-4A3E-BFF0-3C71C3A79317@llnl.gov>
	<B078CDF40DFE4045AF172A8B4F68FC4857C79B8226@DKRDSEXC016.vestas.net>
Message-ID: <alpine.LRH.2.03.1408290916450.8617@reclus.nhh.no>

On Fri, 29 Aug 2014, Frede Aakmann T?gersen wrote:

> Hi
>
> It seems to me that you think that ESRI performs the "correct" 
> transformation.

Thanks, Frede. My guess is that this is a question for the proj-devel 
list, probably using cs2cs as the workhorse. Please re-cast your example 
to use cs2cs from the console prompt - I think that will be the most 
efficient resolution. I can post on the proj list if you like.

I suspect that the +/- 1m is what is available, but if it was possible to 
help in the PROJ.4 framework, all other downstream software components 
would benefit.

I do see that Frank Warmerdam posted:

http://lists.maptools.org/pipermail/proj/2008-September/003833.html

6 years ago in answer to a question about NAD_1983_To_WGS_1984_5.

Hope this helps,

Roger

>
>> From http://help.arcgis.com/en/arcgisdesktop/10.0/help/index.html#//003r00000010000000:
>
> <quote start>
> Converting between NAD 1983 and WGS 1984
>
> Originally, NAD 1983 and WGS 1984 were considered coincident. To minimize coordinate changes, NAD 1983 is tied to the North American and Pacific (for Hawaii, and so on) plates. WGS 1984 is tied to the International Terrestrial Reference System (ITRF), which is independent of the tectonic plates. Over time, the two coordinate systems have become increasingly different.
>
> NAD_1983_To_WGS_1984_1: Published accuracy from EPSG is 2 meters. This transformation applies to the entire North American continent. This transformation uses the geocentric translation method, with the transformation's parameters (dx, dy, and dz) all equal to zeroes. This transformation treats the NAD 1983 and WGS 1984 datums as though they are equivalent.
> NAD_1983_To_WGS_1984_2: Calculated by the U. S. Defence Mapping Agency (DMA), now known as the National Geospatial Intelligence Agency (NGA), for the Aleutian islands. Accuracy is listed by EPSG at +/-8 m.
> NAD_1983_To_WGS_1984_3: Calculated by the NGA for Hawaii. Accuracy is listed by EPSG at +/-4 m.
> NAD_1983_To_WGS_1984_4: Formerly applied within the 48 contiguous states, but is superseded by _5. This transformation method should no longer be used.
> NAD_1983_To_WGS_1984_5: Transformation parameters calculated by the U.S. National Geodetic Survey (NGS) using CORS stations, and ties WGS 1984 to ITRF96. Accuracy according to EPSG is +/- 1 meter.
> NAD_1983_To_WGS_1984_6, _7, and _8: Canadian NTv2 transformations, for the Quebec, Saskatchewan, and Alberta provinces, respectively.
> <quote end>
>
> So the precision of NAD_1983_To_WGS_1984_5 according to EPSG is +- 1 meter so if your results are in feet then they are within that limit.
>
> In R the parameters for PROJ.4 are:
>
>> CRS("+init=epsg:26743")
> CRS arguments:
> +init=epsg:26743 +proj=lcc +lat_1=38.43333333333333
> +lat_2=37.06666666666667 +lat_0=36.5 +lon_0=-120.5
> +x_0=609601.2192024384 +y_0=0 +datum=NAD27 +units=us-ft +no_defs
> +ellps=clrk66 +nadgrids=@conus, at alaska, at ntv2_0.gsb, at ntv1_can.dat +towgs=-3.746315,1.876856
>
> This corresponds to what you can find on www.epsg-registry.org
>
> Is there a corresponding EPSG code for the ESRI NAD_1983_To_WGS_1984_5 transformation? Or can you by any other means find something similar to the CRS arguments? If so we can compare the CRS arguments from R and ESRI.
>
>
>
>
> Yours sincerely / Med venlig hilsen
>
>
> Frede Aakmann T?gersen
> Specialist, M.Sc., Ph.D.
> Plant Performance & Modeling
>
> Technology & Service Solutions
> T +45 9730 5135
> M +45 2547 6050
> frtog at vestas.com
> http://www.vestas.com
>
> Company reg. name: Vestas Wind Systems A/S
> This e-mail is subject to our e-mail disclaimer statement.
> Please refer to www.vestas.com/legal/notice
> If you have received this e-mail in error please contact the sender.
>
>
>> -----Original Message-----
>> From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-
>> project.org] On Behalf Of MacQueen, Don
>> Sent: 29. august 2014 01:58
>> To: r-sig-geo at r-project.org
>> Subject: [R-sig-Geo] Using spTransform() to reproduce another software
>> package's transformation
>>
>> The program I work for has specified the use of a local coordinate reference
>> system and a method for transforming and projecting from WGS84 long/lat
>> to the local system. They use ESRI products to convert from long/lat to the
>> local system.
>>
>> Since I do everything in R, naturally I wish to use spTransform() to replicate
>> their conversion. I've been using spTransform() for a number of years now,
>> and thought I understood what I've been doing.
>>
>> But I have run into trouble. I would appreciate any advice.
>>
>> I believe I have a reproducible example. Toward the end of this email are R
>> expressions (based on dput) that will create two SpatialPoints objects that
>> are used in the example. They need to be created first, before running the
>> example.
>>
>> ####
>> ## before adding further detail and the example, here are some references
>> ####
>>
>> (1)
>> http://downloads2.esri.com/support/TechArticles/Geographic_Transformati
>> ons_10.1.zip
>> (2)
>> http://resources.arcgis.com/en/help/main/10.2/index.html#/Equation_base
>> d_methods/003r00000012000000/
>> (3)
>> http://resources.arcgis.com/en/help/main/10.2/index.html#/Grid_based_m
>> ethods/003r00000013000000/
>>
>>
>>
>> The programs's specified CRS is epsg 26743 = California State Plane Zone 3
>> NAD27 US feet (out of my control!)
>>
>> The specified method for transforming and projecting from WGS84 long/lat
>> to the local CRS consists of two steps:
>>  1) transform and project to epsg 2227 = California State Plane Zone 3 NAD83
>> US feet
>>  2) transform to epsg 26743 = California State Plane Zone 3 NAD27 US feet
>>
>> When doing the steps in the ESRI software's projection tool:
>>  step 1) use what ESRI calls "NAD_1983_To_WGS_1984_5"  (wkid 1515 in
>> reference 1)
>>  step 2) use what ESRI calls "NAD_1927_To_NAD_1983_NADCON"  (wkid 1241
>> in reference 1)
>>
>> According to reference 1 "NAD_1983_To_WGS_1984_5" is a "coordinate
>> frame" transformation.
>> Based on reference 2, this means it is a 7 parameter Bursa-Wolf method
>> Also based on reference 1, "NAD_1927_To_NAD_1983_NADCON" is a grid-
>> based method
>>
>>
>> As I hope you will see, a naive use of spTransform() produces coordinates
>> that differ from the ESRI two-step process by approximately 3.7 ft (x) and -
>> 1.9 ft (y). This is too large for our use case. I also believe as a matter of
>> principle that it should be possible to do better (I'd like to believe that any
>> transformation possible in ESRI is also possible using PROJ.4).
>>
>>
>> ##
>> ## reproducible example begins
>> ##
>>
>> ## define two example points in WGS84 long/lat
>> locs.xy <- cbind(
>>              c(-121.524764291826,-121.523480804667),
>>              c(37.6600366036405,37.6543604613483)
>>              )
>>
>> locs.ll <- SpatialPoints(locs.xy, proj4string=CRS("+proj=longlat
>> +datum=WGS84") )
>>
>> ## source the expressions near the bottom of this email to create
>> ##    locs.ref
>> ##    locs.step1.esri
>>
>> ## use spTransform to go from WGS84 to the local system in one step:
>> locs.26743 <- spTransform(locs.ll, CRS("+init=epsg:26743"))
>>
>> ## not close enough:
>> coordinates(locs.ref)-coordinates(locs.26743)
>> ##      coords.x1 coords.x2
>> ## [1,]  3.746539 -1.876668
>> ## [2,]  3.746607 -1.876466
>>
>>
>> ## spTransform equivalent of ESRI step 1
>> locs.step1.proj4 <- spTransform(locs.ll, CRS("+init=epsg:2227"))
>>
>> ## not close enough, essentially the same difference as above
>> coordinates(locs.step1.esri)-coordinates(locs.step1.proj4)
>> ##      coords.x1 coords.x2
>> ## [1,]  3.746244 -1.877057
>> ## [2,]  3.746315 -1.876856
>>
>>
>> ## next, try the spTransform equivalent of ESRI step 1, but specifying the
>> seven parameters
>> ## note, had to reverse the sign of the rotation args from wkid 1515 in
>> reference 1;
>> ## evidently the PROJ.4 default is the "position vector" method (reference 2)
>>
>> crs.step1.cf <- CRS('+proj=lcc +lat_1=38.43333333333333
>> +lat_2=37.06666666666667 +lat_0=36.5 +lon_0=-120.5\
>>  +x_0=2000000.0 +y_0=500000.0 +ellps=GRS80 +datum=NAD83\
>>  +units=us-ft +no_defs\
>>  +towgs84=-0.991,1.9072,0.5129,0.025789908,0.0096501,0.0116599,0.0')
>>
>> ## by the way, this alternative to specifying the CRS gives the same result
>> ##  crs.step1.cf <- CRS("+init=epsg:2227 +towgs84=-
>> 0.991,1.9072,0.5129,0.025789908,0.0096501,0.0116599,0.0")
>>
>> locs.step1.cf <- spTransform(locs.ll, crs.step1.cf)
>>
>> ## good enough (hooray!)
>> coordinates(locs.step1.esri)-coordinates(locs.step1.cf)
>> ##          coords.x1     coords.x2
>> ## [1,] -3.469177e-06 -5.122274e-08
>> ## [2,] -3.418885e-06 -7.380731e-08
>>
>>
>>
>> ## now try for step 2 using spTranform()
>> locs.step2.cf <- spTransform(locs.step1.cf, CRS("+init=epsg:26743"))
>>
>> ## the original difference is back!
>> coordinates(locs.ref)-coordinates(locs.step2.cf)
>> ##      coords.x1 coords.x2
>> ## [1,]  3.746539 -1.876668
>> ## [2,]  3.746608 -1.876466
>>
>> ## the implication is that in doing the transformation to epsg 26743, it
>> reversed the effect of the 7-parameter method
>>
>> ## attempt to prevent that:
>>
>> locs.tmp <- locs.step1.cf
>> proj4string(locs.tmp) <- CRS("+init=epsg:2227")
>> ## Warning message:
>> ## In `proj4string<-`(`*tmp*`, value = <S4 object of class "CRS">) :
>> ##   A new CRS was assigned to an object with an existing CRS:
>> ## +proj=lcc +lat_1=38.43333333333333 +lat_2=37.06666666666667
>> +lat_0=36.5 +lon_0=-120.5 +x_0=2000000.0 +y_0=500000.0 +ellps=GRS80
>> +datum=NAD83 +units=us-ft +no_defs +towgs84=-
>> 0.991,1.9072,0.5129,0.025789908,0.0096501,0.0116599,0.0
>> ## without reprojecting.
>> ## For reprojection, use function spTransform in package rgdal
>>
>> locs.step2.cfb <- spTransform(locs.tmp, CRS("+init=epsg:26743"))
>>
>> ## This actually works; the difference is now acceptably small
>> coordinates(locs.ref)-coordinates(locs.step2.cfb)
>> ##         coords.x1    coords.x2
>> ## [1,] 0.0003266879 0.0006651825
>> ## [2,] 0.0003261503 0.0006651356
>>
>>
>> ## Another way, perhaps more appropriate (and with no warning message)
>> is recreate the SpatialPoints
>> ## object instead of modifying it:
>> locs.tmp <- SpatialPoints(coordinates(locs.step1.cf),
>> proj4string=CRS("+init=epsg:2227"))
>> locs.step2.cfb <- spTransform(locs.tmp, CRS("+init=epsg:26743"))
>>
>> coordinates(locs.ref)-coordinates(locs.step2.cfb)
>> ##         coords.x1    coords.x2
>> ## [1,] 0.0003266879 0.0006651825
>> ## [2,] 0.0003261503 0.0006651356
>>
>>
>>
>> This suggests to me that in PROJ.4 the specifications for the CRS are in some
>> way mixed in with the specifications for how the geographic transformation
>> is performed. Apparently, one cannot specify the transformation method
>> independent of the CRS specification. To put it another way, I have two ways
>> of converting from the original CRS to the first step's target CRS. The target
>> CRS is the same either way. But a second conversion to another CRS is
>> affected by the method of the first one.
>>
>> Have I interpreted correctly? If so, I guess it doesn't seem appropriate-the
>> conversion from one CRS to another should depend only on what the CRS is,
>> not on how it got there.
>>
>> Is there something I don't understand so that this kind of dependency is
>> appropriate?
>>
>> In the end, I guess I do have a solution, but I kind of don't like it. I have to
>> insert a "correction" to the CRS. Is there a better way?
>>
>>
>>
>>
>> #####
>> ### source the following to create objects used by the reproducible example
>> above
>> #####
>>
>> ## the two points converted from long/lat using the complete ESRI "two-
>> step process"
>> ## saved as a shapefile, loaded into R using readOGR(). Then just the
>> coordinates
>> ## were "dput"
>> locs.ref <- new(
>>               "SpatialPoints",
>>               coords = structure(c(1703671.30566227, 1704020.20113366,
>>                 424014.398045834, 421943.708664294), .Dim = c(2L, 2L),
>>                 .Dimnames = list(NULL, c("coords.x1", "coords.x2")))
>>               , bbox = structure(
>>                   c(1703671.30566227, 421943.708664294,
>>                     1704020.20113366, 424014.398045834),
>>                   .Dim = c(2L, 2L),
>>                   .Dimnames = list(c("coords.x1",  "coords.x2"), c("min", "max")))
>>               , proj4string =
>>               new("CRS",
>>                   projargs = "+proj=lcc +lat_1=37.06666666666667
>> +lat_2=38.43333333333333 +lat_0=36.5 +lon_0=-120.5
>> +x_0=609601.2192024384 +y_0=0 +datum=NAD27 +units=us-ft +no_defs
>> +ellps=clrk66 +nadgrids=@conus, at alaska, at ntv2_0.gsb, at ntv1_can.dat"
>>                   )
>>               )
>>
>>
>> ## the points converted to epsg 2227 using ESRI's step 1
>> ## saved as a shapefile, loaded into R using readOGR
>> ## Then just the coordinates were "dput"
>> locs.step1.esri <- new(
>>                      "SpatialPoints",
>>                      coords = structure(c(6265039.1378244, 6265388.04257557,
>>                        2064418.92932968, 2062348.22239488), .Dim = c(2L, 2L),
>>                        .Dimnames = list(NULL, c("coords.x1", "coords.x2")))
>>                      , bbox = structure(
>>                          c(6265039.1378244, 2062348.22239488,
>>                            6265388.04257557, 2064418.92932968),
>>                          .Dim = c(2L, 2L),
>>                          .Dimnames = list(c("coords.x1", "coords.x2"), c("min", "max")))
>>                      , proj4string = new("CRS",
>>                          projargs = "+proj=lcc +lat_1=37.06666666666667
>> +lat_2=38.43333333333333 +lat_0=36.5 +lon_0=-120.5 +x_0=2000000
>> +y_0=500000.0000000001 +datum=NAD83 +units=us-ft +no_defs
>> +ellps=GRS80 +towgs84=0,0,0"
>>                          )
>>                      )
>>
>>
>> #####
>> ###package and session information
>> #####
>>
>>
>> Loading required package: sp
>> Checking rgeos availability: TRUE
>>
>> Loading required package: rgdal
>> rgdal: version: 0.8-16, (SVN revision 498)
>> Geospatial Data Abstraction Library extensions to R successfully loaded
>> Loaded GDAL runtime: GDAL 1.11.0, released 2014/04/16
>> Path to GDAL shared files:
>> /Users/macqueen1/Library/R/3.1/library/rgdal/gdal
>> Loaded PROJ.4 runtime: Rel. 4.8.0, 6 March 2012, [PJ_VERSION: 480]
>> Path to PROJ.4 shared files:
>> /Users/macqueen1/Library/R/3.1/library/rgdal/proj
>>
>>
>>> sessionInfo()
>> R version 3.1.1 (2014-07-10)
>> Platform: x86_64-apple-darwin13.1.0 (64-bit)
>>
>> locale:
>> [1] C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] sp_1.0-15       rgdal_0.8-16    maptools_0.8-30 xlsx_0.5.5
>> [5] xlsxjars_0.6.0  rJava_0.9-6     rmacq_1.3-1
>>
>> loaded via a namespace (and not attached):
>> [1] foreign_0.8-61  grid_3.1.1      lattice_0.20-29 tools_3.1.1
>>
>> ----
>> two final comments:
>>
>> I understand that this is really a PROJ.4 question, so I hope that R-sig-geo
>> folks don't mind too much; apologies in advance if so.
>>
>> I hope my email software truly sends a plain text email like it claims. But I'm
>> not sure I trust it!
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no

From helen at rams.colostate.edu  Fri Aug 29 17:22:32 2014
From: helen at rams.colostate.edu (Helen Sofaer)
Date: Fri, 29 Aug 2014 09:22:32 -0600
Subject: [R-sig-Geo] raster to dataframe with xy=TRUE, na.rm=TRUE
In-Reply-To: <CAAcyNCzG54=hiFhsi0GURfo1XnrnLKAzZNUwyBaJCuksW+2x-A@mail.gmail.com>
References: <CAOckJBO=uS5fL=G4akfsMtcQ4Npfx3qSYFH+C15fyfWuwPrHcg@mail.gmail.com>
	<CAAcyNCzG54=hiFhsi0GURfo1XnrnLKAzZNUwyBaJCuksW+2x-A@mail.gmail.com>
Message-ID: <CAOckJBNF0RmLFy0jmsBV4BdNcMRBFJCSg-MzikQv-GhgoSRVhg@mail.gmail.com>

Thanks Pascal,
That's helpful.

I am curious about what happened in the second example, if anyone else
takes a look.
Cheers,
Helen


On Thu, Aug 28, 2014 at 11:17 PM, Pascal Oettli <kridox at ymail.com> wrote:

> Hello,
>
> Did you try with the "rasterToPoints" function?
>
> Something like:
>
> r1.b.df <- as.data.frame(rasterToPoints(r1.b.mask))
> coordinates(r1.b.df) <- ~x+y
> plot(r1.b.df)
>
> Regards,
> Pascal
>
> On Fri, Aug 29, 2014 at 1:52 PM, Helen Sofaer <helen at rams.colostate.edu>
> wrote:
> > Hi all,
> >
> > I?m trying to convert a RasterBrick to a dataframe while adding the
> > coordinates and while dropping cells that were masked to NA. This
> > combination of options gives me an error when the mask is done with an sp
> > object.
> >
> >
> >
> > Some reproducible code:
> >
> >
> >
> > usa = getData('GADM', country = 'USA', level = 0)
> >
> >
> >
> > r1 = raster()
> >
> > values(r1) = 1:ncell(r1)
> >
> > r1.b = brick(r1, r1, r1, r1)
> >
> > r1.b.mask = mask(r1.b, usa)
> >
> > plot(r1.b.mask)
> >
> > r1.b.df = as.data.frame(r1.b.mask, xy = TRUE, na.rm = TRUE)
> >
> >
> >
> > The error is:
> >
> > Error in data.frame(..., check.names = FALSE) :
> >
> >   arguments imply differing number of rows: 64800, 1109
> >
> >
> >
> > Looks like it wants to combine all the coordinates with just the subset
> of
> > the data.
> >
> >
> >
> > I surprised myself further by looking at what happens if the NAs are in
> > random locations, rather than masked out:
> >
> >
> >
> > # random NAs:
> >
> > r2 = raster()
> >
> > vals = 1:ncell(r2)
> >
> > vals[sample(1:ncell(r2), .5*ncell(r2))] = NA
> >
> > values(r2) = vals
> >
> > plot(r2)
> >
> > r2.b = brick(r2, r2, r2, r2)
> >
> > r2.b.df = as.data.frame(r2.b, xy = TRUE, na.rm = TRUE)
> >
> > str(r2.b.df) # 64800 obs; same as ncell in each layer; further inspection
> > shows all locations are there and some values are repeated
> >
> >
> >
> > Any advice/interpretation is appreciated. In practice I have already
> > cropped but still have a lot of NAs within my extent. Of course, I can
> drop
> > the rows afterwards, but thought I?d ask. Also, I see the same thing if
> > it?s a single layer, rather than a brick.
> >
> >
> >
> > FYI, I?m running 3.1.1 and raster version 2.2-31 and a Mavericks OSX
> (and I
> > also tried it on a Fedora linux machine running 3.1.0 to make sure it
> > wasn?t a Mavericks thing).
> >
> >
> >
> > Thanks for your time!
> >
> > Helen
> >
> > --
> > Helen Sofaer
> > Postdoctoral Fellow
> > Fish Wildlife and Conservation Biology
> > Colorado State University
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>
> --
> Pascal Oettli
> Project Scientist
> JAMSTEC
> Yokohama, Japan
>



-- 
Helen Sofaer
Postdoctoral Fellow
Fish Wildlife and Conservation Biology
Colorado State University

	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Fri Aug 29 18:48:37 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 29 Aug 2014 18:48:37 +0200
Subject: [R-sig-Geo] How do I calculate neighborhood contiguity in R?
In-Reply-To: <001301cfc0c8$bc27f080$3477d180$@uvic.ca>
References: <001301cfc0c8$bc27f080$3477d180$@uvic.ca>
Message-ID: <alpine.LRH.2.03.1408291826560.10762@reclus.nhh.no>

On Tue, 26 Aug 2014, Shanley Thompson wrote:

> Hello,
> My end goal is to calculate join counts, using the function
> joincounts.multi() from the R package spdep. I understand that first I need
> to calculate the nb object, then the spatial weights matrix, then I can do
> the join counts.
>
> I have a very large raster file (nrows = 19663, ncols = 34073), with cell
> size of 30 m, in integer format. I read it in using the raster() function
> from the Raster package.
>
> For the first part (creating a "nb" object), I have tried using the cell2nb
> file but it keeps crashing - a quick search tells me others have had the
> same problem due to large files.

Please note that "crash" means that R error-exits. I believe you mean that 
R ran out of memory, and it does this in different ways on different 
platforms. You didn't provide the output of sessionInfo(), so we don't 
know your platform. Obviously a neighbour object with almost 640 million 
observations, say with <=8 neighbours each, is itself a very large object. 
But this isn't the main problem.

>
> I read that one can use "dnearneigh" function in the spdep package instead,
> but I do not understand how to do so. Can someone provide a detailed
> example?  Alternatively, would it be better to convert my raster layer to a
> polygon layer then use the function poly2nb?
>
> I am relatively new to R so the simpler the better!
>

Step back and ask yourself whether the entities represented by 30x30m 
raster cells are actually entities (like botanical field plots) or are an 
artificial result of the arbitrary gridding of the scene by the 
instrument. I would argue that a:

RRRGG
RRGGG
RGGBB
GGBBB
GBBBB

grid is three entities, not 25, with the R G and B entities gridded 
inflating the degrees of freedom - and giving completely different sets of 
join counts. The only reason to believe the 30x30 grid is if the scale or 
footprint of the land cover classes (or whatever) that you are studying 
matches the grid resolution.

So the simple answer is: don't do join count on this kind of data unless 
the entities are suitable - even if there was a way (making the counts as 
a focal procedure in raster perhaps), the results would be spurious. You 
could also sample your scene in say 500x500 blocks, choosing a random SW 
cell to start. With a number of samples, you'd get a picture of the join 
counts that would not be far from the whole scene.

Hope this helps,

Roger

> Thank you so much!
>
>
> Shanley Thompson, MSc, PhD Candidate
> Department of Geography, University of Victoria, Canada
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From srinivasv at feralindia.org  Sat Aug 30 05:08:31 2014
From: srinivasv at feralindia.org (Srinivas V)
Date: Sat, 30 Aug 2014 08:38:31 +0530
Subject: [R-sig-Geo] Subsetting Raster Time Series
In-Reply-To: <A83620D4CC4762448EFB789FD6E9BBB7429D1E78@SCOMP0937.wurnet.nl>
References: <53FC599A.20101@feralindia.org>
	<A83620D4CC4762448EFB789FD6E9BBB7429D1E78@SCOMP0937.wurnet.nl>
Message-ID: <5401402F.1010100@feralindia.org>

Thanks the nested approach worked perfectly.
Regards
Srinivas

  

On Tuesday 26 August 2014 05:24 PM, Dutrieux, Loic wrote:
> Hi Srinivas,
>
> You can access the time dimension of these raster object using the getZ and setZ functions; both from the raster package (avoid when possible accessing objects' slots by using @). Following that it is mostly vector arithmetic, which can be achieved in several ways.
>
> Using the example in the help of getZ.
>
> library(raster)
> # Create a rasterStack object with time written to z dimension.
> r <- raster(ncol=10, nrow=10)
> s <- stack(lapply(1:3, function(x) setValues(r, runif(ncell(r)))))
> s <- setZ(s, as.Date('2000-1-1') + 0:2)
> s
>
> # Extract time vector
> time <- getZ(s)
> # You can get the indices which fit your subset criteria using which() and inject them into raster::subset()
> id <- which(time < as.Date('2000-1-3'))
> subset(s, id)
>
> # Nested
> subset(s, which(getZ(s) < as.Date('2000-1-3')))
>
> Best regards,
>
> --
> Lo?c Dutrieux
> Laboratory of Geo-Information sciences and remote sensing
> Wageningen University
> The Netherlands
>
>
>
>
> -----Original Message-----
> From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of Srinivas V
> Sent: Tuesday, August 26, 2014 11:56
> To: r-sig-geo at r-project.org
> Subject: [R-sig-Geo] Subsetting Raster Time Series
>
> Hi,
>
> I would like to subset the CRU dataset to a particular time period
> (1980-2013) is there an option to do this within package raster? I can manually specifiy the layers to drop, but I would like to drop them based on a time period. I'm doing this to ensure two datasets are of the same time period.
>
> I would appreciate any advice on dealing with this issue. Thanks!
>
> library(raster)
> library(rgdal)
> library(ncdf)
> library(zoo)
>
> temp<-brick("/media/data/data_cru/tmp/cru_ts3.22.1901.2013.tmp.dat.nc")
> temp
> temp at z
>
> output
> +++++
>   > temp
> class       : RasterBrick
> dimensions  : 360, 720, 259200, 1356  (nrow, ncol, ncell, nlayers) resolution  : 0.5, 0.5  (x, y)
> extent      : -180, 180, -90, 90  (xmin, xmax, ymin, ymax)
> coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0 data source : /media/data/data_cru/tmp/cru_ts3.22.1901.2013.tmp.dat.nc
> names       : X1901.01.16, X1901.02.15, X1901.03.16, X1901.04.16,
> X1901.05.16, X1901.06.16, X1901.07.16, X1901.08.16, X1901.09.16, X1901.10.16, X1901.11.16, X1901.12.16, X1902.01.16, X1902.02.15, X1902.03.16, ...
> Date        : 1901-01-16, 2013-12-16 (min, max)
> varname     : tmp
>
>   > temp at z
> $Date
>    [1] "1901-01-16" "1901-02-15" "1901-03-16" "1901-04-16" "1901-05-16"
> "1901-06-16" "1901-07-16" "1901-08-16" "1901-09-16" "1901-10-16"
>
> [1351] "2013-07-16" "2013-08-16" "2013-09-16" "2013-10-16" "2013-11-16"
> "2013-12-16"
>
>
>


	[[alternative HTML version deleted]]


From jwm302 at gmail.com  Sat Aug 30 13:27:28 2014
From: jwm302 at gmail.com (Justin Michell)
Date: Sat, 30 Aug 2014 13:27:28 +0200
Subject: [R-sig-Geo] Raster Layers same resolution but not the same
	coordinates over the same area
In-Reply-To: <CABG0rfvymz-7HXdcPS3DvXzQ9eDuojP-sDWZqxP6+5iuiJ46zQ@mail.gmail.com>
References: <FEFE7375-7C62-47E7-B906-BB257581C587@gmail.com>
	<csym1f9skc7sbexltddb6dc3.1403877499889@email.android.com>
	<4A71BF68-2BC3-48FC-B988-80CB966F46FF@gmail.com>
	<CABG0rfvymz-7HXdcPS3DvXzQ9eDuojP-sDWZqxP6+5iuiJ46zQ@mail.gmail.com>
Message-ID: <5B0127DE-CE8B-4E9D-B9D2-238B92178A79@gmail.com>

Hi Jonathan

I tried that.. But I am but the results don?t make sense:

> head(NDVIStackDf)
         x         y     NDVI1     NDVI2    NDVI3     NDVI4    NDVI5     NDVI6     NDVI7     NDVI8     NDVI9    NDVI10    NDVI11    NDVI12
1 29.42809 -1.002081 0.7196462 0.6093929 0.614475 0.7851786 0.799475 0.7241929 0.5946000 0.5948500 0.6585143 0.7874357 0.8305786 0.7774929
2 29.43662 -1.002081 0.7103154 0.5823500 0.572225 0.7867429 0.794050 0.7445643 0.6033786 0.5635429 0.6421857 0.7802786 0.8300643 0.7886786
3 29.44514 -1.002081 0.7303692 0.6254571 0.599350 0.7771143 0.785850 0.7510071 0.6404571 0.6197286 0.6770929 0.7686786 0.8169571 0.7957786
4 29.45367 -1.002081 0.7641923 0.6890714 0.657850 0.7936786 0.809975 0.7805429 0.6769643 0.6590714 0.7165357 0.7843357 0.8283286 0.8231500
5 29.46220 -1.002081 0.8057769 0.7500714 0.718175 0.8208786 0.838575 0.8126500 0.7345786 0.7359571 0.7661214 0.8087214 0.8442643 0.8380071
6 29.47073 -1.002081 0.8065615 0.7627071 0.730550 0.8142214 0.841100 0.8252000 0.7574786 0.7425071 0.7590571 0.8025071 0.8518357 0.8430286
> head(rainStackDf)
         x         y rain1 rain2 rain3 rain4 rain5 rain6 rain7 rain8 rain9 rain10 rain11 rain12
1 29.42917 -1.004167    66    68    85   116   105    61    40    85   110    125    118     85
2 29.43750 -1.004167    66    69    85   117   106    61    40    85   110    125    119     86
3 29.44583 -1.004167    66    68    84   116   106    60    39    84   110    124    118     85
4 29.45417 -1.004167    65    67    83   116   105    60    39    83   108    123    117     84
5 29.46250 -1.004167    65    68    83   117   106    59    38    83   109    124    118     84
6 29.47083 -1.004167    66    68    84   118   107    59    38    83   110    125    119     85
> mystackDf <- stack(NDVIStackDf, rainStackDf)
> 
> head(mystackDf)
    values ind
1 29.42809   x
2 29.43662   x
3 29.44514   x
4 29.45367   x
5 29.46220   x
6 29.47073   x

Is there a better way maybe without using data frames?

I tried stacking the stacks too:

> s1 <- stack(NDVIStack, rainStack)
Error in compareRaster(x) : different number or columns
> rainStack
class       : RasterStack 
dimensions  : 1287, 1321, 1700127, 12  (nrow, ncol, ncell, nlayers)
resolution  : 0.008333333, 0.008333333  (x, y)
extent      : 29.425, 40.43333, -11.725, -1  (xmin, xmax, ymin, ymax)
coord. ref. : +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0 
names       : rain1, rain2, rain3, rain4, rain5, rain6, rain7, rain8, rain9, rain10, rain11, rain12 
min values  :     7,     5,    31,    13,     0,     0,     0,     0,     0,      0,     22,     32 
max values  :   391,   392,   563,   746,   473,   159,   109,   106,   164,    247,    349,    464 

> NDVIStack
class       : RasterStack 
dimensions  : 1258, 1291, 1624078, 12  (nrow, ncol, ncell, nlayers)
resolution  : 0.008526982, 0.008525437  (x, y)
extent      : 29.425, 40.43333, -11.725, -1  (xmin, xmax, ymin, ymax)
coord. ref. : +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0 
names       :      NDVI1,      NDVI2,      NDVI3,      NDVI4,      NDVI5,      NDVI6,      NDVI7,      NDVI8,      NDVI9,     NDVI10,     NDVI11,     NDVI12 
min values  : -0.1524615, -0.1353071, -0.1970500, -0.1632071, -0.1919250, -0.1647286, -0.1665000, -0.1693357, -0.1852643, -0.1733714, -0.1555357, -0.1682571 
max values  :  0.9153615,  0.9013000,  0.9295500,  0.9134643,  0.9421750,  0.9158357,  0.9000071,  0.9009786,  0.8733571,  0.8792429,  0.9151357,  0.9233000 

Thanks 
Justin

On Jun 30, 2014, at 5:55 PM, Jonathan Greenberg <jgrn at illinois.edu> wrote:

> Justin:
> 
> It would make more sense, if you insist on working with data.frames,
> for you to create a single stack with all of your predictor and
> response variables, and then do your extraction -- that way you don't
> need to worry about a merge after the fact.  The chances of the
> coordinates being EXACT I suspect are very low, which is why the
> merge() is failing.
> 
> Basically:
> 
> mystack <- stack(meanTempStackDf, rainStackDf)
> 
> ... Then you can extract the data.
> 
> --j
> 
> On Mon, Jun 30, 2014 at 6:22 AM, Justin Michell <jwm302 at gmail.com> wrote:
>> Dear Niandou
>> 
>> No I have not received any feedback.
>> 
>> I do have some thoughts though. Is it possible/or at least would it make sense to get values in NDVI layer (average of nearby cells?) at the coordinates of raster values in other layers which one wants to merge with?
>> 
>> I am not very well versed in these things so it?s just a thought- not sure how it would be implemented in R.
>> 
>> Regards
>> Justin
>> 
>> 
>> On Jun 27, 2014, at 3:58 PM, ISSAKA NIANDOU, Yacouba <niandouy at who.int> wrote:
>> 
>>> Niandou
>> 
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> 
> 
> -- 
> Jonathan A. Greenberg, PhD
> Assistant Professor
> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
> Department of Geography and Geographic Information Science
> University of Illinois at Urbana-Champaign
> 259 Computing Applications Building, MC-150
> 605 East Springfield Avenue
> Champaign, IL  61820-6371
> Phone: 217-300-1924
> http://www.geog.illinois.edu/~jgrn/
> AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007


From jwm302 at gmail.com  Sat Aug 30 13:31:02 2014
From: jwm302 at gmail.com (Justin Michell)
Date: Sat, 30 Aug 2014 13:31:02 +0200
Subject: [R-sig-Geo] Raster Layers same resolution but not the same
	coordinates over the same area
In-Reply-To: <5B0127DE-CE8B-4E9D-B9D2-238B92178A79@gmail.com>
References: <FEFE7375-7C62-47E7-B906-BB257581C587@gmail.com>
	<csym1f9skc7sbexltddb6dc3.1403877499889@email.android.com>
	<4A71BF68-2BC3-48FC-B988-80CB966F46FF@gmail.com>
	<CABG0rfvymz-7HXdcPS3DvXzQ9eDuojP-sDWZqxP6+5iuiJ46zQ@mail.gmail.com>
	<5B0127DE-CE8B-4E9D-B9D2-238B92178A79@gmail.com>
Message-ID: <A618DF42-6AAF-48F6-B886-94B33A64517E@gmail.com>

My apologies, I forgot to send as plain text.

On Aug 30, 2014, at 1:27 PM, Justin Michell <jwm302 at gmail.com> wrote:

> Hi Jonathan
> 
> I tried that.. But I am but the results don?t make sense:
> 
>> head(NDVIStackDf)
>         x         y     NDVI1     NDVI2    NDVI3     NDVI4    NDVI5     NDVI6     NDVI7     NDVI8     NDVI9    NDVI10    NDVI11    NDVI12
> 1 29.42809 -1.002081 0.7196462 0.6093929 0.614475 0.7851786 0.799475 0.7241929 0.5946000 0.5948500 0.6585143 0.7874357 0.8305786 0.7774929
> 2 29.43662 -1.002081 0.7103154 0.5823500 0.572225 0.7867429 0.794050 0.7445643 0.6033786 0.5635429 0.6421857 0.7802786 0.8300643 0.7886786
> 3 29.44514 -1.002081 0.7303692 0.6254571 0.599350 0.7771143 0.785850 0.7510071 0.6404571 0.6197286 0.6770929 0.7686786 0.8169571 0.7957786
> 4 29.45367 -1.002081 0.7641923 0.6890714 0.657850 0.7936786 0.809975 0.7805429 0.6769643 0.6590714 0.7165357 0.7843357 0.8283286 0.8231500
> 5 29.46220 -1.002081 0.8057769 0.7500714 0.718175 0.8208786 0.838575 0.8126500 0.7345786 0.7359571 0.7661214 0.8087214 0.8442643 0.8380071
> 6 29.47073 -1.002081 0.8065615 0.7627071 0.730550 0.8142214 0.841100 0.8252000 0.7574786 0.7425071 0.7590571 0.8025071 0.8518357 0.8430286
>> head(rainStackDf)
>         x         y rain1 rain2 rain3 rain4 rain5 rain6 rain7 rain8 rain9 rain10 rain11 rain12
> 1 29.42917 -1.004167    66    68    85   116   105    61    40    85   110    125    118     85
> 2 29.43750 -1.004167    66    69    85   117   106    61    40    85   110    125    119     86
> 3 29.44583 -1.004167    66    68    84   116   106    60    39    84   110    124    118     85
> 4 29.45417 -1.004167    65    67    83   116   105    60    39    83   108    123    117     84
> 5 29.46250 -1.004167    65    68    83   117   106    59    38    83   109    124    118     84
> 6 29.47083 -1.004167    66    68    84   118   107    59    38    83   110    125    119     85
>> mystackDf <- stack(NDVIStackDf, rainStackDf)
>> 
>> head(mystackDf)
>    values ind
> 1 29.42809   x
> 2 29.43662   x
> 3 29.44514   x
> 4 29.45367   x
> 5 29.46220   x
> 6 29.47073   x
> 
> Is there a better way maybe without using data frames?
> 
> I tried stacking the stacks too:
> 
>> s1 <- stack(NDVIStack, rainStack)
> Error in compareRaster(x) : different number or columns
>> rainStack
> class       : RasterStack 
> dimensions  : 1287, 1321, 1700127, 12  (nrow, ncol, ncell, nlayers)
> resolution  : 0.008333333, 0.008333333  (x, y)
> extent      : 29.425, 40.43333, -11.725, -1  (xmin, xmax, ymin, ymax)
> coord. ref. : +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0 
> names       : rain1, rain2, rain3, rain4, rain5, rain6, rain7, rain8, rain9, rain10, rain11, rain12 
> min values  :     7,     5,    31,    13,     0,     0,     0,     0,     0,      0,     22,     32 
> max values  :   391,   392,   563,   746,   473,   159,   109,   106,   164,    247,    349,    464 
> 
>> NDVIStack
> class       : RasterStack 
> dimensions  : 1258, 1291, 1624078, 12  (nrow, ncol, ncell, nlayers)
> resolution  : 0.008526982, 0.008525437  (x, y)
> extent      : 29.425, 40.43333, -11.725, -1  (xmin, xmax, ymin, ymax)
> coord. ref. : +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0 
> names       :      NDVI1,      NDVI2,      NDVI3,      NDVI4,      NDVI5,      NDVI6,      NDVI7,      NDVI8,      NDVI9,     NDVI10,     NDVI11,     NDVI12 
> min values  : -0.1524615, -0.1353071, -0.1970500, -0.1632071, -0.1919250, -0.1647286, -0.1665000, -0.1693357, -0.1852643, -0.1733714, -0.1555357, -0.1682571 
> max values  :  0.9153615,  0.9013000,  0.9295500,  0.9134643,  0.9421750,  0.9158357,  0.9000071,  0.9009786,  0.8733571,  0.8792429,  0.9151357,  0.9233000 
> 
> Thanks 
> Justin
> 
> On Jun 30, 2014, at 5:55 PM, Jonathan Greenberg <jgrn at illinois.edu> wrote:
> 
>> Justin:
>> 
>> It would make more sense, if you insist on working with data.frames,
>> for you to create a single stack with all of your predictor and
>> response variables, and then do your extraction -- that way you don't
>> need to worry about a merge after the fact.  The chances of the
>> coordinates being EXACT I suspect are very low, which is why the
>> merge() is failing.
>> 
>> Basically:
>> 
>> mystack <- stack(meanTempStackDf, rainStackDf)
>> 
>> ... Then you can extract the data.
>> 
>> --j
>> 
>> On Mon, Jun 30, 2014 at 6:22 AM, Justin Michell <jwm302 at gmail.com> wrote:
>>> Dear Niandou
>>> 
>>> No I have not received any feedback.
>>> 
>>> I do have some thoughts though. Is it possible/or at least would it make sense to get values in NDVI layer (average of nearby cells?) at the coordinates of raster values in other layers which one wants to merge with?
>>> 
>>> I am not very well versed in these things so it?s just a thought- not sure how it would be implemented in R.
>>> 
>>> Regards
>>> Justin
>>> 
>>> 
>>> On Jun 27, 2014, at 3:58 PM, ISSAKA NIANDOU, Yacouba <niandouy at who.int> wrote:
>>> 
>>>> Niandou
>>> 
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> 
>> 
>> 
>> -- 
>> Jonathan A. Greenberg, PhD
>> Assistant Professor
>> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
>> Department of Geography and Geographic Information Science
>> University of Illinois at Urbana-Champaign
>> 259 Computing Applications Building, MC-150
>> 605 East Springfield Avenue
>> Champaign, IL  61820-6371
>> Phone: 217-300-1924
>> http://www.geog.illinois.edu/~jgrn/
>> AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007
> 


From jeandaniel.sylvain at gmail.com  Sat Aug 30 16:30:56 2014
From: jeandaniel.sylvain at gmail.com (Jean-Daniel Sylvain)
Date: Sat, 30 Aug 2014 10:30:56 -0400
Subject: [R-sig-Geo] Comparison of prediction performance (mapping
 accuracy) - how to test if a method B is significantly more accurate than
 method A?
In-Reply-To: <53FF4A9E.2080008@gmail.com>
References: <53FF465E.9000009@spatial-analyst.net> <53FF4A9E.2080008@gmail.com>
Message-ID: <5401E020.5070604@gmail.com>

Dear Tom/list,

The subject could also be look as the same problem encoutered in 
ensemble forecast (e.g. meteorology).

If you could have more "folders" in your analysis (you can see each 
folder as a member of an ensemble)
you could compare the two methods as it is done in ensemble forecast, in 
meteorology and hydrology. Both disciplines provide tools which help to 
study the accuracy, uncertainty and bias related to a forecast. Based on 
this methodological framework, it could be possible to compare both 
methods on several criterias.

For those which could be interested by the subject :

Brochero (2013) provides a good review of this subject in is Ph.D. 
thesis and describe several indicators (Chapter 1). Hydroinformatics and 
diversity in hydrological ensemble prediction systems.
  http://theses.ulaval.ca/archimede/meta/29908

The site below also provides a quick and simple review of the typical 
indicators use in meteorological forecast:
http://www.eumetcal.org/resources/ukmeteocal/verification/www/english/courses/msgcrs/index.htm

However, in your case this approach seems limited by the number of 
k-folders use.

This is just an idea that is worth explorating. In my research, I entend 
to explore this approach. Any comments/suggestions?

Le 8/28/2014 11:28 AM, Tim Appelhans a ?crit :
> On 08/28/2014 05:10 PM, Tomislav Hengl wrote:
>> Dear list,
>>
>> I'm trying to standardize a procedure to compare performance of
>> competing spatial prediction methods. I know that this has been
>> discussed in various literature and on various mailing lists, but I
>> would be interested in any opinion I could get.
>>
>> I am comparing (see below) 2 spatial prediction methods
>> (regression-kriging and inverse distance interpolation) using 5-fold
>> cross-validation and then testing if the difference between the two is
>> significant. What I concluded is that there are two possible tests for
>> the final residuals:
>> 1. F-test to compare variances (cross-validation residuals),
>> 2. t-test to compare mean values,
> If you think in terms of accuracy vs. precision, I'd say both tests are
> equally important. Ideally you want your method to be precise (low
> variance) and accurate (low deviation around mean). What I usually tend
> to do is repeated random sub-sampling with 100+ runs.
>> Both tests might be important, nevertheless the F-test ("var.test")
>> seems to be more interesting to really be able to answer "is the
>> method B significantly more accurate than method A?". It appears that
>> the second test ("t.test") is only important if it fails -> which
>> would mean that one of the methods systematically over or
>> under-estimates the mean value (which should be 0). Did I maybe miss
>> some important test?
>>
>> Thank you!
>>
>> R> library(GSIF)
>> R> library(gstat)
>> R> library(sp)
>> R> set.seed(2419)
>> R> demo(meuse, echo=FALSE)
>> R> omm1 <- fit.gstatModel(meuse, log1p(om)~dist+soil, meuse.grid)
>> Fitting a linear model...
>> Fitting a 2D variogram...
>> Saving an object of class 'gstatModel'...
>> R> rk1 <- predict(omm1, meuse.grid)
>> R> meuse.s <- meuse[!is.na(meuse$om),]
>> R> ok1 <- krige.cv(log1p(om)~1, meuse.s, nfold=5)
>> R> var.test(ok1$residual, rk1 at validation$residual, alternative =
>> "greater")
>>
>>          F test to compare two variances
>>
>> data:  ok1$residual and rk1 at validation$residual
>> F = 1.2283, num df = 152, denom df = 152, p-value =
>> 0.103
>> alternative hypothesis: true ratio of variances is greater than 1
>> 95 percent confidence interval:
>>   0.9398662       Inf
>> sample estimates:
>> ratio of variances
>>            1.228322
>> R> ## No significant difference
>> R> t.test(ok1$residual, rk1 at validation$residual)
>>
>>          Welch Two Sample t-test
>>
>> data:  ok1$residual and rk1 at validation$residual
>> t = -0.0204, df = 300.842, p-value = 0.9837
>> alternative hypothesis: true difference in means is not equal to 0
>> 95 percent confidence interval:
>>   -0.07084667  0.06939220
>> sample estimates:
>>     mean of x    mean of y
>> 0.0004766718 0.0012039089
>> R> ## Again, no significant difference
>>
>> R> sessionInfo()
>> R version 3.0.3 (2014-03-06)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> other attached packages:
>> [1] randomForest_4.6-7 nortest_1.0-2
>> [3] gstat_1.0-19       GSIF_0.4-2
>> [5] sp_1.0-15          gap_1.1-12
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Sat Aug 30 21:00:31 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 30 Aug 2014 21:00:31 +0200
Subject: [R-sig-Geo] Using spTransform() to reproduce another software
 package's transformation
In-Reply-To: <alpine.LRH.2.03.1408290916450.8617@reclus.nhh.no>
References: <10CAD6CB-3271-4A3E-BFF0-3C71C3A79317@llnl.gov>
	<B078CDF40DFE4045AF172A8B4F68FC4857C79B8226@DKRDSEXC016.vestas.net>
	<alpine.LRH.2.03.1408290916450.8617@reclus.nhh.no>
Message-ID: <alpine.LRH.2.03.1408302025490.15324@reclus.nhh.no>

On Fri, 29 Aug 2014, Roger Bivand wrote:

> On Fri, 29 Aug 2014, Frede Aakmann T?gersen wrote:
>
>> Hi
>> 
>> It seems to me that you think that ESRI performs the "correct" 
>> transformation.
>
> Thanks, Frede. My guess is that this is a question for the proj-devel list, 
> probably using cs2cs as the workhorse. Please re-cast your example to use 
> cs2cs from the console prompt - I think that will be the most efficient 
> resolution. I can post on the proj list if you like.

Having posted on the proj list, and after being helped by Hermann Peifer, 
this now does better:

crs.step1.cf <- CRS(paste("+proj=lcc +lat_1=38.43333333333333",
"+lat_2=37.06666666666667 +lat_0=36.5 +lon_0=-120.5",
"+x_0=2000000.0 +y_0=500000.0 +ellps=GRS80 +units=us-ft +no_defs",
"+towgs84=-0.991,1.9072,0.5129,0.025789908,0.0096501,0.0116599,0.0"))
crs.step1.cf
locs.step1.cf <- spTransform(locs.ll, crs.step1.cf)
coordinates(locs.step1.esri)-coordinates(locs.step1.cf)
#         coords.x1     coords.x2
#[1,] -3.469177e-06 -5.122274e-08
#[2,] -3.418885e-06 -7.846393e-08


locs.tmp <- locs.step1.cf
suppressWarnings(proj4string(locs.tmp) <- CRS(paste("+proj=lcc",
"+lat_1=38.43333333333333 +lat_2=37.06666666666667 +lat_0=36.5", 
"+lon_0=-120.5 +x_0=2000000.0 +y_0=500000.0 +ellps=GRS80 +units=us-ft",
"+no_defs +nadgrids=@null")))
locs.step2.cfb <- spTransform(locs.tmp, CRS("+init=epsg:26743"))
coordinates(locs.ref)-coordinates(locs.step2.cfb)
#         coords.x1     coords.x2
#[1,] -1.028087e-05 -5.030306e-07
#[2,] -1.081964e-05 -5.360343e-07

This with (forthcoming) PROJ.4 4.9.0 and (forthcoming) rgdal 0.9-1, not 
checked with earlier versions, but should work. The sources are not very 
forthcoming on why the +nadgrids=@null trick works, but it appears to 
force the omission a step in datum transformation, which itself is a 
multi-step process internally.

Hope this helps,

Roger

>
> I suspect that the +/- 1m is what is available, but if it was possible to 
> help in the PROJ.4 framework, all other downstream software components would 
> benefit.
>
> I do see that Frank Warmerdam posted:
>
> http://lists.maptools.org/pipermail/proj/2008-September/003833.html
>
> 6 years ago in answer to a question about NAD_1983_To_WGS_1984_5.
>
> Hope this helps,
>
> Roger
>
>> 
>>> From 
>>> http://help.arcgis.com/en/arcgisdesktop/10.0/help/index.html#//003r00000010000000:
>> 
>> <quote start>
>> Converting between NAD 1983 and WGS 1984
>> 
>> Originally, NAD 1983 and WGS 1984 were considered coincident. To minimize 
>> coordinate changes, NAD 1983 is tied to the North American and Pacific (for 
>> Hawaii, and so on) plates. WGS 1984 is tied to the International 
>> Terrestrial Reference System (ITRF), which is independent of the tectonic 
>> plates. Over time, the two coordinate systems have become increasingly 
>> different.
>> 
>> NAD_1983_To_WGS_1984_1: Published accuracy from EPSG is 2 meters. This 
>> transformation applies to the entire North American continent. This 
>> transformation uses the geocentric translation method, with the 
>> transformation's parameters (dx, dy, and dz) all equal to zeroes. This 
>> transformation treats the NAD 1983 and WGS 1984 datums as though they are 
>> equivalent.
>> NAD_1983_To_WGS_1984_2: Calculated by the U. S. Defence Mapping Agency 
>> (DMA), now known as the National Geospatial Intelligence Agency (NGA), for 
>> the Aleutian islands. Accuracy is listed by EPSG at +/-8 m.
>> NAD_1983_To_WGS_1984_3: Calculated by the NGA for Hawaii. Accuracy is 
>> listed by EPSG at +/-4 m.
>> NAD_1983_To_WGS_1984_4: Formerly applied within the 48 contiguous states, 
>> but is superseded by _5. This transformation method should no longer be 
>> used.
>> NAD_1983_To_WGS_1984_5: Transformation parameters calculated by the U.S. 
>> National Geodetic Survey (NGS) using CORS stations, and ties WGS 1984 to 
>> ITRF96. Accuracy according to EPSG is +/- 1 meter.
>> NAD_1983_To_WGS_1984_6, _7, and _8: Canadian NTv2 transformations, for the 
>> Quebec, Saskatchewan, and Alberta provinces, respectively.
>> <quote end>
>> 
>> So the precision of NAD_1983_To_WGS_1984_5 according to EPSG is +- 1 meter 
>> so if your results are in feet then they are within that limit.
>> 
>> In R the parameters for PROJ.4 are:
>> 
>>> CRS("+init=epsg:26743")
>> CRS arguments:
>> +init=epsg:26743 +proj=lcc +lat_1=38.43333333333333
>> +lat_2=37.06666666666667 +lat_0=36.5 +lon_0=-120.5
>> +x_0=609601.2192024384 +y_0=0 +datum=NAD27 +units=us-ft +no_defs
>> +ellps=clrk66 +nadgrids=@conus, at alaska, at ntv2_0.gsb, at ntv1_can.dat 
>> +towgs=-3.746315,1.876856
>> 
>> This corresponds to what you can find on www.epsg-registry.org
>> 
>> Is there a corresponding EPSG code for the ESRI NAD_1983_To_WGS_1984_5 
>> transformation? Or can you by any other means find something similar to the 
>> CRS arguments? If so we can compare the CRS arguments from R and ESRI.
>> 
>> 
>> 
>> 
>> Yours sincerely / Med venlig hilsen
>> 
>> 
>> Frede Aakmann T?gersen
>> Specialist, M.Sc., Ph.D.
>> Plant Performance & Modeling
>> 
>> Technology & Service Solutions
>> T +45 9730 5135
>> M +45 2547 6050
>> frtog at vestas.com
>> http://www.vestas.com
>> 
>> Company reg. name: Vestas Wind Systems A/S
>> This e-mail is subject to our e-mail disclaimer statement.
>> Please refer to www.vestas.com/legal/notice
>> If you have received this e-mail in error please contact the sender.
>> 
>> 
>>> -----Original Message-----
>>> From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-
>>> project.org] On Behalf Of MacQueen, Don
>>> Sent: 29. august 2014 01:58
>>> To: r-sig-geo at r-project.org
>>> Subject: [R-sig-Geo] Using spTransform() to reproduce another software
>>> package's transformation
>>> 
>>> The program I work for has specified the use of a local coordinate 
>>> reference
>>> system and a method for transforming and projecting from WGS84 long/lat
>>> to the local system. They use ESRI products to convert from long/lat to 
>>> the
>>> local system.
>>> 
>>> Since I do everything in R, naturally I wish to use spTransform() to 
>>> replicate
>>> their conversion. I've been using spTransform() for a number of years now,
>>> and thought I understood what I've been doing.
>>> 
>>> But I have run into trouble. I would appreciate any advice.
>>> 
>>> I believe I have a reproducible example. Toward the end of this email are 
>>> R
>>> expressions (based on dput) that will create two SpatialPoints objects 
>>> that
>>> are used in the example. They need to be created first, before running the
>>> example.
>>> 
>>> ####
>>> ## before adding further detail and the example, here are some references
>>> ####
>>> 
>>> (1)
>>> http://downloads2.esri.com/support/TechArticles/Geographic_Transformati
>>> ons_10.1.zip
>>> (2)
>>> http://resources.arcgis.com/en/help/main/10.2/index.html#/Equation_base
>>> d_methods/003r00000012000000/
>>> (3)
>>> http://resources.arcgis.com/en/help/main/10.2/index.html#/Grid_based_m
>>> ethods/003r00000013000000/
>>> 
>>> 
>>> 
>>> The programs's specified CRS is epsg 26743 = California State Plane Zone 3
>>> NAD27 US feet (out of my control!)
>>> 
>>> The specified method for transforming and projecting from WGS84 long/lat
>>> to the local CRS consists of two steps:
>>>  1) transform and project to epsg 2227 = California State Plane Zone 3 
>>> NAD83
>>> US feet
>>>  2) transform to epsg 26743 = California State Plane Zone 3 NAD27 US feet
>>> 
>>> When doing the steps in the ESRI software's projection tool:
>>>  step 1) use what ESRI calls "NAD_1983_To_WGS_1984_5"  (wkid 1515 in
>>> reference 1)
>>>  step 2) use what ESRI calls "NAD_1927_To_NAD_1983_NADCON"  (wkid 1241
>>> in reference 1)
>>> 
>>> According to reference 1 "NAD_1983_To_WGS_1984_5" is a "coordinate
>>> frame" transformation.
>>> Based on reference 2, this means it is a 7 parameter Bursa-Wolf method
>>> Also based on reference 1, "NAD_1927_To_NAD_1983_NADCON" is a grid-
>>> based method
>>> 
>>> 
>>> As I hope you will see, a naive use of spTransform() produces coordinates
>>> that differ from the ESRI two-step process by approximately 3.7 ft (x) and 
>>> -
>>> 1.9 ft (y). This is too large for our use case. I also believe as a matter 
>>> of
>>> principle that it should be possible to do better (I'd like to believe 
>>> that any
>>> transformation possible in ESRI is also possible using PROJ.4).
>>> 
>>> 
>>> ##
>>> ## reproducible example begins
>>> ##
>>> 
>>> ## define two example points in WGS84 long/lat
>>> locs.xy <- cbind(
>>>              c(-121.524764291826,-121.523480804667),
>>>              c(37.6600366036405,37.6543604613483)
>>>              )
>>> 
>>> locs.ll <- SpatialPoints(locs.xy, proj4string=CRS("+proj=longlat
>>> +datum=WGS84") )
>>> 
>>> ## source the expressions near the bottom of this email to create
>>> ##    locs.ref
>>> ##    locs.step1.esri
>>> 
>>> ## use spTransform to go from WGS84 to the local system in one step:
>>> locs.26743 <- spTransform(locs.ll, CRS("+init=epsg:26743"))
>>> 
>>> ## not close enough:
>>> coordinates(locs.ref)-coordinates(locs.26743)
>>> ##      coords.x1 coords.x2
>>> ## [1,]  3.746539 -1.876668
>>> ## [2,]  3.746607 -1.876466
>>> 
>>> 
>>> ## spTransform equivalent of ESRI step 1
>>> locs.step1.proj4 <- spTransform(locs.ll, CRS("+init=epsg:2227"))
>>> 
>>> ## not close enough, essentially the same difference as above
>>> coordinates(locs.step1.esri)-coordinates(locs.step1.proj4)
>>> ##      coords.x1 coords.x2
>>> ## [1,]  3.746244 -1.877057
>>> ## [2,]  3.746315 -1.876856
>>> 
>>> 
>>> ## next, try the spTransform equivalent of ESRI step 1, but specifying the
>>> seven parameters
>>> ## note, had to reverse the sign of the rotation args from wkid 1515 in
>>> reference 1;
>>> ## evidently the PROJ.4 default is the "position vector" method (reference 
>>> 2)
>>> 
>>> crs.step1.cf <- CRS('+proj=lcc +lat_1=38.43333333333333
>>> +lat_2=37.06666666666667 +lat_0=36.5 +lon_0=-120.5\
>>>  +x_0=2000000.0 +y_0=500000.0 +ellps=GRS80 +datum=NAD83\
>>>  +units=us-ft +no_defs\
>>>  +towgs84=-0.991,1.9072,0.5129,0.025789908,0.0096501,0.0116599,0.0')
>>> 
>>> ## by the way, this alternative to specifying the CRS gives the same 
>>> result
>>> ##  crs.step1.cf <- CRS("+init=epsg:2227 +towgs84=-
>>> 0.991,1.9072,0.5129,0.025789908,0.0096501,0.0116599,0.0")
>>> 
>>> locs.step1.cf <- spTransform(locs.ll, crs.step1.cf)
>>> 
>>> ## good enough (hooray!)
>>> coordinates(locs.step1.esri)-coordinates(locs.step1.cf)
>>> ##          coords.x1     coords.x2
>>> ## [1,] -3.469177e-06 -5.122274e-08
>>> ## [2,] -3.418885e-06 -7.380731e-08
>>> 
>>> 
>>> 
>>> ## now try for step 2 using spTranform()
>>> locs.step2.cf <- spTransform(locs.step1.cf, CRS("+init=epsg:26743"))
>>> 
>>> ## the original difference is back!
>>> coordinates(locs.ref)-coordinates(locs.step2.cf)
>>> ##      coords.x1 coords.x2
>>> ## [1,]  3.746539 -1.876668
>>> ## [2,]  3.746608 -1.876466
>>> 
>>> ## the implication is that in doing the transformation to epsg 26743, it
>>> reversed the effect of the 7-parameter method
>>> 
>>> ## attempt to prevent that:
>>> 
>>> locs.tmp <- locs.step1.cf
>>> proj4string(locs.tmp) <- CRS("+init=epsg:2227")
>>> ## Warning message:
>>> ## In `proj4string<-`(`*tmp*`, value = <S4 object of class "CRS">) :
>>> ##   A new CRS was assigned to an object with an existing CRS:
>>> ## +proj=lcc +lat_1=38.43333333333333 +lat_2=37.06666666666667
>>> +lat_0=36.5 +lon_0=-120.5 +x_0=2000000.0 +y_0=500000.0 +ellps=GRS80
>>> +datum=NAD83 +units=us-ft +no_defs +towgs84=-
>>> 0.991,1.9072,0.5129,0.025789908,0.0096501,0.0116599,0.0
>>> ## without reprojecting.
>>> ## For reprojection, use function spTransform in package rgdal
>>> 
>>> locs.step2.cfb <- spTransform(locs.tmp, CRS("+init=epsg:26743"))
>>> 
>>> ## This actually works; the difference is now acceptably small
>>> coordinates(locs.ref)-coordinates(locs.step2.cfb)
>>> ##         coords.x1    coords.x2
>>> ## [1,] 0.0003266879 0.0006651825
>>> ## [2,] 0.0003261503 0.0006651356
>>> 
>>> 
>>> ## Another way, perhaps more appropriate (and with no warning message)
>>> is recreate the SpatialPoints
>>> ## object instead of modifying it:
>>> locs.tmp <- SpatialPoints(coordinates(locs.step1.cf),
>>> proj4string=CRS("+init=epsg:2227"))
>>> locs.step2.cfb <- spTransform(locs.tmp, CRS("+init=epsg:26743"))
>>> 
>>> coordinates(locs.ref)-coordinates(locs.step2.cfb)
>>> ##         coords.x1    coords.x2
>>> ## [1,] 0.0003266879 0.0006651825
>>> ## [2,] 0.0003261503 0.0006651356
>>> 
>>> 
>>> 
>>> This suggests to me that in PROJ.4 the specifications for the CRS are in 
>>> some
>>> way mixed in with the specifications for how the geographic transformation
>>> is performed. Apparently, one cannot specify the transformation method
>>> independent of the CRS specification. To put it another way, I have two 
>>> ways
>>> of converting from the original CRS to the first step's target CRS. The 
>>> target
>>> CRS is the same either way. But a second conversion to another CRS is
>>> affected by the method of the first one.
>>> 
>>> Have I interpreted correctly? If so, I guess it doesn't seem 
>>> appropriate-the
>>> conversion from one CRS to another should depend only on what the CRS is,
>>> not on how it got there.
>>> 
>>> Is there something I don't understand so that this kind of dependency is
>>> appropriate?
>>> 
>>> In the end, I guess I do have a solution, but I kind of don't like it. I 
>>> have to
>>> insert a "correction" to the CRS. Is there a better way?
>>> 
>>> 
>>> 
>>> 
>>> #####
>>> ### source the following to create objects used by the reproducible 
>>> example
>>> above
>>> #####
>>> 
>>> ## the two points converted from long/lat using the complete ESRI "two-
>>> step process"
>>> ## saved as a shapefile, loaded into R using readOGR(). Then just the
>>> coordinates
>>> ## were "dput"
>>> locs.ref <- new(
>>>               "SpatialPoints",
>>>               coords = structure(c(1703671.30566227, 1704020.20113366,
>>>                 424014.398045834, 421943.708664294), .Dim = c(2L, 2L),
>>>                 .Dimnames = list(NULL, c("coords.x1", "coords.x2")))
>>>               , bbox = structure(
>>>                   c(1703671.30566227, 421943.708664294,
>>>                     1704020.20113366, 424014.398045834),
>>>                   .Dim = c(2L, 2L),
>>>                   .Dimnames = list(c("coords.x1",  "coords.x2"), c("min", 
>>> "max")))
>>>               , proj4string =
>>>               new("CRS",
>>>                   projargs = "+proj=lcc +lat_1=37.06666666666667
>>> +lat_2=38.43333333333333 +lat_0=36.5 +lon_0=-120.5
>>> +x_0=609601.2192024384 +y_0=0 +datum=NAD27 +units=us-ft +no_defs
>>> +ellps=clrk66 +nadgrids=@conus, at alaska, at ntv2_0.gsb, at ntv1_can.dat"
>>>                   )
>>>               )
>>> 
>>> 
>>> ## the points converted to epsg 2227 using ESRI's step 1
>>> ## saved as a shapefile, loaded into R using readOGR
>>> ## Then just the coordinates were "dput"
>>> locs.step1.esri <- new(
>>>                      "SpatialPoints",
>>>                      coords = structure(c(6265039.1378244, 
>>> 6265388.04257557,
>>>                        2064418.92932968, 2062348.22239488), .Dim = c(2L, 
>>> 2L),
>>>                        .Dimnames = list(NULL, c("coords.x1", 
>>> "coords.x2")))
>>>                      , bbox = structure(
>>>                          c(6265039.1378244, 2062348.22239488,
>>>                            6265388.04257557, 2064418.92932968),
>>>                          .Dim = c(2L, 2L),
>>>                          .Dimnames = list(c("coords.x1", "coords.x2"), 
>>> c("min", "max")))
>>>                      , proj4string = new("CRS",
>>>                          projargs = "+proj=lcc +lat_1=37.06666666666667
>>> +lat_2=38.43333333333333 +lat_0=36.5 +lon_0=-120.5 +x_0=2000000
>>> +y_0=500000.0000000001 +datum=NAD83 +units=us-ft +no_defs
>>> +ellps=GRS80 +towgs84=0,0,0"
>>>                          )
>>>                      )
>>> 
>>> 
>>> #####
>>> ###package and session information
>>> #####
>>> 
>>> 
>>> Loading required package: sp
>>> Checking rgeos availability: TRUE
>>> 
>>> Loading required package: rgdal
>>> rgdal: version: 0.8-16, (SVN revision 498)
>>> Geospatial Data Abstraction Library extensions to R successfully loaded
>>> Loaded GDAL runtime: GDAL 1.11.0, released 2014/04/16
>>> Path to GDAL shared files:
>>> /Users/macqueen1/Library/R/3.1/library/rgdal/gdal
>>> Loaded PROJ.4 runtime: Rel. 4.8.0, 6 March 2012, [PJ_VERSION: 480]
>>> Path to PROJ.4 shared files:
>>> /Users/macqueen1/Library/R/3.1/library/rgdal/proj
>>> 
>>> 
>>>> sessionInfo()
>>> R version 3.1.1 (2014-07-10)
>>> Platform: x86_64-apple-darwin13.1.0 (64-bit)
>>> 
>>> locale:
>>> [1] C
>>> 
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>> 
>>> other attached packages:
>>> [1] sp_1.0-15       rgdal_0.8-16    maptools_0.8-30 xlsx_0.5.5
>>> [5] xlsxjars_0.6.0  rJava_0.9-6     rmacq_1.3-1
>>> 
>>> loaded via a namespace (and not attached):
>>> [1] foreign_0.8-61  grid_3.1.1      lattice_0.20-29 tools_3.1.1
>>> 
>>> ----
>>> two final comments:
>>> 
>>> I understand that this is really a PROJ.4 question, so I hope that 
>>> R-sig-geo
>>> folks don't mind too much; apologies in advance if so.
>>> 
>>> I hope my email software truly sends a plain text email like it claims. 
>>> But I'm
>>> not sure I trust it!
>>> 
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> 
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> 
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no

From r.hijmans at gmail.com  Sat Aug 30 23:37:30 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Sat, 30 Aug 2014 14:37:30 -0700
Subject: [R-sig-Geo] Issue saving ascii with writeRaster function
In-Reply-To: <53D1FE59.80000@gmail.com>
References: <53D1FE59.80000@gmail.com>
Message-ID: <CANtt_hzqDSo8TYA=W0p2xsAbzK-5YAM1aXu1eKX7XqGZU1OqvA@mail.gmail.com>

Damien,

The default setting is to write Real numbers, hence the
1.000000000000000 (which is needed to trick GDAL and ESRI to not
assume that the values are all integers when the first numbers have no
decimals).
If you want integers, you can do

writeRaster(r, filename = "test.asc", datatype='INT4S')

> cat(readLines("test.asc"), sep="\n")
NCOLS 2
NROWS 2
XLLCORNER -100
YLLCORNER -100
CELLSIZE 100
NODATA_value -9999
1 1
1 1

Best, Robert

On Thu, Jul 24, 2014 at 11:51 PM, Damien GEORGES
<damien.georges2 at gmail.com> wrote:
> Dear all,
>
> When I try to write a raster as .asc file on my HD using writeRaster
> function. When I check then the .asc file produce with a text editor, the
> first item on my raster is always stored under a strange format (e.g adding
> lot of decimals). That cause then some trouble in other software using this
> maps as input..
>
> Here a (reproducible example) :
>
> ##########
>
> library(raster)
>
> ## create raster
> r <- raster(ncols=2,nrows=2,xmn=-100,ymn=-100,xmx=100,ymx=100)
> r[] <- 1
> # plot(r)
>
> ## save the raster in acii format
> writeRaster(r, filename = "test.asc")
>
> ## check .asc file content
> cat(readLines("test.asc"), sep="\n")
>
> ## output :
> # NCOLS 2
> # NROWS 2
> # XLLCORNER -100
> # YLLCORNER -100
> # CELLSIZE 100
> # NODATA_value -9999
> # 1.000000000000000 1
> # 1 1
>
> ## The first value is 1.00000000000 and I want it to be 1
>
> ##########
>
> Does someone has already experiment this kind of issue?
> Any suggestion to prevent from it?
>
> Best,
> Damien.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From r.hijmans at gmail.com  Sun Aug 31 00:09:14 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Sat, 30 Aug 2014 15:09:14 -0700
Subject: [R-sig-Geo] raster to dataframe with xy=TRUE, na.rm=TRUE
In-Reply-To: <CAOckJBNF0RmLFy0jmsBV4BdNcMRBFJCSg-MzikQv-GhgoSRVhg@mail.gmail.com>
References: <CAOckJBO=uS5fL=G4akfsMtcQ4Npfx3qSYFH+C15fyfWuwPrHcg@mail.gmail.com>
	<CAAcyNCzG54=hiFhsi0GURfo1XnrnLKAzZNUwyBaJCuksW+2x-A@mail.gmail.com>
	<CAOckJBNF0RmLFy0jmsBV4BdNcMRBFJCSg-MzikQv-GhgoSRVhg@mail.gmail.com>
Message-ID: <CANtt_hzn3FOwK6-3z0a1heuOd5vT8U5Xtp=wP5-m=BqWEXn_SQ@mail.gmail.com>

Helen,
This is a bug, thanks for reporting it. I have fixed it in
(development) version 2.2-43
Robert

On Fri, Aug 29, 2014 at 8:22 AM, Helen Sofaer <helen at rams.colostate.edu> wrote:
> Thanks Pascal,
> That's helpful.
>
> I am curious about what happened in the second example, if anyone else
> takes a look.
> Cheers,
> Helen
>
>
> On Thu, Aug 28, 2014 at 11:17 PM, Pascal Oettli <kridox at ymail.com> wrote:
>
>> Hello,
>>
>> Did you try with the "rasterToPoints" function?
>>
>> Something like:
>>
>> r1.b.df <- as.data.frame(rasterToPoints(r1.b.mask))
>> coordinates(r1.b.df) <- ~x+y
>> plot(r1.b.df)
>>
>> Regards,
>> Pascal
>>
>> On Fri, Aug 29, 2014 at 1:52 PM, Helen Sofaer <helen at rams.colostate.edu>
>> wrote:
>> > Hi all,
>> >
>> > I?m trying to convert a RasterBrick to a dataframe while adding the
>> > coordinates and while dropping cells that were masked to NA. This
>> > combination of options gives me an error when the mask is done with an sp
>> > object.
>> >
>> >
>> >
>> > Some reproducible code:
>> >
>> >
>> >
>> > usa = getData('GADM', country = 'USA', level = 0)
>> >
>> >
>> >
>> > r1 = raster()
>> >
>> > values(r1) = 1:ncell(r1)
>> >
>> > r1.b = brick(r1, r1, r1, r1)
>> >
>> > r1.b.mask = mask(r1.b, usa)
>> >
>> > plot(r1.b.mask)
>> >
>> > r1.b.df = as.data.frame(r1.b.mask, xy = TRUE, na.rm = TRUE)
>> >
>> >
>> >
>> > The error is:
>> >
>> > Error in data.frame(..., check.names = FALSE) :
>> >
>> >   arguments imply differing number of rows: 64800, 1109
>> >
>> >
>> >
>> > Looks like it wants to combine all the coordinates with just the subset
>> of
>> > the data.
>> >
>> >
>> >
>> > I surprised myself further by looking at what happens if the NAs are in
>> > random locations, rather than masked out:
>> >
>> >
>> >
>> > # random NAs:
>> >
>> > r2 = raster()
>> >
>> > vals = 1:ncell(r2)
>> >
>> > vals[sample(1:ncell(r2), .5*ncell(r2))] = NA
>> >
>> > values(r2) = vals
>> >
>> > plot(r2)
>> >
>> > r2.b = brick(r2, r2, r2, r2)
>> >
>> > r2.b.df = as.data.frame(r2.b, xy = TRUE, na.rm = TRUE)
>> >
>> > str(r2.b.df) # 64800 obs; same as ncell in each layer; further inspection
>> > shows all locations are there and some values are repeated
>> >
>> >
>> >
>> > Any advice/interpretation is appreciated. In practice I have already
>> > cropped but still have a lot of NAs within my extent. Of course, I can
>> drop
>> > the rows afterwards, but thought I?d ask. Also, I see the same thing if
>> > it?s a single layer, rather than a brick.
>> >
>> >
>> >
>> > FYI, I?m running 3.1.1 and raster version 2.2-31 and a Mavericks OSX
>> (and I
>> > also tried it on a Fedora linux machine running 3.1.0 to make sure it
>> > wasn?t a Mavericks thing).
>> >
>> >
>> >
>> > Thanks for your time!
>> >
>> > Helen
>> >
>> > --
>> > Helen Sofaer
>> > Postdoctoral Fellow
>> > Fish Wildlife and Conservation Biology
>> > Colorado State University
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-Geo mailing list
>> > R-sig-Geo at r-project.org
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
>>
>> --
>> Pascal Oettli
>> Project Scientist
>> JAMSTEC
>> Yokohama, Japan
>>
>
>
>
> --
> Helen Sofaer
> Postdoctoral Fellow
> Fish Wildlife and Conservation Biology
> Colorado State University
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From r.hijmans at gmail.com  Sun Aug 31 00:24:56 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Sat, 30 Aug 2014 15:24:56 -0700
Subject: [R-sig-Geo] distance between raster cell centroids and spatial
	points
In-Reply-To: <CADr8yXCUN4ezhyRt_NUCUokEJYNFwu-CpEgoQNOBQrmJOYi0gg@mail.gmail.com>
References: <CADr8yXCUN4ezhyRt_NUCUokEJYNFwu-CpEgoQNOBQrmJOYi0gg@mail.gmail.com>
Message-ID: <CANtt_hxYrji6zM9uEzxHkiyzW-JVqoLTK-5gchn14zuMDg1mbA@mail.gmail.com>

Gabriele,
I think you can do:

library(raster)
x <- distanceFromPoints(ras, villages)

Robert

On Mon, Jul 28, 2014 at 6:56 AM, Gabriele Cozzi <gab.cozzi at gmail.com> wrote:
> Dear list,
>
> I want to calculate the distance between the centroid of each cell in a
> raster ?ras? and the closest village (villages are stored as
> SpatialPointsDataFrame).
>
> ras is as follow:
>      class       : RasterLayer
>      dimensions  : 5027, 3386, 17021422  (nrow, ncol, ncell)
>      resolution  : 27.28532, 27.28532  (x, y)
>
>
> I can obtain what I want with a sub-sample of ras that has less cells, and
> here are my codes:
>
> *# sub sample ras*
> *sub_ras <- aggregate(ras, fact=20, fun=mean)*
>      class       : RasterLayer
>      dimensions  : 252, 170, 42840  (nrow, ncol, ncell)
>      resolution  : 545.7063, 545.7063  (x, y)
>
> *# extract x and y coord from each cell of the raster*
> *centroid <- xyFromCell(sub_ras, c(1:ncell(sub_ras)))  *
>
> *# combine x and y into a spatial point object*
> *centroid <- SpatialPoints(cbind(centroid[,1], centroid[,2]))*
>
> *# calculate distance of each centroid to the closest village and then turn
> it into a raster of *
> *# extent ?sub_ras' and values 'dist'*
> *dist <- nncross(as(centroid,"ppp"), as(villages, "ppp"))$dist  *
>
> *rasterdist2village <- rasterize(centroid, sub_ras, dist)*
> *plot(rasterdist2village)*
>
>
> I then tried to run the same codes using all cells of ras. After 15 minutes
> the ?rasterize? function was still running and so I aborted the procedure.
>
> I wonder whether there is a more elegant and computationally faster way of
> doing what explained above?
>
> Any input is highly appreciated
>
> Best,
> Gabriele
>
>
>
>
>
>
> --
> Gabriele Cozzi
> Postdoctoral Research Associate
> Population Ecology Research Group
> http://www.popecol.org
>
> Zurich University
> Institute of Evolutionary Biology and Environmental Studies
> Winterthurerstr. 190
> 8057 Zurich - Switzerland
> E-mail: gabriele.cozzi at uzh.ch
> Phone: +41(0)44 635 49 12
> Fax: +41(0)16355711
> http://www.ieu.uzh.ch
>
>         [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From r.hijmans at gmail.com  Sun Aug 31 00:31:55 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Sat, 30 Aug 2014 15:31:55 -0700
Subject: [R-sig-Geo] Unexpected behavior of raster "mask" function
In-Reply-To: <CACwzsXHyCH09+qsPdre8NmNxE3BjehOcyuOmkAhKPn7UpAgA1w@mail.gmail.com>
References: <CACwzsXHyCH09+qsPdre8NmNxE3BjehOcyuOmkAhKPn7UpAgA1w@mail.gmail.com>
Message-ID: <CANtt_hwx2gFhfa8k9Sp96mVB4JHaaOhiyqaMjtvEM5XdS1+5cg@mail.gmail.com>

Alex,
Thanks for the clear example. I had not considered that case.
I have added an argument 'updateNA' to the mask function (version
2.2-43) such that you can do:

masked_image <- mask(img, msk, updatevalue=2, updateNA=TRUE)

That is, if updateNA is TRUE, NA cells outside the mask are also updated.

Robert


On Fri, Jul 18, 2014 at 11:18 AM, Alex Zvoleff
<azvoleff at conservation.org> wrote:
> I am using the mask function in the raster package (2.2-38) to mask out
> areas within an image that are outside an area of interest (AOI). There are
> NAs within this AOI that are meaningful - after masking the image I am
> using freq to tabulate these NAs along with the other values in my AOI. For
> this reason, I am using the "updatevalue" option in the mask function to
> recode all areas outside of my AOI to a value (say 99) so that I can ignore
> these areas in subsequent analysis, without having ignored areas share a
> value (NA) with areas inside my AOI.
>
> However, the mask function does not operate as I expected - areas in the
> image that should be masked but that are NA prior to masking are not set to
> "updatevalue". Is there an way to tell the mask function to recode all
> areas (regardless of their initial value) to updatevalue? The below example
> shows my problem:
>
> library(raster)
> # Setup an image with two NA values. Make one NA value inside
> # the AOI, and make the other outside the AOI
> img <- matrix(1, nrow=5, ncol=5)
> img[3, 2] <- NA # Inside AOI
> img[1, 2] <- NA # Outside AOI
> img <- raster(img)
> plot(img)
>
> # Setup a mask where only the 3x3 region in the center of img is retained
> msk <- matrix(1, nrow=5, ncol=5)
> msk[1,] <- NA
> msk[5,] <- NA
> msk[,1] <- NA
> msk[,5] <- NA
> msk <- raster(msk)
> plot(msk)
>
> # Apply mask
> masked_image <- mask(img, msk, updatevalue=2)
>
> # Notice that cell (1, 2) of masked_image is NA, instead of the updatevalue
> (2).
> # This cell was not affected by the mask because it was NA prior to calling
> mask.
> # Is there a way to tell the mask function to set all masked areas to
> updatevalue,
> # regardless of whether a cell is NA prior to masking?
> plot(masked_image)
>
> Thanks,
> Alex
>
> --
> Alex Zvoleff
> Postdoctoral Associate
> Tropical Ecology Assessment and Monitoring (TEAM) Network
> Conservation International
> 2011 Crystal Dr. Suite 500, Arlington, Virginia 22202, USA
> Tel: +1-703-341-2749, Fax: +1-703-979-0953, Skype: azvoleff
> http://www.teamnetwork.org | http://www.conservation.org
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From r.hijmans at gmail.com  Sun Aug 31 00:36:35 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Sat, 30 Aug 2014 15:36:35 -0700
Subject: [R-sig-Geo] Verify units of distance between coordinates
In-Reply-To: <alpine.LRH.2.03.1408281701520.4825@reclus.nhh.no>
References: <0D665D1E-F2F9-4846-B424-6F97FCA93A6B@gmail.com>
	<CAM_vjukf3+f2r3ui2nvQxpa6mWzYf0i8QnkeSUyAcL-ArvbxAQ@mail.gmail.com>
	<CAAcGz9_bOSzLT1jyNdW_M=UeM+BSRDoaxrC8VLrDUu9rfcksKQ@mail.gmail.com>
	<CAM_vjunE_fjiFc7qOW3y4ciCn+QODHRo_FbFde4auCVyWW0zVw@mail.gmail.com>
	<alpine.LRH.2.03.1408281632570.4825@reclus.nhh.no>
	<alpine.LRH.2.03.1408281701520.4825@reclus.nhh.no>
Message-ID: <CANtt_hx+=ycYzt2NFhZai8Y01z26rOhPXqciaOS9GAU+tN51KQ@mail.gmail.com>

library(geosphere)

d <- distCosine(df[, 1:2], df[,3:4])



On Thu, Aug 28, 2014 at 8:02 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> On Thu, 28 Aug 2014, Roger Bivand wrote:
>
>> On Thu, 28 Aug 2014, Sarah Goslee wrote:
>>
>>> On Thu, Aug 28, 2014 at 9:32 AM, Michael Sumner <mdsumner at gmail.com>
>>> wrote:
>>>>
>>>> On Thu, Aug 28, 2014 at 10:50 PM, Sarah Goslee <sarah.goslee at gmail.com>
>>>> wrote:
>>>>>
>>>>> They don't make sense.
>>>>>
>>>>> Best: convert them into a projection where the distances are in meters
>>>>> already, like UTM. Then distances calculated on your new coordinates
>>>>> are in meters.
>>>>
>>>>
>>>> However great circle from lat/lon is arguably the best since you can
>>>> really do get distance along a great circle (on the ellipsoid or the
>>>> sphere). (There are several algorithms, and also other methods for
>>>> e.g. loxodromes, and even other definitions of "straight".)
>>>>
>>>> No projection has the property that any straight line is a great
>>>> circle, and most certainly *not* any of UTM family.
>>>
>>>
>>> True, but as long as your points are reasonably close together,
>>> something like UTM is a very useful approximation. And even great
>>> circle is an approximation. The best answer depends on the data and
>>> the objectives (as always!).
>>
>>
>> The OP didn't say how the distances were computed:
>>
>> library(sp)
>> locs <- SpatialPoints(cbind(Lon = c(29.6000, 29.7333, 30.3887, 30.6667,
>> 30.6833, 30.8667), Lat = c(-4.9000, -4.6000, -5.1280, -1.0667, -2.7500,
>> -3.3833)), proj4string=CRS("+proj=longlat +datum=WGS84") )
>> src <- SpatialPoints(cbind(LonWater = c(29.63333, 29.63333, 30.25000,
>> 30.65000, 30.35444, 30.83278), LatWater = c(-4.31667, -4.31667, -4.76667,
>> -1.35000, -2.46667, -3.57000)),
>> proj4string=CRS("+proj=longlat +datum=WGS84"))
>>
>> plot(locs)
>> plot(src, add=TRUE, col="red")
>>
>> Naively using spDistsN1 appears to replicate the distances the OP got:
>>
>> D0 <- lapply(1:length(locs), function(i) spDistsN1(src, locs[i],
>> longlat=FALSE))
>>
>> which is wrong.
>>
>> D0 <- lapply(1:length(locs), function(i) spDistsN1(src, locs[i],
>> longlat=TRUE))
>
>
> Sorry:
>
>
> D <- lapply(1:length(locs), function(i) spDistsN1(src, locs[i],
>  longlat=TRUE))
>
> of course.
>
>
>>
>> is in km, but the minimum criterion is met by multiple pairs of points:
>>
>> D1 <- lapply(D, function(x) x-min(x))
>> D1
>>
>> so finding out which source is closest still isn't well-defined. To get
>> minimum distances by location:
>>
>> D2 <- sapply(D, min)
>>
>> The spDists* functions use GC distances on a WGS84 ellipsoid, so are
>> closer than a spheroid (many online shortcuts use spheroids), and will be OK
>> if the input coordinates are also WGS84.
>>
>> Hope this helps,
>>
>> Roger
>>
>>>
>>>> Cheers, Mike.
>>>>
>>>>
>>>>>
>>>>> Latitude and longitude don't translate neatly into distances on their
>>>>> own.
>>>>>
>>>>> Second best: find and use a great circle distance function that can
>>>>> determine the correct distances for where those lat/lon coordinates
>>>>> are on the earth's surface. There's been discussion on this list
>>>>> before about calculating distances from geographic coordinates; google
>>>>> should find them.
>>>>>
>>>>> Sarah
>>>>>
>>>>> On Thu, Aug 28, 2014 at 8:44 AM, Justin Michell <jwm302 at gmail.com>
>>>>> wrote:
>>>>>>
>>>>>> Dear geo R group
>>>>>>
>>>>>> I have a data frame like this:
>>>>>>
>>>>>> df <- data.frame(Lon =
>>>>>> c(29.6000,29.7333,30.3887,30.6667,30.6833,30.8667), Lat =
>>>>>> c(-4.9000,-4.6000,-5.1280,-1.0667,-2.7500,-3.3833),
>>>>>>                   LonWater =
>>>>>> c(29.63333,29.63333,30.25000,30.65000,30.35444,30.83278), LatWater =
>>>>>> c(-4.31667,-4.31667,-4.76667,-1.35000,-2.46667,-3.57000), DstClW =
>>>>>> c(0.5842815,0.3004491,0.3870362,0.2837918,0.4340793,0.1897561) )
>>>>>>
>>>>>> At these locations (Lon, Lat pairs) I calculated the shortest distance
>>>>>> to a water source (DstClW) and where that source is (LonWater, LatWater).
>>>>>>
>>>>>> I want to now determine what units DstClW is in, and also verify that
>>>>>> these distances make sense and were calculated correctly.
>>>>>>
>>>>>> Any suggestions as to how this might be done?
>>>>>>
>>>>>> Regards
>>>>>> Justin Michell
>>>>>>
>>>>>>
>>>
>>>
>>>
>>
>>
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From r.hijmans at gmail.com  Sun Aug 31 00:46:00 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Sat, 30 Aug 2014 15:46:00 -0700
Subject: [R-sig-Geo] Raster Layers same resolution but not the same
 coordinates over the same area
In-Reply-To: <A618DF42-6AAF-48F6-B886-94B33A64517E@gmail.com>
References: <FEFE7375-7C62-47E7-B906-BB257581C587@gmail.com>
	<csym1f9skc7sbexltddb6dc3.1403877499889@email.android.com>
	<4A71BF68-2BC3-48FC-B988-80CB966F46FF@gmail.com>
	<CABG0rfvymz-7HXdcPS3DvXzQ9eDuojP-sDWZqxP6+5iuiJ46zQ@mail.gmail.com>
	<5B0127DE-CE8B-4E9D-B9D2-238B92178A79@gmail.com>
	<A618DF42-6AAF-48F6-B886-94B33A64517E@gmail.com>
Message-ID: <CANtt_hzbGJgPHZTgs01gzSi_FxpLae=_2xg1c9xbkEJ6jRz3ow@mail.gmail.com>

Justin,

The RasterStack approach is fine, but as you show, the layers do not
match. The resolution of NDVIStack is larger than the resolution of
rainStack; it seems that you did not resample the NDVI data correctly.

Robert



On Sat, Aug 30, 2014 at 4:31 AM, Justin Michell <jwm302 at gmail.com> wrote:
> My apologies, I forgot to send as plain text.
>
> On Aug 30, 2014, at 1:27 PM, Justin Michell <jwm302 at gmail.com> wrote:
>
>> Hi Jonathan
>>
>> I tried that.. But I am but the results don?t make sense:
>>
>>> head(NDVIStackDf)
>>         x         y     NDVI1     NDVI2    NDVI3     NDVI4    NDVI5     NDVI6     NDVI7     NDVI8     NDVI9    NDVI10    NDVI11    NDVI12
>> 1 29.42809 -1.002081 0.7196462 0.6093929 0.614475 0.7851786 0.799475 0.7241929 0.5946000 0.5948500 0.6585143 0.7874357 0.8305786 0.7774929
>> 2 29.43662 -1.002081 0.7103154 0.5823500 0.572225 0.7867429 0.794050 0.7445643 0.6033786 0.5635429 0.6421857 0.7802786 0.8300643 0.7886786
>> 3 29.44514 -1.002081 0.7303692 0.6254571 0.599350 0.7771143 0.785850 0.7510071 0.6404571 0.6197286 0.6770929 0.7686786 0.8169571 0.7957786
>> 4 29.45367 -1.002081 0.7641923 0.6890714 0.657850 0.7936786 0.809975 0.7805429 0.6769643 0.6590714 0.7165357 0.7843357 0.8283286 0.8231500
>> 5 29.46220 -1.002081 0.8057769 0.7500714 0.718175 0.8208786 0.838575 0.8126500 0.7345786 0.7359571 0.7661214 0.8087214 0.8442643 0.8380071
>> 6 29.47073 -1.002081 0.8065615 0.7627071 0.730550 0.8142214 0.841100 0.8252000 0.7574786 0.7425071 0.7590571 0.8025071 0.8518357 0.8430286
>>> head(rainStackDf)
>>         x         y rain1 rain2 rain3 rain4 rain5 rain6 rain7 rain8 rain9 rain10 rain11 rain12
>> 1 29.42917 -1.004167    66    68    85   116   105    61    40    85   110    125    118     85
>> 2 29.43750 -1.004167    66    69    85   117   106    61    40    85   110    125    119     86
>> 3 29.44583 -1.004167    66    68    84   116   106    60    39    84   110    124    118     85
>> 4 29.45417 -1.004167    65    67    83   116   105    60    39    83   108    123    117     84
>> 5 29.46250 -1.004167    65    68    83   117   106    59    38    83   109    124    118     84
>> 6 29.47083 -1.004167    66    68    84   118   107    59    38    83   110    125    119     85
>>> mystackDf <- stack(NDVIStackDf, rainStackDf)
>>>
>>> head(mystackDf)
>>    values ind
>> 1 29.42809   x
>> 2 29.43662   x
>> 3 29.44514   x
>> 4 29.45367   x
>> 5 29.46220   x
>> 6 29.47073   x
>>
>> Is there a better way maybe without using data frames?
>>
>> I tried stacking the stacks too:
>>
>>> s1 <- stack(NDVIStack, rainStack)
>> Error in compareRaster(x) : different number or columns
>>> rainStack
>> class       : RasterStack
>> dimensions  : 1287, 1321, 1700127, 12  (nrow, ncol, ncell, nlayers)
>> resolution  : 0.008333333, 0.008333333  (x, y)
>> extent      : 29.425, 40.43333, -11.725, -1  (xmin, xmax, ymin, ymax)
>> coord. ref. : +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0
>> names       : rain1, rain2, rain3, rain4, rain5, rain6, rain7, rain8, rain9, rain10, rain11, rain12
>> min values  :     7,     5,    31,    13,     0,     0,     0,     0,     0,      0,     22,     32
>> max values  :   391,   392,   563,   746,   473,   159,   109,   106,   164,    247,    349,    464
>>
>>> NDVIStack
>> class       : RasterStack
>> dimensions  : 1258, 1291, 1624078, 12  (nrow, ncol, ncell, nlayers)
>> resolution  : 0.008526982, 0.008525437  (x, y)
>> extent      : 29.425, 40.43333, -11.725, -1  (xmin, xmax, ymin, ymax)
>> coord. ref. : +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0
>> names       :      NDVI1,      NDVI2,      NDVI3,      NDVI4,      NDVI5,      NDVI6,      NDVI7,      NDVI8,      NDVI9,     NDVI10,     NDVI11,     NDVI12
>> min values  : -0.1524615, -0.1353071, -0.1970500, -0.1632071, -0.1919250, -0.1647286, -0.1665000, -0.1693357, -0.1852643, -0.1733714, -0.1555357, -0.1682571
>> max values  :  0.9153615,  0.9013000,  0.9295500,  0.9134643,  0.9421750,  0.9158357,  0.9000071,  0.9009786,  0.8733571,  0.8792429,  0.9151357,  0.9233000
>>
>> Thanks
>> Justin
>>
>> On Jun 30, 2014, at 5:55 PM, Jonathan Greenberg <jgrn at illinois.edu> wrote:
>>
>>> Justin:
>>>
>>> It would make more sense, if you insist on working with data.frames,
>>> for you to create a single stack with all of your predictor and
>>> response variables, and then do your extraction -- that way you don't
>>> need to worry about a merge after the fact.  The chances of the
>>> coordinates being EXACT I suspect are very low, which is why the
>>> merge() is failing.
>>>
>>> Basically:
>>>
>>> mystack <- stack(meanTempStackDf, rainStackDf)
>>>
>>> ... Then you can extract the data.
>>>
>>> --j
>>>
>>> On Mon, Jun 30, 2014 at 6:22 AM, Justin Michell <jwm302 at gmail.com> wrote:
>>>> Dear Niandou
>>>>
>>>> No I have not received any feedback.
>>>>
>>>> I do have some thoughts though. Is it possible/or at least would it make sense to get values in NDVI layer (average of nearby cells?) at the coordinates of raster values in other layers which one wants to merge with?
>>>>
>>>> I am not very well versed in these things so it?s just a thought- not sure how it would be implemented in R.
>>>>
>>>> Regards
>>>> Justin
>>>>
>>>>
>>>> On Jun 27, 2014, at 3:58 PM, ISSAKA NIANDOU, Yacouba <niandouy at who.int> wrote:
>>>>
>>>>> Niandou
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at r-project.org
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>
>>>
>>> --
>>> Jonathan A. Greenberg, PhD
>>> Assistant Professor
>>> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
>>> Department of Geography and Geographic Information Science
>>> University of Illinois at Urbana-Champaign
>>> 259 Computing Applications Building, MC-150
>>> 605 East Springfield Avenue
>>> Champaign, IL  61820-6371
>>> Phone: 217-300-1924
>>> http://www.geog.illinois.edu/~jgrn/
>>> AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007
>>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From r.hijmans at gmail.com  Sun Aug 31 00:47:43 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Sat, 30 Aug 2014 15:47:43 -0700
Subject: [R-sig-Geo] raster brick error cells are not equally spaced
In-Reply-To: <2F09C501769D914983129DD4812457203623B3FCBA@FWC-TLEX10.fwc.state.fl.us>
References: <2F09C501769D914983129DD4812457203623AA424F@FWC-TLEX10.fwc.state.fl.us>
	<CAAcGz9_N4LSMxTRrAmRZwGzWNwHiegmx49k0rQ4s3f+s0cHE=w@mail.gmail.com>
	<2F09C501769D914983129DD4812457203623AA456F@FWC-TLEX10.fwc.state.fl.us>
	<CAAcGz98LAkOQSX78b2JpiaJjaP_i7nBb=sBjwmeVff5gS8eA_w@mail.gmail.com>
	<2F09C501769D914983129DD4812457203623B3FCBA@FWC-TLEX10.fwc.state.fl.us>
Message-ID: <CANtt_hyTds3M9XU2Dk13gyoJJLEFTeoo7tD6a2nEfy_cJSK77Q@mail.gmail.com>

Dave,
The "code now works on both machines". Perhaps it works, but the
results are probably incorrect.
There always a check for non-regularly spaced values, but some cases
slipped through. This has now been fixed.
Robert

On Tue, Aug 19, 2014 at 12:42 PM, Chagaris, Dave
<Dave.Chagaris at myfwc.com> wrote:
> Thanks Mike.  That appears to be the problem.  I was able to install all the libraries from my laptop onto the workstation and the code now works on both machines (with older version of raster).
>
> Dave
>
> -----Original Message-----
> From: Michael Sumner [mailto:mdsumner at gmail.com]
> Sent: Thursday, August 14, 2014 10:19 AM
> To: Chagaris, Dave
> Subject: Re: [R-sig-Geo] raster brick error cells are not equally spaced
>
> On Thu, Aug 14, 2014 at 11:58 PM, Chagaris, Dave <Dave.Chagaris at myfwc.com> wrote:
>> [deleted].  Any reason why it would work on one computer and not on the other?  Is it possible I don't have all the required packages (or wrong versions) on the workstation?
>>
>
> Only if you had a more recent version of raster on one computer that predated checks for these irregular axes.
>
> (Please use the list in public).
>
> Cheers, Mike.
>
>>
>>
>> -----Original Message-----
>> From: Michael Sumner [mailto:mdsumner at gmail.com]
>> Sent: Wednesday, August 13, 2014 8:59 PM
>> To: Chagaris, Dave
>> Cc: r-sig-geo at r-project.org
>> Subject: Re: [R-sig-Geo] raster brick error cells are not equally
>> spaced
>>
>> Hello, can you point to or share one of the files? Sometimes these things are just a regular grid under the hood but that has been forgotten in favour of longitude/latitude arrays.
>>
>> If that's the case you can reconstruct the original grid and all is well, there's not really any precedent for this but I have a lot of examples that work well.  (Also sometimes there's only a small amount of numeric fuzz that you can ignore).
>>
>> The raster types cannot take grids that have irregular (rectilinear or
>> curvilinear) coordinates. There's no way around this except some combination of these:
>>
>> - read the data in the raw using ncdf/ncdf4 or RNetCDF and use base
>> graphics with image() (which can deal with rectilinear grids), or
>> points() or maybe polygons (which with care can  deal with curvilinear grids).
>> - use the hidden argument "stopIfNotEqualSpaced=FALSE" to raster() to
>> get the data out and deal with the arrays as "index-only" grids
>>
>>
>> Cheers, Mike.
>>
>>
>>
>> On Thu, Aug 14, 2014 at 2:26 AM, Chagaris, Dave <Dave.Chagaris at myfwc.com> wrote:
>>> I am trying to read netcdf files into R using the brick function.  I have many netcdf files and want to process them on a 64bit workstation instead my 32bit laptop.  The code    I'm using works fine on my 32 bit laptop, but on the workstation I get an error "Error in .rasterObjectFromCDF(x, type = objecttype, band = band, ...) :
>>>   cells are not equally spaced; you should extract values as points".
>>>
>>> Any  help is appreciated.
>>>
>>> On Laptop...
>>>> library(raster)
>>>
>>>> library(ncdf)
>>>
>>>> windows(record=T)
>>>
>>>> sessionInfo()
>>> R version 2.15.0 (2012-03-30)
>>> Platform: i386-pc-mingw32/i386 (32-bit)
>>>
>>> locale:
>>> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252    LC_MONETARY=English_United States.1252 LC_NUMERIC=C
>>> [5] LC_TIME=English_United States.1252
>>>
>>> attached base packages:
>>> [1] grDevices datasets  splines   graphics  stats     tcltk     utils     methods   base
>>>
>>> other attached packages:
>>> [1] ncdf_1.6.6       raster_2.0-41    sp_1.0-11        svSocket_0.9-53  TinnR_1.0-5      R2HTML_2.2       Hmisc_3.9-3      survival_2.36-12
>>>
>>> loaded via a namespace (and not attached):
>>> [1] cluster_1.14.2 grid_2.15.0    lattice_0.20-6 svMisc_0.9-65  tools_2.15.0
>>>
>>>> i = "expt_31.0_20130226.nc"
>>>
>>>> open.ncdf(paste(getwd(),i,sep='/'))
>>> [1] "file C:/dave.chagaris/HYCOM/expt_31.0_20130226.nc has 4 dimensions:"
>>> [1] "MT   Size: 1"
>>> [1] "Depth   Size: 40"
>>> [1] "Latitude   Size: 213"
>>> [1] "Longitude   Size: 290"
>>> [1] "------------------------"
>>> [1] "file C:/dave.chagaris/HYCOM/expt_31.0_20130226.nc has 8 variables:"
>>> [1] "float ssh[Longitude,Latitude,MT]  Longname: sea surf. height  [31.0H] Missval:1.26765060022823e+30"
>>> [1] "float u[Longitude,Latitude,Depth,MT]  Longname: u-veloc. [31.0H] Missval:1.26765060022823e+30"
>>> [1] "float v[Longitude,Latitude,Depth,MT]  Longname: v-veloc. [31.0H] Missval:1.26765060022823e+30"
>>> [1] "float w_velocity[Longitude,Latitude,Depth,MT]  Longname: w-veloc. [31.0H] Missval:1.26765060022823e+30"
>>> [1] "float temperature[Longitude,Latitude,Depth,MT]  Longname:  temp [31.0H] Missval:1.26765060022823e+30"
>>> [1] "float salinity[Longitude,Latitude,Depth,MT]  Longname: salinity [31.0H] Missval:1.26765060022823e+30"
>>> [1] "float mld[Longitude,Latitude,MT]  Longname: MLT (0.20 degC)   [31.0H] Missval:1.26765060022823e+30"
>>> [1] "float mlp[Longitude,Latitude,MT]  Longname: MLT (0.03 kg/m3)  [31.0H] Missval:1.26765060022823e+30"
>>>
>>>> salt =
>>>> brick(paste(getwd(),i,sep='/'),varname='salinity',lvar=4,level=2)
>>> Warning messages:
>>> 1: In rm(.SavedPlots) : object '.SavedPlots' not found
>>> 2: In .rasterObjectFromCDF(x, type = objecttype, band = band, ...) :
>>>   level set to: 1
>>>
>>> on workstation...
>>>
>>>> setwd('E:\\work\\data\\HYCOM')
>>>
>>>> .libPaths('C:\\Users\\dave.chagaris\\Documents\\R\\win-library\\3.1'
>>>> )
>>>
>>>> library(raster)
>>>
>>>> library(ncdf)
>>>
>>>> sessionInfo()
>>>
>>> R version 2.15.1 (2012-06-22)
>>>
>>> Platform: x86_64-pc-mingw32/x64 (64-bit)
>>>
>>>
>>>
>>> locale:
>>>
>>> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
>>> States.1252
>>>
>>> [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
>>>
>>> [5] LC_TIME=English_United States.1252
>>>
>>>
>>>
>>> attached base packages:
>>>
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>>
>>>
>>> other attached packages:
>>>
>>> [1] ncdf_1.6.6    raster_2.2-31 sp_1.0-15
>>>
>>>
>>>
>>> loaded via a namespace (and not attached):
>>>
>>> [1] grid_2.15.1    lattice_0.20-6 tools_2.15.1
>>>
>>>> i = "expt_31.0_20130226.nc"
>>>
>>>> open.ncdf(paste(getwd(),i,sep='/'))
>>>
>>> [1] "file E:/work/data/HYCOM/expt_31.0_20130226.nc has 4 dimensions:"
>>>
>>> [1] "MT   Size: 1"
>>>
>>> [1] "Depth   Size: 40"
>>>
>>> [1] "Latitude   Size: 213"
>>>
>>> [1] "Longitude   Size: 290"
>>>
>>> [1] "------------------------"
>>>
>>> [1] "file E:/work/data/HYCOM/expt_31.0_20130226.nc has 8 variables:"
>>>
>>> [1] "float ssh[Longitude,Latitude,MT]  Longname: sea surf. height  [31.0H] Missval:1.26765060022823e+30"
>>>
>>> [1] "float u[Longitude,Latitude,Depth,MT]  Longname: u-veloc. [31.0H] Missval:1.26765060022823e+30"
>>>
>>> [1] "float v[Longitude,Latitude,Depth,MT]  Longname: v-veloc. [31.0H] Missval:1.26765060022823e+30"
>>>
>>> [1] "float w_velocity[Longitude,Latitude,Depth,MT]  Longname: w-veloc. [31.0H] Missval:1.26765060022823e+30"
>>>
>>> [1] "float temperature[Longitude,Latitude,Depth,MT]  Longname:  temp [31.0H] Missval:1.26765060022823e+30"
>>>
>>> [1] "float salinity[Longitude,Latitude,Depth,MT]  Longname: salinity [31.0H] Missval:1.26765060022823e+30"
>>>
>>> [1] "float mld[Longitude,Latitude,MT]  Longname: MLT (0.20 degC)   [31.0H] Missval:1.26765060022823e+30"
>>>
>>> [1] "float mlp[Longitude,Latitude,MT]  Longname: MLT (0.03 kg/m3)  [31.0H] Missval:1.26765060022823e+30"
>>>
>>>> salt =
>>>> brick(paste(getwd(),i,sep='/'),varname='salinity',lvar=4,level=2)
>>>
>>> Error in .rasterObjectFromCDF(x, type = objecttype, band = band, ...) :
>>>
>>>   cells are not equally spaced; you should extract values as points
>>>
>>> In addition: Warning message:
>>>
>>> In .rasterObjectFromCDF(x, type = objecttype, band = band, ...) :
>>>
>>>   level set to: 1
>>>
>>>
>>>
>>> David Chagaris, PhD
>>> Associate Research Scientist
>>> Florida Fish and Wildlife Conservation Commission Fish and Wildlife
>>> Research Institute
>>> 100 8th Ave SE
>>> St. Petersburg, FL  33701
>>> 727-502-4959
>>> fax: 727-893-1374
>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
>>
>> --
>> Michael Sumner
>> Software and Database Engineer
>> Australian Antarctic Division
>> Hobart, Australia
>> e-mail: mdsumner at gmail.com
>
>
>
> --
> Michael Sumner
> Software and Database Engineer
> Australian Antarctic Division
> Hobart, Australia
> e-mail: mdsumner at gmail.com
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From acocac at gmail.com  Sun Aug 31 04:39:57 2014
From: acocac at gmail.com (acocac)
Date: Sat, 30 Aug 2014 19:39:57 -0700 (PDT)
Subject: [R-sig-Geo] plotting raster returns error about NA
In-Reply-To: <1406691584510-7586834.post@n2.nabble.com>
References: <1406691584510-7586834.post@n2.nabble.com>
Message-ID: <1409452797843-7587036.post@n2.nabble.com>

Hi,

Did you solve this problem, how large is your raster file?

Alejandro



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/plotting-raster-returns-error-about-NA-tp7586834p7587036.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From r.hijmans at gmail.com  Sun Aug 31 06:43:10 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Sat, 30 Aug 2014 21:43:10 -0700
Subject: [R-sig-Geo] image(rs) returns error after reclassify
In-Reply-To: <1405666656295-7586757.post@n2.nabble.com>
References: <1405666561008-7586756.post@n2.nabble.com>
	<1405666656295-7586757.post@n2.nabble.com>
Message-ID: <CANtt_hx=rQ4fiRA6DEDU2Qnh4+Qxj-cWNqqPJWmK1+gfEx4K7A@mail.gmail.com>

Herry,
This is caused by a call to as.integer(cell numbers) which leads to NAs as
as.integer(ncell(rs))  returns NA
I have removed the call to as.integer in version 2.2-43 and this works now
(and it does not seem to mess up other things).
Thanks for reporting this,
Robert

On Thu, Jul 17, 2014 at 11:57 PM, Herry <Alexander.Herr at csiro.au> wrote:
>
> you probably also want to know about the raster:
>
>> rster
> class       : RasterLayer
> dimensions  : 76740, 80200, 6154548000  (nrow, ncol, ncell)
> resolution  : 50, 50  (x, y)
> extent      : -1888000, 2122000, -4847000, -1010000  (xmin, xmax, ymin,
> ymax)
> coord. ref. : +proj=aea +lat_1=-18 +lat_2=-36 +lat_0=0 +lon_0=132 +x_0=0
> +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs
> data source : /data/her134/BA/GDA94albers/clum50m0314
> names       : clum50m0314
> values      : 100, 663  (min, max)
>
>>rs
> class       : RasterLayer
> dimensions  : 76740, 80200, 6154548000  (nrow, ncol, ncell)
> resolution  : 50, 50  (x, y)
> extent      : -1888000, 2122000, -4847000, -1010000  (xmin, xmax, ymin,
> ymax)
> coord. ref. : +proj=aea +lat_1=-18 +lat_2=-36 +lat_0=0 +lon_0=132 +x_0=0
> +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs
> data source : /data/her134/BA/landuse4BA.grd
> names       : layer
> values      : 100, 661  (min, max)
>
>
>
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/image-rs-returns-error-after-reclassify-tp7586756p7586757.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From r.hijmans at gmail.com  Sun Aug 31 07:20:31 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Sat, 30 Aug 2014 22:20:31 -0700
Subject: [R-sig-Geo] Randomly moving a locality (within set limits)
In-Reply-To: <B078CDF40DFE4045AF172A8B4F68FC4857C78D0354@DKRDSEXC016.vestas.net>
References: <CAG_8N1YkczrHxWi6skkNJqwt6Uy6MmKNYxRUbySz163_x_dFAw@mail.gmail.com>
	<B078CDF40DFE4045AF172A8B4F68FC4857C78D0354@DKRDSEXC016.vestas.net>
Message-ID: <CANtt_hwi-HQgJKTvQrOCD4sUB=wafmo5NjYKSb6WZsZ2+R+jKA@mail.gmail.com>

I think this is implemented as the destPoint function in the geosphere
package. Robert

On Mon, Aug 25, 2014 at 1:26 AM, Frede Aakmann T?gersen
<frtog at vestas.com> wrote:
>
> Hi
>
> The following is based on http://www.movable-type.co.uk/scripts/latlong.html.
>
> foo <- function(origin, bearing, distance){
>     ## origin (lat, lon) is the point to randomly move
>     ## bearing (in degrees) is the direction in which to move
>     ## the distance to move origin
>
>     R = 6378.1 #Radius of the Earth in km
>
>     bearing <- bearing/180 * pi
>
>     lat1 = origin[1]/180 * pi #Current lat point converted to radians
>     lon1 = origin[2]/180 * pi  #Current long point converted to radians
>
>     lat2 = asin( sin(lat1)*cos(distance/R) +
>         cos(lat1)*sin(distance/R)*cos(bearing))
>
>     lon2 = lon1 + atan2(sin(bearing)*sin(distance/R)*cos(lat1),
>         cos(distance/R)-sin(lat1)*sin(lat2))
>
>     ## destination in degrees decimal
>     destination <- c(Latitude = lat2/pi*180, Longitude = lon2/pi*180)
>
>     return(destination)
> }
>
>> foo(c(52.20472, 0.14056), 90, 15)
>   Latitude  Longitude
> 52.2045157  0.3604334
>>
>
> Now choose
>
> bearing <- runif(1, 0, 360)
>
> and
>
> distance <- runif(1, 0, 15)
>
> Please check the formulas against the homepage above.
>
> Yours sincerely / Med venlig hilsen
>
>
> Frede Aakmann T?gersen
> Specialist, M.Sc., Ph.D.
> Plant Performance & Modeling
>
> Technology & Service Solutions
> T +45 9730 5135
> M +45 2547 6050
> frtog at vestas.com
> http://www.vestas.com
>
> Company reg. name: Vestas Wind Systems A/S
> This e-mail is subject to our e-mail disclaimer statement.
> Please refer to www.vestas.com/legal/notice
> If you have received this e-mail in error please contact the sender.
>
>
>> -----Original Message-----
>> From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-
>> project.org] On Behalf Of Alastair Potts
>> Sent: 22. august 2014 13:13
>> To: r-sig-geo at r-project.org
>> Subject: [R-sig-Geo] Randomly moving a locality (within set limits)
>>
>> Hi all,
>>
>> I was wondering if someone could help point me in the right direction here
>> - I can't seem to find a function or post that focuses on this.
>>
>> I have localities around the world. I want to be able to randomly move a
>> given locality within a set radius (defined by km). So, I have a point at
>> xy and want it to be shifted to some other locality within, say, 15 km of
>> of its current locality.
>>
>> This is simple enough using something like runif(1,-15,15), but it's the
>> lat-long conversion that is confusing me (how to work out how many decimal
>> degrees this might be around the point at different global localities).
>>
>> Any help or pointers would be greatly appreciated.
>>
>> Thanks in advance,
>>
>> Cheers,
>> Alastair
>>
>>       [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From r.hijmans at gmail.com  Sun Aug 31 20:51:40 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Sun, 31 Aug 2014 11:51:40 -0700
Subject: [R-sig-Geo] raster::ratify and as.factor Error in 1:ncol(r) :
 argument of length with raster read from large tif
In-Reply-To: <CAN9eD7=XUmTL0Muaq6XhGG0dTJn5+dtN=RR2AJRjRN61P1Ecgg@mail.gmail.com>
References: <CAN9eD7=XUmTL0Muaq6XhGG0dTJn5+dtN=RR2AJRjRN61P1Ecgg@mail.gmail.com>
Message-ID: <CANtt_hw4ER-1wC5r+=B0dOWxS+hReH72zKGqs-kBrJTdQ43upg@mail.gmail.com>

Nevil,
Thanks for reporting and including an example file. The error occurs
when showing a RasterLayer with a RAT table that only has IDs (but no
attributes for these IDs). Did it otherwise affect anything? Either
way, this has been fixed for the next version.
Robert

On Mon, Jul 7, 2014 at 6:52 AM, nevil amos <nevil.amos at gmail.com> wrote:
> I have encountered the following error , and not that it was previously
> raised: https://stat.ethz.ch/pipermail/r-help/2013-December/364489.html
> but I cannot find any solution.
>
> I have now encountered this issue a number of times with various large tif
> files  exported form ARCGIS.
>
> Can anyone suggest a solution?
>
> I cannot include w worked example since the functions work OK with rasters
> created within R ( and many imported ones too).
>
> I have put a zipped copy of the tif file ( and its associated vat file ovr
> file etc) on the web at
> :https://www.dropbox.com/s/oqur9m5lpt9menx/EFG_PLMGEN_FIREHAT2014_VG94100.zip
>
> Thanks
>
>
>> sessionInfo()
> R version 3.1.0 (2014-04-10)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=English_Australia.1252  LC_CTYPE=English_Australia.1252
> LC_MONETARY=English_Australia.1252
> [4] LC_NUMERIC=C                       LC_TIME=English_Australia.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] rgdal_0.8-16  raster_2.2-31 sp_1.0-14
>
> loaded via a namespace (and not attached):
> [1] grid_3.1.0      lattice_0.20-29 tools_3.1.0
>>
>> R<-raster("C:/Users/JNA/Documents/GIS/GrowthStage_TFI_Status/EFG_PLMGEN_FIREHAT2014_VG94100.tif")
>> ratify(R)
> class       : RasterLayer
> dimensions  : 5676, 8129, 46140204  (nrow, ncol, ncell)
> resolution  : 100, 100  (x, y)
> extent      : 2126760, 2939660, 2259503, 2827103  (xmin, xmax, ymin, ymax)
> coord. ref. : +proj=lcc +lat_1=-36 +lat_2=-38 +lat_0=-37 +lon_0=145
> +x_0=2500000 +y_0=2500000 +ellps=GRS80 +units=m +no_defs
> data source :
> C:\Users\JNA\Documents\GIS\GrowthStage_TFI_Status\EFG_PLMGEN_FIREHAT2014_VG94100.tif
> names       : EFG_PLMGEN_FIREHAT2014_VG94100
> values      : 0, 56660  (min, max)
> attributes  :
> Error in 1:ncol(r) : argument of length 0
>> as.factor(R)
> class       : RasterLayer
> dimensions  : 5676, 8129, 46140204  (nrow, ncol, ncell)
> resolution  : 100, 100  (x, y)
> extent      : 2126760, 2939660, 2259503, 2827103  (xmin, xmax, ymin, ymax)
> coord. ref. : +proj=lcc +lat_1=-36 +lat_2=-38 +lat_0=-37 +lon_0=145
> +x_0=2500000 +y_0=2500000 +ellps=GRS80 +units=m +no_defs
> data source :
> C:\Users\JNA\Documents\GIS\GrowthStage_TFI_Status\EFG_PLMGEN_FIREHAT2014_VG94100.tif
> names       : EFG_PLMGEN_FIREHAT2014_VG94100
> values      : 0, 56660  (min, max)
> attributes  :
> Error in 1:ncol(r) : argument of length 0


