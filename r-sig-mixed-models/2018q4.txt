From phillip@@ld@y @ending from mpi@nl  Tue Oct  2 11:48:12 2018
From: phillip@@ld@y @ending from mpi@nl (Phillip Alday)
Date: Tue, 2 Oct 2018 11:48:12 +0200
Subject: [R-sig-ME] R Consortium call for funding
In-Reply-To: <CAHB8JpKDnLWo_R9gf+ep0Gp5N6YPfdig==Bjxr5XHck9O6Fmeg@mail.gmail.com>
References: <daeea344-1e24-d314-8583-da0e1e8b6d4d@gmail.com>
 <CAHB8JpKDnLWo_R9gf+ep0Gp5N6YPfdig==Bjxr5XHck9O6Fmeg@mail.gmail.com>
Message-ID: <c9e6ad8b-29a4-b58d-874d-9669bb5eb7ee@mpi.nl>

I'm a bit late to the game on this one, but I would second the votes for
flexible covariance structures as in nlme. Perhaps this could be done by
investing funds into the flexlambda work?

Regarding two other suggestions:

1. Julia-like speed. There are bridges between Julia and R, but this
still doesn't help me once I have a fitted model in Julia and want the R
mixed-models ecosystem (effects, car::Anova(), lmerTest, etc.) to
examine the model. It should however be possible to construct a merMod
object from the fit in Julia. Tools for doing this would be quite nice.
(This also seems like relatively low-hanging fruit for a Google summer
of code type project.)

2. Better confidence intervals and predictions for non-linear links. I
think some parts of this are implemented in the effects and emmeans
packages. In addition to a more extensive/complete implementation, this
seems like something where additional documentation and worked examples
comparing conditional and marginalized coefficients would be useful,
potentially as part of the GLMM FAQ.

Best,
Phillip

On 09/26/2018 12:52 PM, Manuel Ramon wrote:
> I totally agree with you, Ben. I have to admit that all the tidyverse world
> has suppose a great improvement in the way I work with data, but in the
> end, almost all my analyses conclude with the nlme/lme4 packages. So I
> think it is worth investing funds and time on it.
> 
> As suggested by others, the inclusion of the variance functions from nlme
> would be very useful. Also, some of the capabilities of the mixed.models in
> Julia language in terms of computation time and data size would be very
> welcome, but this latter it is probably very difficult (almost impossible)
> given that they are to different platforms.
> 
> In any case, thanks for the initiative and I hope it will go ahead.
> 
> Regards,
> Manuel
> 
> 
> On Tue, Sep 25, 2018 at 11:00 PM Ben Bolker <bbolker at gmail.com> wrote:
> 
>>
>>
>> https://www.r-consortium.org/announcement/2018/09/25/fall-2018-isc-call-for-proposals
>>
>> "What can you do to improve the R ecosystem and how can the R Consortium
>> help you do it?"
>>
>>  The mixed-model ecosystem is admittedly a small part of the R
>> ecosystem, but I (biasedly) think it's an important one.
>>
>>   If people have ideas & opinions about how a chunk of money on the
>> order of $10,000 could be valuably spent to improve the mixed-model
>> ecosystem in a way that would be appealing to a very broad audience of
>> useRs, please discuss.
>>
>> The deadline for submitting a proposal is midnight PST, Sunday October
>> 31, 2018.
>>
>>
>>   cheers
>>    Ben Bolker
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From high@t@t @ending from high@t@t@com  Tue Oct  2 16:14:20 2018
From: high@t@t @ending from high@t@t@com (Highland Statistics Ltd)
Date: Tue, 2 Oct 2018 16:14:20 +0200
Subject: [R-sig-ME] Book: Spatial,
 Temporal and Spatial-Temporal Ecological Data Analysis
 with R-INLA. Volume II: GAM and Zero-Inflated Models
Message-ID: <22059521-a871-7f7f-1c12-9f68d8aa764a@highstat.com>

We are pleased to announce the following book:

Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with 
R-INLA. Volume II: GAM and Zero-Inflated Models
Authors: Zuur and Ieno

Book website: www.highstat.com
Paperback or EBook can be order (exclusively) from www.highstat.com
TOC: http://highstat.com/Books/BGS/SpatialTempVII/TOC_SpatTempII_Online.pdf

Summary: In Volume II we apply zero-inflated models and generalised 
additive (mixed-effects) models to spatial and spatial-temporal data. 
Data and all R code is available.


Outline:

In Chapter 18 we will explain how to deal with zero-inflated data. We 
introduce so-called zero-inflated Poisson (ZIP) models, zero-inflated 
negative binomial (ZINB) models, zero-altered Poisson (ZAP) models and 
zero-altered negative binomial (ZINB) models.

In Chapter 19 we extend the ZIP, ZINB, ZAP and ZANB models with spatial 
correlation. Both these chapters use a skate data set from South 
America. In the appendix accompanying Chapter 19 we also explain how to 
manipulate maps and create spatial polygons (e.g. for coastlines).

In Chapter 20 we revisit a data set with which we have been battling 
since 2006. It is about begging behaviour of owl nestlings. In Zuur 
(2009a) we applied linear mixed-effects models on it, and in Zuur et al. 
(2012a) we analysed it with a zero-inflated GLMM. Thanks to R-INLA we 
finally cracked this data set and apply a zero-inflated GAMM.

In Chapter 21 we analyse sandeel count data. This work came out of a 
consultancy project that we carried out for Wageningen Marine Research 
(The Netherlands) in 2017. Although the setup of the experiment is 
simple (approximately 400 sites sampled once per year, for 4 years), 
analysing these data and writing this chapter took about 30 days. This 
should give you an idea about the complexity of the statistical tools 
(zero-inflated GAMMs + spatial-temporal correlation) that we discuss in 
this book.

Chapter 22 is about zero-inflated bird densities sampled in the Labrador 
Sea, located between the Labrador Peninsula (Eastern Canada) and 
Greenland. This chapter is about the analysis of zero-inflated 
continuous data with spatial correlation. A zero-altered gamma model 
with spatial correlation is used.

In Chapter 23 we analyse coral reef data sampled around an island. A lot 
of misery comes together in this chapter: smoothers, zero-inflation and 
spatial dependency that should not cross land as benthic species that 
live in a coral reef do not walk over land! We will discuss barrier 
models (Bakka et al. 2018) which ensure that spatial correlation seeps 
around a barrier (in this case an island).

Up to Chapter 23 all data sets analysed were geostatistical data and not 
areal or lattice data. The reason for this is that most ecological data 
is geostatistical. In Chapter 24 we analyse aggregated tornado data in 
102 counties in Illinois. This is areal data. We will use various CAR 
models (e.g. iCAR, BYM, BYM2) for zero-inflated spatial and 
spatial-temporal correlated data.


-- 

Dr. Alain F. Zuur
Highland Statistics Ltd.
9 St Clair Wynd
AB41 6DZ Newburgh, UK
Email: highstat at highstat.com
URL:   www.highstat.com

And:
NIOZ Royal Netherlands Institute for Sea Research,
Department of Coastal Systems, and Utrecht University,
P.O. Box 59, 1790 AB Den Burg,
Texel, The Netherlands



Author of:
1. Beginner's Guide to Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA. (2017).
2. Beginner's Guide to Zero-Inflated Models with R (2016).
3. Beginner's Guide to Data Exploration and Visualisation with R (2015).
4. Beginner's Guide to GAMM with R (2014).
5. Beginner's Guide to GLM and GLMM with R (2013).
6. Beginner's Guide to GAM with R (2012).
7. Zero Inflated Models and GLMM with R (2012).
8. A Beginner's Guide to R (2009).
9. Mixed effects models and extensions in ecology with R (2009).
10. Analysing Ecological Data (2007).


	[[alternative HTML version deleted]]


From @rive@ @ending from wi@c@edu  Tue Oct  2 17:07:28 2018
From: @rive@ @ending from wi@c@edu (Anthony R. Ives)
Date: Tue, 2 Oct 2018 15:07:28 +0000
Subject: [R-sig-ME] Book: Mixed and Phylogenetic Models: A Conceptual
 Introduction to Correlated Data
Message-ID: <9882C218-22CF-4767-BA2F-8AED9B42500F@wisc.edu>

In case it might be useful, I recently self-published a tutorial on mixed and phylogenetic models:



Mixed and Phylogenetic Models: A Conceptual Introduction to Correlated Data

Anthony R. Ives



You can download it for free at https://leanpub.com/correlateddata. And please, do get it for free. I'm just using leanpub.com because it provides a nice platform and notifies downloaders when I update the book.



Summary



This book introduces the concepts behind statistical methods used to analyze data with correlated error structures. While correlated data arise in many ways, the focus is on ecological and evolutionary data, and two types of correlations: correlations generated by the hierarchical nature of the sampling (e.g., plots sampled within sites) and correlations generated by the phylogenetic relationships among species.



The book is integrated with R code that illustrates every point. Although it is possible to read the book without the code, or work through the code without the book, they are designed to go hand-in-hand. The R code comes with the complete downloadable package of the book on leanpub.com; if you have problems downloading it, please contact me.



Chapter 1, Multiple Methods for Analyzing Hierarchical Data

Chapter 2, Good Statistical Properties

Chapter 3, Phylogenetic Comparative Methods

Chapter 4, Phylogenetic Community Ecology



Background you'll need



Although the book is titled an introduction, it is an introduction to the concepts behind the methods discussed, not so much the methods themselves. It assumes that you understand basic statistical concepts (such as random variables) and know R and how to run mixed and phylogenetic models. I think that in many cases, the best way of learning is by doing. On the other hand, there is no substitute for getting a good background in the basics of statistical analyses and R before launching off into the more complicated material in this book.



Acknowledgments



This book is the product of many people. The general ideas come from a class I teach at UW-Madison for graduate students, and they have all had a huge impact on how I think about and try to explain statistics. The more proximate origin of the book is a workshop I gave in 2018 at the Xishuangbanna Tropical Botanical Garden, Chinese Academy of Sciences, which followed the same outline. Participants in this workshop provided great help in honing the content and messages. I am indebted to Professors Chen Jin and Wang Bo for hosting my visit.



I also thank Li Daijiang for all of his work developing, cleaning, and speeding the `communityPGLMM()` code that is the main tool used for Chapter 4. I wish I had his skills. Michael Hardy also kindly allowed me to model the example used in Chapters 1 and 2 on his real dataset. Li Daijiang, Joe Phillips, Tanjona Ramiadantsoa, and Xu Fangfang provided thoughtful comments on parts or all of the manuscript, although I'm responsible for all the lingering errors.



Finally, this work has been supported by the National Science Foundation through various grants, and I am very grateful for this support.





______________

Anthony R. Ives

UW-Madison

Integrative Biology

608-262-1519



	[[alternative HTML version deleted]]


From @jm@ckey @ending from gm@il@com  Wed Oct  3 20:18:51 2018
From: @jm@ckey @ending from gm@il@com (Aaron Mackey)
Date: Wed, 3 Oct 2018 14:18:51 -0400
Subject: [R-sig-ME] glmmTMB: how to calculate posterior prob. of structural
 zero?
Message-ID: <CAErFSojhif49jRmO-qWqjvR+pG-zcsV=jRxm4tpZr_QQ8q+a+w@mail.gmail.com>

I'm happily using glmmTMB to fit zero-inflated count models with my data,
but I'd like to also know which zeroes in my data are more likely (or not)
to be structural vs. expected from the conditional distribution. I know how
to use Bayes formula to calculate the posterior, and predict(zinb,
type="zprob") gives me the prior probabilites for each data point being
structural or not (respecting the zero inflation part of the model), and
the likelihoods for the structural components are 1 (if the data point is a
zero) or 0 (if the data point is not a zero) -- but is there a way to
extract the likelihood for each zero data point with respect to the
conditional part of the model?

thanks,
-Aaron

	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Wed Oct  3 21:01:09 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Wed, 3 Oct 2018 15:01:09 -0400
Subject: [R-sig-ME] 
 glmmTMB: how to calculate posterior prob. of structural zero?
In-Reply-To: <CAErFSojhif49jRmO-qWqjvR+pG-zcsV=jRxm4tpZr_QQ8q+a+w@mail.gmail.com>
References: <CAErFSojhif49jRmO-qWqjvR+pG-zcsV=jRxm4tpZr_QQ8q+a+w@mail.gmail.com>
Message-ID: <479de38f-4f50-ba7f-bb9e-63a9a31963a9@gmail.com>


  If you're fitting a zero-inflated Poisson model, it would be
especially easy because the zero probability is simply exp(-lambda), so
I believe the "posterior"(ish) probability that the zero is due to the
structural rather than conditional part of the model would be

 P(zero|structural)/P(zero) =
P(zero|structural)/(P(zero_structural)+P(zero_conditional))

or

prob_struc <- function(model) {
   strucprob <- predict(model, type="zprob")
   condprob <- exp(-predict(model, type="conditional"))
   return(strucprob/(strucprob+condprob))
}

For a negative binomial ("nbinom2", or quadratic parameterization) the
zero probability is (k/(k+mu))^k (I think ... e.g.
dnbinom(0,mu=0.5,size=0.5) is sqrt(0.5)).  sigma(model) returns the
overdispersion parameter k, so a function as above but with

  k <- sigma(model)
  condprob <- (k/(k+predict(model,type="conditional")))^k

 inserted should do the trick.  (Please test these yourself and make
sure they are sensible before proceeding!)

On 2018-10-03 02:18 PM, Aaron Mackey wrote:
> I'm happily using glmmTMB to fit zero-inflated count models with my data,
> but I'd like to also know which zeroes in my data are more likely (or not)
> to be structural vs. expected from the conditional distribution. I know how
> to use Bayes formula to calculate the posterior, and predict(zinb,
> type="zprob") gives me the prior probabilites for each data point being
> structural or not (respecting the zero inflation part of the model), and
> the likelihoods for the structural components are 1 (if the data point is a
> zero) or 0 (if the data point is not a zero) -- but is there a way to
> extract the likelihood for each zero data point with respect to the
> conditional part of the model?
> 
> thanks,
> -Aaron
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From @jm@ckey @ending from gm@il@com  Fri Oct  5 22:07:15 2018
From: @jm@ckey @ending from gm@il@com (Aaron Mackey)
Date: Fri, 5 Oct 2018 16:07:15 -0400
Subject: [R-sig-ME] 
 glmmTMB: how to calculate posterior prob. of structural zero?
In-Reply-To: <479de38f-4f50-ba7f-bb9e-63a9a31963a9@gmail.com>
References: <CAErFSojhif49jRmO-qWqjvR+pG-zcsV=jRxm4tpZr_QQ8q+a+w@mail.gmail.com>
 <479de38f-4f50-ba7f-bb9e-63a9a31963a9@gmail.com>
Message-ID: <CAErFSogRQT+1j4keZmpARy2XEnABBYLZSLzjm+Gi2QSgSL3N+w@mail.gmail.com>

Thanks for this, it seems to provide sensible numbers; but just to confirm,
does predict(model, type="conditional") actually use the Y variable
observed count? Or does it generate the expected log count from the
provided X variables (as in the case when newdata is provided)?

-Aaron

On Wed, Oct 3, 2018 at 3:01 PM Ben Bolker <bbolker at gmail.com> wrote:

>
>   If you're fitting a zero-inflated Poisson model, it would be
> especially easy because the zero probability is simply exp(-lambda), so
> I believe the "posterior"(ish) probability that the zero is due to the
> structural rather than conditional part of the model would be
>
>  P(zero|structural)/P(zero) =
> P(zero|structural)/(P(zero_structural)+P(zero_conditional))
>
> or
>
> prob_struc <- function(model) {
>    strucprob <- predict(model, type="zprob")
>    condprob <- exp(-predict(model, type="conditional"))
>    return(strucprob/(strucprob+condprob))
> }
>
> For a negative binomial ("nbinom2", or quadratic parameterization) the
> zero probability is (k/(k+mu))^k (I think ... e.g.
> dnbinom(0,mu=0.5,size=0.5) is sqrt(0.5)).  sigma(model) returns the
> overdispersion parameter k, so a function as above but with
>
>   k <- sigma(model)
>   condprob <- (k/(k+predict(model,type="conditional")))^k
>
>  inserted should do the trick.  (Please test these yourself and make
> sure they are sensible before proceeding!)
>
> On 2018-10-03 02:18 PM, Aaron Mackey wrote:
> > I'm happily using glmmTMB to fit zero-inflated count models with my data,
> > but I'd like to also know which zeroes in my data are more likely (or
> not)
> > to be structural vs. expected from the conditional distribution. I know
> how
> > to use Bayes formula to calculate the posterior, and predict(zinb,
> > type="zprob") gives me the prior probabilites for each data point being
> > structural or not (respecting the zero inflation part of the model), and
> > the likelihoods for the structural components are 1 (if the data point
> is a
> > zero) or 0 (if the data point is not a zero) -- but is there a way to
> > extract the likelihood for each zero data point with respect to the
> > conditional part of the model?
> >
> > thanks,
> > -Aaron
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Fri Oct  5 22:30:15 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Fri, 5 Oct 2018 16:30:15 -0400
Subject: [R-sig-ME] 
 glmmTMB: how to calculate posterior prob. of structural zero?
In-Reply-To: <CAErFSogRQT+1j4keZmpARy2XEnABBYLZSLzjm+Gi2QSgSL3N+w@mail.gmail.com>
References: <CAErFSojhif49jRmO-qWqjvR+pG-zcsV=jRxm4tpZr_QQ8q+a+w@mail.gmail.com>
 <479de38f-4f50-ba7f-bb9e-63a9a31963a9@gmail.com>
 <CAErFSogRQT+1j4keZmpARy2XEnABBYLZSLzjm+Gi2QSgSL3N+w@mail.gmail.com>
Message-ID: <CABghstTKtr1ag6GhiXUypx=rA3Jj83yQ8QKAKsbZ-9noRQ+Q9A@mail.gmail.com>

On Fri, Oct 5, 2018 at 4:07 PM Aaron Mackey <ajmackey at gmail.com> wrote:
>
> Thanks for this, it seems to provide sensible numbers; but just to confirm, does predict(model, type="conditional") actually use the Y variable observed count? Or does it generate the expected log count from the provided X variables (as in the case when newdata is provided)?

  It generates the expected  *count* (not the log count) *of the
conditional part of the model only* (i.e. not including structural
zeros), based on the estimated parameters and a model matrix (either
the one from the model or a newly generated one, if newdata is
specified)

>
> -Aaron
>
> On Wed, Oct 3, 2018 at 3:01 PM Ben Bolker <bbolker at gmail.com> wrote:
>>
>>
>>   If you're fitting a zero-inflated Poisson model, it would be
>> especially easy because the zero probability is simply exp(-lambda), so
>> I believe the "posterior"(ish) probability that the zero is due to the
>> structural rather than conditional part of the model would be
>>
>>  P(zero|structural)/P(zero) =
>> P(zero|structural)/(P(zero_structural)+P(zero_conditional))
>>
>> or
>>
>> prob_struc <- function(model) {
>>    strucprob <- predict(model, type="zprob")
>>    condprob <- exp(-predict(model, type="conditional"))
>>    return(strucprob/(strucprob+condprob))
>> }
>>
>> For a negative binomial ("nbinom2", or quadratic parameterization) the
>> zero probability is (k/(k+mu))^k (I think ... e.g.
>> dnbinom(0,mu=0.5,size=0.5) is sqrt(0.5)).  sigma(model) returns the
>> overdispersion parameter k, so a function as above but with
>>
>>   k <- sigma(model)
>>   condprob <- (k/(k+predict(model,type="conditional")))^k
>>
>>  inserted should do the trick.  (Please test these yourself and make
>> sure they are sensible before proceeding!)
>>
>> On 2018-10-03 02:18 PM, Aaron Mackey wrote:
>> > I'm happily using glmmTMB to fit zero-inflated count models with my data,
>> > but I'd like to also know which zeroes in my data are more likely (or not)
>> > to be structural vs. expected from the conditional distribution. I know how
>> > to use Bayes formula to calculate the posterior, and predict(zinb,
>> > type="zprob") gives me the prior probabilites for each data point being
>> > structural or not (respecting the zero inflation part of the model), and
>> > the likelihoods for the structural components are 1 (if the data point is a
>> > zero) or 0 (if the data point is not a zero) -- but is there a way to
>> > extract the likelihood for each zero data point with respect to the
>> > conditional part of the model?
>> >
>> > thanks,
>> > -Aaron
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From @jm@ckey @ending from gm@il@com  Sat Oct  6 02:29:53 2018
From: @jm@ckey @ending from gm@il@com (Aaron Mackey)
Date: Fri, 5 Oct 2018 20:29:53 -0400
Subject: [R-sig-ME] 
 glmmTMB: how to calculate posterior prob. of structural zero?
In-Reply-To: <CABghstTKtr1ag6GhiXUypx=rA3Jj83yQ8QKAKsbZ-9noRQ+Q9A@mail.gmail.com>
References: <CAErFSojhif49jRmO-qWqjvR+pG-zcsV=jRxm4tpZr_QQ8q+a+w@mail.gmail.com>
 <479de38f-4f50-ba7f-bb9e-63a9a31963a9@gmail.com>
 <CAErFSogRQT+1j4keZmpARy2XEnABBYLZSLzjm+Gi2QSgSL3N+w@mail.gmail.com>
 <CABghstTKtr1ag6GhiXUypx=rA3Jj83yQ8QKAKsbZ-9noRQ+Q9A@mail.gmail.com>
Message-ID: <CAErFSoiYjCzLExMQ1un3mfm-Vc-KVfdVoJjXz08K51HmPKr+fQ@mail.gmail.com>

Right -- so that's not what we need, is it? We need the probability of
having actually seen a zero, given the conditional model (regardless of
what the expected count might be). The probability of seeing a zero in the
other part of the mixture is 1.0, and the prior for both of the two models
is the mixture coefficient (and 1-coef). But we still need the likelihood
of the zero, given the conditional model, not the likelihood of seeing the
expected value.

-Aaron

On Fri, Oct 5, 2018 at 4:30 PM Ben Bolker <bbolker at gmail.com> wrote:

> On Fri, Oct 5, 2018 at 4:07 PM Aaron Mackey <ajmackey at gmail.com> wrote:
> >
> > Thanks for this, it seems to provide sensible numbers; but just to
> confirm, does predict(model, type="conditional") actually use the Y
> variable observed count? Or does it generate the expected log count from
> the provided X variables (as in the case when newdata is provided)?
>
>   It generates the expected  *count* (not the log count) *of the
> conditional part of the model only* (i.e. not including structural
> zeros), based on the estimated parameters and a model matrix (either
> the one from the model or a newly generated one, if newdata is
> specified)
>
> >
> > -Aaron
> >
> > On Wed, Oct 3, 2018 at 3:01 PM Ben Bolker <bbolker at gmail.com> wrote:
> >>
> >>
> >>   If you're fitting a zero-inflated Poisson model, it would be
> >> especially easy because the zero probability is simply exp(-lambda), so
> >> I believe the "posterior"(ish) probability that the zero is due to the
> >> structural rather than conditional part of the model would be
> >>
> >>  P(zero|structural)/P(zero) =
> >> P(zero|structural)/(P(zero_structural)+P(zero_conditional))
> >>
> >> or
> >>
> >> prob_struc <- function(model) {
> >>    strucprob <- predict(model, type="zprob")
> >>    condprob <- exp(-predict(model, type="conditional"))
> >>    return(strucprob/(strucprob+condprob))
> >> }
> >>
> >> For a negative binomial ("nbinom2", or quadratic parameterization) the
> >> zero probability is (k/(k+mu))^k (I think ... e.g.
> >> dnbinom(0,mu=0.5,size=0.5) is sqrt(0.5)).  sigma(model) returns the
> >> overdispersion parameter k, so a function as above but with
> >>
> >>   k <- sigma(model)
> >>   condprob <- (k/(k+predict(model,type="conditional")))^k
> >>
> >>  inserted should do the trick.  (Please test these yourself and make
> >> sure they are sensible before proceeding!)
> >>
> >> On 2018-10-03 02:18 PM, Aaron Mackey wrote:
> >> > I'm happily using glmmTMB to fit zero-inflated count models with my
> data,
> >> > but I'd like to also know which zeroes in my data are more likely (or
> not)
> >> > to be structural vs. expected from the conditional distribution. I
> know how
> >> > to use Bayes formula to calculate the posterior, and predict(zinb,
> >> > type="zprob") gives me the prior probabilites for each data point
> being
> >> > structural or not (respecting the zero inflation part of the model),
> and
> >> > the likelihoods for the structural components are 1 (if the data
> point is a
> >> > zero) or 0 (if the data point is not a zero) -- but is there a way to
> >> > extract the likelihood for each zero data point with respect to the
> >> > conditional part of the model?
> >> >
> >> > thanks,
> >> > -Aaron
> >> >
> >> >       [[alternative HTML version deleted]]
> >> >
> >> > _______________________________________________
> >> > R-sig-mixed-models at r-project.org mailing list
> >> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From @jm@ckey @ending from gm@il@com  Sat Oct  6 02:33:31 2018
From: @jm@ckey @ending from gm@il@com (Aaron Mackey)
Date: Fri, 5 Oct 2018 20:33:31 -0400
Subject: [R-sig-ME] 
 glmmTMB: how to calculate posterior prob. of structural zero?
In-Reply-To: <CAErFSoiYjCzLExMQ1un3mfm-Vc-KVfdVoJjXz08K51HmPKr+fQ@mail.gmail.com>
References: <CAErFSojhif49jRmO-qWqjvR+pG-zcsV=jRxm4tpZr_QQ8q+a+w@mail.gmail.com>
 <479de38f-4f50-ba7f-bb9e-63a9a31963a9@gmail.com>
 <CAErFSogRQT+1j4keZmpARy2XEnABBYLZSLzjm+Gi2QSgSL3N+w@mail.gmail.com>
 <CABghstTKtr1ag6GhiXUypx=rA3Jj83yQ8QKAKsbZ-9noRQ+Q9A@mail.gmail.com>
 <CAErFSoiYjCzLExMQ1un3mfm-Vc-KVfdVoJjXz08K51HmPKr+fQ@mail.gmail.com>
Message-ID: <CAErFSogLot3178wJQssXxP8WXyNByAzbbAf0ti9cTx7w4iXM-Q@mail.gmail.com>

Nevermind, I think I see my mistake -- the conditional expectation gives
the new mean, and with the dispersion you get a P value for having seen
zero, given the mean and dispersion. Sorry to be daft. If I wanted the
probability of some value other than zero, then the formula would contain
that actual value. thanks again! -Aaron

On Fri, Oct 5, 2018 at 8:29 PM Aaron Mackey <ajmackey at gmail.com> wrote:

> Right -- so that's not what we need, is it? We need the probability of
> having actually seen a zero, given the conditional model (regardless of
> what the expected count might be). The probability of seeing a zero in the
> other part of the mixture is 1.0, and the prior for both of the two models
> is the mixture coefficient (and 1-coef). But we still need the likelihood
> of the zero, given the conditional model, not the likelihood of seeing the
> expected value.
>
> -Aaron
>
> On Fri, Oct 5, 2018 at 4:30 PM Ben Bolker <bbolker at gmail.com> wrote:
>
>> On Fri, Oct 5, 2018 at 4:07 PM Aaron Mackey <ajmackey at gmail.com> wrote:
>> >
>> > Thanks for this, it seems to provide sensible numbers; but just to
>> confirm, does predict(model, type="conditional") actually use the Y
>> variable observed count? Or does it generate the expected log count from
>> the provided X variables (as in the case when newdata is provided)?
>>
>>   It generates the expected  *count* (not the log count) *of the
>> conditional part of the model only* (i.e. not including structural
>> zeros), based on the estimated parameters and a model matrix (either
>> the one from the model or a newly generated one, if newdata is
>> specified)
>>
>> >
>> > -Aaron
>> >
>> > On Wed, Oct 3, 2018 at 3:01 PM Ben Bolker <bbolker at gmail.com> wrote:
>> >>
>> >>
>> >>   If you're fitting a zero-inflated Poisson model, it would be
>> >> especially easy because the zero probability is simply exp(-lambda), so
>> >> I believe the "posterior"(ish) probability that the zero is due to the
>> >> structural rather than conditional part of the model would be
>> >>
>> >>  P(zero|structural)/P(zero) =
>> >> P(zero|structural)/(P(zero_structural)+P(zero_conditional))
>> >>
>> >> or
>> >>
>> >> prob_struc <- function(model) {
>> >>    strucprob <- predict(model, type="zprob")
>> >>    condprob <- exp(-predict(model, type="conditional"))
>> >>    return(strucprob/(strucprob+condprob))
>> >> }
>> >>
>> >> For a negative binomial ("nbinom2", or quadratic parameterization) the
>> >> zero probability is (k/(k+mu))^k (I think ... e.g.
>> >> dnbinom(0,mu=0.5,size=0.5) is sqrt(0.5)).  sigma(model) returns the
>> >> overdispersion parameter k, so a function as above but with
>> >>
>> >>   k <- sigma(model)
>> >>   condprob <- (k/(k+predict(model,type="conditional")))^k
>> >>
>> >>  inserted should do the trick.  (Please test these yourself and make
>> >> sure they are sensible before proceeding!)
>> >>
>> >> On 2018-10-03 02:18 PM, Aaron Mackey wrote:
>> >> > I'm happily using glmmTMB to fit zero-inflated count models with my
>> data,
>> >> > but I'd like to also know which zeroes in my data are more likely
>> (or not)
>> >> > to be structural vs. expected from the conditional distribution. I
>> know how
>> >> > to use Bayes formula to calculate the posterior, and predict(zinb,
>> >> > type="zprob") gives me the prior probabilites for each data point
>> being
>> >> > structural or not (respecting the zero inflation part of the model),
>> and
>> >> > the likelihoods for the structural components are 1 (if the data
>> point is a
>> >> > zero) or 0 (if the data point is not a zero) -- but is there a way to
>> >> > extract the likelihood for each zero data point with respect to the
>> >> > conditional part of the model?
>> >> >
>> >> > thanks,
>> >> > -Aaron
>> >> >
>> >> >       [[alternative HTML version deleted]]
>> >> >
>> >> > _______________________________________________
>> >> > R-sig-mixed-models at r-project.org mailing list
>> >> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >> >
>> >>
>> >> _______________________________________________
>> >> R-sig-mixed-models at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

	[[alternative HTML version deleted]]


From g@@dio @ending from po@t@bgu@@c@il  Sat Oct  6 16:26:23 2018
From: g@@dio @ending from po@t@bgu@@c@il (Mario Garrido)
Date: Sat, 6 Oct 2018 17:26:23 +0300
Subject: [R-sig-ME] help: error in (function...): Downdated VtV is not
 positive definite and convergence problems
Message-ID: <CAHzBVpJt2wEBUdsGXRCRt1=ZtgbsaJjmaRuauKZoX55QV6=GoA@mail.gmail.com>

Hello,
I tried to fit a GLMM and I get the following error. I know that my data is
probably more negative binomial than Poisson (sd>>mean), but I want to
understand where this problem comes from

glmer(countMyc.qPCR ~ sp+day +(0+day|exp.ID), family=poisson)

Error in (function (fr, X, reTrms, family, nAGQ = 1L, verbose = 0L, maxit =
100L,  :
  Downdated VtV is not positive definite

*countMyc.qPCR*:amount of bacteria ina particualr individual     Numeric
discrete value
*sp*:species each individual vbelongs to Factor w/ 3 levels "GA","GG","GP"
*day*: day of infection    Numeric discrete value
*exp.ID*: number of individual under experiment  Factor w/ 33 levels
"EA1","EA10","EA12",..: 3 6 7 10 11 14 18 21 22 31 ...

I fixed the random factor as 0+day|exp.ID cause at day zero the amount of
bacteria is zero

Can be the error due the differences in scales between the minimum and
maximum value
> describe.by(countMyc.qPCR)
   vars   n     mean       sd       median   trimmed     mad      min
   max      range       skew      kurtosis       se
X1  1    363  127789.2  783829.6      6      455.65      8.9       0
 8434322   8434322     7.84        67.75      41140.39

In addition, when I tried to fix an simpler data I have also warnings, but
other kinds

glmer(countMyc.qPCR ~day +(0+day|exp.ID), family=poisson)
Generalized linear mixed model fit by maximum likelihood (Laplace
Approximation) ['glmerMod']
 Family: poisson  ( log )
Formula: countMyc.qPCR ~ day + (0 + day | exp.ID)
       AIC        BIC     logLik   deviance   df.resid
 213021061  213021073 -106510528  213021055        360
Random effects:
 Groups Name Std.Dev.
 exp.ID day  0.1742
Number of obs: 363, groups:  exp.ID, 33
Fixed Effects:
(Intercept)          day
    13.3201      -0.1898
convergence code 0; 1 optimizer warnings; 0 lme4 warnings
Warning message:
In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model is nearly unidentifiable: very large eigenvalue
 - Rescale variables?


PS. I saw a similar question before (19th July) but cannot find a solution
there
-- 
Mario Garrido Escudero, PhD
Dr. Hadas Hawlena Lab
Mitrani Department of Desert Ecology
Jacob Blaustein Institutes for Desert Research
Ben-Gurion University of the Negev
Midreshet Ben-Gurion 84990 ISRAEL

gaiarrido at gmail.com; gaadio at post.bgu.ac.il
phone: (+972) 08-659-6854

	[[alternative HTML version deleted]]


From t@omidi@n@t@o @ending from gm@il@com  Sat Oct  6 00:16:42 2018
From: t@omidi@n@t@o @ending from gm@il@com (Taha Omidian)
Date: Sat, 6 Oct 2018 11:16:42 +1300
Subject: [R-sig-ME] Multilevel modeling-corpus linguistics
Message-ID: <4699788E-64D4-4845-80DD-4BAD12BF6B99@gmail.com>

Greetings, 

I am a researcher in the field applied linguistics. My colleagues and I are currently working on a corpus based study. We have decided to use mixed effect modelling due to the hierarchical and unbalanced design of our data. However, we are having trouble specifying the best random effects structure that can reflect the nested design of our data. We would be very grateful if we could have your expert opinion on this. 

I have pasted our R script and data below. 

Thank you.

Kindest regards, 

Taha


From d@rizopoulo@ @ending from er@@mu@mc@nl  Sat Oct  6 18:56:34 2018
From: d@rizopoulo@ @ending from er@@mu@mc@nl (D. Rizopoulos)
Date: Sat, 6 Oct 2018 16:56:34 +0000
Subject: [R-sig-ME] help: error in (function...): Downdated VtV is not
 positive definite and convergence problems
In-Reply-To: <CAHzBVpJt2wEBUdsGXRCRt1=ZtgbsaJjmaRuauKZoX55QV6=GoA@mail.gmail.com>
References: <CAHzBVpJt2wEBUdsGXRCRt1=ZtgbsaJjmaRuauKZoX55QV6=GoA@mail.gmail.com>
Message-ID: <7191AFC7255B4F49A30707E39BEAD05FDEB9DCD0@EXCH-HE03.erasmusmc.nl>

You could give a try to the GLMMadaptive package that can fit the same model using the adaptive Gaussian quadrature, i.e.,

library(GLMMadaptive)
fm <- mixed_model(countMyc.qPCR ~ sp + day, random = ~ 0 day | exp.ID, data = your_data, family = poisson())
summary(fm)

Best,
Dimitris


- - - - - -
Dimitris Rizopoulos
Professor of Biostatistics
Erasmus University Medical Center
The Netherlands

From: Mario Garrido <gaadio at post.bgu.ac.il<mailto:gaadio at post.bgu.ac.il>>
Date: Saturday, 06 Oct 2018, 4:26 PM
To: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
Subject: [R-sig-ME] help: error in (function...): Downdated VtV is not positive definite and convergence problems

Hello,
I tried to fit a GLMM and I get the following error. I know that my data is
probably more negative binomial than Poisson (sd>>mean), but I want to
understand where this problem comes from

glmer(countMyc.qPCR ~ sp+day +(0+day|exp.ID), family=poisson)

Error in (function (fr, X, reTrms, family, nAGQ = 1L, verbose = 0L, maxit =
100L,  :
  Downdated VtV is not positive definite

*countMyc.qPCR*:amount of bacteria ina particualr individual     Numeric
discrete value
*sp*:species each individual vbelongs to Factor w/ 3 levels "GA","GG","GP"
*day*: day of infection    Numeric discrete value
*exp.ID*: number of individual under experiment  Factor w/ 33 levels
"EA1","EA10","EA12",..: 3 6 7 10 11 14 18 21 22 31 ...

I fixed the random factor as 0+day|exp.ID cause at day zero the amount of
bacteria is zero

Can be the error due the differences in scales between the minimum and
maximum value
> describe.by(countMyc.qPCR)
   vars   n     mean       sd       median   trimmed     mad      min
   max      range       skew      kurtosis       se
X1  1    363  127789.2  783829.6      6      455.65      8.9       0
 8434322   8434322     7.84        67.75      41140.39

In addition, when I tried to fix an simpler data I have also warnings, but
other kinds

glmer(countMyc.qPCR ~day +(0+day|exp.ID), family=poisson)
Generalized linear mixed model fit by maximum likelihood (Laplace
Approximation) ['glmerMod']
 Family: poisson  ( log )
Formula: countMyc.qPCR ~ day + (0 + day | exp.ID)
       AIC        BIC     logLik   deviance   df.resid
 213021061  213021073 -106510528  213021055        360
Random effects:
 Groups Name Std.Dev.
 exp.ID day  0.1742
Number of obs: 363, groups:  exp.ID, 33
Fixed Effects:
(Intercept)          day
    13.3201      -0.1898
convergence code 0; 1 optimizer warnings; 0 lme4 warnings
Warning message:
In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model is nearly unidentifiable: very large eigenvalue
 - Rescale variables?


PS. I saw a similar question before (19th July) but cannot find a solution
there
--
Mario Garrido Escudero, PhD
Dr. Hadas Hawlena Lab
Mitrani Department of Desert Ecology
Jacob Blaustein Institutes for Desert Research
Ben-Gurion University of the Negev
Midreshet Ben-Gurion 84990 ISRAEL

gaiarrido at gmail.com; gaadio at post.bgu.ac.il
phone: (+972) 08-659-6854

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From t@h@@omidi@n @ending from vuw@@c@nz  Mon Oct  8 00:46:38 2018
From: t@h@@omidi@n @ending from vuw@@c@nz (Taha Omidian)
Date: Sun, 7 Oct 2018 22:46:38 +0000
Subject: [R-sig-ME] LMER-CorpusData
Message-ID: <E807D6B5-D058-4CF0-8288-48D083972227@staff.vuw.ac.nz>

Hello,

I?m trying to fit a mixed effects model to my corpus data. The data has a hierarchical structure. I need to make sure that the final model reflects this nested structure.

My final model looks like this:

theMdl<-lmer(dis.norm.j$transformed~disciplinaryGroup+genreGroup+level+(1|student_id)+(1|levelA)+(1|levelB)+(1|levelC),data=thedata, control=lmerControl("bobyqa?))

where 

LevelA is genreGroup:genreFamily:student_id
levelB is disciplinaryGroup:discipline:student_id
levelC is level:student_id

Here is a link to my data and R script: https://www.dropbox.com/sh/46r6lv6n89bromk/AABMc8MQmAYhRC3ubJ0Ii7Wma?dl=0

Thanks 

Taha

From g@@dio @ending from po@t@bgu@@c@il  Mon Oct  8 13:09:12 2018
From: g@@dio @ending from po@t@bgu@@c@il (Mario Garrido)
Date: Mon, 8 Oct 2018 14:09:12 +0300
Subject: [R-sig-ME] Fwd: help: error in (function...): Downdated VtV is not
 positive definite and convergence problems
In-Reply-To: <CAHzBVpJMJV5d2QLUtO=aRauc9cqJiNnZA7Pd45zF9S1isLn_gw@mail.gmail.com>
References: <CAHzBVpJt2wEBUdsGXRCRt1=ZtgbsaJjmaRuauKZoX55QV6=GoA@mail.gmail.com>
 <7191AFC7255B4F49A30707E39BEAD05FDEB9DCD0@EXCH-HE03.erasmusmc.nl>
 <CAHzBVpJMJV5d2QLUtO=aRauc9cqJiNnZA7Pd45zF9S1isLn_gw@mail.gmail.com>
Message-ID: <CAHzBVpL5GqSZwb0bkXZMV5kpOLZ-DBy9276GkMWnaiTnGPBMwQ@mail.gmail.com>

Thanks so much Dimitris,
in any case, now I have recieved another warning

fm <- mixed_model(countMyc.qPCR ~ sp + day, random = ~ 0+day | exp.ID, data
= MycGLMM, family = poisson())
Error in optim(par = b_i, fn = log_post_b, gr = score_log_post_b, method =
"BFGS",  :
  non-finite value supplied by optim

Any idea why?

Thanks!

PS, sorry to insist, but is not a problem what I said in the mail
before? due the differences in scales between the minimum and maximum value




El s?b., 6 oct. 2018 19:56, D. Rizopoulos <d.rizopoulos at erasmusmc.nl>
escribi?:

> You could give a try to the GLMMadaptive package that can fit the same
> model using the adaptive Gaussian quadrature, i.e.,
>
> library(GLMMadaptive)
> fm <- mixed_model(countMyc.qPCR ~ sp + day, random = ~ 0 day | exp.ID,
> data = your_data, family = poisson())
> summary(fm)
>
> Best,
> Dimitris
>
>
> - - - - - -
> Dimitris Rizopoulos
> Professor of Biostatistics
> Erasmus University Medical Center
> The Netherlands
>
> *From: *Mario Garrido <gaadio at post.bgu.ac.il>
> *Date: *Saturday, 06 Oct 2018, 4:26 PM
> *To: *r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
> *Subject: *[R-sig-ME] help: error in (function...): Downdated VtV is not
> positive definite and convergence problems
>
> Hello,
> I tried to fit a GLMM and I get the following error. I know that my data is
> probably more negative binomial than Poisson (sd>>mean), but I want to
> understand where this problem comes from
>
> glmer(countMyc.qPCR ~ sp+day +(0+day|exp.ID), family=poisson)
>
> Error in (function (fr, X, reTrms, family, nAGQ = 1L, verbose = 0L, maxit =
> 100L,  :
>   Downdated VtV is not positive definite
>
> *countMyc.qPCR*:amount of bacteria ina particualr individual     Numeric
> discrete value
> *sp*:species each individual vbelongs to Factor w/ 3 levels "GA","GG","GP"
> *day*: day of infection    Numeric discrete value
> *exp.ID*: number of individual under experiment  Factor w/ 33 levels
> "EA1","EA10","EA12",..: 3 6 7 10 11 14 18 21 22 31 ...
>
> I fixed the random factor as 0+day|exp.ID cause at day zero the amount of
> bacteria is zero
>
> Can be the error due the differences in scales between the minimum and
> maximum value
> > describe.by(countMyc.qPCR)
>    vars   n     mean       sd       median   trimmed     mad      min
>    max      range       skew      kurtosis       se
> X1  1    363  127789.2  783829.6      6      455.65      8.9       0
>  8434322   8434322     7.84        67.75      41140.39
>
> In addition, when I tried to fix an simpler data I have also warnings, but
> other kinds
>
> glmer(countMyc.qPCR ~day +(0+day|exp.ID), family=poisson)
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) ['glmerMod']
>  Family: poisson  ( log )
> Formula: countMyc.qPCR ~ day + (0 + day | exp.ID)
>        AIC        BIC     logLik   deviance   df.resid
>  213021061  213021073 -106510528  213021055        360
> Random effects:
>  Groups Name Std.Dev.
>  exp.ID day  0.1742
> Number of obs: 363, groups:  exp.ID, 33
> Fixed Effects:
> (Intercept)          day
>     13.3201      -0.1898
> convergence code 0; 1 optimizer warnings; 0 lme4 warnings
> Warning message:
> In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model is nearly unidentifiable: very large eigenvalue
>  - Rescale variables?
>
>
> PS. I saw a similar question before (19th July) but cannot find a solution
> there
> --
> Mario Garrido Escudero, PhD
> Dr. Hadas Hawlena Lab
> Mitrani Department of Desert Ecology
> Jacob Blaustein Institutes for Desert Research
> Ben-Gurion University of the Negev
> Midreshet Ben-Gurion 84990 ISRAEL
>
> gaiarrido at gmail.com; gaadio at post.bgu.ac.il
> phone: (+972) 08-659-6854
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Mario Garrido Escudero, PhD
Dr. Hadas Hawlena Lab
Mitrani Department of Desert Ecology
Jacob Blaustein Institutes for Desert Research
Ben-Gurion University of the Negev
Midreshet Ben-Gurion 84990 ISRAEL

gaiarrido at gmail.com; gaadio at post.bgu.ac.il
phone: (+972) 08-659-6854

	[[alternative HTML version deleted]]


From g@@dio @ending from po@t@bgu@@c@il  Mon Oct  8 13:10:56 2018
From: g@@dio @ending from po@t@bgu@@c@il (Mario Garrido)
Date: Mon, 8 Oct 2018 14:10:56 +0300
Subject: [R-sig-ME] help: error in (function...): Downdated VtV is not
 positive definite and convergence problems
In-Reply-To: <CAHzBVpL5GqSZwb0bkXZMV5kpOLZ-DBy9276GkMWnaiTnGPBMwQ@mail.gmail.com>
References: <CAHzBVpJt2wEBUdsGXRCRt1=ZtgbsaJjmaRuauKZoX55QV6=GoA@mail.gmail.com>
 <7191AFC7255B4F49A30707E39BEAD05FDEB9DCD0@EXCH-HE03.erasmusmc.nl>
 <CAHzBVpJMJV5d2QLUtO=aRauc9cqJiNnZA7Pd45zF9S1isLn_gw@mail.gmail.com>
 <CAHzBVpL5GqSZwb0bkXZMV5kpOLZ-DBy9276GkMWnaiTnGPBMwQ@mail.gmail.com>
Message-ID: <CAHzBVpLsN-q-HNLsXzPweboTTMsOxgYueJoOwbwSfGdcxb_V-w@mail.gmail.com>

Thanks again Dr. Rizopoulos,
i cannot find the command initial values in the Package 'lme4' PDF here:
https://cran.r-project.org/web/packages/lme4/lme4.pdf

Where can I look how to use it?

thanks!

2018-10-08 14:09 GMT+03:00 Mario Garrido <gaadio at post.bgu.ac.il>:

> Thanks so much Dimitris,
> in any case, now I have recieved another warning
>
> fm <- mixed_model(countMyc.qPCR ~ sp + day, random = ~ 0+day | exp.ID,
> data = MycGLMM, family = poisson())
> Error in optim(par = b_i, fn = log_post_b, gr = score_log_post_b, method =
> "BFGS",  :
>   non-finite value supplied by optim
>
> Any idea why?
>
> Thanks!
>
> PS, sorry to insist, but is not a problem what I said in the mail
> before? due the differences in scales between the minimum and maximum value
>
>
>
>
> El s?b., 6 oct. 2018 19:56, D. Rizopoulos <d.rizopoulos at erasmusmc.nl>
> escribi?:
>
>> You could give a try to the GLMMadaptive package that can fit the same
>> model using the adaptive Gaussian quadrature, i.e.,
>>
>> library(GLMMadaptive)
>> fm <- mixed_model(countMyc.qPCR ~ sp + day, random = ~ 0 day | exp.ID,
>> data = your_data, family = poisson())
>> summary(fm)
>>
>> Best,
>> Dimitris
>>
>>
>> - - - - - -
>> Dimitris Rizopoulos
>> Professor of Biostatistics
>> Erasmus University Medical Center
>> The Netherlands
>>
>> *From: *Mario Garrido <gaadio at post.bgu.ac.il>
>> *Date: *Saturday, 06 Oct 2018, 4:26 PM
>> *To: *r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
>> *Subject: *[R-sig-ME] help: error in (function...): Downdated VtV is not
>> positive definite and convergence problems
>>
>> Hello,
>> I tried to fit a GLMM and I get the following error. I know that my data
>> is
>> probably more negative binomial than Poisson (sd>>mean), but I want to
>> understand where this problem comes from
>>
>> glmer(countMyc.qPCR ~ sp+day +(0+day|exp.ID), family=poisson)
>>
>> Error in (function (fr, X, reTrms, family, nAGQ = 1L, verbose = 0L, maxit
>> =
>> 100L,  :
>>   Downdated VtV is not positive definite
>>
>> *countMyc.qPCR*:amount of bacteria ina particualr individual     Numeric
>> discrete value
>> *sp*:species each individual vbelongs to Factor w/ 3 levels "GA","GG","GP"
>> *day*: day of infection    Numeric discrete value
>> *exp.ID*: number of individual under experiment  Factor w/ 33 levels
>> "EA1","EA10","EA12",..: 3 6 7 10 11 14 18 21 22 31 ...
>>
>> I fixed the random factor as 0+day|exp.ID cause at day zero the amount of
>> bacteria is zero
>>
>> Can be the error due the differences in scales between the minimum and
>> maximum value
>> > describe.by(countMyc.qPCR)
>>    vars   n     mean       sd       median   trimmed     mad      min
>>    max      range       skew      kurtosis       se
>> X1  1    363  127789.2  783829.6      6      455.65      8.9       0
>>  8434322   8434322     7.84        67.75      41140.39
>>
>> In addition, when I tried to fix an simpler data I have also warnings, but
>> other kinds
>>
>> glmer(countMyc.qPCR ~day +(0+day|exp.ID), family=poisson)
>> Generalized linear mixed model fit by maximum likelihood (Laplace
>> Approximation) ['glmerMod']
>>  Family: poisson  ( log )
>> Formula: countMyc.qPCR ~ day + (0 + day | exp.ID)
>>        AIC        BIC     logLik   deviance   df.resid
>>  213021061  213021073 -106510528  213021055        360
>> Random effects:
>>  Groups Name Std.Dev.
>>  exp.ID day  0.1742
>> Number of obs: 363, groups:  exp.ID, 33
>> Fixed Effects:
>> (Intercept)          day
>>     13.3201      -0.1898
>> convergence code 0; 1 optimizer warnings; 0 lme4 warnings
>> Warning message:
>> In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>>   Model is nearly unidentifiable: very large eigenvalue
>>  - Rescale variables?
>>
>>
>> PS. I saw a similar question before (19th July) but cannot find a solution
>> there
>> --
>> Mario Garrido Escudero, PhD
>> Dr. Hadas Hawlena Lab
>> Mitrani Department of Desert Ecology
>> Jacob Blaustein Institutes for Desert Research
>> Ben-Gurion University of the Negev
>> Midreshet Ben-Gurion 84990 ISRAEL
>>
>> gaiarrido at gmail.com; gaadio at post.bgu.ac.il
>> phone: (+972) 08-659-6854
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
> Mario Garrido Escudero, PhD
> Dr. Hadas Hawlena Lab
> Mitrani Department of Desert Ecology
> Jacob Blaustein Institutes for Desert Research
> Ben-Gurion University of the Negev
> Midreshet Ben-Gurion 84990 ISRAEL
>
> gaiarrido at gmail.com; gaadio at post.bgu.ac.il
> phone: (+972) 08-659-6854
>
>
>


-- 
Mario Garrido Escudero, PhD
Dr. Hadas Hawlena Lab
Mitrani Department of Desert Ecology
Jacob Blaustein Institutes for Desert Research
Ben-Gurion University of the Negev
Midreshet Ben-Gurion 84990 ISRAEL

gaiarrido at gmail.com; gaadio at post.bgu.ac.il
phone: (+972) 08-659-6854

	[[alternative HTML version deleted]]


From d@rizopoulo@ @ending from er@@mu@mc@nl  Mon Oct  8 16:56:23 2018
From: d@rizopoulo@ @ending from er@@mu@mc@nl (D. Rizopoulos)
Date: Mon, 8 Oct 2018 14:56:23 +0000
Subject: [R-sig-ME] help: error in (function...): Downdated VtV is not
 positive definite and convergence problems
In-Reply-To: <CAHzBVpLsN-q-HNLsXzPweboTTMsOxgYueJoOwbwSfGdcxb_V-w@mail.gmail.com>
References: <CAHzBVpJt2wEBUdsGXRCRt1=ZtgbsaJjmaRuauKZoX55QV6=GoA@mail.gmail.com>
 <7191AFC7255B4F49A30707E39BEAD05FDEB9DCD0@EXCH-HE03.erasmusmc.nl>
 <CAHzBVpJMJV5d2QLUtO=aRauc9cqJiNnZA7Pd45zF9S1isLn_gw@mail.gmail.com>
 <CAHzBVpL5GqSZwb0bkXZMV5kpOLZ-DBy9276GkMWnaiTnGPBMwQ@mail.gmail.com>
 <CAHzBVpLsN-q-HNLsXzPweboTTMsOxgYueJoOwbwSfGdcxb_V-w@mail.gmail.com>
Message-ID: <b47cc52c-50af-021c-59d2-a5e8210e5d9c@erasmusmc.nl>

You can set the initial values in the mixed_model() function of my 
GLMMadaptive package using the initial_values argument. For more info, 
check: https://drizopoulos.github.io/GLMMadaptive/reference/mixed_model.html

Best,
Dimitris


On 10/8/2018 1:10 PM, Mario Garrido wrote:
> Thanks again Dr. Rizopoulos,
> i cannot find the command initial values in the Package 'lme4' PDF here:
> https://cran.r-project.org/web/packages/lme4/lme4.pdf
> 
> Where can I look how to use it?
> 
> thanks!
> 
> 2018-10-08 14:09 GMT+03:00 Mario Garrido <gaadio at post.bgu.ac.il>:
> 
>> Thanks so much Dimitris,
>> in any case, now I have recieved another warning
>>
>> fm <- mixed_model(countMyc.qPCR ~ sp + day, random = ~ 0+day | exp.ID,
>> data = MycGLMM, family = poisson())
>> Error in optim(par = b_i, fn = log_post_b, gr = score_log_post_b, method =
>> "BFGS",  :
>>    non-finite value supplied by optim
>>
>> Any idea why?
>>
>> Thanks!
>>
>> PS, sorry to insist, but is not a problem what I said in the mail
>> before? due the differences in scales between the minimum and maximum value
>>
>>
>>
>>
>> El s?b., 6 oct. 2018 19:56, D. Rizopoulos <d.rizopoulos at erasmusmc.nl>
>> escribi?:
>>
>>> You could give a try to the GLMMadaptive package that can fit the same
>>> model using the adaptive Gaussian quadrature, i.e.,
>>>
>>> library(GLMMadaptive)
>>> fm <- mixed_model(countMyc.qPCR ~ sp + day, random = ~ 0 day | exp.ID,
>>> data = your_data, family = poisson())
>>> summary(fm)
>>>
>>> Best,
>>> Dimitris
>>>
>>>
>>> - - - - - -
>>> Dimitris Rizopoulos
>>> Professor of Biostatistics
>>> Erasmus University Medical Center
>>> The Netherlands
>>>
>>> *From: *Mario Garrido <gaadio at post.bgu.ac.il>
>>> *Date: *Saturday, 06 Oct 2018, 4:26 PM
>>> *To: *r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
>>> *Subject: *[R-sig-ME] help: error in (function...): Downdated VtV is not
>>> positive definite and convergence problems
>>>
>>> Hello,
>>> I tried to fit a GLMM and I get the following error. I know that my data
>>> is
>>> probably more negative binomial than Poisson (sd>>mean), but I want to
>>> understand where this problem comes from
>>>
>>> glmer(countMyc.qPCR ~ sp+day +(0+day|exp.ID), family=poisson)
>>>
>>> Error in (function (fr, X, reTrms, family, nAGQ = 1L, verbose = 0L, maxit
>>> =
>>> 100L,  :
>>>    Downdated VtV is not positive definite
>>>
>>> *countMyc.qPCR*:amount of bacteria ina particualr individual     Numeric
>>> discrete value
>>> *sp*:species each individual vbelongs to Factor w/ 3 levels "GA","GG","GP"
>>> *day*: day of infection    Numeric discrete value
>>> *exp.ID*: number of individual under experiment  Factor w/ 33 levels
>>> "EA1","EA10","EA12",..: 3 6 7 10 11 14 18 21 22 31 ...
>>>
>>> I fixed the random factor as 0+day|exp.ID cause at day zero the amount of
>>> bacteria is zero
>>>
>>> Can be the error due the differences in scales between the minimum and
>>> maximum value
>>>> describe.by(countMyc.qPCR)
>>>     vars   n     mean       sd       median   trimmed     mad      min
>>>     max      range       skew      kurtosis       se
>>> X1  1    363  127789.2  783829.6      6      455.65      8.9       0
>>>   8434322   8434322     7.84        67.75      41140.39
>>>
>>> In addition, when I tried to fix an simpler data I have also warnings, but
>>> other kinds
>>>
>>> glmer(countMyc.qPCR ~day +(0+day|exp.ID), family=poisson)
>>> Generalized linear mixed model fit by maximum likelihood (Laplace
>>> Approximation) ['glmerMod']
>>>   Family: poisson  ( log )
>>> Formula: countMyc.qPCR ~ day + (0 + day | exp.ID)
>>>         AIC        BIC     logLik   deviance   df.resid
>>>   213021061  213021073 -106510528  213021055        360
>>> Random effects:
>>>   Groups Name Std.Dev.
>>>   exp.ID day  0.1742
>>> Number of obs: 363, groups:  exp.ID, 33
>>> Fixed Effects:
>>> (Intercept)          day
>>>      13.3201      -0.1898
>>> convergence code 0; 1 optimizer warnings; 0 lme4 warnings
>>> Warning message:
>>> In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>>>    Model is nearly unidentifiable: very large eigenvalue
>>>   - Rescale variables?
>>>
>>>
>>> PS. I saw a similar question before (19th July) but cannot find a solution
>>> there
>>> --
>>> Mario Garrido Escudero, PhD
>>> Dr. Hadas Hawlena Lab
>>> Mitrani Department of Desert Ecology
>>> Jacob Blaustein Institutes for Desert Research
>>> Ben-Gurion University of the Negev
>>> Midreshet Ben-Gurion 84990 ISRAEL
>>>
>>> gaiarrido at gmail.com; gaadio at post.bgu.ac.il
>>> phone: (+972) 08-659-6854
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>>
>> --
>> Mario Garrido Escudero, PhD
>> Dr. Hadas Hawlena Lab
>> Mitrani Department of Desert Ecology
>> Jacob Blaustein Institutes for Desert Research
>> Ben-Gurion University of the Negev
>> Midreshet Ben-Gurion 84990 ISRAEL
>>
>> gaiarrido at gmail.com; gaadio at post.bgu.ac.il
>> phone: (+972) 08-659-6854
>>
>>
>>
> 
> 

-- 
Dimitris Rizopoulos
Professor of Biostatistics
Department of Biostatistics
Erasmus University Medical Center

Address: PO Box 2040, 3000 CA Rotterdam, the Netherlands
Tel: +31/(0)10/7043478
Fax: +31/(0)10/7043014
Web (personal): http://www.drizopoulos.com/
Web (work): http://www.erasmusmc.nl/biostatistiek/
Blog: http://iprogn.blogspot.nl/

From g@@dio @ending from po@t@bgu@@c@il  Tue Oct  9 11:45:16 2018
From: g@@dio @ending from po@t@bgu@@c@il (Mario Garrido)
Date: Tue, 9 Oct 2018 12:45:16 +0300
Subject: [R-sig-ME] Conceptual doubts on how to define my random effects
Message-ID: <CAHzBVpKR8Dm7Cbhf99yc7Q-Aj5ozTgKE8b6tu9TytAVw4uVpaw@mail.gmail.com>

Dear lme4users,
I have some conceptual doubts on understanding the meaning of some random
factors.

Briefly, I am checking the dynamics of infection by bacteria on individuals
from 3 different species of hosts. I am trying to fit my data to a
generalized linear model with repeated measures. My data consists on the amount
of bacterial colonies  (Myc.qPCR) at different time points (day) fin the
blood of the 33 individual hosts (exp.ID), belonging to 3 different
species  (sp). At time zero all the values are 0 cause the indivuals were
still not infected.
As I want to check whether the dynamics in the three species are different
I included in my first model day*sp as fixed factor

I am trying to fit the random effect but I have some problems with the
interpretation. Any reading recommendations for Ecologists that we are not
experts in statistics to understand the ecological meaning of random
effects?

I know for use that I want to control  for variance at individual level so,
|exp.ID is needed, I also want to 'force the intercept to be zero (since at
day zero amount of bacteria is zero) , and I also wonder whether I have to
nest the individuals within day.
Thus, my model would be



lme(lg(Myc.qPCR)~day*sp,random=?,method="ML")

And I have doubts on how to define my random effect, cause, indeed, I do
not know what is the exact meaning of them under lme4. I understand that as
I have a Mixed-effects model with temporal pseudoreplication I hould use
day in the random factor, but how to include that intercept is zero?
(1|exp.ID)
(day|exp.ID)
(0+day|exp.ID)
+(1|exp.ID)+(0+day|exp.ID)

Thanks!

-- 
Mario Garrido Escudero, PhD
Dr. Hadas Hawlena Lab
Mitrani Department of Desert Ecology
Jacob Blaustein Institutes for Desert Research
Ben-Gurion University of the Negev
Midreshet Ben-Gurion 84990 ISRAEL

gaiarrido at gmail.com; gaadio at post.bgu.ac.il
phone: (+972) 08-659-6854

	[[alternative HTML version deleted]]


From phillip@@ld@y @ending from mpi@nl  Tue Oct  9 12:10:37 2018
From: phillip@@ld@y @ending from mpi@nl (Phillip Alday)
Date: Tue, 9 Oct 2018 12:10:37 +0200
Subject: [R-sig-ME] LMER-CorpusData
In-Reply-To: <E807D6B5-D058-4CF0-8288-48D083972227@staff.vuw.ac.nz>
References: <E807D6B5-D058-4CF0-8288-48D083972227@staff.vuw.ac.nz>
Message-ID: <25d38071-213b-7a42-bcb2-92f0de8fd6c5@mpi.nl>

I don't think this is the model you're looking for...

1. It's really weird to have your predictors in one dataframe and your
dependent variable in a different one. Are you really sure that the rows
line up like you think they do? If so, why not join the dataframes
earlier (with merge(), plyr::join() or dplyr::join())?

I'm overall quite nervous about namespaces / scope / etc. in your code
-- using attach() isn't recommended practice, especially when you mix
and match things (e.g. your levelX variables aren't in your dataframe,
but the other predictors are). You have to be really careful to make
sure you're using the data you think you're using.

You can do it like you have it, but it makes me very nervous in terms of
computing what you think you're computing.

2. Your levels include the same predictor in both the fixed effects and
as a grouping variable (the part of the random effect after the |) .
This generally doesn't make sense -- there are a number of posts on this
mailing list to that effect (see also
https://rpubs.com/INBOstats/both_fixed_random and
https://www.muscardinus.be/2017/08/fixed-and-random/) -- but it depends
on your data.

In other words, seeing your model specification isn't quite enough -- we
also need to know something about your data, more than your variable
names alone reveal. Even though I work a lot with language data, I still
can't tell enough from your variable names and code what your data
actually represent.


Best,
Phillip




On 10/08/2018 12:46 AM, Taha Omidian wrote:
> Hello,
> 
> I?m trying to fit a mixed effects model to my corpus data. The data has a hierarchical structure. I need to make sure that the final model reflects this nested structure.
> 
> My final model looks like this:
> 
> theMdl<-lmer(dis.norm.j$transformed~disciplinaryGroup+genreGroup+level+(1|student_id)+(1|levelA)+(1|levelB)+(1|levelC),data=thedata, control=lmerControl("bobyqa?))
> 
> where 
> 
> LevelA is genreGroup:genreFamily:student_id
> levelB is disciplinaryGroup:discipline:student_id
> levelC is level:student_id
> 
> Here is a link to my data and R script: https://www.dropbox.com/sh/46r6lv6n89bromk/AABMc8MQmAYhRC3ubJ0Ii7Wma?dl=0
> 
> Thanks 
> 
> Taha
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From jdpo223 @ending from g@uky@edu  Tue Oct  9 22:05:08 2018
From: jdpo223 @ending from g@uky@edu (Poe, John)
Date: Tue, 9 Oct 2018 16:05:08 -0400
Subject: [R-sig-ME] Conceptual doubts on how to define my random effects
In-Reply-To: <CAHzBVpKR8Dm7Cbhf99yc7Q-Aj5ozTgKE8b6tu9TytAVw4uVpaw@mail.gmail.com>
References: <CAHzBVpKR8Dm7Cbhf99yc7Q-Aj5ozTgKE8b6tu9TytAVw4uVpaw@mail.gmail.com>
Message-ID: <CAFW8Byq=a2DQ8cpUgVttWSJi3Bv6KnVZW-LLuj2zW8_JZqOgtw@mail.gmail.com>

This is (more or less) a chapter from Jim Hodges' book called Richly
Parameterized Linear Models: Additive, Time Series, and Spatial Models
Using Random Effects. The chapter goes through the classical interpretation
of a random effect in an experimental setting and then more modern
interpretations. It is VERY in line with Richard McElreath's general
interpretation of random effects in his statistical rethinking book.

http://www.biostat.umn.edu/~hodges/PubH8492/Hodges-ClaytonREONsubToStatSci.pdf

On Tue, Oct 9, 2018 at 5:45 AM Mario Garrido <gaadio at post.bgu.ac.il> wrote:

> Dear lme4users,
> I have some conceptual doubts on understanding the meaning of some random
> factors.
>
> Briefly, I am checking the dynamics of infection by bacteria on individuals
> from 3 different species of hosts. I am trying to fit my data to a
> generalized linear model with repeated measures. My data consists on the
> amount
> of bacterial colonies  (Myc.qPCR) at different time points (day) fin the
> blood of the 33 individual hosts (exp.ID), belonging to 3 different
> species  (sp). At time zero all the values are 0 cause the indivuals were
> still not infected.
> As I want to check whether the dynamics in the three species are different
> I included in my first model day*sp as fixed factor
>
> I am trying to fit the random effect but I have some problems with the
> interpretation. Any reading recommendations for Ecologists that we are not
> experts in statistics to understand the ecological meaning of random
> effects?
>
> I know for use that I want to control  for variance at individual level so,
> |exp.ID is needed, I also want to 'force the intercept to be zero (since at
> day zero amount of bacteria is zero) , and I also wonder whether I have to
> nest the individuals within day.
> Thus, my model would be
>
>
>
> lme(lg(Myc.qPCR)~day*sp,random=?,method="ML")
>
> And I have doubts on how to define my random effect, cause, indeed, I do
> not know what is the exact meaning of them under lme4. I understand that as
> I have a Mixed-effects model with temporal pseudoreplication I hould use
> day in the random factor, but how to include that intercept is zero?
> (1|exp.ID)
> (day|exp.ID)
> (0+day|exp.ID)
> +(1|exp.ID)+(0+day|exp.ID)
>
> Thanks!
>
> --
> Mario Garrido Escudero, PhD
> Dr. Hadas Hawlena Lab
> Mitrani Department of Desert Ecology
> Jacob Blaustein Institutes for Desert Research
> Ben-Gurion University of the Negev
> Midreshet Ben-Gurion 84990 ISRAEL
>
> gaiarrido at gmail.com; gaadio at post.bgu.ac.il
> phone: (+972) 08-659-6854
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 




Thanks,
John


John Poe, Ph.D.
Postdoctoral Scholar / Research Methodologist
Center for Public Health Services & Systems Research
University of Kentucky
www.johndavidpoe.com

	[[alternative HTML version deleted]]


From j@z@vr@kidis m@ili@g off @ki@@l  Wed Oct 10 12:45:47 2018
From: j@z@vr@kidis m@ili@g off @ki@@l (j@z@vr@kidis m@ili@g off @ki@@l)
Date: Wed, 10 Oct 2018 10:45:47 +0000
Subject: [R-sig-ME] GLS with small-sample-sizes corrections
Message-ID: <0e8a3ae04b6648639db9a80fbffccffc@EXCH-D02.nki.nl>

Dear all,

My question is more theoretical I guess and less practical. Is it possible/necessary/appropriate to apply small-sample-size corrections, such as Satterthwaite and Kenward-Roger approximation, in a marginal model via GLS ? So no random parts, but only covariance structure... I am working with datasets of 5-10 observations per group. I already use the REML instead of the conventional ML, but I was wondering if this is not enough. Although a quick check I did, gave small to none differences between with and without these corrections... 

And of course, if the answer is "yes, you should apply them", can you tell me if and how can I do it in R with lme4/nlme ? I currently use the nlme::gls() function...


Kind regards,

John Zavrakidis

Junior Researcher - Statistician
Department of Epidemiology and Biostatistics

e-mail:  j.zavrakidis at nki.nl





The Netherlands Cancer Institute | Plesmanlaan 121 | 1066 CX AMSTERDAM | www.nki.nl



This e-mail is intended for the addressee(s) eyes only. If you are not the intended recipient, you are hereby kindly requested to inform the sender of this. In view of the electronic nature of this communication, The Netherlands Cancer Institute (NKI) is neither liable for the proper and complete transmission of the information contained therein nor for any delay in its receipt. For information about the Netherlands Cancer Institute, go to www.nki.nl.


Dit e-mailbericht is uitsluitend bestemd voor de geadresseerde(n). Als dit bericht niet voor u bestemd is, wordt u vriendelijk verzocht dit aan de afzender te melden. Het Antoni van Leeuwenhoek  (AVL) staat door de elektronische verzending van dit bericht niet in voor de juiste en volledige overbrenging van de inhoud, noch voor tijdige ontvangst daarvan. Voor informatie over het AVL raadpleegt u www.avl.nl


From t@h@@omidi@n @ending from vuw@@c@nz  Wed Oct 10 12:52:52 2018
From: t@h@@omidi@n @ending from vuw@@c@nz (Taha Omidian)
Date: Wed, 10 Oct 2018 10:52:52 +0000
Subject: [R-sig-ME] LMER-CorpusData
In-Reply-To: <25d38071-213b-7a42-bcb2-92f0de8fd6c5@mpi.nl>
References: <E807D6B5-D058-4CF0-8288-48D083972227@staff.vuw.ac.nz>
 <25d38071-213b-7a42-bcb2-92f0de8fd6c5@mpi.nl>
Message-ID: <CEF350EB-9B44-4A8E-BB7E-71D1B09AC9EE@staff.vuw.ac.nz>

Hi Philip,

Thanks so much for your reply.

I think the best way to describe the data is to start with the aim of our study. The purpose of our study is to investigate the effect of discipline, genre, and level of study on the use certain word combinations in learner writing. To represent learner writing, we compiled a corpus of texts collected from students in 30 different disciplines and at four levels of study. Texts in the corpus were then categorised based on their genres (13 genres).

Following this, we classified the disciplines into four major disciplinary groupings. Genres were also grouped under 5 broad categories based on their social purposes. We then search the corpus for the occurrence of 278 word combinations (e.g., on the other hand) and recorded their normalised frequency of occurrence for each text (labeled as ref.norm in our data).

To me, our data is structured in a hierarchical fashion (for each predictor). So here is what we have in our data:

-Students (student_id col) contributed multiple texts (id col)

-Each text is nested within different disciplines (discipline col) which are clustered within four disciplinary groupings (disciplinaryGroup col)

-Each text is nested within genres (genreFamily col) which are grouped into five genre groups (genreGroup col)

-Each text is nested within four levels of study (level col)

Predictors (based on the labels in our data) are: disciplinaryGroup, genreGroup, level
Dependent variable (based on its label in our data) is: ref.norm

So I need to know how this nested structure can be reflected in a LME model.

As always thanks for your help.

T

On Oct 9, 2018, at 11:10 PM, Phillip Alday <phillip.alday at mpi.nl<mailto:phillip.alday at mpi.nl>> wrote:

I don't think this is the model you're looking for...

1. It's really weird to have your predictors in one dataframe and your
dependent variable in a different one. Are you really sure that the rows
line up like you think they do? If so, why not join the dataframes
earlier (with merge(), plyr::join() or dplyr::join())?

I'm overall quite nervous about namespaces / scope / etc. in your code
-- using attach() isn't recommended practice, especially when you mix
and match things (e.g. your levelX variables aren't in your dataframe,
but the other predictors are). You have to be really careful to make
sure you're using the data you think you're using.

You can do it like you have it, but it makes me very nervous in terms of
computing what you think you're computing.

2. Your levels include the same predictor in both the fixed effects and
as a grouping variable (the part of the random effect after the |) .
This generally doesn't make sense -- there are a number of posts on this
mailing list to that effect (see also
https://apac01.safelinks.protection.outlook.com/?url=https%3A%2F%2Frpubs.com%2FINBOstats%2Fboth_fixed_random&amp;data=02%7C01%7Ctaha.omidian%40vuw.ac.nz%7C4f9c8008c76b4354479908d62dcf77f8%7Ccfe63e236951427e8683bb84dcf1d20c%7C0%7C0%7C636746766469897297&amp;sdata=nDnQofQVnta%2BUlvfdGI1z5PiNxkai0AXW59Uy368xUU%3D&amp;reserved=0 and
https://apac01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.muscardinus.be%2F2017%2F08%2Ffixed-and-random%2F&amp;data=02%7C01%7Ctaha.omidian%40vuw.ac.nz%7C4f9c8008c76b4354479908d62dcf77f8%7Ccfe63e236951427e8683bb84dcf1d20c%7C0%7C0%7C636746766469897297&amp;sdata=7D%2FgIEUAJ%2BCOmR%2BrpNRtU49jyOtXDZk33cz5h9Ke04Y%3D&amp;reserved=0) -- but it depends
on your data.

In other words, seeing your model specification isn't quite enough -- we
also need to know something about your data, more than your variable
names alone reveal. Even though I work a lot with language data, I still
can't tell enough from your variable names and code what your data
actually represent.


Best,
Phillip




On 10/08/2018 12:46 AM, Taha Omidian wrote:
Hello,

I?m trying to fit a mixed effects model to my corpus data. The data has a hierarchical structure. I need to make sure that the final model reflects this nested structure.

My final model looks like this:

theMdl<-lmer(dis.norm.j$transformed~disciplinaryGroup+genreGroup+level+(1|student_id)+(1|levelA)+(1|levelB)+(1|levelC),data=thedata, control=lmerControl("bobyqa?))

where

LevelA is genreGroup:genreFamily:student_id
levelB is disciplinaryGroup:discipline:student_id
levelC is level:student_id

Here is a link to my data and R script: https://apac01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.dropbox.com%2Fsh%2F46r6lv6n89bromk%2FAABMc8MQmAYhRC3ubJ0Ii7Wma%3Fdl%3D0&amp;data=02%7C01%7Ctaha.omidian%40vuw.ac.nz%7C4f9c8008c76b4354479908d62dcf77f8%7Ccfe63e236951427e8683bb84dcf1d20c%7C0%7C0%7C636746766469897297&amp;sdata=%2FnFwGE4shUmS2L1QGO0ExQ0jh49iyLMCj7xhx9%2BX2yI%3D&amp;reserved=0

Thanks

Taha
_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://apac01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Ctaha.omidian%40vuw.ac.nz%7C4f9c8008c76b4354479908d62dcf77f8%7Ccfe63e236951427e8683bb84dcf1d20c%7C0%7C0%7C636746766469897297&amp;sdata=lutNcUBM2okGBj2fpYUhH216af55V1lfnr49U47LRkE%3D&amp;reserved=0


	[[alternative HTML version deleted]]


From p@uljohn32 @ending from gm@il@com  Wed Oct 10 17:21:50 2018
From: p@uljohn32 @ending from gm@il@com (Paul Johnson)
Date: Wed, 10 Oct 2018 10:21:50 -0500
Subject: [R-sig-ME] ordinal mixed model - which one to use?
In-Reply-To: <2815fc18-15f6-baba-682e-23cc9b84bbd7@uni-potsdam.de>
References: <2815fc18-15f6-baba-682e-23cc9b84bbd7@uni-potsdam.de>
Message-ID: <CAErODj8L+xOiRYAxEBGkAo_TTeaSaj-2AJjFKaE2W22Zb1JheQ@mail.gmail.com>

Hey, everybody

On Diana's link question, Would a comparison of the AIC or BIC be
informative for choice of link? We've been exploring that in our group and
majority says yes.

I don't know reasons people prefer cloglog. Except when using binary model
as proxy for hazard/survival, I wonder what other reasons for cloglog.

Paul Johnson
University of Kansas


On Tue, May 29, 2018, 1:31 PM Diana Michl <dmichl at uni-potsdam.de> wrote:

> Dear List,
>
> I'm fitting ordinal mixed models with package {ordinal}. I have a clmm
> with 1 predictor (fixed effect, factor with 2 levels "woe" and "meta"),
> 2 random effects, and an ordinal outcome, ratings from 1-4. Items=82,
> n=26. My question: Do I use
>
> link="logit" or link="cloglog"? Or something else all together?
>
> For all I know, cloglog is rather used when higher outcomes are more
> likely, but it also depends on the model fit. I thought cloglog made
> sense here b/c I have 53 cases of "woe" and 29 cases of "meta". "woe"
> are conceptually more likely to be rated as 4 or 3 (higher events).
> If this is incorrect, please correct me.
>
> In my logit model, I get a ridiculously huge odds ratio - but much
> better fit.
> In my cloglog model, the odds ratio is still worryingly large, but less
> a tenth, while the fit is much worse. I post the outputs below.
>
> A few remarks: Overall, I don't understand the huge OR. I have an
> extremely similar dataset (items=80, n=28) where the OR with the logit
> model are just 4.7 and the cloglog OR are only 2.73. So that seems fine.
> The difference between dataset 2 and the problematic one is the means:
> Their difference is much bigger in the problematic dataset:
>
> #mean of typ meta = 1.27
>
> #mean of typ woe = 3.42
>
> as opposed to dataset 2:
>
> #mean of typ meta = 2.35
>
> #mean of typ woe = 3.02
>
>
> Output logit model with link="logit":
>
>
> > summary(m) Cumulative Link Mixed Model fitted with the Laplace
> approximation formula: rat ~ typ + (1 | itemid) + (1 | Vp) data: nwmeta
> link threshold nobs logLik AIC niter max.grad cond.H logit equidistant
> 2132 -1682.63 3375.25 215(1094) 2.68e-04 3.6e+01 Random effects: Groups
> Name Variance Std.Dev. itemid (Intercept) 0.8829 0.9396 Vp (Intercept)
> 0.7831 0.8849 Number of groups: itemid 82, Vp 26 Coefficients: Estimate
> Std. Error z value Pr(>|z|) typwoe 6.0994 0.2846 21.43 <2e-16 *** ---
> Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 Threshold
> coefficients: Estimate Std. Error z value threshold.1 1.73903 0.26937
> 6.456 spacing 1.96709 0.07206 27.299 OR(typwoe) = 429.57
>
> cloglog model:
>
> > summary(mcloglog) Cumulative Link Mixed Model fitted with the Laplace
> approximation formula: rat ~ typ + (1 | itemid) + (1 | Vp) data: nwmeta
> link threshold nobs logLik AIC niter max.grad cond.H cloglog flexible
> 2132 -1735.62 3483.24 352(2061) 1.48e-05 7.1e+01 Random effects: Groups
> Name Variance Std.Dev. itemid (Intercept) 0.3774 0.6143 Vp (Intercept)
> 0.3413 0.5842 Number of groups: itemid 82, Vp 26 Coefficients: Estimate
> Std. Error z value Pr(>|z|) typwoe 3.7495 0.1763 21.27 <2e-16 *** ---
> Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 Threshold
> coefficients: Estimate Std. Error z value 1|2 0.4984 0.1704 2.926 2|3
> 1.6293 0.1780 9.153 3|4 3.0036 0.1864 16.113
>
>
>
> OR(typwoe) = 40.69
>
>
>
>
>
> comparison:
>
> > anova(mcloglog, m) Likelihood ratio tests of cumulative link models:
> formula: link: threshold: mcloglog rat ~ typ + (1 | itemid) + (1 | Vp)
> cloglog flexible m rat ~ typ + (1 | itemid) + (1 | Vp) logit flexible
> no.par AIC logLik LR.stat df Pr(>Chisq) mcloglog 6 3483.2 -1735.6 m 6
> 3376.6 -1682.3 106.67 0
>
>
> My sd seems fine at 1.26. Checking for outliers and several model
> assumptions isn't possible for a clmm.
>
> Thanks very much in advance for any input
>
> --
> Diana Michl
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From @rive046 @ending from uott@w@@c@  Wed Oct 10 22:26:35 2018
From: @rive046 @ending from uott@w@@c@ (Stephanie Rivest)
Date: Wed, 10 Oct 2018 16:26:35 -0400
Subject: [R-sig-ME] model estimates in glmmTMB
Message-ID: <CAAYeMWHR=xvVPtnRxzQVyue67VbretkOk6V3UxviaaPWDS8O9A@mail.gmail.com>

Hi there,

I'm hoping to get some clarification on interpreting the model estimates
from the output of a glmmTMB. I fit a model using this package where my
response was zero-inflated count data. I had multiple continuous and
categorical predictors and a random effect of site.

My question relates to the sign of the model estimates. It is my intuition
that the sign of the model estimates (+ or -) indicates the direction of
effect. Therefore, when back-transforming model estimates to get them on
the scale of the response, I *would not* include the sign in this
calculation.

For example, from the model output below, I would conclude that the
predictor CanopyCover significantly (although only marginally) and
negatively affected my response variable. Back-transforming this estimate
should work if I simply take e^(2.6705) which results in the interpretation
that counts decrease by 14.4 for every 1 unit increase in canopy. Is this
correct? Does the sign actually need to be included when back-transforming?

Conditional model:
                              Estimate   Std. Error z value Pr(>|z|)
(Intercept)              0.1274      0.7162   0.178    0.85882
Grass                     -0.7919     0.7340  -1.079    0.28060
AllFlowers              1.9984      1.8340   1.090    0.27589
CanopyCover         -2.6705     1.3044  -2.047    0.04062 *
avg.bft                     3.1577     6.5799   0.480    0.63130
season.bft1              0.6337     0.3705   1.710    0.08719 .
occur.bft1                 0.6664     0.2560   2.603    0.00925 **
DisturbanceLevel2   0.2997     0.7239   0.414    0.67883
DisturbanceLevel3   1.5339     0.7170   2.139    0.03240 *
DisturbanceLevel4   0.7870     0.7743   1.016    0.30945

Also, what does it mean if the intercept is negative? For example, in the
output above, the intercept represents the baseline level for my
categorical predictors. For arguments sake, if the intercept was negative
would this represent that at the baseline level, the model is predicting
negative counts?

Any help would be greatly appreciated!

Thanks!
Stephanie Rivest

	[[alternative HTML version deleted]]


From kog@n@cl@rk @ending from gm@il@com  Thu Oct 11 23:26:31 2018
From: kog@n@cl@rk @ending from gm@il@com (Clark Kogan)
Date: Thu, 11 Oct 2018 14:26:31 -0700
Subject: [R-sig-ME] GLMM estimates and confidence intervals for average
 predicted probability
Message-ID: <CAJXvfGQ1-w3ShbH4YqhQsK7oBDrD+cFOz+K00OncMbwDCk0O5A@mail.gmail.com>

I am trying to get a sense as to whether there is a standard accepted
method for producing estimates of the probability averaged over yet
unobserved individuals along with confidence intervals on the average
probability for mixed effects logistic regression.


The basic question is this: for a particular set of covariates, what is the
average probability that people will choose the response y = 1, and how
confident are we in this average.


I have been using the following method:

For the estimate of the average probability, I predict the probability of
y=1 for each individual in the data, and then average the probability over
these individuals. For confidence intervals, I use the non-parametric
bootstrap percentile method (bootstrapping individuals and using the
previous method to estimate the average probability). This typically takes
a while to finish, which is ok, though if there were a quicker Frequentist
method (I know Bayesian methods are probably a lot quicker here), that
would be nice.


My questions are:

1) Is this in line with what people would suggest?

2) Is there literature available that recommends this approach.


I'm thinking Gelman's Data Analysis Using Regression and
Multilevel/Hierarchical Models (p 101) for estimation by first predicting
and then averaging, however, he focuses on predictive differences (which is
not what I'm looking at here), though I assume the suggestion would hold
for estimating average probabilities that do not involve differences.


For the confidence intervals, it is sort of touched on in the GLMM FAQ:
https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html

by mentioning that none of the suggested approaches for confidence
intervals / prediction intervals take into account the random effects.


Thanks,

Clark

	[[alternative HTML version deleted]]


From d@rizopoulo@ @ending from er@@mu@mc@nl  Fri Oct 12 08:37:56 2018
From: d@rizopoulo@ @ending from er@@mu@mc@nl (D. Rizopoulos)
Date: Fri, 12 Oct 2018 06:37:56 +0000
Subject: [R-sig-ME] GLMM estimates and confidence intervals for average
 predicted probability
In-Reply-To: <CAJXvfGQ1-w3ShbH4YqhQsK7oBDrD+cFOz+K00OncMbwDCk0O5A@mail.gmail.com>
References: <CAJXvfGQ1-w3ShbH4YqhQsK7oBDrD+cFOz+K00OncMbwDCk0O5A@mail.gmail.com>
Message-ID: <7191AFC7255B4F49A30707E39BEAD05FDEBA2D25@EXCH-HE03.erasmusmc.nl>

This is implemented in my GLMMadaptive package (https://drizopoulos.github.io/GLMMadaptive/). In particular, function marginal_coefs() computes coefficients with a marginal interpretation that link covariates to the marginal probabilities (i.e., the probabilities of y = 1 given covariates averaged over the subjects). Based on these coefficients, you can calculate effects and predictions; for more info check the vignette: https://drizopoulos.github.io/GLMMadaptive/articles/Methods_MixMod.html (especially Sections Marginalized Coefficients, Effect Plots, and Predictions).

Best,
Dimitris


-----Original Message-----
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Clark Kogan
Sent: Thursday, October 11, 2018 11:27 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] GLMM estimates and confidence intervals for average predicted probability

I am trying to get a sense as to whether there is a standard accepted method for producing estimates of the probability averaged over yet unobserved individuals along with confidence intervals on the average probability for mixed effects logistic regression.


The basic question is this: for a particular set of covariates, what is the average probability that people will choose the response y = 1, and how confident are we in this average.


I have been using the following method:

For the estimate of the average probability, I predict the probability of
y=1 for each individual in the data, and then average the probability over these individuals. For confidence intervals, I use the non-parametric bootstrap percentile method (bootstrapping individuals and using the previous method to estimate the average probability). This typically takes a while to finish, which is ok, though if there were a quicker Frequentist method (I know Bayesian methods are probably a lot quicker here), that would be nice.


My questions are:

1) Is this in line with what people would suggest?

2) Is there literature available that recommends this approach.


I'm thinking Gelman's Data Analysis Using Regression and Multilevel/Hierarchical Models (p 101) for estimation by first predicting and then averaging, however, he focuses on predictive differences (which is not what I'm looking at here), though I assume the suggestion would hold for estimating average probabilities that do not involve differences.


For the confidence intervals, it is sort of touched on in the GLMM FAQ:
https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html

by mentioning that none of the suggested approaches for confidence intervals / prediction intervals take into account the random effects.


Thanks,

Clark

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From thom@@merkling00 @ending from gm@il@com  Fri Oct 12 11:12:01 2018
From: thom@@merkling00 @ending from gm@il@com (Thomas Merkling)
Date: Fri, 12 Oct 2018 11:12:01 +0200
Subject: [R-sig-ME] model estimates in glmmTMB
Message-ID: <ab2b1745-4ca0-b2bb-f872-d3066c3a8eef@gmail.com>

Hi Stephanie,

First, I think you should try to simplify your model (unless you have 
good reasons to keep the non-significant variables in your model), this 
will likely influence the other estimates. Also, I wouldn't rely on the 
p-values from the summary to assess the significance of your variables. 
As for your question about back-transforming to interpret the effect of 
a variable, I don't think you can just use exp(estimate)? as the 
estimate is part of a model equation involving all the parameters (e.g. 
intercept + beta1 * Grass + beta2 * AllFlowers ...) and the estimates 
are also influenced by the scale of the response variable. I usually use 
the predict function to graphically plot the effect of a given variable. 
If you're interested in knowing if a given variable has a stronger 
effect than another one, I'd recommend standardising your continuous 
variables, so that they are all on the same scale.

A negative intercept would mean that the baseline level is somewhere 
between 0 and 1 (but still positive!), as exp(-1) = 0.36.. for example.

Hope that helps,
Thomas

-- 
Dr Thomas Merkling
Website <https://sites.google.com/site/merklingthomas/>
LinkedIn Profile <https://www.linkedin.com/in/thomas-merkling-a286b6a1>

	[[alternative HTML version deleted]]


From ro@lyn@d@kin @ending from gm@il@com  Fri Oct 12 20:12:22 2018
From: ro@lyn@d@kin @ending from gm@il@com (Roslyn Dakin)
Date: Fri, 12 Oct 2018 14:12:22 -0400
Subject: [R-sig-ME] MCMCglmm and multimembership analysis
Message-ID: <CAJBOW-sv2AErv3fP3UfH8wu=gnMh6UNSHuTWfwUBhB9EcTxY7w@mail.gmail.com>

Dear List,

I have two questions about MCMCglmm and multimembership models (aka
multiple membership models).

I am using these models to study social influence. In my scenario, the
focal individuals express a phenotype (the dependent variable) depending on
their social environment. The social environment is made up of other
individuals. For example:
MCMCglmm(phenotype ~ 1, random = ~focalID + mm(partnerID1 + partnerID2 +
partnerID2), data=data)
...but the partners are also weighted (i.e., some interact more closely
with the focal than others).

Q1: Can MCMCglmm specify weights for the multimembership structure?

I have been able to do this in brms, but I haven?t seen an example for how
the weights could be done in MCMCglmm.

The second part of my question stems from the fact that a given individual
can act both as a focal and a partner, and I am specifically interested in
the covariance between these two sources of variation. (i.e., I would like
to be able to evaluate whether IDs that score highly on the phenotype also
elicit higher levels of the phenotype in others, using the same model.) In
a simpler, non-multimembership scenario, I would model this covariance as:
MCMCglmm(phenotype ~ 1, random = ~str(focalID + partnerID), rcov = ~units,
data=data)

Q2: Can MCMCglmm accommodate the covariance between a single
multimembership structure and focalID, in the same model?
?e.g., something like this:
MCMCglmm(phenotype ~ 1, random = ~str(focalID + mm(partnerID1 + partnerID2
+ partnerID3)), rock = ~units, data=data)
I have verified that brms doesn't currently have the functionality to do
this.

Any guidance is greatly appreciated.
Thank you!


-- 

Roslyn Dakin, PhD
Postdoctoral Fellow
Smithsonian Conservation Biology Institute
and the University of Ottawa

Website and blog: roslyndakin.com
Email: roslyn.dakin at gmail.com

	[[alternative HTML version deleted]]


From b@ud-bovy@g@briel @ending from h@r@it  Mon Oct 15 14:53:24 2018
From: b@ud-bovy@g@briel @ending from h@r@it (Gabriel Baud-Bovy)
Date: Mon, 15 Oct 2018 14:53:24 +0200
Subject: [R-sig-ME] Response time modeling: Warning message with non-normal
 RAs
Message-ID: <fc73fbf5-de6f-8d50-43b9-6e3571924487@hsr.it>

Dear all,

I have a dataset with response times of 200 participants measured 36 time in different conditions.
The RTs distribution is right skewed as it is generally the case for RTs. I would like to avoid transform them
(see Lo & Andrew (2015)](https://www.frontiersin.org/articles/10.3389/fpsyg.2015.01171/full).
However, I often encounter warning messages with this dataset with a GLMM with Gamma
distribution and identity link. The problem is not caused by an over parametrization as it arises
even in the case in a intercept only model.

> fit <- glmer(choice.lat ~ 1 + (1|su), data=dat, family=Gamma(link="identity"))
Warning messages:
1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model failed to converge with max|grad| = 0.220808 (tol = 0.001, component 1)
2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model is nearly unidentifiable: very large eigenvalue
 - Rescale variables?

> fit
Generalized linear mixed model fit by maximum likelihood (Laplace
  Approximation) [glmerMod]
 Family: Gamma  ( identity )
Formula: choice.lat ~ 1 + (1 | su)
   Data: dat
      AIC       BIC    logLik  deviance  df.resid
 22629.26  22649.78 -11311.63  22623.26      6914
Random effects:
 Groups   Name        Std.Dev.
 su       (Intercept) 0.8477
 Residual             0.5721
Number of obs: 6917, groups:  su, 200
Fixed Effects:
(Intercept)
      3.044
convergence code 0; 2 optimizer warnings; 0 lme4 warnings

The dispersion parameter of the estimated Gamma distribution is  sigma(fit.glmer)^2 = 0.327, which
fits reasonably well the RTs.

After some poking around, I figured out that the problem probably comes from the
fact that the participants means are NOT distributed normally.  In fact, their distribution
is similarly skewed. Removing the two extreme subjects or using a log link function "solves" the convergence
problem but I don't like either solution because the is no valid reason to exclude these subjects
and using a log transform cause theoretical problems when one want to interpret
effects of more complex models (see Lo & Andrew (2015)).

I have seen many discussions of about warning message/convergence problem (
e.g. https://rstudio-pubs-static.s3.amazonaws.com/33653_57fc7b8e5d484c909b615d8633c01d51.html).
The usual advice is to try with different optimizers and/or simplify the model, which do not help here (they all give
similar warning messages).  I have two questions:

1) Can somebody explain intuitively why non-normal random effects lead to warning
   messages ?  I would have naively assumed that it would simply lead to large a large variance estimate.

2) Is there something within the lme4 framework  to tackle this problem? Should I
   simply ignore the warning messages ?

3) What principle approach would you suggest ? I have  seen that brms allow in principle to specify
   non-normal random effect (I think that only student  is implemented so far) but I haven't tried yet.

Here is a toy problem that reproduces the issue (it depends on the seed actually). Depending
on the choice of the dispersion parameter for the RAs, it is possible also to induce convergence
problem.

# artificial data set
nsu <- 200
nrep <- 36
mu <- 3.0      # mean RT
phi.su <- 0.8  # dispersion participants
phi <- 0.3     # dispersion
d <- expand.grid(
  su = paste0("S",1:nsu),
  rep = 1:nrep,
  mu =NA,
  rt = NA)

set.seed(125)
# generate 200 gamma distributed  participant means
mu.su <- sort(rgamma(nsu, shape=1/phi.su, scale=phi.su*mu))
d$mu <- mu.su[d$su]
# add Gamma noise
d$rt <- rgamma(nsu*nrep,shape=1/phi,scale=phi*d$mu)
# fit intercept GLMM model
D

# histogram of participant means and response times
par(mfrow=c(1,2))
hist(mu.su,n=50)
hist(d$rt,n=200,xlim=c(0,10))

> all_fit(fit)
bobyqa. : [OK]
Nelder_Mead. : [OK]
optimx.nlminb : [OK]
optimx.L-BFGS-B : [OK]
nloptwrap.NLOPT_LN_NELDERMEAD : [OK]
nloptwrap.NLOPT_LN_BOBYQA : [OK]
nmkbw. : [OK]
....
were 13 warnings (use warnings() to see them)
1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  ... :
  Model failed to converge with max|grad| = 0.215844 (tol = 0.001, component 1)
2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  ... :
  Model is nearly unidentifiable: very large eigenvalue
 - Rescale variables?
3: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  ... :
  Model failed to converge with max|grad| = 0.220808 (tol = 0.001, component 1)
4: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  ... :
  Model is nearly unidentifiable: very large eigenvalue
 - Rescale variables?
5: In optwrap(optimizer, devfun, start, rho$lower, control = control,  ... :
  convergence code 1 from optimx
6: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  ... :
  Model failed to converge with max|grad| = 0.215713 (tol = 0.001, component 1)
7: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  ... :
  Model is nearly unidentifiable: very large eigenvalue
 - Rescale variables?
8: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  ... :
  Model failed to converge with max|grad| = 0.102562 (tol = 0.001, component 1)
9: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  ... :
  Model failed to converge with max|grad| = 0.109779 (tol = 0.001, component 1)
10: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  ... :
  Model failed to converge with max|grad| = 0.109779 (tol = 0.001, component 1)
11: In optwrap(optimizer, devfun, start, rho$lower, control = control,  ... :
  convergence code 2 from nmkbw
12: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  ... :
  Model failed to converge with max|grad| = 0.220811 (tol = 0.001, component 1)
13: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  ... :
  Model is nearly unidentifiable: very large eigenvalue
 - Rescale variables?


Thank you,

Gabriel


--
---------------------------------------------------------------------
Gabriel Baud-Bovy               tel.: (+39) 348 172 4045     (mobile)
UHSR University                       (+39) 02 2643 3429 (laboratory)
via Olgettina, 58                     (+39) 02 9175 1540  (secretary)
20132 Milan, Italy              email:       gabriel.baud-bovy at hsr.it<mailto:gabriel.baud-bovy at hsr.it>
---------------------------------------------------------------------



Rispetta l?ambiente: non stampare questa mail se non ? necessario.
Respect the environment: print this email only if necessary.

	[[alternative HTML version deleted]]


From y@@hree19 @ending from gm@il@com  Tue Oct 16 19:03:27 2018
From: y@@hree19 @ending from gm@il@com (Yashree Mehta)
Date: Tue, 16 Oct 2018 19:03:27 +0200
Subject: [R-sig-ME] Dependency structure
Message-ID: <CAOE=hqLskrB+f1fnq2Uw-XYNbVyenYby4o=_ZecK5336D-=U3Q@mail.gmail.com>

Hi,

Is there literature on how to specify the dependency structure between the
random intercept and the statistical noise error term in a random intercept
model?
It would be useful to also know how to implement using R...

Thank you

Yashree

	[[alternative HTML version deleted]]


From m@n@pend @ending from ntuzov@com  Tue Oct 16 23:14:56 2018
From: m@n@pend @ending from ntuzov@com (Nik Tuzov)
Date: Tue, 16 Oct 2018 21:14:56 +0000 (UTC)
Subject: [R-sig-ME] Weighted regression in REML
References: <1070079121.11021335.1539724496863.ref@mail.yahoo.com>
Message-ID: <1070079121.11021335.1539724496863@mail.yahoo.com>

Hello:
I'm reading the book of Searle:
http://www.leg.ufpr.br/~eder/Variance%20Components.pdf

I think that equation 53 on p 276 suggests that if one wants to use weights in REML, the solution is very similar to that in OLS: multiply X, Z, and Y by the square root of the weight matrixand proceed as in unweighted case. Am I right or there is more that needs to be done?
Regards,Nik

	[[alternative HTML version deleted]]


From m@n@pend @ending from ntuzov@com  Tue Oct 16 23:17:39 2018
From: m@n@pend @ending from ntuzov@com (Nik Tuzov)
Date: Tue, 16 Oct 2018 21:17:39 +0000 (UTC)
Subject: [R-sig-ME] Weighted regression in REML
References: <529404307.11062962.1539724659849.ref@mail.yahoo.com>
Message-ID: <529404307.11062962.1539724659849@mail.yahoo.com>

Hello:
I'm reading the book of Searle:
http://www.leg.ufpr.br/~eder/Variance%20Components.pdf

I think that equation 53 on p 276 suggests that if one wants to use weights in REML, the solution is very similar to that in OLS: multiply X, Z, and Y by the square root of the weight matrixand proceed as in unweighted case. Am I right or there is more that needs to be done?
Regards,Nik

	[[alternative HTML version deleted]]


From m@n@pend @ending from ntuzov@com  Tue Oct 16 23:16:07 2018
From: m@n@pend @ending from ntuzov@com (Nik Tuzov)
Date: Tue, 16 Oct 2018 21:16:07 +0000 (UTC)
Subject: [R-sig-ME] Weighted regression in REML
References: <1606529909.11061754.1539724568007.ref@mail.yahoo.com>
Message-ID: <1606529909.11061754.1539724568007@mail.yahoo.com>

Hello:
I'm reading the book of Searle:
http://www.leg.ufpr.br/~eder/Variance%20Components.pdf

I think that equation 53 on p 276 suggests that if one wants to use weights in REML, the solution is very similar to that in OLS: multiply X, Z, and Y by the square root of the weight matrixand proceed as in unweighted case. Am I right or there is more that needs to be done?
Regards,Nik

	[[alternative HTML version deleted]]


From m@n@pend @ending from ntuzov@com  Tue Oct 16 23:21:48 2018
From: m@n@pend @ending from ntuzov@com (Nik Tuzov)
Date: Tue, 16 Oct 2018 21:21:48 +0000 (UTC)
Subject: [R-sig-ME] Weighted regression in REML
References: <1435233226.11048314.1539724908472.ref@mail.yahoo.com>
Message-ID: <1435233226.11048314.1539724908472@mail.yahoo.com>

Hello:
I'mreading the book of Searle:
http://www.leg.ufpr.br/~eder/Variance%20Components.pdf
Ithink that equation 53 on p 276 suggests that if one wants to useweights in REML, the solution is very similar to that in OLS:multiply X, Z, and Y by the square root of the weight matrix?andproceed as in unweighted case. Am I right or there is more that needsto be done?
Regards, Nik

	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Wed Oct 17 02:27:36 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Tue, 16 Oct 2018 20:27:36 -0400
Subject: [R-sig-ME] Weighted regression in REML
In-Reply-To: <1606529909.11061754.1539724568007@mail.yahoo.com>
References: <1606529909.11061754.1539724568007.ref@mail.yahoo.com>
 <1606529909.11061754.1539724568007@mail.yahoo.com>
Message-ID: <a483cb3b-b15a-d30f-b7b2-65e97c2bef20@gmail.com>


  Can I please request that in general people **not** use this list to
post links to material that is (presumably) violating the
authors'/publisher's wishes? (A screenshot of a particular equation
would seem to constitute "fair use" ...)

  FWIW your statement sounds correct to me -- in the Bates et al.
JSS/lmer paper (available via vignette("lmer", package="lme4")), the
development of the estimation procedure mostly leaves the weights out
for simplicity, but says:

"To allow for case weights, we save the products X^? W X, X^? W y, Z^? W
X, Z^? W y and Z^? W Z (see Table 6)."

  W is the weight matrix, so this is equivalent to multiplying X, y, Z
by W^(1/2) ...

  cheers
    Ben Bolker


On 2018-10-16 05:16 PM, Nik Tuzov wrote:
> Hello:
> I'm reading the book of Searle:
> http://www.leg.ufpr.br/~eder/Variance%20Components.pdf
> 
> I think that equation 53 on p 276 suggests that if one wants to use weights in REML, the solution is very similar to that in OLS: multiply X, Z, and Y by the square root of the weight matrixand proceed as in unweighted case. Am I right or there is more that needs to be done?
> Regards,Nik
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From bbolker @ending from gm@il@com  Wed Oct 17 02:34:59 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Tue, 16 Oct 2018 20:34:59 -0400
Subject: [R-sig-ME] Dependency structure
In-Reply-To: <CAOE=hqLskrB+f1fnq2Uw-XYNbVyenYby4o=_ZecK5336D-=U3Q@mail.gmail.com>
References: <CAOE=hqLskrB+f1fnq2Uw-XYNbVyenYby4o=_ZecK5336D-=U3Q@mail.gmail.com>
Message-ID: <a9e4d806-0e47-33c1-f1f4-ff5e23dd0240@gmail.com>


> Hi,
>
> Is there literature on how to specify the dependency structure between the
> random intercept and the statistical noise error term in a random
intercept
> model?
> It would be useful to also know how to implement using R...


  Can you be more specific about what you want?  Suppose you have
observations j within groups i, and you have an epsilon_{0,ij} for each
observation (error term) and an epsilon_"1,i} for each group (random
intercept).  Typically the epsilon_{0,ij} values are iid with
homogeneous variance sigma_0^2, and epsilon_{1,i} are iid with variance
sigma_1^2.  What kind of correlation structure are you looking for?

While we're at it, you previously asked:

===
I am working with a random intercept model. I have the usual "X" vector
of covariates and one id variable which will make up the random
intercept. For example,

Response variable: Production of maize
Covariate: Size of plot
ID variable: Household_ID

I need to acknowledge that there is correlation between the FIXED EFFECT
coefficient of plot size and the estimated random intercept. It is my
model assumption.

Does lme4 assume this correlation or do I have to make changes in the
formula so that it gets considered?
===

  The short answer to this one is "no", I think -- I don't know that
there's a way to allow for correlation between fixed effect coefficients
and random intercepts. (This actually seems like a weird question to me;
in the frequentist world, as far as I know, you can only specify
correlation models for *random variables* within the model.  In the
context of LMM fitting, I don't think parameters are random effects in
this sense.

On 2018-10-16 01:03 PM, Yashree Mehta wrote:

> 
> Thank you
> 
> Yashree
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From b@ud-bovy@g@briel @ending from h@r@it  Wed Oct 17 11:06:43 2018
From: b@ud-bovy@g@briel @ending from h@r@it (Baud-Bovy Gabriel)
Date: Wed, 17 Oct 2018 09:06:43 +0000
Subject: [R-sig-ME] [RE] Response time modeling: Warning message with
 non-normal RAs
In-Reply-To: <a9e4d806-0e47-33c1-f1f4-ff5e23dd0240@gmail.com>
References: <CAOE=hqLskrB+f1fnq2Uw-XYNbVyenYby4o=_ZecK5336D-=U3Q@mail.gmail.com>
 <a9e4d806-0e47-33c1-f1f4-ff5e23dd0240@gmail.com>
Message-ID: <33dcf30c-54eb-1ae1-af29-6f9e1bbe82b4@hsr.it>

My apologies for sending this post again.  I am not sure that it went
through because I did not
receive it myself (though I think my options should have let me receive
it).  Also, there was
a line missing due to hurried cut-and-paste in the example below.

Dear all,

I have a dataset with response times of 200 participants measured 36
times in different conditions.
The RTs distribution is right skewed as it is generally the case for
RTs. I would like to avoid transform them
(see Lo & Andrew
(2015)](https://www.frontiersin.org/articles/10.3389/fpsyg.2015.01171/full).
However, I often encounter warning messages with this dataset when using
a GLMM with Gamma
distribution and identity link. The problem is not caused by an over
parametrization as it arises
even in the case in a intercept only model.

 > fit <- glmer(choice.lat ~ 1 + (1|su), data=dat,
family=Gamma(link="identity"))
Warning messages:
1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
   Model failed to converge with max|grad| = 0.220808 (tol = 0.001,
component 1)
2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
   Model is nearly unidentifiable: very large eigenvalue
  - Rescale variables?

 > fit
Generalized linear mixed model fit by maximum likelihood (Laplace
   Approximation) [glmerMod]
  Family: Gamma  ( identity )
Formula: choice.lat ~ 1 + (1 | su)
    Data: dat
       AIC       BIC    logLik  deviance  df.resid
  22629.26  22649.78 -11311.63  22623.26      6914
Random effects:
  Groups   Name        Std.Dev.
  su       (Intercept) 0.8477
  Residual             0.5721
Number of obs: 6917, groups:  su, 200
Fixed Effects:
(Intercept)
       3.044
convergence code 0; 2 optimizer warnings; 0 lme4 warnings

The dispersion parameter of the estimated Gamma distribution is
sigma(fit.glmer)^2 = 0.327
with a population mean (Fixed effect) of circa  3.0 sec which fits
reasonably well the RTs.

After some poking around, I figured out that the problem probably comes
from the
fact that the participants means are NOT distributed normally.  In fact,
their distribution
is similarly skewed. Removing the two extreme subjects or using a log
link function "solves" the convergence
problem/ warning messages but I don't like either solution because the
is no valid reason to exclude these subjects
and using a log transform cause theoretical problems when one want to
interpret
effects of more complex models (see Lo & Andrew (2015)).

I have seen many discussions of about warning message/convergence problem (
e.g.
https://rstudio-pubs-static.s3.amazonaws.com/33653_57fc7b8e5d484c909b615d8633c01d51.html).
The usual advice is to try with different optimizers and/or simplify the
model, which do not help here (they all give
similar warning messages; see below).  I have two questions:

1) Can somebody explain intuitively why non-normal random effects lead
to these warning
    messages ?  I would have naively assumed that it would simply lead
to large a large variance estimate.

2) Is there something within the lme4 framework  to tackle this problem?
Should I simply ignore the
     warning messages ?

3) What principle approach would you suggest ? I have  seen that brms
allow in principle to specify
    non-normal random effect (I think that only student  is implemented
so far) but I haven't tried yet.

Here is a toy problem that reproduces the issue (it depends on the seed
actually). Depending
on the choice of the dispersion parameter for the REs, it is possible
also to induce convergence
problem.

# artificial data set
nsu <- 200
nrep <- 36
mu <- 3.0      # mean RT
phi.su <- 0.8  # dispersion participants
phi <- 0.3     # dispersion
d <- expand.grid(
   su = paste0("S",1:nsu),
   rep = 1:nrep,
   mu =NA,
   rt = NA)

set.seed(125)
# generate 200 gamma distributed  participant means
mu.su <- sort(rgamma(nsu, shape=1/phi.su, scale=phi.su*mu))
d$mu <- mu.su[d$su]
# add Gamma noise
d$rt <- rgamma(nsu*nrep,shape=1/phi,scale=phi*d$mu)

# fit intercept GLMM model (gives warning messages)
fit <- glmer(rt ~  1 + (1|su), data=d, family=Gamma(link="identity"))

# histogram of participant means and response times
par(mfrow=c(1,2))
hist(mu.su,n=50)
hist(d$rt,n=200,xlim=c(0,10))

 > all_fit(fit)
bobyqa. : [OK]
Nelder_Mead. : [OK]
optimx.nlminb : [OK]
optimx.L-BFGS-B : [OK]
nloptwrap.NLOPT_LN_NELDERMEAD : [OK]
nloptwrap.NLOPT_LN_BOBYQA : [OK]
nmkbw. : [OK]
....
were 13 warnings (use warnings() to see them)
1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
... :
   Model failed to converge with max|grad| = 0.215844 (tol = 0.001,
component 1)
2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
... :
   Model is nearly unidentifiable: very large eigenvalue
  - Rescale variables?
3: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
... :
   Model failed to converge with max|grad| = 0.220808 (tol = 0.001,
component 1)
4: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
... :
   Model is nearly unidentifiable: very large eigenvalue
  - Rescale variables?
5: In optwrap(optimizer, devfun, start, rho$lower, control = control,  ... :
   convergence code 1 from optimx
6: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
... :
   Model failed to converge with max|grad| = 0.215713 (tol = 0.001,
component 1)
7: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
... :
   Model is nearly unidentifiable: very large eigenvalue
  - Rescale variables?
8: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
... :
   Model failed to converge with max|grad| = 0.102562 (tol = 0.001,
component 1)
9: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
... :
   Model failed to converge with max|grad| = 0.109779 (tol = 0.001,
component 1)
10: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
control$checkConv,  ... :
   Model failed to converge with max|grad| = 0.109779 (tol = 0.001,
component 1)
11: In optwrap(optimizer, devfun, start, rho$lower, control = control,
... :
   convergence code 2 from nmkbw
12: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
control$checkConv,  ... :
   Model failed to converge with max|grad| = 0.220811 (tol = 0.001,
component 1)
13: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
control$checkConv,  ... :
   Model is nearly unidentifiable: very large eigenvalue
  - Rescale variables?


Thank you,

Gabriel

--
---------------------------------------------------------------------
Gabriel Baud-Bovy               tel.: (+39) 348 172 4045     (mobile)
UHSR University                       (+39) 02 2643 3429 (laboratory)
via Olgettina, 58                     (+39) 02 9175 1540  (secretary)
20132 Milan, Italy              email:       gabriel.baud-bovy at hsr.it
---------------------------------------------------------------------



Rispetta l?ambiente: non stampare questa mail se non ? necessario.
Respect the environment: print this email only if necessary.

From cri@@le@@@ndro @ending from gm@il@com  Wed Oct 17 17:50:37 2018
From: cri@@le@@@ndro @ending from gm@il@com (Cristiano Alessandro)
Date: Wed, 17 Oct 2018 10:50:37 -0500
Subject: [R-sig-ME] partial correlation and mixed models in R
Message-ID: <CAHhX7Wh1_yNzZqJ=4nOhBAnjg7tu3rgTbsKDAFhMgcH49sTXEQ@mail.gmail.com>

Hello all,

I have Nr repeated measures of four continuous variables Aij, Bij, Cij,
Dij, i=1...Nr, for each subject j=1...Ns. The repeated measures within each
subject are sequential in time, and therefore correlated. I need to compute
the correlation between each pair of the four variables, and compare the
correlations across the 6 pairs.

The initial, very naive, idea I had to perform this analysis was to compute
the Pearson correlation for each pair of variables (they are approximately
normally distributed) within each subject, and then run a linear mixed
effect models (LMEM) using the correlation coefficients as the independent
variables and subject as a random effect. I have the strong feeling this
approach is wrong though. Right?

I then figured that people have approached this problem by fitting a LMEM
directly on the variables A, B, C, D (using subject as a random effect),
specifying appropriate covariance matrices in order to reflect the
correlation between the repeated measures within subjects, as well as the
correlations between pairs of variables. Fitting such a model would give
estimates of the correlations that I need to compare.
https://www.ncbi.nlm.nih.gov/pubmed/12708508

I have the following questions:
- Do I need to use partial correlation (or something similar) when I
compute the correlation between pairs of variables to control for the
values of the remaining two variables?
- If so, how do I integrate partial correlation into the LMEM approach that
uses the variables A,B,C,D as the independent variables?
no matter how I estimates the correlations, how do I compare the
correlation coefficients across the pairs of variables? can I use Fisher?s
r to z transformation, and then compare the z scores? Still, I would need
to compare 6 pairs, not only two.
- Is the naive approach (fitting a LMEM on the correlation coefficients
previously computed) inherently wrong? why?

Thanks
Cristiano

	[[alternative HTML version deleted]]


From phillip@@ld@y @ending from mpi@nl  Wed Oct 17 18:05:44 2018
From: phillip@@ld@y @ending from mpi@nl (Phillip Alday)
Date: Wed, 17 Oct 2018 18:05:44 +0200
Subject: [R-sig-ME] LMER-CorpusData
In-Reply-To: <CEF350EB-9B44-4A8E-BB7E-71D1B09AC9EE@staff.vuw.ac.nz>
References: <E807D6B5-D058-4CF0-8288-48D083972227@staff.vuw.ac.nz>
 <25d38071-213b-7a42-bcb2-92f0de8fd6c5@mpi.nl>
 <CEF350EB-9B44-4A8E-BB7E-71D1B09AC9EE@staff.vuw.ac.nz>
Message-ID: <c7d93150-4099-6185-a2e4-0323a8d2fb17@mpi.nl>

Hi Taha,

You can use the term "collocation" with me -- it's more precise than
"word combination". ;)

What seems to be missing from your model are your particular
collocations -- are you doing a separate model for each collocation? Or
are you looking at the combined frequency of all the collocations?
Assuming the answer to one of these questions is yes (and each has its
own implications and potential pitfalls for your inferences) ...

I would massively reduce your random effects structure.  I propose the
following basic structure for the model, under the assumption that each
is only in one discipline)

ref.norm ~ 1 + disciplinaryGroup + genreGroup + level + (1|student_id)

I would seriously consider using the following interaction model, if you
have enough data to do so. Depending on which combinations of
disciplinaryGroup, genreGroup and level are present in the data, this
may give you warnings about a rank-deficient model matrix and dropped
columns, but that's okay. lme4 is just telling you that it can't
estimate interactions for combinations that didn't occur and so it won't
try.

If each student also produced texts in multiple genre groups, then I
would see if changing (1|student_id) to (1+genreGroup|student_id)
improved the fit.

Is each student measured at different levels? If so, then you can
consider doing the same thing as genreGroup for level|student_id.

I'm not sure I would include text id in the model because it's not
"repeated" in any meaningful sense and would thus be an
observation-level random effect. Text id essentially is just a way of
distinguishing between repetitions within each unit/student of the
student grouping.

Now, assuming that you don't care about particular disciplines or
genres, but rather just want to see if they account for any additional
variance beyond the coarser disciplinaryGroup and genreGroup
categorizations, you could include them as random effects:

ref.norm ~ 1 + disciplinaryGroup + genreGroup + level + (1|student_id) +
(1|discipline) + (1|genreFamily)

You don't have to explicitly nest student_id within discipline -- lme4
already picks up on that. genre is (at least partially) crossed with
student_id and discipline, and lme4 also picks up on that. (More
precisely, the mathematical formulation that lme4 uses deals with such
structures without any extra work.)  This formulation assumes that the
effects of subject/discipline and genre are additive; you could
potentially add in a (1|subject_id:genreFamily) or
(1|discipline:genreFamily), but (1) I don't think this would explain
that much more variation and (2) you would need a *lot* of data for this
to actually be meaningful and not just overfitting.

Overfitting is actually a potential problem for all of these more
overcomplicated models: make sure that AIC and BIC aren't getting worse!
(The likelihood-ratio test is invalid for non-nested models and tricky
for nested models that only differ in their variance components.
Rejecting a variance component is the same thing as saying it's equal to
zero, which is at the edge of the parameter space for variance, which
means the p-values from the LRT aren't right.)

Assuming that each discipline only occurs within one discipline group,
disciplinaryGroup:discipline is the same thing as discipline. Same thing
for genreGroup:genreFamily.

Finally, please note that depending on your exact normalization
procedure, a standard Gaussian model with identity link (i.e. "linear")
might not be the right model for the job. I'm thinking in particular
about issues that can arise when your normalization procedure results in
an a measure that's bounded on [0,1].

Best,
Phillip


On 10/10/2018 12:52 PM, Taha Omidian wrote:
> Hi Philip, 
> 
> Thanks so much for your reply. 
> 
> I think the best way to describe the data is to start with the aim of
> our study. The purpose of our study is to investigate the effect of
> discipline, genre, and level of study on the use certain word
> combinations in learner writing. To represent learner writing, we
> compiled a corpus of texts collected from students in 30 different
> disciplines and at four levels of study. Texts in the corpus were then
> categorised based on their genres (13 genres). 
> 
> Following this, we classified the disciplines into four major
> disciplinary groupings. Genres were also grouped under 5 broad
> categories based on their social purposes. We then search the corpus for
> the occurrence of 278 word combinations (e.g., on the other hand) and
> recorded their normalised frequency of occurrence for each text (labeled
> as ref.norm in our data). 
> 
> To me, our data is structured in a hierarchical fashion (for each
> predictor). So here is what we have in our data:
> 
> -Students (*student_id *col) contributed multiple texts (*id* col)
> 
> -Each text is nested within different disciplines (*discipline* col)
> which are clustered within four disciplinary groupings
> (*disciplinaryGroup* col)
> 
> -Each text is nested within genres (*genreFamily* col) which are grouped
> into five genre groups (*genreGroup* col)
> 
> -Each text is nested within four levels of study (*level* col)
> 
> Predictors (based on the labels in our data)
> are: *disciplinaryGroup, **genreGroup, **level* 
> Dependent variable (based on its label in our data) is: /*ref.norm*/
> /*
> */
> So I need to know how this nested structure can be reflected in a LME
> model. 
> 
> As always thanks for your help. 
> 
> T
> 
>> On Oct 9, 2018, at 11:10 PM, Phillip Alday <phillip.alday at mpi.nl
>> <mailto:phillip.alday at mpi.nl>> wrote:
>>
>> I don't think this is the model you're looking for...
>>
>> 1. It's really weird to have your predictors in one dataframe and your
>> dependent variable in a different one. Are you really sure that the rows
>> line up like you think they do? If so, why not join the dataframes
>> earlier (with merge(), plyr::join() or dplyr::join())?
>>
>> I'm overall quite nervous about namespaces / scope / etc. in your code
>> -- using attach() isn't recommended practice, especially when you mix
>> and match things (e.g. your levelX variables aren't in your dataframe,
>> but the other predictors are). You have to be really careful to make
>> sure you're using the data you think you're using.
>>
>> You can do it like you have it, but it makes me very nervous in terms of
>> computing what you think you're computing.
>>
>> 2. Your levels include the same predictor in both the fixed effects and
>> as a grouping variable (the part of the random effect after the |) .
>> This generally doesn't make sense -- there are a number of posts on this
>> mailing list to that effect (see also
>> https://apac01.safelinks.protection.outlook.com/?url=https%3A%2F%2Frpubs.com%2FINBOstats%2Fboth_fixed_random&amp;data=02%7C01%7Ctaha.omidian%40vuw.ac.nz%7C4f9c8008c76b4354479908d62dcf77f8%7Ccfe63e236951427e8683bb84dcf1d20c%7C0%7C0%7C636746766469897297&amp;sdata=nDnQofQVnta%2BUlvfdGI1z5PiNxkai0AXW59Uy368xUU%3D&amp;reserved=0 and
>> https://apac01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.muscardinus.be%2F2017%2F08%2Ffixed-and-random%2F&amp;data=02%7C01%7Ctaha.omidian%40vuw.ac.nz%7C4f9c8008c76b4354479908d62dcf77f8%7Ccfe63e236951427e8683bb84dcf1d20c%7C0%7C0%7C636746766469897297&amp;sdata=7D%2FgIEUAJ%2BCOmR%2BrpNRtU49jyOtXDZk33cz5h9Ke04Y%3D&amp;reserved=0)
>> -- but it depends
>> on your data.
>>
>> In other words, seeing your model specification isn't quite enough -- we
>> also need to know something about your data, more than your variable
>> names alone reveal. Even though I work a lot with language data, I still
>> can't tell enough from your variable names and code what your data
>> actually represent.
>>
>>
>> Best,
>> Phillip
>>
>>
>>
>>
>> On 10/08/2018 12:46 AM, Taha Omidian wrote:
>>> Hello,
>>>
>>> I?m trying to fit a mixed effects model to my corpus data. The data
>>> has a hierarchical structure. I need to make sure that the final
>>> model reflects this nested structure.
>>>
>>> My final model looks like this:
>>>
>>> theMdl<-lmer(dis.norm.j$transformed~disciplinaryGroup+genreGroup+level+(1|student_id)+(1|levelA)+(1|levelB)+(1|levelC),data=thedata,
>>> control=lmerControl("bobyqa?))
>>>
>>> where 
>>>
>>> LevelA is genreGroup:genreFamily:student_id
>>> levelB is disciplinaryGroup:discipline:student_id
>>> levelC is level:student_id
>>>
>>> Here is a link to my data and R
>>> script: https://apac01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.dropbox.com%2Fsh%2F46r6lv6n89bromk%2FAABMc8MQmAYhRC3ubJ0Ii7Wma%3Fdl%3D0&amp;data=02%7C01%7Ctaha.omidian%40vuw.ac.nz%7C4f9c8008c76b4354479908d62dcf77f8%7Ccfe63e236951427e8683bb84dcf1d20c%7C0%7C0%7C636746766469897297&amp;sdata=%2FnFwGE4shUmS2L1QGO0ExQ0jh49iyLMCj7xhx9%2BX2yI%3D&amp;reserved=0
>>>
>>> Thanks 
>>>
>>> Taha
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org
>>> <mailto:R-sig-mixed-models at r-project.org> mailing list
>>> https://apac01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Ctaha.omidian%40vuw.ac.nz%7C4f9c8008c76b4354479908d62dcf77f8%7Ccfe63e236951427e8683bb84dcf1d20c%7C0%7C0%7C636746766469897297&amp;sdata=lutNcUBM2okGBj2fpYUhH216af55V1lfnr49U47LRkE%3D&amp;reserved=0
>


From ukoether @ending from uke@de  Wed Oct 17 18:28:30 2018
From: ukoether @ending from uke@de (=?UTF-8?Q?Ulf_K=c3=b6ther?=)
Date: Wed, 17 Oct 2018 18:28:30 +0200
Subject: [R-sig-ME] [RE] Response time modeling: Warning message with
 non-normal RAs
In-Reply-To: <33dcf30c-54eb-1ae1-af29-6f9e1bbe82b4@hsr.it>
References: <CAOE=hqLskrB+f1fnq2Uw-XYNbVyenYby4o=_ZecK5336D-=U3Q@mail.gmail.com>
 <a9e4d806-0e47-33c1-f1f4-ff5e23dd0240@gmail.com>
 <33dcf30c-54eb-1ae1-af29-6f9e1bbe82b4@hsr.it>
Message-ID: <4799d233-475b-09b7-8162-8818220b1699@uke.de>

Dear Gabriel,

as no one of the real professionals stepped in yet, I will try to
provide some thoughts:

(1) In my experience, Gamma GLMMs with an identity link are very buggy
all the time, so normally, when I am confronted with positive continuous
data, I mostly never consider them in the first place...why not use
another link function when using GLMMs, because that's exactly the goal
they were invented for: modeling data that does not belong to a normal
distribution by using an appropriate link function.

(2) I see why you don't want to transform the raw RT data and use an
ordinary LMM, but in my opinion, using a Gamma GLMM with a log-Link is a
valid option. Especially because you can insert the raw RT as a DV and
then model it on the scale of the linear predictor and after that, get
all parameter estimates and (which is much more valuable in my opinion)
the predicted values on the scale of the dependent variable without any
hard work, just use the invert link function (e.g., use the effects
package with lme4 and get the raw RT predictions). The interpretation if
such a model is much easier as you can directly get the predictions on
the scale of the DV.

Is it totally reasonable with regards to power? That's another question
that a real RT specialist should answer...

(2) I know the article you mentioned and skimmed it again. I really
wonder why they do not mention a log-link function as a valid option and
just compare the LMM with the transformed DV against a Gamma GLMM with
the identity link or an inverse Gaussian with identity link. It seems to
my that the Gamma GLMM with a log link is never really discussed. But,
as they also use the inverse Gaussian with the following link function
in lme4:

invfn <- function() {
    ## link
    linkfun <- function(y) -1000/y
    ## inverse link
    linkinv <- function(eta)  -1000/eta
    ## derivative of invlink wrt eta
    mu.eta <- function(eta) { 1000/(eta^2) }
    valideta <- function(eta) TRUE
    link <- "-1000/y"
    structure(list(linkfun = linkfun, linkinv = linkinv,
                   mu.eta = mu.eta, valideta = valideta,
                   name = link),
              class = "link-glm")
}

Why not try this when you want to go along the line the authors suggest?
The parameter estimates in their analyses seem really comparable between
Gamma and inverse Gaussian GLMMs to me. Just have a look at the
supplement! ;-)

Try to play around with your generated data with the log-link function
and with the inverse Gaussian to see which one recovers your parameters
best and go from there...!

Greetings,

Ulf




Am 17.10.2018 um 11:06 schrieb Baud-Bovy Gabriel:
> My apologies for sending this post again.  I am not sure that it went
> through because I did not
> receive it myself (though I think my options should have let me receive
> it).  Also, there was
> a line missing due to hurried cut-and-paste in the example below.
> 
> Dear all,
> 
> I have a dataset with response times of 200 participants measured 36
> times in different conditions.
> The RTs distribution is right skewed as it is generally the case for
> RTs. I would like to avoid transform them
> (see Lo & Andrew
> (2015)](https://www.frontiersin.org/articles/10.3389/fpsyg.2015.01171/full).
> However, I often encounter warning messages with this dataset when using
> a GLMM with Gamma
> distribution and identity link. The problem is not caused by an over
> parametrization as it arises
> even in the case in a intercept only model.
> 
>  > fit <- glmer(choice.lat ~ 1 + (1|su), data=dat,
> family=Gamma(link="identity"))
> Warning messages:
> 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>    Model failed to converge with max|grad| = 0.220808 (tol = 0.001,
> component 1)
> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>    Model is nearly unidentifiable: very large eigenvalue
>   - Rescale variables?
> 
>  > fit
> Generalized linear mixed model fit by maximum likelihood (Laplace
>    Approximation) [glmerMod]
>   Family: Gamma  ( identity )
> Formula: choice.lat ~ 1 + (1 | su)
>     Data: dat
>        AIC       BIC    logLik  deviance  df.resid
>   22629.26  22649.78 -11311.63  22623.26      6914
> Random effects:
>   Groups   Name        Std.Dev.
>   su       (Intercept) 0.8477
>   Residual             0.5721
> Number of obs: 6917, groups:  su, 200
> Fixed Effects:
> (Intercept)
>        3.044
> convergence code 0; 2 optimizer warnings; 0 lme4 warnings
> 
> The dispersion parameter of the estimated Gamma distribution is
> sigma(fit.glmer)^2 = 0.327
> with a population mean (Fixed effect) of circa  3.0 sec which fits
> reasonably well the RTs.
> 
> After some poking around, I figured out that the problem probably comes
> from the
> fact that the participants means are NOT distributed normally.  In fact,
> their distribution
> is similarly skewed. Removing the two extreme subjects or using a log
> link function "solves" the convergence
> problem/ warning messages but I don't like either solution because the
> is no valid reason to exclude these subjects
> and using a log transform cause theoretical problems when one want to
> interpret
> effects of more complex models (see Lo & Andrew (2015)).
> 
> I have seen many discussions of about warning message/convergence problem (
> e.g.
> https://rstudio-pubs-static.s3.amazonaws.com/33653_57fc7b8e5d484c909b615d8633c01d51.html).
> The usual advice is to try with different optimizers and/or simplify the
> model, which do not help here (they all give
> similar warning messages; see below).  I have two questions:
> 
> 1) Can somebody explain intuitively why non-normal random effects lead
> to these warning
>     messages ?  I would have naively assumed that it would simply lead
> to large a large variance estimate.
> 
> 2) Is there something within the lme4 framework  to tackle this problem?
> Should I simply ignore the
>      warning messages ?
> 
> 3) What principle approach would you suggest ? I have  seen that brms
> allow in principle to specify
>     non-normal random effect (I think that only student  is implemented
> so far) but I haven't tried yet.
> 
> Here is a toy problem that reproduces the issue (it depends on the seed
> actually). Depending
> on the choice of the dispersion parameter for the REs, it is possible
> also to induce convergence
> problem.
> 
> # artificial data set
> nsu <- 200
> nrep <- 36
> mu <- 3.0      # mean RT
> phi.su <- 0.8  # dispersion participants
> phi <- 0.3     # dispersion
> d <- expand.grid(
>    su = paste0("S",1:nsu),
>    rep = 1:nrep,
>    mu =NA,
>    rt = NA)
> 
> set.seed(125)
> # generate 200 Gamma distributed  participant means
> mu.su <- sort(rGamma(nsu, shape=1/phi.su, scale=phi.su*mu))
> d$mu <- mu.su[d$su]
> # add Gamma noise
> d$rt <- rGamma(nsu*nrep,shape=1/phi,scale=phi*d$mu)
> 
> # fit intercept GLMM model (gives warning messages)
> fit <- glmer(rt ~  1 + (1|su), data=d, family=Gamma(link="identity"))
> 
> # histogram of participant means and response times
> par(mfrow=c(1,2))
> hist(mu.su,n=50)
> hist(d$rt,n=200,xlim=c(0,10))
> 
>  > all_fit(fit)
> bobyqa. : [OK]
> Nelder_Mead. : [OK]
> optimx.nlminb : [OK]
> optimx.L-BFGS-B : [OK]
> nloptwrap.NLOPT_LN_NELDERMEAD : [OK]
> nloptwrap.NLOPT_LN_BOBYQA : [OK]
> nmkbw. : [OK]
> ....
> were 13 warnings (use warnings() to see them)
> 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
> ... :
>    Model failed to converge with max|grad| = 0.215844 (tol = 0.001,
> component 1)
> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
> ... :
>    Model is nearly unidentifiable: very large eigenvalue
>   - Rescale variables?
> 3: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
> ... :
>    Model failed to converge with max|grad| = 0.220808 (tol = 0.001,
> component 1)
> 4: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
> ... :
>    Model is nearly unidentifiable: very large eigenvalue
>   - Rescale variables?
> 5: In optwrap(optimizer, devfun, start, rho$lower, control = control,  ... :
>    convergence code 1 from optimx
> 6: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
> ... :
>    Model failed to converge with max|grad| = 0.215713 (tol = 0.001,
> component 1)
> 7: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
> ... :
>    Model is nearly unidentifiable: very large eigenvalue
>   - Rescale variables?
> 8: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
> ... :
>    Model failed to converge with max|grad| = 0.102562 (tol = 0.001,
> component 1)
> 9: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
> ... :
>    Model failed to converge with max|grad| = 0.109779 (tol = 0.001,
> component 1)
> 10: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
> control$checkConv,  ... :
>    Model failed to converge with max|grad| = 0.109779 (tol = 0.001,
> component 1)
> 11: In optwrap(optimizer, devfun, start, rho$lower, control = control,
> ... :
>    convergence code 2 from nmkbw
> 12: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
> control$checkConv,  ... :
>    Model failed to converge with max|grad| = 0.220811 (tol = 0.001,
> component 1)
> 13: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
> control$checkConv,  ... :
>    Model is nearly unidentifiable: very large eigenvalue
>   - Rescale variables?
> 
> 
> Thank you,
> 
> Gabriel
> 
> --
> ---------------------------------------------------------------------
> Gabriel Baud-Bovy               tel.: (+39) 348 172 4045     (mobile)
> UHSR University                       (+39) 02 2643 3429 (laboratory)
> via Olgettina, 58                     (+39) 02 9175 1540  (secretary)
> 20132 Milan, Italy              email:       gabriel.baud-bovy at hsr.it
> ---------------------------------------------------------------------
> 
> 
> 
> Rispetta l?ambiente: non stampare questa mail se non ? necessario.
> Respect the environment: print this email only if necessary.
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Martina Saurin (komm.)
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

From m@n@pend @ending from ntuzov@com  Wed Oct 17 19:23:39 2018
From: m@n@pend @ending from ntuzov@com (Nik Tuzov)
Date: Wed, 17 Oct 2018 17:23:39 +0000 (UTC)
Subject: [R-sig-ME] Weighted regression in REML
In-Reply-To: <mailman.16968.6728.1539736045.1179.r-sig-mixed-models@r-project.org>
References: <mailman.16968.6728.1539736045.1179.r-sig-mixed-models@r-project.org>
Message-ID: <376733514.11581627.1539797019771@mail.yahoo.com>

Hello Ben:
Thanks for replying.?
Unfortunately, it's hard for me or anyone else to determine when the copyright is violated. For instance,?"The elements of statistical learning" is available on Amazon for a hefty price of $63, and yet the authors made the pdf freely available as well. I assumed that the same was true for Searle's book.
I have developed an implementation of Searle's algorithm based on the equations 96-99 and 91b.?On top of that, it uses the multiplication trick to incorporate weights.It generates results that are close to those of PROC MIXED when there are no weights, or when weights are used w/o
random effects. However, when weights are used with random effects, the results are off. Did I get it right that, in your?opinion, I should look for some error in the code?
Regards,Nik

      From: "r-sig-mixed-models-request at r-project.org" <r-sig-mixed-models-request at r-project.org>
 To: r-sig-mixed-models at r-project.org 
 Sent: Tuesday, October 16, 2018 7:27 PM
 Subject: R-sig-mixed-models Digest, Vol 142, Issue 15
   
Send R-sig-mixed-models mailing list submissions to
??? r-sig-mixed-models at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
??? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
or, via email, send a message with subject or body 'help' to
??? r-sig-mixed-models-request at r-project.org

You can reach the person managing the list at
??? r-sig-mixed-models-owner at r-project.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-mixed-models digest..."


Today's Topics:

? 1. Dependency structure (Yashree Mehta)
? 2. Weighted regression in REML (Nik Tuzov)
? 3. Weighted regression in REML (Nik Tuzov)
? 4. Weighted regression in REML (Nik Tuzov)
? 5. Weighted regression in REML (Nik Tuzov)
? 6. Re: Weighted regression in REML (Ben Bolker)

----------------------------------------------------------------------

Message: 1
Date: Tue, 16 Oct 2018 19:03:27 +0200
From: Yashree Mehta <yashree19 at gmail.com>
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Dependency structure
Message-ID:
??? <CAOE=hqLskrB+f1fnq2Uw-XYNbVyenYby4o=_ZecK5336D-=U3Q at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

Hi,

Is there literature on how to specify the dependency structure between the
random intercept and the statistical noise error term in a random intercept
model?
It would be useful to also know how to implement using R...

Thank you

Yashree

??? [[alternative HTML version deleted]]




------------------------------

Message: 2
Date: Tue, 16 Oct 2018 21:14:56 +0000 (UTC)
From: Nik Tuzov <manspend at ntuzov.com>
To: "r-sig-mixed-models at r-project.org"
??? <r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] Weighted regression in REML
Message-ID: <1070079121.11021335.1539724496863 at mail.yahoo.com>
Content-Type: text/plain; charset="utf-8"

Hello:
I'm reading the book of Searle:
http://www.leg.ufpr.br/~eder/Variance%20Components.pdf

I think that equation 53 on p 276 suggests that if one wants to use weights in REML, the solution is very similar to that in OLS: multiply X, Z, and Y by the square root of the weight matrixand proceed as in unweighted case. Am I right or there is more that needs to be done?
Regards,Nik

??? [[alternative HTML version deleted]]




------------------------------

Message: 3
Date: Tue, 16 Oct 2018 21:17:39 +0000 (UTC)
From: Nik Tuzov <manspend at ntuzov.com>
To: "r-sig-mixed-models at r-project.org"
??? <r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] Weighted regression in REML
Message-ID: <529404307.11062962.1539724659849 at mail.yahoo.com>
Content-Type: text/plain; charset="utf-8"

Hello:
I'm reading the book of Searle:
http://www.leg.ufpr.br/~eder/Variance%20Components.pdf

I think that equation 53 on p 276 suggests that if one wants to use weights in REML, the solution is very similar to that in OLS: multiply X, Z, and Y by the square root of the weight matrixand proceed as in unweighted case. Am I right or there is more that needs to be done?
Regards,Nik

??? [[alternative HTML version deleted]]




------------------------------

Message: 4
Date: Tue, 16 Oct 2018 21:16:07 +0000 (UTC)
From: Nik Tuzov <manspend at ntuzov.com>
To: "r-sig-mixed-models at r-project.org"
??? <r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] Weighted regression in REML
Message-ID: <1606529909.11061754.1539724568007 at mail.yahoo.com>
Content-Type: text/plain; charset="utf-8"

Hello:
I'm reading the book of Searle:
http://www.leg.ufpr.br/~eder/Variance%20Components.pdf

I think that equation 53 on p 276 suggests that if one wants to use weights in REML, the solution is very similar to that in OLS: multiply X, Z, and Y by the square root of the weight matrixand proceed as in unweighted case. Am I right or there is more that needs to be done?
Regards,Nik

??? [[alternative HTML version deleted]]




------------------------------

Message: 5
Date: Tue, 16 Oct 2018 21:21:48 +0000 (UTC)
From: Nik Tuzov <manspend at ntuzov.com>
To: "r-sig-mixed-models at r-project.org"
??? <r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] Weighted regression in REML
Message-ID: <1435233226.11048314.1539724908472 at mail.yahoo.com>
Content-Type: text/plain; charset="utf-8"

Hello:
I'mreading the book of Searle:
http://www.leg.ufpr.br/~eder/Variance%20Components.pdf
Ithink that equation 53 on p 276 suggests that if one wants to useweights in REML, the solution is very similar to that in OLS:multiply X, Z, and Y by the square root of the weight matrix?andproceed as in unweighted case. Am I right or there is more that needsto be done?
Regards, Nik

??? [[alternative HTML version deleted]]




------------------------------

Message: 6
Date: Tue, 16 Oct 2018 20:27:36 -0400
From: Ben Bolker <bbolker at gmail.com>
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Weighted regression in REML
Message-ID: <a483cb3b-b15a-d30f-b7b2-65e97c2bef20 at gmail.com>
Content-Type: text/plain; charset="utf-8"


? Can I please request that in general people **not** use this list to
post links to material that is (presumably) violating the
authors'/publisher's wishes? (A screenshot of a particular equation
would seem to constitute "fair use" ...)

? FWIW your statement sounds correct to me -- in the Bates et al.
JSS/lmer paper (available via vignette("lmer", package="lme4")), the
development of the estimation procedure mostly leaves the weights out
for simplicity, but says:

"To allow for case weights, we save the products X^? W X, X^? W y, Z^? W
X, Z^? W y and Z^? W Z (see Table 6)."

? W is the weight matrix, so this is equivalent to multiplying X, y, Z
by W^(1/2) ...

? cheers
? ? Ben Bolker


On 2018-10-16 05:16 PM, Nik Tuzov wrote:
> Hello:
> I'm reading the book of Searle:
> http://www.leg.ufpr.br/~eder/Variance%20Components.pdf
> 
> I think that equation 53 on p 276 suggests that if one wants to use weights in REML, the solution is very similar to that in OLS: multiply X, Z, and Y by the square root of the weight matrixand proceed as in unweighted case. Am I right or there is more that needs to be done?
> Regards,Nik
> 
> ??? [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>




------------------------------

Subject: Digest Footer

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


------------------------------

End of R-sig-mixed-models Digest, Vol 142, Issue 15
***************************************************

   
	[[alternative HTML version deleted]]


From p@wijer@tne @ending from ucl@@c@uk  Thu Oct 18 10:28:08 2018
From: p@wijer@tne @ending from ucl@@c@uk (Wijeratne, Peter)
Date: Thu, 18 Oct 2018 08:28:08 +0000
Subject: [R-sig-ME] Simulating data with nested random effects
Message-ID: <HE1PR01MB29391404622F275C8CC31F14BFF80@HE1PR01MB2939.eurprd01.prod.exchangelabs.com>

Dear r-sig-mixed-models,


I would like to simulate nested data, where my mixed effects model fitted to real data has the form:

y ~ time + (1 | site/subject)

I then take the hyper-parameters from this model to simulate fake data, using this function:

create_fake <- function(J,K,L,HP,t){
# J : number of sites
# K : number of subjects / site
# L : number of years
# HP: hyperparameters from fit, y ~ time + (1 | site/subject)
# t: fractional effectiveness of treatment
time <- rep(seq(0,2,length=L), J*K)
subject <- rep(1:(J*K), each=L)
site <- sample(rep (1:J, K))
site1 <- factor(site[subject])
treatment <- sample(rep (0:1, J*K/2))
treatment1 <- treatment[subject]

# time coefficient
g.0.true <- as.numeric( HP['g.0.true'] )
# treatment coefficient
g.1.true <- -as.numeric(t)*g.0.true
# intercept
mu.a.true <- as.numeric( HP['mu.a.true'] )
# fixed effects
b.true <- (g.0.true + g.1.true*treatment)
# random effects
sigma.y.true <- as.numeric( HP['sigma.y.true'] ) # residual std dev
sigma.a.true <- as.numeric( HP['sigma.a.true'] ) # site std dev
sigma.a0.true <- as.numeric( HP['sigma.a0.true'] ) # site:person std dev
a0.true <- rnorm(J*K, 0, sigma.a0.true)
a.true <- rnorm(J*K, mu.a.true + a0.true, sigma.a.true)
y <- rnorm(J*K*L, a.true[subject] + b.true[subject]*time, sigma.y.true)

return(data.frame( y, time, subject, treatment1, site1 ))

I then fit models of the form:

y ~ time + time:treatment1 + (1 | site1/subject)

To the fake data. However, this approach can (but not always) produce a 'site' standard deviation approximately a factor of 10 less than in the real data.


My question is - is my simulation function correct?


Note - I can generate data and provide the full code if required.


Thanks in advance for any help.

	[[alternative HTML version deleted]]


From b@ud-bovy@g@briel @ending from h@r@it  Thu Oct 18 15:04:36 2018
From: b@ud-bovy@g@briel @ending from h@r@it (Baud-Bovy Gabriel)
Date: Thu, 18 Oct 2018 13:04:36 +0000
Subject: [R-sig-ME] [RE] Response time modeling: Warning message with
 non-normal RAs
In-Reply-To: <4799d233-475b-09b7-8162-8818220b1699@uke.de>
References: <CAOE=hqLskrB+f1fnq2Uw-XYNbVyenYby4o=_ZecK5336D-=U3Q@mail.gmail.com>
 <a9e4d806-0e47-33c1-f1f4-ff5e23dd0240@gmail.com>
 <33dcf30c-54eb-1ae1-af29-6f9e1bbe82b4@hsr.it>
 <4799d233-475b-09b7-8162-8818220b1699@uke.de>
Message-ID: <171dbc8b-04c8-e578-8625-9af6a73f0215@hsr.it>

Dear Ulf,

Thank you for the reply. I think that the approach is very reasonable 
but I am
not fully comfortable with it for reasons that I detail below your comments.

On 10/17/2018 6:28 PM, Ulf K?ther wrote:
> Dear Gabriel,
>
> as no one of the real professionals stepped in yet, I will try to
> provide some thoughts:
>
> (1) In my experience, Gamma GLMMs with an identity link are very buggy
> all the time, so normally, when I am confronted with positive continuous
> data, I mostly never consider them in the first place...why not use
> another link function when using GLMMs, because that's exactly the goal
> they were invented for: modeling data that does not belong to a normal
> distribution by using an appropriate link function.
One motivation for my post was to ask for insights about why Gamma GLMMS 
with identity link
are so difficult to fit even with a very simple intercept only model.? 
My guess is that it is related to the
fact that the distribution of the subject's mean are not gaussian but I 
would very much appreciate
opinion of the experts.

> (2) I see why you don't want to transform the raw RT data and use an
> ordinary LMM, but in my opinion, using a Gamma GLMM with a log-Link is a
> valid option. Especially because you can insert the raw RT as a DV and
> then model it on the scale of the linear predictor and after that, get
> all parameter estimates and (which is much more valuable in my opinion)
> the predicted values on the scale of the dependent variable without any
> hard work, just use the invert link function (e.g., use the effects
> package with lme4 and get the raw RT predictions). The interpretation if
> such a model is much easier as you can directly get the predictions on
> the scale of the DV.
>
> Is it totally reasonable with regards to power? That's another question
> that a real RT specialist should answer...
The log link solves indeed the fitting issue. However, my reason for not 
doing it, which is
discussed in Lo & Andrew 2015 paper, is the problem of "scale dependent" 
interactions,
which they discuss in their section on Transform or Not to Transform.
https://www.frontiersin.org/articles/10.3389/fpsyg.2015.01171/full

The "existence" of an such an interaction and, its statistical 
significance, depends on
the scale.? If I am not mistaken, being able to transform back the 
coefficients on the raw RTs scale is a
separate issue.

>
> (2) I know the article you mentioned and skimmed it again. I really
> wonder why they do not mention a log-link function as a valid option and
> just compare the LMM with the transformed DV against a Gamma GLMM with
> the identity link or an inverse Gaussian with identity link. It seems to
> my that the Gamma GLMM with a log link is never really discussed. But,
> as they also use the inverse Gaussian with the following link function
> in lme4:
>
> invfn <- function() {
>      ## link
>      linkfun <- function(y) -1000/y
>      ## inverse link
>      linkinv <- function(eta)  -1000/eta
>      ## derivative of invlink wrt eta
>      mu.eta <- function(eta) { 1000/(eta^2) }
>      valideta <- function(eta) TRUE
>      link <- "-1000/y"
>      structure(list(linkfun = linkfun, linkinv = linkinv,
>                     mu.eta = mu.eta, valideta = valideta,
>                     name = link),
>                class = "link-glm")
> }
>
> Why not try this when you want to go along the line the authors suggest?
> The parameter estimates in their analyses seem really comparable between
> Gamma and inverse Gaussian GLMMs to me. Just have a look at the
> supplement! ;-)

While I think that the problem of "scale dependent"? interaction 
remains, I probably should explore more
this possibility because the transformed scale might? justified on the 
theoretical basis. In fact, I think
that inverse transformation might be justified on basis of the LATER's 
model or similar
(https://www.sciencedirect.com/science/article/pii/S0149763415301226). 
In this case,
the coefficients represent the rate of accumulation of evidence. My 
understanding
of this model is that gaussian noise is added to the rate of 
accumulation.? Typically, the inverse
is applied to the RTs and the transformed data are analyzed with LMs or 
LMMs.

Lo & Andrew use the inverse link function with Gamma or Inverse Gaussian 
distribution but they don't
really discuss the assumptions behind choosing the inverse link 
function? and the inverse gaussian. From what I
know, the inverse gaussian distribution is not the reciprocal of the 
normal distribution and I see only a
partial? connection between the LATER model and the proposed GLMM model.

I would appreciate any further comment from you and other RT experts on 
this issue.

Best,

Gabriel

P.S.? Paul Johnson's wrote an interesting note on Gamma GLM with the 
inverse link
(i.e. when modeling relationships of the form mu = a + b/x or 1/mu = a + 
b/x).
http://pj.freefaculty.org/guides/stat/Regression-GLM/Gamma/GammaGLM-01.pdf
His point was that using GLM rather than OLS? was important when there 
is a transformation
but using Normal? instead of Gamma? distributed dependent variable with 
GLM does not
result in disaster.? I think that the question when analyzing RTs is 
different since there
is reason to use Gamma without a transformation, a case that is not 
discussed in Paul
Johnson's note.

> Try to play around with your generated data with the log-link function
> and with the inverse Gaussian to see which one recovers your parameters
> best and go from there...!
>
> Greetings,
>
> Ulf
>
>
>
>
> Am 17.10.2018 um 11:06 schrieb Baud-Bovy Gabriel:
>> My apologies for sending this post again.  I am not sure that it went
>> through because I did not
>> receive it myself (though I think my options should have let me receive
>> it).  Also, there was
>> a line missing due to hurried cut-and-paste in the example below.
>>
>> Dear all,
>>
>> I have a dataset with response times of 200 participants measured 36
>> times in different conditions.
>> The RTs distribution is right skewed as it is generally the case for
>> RTs. I would like to avoid transform them
>> (see Lo & Andrew
>> (2015)](https://www.frontiersin.org/articles/10.3389/fpsyg.2015.01171/full).
>> However, I often encounter warning messages with this dataset when using
>> a GLMM with Gamma
>> distribution and identity link. The problem is not caused by an over
>> parametrization as it arises
>> even in the case in a intercept only model.
>>
>>   > fit <- glmer(choice.lat ~ 1 + (1|su), data=dat,
>> family=Gamma(link="identity"))
>> Warning messages:
>> 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>>     Model failed to converge with max|grad| = 0.220808 (tol = 0.001,
>> component 1)
>> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>>     Model is nearly unidentifiable: very large eigenvalue
>>    - Rescale variables?
>>
>>   > fit
>> Generalized linear mixed model fit by maximum likelihood (Laplace
>>     Approximation) [glmerMod]
>>    Family: Gamma  ( identity )
>> Formula: choice.lat ~ 1 + (1 | su)
>>      Data: dat
>>         AIC       BIC    logLik  deviance  df.resid
>>    22629.26  22649.78 -11311.63  22623.26      6914
>> Random effects:
>>    Groups   Name        Std.Dev.
>>    su       (Intercept) 0.8477
>>    Residual             0.5721
>> Number of obs: 6917, groups:  su, 200
>> Fixed Effects:
>> (Intercept)
>>         3.044
>> convergence code 0; 2 optimizer warnings; 0 lme4 warnings
>>
>> The dispersion parameter of the estimated Gamma distribution is
>> sigma(fit.glmer)^2 = 0.327
>> with a population mean (Fixed effect) of circa  3.0 sec which fits
>> reasonably well the RTs.
>>
>> After some poking around, I figured out that the problem probably comes
>> from the
>> fact that the participants means are NOT distributed normally.  In fact,
>> their distribution
>> is similarly skewed. Removing the two extreme subjects or using a log
>> link function "solves" the convergence
>> problem/ warning messages but I don't like either solution because the
>> is no valid reason to exclude these subjects
>> and using a log transform cause theoretical problems when one want to
>> interpret
>> effects of more complex models (see Lo & Andrew (2015)).
>>
>> I have seen many discussions of about warning message/convergence problem (
>> e.g.
>> https://rstudio-pubs-static.s3.amazonaws.com/33653_57fc7b8e5d484c909b615d8633c01d51.html).
>> The usual advice is to try with different optimizers and/or simplify the
>> model, which do not help here (they all give
>> similar warning messages; see below).  I have two questions:
>>
>> 1) Can somebody explain intuitively why non-normal random effects lead
>> to these warning
>>      messages ?  I would have naively assumed that it would simply lead
>> to large a large variance estimate.
>>
>> 2) Is there something within the lme4 framework  to tackle this problem?
>> Should I simply ignore the
>>       warning messages ?
>>
>> 3) What principle approach would you suggest ? I have  seen that brms
>> allow in principle to specify
>>      non-normal random effect (I think that only student  is implemented
>> so far) but I haven't tried yet.
>>
>> Here is a toy problem that reproduces the issue (it depends on the seed
>> actually). Depending
>> on the choice of the dispersion parameter for the REs, it is possible
>> also to induce convergence
>> problem.
>>
>> # artificial data set
>> nsu <- 200
>> nrep <- 36
>> mu <- 3.0      # mean RT
>> phi.su <- 0.8  # dispersion participants
>> phi <- 0.3     # dispersion
>> d <- expand.grid(
>>     su = paste0("S",1:nsu),
>>     rep = 1:nrep,
>>     mu =NA,
>>     rt = NA)
>>
>> set.seed(125)
>> # generate 200 Gamma distributed  participant means
>> mu.su <- sort(rGamma(nsu, shape=1/phi.su, scale=phi.su*mu))
>> d$mu <- mu.su[d$su]
>> # add Gamma noise
>> d$rt <- rGamma(nsu*nrep,shape=1/phi,scale=phi*d$mu)
>>
>> # fit intercept GLMM model (gives warning messages)
>> fit <- glmer(rt ~  1 + (1|su), data=d, family=Gamma(link="identity"))
>>
>> # histogram of participant means and response times
>> par(mfrow=c(1,2))
>> hist(mu.su,n=50)
>> hist(d$rt,n=200,xlim=c(0,10))
>>
>>   > all_fit(fit)
>> bobyqa. : [OK]
>> Nelder_Mead. : [OK]
>> optimx.nlminb : [OK]
>> optimx.L-BFGS-B : [OK]
>> nloptwrap.NLOPT_LN_NELDERMEAD : [OK]
>> nloptwrap.NLOPT_LN_BOBYQA : [OK]
>> nmkbw. : [OK]
>> ....
>> were 13 warnings (use warnings() to see them)
>> 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
>> ... :
>>     Model failed to converge with max|grad| = 0.215844 (tol = 0.001,
>> component 1)
>> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
>> ... :
>>     Model is nearly unidentifiable: very large eigenvalue
>>    - Rescale variables?
>> 3: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
>> ... :
>>     Model failed to converge with max|grad| = 0.220808 (tol = 0.001,
>> component 1)
>> 4: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
>> ... :
>>     Model is nearly unidentifiable: very large eigenvalue
>>    - Rescale variables?
>> 5: In optwrap(optimizer, devfun, start, rho$lower, control = control,  ... :
>>     convergence code 1 from optimx
>> 6: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
>> ... :
>>     Model failed to converge with max|grad| = 0.215713 (tol = 0.001,
>> component 1)
>> 7: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
>> ... :
>>     Model is nearly unidentifiable: very large eigenvalue
>>    - Rescale variables?
>> 8: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
>> ... :
>>     Model failed to converge with max|grad| = 0.102562 (tol = 0.001,
>> component 1)
>> 9: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
>> ... :
>>     Model failed to converge with max|grad| = 0.109779 (tol = 0.001,
>> component 1)
>> 10: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
>> control$checkConv,  ... :
>>     Model failed to converge with max|grad| = 0.109779 (tol = 0.001,
>> component 1)
>> 11: In optwrap(optimizer, devfun, start, rho$lower, control = control,
>> ... :
>>     convergence code 2 from nmkbw
>> 12: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
>> control$checkConv,  ... :
>>     Model failed to converge with max|grad| = 0.220811 (tol = 0.001,
>> component 1)
>> 13: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
>> control$checkConv,  ... :
>>     Model is nearly unidentifiable: very large eigenvalue
>>    - Rescale variables?
>>
>>
>> Thank you,
>>
>> Gabriel
>>
>> --
>> ---------------------------------------------------------------------
>> Gabriel Baud-Bovy               tel.: (+39) 348 172 4045     (mobile)
>> UHSR University                       (+39) 02 2643 3429 (laboratory)
>> via Olgettina, 58                     (+39) 02 9175 1540  (secretary)
>> 20132 Milan, Italy              email:       gabriel.baud-bovy at hsr.it
>> ---------------------------------------------------------------------
>>
>>
>>
>> Rispetta l?ambiente: non stampare questa mail se non ? necessario.
>> Respect the environment: print this email only if necessary.
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> --
>
> _____________________________________________________________________
>
> Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
> Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Martina Saurin (komm.)
> _____________________________________________________________________
>
> SAVE PAPER - THINK BEFORE PRINTING


-- 
---------------------------------------------------------------------
Gabriel Baud-Bovy               tel.: (+39) 348 172 4045     (mobile)
UHSR University                       (+39) 02 2643 3429 (laboratory)
via Olgettina, 58                     (+39) 02 9175 1540  (secretary)
20132 Milan, Italy              email:       gabriel.baud-bovy at hsr.it
---------------------------------------------------------------------


From emm@nuel@curi@ @ending from p@ri@de@c@rte@@fr  Fri Oct 19 15:28:07 2018
From: emm@nuel@curi@ @ending from p@ri@de@c@rte@@fr (Emmanuel Curis)
Date: Fri, 19 Oct 2018 15:28:07 +0200
Subject: [R-sig-ME] [RE] Response time modeling: Warning message with
 non-normal RAs
In-Reply-To: <171dbc8b-04c8-e578-8625-9af6a73f0215@hsr.it>
References: <CAOE=hqLskrB+f1fnq2Uw-XYNbVyenYby4o=_ZecK5336D-=U3Q@mail.gmail.com>
 <a9e4d806-0e47-33c1-f1f4-ff5e23dd0240@gmail.com>
 <33dcf30c-54eb-1ae1-af29-6f9e1bbe82b4@hsr.it>
 <4799d233-475b-09b7-8162-8818220b1699@uke.de>
 <171dbc8b-04c8-e578-8625-9af6a73f0215@hsr.it>
Message-ID: <20181019132807.GB16416@info124.pharmacie.univ-paris5.fr>

Hello,

Just a personnal opinion considering the point of interaction
depending on the scale. I think this is more an issue of what model do
you believe in and its mathematical formulation, and how to handle
non-linearities, than a problem of link function (or data
transformation), especially if you consider an interaction ? simply ?
as a product of predictor variables term in a linear model.

That is, considering your RT variable for instance, and two predictors
for sake of simplicity, you simply cannot have simultaneously

RT = ?0 + a * factor1 + b * factor2

and

log RT = ?0' + a' * factor1 + b' * factor2

(unless a = b = 0, or both factor1 and factor2 are indicator
variables, that is associated to binary qualitative predictors)

so when trying to apply a linear model to the scale where the
relationship is not linear, some ? spurious ? interactions (defined as
product of factor1 and factor2) seem to appear because the model will
add these terms to handle the intrinsic non-linearity of the model
induced by the scale change.

That does not mean the answer is easy, but that using this argument to
avoid using non-linear link functions seems strange unless you have
strong arguments to affirm that the relationship is indeed linear in
the original scale. If you think the model is linear in the log scale,
then it is the model with the linear link that is doubtful, and the
associated (lack of) interaction ? spurious ?.

My guess would be, in your particular case, that a gamma model with
identity link and linear model on this scale simply does not hold,
because it violates the constraints on the gamma distribution
parameters, and that having random effects with a large variance may
be enough to have cases where the model, even quite simple, gives
irrealistic results. Especially with a Gaussian random effect, that
can have negative values...


On Thu, Oct 18, 2018 at 01:04:36PM +0000, Baud-Bovy Gabriel wrote:
? Dear Ulf,
? 
? Thank you for the reply. I think that the approach is very reasonable 
? but I am
? not fully comfortable with it for reasons that I detail below your comments.
? 
? On 10/17/2018 6:28 PM, Ulf K?ther wrote:
? > Dear Gabriel,
? >
? > as no one of the real professionals stepped in yet, I will try to
? > provide some thoughts:
? >
? > (1) In my experience, Gamma GLMMs with an identity link are very buggy
? > all the time, so normally, when I am confronted with positive continuous
? > data, I mostly never consider them in the first place...why not use
? > another link function when using GLMMs, because that's exactly the goal
? > they were invented for: modeling data that does not belong to a normal
? > distribution by using an appropriate link function.
? One motivation for my post was to ask for insights about why Gamma GLMMS 
? with identity link
? are so difficult to fit even with a very simple intercept only model.? 
? My guess is that it is related to the
? fact that the distribution of the subject's mean are not gaussian but I 
? would very much appreciate
? opinion of the experts.
? 
? > (2) I see why you don't want to transform the raw RT data and use an
? > ordinary LMM, but in my opinion, using a Gamma GLMM with a log-Link is a
? > valid option. Especially because you can insert the raw RT as a DV and
? > then model it on the scale of the linear predictor and after that, get
? > all parameter estimates and (which is much more valuable in my opinion)
? > the predicted values on the scale of the dependent variable without any
? > hard work, just use the invert link function (e.g., use the effects
? > package with lme4 and get the raw RT predictions). The interpretation if
? > such a model is much easier as you can directly get the predictions on
? > the scale of the DV.
? >
? > Is it totally reasonable with regards to power? That's another question
? > that a real RT specialist should answer...
? The log link solves indeed the fitting issue. However, my reason for not 
? doing it, which is
? discussed in Lo & Andrew 2015 paper, is the problem of "scale dependent" 
? interactions,
? which they discuss in their section on Transform or Not to Transform.
? https://www.frontiersin.org/articles/10.3389/fpsyg.2015.01171/full
? 
? The "existence" of an such an interaction and, its statistical 
? significance, depends on
? the scale.? If I am not mistaken, being able to transform back the 
? coefficients on the raw RTs scale is a
? separate issue.
? 
? >
? > (2) I know the article you mentioned and skimmed it again. I really
? > wonder why they do not mention a log-link function as a valid option and
? > just compare the LMM with the transformed DV against a Gamma GLMM with
? > the identity link or an inverse Gaussian with identity link. It seems to
? > my that the Gamma GLMM with a log link is never really discussed. But,
? > as they also use the inverse Gaussian with the following link function
? > in lme4:
? >
? > invfn <- function() {
? >      ## link
? >      linkfun <- function(y) -1000/y
? >      ## inverse link
? >      linkinv <- function(eta)  -1000/eta
? >      ## derivative of invlink wrt eta
? >      mu.eta <- function(eta) { 1000/(eta^2) }
? >      valideta <- function(eta) TRUE
? >      link <- "-1000/y"
? >      structure(list(linkfun = linkfun, linkinv = linkinv,
? >                     mu.eta = mu.eta, valideta = valideta,
? >                     name = link),
? >                class = "link-glm")
? > }
? >
? > Why not try this when you want to go along the line the authors suggest?
? > The parameter estimates in their analyses seem really comparable between
? > Gamma and inverse Gaussian GLMMs to me. Just have a look at the
? > supplement! ;-)
? 
? While I think that the problem of "scale dependent"? interaction 
? remains, I probably should explore more
? this possibility because the transformed scale might? justified on the 
? theoretical basis. In fact, I think
? that inverse transformation might be justified on basis of the LATER's 
? model or similar
? (https://www.sciencedirect.com/science/article/pii/S0149763415301226). 
? In this case,
? the coefficients represent the rate of accumulation of evidence. My 
? understanding
? of this model is that gaussian noise is added to the rate of 
? accumulation.? Typically, the inverse
? is applied to the RTs and the transformed data are analyzed with LMs or 
? LMMs.
? 
? Lo & Andrew use the inverse link function with Gamma or Inverse Gaussian 
? distribution but they don't
? really discuss the assumptions behind choosing the inverse link 
? function? and the inverse gaussian. From what I
? know, the inverse gaussian distribution is not the reciprocal of the 
? normal distribution and I see only a
? partial? connection between the LATER model and the proposed GLMM model.
? 
? I would appreciate any further comment from you and other RT experts on 
? this issue.
? 
? Best,
? 
? Gabriel
? 
? P.S.? Paul Johnson's wrote an interesting note on Gamma GLM with the 
? inverse link
? (i.e. when modeling relationships of the form mu = a + b/x or 1/mu = a + 
? b/x).
? http://pj.freefaculty.org/guides/stat/Regression-GLM/Gamma/GammaGLM-01.pdf
? His point was that using GLM rather than OLS? was important when there 
? is a transformation
? but using Normal? instead of Gamma? distributed dependent variable with 
? GLM does not
? result in disaster.? I think that the question when analyzing RTs is 
? different since there
? is reason to use Gamma without a transformation, a case that is not 
? discussed in Paul
? Johnson's note.
? 
? > Try to play around with your generated data with the log-link function
? > and with the inverse Gaussian to see which one recovers your parameters
? > best and go from there...!
? >
? > Greetings,
? >
? > Ulf
? >
? >
? >
? >
? > Am 17.10.2018 um 11:06 schrieb Baud-Bovy Gabriel:
? >> My apologies for sending this post again.  I am not sure that it went
? >> through because I did not
? >> receive it myself (though I think my options should have let me receive
? >> it).  Also, there was
? >> a line missing due to hurried cut-and-paste in the example below.
? >>
? >> Dear all,
? >>
? >> I have a dataset with response times of 200 participants measured 36
? >> times in different conditions.
? >> The RTs distribution is right skewed as it is generally the case for
? >> RTs. I would like to avoid transform them
? >> (see Lo & Andrew
? >> (2015)](https://www.frontiersin.org/articles/10.3389/fpsyg.2015.01171/full).
? >> However, I often encounter warning messages with this dataset when using
? >> a GLMM with Gamma
? >> distribution and identity link. The problem is not caused by an over
? >> parametrization as it arises
? >> even in the case in a intercept only model.
? >>
? >>   > fit <- glmer(choice.lat ~ 1 + (1|su), data=dat,
? >> family=Gamma(link="identity"))
? >> Warning messages:
? >> 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
? >>     Model failed to converge with max|grad| = 0.220808 (tol = 0.001,
? >> component 1)
? >> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
? >>     Model is nearly unidentifiable: very large eigenvalue
? >>    - Rescale variables?
? >>
? >>   > fit
? >> Generalized linear mixed model fit by maximum likelihood (Laplace
? >>     Approximation) [glmerMod]
? >>    Family: Gamma  ( identity )
? >> Formula: choice.lat ~ 1 + (1 | su)
? >>      Data: dat
? >>         AIC       BIC    logLik  deviance  df.resid
? >>    22629.26  22649.78 -11311.63  22623.26      6914
? >> Random effects:
? >>    Groups   Name        Std.Dev.
? >>    su       (Intercept) 0.8477
? >>    Residual             0.5721
? >> Number of obs: 6917, groups:  su, 200
? >> Fixed Effects:
? >> (Intercept)
? >>         3.044
? >> convergence code 0; 2 optimizer warnings; 0 lme4 warnings
? >>
? >> The dispersion parameter of the estimated Gamma distribution is
? >> sigma(fit.glmer)^2 = 0.327
? >> with a population mean (Fixed effect) of circa  3.0 sec which fits
? >> reasonably well the RTs.
? >>
? >> After some poking around, I figured out that the problem probably comes
? >> from the
? >> fact that the participants means are NOT distributed normally.  In fact,
? >> their distribution
? >> is similarly skewed. Removing the two extreme subjects or using a log
? >> link function "solves" the convergence
? >> problem/ warning messages but I don't like either solution because the
? >> is no valid reason to exclude these subjects
? >> and using a log transform cause theoretical problems when one want to
? >> interpret
? >> effects of more complex models (see Lo & Andrew (2015)).
? >>
? >> I have seen many discussions of about warning message/convergence problem (
? >> e.g.
? >> https://rstudio-pubs-static.s3.amazonaws.com/33653_57fc7b8e5d484c909b615d8633c01d51.html).
? >> The usual advice is to try with different optimizers and/or simplify the
? >> model, which do not help here (they all give
? >> similar warning messages; see below).  I have two questions:
? >>
? >> 1) Can somebody explain intuitively why non-normal random effects lead
? >> to these warning
? >>      messages ?  I would have naively assumed that it would simply lead
? >> to large a large variance estimate.
? >>
? >> 2) Is there something within the lme4 framework  to tackle this problem?
? >> Should I simply ignore the
? >>       warning messages ?
? >>
? >> 3) What principle approach would you suggest ? I have  seen that brms
? >> allow in principle to specify
? >>      non-normal random effect (I think that only student  is implemented
? >> so far) but I haven't tried yet.
? >>
? >> Here is a toy problem that reproduces the issue (it depends on the seed
? >> actually). Depending
? >> on the choice of the dispersion parameter for the REs, it is possible
? >> also to induce convergence
? >> problem.
? >>
? >> # artificial data set
? >> nsu <- 200
? >> nrep <- 36
? >> mu <- 3.0      # mean RT
? >> phi.su <- 0.8  # dispersion participants
? >> phi <- 0.3     # dispersion
? >> d <- expand.grid(
? >>     su = paste0("S",1:nsu),
? >>     rep = 1:nrep,
? >>     mu =NA,
? >>     rt = NA)
? >>
? >> set.seed(125)
? >> # generate 200 Gamma distributed  participant means
? >> mu.su <- sort(rGamma(nsu, shape=1/phi.su, scale=phi.su*mu))
? >> d$mu <- mu.su[d$su]
? >> # add Gamma noise
? >> d$rt <- rGamma(nsu*nrep,shape=1/phi,scale=phi*d$mu)
? >>
? >> # fit intercept GLMM model (gives warning messages)
? >> fit <- glmer(rt ~  1 + (1|su), data=d, family=Gamma(link="identity"))
? >>
? >> # histogram of participant means and response times
? >> par(mfrow=c(1,2))
? >> hist(mu.su,n=50)
? >> hist(d$rt,n=200,xlim=c(0,10))
? >>
? >>   > all_fit(fit)
? >> bobyqa. : [OK]
? >> Nelder_Mead. : [OK]
? >> optimx.nlminb : [OK]
? >> optimx.L-BFGS-B : [OK]
? >> nloptwrap.NLOPT_LN_NELDERMEAD : [OK]
? >> nloptwrap.NLOPT_LN_BOBYQA : [OK]
? >> nmkbw. : [OK]
? >> ....
? >> were 13 warnings (use warnings() to see them)
? >> 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
? >> ... :
? >>     Model failed to converge with max|grad| = 0.215844 (tol = 0.001,
? >> component 1)
? >> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
? >> ... :
? >>     Model is nearly unidentifiable: very large eigenvalue
? >>    - Rescale variables?
? >> 3: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
? >> ... :
? >>     Model failed to converge with max|grad| = 0.220808 (tol = 0.001,
? >> component 1)
? >> 4: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
? >> ... :
? >>     Model is nearly unidentifiable: very large eigenvalue
? >>    - Rescale variables?
? >> 5: In optwrap(optimizer, devfun, start, rho$lower, control = control,  ... :
? >>     convergence code 1 from optimx
? >> 6: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
? >> ... :
? >>     Model failed to converge with max|grad| = 0.215713 (tol = 0.001,
? >> component 1)
? >> 7: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
? >> ... :
? >>     Model is nearly unidentifiable: very large eigenvalue
? >>    - Rescale variables?
? >> 8: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
? >> ... :
? >>     Model failed to converge with max|grad| = 0.102562 (tol = 0.001,
? >> component 1)
? >> 9: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
? >> ... :
? >>     Model failed to converge with max|grad| = 0.109779 (tol = 0.001,
? >> component 1)
? >> 10: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
? >> control$checkConv,  ... :
? >>     Model failed to converge with max|grad| = 0.109779 (tol = 0.001,
? >> component 1)
? >> 11: In optwrap(optimizer, devfun, start, rho$lower, control = control,
? >> ... :
? >>     convergence code 2 from nmkbw
? >> 12: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
? >> control$checkConv,  ... :
? >>     Model failed to converge with max|grad| = 0.220811 (tol = 0.001,
? >> component 1)
? >> 13: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
? >> control$checkConv,  ... :
? >>     Model is nearly unidentifiable: very large eigenvalue
? >>    - Rescale variables?
? >>
? >>
? >> Thank you,
? >>
? >> Gabriel
? >>
? >> --
? >> ---------------------------------------------------------------------
? >> Gabriel Baud-Bovy               tel.: (+39) 348 172 4045     (mobile)
? >> UHSR University                       (+39) 02 2643 3429 (laboratory)
? >> via Olgettina, 58                     (+39) 02 9175 1540  (secretary)
? >> 20132 Milan, Italy              email:       gabriel.baud-bovy at hsr.it
? >> ---------------------------------------------------------------------
? >>
? >>
? >>
? >> Rispetta l?ambiente: non stampare questa mail se non ? necessario.
? >> Respect the environment: print this email only if necessary.
? >> _______________________________________________
? >> R-sig-mixed-models at r-project.org mailing list
? >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
? >>
? > --
? >
? > _____________________________________________________________________
? >
? > Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
? > Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Martina Saurin (komm.)
? > _____________________________________________________________________
? >
? > SAVE PAPER - THINK BEFORE PRINTING
? 
? 
? -- 
? ---------------------------------------------------------------------
? Gabriel Baud-Bovy               tel.: (+39) 348 172 4045     (mobile)
? UHSR University                       (+39) 02 2643 3429 (laboratory)
? via Olgettina, 58                     (+39) 02 9175 1540  (secretary)
? 20132 Milan, Italy              email:       gabriel.baud-bovy at hsr.it
? ---------------------------------------------------------------------
? 
? _______________________________________________
? R-sig-mixed-models at r-project.org mailing list
? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From thierry@onkelinx @ending from inbo@be  Sun Oct 21 10:41:49 2018
From: thierry@onkelinx @ending from inbo@be (Thierry Onkelinx)
Date: Sun, 21 Oct 2018 10:41:49 +0200
Subject: [R-sig-ME] Simulating data with nested random effects
In-Reply-To: <HE1PR01MB29391404622F275C8CC31F14BFF80@HE1PR01MB2939.eurprd01.prod.exchangelabs.com>
References: <HE1PR01MB29391404622F275C8CC31F14BFF80@HE1PR01MB2939.eurprd01.prod.exchangelabs.com>
Message-ID: <CAJuCY5xGNDyMKukutJ4M4QS_VLh72i3imXsESMU-2cSVNxyaKw@mail.gmail.com>

Dear Pete,

I rewrote your code to make it shorter and IMHO more readable. Meaningful
variables names require less comments on what they are. The model yields
sensible estimates on data simulated with the code below.

library(lme4)
library(dplyr)
create_fake <- function(
  n_site = 100, n_subject_site = 10, n_time = 10,
  intercept = 10, trend = 0.1, effect = 0.5,
  sigma_site = 5, sigma_subject = 2, sigma_noise = 1
){
  re.site <- rnorm(n_site, mean = 0, sd = sigma_site)
  re.subject <- rnorm(n_site * n_subject_site, mean = 0, sd = sigma_subject)

  expand.grid(
    time = seq(0, 2, length = n_time),
    site = seq_len(n_site),
    subject = seq_len(n_subject_site)
  ) %>%
    mutate(
      subject = interaction(site, subject),
      treatment = sample(0:1, size = n_site * n_subject_site,, replace =
TRUE)[subject],
      fixed = intercept + effect * treatment + trend * time,
      random = re.site[site] + re.subject[subject],
      mu = fixed + random,
      y = rnorm(n(), mean = mu, sd = sigma_noise)
    )
}
dataset <- create_fake()
m <- lmer(y ~ treatment + time + (1|site/subject), data = dataset)
summary(m)

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op do 18 okt. 2018 om 10:28 schreef Wijeratne, Peter <p.wijeratne at ucl.ac.uk
>:

> Dear r-sig-mixed-models,
>
>
> I would like to simulate nested data, where my mixed effects model fitted
> to real data has the form:
>
> y ~ time + (1 | site/subject)
>
> I then take the hyper-parameters from this model to simulate fake data,
> using this function:
>
> create_fake <- function(J,K,L,HP,t){
> # J : number of sites
> # K : number of subjects / site
> # L : number of years
> # HP: hyperparameters from fit, y ~ time + (1 | site/subject)
> # t: fractional effectiveness of treatment
> time <- rep(seq(0,2,length=L), J*K)
> subject <- rep(1:(J*K), each=L)
> site <- sample(rep (1:J, K))
> site1 <- factor(site[subject])
> treatment <- sample(rep (0:1, J*K/2))
> treatment1 <- treatment[subject]
>
> # time coefficient
> g.0.true <- as.numeric( HP['g.0.true'] )
> # treatment coefficient
> g.1.true <- -as.numeric(t)*g.0.true
> # intercept
> mu.a.true <- as.numeric( HP['mu.a.true'] )
> # fixed effects
> b.true <- (g.0.true + g.1.true*treatment)
> # random effects
> sigma.y.true <- as.numeric( HP['sigma.y.true'] ) # residual std dev
> sigma.a.true <- as.numeric( HP['sigma.a.true'] ) # site std dev
> sigma.a0.true <- as.numeric( HP['sigma.a0.true'] ) # site:person std dev
> a0.true <- rnorm(J*K, 0, sigma.a0.true)
> a.true <- rnorm(J*K, mu.a.true + a0.true, sigma.a.true)
> y <- rnorm(J*K*L, a.true[subject] + b.true[subject]*time, sigma.y.true)
>
> return(data.frame( y, time, subject, treatment1, site1 ))
>
> I then fit models of the form:
>
> y ~ time + time:treatment1 + (1 | site1/subject)
>
> To the fake data. However, this approach can (but not always) produce a
> 'site' standard deviation approximately a factor of 10 less than in the
> real data.
>
>
> My question is - is my simulation function correct?
>
>
> Note - I can generate data and provide the full code if required.
>
>
> Thanks in advance for any help.
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From guill@ume@imon@@2 @ending from gm@il@com  Tue Oct 23 12:06:07 2018
From: guill@ume@imon@@2 @ending from gm@il@com (Guillaume Adeux)
Date: Tue, 23 Oct 2018 12:06:07 +0200
Subject: [R-sig-ME] test_terms for lme model with crossed random effects and
 weights
Message-ID: <CAENiVe8fAfe_Hxm625sEYT-Y8EAXb6ikoO-4ui46hqC5nKYQng@mail.gmail.com>

Hi everyone,

I wanted to allow for different variances across treatment levels so I
headed towards nlme:lme in order to use varIdent().

However, I also have crossed random effects (year and plot) which needs a
little hack in nlme:lme to specify.

Hence the final model is:

dat$Grp=1 ### fake grouping in order to create grouped data object
gr=groupedData(response~time|Grp,data=dat) ### grouped data object
mod4 <- lme(response~ block+treatment*time, random =
pdBlocked(list(pdIdent(~ year - 1),pdIdent(~ plot -
1))),weights=varIdent(form=~1|treatment), data=gr,method="ML")

The question now is: is it possible to supply such a model to
monet::test_terms() ?
I cannot find such examples in
https://rdrr.io/github/singmann/monet/src/examples/examples.test_terms.R

Thank you all once again for you help.

Sincerely,

Guillaume ADEUX

Nb: if I understood correctly from previous messages, this type of model
(crossed random effects, specific variance structure) could also be fitted
with glmmTMB

	[[alternative HTML version deleted]]


From M@@rten@Jung @ending from m@ilbox@tu-dre@den@de  Tue Oct 23 16:54:56 2018
From: M@@rten@Jung @ending from m@ilbox@tu-dre@den@de (Maarten Jung)
Date: Tue, 23 Oct 2018 16:54:56 +0200
Subject: [R-sig-ME] 
 test_terms for lme model with crossed random effects and weights
In-Reply-To: <CAENiVe8fAfe_Hxm625sEYT-Y8EAXb6ikoO-4ui46hqC5nKYQng@mail.gmail.com>
References: <CAENiVe8fAfe_Hxm625sEYT-Y8EAXb6ikoO-4ui46hqC5nKYQng@mail.gmail.com>
Message-ID: <CAHr4Dyf+ku5cU722P-POUmTRRqiLS_7=wgq8dWZgcfcCxyMtyg@mail.gmail.com>

I don't know if monet::test_terms() can do this.
But maybe the emmeans package can help here. The joint_tests() function
computes Type-III test for each effect in a model [1].
Also (what I find quite interesting), "[t]here is an experimental mode =
"satterthwaite" option that determines degrees of freedom approximately: It
estimates a needed gradient in the covariance matrix experimentally by
randomly perturbing the response values. Thus, the degrees of freedom will
vary slightly (or possibly even a lot) if the reference grid is
re-calculated" [2].

Cheers, Maarten

[1]
https://cran.r-project.org/web/packages/emmeans/vignettes/interactions.html
[2] https://cran.r-project.org/web/packages/emmeans/vignettes/models.html#K


On Tue, Oct 23, 2018 at 12:06 PM Guillaume Adeux <
guillaumesimon.a2 at gmail.com> wrote:

> Hi everyone,
>
> I wanted to allow for different variances across treatment levels so I
> headed towards nlme:lme in order to use varIdent().
>
> However, I also have crossed random effects (year and plot) which needs a
> little hack in nlme:lme to specify.
>
> Hence the final model is:
>
> dat$Grp=1 ### fake grouping in order to create grouped data object
> gr=groupedData(response~time|Grp,data=dat) ### grouped data object
> mod4 <- lme(response~ block+treatment*time, random =
> pdBlocked(list(pdIdent(~ year - 1),pdIdent(~ plot -
> 1))),weights=varIdent(form=~1|treatment), data=gr,method="ML")
>
> The question now is: is it possible to supply such a model to
> monet::test_terms() ?
> I cannot find such examples in
> https://rdrr.io/github/singmann/monet/src/examples/examples.test_terms.R
>
> Thank you all once again for you help.
>
> Sincerely,
>
> Guillaume ADEUX
>
> Nb: if I understood correctly from previous messages, this type of model
> (crossed random effects, specific variance structure) could also be fitted
> with glmmTMB
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From jhwil@on@nb @ending from gm@il@com  Tue Oct 23 19:46:58 2018
From: jhwil@on@nb @ending from gm@il@com (John Wilson)
Date: Tue, 23 Oct 2018 14:46:58 -0300
Subject: [R-sig-ME] population-level predict glmmtmb with poly()
Message-ID: <CABdA5Q123BEb66wy+BBHcUfSJ5-OznBEqg6CJ0VctU8ok-agxg@mail.gmail.com>

Hello,

I'm working on a glmmtmb() model with multiple continuous and categorical
predictors. Two of the predictors are orthogonal polynomials (I just saw
that the package was updated yesterday (!) to correctly handle those). One
of the polynomials has an interaction with another covariate.

Since predict(re.form = 0) doesn't work just yet and one has to use
the model.matrix(lme4::nobars(formula(mod1)[-2]), newdata) approach - how
do I get the correct polynomial predictions out? It looks like my results
depend on how I structure the newdata data frame - when I use
expand.grid(), the predictions are wrong, but when I subset the original
data, the predictions are correct.

Thanks so much!
John

Here's an example:

library(ggplot2)
library(glmmTMB)

set.seed(0)
x <- 1:20
z <- sample(c("a", "b"), length(x), replace = TRUE)
y <- round(5 * 2*x + 3 * x^2 + 0.1 * x^3 + rnbinom(length(x), 10, 0.03))
group <- sample(c("i", "ii"), length(x), replace = TRUE)
df <- data.frame(x = x, y = y, z = z, group = group)
m <- glmmTMB(y ~ poly(x, 3) * z +
(1 | group),
family = nbinom2,
data = df)
# prediction on a new grid
newdata <- expand.grid(x = 1:20, z = unique(df$z))
X.cond = model.matrix(lme4::nobars(formula(m)[-2]), newdata)
beta.cond = fixef(m)$cond
newdata$Pred1 = as.numeric(X.cond %*% beta.cond)
# prediction in original data frame
X.cond = model.matrix(lme4::nobars(formula(m)[-2]))
beta.cond = fixef(m)$cond
df$Pred1 = as.numeric(X.cond %*% beta.cond)

# the newdata preds are obviously off
ggplot(df) +
geom_point(aes(x = x, y = y, colour = z)) +
geom_line(data = newdata, aes(x = x, y = exp(Pred1), colour = z), size = 2)
+
geom_line(aes(x = x, y = exp(Pred1), colour = z, linetype = group))

# if the new grid is defined like this, then the predictions are ok
newdata <- unique(select(df, x, z))
X.cond = model.matrix(lme4::nobars(formula(m)[-2]), newdata)
beta.cond = fixef(m)$cond
newdata$Pred1 = as.numeric(X.cond %*% beta.cond)
ggplot(df) +
geom_point(aes(x = x, y = y, colour = z)) +
geom_line(data = newdata, aes(x = x, y = exp(Pred1), colour = z), size = 2)
+
geom_line(aes(x = x, y = exp(Pred1), colour = z, linetype = group))

	[[alternative HTML version deleted]]


From d@rizopoulo@ @ending from er@@mu@mc@nl  Tue Oct 23 21:31:04 2018
From: d@rizopoulo@ @ending from er@@mu@mc@nl (D. Rizopoulos)
Date: Tue, 23 Oct 2018 19:31:04 +0000
Subject: [R-sig-ME] population-level predict glmmtmb with poly()
In-Reply-To: <CABdA5Q123BEb66wy+BBHcUfSJ5-OznBEqg6CJ0VctU8ok-agxg@mail.gmail.com>
References: <CABdA5Q123BEb66wy+BBHcUfSJ5-OznBEqg6CJ0VctU8ok-agxg@mail.gmail.com>
Message-ID: <d5b43bb6-4a3b-8cf0-b11c-c64492d081f6@erasmusmc.nl>

You could fit the same model also using the GLMMadaptive package in 
which the predict() method can produce predictions for the mean subject 
(i.e., the one with random effects values equal to 0), marginal 
predictions (i.e., averaged over the subjects), and subject-specific 
predictions.

For more info you can have a look at:

https://drizopoulos.github.io/GLMMadaptive/

https://drizopoulos.github.io/GLMMadaptive/articles/Methods_MixMod.html#predictions

and potentially also

https://drizopoulos.github.io/GLMMadaptive/articles/Dynamic_Predictions.html

if you're interested in dynamic predictions.

Best,
Dimitris



On 10/23/2018 7:46 PM, John Wilson wrote:
> Hello,
> 
> I'm working on a glmmtmb() model with multiple continuous and categorical
> predictors. Two of the predictors are orthogonal polynomials (I just saw
> that the package was updated yesterday (!) to correctly handle those). One
> of the polynomials has an interaction with another covariate.
> 
> Since predict(re.form = 0) doesn't work just yet and one has to use
> the model.matrix(lme4::nobars(formula(mod1)[-2]), newdata) approach - how
> do I get the correct polynomial predictions out? It looks like my results
> depend on how I structure the newdata data frame - when I use
> expand.grid(), the predictions are wrong, but when I subset the original
> data, the predictions are correct.
> 
> Thanks so much!
> John
> 
> Here's an example:
> 
> library(ggplot2)
> library(glmmTMB)
> 
> set.seed(0)
> x <- 1:20
> z <- sample(c("a", "b"), length(x), replace = TRUE)
> y <- round(5 * 2*x + 3 * x^2 + 0.1 * x^3 + rnbinom(length(x), 10, 0.03))
> group <- sample(c("i", "ii"), length(x), replace = TRUE)
> df <- data.frame(x = x, y = y, z = z, group = group)
> m <- glmmTMB(y ~ poly(x, 3) * z +
> (1 | group),
> family = nbinom2,
> data = df)
> # prediction on a new grid
> newdata <- expand.grid(x = 1:20, z = unique(df$z))
> X.cond = model.matrix(lme4::nobars(formula(m)[-2]), newdata)
> beta.cond = fixef(m)$cond
> newdata$Pred1 = as.numeric(X.cond %*% beta.cond)
> # prediction in original data frame
> X.cond = model.matrix(lme4::nobars(formula(m)[-2]))
> beta.cond = fixef(m)$cond
> df$Pred1 = as.numeric(X.cond %*% beta.cond)
> 
> # the newdata preds are obviously off
> ggplot(df) +
> geom_point(aes(x = x, y = y, colour = z)) +
> geom_line(data = newdata, aes(x = x, y = exp(Pred1), colour = z), size = 2)
> +
> geom_line(aes(x = x, y = exp(Pred1), colour = z, linetype = group))
> 
> # if the new grid is defined like this, then the predictions are ok
> newdata <- unique(select(df, x, z))
> X.cond = model.matrix(lme4::nobars(formula(m)[-2]), newdata)
> beta.cond = fixef(m)$cond
> newdata$Pred1 = as.numeric(X.cond %*% beta.cond)
> ggplot(df) +
> geom_point(aes(x = x, y = y, colour = z)) +
> geom_line(data = newdata, aes(x = x, y = exp(Pred1), colour = z), size = 2)
> +
> geom_line(aes(x = x, y = exp(Pred1), colour = z, linetype = group))
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
Dimitris Rizopoulos
Professor of Biostatistics
Department of Biostatistics
Erasmus University Medical Center

Address: PO Box 2040, 3000 CA Rotterdam, the Netherlands
Tel: +31/(0)10/7043478
Fax: +31/(0)10/7043014
Web (personal): http://www.drizopoulos.com/
Web (work): http://www.erasmusmc.nl/biostatistiek/
Blog: http://iprogn.blogspot.nl/

From jhwil@on@nb @ending from gm@il@com  Wed Oct 24 00:48:54 2018
From: jhwil@on@nb @ending from gm@il@com (John Wilson)
Date: Tue, 23 Oct 2018 19:48:54 -0300
Subject: [R-sig-ME] population-level predict glmmtmb with poly()
In-Reply-To: <d5b43bb6-4a3b-8cf0-b11c-c64492d081f6@erasmusmc.nl>
References: <CABdA5Q123BEb66wy+BBHcUfSJ5-OznBEqg6CJ0VctU8ok-agxg@mail.gmail.com>
 <d5b43bb6-4a3b-8cf0-b11c-c64492d081f6@erasmusmc.nl>
Message-ID: <CABdA5Q35s1_-sHX8jsCGCPDk+EpsBZXyA6jB=6jnzd1_BQ3VbA@mail.gmail.com>

Thank you, Dimitris. I poked around a bit but didn't see mention of
autocorrelation structures - are those supported as well?

I was wondering if this issue was related to the problem logged here:
https://github.com/glmmTMB/glmmTMB/issues/402. Can anyone comment on
whether what I'm seeing is a bug or just a user (=me) mistake? When I
change the toy example to be a simple linear form (rather than poly()), the
two predictions are identical, so I'm pretty sure it's a poly() issue...

On Tue, Oct 23, 2018 at 4:31 PM D. Rizopoulos <d.rizopoulos at erasmusmc.nl>
wrote:

> You could fit the same model also using the GLMMadaptive package in
> which the predict() method can produce predictions for the mean subject
> (i.e., the one with random effects values equal to 0), marginal
> predictions (i.e., averaged over the subjects), and subject-specific
> predictions.
>
> For more info you can have a look at:
>
> https://drizopoulos.github.io/GLMMadaptive/
>
>
> https://drizopoulos.github.io/GLMMadaptive/articles/Methods_MixMod.html#predictions
>
> and potentially also
>
>
> https://drizopoulos.github.io/GLMMadaptive/articles/Dynamic_Predictions.html
>
> if you're interested in dynamic predictions.
>
> Best,
> Dimitris
>
>
>
> On 10/23/2018 7:46 PM, John Wilson wrote:
> > Hello,
> >
> > I'm working on a glmmtmb() model with multiple continuous and categorical
> > predictors. Two of the predictors are orthogonal polynomials (I just saw
> > that the package was updated yesterday (!) to correctly handle those).
> One
> > of the polynomials has an interaction with another covariate.
> >
> > Since predict(re.form = 0) doesn't work just yet and one has to use
> > the model.matrix(lme4::nobars(formula(mod1)[-2]), newdata) approach - how
> > do I get the correct polynomial predictions out? It looks like my results
> > depend on how I structure the newdata data frame - when I use
> > expand.grid(), the predictions are wrong, but when I subset the original
> > data, the predictions are correct.
> >
> > Thanks so much!
> > John
> >
> > Here's an example:
> >
> > library(ggplot2)
> > library(glmmTMB)
> >
> > set.seed(0)
> > x <- 1:20
> > z <- sample(c("a", "b"), length(x), replace = TRUE)
> > y <- round(5 * 2*x + 3 * x^2 + 0.1 * x^3 + rnbinom(length(x), 10, 0.03))
> > group <- sample(c("i", "ii"), length(x), replace = TRUE)
> > df <- data.frame(x = x, y = y, z = z, group = group)
> > m <- glmmTMB(y ~ poly(x, 3) * z +
> > (1 | group),
> > family = nbinom2,
> > data = df)
> > # prediction on a new grid
> > newdata <- expand.grid(x = 1:20, z = unique(df$z))
> > X.cond = model.matrix(lme4::nobars(formula(m)[-2]), newdata)
> > beta.cond = fixef(m)$cond
> > newdata$Pred1 = as.numeric(X.cond %*% beta.cond)
> > # prediction in original data frame
> > X.cond = model.matrix(lme4::nobars(formula(m)[-2]))
> > beta.cond = fixef(m)$cond
> > df$Pred1 = as.numeric(X.cond %*% beta.cond)
> >
> > # the newdata preds are obviously off
> > ggplot(df) +
> > geom_point(aes(x = x, y = y, colour = z)) +
> > geom_line(data = newdata, aes(x = x, y = exp(Pred1), colour = z), size =
> 2)
> > +
> > geom_line(aes(x = x, y = exp(Pred1), colour = z, linetype = group))
> >
> > # if the new grid is defined like this, then the predictions are ok
> > newdata <- unique(select(df, x, z))
> > X.cond = model.matrix(lme4::nobars(formula(m)[-2]), newdata)
> > beta.cond = fixef(m)$cond
> > newdata$Pred1 = as.numeric(X.cond %*% beta.cond)
> > ggplot(df) +
> > geom_point(aes(x = x, y = y, colour = z)) +
> > geom_line(data = newdata, aes(x = x, y = exp(Pred1), colour = z), size =
> 2)
> > +
> > geom_line(aes(x = x, y = exp(Pred1), colour = z, linetype = group))
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> --
> Dimitris Rizopoulos
> Professor of Biostatistics
> Department of Biostatistics
> Erasmus University Medical Center
>
> Address: PO Box 2040, 3000 CA Rotterdam, the Netherlands
> Tel: +31/(0)10/7043478
> Fax: +31/(0)10/7043014
> Web (personal): http://www.drizopoulos.com/
> Web (work): http://www.erasmusmc.nl/biostatistiek/
> Blog: http://iprogn.blogspot.nl/

	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Wed Oct 24 01:21:47 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Tue, 23 Oct 2018 19:21:47 -0400
Subject: [R-sig-ME] population-level predict glmmtmb with poly()
In-Reply-To: <CABdA5Q35s1_-sHX8jsCGCPDk+EpsBZXyA6jB=6jnzd1_BQ3VbA@mail.gmail.com>
References: <CABdA5Q123BEb66wy+BBHcUfSJ5-OznBEqg6CJ0VctU8ok-agxg@mail.gmail.com>
 <d5b43bb6-4a3b-8cf0-b11c-c64492d081f6@erasmusmc.nl>
 <CABdA5Q35s1_-sHX8jsCGCPDk+EpsBZXyA6jB=6jnzd1_BQ3VbA@mail.gmail.com>
Message-ID: <274cb210-bdba-5eb3-e656-329e3d1cbc8a@gmail.com>


  Naive prediction with data-dependent bases **will not work** with new
input variables. (This is a general R/model.matrix() thing ... not
glmmTMB's fault.)  The current development version of glmmTMB does some
magic (see ?makepredictcall,
https://developer.r-project.org/model-fitting-functions.html for more
detail) that makes this work.

  It wasn't documented until about 120 seconds ago, but in order to do
population-level predictions with predict() all you need to do is set
the group variable to NA.  This has less flexibility than the re.form=
argument in lme4 (which allows you to drop a *subset* of the random
effects terms for a given grouping variables), but it does handle the
most common use case ...

  Does this work for you (with devel version of glmmTMB) ?

# prediction on a new grid
newdata <- expand.grid(x = 1:20, z = unique(df$z), group=NA)
newdata$y <- predict(m,newdata=newdata, type="response")

(ggplot(df, aes(x,y, colour=z))
    + geom_point()
    + geom_line(data = newdata, size =2)
)


On 2018-10-23 6:48 p.m., John Wilson wrote:
> Thank you, Dimitris. I poked around a bit but didn't see mention of
> autocorrelation structures - are those supported as well?
> 
> I was wondering if this issue was related to the problem logged here:
> https://github.com/glmmTMB/glmmTMB/issues/402. Can anyone comment on
> whether what I'm seeing is a bug or just a user (=me) mistake? When I
> change the toy example to be a simple linear form (rather than poly()), the
> two predictions are identical, so I'm pretty sure it's a poly() issue...
> 
> On Tue, Oct 23, 2018 at 4:31 PM D. Rizopoulos <d.rizopoulos at erasmusmc.nl>
> wrote:
> 
>> You could fit the same model also using the GLMMadaptive package in
>> which the predict() method can produce predictions for the mean subject
>> (i.e., the one with random effects values equal to 0), marginal
>> predictions (i.e., averaged over the subjects), and subject-specific
>> predictions.
>>
>> For more info you can have a look at:
>>
>> https://drizopoulos.github.io/GLMMadaptive/
>>
>>
>> https://drizopoulos.github.io/GLMMadaptive/articles/Methods_MixMod.html#predictions
>>
>> and potentially also
>>
>>
>> https://drizopoulos.github.io/GLMMadaptive/articles/Dynamic_Predictions.html
>>
>> if you're interested in dynamic predictions.
>>
>> Best,
>> Dimitris
>>
>>
>>
>> On 10/23/2018 7:46 PM, John Wilson wrote:
>>> Hello,
>>>
>>> I'm working on a glmmtmb() model with multiple continuous and categorical
>>> predictors. Two of the predictors are orthogonal polynomials (I just saw
>>> that the package was updated yesterday (!) to correctly handle those).
>> One
>>> of the polynomials has an interaction with another covariate.
>>>
>>> Since predict(re.form = 0) doesn't work just yet and one has to use
>>> the model.matrix(lme4::nobars(formula(mod1)[-2]), newdata) approach - how
>>> do I get the correct polynomial predictions out? It looks like my results
>>> depend on how I structure the newdata data frame - when I use
>>> expand.grid(), the predictions are wrong, but when I subset the original
>>> data, the predictions are correct.
>>>
>>> Thanks so much!
>>> John
>>>
>>> Here's an example:
>>>
>>> library(ggplot2)
>>> library(glmmTMB)
>>>
>>> set.seed(0)
>>> x <- 1:20
>>> z <- sample(c("a", "b"), length(x), replace = TRUE)
>>> y <- round(5 * 2*x + 3 * x^2 + 0.1 * x^3 + rnbinom(length(x), 10, 0.03))
>>> group <- sample(c("i", "ii"), length(x), replace = TRUE)
>>> df <- data.frame(x = x, y = y, z = z, group = group)
>>> m <- glmmTMB(y ~ poly(x, 3) * z +
>>> (1 | group),
>>> family = nbinom2,
>>> data = df)
>>> # prediction on a new grid
>>> newdata <- expand.grid(x = 1:20, z = unique(df$z))
>>> X.cond = model.matrix(lme4::nobars(formula(m)[-2]), newdata)
>>> beta.cond = fixef(m)$cond
>>> newdata$Pred1 = as.numeric(X.cond %*% beta.cond)
>>> # prediction in original data frame
>>> X.cond = model.matrix(lme4::nobars(formula(m)[-2]))
>>> beta.cond = fixef(m)$cond
>>> df$Pred1 = as.numeric(X.cond %*% beta.cond)
>>>
>>> # the newdata preds are obviously off
>>> ggplot(df) +
>>> geom_point(aes(x = x, y = y, colour = z)) +
>>> geom_line(data = newdata, aes(x = x, y = exp(Pred1), colour = z), size =
>> 2)
>>> +
>>> geom_line(aes(x = x, y = exp(Pred1), colour = z, linetype = group))
>>>
>>> # if the new grid is defined like this, then the predictions are ok
>>> newdata <- unique(select(df, x, z))
>>> X.cond = model.matrix(lme4::nobars(formula(m)[-2]), newdata)
>>> beta.cond = fixef(m)$cond
>>> newdata$Pred1 = as.numeric(X.cond %*% beta.cond)
>>> ggplot(df) +
>>> geom_point(aes(x = x, y = y, colour = z)) +
>>> geom_line(data = newdata, aes(x = x, y = exp(Pred1), colour = z), size =
>> 2)
>>> +
>>> geom_line(aes(x = x, y = exp(Pred1), colour = z, linetype = group))
>>>
>>>       [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> --
>> Dimitris Rizopoulos
>> Professor of Biostatistics
>> Department of Biostatistics
>> Erasmus University Medical Center
>>
>> Address: PO Box 2040, 3000 CA Rotterdam, the Netherlands
>> Tel: +31/(0)10/7043478
>> Fax: +31/(0)10/7043014
>> Web (personal): http://www.drizopoulos.com/
>> Web (work): http://www.erasmusmc.nl/biostatistiek/
>> Blog: http://iprogn.blogspot.nl/
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From d@rizopoulo@ @ending from er@@mu@mc@nl  Wed Oct 24 04:16:57 2018
From: d@rizopoulo@ @ending from er@@mu@mc@nl (D. Rizopoulos)
Date: Wed, 24 Oct 2018 02:16:57 +0000
Subject: [R-sig-ME] population-level predict glmmtmb with poly()
In-Reply-To: <CABdA5Q35s1_-sHX8jsCGCPDk+EpsBZXyA6jB=6jnzd1_BQ3VbA@mail.gmail.com>
References: <CABdA5Q123BEb66wy+BBHcUfSJ5-OznBEqg6CJ0VctU8ok-agxg@mail.gmail.com>
 <d5b43bb6-4a3b-8cf0-b11c-c64492d081f6@erasmusmc.nl>,
 <CABdA5Q35s1_-sHX8jsCGCPDk+EpsBZXyA6jB=6jnzd1_BQ3VbA@mail.gmail.com>
Message-ID: <7191AFC7255B4F49A30707E39BEAD05FDEBC8665@EXCH-HE03.erasmusmc.nl>

Indeed, currently in GLMMadaptive for the random effects you can assume an unstructured or a diagonal covariance matrix. In my future plans is to also include the compound symmetric one.

However, in general, for categorical multivariate outcome data Y, note that assuming a particular covariance structure for the unobserved random effects b, does *not* translate to the same covariance structure for the marginal distribution of the observed Y. This is because of the nonlinear link function used, and the fact that the marginal distribution p(Y) = \int p(Y | b) p(b) db doesn?t even have a closed-form. Hence, the estimated parameters from such a covariance structure for the random effects in this case do not have any directly meaningful interpretation.

Best,
Dimitris

From: John Wilson <jhwilson.nb at gmail.com<mailto:jhwilson.nb at gmail.com>>
Date: Wednesday, 24 Oct 2018, 12:48 AM
To: D. Rizopoulos <d.rizopoulos at erasmusmc.nl<mailto:d.rizopoulos at erasmusmc.nl>>
Cc: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
Subject: Re: [R-sig-ME] population-level predict glmmtmb with poly()

Thank you, Dimitris. I poked around a bit but didn't see mention of autocorrelation structures - are those supported as well?

I was wondering if this issue was related to the problem logged here: https://github.com/glmmTMB/glmmTMB/issues/402. Can anyone comment on whether what I'm seeing is a bug or just a user (=me) mistake? When I change the toy example to be a simple linear form (rather than poly()), the two predictions are identical, so I'm pretty sure it's a poly() issue...

On Tue, Oct 23, 2018 at 4:31 PM D. Rizopoulos <d.rizopoulos at erasmusmc.nl<mailto:d.rizopoulos at erasmusmc.nl>> wrote:
You could fit the same model also using the GLMMadaptive package in
which the predict() method can produce predictions for the mean subject
(i.e., the one with random effects values equal to 0), marginal
predictions (i.e., averaged over the subjects), and subject-specific
predictions.

For more info you can have a look at:

https://drizopoulos.github.io/GLMMadaptive/

https://drizopoulos.github.io/GLMMadaptive/articles/Methods_MixMod.html#predictions

and potentially also

https://drizopoulos.github.io/GLMMadaptive/articles/Dynamic_Predictions.html

if you're interested in dynamic predictions.

Best,
Dimitris



On 10/23/2018 7:46 PM, John Wilson wrote:
> Hello,
>
> I'm working on a glmmtmb() model with multiple continuous and categorical
> predictors. Two of the predictors are orthogonal polynomials (I just saw
> that the package was updated yesterday (!) to correctly handle those). One
> of the polynomials has an interaction with another covariate.
>
> Since predict(re.form = 0) doesn't work just yet and one has to use
> the model.matrix(lme4::nobars(formula(mod1)[-2]), newdata) approach - how
> do I get the correct polynomial predictions out? It looks like my results
> depend on how I structure the newdata data frame - when I use
> expand.grid(), the predictions are wrong, but when I subset the original
> data, the predictions are correct.
>
> Thanks so much!
> John
>
> Here's an example:
>
> library(ggplot2)
> library(glmmTMB)
>
> set.seed(0)
> x <- 1:20
> z <- sample(c("a", "b"), length(x), replace = TRUE)
> y <- round(5 * 2*x + 3 * x^2 + 0.1 * x^3 + rnbinom(length(x), 10, 0.03))
> group <- sample(c("i", "ii"), length(x), replace = TRUE)
> df <- data.frame(x = x, y = y, z = z, group = group)
> m <- glmmTMB(y ~ poly(x, 3) * z +
> (1 | group),
> family = nbinom2,
> data = df)
> # prediction on a new grid
> newdata <- expand.grid(x = 1:20, z = unique(df$z))
> X.cond = model.matrix(lme4::nobars(formula(m)[-2]), newdata)
> beta.cond = fixef(m)$cond
> newdata$Pred1 = as.numeric(X.cond %*% beta.cond)
> # prediction in original data frame
> X.cond = model.matrix(lme4::nobars(formula(m)[-2]))
> beta.cond = fixef(m)$cond
> df$Pred1 = as.numeric(X.cond %*% beta.cond)
>
> # the newdata preds are obviously off
> ggplot(df) +
> geom_point(aes(x = x, y = y, colour = z)) +
> geom_line(data = newdata, aes(x = x, y = exp(Pred1), colour = z), size = 2)
> +
> geom_line(aes(x = x, y = exp(Pred1), colour = z, linetype = group))
>
> # if the new grid is defined like this, then the predictions are ok
> newdata <- unique(select(df, x, z))
> X.cond = model.matrix(lme4::nobars(formula(m)[-2]), newdata)
> beta.cond = fixef(m)$cond
> newdata$Pred1 = as.numeric(X.cond %*% beta.cond)
> ggplot(df) +
> geom_point(aes(x = x, y = y, colour = z)) +
> geom_line(data = newdata, aes(x = x, y = exp(Pred1), colour = z), size = 2)
> +
> geom_line(aes(x = x, y = exp(Pred1), colour = z, linetype = group))
>
>       [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

--
Dimitris Rizopoulos
Professor of Biostatistics
Department of Biostatistics
Erasmus University Medical Center

Address: PO Box 2040, 3000 CA Rotterdam, the Netherlands
Tel: +31/(0)10/7043478
Fax: +31/(0)10/7043014
Web (personal): http://www.drizopoulos.com/
Web (work): http://www.erasmusmc.nl/biostatistiek/
Blog: http://iprogn.blogspot.nl/

	[[alternative HTML version deleted]]


From jhwil@on@nb @ending from gm@il@com  Wed Oct 24 16:24:32 2018
From: jhwil@on@nb @ending from gm@il@com (John Wilson)
Date: Wed, 24 Oct 2018 11:24:32 -0300
Subject: [R-sig-ME] population-level predict glmmtmb with poly()
In-Reply-To: <274cb210-bdba-5eb3-e656-329e3d1cbc8a@gmail.com>
References: <CABdA5Q123BEb66wy+BBHcUfSJ5-OznBEqg6CJ0VctU8ok-agxg@mail.gmail.com>
 <d5b43bb6-4a3b-8cf0-b11c-c64492d081f6@erasmusmc.nl>
 <CABdA5Q35s1_-sHX8jsCGCPDk+EpsBZXyA6jB=6jnzd1_BQ3VbA@mail.gmail.com>
 <274cb210-bdba-5eb3-e656-329e3d1cbc8a@gmail.com>
Message-ID: <CABdA5Q0nojrzi2Npr5dY1dK+GPR4wJau=N01R4D_zp4ut8FqVA@mail.gmail.com>

So far it's looking just grand! +1 for "it  wasn't documented until about
120 seconds ago".
Just to push my luck here - in my full model, I have autocorrelation
structures. When I only set group = NA, the predict() function gave me an
error due to lack of the autocorrelation variable in the new data. I then
crossed my fingers and did the same thing as for group - a column with NAs.
The predict() function had no problem with that. However, I wanted to see
if that's a (semi) legit way to doing it.

On Tue, Oct 23, 2018 at 8:22 PM Ben Bolker <bbolker at gmail.com> wrote:

>
>   Naive prediction with data-dependent bases **will not work** with new
> input variables. (This is a general R/model.matrix() thing ... not
> glmmTMB's fault.)  The current development version of glmmTMB does some
> magic (see ?makepredictcall,
> https://developer.r-project.org/model-fitting-functions.html for more
> detail) that makes this work.
>
>   It wasn't documented until about 120 seconds ago, but in order to do
> population-level predictions with predict() all you need to do is set
> the group variable to NA.  This has less flexibility than the re.form=
> argument in lme4 (which allows you to drop a *subset* of the random
> effects terms for a given grouping variables), but it does handle the
> most common use case ...
>
>   Does this work for you (with devel version of glmmTMB) ?
>
> # prediction on a new grid
> newdata <- expand.grid(x = 1:20, z = unique(df$z), group=NA)
> newdata$y <- predict(m,newdata=newdata, type="response")
>
> (ggplot(df, aes(x,y, colour=z))
>     + geom_point()
>     + geom_line(data = newdata, size =2)
> )
>
>
> On 2018-10-23 6:48 p.m., John Wilson wrote:
> > Thank you, Dimitris. I poked around a bit but didn't see mention of
> > autocorrelation structures - are those supported as well?
> >
> > I was wondering if this issue was related to the problem logged here:
> > https://github.com/glmmTMB/glmmTMB/issues/402. Can anyone comment on
> > whether what I'm seeing is a bug or just a user (=me) mistake? When I
> > change the toy example to be a simple linear form (rather than poly()),
> the
> > two predictions are identical, so I'm pretty sure it's a poly() issue...
> >
> > On Tue, Oct 23, 2018 at 4:31 PM D. Rizopoulos <d.rizopoulos at erasmusmc.nl
> >
> > wrote:
> >
> >> You could fit the same model also using the GLMMadaptive package in
> >> which the predict() method can produce predictions for the mean subject
> >> (i.e., the one with random effects values equal to 0), marginal
> >> predictions (i.e., averaged over the subjects), and subject-specific
> >> predictions.
> >>
> >> For more info you can have a look at:
> >>
> >> https://drizopoulos.github.io/GLMMadaptive/
> >>
> >>
> >>
> https://drizopoulos.github.io/GLMMadaptive/articles/Methods_MixMod.html#predictions
> >>
> >> and potentially also
> >>
> >>
> >>
> https://drizopoulos.github.io/GLMMadaptive/articles/Dynamic_Predictions.html
> >>
> >> if you're interested in dynamic predictions.
> >>
> >> Best,
> >> Dimitris
> >>
> >>
> >>
> >> On 10/23/2018 7:46 PM, John Wilson wrote:
> >>> Hello,
> >>>
> >>> I'm working on a glmmtmb() model with multiple continuous and
> categorical
> >>> predictors. Two of the predictors are orthogonal polynomials (I just
> saw
> >>> that the package was updated yesterday (!) to correctly handle those).
> >> One
> >>> of the polynomials has an interaction with another covariate.
> >>>
> >>> Since predict(re.form = 0) doesn't work just yet and one has to use
> >>> the model.matrix(lme4::nobars(formula(mod1)[-2]), newdata) approach -
> how
> >>> do I get the correct polynomial predictions out? It looks like my
> results
> >>> depend on how I structure the newdata data frame - when I use
> >>> expand.grid(), the predictions are wrong, but when I subset the
> original
> >>> data, the predictions are correct.
> >>>
> >>> Thanks so much!
> >>> John
> >>>
> >>> Here's an example:
> >>>
> >>> library(ggplot2)
> >>> library(glmmTMB)
> >>>
> >>> set.seed(0)
> >>> x <- 1:20
> >>> z <- sample(c("a", "b"), length(x), replace = TRUE)
> >>> y <- round(5 * 2*x + 3 * x^2 + 0.1 * x^3 + rnbinom(length(x), 10,
> 0.03))
> >>> group <- sample(c("i", "ii"), length(x), replace = TRUE)
> >>> df <- data.frame(x = x, y = y, z = z, group = group)
> >>> m <- glmmTMB(y ~ poly(x, 3) * z +
> >>> (1 | group),
> >>> family = nbinom2,
> >>> data = df)
> >>> # prediction on a new grid
> >>> newdata <- expand.grid(x = 1:20, z = unique(df$z))
> >>> X.cond = model.matrix(lme4::nobars(formula(m)[-2]), newdata)
> >>> beta.cond = fixef(m)$cond
> >>> newdata$Pred1 = as.numeric(X.cond %*% beta.cond)
> >>> # prediction in original data frame
> >>> X.cond = model.matrix(lme4::nobars(formula(m)[-2]))
> >>> beta.cond = fixef(m)$cond
> >>> df$Pred1 = as.numeric(X.cond %*% beta.cond)
> >>>
> >>> # the newdata preds are obviously off
> >>> ggplot(df) +
> >>> geom_point(aes(x = x, y = y, colour = z)) +
> >>> geom_line(data = newdata, aes(x = x, y = exp(Pred1), colour = z), size
> =
> >> 2)
> >>> +
> >>> geom_line(aes(x = x, y = exp(Pred1), colour = z, linetype = group))
> >>>
> >>> # if the new grid is defined like this, then the predictions are ok
> >>> newdata <- unique(select(df, x, z))
> >>> X.cond = model.matrix(lme4::nobars(formula(m)[-2]), newdata)
> >>> beta.cond = fixef(m)$cond
> >>> newdata$Pred1 = as.numeric(X.cond %*% beta.cond)
> >>> ggplot(df) +
> >>> geom_point(aes(x = x, y = y, colour = z)) +
> >>> geom_line(data = newdata, aes(x = x, y = exp(Pred1), colour = z), size
> =
> >> 2)
> >>> +
> >>> geom_line(aes(x = x, y = exp(Pred1), colour = z, linetype = group))
> >>>
> >>>       [[alternative HTML version deleted]]
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>
> >>
> >> --
> >> Dimitris Rizopoulos
> >> Professor of Biostatistics
> >> Department of Biostatistics
> >> Erasmus University Medical Center
> >>
> >> Address: PO Box 2040, 3000 CA Rotterdam, the Netherlands
> >> Tel: +31/(0)10/7043478
> >> Fax: +31/(0)10/7043014
> >> Web (personal): http://www.drizopoulos.com/
> >> Web (work): http://www.erasmusmc.nl/biostatistiek/
> >> Blog: http://iprogn.blogspot.nl/
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Wed Oct 24 16:51:02 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Wed, 24 Oct 2018 10:51:02 -0400
Subject: [R-sig-ME] population-level predict glmmtmb with poly()
In-Reply-To: <CABdA5Q0nojrzi2Npr5dY1dK+GPR4wJau=N01R4D_zp4ut8FqVA@mail.gmail.com>
References: <CABdA5Q123BEb66wy+BBHcUfSJ5-OznBEqg6CJ0VctU8ok-agxg@mail.gmail.com>
 <d5b43bb6-4a3b-8cf0-b11c-c64492d081f6@erasmusmc.nl>
 <CABdA5Q35s1_-sHX8jsCGCPDk+EpsBZXyA6jB=6jnzd1_BQ3VbA@mail.gmail.com>
 <274cb210-bdba-5eb3-e656-329e3d1cbc8a@gmail.com>
 <CABdA5Q0nojrzi2Npr5dY1dK+GPR4wJau=N01R4D_zp4ut8FqVA@mail.gmail.com>
Message-ID: <e75e03e7-c51e-a73c-4a60-e485b7d7b552@gmail.com>



On 2018-10-24 10:24 a.m., John Wilson wrote:
> So far it's looking just grand!?+1 for "it? wasn't documented until
> about 120 seconds ago".
> Just to push my luck here - in my full model, I have autocorrelation
> structures. When I only set group = NA, the predict() function gave me
> an error due to lack of the autocorrelation variable in the new data. I
> then crossed my fingers and did the same thing as for group - a column
> with NAs. The predict() function had no problem with that. However, I
> wanted to see if that's a (semi) legit way to doing it.

  Seems reasonable (but I can't give any guarantees without spending a
lot more time looking); I would try some simple tests and proceed if the
answers look OK.

> 
> On Tue, Oct 23, 2018 at 8:22 PM Ben Bolker <bbolker at gmail.com
> <mailto:bbolker at gmail.com>> wrote:
> 
> 
>     ? Naive prediction with data-dependent bases **will not work** with new
>     input variables. (This is a general R/model.matrix() thing ... not
>     glmmTMB's fault.)? The current development version of glmmTMB does some
>     magic (see ?makepredictcall,
>     https://developer.r-project.org/model-fitting-functions.html for more
>     detail) that makes this work.
> 
>     ? It wasn't documented until about 120 seconds ago, but in order to do
>     population-level predictions with predict() all you need to do is set
>     the group variable to NA.? This has less flexibility than the re.form=
>     argument in lme4 (which allows you to drop a *subset* of the random
>     effects terms for a given grouping variables), but it does handle the
>     most common use case ...
> 
>     ? Does this work for you (with devel version of glmmTMB) ?
> 
>     # prediction on a new grid
>     newdata <- expand.grid(x = 1:20, z = unique(df$z), group=NA)
>     newdata$y <- predict(m,newdata=newdata, type="response")
> 
>     (ggplot(df, aes(x,y, colour=z))
>     ? ? + geom_point()
>     ? ? + geom_line(data = newdata, size =2)
>     )
> 
> 
>     On 2018-10-23 6:48 p.m., John Wilson wrote:
>     > Thank you, Dimitris. I poked around a bit but didn't see mention of
>     > autocorrelation structures - are those supported as well?
>     >
>     > I was wondering if this issue was related to the problem logged here:
>     > https://github.com/glmmTMB/glmmTMB/issues/402. Can anyone comment on
>     > whether what I'm seeing is a bug or just a user (=me) mistake? When I
>     > change the toy example to be a simple linear form (rather than
>     poly()), the
>     > two predictions are identical, so I'm pretty sure it's a poly()
>     issue...
>     >
>     > On Tue, Oct 23, 2018 at 4:31 PM D. Rizopoulos
>     <d.rizopoulos at erasmusmc.nl <mailto:d.rizopoulos at erasmusmc.nl>>
>     > wrote:
>     >
>     >> You could fit the same model also using the GLMMadaptive package in
>     >> which the predict() method can produce predictions for the mean
>     subject
>     >> (i.e., the one with random effects values equal to 0), marginal
>     >> predictions (i.e., averaged over the subjects), and subject-specific
>     >> predictions.
>     >>
>     >> For more info you can have a look at:
>     >>
>     >> https://drizopoulos.github.io/GLMMadaptive/
>     >>
>     >>
>     >>
>     https://drizopoulos.github.io/GLMMadaptive/articles/Methods_MixMod.html#predictions
>     >>
>     >> and potentially also
>     >>
>     >>
>     >>
>     https://drizopoulos.github.io/GLMMadaptive/articles/Dynamic_Predictions.html
>     >>
>     >> if you're interested in dynamic predictions.
>     >>
>     >> Best,
>     >> Dimitris
>     >>
>     >>
>     >>
>     >> On 10/23/2018 7:46 PM, John Wilson wrote:
>     >>> Hello,
>     >>>
>     >>> I'm working on a glmmtmb() model with multiple continuous and
>     categorical
>     >>> predictors. Two of the predictors are orthogonal polynomials (I
>     just saw
>     >>> that the package was updated yesterday (!) to correctly handle
>     those).
>     >> One
>     >>> of the polynomials has an interaction with another covariate.
>     >>>
>     >>> Since predict(re.form = 0) doesn't work just yet and one has to use
>     >>> the model.matrix(lme4::nobars(formula(mod1)[-2]), newdata)
>     approach - how
>     >>> do I get the correct polynomial predictions out? It looks like
>     my results
>     >>> depend on how I structure the newdata data frame - when I use
>     >>> expand.grid(), the predictions are wrong, but when I subset the
>     original
>     >>> data, the predictions are correct.
>     >>>
>     >>> Thanks so much!
>     >>> John
>     >>>
>     >>> Here's an example:
>     >>>
>     >>> library(ggplot2)
>     >>> library(glmmTMB)
>     >>>
>     >>> set.seed(0)
>     >>> x <- 1:20
>     >>> z <- sample(c("a", "b"), length(x), replace = TRUE)
>     >>> y <- round(5 * 2*x + 3 * x^2 + 0.1 * x^3 + rnbinom(length(x),
>     10, 0.03))
>     >>> group <- sample(c("i", "ii"), length(x), replace = TRUE)
>     >>> df <- data.frame(x = x, y = y, z = z, group = group)
>     >>> m <- glmmTMB(y ~ poly(x, 3) * z +
>     >>> (1 | group),
>     >>> family = nbinom2,
>     >>> data = df)
>     >>> # prediction on a new grid
>     >>> newdata <- expand.grid(x = 1:20, z = unique(df$z))
>     >>> X.cond = model.matrix(lme4::nobars(formula(m)[-2]), newdata)
>     >>> beta.cond = fixef(m)$cond
>     >>> newdata$Pred1 = as.numeric(X.cond %*% beta.cond)
>     >>> # prediction in original data frame
>     >>> X.cond = model.matrix(lme4::nobars(formula(m)[-2]))
>     >>> beta.cond = fixef(m)$cond
>     >>> df$Pred1 = as.numeric(X.cond %*% beta.cond)
>     >>>
>     >>> # the newdata preds are obviously off
>     >>> ggplot(df) +
>     >>> geom_point(aes(x = x, y = y, colour = z)) +
>     >>> geom_line(data = newdata, aes(x = x, y = exp(Pred1), colour =
>     z), size =
>     >> 2)
>     >>> +
>     >>> geom_line(aes(x = x, y = exp(Pred1), colour = z, linetype = group))
>     >>>
>     >>> # if the new grid is defined like this, then the predictions are ok
>     >>> newdata <- unique(select(df, x, z))
>     >>> X.cond = model.matrix(lme4::nobars(formula(m)[-2]), newdata)
>     >>> beta.cond = fixef(m)$cond
>     >>> newdata$Pred1 = as.numeric(X.cond %*% beta.cond)
>     >>> ggplot(df) +
>     >>> geom_point(aes(x = x, y = y, colour = z)) +
>     >>> geom_line(data = newdata, aes(x = x, y = exp(Pred1), colour =
>     z), size =
>     >> 2)
>     >>> +
>     >>> geom_line(aes(x = x, y = exp(Pred1), colour = z, linetype = group))
>     >>>
>     >>>? ? ? ?[[alternative HTML version deleted]]
>     >>>
>     >>> _______________________________________________
>     >>> R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >>>
>     >>
>     >> --
>     >> Dimitris Rizopoulos
>     >> Professor of Biostatistics
>     >> Department of Biostatistics
>     >> Erasmus University Medical Center
>     >>
>     >> Address: PO Box 2040, 3000 CA Rotterdam, the Netherlands
>     >> Tel: +31/(0)10/7043478
>     >> Fax: +31/(0)10/7043014
>     >> Web (personal): http://www.drizopoulos.com/
>     >> Web (work): http://www.erasmusmc.nl/biostatistiek/
>     >> Blog: http://iprogn.blogspot.nl/
>     >
>     >? ? ? ?[[alternative HTML version deleted]]
>     >
>     > _______________________________________________
>     > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >
> 
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From jhwil@on@nb @ending from gm@il@com  Thu Oct 25 12:46:26 2018
From: jhwil@on@nb @ending from gm@il@com (John Wilson)
Date: Thu, 25 Oct 2018 07:46:26 -0300
Subject: [R-sig-ME] examine removal of autocorrelation in glmmTMB
Message-ID: <CABdA5Q1c398UivYLoaJMuGcAqaRE1ApReurCC4+2E3rpKsMH_Q@mail.gmail.com>

Hello,

I'm using a glmmTMB model with an autocorrelation structure. How do I check
if the autocorrelation has been successfully removed? In both lme and gamm,
I would extract normalized residuals, but I haven't seen a comparable
example for glmmTMB.

Thank you!
John

	[[alternative HTML version deleted]]


From y@@hree19 @ending from gm@il@com  Thu Oct 25 18:00:27 2018
From: y@@hree19 @ending from gm@il@com (Yashree Mehta)
Date: Thu, 25 Oct 2018 18:00:27 +0200
Subject: [R-sig-ME] Random intercept model- unbalanced cluster
Message-ID: <CAOE=hq+iHnNUfrzYOuKuNLx77uTA-zq1o0Xt67YabXZeSxNZng@mail.gmail.com>

Hi,

I am working with a random intercept model on a cluster dataset (Repeated
measurements of plots per household). I have the usual "X" vector
of covariates and one id variable which will make up the random
intercept. For example,

Response variable: Production of maize
Covariates: Size, input quantities, soil fertility dummies etc..
ID variable: Household_ID

However, about 40% of the households own one plot. The number of plots per
household ranges from 1 to 13.

When I estimated the random intercept model using lmer, I can extract a
random intercept for all households, irrespective of their number of plots.

How does lmer treat these households with just 1 plot? Also, is it
theoretically correct to include these observations ?

Thank you,

Regards,
Yashree

	[[alternative HTML version deleted]]


From p@wijer@tne @ending from ucl@@c@uk  Thu Oct 25 18:15:19 2018
From: p@wijer@tne @ending from ucl@@c@uk (Wijeratne, Peter)
Date: Thu, 25 Oct 2018 16:15:19 +0000
Subject: [R-sig-ME] Simulating data with nested random effects
In-Reply-To: <CAJuCY5xGNDyMKukutJ4M4QS_VLh72i3imXsESMU-2cSVNxyaKw@mail.gmail.com>
References: <HE1PR01MB29391404622F275C8CC31F14BFF80@HE1PR01MB2939.eurprd01.prod.exchangelabs.com>,
 <CAJuCY5xGNDyMKukutJ4M4QS_VLh72i3imXsESMU-2cSVNxyaKw@mail.gmail.com>
Message-ID: <HE1PR01MB29396165F51F48759E28C5E3BFF70@HE1PR01MB2939.eurprd01.prod.exchangelabs.com>

Dear Thierry,


Thanks very much for your code. I have expanded it to estimate the power of average treatment effect, for various combinations of site, subject, number of time points, and treatment effect size (copied at the end of this mail). It works nicely, predicting increasing power for increasing n_site or n_subject_site.


However, I see only small random differences in power as a function of the relative values of n_site and n_subject_site. For example, n_site = 10 and n_subject_site = 20 produces the same power (+- 0.01) as n_site = 4 and n_subject_site = 50. You can test this yourself using the code below, by setting "site.values" and "subject_site.values" to the appropriate values.


Naively I would expect there to be a more distinct dependency of power on the relative values of n_site and n_subject_site, since sigma_site and sigma_subject are not equal. For example, if I set sigma_site > sigma_subject, I would naively expect that increasing the number of sites should capture more of the between-site variance than increasing the number of subjects per site, and hence increase the power. However, I don't see any effect beyond random fluctuations, even when choosing extreme values.


Do you know why this is the case? Any insight would be greatly appreciated.


Best,

Pete


# example power analysis of treatment effect

set.seed(42)
library(lme4)
library(dplyr)

create_fake <- function(n_site, n_subject_site, n_time, effect){
  # change these hyper-parameters for testing
  intercept = 5
  trend = -0.2
  sigma_site = 0.4
  sigma_subject = 0.6
  sigma_noise = 0.1

  effect = -1.0*effect*trend
  re.site <- rnorm(n_site, mean = 0, sd = sigma_site)
  re.subject <- rnorm(n_site * n_subject_site, mean = 0, sd = sigma_subject)

  expand.grid(
    time = seq(0, (n_time-1), length = n_time),
    site = factor(seq_len(n_site)),
    subject = factor(seq_len(n_subject_site))
  ) %>%
    mutate(
      subject = factor(interaction(site, subject)),
      treatment = sample(rep(0:1, n_site*n_subject_site/2))[subject],
      fixed = intercept + (trend + effect*treatment)*time,
      random = re.site[site] + re.subject[subject],
      mu = fixed + random,
      y = rnorm(n(), mean = mu, sd = sigma_noise)
    )
}

trial.power <- function(n_site, n_subject_site, n_time, effect, n.sims=1000){
  signif <- rep (NA, n.sims)
  for (s in 1:n.sims){
    fake <- create_fake(n_site, n_subject_site, n_time, effect)
    lme.power <- lmer(
                  y ~ time + time:treatment + (1 | site/subject),
              data=fake
             )
    theta.hat <- coef(summary(lme.power))['time:treatment', 'Estimate']
    theta.se <- coef(summary(lme.power))['time:treatment', 'Std. Error']
    signif[s] <- ifelse (theta.hat - 2*theta.se > 0, 1, 0)
  }
  power <- mean(signif)
  return(power)
}

# change these values for testing
effect.values <- c(0.2,0.4,0.6,0.8,1.0)
site.values <- c(6, 8, 10, 15, 20, 40, 60, 100)
subject_site.values <- c(20)
time.values <- c(3)

for(i1 in 1:length(effect.values)){
 for(i2 in 1:length(site.values)){
  for(i3 in 1:length(subject_site.values)){
   for(i4 in 1:length(time.values)){
    power <- trial.power(site.values[i2], subject_site.values[i3], time.values[i4], effect.values[i1])
    cat("Power =", power ,", for effect =", effect.values[i1] ,", n_sites =", site.values[i2], ", n_subject_site =", subject_site.values[i3], ", n_time =", time.values[i4], "\n")
   }
  }
 }
}

________________________________
From: Thierry Onkelinx <thierry.onkelinx at inbo.be>
Sent: 21 October 2018 09:41:49
To: Wijeratne, Peter
Cc: r-sig-mixed-models
Subject: Re: [R-sig-ME] Simulating data with nested random effects

Dear Pete,

I rewrote your code to make it shorter and IMHO more readable. Meaningful variables names require less comments on what they are. The model yields sensible estimates on data simulated with the code below.

library(lme4)
library(dplyr)
create_fake <- function(
  n_site = 100, n_subject_site = 10, n_time = 10,
  intercept = 10, trend = 0.1, effect = 0.5,
  sigma_site = 5, sigma_subject = 2, sigma_noise = 1
){
  re.site <- rnorm(n_site, mean = 0, sd = sigma_site)
  re.subject <- rnorm(n_site * n_subject_site, mean = 0, sd = sigma_subject)

  expand.grid(
    time = seq(0, 2, length = n_time),
    site = seq_len(n_site),
    subject = seq_len(n_subject_site)
  ) %>%
    mutate(
      subject = interaction(site, subject),
      treatment = sample(0:1, size = n_site * n_subject_site,, replace = TRUE)[subject],
      fixed = intercept + effect * treatment + trend * time,
      random = re.site[site] + re.subject[subject],
      mu = fixed + random,
      y = rnorm(n(), mean = mu, sd = sigma_noise)
    )
}
dataset <- create_fake()
m <- lmer(y ~ treatment + time + (1|site/subject), data = dataset)
summary(m)

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be<http://www.inbo.be>

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

[https://inbo-website-prd-532750756126.s3-eu-west-1.amazonaws.com/inbologoleeuw_nl.png]<https://www.inbo.be>


Op do 18 okt. 2018 om 10:28 schreef Wijeratne, Peter <p.wijeratne at ucl.ac.uk<mailto:p.wijeratne at ucl.ac.uk>>:
Dear r-sig-mixed-models,


I would like to simulate nested data, where my mixed effects model fitted to real data has the form:

y ~ time + (1 | site/subject)

I then take the hyper-parameters from this model to simulate fake data, using this function:

create_fake <- function(J,K,L,HP,t){
# J : number of sites
# K : number of subjects / site
# L : number of years
# HP: hyperparameters from fit, y ~ time + (1 | site/subject)
# t: fractional effectiveness of treatment
time <- rep(seq(0,2,length=L), J*K)
subject <- rep(1:(J*K), each=L)
site <- sample(rep (1:J, K))
site1 <- factor(site[subject])
treatment <- sample(rep (0:1, J*K/2))
treatment1 <- treatment[subject]

# time coefficient
g.0.true <- as.numeric( HP['g.0.true'] )
# treatment coefficient
g.1.true <- -as.numeric(t)*g.0.true
# intercept
mu.a.true <- as.numeric( HP['mu.a.true'] )
# fixed effects
b.true <- (g.0.true + g.1.true*treatment)
# random effects
sigma.y.true <- as.numeric( HP['sigma.y.true'] ) # residual std dev
sigma.a.true <- as.numeric( HP['sigma.a.true'] ) # site std dev
sigma.a0.true <- as.numeric( HP['sigma.a0.true'] ) # site:person std dev
a0.true <- rnorm(J*K, 0, sigma.a0.true)
a.true <- rnorm(J*K, mu.a.true + a0.true, sigma.a.true)
y <- rnorm(J*K*L, a.true[subject] + b.true[subject]*time, sigma.y.true)

return(data.frame( y, time, subject, treatment1, site1 ))

I then fit models of the form:

y ~ time + time:treatment1 + (1 | site1/subject)

To the fake data. However, this approach can (but not always) produce a 'site' standard deviation approximately a factor of 10 less than in the real data.


My question is - is my simulation function correct?


Note - I can generate data and provide the full code if required.


Thanks in advance for any help.

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Fri Oct 26 01:45:45 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Thu, 25 Oct 2018 19:45:45 -0400
Subject: [R-sig-ME] Dependency structure
In-Reply-To: <CAOE=hqJdc97afTm4rrL566gxZ5rTgdHpxZDgzaPuF1Sv7JY5xA@mail.gmail.com>
References: <CAOE=hqLskrB+f1fnq2Uw-XYNbVyenYby4o=_ZecK5336D-=U3Q@mail.gmail.com>
 <a9e4d806-0e47-33c1-f1f4-ff5e23dd0240@gmail.com>
 <CAOE=hqJdc97afTm4rrL566gxZ5rTgdHpxZDgzaPuF1Sv7JY5xA@mail.gmail.com>
Message-ID: <a1cab4e4-514a-e18e-4e86-e52bc60afd1a@gmail.com>


  Please keep r-sig-mixed-models in the Cc: .

  I don't immediately see any way to allow a correlation between the
intercept terms and the X-covariates, nor even why that would
necessarily make sense.  I do recall that there's some stuff in the
causal inference literature (of special interest to economists)
surrounding this assumption, and how one can center covariates by group
to address the issue, but I can't remember where it is/point you to it
at the moment.  Perhaps someone else on the mailing list can help ...



On 2018-10-25 12:04 p.m., Yashree Mehta wrote:
> Hi Ben,
> 
> Thanks for your response. For the second question in your reply to this
> email, it is my mistake. I meant to incorporate correlation between the
> random intercept and X-covariates, not their beta coefficients. Is there
> a way to do that?
> 
> Regards
> Yashree-
> 
> On Wed, Oct 17, 2018 at 2:37 AM Ben Bolker <bbolker at gmail.com
> <mailto:bbolker at gmail.com>> wrote:
> 
> 
>     > Hi,
>     >
>     > Is there literature on how to specify the dependency structure
>     between the
>     > random intercept and the statistical noise error term in a random
>     intercept
>     > model?
>     > It would be useful to also know how to implement using R...
> 
> 
>     ? Can you be more specific about what you want?? Suppose you have
>     observations j within groups i, and you have an epsilon_{0,ij} for each
>     observation (error term) and an epsilon_"1,i} for each group (random
>     intercept).? Typically the epsilon_{0,ij} values are iid with
>     homogeneous variance sigma_0^2, and epsilon_{1,i} are iid with variance
>     sigma_1^2.? What kind of correlation structure are you looking for?
> 
>     While we're at it, you previously asked:
> 
>     ===
>     I am working with a random intercept model. I have the usual "X" vector
>     of covariates and one id variable which will make up the random
>     intercept. For example,
> 
>     Response variable: Production of maize
>     Covariate: Size of plot
>     ID variable: Household_ID
> 
>     I need to acknowledge that there is correlation between the FIXED EFFECT
>     coefficient of plot size and the estimated random intercept. It is my
>     model assumption.
> 
>     Does lme4 assume this correlation or do I have to make changes in the
>     formula so that it gets considered?
>     ===
> 
>     ? The short answer to this one is "no", I think -- I don't know that
>     there's a way to allow for correlation between fixed effect coefficients
>     and random intercepts. (This actually seems like a weird question to me;
>     in the frequentist world, as far as I know, you can only specify
>     correlation models for *random variables* within the model.? In the
>     context of LMM fitting, I don't think parameters are random effects in
>     this sense.
> 
>     On 2018-10-16 01:03 PM, Yashree Mehta wrote:
> 
>     >
>     > Thank you
>     >
>     > Yashree
>     >
>     >? ? ? ?[[alternative HTML version deleted]]
>     >
>     > _______________________________________________
>     > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >
> 
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From jdpo223 @ending from g@uky@edu  Fri Oct 26 02:30:48 2018
From: jdpo223 @ending from g@uky@edu (Poe, John)
Date: Thu, 25 Oct 2018 20:30:48 -0400
Subject: [R-sig-ME] Dependency structure
In-Reply-To: <a1cab4e4-514a-e18e-4e86-e52bc60afd1a@gmail.com>
References: <CAOE=hqLskrB+f1fnq2Uw-XYNbVyenYby4o=_ZecK5336D-=U3Q@mail.gmail.com>
 <a9e4d806-0e47-33c1-f1f4-ff5e23dd0240@gmail.com>
 <CAOE=hqJdc97afTm4rrL566gxZ5rTgdHpxZDgzaPuF1Sv7JY5xA@mail.gmail.com>
 <a1cab4e4-514a-e18e-4e86-e52bc60afd1a@gmail.com>
Message-ID: <CAFW8BypBtkwEWOKzajv=D0EXFerrRMbT-9rGHm7u47PQ+dQ4VA@mail.gmail.com>

Here's a link to my previous post on the topic of model specification and
endogeneity (correlation between X and the grouping structure). You
basically either do group mean centering or group varying coefficients.
However,  those aren't bullet proof depending on your data structure.

Also, i did a thread on twitter a while back that is related and links some
additional readings. I have a link to my advanced multilevel syllabus for
the icpsr program on the Twitter thead and it has a pretty decent reading
list on there.

https://stat.ethz.ch/pipermail/r-sig-mixed-models/2016q4/025150.html

https://twitter.com/DavidPoe223/status/1009485620337692674?s=09



On Thu, Oct 25, 2018, 8:05 PM Ben Bolker <bbolker at gmail.com> wrote:

>
>   Please keep r-sig-mixed-models in the Cc: .
>
>   I don't immediately see any way to allow a correlation between the
> intercept terms and the X-covariates, nor even why that would
> necessarily make sense.  I do recall that there's some stuff in the
> causal inference literature (of special interest to economists)
> surrounding this assumption, and how one can center covariates by group
> to address the issue, but I can't remember where it is/point you to it
> at the moment.  Perhaps someone else on the mailing list can help ...
>
>
>
> On 2018-10-25 12:04 p.m., Yashree Mehta wrote:
> > Hi Ben,
> >
> > Thanks for your response. For the second question in your reply to this
> > email, it is my mistake. I meant to incorporate correlation between the
> > random intercept and X-covariates, not their beta coefficients. Is there
> > a way to do that?
> >
> > Regards
> > Yashree-
> >
> > On Wed, Oct 17, 2018 at 2:37 AM Ben Bolker <bbolker at gmail.com
> > <mailto:bbolker at gmail.com>> wrote:
> >
> >
> >     > Hi,
> >     >
> >     > Is there literature on how to specify the dependency structure
> >     between the
> >     > random intercept and the statistical noise error term in a random
> >     intercept
> >     > model?
> >     > It would be useful to also know how to implement using R...
> >
> >
> >       Can you be more specific about what you want?  Suppose you have
> >     observations j within groups i, and you have an epsilon_{0,ij} for
> each
> >     observation (error term) and an epsilon_"1,i} for each group (random
> >     intercept).  Typically the epsilon_{0,ij} values are iid with
> >     homogeneous variance sigma_0^2, and epsilon_{1,i} are iid with
> variance
> >     sigma_1^2.  What kind of correlation structure are you looking for?
> >
> >     While we're at it, you previously asked:
> >
> >     ===
> >     I am working with a random intercept model. I have the usual "X"
> vector
> >     of covariates and one id variable which will make up the random
> >     intercept. For example,
> >
> >     Response variable: Production of maize
> >     Covariate: Size of plot
> >     ID variable: Household_ID
> >
> >     I need to acknowledge that there is correlation between the FIXED
> EFFECT
> >     coefficient of plot size and the estimated random intercept. It is my
> >     model assumption.
> >
> >     Does lme4 assume this correlation or do I have to make changes in the
> >     formula so that it gets considered?
> >     ===
> >
> >       The short answer to this one is "no", I think -- I don't know that
> >     there's a way to allow for correlation between fixed effect
> coefficients
> >     and random intercepts. (This actually seems like a weird question to
> me;
> >     in the frequentist world, as far as I know, you can only specify
> >     correlation models for *random variables* within the model.  In the
> >     context of LMM fitting, I don't think parameters are random effects
> in
> >     this sense.
> >
> >     On 2018-10-16 01:03 PM, Yashree Mehta wrote:
> >
> >     >
> >     > Thank you
> >     >
> >     > Yashree
> >     >
> >     >       [[alternative HTML version deleted]]
> >     >
> >     > _______________________________________________
> >     > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     >
> >
> >     _______________________________________________
> >     R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From m@lcolm@f@irbrother @ending from umu@@e  Fri Oct 26 11:02:35 2018
From: m@lcolm@f@irbrother @ending from umu@@e (Malcolm Fairbrother)
Date: Fri, 26 Oct 2018 09:02:35 +0000
Subject: [R-sig-ME] Dependency structure
In-Reply-To: <mailman.16991.7220.1540512356.1179.r-sig-mixed-models@r-project.org>
References: <mailman.16991.7220.1540512356.1179.r-sig-mixed-models@r-project.org>
Message-ID: <2A2556A8-BA65-4051-A83A-FE7BCB67F27E@umu.se>

Hi,

John Poe?s response to this just now is very helpful.

Yashree, you may find it helpful to look at some code I wrote to run simulations effectively implementing what John suggests (distinguishing between from within effects). A paper presenting the simulations is here <https://doi.org/10.1017/psrm.2013.24>, and the R code is in the supplementary material linked from that website. I used the ?rmsn? function to generate random intercepts that are correlated with a group-level covariate?which I take it is the issue you want to deal with.

Other than using a ?REWB? specification (see also https://doi.org/10.1007/s11135-018-0802-x), I?m not sure there?s much you can do.

Hope that helps,
Malcolm


Malcolm Fairbrother

Professor of Sociology, Ume? University<http://www.soc.umu.se/english/>
Researcher, Institute for Futures Studies<https://www.iffs.se/en/>
Sweden



Date: Thu, 25 Oct 2018 19:45:45 -0400
From: Ben Bolker <bbolker at gmail.com<mailto:bbolker at gmail.com>>
To: Yashree Mehta <yashree19 at gmail.com<mailto:yashree19 at gmail.com>>
Cc: "r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>"
<r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
Subject: Re: [R-sig-ME] Dependency structure
Message-ID: <a1cab4e4-514a-e18e-4e86-e52bc60afd1a at gmail.com<mailto:a1cab4e4-514a-e18e-4e86-e52bc60afd1a at gmail.com>>
Content-Type: text/plain; charset="utf-8"


 Please keep r-sig-mixed-models in the Cc: .

 I don't immediately see any way to allow a correlation between the
intercept terms and the X-covariates, nor even why that would
necessarily make sense.  I do recall that there's some stuff in the
causal inference literature (of special interest to economists)
surrounding this assumption, and how one can center covariates by group
to address the issue, but I can't remember where it is/point you to it
at the moment.  Perhaps someone else on the mailing list can help ...



On 2018-10-25 12:04 p.m., Yashree Mehta wrote:
Hi Ben,

Thanks for your response. For the second question in your reply to this
email, it is my mistake. I meant to incorporate correlation between the
random intercept and X-covariates, not their beta coefficients. Is there
a way to do that?

Regards
Yashree-

On Wed, Oct 17, 2018 at 2:37 AM Ben Bolker <bbolker at gmail.com<mailto:bbolker at gmail.com>
<mailto:bbolker at gmail.com>> wrote:


Hi,

Is there literature on how to specify the dependency structure
   between the
random intercept and the statistical noise error term in a random
   intercept
model?
It would be useful to also know how to implement using R...


     Can you be more specific about what you want?  Suppose you have
   observations j within groups i, and you have an epsilon_{0,ij} for each
   observation (error term) and an epsilon_"1,i} for each group (random
   intercept).  Typically the epsilon_{0,ij} values are iid with
   homogeneous variance sigma_0^2, and epsilon_{1,i} are iid with variance
   sigma_1^2.  What kind of correlation structure are you looking for?

   While we're at it, you previously asked:

   ===
   I am working with a random intercept model. I have the usual "X" vector
   of covariates and one id variable which will make up the random
   intercept. For example,

   Response variable: Production of maize
   Covariate: Size of plot
   ID variable: Household_ID

   I need to acknowledge that there is correlation between the FIXED EFFECT
   coefficient of plot size and the estimated random intercept. It is my
   model assumption.

   Does lme4 assume this correlation or do I have to make changes in the
   formula so that it gets considered?
   ===

     The short answer to this one is "no", I think -- I don't know that
   there's a way to allow for correlation between fixed effect coefficients
   and random intercepts. (This actually seems like a weird question to me;
   in the frequentist world, as far as I know, you can only specify
   correlation models for *random variables* within the model.  In the
   context of LMM fitting, I don't think parameters are random effects in
   this sense.

   On 2018-10-16 01:03 PM, Yashree Mehta wrote:


Thank you

Yashree

       [[alternative HTML version deleted]]


	[[alternative HTML version deleted]]


From @deel@@u@f @ending from gm@il@com  Sun Oct 28 12:47:02 2018
From: @deel@@u@f @ending from gm@il@com (Adeela Munawar)
Date: Sun, 28 Oct 2018 16:47:02 +0500
Subject: [R-sig-ME] Simulations in Fisher's Exact test
Message-ID: <CABGg3O5zJAuLw33QZiEDmOrG7kBkBd_-XypvKTMypKjsmexwOg@mail.gmail.com>

hi all,
Probably I am posted in wrong mailing list. I am getting a problem in
applying Fisher's exact test. I am applying Fisher's exact test as

 ntable<- array(data = c(3, 1, 8,11), dim = c(2,2))
fisher.test(ntable)

now, I have to repeat the same 10000 times and have to report p-values.
Using the arguments simulate.p.value in the command is producing the same
results
test<-fisher.test(ntable,workspace=20000,simulate.p.value=T,B=10000)

what changes I have to made in my model.

regards
Adeela

	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Sun Oct 28 17:18:44 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Sun, 28 Oct 2018 12:18:44 -0400
Subject: [R-sig-ME] Simulations in Fisher's Exact test
In-Reply-To: <CABGg3O5zJAuLw33QZiEDmOrG7kBkBd_-XypvKTMypKjsmexwOg@mail.gmail.com>
References: <CABGg3O5zJAuLw33QZiEDmOrG7kBkBd_-XypvKTMypKjsmexwOg@mail.gmail.com>
Message-ID: <b9fd6b4b-e9e6-d368-4148-d9762544e169@gmail.com>


  This is indeed the wrong list; r-help at r-project.org, or StackOverflow,
might be more appropriate.  I am guessing this is an assignment for a
class?  If so, it might be more useful to get clarification from your
instructor or teaching assistant (or a colleague in your class). The
help page for ?fisher.test says:

simulate.p.value: a logical indicating whether to compute p-values by
          Monte Carlo simulation, **in larger than 2 by 2 tables**.

Emphasis (**) added.  Since you're using a 2x2 table, I'm guessing that
simulate.p.value has no effect ...  R probably should warn you, but oh
well ..


On 2018-10-28 7:47 a.m., Adeela Munawar wrote:
> hi all,
> Probably I am posted in wrong mailing list. I am getting a problem in
> applying Fisher's exact test. I am applying Fisher's exact test as
> 
>  ntable<- array(data = c(3, 1, 8,11), dim = c(2,2))
> fisher.test(ntable)
> 
> now, I have to repeat the same 10000 times and have to report p-values.
> Using the arguments simulate.p.value in the command is producing the same
> results
> test<-fisher.test(ntable,workspace=20000,simulate.p.value=T,B=10000)
> 
> what changes I have to made in my model.
> 
> regards
> Adeela
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From m@ir@f@toretto @ending from gm@il@com  Mon Oct 29 08:25:33 2018
From: m@ir@f@toretto @ending from gm@il@com (Maira Fatoretto)
Date: Mon, 29 Oct 2018 04:25:33 -0300
Subject: [R-sig-ME] glmmTMB
Message-ID: <CAB4qdLPPXcLcLXxv=GbBrfM1cRE9tM0Mje7WWXM5vo+UDdVDdQ@mail.gmail.com>

Hello,

I am using glmmTMb with binomial family. I chose REML=TRUE  because I have
three random effects and I would like to know which is the restriction used
in this  estimation in the package.
The REML = TRUE have better estimation than ML in my case.



Thank you.
Best regards.



-- 
*Ma?ra Blumer Fatoretto*
Estat?stica - Universidade Estadual de Campinas- UNICAMP
Mestra em Ci?ncias(Estat?stica e Experimenta??o Agron?mica) - ESALQ/USP -
Piracicaba - SP
Doutoranda em Estat?stica e Experimenta??o Agron?mica
Telefone:(19) 988309481
E-mail: mairafatoretto at gmail.com

	[[alternative HTML version deleted]]


From @lex@ndre@courtiol @ending from gm@il@com  Mon Oct 29 12:11:24 2018
From: @lex@ndre@courtiol @ending from gm@il@com (Alexandre Courtiol)
Date: Mon, 29 Oct 2018 12:11:24 +0100
Subject: [R-sig-ME] Simulations in Fisher's Exact test
In-Reply-To: <mailman.16997.5.1540810802.51314.r-sig-mixed-models@r-project.org>
References: <mailman.16997.5.1540810802.51314.r-sig-mixed-models@r-project.org>
Message-ID: <CAERMt4dwmh1rLe_gdLBw8_K-cutyFVFphwHBL85tQCNtHswH1w@mail.gmail.com>

>
> Message: 2
> Date: Sun, 28 Oct 2018 12:18:44 -0400
> From: Ben Bolker <bbolker at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Simulations in Fisher's Exact test
> Message-ID: <b9fd6b4b-e9e6-d368-4148-d9762544e169 at gmail.com>
> Content-Type: text/plain; charset="utf-8"
>
>
>   This is indeed the wrong list; r-help at r-project.org, or StackOverflow,
> might be more appropriate.  I am guessing this is an assignment for a
> class?  If so, it might be more useful to get clarification from your
> instructor or teaching assistant (or a colleague in your class). The
> help page for ?fisher.test says:
>
> simulate.p.value: a logical indicating whether to compute p-values by
>           Monte Carlo simulation, **in larger than 2 by 2 tables**.
>
> Emphasis (**) added.  Since you're using a 2x2 table, I'm guessing that
> simulate.p.value has no effect ...  R probably should warn you, but oh
> well ..
>
>
> On 2018-10-28 7:47 a.m., Adeela Munawar wrote:
> > hi all,
> > Probably I am posted in wrong mailing list. I am getting a problem in
> > applying Fisher's exact test. I am applying Fisher's exact test as
> >
> >  ntable<- array(data = c(3, 1, 8,11), dim = c(2,2))
> > fisher.test(ntable)
> >
> > now, I have to repeat the same 10000 times and have to report p-values.
> > Using the arguments simulate.p.value in the command is producing the same
> > results
> > test<-fisher.test(ntable,workspace=20000,simulate.p.value=T,B=10000)
> >
> > what changes I have to made in my model.
> >
> > regards
> > Adeela
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> Adeela, with simulate.p.value = FALSE, the Fisher exact test will attempt
to create all possible contingency tables (keeping marginal sum constant)
to compute the p-value of the test. With simulate.p.value = TRUE (when it
has an effect -> see Ben's comment), it will only sample the space of
possible contingency tables. If the number of possible contingency tables
is not too large, there is not need to use simulate.p.value and if it is
lower than the number of table you simulate, then you should obtain nearly
the same results anyhow. In other words, I don't really understand what you
are trying to achieve but a simple call to fisher.test(ntable) should do
the job.
++
Alex

	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Mon Oct 29 13:48:05 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Mon, 29 Oct 2018 08:48:05 -0400
Subject: [R-sig-ME] glmmTMB
In-Reply-To: <CAB4qdLPPXcLcLXxv=GbBrfM1cRE9tM0Mje7WWXM5vo+UDdVDdQ@mail.gmail.com>
References: <CAB4qdLPPXcLcLXxv=GbBrfM1cRE9tM0Mje7WWXM5vo+UDdVDdQ@mail.gmail.com>
Message-ID: <CABghstQFdj44Awgfhj66ZTSEAarx1xTGOVZk=XzhJ5B0vd_uBg@mail.gmail.com>

   glmmTMB implements REML by treating the fixed effect parameters as
'random variables', i.e. turning on the Laplace approximation
machinery; see http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#reml-for-glmms
for starting points in the literature.

https://github.com/glmmTMB/glmmTMB/blob/master/glmmTMB/R/glmmTMB.R#L191
On Mon, Oct 29, 2018 at 6:26 AM Maira Fatoretto
<mairafatoretto at gmail.com> wrote:
>
> Hello,
>
> I am using glmmTMb with binomial family. I chose REML=TRUE  because I have
> three random effects and I would like to know which is the restriction used
> in this  estimation in the package.
> The REML = TRUE have better estimation than ML in my case.
>
>
>
> Thank you.
> Best regards.
>
>
>
> --
> *Ma?ra Blumer Fatoretto*
> Estat?stica - Universidade Estadual de Campinas- UNICAMP
> Mestra em Ci?ncias(Estat?stica e Experimenta??o Agron?mica) - ESALQ/USP -
> Piracicaba - SP
> Doutoranda em Estat?stica e Experimenta??o Agron?mica
> Telefone:(19) 988309481
> E-mail: mairafatoretto at gmail.com
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From y@@hree19 @ending from gm@il@com  Mon Oct 29 22:13:06 2018
From: y@@hree19 @ending from gm@il@com (Yashree Mehta)
Date: Mon, 29 Oct 2018 22:13:06 +0100
Subject: [R-sig-ME] Random intercept model- unbalanced cluster
In-Reply-To: <CAOE=hq+iHnNUfrzYOuKuNLx77uTA-zq1o0Xt67YabXZeSxNZng@mail.gmail.com>
References: <CAOE=hq+iHnNUfrzYOuKuNLx77uTA-zq1o0Xt67YabXZeSxNZng@mail.gmail.com>
Message-ID: <CAOE=hq+3u9pAr5Xp-BMWeQ4JNE-ZVpm6YYS=wEmUXhGVihvG8w@mail.gmail.com>

Or is there an alternative method of modeling this subset of households who
only own one plot?

thank you,

Regards,
Yashree

On Thu, Oct 25, 2018 at 6:00 PM Yashree Mehta <yashree19 at gmail.com> wrote:

> Hi,
>
> I am working with a random intercept model on a cluster dataset (Repeated
> measurements of plots per household). I have the usual "X" vector
> of covariates and one id variable which will make up the random
> intercept. For example,
>
> Response variable: Production of maize
> Covariates: Size, input quantities, soil fertility dummies etc..
> ID variable: Household_ID
>
> However, about 40% of the households own one plot. The number of plots per
> household ranges from 1 to 13.
>
> When I estimated the random intercept model using lmer, I can extract a
> random intercept for all households, irrespective of their number of plots.
>
> How does lmer treat these households with just 1 plot? Also, is it
> theoretically correct to include these observations ?
>
> Thank you,
>
> Regards,
> Yashree
>
>
>

	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Mon Oct 29 22:23:16 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Mon, 29 Oct 2018 17:23:16 -0400
Subject: [R-sig-ME] Random intercept model- unbalanced cluster
In-Reply-To: <CAOE=hq+3u9pAr5Xp-BMWeQ4JNE-ZVpm6YYS=wEmUXhGVihvG8w@mail.gmail.com>
References: <CAOE=hq+iHnNUfrzYOuKuNLx77uTA-zq1o0Xt67YabXZeSxNZng@mail.gmail.com>
 <CAOE=hq+3u9pAr5Xp-BMWeQ4JNE-ZVpm6YYS=wEmUXhGVihvG8w@mail.gmail.com>
Message-ID: <1a88c90a-8869-3b01-072d-57513f5293c4@gmail.com>


  In principle lme4 shouldn't have problems with a subset of groups that
have only one observation (although clearly the model will get more
fragile/unreliable the less information is available about within vs
among group variation ...).  I'd expect the random effects for groups
with only one observation to be strongly shrunk toward the population
mean ... if in doubt, it can be very useful to simulate a situation
similar to your real data set to see what happens in cases where you
know the real answer ...



On 2018-10-29 5:13 p.m., Yashree Mehta wrote:
> Or is there an alternative method of modeling this subset of households who
> only own one plot?
> 
> thank you,
> 
> Regards,
> Yashree
> 
> On Thu, Oct 25, 2018 at 6:00 PM Yashree Mehta <yashree19 at gmail.com> wrote:
> 
>> Hi,
>>
>> I am working with a random intercept model on a cluster dataset (Repeated
>> measurements of plots per household). I have the usual "X" vector
>> of covariates and one id variable which will make up the random
>> intercept. For example,
>>
>> Response variable: Production of maize
>> Covariates: Size, input quantities, soil fertility dummies etc..
>> ID variable: Household_ID
>>
>> However, about 40% of the households own one plot. The number of plots per
>> household ranges from 1 to 13.
>>
>> When I estimated the random intercept model using lmer, I can extract a
>> random intercept for all households, irrespective of their number of plots.
>>
>> How does lmer treat these households with just 1 plot? Also, is it
>> theoretically correct to include these observations ?
>>
>> Thank you,
>>
>> Regards,
>> Yashree
>>
>>
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From jhwil@on@nb @ending from gm@il@com  Tue Oct 30 00:58:09 2018
From: jhwil@on@nb @ending from gm@il@com (John Wilson)
Date: Mon, 29 Oct 2018 20:58:09 -0300
Subject: [R-sig-ME] zero-inflated glmmTMB with poly() - confidence band
Message-ID: <CABdA5Q0o2nJTRFo+mj6Hcz_UbZ+6DM0Rxfzmyk2aOwzovjc92g@mail.gmail.com>

Hello,

I've been using the newly documented predict() with group = NA to predict
population-level values, as per the thread here (
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2018q4/027305.html). A
follow-up question: in the case of a zero-inflated model, how would I go
about to get the 95% CIs for response predictions? Obviously, I can get
them for the count and the zero-component, and without poly(), I would just
follow the example in Brooks et al (2017).

However, I have a poly() predictor; how do I get the 95% CIs if I can't use
model.matrix naively when I have a poly() in the model? The models take a
while to converge, so I don't want to run a full bootstrapping either, if
at all possible.

Thank you!
John

Here's a toy dataset:

library(ggplot2)
library(glmmTMB)

set.seed(0)
x <- 1:20
z <- sample(c("a", "b"), length(x), replace = TRUE)
y <- round(5 * 2*x + 3 * x^2 + 0.1 * x^3 + rnbinom(length(x), 10, 0.03))
y[c(2, 3, 5, 11, 13, 19)] <- 0
group <- sample(c("i", "ii"), length(x), replace = TRUE)
df <- data.frame(x = x, y = y, z = z, group = group)

ggplot(df) +
geom_point(aes(x = x, y = y, colour = z))

m <- glmmTMB(y ~ poly(x, 3) * z +
(1 | group),
zi = ~ z,
family = nbinom1,
data = df)
# prediction on a new grid
newdata <- expand.grid(x = 1:20, z = unique(df$z), group = NA)
newdata$Pred <- predict(m, type = "response")
### now how to add CIs?

ggplot(df) +
geom_point(aes(x = x, y = y, colour = z)) +
geom_line(data = newdata, aes(x = x, y = Pred, colour = z, group = z), size
= 2) +
facet_wrap(~ z)

	[[alternative HTML version deleted]]


From drki@mu@@ @ending from gm@il@com  Tue Oct 30 06:18:25 2018
From: drki@mu@@ @ending from gm@il@com (K Imran M)
Date: Tue, 30 Oct 2018 13:18:25 +0800
Subject: [R-sig-ME] intercept and threshold values to calculate probability
 based on mixor package
Message-ID: <CADop7+greXQ2ES1YmB3WyF4o80sdC-Dkm_tkRJOMb8g3EQHnCA@mail.gmail.com>

Hi everyone,

I need help to identify the values for intercept and thresholds in the
equations to calculate the probability (based on cumulative link models).

On page 209 in Longitudinal Data Analysis book by Hedeker, the
probabilities are written as:

Pr(Yij=1) = 1/{1 + exp[-(v1 -(xijB+zijV))]}
Pr(Yij=2) = 1/{1 + exp[-(v2 -(xijB+zijV))]} - Pr(Yij=1)
Pr(Yij=3) = 1/{1 + exp[-(v3 -(xijB+zijV))]} - Pr(Yij=2)
Pr(Yij=4) = 1 - 1/{1 + exp[-(v3 -(xijB+zijV))]}

My question is what are the values for v1, v2 and v3?

The R scripts below shows the codes and the results from running mixor.

library(mixor)
#> Loading required package: survival
data("schizophrenia")
mixor.mod <- mixor(imps79o ~ TxDrug + SqrtWeek + TxSWeek,
                     data = schizophrenia, id = id, which.random.slope = 2,
link = "logit")
summary(mixor.mod)

#>
#>                          Estimate Std. Error z value   P(>|z|)
#> (Intercept)              7.318831   0.480778 15.2229 < 2.2e-16 ***
#> SqrtWeek                -0.882261   0.234568 -3.7612 0.0001691 ***
#> TxDrug                   0.057917   0.399102  0.1451 0.8846178
#> TxSWeek                 -1.694861   0.268131 -6.3210 2.598e-10 ***
#> (Intercept) (Intercept)  6.997646   1.369273  5.1105 3.213e-07 ***
#> (Intercept) SqrtWeek    -1.508514   0.536023 -2.8143 0.0048888 **
#> SqrtWeek SqrtWeek        2.008916   0.453587  4.4290 9.469e-06 ***
#> Threshold2               3.901260   0.213257 18.2937 < 2.2e-16 ***
#> Threshold3               6.507172   0.289991 22.4392 < 2.2e-16 ***
#> ---
#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1


Thank you very much.

Best wishes,

Kamarul Imran Musa
MD PhD
Universiti Sains Malaysia
Malaysia

	[[alternative HTML version deleted]]


From drki@mu@@ @ending from gm@il@com  Tue Oct 30 07:49:57 2018
From: drki@mu@@ @ending from gm@il@com (K Imran M)
Date: Tue, 30 Oct 2018 14:49:57 +0800
Subject: [R-sig-ME] 
 intercept and threshold values to calculate probability
 based on mixor package
In-Reply-To: <CADop7+greXQ2ES1YmB3WyF4o80sdC-Dkm_tkRJOMb8g3EQHnCA@mail.gmail.com>
References: <CADop7+greXQ2ES1YmB3WyF4o80sdC-Dkm_tkRJOMb8g3EQHnCA@mail.gmail.com>
Message-ID: <CADop7+jF-wKbx3AUShkPM1=ck+YLyDEDgbY_uepEUUYJyaE1uQ@mail.gmail.com>

Let me improve the question. On page 209, the authors wrote this for
Pr(Yij=1);
Pr(Yij=1) = 1/{1 + exp[7.31 + ....]} . Unfortunately. the values given for
the rest of the formula for Yij=2 and Yij=3.

My questions are:
1) Why v1 is 7.31 and not  -7.31
2) What are the values for v2 and v3

Thanks David for your reply. Can you be more specific?

Best wishes,

Kamarul




On Tue, Oct 30, 2018 at 1:18 PM K Imran M <drki.musa at gmail.com> wrote:

> Hi everyone,
>
> I need help to identify the values for intercept and thresholds in the
> equations to calculate the probability (based on cumulative link models).
>
> On page 209 in Longitudinal Data Analysis book by Hedeker, the
> probabilities are written as:
>
> Pr(Yij=1) = 1/{1 + exp[-(v1 -(xijB+zijV))]}
> Pr(Yij=2) = 1/{1 + exp[-(v2 -(xijB+zijV))]} - Pr(Yij=1)
> Pr(Yij=3) = 1/{1 + exp[-(v3 -(xijB+zijV))]} - Pr(Yij=2)
> Pr(Yij=4) = 1 - 1/{1 + exp[-(v3 -(xijB+zijV))]}
>
> My question is what are the values for v1, v2 and v3?
>
> The R scripts below shows the codes and the results from running mixor.
>
> library(mixor)
> #> Loading required package: survival
> data("schizophrenia")
> mixor.mod <- mixor(imps79o ~ TxDrug + SqrtWeek + TxSWeek,
>                      data = schizophrenia, id = id, which.random.slope =
> 2, link = "logit")
> summary(mixor.mod)
>
> #>
> #>                          Estimate Std. Error z value   P(>|z|)
> #> (Intercept)              7.318831   0.480778 15.2229 < 2.2e-16 ***
> #> SqrtWeek                -0.882261   0.234568 -3.7612 0.0001691 ***
> #> TxDrug                   0.057917   0.399102  0.1451 0.8846178
> #> TxSWeek                 -1.694861   0.268131 -6.3210 2.598e-10 ***
> #> (Intercept) (Intercept)  6.997646   1.369273  5.1105 3.213e-07 ***
> #> (Intercept) SqrtWeek    -1.508514   0.536023 -2.8143 0.0048888 **
> #> SqrtWeek SqrtWeek        2.008916   0.453587  4.4290 9.469e-06 ***
> #> Threshold2               3.901260   0.213257 18.2937 < 2.2e-16 ***
> #> Threshold3               6.507172   0.289991 22.4392 < 2.2e-16 ***
> #> ---
> #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
>
> Thank you very much.
>
> Best wishes,
>
> Kamarul Imran Musa
> MD PhD
> Universiti Sains Malaysia
> Malaysia
>

	[[alternative HTML version deleted]]


From d@rizopoulo@ @ending from er@@mu@mc@nl  Tue Oct 30 09:37:09 2018
From: d@rizopoulo@ @ending from er@@mu@mc@nl (D. Rizopoulos)
Date: Tue, 30 Oct 2018 08:37:09 +0000
Subject: [R-sig-ME] zero-inflated glmmTMB with poly() - confidence band
In-Reply-To: <CABdA5Q0o2nJTRFo+mj6Hcz_UbZ+6DM0Rxfzmyk2aOwzovjc92g@mail.gmail.com>
References: <CABdA5Q0o2nJTRFo+mj6Hcz_UbZ+6DM0Rxfzmyk2aOwzovjc92g@mail.gmail.com>
Message-ID: <0081daab-0ed7-4748-bde8-8fe569aa22e3@erasmusmc.nl>

You can use still compute the correct design matrix when using poly() on 
newdata by working with a terms objects that has an appropriately 
defined the 'predvars' attribute. For an example, check the following:

# data and new data for prediction
DF <- data.frame(y = rnorm(10), x = rnorm(10))
newDF <- data.frame(x = rnorm(10))

# *wrong* design matrix X on new data
X_new1 <- model.matrix(~ poly(x, 3), data = newDF)

# correct design matrix on new data
termsX <- terms(model.frame(y ~ poly(x, 3), data = DF))
# check predvars attribute
attr(termsX, "predvars")
X_new2 <- model.matrix(delete.response(termsX), data = newDF)

head(X_new1)
head(X_new2)

Best,
Dimitris



On 10/30/2018 12:58 AM, John Wilson wrote:
> Hello,
> 
> I've been using the newly documented predict() with group = NA to predict
> population-level values, as per the thread here (
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2018q4/027305.html). A
> follow-up question: in the case of a zero-inflated model, how would I go
> about to get the 95% CIs for response predictions? Obviously, I can get
> them for the count and the zero-component, and without poly(), I would just
> follow the example in Brooks et al (2017).
> 
> However, I have a poly() predictor; how do I get the 95% CIs if I can't use
> model.matrix naively when I have a poly() in the model? The models take a
> while to converge, so I don't want to run a full bootstrapping either, if
> at all possible.
> 
> Thank you!
> John
> 
> Here's a toy dataset:
> 
> library(ggplot2)
> library(glmmTMB)
> 
> set.seed(0)
> x <- 1:20
> z <- sample(c("a", "b"), length(x), replace = TRUE)
> y <- round(5 * 2*x + 3 * x^2 + 0.1 * x^3 + rnbinom(length(x), 10, 0.03))
> y[c(2, 3, 5, 11, 13, 19)] <- 0
> group <- sample(c("i", "ii"), length(x), replace = TRUE)
> df <- data.frame(x = x, y = y, z = z, group = group)
> 
> ggplot(df) +
> geom_point(aes(x = x, y = y, colour = z))
> 
> m <- glmmTMB(y ~ poly(x, 3) * z +
> (1 | group),
> zi = ~ z,
> family = nbinom1,
> data = df)
> # prediction on a new grid
> newdata <- expand.grid(x = 1:20, z = unique(df$z), group = NA)
> newdata$Pred <- predict(m, type = "response")
> ### now how to add CIs?
> 
> ggplot(df) +
> geom_point(aes(x = x, y = y, colour = z)) +
> geom_line(data = newdata, aes(x = x, y = Pred, colour = z, group = z), size
> = 2) +
> facet_wrap(~ z)
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
Dimitris Rizopoulos
Professor of Biostatistics
Department of Biostatistics
Erasmus University Medical Center

Address: PO Box 2040, 3000 CA Rotterdam, the Netherlands
Tel: +31/(0)10/7043478
Fax: +31/(0)10/7043014
Web (personal): http://www.drizopoulos.com/
Web (work): http://www.erasmusmc.nl/biostatistiek/
Blog: http://iprogn.blogspot.nl/

From d@e@kornbrot @ending from hert@@@c@uk  Tue Oct 30 10:15:33 2018
From: d@e@kornbrot @ending from hert@@@c@uk (Kornbrot, Diana)
Date: Tue, 30 Oct 2018 09:15:33 +0000
Subject: [R-sig-ME] Covariance matrices in GLMER
Message-ID: <88479480-8756-4775-8EAC-150EB9FB8558@herts.ac.uk>

It seems to me that GLMER always uses diagonal matrices.
1. Is this correct?
2. If not, (a) how does one specify different covariance matrices (b) how does one get output of covariance matrices that GLMER actually used/
Thanks for all help
Diana
_____________________________________
Professor Diana Kornbrot
Mobile
+44 (0) 7403 18 16 12
Work
University of Hertfordshire
College Lane, Hatfield, Hertfordshire AL10 9AB, UK
+44 (0) 170 728 4626
d.e.kornbrot at herts.ac.uk<mailto:d.e.kornbrot at herts.ac.uk>
http://dianakornbrot.wordpress.com/
http://go.herts.ac.uk/Diana_Kornbrot
skype:  kornbrotme
Home
19 Elmhurst Avenue
London N2 0LT, UK
+44 (0) 208 444 2081
 ------------------------------------------------------------




	[[alternative HTML version deleted]]


From roeem@or @ending from gm@il@com  Tue Oct 30 10:41:08 2018
From: roeem@or @ending from gm@il@com (roee maor)
Date: Tue, 30 Oct 2018 09:41:08 +0000
Subject: [R-sig-ME] 
 intercept and threshold values to calculate probability
 based on mixor package
Message-ID: <CACxNx6vUN_8XGOGq+45EF0zfkFHhSdRXW29dpZ9FwxuMUeXokQ@mail.gmail.com>

Hi Kamarul,

I'm not familiar with the mixor package, but looking at your model's output
it seems that the threshold values you're looking for are Threshold2 and
Threshold3.

The first and last thresholds in any threshold model are minus infinity and
infinity, respectively. In your current model, that leaves 3 thresholds to
be recovered. To simplify calculations, one of these is assumed to be 0,
which leaves only two thresholds to estimate from the data. These two are
the last two parameters listed in your model's output.

However, I'm not familiar with package mixor, so I can't say which one of
the three thresholds is the one set to 0. In MCMCglmm it is the second
threshold, but I don't think that has to be so by necessity. Finding out
which of the thresholds is 0 may (or may not) clarify why you get a
positive value where you expect a negative one.

Best,
Roi Maor

	[[alternative HTML version deleted]]


From c@c@voeten @ending from hum@leidenuniv@nl  Tue Oct 30 14:17:17 2018
From: c@c@voeten @ending from hum@leidenuniv@nl (Voeten, C.C.)
Date: Tue, 30 Oct 2018 13:17:17 +0000
Subject: [R-sig-ME] Covariance matrices in GLMER
In-Reply-To: <88479480-8756-4775-8EAC-150EB9FB8558@herts.ac.uk>
References: <88479480-8756-4775-8EAC-150EB9FB8558@herts.ac.uk>
Message-ID: <D14049CE02C4F54D95360EEC06CE45C50F985C24@SPMXM08.VUW.leidenuniv.nl>

Dear Diana,

1. No, both lmer and glmer by default use unstructured covariance matrices, although they can be massaged into using diagonal, see afex::lmer_alt. Those are the only two options.
2a. Support for other covariance matrices is available in MASS::glmmPQL (which I would not recommend; it inherits all the limitations of nlme::lme and uses PQL) and in glmmTMB::glmmTMB. Depending on what exactly you need to do, glmmTMB is probably what you're looking for.
2b. For glmer and glmmTMB, the ranef function will probably give you what you need.

Best,
Cesko

> -----Oorspronkelijk bericht-----
> Van: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> project.org] Namens Kornbrot, Diana
> Verzonden: dinsdag 30 oktober 2018 10:16
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] Covariance matrices in GLMER
> 
> It seems to me that GLMER always uses diagonal matrices.
> 1. Is this correct?
> 2. If not, (a) how does one specify different covariance matrices (b) how
> does one get output of covariance matrices that GLMER actually used/
> Thanks for all help Diana _____________________________________
> Professor Diana Kornbrot
> Mobile
> +44 (0) 7403 18 16 12
> Work
> University of Hertfordshire
> College Lane, Hatfield, Hertfordshire AL10 9AB, UK
> +44 (0) 170 728 4626
> d.e.kornbrot at herts.ac.uk<mailto:d.e.kornbrot at herts.ac.uk>
> http://dianakornbrot.wordpress.com/
> http://go.herts.ac.uk/Diana_Kornbrot
> skype:  kornbrotme
> Home
> 19 Elmhurst Avenue
> London N2 0LT, UK
> +44 (0) 208 444 2081
>  ------------------------------------------------------------
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From ntuzov @ending from ntuzov@com  Tue Oct 30 16:45:20 2018
From: ntuzov @ending from ntuzov@com (Nik Tuzov)
Date: Tue, 30 Oct 2018 15:45:20 +0000 (UTC)
Subject: [R-sig-ME] Repeated measures - general question
In-Reply-To: <mailman.17001.7346.1540857513.1179.r-sig-mixed-models@r-project.org>
References: <mailman.17001.7346.1540857513.1179.r-sig-mixed-models@r-project.org>
Message-ID: <866983453.4795158.1540914320601@mail.yahoo.com>

What is the best package to analyze RM data in R, given that time is on continuous scale and the time pointsare not equally spaced. Ideally, that package should match SAS results.
Regards,Nik

      From: "r-sig-mixed-models-request at r-project.org" <r-sig-mixed-models-request at r-project.org>
 To: r-sig-mixed-models at r-project.org 
 Sent: Monday, October 29, 2018 6:58 PM
 Subject: R-sig-mixed-models Digest, Vol 142, Issue 28
   
Send R-sig-mixed-models mailing list submissions to
??? r-sig-mixed-models at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
??? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
or, via email, send a message with subject or body 'help' to
??? r-sig-mixed-models-request at r-project.org

You can reach the person managing the list at
??? r-sig-mixed-models-owner at r-project.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-mixed-models digest..."


Today's Topics:

? 1. Re: Simulations in Fisher's Exact test (Alexandre Courtiol)
? 2. Re: glmmTMB (Ben Bolker)
? 3. Re: Random intercept model- unbalanced cluster (Yashree Mehta)
? 4. Re: Random intercept model- unbalanced cluster (Ben Bolker)
? 5. zero-inflated glmmTMB with poly() - confidence band (John Wilson)

----------------------------------------------------------------------

Message: 1
Date: Mon, 29 Oct 2018 12:11:24 +0100
From: Alexandre Courtiol <alexandre.courtiol at gmail.com>
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Simulations in Fisher's Exact test
Message-ID:
??? <CAERMt4dwmh1rLe_gdLBw8_K-cutyFVFphwHBL85tQCNtHswH1w at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

>
> Message: 2
> Date: Sun, 28 Oct 2018 12:18:44 -0400
> From: Ben Bolker <bbolker at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Simulations in Fisher's Exact test
> Message-ID: <b9fd6b4b-e9e6-d368-4148-d9762544e169 at gmail.com>
> Content-Type: text/plain; charset="utf-8"
>
>
>? This is indeed the wrong list; r-help at r-project.org, or StackOverflow,
> might be more appropriate.? I am guessing this is an assignment for a
> class?? If so, it might be more useful to get clarification from your
> instructor or teaching assistant (or a colleague in your class). The
> help page for ?fisher.test says:
>
> simulate.p.value: a logical indicating whether to compute p-values by
>? ? ? ? ? Monte Carlo simulation, **in larger than 2 by 2 tables**.
>
> Emphasis (**) added.? Since you're using a 2x2 table, I'm guessing that
> simulate.p.value has no effect ...? R probably should warn you, but oh
> well ..
>
>
> On 2018-10-28 7:47 a.m., Adeela Munawar wrote:
> > hi all,
> > Probably I am posted in wrong mailing list. I am getting a problem in
> > applying Fisher's exact test. I am applying Fisher's exact test as
> >
> >? ntable<- array(data = c(3, 1, 8,11), dim = c(2,2))
> > fisher.test(ntable)
> >
> > now, I have to repeat the same 10000 times and have to report p-values.
> > Using the arguments simulate.p.value in the command is producing the same
> > results
> > test<-fisher.test(ntable,workspace=20000,simulate.p.value=T,B=10000)
> >
> > what changes I have to made in my model.
> >
> > regards
> > Adeela
> >
> >? ? ? [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> Adeela, with simulate.p.value = FALSE, the Fisher exact test will attempt
to create all possible contingency tables (keeping marginal sum constant)
to compute the p-value of the test. With simulate.p.value = TRUE (when it
has an effect -> see Ben's comment), it will only sample the space of
possible contingency tables. If the number of possible contingency tables
is not too large, there is not need to use simulate.p.value and if it is
lower than the number of table you simulate, then you should obtain nearly
the same results anyhow. In other words, I don't really understand what you
are trying to achieve but a simple call to fisher.test(ntable) should do
the job.
++
Alex

??? [[alternative HTML version deleted]]




------------------------------

Message: 2
Date: Mon, 29 Oct 2018 08:48:05 -0400
From: Ben Bolker <bbolker at gmail.com>
To: mairafatoretto at gmail.com
Cc: R SIG Mixed Models <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] glmmTMB
Message-ID:
??? <CABghstQFdj44Awgfhj66ZTSEAarx1xTGOVZk=XzhJ5B0vd_uBg at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

? glmmTMB implements REML by treating the fixed effect parameters as
'random variables', i.e. turning on the Laplace approximation
machinery; see http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#reml-for-glmms
for starting points in the literature.

https://github.com/glmmTMB/glmmTMB/blob/master/glmmTMB/R/glmmTMB.R#L191
On Mon, Oct 29, 2018 at 6:26 AM Maira Fatoretto
<mairafatoretto at gmail.com> wrote:
>
> Hello,
>
> I am using glmmTMb with binomial family. I chose REML=TRUE? because I have
> three random effects and I would like to know which is the restriction used
> in this? estimation in the package.
> The REML = TRUE have better estimation than ML in my case.
>
>
>
> Thank you.
> Best regards.
>
>
>
> --
> *Ma?ra Blumer Fatoretto*
> Estat?stica - Universidade Estadual de Campinas- UNICAMP
> Mestra em Ci?ncias(Estat?stica e Experimenta??o Agron?mica) - ESALQ/USP -
> Piracicaba - SP
> Doutoranda em Estat?stica e Experimenta??o Agron?mica
> Telefone:(19) 988309481
> E-mail: mairafatoretto at gmail.com
>
>? ? ? ? [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models




------------------------------

Message: 3
Date: Mon, 29 Oct 2018 22:13:06 +0100
From: Yashree Mehta <yashree19 at gmail.com>
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Random intercept model- unbalanced cluster
Message-ID:
??? <CAOE=hq+3u9pAr5Xp-BMWeQ4JNE-ZVpm6YYS=wEmUXhGVihvG8w at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

Or is there an alternative method of modeling this subset of households who
only own one plot?

thank you,

Regards,
Yashree

On Thu, Oct 25, 2018 at 6:00 PM Yashree Mehta <yashree19 at gmail.com> wrote:

> Hi,
>
> I am working with a random intercept model on a cluster dataset (Repeated
> measurements of plots per household). I have the usual "X" vector
> of covariates and one id variable which will make up the random
> intercept. For example,
>
> Response variable: Production of maize
> Covariates: Size, input quantities, soil fertility dummies etc..
> ID variable: Household_ID
>
> However, about 40% of the households own one plot. The number of plots per
> household ranges from 1 to 13.
>
> When I estimated the random intercept model using lmer, I can extract a
> random intercept for all households, irrespective of their number of plots.
>
> How does lmer treat these households with just 1 plot? Also, is it
> theoretically correct to include these observations ?
>
> Thank you,
>
> Regards,
> Yashree
>
>
>

??? [[alternative HTML version deleted]]




------------------------------

Message: 4
Date: Mon, 29 Oct 2018 17:23:16 -0400
From: Ben Bolker <bbolker at gmail.com>
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Random intercept model- unbalanced cluster
Message-ID: <1a88c90a-8869-3b01-072d-57513f5293c4 at gmail.com>
Content-Type: text/plain; charset="utf-8"


? In principle lme4 shouldn't have problems with a subset of groups that
have only one observation (although clearly the model will get more
fragile/unreliable the less information is available about within vs
among group variation ...).? I'd expect the random effects for groups
with only one observation to be strongly shrunk toward the population
mean ... if in doubt, it can be very useful to simulate a situation
similar to your real data set to see what happens in cases where you
know the real answer ...



On 2018-10-29 5:13 p.m., Yashree Mehta wrote:
> Or is there an alternative method of modeling this subset of households who
> only own one plot?
> 
> thank you,
> 
> Regards,
> Yashree
> 
> On Thu, Oct 25, 2018 at 6:00 PM Yashree Mehta <yashree19 at gmail.com> wrote:
> 
>> Hi,
>>
>> I am working with a random intercept model on a cluster dataset (Repeated
>> measurements of plots per household). I have the usual "X" vector
>> of covariates and one id variable which will make up the random
>> intercept. For example,
>>
>> Response variable: Production of maize
>> Covariates: Size, input quantities, soil fertility dummies etc..
>> ID variable: Household_ID
>>
>> However, about 40% of the households own one plot. The number of plots per
>> household ranges from 1 to 13.
>>
>> When I estimated the random intercept model using lmer, I can extract a
>> random intercept for all households, irrespective of their number of plots.
>>
>> How does lmer treat these households with just 1 plot? Also, is it
>> theoretically correct to include these observations ?
>>
>> Thank you,
>>
>> Regards,
>> Yashree
>>
>>
>>
> 
> ??? [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>




------------------------------

Message: 5
Date: Mon, 29 Oct 2018 20:58:09 -0300
From: John Wilson <jhwilson.nb at gmail.com>
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] zero-inflated glmmTMB with poly() - confidence
??? band
Message-ID:
??? <CABdA5Q0o2nJTRFo+mj6Hcz_UbZ+6DM0Rxfzmyk2aOwzovjc92g at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

Hello,

I've been using the newly documented predict() with group = NA to predict
population-level values, as per the thread here (
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2018q4/027305.html). A
follow-up question: in the case of a zero-inflated model, how would I go
about to get the 95% CIs for response predictions? Obviously, I can get
them for the count and the zero-component, and without poly(), I would just
follow the example in Brooks et al (2017).

However, I have a poly() predictor; how do I get the 95% CIs if I can't use
model.matrix naively when I have a poly() in the model? The models take a
while to converge, so I don't want to run a full bootstrapping either, if
at all possible.

Thank you!
John

Here's a toy dataset:

library(ggplot2)
library(glmmTMB)

set.seed(0)
x <- 1:20
z <- sample(c("a", "b"), length(x), replace = TRUE)
y <- round(5 * 2*x + 3 * x^2 + 0.1 * x^3 + rnbinom(length(x), 10, 0.03))
y[c(2, 3, 5, 11, 13, 19)] <- 0
group <- sample(c("i", "ii"), length(x), replace = TRUE)
df <- data.frame(x = x, y = y, z = z, group = group)

ggplot(df) +
geom_point(aes(x = x, y = y, colour = z))

m <- glmmTMB(y ~ poly(x, 3) * z +
(1 | group),
zi = ~ z,
family = nbinom1,
data = df)
# prediction on a new grid
newdata <- expand.grid(x = 1:20, z = unique(df$z), group = NA)
newdata$Pred <- predict(m, type = "response")
### now how to add CIs?

ggplot(df) +
geom_point(aes(x = x, y = y, colour = z)) +
geom_line(data = newdata, aes(x = x, y = Pred, colour = z, group = z), size
= 2) +
facet_wrap(~ z)

??? [[alternative HTML version deleted]]




------------------------------

Subject: Digest Footer

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


------------------------------

End of R-sig-mixed-models Digest, Vol 142, Issue 28
***************************************************

   
	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Tue Oct 30 18:15:22 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Tue, 30 Oct 2018 13:15:22 -0400
Subject: [R-sig-ME] Repeated measures - general question
In-Reply-To: <866983453.4795158.1540914320601@mail.yahoo.com>
References: <mailman.17001.7346.1540857513.1179.r-sig-mixed-models@r-project.org>
 <866983453.4795158.1540914320601@mail.yahoo.com>
Message-ID: <323d6248-1e19-59d9-a2e2-c3e2117f2239@gmail.com>


  Don't know about matching SAS, but nlme::lme() with
correlation=corCAR1() or glmmTMB::glmmTMB() with an ou() correlation
structure should both work for accounting for autocorrelation with
unevenly spaced data.  Maybe you could let us know how you're analyzing
the data in SAS?

On 2018-10-30 11:45 a.m., Nik Tuzov wrote:
> What is the best package to analyze RM data in R, given that time is on continuous scale and the time pointsare not equally spaced. Ideally, that package should match SAS results.
> Regards,Nik
> 
>       From: "r-sig-mixed-models-request at r-project.org" <r-sig-mixed-models-request at r-project.org>
>  To: r-sig-mixed-models at r-project.org 
>  Sent: Monday, October 29, 2018 6:58 PM
>  Subject: R-sig-mixed-models Digest, Vol 142, Issue 28
>    
> Send R-sig-mixed-models mailing list submissions to
> ??? r-sig-mixed-models at r-project.org
> 
> To subscribe or unsubscribe via the World Wide Web, visit
> ??? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> or, via email, send a message with subject or body 'help' to
> ??? r-sig-mixed-models-request at r-project.org
> 
> You can reach the person managing the list at
> ??? r-sig-mixed-models-owner at r-project.org
> 
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-sig-mixed-models digest..."
> 
> 
> Today's Topics:
> 
> ? 1. Re: Simulations in Fisher's Exact test (Alexandre Courtiol)
> ? 2. Re: glmmTMB (Ben Bolker)
> ? 3. Re: Random intercept model- unbalanced cluster (Yashree Mehta)
> ? 4. Re: Random intercept model- unbalanced cluster (Ben Bolker)
> ? 5. zero-inflated glmmTMB with poly() - confidence band (John Wilson)
> 
> ----------------------------------------------------------------------
> 
> Message: 1
> Date: Mon, 29 Oct 2018 12:11:24 +0100
> From: Alexandre Courtiol <alexandre.courtiol at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Simulations in Fisher's Exact test
> Message-ID:
> ??? <CAERMt4dwmh1rLe_gdLBw8_K-cutyFVFphwHBL85tQCNtHswH1w at mail.gmail.com>
> Content-Type: text/plain; charset="utf-8"
> 
>>
>> Message: 2
>> Date: Sun, 28 Oct 2018 12:18:44 -0400
>> From: Ben Bolker <bbolker at gmail.com>
>> To: r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] Simulations in Fisher's Exact test
>> Message-ID: <b9fd6b4b-e9e6-d368-4148-d9762544e169 at gmail.com>
>> Content-Type: text/plain; charset="utf-8"
>>
>>
>> ? This is indeed the wrong list; r-help at r-project.org, or StackOverflow,
>> might be more appropriate.? I am guessing this is an assignment for a
>> class?? If so, it might be more useful to get clarification from your
>> instructor or teaching assistant (or a colleague in your class). The
>> help page for ?fisher.test says:
>>
>> simulate.p.value: a logical indicating whether to compute p-values by
>> ? ? ? ? ? Monte Carlo simulation, **in larger than 2 by 2 tables**.
>>
>> Emphasis (**) added.? Since you're using a 2x2 table, I'm guessing that
>> simulate.p.value has no effect ...? R probably should warn you, but oh
>> well ..
>>
>>
>> On 2018-10-28 7:47 a.m., Adeela Munawar wrote:
>>> hi all,
>>> Probably I am posted in wrong mailing list. I am getting a problem in
>>> applying Fisher's exact test. I am applying Fisher's exact test as
>>>
>>> ? ntable<- array(data = c(3, 1, 8,11), dim = c(2,2))
>>> fisher.test(ntable)
>>>
>>> now, I have to repeat the same 10000 times and have to report p-values.
>>> Using the arguments simulate.p.value in the command is producing the same
>>> results
>>> test<-fisher.test(ntable,workspace=20000,simulate.p.value=T,B=10000)
>>>
>>> what changes I have to made in my model.
>>>
>>> regards
>>> Adeela
>>>
>>> ? ? ? [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> Adeela, with simulate.p.value = FALSE, the Fisher exact test will attempt
> to create all possible contingency tables (keeping marginal sum constant)
> to compute the p-value of the test. With simulate.p.value = TRUE (when it
> has an effect -> see Ben's comment), it will only sample the space of
> possible contingency tables. If the number of possible contingency tables
> is not too large, there is not need to use simulate.p.value and if it is
> lower than the number of table you simulate, then you should obtain nearly
> the same results anyhow. In other words, I don't really understand what you
> are trying to achieve but a simple call to fisher.test(ntable) should do
> the job.
> ++
> Alex
> 
> ??? [[alternative HTML version deleted]]
> 
> 
> 
> 
> ------------------------------
> 
> Message: 2
> Date: Mon, 29 Oct 2018 08:48:05 -0400
> From: Ben Bolker <bbolker at gmail.com>
> To: mairafatoretto at gmail.com
> Cc: R SIG Mixed Models <r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] glmmTMB
> Message-ID:
> ??? <CABghstQFdj44Awgfhj66ZTSEAarx1xTGOVZk=XzhJ5B0vd_uBg at mail.gmail.com>
> Content-Type: text/plain; charset="utf-8"
> 
> ? glmmTMB implements REML by treating the fixed effect parameters as
> 'random variables', i.e. turning on the Laplace approximation
> machinery; see http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#reml-for-glmms
> for starting points in the literature.
> 
> https://github.com/glmmTMB/glmmTMB/blob/master/glmmTMB/R/glmmTMB.R#L191
> On Mon, Oct 29, 2018 at 6:26 AM Maira Fatoretto
> <mairafatoretto at gmail.com> wrote:
>>
>> Hello,
>>
>> I am using glmmTMb with binomial family. I chose REML=TRUE? because I have
>> three random effects and I would like to know which is the restriction used
>> in this? estimation in the package.
>> The REML = TRUE have better estimation than ML in my case.
>>
>>
>>
>> Thank you.
>> Best regards.
>>
>>
>>
>> --
>> *Ma?ra Blumer Fatoretto*
>> Estat?stica - Universidade Estadual de Campinas- UNICAMP
>> Mestra em Ci?ncias(Estat?stica e Experimenta??o Agron?mica) - ESALQ/USP -
>> Piracicaba - SP
>> Doutoranda em Estat?stica e Experimenta??o Agron?mica
>> Telefone:(19) 988309481
>> E-mail: mairafatoretto at gmail.com
>>
>> ? ? ? ? [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 
> 
> ------------------------------
> 
> Message: 3
> Date: Mon, 29 Oct 2018 22:13:06 +0100
> From: Yashree Mehta <yashree19 at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Random intercept model- unbalanced cluster
> Message-ID:
> ??? <CAOE=hq+3u9pAr5Xp-BMWeQ4JNE-ZVpm6YYS=wEmUXhGVihvG8w at mail.gmail.com>
> Content-Type: text/plain; charset="utf-8"
> 
> Or is there an alternative method of modeling this subset of households who
> only own one plot?
> 
> thank you,
> 
> Regards,
> Yashree
> 
> On Thu, Oct 25, 2018 at 6:00 PM Yashree Mehta <yashree19 at gmail.com> wrote:
> 
>> Hi,
>>
>> I am working with a random intercept model on a cluster dataset (Repeated
>> measurements of plots per household). I have the usual "X" vector
>> of covariates and one id variable which will make up the random
>> intercept. For example,
>>
>> Response variable: Production of maize
>> Covariates: Size, input quantities, soil fertility dummies etc..
>> ID variable: Household_ID
>>
>> However, about 40% of the households own one plot. The number of plots per
>> household ranges from 1 to 13.
>>
>> When I estimated the random intercept model using lmer, I can extract a
>> random intercept for all households, irrespective of their number of plots.
>>
>> How does lmer treat these households with just 1 plot? Also, is it
>> theoretically correct to include these observations ?
>>
>> Thank you,
>>
>> Regards,
>> Yashree
>>
>>
>>
> 
> ??? [[alternative HTML version deleted]]
> 
> 
> 
> 
> ------------------------------
> 
> Message: 4
> Date: Mon, 29 Oct 2018 17:23:16 -0400
> From: Ben Bolker <bbolker at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Random intercept model- unbalanced cluster
> Message-ID: <1a88c90a-8869-3b01-072d-57513f5293c4 at gmail.com>
> Content-Type: text/plain; charset="utf-8"
> 
> 
> ? In principle lme4 shouldn't have problems with a subset of groups that
> have only one observation (although clearly the model will get more
> fragile/unreliable the less information is available about within vs
> among group variation ...).? I'd expect the random effects for groups
> with only one observation to be strongly shrunk toward the population
> mean ... if in doubt, it can be very useful to simulate a situation
> similar to your real data set to see what happens in cases where you
> know the real answer ...
> 
> 
> 
> On 2018-10-29 5:13 p.m., Yashree Mehta wrote:
>> Or is there an alternative method of modeling this subset of households who
>> only own one plot?
>>
>> thank you,
>>
>> Regards,
>> Yashree
>>
>> On Thu, Oct 25, 2018 at 6:00 PM Yashree Mehta <yashree19 at gmail.com> wrote:
>>
>>> Hi,
>>>
>>> I am working with a random intercept model on a cluster dataset (Repeated
>>> measurements of plots per household). I have the usual "X" vector
>>> of covariates and one id variable which will make up the random
>>> intercept. For example,
>>>
>>> Response variable: Production of maize
>>> Covariates: Size, input quantities, soil fertility dummies etc..
>>> ID variable: Household_ID
>>>
>>> However, about 40% of the households own one plot. The number of plots per
>>> household ranges from 1 to 13.
>>>
>>> When I estimated the random intercept model using lmer, I can extract a
>>> random intercept for all households, irrespective of their number of plots.
>>>
>>> How does lmer treat these households with just 1 plot? Also, is it
>>> theoretically correct to include these observations ?
>>>
>>> Thank you,
>>>
>>> Regards,
>>> Yashree
>>>
>>>
>>>
>>
>> ??? [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> 
> 
> 
> ------------------------------
> 
> Message: 5
> Date: Mon, 29 Oct 2018 20:58:09 -0300
> From: John Wilson <jhwilson.nb at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] zero-inflated glmmTMB with poly() - confidence
> ??? band
> Message-ID:
> ??? <CABdA5Q0o2nJTRFo+mj6Hcz_UbZ+6DM0Rxfzmyk2aOwzovjc92g at mail.gmail.com>
> Content-Type: text/plain; charset="utf-8"
> 
> Hello,
> 
> I've been using the newly documented predict() with group = NA to predict
> population-level values, as per the thread here (
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2018q4/027305.html). A
> follow-up question: in the case of a zero-inflated model, how would I go
> about to get the 95% CIs for response predictions? Obviously, I can get
> them for the count and the zero-component, and without poly(), I would just
> follow the example in Brooks et al (2017).
> 
> However, I have a poly() predictor; how do I get the 95% CIs if I can't use
> model.matrix naively when I have a poly() in the model? The models take a
> while to converge, so I don't want to run a full bootstrapping either, if
> at all possible.
> 
> Thank you!
> John
> 
> Here's a toy dataset:
> 
> library(ggplot2)
> library(glmmTMB)
> 
> set.seed(0)
> x <- 1:20
> z <- sample(c("a", "b"), length(x), replace = TRUE)
> y <- round(5 * 2*x + 3 * x^2 + 0.1 * x^3 + rnbinom(length(x), 10, 0.03))
> y[c(2, 3, 5, 11, 13, 19)] <- 0
> group <- sample(c("i", "ii"), length(x), replace = TRUE)
> df <- data.frame(x = x, y = y, z = z, group = group)
> 
> ggplot(df) +
> geom_point(aes(x = x, y = y, colour = z))
> 
> m <- glmmTMB(y ~ poly(x, 3) * z +
> (1 | group),
> zi = ~ z,
> family = nbinom1,
> data = df)
> # prediction on a new grid
> newdata <- expand.grid(x = 1:20, z = unique(df$z), group = NA)
> newdata$Pred <- predict(m, type = "response")
> ### now how to add CIs?
> 
> ggplot(df) +
> geom_point(aes(x = x, y = y, colour = z)) +
> geom_line(data = newdata, aes(x = x, y = Pred, colour = z, group = z), size
> = 2) +
> facet_wrap(~ z)
> 
> ??? [[alternative HTML version deleted]]
> 
> 
> 
> 
> ------------------------------
> 
> Subject: Digest Footer
> 
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> ------------------------------
> 
> End of R-sig-mixed-models Digest, Vol 142, Issue 28
> ***************************************************
> 
>    
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From roeem@or @ending from gm@il@com  Thu Nov  1 11:07:08 2018
From: roeem@or @ending from gm@il@com (roee maor)
Date: Thu, 1 Nov 2018 10:07:08 +0000
Subject: [R-sig-ME] 
 intercept and threshold values to calculate probability
 based on mixor package
In-Reply-To: <CADop7+jR91d2wxkmAr11fBt62Y6gm2RNsAaDKLZ+djnzJTj7Sg@mail.gmail.com>
References: <CACxNx6vUN_8XGOGq+45EF0zfkFHhSdRXW29dpZ9FwxuMUeXokQ@mail.gmail.com>
 <CADop7+jR91d2wxkmAr11fBt62Y6gm2RNsAaDKLZ+djnzJTj7Sg@mail.gmail.com>
Message-ID: <CACxNx6sxGCmP_XWgnWN-q89m0FvJC-Hw+NBB8i5w9dcO=9WQRg@mail.gmail.com>

Hi Kamarul,

I'm not familiar with this specific package so I don't know how to
interpret this output. I can see the standard line for "(Intercept)", but
the there is another line for "(Intercept)(Intercept)" which means nothing
to me. It makes no sense to me to add/subtract intercepts and threshold
values because intercept is a value on the y-axis and the thresholds are
values on the x-axis.

I'm putting the list back in the cc to potentially reach others who could
help.

All the best,
Roi

On Thu, 1 Nov 2018 at 03:29, K Imran M <drki.musa at gmail.com> wrote:

> Dear Roi,
>
> Really appreciate your response. Perhaps the first v1 equals 0 minus the
> intercept (7.31). That gives rise to v1= -7.31.
> How about v2 and v3. Can I say v2 = 3.90 and v3 = 6.51?
>
> Best wishes,
>
> Kamarul
>
>
>
> On Tue, Oct 30, 2018 at 5:40 PM roee maor <roeemaor at gmail.com> wrote:
>
>> Hi Kamarul,
>>
>> I'm not familiar with the mixor package, but looking at your model's
>> output
>> it seems that the threshold values you're looking for are Threshold2 and
>> Threshold3.
>>
>> The first and last thresholds in any threshold model are minus infinity
>> and
>> infinity, respectively. In your current model, that leaves 3 thresholds to
>> be recovered. To simplify calculations, one of these is assumed to be 0,
>> which leaves only two thresholds to estimate from the data. These two are
>> the last two parameters listed in your model's output.
>>
>> However, I'm not familiar with package mixor, so I can't say which one of
>> the three thresholds is the one set to 0. In MCMCglmm it is the second
>> threshold, but I don't think that has to be so by necessity. Finding out
>> which of the thresholds is 0 may (or may not) clarify why you get a
>> positive value where you expect a negative one.
>>
>> Best,
>> Roi Maor
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

-- 
Roi Maor
PhD candidate
School of Zoology, Tel Aviv University
Centre for Biodiversity and Environment Research, UCL

	[[alternative HTML version deleted]]


From @rive046 @ending from uott@w@@c@  Thu Nov  1 16:59:55 2018
From: @rive046 @ending from uott@w@@c@ (Stephanie Rivest)
Date: Thu, 1 Nov 2018 11:59:55 -0400
Subject: [R-sig-ME] pvalues & model inference
Message-ID: <CAAYeMWEkZZbSwekDnC0sqP1ir01hTWfQDwwDsRta_fP7CNnMXw@mail.gmail.com>

Hi there,

I am having some trouble understanding all the documentation that I've read
regarding how to do hypothesis testing and model inference for a glmm with
zero-inflation. I'm hoping someone can clarify. For a little background, I
fit a model with the package glmmTMB for a response that is a count and is
zero-inflated, random effects were included.

>From what I understand, the Wald Z tests that are reported in the output of
a model fit with glmmTMB cannot be fully trusted for several reasons: (1)
df are difficult to calculate, yet are used to do hypothesis testing, (2)
Wald z tests make assumptions that can be violated (asymptotic null
distributions), and (3) boundary effects can occur, especially for the
random effects. To me, this sounds like the parameter estimates are ok, but
the standard errors and p-values cannot be trusted. Therefore, its the
*prediction
intervals* that are incorrect, but not the estimates themselves. Is this
interpretation right? I may have misinterpreted some of the terminology
used as well, any guidance on this would be appreciated.

I understand that a bootstrap is the next logical step, and my dataset is
small enough that this option is feasible for me. What I don't understand
is the purpose of the bootstrap. Is the aim to obtain more accurate
prediction intervals and correct p-values? OR, are model estimates also
made more reliable?

Thanks in advance for taking the time to respond.

Cheers,
Stephanie

Stephanie Rivest
Ph.D. Candidate | Candidate au Doctorat
Dept. of Biology | D?p. de Biologie
University of Ottawa | Universit? d'Ottawa

	[[alternative HTML version deleted]]


From @rive@ @ending from wi@c@edu  Thu Nov  1 17:30:05 2018
From: @rive@ @ending from wi@c@edu (Anthony R. Ives)
Date: Thu, 1 Nov 2018 16:30:05 +0000
Subject: [R-sig-ME] pvalues & model inference
In-Reply-To: <CAAYeMWEkZZbSwekDnC0sqP1ir01hTWfQDwwDsRta_fP7CNnMXw@mail.gmail.com>
References: <CAAYeMWEkZZbSwekDnC0sqP1ir01hTWfQDwwDsRta_fP7CNnMXw@mail.gmail.com>
Message-ID: <412ACF4A-EAF0-4E29-B108-30ECD7CF7644@wisc.edu>

Stephanie,

The short answer is that a bootstrap can address both bias (problems with estimates) and hypothesis testing. It is often the case that, even though estimates are unbiased, a bootstrap is still needed for hypothesis testing.

If you are interested in p-values, I'd perform bootstraps under the null hypothesis. Standard bootstraps are generally performed using the estimates, and if there is bias, this can still give you incorrect p-values. 

There are several examples of different types of bootstraps and randomizations here: https://leanpub.com/correlateddata

Cheers, Tony

______________
Anthony R. Ives
UW-Madison
459 Birge Hall
608-262-1519
 

?-----Original Message-----
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Stephanie Rivest <srive046 at uottawa.ca>
Date: Thursday, November 1, 2018 at 11:03 AM
To: "r-sig-mixed-models at r-project.org" <r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] pvalues & model inference

    Hi there,
    
    I am having some trouble understanding all the documentation that I've read
    regarding how to do hypothesis testing and model inference for a glmm with
    zero-inflation. I'm hoping someone can clarify. For a little background, I
    fit a model with the package glmmTMB for a response that is a count and is
    zero-inflated, random effects were included.
    
    From what I understand, the Wald Z tests that are reported in the output of
    a model fit with glmmTMB cannot be fully trusted for several reasons: (1)
    df are difficult to calculate, yet are used to do hypothesis testing, (2)
    Wald z tests make assumptions that can be violated (asymptotic null
    distributions), and (3) boundary effects can occur, especially for the
    random effects. To me, this sounds like the parameter estimates are ok, but
    the standard errors and p-values cannot be trusted. Therefore, its the
    *prediction
    intervals* that are incorrect, but not the estimates themselves. Is this
    interpretation right? I may have misinterpreted some of the terminology
    used as well, any guidance on this would be appreciated.
    
    I understand that a bootstrap is the next logical step, and my dataset is
    small enough that this option is feasible for me. What I don't understand
    is the purpose of the bootstrap. Is the aim to obtain more accurate
    prediction intervals and correct p-values? OR, are model estimates also
    made more reliable?
    
    Thanks in advance for taking the time to respond.
    
    Cheers,
    Stephanie
    
    Stephanie Rivest
    Ph.D. Candidate | Candidate au Doctorat
    Dept. of Biology | D?p. de Biologie
    University of Ottawa | Universit? d'Ottawa
    
    	[[alternative HTML version deleted]]
    
    _______________________________________________
    R-sig-mixed-models at r-project.org mailing list
    https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
    


From p@wijer@tne @ending from ucl@@c@uk  Thu Nov  1 17:52:43 2018
From: p@wijer@tne @ending from ucl@@c@uk (Wijeratne, Peter)
Date: Thu, 1 Nov 2018 16:52:43 +0000
Subject: [R-sig-ME] Simulating data with nested random effects
In-Reply-To: <HE1PR01MB29396165F51F48759E28C5E3BFF70@HE1PR01MB2939.eurprd01.prod.exchangelabs.com>
References: <HE1PR01MB29391404622F275C8CC31F14BFF80@HE1PR01MB2939.eurprd01.prod.exchangelabs.com>,
 <CAJuCY5xGNDyMKukutJ4M4QS_VLh72i3imXsESMU-2cSVNxyaKw@mail.gmail.com>,
 <HE1PR01MB29396165F51F48759E28C5E3BFF70@HE1PR01MB2939.eurprd01.prod.exchangelabs.com>
Message-ID: <HE1PR01MB2939A7FCF170604F50C3EAB2BFCE0@HE1PR01MB2939.eurprd01.prod.exchangelabs.com>

Hi again,


For those who are interested, I figured this out - it's because there is no interaction between time and treatment in my simulated data, so the number of sites only affects the variance of the intercept, and not the treatment variance. Adding interaction random effects for 'time:treatment:site' and 'time:treatment:site:subject' when simulating data, and fitting with y ~ time + time:treatment + (1 + time | site/subject), produces the desired result.


Best,

Pete

________________________________
From: Wijeratne, Peter
Sent: 25 October 2018 17:15:19
To: Thierry Onkelinx
Cc: r-sig-mixed-models
Subject: Re: [R-sig-ME] Simulating data with nested random effects


Dear Thierry,


Thanks very much for your code. I have expanded it to estimate the power of average treatment effect, for various combinations of site, subject, number of time points, and treatment effect size (copied at the end of this mail). It works nicely, predicting increasing power for increasing n_site or n_subject_site.


However, I see only small random differences in power as a function of the relative values of n_site and n_subject_site. For example, n_site = 10 and n_subject_site = 20 produces the same power (+- 0.01) as n_site = 4 and n_subject_site = 50. You can test this yourself using the code below, by setting "site.values" and "subject_site.values" to the appropriate values.


Naively I would expect there to be a more distinct dependency of power on the relative values of n_site and n_subject_site, since sigma_site and sigma_subject are not equal. For example, if I set sigma_site > sigma_subject, I would naively expect that increasing the number of sites should capture more of the between-site variance than increasing the number of subjects per site, and hence increase the power. However, I don't see any effect beyond random fluctuations, even when choosing extreme values.


Do you know why this is the case? Any insight would be greatly appreciated.


Best,

Pete


# example power analysis of treatment effect

set.seed(42)
library(lme4)
library(dplyr)

create_fake <- function(n_site, n_subject_site, n_time, effect){
  # change these hyper-parameters for testing
  intercept = 5
  trend = -0.2
  sigma_site = 0.4
  sigma_subject = 0.6
  sigma_noise = 0.1

  effect = -1.0*effect*trend
  re.site <- rnorm(n_site, mean = 0, sd = sigma_site)
  re.subject <- rnorm(n_site * n_subject_site, mean = 0, sd = sigma_subject)

  expand.grid(
    time = seq(0, (n_time-1), length = n_time),
    site = factor(seq_len(n_site)),
    subject = factor(seq_len(n_subject_site))
  ) %>%
    mutate(
      subject = factor(interaction(site, subject)),
      treatment = sample(rep(0:1, n_site*n_subject_site/2))[subject],
      fixed = intercept + (trend + effect*treatment)*time,
      random = re.site[site] + re.subject[subject],
      mu = fixed + random,
      y = rnorm(n(), mean = mu, sd = sigma_noise)
    )
}

trial.power <- function(n_site, n_subject_site, n_time, effect, n.sims=1000){
  signif <- rep (NA, n.sims)
  for (s in 1:n.sims){
    fake <- create_fake(n_site, n_subject_site, n_time, effect)
    lme.power <- lmer(
                  y ~ time + time:treatment + (1 | site/subject),
              data=fake
             )
    theta.hat <- coef(summary(lme.power))['time:treatment', 'Estimate']
    theta.se <- coef(summary(lme.power))['time:treatment', 'Std. Error']
    signif[s] <- ifelse (theta.hat - 2*theta.se > 0, 1, 0)
  }
  power <- mean(signif)
  return(power)
}

# change these values for testing
effect.values <- c(0.2,0.4,0.6,0.8,1.0)
site.values <- c(6, 8, 10, 15, 20, 40, 60, 100)
subject_site.values <- c(20)
time.values <- c(3)

for(i1 in 1:length(effect.values)){
 for(i2 in 1:length(site.values)){
  for(i3 in 1:length(subject_site.values)){
   for(i4 in 1:length(time.values)){
    power <- trial.power(site.values[i2], subject_site.values[i3], time.values[i4], effect.values[i1])
    cat("Power =", power ,", for effect =", effect.values[i1] ,", n_sites =", site.values[i2], ", n_subject_site =", subject_site.values[i3], ", n_time =", time.values[i4], "\n")
   }
  }
 }
}

________________________________
From: Thierry Onkelinx <thierry.onkelinx at inbo.be>
Sent: 21 October 2018 09:41:49
To: Wijeratne, Peter
Cc: r-sig-mixed-models
Subject: Re: [R-sig-ME] Simulating data with nested random effects

Dear Pete,

I rewrote your code to make it shorter and IMHO more readable. Meaningful variables names require less comments on what they are. The model yields sensible estimates on data simulated with the code below.

library(lme4)
library(dplyr)
create_fake <- function(
  n_site = 100, n_subject_site = 10, n_time = 10,
  intercept = 10, trend = 0.1, effect = 0.5,
  sigma_site = 5, sigma_subject = 2, sigma_noise = 1
){
  re.site <- rnorm(n_site, mean = 0, sd = sigma_site)
  re.subject <- rnorm(n_site * n_subject_site, mean = 0, sd = sigma_subject)

  expand.grid(
    time = seq(0, 2, length = n_time),
    site = seq_len(n_site),
    subject = seq_len(n_subject_site)
  ) %>%
    mutate(
      subject = interaction(site, subject),
      treatment = sample(0:1, size = n_site * n_subject_site,, replace = TRUE)[subject],
      fixed = intercept + effect * treatment + trend * time,
      random = re.site[site] + re.subject[subject],
      mu = fixed + random,
      y = rnorm(n(), mean = mu, sd = sigma_noise)
    )
}
dataset <- create_fake()
m <- lmer(y ~ treatment + time + (1|site/subject), data = dataset)
summary(m)

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be<http://www.inbo.be>

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

[https://inbo-website-prd-532750756126.s3-eu-west-1.amazonaws.com/inbologoleeuw_nl.png]<https://www.inbo.be>


Op do 18 okt. 2018 om 10:28 schreef Wijeratne, Peter <p.wijeratne at ucl.ac.uk<mailto:p.wijeratne at ucl.ac.uk>>:
Dear r-sig-mixed-models,


I would like to simulate nested data, where my mixed effects model fitted to real data has the form:

y ~ time + (1 | site/subject)

I then take the hyper-parameters from this model to simulate fake data, using this function:

create_fake <- function(J,K,L,HP,t){
# J : number of sites
# K : number of subjects / site
# L : number of years
# HP: hyperparameters from fit, y ~ time + (1 | site/subject)
# t: fractional effectiveness of treatment
time <- rep(seq(0,2,length=L), J*K)
subject <- rep(1:(J*K), each=L)
site <- sample(rep (1:J, K))
site1 <- factor(site[subject])
treatment <- sample(rep (0:1, J*K/2))
treatment1 <- treatment[subject]

# time coefficient
g.0.true <- as.numeric( HP['g.0.true'] )
# treatment coefficient
g.1.true <- -as.numeric(t)*g.0.true
# intercept
mu.a.true <- as.numeric( HP['mu.a.true'] )
# fixed effects
b.true <- (g.0.true + g.1.true*treatment)
# random effects
sigma.y.true <- as.numeric( HP['sigma.y.true'] ) # residual std dev
sigma.a.true <- as.numeric( HP['sigma.a.true'] ) # site std dev
sigma.a0.true <- as.numeric( HP['sigma.a0.true'] ) # site:person std dev
a0.true <- rnorm(J*K, 0, sigma.a0.true)
a.true <- rnorm(J*K, mu.a.true + a0.true, sigma.a.true)
y <- rnorm(J*K*L, a.true[subject] + b.true[subject]*time, sigma.y.true)

return(data.frame( y, time, subject, treatment1, site1 ))

I then fit models of the form:

y ~ time + time:treatment1 + (1 | site1/subject)

To the fake data. However, this approach can (but not always) produce a 'site' standard deviation approximately a factor of 10 less than in the real data.


My question is - is my simulation function correct?


Note - I can generate data and provide the full code if required.


Thanks in advance for any help.

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From ntuzov @ending from ntuzov@com  Thu Nov  1 19:32:21 2018
From: ntuzov @ending from ntuzov@com (Nik Tuzov)
Date: Thu, 1 Nov 2018 18:32:21 +0000 (UTC)
Subject: [R-sig-ME] A theoretical question : usage of AIC and similar
 information criteria for mixed models
References: <399244602.20694412.1541097141160.ref@mail.yahoo.com>
Message-ID: <399244602.20694412.1541097141160@mail.yahoo.com>

Hello all:
I was wondering if you could comment on this theoretical question.
You are probably familiar with the book of Burnham & Anderson:

https://www.amazon.com/Kenneth-Burnham-Selection-Multi-Model-Information-Theoretic/dp/B008UBJ0VQ/ref=sr_1_2?s=books&ie=UTF8&qid=1540931659&sr=1-2&keywords=model+selection+and+multimodel+inference

1) They claim (Section 6.6.1) that AIC and similar information criteria can not be used to compare models that have different random effects
because the number of effective parameters associated with a random effect is unknown. For instance, if there is a fixed categorical factor with K levels,
then the number of parameters associated with it is (K - 1). If that factor is labeled random, then one can say there is only one parameter, 
the corresponding variance component sigma_K. However, most likely the number of "effective" parameters is somewhere between 1 and (K-1). 
Since we don't know what it is, AIC is not computable.

2) On the other hand, I believe any mixed model can be represented as Y = Xb + e, where X describes the fixed effects and e is the variance-covariance matrix
of the error terms that is defined by random effects. Technically speaking, that model has no random effects, and the solution can be obtained using 
Generalized Least Squares. Given all that, Burnham & Anderson essentially claim that AIC and similar criteria cannot be computed for GLS. 

3) I find it hard to believe in 2). In particular, AIC have been routinely used in Time Series. A simple AR(1) model can be represented as Y = Xb + e
where Var[e] is not diagonal because all of the observations are correlated. If it's ok to use AIC for Time Series, why is it a problem with
GLS and mixed models?

Please let me know what you think.

Regards,
Nik Tuzov, PhD

	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Thu Nov  1 20:48:37 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Thu, 1 Nov 2018 15:48:37 -0400
Subject: [R-sig-ME] A theoretical question : usage of AIC and similar
 information criteria for mixed models
In-Reply-To: <399244602.20694412.1541097141160@mail.yahoo.com>
References: <399244602.20694412.1541097141160.ref@mail.yahoo.com>
 <399244602.20694412.1541097141160@mail.yahoo.com>
Message-ID: <CABghstSdKHKzKka3-s4kZgkkr+NG99fiz=tudTjtS=o9aAa63g@mail.gmail.com>

This is a good question; I think it's harder than you think.

https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#can-i-use-aic-for-mixed-models-how-do-i-count-the-number-of-degrees-of-freedom-for-a-random-effect

  has some discussion, including references to the "conditional AIC"
which tries to compute an effective number of parameters based on the
degree of shrinkage.  The key question is whether we're trying to
evaluate expected predictive accuracy at the level of the population
(as typically assumed in the time series/GLS literature) or the
individual group (as Burnham and Anderson seem to be assuming).

On Thu, Nov 1, 2018 at 3:02 PM Nik Tuzov <ntuzov at ntuzov.com> wrote:
>
> Hello all:
> I was wondering if you could comment on this theoretical question.
> You are probably familiar with the book of Burnham & Anderson:
>
> https://www.amazon.com/Kenneth-Burnham-Selection-Multi-Model-Information-Theoretic/dp/B008UBJ0VQ/ref=sr_1_2?s=books&ie=UTF8&qid=1540931659&sr=1-2&keywords=model+selection+and+multimodel+inference
>
> 1) They claim (Section 6.6.1) that AIC and similar information criteria can not be used to compare models that have different random effects
> because the number of effective parameters associated with a random effect is unknown. For instance, if there is a fixed categorical factor with K levels,
> then the number of parameters associated with it is (K - 1). If that factor is labeled random, then one can say there is only one parameter,
> the corresponding variance component sigma_K. However, most likely the number of "effective" parameters is somewhere between 1 and (K-1).
> Since we don't know what it is, AIC is not computable.
>
> 2) On the other hand, I believe any mixed model can be represented as Y = Xb + e, where X describes the fixed effects and e is the variance-covariance matrix
> of the error terms that is defined by random effects. Technically speaking, that model has no random effects, and the solution can be obtained using
> Generalized Least Squares. Given all that, Burnham & Anderson essentially claim that AIC and similar criteria cannot be computed for GLS.
>
> 3) I find it hard to believe in 2). In particular, AIC have been routinely used in Time Series. A simple AR(1) model can be represented as Y = Xb + e
> where Var[e] is not diagonal because all of the observations are correlated. If it's ok to use AIC for Time Series, why is it a problem with
> GLS and mixed models?
>
> Please let me know what you think.
>
> Regards,
> Nik Tuzov, PhD
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From d@rizopoulo@ @ending from er@@mu@mc@nl  Thu Nov  1 22:24:55 2018
From: d@rizopoulo@ @ending from er@@mu@mc@nl (D. Rizopoulos)
Date: Thu, 1 Nov 2018 21:24:55 +0000
Subject: [R-sig-ME] A theoretical question : usage of AIC and similar
 information criteria for mixed models
In-Reply-To: <399244602.20694412.1541097141160@mail.yahoo.com>
References: <399244602.20694412.1541097141160.ref@mail.yahoo.com>,
 <399244602.20694412.1541097141160@mail.yahoo.com>
Message-ID: <7191AFC7255B4F49A30707E39BEAD05FDEBD5C87@EXCH-HE03.erasmusmc.nl>

There are several definitions of AIC for mixed models, and it matters at which level you want to do the selection, i.e., for the implied marginal model (fixed effects alone) or the hierarchical model (fixed and random effects).

For the latter, have a look at the cAIC4 package (https://cran.r-project.org/package=cAIC4 )

Best,
Dimitris

From: Nik Tuzov <ntuzov at ntuzov.com<mailto:ntuzov at ntuzov.com>>
Date: Thursday, 01 Nov 2018, 8:02 PM
To: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
Subject: [R-sig-ME] A theoretical question : usage of AIC and similar information criteria for mixed models

Hello all:
I was wondering if you could comment on this theoretical question.
You are probably familiar with the book of Burnham & Anderson:

https://www.amazon.com/Kenneth-Burnham-Selection-Multi-Model-Information-Theoretic/dp/B008UBJ0VQ/ref=sr_1_2?s=books&ie=UTF8&qid=1540931659&sr=1-2&keywords=model+selection+and+multimodel+inference

1) They claim (Section 6.6.1) that AIC and similar information criteria can not be used to compare models that have different random effects
because the number of effective parameters associated with a random effect is unknown. For instance, if there is a fixed categorical factor with K levels,
then the number of parameters associated with it is (K - 1). If that factor is labeled random, then one can say there is only one parameter,
the corresponding variance component sigma_K. However, most likely the number of "effective" parameters is somewhere between 1 and (K-1).
Since we don't know what it is, AIC is not computable.

2) On the other hand, I believe any mixed model can be represented as Y = Xb + e, where X describes the fixed effects and e is the variance-covariance matrix
of the error terms that is defined by random effects. Technically speaking, that model has no random effects, and the solution can be obtained using
Generalized Least Squares. Given all that, Burnham & Anderson essentially claim that AIC and similar criteria cannot be computed for GLS.

3) I find it hard to believe in 2). In particular, AIC have been routinely used in Time Series. A simple AR(1) model can be represented as Y = Xb + e
where Var[e] is not diagonal because all of the observations are correlated. If it's ok to use AIC for Time Series, why is it a problem with
GLS and mixed models?

Please let me know what you think.

Regards,
Nik Tuzov, PhD

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From drki@mu@@ @ending from gm@il@com  Fri Nov  2 02:54:43 2018
From: drki@mu@@ @ending from gm@il@com (K Imran M)
Date: Fri, 2 Nov 2018 09:54:43 +0800
Subject: [R-sig-ME] 
 intercept and threshold values to calculate probability
 based on mixor package
In-Reply-To: <CACxNx6sxGCmP_XWgnWN-q89m0FvJC-Hw+NBB8i5w9dcO=9WQRg@mail.gmail.com>
References: <CACxNx6vUN_8XGOGq+45EF0zfkFHhSdRXW29dpZ9FwxuMUeXokQ@mail.gmail.com>
 <CADop7+jR91d2wxkmAr11fBt62Y6gm2RNsAaDKLZ+djnzJTj7Sg@mail.gmail.com>
 <CACxNx6sxGCmP_XWgnWN-q89m0FvJC-Hw+NBB8i5w9dcO=9WQRg@mail.gmail.com>
Message-ID: <CADop7+hcQprtjUuNo8bzwaX0me-NrGW4+Hqaz_6L1sYdZP6ZpA@mail.gmail.com>

Dear Roi,

Really appreciate it.

Regards,
Kamarul


On Thu, Nov 1, 2018 at 6:06 PM roee maor <roeemaor at gmail.com> wrote:

> Hi Kamarul,
>
> I'm not familiar with this specific package so I don't know how to
> interpret this output. I can see the standard line for "(Intercept)", but
> the there is another line for "(Intercept)(Intercept)" which means nothing
> to me. It makes no sense to me to add/subtract intercepts and threshold
> values because intercept is a value on the y-axis and the thresholds are
> values on the x-axis.
>
> I'm putting the list back in the cc to potentially reach others who could
> help.
>
> All the best,
> Roi
>
> On Thu, 1 Nov 2018 at 03:29, K Imran M <drki.musa at gmail.com> wrote:
>
>> Dear Roi,
>>
>> Really appreciate your response. Perhaps the first v1 equals 0 minus the
>> intercept (7.31). That gives rise to v1= -7.31.
>> How about v2 and v3. Can I say v2 = 3.90 and v3 = 6.51?
>>
>> Best wishes,
>>
>> Kamarul
>>
>>
>>
>> On Tue, Oct 30, 2018 at 5:40 PM roee maor <roeemaor at gmail.com> wrote:
>>
>>> Hi Kamarul,
>>>
>>> I'm not familiar with the mixor package, but looking at your model's
>>> output
>>> it seems that the threshold values you're looking for are Threshold2 and
>>> Threshold3.
>>>
>>> The first and last thresholds in any threshold model are minus infinity
>>> and
>>> infinity, respectively. In your current model, that leaves 3 thresholds
>>> to
>>> be recovered. To simplify calculations, one of these is assumed to be 0,
>>> which leaves only two thresholds to estimate from the data. These two are
>>> the last two parameters listed in your model's output.
>>>
>>> However, I'm not familiar with package mixor, so I can't say which one of
>>> the three thresholds is the one set to 0. In MCMCglmm it is the second
>>> threshold, but I don't think that has to be so by necessity. Finding out
>>> which of the thresholds is 0 may (or may not) clarify why you get a
>>> positive value where you expect a negative one.
>>>
>>> Best,
>>> Roi Maor
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>
> --
> Roi Maor
> PhD candidate
> School of Zoology, Tel Aviv University
> Centre for Biodiversity and Environment Research, UCL
>

	[[alternative HTML version deleted]]


From d@rizopoulo@ @ending from er@@mu@mc@nl  Mon Nov  5 11:52:48 2018
From: d@rizopoulo@ @ending from er@@mu@mc@nl (D. Rizopoulos)
Date: Mon, 5 Nov 2018 10:52:48 +0000
Subject: [R-sig-ME] GLMMs with Adaptive Gaussian Quadrature - GLMMadaptive
 0.4-0
Message-ID: <a610af77-e1df-929d-e51f-93b44481b529@erasmusmc.nl>

Dear R mixed-model users,

A new version of GLMMadaptive (0.4-0) has been rolled out on CRAN.

Summary: GLMMadaptive can fit mixed effects models using adaptive 
Gaussian quadrature to approximate the integrals over the random 
effects, allowing also for user-specified models.

New features:

- New family objects and extended support for models with an extra 
zero-part:

   * Zero-inflated Poisson using zi.poisson(), and hurdle/truncated 
Poisson using hurdle.poisson().

   * Zero-inflated negative binomial using zi.negative.binomial(), and 
hurdle/truncated negative binomial using hurdle.negative.binomial().

   * Two-part/hurdle model for semi-continuous Gaussian outcomes using 
hurdle.lognormal().

   * Two-part/hurdle Beta using hurdle.beta.fam().

   * More info in: vignette("ZeroInflated_and_TwoPart_Models", package = 
"GLMMadaptive")

- Full support has been added for multiple comparisons and effects 
estimates as provided the **emmeans** and **multcomp** packages. More 
info in: vignette("Multiple_Comparisons", package = "GLMMadaptive")

- The predict() method

   * now works also for models with an extra zero-part;

   * it has been extended to calculate dynamic predictions for the 
different types of models using the 'newdata2' argument;

   * the function scoring_rules() calculate proper scoring rules for 
categorical data.

   * More info in: vignette("Dynamic_Predictions", package = "GLMMadaptive")

As always, any kind of feedback is more than welcome.

Best,
Dimitris


-- 
Dimitris Rizopoulos
Professor of Biostatistics
Department of Biostatistics
Erasmus University Medical Center

Address: PO Box 2040, 3000 CA Rotterdam, the Netherlands
Tel: +31/(0)10/7043478
Fax: +31/(0)10/7043014
Web (personal): http://www.drizopoulos.com/
Web (work): http://www.erasmusmc.nl/biostatistiek/
Blog: http://iprogn.blogspot.nl/

From jhwil@on@nb @ending from gm@il@com  Mon Nov  5 13:19:12 2018
From: jhwil@on@nb @ending from gm@il@com (John Wilson)
Date: Mon, 5 Nov 2018 08:19:12 -0400
Subject: [R-sig-ME] zero-inflated glmmTMB with poly() - confidence band
In-Reply-To: <0081daab-0ed7-4748-bde8-8fe569aa22e3@erasmusmc.nl>
References: <CABdA5Q0o2nJTRFo+mj6Hcz_UbZ+6DM0Rxfzmyk2aOwzovjc92g@mail.gmail.com>
 <0081daab-0ed7-4748-bde8-8fe569aa22e3@erasmusmc.nl>
Message-ID: <CABdA5Q1U2LdrhVpUZtB5uStY4kUqKZJP2x6=FFwJPnHOb7+J1w@mail.gmail.com>

This worked like a charm, thank you for setting me straight!

On Tue, Oct 30, 2018 at 5:37 AM D. Rizopoulos <d.rizopoulos at erasmusmc.nl>
wrote:

> You can use still compute the correct design matrix when using poly() on
> newdata by working with a terms objects that has an appropriately
> defined the 'predvars' attribute. For an example, check the following:
>
> # data and new data for prediction
> DF <- data.frame(y = rnorm(10), x = rnorm(10))
> newDF <- data.frame(x = rnorm(10))
>
> # *wrong* design matrix X on new data
> X_new1 <- model.matrix(~ poly(x, 3), data = newDF)
>
> # correct design matrix on new data
> termsX <- terms(model.frame(y ~ poly(x, 3), data = DF))
> # check predvars attribute
> attr(termsX, "predvars")
> X_new2 <- model.matrix(delete.response(termsX), data = newDF)
>
> head(X_new1)
> head(X_new2)
>
> Best,
> Dimitris
>
>
>
> On 10/30/2018 12:58 AM, John Wilson wrote:
> > Hello,
> >
> > I've been using the newly documented predict() with group = NA to predict
> > population-level values, as per the thread here (
> > https://stat.ethz.ch/pipermail/r-sig-mixed-models/2018q4/027305.html). A
> > follow-up question: in the case of a zero-inflated model, how would I go
> > about to get the 95% CIs for response predictions? Obviously, I can get
> > them for the count and the zero-component, and without poly(), I would
> just
> > follow the example in Brooks et al (2017).
> >
> > However, I have a poly() predictor; how do I get the 95% CIs if I can't
> use
> > model.matrix naively when I have a poly() in the model? The models take a
> > while to converge, so I don't want to run a full bootstrapping either, if
> > at all possible.
> >
> > Thank you!
> > John
> >
> > Here's a toy dataset:
> >
> > library(ggplot2)
> > library(glmmTMB)
> >
> > set.seed(0)
> > x <- 1:20
> > z <- sample(c("a", "b"), length(x), replace = TRUE)
> > y <- round(5 * 2*x + 3 * x^2 + 0.1 * x^3 + rnbinom(length(x), 10, 0.03))
> > y[c(2, 3, 5, 11, 13, 19)] <- 0
> > group <- sample(c("i", "ii"), length(x), replace = TRUE)
> > df <- data.frame(x = x, y = y, z = z, group = group)
> >
> > ggplot(df) +
> > geom_point(aes(x = x, y = y, colour = z))
> >
> > m <- glmmTMB(y ~ poly(x, 3) * z +
> > (1 | group),
> > zi = ~ z,
> > family = nbinom1,
> > data = df)
> > # prediction on a new grid
> > newdata <- expand.grid(x = 1:20, z = unique(df$z), group = NA)
> > newdata$Pred <- predict(m, type = "response")
> > ### now how to add CIs?
> >
> > ggplot(df) +
> > geom_point(aes(x = x, y = y, colour = z)) +
> > geom_line(data = newdata, aes(x = x, y = Pred, colour = z, group = z),
> size
> > = 2) +
> > facet_wrap(~ z)
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> --
> Dimitris Rizopoulos
> Professor of Biostatistics
> Department of Biostatistics
> Erasmus University Medical Center
>
> Address: PO Box 2040, 3000 CA Rotterdam, the Netherlands
> Tel: +31/(0)10/7043478
> Fax: +31/(0)10/7043014
> Web (personal): http://www.drizopoulos.com/
> Web (work): http://www.erasmusmc.nl/biostatistiek/
> Blog: http://iprogn.blogspot.nl/

	[[alternative HTML version deleted]]


From y@@hree19 @ending from gm@il@com  Tue Nov  6 19:11:08 2018
From: y@@hree19 @ending from gm@il@com (Yashree Mehta)
Date: Tue, 6 Nov 2018 19:11:08 +0100
Subject: [R-sig-ME] Dependency structure
In-Reply-To: <a9e4d806-0e47-33c1-f1f4-ff5e23dd0240@gmail.com>
References: <CAOE=hqLskrB+f1fnq2Uw-XYNbVyenYby4o=_ZecK5336D-=U3Q@mail.gmail.com>
 <a9e4d806-0e47-33c1-f1f4-ff5e23dd0240@gmail.com>
Message-ID: <CAOE=hqKBx9w3kgj0y-CbPCs3GMY_Pesu_Ytxd8O2j5k1gN-5LA@mail.gmail.com>

Hi,

Regarding the question on dependency structure, is there a way to allow for
the possibility of the error term and random intercept being correlated? I
need to define the covariance matrix between these two terms and estimate
the values which should go into this matrix.

Thank you

Regards,
Yashree

On Wed, Oct 17, 2018 at 2:37 AM Ben Bolker <bbolker at gmail.com> wrote:

>
> > Hi,
> >
> > Is there literature on how to specify the dependency structure between
> the
> > random intercept and the statistical noise error term in a random
> intercept
> > model?
> > It would be useful to also know how to implement using R...
>
>
>   Can you be more specific about what you want?  Suppose you have
> observations j within groups i, and you have an epsilon_{0,ij} for each
> observation (error term) and an epsilon_"1,i} for each group (random
> intercept).  Typically the epsilon_{0,ij} values are iid with
> homogeneous variance sigma_0^2, and epsilon_{1,i} are iid with variance
> sigma_1^2.  What kind of correlation structure are you looking for?
>
> While we're at it, you previously asked:
>
> ===
> I am working with a random intercept model. I have the usual "X" vector
> of covariates and one id variable which will make up the random
> intercept. For example,
>
> Response variable: Production of maize
> Covariate: Size of plot
> ID variable: Household_ID
>
> I need to acknowledge that there is correlation between the FIXED EFFECT
> coefficient of plot size and the estimated random intercept. It is my
> model assumption.
>
> Does lme4 assume this correlation or do I have to make changes in the
> formula so that it gets considered?
> ===
>
>   The short answer to this one is "no", I think -- I don't know that
> there's a way to allow for correlation between fixed effect coefficients
> and random intercepts. (This actually seems like a weird question to me;
> in the frequentist world, as far as I know, you can only specify
> correlation models for *random variables* within the model.  In the
> context of LMM fitting, I don't think parameters are random effects in
> this sense.
>
> On 2018-10-16 01:03 PM, Yashree Mehta wrote:
>
> >
> > Thank you
> >
> > Yashree
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From jdpo223 @ending from g@uky@edu  Tue Nov  6 19:25:12 2018
From: jdpo223 @ending from g@uky@edu (Poe, John)
Date: Tue, 6 Nov 2018 13:25:12 -0500
Subject: [R-sig-ME] Dependency structure
In-Reply-To: <CAOE=hqKBx9w3kgj0y-CbPCs3GMY_Pesu_Ytxd8O2j5k1gN-5LA@mail.gmail.com>
References: <CAOE=hqLskrB+f1fnq2Uw-XYNbVyenYby4o=_ZecK5336D-=U3Q@mail.gmail.com>
 <a9e4d806-0e47-33c1-f1f4-ff5e23dd0240@gmail.com>
 <CAOE=hqKBx9w3kgj0y-CbPCs3GMY_Pesu_Ytxd8O2j5k1gN-5LA@mail.gmail.com>
Message-ID: <CAFW8ByqbE71DDwTC3X5zi-GAck2hG=cH7XTOts167hKq5Qv47A@mail.gmail.com>

Just to clarify, you mean that you want to specify a correlation structure
between the individual level error term in the model (also called the
residuals) and the random intercept or group-level error.

This doesn't make a lot of sense to me because the random intercept is
literally the product of a decomposition of the general model's error
structure into the within group (R matrix) and between group (G matrix)
components of the error. They are uncorrelated by construction. The only
way that they could possibly be correlated would be if you had an
exchangability problem in the random effects structure. You could have a
fuzzy boundaries issue like US counties are correlated by space. But you
wouldn't solve that by correlating the lower level error term with the
random intercept. You'd build a group boundary spatial weights matrix and
include it in the model.

I must be missing something in the translation.

On Tue, Nov 6, 2018 at 1:11 PM Yashree Mehta <yashree19 at gmail.com> wrote:

> Hi,
>
> Regarding the question on dependency structure, is there a way to allow for
> the possibility of the error term and random intercept being correlated? I
> need to define the covariance matrix between these two terms and estimate
> the values which should go into this matrix.
>
> Thank you
>
> Regards,
> Yashree
>
> On Wed, Oct 17, 2018 at 2:37 AM Ben Bolker <bbolker at gmail.com> wrote:
>
> >
> > > Hi,
> > >
> > > Is there literature on how to specify the dependency structure between
> > the
> > > random intercept and the statistical noise error term in a random
> > intercept
> > > model?
> > > It would be useful to also know how to implement using R...
> >
> >
> >   Can you be more specific about what you want?  Suppose you have
> > observations j within groups i, and you have an epsilon_{0,ij} for each
> > observation (error term) and an epsilon_"1,i} for each group (random
> > intercept).  Typically the epsilon_{0,ij} values are iid with
> > homogeneous variance sigma_0^2, and epsilon_{1,i} are iid with variance
> > sigma_1^2.  What kind of correlation structure are you looking for?
> >
> > While we're at it, you previously asked:
> >
> > ===
> > I am working with a random intercept model. I have the usual "X" vector
> > of covariates and one id variable which will make up the random
> > intercept. For example,
> >
> > Response variable: Production of maize
> > Covariate: Size of plot
> > ID variable: Household_ID
> >
> > I need to acknowledge that there is correlation between the FIXED EFFECT
> > coefficient of plot size and the estimated random intercept. It is my
> > model assumption.
> >
> > Does lme4 assume this correlation or do I have to make changes in the
> > formula so that it gets considered?
> > ===
> >
> >   The short answer to this one is "no", I think -- I don't know that
> > there's a way to allow for correlation between fixed effect coefficients
> > and random intercepts. (This actually seems like a weird question to me;
> > in the frequentist world, as far as I know, you can only specify
> > correlation models for *random variables* within the model.  In the
> > context of LMM fitting, I don't think parameters are random effects in
> > this sense.
> >
> > On 2018-10-16 01:03 PM, Yashree Mehta wrote:
> >
> > >
> > > Thank you
> > >
> > > Yashree
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 




Thanks,
John


John Poe, Ph.D.
Postdoctoral Scholar / Research Methodologist
Center for Public Health Services & Systems Research
University of Kentucky
www.johndavidpoe.com

	[[alternative HTML version deleted]]


From y@@hree19 @ending from gm@il@com  Tue Nov  6 21:05:33 2018
From: y@@hree19 @ending from gm@il@com (Yashree Mehta)
Date: Tue, 6 Nov 2018 21:05:33 +0100
Subject: [R-sig-ME] Dependency structure
In-Reply-To: <CAFW8ByqbE71DDwTC3X5zi-GAck2hG=cH7XTOts167hKq5Qv47A@mail.gmail.com>
References: <CAOE=hqLskrB+f1fnq2Uw-XYNbVyenYby4o=_ZecK5336D-=U3Q@mail.gmail.com>
 <a9e4d806-0e47-33c1-f1f4-ff5e23dd0240@gmail.com>
 <CAOE=hqKBx9w3kgj0y-CbPCs3GMY_Pesu_Ytxd8O2j5k1gN-5LA@mail.gmail.com>
 <CAFW8ByqbE71DDwTC3X5zi-GAck2hG=cH7XTOts167hKq5Qv47A@mail.gmail.com>
Message-ID: <CAOE=hqL-gh=-kn+QrDdLGGSDJhdcazEtWiVqBzz_9NLRtB6mEQ@mail.gmail.com>

thanks for your reply. I read about prediction theory that in the
application of BLUP, one can try to reparameterize a model with non-zero
variance-covariance matrix between the error term and the random intercept
into an equivalent model containing the random intercept and error term as
uncorrelated. Is this possible?



On Tue, Nov 6, 2018 at 7:25 PM Poe, John <jdpo223 at g.uky.edu> wrote:

> Just to clarify, you mean that you want to specify a correlation structure
> between the individual level error term in the model (also called the
> residuals) and the random intercept or group-level error.
>
> This doesn't make a lot of sense to me because the random intercept is
> literally the product of a decomposition of the general model's error
> structure into the within group (R matrix) and between group (G matrix)
> components of the error. They are uncorrelated by construction. The only
> way that they could possibly be correlated would be if you had an
> exchangability problem in the random effects structure. You could have a
> fuzzy boundaries issue like US counties are correlated by space. But you
> wouldn't solve that by correlating the lower level error term with the
> random intercept. You'd build a group boundary spatial weights matrix and
> include it in the model.
>
> I must be missing something in the translation.
>
> On Tue, Nov 6, 2018 at 1:11 PM Yashree Mehta <yashree19 at gmail.com> wrote:
>
>> Hi,
>>
>> Regarding the question on dependency structure, is there a way to allow
>> for
>> the possibility of the error term and random intercept being correlated? I
>> need to define the covariance matrix between these two terms and estimate
>> the values which should go into this matrix.
>>
>> Thank you
>>
>> Regards,
>> Yashree
>>
>> On Wed, Oct 17, 2018 at 2:37 AM Ben Bolker <bbolker at gmail.com> wrote:
>>
>> >
>> > > Hi,
>> > >
>> > > Is there literature on how to specify the dependency structure between
>> > the
>> > > random intercept and the statistical noise error term in a random
>> > intercept
>> > > model?
>> > > It would be useful to also know how to implement using R...
>> >
>> >
>> >   Can you be more specific about what you want?  Suppose you have
>> > observations j within groups i, and you have an epsilon_{0,ij} for each
>> > observation (error term) and an epsilon_"1,i} for each group (random
>> > intercept).  Typically the epsilon_{0,ij} values are iid with
>> > homogeneous variance sigma_0^2, and epsilon_{1,i} are iid with variance
>> > sigma_1^2.  What kind of correlation structure are you looking for?
>> >
>> > While we're at it, you previously asked:
>> >
>> > ===
>> > I am working with a random intercept model. I have the usual "X" vector
>> > of covariates and one id variable which will make up the random
>> > intercept. For example,
>> >
>> > Response variable: Production of maize
>> > Covariate: Size of plot
>> > ID variable: Household_ID
>> >
>> > I need to acknowledge that there is correlation between the FIXED EFFECT
>> > coefficient of plot size and the estimated random intercept. It is my
>> > model assumption.
>> >
>> > Does lme4 assume this correlation or do I have to make changes in the
>> > formula so that it gets considered?
>> > ===
>> >
>> >   The short answer to this one is "no", I think -- I don't know that
>> > there's a way to allow for correlation between fixed effect coefficients
>> > and random intercepts. (This actually seems like a weird question to me;
>> > in the frequentist world, as far as I know, you can only specify
>> > correlation models for *random variables* within the model.  In the
>> > context of LMM fitting, I don't think parameters are random effects in
>> > this sense.
>> >
>> > On 2018-10-16 01:03 PM, Yashree Mehta wrote:
>> >
>> > >
>> > > Thank you
>> > >
>> > > Yashree
>> > >
>> > >       [[alternative HTML version deleted]]
>> > >
>> > > _______________________________________________
>> > > R-sig-mixed-models at r-project.org mailing list
>> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> > >
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
> --
>
>
>
>
> Thanks,
> John
>
>
> John Poe, Ph.D.
> Postdoctoral Scholar / Research Methodologist
> Center for Public Health Services & Systems Research
> University of Kentucky
> www.johndavidpoe.com
>

	[[alternative HTML version deleted]]


From levine@brenn@@@ @ending from gm@il@com  Wed Nov  7 00:16:07 2018
From: levine@brenn@@@ @ending from gm@il@com (Brenna Levine)
Date: Tue, 6 Nov 2018 17:16:07 -0600
Subject: [R-sig-ME] glmmTMB: testing for temporal variation in effect of
 fixed predictor on response variable
Message-ID: <CAC7dje8+7h8sYWEFMKi9FtC2+eLcm6AVfz1qi2-KKMrWLLor5w@mail.gmail.com>

Dr. Bolker,

I'm hoping that I might be able to bother you with a quick question. I am
trying to *test whether there is significant temporal variation in the
effect of a fixed predictor on my response variable *with a model in which
year is specified as a random effect (I have 20 years of data). Currently,
I am doing this by fitting an interaction between the fixed effect and the
random effect of year as* (1|year:fixed)* (per a recommendation that I saw
on RSeek.org at some point and some tips that I have read on this
list-serve), and am testing the significance of this random interaction
with a LRT (i.e., with a model lacking this interaction).

Could you tell me if (a) (1|year:fixed) is the correct way to specify this,
and (b) if not, do you have a recommendation for how I should specify this
interaction to test for temporal variation in the effect of a fixed
predictor on my response variable?

Thanks.

	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Wed Nov  7 03:36:26 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Tue, 6 Nov 2018 21:36:26 -0500
Subject: [R-sig-ME] lme4 1.1-19 going to CRAN soon
Message-ID: <61457219-98c9-4758-1d2d-0e1cbfe86681@mcmaster.ca>


  This is a heads-up that we'll be sending a new version of lme4 to CRAN
soon.  This is not a major revision (the proximal reason for sending a
new version is to address some minor CRAN-compatibility issues).
However, I did *almost* make a "brown paper bag release"
<http://www.catb.org/jargon/html/B/brown-paper-bag-bug.html>, so if
anyone feels like taking the development version for a spin in the next
day or so that would be appreciated.  (The new version is due on CRAN by
Nov 9; we have otherwise completed testing on Travis, win-builder,
reverse dependencies, etc ...)

  cheers
    Ben Bolker


=====
  NEW FEATURES:

         ? influence measure code from ?car? rolled in (see
           ??influence.merMod?)

         ? ?mkReTrm? gets new arguments ?reorder.terms?, ?reorder.vars?
           to control arrangement of RE terms and individual effects
           with RE terms within model structures

         ? adding material from the ?RePsychLing? package (on GitHub;
           see Bates et al 2015 arXiv:1506.04967) to show orthogonal
           variance components.

  USER-VISIBLE CHANGES:

         ? ?as.data.frame.merMod? finds conditional variance
           information stored either as ?attr(.,"postVar")? or
           ?attr(.,"condVar")? (for ?glmmTMB? compatibility)

         ? change to defaults of ?[g]lmerControl? to print a message
           when fits are singular

         ? new utility ?isSingular()? function for detecting singular
           fits; by default a message is printed for singular fits

         ? ?allFit? function/methods have been moved to the main
           package, rather than being included in an auxiliary source
           file

         ? post-fitting convergence checks based on estimated gradient
           and Hessian (see ?troubleshooting?) are no longer performed
           for (nearly-)singular fits (see ?isSingular?)


From thierry@onkelinx @ending from inbo@be  Wed Nov  7 10:34:47 2018
From: thierry@onkelinx @ending from inbo@be (Thierry Onkelinx)
Date: Wed, 7 Nov 2018 10:34:47 +0100
Subject: [R-sig-ME] glmmTMB: testing for temporal variation in effect of
 fixed predictor on response variable
In-Reply-To: <CAC7dje8+7h8sYWEFMKi9FtC2+eLcm6AVfz1qi2-KKMrWLLor5w@mail.gmail.com>
References: <CAC7dje8+7h8sYWEFMKi9FtC2+eLcm6AVfz1qi2-KKMrWLLor5w@mail.gmail.com>
Message-ID: <CAJuCY5wXX3cJ57GM8zpNrJuR4eQOdw18i7Tue004jgw8Rds1nQ@mail.gmail.com>

Dear Brenna,

Adding a random effect (1|year:fixed) makes sense, assuming that both year
and fixed are discrete. Note that adding this allows for a very liberal
temporal variantion by the fixed effect. Each level of the interaction is
independent from all other levels.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op wo 7 nov. 2018 om 00:16 schreef Brenna Levine <levine.brenna.a at gmail.com
>:

> Dr. Bolker,
>
> I'm hoping that I might be able to bother you with a quick question. I am
> trying to *test whether there is significant temporal variation in the
> effect of a fixed predictor on my response variable *with a model in which
> year is specified as a random effect (I have 20 years of data). Currently,
> I am doing this by fitting an interaction between the fixed effect and the
> random effect of year as* (1|year:fixed)* (per a recommendation that I saw
> on RSeek.org at some point and some tips that I have read on this
> list-serve), and am testing the significance of this random interaction
> with a LRT (i.e., with a model lacking this interaction).
>
> Could you tell me if (a) (1|year:fixed) is the correct way to specify this,
> and (b) if not, do you have a recommendation for how I should specify this
> interaction to test for temporal variation in the effect of a fixed
> predictor on my response variable?
>
> Thanks.
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From thierry@onkelinx @ending from inbo@be  Wed Nov  7 16:53:31 2018
From: thierry@onkelinx @ending from inbo@be (Thierry Onkelinx)
Date: Wed, 7 Nov 2018 16:53:31 +0100
Subject: [R-sig-ME] glmmTMB: testing for temporal variation in effect of
 fixed predictor on response variable
In-Reply-To: <CAC7dje89MyNVLG_USN=-Ocwwi4HsLO1drih9zSJ-y842it2HFA@mail.gmail.com>
References: <CAC7dje8+7h8sYWEFMKi9FtC2+eLcm6AVfz1qi2-KKMrWLLor5w@mail.gmail.com>
 <CAJuCY5wXX3cJ57GM8zpNrJuR4eQOdw18i7Tue004jgw8Rds1nQ@mail.gmail.com>
 <CAC7dje89MyNVLG_USN=-Ocwwi4HsLO1drih9zSJ-y842it2HFA@mail.gmail.com>
Message-ID: <CAJuCY5yTLiHY++YjHwvhs+-j03nry8-QE-U49+K3HJBU3HVL1w@mail.gmail.com>

Dear Brenna,

Please keep the mailing list in cc.

(1 + fixed|year) fits a random intercept and a random slope along "fixed"
for every "year". Keep in mind that you need enough data to support such a
model. See e.g.
https://www.muscardinus.be/2018/02/highly-correlated-random-effects/

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op wo 7 nov. 2018 om 14:18 schreef Brenna Levine <levine.brenna.a at gmail.com
>:

> Hi Thierry,
>
> Thanks for your detailed response. I have one fixed effect that is not
> discrete. How should I fit this interaction in this case?
>
> Thanks!
>
> Brenna
>
> On Wed, Nov 7, 2018, 3:35 AM Thierry Onkelinx <thierry.onkelinx at inbo.be
> wrote:
>
>> Dear Brenna,
>>
>> Adding a random effect (1|year:fixed) makes sense, assuming that both
>> year and fixed are discrete. Note that adding this allows for a very
>> liberal temporal variantion by the fixed effect. Each level of the
>> interaction is independent from all other levels.
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>> AND FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be
>> Havenlaan 88 bus 73, 1000 Brussel
>> www.inbo.be
>>
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>>
>> <https://www.inbo.be>
>>
>>
>> Op wo 7 nov. 2018 om 00:16 schreef Brenna Levine <
>> levine.brenna.a at gmail.com>:
>>
>>> Dr. Bolker,
>>>
>>> I'm hoping that I might be able to bother you with a quick question. I am
>>> trying to *test whether there is significant temporal variation in the
>>> effect of a fixed predictor on my response variable *with a model in
>>> which
>>> year is specified as a random effect (I have 20 years of data).
>>> Currently,
>>> I am doing this by fitting an interaction between the fixed effect and
>>> the
>>> random effect of year as* (1|year:fixed)* (per a recommendation that I
>>> saw
>>> on RSeek.org at some point and some tips that I have read on this
>>> list-serve), and am testing the significance of this random interaction
>>> with a LRT (i.e., with a model lacking this interaction).
>>>
>>> Could you tell me if (a) (1|year:fixed) is the correct way to specify
>>> this,
>>> and (b) if not, do you have a recommendation for how I should specify
>>> this
>>> interaction to test for temporal variation in the effect of a fixed
>>> predictor on my response variable?
>>>
>>> Thanks.
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>

	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Wed Nov  7 17:42:32 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Wed, 7 Nov 2018 11:42:32 -0500
Subject: [R-sig-ME] glmmTMB: testing for temporal variation in effect of
 fixed predictor on response variable
In-Reply-To: <CAJuCY5yTLiHY++YjHwvhs+-j03nry8-QE-U49+K3HJBU3HVL1w@mail.gmail.com>
References: <CAC7dje8+7h8sYWEFMKi9FtC2+eLcm6AVfz1qi2-KKMrWLLor5w@mail.gmail.com>
 <CAJuCY5wXX3cJ57GM8zpNrJuR4eQOdw18i7Tue004jgw8Rds1nQ@mail.gmail.com>
 <CAC7dje89MyNVLG_USN=-Ocwwi4HsLO1drih9zSJ-y842it2HFA@mail.gmail.com>
 <CAJuCY5yTLiHY++YjHwvhs+-j03nry8-QE-U49+K3HJBU3HVL1w@mail.gmail.com>
Message-ID: <CABghstQXz4zYvuT3NDRWXZAvzVvOYjjUrWQg1VroNGuaVh-oiw@mail.gmail.com>

  Yes, to amplify slightly: suppose you have categorical fixed effects
f1, f2, f3 and continuous fixed effect x1.

  The most complete random-effects model would be (1+f1+f2+f3+x1|year)
 (assuming that all of the fixed effects vary among years and so it
even makes sense to estimate year-by-effect variation), but this is
very likely to be too complex to fit, especially if your categorical
predictors have more than 2 levels.

  (1|year) + (1|f1:year) + (1|f2:year) + (1|f3:year) + (0+x1|year)

would be a reasonable simplification (this only fits 5 variance
parameters), but does assume that the effects vary independently.

  Also note that likelihood ratio tests of variance components are
generally conservative (see details at
http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#testing-significance-of-random-effects
)
On Wed, Nov 7, 2018 at 10:53 AM Thierry Onkelinx via
R-sig-mixed-models <r-sig-mixed-models at r-project.org> wrote:
>
> Dear Brenna,
>
> Please keep the mailing list in cc.
>
> (1 + fixed|year) fits a random intercept and a random slope along "fixed"
> for every "year". Keep in mind that you need enough data to support such a
> model. See e.g.
> https://www.muscardinus.be/2018/02/highly-correlated-random-effects/
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be>
>
>
> Op wo 7 nov. 2018 om 14:18 schreef Brenna Levine <levine.brenna.a at gmail.com
> >:
>
> > Hi Thierry,
> >
> > Thanks for your detailed response. I have one fixed effect that is not
> > discrete. How should I fit this interaction in this case?
> >
> > Thanks!
> >
> > Brenna
> >
> > On Wed, Nov 7, 2018, 3:35 AM Thierry Onkelinx <thierry.onkelinx at inbo.be
> > wrote:
> >
> >> Dear Brenna,
> >>
> >> Adding a random effect (1|year:fixed) makes sense, assuming that both
> >> year and fixed are discrete. Note that adding this allows for a very
> >> liberal temporal variantion by the fixed effect. Each level of the
> >> interaction is independent from all other levels.
> >>
> >> Best regards,
> >>
> >> ir. Thierry Onkelinx
> >> Statisticus / Statistician
> >>
> >> Vlaamse Overheid / Government of Flanders
> >> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> >> AND FOREST
> >> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> >> thierry.onkelinx at inbo.be
> >> Havenlaan 88 bus 73, 1000 Brussel
> >> www.inbo.be
> >>
> >>
> >> ///////////////////////////////////////////////////////////////////////////////////////////
> >> To call in the statistician after the experiment is done may be no more
> >> than asking him to perform a post-mortem examination: he may be able to say
> >> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> >> The plural of anecdote is not data. ~ Roger Brinner
> >> The combination of some data and an aching desire for an answer does not
> >> ensure that a reasonable answer can be extracted from a given body of data.
> >> ~ John Tukey
> >>
> >> ///////////////////////////////////////////////////////////////////////////////////////////
> >>
> >> <https://www.inbo.be>
> >>
> >>
> >> Op wo 7 nov. 2018 om 00:16 schreef Brenna Levine <
> >> levine.brenna.a at gmail.com>:
> >>
> >>> Dr. Bolker,
> >>>
> >>> I'm hoping that I might be able to bother you with a quick question. I am
> >>> trying to *test whether there is significant temporal variation in the
> >>> effect of a fixed predictor on my response variable *with a model in
> >>> which
> >>> year is specified as a random effect (I have 20 years of data).
> >>> Currently,
> >>> I am doing this by fitting an interaction between the fixed effect and
> >>> the
> >>> random effect of year as* (1|year:fixed)* (per a recommendation that I
> >>> saw
> >>> on RSeek.org at some point and some tips that I have read on this
> >>> list-serve), and am testing the significance of this random interaction
> >>> with a LRT (i.e., with a model lacking this interaction).
> >>>
> >>> Could you tell me if (a) (1|year:fixed) is the correct way to specify
> >>> this,
> >>> and (b) if not, do you have a recommendation for how I should specify
> >>> this
> >>> interaction to test for temporal variation in the effect of a fixed
> >>> predictor on my response variable?
> >>>
> >>> Thanks.
> >>>
> >>>         [[alternative HTML version deleted]]
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>
> >>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From @imon@kf @ending from zrc-@@zu@@i  Wed Nov  7 13:05:28 2018
From: @imon@kf @ending from zrc-@@zu@@i (Simona Kralj Fiser)
Date: Wed, 7 Nov 2018 13:05:28 +0100
Subject: [R-sig-ME] MCMCglmm: square root of the sampling variance of
 additive genetic variance
Message-ID: <CAPkBqkkp_Fc9v5g2aMTFH3jZTn4ECcwZKMOEwkKNc+bF-qxa1Q@mail.gmail.com>

Hi.
I used MCMCglmm to calculate the heritability of a trait [Va/(Va+Vr)]; e.g.:

prior<-list(G=list(G1=list(V=matrix(p.var*0.5),n=1)),R=list(V=matrix(p.var*0.5),n=1)

model <- MCMCglmm(trait~ 1, random = ~animal, pedigree = pedigree,data =
data, nitt = 5000000, thin = 100, burnin = 150000, prior = prior, verbose =
FALSE)

> summary(model)



 Iterations = 150001:4999901

 Thinning interval  = 100

 Sample size  = 48500



 DIC: 2032.226



 G-structure:  ~animal



       post.mean l-95% CI u-95% CI eff.samp

animal     78.48    38.18    120.3    48500



 R-structure:  ~units



      post.mean l-95% CI u-95% CI eff.samp

units     84.11     59.5    109.2    48500



 Location effects: trait~ 1



            post.mean l-95% CI u-95% CI eff.samp  pMCMC

(Intercept)     6.918    4.589    9.091    48500 <2e-05 ***


> HPDinterval(model$VCV)

          lower    upper

animal 38.18195 120.3350

units  59.50312 109.1574

attr(,"Probability")

[1] 0.95


> herit <- model$VCV[, "animal"]/(model$VCV[, "animal"] + model$VCV[,
"units"])


> mean(herit)

[1] 0.4772017


> HPDinterval(herit, 0.95)

         lower     upper

var1 0.2940021 0.6576105

attr(,"Probability")

[1] 0.95


I have two questions:

1. I am trying to call the standard errors for additive and residual
variance


se(model$VCV[, "animal"]) does not work


I used

> sd(model$VCV[, "animal"])

[1] 21.36365



> sd(model$VCV[, "units"])

[1] 12.8011



I wonder whether the SD (of Va) provides the square root of the sampling
variance of Va. Could you please confirm this? I am interested in
calculating the SE of Va to calculate the SEs of other statistics (e.g.,
CVa).

2. Also, is there a way to plot the posterior distribution of the
heritability (or Va) estimates?

Thank you!

Simona

---

	[[alternative HTML version deleted]]


From roim@or m@ili@g off post@t@u@@c@il  Wed Nov  7 14:51:40 2018
From: roim@or m@ili@g off post@t@u@@c@il (roim@or m@ili@g off post@t@u@@c@il)
Date: Wed, 07 Nov 2018 15:51:40 +0200
Subject: [R-sig-ME] Unclear output from MCMCglmm with categorical predictors
Message-ID: <20181107155140.Horde.oHgXEzpRoYRb4u3sVchVdtA@webmail.tau.ac.il>

Dear list members,

I have a model with categorical response and categorical + continuous  
predictors.

My model has two categorical predictors: "diet" (3 levels) and  
"habitat" (6 levels):

THRE1 <- MCMCglmm(Activity ~ -1 + Habitat + Diet + log(Mass) + Max.Temp,
                      prior = list(R = list(V = 1, fix = 1)),
                      ginverse = list(Binomial=INphylo$Ainv),
                      family = "threshold",
                      data = Tdata)

If I understand correctly, in this configuration the algorithm  
shouldn't return estimated values for the effect of each level of a  
categorical predictor, instead, it returns a contrast between that  
level and another level which was arbitrarily chosen as the base  
level. Each species (data point) has a value for each of these traits,  
so I would expect them to be estimated independently, meaning that one  
level of each predictor should be the 'baseline' and absorbed into the  
global intercept. In that case I expect 2 contrasts to be returned for  
diet categories and 5 contrasts for habitat.

However, I get 2 estimates (presumably contrasts) for diet categories,  
and 6 for habitat categories, i.e., no habitat category was designated  
as baseline, which makes me question whether the estimates are  
contrasts or actual effect sizes.

My questions:
- Is the algorithm pooling all the predictor categories as if they  
were a single trait with 8 levels?
- If the habitat effect estimates are contrasts - what are they compared to?
- If they are effect sizes - what did I do to not get the contrasts as  
I expected?

Any help would be much appreciated!
Thanks,
-- 
Roi Maor
PhD candidate
School of Zoology, Tel Aviv University
Centre for Biodiversity and Environment Research, UCL


From w@lidm@w@@@10 @ending from gm@il@com  Wed Nov  7 18:28:43 2018
From: w@lidm@w@@@10 @ending from gm@il@com (Walid Mawass)
Date: Wed, 7 Nov 2018 12:28:43 -0500
Subject: [R-sig-ME] MCMCglmm: square root of the sampling variance of
 additive genetic variance
In-Reply-To: <CAPkBqkkp_Fc9v5g2aMTFH3jZTn4ECcwZKMOEwkKNc+bF-qxa1Q@mail.gmail.com>
References: <CAPkBqkkp_Fc9v5g2aMTFH3jZTn4ECcwZKMOEwkKNc+bF-qxa1Q@mail.gmail.com>
Message-ID: <CAJtCY7U9SsBjNrwbJ=5ytYj_RLU+fdjZ5ZO6ZyxJUNE9qsCj4Q@mail.gmail.com>

Hello,

The MCMCglmm estimates the posterior distribution of the additive and
residual variances, to my knowledge then, there is no standard error
associated with it rather you can output the HPD interval or highest
posterior density interval at a 95 or 98% confidence interval, which you
already have done. I stand to be corrected though.

for your second question, it is quite easy, you just need use the basic
plot function. In your case, plot(model$VCV[, "animal"]), this will return
a plot of the posterior distribution and the iterations of the Markov Chain
to visually check for autocorrelation between iterations.(there are other
packages to plot mcmc outputs if you dont want to go with the basic plot,
bayesplot comes to mind)

Good luck
-- 
Walid Mawass
Ph.D. candidate in Cellular and Molecular Biology
Population Genetics Laboratory
University of Qu?bec at Trois-Rivi?res
3351, boul. des Forges, C.P. 500
Trois-Rivi?res (Qu?bec) G9A 5H7
Telephone: 819-376-5011 poste 3384


On Wed, Nov 7, 2018 at 12:09 PM Simona Kralj Fiser <simonakf at zrc-sazu.si>
wrote:

> Hi.
> I used MCMCglmm to calculate the heritability of a trait [Va/(Va+Vr)];
> e.g.:
>
>
> prior<-list(G=list(G1=list(V=matrix(p.var*0.5),n=1)),R=list(V=matrix(p.var*0.5),n=1)
>
> model <- MCMCglmm(trait~ 1, random = ~animal, pedigree = pedigree,data =
> data, nitt = 5000000, thin = 100, burnin = 150000, prior = prior, verbose =
> FALSE)
>
> > summary(model)
>
>
>
>  Iterations = 150001:4999901
>
>  Thinning interval  = 100
>
>  Sample size  = 48500
>
>
>
>  DIC: 2032.226
>
>
>
>  G-structure:  ~animal
>
>
>
>        post.mean l-95% CI u-95% CI eff.samp
>
> animal     78.48    38.18    120.3    48500
>
>
>
>  R-structure:  ~units
>
>
>
>       post.mean l-95% CI u-95% CI eff.samp
>
> units     84.11     59.5    109.2    48500
>
>
>
>  Location effects: trait~ 1
>
>
>
>             post.mean l-95% CI u-95% CI eff.samp  pMCMC
>
> (Intercept)     6.918    4.589    9.091    48500 <2e-05 ***
>
>
> > HPDinterval(model$VCV)
>
>           lower    upper
>
> animal 38.18195 120.3350
>
> units  59.50312 109.1574
>
> attr(,"Probability")
>
> [1] 0.95
>
>
> > herit <- model$VCV[, "animal"]/(model$VCV[, "animal"] + model$VCV[,
> "units"])
>
>
> > mean(herit)
>
> [1] 0.4772017
>
>
> > HPDinterval(herit, 0.95)
>
>          lower     upper
>
> var1 0.2940021 0.6576105
>
> attr(,"Probability")
>
> [1] 0.95
>
>
> I have two questions:
>
> 1. I am trying to call the standard errors for additive and residual
> variance
>
>
> se(model$VCV[, "animal"]) does not work
>
>
> I used
>
> > sd(model$VCV[, "animal"])
>
> [1] 21.36365
>
>
>
> > sd(model$VCV[, "units"])
>
> [1] 12.8011
>
>
>
> I wonder whether the SD (of Va) provides the square root of the sampling
> variance of Va. Could you please confirm this? I am interested in
> calculating the SE of Va to calculate the SEs of other statistics (e.g.,
> CVa).
>
> 2. Also, is there a way to plot the posterior distribution of the
> heritability (or Va) estimates?
>
> Thank you!
>
> Simona
>
> ---
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From w@lidm@w@@@10 @ending from gm@il@com  Wed Nov  7 18:36:17 2018
From: w@lidm@w@@@10 @ending from gm@il@com (Walid Mawass)
Date: Wed, 7 Nov 2018 12:36:17 -0500
Subject: [R-sig-ME] 
 Unclear output from MCMCglmm with categorical predictors
In-Reply-To: <20181107155140.Horde.oHgXEzpRoYRb4u3sVchVdtA@webmail.tau.ac.il>
References: <20181107155140.Horde.oHgXEzpRoYRb4u3sVchVdtA@webmail.tau.ac.il>
Message-ID: <CAJtCY7UpBkrLZMGM1+Riv6U_epqfj_K5Xek=Cnjsdcdm7dvojw@mail.gmail.com>

Hello,

by adding -1 into your model's formula, you are explicitly calling for no
intercept term to be included in the estimates. If you do want an intercept
term which would include a baseline level for each of your categorical
variables then the syntax should be:

MCMCglmm(Activity ~1 + Habitat + Diet + log(Mass) + Max.Temp... (explicit
call for intercept term)
or
MCMCglmm(Activity ~ Habitat + Diet + log(Mass) + Max.Temp... (implicit call
for intercept term)

Hope this helps
-- 
Walid Mawass
Ph.D. candidate in Cellular and Molecular Biology
Population Genetics Laboratory
University of Qu?bec at Trois-Rivi?res
3351, boul. des Forges, C.P. 500
Trois-Rivi?res (Qu?bec) G9A 5H7
Telephone: 819-376-5011 poste 3384


On Wed, Nov 7, 2018 at 12:09 PM <roimaor at post.tau.ac.il> wrote:

> Dear list members,
>
> I have a model with categorical response and categorical + continuous
> predictors.
>
> My model has two categorical predictors: "diet" (3 levels) and
> "habitat" (6 levels):
>
> THRE1 <- MCMCglmm(Activity ~ -1 + Habitat + Diet + log(Mass) + Max.Temp,
>                       prior = list(R = list(V = 1, fix = 1)),
>                       ginverse = list(Binomial=INphylo$Ainv),
>                       family = "threshold",
>                       data = Tdata)
>
> If I understand correctly, in this configuration the algorithm
> shouldn't return estimated values for the effect of each level of a
> categorical predictor, instead, it returns a contrast between that
> level and another level which was arbitrarily chosen as the base
> level. Each species (data point) has a value for each of these traits,
> so I would expect them to be estimated independently, meaning that one
> level of each predictor should be the 'baseline' and absorbed into the
> global intercept. In that case I expect 2 contrasts to be returned for
> diet categories and 5 contrasts for habitat.
>
> However, I get 2 estimates (presumably contrasts) for diet categories,
> and 6 for habitat categories, i.e., no habitat category was designated
> as baseline, which makes me question whether the estimates are
> contrasts or actual effect sizes.
>
> My questions:
> - Is the algorithm pooling all the predictor categories as if they
> were a single trait with 8 levels?
> - If the habitat effect estimates are contrasts - what are they compared
> to?
> - If they are effect sizes - what did I do to not get the contrasts as
> I expected?
>
> Any help would be much appreciated!
> Thanks,
> --
> Roi Maor
> PhD candidate
> School of Zoology, Tel Aviv University
> Centre for Biodiversity and Environment Research, UCL
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From pierre@de@villemereuil @ending from m@iloo@org  Wed Nov  7 19:09:42 2018
From: pierre@de@villemereuil @ending from m@iloo@org (Pierre de Villemereuil)
Date: Wed, 07 Nov 2018 19:09:42 +0100
Subject: [R-sig-ME] MCMCglmm: square root of the sampling variance of
 additive genetic variance
In-Reply-To: <CAJtCY7U9SsBjNrwbJ=5ytYj_RLU+fdjZ5ZO6ZyxJUNE9qsCj4Q@mail.gmail.com>
References: <CAPkBqkkp_Fc9v5g2aMTFH3jZTn4ECcwZKMOEwkKNc+bF-qxa1Q@mail.gmail.com>
 <CAJtCY7U9SsBjNrwbJ=5ytYj_RLU+fdjZ5ZO6ZyxJUNE9qsCj4Q@mail.gmail.com>
Message-ID: <13524669.ijSL9NVrgx@flyosfixe>

Hi,

Just to clarify this:

> The MCMCglmm estimates the posterior distribution of the additive and
> residual variances, to my knowledge then, there is no standard error
> associated with it rather you can output the HPD interval or highest
> posterior density interval at a 95 or 98% confidence interval, which you
> already have done. I stand to be corrected though.

The sd() of the MCMC chain is indeed an estimate of the standard error (+ some error itself coming from the Monte Carlo process), though HPD interval is indeed probably a better (and more Bayesian, in a way) way to measure the uncertainty. 

I might also stand to be corrected! ;)

Cheers,
Pierre.


From d@idhu @ending from uc@lg@ry@c@  Wed Nov  7 23:27:47 2018
From: d@idhu @ending from uc@lg@ry@c@ (David Sidhu)
Date: Wed, 7 Nov 2018 22:27:47 +0000
Subject: [R-sig-ME] Adding random subject or item slopes for a specific
 contrast
Message-ID: <2E987257-ADF7-43A3-B95B-CB9420CE820A@ucalgary.ca>

Hi There

I have been following the approach described in Bates et al. (2018) to simplify my random effects structure. I will use the data pasted below as an example (though the effects I describe aren?t present there, I use it only to have an example to refer to).

Now, if it seems that there is variance in the random subject slope comparing IV1 level 2 vs. IV1 level 1, but in no other contrast?s random subject slope, I would like to only include a random subject slope for that one specific contrast. Also assume that the method described by Bates et al. (2018) suggests that the random effects structure should only have one component.

Two questions: Is it sensible to only include this one slope? Is it possible in lme4 to only include this one slope?

Thanks!
Dave





Subj <- rep(1:10, each = 10) Item <- rep(1:10, times = 10) IV1 <- rep(1:5, times = 20) DV <- rnorm(100) library(data.table) data <- as.data.table(cbind(Subj, Item, IV1, DV)) data$Subj <- as.factor(data$Subj) data$Item <- as.factor(data$Item) data$IV1 <- as.factor(data$IV1) library(MASS) contrasts(data$IV1) <- contr.sdif(5) library(lme4) m <- lmer(DV ~ IV1 + (1 + IV1|Subj) + (1|Item), data = data)




---
David M. Sidhu, MSc
PhD Candidate
Department of Psychology
University of Calgary







	[[alternative HTML version deleted]]


From Benj@min_CARBONNE @ending from hotm@il@fr  Thu Nov  8 16:48:28 2018
From: Benj@min_CARBONNE @ending from hotm@il@fr (Benjamin CARBONNE)
Date: Thu, 8 Nov 2018 15:48:28 +0000
Subject: [R-sig-ME] GLMERTREE and REEMTREE to build regression trees with
 random effects
Message-ID: <AM6PR0402MB34488AACBAC5DD7C96A6E95CF5C50@AM6PR0402MB3448.eurprd04.prod.outlook.com>

Good morning, everyone,

I am trying to build a regression tree with a predation rate (between 0 and 1) as the response variable, and the abundance of different species as the partitioning variables. In order to take into account the structure of my data (monitoring of several plots nested in different projects, and monitored over different months), I want to use methods to integrate random effects.

I have identified two methods that I think are appropriate: GLMERTREE and REEMTREE.

With GLMERTREE:
My question about GLMERTREE is whether I can use it without a "treatment" variable, as follows:
gt <- glmertree(TP_viola ~  1 |(1 | Data)+(1|Parcelle)+(1|Mois)| HarpalusCP+....+ParophonusCP, joint=TRUE,
                data = Compilation_zone_av_genre_CP,family = "binomial", alpha = 0.05)
In addition, do you have any ideas to help me validate the tree? I tried the stabletree package to get information about the stability of the tree (selection of varaibles, and cutpoints) but the stabletree function gives me an error message as follow:
Error in length(value <- as.numeric(value)) == 1L :
  (maxstephalfit) PIRLS step-halvings failed to reduce deviance in pwrssUpdate
Which is not the case if I use LMERTREE

With REEMTREE:
Strangely, when I realize my regression tree with REEMTREE as follows:

REEMresult<-REEMtree(TP_viola ~HarpalusCP+....+ParophonusCP,
+                      data = Compilation_zone_av_genre_CP, random=list(~1|Projet,~1|Parcelle,~1|Mois))
I get different trees each time I run my code (the trees are more or less deep and different). Moreover, when I visualize my tree with boxplot I see that the values are no longer between 0 and 1. Do you have any idea where this instability comes from, and why the predation values are changed?

Finally, concerning REEMTREE and GLMETREE, do you have any idea how to see the surrogate splits?

Thank you very much
Benjamin Carbonne


	[[alternative HTML version deleted]]


From g@ughr@ @ending from tcd@ie  Fri Nov  9 13:24:47 2018
From: g@ughr@ @ending from tcd@ie (Aoibheann Gaughran)
Date: Fri, 9 Nov 2018 12:24:47 +0000
Subject: [R-sig-ME] post hoc tests for glmmTMB
Message-ID: <CAN=0SEmQE6f=OAofUeSg_e2f-O2tnfUepqUSRO28onLw_dgh1w@mail.gmail.com>

Dear list,

I am trying to perform post hoc tests on a glmmTMB model. I would normally
use car::Anova and mulgcomp::glht on my glmms (lmers). However, these
functions do not appear to be working for glmmTMB (when I run the model as
an lmer they work fine). I have also tried lsmeans and emmeans but they do
not appear to support glmmTMB either (although it appears they used to). I
have found various treads online suggesting that these functions should
work with TMB but they date back a few months.

I am using the most up to date versions of R (3.5.1) and have updated all
of my packages e.g. glmmTMB 0.2.2.0, lsmeans 2.30-0

The following are the error messages that I receive:

> Anova(topmodTRFETE, type = 2)Error in I.p[c(subs.relatives, subs.term), , drop = FALSE] :
  subscript out of bound

> summary(glht(topmodTRFETE, linfct = mcp(roadworks = "Tukey")), test = adjusted("holm"))Error in modelparm.default(model, ...) :
  dimensions of coefficients and covariance matrix don't match
> source(system.file("other_methods","lsmeans_methods.R",package="glmmTMB"))> lsmeans(topmodTRFETE, pairwise ~ roadworks, adjustSigma = TRUE, adjust = "holm")Error in ref_grid(object, ...) :
  Can't handle an object of class  ?glmmTMB?
 Use help("models", package = "emmeans") for information on supported
models.> rw.emm.s <- emmeans(topmodTRFETE, "roadworks")Error in
ref_grid(object, ...) :
  Can't handle an object of class  ?glmmTMB?
 Use help("models", package = "emmeans") for information on supported models.


Can any point me in the direction of a workaround for performing posthocs
on my glmmTMB model?

Many thanks,

-- 
Aoibheann Gaughran

Behavioural and Evolutionary Ecology Research Group
Zoology Building
School of Natural Sciences
Trinity College Dublin
Dublin 2
Ireland
Phone: +353 (86) 3812615

	[[alternative HTML version deleted]]


From g@ughr@ @ending from tcd@ie  Fri Nov  9 15:24:16 2018
From: g@ughr@ @ending from tcd@ie (Aoibheann Gaughran)
Date: Fri, 9 Nov 2018 14:24:16 +0000
Subject: [R-sig-ME] post hoc tests for glmmTMB
In-Reply-To: <CAN=0SEmQE6f=OAofUeSg_e2f-O2tnfUepqUSRO28onLw_dgh1w@mail.gmail.com>
References: <CAN=0SEmQE6f=OAofUeSg_e2f-O2tnfUepqUSRO28onLw_dgh1w@mail.gmail.com>
Message-ID: <CAN=0SEmLvC_X87qQgMmuBh_npb=g7WJ5acM78jX44TXjS7VAqQ@mail.gmail.com>

Update: lsmeans works if I use an older version of lsmeans (2.27-62) - can
I rely on the results?

Many thanks, Aoibheann

On Fri, 9 Nov 2018 at 12:24, Aoibheann Gaughran <gaughra at tcd.ie> wrote:

> Dear list,
>
> I am trying to perform post hoc tests on a glmmTMB model. I would normally
> use car::Anova and mulgcomp::glht on my glmms (lmers). However, these
> functions do not appear to be working for glmmTMB (when I run the model as
> an lmer they work fine). I have also tried lsmeans and emmeans but they do
> not appear to support glmmTMB either (although it appears they used to). I
> have found various treads online suggesting that these functions should
> work with TMB but they date back a few months.
>
> I am using the most up to date versions of R (3.5.1) and have updated all
> of my packages e.g. glmmTMB 0.2.2.0, lsmeans 2.30-0
>
> The following are the error messages that I receive:
>
> > Anova(topmodTRFETE, type = 2)Error in I.p[c(subs.relatives, subs.term), , drop = FALSE] :
>   subscript out of bound
>
> > summary(glht(topmodTRFETE, linfct = mcp(roadworks = "Tukey")), test = adjusted("holm"))Error in modelparm.default(model, ...) :
>   dimensions of coefficients and covariance matrix don't match
> > source(system.file("other_methods","lsmeans_methods.R",package="glmmTMB"))> lsmeans(topmodTRFETE, pairwise ~ roadworks, adjustSigma = TRUE, adjust = "holm")Error in ref_grid(object, ...) :
>   Can't handle an object of class  ?glmmTMB?
>  Use help("models", package = "emmeans") for information on supported models.> rw.emm.s <- emmeans(topmodTRFETE, "roadworks")Error in ref_grid(object, ...) :
>   Can't handle an object of class  ?glmmTMB?
>  Use help("models", package = "emmeans") for information on supported models.
>
>
> Can any point me in the direction of a workaround for performing posthocs
> on my glmmTMB model?
>
> Many thanks,
>
> --
> Aoibheann Gaughran
>
> Behavioural and Evolutionary Ecology Research Group
> Zoology Building
> School of Natural Sciences
> Trinity College Dublin
> Dublin 2
> Ireland
> Phone: +353 (86) 3812615
>


-- 
Aoibheann Gaughran

Behavioural and Evolutionary Ecology Research Group
Zoology Building
School of Natural Sciences
Trinity College Dublin
Dublin 2
Ireland
Phone: +353 (86) 3812615

	[[alternative HTML version deleted]]


From guill@ume@imon@@2 @ending from gm@il@com  Fri Nov  9 15:42:54 2018
From: guill@ume@imon@@2 @ending from gm@il@com (Guillaume Adeux)
Date: Fri, 9 Nov 2018 15:42:54 +0100
Subject: [R-sig-ME] post hoc tests for glmmTMB
In-Reply-To: <CAN=0SEmLvC_X87qQgMmuBh_npb=g7WJ5acM78jX44TXjS7VAqQ@mail.gmail.com>
References: <CAN=0SEmQE6f=OAofUeSg_e2f-O2tnfUepqUSRO28onLw_dgh1w@mail.gmail.com>
 <CAN=0SEmLvC_X87qQgMmuBh_npb=g7WJ5acM78jX44TXjS7VAqQ@mail.gmail.com>
Message-ID: <CAENiVe-6DfUx3ztwFrr08a5jc1BBQ9C7EaXLD71nG5NuC+TkWQ@mail.gmail.com>

Hi Aoibheann,

I think that anova on glmmTMB objects only produce Wald tests, which don't
seem to be very reliable.
You might want to look at the monet package (or its little brother afex)
that can produce LRT tests or parametric bootstrap.

Moreover, emmeans should work fine with glmmTMB but I remember having a
similar problem.

Maybe this thread and the following discussion can help you out:
https://stackoverflow.com/questions/48609432/error-message-lsmeans-for-beta-mixed-regression-model-with-glmmtmb

GA2



Le ven. 9 nov. 2018 ? 15:24, Aoibheann Gaughran <gaughra at tcd.ie> a ?crit :

> Update: lsmeans works if I use an older version of lsmeans (2.27-62) - can
> I rely on the results?
>
> Many thanks, Aoibheann
>
> On Fri, 9 Nov 2018 at 12:24, Aoibheann Gaughran <gaughra at tcd.ie> wrote:
>
> > Dear list,
> >
> > I am trying to perform post hoc tests on a glmmTMB model. I would
> normally
> > use car::Anova and mulgcomp::glht on my glmms (lmers). However, these
> > functions do not appear to be working for glmmTMB (when I run the model
> as
> > an lmer they work fine). I have also tried lsmeans and emmeans but they
> do
> > not appear to support glmmTMB either (although it appears they used to).
> I
> > have found various treads online suggesting that these functions should
> > work with TMB but they date back a few months.
> >
> > I am using the most up to date versions of R (3.5.1) and have updated all
> > of my packages e.g. glmmTMB 0.2.2.0, lsmeans 2.30-0
> >
> > The following are the error messages that I receive:
> >
> > > Anova(topmodTRFETE, type = 2)Error in I.p[c(subs.relatives,
> subs.term), , drop = FALSE] :
> >   subscript out of bound
> >
> > > summary(glht(topmodTRFETE, linfct = mcp(roadworks = "Tukey")), test =
> adjusted("holm"))Error in modelparm.default(model, ...) :
> >   dimensions of coefficients and covariance matrix don't match
> > >
> source(system.file("other_methods","lsmeans_methods.R",package="glmmTMB"))>
> lsmeans(topmodTRFETE, pairwise ~ roadworks, adjustSigma = TRUE, adjust =
> "holm")Error in ref_grid(object, ...) :
> >   Can't handle an object of class  ?glmmTMB?
> >  Use help("models", package = "emmeans") for information on supported
> models.> rw.emm.s <- emmeans(topmodTRFETE, "roadworks")Error in
> ref_grid(object, ...) :
> >   Can't handle an object of class  ?glmmTMB?
> >  Use help("models", package = "emmeans") for information on supported
> models.
> >
> >
> > Can any point me in the direction of a workaround for performing posthocs
> > on my glmmTMB model?
> >
> > Many thanks,
> >
> > --
> > Aoibheann Gaughran
> >
> > Behavioural and Evolutionary Ecology Research Group
> > Zoology Building
> > School of Natural Sciences
> > Trinity College Dublin
> > Dublin 2
> > Ireland
> > Phone: +353 (86) 3812615
> >
>
>
> --
> Aoibheann Gaughran
>
> Behavioural and Evolutionary Ecology Research Group
> Zoology Building
> School of Natural Sciences
> Trinity College Dublin
> Dublin 2
> Ireland
> Phone: +353 (86) 3812615
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From g@ughr@ @ending from tcd@ie  Fri Nov  9 16:07:40 2018
From: g@ughr@ @ending from tcd@ie (Aoibheann Gaughran)
Date: Fri, 9 Nov 2018 15:07:40 +0000
Subject: [R-sig-ME] post hoc tests for glmmTMB
In-Reply-To: <CAENiVe-6DfUx3ztwFrr08a5jc1BBQ9C7EaXLD71nG5NuC+TkWQ@mail.gmail.com>
References: <CAN=0SEmQE6f=OAofUeSg_e2f-O2tnfUepqUSRO28onLw_dgh1w@mail.gmail.com>
 <CAN=0SEmLvC_X87qQgMmuBh_npb=g7WJ5acM78jX44TXjS7VAqQ@mail.gmail.com>
 <CAENiVe-6DfUx3ztwFrr08a5jc1BBQ9C7EaXLD71nG5NuC+TkWQ@mail.gmail.com>
Message-ID: <CAN=0SE=V+oX7O6kjZn4it8T8TobYfcNbvrv0Bq2dZanqwjJ2Mg@mail.gmail.com>

 Thank you, I have managed to get lsmeans to run using a slightly older
version of the package.

However, the problem with glmmTMB seems to be with the most up to date
version of lsmeans (which, as is noted, now now relies primarily on code in
the 'emmeans' package. 'lsmeans' will be archived in the near future).
emmeans is definitely *not *working with glmmTMB currently, even with the
like of code supplied by Ben Bolker:
source(system.file("other_methods","lsmeans_methods.R",package="glmmTMB").


On Fri, 9 Nov 2018 at 14:43, Guillaume Adeux <guillaumesimon.a2 at gmail.com>
wrote:

> Hi Aoibheann,
>
> I think that anova on glmmTMB objects only produce Wald tests, which don't
> seem to be very reliable.
> You might want to look at the monet package (or its little brother afex)
> that can produce LRT tests or parametric bootstrap.
>
> Moreover, emmeans should work fine with glmmTMB but I remember having a
> similar problem.
>
> Maybe this thread and the following discussion can help you out:
>
> https://stackoverflow.com/questions/48609432/error-message-lsmeans-for-beta-mixed-regression-model-with-glmmtmb
>
> GA2
>
>
>
> Le ven. 9 nov. 2018 ? 15:24, Aoibheann Gaughran <gaughra at tcd.ie> a ?crit :
>
>> Update: lsmeans works if I use an older version of lsmeans (2.27-62) - can
>> I rely on the results?
>>
>> Many thanks, Aoibheann
>>
>> On Fri, 9 Nov 2018 at 12:24, Aoibheann Gaughran <gaughra at tcd.ie> wrote:
>>
>> > Dear list,
>> >
>> > I am trying to perform post hoc tests on a glmmTMB model. I would
>> normally
>> > use car::Anova and mulgcomp::glht on my glmms (lmers). However, these
>> > functions do not appear to be working for glmmTMB (when I run the model
>> as
>> > an lmer they work fine). I have also tried lsmeans and emmeans but they
>> do
>> > not appear to support glmmTMB either (although it appears they used
>> to). I
>> > have found various treads online suggesting that these functions should
>> > work with TMB but they date back a few months.
>> >
>> > I am using the most up to date versions of R (3.5.1) and have updated
>> all
>> > of my packages e.g. glmmTMB 0.2.2.0, lsmeans 2.30-0
>> >
>> > The following are the error messages that I receive:
>> >
>> > > Anova(topmodTRFETE, type = 2)Error in I.p[c(subs.relatives,
>> subs.term), , drop = FALSE] :
>> >   subscript out of bound
>> >
>> > > summary(glht(topmodTRFETE, linfct = mcp(roadworks = "Tukey")), test =
>> adjusted("holm"))Error in modelparm.default(model, ...) :
>> >   dimensions of coefficients and covariance matrix don't match
>> > >
>> source(system.file("other_methods","lsmeans_methods.R",package="glmmTMB"))>
>> lsmeans(topmodTRFETE, pairwise ~ roadworks, adjustSigma = TRUE, adjust =
>> "holm")Error in ref_grid(object, ...) :
>> >   Can't handle an object of class  ?glmmTMB?
>> >  Use help("models", package = "emmeans") for information on supported
>> models.> rw.emm.s <- emmeans(topmodTRFETE, "roadworks")Error in
>> ref_grid(object, ...) :
>> >   Can't handle an object of class  ?glmmTMB?
>> >  Use help("models", package = "emmeans") for information on supported
>> models.
>> >
>> >
>> > Can any point me in the direction of a workaround for performing
>> posthocs
>> > on my glmmTMB model?
>> >
>> > Many thanks,
>> >
>> > --
>> > Aoibheann Gaughran
>> >
>> > Behavioural and Evolutionary Ecology Research Group
>> > Zoology Building
>> > School of Natural Sciences
>> > Trinity College Dublin
>> > Dublin 2
>> > Ireland
>> > Phone: +353 (86) 3812615
>> >
>>
>>
>> --
>> Aoibheann Gaughran
>>
>> Behavioural and Evolutionary Ecology Research Group
>> Zoology Building
>> School of Natural Sciences
>> Trinity College Dublin
>> Dublin 2
>> Ireland
>> Phone: +353 (86) 3812615
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

-- 
Aoibheann Gaughran

Behavioural and Evolutionary Ecology Research Group
Zoology Building
School of Natural Sciences
Trinity College Dublin
Dublin 2
Ireland
Phone: +353 (86) 3812615

	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Fri Nov  9 16:07:06 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Fri, 9 Nov 2018 10:07:06 -0500
Subject: [R-sig-ME] post hoc tests for glmmTMB
In-Reply-To: <CAENiVe-6DfUx3ztwFrr08a5jc1BBQ9C7EaXLD71nG5NuC+TkWQ@mail.gmail.com>
References: <CAN=0SEmQE6f=OAofUeSg_e2f-O2tnfUepqUSRO28onLw_dgh1w@mail.gmail.com>
 <CAN=0SEmLvC_X87qQgMmuBh_npb=g7WJ5acM78jX44TXjS7VAqQ@mail.gmail.com>
 <CAENiVe-6DfUx3ztwFrr08a5jc1BBQ9C7EaXLD71nG5NuC+TkWQ@mail.gmail.com>
Message-ID: <c4a50ee1-0f82-9764-3ac6-8b6740c80d9b@gmail.com>


  The point about Wald tests is correct, although their reliability
depends very much on context (they should be pretty good for tests of
fixed effects when the data set is reasonably large and predicted
probabilities/counts are not too extreme, i.e. not too close to zero
(counts) or 0/1 (probabilities)).

  There are a lot of improvements in the development version with
respect to post hoc tests etc. on glmmTMB fits, as documented here:
<https://github.com/glmmTMB/glmmTMB/blob/master/glmmTMB/vignettes/model_evaluation.rmd>

  If you can install the development version (see
https://github.com/glmmTMB/glmmTMB/blob/master/README.md), that should
help a lot.

 If you can't, most of these improvements will probably get to CRAN in
the next week or two; we're planning a new release soon.

  In any case, I think that running the following code should make
multcomp work with glmmTMB objects (not quite sure what that first
function is doing ... ???)

glht_glmmTMB <- function (model, ..., component="cond") {
    glht(model, ...,
         coef. = function(x) fixef(x)[[component]],
         vcov. = function(x) vcov(x)[[component]],
         df = NULL)
}
modelparm.glmmTMB <- function (model, coef. = function(x)
fixef(x)[[component]],
                               vcov. = function(x) vcov(x)[[component]],
                               df = NULL, component="cond", ...) {
    multcomp:::modelparm.default(model, coef. = coef., vcov. = vcov.,
                        df = df, ...)
}

## example
g1 <- glht(cbpp_b1, linfct = mcp(period = "Tukey"))



On 2018-11-09 9:42 a.m., Guillaume Adeux wrote:
> Hi Aoibheann,
> 
> I think that anova on glmmTMB objects only produce Wald tests, which don't
> seem to be very reliable.
> You might want to look at the monet package (or its little brother afex)
> that can produce LRT tests or parametric bootstrap.
> 
> Moreover, emmeans should work fine with glmmTMB but I remember having a
> similar problem.
> 
> Maybe this thread and the following discussion can help you out:
> https://stackoverflow.com/questions/48609432/error-message-lsmeans-for-beta-mixed-regression-model-with-glmmtmb
> 
> GA2
> 
> 
> 
> Le ven. 9 nov. 2018 ? 15:24, Aoibheann Gaughran <gaughra at tcd.ie> a ?crit :
> 
>> Update: lsmeans works if I use an older version of lsmeans (2.27-62) - can
>> I rely on the results?
>>
>> Many thanks, Aoibheann
>>
>> On Fri, 9 Nov 2018 at 12:24, Aoibheann Gaughran <gaughra at tcd.ie> wrote:
>>
>>> Dear list,
>>>
>>> I am trying to perform post hoc tests on a glmmTMB model. I would
>> normally
>>> use car::Anova and mulgcomp::glht on my glmms (lmers). However, these
>>> functions do not appear to be working for glmmTMB (when I run the model
>> as
>>> an lmer they work fine). I have also tried lsmeans and emmeans but they
>> do
>>> not appear to support glmmTMB either (although it appears they used to).
>> I
>>> have found various treads online suggesting that these functions should
>>> work with TMB but they date back a few months.
>>>
>>> I am using the most up to date versions of R (3.5.1) and have updated all
>>> of my packages e.g. glmmTMB 0.2.2.0, lsmeans 2.30-0
>>>
>>> The following are the error messages that I receive:
>>>
>>>> Anova(topmodTRFETE, type = 2)Error in I.p[c(subs.relatives,
>> subs.term), , drop = FALSE] :
>>>   subscript out of bound
>>>
>>>> summary(glht(topmodTRFETE, linfct = mcp(roadworks = "Tukey")), test =
>> adjusted("holm"))Error in modelparm.default(model, ...) :
>>>   dimensions of coefficients and covariance matrix don't match
>>>>
>> source(system.file("other_methods","lsmeans_methods.R",package="glmmTMB"))>
>> lsmeans(topmodTRFETE, pairwise ~ roadworks, adjustSigma = TRUE, adjust =
>> "holm")Error in ref_grid(object, ...) :
>>>   Can't handle an object of class  ?glmmTMB?
>>>  Use help("models", package = "emmeans") for information on supported
>> models.> rw.emm.s <- emmeans(topmodTRFETE, "roadworks")Error in
>> ref_grid(object, ...) :
>>>   Can't handle an object of class  ?glmmTMB?
>>>  Use help("models", package = "emmeans") for information on supported
>> models.
>>>
>>>
>>> Can any point me in the direction of a workaround for performing posthocs
>>> on my glmmTMB model?
>>>
>>> Many thanks,
>>>
>>> --
>>> Aoibheann Gaughran
>>>
>>> Behavioural and Evolutionary Ecology Research Group
>>> Zoology Building
>>> School of Natural Sciences
>>> Trinity College Dublin
>>> Dublin 2
>>> Ireland
>>> Phone: +353 (86) 3812615
>>>
>>
>>
>> --
>> Aoibheann Gaughran
>>
>> Behavioural and Evolutionary Ecology Research Group
>> Zoology Building
>> School of Natural Sciences
>> Trinity College Dublin
>> Dublin 2
>> Ireland
>> Phone: +353 (86) 3812615
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From g@ughr@ @ending from tcd@ie  Fri Nov  9 16:22:36 2018
From: g@ughr@ @ending from tcd@ie (Aoibheann Gaughran)
Date: Fri, 9 Nov 2018 15:22:36 +0000
Subject: [R-sig-ME] post hoc tests for glmmTMB
In-Reply-To: <c4a50ee1-0f82-9764-3ac6-8b6740c80d9b@gmail.com>
References: <CAN=0SEmQE6f=OAofUeSg_e2f-O2tnfUepqUSRO28onLw_dgh1w@mail.gmail.com>
 <CAN=0SEmLvC_X87qQgMmuBh_npb=g7WJ5acM78jX44TXjS7VAqQ@mail.gmail.com>
 <CAENiVe-6DfUx3ztwFrr08a5jc1BBQ9C7EaXLD71nG5NuC+TkWQ@mail.gmail.com>
 <c4a50ee1-0f82-9764-3ac6-8b6740c80d9b@gmail.com>
Message-ID: <CAN=0SEkjpT0gA1gBTb0vMDKGWktQQDdBfXJ5v7izBC-XmdHtXA@mail.gmail.com>

Great, thank you - I will keep plugging on. I will reconsider my use of the
Anova function in car as well!

On Fri, 9 Nov 2018 at 15:19, Ben Bolker <bbolker at gmail.com> wrote:

>
>   The point about Wald tests is correct, although their reliability
> depends very much on context (they should be pretty good for tests of
> fixed effects when the data set is reasonably large and predicted
> probabilities/counts are not too extreme, i.e. not too close to zero
> (counts) or 0/1 (probabilities)).
>
>   There are a lot of improvements in the development version with
> respect to post hoc tests etc. on glmmTMB fits, as documented here:
> <
> https://github.com/glmmTMB/glmmTMB/blob/master/glmmTMB/vignettes/model_evaluation.rmd
> >
>
>   If you can install the development version (see
> https://github.com/glmmTMB/glmmTMB/blob/master/README.md), that should
> help a lot.
>
>  If you can't, most of these improvements will probably get to CRAN in
> the next week or two; we're planning a new release soon.
>
>   In any case, I think that running the following code should make
> multcomp work with glmmTMB objects (not quite sure what that first
> function is doing ... ???)
>
> glht_glmmTMB <- function (model, ..., component="cond") {
>     glht(model, ...,
>          coef. = function(x) fixef(x)[[component]],
>          vcov. = function(x) vcov(x)[[component]],
>          df = NULL)
> }
> modelparm.glmmTMB <- function (model, coef. = function(x)
> fixef(x)[[component]],
>                                vcov. = function(x) vcov(x)[[component]],
>                                df = NULL, component="cond", ...) {
>     multcomp:::modelparm.default(model, coef. = coef., vcov. = vcov.,
>                         df = df, ...)
> }
>
> ## example
> g1 <- glht(cbpp_b1, linfct = mcp(period = "Tukey"))
>
>
>
> On 2018-11-09 9:42 a.m., Guillaume Adeux wrote:
> > Hi Aoibheann,
> >
> > I think that anova on glmmTMB objects only produce Wald tests, which
> don't
> > seem to be very reliable.
> > You might want to look at the monet package (or its little brother afex)
> > that can produce LRT tests or parametric bootstrap.
> >
> > Moreover, emmeans should work fine with glmmTMB but I remember having a
> > similar problem.
> >
> > Maybe this thread and the following discussion can help you out:
> >
> https://stackoverflow.com/questions/48609432/error-message-lsmeans-for-beta-mixed-regression-model-with-glmmtmb
> >
> > GA2
> >
> >
> >
> > Le ven. 9 nov. 2018 ? 15:24, Aoibheann Gaughran <gaughra at tcd.ie> a
> ?crit :
> >
> >> Update: lsmeans works if I use an older version of lsmeans (2.27-62) -
> can
> >> I rely on the results?
> >>
> >> Many thanks, Aoibheann
> >>
> >> On Fri, 9 Nov 2018 at 12:24, Aoibheann Gaughran <gaughra at tcd.ie> wrote:
> >>
> >>> Dear list,
> >>>
> >>> I am trying to perform post hoc tests on a glmmTMB model. I would
> >> normally
> >>> use car::Anova and mulgcomp::glht on my glmms (lmers). However, these
> >>> functions do not appear to be working for glmmTMB (when I run the model
> >> as
> >>> an lmer they work fine). I have also tried lsmeans and emmeans but they
> >> do
> >>> not appear to support glmmTMB either (although it appears they used
> to).
> >> I
> >>> have found various treads online suggesting that these functions should
> >>> work with TMB but they date back a few months.
> >>>
> >>> I am using the most up to date versions of R (3.5.1) and have updated
> all
> >>> of my packages e.g. glmmTMB 0.2.2.0, lsmeans 2.30-0
> >>>
> >>> The following are the error messages that I receive:
> >>>
> >>>> Anova(topmodTRFETE, type = 2)Error in I.p[c(subs.relatives,
> >> subs.term), , drop = FALSE] :
> >>>   subscript out of bound
> >>>
> >>>> summary(glht(topmodTRFETE, linfct = mcp(roadworks = "Tukey")), test =
> >> adjusted("holm"))Error in modelparm.default(model, ...) :
> >>>   dimensions of coefficients and covariance matrix don't match
> >>>>
> >>
> source(system.file("other_methods","lsmeans_methods.R",package="glmmTMB"))>
> >> lsmeans(topmodTRFETE, pairwise ~ roadworks, adjustSigma = TRUE, adjust =
> >> "holm")Error in ref_grid(object, ...) :
> >>>   Can't handle an object of class  ?glmmTMB?
> >>>  Use help("models", package = "emmeans") for information on supported
> >> models.> rw.emm.s <- emmeans(topmodTRFETE, "roadworks")Error in
> >> ref_grid(object, ...) :
> >>>   Can't handle an object of class  ?glmmTMB?
> >>>  Use help("models", package = "emmeans") for information on supported
> >> models.
> >>>
> >>>
> >>> Can any point me in the direction of a workaround for performing
> posthocs
> >>> on my glmmTMB model?
> >>>
> >>> Many thanks,
> >>>
> >>> --
> >>> Aoibheann Gaughran
> >>>
> >>> Behavioural and Evolutionary Ecology Research Group
> >>> Zoology Building
> >>> School of Natural Sciences
> >>> Trinity College Dublin
> >>> Dublin 2
> >>> Ireland
> >>> Phone: +353 (86) 3812615
> >>>
> >>
> >>
> >> --
> >> Aoibheann Gaughran
> >>
> >> Behavioural and Evolutionary Ecology Research Group
> >> Zoology Building
> >> School of Natural Sciences
> >> Trinity College Dublin
> >> Dublin 2
> >> Ireland
> >> Phone: +353 (86) 3812615
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
Aoibheann Gaughran

Behavioural and Evolutionary Ecology Research Group
Zoology Building
School of Natural Sciences
Trinity College Dublin
Dublin 2
Ireland
Phone: +353 (86) 3812615

	[[alternative HTML version deleted]]


From jfox @ending from mcm@@ter@c@  Fri Nov  9 16:37:43 2018
From: jfox @ending from mcm@@ter@c@ (Fox, John)
Date: Fri, 9 Nov 2018 15:37:43 +0000
Subject: [R-sig-ME] post hoc tests for glmmTMB
In-Reply-To: <7620_1541777002_wA9FNLap029918_CAN=0SEkjpT0gA1gBTb0vMDKGWktQQDdBfXJ5v7izBC-XmdHtXA@mail.gmail.com>
References: <CAN=0SEmQE6f=OAofUeSg_e2f-O2tnfUepqUSRO28onLw_dgh1w@mail.gmail.com>
 <CAN=0SEmLvC_X87qQgMmuBh_npb=g7WJ5acM78jX44TXjS7VAqQ@mail.gmail.com>
 <CAENiVe-6DfUx3ztwFrr08a5jc1BBQ9C7EaXLD71nG5NuC+TkWQ@mail.gmail.com>
 <c4a50ee1-0f82-9764-3ac6-8b6740c80d9b@gmail.com>
 <7620_1541777002_wA9FNLap029918_CAN=0SEkjpT0gA1gBTb0vMDKGWktQQDdBfXJ5v7izBC-XmdHtXA@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC83692F36D@FHSDB2D11-2.csu.mcmaster.ca>

Dear Aoibheann,

There is no specific Anova() method for "glmmTMB" objects, so the default method is invoked. This won't work because of the structure of "glmmTMB" models. I think that ideally one would want two tables of Wald tests of fixed effects, one for the conditional nonzero part of the model and one for the zero-inflation part of the model. 

This seems to me of sufficient interest that I'll look into writing "glmmTMB" methods for Anova() and for the linearHypothesis() function in the car package, on which Anova() depends. I can't promise, however, when I'll get to this.

Best,
 John

--------------------------------------
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: socialsciences.mcmaster.ca/jfox/



> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> project.org] On Behalf Of Aoibheann Gaughran
> Sent: Friday, November 9, 2018 10:23 AM
> To: Ben Bolker <bbolker at gmail.com>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] post hoc tests for glmmTMB
> 
> Great, thank you - I will keep plugging on. I will reconsider my use of
> the Anova function in car as well!
> 
> On Fri, 9 Nov 2018 at 15:19, Ben Bolker <bbolker at gmail.com> wrote:
> 
> >
> >   The point about Wald tests is correct, although their reliability
> > depends very much on context (they should be pretty good for tests of
> > fixed effects when the data set is reasonably large and predicted
> > probabilities/counts are not too extreme, i.e. not too close to zero
> > (counts) or 0/1 (probabilities)).
> >
> >   There are a lot of improvements in the development version with
> > respect to post hoc tests etc. on glmmTMB fits, as documented here:
> > <
> > https://github.com/glmmTMB/glmmTMB/blob/master/glmmTMB/vignettes/model
> > _evaluation.rmd
> > >
> >
> >   If you can install the development version (see
> > https://github.com/glmmTMB/glmmTMB/blob/master/README.md), that should
> > help a lot.
> >
> >  If you can't, most of these improvements will probably get to CRAN in
> > the next week or two; we're planning a new release soon.
> >
> >   In any case, I think that running the following code should make
> > multcomp work with glmmTMB objects (not quite sure what that first
> > function is doing ... ???)
> >
> > glht_glmmTMB <- function (model, ..., component="cond") {
> >     glht(model, ...,
> >          coef. = function(x) fixef(x)[[component]],
> >          vcov. = function(x) vcov(x)[[component]],
> >          df = NULL)
> > }
> > modelparm.glmmTMB <- function (model, coef. = function(x)
> > fixef(x)[[component]],
> >                                vcov. = function(x)
> vcov(x)[[component]],
> >                                df = NULL, component="cond", ...) {
> >     multcomp:::modelparm.default(model, coef. = coef., vcov. = vcov.,
> >                         df = df, ...)
> > }
> >
> > ## example
> > g1 <- glht(cbpp_b1, linfct = mcp(period = "Tukey"))
> >
> >
> >
> > On 2018-11-09 9:42 a.m., Guillaume Adeux wrote:
> > > Hi Aoibheann,
> > >
> > > I think that anova on glmmTMB objects only produce Wald tests, which
> > don't
> > > seem to be very reliable.
> > > You might want to look at the monet package (or its little brother
> > > afex) that can produce LRT tests or parametric bootstrap.
> > >
> > > Moreover, emmeans should work fine with glmmTMB but I remember
> > > having a similar problem.
> > >
> > > Maybe this thread and the following discussion can help you out:
> > >
> > https://stackoverflow.com/questions/48609432/error-message-lsmeans-for
> > -beta-mixed-regression-model-with-glmmtmb
> > >
> > > GA2
> > >
> > >
> > >
> > > Le ven. 9 nov. 2018 ? 15:24, Aoibheann Gaughran <gaughra at tcd.ie> a
> > ?crit :
> > >
> > >> Update: lsmeans works if I use an older version of lsmeans
> > >> (2.27-62) -
> > can
> > >> I rely on the results?
> > >>
> > >> Many thanks, Aoibheann
> > >>
> > >> On Fri, 9 Nov 2018 at 12:24, Aoibheann Gaughran <gaughra at tcd.ie>
> wrote:
> > >>
> > >>> Dear list,
> > >>>
> > >>> I am trying to perform post hoc tests on a glmmTMB model. I would
> > >> normally
> > >>> use car::Anova and mulgcomp::glht on my glmms (lmers). However,
> > >>> these functions do not appear to be working for glmmTMB (when I
> > >>> run the model
> > >> as
> > >>> an lmer they work fine). I have also tried lsmeans and emmeans but
> > >>> they
> > >> do
> > >>> not appear to support glmmTMB either (although it appears they
> > >>> used
> > to).
> > >> I
> > >>> have found various treads online suggesting that these functions
> > >>> should work with TMB but they date back a few months.
> > >>>
> > >>> I am using the most up to date versions of R (3.5.1) and have
> > >>> updated
> > all
> > >>> of my packages e.g. glmmTMB 0.2.2.0, lsmeans 2.30-0
> > >>>
> > >>> The following are the error messages that I receive:
> > >>>
> > >>>> Anova(topmodTRFETE, type = 2)Error in I.p[c(subs.relatives,
> > >> subs.term), , drop = FALSE] :
> > >>>   subscript out of bound
> > >>>
> > >>>> summary(glht(topmodTRFETE, linfct = mcp(roadworks = "Tukey")),
> > >>>> test =
> > >> adjusted("holm"))Error in modelparm.default(model, ...) :
> > >>>   dimensions of coefficients and covariance matrix don't match
> > >>>>
> > >>
> > source(system.file("other_methods","lsmeans_methods.R",package="glmmTM
> > B"))>
> > >> lsmeans(topmodTRFETE, pairwise ~ roadworks, adjustSigma = TRUE,
> > >> adjust = "holm")Error in ref_grid(object, ...) :
> > >>>   Can't handle an object of class  ?glmmTMB?
> > >>>  Use help("models", package = "emmeans") for information on
> > >>> supported
> > >> models.> rw.emm.s <- emmeans(topmodTRFETE, "roadworks")Error in
> > >> ref_grid(object, ...) :
> > >>>   Can't handle an object of class  ?glmmTMB?
> > >>>  Use help("models", package = "emmeans") for information on
> > >>> supported
> > >> models.
> > >>>
> > >>>
> > >>> Can any point me in the direction of a workaround for performing
> > posthocs
> > >>> on my glmmTMB model?
> > >>>
> > >>> Many thanks,
> > >>>
> > >>> --
> > >>> Aoibheann Gaughran
> > >>>
> > >>> Behavioural and Evolutionary Ecology Research Group Zoology
> > >>> Building School of Natural Sciences Trinity College Dublin Dublin
> > >>> 2 Ireland
> > >>> Phone: +353 (86) 3812615
> > >>>
> > >>
> > >>
> > >> --
> > >> Aoibheann Gaughran
> > >>
> > >> Behavioural and Evolutionary Ecology Research Group Zoology
> > >> Building School of Natural Sciences Trinity College Dublin Dublin 2
> > >> Ireland
> > >> Phone: +353 (86) 3812615
> > >>
> > >>         [[alternative HTML version deleted]]
> > >>
> > >> _______________________________________________
> > >> R-sig-mixed-models at r-project.org mailing list
> > >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >>
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> 
> 
> --
> Aoibheann Gaughran
> 
> Behavioural and Evolutionary Ecology Research Group Zoology Building
> School of Natural Sciences Trinity College Dublin Dublin 2 Ireland
> Phone: +353 (86) 3812615
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From bbolker @ending from gm@il@com  Fri Nov  9 16:27:57 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Fri, 9 Nov 2018 10:27:57 -0500
Subject: [R-sig-ME] post hoc tests for glmmTMB
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC83692F36D@FHSDB2D11-2.csu.mcmaster.ca>
References: <CAN=0SEmQE6f=OAofUeSg_e2f-O2tnfUepqUSRO28onLw_dgh1w@mail.gmail.com>
 <CAN=0SEmLvC_X87qQgMmuBh_npb=g7WJ5acM78jX44TXjS7VAqQ@mail.gmail.com>
 <CAENiVe-6DfUx3ztwFrr08a5jc1BBQ9C7EaXLD71nG5NuC+TkWQ@mail.gmail.com>
 <c4a50ee1-0f82-9764-3ac6-8b6740c80d9b@gmail.com>
 <7620_1541777002_wA9FNLap029918_CAN=0SEkjpT0gA1gBTb0vMDKGWktQQDdBfXJ5v7izBC-XmdHtXA@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC83692F36D@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <beea4584-61d8-fe96-f831-ea2788f802ab@gmail.com>


  The devel version of glmmTMB contains Anova methods for glmmTMB :

https://github.com/glmmTMB/glmmTMB/blob/master/glmmTMB/R/Anova.R

 cheers
  Ben

On 2018-11-09 10:37 a.m., Fox, John wrote:
> Dear Aoibheann,
> 
> There is no specific Anova() method for "glmmTMB" objects, so the default method is invoked. This won't work because of the structure of "glmmTMB" models. I think that ideally one would want two tables of Wald tests of fixed effects, one for the conditional nonzero part of the model and one for the zero-inflation part of the model. 
> 
> This seems to me of sufficient interest that I'll look into writing "glmmTMB" methods for Anova() and for the linearHypothesis() function in the car package, on which Anova() depends. I can't promise, however, when I'll get to this.
> 
> Best,
>  John
> 
> --------------------------------------
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> Web: socialsciences.mcmaster.ca/jfox/
> 
> 
> 
>> -----Original Message-----
>> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
>> project.org] On Behalf Of Aoibheann Gaughran
>> Sent: Friday, November 9, 2018 10:23 AM
>> To: Ben Bolker <bbolker at gmail.com>
>> Cc: r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] post hoc tests for glmmTMB
>>
>> Great, thank you - I will keep plugging on. I will reconsider my use of
>> the Anova function in car as well!
>>
>> On Fri, 9 Nov 2018 at 15:19, Ben Bolker <bbolker at gmail.com> wrote:
>>
>>>
>>>   The point about Wald tests is correct, although their reliability
>>> depends very much on context (they should be pretty good for tests of
>>> fixed effects when the data set is reasonably large and predicted
>>> probabilities/counts are not too extreme, i.e. not too close to zero
>>> (counts) or 0/1 (probabilities)).
>>>
>>>   There are a lot of improvements in the development version with
>>> respect to post hoc tests etc. on glmmTMB fits, as documented here:
>>> <
>>> https://github.com/glmmTMB/glmmTMB/blob/master/glmmTMB/vignettes/model
>>> _evaluation.rmd
>>>>
>>>
>>>   If you can install the development version (see
>>> https://github.com/glmmTMB/glmmTMB/blob/master/README.md), that should
>>> help a lot.
>>>
>>>  If you can't, most of these improvements will probably get to CRAN in
>>> the next week or two; we're planning a new release soon.
>>>
>>>   In any case, I think that running the following code should make
>>> multcomp work with glmmTMB objects (not quite sure what that first
>>> function is doing ... ???)
>>>
>>> glht_glmmTMB <- function (model, ..., component="cond") {
>>>     glht(model, ...,
>>>          coef. = function(x) fixef(x)[[component]],
>>>          vcov. = function(x) vcov(x)[[component]],
>>>          df = NULL)
>>> }
>>> modelparm.glmmTMB <- function (model, coef. = function(x)
>>> fixef(x)[[component]],
>>>                                vcov. = function(x)
>> vcov(x)[[component]],
>>>                                df = NULL, component="cond", ...) {
>>>     multcomp:::modelparm.default(model, coef. = coef., vcov. = vcov.,
>>>                         df = df, ...)
>>> }
>>>
>>> ## example
>>> g1 <- glht(cbpp_b1, linfct = mcp(period = "Tukey"))
>>>
>>>
>>>
>>> On 2018-11-09 9:42 a.m., Guillaume Adeux wrote:
>>>> Hi Aoibheann,
>>>>
>>>> I think that anova on glmmTMB objects only produce Wald tests, which
>>> don't
>>>> seem to be very reliable.
>>>> You might want to look at the monet package (or its little brother
>>>> afex) that can produce LRT tests or parametric bootstrap.
>>>>
>>>> Moreover, emmeans should work fine with glmmTMB but I remember
>>>> having a similar problem.
>>>>
>>>> Maybe this thread and the following discussion can help you out:
>>>>
>>> https://stackoverflow.com/questions/48609432/error-message-lsmeans-for
>>> -beta-mixed-regression-model-with-glmmtmb
>>>>
>>>> GA2
>>>>
>>>>
>>>>
>>>> Le ven. 9 nov. 2018 ? 15:24, Aoibheann Gaughran <gaughra at tcd.ie> a
>>> ?crit :
>>>>
>>>>> Update: lsmeans works if I use an older version of lsmeans
>>>>> (2.27-62) -
>>> can
>>>>> I rely on the results?
>>>>>
>>>>> Many thanks, Aoibheann
>>>>>
>>>>> On Fri, 9 Nov 2018 at 12:24, Aoibheann Gaughran <gaughra at tcd.ie>
>> wrote:
>>>>>
>>>>>> Dear list,
>>>>>>
>>>>>> I am trying to perform post hoc tests on a glmmTMB model. I would
>>>>> normally
>>>>>> use car::Anova and mulgcomp::glht on my glmms (lmers). However,
>>>>>> these functions do not appear to be working for glmmTMB (when I
>>>>>> run the model
>>>>> as
>>>>>> an lmer they work fine). I have also tried lsmeans and emmeans but
>>>>>> they
>>>>> do
>>>>>> not appear to support glmmTMB either (although it appears they
>>>>>> used
>>> to).
>>>>> I
>>>>>> have found various treads online suggesting that these functions
>>>>>> should work with TMB but they date back a few months.
>>>>>>
>>>>>> I am using the most up to date versions of R (3.5.1) and have
>>>>>> updated
>>> all
>>>>>> of my packages e.g. glmmTMB 0.2.2.0, lsmeans 2.30-0
>>>>>>
>>>>>> The following are the error messages that I receive:
>>>>>>
>>>>>>> Anova(topmodTRFETE, type = 2)Error in I.p[c(subs.relatives,
>>>>> subs.term), , drop = FALSE] :
>>>>>>   subscript out of bound
>>>>>>
>>>>>>> summary(glht(topmodTRFETE, linfct = mcp(roadworks = "Tukey")),
>>>>>>> test =
>>>>> adjusted("holm"))Error in modelparm.default(model, ...) :
>>>>>>   dimensions of coefficients and covariance matrix don't match
>>>>>>>
>>>>>
>>> source(system.file("other_methods","lsmeans_methods.R",package="glmmTM
>>> B"))>
>>>>> lsmeans(topmodTRFETE, pairwise ~ roadworks, adjustSigma = TRUE,
>>>>> adjust = "holm")Error in ref_grid(object, ...) :
>>>>>>   Can't handle an object of class  ?glmmTMB?
>>>>>>  Use help("models", package = "emmeans") for information on
>>>>>> supported
>>>>> models.> rw.emm.s <- emmeans(topmodTRFETE, "roadworks")Error in
>>>>> ref_grid(object, ...) :
>>>>>>   Can't handle an object of class  ?glmmTMB?
>>>>>>  Use help("models", package = "emmeans") for information on
>>>>>> supported
>>>>> models.
>>>>>>
>>>>>>
>>>>>> Can any point me in the direction of a workaround for performing
>>> posthocs
>>>>>> on my glmmTMB model?
>>>>>>
>>>>>> Many thanks,
>>>>>>
>>>>>> --
>>>>>> Aoibheann Gaughran
>>>>>>
>>>>>> Behavioural and Evolutionary Ecology Research Group Zoology
>>>>>> Building School of Natural Sciences Trinity College Dublin Dublin
>>>>>> 2 Ireland
>>>>>> Phone: +353 (86) 3812615
>>>>>>
>>>>>
>>>>>
>>>>> --
>>>>> Aoibheann Gaughran
>>>>>
>>>>> Behavioural and Evolutionary Ecology Research Group Zoology
>>>>> Building School of Natural Sciences Trinity College Dublin Dublin 2
>>>>> Ireland
>>>>> Phone: +353 (86) 3812615
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>
>>>>       [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>> --
>> Aoibheann Gaughran
>>
>> Behavioural and Evolutionary Ecology Research Group Zoology Building
>> School of Natural Sciences Trinity College Dublin Dublin 2 Ireland
>> Phone: +353 (86) 3812615
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From ru@@ell-lenth @ending from uiow@@edu  Fri Nov  9 17:21:40 2018
From: ru@@ell-lenth @ending from uiow@@edu (Lenth, Russell V)
Date: Fri, 9 Nov 2018 16:21:40 +0000
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 143, Issue 12
In-Reply-To: <mailman.17038.7964.1541776105.1179.r-sig-mixed-models@r-project.org>
References: <mailman.17038.7964.1541776105.1179.r-sig-mixed-models@r-project.org>
Message-ID: <DM6PR04MB4380BC14CA9230A79D8A4142F1C60@DM6PR04MB4380.namprd04.prod.outlook.com>

I screwed up -- in a kind of brown-paper-bag way...

I think it may work with emmeans if you do this:

    recover.data <- function(object, ...) UseMethod("recover.data")
    lsm.basis <- function(object, ...) UseMethod("lsm.basis")
    recover.data.default <- function(object, ...) emmeans::recover_data(object, ...)
    lsm.basis.default <- function(object, ...) emmeans::emm_basis(object, ...)

Hope this helps.

Russ Lenth

Russell V. Lenth? -? Professor Emeritus
Department of Statistics and Actuarial Science?? 
The University of Iowa ?-? Iowa City, IA 52242? USA?? 
Voice (319)335-0712 (Dept. office)? -? FAX (319)335-3017



-----Original Message-----

Message: 1
Date: Fri, 9 Nov 2018 12:24:47 +0000
From: Aoibheann Gaughran <gaughra at tcd.ie>
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] post hoc tests for glmmTMB
Message-ID:
	<CAN=0SEmQE6f=OAofUeSg_e2f-O2tnfUepqUSRO28onLw_dgh1w at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

Dear list,

I am trying to perform post hoc tests on a glmmTMB model. I would normally use car::Anova and mulgcomp::glht on my glmms (lmers). However, these functions do not appear to be working for glmmTMB (when I run the model as an lmer they work fine). I have also tried lsmeans and emmeans but they do not appear to support glmmTMB either (although it appears they used to). I have found various treads online suggesting that these functions should work with TMB but they date back a few months.

I am using the most up to date versions of R (3.5.1) and have updated all of my packages e.g. glmmTMB 0.2.2.0, lsmeans 2.30-0

The following are the error messages that I receive:

> Anova(topmodTRFETE, type = 2)Error in I.p[c(subs.relatives, subs.term), , drop = FALSE] :
  subscript out of bound

> summary(glht(topmodTRFETE, linfct = mcp(roadworks = "Tukey")), test = adjusted("holm"))Error in modelparm.default(model, ...) :
  dimensions of coefficients and covariance matrix don't match
> source(system.file("other_methods","lsmeans_methods.R",package="glmmTMB"))> lsmeans(topmodTRFETE, pairwise ~ roadworks, adjustSigma = TRUE, adjust = "holm")Error in ref_grid(object, ...) :
  Can't handle an object of class  ?glmmTMB?
 Use help("models", package = "emmeans") for information on supported models.> rw.emm.s <- emmeans(topmodTRFETE, "roadworks")Error in ref_grid(object, ...) :
  Can't handle an object of class  ?glmmTMB?
 Use help("models", package = "emmeans") for information on supported models.


Can any point me in the direction of a workaround for performing posthocs on my glmmTMB model?

Many thanks,

--
Aoibheann Gaughran

Behavioural and Evolutionary Ecology Research Group Zoology Building School of Natural Sciences Trinity College Dublin Dublin 2 Ireland
Phone: +353 (86) 3812615


From jfox @ending from mcm@@ter@c@  Fri Nov  9 17:32:24 2018
From: jfox @ending from mcm@@ter@c@ (Fox, John)
Date: Fri, 9 Nov 2018 16:32:24 +0000
Subject: [R-sig-ME] post hoc tests for glmmTMB
In-Reply-To: <beea4584-61d8-fe96-f831-ea2788f802ab@gmail.com>
References: <CAN=0SEmQE6f=OAofUeSg_e2f-O2tnfUepqUSRO28onLw_dgh1w@mail.gmail.com>
 <CAN=0SEmLvC_X87qQgMmuBh_npb=g7WJ5acM78jX44TXjS7VAqQ@mail.gmail.com>
 <CAENiVe-6DfUx3ztwFrr08a5jc1BBQ9C7EaXLD71nG5NuC+TkWQ@mail.gmail.com>
 <c4a50ee1-0f82-9764-3ac6-8b6740c80d9b@gmail.com>
 <7620_1541777002_wA9FNLap029918_CAN=0SEkjpT0gA1gBTb0vMDKGWktQQDdBfXJ5v7izBC-XmdHtXA@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC83692F36D@FHSDB2D11-2.csu.mcmaster.ca>
 <beea4584-61d8-fe96-f831-ea2788f802ab@gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC83692F50D@FHSDB2D11-2.csu.mcmaster.ca>

Hi Ben,

My apologies if you told me about this before and I forgot (because it does ring a bell).

I've taken a look at what you did and have some questions/comments: 

(1) I see that you have a component argument to determine what to test -- the conditional part of the model, the zero-inflated part, or the dispersion part. I'd allow multiple choices, like component=c("cond", "zi"), and consider making c("cond", "zi") the default. It should be easy to do this via a recursive call.

(2) I also see that you don't export a linearHypothesis.glmmTMB() method. I think that's a pity since it would be useful and shouldn't involve much more work.

Best,
 John

--------------------------------------
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: socialsciences.mcmaster.ca/jfox/




> -----Original Message-----
> From: Ben Bolker [mailto:bbolker at gmail.com]
> Sent: Friday, November 9, 2018 10:28 AM
> To: Fox, John <jfox at mcmaster.ca>; Aoibheann Gaughran <gaughra at tcd.ie>
> Cc: r-sig-mixed-models at r-project.org; Sandy Weisberg <sandy at umn.edu>;
> Brad Price (brad.price at mail.wvu.edu) <brad.price at mail.wvu.edu>
> Subject: Re: [R-sig-ME] post hoc tests for glmmTMB
> 
> 
>   The devel version of glmmTMB contains Anova methods for glmmTMB :
> 
> https://github.com/glmmTMB/glmmTMB/blob/master/glmmTMB/R/Anova.R
> 
>  cheers
>   Ben
> 
> On 2018-11-09 10:37 a.m., Fox, John wrote:
> > Dear Aoibheann,
> >
> > There is no specific Anova() method for "glmmTMB" objects, so the
> default method is invoked. This won't work because of the structure of
> "glmmTMB" models. I think that ideally one would want two tables of Wald
> tests of fixed effects, one for the conditional nonzero part of the
> model and one for the zero-inflation part of the model.
> >
> > This seems to me of sufficient interest that I'll look into writing
> "glmmTMB" methods for Anova() and for the linearHypothesis() function in
> the car package, on which Anova() depends. I can't promise, however,
> when I'll get to this.
> >
> > Best,
> >  John
> >
> > --------------------------------------
> > John Fox, Professor Emeritus
> > McMaster University
> > Hamilton, Ontario, Canada
> > Web: socialsciences.mcmaster.ca/jfox/
> >
> >
> >
> >> -----Original Message-----
> >> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> >> project.org] On Behalf Of Aoibheann Gaughran
> >> Sent: Friday, November 9, 2018 10:23 AM
> >> To: Ben Bolker <bbolker at gmail.com>
> >> Cc: r-sig-mixed-models at r-project.org
> >> Subject: Re: [R-sig-ME] post hoc tests for glmmTMB
> >>
> >> Great, thank you - I will keep plugging on. I will reconsider my use
> >> of the Anova function in car as well!
> >>
> >> On Fri, 9 Nov 2018 at 15:19, Ben Bolker <bbolker at gmail.com> wrote:
> >>
> >>>
> >>>   The point about Wald tests is correct, although their reliability
> >>> depends very much on context (they should be pretty good for tests
> >>> of fixed effects when the data set is reasonably large and predicted
> >>> probabilities/counts are not too extreme, i.e. not too close to zero
> >>> (counts) or 0/1 (probabilities)).
> >>>
> >>>   There are a lot of improvements in the development version with
> >>> respect to post hoc tests etc. on glmmTMB fits, as documented here:
> >>> <
> >>> https://github.com/glmmTMB/glmmTMB/blob/master/glmmTMB/vignettes/mod
> >>> el
> >>> _evaluation.rmd
> >>>>
> >>>
> >>>   If you can install the development version (see
> >>> https://github.com/glmmTMB/glmmTMB/blob/master/README.md), that
> >>> should help a lot.
> >>>
> >>>  If you can't, most of these improvements will probably get to CRAN
> >>> in the next week or two; we're planning a new release soon.
> >>>
> >>>   In any case, I think that running the following code should make
> >>> multcomp work with glmmTMB objects (not quite sure what that first
> >>> function is doing ... ???)
> >>>
> >>> glht_glmmTMB <- function (model, ..., component="cond") {
> >>>     glht(model, ...,
> >>>          coef. = function(x) fixef(x)[[component]],
> >>>          vcov. = function(x) vcov(x)[[component]],
> >>>          df = NULL)
> >>> }
> >>> modelparm.glmmTMB <- function (model, coef. = function(x)
> >>> fixef(x)[[component]],
> >>>                                vcov. = function(x)
> >> vcov(x)[[component]],
> >>>                                df = NULL, component="cond", ...) {
> >>>     multcomp:::modelparm.default(model, coef. = coef., vcov. =
> vcov.,
> >>>                         df = df, ...) }
> >>>
> >>> ## example
> >>> g1 <- glht(cbpp_b1, linfct = mcp(period = "Tukey"))
> >>>
> >>>
> >>>
> >>> On 2018-11-09 9:42 a.m., Guillaume Adeux wrote:
> >>>> Hi Aoibheann,
> >>>>
> >>>> I think that anova on glmmTMB objects only produce Wald tests,
> >>>> which
> >>> don't
> >>>> seem to be very reliable.
> >>>> You might want to look at the monet package (or its little brother
> >>>> afex) that can produce LRT tests or parametric bootstrap.
> >>>>
> >>>> Moreover, emmeans should work fine with glmmTMB but I remember
> >>>> having a similar problem.
> >>>>
> >>>> Maybe this thread and the following discussion can help you out:
> >>>>
> >>> https://stackoverflow.com/questions/48609432/error-message-lsmeans-f
> >>> or -beta-mixed-regression-model-with-glmmtmb
> >>>>
> >>>> GA2
> >>>>
> >>>>
> >>>>
> >>>> Le ven. 9 nov. 2018 ? 15:24, Aoibheann Gaughran <gaughra at tcd.ie> a
> >>> ?crit :
> >>>>
> >>>>> Update: lsmeans works if I use an older version of lsmeans
> >>>>> (2.27-62) -
> >>> can
> >>>>> I rely on the results?
> >>>>>
> >>>>> Many thanks, Aoibheann
> >>>>>
> >>>>> On Fri, 9 Nov 2018 at 12:24, Aoibheann Gaughran <gaughra at tcd.ie>
> >> wrote:
> >>>>>
> >>>>>> Dear list,
> >>>>>>
> >>>>>> I am trying to perform post hoc tests on a glmmTMB model. I would
> >>>>> normally
> >>>>>> use car::Anova and mulgcomp::glht on my glmms (lmers). However,
> >>>>>> these functions do not appear to be working for glmmTMB (when I
> >>>>>> run the model
> >>>>> as
> >>>>>> an lmer they work fine). I have also tried lsmeans and emmeans
> >>>>>> but they
> >>>>> do
> >>>>>> not appear to support glmmTMB either (although it appears they
> >>>>>> used
> >>> to).
> >>>>> I
> >>>>>> have found various treads online suggesting that these functions
> >>>>>> should work with TMB but they date back a few months.
> >>>>>>
> >>>>>> I am using the most up to date versions of R (3.5.1) and have
> >>>>>> updated
> >>> all
> >>>>>> of my packages e.g. glmmTMB 0.2.2.0, lsmeans 2.30-0
> >>>>>>
> >>>>>> The following are the error messages that I receive:
> >>>>>>
> >>>>>>> Anova(topmodTRFETE, type = 2)Error in I.p[c(subs.relatives,
> >>>>> subs.term), , drop = FALSE] :
> >>>>>>   subscript out of bound
> >>>>>>
> >>>>>>> summary(glht(topmodTRFETE, linfct = mcp(roadworks = "Tukey")),
> >>>>>>> test =
> >>>>> adjusted("holm"))Error in modelparm.default(model, ...) :
> >>>>>>   dimensions of coefficients and covariance matrix don't match
> >>>>>>>
> >>>>>
> >>> source(system.file("other_methods","lsmeans_methods.R",package="glmm
> >>> TM
> >>> B"))>
> >>>>> lsmeans(topmodTRFETE, pairwise ~ roadworks, adjustSigma = TRUE,
> >>>>> adjust = "holm")Error in ref_grid(object, ...) :
> >>>>>>   Can't handle an object of class  ?glmmTMB?
> >>>>>>  Use help("models", package = "emmeans") for information on
> >>>>>> supported
> >>>>> models.> rw.emm.s <- emmeans(topmodTRFETE, "roadworks")Error in
> >>>>> ref_grid(object, ...) :
> >>>>>>   Can't handle an object of class  ?glmmTMB?
> >>>>>>  Use help("models", package = "emmeans") for information on
> >>>>>> supported
> >>>>> models.
> >>>>>>
> >>>>>>
> >>>>>> Can any point me in the direction of a workaround for performing
> >>> posthocs
> >>>>>> on my glmmTMB model?
> >>>>>>
> >>>>>> Many thanks,
> >>>>>>
> >>>>>> --
> >>>>>> Aoibheann Gaughran
> >>>>>>
> >>>>>> Behavioural and Evolutionary Ecology Research Group Zoology
> >>>>>> Building School of Natural Sciences Trinity College Dublin Dublin
> >>>>>> 2 Ireland
> >>>>>> Phone: +353 (86) 3812615
> >>>>>>
> >>>>>
> >>>>>
> >>>>> --
> >>>>> Aoibheann Gaughran
> >>>>>
> >>>>> Behavioural and Evolutionary Ecology Research Group Zoology
> >>>>> Building School of Natural Sciences Trinity College Dublin Dublin
> >>>>> 2 Ireland
> >>>>> Phone: +353 (86) 3812615
> >>>>>
> >>>>>         [[alternative HTML version deleted]]
> >>>>>
> >>>>> _______________________________________________
> >>>>> R-sig-mixed-models at r-project.org mailing list
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>>
> >>>>
> >>>>       [[alternative HTML version deleted]]
> >>>>
> >>>> _______________________________________________
> >>>> R-sig-mixed-models at r-project.org mailing list
> >>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>
> >>
> >>
> >> --
> >> Aoibheann Gaughran
> >>
> >> Behavioural and Evolutionary Ecology Research Group Zoology Building
> >> School of Natural Sciences Trinity College Dublin Dublin 2 Ireland
> >> Phone: +353 (86) 3812615
> >>
> >> 	[[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From ru@@ell-lenth @ending from uiow@@edu  Fri Nov  9 21:46:02 2018
From: ru@@ell-lenth @ending from uiow@@edu (Lenth, Russell V)
Date: Fri, 9 Nov 2018 20:46:02 +0000
Subject: [R-sig-ME] post hoc tests for glmmTMB
Message-ID: <DM6PR04MB43808C053FD49A1CEB13AA93F1C60@DM6PR04MB4380.namprd04.prod.outlook.com>

With emmeans/lsmeans, it turns out the mistake was in sourcing that obsolete lsmeans-methods.R code. Please  erase all functions in your workspace that begin with "recover.data" or "lsm.basis" -- then you can obtain EMMs without problems, because emmeans support is built-in to the cirrent glmmTMB package. For example:

    require(glmmTMB)
    require(emmeans)

    example("glmmTMB")
    # ... quite a few lines excluded here

    emmeans(m2, "spp")
#   spp        emmean        SE  df   lower.CL  upper.CL
#    GP     0.10429796 0.2629172 626 -0.4120086 0.6206045
#    PR    -0.85940395 0.6723753 626 -2.1797882 0.4609803
#    DM     0.27498137 0.2456147 626 -0.2073472 0.7573099
#    EC-A  -0.28275838 0.3610020 626 -0.9916800 0.4261633
#    EC-L   0.59224612 0.2581265 626  0.0853474 1.0991448
#    DES-L  0.69378481 0.2410053 626  0.2205080 1.1670616
#    DF    -0.00896838 0.2496003 626 -0.4991237 0.4811869

Russ

-----Original Message-----
From: Lenth, Russell V 
Sent: Friday, November 9, 2018 10:22 AM
To: r-sig-mixed-models at r-project.org; 'Aoibheann Gaughran' <gaughra at tcd.ie>
Subject: RE: R-sig-mixed-models Digest, Vol 143, Issue 12

I screwed up -- in a kind of brown-paper-bag way...

I think it may work with emmeans if you do this:

    recover.data <- function(object, ...) UseMethod("recover.data")
    lsm.basis <- function(object, ...) UseMethod("lsm.basis")
    recover.data.default <- function(object, ...) emmeans::recover_data(object, ...)
    lsm.basis.default <- function(object, ...) emmeans::emm_basis(object, ...)

Hope this helps.

Russ Lenth

Russell V. Lenth? -? Professor Emeritus
Department of Statistics and Actuarial Science The University of Iowa ?-? Iowa City, IA 52242? USA Voice (319)335-0712 (Dept. office)? -? FAX (319)335-3017



-----Original Message-----

Message: 1
Date: Fri, 9 Nov 2018 12:24:47 +0000
From: Aoibheann Gaughran <gaughra at tcd.ie>
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] post hoc tests for glmmTMB
Message-ID:
	<CAN=0SEmQE6f=OAofUeSg_e2f-O2tnfUepqUSRO28onLw_dgh1w at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

Dear list,

I am trying to perform post hoc tests on a glmmTMB model. I would normally use car::Anova and mulgcomp::glht on my glmms (lmers). However, these functions do not appear to be working for glmmTMB (when I run the model as an lmer they work fine). I have also tried lsmeans and emmeans but they do not appear to support glmmTMB either (although it appears they used to). I have found various treads online suggesting that these functions should work with TMB but they date back a few months.

I am using the most up to date versions of R (3.5.1) and have updated all of my packages e.g. glmmTMB 0.2.2.0, lsmeans 2.30-0

The following are the error messages that I receive:

> Anova(topmodTRFETE, type = 2)Error in I.p[c(subs.relatives, subs.term), , drop = FALSE] :
  subscript out of bound

> summary(glht(topmodTRFETE, linfct = mcp(roadworks = "Tukey")), test = adjusted("holm"))Error in modelparm.default(model, ...) :
  dimensions of coefficients and covariance matrix don't match
> source(system.file("other_methods","lsmeans_methods.R",package="glmmTMB"))> lsmeans(topmodTRFETE, pairwise ~ roadworks, adjustSigma = TRUE, adjust = "holm")Error in ref_grid(object, ...) :
  Can't handle an object of class  ?glmmTMB?
 Use help("models", package = "emmeans") for information on supported models.> rw.emm.s <- emmeans(topmodTRFETE, "roadworks")Error in ref_grid(object, ...) :
  Can't handle an object of class  ?glmmTMB?
 Use help("models", package = "emmeans") for information on supported models.


Can any point me in the direction of a workaround for performing posthocs on my glmmTMB model?

Many thanks,

--
Aoibheann Gaughran

Behavioural and Evolutionary Ecology Research Group Zoology Building School of Natural Sciences Trinity College Dublin Dublin 2 Ireland
Phone: +353 (86) 3812615


From jwmille7 @ending from nc@u@edu  Fri Nov  9 22:15:53 2018
From: jwmille7 @ending from nc@u@edu (Jonathan Miller)
Date: Fri, 9 Nov 2018 16:15:53 -0500
Subject: [R-sig-ME] Running
Message-ID: <CAGomFPWyCegZpTbpNLVNn100wHm=RFLq_Uw8p-B0gqkjxurqVA@mail.gmail.com>

Dr. Bolker,

I am a Phd student at NCSU and struggling with a coding issue. I am
bootstrapping some glmm model predictions in order to determine the
uncertainty associated with their fixed effects.  I read your comments on
https://github.com/lme4/lme4/issues/388 and have used a code similar to
yours below (b3):

## param, RE, and conditional
b1 <- bootMer(fm1,FUN=sfun1,nsim=100,seed=101)
## param and RE (no conditional)
b2 <- bootMer(fm1,FUN=sfun2,nsim=100,seed=101)
## param only
b3 <- bootMer(fm1,FUN=function(x) predict(x,newdata=test,re.form=~0),
              ## re.form=~0 is equivalent to use.u=FALSE
              nsim=100,seed=101)


It has worked well for me but takes an extremely long time to run. I am
predicting 6 different wq indicators for 1,423 sites and the datasets range
in size from 3,000 to 25,000 entries each.  The small one is relatively
runs relatively ok, but the others are extremely slow. In my code (below),
I also want to make more than one prediction (current conditions, possible
future conditions) using the bootstrapping. Using "snow" in parallel
doesn't seem to speed things up.  I thought of two possibilities, but am
unsure how to implement them.

for (s in 1:1423){

bi <- bootMer(BI.mod,FUN=function(x)
predict(x,newdata=pred.sites[s,],re.form=~0,REML=TRUE),
              parallel="snow",nsim=1000,seed=101)
bi.5 <- bootMer(BI.mod,FUN=function(x)
predict(x,newdata=pred.sites.m5[s,],re.form=~0,REML=TRUE),
              parallel="snow",nsim=1000,seed=101)
}

1) Can I predict the bootstrapped model using two different datasets at
once to speed things up (i.e., pred.sites and pred.sites.m5)?
2) Can I use parallel processing of the initial loop (1,423 sites) outside
of bootmer (perhaps with doParallel and foreach) and then run bootmer
within that loop?  Though I have used foreach before, I find it hard to
compile the data that I really want on the backend.

Thank you for your time and any suggestions you might have.

Sincerely,

Jonathan

	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Fri Nov  9 23:17:22 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Fri, 9 Nov 2018 17:17:22 -0500
Subject: [R-sig-ME] Running
In-Reply-To: <CAGomFPWyCegZpTbpNLVNn100wHm=RFLq_Uw8p-B0gqkjxurqVA@mail.gmail.com>
References: <CAGomFPWyCegZpTbpNLVNn100wHm=RFLq_Uw8p-B0gqkjxurqVA@mail.gmail.com>
Message-ID: <6d44272f-a303-6467-3d4f-37962a0f5eec@gmail.com>


  I will give this some thought when I get a chance (hopefully someone
else will give it some thought and find some answers sooner ...)  In the
meantime -- do you really need parametric bootstrapping/bootMer to get
the confidence intervals you want?  It's quite possible that a simpler
approximation (e.g. assuming that the variation caused by uncertainty in
the top-level random-effects parameters is small relative to other
sources of variability) is adequate, given that you have thousands of
samples ...

On 2018-11-09 4:15 p.m., Jonathan Miller wrote:
> Dr. Bolker,
> 
> I am a Phd student at NCSU and struggling with a coding issue. I am
> bootstrapping some glmm model predictions in order to determine the
> uncertainty associated with their fixed effects.  I read your comments on
> https://github.com/lme4/lme4/issues/388 and have used a code similar to
> yours below (b3):
> 
> ## param, RE, and conditional
> b1 <- bootMer(fm1,FUN=sfun1,nsim=100,seed=101)
> ## param and RE (no conditional)
> b2 <- bootMer(fm1,FUN=sfun2,nsim=100,seed=101)
> ## param only
> b3 <- bootMer(fm1,FUN=function(x) predict(x,newdata=test,re.form=~0),
>               ## re.form=~0 is equivalent to use.u=FALSE
>               nsim=100,seed=101)
> 
> 
> It has worked well for me but takes an extremely long time to run. I am
> predicting 6 different wq indicators for 1,423 sites and the datasets range
> in size from 3,000 to 25,000 entries each.  The small one is relatively
> runs relatively ok, but the others are extremely slow. In my code (below),
> I also want to make more than one prediction (current conditions, possible
> future conditions) using the bootstrapping. Using "snow" in parallel
> doesn't seem to speed things up.  I thought of two possibilities, but am
> unsure how to implement them.
> 
> for (s in 1:1423){
> 
> bi <- bootMer(BI.mod,FUN=function(x)
> predict(x,newdata=pred.sites[s,],re.form=~0,REML=TRUE),
>               parallel="snow",nsim=1000,seed=101)
> bi.5 <- bootMer(BI.mod,FUN=function(x)
> predict(x,newdata=pred.sites.m5[s,],re.form=~0,REML=TRUE),
>               parallel="snow",nsim=1000,seed=101)
> }
> 
> 1) Can I predict the bootstrapped model using two different datasets at
> once to speed things up (i.e., pred.sites and pred.sites.m5)?
> 2) Can I use parallel processing of the initial loop (1,423 sites) outside
> of bootmer (perhaps with doParallel and foreach) and then run bootmer
> within that loop?  Though I have used foreach before, I find it hard to
> compile the data that I really want on the backend.
> 
> Thank you for your time and any suggestions you might have.
> 
> Sincerely,
> 
> Jonathan
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From bbolker @ending from gm@il@com  Sat Nov 10 00:44:27 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Fri, 9 Nov 2018 18:44:27 -0500
Subject: [R-sig-ME] Running
In-Reply-To: <CAGomFPUfUZ8cC-8N2BmHyuEKtG=VxQqpU=sjSTTb1Ln=FJigYQ@mail.gmail.com>
References: <CAGomFPWyCegZpTbpNLVNn100wHm=RFLq_Uw8p-B0gqkjxurqVA@mail.gmail.com>
 <6d44272f-a303-6467-3d4f-37962a0f5eec@gmail.com>
 <CAGomFPUfUZ8cC-8N2BmHyuEKtG=VxQqpU=sjSTTb1Ln=FJigYQ@mail.gmail.com>
Message-ID: <6d0229e9-c807-3983-ef79-82cd7e06e178@gmail.com>


  [please keep r-sig-mixed-models in the Cc: if possible - although I
see it's a judgment call in this case because the e-mail contains both
generally pertinent info (uncertainty of FE small) and a personal-ish
message ...]

  Just to be clear, (1) I was suggesting that the uncertainty of the
fixed effects might be *large* with respect to the uncertainty of the
random effects, and largely independent of it; (2) have you already
tried implementing other (approximate, faster) methods for the
uncertainty on a small subset of the sites to convince yourself that you
really need the full PB method?

On 2018-11-09 6:28 p.m., Jonathan Miller wrote:
> Thank you.? You are right the uncertainty of the fixed effects is
> smaller than the others, but is of importance for my project. I
> appreciate any thoughts you have when you have time to get to it.
> 
> Jonathan
> 
> On Fri, Nov 9, 2018, 5:17 PM Ben Bolker <bbolker at gmail.com
> <mailto:bbolker at gmail.com>> wrote:
> 
> 
>     ? I will give this some thought when I get a chance (hopefully someone
>     else will give it some thought and find some answers sooner ...)? In the
>     meantime -- do you really need parametric bootstrapping/bootMer to get
>     the confidence intervals you want?? It's quite possible that a simpler
>     approximation (e.g. assuming that the variation caused by uncertainty in
>     the top-level random-effects parameters is small relative to other
>     sources of variability) is adequate, given that you have thousands of
>     samples ...
> 
>     On 2018-11-09 4:15 p.m., Jonathan Miller wrote:
>     > Dr. Bolker,
>     >
>     > I am a Phd student at NCSU and struggling with a coding issue. I am
>     > bootstrapping some glmm model predictions in order to determine the
>     > uncertainty associated with their fixed effects.? I read your
>     comments on
>     > https://github.com/lme4/lme4/issues/388 and have used a code
>     similar to
>     > yours below (b3):
>     >
>     > ## param, RE, and conditional
>     > b1 <- bootMer(fm1,FUN=sfun1,nsim=100,seed=101)
>     > ## param and RE (no conditional)
>     > b2 <- bootMer(fm1,FUN=sfun2,nsim=100,seed=101)
>     > ## param only
>     > b3 <- bootMer(fm1,FUN=function(x) predict(x,newdata=test,re.form=~0),
>     >? ? ? ? ? ? ? ?## re.form=~0 is equivalent to use.u=FALSE
>     >? ? ? ? ? ? ? ?nsim=100,seed=101)
>     >
>     >
>     > It has worked well for me but takes an extremely long time to run.
>     I am
>     > predicting 6 different wq indicators for 1,423 sites and the
>     datasets range
>     > in size from 3,000 to 25,000 entries each.? The small one is
>     relatively
>     > runs relatively ok, but the others are extremely slow. In my code
>     (below),
>     > I also want to make more than one prediction (current conditions,
>     possible
>     > future conditions) using the bootstrapping. Using "snow" in parallel
>     > doesn't seem to speed things up.? I thought of two possibilities,
>     but am
>     > unsure how to implement them.
>     >
>     > for (s in 1:1423){
>     >
>     > bi <- bootMer(BI.mod,FUN=function(x)
>     > predict(x,newdata=pred.sites[s,],re.form=~0,REML=TRUE),
>     >? ? ? ? ? ? ? ?parallel="snow",nsim=1000,seed=101)
>     > bi.5 <- bootMer(BI.mod,FUN=function(x)
>     > predict(x,newdata=pred.sites.m5[s,],re.form=~0,REML=TRUE),
>     >? ? ? ? ? ? ? ?parallel="snow",nsim=1000,seed=101)
>     > }
>     >
>     > 1) Can I predict the bootstrapped model using two different
>     datasets at
>     > once to speed things up (i.e., pred.sites and pred.sites.m5)?
>     > 2) Can I use parallel processing of the initial loop (1,423 sites)
>     outside
>     > of bootmer (perhaps with doParallel and foreach) and then run bootmer
>     > within that loop?? Though I have used foreach before, I find it
>     hard to
>     > compile the data that I really want on the backend.
>     >
>     > Thank you for your time and any suggestions you might have.
>     >
>     > Sincerely,
>     >
>     > Jonathan
>     >
>     >? ? ? ?[[alternative HTML version deleted]]
>     >
>     > _______________________________________________
>     > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >
> 
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From jwmille7 @ending from nc@u@edu  Sat Nov 10 14:56:58 2018
From: jwmille7 @ending from nc@u@edu (Jonathan Miller)
Date: Sat, 10 Nov 2018 08:56:58 -0500
Subject: [R-sig-ME] Running
In-Reply-To: <6d0229e9-c807-3983-ef79-82cd7e06e178@gmail.com>
References: <CAGomFPWyCegZpTbpNLVNn100wHm=RFLq_Uw8p-B0gqkjxurqVA@mail.gmail.com>
 <6d44272f-a303-6467-3d4f-37962a0f5eec@gmail.com>
 <CAGomFPUfUZ8cC-8N2BmHyuEKtG=VxQqpU=sjSTTb1Ln=FJigYQ@mail.gmail.com>
 <6d0229e9-c807-3983-ef79-82cd7e06e178@gmail.com>
Message-ID: <CAGomFPVe4RFfuHM7KPs2oerREAKXzPd996dfo3yvA5WrHSuAow@mail.gmail.com>

Ben,

I am sorry.  I did misunderstand your first email last night.  I am using
the glmm models for predicting water quality and my random effects are at
the site and basin level and they do explain a lot of the variance in the
models especially for "noisy" indicators like turbidity and fecal
coliform.  In the project, I am predicting for current conditions as well
as potential management scenarios throughout a region.  Initially, I just
calculate the mean difference between these two values (current vs.
management scenario) for the region, but I would like to get an idea of the
uncertainty in this mean reduction. Though the random effects are
significant, we are making an assumption that when trying to restore a
particular site, the random effect at that site will not change over the
course of the restoration. This implies that the uncertainty of improvement
for a given site is mostly affected by the uncertainty in the fixed effects
which are being adjusted for the management scenarios  (i.e., increase of
canopy cover, nutrient loadings from wastewater treatment plants, etc.). I
tried to use the predictInterval function, but it seemed to give me
predictive intervals including random effects as well. In essence, they
were much larger than the ones I am getting using :

## param only
b3 <- bootMer(fm1,FUN=function(x) predict(x,newdata=test,re.form=~0),
              ## re.form=~0 is equivalent to use.u=FALSE
              nsim=100,seed=101)

I also used Cholesky decomposition on the covariance matrix of the fixed
effects to "simulate" the uncertainty of the fixed effects giving similar
results.  I think bootstrapping is a bit easier to explain in my manuscript
though and thought it might also be easier for coding purposes using
bootmer.

It does seem to be working well, but my question was more on why using
parallel= "snow" isn't speeding things up, though maybe your concerns of me
having to do PB are right as well.

Thank you,

Jonathan



On Fri, Nov 9, 2018 at 6:44 PM Ben Bolker <bbolker at gmail.com> wrote:

>
>   [please keep r-sig-mixed-models in the Cc: if possible - although I
> see it's a judgment call in this case because the e-mail contains both
> generally pertinent info (uncertainty of FE small) and a personal-ish
> message ...]
>
>   Just to be clear, (1) I was suggesting that the uncertainty of the
> fixed effects might be *large* with respect to the uncertainty of the
> random effects, and largely independent of it; (2) have you already
> tried implementing other (approximate, faster) methods for the
> uncertainty on a small subset of the sites to convince yourself that you
> really need the full PB method?
>
> On 2018-11-09 6:28 p.m., Jonathan Miller wrote:
> > Thank you.  You are right the uncertainty of the fixed effects is
> > smaller than the others, but is of importance for my project. I
> > appreciate any thoughts you have when you have time to get to it.
> >
> > Jonathan
> >
> > On Fri, Nov 9, 2018, 5:17 PM Ben Bolker <bbolker at gmail.com
> > <mailto:bbolker at gmail.com>> wrote:
> >
> >
> >       I will give this some thought when I get a chance (hopefully
> someone
> >     else will give it some thought and find some answers sooner ...)  In
> the
> >     meantime -- do you really need parametric bootstrapping/bootMer to
> get
> >     the confidence intervals you want?  It's quite possible that a
> simpler
> >     approximation (e.g. assuming that the variation caused by
> uncertainty in
> >     the top-level random-effects parameters is small relative to other
> >     sources of variability) is adequate, given that you have thousands of
> >     samples ...
> >
> >     On 2018-11-09 4:15 p.m., Jonathan Miller wrote:
> >     > Dr. Bolker,
> >     >
> >     > I am a Phd student at NCSU and struggling with a coding issue. I am
> >     > bootstrapping some glmm model predictions in order to determine the
> >     > uncertainty associated with their fixed effects.  I read your
> >     comments on
> >     > https://github.com/lme4/lme4/issues/388 and have used a code
> >     similar to
> >     > yours below (b3):
> >     >
> >     > ## param, RE, and conditional
> >     > b1 <- bootMer(fm1,FUN=sfun1,nsim=100,seed=101)
> >     > ## param and RE (no conditional)
> >     > b2 <- bootMer(fm1,FUN=sfun2,nsim=100,seed=101)
> >     > ## param only
> >     > b3 <- bootMer(fm1,FUN=function(x)
> predict(x,newdata=test,re.form=~0),
> >     >               ## re.form=~0 is equivalent to use.u=FALSE
> >     >               nsim=100,seed=101)
> >     >
> >     >
> >     > It has worked well for me but takes an extremely long time to run.
> >     I am
> >     > predicting 6 different wq indicators for 1,423 sites and the
> >     datasets range
> >     > in size from 3,000 to 25,000 entries each.  The small one is
> >     relatively
> >     > runs relatively ok, but the others are extremely slow. In my code
> >     (below),
> >     > I also want to make more than one prediction (current conditions,
> >     possible
> >     > future conditions) using the bootstrapping. Using "snow" in
> parallel
> >     > doesn't seem to speed things up.  I thought of two possibilities,
> >     but am
> >     > unsure how to implement them.
> >     >
> >     > for (s in 1:1423){
> >     >
> >     > bi <- bootMer(BI.mod,FUN=function(x)
> >     > predict(x,newdata=pred.sites[s,],re.form=~0,REML=TRUE),
> >     >               parallel="snow",nsim=1000,seed=101)
> >     > bi.5 <- bootMer(BI.mod,FUN=function(x)
> >     > predict(x,newdata=pred.sites.m5[s,],re.form=~0,REML=TRUE),
> >     >               parallel="snow",nsim=1000,seed=101)
> >     > }
> >     >
> >     > 1) Can I predict the bootstrapped model using two different
> >     datasets at
> >     > once to speed things up (i.e., pred.sites and pred.sites.m5)?
> >     > 2) Can I use parallel processing of the initial loop (1,423 sites)
> >     outside
> >     > of bootmer (perhaps with doParallel and foreach) and then run
> bootmer
> >     > within that loop?  Though I have used foreach before, I find it
> >     hard to
> >     > compile the data that I really want on the backend.
> >     >
> >     > Thank you for your time and any suggestions you might have.
> >     >
> >     > Sincerely,
> >     >
> >     > Jonathan
> >     >
> >     >       [[alternative HTML version deleted]]
> >     >
> >     > _______________________________________________
> >     > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     >
> >
> >     _______________________________________________
> >     R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>

	[[alternative HTML version deleted]]


From roim@or m@ili@g off post@t@u@@c@il  Mon Nov 12 13:26:52 2018
From: roim@or m@ili@g off post@t@u@@c@il (roim@or m@ili@g off post@t@u@@c@il)
Date: Mon, 12 Nov 2018 14:26:52 +0200
Subject: [R-sig-ME] 
 Unclear output from MCMCglmm with categorical predictors
In-Reply-To: <CAJtCY7UpBkrLZMGM1+Riv6U_epqfj_K5Xek=Cnjsdcdm7dvojw@mail.gmail.com>
References: <20181107155140.Horde.oHgXEzpRoYRb4u3sVchVdtA@webmail.tau.ac.il>
 <CAJtCY7UpBkrLZMGM1+Riv6U_epqfj_K5Xek=Cnjsdcdm7dvojw@mail.gmail.com>
Message-ID: <20181112142652.Horde.oCI6KTpRoYRb6XGMgvSDMEA@webmail.tau.ac.il>


Thanks for your response Walid.
However, it doesn't really answer my questions, so I'll try to clarify those.

An intercept estimate in my model makes no biological sense because  
all species have both diet and habitat. This is why I chose to  
suppress the intercept.

In the context of categorical predictors, suppressing the intercept   
means that an arbitrarily-chosen category is taken as baseline, and  
the model estimates the difference (in the response variable) between  
this baseline and all other categories.
When dealing with two categorical traits as predictors, each data  
point is a combination of the effects of both traits, i.e. it is a  
combination of one category from each trait.

If this is indeed the case, the baseline value must include one  
category of each predictor in the model, otherwise their effects would  
be confounded.

For example, in my model I would expect one diet category AND one  
habitat category, say, 'herbivorous' and 'aquatic', to be  
baseline/intercept (un-estimated).
Instead, it seems that only 'herbivorous' is absorbed in the  
intercept, while all habitat classes have posterior estimates.

My questions are:
1- why does no habitat category get absorbed in the intercept? and
2- what can I do to fix that?

If it's at all useful, here is an example:

## data format
unique(Tdata$Habitat)
[1] TE AR AQ ST SA
Levels: AQ AR SA ST TE

unique(Tdata$Diet)
[1] Herb Omni Faun
Levels: Faun Herb Omni

ModTHRE <- MCMCglmm(Response ~ -1 + Habitat + Diet,
                     prior = list(R = list(V = 1, nu = 0.002)),
                     ginverse = list(Binomial=INphylo$Ainv),
                     burnin = 25000, nitt = 225000, thin = 200,
                     family = "threshold",
                     data = Tdata,
                     verbose = FALSE)

## model output
summary(ModTHRE)

  Iterations = 25001:224801
  Thinning interval  = 200
  Sample size  = 1000

  DIC: 2321.861

  R-structure:  ~units

       post.mean l-95% CI u-95% CI eff.samp
units         1   0.9973    1.003     1000

  Location effects: Response ~ -1 + ForagingHab + Troph_Lev

             post.mean l-95% CI u-95% CI eff.samp  pMCMC
HabitatST   -0.07612 -0.42629  0.33746   1000.0  0.694
HabitatTE   -0.36682 -0.52533 -0.21118   1000.0 <0.001 ***
HabitatSA   -0.04691 -0.25769  0.19636   1000.0  0.724
HabitatAR   -0.07302 -0.29900  0.16681    883.3  0.548
HabitatAQ   -0.47948 -0.82598 -0.15793   1000.0  0.002 **
DietHerb     0.30708  0.11255  0.48545   1000.0  0.002 **
DietOmni     0.05263 -0.12176  0.26105   1000.0  0.604
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

  Cutpoints:
                          post.mean l-95% CI u-95% CI eff.samp
cutpoint.traitActivity.1    0.4911    0.436   0.5495    877.6



Any thoughts, ideas of what's going on here, or corrections of my  
mis-perceptions, are all very welcome.

Many thanks,
Roi


Quoting Walid Mawass <walidmawass10 at gmail.com>:

> Hello,
>
> by adding -1 into your model's formula, you are explicitly calling for no
> intercept term to be included in the estimates. If you do want an intercept
> term which would include a baseline level for each of your categorical
> variables then the syntax should be:
>
> MCMCglmm(Activity ~1 + Habitat + Diet + log(Mass) + Max.Temp... (explicit
> call for intercept term)
> or
> MCMCglmm(Activity ~ Habitat + Diet + log(Mass) + Max.Temp... (implicit call
> for intercept term)
>
> Hope this helps
> --
> Walid Mawass
> Ph.D. candidate in Cellular and Molecular Biology
> Population Genetics Laboratory
> University of Qu?bec at Trois-Rivi?res
> 3351, boul. des Forges, C.P. 500
> Trois-Rivi?res (Qu?bec) G9A 5H7
> Telephone: 819-376-5011 poste 3384
>
>
> On Wed, Nov 7, 2018 at 12:09 PM <roimaor at post.tau.ac.il> wrote:
>
>> Dear list members,
>>
>> I have a model with categorical response and categorical + continuous
>> predictors.
>>
>> My model has two categorical predictors: "diet" (3 levels) and
>> "habitat" (6 levels):
>>
>> THRE1 <- MCMCglmm(Activity ~ -1 + Habitat + Diet + log(Mass) + Max.Temp,
>>                       prior = list(R = list(V = 1, fix = 1)),
>>                       ginverse = list(Binomial=INphylo$Ainv),
>>                       family = "threshold",
>>                       data = Tdata)
>>
>> If I understand correctly, in this configuration the algorithm
>> shouldn't return estimated values for the effect of each level of a
>> categorical predictor, instead, it returns a contrast between that
>> level and another level which was arbitrarily chosen as the base
>> level. Each species (data point) has a value for each of these traits,
>> so I would expect them to be estimated independently, meaning that one
>> level of each predictor should be the 'baseline' and absorbed into the
>> global intercept. In that case I expect 2 contrasts to be returned for
>> diet categories and 5 contrasts for habitat.
>>
>> However, I get 2 estimates (presumably contrasts) for diet categories,
>> and 6 for habitat categories, i.e., no habitat category was designated
>> as baseline, which makes me question whether the estimates are
>> contrasts or actual effect sizes.
>>
>> My questions:
>> - Is the algorithm pooling all the predictor categories as if they
>> were a single trait with 8 levels?
>> - If the habitat effect estimates are contrasts - what are they compared
>> to?
>> - If they are effect sizes - what did I do to not get the contrasts as
>> I expected?
>>
>> Any help would be much appreciated!
>> Thanks,
>> --
>> Roi Maor
>> PhD candidate
>> School of Zoology, Tel Aviv University
>> Centre for Biodiversity and Environment Research, UCL
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>


From j@h@dfield @ending from ed@@c@uk  Mon Nov 12 17:58:17 2018
From: j@h@dfield @ending from ed@@c@uk (HADFIELD Jarrod)
Date: Mon, 12 Nov 2018 16:58:17 +0000
Subject: [R-sig-ME] 
 Unclear output from MCMCglmm with categorical predictors
In-Reply-To: <20181112142652.Horde.oCI6KTpRoYRb6XGMgvSDMEA@webmail.tau.ac.il>
References: <20181107155140.Horde.oHgXEzpRoYRb4u3sVchVdtA@webmail.tau.ac.il>
 <CAJtCY7UpBkrLZMGM1+Riv6U_epqfj_K5Xek=Cnjsdcdm7dvojw@mail.gmail.com>
 <20181112142652.Horde.oCI6KTpRoYRb6XGMgvSDMEA@webmail.tau.ac.il>
Message-ID: <c1fb7a8b-25eb-f616-db1b-5ad137b938e5@ed.ac.uk>

Hi,

The habitat coefficients are the estimates when (in the example) diet is 
Faun. The two diet coefficients are the differences between Herb and 
Faun and Herb and Omni. As the previous poster said, removing the -1 
will give you an intercept and habitat coefficients that are differences 
between the absorbed (base-line) habitat and the remaining habitats.

Cheers,

Jarrod



On 12/11/2018 12:26, roimaor at post.tau.ac.il wrote:
>
> Thanks for your response Walid.
> However, it doesn't really answer my questions, so I'll try to clarify 
> those.
>
> An intercept estimate in my model makes no biological sense because 
> all species have both diet and habitat. This is why I chose to 
> suppress the intercept.
>
> In the context of categorical predictors, suppressing the intercept? 
> means that an arbitrarily-chosen category is taken as baseline, and 
> the model estimates the difference (in the response variable) between 
> this baseline and all other categories.
> When dealing with two categorical traits as predictors, each data 
> point is a combination of the effects of both traits, i.e. it is a 
> combination of one category from each trait.
>
> If this is indeed the case, the baseline value must include one 
> category of each predictor in the model, otherwise their effects would 
> be confounded.
>
> For example, in my model I would expect one diet category AND one 
> habitat category, say, 'herbivorous' and 'aquatic', to be 
> baseline/intercept (un-estimated).
> Instead, it seems that only 'herbivorous' is absorbed in the 
> intercept, while all habitat classes have posterior estimates.
>
> My questions are:
> 1- why does no habitat category get absorbed in the intercept? and
> 2- what can I do to fix that?
>
> If it's at all useful, here is an example:
>
> ## data format
> unique(Tdata$Habitat)
> [1] TE AR AQ ST SA
> Levels: AQ AR SA ST TE
>
> unique(Tdata$Diet)
> [1] Herb Omni Faun
> Levels: Faun Herb Omni
>
> ModTHRE <- MCMCglmm(Response ~ -1 + Habitat + Diet,
> ??????????????????? prior = list(R = list(V = 1, nu = 0.002)),
> ??????????????????? ginverse = list(Binomial=INphylo$Ainv),
> ??????????????????? burnin = 25000, nitt = 225000, thin = 200,
> ??????????????????? family = "threshold",
> ??????????????????? data = Tdata,
> ??????????????????? verbose = FALSE)
>
> ## model output
> summary(ModTHRE)
>
> ?Iterations = 25001:224801
> ?Thinning interval? = 200
> ?Sample size? = 1000
>
> ?DIC: 2321.861
>
> ?R-structure:? ~units
>
> ????? post.mean l-95% CI u-95% CI eff.samp
> units???????? 1?? 0.9973??? 1.003???? 1000
>
> ?Location effects: Response ~ -1 + ForagingHab + Troph_Lev
>
> ??????????? post.mean l-95% CI u-95% CI eff.samp? pMCMC
> HabitatST?? -0.07612 -0.42629? 0.33746?? 1000.0? 0.694
> HabitatTE?? -0.36682 -0.52533 -0.21118?? 1000.0 <0.001 ***
> HabitatSA?? -0.04691 -0.25769? 0.19636?? 1000.0? 0.724
> HabitatAR?? -0.07302 -0.29900? 0.16681??? 883.3? 0.548
> HabitatAQ?? -0.47948 -0.82598 -0.15793?? 1000.0? 0.002 **
> DietHerb???? 0.30708? 0.11255? 0.48545?? 1000.0? 0.002 **
> DietOmni???? 0.05263 -0.12176? 0.26105?? 1000.0? 0.604
> ---
> Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> ?Cutpoints:
> ???????????????????????? post.mean l-95% CI u-95% CI eff.samp
> cutpoint.traitActivity.1??? 0.4911??? 0.436?? 0.5495??? 877.6
>
>
>
> Any thoughts, ideas of what's going on here, or corrections of my 
> mis-perceptions, are all very welcome.
>
> Many thanks,
> Roi
>
>
> Quoting Walid Mawass <walidmawass10 at gmail.com>:
>
>> Hello,
>>
>> by adding -1 into your model's formula, you are explicitly calling 
>> for no
>> intercept term to be included in the estimates. If you do want an 
>> intercept
>> term which would include a baseline level for each of your categorical
>> variables then the syntax should be:
>>
>> MCMCglmm(Activity ~1 + Habitat + Diet + log(Mass) + Max.Temp... 
>> (explicit
>> call for intercept term)
>> or
>> MCMCglmm(Activity ~ Habitat + Diet + log(Mass) + Max.Temp... 
>> (implicit call
>> for intercept term)
>>
>> Hope this helps
>> -- 
>> Walid Mawass
>> Ph.D. candidate in Cellular and Molecular Biology
>> Population Genetics Laboratory
>> University of Qu?bec at Trois-Rivi?res
>> 3351, boul. des Forges, C.P. 500
>> Trois-Rivi?res (Qu?bec) G9A 5H7
>> Telephone: 819-376-5011 poste 3384
>>
>>
>> On Wed, Nov 7, 2018 at 12:09 PM <roimaor at post.tau.ac.il> wrote:
>>
>>> Dear list members,
>>>
>>> I have a model with categorical response and categorical + continuous
>>> predictors.
>>>
>>> My model has two categorical predictors: "diet" (3 levels) and
>>> "habitat" (6 levels):
>>>
>>> THRE1 <- MCMCglmm(Activity ~ -1 + Habitat + Diet + log(Mass) + 
>>> Max.Temp,
>>> ????????????????????? prior = list(R = list(V = 1, fix = 1)),
>>> ????????????????????? ginverse = list(Binomial=INphylo$Ainv),
>>> ????????????????????? family = "threshold",
>>> ????????????????????? data = Tdata)
>>>
>>> If I understand correctly, in this configuration the algorithm
>>> shouldn't return estimated values for the effect of each level of a
>>> categorical predictor, instead, it returns a contrast between that
>>> level and another level which was arbitrarily chosen as the base
>>> level. Each species (data point) has a value for each of these traits,
>>> so I would expect them to be estimated independently, meaning that one
>>> level of each predictor should be the 'baseline' and absorbed into the
>>> global intercept. In that case I expect 2 contrasts to be returned for
>>> diet categories and 5 contrasts for habitat.
>>>
>>> However, I get 2 estimates (presumably contrasts) for diet categories,
>>> and 6 for habitat categories, i.e., no habitat category was designated
>>> as baseline, which makes me question whether the estimates are
>>> contrasts or actual effect sizes.
>>>
>>> My questions:
>>> - Is the algorithm pooling all the predictor categories as if they
>>> were a single trait with 8 levels?
>>> - If the habitat effect estimates are contrasts - what are they 
>>> compared
>>> to?
>>> - If they are effect sizes - what did I do to not get the contrasts as
>>> I expected?
>>>
>>> Any help would be much appreciated!
>>> Thanks,
>>> -- 
>>> Roi Maor
>>> PhD candidate
>>> School of Zoology, Tel Aviv University
>>> Centre for Biodiversity and Environment Research, UCL
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From ellen@pero @ending from umconnect@umt@edu  Mon Nov 12 19:58:03 2018
From: ellen@pero @ending from umconnect@umt@edu (Pero, Ellen)
Date: Mon, 12 Nov 2018 18:58:03 +0000
Subject: [R-sig-ME] Single DV with multiple measures for time-varying IV?
Message-ID: <CO2PR01MB2198B93539290F1E5DC5C285CCC10@CO2PR01MB2198.prod.exchangelabs.com>

Hi all:

I have an analytical dilemma wherein I have a single DV with multiple categorical and continuous IVs (one of which is a continuous IV that has multiple measurements across time). I'm not sure the best way to model for this - though it's clearly a hierarchical situation so I thought this might be a good venue to pose the question.

Specifically, I have 60 pregnant elk from which I took monthly cortisol samples across gestation (some missing values, so 5-8 samples/female across gestation). I'm interested in how those stress measurements across gestation (along with a range of other IVs that don't vary with time, e.g., dam age, sire age, calf birthdate) influence the birth mass of each female's calf.

Any suggestions on analysis for situations where a single DV is predicted by longitudinal measures of time-varying IV (along with non-varying IVs)?

I'm new to this list and will spend some time familiarizing myself with it - but was eager to get my question out. Apologies if this isn't the right venue for my non-development related question. Please disregard if appropriate.

I appreciate any thoughts/advice/suggestions!
El



Ellen Pero
PhD Student
Wildlife Biology Program
W.A. Franke College of Forestry and Conservation
University of Montana
32 Campus Drive, FOR 318
Missoula, MT 59812


	[[alternative HTML version deleted]]


From j@h@dfield @ending from ed@@c@uk  Mon Nov 12 20:35:39 2018
From: j@h@dfield @ending from ed@@c@uk (HADFIELD Jarrod)
Date: Mon, 12 Nov 2018 19:35:39 +0000
Subject: [R-sig-ME] 
 Unclear output from MCMCglmm with categorical predictors
In-Reply-To: <20181112142652.Horde.oCI6KTpRoYRb6XGMgvSDMEA@webmail.tau.ac.il>
References: <20181107155140.Horde.oHgXEzpRoYRb4u3sVchVdtA@webmail.tau.ac.il>
 <CAJtCY7UpBkrLZMGM1+Riv6U_epqfj_K5Xek=Cnjsdcdm7dvojw@mail.gmail.com>
 <20181112142652.Horde.oCI6KTpRoYRb6XGMgvSDMEA@webmail.tau.ac.il>
Message-ID: <D2DFFB1B-B549-4A4A-8AF7-716D1E93F263@ed.ac.uk>

Hi, 

Sorry - I also noted some errors in your example, and the original code. 

1/ In the example you do not fix the residual variance (to one) which you should do because it is not identifiable in threshold models.

2/ You have what seems to be a phylogenetic correlation structure passed to ginverse, but you don?t associate it with a random term.

Cheers,

Jarrod

> On 12 Nov 2018, at 12:26, roimaor at post.tau.ac.il wrote:
> 
> 
> Thanks for your response Walid.
> However, it doesn't really answer my questions, so I'll try to clarify those.
> 
> An intercept estimate in my model makes no biological sense because all species have both diet and habitat. This is why I chose to suppress the intercept.
> 
> In the context of categorical predictors, suppressing the intercept  means that an arbitrarily-chosen category is taken as baseline, and the model estimates the difference (in the response variable) between this baseline and all other categories.
> When dealing with two categorical traits as predictors, each data point is a combination of the effects of both traits, i.e. it is a combination of one category from each trait.
> 
> If this is indeed the case, the baseline value must include one category of each predictor in the model, otherwise their effects would be confounded.
> 
> For example, in my model I would expect one diet category AND one habitat category, say, 'herbivorous' and 'aquatic', to be baseline/intercept (un-estimated).
> Instead, it seems that only 'herbivorous' is absorbed in the intercept, while all habitat classes have posterior estimates.
> 
> My questions are:
> 1- why does no habitat category get absorbed in the intercept? and
> 2- what can I do to fix that?
> 
> If it's at all useful, here is an example:
> 
> ## data format
> unique(Tdata$Habitat)
> [1] TE AR AQ ST SA
> Levels: AQ AR SA ST TE
> 
> unique(Tdata$Diet)
> [1] Herb Omni Faun
> Levels: Faun Herb Omni
> 
> ModTHRE <- MCMCglmm(Response ~ -1 + Habitat + Diet,
>                    prior = list(R = list(V = 1, nu = 0.002)),
>                    ginverse = list(Binomial=INphylo$Ainv),
>                    burnin = 25000, nitt = 225000, thin = 200,
>                    family = "threshold",
>                    data = Tdata,
>                    verbose = FALSE)
> 
> ## model output
> summary(ModTHRE)
> 
> Iterations = 25001:224801
> Thinning interval  = 200
> Sample size  = 1000
> 
> DIC: 2321.861
> 
> R-structure:  ~units
> 
>      post.mean l-95% CI u-95% CI eff.samp
> units         1   0.9973    1.003     1000
> 
> Location effects: Response ~ -1 + ForagingHab + Troph_Lev
> 
>            post.mean l-95% CI u-95% CI eff.samp  pMCMC
> HabitatST   -0.07612 -0.42629  0.33746   1000.0  0.694
> HabitatTE   -0.36682 -0.52533 -0.21118   1000.0 <0.001 ***
> HabitatSA   -0.04691 -0.25769  0.19636   1000.0  0.724
> HabitatAR   -0.07302 -0.29900  0.16681    883.3  0.548
> HabitatAQ   -0.47948 -0.82598 -0.15793   1000.0  0.002 **
> DietHerb     0.30708  0.11255  0.48545   1000.0  0.002 **
> DietOmni     0.05263 -0.12176  0.26105   1000.0  0.604
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Cutpoints:
>                         post.mean l-95% CI u-95% CI eff.samp
> cutpoint.traitActivity.1    0.4911    0.436   0.5495    877.6
> 
> 
> 
> Any thoughts, ideas of what's going on here, or corrections of my mis-perceptions, are all very welcome.
> 
> Many thanks,
> Roi
> 
> 
> Quoting Walid Mawass <walidmawass10 at gmail.com>:
> 
>> Hello,
>> 
>> by adding -1 into your model's formula, you are explicitly calling for no
>> intercept term to be included in the estimates. If you do want an intercept
>> term which would include a baseline level for each of your categorical
>> variables then the syntax should be:
>> 
>> MCMCglmm(Activity ~1 + Habitat + Diet + log(Mass) + Max.Temp... (explicit
>> call for intercept term)
>> or
>> MCMCglmm(Activity ~ Habitat + Diet + log(Mass) + Max.Temp... (implicit call
>> for intercept term)
>> 
>> Hope this helps
>> --
>> Walid Mawass
>> Ph.D. candidate in Cellular and Molecular Biology
>> Population Genetics Laboratory
>> University of Qu?bec at Trois-Rivi?res
>> 3351, boul. des Forges, C.P. 500
>> Trois-Rivi?res (Qu?bec) G9A 5H7
>> Telephone: 819-376-5011 poste 3384
>> 
>> 
>> On Wed, Nov 7, 2018 at 12:09 PM <roimaor at post.tau.ac.il> wrote:
>> 
>>> Dear list members,
>>> 
>>> I have a model with categorical response and categorical + continuous
>>> predictors.
>>> 
>>> My model has two categorical predictors: "diet" (3 levels) and
>>> "habitat" (6 levels):
>>> 
>>> THRE1 <- MCMCglmm(Activity ~ -1 + Habitat + Diet + log(Mass) + Max.Temp,
>>>                      prior = list(R = list(V = 1, fix = 1)),
>>>                      ginverse = list(Binomial=INphylo$Ainv),
>>>                      family = "threshold",
>>>                      data = Tdata)
>>> 
>>> If I understand correctly, in this configuration the algorithm
>>> shouldn't return estimated values for the effect of each level of a
>>> categorical predictor, instead, it returns a contrast between that
>>> level and another level which was arbitrarily chosen as the base
>>> level. Each species (data point) has a value for each of these traits,
>>> so I would expect them to be estimated independently, meaning that one
>>> level of each predictor should be the 'baseline' and absorbed into the
>>> global intercept. In that case I expect 2 contrasts to be returned for
>>> diet categories and 5 contrasts for habitat.
>>> 
>>> However, I get 2 estimates (presumably contrasts) for diet categories,
>>> and 6 for habitat categories, i.e., no habitat category was designated
>>> as baseline, which makes me question whether the estimates are
>>> contrasts or actual effect sizes.
>>> 
>>> My questions:
>>> - Is the algorithm pooling all the predictor categories as if they
>>> were a single trait with 8 levels?
>>> - If the habitat effect estimates are contrasts - what are they compared
>>> to?
>>> - If they are effect sizes - what did I do to not get the contrasts as
>>> I expected?
>>> 
>>> Any help would be much appreciated!
>>> Thanks,
>>> --
>>> Roi Maor
>>> PhD candidate
>>> School of Zoology, Tel Aviv University
>>> Centre for Biodiversity and Environment Research, UCL
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From H@F@r@h @ending from tudelft@nl  Mon Nov 12 22:28:44 2018
From: H@F@r@h @ending from tudelft@nl (Haneen Farah - CITG)
Date: Mon, 12 Nov 2018 21:28:44 +0000
Subject: [R-sig-ME] Cross-validation
Message-ID: <db17c6fdb0c445f496de0bb454d49373@tudelft.nl>

Is there a package cross validation for linear mixed effect models with GroupKFold cross validation?
Thanks

	[[alternative HTML version deleted]]


From p@ul@buerkner @ending from gm@il@com  Mon Nov 12 22:32:42 2018
From: p@ul@buerkner @ending from gm@il@com (Paul Buerkner)
Date: Mon, 12 Nov 2018 22:32:42 +0100
Subject: [R-sig-ME] Cross-validation
In-Reply-To: <db17c6fdb0c445f496de0bb454d49373@tudelft.nl>
References: <db17c6fdb0c445f496de0bb454d49373@tudelft.nl>
Message-ID: <CAGoSky8Bxebhve1B3Shh-GZyKLVZo=T4Gxa7SBB6LoQ_W+gdPA@mail.gmail.com>

If you are willing to go Bayesian, you can use the brms package and method
kfold.

Am Mo., 12. Nov. 2018 um 22:29 Uhr schrieb Haneen Farah - CITG <
H.Farah at tudelft.nl>:

> Is there a package cross validation for linear mixed effect models with
> GroupKFold cross validation?
> Thanks
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Mon Nov 12 22:31:56 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Mon, 12 Nov 2018 16:31:56 -0500
Subject: [R-sig-ME] Cross-validation
In-Reply-To: <db17c6fdb0c445f496de0bb454d49373@tudelft.nl>
References: <db17c6fdb0c445f496de0bb454d49373@tudelft.nl>
Message-ID: <CABghstTFbY4TrxUHjQvaMZEr_9y5Pd-v2ZBv27kRy63kpb24vg@mail.gmail.com>

Don't know, but I would start by going through the results of

library("sos")
findFn("grouped cross validation")

and see whether anything looks good.

For simple designs it shouldn't be *too* hard to roll something from
scratch ... but admittedly a package that had already done it would be
convenient ...


On Mon, Nov 12, 2018 at 4:29 PM Haneen Farah - CITG <H.Farah at tudelft.nl> wrote:
>
> Is there a package cross validation for linear mixed effect models with GroupKFold cross validation?
> Thanks
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From p@uljohn32 @ending from gm@il@com  Tue Nov 13 17:11:22 2018
From: p@uljohn32 @ending from gm@il@com (Paul Johnson)
Date: Tue, 13 Nov 2018 10:11:22 -0600
Subject: [R-sig-ME] pre/post with partial participation
Message-ID: <CAErODj8ozMcZP-UCYn-=qGSHDdiX8tx8dKyC3aRaMXSUjPs5+w@mail.gmail.com>

I have a crazy ANOVA question and would appreciate your advice.

We have a project that did a pre-post measurement, but the
participation in the data collection was haphazard.  There are only 19
people that participated pre-post, but there are about 40 that
participated only in the pre phase and 30 that participated in the
post phase.

I don't have the data to show you, but I made some up. I've got
ID=1:19 for the ones who are both in pre and post data samples, and ID
20:59 are in pre only and 60:89 are post only.

In my first example, the data has no true random effect and lmer gets
the correct estimate, the random effect is estimated as 0.00, or close
to it.  I find that slight differences in the way I generate the data
(either I get exactly 0.0 or 7 x 10^-13 or similar).

This way of making the data generates a "full pre/post" data set and
then throws away pre and post observations for the missing cases:

set.seed(234234)
dat4 <- data.frame(ID = rep(1:89, 2), x = gl(2, 89, labels = c("pre", "post")))
err <- rnorm(length(dat4$x), 0, 1)
b <- 0
beta <- 4
dat4$y <- ifelse(dat4$x == "pre", 40 + err, 40 + beta + err) + b
## Now omit the
## post measurement for ID 20:59
## pre measurement for ID 60:89
dat4 <- dat4[!(dat4$ID %in%  20:59 & dat4$x == "post"), ]
dat4 <- dat4[!(dat4$ID %in%  60:89 & dat4$x == "pre"), ]

library(lme4)

m1 <- lmer(y ~ x + (1 | ID), dat4)
summary(m1)

Output shows nearly 0 random ID variance:

Linear mixed model fit by REML ['lmerMod']
Formula: y ~ x + (1 | ID)
   Data: dat4

REML criterion at convergence: 313.3

Scaled residuals:
    Min      1Q  Median      3Q     Max
-2.4502 -0.6261 -0.0361  0.5753  3.5321

Random effects:
 Groups   Name        Variance  Std.Dev.
 ID       (Intercept) 7.342e-13 8.569e-07
 Residual             1.043e+00 1.021e+00
Number of obs: 108, groups:  ID, 89

Fixed effects:
            Estimate Std. Error t value
(Intercept)  39.8946     0.1330  299.99
xpost         4.2518     0.1974   21.54

I thought that was a happy result, the pre/post effect is estimated
reasonably and the estimator does not find a random effect if there is
none.

Then I put in a random effect.
set.seed(234234)
dat5 <- data.frame(ID = rep(1:89, 2), x = gl(2, 89, labels = c("pre", "post")))
err <- rnorm(length(dat5$x), 0, 1)
b <- rep(rnorm(89, 0, 1), 2)
beta <- 4
dat5$y <- ifelse(dat5$x == "pre", 40 + err, 40 + beta + err) + b
dat5 <- dat5[!(dat5$ID %in%  20:59 & dat5$x == "post"), ]
dat5 <- dat5[!(dat5$ID %in%  60:89 & dat5$x == "pre"), ]
m2 <- lmer(y ~ x + (1 | ID), dat5)
summary(m2)

> summary(m2)
Linear mixed model fit by REML ['lmerMod']
Formula: y ~ x + (1 | ID)
   Data: dat5

REML criterion at convergence: 367.1

Scaled residuals:
    Min      1Q  Median      3Q     Max
-1.8537 -0.3634 -0.0253  0.3611  2.1063

Random effects:
 Groups   Name        Variance Std.Dev.
 ID       (Intercept) 1.2441   1.1154
 Residual             0.6632   0.8144
Number of obs: 108, groups:  ID, 89

Fixed effects:
            Estimate Std. Error t value
(Intercept)  39.9205     0.1704  234.29
xpost         4.1333     0.2069   19.98


This "seems" to work reasonably.  What dangers await?


-- 
Paul E. Johnson   http://pj.freefaculty.org
Director, Center for Research Methods and Data Analysis http://crmda.ku.edu

To write to me directly, please address me at pauljohn at ku.edu.


From thierry@onkelinx @ending from inbo@be  Tue Nov 13 17:34:15 2018
From: thierry@onkelinx @ending from inbo@be (Thierry Onkelinx)
Date: Tue, 13 Nov 2018 17:34:15 +0100
Subject: [R-sig-ME] pre/post with partial participation
In-Reply-To: <CAErODj8ozMcZP-UCYn-=qGSHDdiX8tx8dKyC3aRaMXSUjPs5+w@mail.gmail.com>
References: <CAErODj8ozMcZP-UCYn-=qGSHDdiX8tx8dKyC3aRaMXSUjPs5+w@mail.gmail.com>
Message-ID: <CAJuCY5yZFGCihg_3j=QReCnSKAEY7ADTAKvB-kSxJJ9YSG1c0A@mail.gmail.com>

Dear Paul,

If the errors are much larger than the random effect, then the random
effect might take some of the errors. Especially if both pre and post
observations have an error in the same direction.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op di 13 nov. 2018 om 17:12 schreef Paul Johnson <pauljohn32 at gmail.com>:

> I have a crazy ANOVA question and would appreciate your advice.
>
> We have a project that did a pre-post measurement, but the
> participation in the data collection was haphazard.  There are only 19
> people that participated pre-post, but there are about 40 that
> participated only in the pre phase and 30 that participated in the
> post phase.
>
> I don't have the data to show you, but I made some up. I've got
> ID=1:19 for the ones who are both in pre and post data samples, and ID
> 20:59 are in pre only and 60:89 are post only.
>
> In my first example, the data has no true random effect and lmer gets
> the correct estimate, the random effect is estimated as 0.00, or close
> to it.  I find that slight differences in the way I generate the data
> (either I get exactly 0.0 or 7 x 10^-13 or similar).
>
> This way of making the data generates a "full pre/post" data set and
> then throws away pre and post observations for the missing cases:
>
> set.seed(234234)
> dat4 <- data.frame(ID = rep(1:89, 2), x = gl(2, 89, labels = c("pre",
> "post")))
> err <- rnorm(length(dat4$x), 0, 1)
> b <- 0
> beta <- 4
> dat4$y <- ifelse(dat4$x == "pre", 40 + err, 40 + beta + err) + b
> ## Now omit the
> ## post measurement for ID 20:59
> ## pre measurement for ID 60:89
> dat4 <- dat4[!(dat4$ID %in%  20:59 & dat4$x == "post"), ]
> dat4 <- dat4[!(dat4$ID %in%  60:89 & dat4$x == "pre"), ]
>
> library(lme4)
>
> m1 <- lmer(y ~ x + (1 | ID), dat4)
> summary(m1)
>
> Output shows nearly 0 random ID variance:
>
> Linear mixed model fit by REML ['lmerMod']
> Formula: y ~ x + (1 | ID)
>    Data: dat4
>
> REML criterion at convergence: 313.3
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -2.4502 -0.6261 -0.0361  0.5753  3.5321
>
> Random effects:
>  Groups   Name        Variance  Std.Dev.
>  ID       (Intercept) 7.342e-13 8.569e-07
>  Residual             1.043e+00 1.021e+00
> Number of obs: 108, groups:  ID, 89
>
> Fixed effects:
>             Estimate Std. Error t value
> (Intercept)  39.8946     0.1330  299.99
> xpost         4.2518     0.1974   21.54
>
> I thought that was a happy result, the pre/post effect is estimated
> reasonably and the estimator does not find a random effect if there is
> none.
>
> Then I put in a random effect.
> set.seed(234234)
> dat5 <- data.frame(ID = rep(1:89, 2), x = gl(2, 89, labels = c("pre",
> "post")))
> err <- rnorm(length(dat5$x), 0, 1)
> b <- rep(rnorm(89, 0, 1), 2)
> beta <- 4
> dat5$y <- ifelse(dat5$x == "pre", 40 + err, 40 + beta + err) + b
> dat5 <- dat5[!(dat5$ID %in%  20:59 & dat5$x == "post"), ]
> dat5 <- dat5[!(dat5$ID %in%  60:89 & dat5$x == "pre"), ]
> m2 <- lmer(y ~ x + (1 | ID), dat5)
> summary(m2)
>
> > summary(m2)
> Linear mixed model fit by REML ['lmerMod']
> Formula: y ~ x + (1 | ID)
>    Data: dat5
>
> REML criterion at convergence: 367.1
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -1.8537 -0.3634 -0.0253  0.3611  2.1063
>
> Random effects:
>  Groups   Name        Variance Std.Dev.
>  ID       (Intercept) 1.2441   1.1154
>  Residual             0.6632   0.8144
> Number of obs: 108, groups:  ID, 89
>
> Fixed effects:
>             Estimate Std. Error t value
> (Intercept)  39.9205     0.1704  234.29
> xpost         4.1333     0.2069   19.98
>
>
> This "seems" to work reasonably.  What dangers await?
>
>
> --
> Paul E. Johnson   http://pj.freefaculty.org
> Director, Center for Research Methods and Data Analysis
> http://crmda.ku.edu
>
> To write to me directly, please address me at pauljohn at ku.edu.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From @imon@kf @ending from zrc-@@zu@@i  Tue Nov 13 11:39:55 2018
From: @imon@kf @ending from zrc-@@zu@@i (Simona Kralj Fiser)
Date: Tue, 13 Nov 2018 11:39:55 +0100
Subject: [R-sig-ME] MCMCglmm: square root of the sampling variance of
 additive genetic variance
In-Reply-To: <CAJtCY7U9SsBjNrwbJ=5ytYj_RLU+fdjZ5ZO6ZyxJUNE9qsCj4Q@mail.gmail.com>
References: <CAPkBqkkp_Fc9v5g2aMTFH3jZTn4ECcwZKMOEwkKNc+bF-qxa1Q@mail.gmail.com>
 <CAJtCY7U9SsBjNrwbJ=5ytYj_RLU+fdjZ5ZO6ZyxJUNE9qsCj4Q@mail.gmail.com>
Message-ID: <CAPkBqk=zShnQDUct11ki29QRt6USvFQiqg8DVwfcnGPB+8DfoQ@mail.gmail.com>

Thank you very much. That helps a lot!
Simona

On Wed, 7 Nov 2018 at 18:33, Walid Mawass <walidmawass10 at gmail.com> wrote:

> Hello,
>
> The MCMCglmm estimates the posterior distribution of the additive and
> residual variances, to my knowledge then, there is no standard error
> associated with it rather you can output the HPD interval or highest
> posterior density interval at a 95 or 98% confidence interval, which you
> already have done. I stand to be corrected though.
>
> for your second question, it is quite easy, you just need use the basic
> plot function. In your case, plot(model$VCV[, "animal"]), this will return
> a plot of the posterior distribution and the iterations of the Markov Chain
> to visually check for autocorrelation between iterations.(there are other
> packages to plot mcmc outputs if you dont want to go with the basic plot,
> bayesplot comes to mind)
>
> Good luck
> --
> Walid Mawass
> Ph.D. candidate in Cellular and Molecular Biology
> Population Genetics Laboratory
> University of Qu?bec at Trois-Rivi?res
> 3351, boul. des Forges, C.P. 500
> Trois-Rivi?res (Qu?bec) G9A 5H7
> Telephone: 819-376-5011 poste 3384
>
>
> On Wed, Nov 7, 2018 at 12:09 PM Simona Kralj Fiser <simonakf at zrc-sazu.si>
> wrote:
>
> > Hi.
> > I used MCMCglmm to calculate the heritability of a trait [Va/(Va+Vr)];
> > e.g.:
> >
> >
> >
> prior<-list(G=list(G1=list(V=matrix(p.var*0.5),n=1)),R=list(V=matrix(p.var*0.5),n=1)
> >
> > model <- MCMCglmm(trait~ 1, random = ~animal, pedigree = pedigree,data =
> > data, nitt = 5000000, thin = 100, burnin = 150000, prior = prior,
> verbose =
> > FALSE)
> >
> > > summary(model)
> >
> >
> >
> >  Iterations = 150001:4999901
> >
> >  Thinning interval  = 100
> >
> >  Sample size  = 48500
> >
> >
> >
> >  DIC: 2032.226
> >
> >
> >
> >  G-structure:  ~animal
> >
> >
> >
> >        post.mean l-95% CI u-95% CI eff.samp
> >
> > animal     78.48    38.18    120.3    48500
> >
> >
> >
> >  R-structure:  ~units
> >
> >
> >
> >       post.mean l-95% CI u-95% CI eff.samp
> >
> > units     84.11     59.5    109.2    48500
> >
> >
> >
> >  Location effects: trait~ 1
> >
> >
> >
> >             post.mean l-95% CI u-95% CI eff.samp  pMCMC
> >
> > (Intercept)     6.918    4.589    9.091    48500 <2e-05 ***
> >
> >
> > > HPDinterval(model$VCV)
> >
> >           lower    upper
> >
> > animal 38.18195 120.3350
> >
> > units  59.50312 109.1574
> >
> > attr(,"Probability")
> >
> > [1] 0.95
> >
> >
> > > herit <- model$VCV[, "animal"]/(model$VCV[, "animal"] + model$VCV[,
> > "units"])
> >
> >
> > > mean(herit)
> >
> > [1] 0.4772017
> >
> >
> > > HPDinterval(herit, 0.95)
> >
> >          lower     upper
> >
> > var1 0.2940021 0.6576105
> >
> > attr(,"Probability")
> >
> > [1] 0.95
> >
> >
> > I have two questions:
> >
> > 1. I am trying to call the standard errors for additive and residual
> > variance
> >
> >
> > se(model$VCV[, "animal"]) does not work
> >
> >
> > I used
> >
> > > sd(model$VCV[, "animal"])
> >
> > [1] 21.36365
> >
> >
> >
> > > sd(model$VCV[, "units"])
> >
> > [1] 12.8011
> >
> >
> >
> > I wonder whether the SD (of Va) provides the square root of the sampling
> > variance of Va. Could you please confirm this? I am interested in
> > calculating the SE of Va to calculate the SEs of other statistics (e.g.,
> > CVa).
> >
> > 2. Also, is there a way to plot the posterior distribution of the
> > heritability (or Va) estimates?
> >
> > Thank you!
> >
> > Simona
> >
> > ---
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From H@Quene @ending from uu@nl  Wed Nov 14 13:16:48 2018
From: H@Quene @ending from uu@nl (=?UTF-8?Q?Hugo_Quen=c3=a9?=)
Date: Wed, 14 Nov 2018 13:16:48 +0100
Subject: [R-sig-ME] pre/post with partial participation
In-Reply-To: <mailman.17060.6.1542193202.58156.r-sig-mixed-models@r-project.org>
References: <mailman.17060.6.1542193202.58156.r-sig-mixed-models@r-project.org>
Message-ID: <517fcbdd-0132-04be-5aef-52e04af02fc7@uu.nl>

Dear Paul,

Thanks for the interesting example.
In this case we do know the true ID effects (b) so we can inspect the 
true and estimated ID effects:

> table(dat5$ID) -> tab5 # nr of obs per ID
> plot( b[1:89], ranef(m2)$ID[,1], xlab="true ID effect", ylab="estimated ID 
effect", pch=ifelse(tab5==2,16,1), cex=2,
 ???? main="m2 of dat5" )
> abline(a=0,b=1,lty=4)
> legend("top",pch=c(16,1), legend=c("two obs","one obs"), pt.cex=2, ncol=2 )

This confirms that the random estimates for ID deviate more from their 
true value if there is only 1 data point available than if there are 2 
data points available. With more data points per ID it becomes easier to 
separate ID (b) and residual (err) random effects. In other words, some 
of the err variance is now considered as part of ID variance. Thus with 
the incomplete data in dat5, the variance between ID is overestimated 
(estimate 1.24, true 1.00), as illustrated in the plot. Conversely, the 
err variance is underestimated (estimate 0.66, true 1.00).

HTH! With kind regards, Hugo Quen?


-- 

Prof.dr. Hugo Quen? | hoogleraar Kwantitatieve Methoden | onderwijsdirecteur Undergraduate School | Dept Talen Literatuur en Communicatie | Utrecht inst of Linguistics OTS | Universiteit Utrecht | Trans 10 | kamer1.43  | 3512 JK Utrecht | The Netherlands |+31 30  253 6070 |H.Quene at uu.nl  |www.uu.nl/gw/medewerkers/HQuene  |www.hugoquene.nl  |uu.academia.edu/HugoQuene <http://uu.academia.edu/HugoQuene>  |


	[[alternative HTML version deleted]]


From verkerk @ending from @hh@mpg@de  Wed Nov 14 10:34:21 2018
From: verkerk @ending from @hh@mpg@de (Annemarie Verkerk)
Date: Wed, 14 Nov 2018 10:34:21 +0100
Subject: [R-sig-ME] Multinomial mixed model in MCMCglmm,
 correcting for genealogy with random effects?
Message-ID: <eef70fa9-873b-e733-618e-1b805fa8db56@shh.mpg.de>

Dear all,

I have a three-way response variable and a mixture of continuous & 
categorical explanatory variables that I model in MCMCglmm. These are 
linguistic data from related languages and I want to correct for 
genealogy. I have given up on the idea of doing this with a full 
phylogeny, which is possible in MCMCglmm but I cannot reach convergence.

So I have decided to use different grouping variables (representing 
different hypotheses on how the languages are related). If I had a 
continuous response variable, I would use random effects, both 
intercepts & slopes if the model would converge, for the different 
explanatory variables. If the slopes all point in the same direction for 
the different groupings, I would feel confident that the effect of that 
variable is relevant.

But with a categorical response variable, random effects seem to work 
differently. I have read about them on prof. Bolker's github 
(https://bbolker.github.io/mixedmodels-misc/ecostats_chap.html) where 
they are also called "conditional modes", but he does not verbally 
interpret the findings. Hence I have three questions:

1. Can I correct for genealogy using random effects?

2. How to interpret output like on Ben Bolker's page above? For 
instance, if the CI of a grouping/family does not overlap with 0, does 
that mean that grouping/family is divergent? If so, in what way is it 
divergent? (To me, it seems like random effects for multinomial models 
do not relate to the explanatory variables, which confuses me.)

3. Is my MCMCglmm code below correct for what I need to do (i.e. correct 
for shared descent of the individual datapoints)?:

IJ <- (1/3) * (diag(2) + matrix(1, 2, 2))

prior = list(R = list(V = IJ, fix = 1),
 ???????????? G=list(G1 = list(V = diag(2), n = 2)))

m_full <- MCMCglmm(factor(3way_response) ~ trait:(latitude + longitude + 
cont1 + cont2 + cat1),
 ?????????????????? random = ~us(trait):grouping1,
 ?????????????????? rcov = ~us(trait):units,
 ?????????????????? prior = prior,
 ?????????????????? data = x,
 ?????????????????? family = "categorical",
 ?????????????????? verbose = FALSE,
 ?????????????????? nitt=550000000,
 ?????????????????? thin=1000000,
 ?????????????????? burnin=50000000,
 ?????????????????? pl=FALSE,
 ?????????????????? pr=TRUE,
 ?????????????????? slice=TRUE)

(I add "pr=TRUE" in the MCMCglmm call to get output on random effects in 
m_full$Sol.)

Apologies for the long message, but I would be very, very thankful for 
any help you can offer. Also pointers to good sources on how to 
understand this aspect of multinomial regression are very welcome.

With best wishes,
Annemarie


	[[alternative HTML version deleted]]


From roim@or m@ili@g off post@t@u@@c@il  Wed Nov 14 18:22:24 2018
From: roim@or m@ili@g off post@t@u@@c@il (roim@or m@ili@g off post@t@u@@c@il)
Date: Wed, 14 Nov 2018 19:22:24 +0200
Subject: [R-sig-ME] 
 Unclear output from MCMCglmm with categorical predictors
In-Reply-To: <D2DFFB1B-B549-4A4A-8AF7-716D1E93F263@ed.ac.uk>
References: <20181107155140.Horde.oHgXEzpRoYRb4u3sVchVdtA@webmail.tau.ac.il>
 <CAJtCY7UpBkrLZMGM1+Riv6U_epqfj_K5Xek=Cnjsdcdm7dvojw@mail.gmail.com>
 <20181112142652.Horde.oCI6KTpRoYRb6XGMgvSDMEA@webmail.tau.ac.il>
 <D2DFFB1B-B549-4A4A-8AF7-716D1E93F263@ed.ac.uk>
Message-ID: <20181114192224.Horde.ewY_UDpRoYRb7FnQVfMx63A@webmail.tau.ac.il>

Hi Jarrod,
Thanks so much for the helpful comments.
I was just about to check why models with and without the ginverse  
argument were giving similar estimates when a strong phylogenetic  
signal is expected... Much appreciated!
And thanks again Walid- I now understand what you meant in your answer.

All the best,
Roi


Quoting HADFIELD Jarrod <j.hadfield at ed.ac.uk>:

> Hi,
>
> Sorry - I also noted some errors in your example, and the original code.
>
> 1/ In the example you do not fix the residual variance (to one)  
> which you should do because it is not identifiable in threshold  
> models.
>
> 2/ You have what seems to be a phylogenetic correlation structure  
> passed to ginverse, but you don?t associate it with a random term.
>
> Cheers,
>
> Jarrod
>
>> On 12 Nov 2018, at 12:26, roimaor at post.tau.ac.il wrote:
>>
>>
>> Thanks for your response Walid.
>> However, it doesn't really answer my questions, so I'll try to  
>> clarify those.
>>
>> An intercept estimate in my model makes no biological sense because  
>> all species have both diet and habitat. This is why I chose to  
>> suppress the intercept.
>>
>> In the context of categorical predictors, suppressing the intercept  
>>  means that an arbitrarily-chosen category is taken as baseline,  
>> and the model estimates the difference (in the response variable)  
>> between this baseline and all other categories.
>> When dealing with two categorical traits as predictors, each data  
>> point is a combination of the effects of both traits, i.e. it is a  
>> combination of one category from each trait.
>>
>> If this is indeed the case, the baseline value must include one  
>> category of each predictor in the model, otherwise their effects  
>> would be confounded.
>>
>> For example, in my model I would expect one diet category AND one  
>> habitat category, say, 'herbivorous' and 'aquatic', to be  
>> baseline/intercept (un-estimated).
>> Instead, it seems that only 'herbivorous' is absorbed in the  
>> intercept, while all habitat classes have posterior estimates.
>>
>> My questions are:
>> 1- why does no habitat category get absorbed in the intercept? and
>> 2- what can I do to fix that?
>>
>> If it's at all useful, here is an example:
>>
>> ## data format
>> unique(Tdata$Habitat)
>> [1] TE AR AQ ST SA
>> Levels: AQ AR SA ST TE
>>
>> unique(Tdata$Diet)
>> [1] Herb Omni Faun
>> Levels: Faun Herb Omni
>>
>> ModTHRE <- MCMCglmm(Response ~ -1 + Habitat + Diet,
>>                    prior = list(R = list(V = 1, nu = 0.002)),
>>                    ginverse = list(Binomial=INphylo$Ainv),
>>                    burnin = 25000, nitt = 225000, thin = 200,
>>                    family = "threshold",
>>                    data = Tdata,
>>                    verbose = FALSE)
>>
>> ## model output
>> summary(ModTHRE)
>>
>> Iterations = 25001:224801
>> Thinning interval  = 200
>> Sample size  = 1000
>>
>> DIC: 2321.861
>>
>> R-structure:  ~units
>>
>>      post.mean l-95% CI u-95% CI eff.samp
>> units         1   0.9973    1.003     1000
>>
>> Location effects: Response ~ -1 + ForagingHab + Troph_Lev
>>
>>            post.mean l-95% CI u-95% CI eff.samp  pMCMC
>> HabitatST   -0.07612 -0.42629  0.33746   1000.0  0.694
>> HabitatTE   -0.36682 -0.52533 -0.21118   1000.0 <0.001 ***
>> HabitatSA   -0.04691 -0.25769  0.19636   1000.0  0.724
>> HabitatAR   -0.07302 -0.29900  0.16681    883.3  0.548
>> HabitatAQ   -0.47948 -0.82598 -0.15793   1000.0  0.002 **
>> DietHerb     0.30708  0.11255  0.48545   1000.0  0.002 **
>> DietOmni     0.05263 -0.12176  0.26105   1000.0  0.604
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>> Cutpoints:
>>                         post.mean l-95% CI u-95% CI eff.samp
>> cutpoint.traitActivity.1    0.4911    0.436   0.5495    877.6
>>
>>
>>
>> Any thoughts, ideas of what's going on here, or corrections of my  
>> mis-perceptions, are all very welcome.
>>
>> Many thanks,
>> Roi
>>
>>
>> Quoting Walid Mawass <walidmawass10 at gmail.com>:
>>
>>> Hello,
>>>
>>> by adding -1 into your model's formula, you are explicitly calling for no
>>> intercept term to be included in the estimates. If you do want an intercept
>>> term which would include a baseline level for each of your categorical
>>> variables then the syntax should be:
>>>
>>> MCMCglmm(Activity ~1 + Habitat + Diet + log(Mass) + Max.Temp... (explicit
>>> call for intercept term)
>>> or
>>> MCMCglmm(Activity ~ Habitat + Diet + log(Mass) + Max.Temp... (implicit call
>>> for intercept term)
>>>
>>> Hope this helps
>>> --
>>> Walid Mawass
>>> Ph.D. candidate in Cellular and Molecular Biology
>>> Population Genetics Laboratory
>>> University of Qu?bec at Trois-Rivi?res
>>> 3351, boul. des Forges, C.P. 500
>>> Trois-Rivi?res (Qu?bec) G9A 5H7
>>> Telephone: 819-376-5011 poste 3384
>>>
>>>
>>> On Wed, Nov 7, 2018 at 12:09 PM <roimaor at post.tau.ac.il> wrote:
>>>
>>>> Dear list members,
>>>>
>>>> I have a model with categorical response and categorical + continuous
>>>> predictors.
>>>>
>>>> My model has two categorical predictors: "diet" (3 levels) and
>>>> "habitat" (6 levels):
>>>>
>>>> THRE1 <- MCMCglmm(Activity ~ -1 + Habitat + Diet + log(Mass) + Max.Temp,
>>>>                      prior = list(R = list(V = 1, fix = 1)),
>>>>                      ginverse = list(Binomial=INphylo$Ainv),
>>>>                      family = "threshold",
>>>>                      data = Tdata)
>>>>
>>>> If I understand correctly, in this configuration the algorithm
>>>> shouldn't return estimated values for the effect of each level of a
>>>> categorical predictor, instead, it returns a contrast between that
>>>> level and another level which was arbitrarily chosen as the base
>>>> level. Each species (data point) has a value for each of these traits,
>>>> so I would expect them to be estimated independently, meaning that one
>>>> level of each predictor should be the 'baseline' and absorbed into the
>>>> global intercept. In that case I expect 2 contrasts to be returned for
>>>> diet categories and 5 contrasts for habitat.
>>>>
>>>> However, I get 2 estimates (presumably contrasts) for diet categories,
>>>> and 6 for habitat categories, i.e., no habitat category was designated
>>>> as baseline, which makes me question whether the estimates are
>>>> contrasts or actual effect sizes.
>>>>
>>>> My questions:
>>>> - Is the algorithm pooling all the predictor categories as if they
>>>> were a single trait with 8 levels?
>>>> - If the habitat effect estimates are contrasts - what are they compared
>>>> to?
>>>> - If they are effect sizes - what did I do to not get the contrasts as
>>>> I expected?
>>>>
>>>> Any help would be much appreciated!
>>>> Thanks,
>>>> --
>>>> Roi Maor
>>>> PhD candidate
>>>> School of Zoology, Tel Aviv University
>>>> Centre for Biodiversity and Environment Research, UCL
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.


From H@F@r@h @ending from tudelft@nl  Thu Nov 15 10:10:36 2018
From: H@F@r@h @ending from tudelft@nl (Haneen Farah - CITG)
Date: Thu, 15 Nov 2018 09:10:36 +0000
Subject: [R-sig-ME] R Caret package
Message-ID: <58f30964e8944c50b3862fbd06e0dd88@tudelft.nl>

Can R Caret package for cross validation be used with lmer (for a linear mixed effect model with a continuous dependent variable)? And are the random effects included when validating the lmer model on a new dataset? And if not what is the way to do that? Is there any other R package for this?

	[[alternative HTML version deleted]]


From Bill@Poling @ending from zeli@@com  Thu Nov 15 12:46:48 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Thu, 15 Nov 2018 11:46:48 +0000
Subject: [R-sig-ME] glmutli package assistance please
Message-ID: <BN7PR02MB507331821C148180EEB4951CEADC0@BN7PR02MB5073.namprd02.prod.outlook.com>

Hi, I have removed the pdf which was causing my e-mail to be blocked by moderators, my apologies.

https://www.jstatsoft.org/article/view/v034i12/v34i12.pdf

Original post:

Hello. I am still trying to get some of the examples in this glmulti pdf to work with my data.

I have sent e-mails to author addresses provided but no response or bounced back as in valid.

I am not sure if this is more likely to receive support on r-help or r-sig-mixed-models, hence the double posting, my apologies in advance.

I am windows 10 -- R3.5.1 -- RStudio Version 1.1.456

glmulti: An R Package for Easy Automated Model Selection with (Generalized) Linear Models

pdf Attached:

On page 13 section 3.1 of the pdf they describe a routine to estimate the candidate models possible.

Their data description:
The number of levels factors have does not affect the number of candidate models, only their complexity. We use a data frame dod, containing as a first column a dummy response variable, the next 6 columns are dummy factors with three levels, and the last six are dummy covariates.
To compute the number of candidate models when there are between 1 and 6 factors and 1 and 6 covariates, we call glmulti with method = "d" and data = dod. We use names(dod) to specify the names of the response variable and of the predictors. We vary the number of factors and covariates, this way:


Their routine:
dd <- matrix(nc = 6, nr = 6) for(i in 1:6) for(j in 1:6) dd[i, j] <- glmulti(names(dod)[1],
+ names(dod)[c(2:(1 + i), 8:(7 + j))], data = dod, method = "d")

My data, I organized it similar to the example, Response, Factor, Factor, 5 covariates

Classes 'data.table' and 'data.frame':23141 obs. of  8 variables:
 $ Editnumber2    : num  0 0 1 1 1 1 1 1 1 1 ...
 $ PatientGender  : Factor w/ 3 levels "F","M","U": 1 1 2 2 2 2 1 1 1 1 ...
 $ B1             : Factor w/ 14 levels "Z","A","C","D",..: 2 2 3 3 2 2 2 2 2 2 ...
 $ SavingsReversed: num  -0.139 -0.139 -0.139 -0.139 -0.139 ...
 $ productID      : int  3 3 3 3 3 3 3 3 1 1 ...
 $ ProviderID     : int  113676 113676 113964 113964 114278 114278 114278 114278 114278 114278 ...
 $ ModCnt         : int  0 0 0 0 1 1 1 1 1 1 ...
 $ B2             : num  -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 ...
 - attr(*, ".internal.selfref")=<externalptr>

Trying to follow what they did, my routine, Editnumber2 is the response variable:

dd <- matrix(nc = 2, nr = 5)
for(i in 1:2) for(j in 1:5) dd[i, j] <- glmulti(names(r1)[1], names(r1)[c(2:(1 + i), 7:(6 + j))], data = r1, method = "d")

The error: Error in terms.formula(formula, data = data) :
  invalid model formula in ExtractVars

I have tried changing the numbers around but get results like this:

Initialization...
TASK: Diagnostic of candidate set.
Sample size: 23141
2 factor(s).
2 covariate(s). <--appears to be missing 3 of the covariates for some reason?
0 f exclusion(s).
0 c exclusion(s).
0 f:f exclusion(s).
0 c:c exclusion(s).
0 f:c exclusion(s).
Size constraints: min =  0 max = -1
Complexity constraints: min =  0 max = -1 Your candidate set contains 250 models.
Error in `[<-`(`*tmp*`, i, j, value = glmulti(names(r1)[1], names(r1)[c(2:(1 +  :
  subscript out of bounds


I hope someone can help straighten out my code, thank you.


WHP



Confidentiality Notice This message is sent from Zelis. ...{{dropped:13}}


From bgunter@4567 @ending from gm@il@com  Thu Nov 15 16:43:00 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Thu, 15 Nov 2018 07:43:00 -0800
Subject: [R-sig-ME] [R] glmutli package assistance please
In-Reply-To: <BN7PR02MB507331821C148180EEB4951CEADC0@BN7PR02MB5073.namprd02.prod.outlook.com>
References: <BN7PR02MB507331821C148180EEB4951CEADC0@BN7PR02MB5073.namprd02.prod.outlook.com>
Message-ID: <CAGxFJbSVZaUeubfuxdbk1JSESg2sZFNDR9hT=DDU52y18zJqrQ@mail.gmail.com>

Please do not cross post (see te posting guide). This should go only
to the mixed models list.

-- Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Nov 15, 2018 at 3:47 AM Bill Poling <Bill.Poling at zelis.com> wrote:
>
> Hi, I have removed the pdf which was causing my e-mail to be blocked by moderators, my apologies.
>
> https://www.jstatsoft.org/article/view/v034i12/v34i12.pdf
>
> Original post:
>
> Hello. I am still trying to get some of the examples in this glmulti pdf to work with my data.
>
> I have sent e-mails to author addresses provided but no response or bounced back as in valid.
>
> I am not sure if this is more likely to receive support on r-help or r-sig-mixed-models, hence the double posting, my apologies in advance.
>
> I am windows 10 -- R3.5.1 -- RStudio Version 1.1.456
>
> glmulti: An R Package for Easy Automated Model Selection with (Generalized) Linear Models
>
> pdf Attached:
>
> On page 13 section 3.1 of the pdf they describe a routine to estimate the candidate models possible.
>
> Their data description:
> The number of levels factors have does not affect the number of candidate models, only their complexity. We use a data frame dod, containing as a first column a dummy response variable, the next 6 columns are dummy factors with three levels, and the last six are dummy covariates.
> To compute the number of candidate models when there are between 1 and 6 factors and 1 and 6 covariates, we call glmulti with method = "d" and data = dod. We use names(dod) to specify the names of the response variable and of the predictors. We vary the number of factors and covariates, this way:
>
>
> Their routine:
> dd <- matrix(nc = 6, nr = 6) for(i in 1:6) for(j in 1:6) dd[i, j] <- glmulti(names(dod)[1],
> + names(dod)[c(2:(1 + i), 8:(7 + j))], data = dod, method = "d")
>
> My data, I organized it similar to the example, Response, Factor, Factor, 5 covariates
>
> Classes 'data.table' and 'data.frame':23141 obs. of  8 variables:
>  $ Editnumber2    : num  0 0 1 1 1 1 1 1 1 1 ...
>  $ PatientGender  : Factor w/ 3 levels "F","M","U": 1 1 2 2 2 2 1 1 1 1 ...
>  $ B1             : Factor w/ 14 levels "Z","A","C","D",..: 2 2 3 3 2 2 2 2 2 2 ...
>  $ SavingsReversed: num  -0.139 -0.139 -0.139 -0.139 -0.139 ...
>  $ productID      : int  3 3 3 3 3 3 3 3 1 1 ...
>  $ ProviderID     : int  113676 113676 113964 113964 114278 114278 114278 114278 114278 114278 ...
>  $ ModCnt         : int  0 0 0 0 1 1 1 1 1 1 ...
>  $ B2             : num  -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 ...
>  - attr(*, ".internal.selfref")=<externalptr>
>
> Trying to follow what they did, my routine, Editnumber2 is the response variable:
>
> dd <- matrix(nc = 2, nr = 5)
> for(i in 1:2) for(j in 1:5) dd[i, j] <- glmulti(names(r1)[1], names(r1)[c(2:(1 + i), 7:(6 + j))], data = r1, method = "d")
>
> The error: Error in terms.formula(formula, data = data) :
>   invalid model formula in ExtractVars
>
> I have tried changing the numbers around but get results like this:
>
> Initialization...
> TASK: Diagnostic of candidate set.
> Sample size: 23141
> 2 factor(s).
> 2 covariate(s). <--appears to be missing 3 of the covariates for some reason?
> 0 f exclusion(s).
> 0 c exclusion(s).
> 0 f:f exclusion(s).
> 0 c:c exclusion(s).
> 0 f:c exclusion(s).
> Size constraints: min =  0 max = -1
> Complexity constraints: min =  0 max = -1 Your candidate set contains 250 models.
> Error in `[<-`(`*tmp*`, i, j, value = glmulti(names(r1)[1], names(r1)[c(2:(1 +  :
>   subscript out of bounds
>
>
> I hope someone can help straighten out my code, thank you.
>
>
> WHP
>
>
>
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:13}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From li@t@ @ending from dewey@myzen@co@uk  Thu Nov 15 16:52:48 2018
From: li@t@ @ending from dewey@myzen@co@uk (Michael Dewey)
Date: Thu, 15 Nov 2018 15:52:48 +0000
Subject: [R-sig-ME] [R] glmutli package assistance please
In-Reply-To: <CAGxFJbSVZaUeubfuxdbk1JSESg2sZFNDR9hT=DDU52y18zJqrQ@mail.gmail.com>
References: <BN7PR02MB507331821C148180EEB4951CEADC0@BN7PR02MB5073.namprd02.prod.outlook.com>
 <CAGxFJbSVZaUeubfuxdbk1JSESg2sZFNDR9hT=DDU52y18zJqrQ@mail.gmail.com>
Message-ID: <626a2e4a-93ef-b4bf-83b8-5b2424c974c6@dewey.myzen.co.uk>

Dear Bert

Since glmulti operates on glm/lm models I think, although I agree about 
not cross-posting, that it was OK here. Perhaps I do not understand the 
full significance of mixed models though.

Michael

On 15/11/2018 15:43, Bert Gunter wrote:
> Please do not cross post (see te posting guide). This should go only
> to the mixed models list.
> 
> -- Bert
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> On Thu, Nov 15, 2018 at 3:47 AM Bill Poling <Bill.Poling at zelis.com> wrote:
>>
>> Hi, I have removed the pdf which was causing my e-mail to be blocked by moderators, my apologies.
>>
>> https://www.jstatsoft.org/article/view/v034i12/v34i12.pdf
>>
>> Original post:
>>
>> Hello. I am still trying to get some of the examples in this glmulti pdf to work with my data.
>>
>> I have sent e-mails to author addresses provided but no response or bounced back as in valid.
>>
>> I am not sure if this is more likely to receive support on r-help or r-sig-mixed-models, hence the double posting, my apologies in advance.
>>
>> I am windows 10 -- R3.5.1 -- RStudio Version 1.1.456
>>
>> glmulti: An R Package for Easy Automated Model Selection with (Generalized) Linear Models
>>
>> pdf Attached:
>>
>> On page 13 section 3.1 of the pdf they describe a routine to estimate the candidate models possible.
>>
>> Their data description:
>> The number of levels factors have does not affect the number of candidate models, only their complexity. We use a data frame dod, containing as a first column a dummy response variable, the next 6 columns are dummy factors with three levels, and the last six are dummy covariates.
>> To compute the number of candidate models when there are between 1 and 6 factors and 1 and 6 covariates, we call glmulti with method = "d" and data = dod. We use names(dod) to specify the names of the response variable and of the predictors. We vary the number of factors and covariates, this way:
>>
>>
>> Their routine:
>> dd <- matrix(nc = 6, nr = 6) for(i in 1:6) for(j in 1:6) dd[i, j] <- glmulti(names(dod)[1],
>> + names(dod)[c(2:(1 + i), 8:(7 + j))], data = dod, method = "d")
>>
>> My data, I organized it similar to the example, Response, Factor, Factor, 5 covariates
>>
>> Classes 'data.table' and 'data.frame':23141 obs. of  8 variables:
>>   $ Editnumber2    : num  0 0 1 1 1 1 1 1 1 1 ...
>>   $ PatientGender  : Factor w/ 3 levels "F","M","U": 1 1 2 2 2 2 1 1 1 1 ...
>>   $ B1             : Factor w/ 14 levels "Z","A","C","D",..: 2 2 3 3 2 2 2 2 2 2 ...
>>   $ SavingsReversed: num  -0.139 -0.139 -0.139 -0.139 -0.139 ...
>>   $ productID      : int  3 3 3 3 3 3 3 3 1 1 ...
>>   $ ProviderID     : int  113676 113676 113964 113964 114278 114278 114278 114278 114278 114278 ...
>>   $ ModCnt         : int  0 0 0 0 1 1 1 1 1 1 ...
>>   $ B2             : num  -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 ...
>>   - attr(*, ".internal.selfref")=<externalptr>
>>
>> Trying to follow what they did, my routine, Editnumber2 is the response variable:
>>
>> dd <- matrix(nc = 2, nr = 5)
>> for(i in 1:2) for(j in 1:5) dd[i, j] <- glmulti(names(r1)[1], names(r1)[c(2:(1 + i), 7:(6 + j))], data = r1, method = "d")
>>
>> The error: Error in terms.formula(formula, data = data) :
>>    invalid model formula in ExtractVars
>>
>> I have tried changing the numbers around but get results like this:
>>
>> Initialization...
>> TASK: Diagnostic of candidate set.
>> Sample size: 23141
>> 2 factor(s).
>> 2 covariate(s). <--appears to be missing 3 of the covariates for some reason?
>> 0 f exclusion(s).
>> 0 c exclusion(s).
>> 0 f:f exclusion(s).
>> 0 c:c exclusion(s).
>> 0 f:c exclusion(s).
>> Size constraints: min =  0 max = -1
>> Complexity constraints: min =  0 max = -1 Your candidate set contains 250 models.
>> Error in `[<-`(`*tmp*`, i, j, value = glmulti(names(r1)[1], names(r1)[c(2:(1 +  :
>>    subscript out of bounds
>>
>>
>> I hope someone can help straighten out my code, thank you.
>>
>>
>> WHP
>>
>>
>>
>> Confidentiality Notice This message is sent from Zelis. ...{{dropped:13}}
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From Bill@Poling @ending from zeli@@com  Thu Nov 15 19:00:18 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Thu, 15 Nov 2018 18:00:18 +0000
Subject: [R-sig-ME] [R] glmutli package assistance please
Message-ID: <BN7PR02MB5073722F7B0AAAE5ACC71116EADC0@BN7PR02MB5073.namprd02.prod.outlook.com>

Hello Michael, thank you for your responses.

I will have to look through the myriad of iterations of attempts at all this on this project but it seems to me that I tried that? Or tried to convert the integers to numeric and it errored out?

If not I certainly will do so and let know, thank you Sir!

WHP



From: Michael Dewey <lists at dewey.myzen.co.uk>
Sent: Thursday, November 15, 2018 7:24 AM
To: Bill Poling <Bill.Poling at zelis.com>; r-sig-mixed-models at r-project.org; r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] glmutli package assistance please

Dear Bill

I am not sure what is going on here but I notice that 2 of your
covariates are numeric and 3 integer. What happens if you make them all
numeric?

Michael

On 15/11/2018 11:46, Bill Poling wrote:
> Hi, I have removed the pdf which was causing my e-mail to be blocked by moderators, my apologies.
>
> https://www.jstatsoft.org/article/view/v034i12/v34i12.pdf
>
> Original post:
>
> Hello. I am still trying to get some of the examples in this glmulti pdf to work with my data.
>
> I have sent e-mails to author addresses provided but no response or bounced back as in valid.
>
> I am not sure if this is more likely to receive support on r-help or r-sig-mixed-models, hence the double posting, my apologies in advance.
>
> I am windows 10 -- R3.5.1 -- RStudio Version 1.1.456
>
> glmulti: An R Package for Easy Automated Model Selection with (Generalized) Linear Models
>
> pdf Attached:
>
> On page 13 section 3.1 of the pdf they describe a routine to estimate the candidate models possible.
>
> Their data description:
> The number of levels factors have does not affect the number of candidate models, only their complexity. We use a data frame dod, containing as a first column a dummy response variable, the next 6 columns are dummy factors with three levels, and the last six are dummy covariates.
> To compute the number of candidate models when there are between 1 and 6 factors and 1 and 6 covariates, we call glmulti with method = "d" and data = dod. We use names(dod) to specify the names of the response variable and of the predictors. We vary the number of factors and covariates, this way:
>
>
> Their routine:
> dd <- matrix(nc = 6, nr = 6) for(i in 1:6) for(j in 1:6) dd[i, j] <- glmulti(names(dod)[1],
> + names(dod)[c(2:(1 + i), 8:(7 + j))], data = dod, method = "d")
>
> My data, I organized it similar to the example, Response, Factor, Factor, 5 covariates
>
> Classes 'data.table' and 'data.frame':23141 obs. of 8 variables:
> $ Editnumber2 : num 0 0 1 1 1 1 1 1 1 1 ...
> $ PatientGender : Factor w/ 3 levels "F","M","U": 1 1 2 2 2 2 1 1 1 1 ...
> $ B1 : Factor w/ 14 levels "Z","A","C","D",..: 2 2 3 3 2 2 2 2 2 2 ...
> $ SavingsReversed: num -0.139 -0.139 -0.139 -0.139 -0.139 ...
> $ productID : int 3 3 3 3 3 3 3 3 1 1 ...
> $ ProviderID : int 113676 113676 113964 113964 114278 114278 114278 114278 114278 114278 ...
> $ ModCnt : int 0 0 0 0 1 1 1 1 1 1 ...
> $ B2 : num -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 ...
> - attr(*, ".internal.selfref")=<externalptr>
>
> Trying to follow what they did, my routine, Editnumber2 is the response variable:
>
> dd <- matrix(nc = 2, nr = 5)
> for(i in 1:2) for(j in 1:5) dd[i, j] <- glmulti(names(r1)[1], names(r1)[c(2:(1 + i), 7:(6 + j))], data = r1, method = "d")
>
> The error: Error in terms.formula(formula, data = data) :
> invalid model formula in ExtractVars
>
> I have tried changing the numbers around but get results like this:
>
> Initialization...
> TASK: Diagnostic of candidate set.
> Sample size: 23141
> 2 factor(s).
> 2 covariate(s). <--appears to be missing 3 of the covariates for some reason?
> 0 f exclusion(s).
> 0 c exclusion(s).
> 0 f:f exclusion(s).
> 0 c:c exclusion(s).
> 0 f:c exclusion(s).
> Size constraints: min = 0 max = -1
> Complexity constraints: min = 0 max = -1 Your candidate set contains 250 models.
> Error in `[<-`(`*tmp*`, i, j, value = glmulti(names(r1)[1], names(r1)[c(2:(1 + :
> subscript out of bounds
>
>
> I hope someone can help straighten out my code, thank you.
>
>
> WHP
>
>
>
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:13}}
>
> ______________________________________________
> mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

--
Michael
http://www.dewey.myzen.co.uk/home.html

Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

From Bill@Poling @ending from zeli@@com  Thu Nov 15 21:01:11 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Thu, 15 Nov 2018 20:01:11 +0000
Subject: [R-sig-ME] [R] glmutli package assistance please - error Solved
Message-ID: <BN7PR02MB5073EDC4B657D6AEB8F10E6FEADC0@BN7PR02MB5073.namprd02.prod.outlook.com>

Hello Michael and all.

1. I replaced INT with Numeric that did not solve the error  problem.
2. However I discovered that my matrix was the problem, I had it set to 2,5 and when I set it to 6,6 I no longer get the error, which was due to not having the correct or more than necessary fields in the matrix.
Clues came from: https://stackoverflow.com/questions/15031338/subscript-out-of-bounds-general-definition-and-solution

Following the author's pattern they described their data as needing matrix = 6,6 due to 6 factors and 6 covariates .

I set my matrix to the number of Factors and Covariates, 2-5 and that caused the error.
[,1]  [,2]
[1,] 497664 10368
[2,]     NA    NA
[3,]     NA    NA
[4,]     NA    NA
[5,]     NA    NA

dd <- matrix(nc = 6, nr = 6) View(dd)
for(i in 1:2) for(j in 1:5) dd[i, j] <- glmulti(names(r1a)[1], names(r1a)[c(2:(1 + i), 8:(3 + j))], data = r1a, method = "d")

[,1]   [,2] [,3] [,4] [,5] [,6]
[1,]   497664  10368  432   36    6   NA
[2,] 16000000 200000 5000  250   25   NA
[3,]       NA     NA   NA   NA   NA   NA
[4,]       NA     NA   NA   NA   NA   NA
[5,]       NA     NA   NA   NA   NA   NA
[6,]       NA     NA   NA   NA   NA   NA

Thank you for your support!

WHP

From: Michael Dewey <lists at dewey.myzen.co.uk>
Sent: Thursday, November 15, 2018 7:24 AM
To: Bill Poling <Bill.Poling at zelis.com>; r-sig-mixed-models at r-project.org; r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] glmutli package assistance please

Dear Bill

I am not sure what is going on here but I notice that 2 of your
covariates are numeric and 3 integer. What happens if you make them all
numeric?

Michael

On 15/11/2018 11:46, Bill Poling wrote:
> Hi, I have removed the pdf which was causing my e-mail to be blocked by moderators, my apologies.
>
> https://www.jstatsoft.org/article/view/v034i12/v34i12.pdf
>
> Original post:
>
> Hello. I am still trying to get some of the examples in this glmulti pdf to work with my data.
>
> I have sent e-mails to author addresses provided but no response or bounced back as in valid.
>
> I am not sure if this is more likely to receive support on r-help or r-sig-mixed-models, hence the double posting, my apologies in advance.
>
> I am windows 10 -- R3.5.1 -- RStudio Version 1.1.456
>
> glmulti: An R Package for Easy Automated Model Selection with (Generalized) Linear Models
>
> pdf Attached:
>
> On page 13 section 3.1 of the pdf they describe a routine to estimate the candidate models possible.
>
> Their data description:
> The number of levels factors have does not affect the number of candidate models, only their complexity. We use a data frame dod, containing as a first column a dummy response variable, the next 6 columns are dummy factors with three levels, and the last six are dummy covariates.
> To compute the number of candidate models when there are between 1 and 6 factors and 1 and 6 covariates, we call glmulti with method = "d" and data = dod. We use names(dod) to specify the names of the response variable and of the predictors. We vary the number of factors and covariates, this way:
>
>
> Their routine:
> dd <- matrix(nc = 6, nr = 6) for(i in 1:6) for(j in 1:6) dd[i, j] <- glmulti(names(dod)[1],
> + names(dod)[c(2:(1 + i), 8:(7 + j))], data = dod, method = "d")
>
> My data, I organized it similar to the example, Response, Factor, Factor, 5 covariates
>
> Classes 'data.table' and 'data.frame':23141 obs. of 8 variables:
> $ Editnumber2 : num 0 0 1 1 1 1 1 1 1 1 ...
> $ PatientGender : Factor w/ 3 levels "F","M","U": 1 1 2 2 2 2 1 1 1 1 ...
> $ B1 : Factor w/ 14 levels "Z","A","C","D",..: 2 2 3 3 2 2 2 2 2 2 ...
> $ SavingsReversed: num -0.139 -0.139 -0.139 -0.139 -0.139 ...
> $ productID : int 3 3 3 3 3 3 3 3 1 1 ...
> $ ProviderID : int 113676 113676 113964 113964 114278 114278 114278 114278 114278 114278 ...
> $ ModCnt : int 0 0 0 0 1 1 1 1 1 1 ...
> $ B2 : num -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 ...
> - attr(*, ".internal.selfref")=<externalptr>
>
> Trying to follow what they did, my routine, Editnumber2 is the response variable:
>
> dd <- matrix(nc = 2, nr = 5)
> for(i in 1:2) for(j in 1:5) dd[i, j] <- glmulti(names(r1)[1], names(r1)[c(2:(1 + i), 7:(6 + j))], data = r1, method = "d")
>
> The error: Error in terms.formula(formula, data = data) :
> invalid model formula in ExtractVars
>
> I have tried changing the numbers around but get results like this:
>
> Initialization...
> TASK: Diagnostic of candidate set.
> Sample size: 23141
> 2 factor(s).
> 2 covariate(s). <--appears to be missing 3 of the covariates for some reason?
> 0 f exclusion(s).
> 0 c exclusion(s).
> 0 f:f exclusion(s).
> 0 c:c exclusion(s).
> 0 f:c exclusion(s).
> Size constraints: min = 0 max = -1
> Complexity constraints: min = 0 max = -1 Your candidate set contains 250 models.
> Error in `[<-`(`*tmp*`, i, j, value = glmulti(names(r1)[1], names(r1)[c(2:(1 + :
> subscript out of bounds
>
>
> I hope someone can help straighten out my code, thank you.
>
>
> WHP
>
>
>
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:13}}
>
> ______________________________________________
> mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

--
Michael
http://www.dewey.myzen.co.uk/home.html

Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

From high@t@t @ending from high@t@t@com  Fri Nov 16 08:45:33 2018
From: high@t@t @ending from high@t@t@com (Highland Statistics Ltd)
Date: Fri, 16 Nov 2018 09:45:33 +0200
Subject: [R-sig-ME] Course: Introduction to GAM and GAMM with R.
Message-ID: <3951bdb4-bfbd-a2c2-4b27-c8b7b19f7d69@highstat.com>

Apologies for cross-posting

We would like to announce the following statistics course in Lisbon.

Course: Introduction to GAM and GAMM with R.
Where:? Lisbon, Portugal.
When:?? 25 February 2019 - 1 March 2019
Course website: http://highstat.com/index.php/courses-upcoming
Course flyer: 
http://highstat.com/Courses/Flyers/2019/Flyer2019_02Lisbon_GAMM_V3.pdf

Kind regards,


Alain Zuur

-- 

Dr. Alain F. Zuur
Highland Statistics Ltd.
9 St Clair Wynd
AB41 6DZ Newburgh, UK
Email: highstat at highstat.com
URL:   www.highstat.com

And:
NIOZ Royal Netherlands Institute for Sea Research,
Department of Coastal Systems, and Utrecht University,
P.O. Box 59, 1790 AB Den Burg,
Texel, The Netherlands



Author of:
1. Beginner's Guide to Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA. (2017).
2. Beginner's Guide to Zero-Inflated Models with R (2016).
3. Beginner's Guide to Data Exploration and Visualisation with R (2015).
4. Beginner's Guide to GAMM with R (2014).
5. Beginner's Guide to GLM and GLMM with R (2013).
6. Beginner's Guide to GAM with R (2012).
7. Zero Inflated Models and GLMM with R (2012).
8. A Beginner's Guide to R (2009).
9. Mixed effects models and extensions in ecology with R (2009).
10. Analysing Ecological Data (2007).


From bgunter@4567 @ending from gm@il@com  Thu Nov 15 17:03:09 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Thu, 15 Nov 2018 08:03:09 -0800
Subject: [R-sig-ME] [R] glmutli package assistance please
In-Reply-To: <626a2e4a-93ef-b4bf-83b8-5b2424c974c6@dewey.myzen.co.uk>
References: <BN7PR02MB507331821C148180EEB4951CEADC0@BN7PR02MB5073.namprd02.prod.outlook.com>
 <CAGxFJbSVZaUeubfuxdbk1JSESg2sZFNDR9hT=DDU52y18zJqrQ@mail.gmail.com>
 <626a2e4a-93ef-b4bf-83b8-5b2424c974c6@dewey.myzen.co.uk>
Message-ID: <CAGxFJbQRYW8uR=R+K1cM46XmyVima0BcDHynwYd9iS42GdGSEg@mail.gmail.com>

OK. Then post here but *not* on mixed models list. One or the other,
exclusive or.

-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Nov 15, 2018 at 7:52 AM Michael Dewey <lists at dewey.myzen.co.uk> wrote:
>
> Dear Bert
>
> Since glmulti operates on glm/lm models I think, although I agree about
> not cross-posting, that it was OK here. Perhaps I do not understand the
> full significance of mixed models though.
>
> Michael
>
> On 15/11/2018 15:43, Bert Gunter wrote:
> > Please do not cross post (see te posting guide). This should go only
> > to the mixed models list.
> >
> > -- Bert
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> > and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> > On Thu, Nov 15, 2018 at 3:47 AM Bill Poling <Bill.Poling at zelis.com> wrote:
> >>
> >> Hi, I have removed the pdf which was causing my e-mail to be blocked by moderators, my apologies.
> >>
> >> https://www.jstatsoft.org/article/view/v034i12/v34i12.pdf
> >>
> >> Original post:
> >>
> >> Hello. I am still trying to get some of the examples in this glmulti pdf to work with my data.
> >>
> >> I have sent e-mails to author addresses provided but no response or bounced back as in valid.
> >>
> >> I am not sure if this is more likely to receive support on r-help or r-sig-mixed-models, hence the double posting, my apologies in advance.
> >>
> >> I am windows 10 -- R3.5.1 -- RStudio Version 1.1.456
> >>
> >> glmulti: An R Package for Easy Automated Model Selection with (Generalized) Linear Models
> >>
> >> pdf Attached:
> >>
> >> On page 13 section 3.1 of the pdf they describe a routine to estimate the candidate models possible.
> >>
> >> Their data description:
> >> The number of levels factors have does not affect the number of candidate models, only their complexity. We use a data frame dod, containing as a first column a dummy response variable, the next 6 columns are dummy factors with three levels, and the last six are dummy covariates.
> >> To compute the number of candidate models when there are between 1 and 6 factors and 1 and 6 covariates, we call glmulti with method = "d" and data = dod. We use names(dod) to specify the names of the response variable and of the predictors. We vary the number of factors and covariates, this way:
> >>
> >>
> >> Their routine:
> >> dd <- matrix(nc = 6, nr = 6) for(i in 1:6) for(j in 1:6) dd[i, j] <- glmulti(names(dod)[1],
> >> + names(dod)[c(2:(1 + i), 8:(7 + j))], data = dod, method = "d")
> >>
> >> My data, I organized it similar to the example, Response, Factor, Factor, 5 covariates
> >>
> >> Classes 'data.table' and 'data.frame':23141 obs. of  8 variables:
> >>   $ Editnumber2    : num  0 0 1 1 1 1 1 1 1 1 ...
> >>   $ PatientGender  : Factor w/ 3 levels "F","M","U": 1 1 2 2 2 2 1 1 1 1 ...
> >>   $ B1             : Factor w/ 14 levels "Z","A","C","D",..: 2 2 3 3 2 2 2 2 2 2 ...
> >>   $ SavingsReversed: num  -0.139 -0.139 -0.139 -0.139 -0.139 ...
> >>   $ productID      : int  3 3 3 3 3 3 3 3 1 1 ...
> >>   $ ProviderID     : int  113676 113676 113964 113964 114278 114278 114278 114278 114278 114278 ...
> >>   $ ModCnt         : int  0 0 0 0 1 1 1 1 1 1 ...
> >>   $ B2             : num  -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 ...
> >>   - attr(*, ".internal.selfref")=<externalptr>
> >>
> >> Trying to follow what they did, my routine, Editnumber2 is the response variable:
> >>
> >> dd <- matrix(nc = 2, nr = 5)
> >> for(i in 1:2) for(j in 1:5) dd[i, j] <- glmulti(names(r1)[1], names(r1)[c(2:(1 + i), 7:(6 + j))], data = r1, method = "d")
> >>
> >> The error: Error in terms.formula(formula, data = data) :
> >>    invalid model formula in ExtractVars
> >>
> >> I have tried changing the numbers around but get results like this:
> >>
> >> Initialization...
> >> TASK: Diagnostic of candidate set.
> >> Sample size: 23141
> >> 2 factor(s).
> >> 2 covariate(s). <--appears to be missing 3 of the covariates for some reason?
> >> 0 f exclusion(s).
> >> 0 c exclusion(s).
> >> 0 f:f exclusion(s).
> >> 0 c:c exclusion(s).
> >> 0 f:c exclusion(s).
> >> Size constraints: min =  0 max = -1
> >> Complexity constraints: min =  0 max = -1 Your candidate set contains 250 models.
> >> Error in `[<-`(`*tmp*`, i, j, value = glmulti(names(r1)[1], names(r1)[c(2:(1 +  :
> >>    subscript out of bounds
> >>
> >>
> >> I hope someone can help straighten out my code, thank you.
> >>
> >>
> >> WHP
> >>
> >>
> >>
> >> Confidentiality Notice This message is sent from Zelis. ...{{dropped:13}}
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html


From brook@@log@n @ending from gene@com  Thu Nov 15 17:38:27 2018
From: brook@@log@n @ending from gene@com (Logan Brooks)
Date: Thu, 15 Nov 2018 08:38:27 -0800
Subject: [R-sig-ME] Simulated mean prediction (lmer or lme) and CI
Message-ID: <CAB2jP6cmt2pL+SFr9vJxSOmvy0YeaqrhXbACX-Ln3Vf_Q4g8Ww@mail.gmail.com>

Hi all,

I'm hoping to get some guidance on doing double delta cQTc analysis using
linear mixed effects.  I have not done this type of modeling before but I
want to create a single fitted line for my data with the associated CI and
then calc the difference between my TX arms (0,1 binary treatment
indicator) and the CI on those estimates but I'm stumped on whether I'm
calculating things correctly or not.

Below is my current model
check3 <- lmer(CHblQTCF ~ TX + CP + popDQTcF + TIME1 + (1 +
CP|Subject),REML = FALSE, data = eg_final)

(using merTools:: predict interval)
PI <- predictInterval(merMod = check2, newdata = eg_final,
                         level = 0.90, n.sims = 1000,
                         stat = "mean", type="linear.prediction",
                         include.resid.var = TRUE)

This gives individual fits and CIs for each subject but how would I get a
mean fit and CI for the population?

I believe something along these lines is required.
https://stats.stackexchange.com/questions/231074/confidence-intervals-on-predictions-for-a-non-linear-mixed-model-nlme

But I don't know what I would need to modify for a linear model.

Thanks for you assistance,
Logan

	[[alternative HTML version deleted]]


From thierry@onkelinx @ending from inbo@be  Mon Nov 19 09:54:12 2018
From: thierry@onkelinx @ending from inbo@be (Thierry Onkelinx)
Date: Mon, 19 Nov 2018 09:54:12 +0100
Subject: [R-sig-ME] Adding random subject or item slopes for a specific
 contrast
In-Reply-To: <2E987257-ADF7-43A3-B95B-CB9420CE820A@ucalgary.ca>
References: <2E987257-ADF7-43A3-B95B-CB9420CE820A@ucalgary.ca>
Message-ID: <CAJuCY5wdvBcMnPGq_9TE6GAfs0E+=SW4ERMubxeVy_K1jASP9Q@mail.gmail.com>

Dear David,

I think you can solve this by creating a dummy variable which has zero's in
case you are not interested in the random slope.

Please note that sending HTML has ruined the code formating, making your
code much harder to read.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op do 8 nov. 2018 om 16:55 schreef David Sidhu <dsidhu at ucalgary.ca>:

> Hi There
>
> I have been following the approach described in Bates et al. (2018) to
> simplify my random effects structure. I will use the data pasted below as
> an example (though the effects I describe aren?t present there, I use it
> only to have an example to refer to).
>
> Now, if it seems that there is variance in the random subject slope
> comparing IV1 level 2 vs. IV1 level 1, but in no other contrast?s random
> subject slope, I would like to only include a random subject slope for that
> one specific contrast. Also assume that the method described by Bates et
> al. (2018) suggests that the random effects structure should only have one
> component.
>
> Two questions: Is it sensible to only include this one slope? Is it
> possible in lme4 to only include this one slope?
>
> Thanks!
> Dave
>
>
>
>
>
> Subj <- rep(1:10, each = 10) Item <- rep(1:10, times = 10) IV1 <- rep(1:5,
> times = 20) DV <- rnorm(100) library(data.table) data <-
> as.data.table(cbind(Subj, Item, IV1, DV)) data$Subj <- as.factor(data$Subj)
> data$Item <- as.factor(data$Item) data$IV1 <- as.factor(data$IV1)
> library(MASS) contrasts(data$IV1) <- contr.sdif(5) library(lme4) m <-
> lmer(DV ~ IV1 + (1 + IV1|Subj) + (1|Item), data = data)
>
>
>
>
> ---
> David M. Sidhu, MSc
> PhD Candidate
> Department of Psychology
> University of Calgary
>
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From thierry@onkelinx @ending from inbo@be  Mon Nov 19 10:01:15 2018
From: thierry@onkelinx @ending from inbo@be (Thierry Onkelinx)
Date: Mon, 19 Nov 2018 10:01:15 +0100
Subject: [R-sig-ME] 
 Single DV with multiple measures for time-varying IV?
In-Reply-To: <CO2PR01MB2198B93539290F1E5DC5C285CCC10@CO2PR01MB2198.prod.exchangelabs.com>
References: <CO2PR01MB2198B93539290F1E5DC5C285CCC10@CO2PR01MB2198.prod.exchangelabs.com>
Message-ID: <CAJuCY5x0P2rku4rp8C0yONEOEOL2=Mrtg3SUkOBUS__pSh7mDQ@mail.gmail.com>

Dear Ellen,

An extract of your dataset or a small dummy dataset coverting the important
features of your data would make it much easier to answer your questions.
And please don't send HTML emails. Any HTML formating gets stripped which
can make your email very hard to read.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op ma 12 nov. 2018 om 20:01 schreef Pero, Ellen <
ellen.pero at umconnect.umt.edu>:

> Hi all:
>
> I have an analytical dilemma wherein I have a single DV with multiple
> categorical and continuous IVs (one of which is a continuous IV that has
> multiple measurements across time). I'm not sure the best way to model for
> this - though it's clearly a hierarchical situation so I thought this might
> be a good venue to pose the question.
>
> Specifically, I have 60 pregnant elk from which I took monthly cortisol
> samples across gestation (some missing values, so 5-8 samples/female across
> gestation). I'm interested in how those stress measurements across
> gestation (along with a range of other IVs that don't vary with time, e.g.,
> dam age, sire age, calf birthdate) influence the birth mass of each
> female's calf.
>
> Any suggestions on analysis for situations where a single DV is predicted
> by longitudinal measures of time-varying IV (along with non-varying IVs)?
>
> I'm new to this list and will spend some time familiarizing myself with it
> - but was eager to get my question out. Apologies if this isn't the right
> venue for my non-development related question. Please disregard if
> appropriate.
>
> I appreciate any thoughts/advice/suggestions!
> El
>
>
>
> Ellen Pero
> PhD Student
> Wildlife Biology Program
> W.A. Franke College of Forestry and Conservation
> University of Montana
> 32 Campus Drive, FOR 318
> Missoula, MT 59812
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From Bill@Poling @ending from zeli@@com  Mon Nov 19 12:26:52 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Mon, 19 Nov 2018 11:26:52 +0000
Subject: [R-sig-ME] 
 Single DV with multiple measures for time-varying IV?
In-Reply-To: <CAJuCY5x0P2rku4rp8C0yONEOEOL2=Mrtg3SUkOBUS__pSh7mDQ@mail.gmail.com>
References: <CO2PR01MB2198B93539290F1E5DC5C285CCC10@CO2PR01MB2198.prod.exchangelabs.com>
 <CAJuCY5x0P2rku4rp8C0yONEOEOL2=Mrtg3SUkOBUS__pSh7mDQ@mail.gmail.com>
Message-ID: <BN7PR02MB5073E8F44D59F30E7F9DF11DEAD80@BN7PR02MB5073.namprd02.prod.outlook.com>

Hi Ellen.

 If the data frame is not too terribly large, a dput() would be useful.
See ?dput()
Or a str() would help as well
See ?str()
However, as Thierry suggests a subset of your data would be most helpful.

I will be interested to follow this topic as I am teaching myself R and learning the various modeling methods and their purposes along the way.

I think you will gain considerable support from this list relevant to your topic.

Best regards.

WHP


From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Thierry Onkelinx via R-sig-mixed-models
Sent: Monday, November 19, 2018 4:01 AM
To: ellen.pero at umconnect.umt.edu
Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Single DV with multiple measures for time-varying IV?

Dear Ellen,

An extract of your dataset or a small dummy dataset coverting the important
features of your data would make it much easier to answer your questions.
And please don't send HTML emails. Any HTML formating gets stripped which
can make your email very hard to read.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
mailto:thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
http://www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op ma 12 nov. 2018 om 20:01 schreef Pero, Ellen <
mailto:ellen.pero at umconnect.umt.edu>:

> Hi all:
>
> I have an analytical dilemma wherein I have a single DV with multiple
> categorical and continuous IVs (one of which is a continuous IV that has
> multiple measurements across time). I'm not sure the best way to model for
> this - though it's clearly a hierarchical situation so I thought this might
> be a good venue to pose the question.
>
> Specifically, I have 60 pregnant elk from which I took monthly cortisol
> samples across gestation (some missing values, so 5-8 samples/female across
> gestation). I'm interested in how those stress measurements across
> gestation (along with a range of other IVs that don't vary with time, e.g.,
> dam age, sire age, calf birthdate) influence the birth mass of each
> female's calf.
>
> Any suggestions on analysis for situations where a single DV is predicted
> by longitudinal measures of time-varying IV (along with non-varying IVs)?
>
> I'm new to this list and will spend some time familiarizing myself with it
> - but was eager to get my question out. Apologies if this isn't the right
> venue for my non-development related question. Please disregard if
> appropriate.
>
> I appreciate any thoughts/advice/suggestions!
> El
>
>
>
> Ellen Pero
> PhD Student
> Wildlife Biology Program
> W.A. Franke College of Forestry and Conservation
> University of Montana
> 32 Campus Drive, FOR 318
> Missoula, MT 59812
>
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> mailto:R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

[[alternative HTML version deleted]]

_______________________________________________
mailto:R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

Confidentiality Notice This message is sent from Zelis. ...{{dropped:13}}


From d@idhu @ending from uc@lg@ry@c@  Mon Nov 19 21:03:30 2018
From: d@idhu @ending from uc@lg@ry@c@ (David Sidhu)
Date: Mon, 19 Nov 2018 20:03:30 +0000
Subject: [R-sig-ME] Adding random subject or item slopes for a specific
 contrast
In-Reply-To: <CAJuCY5wdvBcMnPGq_9TE6GAfs0E+=SW4ERMubxeVy_K1jASP9Q@mail.gmail.com>
References: <2E987257-ADF7-43A3-B95B-CB9420CE820A@ucalgary.ca>
 <CAJuCY5wdvBcMnPGq_9TE6GAfs0E+=SW4ERMubxeVy_K1jASP9Q@mail.gmail.com>
Message-ID: <D61485BE-A54F-4811-94D4-F62EB6A09279@ucalgary.ca>

Hi Thierry

Thank you very much for the reply, and apologies for the troubling code.

I have two follow up questions:

1) Suppose IV is a three level factor. Would I still use this variable for the fixed effects, but then create a dummy variable reflecting the random slope that I want to include? I assume this works out the same as creating a pair of dummy variables to use for fixed effects, and then using one for the random slope.

2) Is it advisable to do this? I.e., to only include the slope for a single contrast. Or, is this problematic statistically.

Thanks very much.

Dave

---
David M. Sidhu, MSc
PhD Candidate
Department of Psychology
University of Calgary






On Nov 19, 2018, at 1:54 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>> wrote:

Dear David,

I think you can solve this by creating a dummy variable which has zero's in case you are not interested in the random slope.

Please note that sending HTML has ruined the code formating, making your code much harder to read.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be<http://www.inbo.be/>

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

[https://inbo-website-prd-532750756126.s3-eu-west-1.amazonaws.com/inbologoleeuw_nl.png]<https://www.inbo.be/>


Op do 8 nov. 2018 om 16:55 schreef David Sidhu <dsidhu at ucalgary.ca<mailto:dsidhu at ucalgary.ca>>:
Hi There

I have been following the approach described in Bates et al. (2018) to simplify my random effects structure. I will use the data pasted below as an example (though the effects I describe aren?t present there, I use it only to have an example to refer to).

Now, if it seems that there is variance in the random subject slope comparing IV1 level 2 vs. IV1 level 1, but in no other contrast?s random subject slope, I would like to only include a random subject slope for that one specific contrast. Also assume that the method described by Bates et al. (2018) suggests that the random effects structure should only have one component.

Two questions: Is it sensible to only include this one slope? Is it possible in lme4 to only include this one slope?

Thanks!
Dave





Subj <- rep(1:10, each = 10) Item <- rep(1:10, times = 10) IV1 <- rep(1:5, times = 20) DV <- rnorm(100) library(data.table) data <- as.data.table(cbind(Subj, Item, IV1, DV)) data$Subj <- as.factor(data$Subj) data$Item <- as.factor(data$Item) data$IV1 <- as.factor(data$IV1) library(MASS) contrasts(data$IV1) <- contr.sdif(5) library(lme4) m <- lmer(DV ~ IV1 + (1 + IV1|Subj) + (1|Item), data = data)




---
David M. Sidhu, MSc
PhD Candidate
Department of Psychology
University of Calgary







        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From roeem@or @ending from gm@il@com  Tue Nov 20 19:08:10 2018
From: roeem@or @ending from gm@il@com (roee maor)
Date: Tue, 20 Nov 2018 18:08:10 +0000
Subject: [R-sig-ME] 
 Unclear output from MCMCglmm with categorical predictors
Message-ID: <CACxNx6tyjKHjBVGVhs+aER7i9iSv4ODvOhofH1ERatAUqexmxw@mail.gmail.com>

Dear Jarrod (and list),

Following your previous comment I added "random = ~ Binomial" to my model
to allow for a phylogenetic analysis.
This causes convergence problems: the trace plots show increasing
oscillations along each chain (although no directional trends, so it's not
a burn-in issue). Also, the posterior samples are highly correlated,
residual variance estimates are >10^3 and threshold estimates are high (>20
on the latent scale).
Surprisingly (to me), predictors that are strongly significant in the
non-phylogenetic model lose their effect in the phylogenetic model (I tried
several alternative parameter configurations).

It seems that this model attributes the explained variance to phylogeny
alone.
Can anyone explain what is going on here?  Am I specifying the model poorly
or just asking my data more than it can answer?

I tried to overcome this issue by using a fully resolved variant of the
phylogeny, which only improved things slightly.
I also changed the random effect to "random=~Family" or "random=~Order",
which reduced the variance and threshold estimates to more acceptable
levels (<10), but still no significant predictors (and I'm not sure how the
algorithm calculates covariance between higher taxa in the phylogeny).
Separately I tried parameter expanded prior: "prior = list(R = list(V=1,
fix=1), G = list(G1 = list(V=1, nu=1, alpha.mu=0, alpha.V=1000)))". That
didn't help, and messing with priors for this reason feels like poor
practice.

This is the model:
T1 <- MCMCglmm(Activity ~ -1 + log(Mass) + Max.Temp * Annual.Precip,
                               random = ~ Binomial,
                               prior = list(R = list(fix=1, V=1), G =
list(G1 = list(V=1, nu=0.002))),
                               ginverse = list(Binomial=INphylo$Ainv),
                               burnin = 150000, nitt = 2650001, thin =
2500,
                               family = "threshold",  data = Tdata,
                               pl = TRUE, pr = TRUE, saveX = TRUE, saveZ =
TRUE,
                               verbose = FALSE)

The data I use looks like this (not all variables appear in each model):

str(Tdata)
'data.frame': 1389 obs. of  10 variables:
 $ Binomial           : Factor w/ 1421 levels "Abrocoma_bennettii",..: 1 2
3 4 5 6 7 8 9 10 ...
 $ Order                : Factor w/ 27 levels "Afrosoricida",..: 24 24 24
24 24 3 24 24 2 2 ...
 $ Family               : Factor w/ 126 levels "Abrocomidae",..: 1 26 26 26
26 46 74 87 10 10 ...
 $ Activity              : Factor w/ 3 levels "1","2","3": 1 3 2 2 2 3 2 3
1 3 ...
 $ Habitat              : Factor w/ 6 levels "Aqua","Arbo",..: 5 5 5 5 5 5
5 5 5 5 ...
 $ Diet                   : Factor w/ 3 levels "Faun","Herb",..: 2 3 3 3 3
1 3 2 2 2 ...
 $ Mass                 : num  250.5 24.9 34.5 38.9 24.5 ...
 $ Max.Temp         : num  22 16.6 19.1 19.8 17.2 ...
 $ Annual.Precip   : num  166 645 558 903 1665 ...

Any advice would be much appreciated!
Many thanks,


-- 
Roi Maor
PhD candidate
School of Zoology, Tel Aviv University
Centre for Biodiversity and Environment Research, UCL

	[[alternative HTML version deleted]]


From j@h@dfield @ending from ed@@c@uk  Tue Nov 20 21:01:44 2018
From: j@h@dfield @ending from ed@@c@uk (HADFIELD Jarrod)
Date: Tue, 20 Nov 2018 20:01:44 +0000
Subject: [R-sig-ME] 
 Unclear output from MCMCglmm with categorical predictors
In-Reply-To: <CACxNx6tyjKHjBVGVhs+aER7i9iSv4ODvOhofH1ERatAUqexmxw@mail.gmail.com>
References: <CACxNx6tyjKHjBVGVhs+aER7i9iSv4ODvOhofH1ERatAUqexmxw@mail.gmail.com>
Message-ID: <1B1687E4-41BE-41F8-8AB3-2D81B44383B5@ed.ac.uk>

Hi,

Most likely the phylogenetic heritability (the phylogenetic variance / the phylogenetic +residual variance) is approaching one resulting in numerical difficulties. Probably the best thing is to assume that the phylogenetic heritability equals 1 and use the reduced phylogenetic mixed model implementation. This allows the phylogenetic heritability to be equal to 1 without causing numerical issues. At some point I will integrate these models into the main MCMCglmm package, but for now you can download it from here: http://jarrod.bio.ed.ac.uk/MCMCglmmRAM_2.24.tar.gz.

Change the name of the ??Binomial? column to ?animal? and fit:

T1 <- MCMCglmm(Activity ~ -1 + log(Mass) + Max.Temp * Annual.Precip,
                               random = ~ animal
                               prior = list(R = list(fix=1, V=1e-15), G = list(G1 = list(V=1, nu=0.002))),
                               pedigree = tree,
       reduced=TRUE,
                               burnin = 150000, nitt = 2650001, thin = 2500,
                               family = "threshold",  data = Tdata,
                               pl = TRUE, pr = TRUE, saveX = TRUE, saveZ = TRUE,
                               verbose = FALSE)

You should need fewer iterations.

Cheers,

Jarrod


On 20 Nov 2018, at 18:08, roee maor <roeemaor at gmail.com<mailto:roeemaor at gmail.com>> wrote:

Dear Jarrod (and list),

Following your previous comment I added "random = ~ Binomial" to my model to allow for a phylogenetic analysis.
This causes convergence problems: the trace plots show increasing oscillations along each chain (although no directional trends, so it's not a burn-in issue). Also, the posterior samples are highly correlated,  residual variance estimates are >10^3 and threshold estimates are high (>20 on the latent scale).
Surprisingly (to me), predictors that are strongly significant in the non-phylogenetic model lose their effect in the phylogenetic model (I tried several alternative parameter configurations).

It seems that this model attributes the explained variance to phylogeny alone.
Can anyone explain what is going on here?  Am I specifying the model poorly or just asking my data more than it can answer?

I tried to overcome this issue by using a fully resolved variant of the phylogeny, which only improved things slightly.
I also changed the random effect to "random=~Family" or "random=~Order", which reduced the variance and threshold estimates to more acceptable levels (<10), but still no significant predictors (and I'm not sure how the algorithm calculates covariance between higher taxa in the phylogeny).
Separately I tried parameter expanded prior: "prior = list(R = list(V=1, fix=1), G = list(G1 = list(V=1, nu=1, alpha.mu<http://alpha.mu/>=0, alpha.V=1000)))". That didn't help, and messing with priors for this reason feels like poor practice.

This is the model:
T1 <- MCMCglmm(Activity ~ -1 + log(Mass) + Max.Temp * Annual.Precip,
                               random = ~ Binomial,
                               prior = list(R = list(fix=1, V=1), G = list(G1 = list(V=1, nu=0.002))),
                               ginverse = list(Binomial=INphylo$Ainv),
                               burnin = 150000, nitt = 2650001, thin = 2500,
                               family = "threshold",  data = Tdata,
                               pl = TRUE, pr = TRUE, saveX = TRUE, saveZ = TRUE,
                               verbose = FALSE)

The data I use looks like this (not all variables appear in each model):

str(Tdata)
'data.frame': 1389 obs. of  10 variables:
 $ Binomial           : Factor w/ 1421 levels "Abrocoma_bennettii",..: 1 2 3 4 5 6 7 8 9 10 ...
 $ Order                : Factor w/ 27 levels "Afrosoricida",..: 24 24 24 24 24 3 24 24 2 2 ...
 $ Family               : Factor w/ 126 levels "Abrocomidae",..: 1 26 26 26 26 46 74 87 10 10 ...
 $ Activity              : Factor w/ 3 levels "1","2","3": 1 3 2 2 2 3 2 3 1 3 ...
 $ Habitat              : Factor w/ 6 levels "Aqua","Arbo",..: 5 5 5 5 5 5 5 5 5 5 ...
 $ Diet                   : Factor w/ 3 levels "Faun","Herb",..: 2 3 3 3 3 1 3 2 2 2 ...
 $ Mass                 : num  250.5 24.9 34.5 38.9 24.5 ...
 $ Max.Temp         : num  22 16.6 19.1 19.8 17.2 ...
 $ Annual.Precip   : num  166 645 558 903 1665 ...

Any advice would be much appreciated!
Many thanks,


--
Roi Maor
PhD candidate
School of Zoology, Tel Aviv University
Centre for Biodiversity and Environment Research, UCL


-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20181120/de21f7e5/attachment.ksh>

From roeem@or @ending from gm@il@com  Wed Nov 21 15:09:20 2018
From: roeem@or @ending from gm@il@com (roee maor)
Date: Wed, 21 Nov 2018 14:09:20 +0000
Subject: [R-sig-ME] 
 Unclear output from MCMCglmm with categorical predictors
In-Reply-To: <1B1687E4-41BE-41F8-8AB3-2D81B44383B5@ed.ac.uk>
References: <CACxNx6tyjKHjBVGVhs+aER7i9iSv4ODvOhofH1ERatAUqexmxw@mail.gmail.com>
 <1B1687E4-41BE-41F8-8AB3-2D81B44383B5@ed.ac.uk>
Message-ID: <CACxNx6srMCNbpj4Hk-=XmUAHjeJvDftPrhnGBhrWPKK-4vUM_g@mail.gmail.com>

Hi Jarrod,
Many thanks for your reply.

I couldn't install the tarball on R v3.4.3 or v3.5.1 so sourced the files
directly to the workspace.
I tried to run this model as you suggested:
> T1 <- MCMCglmm(Activity ~ -1 + log(Mass) + Max.Temp * Annual.Precip,
               random = ~ animal,
               prior = list(R = list(fix=1, V=1e-15), G = list(G1 =
list(V=1, nu=0.002))),
               pedigree = datatree,
               reduced = TRUE,
               burnin = 50000, nitt = 750001, thin = 700,
               family = "threshold",
               data = Rdata,
               pl = TRUE, saveX = TRUE, saveZ = TRUE,
               verbose = TRUE)

It returns some errors about missing functions "is.positive.definite" and
"Matrix", which I addressed with:
> library("corpcor", lib.loc="~/R/win-library/3.5")
> library("MatrixModels", lib.loc="~/R/win-library/3.5")
but I can't figure this one out:
'Error in .C("MCMCglmm", as.double(data$MCMC_y),
as.double(data$MCMC_y.additional),  :
  C symbol name "MCMCglmm" not in load table'
Detaching these packages doesn't necessarily cause that same error to
appear although I execute the exact same code.
Also, several attempts (same code again) caused a fatal error and automatic
session termination (info for a similar session below if interesting).

I tried to use the fully bifurcating tree as an experiment but that made no
difference.

Any ideas what this last error means?

Thanks!
Roi


> sessionInfo()
R version 3.5.1 (2018-07-02)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows >= 8 x64 (build 9200)

Matrix products: default

locale:
[1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United
Kingdom.1252    LC_MONETARY=English_United Kingdom.1252
[4] LC_NUMERIC=C                            LC_TIME=English_United
Kingdom.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] corpcor_1.6.9   Matrix_1.2-14   phytools_0.6-60 maps_3.3.0
ape_5.2

loaded via a namespace (and not attached):
 [1] igraph_1.2.2            Rcpp_0.12.19            magrittr_1.5
  MASS_7.3-50             mnormt_1.5-5
 [6] scatterplot3d_0.3-41    lattice_0.20-35         quadprog_1.5-5
  fastmatch_1.1-0         tools_3.5.1
[11] parallel_3.5.1          grid_3.5.1              nlme_3.1-137
  clusterGeneration_1.3.4 phangorn_2.4.0
[16] plotrix_3.7-4           coda_0.19-2             yaml_2.2.0
  numDeriv_2016.8-1       animation_2.5
[21] compiler_3.5.1          combinat_0.0-8          expm_0.999-3
  pkgconfig_2.0.2

On Tue, 20 Nov 2018 at 20:01, HADFIELD Jarrod <j.hadfield at ed.ac.uk> wrote:

> Hi,
>
> Most likely the phylogenetic heritability (the phylogenetic variance / the
> phylogenetic +residual variance) is approaching one resulting in numerical
> difficulties. Probably the best thing is to assume that the phylogenetic
> heritability equals 1 and use the reduced phylogenetic mixed model
> implementation. This allows the phylogenetic heritability to be equal to 1
> without causing numerical issues. At some point I will integrate these
> models into the main MCMCglmm package, but for now you can download it from
> here: http://jarrod.bio.ed.ac.uk/MCMCglmmRAM_2.24.tar.gz.
>
> Change the name of the ??Binomial? column to ?animal? and fit:
>
> T1 <- MCMCglmm(Activity ~ -1 + log(Mass) + Max.Temp * Annual.Precip,
>                                random = ~ animal
>                                prior = list(R = list(fix=1, V=1e-15), G =
> list(G1 = list(V=1, nu=0.002))),
>                                pedigree = tree,
>        reduced=TRUE,
>                                burnin = 150000, nitt = 2650001, thin =
> 2500,
>                                family = "threshold",  data = Tdata,
>                                pl = TRUE, pr = TRUE, saveX = TRUE, saveZ =
> TRUE,
>                                verbose = FALSE)
>
> You should need fewer iterations.
>
> Cheers,
>
> Jarrod
>
>
> On 20 Nov 2018, at 18:08, roee maor <roeemaor at gmail.com> wrote:
>
> Dear Jarrod (and list),
>
> Following your previous comment I added "random = ~ Binomial" to my model
> to allow for a phylogenetic analysis.
> This causes convergence problems: the trace plots show increasing
> oscillations along each chain (although no directional trends, so it's not
> a burn-in issue). Also, the posterior samples are highly correlated,
> residual variance estimates are >10^3 and threshold estimates are high (>20
> on the latent scale).
> Surprisingly (to me), predictors that are strongly significant in the
> non-phylogenetic model lose their effect in the phylogenetic model (I tried
> several alternative parameter configurations).
>
> It seems that this model attributes the explained variance to phylogeny
> alone.
> Can anyone explain what is going on here?  Am I specifying the model
> poorly or just asking my data more than it can answer?
>
> I tried to overcome this issue by using a fully resolved variant of the
> phylogeny, which only improved things slightly.
> I also changed the random effect to "random=~Family" or "random=~Order",
> which reduced the variance and threshold estimates to more acceptable
> levels (<10), but still no significant predictors (and I'm not sure how the
> algorithm calculates covariance between higher taxa in the phylogeny).
> Separately I tried parameter expanded prior: "prior = list(R = list(V=1,
> fix=1), G = list(G1 = list(V=1, nu=1, alpha.mu=0, alpha.V=1000)))". That
> didn't help, and messing with priors for this reason feels like poor
> practice.
>
> This is the model:
> T1 <- MCMCglmm(Activity ~ -1 + log(Mass) + Max.Temp * Annual.Precip,
>                                random = ~ Binomial,
>                                prior = list(R = list(fix=1, V=1), G =
> list(G1 = list(V=1, nu=0.002))),
>                                ginverse = list(Binomial=INphylo$Ainv),
>                                burnin = 150000, nitt = 2650001, thin =
> 2500,
>                                family = "threshold",  data = Tdata,
>                                pl = TRUE, pr = TRUE, saveX = TRUE, saveZ =
> TRUE,
>                                verbose = FALSE)
>
> The data I use looks like this (not all variables appear in each model):
>
> str(Tdata)
> 'data.frame': 1389 obs. of  10 variables:
>  $ Binomial           : Factor w/ 1421 levels "Abrocoma_bennettii",..: 1 2
> 3 4 5 6 7 8 9 10 ...
>  $ Order                : Factor w/ 27 levels "Afrosoricida",..: 24 24 24
> 24 24 3 24 24 2 2 ...
>  $ Family               : Factor w/ 126 levels "Abrocomidae",..: 1 26 26
> 26 26 46 74 87 10 10 ...
>  $ Activity              : Factor w/ 3 levels "1","2","3": 1 3 2 2 2 3 2 3
> 1 3 ...
>  $ Habitat              : Factor w/ 6 levels "Aqua","Arbo",..: 5 5 5 5 5 5
> 5 5 5 5 ...
>  $ Diet                   : Factor w/ 3 levels "Faun","Herb",..: 2 3 3 3 3
> 1 3 2 2 2 ...
>  $ Mass                 : num  250.5 24.9 34.5 38.9 24.5 ...
>  $ Max.Temp         : num  22 16.6 19.1 19.8 17.2 ...
>  $ Annual.Precip   : num  166 645 558 903 1665 ...
>
> Any advice would be much appreciated!
> Many thanks,
>
>
> --
> Roi Maor
> PhD candidate
> School of Zoology, Tel Aviv University
> Centre for Biodiversity and Environment Research, UCL
>
>
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>


-- 
Roi Maor
PhD candidate
School of Zoology, Tel Aviv University
Centre for Biodiversity and Environment Research, UCL

	[[alternative HTML version deleted]]


From j@h@dfield @ending from ed@@c@uk  Wed Nov 21 16:05:14 2018
From: j@h@dfield @ending from ed@@c@uk (HADFIELD Jarrod)
Date: Wed, 21 Nov 2018 15:05:14 +0000
Subject: [R-sig-ME] 
 Unclear output from MCMCglmm with categorical predictors
In-Reply-To: <CACxNx6srMCNbpj4Hk-=XmUAHjeJvDftPrhnGBhrWPKK-4vUM_g@mail.gmail.com>
References: <CACxNx6tyjKHjBVGVhs+aER7i9iSv4ODvOhofH1ERatAUqexmxw@mail.gmail.com>
 <1B1687E4-41BE-41F8-8AB3-2D81B44383B5@ed.ac.uk>
 <CACxNx6srMCNbpj4Hk-=XmUAHjeJvDftPrhnGBhrWPKK-4vUM_g@mail.gmail.com>
Message-ID: <1551b85a-2cb7-0a46-7014-fb19598c0376@ed.ac.uk>

Hi,

You could upload the tarball to winbuilder (https://win-builder.r-project.org/) and build a Windows source package.

Cheers,

Jarrod


On 21/11/2018 14:09, roee maor wrote:
Hi Jarrod,
Many thanks for your reply.

I couldn't install the tarball on R v3.4.3 or v3.5.1 so sourced the files directly to the workspace.
I tried to run this model as you suggested:
> T1 <- MCMCglmm(Activity ~ -1 + log(Mass) + Max.Temp * Annual.Precip,
               random = ~ animal,
               prior = list(R = list(fix=1, V=1e-15), G = list(G1 = list(V=1, nu=0.002))),
               pedigree = datatree,
               reduced = TRUE,
               burnin = 50000, nitt = 750001, thin = 700,
               family = "threshold",
               data = Rdata,
               pl = TRUE, saveX = TRUE, saveZ = TRUE,
               verbose = TRUE)

It returns some errors about missing functions "is.positive.definite" and "Matrix", which I addressed with:
> library("corpcor", lib.loc="~/R/win-library/3.5")
> library("MatrixModels", lib.loc="~/R/win-library/3.5")
but I can't figure this one out:
'Error in .C("MCMCglmm", as.double(data$MCMC_y), as.double(data$MCMC_y.additional),  :
  C symbol name "MCMCglmm" not in load table'
Detaching these packages doesn't necessarily cause that same error to appear although I execute the exact same code.
Also, several attempts (same code again) caused a fatal error and automatic session termination (info for a similar session below if interesting).

I tried to use the fully bifurcating tree as an experiment but that made no difference.

Any ideas what this last error means?

Thanks!
Roi


> sessionInfo()
R version 3.5.1 (2018-07-02)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows >= 8 x64 (build 9200)

Matrix products: default

locale:
[1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United Kingdom.1252    LC_MONETARY=English_United Kingdom.1252
[4] LC_NUMERIC=C                            LC_TIME=English_United Kingdom.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] corpcor_1.6.9   Matrix_1.2-14   phytools_0.6-60 maps_3.3.0      ape_5.2

loaded via a namespace (and not attached):
 [1] igraph_1.2.2            Rcpp_0.12.19            magrittr_1.5            MASS_7.3-50             mnormt_1.5-5
 [6] scatterplot3d_0.3-41    lattice_0.20-35         quadprog_1.5-5          fastmatch_1.1-0         tools_3.5.1
[11] parallel_3.5.1          grid_3.5.1              nlme_3.1-137            clusterGeneration_1.3.4 phangorn_2.4.0
[16] plotrix_3.7-4           coda_0.19-2             yaml_2.2.0              numDeriv_2016.8-1       animation_2.5
[21] compiler_3.5.1          combinat_0.0-8          expm_0.999-3            pkgconfig_2.0.2

On Tue, 20 Nov 2018 at 20:01, HADFIELD Jarrod <j.hadfield at ed.ac.uk<mailto:j.hadfield at ed.ac.uk>> wrote:
Hi,

Most likely the phylogenetic heritability (the phylogenetic variance / the phylogenetic +residual variance) is approaching one resulting in numerical difficulties. Probably the best thing is to assume that the phylogenetic heritability equals 1 and use the reduced phylogenetic mixed model implementation. This allows the phylogenetic heritability to be equal to 1 without causing numerical issues. At some point I will integrate these models into the main MCMCglmm package, but for now you can download it from here: http://jarrod.bio.ed.ac.uk/MCMCglmmRAM_2.24.tar.gz.

Change the name of the ??Binomial? column to ?animal? and fit:

T1 <- MCMCglmm(Activity ~ -1 + log(Mass) + Max.Temp * Annual.Precip,
                               random = ~ animal
                               prior = list(R = list(fix=1, V=1e-15), G = list(G1 = list(V=1, nu=0.002))),
                               pedigree = tree,
       reduced=TRUE,
                               burnin = 150000, nitt = 2650001, thin = 2500,
                               family = "threshold",  data = Tdata,
                               pl = TRUE, pr = TRUE, saveX = TRUE, saveZ = TRUE,
                               verbose = FALSE)

You should need fewer iterations.

Cheers,

Jarrod


On 20 Nov 2018, at 18:08, roee maor <roeemaor at gmail.com<mailto:roeemaor at gmail.com>> wrote:

Dear Jarrod (and list),

Following your previous comment I added "random = ~ Binomial" to my model to allow for a phylogenetic analysis.
This causes convergence problems: the trace plots show increasing oscillations along each chain (although no directional trends, so it's not a burn-in issue). Also, the posterior samples are highly correlated,  residual variance estimates are >10^3 and threshold estimates are high (>20 on the latent scale).
Surprisingly (to me), predictors that are strongly significant in the non-phylogenetic model lose their effect in the phylogenetic model (I tried several alternative parameter configurations).

It seems that this model attributes the explained variance to phylogeny alone.
Can anyone explain what is going on here?  Am I specifying the model poorly or just asking my data more than it can answer?

I tried to overcome this issue by using a fully resolved variant of the phylogeny, which only improved things slightly.
I also changed the random effect to "random=~Family" or "random=~Order", which reduced the variance and threshold estimates to more acceptable levels (<10), but still no significant predictors (and I'm not sure how the algorithm calculates covariance between higher taxa in the phylogeny).
Separately I tried parameter expanded prior: "prior = list(R = list(V=1, fix=1), G = list(G1 = list(V=1, nu=1, alpha.mu<http://alpha.mu/>=0, alpha.V=1000)))". That didn't help, and messing with priors for this reason feels like poor practice.

This is the model:
T1 <- MCMCglmm(Activity ~ -1 + log(Mass) + Max.Temp * Annual.Precip,
                               random = ~ Binomial,
                               prior = list(R = list(fix=1, V=1), G = list(G1 = list(V=1, nu=0.002))),
                               ginverse = list(Binomial=INphylo$Ainv),
                               burnin = 150000, nitt = 2650001, thin = 2500,
                               family = "threshold",  data = Tdata,
                               pl = TRUE, pr = TRUE, saveX = TRUE, saveZ = TRUE,
                               verbose = FALSE)

The data I use looks like this (not all variables appear in each model):

str(Tdata)
'data.frame': 1389 obs. of  10 variables:
 $ Binomial           : Factor w/ 1421 levels "Abrocoma_bennettii",..: 1 2 3 4 5 6 7 8 9 10 ...
 $ Order                : Factor w/ 27 levels "Afrosoricida",..: 24 24 24 24 24 3 24 24 2 2 ...
 $ Family               : Factor w/ 126 levels "Abrocomidae",..: 1 26 26 26 26 46 74 87 10 10 ...
 $ Activity              : Factor w/ 3 levels "1","2","3": 1 3 2 2 2 3 2 3 1 3 ...
 $ Habitat              : Factor w/ 6 levels "Aqua","Arbo",..: 5 5 5 5 5 5 5 5 5 5 ...
 $ Diet                   : Factor w/ 3 levels "Faun","Herb",..: 2 3 3 3 3 1 3 2 2 2 ...
 $ Mass                 : num  250.5 24.9 34.5 38.9 24.5 ...
 $ Max.Temp         : num  22 16.6 19.1 19.8 17.2 ...
 $ Annual.Precip   : num  166 645 558 903 1665 ...

Any advice would be much appreciated!
Many thanks,


--
Roi Maor
PhD candidate
School of Zoology, Tel Aviv University
Centre for Biodiversity and Environment Research, UCL

The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


--
Roi Maor
PhD candidate
School of Zoology, Tel Aviv University
Centre for Biodiversity and Environment Research, UCL

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20181121/5077804b/attachment-0001.ksh>

From bbolker @ending from gm@il@com  Wed Nov 21 16:20:43 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Wed, 21 Nov 2018 10:20:43 -0500
Subject: [R-sig-ME] 
 Unclear output from MCMCglmm with categorical predictors
In-Reply-To: <1551b85a-2cb7-0a46-7014-fb19598c0376@ed.ac.uk>
References: <CACxNx6tyjKHjBVGVhs+aER7i9iSv4ODvOhofH1ERatAUqexmxw@mail.gmail.com>
 <1B1687E4-41BE-41F8-8AB3-2D81B44383B5@ed.ac.uk>
 <CACxNx6srMCNbpj4Hk-=XmUAHjeJvDftPrhnGBhrWPKK-4vUM_g@mail.gmail.com>
 <1551b85a-2cb7-0a46-7014-fb19598c0376@ed.ac.uk>
Message-ID: <a70653e3-1a49-292d-1791-01168f77aeff@gmail.com>


  If you need to build a windows binary on win-builder, you probably
need to (1) unpack the tarball (2) change the DESCRIPTION file so that
your e-mail is listed as the maintainer's e-mail address (3) repack the
tarball (4) upload to winbuilder.

  Otherwise the original maintainer will be sent an e-mail telling them
the binary is built and giving a link where they can download it ...

  cheers
   Ben Bolker


On 2018-11-21 10:05 a.m., HADFIELD Jarrod wrote:
> Hi,
> 
> You could upload the tarball to winbuilder (https://win-builder.r-project.org/) and build a Windows source package.
> 
> Cheers,
> 
> Jarrod
> 
> 
> On 21/11/2018 14:09, roee maor wrote:
> Hi Jarrod,
> Many thanks for your reply.
> 
> I couldn't install the tarball on R v3.4.3 or v3.5.1 so sourced the files directly to the workspace.
> I tried to run this model as you suggested:
>> T1 <- MCMCglmm(Activity ~ -1 + log(Mass) + Max.Temp * Annual.Precip,
>                random = ~ animal,
>                prior = list(R = list(fix=1, V=1e-15), G = list(G1 = list(V=1, nu=0.002))),
>                pedigree = datatree,
>                reduced = TRUE,
>                burnin = 50000, nitt = 750001, thin = 700,
>                family = "threshold",
>                data = Rdata,
>                pl = TRUE, saveX = TRUE, saveZ = TRUE,
>                verbose = TRUE)
> 
> It returns some errors about missing functions "is.positive.definite" and "Matrix", which I addressed with:
>> library("corpcor", lib.loc="~/R/win-library/3.5")
>> library("MatrixModels", lib.loc="~/R/win-library/3.5")
> but I can't figure this one out:
> 'Error in .C("MCMCglmm", as.double(data$MCMC_y), as.double(data$MCMC_y.additional),  :
>   C symbol name "MCMCglmm" not in load table'
> Detaching these packages doesn't necessarily cause that same error to appear although I execute the exact same code.
> Also, several attempts (same code again) caused a fatal error and automatic session termination (info for a similar session below if interesting).
> 
> I tried to use the fully bifurcating tree as an experiment but that made no difference.
> 
> Any ideas what this last error means?
> 
> Thanks!
> Roi
> 
> 
>> sessionInfo()
> R version 3.5.1 (2018-07-02)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows >= 8 x64 (build 9200)
> 
> Matrix products: default
> 
> locale:
> [1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United Kingdom.1252    LC_MONETARY=English_United Kingdom.1252
> [4] LC_NUMERIC=C                            LC_TIME=English_United Kingdom.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] corpcor_1.6.9   Matrix_1.2-14   phytools_0.6-60 maps_3.3.0      ape_5.2
> 
> loaded via a namespace (and not attached):
>  [1] igraph_1.2.2            Rcpp_0.12.19            magrittr_1.5            MASS_7.3-50             mnormt_1.5-5
>  [6] scatterplot3d_0.3-41    lattice_0.20-35         quadprog_1.5-5          fastmatch_1.1-0         tools_3.5.1
> [11] parallel_3.5.1          grid_3.5.1              nlme_3.1-137            clusterGeneration_1.3.4 phangorn_2.4.0
> [16] plotrix_3.7-4           coda_0.19-2             yaml_2.2.0              numDeriv_2016.8-1       animation_2.5
> [21] compiler_3.5.1          combinat_0.0-8          expm_0.999-3            pkgconfig_2.0.2
> 
> On Tue, 20 Nov 2018 at 20:01, HADFIELD Jarrod <j.hadfield at ed.ac.uk<mailto:j.hadfield at ed.ac.uk>> wrote:
> Hi,
> 
> Most likely the phylogenetic heritability (the phylogenetic variance / the phylogenetic +residual variance) is approaching one resulting in numerical difficulties. Probably the best thing is to assume that the phylogenetic heritability equals 1 and use the reduced phylogenetic mixed model implementation. This allows the phylogenetic heritability to be equal to 1 without causing numerical issues. At some point I will integrate these models into the main MCMCglmm package, but for now you can download it from here: http://jarrod.bio.ed.ac.uk/MCMCglmmRAM_2.24.tar.gz.
> 
> Change the name of the ??Binomial? column to ?animal? and fit:
> 
> T1 <- MCMCglmm(Activity ~ -1 + log(Mass) + Max.Temp * Annual.Precip,
>                                random = ~ animal
>                                prior = list(R = list(fix=1, V=1e-15), G = list(G1 = list(V=1, nu=0.002))),
>                                pedigree = tree,
>        reduced=TRUE,
>                                burnin = 150000, nitt = 2650001, thin = 2500,
>                                family = "threshold",  data = Tdata,
>                                pl = TRUE, pr = TRUE, saveX = TRUE, saveZ = TRUE,
>                                verbose = FALSE)
> 
> You should need fewer iterations.
> 
> Cheers,
> 
> Jarrod
> 
> 
> On 20 Nov 2018, at 18:08, roee maor <roeemaor at gmail.com<mailto:roeemaor at gmail.com>> wrote:
> 
> Dear Jarrod (and list),
> 
> Following your previous comment I added "random = ~ Binomial" to my model to allow for a phylogenetic analysis.
> This causes convergence problems: the trace plots show increasing oscillations along each chain (although no directional trends, so it's not a burn-in issue). Also, the posterior samples are highly correlated,  residual variance estimates are >10^3 and threshold estimates are high (>20 on the latent scale).
> Surprisingly (to me), predictors that are strongly significant in the non-phylogenetic model lose their effect in the phylogenetic model (I tried several alternative parameter configurations).
> 
> It seems that this model attributes the explained variance to phylogeny alone.
> Can anyone explain what is going on here?  Am I specifying the model poorly or just asking my data more than it can answer?
> 
> I tried to overcome this issue by using a fully resolved variant of the phylogeny, which only improved things slightly.
> I also changed the random effect to "random=~Family" or "random=~Order", which reduced the variance and threshold estimates to more acceptable levels (<10), but still no significant predictors (and I'm not sure how the algorithm calculates covariance between higher taxa in the phylogeny).
> Separately I tried parameter expanded prior: "prior = list(R = list(V=1, fix=1), G = list(G1 = list(V=1, nu=1, alpha.mu<http://alpha.mu/>=0, alpha.V=1000)))". That didn't help, and messing with priors for this reason feels like poor practice.
> 
> This is the model:
> T1 <- MCMCglmm(Activity ~ -1 + log(Mass) + Max.Temp * Annual.Precip,
>                                random = ~ Binomial,
>                                prior = list(R = list(fix=1, V=1), G = list(G1 = list(V=1, nu=0.002))),
>                                ginverse = list(Binomial=INphylo$Ainv),
>                                burnin = 150000, nitt = 2650001, thin = 2500,
>                                family = "threshold",  data = Tdata,
>                                pl = TRUE, pr = TRUE, saveX = TRUE, saveZ = TRUE,
>                                verbose = FALSE)
> 
> The data I use looks like this (not all variables appear in each model):
> 
> str(Tdata)
> 'data.frame': 1389 obs. of  10 variables:
>  $ Binomial           : Factor w/ 1421 levels "Abrocoma_bennettii",..: 1 2 3 4 5 6 7 8 9 10 ...
>  $ Order                : Factor w/ 27 levels "Afrosoricida",..: 24 24 24 24 24 3 24 24 2 2 ...
>  $ Family               : Factor w/ 126 levels "Abrocomidae",..: 1 26 26 26 26 46 74 87 10 10 ...
>  $ Activity              : Factor w/ 3 levels "1","2","3": 1 3 2 2 2 3 2 3 1 3 ...
>  $ Habitat              : Factor w/ 6 levels "Aqua","Arbo",..: 5 5 5 5 5 5 5 5 5 5 ...
>  $ Diet                   : Factor w/ 3 levels "Faun","Herb",..: 2 3 3 3 3 1 3 2 2 2 ...
>  $ Mass                 : num  250.5 24.9 34.5 38.9 24.5 ...
>  $ Max.Temp         : num  22 16.6 19.1 19.8 17.2 ...
>  $ Annual.Precip   : num  166 645 558 903 1665 ...
> 
> Any advice would be much appreciated!
> Many thanks,
> 
> 
> --
> Roi Maor
> PhD candidate
> School of Zoology, Tel Aviv University
> Centre for Biodiversity and Environment Research, UCL
> 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
> 
> 
> --
> Roi Maor
> PhD candidate
> School of Zoology, Tel Aviv University
> Centre for Biodiversity and Environment Research, UCL
> 
> 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From ellen@pero @ending from umconnect@umt@edu  Wed Nov 21 16:28:58 2018
From: ellen@pero @ending from umconnect@umt@edu (Pero, Ellen)
Date: Wed, 21 Nov 2018 15:28:58 +0000
Subject: [R-sig-ME] 
 Single DV with multiple measures for time-varying IV?
In-Reply-To: <BN7PR02MB5073E8F44D59F30E7F9DF11DEAD80@BN7PR02MB5073.namprd02.prod.outlook.com>
References: <CO2PR01MB2198B93539290F1E5DC5C285CCC10@CO2PR01MB2198.prod.exchangelabs.com>
 <CAJuCY5x0P2rku4rp8C0yONEOEOL2=Mrtg3SUkOBUS__pSh7mDQ@mail.gmail.com>,
 <BN7PR02MB5073E8F44D59F30E7F9DF11DEAD80@BN7PR02MB5073.namprd02.prod.outlook.com>
Message-ID: <CO2PR01MB219883DB7E69CC84A6B433A1CCDA0@CO2PR01MB2198.prod.exchangelabs.com>

Thank you Bill and Thierry.


I don't yet have data in hand (cortisol samples await assay). However, this is what they will look like:

                     cortisol
           ---------------------------------
ID   DV    Month 1   Month 2  ...   Month 8     dam age, sire age, calf birthdate
 1  ....
 2  ....
..  ....
60  ....

While I can simulate more data, my primary question is theoretical:

Is it acceptable practice to share a single dependent response (DV: here calf mass (kg)) amongst multiple time-varying nested independent predictors (here, monthly cortisol) as long as I place a random effect to signify the individual I am nesting on (ID).



ID    DV   cortisol,  time,   dam age, sire age, calf birthdate
  1    17      35     Month 1     4        3          140
  1    17      42     Month 2     4        3          140
 ........................................................
  1    17      58     Month 8     4        3          140

 2    19      30     Month 1     3        5          150
 2    19      33     Month 2     3        5          150
........................................................
 2    19      42     Month 7     3        5          150

........................................................

60   14      51     Month 2     2        2          162
60   14      58     Month 3     2        2          162
........................................................
60   14      70     Month 8     2        2          162

>From my digging, I don't think it is good practice. So, for now, I am planning to average repeated cortisol samples within an individual to produce an 'early' and 'late' value, and include both as covariates within a glm.


I appreciate your support and encouragement!

El


Ellen Pero
PhD Student
Wildlife Biology Program
W.A. Franke College of Forestry and Conservation
University of Montana
32 Campus Drive, FOR 318
Missoula, MT 59812



________________________________
From: Bill Poling <Bill.Poling at zelis.com>
Sent: Monday, November 19, 2018 4:26 AM
To: Pero, Ellen
Cc: Thierry Onkelinx; r-sig-mixed-models at r-project.org; Bill Poling
Subject: RE: [R-sig-ME] Single DV with multiple measures for time-varying IV?

Hi Ellen.

 If the data frame is not too terribly large, a dput() would be useful.
See ?dput()
Or a str() would help as well
See ?str()
However, as Thierry suggests a subset of your data would be most helpful.

I will be interested to follow this topic as I am teaching myself R and learning the various modeling methods and their purposes along the way.

I think you will gain considerable support from this list relevant to your topic.

Best regards.

WHP


From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Thierry Onkelinx via R-sig-mixed-models
Sent: Monday, November 19, 2018 4:01 AM
To: ellen.pero at umconnect.umt.edu
Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Single DV with multiple measures for time-varying IV?

Dear Ellen,

An extract of your dataset or a small dummy dataset coverting the important
features of your data would make it much easier to answer your questions.
And please don't send HTML emails. Any HTML formating gets stripped which
can make your email very hard to read.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
mailto:thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
http://www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op ma 12 nov. 2018 om 20:01 schreef Pero, Ellen <
mailto:ellen.pero at umconnect.umt.edu>:

> Hi all:
>
> I have an analytical dilemma wherein I have a single DV with multiple
> categorical and continuous IVs (one of which is a continuous IV that has
> multiple measurements across time). I'm not sure the best way to model for
> this - though it's clearly a hierarchical situation so I thought this might
> be a good venue to pose the question.
>
> Specifically, I have 60 pregnant elk from which I took monthly cortisol
> samples across gestation (some missing values, so 5-8 samples/female across
> gestation). I'm interested in how those stress measurements across
> gestation (along with a range of other IVs that don't vary with time, e.g.,
> dam age, sire age, calf birthdate) influence the birth mass of each
> female's calf.
>
> Any suggestions on analysis for situations where a single DV is predicted
> by longitudinal measures of time-varying IV (along with non-varying IVs)?
>
> I'm new to this list and will spend some time familiarizing myself with it
> - but was eager to get my question out. Apologies if this isn't the right
> venue for my non-development related question. Please disregard if
> appropriate.
>
> I appreciate any thoughts/advice/suggestions!
> El
>
>
>
> Ellen Pero
> PhD Student
> Wildlife Biology Program
> W.A. Franke College of Forestry and Conservation
> University of Montana
> 32 Campus Drive, FOR 318
> Missoula, MT 59812
>
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> mailto:R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

[[alternative HTML version deleted]]

_______________________________________________
mailto:R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

Confidentiality Notice This message is sent from Zelis. ...{{dropped:16}}


From d@e@kornbrot @ending from hert@@@c@uk  Wed Nov 21 17:50:09 2018
From: d@e@kornbrot @ending from hert@@@c@uk (Kornbrot, Diana)
Date: Wed, 21 Nov 2018 16:50:09 +0000
Subject: [R-sig-ME] Error means squares  in GLMER and LMER
Message-ID: <9EFFD613-6137-4BDD-94A0-96E450C0B8E0@herts.ac.uk>

How  canine  obtain mean squares   for errors  used  to compute  F  values  in GLMER and LMER?
Would  also    like to be  able  to  obtain marginal  means and standard error in addition to the coefficients.
Must be  possible but   couldn?t  find how
Is it possible to  directly specify error terms  rather  than declaring   which slopes  and intercepts  are  random?
All help  gratefully received
Best
Diana
_____________________________________
Professor Diana Kornbrot
Mobile
+44 (0) 7403 18 16 12
Work
University of Hertfordshire
College Lane, Hatfield, Hertfordshire AL10 9AB, UK
+44 (0) 170 728 4626
d.e.kornbrot at herts.ac.uk<mailto:d.e.kornbrot at herts.ac.uk>
http://dianakornbrot.wordpress.com/
http://go.herts.ac.uk/Diana_Kornbrot
skype:  kornbrotme
Home
19 Elmhurst Avenue
London N2 0LT, UK
+44 (0) 208 444 2081
 ------------------------------------------------------------




	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Wed Nov 21 18:42:49 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Wed, 21 Nov 2018 12:42:49 -0500
Subject: [R-sig-ME] 
 Single DV with multiple measures for time-varying IV?
In-Reply-To: <CO2PR01MB219883DB7E69CC84A6B433A1CCDA0@CO2PR01MB2198.prod.exchangelabs.com>
References: <CO2PR01MB2198B93539290F1E5DC5C285CCC10@CO2PR01MB2198.prod.exchangelabs.com>
 <CAJuCY5x0P2rku4rp8C0yONEOEOL2=Mrtg3SUkOBUS__pSh7mDQ@mail.gmail.com>
 <BN7PR02MB5073E8F44D59F30E7F9DF11DEAD80@BN7PR02MB5073.namprd02.prod.outlook.com>
 <CO2PR01MB219883DB7E69CC84A6B433A1CCDA0@CO2PR01MB2198.prod.exchangelabs.com>
Message-ID: <0bddf8a7-1334-006c-a40f-4133bc6fc3b0@gmail.com>


  Just for the record; I agree that it's almost definitely *not* going
to work to have identical responses for different predictor values.
Someone asked a similar question on StackOverflow recently:
https://stackoverflow.com/questions/53034261/warning-lme4-model-failed-to-converge-with-maxgrad

  cheers
   Ben Bolker

On 2018-11-21 10:28 a.m., Pero, Ellen wrote:
> Thank you Bill and Thierry.
> 
> 
> I don't yet have data in hand (cortisol samples await assay). However, this is what they will look like:
> 
>                      cortisol
>            ---------------------------------
> ID   DV    Month 1   Month 2  ...   Month 8     dam age, sire age, calf birthdate
>  1  ....
>  2  ....
> ..  ....
> 60  ....
> 
> While I can simulate more data, my primary question is theoretical:
> 
> Is it acceptable practice to share a single dependent response (DV: here calf mass (kg)) amongst multiple time-varying nested independent predictors (here, monthly cortisol) as long as I place a random effect to signify the individual I am nesting on (ID).
> 
> 
> 
> ID    DV   cortisol,  time,   dam age, sire age, calf birthdate
>   1    17      35     Month 1     4        3          140
>   1    17      42     Month 2     4        3          140
>  ........................................................
>   1    17      58     Month 8     4        3          140
> 
>  2    19      30     Month 1     3        5          150
>  2    19      33     Month 2     3        5          150
> ........................................................
>  2    19      42     Month 7     3        5          150
> 
> ........................................................
> 
> 60   14      51     Month 2     2        2          162
> 60   14      58     Month 3     2        2          162
> ........................................................
> 60   14      70     Month 8     2        2          162
> 
> From my digging, I don't think it is good practice. So, for now, I am planning to average repeated cortisol samples within an individual to produce an 'early' and 'late' value, and include both as covariates within a glm.
> 
> 
> I appreciate your support and encouragement!
> 
> El
> 
> 
> Ellen Pero
> PhD Student
> Wildlife Biology Program
> W.A. Franke College of Forestry and Conservation
> University of Montana
> 32 Campus Drive, FOR 318
> Missoula, MT 59812
> 
> 
> 
> ________________________________
> From: Bill Poling <Bill.Poling at zelis.com>
> Sent: Monday, November 19, 2018 4:26 AM
> To: Pero, Ellen
> Cc: Thierry Onkelinx; r-sig-mixed-models at r-project.org; Bill Poling
> Subject: RE: [R-sig-ME] Single DV with multiple measures for time-varying IV?
> 
> Hi Ellen.
> 
>  If the data frame is not too terribly large, a dput() would be useful.
> See ?dput()
> Or a str() would help as well
> See ?str()
> However, as Thierry suggests a subset of your data would be most helpful.
> 
> I will be interested to follow this topic as I am teaching myself R and learning the various modeling methods and their purposes along the way.
> 
> I think you will gain considerable support from this list relevant to your topic.
> 
> Best regards.
> 
> WHP
> 
> 
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Thierry Onkelinx via R-sig-mixed-models
> Sent: Monday, November 19, 2018 4:01 AM
> To: ellen.pero at umconnect.umt.edu
> Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] Single DV with multiple measures for time-varying IV?
> 
> Dear Ellen,
> 
> An extract of your dataset or a small dummy dataset coverting the important
> features of your data would make it much easier to answer your questions.
> And please don't send HTML emails. Any HTML formating gets stripped which
> can make your email very hard to read.
> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Statisticus / Statistician
> 
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> mailto:thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> http://www.inbo.be
> 
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
> 
> <https://www.inbo.be>
> 
> 
> Op ma 12 nov. 2018 om 20:01 schreef Pero, Ellen <
> mailto:ellen.pero at umconnect.umt.edu>:
> 
>> Hi all:
>>
>> I have an analytical dilemma wherein I have a single DV with multiple
>> categorical and continuous IVs (one of which is a continuous IV that has
>> multiple measurements across time). I'm not sure the best way to model for
>> this - though it's clearly a hierarchical situation so I thought this might
>> be a good venue to pose the question.
>>
>> Specifically, I have 60 pregnant elk from which I took monthly cortisol
>> samples across gestation (some missing values, so 5-8 samples/female across
>> gestation). I'm interested in how those stress measurements across
>> gestation (along with a range of other IVs that don't vary with time, e.g.,
>> dam age, sire age, calf birthdate) influence the birth mass of each
>> female's calf.
>>
>> Any suggestions on analysis for situations where a single DV is predicted
>> by longitudinal measures of time-varying IV (along with non-varying IVs)?
>>
>> I'm new to this list and will spend some time familiarizing myself with it
>> - but was eager to get my question out. Apologies if this isn't the right
>> venue for my non-development related question. Please disregard if
>> appropriate.
>>
>> I appreciate any thoughts/advice/suggestions!
>> El
>>
>>
>>
>> Ellen Pero
>> PhD Student
>> Wildlife Biology Program
>> W.A. Franke College of Forestry and Conservation
>> University of Montana
>> 32 Campus Drive, FOR 318
>> Missoula, MT 59812
>>
>>
>> [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> mailto:R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________
> mailto:R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:16}}
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From r@turner @ending from @uckl@nd@@c@nz  Thu Nov 22 01:21:14 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Thu, 22 Nov 2018 13:21:14 +1300
Subject: [R-sig-ME] [FORGED]  Error means squares in GLMER and LMER
In-Reply-To: <9EFFD613-6137-4BDD-94A0-96E450C0B8E0@herts.ac.uk>
References: <9EFFD613-6137-4BDD-94A0-96E450C0B8E0@herts.ac.uk>
Message-ID: <62dbb33b-29b0-260c-415d-5185e2e04976@auckland.ac.nz>


On 11/22/18 5:50 AM, Kornbrot, Diana wrote:

> How  canine  obtain mean squares   for errors  used  to compute  F
> values  in GLMER and LMER?

<SNIP>

Were you trying to be funny, or did you get bitten by some damned 
predictive text program?

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From thierry@onkelinx @ending from inbo@be  Thu Nov 22 09:47:03 2018
From: thierry@onkelinx @ending from inbo@be (Thierry Onkelinx)
Date: Thu, 22 Nov 2018 09:47:03 +0100
Subject: [R-sig-ME] 
 Single DV with multiple measures for time-varying IV?
In-Reply-To: <0bddf8a7-1334-006c-a40f-4133bc6fc3b0@gmail.com>
References: <CO2PR01MB2198B93539290F1E5DC5C285CCC10@CO2PR01MB2198.prod.exchangelabs.com>
 <CAJuCY5x0P2rku4rp8C0yONEOEOL2=Mrtg3SUkOBUS__pSh7mDQ@mail.gmail.com>
 <BN7PR02MB5073E8F44D59F30E7F9DF11DEAD80@BN7PR02MB5073.namprd02.prod.outlook.com>
 <CO2PR01MB219883DB7E69CC84A6B433A1CCDA0@CO2PR01MB2198.prod.exchangelabs.com>
 <0bddf8a7-1334-006c-a40f-4133bc6fc3b0@gmail.com>
Message-ID: <CAJuCY5w44vFHdO5AXU51pNsUoebR9eeFS3WsbGYBQZO9CunSmg@mail.gmail.com>

And even if the model would converge, then it still is wrong to do it. When
modelling the calf birth weight, then one calf = one observation. A calf is
born once.

In case you have plenlty of births, then you could try to model the
cortisol values and use that model to impute missing values. And then model
the birth weight using the augemented data. Make sure to use multiple
imputation to do so! Otherwise the confidence intervals will be too small.
See e.g. Rubin 1987 and Onkelinx et al 2017 (doi:10.1007/s10336-016-1404-9)

However given that you have only 60 observations, you have too few
observations to take each of the eight months into account.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op wo 21 nov. 2018 om 18:50 schreef Ben Bolker <bbolker at gmail.com>:

>
>   Just for the record; I agree that it's almost definitely *not* going
> to work to have identical responses for different predictor values.
> Someone asked a similar question on StackOverflow recently:
>
> https://stackoverflow.com/questions/53034261/warning-lme4-model-failed-to-converge-with-maxgrad
>
>   cheers
>    Ben Bolker
>
> On 2018-11-21 10:28 a.m., Pero, Ellen wrote:
> > Thank you Bill and Thierry.
> >
> >
> > I don't yet have data in hand (cortisol samples await assay). However,
> this is what they will look like:
> >
> >                      cortisol
> >            ---------------------------------
> > ID   DV    Month 1   Month 2  ...   Month 8     dam age, sire age, calf
> birthdate
> >  1  ....
> >  2  ....
> > ..  ....
> > 60  ....
> >
> > While I can simulate more data, my primary question is theoretical:
> >
> > Is it acceptable practice to share a single dependent response (DV: here
> calf mass (kg)) amongst multiple time-varying nested independent predictors
> (here, monthly cortisol) as long as I place a random effect to signify the
> individual I am nesting on (ID).
> >
> >
> >
> > ID    DV   cortisol,  time,   dam age, sire age, calf birthdate
> >   1    17      35     Month 1     4        3          140
> >   1    17      42     Month 2     4        3          140
> >  ........................................................
> >   1    17      58     Month 8     4        3          140
> >
> >  2    19      30     Month 1     3        5          150
> >  2    19      33     Month 2     3        5          150
> > ........................................................
> >  2    19      42     Month 7     3        5          150
> >
> > ........................................................
> >
> > 60   14      51     Month 2     2        2          162
> > 60   14      58     Month 3     2        2          162
> > ........................................................
> > 60   14      70     Month 8     2        2          162
> >
> > From my digging, I don't think it is good practice. So, for now, I am
> planning to average repeated cortisol samples within an individual to
> produce an 'early' and 'late' value, and include both as covariates within
> a glm.
> >
> >
> > I appreciate your support and encouragement!
> >
> > El
> >
> >
> > Ellen Pero
> > PhD Student
> > Wildlife Biology Program
> > W.A. Franke College of Forestry and Conservation
> > University of Montana
> > 32 Campus Drive, FOR 318
> > Missoula, MT 59812
> >
> >
> >
> > ________________________________
> > From: Bill Poling <Bill.Poling at zelis.com>
> > Sent: Monday, November 19, 2018 4:26 AM
> > To: Pero, Ellen
> > Cc: Thierry Onkelinx; r-sig-mixed-models at r-project.org; Bill Poling
> > Subject: RE: [R-sig-ME] Single DV with multiple measures for
> time-varying IV?
> >
> > Hi Ellen.
> >
> >  If the data frame is not too terribly large, a dput() would be useful.
> > See ?dput()
> > Or a str() would help as well
> > See ?str()
> > However, as Thierry suggests a subset of your data would be most helpful.
> >
> > I will be interested to follow this topic as I am teaching myself R and
> learning the various modeling methods and their purposes along the way.
> >
> > I think you will gain considerable support from this list relevant to
> your topic.
> >
> > Best regards.
> >
> > WHP
> >
> >
> > From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On
> Behalf Of Thierry Onkelinx via R-sig-mixed-models
> > Sent: Monday, November 19, 2018 4:01 AM
> > To: ellen.pero at umconnect.umt.edu
> > Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
> > Subject: Re: [R-sig-ME] Single DV with multiple measures for
> time-varying IV?
> >
> > Dear Ellen,
> >
> > An extract of your dataset or a small dummy dataset coverting the
> important
> > features of your data would make it much easier to answer your questions.
> > And please don't send HTML emails. Any HTML formating gets stripped which
> > can make your email very hard to read.
> >
> > Best regards,
> >
> > ir. Thierry Onkelinx
> > Statisticus / Statistician
> >
> > Vlaamse Overheid / Government of Flanders
> > INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> AND
> > FOREST
> > Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> > mailto:thierry.onkelinx at inbo.be
> > Havenlaan 88 bus 73, 1000 Brussel
> > http://www.inbo.be
> >
> >
> ///////////////////////////////////////////////////////////////////////////////////////////
> > To call in the statistician after the experiment is done may be no more
> > than asking him to perform a post-mortem examination: he may be able to
> say
> > what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > The plural of anecdote is not data. ~ Roger Brinner
> > The combination of some data and an aching desire for an answer does not
> > ensure that a reasonable answer can be extracted from a given body of
> data.
> > ~ John Tukey
> >
> ///////////////////////////////////////////////////////////////////////////////////////////
> >
> > <https://www.inbo.be>
> >
> >
> > Op ma 12 nov. 2018 om 20:01 schreef Pero, Ellen <
> > mailto:ellen.pero at umconnect.umt.edu>:
> >
> >> Hi all:
> >>
> >> I have an analytical dilemma wherein I have a single DV with multiple
> >> categorical and continuous IVs (one of which is a continuous IV that has
> >> multiple measurements across time). I'm not sure the best way to model
> for
> >> this - though it's clearly a hierarchical situation so I thought this
> might
> >> be a good venue to pose the question.
> >>
> >> Specifically, I have 60 pregnant elk from which I took monthly cortisol
> >> samples across gestation (some missing values, so 5-8 samples/female
> across
> >> gestation). I'm interested in how those stress measurements across
> >> gestation (along with a range of other IVs that don't vary with time,
> e.g.,
> >> dam age, sire age, calf birthdate) influence the birth mass of each
> >> female's calf.
> >>
> >> Any suggestions on analysis for situations where a single DV is
> predicted
> >> by longitudinal measures of time-varying IV (along with non-varying
> IVs)?
> >>
> >> I'm new to this list and will spend some time familiarizing myself with
> it
> >> - but was eager to get my question out. Apologies if this isn't the
> right
> >> venue for my non-development related question. Please disregard if
> >> appropriate.
> >>
> >> I appreciate any thoughts/advice/suggestions!
> >> El
> >>
> >>
> >>
> >> Ellen Pero
> >> PhD Student
> >> Wildlife Biology Program
> >> W.A. Franke College of Forestry and Conservation
> >> University of Montana
> >> 32 Campus Drive, FOR 318
> >> Missoula, MT 59812
> >>
> >>
> >> [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> mailto:R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
> > [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > mailto:R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> > Confidentiality Notice This message is sent from Zelis. ...{{dropped:16}}
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From thierry@onkelinx @ending from inbo@be  Thu Nov 22 11:55:25 2018
From: thierry@onkelinx @ending from inbo@be (Thierry Onkelinx)
Date: Thu, 22 Nov 2018 11:55:25 +0100
Subject: [R-sig-ME] Adding random subject or item slopes for a specific
 contrast
In-Reply-To: <D61485BE-A54F-4811-94D4-F62EB6A09279@ucalgary.ca>
References: <2E987257-ADF7-43A3-B95B-CB9420CE820A@ucalgary.ca>
 <CAJuCY5wdvBcMnPGq_9TE6GAfs0E+=SW4ERMubxeVy_K1jASP9Q@mail.gmail.com>
 <D61485BE-A54F-4811-94D4-F62EB6A09279@ucalgary.ca>
Message-ID: <CAJuCY5wOAm2hKPU33siudr0xPk1nnGJQSx1A=BOfqM5v_YPX=Q@mail.gmail.com>

Dear Dave,

I strongly suggest that you write down the equation of the model with a
random slope for each factor level and the equation of the model you have
in mind. That would allow you to see which coefficients need to be zero.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op ma 19 nov. 2018 om 21:03 schreef David Sidhu <dsidhu at ucalgary.ca>:

> Hi Thierry
>
> Thank you very much for the reply, and apologies for the troubling code.
>
> I have two follow up questions:
>
> 1) Suppose IV is a three level factor. Would I still use this variable for
> the fixed effects, but then create a dummy variable reflecting the random
> slope that I want to include? I assume this works out the same as creating
> a pair of dummy variables to use for fixed effects, and then using one for
> the random slope.
>
> 2) Is it advisable to do this? I.e., to only include the slope for a
> single contrast. Or, is this problematic statistically.
>
> Thanks very much.
>
> Dave
>
> ---
> David M. Sidhu, MSc
> PhD Candidate
> Department of Psychology
> University of Calgary
>
>
>
>
>
>
> On Nov 19, 2018, at 1:54 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
>
> Dear David,
>
> I think you can solve this by creating a dummy variable which has zero's
> in case you are not interested in the random slope.
>
> Please note that sending HTML has ruined the code formating, making your
> code much harder to read.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be/>
>
>
> Op do 8 nov. 2018 om 16:55 schreef David Sidhu <dsidhu at ucalgary.ca>:
>
>> Hi There
>>
>> I have been following the approach described in Bates et al. (2018) to
>> simplify my random effects structure. I will use the data pasted below as
>> an example (though the effects I describe aren?t present there, I use it
>> only to have an example to refer to).
>>
>> Now, if it seems that there is variance in the random subject slope
>> comparing IV1 level 2 vs. IV1 level 1, but in no other contrast?s random
>> subject slope, I would like to only include a random subject slope for that
>> one specific contrast. Also assume that the method described by Bates et
>> al. (2018) suggests that the random effects structure should only have one
>> component.
>>
>> Two questions: Is it sensible to only include this one slope? Is it
>> possible in lme4 to only include this one slope?
>>
>> Thanks!
>> Dave
>>
>>
>>
>>
>>
>> Subj <- rep(1:10, each = 10) Item <- rep(1:10, times = 10) IV1 <-
>> rep(1:5, times = 20) DV <- rnorm(100) library(data.table) data <-
>> as.data.table(cbind(Subj, Item, IV1, DV)) data$Subj <- as.factor(data$Subj)
>> data$Item <- as.factor(data$Item) data$IV1 <- as.factor(data$IV1)
>> library(MASS) contrasts(data$IV1) <- contr.sdif(5) library(lme4) m <-
>> lmer(DV ~ IV1 + (1 + IV1|Subj) + (1|Item), data = data)
>>
>>
>>
>>
>> ---
>> David M. Sidhu, MSc
>> PhD Candidate
>> Department of Psychology
>> University of Calgary
>>
>>
>>
>>
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>

	[[alternative HTML version deleted]]


From r@turner @ending from @uckl@nd@@c@nz  Thu Nov 22 11:58:48 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Thu, 22 Nov 2018 23:58:48 +1300
Subject: [R-sig-ME] [FORGED]  Error means squares in GLMER and LMER
In-Reply-To: <F2775224-C9F2-4FE6-A0F2-E3D074B18587@herts.ac.uk>
References: <9EFFD613-6137-4BDD-94A0-96E450C0B8E0@herts.ac.uk>
 <62dbb33b-29b0-260c-415d-5185e2e04976@auckland.ac.nz>
 <F2775224-C9F2-4FE6-A0F2-E3D074B18587@herts.ac.uk>
Message-ID: <db9af0a5-7cae-f4ca-4982-3308a1f4b54e@auckland.ac.nz>


On 11/22/18 8:37 PM, Kornbrot, Diana wrote:

> My, supposedly helpfu,l predictive text programme has a warped sense of 
> humour.
> Unlike the R documentation which is tedious, verbose, is always sending 
> me on wild goose changes ?and never seems to tell me what i need to know.
> 
> Please, please
> How do I get those means square error terms form lmer and glmer?

I think your accusations against the R documentation are unfair.

Be that as it were, let me respond a little bit to your substantive 
question.  I am no expert, so take everything I say with a grain of 
salt.  Perhaps someone from the R-sig-ME list, who is more knowledgeable 
than I, will give you better advice.

My conjecture is that you are having trouble getting hold of mean 
squared error terms because there *aren't* any.  Mixed models are not 
based on sums of squares; they are *likelihood* based.  Inference is 
based on likelihood ratio tests, not on F-tests.  The covariance matrix 
for the coefficient estimates is formed as the inverse of the Fisher 
Information matrix.  It does not have the simple form that it has in the 
context of ("un-mixed"; ordinary garden-variety) linear models.

Consequently you will need to readjust your thinking.  The learning 
curve for mixed models is steep.  I have barely got my own toes onto the 
bottom of the lowermost slopes.

I hope that I haven't misunderstood either your question or the 
underlying structure of mixed models.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From roeem@or @ending from gm@il@com  Thu Nov 22 12:39:20 2018
From: roeem@or @ending from gm@il@com (roee maor)
Date: Thu, 22 Nov 2018 11:39:20 +0000
Subject: [R-sig-ME] Error means squares in GLMER and LMER
Message-ID: <CACxNx6tfdct1udzTFbE7=N59V1ZExYa8ks+MEEhNZCp9w=myrw@mail.gmail.com>

Dear Diana,
If indeed what you're looking for is what Rolf mentioned, you might find
Nakagawa & Schielzeth (2013) helpful.
It's titled "A general and simple method for obtaining R2 from generalized
linear mixed-effects models". There is no dispute about the method's
generality, but simple is a relative term...
Here's the link:
https://besjournals.onlinelibrary.wiley.com/doi/epdf/10.1111/j.2041-210x.2012.00261.x

Hope this helps,
-- 
Roi Maor
PhD candidate
School of Zoology, Tel Aviv University
Centre for Biodiversity and Environment Research, UCL

	[[alternative HTML version deleted]]


From d@e@kornbrot @ending from hert@@@c@uk  Thu Nov 22 15:40:12 2018
From: d@e@kornbrot @ending from hert@@@c@uk (Kornbrot, Diana)
Date: Thu, 22 Nov 2018 14:40:12 +0000
Subject: [R-sig-ME] Error means squares in GLMER and LMER
In-Reply-To: <CACxNx6tfdct1udzTFbE7=N59V1ZExYa8ks+MEEhNZCp9w=myrw@mail.gmail.com>
References: <CACxNx6tfdct1udzTFbE7=N59V1ZExYa8ks+MEEhNZCp9w=myrw@mail.gmail.com>
Message-ID: <E3DF360A-ADBC-4C65-A6F7-855C6A9772F1@herts.ac.uk>

Dear Roi
Thanks veyr useful  reference
BUT
It assume variance component model, i.e. correlations are assumed zero [not mentioned]



On 22 Nov 2018, at 11:39, roee maor <roeemaor at gmail.com<mailto:roeemaor at gmail.com>> wrote:

Dear Diana,
If indeed what you're looking for is what Rolf mentioned, you might find Nakagawa & Schielzeth (2013) helpful.
It's titled "A general and simple method for obtaining R2 from generalized linear mixed-effects models". There is no dispute about the method's generality, but simple is a relative term...
Here's the link: https://besjournals.onlinelibrary.wiley.com/doi/epdf/10.1111/j.2041-210x.2012.00261.x

Hope this helps,
--
Roi Maor
PhD candidate
School of Zoology, Tel Aviv University
Centre for Biodiversity and Environment Research, UCL

_____________________________________
Professor Diana Kornbrot
Mobile
+44 (0) 7403 18 16 12
Work
University of Hertfordshire
College Lane, Hatfield, Hertfordshire AL10 9AB, UK
+44 (0) 170 728 4626
d.e.kornbrot at herts.ac.uk<mailto:d.e.kornbrot at herts.ac.uk>
http://dianakornbrot.wordpress.com/
http://go.herts.ac.uk/Diana_Kornbrot
skype:  kornbrotme
Home
19 Elmhurst Avenue
London N2 0LT, UK
+44 (0) 208 444 2081
 ------------------------------------------------------------




	[[alternative HTML version deleted]]


From d@e@kornbrot @ending from hert@@@c@uk  Thu Nov 22 18:09:56 2018
From: d@e@kornbrot @ending from hert@@@c@uk (Kornbrot, Diana)
Date: Thu, 22 Nov 2018 17:09:56 +0000
Subject: [R-sig-ME] Error means squares in GLMER and LMER
In-Reply-To: <CACxNx6tfdct1udzTFbE7=N59V1ZExYa8ks+MEEhNZCp9w=myrw@mail.gmail.com>
References: <CACxNx6tfdct1udzTFbE7=N59V1ZExYa8ks+MEEhNZCp9w=myrw@mail.gmail.com>
Message-ID: <8D3FBC0E-8BFD-4AC9-89BF-D71F6A408873@herts.ac.uk>

So I am comparing standard ANOVA on raw  frequencies (or equivalently probabilities) with GLMM for  binomial  proportion with both  logit and probit   link
ALL analyses have  been completed in SPSS using MIXED for: response   = identity ,  link = normal ; response =  proportion=freq/Nmax, link =  probit; response = proportion link  = logit)
I want   to show  how to  do identical  analyses in R using lmer  for are freq and  glmer for proportions
So I wasn?t SAME results  from R and SPSS (and a  diamond  necklace for Christmas,  celebrated as  an EU citizen in UK - I am a demanding woman)
Results are NOT quite  the same.
I am  checking using  the raw  probabilities as raw response with lmer before  moving  on to  glmer  for proportions
Check 1, in SPSS for raw  freq or  probability REPEATED  give  same  result   as  MIXED (response = identity, link = normal). where  there are differences it is REPEATED WITHIN  comparisons  not MULTIVARIATE.
Check 2. Compare R,  lmer with SPSS  mixed
if repeated groups are w1,  w2,  etc  and between groups are b1,  b2  etc, I use:
result <- lmer(freq~b1*b2*w1*w2 + (w1|subject)  + (w2|subject),  data  =  test)
anova(result)
Fand df from R  and SPSS do  not always match,  even  when  they do  match on sums  of squares
I am trying  to  work out WHY there is a mismatch
Thought that  knowing what was in the DENOMINATOR of the F values - which i perhaps  wrongly termed  error sums  of squares, might help

I  want F  for usual reasons:   to test significance  and estimate  effect  size.
I also want  all  my packages  to  give  me the SAME F and df2 and to  UNDERSTAND what is happening

Sorry this is  so long,  but  hope it is now clearer

best

Diana

and as  an extra  treat  would like marginal means from object  of type lmer

Dear Diana,
If indeed what you're looking for is what Rolf mentioned, you might find Nakagawa & Schielzeth (2013) helpful.
It's titled "A general and simple method for obtaining R2 from generalized linear mixed-effects models". There is no dispute about the method's generality, but simple is a relative term...
Here's the link: https://besjournals.onlinelibrary.wiley.com/doi/epdf/10.1111/j.2041-210x.2012.00261.x

Hope this helps,
--
Roi Maor
PhD candidate
School of Zoology, Tel Aviv University
Centre for Biodiversity and Environment Research, UCL

_____________________________________
Professor Diana Kornbrot
Mobile
+44 (0) 7403 18 16 12
Work
University of Hertfordshire
College Lane, Hatfield, Hertfordshire AL10 9AB, UK
+44 (0) 170 728 4626
d.e.kornbrot at herts.ac.uk<mailto:d.e.kornbrot at herts.ac.uk>
http://dianakornbrot.wordpress.com/
http://go.herts.ac.uk/Diana_Kornbrot
skype:  kornbrotme
Home
19 Elmhurst Avenue
London N2 0LT, UK
+44 (0) 208 444 2081
 ------------------------------------------------------------




	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Thu Nov 22 20:44:27 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Thu, 22 Nov 2018 14:44:27 -0500
Subject: [R-sig-ME] Error means squares in GLMER and LMER
In-Reply-To: <8D3FBC0E-8BFD-4AC9-89BF-D71F6A408873@herts.ac.uk>
References: <CACxNx6tfdct1udzTFbE7=N59V1ZExYa8ks+MEEhNZCp9w=myrw@mail.gmail.com>
 <8D3FBC0E-8BFD-4AC9-89BF-D71F6A408873@herts.ac.uk>
Message-ID: <CABghstStwFkNHw1SU59ZPRPxAYBPxf4061pixfuVKhFrNnp8iA@mail.gmail.com>

For marginal means, use the emmeans package.

If you use the lmerTest package, you can get Satterthwaite or
Kenward-Roger df: you can use lme (from the nlme package), or
<https://github.com/bbolker/mixedmodels-misc/blob/master/R/calcDenDF.R>,
to get df via a simple "parameter-counting" exercise.

The problem is that the "F statistics" are quite poorly defined for
GLMMs. Can you show us the contrasting results you're getting for SPSS
and glmer?  Do you know how SPSS is computing the F statistics?  (This
<https://www.ibm.com/support/knowledgecenter/en/SS3RA7_15.0.0/com.ibm.spss.modeler.help/idh_glmm_build_options.htm>
makes it seem like it might be using Satterthwaite approximations ...)
On Thu, Nov 22, 2018 at 12:09 PM Kornbrot, Diana
<d.e.kornbrot at herts.ac.uk> wrote:
>
> So I am comparing standard ANOVA on raw  frequencies (or equivalently probabilities) with GLMM for  binomial  proportion with both  logit and probit   link
> ALL analyses have  been completed in SPSS using MIXED for: response   = identity ,  link = normal ; response =  proportion=freq/Nmax, link =  probit; response = proportion link  = logit)
> I want   to show  how to  do identical  analyses in R using lmer  for are freq and  glmer for proportions
> So I wasn?t SAME results  from R and SPSS (and a  diamond  necklace for Christmas,  celebrated as  an EU citizen in UK - I am a demanding woman)
> Results are NOT quite  the same.
> I am  checking using  the raw  probabilities as raw response with lmer before  moving  on to  glmer  for proportions
> Check 1, in SPSS for raw  freq or  probability REPEATED  give  same  result   as  MIXED (response = identity, link = normal). where  there are differences it is REPEATED WITHIN  comparisons  not MULTIVARIATE.
> Check 2. Compare R,  lmer with SPSS  mixed
> if repeated groups are w1,  w2,  etc  and between groups are b1,  b2  etc, I use:
> result <- lmer(freq~b1*b2*w1*w2 + (w1|subject)  + (w2|subject),  data  =  test)
> anova(result)
> Fand df from R  and SPSS do  not always match,  even  when  they do  match on sums  of squares
> I am trying  to  work out WHY there is a mismatch
> Thought that  knowing what was in the DENOMINATOR of the F values - which i perhaps  wrongly termed  error sums  of squares, might help
>
> I  want F  for usual reasons:   to test significance  and estimate  effect  size.
> I also want  all  my packages  to  give  me the SAME F and df2 and to  UNDERSTAND what is happening
>
> Sorry this is  so long,  but  hope it is now clearer
>
> best
>
> Diana
>
> and as  an extra  treat  would like marginal means from object  of type lmer
>
> Dear Diana,
> If indeed what you're looking for is what Rolf mentioned, you might find Nakagawa & Schielzeth (2013) helpful.
> It's titled "A general and simple method for obtaining R2 from generalized linear mixed-effects models". There is no dispute about the method's generality, but simple is a relative term...
> Here's the link: https://besjournals.onlinelibrary.wiley.com/doi/epdf/10.1111/j.2041-210x.2012.00261.x
>
> Hope this helps,
> --
> Roi Maor
> PhD candidate
> School of Zoology, Tel Aviv University
> Centre for Biodiversity and Environment Research, UCL
>
> _____________________________________
> Professor Diana Kornbrot
> Mobile
> +44 (0) 7403 18 16 12
> Work
> University of Hertfordshire
> College Lane, Hatfield, Hertfordshire AL10 9AB, UK
> +44 (0) 170 728 4626
> d.e.kornbrot at herts.ac.uk<mailto:d.e.kornbrot at herts.ac.uk>
> http://dianakornbrot.wordpress.com/
> http://go.herts.ac.uk/Diana_Kornbrot
> skype:  kornbrotme
> Home
> 19 Elmhurst Avenue
> London N2 0LT, UK
> +44 (0) 208 444 2081
>  ------------------------------------------------------------
>
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From roeem@or @ending from gm@il@com  Thu Nov 22 23:59:33 2018
From: roeem@or @ending from gm@il@com (roee maor)
Date: Thu, 22 Nov 2018 22:59:33 +0000
Subject: [R-sig-ME] 
 Unclear output from MCMCglmm with categorical predictors
In-Reply-To: <1551b85a-2cb7-0a46-7014-fb19598c0376@ed.ac.uk>
References: <CACxNx6tyjKHjBVGVhs+aER7i9iSv4ODvOhofH1ERatAUqexmxw@mail.gmail.com>
 <1B1687E4-41BE-41F8-8AB3-2D81B44383B5@ed.ac.uk>
 <CACxNx6srMCNbpj4Hk-=XmUAHjeJvDftPrhnGBhrWPKK-4vUM_g@mail.gmail.com>
 <1551b85a-2cb7-0a46-7014-fb19598c0376@ed.ac.uk>
Message-ID: <CACxNx6uqb0C3HCEpvOfKDF=pOKTzXjgZStFS-kdCibf1fgYuig@mail.gmail.com>

Dear Jarrod and Ben,
Thank you both for the advice.
Apologies if I accidentally caused anyone to receive an unexpected email.

Running the model specified above returns the error: "non-reduced nodes do
not appear first". The error persists when using a fully-bifurcating tree
so the issue is not tree polytomies.
I tried to go through the source code line-by-line to locate the problem
but got lost in the many loops and conditional statements. This error
message is conditioned on a match() output that also returns a warning that
the two arguments matched are unequal in length: one corresponds to the
tips while the other includes the tree's internal nodes as well.

As always, any help is much appreciated.
Best,
Roi



On Wed, 21 Nov 2018 at 15:05, HADFIELD Jarrod <j.hadfield at ed.ac.uk> wrote:

> Hi,
>
> You could upload the tarball to winbuilder (
> https://win-builder.r-project.org/) and build a Windows source package.
>
> Cheers,
>
> Jarrod
>
>
> On 21/11/2018 14:09, roee maor wrote:
>
> Hi Jarrod,
> Many thanks for your reply.
>
> I couldn't install the tarball on R v3.4.3 or v3.5.1 so sourced the files
> directly to the workspace.
> I tried to run this model as you suggested:
> > T1 <- MCMCglmm(Activity ~ -1 + log(Mass) + Max.Temp * Annual.Precip,
>                random = ~ animal,
>                prior = list(R = list(fix=1, V=1e-15), G = list(G1 =
> list(V=1, nu=0.002))),
>                pedigree = datatree,
>                reduced = TRUE,
>                burnin = 50000, nitt = 750001, thin = 700,
>                family = "threshold",
>                data = Rdata,
>                pl = TRUE, saveX = TRUE, saveZ = TRUE,
>                verbose = TRUE)
>
> It returns some errors about missing functions "is.positive.definite" and
> "Matrix", which I addressed with:
> > library("corpcor", lib.loc="~/R/win-library/3.5")
> > library("MatrixModels", lib.loc="~/R/win-library/3.5")
> but I can't figure this one out:
> 'Error in .C("MCMCglmm", as.double(data$MCMC_y),
> as.double(data$MCMC_y.additional),  :
>   C symbol name "MCMCglmm" not in load table'
> Detaching these packages doesn't necessarily cause that same error to
> appear although I execute the exact same code.
> Also, several attempts (same code again) caused a fatal error and
> automatic session termination (info for a similar session below if
> interesting).
>
> I tried to use the fully bifurcating tree as an experiment but that made
> no difference.
>
> Any ideas what this last error means?
>
> Thanks!
> Roi
>
>
> > sessionInfo()
> R version 3.5.1 (2018-07-02)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows >= 8 x64 (build 9200)
>
> Matrix products: default
>
> locale:
> [1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United
> Kingdom.1252    LC_MONETARY=English_United Kingdom.1252
> [4] LC_NUMERIC=C                            LC_TIME=English_United
> Kingdom.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] corpcor_1.6.9   Matrix_1.2-14   phytools_0.6-60 maps_3.3.0
> ape_5.2
>
> loaded via a namespace (and not attached):
>  [1] igraph_1.2.2            Rcpp_0.12.19            magrittr_1.5
>   MASS_7.3-50             mnormt_1.5-5
>  [6] scatterplot3d_0.3-41    lattice_0.20-35         quadprog_1.5-5
>   fastmatch_1.1-0         tools_3.5.1
> [11] parallel_3.5.1          grid_3.5.1              nlme_3.1-137
>   clusterGeneration_1.3.4 phangorn_2.4.0
> [16] plotrix_3.7-4           coda_0.19-2             yaml_2.2.0
>   numDeriv_2016.8-1       animation_2.5
> [21] compiler_3.5.1          combinat_0.0-8          expm_0.999-3
>   pkgconfig_2.0.2
>
> On Tue, 20 Nov 2018 at 20:01, HADFIELD Jarrod <j.hadfield at ed.ac.uk> wrote:
>
>> Hi,
>>
>> Most likely the phylogenetic heritability (the phylogenetic variance /
>> the phylogenetic +residual variance) is approaching one resulting in
>> numerical difficulties. Probably the best thing is to assume that the
>> phylogenetic heritability equals 1 and use the reduced phylogenetic mixed
>> model implementation. This allows the phylogenetic heritability to be equal
>> to 1 without causing numerical issues. At some point I will integrate these
>> models into the main MCMCglmm package, but for now you can download it from
>> here: http://jarrod.bio.ed.ac.uk/MCMCglmmRAM_2.24.tar.gz.
>>
>> Change the name of the ??Binomial? column to ?animal? and fit:
>>
>> T1 <- MCMCglmm(Activity ~ -1 + log(Mass) + Max.Temp * Annual.Precip,
>>                                random = ~ animal
>>                                prior = list(R = list(fix=1, V=1e-15), G =
>> list(G1 = list(V=1, nu=0.002))),
>>                                pedigree = tree,
>>        reduced=TRUE,
>>                                burnin = 150000, nitt = 2650001, thin =
>> 2500,
>>                                family = "threshold",  data = Tdata,
>>                                pl = TRUE, pr = TRUE, saveX = TRUE, saveZ
>> = TRUE,
>>                                verbose = FALSE)
>>
>> You should need fewer iterations.
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>> On 20 Nov 2018, at 18:08, roee maor <roeemaor at gmail.com> wrote:
>>
>> Dear Jarrod (and list),
>>
>> Following your previous comment I added "random = ~ Binomial" to my model
>> to allow for a phylogenetic analysis.
>> This causes convergence problems: the trace plots show increasing
>> oscillations along each chain (although no directional trends, so it's not
>> a burn-in issue). Also, the posterior samples are highly correlated,
>> residual variance estimates are >10^3 and threshold estimates are high (>20
>> on the latent scale).
>> Surprisingly (to me), predictors that are strongly significant in the
>> non-phylogenetic model lose their effect in the phylogenetic model (I tried
>> several alternative parameter configurations).
>>
>> It seems that this model attributes the explained variance to phylogeny
>> alone.
>> Can anyone explain what is going on here?  Am I specifying the model
>> poorly or just asking my data more than it can answer?
>>
>> I tried to overcome this issue by using a fully resolved variant of the
>> phylogeny, which only improved things slightly.
>> I also changed the random effect to "random=~Family" or "random=~Order",
>> which reduced the variance and threshold estimates to more acceptable
>> levels (<10), but still no significant predictors (and I'm not sure how the
>> algorithm calculates covariance between higher taxa in the phylogeny).
>> Separately I tried parameter expanded prior: "prior = list(R = list(V=1,
>> fix=1), G = list(G1 = list(V=1, nu=1, alpha.mu=0, alpha.V=1000)))". That
>> didn't help, and messing with priors for this reason feels like poor
>> practice.
>>
>> This is the model:
>> T1 <- MCMCglmm(Activity ~ -1 + log(Mass) + Max.Temp * Annual.Precip,
>>                                random = ~ Binomial,
>>                                prior = list(R = list(fix=1, V=1), G =
>> list(G1 = list(V=1, nu=0.002))),
>>                                ginverse = list(Binomial=INphylo$Ainv),
>>                                burnin = 150000, nitt = 2650001, thin =
>> 2500,
>>                                family = "threshold",  data = Tdata,
>>                                pl = TRUE, pr = TRUE, saveX = TRUE, saveZ
>> = TRUE,
>>                                verbose = FALSE)
>>
>> The data I use looks like this (not all variables appear in each model):
>>
>> str(Tdata)
>> 'data.frame': 1389 obs. of  10 variables:
>>  $ Binomial           : Factor w/ 1421 levels "Abrocoma_bennettii",..: 1
>> 2 3 4 5 6 7 8 9 10 ...
>>  $ Order                : Factor w/ 27 levels "Afrosoricida",..: 24 24 24
>> 24 24 3 24 24 2 2 ...
>>  $ Family               : Factor w/ 126 levels "Abrocomidae",..: 1 26 26
>> 26 26 46 74 87 10 10 ...
>>  $ Activity              : Factor w/ 3 levels "1","2","3": 1 3 2 2 2 3 2
>> 3 1 3 ...
>>  $ Habitat              : Factor w/ 6 levels "Aqua","Arbo",..: 5 5 5 5 5
>> 5 5 5 5 5 ...
>>  $ Diet                   : Factor w/ 3 levels "Faun","Herb",..: 2 3 3 3
>> 3 1 3 2 2 2 ...
>>  $ Mass                 : num  250.5 24.9 34.5 38.9 24.5 ...
>>  $ Max.Temp         : num  22 16.6 19.1 19.8 17.2 ...
>>  $ Annual.Precip   : num  166 645 558 903 1665 ...
>>
>> Any advice would be much appreciated!
>> Many thanks,
>>
>>
>> --
>> Roi Maor
>> PhD candidate
>> School of Zoology, Tel Aviv University
>> Centre for Biodiversity and Environment Research, UCL
>>
>>
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>
>
> --
> Roi Maor
> PhD candidate
> School of Zoology, Tel Aviv University
> Centre for Biodiversity and Environment Research, UCL
>
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>


-- 
Roi Maor
PhD candidate
School of Zoology, Tel Aviv University
Centre for Biodiversity and Environment Research, UCL

	[[alternative HTML version deleted]]


From jo@n@m@rtelo @ending from gm@il@com  Fri Nov 23 18:26:04 2018
From: jo@n@m@rtelo @ending from gm@il@com (Joana Martelo)
Date: Fri, 23 Nov 2018 17:26:04 -0000
Subject: [R-sig-ME] warnings when using binomial models and offset
Message-ID: <000a01d48351$9d70c4f0$d8524ed0$@com>

Hello everyone

 

I'm trying to model fish capture success using length, velocity and group
composition as explanatory variables, density as an offset variable, and
fish.id. as random effect. I'm getting the follow warnings:

 

Model1<-glmer(capture~length+offset(density)+(1|fish.id),family=binomial,dat
a=cap)

 

Warning messages:

1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :

  Model failed to converge with max|grad| = 0.260123 (tol = 0.001, component
1)

2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :

  Model is nearly unidentifiable: very large eigenvalue

- Rescale variables?

 

 

-          I only get the warnings when I use length and group composition,
not with velocity.

-          I don't get any warning if I don't use the offset.

 

I've tried:

Model1<-glmer(capture~length+offset(log(density))+(1|fish.id.c),family=binom
ial(link="cloglog"),data=cap)

 

But still get the warning.

 

Any ideas of what might be the problem?

 

Many thanks!

 

 

Joana Martelo

 

 

 

 

Melhores cumprimentos,

 

Joana Martins

 

 

 


	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Fri Nov 23 22:53:43 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Fri, 23 Nov 2018 16:53:43 -0500
Subject: [R-sig-ME] warnings when using binomial models and offset
In-Reply-To: <000a01d48351$9d70c4f0$d8524ed0$@com>
References: <000a01d48351$9d70c4f0$d8524ed0$@com>
Message-ID: <f6a9b285-999e-17f0-0fd1-6191e6ccadd6@gmail.com>


  This is a pretty common error, which I've now added to the GLMM FAQ.
You should be using log(density), not density, as your offset term; if
you use density, then you end up specifying that your capture counts are
proportional to exp(density), which is often a ridiculously huge number.

 cheers
   Ben Bolker

On 2018-11-23 12:26 p.m., Joana Martelo wrote:
> Hello everyone
> 
>  
> 
> I'm trying to model fish capture success using length, velocity and group
> composition as explanatory variables, density as an offset variable, and
> fish.id. as random effect. I'm getting the follow warnings:
> 
>  
> 
> Model1<-glmer(capture~length+offset(density)+(1|fish.id),family=binomial,dat
> a=cap)
> 
>  
> 
> Warning messages:
> 
> 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
> 
>   Model failed to converge with max|grad| = 0.260123 (tol = 0.001, component
> 1)
> 
> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
> 
>   Model is nearly unidentifiable: very large eigenvalue
> 
> - Rescale variables?
> 
>  
> 
>  
> 
> -          I only get the warnings when I use length and group composition,
> not with velocity.
> 
> -          I don't get any warning if I don't use the offset.
> 
>  
> 
> I've tried:
> 
> Model1<-glmer(capture~length+offset(log(density))+(1|fish.id.c),family=binom
> ial(link="cloglog"),data=cap)
> 
>  
> 
> But still get the warning.
> 
>  
> 
> Any ideas of what might be the problem?
> 
>  
> 
> Many thanks!
> 
>  
> 
>  
> 
> Joana Martelo
> 
>  
> 
>  
> 
>  
> 
>  
> 
> Melhores cumprimentos,
> 
>  
> 
> Joana Martins
> 
>  
> 
>  
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From d@e@kornbrot @ending from hert@@@c@uk  Sun Nov 25 18:55:40 2018
From: d@e@kornbrot @ending from hert@@@c@uk (Kornbrot, Diana)
Date: Sun, 25 Nov 2018 17:55:40 +0000
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 143, Issue 33
In-Reply-To: <mailman.17092.8630.1542927592.1179.r-sig-mixed-models@r-project.org>
References: <mailman.17092.8630.1542927592.1179.r-sig-mixed-models@r-project.org>
Message-ID: <BEEFD274-1930-4D97-8F29-127C11184F52@herts.ac.uk>

Error means squares in GLMER and LMER (Kornbrot, Diana)

Have now got lmer in R ad MIXED in SPSS to agree for my data in s4 a 2 between, 2 within anova, iwht pno as random subjects and freq as dependent
You are all correct do not nee ls means directly BUT fa values have numerators and denominators and would really like to see both
Rscript
a<- lmer(freq~b1*b2*w1*w2+(w1|pno) + (w2|pno), data=s4)
anova(a)for inferential and ls_mean(a) for descriptive means.

want to go on to ?correct' analysis which has a binomial proprtion of freq/Nmax
so tried

 b<- glmer(cbind(freq, Nmax-freq) ~ b1*b2*w1*w2 +(w1|pno)+(w2|pno), data= s4,family="binomial" )
Warning message:
In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model failed to converge with max|grad| = 0.00692938 (tol = 0.001, component 1)

So, what can I change so it does converge. Its by no means a big data set

it was happy with print(b), summary(b) and anova(b) but results do not agree with SPSS, which did converge
BUT would not give me mea
> ls_means(b)
Error in UseMethod("ls_means") :
  no applicable method for 'ls_means' applied to an object of class "c('glmerMod', 'merMod')"
>
So how does one get means from objects  of class "c('glmerMod', 'merMod?)??

Also when I try to look up glmer  in packages, it says it ca?t be installed in R3.51. although it must be installed to obey the command. Mystified

All help gratefully received
best
Diana

Message: 3
Date: Thu, 22 Nov 2018 17:09:56 +0000
From: "Kornbrot, Diana" <d.e.kornbrot at herts.ac.uk<mailto:d.e.kornbrot at herts.ac.uk>>
To: roee maor <roeemaor at gmail.com<mailto:roeemaor at gmail.com>>
Cc: "r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>"
<r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
Subject: Re: [R-sig-ME] Error means squares in GLMER and LMER
Message-ID: <8D3FBC0E-8BFD-4AC9-89BF-D71F6A408873 at herts.ac.uk<mailto:8D3FBC0E-8BFD-4AC9-89BF-D71F6A408873 at herts.ac.uk>>
Content-Type: text/plain; charset="utf-8"

So I am comparing standard ANOVA on raw  frequencies (or equivalently probabilities) with GLMM for  binomial  proportion with both  logit and probit   link
ALL analyses have  been completed in SPSS using MIXED for: response   = identity ,  link = normal ; response =  proportion=freq/Nmax, link =  probit; response = proportion link  = logit)
I want   to show  how to  do identical  analyses in R using lmer  for are freq and  glmer for proportions
So I wasn?t SAME results  from R and SPSS (and a  diamond  necklace for Christmas,  celebrated as  an EU citizen in UK - I am a demanding woman)
Results are NOT quite  the same.
I am  checking using  the raw  probabilities as raw response with lmer before  moving  on to  glmer  for proportions
Check 1, in SPSS for raw  freq or  probability REPEATED  give  same  result   as  MIXED (response = identity, link = normal). where  there are differences it is REPEATED WITHIN  comparisons  not MULTIVARIATE.
Check 2. Compare R,  lmer with SPSS  mixed
if repeated groups are w1,  w2,  etc  and between groups are b1,  b2  etc, I use:
result <- lmer(freq~b1*b2*w1*w2 + (w1|subject)  + (w2|subject),  data  =  test)
anova(result)
Fand df from R  and SPSS do  not always match,  even  when  they do  match on sums  of squares
I am trying  to  work out WHY there is a mismatch
Thought that  knowing what was in the DENOMINATOR of the F values - which i perhaps  wrongly termed  error sums  of squares, might help

I  want F  for usual reasons:   to test significance  and estimate  effect  size.
I also want  all  my packages  to  give  me the SAME F and df2 and to  UNDERSTAND what is happening

Sorry this is  so long,  but  hope it is now clearer

best

Diana

and as  an extra  treat  would like marginal means from object  of type lmer

Dear Diana,
If indeed what you're looking for is what Rolf mentioned, you might find Nakagawa & Schielzeth (2013) helpful.
It's titled "A general and simple method for obtaining R2 from generalized linear mixed-effects models". There is no dispute about the method's generality, but simple is a relative term...
Here's the link: https://besjournals.onlinelibrary.wiley.com/doi/epdf/10.1111/j.2041-210x.2012.00261.x

Hope this helps,
--
Roi Maor
PhD candidate
School of Zoology, Tel Aviv University
Centre for Biodiversity and Environment Research, UCL

_____________________________________
Professor Diana Kornbrot
Mobile
+44 (0) 7403 18 16 12
Work
University of Hertfordshire
College Lane, Hatfield, Hertfordshire AL10 9AB, UK
+44 (0) 170 728 4626
d.e.kornbrot at herts.ac.uk<mailto:d.e.kornbrot at herts.ac.uk><mailto:d.e.kornbrot at herts.ac.uk>
http://dianakornbrot.wordpress.com/
http://go.herts.ac.uk/Diana_Kornbrot
skype:  kornbrotme
Home
19 Elmhurst Avenue
London N2 0LT, UK
+44 (0) 208 444 2081
------------------------------------------------------------




[[alternative HTML version deleted]]



------------------------------

Message: 4
Date: Thu, 22 Nov 2018 14:44:27 -0500
From: Ben Bolker <bbolker at gmail.com>
To: "Kornbrot, Diana" <d.e.kornbrot at herts.ac.uk>
Cc: roee maor <roeemaor at gmail.com>,  R SIG Mixed Models
<r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Error means squares in GLMER and LMER
Message-ID:
<CABghstStwFkNHw1SU59ZPRPxAYBPxf4061pixfuVKhFrNnp8iA at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

For marginal means, use the emmeans package.

If you use the lmerTest package, you can get Satterthwaite or
Kenward-Roger df: you can use lme (from the nlme package), or
<https://github.com/bbolker/mixedmodels-misc/blob/master/R/calcDenDF.R>,
to get df via a simple "parameter-counting" exercise.

The problem is that the "F statistics" are quite poorly defined for
GLMMs. Can you show us the contrasting results you're getting for SPSS
and glmer?  Do you know how SPSS is computing the F statistics?  (This
<https://www.ibm.com/support/knowledgecenter/en/SS3RA7_15.0.0/com.ibm.spss.modeler.help/idh_glmm_build_options.htm>
makes it seem like it might be using Satterthwaite approximations ...)
On Thu, Nov 22, 2018 at 12:09 PM Kornbrot, Diana
<d.e.kornbrot at herts.ac.uk> wrote:

So I am comparing standard ANOVA on raw  frequencies (or equivalently probabilities) with GLMM for  binomial  proportion with both  logit and probit   link
ALL analyses have  been completed in SPSS using MIXED for: response   = identity ,  link = normal ; response =  proportion=freq/Nmax, link =  probit; response = proportion link  = logit)
I want   to show  how to  do identical  analyses in R using lmer  for are freq and  glmer for proportions
So I wasn?t SAME results  from R and SPSS (and a  diamond  necklace for Christmas,  celebrated as  an EU citizen in UK - I am a demanding woman)
Results are NOT quite  the same.
I am  checking using  the raw  probabilities as raw response with lmer before  moving  on to  glmer  for proportions
Check 1, in SPSS for raw  freq or  probability REPEATED  give  same  result   as  MIXED (response = identity, link = normal). where  there are differences it is REPEATED WITHIN  comparisons  not MULTIVARIATE.
Check 2. Compare R,  lmer with SPSS  mixed
if repeated groups are w1,  w2,  etc  and between groups are b1,  b2  etc, I use:
result <- lmer(freq~b1*b2*w1*w2 + (w1|subject)  + (w2|subject),  data  =  test)
anova(result)
Fand df from R  and SPSS do  not always match,  even  when  they do  match on sums  of squares
I am trying  to  work out WHY there is a mismatch
Thought that  knowing what was in the DENOMINATOR of the F values - which i perhaps  wrongly termed  error sums  of squares, might help

I  want F  for usual reasons:   to test significance  and estimate  effect  size.
I also want  all  my packages  to  give  me the SAME F and df2 and to  UNDERSTAND what is happening

Sorry this is  so long,  but  hope it is now clearer

best

Diana

and as  an extra  treat  would like marginal means from object  of type lmer

Dear Diana,
If indeed what you're looking for is what Rolf mentioned, you might find Nakagawa & Schielzeth (2013) helpful.
It's titled "A general and simple method for obtaining R2 from generalized linear mixed-effects models". There is no dispute about the method's generality, but simple is a relative term...
Here's the link: https://besjournals.onlinelibrary.wiley.com/doi/epdf/10.1111/j.2041-210x.2012.00261.x

Hope this helps,
--
Roi Maor
PhD candidate
School of Zoology, Tel Aviv University
Centre for Biodiversity and Environment Research, UCL

_____________________________________
Professor Diana Kornbrot
Mobile
+44 (0) 7403 18 16 12
Work
University of Hertfordshire
College Lane, Hatfield, Hertfordshire AL10 9AB, UK
+44 (0) 170 728 4626
d.e.kornbrot at herts.ac.uk<mailto:d.e.kornbrot at herts.ac.uk>
http://dianakornbrot.wordpress.com/
http://go.herts.ac.uk/Diana_Kornbrot
skype:  kornbrotme
Home
19 Elmhurst Avenue
London N2 0LT, UK
+44 (0) 208 444 2081
------------------------------------------------------------




       [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models




------------------------------

Message: 5
Date: Thu, 22 Nov 2018 22:59:33 +0000
From: roee maor <roeemaor at gmail.com>
To: j.hadfield at ed.ac.uk
Cc: R-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME]  Unclear output from MCMCglmm with categorical
predictors
Message-ID:
<CACxNx6uqb0C3HCEpvOfKDF=pOKTzXjgZStFS-kdCibf1fgYuig at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

Dear Jarrod and Ben,
Thank you both for the advice.
Apologies if I accidentally caused anyone to receive an unexpected email.

Running the model specified above returns the error: "non-reduced nodes do
not appear first". The error persists when using a fully-bifurcating tree
so the issue is not tree polytomies.
I tried to go through the source code line-by-line to locate the problem
but got lost in the many loops and conditional statements. This error
message is conditioned on a match() output that also returns a warning that
the two arguments matched are unequal in length: one corresponds to the
tips while the other includes the tree's internal nodes as well.

As always, any help is much appreciated.
Best,
Roi



On Wed, 21 Nov 2018 at 15:05, HADFIELD Jarrod <j.hadfield at ed.ac.uk> wrote:

Hi,

You could upload the tarball to winbuilder (
https://win-builder.r-project.org/) and build a Windows source package.

Cheers,

Jarrod


On 21/11/2018 14:09, roee maor wrote:

Hi Jarrod,
Many thanks for your reply.

I couldn't install the tarball on R v3.4.3 or v3.5.1 so sourced the files
directly to the workspace.
I tried to run this model as you suggested:
T1 <- MCMCglmm(Activity ~ -1 + log(Mass) + Max.Temp * Annual.Precip,
              random = ~ animal,
              prior = list(R = list(fix=1, V=1e-15), G = list(G1 =
list(V=1, nu=0.002))),
              pedigree = datatree,
              reduced = TRUE,
              burnin = 50000, nitt = 750001, thin = 700,
              family = "threshold",
              data = Rdata,
              pl = TRUE, saveX = TRUE, saveZ = TRUE,
              verbose = TRUE)

It returns some errors about missing functions "is.positive.definite" and
"Matrix", which I addressed with:
library("corpcor", lib.loc="~/R/win-library/3.5")
library("MatrixModels", lib.loc="~/R/win-library/3.5")
but I can't figure this one out:
'Error in .C("MCMCglmm", as.double(data$MCMC_y),
as.double(data$MCMC_y.additional),  :
 C symbol name "MCMCglmm" not in load table'
Detaching these packages doesn't necessarily cause that same error to
appear although I execute the exact same code.
Also, several attempts (same code again) caused a fatal error and
automatic session termination (info for a similar session below if
interesting).

I tried to use the fully bifurcating tree as an experiment but that made
no difference.

Any ideas what this last error means?

Thanks!
Roi


sessionInfo()
R version 3.5.1 (2018-07-02)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows >= 8 x64 (build 9200)

Matrix products: default

locale:
[1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United
Kingdom.1252    LC_MONETARY=English_United Kingdom.1252
[4] LC_NUMERIC=C                            LC_TIME=English_United
Kingdom.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] corpcor_1.6.9   Matrix_1.2-14   phytools_0.6-60 maps_3.3.0
ape_5.2

loaded via a namespace (and not attached):
[1] igraph_1.2.2            Rcpp_0.12.19            magrittr_1.5
 MASS_7.3-50             mnormt_1.5-5
[6] scatterplot3d_0.3-41    lattice_0.20-35         quadprog_1.5-5
 fastmatch_1.1-0         tools_3.5.1
[11] parallel_3.5.1          grid_3.5.1              nlme_3.1-137
 clusterGeneration_1.3.4 phangorn_2.4.0
[16] plotrix_3.7-4           coda_0.19-2             yaml_2.2.0
 numDeriv_2016.8-1       animation_2.5
[21] compiler_3.5.1          combinat_0.0-8          expm_0.999-3
 pkgconfig_2.0.2

On Tue, 20 Nov 2018 at 20:01, HADFIELD Jarrod <j.hadfield at ed.ac.uk> wrote:

Hi,

Most likely the phylogenetic heritability (the phylogenetic variance /
the phylogenetic +residual variance) is approaching one resulting in
numerical difficulties. Probably the best thing is to assume that the
phylogenetic heritability equals 1 and use the reduced phylogenetic mixed
model implementation. This allows the phylogenetic heritability to be equal
to 1 without causing numerical issues. At some point I will integrate these
models into the main MCMCglmm package, but for now you can download it from
here: http://jarrod.bio.ed.ac.uk/MCMCglmmRAM_2.24.tar.gz.

Change the name of the ??Binomial? column to ?animal? and fit:

T1 <- MCMCglmm(Activity ~ -1 + log(Mass) + Max.Temp * Annual.Precip,
                              random = ~ animal
                              prior = list(R = list(fix=1, V=1e-15), G =
list(G1 = list(V=1, nu=0.002))),
                              pedigree = tree,
      reduced=TRUE,
                              burnin = 150000, nitt = 2650001, thin =
2500,
                              family = "threshold",  data = Tdata,
                              pl = TRUE, pr = TRUE, saveX = TRUE, saveZ
= TRUE,
                              verbose = FALSE)

You should need fewer iterations.

Cheers,

Jarrod


On 20 Nov 2018, at 18:08, roee maor <roeemaor at gmail.com> wrote:

Dear Jarrod (and list),

Following your previous comment I added "random = ~ Binomial" to my model
to allow for a phylogenetic analysis.
This causes convergence problems: the trace plots show increasing
oscillations along each chain (although no directional trends, so it's not
a burn-in issue). Also, the posterior samples are highly correlated,
residual variance estimates are >10^3 and threshold estimates are high (>20
on the latent scale).
Surprisingly (to me), predictors that are strongly significant in the
non-phylogenetic model lose their effect in the phylogenetic model (I tried
several alternative parameter configurations).

It seems that this model attributes the explained variance to phylogeny
alone.
Can anyone explain what is going on here?  Am I specifying the model
poorly or just asking my data more than it can answer?

I tried to overcome this issue by using a fully resolved variant of the
phylogeny, which only improved things slightly.
I also changed the random effect to "random=~Family" or "random=~Order",
which reduced the variance and threshold estimates to more acceptable
levels (<10), but still no significant predictors (and I'm not sure how the
algorithm calculates covariance between higher taxa in the phylogeny).
Separately I tried parameter expanded prior: "prior = list(R = list(V=1,
fix=1), G = list(G1 = list(V=1, nu=1, alpha.mu=0, alpha.V=1000)))". That
didn't help, and messing with priors for this reason feels like poor
practice.

This is the model:
T1 <- MCMCglmm(Activity ~ -1 + log(Mass) + Max.Temp * Annual.Precip,
                              random = ~ Binomial,
                              prior = list(R = list(fix=1, V=1), G =
list(G1 = list(V=1, nu=0.002))),
                              ginverse = list(Binomial=INphylo$Ainv),
                              burnin = 150000, nitt = 2650001, thin =
2500,
                              family = "threshold",  data = Tdata,
                              pl = TRUE, pr = TRUE, saveX = TRUE, saveZ
= TRUE,
                              verbose = FALSE)

The data I use looks like this (not all variables appear in each model):

str(Tdata)
'data.frame': 1389 obs. of  10 variables:
$ Binomial           : Factor w/ 1421 levels "Abrocoma_bennettii",..: 1
2 3 4 5 6 7 8 9 10 ...
$ Order                : Factor w/ 27 levels "Afrosoricida",..: 24 24 24
24 24 3 24 24 2 2 ...
$ Family               : Factor w/ 126 levels "Abrocomidae",..: 1 26 26
26 26 46 74 87 10 10 ...
$ Activity              : Factor w/ 3 levels "1","2","3": 1 3 2 2 2 3 2
3 1 3 ...
$ Habitat              : Factor w/ 6 levels "Aqua","Arbo",..: 5 5 5 5 5
5 5 5 5 5 ...
$ Diet                   : Factor w/ 3 levels "Faun","Herb",..: 2 3 3 3
3 1 3 2 2 2 ...
$ Mass                 : num  250.5 24.9 34.5 38.9 24.5 ...
$ Max.Temp         : num  22 16.6 19.1 19.8 17.2 ...
$ Annual.Precip   : num  166 645 558 903 1665 ...

Any advice would be much appreciated!
Many thanks,


--
Roi Maor
PhD candidate
School of Zoology, Tel Aviv University
Centre for Biodiversity and Environment Research, UCL


The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



--
Roi Maor
PhD candidate
School of Zoology, Tel Aviv University
Centre for Biodiversity and Environment Research, UCL

The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



--
Roi Maor
PhD candidate
School of Zoology, Tel Aviv University
Centre for Biodiversity and Environment Research, UCL

[[alternative HTML version deleted]]




------------------------------

Subject: Digest Footer

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


------------------------------

End of R-sig-mixed-models Digest, Vol 143, Issue 33
***************************************************

_____________________________________
Professor Diana Kornbrot
Mobile
+44 (0) 7403 18 16 12
Work
University of Hertfordshire
College Lane, Hatfield, Hertfordshire AL10 9AB, UK
+44 (0) 170 728 4626
d.e.kornbrot at herts.ac.uk<mailto:d.e.kornbrot at herts.ac.uk>
http://dianakornbrot.wordpress.com/
http://go.herts.ac.uk/Diana_Kornbrot
skype:  kornbrotme
Home
19 Elmhurst Avenue
London N2 0LT, UK
+44 (0) 208 444 2081
 ------------------------------------------------------------




	[[alternative HTML version deleted]]


From @ndre@@@leh@ @ending from med@uni-goettingen@de  Mon Nov 26 12:10:10 2018
From: @ndre@@@leh@ @ending from med@uni-goettingen@de (Leha, Andreas)
Date: Mon, 26 Nov 2018 11:10:10 +0000
Subject: [R-sig-ME] diverging results with and without random effects
Message-ID: <b913cd50-ee7e-6419-0f87-98da32efd142@med.uni-goettingen.de>

Hi all,

I am interested in assessing the association of a (potential) risk
factor to a (binary) grouping.

I am having trouble with diverging results from modeling one time point
(without random effect) and modeling two time points (with random effect).

When analysing the first time point (base line, BL) only, I get a highly
significant association.
Now, I want to see, whether there is an interaction between time and
risk factor (the risk factor is not constant).  But when analysing both
time points, the estimated effect at BL is estimated to be not significant.

Now my simplified questions are:
(1) Is there an association at BL or not?
(2) How should I analyse both time points with this data?

The aim is to look for confounding with other factors.  But I'd like to
understand the simple models before moving on.

Below you find a reproducible example and the detailed results.

Any suggestions would be highly appreciated!

Regards,
Andreas



PS: The code / results

---------- cut here --------------------------------------------
library("dplyr")
library("lme4")
library("lmerTest")
## install_github("hrbrmstr/pastebin", upgrade_dependencies = FALSE)
library("pastebin")

## ---------------------------------- ##
## load the data                      ##
## ---------------------------------- ##
dat <- pastebin::get_paste("Xgwgtb7j") %>%
  as.character %>%
  gsub("\r\n", "", .) %>%
  parse(text = .) %>%
  eval



## ---------------------------------- ##
## have a look                        ##
## ---------------------------------- ##
dat
## ,----
## | # A tibble: 475 x 4
## |    patient group fu    riskfactor
## |    <fct>   <fct> <fct> <fct>
## |  1 p001    wt    BL    norisk
## |  2 p002    wt    BL    norisk
## |  3 p003    wt    BL    norisk
## |  4 p004    wt    BL    norisk
## |  5 p005    wt    BL    norisk
## |  6 p006    wt    BL    norisk
## |  7 p007    wt    BL    norisk
## |  8 p008    wt    BL    norisk
## |  9 p009    wt    BL    risk
## | 10 p010    wt    BL    norisk
## | # ... with 465 more rows
## `----
dat %>% str
## ,----
## | Classes ?tbl_df?, ?tbl? and 'data.frame':	475 obs. of  4 variables:
## |  $ patient   : Factor w/ 265 levels "p001","p002",..: 1 2 3 4 5 6 7
8 9 10 ...
## |  $ group     : Factor w/ 2 levels "wt","mut": 1 1 1 1 1 1 1 1 1 1 ...
## |  $ fu        : Factor w/ 2 levels "BL","FU": 1 1 1 1 1 1 1 1 1 1 ...
## |  $ riskfactor: Factor w/ 2 levels "risk","norisk": 2 2 2 2 2 2 2 2
1 2 ...
## `----

## there are 265 patients
## in 2 groups: "wt" and "mut"
## with a dichotomous risk factor ("risk" and "norisk")
## measured at two time points ("BL" and "FU")

dat %>% summary
## ,----
## |     patient    group      fu       riskfactor
## |  p001   :  2   wt :209   BL:258   risk  :205
## |  p002   :  2   mut:266   FU:217   norisk:270
## |  p003   :  2
## |  p004   :  2
## |  p005   :  2
## |  p006   :  2
## |  (Other):463
## `----

## group sizes seem fine



## ---------------------------------------------- ##
## first, we look at the first time point, the BL ##
## ---------------------------------------------- ##

## we build a cross table
tab_bl <-
  dat %>%
  dplyr::select(group, riskfactor) %>%
  table
tab_bl
## ,----
## |      riskfactor
## | group risk norisk
## |   wt    35    174
## |   mut  170     96
## `----

## and we test using fisher:
tab_bl %>% fisher.test
## ,----
## |    Fisher's Exact Test for Count Data
## |
## | data:  .
## | p-value < 2.2e-16
## | alternative hypothesis: true odds ratio is not equal to 1
## | 95 percent confidence interval:
## |  0.07099792 0.18002325
## | sample estimates:
## | odds ratio
## |  0.1141677
## `----
log(0.114)
## ,----
## | [1] -2.171557
## `----

## so, we get a highly significant association of the riskfactor
## and the group with an log(odds ratio) of -2.2

## we get the same result using logistic regression:
dat %>%
  glm(group ~ riskfactor, family = "binomial", data = .) %>%
  summary
## ,----
## |
## | Call:
## | glm(formula = group ~ riskfactor, family = "binomial", data = .)
## |
## | Deviance Residuals:
## |     Min       1Q   Median       3Q      Max
## | -1.8802  -0.9374   0.6119   0.6119   1.4381
## |
## | Coefficients:
## |                  Estimate Std. Error z value Pr(>|z|)
## | (Intercept)        1.5805     0.1856   8.515   <2e-16 ***
## | riskfactornorisk  -2.1752     0.2250  -9.668   <2e-16 ***
## | ---
## | Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
## |
## | (Dispersion parameter for binomial family taken to be 1)
## |
## |     Null deviance: 651.63  on 474  degrees of freedom
## | Residual deviance: 538.83  on 473  degrees of freedom
## | AIC: 542.83
## |
## | Number of Fisher Scoring iterations: 4
## `----



## ------------------------------------------------- ##
## Now, we analyse both time points with interaction ##
## ------------------------------------------------- ##

dat %>%
  glmer(group ~ riskfactor + fu + riskfactor:fu + (1|patient), family =
"binomial", data = .) %>%
  summary
## ,----
## | Generalized linear mixed model fit by maximum likelihood (Laplace
## |   Approximation) [glmerMod]
## |  Family: binomial  ( logit )
## | Formula: group ~ riskfactor + fu + riskfactor:fu + (1 | patient)
## |    Data: .
## |
## |      AIC      BIC   logLik deviance df.resid
## |    345.2    366.0   -167.6    335.2      470
## |
## | Scaled residuals:
## |       Min        1Q    Median        3Q       Max
## | -0.095863 -0.058669  0.002278  0.002866  0.007324
## |
## | Random effects:
## |  Groups  Name        Variance Std.Dev.
## |  patient (Intercept) 1849     43
## | Number of obs: 475, groups:  patient, 265
## |
## | Fixed effects:
## |                       Estimate Std. Error z value Pr(>|z|)
## | (Intercept)            11.6846     1.3736   8.507   <2e-16 ***
## | riskfactornorisk       -1.5919     1.4166  -1.124    0.261
## | fuFU                    0.4596     1.9165   0.240    0.810
## | riskfactornorisk:fuFU  -0.8183     2.1651  -0.378    0.705
## | ---
## | Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
## |
## | Correlation of Fixed Effects:
## |             (Intr) rskfct fuFU
## | rskfctrnrsk -0.746
## | fuFU        -0.513  0.510
## | rskfctrn:FU  0.478 -0.576 -0.908
## `----

## I get huge variation in the random effects
##
## And the risk factor at BL gets an estimated log(odds ratio) of -1.6
## but one which is not significant
---------- cut here --------------------------------------------

From jo@n@m@rtelo @ending from gm@il@com  Mon Nov 26 13:33:05 2018
From: jo@n@m@rtelo @ending from gm@il@com (Joana Martelo)
Date: Mon, 26 Nov 2018 12:33:05 -0000
Subject: [R-sig-ME] 
 warnings when using binomial models and offset - NaNs
In-Reply-To: <f6a9b285-999e-17f0-0fd1-6191e6ccadd6@gmail.com>
References: <000a01d48351$9d70c4f0$d8524ed0$@com>
 <f6a9b285-999e-17f0-0fd1-6191e6ccadd6@gmail.com>
Message-ID: <00d201d48584$2e9bd990$8bd38cb0$@com>

Thanks for your email!

Warnings' problem is solved, however, when I use log(density) or log(density+1) I got NaNs because density has negative numbers. Density is 2,4,6 which standardized gives -1.793073717, -0.450015136, 0.893043446. So, log(-1.793073717+1)= NaN

Any suggestions?

Many thanks!
Joana


-----Mensagem original-----
De: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] Em nome de Ben Bolker
Enviada: sexta-feira, 23 de Novembro de 2018 21:54
Para: r-sig-mixed-models at r-project.org
Assunto: Re: [R-sig-ME] warnings when using binomial models and offset


  This is a pretty common error, which I've now added to the GLMM FAQ.
You should be using log(density), not density, as your offset term; if you use density, then you end up specifying that your capture counts are proportional to exp(density), which is often a ridiculously huge number.

 cheers
   Ben Bolker

On 2018-11-23 12:26 p.m., Joana Martelo wrote:
> Hello everyone
> 
>  
> 
> I'm trying to model fish capture success using length, velocity and 
> group composition as explanatory variables, density as an offset 
> variable, and fish.id. as random effect. I'm getting the follow warnings:
> 
>  
> 
> Model1<-glmer(capture~length+offset(density)+(1|fish.id),family=binomi
> al,dat
> a=cap)
> 
>  
> 
> Warning messages:
> 
> 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
> 
>   Model failed to converge with max|grad| = 0.260123 (tol = 0.001, 
> component
> 1)
> 
> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
> 
>   Model is nearly unidentifiable: very large eigenvalue
> 
> - Rescale variables?
> 
>  
> 
>  
> 
> -          I only get the warnings when I use length and group composition,
> not with velocity.
> 
> -          I don't get any warning if I don't use the offset.
> 
>  
> 
> I've tried:
> 
> Model1<-glmer(capture~length+offset(log(density))+(1|fish.id.c),family
> =binom
> ial(link="cloglog"),data=cap)
> 
>  
> 
> But still get the warning.
> 
>  
> 
> Any ideas of what might be the problem?
> 
>  
> 
> Many thanks!
> 
>  
> 
>  
> 
> Joana Martelo
> 
>  
> 
>  
> 
>  
> 
>  
> 
> Melhores cumprimentos,
> 
>  
> 
> Joana Martins
> 
>  
> 
>  
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

---
Este e-mail foi verificado em termos de v?rus pelo AVG.
http://www.avg.com


From mollieebrook@ @ending from gm@il@com  Mon Nov 26 13:35:48 2018
From: mollieebrook@ @ending from gm@il@com (Mollie Brooks)
Date: Mon, 26 Nov 2018 13:35:48 +0100
Subject: [R-sig-ME] 
 warnings when using binomial models and offset - NaNs
In-Reply-To: <00d201d48584$2e9bd990$8bd38cb0$@com>
References: <000a01d48351$9d70c4f0$d8524ed0$@com>
 <f6a9b285-999e-17f0-0fd1-6191e6ccadd6@gmail.com>
 <00d201d48584$2e9bd990$8bd38cb0$@com>
Message-ID: <BAD2A316-6DA0-4F9C-867F-A743130E6002@gmail.com>

If you?re using the scale() function to standardize your density values, you could use the argument, center=FALSE, to avoid subtracting the mean and thus avoid negative densities. 

cheers,
Mollie

> On 26Nov 2018, at 13:33, Joana Martelo <joanamartelo at gmail.com> wrote:
> 
> Thanks for your email!
> 
> Warnings' problem is solved, however, when I use log(density) or log(density+1) I got NaNs because density has negative numbers. Density is 2,4,6 which standardized gives -1.793073717, -0.450015136, 0.893043446. So, log(-1.793073717+1)= NaN
> 
> Any suggestions?
> 
> Many thanks!
> Joana
> 
> 
> -----Mensagem original-----
> De: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] Em nome de Ben Bolker
> Enviada: sexta-feira, 23 de Novembro de 2018 21:54
> Para: r-sig-mixed-models at r-project.org
> Assunto: Re: [R-sig-ME] warnings when using binomial models and offset
> 
> 
>  This is a pretty common error, which I've now added to the GLMM FAQ.
> You should be using log(density), not density, as your offset term; if you use density, then you end up specifying that your capture counts are proportional to exp(density), which is often a ridiculously huge number.
> 
> cheers
>   Ben Bolker
> 
> On 2018-11-23 12:26 p.m., Joana Martelo wrote:
>> Hello everyone
>> 
>> 
>> 
>> I'm trying to model fish capture success using length, velocity and 
>> group composition as explanatory variables, density as an offset 
>> variable, and fish.id. as random effect. I'm getting the follow warnings:
>> 
>> 
>> 
>> Model1<-glmer(capture~length+offset(density)+(1|fish.id),family=binomi
>> al,dat
>> a=cap)
>> 
>> 
>> 
>> Warning messages:
>> 
>> 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>> 
>>  Model failed to converge with max|grad| = 0.260123 (tol = 0.001, 
>> component
>> 1)
>> 
>> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>> 
>>  Model is nearly unidentifiable: very large eigenvalue
>> 
>> - Rescale variables?
>> 
>> 
>> 
>> 
>> 
>> -          I only get the warnings when I use length and group composition,
>> not with velocity.
>> 
>> -          I don't get any warning if I don't use the offset.
>> 
>> 
>> 
>> I've tried:
>> 
>> Model1<-glmer(capture~length+offset(log(density))+(1|fish.id.c),family
>> =binom
>> ial(link="cloglog"),data=cap)
>> 
>> 
>> 
>> But still get the warning.
>> 
>> 
>> 
>> Any ideas of what might be the problem?
>> 
>> 
>> 
>> Many thanks!
>> 
>> 
>> 
>> 
>> 
>> Joana Martelo
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> Melhores cumprimentos,
>> 
>> 
>> 
>> Joana Martins
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> ---
> Este e-mail foi verificado em termos de v?rus pelo AVG.
> http://www.avg.com
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From @ndre@@@leh@ @ending from med@uni-goettingen@de  Mon Nov 26 13:47:57 2018
From: @ndre@@@leh@ @ending from med@uni-goettingen@de (Leha, Andreas)
Date: Mon, 26 Nov 2018 12:47:57 +0000
Subject: [R-sig-ME] diverging results with and without random effects
In-Reply-To: <b913cd50-ee7e-6419-0f87-98da32efd142@med.uni-goettingen.de>
References: <b913cd50-ee7e-6419-0f87-98da32efd142@med.uni-goettingen.de>
Message-ID: <841426ed-40d2-c9a7-b9c1-21507a1c0687@med.uni-goettingen.de>

Hi all,

sent the wrong code (w/o filtering for BL).  If you want to look at the
data, please use this code:

---------- cut here --------------------------------------------
library("dplyr")
library("lme4")
library("lmerTest")
## install_github("hrbrmstr/pastebin", upgrade_dependencies = FALSE)
library("pastebin")

## ---------------------------------- ##
## load the data                      ##
## ---------------------------------- ##
dat <- pastebin::get_paste("Xgwgtb7j") %>% as.character %>% gsub("\r\n",
"", .) %>% parse(text = .) %>% eval



## ---------------------------------- ##
## have a look                        ##
## ---------------------------------- ##
dat
## ,----
## | # A tibble: 475 x 4
## |    patient group fu    riskfactor
## |    <fct>   <fct> <fct> <fct>
## |  1 p001    wt    BL    norisk
## |  2 p002    wt    BL    norisk
## |  3 p003    wt    BL    norisk
## |  4 p004    wt    BL    norisk
## |  5 p005    wt    BL    norisk
## |  6 p006    wt    BL    norisk
## |  7 p007    wt    BL    norisk
## |  8 p008    wt    BL    norisk
## |  9 p009    wt    BL    risk
## | 10 p010    wt    BL    norisk
## | # ... with 465 more rows
## `----
dat %>% str
## ,----
## | Classes ?tbl_df?, ?tbl? and 'data.frame':	475 obs. of  4 variables:
## |  $ patient   : Factor w/ 265 levels "p001","p002",..: 1 2 3 4 5 6 7
8 9 10 ...
## |  $ group     : Factor w/ 2 levels "wt","mut": 1 1 1 1 1 1 1 1 1 1 ...
## |  $ fu        : Factor w/ 2 levels "BL","FU": 1 1 1 1 1 1 1 1 1 1 ...
## |  $ riskfactor: Factor w/ 2 levels "risk","norisk": 2 2 2 2 2 2 2 2
1 2 ...
## `----

## there are 265 patients
## in 2 groups: "wt" and "mut"
## with a dichotomous risk factor ("risk" and "norisk")
## measured at two time points ("BL" and "FU")

dat %>% summary
## ,----
## |     patient    group      fu       riskfactor
## |  p001   :  2   wt :209   BL:258   risk  :205
## |  p002   :  2   mut:266   FU:217   norisk:270
## |  p003   :  2
## |  p004   :  2
## |  p005   :  2
## |  p006   :  2
## |  (Other):463
## `----

## group sizes seem fine



## ---------------------------------------------- ##
## first, we look at the first time point, the BL ##
## ---------------------------------------------- ##

## we build a cross table
tab_bl <-
  dat %>%
  dplyr::filter(fu == "BL") %>%
  dplyr::select(group, riskfactor) %>%
  table
tab_bl
## ,----
## |      riskfactor
## | group risk norisk
## |   wt    22     86
## |   mut   87     63
## `----

## and we test using fisher:
tab_bl %>% fisher.test
## ,----
## | 	Fisher's Exact Test for Count Data
## |
## | data:  .
## | p-value = 1.18e-09
## | alternative hypothesis: true odds ratio is not equal to 1
## | 95 percent confidence interval:
## |  0.09986548 0.33817966
## | sample estimates:
## | odds ratio
## |  0.1865377
## `----
log(0.187)
## ,----
## | [1] -1.676647
## `----

## so, we get a highly significant association of the riskfactor
## and the group with an log(odds ratio) of -1.7

## we get the same result using logistic regression:
dat %>%
  filter(fu == "BL") %>%
  glm(group ~ riskfactor, family = "binomial", data = .) %>%
  summary
## ,----
## | Call:
## | glm(formula = group ~ riskfactor, family = "binomial", data = .)
## |
## | Deviance Residuals:
## |     Min       1Q   Median       3Q      Max
## | -1.7890  -1.0484   0.6715   0.6715   1.3121
## |
## | Coefficients:
## |                  Estimate Std. Error z value Pr(>|z|)
## | (Intercept)        1.3749     0.2386   5.761 8.35e-09 ***
## | riskfactornorisk  -1.6861     0.2906  -5.802 6.55e-09 ***
## | ---
## | Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
## |
## | (Dispersion parameter for binomial family taken to be 1)
## |
## |     Null deviance: 350.80  on 257  degrees of freedom
## | Residual deviance: 312.63  on 256  degrees of freedom
## | AIC: 316.63
## |
## | Number of Fisher Scoring iterations: 4
## `----



## ------------------------------------------------- ##
## Now, we analyse both time points with interaction ##
## ------------------------------------------------- ##

dat %>%
  glmer(group ~ riskfactor + fu + riskfactor:fu + (1|patient), family =
"binomial", data = .) %>%
  summary
## ,----
## | Generalized linear mixed model fit by maximum likelihood (Laplace
## |   Approximation) [glmerMod]
## |  Family: binomial  ( logit )
## | Formula: group ~ riskfactor + fu + riskfactor:fu + (1 | patient)
## |    Data: .
## |
## |      AIC      BIC   logLik deviance df.resid
## |    345.2    366.0   -167.6    335.2      470
## |
## | Scaled residuals:
## |       Min        1Q    Median        3Q       Max
## | -0.095863 -0.058669  0.002278  0.002866  0.007324
## |
## | Random effects:
## |  Groups  Name        Variance Std.Dev.
## |  patient (Intercept) 1849     43
## | Number of obs: 475, groups:  patient, 265
## |
## | Fixed effects:
## |                       Estimate Std. Error z value Pr(>|z|)
## | (Intercept)            11.6846     1.3736   8.507   <2e-16 ***
## | riskfactornorisk       -1.5919     1.4166  -1.124    0.261
## | fuFU                    0.4596     1.9165   0.240    0.810
## | riskfactornorisk:fuFU  -0.8183     2.1651  -0.378    0.705
## | ---
## | Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
## |
## | Correlation of Fixed Effects:
## |             (Intr) rskfct fuFU
## | rskfctrnrsk -0.746
## | fuFU        -0.513  0.510
## | rskfctrn:FU  0.478 -0.576 -0.908
## `----

## I get huge variation in the random effects
##
## And the risk factor at BL gets an estimated log(odds ratio) of -1.6
## but one which is not significant
---------- cut here --------------------------------------------


On 26/11/18 12:10, Leha, Andreas wrote:
> Hi all,
> 
> I am interested in assessing the association of a (potential) risk
> factor to a (binary) grouping.
> 
> I am having trouble with diverging results from modeling one time point
> (without random effect) and modeling two time points (with random effect).
> 
> When analysing the first time point (base line, BL) only, I get a highly
> significant association.
> Now, I want to see, whether there is an interaction between time and
> risk factor (the risk factor is not constant).  But when analysing both
> time points, the estimated effect at BL is estimated to be not significant.
> 
> Now my simplified questions are:
> (1) Is there an association at BL or not?
> (2) How should I analyse both time points with this data?
> 
> The aim is to look for confounding with other factors.  But I'd like to
> understand the simple models before moving on.
> 
> Below you find a reproducible example and the detailed results.
> 
> Any suggestions would be highly appreciated!
> 
> Regards,
> Andreas
> 
> 
> 
> PS: The code / results
> 
> ---------- cut here --------------------------------------------
> library("dplyr")
> library("lme4")
> library("lmerTest")
> ## install_github("hrbrmstr/pastebin", upgrade_dependencies = FALSE)
> library("pastebin")
> 
> ## ---------------------------------- ##
> ## load the data                      ##
> ## ---------------------------------- ##
> dat <- pastebin::get_paste("Xgwgtb7j") %>%
>   as.character %>%
>   gsub("\r\n", "", .) %>%
>   parse(text = .) %>%
>   eval
> 
> 
> 
> ## ---------------------------------- ##
> ## have a look                        ##
> ## ---------------------------------- ##
> dat
> ## ,----
> ## | # A tibble: 475 x 4
> ## |    patient group fu    riskfactor
> ## |    <fct>   <fct> <fct> <fct>
> ## |  1 p001    wt    BL    norisk
> ## |  2 p002    wt    BL    norisk
> ## |  3 p003    wt    BL    norisk
> ## |  4 p004    wt    BL    norisk
> ## |  5 p005    wt    BL    norisk
> ## |  6 p006    wt    BL    norisk
> ## |  7 p007    wt    BL    norisk
> ## |  8 p008    wt    BL    norisk
> ## |  9 p009    wt    BL    risk
> ## | 10 p010    wt    BL    norisk
> ## | # ... with 465 more rows
> ## `----
> dat %>% str
> ## ,----
> ## | Classes ?tbl_df?, ?tbl? and 'data.frame':	475 obs. of  4 variables:
> ## |  $ patient   : Factor w/ 265 levels "p001","p002",..: 1 2 3 4 5 6 7
> 8 9 10 ...
> ## |  $ group     : Factor w/ 2 levels "wt","mut": 1 1 1 1 1 1 1 1 1 1 ...
> ## |  $ fu        : Factor w/ 2 levels "BL","FU": 1 1 1 1 1 1 1 1 1 1 ...
> ## |  $ riskfactor: Factor w/ 2 levels "risk","norisk": 2 2 2 2 2 2 2 2
> 1 2 ...
> ## `----
> 
> ## there are 265 patients
> ## in 2 groups: "wt" and "mut"
> ## with a dichotomous risk factor ("risk" and "norisk")
> ## measured at two time points ("BL" and "FU")
> 
> dat %>% summary
> ## ,----
> ## |     patient    group      fu       riskfactor
> ## |  p001   :  2   wt :209   BL:258   risk  :205
> ## |  p002   :  2   mut:266   FU:217   norisk:270
> ## |  p003   :  2
> ## |  p004   :  2
> ## |  p005   :  2
> ## |  p006   :  2
> ## |  (Other):463
> ## `----
> 
> ## group sizes seem fine
> 
> 
> 
> ## ---------------------------------------------- ##
> ## first, we look at the first time point, the BL ##
> ## ---------------------------------------------- ##
> 
> ## we build a cross table
> tab_bl <-
>   dat %>%
>   dplyr::select(group, riskfactor) %>%
>   table
> tab_bl
> ## ,----
> ## |      riskfactor
> ## | group risk norisk
> ## |   wt    35    174
> ## |   mut  170     96
> ## `----
> 
> ## and we test using fisher:
> tab_bl %>% fisher.test
> ## ,----
> ## |    Fisher's Exact Test for Count Data
> ## |
> ## | data:  .
> ## | p-value < 2.2e-16
> ## | alternative hypothesis: true odds ratio is not equal to 1
> ## | 95 percent confidence interval:
> ## |  0.07099792 0.18002325
> ## | sample estimates:
> ## | odds ratio
> ## |  0.1141677
> ## `----
> log(0.114)
> ## ,----
> ## | [1] -2.171557
> ## `----
> 
> ## so, we get a highly significant association of the riskfactor
> ## and the group with an log(odds ratio) of -2.2
> 
> ## we get the same result using logistic regression:
> dat %>%
>   glm(group ~ riskfactor, family = "binomial", data = .) %>%
>   summary
> ## ,----
> ## |
> ## | Call:
> ## | glm(formula = group ~ riskfactor, family = "binomial", data = .)
> ## |
> ## | Deviance Residuals:
> ## |     Min       1Q   Median       3Q      Max
> ## | -1.8802  -0.9374   0.6119   0.6119   1.4381
> ## |
> ## | Coefficients:
> ## |                  Estimate Std. Error z value Pr(>|z|)
> ## | (Intercept)        1.5805     0.1856   8.515   <2e-16 ***
> ## | riskfactornorisk  -2.1752     0.2250  -9.668   <2e-16 ***
> ## | ---
> ## | Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> ## |
> ## | (Dispersion parameter for binomial family taken to be 1)
> ## |
> ## |     Null deviance: 651.63  on 474  degrees of freedom
> ## | Residual deviance: 538.83  on 473  degrees of freedom
> ## | AIC: 542.83
> ## |
> ## | Number of Fisher Scoring iterations: 4
> ## `----
> 
> 
> 
> ## ------------------------------------------------- ##
> ## Now, we analyse both time points with interaction ##
> ## ------------------------------------------------- ##
> 
> dat %>%
>   glmer(group ~ riskfactor + fu + riskfactor:fu + (1|patient), family =
> "binomial", data = .) %>%
>   summary
> ## ,----
> ## | Generalized linear mixed model fit by maximum likelihood (Laplace
> ## |   Approximation) [glmerMod]
> ## |  Family: binomial  ( logit )
> ## | Formula: group ~ riskfactor + fu + riskfactor:fu + (1 | patient)
> ## |    Data: .
> ## |
> ## |      AIC      BIC   logLik deviance df.resid
> ## |    345.2    366.0   -167.6    335.2      470
> ## |
> ## | Scaled residuals:
> ## |       Min        1Q    Median        3Q       Max
> ## | -0.095863 -0.058669  0.002278  0.002866  0.007324
> ## |
> ## | Random effects:
> ## |  Groups  Name        Variance Std.Dev.
> ## |  patient (Intercept) 1849     43
> ## | Number of obs: 475, groups:  patient, 265
> ## |
> ## | Fixed effects:
> ## |                       Estimate Std. Error z value Pr(>|z|)
> ## | (Intercept)            11.6846     1.3736   8.507   <2e-16 ***
> ## | riskfactornorisk       -1.5919     1.4166  -1.124    0.261
> ## | fuFU                    0.4596     1.9165   0.240    0.810
> ## | riskfactornorisk:fuFU  -0.8183     2.1651  -0.378    0.705
> ## | ---
> ## | Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> ## |
> ## | Correlation of Fixed Effects:
> ## |             (Intr) rskfct fuFU
> ## | rskfctrnrsk -0.746
> ## | fuFU        -0.513  0.510
> ## | rskfctrn:FU  0.478 -0.576 -0.908
> ## `----
> 
> ## I get huge variation in the random effects
> ##
> ## And the risk factor at BL gets an estimated log(odds ratio) of -1.6
> ## but one which is not significant
> ---------- cut here --------------------------------------------
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
Dr. Andreas Leha
Head of the 'Core Facility
Medical Biometry and Statistical Bioinformatics'

UNIVERSITY MEDICAL CENTER G?TTINGEN
GEORG-AUGUST-UNIVERSIT?T
Department of Medical Statistics
Humboldtallee 32
37073 G?ttingen
Mailing Address: 37099 G?ttingen, Germany
Fax: +49 (0) 551 39-4995
Tel: +49 (0) 551 39-4987
http://www.ams.med.uni-goettingen.de/service-de.shtml

From jo@n@m@rtelo @ending from gm@il@com  Mon Nov 26 14:47:06 2018
From: jo@n@m@rtelo @ending from gm@il@com (Joana Martelo)
Date: Mon, 26 Nov 2018 13:47:06 -0000
Subject: [R-sig-ME] 
 warnings when using binomial models and offset (log(x))
In-Reply-To: <BAD2A316-6DA0-4F9C-867F-A743130E6002@gmail.com>
References: <000a01d48351$9d70c4f0$d8524ed0$@com>
 <f6a9b285-999e-17f0-0fd1-6191e6ccadd6@gmail.com>
 <00d201d48584$2e9bd990$8bd38cb0$@com>
 <BAD2A316-6DA0-4F9C-867F-A743130E6002@gmail.com>
Message-ID: <00f301d4858e$85919d70$90b4d850$@com>

Thanks for your help!

However, I still get the warnings when using offset(log(density)


> Model1<-glmer(capture~length+offset(log(density+2))+(1|fish.id.c),family=binomial,data=cap)


Warning messages:
1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model failed to converge with max|grad| = 0.258231 (tol = 0.001, component 1)
2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model is nearly unidentifiable: very large eigenvalue
 - Rescale variables?


Any suggestion?

Thanks
Joana



-----Mensagem original-----
De: Mollie Brooks [mailto:mollieebrooks at gmail.com] 
Enviada: segunda-feira, 26 de Novembro de 2018 12:36
Para: Joana Martelo
Cc: R SIG Mixed Models
Assunto: Re: [R-sig-ME] warnings when using binomial models and offset - NaNs

If you?re using the scale() function to standardize your density values, you could use the argument, center=FALSE, to avoid subtracting the mean and thus avoid negative densities. 

cheers,
Mollie

> On 26Nov 2018, at 13:33, Joana Martelo <joanamartelo at gmail.com> wrote:
> 
> Thanks for your email!
> 
> Warnings' problem is solved, however, when I use log(density) or 
> log(density+1) I got NaNs because density has negative numbers. 
> Density is 2,4,6 which standardized gives -1.793073717, -0.450015136, 
> 0.893043446. So, log(-1.793073717+1)= NaN
> 
> Any suggestions?
> 
> Many thanks!
> Joana
> 
> 
> -----Mensagem original-----
> De: R-sig-mixed-models 
> [mailto:r-sig-mixed-models-bounces at r-project.org] Em nome de Ben 
> Bolker
> Enviada: sexta-feira, 23 de Novembro de 2018 21:54
> Para: r-sig-mixed-models at r-project.org
> Assunto: Re: [R-sig-ME] warnings when using binomial models and offset
> 
> 
>  This is a pretty common error, which I've now added to the GLMM FAQ.
> You should be using log(density), not density, as your offset term; if you use density, then you end up specifying that your capture counts are proportional to exp(density), which is often a ridiculously huge number.
> 
> cheers
>   Ben Bolker
> 
> On 2018-11-23 12:26 p.m., Joana Martelo wrote:
>> Hello everyone
>> 
>> 
>> 
>> I'm trying to model fish capture success using length, velocity and 
>> group composition as explanatory variables, density as an offset 
>> variable, and fish.id. as random effect. I'm getting the follow warnings:
>> 
>> 
>> 
>> Model1<-glmer(capture~length+offset(density)+(1|fish.id),family=binom
>> i
>> al,dat
>> a=cap)
>> 
>> 
>> 
>> Warning messages:
>> 
>> 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>> 
>>  Model failed to converge with max|grad| = 0.260123 (tol = 0.001, 
>> component
>> 1)
>> 
>> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>> 
>>  Model is nearly unidentifiable: very large eigenvalue
>> 
>> - Rescale variables?
>> 
>> 
>> 
>> 
>> 
>> -          I only get the warnings when I use length and group composition,
>> not with velocity.
>> 
>> -          I don't get any warning if I don't use the offset.
>> 
>> 
>> 
>> I've tried:
>> 
>> Model1<-glmer(capture~length+offset(log(density))+(1|fish.id.c),famil
>> y
>> =binom
>> ial(link="cloglog"),data=cap)
>> 
>> 
>> 
>> But still get the warning.
>> 
>> 
>> 
>> Any ideas of what might be the problem?
>> 
>> 
>> 
>> Many thanks!
>> 
>> 
>> 
>> 
>> 
>> Joana Martelo
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> Melhores cumprimentos,
>> 
>> 
>> 
>> Joana Martins
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> ---
> Este e-mail foi verificado em termos de v?rus pelo AVG.
> http://www.avg.com
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker @ending from gm@il@com  Mon Nov 26 15:01:11 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Mon, 26 Nov 2018 09:01:11 -0500
Subject: [R-sig-ME] 
 warnings when using binomial models and offset - NaNs
In-Reply-To: <BAD2A316-6DA0-4F9C-867F-A743130E6002@gmail.com>
References: <000a01d48351$9d70c4f0$d8524ed0$@com>
 <f6a9b285-999e-17f0-0fd1-6191e6ccadd6@gmail.com>
 <00d201d48584$2e9bd990$8bd38cb0$@com>
 <BAD2A316-6DA0-4F9C-867F-A743130E6002@gmail.com>
Message-ID: <a14a0367-8b50-a0fa-2f6b-99f3fe3d76bc@gmail.com>


  More generally: I would ask whether it makes sense to scale the
density at all; if your density is measured in sensible areal units
(e.g. individuals/hectare), then leaving it as-is will mean that your
other parameters will be in units of their effects on
capture/(individuals/hectare).  Maybe you've been standardizing all of
your predictors according to the (generally wise) advice that
standardizing makes parameters more comparable/interpretable -- but
offsets are an exception to this advice ...

On 2018-11-26 7:35 a.m., Mollie Brooks wrote:
> If you?re using the scale() function to standardize your density values, you could use the argument, center=FALSE, to avoid subtracting the mean and thus avoid negative densities. 
> 
> cheers,
> Mollie
> 
>> On 26Nov 2018, at 13:33, Joana Martelo <joanamartelo at gmail.com> wrote:
>>
>> Thanks for your email!
>>
>> Warnings' problem is solved, however, when I use log(density) or log(density+1) I got NaNs because density has negative numbers. Density is 2,4,6 which standardized gives -1.793073717, -0.450015136, 0.893043446. So, log(-1.793073717+1)= NaN
>>
>> Any suggestions?
>>
>> Many thanks!
>> Joana
>>
>>
>> -----Mensagem original-----
>> De: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] Em nome de Ben Bolker
>> Enviada: sexta-feira, 23 de Novembro de 2018 21:54
>> Para: r-sig-mixed-models at r-project.org
>> Assunto: Re: [R-sig-ME] warnings when using binomial models and offset
>>
>>
>>  This is a pretty common error, which I've now added to the GLMM FAQ.
>> You should be using log(density), not density, as your offset term; if you use density, then you end up specifying that your capture counts are proportional to exp(density), which is often a ridiculously huge number.
>>
>> cheers
>>   Ben Bolker
>>
>> On 2018-11-23 12:26 p.m., Joana Martelo wrote:
>>> Hello everyone
>>>
>>>
>>>
>>> I'm trying to model fish capture success using length, velocity and 
>>> group composition as explanatory variables, density as an offset 
>>> variable, and fish.id. as random effect. I'm getting the follow warnings:
>>>
>>>
>>>
>>> Model1<-glmer(capture~length+offset(density)+(1|fish.id),family=binomi
>>> al,dat
>>> a=cap)
>>>
>>>
>>>
>>> Warning messages:
>>>
>>> 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>>>
>>>  Model failed to converge with max|grad| = 0.260123 (tol = 0.001, 
>>> component
>>> 1)
>>>
>>> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>>>
>>>  Model is nearly unidentifiable: very large eigenvalue
>>>
>>> - Rescale variables?
>>>
>>>
>>>
>>>
>>>
>>> -          I only get the warnings when I use length and group composition,
>>> not with velocity.
>>>
>>> -          I don't get any warning if I don't use the offset.
>>>
>>>
>>>
>>> I've tried:
>>>
>>> Model1<-glmer(capture~length+offset(log(density))+(1|fish.id.c),family
>>> =binom
>>> ial(link="cloglog"),data=cap)
>>>
>>>
>>>
>>> But still get the warning.
>>>
>>>
>>>
>>> Any ideas of what might be the problem?
>>>
>>>
>>>
>>> Many thanks!
>>>
>>>
>>>
>>>
>>>
>>> Joana Martelo
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> Melhores cumprimentos,
>>>
>>>
>>>
>>> Joana Martins
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list 
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> ---
>> Este e-mail foi verificado em termos de v?rus pelo AVG.
>> http://www.avg.com
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From bbolker @ending from gm@il@com  Mon Nov 26 15:05:06 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Mon, 26 Nov 2018 09:05:06 -0500
Subject: [R-sig-ME] 
 warnings when using binomial models and offset (log(x))
In-Reply-To: <00f301d4858e$85919d70$90b4d850$@com>
References: <000a01d48351$9d70c4f0$d8524ed0$@com>
 <f6a9b285-999e-17f0-0fd1-6191e6ccadd6@gmail.com>
 <00d201d48584$2e9bd990$8bd38cb0$@com>
 <BAD2A316-6DA0-4F9C-867F-A743130E6002@gmail.com>
 <00f301d4858e$85919d70$90b4d850$@com>
Message-ID: <e3776125-d9de-675a-fc46-ea8da8e63a26@gmail.com>


  Have you looked at the ?convergence help page?

  By the way, what is the purpose of the +2 in your offset term?  Are
you still centering your offset?

On 2018-11-26 8:47 a.m., Joana Martelo wrote:
> Thanks for your help!
> 
> However, I still get the warnings when using offset(log(density)
> 
> 
>> Model1<-glmer(capture~length+offset(log(density+2))+(1|fish.id.c),family=binomial,data=cap)
> 
> 
> Warning messages:
> 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model failed to converge with max|grad| = 0.258231 (tol = 0.001, component 1)
> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model is nearly unidentifiable: very large eigenvalue
>  - Rescale variables?
> 
> 
> Any suggestion?
> 
> Thanks
> Joana
> 
> 
> 
> -----Mensagem original-----
> De: Mollie Brooks [mailto:mollieebrooks at gmail.com] 
> Enviada: segunda-feira, 26 de Novembro de 2018 12:36
> Para: Joana Martelo
> Cc: R SIG Mixed Models
> Assunto: Re: [R-sig-ME] warnings when using binomial models and offset - NaNs
> 
> If you?re using the scale() function to standardize your density values, you could use the argument, center=FALSE, to avoid subtracting the mean and thus avoid negative densities. 
> 
> cheers,
> Mollie
> 
>> On 26Nov 2018, at 13:33, Joana Martelo <joanamartelo at gmail.com> wrote:
>>
>> Thanks for your email!
>>
>> Warnings' problem is solved, however, when I use log(density) or 
>> log(density+1) I got NaNs because density has negative numbers. 
>> Density is 2,4,6 which standardized gives -1.793073717, -0.450015136, 
>> 0.893043446. So, log(-1.793073717+1)= NaN
>>
>> Any suggestions?
>>
>> Many thanks!
>> Joana
>>
>>
>> -----Mensagem original-----
>> De: R-sig-mixed-models 
>> [mailto:r-sig-mixed-models-bounces at r-project.org] Em nome de Ben 
>> Bolker
>> Enviada: sexta-feira, 23 de Novembro de 2018 21:54
>> Para: r-sig-mixed-models at r-project.org
>> Assunto: Re: [R-sig-ME] warnings when using binomial models and offset
>>
>>
>>  This is a pretty common error, which I've now added to the GLMM FAQ.
>> You should be using log(density), not density, as your offset term; if you use density, then you end up specifying that your capture counts are proportional to exp(density), which is often a ridiculously huge number.
>>
>> cheers
>>   Ben Bolker
>>
>> On 2018-11-23 12:26 p.m., Joana Martelo wrote:
>>> Hello everyone
>>>
>>>
>>>
>>> I'm trying to model fish capture success using length, velocity and 
>>> group composition as explanatory variables, density as an offset 
>>> variable, and fish.id. as random effect. I'm getting the follow warnings:
>>>
>>>
>>>
>>> Model1<-glmer(capture~length+offset(density)+(1|fish.id),family=binom
>>> i
>>> al,dat
>>> a=cap)
>>>
>>>
>>>
>>> Warning messages:
>>>
>>> 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>>>
>>>  Model failed to converge with max|grad| = 0.260123 (tol = 0.001, 
>>> component
>>> 1)
>>>
>>> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>>>
>>>  Model is nearly unidentifiable: very large eigenvalue
>>>
>>> - Rescale variables?
>>>
>>>
>>>
>>>
>>>
>>> -          I only get the warnings when I use length and group composition,
>>> not with velocity.
>>>
>>> -          I don't get any warning if I don't use the offset.
>>>
>>>
>>>
>>> I've tried:
>>>
>>> Model1<-glmer(capture~length+offset(log(density))+(1|fish.id.c),famil
>>> y
>>> =binom
>>> ial(link="cloglog"),data=cap)
>>>
>>>
>>>
>>> But still get the warning.
>>>
>>>
>>>
>>> Any ideas of what might be the problem?
>>>
>>>
>>>
>>> Many thanks!
>>>
>>>
>>>
>>>
>>>
>>> Joana Martelo
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> Melhores cumprimentos,
>>>
>>>
>>>
>>> Joana Martins
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list 
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> ---
>> Este e-mail foi verificado em termos de v?rus pelo AVG.
>> http://www.avg.com
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From jo@n@m@rtelo @ending from gm@il@com  Mon Nov 26 15:18:43 2018
From: jo@n@m@rtelo @ending from gm@il@com (Joana Martelo)
Date: Mon, 26 Nov 2018 14:18:43 -0000
Subject: [R-sig-ME] 
 warnings when using binomial models and offset (log(x))
In-Reply-To: <e3776125-d9de-675a-fc46-ea8da8e63a26@gmail.com>
References: <000a01d48351$9d70c4f0$d8524ed0$@com>
 <f6a9b285-999e-17f0-0fd1-6191e6ccadd6@gmail.com>
 <00d201d48584$2e9bd990$8bd38cb0$@com>
 <BAD2A316-6DA0-4F9C-867F-A743130E6002@gmail.com>
 <00f301d4858e$85919d70$90b4d850$@com>
 <e3776125-d9de-675a-fc46-ea8da8e63a26@gmail.com>
Message-ID: <00f501d48592$f09a9910$d1cfcb30$@com>

Yes, I was centering my offset, but that was before I see your email. It was just another option.
I'll have a look at the ?convergence help page?. 
Thanks
Joana

-----Mensagem original-----
De: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] Em nome de Ben Bolker
Enviada: segunda-feira, 26 de Novembro de 2018 14:05
Para: r-sig-mixed-models at r-project.org
Assunto: Re: [R-sig-ME] warnings when using binomial models and offset (log(x))


  Have you looked at the ?convergence help page?

  By the way, what is the purpose of the +2 in your offset term?  Are you still centering your offset?

On 2018-11-26 8:47 a.m., Joana Martelo wrote:
> Thanks for your help!
> 
> However, I still get the warnings when using offset(log(density)
> 
> 
>> Model1<-glmer(capture~length+offset(log(density+2))+(1|fish.id.c),fam
>> ily=binomial,data=cap)
> 
> 
> Warning messages:
> 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model failed to converge with max|grad| = 0.258231 (tol = 0.001, 
> component 1)
> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model is nearly unidentifiable: very large eigenvalue
>  - Rescale variables?
> 
> 
> Any suggestion?
> 
> Thanks
> Joana
> 
> 
> 
> -----Mensagem original-----
> De: Mollie Brooks [mailto:mollieebrooks at gmail.com]
> Enviada: segunda-feira, 26 de Novembro de 2018 12:36
> Para: Joana Martelo
> Cc: R SIG Mixed Models
> Assunto: Re: [R-sig-ME] warnings when using binomial models and offset 
> - NaNs
> 
> If you?re using the scale() function to standardize your density values, you could use the argument, center=FALSE, to avoid subtracting the mean and thus avoid negative densities. 
> 
> cheers,
> Mollie
> 
>> On 26Nov 2018, at 13:33, Joana Martelo <joanamartelo at gmail.com> wrote:
>>
>> Thanks for your email!
>>
>> Warnings' problem is solved, however, when I use log(density) or
>> log(density+1) I got NaNs because density has negative numbers. 
>> Density is 2,4,6 which standardized gives -1.793073717, -0.450015136, 
>> 0.893043446. So, log(-1.793073717+1)= NaN
>>
>> Any suggestions?
>>
>> Many thanks!
>> Joana
>>
>>
>> -----Mensagem original-----
>> De: R-sig-mixed-models
>> [mailto:r-sig-mixed-models-bounces at r-project.org] Em nome de Ben 
>> Bolker
>> Enviada: sexta-feira, 23 de Novembro de 2018 21:54
>> Para: r-sig-mixed-models at r-project.org
>> Assunto: Re: [R-sig-ME] warnings when using binomial models and 
>> offset
>>
>>
>>  This is a pretty common error, which I've now added to the GLMM FAQ.
>> You should be using log(density), not density, as your offset term; if you use density, then you end up specifying that your capture counts are proportional to exp(density), which is often a ridiculously huge number.
>>
>> cheers
>>   Ben Bolker
>>
>> On 2018-11-23 12:26 p.m., Joana Martelo wrote:
>>> Hello everyone
>>>
>>>
>>>
>>> I'm trying to model fish capture success using length, velocity and 
>>> group composition as explanatory variables, density as an offset 
>>> variable, and fish.id. as random effect. I'm getting the follow warnings:
>>>
>>>
>>>
>>> Model1<-glmer(capture~length+offset(density)+(1|fish.id),family=bino
>>> m
>>> i
>>> al,dat
>>> a=cap)
>>>
>>>
>>>
>>> Warning messages:
>>>
>>> 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>>>
>>>  Model failed to converge with max|grad| = 0.260123 (tol = 0.001, 
>>> component
>>> 1)
>>>
>>> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>>>
>>>  Model is nearly unidentifiable: very large eigenvalue
>>>
>>> - Rescale variables?
>>>
>>>
>>>
>>>
>>>
>>> -          I only get the warnings when I use length and group composition,
>>> not with velocity.
>>>
>>> -          I don't get any warning if I don't use the offset.
>>>
>>>
>>>
>>> I've tried:
>>>
>>> Model1<-glmer(capture~length+offset(log(density))+(1|fish.id.c),fami
>>> l
>>> y
>>> =binom
>>> ial(link="cloglog"),data=cap)
>>>
>>>
>>>
>>> But still get the warning.
>>>
>>>
>>>
>>> Any ideas of what might be the problem?
>>>
>>>
>>>
>>> Many thanks!
>>>
>>>
>>>
>>>
>>>
>>> Joana Martelo
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> Melhores cumprimentos,
>>>
>>>
>>>
>>> Joana Martins
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list 
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> ---
>> Este e-mail foi verificado em termos de v?rus pelo AVG.
>> http://www.avg.com
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From thierry@onkelinx @ending from inbo@be  Mon Nov 26 16:36:52 2018
From: thierry@onkelinx @ending from inbo@be (Thierry Onkelinx)
Date: Mon, 26 Nov 2018 16:36:52 +0100
Subject: [R-sig-ME] diverging results with and without random effects
In-Reply-To: <841426ed-40d2-c9a7-b9c1-21507a1c0687@med.uni-goettingen.de>
References: <b913cd50-ee7e-6419-0f87-98da32efd142@med.uni-goettingen.de>
 <841426ed-40d2-c9a7-b9c1-21507a1c0687@med.uni-goettingen.de>
Message-ID: <CAJuCY5xA6_2oe51UJOkDFiKScsw8D_5uDRP=TDCgeGO5MKhPJg@mail.gmail.com>

Dear Andreas,

This is due to quasi complete separatation. This occurs when all responses
for a specific combination of levels are always TRUE or FALSE. In your
case, you have only two observations per patient. Hence adding the patient
as random effect, guarantees quasi complete separation issues.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op ma 26 nov. 2018 om 13:48 schreef Leha, Andreas <
andreas.leha at med.uni-goettingen.de>:

> Hi all,
>
> sent the wrong code (w/o filtering for BL).  If you want to look at the
> data, please use this code:
>
> ---------- cut here --------------------------------------------
> library("dplyr")
> library("lme4")
> library("lmerTest")
> ## install_github("hrbrmstr/pastebin", upgrade_dependencies = FALSE)
> library("pastebin")
>
> ## ---------------------------------- ##
> ## load the data                      ##
> ## ---------------------------------- ##
> dat <- pastebin::get_paste("Xgwgtb7j") %>% as.character %>% gsub("\r\n",
> "", .) %>% parse(text = .) %>% eval
>
>
>
> ## ---------------------------------- ##
> ## have a look                        ##
> ## ---------------------------------- ##
> dat
> ## ,----
> ## | # A tibble: 475 x 4
> ## |    patient group fu    riskfactor
> ## |    <fct>   <fct> <fct> <fct>
> ## |  1 p001    wt    BL    norisk
> ## |  2 p002    wt    BL    norisk
> ## |  3 p003    wt    BL    norisk
> ## |  4 p004    wt    BL    norisk
> ## |  5 p005    wt    BL    norisk
> ## |  6 p006    wt    BL    norisk
> ## |  7 p007    wt    BL    norisk
> ## |  8 p008    wt    BL    norisk
> ## |  9 p009    wt    BL    risk
> ## | 10 p010    wt    BL    norisk
> ## | # ... with 465 more rows
> ## `----
> dat %>% str
> ## ,----
> ## | Classes ?tbl_df?, ?tbl? and 'data.frame':  475 obs. of  4 variables:
> ## |  $ patient   : Factor w/ 265 levels "p001","p002",..: 1 2 3 4 5 6 7
> 8 9 10 ...
> ## |  $ group     : Factor w/ 2 levels "wt","mut": 1 1 1 1 1 1 1 1 1 1 ...
> ## |  $ fu        : Factor w/ 2 levels "BL","FU": 1 1 1 1 1 1 1 1 1 1 ...
> ## |  $ riskfactor: Factor w/ 2 levels "risk","norisk": 2 2 2 2 2 2 2 2
> 1 2 ...
> ## `----
>
> ## there are 265 patients
> ## in 2 groups: "wt" and "mut"
> ## with a dichotomous risk factor ("risk" and "norisk")
> ## measured at two time points ("BL" and "FU")
>
> dat %>% summary
> ## ,----
> ## |     patient    group      fu       riskfactor
> ## |  p001   :  2   wt :209   BL:258   risk  :205
> ## |  p002   :  2   mut:266   FU:217   norisk:270
> ## |  p003   :  2
> ## |  p004   :  2
> ## |  p005   :  2
> ## |  p006   :  2
> ## |  (Other):463
> ## `----
>
> ## group sizes seem fine
>
>
>
> ## ---------------------------------------------- ##
> ## first, we look at the first time point, the BL ##
> ## ---------------------------------------------- ##
>
> ## we build a cross table
> tab_bl <-
>   dat %>%
>   dplyr::filter(fu == "BL") %>%
>   dplyr::select(group, riskfactor) %>%
>   table
> tab_bl
> ## ,----
> ## |      riskfactor
> ## | group risk norisk
> ## |   wt    22     86
> ## |   mut   87     63
> ## `----
>
> ## and we test using fisher:
> tab_bl %>% fisher.test
> ## ,----
> ## |    Fisher's Exact Test for Count Data
> ## |
> ## | data:  .
> ## | p-value = 1.18e-09
> ## | alternative hypothesis: true odds ratio is not equal to 1
> ## | 95 percent confidence interval:
> ## |  0.09986548 0.33817966
> ## | sample estimates:
> ## | odds ratio
> ## |  0.1865377
> ## `----
> log(0.187)
> ## ,----
> ## | [1] -1.676647
> ## `----
>
> ## so, we get a highly significant association of the riskfactor
> ## and the group with an log(odds ratio) of -1.7
>
> ## we get the same result using logistic regression:
> dat %>%
>   filter(fu == "BL") %>%
>   glm(group ~ riskfactor, family = "binomial", data = .) %>%
>   summary
> ## ,----
> ## | Call:
> ## | glm(formula = group ~ riskfactor, family = "binomial", data = .)
> ## |
> ## | Deviance Residuals:
> ## |     Min       1Q   Median       3Q      Max
> ## | -1.7890  -1.0484   0.6715   0.6715   1.3121
> ## |
> ## | Coefficients:
> ## |                  Estimate Std. Error z value Pr(>|z|)
> ## | (Intercept)        1.3749     0.2386   5.761 8.35e-09 ***
> ## | riskfactornorisk  -1.6861     0.2906  -5.802 6.55e-09 ***
> ## | ---
> ## | Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> ## |
> ## | (Dispersion parameter for binomial family taken to be 1)
> ## |
> ## |     Null deviance: 350.80  on 257  degrees of freedom
> ## | Residual deviance: 312.63  on 256  degrees of freedom
> ## | AIC: 316.63
> ## |
> ## | Number of Fisher Scoring iterations: 4
> ## `----
>
>
>
> ## ------------------------------------------------- ##
> ## Now, we analyse both time points with interaction ##
> ## ------------------------------------------------- ##
>
> dat %>%
>   glmer(group ~ riskfactor + fu + riskfactor:fu + (1|patient), family =
> "binomial", data = .) %>%
>   summary
> ## ,----
> ## | Generalized linear mixed model fit by maximum likelihood (Laplace
> ## |   Approximation) [glmerMod]
> ## |  Family: binomial  ( logit )
> ## | Formula: group ~ riskfactor + fu + riskfactor:fu + (1 | patient)
> ## |    Data: .
> ## |
> ## |      AIC      BIC   logLik deviance df.resid
> ## |    345.2    366.0   -167.6    335.2      470
> ## |
> ## | Scaled residuals:
> ## |       Min        1Q    Median        3Q       Max
> ## | -0.095863 -0.058669  0.002278  0.002866  0.007324
> ## |
> ## | Random effects:
> ## |  Groups  Name        Variance Std.Dev.
> ## |  patient (Intercept) 1849     43
> ## | Number of obs: 475, groups:  patient, 265
> ## |
> ## | Fixed effects:
> ## |                       Estimate Std. Error z value Pr(>|z|)
> ## | (Intercept)            11.6846     1.3736   8.507   <2e-16 ***
> ## | riskfactornorisk       -1.5919     1.4166  -1.124    0.261
> ## | fuFU                    0.4596     1.9165   0.240    0.810
> ## | riskfactornorisk:fuFU  -0.8183     2.1651  -0.378    0.705
> ## | ---
> ## | Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> ## |
> ## | Correlation of Fixed Effects:
> ## |             (Intr) rskfct fuFU
> ## | rskfctrnrsk -0.746
> ## | fuFU        -0.513  0.510
> ## | rskfctrn:FU  0.478 -0.576 -0.908
> ## `----
>
> ## I get huge variation in the random effects
> ##
> ## And the risk factor at BL gets an estimated log(odds ratio) of -1.6
> ## but one which is not significant
> ---------- cut here --------------------------------------------
>
>
> On 26/11/18 12:10, Leha, Andreas wrote:
> > Hi all,
> >
> > I am interested in assessing the association of a (potential) risk
> > factor to a (binary) grouping.
> >
> > I am having trouble with diverging results from modeling one time point
> > (without random effect) and modeling two time points (with random
> effect).
> >
> > When analysing the first time point (base line, BL) only, I get a highly
> > significant association.
> > Now, I want to see, whether there is an interaction between time and
> > risk factor (the risk factor is not constant).  But when analysing both
> > time points, the estimated effect at BL is estimated to be not
> significant.
> >
> > Now my simplified questions are:
> > (1) Is there an association at BL or not?
> > (2) How should I analyse both time points with this data?
> >
> > The aim is to look for confounding with other factors.  But I'd like to
> > understand the simple models before moving on.
> >
> > Below you find a reproducible example and the detailed results.
> >
> > Any suggestions would be highly appreciated!
> >
> > Regards,
> > Andreas
> >
> >
> >
> > PS: The code / results
> >
> > ---------- cut here --------------------------------------------
> > library("dplyr")
> > library("lme4")
> > library("lmerTest")
> > ## install_github("hrbrmstr/pastebin", upgrade_dependencies = FALSE)
> > library("pastebin")
> >
> > ## ---------------------------------- ##
> > ## load the data                      ##
> > ## ---------------------------------- ##
> > dat <- pastebin::get_paste("Xgwgtb7j") %>%
> >   as.character %>%
> >   gsub("\r\n", "", .) %>%
> >   parse(text = .) %>%
> >   eval
> >
> >
> >
> > ## ---------------------------------- ##
> > ## have a look                        ##
> > ## ---------------------------------- ##
> > dat
> > ## ,----
> > ## | # A tibble: 475 x 4
> > ## |    patient group fu    riskfactor
> > ## |    <fct>   <fct> <fct> <fct>
> > ## |  1 p001    wt    BL    norisk
> > ## |  2 p002    wt    BL    norisk
> > ## |  3 p003    wt    BL    norisk
> > ## |  4 p004    wt    BL    norisk
> > ## |  5 p005    wt    BL    norisk
> > ## |  6 p006    wt    BL    norisk
> > ## |  7 p007    wt    BL    norisk
> > ## |  8 p008    wt    BL    norisk
> > ## |  9 p009    wt    BL    risk
> > ## | 10 p010    wt    BL    norisk
> > ## | # ... with 465 more rows
> > ## `----
> > dat %>% str
> > ## ,----
> > ## | Classes ?tbl_df?, ?tbl? and 'data.frame':        475 obs. of  4
> variables:
> > ## |  $ patient   : Factor w/ 265 levels "p001","p002",..: 1 2 3 4 5 6 7
> > 8 9 10 ...
> > ## |  $ group     : Factor w/ 2 levels "wt","mut": 1 1 1 1 1 1 1 1 1 1
> ...
> > ## |  $ fu        : Factor w/ 2 levels "BL","FU": 1 1 1 1 1 1 1 1 1 1 ...
> > ## |  $ riskfactor: Factor w/ 2 levels "risk","norisk": 2 2 2 2 2 2 2 2
> > 1 2 ...
> > ## `----
> >
> > ## there are 265 patients
> > ## in 2 groups: "wt" and "mut"
> > ## with a dichotomous risk factor ("risk" and "norisk")
> > ## measured at two time points ("BL" and "FU")
> >
> > dat %>% summary
> > ## ,----
> > ## |     patient    group      fu       riskfactor
> > ## |  p001   :  2   wt :209   BL:258   risk  :205
> > ## |  p002   :  2   mut:266   FU:217   norisk:270
> > ## |  p003   :  2
> > ## |  p004   :  2
> > ## |  p005   :  2
> > ## |  p006   :  2
> > ## |  (Other):463
> > ## `----
> >
> > ## group sizes seem fine
> >
> >
> >
> > ## ---------------------------------------------- ##
> > ## first, we look at the first time point, the BL ##
> > ## ---------------------------------------------- ##
> >
> > ## we build a cross table
> > tab_bl <-
> >   dat %>%
> >   dplyr::select(group, riskfactor) %>%
> >   table
> > tab_bl
> > ## ,----
> > ## |      riskfactor
> > ## | group risk norisk
> > ## |   wt    35    174
> > ## |   mut  170     96
> > ## `----
> >
> > ## and we test using fisher:
> > tab_bl %>% fisher.test
> > ## ,----
> > ## |    Fisher's Exact Test for Count Data
> > ## |
> > ## | data:  .
> > ## | p-value < 2.2e-16
> > ## | alternative hypothesis: true odds ratio is not equal to 1
> > ## | 95 percent confidence interval:
> > ## |  0.07099792 0.18002325
> > ## | sample estimates:
> > ## | odds ratio
> > ## |  0.1141677
> > ## `----
> > log(0.114)
> > ## ,----
> > ## | [1] -2.171557
> > ## `----
> >
> > ## so, we get a highly significant association of the riskfactor
> > ## and the group with an log(odds ratio) of -2.2
> >
> > ## we get the same result using logistic regression:
> > dat %>%
> >   glm(group ~ riskfactor, family = "binomial", data = .) %>%
> >   summary
> > ## ,----
> > ## |
> > ## | Call:
> > ## | glm(formula = group ~ riskfactor, family = "binomial", data = .)
> > ## |
> > ## | Deviance Residuals:
> > ## |     Min       1Q   Median       3Q      Max
> > ## | -1.8802  -0.9374   0.6119   0.6119   1.4381
> > ## |
> > ## | Coefficients:
> > ## |                  Estimate Std. Error z value Pr(>|z|)
> > ## | (Intercept)        1.5805     0.1856   8.515   <2e-16 ***
> > ## | riskfactornorisk  -2.1752     0.2250  -9.668   <2e-16 ***
> > ## | ---
> > ## | Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> > ## |
> > ## | (Dispersion parameter for binomial family taken to be 1)
> > ## |
> > ## |     Null deviance: 651.63  on 474  degrees of freedom
> > ## | Residual deviance: 538.83  on 473  degrees of freedom
> > ## | AIC: 542.83
> > ## |
> > ## | Number of Fisher Scoring iterations: 4
> > ## `----
> >
> >
> >
> > ## ------------------------------------------------- ##
> > ## Now, we analyse both time points with interaction ##
> > ## ------------------------------------------------- ##
> >
> > dat %>%
> >   glmer(group ~ riskfactor + fu + riskfactor:fu + (1|patient), family =
> > "binomial", data = .) %>%
> >   summary
> > ## ,----
> > ## | Generalized linear mixed model fit by maximum likelihood (Laplace
> > ## |   Approximation) [glmerMod]
> > ## |  Family: binomial  ( logit )
> > ## | Formula: group ~ riskfactor + fu + riskfactor:fu + (1 | patient)
> > ## |    Data: .
> > ## |
> > ## |      AIC      BIC   logLik deviance df.resid
> > ## |    345.2    366.0   -167.6    335.2      470
> > ## |
> > ## | Scaled residuals:
> > ## |       Min        1Q    Median        3Q       Max
> > ## | -0.095863 -0.058669  0.002278  0.002866  0.007324
> > ## |
> > ## | Random effects:
> > ## |  Groups  Name        Variance Std.Dev.
> > ## |  patient (Intercept) 1849     43
> > ## | Number of obs: 475, groups:  patient, 265
> > ## |
> > ## | Fixed effects:
> > ## |                       Estimate Std. Error z value Pr(>|z|)
> > ## | (Intercept)            11.6846     1.3736   8.507   <2e-16 ***
> > ## | riskfactornorisk       -1.5919     1.4166  -1.124    0.261
> > ## | fuFU                    0.4596     1.9165   0.240    0.810
> > ## | riskfactornorisk:fuFU  -0.8183     2.1651  -0.378    0.705
> > ## | ---
> > ## | Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> > ## |
> > ## | Correlation of Fixed Effects:
> > ## |             (Intr) rskfct fuFU
> > ## | rskfctrnrsk -0.746
> > ## | fuFU        -0.513  0.510
> > ## | rskfctrn:FU  0.478 -0.576 -0.908
> > ## `----
> >
> > ## I get huge variation in the random effects
> > ##
> > ## And the risk factor at BL gets an estimated log(odds ratio) of -1.6
> > ## but one which is not significant
> > ---------- cut here --------------------------------------------
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> --
> Dr. Andreas Leha
> Head of the 'Core Facility
> Medical Biometry and Statistical Bioinformatics'
>
> UNIVERSITY MEDICAL CENTER G?TTINGEN
> GEORG-AUGUST-UNIVERSIT?T
> Department of Medical Statistics
> Humboldtallee 32
> 37073 G?ttingen
> Mailing Address: 37099 G?ttingen, Germany
> Fax: +49 (0) 551 39-4995
> Tel: +49 (0) 551 39-4987
> http://www.ams.med.uni-goettingen.de/service-de.shtml
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From @ndre@@@leh@ @ending from med@uni-goettingen@de  Mon Nov 26 17:00:53 2018
From: @ndre@@@leh@ @ending from med@uni-goettingen@de (Leha, Andreas)
Date: Mon, 26 Nov 2018 16:00:53 +0000
Subject: [R-sig-ME] diverging results with and without random effects
In-Reply-To: <CAJuCY5xA6_2oe51UJOkDFiKScsw8D_5uDRP=TDCgeGO5MKhPJg@mail.gmail.com>
References: <b913cd50-ee7e-6419-0f87-98da32efd142@med.uni-goettingen.de>
 <841426ed-40d2-c9a7-b9c1-21507a1c0687@med.uni-goettingen.de>
 <CAJuCY5xA6_2oe51UJOkDFiKScsw8D_5uDRP=TDCgeGO5MKhPJg@mail.gmail.com>
Message-ID: <dc5492f4-f310-3957-3755-6613a82a53b9@med.uni-goettingen.de>

Dear Thierry,

thanks for looking into this!

So, one solution would be a baysian analysis, right?

Would you have a recommendation for me?

I followed [1] and used

  library("blme")
  dat %>%
    bglmer(group ~ riskfactor + fu + riskfactor:fu + (1|patient),
           family = "binomial",
           data = .,
           fixef.prior = normal(cov = diag(9,4))) %>%
    summary

Which runs and gives the following fixed effect estimates:


  Fixed effects:
                        Estimate Std. Error z value Pr(>|z|)
  (Intercept)             8.2598     0.7445  11.094   <2e-16 ***
  riskfactornorisk      -16.0942     1.3085 -12.300   <2e-16 ***
  fuFU                    1.0019     1.0047   0.997    0.319
  riskfactornorisk:fuFU  -1.8675     1.2365  -1.510    0.131


These still do not seem reasonable.

Thanks in advance!

Regards,
Andreas


[1]
https://stats.stackexchange.com/questions/132677/binomial-glmm-with-a-categorical-variable-with-full-successes/132678#132678


On 26/11/18 16:36, Thierry Onkelinx wrote:
> Dear Andreas,
> 
> This is due to quasi complete separatation. This occurs when all
> responses for a specific combination of levels are always TRUE or FALSE.
> In your case, you have only two observations per patient. Hence adding
> the patient as random effect, guarantees quasi complete separation issues.??
> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Statisticus / Statistician
> 
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> AND FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be <http://www.inbo.be>
> 
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to
> say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of
> data. ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
> 
> <https://www.inbo.be>
> 
> 
> Op ma 26 nov. 2018 om 13:48 schreef Leha, Andreas
> <andreas.leha at med.uni-goettingen.de
> <mailto:andreas.leha at med.uni-goettingen.de>>:
> 
>     Hi all,
> 
>     sent the wrong code (w/o filtering for BL).? If you want to look at the
>     data, please use this code:
> 
>     ---------- cut here --------------------------------------------
>     library("dplyr")
>     library("lme4")
>     library("lmerTest")
>     ## install_github("hrbrmstr/pastebin", upgrade_dependencies = FALSE)
>     library("pastebin")
> 
>     ## ---------------------------------- ##
>     ## load the data? ? ? ? ? ? ? ? ? ? ? ##
>     ## ---------------------------------- ##
>     dat <- pastebin::get_paste("Xgwgtb7j") %>% as.character %>% gsub("\r\n",
>     "", .) %>% parse(text = .) %>% eval
> 
> 
> 
>     ## ---------------------------------- ##
>     ## have a look? ? ? ? ? ? ? ? ? ? ? ? ##
>     ## ---------------------------------- ##
>     dat
>     ## ,----
>     ## | # A tibble: 475 x 4
>     ## |? ? patient group fu? ? riskfactor
>     ## |? ? <fct>? ?<fct> <fct> <fct>
>     ## |? 1 p001? ? wt? ? BL? ? norisk
>     ## |? 2 p002? ? wt? ? BL? ? norisk
>     ## |? 3 p003? ? wt? ? BL? ? norisk
>     ## |? 4 p004? ? wt? ? BL? ? norisk
>     ## |? 5 p005? ? wt? ? BL? ? norisk
>     ## |? 6 p006? ? wt? ? BL? ? norisk
>     ## |? 7 p007? ? wt? ? BL? ? norisk
>     ## |? 8 p008? ? wt? ? BL? ? norisk
>     ## |? 9 p009? ? wt? ? BL? ? risk
>     ## | 10 p010? ? wt? ? BL? ? norisk
>     ## | # ... with 465 more rows
>     ## `----
>     dat %>% str
>     ## ,----
>     ## | Classes ?tbl_df?, ?tbl? and 'data.frame':? 475 obs. of? 4
>     variables:
>     ## |? $ patient? ?: Factor w/ 265 levels "p001","p002",..: 1 2 3 4 5 6 7
>     8 9 10 ...
>     ## |? $ group? ? ?: Factor w/ 2 levels "wt","mut": 1 1 1 1 1 1 1 1 1
>     1 ...
>     ## |? $ fu? ? ? ? : Factor w/ 2 levels "BL","FU": 1 1 1 1 1 1 1 1 1
>     1 ...
>     ## |? $ riskfactor: Factor w/ 2 levels "risk","norisk": 2 2 2 2 2 2 2 2
>     1 2 ...
>     ## `----
> 
>     ## there are 265 patients
>     ## in 2 groups: "wt" and "mut"
>     ## with a dichotomous risk factor ("risk" and "norisk")
>     ## measured at two time points ("BL" and "FU")
> 
>     dat %>% summary
>     ## ,----
>     ## |? ? ?patient? ? group? ? ? fu? ? ? ?riskfactor
>     ## |? p001? ?:? 2? ?wt :209? ?BL:258? ?risk? :205
>     ## |? p002? ?:? 2? ?mut:266? ?FU:217? ?norisk:270
>     ## |? p003? ?:? 2
>     ## |? p004? ?:? 2
>     ## |? p005? ?:? 2
>     ## |? p006? ?:? 2
>     ## |? (Other):463
>     ## `----
> 
>     ## group sizes seem fine
> 
> 
> 
>     ## ---------------------------------------------- ##
>     ## first, we look at the first time point, the BL ##
>     ## ---------------------------------------------- ##
> 
>     ## we build a cross table
>     tab_bl <-
>     ? dat %>%
>     ? dplyr::filter(fu == "BL") %>%
>     ? dplyr::select(group, riskfactor) %>%
>     ? table
>     tab_bl
>     ## ,----
>     ## |? ? ? riskfactor
>     ## | group risk norisk
>     ## |? ?wt? ? 22? ? ?86
>     ## |? ?mut? ?87? ? ?63
>     ## `----
> 
>     ## and we test using fisher:
>     tab_bl %>% fisher.test
>     ## ,----
>     ## |? ? Fisher's Exact Test for Count Data
>     ## |
>     ## | data:? .
>     ## | p-value = 1.18e-09
>     ## | alternative hypothesis: true odds ratio is not equal to 1
>     ## | 95 percent confidence interval:
>     ## |? 0.09986548 0.33817966
>     ## | sample estimates:
>     ## | odds ratio
>     ## |? 0.1865377
>     ## `----
>     log(0.187)
>     ## ,----
>     ## | [1] -1.676647
>     ## `----
> 
>     ## so, we get a highly significant association of the riskfactor
>     ## and the group with an log(odds ratio) of -1.7
> 
>     ## we get the same result using logistic regression:
>     dat %>%
>     ? filter(fu == "BL") %>%
>     ? glm(group ~ riskfactor, family = "binomial", data = .) %>%
>     ? summary
>     ## ,----
>     ## | Call:
>     ## | glm(formula = group ~ riskfactor, family = "binomial", data = .)
>     ## |
>     ## | Deviance Residuals:
>     ## |? ? ?Min? ? ? ?1Q? ?Median? ? ? ?3Q? ? ? Max
>     ## | -1.7890? -1.0484? ?0.6715? ?0.6715? ?1.3121
>     ## |
>     ## | Coefficients:
>     ## |? ? ? ? ? ? ? ? ? Estimate Std. Error z value Pr(>|z|)
>     ## | (Intercept)? ? ? ? 1.3749? ? ?0.2386? ?5.761 8.35e-09 ***
>     ## | riskfactornorisk? -1.6861? ? ?0.2906? -5.802 6.55e-09 ***
>     ## | ---
>     ## | Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>     ## |
>     ## | (Dispersion parameter for binomial family taken to be 1)
>     ## |
>     ## |? ? ?Null deviance: 350.80? on 257? degrees of freedom
>     ## | Residual deviance: 312.63? on 256? degrees of freedom
>     ## | AIC: 316.63
>     ## |
>     ## | Number of Fisher Scoring iterations: 4
>     ## `----
> 
> 
> 
>     ## ------------------------------------------------- ##
>     ## Now, we analyse both time points with interaction ##
>     ## ------------------------------------------------- ##
> 
>     dat %>%
>     ? glmer(group ~ riskfactor + fu + riskfactor:fu + (1|patient), family =
>     "binomial", data = .) %>%
>     ? summary
>     ## ,----
>     ## | Generalized linear mixed model fit by maximum likelihood (Laplace
>     ## |? ?Approximation) [glmerMod]
>     ## |? Family: binomial? ( logit )
>     ## | Formula: group ~ riskfactor + fu + riskfactor:fu + (1 | patient)
>     ## |? ? Data: .
>     ## |
>     ## |? ? ? AIC? ? ? BIC? ?logLik deviance df.resid
>     ## |? ? 345.2? ? 366.0? ?-167.6? ? 335.2? ? ? 470
>     ## |
>     ## | Scaled residuals:
>     ## |? ? ? ?Min? ? ? ? 1Q? ? Median? ? ? ? 3Q? ? ? ?Max
>     ## | -0.095863 -0.058669? 0.002278? 0.002866? 0.007324
>     ## |
>     ## | Random effects:
>     ## |? Groups? Name? ? ? ? Variance Std.Dev.
>     ## |? patient (Intercept) 1849? ? ?43
>     ## | Number of obs: 475, groups:? patient, 265
>     ## |
>     ## | Fixed effects:
>     ## |? ? ? ? ? ? ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
>     ## | (Intercept)? ? ? ? ? ? 11.6846? ? ?1.3736? ?8.507? ?<2e-16 ***
>     ## | riskfactornorisk? ? ? ?-1.5919? ? ?1.4166? -1.124? ? 0.261
>     ## | fuFU? ? ? ? ? ? ? ? ? ? 0.4596? ? ?1.9165? ?0.240? ? 0.810
>     ## | riskfactornorisk:fuFU? -0.8183? ? ?2.1651? -0.378? ? 0.705
>     ## | ---
>     ## | Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>     ## |
>     ## | Correlation of Fixed Effects:
>     ## |? ? ? ? ? ? ?(Intr) rskfct fuFU
>     ## | rskfctrnrsk -0.746
>     ## | fuFU? ? ? ? -0.513? 0.510
>     ## | rskfctrn:FU? 0.478 -0.576 -0.908
>     ## `----
> 
>     ## I get huge variation in the random effects
>     ##
>     ## And the risk factor at BL gets an estimated log(odds ratio) of -1.6
>     ## but one which is not significant
>     ---------- cut here --------------------------------------------
> 
> 
>     On 26/11/18 12:10, Leha, Andreas wrote:
>     > Hi all,
>     >
>     > I am interested in assessing the association of a (potential) risk
>     > factor to a (binary) grouping.
>     >
>     > I am having trouble with diverging results from modeling one time
>     point
>     > (without random effect) and modeling two time points (with random
>     effect).
>     >
>     > When analysing the first time point (base line, BL) only, I get a
>     highly
>     > significant association.
>     > Now, I want to see, whether there is an interaction between time and
>     > risk factor (the risk factor is not constant).? But when analysing
>     both
>     > time points, the estimated effect at BL is estimated to be not
>     significant.
>     >
>     > Now my simplified questions are:
>     > (1) Is there an association at BL or not?
>     > (2) How should I analyse both time points with this data?
>     >
>     > The aim is to look for confounding with other factors.? But I'd
>     like to
>     > understand the simple models before moving on.
>     >
>     > Below you find a reproducible example and the detailed results.
>     >
>     > Any suggestions would be highly appreciated!
>     >
>     > Regards,
>     > Andreas
>     >
>     >
>     >
>     > PS: The code / results
>     >
>     > ---------- cut here --------------------------------------------
>     > library("dplyr")
>     > library("lme4")
>     > library("lmerTest")
>     > ## install_github("hrbrmstr/pastebin", upgrade_dependencies = FALSE)
>     > library("pastebin")
>     >
>     > ## ---------------------------------- ##
>     > ## load the data? ? ? ? ? ? ? ? ? ? ? ##
>     > ## ---------------------------------- ##
>     > dat <- pastebin::get_paste("Xgwgtb7j") %>%
>     >? ?as.character %>%
>     >? ?gsub("\r\n", "", .) %>%
>     >? ?parse(text = .) %>%
>     >? ?eval
>     >
>     >
>     >
>     > ## ---------------------------------- ##
>     > ## have a look? ? ? ? ? ? ? ? ? ? ? ? ##
>     > ## ---------------------------------- ##
>     > dat
>     > ## ,----
>     > ## | # A tibble: 475 x 4
>     > ## |? ? patient group fu? ? riskfactor
>     > ## |? ? <fct>? ?<fct> <fct> <fct>
>     > ## |? 1 p001? ? wt? ? BL? ? norisk
>     > ## |? 2 p002? ? wt? ? BL? ? norisk
>     > ## |? 3 p003? ? wt? ? BL? ? norisk
>     > ## |? 4 p004? ? wt? ? BL? ? norisk
>     > ## |? 5 p005? ? wt? ? BL? ? norisk
>     > ## |? 6 p006? ? wt? ? BL? ? norisk
>     > ## |? 7 p007? ? wt? ? BL? ? norisk
>     > ## |? 8 p008? ? wt? ? BL? ? norisk
>     > ## |? 9 p009? ? wt? ? BL? ? risk
>     > ## | 10 p010? ? wt? ? BL? ? norisk
>     > ## | # ... with 465 more rows
>     > ## `----
>     > dat %>% str
>     > ## ,----
>     > ## | Classes ?tbl_df?, ?tbl? and 'data.frame':? ? ? ? 475 obs. of?
>     4 variables:
>     > ## |? $ patient? ?: Factor w/ 265 levels "p001","p002",..: 1 2 3 4
>     5 6 7
>     > 8 9 10 ...
>     > ## |? $ group? ? ?: Factor w/ 2 levels "wt","mut": 1 1 1 1 1 1 1 1
>     1 1 ...
>     > ## |? $ fu? ? ? ? : Factor w/ 2 levels "BL","FU": 1 1 1 1 1 1 1 1
>     1 1 ...
>     > ## |? $ riskfactor: Factor w/ 2 levels "risk","norisk": 2 2 2 2 2
>     2 2 2
>     > 1 2 ...
>     > ## `----
>     >
>     > ## there are 265 patients
>     > ## in 2 groups: "wt" and "mut"
>     > ## with a dichotomous risk factor ("risk" and "norisk")
>     > ## measured at two time points ("BL" and "FU")
>     >
>     > dat %>% summary
>     > ## ,----
>     > ## |? ? ?patient? ? group? ? ? fu? ? ? ?riskfactor
>     > ## |? p001? ?:? 2? ?wt :209? ?BL:258? ?risk? :205
>     > ## |? p002? ?:? 2? ?mut:266? ?FU:217? ?norisk:270
>     > ## |? p003? ?:? 2
>     > ## |? p004? ?:? 2
>     > ## |? p005? ?:? 2
>     > ## |? p006? ?:? 2
>     > ## |? (Other):463
>     > ## `----
>     >
>     > ## group sizes seem fine
>     >
>     >
>     >
>     > ## ---------------------------------------------- ##
>     > ## first, we look at the first time point, the BL ##
>     > ## ---------------------------------------------- ##
>     >
>     > ## we build a cross table
>     > tab_bl <-
>     >? ?dat %>%
>     >? ?dplyr::select(group, riskfactor) %>%
>     >? ?table
>     > tab_bl
>     > ## ,----
>     > ## |? ? ? riskfactor
>     > ## | group risk norisk
>     > ## |? ?wt? ? 35? ? 174
>     > ## |? ?mut? 170? ? ?96
>     > ## `----
>     >
>     > ## and we test using fisher:
>     > tab_bl %>% fisher.test
>     > ## ,----
>     > ## |? ? Fisher's Exact Test for Count Data
>     > ## |
>     > ## | data:? .
>     > ## | p-value < 2.2e-16
>     > ## | alternative hypothesis: true odds ratio is not equal to 1
>     > ## | 95 percent confidence interval:
>     > ## |? 0.07099792 0.18002325
>     > ## | sample estimates:
>     > ## | odds ratio
>     > ## |? 0.1141677
>     > ## `----
>     > log(0.114)
>     > ## ,----
>     > ## | [1] -2.171557
>     > ## `----
>     >
>     > ## so, we get a highly significant association of the riskfactor
>     > ## and the group with an log(odds ratio) of -2.2
>     >
>     > ## we get the same result using logistic regression:
>     > dat %>%
>     >? ?glm(group ~ riskfactor, family = "binomial", data = .) %>%
>     >? ?summary
>     > ## ,----
>     > ## |
>     > ## | Call:
>     > ## | glm(formula = group ~ riskfactor, family = "binomial", data = .)
>     > ## |
>     > ## | Deviance Residuals:
>     > ## |? ? ?Min? ? ? ?1Q? ?Median? ? ? ?3Q? ? ? Max
>     > ## | -1.8802? -0.9374? ?0.6119? ?0.6119? ?1.4381
>     > ## |
>     > ## | Coefficients:
>     > ## |? ? ? ? ? ? ? ? ? Estimate Std. Error z value Pr(>|z|)
>     > ## | (Intercept)? ? ? ? 1.5805? ? ?0.1856? ?8.515? ?<2e-16 ***
>     > ## | riskfactornorisk? -2.1752? ? ?0.2250? -9.668? ?<2e-16 ***
>     > ## | ---
>     > ## | Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>     > ## |
>     > ## | (Dispersion parameter for binomial family taken to be 1)
>     > ## |
>     > ## |? ? ?Null deviance: 651.63? on 474? degrees of freedom
>     > ## | Residual deviance: 538.83? on 473? degrees of freedom
>     > ## | AIC: 542.83
>     > ## |
>     > ## | Number of Fisher Scoring iterations: 4
>     > ## `----
>     >
>     >
>     >
>     > ## ------------------------------------------------- ##
>     > ## Now, we analyse both time points with interaction ##
>     > ## ------------------------------------------------- ##
>     >
>     > dat %>%
>     >? ?glmer(group ~ riskfactor + fu + riskfactor:fu + (1|patient),
>     family =
>     > "binomial", data = .) %>%
>     >? ?summary
>     > ## ,----
>     > ## | Generalized linear mixed model fit by maximum likelihood (Laplace
>     > ## |? ?Approximation) [glmerMod]
>     > ## |? Family: binomial? ( logit )
>     > ## | Formula: group ~ riskfactor + fu + riskfactor:fu + (1 | patient)
>     > ## |? ? Data: .
>     > ## |
>     > ## |? ? ? AIC? ? ? BIC? ?logLik deviance df.resid
>     > ## |? ? 345.2? ? 366.0? ?-167.6? ? 335.2? ? ? 470
>     > ## |
>     > ## | Scaled residuals:
>     > ## |? ? ? ?Min? ? ? ? 1Q? ? Median? ? ? ? 3Q? ? ? ?Max
>     > ## | -0.095863 -0.058669? 0.002278? 0.002866? 0.007324
>     > ## |
>     > ## | Random effects:
>     > ## |? Groups? Name? ? ? ? Variance Std.Dev.
>     > ## |? patient (Intercept) 1849? ? ?43
>     > ## | Number of obs: 475, groups:? patient, 265
>     > ## |
>     > ## | Fixed effects:
>     > ## |? ? ? ? ? ? ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
>     > ## | (Intercept)? ? ? ? ? ? 11.6846? ? ?1.3736? ?8.507? ?<2e-16 ***
>     > ## | riskfactornorisk? ? ? ?-1.5919? ? ?1.4166? -1.124? ? 0.261
>     > ## | fuFU? ? ? ? ? ? ? ? ? ? 0.4596? ? ?1.9165? ?0.240? ? 0.810
>     > ## | riskfactornorisk:fuFU? -0.8183? ? ?2.1651? -0.378? ? 0.705
>     > ## | ---
>     > ## | Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>     > ## |
>     > ## | Correlation of Fixed Effects:
>     > ## |? ? ? ? ? ? ?(Intr) rskfct fuFU
>     > ## | rskfctrnrsk -0.746
>     > ## | fuFU? ? ? ? -0.513? 0.510
>     > ## | rskfctrn:FU? 0.478 -0.576 -0.908
>     > ## `----
>     >
>     > ## I get huge variation in the random effects
>     > ##
>     > ## And the risk factor at BL gets an estimated log(odds ratio) of -1.6
>     > ## but one which is not significant
>     > ---------- cut here --------------------------------------------
>     > _______________________________________________
>     > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >
> 
>     -- 
>     Dr. Andreas Leha
>     Head of the 'Core Facility
>     Medical Biometry and Statistical Bioinformatics'
> 
>     UNIVERSITY MEDICAL CENTER G?TTINGEN
>     GEORG-AUGUST-UNIVERSIT?T
>     Department of Medical Statistics
>     Humboldtallee 32
>     37073 G?ttingen
>     Mailing Address: 37099 G?ttingen, Germany
>     Fax: +49 (0) 551 39-4995
>     Tel: +49 (0) 551 39-4987
>     http://www.ams.med.uni-goettingen.de/service-de.shtml
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
Dr. Andreas Leha
Head of the 'Core Facility
Medical Biometry and Statistical Bioinformatics'

UNIVERSITY MEDICAL CENTER G?TTINGEN
GEORG-AUGUST-UNIVERSIT?T
Department of Medical Statistics
Humboldtallee 32
37073 G?ttingen
Mailing Address: 37099 G?ttingen, Germany
Fax: +49 (0) 551 39-4995
Tel: +49 (0) 551 39-4987
http://www.ams.med.uni-goettingen.de/service-de.shtml

From thierry@onkelinx @ending from inbo@be  Mon Nov 26 17:05:43 2018
From: thierry@onkelinx @ending from inbo@be (Thierry Onkelinx)
Date: Mon, 26 Nov 2018 17:05:43 +0100
Subject: [R-sig-ME] diverging results with and without random effects
In-Reply-To: <dc5492f4-f310-3957-3755-6613a82a53b9@med.uni-goettingen.de>
References: <b913cd50-ee7e-6419-0f87-98da32efd142@med.uni-goettingen.de>
 <841426ed-40d2-c9a7-b9c1-21507a1c0687@med.uni-goettingen.de>
 <CAJuCY5xA6_2oe51UJOkDFiKScsw8D_5uDRP=TDCgeGO5MKhPJg@mail.gmail.com>
 <dc5492f4-f310-3957-3755-6613a82a53b9@med.uni-goettingen.de>
Message-ID: <CAJuCY5x49n=V8tYzQZh=p5hKyqaHE-ZXMBO32D1bhwS9iz5uBQ@mail.gmail.com>

Dear Andreas,

You'll need a very informative prior for the random intercept variance in
order to keep the random intercepts reasonable small.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op ma 26 nov. 2018 om 17:00 schreef Leha, Andreas <
andreas.leha at med.uni-goettingen.de>:

> Dear Thierry,
>
> thanks for looking into this!
>
> So, one solution would be a baysian analysis, right?
>
> Would you have a recommendation for me?
>
> I followed [1] and used
>
>   library("blme")
>   dat %>%
>     bglmer(group ~ riskfactor + fu + riskfactor:fu + (1|patient),
>            family = "binomial",
>            data = .,
>            fixef.prior = normal(cov = diag(9,4))) %>%
>     summary
>
> Which runs and gives the following fixed effect estimates:
>
>
>   Fixed effects:
>                         Estimate Std. Error z value Pr(>|z|)
>   (Intercept)             8.2598     0.7445  11.094   <2e-16 ***
>   riskfactornorisk      -16.0942     1.3085 -12.300   <2e-16 ***
>   fuFU                    1.0019     1.0047   0.997    0.319
>   riskfactornorisk:fuFU  -1.8675     1.2365  -1.510    0.131
>
>
> These still do not seem reasonable.
>
> Thanks in advance!
>
> Regards,
> Andreas
>
>
> [1]
>
> https://stats.stackexchange.com/questions/132677/binomial-glmm-with-a-categorical-variable-with-full-successes/132678#132678
>
>
> On 26/11/18 16:36, Thierry Onkelinx wrote:
> > Dear Andreas,
> >
> > This is due to quasi complete separatation. This occurs when all
> > responses for a specific combination of levels are always TRUE or FALSE.
> > In your case, you have only two observations per patient. Hence adding
> > the patient as random effect, guarantees quasi complete separation
> issues.
> >
> > Best regards,
> >
> > ir. Thierry Onkelinx
> > Statisticus / Statistician
> >
> > Vlaamse Overheid / Government of Flanders
> > INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> > AND FOREST
> > Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> > thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>
> > Havenlaan 88 bus 73, 1000 Brussel
> > www.inbo.be <http://www.inbo.be>
> >
> >
> ///////////////////////////////////////////////////////////////////////////////////////////
> > To call in the statistician after the experiment is done may be no more
> > than asking him to perform a post-mortem examination: he may be able to
> > say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > The plural of anecdote is not data. ~ Roger Brinner
> > The combination of some data and an aching desire for an answer does not
> > ensure that a reasonable answer can be extracted from a given body of
> > data. ~ John Tukey
> >
> ///////////////////////////////////////////////////////////////////////////////////////////
> >
> > <https://www.inbo.be>
> >
> >
> > Op ma 26 nov. 2018 om 13:48 schreef Leha, Andreas
> > <andreas.leha at med.uni-goettingen.de
> > <mailto:andreas.leha at med.uni-goettingen.de>>:
> >
> >     Hi all,
> >
> >     sent the wrong code (w/o filtering for BL).  If you want to look at
> the
> >     data, please use this code:
> >
> >     ---------- cut here --------------------------------------------
> >     library("dplyr")
> >     library("lme4")
> >     library("lmerTest")
> >     ## install_github("hrbrmstr/pastebin", upgrade_dependencies = FALSE)
> >     library("pastebin")
> >
> >     ## ---------------------------------- ##
> >     ## load the data                      ##
> >     ## ---------------------------------- ##
> >     dat <- pastebin::get_paste("Xgwgtb7j") %>% as.character %>%
> gsub("\r\n",
> >     "", .) %>% parse(text = .) %>% eval
> >
> >
> >
> >     ## ---------------------------------- ##
> >     ## have a look                        ##
> >     ## ---------------------------------- ##
> >     dat
> >     ## ,----
> >     ## | # A tibble: 475 x 4
> >     ## |    patient group fu    riskfactor
> >     ## |    <fct>   <fct> <fct> <fct>
> >     ## |  1 p001    wt    BL    norisk
> >     ## |  2 p002    wt    BL    norisk
> >     ## |  3 p003    wt    BL    norisk
> >     ## |  4 p004    wt    BL    norisk
> >     ## |  5 p005    wt    BL    norisk
> >     ## |  6 p006    wt    BL    norisk
> >     ## |  7 p007    wt    BL    norisk
> >     ## |  8 p008    wt    BL    norisk
> >     ## |  9 p009    wt    BL    risk
> >     ## | 10 p010    wt    BL    norisk
> >     ## | # ... with 465 more rows
> >     ## `----
> >     dat %>% str
> >     ## ,----
> >     ## | Classes ?tbl_df?, ?tbl? and 'data.frame':  475 obs. of  4
> >     variables:
> >     ## |  $ patient   : Factor w/ 265 levels "p001","p002",..: 1 2 3 4 5
> 6 7
> >     8 9 10 ...
> >     ## |  $ group     : Factor w/ 2 levels "wt","mut": 1 1 1 1 1 1 1 1 1
> >     1 ...
> >     ## |  $ fu        : Factor w/ 2 levels "BL","FU": 1 1 1 1 1 1 1 1 1
> >     1 ...
> >     ## |  $ riskfactor: Factor w/ 2 levels "risk","norisk": 2 2 2 2 2 2
> 2 2
> >     1 2 ...
> >     ## `----
> >
> >     ## there are 265 patients
> >     ## in 2 groups: "wt" and "mut"
> >     ## with a dichotomous risk factor ("risk" and "norisk")
> >     ## measured at two time points ("BL" and "FU")
> >
> >     dat %>% summary
> >     ## ,----
> >     ## |     patient    group      fu       riskfactor
> >     ## |  p001   :  2   wt :209   BL:258   risk  :205
> >     ## |  p002   :  2   mut:266   FU:217   norisk:270
> >     ## |  p003   :  2
> >     ## |  p004   :  2
> >     ## |  p005   :  2
> >     ## |  p006   :  2
> >     ## |  (Other):463
> >     ## `----
> >
> >     ## group sizes seem fine
> >
> >
> >
> >     ## ---------------------------------------------- ##
> >     ## first, we look at the first time point, the BL ##
> >     ## ---------------------------------------------- ##
> >
> >     ## we build a cross table
> >     tab_bl <-
> >       dat %>%
> >       dplyr::filter(fu == "BL") %>%
> >       dplyr::select(group, riskfactor) %>%
> >       table
> >     tab_bl
> >     ## ,----
> >     ## |      riskfactor
> >     ## | group risk norisk
> >     ## |   wt    22     86
> >     ## |   mut   87     63
> >     ## `----
> >
> >     ## and we test using fisher:
> >     tab_bl %>% fisher.test
> >     ## ,----
> >     ## |    Fisher's Exact Test for Count Data
> >     ## |
> >     ## | data:  .
> >     ## | p-value = 1.18e-09
> >     ## | alternative hypothesis: true odds ratio is not equal to 1
> >     ## | 95 percent confidence interval:
> >     ## |  0.09986548 0.33817966
> >     ## | sample estimates:
> >     ## | odds ratio
> >     ## |  0.1865377
> >     ## `----
> >     log(0.187)
> >     ## ,----
> >     ## | [1] -1.676647
> >     ## `----
> >
> >     ## so, we get a highly significant association of the riskfactor
> >     ## and the group with an log(odds ratio) of -1.7
> >
> >     ## we get the same result using logistic regression:
> >     dat %>%
> >       filter(fu == "BL") %>%
> >       glm(group ~ riskfactor, family = "binomial", data = .) %>%
> >       summary
> >     ## ,----
> >     ## | Call:
> >     ## | glm(formula = group ~ riskfactor, family = "binomial", data = .)
> >     ## |
> >     ## | Deviance Residuals:
> >     ## |     Min       1Q   Median       3Q      Max
> >     ## | -1.7890  -1.0484   0.6715   0.6715   1.3121
> >     ## |
> >     ## | Coefficients:
> >     ## |                  Estimate Std. Error z value Pr(>|z|)
> >     ## | (Intercept)        1.3749     0.2386   5.761 8.35e-09 ***
> >     ## | riskfactornorisk  -1.6861     0.2906  -5.802 6.55e-09 ***
> >     ## | ---
> >     ## | Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >     ## |
> >     ## | (Dispersion parameter for binomial family taken to be 1)
> >     ## |
> >     ## |     Null deviance: 350.80  on 257  degrees of freedom
> >     ## | Residual deviance: 312.63  on 256  degrees of freedom
> >     ## | AIC: 316.63
> >     ## |
> >     ## | Number of Fisher Scoring iterations: 4
> >     ## `----
> >
> >
> >
> >     ## ------------------------------------------------- ##
> >     ## Now, we analyse both time points with interaction ##
> >     ## ------------------------------------------------- ##
> >
> >     dat %>%
> >       glmer(group ~ riskfactor + fu + riskfactor:fu + (1|patient),
> family =
> >     "binomial", data = .) %>%
> >       summary
> >     ## ,----
> >     ## | Generalized linear mixed model fit by maximum likelihood
> (Laplace
> >     ## |   Approximation) [glmerMod]
> >     ## |  Family: binomial  ( logit )
> >     ## | Formula: group ~ riskfactor + fu + riskfactor:fu + (1 | patient)
> >     ## |    Data: .
> >     ## |
> >     ## |      AIC      BIC   logLik deviance df.resid
> >     ## |    345.2    366.0   -167.6    335.2      470
> >     ## |
> >     ## | Scaled residuals:
> >     ## |       Min        1Q    Median        3Q       Max
> >     ## | -0.095863 -0.058669  0.002278  0.002866  0.007324
> >     ## |
> >     ## | Random effects:
> >     ## |  Groups  Name        Variance Std.Dev.
> >     ## |  patient (Intercept) 1849     43
> >     ## | Number of obs: 475, groups:  patient, 265
> >     ## |
> >     ## | Fixed effects:
> >     ## |                       Estimate Std. Error z value Pr(>|z|)
> >     ## | (Intercept)            11.6846     1.3736   8.507   <2e-16 ***
> >     ## | riskfactornorisk       -1.5919     1.4166  -1.124    0.261
> >     ## | fuFU                    0.4596     1.9165   0.240    0.810
> >     ## | riskfactornorisk:fuFU  -0.8183     2.1651  -0.378    0.705
> >     ## | ---
> >     ## | Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >     ## |
> >     ## | Correlation of Fixed Effects:
> >     ## |             (Intr) rskfct fuFU
> >     ## | rskfctrnrsk -0.746
> >     ## | fuFU        -0.513  0.510
> >     ## | rskfctrn:FU  0.478 -0.576 -0.908
> >     ## `----
> >
> >     ## I get huge variation in the random effects
> >     ##
> >     ## And the risk factor at BL gets an estimated log(odds ratio) of
> -1.6
> >     ## but one which is not significant
> >     ---------- cut here --------------------------------------------
> >
> >
> >     On 26/11/18 12:10, Leha, Andreas wrote:
> >     > Hi all,
> >     >
> >     > I am interested in assessing the association of a (potential) risk
> >     > factor to a (binary) grouping.
> >     >
> >     > I am having trouble with diverging results from modeling one time
> >     point
> >     > (without random effect) and modeling two time points (with random
> >     effect).
> >     >
> >     > When analysing the first time point (base line, BL) only, I get a
> >     highly
> >     > significant association.
> >     > Now, I want to see, whether there is an interaction between time
> and
> >     > risk factor (the risk factor is not constant).  But when analysing
> >     both
> >     > time points, the estimated effect at BL is estimated to be not
> >     significant.
> >     >
> >     > Now my simplified questions are:
> >     > (1) Is there an association at BL or not?
> >     > (2) How should I analyse both time points with this data?
> >     >
> >     > The aim is to look for confounding with other factors.  But I'd
> >     like to
> >     > understand the simple models before moving on.
> >     >
> >     > Below you find a reproducible example and the detailed results.
> >     >
> >     > Any suggestions would be highly appreciated!
> >     >
> >     > Regards,
> >     > Andreas
> >     >
> >     >
> >     >
> >     > PS: The code / results
> >     >
> >     > ---------- cut here --------------------------------------------
> >     > library("dplyr")
> >     > library("lme4")
> >     > library("lmerTest")
> >     > ## install_github("hrbrmstr/pastebin", upgrade_dependencies =
> FALSE)
> >     > library("pastebin")
> >     >
> >     > ## ---------------------------------- ##
> >     > ## load the data                      ##
> >     > ## ---------------------------------- ##
> >     > dat <- pastebin::get_paste("Xgwgtb7j") %>%
> >     >   as.character %>%
> >     >   gsub("\r\n", "", .) %>%
> >     >   parse(text = .) %>%
> >     >   eval
> >     >
> >     >
> >     >
> >     > ## ---------------------------------- ##
> >     > ## have a look                        ##
> >     > ## ---------------------------------- ##
> >     > dat
> >     > ## ,----
> >     > ## | # A tibble: 475 x 4
> >     > ## |    patient group fu    riskfactor
> >     > ## |    <fct>   <fct> <fct> <fct>
> >     > ## |  1 p001    wt    BL    norisk
> >     > ## |  2 p002    wt    BL    norisk
> >     > ## |  3 p003    wt    BL    norisk
> >     > ## |  4 p004    wt    BL    norisk
> >     > ## |  5 p005    wt    BL    norisk
> >     > ## |  6 p006    wt    BL    norisk
> >     > ## |  7 p007    wt    BL    norisk
> >     > ## |  8 p008    wt    BL    norisk
> >     > ## |  9 p009    wt    BL    risk
> >     > ## | 10 p010    wt    BL    norisk
> >     > ## | # ... with 465 more rows
> >     > ## `----
> >     > dat %>% str
> >     > ## ,----
> >     > ## | Classes ?tbl_df?, ?tbl? and 'data.frame':        475 obs. of
> >     4 variables:
> >     > ## |  $ patient   : Factor w/ 265 levels "p001","p002",..: 1 2 3 4
> >     5 6 7
> >     > 8 9 10 ...
> >     > ## |  $ group     : Factor w/ 2 levels "wt","mut": 1 1 1 1 1 1 1 1
> >     1 1 ...
> >     > ## |  $ fu        : Factor w/ 2 levels "BL","FU": 1 1 1 1 1 1 1 1
> >     1 1 ...
> >     > ## |  $ riskfactor: Factor w/ 2 levels "risk","norisk": 2 2 2 2 2
> >     2 2 2
> >     > 1 2 ...
> >     > ## `----
> >     >
> >     > ## there are 265 patients
> >     > ## in 2 groups: "wt" and "mut"
> >     > ## with a dichotomous risk factor ("risk" and "norisk")
> >     > ## measured at two time points ("BL" and "FU")
> >     >
> >     > dat %>% summary
> >     > ## ,----
> >     > ## |     patient    group      fu       riskfactor
> >     > ## |  p001   :  2   wt :209   BL:258   risk  :205
> >     > ## |  p002   :  2   mut:266   FU:217   norisk:270
> >     > ## |  p003   :  2
> >     > ## |  p004   :  2
> >     > ## |  p005   :  2
> >     > ## |  p006   :  2
> >     > ## |  (Other):463
> >     > ## `----
> >     >
> >     > ## group sizes seem fine
> >     >
> >     >
> >     >
> >     > ## ---------------------------------------------- ##
> >     > ## first, we look at the first time point, the BL ##
> >     > ## ---------------------------------------------- ##
> >     >
> >     > ## we build a cross table
> >     > tab_bl <-
> >     >   dat %>%
> >     >   dplyr::select(group, riskfactor) %>%
> >     >   table
> >     > tab_bl
> >     > ## ,----
> >     > ## |      riskfactor
> >     > ## | group risk norisk
> >     > ## |   wt    35    174
> >     > ## |   mut  170     96
> >     > ## `----
> >     >
> >     > ## and we test using fisher:
> >     > tab_bl %>% fisher.test
> >     > ## ,----
> >     > ## |    Fisher's Exact Test for Count Data
> >     > ## |
> >     > ## | data:  .
> >     > ## | p-value < 2.2e-16
> >     > ## | alternative hypothesis: true odds ratio is not equal to 1
> >     > ## | 95 percent confidence interval:
> >     > ## |  0.07099792 0.18002325
> >     > ## | sample estimates:
> >     > ## | odds ratio
> >     > ## |  0.1141677
> >     > ## `----
> >     > log(0.114)
> >     > ## ,----
> >     > ## | [1] -2.171557
> >     > ## `----
> >     >
> >     > ## so, we get a highly significant association of the riskfactor
> >     > ## and the group with an log(odds ratio) of -2.2
> >     >
> >     > ## we get the same result using logistic regression:
> >     > dat %>%
> >     >   glm(group ~ riskfactor, family = "binomial", data = .) %>%
> >     >   summary
> >     > ## ,----
> >     > ## |
> >     > ## | Call:
> >     > ## | glm(formula = group ~ riskfactor, family = "binomial", data =
> .)
> >     > ## |
> >     > ## | Deviance Residuals:
> >     > ## |     Min       1Q   Median       3Q      Max
> >     > ## | -1.8802  -0.9374   0.6119   0.6119   1.4381
> >     > ## |
> >     > ## | Coefficients:
> >     > ## |                  Estimate Std. Error z value Pr(>|z|)
> >     > ## | (Intercept)        1.5805     0.1856   8.515   <2e-16 ***
> >     > ## | riskfactornorisk  -2.1752     0.2250  -9.668   <2e-16 ***
> >     > ## | ---
> >     > ## | Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >     > ## |
> >     > ## | (Dispersion parameter for binomial family taken to be 1)
> >     > ## |
> >     > ## |     Null deviance: 651.63  on 474  degrees of freedom
> >     > ## | Residual deviance: 538.83  on 473  degrees of freedom
> >     > ## | AIC: 542.83
> >     > ## |
> >     > ## | Number of Fisher Scoring iterations: 4
> >     > ## `----
> >     >
> >     >
> >     >
> >     > ## ------------------------------------------------- ##
> >     > ## Now, we analyse both time points with interaction ##
> >     > ## ------------------------------------------------- ##
> >     >
> >     > dat %>%
> >     >   glmer(group ~ riskfactor + fu + riskfactor:fu + (1|patient),
> >     family =
> >     > "binomial", data = .) %>%
> >     >   summary
> >     > ## ,----
> >     > ## | Generalized linear mixed model fit by maximum likelihood
> (Laplace
> >     > ## |   Approximation) [glmerMod]
> >     > ## |  Family: binomial  ( logit )
> >     > ## | Formula: group ~ riskfactor + fu + riskfactor:fu + (1 |
> patient)
> >     > ## |    Data: .
> >     > ## |
> >     > ## |      AIC      BIC   logLik deviance df.resid
> >     > ## |    345.2    366.0   -167.6    335.2      470
> >     > ## |
> >     > ## | Scaled residuals:
> >     > ## |       Min        1Q    Median        3Q       Max
> >     > ## | -0.095863 -0.058669  0.002278  0.002866  0.007324
> >     > ## |
> >     > ## | Random effects:
> >     > ## |  Groups  Name        Variance Std.Dev.
> >     > ## |  patient (Intercept) 1849     43
> >     > ## | Number of obs: 475, groups:  patient, 265
> >     > ## |
> >     > ## | Fixed effects:
> >     > ## |                       Estimate Std. Error z value Pr(>|z|)
> >     > ## | (Intercept)            11.6846     1.3736   8.507   <2e-16 ***
> >     > ## | riskfactornorisk       -1.5919     1.4166  -1.124    0.261
> >     > ## | fuFU                    0.4596     1.9165   0.240    0.810
> >     > ## | riskfactornorisk:fuFU  -0.8183     2.1651  -0.378    0.705
> >     > ## | ---
> >     > ## | Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >     > ## |
> >     > ## | Correlation of Fixed Effects:
> >     > ## |             (Intr) rskfct fuFU
> >     > ## | rskfctrnrsk -0.746
> >     > ## | fuFU        -0.513  0.510
> >     > ## | rskfctrn:FU  0.478 -0.576 -0.908
> >     > ## `----
> >     >
> >     > ## I get huge variation in the random effects
> >     > ##
> >     > ## And the risk factor at BL gets an estimated log(odds ratio) of
> -1.6
> >     > ## but one which is not significant
> >     > ---------- cut here --------------------------------------------
> >     > _______________________________________________
> >     > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     >
> >
> >     --
> >     Dr. Andreas Leha
> >     Head of the 'Core Facility
> >     Medical Biometry and Statistical Bioinformatics'
> >
> >     UNIVERSITY MEDICAL CENTER G?TTINGEN
> >     GEORG-AUGUST-UNIVERSIT?T
> >     Department of Medical Statistics
> >     Humboldtallee 32
> >     37073 G?ttingen
> >     Mailing Address: 37099 G?ttingen, Germany
> >     Fax: +49 (0) 551 39-4995
> >     Tel: +49 (0) 551 39-4987
> >     http://www.ams.med.uni-goettingen.de/service-de.shtml
> >     _______________________________________________
> >     R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> --
> Dr. Andreas Leha
> Head of the 'Core Facility
> Medical Biometry and Statistical Bioinformatics'
>
> UNIVERSITY MEDICAL CENTER G?TTINGEN
> GEORG-AUGUST-UNIVERSIT?T
> Department of Medical Statistics
> Humboldtallee 32
> 37073 G?ttingen
> Mailing Address: 37099 G?ttingen, Germany
> Fax: +49 (0) 551 39-4995
> Tel: +49 (0) 551 39-4987
> http://www.ams.med.uni-goettingen.de/service-de.shtml

	[[alternative HTML version deleted]]


From @ndre@@@leh@ @ending from med@uni-goettingen@de  Sun Nov 25 05:23:33 2018
From: @ndre@@@leh@ @ending from med@uni-goettingen@de (Leha, Andreas)
Date: Sun, 25 Nov 2018 04:23:33 +0000
Subject: [R-sig-ME] diverging results with and without random effects
Message-ID: <e42fbaaf-6287-88e7-b589-4e3196e6b2e2@med.uni-goettingen.de>

Hi all,

I am interested in assessing the association of a (potential) risk
factor to a (binary) grouping.

I am having trouble with diverging results from modeling one time point
(without random effect) and modeling two time points (with random effect).

When analysing the first time point (base line, BL) only, I get a highly
significant association.
Now, I want to see, whether there is an interaction between time and
risk factor (the risk factor is not constant).  But when analysing both
time points, the estimated effect at BL is estimated to be not significant.

Now my simplified questions are:
(1) Is there an association at BL or not?
(2) How should I analyse both time points with this data?

The aim is to look for confounding with other factors.  But I'd like to
understand the simple models before moving on.

Below you find a reproducible example and the detailed results.

Any suggestions would be highly appreciated!

Regards,
Andreas



PS: The code / results

---------- cut here --------------------------------------------
library("dplyr")
library("lme4")
library("lmerTest")
## install_github("hrbrmstr/pastebin", upgrade_dependencies = FALSE)
library("pastebin")

## ---------------------------------- ##
## load the data                      ##
## ---------------------------------- ##
dat <- pastebin::get_paste("Xgwgtb7j") %>%
  as.character %>%
  gsub("\r\n", "", .) %>%
  parse(text = .) %>%
  eval



## ---------------------------------- ##
## have a look                        ##
## ---------------------------------- ##
dat
## ,----
## | # A tibble: 475 x 4
## |    patient group fu    riskfactor
## |    <fct>   <fct> <fct> <fct>
## |  1 p001    wt    BL    norisk
## |  2 p002    wt    BL    norisk
## |  3 p003    wt    BL    norisk
## |  4 p004    wt    BL    norisk
## |  5 p005    wt    BL    norisk
## |  6 p006    wt    BL    norisk
## |  7 p007    wt    BL    norisk
## |  8 p008    wt    BL    norisk
## |  9 p009    wt    BL    risk
## | 10 p010    wt    BL    norisk
## | # ... with 465 more rows
## `----
dat %>% str
## ,----
## | Classes ?tbl_df?, ?tbl? and 'data.frame':	475 obs. of  4 variables:
## |  $ patient   : Factor w/ 265 levels "p001","p002",..: 1 2 3 4 5 6 7
8 9 10 ...
## |  $ group     : Factor w/ 2 levels "wt","mut": 1 1 1 1 1 1 1 1 1 1 ...
## |  $ fu        : Factor w/ 2 levels "BL","FU": 1 1 1 1 1 1 1 1 1 1 ...
## |  $ riskfactor: Factor w/ 2 levels "risk","norisk": 2 2 2 2 2 2 2 2
1 2 ...
## `----

## there are 265 patients
## in 2 groups: "wt" and "mut"
## with a dichotomous risk factor ("risk" and "norisk")
## measured at two time points ("BL" and "FU")

dat %>% summary
## ,----
## |     patient    group      fu       riskfactor
## |  p001   :  2   wt :209   BL:258   risk  :205
## |  p002   :  2   mut:266   FU:217   norisk:270
## |  p003   :  2
## |  p004   :  2
## |  p005   :  2
## |  p006   :  2
## |  (Other):463
## `----

## group sizes seem fine



## ---------------------------------------------- ##
## first, we look at the first time point, the BL ##
## ---------------------------------------------- ##

## we build a cross table
tab_bl <-
  dat %>%
  dplyr::select(group, riskfactor) %>%
  table
tab_bl
## ,----
## |      riskfactor
## | group risk norisk
## |   wt    35    174
## |   mut  170     96
## `----

## and we test using fisher:
tab_bl %>% fisher.test
## ,----
## |    Fisher's Exact Test for Count Data
## |
## | data:  .
## | p-value < 2.2e-16
## | alternative hypothesis: true odds ratio is not equal to 1
## | 95 percent confidence interval:
## |  0.07099792 0.18002325
## | sample estimates:
## | odds ratio
## |  0.1141677
## `----
log(0.114)
## ,----
## | [1] -2.171557
## `----

## so, we get a highly significant association of the riskfactor
## and the group with an log(odds ratio) of -2.2

## we get the same result using logistic regression:
dat %>%
  glm(group ~ riskfactor, family = "binomial", data = .) %>%
  summary
## ,----
## |
## | Call:
## | glm(formula = group ~ riskfactor, family = "binomial", data = .)
## |
## | Deviance Residuals:
## |     Min       1Q   Median       3Q      Max
## | -1.8802  -0.9374   0.6119   0.6119   1.4381
## |
## | Coefficients:
## |                  Estimate Std. Error z value Pr(>|z|)
## | (Intercept)        1.5805     0.1856   8.515   <2e-16 ***
## | riskfactornorisk  -2.1752     0.2250  -9.668   <2e-16 ***
## | ---
## | Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
## |
## | (Dispersion parameter for binomial family taken to be 1)
## |
## |     Null deviance: 651.63  on 474  degrees of freedom
## | Residual deviance: 538.83  on 473  degrees of freedom
## | AIC: 542.83
## |
## | Number of Fisher Scoring iterations: 4
## `----



## ------------------------------------------------- ##
## Now, we analyse both time points with interaction ##
## ------------------------------------------------- ##

dat %>%
  glmer(group ~ riskfactor + fu + riskfactor:fu + (1|patient), family =
"binomial", data = .) %>%
  summary
## ,----
## | Generalized linear mixed model fit by maximum likelihood (Laplace
## |   Approximation) [glmerMod]
## |  Family: binomial  ( logit )
## | Formula: group ~ riskfactor + fu + riskfactor:fu + (1 | patient)
## |    Data: .
## |
## |      AIC      BIC   logLik deviance df.resid
## |    345.2    366.0   -167.6    335.2      470
## |
## | Scaled residuals:
## |       Min        1Q    Median        3Q       Max
## | -0.095863 -0.058669  0.002278  0.002866  0.007324
## |
## | Random effects:
## |  Groups  Name        Variance Std.Dev.
## |  patient (Intercept) 1849     43
## | Number of obs: 475, groups:  patient, 265
## |
## | Fixed effects:
## |                       Estimate Std. Error z value Pr(>|z|)
## | (Intercept)            11.6846     1.3736   8.507   <2e-16 ***
## | riskfactornorisk       -1.5919     1.4166  -1.124    0.261
## | fuFU                    0.4596     1.9165   0.240    0.810
## | riskfactornorisk:fuFU  -0.8183     2.1651  -0.378    0.705
## | ---
## | Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
## |
## | Correlation of Fixed Effects:
## |             (Intr) rskfct fuFU
## | rskfctrnrsk -0.746
## | fuFU        -0.513  0.510
## | rskfctrn:FU  0.478 -0.576 -0.908
## `----

## I get huge variation in the random effects
##
## And the risk factor at BL gets an estimated log(odds ratio) of -1.6
## but one which is not significant
---------- cut here --------------------------------------------

From @ndre@@@leh@ @ending from med@uni-goettingen@de  Tue Nov 27 05:30:55 2018
From: @ndre@@@leh@ @ending from med@uni-goettingen@de (Leha, Andreas)
Date: Tue, 27 Nov 2018 04:30:55 +0000
Subject: [R-sig-ME] diverging results with and without random effects
In-Reply-To: <CAJuCY5x49n=V8tYzQZh=p5hKyqaHE-ZXMBO32D1bhwS9iz5uBQ@mail.gmail.com>
References: <b913cd50-ee7e-6419-0f87-98da32efd142@med.uni-goettingen.de>
 <841426ed-40d2-c9a7-b9c1-21507a1c0687@med.uni-goettingen.de>
 <CAJuCY5xA6_2oe51UJOkDFiKScsw8D_5uDRP=TDCgeGO5MKhPJg@mail.gmail.com>
 <dc5492f4-f310-3957-3755-6613a82a53b9@med.uni-goettingen.de>
 <CAJuCY5x49n=V8tYzQZh=p5hKyqaHE-ZXMBO32D1bhwS9iz5uBQ@mail.gmail.com>
Message-ID: <d6c3e41b-3f92-2c06-15e4-3fb687687d96@med.uni-goettingen.de>

Dear Thierry and all,

Thanks for your continued help here.  I am not versed with Bayesian
analyses.

Below is the code I currently use.  The priors are basically due to
trial and error until I got expected/reasonable results.

Therefor I would be grateful for some comments on the
(in-)appropriateness of my (quite extreme) parameters.

As cov.prior I used
  invwishart(df = 50, scale = diag(0.5, 1))

Thanks in advance!

Regards,
Andreas


PS: The code/results


library("blme")
dat %>%
  bglmer(group ~ riskfactor + fu + riskfactor:fu + (1|patient),
         family = "binomial",
         data = .,
         cov.prior = invwishart(df = 50, scale = diag(0.5, 1)),
         fixef.prior = normal(cov = diag(9,4))) %>%
  summary
## ,----
## | Cov prior  : patient ~ invwishart(df = 50, scale = 0.5,
## |                  posterior.scale = cov, common.scale = TRUE)
## | Fixef prior: normal(sd = c(3, 3, ...), corr = c(0 ...),
## |                  common.scale = FALSE)
## | Prior dev  : 6.2087
## |
## | Generalized linear mixed model fit by maximum likelihood (Laplace
## |   Approximation) [bglmerMod]
## |  Family: binomial  ( logit )
## | Formula: group ~ riskfactor + fu + riskfactor:fu + (1 | patient)
## |    Data: .
## |
## |      AIC      BIC   logLik deviance df.resid
## |    540.0    560.8   -265.0    530.0      470
## |
## | Scaled residuals:
## |     Min      1Q  Median      3Q     Max
## | -2.4984 -0.8512  0.3979  0.5038  1.6228
## |
## | Random effects:
## |  Groups  Name        Variance Std.Dev.
## |  patient (Intercept) 0.009725 0.09862
## | Number of obs: 475, groups:  patient, 265
## |
## | Fixed effects:
## |                       Estimate Std. Error z value Pr(>|z|)
## | (Intercept)             1.3679     0.2355   5.810 6.26e-09 ***
## | riskfactornorisk       -1.6776     0.2868  -5.850 4.91e-09 ***
## | fuFU                    0.4718     0.3738   1.262   0.2069
## | riskfactornorisk:fuFU  -1.1375     0.4539  -2.506   0.0122 *
## | ---
## | Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
## |
## | Correlation of Fixed Effects:
## |             (Intr) rskfct fuFU
## | rskfctrnrsk -0.816
## | fuFU        -0.617  0.502
## | rskfctrn:FU  0.503 -0.618 -0.817
## `----




On 26/11/18 17:05, Thierry Onkelinx wrote:
> Dear Andreas,
> 
> You'll need a very informative prior for the random intercept variance
> in order to keep the random intercepts reasonable small.
> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Statisticus / Statistician
> 
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> AND FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be <http://www.inbo.be>
> 
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to
> say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of
> data. ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
> 
> <https://www.inbo.be>
> 
> 
> Op ma 26 nov. 2018 om 17:00 schreef Leha, Andreas
> <andreas.leha at med.uni-goettingen.de
> <mailto:andreas.leha at med.uni-goettingen.de>>:
> 
>     Dear Thierry,
> 
>     thanks for looking into this!
> 
>     So, one solution would be a baysian analysis, right?
> 
>     Would you have a recommendation for me?
> 
>     I followed [1] and used
> 
>     ? library("blme")
>     ? dat %>%
>     ? ? bglmer(group ~ riskfactor + fu + riskfactor:fu + (1|patient),
>     ? ? ? ? ? ?family = "binomial",
>     ? ? ? ? ? ?data = .,
>     ? ? ? ? ? ?fixef.prior = normal(cov = diag(9,4))) %>%
>     ? ? summary
> 
>     Which runs and gives the following fixed effect estimates:
> 
> 
>     ? Fixed effects:
>     ? ? ? ? ? ? ? ? ? ? ? ? Estimate Std. Error z value Pr(>|z|)
>     ? (Intercept)? ? ? ? ? ? ?8.2598? ? ?0.7445? 11.094? ?<2e-16 ***
>     ? riskfactornorisk? ? ? -16.0942? ? ?1.3085 -12.300? ?<2e-16 ***
>     ? fuFU? ? ? ? ? ? ? ? ? ? 1.0019? ? ?1.0047? ?0.997? ? 0.319
>     ? riskfactornorisk:fuFU? -1.8675? ? ?1.2365? -1.510? ? 0.131
> 
> 
>     These still do not seem reasonable.
> 
>     Thanks in advance!
> 
>     Regards,
>     Andreas
> 
> 
>     [1]
>     https://stats.stackexchange.com/questions/132677/binomial-glmm-with-a-categorical-variable-with-full-successes/132678#132678
> 
> 
>     On 26/11/18 16:36, Thierry Onkelinx wrote:
>     > Dear Andreas,
>     >
>     > This is due to quasi complete separatation. This occurs when all
>     > responses for a specific combination of levels are always TRUE or
>     FALSE.
>     > In your case, you have only two observations per patient. Hence adding
>     > the patient as random effect, guarantees quasi complete separation
>     issues.??
>     >
>     > Best regards,
>     >
>     > ir. Thierry Onkelinx
>     > Statisticus / Statistician
>     >
>     > Vlaamse Overheid / Government of Flanders
>     > INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>     > AND FOREST
>     > Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>     > thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>
>     <mailto:thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>>
>     > Havenlaan 88 bus 73, 1000 Brussel
>     > www.inbo.be <http://www.inbo.be> <http://www.inbo.be>
>     >
>     >
>     ///////////////////////////////////////////////////////////////////////////////////////////
>     > To call in the statistician after the experiment is done may be no
>     more
>     > than asking him to perform a post-mortem examination: he may be
>     able to
>     > say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>     > The plural of anecdote is not data. ~ Roger Brinner
>     > The combination of some data and an aching desire for an answer
>     does not
>     > ensure that a reasonable answer can be extracted from a given body of
>     > data. ~ John Tukey
>     >
>     ///////////////////////////////////////////////////////////////////////////////////////////
>     >
>     > <https://www.inbo.be>
>     >
>     >
>     > Op ma 26 nov. 2018 om 13:48 schreef Leha, Andreas
>     > <andreas.leha at med.uni-goettingen.de
>     <mailto:andreas.leha at med.uni-goettingen.de>
>     > <mailto:andreas.leha at med.uni-goettingen.de
>     <mailto:andreas.leha at med.uni-goettingen.de>>>:
>     >
>     >? ? ?Hi all,
>     >
>     >? ? ?sent the wrong code (w/o filtering for BL).? If you want to
>     look at the
>     >? ? ?data, please use this code:
>     >
>     >? ? ?---------- cut here --------------------------------------------
>     >? ? ?library("dplyr")
>     >? ? ?library("lme4")
>     >? ? ?library("lmerTest")
>     >? ? ?## install_github("hrbrmstr/pastebin", upgrade_dependencies =
>     FALSE)
>     >? ? ?library("pastebin")
>     >
>     >? ? ?## ---------------------------------- ##
>     >? ? ?## load the data? ? ? ? ? ? ? ? ? ? ? ##
>     >? ? ?## ---------------------------------- ##
>     >? ? ?dat <- pastebin::get_paste("Xgwgtb7j") %>% as.character %>%
>     gsub("\r\n",
>     >? ? ?"", .) %>% parse(text = .) %>% eval
>     >
>     >
>     >
>     >? ? ?## ---------------------------------- ##
>     >? ? ?## have a look? ? ? ? ? ? ? ? ? ? ? ? ##
>     >? ? ?## ---------------------------------- ##
>     >? ? ?dat
>     >? ? ?## ,----
>     >? ? ?## | # A tibble: 475 x 4
>     >? ? ?## |? ? patient group fu? ? riskfactor
>     >? ? ?## |? ? <fct>? ?<fct> <fct> <fct>
>     >? ? ?## |? 1 p001? ? wt? ? BL? ? norisk
>     >? ? ?## |? 2 p002? ? wt? ? BL? ? norisk
>     >? ? ?## |? 3 p003? ? wt? ? BL? ? norisk
>     >? ? ?## |? 4 p004? ? wt? ? BL? ? norisk
>     >? ? ?## |? 5 p005? ? wt? ? BL? ? norisk
>     >? ? ?## |? 6 p006? ? wt? ? BL? ? norisk
>     >? ? ?## |? 7 p007? ? wt? ? BL? ? norisk
>     >? ? ?## |? 8 p008? ? wt? ? BL? ? norisk
>     >? ? ?## |? 9 p009? ? wt? ? BL? ? risk
>     >? ? ?## | 10 p010? ? wt? ? BL? ? norisk
>     >? ? ?## | # ... with 465 more rows
>     >? ? ?## `----
>     >? ? ?dat %>% str
>     >? ? ?## ,----
>     >? ? ?## | Classes ?tbl_df?, ?tbl? and 'data.frame':? 475 obs. of? 4
>     >? ? ?variables:
>     >? ? ?## |? $ patient? ?: Factor w/ 265 levels "p001","p002",..: 1 2
>     3 4 5 6 7
>     >? ? ?8 9 10 ...
>     >? ? ?## |? $ group? ? ?: Factor w/ 2 levels "wt","mut": 1 1 1 1 1 1
>     1 1 1
>     >? ? ?1 ...
>     >? ? ?## |? $ fu? ? ? ? : Factor w/ 2 levels "BL","FU": 1 1 1 1 1 1
>     1 1 1
>     >? ? ?1 ...
>     >? ? ?## |? $ riskfactor: Factor w/ 2 levels "risk","norisk": 2 2 2
>     2 2 2 2 2
>     >? ? ?1 2 ...
>     >? ? ?## `----
>     >
>     >? ? ?## there are 265 patients
>     >? ? ?## in 2 groups: "wt" and "mut"
>     >? ? ?## with a dichotomous risk factor ("risk" and "norisk")
>     >? ? ?## measured at two time points ("BL" and "FU")
>     >
>     >? ? ?dat %>% summary
>     >? ? ?## ,----
>     >? ? ?## |? ? ?patient? ? group? ? ? fu? ? ? ?riskfactor
>     >? ? ?## |? p001? ?:? 2? ?wt :209? ?BL:258? ?risk? :205
>     >? ? ?## |? p002? ?:? 2? ?mut:266? ?FU:217? ?norisk:270
>     >? ? ?## |? p003? ?:? 2
>     >? ? ?## |? p004? ?:? 2
>     >? ? ?## |? p005? ?:? 2
>     >? ? ?## |? p006? ?:? 2
>     >? ? ?## |? (Other):463
>     >? ? ?## `----
>     >
>     >? ? ?## group sizes seem fine
>     >
>     >
>     >
>     >? ? ?## ---------------------------------------------- ##
>     >? ? ?## first, we look at the first time point, the BL ##
>     >? ? ?## ---------------------------------------------- ##
>     >
>     >? ? ?## we build a cross table
>     >? ? ?tab_bl <-
>     >? ? ?? dat %>%
>     >? ? ?? dplyr::filter(fu == "BL") %>%
>     >? ? ?? dplyr::select(group, riskfactor) %>%
>     >? ? ?? table
>     >? ? ?tab_bl
>     >? ? ?## ,----
>     >? ? ?## |? ? ? riskfactor
>     >? ? ?## | group risk norisk
>     >? ? ?## |? ?wt? ? 22? ? ?86
>     >? ? ?## |? ?mut? ?87? ? ?63
>     >? ? ?## `----
>     >
>     >? ? ?## and we test using fisher:
>     >? ? ?tab_bl %>% fisher.test
>     >? ? ?## ,----
>     >? ? ?## |? ? Fisher's Exact Test for Count Data
>     >? ? ?## |
>     >? ? ?## | data:? .
>     >? ? ?## | p-value = 1.18e-09
>     >? ? ?## | alternative hypothesis: true odds ratio is not equal to 1
>     >? ? ?## | 95 percent confidence interval:
>     >? ? ?## |? 0.09986548 0.33817966
>     >? ? ?## | sample estimates:
>     >? ? ?## | odds ratio
>     >? ? ?## |? 0.1865377
>     >? ? ?## `----
>     >? ? ?log(0.187)
>     >? ? ?## ,----
>     >? ? ?## | [1] -1.676647
>     >? ? ?## `----
>     >
>     >? ? ?## so, we get a highly significant association of the riskfactor
>     >? ? ?## and the group with an log(odds ratio) of -1.7
>     >
>     >? ? ?## we get the same result using logistic regression:
>     >? ? ?dat %>%
>     >? ? ?? filter(fu == "BL") %>%
>     >? ? ?? glm(group ~ riskfactor, family = "binomial", data = .) %>%
>     >? ? ?? summary
>     >? ? ?## ,----
>     >? ? ?## | Call:
>     >? ? ?## | glm(formula = group ~ riskfactor, family = "binomial",
>     data = .)
>     >? ? ?## |
>     >? ? ?## | Deviance Residuals:
>     >? ? ?## |? ? ?Min? ? ? ?1Q? ?Median? ? ? ?3Q? ? ? Max
>     >? ? ?## | -1.7890? -1.0484? ?0.6715? ?0.6715? ?1.3121
>     >? ? ?## |
>     >? ? ?## | Coefficients:
>     >? ? ?## |? ? ? ? ? ? ? ? ? Estimate Std. Error z value Pr(>|z|)
>     >? ? ?## | (Intercept)? ? ? ? 1.3749? ? ?0.2386? ?5.761 8.35e-09 ***
>     >? ? ?## | riskfactornorisk? -1.6861? ? ?0.2906? -5.802 6.55e-09 ***
>     >? ? ?## | ---
>     >? ? ?## | Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1
>     ? ? 1
>     >? ? ?## |
>     >? ? ?## | (Dispersion parameter for binomial family taken to be 1)
>     >? ? ?## |
>     >? ? ?## |? ? ?Null deviance: 350.80? on 257? degrees of freedom
>     >? ? ?## | Residual deviance: 312.63? on 256? degrees of freedom
>     >? ? ?## | AIC: 316.63
>     >? ? ?## |
>     >? ? ?## | Number of Fisher Scoring iterations: 4
>     >? ? ?## `----
>     >
>     >
>     >
>     >? ? ?## ------------------------------------------------- ##
>     >? ? ?## Now, we analyse both time points with interaction ##
>     >? ? ?## ------------------------------------------------- ##
>     >
>     >? ? ?dat %>%
>     >? ? ?? glmer(group ~ riskfactor + fu + riskfactor:fu + (1|patient),
>     family =
>     >? ? ?"binomial", data = .) %>%
>     >? ? ?? summary
>     >? ? ?## ,----
>     >? ? ?## | Generalized linear mixed model fit by maximum likelihood
>     (Laplace
>     >? ? ?## |? ?Approximation) [glmerMod]
>     >? ? ?## |? Family: binomial? ( logit )
>     >? ? ?## | Formula: group ~ riskfactor + fu + riskfactor:fu + (1 |
>     patient)
>     >? ? ?## |? ? Data: .
>     >? ? ?## |
>     >? ? ?## |? ? ? AIC? ? ? BIC? ?logLik deviance df.resid
>     >? ? ?## |? ? 345.2? ? 366.0? ?-167.6? ? 335.2? ? ? 470
>     >? ? ?## |
>     >? ? ?## | Scaled residuals:
>     >? ? ?## |? ? ? ?Min? ? ? ? 1Q? ? Median? ? ? ? 3Q? ? ? ?Max
>     >? ? ?## | -0.095863 -0.058669? 0.002278? 0.002866? 0.007324
>     >? ? ?## |
>     >? ? ?## | Random effects:
>     >? ? ?## |? Groups? Name? ? ? ? Variance Std.Dev.
>     >? ? ?## |? patient (Intercept) 1849? ? ?43
>     >? ? ?## | Number of obs: 475, groups:? patient, 265
>     >? ? ?## |
>     >? ? ?## | Fixed effects:
>     >? ? ?## |? ? ? ? ? ? ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
>     >? ? ?## | (Intercept)? ? ? ? ? ? 11.6846? ? ?1.3736? ?8.507?
>     ?<2e-16 ***
>     >? ? ?## | riskfactornorisk? ? ? ?-1.5919? ? ?1.4166? -1.124? ? 0.261
>     >? ? ?## | fuFU? ? ? ? ? ? ? ? ? ? 0.4596? ? ?1.9165? ?0.240? ? 0.810
>     >? ? ?## | riskfactornorisk:fuFU? -0.8183? ? ?2.1651? -0.378? ? 0.705
>     >? ? ?## | ---
>     >? ? ?## | Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1
>     ? ? 1
>     >? ? ?## |
>     >? ? ?## | Correlation of Fixed Effects:
>     >? ? ?## |? ? ? ? ? ? ?(Intr) rskfct fuFU
>     >? ? ?## | rskfctrnrsk -0.746
>     >? ? ?## | fuFU? ? ? ? -0.513? 0.510
>     >? ? ?## | rskfctrn:FU? 0.478 -0.576 -0.908
>     >? ? ?## `----
>     >
>     >? ? ?## I get huge variation in the random effects
>     >? ? ?##
>     >? ? ?## And the risk factor at BL gets an estimated log(odds ratio)
>     of -1.6
>     >? ? ?## but one which is not significant
>     >? ? ?---------- cut here --------------------------------------------
>     >
>     >
>     >? ? ?On 26/11/18 12:10, Leha, Andreas wrote:
>     >? ? ?> Hi all,
>     >? ? ?>
>     >? ? ?> I am interested in assessing the association of a
>     (potential) risk
>     >? ? ?> factor to a (binary) grouping.
>     >? ? ?>
>     >? ? ?> I am having trouble with diverging results from modeling one
>     time
>     >? ? ?point
>     >? ? ?> (without random effect) and modeling two time points (with
>     random
>     >? ? ?effect).
>     >? ? ?>
>     >? ? ?> When analysing the first time point (base line, BL) only, I
>     get a
>     >? ? ?highly
>     >? ? ?> significant association.
>     >? ? ?> Now, I want to see, whether there is an interaction between
>     time and
>     >? ? ?> risk factor (the risk factor is not constant).? But when
>     analysing
>     >? ? ?both
>     >? ? ?> time points, the estimated effect at BL is estimated to be not
>     >? ? ?significant.
>     >? ? ?>
>     >? ? ?> Now my simplified questions are:
>     >? ? ?> (1) Is there an association at BL or not?
>     >? ? ?> (2) How should I analyse both time points with this data?
>     >? ? ?>
>     >? ? ?> The aim is to look for confounding with other factors.? But I'd
>     >? ? ?like to
>     >? ? ?> understand the simple models before moving on.
>     >? ? ?>
>     >? ? ?> Below you find a reproducible example and the detailed results.
>     >? ? ?>
>     >? ? ?> Any suggestions would be highly appreciated!
>     >? ? ?>
>     >? ? ?> Regards,
>     >? ? ?> Andreas
>     >? ? ?>
>     >? ? ?>
>     >? ? ?>
>     >? ? ?> PS: The code / results
>     >? ? ?>
>     >? ? ?> ---------- cut here --------------------------------------------
>     >? ? ?> library("dplyr")
>     >? ? ?> library("lme4")
>     >? ? ?> library("lmerTest")
>     >? ? ?> ## install_github("hrbrmstr/pastebin", upgrade_dependencies
>     = FALSE)
>     >? ? ?> library("pastebin")
>     >? ? ?>
>     >? ? ?> ## ---------------------------------- ##
>     >? ? ?> ## load the data? ? ? ? ? ? ? ? ? ? ? ##
>     >? ? ?> ## ---------------------------------- ##
>     >? ? ?> dat <- pastebin::get_paste("Xgwgtb7j") %>%
>     >? ? ?>? ?as.character %>%
>     >? ? ?>? ?gsub("\r\n", "", .) %>%
>     >? ? ?>? ?parse(text = .) %>%
>     >? ? ?>? ?eval
>     >? ? ?>
>     >? ? ?>
>     >? ? ?>
>     >? ? ?> ## ---------------------------------- ##
>     >? ? ?> ## have a look? ? ? ? ? ? ? ? ? ? ? ? ##
>     >? ? ?> ## ---------------------------------- ##
>     >? ? ?> dat
>     >? ? ?> ## ,----
>     >? ? ?> ## | # A tibble: 475 x 4
>     >? ? ?> ## |? ? patient group fu? ? riskfactor
>     >? ? ?> ## |? ? <fct>? ?<fct> <fct> <fct>
>     >? ? ?> ## |? 1 p001? ? wt? ? BL? ? norisk
>     >? ? ?> ## |? 2 p002? ? wt? ? BL? ? norisk
>     >? ? ?> ## |? 3 p003? ? wt? ? BL? ? norisk
>     >? ? ?> ## |? 4 p004? ? wt? ? BL? ? norisk
>     >? ? ?> ## |? 5 p005? ? wt? ? BL? ? norisk
>     >? ? ?> ## |? 6 p006? ? wt? ? BL? ? norisk
>     >? ? ?> ## |? 7 p007? ? wt? ? BL? ? norisk
>     >? ? ?> ## |? 8 p008? ? wt? ? BL? ? norisk
>     >? ? ?> ## |? 9 p009? ? wt? ? BL? ? risk
>     >? ? ?> ## | 10 p010? ? wt? ? BL? ? norisk
>     >? ? ?> ## | # ... with 465 more rows
>     >? ? ?> ## `----
>     >? ? ?> dat %>% str
>     >? ? ?> ## ,----
>     >? ? ?> ## | Classes ?tbl_df?, ?tbl? and 'data.frame':? ? ? ? 475
>     obs. of?
>     >? ? ?4 variables:
>     >? ? ?> ## |? $ patient? ?: Factor w/ 265 levels "p001","p002",..: 1
>     2 3 4
>     >? ? ?5 6 7
>     >? ? ?> 8 9 10 ...
>     >? ? ?> ## |? $ group? ? ?: Factor w/ 2 levels "wt","mut": 1 1 1 1 1
>     1 1 1
>     >? ? ?1 1 ...
>     >? ? ?> ## |? $ fu? ? ? ? : Factor w/ 2 levels "BL","FU": 1 1 1 1 1
>     1 1 1
>     >? ? ?1 1 ...
>     >? ? ?> ## |? $ riskfactor: Factor w/ 2 levels "risk","norisk": 2 2
>     2 2 2
>     >? ? ?2 2 2
>     >? ? ?> 1 2 ...
>     >? ? ?> ## `----
>     >? ? ?>
>     >? ? ?> ## there are 265 patients
>     >? ? ?> ## in 2 groups: "wt" and "mut"
>     >? ? ?> ## with a dichotomous risk factor ("risk" and "norisk")
>     >? ? ?> ## measured at two time points ("BL" and "FU")
>     >? ? ?>
>     >? ? ?> dat %>% summary
>     >? ? ?> ## ,----
>     >? ? ?> ## |? ? ?patient? ? group? ? ? fu? ? ? ?riskfactor
>     >? ? ?> ## |? p001? ?:? 2? ?wt :209? ?BL:258? ?risk? :205
>     >? ? ?> ## |? p002? ?:? 2? ?mut:266? ?FU:217? ?norisk:270
>     >? ? ?> ## |? p003? ?:? 2
>     >? ? ?> ## |? p004? ?:? 2
>     >? ? ?> ## |? p005? ?:? 2
>     >? ? ?> ## |? p006? ?:? 2
>     >? ? ?> ## |? (Other):463
>     >? ? ?> ## `----
>     >? ? ?>
>     >? ? ?> ## group sizes seem fine
>     >? ? ?>
>     >? ? ?>
>     >? ? ?>
>     >? ? ?> ## ---------------------------------------------- ##
>     >? ? ?> ## first, we look at the first time point, the BL ##
>     >? ? ?> ## ---------------------------------------------- ##
>     >? ? ?>
>     >? ? ?> ## we build a cross table
>     >? ? ?> tab_bl <-
>     >? ? ?>? ?dat %>%
>     >? ? ?>? ?dplyr::select(group, riskfactor) %>%
>     >? ? ?>? ?table
>     >? ? ?> tab_bl
>     >? ? ?> ## ,----
>     >? ? ?> ## |? ? ? riskfactor
>     >? ? ?> ## | group risk norisk
>     >? ? ?> ## |? ?wt? ? 35? ? 174
>     >? ? ?> ## |? ?mut? 170? ? ?96
>     >? ? ?> ## `----
>     >? ? ?>
>     >? ? ?> ## and we test using fisher:
>     >? ? ?> tab_bl %>% fisher.test
>     >? ? ?> ## ,----
>     >? ? ?> ## |? ? Fisher's Exact Test for Count Data
>     >? ? ?> ## |
>     >? ? ?> ## | data:? .
>     >? ? ?> ## | p-value < 2.2e-16
>     >? ? ?> ## | alternative hypothesis: true odds ratio is not equal to 1
>     >? ? ?> ## | 95 percent confidence interval:
>     >? ? ?> ## |? 0.07099792 0.18002325
>     >? ? ?> ## | sample estimates:
>     >? ? ?> ## | odds ratio
>     >? ? ?> ## |? 0.1141677
>     >? ? ?> ## `----
>     >? ? ?> log(0.114)
>     >? ? ?> ## ,----
>     >? ? ?> ## | [1] -2.171557
>     >? ? ?> ## `----
>     >? ? ?>
>     >? ? ?> ## so, we get a highly significant association of the riskfactor
>     >? ? ?> ## and the group with an log(odds ratio) of -2.2
>     >? ? ?>
>     >? ? ?> ## we get the same result using logistic regression:
>     >? ? ?> dat %>%
>     >? ? ?>? ?glm(group ~ riskfactor, family = "binomial", data = .) %>%
>     >? ? ?>? ?summary
>     >? ? ?> ## ,----
>     >? ? ?> ## |
>     >? ? ?> ## | Call:
>     >? ? ?> ## | glm(formula = group ~ riskfactor, family = "binomial",
>     data = .)
>     >? ? ?> ## |
>     >? ? ?> ## | Deviance Residuals:
>     >? ? ?> ## |? ? ?Min? ? ? ?1Q? ?Median? ? ? ?3Q? ? ? Max
>     >? ? ?> ## | -1.8802? -0.9374? ?0.6119? ?0.6119? ?1.4381
>     >? ? ?> ## |
>     >? ? ?> ## | Coefficients:
>     >? ? ?> ## |? ? ? ? ? ? ? ? ? Estimate Std. Error z value Pr(>|z|)
>     >? ? ?> ## | (Intercept)? ? ? ? 1.5805? ? ?0.1856? ?8.515? ?<2e-16 ***
>     >? ? ?> ## | riskfactornorisk? -2.1752? ? ?0.2250? -9.668? ?<2e-16 ***
>     >? ? ?> ## | ---
>     >? ? ?> ## | Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.?
>     0.1 ? ? 1
>     >? ? ?> ## |
>     >? ? ?> ## | (Dispersion parameter for binomial family taken to be 1)
>     >? ? ?> ## |
>     >? ? ?> ## |? ? ?Null deviance: 651.63? on 474? degrees of freedom
>     >? ? ?> ## | Residual deviance: 538.83? on 473? degrees of freedom
>     >? ? ?> ## | AIC: 542.83
>     >? ? ?> ## |
>     >? ? ?> ## | Number of Fisher Scoring iterations: 4
>     >? ? ?> ## `----
>     >? ? ?>
>     >? ? ?>
>     >? ? ?>
>     >? ? ?> ## ------------------------------------------------- ##
>     >? ? ?> ## Now, we analyse both time points with interaction ##
>     >? ? ?> ## ------------------------------------------------- ##
>     >? ? ?>
>     >? ? ?> dat %>%
>     >? ? ?>? ?glmer(group ~ riskfactor + fu + riskfactor:fu + (1|patient),
>     >? ? ?family =
>     >? ? ?> "binomial", data = .) %>%
>     >? ? ?>? ?summary
>     >? ? ?> ## ,----
>     >? ? ?> ## | Generalized linear mixed model fit by maximum
>     likelihood (Laplace
>     >? ? ?> ## |? ?Approximation) [glmerMod]
>     >? ? ?> ## |? Family: binomial? ( logit )
>     >? ? ?> ## | Formula: group ~ riskfactor + fu + riskfactor:fu + (1 |
>     patient)
>     >? ? ?> ## |? ? Data: .
>     >? ? ?> ## |
>     >? ? ?> ## |? ? ? AIC? ? ? BIC? ?logLik deviance df.resid
>     >? ? ?> ## |? ? 345.2? ? 366.0? ?-167.6? ? 335.2? ? ? 470
>     >? ? ?> ## |
>     >? ? ?> ## | Scaled residuals:
>     >? ? ?> ## |? ? ? ?Min? ? ? ? 1Q? ? Median? ? ? ? 3Q? ? ? ?Max
>     >? ? ?> ## | -0.095863 -0.058669? 0.002278? 0.002866? 0.007324
>     >? ? ?> ## |
>     >? ? ?> ## | Random effects:
>     >? ? ?> ## |? Groups? Name? ? ? ? Variance Std.Dev.
>     >? ? ?> ## |? patient (Intercept) 1849? ? ?43
>     >? ? ?> ## | Number of obs: 475, groups:? patient, 265
>     >? ? ?> ## |
>     >? ? ?> ## | Fixed effects:
>     >? ? ?> ## |? ? ? ? ? ? ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
>     >? ? ?> ## | (Intercept)? ? ? ? ? ? 11.6846? ? ?1.3736? ?8.507?
>     ?<2e-16 ***
>     >? ? ?> ## | riskfactornorisk? ? ? ?-1.5919? ? ?1.4166? -1.124? ? 0.261
>     >? ? ?> ## | fuFU? ? ? ? ? ? ? ? ? ? 0.4596? ? ?1.9165? ?0.240? ? 0.810
>     >? ? ?> ## | riskfactornorisk:fuFU? -0.8183? ? ?2.1651? -0.378? ? 0.705
>     >? ? ?> ## | ---
>     >? ? ?> ## | Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.?
>     0.1 ? ? 1
>     >? ? ?> ## |
>     >? ? ?> ## | Correlation of Fixed Effects:
>     >? ? ?> ## |? ? ? ? ? ? ?(Intr) rskfct fuFU
>     >? ? ?> ## | rskfctrnrsk -0.746
>     >? ? ?> ## | fuFU? ? ? ? -0.513? 0.510
>     >? ? ?> ## | rskfctrn:FU? 0.478 -0.576 -0.908
>     >? ? ?> ## `----
>     >? ? ?>
>     >? ? ?> ## I get huge variation in the random effects
>     >? ? ?> ##
>     >? ? ?> ## And the risk factor at BL gets an estimated log(odds
>     ratio) of -1.6
>     >? ? ?> ## but one which is not significant
>     >? ? ?> ---------- cut here --------------------------------------------
>     >? ? ?> _______________________________________________
>     >? ? ?> R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>> mailing list
>     >? ? ?> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >? ? ?>
>     >
>     >? ? ?--
>     >? ? ?Dr. Andreas Leha
>     >? ? ?Head of the 'Core Facility
>     >? ? ?Medical Biometry and Statistical Bioinformatics'
>     >
>     >? ? ?UNIVERSITY MEDICAL CENTER G?TTINGEN
>     >? ? ?GEORG-AUGUST-UNIVERSIT?T
>     >? ? ?Department of Medical Statistics
>     >? ? ?Humboldtallee 32
>     >? ? ?37073 G?ttingen
>     >? ? ?Mailing Address: 37099 G?ttingen, Germany
>     >? ? ?Fax: +49 (0) 551 39-4995
>     >? ? ?Tel: +49 (0) 551 39-4987
>     >? ? ?http://www.ams.med.uni-goettingen.de/service-de.shtml
>     >? ? ?_______________________________________________
>     >? ? ?R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>> mailing list
>     >? ? ?https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >
> 
>     -- 
>     Dr. Andreas Leha
>     Head of the 'Core Facility
>     Medical Biometry and Statistical Bioinformatics'
> 
>     UNIVERSITY MEDICAL CENTER G?TTINGEN
>     GEORG-AUGUST-UNIVERSIT?T
>     Department of Medical Statistics
>     Humboldtallee 32
>     37073 G?ttingen
>     Mailing Address: 37099 G?ttingen, Germany
>     Fax: +49 (0) 551 39-4995
>     Tel: +49 (0) 551 39-4987
>     http://www.ams.med.uni-goettingen.de/service-de.shtml
> 

-- 
Dr. Andreas Leha
Head of the 'Core Facility
Medical Biometry and Statistical Bioinformatics'

UNIVERSITY MEDICAL CENTER G?TTINGEN
GEORG-AUGUST-UNIVERSIT?T
Department of Medical Statistics
Humboldtallee 32
37073 G?ttingen
Mailing Address: 37099 G?ttingen, Germany
Fax: +49 (0) 551 39-4995
Tel: +49 (0) 551 39-4987
http://www.ams.med.uni-goettingen.de/service-de.shtml

From @teph@ne@l@@@@lvy @ending from geve@@fr  Tue Nov 27 09:50:31 2018
From: @teph@ne@l@@@@lvy @ending from geve@@fr (LASSALVY Stephane)
Date: Tue, 27 Nov 2018 08:50:31 +0000
Subject: [R-sig-ME] Are BLUP from two different random factors independant ?
Message-ID: <PR0P264MB0539BE011557F5344B03777A93D00@PR0P264MB0539.FRAP264.PROD.OUTLOOK.COM>

Hello all,
I am encountering a question related to linear combination of the estimations of random effects with the Asreml-R package. I am considering the problem of getting the sum of two BLUP. I only want to make the sum of two random effects.

My team and I, we are modelling over the years and over networks field trials data. The number of years which we use for an analysis is usually 2 and the number of networks is 3.

The model which we use is :
Yield = intercept + year + network + year x network + year x network x trial + [[variety]] + [[variety x network]] + [[variety x year x network]] + [[variety x year x network x trial]] + [[error term ]]

Year, network, year x network are fixed effects. The terms between brackets [[ ]] are random terms so we can compute BLUP.

We get the estimation of random terms for single random terms with the summary.asreml command with the all = TRUE option.


  1.  Would you know a mean to compute the sum of two random terms estimations ? We are mostly interested in computing the sum of a BLUP "variety x network" and the related BLUPs for the "variety x year x network" term to get the estimation of the variety x network interaction for each year of trial. Computing the sum of the estimations is not so difficult, but I am not sure that we will be able to compute the standard error for such a sum. Therefore, if a function like predict is able to compute this sum, it would be a very good news for us.



  1.  In case I would have to do the calculation by myself, can I consider that, as  the random factors [[variety x network]]  and  [[variety x year x network]] are independent, for a given variety, BLUP(variety x network) and BLUP(variety x year x network) ?

Best regards,
Stephane

St?phane LASSALVY
GEVES La Valette
711, rue Jean-Fran?ois Breton
F-34090 Montpellier
T?l. +33 (0)4 67 04 35 81
Email : stephane.lassalvy at geves.fr<mailto:contact at geves.fr>


	[[alternative HTML version deleted]]


From thierry@onkelinx @ending from inbo@be  Tue Nov 27 09:59:21 2018
From: thierry@onkelinx @ending from inbo@be (Thierry Onkelinx)
Date: Tue, 27 Nov 2018 09:59:21 +0100
Subject: [R-sig-ME] 
 Are BLUP from two different random factors independant ?
In-Reply-To: <PR0P264MB0539BE011557F5344B03777A93D00@PR0P264MB0539.FRAP264.PROD.OUTLOOK.COM>
References: <PR0P264MB0539BE011557F5344B03777A93D00@PR0P264MB0539.FRAP264.PROD.OUTLOOK.COM>
Message-ID: <CAJuCY5zgXh01_ex-6eY1dLGzPDE6w6GUAESQ1CCujBgOp_sNCg@mail.gmail.com>

Dear Stephane,

Why not simply fit a model without  [[variety x network]]. Then IMHO [[variety
x year x network]] would be an estimate of sum you're interested in.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op di 27 nov. 2018 om 09:53 schreef LASSALVY Stephane <
stephane.lassalvy at geves.fr>:

> Hello all,
> I am encountering a question related to linear combination of the
> estimations of random effects with the Asreml-R package. I am considering
> the problem of getting the sum of two BLUP. I only want to make the sum of
> two random effects.
>
> My team and I, we are modelling over the years and over networks field
> trials data. The number of years which we use for an analysis is usually 2
> and the number of networks is 3.
>
> The model which we use is :
> Yield = intercept + year + network + year x network + year x network x
> trial + [[variety]] + [[variety x network]] + [[variety x year x network]]
> + [[variety x year x network x trial]] + [[error term ]]
>
> Year, network, year x network are fixed effects. The terms between
> brackets [[ ]] are random terms so we can compute BLUP.
>
> We get the estimation of random terms for single random terms with the
> summary.asreml command with the all = TRUE option.
>
>
>   1.  Would you know a mean to compute the sum of two random terms
> estimations ? We are mostly interested in computing the sum of a BLUP
> "variety x network" and the related BLUPs for the "variety x year x
> network" term to get the estimation of the variety x network interaction
> for each year of trial. Computing the sum of the estimations is not so
> difficult, but I am not sure that we will be able to compute the standard
> error for such a sum. Therefore, if a function like predict is able to
> compute this sum, it would be a very good news for us.
>
>
>
>   1.  In case I would have to do the calculation by myself, can I consider
> that, as  the random factors [[variety x network]]  and  [[variety x year x
> network]] are independent, for a given variety, BLUP(variety x network) and
> BLUP(variety x year x network) ?
>
> Best regards,
> Stephane
>
> St?phane LASSALVY
> GEVES La Valette
> 711, rue Jean-Fran?ois Breton
> F-34090 Montpellier
> T?l. +33 (0)4 67 04 35 81
> Email : stephane.lassalvy at geves.fr<mailto:contact at geves.fr>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From @teph@ne@l@@@@lvy @ending from geve@@fr  Tue Nov 27 11:08:58 2018
From: @teph@ne@l@@@@lvy @ending from geve@@fr (LASSALVY Stephane)
Date: Tue, 27 Nov 2018 10:08:58 +0000
Subject: [R-sig-ME] 
 Are BLUP from two different random factors independant ?
In-Reply-To: <PR0P264MB05396326162BFF3241A5E59E93D00@PR0P264MB0539.FRAP264.PROD.OUTLOOK.COM>
References: <PR0P264MB0539BE011557F5344B03777A93D00@PR0P264MB0539.FRAP264.PROD.OUTLOOK.COM>
 <CAJuCY5zgXh01_ex-6eY1dLGzPDE6w6GUAESQ1CCujBgOp_sNCg@mail.gmail.com>
 <PR0P264MB05396326162BFF3241A5E59E93D00@PR0P264MB0539.FRAP264.PROD.OUTLOOK.COM>
Message-ID: <PR0P264MB053980DD2A1D9E25EF8597B193D00@PR0P264MB0539.FRAP264.PROD.OUTLOOK.COM>

Dear Thierry,
Yes you are right. I think it would be a way of doing it.

Best regards,
Stephane

De?: Thierry Onkelinx <mailto:thierry.onkelinx at inbo.be> 
Envoy??: mardi 27 novembre 2018 09:59
??: LASSALVY Stephane <mailto:stephane.lassalvy at geves.fr>
Cc?: r-sig-mixed-models <mailto:r-sig-mixed-models at r-project.org>
Objet?: Re: [R-sig-ME] Are BLUP from two different random factors independant ?

Dear Stephane,

Why not simply fit a model without??[[variety x network]]. Then IMHO?[[variety x year x network]] would be an estimate of sum you're interested in.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance 
mailto:thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
http://www.inbo.be
///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

https://www.inbo.be/


Op di 27 nov. 2018 om 09:53 schreef LASSALVY Stephane <mailto:stephane.lassalvy at geves.fr>:
Hello all,
I am encountering a question related to linear combination of the estimations of random effects with the Asreml-R package. I am considering the problem of getting the sum of two BLUP. I only want to make the sum of two random effects.

My team and I, we are modelling over the years and over networks field trials data. The number of years which we use for an analysis is usually 2 and the number of networks is 3.

The model which we use is :
Yield = intercept + year + network + year x network + year x network x trial + [[variety]] + [[variety x network]] + [[variety x year x network]] + [[variety x year x network x trial]] + [[error term ]]

Year, network, year x network are fixed effects. The terms between brackets [[ ]] are random terms so we can compute BLUP.

We get the estimation of random terms for single random terms with the summary.asreml command with the all = TRUE option.


? 1.? Would you know a mean to compute the sum of two random terms estimations ? We are mostly interested in computing the sum of a BLUP "variety x network" and the related BLUPs for the "variety x year x network" term to get the estimation of the variety x network interaction for each year of trial. Computing the sum of the estimations is not so difficult, but I am not sure that we will be able to compute the standard error for such a sum. Therefore, if a function like predict is able to compute this sum, it would be a very good news for us.



? 1.? In case I would have to do the calculation by myself, can I consider that, as? the random factors [[variety x network]]? and? [[variety x year x network]] are independent, for a given variety, BLUP(variety x network) and BLUP(variety x year x network) ?

Best regards,
Stephane

St?phane LASSALVY
GEVES La Valette
711, rue Jean-Fran?ois Breton
F-34090 Montpellier
T?l. +33 (0)4 67 04 35 81
Email : mailto:stephane.lassalvy at geves.fr<mailto:mailto:contact at geves.fr>


? ? ? ? [[alternative HTML version deleted]]

_______________________________________________
mailto:R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From d@e@kornbrot @ending from hert@@@c@uk  Tue Nov 27 12:26:37 2018
From: d@e@kornbrot @ending from hert@@@c@uk (Kornbrot, Diana)
Date: Tue, 27 Nov 2018 11:26:37 +0000
Subject: [R-sig-ME] Print Bayes Factor and posterior odds
In-Reply-To: <mailman.17108.8764.1543293072.1179.r-sig-mixed-models@r-project.org>
References: <mailman.17108.8764.1543293072.1179.r-sig-mixed-models@r-project.org>
Message-ID: <299AA4DB-0D8E-4662-95CC-78DCBBFCAC24@herts.ac.uk>

Print Bayes Factor and posterior odds
Have successfully performed bglmer and obtained asme F table as
glmer
bf<- glmer(cbind(freq, Nmax-freq) ~ b1*b2*w1*w2 +(w1|pno)+(w2|pno), data= s4,family=binomial(link=probit))
did not include prior statements, so assume it will do default Wishart

How does one obtain Bayes factors and posterior odds from the object bf created by this script?

bf<- glmer(cbind(freq, Nmax-freq) ~ b1*b2*w1*w2 +(w1|pno)+(w2|pno), data= s4,family=binomial(link=probit)
All help gratefully received
best
Diana

On 27 Nov 2018, at 04:31, r-sig-mixed-models-request at r-project.org<mailto:r-sig-mixed-models-request at r-project.org> wrote:

Send R-sig-mixed-models mailing list submissions to
r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>

To subscribe or unsubscribe via the World Wide Web, visit
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
or, via email, send a message with subject or body 'help' to
r-sig-mixed-models-request at r-project.org

You can reach the person managing the list at
r-sig-mixed-models-owner at r-project.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-mixed-models digest..."


Today's Topics:

  1. Re: diverging results with and without random effects
     (Leha, Andreas)

----------------------------------------------------------------------

Message: 1
Date: Tue, 27 Nov 2018 04:30:55 +0000
From: "Leha, Andreas" <andreas.leha at med.uni-goettingen.de>
To: Thierry Onkelinx <thierry.onkelinx at inbo.be>
Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] diverging results with and without random
effects
Message-ID:
<d6c3e41b-3f92-2c06-15e4-3fb687687d96 at med.uni-goettingen.de>
Content-Type: text/plain; charset="utf-8"

Dear Thierry and all,

Thanks for your continued help here.  I am not versed with Bayesian
analyses.

Below is the code I currently use.  The priors are basically due to
trial and error until I got expected/reasonable results.

Therefor I would be grateful for some comments on the
(in-)appropriateness of my (quite extreme) parameters.

As cov.prior I used
 invwishart(df = 50, scale = diag(0.5, 1))

Thanks in advance!

Regards,
Andreas


PS: The code/results


library("blme")
dat %>%
 bglmer(group ~ riskfactor + fu + riskfactor:fu + (1|patient),
        family = "binomial",
        data = .,
        cov.prior = invwishart(df = 50, scale = diag(0.5, 1)),
        fixef.prior = normal(cov = diag(9,4))) %>%
 summary
## ,----
## | Cov prior  : patient ~ invwishart(df = 50, scale = 0.5,
## |                  posterior.scale = cov, common.scale = TRUE)
## | Fixef prior: normal(sd = c(3, 3, ...), corr = c(0 ...),
## |                  common.scale = FALSE)
## | Prior dev  : 6.2087
## |
## | Generalized linear mixed model fit by maximum likelihood (Laplace
## |   Approximation) [bglmerMod]
## |  Family: binomial  ( logit )
## | Formula: group ~ riskfactor + fu + riskfactor:fu + (1 | patient)
## |    Data: .
## |
## |      AIC      BIC   logLik deviance df.resid
## |    540.0    560.8   -265.0    530.0      470
## |
## | Scaled residuals:
## |     Min      1Q  Median      3Q     Max
## | -2.4984 -0.8512  0.3979  0.5038  1.6228
## |
## | Random effects:
## |  Groups  Name        Variance Std.Dev.
## |  patient (Intercept) 0.009725 0.09862
## | Number of obs: 475, groups:  patient, 265
## |
## | Fixed effects:
## |                       Estimate Std. Error z value Pr(>|z|)
## | (Intercept)             1.3679     0.2355   5.810 6.26e-09 ***
## | riskfactornorisk       -1.6776     0.2868  -5.850 4.91e-09 ***
## | fuFU                    0.4718     0.3738   1.262   0.2069
## | riskfactornorisk:fuFU  -1.1375     0.4539  -2.506   0.0122 *
## | ---
## | Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
## |
## | Correlation of Fixed Effects:
## |             (Intr) rskfct fuFU
## | rskfctrnrsk -0.816
## | fuFU        -0.617  0.502
## | rskfctrn:FU  0.503 -0.618 -0.817
## `----




On 26/11/18 17:05, Thierry Onkelinx wrote:
Dear Andreas,

You'll need a very informative prior for the random intercept variance
in order to keep the random intercepts reasonable small.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be <http://www.inbo.be>

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op ma 26 nov. 2018 om 17:00 schreef Leha, Andreas
<andreas.leha at med.uni-goettingen.de
<mailto:andreas.leha at med.uni-goettingen.de>>:

   Dear Thierry,

   thanks for looking into this!

   So, one solution would be a baysian analysis, right?

   Would you have a recommendation for me?

   I followed [1] and used

     library("blme")
     dat %>%
       bglmer(group ~ riskfactor + fu + riskfactor:fu + (1|patient),
              family = "binomial",
              data = .,
              fixef.prior = normal(cov = diag(9,4))) %>%
       summary

   Which runs and gives the following fixed effect estimates:


     Fixed effects:
                           Estimate Std. Error z value Pr(>|z|)
     (Intercept)             8.2598     0.7445  11.094   <2e-16 ***
     riskfactornorisk      -16.0942     1.3085 -12.300   <2e-16 ***
     fuFU                    1.0019     1.0047   0.997    0.319
     riskfactornorisk:fuFU  -1.8675     1.2365  -1.510    0.131


   These still do not seem reasonable.

   Thanks in advance!

   Regards,
   Andreas


   [1]
   https://stats.stackexchange.com/questions/132677/binomial-glmm-with-a-categorical-variable-with-full-successes/132678#132678


   On 26/11/18 16:36, Thierry Onkelinx wrote:
Dear Andreas,

This is due to quasi complete separatation. This occurs when all
responses for a specific combination of levels are always TRUE or
   FALSE.
In your case, you have only two observations per patient. Hence adding
the patient as random effect, guarantees quasi complete separation
   issues.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>
   <mailto:thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>>
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be <http://www.inbo.be> <http://www.inbo.be>


   ///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
   more
than asking him to perform a post-mortem examination: he may be
   able to
say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer
   does not
ensure that a reasonable answer can be extracted from a given body of
data. ~ John Tukey

   ///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op ma 26 nov. 2018 om 13:48 schreef Leha, Andreas
<andreas.leha at med.uni-goettingen.de
   <mailto:andreas.leha at med.uni-goettingen.de>
<mailto:andreas.leha at med.uni-goettingen.de
   <mailto:andreas.leha at med.uni-goettingen.de>>>:

     Hi all,

     sent the wrong code (w/o filtering for BL).  If you want to
   look at the
     data, please use this code:

     ---------- cut here --------------------------------------------
     library("dplyr")
     library("lme4")
     library("lmerTest")
     ## install_github("hrbrmstr/pastebin", upgrade_dependencies =
   FALSE)
     library("pastebin")

     ## ---------------------------------- ##
     ## load the data                      ##
     ## ---------------------------------- ##
     dat <- pastebin::get_paste("Xgwgtb7j") %>% as.character %>%
   gsub("\r\n",
     "", .) %>% parse(text = .) %>% eval



     ## ---------------------------------- ##
     ## have a look                        ##
     ## ---------------------------------- ##
     dat
     ## ,----
     ## | # A tibble: 475 x 4
     ## |    patient group fu    riskfactor
     ## |    <fct>   <fct> <fct> <fct>
     ## |  1 p001    wt    BL    norisk
     ## |  2 p002    wt    BL    norisk
     ## |  3 p003    wt    BL    norisk
     ## |  4 p004    wt    BL    norisk
     ## |  5 p005    wt    BL    norisk
     ## |  6 p006    wt    BL    norisk
     ## |  7 p007    wt    BL    norisk
     ## |  8 p008    wt    BL    norisk
     ## |  9 p009    wt    BL    risk
     ## | 10 p010    wt    BL    norisk
     ## | # ... with 465 more rows
     ## `----
     dat %>% str
     ## ,----
     ## | Classes ?tbl_df?, ?tbl? and 'data.frame':  475 obs. of  4
     variables:
     ## |  $ patient   : Factor w/ 265 levels "p001","p002",..: 1 2
   3 4 5 6 7
     8 9 10 ...
     ## |  $ group     : Factor w/ 2 levels "wt","mut": 1 1 1 1 1 1
   1 1 1
     1 ...
     ## |  $ fu        : Factor w/ 2 levels "BL","FU": 1 1 1 1 1 1
   1 1 1
     1 ...
     ## |  $ riskfactor: Factor w/ 2 levels "risk","norisk": 2 2 2
   2 2 2 2 2
     1 2 ...
     ## `----

     ## there are 265 patients
     ## in 2 groups: "wt" and "mut"
     ## with a dichotomous risk factor ("risk" and "norisk")
     ## measured at two time points ("BL" and "FU")

     dat %>% summary
     ## ,----
     ## |     patient    group      fu       riskfactor
     ## |  p001   :  2   wt :209   BL:258   risk  :205
     ## |  p002   :  2   mut:266   FU:217   norisk:270
     ## |  p003   :  2
     ## |  p004   :  2
     ## |  p005   :  2
     ## |  p006   :  2
     ## |  (Other):463
     ## `----

     ## group sizes seem fine



     ## ---------------------------------------------- ##
     ## first, we look at the first time point, the BL ##
     ## ---------------------------------------------- ##

     ## we build a cross table
     tab_bl <-
       dat %>%
       dplyr::filter(fu == "BL") %>%
       dplyr::select(group, riskfactor) %>%
       table
     tab_bl
     ## ,----
     ## |      riskfactor
     ## | group risk norisk
     ## |   wt    22     86
     ## |   mut   87     63
     ## `----

     ## and we test using fisher:
     tab_bl %>% fisher.test
     ## ,----
     ## |    Fisher's Exact Test for Count Data
     ## |
     ## | data:  .
     ## | p-value = 1.18e-09
     ## | alternative hypothesis: true odds ratio is not equal to 1
     ## | 95 percent confidence interval:
     ## |  0.09986548 0.33817966
     ## | sample estimates:
     ## | odds ratio
     ## |  0.1865377
     ## `----
     log(0.187)
     ## ,----
     ## | [1] -1.676647
     ## `----

     ## so, we get a highly significant association of the riskfactor
     ## and the group with an log(odds ratio) of -1.7

     ## we get the same result using logistic regression:
     dat %>%
       filter(fu == "BL") %>%
       glm(group ~ riskfactor, family = "binomial", data = .) %>%
       summary
     ## ,----
     ## | Call:
     ## | glm(formula = group ~ riskfactor, family = "binomial",
   data = .)
     ## |
     ## | Deviance Residuals:
     ## |     Min       1Q   Median       3Q      Max
     ## | -1.7890  -1.0484   0.6715   0.6715   1.3121
     ## |
     ## | Coefficients:
     ## |                  Estimate Std. Error z value Pr(>|z|)
     ## | (Intercept)        1.3749     0.2386   5.761 8.35e-09 ***
     ## | riskfactornorisk  -1.6861     0.2906  -5.802 6.55e-09 ***
     ## | ---
     ## | Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1
   ? ? 1
     ## |
     ## | (Dispersion parameter for binomial family taken to be 1)
     ## |
     ## |     Null deviance: 350.80  on 257  degrees of freedom
     ## | Residual deviance: 312.63  on 256  degrees of freedom
     ## | AIC: 316.63
     ## |
     ## | Number of Fisher Scoring iterations: 4
     ## `----



     ## ------------------------------------------------- ##
     ## Now, we analyse both time points with interaction ##
     ## ------------------------------------------------- ##

     dat %>%
       glmer(group ~ riskfactor + fu + riskfactor:fu + (1|patient),
   family =
     "binomial", data = .) %>%
       summary
     ## ,----
     ## | Generalized linear mixed model fit by maximum likelihood
   (Laplace
     ## |   Approximation) [glmerMod]
     ## |  Family: binomial  ( logit )
     ## | Formula: group ~ riskfactor + fu + riskfactor:fu + (1 |
   patient)
     ## |    Data: .
     ## |
     ## |      AIC      BIC   logLik deviance df.resid
     ## |    345.2    366.0   -167.6    335.2      470
     ## |
     ## | Scaled residuals:
     ## |       Min        1Q    Median        3Q       Max
     ## | -0.095863 -0.058669  0.002278  0.002866  0.007324
     ## |
     ## | Random effects:
     ## |  Groups  Name        Variance Std.Dev.
     ## |  patient (Intercept) 1849     43
     ## | Number of obs: 475, groups:  patient, 265
     ## |
     ## | Fixed effects:
     ## |                       Estimate Std. Error z value Pr(>|z|)
     ## | (Intercept)            11.6846     1.3736   8.507
    <2e-16 ***
     ## | riskfactornorisk       -1.5919     1.4166  -1.124    0.261
     ## | fuFU                    0.4596     1.9165   0.240    0.810
     ## | riskfactornorisk:fuFU  -0.8183     2.1651  -0.378    0.705
     ## | ---
     ## | Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1
   ? ? 1
     ## |
     ## | Correlation of Fixed Effects:
     ## |             (Intr) rskfct fuFU
     ## | rskfctrnrsk -0.746
     ## | fuFU        -0.513  0.510
     ## | rskfctrn:FU  0.478 -0.576 -0.908
     ## `----

     ## I get huge variation in the random effects
     ##
     ## And the risk factor at BL gets an estimated log(odds ratio)
   of -1.6
     ## but one which is not significant
     ---------- cut here --------------------------------------------


     On 26/11/18 12:10, Leha, Andreas wrote:
     > Hi all,
     >
     > I am interested in assessing the association of a
   (potential) risk
     > factor to a (binary) grouping.
     >
     > I am having trouble with diverging results from modeling one
   time
     point
     > (without random effect) and modeling two time points (with
   random
     effect).
     >
     > When analysing the first time point (base line, BL) only, I
   get a
     highly
     > significant association.
     > Now, I want to see, whether there is an interaction between
   time and
     > risk factor (the risk factor is not constant).  But when
   analysing
     both
     > time points, the estimated effect at BL is estimated to be not
     significant.
     >
     > Now my simplified questions are:
     > (1) Is there an association at BL or not?
     > (2) How should I analyse both time points with this data?
     >
     > The aim is to look for confounding with other factors.  But I'd
     like to
     > understand the simple models before moving on.
     >
     > Below you find a reproducible example and the detailed results.
     >
     > Any suggestions would be highly appreciated!
     >
     > Regards,
     > Andreas
     >
     >
     >
     > PS: The code / results
     >
     > ---------- cut here --------------------------------------------
     > library("dplyr")
     > library("lme4")
     > library("lmerTest")
     > ## install_github("hrbrmstr/pastebin", upgrade_dependencies
   = FALSE)
     > library("pastebin")
     >
     > ## ---------------------------------- ##
     > ## load the data                      ##
     > ## ---------------------------------- ##
     > dat <- pastebin::get_paste("Xgwgtb7j") %>%
     >   as.character %>%
     >   gsub("\r\n", "", .) %>%
     >   parse(text = .) %>%
     >   eval
     >
     >
     >
     > ## ---------------------------------- ##
     > ## have a look                        ##
     > ## ---------------------------------- ##
     > dat
     > ## ,----
     > ## | # A tibble: 475 x 4
     > ## |    patient group fu    riskfactor
     > ## |    <fct>   <fct> <fct> <fct>
     > ## |  1 p001    wt    BL    norisk
     > ## |  2 p002    wt    BL    norisk
     > ## |  3 p003    wt    BL    norisk
     > ## |  4 p004    wt    BL    norisk
     > ## |  5 p005    wt    BL    norisk
     > ## |  6 p006    wt    BL    norisk
     > ## |  7 p007    wt    BL    norisk
     > ## |  8 p008    wt    BL    norisk
     > ## |  9 p009    wt    BL    risk
     > ## | 10 p010    wt    BL    norisk
     > ## | # ... with 465 more rows
     > ## `----
     > dat %>% str
     > ## ,----
     > ## | Classes ?tbl_df?, ?tbl? and 'data.frame':        475
   obs. of
     4 variables:
     > ## |  $ patient   : Factor w/ 265 levels "p001","p002",..: 1
   2 3 4
     5 6 7
     > 8 9 10 ...
     > ## |  $ group     : Factor w/ 2 levels "wt","mut": 1 1 1 1 1
   1 1 1
     1 1 ...
     > ## |  $ fu        : Factor w/ 2 levels "BL","FU": 1 1 1 1 1
   1 1 1
     1 1 ...
     > ## |  $ riskfactor: Factor w/ 2 levels "risk","norisk": 2 2
   2 2 2
     2 2 2
     > 1 2 ...
     > ## `----
     >
     > ## there are 265 patients
     > ## in 2 groups: "wt" and "mut"
     > ## with a dichotomous risk factor ("risk" and "norisk")
     > ## measured at two time points ("BL" and "FU")
     >
     > dat %>% summary
     > ## ,----
     > ## |     patient    group      fu       riskfactor
     > ## |  p001   :  2   wt :209   BL:258   risk  :205
     > ## |  p002   :  2   mut:266   FU:217   norisk:270
     > ## |  p003   :  2
     > ## |  p004   :  2
     > ## |  p005   :  2
     > ## |  p006   :  2
     > ## |  (Other):463
     > ## `----
     >
     > ## group sizes seem fine
     >
     >
     >
     > ## ---------------------------------------------- ##
     > ## first, we look at the first time point, the BL ##
     > ## ---------------------------------------------- ##
     >
     > ## we build a cross table
     > tab_bl <-
     >   dat %>%
     >   dplyr::select(group, riskfactor) %>%
     >   table
     > tab_bl
     > ## ,----
     > ## |      riskfactor
     > ## | group risk norisk
     > ## |   wt    35    174
     > ## |   mut  170     96
     > ## `----
     >
     > ## and we test using fisher:
     > tab_bl %>% fisher.test
     > ## ,----
     > ## |    Fisher's Exact Test for Count Data
     > ## |
     > ## | data:  .
     > ## | p-value < 2.2e-16
     > ## | alternative hypothesis: true odds ratio is not equal to 1
     > ## | 95 percent confidence interval:
     > ## |  0.07099792 0.18002325
     > ## | sample estimates:
     > ## | odds ratio
     > ## |  0.1141677
     > ## `----
     > log(0.114)
     > ## ,----
     > ## | [1] -2.171557
     > ## `----
     >
     > ## so, we get a highly significant association of the riskfactor
     > ## and the group with an log(odds ratio) of -2.2
     >
     > ## we get the same result using logistic regression:
     > dat %>%
     >   glm(group ~ riskfactor, family = "binomial", data = .) %>%
     >   summary
     > ## ,----
     > ## |
     > ## | Call:
     > ## | glm(formula = group ~ riskfactor, family = "binomial",
   data = .)
     > ## |
     > ## | Deviance Residuals:
     > ## |     Min       1Q   Median       3Q      Max
     > ## | -1.8802  -0.9374   0.6119   0.6119   1.4381
     > ## |
     > ## | Coefficients:
     > ## |                  Estimate Std. Error z value Pr(>|z|)
     > ## | (Intercept)        1.5805     0.1856   8.515   <2e-16 ***
     > ## | riskfactornorisk  -2.1752     0.2250  -9.668   <2e-16 ***
     > ## | ---
     > ## | Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.?
   0.1 ? ? 1
     > ## |
     > ## | (Dispersion parameter for binomial family taken to be 1)
     > ## |
     > ## |     Null deviance: 651.63  on 474  degrees of freedom
     > ## | Residual deviance: 538.83  on 473  degrees of freedom
     > ## | AIC: 542.83
     > ## |
     > ## | Number of Fisher Scoring iterations: 4
     > ## `----
     >
     >
     >
     > ## ------------------------------------------------- ##
     > ## Now, we analyse both time points with interaction ##
     > ## ------------------------------------------------- ##
     >
     > dat %>%
     >   glmer(group ~ riskfactor + fu + riskfactor:fu + (1|patient),
     family =
     > "binomial", data = .) %>%
     >   summary
     > ## ,----
     > ## | Generalized linear mixed model fit by maximum
   likelihood (Laplace
     > ## |   Approximation) [glmerMod]
     > ## |  Family: binomial  ( logit )
     > ## | Formula: group ~ riskfactor + fu + riskfactor:fu + (1 |
   patient)
     > ## |    Data: .
     > ## |
     > ## |      AIC      BIC   logLik deviance df.resid
     > ## |    345.2    366.0   -167.6    335.2      470
     > ## |
     > ## | Scaled residuals:
     > ## |       Min        1Q    Median        3Q       Max
     > ## | -0.095863 -0.058669  0.002278  0.002866  0.007324
     > ## |
     > ## | Random effects:
     > ## |  Groups  Name        Variance Std.Dev.
     > ## |  patient (Intercept) 1849     43
     > ## | Number of obs: 475, groups:  patient, 265
     > ## |
     > ## | Fixed effects:
     > ## |                       Estimate Std. Error z value Pr(>|z|)
     > ## | (Intercept)            11.6846     1.3736   8.507
    <2e-16 ***
     > ## | riskfactornorisk       -1.5919     1.4166  -1.124    0.261
     > ## | fuFU                    0.4596     1.9165   0.240    0.810
     > ## | riskfactornorisk:fuFU  -0.8183     2.1651  -0.378    0.705
     > ## | ---
     > ## | Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.?
   0.1 ? ? 1
     > ## |
     > ## | Correlation of Fixed Effects:
     > ## |             (Intr) rskfct fuFU
     > ## | rskfctrnrsk -0.746
     > ## | fuFU        -0.513  0.510
     > ## | rskfctrn:FU  0.478 -0.576 -0.908
     > ## `----
     >
     > ## I get huge variation in the random effects
     > ##
     > ## And the risk factor at BL gets an estimated log(odds
   ratio) of -1.6
     > ## but one which is not significant
     > ---------- cut here --------------------------------------------
     > _______________________________________________
     > R-sig-mixed-models at r-project.org
   <mailto:R-sig-mixed-models at r-project.org>
     <mailto:R-sig-mixed-models at r-project.org
   <mailto:R-sig-mixed-models at r-project.org>> mailing list
     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
     >

     --
     Dr. Andreas Leha
     Head of the 'Core Facility
     Medical Biometry and Statistical Bioinformatics'

     UNIVERSITY MEDICAL CENTER G?TTINGEN
     GEORG-AUGUST-UNIVERSIT?T
     Department of Medical Statistics
     Humboldtallee 32
     37073 G?ttingen
     Mailing Address: 37099 G?ttingen, Germany
     Fax: +49 (0) 551 39-4995
     Tel: +49 (0) 551 39-4987
     http://www.ams.med.uni-goettingen.de/service-de.shtml
     _______________________________________________
     R-sig-mixed-models at r-project.org
   <mailto:R-sig-mixed-models at r-project.org>
     <mailto:R-sig-mixed-models at r-project.org
   <mailto:R-sig-mixed-models at r-project.org>> mailing list
     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


   --
   Dr. Andreas Leha
   Head of the 'Core Facility
   Medical Biometry and Statistical Bioinformatics'

   UNIVERSITY MEDICAL CENTER G?TTINGEN
   GEORG-AUGUST-UNIVERSIT?T
   Department of Medical Statistics
   Humboldtallee 32
   37073 G?ttingen
   Mailing Address: 37099 G?ttingen, Germany
   Fax: +49 (0) 551 39-4995
   Tel: +49 (0) 551 39-4987
   http://www.ams.med.uni-goettingen.de/service-de.shtml


--
Dr. Andreas Leha
Head of the 'Core Facility
Medical Biometry and Statistical Bioinformatics'

UNIVERSITY MEDICAL CENTER G?TTINGEN
GEORG-AUGUST-UNIVERSIT?T
Department of Medical Statistics
Humboldtallee 32
37073 G?ttingen
Mailing Address: 37099 G?ttingen, Germany
Fax: +49 (0) 551 39-4995
Tel: +49 (0) 551 39-4987
http://www.ams.med.uni-goettingen.de/service-de.shtml

------------------------------

Subject: Digest Footer

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


------------------------------

End of R-sig-mixed-models Digest, Vol 143, Issue 41
***************************************************

_____________________________________
Professor Diana Kornbrot
Mobile
+44 (0) 7403 18 16 12
Work
University of Hertfordshire
College Lane, Hatfield, Hertfordshire AL10 9AB, UK
+44 (0) 170 728 4626
d.e.kornbrot at herts.ac.uk<mailto:d.e.kornbrot at herts.ac.uk>
http://dianakornbrot.wordpress.com/
http://go.herts.ac.uk/Diana_Kornbrot
skype:  kornbrotme
Home
19 Elmhurst Avenue
London N2 0LT, UK
+44 (0) 208 444 2081
 ------------------------------------------------------------




	[[alternative HTML version deleted]]


From @@chiin@mh @ending from gm@il@com  Tue Nov 27 13:51:17 2018
From: @@chiin@mh @ending from gm@il@com (Sachiin M H)
Date: Tue, 27 Nov 2018 07:51:17 -0500
Subject: [R-sig-ME] help with glmer
Message-ID: <CAF2JtxdPqe7o-Ki7PRyYgLiskTwu6Nzys1EXONZGkza7vjwh=g@mail.gmail.com>

Hi,
model1=glmer(survival~size+CON+HET+INT+(1+size|species)+(1|quadrat),offset=time,data=data,family=binomial(link="cloglog"),verbose=T)

survival- dead (1), alive(0)
size - sapling, juvenile and adult categories
HET and CON  - Heterospecific and conspecific negative densitites at 20m
radius
(summ of basal area around 20 m radius of a focal tree)
INT - Census interval
quadrat - 100 number - 10x10m
time - log transformed number of years

this is the warning message at the model summary

Warning messages:1: In (function (fn, par, lower = rep.int(-Inf, n),
upper = rep.int(Inf,  :  failure to converge in 10000 evaluations2: In
checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
unable to evaluate scaled gradient3: In checkConv(attr(opt, "derivs"),
opt$par, ctrl = control$checkConv,  :  Model failed to converge:
degenerate  Hessian with 1 negative eigenvalues


my question is - how heterospecific and conspecific desnity influence
survival of sapling, juvenile and adult trees?

	[[alternative HTML version deleted]]


From Bill@Poling @ending from zeli@@com  Tue Nov 27 17:57:14 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Tue, 27 Nov 2018 16:57:14 +0000
Subject: [R-sig-ME] Help with split data routine and subsequent predict
 function --caret and klaR pkgs
Message-ID: <BN7PR02MB50732DC88CDDD720F2461A06EAD00@BN7PR02MB5073.namprd02.prod.outlook.com>

R=3.5.1
Windows=10
RStudio Version = 1.1.456

Hello I am following this split data routine located at:
https://machinelearningmastery.com/how-to-estimate-model-accuracy-in-r-using-the-caret-package/

When I get to the "predictions <- predict(model, x_test)" below I am getting the following error:
#Error in `[[<-.data.frame`(`*tmp*`, i, value = integer(0)) :  replacement has 0 rows, data has 4628

So I checked again for the usual culprit being NA's but there are none?

I Thought maybe "tryCatch()" might help but it isn't working for me either? LOL!
#Error: unexpected ')' in "tryCatch({predictions <- predict(model, x_test)}, error = function(e)print(e), warning = function(w))"

Thank you for any insight and direction.

WHP

str(r1a1)
# Classes 'data.table' and 'data.frame':23141 obs. of  8 variables:
#   $ SavingsReversed: num  0 0 0 0 0 0 0 0 0 0 ...
# $ productID      : num  3 3 3 3 3 3 3 3 1 1 ...
# $ ProviderID     : num  113676 113676 113964 113964 114278 ...
# $ ModCnt         : num  0 0 0 0 1 1 1 1 1 1 ...
# $ Editnumber2    : num  0 0 1 1 1 1 1 1 1 1 ...
# $ B2             : num  -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 ...
# $ B1a            : num  1 1 3 3 1 1 1 1 1 1 ...
# $ PatientGender2 : num  0 0 1 1 1 1 0 0 0 0 ...
# - attr(*, ".internal.selfref")=<externalptr>

tail(r1a1)
   SavingsReversed productID ProviderID ModCnt Editnumber2 B2 B1a PatientGender2
1:            0.00         3    6266065      0           0  9  26              1
2:           32.61         3    6266065      0           0  9  26              0
3:            0.00         1    6266651      0           1  9  26              1
4:            0.00         3    6270643      2           1  7  26              0
5:            0.00         3    6270643      0           1 -1   3              0
6:            0.00         3    6273280      0           0  9  26              0

#reorg r1a1
r1a2 <- r1a1[,c(5,1,2,3,4,6,7,8)]
str(r1a2)
#Data Split
# define an 80%/20% train/test split of the dataset
split=0.80
trainIndex <- createDataPartition(r1a1$Editnumber2, p=split, list=FALSE)
str(trainIndex) # abbreviated here
#int [1:18513, 1] 2 3 5 7 8 9 10 11 12 14 ...
# - attr(*, "dimnames")=List of 2
# ..$ : NULL
# ..$ : chr "Resample1"
data_train <- r1a1[ trainIndex,]
str(data_train) #abbreviated here
#Classes 'data.table' and 'data.frame':18513 obs. of  8 variables:
data_test <-  r1a1[-trainIndex,]
str(data_test)# abbreviated here
#Classes 'data.table' and 'data.frame':4628 obs. of  8 variables:

# train a naive bayes model
# install.packages("klaR")
# library(klaR)
model <- naiveBayes(Editnumber2~., data=data_train)
# make predictions
x_test <- data_test[,2:8]
y_test <- data_test[,1]
predictions <- predict(model, x_test)
#Error in `[[<-.data.frame`(`*tmp*`, i, value = integer(0)) :  replacement has 0 rows, data has 4628
row.has.na <- apply(r1a1, 1, function(x){any(is.na(x))})
sum(row.has.na) #48
View(row.has.na)
#[1] 0

??tryCatch
tryCatch({predictions <- predict(model, x_test)}, error = function(e)print(e), warning = function(w))

#NOT RUN
# summarize results
confusionMatrix(Editnumber2, y_test)





Confidentiality Notice This message is sent from Zelis. ...{{dropped:13}}


From M@@rten@Jung @ending from m@ilbox@tu-dre@den@de  Wed Nov 28 19:17:32 2018
From: M@@rten@Jung @ending from m@ilbox@tu-dre@den@de (Maarten Jung)
Date: Wed, 28 Nov 2018 19:17:32 +0100
Subject: [R-sig-ME] LMM reduction following marginality taking out "item"
 before "subject:item" grouping factor
Message-ID: <CAHr4DydeDW5mR-HNkHqKK22VetQ20AZ-bScnNP-yLLEfrrXeng@mail.gmail.com>

Dear list,

In a 2 x 2 fully crossed design in which every participant responds to
every stimulus multiple times in each cell of the factorial design the
maximal linear mixed model justified by the design (using the lme4 syntax)
should be:
y ~ A * B + (1 + A * B | subject) + (1 + A * B | item)  + (1 + A * B |
subject:item)

Within a model reduction process, be it because the estimation algorithm
doesn't converge or the model is overparameterized or one wants to balance
Type-1 error rate and power, I follow the principle of marginality taking
out higher-order interactions before lower-order terms (i.e. lower-order
interactions and main effects) nested under them and random slopes before
random intercepts.
However, it occurs that the variance components of the grouping factor
"item" are not significant while those of the grouping factor
"subject:item" are.

Does it make sense to remove the whole grouping factor "item" before taking
out the variance components of the grouping factor "subejct:item"?

A reduced model would f.i. look like this:
y ~ A * B + (1 + A | subject) + (1 | subject:item)

I'm not sure whether this contradicts the principal of marginality and, in
general, whether this is a sound approach.

Any help is highly appreciated.

Best regards,
Maarten

	[[alternative HTML version deleted]]


From j@ke@@@we@tf@ll @ending from gm@il@com  Wed Nov 28 19:24:30 2018
From: j@ke@@@we@tf@ll @ending from gm@il@com (Jake Westfall)
Date: Wed, 28 Nov 2018 12:24:30 -0600
Subject: [R-sig-ME] 
 LMM reduction following marginality taking out "item"
 before "subject:item" grouping factor
In-Reply-To: <CAHr4DydeDW5mR-HNkHqKK22VetQ20AZ-bScnNP-yLLEfrrXeng@mail.gmail.com>
References: <CAHr4DydeDW5mR-HNkHqKK22VetQ20AZ-bScnNP-yLLEfrrXeng@mail.gmail.com>
Message-ID: <CAE9_Wg4XTY+1Kt4kdHWShfYbpA4Us49oj36bakgJnUVF3Jg92g@mail.gmail.com>

Maarten,

I think it's fine. I can't think of any reason to respect a principle of
marginality for the random variance components. I agree with the feeling
that it's better to remove higher-order interactions before lower-order
interactions and so on, but that's just because of hierarchical ordering
(higher-order interactions tend to explain less variance than lower-order
interations), not because of any consideration of marginality. If in your
data you find that hierarchical ordering is not quite true and instead the
highest-order interaction is important while a lower-order one is not, then
it makes sense to me to let your model reflect that finding.

Jake

On Wed, Nov 28, 2018 at 12:18 PM Maarten Jung <
Maarten.Jung at mailbox.tu-dresden.de> wrote:

> Dear list,
>
> In a 2 x 2 fully crossed design in which every participant responds to
> every stimulus multiple times in each cell of the factorial design the
> maximal linear mixed model justified by the design (using the lme4 syntax)
> should be:
> y ~ A * B + (1 + A * B | subject) + (1 + A * B | item)  + (1 + A * B |
> subject:item)
>
> Within a model reduction process, be it because the estimation algorithm
> doesn't converge or the model is overparameterized or one wants to balance
> Type-1 error rate and power, I follow the principle of marginality taking
> out higher-order interactions before lower-order terms (i.e. lower-order
> interactions and main effects) nested under them and random slopes before
> random intercepts.
> However, it occurs that the variance components of the grouping factor
> "item" are not significant while those of the grouping factor
> "subject:item" are.
>
> Does it make sense to remove the whole grouping factor "item" before taking
> out the variance components of the grouping factor "subejct:item"?
>
> A reduced model would f.i. look like this:
> y ~ A * B + (1 + A | subject) + (1 | subject:item)
>
> I'm not sure whether this contradicts the principal of marginality and, in
> general, whether this is a sound approach.
>
> Any help is highly appreciated.
>
> Best regards,
> Maarten
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From M@@rten@Jung @ending from m@ilbox@tu-dre@den@de  Wed Nov 28 19:52:56 2018
From: M@@rten@Jung @ending from m@ilbox@tu-dre@den@de (Maarten Jung)
Date: Wed, 28 Nov 2018 19:52:56 +0100
Subject: [R-sig-ME] 
 LMM reduction following marginality taking out "item"
 before "subject:item" grouping factor
In-Reply-To: <CAE9_Wg4XTY+1Kt4kdHWShfYbpA4Us49oj36bakgJnUVF3Jg92g@mail.gmail.com>
References: <CAHr4DydeDW5mR-HNkHqKK22VetQ20AZ-bScnNP-yLLEfrrXeng@mail.gmail.com>
 <CAE9_Wg4XTY+1Kt4kdHWShfYbpA4Us49oj36bakgJnUVF3Jg92g@mail.gmail.com>
Message-ID: <CAHr4DycXeUR=g+y2ayj9k279gejiGAsirwUdO0oigkiLOJCSSw@mail.gmail.com>

Hi Jake,

Thanks for your thoughts on this.

I thought that Bates et al. (2015; [1]) were referring to this principle
when they stated:
"[...] we can eliminate variance components from the LMM, following the
standard statistical principle with respect to interactions and main
effects: variance components of higher-order
interactions should generally be taken out of the model before lower-order
terms nested under them. Frequently, in the end, this leads also to the
elimination of variance
components of main effects." (p. 6)

Would you agree with me that this is referring to the principle of
marginality? And if so, can you think of a reason why they suggest to
follow this principle other than "higher-order interactions tend to explain
less variance than lower-order interations"?

Best regards,
Maarten

[1] https://arxiv.org/pdf/1506.04967v1.pdf

On Wed, Nov 28, 2018 at 7:24 PM Jake Westfall <jake.a.westfall at gmail.com>
wrote:

> Maarten,
>
> I think it's fine. I can't think of any reason to respect a principle of
> marginality for the random variance components. I agree with the feeling
> that it's better to remove higher-order interactions before lower-order
> interactions and so on, but that's just because of hierarchical ordering
> (higher-order interactions tend to explain less variance than lower-order
> interations), not because of any consideration of marginality. If in your
> data you find that hierarchical ordering is not quite true and instead the
> highest-order interaction is important while a lower-order one is not, then
> it makes sense to me to let your model reflect that finding.
>
> Jake
>
> On Wed, Nov 28, 2018 at 12:18 PM Maarten Jung <
> Maarten.Jung at mailbox.tu-dresden.de> wrote:
>
>> Dear list,
>>
>> In a 2 x 2 fully crossed design in which every participant responds to
>> every stimulus multiple times in each cell of the factorial design the
>> maximal linear mixed model justified by the design (using the lme4 syntax)
>> should be:
>> y ~ A * B + (1 + A * B | subject) + (1 + A * B | item)  + (1 + A * B |
>> subject:item)
>>
>> Within a model reduction process, be it because the estimation algorithm
>> doesn't converge or the model is overparameterized or one wants to balance
>> Type-1 error rate and power, I follow the principle of marginality taking
>> out higher-order interactions before lower-order terms (i.e. lower-order
>> interactions and main effects) nested under them and random slopes before
>> random intercepts.
>> However, it occurs that the variance components of the grouping factor
>> "item" are not significant while those of the grouping factor
>> "subject:item" are.
>>
>> Does it make sense to remove the whole grouping factor "item" before
>> taking
>> out the variance components of the grouping factor "subejct:item"?
>>
>> A reduced model would f.i. look like this:
>> y ~ A * B + (1 + A | subject) + (1 | subject:item)
>>
>> I'm not sure whether this contradicts the principal of marginality and, in
>> general, whether this is a sound approach.
>>
>> Any help is highly appreciated.
>>
>> Best regards,
>> Maarten
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

	[[alternative HTML version deleted]]


From j@ke@@@we@tf@ll @ending from gm@il@com  Wed Nov 28 20:03:39 2018
From: j@ke@@@we@tf@ll @ending from gm@il@com (Jake Westfall)
Date: Wed, 28 Nov 2018 13:03:39 -0600
Subject: [R-sig-ME] 
 LMM reduction following marginality taking out "item"
 before "subject:item" grouping factor
In-Reply-To: <CAHr4DycXeUR=g+y2ayj9k279gejiGAsirwUdO0oigkiLOJCSSw@mail.gmail.com>
References: <CAHr4DydeDW5mR-HNkHqKK22VetQ20AZ-bScnNP-yLLEfrrXeng@mail.gmail.com>
 <CAE9_Wg4XTY+1Kt4kdHWShfYbpA4Us49oj36bakgJnUVF3Jg92g@mail.gmail.com>
 <CAHr4DycXeUR=g+y2ayj9k279gejiGAsirwUdO0oigkiLOJCSSw@mail.gmail.com>
Message-ID: <CAE9_Wg63ZGgR1ZGut5N5qY4qKexgVc8ADTMDoJt1BtAaDodvGA@mail.gmail.com>

Maarten,

No, I would not agree that the Bates quote is referring to the principle of
marginality in the sense of e.g.:
https://en.wikipedia.org/wiki/Principle_of_marginality

Bates can chip in if he wants, but as I see it, the quote doesn't hint at
anything like this. It simply says that "variance components of
higher-order interactions should generally be taken out of the model before
lower-order terms nested under them" -- which I agree with. The reason this
is _generally_ true is because hierarchical ordering is _generally_ true.
But it looks like it's not true in your particular case.

can you think of a reason why they suggest to follow this principle other
> than "higher-order interactions tend to explain less variance than
> lower-order interations"?


No.

Jake

On Wed, Nov 28, 2018 at 12:53 PM Maarten Jung <
Maarten.Jung at mailbox.tu-dresden.de> wrote:

> Hi Jake,
>
> Thanks for your thoughts on this.
>
> I thought that Bates et al. (2015; [1]) were referring to this principle
> when they stated:
> "[...] we can eliminate variance components from the LMM, following the
> standard statistical principle with respect to interactions and main
> effects: variance components of higher-order
> interactions should generally be taken out of the model before lower-order
> terms nested under them. Frequently, in the end, this leads also to the
> elimination of variance
> components of main effects." (p. 6)
>
> Would you agree with me that this is referring to the principle of
> marginality? And if so, can you think of a reason why they suggest to
> follow this principle other than "higher-order interactions tend to explain
> less variance than lower-order interations"?
>
> Best regards,
> Maarten
>
> [1] https://arxiv.org/pdf/1506.04967v1.pdf
>
> On Wed, Nov 28, 2018 at 7:24 PM Jake Westfall <jake.a.westfall at gmail.com>
> wrote:
>
>> Maarten,
>>
>> I think it's fine. I can't think of any reason to respect a principle of
>> marginality for the random variance components. I agree with the feeling
>> that it's better to remove higher-order interactions before lower-order
>> interactions and so on, but that's just because of hierarchical ordering
>> (higher-order interactions tend to explain less variance than lower-order
>> interations), not because of any consideration of marginality. If in your
>> data you find that hierarchical ordering is not quite true and instead the
>> highest-order interaction is important while a lower-order one is not, then
>> it makes sense to me to let your model reflect that finding.
>>
>> Jake
>>
>> On Wed, Nov 28, 2018 at 12:18 PM Maarten Jung <
>> Maarten.Jung at mailbox.tu-dresden.de> wrote:
>>
>>> Dear list,
>>>
>>> In a 2 x 2 fully crossed design in which every participant responds to
>>> every stimulus multiple times in each cell of the factorial design the
>>> maximal linear mixed model justified by the design (using the lme4
>>> syntax)
>>> should be:
>>> y ~ A * B + (1 + A * B | subject) + (1 + A * B | item)  + (1 + A * B |
>>> subject:item)
>>>
>>> Within a model reduction process, be it because the estimation algorithm
>>> doesn't converge or the model is overparameterized or one wants to
>>> balance
>>> Type-1 error rate and power, I follow the principle of marginality taking
>>> out higher-order interactions before lower-order terms (i.e. lower-order
>>> interactions and main effects) nested under them and random slopes before
>>> random intercepts.
>>> However, it occurs that the variance components of the grouping factor
>>> "item" are not significant while those of the grouping factor
>>> "subject:item" are.
>>>
>>> Does it make sense to remove the whole grouping factor "item" before
>>> taking
>>> out the variance components of the grouping factor "subejct:item"?
>>>
>>> A reduced model would f.i. look like this:
>>> y ~ A * B + (1 + A | subject) + (1 | subject:item)
>>>
>>> I'm not sure whether this contradicts the principal of marginality and,
>>> in
>>> general, whether this is a sound approach.
>>>
>>> Any help is highly appreciated.
>>>
>>> Best regards,
>>> Maarten
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>

	[[alternative HTML version deleted]]


From d@e@kornbrot @ending from hert@@@c@uk  Wed Nov 28 21:01:12 2018
From: d@e@kornbrot @ending from hert@@@c@uk (Kornbrot, Diana)
Date: Wed, 28 Nov 2018 20:01:12 +0000
Subject: [R-sig-ME] Need Bayes Factor and posterior odds
Message-ID: <65067358-1F28-4C07-8B61-AF2A0B97F921@herts.ac.uk>

Please help me get Bayes Factor and posterior odds out ofreuslts  of bglmer
It MUST be possible, fairly desperate about this
Many thanks
Diana
_____________________________________
Professor Diana Kornbrot
Mobile
+44 (0) 7403 18 16 12
Work
University of Hertfordshire
College Lane, Hatfield, Hertfordshire AL10 9AB, UK
+44 (0) 170 728 4626
d.e.kornbrot at herts.ac.uk<mailto:d.e.kornbrot at herts.ac.uk>
http://dianakornbrot.wordpress.com/
http://go.herts.ac.uk/Diana_Kornbrot
skype:  kornbrotme
Home
19 Elmhurst Avenue
London N2 0LT, UK
+44 (0) 208 444 2081
 ------------------------------------------------------------




	[[alternative HTML version deleted]]


From p@ul@buerkner @ending from gm@il@com  Wed Nov 28 21:06:34 2018
From: p@ul@buerkner @ending from gm@il@com (Paul Buerkner)
Date: Wed, 28 Nov 2018 21:06:34 +0100
Subject: [R-sig-ME] Need Bayes Factor and posterior odds
In-Reply-To: <65067358-1F28-4C07-8B61-AF2A0B97F921@herts.ac.uk>
References: <65067358-1F28-4C07-8B61-AF2A0B97F921@herts.ac.uk>
Message-ID: <CAGoSky_dx2ssTYhTfb_5j7bGZ3e20iQHZLi8vGC5-72yKmR9iA@mail.gmail.com>

I don't know how to do it in bglmer but in case nobody has a solution for
this you may want to try the brms package for Bayes factors in Bayesian
multilevel models.

Am Mi., 28. Nov. 2018, 21:01 hat Kornbrot, Diana <d.e.kornbrot at herts.ac.uk>
geschrieben:

> Please help me get Bayes Factor and posterior odds out ofreuslts  of bglmer
> It MUST be possible, fairly desperate about this
> Many thanks
> Diana
> _____________________________________
> Professor Diana Kornbrot
> Mobile
> +44 (0) 7403 18 16 12
> Work
> University of Hertfordshire
> College Lane, Hatfield, Hertfordshire AL10 9AB, UK
> +44 (0) 170 728 4626
> d.e.kornbrot at herts.ac.uk<mailto:d.e.kornbrot at herts.ac.uk>
> http://dianakornbrot.wordpress.com/
> http://go.herts.ac.uk/Diana_Kornbrot
> skype:  kornbrotme
> Home
> 19 Elmhurst Avenue
> London N2 0LT, UK
> +44 (0) 208 444 2081
>  ------------------------------------------------------------
>
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From M@@rten@Jung @ending from m@ilbox@tu-dre@den@de  Wed Nov 28 21:33:28 2018
From: M@@rten@Jung @ending from m@ilbox@tu-dre@den@de (Maarten Jung)
Date: Wed, 28 Nov 2018 21:33:28 +0100
Subject: [R-sig-ME] 
 LMM reduction following marginality taking out "item"
 before "subject:item" grouping factor
In-Reply-To: <CAE9_Wg63ZGgR1ZGut5N5qY4qKexgVc8ADTMDoJt1BtAaDodvGA@mail.gmail.com>
References: <CAHr4DydeDW5mR-HNkHqKK22VetQ20AZ-bScnNP-yLLEfrrXeng@mail.gmail.com>
 <CAE9_Wg4XTY+1Kt4kdHWShfYbpA4Us49oj36bakgJnUVF3Jg92g@mail.gmail.com>
 <CAHr4DycXeUR=g+y2ayj9k279gejiGAsirwUdO0oigkiLOJCSSw@mail.gmail.com>
 <CAE9_Wg63ZGgR1ZGut5N5qY4qKexgVc8ADTMDoJt1BtAaDodvGA@mail.gmail.com>
Message-ID: <CAHr4DycgwzdnKXQSp43pJJJrkiDrELF2PVTeZLCZzizOOj1DiQ@mail.gmail.com>

Jake,

thanks for this insight.
So, regarding this issue, there is no difference between taking out
variance components for main effects before interactions within the same
grouping factor, e.g. reducing (1 + A*B | subject) to (1 + A:B | subject),
and taking out the whole grouping factor "item" (i.e. all variance
components of it) before "subject:item"?

And, I would be glad if you could answer this related question:
Do all variances of the random slopes (for interactions and main effects)
of a single grouping factor contribute to the standard errors of the fixed
main effects and interactions in the same way?

Regards,
Maarten

On Wed, Nov 28, 2018, 20:03 Jake Westfall <jake.a.westfall at gmail.com wrote:

> Maarten,
>
> No, I would not agree that the Bates quote is referring to the principle
> of marginality in the sense of e.g.:
> https://en.wikipedia.org/wiki/Principle_of_marginality
>
> Bates can chip in if he wants, but as I see it, the quote doesn't hint at
> anything like this. It simply says that "variance components of
> higher-order interactions should generally be taken out of the model before
> lower-order terms nested under them" -- which I agree with. The reason this
> is _generally_ true is because hierarchical ordering is _generally_ true.
> But it looks like it's not true in your particular case.
>
> can you think of a reason why they suggest to follow this principle other
>> than "higher-order interactions tend to explain less variance than
>> lower-order interations"?
>
>
> No.
>
> Jake
>
> On Wed, Nov 28, 2018 at 12:53 PM Maarten Jung <
> Maarten.Jung at mailbox.tu-dresden.de> wrote:
>
>> Hi Jake,
>>
>> Thanks for your thoughts on this.
>>
>> I thought that Bates et al. (2015; [1]) were referring to this principle
>> when they stated:
>> "[...] we can eliminate variance components from the LMM, following the
>> standard statistical principle with respect to interactions and main
>> effects: variance components of higher-order
>> interactions should generally be taken out of the model before
>> lower-order terms nested under them. Frequently, in the end, this leads
>> also to the elimination of variance
>> components of main effects." (p. 6)
>>
>> Would you agree with me that this is referring to the principle of
>> marginality? And if so, can you think of a reason why they suggest to
>> follow this principle other than "higher-order interactions tend to explain
>> less variance than lower-order interations"?
>>
>> Best regards,
>> Maarten
>>
>> [1] https://arxiv.org/pdf/1506.04967v1.pdf
>>
>> On Wed, Nov 28, 2018 at 7:24 PM Jake Westfall <jake.a.westfall at gmail.com>
>> wrote:
>>
>>> Maarten,
>>>
>>> I think it's fine. I can't think of any reason to respect a principle of
>>> marginality for the random variance components. I agree with the feeling
>>> that it's better to remove higher-order interactions before lower-order
>>> interactions and so on, but that's just because of hierarchical ordering
>>> (higher-order interactions tend to explain less variance than lower-order
>>> interations), not because of any consideration of marginality. If in your
>>> data you find that hierarchical ordering is not quite true and instead the
>>> highest-order interaction is important while a lower-order one is not, then
>>> it makes sense to me to let your model reflect that finding.
>>>
>>> Jake
>>>
>>> On Wed, Nov 28, 2018 at 12:18 PM Maarten Jung <
>>> Maarten.Jung at mailbox.tu-dresden.de> wrote:
>>>
>>>> Dear list,
>>>>
>>>> In a 2 x 2 fully crossed design in which every participant responds to
>>>> every stimulus multiple times in each cell of the factorial design the
>>>> maximal linear mixed model justified by the design (using the lme4
>>>> syntax)
>>>> should be:
>>>> y ~ A * B + (1 + A * B | subject) + (1 + A * B | item)  + (1 + A * B |
>>>> subject:item)
>>>>
>>>> Within a model reduction process, be it because the estimation algorithm
>>>> doesn't converge or the model is overparameterized or one wants to
>>>> balance
>>>> Type-1 error rate and power, I follow the principle of marginality
>>>> taking
>>>> out higher-order interactions before lower-order terms (i.e. lower-order
>>>> interactions and main effects) nested under them and random slopes
>>>> before
>>>> random intercepts.
>>>> However, it occurs that the variance components of the grouping factor
>>>> "item" are not significant while those of the grouping factor
>>>> "subject:item" are.
>>>>
>>>> Does it make sense to remove the whole grouping factor "item" before
>>>> taking
>>>> out the variance components of the grouping factor "subejct:item"?
>>>>
>>>> A reduced model would f.i. look like this:
>>>> y ~ A * B + (1 + A | subject) + (1 | subject:item)
>>>>
>>>> I'm not sure whether this contradicts the principal of marginality and,
>>>> in
>>>> general, whether this is a sound approach.
>>>>
>>>> Any help is highly appreciated.
>>>>
>>>> Best regards,
>>>> Maarten
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>

	[[alternative HTML version deleted]]


From j@ke@@@we@tf@ll @ending from gm@il@com  Wed Nov 28 22:23:13 2018
From: j@ke@@@we@tf@ll @ending from gm@il@com (Jake Westfall)
Date: Wed, 28 Nov 2018 15:23:13 -0600
Subject: [R-sig-ME] 
 LMM reduction following marginality taking out "item"
 before "subject:item" grouping factor
In-Reply-To: <CAHr4DycgwzdnKXQSp43pJJJrkiDrELF2PVTeZLCZzizOOj1DiQ@mail.gmail.com>
References: <CAHr4DydeDW5mR-HNkHqKK22VetQ20AZ-bScnNP-yLLEfrrXeng@mail.gmail.com>
 <CAE9_Wg4XTY+1Kt4kdHWShfYbpA4Us49oj36bakgJnUVF3Jg92g@mail.gmail.com>
 <CAHr4DycXeUR=g+y2ayj9k279gejiGAsirwUdO0oigkiLOJCSSw@mail.gmail.com>
 <CAE9_Wg63ZGgR1ZGut5N5qY4qKexgVc8ADTMDoJt1BtAaDodvGA@mail.gmail.com>
 <CAHr4DycgwzdnKXQSp43pJJJrkiDrELF2PVTeZLCZzizOOj1DiQ@mail.gmail.com>
Message-ID: <CAE9_Wg6wC=UVCYCYhUqzTDSDBNqjJHGBXncNzvL-n3k4tJXXyQ@mail.gmail.com>

Maarten,

So, regarding this issue, there is no difference between taking out
> variance components for main effects before interactions within the same
> grouping factor, e.g. reducing (1 + A*B | subject) to (1 + A:B | subject),
> and taking out the whole grouping factor "item" (i.e. all variance
> components of it) before "subject:item"?


I think that if you have strong evidence that this is the appropriate
random effects structure, then it makes sense to modify your model
accordingly, yes.

Do all variances of the random slopes (for interactions and main effects)
> of a single grouping factor contribute to the standard errors of the fixed
> main effects and interactions in the same way?


No -- in general, with unbalanced datasets and continuous predictors, it's
hard to say much for sure other than "no." But it can be informative to
think of simpler, approximately balanced ANOVA-like designs where it's much
easier to say much more about which variance components enter which
standard errors and how.

I have a Shiny power analysis app, PANGEA (power analysis for general anova
designs) <http://jakewestfall.org/pangea/>, which as a side feature you can
also use to compute the expected mean square equations for arbitrary
balanced designs w/ categorical predictors. Near the bottom of "step 1"
there is a checkbox for "show expected mean square equations." So you can
specify your design, check the box, then hit the "submit design" button to
view a table representing the equations, with rows = mean squares and
columns = variance components. (A little while ago Shiny changed how it
renders tables and now the row labels no longer appear, which is really
annoying, but they are given in the reverse order of the column labels, so
that the diagonal from bottom-left to top-right is where the mean squares
and variance components correspond.) The standard error for a particular
fixed effect is proportional to the (square root of the) corresponding mean
square divided by the total sample size, that is, by the product of all the
factor sample sizes. So examining the mean square for an effect will tell
you which variance components enter its standard error and which sample
sizes they are divided by in the expression. I find this useful for getting
a sense of how the variance components affect the standard errors, even
though the results from this app are only simplified approximations to
those from more realistic and complicated designs.

Jake

On Wed, Nov 28, 2018 at 2:33 PM Maarten Jung <
Maarten.Jung at mailbox.tu-dresden.de> wrote:

> Jake,
>
> thanks for this insight.
> So, regarding this issue, there is no difference between taking out
> variance components for main effects before interactions within the same
> grouping factor, e.g. reducing (1 + A*B | subject) to (1 + A:B | subject),
> and taking out the whole grouping factor "item" (i.e. all variance
> components of it) before "subject:item"?
>
> And, I would be glad if you could answer this related question:
> Do all variances of the random slopes (for interactions and main effects)
> of a single grouping factor contribute to the standard errors of the fixed
> main effects and interactions in the same way?
>
> Regards,
> Maarten
>
> On Wed, Nov 28, 2018, 20:03 Jake Westfall <jake.a.westfall at gmail.com
> wrote:
>
>> Maarten,
>>
>> No, I would not agree that the Bates quote is referring to the principle
>> of marginality in the sense of e.g.:
>> https://en.wikipedia.org/wiki/Principle_of_marginality
>>
>> Bates can chip in if he wants, but as I see it, the quote doesn't hint at
>> anything like this. It simply says that "variance components of
>> higher-order interactions should generally be taken out of the model before
>> lower-order terms nested under them" -- which I agree with. The reason this
>> is _generally_ true is because hierarchical ordering is _generally_ true.
>> But it looks like it's not true in your particular case.
>>
>> can you think of a reason why they suggest to follow this principle other
>>> than "higher-order interactions tend to explain less variance than
>>> lower-order interations"?
>>
>>
>> No.
>>
>> Jake
>>
>> On Wed, Nov 28, 2018 at 12:53 PM Maarten Jung <
>> Maarten.Jung at mailbox.tu-dresden.de> wrote:
>>
>>> Hi Jake,
>>>
>>> Thanks for your thoughts on this.
>>>
>>> I thought that Bates et al. (2015; [1]) were referring to this principle
>>> when they stated:
>>> "[...] we can eliminate variance components from the LMM, following the
>>> standard statistical principle with respect to interactions and main
>>> effects: variance components of higher-order
>>> interactions should generally be taken out of the model before
>>> lower-order terms nested under them. Frequently, in the end, this leads
>>> also to the elimination of variance
>>> components of main effects." (p. 6)
>>>
>>> Would you agree with me that this is referring to the principle of
>>> marginality? And if so, can you think of a reason why they suggest to
>>> follow this principle other than "higher-order interactions tend to explain
>>> less variance than lower-order interations"?
>>>
>>> Best regards,
>>> Maarten
>>>
>>> [1] https://arxiv.org/pdf/1506.04967v1.pdf
>>>
>>> On Wed, Nov 28, 2018 at 7:24 PM Jake Westfall <jake.a.westfall at gmail.com>
>>> wrote:
>>>
>>>> Maarten,
>>>>
>>>> I think it's fine. I can't think of any reason to respect a principle
>>>> of marginality for the random variance components. I agree with the feeling
>>>> that it's better to remove higher-order interactions before lower-order
>>>> interactions and so on, but that's just because of hierarchical ordering
>>>> (higher-order interactions tend to explain less variance than lower-order
>>>> interations), not because of any consideration of marginality. If in your
>>>> data you find that hierarchical ordering is not quite true and instead the
>>>> highest-order interaction is important while a lower-order one is not, then
>>>> it makes sense to me to let your model reflect that finding.
>>>>
>>>> Jake
>>>>
>>>> On Wed, Nov 28, 2018 at 12:18 PM Maarten Jung <
>>>> Maarten.Jung at mailbox.tu-dresden.de> wrote:
>>>>
>>>>> Dear list,
>>>>>
>>>>> In a 2 x 2 fully crossed design in which every participant responds to
>>>>> every stimulus multiple times in each cell of the factorial design the
>>>>> maximal linear mixed model justified by the design (using the lme4
>>>>> syntax)
>>>>> should be:
>>>>> y ~ A * B + (1 + A * B | subject) + (1 + A * B | item)  + (1 + A * B |
>>>>> subject:item)
>>>>>
>>>>> Within a model reduction process, be it because the estimation
>>>>> algorithm
>>>>> doesn't converge or the model is overparameterized or one wants to
>>>>> balance
>>>>> Type-1 error rate and power, I follow the principle of marginality
>>>>> taking
>>>>> out higher-order interactions before lower-order terms (i.e.
>>>>> lower-order
>>>>> interactions and main effects) nested under them and random slopes
>>>>> before
>>>>> random intercepts.
>>>>> However, it occurs that the variance components of the grouping factor
>>>>> "item" are not significant while those of the grouping factor
>>>>> "subject:item" are.
>>>>>
>>>>> Does it make sense to remove the whole grouping factor "item" before
>>>>> taking
>>>>> out the variance components of the grouping factor "subejct:item"?
>>>>>
>>>>> A reduced model would f.i. look like this:
>>>>> y ~ A * B + (1 + A | subject) + (1 | subject:item)
>>>>>
>>>>> I'm not sure whether this contradicts the principal of marginality
>>>>> and, in
>>>>> general, whether this is a sound approach.
>>>>>
>>>>> Any help is highly appreciated.
>>>>>
>>>>> Best regards,
>>>>> Maarten
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>

	[[alternative HTML version deleted]]


From diego@p@vonjord@n @ending from gm@il@com  Thu Nov 29 12:31:07 2018
From: diego@p@vonjord@n @ending from gm@il@com (Diego Pavon)
Date: Thu, 29 Nov 2018 13:31:07 +0200
Subject: [R-sig-ME] emmeans and emtrends for a glmmTMB object
Message-ID: <CAD93_Fo4Ud=K2r=1DC_bn1DvYViDr+cV2gyqUCJ6Zgr48YJFuw@mail.gmail.com>

Dear all,

I understood that I could use emmeans and emtrends on a glmmTMB model for
contrasts, e.g.:

https://github.com/glmmTMB/glmmTMB/blob/master/glmmTMB/vignettes/model_evaluation.rmd

https://stackoverflow.com/questions/51886334/planned-contrasts-on-glmmtmb


I have a model with a three-way interaction (continous * continuous *
categorical variable with 4 levels), but when I run:

emms1 <- emmeans(m1b, ~ Winter_std * NEnessSpp_std | SiteCategory)

I get the error

Error in ref_grid(object, ...) :
  Can't handle an object of class  ?glmmTMB?
 Use help("models", package = "emmeans") for information on supported
models.

And in that vignette, glmmTMB is not one of the supported models.

Does anyone know how to do contrasts of slopes for glmmTMB models?

Cheers,

Diego



-- 
*Diego Pav?n Jord?n*

*Finnish Museum of Natural History*
*PO BOX 17 *

*Helsinki. Finland*

*0445061210https://www.researchgate.net/profile/Diego_Pavon-jordan
<https://www.researchgate.net/profile/Diego_Pavon-jordan>*

	[[alternative HTML version deleted]]


From M@@rten@Jung @ending from m@ilbox@tu-dre@den@de  Thu Nov 29 14:36:35 2018
From: M@@rten@Jung @ending from m@ilbox@tu-dre@den@de (Maarten Jung)
Date: Thu, 29 Nov 2018 14:36:35 +0100
Subject: [R-sig-ME] 
 LMM reduction following marginality taking out "item"
 before "subject:item" grouping factor
In-Reply-To: <CAE9_Wg6wC=UVCYCYhUqzTDSDBNqjJHGBXncNzvL-n3k4tJXXyQ@mail.gmail.com>
References: <CAHr4DydeDW5mR-HNkHqKK22VetQ20AZ-bScnNP-yLLEfrrXeng@mail.gmail.com>
 <CAE9_Wg4XTY+1Kt4kdHWShfYbpA4Us49oj36bakgJnUVF3Jg92g@mail.gmail.com>
 <CAHr4DycXeUR=g+y2ayj9k279gejiGAsirwUdO0oigkiLOJCSSw@mail.gmail.com>
 <CAE9_Wg63ZGgR1ZGut5N5qY4qKexgVc8ADTMDoJt1BtAaDodvGA@mail.gmail.com>
 <CAHr4DycgwzdnKXQSp43pJJJrkiDrELF2PVTeZLCZzizOOj1DiQ@mail.gmail.com>
 <CAE9_Wg6wC=UVCYCYhUqzTDSDBNqjJHGBXncNzvL-n3k4tJXXyQ@mail.gmail.com>
Message-ID: <CAHr4Dycsqq4nd_-MvSf_FEFzTndpUfYKTaWKkS1AHq-kn-1jEw@mail.gmail.com>

Hi Jake,

So, regarding this issue, there is no difference between taking out
>> variance components for main effects before interactions within the same
>> grouping factor, e.g. reducing (1 + A*B | subject) to (1 + A:B | subject),
>> and taking out the whole grouping factor "item" (i.e. all variance
>> components of it) before "subject:item"?
>
>
> I think that if you have strong evidence that this is the appropriate
> random effects structure, then it makes sense to modify your model
> accordingly, yes.
>

 This makes sense to me.

Do all variances of the random slopes (for interactions and main effects)
>> of a single grouping factor contribute to the standard errors of the fixed
>> main effects and interactions in the same way?
>
>
> No -- in general, with unbalanced datasets and continuous predictors, it's
> hard to say much for sure other than "no." But it can be informative to
> think of simpler, approximately balanced ANOVA-like designs where it's much
> easier to say much more about which variance components enter which
> standard errors and how.
>
> The standard error for a particular fixed effect is proportional to the
> (square root of the) corresponding mean square divided by the total sample
> size, that is, by the product of all the factor sample sizes. So examining
> the mean square for an effect will tell you which variance components enter
> its standard error and which sample sizes they are divided by in the
> expression.
>

Your app is very useful, too. Just to double-check if I get this right: the
entries in each cell of the table are the numbers by which the variance
components are divided in the equation of the noncentrality parameter. Is
this correct?


Regards,
Maarten

	[[alternative HTML version deleted]]


From j@ke@@@we@tf@ll @ending from gm@il@com  Thu Nov 29 15:54:18 2018
From: j@ke@@@we@tf@ll @ending from gm@il@com (Jake Westfall)
Date: Thu, 29 Nov 2018 08:54:18 -0600
Subject: [R-sig-ME] 
 LMM reduction following marginality taking out "item"
 before "subject:item" grouping factor
In-Reply-To: <CAHr4Dycsqq4nd_-MvSf_FEFzTndpUfYKTaWKkS1AHq-kn-1jEw@mail.gmail.com>
References: <CAHr4DydeDW5mR-HNkHqKK22VetQ20AZ-bScnNP-yLLEfrrXeng@mail.gmail.com>
 <CAE9_Wg4XTY+1Kt4kdHWShfYbpA4Us49oj36bakgJnUVF3Jg92g@mail.gmail.com>
 <CAHr4DycXeUR=g+y2ayj9k279gejiGAsirwUdO0oigkiLOJCSSw@mail.gmail.com>
 <CAE9_Wg63ZGgR1ZGut5N5qY4qKexgVc8ADTMDoJt1BtAaDodvGA@mail.gmail.com>
 <CAHr4DycgwzdnKXQSp43pJJJrkiDrELF2PVTeZLCZzizOOj1DiQ@mail.gmail.com>
 <CAE9_Wg6wC=UVCYCYhUqzTDSDBNqjJHGBXncNzvL-n3k4tJXXyQ@mail.gmail.com>
 <CAHr4Dycsqq4nd_-MvSf_FEFzTndpUfYKTaWKkS1AHq-kn-1jEw@mail.gmail.com>
Message-ID: <CAE9_Wg47bXn-3O0cmyw1n4a134ikpopw8Fhij-aC4X25uAco_A@mail.gmail.com>

Maarten,

Just to double-check if I get this right: the entries in each cell of the
> table are the numbers by which the variance components are divided in the
> equation of the noncentrality parameter. Is this correct?


Almost. They multiply the variance components, not divide them. Essentially
each row gives the weights of a weighted sum of variance components. Then
to translate that to what appears in the denominator of the noncentrality
parameter, the entire thing is divided by the total sample size *and we
remove the variance component for the effect in question *(I forgot to
mention that part in my last email).

For example, consider the simple design with random participants (P) nested
in fixed groups (G). So g is the number of groups, p is the number of
participants per group, and # is the number of replicates. (This is design
2 in the dropdown menu of examples.) The EMS table shows that, for the
between-group effect, the coefficients for the error, participant, and
group variance components are, respectively, 1, #, and #p. So the expected
mean square is var_error + # * var_participants + # * p * var_groups. The
total sample size is pg#, so in the noncentrality parameter expression this
becomes sqrt(var_error / pg# + var_participants / pg). Note that this only
gives most of the denominator of the of the noncentrality parameter
expression -- it ignores the variance of the contrast weights -- you can
see more in the PANGEA working paper, linked in the app.

Jake

On Thu, Nov 29, 2018 at 7:36 AM Maarten Jung <
Maarten.Jung at mailbox.tu-dresden.de> wrote:

> Hi Jake,
>
> So, regarding this issue, there is no difference between taking out
>>> variance components for main effects before interactions within the same
>>> grouping factor, e.g. reducing (1 + A*B | subject) to (1 + A:B | subject),
>>> and taking out the whole grouping factor "item" (i.e. all variance
>>> components of it) before "subject:item"?
>>
>>
>> I think that if you have strong evidence that this is the appropriate
>> random effects structure, then it makes sense to modify your model
>> accordingly, yes.
>>
>
>  This makes sense to me.
>
> Do all variances of the random slopes (for interactions and main effects)
>>> of a single grouping factor contribute to the standard errors of the fixed
>>> main effects and interactions in the same way?
>>
>>
>> No -- in general, with unbalanced datasets and continuous predictors,
>> it's hard to say much for sure other than "no." But it can be informative
>> to think of simpler, approximately balanced ANOVA-like designs where it's
>> much easier to say much more about which variance components enter which
>> standard errors and how.
>>
>> The standard error for a particular fixed effect is proportional to the
>> (square root of the) corresponding mean square divided by the total sample
>> size, that is, by the product of all the factor sample sizes. So examining
>> the mean square for an effect will tell you which variance components enter
>> its standard error and which sample sizes they are divided by in the
>> expression.
>>
>
> Your app is very useful, too. Just to double-check if I get this right:
> the entries in each cell of the table are the numbers by which the variance
> components are divided in the equation of the noncentrality parameter. Is
> this correct?
>
>
> Regards,
> Maarten
>

	[[alternative HTML version deleted]]


From @ilv@d@v@@co @ending from gm@il@com  Thu Nov 29 22:24:42 2018
From: @ilv@d@v@@co @ending from gm@il@com (Vasco Silva)
Date: Thu, 29 Nov 2018 21:24:42 +0000
Subject: [R-sig-ME] Fitting GLMM to percent cover data with glmmTMB
Message-ID: <CAC8jbZedKU1dj=n1qYRxu306q8wbAqbw5juAnr9k0WB713HfzA@mail.gmail.com>

 Hi,

I am trying to fit a GLMM on percent cover for each plant species:

>str(cover)
'data.frame': 100 obs. of  114 variables:
$ Plot : Factor w/ 10 levels "P1","P10","P2",..: 1 1 1 1 1 3 3 ...
$ Sub.plot: Factor w/ 5 levels "S1","S2","S3",..: 1 2 3 4 5 1 2 ...
$ Grazing : Factor w/ 2 levels "Fenced","Unfenced": 1 1 1 1 1 1 1  ...
$ sp1 : int  0 0 0 1 0 0 1 ...
$ sp2 : int  0 0 0 0 0 3 3 ...
$ sp3 : int  0 1 0 0 1 3 3 ...
$ sp4 : int  1 3 13 3 3 3 0 ...
$ sp6 : int  0 0 0 0 0 0 0 ...
 ...
$ tot  : int  93 65 120 80 138 113 ...

I was wondering whether the GLMM can be fitted with glmmTMB (tweedie
distribution) and if so, should I use percent cover or percent cover
converted to relative abundance?

sp1.glmm <- glmmTMB (sp1 ~ Grazing + (1|Plot), data=cover, family=tweedie
(link ="logit"))

Any advice would be very much appreciated.

Cheers.

Vasco Silva

	[[alternative HTML version deleted]]


From burwood70 @ending from gm@il@com  Fri Nov 30 02:07:47 2018
From: burwood70 @ending from gm@il@com (Steve Candy)
Date: Fri, 30 Nov 2018 12:07:47 +1100
Subject: [R-sig-ME] help with glmer
Message-ID: <CAB9+ci20NDvPUEtHKWKzgxaSnDBDY=BR+AstS-20F-feqrO6rQ@mail.gmail.com>

Hi Sachiin

I do not understand why "time" is included as an offset and even before
that what the variable "number of years" refers to. An offset does not
allow any scaling by a corresponding regression coefficient so you have to
be very careful  to determine whether a predictor variable can validly be
included as an offset.

cheers

Steve

-- 
Dr Steven G. Candy
Director/Consultant
SCANDY STATISTICAL MODELLING PTY LTD
(ABN: 83 601 268 419)
70 Burwood Drive
Blackmans Bay, TASMANIA, Australia 7052
Mobile: (61) 0439284983

	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Fri Nov 30 02:15:24 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Thu, 29 Nov 2018 20:15:24 -0500
Subject: [R-sig-ME] help with glmer
In-Reply-To: <CAB9+ci20NDvPUEtHKWKzgxaSnDBDY=BR+AstS-20F-feqrO6rQ@mail.gmail.com>
References: <CAB9+ci20NDvPUEtHKWKzgxaSnDBDY=BR+AstS-20F-feqrO6rQ@mail.gmail.com>
Message-ID: <CABghstT-ebZgFj=9vsADav0FEQjf0md==N-awm=iY3V95zXvjQ@mail.gmail.com>

You should use log(time) as an offset, not time.  I prefer to include
it in the model formula, but that's largely a question of style.
@SteveCandy: with a cloglog link in a binomial-outcome model, using
log(time) as an offset allows a natural way to scale the probability
of mortality within the time for which an individual has been
observed.

I recently added a bullet point about using time rather than log(time)
as an offset here:

https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#convergence-warnings

Another example of this approach:

https://www.researchgate.net/profile/Alexander_Shenkin/publication/328148029_Interactive_effects_of_tree_size_crown_exposure_and_logging_on_drought-induced_mortality/links/5bc0645f299bf1004c5ac9f9/Interactive-effects-of-tree-size-crown-exposure-and-logging-on-drought-induced-mortality.pdf
On Thu, Nov 29, 2018 at 8:07 PM Steve Candy <burwood70 at gmail.com> wrote:
>
> Hi Sachiin
>
> I do not understand why "time" is included as an offset and even before
> that what the variable "number of years" refers to. An offset does not
> allow any scaling by a corresponding regression coefficient so you have to
> be very careful  to determine whether a predictor variable can validly be
> included as an offset.
>
> cheers
>
> Steve
>
> --
> Dr Steven G. Candy
> Director/Consultant
> SCANDY STATISTICAL MODELLING PTY LTD
> (ABN: 83 601 268 419)
> 70 Burwood Drive
> Blackmans Bay, TASMANIA, Australia 7052
> Mobile: (61) 0439284983
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker @ending from gm@il@com  Fri Nov 30 02:59:56 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Thu, 29 Nov 2018 20:59:56 -0500
Subject: [R-sig-ME] help with glmer
In-Reply-To: <CAB9+ci20NDvPUEtHKWKzgxaSnDBDY=BR+AstS-20F-feqrO6rQ@mail.gmail.com>
References: <CAB9+ci20NDvPUEtHKWKzgxaSnDBDY=BR+AstS-20F-feqrO6rQ@mail.gmail.com>
Message-ID: <f5763d6f-3a79-6564-6a0f-a992f628dc99@gmail.com>


  An off-list conversation with Steve convinces me that he is right and
I'm wrong (on several counts); I was reading too fast.

  * 'time' is indeed log-transformed.  BUT ...
  * for the standard exposure correction, it would be log(INT<="census
exposure">) and not log(time<="number of years">) that would be the
sensible thing to do.


On 2018-11-29 8:07 p.m., Steve Candy wrote:
> Hi Sachiin
> 
> I do not understand why "time" is included as an offset and even before
> that what the variable "number of years" refers to. An offset does not
> allow any scaling by a corresponding regression coefficient so you have to
> be very careful  to determine whether a predictor variable can validly be
> included as an offset.
> 
> cheers
> 
> Steve
>


From @ilv@d@v@@co @ending from gm@il@com  Fri Nov 30 10:27:37 2018
From: @ilv@d@v@@co @ending from gm@il@com (Vasco Silva)
Date: Fri, 30 Nov 2018 09:27:37 +0000
Subject: [R-sig-ME] Fitting GLMM to percent cover data with glmmTMB
In-Reply-To: <CAC8jbZedKU1dj=n1qYRxu306q8wbAqbw5juAnr9k0WB713HfzA@mail.gmail.com>
References: <CAC8jbZedKU1dj=n1qYRxu306q8wbAqbw5juAnr9k0WB713HfzA@mail.gmail.com>
Message-ID: <CAC8jbZehq+eFQ1soWSwKNK1EzgLpUAO0a1qYDkcWeDM2cqoY4g@mail.gmail.com>

 Apologies for eventual cross-posting.

Vasco



Vasco Silva <silvadavasco at gmail.com> escreveu no dia quinta, 29/11/2018
?(s) 21:24:

> Hi,
>
> I am trying to fit a GLMM on percent cover for each plant species:
>
> >str(cover)
> 'data.frame': 100 obs. of  114 variables:
> $ Plot : Factor w/ 10 levels "P1","P10","P2",..: 1 1 1 1 1 3 3 ...
> $ Sub.plot: Factor w/ 5 levels "S1","S2","S3",..: 1 2 3 4 5 1 2 ...
> $ Grazing : Factor w/ 2 levels "Fenced","Unfenced": 1 1 1 1 1 1 1  ...
> $ sp1 : int  0 0 0 1 0 0 1 ...
> $ sp2 : int  0 0 0 0 0 3 3 ...
> $ sp3 : int  0 1 0 0 1 3 3 ...
> $ sp4 : int  1 3 13 3 3 3 0 ...
> $ sp6 : int  0 0 0 0 0 0 0 ...
>  ...
> $ tot  : int  93 65 120 80 138 113 ...
>
> I was wondering whether the GLMM can be fitted with glmmTMB (tweedie
> distribution) and if so, should I use percent cover or percent cover
> converted to relative abundance?
>
> sp1.glmm <- glmmTMB (sp1 ~ Grazing + (1|Plot), data=cover, family=tweedie
> (link ="logit"))
>
> Any advice would be very much appreciated.
>
> Cheers.
>
> Vasco Silva
>
>

	[[alternative HTML version deleted]]


From mollieebrook@ @ending from gm@il@com  Fri Nov 30 12:21:04 2018
From: mollieebrook@ @ending from gm@il@com (Mollie Brooks)
Date: Fri, 30 Nov 2018 12:21:04 +0100
Subject: [R-sig-ME] Fitting GLMM to percent cover data with glmmTMB
In-Reply-To: <CAC8jbZedKU1dj=n1qYRxu306q8wbAqbw5juAnr9k0WB713HfzA@mail.gmail.com>
References: <CAC8jbZedKU1dj=n1qYRxu306q8wbAqbw5juAnr9k0WB713HfzA@mail.gmail.com>
Message-ID: <ED14F600-E515-4B06-A1F6-02CB85860F48@gmail.com>

Hi Vasco,

I mostly agree with what Scott Foster said over on R-sig-eco to your earlier question:

> I agree with Zoltan that bionimial is probably inappropriate, for the reasons he stated.
> 
> I'm not sure that Tweedie is your solution though -- it is defined for non-negative real numbers.
>  Not just those between 0 and 100%.  Perhaps easiest to think of fish biomass caught in a net (can
> be zero, or more.
> 
> Tweedie might work though, if your percentages are typically nowhere near the 100% boundary.  In
> this case, the upper end of the support is kind of immaterial...  You hope...
> 
> Does glmmTMB supply a beta distribution?  Zero-inflated beta?  The quantile regression idea might be
> useful too, as Brian suggested, but I'm not sure about random effects in that case.  Beta regression
> will also have problems with exactly 0% (or 100%) observations.

I would convert percentages to the 0-1 scale and then try a zero-inflated beta distribution. The Tweedie makes more sense if your response variable is the sum of a bunch of positive values like body weights. 

You can do a GLMM with a zero-inflated beta distribution in glmmTMB with something like

m1 <- glmmTMB(sp1 ~ Grazing + (1|Plot), zi=~1, data=cover, family=beta_family())
m2 <- glmmTMB(sp1 ~ Grazing + (1|Plot), zi=~ Grazing, data=cover, family=beta_family())

cheers,
Mollie


> On 29Nov 2018, at 22:24, Vasco Silva <silvadavasco at gmail.com> wrote:
> 
> Hi,
> 
> I am trying to fit a GLMM on percent cover for each plant species:
> 
>> str(cover)
> 'data.frame': 100 obs. of  114 variables:
> $ Plot : Factor w/ 10 levels "P1","P10","P2",..: 1 1 1 1 1 3 3 ...
> $ Sub.plot: Factor w/ 5 levels "S1","S2","S3",..: 1 2 3 4 5 1 2 ...
> $ Grazing : Factor w/ 2 levels "Fenced","Unfenced": 1 1 1 1 1 1 1  ...
> $ sp1 : int  0 0 0 1 0 0 1 ...
> $ sp2 : int  0 0 0 0 0 3 3 ...
> $ sp3 : int  0 1 0 0 1 3 3 ...
> $ sp4 : int  1 3 13 3 3 3 0 ...
> $ sp6 : int  0 0 0 0 0 0 0 ...
> ...
> $ tot  : int  93 65 120 80 138 113 ...
> 
> I was wondering whether the GLMM can be fitted with glmmTMB (tweedie
> distribution) and if so, should I use percent cover or percent cover
> converted to relative abundance?
> 
> sp1.glmm <- glmmTMB (sp1 ~ Grazing + (1|Plot), data=cover, family=tweedie
> (link ="logit"))
> 
> Any advice would be very much appreciated.
> 
> Cheers.
> 
> Vasco Silva
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From cl@rk@kog@n @ending from w@u@edu  Fri Nov 30 18:20:01 2018
From: cl@rk@kog@n @ending from w@u@edu (Kogan, Clark)
Date: Fri, 30 Nov 2018 17:20:01 +0000
Subject: [R-sig-ME] Specifying and fitting LME model with unstructured error
 correlation within subject
Message-ID: <MWHPR0101MB29907FBAAE88E6DD7281544FE4D30@MWHPR0101MB2990.prod.exchangelabs.com>

I have some data where a number of individuals have taken a few different subtests and there is 1 response per individual for each subtest. I am fitting the following model using lmer:

mod <- lmer(score ~ faculty + gender + subtest + gender:subtest + faculty:gender + faculty:subtest+ (subtest|id), data = score)

When fitting this model, I get the error:
Error: number of observations (=219) <= number of random effects (=219) for term (subtest | id); the random-effects parameters and the residual variance (or scale parameter) are probably unidentifiable

The error makes sense to me - as there is only one data point for every subtest*id, and so we cannot differentiate the random effects from the residuals. What I would like to be able to do is specify that the residuals have an unstructured correlation matrix within individuals to account for the fact that an individual will likely have some correlation between their subtest scores.

Is there a way to do this in lmer or a similar package so that I can still get Kenwood Rodgers or Satterthwaite corrected tests of effects (e.g., with pbkrtest or lmerTest).

Thanks,
Clark


	[[alternative HTML version deleted]]


From @ilv@d@v@@co @ending from gm@il@com  Fri Nov 30 21:21:30 2018
From: @ilv@d@v@@co @ending from gm@il@com (Vasco Silva)
Date: Fri, 30 Nov 2018 20:21:30 +0000
Subject: [R-sig-ME] Fitting GLMM to percent cover data with glmmTMB
In-Reply-To: <ED14F600-E515-4B06-A1F6-02CB85860F48@gmail.com>
References: <CAC8jbZedKU1dj=n1qYRxu306q8wbAqbw5juAnr9k0WB713HfzA@mail.gmail.com>
 <ED14F600-E515-4B06-A1F6-02CB85860F48@gmail.com>
Message-ID: <CAC8jbZd6Ha887GwdkXyeMAfbfhep5LgssCwH09rQvSNji=Mkig@mail.gmail.com>

Thanks Mollie.

I convert % cover to relative abundance using "decostand" function and fit
the GLMMM but it seems to lack something:

> sp1.glm1<-glmmTMB(sp1~Grazing+(1|Plot),zi=~0, data=cover,
+                        family=beta_family(link ="logit"))
Error in eval(expr, envir, enclos) : y values must be 0 < y < 1

Cheers.

Vasco

Mollie Brooks <mollieebrooks at gmail.com> escreveu no dia sexta, 30/11/2018
?(s) 11:21:

> Hi Vasco,
>
> I mostly agree with what Scott Foster said over on R-sig-eco to your
> earlier question:
>
> > I agree with Zoltan that bionimial is probably inappropriate, for the
> reasons he stated.
> >
> > I'm not sure that Tweedie is your solution though -- it is defined for
> non-negative real numbers.
> >  Not just those between 0 and 100%.  Perhaps easiest to think of fish
> biomass caught in a net (can
> > be zero, or more.
> >
> > Tweedie might work though, if your percentages are typically nowhere
> near the 100% boundary.  In
> > this case, the upper end of the support is kind of immaterial...  You
> hope...
> >
> > Does glmmTMB supply a beta distribution?  Zero-inflated beta?  The
> quantile regression idea might be
> > useful too, as Brian suggested, but I'm not sure about random effects in
> that case.  Beta regression
> > will also have problems with exactly 0% (or 100%) observations.
>
> I would convert percentages to the 0-1 scale and then try a zero-inflated
> beta distribution. The Tweedie makes more sense if your response variable
> is the sum of a bunch of positive values like body weights.
>
> You can do a GLMM with a zero-inflated beta distribution in glmmTMB with
> something like
>
> m1 <- glmmTMB(sp1 ~ Grazing + (1|Plot), zi=~1, data=cover,
> family=beta_family())
> m2 <- glmmTMB(sp1 ~ Grazing + (1|Plot), zi=~ Grazing, data=cover,
> family=beta_family())
>
> cheers,
> Mollie
>
>
> > On 29Nov 2018, at 22:24, Vasco Silva <silvadavasco at gmail.com> wrote:
> >
> > Hi,
> >
> > I am trying to fit a GLMM on percent cover for each plant species:
> >
> >> str(cover)
> > 'data.frame': 100 obs. of  114 variables:
> > $ Plot : Factor w/ 10 levels "P1","P10","P2",..: 1 1 1 1 1 3 3 ...
> > $ Sub.plot: Factor w/ 5 levels "S1","S2","S3",..: 1 2 3 4 5 1 2 ...
> > $ Grazing : Factor w/ 2 levels "Fenced","Unfenced": 1 1 1 1 1 1 1  ...
> > $ sp1 : int  0 0 0 1 0 0 1 ...
> > $ sp2 : int  0 0 0 0 0 3 3 ...
> > $ sp3 : int  0 1 0 0 1 3 3 ...
> > $ sp4 : int  1 3 13 3 3 3 0 ...
> > $ sp6 : int  0 0 0 0 0 0 0 ...
> > ...
> > $ tot  : int  93 65 120 80 138 113 ...
> >
> > I was wondering whether the GLMM can be fitted with glmmTMB (tweedie
> > distribution) and if so, should I use percent cover or percent cover
> > converted to relative abundance?
> >
> > sp1.glmm <- glmmTMB (sp1 ~ Grazing + (1|Plot), data=cover, family=tweedie
> > (link ="logit"))
> >
> > Any advice would be very much appreciated.
> >
> > Cheers.
> >
> > Vasco Silva
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

	[[alternative HTML version deleted]]


From M@@rten@Jung @ending from m@ilbox@tu-dre@den@de  Sat Dec  1 17:58:11 2018
From: M@@rten@Jung @ending from m@ilbox@tu-dre@den@de (Maarten Jung)
Date: Sat, 1 Dec 2018 17:58:11 +0100
Subject: [R-sig-ME] 
 LMM reduction following marginality taking out "item"
 before "subject:item" grouping factor
In-Reply-To: <CAE9_Wg47bXn-3O0cmyw1n4a134ikpopw8Fhij-aC4X25uAco_A@mail.gmail.com>
References: <CAHr4DydeDW5mR-HNkHqKK22VetQ20AZ-bScnNP-yLLEfrrXeng@mail.gmail.com>
 <CAE9_Wg4XTY+1Kt4kdHWShfYbpA4Us49oj36bakgJnUVF3Jg92g@mail.gmail.com>
 <CAHr4DycXeUR=g+y2ayj9k279gejiGAsirwUdO0oigkiLOJCSSw@mail.gmail.com>
 <CAE9_Wg63ZGgR1ZGut5N5qY4qKexgVc8ADTMDoJt1BtAaDodvGA@mail.gmail.com>
 <CAHr4DycgwzdnKXQSp43pJJJrkiDrELF2PVTeZLCZzizOOj1DiQ@mail.gmail.com>
 <CAE9_Wg6wC=UVCYCYhUqzTDSDBNqjJHGBXncNzvL-n3k4tJXXyQ@mail.gmail.com>
 <CAHr4Dycsqq4nd_-MvSf_FEFzTndpUfYKTaWKkS1AHq-kn-1jEw@mail.gmail.com>
 <CAE9_Wg47bXn-3O0cmyw1n4a134ikpopw8Fhij-aC4X25uAco_A@mail.gmail.com>
Message-ID: <CAHr4DyeFBN6V9MUCUy0yMDPR_Duu0kafhD+gKfdCo6DN0vf0Fg@mail.gmail.com>

Hi Jake,

this clears things up for me - thank you.

Regards,
Maarten

On Thu, Nov 29, 2018 at 3:54 PM Jake Westfall <jake.a.westfall at gmail.com>
wrote:

> Maarten,
>
> Just to double-check if I get this right: the entries in each cell of the
>> table are the numbers by which the variance components are divided in the
>> equation of the noncentrality parameter. Is this correct?
>
>
> Almost. They multiply the variance components, not divide them.
> Essentially each row gives the weights of a weighted sum of variance
> components. Then to translate that to what appears in the denominator of
> the noncentrality parameter, the entire thing is divided by the total
> sample size *and we remove the variance component for the effect in
> question *(I forgot to mention that part in my last email).
>
> For example, consider the simple design with random participants (P)
> nested in fixed groups (G). So g is the number of groups, p is the number
> of participants per group, and # is the number of replicates. (This is
> design 2 in the dropdown menu of examples.) The EMS table shows that, for
> the between-group effect, the coefficients for the error, participant, and
> group variance components are, respectively, 1, #, and #p. So the expected
> mean square is var_error + # * var_participants + # * p * var_groups. The
> total sample size is pg#, so in the noncentrality parameter expression this
> becomes sqrt(var_error / pg# + var_participants / pg). Note that this only
> gives most of the denominator of the of the noncentrality parameter
> expression -- it ignores the variance of the contrast weights -- you can
> see more in the PANGEA working paper, linked in the app.
>
> Jake
>
> On Thu, Nov 29, 2018 at 7:36 AM Maarten Jung <
> Maarten.Jung at mailbox.tu-dresden.de> wrote:
>
>> Hi Jake,
>>
>> So, regarding this issue, there is no difference between taking out
>>>> variance components for main effects before interactions within the same
>>>> grouping factor, e.g. reducing (1 + A*B | subject) to (1 + A:B | subject),
>>>> and taking out the whole grouping factor "item" (i.e. all variance
>>>> components of it) before "subject:item"?
>>>
>>>
>>> I think that if you have strong evidence that this is the appropriate
>>> random effects structure, then it makes sense to modify your model
>>> accordingly, yes.
>>>
>>
>>  This makes sense to me.
>>
>> Do all variances of the random slopes (for interactions and main effects)
>>>> of a single grouping factor contribute to the standard errors of the fixed
>>>> main effects and interactions in the same way?
>>>
>>>
>>> No -- in general, with unbalanced datasets and continuous predictors,
>>> it's hard to say much for sure other than "no." But it can be informative
>>> to think of simpler, approximately balanced ANOVA-like designs where it's
>>> much easier to say much more about which variance components enter which
>>> standard errors and how.
>>>
>>> The standard error for a particular fixed effect is proportional to the
>>> (square root of the) corresponding mean square divided by the total sample
>>> size, that is, by the product of all the factor sample sizes. So examining
>>> the mean square for an effect will tell you which variance components enter
>>> its standard error and which sample sizes they are divided by in the
>>> expression.
>>>
>>
>> Your app is very useful, too. Just to double-check if I get this right:
>> the entries in each cell of the table are the numbers by which the variance
>> components are divided in the equation of the noncentrality parameter. Is
>> this correct?
>>
>>
>> Regards,
>> Maarten
>>
>

	[[alternative HTML version deleted]]


From mollieebrook@ @ending from gm@il@com  Sun Dec  2 15:19:19 2018
From: mollieebrook@ @ending from gm@il@com (Mollie Brooks)
Date: Sun, 2 Dec 2018 15:19:19 +0100
Subject: [R-sig-ME] Fitting GLMM to percent cover data with glmmTMB
In-Reply-To: <CAC8jbZd6Ha887GwdkXyeMAfbfhep5LgssCwH09rQvSNji=Mkig@mail.gmail.com>
References: <CAC8jbZedKU1dj=n1qYRxu306q8wbAqbw5juAnr9k0WB713HfzA@mail.gmail.com>
 <ED14F600-E515-4B06-A1F6-02CB85860F48@gmail.com>
 <CAC8jbZd6Ha887GwdkXyeMAfbfhep5LgssCwH09rQvSNji=Mkig@mail.gmail.com>
Message-ID: <257423E7-1CF2-4B9F-A269-97EBFE6AE17F@gmail.com>

Sorry, I had been thinking that the ziformula in glmmTMB would handle the zeros, but I just realized that, for now, the zeros have to be fit with a separate model because of a call to family$initialize which checks the response variable.  https://github.com/glmmTMB/glmmTMB/issues/355 <https://github.com/glmmTMB/glmmTMB/issues/355>

So for now, you could either fit the hurdle in two separate models in glmmTMB or fit a single model in gamlss.

cheers,
Mollie

> On 30Nov 2018, at 21:21, Vasco Silva <silvadavasco at gmail.com> wrote:
> 
> Thanks Mollie. 
> 
> I convert % cover to relative abundance using "decostand" function and fit the GLMMM but it seems to lack something:
> 
> > sp1.glm1<-glmmTMB(sp1~Grazing+(1|Plot),zi=~0, data=cover,
> +                        family=beta_family(link ="logit"))
> Error in eval(expr, envir, enclos) : y values must be 0 < y < 1
> 
> Cheers.
> 
> Vasco
> 
> Mollie Brooks <mollieebrooks at gmail.com <mailto:mollieebrooks at gmail.com>> escreveu no dia sexta, 30/11/2018 ?(s) 11:21:
> Hi Vasco,
> 
> I mostly agree with what Scott Foster said over on R-sig-eco to your earlier question:
> 
> > I agree with Zoltan that bionimial is probably inappropriate, for the reasons he stated.
> > 
> > I'm not sure that Tweedie is your solution though -- it is defined for non-negative real numbers.
> >  Not just those between 0 and 100%.  Perhaps easiest to think of fish biomass caught in a net (can
> > be zero, or more.
> > 
> > Tweedie might work though, if your percentages are typically nowhere near the 100% boundary.  In
> > this case, the upper end of the support is kind of immaterial...  You hope...
> > 
> > Does glmmTMB supply a beta distribution?  Zero-inflated beta?  The quantile regression idea might be
> > useful too, as Brian suggested, but I'm not sure about random effects in that case.  Beta regression
> > will also have problems with exactly 0% (or 100%) observations.
> 
> I would convert percentages to the 0-1 scale and then try a zero-inflated beta distribution. The Tweedie makes more sense if your response variable is the sum of a bunch of positive values like body weights. 
> 
> You can do a GLMM with a zero-inflated beta distribution in glmmTMB with something like
> 
> m1 <- glmmTMB(sp1 ~ Grazing + (1|Plot), zi=~1, data=cover, family=beta_family())
> m2 <- glmmTMB(sp1 ~ Grazing + (1|Plot), zi=~ Grazing, data=cover, family=beta_family())
> 
> cheers,
> Mollie
> 
> 
> > On 29Nov 2018, at 22:24, Vasco Silva <silvadavasco at gmail.com <mailto:silvadavasco at gmail.com>> wrote:
> > 
> > Hi,
> > 
> > I am trying to fit a GLMM on percent cover for each plant species:
> > 
> >> str(cover)
> > 'data.frame': 100 obs. of  114 variables:
> > $ Plot : Factor w/ 10 levels "P1","P10","P2",..: 1 1 1 1 1 3 3 ...
> > $ Sub.plot: Factor w/ 5 levels "S1","S2","S3",..: 1 2 3 4 5 1 2 ...
> > $ Grazing : Factor w/ 2 levels "Fenced","Unfenced": 1 1 1 1 1 1 1  ...
> > $ sp1 : int  0 0 0 1 0 0 1 ...
> > $ sp2 : int  0 0 0 0 0 3 3 ...
> > $ sp3 : int  0 1 0 0 1 3 3 ...
> > $ sp4 : int  1 3 13 3 3 3 0 ...
> > $ sp6 : int  0 0 0 0 0 0 0 ...
> > ...
> > $ tot  : int  93 65 120 80 138 113 ...
> > 
> > I was wondering whether the GLMM can be fitted with glmmTMB (tweedie
> > distribution) and if so, should I use percent cover or percent cover
> > converted to relative abundance?
> > 
> > sp1.glmm <- glmmTMB (sp1 ~ Grazing + (1|Plot), data=cover, family=tweedie
> > (link ="logit"))
> > 
> > Any advice would be very much appreciated.
> > 
> > Cheers.
> > 
> > Vasco Silva
> > 
> >       [[alternative HTML version deleted]]
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org> mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> 


	[[alternative HTML version deleted]]


From thierry@onkelinx @ending from inbo@be  Sun Dec  2 20:57:44 2018
From: thierry@onkelinx @ending from inbo@be (Thierry Onkelinx)
Date: Sun, 2 Dec 2018 20:57:44 +0100
Subject: [R-sig-ME] 
 Specifying and fitting LME model with unstructured error
 correlation within subject
In-Reply-To: <MWHPR0101MB29907FBAAE88E6DD7281544FE4D30@MWHPR0101MB2990.prod.exchangelabs.com>
References: <MWHPR0101MB29907FBAAE88E6DD7281544FE4D30@MWHPR0101MB2990.prod.exchangelabs.com>
Message-ID: <CAJuCY5x_Wh1yVQE51sh+nsTpXP30V6c-TRWxJptSq2zvX94TPQ@mail.gmail.com>

Dear Kogan,

Add (1|id) as random effect. This will induce a correlation among the
observations from the same individual.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op vr 30 nov. 2018 om 18:20 schreef Kogan, Clark <clark.kogan at wsu.edu>:

> I have some data where a number of individuals have taken a few different
> subtests and there is 1 response per individual for each subtest. I am
> fitting the following model using lmer:
>
> mod <- lmer(score ~ faculty + gender + subtest + gender:subtest +
> faculty:gender + faculty:subtest+ (subtest|id), data = score)
>
> When fitting this model, I get the error:
> Error: number of observations (=219) <= number of random effects (=219)
> for term (subtest | id); the random-effects parameters and the residual
> variance (or scale parameter) are probably unidentifiable
>
> The error makes sense to me - as there is only one data point for every
> subtest*id, and so we cannot differentiate the random effects from the
> residuals. What I would like to be able to do is specify that the residuals
> have an unstructured correlation matrix within individuals to account for
> the fact that an individual will likely have some correlation between their
> subtest scores.
>
> Is there a way to do this in lmer or a similar package so that I can still
> get Kenwood Rodgers or Satterthwaite corrected tests of effects (e.g., with
> pbkrtest or lmerTest).
>
> Thanks,
> Clark
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From kog@n@cl@rk @ending from gm@il@com  Mon Dec  3 00:22:03 2018
From: kog@n@cl@rk @ending from gm@il@com (Clark Kogan)
Date: Sun, 2 Dec 2018 15:22:03 -0800
Subject: [R-sig-ME] 
 Specifying and fitting LME model with unstructured error
 correlation within subject
In-Reply-To: <CAJuCY5x_Wh1yVQE51sh+nsTpXP30V6c-TRWxJptSq2zvX94TPQ@mail.gmail.com>
References: <MWHPR0101MB29907FBAAE88E6DD7281544FE4D30@MWHPR0101MB2990.prod.exchangelabs.com>
 <CAJuCY5x_Wh1yVQE51sh+nsTpXP30V6c-TRWxJptSq2zvX94TPQ@mail.gmail.com>
Message-ID: <CAJXvfGSK0Cy0rKwK4KNZDAVH_DwaU5M5Y1H+AU7UvMdhf93xgg@mail.gmail.com>

Thierry,

I believe this will induce a compound symmetric covariance structure rather
than an unstructured covariance structure. I would like to allow for unique
correlations between different subtests.

Thanks,
Clark


On Sun, Dec 2, 2018 at 11:58 AM Thierry Onkelinx via R-sig-mixed-models <
r-sig-mixed-models at r-project.org> wrote:

> Dear Kogan,
>
> Add (1|id) as random effect. This will induce a correlation among the
> observations from the same individual.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be>
>
>
> Op vr 30 nov. 2018 om 18:20 schreef Kogan, Clark <clark.kogan at wsu.edu>:
>
> > I have some data where a number of individuals have taken a few different
> > subtests and there is 1 response per individual for each subtest. I am
> > fitting the following model using lmer:
> >
> > mod <- lmer(score ~ faculty + gender + subtest + gender:subtest +
> > faculty:gender + faculty:subtest+ (subtest|id), data = score)
> >
> > When fitting this model, I get the error:
> > Error: number of observations (=219) <= number of random effects (=219)
> > for term (subtest | id); the random-effects parameters and the residual
> > variance (or scale parameter) are probably unidentifiable
> >
> > The error makes sense to me - as there is only one data point for every
> > subtest*id, and so we cannot differentiate the random effects from the
> > residuals. What I would like to be able to do is specify that the
> residuals
> > have an unstructured correlation matrix within individuals to account for
> > the fact that an individual will likely have some correlation between
> their
> > subtest scores.
> >
> > Is there a way to do this in lmer or a similar package so that I can
> still
> > get Kenwood Rodgers or Satterthwaite corrected tests of effects (e.g.,
> with
> > pbkrtest or lmerTest).
> >
> > Thanks,
> > Clark
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Mon Dec  3 01:17:44 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Sun, 2 Dec 2018 19:17:44 -0500
Subject: [R-sig-ME] 
 Specifying and fitting LME model with unstructured error
 correlation within subject
In-Reply-To: <CAJXvfGSK0Cy0rKwK4KNZDAVH_DwaU5M5Y1H+AU7UvMdhf93xgg@mail.gmail.com>
References: <MWHPR0101MB29907FBAAE88E6DD7281544FE4D30@MWHPR0101MB2990.prod.exchangelabs.com>
 <CAJuCY5x_Wh1yVQE51sh+nsTpXP30V6c-TRWxJptSq2zvX94TPQ@mail.gmail.com>
 <CAJXvfGSK0Cy0rKwK4KNZDAVH_DwaU5M5Y1H+AU7UvMdhf93xgg@mail.gmail.com>
Message-ID: <CABghstQL9ERGVvrYM_dLXRh5w4rYeAjbRT7SrU0QE3x=wLK33A@mail.gmail.com>

I'd suggest using control=lmerControl(...) to override the error
(something like check.nobs.vs.nRE="ignore", but you can look it up in
the help page ...). Your residual variance and random-effects
variances will indeed be confounded, and I can't say for sure how it
will affect the Kenward-Roger [sic] degrees of freedom calculation,
but the estimates of the fixed effects and their standard errors
should still be correct.

  Actually, if you want Kenward-Roger, that may be the only option I
can think of (other than switching to SAS or something ...) For
various technical reasons previously described on this list (and in
the lme4 paper), it's not possible to force the residual variance to
zero and remove the confounding (or, in fact, to any specified value).
You _can_ fix the residual variance to a very small value (but not
exactly zero) by setting a prior in blme::blmer(), or you can fit a
model without a residual variance in glmmTMB (using dispformula ~ 0),
but ... these models won't work with lmerTest to give you
degrees-of-freedom calculations, as far as I know.
On Sun, Dec 2, 2018 at 6:22 PM Clark Kogan <kogan.clark at gmail.com> wrote:
>
> Thierry,
>
> I believe this will induce a compound symmetric covariance structure rather
> than an unstructured covariance structure. I would like to allow for unique
> correlations between different subtests.
>
> Thanks,
> Clark
>
>
> On Sun, Dec 2, 2018 at 11:58 AM Thierry Onkelinx via R-sig-mixed-models <
> r-sig-mixed-models at r-project.org> wrote:
>
> > Dear Kogan,
> >
> > Add (1|id) as random effect. This will induce a correlation among the
> > observations from the same individual.
> >
> > Best regards,
> >
> > ir. Thierry Onkelinx
> > Statisticus / Statistician
> >
> > Vlaamse Overheid / Government of Flanders
> > INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> > FOREST
> > Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> > thierry.onkelinx at inbo.be
> > Havenlaan 88 bus 73, 1000 Brussel
> > www.inbo.be
> >
> >
> > ///////////////////////////////////////////////////////////////////////////////////////////
> > To call in the statistician after the experiment is done may be no more
> > than asking him to perform a post-mortem examination: he may be able to say
> > what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > The plural of anecdote is not data. ~ Roger Brinner
> > The combination of some data and an aching desire for an answer does not
> > ensure that a reasonable answer can be extracted from a given body of data.
> > ~ John Tukey
> >
> > ///////////////////////////////////////////////////////////////////////////////////////////
> >
> > <https://www.inbo.be>
> >
> >
> > Op vr 30 nov. 2018 om 18:20 schreef Kogan, Clark <clark.kogan at wsu.edu>:
> >
> > > I have some data where a number of individuals have taken a few different
> > > subtests and there is 1 response per individual for each subtest. I am
> > > fitting the following model using lmer:
> > >
> > > mod <- lmer(score ~ faculty + gender + subtest + gender:subtest +
> > > faculty:gender + faculty:subtest+ (subtest|id), data = score)
> > >
> > > When fitting this model, I get the error:
> > > Error: number of observations (=219) <= number of random effects (=219)
> > > for term (subtest | id); the random-effects parameters and the residual
> > > variance (or scale parameter) are probably unidentifiable
> > >
> > > The error makes sense to me - as there is only one data point for every
> > > subtest*id, and so we cannot differentiate the random effects from the
> > > residuals. What I would like to be able to do is specify that the
> > residuals
> > > have an unstructured correlation matrix within individuals to account for
> > > the fact that an individual will likely have some correlation between
> > their
> > > subtest scores.
> > >
> > > Is there a way to do this in lmer or a similar package so that I can
> > still
> > > get Kenwood Rodgers or Satterthwaite corrected tests of effects (e.g.,
> > with
> > > pbkrtest or lmerTest).
> > >
> > > Thanks,
> > > Clark
> > >
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From j@z@vr@kidis m@ili@g off @ki@@l  Mon Dec  3 08:55:58 2018
From: j@z@vr@kidis m@ili@g off @ki@@l (j@z@vr@kidis m@ili@g off @ki@@l)
Date: Mon, 3 Dec 2018 07:55:58 +0000
Subject: [R-sig-ME] GLMM with many and highly correlated features
Message-ID: <973263b39b81448a9435cf19204427a2@EXCH-A02.nki.nl>

Dear all, 

Lately I came upon a very interesting project, which also made me thinking since it was the first time for me to work on such data.
So, I have 2-level data, with 60 participants having 2-3 measurements each, allocated (almost balanced) in two groups, say Y variable. This Y is also my outcome. Then, there are also about 350 features. 
Therefore, the goal is to predict the Y class based on the 350 features. 

Problem: I have around 180 (not independent) observations, and 350 variables. Obviously this will not work... So somehow they have to be reduced

Possible solution : These 350 features are highly correlated in groups, meaning that they can form clusters which give similar information. If we were talking about independent data, then possible solution would be, say PCA, and then building the prediction model with a GLM based on these PCA features (although I never tried something like that, I see it is usual). 

However, Now that ultimately the goal is to use a GLMM, how can this be done ? Can you do PCA (or any variable reduction technique) in 2-level data ? And if yes, can you point me out where to learn about it? 
If this is not possible, can you suggest something that you would do in this case ?

P.S. Since we are talking about a prediction model, is it still valid to assess prediction accuracy with AUC under GLMM ?

Thank you
John Zavrakidis

Junior Researcher - Statistician
Department of Epidemiology and Biostatistics


From thierry@onkelinx @ending from inbo@be  Mon Dec  3 10:38:41 2018
From: thierry@onkelinx @ending from inbo@be (Thierry Onkelinx)
Date: Mon, 3 Dec 2018 10:38:41 +0100
Subject: [R-sig-ME] GLMM with many and highly correlated features
In-Reply-To: <973263b39b81448a9435cf19204427a2@EXCH-A02.nki.nl>
References: <973263b39b81448a9435cf19204427a2@EXCH-A02.nki.nl>
Message-ID: <CAJuCY5xDEexThA-K-mZ-Qk77M2Jyu2FkOUnH571kZQCweAy06Q@mail.gmail.com>

Dear John,

It looks like you have a binomial response variable. And each
participant has either always 0 or always 1 as outcome. Adding
participant as a random effect, will induce complete separation.
Aggregating the data to one observation per participant leaves you
with 60 observations: in case of a balanced design 30 with the outcome
and 30 without. Hence you have about 30 effective observations, which
leaves room for at most 3 (three) parameters to be estimated. So
you'll need a way to reduce your 350 variables down to 3 without
looking at the response variable.

IMHO Tukey's quote in my signature and fortunes::fortune(119) apply.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////



ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




Op ma 3 dec. 2018 om 08:56 schreef <j.zavrakidis at nki.nl>:
>
> Dear all,
>
> Lately I came upon a very interesting project, which also made me thinking since it was the first time for me to work on such data.
> So, I have 2-level data, with 60 participants having 2-3 measurements each, allocated (almost balanced) in two groups, say Y variable. This Y is also my outcome. Then, there are also about 350 features.
> Therefore, the goal is to predict the Y class based on the 350 features.
>
> Problem: I have around 180 (not independent) observations, and 350 variables. Obviously this will not work... So somehow they have to be reduced
>
> Possible solution : These 350 features are highly correlated in groups, meaning that they can form clusters which give similar information. If we were talking about independent data, then possible solution would be, say PCA, and then building the prediction model with a GLM based on these PCA features (although I never tried something like that, I see it is usual).
>
> However, Now that ultimately the goal is to use a GLMM, how can this be done ? Can you do PCA (or any variable reduction technique) in 2-level data ? And if yes, can you point me out where to learn about it?
> If this is not possible, can you suggest something that you would do in this case ?
>
> P.S. Since we are talking about a prediction model, is it still valid to assess prediction accuracy with AUC under GLMM ?
>
> Thank you
> John Zavrakidis
>
> Junior Researcher - Statistician
> Department of Epidemiology and Biostatistics
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From j@z@vr@kidis m@ili@g off @ki@@l  Mon Dec  3 11:42:12 2018
From: j@z@vr@kidis m@ili@g off @ki@@l (j@z@vr@kidis m@ili@g off @ki@@l)
Date: Mon, 3 Dec 2018 10:42:12 +0000
Subject: [R-sig-ME] GLMM with many and highly correlated features
In-Reply-To: <CAJuCY5xDEexThA-K-mZ-Qk77M2Jyu2FkOUnH571kZQCweAy06Q@mail.gmail.com>
References: <973263b39b81448a9435cf19204427a2@EXCH-A02.nki.nl>
 <CAJuCY5xDEexThA-K-mZ-Qk77M2Jyu2FkOUnH571kZQCweAy06Q@mail.gmail.com>
Message-ID: <5ef8b0c671dc466bb512479329f69c92@EXCH-A02.nki.nl>

Dear Thierry,

Thanks for your reply! 

Actually, this is exactly my question! How can I do that ? Is there a way to combine variable-reduction technique with GLMM (in r)? Does PCA work also in the context of GLMM? 

Kind regards,
John

-----Original Message-----
From: Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be] 
Sent: maandag 3 december 2018 10:39
To: John Zavrakidis
Cc: r-sig-mixed-models
Subject: Re: [R-sig-ME] GLMM with many and highly correlated features

Dear John,

It looks like you have a binomial response variable. And each participant has either always 0 or always 1 as outcome. Adding participant as a random effect, will induce complete separation.
Aggregating the data to one observation per participant leaves you with 60 observations: in case of a balanced design 30 with the outcome and 30 without. Hence you have about 30 effective observations, which leaves room for at most 3 (three) parameters to be estimated. So you'll need a way to reduce your 350 variables down to 3 without looking at the response variable.

IMHO Tukey's quote in my signature and fortunes::fortune(119) apply.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance thierry.onkelinx at inbo.be Havenlaan 88 bus 73, 1000 Brussel www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher The plural of anecdote is not data. ~ Roger Brinner The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey ///////////////////////////////////////////////////////////////////////////////////////////



ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance thierry.onkelinx at inbo.be Havenlaan 88 bus 73, 1000 Brussel www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher The plural of anecdote is not data. ~ Roger Brinner The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey ///////////////////////////////////////////////////////////////////////////////////////////




Op ma 3 dec. 2018 om 08:56 schreef <j.zavrakidis at nki.nl>:
>
> Dear all,
>
> Lately I came upon a very interesting project, which also made me thinking since it was the first time for me to work on such data.
> So, I have 2-level data, with 60 participants having 2-3 measurements each, allocated (almost balanced) in two groups, say Y variable. This Y is also my outcome. Then, there are also about 350 features.
> Therefore, the goal is to predict the Y class based on the 350 features.
>
> Problem: I have around 180 (not independent) observations, and 350 
> variables. Obviously this will not work... So somehow they have to be 
> reduced
>
> Possible solution : These 350 features are highly correlated in groups, meaning that they can form clusters which give similar information. If we were talking about independent data, then possible solution would be, say PCA, and then building the prediction model with a GLM based on these PCA features (although I never tried something like that, I see it is usual).
>
> However, Now that ultimately the goal is to use a GLMM, how can this be done ? Can you do PCA (or any variable reduction technique) in 2-level data ? And if yes, can you point me out where to learn about it?
> If this is not possible, can you suggest something that you would do in this case ?
>
> P.S. Since we are talking about a prediction model, is it still valid to assess prediction accuracy with AUC under GLMM ?
>
> Thank you
> John Zavrakidis
>
> Junior Researcher - Statistician
> Department of Epidemiology and Biostatistics
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From d@e@kornbrot @ending from hert@@@c@uk  Mon Dec  3 14:52:26 2018
From: d@e@kornbrot @ending from hert@@@c@uk (Kornbrot, Diana)
Date: Mon, 3 Dec 2018 13:52:26 +0000
Subject: [R-sig-ME] Print Bayes Factor and posterior odds
In-Reply-To: <mailman.17108.8764.1543293072.1179.r-sig-mixed-models@r-project.org>
References: <mailman.17108.8764.1543293072.1179.r-sig-mixed-models@r-project.org>
Message-ID: <E32F02B0-7175-46FD-B156-81E074FAF0D1@herts.ac.uk>

Print Bayes Factor and posterior odds
Have successfully performed bglmer and obtained asme F table as
glmer
bf<- glmer(cbind(freq, Nmax-freq) ~ b1*b2*w1*w2 +(w1|pno)+(w2|pno), data= s4,family=binomial(link=probit))
did not include prior statements, so assume it will do default Wishart

How does one obtain Bayes factors and posterior odds from the object bf created by this script?

bf<- glmer(cbind(freq, Nmax-freq) ~ b1*b2*w1*w2 +(w1|pno)+(w2|pno), data= s4,family=binomial(link=probit)
All help gratefully received
best
Diana

On 27 Nov 2018, at 04:31, r-sig-mixed-models-request at r-project.org<mailto:r-sig-mixed-models-request at r-project.org> wrote:

Send R-sig-mixed-models mailing list submissions to
r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>

To subscribe or unsubscribe via the World Wide Web, visit
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
or, via email, send a message with subject or body 'help' to
r-sig-mixed-models-request at r-project.org

You can reach the person managing the list at
r-sig-mixed-models-owner at r-project.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-mixed-models digest..."


Today's Topics:

  1. Re: diverging results with and without random effects
     (Leha, Andreas)

----------------------------------------------------------------------

Message: 1
Date: Tue, 27 Nov 2018 04:30:55 +0000
From: "Leha, Andreas" <andreas.leha at med.uni-goettingen.de>
To: Thierry Onkelinx <thierry.onkelinx at inbo.be>
Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] diverging results with and without random
effects
Message-ID:
<d6c3e41b-3f92-2c06-15e4-3fb687687d96 at med.uni-goettingen.de>
Content-Type: text/plain; charset="utf-8"

Dear Thierry and all,

Thanks for your continued help here.  I am not versed with Bayesian
analyses.

Below is the code I currently use.  The priors are basically due to
trial and error until I got expected/reasonable results.

Therefor I would be grateful for some comments on the
(in-)appropriateness of my (quite extreme) parameters.

As cov.prior I used
 invwishart(df = 50, scale = diag(0.5, 1))

Thanks in advance!

Regards,
Andreas


PS: The code/results


library("blme")
dat %>%
 bglmer(group ~ riskfactor + fu + riskfactor:fu + (1|patient),
        family = "binomial",
        data = .,
        cov.prior = invwishart(df = 50, scale = diag(0.5, 1)),
        fixef.prior = normal(cov = diag(9,4))) %>%
 summary
## ,----
## | Cov prior  : patient ~ invwishart(df = 50, scale = 0.5,
## |                  posterior.scale = cov, common.scale = TRUE)
## | Fixef prior: normal(sd = c(3, 3, ...), corr = c(0 ...),
## |                  common.scale = FALSE)
## | Prior dev  : 6.2087
## |
## | Generalized linear mixed model fit by maximum likelihood (Laplace
## |   Approximation) [bglmerMod]
## |  Family: binomial  ( logit )
## | Formula: group ~ riskfactor + fu + riskfactor:fu + (1 | patient)
## |    Data: .
## |
## |      AIC      BIC   logLik deviance df.resid
## |    540.0    560.8   -265.0    530.0      470
## |
## | Scaled residuals:
## |     Min      1Q  Median      3Q     Max
## | -2.4984 -0.8512  0.3979  0.5038  1.6228
## |
## | Random effects:
## |  Groups  Name        Variance Std.Dev.
## |  patient (Intercept) 0.009725 0.09862
## | Number of obs: 475, groups:  patient, 265
## |
## | Fixed effects:
## |                       Estimate Std. Error z value Pr(>|z|)
## | (Intercept)             1.3679     0.2355   5.810 6.26e-09 ***
## | riskfactornorisk       -1.6776     0.2868  -5.850 4.91e-09 ***
## | fuFU                    0.4718     0.3738   1.262   0.2069
## | riskfactornorisk:fuFU  -1.1375     0.4539  -2.506   0.0122 *
## | ---
## | Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
## |
## | Correlation of Fixed Effects:
## |             (Intr) rskfct fuFU
## | rskfctrnrsk -0.816
## | fuFU        -0.617  0.502
## | rskfctrn:FU  0.503 -0.618 -0.817
## `----




On 26/11/18 17:05, Thierry Onkelinx wrote:
Dear Andreas,

You'll need a very informative prior for the random intercept variance
in order to keep the random intercepts reasonable small.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be <http://www.inbo.be>

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op ma 26 nov. 2018 om 17:00 schreef Leha, Andreas
<andreas.leha at med.uni-goettingen.de
<mailto:andreas.leha at med.uni-goettingen.de>>:

   Dear Thierry,

   thanks for looking into this!

   So, one solution would be a baysian analysis, right?

   Would you have a recommendation for me?

   I followed [1] and used

     library("blme")
     dat %>%
       bglmer(group ~ riskfactor + fu + riskfactor:fu + (1|patient),
              family = "binomial",
              data = .,
              fixef.prior = normal(cov = diag(9,4))) %>%
       summary

   Which runs and gives the following fixed effect estimates:


     Fixed effects:
                           Estimate Std. Error z value Pr(>|z|)
     (Intercept)             8.2598     0.7445  11.094   <2e-16 ***
     riskfactornorisk      -16.0942     1.3085 -12.300   <2e-16 ***
     fuFU                    1.0019     1.0047   0.997    0.319
     riskfactornorisk:fuFU  -1.8675     1.2365  -1.510    0.131


   These still do not seem reasonable.

   Thanks in advance!

   Regards,
   Andreas


   [1]
   https://stats.stackexchange.com/questions/132677/binomial-glmm-with-a-categorical-variable-with-full-successes/132678#132678


   On 26/11/18 16:36, Thierry Onkelinx wrote:
Dear Andreas,

This is due to quasi complete separatation. This occurs when all
responses for a specific combination of levels are always TRUE or
   FALSE.
In your case, you have only two observations per patient. Hence adding
the patient as random effect, guarantees quasi complete separation
   issues.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>
   <mailto:thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>>
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be <http://www.inbo.be> <http://www.inbo.be>


   ///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
   more
than asking him to perform a post-mortem examination: he may be
   able to
say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer
   does not
ensure that a reasonable answer can be extracted from a given body of
data. ~ John Tukey

   ///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op ma 26 nov. 2018 om 13:48 schreef Leha, Andreas
<andreas.leha at med.uni-goettingen.de
   <mailto:andreas.leha at med.uni-goettingen.de>
<mailto:andreas.leha at med.uni-goettingen.de
   <mailto:andreas.leha at med.uni-goettingen.de>>>:

     Hi all,

     sent the wrong code (w/o filtering for BL).  If you want to
   look at the
     data, please use this code:

     ---------- cut here --------------------------------------------
     library("dplyr")
     library("lme4")
     library("lmerTest")
     ## install_github("hrbrmstr/pastebin", upgrade_dependencies =
   FALSE)
     library("pastebin")

     ## ---------------------------------- ##
     ## load the data                      ##
     ## ---------------------------------- ##
     dat <- pastebin::get_paste("Xgwgtb7j") %>% as.character %>%
   gsub("\r\n",
     "", .) %>% parse(text = .) %>% eval



     ## ---------------------------------- ##
     ## have a look                        ##
     ## ---------------------------------- ##
     dat
     ## ,----
     ## | # A tibble: 475 x 4
     ## |    patient group fu    riskfactor
     ## |    <fct>   <fct> <fct> <fct>
     ## |  1 p001    wt    BL    norisk
     ## |  2 p002    wt    BL    norisk
     ## |  3 p003    wt    BL    norisk
     ## |  4 p004    wt    BL    norisk
     ## |  5 p005    wt    BL    norisk
     ## |  6 p006    wt    BL    norisk
     ## |  7 p007    wt    BL    norisk
     ## |  8 p008    wt    BL    norisk
     ## |  9 p009    wt    BL    risk
     ## | 10 p010    wt    BL    norisk
     ## | # ... with 465 more rows
     ## `----
     dat %>% str
     ## ,----
     ## | Classes ?tbl_df?, ?tbl? and 'data.frame':  475 obs. of  4
     variables:
     ## |  $ patient   : Factor w/ 265 levels "p001","p002",..: 1 2
   3 4 5 6 7
     8 9 10 ...
     ## |  $ group     : Factor w/ 2 levels "wt","mut": 1 1 1 1 1 1
   1 1 1
     1 ...
     ## |  $ fu        : Factor w/ 2 levels "BL","FU": 1 1 1 1 1 1
   1 1 1
     1 ...
     ## |  $ riskfactor: Factor w/ 2 levels "risk","norisk": 2 2 2
   2 2 2 2 2
     1 2 ...
     ## `----

     ## there are 265 patients
     ## in 2 groups: "wt" and "mut"
     ## with a dichotomous risk factor ("risk" and "norisk")
     ## measured at two time points ("BL" and "FU")

     dat %>% summary
     ## ,----
     ## |     patient    group      fu       riskfactor
     ## |  p001   :  2   wt :209   BL:258   risk  :205
     ## |  p002   :  2   mut:266   FU:217   norisk:270
     ## |  p003   :  2
     ## |  p004   :  2
     ## |  p005   :  2
     ## |  p006   :  2
     ## |  (Other):463
     ## `----

     ## group sizes seem fine



     ## ---------------------------------------------- ##
     ## first, we look at the first time point, the BL ##
     ## ---------------------------------------------- ##

     ## we build a cross table
     tab_bl <-
       dat %>%
       dplyr::filter(fu == "BL") %>%
       dplyr::select(group, riskfactor) %>%
       table
     tab_bl
     ## ,----
     ## |      riskfactor
     ## | group risk norisk
     ## |   wt    22     86
     ## |   mut   87     63
     ## `----

     ## and we test using fisher:
     tab_bl %>% fisher.test
     ## ,----
     ## |    Fisher's Exact Test for Count Data
     ## |
     ## | data:  .
     ## | p-value = 1.18e-09
     ## | alternative hypothesis: true odds ratio is not equal to 1
     ## | 95 percent confidence interval:
     ## |  0.09986548 0.33817966
     ## | sample estimates:
     ## | odds ratio
     ## |  0.1865377
     ## `----
     log(0.187)
     ## ,----
     ## | [1] -1.676647
     ## `----

     ## so, we get a highly significant association of the riskfactor
     ## and the group with an log(odds ratio) of -1.7

     ## we get the same result using logistic regression:
     dat %>%
       filter(fu == "BL") %>%
       glm(group ~ riskfactor, family = "binomial", data = .) %>%
       summary
     ## ,----
     ## | Call:
     ## | glm(formula = group ~ riskfactor, family = "binomial",
   data = .)
     ## |
     ## | Deviance Residuals:
     ## |     Min       1Q   Median       3Q      Max
     ## | -1.7890  -1.0484   0.6715   0.6715   1.3121
     ## |
     ## | Coefficients:
     ## |                  Estimate Std. Error z value Pr(>|z|)
     ## | (Intercept)        1.3749     0.2386   5.761 8.35e-09 ***
     ## | riskfactornorisk  -1.6861     0.2906  -5.802 6.55e-09 ***
     ## | ---
     ## | Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1
   ? ? 1
     ## |
     ## | (Dispersion parameter for binomial family taken to be 1)
     ## |
     ## |     Null deviance: 350.80  on 257  degrees of freedom
     ## | Residual deviance: 312.63  on 256  degrees of freedom
     ## | AIC: 316.63
     ## |
     ## | Number of Fisher Scoring iterations: 4
     ## `----



     ## ------------------------------------------------- ##
     ## Now, we analyse both time points with interaction ##
     ## ------------------------------------------------- ##

     dat %>%
       glmer(group ~ riskfactor + fu + riskfactor:fu + (1|patient),
   family =
     "binomial", data = .) %>%
       summary
     ## ,----
     ## | Generalized linear mixed model fit by maximum likelihood
   (Laplace
     ## |   Approximation) [glmerMod]
     ## |  Family: binomial  ( logit )
     ## | Formula: group ~ riskfactor + fu + riskfactor:fu + (1 |
   patient)
     ## |    Data: .
     ## |
     ## |      AIC      BIC   logLik deviance df.resid
     ## |    345.2    366.0   -167.6    335.2      470
     ## |
     ## | Scaled residuals:
     ## |       Min        1Q    Median        3Q       Max
     ## | -0.095863 -0.058669  0.002278  0.002866  0.007324
     ## |
     ## | Random effects:
     ## |  Groups  Name        Variance Std.Dev.
     ## |  patient (Intercept) 1849     43
     ## | Number of obs: 475, groups:  patient, 265
     ## |
     ## | Fixed effects:
     ## |                       Estimate Std. Error z value Pr(>|z|)
     ## | (Intercept)            11.6846     1.3736   8.507
    <2e-16 ***
     ## | riskfactornorisk       -1.5919     1.4166  -1.124    0.261
     ## | fuFU                    0.4596     1.9165   0.240    0.810
     ## | riskfactornorisk:fuFU  -0.8183     2.1651  -0.378    0.705
     ## | ---
     ## | Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1
   ? ? 1
     ## |
     ## | Correlation of Fixed Effects:
     ## |             (Intr) rskfct fuFU
     ## | rskfctrnrsk -0.746
     ## | fuFU        -0.513  0.510
     ## | rskfctrn:FU  0.478 -0.576 -0.908
     ## `----

     ## I get huge variation in the random effects
     ##
     ## And the risk factor at BL gets an estimated log(odds ratio)
   of -1.6
     ## but one which is not significant
     ---------- cut here --------------------------------------------


     On 26/11/18 12:10, Leha, Andreas wrote:
     > Hi all,
     >
     > I am interested in assessing the association of a
   (potential) risk
     > factor to a (binary) grouping.
     >
     > I am having trouble with diverging results from modeling one
   time
     point
     > (without random effect) and modeling two time points (with
   random
     effect).
     >
     > When analysing the first time point (base line, BL) only, I
   get a
     highly
     > significant association.
     > Now, I want to see, whether there is an interaction between
   time and
     > risk factor (the risk factor is not constant).  But when
   analysing
     both
     > time points, the estimated effect at BL is estimated to be not
     significant.
     >
     > Now my simplified questions are:
     > (1) Is there an association at BL or not?
     > (2) How should I analyse both time points with this data?
     >
     > The aim is to look for confounding with other factors.  But I'd
     like to
     > understand the simple models before moving on.
     >
     > Below you find a reproducible example and the detailed results.
     >
     > Any suggestions would be highly appreciated!
     >
     > Regards,
     > Andreas
     >
     >
     >
     > PS: The code / results
     >
     > ---------- cut here --------------------------------------------
     > library("dplyr")
     > library("lme4")
     > library("lmerTest")
     > ## install_github("hrbrmstr/pastebin", upgrade_dependencies
   = FALSE)
     > library("pastebin")
     >
     > ## ---------------------------------- ##
     > ## load the data                      ##
     > ## ---------------------------------- ##
     > dat <- pastebin::get_paste("Xgwgtb7j") %>%
     >   as.character %>%
     >   gsub("\r\n", "", .) %>%
     >   parse(text = .) %>%
     >   eval
     >
     >
     >
     > ## ---------------------------------- ##
     > ## have a look                        ##
     > ## ---------------------------------- ##
     > dat
     > ## ,----
     > ## | # A tibble: 475 x 4
     > ## |    patient group fu    riskfactor
     > ## |    <fct>   <fct> <fct> <fct>
     > ## |  1 p001    wt    BL    norisk
     > ## |  2 p002    wt    BL    norisk
     > ## |  3 p003    wt    BL    norisk
     > ## |  4 p004    wt    BL    norisk
     > ## |  5 p005    wt    BL    norisk
     > ## |  6 p006    wt    BL    norisk
     > ## |  7 p007    wt    BL    norisk
     > ## |  8 p008    wt    BL    norisk
     > ## |  9 p009    wt    BL    risk
     > ## | 10 p010    wt    BL    norisk
     > ## | # ... with 465 more rows
     > ## `----
     > dat %>% str
     > ## ,----
     > ## | Classes ?tbl_df?, ?tbl? and 'data.frame':        475
   obs. of
     4 variables:
     > ## |  $ patient   : Factor w/ 265 levels "p001","p002",..: 1
   2 3 4
     5 6 7
     > 8 9 10 ...
     > ## |  $ group     : Factor w/ 2 levels "wt","mut": 1 1 1 1 1
   1 1 1
     1 1 ...
     > ## |  $ fu        : Factor w/ 2 levels "BL","FU": 1 1 1 1 1
   1 1 1
     1 1 ...
     > ## |  $ riskfactor: Factor w/ 2 levels "risk","norisk": 2 2
   2 2 2
     2 2 2
     > 1 2 ...
     > ## `----
     >
     > ## there are 265 patients
     > ## in 2 groups: "wt" and "mut"
     > ## with a dichotomous risk factor ("risk" and "norisk")
     > ## measured at two time points ("BL" and "FU")
     >
     > dat %>% summary
     > ## ,----
     > ## |     patient    group      fu       riskfactor
     > ## |  p001   :  2   wt :209   BL:258   risk  :205
     > ## |  p002   :  2   mut:266   FU:217   norisk:270
     > ## |  p003   :  2
     > ## |  p004   :  2
     > ## |  p005   :  2
     > ## |  p006   :  2
     > ## |  (Other):463
     > ## `----
     >
     > ## group sizes seem fine
     >
     >
     >
     > ## ---------------------------------------------- ##
     > ## first, we look at the first time point, the BL ##
     > ## ---------------------------------------------- ##
     >
     > ## we build a cross table
     > tab_bl <-
     >   dat %>%
     >   dplyr::select(group, riskfactor) %>%
     >   table
     > tab_bl
     > ## ,----
     > ## |      riskfactor
     > ## | group risk norisk
     > ## |   wt    35    174
     > ## |   mut  170     96
     > ## `----
     >
     > ## and we test using fisher:
     > tab_bl %>% fisher.test
     > ## ,----
     > ## |    Fisher's Exact Test for Count Data
     > ## |
     > ## | data:  .
     > ## | p-value < 2.2e-16
     > ## | alternative hypothesis: true odds ratio is not equal to 1
     > ## | 95 percent confidence interval:
     > ## |  0.07099792 0.18002325
     > ## | sample estimates:
     > ## | odds ratio
     > ## |  0.1141677
     > ## `----
     > log(0.114)
     > ## ,----
     > ## | [1] -2.171557
     > ## `----
     >
     > ## so, we get a highly significant association of the riskfactor
     > ## and the group with an log(odds ratio) of -2.2
     >
     > ## we get the same result using logistic regression:
     > dat %>%
     >   glm(group ~ riskfactor, family = "binomial", data = .) %>%
     >   summary
     > ## ,----
     > ## |
     > ## | Call:
     > ## | glm(formula = group ~ riskfactor, family = "binomial",
   data = .)
     > ## |
     > ## | Deviance Residuals:
     > ## |     Min       1Q   Median       3Q      Max
     > ## | -1.8802  -0.9374   0.6119   0.6119   1.4381
     > ## |
     > ## | Coefficients:
     > ## |                  Estimate Std. Error z value Pr(>|z|)
     > ## | (Intercept)        1.5805     0.1856   8.515   <2e-16 ***
     > ## | riskfactornorisk  -2.1752     0.2250  -9.668   <2e-16 ***
     > ## | ---
     > ## | Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.?
   0.1 ? ? 1
     > ## |
     > ## | (Dispersion parameter for binomial family taken to be 1)
     > ## |
     > ## |     Null deviance: 651.63  on 474  degrees of freedom
     > ## | Residual deviance: 538.83  on 473  degrees of freedom
     > ## | AIC: 542.83
     > ## |
     > ## | Number of Fisher Scoring iterations: 4
     > ## `----
     >
     >
     >
     > ## ------------------------------------------------- ##
     > ## Now, we analyse both time points with interaction ##
     > ## ------------------------------------------------- ##
     >
     > dat %>%
     >   glmer(group ~ riskfactor + fu + riskfactor:fu + (1|patient),
     family =
     > "binomial", data = .) %>%
     >   summary
     > ## ,----
     > ## | Generalized linear mixed model fit by maximum
   likelihood (Laplace
     > ## |   Approximation) [glmerMod]
     > ## |  Family: binomial  ( logit )
     > ## | Formula: group ~ riskfactor + fu + riskfactor:fu + (1 |
   patient)
     > ## |    Data: .
     > ## |
     > ## |      AIC      BIC   logLik deviance df.resid
     > ## |    345.2    366.0   -167.6    335.2      470
     > ## |
     > ## | Scaled residuals:
     > ## |       Min        1Q    Median        3Q       Max
     > ## | -0.095863 -0.058669  0.002278  0.002866  0.007324
     > ## |
     > ## | Random effects:
     > ## |  Groups  Name        Variance Std.Dev.
     > ## |  patient (Intercept) 1849     43
     > ## | Number of obs: 475, groups:  patient, 265
     > ## |
     > ## | Fixed effects:
     > ## |                       Estimate Std. Error z value Pr(>|z|)
     > ## | (Intercept)            11.6846     1.3736   8.507
    <2e-16 ***
     > ## | riskfactornorisk       -1.5919     1.4166  -1.124    0.261
     > ## | fuFU                    0.4596     1.9165   0.240    0.810
     > ## | riskfactornorisk:fuFU  -0.8183     2.1651  -0.378    0.705
     > ## | ---
     > ## | Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.?
   0.1 ? ? 1
     > ## |
     > ## | Correlation of Fixed Effects:
     > ## |             (Intr) rskfct fuFU
     > ## | rskfctrnrsk -0.746
     > ## | fuFU        -0.513  0.510
     > ## | rskfctrn:FU  0.478 -0.576 -0.908
     > ## `----
     >
     > ## I get huge variation in the random effects
     > ##
     > ## And the risk factor at BL gets an estimated log(odds
   ratio) of -1.6
     > ## but one which is not significant
     > ---------- cut here --------------------------------------------
     > _______________________________________________
     > R-sig-mixed-models at r-project.org
   <mailto:R-sig-mixed-models at r-project.org>
     <mailto:R-sig-mixed-models at r-project.org
   <mailto:R-sig-mixed-models at r-project.org>> mailing list
     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
     >

     --
     Dr. Andreas Leha
     Head of the 'Core Facility
     Medical Biometry and Statistical Bioinformatics'

     UNIVERSITY MEDICAL CENTER G?TTINGEN
     GEORG-AUGUST-UNIVERSIT?T
     Department of Medical Statistics
     Humboldtallee 32
     37073 G?ttingen
     Mailing Address: 37099 G?ttingen, Germany
     Fax: +49 (0) 551 39-4995
     Tel: +49 (0) 551 39-4987
     http://www.ams.med.uni-goettingen.de/service-de.shtml
     _______________________________________________
     R-sig-mixed-models at r-project.org
   <mailto:R-sig-mixed-models at r-project.org>
     <mailto:R-sig-mixed-models at r-project.org
   <mailto:R-sig-mixed-models at r-project.org>> mailing list
     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


   --
   Dr. Andreas Leha
   Head of the 'Core Facility
   Medical Biometry and Statistical Bioinformatics'

   UNIVERSITY MEDICAL CENTER G?TTINGEN
   GEORG-AUGUST-UNIVERSIT?T
   Department of Medical Statistics
   Humboldtallee 32
   37073 G?ttingen
   Mailing Address: 37099 G?ttingen, Germany
   Fax: +49 (0) 551 39-4995
   Tel: +49 (0) 551 39-4987
   http://www.ams.med.uni-goettingen.de/service-de.shtml


--
Dr. Andreas Leha
Head of the 'Core Facility
Medical Biometry and Statistical Bioinformatics'

UNIVERSITY MEDICAL CENTER G?TTINGEN
GEORG-AUGUST-UNIVERSIT?T
Department of Medical Statistics
Humboldtallee 32
37073 G?ttingen
Mailing Address: 37099 G?ttingen, Germany
Fax: +49 (0) 551 39-4995
Tel: +49 (0) 551 39-4987
http://www.ams.med.uni-goettingen.de/service-de.shtml

------------------------------

Subject: Digest Footer

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


------------------------------

End of R-sig-mixed-models Digest, Vol 143, Issue 41
***************************************************

_____________________________________
Professor Diana Kornbrot
Mobile
+44 (0) 7403 18 16 12
Work
University of Hertfordshire
College Lane, Hatfield, Hertfordshire AL10 9AB, UK
+44 (0) 170 728 4626
d.e.kornbrot at herts.ac.uk<mailto:d.e.kornbrot at herts.ac.uk>
http://dianakornbrot.wordpress.com/
http://go.herts.ac.uk/Diana_Kornbrot
skype:  kornbrotme
Home
19 Elmhurst Avenue
London N2 0LT, UK
+44 (0) 208 444 2081
 ------------------------------------------------------------




	[[alternative HTML version deleted]]


From thierry@onkelinx @ending from inbo@be  Mon Dec  3 21:26:27 2018
From: thierry@onkelinx @ending from inbo@be (Thierry Onkelinx)
Date: Mon, 3 Dec 2018 21:26:27 +0100
Subject: [R-sig-ME] GLMM with many and highly correlated features
In-Reply-To: <5ef8b0c671dc466bb512479329f69c92@EXCH-A02.nki.nl>
References: <973263b39b81448a9435cf19204427a2@EXCH-A02.nki.nl>
 <CAJuCY5xDEexThA-K-mZ-Qk77M2Jyu2FkOUnH571kZQCweAy06Q@mail.gmail.com>
 <5ef8b0c671dc466bb512479329f69c92@EXCH-A02.nki.nl>
Message-ID: <CAJuCY5xcK2x=drc1dqcSKbXpp5uzyXAffQcD8p3Rj_4mvMBKtQ@mail.gmail.com>

Dear John,

As I said before, a GLMM is out of the question due to complete
separation. Hence a simple GLM would be sufficient.

IMHO you first need to reduce the dimensionalty of the covariates from
350 down to 3(!), and then fit the GLM. Using the response in this
selection is cheating.

You could use the first 3 PCA axes to reduce the dimensionality. But
the interpretation of those axis would be hard.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////



Op ma 3 dec. 2018 om 11:42 schreef <j.zavrakidis at nki.nl>:
>
> Dear Thierry,
>
> Thanks for your reply!
>
> Actually, this is exactly my question! How can I do that ? Is there a way to combine variable-reduction technique with GLMM (in r)? Does PCA work also in the context of GLMM?
>
> Kind regards,
> John
>
> -----Original Message-----
> From: Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be]
> Sent: maandag 3 december 2018 10:39
> To: John Zavrakidis
> Cc: r-sig-mixed-models
> Subject: Re: [R-sig-ME] GLMM with many and highly correlated features
>
> Dear John,
>
> It looks like you have a binomial response variable. And each participant has either always 0 or always 1 as outcome. Adding participant as a random effect, will induce complete separation.
> Aggregating the data to one observation per participant leaves you with 60 observations: in case of a balanced design 30 with the outcome and 30 without. Hence you have about 30 effective observations, which leaves room for at most 3 (three) parameters to be estimated. So you'll need a way to reduce your 350 variables down to 3 without looking at the response variable.
>
> IMHO Tukey's quote in my signature and fortunes::fortune(119) apply.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance thierry.onkelinx at inbo.be Havenlaan 88 bus 73, 1000 Brussel www.inbo.be
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher The plural of anecdote is not data. ~ Roger Brinner The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey ///////////////////////////////////////////////////////////////////////////////////////////
>
>
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance thierry.onkelinx at inbo.be Havenlaan 88 bus 73, 1000 Brussel www.inbo.be
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher The plural of anecdote is not data. ~ Roger Brinner The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey ///////////////////////////////////////////////////////////////////////////////////////////
>
>
>
>
> Op ma 3 dec. 2018 om 08:56 schreef <j.zavrakidis at nki.nl>:
> >
> > Dear all,
> >
> > Lately I came upon a very interesting project, which also made me thinking since it was the first time for me to work on such data.
> > So, I have 2-level data, with 60 participants having 2-3 measurements each, allocated (almost balanced) in two groups, say Y variable. This Y is also my outcome. Then, there are also about 350 features.
> > Therefore, the goal is to predict the Y class based on the 350 features.
> >
> > Problem: I have around 180 (not independent) observations, and 350
> > variables. Obviously this will not work... So somehow they have to be
> > reduced
> >
> > Possible solution : These 350 features are highly correlated in groups, meaning that they can form clusters which give similar information. If we were talking about independent data, then possible solution would be, say PCA, and then building the prediction model with a GLM based on these PCA features (although I never tried something like that, I see it is usual).
> >
> > However, Now that ultimately the goal is to use a GLMM, how can this be done ? Can you do PCA (or any variable reduction technique) in 2-level data ? And if yes, can you point me out where to learn about it?
> > If this is not possible, can you suggest something that you would do in this case ?
> >
> > P.S. Since we are talking about a prediction model, is it still valid to assess prediction accuracy with AUC under GLMM ?
> >
> > Thank you
> > John Zavrakidis
> >
> > Junior Researcher - Statistician
> > Department of Epidemiology and Biostatistics
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From d@rizopoulo@ @ending from er@@mu@mc@nl  Tue Dec  4 09:33:49 2018
From: d@rizopoulo@ @ending from er@@mu@mc@nl (D. Rizopoulos)
Date: Tue, 4 Dec 2018 08:33:49 +0000
Subject: [R-sig-ME] GLMM with many and highly correlated features
In-Reply-To: <CAJuCY5xcK2x=drc1dqcSKbXpp5uzyXAffQcD8p3Rj_4mvMBKtQ@mail.gmail.com>
References: <973263b39b81448a9435cf19204427a2@EXCH-A02.nki.nl>
 <CAJuCY5xDEexThA-K-mZ-Qk77M2Jyu2FkOUnH571kZQCweAy06Q@mail.gmail.com>
 <5ef8b0c671dc466bb512479329f69c92@EXCH-A02.nki.nl>
 <CAJuCY5xcK2x=drc1dqcSKbXpp5uzyXAffQcD8p3Rj_4mvMBKtQ@mail.gmail.com>
Message-ID: <64a5b17c-1dc2-9bef-cf60-e9ca47246a80@erasmusmc.nl>

Indeed, the data do not seem to have a lot of information, but still 
this is a problem that is nowadays often encountered in practice, and 
for which methodology has been developed. For example, glmnet 
(https://cran.r-project.org/package=glmnet) could be of use here.

Best,
Dimitris


On 12/3/2018 9:26 PM, Thierry Onkelinx via R-sig-mixed-models wrote:
> Dear John,
> 
> As I said before, a GLMM is out of the question due to complete
> separation. Hence a simple GLM would be sufficient.
> 
> IMHO you first need to reduce the dimensionalty of the covariates from
> 350 down to 3(!), and then fit the GLM. Using the response in this
> selection is cheating.
> 
> You could use the first 3 PCA axes to reduce the dimensionality. But
> the interpretation of those axis would be hard.
> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Statisticus / Statistician
> 
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> AND FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
> 
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body
> of data. ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
> 
> 
> 
> Op ma 3 dec. 2018 om 11:42 schreef <j.zavrakidis at nki.nl>:
>>
>> Dear Thierry,
>>
>> Thanks for your reply!
>>
>> Actually, this is exactly my question! How can I do that ? Is there a way to combine variable-reduction technique with GLMM (in r)? Does PCA work also in the context of GLMM?
>>
>> Kind regards,
>> John
>>
>> -----Original Message-----
>> From: Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be]
>> Sent: maandag 3 december 2018 10:39
>> To: John Zavrakidis
>> Cc: r-sig-mixed-models
>> Subject: Re: [R-sig-ME] GLMM with many and highly correlated features
>>
>> Dear John,
>>
>> It looks like you have a binomial response variable. And each participant has either always 0 or always 1 as outcome. Adding participant as a random effect, will induce complete separation.
>> Aggregating the data to one observation per participant leaves you with 60 observations: in case of a balanced design 30 with the outcome and 30 without. Hence you have about 30 effective observations, which leaves room for at most 3 (three) parameters to be estimated. So you'll need a way to reduce your 350 variables down to 3 without looking at the response variable.
>>
>> IMHO Tukey's quote in my signature and fortunes::fortune(119) apply.
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance thierry.onkelinx at inbo.be Havenlaan 88 bus 73, 1000 Brussel www.inbo.be
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher The plural of anecdote is not data. ~ Roger Brinner The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey ///////////////////////////////////////////////////////////////////////////////////////////
>>
>>
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance thierry.onkelinx at inbo.be Havenlaan 88 bus 73, 1000 Brussel www.inbo.be
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher The plural of anecdote is not data. ~ Roger Brinner The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey ///////////////////////////////////////////////////////////////////////////////////////////
>>
>>
>>
>>
>> Op ma 3 dec. 2018 om 08:56 schreef <j.zavrakidis at nki.nl>:
>>>
>>> Dear all,
>>>
>>> Lately I came upon a very interesting project, which also made me thinking since it was the first time for me to work on such data.
>>> So, I have 2-level data, with 60 participants having 2-3 measurements each, allocated (almost balanced) in two groups, say Y variable. This Y is also my outcome. Then, there are also about 350 features.
>>> Therefore, the goal is to predict the Y class based on the 350 features.
>>>
>>> Problem: I have around 180 (not independent) observations, and 350
>>> variables. Obviously this will not work... So somehow they have to be
>>> reduced
>>>
>>> Possible solution : These 350 features are highly correlated in groups, meaning that they can form clusters which give similar information. If we were talking about independent data, then possible solution would be, say PCA, and then building the prediction model with a GLM based on these PCA features (although I never tried something like that, I see it is usual).
>>>
>>> However, Now that ultimately the goal is to use a GLMM, how can this be done ? Can you do PCA (or any variable reduction technique) in 2-level data ? And if yes, can you point me out where to learn about it?
>>> If this is not possible, can you suggest something that you would do in this case ?
>>>
>>> P.S. Since we are talking about a prediction model, is it still valid to assess prediction accuracy with AUC under GLMM ?
>>>
>>> Thank you
>>> John Zavrakidis
>>>
>>> Junior Researcher - Statistician
>>> Department of Epidemiology and Biostatistics
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
Dimitris Rizopoulos
Professor of Biostatistics
Department of Biostatistics
Erasmus University Medical Center

Address: PO Box 2040, 3000 CA Rotterdam, the Netherlands
Tel: +31/(0)10/7043478
Fax: +31/(0)10/7043014
Web (personal): http://www.drizopoulos.com/
Web (work): http://www.erasmusmc.nl/biostatistiek/
Blog: http://iprogn.blogspot.nl/

From @@chiin@mh @ending from gm@il@com  Tue Dec  4 22:58:27 2018
From: @@chiin@mh @ending from gm@il@com (Sachiin M H)
Date: Tue, 4 Dec 2018 16:58:27 -0500
Subject: [R-sig-ME] Please help me to interpret this result
Message-ID: <CAF2JtxdsA3VBKnFb6MjEPPAreGb2ur_Q_sBaxETM9zK7LjECww@mail.gmail.com>

Hi,
objective - to examine neighbourhood effects on individual survival at
multiple life history stages.

Kindly help me to interpret the results such as
survival rates of sapling = ...... , Juvenile= ........, adult= ......



Metadata

survival= alive 0 and dead 1, size = sapling, adult and juvenile, con
and het = con and heterospecific density at 5 m radius, INT = 1,2,3
census interval, sp= species codes, quadrat = 5 1ha sites *100
(10*10m) subplots.




summary(model5)Generalized linear mixed model fit by maximum
likelihood (Laplace Approximation) ['glmerMod']
 Family: binomial  ( cloglog )
Formula: survival ~ size + CON_5 + HET_5 + INT + (1 + size | sp) + (1
|      quadrat)
   Data: sf
 Offset: time
Control: glmerControl(optCtrl = list(maxfun = 20000))

     AIC      BIC   logLik deviance df.resid
 45063.2  45176.7 -22518.6  45037.2    45668

Scaled residuals:
    Min      1Q  Median      3Q     Max
-2.6449 -0.6093 -0.3445  0.6770  7.8842

Random effects:
 Groups  Name        Variance Std.Dev. Corr
 quadrat (Intercept) 0.20809  0.4562
 sp      (Intercept) 0.87971  0.9379
         sizeJ       0.03747  0.1936   -0.41
         sizeS       0.49247  0.7018   -0.82  0.86
Number of obs: 45681, groups:  quadrat, 500; sp, 60

Fixed effects:
            Estimate Std. Error z value Pr(>|z|)
(Intercept) -3.96230    0.17254 -22.965  < 2e-16 ***
sizeJ        0.68744    0.09500   7.236 4.62e-13 ***
sizeS        1.99743    0.14818  13.480  < 2e-16 ***
CON_5        0.11348    0.01215   9.337  < 2e-16 ***
HET_5        0.06551    0.01547   4.235 2.28e-05 ***
INT          0.32286    0.01358  23.769  < 2e-16 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
      (Intr) sizeJ  sizeS  CON_5  HET_5
sizeJ -0.590
sizeS -0.857  0.767
CON_5 -0.022  0.000 -0.001
HET_5 -0.075  0.000  0.000  0.107
INT   -0.189  0.039  0.056  0.290  0.398
convergence code: 0
Model failed to converge with max|grad| = 0.00950462 (tol = 0.001, component 1)



-- 

Sachin Medigeshi Harish
Ph.D. student,
Dr. Dayanandan's Research Lab
Department of Biology
Concordia University - Loyola campus
Montreal, Quebec H4B 1R6, Canada

	[[alternative HTML version deleted]]


From Bill@Poling @ending from zeli@@com  Wed Dec  5 18:45:10 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Wed, 5 Dec 2018 17:45:10 +0000
Subject: [R-sig-ME] Help understanding an error Line Search Fails
Message-ID: <BN7PR02MB507313DEF702A69A20D89652EAA80@BN7PR02MB5073.namprd02.prod.outlook.com>



Good afternoon. I hope I have provided enough info to get my question answered.

> I am running windows 10 -- R3.5.1 -- RStudio Version 1.1.456


Using caret package I have been comparing models using my data, a training subset N=17357.

I have run PLS, RDA, GLM, and Boosted Logit based on a couple of tutorials.

http://dataaspirant.com/2017/01/19/support-vector-machine-classifier-implementation-r-caret-package/

https://cran.r-project.org/web/packages/caret/vignettes/caret.html

https://topepo.github.io/caret/model-training-and-tuning.html

However, when I get to trying svmLinear or svmRadial they both produce error: line search fails -1.614732 -0.257144 0.00001920624 0.00001369617 -0.00000001857456 -0.00000001542947 -0.000000000000568072

I have done some googling research but cannot find a definitive answer as to why this model does not work with my data but the other models do?

https://stackoverflow.com/questions/43267209/line-search-fails-when-training-a-model-using-caret

https://stackoverflow.com/questions/15895897/line-search-fails-in-training-ksvm-prob-model



Any advice would be appreciated.

Thank you

WHP

str(training)

# 'data.frame':17357 obs. of  7 variables:
#   $ SavingsReversed: num  0 0 0 0 0 ...
# $ productID      : num  3 3 3 3 3 1 3 3 3 1 ...
# $ ProviderID     : num  113676 114278 114278 114278 114278 ...
# $ ModCnt         : num  0 1 1 1 1 1 1 0 0 1 ...
# $ B2             : num  -1 -1 -1 -1 -1 -1 7 9 9 -1 ...
# $ B1a            : num  1 1 1 1 1 1 26 26 26 3 ...
# $ EditnumberI    : Factor w/ 2 levels "Bad","Good": 1 2 2 2 2 2 1 1 2 2 ...


head(training, n=25)

# SavingsReversed productID ProviderID ModCnt B2 B1a EditnumberI
# 1             0.00         3     113676      0 -1   1         Bad
# 5             0.00         3     114278      1 -1   1        Good
# 6             0.00         3     114278      1 -1   1        Good
# 7             0.00         3     114278      1 -1   1        Good
# 8             0.00         3     114278      1 -1   1        Good
# 10            0.00         1     114278      1 -1   1        Good
# 12          128.25         3     116641      1  7  26         Bad
# 13          159.60         3     116641      0  9  26         Bad
# 14            0.00         3     116641      0  9  26        Good
# 15            0.00         1     117280      1 -1   3        Good
# 16         1622.55         3     117439      1  9  26        Good
# 17           60.07         3     117439      1  9  26        Good
# 18            0.00         3     117439      0 -1   3        Good
# 19          190.00         3     117962      0  9  26        Good
# 20          372.66         3     119316      0  1  26         Bad
# 22            0.00         3     120431      1 -1   1        Good
# 25            0.00         3     121319      1  7  26         Bad
# 26           18.79         3     121319      1  7  26         Bad
# 27           23.00         3     121319      1  7  26         Bad
# 28           18.79         3     121319      1  7  26         Bad
# 29            0.00         3     121319      1  7  26         Bad
# 30           25.86         3     121319      2  7  26         Bad
# 31           14.00         3     121319      1  7  26         Bad
# 36          113.00         3     121545      1  1  26         Bad
# 37          197.20         3     121545      1  9  26         Bad


anyNA(training)
#[1] FALSE

My scripts

ctrl <- trainControl(
  method = "repeatedcv",
  repeats = 3,
  classProbs = TRUE,
  summaryFunction = twoClassSummary
)

set.seed(123)
svm_Linear <- train(EditnumberI ~., data = training,
                    method = "svmLinear",
                    trControl = ctrl,
                    preProcess = c("center", "scale"),
                    tuneLength = 10,
                    metric="ROC")
#warnings()
svm_Linear



set.seed(123)
svm_Radial <- train(EditnumberI ~., data = training,
                    method = "svmRadial",
                    trControl = ctrl,
                    preProcess = c("center", "scale"),
                    tuneLength = 10,
                    metric="ROC")
#warnings()
svm_Radial



line search fails -1.614732 -0.257144 0.00001920624 0.00001369617 -0.00000001857456 -0.00000001542947 -0.000000000000568072



WHP



Confidentiality Notice This message is sent from Zelis. ...{{dropped:13}}


From bbolker @ending from gm@il@com  Wed Dec  5 18:48:04 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Wed, 5 Dec 2018 12:48:04 -0500
Subject: [R-sig-ME] Help understanding an error Line Search Fails
In-Reply-To: <BN7PR02MB507313DEF702A69A20D89652EAA80@BN7PR02MB5073.namprd02.prod.outlook.com>
References: <BN7PR02MB507313DEF702A69A20D89652EAA80@BN7PR02MB5073.namprd02.prod.outlook.com>
Message-ID: <4a3a9791-50c0-4f55-12da-3c8d5ecef675@gmail.com>


  As far as I can tell none of the model types you're using fall under
the category of "mixed models" (linear/generalized linear models with
data  identified in known groups that are to be estimated by some form
of shrinkage estimator/"random effect").  (Please feel free to correct me!)

  By the way, I don't think it makes any sense to use "ProviderID" as a
*numeric* predictor variable ... that (and ProductID) are places where
you *might* actually want to use a mixed model.

  This looks like more of a CrossValidated question - note that you'll
have to provide a *reproducible* example in order to get help ...

  cheers
    Ben Bolker

On 2018-12-05 12:45 p.m., Bill Poling wrote:
> 
> 
> Good afternoon. I hope I have provided enough info to get my question answered.
> 
>> I am running windows 10 -- R3.5.1 -- RStudio Version 1.1.456
> 
> 
> Using caret package I have been comparing models using my data, a training subset N=17357.
> 
> I have run PLS, RDA, GLM, and Boosted Logit based on a couple of tutorials.
> 
> http://dataaspirant.com/2017/01/19/support-vector-machine-classifier-implementation-r-caret-package/
> 
> https://cran.r-project.org/web/packages/caret/vignettes/caret.html
> 
> https://topepo.github.io/caret/model-training-and-tuning.html
> 
> However, when I get to trying svmLinear or svmRadial they both produce error: line search fails -1.614732 -0.257144 0.00001920624 0.00001369617 -0.00000001857456 -0.00000001542947 -0.000000000000568072
> 
> I have done some googling research but cannot find a definitive answer as to why this model does not work with my data but the other models do?
> 
> https://stackoverflow.com/questions/43267209/line-search-fails-when-training-a-model-using-caret
> 
> https://stackoverflow.com/questions/15895897/line-search-fails-in-training-ksvm-prob-model
> 
> 
> 
> Any advice would be appreciated.
> 
> Thank you
> 
> WHP
> 
> str(training)
> 
> # 'data.frame':17357 obs. of  7 variables:
> #   $ SavingsReversed: num  0 0 0 0 0 ...
> # $ productID      : num  3 3 3 3 3 1 3 3 3 1 ...
> # $ ProviderID     : num  113676 114278 114278 114278 114278 ...
> # $ ModCnt         : num  0 1 1 1 1 1 1 0 0 1 ...
> # $ B2             : num  -1 -1 -1 -1 -1 -1 7 9 9 -1 ...
> # $ B1a            : num  1 1 1 1 1 1 26 26 26 3 ...
> # $ EditnumberI    : Factor w/ 2 levels "Bad","Good": 1 2 2 2 2 2 1 1 2 2 ...
> 
> 
> head(training, n=25)
> 
> # SavingsReversed productID ProviderID ModCnt B2 B1a EditnumberI
> # 1             0.00         3     113676      0 -1   1         Bad
> # 5             0.00         3     114278      1 -1   1        Good
> # 6             0.00         3     114278      1 -1   1        Good
> # 7             0.00         3     114278      1 -1   1        Good
> # 8             0.00         3     114278      1 -1   1        Good
> # 10            0.00         1     114278      1 -1   1        Good
> # 12          128.25         3     116641      1  7  26         Bad
> # 13          159.60         3     116641      0  9  26         Bad
> # 14            0.00         3     116641      0  9  26        Good
> # 15            0.00         1     117280      1 -1   3        Good
> # 16         1622.55         3     117439      1  9  26        Good
> # 17           60.07         3     117439      1  9  26        Good
> # 18            0.00         3     117439      0 -1   3        Good
> # 19          190.00         3     117962      0  9  26        Good
> # 20          372.66         3     119316      0  1  26         Bad
> # 22            0.00         3     120431      1 -1   1        Good
> # 25            0.00         3     121319      1  7  26         Bad
> # 26           18.79         3     121319      1  7  26         Bad
> # 27           23.00         3     121319      1  7  26         Bad
> # 28           18.79         3     121319      1  7  26         Bad
> # 29            0.00         3     121319      1  7  26         Bad
> # 30           25.86         3     121319      2  7  26         Bad
> # 31           14.00         3     121319      1  7  26         Bad
> # 36          113.00         3     121545      1  1  26         Bad
> # 37          197.20         3     121545      1  9  26         Bad
> 
> 
> anyNA(training)
> #[1] FALSE
> 
> My scripts
> 
> ctrl <- trainControl(
>   method = "repeatedcv",
>   repeats = 3,
>   classProbs = TRUE,
>   summaryFunction = twoClassSummary
> )
> 
> set.seed(123)
> svm_Linear <- train(EditnumberI ~., data = training,
>                     method = "svmLinear",
>                     trControl = ctrl,
>                     preProcess = c("center", "scale"),
>                     tuneLength = 10,
>                     metric="ROC")
> #warnings()
> svm_Linear
> 
> 
> 
> set.seed(123)
> svm_Radial <- train(EditnumberI ~., data = training,
>                     method = "svmRadial",
>                     trControl = ctrl,
>                     preProcess = c("center", "scale"),
>                     tuneLength = 10,
>                     metric="ROC")
> #warnings()
> svm_Radial
> 
> 
> 
> line search fails -1.614732 -0.257144 0.00001920624 0.00001369617 -0.00000001857456 -0.00000001542947 -0.000000000000568072
> 
> 
> 
> WHP
> 
> 
> 
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:13}}
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From d@e@kornbrot @ending from hert@@@c@uk  Thu Dec  6 10:21:15 2018
From: d@e@kornbrot @ending from hert@@@c@uk (Kornbrot, Diana)
Date: Thu, 6 Dec 2018 09:21:15 +0000
Subject: [R-sig-ME] Denominator df in glmer
In-Reply-To: <mailman.17138.9003.1543796292.1179.r-sig-mixed-models@r-project.org>
References: <mailman.17138.9003.1543796292.1179.r-sig-mixed-models@r-project.org>
Message-ID: <A7E7F43B-8B39-4C55-9D2C-035E97F36403@herts.ac.uk>

Simple question. How does one obtain denominator df for F testa   resulting  from glmer?  Do  not appear  in anova()
Many  thanks
Diana

_____________________________________
Professor Diana Kornbrot
Mobile
+44 (0) 7403 18 16 12
Work
University of Hertfordshire
College Lane, Hatfield, Hertfordshire AL10 9AB, UK
+44 (0) 170 728 4626
d.e.kornbrot at herts.ac.uk<mailto:d.e.kornbrot at herts.ac.uk>
http://dianakornbrot.wordpress.com/
http://go.herts.ac.uk/Diana_Kornbrot
skype:  kornbrotme
Home
19 Elmhurst Avenue
London N2 0LT, UK
+44 (0) 208 444 2081
 ------------------------------------------------------------




	[[alternative HTML version deleted]]


From mollieebrook@ @ending from gm@il@com  Thu Dec  6 11:57:43 2018
From: mollieebrook@ @ending from gm@il@com (Mollie Brooks)
Date: Thu, 6 Dec 2018 11:57:43 +0100
Subject: [R-sig-ME] Denominator df in glmer
In-Reply-To: <A7E7F43B-8B39-4C55-9D2C-035E97F36403@herts.ac.uk>
References: <mailman.17138.9003.1543796292.1179.r-sig-mixed-models@r-project.org>
 <A7E7F43B-8B39-4C55-9D2C-035E97F36403@herts.ac.uk>
Message-ID: <54195C71-729B-4DF6-A716-79379220856F@gmail.com>

Hi Diana,

Here?s some documentation on that topic. 
https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#why-doesnt-lme4-display-denominator-degrees-of-freedomp-values-what-other-options-do-i-have <https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#why-doesnt-lme4-display-denominator-degrees-of-freedomp-values-what-other-options-do-i-have>

cheers,
Mollie

???????????
Mollie E. Brooks, Ph.D.
Research Scientist
National Institute of Aquatic Resources
Technical University of Denmark

> On 6Dec 2018, at 10:21, Kornbrot, Diana <d.e.kornbrot at herts.ac.uk> wrote:
> 
> Simple question. How does one obtain denominator df for F testa   resulting  from glmer?  Do  not appear  in anova()
> Many  thanks
> Diana
> 
> _____________________________________
> Professor Diana Kornbrot
> Mobile
> +44 (0) 7403 18 16 12
> Work
> University of Hertfordshire
> College Lane, Hatfield, Hertfordshire AL10 9AB, UK
> +44 (0) 170 728 4626
> d.e.kornbrot at herts.ac.uk<mailto:d.e.kornbrot at herts.ac.uk>
> http://dianakornbrot.wordpress.com/
> http://go.herts.ac.uk/Diana_Kornbrot
> skype:  kornbrotme
> Home
> 19 Elmhurst Avenue
> London N2 0LT, UK
> +44 (0) 208 444 2081
> ------------------------------------------------------------
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From Bill@Poling @ending from zeli@@com  Thu Dec  6 13:36:58 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Thu, 6 Dec 2018 12:36:58 +0000
Subject: [R-sig-ME] Help understanding an error Line Search Fails
In-Reply-To: <4a3a9791-50c0-4f55-12da-3c8d5ecef675@gmail.com>
References: <BN7PR02MB507313DEF702A69A20D89652EAA80@BN7PR02MB5073.namprd02.prod.outlook.com>
 <4a3a9791-50c0-4f55-12da-3c8d5ecef675@gmail.com>
Message-ID: <BN7PR02MB5073C92C5F9A0088EFED1BDEEAA90@BN7PR02MB5073.namprd02.prod.outlook.com>

Good morning Ben and thank you for your response.

Yes, had not considered this a sig-mixed-models question but was unsure of where to start my questions.

How would I make available a reproducible example for further help?

If you suggest that this may be more suitable data for mixed model I would like to pursue that.

Appreciate your help Sir, thank you.

WHP




From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Ben Bolker
Sent: Wednesday, December 5, 2018 12:48 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Help understanding an error Line Search Fails


As far as I can tell none of the model types you're using fall under
the category of "mixed models" (linear/generalized linear models with
data identified in known groups that are to be estimated by some form
of shrinkage estimator/"random effect"). (Please feel free to correct me!)

By the way, I don't think it makes any sense to use "ProviderID" as a
*numeric* predictor variable ... that (and ProductID) are places where
you *might* actually want to use a mixed model.

This looks like more of a CrossValidated question - note that you'll
have to provide a *reproducible* example in order to get help ...

cheers
Ben Bolker

On 2018-12-05 12:45 p.m., Bill Poling wrote:
>
>
> Good afternoon. I hope I have provided enough info to get my question answered.
>
>> I am running windows 10 -- R3.5.1 -- RStudio Version 1.1.456
>
>
> Using caret package I have been comparing models using my data, a training subset N=17357.
>
> I have run PLS, RDA, GLM, and Boosted Logit based on a couple of tutorials.
>
> http://dataaspirant.com/2017/01/19/support-vector-machine-classifier-implementation-r-caret-package/
>
> https://cran.r-project.org/web/packages/caret/vignettes/caret.html
>
> https://topepo.github.io/caret/model-training-and-tuning.html
>
> However, when I get to trying svmLinear or svmRadial they both produce error: line search fails -1.614732 -0.257144 0.00001920624 0.00001369617 -0.00000001857456 -0.00000001542947 -0.000000000000568072
>
> I have done some googling research but cannot find a definitive answer as to why this model does not work with my data but the other models do?
>
> https://stackoverflow.com/questions/43267209/line-search-fails-when-training-a-model-using-caret
>
> https://stackoverflow.com/questions/15895897/line-search-fails-in-training-ksvm-prob-model
>
>
>
> Any advice would be appreciated.
>
> Thank you
>
> WHP
>
> str(training)
>
> # 'data.frame':17357 obs. of 7 variables:
> # $ SavingsReversed: num 0 0 0 0 0 ...
> # $ productID : num 3 3 3 3 3 1 3 3 3 1 ...
> # $ ProviderID : num 113676 114278 114278 114278 114278 ...
> # $ ModCnt : num 0 1 1 1 1 1 1 0 0 1 ...
> # $ B2 : num -1 -1 -1 -1 -1 -1 7 9 9 -1 ...
> # $ B1a : num 1 1 1 1 1 1 26 26 26 3 ...
> # $ EditnumberI : Factor w/ 2 levels "Bad","Good": 1 2 2 2 2 2 1 1 2 2 ...
>
>
> head(training, n=25)
>
> # SavingsReversed productID ProviderID ModCnt B2 B1a EditnumberI
> # 1 0.00 3 113676 0 -1 1 Bad
> # 5 0.00 3 114278 1 -1 1 Good
> # 6 0.00 3 114278 1 -1 1 Good
> # 7 0.00 3 114278 1 -1 1 Good
> # 8 0.00 3 114278 1 -1 1 Good
> # 10 0.00 1 114278 1 -1 1 Good
> # 12 128.25 3 116641 1 7 26 Bad
> # 13 159.60 3 116641 0 9 26 Bad
> # 14 0.00 3 116641 0 9 26 Good
> # 15 0.00 1 117280 1 -1 3 Good
> # 16 1622.55 3 117439 1 9 26 Good
> # 17 60.07 3 117439 1 9 26 Good
> # 18 0.00 3 117439 0 -1 3 Good
> # 19 190.00 3 117962 0 9 26 Good
> # 20 372.66 3 119316 0 1 26 Bad
> # 22 0.00 3 120431 1 -1 1 Good
> # 25 0.00 3 121319 1 7 26 Bad
> # 26 18.79 3 121319 1 7 26 Bad
> # 27 23.00 3 121319 1 7 26 Bad
> # 28 18.79 3 121319 1 7 26 Bad
> # 29 0.00 3 121319 1 7 26 Bad
> # 30 25.86 3 121319 2 7 26 Bad
> # 31 14.00 3 121319 1 7 26 Bad
> # 36 113.00 3 121545 1 1 26 Bad
> # 37 197.20 3 121545 1 9 26 Bad
>
>
> anyNA(training)
> #[1] FALSE
>
> My scripts
>
> ctrl <- trainControl(
> method = "repeatedcv",
> repeats = 3,
> classProbs = TRUE,
> summaryFunction = twoClassSummary
> )
>
> set.seed(123)
> svm_Linear <- train(EditnumberI ~., data = training,
> method = "svmLinear",
> trControl = ctrl,
> preProcess = c("center", "scale"),
> tuneLength = 10,
> metric="ROC")
> #warnings()
> svm_Linear
>
>
>
> set.seed(123)
> svm_Radial <- train(EditnumberI ~., data = training,
> method = "svmRadial",
> trControl = ctrl,
> preProcess = c("center", "scale"),
> tuneLength = 10,
> metric="ROC")
> #warnings()
> svm_Radial
>
>
>
> line search fails -1.614732 -0.257144 0.00001920624 0.00001369617 -0.00000001857456 -0.00000001542947 -0.000000000000568072
>
>
>
> WHP
>
>
>
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:13}}
>
> _______________________________________________
> mailto:R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

_______________________________________________
mailto:R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

Confidentiality Notice This message is sent from Zelis. ...{{dropped:13}}


From bbolker @ending from gm@il@com  Thu Dec  6 17:20:12 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Thu, 6 Dec 2018 11:20:12 -0500
Subject: [R-sig-ME] Help understanding an error Line Search Fails
In-Reply-To: <BN7PR02MB5073C92C5F9A0088EFED1BDEEAA90@BN7PR02MB5073.namprd02.prod.outlook.com>
References: <BN7PR02MB507313DEF702A69A20D89652EAA80@BN7PR02MB5073.namprd02.prod.outlook.com>
 <4a3a9791-50c0-4f55-12da-3c8d5ecef675@gmail.com>
 <BN7PR02MB5073C92C5F9A0088EFED1BDEEAA90@BN7PR02MB5073.namprd02.prod.outlook.com>
Message-ID: <fd99d2b2-6d8a-4009-54b6-d3d4a534ea3a@gmail.com>


   You could ask your question on r-help or StackOverflow or
CrossValidated (https://stats.stackexchange.com). r-help is mostly for R
questions (obviously).  StackOverflow might be best, as this is
primarily a programming question (and you're already looking on SO for
answers ...)

 There's a whole lot of information & advice on constructing
reproducible examples here:

https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

  If you choose to post on SO or CV, make sure to read the info on "how
to post"; for R-help, read https://www.r-project.org/posting-guide.html

  good luck,
     Ben Bolker


On 2018-12-06 7:36 a.m., Bill Poling wrote:
> Good morning Ben and thank you for your response.
> 
> Yes, had not considered this a sig-mixed-models question but was unsure of where to start my questions.
> 
> How would I make available a reproducible example for further help?
> 
> If you suggest that this may be more suitable data for mixed model I would like to pursue that.
> 
> Appreciate your help Sir, thank you.
> 
> WHP
> 
> 
> 
> 
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Ben Bolker
> Sent: Wednesday, December 5, 2018 12:48 PM
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Help understanding an error Line Search Fails
> 
> 
> As far as I can tell none of the model types you're using fall under
> the category of "mixed models" (linear/generalized linear models with
> data identified in known groups that are to be estimated by some form
> of shrinkage estimator/"random effect"). (Please feel free to correct me!)
> 
> By the way, I don't think it makes any sense to use "ProviderID" as a
> *numeric* predictor variable ... that (and ProductID) are places where
> you *might* actually want to use a mixed model.
> 
> This looks like more of a CrossValidated question - note that you'll
> have to provide a *reproducible* example in order to get help ...
> 
> cheers
> Ben Bolker
> 
> On 2018-12-05 12:45 p.m., Bill Poling wrote:
>>
>>
>> Good afternoon. I hope I have provided enough info to get my question answered.
>>
>>> I am running windows 10 -- R3.5.1 -- RStudio Version 1.1.456
>>
>>
>> Using caret package I have been comparing models using my data, a training subset N=17357.
>>
>> I have run PLS, RDA, GLM, and Boosted Logit based on a couple of tutorials.
>>
>> http://dataaspirant.com/2017/01/19/support-vector-machine-classifier-implementation-r-caret-package/
>>
>> https://cran.r-project.org/web/packages/caret/vignettes/caret.html
>>
>> https://topepo.github.io/caret/model-training-and-tuning.html
>>
>> However, when I get to trying svmLinear or svmRadial they both produce error: line search fails -1.614732 -0.257144 0.00001920624 0.00001369617 -0.00000001857456 -0.00000001542947 -0.000000000000568072
>>
>> I have done some googling research but cannot find a definitive answer as to why this model does not work with my data but the other models do?
>>
>> https://stackoverflow.com/questions/43267209/line-search-fails-when-training-a-model-using-caret
>>
>> https://stackoverflow.com/questions/15895897/line-search-fails-in-training-ksvm-prob-model
>>
>>
>>
>> Any advice would be appreciated.
>>
>> Thank you
>>
>> WHP
>>
>> str(training)
>>
>> # 'data.frame':17357 obs. of 7 variables:
>> # $ SavingsReversed: num 0 0 0 0 0 ...
>> # $ productID : num 3 3 3 3 3 1 3 3 3 1 ...
>> # $ ProviderID : num 113676 114278 114278 114278 114278 ...
>> # $ ModCnt : num 0 1 1 1 1 1 1 0 0 1 ...
>> # $ B2 : num -1 -1 -1 -1 -1 -1 7 9 9 -1 ...
>> # $ B1a : num 1 1 1 1 1 1 26 26 26 3 ...
>> # $ EditnumberI : Factor w/ 2 levels "Bad","Good": 1 2 2 2 2 2 1 1 2 2 ...
>>
>>
>> head(training, n=25)
>>
>> # SavingsReversed productID ProviderID ModCnt B2 B1a EditnumberI
>> # 1 0.00 3 113676 0 -1 1 Bad
>> # 5 0.00 3 114278 1 -1 1 Good
>> # 6 0.00 3 114278 1 -1 1 Good
>> # 7 0.00 3 114278 1 -1 1 Good
>> # 8 0.00 3 114278 1 -1 1 Good
>> # 10 0.00 1 114278 1 -1 1 Good
>> # 12 128.25 3 116641 1 7 26 Bad
>> # 13 159.60 3 116641 0 9 26 Bad
>> # 14 0.00 3 116641 0 9 26 Good
>> # 15 0.00 1 117280 1 -1 3 Good
>> # 16 1622.55 3 117439 1 9 26 Good
>> # 17 60.07 3 117439 1 9 26 Good
>> # 18 0.00 3 117439 0 -1 3 Good
>> # 19 190.00 3 117962 0 9 26 Good
>> # 20 372.66 3 119316 0 1 26 Bad
>> # 22 0.00 3 120431 1 -1 1 Good
>> # 25 0.00 3 121319 1 7 26 Bad
>> # 26 18.79 3 121319 1 7 26 Bad
>> # 27 23.00 3 121319 1 7 26 Bad
>> # 28 18.79 3 121319 1 7 26 Bad
>> # 29 0.00 3 121319 1 7 26 Bad
>> # 30 25.86 3 121319 2 7 26 Bad
>> # 31 14.00 3 121319 1 7 26 Bad
>> # 36 113.00 3 121545 1 1 26 Bad
>> # 37 197.20 3 121545 1 9 26 Bad
>>
>>
>> anyNA(training)
>> #[1] FALSE
>>
>> My scripts
>>
>> ctrl <- trainControl(
>> method = "repeatedcv",
>> repeats = 3,
>> classProbs = TRUE,
>> summaryFunction = twoClassSummary
>> )
>>
>> set.seed(123)
>> svm_Linear <- train(EditnumberI ~., data = training,
>> method = "svmLinear",
>> trControl = ctrl,
>> preProcess = c("center", "scale"),
>> tuneLength = 10,
>> metric="ROC")
>> #warnings()
>> svm_Linear
>>
>>
>>
>> set.seed(123)
>> svm_Radial <- train(EditnumberI ~., data = training,
>> method = "svmRadial",
>> trControl = ctrl,
>> preProcess = c("center", "scale"),
>> tuneLength = 10,
>> metric="ROC")
>> #warnings()
>> svm_Radial
>>
>>
>>
>> line search fails -1.614732 -0.257144 0.00001920624 0.00001369617 -0.00000001857456 -0.00000001542947 -0.000000000000568072
>>
>>
>>
>> WHP
>>
>>
>>
>> Confidentiality Notice This message is sent from Zelis. ...{{dropped:13}}
>>
>> _______________________________________________
>> mailto:R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> _______________________________________________
> mailto:R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.
> 
>


From bbolker @ending from gm@il@com  Thu Dec  6 18:25:38 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Thu, 6 Dec 2018 12:25:38 -0500
Subject: [R-sig-ME] Denominator df in glmer
In-Reply-To: <54195C71-729B-4DF6-A716-79379220856F@gmail.com>
References: <mailman.17138.9003.1543796292.1179.r-sig-mixed-models@r-project.org>
 <A7E7F43B-8B39-4C55-9D2C-035E97F36403@herts.ac.uk>
 <54195C71-729B-4DF6-A716-79379220856F@gmail.com>
Message-ID: <8a226961-768b-1f68-3d87-22d13fddbdb2@gmail.com>


  I can't remember any more where I saw the commentary, but I'm pretty
sure that in Walt Stroup's book he mentions that Kenward-Roger seems to
work pretty well for GLMMs, even though it doesn't have much theoretical
justification (it was developed for LMMs).  However, he also mentions
somewhere that in order to make it work (i.e. to be able to extract the
quantities on which the K-R approximation is based) you have to use a
pseudo-likelihood approach (which lme4 doesn't).

  I agree that the URL Mollie provides should give you useful
information (especially the "Df alternatives" section) ...


On 2018-12-06 5:57 a.m., Mollie Brooks wrote:
> Hi Diana,
> 
> Here?s some documentation on that topic. 
> https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#why-doesnt-lme4-display-denominator-degrees-of-freedomp-values-what-other-options-do-i-have <https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#why-doesnt-lme4-display-denominator-degrees-of-freedomp-values-what-other-options-do-i-have>
> 
> cheers,
> Mollie
> 
> ???????????
> Mollie E. Brooks, Ph.D.
> Research Scientist
> National Institute of Aquatic Resources
> Technical University of Denmark
> 
>> On 6Dec 2018, at 10:21, Kornbrot, Diana <d.e.kornbrot at herts.ac.uk> wrote:
>>
>> Simple question. How does one obtain denominator df for F testa   resulting  from glmer?  Do  not appear  in anova()
>> Many  thanks
>> Diana
>>
>> _____________________________________
>> Professor Diana Kornbrot
>> Mobile
>> +44 (0) 7403 18 16 12
>> Work
>> University of Hertfordshire
>> College Lane, Hatfield, Hertfordshire AL10 9AB, UK
>> +44 (0) 170 728 4626
>> d.e.kornbrot at herts.ac.uk<mailto:d.e.kornbrot at herts.ac.uk>
>> http://dianakornbrot.wordpress.com/
>> http://go.herts.ac.uk/Diana_Kornbrot
>> skype:  kornbrotme
>> Home
>> 19 Elmhurst Avenue
>> London N2 0LT, UK
>> +44 (0) 208 444 2081
>> ------------------------------------------------------------
>>
>>
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From viniciu@@@@m@i@ @ending from hotm@il@com  Thu Dec  6 19:33:35 2018
From: viniciu@@@@m@i@ @ending from hotm@il@com (Vinicius Maia)
Date: Thu, 6 Dec 2018 18:33:35 +0000
Subject: [R-sig-ME] Cannot have zero distances in "corSpatial"
Message-ID: <DM3PR14MB0540FDA33994547C66C6BFAABEA90@DM3PR14MB0540.namprd14.prod.outlook.com>

Hi folks

data structure: plots nested in sites, and observations nested in plots. both site and plots used as random factors

When running a mixed model (lme4) I founded spatial autocorrelation on model residuals, thus, I tried nlme mixed models inclunding a spatial structure (e.g. corr=corExp(...)), since I have repeated measures at the same point (then, with the same coordinates) the package is unable to run, giving the error: Cannot have zero distances in "corSpatial" in nlme

It seems to be a common and unsolved problem

https://www.google.com/search?q=Cannot+have+zero+distances+in+%22corSpatial%22&ie=utf-8&oe=utf-8&client=firefox-b

It is my first time here, sorry for any mistake in my post.

Thanks

vmaia

	[[alternative HTML version deleted]]


From Bill@Poling @ending from zeli@@com  Thu Dec  6 19:53:26 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Thu, 6 Dec 2018 18:53:26 +0000
Subject: [R-sig-ME] Help understanding an error Line Search Fails
Message-ID: <BN7PR02MB5073F156054C25A70BE3703CEAA90@BN7PR02MB5073.namprd02.prod.outlook.com>

Just found your tutorial, wow!

I am going to see if I can figure out how or if my data is applicable to this process.

https://bbolker.github.io/mixedmodels-misc/ecostats_chap.html

Thanks again

WHP

From: Ben Bolker <bbolker at gmail.com>
Sent: Thursday, December 6, 2018 11:20 AM
To: Bill Poling <Bill.Poling at zelis.com>; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Help understanding an error Line Search Fails


You could ask your question on r-help or StackOverflow or
CrossValidated (https://stats.stackexchange.com). r-help is mostly for R
questions (obviously). StackOverflow might be best, as this is
primarily a programming question (and you're already looking on SO for
answers ...)

There's a whole lot of information & advice on constructing
reproducible examples here:

https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

If you choose to post on SO or CV, make sure to read the info on "how
to post"; for R-help, read https://www.r-project.org/posting-guide.html

good luck,
Ben Bolker


On 2018-12-06 7:36 a.m., Bill Poling wrote:
> Good morning Ben and thank you for your response.
>
> Yes, had not considered this a sig-mixed-models question but was unsure of where to start my questions.
>
> How would I make available a reproducible example for further help?
>
> If you suggest that this may be more suitable data for mixed model I would like to pursue that.
>
> Appreciate your help Sir, thank you.
>
> WHP
>
>
>
>
> From: R-sig-mixed-models <mailto:r-sig-mixed-models-bounces at r-project.org> On Behalf Of Ben Bolker
> Sent: Wednesday, December 5, 2018 12:48 PM
> To: mailto:r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Help understanding an error Line Search Fails
>
>
> As far as I can tell none of the model types you're using fall under
> the category of "mixed models" (linear/generalized linear models with
> data identified in known groups that are to be estimated by some form
> of shrinkage estimator/"random effect"). (Please feel free to correct me!)
>
> By the way, I don't think it makes any sense to use "ProviderID" as a
> *numeric* predictor variable ... that (and ProductID) are places where
> you *might* actually want to use a mixed model.
>
> This looks like more of a CrossValidated question - note that you'll
> have to provide a *reproducible* example in order to get help ...
>
> cheers
> Ben Bolker
>
> On 2018-12-05 12:45 p.m., Bill Poling wrote:
>>
>>
>> Good afternoon. I hope I have provided enough info to get my question answered.
>>
>>> I am running windows 10 -- R3.5.1 -- RStudio Version 1.1.456
>>
>>
>> Using caret package I have been comparing models using my data, a training subset N=17357.
>>
>> I have run PLS, RDA, GLM, and Boosted Logit based on a couple of tutorials.
>>
>> http://dataaspirant.com/2017/01/19/support-vector-machine-classifier-implementation-r-caret-package/
>>
>> https://cran.r-project.org/web/packages/caret/vignettes/caret.html
>>
>> https://topepo.github.io/caret/model-training-and-tuning.html
>>
>> However, when I get to trying svmLinear or svmRadial they both produce error: line search fails -1.614732 -0.257144 0.00001920624 0.00001369617 -0.00000001857456 -0.00000001542947 -0.000000000000568072
>>
>> I have done some googling research but cannot find a definitive answer as to why this model does not work with my data but the other models do?
>>
>> https://stackoverflow.com/questions/43267209/line-search-fails-when-training-a-model-using-caret
>>
>> https://stackoverflow.com/questions/15895897/line-search-fails-in-training-ksvm-prob-model
>>
>>
>>
>> Any advice would be appreciated.
>>
>> Thank you
>>
>> WHP
>>
>> str(training)
>>
>> # 'data.frame':17357 obs. of 7 variables:
>> # $ SavingsReversed: num 0 0 0 0 0 ...
>> # $ productID : num 3 3 3 3 3 1 3 3 3 1 ...
>> # $ ProviderID : num 113676 114278 114278 114278 114278 ...
>> # $ ModCnt : num 0 1 1 1 1 1 1 0 0 1 ...
>> # $ B2 : num -1 -1 -1 -1 -1 -1 7 9 9 -1 ...
>> # $ B1a : num 1 1 1 1 1 1 26 26 26 3 ...
>> # $ EditnumberI : Factor w/ 2 levels "Bad","Good": 1 2 2 2 2 2 1 1 2 2 ...
>>
>>
>> head(training, n=25)
>>
>> # SavingsReversed productID ProviderID ModCnt B2 B1a EditnumberI
>> # 1 0.00 3 113676 0 -1 1 Bad
>> # 5 0.00 3 114278 1 -1 1 Good
>> # 6 0.00 3 114278 1 -1 1 Good
>> # 7 0.00 3 114278 1 -1 1 Good
>> # 8 0.00 3 114278 1 -1 1 Good
>> # 10 0.00 1 114278 1 -1 1 Good
>> # 12 128.25 3 116641 1 7 26 Bad
>> # 13 159.60 3 116641 0 9 26 Bad
>> # 14 0.00 3 116641 0 9 26 Good
>> # 15 0.00 1 117280 1 -1 3 Good
>> # 16 1622.55 3 117439 1 9 26 Good
>> # 17 60.07 3 117439 1 9 26 Good
>> # 18 0.00 3 117439 0 -1 3 Good
>> # 19 190.00 3 117962 0 9 26 Good
>> # 20 372.66 3 119316 0 1 26 Bad
>> # 22 0.00 3 120431 1 -1 1 Good
>> # 25 0.00 3 121319 1 7 26 Bad
>> # 26 18.79 3 121319 1 7 26 Bad
>> # 27 23.00 3 121319 1 7 26 Bad
>> # 28 18.79 3 121319 1 7 26 Bad
>> # 29 0.00 3 121319 1 7 26 Bad
>> # 30 25.86 3 121319 2 7 26 Bad
>> # 31 14.00 3 121319 1 7 26 Bad
>> # 36 113.00 3 121545 1 1 26 Bad
>> # 37 197.20 3 121545 1 9 26 Bad
>>
>>
>> anyNA(training)
>> #[1] FALSE
>>
>> My scripts
>>
>> ctrl <- trainControl(
>> method = "repeatedcv",
>> repeats = 3,
>> classProbs = TRUE,
>> summaryFunction = twoClassSummary
>> )
>>
>> set.seed(123)
>> svm_Linear <- train(EditnumberI ~., data = training,
>> method = "svmLinear",
>> trControl = ctrl,
>> preProcess = c("center", "scale"),
>> tuneLength = 10,
>> metric="ROC")
>> #warnings()
>> svm_Linear
>>
>>
>>
>> set.seed(123)
>> svm_Radial <- train(EditnumberI ~., data = training,
>> method = "svmRadial",
>> trControl = ctrl,
>> preProcess = c("center", "scale"),
>> tuneLength = 10,
>> metric="ROC")
>> #warnings()
>> svm_Radial
>>
>>
>>
>> line search fails -1.614732 -0.257144 0.00001920624 0.00001369617 -0.00000001857456 -0.00000001542947 -0.000000000000568072
>>
>>
>>
>> WHP
>>
>>
>>
>> Confidentiality Notice This message is sent from Zelis. ...{{dropped:13}}
>>
>> _______________________________________________
>> mailto:R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> mailto:R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.
>
>

Confidentiality Notice This message is sent from Zelis. ...{{dropped:13}}


From men@ur@tioni@t @ending from gm@il@com  Thu Dec  6 20:15:03 2018
From: men@ur@tioni@t @ending from gm@il@com (Andrew Robinson)
Date: Fri, 7 Dec 2018 06:15:03 +1100
Subject: [R-sig-ME] Cannot have zero distances in "corSpatial"
In-Reply-To: <d354fa8526b2424fbb8dbc450ae7a526@MEXPR01MB0758.ausprd01.prod.outlook.com>
References: <d354fa8526b2424fbb8dbc450ae7a526@MEXPR01MB0758.ausprd01.prod.outlook.com>
Message-ID: <426e290f-a42a-467e-97ee-9899659bca51@Spark>

Try adding a small random jitter to the locations.

Cheers,

Andrew
On 7 Dec 2018, 5:34 AM +1100, Vinicius Maia <vinicius.a.maia at hotmail.com>, wrote:
> Hi folks
>
> data structure: plots nested in sites, and observations nested in plots. both site and plots used as random factors
>
> When running a mixed model (lme4) I founded spatial autocorrelation on model residuals, thus, I tried nlme mixed models inclunding a spatial structure (e.g. corr=corExp(...)), since I have repeated measures at the same point (then, with the same coordinates) the package is unable to run, giving the error: Cannot have zero distances in "corSpatial" in nlme
>
> It seems to be a common and unsolved problem
>
> https://www.google.com/search?q=Cannot+have+zero+distances+in+%22corSpatial%22&ie=utf-8&oe=utf-8&client=firefox-b
>
> It is my first time here, sorry for any mistake in my post.
>
> Thanks
>
> vmaia
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From thierry@onkelinx @ending from inbo@be  Fri Dec  7 09:58:29 2018
From: thierry@onkelinx @ending from inbo@be (Thierry Onkelinx)
Date: Fri, 7 Dec 2018 09:58:29 +0100
Subject: [R-sig-ME] Cannot have zero distances in "corSpatial"
In-Reply-To: <DM3PR14MB0540FDA33994547C66C6BFAABEA90@DM3PR14MB0540.namprd14.prod.outlook.com>
References: <DM3PR14MB0540FDA33994547C66C6BFAABEA90@DM3PR14MB0540.namprd14.prod.outlook.com>
Message-ID: <CAJuCY5zGpZPp-RmyAi_pY6N410AQe4hGfpr-Yom2_S3cj=04Tg@mail.gmail.com>

Dear Maia,

Add a correlation structure with nlme won't solve your problem. Is applies
the correlation structure on the residuals **within** each finest group as
defined by the random effects. The residuals **between** random effects
group are assumed to be independent. The spatial structure is your design
is probably defined by site and plot so this won't work.

Have a look at the INLA or inlabru packages. They can model spatially
correlated random effects. See
https://www.muscardinus.be/2018/07/inlabru-bru/ for some examples.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op do 6 dec. 2018 om 19:33 schreef Vinicius Maia <
vinicius.a.maia at hotmail.com>:

> Hi folks
>
> data structure: plots nested in sites, and observations nested in plots.
> both site and plots used as random factors
>
> When running a mixed model (lme4) I founded spatial autocorrelation on
> model residuals, thus, I tried nlme mixed models inclunding a spatial
> structure (e.g. corr=corExp(...)), since I have repeated measures at the
> same point (then, with the same coordinates) the package is unable to run,
> giving the error: Cannot have zero distances in "corSpatial" in nlme
>
> It seems to be a common and unsolved problem
>
>
> https://www.google.com/search?q=Cannot+have+zero+distances+in+%22corSpatial%22&ie=utf-8&oe=utf-8&client=firefox-b
>
> It is my first time here, sorry for any mistake in my post.
>
> Thanks
>
> vmaia
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From y@@hree19 @ending from gm@il@com  Fri Dec  7 19:14:43 2018
From: y@@hree19 @ending from gm@il@com (Yashree Mehta)
Date: Fri, 7 Dec 2018 19:14:43 +0100
Subject: [R-sig-ME] Compound Symmetry Covariance structure
Message-ID: <CAOE=hqKdo9hPGd=3gWvz8xOSdFxChXBsQg-Nc=6drEd9aFCdyQ@mail.gmail.com>

Hi,

I have a question about the random effects model (Specifically, a random
intercept model) in its role in assuming a covariance structure in
estimation. In a panel data textbook, I read that by estimating a random
effects model itself, there is an induced covariance structure.

In nlme package, there are several types of covariance structures such as
Compound Symmetry (which I assume in my model) but the default value is 0.
I initialize it and proceed with the estimation.

Does this mean that if I do not specify the compound symmetry value in
nlme, the estimation is without a covariance assumption or there is
something I have missed in my understanding? That the " by estimating a
random effects model itself, there is an induced covariance structure"
confuses me a little.

It would be very helpful to get an explanation on this.

Thank you very much!

Regards,
Yashree

	[[alternative HTML version deleted]]


From jdpo223 @ending from g@uky@edu  Fri Dec  7 19:53:23 2018
From: jdpo223 @ending from g@uky@edu (Poe, John)
Date: Fri, 7 Dec 2018 13:53:23 -0500
Subject: [R-sig-ME] Compound Symmetry Covariance structure
In-Reply-To: <CAOE=hqKdo9hPGd=3gWvz8xOSdFxChXBsQg-Nc=6drEd9aFCdyQ@mail.gmail.com>
References: <CAOE=hqKdo9hPGd=3gWvz8xOSdFxChXBsQg-Nc=6drEd9aFCdyQ@mail.gmail.com>
Message-ID: <CAFW8BypcBQ1AFRSGcMSF1m_bZJXg=Znwqc1MzU3hSP3itaNscw@mail.gmail.com>

Hi Yashree,

Can you give the citation and page number for the panel data book?

On Fri, Dec 7, 2018 at 1:15 PM Yashree Mehta <yashree19 at gmail.com> wrote:

> Hi,
>
> I have a question about the random effects model (Specifically, a random
> intercept model) in its role in assuming a covariance structure in
> estimation. In a panel data textbook, I read that by estimating a random
> effects model itself, there is an induced covariance structure.
>
> In nlme package, there are several types of covariance structures such as
> Compound Symmetry (which I assume in my model) but the default value is 0.
> I initialize it and proceed with the estimation.
>
> Does this mean that if I do not specify the compound symmetry value in
> nlme, the estimation is without a covariance assumption or there is
> something I have missed in my understanding? That the " by estimating a
> random effects model itself, there is an induced covariance structure"
> confuses me a little.
>
> It would be very helpful to get an explanation on this.
>
> Thank you very much!
>
> Regards,
> Yashree
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 




Thanks,
John


John Poe, Ph.D.
Postdoctoral Scholar / Research Methodologist
Center for Public Health Services & Systems Research
University of Kentucky
www.johndavidpoe.com

	[[alternative HTML version deleted]]


From denni@@ruenger @ending from gm@il@com  Fri Dec  7 22:18:52 2018
From: denni@@ruenger @ending from gm@il@com (Dennis Ruenger)
Date: Fri, 7 Dec 2018 13:18:52 -0800
Subject: [R-sig-ME] glmmTMB: standard error of dispersion parameter
Message-ID: <CAFvg1=saY3SrekiVvT2hbWogV+thdkBvLLOCrqW_SiQDUg9ekg@mail.gmail.com>

In a fitted glmmTMB object, where do I find the standard error of the
dispersion parameter estimate for a negative binomial model? Thanks!

	[[alternative HTML version deleted]]


From john@m@indon@ld @ending from @nu@edu@@u  Sat Dec  8 04:29:08 2018
From: john@m@indon@ld @ending from @nu@edu@@u (John Maindonald)
Date: Sat, 8 Dec 2018 03:29:08 +0000
Subject: [R-sig-ME] glmmTMB: standard error of dispersion parameter
In-Reply-To: <CAFvg1=saY3SrekiVvT2hbWogV+thdkBvLLOCrqW_SiQDUg9ekg@mail.gmail.com>
References: <CAFvg1=saY3SrekiVvT2hbWogV+thdkBvLLOCrqW_SiQDUg9ekg@mail.gmail.com>
Message-ID: <EB918A4B-6E03-4056-9340-6C766B87BFDF@anu.edu.au>

> obj <- glmmTMB(deaths~I(NDAM2014^0.14), family=nbinom1(link='log'),
                            data=DAAG::hurricNamed)
> coef(summary(obj))[['cond']][,1:2]
                  Estimate Std. Error
(Intercept)      1.3003220  0.4764633
I(NDAM2014^0.14) 0.7702897  0.1283899

I would have expected coef(summary(obj))[[?disp?]] to give the information you want,
but it returns NULL.  I judge that this is an oversight. If one specifies a dispformula
that is more than the default ~1, coef(summary(obj))[[?disp?]]  does give the output
that is desired ? see below.  Try however:

> obj[['sdr']]
sdreport(.) result
       Estimate Std. Error
beta  1.3003220  0.4764633
beta  0.7702897  0.1283899
betad 4.5529957  0.2116238
Maximum gradient component: 1.733627e-07

betad is the scale parameter, with a log link function.

Observe that exp(4.5529957) = 94.91632, which is what summary(obj) gives as
'Overdispersion parameter for nbinom1 family?.

-----------------------------------------------------------------------------------------------------------

Note that if one specifies a dispformula that is more than the default ~1,
coef(summary(obj))[[?disp?]]  does give the required information:

> obj2 <- glmmTMB(deaths~I(NDAM2014^0.14), family=nbinom1(link='log'), data=DAAG::hurricNamed,
+ dispformula=~poly(NDAM2014,2))
> coef(summary(obj2))[['disp']]
NULL
> coef(summary(obj))[['disp']]
                    Estimate Std. Error   z value     Pr(>|z|)
(Intercept)         3.389720  0.2040211 16.614557 5.467767e-62
poly(NDAM2014, 2)1  7.737363  1.7277783  4.478215 7.526974e-06
poly(NDAM2014, 2)2 -1.780921  1.6305625 -1.092213 2.747396e-01

John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>

On 8/12/2018, at 10:18, Dennis Ruenger <dennis.ruenger at gmail.com<mailto:dennis.ruenger at gmail.com>> wrote:

In a fitted glmmTMB object, where do I find the standard error of the
dispersion parameter estimate for a negative binomial model? Thanks!

[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From jo@quin@@ld@be @ending from gm@il@com  Sat Dec  8 10:30:04 2018
From: jo@quin@@ld@be @ending from gm@il@com (=?UTF-8?Q?Joaqu=C3=ADn_Aldabe?=)
Date: Sat, 8 Dec 2018 06:30:04 -0300
Subject: [R-sig-ME] Compound Symmetry Covariance structure
In-Reply-To: <CAOE=hqKdo9hPGd=3gWvz8xOSdFxChXBsQg-Nc=6drEd9aFCdyQ@mail.gmail.com>
References: <CAOE=hqKdo9hPGd=3gWvz8xOSdFxChXBsQg-Nc=6drEd9aFCdyQ@mail.gmail.com>
Message-ID: <CAMM93=JpGa8JGhV9ZL61wZi-jCs9u3J=OwAHWpD0v95ptNSkYA@mail.gmail.com>

Hi,  random effects induce correlation through a covariance matrix (G
matrix) , in nlme  using compound symmetry as default. If variance
component of random effect are close to zero you may be having fitting
problems or the random intercepts is not that important.
Hooe this helps

El vie., 7 de dic. de 2018 3:15 PM, Yashree Mehta <yashree19 at gmail.com>
escribi?:

> Hi,
>
> I have a question about the random effects model (Specifically, a random
> intercept model) in its role in assuming a covariance structure in
> estimation. In a panel data textbook, I read that by estimating a random
> effects model itself, there is an induced covariance structure.
>
> In nlme package, there are several types of covariance structures such as
> Compound Symmetry (which I assume in my model) but the default value is 0.
> I initialize it and proceed with the estimation.
>
> Does this mean that if I do not specify the compound symmetry value in
> nlme, the estimation is without a covariance assumption or there is
> something I have missed in my understanding? That the " by estimating a
> random effects model itself, there is an induced covariance structure"
> confuses me a little.
>
> It would be very helpful to get an explanation on this.
>
> Thank you very much!
>
> Regards,
> Yashree
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Sun Dec  9 20:23:54 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Sun, 9 Dec 2018 14:23:54 -0500
Subject: [R-sig-ME] Compound Symmetry Covariance structure
In-Reply-To: <CAFW8BypcBQ1AFRSGcMSF1m_bZJXg=Znwqc1MzU3hSP3itaNscw@mail.gmail.com>
References: <CAOE=hqKdo9hPGd=3gWvz8xOSdFxChXBsQg-Nc=6drEd9aFCdyQ@mail.gmail.com>
 <CAFW8BypcBQ1AFRSGcMSF1m_bZJXg=Znwqc1MzU3hSP3itaNscw@mail.gmail.com>
Message-ID: <dcf7f24d-6bfd-2436-76ce-d037703f5a1f@gmail.com>


  A quick example of the induced covariance structure.

  Suppose you set up the simplest possible (linear) mixed model, which
has an overall intercept B; a group-level random effect on the intercept
e1_i with variance v1; and a residual error e0_ij with variance v0. The
value of x_{ij} = B + e1_i + e0_ij.  The variance of any observation
(E[(x_{ij}-B)^2]) is v0+v1.  The covariance of observations in the same
group is E[(x_{ij}-B)(x_{kj}-B)] = v1. The covariance of observations in
*different* groups is 0.  If we write out the correlation matrix for the
whole data set (assuming the observations are written out with samples
from the same group occurring contiguously), it will consist of a
block-diagonal matrix with correlation v1/(v0+v1) within each block; the
rest of the matrix will be zero.  This is a form of induced
compound-symmetric covariance structure.

  Presumably others can give good references to where this is explained
clearly in the literature (maybe even in Pinheiro and Bates, I don't
have access to my copy right now)

On 2018-12-07 1:53 p.m., Poe, John wrote:
> Hi Yashree,
> 
> Can you give the citation and page number for the panel data book?
> 
> On Fri, Dec 7, 2018 at 1:15 PM Yashree Mehta <yashree19 at gmail.com> wrote:
> 
>> Hi,
>>
>> I have a question about the random effects model (Specifically, a random
>> intercept model) in its role in assuming a covariance structure in
>> estimation. In a panel data textbook, I read that by estimating a random
>> effects model itself, there is an induced covariance structure.
>>
>> In nlme package, there are several types of covariance structures such as
>> Compound Symmetry (which I assume in my model) but the default value is 0.
>> I initialize it and proceed with the estimation.
>>
>> Does this mean that if I do not specify the compound symmetry value in
>> nlme, the estimation is without a covariance assumption or there is
>> something I have missed in my understanding? That the " by estimating a
>> random effects model itself, there is an induced covariance structure"
>> confuses me a little.
>>
>> It would be very helpful to get an explanation on this.
>>
>> Thank you very much!
>>
>> Regards,
>> Yashree
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
>


From y@@hree19 @ending from gm@il@com  Sun Dec  9 21:37:15 2018
From: y@@hree19 @ending from gm@il@com (Yashree Mehta)
Date: Sun, 9 Dec 2018 21:37:15 +0100
Subject: [R-sig-ME] Compound Symmetry Covariance structure
In-Reply-To: <dcf7f24d-6bfd-2436-76ce-d037703f5a1f@gmail.com>
References: <CAOE=hqKdo9hPGd=3gWvz8xOSdFxChXBsQg-Nc=6drEd9aFCdyQ@mail.gmail.com>
 <CAFW8BypcBQ1AFRSGcMSF1m_bZJXg=Znwqc1MzU3hSP3itaNscw@mail.gmail.com>
 <dcf7f24d-6bfd-2436-76ce-d037703f5a1f@gmail.com>
Message-ID: <CAOE=hq+jzUXfwtk7F8cV7NRzjX4o2dYYZXBNi95jhfgzxK-Gjg@mail.gmail.com>

Hi Ben, Joaquin and John,

First of all, thank you very much for your responses. They are all very
helpful.

Yes, I understand now that there is an induced compound -symmetry
covariance structure in random effects model in nlme as default. I was
wondering if now, if I explicitly initialize the correlation and impose
compound symmetry in the model code (learnt from the example in Pinheiro
and Bates):

First, I estimate the intra-class correlation coefficient and the value is
0.908. Then, I estimate the standard LME model,

model <- maize ~ "covariates" + random = ~ 1|HOUSEHOLD_ID, data=farm

Then, I impose compound symmetry explicitly:

dependency<-corCompSymm(value=0.908, form=~1|HOUSEHOLD_ID)
cs<-Initialize( dependency  , data=farm)
new_model<-update(model, correlation=cs)

Is this fundamentally correct or is it double accounting for compound
symmetry since there already is default in lme function?

Thank you very much.

Regards,
Yashree

On Sun, Dec 9, 2018 at 8:24 PM Ben Bolker <bbolker at gmail.com> wrote:

>
>   A quick example of the induced covariance structure.
>
>   Suppose you set up the simplest possible (linear) mixed model, which
> has an overall intercept B; a group-level random effect on the intercept
> e1_i with variance v1; and a residual error e0_ij with variance v0. The
> value of x_{ij} = B + e1_i + e0_ij.  The variance of any observation
> (E[(x_{ij}-B)^2]) is v0+v1.  The covariance of observations in the same
> group is E[(x_{ij}-B)(x_{kj}-B)] = v1. The covariance of observations in
> *different* groups is 0.  If we write out the correlation matrix for the
> whole data set (assuming the observations are written out with samples
> from the same group occurring contiguously), it will consist of a
> block-diagonal matrix with correlation v1/(v0+v1) within each block; the
> rest of the matrix will be zero.  This is a form of induced
> compound-symmetric covariance structure.
>
>   Presumably others can give good references to where this is explained
> clearly in the literature (maybe even in Pinheiro and Bates, I don't
> have access to my copy right now)
>
> On 2018-12-07 1:53 p.m., Poe, John wrote:
> > Hi Yashree,
> >
> > Can you give the citation and page number for the panel data book?
> >
> > On Fri, Dec 7, 2018 at 1:15 PM Yashree Mehta <yashree19 at gmail.com>
> wrote:
> >
> >> Hi,
> >>
> >> I have a question about the random effects model (Specifically, a random
> >> intercept model) in its role in assuming a covariance structure in
> >> estimation. In a panel data textbook, I read that by estimating a random
> >> effects model itself, there is an induced covariance structure.
> >>
> >> In nlme package, there are several types of covariance structures such
> as
> >> Compound Symmetry (which I assume in my model) but the default value is
> 0.
> >> I initialize it and proceed with the estimation.
> >>
> >> Does this mean that if I do not specify the compound symmetry value in
> >> nlme, the estimation is without a covariance assumption or there is
> >> something I have missed in my understanding? That the " by estimating a
> >> random effects model itself, there is an induced covariance structure"
> >> confuses me a little.
> >>
> >> It would be very helpful to get an explanation on this.
> >>
> >> Thank you very much!
> >>
> >> Regards,
> >> Yashree
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Mon Dec 10 01:10:27 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Sun, 9 Dec 2018 19:10:27 -0500
Subject: [R-sig-ME] Compound Symmetry Covariance structure
In-Reply-To: <CAOE=hq+jzUXfwtk7F8cV7NRzjX4o2dYYZXBNi95jhfgzxK-Gjg@mail.gmail.com>
References: <CAOE=hqKdo9hPGd=3gWvz8xOSdFxChXBsQg-Nc=6drEd9aFCdyQ@mail.gmail.com>
 <CAFW8BypcBQ1AFRSGcMSF1m_bZJXg=Znwqc1MzU3hSP3itaNscw@mail.gmail.com>
 <dcf7f24d-6bfd-2436-76ce-d037703f5a1f@gmail.com>
 <CAOE=hq+jzUXfwtk7F8cV7NRzjX4o2dYYZXBNi95jhfgzxK-Gjg@mail.gmail.com>
Message-ID: <07f27448-4ca6-3cf8-7a81-5873462ebc89@gmail.com>


  I don't think a compound-symmetric specification would do anything in
this case (i.e. when only the intercept varies among groups), because
there are no explicit correlation parameters to model. Does the model
actually change (e.g. are the log-likelihoods of the original and the
compound-symmetrized models the same)?

On 2018-12-09 3:37 p.m., Yashree Mehta wrote:
> Hi Ben, Joaquin and John,
> 
> First of all, thank you very much for your responses. They are all very
> helpful.
> 
> Yes, I understand now that there is an induced compound -symmetry
> covariance structure in random effects model in nlme as default. I was
> wondering if now, if I explicitly initialize the correlation and impose
> compound symmetry in the model code (learnt from the example in Pinheiro
> and Bates):
> 
> First, I estimate the intra-class correlation coefficient and the value
> is 0.908. Then, I estimate the standard LME model,
> 
> model <- maize ~ "covariates"?+ random = ~ 1|HOUSEHOLD_ID, data=farm
> 
> Then, I impose compound symmetry explicitly:
> ?
> dependency<-corCompSymm(value=0.908, form=~1|HOUSEHOLD_ID)
> cs<-Initialize( dependency? , data=farm)
> new_model<-update(model, correlation=cs)
> 
> Is this fundamentally correct or is it double accounting for compound
> symmetry since there already is default in lme function?
> 
> Thank you very much.
> 
> Regards,
> Yashree
> 
> On Sun, Dec 9, 2018 at 8:24 PM Ben Bolker <bbolker at gmail.com
> <mailto:bbolker at gmail.com>> wrote:
> 
> 
>     ? A quick example of the induced covariance structure.
> 
>     ? Suppose you set up the simplest possible (linear) mixed model, which
>     has an overall intercept B; a group-level random effect on the intercept
>     e1_i with variance v1; and a residual error e0_ij with variance v0. The
>     value of x_{ij} = B + e1_i + e0_ij.? The variance of any observation
>     (E[(x_{ij}-B)^2]) is v0+v1.? The covariance of observations in the same
>     group is E[(x_{ij}-B)(x_{kj}-B)] = v1. The covariance of observations in
>     *different* groups is 0.? If we write out the correlation matrix for the
>     whole data set (assuming the observations are written out with samples
>     from the same group occurring contiguously), it will consist of a
>     block-diagonal matrix with correlation v1/(v0+v1) within each block; the
>     rest of the matrix will be zero.? This is a form of induced
>     compound-symmetric covariance structure.
> 
>     ? Presumably others can give good references to where this is explained
>     clearly in the literature (maybe even in Pinheiro and Bates, I don't
>     have access to my copy right now)
> 
>     On 2018-12-07 1:53 p.m., Poe, John wrote:
>     > Hi Yashree,
>     >
>     > Can you give the citation and page number for the panel data book?
>     >
>     > On Fri, Dec 7, 2018 at 1:15 PM Yashree Mehta <yashree19 at gmail.com
>     <mailto:yashree19 at gmail.com>> wrote:
>     >
>     >> Hi,
>     >>
>     >> I have a question about the random effects model (Specifically, a
>     random
>     >> intercept model) in its role in assuming a covariance structure in
>     >> estimation. In a panel data textbook, I read that by estimating a
>     random
>     >> effects model itself, there is an induced covariance structure.
>     >>
>     >> In nlme package, there are several types of covariance structures
>     such as
>     >> Compound Symmetry (which I assume in my model) but the default
>     value is 0.
>     >> I initialize it and proceed with the estimation.
>     >>
>     >> Does this mean that if I do not specify the compound symmetry
>     value in
>     >> nlme, the estimation is without a covariance assumption or there is
>     >> something I have missed in my understanding? That the " by
>     estimating a
>     >> random effects model itself, there is an induced covariance
>     structure"
>     >> confuses me a little.
>     >>
>     >> It would be very helpful to get an explanation on this.
>     >>
>     >> Thank you very much!
>     >>
>     >> Regards,
>     >> Yashree
>     >>
>     >>? ? ? ? ?[[alternative HTML version deleted]]
>     >>
>     >> _______________________________________________
>     >> R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >>
>     >
>     >
> 
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From b@b@yu@@ifk @ending from gm@il@com  Mon Dec 10 12:50:27 2018
From: b@b@yu@@ifk @ending from gm@il@com (Kassim Baba Yussif)
Date: Mon, 10 Dec 2018 11:50:27 +0000
Subject: [R-sig-ME] Covariance matrix of random genetic effects
Message-ID: <CAH3UFiWe8nH74EQKvSKDXCB=swZV1TT-dQd_9NaV-dSfXLPxwg@mail.gmail.com>

Dear mix modelers,
I am modeling genotype-by-environment interaction with environment (E) as
the fixed effect and genotype (G) as the random effect using nlme package.
The model assumes residual heterogeneity across environments and a random
genetic main effects that changes between groups of environments (group)
that are positively correlated.

The genetic main effects that changes between groups of environments has a
covariance matrix that consists of group specific variances on the
diagonals and pairwise-specific genetic covariance between groups on the
off-diagonals.

I fitted the following models:
fm3b <- lme(yield ~ E,
           random = list(G = pdDiag(~group)),
           weights = varIdent(form = ~ 1 | E), data = BABS , method =
"REML" )

summary(fm3b)Linear mixed-effects model fit by REML
 Data: BABS
       AIC      BIC    logLik
  3822.193 3925.297 -1892.096

Random effects:
 Formula: ~group | G
 Structure: Diagonal
        (Intercept)    group2  group3 Residual
StdDev:   0.2698093 0.5510772 1.05834 0.657899

Variance function:
 Structure: Different standard deviations per stratum
 Formula: ~1 | E
 Parameter estimates:
    SS92a     IS92a     NS92a     IS94a     SS94a     LN96a     LN96b
1.0000000 1.0274616 0.9887740 0.9880075 1.0702162 0.5393888 0.5381522
    HN96b
1.3293175
Fixed effects: yield ~ E
                Value  Std.Error   DF   t-value p-value
(Intercept)  3.234534 0.07354699 1470  43.97915       0
EIS92a       1.033065 0.07609483 1470  13.57602       0
EIS94a      -0.434446 0.07501537 1470  -5.79143       0
ELN96a      -2.009100 0.07523938 1470 -26.70276       0
ELN96b      -2.636272 0.07522121 1470 -35.04692       0
ENS92a       3.759188 0.11125709 1470  33.78830       0
ESS92a      -0.781158 0.07534063 1470 -10.36835       0
ESS94a      -0.477911 0.07729423 1470  -6.18301       0


fm3c <- lme(yield ~ E,
            random = list(G = pdSymm(~group)),
            weights = varIdent(form = ~ 1 | E) , data = BABS, method =
"REML")


summary(fm3c)Linear mixed-effects model fit by REML
 Data: BABS
       AIC      BIC    logLik
  3751.569 3870.953 -1853.785

Random effects:
 Formula: ~group | G
 Structure: General positive-definite
            StdDev    Corr
(Intercept) 0.2050822 (Intr) group2
group2      0.5137835 0.631
group3      1.0695264 0.335  0.671
Residual    0.6677121

Variance function:
 Structure: Different standard deviations per stratum
 Formula: ~1 | E
 Parameter estimates:
    SS92a     IS92a     NS92a     IS94a     SS94a     LN96a     LN96b
1.0000000 0.9988832 0.9509165 0.9799925 1.0669147 0.5698006 0.5565435
    HN96b
1.2884907
Fixed effects: yield ~ E
                Value  Std.Error   DF   t-value p-value
(Intercept)  3.234534 0.07475904 1470  43.26612       0
EIS92a       1.033065 0.07494170 1470  13.78491       0
EIS94a      -0.434446 0.07441283 1470  -5.83833       0
ELN96a      -2.009100 0.07379078 1470 -27.22697       0
ELN96b      -2.636272 0.07357668 1470 -35.83026       0
ENS92a       3.759188 0.09272196 1470  40.54258       0
ESS92a      -0.781158 0.07497316 1470 -10.41917       0
ESS94a      -0.477911 0.07689743 1470  -6.21491       0


The two models gives me the residual heterogeneity across environments. But
I don't get the group specific variances and covariance. Model fm3b gives
me only group specific variances whiles fm3c gives group specific variances
and some between groups correlations.

Is there a way I can get group specific variances and the pair-wise
covariance?
https://orcid.org/0000-0002-3994-5066

	[[alternative HTML version deleted]]


From bpo@@en @ending from gm@il@com  Mon Dec 10 22:17:32 2018
From: bpo@@en @ending from gm@il@com (Boy Possen)
Date: Mon, 10 Dec 2018 22:17:32 +0100
Subject: [R-sig-ME] lme ->Error in getGroups.data.frame(dataMix, groups)
Message-ID: <CAFo30y0hiUKp0hDopyMBFOTOCwC7O_wjqNeO9rrCS2CrcF=-ww@mail.gmail.com>

The basic idea is to create a linear model in R such that FinH is explained
by SoilNkh, dDDSP, dDDSP2, Provenance, Site, Genotype and Block, where
SoilNkh, dDDSP and dDDSP2 are continuous covariates, Provenance, Site,
Genotype and Block are factors, Site and Provenance are fixed and Genotype
and Block are random. Also, Genotype is nested within Provenance and Block
within Site.

Since the order the variables go in is of importance, it should be a Anova
type-I with the parameters in following order:
FinH~SoilNkh,Site,dDDSP,dDDSP2,Provenance,Site:Provenance,Provenance/Genotype,Site/Block


For the fixed part I am ok? with either:

test31 <-lm(FinH~SoilNkh + Site + dDDSP + dDDSP2 + Provenance +
Site:Provenance ,data=d1)

test32 <-aov(FinH~SoilNkh + Site + dDDSP + dDDSP2 + Provenance +
Site:Provenance ,data=d1

When trying to specify the random-part, taking the above text as starting
point, trouble starts :)

I feel it should be of the form:

test64 <- lme(FinH~SoilNkh + Site + dDDSP + dDDSP2 + Provenance +
Site:Provenance,
            random = ~1|Provenance/Genotype + ~1|Site/Block,data=d1)

but I can't avoid the error

"Error in getGroups.data.frame(dataMix, groups) : invalid formula for
groups"

I am lost for clues, really, so any advice would be great! If any data
should be supplied, I'd be happy to provide of course, but can't (yet)
figure out how...

Thanks in advance for your time.


-- 
B.J.H.M. Possen

	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Tue Dec 11 23:40:29 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Tue, 11 Dec 2018 17:40:29 -0500
Subject: [R-sig-ME] lme ->Error in getGroups.data.frame(dataMix, groups)
In-Reply-To: <CAFo30y0hiUKp0hDopyMBFOTOCwC7O_wjqNeO9rrCS2CrcF=-ww@mail.gmail.com>
References: <CAFo30y0hiUKp0hDopyMBFOTOCwC7O_wjqNeO9rrCS2CrcF=-ww@mail.gmail.com>
Message-ID: <CABghstRaNAv=ibrNt0BmUuN7rbMk4eQWmrOFrdVkojVCDH648w@mail.gmail.com>

  Didn't read carefully, but: lme does not allow crossed random
effects without considerable effort (there is an example somewhere in
the later chapters of Pinheiro and Bates's book).  You r model
specification

 test64 <- lme(FinH~SoilNkh + Site + dDDSP + dDDSP2 + Provenance +
Site:Provenance,
            random = ~1|Provenance/Genotype + ~1|Site/Block,data=d1)

appears to specify crossed provenance/genotype and site/block REs.

If you can use lme4::lmer it should be easier (note RE is specified as
an additive term within the single formula argument).

On Tue, Dec 11, 2018 at 12:17 PM Boy Possen <bpossen at gmail.com> wrote:
>
> The basic idea is to create a linear model in R such that FinH is explained
> by SoilNkh, dDDSP, dDDSP2, Provenance, Site, Genotype and Block, where
> SoilNkh, dDDSP and dDDSP2 are continuous covariates, Provenance, Site,
> Genotype and Block are factors, Site and Provenance are fixed and Genotype
> and Block are random. Also, Genotype is nested within Provenance and Block
> within Site.
>
> Since the order the variables go in is of importance, it should be a Anova
> type-I with the parameters in following order:
> FinH~SoilNkh,Site,dDDSP,dDDSP2,Provenance,Site:Provenance,Provenance/Genotype,Site/Block
>
>
> For the fixed part I am ok? with either:
>
> test31 <-lm(FinH~SoilNkh + Site + dDDSP + dDDSP2 + Provenance +
> Site:Provenance ,data=d1)
>
> test32 <-aov(FinH~SoilNkh + Site + dDDSP + dDDSP2 + Provenance +
> Site:Provenance ,data=d1
>
> When trying to specify the random-part, taking the above text as starting
> point, trouble starts :)
>
> I feel it should be of the form:
>
> test64 <- lme(FinH~SoilNkh + Site + dDDSP + dDDSP2 + Provenance +
> Site:Provenance,
>             random = ~1|Provenance/Genotype + ~1|Site/Block,data=d1)
>
> but I can't avoid the error
>
> "Error in getGroups.data.frame(dataMix, groups) : invalid formula for
> groups"
>
> I am lost for clues, really, so any advice would be great! If any data
> should be supplied, I'd be happy to provide of course, but can't (yet)
> figure out how...
>
> Thanks in advance for your time.
>
>
> --
> B.J.H.M. Possen
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From juho@kri@ti@n@ruohonen @ending from gm@il@com  Wed Dec 12 06:36:48 2018
From: juho@kri@ti@n@ruohonen @ending from gm@il@com (Juho Kristian Ruohonen)
Date: Wed, 12 Dec 2018 07:36:48 +0200
Subject: [R-sig-ME] LRT between GLMM and GLM to test a Single Random
 Intercept
Message-ID: <CAG_dBVd1MPbY07Jp0dHqEa1h4+siyRrqKZp-d-1+Nhwo5senbg@mail.gmail.com>

My readers are likely to want to see a p-value on the only random effect
(an intercept) in my logistic GLMM.

Supposedly, if I fit the model using Laplace approximation, then the
likelihood is comparable with that of the fixed-effects model, so the
p-value from a LRT (divided by two) can be used. But I don't trust the
Laplace approximation much. I'd rather use at least 10 quadrature points
for improved accuracy. This also results in a more flattering (smaller)
random-effect variance and hence a lower reported intraclass correlation.
But if I use any more than 1 quadrature point, I can no longer report a
p-value on the random effect because *anova()* refuses to compare the
models, citing incomparable likelihood functions. I thought of calculating
the log-likelihood of the GLMM manually using *dbinom()*, the data and the
fitted values, but this thread
<https://stats.stackexchange.com/questions/381085/calculating-log-likelihood-of-logistic-adaptive-quadrature-glmm-for-comparison-w>
says I can't use the binomial PMF for that.


Is there a way I can have my cake (many quadrature points) and eat it too
(get a p-value for the random effect)? That parametric bootstrap procedure
sounds neat, but I'd still be running into the same problem: the LRT
calculated at each iteration compares a fixed and a mixed model, hence the
likelihoods cannot be compared.

	[[alternative HTML version deleted]]


From thierry@onkelinx @ending from inbo@be  Wed Dec 12 11:07:40 2018
From: thierry@onkelinx @ending from inbo@be (Thierry Onkelinx)
Date: Wed, 12 Dec 2018 11:07:40 +0100
Subject: [R-sig-ME] LRT between GLMM and GLM to test a Single Random
 Intercept
In-Reply-To: <CAG_dBVd1MPbY07Jp0dHqEa1h4+siyRrqKZp-d-1+Nhwo5senbg@mail.gmail.com>
References: <CAG_dBVd1MPbY07Jp0dHqEa1h4+siyRrqKZp-d-1+Nhwo5senbg@mail.gmail.com>
Message-ID: <CAJuCY5w=43yfGe72ZrwojDw3zpexBAay5XFc1XgP5=6v=6Hdeg@mail.gmail.com>

Dear Juho,

I'd take a step back and think on why you add the random intercept. Is it
clearly a part of the design? E.g. it takes repeated measures into account.
Then you need the term in the model, what ever the p-value. The variance of
the random effect indicates its importance.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op wo 12 dec. 2018 om 06:37 schreef Juho Kristian Ruohonen <
juho.kristian.ruohonen at gmail.com>:

> My readers are likely to want to see a p-value on the only random effect
> (an intercept) in my logistic GLMM.
>
> Supposedly, if I fit the model using Laplace approximation, then the
> likelihood is comparable with that of the fixed-effects model, so the
> p-value from a LRT (divided by two) can be used. But I don't trust the
> Laplace approximation much. I'd rather use at least 10 quadrature points
> for improved accuracy. This also results in a more flattering (smaller)
> random-effect variance and hence a lower reported intraclass correlation.
> But if I use any more than 1 quadrature point, I can no longer report a
> p-value on the random effect because *anova()* refuses to compare the
> models, citing incomparable likelihood functions. I thought of calculating
> the log-likelihood of the GLMM manually using *dbinom()*, the data and the
> fitted values, but this thread
> <
> https://stats.stackexchange.com/questions/381085/calculating-log-likelihood-of-logistic-adaptive-quadrature-glmm-for-comparison-w
> >
> says I can't use the binomial PMF for that.
>
>
> Is there a way I can have my cake (many quadrature points) and eat it too
> (get a p-value for the random effect)? That parametric bootstrap procedure
> sounds neat, but I'd still be running into the same problem: the LRT
> calculated at each iteration compares a fixed and a mixed model, hence the
> likelihoods cannot be compared.
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From d@idhu @ending from uc@lg@ry@c@  Wed Dec 12 01:28:39 2018
From: d@idhu @ending from uc@lg@ry@c@ (David Sidhu)
Date: Wed, 12 Dec 2018 00:28:39 +0000
Subject: [R-sig-ME] Plotting interactions while controlling for other
 predictors.
Message-ID: <5DE92D15-C405-470B-9B31-79F0AE7D4A26@ucalgary.ca>

I am interested in creating a plot of an interaction that accounts for other variables present in a model.

I am attaching a reproducible example of my try so far, but I don?t believe this is quite getting at what I?d like.

Essentially, I want to show the interaction between X2 and X3, while controlling for X1.

Thank you very much.
Dave

set.seed(182)
require(data.table)
require(lme4)
require(ggplot2)

X1 = rnorm(1000)
X2 = rnorm(1000)
X3 = sample(1:3, size = 1000, replace = TRUE)
X3 <- as.factor(X3)
DV = rnorm(1000)

Item <- rep(1:10, times = 100)
Subject <- rep(1:100, each = 10)

d <- as.data.frame(cbind(X1, X2, X3, DV, Item, Subject))

m1 <- lmer(DV ~ X1 + X2*X3 + (1|Subject) + (1|Item), data = d)

d$Pred <- predict(m1)
library(ggplot2)
ggplot(d, aes(x = X2, y = Pred, col = factor(X3), group = X3)) + geom_jitter(alpha = .2) + geom_smooth(method = "lm")


---
David M. Sidhu, MSc
PhD Candidate
Department of Psychology
University of Calgary







From w@lidm@w@@@10 @ending from gm@il@com  Wed Dec 12 18:05:23 2018
From: w@lidm@w@@@10 @ending from gm@il@com (Walid Mawass)
Date: Wed, 12 Dec 2018 12:05:23 -0500
Subject: [R-sig-ME] Plotting interactions while controlling for other
 predictors.
In-Reply-To: <5DE92D15-C405-470B-9B31-79F0AE7D4A26@ucalgary.ca>
References: <5DE92D15-C405-470B-9B31-79F0AE7D4A26@ucalgary.ca>
Message-ID: <CAJtCY7U_QRDPEbEP9dbpzoEL295ZcM9cc9D8X6C-R+0hLfyULQ@mail.gmail.com>

Hi,

The package 'effects' is a good tool for this sort of thing. It let's you
plot the effect of the interaction term from a regression model while
controlling for other predictors by using the mean value for each other
variable by default while plotting the predictions for the interaction term
based on the model.

Hope this helps.
-- 
Walid Mawass
Ph.D. candidate in Cellular and Molecular Biology
Population Genetics Laboratory
University of Qu?bec at Trois-Rivi?res
3351, boul. des Forges, C.P. 500
Trois-Rivi?res (Qu?bec) G9A 5H7
Telephone: 819-376-5011 poste 3384
On Wed, Dec 12, 2018, 11:51 AM David Sidhu <dsidhu at ucalgary.ca wrote:

> I am interested in creating a plot of an interaction that accounts for
> other variables present in a model.
>
> I am attaching a reproducible example of my try so far, but I don?t
> believe this is quite getting at what I?d like.
>
> Essentially, I want to show the interaction between X2 and X3, while
> controlling for X1.
>
> Thank you very much.
> Dave
>
> set.seed(182)
> require(data.table)
> require(lme4)
> require(ggplot2)
>
> X1 = rnorm(1000)
> X2 = rnorm(1000)
> X3 = sample(1:3, size = 1000, replace = TRUE)
> X3 <- as.factor(X3)
> DV = rnorm(1000)
>
> Item <- rep(1:10, times = 100)
> Subject <- rep(1:100, each = 10)
>
> d <- as.data.frame(cbind(X1, X2, X3, DV, Item, Subject))
>
> m1 <- lmer(DV ~ X1 + X2*X3 + (1|Subject) + (1|Item), data = d)
>
> d$Pred <- predict(m1)
> library(ggplot2)
> ggplot(d, aes(x = X2, y = Pred, col = factor(X3), group = X3)) +
> geom_jitter(alpha = .2) + geom_smooth(method = "lm")
>
>
> ---
> David M. Sidhu, MSc
> PhD Candidate
> Department of Psychology
> University of Calgary
>
>
>
>
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From guill@ume@imon@@2 @ending from gm@il@com  Wed Dec 12 18:06:49 2018
From: guill@ume@imon@@2 @ending from gm@il@com (Guillaume Adeux)
Date: Wed, 12 Dec 2018 18:06:49 +0100
Subject: [R-sig-ME] Plotting interactions while controlling for other
 predictors.
In-Reply-To: <5DE92D15-C405-470B-9B31-79F0AE7D4A26@ucalgary.ca>
References: <5DE92D15-C405-470B-9B31-79F0AE7D4A26@ucalgary.ca>
Message-ID: <CAENiVe_pa7xWp8bsUJEtXPaifS_rRn+fHA7STOdv-b89Cn+D1A@mail.gmail.com>

Hi David,

For plotting interactions between two continuous variables, maybe a gamm
model might be more adapted?

However, by defaut, in the visreg package, you can facet one of your
continuous variables (which is subsetted relative to its distribution) and
plot the other one accordingly.

This would be coded the following way: visreg(m1, X2, by="X3")
#overlay=TRUE to have them all combined in one plot, partial=TRUE to have
the partial residuals (which do not include RE by default), by default X1
will be fixed to its median

This will produce a conditional plot in which all random effects (or X1 in
this case) are fixed at a certain level (you can also fix this at a
particular value with cond=list(X1=XXXX) ).

Nevertheless, this simply calls for predict.lmer(). It is still pretty
convenient IMHO.

Hope this helps.

Sincerely,

GA2

Le mer. 12 d?c. 2018 ? 17:51, David Sidhu <dsidhu at ucalgary.ca> a ?crit :

> I am interested in creating a plot of an interaction that accounts for
> other variables present in a model.
>
> I am attaching a reproducible example of my try so far, but I don?t
> believe this is quite getting at what I?d like.
>
> Essentially, I want to show the interaction between X2 and X3, while
> controlling for X1.
>
> Thank you very much.
> Dave
>
> set.seed(182)
> require(data.table)
> require(lme4)
> require(ggplot2)
>
> X1 = rnorm(1000)
> X2 = rnorm(1000)
> X3 = sample(1:3, size = 1000, replace = TRUE)
> X3 <- as.factor(X3)
> DV = rnorm(1000)
>
> Item <- rep(1:10, times = 100)
> Subject <- rep(1:100, each = 10)
>
> d <- as.data.frame(cbind(X1, X2, X3, DV, Item, Subject))
>
> m1 <- lmer(DV ~ X1 + X2*X3 + (1|Subject) + (1|Item), data = d)
>
> d$Pred <- predict(m1)
> library(ggplot2)
> ggplot(d, aes(x = X2, y = Pred, col = factor(X3), group = X3)) +
> geom_jitter(alpha = .2) + geom_smooth(method = "lm")
>
>
> ---
> David M. Sidhu, MSc
> PhD Candidate
> Department of Psychology
> University of Calgary
>
>
>
>
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From guill@ume@imon@@2 @ending from gm@il@com  Wed Dec 12 18:19:06 2018
From: guill@ume@imon@@2 @ending from gm@il@com (Guillaume Adeux)
Date: Wed, 12 Dec 2018 18:19:06 +0100
Subject: [R-sig-ME] Plotting interactions while controlling for other
 predictors.
In-Reply-To: <CAENiVe_pa7xWp8bsUJEtXPaifS_rRn+fHA7STOdv-b89Cn+D1A@mail.gmail.com>
References: <5DE92D15-C405-470B-9B31-79F0AE7D4A26@ucalgary.ca>
 <CAENiVe_pa7xWp8bsUJEtXPaifS_rRn+fHA7STOdv-b89Cn+D1A@mail.gmail.com>
Message-ID: <CAENiVe-xCp79pz8OL4kAkj1a3ncx6qYBj3ijLYEwDGjMRfYDag@mail.gmail.com>

Sorry I hadn't seen X3 was a factor.

The above example will then work how you want it to (one facet per level of
X3) highlithing the effect of X2 on Y (per level of X3) while controlling
for X1 and random effects (set to a particular level).

This will be similar (not identical considering visreg fixes random effects
at a particular level) to creating your own prediction matrix with
new.dat=expand.grid(X1=median(X1),X2=seq(min(X2),max(X2),by=1),X3=c(1:3))
and feeding it to predict.merMod while predicting at the population level
(re.form=~0).

How partial residuals can be extracted however, I am not so sure.

GA2

Le mer. 12 d?c. 2018 ? 18:06, Guillaume Adeux <guillaumesimon.a2 at gmail.com>
a ?crit :

> Hi David,
>
> For plotting interactions between two continuous variables, maybe a gamm
> model might be more adapted?
>
> However, by defaut, in the visreg package, you can facet one of your
> continuous variables (which is subsetted relative to its distribution) and
> plot the other one accordingly.
>
> This would be coded the following way: visreg(m1, X2, by="X3")
> #overlay=TRUE to have them all combined in one plot, partial=TRUE to have
> the partial residuals (which do not include RE by default), by default X1
> will be fixed to its median
>
> This will produce a conditional plot in which all random effects (or X1 in
> this case) are fixed at a certain level (you can also fix this at a
> particular value with cond=list(X1=XXXX) ).
>
> Nevertheless, this simply calls for predict.lmer(). It is still pretty
> convenient IMHO.
>
> Hope this helps.
>
> Sincerely,
>
> GA2
>
> Le mer. 12 d?c. 2018 ? 17:51, David Sidhu <dsidhu at ucalgary.ca> a ?crit :
>
>> I am interested in creating a plot of an interaction that accounts for
>> other variables present in a model.
>>
>> I am attaching a reproducible example of my try so far, but I don?t
>> believe this is quite getting at what I?d like.
>>
>> Essentially, I want to show the interaction between X2 and X3, while
>> controlling for X1.
>>
>> Thank you very much.
>> Dave
>>
>> set.seed(182)
>> require(data.table)
>> require(lme4)
>> require(ggplot2)
>>
>> X1 = rnorm(1000)
>> X2 = rnorm(1000)
>> X3 = sample(1:3, size = 1000, replace = TRUE)
>> X3 <- as.factor(X3)
>> DV = rnorm(1000)
>>
>> Item <- rep(1:10, times = 100)
>> Subject <- rep(1:100, each = 10)
>>
>> d <- as.data.frame(cbind(X1, X2, X3, DV, Item, Subject))
>>
>> m1 <- lmer(DV ~ X1 + X2*X3 + (1|Subject) + (1|Item), data = d)
>>
>> d$Pred <- predict(m1)
>> library(ggplot2)
>> ggplot(d, aes(x = X2, y = Pred, col = factor(X3), group = X3)) +
>> geom_jitter(alpha = .2) + geom_smooth(method = "lm")
>>
>>
>> ---
>> David M. Sidhu, MSc
>> PhD Candidate
>> Department of Psychology
>> University of Calgary
>>
>>
>>
>>
>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

	[[alternative HTML version deleted]]


From jfox @ending from mcm@@ter@c@  Wed Dec 12 19:01:16 2018
From: jfox @ending from mcm@@ter@c@ (Fox, John)
Date: Wed, 12 Dec 2018 18:01:16 +0000
Subject: [R-sig-ME] Plotting interactions while controlling for other
 predictors.
In-Reply-To: <7401_1544633519_wBCGpxTM015461_5DE92D15-C405-470B-9B31-79F0AE7D4A26@ucalgary.ca>
References: <7401_1544633519_wBCGpxTM015461_5DE92D15-C405-470B-9B31-79F0AE7D4A26@ucalgary.ca>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8369BF4DC@FHSDB2D11-2.csu.mcmaster.ca>

Dear David,

You've already received a couple of suggestions to use the effects package. To clarify, the functions in the package can handle models fit by lmer() (for which it will plot fixed effects) with both factors and numeric predictors, interactions of arbitrary complexity, terms in numeric predictors with transformations, polynomials, and regression splines, and can add partial residuals and nonparametric smooths to the plot. 

See the help pages (in particular ?Effect, ?predictorEffect, and ?plot.eff) and vignettes for the package; there's a recent Journal of Statistical Software article describing partial residuals in effect plots and a book (Fox and Weisberg, An R Companion to Applied Regression, 2nd edition) with many examples.

I hope this helps,
 John

--------------------------------------
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: socialsciences.mcmaster.ca/jfox/



> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> project.org] On Behalf Of David Sidhu
> Sent: Tuesday, December 11, 2018 7:29 PM
> To: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] Plotting interactions while controlling for other
> predictors.
> 
> I am interested in creating a plot of an interaction that accounts for
> other variables present in a model.
> 
> I am attaching a reproducible example of my try so far, but I don?t
> believe this is quite getting at what I?d like.
> 
> Essentially, I want to show the interaction between X2 and X3, while
> controlling for X1.
> 
> Thank you very much.
> Dave
> 
> set.seed(182)
> require(data.table)
> require(lme4)
> require(ggplot2)
> 
> X1 = rnorm(1000)
> X2 = rnorm(1000)
> X3 = sample(1:3, size = 1000, replace = TRUE)
> X3 <- as.factor(X3)
> DV = rnorm(1000)
> 
> Item <- rep(1:10, times = 100)
> Subject <- rep(1:100, each = 10)
> 
> d <- as.data.frame(cbind(X1, X2, X3, DV, Item, Subject))
> 
> m1 <- lmer(DV ~ X1 + X2*X3 + (1|Subject) + (1|Item), data = d)
> 
> d$Pred <- predict(m1)
> library(ggplot2)
> ggplot(d, aes(x = X2, y = Pred, col = factor(X3), group = X3)) +
> geom_jitter(alpha = .2) + geom_smooth(method = "lm")
> 
> 
> ---
> David M. Sidhu, MSc
> PhD Candidate
> Department of Psychology
> University of Calgary
> 
> 
> 
> 
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From helen@w@ter@ @ending from gm@il@com  Fri Dec 14 11:15:02 2018
From: helen@w@ter@ @ending from gm@il@com (Helen Waters)
Date: Fri, 14 Dec 2018 10:15:02 +0000
Subject: [R-sig-ME] glmmTMB: how to get normalized residuals for use in ACF
 plotting
Message-ID: <CAE1vT3tpre5Gs4jJ80yMWSfTds2KywDFsN6j+bfqnz=Cp2WadA@mail.gmail.com>

Dear all,

This question is generally about glmmTMB, rather than lme4 - apologies
if this puts it out of the jurisdiction of r-sig-mixed-models.

I've been using glmmTMB to implement beta GLMMs. The data I'm using
was collected from a series of plots that were measured continually,
every three months, for ~2 years.

I would like to use ACF plots to look at possible temporal
auto-correlation in the residuals, and in the event that I need to
include a correlation structure (e.g. AR1), I would like to see how
well any such structure accounts for the auto-correlation.

I read here: https://stats.stackexchange.com/questions/80823/do-autocorrelated-residual-patterns-remain-even-in-models-with-appropriate-corre

...and here: http://bbolker.github.io/mixedmodels-misc/ecostats_chap.html

...that it is necessary to use the normalized residuals for ACF
plotting, rather than the raw residuals, as the raw residuals contain
no information on any correlation terms. The information in the
residuals.glm help file also implies that pearson/standardized
residuals may be no good for this?:

"type: an optional character string specifying the type of residuals
      to be used. If ?"response"?, the "raw" residuals (observed -
      fitted) are used; else, if ?"pearson"?, the standardized
      residuals (raw residuals divided by the corresponding
      standard errors) are used; else, if ?"normalized"?, the
      normalized residuals (standardized residuals pre-multiplied
      by the inverse square-root factor of the estimated error
      correlation matrix) are used. Partial matching of arguments
      is used, so only the first character needs to be provided.
      Defaults to ?"response"?."

Assuming it is indeed the normalized residuals that I need, does
anyone know how I could derive them from a glmmTMB object? The
residuals.glmmTMB function currently only accepts "response" and
"pearson" as 'type' arguments.

If it is necessary to calculate them 'by hand', then what R code
should I use to convert the standardized residuals, as per the
definition above? (i.e. "standardized residuals pre-multiplied by the
inverse square-root factor of the estimated error correlation
matrix").

Apologies if I have misunderstood any concepts here, I am new to
analysing time series data.

Many thanks in advance,
Helen


From h@@hemi @ending from h@w@ii@edu  Fri Dec 14 09:28:15 2018
From: h@@hemi @ending from h@w@ii@edu (Mohammadreza Hashemi)
Date: Thu, 13 Dec 2018 22:28:15 -1000
Subject: [R-sig-ME] Quick Question on glmer.nb
Message-ID: <28787D5F-4597-4938-B7B7-F6A4635A2167@hawaii.edu>

Hi folks,
 
I was working with glmer.nb function to estimate a negative binomial mixed effects model.
I was wondering if there is any chance to get the t statistics or the p values for the random effects as well as the fixed effects? 

Thank you so much for your time.

Sincerely, 
Pasha

P.S. More info just in case my question is not clear:
I am looking to find a way to justify if I should assume a random slope for a variable or not. The lme4 output shows the standard deviation of each random parameter, but it does not say anything about its significance for the model (Please correct me if I am wrong).




	[[alternative HTML version deleted]]


From thierry@onkelinx @ending from inbo@be  Mon Dec 17 20:24:09 2018
From: thierry@onkelinx @ending from inbo@be (Thierry Onkelinx)
Date: Mon, 17 Dec 2018 20:24:09 +0100
Subject: [R-sig-ME] Quick Question on glmer.nb
In-Reply-To: <28787D5F-4597-4938-B7B7-F6A4635A2167@hawaii.edu>
References: <28787D5F-4597-4938-B7B7-F6A4635A2167@hawaii.edu>
Message-ID: <CAJuCY5xLJuOuzuWXi9Hc-8c5wN16KBY9DGBq4poYSFcMUUODsQ@mail.gmail.com>

Dear Pasha,

This is explained on the FAQ:
http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#testing-significance-of-random-effects

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op ma 17 dec. 2018 om 18:49 schreef Mohammadreza Hashemi <hashemi at hawaii.edu
>:

> Hi folks,
>
> I was working with glmer.nb function to estimate a negative binomial mixed
> effects model.
> I was wondering if there is any chance to get the t statistics or the p
> values for the random effects as well as the fixed effects?
>
> Thank you so much for your time.
>
> Sincerely,
> Pasha
>
> P.S. More info just in case my question is not clear:
> I am looking to find a way to justify if I should assume a random slope
> for a variable or not. The lme4 output shows the standard deviation of each
> random parameter, but it does not say anything about its significance for
> the model (Please correct me if I am wrong).
>
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From Il@n@Rein@tein @ending from nyul@ngone@org  Tue Dec 18 18:06:39 2018
From: Il@n@Rein@tein @ending from nyul@ngone@org (Reinstein, Ilan)
Date: Tue, 18 Dec 2018 17:06:39 +0000
Subject: [R-sig-ME] Unbalanced Nested Models with Heteroscedastic Errors
Message-ID: <5cdc01972b6e4ec8819c1d10e5db0073@nyulangone.org>

Hi,


I am trying to model a multilevel structure of items (questions in a test) of different classes or types. Specifically, each of the items belongs to a particular class and the classes are mutually exclusive and the number of items by class is different. I want to avoid adding a a fixed effect to each class as I would like to see: first, the variation of classes around the intercept or grand mean, and second, the variation of items within each class but centered around the class mean and not the grand mean/intercept.


I have fitted several models like so:


~ 1 + (1|class/item)


This model returns an intercept and two random effects for class and items respectively, although both are centered around the intercept. I need one variance term by class to understand the within-class variability.


The second model that seems to help is:


 ~ 1 + class + (1 + class|item)


I have variances by class but the random effects for items are still centered around zero and one of the classes is now the reference/intercept (not an issue).


The last model is the one that seems to work best for my needs, however, I do need the variance of each class to be centered around the corresponding fixed effect and not zero, as it appears to be happening. Also, this model is considering crossed effects rather than nested. I may be willing to sacrifice the nesting as long as I can get variances for each class centered around their mean.


Ideally, I would like to get both a variance of class around an overall grand mean intercept, as well as variances for each of the classes informed only by those items that belong to that class.


 - Is this possible to fit in lme4?


 - Am I extracting the coefficients correctly? I am using ranef() and that is where I note the random effects by class are centered around zero. However, when using coef() the average value of the REs for each class is equal to the fixed effect, but I am not sure this is the result I need and if I can say those numbers are random effects rather than the FE + RE value.


- I understand I may not have enough items by class to get a reliable estimate of the variance around the fixed effect but as a theoretical model and our context it is not critical since we expect to gather enough data in the future.


Notes:

 - The response variable is binary so I am using glmer with binomial link.

 - The modeling context is very similar to the LLTM with heteroscedastic error from IRT, which I have previously modeled as

~  -1 + class + (-1 + class|item) + (1|person)


Thank you in advance for your time, I appreciate any insight


Kind regards,


Ilan Reinstein

------------------------------------------------------------
This email message, including any attachments, is for th...{{dropped:14}}


From Il@n@Rein@tein @ending from nyul@ngone@org  Tue Dec 18 21:21:38 2018
From: Il@n@Rein@tein @ending from nyul@ngone@org (Reinstein, Ilan)
Date: Tue, 18 Dec 2018 20:21:38 +0000
Subject: [R-sig-ME] Fw: Unbalanced Nested Models with Heteroscedastic Errors
In-Reply-To: <5cdc01972b6e4ec8819c1d10e5db0073@nyulangone.org>
References: <5cdc01972b6e4ec8819c1d10e5db0073@nyulangone.org>
Message-ID: <873f52ba938e4c0da122474a4586b474@nyulangone.org>

I sent the previous message as a non-member. I have signed up to the list so hopefully I can get an answer.


Thanks again for your time.




________________________________
From: Reinstein, Ilan
Sent: Tuesday, December 18, 2018 12:06 PM
To: r-sig-mixed-models at r-project.org
Subject: Unbalanced Nested Models with Heteroscedastic Errors


Hi,


I am trying to model a multilevel structure of items (questions in a test) of different classes or types. Specifically, each of the items belongs to a particular class and the classes are mutually exclusive and the number of items by class is different. I want to avoid adding a a fixed effect to each class as I would like to see: first, the variation of classes around the intercept or grand mean, and second, the variation of items within each class but centered around the class mean and not the grand mean/intercept.


I have fitted several models like so:


~ 1 + (1|class/item)


This model returns an intercept and two random effects for class and items respectively, although both are centered around the intercept. I need one variance term by class to understand the within-class variability.


The second model that seems to help is:


 ~ 1 + class + (1 + class|item)


I have variances by class but the random effects for items are still centered around zero and one of the classes is now the reference/intercept (not an issue).


The last model is the one that seems to work best for my needs, however, I do need the variance of each class to be centered around the corresponding fixed effect and not zero, as it appears to be happening. Also, this model is considering crossed effects rather than nested. I may be willing to sacrifice the nesting as long as I can get variances for each class centered around their mean.


Ideally, I would like to get both a variance of class around an overall grand mean intercept, as well as variances for each of the classes informed only by those items that belong to that class.


 - Is this possible to fit in lme4?


 - Am I extracting the coefficients correctly? I am using ranef() and that is where I note the random effects by class are centered around zero. However, when using coef() the average value of the REs for each class is equal to the fixed effect, but I am not sure this is the result I need and if I can say those numbers are random effects rather than the FE + RE value.


- I understand I may not have enough items by class to get a reliable estimate of the variance around the fixed effect but as a theoretical model and our context it is not critical since we expect to gather enough data in the future.


Notes:

 - The response variable is binary so I am using glmer with binomial link.

 - The modeling context is very similar to the LLTM with heteroscedastic error from IRT, which I have previously modeled as

~  -1 + class + (-1 + class|item) + (1|person)


Thank you in advance for your time, I appreciate any insight


Kind regards,


Ilan Reinstein

------------------------------------------------------------
This email message, including any attachments, is for th...{{dropped:14}}


From ry@n@@immon@ @ending from duke@edu  Wed Dec 19 15:52:50 2018
From: ry@n@@immon@ @ending from duke@edu (Ryan Simmons)
Date: Wed, 19 Dec 2018 14:52:50 +0000
Subject: [R-sig-ME] Unbalanced Nested Models with Heteroscedastic Errors
Message-ID: <SN6PR05MB5341DA84F8639D93AC5B7091FDBE0@SN6PR05MB5341.namprd05.prod.outlook.com>

Hi Ilan,

Could you clarify what you mean by "the random effects by class are centered around zero" and/or provide the code you are using to make this evaluation? It's hard to tell right now whether your issue is a coding one or a conceptual one. 

Random effects are, by definition, random variables with mean 0, and are often interpreted as the class-specific deviations from the grand mean. That is, if you just look at the random effect itself, of course it will be centered around zero, that's how it is defined in the model. The (conditional) mean for class j from the model would be calculated as something like: Intercept + Fixed-Effect for Class j + Random-Effect for Class j. There's nothing pathological about the random-effect term for a class in isolation being centered around 0, indeed that's exactly what you expect to see. 

Regards,

Ryan Simmons
Department of Biostatistics and Bioinformatics
Duke University
Durham, NC 27710
(919) 681-2567

-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of r-sig-mixed-models-request at r-project.org
Sent: Wednesday, December 19, 2018 6:03 AM
To: r-sig-mixed-models at r-project.org
Subject: R-sig-mixed-models Digest, Vol 144, Issue 21

Send R-sig-mixed-models mailing list submissions to
	r-sig-mixed-models at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
	https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dsig-2Dmixed-2Dmodels&d=DwICAg&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_gZ4adc&r=szMipnZzQMIctqnszKsX-AUNBHtRn663-NaJh5_rHBE&m=hBvCaNGt_bk-s68BkfzjQ0IeU_UHl1q7w22Gi1IaYZY&s=ZNUPRM1S5yri6v5VDxxdjyTf_QDtZQF-x9GrHWHl5Fs&e=
or, via email, send a message with subject or body 'help' to
	r-sig-mixed-models-request at r-project.org

You can reach the person managing the list at
	r-sig-mixed-models-owner at r-project.org

When replying, please edit your Subject line so it is more specific than "Re: Contents of R-sig-mixed-models digest..."


Today's Topics:

   1. Fw: Unbalanced Nested Models with Heteroscedastic Errors
      (Reinstein, Ilan)
   2. Unbalanced Nested Models with Heteroscedastic Errors
      (Reinstein, Ilan)

----------------------------------------------------------------------

Message: 1
Date: Tue, 18 Dec 2018 20:21:38 +0000
From: "Reinstein, Ilan" <Ilan.Reinstein at nyulangone.org>
To: "r-sig-mixed-models at r-project.org"
	<r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] Fw: Unbalanced Nested Models with Heteroscedastic
	Errors
Message-ID: <873f52ba938e4c0da122474a4586b474 at nyulangone.org>
Content-Type: text/plain; charset="utf-8"

I sent the previous message as a non-member. I have signed up to the list so hopefully I can get an answer.


Thanks again for your time.




________________________________
From: Reinstein, Ilan
Sent: Tuesday, December 18, 2018 12:06 PM
To: r-sig-mixed-models at r-project.org
Subject: Unbalanced Nested Models with Heteroscedastic Errors


Hi,


I am trying to model a multilevel structure of items (questions in a test) of different classes or types. Specifically, each of the items belongs to a particular class and the classes are mutually exclusive and the number of items by class is different. I want to avoid adding a a fixed effect to each class as I would like to see: first, the variation of classes around the intercept or grand mean, and second, the variation of items within each class but centered around the class mean and not the grand mean/intercept.


I have fitted several models like so:


~ 1 + (1|class/item)


This model returns an intercept and two random effects for class and items respectively, although both are centered around the intercept. I need one variance term by class to understand the within-class variability.


The second model that seems to help is:


 ~ 1 + class + (1 + class|item)


I have variances by class but the random effects for items are still centered around zero and one of the classes is now the reference/intercept (not an issue).


The last model is the one that seems to work best for my needs, however, I do need the variance of each class to be centered around the corresponding fixed effect and not zero, as it appears to be happening. Also, this model is considering crossed effects rather than nested. I may be willing to sacrifice the nesting as long as I can get variances for each class centered around their mean.


Ideally, I would like to get both a variance of class around an overall grand mean intercept, as well as variances for each of the classes informed only by those items that belong to that class.


 - Is this possible to fit in lme4?


 - Am I extracting the coefficients correctly? I am using ranef() and that is where I note the random effects by class are centered around zero. However, when using coef() the average value of the REs for each class is equal to the fixed effect, but I am not sure this is the result I need and if I can say those numbers are random effects rather than the FE + RE value.


- I understand I may not have enough items by class to get a reliable estimate of the variance around the fixed effect but as a theoretical model and our context it is not critical since we expect to gather enough data in the future.


Notes:

 - The response variable is binary so I am using glmer with binomial link.

 - The modeling context is very similar to the LLTM with heteroscedastic error from IRT, which I have previously modeled as

~  -1 + class + (-1 + class|item) + (1|person)


Thank you in advance for your time, I appreciate any insight


Kind regards,


Ilan Reinstein

------------------------------------------------------------
This email message, including any attachments, is for th...{{dropped:14}}




------------------------------

Message: 2
Date: Tue, 18 Dec 2018 17:06:39 +0000
From: "Reinstein, Ilan" <Ilan.Reinstein at nyulangone.org>
To: "r-sig-mixed-models at r-project.org"
	<r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] Unbalanced Nested Models with Heteroscedastic
	Errors
Message-ID: <5cdc01972b6e4ec8819c1d10e5db0073 at nyulangone.org>
Content-Type: text/plain; charset="utf-8"

Hi,


I am trying to model a multilevel structure of items (questions in a test) of different classes or types. Specifically, each of the items belongs to a particular class and the classes are mutually exclusive and the number of items by class is different. I want to avoid adding a a fixed effect to each class as I would like to see: first, the variation of classes around the intercept or grand mean, and second, the variation of items within each class but centered around the class mean and not the grand mean/intercept.


I have fitted several models like so:


~ 1 + (1|class/item)


This model returns an intercept and two random effects for class and items respectively, although both are centered around the intercept. I need one variance term by class to understand the within-class variability.


The second model that seems to help is:


 ~ 1 + class + (1 + class|item)


I have variances by class but the random effects for items are still centered around zero and one of the classes is now the reference/intercept (not an issue).


The last model is the one that seems to work best for my needs, however, I do need the variance of each class to be centered around the corresponding fixed effect and not zero, as it appears to be happening. Also, this model is considering crossed effects rather than nested. I may be willing to sacrifice the nesting as long as I can get variances for each class centered around their mean.


Ideally, I would like to get both a variance of class around an overall grand mean intercept, as well as variances for each of the classes informed only by those items that belong to that class.


 - Is this possible to fit in lme4?


 - Am I extracting the coefficients correctly? I am using ranef() and that is where I note the random effects by class are centered around zero. However, when using coef() the average value of the REs for each class is equal to the fixed effect, but I am not sure this is the result I need and if I can say those numbers are random effects rather than the FE + RE value.


- I understand I may not have enough items by class to get a reliable estimate of the variance around the fixed effect but as a theoretical model and our context it is not critical since we expect to gather enough data in the future.


Notes:

 - The response variable is binary so I am using glmer with binomial link.

 - The modeling context is very similar to the LLTM with heteroscedastic error from IRT, which I have previously modeled as

~  -1 + class + (-1 + class|item) + (1|person)


Thank you in advance for your time, I appreciate any insight


Kind regards,


Ilan Reinstein

------------------------------------------------------------
This email message, including any attachments, is for th...{{dropped:14}}




------------------------------

Subject: Digest Footer

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dsig-2Dmixed-2Dmodels&d=DwICAg&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_gZ4adc&r=szMipnZzQMIctqnszKsX-AUNBHtRn663-NaJh5_rHBE&m=hBvCaNGt_bk-s68BkfzjQ0IeU_UHl1q7w22Gi1IaYZY&s=ZNUPRM1S5yri6v5VDxxdjyTf_QDtZQF-x9GrHWHl5Fs&e=


------------------------------

End of R-sig-mixed-models Digest, Vol 144, Issue 21


From @ouheyl@@ghebghoub @ending from gm@il@com  Wed Dec 19 18:26:11 2018
From: @ouheyl@@ghebghoub @ending from gm@il@com (Souheyla GHEBGHOUB)
Date: Wed, 19 Dec 2018 17:26:11 +0000
Subject: [R-sig-ME] MCMCglmm r function
Message-ID: <CAEA998g52nF_ugCr3uD1n35ZRHFM4pew3SbaBgbSUd8ziwXiEg@mail.gmail.com>

Is MCMCglmm the correct r function for multinomial multilevel mixed
logistic regression ?

	[[alternative HTML version deleted]]


From phillip@@ld@y @ending from mpi@nl  Thu Dec 20 09:42:02 2018
From: phillip@@ld@y @ending from mpi@nl (Phillip Alday)
Date: Thu, 20 Dec 2018 09:42:02 +0100
Subject: [R-sig-ME] MCMCglmm r function
In-Reply-To: <803a00da-0f50-97dc-d691-f6b39d5d3d29@mpi.nl>
References: <803a00da-0f50-97dc-d691-f6b39d5d3d29@mpi.nl>
Message-ID: <3362ad9d-2d11-42c2-63a2-be4efe7cc413@mpi.nl>

It's one of several possibilities ...

Phillip

On 19/12/18 18:26, Souheyla GHEBGHOUB wrote:
> Is MCMCglmm the correct r function for multinomial multilevel mixed
> logistic regression ?
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From @ouheyl@@ghebghoub @ending from gm@il@com  Fri Dec 21 15:46:38 2018
From: @ouheyl@@ghebghoub @ending from gm@il@com (Souheyla GHEBGHOUB)
Date: Fri, 21 Dec 2018 14:46:38 +0000
Subject: [R-sig-ME] convergence
Message-ID: <CAEA998imHQwyvYeNiMdgLZNe2aeJX91NW8X9cRtg19PEHBKy+g@mail.gmail.com>

Should I "ignore" or get "too concerned" about this warning?

Model failed to converge with max|grad| = 0.00542358 (tol = 0.001,
component 1)

	[[alternative HTML version deleted]]


From thierry@onkelinx @ending from inbo@be  Fri Dec 21 15:59:47 2018
From: thierry@onkelinx @ending from inbo@be (Thierry Onkelinx)
Date: Fri, 21 Dec 2018 15:59:47 +0100
Subject: [R-sig-ME] convergence
In-Reply-To: <CAEA998imHQwyvYeNiMdgLZNe2aeJX91NW8X9cRtg19PEHBKy+g@mail.gmail.com>
References: <CAEA998imHQwyvYeNiMdgLZNe2aeJX91NW8X9cRtg19PEHBKy+g@mail.gmail.com>
Message-ID: <CAJuCY5xqspFPfXTz+Hy6tK1xzW6dNT9d+A=8tMYFP3VGHww9jg@mail.gmail.com>

This is like calling a doctor and asking "my leg hurts, how bad is it?". A
doctor needs to physically examine your leg before drawing conclussions.
Likewise we need much more context about your model before we can give you
any advise.

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op vr 21 dec. 2018 om 15:44 schreef Souheyla GHEBGHOUB <
souheyla.ghebghoub at gmail.com>:

> Should I "ignore" or get "too concerned" about this warning?
>
> Model failed to converge with max|grad| = 0.00542358 (tol = 0.001,
> component 1)
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From @ouheyl@@ghebghoub @ending from gm@il@com  Fri Dec 21 16:25:12 2018
From: @ouheyl@@ghebghoub @ending from gm@il@com (Souheyla GHEBGHOUB)
Date: Fri, 21 Dec 2018 15:25:12 +0000
Subject: [R-sig-ME] convergence
In-Reply-To: <CAEA998imHQwyvYeNiMdgLZNe2aeJX91NW8X9cRtg19PEHBKy+g@mail.gmail.com>
References: <CAEA998imHQwyvYeNiMdgLZNe2aeJX91NW8X9cRtg19PEHBKy+g@mail.gmail.com>
Message-ID: <CAEA998j8Gitb5iNdfSFbJ+M9Om6sSkMRLoj+Bz8ekCYzceTfcA@mail.gmail.com>

Update on context:
Aim: estimating the association between (1) responses accuracy and (2)
time, groups, and 7 word-covariates.

I included 2 covariates in the interactions with group & Time.
Number of observations : 5800

glmer(
  *Response* ~ Characters + Band_freq + Imageability + Cognateness +
Syllables + *Group*Time*PoS* + *Group*Time*Verbal_freq *
+ (Time|Subject) + (Time| Word),
glmerControl(optimizer="bobyqa", optCtrl = list(maxfun = 2e5)), data =
written.Form.data
  family = 'binomial'

On Fri, 21 Dec 2018 at 14:46, Souheyla GHEBGHOUB <
souheyla.ghebghoub at gmail.com> wrote:

> Should I "ignore" or get "too concerned" about this warning?
>
> Model failed to converge with max|grad| = 0.00542358 (tol = 0.001,
> component 1)
>

	[[alternative HTML version deleted]]


From thierry@onkelinx @ending from inbo@be  Fri Dec 21 16:29:49 2018
From: thierry@onkelinx @ending from inbo@be (Thierry Onkelinx)
Date: Fri, 21 Dec 2018 16:29:49 +0100
Subject: [R-sig-ME] convergence
In-Reply-To: <CAEA998j8Gitb5iNdfSFbJ+M9Om6sSkMRLoj+Bz8ekCYzceTfcA@mail.gmail.com>
References: <CAEA998imHQwyvYeNiMdgLZNe2aeJX91NW8X9cRtg19PEHBKy+g@mail.gmail.com>
 <CAEA998j8Gitb5iNdfSFbJ+M9Om6sSkMRLoj+Bz8ekCYzceTfcA@mail.gmail.com>
Message-ID: <CAJuCY5y6QTNFhXHkXWX2qUdKs6PbG6J+1XwiWe-dYbjC58P1jA@mail.gmail.com>

Quasi complete separation is one of the things that might cause the
convergence problems. You'll need to investigate whether any combination of
your covariates causes (quasi) complete separation. If it is in the fixed
effect, you'll need to simplify the model. If it is a single random effect
level, then you can get away with it.

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op vr 21 dec. 2018 om 16:22 schreef Souheyla GHEBGHOUB <
souheyla.ghebghoub at gmail.com>:

> Update on context:
> Aim: estimating the association between (1) responses accuracy and (2)
> time, groups, and 7 word-covariates.
>
> I included 2 covariates in the interactions with group & Time.
> Number of observations : 5800
>
> glmer(
>   *Response* ~ Characters + Band_freq + Imageability + Cognateness +
> Syllables + *Group*Time*PoS* + *Group*Time*Verbal_freq *
> + (Time|Subject) + (Time| Word),
> glmerControl(optimizer="bobyqa", optCtrl = list(maxfun = 2e5)), data =
> written.Form.data
>   family = 'binomial'
>
> On Fri, 21 Dec 2018 at 14:46, Souheyla GHEBGHOUB <
> souheyla.ghebghoub at gmail.com> wrote:
>
> > Should I "ignore" or get "too concerned" about this warning?
> >
> > Model failed to converge with max|grad| = 0.00542358 (tol = 0.001,
> > component 1)
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From @hm@dr215 m@ili@g off tpg@com@@u  Thu Dec 27 02:45:09 2018
From: @hm@dr215 m@ili@g off tpg@com@@u (@hm@dr215 m@ili@g off tpg@com@@u)
Date: Thu, 27 Dec 2018 12:45:09 +1100
Subject: [R-sig-ME] Robust mixed-effect linear regression with repeated
 measures
Message-ID: <003101d49d85$cda60dd0$68f22970$@tpg.com.au>

Hi

I am looking for a package to perform "Robust mixed-effect linear regression
with repeated measures".
I looked at robustlmm package, not sure if it handles the repeated measures
over time- if I consider repeated observations (e.g. (1|id) as a random
effects.

Your help is greatly appreciated!

Ahmad


From bbolker @ending from gm@il@com  Thu Dec 27 05:23:08 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Wed, 26 Dec 2018 23:23:08 -0500
Subject: [R-sig-ME] Robust mixed-effect linear regression with repeated
 measures
In-Reply-To: <003101d49d85$cda60dd0$68f22970$@tpg.com.au>
References: <003101d49d85$cda60dd0$68f22970$@tpg.com.au>
Message-ID: <CABghstTxZbcerHhwQgztfkGHAEKB4=MT79FooiXE16Ttw7G3Og@mail.gmail.com>

 Looking at the docs, help(package="robustlmm") says:

The main workhorse is the function ?rlmer?; it is implemented as
     direct robust analogue of the popular ?lmer? function of the
     ?lme4? package. The two functions have similar abilities and
     limitations.

Based on that, even without digging more deeply, I would assume it
would handle the case you're talking about.

Why not try it and ask again on the list if you have a more specific question?

  cheers
   Ben Bolker

On Wed, Dec 26, 2018 at 8:45 PM <ahmadr215 at tpg.com.au> wrote:
>
> Hi
>
> I am looking for a package to perform "Robust mixed-effect linear regression
> with repeated measures".
> I looked at robustlmm package, not sure if it handles the repeated measures
> over time- if I consider repeated observations (e.g. (1|id) as a random
> effects.
>
> Your help is greatly appreciated!
>
> Ahmad
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From @hm@dr215 m@ili@g off tpg@com@@u  Thu Dec 27 05:39:36 2018
From: @hm@dr215 m@ili@g off tpg@com@@u (@hm@dr215 m@ili@g off tpg@com@@u)
Date: Thu, 27 Dec 2018 15:39:36 +1100
Subject: [R-sig-ME] Robust mixed-effect linear regression with repeated
 measures
In-Reply-To: <CABghstTxZbcerHhwQgztfkGHAEKB4=MT79FooiXE16Ttw7G3Og@mail.gmail.com>
References: <003101d49d85$cda60dd0$68f22970$@tpg.com.au>
 <CABghstTxZbcerHhwQgztfkGHAEKB4=MT79FooiXE16Ttw7G3Og@mail.gmail.com>
Message-ID: <004001d49d9e$2cc6d9d0$86548d70$@tpg.com.au>

Thanks Ben, that's very useful -which I missed.
I did run it, and checked the coefficients. But will look at it more carefully and post the outputs. 
I just want to make sure if the "repeated measures" have been considered in the function to estimate the coefficients.

Ahmad


-----Original Message-----
From: Ben Bolker <bbolker at gmail.com> 
Sent: Thursday, 27 December 2018 3:23 PM
To: ahmadr215 at tpg.com.au
Cc: R SIG Mixed Models <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Robust mixed-effect linear regression with repeated measures

 Looking at the docs, help(package="robustlmm") says:

The main workhorse is the function ?rlmer?; it is implemented as
     direct robust analogue of the popular ?lmer? function of the
     ?lme4? package. The two functions have similar abilities and
     limitations.

Based on that, even without digging more deeply, I would assume it would handle the case you're talking about.

Why not try it and ask again on the list if you have a more specific question?

  cheers
   Ben Bolker

On Wed, Dec 26, 2018 at 8:45 PM <ahmadr215 at tpg.com.au> wrote:
>
> Hi
>
> I am looking for a package to perform "Robust mixed-effect linear 
> regression with repeated measures".
> I looked at robustlmm package, not sure if it handles the repeated 
> measures over time- if I consider repeated observations (e.g. (1|id) 
> as a random effects.
>
> Your help is greatly appreciated!
>
> Ahmad
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


