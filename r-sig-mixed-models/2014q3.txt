From munozsandoval at ug.uchile.cl  Tue Jul  1 06:21:33 2014
From: munozsandoval at ug.uchile.cl (=?UTF-8?B?TWF0w61hcyBNdcOxb3o=?=)
Date: Tue, 1 Jul 2014 00:21:33 -0400
Subject: [R-sig-ME] LRT on fixed-effects
Message-ID: <CAPSM5eRFDsY3PnBc1YGgcZZekErJOk8LLLzSvpbdP4S6wP0+4A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140701/df56c579/attachment.pl>

From chozen86 at gmail.com  Tue Jul  1 16:14:17 2014
From: chozen86 at gmail.com (Joel Chan)
Date: Tue, 1 Jul 2014 10:14:17 -0400
Subject: [R-sig-ME] LRT on fixed-effects (Mat?as Mu?oz)
Message-ID: <CAL0Enki0evQMCnfFVZYWR_UmwrSWtqKoBq3VFDr-7fiMdkDtsQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140701/33f2ee03/attachment.pl>

From tobias.heed.uhh at gmail.com  Tue Jul  1 16:31:47 2014
From: tobias.heed.uhh at gmail.com (Tobias Heed)
Date: Tue, 1 Jul 2014 16:31:47 +0200
Subject: [R-sig-ME] LRT on fixed-effects
In-Reply-To: <CAPSM5eRFDsY3PnBc1YGgcZZekErJOk8LLLzSvpbdP4S6wP0+4A@mail.gmail.com>
References: <CAPSM5eRFDsY3PnBc1YGgcZZekErJOk8LLLzSvpbdP4S6wP0+4A@mail.gmail.com>
Message-ID: <etPan.53b2c653.5c482a97.49b@Macintosh.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140701/95a7f560/attachment.pl>

From bbolker at gmail.com  Tue Jul  1 23:03:02 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 01 Jul 2014 17:03:02 -0400
Subject: [R-sig-ME] R2admb-package
In-Reply-To: <53B29728.8070704@icm.csic.es>
References: <53B29728.8070704@icm.csic.es>
Message-ID: <53B32206.5020106@gmail.com>

 [cc'ing to R-sig-mixed-models]

  There appears to be a deviance() method for 'admb' objects (produced
by R2ADMB), but not for 'glmmadmb" objects (produced by glmmADMB).
However, you should be able to use -2*logLik(object) to obtain the
deviance (to be precise, -2*logLik(object) is equal to the deviance in
general only _up to an additive constant_, but I think this workaround
will be OK for your purposes).

  Ben Bolker


On 14-07-01 07:10 AM, Elena Guerrero wrote:
> Dear Ben Bolker,
> 
> I have run a glmmADMB model to my count data with a family = "nbinom" .
> It worked very nice.
> 
> Now I want to calculate the *deviance explained* by this model
> (100*(Null deviance-Residual deviance)/Null deviance). I installed the
> R2admb package to use the deviance() function, however when I write
> deviance(my model) R gives me "NULL" as a response. When I try with the
> "admbex" example it works perfectly.
> 
> What is it happening? What does mean NULL in this case? Is there any
> other way to obtain the explained deviance of a glmmADMB model?
> 
> Thank you very much in advance.
> Best regards,
> Elena
> 
> -- 
> --
> Elena Guerrero S?nchez-Guerrero
> PhD student
> Dept. Biologia Marina i Oceanografia
> INSTITUTO DE CIENCIAS DEL MAR - CSIC
> Pg. Mar?tim de la Barceloneta, 37-49
> 08003 BARCELONA
> Spain
> Phone:(+34) 93 230 95 00 (ext. 1209)
> Fax: (+34) 93 230 95 55 
> http://www.icm.csic.es/icmdivulga/es/mediterraneo-monograficos-08.htm
> http://www.icm.csic.es/bio/
>


From mertens.ulf at gmail.com  Wed Jul  2 12:56:59 2014
From: mertens.ulf at gmail.com (Ulf Mertens)
Date: Wed, 2 Jul 2014 12:56:59 +0200
Subject: [R-sig-ME] Manipulating Compound Symmetry
Message-ID: <CA+7RmvaCuKTVcNpfxwoF0PV3cYF9N56WcH7bYOeBmzBbj9hF9Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140702/22d326cd/attachment.pl>

From bbolker at gmail.com  Thu Jul  3 00:42:06 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 2 Jul 2014 18:42:06 -0400
Subject: [R-sig-ME] R2admb-package
In-Reply-To: <53B407D8.2040309@icm.csic.es>
References: <53B29728.8070704@icm.csic.es> <53B32206.5020106@gmail.com>
	<53B407D8.2040309@icm.csic.es>
Message-ID: <CABghstT=f7FZ8xh__NNC5BFNFRi3JoRJWH79oeHcT4az5Z8-LQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140702/8eb709cc/attachment.pl>

From talischen at hotmail.com  Thu Jul  3 17:19:25 2014
From: talischen at hotmail.com (ChenChun)
Date: Thu, 3 Jul 2014 15:19:25 +0000
Subject: [R-sig-ME] help: different p-values from z-statistic and anova in
	coxme
In-Reply-To: <mailman.3.1404381601.19993.r-sig-mixed-models@r-project.org>
References: <mailman.3.1404381601.19993.r-sig-mixed-models@r-project.org>
Message-ID: <DUB124-W36D808A95E0E62083B6546AC010@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140703/961bbd9a/attachment.pl>

From bbolker at gmail.com  Thu Jul  3 23:45:34 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 3 Jul 2014 17:45:34 -0400
Subject: [R-sig-ME] [Lme4-authors] Error in lme4 package
In-Reply-To: <53B5735B.5050808@utoronto.ca>
References: <DE32C4F62968504F8BC4EE149D94821BA092B08B@ONBEREXMBX2.oakton.com.au>
	<53B5735B.5050808@utoronto.ca>
Message-ID: <CABghstTW7UEygK5ppNvvbG5A+-xe2ABUMsZZSJaaJ4oFZcM1Ag@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140703/b2a9185e/attachment.pl>

From Ronald.Richman at aig.com  Fri Jul  4 09:44:02 2014
From: Ronald.Richman at aig.com (Richman, Ronald)
Date: Fri, 4 Jul 2014 09:44:02 +0200
Subject: [R-sig-ME] Using glmm for penalised spline model
Message-ID: <466C6A0445D25841BAC0B80BEE58807A1A5717FDCE@JOHP3MMFS01.mail.aig.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140704/2747e20b/attachment.pl>

From bbolker at gmail.com  Fri Jul  4 11:54:51 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 4 Jul 2014 05:54:51 -0400
Subject: [R-sig-ME] Using glmm for penalised spline model
In-Reply-To: <466C6A0445D25841BAC0B80BEE58807A1A5717FDCE@JOHP3MMFS01.mail.aig.net>
References: <466C6A0445D25841BAC0B80BEE58807A1A5717FDCE@JOHP3MMFS01.mail.aig.net>
Message-ID: <CABghstSJFb_0_+LBxEvWMuWEk-LxX3AUfJ_KeP0h9pGq2JEotw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140704/9014f54b/attachment.pl>

From holtermann at hwwi.org  Fri Jul  4 13:23:14 2014
From: holtermann at hwwi.org (Linus Holtermann)
Date: Fri, 4 Jul 2014 13:23:14 +0200
Subject: [R-sig-ME] Using glmm for penalised spline model
In-Reply-To: <CABghstSJFb_0_+LBxEvWMuWEk-LxX3AUfJ_KeP0h9pGq2JEotw@mail.gmail.com>
References: <466C6A0445D25841BAC0B80BEE58807A1A5717FDCE@JOHP3MMFS01.mail.aig.net>,
	<CABghstSJFb_0_+LBxEvWMuWEk-LxX3AUfJ_KeP0h9pGq2JEotw@mail.gmail.com>
Message-ID: <AD0050057515F54084E7D5B93478C8481FC662065C@winxbede39.exchange.xchg>

Hello,

the gamm4 package is right. Also check the mgcv package.
There are some references:
Kuehlenkasper: Multilevel models with spline functions
Wood: references in the gamm4 (mgcv) package
Wood: Generalized Additive Models: an introduction with R
Snijders: Diagnostic Checks for Multilevel Models
All references require some knowledge on the topic.

You can also check the software R2BayesX. The Software runs with the R-interface and commands, similiar to BUGS etc...

Mit freundlichen Gr??en


Linus Holtermann
Hamburgisches WeltWirtschaftsInstitut gemeinn?tzige GmbH (HWWI)
Heimhuder Stra?e 71
20148 Hamburg
Tel +49-(0)40-340576-336
Fax+49-(0)40-340576-776
Internet: www.hwwi.org
Email: holtermann at hwwi.org

AmtsgerichtHamburg HRB 94303
Gesch?ftsf?hrer: Prof. Dr. Thomas Straubhaar, Gunnar Geyer
Umsatzsteuer-ID: DE 241849425
________________________________________
Von: r-sig-mixed-models-bounces at r-project.org [r-sig-mixed-models-bounces at r-project.org] im Auftrag von Ben Bolker [bbolker at gmail.com]
Gesendet: Freitag, 4. Juli 2014 11:54
An: Richman, Ronald
Cc: R-sig-mixed-models at r-project.org
Betreff: Re: [R-sig-ME] Using glmm for penalised spline model

I believe this is more or less what the gamm4 package does ...


On Fri, Jul 4, 2014 at 3:44 AM, Richman, Ronald <Ronald.Richman at aig.com>
wrote:

> Hi All,
>
> This is my first post to the mailing list, and may I thank you all for the
> interesting and varied correspondence which you post.
>
> I have come across a reference for using mixed models to fit penalised
> spline models in Currie<
> http://www.macs.hw.ac.uk/~iain/research/Currie.SM.pdf>(2013). He writes
> that -:
>
> "An alternative approach is to express the PGLM as a generalized linear
> mixed model
> (GLMM) and this also leads to an estimate of the smoothing parameter."
>
> I have searched for a reference on how to accomplish this, but to little
> avail. Does anyone have any experience in this?
>
> Kind regards,
> Ron
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From highstat at highstat.com  Fri Jul  4 16:44:09 2014
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Fri, 04 Jul 2014 16:44:09 +0200
Subject: [R-sig-ME] Using glmm for penalised spline model
In-Reply-To: <mailman.7.1404468002.24289.r-sig-mixed-models@r-project.org>
References: <mailman.7.1404468002.24289.r-sig-mixed-models@r-project.org>
Message-ID: <53B6BDB9.6070305@highstat.com>




>
>
> ------------------------------
>
> Message: 3
> Date: Fri, 4 Jul 2014 09:44:02 +0200
> From: "Richman, Ronald" <Ronald.Richman at aig.com>
> To: "R-sig-mixed-models at r-project.org"
> 	<R-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] Using glmm for penalised spline model
> Message-ID:
> 	<466C6A0445D25841BAC0B80BEE58807A1A5717FDCE at JOHP3MMFS01.mail.aig.net>
> Content-Type: text/plain
>
> Hi All,
>
> This is my first post to the mailing list, and may I thank you all for the interesting and varied correspondence which you post.
>
> I have come across a reference for using mixed models to fit penalised spline models in Currie<http://www.macs.hw.ac.uk/~iain/research/Currie.SM.pdf>(2013). He writes that -:
>
> "An alternative approach is to express the PGLM as a generalized linear mixed model
> (GLMM) and this also leads to an estimate of the smoothing parameter."


Ron,

Sorry for self-citing..but see:

http://www.highstat.com/BGGAMM.htm

for examples how to write a smoother as a mixed model and use 
nlme/lmer/JAGS to estimate the smoother.

Kind regards,

Alain
> I have searched for a reference on how to accomplish this, but to little avail. Does anyone have any experience in this?
>
> Kind regards,
> Ron
>
> 	[[alternative HTML version deleted]]
>
>



-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From bobmrtin444 at gmail.com  Fri Jul  4 12:36:45 2014
From: bobmrtin444 at gmail.com (bob martin)
Date: Fri, 4 Jul 2014 11:36:45 +0100
Subject: [R-sig-ME] glmer convergence warning
Message-ID: <CACNJNT-DRKLaQt5mEnWnuvK2VKMqS4aZTXq5tZHPx5bz1eBoFA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140704/f384a329/attachment.pl>

From david.federer at oakton.com.au  Fri Jul  4 02:03:58 2014
From: david.federer at oakton.com.au (David Federer)
Date: Fri, 4 Jul 2014 00:03:58 +0000
Subject: [R-sig-ME] [Lme4-authors] Error in lme4 package
In-Reply-To: <CABghstTW7UEygK5ppNvvbG5A+-xe2ABUMsZZSJaaJ4oFZcM1Ag@mail.gmail.com>
References: <DE32C4F62968504F8BC4EE149D94821BA092B08B@ONBEREXMBX2.oakton.com.au>
	<53B5735B.5050808@utoronto.ca>
	<CABghstTW7UEygK5ppNvvbG5A+-xe2ABUMsZZSJaaJ4oFZcM1Ag@mail.gmail.com>
Message-ID: <DE32C4F62968504F8BC4EE149D94821BA092B126@ONBEREXMBX2.oakton.com.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140704/624d80f5/attachment.pl>

From david.federer at oakton.com.au  Fri Jul  4 07:10:17 2014
From: david.federer at oakton.com.au (David Federer)
Date: Fri, 4 Jul 2014 05:10:17 +0000
Subject: [R-sig-ME] [Lme4-authors] Error in lme4 package
In-Reply-To: <CABghstTW7UEygK5ppNvvbG5A+-xe2ABUMsZZSJaaJ4oFZcM1Ag@mail.gmail.com>
References: <DE32C4F62968504F8BC4EE149D94821BA092B08B@ONBEREXMBX2.oakton.com.au>
	<53B5735B.5050808@utoronto.ca>
	<CABghstTW7UEygK5ppNvvbG5A+-xe2ABUMsZZSJaaJ4oFZcM1Ag@mail.gmail.com>
Message-ID: <DE32C4F62968504F8BC4EE149D94821BA092B332@ONBEREXMBX2.oakton.com.au>

Hi Ben, Steve,

See attached the dataset I performed the analysis on.

Employee_Id: Employee Number
Dpmt_Code: Department Code
HadIncident: Flags whether the employee has had an incident
Yrs_Service: The number of service years with the company

First I ran a regular logit, see below, which works out fine. The estimate of the intercept equals -0.9301 which equals the natural logarithm of the odd ratio:
p = 430/1520 = 0.2829; ln(0.2829/(1-0.2829)) = -0.9301

setwd("C:\\Users\\david.federer\\Documents")

mydata <- read.csv("SafetyAnalytics.csv", header=TRUE)

fixedmodel <- glm(HadIncident ~ 1, data = mydata, family = binomial("logit"))

summary(fixedmodel)



Call:

glm(formula = HadIncident ~ 1, family = binomial("logit"), data = mydata)



Deviance Residuals:

    Min       1Q   Median       3Q      Max

-0.8155  -0.8155  -0.8155   1.5891   1.5891



Coefficients:

            Estimate Std. Error z value Pr(>|z|)

(Intercept) -0.93015    0.05695  -16.33   <2e-16 ***

---

Signif. codes:

0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1



(Dispersion parameter for binomial family taken to be 1)



    Null deviance: 1810.8  on 1519  degrees of freedom

Residual deviance: 1810.8  on 1519  degrees of freedom

AIC: 1812.8



Number of Fisher Scoring iterations: 4

The I went ahead and ran a multilevel logit (intercept-only) which gave an estimated intercept of logistic of -1.2589 (see below). This figure roughly equates to the natural logarithm of the proportion 0.2829 (-1.2627) which is remarkable. If I would take -1.2627 to be the ln of the odds ratio the proportion would work out to be 0.2205 which is a 22% decrease relative to the fixed effect model.
It might be that ?Dpmt_Code? adds a lot of variance. I just wanted to ascertain that that is the case and glmer comes back with the ln of the odds ratio, rather than the proportion. Thanks guys for making time to look into this. David


library(lme4)

fit <- glmer(HadIncident ~ (1|Dpmt_Code), family=binomial("logit"), data=mydata)

summary(fit)

Generalized linear mixed model fit by maximum likelihood

  (Laplace Approximation) [glmerMod]

 Family: binomial ( logit )

Formula: HadIncident ~ (1 | Dpmt_Code)

   Data: mydata



     AIC      BIC   logLik deviance df.resid

  1728.6   1739.2   -862.3   1724.6     1518



Scaled residuals:

    Min      1Q  Median      3Q     Max

-1.2337 -0.6240 -0.4391  0.9691  2.8970



Random effects:

 Groups    Name        Variance Std.Dev.

 Dpmt_Code (Intercept) 0.7986   0.8936

Number of obs: 1520, groups: Dpmt_Code, 145



Fixed effects:

            Estimate Std. Error z value Pr(>|z|)

(Intercept)  -1.2589     0.1164  -10.81   <2e-16 ***

---

Signif. codes:

0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1


From: Ben Bolker [mailto:bbolker at gmail.com]
Sent: Friday, 4 July 2014 7:46 AM
To: Steve Walker
Cc: David Federer; r-sig-mixed-models at r-project.org
Subject: Re: [Lme4-authors] Error in lme4 package

Agree with what Steve said.  It's quite possible that accounting for the random effects is giving you results that are correct but initially surprising. See for example this thread: http://article.gmane.org/gmane.comp.lang.r.lme4.devel/11951
  [taking the liberty of cc'ing to r-sig-mixed-models]

On Thu, Jul 3, 2014 at 11:14 AM, Steve Walker <steve.walker at utoronto.ca<mailto:steve.walker at utoronto.ca>> wrote:
Hi David,

I explored this issue with the build-in cbpp example in lme4 (attached) but didn't find any problems.  We would need a reproducible example to pursue this any farther.

Cheers,
Steve


On 2014-07-03, 2:44 AM, David Federer wrote:
Hi Ben,

I need to run a multilevel logistic regression on a dataset that embeds a nested structure.  I used the 'glmer' function to run a multilevel logit, setting the 'family' parameter to 'binomial("logit")'. I expected the function to regress the natural logarithm of the odds ratio ( ln(p/1-p) )against the independent variable that I had specified. Instead, it returned the natural logarithm of the proportion ( ln(p) ). Here is a numerical example (for the intercept only model):

In my dataset, p equals 0.2829. ln(p/p-1) should lie in the vicinity of -0.9301. Instead glmer returned -1.2589 which approximates ln(0.2829)

Is this an error in the 'glmer' function?


Kind Regards,



David

This message is for the designated recipient only and may contain privileged, proprietary, or otherwise private information. If you have received it in error, please notify the sender immediately and delete the original. Any other use of the email by you is prohibited.


_______________________________________________
Lme4-authors mailing list
Lme4-authors at lists.r-forge.r-project.org<mailto:Lme4-authors at lists.r-forge.r-project.org>
https://lists.r-forge.r-project.org/cgi-bin/mailman/listinfo/lme4-authors



This message is for the designated recipient only and may contain privileged, proprietary, or otherwise private information. If you have received it in error, please notify the sender immediately and delete the original. Any other use of the email by you is prohibited.

From nimrod.rubinstein at gmail.com  Sat Jul  5 19:33:35 2014
From: nimrod.rubinstein at gmail.com (Nimrod Rubinstein)
Date: Sat, 5 Jul 2014 13:33:35 -0400
Subject: [R-sig-ME] Getting the error message: Error: (maxstephalfit) PIRLS
 step-halvings failed to reduce deviance in pwrssUpdate when trying to fit
 glmer to my data
Message-ID: <CAEDz9egpOP1zdNOe9ZJEzQJiWq9u5_6iE5=Kg13qQd9+NT_TMg@mail.gmail.com>

Hi,

I have these data:

my.df = structure(list(response = c(0.516074952, 0.580012258, 0.5488396,
0.514189282, 0.541119544, 0.534505123, 0.51646652, 0.509050733,
0.518528396, 0.518612368, 0.633614104, 0.571088979, 0.707287635,
0.551960442, 0.628561587, 0.636816662, 0.84273424, 0.791398785,
0.564327876, 0.572247664, 0.542536414, 0.817166116, 0.598312173,
0.549507424, 0.648524073, 0.548890252, 0.525518275, 0.55938954,
0.632503362, 0.525381357, 0.52893369), distance = c(558648, 384605, 357615,
313157, 268367, 201775, 166657, 145176, 143358, 92778, 80661, 64350, 33872,
30410, 10309, 100, 12670, 51609, 66232, 72622, 76022, 89428, 92727, 131314,
160023, 197924, 227711, 280067, 285519, 413874, 688813), direction = c(-1,
-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1,
1, 1, 1, 1, 1, 1, 1, 1, 1, 1), id = c("12", "12", "7.3", "7.3", "6.2",
"7.4", "2.3", "7.5", "2.3", "1", "7.4", "7.3", "7.1", "18", "7.1", "17",
"7.5", "X", "2.1", "7.4", "10", "6.2", "2.1", "1", "2.1", "11.1", "7.5",
"15.1", "15.1", "2.3", "15.2"), color = c("aquamarine3", "aquamarine3",
"aquamarine3", "aquamarine3", "orange1", "orange1", "lemonchiffon",
"goldenrod1", "lemonchiffon", "wheat4", "orange1", "aquamarine3",
"darkslategrey", "wheat4", "darkslategrey", "cyan", "goldenrod1",
"goldenrod1", "orange1", "orange1", "navajowhite1", "orange1", "orange1",
"wheat4", "orange1", "tomato", "goldenrod1", "navajowhite1",
"navajowhite1", "lemonchiffon", "darkred")), .Names = c("response",
"distance", "direction", "id", "color"), row.names = c(NA, -31L ), class =
"data.frame")

And I would like to fit a mixed effects model where the response is
my.df$response, the fixed effects are: as.numeric(my.df$distance) and
as.factor(my.df$direction), and the random effect isas.factor(my.df$id).

The attached plot (plot(x = my.df$distance*as.numeric(my.df$direction), y =
my.df$response, col = my.df$color, lwd = 2, xlab = "Direction", ylab =
"Response"))

gives me the sense that a generalized linear mixed effects model with a
Gamma family is appropriate, but I may be wrong.

Trying to fit such a model with:
library(lme4)
#set my.df$direction and my.df$id as factors
my.df$direction = as.factor(my.df$direction)
my.df$id = as.factor(my.df$id)
my.fit = glmer(response ~ distance + direction + (1|id), data = my.df,
family = Gamma())

I get many lines with a message of this sort:
(bG) nan @ pos 23: y= 0.549507; mu=-0.0772004; wt=1; y/mu=-7.11793;
log(y/mu) =1.#QNAN

And at the end this message:
Error: (maxstephalfit) PIRLS step-halvings failed to reduce deviance in
pwrssUpdate In addition: Warning message:
In checkScaleX(X, ctrl = control) : Some predictor variables are on very
different scales: consider rescaling

Are my data that messy that a glmer with a gamma family cannot be fitted to
them or am I doing something wrong?
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplot.png
Type: image/png
Size: 3669 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140705/b3e06eb7/attachment.png>

From bbolker at gmail.com  Sat Jul  5 23:46:37 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 5 Jul 2014 17:46:37 -0400
Subject: [R-sig-ME] Getting the error message: Error: (maxstephalfit)
 PIRLS step-halvings failed to reduce deviance in pwrssUpdate when trying to
 fit glmer to my data
In-Reply-To: <CAEDz9egpOP1zdNOe9ZJEzQJiWq9u5_6iE5=Kg13qQd9+NT_TMg@mail.gmail.com>
References: <CAEDz9egpOP1zdNOe9ZJEzQJiWq9u5_6iE5=Kg13qQd9+NT_TMg@mail.gmail.com>
Message-ID: <CABghstT96GiD17KcVOZSz4ed7uqt1_tgBCN1CsFm5g8iQN98+Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140705/a0f41d34/attachment.pl>

From bbolker at gmail.com  Sun Jul  6 00:10:22 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 5 Jul 2014 18:10:22 -0400
Subject: [R-sig-ME] glmer convergence warning
In-Reply-To: <CACNJNT-DRKLaQt5mEnWnuvK2VKMqS4aZTXq5tZHPx5bz1eBoFA@mail.gmail.com>
References: <CACNJNT-DRKLaQt5mEnWnuvK2VKMqS4aZTXq5tZHPx5bz1eBoFA@mail.gmail.com>
Message-ID: <CABghstQuGD4AkN-x-8-NiHntiwfLrbz06KGnhUDY77pBVEczqA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140705/1a89b968/attachment.pl>

From bbolker at gmail.com  Mon Jul  7 16:34:23 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 7 Jul 2014 10:34:23 -0400
Subject: [R-sig-ME] How to extract convergence code from lmer object?
In-Reply-To: <CAL79i+SPJtd-0PL0dfb5E3gxxq6+dkWVWm6_FXV_dy0oR=K9KA@mail.gmail.com>
References: <CAL79i+SPJtd-0PL0dfb5E3gxxq6+dkWVWm6_FXV_dy0oR=K9KA@mail.gmail.com>
Message-ID: <CABghstQOvvf2UbLKvFROU_DMS1kFL40k0WuUrtzL4QwidWGzaw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140707/a83b145f/attachment.pl>

From Issac.Hebert at ontario.ca  Mon Jul  7 16:47:04 2014
From: Issac.Hebert at ontario.ca (Hebert, Issac (MNR))
Date: Mon, 7 Jul 2014 14:47:04 +0000
Subject: [R-sig-ME] gls function - goodness of fit
Message-ID: <9EDF5E9411952D45897CC8AB1B669239010E78B1@CTSPIGDCAPMXS24.cihs.ad.gov.on.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140707/2b521c9c/attachment.pl>

From bbolker at gmail.com  Tue Jul  8 09:09:44 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 8 Jul 2014 07:09:44 +0000 (UTC)
Subject: [R-sig-ME] gls function - goodness of fit
References: <9EDF5E9411952D45897CC8AB1B669239010E78B1@CTSPIGDCAPMXS24.cihs.ad.gov.on.ca>
Message-ID: <loom.20140708T084638-153@post.gmane.org>

Hebert, Issac (MNR <Issac.Hebert at ...> writes:

>  Hello, I am using the gls function to model lake whitefish growth
> rates in response to selected climate variables.  I am comparing
> models using AIC and I would also like to report the goodness of fit
> of each model. However, I am having difficulty finding a method that
> can be used with the gls function. For several of the models I am
> including an ARMA correlation to correct for temporal
> autocorrelation within the models and therefore cannot simply use
> the r-squared values within a linear model.  Do you have any advice
> on this matter or know of a method that I can use?  Any
> help/guidance would be greatly appreciated.  Regards, Issac H?bert

  I don't know the answer (sorry), but I will suggest that this might be
a non-trivial statistical question; in general, 'simple' goodness-of-fit
questions become more difficult as soon as you encounter anything
more complicated than simple least-squares problem.  You can compare
your model to a null model and see if it is significantly better,
but I don't know whether any of the standard strategies (e.g. comparing
proportion of sum of squared residuals to those of a null model)
make sense in this case.               

library(nlme)
fm1 <- gls(follicles ~ sin(2*pi*Time) + cos(2*pi*Time), Ovary,
            correlation = corAR1(form = ~ 1 | Mare), method="ML")
fm0 <- update(fm1,.~1)
anova(fm0,fm1)
## ???

A Google Scholar search finds Buse (1973)
"Goodness of Fit in Generalized Least Squares Estimation"
DOI: 10.1080/00031305.1973.10479003

  Buse gives an expression for R^2 (eq. 15), although (1) this isn't
completely trivial (you have to set up an estimated
variance-covariance matrix for the residuals) and (2) Buse warns that
it shouldn't be taken too seriously (e.g. shouldn't be used for
statistical tests).
fo


From romanova.anastasiya at hotmail.com  Wed Jul  9 12:03:38 2014
From: romanova.anastasiya at hotmail.com (Anastasiia Romanova)
Date: Wed, 9 Jul 2014 14:03:38 +0400
Subject: [R-sig-ME] A question on item random effects
Message-ID: <DUB124-W101C2F8BA85FC93A530650EC0F0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140709/47636fbf/attachment.pl>

From bbolker at gmail.com  Wed Jul  9 18:41:27 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 09 Jul 2014 12:41:27 -0400
Subject: [R-sig-ME] A question on item random effects
In-Reply-To: <DUB124-W101C2F8BA85FC93A530650EC0F0@phx.gbl>
References: <DUB124-W101C2F8BA85FC93A530650EC0F0@phx.gbl>
Message-ID: <53BD70B7.1070507@gmail.com>

On 14-07-09 06:03 AM, Anastasiia Romanova wrote:
> Dear all,I would be very grateful if somebody helped me answering the
> following question.. I'm looking at some categorical (naming
> accuracy) data with glmer, and I would like to use items as a random
> factor. I have 4 participants that name the items. The problem is
> that items vary across participants quite considerably, which leads
> to one third of the items being named only by 1 participant. I have
> heard that you need at least 2 subjects to  give a response on one
> item to be able to include this item into the random effect analysis.
> Is that right? And if it is, can I avoid this problem somehow? Thank
> you very muchBest wishes,Anastasiya 

  A reproducible example might be nice, but I'll take a shot.

  In theory it should be possible to fit a random effect of item as long
as _any_ items are measured repeated times (they don't _all_ have to be
measured more than once).  In practice it may be difficult if only a
small fraction of items have been measured repeatedly.  It's hard to say
with precision what "small" means in the previous sentence, or how this
will come out in your case.  If you are in fact pushing your data too
hard, the symptoms will be convergence warnings and singular fits
(getME(.,"theta") including zero values, or VarCorr() including
variances of zero or correlations of +/- 1).  The singular fit is not
_necessarily_ wrong, but increases the chances of numerical errors and
complicates interpretation. One choice would be to use blme::bglmer() to
force your data away from the singular edge (but you would have to read
the corresponding paper to understand what you were actually doing).

  cheers
    Ben Bolker


From richard.zijdeman at gmail.com  Thu Jul 10 12:46:06 2014
From: richard.zijdeman at gmail.com (Richard Zijdeman)
Date: Thu, 10 Jul 2014 11:46:06 +0100
Subject: [R-sig-ME] visualising interaction with predict.merMod
Message-ID: <56910434-600C-4ECB-B339-F3079F3DC193@gmail.com>

Dear all,

I?ve fitted a model with the lme4 (version 1.1.7) package, using the glmer command. The only random component in the model is the intercept. The model contains an interaction with time and a dichotomous variable and I would like to visualise this interaction (the model actually contains more interactions and variables, but I don?t think this matters):

model1 <- glmer(dep.var ~ var1 + var2 + ? + time + var1_time + (1 | reff), data = data, family = binomial("logit?)) # where var1_time is the interaction

To visualise the interaction, I think I would need to predict new values from the model. To do so, I have used the actual data, but I don?t think that?s right:

pred.values <- predict(model1, type = "response")

I think I should create a new dataset, in which all variables are held at constant value (e.g. the mean), except for, in this case the main effects of the interaction and the interaction.

My questions are: 
- could someone please comment on my reflection (do I indeed need to create a new dataset)?
- If I indeed would need to create such a new dataset, with average values, how would I do that (my model actually contains a lot of variables)?

Thanks in advance,

Richard

From henrik.singmann at psychologie.uni-freiburg.de  Thu Jul 10 14:49:27 2014
From: henrik.singmann at psychologie.uni-freiburg.de (Henrik Singmann)
Date: Thu, 10 Jul 2014 14:49:27 +0200
Subject: [R-sig-ME] visualising interaction with predict.merMod
In-Reply-To: <56910434-600C-4ECB-B339-F3079F3DC193@gmail.com>
References: <56910434-600C-4ECB-B339-F3079F3DC193@gmail.com>
Message-ID: <53BE8BD7.70202@psychologie.uni-freiburg.de>

Hi Richard,

did you already check out the effects package? This probably can do what you want. See the following example:


require(effects)
require(lme4)

gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
               data = cbpp, family = binomial)
plot(Effect("period", gm1), rescale.axis = FALSE, ylim = c(0, 1))

rescale.axis = FALSE here leads to the probability scale being equally spaced on the y-axis.

Otherwise you probably want to create a new data.frame using mean values for all other variables than the one you are interested in and with the values you want to plot for the variable you are interested in (and most likely ignoring the random effects for the first try). expand.grid is usually your friend for doing so. An example is given in the prediction section of: http://rpubs.com/bbolker/glmmchapter

Note however, that for factors you need to have all levels present and need to aggregate across them after having obtained the predictions.

Hope that helps,
Henrik

Am 10.07.2014 12:46, schrieb Richard Zijdeman:
> Dear all,
>
> I?ve fitted a model with the lme4 (version 1.1.7) package, using the glmer command. The only random component in the model is the intercept. The model contains an interaction with time and a dichotomous variable and I would like to visualise this interaction (the model actually contains more interactions and variables, but I don?t think this matters):
>
> model1 <- glmer(dep.var ~ var1 + var2 + ? + time + var1_time + (1 | reff), data = data, family = binomial("logit?)) # where var1_time is the interaction
>
> To visualise the interaction, I think I would need to predict new values from the model. To do so, I have used the actual data, but I don?t think that?s right:
>
> pred.values <- predict(model1, type = "response")
>
> I think I should create a new dataset, in which all variables are held at constant value (e.g. the mean), except for, in this case the main effects of the interaction and the interaction.
>
> My questions are:
> - could someone please comment on my reflection (do I indeed need to create a new dataset)?
> - If I indeed would need to create such a new dataset, with average values, how would I do that (my model actually contains a lot of variables)?
>
> Thanks in advance,
>
> Richard
>

-- 
Dr. Henrik Singmann
Albert-Ludwigs-Universit?t Freiburg, Germany
http://www.psychologie.uni-freiburg.de/Members/singmann


From teplitsky at mnhn.fr  Fri Jul 11 16:21:49 2014
From: teplitsky at mnhn.fr (=?ISO-8859-1?Q?C=E9line_Teplitsky?=)
Date: Fri, 11 Jul 2014 16:21:49 +0200
Subject: [R-sig-ME] No residual variance using MCMCglmm
In-Reply-To: <20140623202213.236654ouzfcuqigw@www.staffmail.ed.ac.uk>
References: <53A42B85.4040203@mnhn.fr>
	<20140623202213.236654ouzfcuqigw@www.staffmail.ed.ac.uk>
Message-ID: <53BFF2FD.5030803@mnhn.fr>

Hi Jarrod,

many thanks for your answer. I've been trying to understand better the 
idea behind the models before answering, but I'd like to be sure I got 
this right.

In the data set I have
var(y)=0.68
mean(y)=0.52
and if I run a model with only intercept and residual, I get an 
intercept of -0.81, so that the expected variance would be 0.44, 
suggesting the data could be a bit overdispersed. But the residual in 
this model is collapsing on 0.

In your latest version of the course notes, you mention p37" if the 
residual was zero, then e would be a vector of zero and the model would 
conform to the standard Poisson glm." So do I get this right that no 
residual in a Poisson model is ok, just an indicator of no 
overdispersion, but is not per se a problem?

Many thanks again for your help

Cheers

Celine

Le 23/06/2014 21:22, Jarrod Hadfield a ?crit :
> Hi C?line,
>
> Zero residual variance with (truncated) Poisson response would imply 
> that the data are under-dispersed with respect to the (truncated) 
> Poisson model. You could check this by comparing the variance of the 
> data with the expected variance given the intercept.
>
>
> Cheers,
>
> Jarrod
>
>
>
> Quoting C?line Teplitsky <teplitsky at mnhn.fr> on Fri, 20 Jun 2014 
> 14:39:33 +0200:
>
>> Dear all,
>>
>> I have recently bumped twice in the same issue running glmm in 
>> MCMCglmm: the posterior distribution of residual collapses on 0. 
>> While I have often seen it for other effects (e.g ID) and interpreted 
>> it as evidence of non existence / non significance of these effects, 
>> I can not get why residual variance would not be well defined.
>>
>> More specifically, with priors V=1, nu=0.02, I was trying to estimate 
>> additive genetic variance in age at first breeding. I first tried a 
>> Poisson distribution and the posterior distribution of the residual 
>> looked more or less ok, although not perfectly bell shaped. Then I 
>> thought as age at first breeding could not be zero, that a zero 
>> truncated Poisson might be better but then the posterior distribution 
>> of residual variance totally collapses on zero. As I thought it could 
>> be due to over parametrisation, I rerun the model with only intercept 
>> but results were the same.
>>
>> Is it a problem with the variables distributions not really fitting 
>> the distribution I'm specifying? Any help would be greatly appreciated!
>>
>> Many thanks in advance
>>
>> Celine
>>
>> -- 
>>
>> Celine Teplitsky
>> UMR 7204 - CESCO
>> D?partement Ecologie et Gestion de la Biodiversit?
>> CP 51
>> 55 rue Buffon 75005 Paris
>>
>> Webpage : http://www2.mnhn.fr/cersp/spip.php?rubrique96
>> Fax : (33-1)-4079-3835
>> Phone: (33-1)-4079-3443
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
>

-- 

Celine Teplitsky
UMR 7204 - CESCO
D?partement Ecologie et Gestion de la Biodiversit?
CP 51
55 rue Buffon 75005 Paris

Webpage : http://www2.mnhn.fr/cersp/spip.php?rubrique96
Fax : (33-1)-4079-3835
Phone: (33-1)-4079-3443


From j.hadfield at ed.ac.uk  Fri Jul 11 17:11:39 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 11 Jul 2014 16:11:39 +0100
Subject: [R-sig-ME] No residual variance using MCMCglmm
In-Reply-To: <53BFF2FD.5030803@mnhn.fr>
References: <53A42B85.4040203@mnhn.fr>
	<20140623202213.236654ouzfcuqigw@www.staffmail.ed.ac.uk>
	<53BFF2FD.5030803@mnhn.fr>
Message-ID: <20140711161139.10984oaak2jdq0mc@www.staffmail.ed.ac.uk>

Hi Celine,

There is more variance than you expect (0.68/0.52 = 1.31X), but this  
might be consistent with chance if sample size is small. For example  
if n=30 you expect var(x)/mean(x) > 1.31 in about 10% of cases if  
lambda=0.52. For n=30 I would expect values of zero for the units  
variance to have some support in the posterior (conditional on the  
prior of course). For sample sizes of around 100 I would expect the  
posterior to be well away from zero. How many data do you have?

 From a model perspective having a units variance of zero is not a  
problem per se. From the perspective of MCMCglmm it will mean the  
chain will not mix (if it is always exactly zero) or mix slowly (if it  
is near zero).

Cheers,

Jarrod








Quoting C?line Teplitsky <teplitsky at mnhn.fr> on Fri, 11 Jul 2014  
16:21:49 +0200:

> Hi Jarrod,
>
> many thanks for your answer. I've been trying to understand better  
> the idea behind the models before answering, but I'd like to be sure  
> I got this right.
>
> In the data set I have
> var(y)=0.68
> mean(y)=0.52
> and if I run a model with only intercept and residual, I get an  
> intercept of -0.81, so that the expected variance would be 0.44,  
> suggesting the data could be a bit overdispersed. But the residual  
> in this model is collapsing on 0.
>
> In your latest version of the course notes, you mention p37" if the  
> residual was zero, then e would be a vector of zero and the model  
> would conform to the standard Poisson glm." So do I get this right  
> that no residual in a Poisson model is ok, just an indicator of no  
> overdispersion, but is not per se a problem?
>
> Many thanks again for your help
>
> Cheers
>
> Celine
>
> Le 23/06/2014 21:22, Jarrod Hadfield a ?crit :
>> Hi C?line,
>>
>> Zero residual variance with (truncated) Poisson response would  
>> imply that the data are under-dispersed with respect to the  
>> (truncated) Poisson model. You could check this by comparing the  
>> variance of the data with the expected variance given the intercept.
>>
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>> Quoting C?line Teplitsky <teplitsky at mnhn.fr> on Fri, 20 Jun 2014  
>> 14:39:33 +0200:
>>
>>> Dear all,
>>>
>>> I have recently bumped twice in the same issue running glmm in  
>>> MCMCglmm: the posterior distribution of residual collapses on 0.  
>>> While I have often seen it for other effects (e.g ID) and  
>>> interpreted it as evidence of non existence / non significance of  
>>> these effects, I can not get why residual variance would not be  
>>> well defined.
>>>
>>> More specifically, with priors V=1, nu=0.02, I was trying to  
>>> estimate additive genetic variance in age at first breeding. I  
>>> first tried a Poisson distribution and the posterior distribution  
>>> of the residual looked more or less ok, although not perfectly  
>>> bell shaped. Then I thought as age at first breeding could not be  
>>> zero, that a zero truncated Poisson might be better but then the  
>>> posterior distribution of residual variance totally collapses on  
>>> zero. As I thought it could be due to over parametrisation, I  
>>> rerun the model with only intercept but results were the same.
>>>
>>> Is it a problem with the variables distributions not really  
>>> fitting the distribution I'm specifying? Any help would be greatly  
>>> appreciated!
>>>
>>> Many thanks in advance
>>>
>>> Celine
>>>
>>> -- 
>>>
>>> Celine Teplitsky
>>> UMR 7204 - CESCO
>>> D?partement Ecologie et Gestion de la Biodiversit?
>>> CP 51
>>> 55 rue Buffon 75005 Paris
>>>
>>> Webpage : http://www2.mnhn.fr/cersp/spip.php?rubrique96
>>> Fax : (33-1)-4079-3835
>>> Phone: (33-1)-4079-3443
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>
>>
>
> -- 
>
> Celine Teplitsky
> UMR 7204 - CESCO
> D?partement Ecologie et Gestion de la Biodiversit?
> CP 51
> 55 rue Buffon 75005 Paris
>
> Webpage : http://www2.mnhn.fr/cersp/spip.php?rubrique96
> Fax : (33-1)-4079-3835
> Phone: (33-1)-4079-3443
>
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From teplitsky at mnhn.fr  Fri Jul 11 18:00:32 2014
From: teplitsky at mnhn.fr (Celine Teplitsky)
Date: Fri, 11 Jul 2014 18:00:32 +0200
Subject: [R-sig-ME] No residual variance using MCMCglmm
In-Reply-To: <20140711161139.10984oaak2jdq0mc@www.staffmail.ed.ac.uk>
References: <53A42B85.4040203@mnhn.fr>
	<20140623202213.236654ouzfcuqigw@www.staffmail.ed.ac.uk>
	<53BFF2FD.5030803@mnhn.fr>
	<20140711161139.10984oaak2jdq0mc@www.staffmail.ed.ac.uk>
Message-ID: <20140711180032.19166pwklos56m1s@dsiwebmail.mnhn.fr>

Hi Jarrod,

I actually have 254 observations (152 individuals), and I left the  
default prior

And indeed, the chain doesn't look very nice. But I can't get what is  
the prpoblem....

Cheers

Celine

> Hi Celine,
>
> There is more variance than you expect (0.68/0.52 = 1.31X), but this  
> might be consistent with chance if sample size is small. For example  
> if n=30 you expect var(x)/mean(x) > 1.31 in about 10% of cases if  
> lambda=0.52. For n=30 I would expect values of zero for the units  
> variance to have some support in the posterior (conditional on the  
> prior of course). For sample sizes of around 100 I would expect the  
> posterior to be well away from zero. How many data do you have?
>
> From a model perspective having a units variance of zero is not a  
> problem per se. From the perspective of MCMCglmm it will mean the  
> chain will not mix (if it is always exactly zero) or mix slowly (if  
> it is near zero).
>
> Cheers,
>
> Jarrod
>
>
>
>
>
>
>
>
> Quoting C?line Teplitsky <teplitsky at mnhn.fr> on Fri, 11 Jul 2014  
> 16:21:49 +0200:
>
>> Hi Jarrod,
>>
>> many thanks for your answer. I've been trying to understand better  
>> the idea behind the models before answering, but I'd like to be  
>> sure I got this right.
>>
>> In the data set I have
>> var(y)=0.68
>> mean(y)=0.52
>> and if I run a model with only intercept and residual, I get an  
>> intercept of -0.81, so that the expected variance would be 0.44,  
>> suggesting the data could be a bit overdispersed. But the residual  
>> in this model is collapsing on 0.
>>
>> In your latest version of the course notes, you mention p37" if the  
>> residual was zero, then e would be a vector of zero and the model  
>> would conform to the standard Poisson glm." So do I get this right  
>> that no residual in a Poisson model is ok, just an indicator of no  
>> overdispersion, but is not per se a problem?
>>
>> Many thanks again for your help
>>
>> Cheers
>>
>> Celine
>>
>> Le 23/06/2014 21:22, Jarrod Hadfield a ?crit :
>>> Hi C?line,
>>>
>>> Zero residual variance with (truncated) Poisson response would  
>>> imply that the data are under-dispersed with respect to the  
>>> (truncated) Poisson model. You could check this by comparing the  
>>> variance of the data with the expected variance given the intercept.
>>>
>>>
>>> Cheers,
>>>
>>> Jarrod
>>>
>>>
>>>
>>> Quoting C?line Teplitsky <teplitsky at mnhn.fr> on Fri, 20 Jun 2014  
>>> 14:39:33 +0200:
>>>
>>>> Dear all,
>>>>
>>>> I have recently bumped twice in the same issue running glmm in  
>>>> MCMCglmm: the posterior distribution of residual collapses on 0.  
>>>> While I have often seen it for other effects (e.g ID) and  
>>>> interpreted it as evidence of non existence / non significance of  
>>>> these effects, I can not get why residual variance would not be  
>>>> well defined.
>>>>
>>>> More specifically, with priors V=1, nu=0.02, I was trying to  
>>>> estimate additive genetic variance in age at first breeding. I  
>>>> first tried a Poisson distribution and the posterior distribution  
>>>> of the residual looked more or less ok, although not perfectly  
>>>> bell shaped. Then I thought as age at first breeding could not be  
>>>> zero, that a zero truncated Poisson might be better but then the  
>>>> posterior distribution of residual variance totally collapses on  
>>>> zero. As I thought it could be due to over parametrisation, I  
>>>> rerun the model with only intercept but results were the same.
>>>>
>>>> Is it a problem with the variables distributions not really  
>>>> fitting the distribution I'm specifying? Any help would be  
>>>> greatly appreciated!
>>>>
>>>> Many thanks in advance
>>>>
>>>> Celine
>>>>
>>>> -- 
>>>>
>>>> Celine Teplitsky
>>>> UMR 7204 - CESCO
>>>> D?partement Ecologie et Gestion de la Biodiversit?
>>>> CP 51
>>>> 55 rue Buffon 75005 Paris
>>>>
>>>> Webpage : http://www2.mnhn.fr/cersp/spip.php?rubrique96
>>>> Fax : (33-1)-4079-3835
>>>> Phone: (33-1)-4079-3443
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>>
>>>
>>>
>>
>> -- 
>>
>> Celine Teplitsky
>> UMR 7204 - CESCO
>> D?partement Ecologie et Gestion de la Biodiversit?
>> CP 51
>> 55 rue Buffon 75005 Paris
>>
>> Webpage : http://www2.mnhn.fr/cersp/spip.php?rubrique96
>> Fax : (33-1)-4079-3835
>> Phone: (33-1)-4079-3443
>>
>>
>>
>
>
>
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>
>



-- 

Celine Teplitsky
UMR 5173 MNHN-CNRS-P6 'Conservation des esp?ces, restauration et suivi des
populations'
Mus?um National d'Histoire Naturelle
CRBPO, 55, Rue Buffon, CP51, 75005 Paris, France

Fax : (33-1)-4079-3835
Phone: (33-1)-4079-3443


From j.hadfield at ed.ac.uk  Fri Jul 11 18:13:11 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 11 Jul 2014 17:13:11 +0100
Subject: [R-sig-ME] No residual variance using MCMCglmm
In-Reply-To: <20140711180032.19166pwklos56m1s@dsiwebmail.mnhn.fr>
References: <53A42B85.4040203@mnhn.fr>
	<20140623202213.236654ouzfcuqigw@www.staffmail.ed.ac.uk>
	<53BFF2FD.5030803@mnhn.fr>
	<20140711161139.10984oaak2jdq0mc@www.staffmail.ed.ac.uk>
	<20140711180032.19166pwklos56m1s@dsiwebmail.mnhn.fr>
Message-ID: <20140711171311.80929dqy5xnh2t5k@www.staffmail.ed.ac.uk>

Hi Celine,

Is this problem happening when individual is NOT fitted as a random  
term? If so, can you post the counts and I'll take a look? I'm not  
sure whether you can have attachments on the list. If not you can  
paste in the output from

paste("counts<-c(", paste(counts, collapse=","), ")", sep="")

into the body of the text, where counts are the data (surely there is  
a better way of doing this?).

Cheers,

Jarrod



Quoting Celine Teplitsky <teplitsky at mnhn.fr> on Fri, 11 Jul 2014  
18:00:32 +0200:

> Hi Jarrod,
>
> I actually have 254 observations (152 individuals), and I left the  
> default prior
>
> And indeed, the chain doesn't look very nice. But I can't get what  
> is the prpoblem....
>
> Cheers
>
> Celine
>
>> Hi Celine,
>>
>> There is more variance than you expect (0.68/0.52 = 1.31X), but  
>> this might be consistent with chance if sample size is small. For  
>> example if n=30 you expect var(x)/mean(x) > 1.31 in about 10% of  
>> cases if lambda=0.52. For n=30 I would expect values of zero for  
>> the units variance to have some support in the posterior  
>> (conditional on the prior of course). For sample sizes of around  
>> 100 I would expect the posterior to be well away from zero. How  
>> many data do you have?
>>
>> From a model perspective having a units variance of zero is not a  
>> problem per se. From the perspective of MCMCglmm it will mean the  
>> chain will not mix (if it is always exactly zero) or mix slowly (if  
>> it is near zero).
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>>
>>
>>
>>
>>
>> Quoting C?line Teplitsky <teplitsky at mnhn.fr> on Fri, 11 Jul 2014  
>> 16:21:49 +0200:
>>
>>> Hi Jarrod,
>>>
>>> many thanks for your answer. I've been trying to understand better  
>>> the idea behind the models before answering, but I'd like to be  
>>> sure I got this right.
>>>
>>> In the data set I have
>>> var(y)=0.68
>>> mean(y)=0.52
>>> and if I run a model with only intercept and residual, I get an  
>>> intercept of -0.81, so that the expected variance would be 0.44,  
>>> suggesting the data could be a bit overdispersed. But the residual  
>>> in this model is collapsing on 0.
>>>
>>> In your latest version of the course notes, you mention p37" if  
>>> the residual was zero, then e would be a vector of zero and the  
>>> model would conform to the standard Poisson glm." So do I get this  
>>> right that no residual in a Poisson model is ok, just an indicator  
>>> of no overdispersion, but is not per se a problem?
>>>
>>> Many thanks again for your help
>>>
>>> Cheers
>>>
>>> Celine
>>>
>>> Le 23/06/2014 21:22, Jarrod Hadfield a ?crit :
>>>> Hi C?line,
>>>>
>>>> Zero residual variance with (truncated) Poisson response would  
>>>> imply that the data are under-dispersed with respect to the  
>>>> (truncated) Poisson model. You could check this by comparing the  
>>>> variance of the data with the expected variance given the  
>>>> intercept.
>>>>
>>>>
>>>> Cheers,
>>>>
>>>> Jarrod
>>>>
>>>>
>>>>
>>>> Quoting C?line Teplitsky <teplitsky at mnhn.fr> on Fri, 20 Jun 2014  
>>>> 14:39:33 +0200:
>>>>
>>>>> Dear all,
>>>>>
>>>>> I have recently bumped twice in the same issue running glmm in  
>>>>> MCMCglmm: the posterior distribution of residual collapses on 0.  
>>>>> While I have often seen it for other effects (e.g ID) and  
>>>>> interpreted it as evidence of non existence / non significance  
>>>>> of these effects, I can not get why residual variance would not  
>>>>> be well defined.
>>>>>
>>>>> More specifically, with priors V=1, nu=0.02, I was trying to  
>>>>> estimate additive genetic variance in age at first breeding. I  
>>>>> first tried a Poisson distribution and the posterior  
>>>>> distribution of the residual looked more or less ok, although  
>>>>> not perfectly bell shaped. Then I thought as age at first  
>>>>> breeding could not be zero, that a zero truncated Poisson might  
>>>>> be better but then the posterior distribution of residual  
>>>>> variance totally collapses on zero. As I thought it could be due  
>>>>> to over parametrisation, I rerun the model with only intercept  
>>>>> but results were the same.
>>>>>
>>>>> Is it a problem with the variables distributions not really  
>>>>> fitting the distribution I'm specifying? Any help would be  
>>>>> greatly appreciated!
>>>>>
>>>>> Many thanks in advance
>>>>>
>>>>> Celine
>>>>>
>>>>> -- 
>>>>>
>>>>> Celine Teplitsky
>>>>> UMR 7204 - CESCO
>>>>> D?partement Ecologie et Gestion de la Biodiversit?
>>>>> CP 51
>>>>> 55 rue Buffon 75005 Paris
>>>>>
>>>>> Webpage : http://www2.mnhn.fr/cersp/spip.php?rubrique96
>>>>> Fax : (33-1)-4079-3835
>>>>> Phone: (33-1)-4079-3443
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>>
>>>>
>>>>
>>>
>>> -- 
>>>
>>> Celine Teplitsky
>>> UMR 7204 - CESCO
>>> D?partement Ecologie et Gestion de la Biodiversit?
>>> CP 51
>>> 55 rue Buffon 75005 Paris
>>>
>>> Webpage : http://www2.mnhn.fr/cersp/spip.php?rubrique96
>>> Fax : (33-1)-4079-3835
>>> Phone: (33-1)-4079-3443
>>>
>>>
>>>
>>
>>
>>
>> -- 
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>>
>>
>
>
>
> -- 
>
> Celine Teplitsky
> UMR 5173 MNHN-CNRS-P6 'Conservation des esp?ces, restauration et suivi des
> populations'
> Mus?um National d'Histoire Naturelle
> CRBPO, 55, Rue Buffon, CP51, 75005 Paris, France
>
> Fax : (33-1)-4079-3835
> Phone: (33-1)-4079-3443
>
>
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From dfulop.ucd at gmail.com  Sat Jul 12 04:29:10 2014
From: dfulop.ucd at gmail.com (Daniel Fulop)
Date: Fri, 11 Jul 2014 19:29:10 -0700
Subject: [R-sig-ME] Help with pdMat constructors in nlme
Message-ID: <53C09D76.4060509@gmail.com>

Dear All,

I am running into a known and unresolved issue in lme() having to do 
with how phylogenetic correlation structures (specifically corPagel with 
co-estimation of phylogenetic signal within the regression) interact 
with the formula-based way of specifying random effects: 
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2012q1/015015.html

I have a randomized block design in which the block factor is "plate" 
and multiple measurements per individual (specified by ID), which are 
nested within "plate" blocks.  So, the random formula I am using is: ~ 1 
| plate / ID.  It turns out that an lme() model with just ~ 1 | ID is 
slightly favored by AIC and BIC.

I am now trying to account for phylogeny and I've been able to get the 
model to run with gls() with the above two alternative random effects 
formulas.  However, when I try including either random effect formula 
and corPagel in lme() I get the error mentioned in the linked r-sig-me 
archived post, i.e.:

Error in corFactor.corStruct(object) :
   NA/NaN/Inf in foreign function call (arg 1)

 From Simon Blomberg's post I get that when using corPagel specifying 
the random effects using pdMat constructors is more robust than doing so 
with a formula.  However, I have read parts of Pinheiro & Bates and 
other resources on the web, but I cannot seem to properly specify a 
either "~ 1 | plate / ID" nor "~ 1 | ID" with pdMat constructors and I 
keep on getting a variety of errors when I do so.

So, can someone please help me specify "~ 1 | plate / ID" and "~ 1 | ID" 
with pdMat constructors?

Thanks!
Dan.

-- 
Daniel Fulop, Ph.D.
Postdoctoral Scholar
Dept. Plant Biology, UC Davis
Maloof Lab, Rm. 2220
Life Sciences Addition, One Shields Ave.
Davis, CA 95616


From russell-lenth at uiowa.edu  Sat Jul 12 18:53:47 2014
From: russell-lenth at uiowa.edu (Lenth, Russell V)
Date: Sat, 12 Jul 2014 16:53:47 +0000
Subject: [R-sig-ME] visualising interaction with predict.merMod
Message-ID: <51F0C7C54B032A42A23B74A088E7141C2E57DBBE@itsnt443.iowa.uiowa.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140712/ba6ff3d2/attachment.pl>

From richard.zijdeman at gmail.com  Sun Jul 13 13:31:02 2014
From: richard.zijdeman at gmail.com (Richard Zijdeman)
Date: Sun, 13 Jul 2014 12:31:02 +0100
Subject: [R-sig-ME] visualising interaction with predict.merMod
In-Reply-To: <51F0C7C54B032A42A23B74A088E7141C2E57DBBE@itsnt443.iowa.uiowa.edu>
References: <51F0C7C54B032A42A23B74A088E7141C2E57DBBE@itsnt443.iowa.uiowa.edu>
Message-ID: <AA45C033-8925-491F-8053-19F29936573F@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140713/b1bf969d/attachment.pl>

From nlange at hms.harvard.edu  Sun Jul 13 14:13:17 2014
From: nlange at hms.harvard.edu (Nicholas Lange)
Date: Sun, 13 Jul 2014 08:13:17 -0400
Subject: [R-sig-ME] gamm4 model fit error
Message-ID: <982780C0-8FE9-4EED-935F-CEA50E1AB373@hms.harvard.edu>

Hello,

I'm running R.3.1.1 on Mac OS X 10.6.8 with gamm4 version 0.2-2 and lme4 version 1.1-7. I get the following error when trying to fit the simplest gamm4 model I can think of:

> fit = gamm4( y ~ s(x))

Warning message:
In deviance.merMod(ret$mer) :
 deviance() is deprecated for REML fits; use REMLcrit for the REML criterion or deviance(.,REML=FALSE) for deviance calculated at the REML fit.

> fit

$mer
Linear mixed model fit by REML ['lmerMod']
REML criterion at convergence: 3891.265
Random effects:
 Groups   Name        Std.Dev.
 LabID    (Intercept) 112.16  
 Xr       s(AgeYears) 452.89  
 Residual              35.24  
Number of obs: 343, groups:  LabID, 156; Xr, 8
Fixed Effects:
   X(Intercept)  Xs(AgeYears)Fx1  
        1310.73            23.13  

$gam

Family: gaussian 
Link function: identity 

Formula:
TotalBrain ~ s(AgeYears)

Estimated degrees of freedom:
5.28  total = 6.28 

lmer.REML score: 3891.265     

Not the usual regression summary table, no p-values.

Does anyone see what's wrong? Any help would be greatly appreciated.

Nick


From bbolker at gmail.com  Sun Jul 13 17:33:46 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 13 Jul 2014 11:33:46 -0400
Subject: [R-sig-ME] gamm4 model fit error
In-Reply-To: <982780C0-8FE9-4EED-935F-CEA50E1AB373@hms.harvard.edu>
References: <982780C0-8FE9-4EED-935F-CEA50E1AB373@hms.harvard.edu>
Message-ID: <53C2A6DA.3010405@gmail.com>

On 14-07-13 08:13 AM, Nicholas Lange wrote:
> Hello,

> I'm running R.3.1.1 on Mac OS X 10.6.8 with gamm4 version 0.2-2 and
>  lme4 version 1.1-7. I get the following error when trying to fit the
>  simplest gamm4 model I can think of:

>> fit = gamm4( y ~ s(x))
> 


> Warning message: In deviance.merMod(ret$mer) : deviance() is
> deprecated for REML fits; use REMLcrit for the REML criterion or
> deviance(.,REML=FALSE) for deviance calculated at the REML fit.

Note that in R terminology this is a warning, not an error (sorry to
be fussy about terminology, but it helps to be precise).  This is
due to a change in 1.1-7 -- we apologize to the gamm4 maintainers,
presumably they can fix this up in a future release.  It should
be harmless, though.


>> fit
> 
> $mer
> Linear mixed model fit by REML ['lmerMod']
> REML criterion at convergence: 3891.265
> Random effects:
>  Groups   Name        Std.Dev.
>  LabID    (Intercept) 112.16  
>  Xr       s(AgeYears) 452.89  
>  Residual              35.24  
> Number of obs: 343, groups:  LabID, 156; Xr, 8
> Fixed Effects:
>    X(Intercept)  Xs(AgeYears)Fx1  
>         1310.73            23.13  
> 
> $gam
> 
> Family: gaussian 
> Link function: identity 
> 
> Formula:
> TotalBrain ~ s(AgeYears)
> 
> Estimated degrees of freedom:
> 5.28  total = 6.28 
> 
> lmer.REML score: 3891.265     
> 
> Not the usual regression summary table, no p-values.
> 
> Does anyone see what's wrong? Any help would be greatly appreciated.
> 
> Nick

  It's been a while since I've looked at gamm4.  Just to be precise,
is this the first time you've used gamm4 -- i.e. this is not a change
from previous versions?  I *think* the answer is that you need to
operate on the $mer component of the result, e.g.

coef(summary(fit$mer))

... but perhaps someone with more experience of gamm4 can comment.


  Ben Bolker


From nlange at hms.harvard.edu  Mon Jul 14 00:52:00 2014
From: nlange at hms.harvard.edu (Nicholas Lange)
Date: Sun, 13 Jul 2014 18:52:00 -0400
Subject: [R-sig-ME] gamm4 model fit error
In-Reply-To: <982780C0-8FE9-4EED-935F-CEA50E1AB373@hms.harvard.edu>
References: <982780C0-8FE9-4EED-935F-CEA50E1AB373@hms.harvard.edu>
Message-ID: <63CC917E-BB28-4867-937F-AE9BFB0B0652@hms.harvard.edu>

Hello,

I figured it out: fit$gam for the full table.
(this was a Warning, not an Error.)

Nick


From bbolker at gmail.com  Mon Jul 14 02:42:54 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 13 Jul 2014 20:42:54 -0400
Subject: [R-sig-ME] gamm4 model fit error
In-Reply-To: <F6D38B9D-B386-4897-9AAC-92921D5A2849@hms.harvard.edu>
References: <982780C0-8FE9-4EED-935F-CEA50E1AB373@hms.harvard.edu>
	<53C2A6DA.3010405@gmail.com>
	<F6D38B9D-B386-4897-9AAC-92921D5A2849@hms.harvard.edu>
Message-ID: <53C3278E.7020907@gmail.com>

On 14-07-13 01:37 PM, Nick Lange wrote:
> Thanks, Ben,
> 
> Yes, a warning not and error, thanks. And also, yes, this is the
> first time I've used gamm4.
> 
> I tried coef(summary(fit$mer))
> 
> and it gave an improved regression summary table, but without
> p-values:
> 
> Estimate Std. Error     t value X(Intercept)    1310.68401   9.204793
> 142.3914670 Xs(AgeYears)Fx1   19.89873  25.072824   0.7936372
> 
> which I can't calculate without the df (but it's large).

  I'm not surprised that you don't get p-values: there is even an R FAQ
on this subject

http://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-are-p_002dvalues-not-displayed-when-using-lmer_0028_0029_003f

(which simply refers to

https://stat.ethz.ch/pipermail/r-help/2006-May/094765.html

 -- you may also want to look at http://glmm.wikidot.com/faq)

> 
> My colleague has the same versions as I do, except she's running lme4
> 1.1-6 not lme4 1.1-7. Everything works fine for her.

  I'm not surprised she doesn't get the warning messages (those were
introduced in 1.1-6), but I *am* surprised if she gets p-values.  Since
you have large degrees of freedom, you could just compute two-tailed
p-values as:

cc  <- coef(summary(fit$mer))
2*pnorm(abs(cc[,"t value"]),lower.tail=FALSE)

or

2*pnorm(-abs(cc["t value"]))



> 
> I've been using R for decades (was at MIT when Ross Ihaka has writing
> it) but have never joined the sigs. How do I post this reply on the
> R-sig-ME thread?
> 
> Nick
>


From nlange at hms.harvard.edu  Mon Jul 14 23:37:47 2014
From: nlange at hms.harvard.edu (Nick Lange)
Date: Mon, 14 Jul 2014 17:37:47 -0400
Subject: [R-sig-ME] gamm4: extract the (x,y) values of the plotted smooth
Message-ID: <9F191B81-11E1-4BB3-A58C-1EE5F742C32C@hms.harvard.edu>

Hello again,

I need to re-label the y-axis of a gamm4() plot with the original y values. Does anyone know how to do this? And/or does anyone know how to extract the (x,y) values of the plotted smooth? One can do this with those.

Thanks,

Nick


From bbolker at gmail.com  Tue Jul 15 03:38:07 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 14 Jul 2014 21:38:07 -0400
Subject: [R-sig-ME] Very important question regarding the error while
	using library(lme4)
In-Reply-To: <6f06fbdfb50e494e9124ea4711573ae8@CO1PR01MB206.prod.exchangelabs.com>
References: <6f06fbdfb50e494e9124ea4711573ae8@CO1PR01MB206.prod.exchangelabs.com>
Message-ID: <CABghstR5aLOAr3siG0vZiVJDjNxb9qGrVXVRyd+Bunr1U=ca7A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140714/f02c9827/attachment.pl>

From bbolker at gmail.com  Tue Jul 15 04:28:12 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 14 Jul 2014 22:28:12 -0400
Subject: [R-sig-ME] R2admb-package
In-Reply-To: <53C3A008.5080508@icm.csic.es>
References: <53B29728.8070704@icm.csic.es>	<53B32206.5020106@gmail.com>	<53B407D8.2040309@icm.csic.es>
	<CABghstT=f7FZ8xh__NNC5BFNFRi3JoRJWH79oeHcT4az5Z8-LQ@mail.gmail.com>
	<53B6C5BB.30904@icm.csic.es> <53C3A008.5080508@icm.csic.es>
Message-ID: <53C491BC.5000501@gmail.com>

  [cc'ing to r-sig-mixed-models]

  Yes, sort of: see the caveats listed at
http://glmm.wikidot.com/faq#random-sig, in particular the last one (the
LRT is conservative for tests of null hypotheses where the parameter is
at the boundary). anova(m1,m2) should give you a likelihood ratio test
for the difference.

  glmmADMB uses the Laplace approximation to maximum likelihood estimation.

On 14-07-14 05:16 AM, Elena Guerrero wrote:
> Dear Ben,
> 
> Is it possible to compare a glmmADMB model with a random term and and
> the same model without that random term, with an ANOVA, in order to know
> if the random term is significantly important? Does glmmADMB package use
> ML method? I have seen (http://glmm.wikidot.com/pkg-comparison) that it
> uses the Laplace estimation method, it is possible to make such
> comparison with this method?
> 
> My model is of the following type:
> Mugg_glmmADMB<-glmmadmb(Mugg ~ S10 + T10 + F10 + Prof+ offset (L.vol) +
> (1|Est), link = "log",
>                      data =tabla10m, zeroInflation=FALSE, family="nbinom")
> 
> Thank you very much in advance.
> Best regards,
> Elena


> 
> --
> Elena Guerrero S?nchez-Guerrero
> PhD student
> Dept. Biologia Marina i Oceanografia
> INSTITUTO DE CIENCIAS DEL MAR - CSIC
> Pg. Mar?tim de la Barceloneta, 37-49
> 08003 BARCELONA
> Spain
> Phone:(+34) 93 230 95 00 (ext. 1209)
> Fax: (+34) 93 230 95 55 
> http://www.icm.csic.es/icmdivulga/es/mediterraneo-monograficos-08.htm
> http://www.icm.csic.es/bio/
> 
> El 04/07/14 17:18, Elena Guerrero escribi?:
>> Great, thank you very much Ben. I've got it!
>>
>> All the best,
>> Elena
>> --
>> Elena Guerrero S?nchez-Guerrero
>> PhD student
>> Dept. Biologia Marina i Oceanografia
>> INSTITUTO DE CIENCIAS DEL MAR - CSIC
>> Pg. Mar?tim de la Barceloneta, 37-49
>> 08003 BARCELONA
>> Spain
>> Phone:(+34) 93 230 95 00 (ext. 1209)
>> Fax: (+34) 93 230 95 55 
>> http://www.icm.csic.es/icmdivulga/es/mediterraneo-monograficos-08.htm
>> http://www.icm.csic.es/bio/
>> El 03/07/14 00:42, Ben Bolker escribi?:
>>> -2*logLik() is the deviance, so you should be able to fill that into
>>> the formula.  To get the null deviance you will need something like
>>> null.model <- update(full.model, [formula including only an intercept
>>> term in the fixed effects]).  It is up to you to decide what a
>>> 'sensible' null model is -- i.e. whether it includes the random
>>> effects or not ...
>>>
>>>
>>> On Wed, Jul 2, 2014 at 9:23 AM, Elena Guerrero <eguerrero at icm.csic.es
>>> <mailto:eguerrero at icm.csic.es>> wrote:
>>>
>>>     Dear Ben,
>>>
>>>     Thank you very much for your fast reply.
>>>
>>>     I've tried: "-2*logLik(My glmmADMB)" and it gave me: 'log Lik.'
>>>     1854.08 (df=7).
>>>
>>>     How should I interpret this result? Is is possible to obtain a
>>>     proportion % value of the explained deviance by the model?
>>>
>>>     Thank you very much!
>>>     All the best,
>>>     Elena
>>>
>>>
>>>     --
>>>     Elena Guerrero S?nchez-Guerrero
>>>     PhD student
>>>     Dept. Biologia Marina i Oceanografia
>>>     INSTITUTO DE CIENCIAS DEL MAR - CSIC
>>>     Pg. Mar?tim de la Barceloneta, 37-49
>>>     08003 BARCELONA
>>>     Spain
>>>     Phone:(+34) 93 230 95 00 <tel:%28%2B34%29%2093%20230%2095%2000>
>>>     (ext. 1209)
>>>     Fax: (+34) 93 230 95 55 <tel:%28%2B34%29%2093%20230%2095%2055>
>>>     http://www.icm.csic.es/icmdivulga/es/mediterraneo-monograficos-08.htm
>>>     http://www.icm.csic.es/bio/
>>>
>>>     El 01/07/14 23:03, Ben Bolker escribi?:
>>>
>>>           [cc'ing to R-sig-mixed-models]
>>>
>>>            There appears to be a deviance() method for 'admb' objects
>>>         (produced
>>>         by R2ADMB), but not for 'glmmadmb" objects (produced by
>>>         glmmADMB).
>>>         However, you should be able to use -2*logLik(object) to
>>>         obtain the
>>>         deviance (to be precise, -2*logLik(object) is equal to the
>>>         deviance in
>>>         general only _up to an additive constant_, but I think this
>>>         workaround
>>>         will be OK for your purposes).
>>>
>>>            Ben Bolker
>>>
>>>
>>>         On 14-07-01 07:10 AM, Elena Guerrero wrote:
>>>
>>>             Dear Ben Bolker,
>>>
>>>             I have run a glmmADMB model to my count data with a
>>>             family = "nbinom" .
>>>             It worked very nice.
>>>
>>>             Now I want to calculate the *deviance explained* by this
>>>             model
>>>             (100*(Null deviance-Residual deviance)/Null deviance). I
>>>             installed the
>>>             R2admb package to use the deviance() function, however
>>>             when I write
>>>             deviance(my model) R gives me "NULL" as a response. When
>>>             I try with the
>>>             "admbex" example it works perfectly.
>>>
>>>             What is it happening? What does mean NULL in this case?
>>>             Is there any
>>>             other way to obtain the explained deviance of a glmmADMB
>>>             model?
>>>
>>>             Thank you very much in advance.
>>>             Best regards,
>>>             Elena
>>>
>>>             -- 
>>>             --
>>>             Elena Guerrero S?nchez-Guerrero
>>>             PhD student
>>>             Dept. Biologia Marina i Oceanografia
>>>             INSTITUTO DE CIENCIAS DEL MAR - CSIC
>>>             Pg. Mar?tim de la Barceloneta, 37-49
>>>             08003 BARCELONA
>>>             Spain
>>>             Phone:(+34) 93 230 95 00
>>>             <tel:%28%2B34%29%2093%20230%2095%2000> (ext. 1209)
>>>             Fax: (+34) 93 230 95 55
>>>             <tel:%28%2B34%29%2093%20230%2095%2055>
>>>             http://www.icm.csic.es/icmdivulga/es/mediterraneo-monograficos-08.htm
>>>             http://www.icm.csic.es/bio/
>>>
>>>
>>>
>>
>


From Julia.Sommerfeld at utas.edu.au  Tue Jul 15 10:35:10 2014
From: Julia.Sommerfeld at utas.edu.au (Julia Sommerfeld)
Date: Tue, 15 Jul 2014 10:35:10 +0200
Subject: [R-sig-ME] How to deal with Hessian error if the model only
 contains binomial (0, 1) fixed factors?
Message-ID: <CAOCHjhQyOapdFxi-B7L-wEQtybOG+Y-tPkjY0dg6=Ma0K5XAPQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140715/dd3f4e98/attachment.pl>

From Thierry.ONKELINX at inbo.be  Tue Jul 15 10:57:30 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 15 Jul 2014 08:57:30 +0000
Subject: [R-sig-ME] How to deal with Hessian error if the model only
 contains binomial (0, 1) fixed factors?
In-Reply-To: <CAOCHjhQyOapdFxi-B7L-wEQtybOG+Y-tPkjY0dg6=Ma0K5XAPQ@mail.gmail.com>
References: <CAOCHjhQyOapdFxi-B7L-wEQtybOG+Y-tPkjY0dg6=Ma0K5XAPQ@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3AC0F2F@inbomail.inbo.be>

Dear Julia,

It looks like a problem of (quasi-)complete separation. The random effect structure is rather complicated given your data. You have only a few bird:year combinations with multiple observations. Furthermore year has only 3 levels, which very low to fit as a random effect.

So you'll need to rethink your model.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Julia Sommerfeld
Verzonden: dinsdag 15 juli 2014 10:35
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] How to deal with Hessian error if the model only contains binomial (0, 1) fixed factors?

Hi list,

I have the following model:

*mod <-  glmer(samemate ~ success + type + (1|year/bird), family=binomial,
data=dat)*

All variables are binomial:

"samemate" = 0 or 1
"success" = 0 or 1
"type" = first or replacement

The data look like this:

bird     year   samemate  success    type
A         2        0                 0               first
A         2        1                 1               replacement
B         1        1                 0               first
C         1        0                 1               first

and so on....

When I run the model I get following error message:

1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  unable to evaluate scaled gradient
2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
   Hessian is numerically singular: parameters are not uniquely determined Warning messages:
1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  unable to evaluate scaled gradient
2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
   Hessian is numerically singular: parameters are not uniquely determined

One solution to this seems to standardize the model:

*> st.mod <- standardize(mod, standardize.y=FALSE)*


But this gives the following error message:

Warning message:
In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model is nearly unidentifiable: large eigenvalue ratio
 - Rescale variables?
Warning message:
In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model is nearly unidentifiable: large eigenvalue ratio
 - Rescale variables?

The model output of the standardized model is:

*summary(st.mod)*
Generalized linear mixed model fit by maximum likelihood (Laplace
Approximation) ['glmerMod']
 Family: binomial  ( logit )
Formula: samemate ~ c.success + c.type + (1 | year/bird)
   Data: dat

     AIC      BIC   logLik deviance df.resid
    56.0     66.9    -23.0     46.0       61

Scaled residuals:
    Min      1Q  Median      3Q     Max
-2.7386  0.0000  0.0000  0.3651  0.8165

Random effects:
 Groups     Name        Variance  Std.Dev.
 bird:year (Intercept)  2.672e-08 0.0001635
 year      (Intercept) 0.000e+00 0.0000000
Number of obs: 66, groups:  bird:year, 59; year, 3

Fixed effects:
                   Estimate Std. Error    z value   Pr(>|z|)
(Intercept)  12.6988   165.3971   0.077      0.9388
c.success    1.6094     0.8572      1.878      0.0605 .
c.type         32.6667   454.8498   0.072       0.9427
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Correlation of Fixed Effects:
           (Intr)  c.fld1
c.success    -0.006
c.type          1.000 -0.006
Generalized linear mixed model fit by maximum likelihood (Laplace
Approximation) ['glmerMod']
 Family: binomial  ( logit )
Formula: samemate ~ c.success + c.type + (1 | year/bird)
   Data: dat

     AIC      BIC   logLik deviance df.resid
    56.0     66.9    -23.0     46.0       61

Scaled residuals:
    Min      1Q  Median      3Q     Max
-2.7386  0.0000  0.0000  0.3651  0.8165

Random effects:
 Groups     Name        Variance     Std.Dev.
 bird:year (Intercept)   2.672e-08   0.0001635
 year      (Intercept)     0.000e+00  0.0000000
Number of obs: 66, groups:  bird:year, 59; year, 3

Fixed effects:
                    Estimate    Std. Error   z value  Pr(>|z|)
(Intercept)    12.6988    165.3971   0.077     0.9388
c.success    1.6094      0.8572       1.878     0.0605 .
c.type          32.6667    454.8498   0.072     0.9427
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Correlation of Fixed Effects:
           (Intr) c.fld1
c.success -0.006
c.type   1.000 -0.006
>


*Do I need to worry about the error message? Does it even make sense to standardize a model that only contains binomial variables? How could I possibly rescale 0,1 variables? *

When I run a glm, I don't get the error message:

*mod <-  glm(samemate ~ success + type, family=binomial, data=dat)*


> summary(mod)

Call:
glm(formula = samemate ~ fledged1 + clutch2, family = binomial,
    data = dat)

Deviance Residuals:
     Min        1Q    Median        3Q       Max
-2.06885   0.00008   0.00008   0.50033   1.01077

Coefficients:

Call:
glm(formula = samemate ~ fledged1 + clutch2, family = binomial,
    data = dat)

Deviance Residuals:
     Min        1Q    Median        3Q       Max
-2.06885   0.00008   0.00008   0.50033   1.01077

Coefficients:
                          Estimate Std. Error z value Pr(>|z|)
(Intercept)           0.4055     0.4082   0.993   0.3206
success              1.6094     0.8563   1.879   0.0602 .
typereplacement   19.1606  2195.1537   0.009   0.9930
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 62.586  on 65  degrees of freedom Residual deviance: 45.966  on 63  degrees of freedom
AIC: 51.966

Number of Fisher Scoring iterations: 18

*Could the glmer fail, because I only have 66 observation for 59 birds and only 3 years? Considering this and the very small variance explained by bird and year, shall I stick to the glm?*

Any suggestion or thoughts on this would be highly appreciated.

Cheers

Julia

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From Julia.Sommerfeld at utas.edu.au  Tue Jul 15 11:12:09 2014
From: Julia.Sommerfeld at utas.edu.au (Julia Sommerfeld)
Date: Tue, 15 Jul 2014 11:12:09 +0200
Subject: [R-sig-ME] How to deal with Hessian error if the model only
 contains binomial (0, 1) fixed factors?
In-Reply-To: <AA818EAD2576BC488B4F623941DA7427F3AC0F2F@inbomail.inbo.be>
References: <CAOCHjhQyOapdFxi-B7L-wEQtybOG+Y-tPkjY0dg6=Ma0K5XAPQ@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA7427F3AC0F2F@inbomail.inbo.be>
Message-ID: <CAOCHjhRXrwaNLrzO994DBSa=NM4xzoTRdg1JEJB4auNECS3V1w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140715/5c815206/attachment.pl>

From Thierry.ONKELINX at inbo.be  Tue Jul 15 11:50:21 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 15 Jul 2014 09:50:21 +0000
Subject: [R-sig-ME] How to deal with Hessian error if the model only
 contains binomial (0, 1) fixed factors?
In-Reply-To: <CAOCHjhRXrwaNLrzO994DBSa=NM4xzoTRdg1JEJB4auNECS3V1w@mail.gmail.com>
References: <CAOCHjhQyOapdFxi-B7L-wEQtybOG+Y-tPkjY0dg6=Ma0K5XAPQ@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA7427F3AC0F2F@inbomail.inbo.be>
	<CAOCHjhRXrwaNLrzO994DBSa=NM4xzoTRdg1JEJB4auNECS3V1w@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3AC0F9D@inbomail.inbo.be>

Een ingesloten tekst met niet-gespecificeerde tekenset is gescrubt ...
Naam: niet beschikbaar
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140715/cdf772ad/attachment.pl>

From bbolker at gmail.com  Tue Jul 15 19:11:14 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 15 Jul 2014 13:11:14 -0400
Subject: [R-sig-ME] Very important question regarding the error while
	using library(lme4)
In-Reply-To: <CAE7K-2y6D=iq4bkVbKwFaed-ubgb3_+s7HZYH6npW7_aOk5PPg@mail.gmail.com>
References: <6f06fbdfb50e494e9124ea4711573ae8@CO1PR01MB206.prod.exchangelabs.com>
	<10409ed046874fb88bd0f59a75beb563@CO1PR01MB206.prod.exchangelabs.com>
	<C066842E-4974-4370-8F6D-D794B95F40BB@gmail.com>
	<CABghstTXT43rFNF9ptKibAOhArDaLSZ1hffWvypVXQk6B8v4kg@mail.gmail.com>
	<CAE7K-2y6D=iq4bkVbKwFaed-ubgb3_+s7HZYH6npW7_aOk5PPg@mail.gmail.com>
Message-ID: <CABghstTh+cvCx6v8W0uOM4sWTTNq=cj2PEB4vx7b21kv3zrhaw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140715/15eab6aa/attachment.pl>

From stevedrd at yahoo.com  Tue Jul 15 20:15:07 2014
From: stevedrd at yahoo.com (Steve Denham)
Date: Tue, 15 Jul 2014 11:15:07 -0700
Subject: [R-sig-ME] Very important question regarding the error
	while	using library(lme4)
In-Reply-To: <CABghstTh+cvCx6v8W0uOM4sWTTNq=cj2PEB4vx7b21kv3zrhaw@mail.gmail.com>
References: <6f06fbdfb50e494e9124ea4711573ae8@CO1PR01MB206.prod.exchangelabs.com>	<10409ed046874fb88bd0f59a75beb563@CO1PR01MB206.prod.exchangelabs.com>	<C066842E-4974-4370-8F6D-D794B95F40BB@gmail.com>	<CABghstTXT43rFNF9ptKibAOhArDaLSZ1hffWvypVXQk6B8v4kg@mail.gmail.com>	<CAE7K-2y6D=iq4bkVbKwFaed-ubgb3_+s7HZYH6npW7_aOk5PPg@mail.gmail.com>
	<CABghstTh+cvCx6v8W0uOM4sWTTNq=cj2PEB4vx7b21kv3zrhaw@mail.gmail.com>
Message-ID: <1405448107.13727.YahooMailNeo@web164501.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140715/f4d5b20d/attachment.pl>

From Julia.Sommerfeld at utas.edu.au  Wed Jul 16 08:29:38 2014
From: Julia.Sommerfeld at utas.edu.au (Julia Sommerfeld)
Date: Wed, 16 Jul 2014 08:29:38 +0200
Subject: [R-sig-ME] How to deal with Hessian error if the model only
 contains binomial (0, 1) fixed factors?
In-Reply-To: <AA818EAD2576BC488B4F623941DA7427F3AC0F9D@inbomail.inbo.be>
References: <CAOCHjhQyOapdFxi-B7L-wEQtybOG+Y-tPkjY0dg6=Ma0K5XAPQ@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA7427F3AC0F2F@inbomail.inbo.be>
	<CAOCHjhRXrwaNLrzO994DBSa=NM4xzoTRdg1JEJB4auNECS3V1w@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA7427F3AC0F9D@inbomail.inbo.be>
Message-ID: <CAOCHjhRs23kg=QRe==Ta23cRjswV-Pi-Yax0K2WPz2ZW3mkKTA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140716/9edae7a0/attachment.pl>

From Thierry.ONKELINX at inbo.be  Wed Jul 16 09:55:23 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 16 Jul 2014 07:55:23 +0000
Subject: [R-sig-ME] How to deal with Hessian error if the model only
 contains binomial (0, 1) fixed factors?
In-Reply-To: <CAOCHjhRs23kg=QRe==Ta23cRjswV-Pi-Yax0K2WPz2ZW3mkKTA@mail.gmail.com>
References: <CAOCHjhQyOapdFxi-B7L-wEQtybOG+Y-tPkjY0dg6=Ma0K5XAPQ@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA7427F3AC0F2F@inbomail.inbo.be>
	<CAOCHjhRXrwaNLrzO994DBSa=NM4xzoTRdg1JEJB4auNECS3V1w@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA7427F3AC0F9D@inbomail.inbo.be>
	<CAOCHjhRs23kg=QRe==Ta23cRjswV-Pi-Yax0K2WPz2ZW3mkKTA@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3AC12C6@inbomail.inbo.be>

Een ingesloten tekst met niet-gespecificeerde tekenset is gescrubt ...
Naam: niet beschikbaar
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140716/7a5d982f/attachment.pl>

From highstat at highstat.com  Wed Jul 16 12:04:04 2014
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Wed, 16 Jul 2014 11:04:04 +0100
Subject: [R-sig-ME] New book: Beginner's Guide to GAMM with R
Message-ID: <53C64E14.5080006@highstat.com>


We are please to announce the following book:

Title: Beginner's Guide to GAMM with R.
Authors: Zuur, Saveliev, Ieno


Book website: http://www.highstat.com/BGGAMM.htm
Paperback, hardcover or EBook can be order (exclusively) from: 
http://www.highstat.com/bookorder.htm
Table of Contents: http://www.highstat.com/BGS/GAMM/TOC_7_12.pdf

Keywords:
In this book we take the reader on an exciting voyage into the world of 
generalised additive mixed effects models (GAMM). Keywords are GAM, 
mgcv, gamm4, random effects, Poisson and negative binomial GAMM, gamma 
GAMM, binomial GAMM, negative binomial-P models, GAMMs with generalised 
extreme value distributions, overdispersion, underdispersion, 
two-dimensional smoothers, zero-inflated GAMMs, spatial correlation, 
INLA, Markov chain Monte Carlo techniques, JAGS, and two-way nested 
GAMMs. The book includes three chapters on the analysis of zero-inflated 
data.


Kind regards,

Alain Zuur

-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From bbolker at gmail.com  Wed Jul 16 14:31:26 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 16 Jul 2014 08:31:26 -0400
Subject: [R-sig-ME] Very important question regarding the error while
 using library(lme4)
In-Reply-To: <1405448107.13727.YahooMailNeo@web164501.mail.gq1.yahoo.com>
References: <6f06fbdfb50e494e9124ea4711573ae8@CO1PR01MB206.prod.exchangelabs.com>	<10409ed046874fb88bd0f59a75beb563@CO1PR01MB206.prod.exchangelabs.com>	<C066842E-4974-4370-8F6D-D794B95F40BB@gmail.com>	<CABghstTXT43rFNF9ptKibAOhArDaLSZ1hffWvypVXQk6B8v4kg@mail.gmail.com>	<CAE7K-2y6D=iq4bkVbKwFaed-ubgb3_+s7HZYH6npW7_aOk5PPg@mail.gmail.com>
	<CABghstTh+cvCx6v8W0uOM4sWTTNq=cj2PEB4vx7b21kv3zrhaw@mail.gmail.com>
	<1405448107.13727.YahooMailNeo@web164501.mail.gq1.yahoo.com>
Message-ID: <53C6709E.8070907@gmail.com>

On 14-07-15 02:15 PM, Steve Denham wrote:
> I use SAS a LOT, probably in a ratio of 100 to 1 over R, for mixed models.  
> 
> However, one thing I would never do is use the covtest option in PROC
> MIXED to see whether a variance component was "significant" or not.
>  There is a reason that Russ Wolfinger and the other developers pulled
> it out of the default output, and it is that a Wald test here is, well,
> the best I can come up with is "a very bad idea".  Estimation of the
> standard error of a variance component is difficult, and strongly
> sensitive to assumptions, as well as being non-linear and iterative, so
> that there is sensitive dependence on initial conditions (SDIC).  So the
> Hessian inverse may be chaotic.  Thus, any "p value" you get is
> certainly suspect.
> 
> Second, why in the world would you 'test' for significance of a variance
> component to begin with?  What end can be obtained from it?  Variance
> components arise out of design considerations, and I can't imagine a
> null hypothesis relevant in this case.  That may be the fault of my
> imagination, but isn't the whole point estimation and accommodation of
> identifiable sources of variation?
> 
> Pardon the soapbox...
>  
> Steve Denham
> Director, Biostatistics
> MPI Research, Inc.
> 

  Steve, thanks for speaking up.

* for what it's worth, it's fairly hard to get a Wald test out of lme4,
although if you wanted you could do it by inverting
model at optinfo$derivs$Hessian ...
* my personal feeling is that the estimate of the variance-covariance
matrix of the random effects is not "chaotic", but I agree that it could
be numerically unstable.
* I would say there _are_ times when one is interested in a standard
null-hypothesis test of whether the variation among units of the
grouping variable is distinguishable from the effect of noise elsewhere
in the model (e.g. evolutionary/population genetics questions), but I
agree that this null hypothesis is often tested needlessly/thoughtlessly ...

   As a SAS user I would be interested in your comments/opinions about
the pros and cons of PROC MIXED/GLIMMIX vs. lme4 -- *not* with the
intention of starting a flame war, but for the general hope of informing
myself (and others) about the strengths and weaknesses of different
systems, and of finding out how we can improve lme4 ...

  cheers
    Ben Bolker


-- 



>     ------------------------------------------------------------------------
>     *From:* Ben Bolker <bbolker at gmail.com>
>     *To:* Mao Huang <hannahmaohuang at gmail.com>
>     *Cc:* "r-sig-mixed-models at r-project.org"
>     <r-sig-mixed-models at r-project.org>
>     *Sent:* Tuesday, July 15, 2014 1:11 PM
>     *Subject:* Re: [R-sig-ME] Very important question regarding the
>     error while using library(lme4)
> 
>     [cc'ing to r-sig-mixed-models]
> 
>     Please ask these kinds of general question on
>     r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org> .  And see
>     http://glmm.wikidot.com/faq <http://glmm.wikidot.com/faq>,
>     ?pvalues in the package help, and the lmerTest package ...
> 
> 
>     On Tue, Jul 15, 2014 at 9:51 AM, Mao Huang <hannahmaohuang at gmail.com
>     <mailto:hannahmaohuang at gmail.com>> wrote:
> 
>     > Hi Ben,
>     >
>     > I got a new question for ya:
>     >
>     > lmer can provide the estimates of variance-covariance for the
>     variables
>     > that you put in the model.
>     > e.g. Y= X1 + X2
>     >
>     > But I want to test to see if the effects of X1 or X2  are
>     significant or
>     > not, which needs a test for these variables.
>     >
>     > In SAS proc mixed we could specify "covtest", which then provide the
>     > Z-test value and p-value for each of those variables (along with their
>     > estimated variances).
>     > So based on that, we could see if any of these factors are
>     significant or
>     > not.
>     > example output would be something like this, here X1 and X2 are not
>     > significant:
>     >
>     > Covariance Parameter Estimates
>     > Cov Parm Estimate Standard Error Z Value Pr > Z
>     > X1  222.19 182.50    1.22 0.1117
>     > X2  2.3316 1.8721    1.25 0.1065
>     > Residual 89.0390 2.8537 31.20 <.0001
>     >
>     >
>     >
>     > How do you do such similar tests  in lme4() ?
>     >
>     > Thanks.
>     >
>     >
>     >
>     >
>     >
>     > On Mon, Jul 14, 2014 at 11:08 PM, Ben Bolker <bbolker at gmail.com
>     <mailto:bbolker at gmail.com>> wrote:
>     >
>     >> glad it worked.
>     >>
>     >>
>     >> On Mon, Jul 14, 2014 at 11:01 PM, mao Huang
>     <hannahmaohuang at gmail.com <mailto:hannahmaohuang at gmail.com>>
>     >> wrote:
>     >>
>     >>> It worked. Thanks so much!
>     >>> I hope it was that obvious to me at the beginning too :(
>     >>>
>     >>> I thought it was the library path problem and so was keeping
>     checking on
>     >>> that....:(
>     >>>
>     >>>
>     >>>
>     >>> Sent from my iPhone
>     >>>
>     >>> On Jul 14, 2014, at 9:38 PM, Ben Bolker <bbolker at gmail.com
>     <mailto:bbolker at gmail.com>> wrote:
>     >>>
>     >>>  [cc'ing to r-sig-mixed-models]
>     >>>
>     >>>  The obvious question would be whether you have tried
>     >>>
>     >>> install.packages("minqa")
>     >>>
>     >>> ?
>     >>>
>     >>>  I would try that, then *re*-install lme4.
>     >>>
>     >>>  Otherwise: operating system, results of sessionInfo(), results of
>     >>>
>     >>> installed.packages()[c("lme4","minqa"),]
>     >>>
>     >>> ?
>     >>>
>     >>>
>     >>> On Mon, Jul 14, 2014 at 3:54 PM, Huang, Mao <
>     >>> huang.823 at buckeyemail.osu.edu
>     <mailto:huang.823 at buckeyemail.osu.edu>> wrote:
>     >>>
>     >>>>  Hi Ben,
>     >>>>
>     >>>> Thank you for your work in creating lme4()
>     >>>>
>     >>>>  I need to analyze my data very urgently using lmer in lme4
>     library.
>     >>>>
>     >>>>  I tried different ways to download the package, it can be
>     downloaded
>     >>>> and installed properly.
>     >>>> But once I call the library, it gives error and I can't use it:
>     >>>>
>     >>>>  utils:::menuInstallLocal()
>     >>>> package ?lme4? successfully unpacked and MD5 sums checked
>     >>>>
>     >>>>  > library(lme4)
>     >>>> Error in library.dynam(lib, package, package.lib) :
>     >>>>  DLL ?minqa? not found: maybe not installed for this architecture?
>     >>>> Error: package or namespace load failed for ?lme4?
>     >>>>
>     >>>>
>     >>>>  I tried to look for answers online but nothing useful found yet.
>     >>>>
>     >>>>  Do you have any idea what's going on there?
>     >>>>
>     >>>>  Please reply at your earliest convenience.
>     >>>>
>     >>>>  Thanks so much!
>     >>>>
>     >>>>  Mao
>     >>>>
>     >>>> ?
>     >>>>
>     >>>>
>     >>>>
>     >>>
>     >>
>     >
> 
>         [[alternative HTML version deleted]]
> 
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
>


From ingaschwabe at gmail.com  Wed Jul 16 14:37:25 2014
From: ingaschwabe at gmail.com (Inga Schwabe)
Date: Wed, 16 Jul 2014 14:37:25 +0200
Subject: [R-sig-ME] Question regarding the estimation of the correlation
 between random intercepts and random slopes in the lme4 package
Message-ID: <CAFgqi95QbfUes1pH1UFSFjs6h3m7JamBHioE3N2-cXVZfXOyDg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140716/7532db3c/attachment.pl>

From bbolker at gmail.com  Wed Jul 16 15:57:08 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 16 Jul 2014 09:57:08 -0400
Subject: [R-sig-ME] Question regarding the estimation of the correlation
 between random intercepts and random slopes in the lme4 package
In-Reply-To: <CAFgqi95QbfUes1pH1UFSFjs6h3m7JamBHioE3N2-cXVZfXOyDg@mail.gmail.com>
References: <CAFgqi95QbfUes1pH1UFSFjs6h3m7JamBHioE3N2-cXVZfXOyDg@mail.gmail.com>
Message-ID: <53C684B4.5030209@gmail.com>

On 14-07-16 08:37 AM, Inga Schwabe wrote:
> Dear list members,
> 
> I posted a question regarding the lme4 package in R on stackoverflow.com
> (see
> http://stackoverflow.com/questions/24778642/estimating-correlation-between-random-slopes-and-random-intercepts-using-the-lme)
> and a stackoverflow-user kindly  referred me to this mailing list. I hope
> that my question is appropriate for this mailing list. If it is not, please
> let me know!
> 
> This is my question:
> 
> For answering my research question I am interested in the correlation
> between the random slopes and random intercepts in a multilevel model,
> estimated using the R library lme4.
> 
> The data I have is: Y (test-scores from students), SES (socio-economic
> status for each student) and schoolid (ID for each school).
> 
> I am using the following syntax to estimate random intercepts and slopes
> for the schools:
> 
> library(lme4)
> model3 <- lmer(Y ~ SES + (1 + SES | schoolid))
> 
>  The reference I used for this syntax is this pdf:
> 
> http://www.bristol.ac.uk/cmm/learning/module-samples/5-concepts-sample.pdf
> 
> On page 19, a similar analysis is described. It is said that by defining
> the random intercepts and slopes toghether, it is indirectly specified that
> we want the random intercepts and slopes to covary. Therefore, also the
> correlation between random slopes and random intercepts is estimated.
> Basically, exactly what I need for answering my research hyptohesis.
> 
> However, when I look at the results:
> 
>  summary(model3)
> 
>  I am getting the following output:
> 
> Linear mixed model fit by REML ['lmerMod']
> Formula: Y ~ SES + (1 + SES | schoolid)
> 
> REML criterion at convergence: 8256.4
> 
> Scaled residuals:
>     Min      1Q  Median      3Q     Max -3.1054 -0.6633 -0.0028  0.6810  3.5606
> 
> Random effects:
>  Groups   Name        Variance  Std.Dev. Corr
>  schoolid (Intercept) 0.6427924 0.80174
>       SES             0.0009143 0.03024  1.00
>  Residual             0.3290902 0.57366
> Number of obs: 4376, groups: schoolid, 179
> 
> Fixed effects:
>              Estimate Std. Error t value(Intercept) -0.036532   0.060582  -0.603
> SES          0.062491   0.009984   6.259
> 
> Correlation of Fixed Effects:
>     (Intr)
> SES 0.226
> 
>  As stated in the output, the correlation between the random slopes and
> random intercepts equals 1.00. I find this hard to believe. When I call in
> R:
> 
> VarCorr(model3)$schoolid
> 
>  I am getting the following output which gives the correlations and
> covariance matrix:
> 
>                 (Intercept)          SES(Intercept)  0.64279243 0.0242429680
> SES          0.02424297 0.0009143255
> 
> attr(,"stddev")(Intercept)         SES
>  0.80174337  0.03023782
> 
> attr(,"correlation")
>         (Intercept) SES(Intercept)           1   1
> SES                   1   1
> 
>  It seems as if the correlation between the slopes and intercepts was set
> to 1.00 by R. I did not see this in the output of anyone else when I was
> searching the internet on references on multilevel modelling.
> 
> Does anybody know what can be the cause of this correlation? Can it be that
> the correlation is set to 1.00 because otherwise the model would not be
> identified? Or is it because the variance of the random slopes is so small
> (0.0009) that the correlation can not be estimated?
> 
> I have tried to simulate data in order provide the code for a small
> reproducible dataset. I was however not yet able to reproduce this output
> by means of simulated data. As far as I have the code I will eidt my post
> and add the code.
> 
> 
> Many thanks for you time and effort,
> Kind regards,
> 
> Inga
> 

  I was thinking about answering on StackOverflow, but since you've
asked here: yes, your second-to-last paragraph is exactly correct.  You
don't have enough information (or equivalently there is too much noise)
in your data to uniquely identify the full variance-covariance matrix,
so the results are 'singular'; that is, one of the underlying components
is identified as zero.  Common symptoms of this situation include either
variances equal to zero (or nearly equal, although I see in your case
that the variances while small are *not* exactly zero) or correlations
equal to +/- 1.

http://rpubs.com/bbolker/4187 shows some simulated examples where the
estimated variance collapses to zero (despite the true, simulated model
having a non-zero among-group variance).  Presumably one could make up
similar examples (with randomized-block designs/random-slope models)
that would show analogous situations of correlations collapsing to +/- 1.

 It's a little bit surprising that you have encountered this problem
since it is most commonly a problem with small numbers of levels in the
grouping variables, which doesn't appear to be the case here.

  See http://glmm.wikidot.com/faq#singular_fits for more information ...

  Ben Bolker


From bbolker at gmail.com  Wed Jul 16 19:59:12 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 16 Jul 2014 13:59:12 -0400
Subject: [R-sig-ME] Significance of Repeatablity Estimates
In-Reply-To: <CAHe08Shw4cetN-D0vHw997Lek3KrE4uHDnUHdfCs1UnRnzq+AA@mail.gmail.com>
References: <CAHe08Shw4cetN-D0vHw997Lek3KrE4uHDnUHdfCs1UnRnzq+AA@mail.gmail.com>
Message-ID: <53C6BD70.1090309@gmail.com>


[cc'd to r-sig-mixed-models]

On 14-07-16 08:24 AM, AvianResearchDivision wrote:
> Hi Ben,
> 
> I was reading through Nakagawa and Schielzeth (2010) about how to
> calculate the significance of repeatability estimates and they mention
> your 2009 paper.  I can't seem to find this paper and was wondering if
> you could clear up the procedure for me.  They state that you compare
> models with and without a random intercept parameter, which would mean
> comparing a linear model with a linear mixed-effect model, which can't
> be done in R and returns 'Error: $ operator not defined for this S4
> class'.  I also thought this wasn't a good idea to do in general.  Can
> you briefly describe how this can be done in R?  Thank you for the help.
> 
> Jacob

The 2009 paper is available from
http://ms.mcmaster.ca/~bolker/bb-pubs.html (username: bbpapers,
password: research).

There are a variety ways of doing this:

library(lme4)

fm1 <- lmer(Reaction ~ Days + (Days | Subject), sleepstudy, REML=FALSE)
fm0 <- lm(Reaction ~ Days, sleepstudy)

## likelihood ratio test -- subject to the various caveats listed
##  at http://glmm.wikidot.com/faq#random-sig
## The log-likelihoods reported by lm() and lmer()
##  *are* commensurate; see test below ...

ddiff <- -2*(logLik(fm0)-logLik(fm1))
pchisq(ddiff,3,lower.tail=FALSE)

## use RLRsim (redo model with only a single random effect -- RLRsim
##  is limited in this way
fm2 <- lmer(Reaction ~ Days + (1 | Subject), sleepstudy, REML=FALSE)
library(RLRsim)
exactLRT(fm2,fm0)

## check commensurateness
dd <- update(fm2,devFunOnly=TRUE)
all.equal(dd(0),c(-2*logLik(fm0)))  ## TRUE

## parametric bootstrapping
bootSim <- function() {
   s <- simulate(fm0)[[1]]
   fm1B <- refit(fm1,s)
   fm0B <- update(fm0,data=transform(sleepstudy,Reaction=s))
   -2*(logLik(fm0B)-logLik(fm1B))
}
set.seed(101)
rr <- replicate(500,bootSim())
hist(rr,breaks=50,col="gray")
mean(ddiff<=c(rr,ddiff))
##  =1/501; essentially limited by size of bootstrap set


From bbolker at gmail.com  Wed Jul 16 20:11:56 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 16 Jul 2014 18:11:56 +0000 (UTC)
Subject: [R-sig-ME] How to deal with Hessian error if the model only
	contains binomial (0, 1) fixed factors?
References: <CAOCHjhQyOapdFxi-B7L-wEQtybOG+Y-tPkjY0dg6=Ma0K5XAPQ@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA7427F3AC0F2F@inbomail.inbo.be>
	<CAOCHjhRXrwaNLrzO994DBSa=NM4xzoTRdg1JEJB4auNECS3V1w@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA7427F3AC0F9D@inbomail.inbo.be>
	<CAOCHjhRs23kg=QRe==Ta23cRjswV-Pi-Yax0K2WPz2ZW3mkKTA@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA7427F3AC12C6@inbomail.inbo.be>
Message-ID: <loom.20140716T200825-984@post.gmane.org>

ONKELINX, Thierry <Thierry.ONKELINX at ...> writes:

> 
> Dear Julia,
 
> Note that the smallest category of the response (samemate == 0) has
> 12 observations. According to a rule of thumb, you need 10
> observations in each response category per parameter in the
> model. Hence a model with one (if you're lucky two) parameters is
> doable.
 
> Complete separation appears when for a combination of covariates all
> responses are 0 or 1. Adding complexity to the model, increases the
> probability of complete separation because you have more possible
> combination and a lower number of observations per
> combination. Adding a random effect with 59 levels to a dataset of
> 66 observations guarantees complete separation...
 
> The separation of the simple glm(samemate ~ success) is not that
> bad. But glm(samemate ~ success + type) will give (quasi-)complete
> separation. The glm model gives implicit warnings (see the last
> model in your first email): type has a very large effect size and a
> huge standard error.

There is a short example of how to deal with complete separation
by setting weakly informative priors at http://rpubs.com/bbolker/glmmchapter
(search for "complete separation"), via the blme or MCMCglmm packages,
but I would second Thierry's opinion that you may be overcomplicating
things.

  Ben Bolker


From stevedrd at yahoo.com  Wed Jul 16 21:01:05 2014
From: stevedrd at yahoo.com (Steve Denham)
Date: Wed, 16 Jul 2014 12:01:05 -0700
Subject: [R-sig-ME] Very important question regarding the error while
	using library(lme4)
In-Reply-To: <53C6709E.8070907@gmail.com>
References: <6f06fbdfb50e494e9124ea4711573ae8@CO1PR01MB206.prod.exchangelabs.com>	<10409ed046874fb88bd0f59a75beb563@CO1PR01MB206.prod.exchangelabs.com>	<C066842E-4974-4370-8F6D-D794B95F40BB@gmail.com>	<CABghstTXT43rFNF9ptKibAOhArDaLSZ1hffWvypVXQk6B8v4kg@mail.gmail.com>	<CAE7K-2y6D=iq4bkVbKwFaed-ubgb3_+s7HZYH6npW7_aOk5PPg@mail.gmail.com>
	<CABghstTh+cvCx6v8W0uOM4sWTTNq=cj2PEB4vx7b21kv3zrhaw@mail.gmail.com>
	<1405448107.13727.YahooMailNeo@web164501.mail.gq1.yahoo.com>
	<53C6709E.8070907@gmail.com>
Message-ID: <1405537265.65471.YahooMailNeo@web164505.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140716/b6108641/attachment.pl>

From jake987722 at hotmail.com  Thu Jul 17 00:27:35 2014
From: jake987722 at hotmail.com (Jake Westfall)
Date: Wed, 16 Jul 2014 16:27:35 -0600
Subject: [R-sig-ME] Very important question regarding the error while
 using library(lme4)
In-Reply-To: <53C6709E.8070907@gmail.com>
References: <6f06fbdfb50e494e9124ea4711573ae8@CO1PR01MB206.prod.exchangelabs.com>
	<10409ed046874fb88bd0f59a75beb563@CO1PR01MB206.prod.exchangelabs.com>
	<C066842E-4974-4370-8F6D-D794B95F40BB@gmail.com>
	<CABghstTXT43rFNF9ptKibAOhArDaLSZ1hffWvypVXQk6B8v4kg@mail.gmail.com>
	<CAE7K-2y6D=iq4bkVbKwFaed-ubgb3_+s7HZYH6npW7_aOk5PPg@mail.gmail.com>,
	<CABghstTh+cvCx6v8W0uOM4sWTTNq=cj2PEB4vx7b21kv3zrhaw@mail.gmail.com>,
	<1405448107.13727.YahooMailNeo@web164501.mail.gq1.yahoo.com>,
	<53C6709E.8070907@gmail.com>
Message-ID: <BAY172-W6BED4F2973D239B444D93CBF70@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140716/ea8beb95/attachment.pl>

From jake987722 at hotmail.com  Thu Jul 17 00:39:14 2014
From: jake987722 at hotmail.com (Jake Westfall)
Date: Wed, 16 Jul 2014 16:39:14 -0600
Subject: [R-sig-ME] Question regarding the estimation of the correlation
 between random intercepts and random slopes in the lme4 package
In-Reply-To: <53C684B4.5030209@gmail.com>
References: <CAFgqi95QbfUes1pH1UFSFjs6h3m7JamBHioE3N2-cXVZfXOyDg@mail.gmail.com>,
	<53C684B4.5030209@gmail.com>
Message-ID: <BAY172-W34A2ECDBF7A3806CD97A10CBF70@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140716/335831b2/attachment.pl>

From Julia.Sommerfeld at utas.edu.au  Thu Jul 17 09:26:25 2014
From: Julia.Sommerfeld at utas.edu.au (Julia Sommerfeld)
Date: Thu, 17 Jul 2014 09:26:25 +0200
Subject: [R-sig-ME] How to deal with Hessian error if the model only
 contains binomial (0, 1) fixed factors?
In-Reply-To: <loom.20140716T200825-984@post.gmane.org>
References: <CAOCHjhQyOapdFxi-B7L-wEQtybOG+Y-tPkjY0dg6=Ma0K5XAPQ@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA7427F3AC0F2F@inbomail.inbo.be>
	<CAOCHjhRXrwaNLrzO994DBSa=NM4xzoTRdg1JEJB4auNECS3V1w@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA7427F3AC0F9D@inbomail.inbo.be>
	<CAOCHjhRs23kg=QRe==Ta23cRjswV-Pi-Yax0K2WPz2ZW3mkKTA@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA7427F3AC12C6@inbomail.inbo.be>
	<loom.20140716T200825-984@post.gmane.org>
Message-ID: <CAOCHjhSxjROH_sHrL2MYvuqkMYT+44ORJAP=0HcuXWsbxYC9VA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140717/71de8bce/attachment.pl>

From rajibulmian at gmail.com  Tue Jul 15 18:40:34 2014
From: rajibulmian at gmail.com (Rajibul Mian)
Date: Tue, 15 Jul 2014 12:40:34 -0400
Subject: [R-sig-ME] glmmADMB package
Message-ID: <CAGAKjUM82pOBQ_8ZFgb9CP=7nF2uHeqrM_hWjRWX7u0tSASMQA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140715/d2acbff2/attachment.pl>

From smayor at neoninc.org  Tue Jul 15 18:47:29 2014
From: smayor at neoninc.org (Stephen Mayor)
Date: Tue, 15 Jul 2014 16:47:29 +0000
Subject: [R-sig-ME] Same variable as both fixed and random
Message-ID: <1d9db02e7db440829041408fc54618db@SN2PR0701MB798.namprd07.prod.outlook.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140715/20c6c34a/attachment.pl>

From ravi.varadhan at jhu.edu  Mon Jul 14 16:19:37 2014
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Mon, 14 Jul 2014 14:19:37 +0000
Subject: [R-sig-ME] Checking modeling assumptions in a binomial GLMM
Message-ID: <2F9EA67EF9AE1C48A147CB41BE2E15C3124323CA@DOM-MTW-MAIL2.win.ad.jhu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140714/5ac8c1b4/attachment.pl>

From ingaschwabe at gmail.com  Thu Jul 17 10:43:22 2014
From: ingaschwabe at gmail.com (Inga Schwabe)
Date: Thu, 17 Jul 2014 10:43:22 +0200
Subject: [R-sig-ME] Question regarding the estimation of the correlation
 between random intercepts and random slopes in the lme4 package
In-Reply-To: <BAY172-W34A2ECDBF7A3806CD97A10CBF70@phx.gbl>
References: <CAFgqi95QbfUes1pH1UFSFjs6h3m7JamBHioE3N2-cXVZfXOyDg@mail.gmail.com>
	<53C684B4.5030209@gmail.com>
	<BAY172-W34A2ECDBF7A3806CD97A10CBF70@phx.gbl>
Message-ID: <CAFgqi96ccAAzGYKHDuDFjq_SPcwK7Zf5_A-8==5M=k-sCKvEgA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140717/827cad76/attachment.pl>

From jwiley.psych at gmail.com  Thu Jul 17 11:24:28 2014
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Thu, 17 Jul 2014 19:24:28 +1000
Subject: [R-sig-ME] Same variable as both fixed and random
In-Reply-To: <1d9db02e7db440829041408fc54618db@SN2PR0701MB798.namprd07.prod.outlook.com>
References: <1d9db02e7db440829041408fc54618db@SN2PR0701MB798.namprd07.prod.outlook.com>
Message-ID: <CANz9Z_J4t4PmZrNi70n13SOXF08Shgb1r+ZNRcY6y555WLfNXg@mail.gmail.com>

Hi Stephen,

In your example, I would recommend not including year as both a fixed
and random effect (note that Arrival ~DegreeDays + Year + (1 + Year |
State) --- i.e., allowing the effects of year to differ by state or
some such, would be a different scenario).

You will partial the most variability out of the estimates by
specifying Year as a fixed effect, however, if it is being treated
categorically, this will result in quite a few extra parameters, and
you will also not get an estimate of the overall variability in
intercept by year.  If those specific ten years are not of interest,
and you are controlling for the "key" feature that you expect to
change, namely, DegreeDays, then I would suggest:

lmer(Arrival ~ DegreeDays + Longitude + Latitude + (1 | State) + (1 | Year))

A separate issue is how longitude and latitude are included (e.g.,
depending on the precision of your data, it may be helpful to allow a
stronger similarity between nearby locations, although it may not
matter much if you only have data at the level of State).

Cheers,

Josh


On Wed, Jul 16, 2014 at 2:47 AM, Stephen Mayor <smayor at neoninc.org> wrote:
> Hello,
> When should a variable be specified as both a fixed effect AND as a random effect?  If a single variable is defined as both fixed and random, how does one interpret the coefficients?  Is it 'sloppy' practice to include it as both?  Should one be cautious specifying a variable twice, or is it actually more conservative to do so?
>
> I am interested in your thoughts in general, but here is a simplified example if helpful:
> I am interested in the date of arrival of house wren, a migratory bird, to each state in the US as a response to year, degree days (climate), latitude, longitude, state.  I primarily want to test if there is a temporal trend in earlier arrival in more recent years, as a result of recent climatic warming.
>
> I specified the model as follows, treating state as a random group.  Because I am interested in testing a linear trend across years, I specified Year as a fixed (and continuous) effect.  But I am unsure as to whether I should ALSO specify it as a random factor, because I am interested in making inferences beyond the 10 years of data that I have and I don't have any specific interest in these 10 years over any other period.
>
> lmer(Arrival ~ DegreeDays + Year + Longitude + Latitude + (1|State) )
> OR
> lmer(Arrival ~ DegreeDays + Year + Longitude + Latitude + (1|State) + (1|Year))
>
> Thanks in advance for any help or suggestions,
> Stephen.
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Joshua F. Wiley
Ph.D. Student, UCLA Department of Psychology
http://joshuawiley.com/
Senior Analyst, Elkhart Group Ltd.
http://elkhartgroup.com
Office: 260.673.5518


From f.rodriguez.sanc at gmail.com  Thu Jul 17 11:53:50 2014
From: f.rodriguez.sanc at gmail.com (Francisco Rodriguez Sanchez)
Date: Thu, 17 Jul 2014 11:53:50 +0200
Subject: [R-sig-ME] Checking modeling assumptions in a binomial GLMM
In-Reply-To: <2F9EA67EF9AE1C48A147CB41BE2E15C3124323CA@DOM-MTW-MAIL2.win.ad.jhu.edu>
References: <2F9EA67EF9AE1C48A147CB41BE2E15C3124323CA@DOM-MTW-MAIL2.win.ad.jhu.edu>
Message-ID: <53C79D2E.6070209@gmail.com>

Dear Ravi,

I wonder if you received some answer off-list. There are some functions 
for simple logistic regression that I think can be applied to binomial 
GLMMs as well, such as binnedplot in arm package 
(http://www.rdocumentation.org/packages/arm/functions/binnedplot) to 
check residuals, or plotCalibration in PredictABEL 
(http://www.rdocumentation.org/packages/PredictABEL/functions/plotCalibration) 
to check goodness of fit.

I tried to put together these tests in a single function some time ago, 
check here: 
https://github.com/Pakillo/pacotools/blob/master/R/checkLogReg.R.

Hope this helps,

Paco


El 14/07/2014 16:19, Ravi Varadhan escribi?:
> Dear All,
>
> I am fitting a model for a binary response variable measured repeatedly at multiple visits.  I am fitting the binomial GLMM using the glmer() function in lme4 package.  How can I evaluate the model assumptions (e.g., residual diagnostics, covariate form, adequacy of random effects distribution) for a binomial GLMM?  Could you please give me some suggestions on how to do this?  Are there any pedagogical examples or data sets where these issues have been demonstrated for binomial GLMMs?
>
> I appreciate your help very much.
>
> Thank you,
> Ravi
>
>
> Ravi Varadhan, Ph.D. (Environmental Eng.), Ph.D. (Biostatistics)
> Associate Professor,
> Division of Geriatric Medicine & Gerontology
> School of Medicine,
> Johns Hopkins University
> Ph: 410-502-2619
> Email: ravi.varadhan at jhu.edu<mailto:ravi.varadhan at jhu.edu>
> http://www.jhsph.edu/research/centers-and-institutes/johns-hopkins-center-on-aging-and-health/people/Faculty_personal_Pages/Varadhan.html
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Dr Francisco Rodriguez-Sanchez
Integrative Ecology Group
Estacion Biologica de Do?ana - CSIC
Avda. Americo Vespucio s/n
41092 Sevilla (Spain)
http://sites.google.com/site/rodriguezsanchezf


From Thierry.ONKELINX at inbo.be  Thu Jul 17 12:39:35 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 17 Jul 2014 10:39:35 +0000
Subject: [R-sig-ME] Same variable as both fixed and random
In-Reply-To: <CANz9Z_J4t4PmZrNi70n13SOXF08Shgb1r+ZNRcY6y555WLfNXg@mail.gmail.com>
References: <1d9db02e7db440829041408fc54618db@SN2PR0701MB798.namprd07.prod.outlook.com>
	<CANz9Z_J4t4PmZrNi70n13SOXF08Shgb1r+ZNRcY6y555WLfNXg@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3AC1774@inbomail.inbo.be>

Dear Joshua,

I agree when the variable is a factor, because then the model with both fixed and random effect becomes unidentifiable. But I disagree when the variable is used as a continuous variable in the fixed effects and makes sense as a factor as well. In that case (provided the variable has enough levels) it makes sense to add the variable as a continuous fixed effect and a random intercept. I'm made a toy example below. The first model has a linear trend along year with additional year-to-year variation. The second one assumes a quadratic effect that is modeled as a linear effect. In the third case the fixed effect uses a quadratic model. The random effects of the first two models capture the discrepancy between the model and the true trend. The random effects in the third model have zero variance because they are not relevant.

Best regards,

Thierry

library(lme4)
library(ggplot2)
set.seed(123546)
n.year <- 10
n.replicate <- 10
intercept <- 1
trend <- 2
quadratic <- -0.5
sd.noise <- 1
sd.year <- 2
test <- expand.grid(year = seq_len(n.year), replicate = seq_len(n.replicate))

test$y.true <- intercept + trend * test$year + rnorm(n.year, sd = sd.year)
test$y <- test$y.true + rnorm(nrow(test), sd = sd.noise)

model <- lmer(y ~ year + (1|year), data = test)
test$fit <- fitted(model)
test$global <- predict(model, re.form = ~0)
ggplot(test, aes(x = year, y = y.true)) + geom_line() + geom_point(aes(y = y)) + geom_line(aes(y = fit), colour = "red") + geom_line(aes(y = global), colour = "blue") + geom_abline(intercept = intercept, slope = trend, colour = "magenta")
plot(ranef(model)$year[, 1])

test$y.true <- intercept + trend * test$year + quadratic * test$year ^ 2
test$y <- test$y.true + rnorm(nrow(test), sd = sd.noise)
model <- lmer(y ~ year + (1|year), data = test)
test$fit <- fitted(model)
test$global <- predict(model, re.form = ~0)
ggplot(test, aes(x = year, y = y.true)) + geom_line() + geom_point(aes(y = y)) + geom_line(aes(y = fit), colour = "red") + geom_line(aes(y = global), colour = "blue") + stat_function(fun = function(x){intercept + trend * x + quadratic * x ^ 2}, colour = "magenta", geom = "line")

plot(ranef(model)$year[, 1])

model <- lmer(y ~ poly(year, 2) + (1|year), data = test)
test$fit <- fitted(model)
test$global <- predict(model, re.form = ~0)
ggplot(test, aes(x = year, y = y.true)) + geom_line() + geom_point(aes(y = y)) + geom_line(aes(y = fit), colour = "red") + geom_line(aes(y = global), colour = "blue") + stat_function(fun = function(x){intercept + trend * x + quadratic * x ^ 2}, colour = "magenta", geom = "line")
plot(ranef(model)$year[, 1])


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Joshua Wiley
Verzonden: donderdag 17 juli 2014 11:24
Aan: Stephen Mayor
CC: r-sig-mixed-models at r-project.org
Onderwerp: Re: [R-sig-ME] Same variable as both fixed and random

Hi Stephen,

In your example, I would recommend not including year as both a fixed and random effect (note that Arrival ~DegreeDays + Year + (1 + Year |
State) --- i.e., allowing the effects of year to differ by state or some such, would be a different scenario).

You will partial the most variability out of the estimates by specifying Year as a fixed effect, however, if it is being treated categorically, this will result in quite a few extra parameters, and you will also not get an estimate of the overall variability in intercept by year.  If those specific ten years are not of interest, and you are controlling for the "key" feature that you expect to change, namely, DegreeDays, then I would suggest:

lmer(Arrival ~ DegreeDays + Longitude + Latitude + (1 | State) + (1 | Year))

A separate issue is how longitude and latitude are included (e.g., depending on the precision of your data, it may be helpful to allow a stronger similarity between nearby locations, although it may not matter much if you only have data at the level of State).

Cheers,

Josh


On Wed, Jul 16, 2014 at 2:47 AM, Stephen Mayor <smayor at neoninc.org> wrote:
> Hello,
> When should a variable be specified as both a fixed effect AND as a random effect?  If a single variable is defined as both fixed and random, how does one interpret the coefficients?  Is it 'sloppy' practice to include it as both?  Should one be cautious specifying a variable twice, or is it actually more conservative to do so?
>
> I am interested in your thoughts in general, but here is a simplified example if helpful:
> I am interested in the date of arrival of house wren, a migratory bird, to each state in the US as a response to year, degree days (climate), latitude, longitude, state.  I primarily want to test if there is a temporal trend in earlier arrival in more recent years, as a result of recent climatic warming.
>
> I specified the model as follows, treating state as a random group.  Because I am interested in testing a linear trend across years, I specified Year as a fixed (and continuous) effect.  But I am unsure as to whether I should ALSO specify it as a random factor, because I am interested in making inferences beyond the 10 years of data that I have and I don't have any specific interest in these 10 years over any other period.
>
> lmer(Arrival ~ DegreeDays + Year + Longitude + Latitude + (1|State) )
> OR lmer(Arrival ~ DegreeDays + Year + Longitude + Latitude + (1|State)
> + (1|Year))
>
> Thanks in advance for any help or suggestions, Stephen.
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



--
Joshua F. Wiley
Ph.D. Student, UCLA Department of Psychology
http://joshuawiley.com/
Senior Analyst, Elkhart Group Ltd.
http://elkhartgroup.com
Office: 260.673.5518

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From jwiley.psych at gmail.com  Thu Jul 17 13:42:33 2014
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Thu, 17 Jul 2014 21:42:33 +1000
Subject: [R-sig-ME] Same variable as both fixed and random
In-Reply-To: <AA818EAD2576BC488B4F623941DA7427F3AC1774@inbomail.inbo.be>
References: <1d9db02e7db440829041408fc54618db@SN2PR0701MB798.namprd07.prod.outlook.com>
	<CANz9Z_J4t4PmZrNi70n13SOXF08Shgb1r+ZNRcY6y555WLfNXg@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA7427F3AC1774@inbomail.inbo.be>
Message-ID: <CANz9Z_LkdMFxUeGxJ_3+yssox_JmMH5id9cgbt4OmVhoW66f=g@mail.gmail.com>

Dear Thierry,

I completely agree with you.  There is a distinction between treating
year continuously and as a factor.

That is why I made the point about DegreeDays.  If DegreeDays were not
in the model, one might hypothesize that year would pick up some time
trends in climate change, but if climate change is itself directly
measured and in the model, than it would seem year is some general
proxy for any other effects that vary across years, and in that sense,
I do not know that imposing a linear relationship is sensible, leaving
the choice of treating it as a factor or as a random effect.

Thanks for the examples, they are an excellent way to show the point.

Sincerely,

Josh





On Thu, Jul 17, 2014 at 8:39 PM, ONKELINX, Thierry
<Thierry.ONKELINX at inbo.be> wrote:
> Dear Joshua,
>
> I agree when the variable is a factor, because then the model with both fixed and random effect becomes unidentifiable. But I disagree when the variable is used as a continuous variable in the fixed effects and makes sense as a factor as well. In that case (provided the variable has enough levels) it makes sense to add the variable as a continuous fixed effect and a random intercept. I'm made a toy example below. The first model has a linear trend along year with additional year-to-year variation. The second one assumes a quadratic effect that is modeled as a linear effect. In the third case the fixed effect uses a quadratic model. The random effects of the first two models capture the discrepancy between the model and the true trend. The random effects in the third model have zero variance because they are not relevant.
>
> Best regards,
>
> Thierry
>
> library(lme4)
> library(ggplot2)
> set.seed(123546)
> n.year <- 10
> n.replicate <- 10
> intercept <- 1
> trend <- 2
> quadratic <- -0.5
> sd.noise <- 1
> sd.year <- 2
> test <- expand.grid(year = seq_len(n.year), replicate = seq_len(n.replicate))
>
> test$y.true <- intercept + trend * test$year + rnorm(n.year, sd = sd.year)
> test$y <- test$y.true + rnorm(nrow(test), sd = sd.noise)
>
> model <- lmer(y ~ year + (1|year), data = test)
> test$fit <- fitted(model)
> test$global <- predict(model, re.form = ~0)
> ggplot(test, aes(x = year, y = y.true)) + geom_line() + geom_point(aes(y = y)) + geom_line(aes(y = fit), colour = "red") + geom_line(aes(y = global), colour = "blue") + geom_abline(intercept = intercept, slope = trend, colour = "magenta")
> plot(ranef(model)$year[, 1])
>
> test$y.true <- intercept + trend * test$year + quadratic * test$year ^ 2
> test$y <- test$y.true + rnorm(nrow(test), sd = sd.noise)
> model <- lmer(y ~ year + (1|year), data = test)
> test$fit <- fitted(model)
> test$global <- predict(model, re.form = ~0)
> ggplot(test, aes(x = year, y = y.true)) + geom_line() + geom_point(aes(y = y)) + geom_line(aes(y = fit), colour = "red") + geom_line(aes(y = global), colour = "blue") + stat_function(fun = function(x){intercept + trend * x + quadratic * x ^ 2}, colour = "magenta", geom = "line")
>
> plot(ranef(model)$year[, 1])
>
> model <- lmer(y ~ poly(year, 2) + (1|year), data = test)
> test$fit <- fitted(model)
> test$global <- predict(model, re.form = ~0)
> ggplot(test, aes(x = year, y = y.true)) + geom_line() + geom_point(aes(y = y)) + geom_line(aes(y = fit), colour = "red") + geom_line(aes(y = global), colour = "blue") + stat_function(fun = function(x){intercept + trend * x + quadratic * x ^ 2}, colour = "magenta", geom = "line")
> plot(ranef(model)$year[, 1])
>
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> + 32 2 525 02 51
> + 32 54 43 61 85
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Joshua Wiley
> Verzonden: donderdag 17 juli 2014 11:24
> Aan: Stephen Mayor
> CC: r-sig-mixed-models at r-project.org
> Onderwerp: Re: [R-sig-ME] Same variable as both fixed and random
>
> Hi Stephen,
>
> In your example, I would recommend not including year as both a fixed and random effect (note that Arrival ~DegreeDays + Year + (1 + Year |
> State) --- i.e., allowing the effects of year to differ by state or some such, would be a different scenario).
>
> You will partial the most variability out of the estimates by specifying Year as a fixed effect, however, if it is being treated categorically, this will result in quite a few extra parameters, and you will also not get an estimate of the overall variability in intercept by year.  If those specific ten years are not of interest, and you are controlling for the "key" feature that you expect to change, namely, DegreeDays, then I would suggest:
>
> lmer(Arrival ~ DegreeDays + Longitude + Latitude + (1 | State) + (1 | Year))
>
> A separate issue is how longitude and latitude are included (e.g., depending on the precision of your data, it may be helpful to allow a stronger similarity between nearby locations, although it may not matter much if you only have data at the level of State).
>
> Cheers,
>
> Josh
>
>
> On Wed, Jul 16, 2014 at 2:47 AM, Stephen Mayor <smayor at neoninc.org> wrote:
>> Hello,
>> When should a variable be specified as both a fixed effect AND as a random effect?  If a single variable is defined as both fixed and random, how does one interpret the coefficients?  Is it 'sloppy' practice to include it as both?  Should one be cautious specifying a variable twice, or is it actually more conservative to do so?
>>
>> I am interested in your thoughts in general, but here is a simplified example if helpful:
>> I am interested in the date of arrival of house wren, a migratory bird, to each state in the US as a response to year, degree days (climate), latitude, longitude, state.  I primarily want to test if there is a temporal trend in earlier arrival in more recent years, as a result of recent climatic warming.
>>
>> I specified the model as follows, treating state as a random group.  Because I am interested in testing a linear trend across years, I specified Year as a fixed (and continuous) effect.  But I am unsure as to whether I should ALSO specify it as a random factor, because I am interested in making inferences beyond the 10 years of data that I have and I don't have any specific interest in these 10 years over any other period.
>>
>> lmer(Arrival ~ DegreeDays + Year + Longitude + Latitude + (1|State) )
>> OR lmer(Arrival ~ DegreeDays + Year + Longitude + Latitude + (1|State)
>> + (1|Year))
>>
>> Thanks in advance for any help or suggestions, Stephen.
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
> --
> Joshua F. Wiley
> Ph.D. Student, UCLA Department of Psychology
> http://joshuawiley.com/
> Senior Analyst, Elkhart Group Ltd.
> http://elkhartgroup.com
> Office: 260.673.5518
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> * * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
> Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
> The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.



-- 
Joshua F. Wiley
Ph.D. Student, UCLA Department of Psychology
http://joshuawiley.com/
Senior Analyst, Elkhart Group Ltd.
http://elkhartgroup.com
Office: 260.673.5518


From chantepie at mnhn.fr  Thu Jul 17 14:03:50 2014
From: chantepie at mnhn.fr (chantepie at mnhn.fr)
Date: Thu, 17 Jul 2014 14:03:50 +0200
Subject: [R-sig-ME] Accuracy of Va estimates using univariate versus
 multivariate animal model
Message-ID: <20140717140350.683056t8lzyo5f3a@dsiwebmail.mnhn.fr>

Dear all,

I have a question concerning the interpretation of Va estimate using  
univariate versus the bivariate animal models.

Indeed, I am interested to understand the age-related variation of the  
additive genetic variance. For this, I made an analysis with different  
age classes using univariate models for each age class. I also tried  
to run a multivariate model with my different age classes (9 in  
total). Nevertheless, even if the multivariate model can be written  
and runs, the time needed to reach its converenge is greater than 1  
year.

I'd like to know if it is better to estimate the Va of an age-class  
with a multivariate animal model than with a univariate one and why?

My view of the problem :

I understand that with univariate models the ages classes are  
considered as separate traits while in fact, the age classes are not  
independent because the same individuals are found in different ages  
classes. However, I do not really see the problem that univariate  
model can generate on the estimates of Va and therefore in the  
interpretation of results (as suggest a reviewer).

When I realized bivariate models between two ages-classes where there  
is a lot of information in each of the age-classes , the variance of  
traits remains the same compared with univariate models. However, when  
one of the age classes has less information (basically with the old  
ages eg classes), the variance  estimates may be different for this  
age clases (always in comparison with univariate models). Note that  
all models were run with expanded parameters priors.

I do not understand how the variance can change between two models  
(univariate and bivariate). In bivariate models, it is like Va  
estimate of an age class depends on the estimate of the covariance  
between age classes. For me, variance ??is calculated  independently  
from covariance (for example if var(x1)=cov(x1,x1), there is no use of  
cov(x1,x2)). After a long search, I did not find the line in the  
MCMCglmm function that could answer my question.
I was wondering if the  covariance properties between age classes were  
used to extrapolate missing points and thus refine the Va estimates.  
If this is the case, the variances calculated using multivariate  
models would be suceptible to estimate a biased Va for age classes  
which contain a large number of empty rows.

So if I go back to my questions :

Are there any constraints when estimating variance with univariate  
models compared with multivariate models? With univariate models, the  
estimated variances are they less 'real' than a multivariate model?

In bivariate models, Is there a dependency between the Va estimate of  
an age-class and the covariance between this age class and another one?

Thank in advance for your reply

St?phane Chantepie


From j.hadfield at ed.ac.uk  Thu Jul 17 14:40:05 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 17 Jul 2014 13:40:05 +0100
Subject: [R-sig-ME] Accuracy of Va estimates using univariate versus
 multivariate animal model
In-Reply-To: <20140717140350.683056t8lzyo5f3a@dsiwebmail.mnhn.fr>
References: <20140717140350.683056t8lzyo5f3a@dsiwebmail.mnhn.fr>
Message-ID: <20140717134005.166037p342c9lb0g@www.staffmail.ed.ac.uk>

Dear St?phane,

Va estimates may change between univariate and multivariate models for  
(at least) three reasons:

1/ The priors may have different effects, even if you have the same  
marginal priors for each variance. It is probably easier to understand  
this with a simpler example: Imagine I draw 100 numbers from a unit  
normal (mean zero, variance one), and fitted a model in which I placed  
a strong prior on the mean that conflicted with the true mean (lets  
say I put a prior point mass on a mean of 1) but used a flat improper  
prior for the variance. The posterior for the variance would give  
support for higher values than if a weaker prior on the mean was  
given. This happens because deviations are being calculated from a  
mean of one, rather than a mean closer to the data-driven value of  
zero. The marginal prior for the variance is flat and does not alert  
us to the fact that the prior on the mean may be informative for the  
variance.

2/ As you point out, if there is selective drop-out then Va in later  
age-classes may be smaller in the univariate model then the  
multivariate model. The multivariate model accounts for selection  
(under some conditions). The multivariate estimates are therefore  
better because they tell you what Va would have been had there been no  
selection. Va in the univariate models will change as the strength and  
pattern of selection change.

3/ (Possibly) Imagine a trait with h^2=1 and a trait h^2=0.1, and the  
genetic correlation is 1. Up to proportionality you know the breeding  
values for the second trait perfectly; they are the phenotypic values  
of the first trait. In a univariate analysis it would be much more  
difficult to predict the breeding values because of all the residual  
noise. So, the precision of the breeding value predictions clearly  
goes up in a multivariate model. However, I'm not sure whether this  
effect is also true for Va of the second trait, since it is the  
coefficient of proportionality for breeding value prediction. Possibly  
not, but I would have to check.

Cheers,

Jarrod











Quoting chantepie at mnhn.fr on Thu, 17 Jul 2014 14:03:50 +0200:

> Dear all,
>
> I have a question concerning the interpretation of Va estimate using  
> univariate versus the bivariate animal models.
>
> Indeed, I am interested to understand the age-related variation of  
> the additive genetic variance. For this, I made an analysis with  
> different age classes using univariate models for each age class. I  
> also tried to run a multivariate model with my different age classes  
> (9 in total). Nevertheless, even if the multivariate model can be  
> written and runs, the time needed to reach its converenge is greater  
> than 1 year.
>
> I'd like to know if it is better to estimate the Va of an age-class  
> with a multivariate animal model than with a univariate one and why?
>
> My view of the problem :
>
> I understand that with univariate models the ages classes are  
> considered as separate traits while in fact, the age classes are not  
> independent because the same individuals are found in different ages  
> classes. However, I do not really see the problem that univariate  
> model can generate on the estimates of Va and therefore in the  
> interpretation of results (as suggest a reviewer).
>
> When I realized bivariate models between two ages-classes where  
> there is a lot of information in each of the age-classes , the  
> variance of traits remains the same compared with univariate models.  
> However, when one of the age classes has less information (basically  
> with the old ages eg classes), the variance  estimates may be  
> different for this age clases (always in comparison with univariate  
> models). Note that all models were run with expanded parameters  
> priors.
>
> I do not understand how the variance can change between two models  
> (univariate and bivariate). In bivariate models, it is like Va  
> estimate of an age class depends on the estimate of the covariance  
> between age classes. For me, variance ??is calculated  independently  
> from covariance (for example if var(x1)=cov(x1,x1), there is no use  
> of cov(x1,x2)). After a long search, I did not find the line in the  
> MCMCglmm function that could answer my question.
> I was wondering if the  covariance properties between age classes  
> were used to extrapolate missing points and thus refine the Va  
> estimates. If this is the case, the variances calculated using  
> multivariate models would be suceptible to estimate a biased Va for  
> age classes which contain a large number of empty rows.
>
> So if I go back to my questions :
>
> Are there any constraints when estimating variance with univariate  
> models compared with multivariate models? With univariate models,  
> the estimated variances are they less 'real' than a multivariate  
> model?
>
> In bivariate models, Is there a dependency between the Va estimate  
> of an age-class and the covariance between this age class and  
> another one?
>
> Thank in advance for your reply
>
> St?phane Chantepie
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From christianvanbrauner at gmail.com  Thu Jul 17 17:41:25 2014
From: christianvanbrauner at gmail.com (Christian Brauner)
Date: Thu, 17 Jul 2014 17:41:25 +0200
Subject: [R-sig-ME] How is the covariance factor computed?
Message-ID: <20140717154124.GA11106@gmail.com>

Hello,

I am performing a priori power simulations for mixed-effect models based
on previous experiments. This works out quite nicely. I extract parts of
my parameters from a previous model I fitted:

prev_mod <- lmer(Y ~ A
                   + (B | Context)
                   + (B | Subjects),
                   data =3D data)

"A" :=3D 2 level factor
"Context" :=3D 40 level factor
"Subjects" :=3D 70 level factor

create design matrices for the fixed- and each random effect use functions from
the apply-family and bind them to a previously set-up data frame and so on.

In order to simulate data I draw from two multivariate distributions. One
for Subjects and one for Context. I previously constructed the
variance-covariance matrix by using the estimations I get by issuing
"as.data.frame(prev_mod)". After having read that Doug implemented a new
method for the "getME()" extractor "Tlist" that gives the covariance
factors from which the block matrices in "Lambda" are created I figured I
could get the variance-covariance matrix way easier by doing (code here
only for the "Context" variance-covariance matrix):

cov_fac <- getME(prev_mod, "Tlist")
cov_fac_context <- cov_fac$Context

sigma(prev_mod)^2*cov_fac_context%*%t(cov_fac_context)

But the question that has been haunting me for weeks now is how the individual
covariance factors (better: "matrices" in this case) that I can extract via
"getME(prev_mod, "Tlist") are computed. Is there some literature on that?  I
couldn't find any apart from the paper "Fitting linear mixed-effects models
using lme4" published 23.06.2014. I would be interested in reading up/get an
explanation how the covariance factor can be computed (mathematically and in
lme4) and if I need the variance-covariance matrix beforehand or vica versa.

Thank for any help!

Best,
Christian Brauner
Eberhard Karls Universit=C3=A4t T=C3=BCbingen
Mathematisch-Naturwissenschaftliche Fakult=C3=A4t - Faculty of Science
Evolutionary Cognition - Cognitive Science
Schleichstra=C3=9Fe 4 =C2=B7 72076 T=C3=BCbingen =C2=B7 Germany
Telefon +49 7071 29-75643 =C2=B7 Telefax +49 7071 29-4721
christianvanbrauner at gmail.com


From bbolker at gmail.com  Thu Jul 17 17:59:14 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 17 Jul 2014 11:59:14 -0400
Subject: [R-sig-ME] Negative binomial in glmmadmb
In-Reply-To: <30648_1405579287_s6H6fQAA030342_CAO4cCjozOvm+30_25E0F+kvVDHj==BgJ+GTGToBBZAmhXUuCfA@mail.gmail.com>
References: <30648_1405579287_s6H6fQAA030342_CAO4cCjozOvm+30_25E0F+kvVDHj==BgJ+GTGToBBZAmhXUuCfA@mail.gmail.com>
Message-ID: <53C7F2D2.2070908@mcmaster.ca>

On 14-07-17 02:41 AM, Daniel Moreno Fern?ndez wrote:
> Dear Mr. Bolker,
> 
> My name is Daniel Moreno-Fern?ndez. Currently, I am working with
> forest regeneration data. I would like to assess how the
> environmental factors evaluate the influence of environmental
> factors on natural regeneration of forest species. Thus, we
> installed several plots in the forest and each plot was subdivided
> into subplots. We counted the number of young trees (seedlings) in
> each subplot. Due to the variance is higher than the mean we used a
> negative binomial. In addition, the hierarchical desing makes 
> necessary to enter a plot random effect. We assumed a constant
> value of the dispersion parameter ( family="nbinom"). We fitted
> following model using the glmmadmb function in R:
> 
> model1<-glmmadmb(Seedlings~ph+calcium +(1|Plot), data=reg, 
> zeroInflation=FALSE,   family="nbinom",  link="log")
> 
> I am worried about some doubts about the the random effect and the
> residual error (I have hardly worked with Generalized linear
> models):
> 
> - Are the random effect and the residual error within the
> log-link? - Concerning the properties of the the random effect and
> the residual error, I expect that both follow a N ~ (0, var), am I
> right?
> 
> Yours sincerely,
> 
> Daniel
> 

  [cc'ing to r-sig-mixed-models]

  You might be a little bit confused about negative binomial models.
The model fitted by glmmadmb in this case is

   Seedlings ~ NegBinom(mu,theta)         (1)
   mu = exp(b0+b1*ph+b2*calcium + eps_i)  (2)
   eps_i ~ Normal(0,sigma_p^2)            (3)

The effect of the log link shows up as the exponential (inverse-link)
in eq. 2.  'Residual error' is a bit hard to define for GLMMs, but we
can say that the _conditional distribution_ of the response (i.e.
conditional on the plot-level random effects) is negative binomial.

   Ben Bolker


From vdorie at cs.stanford.edu  Thu Jul 17 21:24:07 2014
From: vdorie at cs.stanford.edu (Vincent Dorie)
Date: Thu, 17 Jul 2014 15:24:07 -0400
Subject: [R-sig-ME] How is the covariance factor computed?
In-Reply-To: <20140717154124.GA11106@gmail.com>
References: <20140717154124.GA11106@gmail.com>
Message-ID: <D25F189B-F962-41A8-8FEF-2C7D6DE8A1DB@nyu.edu>

I'm not sure if this answers your question, but the parameters of the variance/covariance matrix are stored in the theta slot of a merMod in a form such that they correspond to a Cholesky factorization of the individual components of the var/cov matrix of the random effects, with the diagonal in the first 'd' parts of the vector and the off-diagonal stored in column-major format in the next d * (d - 1) / 2 elements. Given a theta vector, to get to a representation such as that which Tlist gives requires knowing how to map the parameters to matrices. This is currently done by hand, using the knowledge that the cnms slot of a merMod contains the dimension of each grouping "factor"/"level" and the aforementioned Cholesky decomposition storage concept. In the future, however, if lme4 supports different forms of variance/covariances matrices for factors other than "full" (e.g. independent, or correlation only), then that knowledge will need to be referenced instead. I believe there is effort on that front in the "flexLambda" branch on github.

On the other hand, if you were asking where those numbers come from, it turns out that (at least for linear models) those parameters are sufficient to define a likelihood wherein the fixed effects and conditional error term (sigma) are analytically optimized. Since the goal is a maximum likelihood, or REML, the sigma parameters are then simply numerically optimized. You can then easily evaluate the mixed model likelihood at any value of the var/cov matrix of the random effects that you like, provided you are willing to accept maximal values for the fixed effects and sigma. If you wanted to plug those values in as well, it's a bit of a pain but it can be done.

Vince

On Jul 17, 2014, at 11:41 AM, Christian Brauner <christianvanbrauner at gmail.com> wrote:

> Hello,
> 
> I am performing a priori power simulations for mixed-effect models based
> on previous experiments. This works out quite nicely. I extract parts of
> my parameters from a previous model I fitted:
> 
> prev_mod <- lmer(Y ~ A
>                   + (B | Context)
>                   + (B | Subjects),
>                   data =3D data)
> 
> "A" :=3D 2 level factor
> "Context" :=3D 40 level factor
> "Subjects" :=3D 70 level factor
> 
> create design matrices for the fixed- and each random effect use functions from
> the apply-family and bind them to a previously set-up data frame and so on.
> 
> In order to simulate data I draw from two multivariate distributions. One
> for Subjects and one for Context. I previously constructed the
> variance-covariance matrix by using the estimations I get by issuing
> "as.data.frame(prev_mod)". After having read that Doug implemented a new
> method for the "getME()" extractor "Tlist" that gives the covariance
> factors from which the block matrices in "Lambda" are created I figured I
> could get the variance-covariance matrix way easier by doing (code here
> only for the "Context" variance-covariance matrix):
> 
> cov_fac <- getME(prev_mod, "Tlist")
> cov_fac_context <- cov_fac$Context
> 
> sigma(prev_mod)^2*cov_fac_context%*%t(cov_fac_context)
> 
> But the question that has been haunting me for weeks now is how the individual
> covariance factors (better: "matrices" in this case) that I can extract via
> "getME(prev_mod, "Tlist") are computed. Is there some literature on that?  I
> couldn't find any apart from the paper "Fitting linear mixed-effects models
> using lme4" published 23.06.2014. I would be interested in reading up/get an
> explanation how the covariance factor can be computed (mathematically and in
> lme4) and if I need the variance-covariance matrix beforehand or vica versa.
> 
> Thank for any help!
> 
> Best,
> Christian Brauner
> Eberhard Karls Universit=C3=A4t T=C3=BCbingen
> Mathematisch-Naturwissenschaftliche Fakult=C3=A4t - Faculty of Science
> Evolutionary Cognition - Cognitive Science
> Schleichstra=C3=9Fe 4 =C2=B7 72076 T=C3=BCbingen =C2=B7 Germany
> Telefon +49 7071 29-75643 =C2=B7 Telefax +49 7071 29-4721
> christianvanbrauner at gmail.com
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Thu Jul 17 22:18:19 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 17 Jul 2014 20:18:19 +0000 (UTC)
Subject: [R-sig-ME] How is the covariance factor computed?
References: <20140717154124.GA11106@gmail.com>
	<D25F189B-F962-41A8-8FEF-2C7D6DE8A1DB@nyu.edu>
Message-ID: <loom.20140717T221254-828@post.gmane.org>

Vincent Dorie <vdorie at ...> writes:

 [snip]

> On the other hand, if you were asking where those numbers come from,
> it turns out that (at least for linear models) those parameters are
> sufficient to define a likelihood wherein the fixed effects and
> conditional error term (sigma) are analytically optimized. Since the
> goal is a maximum likelihood, or REML, the sigma parameters are then
> simply numerically optimized. You can then easily evaluate the mixed
> model likelihood at any value of the var/cov matrix of the random
> effects that you like, provided you are willing to accept maximal
> values for the fixed effects and sigma. If you wanted to plug those
> values in as well, it's a bit of a pain but it can be done.  
>   Vince

  ... specifically, for this last bit, see the devfun2() function in
https://github.com/lme4/lme4/blob/master/R/profile.R ; there is a
brief description of how this works in the lme4 preprint at
http://arxiv.org/abs/1406.5823 , in the 'profiling' section.  (I
think "... the sigma parameters are then simply numerically optimized"
should be "... the theta parameters ...") [defined in previous para.
as the elements of the Cholesky factorization(s) of the random effects
variance-covariance matri[xc](es) ...]

  Ben Bolker


From bbolker at gmail.com  Thu Jul 17 22:39:42 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 17 Jul 2014 16:39:42 -0400
Subject: [R-sig-ME] [R] Checking modeling assumptions in a binomial GLMM
In-Reply-To: <2F9EA67EF9AE1C48A147CB41BE2E15C312434DF7@DOM-MTW-MAIL2.win.ad.jhu.edu>
References: <2F9EA67EF9AE1C48A147CB41BE2E15C312434DF7@DOM-MTW-MAIL2.win.ad.jhu.edu>
Message-ID: <53C8348E.6050704@gmail.com>

On 14-07-17 10:05 AM, Ravi Varadhan wrote:

> Dear Ben,

> Thank you for the helpful response.  I had posted the question to
  r-sig-mixed last week, but I did not hear from anyone.  Perhaps, the
  moderator never approved my post.  Hence, the post to r-help.

[cc'ing to r-sig-mixed-models now]

> My example has repeated binary (0/1) responses at each visit of a
  clinical trial (it is actually the schizophrenia trial discussed in
  Hedeker and Gibbons' book on longitudinal analysis).  My impression
  was that diagnostics are quite difficult to do, but was interested
  in seeing if someone had demonstrated this.


> I have some related questions: the glmer function in "lme4" does not
  handle nAGQ > 1 when there are more than 1 random effects.  I know
  this is a curse of dimensionality problem, but I do not see why it
  cannot handle nAGQ up to 9 for 2-3 dimensions.  Is Laplace's
  approximation sufficiently accurate for multiple random effects?  Is
  mcmcGLMM the way to go for binary GLMM with multiple random effects?


To a large extent AGQ is not implemented for multiple random effects
(or, in lme4 >= 1.0.0, for vector-valued random effects) because we
simply haven't had the time and energy to implement it.  Doug Bates has
long felt/stated that AGQ would be infeasibly slow for multiple random
effects.  To be honest, I don't know if he's basing that on better knowledge
than I (or anyone!) have about the internals of lme4 (e.g. trying to
construct the data structures necessary to do AGQ would lead to a
catastrophic loss of sparsity) or whether it's just that his focus
is usually on gigantic data sets where multi-dimensional AGQ truly
would be infeasible.

  Certainly MCMCglmm, or going outside the R framework (to SAS
PROC GLIMMIX, or Stata's GLLAMM
<http://www.stata-press.com/books/mlmus3_ch10.pdf>), would be my first
resort when worrying about whether AGQ is necessary.
Unfortunately, I know of very little discussion about how to determine
in general whether AGQ is necessary (or what number of quadrature
points is sufficient), without actually doing it -- most of the examples
I've seen (e.g. <http://www.stata-press.com/books/mlmus3_ch10.pdf>
or Breslow 2003) just check by brute force (see
http://rpubs.com/bbolker/glmmchapter for another example).  It would
be nice to figure out a score test, or at least graphical diagnostics,
that could suggest (without actually doing the entire integral) how
much the underlying densities departed from those assumed by the
Laplace approximation.  (The zeta() function in
http://lme4.r-forge.r-project.org/JSS/glmer.Rnw might be a good
starting point ...)

  cheers
    Ben Bolker


From bbolker at gmail.com  Fri Jul 18 01:02:15 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 17 Jul 2014 19:02:15 -0400
Subject: [R-sig-ME] [R] Checking modeling assumptions in a binomial GLMM
In-Reply-To: <2F9EA67EF9AE1C48A147CB41BE2E15C312434FFD@DOM-MTW-MAIL2.win.ad.jhu.edu>
References: <2F9EA67EF9AE1C48A147CB41BE2E15C312434DF7@DOM-MTW-MAIL2.win.ad.jhu.edu>
	<53C8348E.6050704@gmail.com>
	<2F9EA67EF9AE1C48A147CB41BE2E15C312434FFD@DOM-MTW-MAIL2.win.ad.jhu.edu>
Message-ID: <53C855F7.70200@gmail.com>

On 14-07-17 05:19 PM, Ravi Varadhan wrote:
> Thank you very much, Ben.
> 
> I have one more question:  you have function for computing
> overdispersion, overdisp.glmer() in "RVAideMemoire" package.  This is
> useful, I suppose.  Why is it not part of lme4, or, equivalently why
> doesn't glmer() not provide this information?
> 
> Thanks, Ravi

RVAideMemoire is not our package: it's by Maxime Herv?.

We probably didn't add the overdispersion calculation to lme4
because (1) we didn't get around to it; (2) for GLMMs it's an
even-more-approximate estimate of overdispersion than it is
for GLMs; (3) it's easy enough for users to implement themselves
(another version is listed at
http://glmm.wikidot.com/faq#overdispersion_est,
and the aods3::gof() function also does these calculations
(although looking at it, there may be some issues with the
using the results of lme4::deviance() for these purposes -- it returns
something different from the sum of squares of the deviance
residuals ...)

  The summary statement of glmer models probably *should* include this
information.  Feel free to post an issue at
https://github.com/lme4/lme4/issues ...

This somewhat simpler expression replicates the results of
RVAideMemoire's function, although not quite as prettily:

library(lme4)
example(glmer)

c(dev <- sum(residuals(gm1)^2),
  dfr <- df.residual(gm1),
  ratio <- dev/dfr)

RVAideMemoire::overdisp.glmer(gm1)

> 
> -----Original Message----- From: Ben Bolker
> [mailto:bbolker at gmail.com] Sent: Thursday, July 17, 2014 4:40 PM To:
> Ravi Varadhan Cc: r-sig-mixed-models at r-project.org Subject: Re: [R]
> Checking modeling assumptions in a binomial GLMM
> 
> On 14-07-17 10:05 AM, Ravi Varadhan wrote:
> 
>> Dear Ben,
> 
>> Thank you for the helpful response.  I had posted the question to
> r-sig-mixed last week, but I did not hear from anyone.  Perhaps, the 
> moderator never approved my post.  Hence, the post to r-help.
> 
> [cc'ing to r-sig-mixed-models now]
> 
>> My example has repeated binary (0/1) responses at each visit of a
> clinical trial (it is actually the schizophrenia trial discussed in 
> Hedeker and Gibbons' book on longitudinal analysis).  My impression 
> was that diagnostics are quite difficult to do, but was interested in
> seeing if someone had demonstrated this.
> 
> 
>> I have some related questions: the glmer function in "lme4" does
>> not
> handle nAGQ > 1 when there are more than 1 random effects.  I know 
> this is a curse of dimensionality problem, but I do not see why it 
> cannot handle nAGQ up to 9 for 2-3 dimensions.  Is Laplace's 
> approximation sufficiently accurate for multiple random effects?  Is 
> mcmcGLMM the way to go for binary GLMM with multiple random effects?
> 
> 
> To a large extent AGQ is not implemented for multiple random effects
> (or, in lme4 >= 1.0.0, for vector-valued random effects) because we
> simply haven't had the time and energy to implement it.  Doug Bates
> has long felt/stated that AGQ would be infeasibly slow for multiple
> random effects.  To be honest, I don't know if he's basing that on
> better knowledge than I (or anyone!) have about the internals of lme4
> (e.g. trying to construct the data structures necessary to do AGQ
> would lead to a catastrophic loss of sparsity) or whether it's just
> that his focus is usually on gigantic data sets where
> multi-dimensional AGQ truly would be infeasible.
> 
> Certainly MCMCglmm, or going outside the R framework (to SAS PROC
> GLIMMIX, or Stata's GLLAMM
> <http://www.stata-press.com/books/mlmus3_ch10.pdf>), would be my
> first resort when worrying about whether AGQ is necessary. 
> Unfortunately, I know of very little discussion about how to
> determine in general whether AGQ is necessary (or what number of
> quadrature points is sufficient), without actually doing it -- most
> of the examples I've seen (e.g.
> <http://www.stata-press.com/books/mlmus3_ch10.pdf> or Breslow 2003)
> just check by brute force (see http://rpubs.com/bbolker/glmmchapter
> for another example).  It would be nice to figure out a score test,
> or at least graphical diagnostics, that could suggest (without
> actually doing the entire integral) how much the underlying densities
> departed from those assumed by the Laplace approximation.  (The
> zeta() function in http://lme4.r-forge.r-project.org/JSS/glmer.Rnw
> might be a good starting point ...)
> 
> cheers Ben Bolker
>


From steve.walker at utoronto.ca  Fri Jul 18 03:38:06 2014
From: steve.walker at utoronto.ca (steve.walker at utoronto.ca)
Date: Thu, 17 Jul 2014 21:38:06 -0400
Subject: [R-sig-ME] How is the covariance factor computed?
In-Reply-To: <D25F189B-F962-41A8-8FEF-2C7D6DE8A1DB@nyu.edu>
References: <20140717154124.GA11106@gmail.com>
	<D25F189B-F962-41A8-8FEF-2C7D6DE8A1DB@nyu.edu>
Message-ID: <20140717213806.w87sui3fggkgkk0c@webmail.utoronto.ca>

Hi Christian,

Although Vince pretty much answered your question, the preprint that  
you refer to provides another description that some might find helpful,

http://arxiv.org/pdf/1406.5823v1.pdf

See "Constructing the relative covariance factor" starting at the  
bottom of p. 10 and "PLS step I: update relative covariance factor" at  
the bottom of p. 19.

The (profile) likelihood for theta that Vince discussed is equation 34  
on page 16.  Equation 30 is the likelihood for all three types of  
parameters -- theta, beta, and sigma.

Small point:  I think there is a typo in the answer below in that,

> the sigma parameters are then  simply numerically optimized

should refer to theta, not sigma.

Cheers,
Steve


Quoting Vincent Dorie <vdorie at cs.stanford.edu>:

> I'm not sure if this answers your question, but the parameters of   
> the variance/covariance matrix are stored in the theta slot of a   
> merMod in a form such that they correspond to a Cholesky   
> factorization of the individual components of the var/cov matrix of   
> the random effects, with the diagonal in the first 'd' parts of the   
> vector and the off-diagonal stored in column-major format in the   
> next d * (d - 1) / 2 elements. Given a theta vector, to get to a   
> representation such as that which Tlist gives requires knowing how   
> to map the parameters to matrices. This is currently done by hand,   
> using the knowledge that the cnms slot of a merMod contains the   
> dimension of each grouping "factor"/"level" and the aforementioned   
> Cholesky decomposition storage concept. In the future, however, if   
> lme4 supports different forms of variance/covariances matrices for   
> factors other than "full" (e.g. independent, or correlation only),   
> then that knowledge will need to be referenced instead. I believe the!
>  re is effort on that front in the "flexLambda" branch on github.
>
> On the other hand, if you were asking where those numbers come from,  
>  it turns out that (at least for linear models) those parameters are  
>  sufficient to define a likelihood wherein the fixed effects and   
> conditional error term (sigma) are analytically optimized. Since the  
>  goal is a maximum likelihood, or REML, the sigma parameters are  
> then  simply numerically optimized. You can then easily evaluate the  
> mixed  model likelihood at any value of the var/cov matrix of the  
> random  effects that you like, provided you are willing to accept  
> maximal  values for the fixed effects and sigma. If you wanted to  
> plug those  values in as well, it's a bit of a pain but it can be  
> done.
>
> Vince
>
> On Jul 17, 2014, at 11:41 AM, Christian Brauner   
> <christianvanbrauner at gmail.com> wrote:
>
>> Hello,
>>
>> I am performing a priori power simulations for mixed-effect models based
>> on previous experiments. This works out quite nicely. I extract parts of
>> my parameters from a previous model I fitted:
>>
>> prev_mod <- lmer(Y ~ A
>>                   + (B | Context)
>>                   + (B | Subjects),
>>                   data =3D data)
>>
>> "A" :=3D 2 level factor
>> "Context" :=3D 40 level factor
>> "Subjects" :=3D 70 level factor
>>
>> create design matrices for the fixed- and each random effect use   
>> functions from
>> the apply-family and bind them to a previously set-up data frame and so on.
>>
>> In order to simulate data I draw from two multivariate distributions. One
>> for Subjects and one for Context. I previously constructed the
>> variance-covariance matrix by using the estimations I get by issuing
>> "as.data.frame(prev_mod)". After having read that Doug implemented a new
>> method for the "getME()" extractor "Tlist" that gives the covariance
>> factors from which the block matrices in "Lambda" are created I figured I
>> could get the variance-covariance matrix way easier by doing (code here
>> only for the "Context" variance-covariance matrix):
>>
>> cov_fac <- getME(prev_mod, "Tlist")
>> cov_fac_context <- cov_fac$Context
>>
>> sigma(prev_mod)^2*cov_fac_context%*%t(cov_fac_context)
>>
>> But the question that has been haunting me for weeks now is how the  
>>  individual
>> covariance factors (better: "matrices" in this case) that I can extract via
>> "getME(prev_mod, "Tlist") are computed. Is there some literature on that?  I
>> couldn't find any apart from the paper "Fitting linear mixed-effects models
>> using lme4" published 23.06.2014. I would be interested in reading up/get an
>> explanation how the covariance factor can be computed (mathematically and in
>> lme4) and if I need the variance-covariance matrix beforehand or vica versa.
>>
>> Thank for any help!
>>
>> Best,
>> Christian Brauner
>> Eberhard Karls Universit=C3=A4t T=C3=BCbingen
>> Mathematisch-Naturwissenschaftliche Fakult=C3=A4t - Faculty of Science
>> Evolutionary Cognition - Cognitive Science
>> Schleichstra=C3=9Fe 4 =C2=B7 72076 T=C3=BCbingen =C2=B7 Germany
>> Telefon +49 7071 29-75643 =C2=B7 Telefax +49 7071 29-4721
>> christianvanbrauner at gmail.com
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From ravi.varadhan at jhu.edu  Thu Jul 17 23:19:38 2014
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Thu, 17 Jul 2014 21:19:38 +0000
Subject: [R-sig-ME] [R] Checking modeling assumptions in a binomial GLMM
In-Reply-To: <53C8348E.6050704@gmail.com>
References: <2F9EA67EF9AE1C48A147CB41BE2E15C312434DF7@DOM-MTW-MAIL2.win.ad.jhu.edu>
	<53C8348E.6050704@gmail.com>
Message-ID: <2F9EA67EF9AE1C48A147CB41BE2E15C312434FFD@DOM-MTW-MAIL2.win.ad.jhu.edu>

Thank you very much, Ben.  

I have one more question:  you have function for computing overdispersion, overdisp.glmer() in "RVAideMemoire" package.  This is useful, I suppose.  Why is it not part of lme4, or, equivalently why doesn't glmer() not provide this information?

Thanks,
Ravi

-----Original Message-----
From: Ben Bolker [mailto:bbolker at gmail.com] 
Sent: Thursday, July 17, 2014 4:40 PM
To: Ravi Varadhan
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R] Checking modeling assumptions in a binomial GLMM

On 14-07-17 10:05 AM, Ravi Varadhan wrote:

> Dear Ben,

> Thank you for the helpful response.  I had posted the question to
  r-sig-mixed last week, but I did not hear from anyone.  Perhaps, the
  moderator never approved my post.  Hence, the post to r-help.

[cc'ing to r-sig-mixed-models now]

> My example has repeated binary (0/1) responses at each visit of a
  clinical trial (it is actually the schizophrenia trial discussed in
  Hedeker and Gibbons' book on longitudinal analysis).  My impression
  was that diagnostics are quite difficult to do, but was interested
  in seeing if someone had demonstrated this.


> I have some related questions: the glmer function in "lme4" does not
  handle nAGQ > 1 when there are more than 1 random effects.  I know
  this is a curse of dimensionality problem, but I do not see why it
  cannot handle nAGQ up to 9 for 2-3 dimensions.  Is Laplace's
  approximation sufficiently accurate for multiple random effects?  Is
  mcmcGLMM the way to go for binary GLMM with multiple random effects?


To a large extent AGQ is not implemented for multiple random effects (or, in lme4 >= 1.0.0, for vector-valued random effects) because we simply haven't had the time and energy to implement it.  Doug Bates has long felt/stated that AGQ would be infeasibly slow for multiple random effects.  To be honest, I don't know if he's basing that on better knowledge than I (or anyone!) have about the internals of lme4 (e.g. trying to construct the data structures necessary to do AGQ would lead to a catastrophic loss of sparsity) or whether it's just that his focus is usually on gigantic data sets where multi-dimensional AGQ truly would be infeasible.

  Certainly MCMCglmm, or going outside the R framework (to SAS PROC GLIMMIX, or Stata's GLLAMM <http://www.stata-press.com/books/mlmus3_ch10.pdf>), would be my first resort when worrying about whether AGQ is necessary.
Unfortunately, I know of very little discussion about how to determine in general whether AGQ is necessary (or what number of quadrature points is sufficient), without actually doing it -- most of the examples I've seen (e.g. <http://www.stata-press.com/books/mlmus3_ch10.pdf>
or Breslow 2003) just check by brute force (see http://rpubs.com/bbolker/glmmchapter for another example).  It would be nice to figure out a score test, or at least graphical diagnostics, that could suggest (without actually doing the entire integral) how much the underlying densities departed from those assumed by the Laplace approximation.  (The zeta() function in http://lme4.r-forge.r-project.org/JSS/glmer.Rnw might be a good starting point ...)

  cheers
    Ben Bolker


From vdorie at cs.stanford.edu  Thu Jul 17 22:41:40 2014
From: vdorie at cs.stanford.edu (Vincent Dorie)
Date: Thu, 17 Jul 2014 16:41:40 -0400
Subject: [R-sig-ME] How is the covariance factor computed?
In-Reply-To: <loom.20140717T221254-828@post.gmane.org>
References: <20140717154124.GA11106@gmail.com>
	<D25F189B-F962-41A8-8FEF-2C7D6DE8A1DB@nyu.edu>
	<loom.20140717T221254-828@post.gmane.org>
Message-ID: <233E6D2F-E8B9-477D-8E84-440853531DBF@cs.stanford.edu>

> (I
> think "... the sigma parameters are then simply numerically optimized"
> should be "... the theta parameters ...")


Whoops. Ben is right, as usual.

On Jul 17, 2014, at 4:18 PM, Ben Bolker <bbolker at gmail.com> wrote:

> Vincent Dorie <vdorie at ...> writes:
> 
> [snip]
> 
>> On the other hand, if you were asking where those numbers come from,
>> it turns out that (at least for linear models) those parameters are
>> sufficient to define a likelihood wherein the fixed effects and
>> conditional error term (sigma) are analytically optimized. Since the
>> goal is a maximum likelihood, or REML, the sigma parameters are then
>> simply numerically optimized. You can then easily evaluate the mixed
>> model likelihood at any value of the var/cov matrix of the random
>> effects that you like, provided you are willing to accept maximal
>> values for the fixed effects and sigma. If you wanted to plug those
>> values in as well, it's a bit of a pain but it can be done.  
>>  Vince
> 
>  ... specifically, for this last bit, see the devfun2() function in
> https://github.com/lme4/lme4/blob/master/R/profile.R ; there is a
> brief description of how this works in the lme4 preprint at
> http://arxiv.org/abs/1406.5823 , in the 'profiling' section.  (I
> think "... the sigma parameters are then simply numerically optimized"
> should be "... the theta parameters ...") [defined in previous para.
> as the elements of the Cholesky factorization(s) of the random effects
> variance-covariance matri[xc](es) ...]
> 
>  Ben Bolker
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From christianvanbrauner at gmail.com  Fri Jul 18 14:39:10 2014
From: christianvanbrauner at gmail.com (Christian Brauner)
Date: Fri, 18 Jul 2014 14:39:10 +0200
Subject: [R-sig-ME] How is the covariance factor computed?
In-Reply-To: <20140717213806.w87sui3fggkgkk0c@webmail.utoronto.ca>
References: <20140717154124.GA11106@gmail.com>
	<D25F189B-F962-41A8-8FEF-2C7D6DE8A1DB@nyu.edu>
	<20140717213806.w87sui3fggkgkk0c@webmail.utoronto.ca>
Message-ID: <20140718123910.GA7605@gmail.com>

Dear Vince, Ben and Steve,

thank you! I'm reading the paper and the suggested sections. It's really
good and really helpful! Just to make sure I understand you correctly: The
individual variance-covariance matrices for the random effects can be
easily computed from the data by "estimating" the variances and
covariances for the random effects. A simple example of two
variance-covariance matrices for two (non-scalar) random effects:

R1=
var_11 cov_21
cov_12 var_22


R2=
var_11 cov_21
cov_12 var_22

Vince stated that that the "theta" slot which in your paper you call
"variance-component parameter" (p. 4 right above equation (4)) contains
the Cholesky factorization of the individual components of the
variance-covariance matrices of the random effects. Hence, I assume that
you can just compute them in R calling "chol(R1)" and "chol(R2)". This
however, gives the wrong resuls when I compare the output of "getME(mod8,
"theta") and "chol(R1)" and "chol(R2)".  How do I compute Cholesky
factorization in R correctly?

Best,
Christian


On Thu, Jul 17, 2014 at 09:38:06PM -0400, steve.walker at utoronto.ca wrote:
> Hi Christian,
> 
> Although Vince pretty much answered your question, the preprint that you
> refer to provides another description that some might find helpful,
> 
> http://arxiv.org/pdf/1406.5823v1.pdf
> 
> See "Constructing the relative covariance factor" starting at the bottom of
> p. 10 and "PLS step I: update relative covariance factor" at the bottom of
> p. 19.
> 
> The (profile) likelihood for theta that Vince discussed is equation 34 on
> page 16.  Equation 30 is the likelihood for all three types of parameters --
> theta, beta, and sigma.
> 
> Small point:  I think there is a typo in the answer below in that,
> 
> >the sigma parameters are then  simply numerically optimized
> 
> should refer to theta, not sigma.
> 
> Cheers,
> Steve
> 
> 
> Quoting Vincent Dorie <vdorie at cs.stanford.edu>:
> 
> >I'm not sure if this answers your question, but the parameters of  the
> >variance/covariance matrix are stored in the theta slot of a  merMod in a
> >form such that they correspond to a Cholesky  factorization of the
> >individual components of the var/cov matrix of  the random effects, with
> >the diagonal in the first 'd' parts of the  vector and the off-diagonal
> >stored in column-major format in the  next d * (d - 1) / 2 elements. Given
> >a theta vector, to get to a  representation such as that which Tlist gives
> >requires knowing how  to map the parameters to matrices. This is currently
> >done by hand,  using the knowledge that the cnms slot of a merMod contains
> >the  dimension of each grouping "factor"/"level" and the aforementioned
> >Cholesky decomposition storage concept. In the future, however, if  lme4
> >supports different forms of variance/covariances matrices for  factors
> >other than "full" (e.g. independent, or correlation only),  then that
> >knowledge will need to be referenced instead. I believe the!
> > re is effort on that front in the "flexLambda" branch on github.
> >
> >On the other hand, if you were asking where those numbers come from,  it
> >turns out that (at least for linear models) those parameters are
> >sufficient to define a likelihood wherein the fixed effects and
> >conditional error term (sigma) are analytically optimized. Since the  goal
> >is a maximum likelihood, or REML, the sigma parameters are then  simply
> >numerically optimized. You can then easily evaluate the mixed  model
> >likelihood at any value of the var/cov matrix of the random  effects that
> >you like, provided you are willing to accept maximal  values for the fixed
> >effects and sigma. If you wanted to plug those  values in as well, it's a
> >bit of a pain but it can be done.
> >
> >Vince
> >
> >On Jul 17, 2014, at 11:41 AM, Christian Brauner
> ><christianvanbrauner at gmail.com> wrote:
> >
> >>Hello,
> >>
> >>I am performing a priori power simulations for mixed-effect models based
> >>on previous experiments. This works out quite nicely. I extract parts of
> >>my parameters from a previous model I fitted:
> >>
> >>prev_mod <- lmer(Y ~ A
> >>                  + (B | Context)
> >>                  + (B | Subjects),
> >>                  data =3D data)
> >>
> >>"A" :=3D 2 level factor
> >>"Context" :=3D 40 level factor
> >>"Subjects" :=3D 70 level factor
> >>
> >>create design matrices for the fixed- and each random effect use
> >>functions from
> >>the apply-family and bind them to a previously set-up data frame and so on.
> >>
> >>In order to simulate data I draw from two multivariate distributions. One
> >>for Subjects and one for Context. I previously constructed the
> >>variance-covariance matrix by using the estimations I get by issuing
> >>"as.data.frame(prev_mod)". After having read that Doug implemented a new
> >>method for the "getME()" extractor "Tlist" that gives the covariance
> >>factors from which the block matrices in "Lambda" are created I figured I
> >>could get the variance-covariance matrix way easier by doing (code here
> >>only for the "Context" variance-covariance matrix):
> >>
> >>cov_fac <- getME(prev_mod, "Tlist")
> >>cov_fac_context <- cov_fac$Context
> >>
> >>sigma(prev_mod)^2*cov_fac_context%*%t(cov_fac_context)
> >>
> >>But the question that has been haunting me for weeks now is how the
> >>individual
> >>covariance factors (better: "matrices" in this case) that I can extract via
> >>"getME(prev_mod, "Tlist") are computed. Is there some literature on that?  I
> >>couldn't find any apart from the paper "Fitting linear mixed-effects models
> >>using lme4" published 23.06.2014. I would be interested in reading up/get an
> >>explanation how the covariance factor can be computed (mathematically and in
> >>lme4) and if I need the variance-covariance matrix beforehand or vica versa.
> >>
> >>Thank for any help!
> >>
> >>Best,
> >>Christian Brauner
> >>Eberhard Karls Universit=C3=A4t T=C3=BCbingen
> >>Mathematisch-Naturwissenschaftliche Fakult=C3=A4t - Faculty of Science
> >>Evolutionary Cognition - Cognitive Science
> >>Schleichstra=C3=9Fe 4 =C2=B7 72076 T=C3=BCbingen =C2=B7 Germany
> >>Telefon +49 7071 29-75643 =C2=B7 Telefax +49 7071 29-4721
> >>christianvanbrauner at gmail.com
> >>
> >>_______________________________________________
> >>R-sig-mixed-models at r-project.org mailing list
> >>https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >_______________________________________________
> >R-sig-mixed-models at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> 
> 
>


From bbolker at gmail.com  Fri Jul 18 15:18:15 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 18 Jul 2014 09:18:15 -0400
Subject: [R-sig-ME] How is the covariance factor computed?
In-Reply-To: <20140718123910.GA7605@gmail.com>
References: <20140717154124.GA11106@gmail.com>	<D25F189B-F962-41A8-8FEF-2C7D6DE8A1DB@nyu.edu>	<20140717213806.w87sui3fggkgkk0c@webmail.utoronto.ca>
	<20140718123910.GA7605@gmail.com>
Message-ID: <53C91E97.3040109@gmail.com>

On 14-07-18 08:39 AM, Christian Brauner wrote:
> Dear Vince, Ben and Steve,
> 
> thank you! I'm reading the paper and the suggested sections. It's really
> good and really helpful! Just to make sure I understand you correctly: The
> individual variance-covariance matrices for the random effects can be
> easily computed from the data by "estimating" the variances and
> covariances for the random effects. A simple example of two
> variance-covariance matrices for two (non-scalar) random effects:
> 
> R1=
> var_11 cov_21
> cov_12 var_22
> 
> 
> R2=
> var_11 cov_21
> cov_12 var_22
> 
> Vince stated that that the "theta" slot which in your paper you call
> "variance-component parameter" (p. 4 right above equation (4)) contains
> the Cholesky factorization of the individual components of the
> variance-covariance matrices of the random effects. Hence, I assume that
> you can just compute them in R calling "chol(R1)" and "chol(R2)". This
> however, gives the wrong resuls when I compare the output of "getME(mod8,
> "theta") and "chol(R1)" and "chol(R2)".  How do I compute Cholesky
> factorization in R correctly?
> 
> Best,
> Christian

   You probably forgot to scale by the residual standard error:

chol(VarCorr(fm1)[[1]])/sigma(fm1)
getME(fm1,"theta")
> 
> 
> On Thu, Jul 17, 2014 at 09:38:06PM -0400, steve.walker at utoronto.ca wrote:
>> Hi Christian,
>>
>> Although Vince pretty much answered your question, the preprint that you
>> refer to provides another description that some might find helpful,
>>
>> http://arxiv.org/pdf/1406.5823v1.pdf
>>
>> See "Constructing the relative covariance factor" starting at the bottom of
>> p. 10 and "PLS step I: update relative covariance factor" at the bottom of
>> p. 19.
>>
>> The (profile) likelihood for theta that Vince discussed is equation 34 on
>> page 16.  Equation 30 is the likelihood for all three types of parameters --
>> theta, beta, and sigma.
>>
>> Small point:  I think there is a typo in the answer below in that,
>>
>>> the sigma parameters are then  simply numerically optimized
>>
>> should refer to theta, not sigma.
>>
>> Cheers,
>> Steve
>>
>>
>> Quoting Vincent Dorie <vdorie at cs.stanford.edu>:
>>
>>> I'm not sure if this answers your question, but the parameters of  the
>>> variance/covariance matrix are stored in the theta slot of a  merMod in a
>>> form such that they correspond to a Cholesky  factorization of the
>>> individual components of the var/cov matrix of  the random effects, with
>>> the diagonal in the first 'd' parts of the  vector and the off-diagonal
>>> stored in column-major format in the  next d * (d - 1) / 2 elements. Given
>>> a theta vector, to get to a  representation such as that which Tlist gives
>>> requires knowing how  to map the parameters to matrices. This is currently
>>> done by hand,  using the knowledge that the cnms slot of a merMod contains
>>> the  dimension of each grouping "factor"/"level" and the aforementioned
>>> Cholesky decomposition storage concept. In the future, however, if  lme4
>>> supports different forms of variance/covariances matrices for  factors
>>> other than "full" (e.g. independent, or correlation only),  then that
>>> knowledge will need to be referenced instead. I believe the!
>>> re is effort on that front in the "flexLambda" branch on github.
>>>
>>> On the other hand, if you were asking where those numbers come from,  it
>>> turns out that (at least for linear models) those parameters are
>>> sufficient to define a likelihood wherein the fixed effects and
>>> conditional error term (sigma) are analytically optimized. Since the  goal
>>> is a maximum likelihood, or REML, the sigma parameters are then  simply
>>> numerically optimized. You can then easily evaluate the mixed  model
>>> likelihood at any value of the var/cov matrix of the random  effects that
>>> you like, provided you are willing to accept maximal  values for the fixed
>>> effects and sigma. If you wanted to plug those  values in as well, it's a
>>> bit of a pain but it can be done.
>>>
>>> Vince
>>>
>>> On Jul 17, 2014, at 11:41 AM, Christian Brauner
>>> <christianvanbrauner at gmail.com> wrote:
>>>
>>>> Hello,
>>>>
>>>> I am performing a priori power simulations for mixed-effect models based
>>>> on previous experiments. This works out quite nicely. I extract parts of
>>>> my parameters from a previous model I fitted:
>>>>
>>>> prev_mod <- lmer(Y ~ A
>>>>                  + (B | Context)
>>>>                  + (B | Subjects),
>>>>                  data =3D data)
>>>>
>>>> "A" :=3D 2 level factor
>>>> "Context" :=3D 40 level factor
>>>> "Subjects" :=3D 70 level factor
>>>>
>>>> create design matrices for the fixed- and each random effect use
>>>> functions from
>>>> the apply-family and bind them to a previously set-up data frame and so on.
>>>>
>>>> In order to simulate data I draw from two multivariate distributions. One
>>>> for Subjects and one for Context. I previously constructed the
>>>> variance-covariance matrix by using the estimations I get by issuing
>>>> "as.data.frame(prev_mod)". After having read that Doug implemented a new
>>>> method for the "getME()" extractor "Tlist" that gives the covariance
>>>> factors from which the block matrices in "Lambda" are created I figured I
>>>> could get the variance-covariance matrix way easier by doing (code here
>>>> only for the "Context" variance-covariance matrix):
>>>>
>>>> cov_fac <- getME(prev_mod, "Tlist")
>>>> cov_fac_context <- cov_fac$Context
>>>>
>>>> sigma(prev_mod)^2*cov_fac_context%*%t(cov_fac_context)
>>>>
>>>> But the question that has been haunting me for weeks now is how the
>>>> individual
>>>> covariance factors (better: "matrices" in this case) that I can extract via
>>>> "getME(prev_mod, "Tlist") are computed. Is there some literature on that?  I
>>>> couldn't find any apart from the paper "Fitting linear mixed-effects models
>>>> using lme4" published 23.06.2014. I would be interested in reading up/get an
>>>> explanation how the covariance factor can be computed (mathematically and in
>>>> lme4) and if I need the variance-covariance matrix beforehand or vica versa.
>>>>
>>>> Thank for any help!
>>>>
>>>> Best,
>>>> Christian Brauner
>>>> Eberhard Karls Universit=C3=A4t T=C3=BCbingen
>>>> Mathematisch-Naturwissenschaftliche Fakult=C3=A4t - Faculty of Science
>>>> Evolutionary Cognition - Cognitive Science
>>>> Schleichstra=C3=9Fe 4 =C2=B7 72076 T=C3=BCbingen =C2=B7 Germany
>>>> Telefon +49 7071 29-75643 =C2=B7 Telefax +49 7071 29-4721
>>>> christianvanbrauner at gmail.com
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From bbolker at gmail.com  Fri Jul 18 19:14:16 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 18 Jul 2014 13:14:16 -0400
Subject: [R-sig-ME] question about lme4
In-Reply-To: <CAA+UucUBQzrMgVMGHEJU_hbmcojNr54_TFe-G4V9VF4pyzoH4A@mail.gmail.com>
References: <2169_1405641008_s6HNo8Z7030338_CAA+UucWay_LN3xuE=x6Ut8WATkxEdSJoYqKqOiTFrn2pi1WztQ@mail.gmail.com>
	<53C88AA5.3040706@mcmaster.ca>
	<CAA+UucUBQzrMgVMGHEJU_hbmcojNr54_TFe-G4V9VF4pyzoH4A@mail.gmail.com>
Message-ID: <CABghstQUGTSusdqc6PW6RgvFi-YU8Bbp+c9xCdn_f00Lqg8Csg@mail.gmail.com>

On 14-07-18 10:32 AM, Leithen wrote:
> Hi Ben,
> Thank you for this. I hadn't seen it. Does this apply to 1.1-7 as well?
> --L

  [cc'ing r-sig-mixed-models]

  No, it doesn't; in 1.1-7 we have changed the tests so that it is
much more likely that reported convergence failures represent a real
problem rather than a false positive. They *might* still be false
positives, but for now we'd rather worry people while we figure out
how to tweak the messages so they're slightly less sensitive (but
still don't miss things that are real problems).

  Ben Bolker






>
>
> On Thu, Jul 17, 2014 at 7:47 PM, Ben Bolker <bbolker at gmail.com> wrote:
>
> On 14-07-17 07:49 PM, Leithen wrote:
>>>> Hi Ben,
>>>>
>>>> I am a post-doc at UC Berkeley (ecology and evolutionary biology)
>>>> and was hoping I could ask you a quick question. I use lme4 a fair
>>>> bit for my analyses and I recently upgraded to the latest version
>>>> of R and lme4. I am now finding that analyses which previously ran
>>>> without warnings are giving me convergence warnings when they
>>>> didn't before. E.g., this type of error:
>>>>
>>>> Warning message: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
>>>> control$checkConv,  : Model failed to converge with max|grad| =
>>>> 0.0119784 (tol = 0.001, component 3)
>>>>
>>>> I'm just wondering if you have an idea why? Have you updated lme4
>>>> so that it now prints out warnings more readily?
>>>>
>>>> Thank you for your help. I am at a bit of a loss for ideas why this
>>>> is happening. Cheers, --Leithen
>
>   Are you using version 1.1-6?  Have you looked at
> https://github.com/lme4/lme4/blob/master/README.md ?
>
>   cheers
>     Ben Bolker


From christianvanbrauner at gmail.com  Sat Jul 19 12:21:51 2014
From: christianvanbrauner at gmail.com (Christian Brauner)
Date: Sat, 19 Jul 2014 12:21:51 +0200
Subject: [R-sig-ME] How is the covariance factor computed?
In-Reply-To: <D25F189B-F962-41A8-8FEF-2C7D6DE8A1DB@nyu.edu>
References: <20140717154124.GA11106@gmail.com>
	<D25F189B-F962-41A8-8FEF-2C7D6DE8A1DB@nyu.edu>
Message-ID: <20140719102151.GA2179@gmail.com>

Thanks Ben!
Figured it out myself pretty quickly. Seems you also have to transpose:

t(chol(VarCorr(fm1)[[1]]/sigma(fm1))

if you want the representation to be identical to

"getME(fm1, "Tlist")[[1]]


Thanks again Vince, Steve and Ben!
(I really enjoyed reading the paper you guys wrote!)

On Thu, Jul 17, 2014 at 03:24:07PM -0400, Vincent Dorie wrote:
> I'm not sure if this answers your question, but the parameters of the variance/covariance matrix are stored in the theta slot of a merMod in a form such that they correspond to a Cholesky factorization of the individual components of the var/cov matrix of the random effects, with the diagonal in the first 'd' parts of the vector and the off-diagonal stored in column-major format in the next d * (d - 1) / 2 elements. Given a theta vector, to get to a representation such as that which Tlist gives requires knowing how to map the parameters to matrices. This is currently done by hand, using the knowledge that the cnms slot of a merMod contains the dimension of each grouping "factor"/"level" and the aforementioned Cholesky decomposition storage concept. In the future, however, if lme4 supports different forms of variance/covariances matrices for factors other than "full" (e.g. independent, or correlation only), then that knowledge will need to be referenced instead. I believe there is effort on that front in the "flexLambda" branch on github.
> 
> On the other hand, if you were asking where those numbers come from, it turns out that (at least for linear models) those parameters are sufficient to define a likelihood wherein the fixed effects and conditional error term (sigma) are analytically optimized. Since the goal is a maximum likelihood, or REML, the sigma parameters are then simply numerically optimized. You can then easily evaluate the mixed model likelihood at any value of the var/cov matrix of the random effects that you like, provided you are willing to accept maximal values for the fixed effects and sigma. If you wanted to plug those values in as well, it's a bit of a pain but it can be done.
> 
> Vince
> 
> On Jul 17, 2014, at 11:41 AM, Christian Brauner <christianvanbrauner at gmail.com> wrote:
> 
> > Hello,
> > 
> > I am performing a priori power simulations for mixed-effect models based
> > on previous experiments. This works out quite nicely. I extract parts of
> > my parameters from a previous model I fitted:
> > 
> > prev_mod <- lmer(Y ~ A
> >                   + (B | Context)
> >                   + (B | Subjects),
> >                   data =3D data)
> > 
> > "A" :=3D 2 level factor
> > "Context" :=3D 40 level factor
> > "Subjects" :=3D 70 level factor
> > 
> > create design matrices for the fixed- and each random effect use functions from
> > the apply-family and bind them to a previously set-up data frame and so on.
> > 
> > In order to simulate data I draw from two multivariate distributions. One
> > for Subjects and one for Context. I previously constructed the
> > variance-covariance matrix by using the estimations I get by issuing
> > "as.data.frame(prev_mod)". After having read that Doug implemented a new
> > method for the "getME()" extractor "Tlist" that gives the covariance
> > factors from which the block matrices in "Lambda" are created I figured I
> > could get the variance-covariance matrix way easier by doing (code here
> > only for the "Context" variance-covariance matrix):
> > 
> > cov_fac <- getME(prev_mod, "Tlist")
> > cov_fac_context <- cov_fac$Context
> > 
> > sigma(prev_mod)^2*cov_fac_context%*%t(cov_fac_context)
> > 
> > But the question that has been haunting me for weeks now is how the individual
> > covariance factors (better: "matrices" in this case) that I can extract via
> > "getME(prev_mod, "Tlist") are computed. Is there some literature on that?  I
> > couldn't find any apart from the paper "Fitting linear mixed-effects models
> > using lme4" published 23.06.2014. I would be interested in reading up/get an
> > explanation how the covariance factor can be computed (mathematically and in
> > lme4) and if I need the variance-covariance matrix beforehand or vica versa.
> > 
> > Thank for any help!
> > 
> > Best,
> > Christian Brauner
> > Eberhard Karls Universit=C3=A4t T=C3=BCbingen
> > Mathematisch-Naturwissenschaftliche Fakult=C3=A4t - Faculty of Science
> > Evolutionary Cognition - Cognitive Science
> > Schleichstra=C3=9Fe 4 =C2=B7 72076 T=C3=BCbingen =C2=B7 Germany
> > Telefon +49 7071 29-75643 =C2=B7 Telefax +49 7071 29-4721
> > christianvanbrauner at gmail.com
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 


From bbolker at gmail.com  Sun Jul 20 01:55:48 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 19 Jul 2014 23:55:48 +0000 (UTC)
Subject: [R-sig-ME] glmmADMB package
References: <CAGAKjUM82pOBQ_8ZFgb9CP=7nF2uHeqrM_hWjRWX7u0tSASMQA@mail.gmail.com>
Message-ID: <loom.20140720T015253-29@post.gmane.org>

Rajibul Mian <rajibulmian at ...> writes:

> 
> Dear All,
> 
> I have been facing problem running the following code by using
> ---glamADMB()--
> 
> glmmadmb(y_zibb~x+factor(z)+g, data= data_mis_model, family =
> "betabinomial", link = "logit", zeroInflation=T)
> 
> where "y_zibb" contains zero inflated Beta Binomial response ,
> "x" is a normal random variate
> "z" is a binomial random variate
> "g" is a exponential random variate
> 
> the error message----
> 
> Error in glmmadmb(y_zibb ~ x + factor(z) + g, data = data_mis, family =
> "betabinomial",  :
>   The function maximizer failed (couldn't find STD file) Troubleshooting
> steps include (1) run with 'save.dir' set and inspect output files; (2)
> change run parameters: see '?admbControl'
> In addition: Warning message:
> running command 'C:\Windows\system32\cmd.exe /c
> -maxfn 500 -maxph 5 -noinit -shess' had status 22
> 
> I have tried the  "change run parameters: see '?admbControl'" in different
> combinations but couldn't help.  I am giving part of the data with this
> mail.
> 

With the data you've given, it's hardly worth fitting the z component
(out of 100 values, only 4 are 1, the rest are zero -- very little
information here).

If you don't have any random effects, you don't really need
glmmADMB -- you can do the problem in pure R (although it might
be faster & more robust if you were able to get it working in
glmmADMB).

A little bit of exploration:

dd <- read.table("mian_mm.dat",header=TRUE)
library(ggplot2); theme_set(theme_bw())
ggplot(dd,aes(x,y_zibb))+geom_point(aes(colour=g),size=4, alpha=0.5)
ggplot(dd,aes(x,y_zibb))+geom_point(aes(colour=log10(g),shape=factor(z)),
                                    size=4, alpha=0.7)

The values of g are so restricted that I decided it might make
more sense to use log10(g) rather than g as a predictor variable
(unless you have some strong _a priori_ reason for using it on
the original scale).

with(dd,table(z))  ## only 4 '0' values
par(las=1,bty="l")
with(dd,hist(log10(g),col="gray"))


These fits both work OK:

library(emdbook)  ## for dbetabinom
library(bbmle)
## fit with NON-zero-inflated beta-binomial
(m1 <- mle2(y_zibb~dbetabinom(prob=plogis(eta),theta=exp(logtheta),
                       size=10),
     parameters=list(eta~log10(g)),
     start=list(eta=0,logtheta=0),
     data=dd))
## define zero-inflated version of dbetabinom
dzibb <- function(x,prob,size,theta,zprob,log=FALSE) {
    dd <- dbetabinom(x,prob=prob,size=size,theta=theta,log=FALSE)
    rr <- ifelse(x==0,zprob+(1-zprob)*dd,(1-zprob)*dd)
    if (log) log(rr) else rr
}
(m2 <- mle2(y_zibb~dzibb(prob=plogis(eta),
                         theta=exp(logtheta),
                         zprob=plogis(eta2),
                         size=10),
            parameters=list(eta~log10(g)),
            start=list(eta=0,logtheta=0,eta2=-3),
            data=dd))

> Any related suggestions would help. Thank you.
> 
> Best.
> Rajibul Mian
> Grad Student, Maths & STATS,
> UWindsor, Canada.
>


From annajess at gmx.de  Mon Jul 21 13:37:48 2014
From: annajess at gmx.de (Anna-Marie Corman)
Date: Mon, 21 Jul 2014 13:37:48 +0200
Subject: [R-sig-ME] LMM: including ranef or not?
In-Reply-To: <53CCFB0D.8020903@ftz-west.uni-kiel.de>
References: <53CCFB0D.8020903@ftz-west.uni-kiel.de>
Message-ID: <53CCFB8C.30502@gmx.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140721/ba1f007b/attachment.pl>

From annajess at gmx.de  Mon Jul 21 16:22:21 2014
From: annajess at gmx.de (Anna-Marie Corman)
Date: Mon, 21 Jul 2014 16:22:21 +0200
Subject: [R-sig-ME] LMM: including ranef or not?
In-Reply-To: <53CCFE5F.80407@nexs.ku.dk>
References: <53CCFB0D.8020903@ftz-west.uni-kiel.de> <53CCFB8C.30502@gmx.de>
	<53CCFE5F.80407@nexs.ku.dk>
Message-ID: <53CD221D.9020702@gmx.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140721/890512b0/attachment.pl>

From bates at stat.wisc.edu  Mon Jul 21 17:17:18 2014
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 21 Jul 2014 10:17:18 -0500
Subject: [R-sig-ME] lmer Control Parameters Question
In-Reply-To: <CAPqs5zV6677AK+UQkUPPSZXW5_pputwc4a6-pBAOprO68x-_1w@mail.gmail.com>
References: <CAPqs5zV6677AK+UQkUPPSZXW5_pputwc4a6-pBAOprO68x-_1w@mail.gmail.com>
Message-ID: <CAO7JsnSfiPy2AUd3-UJ0XPxu-wGeEDvWHRtAfKdoE_0BVhVVOw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140721/26a25c1e/attachment.pl>

From David.Duffy at qimr.edu.au  Mon Jul 21 23:07:10 2014
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Tue, 22 Jul 2014 07:07:10 +1000
Subject: [R-sig-ME] lmer Control Parameters Question
In-Reply-To: <CAO7JsnSfiPy2AUd3-UJ0XPxu-wGeEDvWHRtAfKdoE_0BVhVVOw@mail.gmail.com>
References: <CAPqs5zV6677AK+UQkUPPSZXW5_pputwc4a6-pBAOprO68x-_1w@mail.gmail.com>
	<CAO7JsnSfiPy2AUd3-UJ0XPxu-wGeEDvWHRtAfKdoE_0BVhVVOw@mail.gmail.com>
Message-ID: <alpine.LMD.2.00.1407220657160.19087@orpheus.qimr.edu.au>

On Tue, 22 Jul 2014, Douglas Bates wrote:

>> I am working with the latest version of lme4 and having a great deal of
>> difficulty specify control parameters (specifically, iterations and
>> convergence criteria).  I have been using variants of the following, with
>> no success:

The usable arguments in optCtrl vary according to which optimizer you have 
chosen:

glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
   family = binomial, data = cbpp,
   control=glmerControl(optimizer="Nelder_Mead",
                        optCtrl=list(FtolAbs = 1e-2, iprint=1),
                        boundary.tol = 1e-2))
load(optimx)
glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
   family = binomial, data = cbpp,
   control=glmerControl(optimizer="optimx",
                        optCtrl=list(method="nlminb", trace=1, kkt=FALSE),
                        boundary.tol = 1e-2))



| David Duffy (MBBS PhD)
| email: David.Duffy at qimrberghofer.edu.au  ph: INT+61+7+3362-0217 fax: -0101
| Genetic Epidemiology, QIMR Berghofer Institute of Medical Research
| 300 Herston Rd, Brisbane, Queensland 4006, Australia  GPG 4D0B994A


From bbolker at gmail.com  Mon Jul 21 23:24:51 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 21 Jul 2014 17:24:51 -0400
Subject: [R-sig-ME] LMM: including ranef or not?
In-Reply-To: <53CD221D.9020702@gmx.de>
References: <53CCFB0D.8020903@ftz-west.uni-kiel.de>
	<53CCFB8C.30502@gmx.de>	<53CCFE5F.80407@nexs.ku.dk>
	<53CD221D.9020702@gmx.de>
Message-ID: <53CD8523.7020301@gmail.com>


  If you're going to use ud95 as the response you might as well average
the prop_land values per bird (i.e., aggregate the data down to a single
data record per bird); the within-bird variation in prop_land values
won't affect the model output at all (although the _number_ of
observations per bird will; if you have unbalanced information in this
way, you should incorporate weights proportional to the number of
observations as well).

  With only 6 colonies you're going to have some difficulty estimating
the among-colony variance very well; if you end up with zero estimates
of among-colony variance, you might want to use blme or set the colonies
as fixed effects ...

  If you use prop_land as the response variable you would indeed want to
put bird_id in as a random effect (and you might consider estimating the
proportional as a binomial (GLMM) response, _if_ you know the total
number of fixes for each bird)

On 14-07-21 10:22 AM, Anna-Marie Corman wrote:
> Dear Christian,
> 
> thanks for your answer. So, including the ranef or not depends on the 
> response, doesn't it? If I tested the model the other way around 
> (prop_land~ud95...) I would have to include bird_id as ranef, because 
> there are more than one measurments for each bird, right?
> 
> Best,
> Anna
> 
> Am 21.07.2014 13:49, schrieb Christian Ritz:
>> Dear Anna,
>>
>> no, with only one measurement per bird there is no need for a 
>> bird-specific random effect.
>>
>> Your model looks okay to me.
>>
>> Best wishes Christian
>>
>>
>> On 21-07-2014 13:37, Anna-Marie Corman wrote:
>>> Dear list,
>>>
>>> I want to test whether the UD sizes of several tracked seabird
>>> individuals from 6 different breeding  colonies depends on the foraging
>>> target (on land or at sea) as  follows:
>>>
>>> mod<-lmer(ud95~prop_land+(1|colony),data=dat);
>>>
>>> I have one UD95 value for each individual, but the proportion of fixes
>>> on land are on a trip basis, i.e. several values for one individual. Do
>>> I need to include bird_id as random factor to exclude pseudo
>>> replication, though the response has only one value per individual???
>>>
>>> Many thanks in advance.
>>>
>>> Best,
>>> Anna
>>>
>>> data:
>>>
>>>      bird_id colony FT_id year sex max_speed max_distnest  tot_dist       tdur mean_dist mean_distnest
>>> 1 HA1_2012  Amrum     1 2012   1  53.65358    36.008004 101.34099  7.5827778 0.4444780     15.867350
>>> 2 HA1_2012  Amrum     2 2012   1  63.88851    69.993403 149.00254  6.1788889 0.8186953     46.947190
>>> 3 HA1_2012  Amrum     3 2012   1  82.68318    70.532407 176.65181  7.7008333 0.7886241     48.160436
>>> 4 HA1_2012  Amrum     4 2012   1  56.25961     5.293994  15.11632  0.8130556 0.6298466      3.710259
>>> 5 HA1_2012  Amrum     5 2012   1  70.04150    71.002162 215.32017 12.6369444 0.5851092     42.360905
>>> 6 HA1_2012  Amrum     6 2012   1  71.40167    71.712123 213.43533 12.1355556 0.5995374     54.878232
>>>     mean_speed  prop_sea   prop_land straightness   prop_day prop_night ft_start ft_start_s   ft_end ft_end_s
>>> 1   13.01700 0.9912664 0.008733624    0.3553153 0.08296943  0.9170306 21:34:09      77649 05:11:03    18663
>>> 2   25.24134 0.2786885 0.721311500    0.4697464 1.00000000  0.0000000 06:47:53      24473 13:00:35    46835
>>> 3   26.50082 0.1644444 0.835555600    0.3992736 0.92888890  0.0711111 04:28:00      16080 12:12:06    43926
>>> 4   22.27650 0.8000000 0.200000000    0.3502171 0.24000000  0.7600000 04:21:24      15684 05:12:12    18732
>>> 5   19.70902 0.3821138 0.617886200    0.3297516 0.84552850  0.1544715 03:05:05      11105 15:45:16    56716
>>> 6   22.07548 0.2997199 0.700280100    0.3359899 0.91596640  0.0840336 04:02:14      14534 16:12:19    58339
>>>
>>>       ud95 ud50 id30  rd30 udoi50_colmean udoi95_colmean idoi30_colmean rdoi30_colmean
>>> 1 460.73 9.76 24.8 64.16          0.002         0.0985          1e-04         0.0059
>>> 2 460.73 9.76 24.8 64.16          0.002         0.0985          1e-04         0.0059
>>> 3 460.73 9.76 24.8 64.16          0.002         0.0985          1e-04         0.0059
>>> 4 460.73 9.76 24.8 64.16          0.002         0.0985          1e-04         0.0059
>>> 5 460.73 9.76 24.8 64.16          0.002         0.0985          1e-04         0.0059
>>> 6 460.73 9.76 24.8 64.16          0.002         0.0985          1e-04         0.0059
>>>
>>>
>>>
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org  mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From marklhc at gmail.com  Tue Jul 22 06:11:12 2014
From: marklhc at gmail.com (Mark Lai)
Date: Mon, 21 Jul 2014 23:11:12 -0500
Subject: [R-sig-ME]  Question on semiparametric bootstrap in lme4
Message-ID: <53CDE460.7030907@gmail.com>

Hi,

I have a question on the semiparametric bootstrap result for lme4. 
Specifically, the bootstrap standard deviation for the fixed effect is 
essentially zero. Here is an example:

 > require(lme4)
 > fm01 <- lmer(Yield ~ 1|Batch, Dyestuff)
 > set.seed(1)
 > require(boot)
 > boo01_sp <- bootMer(fm01, fixef, nsim = 100, use.u = TRUE,
+                  type = "semiparametric")
 > boo01_sp


Call:
bootMer(x = fm01, FUN = fixef, nsim = 100, use.u = TRUE, type = 
"semiparametric")


Bootstrap Statistics :
     original       bias     std. error
t1*   1527.5 9.094947e-13 1.392467e-12

Then I took a look on the source code for the function `bootMer`, and 
found the relevant code:

if (type == "parametric") {
         ss <- simulate(x, nsim = nsim, use.u = use.u, na.action = 
na.exclude)
     }
     else {
         if (use.u) {
             if (isGLMM(x))
                 warning("semiparametric bootstrapping is questionable 
for GLMMs")
             ss <- replicate(nsim, fitted(x) + sample(residuals(x,
                 "response")), simplify = FALSE)
         }
         else {
             stop("semiparametric bootstrapping with use.u=FALSE not yet 
implemented")
         }
     }

I notice that the semiparametric method is using sampling without 
replacement (i.e., `sample(residuals(x, "response"))`, which is 
different from what I learned about bootstrap. Should the `replace = 
TRUE` argument be added?

Mark


From annajess at gmx.de  Tue Jul 22 08:55:44 2014
From: annajess at gmx.de (Anna-Marie Corman)
Date: Tue, 22 Jul 2014 08:55:44 +0200
Subject: [R-sig-ME] LMM: including ranef or not?
In-Reply-To: <53CD8523.7020301@gmail.com>
References: <53CCFB0D.8020903@ftz-west.uni-kiel.de>	<53CCFB8C.30502@gmx.de>	<53CCFE5F.80407@nexs.ku.dk>	<53CD221D.9020702@gmx.de>
	<53CD8523.7020301@gmail.com>
Message-ID: <53CE0AF0.5010808@gmx.de>

Dear Ben and Christian,

thanks again for your help! I know the number of fixes per bird, though 
my dataset is on a trip basis. All individuals made a different number 
of trips during the study period.

I will try this out.

Best,
Anna

Am 21.07.2014 23:24, schrieb Ben Bolker:
>    If you're going to use ud95 as the response you might as well average
> the prop_land values per bird (i.e., aggregate the data down to a single
> data record per bird); the within-bird variation in prop_land values
> won't affect the model output at all (although the _number_ of
> observations per bird will; if you have unbalanced information in this
> way, you should incorporate weights proportional to the number of
> observations as well).
>
>    With only 6 colonies you're going to have some difficulty estimating
> the among-colony variance very well; if you end up with zero estimates
> of among-colony variance, you might want to use blme or set the colonies
> as fixed effects ...
>
>    If you use prop_land as the response variable you would indeed want to
> put bird_id in as a random effect (and you might consider estimating the
> proportional as a binomial (GLMM) response, _if_ you know the total
> number of fixes for each bird)
>
>


From marcoplebani85 at gmail.com  Tue Jul 22 14:22:26 2014
From: marcoplebani85 at gmail.com (Marco Plebani)
Date: Tue, 22 Jul 2014 14:22:26 +0200
Subject: [R-sig-ME] Mixed effect models for a study with no (real)
	replication
Message-ID: <3A1E8A8D-994A-47B5-A7D9-2A4223DE4D4A@gmail.com>

Dear list members,

I am analyzing the effects of temperature on species richness across a natural temperature gradient. The study is based on 13 streams, each at a different temperature; for each stream I have measures of species richness obtained from three samples i.e. 39 data points in total.
I expect the observed variability to be due to four possible sources, three of which are discernible:
- differences AMONG streams due to temperature,
- differences AMONG streams not due to temperature (e.g. due to other environmental factors not accounted for in the study),
- differences WITHIN streams (due to either natural heterogeneity and/or the observation process, indiscernible without having multiple measures for each sample).

I should point out that ?temperature? is coded as a continuous variable while ? Stream.ID? is a factor (I did this for clarity; I could have used ?temperature? as both fixef and ranef).
A very similar issue has been discussed recently (https://stat.ethz.ch/pipermail/r-sig-mixed-models/2014q3/022365.html, ?Same variable as both fixed and random") so I fitted the following model:

glmer(species.richness ~ temperature + (1 | Stream.ID), data=dd, family=poisson)

I tested the above-mentioned model on simulated data obtained as follows (see script at the end of this message):

species.richness = a * exp(b* temperature * epsilon1 * epsilon2)

Where epsilon1 adds variability AMONG streams not explained by temperature, and epsilon2 adds variability WITHIN streams.
The estimates of parameters a and b are coherent with the parameters of the simulation, but the st.dev estimates due to Stream.ID are often far off (somewhere between the actual st.dev due to Stream ID and the residual st.dev)  and often touching zero (when the simulated st.dev due to Stream ID and the residual st.dev are similar).
Why does that happen? Here: https://stat.ethz.ch/pipermail/r-sig-mixed-models/2014q3/022386.html (?LMM: including ranef or not??) Ben Bolker foresees such an issue when the ranef has only few levels and suggests to use blme to fix the problem. I tried; blme still confounds the st.dev due to Stream ID and the residual st.dev when the latter is much higher then the former, but it does succeed in reducing the estimate of false zeroes for the st.dev of Stream ID when st.dev(Stream.ID)~st.dev(residual) and both <1.
Why blme is better than lme4 in detecting the st.dev of the ranef ?Stream.ID? when it is small?
My familiarity with Bayesian stats is limited to studying Bayes?s theorem as an undergrad, so to be honest I have no idea what?s going on ?inside? blme.

Thank you very much in advance for any help provided.
Cheers,

Marco

-----
Marco Plebani
Institute of Evolutionary Biology and Environmental Studies
University of Zurich
http://www.ieu.uzh.ch/staff/phd/plebani.html





###################################
###################################
# Marco Plebani, July 17th 2014
# Given a study based on 13 streams at 13 different temperatures, sampled 3 times each for species richness and total biomass, is it possible to discern the temperature effect on species richness and total biomass from the effect of variability among streams not due to temperature?
# Note that the multiple samples are PSEUDO-replicates and that there is complete temperature=stream identity.
###################################
###################################

rm(list=ls())
library(lme4)
library(blme)
#set.seed(2)

# Simulate data based on the observed temperature effect.
# the model is:

# y = a * exp(b*x) + epsilon

#a, i.e. species richness at 0?C, is set at 13
# b is set at -0.07

# epsilon is the sum of:
# epsilon1 due to variability AMONG streams not explained by temperature,
# epsilon2 due to variability WITHIN streams (i.e. residual variuability, made up by both the streams natural heterogeneity and the sampling error)

# create empty vectors where to save estimates for the sd due to Stream ID, and the p-val of parameter "b" (see model above):

stream.ID.stdev<-rep(NA,50)
stream.ID.stdev.bayes<-rep(NA,50)
model.significance<-rep(NA,50)

# create the dataset:

reps <- 1:3
Stream.ID <- letters[1:13]
temperature <- seq(5,20, length.out=13)
rr <- expand.grid(Stream.ID = Stream.ID, reps=reps)
rr$temperature = rep(temperature,3)

## predicted species richness for the observed temperature:
rr$pred.rich <- 13 * exp(-0.07 * rr$temperature) # a and b values are realistic estimates

# continuous prediction: 
temp=seq(0,22,0.1)
pred.richness <- 13 * exp(-0.07 * temp)

par(mfrow=c(1,3))
plot(x= temp, y= pred.richness, xlim=c(0,23), ylim=c(0, 15), type="l")

# run the analysis on 50 datasets drawn from the same distribution:

for(i in 1:50){

## epsilon1: stream.ID effect
stream.eff <- data.frame(Stream.ID = rr$Stream.ID,
						effect=rnorm(n=length(Stream.ID), mean=0, sd=0.2))
# add epsilon1 to the dataset						
rr$epsilon1 <- stream.eff$effect[match(rr$Stream.ID, stream.eff$Stream.ID)]

## epsilon2: residual variability within streams
rr$epsilon2 <-  rnorm(length(rr$temperature), mean=0, sd=0.2)

# pred.richness accounting for epsilon1
rr$pred.rich_e1 <- 13 * exp(-0.07 * rr$temperature) * exp(rr$epsilon1)

# pred.richness accounting for epsilon1 and epsilon2				
rr$pred.rich_e1_e2 <- round(13 * exp(-0.07 * rr$temperature) * exp(rr$epsilon1) * exp(rr$epsilon2))
# rounded to the closest integer
							
points(x= rr$temperature, y= rr$pred.rich_e1, pch=8, cex=1)
#points(x= rr$temperature, y= rr$pred.rich_e1_e2, cex=1.5)
# solid line represents predicted mean richness
# *'s represent predicted mean richness + epsilon1
# circles represent predicted mean richness + epsilon1 + epsilon2, i.e. the observations from each sample

# glmm:

richness.glmm <- glmer(pred.rich_e1_e2 ~ temperature + (1|Stream.ID), data=rr, family=poisson)
# "pred.rich_e1_e2" is the observed richness in each sample.
richness.glmm.bayes <- bglmer(pred.rich_e1_e2 ~ temperature + (1|Stream.ID), data=rr, family=poisson)

stream.ID.stdev[i] <- as.numeric(attributes(summary(richness.glmm)$varcor[[1]])$stddev)
stream.ID.stdev.bayes[i] <- as.numeric(attributes(summary(richness.glmm.bayes)$varcor[[1]])$stddev)
model.significance[i] <- ifelse(summary(richness.glmm)$coefficients[2,4]<0.05,1,0)
# library(MuMIn) # estimates pseudo-R^2 for MEM.
# r.squaredGLMM(richness.glmm)

}

hist(stream.ID.stdev)
abline(v=mean(stream.ID.stdev), col="red",lwd=2)
legend("topright",title=paste("mean=", round(mean(stream.ID.stdev),2), "; sd=", round(sd(stream.ID.stdev),2)), legend=c(NA))

hist(stream.ID.stdev.bayes)
abline(v=mean(stream.ID.stdev.bayes), col="red",lwd=2)
legend("topright",title=paste("mean=", round(mean(stream.ID.stdev.bayes),2), "; sd=", round(sd(stream.ID.stdev.bayes),2)), legend=c(NA))

# end

From bbolker at gmail.com  Tue Jul 22 15:49:05 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 22 Jul 2014 09:49:05 -0400
Subject: [R-sig-ME] Question on semiparametric bootstrap in lme4
In-Reply-To: <53CDE460.7030907@gmail.com>
References: <53CDE460.7030907@gmail.com>
Message-ID: <53CE6BD1.2000403@gmail.com>

  Yes, that does look like a bug.  Thanks!  (Interesting that the
bootstrap std dev is about half the size of the parametric std error ...
qqmath(fm01) shows that the distribution of residuals is indeed thin-tailed.

  Fixed on Github (testing now ...)

  Ben Bolker

On 14-07-22 12:11 AM, Mark Lai wrote:
> Hi,
> 
> I have a question on the semiparametric bootstrap result for lme4.
> Specifically, the bootstrap standard deviation for the fixed effect is
> essentially zero. Here is an example:
> 
>> require(lme4)
>> fm01 <- lmer(Yield ~ 1|Batch, Dyestuff)
>> set.seed(1)
>> require(boot)
>> boo01_sp <- bootMer(fm01, fixef, nsim = 100, use.u = TRUE,
> +                  type = "semiparametric")
>> boo01_sp
> 
> 
> Call:
> bootMer(x = fm01, FUN = fixef, nsim = 100, use.u = TRUE, type =
> "semiparametric")
> 
> 
> Bootstrap Statistics :
>     original       bias     std. error
> t1*   1527.5 9.094947e-13 1.392467e-12
> 
> Then I took a look on the source code for the function `bootMer`, and
> found the relevant code:
> 
> if (type == "parametric") {
>         ss <- simulate(x, nsim = nsim, use.u = use.u, na.action =
> na.exclude)
>     }
>     else {
>         if (use.u) {
>             if (isGLMM(x))
>                 warning("semiparametric bootstrapping is questionable
> for GLMMs")
>             ss <- replicate(nsim, fitted(x) + sample(residuals(x,
>                 "response")), simplify = FALSE)
>         }
>         else {
>             stop("semiparametric bootstrapping with use.u=FALSE not yet
> implemented")
>         }
>     }
> 
> I notice that the semiparametric method is using sampling without
> replacement (i.e., `sample(residuals(x, "response"))`, which is
> different from what I learned about bootstrap. Should the `replace =
> TRUE` argument be added?
> 
> Mark
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From Thierry.ONKELINX at inbo.be  Tue Jul 22 15:57:30 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 22 Jul 2014 13:57:30 +0000
Subject: [R-sig-ME] Mixed effect models for a study with no
	(real)	replication
In-Reply-To: <3A1E8A8D-994A-47B5-A7D9-2A4223DE4D4A@gmail.com>
References: <3A1E8A8D-994A-47B5-A7D9-2A4223DE4D4A@gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3AC33D1@inbomail.inbo.be>

Dear Marco,

You are simulating underdispersed data by rounding the expected values. Use rpois() instead of round() and you will get more sensible results.

rr$pred.rich_e1_e2 <- rpois(nrow(rr), lambda = 13 * exp(-0.07 * rr$temperature) * exp(rr$epsilon1) * exp(rr$epsilon2)) # rounded to the closest integer

I find it easier to generate all expected values on the log scale.

rr$mu <- log(13) - 0.07 * rr$temperature + rr$epsilon1 + rr$epsilon2
rr$pred.rich_e1_e2 <- rpois(nrow(rr), lambda = exp(rr$mu))

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Marco Plebani
Verzonden: dinsdag 22 juli 2014 14:22
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Mixed effect models for a study with no (real) replication

Dear list members,

I am analyzing the effects of temperature on species richness across a natural temperature gradient. The study is based on 13 streams, each at a different temperature; for each stream I have measures of species richness obtained from three samples i.e. 39 data points in total.
I expect the observed variability to be due to four possible sources, three of which are discernible:
- differences AMONG streams due to temperature,
- differences AMONG streams not due to temperature (e.g. due to other environmental factors not accounted for in the study),
- differences WITHIN streams (due to either natural heterogeneity and/or the observation process, indiscernible without having multiple measures for each sample).

I should point out that "temperature" is coded as a continuous variable while " Stream.ID" is a factor (I did this for clarity; I could have used "temperature" as both fixef and ranef).
A very similar issue has been discussed recently (https://stat.ethz.ch/pipermail/r-sig-mixed-models/2014q3/022365.html, "Same variable as both fixed and random") so I fitted the following model:

glmer(species.richness ~ temperature + (1 | Stream.ID), data=dd, family=poisson)

I tested the above-mentioned model on simulated data obtained as follows (see script at the end of this message):

species.richness = a * exp(b* temperature * epsilon1 * epsilon2)

Where epsilon1 adds variability AMONG streams not explained by temperature, and epsilon2 adds variability WITHIN streams.
The estimates of parameters a and b are coherent with the parameters of the simulation, but the st.dev estimates due to Stream.ID are often far off (somewhere between the actual st.dev due to Stream ID and the residual st.dev)  and often touching zero (when the simulated st.dev due to Stream ID and the residual st.dev are similar).
Why does that happen? Here: https://stat.ethz.ch/pipermail/r-sig-mixed-models/2014q3/022386.html ("LMM: including ranef or not?") Ben Bolker foresees such an issue when the ranef has only few levels and suggests to use blme to fix the problem. I tried; blme still confounds the st.dev due to Stream ID and the residual st.dev when the latter is much higher then the former, but it does succeed in reducing the estimate of false zeroes for the st.dev of Stream ID when st.dev(Stream.ID)~st.dev(residual) and both <1.
Why blme is better than lme4 in detecting the st.dev of the ranef "Stream.ID" when it is small?
My familiarity with Bayesian stats is limited to studying Bayes's theorem as an undergrad, so to be honest I have no idea what's going on "inside" blme.

Thank you very much in advance for any help provided.
Cheers,

Marco

-----
Marco Plebani
Institute of Evolutionary Biology and Environmental Studies University of Zurich http://www.ieu.uzh.ch/staff/phd/plebani.html





###################################
###################################
# Marco Plebani, July 17th 2014
# Given a study based on 13 streams at 13 different temperatures, sampled 3 times each for species richness and total biomass, is it possible to discern the temperature effect on species richness and total biomass from the effect of variability among streams not due to temperature?
# Note that the multiple samples are PSEUDO-replicates and that there is complete temperature=stream identity.
###################################
###################################

rm(list=ls())
library(lme4)
library(blme)
#set.seed(2)

# Simulate data based on the observed temperature effect.
# the model is:

# y = a * exp(b*x) + epsilon

#a, i.e. species richness at 0?C, is set at 13 # b is set at -0.07

# epsilon is the sum of:
# epsilon1 due to variability AMONG streams not explained by temperature, # epsilon2 due to variability WITHIN streams (i.e. residual variuability, made up by both the streams natural heterogeneity and the sampling error)

# create empty vectors where to save estimates for the sd due to Stream ID, and the p-val of parameter "b" (see model above):

stream.ID.stdev<-rep(NA,50)
stream.ID.stdev.bayes<-rep(NA,50)
model.significance<-rep(NA,50)

# create the dataset:

reps <- 1:3
Stream.ID <- letters[1:13]
temperature <- seq(5,20, length.out=13)
rr <- expand.grid(Stream.ID = Stream.ID, reps=reps) rr$temperature = rep(temperature,3)

## predicted species richness for the observed temperature:
rr$pred.rich <- 13 * exp(-0.07 * rr$temperature) # a and b values are realistic estimates

# continuous prediction:
temp=seq(0,22,0.1)
pred.richness <- 13 * exp(-0.07 * temp)

par(mfrow=c(1,3))
plot(x= temp, y= pred.richness, xlim=c(0,23), ylim=c(0, 15), type="l")

# run the analysis on 50 datasets drawn from the same distribution:

for(i in 1:50){

## epsilon1: stream.ID effect
stream.eff <- data.frame(Stream.ID = rr$Stream.ID,
                                                effect=rnorm(n=length(Stream.ID), mean=0, sd=0.2))
# add epsilon1 to the dataset
rr$epsilon1 <- stream.eff$effect[match(rr$Stream.ID, stream.eff$Stream.ID)]

## epsilon2: residual variability within streams
rr$epsilon2 <-  rnorm(length(rr$temperature), mean=0, sd=0.2)

# pred.richness accounting for epsilon1
rr$pred.rich_e1 <- 13 * exp(-0.07 * rr$temperature) * exp(rr$epsilon1)

# pred.richness accounting for epsilon1 and epsilon2
rr$pred.rich_e1_e2 <- round(13 * exp(-0.07 * rr$temperature) * exp(rr$epsilon1) * exp(rr$epsilon2)) # rounded to the closest integer

points(x= rr$temperature, y= rr$pred.rich_e1, pch=8, cex=1) #points(x= rr$temperature, y= rr$pred.rich_e1_e2, cex=1.5) # solid line represents predicted mean richness # *'s represent predicted mean richness + epsilon1 # circles represent predicted mean richness + epsilon1 + epsilon2, i.e. the observations from each sample

# glmm:

richness.glmm <- glmer(pred.rich_e1_e2 ~ temperature + (1|Stream.ID), data=rr, family=poisson) # "pred.rich_e1_e2" is the observed richness in each sample.
richness.glmm.bayes <- bglmer(pred.rich_e1_e2 ~ temperature + (1|Stream.ID), data=rr, family=poisson)

stream.ID.stdev[i] <- as.numeric(attributes(summary(richness.glmm)$varcor[[1]])$stddev)
stream.ID.stdev.bayes[i] <- as.numeric(attributes(summary(richness.glmm.bayes)$varcor[[1]])$stddev)
model.significance[i] <- ifelse(summary(richness.glmm)$coefficients[2,4]<0.05,1,0)
# library(MuMIn) # estimates pseudo-R^2 for MEM.
# r.squaredGLMM(richness.glmm)

}

hist(stream.ID.stdev)
abline(v=mean(stream.ID.stdev), col="red",lwd=2) legend("topright",title=paste("mean=", round(mean(stream.ID.stdev),2), "; sd=", round(sd(stream.ID.stdev),2)), legend=c(NA))

hist(stream.ID.stdev.bayes)
abline(v=mean(stream.ID.stdev.bayes), col="red",lwd=2) legend("topright",title=paste("mean=", round(mean(stream.ID.stdev.bayes),2), "; sd=", round(sd(stream.ID.stdev.bayes),2)), legend=c(NA))

# end
_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From leithen at gmail.com  Mon Jul 21 23:14:09 2014
From: leithen at gmail.com (Leithen)
Date: Mon, 21 Jul 2014 17:14:09 -0400
Subject: [R-sig-ME] question about lme4
In-Reply-To: <CABghstQUGTSusdqc6PW6RgvFi-YU8Bbp+c9xCdn_f00Lqg8Csg@mail.gmail.com>
References: <2169_1405641008_s6HNo8Z7030338_CAA+UucWay_LN3xuE=x6Ut8WATkxEdSJoYqKqOiTFrn2pi1WztQ@mail.gmail.com>
	<53C88AA5.3040706@mcmaster.ca>
	<CAA+UucUBQzrMgVMGHEJU_hbmcojNr54_TFe-G4V9VF4pyzoH4A@mail.gmail.com>
	<CABghstQUGTSusdqc6PW6RgvFi-YU8Bbp+c9xCdn_f00Lqg8Csg@mail.gmail.com>
Message-ID: <CAA+UucWsxmzJ-pOccPwsZrUyHVbdL7M9QvXVsp5V+TBXM_9Tew@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140721/2cbe7cf4/attachment.pl>

From ravi.varadhan at jhu.edu  Tue Jul 22 17:40:05 2014
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Tue, 22 Jul 2014 15:40:05 +0000
Subject: [R-sig-ME] Error in Profile likelihood based confidence intervals
	in glmer()
Message-ID: <2F9EA67EF9AE1C48A147CB41BE2E15C3124400D0@DOM-EB-MAIL2.win.ad.jhu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140722/0afa02a3/attachment.pl>

From bbolker at gmail.com  Tue Jul 22 20:55:55 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 22 Jul 2014 14:55:55 -0400
Subject: [R-sig-ME] Error in Profile likelihood based confidence
	intervals in glmer()
In-Reply-To: <2F9EA67EF9AE1C48A147CB41BE2E15C3124400D0@DOM-EB-MAIL2.win.ad.jhu.edu>
References: <2F9EA67EF9AE1C48A147CB41BE2E15C3124400D0@DOM-EB-MAIL2.win.ad.jhu.edu>
Message-ID: <53CEB3BB.2080203@gmail.com>


  I should add this to the "troubleshooting" page, but:

* There's in principle no problem at all with profiling models with
multiple random effects (other than that it's likely to be slow)
* The error message indicates that during profiling, the optimizer found
a fitted value that was significantly better (as characterized by the
'devtol' parameter) than the supposed minimum-deviance solution returned
in the first place.  You can boost the 'devtol' parameter (which is
currently set at a conservative 1e-9 ...) if you want to ignore this --
however, the non-monotonic profiles are also warning you that something
may be wonky with the profile.  It should (???) be possible to capture
the new/improved parameters that were found (although I don't know if
this is implemented in profile.merMod; I may have done it for bbmle but
not for lme4).
* the 'slice2D' methods in the bbmle package (see e.g.
http://rpubs.com/bbolker/22607 ) may be useful for exploring the
likelihood surface.

On 14-07-22 11:40 AM, Ravi Varadhan wrote:
> Hi,
> 
> I have longitudinal binary responses from a clinical trial. I am fitting
> the following random effects model in lme4::glmer.  The model is
> estimated without any problems.  However, I get an error when I try to
> compute the confidence intervals using the profile likelihood.  Does not
> the profiling approach work for more than one random effect?  Can
> someone point  out the problem?
> 
> Thanks,
> 
> Ravi
> 
>  
> 
> summary(mod2 <- glmer(imps79b ~ tx + sweek + (sweek|id), data=schiz,
> family=binomial))
> 
>  
> 
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) ['glmerMod']
> 
> Family: binomial  ( logit )
> 
> Formula: imps79b ~ tx + sweek + (sweek | id)
> 
>    Data: schiz
> 
>  
> 
>      AIC      BIC   logLik deviance df.resid
> 
>   1259.4   1291.7   -623.7   1247.4     1597
> 
>  
> 
> Scaled residuals:
> 
>      Min       1Q   Median       3Q      Max
> 
> -3.03973  0.00912  0.04957  0.21372  1.45395
> 
>  
> 
> Random effects:
> 
> Groups Name        Variance Std.Dev. Corr
> 
>  id     (Intercept) 13.993   3.741        
> 
>         sweek        4.093   2.023    -0.65
> 
> Number of obs: 1603, groups:  id, 437
> 
>  
> 
> Fixed effects:
> 
>             Estimate Std. Error z value Pr(>|z|)   
> 
> (Intercept)   9.1994     1.3105   7.020 2.22e-12 ***
> 
> tx           -2.5075     0.5996  -4.182 2.89e-05 ***
> 
> sweek        -3.1344     0.4503  -6.960 3.40e-12 ***
> 
> ---
> 
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
>  
> 
> Correlation of Fixed Effects:
> 
>       (Intr) tx    
> 
> tx    -0.786      
> 
> sweek -0.922  0.537
> 
>> 
> 
>  
> 
> # profiled confidence intervals
> 
>> confint(mod2, method="profile")
> 
> Computing profile confidence intervals ...
> 
> Error in zetafun(np, ns) : profiling detected new, lower deviance
> 
> In addition: Warning messages:
> 
> 1: In profile.merMod(object, signames = oldNames, ...) :
> 
>   non-monotonic profile
> 
> 2: In profile.merMod(object, signames = oldNames, ...) :
> 
>   non-monotonic profile
> 
>> 
> 
>  
> 
>  
> 
> Ravi Varadhan, Ph.D. (Environmental Eng.), Ph.D. (Biostatistics)
> 
> Associate Professor,
> 
> Division of Geriatric Medicine & Gerontology
> 
> School of Medicine,
> 
> Johns Hopkins University
> 
> Ph: 410-502-2619
> 
> Email: ravi.varadhan at jhu.edu <mailto:ravi.varadhan at jhu.edu>
> 
> http://www.jhsph.edu/research/centers-and-institutes/johns-hopkins-center-on-aging-and-health/people/Faculty_personal_Pages/Varadhan.html
> 
> 
>  
>


From T.Pennell at sussex.ac.uk  Wed Jul 23 12:16:50 2014
From: T.Pennell at sussex.ac.uk (Tanya Pennell)
Date: Wed, 23 Jul 2014 10:16:50 +0000
Subject: [R-sig-ME] MCMCglmm prior specification
Message-ID: <C11D7BD4-D1D8-4C36-944C-5407670BB1BC@sussex.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140723/25273bc6/attachment.pl>

From christianvanbrauner at gmail.com  Wed Jul 23 17:44:34 2014
From: christianvanbrauner at gmail.com (Christian Brauner)
Date: Wed, 23 Jul 2014 17:44:34 +0200
Subject: [R-sig-ME] Install flexlambda- and master-lme4 from Github
Message-ID: <20140723154433.GA5351@gmail.com>

Hello,

is it possible to install the flexlambda and master branch of lme4 at the
same time:

library(devtools)
install_github("lme4", "lme4")
install_github("lme4", "flexlambda")

such that I can load them as different packages. (Obviously not both at the
same time but for example in two different sessions; using "lme4" in one
and "flexlambda" in the other)?

Best,
Christian

Eberhard Karls Universit?t T?bingen
Mathematisch-Naturwissenschaftliche Fakult?t - Faculty of Science
Evolutionary Cognition - Cognitive Science
Schleichstra?e 4 ? 72076 T?bingen ? Germany
Telefon +49 7071 29-75643 ? Telefax +49 7071 29-4721
christian.brauner at uni-tuebingen.de


From omssmo at hotmail.com  Wed Jul 23 20:02:45 2014
From: omssmo at hotmail.com (Ofer Agai)
Date: Wed, 23 Jul 2014 11:02:45 -0700
Subject: [R-sig-ME] Mixed-effects Model - LMER - Plot of estimated Mean and
	CI
Message-ID: <BLU171-W5790E215A162419391287CCFFE0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140723/2e0a6ce8/attachment.pl>

From clelia.gasparini at uwa.edu.au  Wed Jul 23 18:36:25 2014
From: clelia.gasparini at uwa.edu.au (Clelia Gasparini)
Date: Thu, 24 Jul 2014 00:36:25 +0800
Subject: [R-sig-ME] glmer z values binomial data
In-Reply-To: <53CFDEDF.9040008@gmail.com>
References: <6B87DE513C3AC945ACFE067E1BC879615CE9E4024D@IS-WIN-375.staffad.uwa.edu.au>,
	<53CFDAE1.6000202@gmail.com>
	<6B87DE513C3AC945ACFE067E1BC879615CE9E40251@IS-WIN-375.staffad.uwa.edu.au>,
	<53CFDEDF.9040008@gmail.com>
Message-ID: <6B87DE513C3AC945ACFE067E1BC879615CE9E40253@IS-WIN-375.staffad.uwa.edu.au>


Hi

I'm using glmer (lme4) to analyse binomial data. I have used observation level to account for overdispersion.
My problem is that a referee asked to get wald t or F instead of wald Z mentioning Bolker's review in TREE 2008.

Can you suggest a way to get t or F instead of z in the output?


this is the code I'm using now:

y=cbind(data$Success,data$Failure) 
glmer.r<-glmer(y~ treat  + (1|obs), data=data, family=binomial(logit), weights =total.size) 
summary(glmer.r)

Many thanks in advance, 
Clelia 


From bbolker at gmail.com  Wed Jul 23 21:05:41 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 23 Jul 2014 15:05:41 -0400
Subject: [R-sig-ME] Providing starting values for glmer()
In-Reply-To: <2F9EA67EF9AE1C48A147CB41BE2E15C31244139C@DOM-EB-MAIL2.win.ad.jhu.edu>
References: <2F9EA67EF9AE1C48A147CB41BE2E15C31244139C@DOM-EB-MAIL2.win.ad.jhu.edu>
Message-ID: <53D00785.6010709@gmail.com>

On 14-07-23 02:18 PM, Ravi Varadhan wrote:
> Dear Ben,
> 
> I would appreciate your help with one more question.  How would I 
> provide starting values to glmer()?  I know it is supposed to be a
> named list, but I don?t know what the names are supposed to be.

 [cc'ing to r-sig-mixed models]

  In the grand tradition of R help pages, I think the definition of
'start' in the ?glmer page is technically correct if somewhat opaque.
Short answer: the names should be 'theta' and/or 'fixef'.


 start: a named list of starting values for the parameters in the
          model, or a numeric vector. A numeric ?start? argument will
          be used as the starting value of ?theta?.  If ?start? is a
          list, the ?theta? element (a numeric vector) is used as the
          starting value for the first optimization step (default=1 for
          diagonal elements and 0 for off-diagonal elements of the
          lower Cholesky factor); the fitted value of ?theta? from the
          first step, plus ?start[["fixef"]]?, are used as starting
          values for the second optimization step.  If ?start? has both
          ?fixef? and ?theta? elements, the first optimization step is
          skipped. For more details or finer control of optimization,
          see ?modular?.

Since you're fitting a logistic model, large parameter estimates (e.g.
|beta|>10) are strongly suspicious of complete separation (consider the
value of `plogis(41,log.p=TRUE)`); large intercept terms are also
diagnostic for continuous predictors that should be centered.  The
proximal cause of the convergence warning is most likely that glmer
scales the estimated gradients at the MLE by the estimated curvature
(inverse Hessian); if the surface is really, really flat then the scaled
gradients will be large even if the gradients themselves are OK.

  MCMCglmm and blme give fairly straightforward ways to deal with
complete separation (see http://rpubs.com/bbolker/glmmchapter).

  Ben Bolker


> 
> Here is the model I am trying to fit.  As you can see, the model
> does not converge. I would like to look at different starting
> values.
> 
> 
> 
>> summary(mod1 <- glmer(imps79b ~ tx*sweek + (sweek|id),data=schiz,
>> family=binomial))
> 
> Generalized linear mixed model fit by maximum likelihood (Laplace 
> Approximation) ['glmerMod']
> 
> Family: binomial  ( logit )
> 
> Formula: imps79b ~ tx * sweek + (sweek | id)
> 
> Data: schiz
> 
> 
> 
> AIC      BIC   logLik deviance df.resid
> 
> 1206     1244     -596     1192     1596
> 
> 
> 
> Scaled residuals:
> 
> Min      1Q  Median      3Q     Max
> 
> -1.7008  0.0000  0.0000  0.0001  1.3310
> 
> 
> 
> Random effects:
> 
> Groups Name        Variance Std.Dev. Corr
> 
> id     (Intercept) 1143     33.8
> 
> sweek        255     16.0     -0.43
> 
> Number of obs: 1603, groups:  id, 437
> 
> 
> 
> Fixed effects:
> 
> Estimate Std. Error z value Pr(>|z|)
> 
> (Intercept)    41.54       8.50    4.88    1e-06 ***
> 
> tx              5.81       5.12    1.14    0.256
> 
> sweek         -10.91       3.32   -3.28    0.001 **
> 
> tx:sweek      -11.93       5.17   -2.31    0.021 *
> 
> ---
> 
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> 
> 
> Correlation of Fixed Effects:
> 
> (Intr) tx     sweek
> 
> tx       -0.823
> 
> sweek     0.527 -0.289
> 
> tx:sweek -0.734  0.360 -0.922
> 
> Warning message:
> 
> In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
> :
> 
> Model failed to converge with max|grad| = 73.9422 (tol = 0.001, 
> component 4)
> 
>> 
> 
> 
> 
> Thanks,
> 
> Ravi
> 
> 
> 
> Ravi Varadhan, Ph.D. (Environmental Eng.), Ph.D. (Biostatistics)
> 
> Associate Professor,
> 
> Division of Geriatric Medicine & Gerontology
> 
> School of Medicine,
> 
> Johns Hopkins University
> 
> Ph: 410-502-2619
> 
> Email: ravi.varadhan at jhu.edu <mailto:ravi.varadhan at jhu.edu>
> 
> http://www.jhsph.edu/research/centers-and-institutes/johns-hopkins-center-on-aging-and-health/people/Faculty_personal_Pages/Varadhan.html
>
> 
> 
> 
>


From ravi.varadhan at jhu.edu  Wed Jul 23 21:29:13 2014
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Wed, 23 Jul 2014 19:29:13 +0000
Subject: [R-sig-ME] Providing starting values for glmer()
In-Reply-To: <53D00785.6010709@gmail.com>
References: <2F9EA67EF9AE1C48A147CB41BE2E15C31244139C@DOM-EB-MAIL2.win.ad.jhu.edu>
	<53D00785.6010709@gmail.com>
Message-ID: <2F9EA67EF9AE1C48A147CB41BE2E15C3124413E7@DOM-EB-MAIL2.win.ad.jhu.edu>

I am getting sensible results for the same model from SAS: both PROC GLIMMIX and NLMIXED were able to provide "reasonable looking" estimates.  I can send you the results, if you are interested.

Ravi

-----Original Message-----
From: Ben Bolker [mailto:bbolker at gmail.com] 
Sent: Wednesday, July 23, 2014 3:06 PM
To: Ravi Varadhan; r-sig-mixed-models at r-project.org
Subject: Re: Providing starting values for glmer()

On 14-07-23 02:18 PM, Ravi Varadhan wrote:
> Dear Ben,
> 
> I would appreciate your help with one more question.  How would I 
> provide starting values to glmer()?  I know it is supposed to be a 
> named list, but I don't know what the names are supposed to be.

 [cc'ing to r-sig-mixed models]

  In the grand tradition of R help pages, I think the definition of 'start' in the ?glmer page is technically correct if somewhat opaque.
Short answer: the names should be 'theta' and/or 'fixef'.


 start: a named list of starting values for the parameters in the
          model, or a numeric vector. A numeric 'start' argument will
          be used as the starting value of 'theta'.  If 'start' is a
          list, the 'theta' element (a numeric vector) is used as the
          starting value for the first optimization step (default=1 for
          diagonal elements and 0 for off-diagonal elements of the
          lower Cholesky factor); the fitted value of 'theta' from the
          first step, plus 'start[["fixef"]]', are used as starting
          values for the second optimization step.  If 'start' has both
          'fixef' and 'theta' elements, the first optimization step is
          skipped. For more details or finer control of optimization,
          see 'modular'.

Since you're fitting a logistic model, large parameter estimates (e.g.
|beta|>10) are strongly suspicious of complete separation (consider the
value of `plogis(41,log.p=TRUE)`); large intercept terms are also diagnostic for continuous predictors that should be centered.  The proximal cause of the convergence warning is most likely that glmer scales the estimated gradients at the MLE by the estimated curvature (inverse Hessian); if the surface is really, really flat then the scaled gradients will be large even if the gradients themselves are OK.

  MCMCglmm and blme give fairly straightforward ways to deal with complete separation (see http://rpubs.com/bbolker/glmmchapter).

  Ben Bolker


> 
> Here is the model I am trying to fit.  As you can see, the model does 
> not converge. I would like to look at different starting values.
> 
> 
> 
>> summary(mod1 <- glmer(imps79b ~ tx*sweek + (sweek|id),data=schiz,
>> family=binomial))
> 
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) ['glmerMod']
> 
> Family: binomial  ( logit )
> 
> Formula: imps79b ~ tx * sweek + (sweek | id)
> 
> Data: schiz
> 
> 
> 
> AIC      BIC   logLik deviance df.resid
> 
> 1206     1244     -596     1192     1596
> 
> 
> 
> Scaled residuals:
> 
> Min      1Q  Median      3Q     Max
> 
> -1.7008  0.0000  0.0000  0.0001  1.3310
> 
> 
> 
> Random effects:
> 
> Groups Name        Variance Std.Dev. Corr
> 
> id     (Intercept) 1143     33.8
> 
> sweek        255     16.0     -0.43
> 
> Number of obs: 1603, groups:  id, 437
> 
> 
> 
> Fixed effects:
> 
> Estimate Std. Error z value Pr(>|z|)
> 
> (Intercept)    41.54       8.50    4.88    1e-06 ***
> 
> tx              5.81       5.12    1.14    0.256
> 
> sweek         -10.91       3.32   -3.28    0.001 **
> 
> tx:sweek      -11.93       5.17   -2.31    0.021 *
> 
> ---
> 
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> 
> 
> 
> Correlation of Fixed Effects:
> 
> (Intr) tx     sweek
> 
> tx       -0.823
> 
> sweek     0.527 -0.289
> 
> tx:sweek -0.734  0.360 -0.922
> 
> Warning message:
> 
> In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
> :
> 
> Model failed to converge with max|grad| = 73.9422 (tol = 0.001, 
> component 4)
> 
>> 
> 
> 
> 
> Thanks,
> 
> Ravi
> 
> 
> 
> Ravi Varadhan, Ph.D. (Environmental Eng.), Ph.D. (Biostatistics)
> 
> Associate Professor,
> 
> Division of Geriatric Medicine & Gerontology
> 
> School of Medicine,
> 
> Johns Hopkins University
> 
> Ph: 410-502-2619
> 
> Email: ravi.varadhan at jhu.edu <mailto:ravi.varadhan at jhu.edu>
> 
> http://www.jhsph.edu/research/centers-and-institutes/johns-hopkins-cen
> ter-on-aging-and-health/people/Faculty_personal_Pages/Varadhan.html
>
> 
> 
> 
> 


From bbolker at gmail.com  Thu Jul 24 01:37:30 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 23 Jul 2014 23:37:30 +0000 (UTC)
Subject: [R-sig-ME] glmer z values binomial data
References: <6B87DE513C3AC945ACFE067E1BC879615CE9E4024D@IS-WIN-375.staffad.uwa.edu.au>,
	<53CFDAE1.6000202@gmail.com>
	<6B87DE513C3AC945ACFE067E1BC879615CE9E40251@IS-WIN-375.staffad.uwa.edu.au>,
	<53CFDEDF.9040008@gmail.com>
	<6B87DE513C3AC945ACFE067E1BC879615CE9E40253@IS-WIN-375.staffad.uwa.edu.au>
Message-ID: <loom.20140724T013004-350@post.gmane.org>

Clelia Gasparini <clelia.gasparini at ...> writes:

> 
> 
> Hi
> 
> I'm using glmer (lme4) to analyse binomial data. I have 
> used observation level to account for overdispersion.
> My problem is that a referee asked to get wald t or F 
> instead of wald Z mentioning Bolker's review in TREE 2008.
> 
> Can you suggest a way to get t or F instead of z in the output?
> 
> this is the code I'm using now:
> 
> y=cbind(data$Success,data$Failure) 
> glmer.r<-glmer(y~ treat  + (1|obs), data=data, 
>  family=binomial(logit), weights =total.size) 
> summary(glmer.r)
> 
> Many thanks in advance, 
> Clelia 
> 

  The Bolker 2008 t/F suggestion is based on using penalized 
quasi-likelihood (PQL) to account for overdispersion; lme4 no longer does 
PQL, because we decided that we don't really understand/aren't comfortable
with the properties of PQL for GLMMs.

* if you can decide on the degrees of freedom (see 
http://glmm.wikidot.com/faq#df , and scroll down to "DF alternatives"),
then you can take the Z scores, reinterpret them as t scores, and
use 2*pt(abs(scores),df=df,lower.tail=FALSE) to get p-values.
* including a per-observation random effect should account for
overdispersion anyway (see the "overdispersion" section of the FAQ)
* I'm a little puzzled that you have specified the response as
a two-column matrix *and* have separately specified the weights:
normally you would do one or the other ...
* the model specification you have above has no grouping variable/
random effect term other than the observation-level RE, which makes
it look just like a regular binomial GLM + overdispersion.  Therefore
you might be better off/have an easier time with

  glm(y~ treat , data=data, family=quasibinomial)

or a beta-binomial model.


From russell-lenth at uiowa.edu  Thu Jul 24 02:21:44 2014
From: russell-lenth at uiowa.edu (Lenth, Russell V)
Date: Thu, 24 Jul 2014 00:21:44 +0000
Subject: [R-sig-ME] Mixed-effects Model - LMER - Plot of estimated Mean
	and CI
Message-ID: <677B501B-B276-4A36-85E5-BA8AC377C391@uiowa.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140724/19e2663f/attachment.pl>

From russell-lenth at uiowa.edu  Thu Jul 24 02:29:34 2014
From: russell-lenth at uiowa.edu (Lenth, Russell V)
Date: Thu, 24 Jul 2014 00:29:34 +0000
Subject: [R-sig-ME] Mixed-effects Model - LMER - Plot of estimated Mean
	and CI
In-Reply-To: <677B501B-B276-4A36-85E5-BA8AC377C391@uiowa.edu>
References: <677B501B-B276-4A36-85E5-BA8AC377C391@uiowa.edu>
Message-ID: <CFA4BA30-DD8D-4088-AD6D-E1524234A47A@uiowa.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140724/18f62544/attachment.pl>

From bbolker at gmail.com  Thu Jul 24 06:14:07 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 24 Jul 2014 04:14:07 +0000 (UTC)
Subject: [R-sig-ME] Install flexlambda- and master-lme4 from Github
References: <20140723154433.GA5351@gmail.com>
Message-ID: <loom.20140724T061222-74@post.gmane.org>

Christian Brauner <christianvanbrauner at ...> writes:

> 
> Hello,
> 
> is it possible to install the flexlambda and master branch of lme4 at the
> same time:
> 
> library(devtools)
> install_github("lme4", "lme4")
> install_github("lme4", "flexlambda")
> 
> such that I can load them as different packages.
> (Obviously not both at the
> same time but for example in two different sessions; using "lme4" in one
> and "flexlambda" in the other)?
> 

  
  devtools::dev_mode() might be useful (I haven't used it),
or install the packages to different libraries and specify
`lib.loc` when loading ... or clone the package to your system
and hack the DESCRIPTION file to create two different packages
with different names ...


From tobias.heed.uhh at gmail.com  Thu Jul 24 06:43:20 2014
From: tobias.heed.uhh at gmail.com (Tobias Heed)
Date: Thu, 24 Jul 2014 06:43:20 +0200
Subject: [R-sig-ME] Install flexlambda- and master-lme4 from Github
In-Reply-To: <loom.20140724T061222-74@post.gmane.org>
References: <20140723154433.GA5351@gmail.com>
	<loom.20140724T061222-74@post.gmane.org>
Message-ID: <119A164C-CD59-40B1-996E-C996BFFD044F@gmail.com>

Dear Christian,

I think the package manager packrat (implemented also in the project functionality of the RStudio beta that came out this monday) would enable you to do what you need.

Best, Tobias 



> On 24.07.2014, at 06:14, Ben Bolker <bbolker at gmail.com> wrote:
> 
> Christian Brauner <christianvanbrauner at ...> writes:
> 
>> 
>> Hello,
>> 
>> is it possible to install the flexlambda and master branch of lme4 at the
>> same time:
>> 
>> library(devtools)
>> install_github("lme4", "lme4")
>> install_github("lme4", "flexlambda")
>> 
>> such that I can load them as different packages.
>> (Obviously not both at the
>> same time but for example in two different sessions; using "lme4" in one
>> and "flexlambda" in the other)?
> 
> 
>  devtools::dev_mode() might be useful (I haven't used it),
> or install the packages to different libraries and specify
> `lib.loc` when loading ... or clone the package to your system
> and hack the DESCRIPTION file to create two different packages
> with different names ...
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From mcarrete at upo.es  Thu Jul 24 09:31:45 2014
From: mcarrete at upo.es (Martina Carrete)
Date: Thu, 24 Jul 2014 09:31:45 +0200
Subject: [R-sig-ME] MCMCglmm question: multivariate model
Message-ID: <745f82562ae53629.53d0d281@upo.es>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140724/ddacecc2/attachment.pl>

From christianvanbrauner at gmail.com  Fri Jul 25 10:31:17 2014
From: christianvanbrauner at gmail.com (Christian Brauner)
Date: Fri, 25 Jul 2014 10:31:17 +0200
Subject: [R-sig-ME] Install flexlambda- and master-lme4 from Github
In-Reply-To: <mailman.7.1406196002.6705.r-sig-mixed-models@r-project.org>
References: <mailman.7.1406196002.6705.r-sig-mixed-models@r-project.org>
Message-ID: <20140725083116.GA1656@gmail.com>

Dear Ben,
dear Tobias,

the devtools solution is actually pretty nice:

library(devtools)
dev_mode(, path = "~/your/path/to/new/library/here")

will switch your R repl from

>

to

d>

you can then simply install

install_github("lme4", "lme4", ref = "flexLambda")

which will install into the directory specificied in your dev_mode() call.
Next time you enter R and want to load the flexLambda version of lme4 you
need to pass

dev_mode(, path = ~/your/path/to/new/library/here")

again. If you now use

library(lme4)

it will load the flexLambda package from the specified library path.

Thank you!
Christian

> ------------------------------
> 
> Message: 3
> Date: Thu, 24 Jul 2014 04:14:07 +0000 (UTC)
> From: Ben Bolker <bbolker at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Install flexlambda- and master-lme4 from
> 	Github
> Message-ID: <loom.20140724T061222-74 at post.gmane.org>
> Content-Type: text/plain; charset=us-ascii
> 
> Christian Brauner <christianvanbrauner at ...> writes:
> 
> > 
> > Hello,
> > 
> > is it possible to install the flexlambda and master branch of lme4 at the
> > same time:
> > 
> > library(devtools)
> > install_github("lme4", "lme4")
> > install_github("lme4", "flexlambda")
> > 
> > such that I can load them as different packages.
> > (Obviously not both at the
> > same time but for example in two different sessions; using "lme4" in one
> > and "flexlambda" in the other)?
> > 
> 
>   
>   devtools::dev_mode() might be useful (I haven't used it),
> or install the packages to different libraries and specify
> `lib.loc` when loading ... or clone the package to your system
> and hack the DESCRIPTION file to create two different packages
> with different names ...
> 
> 
> 
> ------------------------------
> 
> Message: 4
> Date: Thu, 24 Jul 2014 06:43:20 +0200
> From: Tobias Heed <tobias.heed.uhh at gmail.com>
> To: Ben Bolker <bbolker at gmail.com>
> Cc: "r-sig-mixed-models at r-project.org"
> 	<r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] Install flexlambda- and master-lme4 from
> 	Github
> Message-ID: <119A164C-CD59-40B1-996E-C996BFFD044F at gmail.com>
> Content-Type: text/plain;	charset=us-ascii
> 
> Dear Christian,
> 
> I think the package manager packrat (implemented also in the project functionality of the RStudio beta that came out this monday) would enable you to do what you need.
> 
> Best, Tobias 
> 
> 
> 
> > On 24.07.2014, at 06:14, Ben Bolker <bbolker at gmail.com> wrote:
> > 
> > Christian Brauner <christianvanbrauner at ...> writes:
> > 
> >> 
> >> Hello,
> >> 
> >> is it possible to install the flexlambda and master branch of lme4 at the
> >> same time:
> >> 
> >> library(devtools)
> >> install_github("lme4", "lme4")
> >> install_github("lme4", "flexlambda")
> >> 
> >> such that I can load them as different packages.
> >> (Obviously not both at the
> >> same time but for example in two different sessions; using "lme4" in one
> >> and "flexlambda" in the other)?
> > 
> > 
> >  devtools::dev_mode() might be useful (I haven't used it),
> > or install the packages to different libraries and specify
> > `lib.loc` when loading ... or clone the package to your system
> > and hack the DESCRIPTION file to create two different packages
> > with different names ...
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 
> ------------------------------
> 
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> End of R-sig-mixed-models Digest, Vol 91, Issue 31
> **************************************************


From n.clark at griffith.edu.au  Fri Jul 25 11:21:21 2014
From: n.clark at griffith.edu.au (Nick Clark)
Date: Fri, 25 Jul 2014 19:21:21 +1000
Subject: [R-sig-ME] Cbind and taxa rows trouble in MCMCglmm
Message-ID: <CAD3_oRF6OB2rFwE6tFMm97YmxVd6NymKXKLrwVN3mhJNB33MRw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140725/c91e13b7/attachment.pl>

From robert.espesser at lpl-aix.fr  Fri Jul 25 17:12:36 2014
From: robert.espesser at lpl-aix.fr (espesser)
Date: Fri, 25 Jul 2014 17:12:36 +0200
Subject: [R-sig-ME] longitudinal analysis covariance or mixed model approach
Message-ID: <53D273E4.5070405@lpl-aix.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140725/cede7820/attachment.pl>

From j.hadfield at ed.ac.uk  Sat Jul 26 14:01:41 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sat, 26 Jul 2014 13:01:41 +0100
Subject: [R-sig-ME] Cbind and taxa rows trouble in MCMCglmm
In-Reply-To: <CAD3_oRF6OB2rFwE6tFMm97YmxVd6NymKXKLrwVN3mhJNB33MRw@mail.gmail.com>
References: <CAD3_oRF6OB2rFwE6tFMm97YmxVd6NymKXKLrwVN3mhJNB33MRw@mail.gmail.com>
Message-ID: <20140726130141.995679h50awkf4g8@www.staffmail.ed.ac.uk>

Hi Nick,

For Q1 can you post your model specification?

For Q2 the dimensions of the data-frame and the phylogeny do not have  
to be the same. The only condition is that the levels of the column  
that you wish to associate with the phylogeny (i.e. Species) are all  
represented in either a) the row names of the inverse phylogenetic  
covariance matrix (if you use the ginverse= argument) or b) the tip  
labels of the phylogeny (if you use the pedigree= argument).

If you do have multiple records per species then you might also want  
to consider fitting a non-phylogenetic species effect.

Cheers,

Jarrod.



Quoting Nick Clark <n.clark at griffith.edu.au> on Fri, 25 Jul 2014  
19:21:21 +1000:

> Hi all,
>
> I have been trying to run a phylogenetic model using a recently updated
> version of MCMCglmm, but for some reason the model will not run when using
> cbind to form the response variable. I have two variables, one for number
> of individuals uninfected (NoUninf) and one for number infected (NoInf),
> and I have tried both separately to make sure the model works. However,
> when I combine the two using cbind, the model cannot assign the R
> structure, even if I make sure to assign the family using c("gaussian,
> "gaussian") to account for the two variables in the response (error
> repeatedly says r structure not specified properly). I'm not sure if the
> length of the variable is confusing the program, as cbind works perfectly
> well in a glm using lme4.
>
> On a separate note, I'm not sure how to combine rows to make sure that the
> number of records in the data file equals the number of records in the
> phylogeny (1) for each species. Basically, I have a data file with multiple
> rows for each species depending on sampling location, ie:
>
> Species     Site     NoInf     NoUninf
> C. canutus WA     10          25
> C. canutus NA      11          34
>
> Since each line is important as it represents a unique sample location, I
> would like to incorporate them all into the data file. However, my
> phylogeny and covariance matrix will only have one record per species, so
> should I try to shape my data so that each row is a matrix of multiple row
> records? Any help would be greatly appreciated, sorry if these are rather
> mundane problems but I'm quite new to using R.
>
> Thanks,
>
> Nick
>
> --
> Nick Clark
> PhD Candidate, School of Environment
> Griffith University, Gold Coast
>
> Researchgate profile:
> https://www.researchgate.net/profile/Nicholas_Clark4/?ev=hdr_xprf
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From j.hadfield at ed.ac.uk  Sat Jul 26 15:14:42 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sat, 26 Jul 2014 14:14:42 +0100
Subject: [R-sig-ME] MCMCglmm prior specification
In-Reply-To: <C11D7BD4-D1D8-4C36-944C-5407670BB1BC@sussex.ac.uk>
References: <C11D7BD4-D1D8-4C36-944C-5407670BB1BC@sussex.ac.uk>
Message-ID: <20140726141442.11825jeczgpl8vgo@www.staffmail.ed.ac.uk>

Hi Tanya,

The error message is because your between-line covariance matrix is  
6x6 (each sex at three temperatures) but your prior is for a 2x2  
covariance matrix. With 14 lines I would not advise fitting a 6x6  
covariance matrix (21 parameters) and I would try and keep it simple.

Cheers,

Jarrod





Quoting Tanya Pennell <T.Pennell at sussex.ac.uk> on Wed, 23 Jul 2014  
10:16:50 +0000:

> Hi all,
>
> I'm trying to amend a previous model that included gene x sex  
> interactions, but now i'm looking at gene x sex x environment  
> interactions. I'm getting an error message appear that says 'V is  
> the wrong dimension for some prior$G/prior$R elements'
>
> Here is my code -
>
>
> prior.model.2<-list(R=list(V=diag(2)/252, nu=0.01),G=list     (   
> G1=list   (V=diag(2)/252, nu=2, alpha.mu=c(0,0),  
> alpha.V=diag(2)/252)))
>
>
> model.2 <- MCMCglmm(relative_fec ~  
> sex*rep-1,random=~us(sex:temp):line, rcov=~idh(sex):units,  
> family="gaussian", nitt = 100000, burnin = 30000, thin=30, data =  
> all_treatments, prior = prior.model.2, verbose = FALSE)
>
>
> I have relative fecundity measurements for males and females from 14  
> lines, that were measured in 3 temperatures. Each line, sex and temp  
> combination had  6 replicates.
>
> Can anyone guide me on my prior here please?
>
> Many thanks,
> Tanya
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From jsmith5 at ucsc.edu  Sun Jul 27 18:54:13 2014
From: jsmith5 at ucsc.edu (Justine Smith)
Date: Sun, 27 Jul 2014 09:54:13 -0700
Subject: [R-sig-ME] MCMCglmm predict function output and interpretation
Message-ID: <CAOBBrxNqrTGCz0xo8yB4_xoVGeZqKPut+tSJQ+o+sKGb7VCGGQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140727/d89e2a48/attachment.pl>

From geetha.r.v at gmail.com  Sun Jul 27 20:50:57 2014
From: geetha.r.v at gmail.com (geetha venkatesh)
Date: Sun, 27 Jul 2014 20:50:57 +0200
Subject: [R-sig-ME] How to check if the interaction term is significant?
Message-ID: <CAHOXprnN0OaZFbAOgnJvJ=2ZwEsw+3OHKq3AXeUduHOHwRZSgA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140727/82e893b6/attachment.pl>

From bbolker at gmail.com  Sun Jul 27 21:43:22 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 27 Jul 2014 19:43:22 +0000 (UTC)
Subject: [R-sig-ME] How to check if the interaction term is significant?
References: <CAHOXprnN0OaZFbAOgnJvJ=2ZwEsw+3OHKq3AXeUduHOHwRZSgA@mail.gmail.com>
Message-ID: <loom.20140727T214227-490@post.gmane.org>

geetha venkatesh <geetha.r.v at ...> writes:

> 
> Dear lmer users,
> 
> I am using this package for the first time. I have a very basic question
> and I hope I can clarify my doubt. I would like to check if the interaction
> between two variables is significant. If I use two models, one with
> interaction term and the other without interaction and run a anova test,
> does this make sense?
> 
> m1=lmer(res~variant*age+sex+(1|batch))
> m2=lmer(res~variant+age+sex+(1|batch))
> 
> anova(m1,m2)
> 
> Is this the correct way to fit models in order to check for the
> significance of the interaction terms?
> 

  Yes; this runs a likelihood ratio test.  It is an asymptotic
test; you may want to consider the alternatives in the pbkrtest
package for other kinds of tests, but the basic idea is the same.

  Ben Bolker


From mkbartl at ucla.edu  Mon Jul 28 07:34:32 2014
From: mkbartl at ucla.edu (Megan Bartlett)
Date: Sun, 27 Jul 2014 22:34:32 -0700
Subject: [R-sig-ME] Looking for an effect of relatedness in non-normal data
	(MCMCglmm)
Message-ID: <CAB2zMEG4Vsh+KRoykiBx_sA8hGe9efJyGG_-wb5sNrATe+6NiQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140727/042dbdff/attachment.pl>

From marcoplebani85 at gmail.com  Mon Jul 28 09:20:05 2014
From: marcoplebani85 at gmail.com (Marco Plebani)
Date: Mon, 28 Jul 2014 09:20:05 +0200
Subject: [R-sig-ME] Mixed effect models for a study with no (real)
	replication
In-Reply-To: <EADD2F16-BABD-42C5-9372-B8CF53148B98@gmail.com>
References: <3A1E8A8D-994A-47B5-A7D9-2A4223DE4D4A@gmail.com>
	<AA818EAD2576BC488B4F623941DA7427F3AC33D1@inbomail.inbo.be>
	<EADD2F16-BABD-42C5-9372-B8CF53148B98@gmail.com>
Message-ID: <0BA85A64-1D22-4394-827B-C251948A98D4@gmail.com>

Dear Thierry,

thank you for spotting the mistake. Some questions are still standing though:

1) Why lme4 estimates the st.dev of the fixed effect correctly when it is larger than the residual st.dev, while if the residual st.dev is higher than the st.dev of the fixed effect, the latter is overestimated?
2) Why blme is better than lme4 in detecting the st.dev of the ranef "Stream.ID? ? I have tested this only in the case the st.dev of both the fixed effect and the residual are small. What does blme do that lme4 does not?

Thank you very much for your help,

Marco

-----
Marco Plebani
Institute of Evolutionary Biology and Environmental Studies
University of Zurich


On 22/lug/2014, at 15:57, ONKELINX, Thierry <Thierry.ONKELINX at inbo.be> wrote:

> Dear Marco,
> 
> You are simulating underdispersed data by rounding the expected values. Use rpois() instead of round() and you will get more sensible results.
> 
> rr$pred.rich_e1_e2 <- rpois(nrow(rr), lambda = 13 * exp(-0.07 * rr$temperature) * exp(rr$epsilon1) * exp(rr$epsilon2)) # rounded to the closest integer
> 
> I find it easier to generate all expected values on the log scale.
> 
> rr$mu <- log(13) - 0.07 * rr$temperature + rr$epsilon1 + rr$epsilon2
> rr$pred.rich_e1_e2 <- rpois(nrow(rr), lambda = exp(rr$mu))
> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> + 32 2 525 02 51
> + 32 54 43 61 85
> Thierry.Onkelinx at inbo.be
> www.inbo.be
> 
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
> 
> The plural of anecdote is not data.
> ~ Roger Brinner
> 
> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> 
> 
> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Marco Plebani
> Verzonden: dinsdag 22 juli 2014 14:22
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] Mixed effect models for a study with no (real) replication
> 
> Dear list members,
> 
> I am analyzing the effects of temperature on species richness across a natural temperature gradient. The study is based on 13 streams, each at a different temperature; for each stream I have measures of species richness obtained from three samples i.e. 39 data points in total.
> I expect the observed variability to be due to four possible sources, three of which are discernible:
> - differences AMONG streams due to temperature,
> - differences AMONG streams not due to temperature (e.g. due to other environmental factors not accounted for in the study),
> - differences WITHIN streams (due to either natural heterogeneity and/or the observation process, indiscernible without having multiple measures for each sample).
> 
> I should point out that "temperature" is coded as a continuous variable while " Stream.ID" is a factor (I did this for clarity; I could have used "temperature" as both fixef and ranef).
> A very similar issue has been discussed recently (https://stat.ethz.ch/pipermail/r-sig-mixed-models/2014q3/022365.html, "Same variable as both fixed and random") so I fitted the following model:
> 
> glmer(species.richness ~ temperature + (1 | Stream.ID), data=dd, family=poisson)
> 
> I tested the above-mentioned model on simulated data obtained as follows (see script at the end of this message):
> 
> species.richness = a * exp(b* temperature * epsilon1 * epsilon2)
> 
> Where epsilon1 adds variability AMONG streams not explained by temperature, and epsilon2 adds variability WITHIN streams.
> The estimates of parameters a and b are coherent with the parameters of the simulation, but the st.dev estimates due to Stream.ID are often far off (somewhere between the actual st.dev due to Stream ID and the residual st.dev)  and often touching zero (when the simulated st.dev due to Stream ID and the residual st.dev are similar).
> Why does that happen? Here: https://stat.ethz.ch/pipermail/r-sig-mixed-models/2014q3/022386.html ("LMM: including ranef or not?") Ben Bolker foresees such an issue when the ranef has only few levels and suggests to use blme to fix the problem. I tried; blme still confounds the st.dev due to Stream ID and the residual st.dev when the latter is much higher then the former, but it does succeed in reducing the estimate of false zeroes for the st.dev of Stream ID when st.dev(Stream.ID)~st.dev(residual) and both <1.
> Why blme is better than lme4 in detecting the st.dev of the ranef "Stream.ID" when it is small?
> My familiarity with Bayesian stats is limited to studying Bayes's theorem as an undergrad, so to be honest I have no idea what's going on "inside" blme.
> 
> Thank you very much in advance for any help provided.
> Cheers,
> 
> Marco
> 
> -----
> Marco Plebani
> Institute of Evolutionary Biology and Environmental Studies University of Zurich http://www.ieu.uzh.ch/staff/phd/plebani.html
> 
> 
> 
> 
> 
> ###################################
> ###################################
> # Marco Plebani, July 17th 2014
> # Given a study based on 13 streams at 13 different temperatures, sampled 3 times each for species richness and total biomass, is it possible to discern the temperature effect on species richness and total biomass from the effect of variability among streams not due to temperature?
> # Note that the multiple samples are PSEUDO-replicates and that there is complete temperature=stream identity.
> ###################################
> ###################################
> 
> rm(list=ls())
> library(lme4)
> library(blme)
> #set.seed(2)
> 
> # Simulate data based on the observed temperature effect.
> # the model is:
> 
> # y = a * exp(b*x) + epsilon
> 
> #a, i.e. species richness at 0?C, is set at 13 # b is set at -0.07
> 
> # epsilon is the sum of:
> # epsilon1 due to variability AMONG streams not explained by temperature, # epsilon2 due to variability WITHIN streams (i.e. residual variuability, made up by both the streams natural heterogeneity and the sampling error)
> 
> # create empty vectors where to save estimates for the sd due to Stream ID, and the p-val of parameter "b" (see model above):
> 
> stream.ID.stdev<-rep(NA,50)
> stream.ID.stdev.bayes<-rep(NA,50)
> model.significance<-rep(NA,50)
> 
> # create the dataset:
> 
> reps <- 1:3
> Stream.ID <- letters[1:13]
> temperature <- seq(5,20, length.out=13)
> rr <- expand.grid(Stream.ID = Stream.ID, reps=reps) rr$temperature = rep(temperature,3)
> 
> ## predicted species richness for the observed temperature:
> rr$pred.rich <- 13 * exp(-0.07 * rr$temperature) # a and b values are realistic estimates
> 
> # continuous prediction:
> temp=seq(0,22,0.1)
> pred.richness <- 13 * exp(-0.07 * temp)
> 
> par(mfrow=c(1,3))
> plot(x= temp, y= pred.richness, xlim=c(0,23), ylim=c(0, 15), type="l")
> 
> # run the analysis on 50 datasets drawn from the same distribution:
> 
> for(i in 1:50){
> 
> ## epsilon1: stream.ID effect
> stream.eff <- data.frame(Stream.ID = rr$Stream.ID,
>                                               effect=rnorm(n=length(Stream.ID), mean=0, sd=0.2))
> # add epsilon1 to the dataset
> rr$epsilon1 <- stream.eff$effect[match(rr$Stream.ID, stream.eff$Stream.ID)]
> 
> ## epsilon2: residual variability within streams
> rr$epsilon2 <-  rnorm(length(rr$temperature), mean=0, sd=0.2)
> 
> # pred.richness accounting for epsilon1
> rr$pred.rich_e1 <- 13 * exp(-0.07 * rr$temperature) * exp(rr$epsilon1)
> 
> # pred.richness accounting for epsilon1 and epsilon2
> rr$pred.rich_e1_e2 <- round(13 * exp(-0.07 * rr$temperature) * exp(rr$epsilon1) * exp(rr$epsilon2)) # rounded to the closest integer
> 
> points(x= rr$temperature, y= rr$pred.rich_e1, pch=8, cex=1) #points(x= rr$temperature, y= rr$pred.rich_e1_e2, cex=1.5) # solid line represents predicted mean richness # *'s represent predicted mean richness + epsilon1 # circles represent predicted mean richness + epsilon1 + epsilon2, i.e. the observations from each sample
> 
> # glmm:
> 
> richness.glmm <- glmer(pred.rich_e1_e2 ~ temperature + (1|Stream.ID), data=rr, family=poisson) # "pred.rich_e1_e2" is the observed richness in each sample.
> richness.glmm.bayes <- bglmer(pred.rich_e1_e2 ~ temperature + (1|Stream.ID), data=rr, family=poisson)
> 
> stream.ID.stdev[i] <- as.numeric(attributes(summary(richness.glmm)$varcor[[1]])$stddev)
> stream.ID.stdev.bayes[i] <- as.numeric(attributes(summary(richness.glmm.bayes)$varcor[[1]])$stddev)
> model.significance[i] <- ifelse(summary(richness.glmm)$coefficients[2,4]<0.05,1,0)
> # library(MuMIn) # estimates pseudo-R^2 for MEM.
> # r.squaredGLMM(richness.glmm)
> 
> }
> 
> hist(stream.ID.stdev)
> abline(v=mean(stream.ID.stdev), col="red",lwd=2) legend("topright",title=paste("mean=", round(mean(stream.ID.stdev),2), "; sd=", round(sd(stream.ID.stdev),2)), legend=c(NA))
> 
> hist(stream.ID.stdev.bayes)
> abline(v=mean(stream.ID.stdev.bayes), col="red",lwd=2) legend("topright",title=paste("mean=", round(mean(stream.ID.stdev.bayes),2), "; sd=", round(sd(stream.ID.stdev.bayes),2)), legend=c(NA))
> 
> # end


From j.hadfield at ed.ac.uk  Mon Jul 28 09:52:03 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 28 Jul 2014 08:52:03 +0100
Subject: [R-sig-ME] MCMCglmm predict function output and interpretation
In-Reply-To: <CAOBBrxNqrTGCz0xo8yB4_xoVGeZqKPut+tSJQ+o+sKGb7VCGGQ@mail.gmail.com>
References: <CAOBBrxNqrTGCz0xo8yB4_xoVGeZqKPut+tSJQ+o+sKGb7VCGGQ@mail.gmail.com>
Message-ID: <20140728085203.27163zhcp5vjj8kk@www.staffmail.ed.ac.uk>

Hi Justine,

The first 634 predictions are for B vs A, and the second 634 are for C  
vs A. If you want the predicted probabilities of falling in category  
A, B or C you'll have to do it by hand I'm afraid.

Cheers,

Jarrod



Quoting Justine Smith <jsmith5 at ucsc.edu> on Sun, 27 Jul 2014 09:54:13 -0700:

> Dear all,
>
> I have constructed a multinomial mixed model using the package MCMCglmm
> that has three potential values of the response variable (let's call them
> A, B, and C). Although the model is running smoothly, I am unclear of how
> to interpret the output of the predict function. I would like to
> cross-validate the model, so I need to know the model prediction for each
> data point (A, B, or C). I have 634 data points and 1268 rows in the output
> of the predict function, which makes me think there is both a probability B
> is more likely than A and a probability that C is more likely than A, but
> because they are all in one column and don't have an index, I don't know
> what point each row corresponds to.
>
> Here is my model:
>
> mt<-MCMCglmm(pcl2~-1+trait + trait:ngtr1 + trait:bin1 + trait:night1,
>
> random = ~ us(1+night1):lID,
>
> rcov=~us(trait):units,
>
> prior = list(
>
> R = list(V=IJ,fix=1),
>
> G = list(
>
> G1 = list(V = diag(2),n = 0.002))),
>
> burnin = 30000,
>
> nitt = 200000,
>
> family = "categorical",
>
> data = killsdf,
>
> verbose=FALSE,
>
> DIC=TRUE,
>
> pr=TRUE,
>
> thin=200)
>
> And the basic predict function:
>
> m.pred<-predict(mt,type="response",interval="prediction")
>
> My output from "predict" looks like this (again, n = 634):
>
>          fit                lwr                upr
> 1 0.07529940 0.0009159809 0.2450521
> 2 0.26639933 0.0006481384 0.8171763
> 3 0.08842384 0.0011288143 0.2682600
> 4 0.28736411 0.0001511912 0.8286539
> 5 0.11389115 0.0013791012 0.3841322
> 6 0.21789723 0.0058586078 0.5767750
> ?
> 1268 0.24447799 5.553336e-03 0.6738022
>
> I apologize if this is clearly discussed in the Course Notes or other
> documents, but I just cannot seem to find it. I would be very grateful to
> anyone who can provide insight on how to interpret the predict function
> output.
>
> Many thanks,
> Justine
>
> 	[[alternative HTML version deleted]]
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From j.hadfield at ed.ac.uk  Mon Jul 28 10:14:22 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 28 Jul 2014 09:14:22 +0100
Subject: [R-sig-ME] Looking for an effect of relatedness in non-normal
 data (MCMCglmm)
In-Reply-To: <CAB2zMEG4Vsh+KRoykiBx_sA8hGe9efJyGG_-wb5sNrATe+6NiQ@mail.gmail.com>
References: <CAB2zMEG4Vsh+KRoykiBx_sA8hGe9efJyGG_-wb5sNrATe+6NiQ@mail.gmail.com>
Message-ID: <20140728091422.58451v7zv0vyao2o@www.staffmail.ed.ac.uk>

Hi Megan,

Its hard to say how much of a problem it is without seeing the  
distribution of the *residuals* and the phylogenetic effects.  
Certainly, the normal likelihood is not robust to outliers because of  
its thin tails, and this will be a problem for MCMCglmm (and linear  
mixed models fitted in other packages). You can run MCMCglmm on  
permuted data, but I always find it hard to permute the data under the  
correct null hypothesis. For example, if you just naively permute the  
data then a phylogenetic heritability of zero is part of the null  
hypothesis, even though this may not be the null hypothesis you would  
like to reject. This may be a problem if the statistic you are using  
depends on the phylogenetic heritability. As an alternative have you  
tried a cube-root transformation?  This is the Wilson-Hilferty normal  
approximation for the Gamma.

Cheers,

Jarrod








Quoting Megan Bartlett <mkbartl at ucla.edu> on Sun, 27 Jul 2014 22:34:32 -0700:

> Hi everyone,
>
> I'd like to use MCMCglmm to look at the importance of phylogenetic
> relatedness to variation in a plant drought tolerance trait, while also
> accounting for a random effect of study site and a fixed effect of climate.
> The difficulty is that my drought tolerance trait data is significantly not
> normally distributed (according to the *shapiro.test* function), even when
> log or square-root transformed (all p < 0.001). This comes from the fact
> that some arid species are very drought tolerant, producing a right-skewed
> trait distribution. My data is best-fit by a gamma distribution, according
> to the* fitdistrplus* package, but my data is better fit by a normal
> distribution than any other family that MCMCglmm can model.
>
> I know there are ways to fit mixed-effects models that allow for
> permutation tests, to avoid assuming normal distributions, but these
> packages (coin, lme4), don't allow for specifying a phylogenetic
> relatedness matrix. This leads me to the problem that it seems incorrect to
> use MCMCglmm to estimate a signal of relatedness for this non-normal data,
> but it also seems incorrect to use packages that allow for permutation
> tests without accounting for relatedness.
>
> So, to try to figure out a way around this, my questions are:
>
> 1) How non-normal is "too" non-normal for MCMCglmm, if no other
> distribution family is a better option? Is it ever acceptable to fit
> non-normal data this way?
>
> 2) There seem to be permutation tests (like in the *coin* package) that can
> handle significance testing for mixed-effects models, but not for models
> with the phylogenetic relatedness matrix specified. Does something like
> this exist that I'm not aware of?
>
> 3) Or, is there a way to apply a permutation test to the MCMCglmm output?
>
> Thanks very much for your help!
>
> Best,
>
> Megan
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From smit.reuben at gmail.com  Mon Jul 28 19:05:27 2014
From: smit.reuben at gmail.com (Reuben Smit)
Date: Mon, 28 Jul 2014 12:05:27 -0500
Subject: [R-sig-ME] Calculating upper and lower confidence limits on a
 population estimate derived from multiple point estimates
Message-ID: <CAFFAEtimJvi8t7Y=FWqavaBz4iJC7v=enZS8wchQdqcDTzXL2A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140728/7e572594/attachment.pl>

From jsmith5 at ucsc.edu  Tue Jul 29 01:45:09 2014
From: jsmith5 at ucsc.edu (Justine)
Date: Mon, 28 Jul 2014 23:45:09 +0000 (UTC)
Subject: [R-sig-ME] MCMCglmm predict function output and interpretation
References: <CAOBBrxNqrTGCz0xo8yB4_xoVGeZqKPut+tSJQ+o+sKGb7VCGGQ@mail.gmail.com>
	<20140728085203.27163zhcp5vjj8kk@www.staffmail.ed.ac.uk>
Message-ID: <loom.20140729T013731-783@post.gmane.org>

Jarrod Hadfield <j.hadfield at ...> writes:

> 
> Hi Justine,
> 
> The first 634 predictions are for B vs A, and the second 634 are for C  
> vs A. If you want the predicted probabilities of falling in category  
> A, B or C you'll have to do it by hand I'm afraid.
> 
> Cheers,
> 
> Jarrod
> 

Hi Jarrod,

Thanks so much for clearing that up. Just to make sure I'm absolutely clear, 
if column 1 is 0.228, and column 635 is 0.092, than for data point #1 the 
probability option B is more likely than option A is 0.228 and C more likely 
than A is 0.092? Does this indicate that A (the reference value) is the most 
likely? Can I calculate its relative probability by subtracting the other 
two values from 1? I'm happy to assign the categories by hand, but I want to 
make sure I am interpreting the output correctly.

Thanks again,

Justine


From jdnewmil at dcn.davis.CA.us  Tue Jul 29 03:47:26 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 28 Jul 2014 18:47:26 -0700
Subject: [R-sig-ME] Calculating upper and lower confidence limits on a
	population estimate derived from multiple point estimates
In-Reply-To: <CAFFAEtimJvi8t7Y=FWqavaBz4iJC7v=enZS8wchQdqcDTzXL2A@mail.gmail.com>
References: <CAFFAEtimJvi8t7Y=FWqavaBz4iJC7v=enZS8wchQdqcDTzXL2A@mail.gmail.com>
Message-ID: <69f0d0bc-5838-4360-8705-10e3208b6d8d@email.android.com>

In general, no. Depends on the level of correlation between all values being added. This is a pretty basic statistical theory question.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On July 28, 2014 10:05:27 AM PDT, Reuben Smit <smit.reuben at gmail.com> wrote:
>I am generating a river reach population estimate for a freshwater
>mussel
>by summing point estimates made across a gridded point network (within
>the
>reach) using a generalized linear mixed model framework. I have
>generated
>95% confidence/prediction intervals at each of the ~150,000 point
>locations
>in R. I have summed all of the point estimates to derive the reach
>population estimate, but am unsure how to derive a single confidence
>interval for the population estimate using the 150,000 individual-point
>confidence intervals. My question: Is it statistically valid to simply
>sum
>all the lower estimates and upper estimates to obtain the absolute
>upper
>and lower most population confidence limits?
>
>	[[alternative HTML version deleted]]
>
>_______________________________________________
>R-sig-mixed-models at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From j.hadfield at ed.ac.uk  Tue Jul 29 10:38:19 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 29 Jul 2014 09:38:19 +0100
Subject: [R-sig-ME] MCMCglmm predict function output and interpretation
In-Reply-To: <loom.20140729T013731-783@post.gmane.org>
References: <CAOBBrxNqrTGCz0xo8yB4_xoVGeZqKPut+tSJQ+o+sKGb7VCGGQ@mail.gmail.com>
	<20140728085203.27163zhcp5vjj8kk@www.staffmail.ed.ac.uk>
	<loom.20140729T013731-783@post.gmane.org>
Message-ID: <20140729093819.11565yde434h73go@www.staffmail.ed.ac.uk>

Hi Justine,

If you get the predictions on the link scale, and denote these as  
eta_1 and  and eta_635 for the first observation, then

Pr(A) = 1/(1+exp(eta_1)+exp(eta_635))
Pr(B) = exp(eta_1)/(1+exp(eta_1)+exp(eta_635))
Pr(C) = exp(eta_635)/(1+exp(eta_1)+exp(eta_635))

There is some code for doing this (and marginalising any random  
effects) in the CourseNotes (p97 after Eq. 5.7).

Cheers,

Jarrod


Quoting Justine <jsmith5 at ucsc.edu> on Mon, 28 Jul 2014 23:45:09 +0000 (UTC):

> Jarrod Hadfield <j.hadfield at ...> writes:
>
>>
>> Hi Justine,
>>
>> The first 634 predictions are for B vs A, and the second 634 are for C
>> vs A. If you want the predicted probabilities of falling in category
>> A, B or C you'll have to do it by hand I'm afraid.
>>
>> Cheers,
>>
>> Jarrod
>>
>
> Hi Jarrod,
>
> Thanks so much for clearing that up. Just to make sure I'm absolutely clear,
> if column 1 is 0.228, and column 635 is 0.092, than for data point #1 the
> probability option B is more likely than option A is 0.228 and C more likely
> than A is 0.092? Does this indicate that A (the reference value) is the most
> likely? Can I calculate its relative probability by subtracting the other
> two values from 1? I'm happy to assign the categories by hand, but I want to
> make sure I am interpreting the output correctly.
>
> Thanks again,
>
> Justine
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From Farrar.David at epa.gov  Tue Jul 29 15:26:13 2014
From: Farrar.David at epa.gov (Farrar, David)
Date: Tue, 29 Jul 2014 13:26:13 +0000
Subject: [R-sig-ME] Calculating upper and lower confidence limits on
	a	population estimate derived from multiple point estimates
In-Reply-To: <69f0d0bc-5838-4360-8705-10e3208b6d8d@email.android.com>
References: <CAFFAEtimJvi8t7Y=FWqavaBz4iJC7v=enZS8wchQdqcDTzXL2A@mail.gmail.com>
	<69f0d0bc-5838-4360-8705-10e3208b6d8d@email.android.com>
Message-ID: <b76225d7d7b54d6092db5a9387b1b624@BY2PR09MB079.namprd09.prod.outlook.com>


Do you have a model for autocorrelation along stream networks? If you do you should be in position for parametric bootstrap.  If you don't, something to consider may be the SSN package.  I haven't used that but I know some people who are want to try. 

cheers,
David


-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Jeff Newmiller
Sent: Monday, July 28, 2014 9:47 PM
To: Reuben Smit; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Calculating upper and lower confidence limits on a population estimate derived from multiple point estimates

In general, no. Depends on the level of correlation between all values being added. This is a pretty basic statistical theory question.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------
Sent from my phone. Please excuse my brevity.

On July 28, 2014 10:05:27 AM PDT, Reuben Smit <smit.reuben at gmail.com> wrote:
>I am generating a river reach population estimate for a freshwater 
>mussel by summing point estimates made across a gridded point network 
>(within the
>reach) using a generalized linear mixed model framework. I have 
>generated 95% confidence/prediction intervals at each of the ~150,000 
>point locations in R. I have summed all of the point estimates to 
>derive the reach population estimate, but am unsure how to derive a 
>single confidence interval for the population estimate using the 
>150,000 individual-point confidence intervals. My question: Is it 
>statistically valid to simply sum all the lower estimates and upper 
>estimates to obtain the absolute upper and lower most population 
>confidence limits?
>
>	[[alternative HTML version deleted]]
>
>_______________________________________________
>R-sig-mixed-models at r-project.org mailing list 
>https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From jbaldwin at fs.fed.us  Tue Jul 29 16:04:18 2014
From: jbaldwin at fs.fed.us (Baldwin, Jim -FS)
Date: Tue, 29 Jul 2014 14:04:18 +0000
Subject: [R-sig-ME] Calculating upper and lower confidence limits on a
 population estimate derived from multiple point estimates
In-Reply-To: <CAFFAEtimJvi8t7Y=FWqavaBz4iJC7v=enZS8wchQdqcDTzXL2A@mail.gmail.com>
References: <CAFFAEtimJvi8t7Y=FWqavaBz4iJC7v=enZS8wchQdqcDTzXL2A@mail.gmail.com>
Message-ID: <DDC5EC9B78340042B0D5A0C3789D456919B066DB@001FSN2MPN1-063.001f.mgd2.msft.net>

I wonder if the following publication might be of use: http://www.treesearch.fs.fed.us/pubs/40477.  The paper gives conditions where the spatial covariance structure can be ignored when performing a model-based inference.  Essentially only the estimated variability of the coefficients in the prediction equation are considered (again, when certain conditions are satisfied).

Jim


-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Reuben Smit
Sent: Monday, July 28, 2014 10:05 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Calculating upper and lower confidence limits on a population estimate derived from multiple point estimates

I am generating a river reach population estimate for a freshwater mussel by summing point estimates made across a gridded point network (within the
reach) using a generalized linear mixed model framework. I have generated 95% confidence/prediction intervals at each of the ~150,000 point locations in R. I have summed all of the point estimates to derive the reach population estimate, but am unsure how to derive a single confidence interval for the population estimate using the 150,000 individual-point confidence intervals. My question: Is it statistically valid to simply sum all the lower estimates and upper estimates to obtain the absolute upper and lower most population confidence limits?

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models




This electronic message contains information generated by the USDA solely for the intended recipients. Any unauthorized interception of this message or the use or disclosure of the information it contains may violate the law and subject the violator to civil or criminal penalties. If you believe you have received this message in error, please notify the sender and delete the email immediately.


From jsmith5 at ucsc.edu  Tue Jul 29 19:55:28 2014
From: jsmith5 at ucsc.edu (Justine Smith)
Date: Tue, 29 Jul 2014 10:55:28 -0700
Subject: [R-sig-ME] MCMCglmm predict function output and interpretation
In-Reply-To: <20140729093819.11565yde434h73go@www.staffmail.ed.ac.uk>
References: <CAOBBrxNqrTGCz0xo8yB4_xoVGeZqKPut+tSJQ+o+sKGb7VCGGQ@mail.gmail.com>
	<20140728085203.27163zhcp5vjj8kk@www.staffmail.ed.ac.uk>
	<loom.20140729T013731-783@post.gmane.org>
	<20140729093819.11565yde434h73go@www.staffmail.ed.ac.uk>
Message-ID: <CAOBBrxNGPA09K7yQ_DVke7mUHnb10CpB2QqfP2cW=q-Jv_U1vw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140729/312a9697/attachment.pl>

From j.hadfield at ed.ac.uk  Tue Jul 29 21:04:22 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 29 Jul 2014 20:04:22 +0100
Subject: [R-sig-ME] MCMCglmm predict function output and interpretation
In-Reply-To: <CAOBBrxNGPA09K7yQ_DVke7mUHnb10CpB2QqfP2cW=q-Jv_U1vw@mail.gmail.com>
References: <CAOBBrxNqrTGCz0xo8yB4_xoVGeZqKPut+tSJQ+o+sKGb7VCGGQ@mail.gmail.com>
	<20140728085203.27163zhcp5vjj8kk@www.staffmail.ed.ac.uk>
	<loom.20140729T013731-783@post.gmane.org>
	<20140729093819.11565yde434h73go@www.staffmail.ed.ac.uk>
	<CAOBBrxNGPA09K7yQ_DVke7mUHnb10CpB2QqfP2cW=q-Jv_U1vw@mail.gmail.com>
Message-ID: <20140729200422.17530uarvmoogwfk@www.staffmail.ed.ac.uk>

Hi Justine,

eta_1 and eta_635 can be negative. If you make them both -10 for  
example, then Pr(A) is close to one.

jarrid


Quoting Justine Smith <jsmith5 at ucsc.edu> on Tue, 29 Jul 2014 10:55:28 -0700:

> Hi Jarrod,
>
> This is great. I have one final question: using the above equations, I am
> finding it impossible for Pr(A) to ever be the greatest (in fact, Pr(C ) is
> always largest using my data set). Even if I put in tiny values for eta_1
> and eta_635 (0.0001 and 0.0001), all values just become essentially equal.
> See results from some made-up combinations below:
>
>
>   eta_1 eta_635 Pr (A)  Pr (B) Pr (C )  0.0001 0.0001 0.333311111
> 0.333344444 0.333344444  0.0001 0.5 0.274061108 0.274088515 0.451850377  0.5
> 0.0001 0.274061108 0.451850377 0.274088515
>
> Why would this be the case? I know from the data that A is in fact the most
> common outcome.
>
> Best,
> Justine
>
>
>
> On Tue, Jul 29, 2014 at 1:38 AM, Jarrod Hadfield <j.hadfield at ed.ac.uk>
> wrote:
>
>> Hi Justine,
>>
>> If you get the predictions on the link scale, and denote these as eta_1
>> and  and eta_635 for the first observation, then
>>
>> Pr(A) = 1/(1+exp(eta_1)+exp(eta_635))
>> Pr(B) = exp(eta_1)/(1+exp(eta_1)+exp(eta_635))
>> Pr(C) = exp(eta_635)/(1+exp(eta_1)+exp(eta_635))
>>
>> There is some code for doing this (and marginalising any random effects)
>> in the CourseNotes (p97 after Eq. 5.7).
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>> Quoting Justine <jsmith5 at ucsc.edu> on Mon, 28 Jul 2014 23:45:09 +0000
>> (UTC):
>>
>>  Jarrod Hadfield <j.hadfield at ...> writes:
>>>
>>>
>>>> Hi Justine,
>>>>
>>>> The first 634 predictions are for B vs A, and the second 634 are for C
>>>> vs A. If you want the predicted probabilities of falling in category
>>>> A, B or C you'll have to do it by hand I'm afraid.
>>>>
>>>> Cheers,
>>>>
>>>> Jarrod
>>>>
>>>>
>>> Hi Jarrod,
>>>
>>> Thanks so much for clearing that up. Just to make sure I'm absolutely
>>> clear,
>>> if column 1 is 0.228, and column 635 is 0.092, than for data point #1 the
>>> probability option B is more likely than option A is 0.228 and C more
>>> likely
>>> than A is 0.092? Does this indicate that A (the reference value) is the
>>> most
>>> likely? Can I calculate its relative probability by subtracting the other
>>> two values from 1? I'm happy to assign the categories by hand, but I want
>>> to
>>> make sure I am interpreting the output correctly.
>>>
>>> Thanks again,
>>>
>>> Justine
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>>
>>
>>
>> --
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>>
>>
>
>
> --
> Justine A. Smith
> PhD Student
> Department of Environmental Studies
> University of California, Santa Cruz
> 1156 High St.
> Santa Cruz, CA 95064
> people.ucsc.edu/~jsmith5
> santacruzpumas.org
> conservationscats.com
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From jsmith5 at ucsc.edu  Tue Jul 29 21:19:19 2014
From: jsmith5 at ucsc.edu (Justine Smith)
Date: Tue, 29 Jul 2014 12:19:19 -0700
Subject: [R-sig-ME] MCMCglmm predict function output and interpretation
In-Reply-To: <20140729200422.17530uarvmoogwfk@www.staffmail.ed.ac.uk>
References: <CAOBBrxNqrTGCz0xo8yB4_xoVGeZqKPut+tSJQ+o+sKGb7VCGGQ@mail.gmail.com>
	<20140728085203.27163zhcp5vjj8kk@www.staffmail.ed.ac.uk>
	<loom.20140729T013731-783@post.gmane.org>
	<20140729093819.11565yde434h73go@www.staffmail.ed.ac.uk>
	<CAOBBrxNGPA09K7yQ_DVke7mUHnb10CpB2QqfP2cW=q-Jv_U1vw@mail.gmail.com>
	<20140729200422.17530uarvmoogwfk@www.staffmail.ed.ac.uk>
Message-ID: <CAOBBrxNG1JNnvq6WrtSZKKHwB_8ipuqVheF3rxougU2fOeW6kw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140729/c448a119/attachment.pl>

From Berin.Mackenzie at environment.nsw.gov.au  Wed Jul 30 05:03:32 2014
From: Berin.Mackenzie at environment.nsw.gov.au (Berin Mackenzie)
Date: Wed, 30 Jul 2014 03:03:32 +0000
Subject: [R-sig-ME] Pseudoreplication in a factorial GLM with a proportional
 response variable and categorical predictor variables
Message-ID: <1770501439A6C74C9141CBA9004FCA8180166B02@LIDCOEX03.dec.int>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140730/27294f64/attachment.pl>

From nburgoyne at mango-solutions.com  Wed Jul 30 10:25:53 2014
From: nburgoyne at mango-solutions.com (Nicholas Burgoyne)
Date: Wed, 30 Jul 2014 08:25:53 +0000
Subject: [R-sig-ME] lme and lmer
Message-ID: <FEC647A5D0EB3749B5BB9A174F06F43913D1EA67@mexchange.Mango.local>

Dear all,

I have been kindly redirected here by Ben Bolker, thank you for your assistance so far!

I apologise for posting what is probably quite a benign query, but for the life of me I can't find an answer.

I have been asked to explain the differences in the variance-covariance data in an identical test in Splus (lme) and R (lmer in lme4).

The input data is standard (from MASS), and identical (I've checked), the test is as similar as I can make it (code below).

The same output (to a high degree of precision) is obtained for all of the output values (not just that displaced here), expect for the vcov data for the Intercept with itself. The effect is therefore that the standard deviations of the fixed values are quite different!

I am using splus 6.2, R 3.0.2 and lme4 v 1.1-7 (see sessionInfo dump later on), the contrasts in splus are set to treatment/poly.

Any advice you could give me would be very helpful.

Kind regards,

Nick Burgoyne

#########
#In Spus#
#########
>options(contrasts=c("contr.treatment", "contr.poly"))
>library(MASS)
>coop <- coop
>lme <- lme(fixed=Conc ~ Lab, data=coop, random = ~ Bat, subset=coop$Spc=="S1")
> lme
Linear mixed-effects model fit by REML
  Data: coop 
  Subset: coop$Spc == "S1" 
  Log-restricted-likelihood: 20.27187
  Fixed: Conc ~ Lab 
 (Intercept)      LabL2 LabL3 LabL4     LabL5     LabL6 
    0.319999 0.08166667  0.04  0.68 0.1233333 0.2033333

Random effects:
Formula:  ~ Bat | 1
Structure: General positive-definite
                  StdDev   Corr        
(Intercept) 0.1401167895 (Intr) BatB2 
      BatB2 0.0001407246  0.000       
      BatB3 0.0003628541  0.000 -0.072
   Residual 0.1029156551              

Number of Observations: 36
Number of Groups: 1
> lme$varFix
             (Intercept)        LabL2        LabL3        LabL4        LabL5        LabL6 
(Intercept)  0.021398003 -0.001765272 -0.001765272 -0.001765272 -0.001765272 -0.001765272
      LabL2 -0.001765272  0.003530544  0.001765272  0.001765272  0.001765272  0.001765272
      LabL3 -0.001765272  0.001765272  0.003530544  0.001765272  0.001765272  0.001765272
      LabL4 -0.001765272  0.001765272  0.001765272  0.003530544  0.001765272  0.001765272
     LabL5 -0.001765272  0.001765272  0.001765272  0.001765272  0.003530544  0.001765272
      LabL6 -0.001765272  0.001765272  0.001765272  0.001765272  0.001765272  0.003530544

######
#In R#
######
>library(lme4)
>library(MASS)
>coop <- coop
>lme <- lmer(formula=Conc ~ Lab + (1|Bat),  data=coop, subset=coop$Spc=="S1")
>lme
Linear mixed model fit by REML ['lmerMod']
Formula: Conc ~ Lab + (1 | Bat)
   Data: coop
Subset: coop$Spc == "S1"
REML criterion at convergence: -40.5438
Random effects:
Groups   Name        Std.Dev.
Bat      (Intercept) 0.0000  
 Residual             0.1029  
Number of obs: 36, groups:  Bat, 3
Fixed Effects:
(Intercept)        LabL2        LabL3        LabL4        LabL5        LabL6  
    0.32000      0.08167      0.04000      0.68000      0.12333      0.20333
>vcov(lme)
6 x 6 Matrix of class "dpoMatrix"
             (Intercept)        LabL2        LabL3        LabL4        LabL5
(Intercept)  0.001765278 -0.001765278 -0.001765278 -0.001765278 -0.001765278
LabL2       -0.001765278  0.003530556  0.001765278  0.001765278  0.001765278
LabL3       -0.001765278  0.001765278  0.003530556  0.001765278  0.001765278
LabL4       -0.001765278  0.001765278  0.001765278  0.003530556  0.001765278
LabL5       -0.001765278  0.001765278  0.001765278  0.001765278  0.003530556
LabL6       -0.001765278  0.001765278  0.001765278  0.001765278  0.001765278
                   LabL6
(Intercept) -0.001765278
LabL2        0.001765278
LabL3        0.001765278
LabL4        0.001765278
LabL5        0.001765278
LabL6        0.003530556

> sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: i386-w64-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United Kingdom.1252 
[2] LC_CTYPE=English_United Kingdom.1252   
[3] LC_MONETARY=English_United Kingdom.1252
[4] LC_NUMERIC=C                           
[5] LC_TIME=English_United Kingdom.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] MASS_7.3-29  lme4_1.1-7   Rcpp_0.11.2  Matrix_1.1-4

loaded via a namespace (and not attached):
[1] grid_3.0.2      lattice_0.20-29 minqa_1.2.3     nlme_3.1-111   
[5] nloptr_1.0.0    splines_3.0.2   tools_3.0.2

--
Nicholas Burgoyne
E:nburgoyne at mango-solutions.com	T:+44 (0)1249 705 450
W:www.mango-solutions.com	
 

________________________________________
  EARL Conference, London 15-17 September 2014 - Hurry as tickets for the event are selling fast
  Mango are delighted to announce the inaugural EARL Conference (Effective Applications of the R Language) 
  For further details please visit  www.earl-conference.com or email  questions at earl-conference.com 

________________________________________

-- 

LEGAL NOTICE 

This message is intended for the use of the named recipient(s) only and may contain 
confidential and / or privileged information. If you are not the intended recipient, please 
contact the sender and delete this message. Any unauthorised use of the information 
contained in this message is prohibited. 

Mango Business Solutions Limited is registered in England under No. 4560258 with its 
registered office at Suite 3, Middlesex House, Rutherford Close, Stevenage, Herts, SG1 2EF, 
UK. 


PLEASE CONSIDER THE ENVIRONMENT BEFORE PRINTING THIS EMAIL

Nicholas Burgoyne
  
Tel. +44 (0)1249 705 450?| Mobile. 
mailto:nburgoyne at mango-solutions.com?| www.mango-solutions.com



2 Methuen Park
Chippenham
Wiltshire 
SN14 OGB
UK

--

LEGAL NOTICE

This message is intended for the use of the named recipient(s) only and may contain
confidential and / or privileged information. If you are not the intended recipient, please
contact the sender and delete this message. Any unauthorised use of the information
contained in this message is prohibited.

Mango Business Solutions Limited is registered in England under No. 4560258 with its
registered office at Suite 3, Middlesex House, Rutherford Close, Stevenage, Herts, SG1 2EF,
UK.

PLEASE CONSIDER THE ENVIRONMENT BEFORE PRINTING THIS EMAIL


From wolfgang.viechtbauer at maastrichtuniversity.nl  Wed Jul 30 10:46:34 2014
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Wed, 30 Jul 2014 10:46:34 +0200
Subject: [R-sig-ME] lme and lmer
In-Reply-To: <FEC647A5D0EB3749B5BB9A174F06F43913D1EA67@mexchange.Mango.local>
References: <FEC647A5D0EB3749B5BB9A174F06F43913D1EA67@mexchange.Mango.local>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730DC97EB11C@UM-MAIL4112.unimaas.nl>

If you want to fit the same models, you should use:

lme <- lme(fixed=Conc ~ Lab, data=coop, random = ~ 1 | Bat, subset=coop$Spc=="S1")

I am surprised that it even ran with 'random = ~ Bat' (lme in R throws an error).

Best,
Wolfgang

--   
Wolfgang Viechtbauer, Ph.D., Statistician   
Department of Psychiatry and Psychology   
School for Mental Health and Neuroscience   
Faculty of Health, Medicine, and Life Sciences   
Maastricht University, P.O. Box 616 (VIJV1)   
6200 MD Maastricht, The Netherlands   
+31 (43) 388-4170 | http://www.wvbauer.com   

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-
> models-bounces at r-project.org] On Behalf Of Nicholas Burgoyne
> Sent: Wednesday, July 30, 2014 10:26
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] lme and lmer
> 
> Dear all,
> 
> I have been kindly redirected here by Ben Bolker, thank you for your
> assistance so far!
> 
> I apologise for posting what is probably quite a benign query, but for
> the life of me I can't find an answer.
> 
> I have been asked to explain the differences in the variance-covariance
> data in an identical test in Splus (lme) and R (lmer in lme4).
> 
> The input data is standard (from MASS), and identical (I've checked), the
> test is as similar as I can make it (code below).
> 
> The same output (to a high degree of precision) is obtained for all of
> the output values (not just that displaced here), expect for the vcov
> data for the Intercept with itself. The effect is therefore that the
> standard deviations of the fixed values are quite different!
> 
> I am using splus 6.2, R 3.0.2 and lme4 v 1.1-7 (see sessionInfo dump
> later on), the contrasts in splus are set to treatment/poly.
> 
> Any advice you could give me would be very helpful.
> 
> Kind regards,
> 
> Nick Burgoyne
> 
> #########
> #In Spus#
> #########
> >options(contrasts=c("contr.treatment", "contr.poly"))
> >library(MASS)
> >coop <- coop
> >lme <- lme(fixed=Conc ~ Lab, data=coop, random = ~ Bat,
> subset=coop$Spc=="S1")
> > lme
> Linear mixed-effects model fit by REML
>   Data: coop
>   Subset: coop$Spc == "S1"
>   Log-restricted-likelihood: 20.27187
>   Fixed: Conc ~ Lab
>  (Intercept)      LabL2 LabL3 LabL4     LabL5     LabL6
>     0.319999 0.08166667  0.04  0.68 0.1233333 0.2033333
> 
> Random effects:
> Formula:  ~ Bat | 1
> Structure: General positive-definite
>                   StdDev   Corr
> (Intercept) 0.1401167895 (Intr) BatB2
>       BatB2 0.0001407246  0.000
>       BatB3 0.0003628541  0.000 -0.072
>    Residual 0.1029156551
> 
> Number of Observations: 36
> Number of Groups: 1
> > lme$varFix
>              (Intercept)        LabL2        LabL3        LabL4
> LabL5        LabL6
> (Intercept)  0.021398003 -0.001765272 -0.001765272 -0.001765272 -
> 0.001765272 -0.001765272
>       LabL2 -0.001765272  0.003530544  0.001765272  0.001765272
> 0.001765272  0.001765272
>       LabL3 -0.001765272  0.001765272  0.003530544  0.001765272
> 0.001765272  0.001765272
>       LabL4 -0.001765272  0.001765272  0.001765272  0.003530544
> 0.001765272  0.001765272
>      LabL5 -0.001765272  0.001765272  0.001765272  0.001765272
> 0.003530544  0.001765272
>       LabL6 -0.001765272  0.001765272  0.001765272  0.001765272
> 0.001765272  0.003530544
> 
> ######
> #In R#
> ######
> >library(lme4)
> >library(MASS)
> >coop <- coop
> >lme <- lmer(formula=Conc ~ Lab + (1|Bat),  data=coop,
> subset=coop$Spc=="S1")
> >lme
> Linear mixed model fit by REML ['lmerMod']
> Formula: Conc ~ Lab + (1 | Bat)
>    Data: coop
> Subset: coop$Spc == "S1"
> REML criterion at convergence: -40.5438
> Random effects:
> Groups   Name        Std.Dev.
> Bat      (Intercept) 0.0000
>  Residual             0.1029
> Number of obs: 36, groups:  Bat, 3
> Fixed Effects:
> (Intercept)        LabL2        LabL3        LabL4        LabL5
> LabL6
>     0.32000      0.08167      0.04000      0.68000      0.12333
> 0.20333
> >vcov(lme)
> 6 x 6 Matrix of class "dpoMatrix"
>              (Intercept)        LabL2        LabL3        LabL4
> LabL5
> (Intercept)  0.001765278 -0.001765278 -0.001765278 -0.001765278 -
> 0.001765278
> LabL2       -0.001765278  0.003530556  0.001765278  0.001765278
> 0.001765278
> LabL3       -0.001765278  0.001765278  0.003530556  0.001765278
> 0.001765278
> LabL4       -0.001765278  0.001765278  0.001765278  0.003530556
> 0.001765278
> LabL5       -0.001765278  0.001765278  0.001765278  0.001765278
> 0.003530556
> LabL6       -0.001765278  0.001765278  0.001765278  0.001765278
> 0.001765278
>                    LabL6
> (Intercept) -0.001765278
> LabL2        0.001765278
> LabL3        0.001765278
> LabL4        0.001765278
> LabL5        0.001765278
> LabL6        0.003530556
> 
> > sessionInfo()
> R version 3.0.2 (2013-09-25)
> Platform: i386-w64-mingw32/i386 (32-bit)
> 
> locale:
> [1] LC_COLLATE=English_United Kingdom.1252
> [2] LC_CTYPE=English_United Kingdom.1252
> [3] LC_MONETARY=English_United Kingdom.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United Kingdom.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] MASS_7.3-29  lme4_1.1-7   Rcpp_0.11.2  Matrix_1.1-4
> 
> loaded via a namespace (and not attached):
> [1] grid_3.0.2      lattice_0.20-29 minqa_1.2.3     nlme_3.1-111
> [5] nloptr_1.0.0    splines_3.0.2   tools_3.0.2
> 
> --
> Nicholas Burgoyne
> E:nburgoyne at mango-solutions.com	T:+44 (0)1249 705 450
> W:www.mango-solutions.com


From nburgoyne at mango-solutions.com  Wed Jul 30 11:00:15 2014
From: nburgoyne at mango-solutions.com (Nicholas Burgoyne)
Date: Wed, 30 Jul 2014 09:00:15 +0000
Subject: [R-sig-ME] lme and lmer
In-Reply-To: <077E31A57DA26E46AB0D493C9966AC730DC97EB11C@UM-MAIL4112.unimaas.nl>
References: <FEC647A5D0EB3749B5BB9A174F06F43913D1EA67@mexchange.Mango.local>
	<077E31A57DA26E46AB0D493C9966AC730DC97EB11C@UM-MAIL4112.unimaas.nl>
Message-ID: <FEC647A5D0EB3749B5BB9A174F06F43913D1EAD2@mexchange.Mango.local>

Thank you, that explains everything!

Nick

-----Original Message-----
From: Viechtbauer Wolfgang (STAT) [mailto:wolfgang.viechtbauer at maastrichtuniversity.nl] 
Sent: 30 July 2014 09:47
To: Nicholas Burgoyne; r-sig-mixed-models at r-project.org
Subject: RE: lme and lmer

If you want to fit the same models, you should use:

lme <- lme(fixed=Conc ~ Lab, data=coop, random = ~ 1 | Bat, subset=coop$Spc=="S1")

I am surprised that it even ran with 'random = ~ Bat' (lme in R throws an error).

Best,
Wolfgang

--   
Wolfgang Viechtbauer, Ph.D., Statistician   
Department of Psychiatry and Psychology   
School for Mental Health and Neuroscience   
Faculty of Health, Medicine, and Life Sciences   
Maastricht University, P.O. Box 616 (VIJV1)   
6200 MD Maastricht, The Netherlands   
+31 (43) 388-4170 | http://www.wvbauer.com   

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed- 
> models-bounces at r-project.org] On Behalf Of Nicholas Burgoyne
> Sent: Wednesday, July 30, 2014 10:26
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] lme and lmer
> 
> Dear all,
> 
> I have been kindly redirected here by Ben Bolker, thank you for your 
> assistance so far!
> 
> I apologise for posting what is probably quite a benign query, but for 
> the life of me I can't find an answer.
> 
> I have been asked to explain the differences in the 
> variance-covariance data in an identical test in Splus (lme) and R (lmer in lme4).
> 
> The input data is standard (from MASS), and identical (I've checked), 
> the test is as similar as I can make it (code below).
> 
> The same output (to a high degree of precision) is obtained for all of 
> the output values (not just that displaced here), expect for the vcov 
> data for the Intercept with itself. The effect is therefore that the 
> standard deviations of the fixed values are quite different!
> 
> I am using splus 6.2, R 3.0.2 and lme4 v 1.1-7 (see sessionInfo dump 
> later on), the contrasts in splus are set to treatment/poly.
> 
> Any advice you could give me would be very helpful.
> 
> Kind regards,
> 
> Nick Burgoyne
> 
> #########
> #In Spus#
> #########
> >options(contrasts=c("contr.treatment", "contr.poly"))
> >library(MASS)
> >coop <- coop
> >lme <- lme(fixed=Conc ~ Lab, data=coop, random = ~ Bat,
> subset=coop$Spc=="S1")
> > lme
> Linear mixed-effects model fit by REML
>   Data: coop
>   Subset: coop$Spc == "S1"
>   Log-restricted-likelihood: 20.27187
>   Fixed: Conc ~ Lab
>  (Intercept)      LabL2 LabL3 LabL4     LabL5     LabL6
>     0.319999 0.08166667  0.04  0.68 0.1233333 0.2033333
> 
> Random effects:
> Formula:  ~ Bat | 1
> Structure: General positive-definite
>                   StdDev   Corr
> (Intercept) 0.1401167895 (Intr) BatB2
>       BatB2 0.0001407246  0.000
>       BatB3 0.0003628541  0.000 -0.072
>    Residual 0.1029156551
> 
> Number of Observations: 36
> Number of Groups: 1
> > lme$varFix
>              (Intercept)        LabL2        LabL3        LabL4
> LabL5        LabL6
> (Intercept)  0.021398003 -0.001765272 -0.001765272 -0.001765272 -
> 0.001765272 -0.001765272
>       LabL2 -0.001765272  0.003530544  0.001765272  0.001765272
> 0.001765272  0.001765272
>       LabL3 -0.001765272  0.001765272  0.003530544  0.001765272
> 0.001765272  0.001765272
>       LabL4 -0.001765272  0.001765272  0.001765272  0.003530544
> 0.001765272  0.001765272
>      LabL5 -0.001765272  0.001765272  0.001765272  0.001765272
> 0.003530544  0.001765272
>       LabL6 -0.001765272  0.001765272  0.001765272  0.001765272
> 0.001765272  0.003530544
> 
> ######
> #In R#
> ######
> >library(lme4)
> >library(MASS)
> >coop <- coop
> >lme <- lmer(formula=Conc ~ Lab + (1|Bat),  data=coop,
> subset=coop$Spc=="S1")
> >lme
> Linear mixed model fit by REML ['lmerMod']
> Formula: Conc ~ Lab + (1 | Bat)
>    Data: coop
> Subset: coop$Spc == "S1"
> REML criterion at convergence: -40.5438 Random effects:
> Groups   Name        Std.Dev.
> Bat      (Intercept) 0.0000
>  Residual             0.1029
> Number of obs: 36, groups:  Bat, 3
> Fixed Effects:
> (Intercept)        LabL2        LabL3        LabL4        LabL5
> LabL6
>     0.32000      0.08167      0.04000      0.68000      0.12333
> 0.20333
> >vcov(lme)
> 6 x 6 Matrix of class "dpoMatrix"
>              (Intercept)        LabL2        LabL3        LabL4
> LabL5
> (Intercept)  0.001765278 -0.001765278 -0.001765278 -0.001765278 -
> 0.001765278
> LabL2       -0.001765278  0.003530556  0.001765278  0.001765278
> 0.001765278
> LabL3       -0.001765278  0.001765278  0.003530556  0.001765278
> 0.001765278
> LabL4       -0.001765278  0.001765278  0.001765278  0.003530556
> 0.001765278
> LabL5       -0.001765278  0.001765278  0.001765278  0.001765278
> 0.003530556
> LabL6       -0.001765278  0.001765278  0.001765278  0.001765278
> 0.001765278
>                    LabL6
> (Intercept) -0.001765278
> LabL2        0.001765278
> LabL3        0.001765278
> LabL4        0.001765278
> LabL5        0.001765278
> LabL6        0.003530556
> 
> > sessionInfo()
> R version 3.0.2 (2013-09-25)
> Platform: i386-w64-mingw32/i386 (32-bit)
> 
> locale:
> [1] LC_COLLATE=English_United Kingdom.1252 [2] LC_CTYPE=English_United 
> Kingdom.1252 [3] LC_MONETARY=English_United Kingdom.1252 [4] 
> LC_NUMERIC=C [5] LC_TIME=English_United Kingdom.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] MASS_7.3-29  lme4_1.1-7   Rcpp_0.11.2  Matrix_1.1-4
> 
> loaded via a namespace (and not attached):
> [1] grid_3.0.2      lattice_0.20-29 minqa_1.2.3     nlme_3.1-111
> [5] nloptr_1.0.0    splines_3.0.2   tools_3.0.2
> 
> --
> Nicholas Burgoyne
> E:nburgoyne at mango-solutions.com	T:+44 (0)1249 705 450
> W:www.mango-solutions.com

--

LEGAL NOTICE\ \ This message is intended for the use of ...{{dropped:18}}


From S.Ellison at LGCGroup.com  Wed Jul 30 14:43:56 2014
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Wed, 30 Jul 2014 13:43:56 +0100
Subject: [R-sig-ME] lme and lmer
In-Reply-To: <FEC647A5D0EB3749B5BB9A174F06F43913D1EAD2@mexchange.Mango.local>
References: <FEC647A5D0EB3749B5BB9A174F06F43913D1EA67@mexchange.Mango.local>
	<077E31A57DA26E46AB0D493C9966AC730DC97EB11C@UM-MAIL4112.unimaas.nl>
	<FEC647A5D0EB3749B5BB9A174F06F43913D1EAD2@mexchange.Mango.local>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED6062C90983@GOLD.corp.lgc-group.com>



> Thank you, that explains everything!
... except the model?

This is an aside to the OP's question, but ?coop says - with some reason given that run to run effects tend to be random inside analytical chemistry labs - that batch is _nested_ in Spc/Lab.

random =~1|Bat doesn't do that; it leaves batch crossed with Lab. You'd surely have to create a Lab:Bat interaction factor and put that in the random part to achieve a nested model.

Steve Ellison

> 
> Nick
> 
> -----Original Message-----
> From: Viechtbauer Wolfgang (STAT)
> [mailto:wolfgang.viechtbauer at maastrichtuniversity.nl]
> Sent: 30 July 2014 09:47
> To: Nicholas Burgoyne; r-sig-mixed-models at r-project.org
> Subject: RE: lme and lmer
> 
> If you want to fit the same models, you should use:
> 
> lme <- lme(fixed=Conc ~ Lab, data=coop, random = ~ 1 | Bat,
> subset=coop$Spc=="S1")
> 
> I am surprised that it even ran with 'random = ~ Bat' (lme in R throws an
> error).
> 
> Best,
> Wolfgang
> 
> --
> Wolfgang Viechtbauer, Ph.D., Statistician
> Department of Psychiatry and Psychology
> School for Mental Health and Neuroscience
> Faculty of Health, Medicine, and Life Sciences
> Maastricht University, P.O. Box 616 (VIJV1)
> 6200 MD Maastricht, The Netherlands
> +31 (43) 388-4170 |
> http://webdefence.global.blackspider.com/urlwrap/?q=AXicE2Rm4DNkYIjxY
> GAoyqk0MknUKy4q08tNzMxJzs8rKcrP0UvOz2UoNgu1NPI2MTQwsDQ2NGU
> o1kvNyckszs9zyElPTi_KLy0Aq8ooKSmw0tcvLy_XKy9LSixNLQILQwAATP4fJA&
> Z
> 
> > -----Original Message-----
> > From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-
> > models-bounces at r-project.org] On Behalf Of Nicholas Burgoyne
> > Sent: Wednesday, July 30, 2014 10:26
> > To: r-sig-mixed-models at r-project.org
> > Subject: [R-sig-ME] lme and lmer
> >
> > Dear all,
> >
> > I have been kindly redirected here by Ben Bolker, thank you for your
> > assistance so far!
> >
> > I apologise for posting what is probably quite a benign query, but for
> > the life of me I can't find an answer.
> >
> > I have been asked to explain the differences in the
> > variance-covariance data in an identical test in Splus (lme) and R (lmer in
> lme4).
> >
> > The input data is standard (from MASS), and identical (I've checked),
> > the test is as similar as I can make it (code below).
> >
> > The same output (to a high degree of precision) is obtained for all of
> > the output values (not just that displaced here), expect for the vcov
> > data for the Intercept with itself. The effect is therefore that the
> > standard deviations of the fixed values are quite different!
> >
> > I am using splus 6.2, R 3.0.2 and lme4 v 1.1-7 (see sessionInfo dump
> > later on), the contrasts in splus are set to treatment/poly.
> >
> > Any advice you could give me would be very helpful.
> >
> > Kind regards,
> >
> > Nick Burgoyne
> >
> > #########
> > #In Spus#
> > #########
> > >options(contrasts=c("contr.treatment", "contr.poly"))
> > >library(MASS)
> > >coop <- coop
> > >lme <- lme(fixed=Conc ~ Lab, data=coop, random = ~ Bat,
> > subset=coop$Spc=="S1")
> > > lme
> > Linear mixed-effects model fit by REML
> >   Data: coop
> >   Subset: coop$Spc == "S1"
> >   Log-restricted-likelihood: 20.27187
> >   Fixed: Conc ~ Lab
> >  (Intercept)      LabL2 LabL3 LabL4     LabL5     LabL6
> >     0.319999 0.08166667  0.04  0.68 0.1233333 0.2033333
> >
> > Random effects:
> > Formula:  ~ Bat | 1
> > Structure: General positive-definite
> >                   StdDev   Corr
> > (Intercept) 0.1401167895 (Intr) BatB2
> >       BatB2 0.0001407246  0.000
> >       BatB3 0.0003628541  0.000 -0.072
> >    Residual 0.1029156551
> >
> > Number of Observations: 36
> > Number of Groups: 1
> > > lme$varFix
> >              (Intercept)        LabL2        LabL3        LabL4
> > LabL5        LabL6
> > (Intercept)  0.021398003 -0.001765272 -0.001765272 -0.001765272 -
> > 0.001765272 -0.001765272
> >       LabL2 -0.001765272  0.003530544  0.001765272  0.001765272
> > 0.001765272  0.001765272
> >       LabL3 -0.001765272  0.001765272  0.003530544  0.001765272
> > 0.001765272  0.001765272
> >       LabL4 -0.001765272  0.001765272  0.001765272  0.003530544
> > 0.001765272  0.001765272
> >      LabL5 -0.001765272  0.001765272  0.001765272  0.001765272
> > 0.003530544  0.001765272
> >       LabL6 -0.001765272  0.001765272  0.001765272  0.001765272
> > 0.001765272  0.003530544
> >
> > ######
> > #In R#
> > ######
> > >library(lme4)
> > >library(MASS)
> > >coop <- coop
> > >lme <- lmer(formula=Conc ~ Lab + (1|Bat),  data=coop,
> > subset=coop$Spc=="S1")
> > >lme
> > Linear mixed model fit by REML ['lmerMod']
> > Formula: Conc ~ Lab + (1 | Bat)
> >    Data: coop
> > Subset: coop$Spc == "S1"
> > REML criterion at convergence: -40.5438 Random effects:
> > Groups   Name        Std.Dev.
> > Bat      (Intercept) 0.0000
> >  Residual             0.1029
> > Number of obs: 36, groups:  Bat, 3
> > Fixed Effects:
> > (Intercept)        LabL2        LabL3        LabL4        LabL5
> > LabL6
> >     0.32000      0.08167      0.04000      0.68000      0.12333
> > 0.20333
> > >vcov(lme)
> > 6 x 6 Matrix of class "dpoMatrix"
> >              (Intercept)        LabL2        LabL3        LabL4
> > LabL5
> > (Intercept)  0.001765278 -0.001765278 -0.001765278 -0.001765278 -
> > 0.001765278
> > LabL2       -0.001765278  0.003530556  0.001765278  0.001765278
> > 0.001765278
> > LabL3       -0.001765278  0.001765278  0.003530556  0.001765278
> > 0.001765278
> > LabL4       -0.001765278  0.001765278  0.001765278  0.003530556
> > 0.001765278
> > LabL5       -0.001765278  0.001765278  0.001765278  0.001765278
> > 0.003530556
> > LabL6       -0.001765278  0.001765278  0.001765278  0.001765278
> > 0.001765278
> >                    LabL6
> > (Intercept) -0.001765278
> > LabL2        0.001765278
> > LabL3        0.001765278
> > LabL4        0.001765278
> > LabL5        0.001765278
> > LabL6        0.003530556
> >
> > > sessionInfo()
> > R version 3.0.2 (2013-09-25)
> > Platform: i386-w64-mingw32/i386 (32-bit)
> >
> > locale:
> > [1] LC_COLLATE=English_United Kingdom.1252 [2]
> LC_CTYPE=English_United
> > Kingdom.1252 [3] LC_MONETARY=English_United Kingdom.1252 [4]
> > LC_NUMERIC=C [5] LC_TIME=English_United Kingdom.1252
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >
> > other attached packages:
> > [1] MASS_7.3-29  lme4_1.1-7   Rcpp_0.11.2  Matrix_1.1-4
> >
> > loaded via a namespace (and not attached):
> > [1] grid_3.0.2      lattice_0.20-29 minqa_1.2.3     nlme_3.1-111
> > [5] nloptr_1.0.0    splines_3.0.2   tools_3.0.2
> >
> > --
> > Nicholas Burgoyne
> > E:nburgoyne at mango-solutions.com	T:+44 (0)1249 705 450
> > W:www.mango-solutions.com
> 
> --
> 
> LEGAL NOTICE\ \ This message is intended for the use of ...{{dropped:18}}
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From g.chiara86 at gmail.com  Wed Jul 30 15:12:35 2014
From: g.chiara86 at gmail.com (Chiara Gambi)
Date: Wed, 30 Jul 2014 15:12:35 +0200
Subject: [R-sig-ME] lme4.0 vs. lme4 version 1.1-7: newer version returns
 inflated SE using glmer() with bobyqa optimizer
Message-ID: <CACUeYTGNrzYwv1a5Xh_ZLoRcba4M_6q1UdasnconSmeAJVkipw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140730/a8a7aa63/attachment.pl>

From bbolker at gmail.com  Wed Jul 30 15:57:36 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 30 Jul 2014 09:57:36 -0400
Subject: [R-sig-ME] lme4.0 vs. lme4 version 1.1-7: newer version returns
 inflated SE using glmer() with bobyqa optimizer
In-Reply-To: <CACUeYTGNrzYwv1a5Xh_ZLoRcba4M_6q1UdasnconSmeAJVkipw@mail.gmail.com>
References: <CACUeYTGNrzYwv1a5Xh_ZLoRcba4M_6q1UdasnconSmeAJVkipw@mail.gmail.com>
Message-ID: <53D8F9D0.2010307@gmail.com>

On 14-07-30 09:12 AM, Chiara Gambi wrote:
> Dear all,
> 
> I apologize if this issue has already been covered in the list.
> 
> I am analyzing accuracy data on a picture naming task. Correct responses
> are coded as 1, errors as 0. I have 2 fixed-effects predictors:
> 
> 1. Condition, 3 levels, within participants and items
> 2. Freq_group: 2 levels, within participants but between items
> 
> Here are the contrasts:
> 
> contrasts(joint$Condition)<-cbind(c(-2/3,1/3,1/3), c(0,-1/2,1/2))
> contrasts(joint$Freq_group)<-cbind(c(-0.5,0.5))
> 
> In addition, I have a between-participants continuous predictor
> (E_proficiency_SP: English Spoken Language Proficiency) that has been
> centered, but not scaled.
> 
> I analyzed these data some time ago using a version of lme4 <1. When I ran
> the analyses in R 3.0.3 using lme4.0, I obtained the same output as in my
> old analyses. See below.
> 
> ----------------------------------------------------------------------
> Generalized linear mixed model fit by the Laplace approximation
> Formula: Resp.bin ~ 1 + Freq_group * Condition * E_proficiency_SP + (1
> +      Freq_group * Condition | Subject) + (1 + Condition | Item_numb)
>    Data: joint.NS
>   AIC  BIC logLik deviance
>  2094 2330  -1008     2016
> Random effects:
>  Groups    Name                   Variance  Std.Dev.
> Corr
>  Item_numb (Intercept)            0.9656165
> 0.982658
>            Condition1             1.6699788 1.292277
> -0.035
>            Condition2             0.0077218 0.087874 -0.052
> 1.000
>  Subject   (Intercept)            0.1608360
> 0.401044
>            Freq_group1            0.1649723 0.406168
> -0.417
>            Condition1             0.4448590 0.666978 -0.678
> 0.269
>            Condition2             0.1776654 0.421504  0.274 -0.739
> 0.319
>            Freq_group1:Condition1 0.7216097 0.849476 -0.940  0.701  0.647
> -0.478
>            Freq_group1:Condition2 0.7144539 0.845254 -0.345 -0.683  0.079
> 0.375  0.010
> Number of obs: 3107, groups: Item_numb, 131; Subject, 24
> 
> Fixed effects:
>                                         Estimate Std. Error z value
> Pr(>|z|)
> (Intercept)                              2.70027    0.14160  19.070  <
> 2e-16 ***
> Freq_group1                             -1.04832    0.24404  -4.296
> 1.74e-05 ***
> Condition1                               0.68127    0.22876   2.978
> 0.00290 **
> Condition2                              -0.56823    0.20482  -2.774
> 0.00553 **
> E_proficiency_SP                         0.04677    0.08473   0.552
> 0.58096
> Freq_group1:Condition1                  -0.32467    0.40460  -0.802
> 0.42229
> Freq_group1:Condition2                  -0.10520    0.40897  -0.257
> 0.79700
> Freq_group1:E_proficiency_SP            -0.20632    0.12643  -1.632
> 0.10268
> Condition1:E_proficiency_SP             -0.13266    0.15364  -0.863
> 0.38791
> Condition2:E_proficiency_SP             -0.39620    0.16135  -2.456
> 0.01407 *
> Freq_group1:Condition1:E_proficiency_SP -0.26202    0.25468  -1.029
> 0.30357
> Freq_group1:Condition2:E_proficiency_SP  0.14582    0.31966   0.456
> 0.64827
> ---
> Signif. codes:  0 ???***??? 0.001 ???**??? 0.01 ???*??? 0.05 ???.??? 0.1 ??? ??? 1
> 
> Correlation of Fixed Effects:
>             (Intr) Frq_g1 Cndtn1 Cndtn2 E_p_SP Fr_1:C1 Fr_1:C2 F_1:E_
> C1:E__ C2:E__ F_1:C1:
> Freq_group1
> -0.202
> 
> Condition1  -0.155
> -0.008
> Condition2  -0.032 -0.048
> 0.010
> E_prfcnc_SP  0.033 -0.052  0.007
> -0.094
> Frq_grp1:C1 -0.299  0.214  0.032 -0.038
> -0.037
> Frq_grp1:C2 -0.036 -0.214  0.064 -0.252  0.077
> -0.075
> Frq_1:E__SP -0.061  0.052 -0.043  0.101 -0.323  0.012
> -0.126
> Cndt1:E__SP  0.006 -0.032  0.044 -0.077 -0.281 -0.045   0.063
> 0.035
> Cndt2:E__SP -0.079  0.071 -0.073  0.068 -0.037  0.065  -0.119  -0.119
> -0.017
> F_1:C1:E__S -0.034  0.008 -0.050  0.074 -0.443  0.060  -0.093   0.343
> 0.103 -0.078
> F_1:C2:E__S  0.063 -0.094  0.059 -0.117 -0.079 -0.087   0.066  -0.317
> 0.039 -0.186 -0.130
> ----------------------------------------------------------------------------------------------------------------
> 
> However, having read recently that lmer version 1.1-7 obtains better fits
> than lme4.0, I fitted the same model using glmer with the bobyqa optimizer
> and maxfun=16000. Here is the output. There were no convergence issues or
> any other warnings (when I increased the number of iterations as suggested).
> 
> -------------------------------------------------------------------------------------------------------------------
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) ['glmerMod']
>  Family: binomial  ( logit )
> Formula: Resp.bin ~ 1 + Freq_group * Condition * E_proficiency_SP + (1
> +      Freq_group * Condition | Subject) + (1 + Condition | Item_numb)
>    Data: joint.NS
> Control: glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 16000))
> 
>      AIC      BIC   logLik deviance df.resid
>   2094.4   2330.0  -1008.2   2016.4     3068
> 
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -6.7090  0.1461  0.2251  0.3482  1.6999
> 
> Random effects:
>  Groups    Name                   Variance Std.Dev.
> Corr
>  Item_numb (Intercept)            0.965582
> 0.98264
>            Condition1             1.669926 1.29226
> -0.04
>            Condition2             0.007722 0.08788  -0.05
> 1.00
>  Subject   (Intercept)            0.160826
> 0.40103
>            Freq_group1            0.164960 0.40615
> -0.42
>            Condition1             0.444855 0.66697  -0.68
> 0.27
>            Condition2             0.177659 0.42150   0.27 -0.74
> 0.32
>            Freq_group1:Condition1 0.721550 0.84944  -0.94  0.70  0.65
> -0.48
>            Freq_group1:Condition2 0.714430 0.84524  -0.35 -0.68  0.08
> 0.37  0.01
> Number of obs: 3107, groups:  Item_numb, 131; Subject, 24
> 
> Fixed effects:
>                                         Estimate Std. Error z value
> Pr(>|z|)
> (Intercept)                              2.70023    0.16124  16.747  <
> 2e-16 ***
> Freq_group1                             -1.04829    0.25693  -4.080
> 4.5e-05 ***
> Condition1                               0.68123    0.27441   2.483
> 0.0130 *
> Condition2                              -0.56822    0.29971  -1.896
> 0.0580 .
> E_proficiency_SP                         0.04675    0.08527   0.548
> 0.5835
> Freq_group1:Condition1                  -0.32464    0.43299  -0.750
> 0.4534
> Freq_group1:Condition2                  -0.10517    0.44365  -0.237
> 0.8126
> Freq_group1:E_proficiency_SP            -0.20633    0.12692  -1.626
> 0.1040
> Condition1:E_proficiency_SP             -0.13266    0.15570  -0.852
> 0.3942
> Condition2:E_proficiency_SP             -0.39620    0.16214  -2.443
> 0.0145 *
> Freq_group1:Condition1:E_proficiency_SP -0.26201    0.25735  -1.018
> 0.3086
> Freq_group1:Condition2:E_proficiency_SP  0.14583    0.31962   0.456
> 0.6482
> ---
> Signif. codes:  0 ???***??? 0.001 ???**??? 0.01 ???*??? 0.05 ???.??? 0.1 ??? ??? 1
> 
> Correlation of Fixed Effects:
>             (Intr) Frq_g1 Cndtn1 Cndtn2 E_p_SP Fr_1:C1 Fr_1:C2 F_1:E_
> C1:E__ C2:E__ F_1:C1:
> Freq_group1
> -0.249
> 
> Condition1  -0.032
> -0.056
> Condition2  -0.085 -0.059
> -0.056
> E_prfcnc_SP  0.046 -0.055  0.001
> -0.094
> Frq_grp1:C1 -0.289  0.211 -0.065 -0.045
> -0.028
> Frq_grp1:C2 -0.042 -0.174  0.036 -0.328  0.079
> -0.053
> Frq_1:E__SP -0.060  0.047 -0.044  0.080 -0.313  0.019
> -0.117
> Cndt1:E__SP  0.001 -0.024  0.061 -0.070 -0.291 -0.048   0.056
> 0.031
> Cndt2:E__SP -0.092  0.071 -0.074  0.069 -0.032  0.060  -0.122  -0.122
> -0.012
> F_1:C1:E__S -0.038  0.015 -0.047  0.059 -0.443  0.044  -0.083   0.321
> 0.116 -0.077
> F_1:C2:E__S  0.061 -0.081  0.050 -0.115 -0.077 -0.071   0.076  -0.305
> 0.035 -0.177 -0.124
> ---------------------------------------------------------------------------------------------------------------
> 
> The two models are very similar, with almost identical estimates and the
> same AIC, BIC, and logLik. However, the model fitted with the newer glmer
> has generally higher standard errors.
> 
> Any idea as to what might be behind this? And is there any reason to prefer
> one method to the other a priori?
> 
> Many thanks,
> 
> Chiara Gambi


  My guess is that it's related to this issue:

https://github.com/lme4/lme4/issues/47

>From https://github.com/lme4/lme4/blob/master/inst/NEWS.Rd

  \item Standard errors of fixed effects are now computed
      from the approximate Hessian by default (see the
      \code{use.hessian} argument in \code{vcov.merMod}); this
      gives better (correct) answers when the estimates of
      the random- and fixed-effect parameters are correlated
      (Github #47)
    }

If I'm correct, you should be able to see the difference in
standard errors by comparing

sqrt(diag(vcov(fitted_model,use.hessian=TRUE)))  ## new default
sqrt(diag(vcov(fitted_model,use.hessian=FALSE)))  ## old default

  As far as we know, the new standard errors are better/more correct.

  Ben Bolker


From g.chiara86 at gmail.com  Wed Jul 30 16:47:57 2014
From: g.chiara86 at gmail.com (Chiara Gambi)
Date: Wed, 30 Jul 2014 16:47:57 +0200
Subject: [R-sig-ME] lme4.0 vs. lme4 version 1.1-7: newer version returns
 inflated SE using glmer() with bobyqa optimizer
In-Reply-To: <CACUeYTGNrzYwv1a5Xh_ZLoRcba4M_6q1UdasnconSmeAJVkipw@mail.gmail.com>
References: <CACUeYTGNrzYwv1a5Xh_ZLoRcba4M_6q1UdasnconSmeAJVkipw@mail.gmail.com>
Message-ID: <CACUeYTEHSJ1PdtLwJhHoLSPcbwdGZY_urdLu9sMDg+y3w4GgGA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140730/e0da1e05/attachment.pl>

From smit.reuben at gmail.com  Wed Jul 30 19:11:10 2014
From: smit.reuben at gmail.com (Reuben Smit)
Date: Wed, 30 Jul 2014 12:11:10 -0500
Subject: [R-sig-ME] Calculating upper and lower confidence limits on a
 population estimate derived from multiple point estimates
In-Reply-To: <CAFFAEtimJvi8t7Y=FWqavaBz4iJC7v=enZS8wchQdqcDTzXL2A@mail.gmail.com>
References: <CAFFAEtimJvi8t7Y=FWqavaBz4iJC7v=enZS8wchQdqcDTzXL2A@mail.gmail.com>
Message-ID: <CAFFAEti+g9WZnK+g1BsDPMeNu7_RPp+-Z0aNGwYP661FT105Mw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140730/6d76506e/attachment.pl>

From hughes.dupond at gmx.de  Wed Jul 30 19:20:09 2014
From: hughes.dupond at gmx.de (Lionel)
Date: Wed, 30 Jul 2014 19:20:09 +0200
Subject: [R-sig-ME] Pseudoreplication in a factorial GLM with a
 proportional response variable and categorical predictor variables
In-Reply-To: <1770501439A6C74C9141CBA9004FCA8180166B02@LIDCOEX03.dec.int>
References: <1770501439A6C74C9141CBA9004FCA8180166B02@LIDCOEX03.dec.int>
Message-ID: <53D92949.20001@gmx.de>

Dear Berin Mackenzie,

I am no specialist of nested design so I am just giving you some of my 
thoughts.
1. The random term is not specified correctly, if you look here: 
http://glmm.wikidot.com/faq#modelspec you would note that Season should 
come first and then PetriDish. Otherwise yes the model is correct.
2. See response above
3. I am not aware of any rules about this but looking at the other 
coefficient which are 9 order of magnitude bigger than the estimated 
standard deviation of the random term, I guess you could rather 
confidently say that the petri dish influence (within season) is 
negligible on your germination rates.
4. The estimated standard deviation value represent the added variation 
by your petri dishes (within season treatment) on top of the fixed 
effect predicted values, usually in such experimental studies random 
terms are due to the design and interpreting their effect is not of 
interest. For other type of studies model comparison with different 
random term part is the way to go (PBmodcomp in the pbkrtest package is 
one way to do this).

Hope that it helped,
Lionel

On 30/07/2014 05:03, Berin Mackenzie wrote:
> Dear list members,
>
>
>
> I'm very new to generalized linear models and mixed effects models, and I'm trying to teach myself how to apply them in R to analyse a series of factorial germination experiments with a proportional response variable and three categorical predictor variables. The problem is that one of the predictor variables is pseudoreplicated and I'm not sure how to deal with this. I came across this post - https://stat.ethz.ch/pipermail/r-help/2011-April/275895.html - which suggested a mixed effects model might be provide a solution, but I'd be extremely grateful for any advice from experienced analysts.
>
>
>
> Full details of the design, a sample dataset, and some models I've tried, appear below.
>
>
>
> Warm regards and many thanks in advance for your time and advice!
>
> Berin
>
>
> BACKGROUND:
> I performed a factorial seed germination experiment to test the effects of i) Heat shock (2 levels: heat or no heat), Smoke (2 levels: smoke or no smoke), and Season (3 levels: summer, autumn, winter), and their interactions, on germination. The experimental units were petri dishes of 20 seeds each, and there were 4 replicate dishes for each factorial treatment combination (2 x 2 x 3 =12 possible treatments x 4 dishes each = 48 petri dishes/observations in total).
> The Heat and Smoke treatments were independently applied, however, Season was pseudoreplicated as only three temperature-controlled incubators were available (one for each level of Season) and all 4 replicate dishes for each unique factorial treatment were placed inside the same incubator. For true independence, each replicate would have required a separate incubator (48 incubators in total for this experiment) which would have been prohibitively expensive and impractical. As such, pseudoreplication of temperature treatments is very common in germination studies but most researchers appear to accept/ignore this limitation in their analyses and treat replicates as though they're independent. I'm wondering if there might be a better way...
> So far, I've tried the following approaches:
>              i) a binomial GLM (although this ignores the non-independence of replicates), and
> ii) a binomial GLMM with PetriDish as a random factor within Season (this idea is based on comments in the post I linked above)
> MODELS & RESULTS:
> Below are the relevant data:
>
> R version 3.1.1 (2014-07-10)
>
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
>
>
> locale:
>
> [1] LC_COLLATE=English_Australia.1252  LC_CTYPE=English_Australia.1252
>
> [3] LC_MONETARY=English_Australia.1252 LC_NUMERIC=C
>
> [5] LC_TIME=English_Australia.1252
>
>
>
> attached base packages:
>
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
>
>
> other attached packages:
>
> [1] lme4_1.1-7   Rcpp_0.11.2  Matrix_1.1-4
>
>
>
> loaded via a namespace (and not attached):
>
> [1] grid_3.1.1      lattice_0.20-29 MASS_7.3-33     minqa_1.2.3     nlme_3.1-117
>
> [6] nloptr_1.0.0    splines_3.1.1   tools_3.1.1
> I've performed this experiment for 7 different species but the table below comprises data on a single species as an example. 'Replicate' refers to the 4 replicate petri dishes for each of the 12 factorial treatments but is not used in my models, and 'CumNoGerm' is the cumulative number of germinants. All other column names are self-explanatory.
>
>> dat[]
>        Heat    Smoke Season PetriDish Replicate ViableSeed CumNoGerm
>
> 1  0NoHeat 0NoSmoke   1SUM      PD01         1         14         0
>
> 2  0NoHeat 0NoSmoke   1SUM      PD02         2         11         0
>
> 3  0NoHeat 0NoSmoke   1SUM      PD03         3         20         0
>
> 4  0NoHeat 0NoSmoke   1SUM      PD04         4         18         0
>
> 5  0NoHeat 0NoSmoke   2AUT      PD05         1         13         0
>
> 6  0NoHeat 0NoSmoke   2AUT      PD06         2         12         0
>
> 7  0NoHeat 0NoSmoke   2AUT      PD07         3         17         0
>
> 8  0NoHeat 0NoSmoke   2AUT      PD08         4         13         0
>
> 9  0NoHeat 0NoSmoke   3WIN      PD09         1         16         0
>
> 10 0NoHeat 0NoSmoke   3WIN      PD10         2         17         1
>
> 11 0NoHeat 0NoSmoke   3WIN      PD11         3         13         1
>
> 12 0NoHeat 0NoSmoke   3WIN      PD12         4         16         1
>
> 13   1Heat 0NoSmoke   1SUM      PD13         1          6         0
>
> 14   1Heat 0NoSmoke   1SUM      PD14         2         14         0
>
> 15   1Heat 0NoSmoke   1SUM      PD15         3         14         0
>
> 16   1Heat 0NoSmoke   1SUM      PD16         4         17         1
>
> 17   1Heat 0NoSmoke   2AUT      PD17         1         13         0
>
> 18   1Heat 0NoSmoke   2AUT      PD18         2         13         2
>
> 19   1Heat 0NoSmoke   2AUT      PD19         3         15         2
>
> 20   1Heat 0NoSmoke   2AUT      PD20         4         14         1
>
> 21   1Heat 0NoSmoke   3WIN      PD21         1         16         0
>
> 22   1Heat 0NoSmoke   3WIN      PD22         2         14         1
>
> 23   1Heat 0NoSmoke   3WIN      PD23         3          8         0
>
> 24   1Heat 0NoSmoke   3WIN      PD24         4         18         2
>
> 25 0NoHeat   1Smoke   1SUM      PD25         1         18         3
>
> 26 0NoHeat   1Smoke   1SUM      PD26         2         14         4
>
> 27 0NoHeat   1Smoke   1SUM      PD27         3          9         1
>
> 28 0NoHeat   1Smoke   1SUM      PD28         4         16         1
>
> 29 0NoHeat   1Smoke   2AUT      PD29         1         19         8
>
> 30 0NoHeat   1Smoke   2AUT      PD30         2         16         6
>
> 31 0NoHeat   1Smoke   2AUT      PD31         3         13         9
>
> 32 0NoHeat   1Smoke   2AUT      PD32         4         11         5
>
> 33 0NoHeat   1Smoke   3WIN      PD33         1         19         7
>
> 34 0NoHeat   1Smoke   3WIN      PD34         2         17        12
>
> 35 0NoHeat   1Smoke   3WIN      PD35         3         14         7
>
> 36 0NoHeat   1Smoke   3WIN      PD36         4         13         8
>
> 37   1Heat   1Smoke   1SUM      PD37         1         14         3
>
> 38   1Heat   1Smoke   1SUM      PD38         2         14         3
>
> 39   1Heat   1Smoke   1SUM      PD39         3         13         4
>
> 40   1Heat   1Smoke   1SUM      PD40         4         16         6
>
> 41   1Heat   1Smoke   2AUT      PD41         1         14         5
>
> 42   1Heat   1Smoke   2AUT      PD42         2         17        11
>
> 43   1Heat   1Smoke   2AUT      PD43         3          5         1
>
> 44   1Heat   1Smoke   2AUT      PD44         4         16         6
>
> 45   1Heat   1Smoke   3WIN      PD45         1         15         2
>
> 46   1Heat   1Smoke   3WIN      PD46         2         13         3
>
> 47   1Heat   1Smoke   3WIN      PD47         3         14         4
>
> 48   1Heat   1Smoke   3WIN      PD48         4         19         3
> 1. Generalized linear model with binomial error structure. First I fitted the global model (model1)...
>
>> model1 = glm(cbind(CumNoGerm,ViableSeed-CumNoGerm) ~ Heat*Smoke*Season, family = binomial, data = dat)
> ...and then I used drop1() and AICc to identify the minimal adequate model (model1.ma)
>
>> model1.ma = glm(cbind(CumNoGerm,ViableSeed-CumNoGerm) ~ Heat + Smoke + Season + Heat:Smoke + Heat:Season, family = binomial, data = dat)
>> anova(model1.ma, test = "Chisq")
> Analysis of Deviance Table
>
>
>
> Model: binomial, link: logit
>
>
>
> Response: cbind(CumNoGerm, ViableSeed - CumNoGerm)
>
>
>
> Terms added sequentially (first to last)
>
>
>
>
>
>              Df Deviance Resid. Df Resid. Dev  Pr(>Chi)
>
> NULL                           47    200.822
>
> Heat         1    0.714        46    200.109 0.3982723
>
> Smoke        1  124.486        45     75.623 < 2.2e-16 ***
>
> Season       2   18.201        43     57.422 0.0001116 ***
>
> Heat:Smoke   1    6.086        42     51.336 0.0136276 *
>
> Heat:Season  2   16.414        40     34.922 0.0002727 ***
>
> ---
>
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
>> summary(model1.ma)
>
>
> Call:
>
> glm(formula = cbind(CumNoGerm, ViableSeed - CumNoGerm) ~ Heat +
>
>      Smoke + Season + Heat:Smoke + Heat:Season, family = binomial,
>
>      data = dat)
>
>
>
> Deviance Residuals:
>
>      Min       1Q   Median       3Q      Max
>
> -1.6767  -0.7036  -0.3749   0.5618   1.7105
>
>
>
> Coefficients:
>
>                        Estimate Std. Error z value Pr(>|z|)
>
> (Intercept)            -5.5039     0.6908  -7.967 1.62e-15 ***
>
> Heat1Heat               2.3836     0.8130   2.932 0.003368 **
>
> Smoke1Smoke             3.7959     0.6090   6.233 4.58e-10 ***
>
> Season2AUT              1.5367     0.4414   3.481 0.000499 ***
>
> Season3WIN              1.9490     0.4362   4.468 7.88e-06 ***
>
> Heat1Heat:Smoke1Smoke  -1.7194     0.7225  -2.380 0.017320 *
>
> Heat1Heat:Season2AUT   -0.7232     0.5751  -1.258 0.208550
>
> Heat1Heat:Season3WIN   -2.1981     0.5912  -3.718 0.000201 ***
>
> ---
>
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
>
>
> (Dispersion parameter for binomial family taken to be 1)
>
>
>
>      Null deviance: 200.822  on 47  degrees of freedom
>
> Residual deviance:  34.922  on 40  degrees of freedom
>
> AIC: 138.32
>
>
>
> Number of Fisher Scoring iterations: 5
> 2. Next, I tried a generalized linear mixed effects model in the 'lme4' package with binomial error and PetriDish as a random factor within Season to account for pseudoreplication. Below is the global model (model2):
>
>> model2 = glmer(cbind(CumNoGerm,ViableSeed-CumNoGerm) ~ Heat*Smoke*Season + (1|PetriDish:Season), family = binomial, data = dat)
> ...and then I fitted the minimal adequate model I'd identified with the GLM in 1) above.
>
>> model2.ma = glmer(cbind(CumNoGerm,ViableSeed-CumNoGerm) ~ Heat + Smoke + Season + Heat:Smoke + Heat:Season + (1|PetriDish:Season), family = binomial, data = dat)
>> summary(model2.ma)
> Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) [glmerMod
>
> ]
>
>   Family: binomial  ( logit )
>
> Formula: cbind(CumNoGerm, ViableSeed - CumNoGerm) ~ Heat + Smoke + Season +
>
>      Heat:Smoke + Heat:Season + (1 | PetriDish:Season)
>
>     Data: dat
>
>
>
>       AIC      BIC   logLik deviance df.resid
>
>     140.3    157.2    -61.2    122.3       39
>
>
>
> Scaled residuals:
>
>      Min      1Q  Median      3Q     Max
>
> -1.6819 -0.5778 -0.3011  0.5930  1.8417
>
>
>
> Random effects:
>
>   Groups           Name        Variance  Std.Dev.
>
>   PetriDish:Season (Intercept) 1.401e-17 3.743e-09
>
> Number of obs: 48, groups:  PetriDish:Season, 48
>
>
>
> Fixed effects:
>
>                        Estimate Std. Error z value Pr(>|z|)
>
> (Intercept)            -5.5039     0.6908  -7.967 1.62e-15 ***
>
> Heat1Heat               2.3836     0.8130   2.932 0.003368 **
>
> Smoke1Smoke             3.7959     0.6090   6.233 4.58e-10 ***
>
> Season2AUT              1.5367     0.4414   3.481 0.000499 ***
>
> Season3WIN              1.9490     0.4362   4.468 7.88e-06 ***
>
> Heat1Heat:Smoke1Smoke  -1.7194     0.7225  -2.380 0.017320 *
>
> Heat1Heat:Season2AUT   -0.7232     0.5751  -1.258 0.208550
>
> Heat1Heat:Season3WIN   -2.1981     0.5912  -3.718 0.000201 ***
>
> ---
>
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
>
>
> Correlation of Fixed Effects:
>
>              (Intr) Het1Ht Smk1Sm Ss2AUT Ss3WIN H1H:S1 H1H:S2
>
> Heat1Heat   -0.850
>
> Smoke1Smoke -0.852  0.724
>
> Season2AUT  -0.465  0.395  0.043
>
> Season3WIN  -0.510  0.433  0.090  0.682
>
> Ht1Ht:Smk1S  0.718 -0.827 -0.843 -0.036 -0.076
>
> Ht1Ht:S2AUT  0.357 -0.495 -0.033 -0.768 -0.524  0.065
>
> Ht1Ht:S3WIN  0.376 -0.477 -0.066 -0.503 -0.738  0.052  0.611
>
> Specifically, I'd appreciate advice on the following:
>
> 1. Is model 2 more appropriate than model 1, given the pseudoreplication of Season?
>
> 2. If so, is the correct random effect to fit PetriDish:Season, instead of PetriDish/Season, as Season is included as a fixed effect?
>
> 3. Does the near-zero variance of PetriDish:Season suggest there is no dish effect between , in which case wouldn't model 1 (GLM) suffice (the coefficients and standard errors are identical between the two models anyway...)?
>
> 4. How would I interpret a non-zero variance for PetriDish:Season, and would that depend on how large it was?
>
> 5. If model 2 isn't adequate to address the pseudoreplication, could anyone suggest other approaches or resources I could try?
>
> Thanks again for your time and assistance - it's very much appreciated.
>
> Warm regards,
> Berin
> ----------------------------------------------------------------------------------------------------------------------------------------------------------------------
> This email is intended for the addressee(s) named and may contain confidential and/or privileged information.
> If you are not the intended recipient, please notify the sender and then delete it immediately.
> Any views expressed in this email are those of the individual sender except where the sender expressly and with authority states them to be the views of the NSW Office of Environment and Heritage.
>
> PLEASE CONSIDER THE ENVIRONMENT BEFORE PRINTING THIS EMAIL
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From nicolas.o.rode at gmail.com  Wed Jul 30 22:35:46 2014
From: nicolas.o.rode at gmail.com (Nicolas Rode)
Date: Wed, 30 Jul 2014 16:35:46 -0400
Subject: [R-sig-ME] Random effect on only one of the response variables in
	bivariate LMM (MCMCglmm)
Message-ID: <CAAnfhNgv6KiuijJy7Krub2oK3qZGaVw5PWoD3Drk1pRbQ3XFNw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140730/11a6fe71/attachment.pl>

From russell-lenth at uiowa.edu  Thu Jul 31 02:59:35 2014
From: russell-lenth at uiowa.edu (Lenth, Russell V)
Date: Thu, 31 Jul 2014 00:59:35 +0000
Subject: [R-sig-ME] Calculating upper and lower confidence limits on a
 population estimate derived from multiple point estimates
Message-ID: <51F0C7C54B032A42A23B74A088E7141C2E5C5CB7@itsnt443.iowa.uiowa.edu>

As I understand it, you want a confidence interval for the sum of all 150000 true predictions - is that right?
You can't get that by summing the confidence limits. You should sum the rows of your mm matrix FIRST:

	summ <- apply(mm, 2, sum)

Then compute  

	pred  <-  sum(summ * fixef(glmmadmb_object))
	predvar  <-  sum(summ * (vcov(glmmadmb_object) %*% summ)) 

(This is just what you did before, specialized to the 1-row case. The result is a single number (aka a 1x1 matrix). Then your CI is 

	pred + c(LCL=-1, est=0, UCL=1) * 1.96 * sqrt{predvar)

There's a potential issue with the fact that the vcov() result is a 150000 x 150000 matrix. But I suppose it's rather sparse and stored that way?

Russ

Russell V. Lenth  -  Professor Emeritus
Department of Statistics and Actuarial Science   
The University of Iowa  -  Iowa City, IA 52242  USA   
Voice (319)335-0712 (Dept. office)  -  FAX (319)335-3017

Thank you for your response everyone. I should provide more information on
the method I used.

1.) I fit the model using the glmmadmb package with a negative binomial
distribution.

2.) I created a model matrix (mm) of fixed effects with new data
(n=~150,000), and multiplied this matrix with the vcov(glmmadmb_model)
matrix, according to some excellent documentation and code examples
developed online (r-sig-wikidot-FAQ-GLMM, etc.):

predvar<-diag(mm%*%vcov(glmmadmb_object)%*%t(mm))

3.) Then I took the square root of predvar to get the SE of each prediction
point:

newdata$SE<-sqrt(predvar)

4.) I made predictions with the fixed effects of the glmmadmb model, and
transformed that response with the link (exp(prediction)).

5.) To compute the upper and lower ranges of population estimates at each
point, I used the following:

(exp transformed prediction) +/- 1.96(SE)

The result is three columns of ~150,000 observations in my new dataset:
upper CI, lower CI, and transformed prediction.

As my question states I was hoping to simply sum the columns for a
reach-wide, minimum and maximum population estimate. However, I understand
the caveats of using glmms in this way for predictions. Have I missed
something? I'm hoping to use this method for a manuscript intended for
publication, so it needs to be sound, if that is even possible with all
things considered.


From nicolas.o.rode at gmail.com  Thu Jul 31 04:16:52 2014
From: nicolas.o.rode at gmail.com (Nicolas Rode)
Date: Wed, 30 Jul 2014 22:16:52 -0400
Subject: [R-sig-ME] Random effect on only one of the response variables
 in bivariate LMM (MCMCglmm)
In-Reply-To: <CAAnfhNgv6KiuijJy7Krub2oK3qZGaVw5PWoD3Drk1pRbQ3XFNw@mail.gmail.com>
References: <CAAnfhNgv6KiuijJy7Krub2oK3qZGaVw5PWoD3Drk1pRbQ3XFNw@mail.gmail.com>
Message-ID: <CAAnfhNhupqsncdkmRiniJQ2tMuw-jN7vz7O1k33y5GNifQP_BA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140730/a8c53ea0/attachment.pl>

From j.hadfield at ed.ac.uk  Thu Jul 31 09:29:31 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 31 Jul 2014 08:29:31 +0100
Subject: [R-sig-ME] Random effect on only one of the response variables
 in bivariate LMM (MCMCglmm)
In-Reply-To: <CAAnfhNgv6KiuijJy7Krub2oK3qZGaVw5PWoD3Drk1pRbQ3XFNw@mail.gmail.com>
References: <CAAnfhNgv6KiuijJy7Krub2oK3qZGaVw5PWoD3Drk1pRbQ3XFNw@mail.gmail.com>
Message-ID: <20140731082931.144555femwns0b4s@www.staffmail.ed.ac.uk>

Dear Nicolas,

Is replicate 1 for trait 1 the same as replicate 1 for trait 2: do you  
expect trait 1 and trait 2 to be correlated if they are in the same  
replicate, over and above that due to strain effects?

If not then

random = ~ us(trait):Strain+us(at.level(trait,2)):replicate,
rcov = ~idh(trait):units

is appropriate, and you do not need to fix any variances.

Cheers,

Jarrod

Quoting Nicolas Rode <nicolas.o.rode at gmail.com> on Wed, 30 Jul 2014  
16:35:46 -0400:

>  <r-sig-mixed-models at r-project.org>
>
> Dear all,
>
>
>
> I'm trying to analyze the genetic correlation between two traits using a
> bivariate normal distribution in MCMCglmm.
>
> I have 32 strains with 3 replicates and 1 observation per replicate for
> Trait1 and 3 replicates and 2 observations per replicate for Trait2. I
> addition to the genetic variance-covariance matrix for Trait1 and Trait2, I
> would like to get the residual variance for Trait1 and Trait2, as well as
> the between replicate variance for Trait2.
>
>
> Would anyone know if it would be possible to fit a between replicate random
> effect to only one of the two traits in MCMCglmm?
>
>
> I detailed 3 different methods I?ve been using below but none of them
> appears satisfactory.
>
>
>
> 1/Fixing the between replicate variance to 1 for Trait1 (?priorvarRep ? and
> fix argument below) also results in fixed residual variances for Trait1 and
> Trait2.
>
>
>
> priorvarRep<-priorvar
>
> diag(priorvarRep)<-c(1,diag(priorvarRep)[2])
>
>
>
> priorm1 <-list(G=list(G1=list(V= priorvar,n=2), G2=list(V=
> priorvarRep,n=2,fix=c(1,0))), R=list(V= priorvar,n=2))
>
>
>
> m1<-MCMCglmm(Value~-1+Trait, random = ~ us(Trait):Strain, rcov = ~
> idh(Trait):units, family = "gaussian", ,prior=priorm1, data = data)
>
>
>
> 2/ Fixing the residual variance of Trait1 to 1 results in very weird
> results for the residual variance of Trait2.
>
>
>
> Priorm2 <-list(G=list(G1=list(V= priorvar,n=2), G2=list(V= priorvar,n=2)),
> R=list(V= priorvarRep,n=2,fix=c(1,0)))
>
>
>
> 3/Out of curiosity, I?ve also tried a model without fixing any variance.
> The between replicate variance fitted for Trait1 is then pretty close to
> the residual variance of Trait1, but this might be an artifact.
>
> Priorm3 <-list(G=list(G1=list(V= priorvar,n=2), G2=list(V= priorvar,n=2)),
> R=list(V= priorvar,n=2,fix=c(1,0)))
>
>
>
>
>
> Thank you very much for your help.
>
>
>
>
>
> Best regards,
>
>
>
> Nicolas
>
> 	[[alternative HTML version deleted]]
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From smit.reuben at gmail.com  Thu Jul 31 19:58:40 2014
From: smit.reuben at gmail.com (Reuben Smit)
Date: Thu, 31 Jul 2014 12:58:40 -0500
Subject: [R-sig-ME] Calculating upper and lower confidence limits on a
 population estimate derived from multiple point estimates
In-Reply-To: <51F0C7C54B032A42A23B74A088E7141C2E5C5CB7@itsnt443.iowa.uiowa.edu>
References: <51F0C7C54B032A42A23B74A088E7141C2E5C5CB7@itsnt443.iowa.uiowa.edu>
Message-ID: <CAFFAEtgNhK-BgBA2ODb2f7pgE+XDxMF8QCjcyt_VJ4U-w7QuSQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140731/6188e8aa/attachment.pl>

From yuki_himawari at hotmail.com  Fri Aug  1 00:01:46 2014
From: yuki_himawari at hotmail.com (yuki fujita)
Date: Thu, 31 Jul 2014 22:01:46 +0000
Subject: [R-sig-ME] Goodness of fit test for GLMM
Message-ID: <BAY172-W50AAB09751D3FF136C6F779EE60@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140731/bbf96784/attachment.pl>

From mtoncic at ffri.hr  Fri Aug  1 01:40:01 2014
From: mtoncic at ffri.hr (marKo)
Date: Fri, 01 Aug 2014 01:40:01 +0200
Subject: [R-sig-ME] Goodness of fit test for GLMM
In-Reply-To: <BAY172-W50AAB09751D3FF136C6F779EE60@phx.gbl>
References: <BAY172-W50AAB09751D3FF136C6F779EE60@phx.gbl>
Message-ID: <53DAD3D1.3060403@ffri.hr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140801/f70cb903/attachment.pl>

From chris at trickysolutions.com.au  Fri Aug  1 03:15:27 2014
From: chris at trickysolutions.com.au (Chris Howden)
Date: Fri, 1 Aug 2014 11:15:27 +1000
Subject: [R-sig-ME] Goodness of fit test for GLMM
In-Reply-To: <BAY172-W50AAB09751D3FF136C6F779EE60@phx.gbl>
References: <BAY172-W50AAB09751D3FF136C6F779EE60@phx.gbl>
Message-ID: <115f7780ce51edfb78764cb73fe6bf61@mail.gmail.com>

Hi Yuki,

Using chi-squared goodness of fit method is OK for comparing between
models, but as a simple goodness of fit statistic for one model it's not
well defined so it's not used much anymore other than a very rough first
look at fit. If it were a GLM you could try comparing to the null model
using Likelihood Ratio Tests, but they can be hard to use with GLMM since
the DF can be hard to define. If you really want a goodness of fit
statistics you could look at Cross Validation Prediction. However that can
be a little hard with logistic regression. I know some people also use ROC
curves and the Hosmer-Lemeshow tests.

As you are estimating 6 parameters the rule of thumb is that U need 60
datum. And if you actually have 258 separate individuals than you should
be OK.

If your GLM and GLMM are very similar than maybe there is little variance
being explained by the variation between individuals? As you are including
an individual level random factor I'm guessing you're maybe also doing it
to account for overdispersion? Have a look at the variance of the random
component, if it's close to 0 than there is no need to include it and you
don?t have overdispersion. (And that?s why your GLM and GLMM are so
similar)

You may find Doug Bates Wiki has some useful ideas
http://glmm.wikidot.com/faq

Chris Howden B.Sc. (Hons) GStat.
Founding Partner
Data Analysis, Modelling and Training
Evidence Based Strategy/Policy Development, IP Commercialisation and
Innovation
(mobile) +61 (0) 410 689 945
(skype) chris.howden
chris at trickysolutions.com.au




Disclaimer: The information in this email and any attachments to it are
confidential and may contain legally privileged information.?If you are
not the named or intended recipient, please delete this communication and
contact us immediately.?Please note you are not authorised to copy, use or
disclose this communication or any attachments without our consent.
Although this email has been checked by anti-virus software, there is a
risk that email messages may be corrupted or infected by viruses or other
interferences. No responsibility is accepted for such interference. Unless
expressly stated, the views of the writer are not those of the company.
Tricky Solutions always does our best to provide accurate forecasts and
analyses based on the data supplied, however it is possible that some
important predictors were not included in the data sent to us. Information
provided by us should not be solely relied upon when making decisions and
clients should use their own judgement.


-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of yuki fujita
Sent: Friday, 1 August 2014 8:02 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Goodness of fit test for GLMM

Hi




I need a help with testing goodness of fit for Generalized linear mixed
model.
It seems there is no solid way of doing it, but I'd like to make sure the
model is a good fit.




My model is




model1 <- glmer(cbind(CorrectHits,12-CorrectHits)~ ADHDYN*Condition + (1
|o..ID),


                data = bert, family="binomial")




where ADHDYN has a 2 levels
and 3 levels in Condition, and interaction. (so 6 fixed effect
parameters). We have allowed random inetrcept for individuals. The number
of observation is 258.




I tried to carry our the
goodness of fit test by using chi-square test, but I get 0 as a answer so
I am not sure if I did right.





# The degrees of freedom is obtained by number of obs - number of fixed
params


df <- length(bert$o..ID)-6;df


1-pchisq(952.5144 , df=251) # The output was 0




Any better way of testing the goodness of fit?




We carried out the same model
 but with glm, but we want to compare which model gives us smaller
Satandard error. The estimate of coefficients were very similay between
GLm and GLMM models.







Thanks in advance
Yuki
	[[alternative HTML version deleted]]


From nburgoyne at mango-solutions.com  Fri Aug  1 12:28:42 2014
From: nburgoyne at mango-solutions.com (Nicholas Burgoyne)
Date: Fri, 1 Aug 2014 10:28:42 +0000
Subject: [R-sig-ME] lme4 vs nlme
Message-ID: <FEC647A5D0EB3749B5BB9A174F06F43913D1F358@mexchange.Mango.local>

Dear all,

I have been using lme4 (1.1-7) extensively for a project, and have become stumped when trying to perform an F-test anova on the output, I want a to jointly set a series of terms as zero (I am using pbkrtest to generate DF values, which I believe are good enough for the test). I see that nlme has this functionality (specifying Terms in the anova function), but I am too far gone down the lme4 route for that.

The lme4 value I think is not generated (I'm not going to say missing, I'm sure there is a good reason for it) is the varFixFac matrix (an attribute of the fixDF in nlme). With this set the anova required should be simple. Is there anyway of defining this matrix using the values generated in the lme4 output?

Any input would be greatly appreciated, many thanks, 

Nicholas Burgoyne
  
Tel. +44 (0)1249 705 450?| Mobile. 
mailto:nburgoyne at mango-solutions.com?| www.mango-solutions.com



2 Methuen Park
Chippenham
Wiltshire 
SN14 OGB
UK


--

LEGAL NOTICE\ \ This message is intended for the use of ...{{dropped:18}}


From jake987722 at hotmail.com  Fri Aug  1 18:44:30 2014
From: jake987722 at hotmail.com (Jake Westfall)
Date: Fri, 1 Aug 2014 10:44:30 -0600
Subject: [R-sig-ME] lme4 vs nlme
In-Reply-To: <FEC647A5D0EB3749B5BB9A174F06F43913D1F358@mexchange.Mango.local>
References: <FEC647A5D0EB3749B5BB9A174F06F43913D1F358@mexchange.Mango.local>
Message-ID: <BAY172-W275264CA78332C57761BB4CBE70@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140801/e602647a/attachment.pl>

From fujyu654 at student.otago.ac.nz  Thu Jul 31 23:53:06 2014
From: fujyu654 at student.otago.ac.nz (Yuki Fujita)
Date: Thu, 31 Jul 2014 21:53:06 +0000
Subject: [R-sig-ME] Testing goodness of fit for GLMM model
Message-ID: <1406843586618.8714@student.otago.ac.nz>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140731/37425b8e/attachment.pl>

From felix.suessenbach at googlemail.com  Sat Aug  2 18:13:55 2014
From: felix.suessenbach at googlemail.com (Felix Suessenbach)
Date: Sat, 2 Aug 2014 17:13:55 +0100
Subject: [R-sig-ME] Standard errors in generalised linear mixed models?
Message-ID: <CAGwfgc6uN05Xf5q=rMfwzXR0zoFK2YtK9dJtn4GnraAEfxPr7A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140802/a5b24451/attachment.pl>

From bbolker at gmail.com  Sun Aug  3 00:19:57 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 2 Aug 2014 18:19:57 -0400
Subject: [R-sig-ME] Testing goodness of fit for GLMM model
In-Reply-To: <1406843586618.8714@student.otago.ac.nz>
References: <1406843586618.8714@student.otago.ac.nz>
Message-ID: <CABghstS+bGMKXxmmvsnYeG-On8DWbh99v1YC8F_=5mtXUHNL6g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140802/71d8e658/attachment.pl>

From bbolker at gmail.com  Sun Aug  3 00:52:23 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 2 Aug 2014 18:52:23 -0400
Subject: [R-sig-ME] Fwd: Standard errors in generalised linear mixed models?
In-Reply-To: <CABghstR6VF+FMULjNHsj=AM2SoZgVBTDVgDeT8tg29TGz-ANSA@mail.gmail.com>
References: <CAGwfgc6uN05Xf5q=rMfwzXR0zoFK2YtK9dJtn4GnraAEfxPr7A@mail.gmail.com>
	<CABghstR6VF+FMULjNHsj=AM2SoZgVBTDVgDeT8tg29TGz-ANSA@mail.gmail.com>
Message-ID: <CABghstRS-GnzSW+ZWTwfqW3H2LNta5ByGzBRwP6LLf5EH0jp0A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140802/114a6cc8/attachment.pl>

From y.shinohara at aoni.waseda.jp  Mon Aug  4 03:03:19 2014
From: y.shinohara at aoni.waseda.jp (Yasuaki SHINOHARA)
Date: Mon, 04 Aug 2014 10:03:19 +0900
Subject: [R-sig-ME] Random slopes for logistic mixed effects model;
 BoxCox transformation
Message-ID: <web-44081810@besv02.spw.secure-premium.ne.jp>

Dear all,

Hello, I am doing research of second language acquisition.
I am  wondering about glmer in R for my analyses. Could you please
answer the following questions?

I collected data of the perceptual identification tests of English
sounds before and after 10 perceptual training sessions by non-native
English speakers.
I am analysing data with logistic mixed effects model because the
dependent variable is correct/incorrect binomial data of perceptual
identification.
But I am now wondering about random slopes.

<1. Random slopes>
The following is the best model for my perceptual tests.

model<-glmer(corr~block+TrainerOrder+rl_pos+bcExp+block:TrainerOrder+TrainerOrder:rl_pos+block:bcExp+(1+block|subject)+(1+block|word:speaker),family=binomial,data=alldata,control=glmerControl(optimizer="bobyqa",
optCtrl=list(maxfun=100000)))

I included the random factor of (1+block|subject).
I think (1+block|subject) corrects variance of perceptual improvement
from pre to post tests between subjects (i.e., excluding the effects
of subjects' difference in perceptual improvement from pre to post
test).
However, I included the fixed factor of "block:bcExp" in this model.
"block" means testing block contrasting pre vs. post tests(categorical
data).
"bcExp" means the English experience in terms of the length (weeks) of
staying in English speaking countries.
English experience (weeks) was transformed by BoxCox transformation
method with lambda = 0.24(continuous data).
I think the interaction of "block:bcExp" tests the effects of English
experience on the perceptual improvement from pre to post test (e.g.,
whether the less English experienced subjects improved less than the
more English experienced subjects, vice versa).
In other words, block:bcExp tests the difference in improvement
between subjects in terms of the length of staying in English speaking
countries.
If my understanding is correct, I am not sure I should include the
random factor of (1+block|subject) or not, because including
"(1+block|subject)" as a random factor conflicts with the fixed factor
of "block:bcExp" to some extent(although "block:bcExp" tests the
regression with the length of staying in English speaking countries
and (1+block|subject) just excludes the effects of subjects'
difference in their improvements from pre to post).
I think I should include (1|subject) instead of (1+block|subject).

[QUESTION]
- Could I ask you whether I should include (1+block|subject) in the
model?
- Or should I use (1|subject) instead of (1+block|subject)?
- Or should I use the best fitting model based on AIC value in any
way?

I also have other data for testing age effects on learning
second-language (English) perception.
"age" is also continuous data, so that it is similar to English
experience data above.
In this case, I am not sure whether I should include
"(1+block|subject)" as a random factor, because it conflicts with
"block:age" included as a fixed factor, to some extent.

<2. BoxCox transformation>
I use BoxCox transformation when I have a continuous data as a fixed
factor to get the better fitting model. I always make "for loop" to
test which lambda value make the model fit best in terms of AIC value.
However, sometimes, the "for loop" stops working in the middle with
showing the following error message.

     cx<-seq(2.2,2.4,by=0.01)
     tbl<-NULL
     ld<-NULL
     aic<-NULL
     for (i in cx) {
  alldata$bcExp<-bcPower(alldata$EngExp_months+0.0001, lambda = i,
jacobian.adjusted = FALSE)
  model<-glmer(corr ~
block*TrainerOrder*bcExp+(1+block|subject)+(1+block|stim),
family=binomial, data=alldata,control=glmerControl(optimizer="bobyqa",
optCtrl=list(maxfun=100000)))
  ld<-rbind(ld,i)
  aic<-rbind(aic,AIC(model))
  }
Error: (maxstephalfit) PIRLS step-halvings failed to reduce deviance
in pwrssUpdate
In addition: Warning message:
In checkScaleX(X, ctrl = control) :
   Some predictor variables are on very different scales: consider
rescaling


[QUESTION]
- What exactly does this error message mean?
- In this case, does it mean I should not use BoxCox transformation
and try polynomial functions (e.g., poly(EngExp,2) or poly(EngExp,3)),
although the model with boxcox transformation fits better than other
models with polynomial transformations.
- What should I do when I get this error message?

Could you please answer my questions above?
Thank you very much in advance.

Best wishes,
Yasu


From Thierry.ONKELINX at inbo.be  Mon Aug  4 09:37:23 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 4 Aug 2014 07:37:23 +0000
Subject: [R-sig-ME] Random slopes for logistic mixed effects model;
 BoxCox transformation
In-Reply-To: <web-44081810@besv02.spw.secure-premium.ne.jp>
References: <web-44081810@besv02.spw.secure-premium.ne.jp>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3AC8A51@inbomail.inbo.be>

Dear Yusa,

(1+block|subject) is possible when you have enough data. That is when you have multiple observation for all (or at least most of the) combinations of block and subject. Since you are dealing with binomial data, you should have both absence and presence data for most of the combinations. Otherwise you get in to problem with quasi-complete separation.

If some of the information in your dataset can be predicted by either the fixed or the random effects, then the model will use the fixed effects. In that case the variance of the random effects will be very small or even 0.

Personally I don't like Boxcox transformations on predictor variables. It makes the model much harder to understand. Note that I do use transformations, but rather depending on the type of variable. E.g. log transformation on concentrations of chemical elements, square root for areas, ...

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Yasuaki SHINOHARA
Verzonden: maandag 4 augustus 2014 3:03
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Random slopes for logistic mixed effects model; BoxCox transformation

Dear all,

Hello, I am doing research of second language acquisition.
I am  wondering about glmer in R for my analyses. Could you please answer the following questions?

I collected data of the perceptual identification tests of English sounds before and after 10 perceptual training sessions by non-native English speakers.
I am analysing data with logistic mixed effects model because the dependent variable is correct/incorrect binomial data of perceptual identification.
But I am now wondering about random slopes.

<1. Random slopes>
The following is the best model for my perceptual tests.

model<-glmer(corr~block+TrainerOrder+rl_pos+bcExp+block:TrainerOrder+TrainerOrder:rl_pos+block:bcExp+(1+block|subject)+(1+block|word:speaker),family=binomial,data=alldata,control=glmerControl(optimizer="bobyqa",
optCtrl=list(maxfun=100000)))

I included the random factor of (1+block|subject).
I think (1+block|subject) corrects variance of perceptual improvement from pre to post tests between subjects (i.e., excluding the effects of subjects' difference in perceptual improvement from pre to post test).
However, I included the fixed factor of "block:bcExp" in this model.
"block" means testing block contrasting pre vs. post tests(categorical data).
"bcExp" means the English experience in terms of the length (weeks) of staying in English speaking countries.
English experience (weeks) was transformed by BoxCox transformation method with lambda = 0.24(continuous data).
I think the interaction of "block:bcExp" tests the effects of English experience on the perceptual improvement from pre to post test (e.g., whether the less English experienced subjects improved less than the more English experienced subjects, vice versa).
In other words, block:bcExp tests the difference in improvement between subjects in terms of the length of staying in English speaking countries.
If my understanding is correct, I am not sure I should include the random factor of (1+block|subject) or not, because including "(1+block|subject)" as a random factor conflicts with the fixed factor of "block:bcExp" to some extent(although "block:bcExp" tests the regression with the length of staying in English speaking countries and (1+block|subject) just excludes the effects of subjects'
difference in their improvements from pre to post).
I think I should include (1|subject) instead of (1+block|subject).

[QUESTION]
- Could I ask you whether I should include (1+block|subject) in the model?
- Or should I use (1|subject) instead of (1+block|subject)?
- Or should I use the best fitting model based on AIC value in any way?

I also have other data for testing age effects on learning second-language (English) perception.
"age" is also continuous data, so that it is similar to English experience data above.
In this case, I am not sure whether I should include "(1+block|subject)" as a random factor, because it conflicts with "block:age" included as a fixed factor, to some extent.

<2. BoxCox transformation>
I use BoxCox transformation when I have a continuous data as a fixed factor to get the better fitting model. I always make "for loop" to test which lambda value make the model fit best in terms of AIC value.
However, sometimes, the "for loop" stops working in the middle with showing the following error message.

     cx<-seq(2.2,2.4,by=0.01)
     tbl<-NULL
     ld<-NULL
     aic<-NULL
     for (i in cx) {
  alldata$bcExp<-bcPower(alldata$EngExp_months+0.0001, lambda = i, jacobian.adjusted = FALSE)
  model<-glmer(corr ~
block*TrainerOrder*bcExp+(1+block|subject)+(1+block|stim),
family=binomial, data=alldata,control=glmerControl(optimizer="bobyqa",
optCtrl=list(maxfun=100000)))
  ld<-rbind(ld,i)
  aic<-rbind(aic,AIC(model))
  }
Error: (maxstephalfit) PIRLS step-halvings failed to reduce deviance in pwrssUpdate In addition: Warning message:
In checkScaleX(X, ctrl = control) :
   Some predictor variables are on very different scales: consider rescaling


[QUESTION]
- What exactly does this error message mean?
- In this case, does it mean I should not use BoxCox transformation and try polynomial functions (e.g., poly(EngExp,2) or poly(EngExp,3)), although the model with boxcox transformation fits better than other models with polynomial transformations.
- What should I do when I get this error message?

Could you please answer my questions above?
Thank you very much in advance.

Best wishes,
Yasu

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From javanvonherp at gmail.com  Mon Aug  4 20:25:09 2014
From: javanvonherp at gmail.com (Javan Bauder)
Date: Mon, 4 Aug 2014 14:25:09 -0400
Subject: [R-sig-ME] Weighting observations by sampling size in lmer
Message-ID: <CAJKR=GN4C4tUtrqHXhdtAmDyC23=hMOTdxk8wSgBRw=U9t5FSw@mail.gmail.com>

I have a data set with which I am running a generalized linear
mixed-effects model using lmer. I have 100 used vegetation plots that
I am comparing with 100 randomly selected vegetation plots. The plots
correspond to different animals including in my study so I am using
animal as a random effect. Many of my used plots were sampled multiple
times (1-10 times). For a plot that was measured, say, five times, I
would like to be able to weight that plot rather than enter its
measurements five different times as five separate plots. I know that
lmer has a weights argument and was wondering if I can use the number
of times a plot was sampled to run a weighted regression analysis with
mixed-effects? I have tried searching the various help forums but have
not been able to make sense of the information out there.

Thank you very much,
Javan


From rubenarslan at gmail.com  Mon Aug  4 20:25:43 2014
From: rubenarslan at gmail.com (Ruben Arslan)
Date: Mon, 4 Aug 2014 20:25:43 +0200
Subject: [R-sig-ME] parallel MCMCglmm execution
Message-ID: <4CD76FE1-D3F5-4980-9122-B0AC0D44FF81@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140804/6068f15a/attachment.pl>

From cosimo2000 at gmail.com  Tue Aug  5 03:40:40 2014
From: cosimo2000 at gmail.com (Diego)
Date: Mon, 04 Aug 2014 20:40:40 -0500
Subject: [R-sig-ME] Looking for differences in G structure among factor
	levels
Message-ID: <53E03618.3010005@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140804/90f04f1b/attachment.pl>

From kmclaughlin23 at qub.ac.uk  Tue Aug  5 16:11:19 2014
From: kmclaughlin23 at qub.ac.uk (Kirsty McLaughlin)
Date: Tue, 5 Aug 2014 14:11:19 +0000
Subject: [R-sig-ME] FW: Error: (maxstephalfit) PIRLS step-halvings failed to
 reduce deviance in pwrssUpdate
In-Reply-To: <1407247408285.41264@qub.ac.uk>
References: <1407247408285.41264@qub.ac.uk>
Message-ID: <1407247881674.74780@qub.ac.uk>


To whom it may concern,


I am a novice in the use of R, however I have been trying my best to assess the effect of noise treatment over a three day period on the time spent carrying out certain behaviours. I am using a GLMM as I don't have sample independence and my response variables are non-normally distributed and skewed. I have been using Family Gamma for my analysis.


When running a model on 'TTAgressionCon' (time spent being aggressive) including the predictor variable Day (3 levels) I get the above error message. When the model runs with other predictor variables e.g. Gender, I do not get this error.


I have the most up to date version of lme4.


Below is the model that generated the error message:

model1 <- glmer(TTAggressionCon ~ Treatment + Day + Treatment*Day + (1|Round/Tank/Pair/Fish), data = data1, family = Gamma)


I have attached my data if this helps with diagnosis or suggestions.


Any help or guidance on this matter would be greatly appreciated.



Kind regards
Kirsty McLaughlin

PhD student
Queen's University Belfast
School of Biological Sciences
Medical Biology Centre
97 Lisburn Road
Belfast, BT9 7GT

Tel: 028 90 972103
Email: kmclaughlin23 at qub.ac.uk
Web: www.animal-behaviour.eu<http://www.animal-behaviour.eu>


From kmclaughlin23 at qub.ac.uk  Tue Aug  5 16:03:25 2014
From: kmclaughlin23 at qub.ac.uk (Kirsty McLaughlin)
Date: Tue, 5 Aug 2014 14:03:25 +0000
Subject: [R-sig-ME] Error: (maxstephalfit) PIRLS step-halvings failed to
 reduce deviance in pwrssUpdate
Message-ID: <1407247408285.41264@qub.ac.uk>

To whom it may concern,


I am a novice in the use of R, however I have been trying my best to assess the effect of noise treatment over a three day period on the time spent carrying out certain behaviours. I am using a GLMM as I don't have sample independence and my response variables are non-normally distributed and skewed. I have been using Family Gamma for my analysis.


When running a model on 'TTAgressionCon' (time spent being aggressive) including the predictor variable Day (3 levels) I get the above error message. When the model runs with other predictor variables e.g. Gender, I do not get this error.


I have the most up to date version of lme4.


Below is the model that generated the error message:

model1 <- glmer(TTAggressionCon ~ Treatment + Day + Treatment*Day + (1|Round/Tank/Pair/Fish), data = data1, family = Gamma)


I have attached my data if this helps with diagnosis or suggestions.


Any help or guidance on this matter would be greatly appreciated.



Kind regards
Kirsty McLaughlin

PhD student
Queen's University Belfast
School of Biological Sciences
Medical Biology Centre
97 Lisburn Road
Belfast, BT9 7GT

Tel: 028 90 972103
Email: kmclaughlin23 at qub.ac.uk
Web: www.animal-behaviour.eu<http://www.animal-behaviour.eu>


From bbolker at gmail.com  Tue Aug  5 18:07:55 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 5 Aug 2014 12:07:55 -0400
Subject: [R-sig-ME] FW: Error: (maxstephalfit) PIRLS step-halvings
 failed to reduce deviance in pwrssUpdate
In-Reply-To: <1407247881674.74780@qub.ac.uk>
References: <1407247408285.41264@qub.ac.uk>
	<1407247881674.74780@qub.ac.uk>
Message-ID: <CABghstRiAVUBmobURQJHuvMWXFCNLchZ6sx5-Uq5nmf1a0WuCw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140805/f88644fd/attachment.pl>

From pauljohn32 at gmail.com  Wed Aug  6 01:23:38 2014
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Tue, 5 Aug 2014 18:23:38 -0500
Subject: [R-sig-ME] autocorrelated errors
Message-ID: <CAErODj_WeH+EEhE1zsfFRSYCZQ6sPJFQVumeOGkzO_EjVAngYw@mail.gmail.com>

Sorry to bother you, but

I ask here every year or so if anybody is working on lme4 with time or
spatially correlated random errors. Bring corStruct back to life?

If nobody is, maybe we could start a project together? I'm getting
great & fast estimates from lme4 with the cross sectional models, but
to work on longitudinal panels, we need some AR(1) error terms, or
such.

pj
-- 
Paul E. Johnson
Professor, Political Science      Assoc. Director
1541 Lilac Lane, Room 504      Center for Research Methods
University of Kansas                 University of Kansas
http://pj.freefaculty.org               http://quant.ku.edu


From M.Fairbrother at bristol.ac.uk  Wed Aug  6 13:29:46 2014
From: M.Fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Wed, 6 Aug 2014 12:29:46 +0100
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 92, Issue 6
In-Reply-To: <mailman.3.1407319203.9169.r-sig-mixed-models@r-project.org>
References: <mailman.3.1407319203.9169.r-sig-mixed-models@r-project.org>
Message-ID: <CAAH-yP-6HbD8-6twAOzhTcv+DAYqhaZHeDAT6c25kPmBCF3_nA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140806/f0089a3b/attachment.pl>

From s1163484 at sms.ed.ac.uk  Wed Aug  6 11:49:16 2014
From: s1163484 at sms.ed.ac.uk (Georgina Brennan)
Date: Wed, 06 Aug 2014 10:49:16 +0100
Subject: [R-sig-ME] lmer not working
Message-ID: <53E1FA1C.9040802@sms.ed.ac.uk>

Dear list,

I am using the lme4 package on R studio (v.0.98.994)****. I haven't used 
it in a while but I have been regularly updating my packages.  Recently 
I attempted to run a simple mixed model:> 
lmer(mean.perDay~complexity+(1|regime),data) and I get the following 
error message:

Error in get(name, envir = asNamespace(pkg), inherits = FALSE) :
   object '.setDummyField' not found


My question is, has anyone else faced any difficulty using lmer and if 
so can you advise me on how to fix my problem?  I am a PC (windows 7) user.

Thanks,

Georgina

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140806/7a6345e0/attachment.pl>

From E.W.Tobi at lumc.nl  Wed Aug  6 16:04:40 2014
From: E.W.Tobi at lumc.nl (E.W.Tobi at lumc.nl)
Date: Wed, 6 Aug 2014 14:04:40 +0000
Subject: [R-sig-ME] discrepency with paired test when adding concordant
 paired data to lmer()
Message-ID: <85454AB97CEF1347BD44F61CAF585E8A62223D80@mail-mb1.lumcnet.prod.intern>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140806/50eaeb13/attachment.pl>

From Thierry.ONKELINX at inbo.be  Wed Aug  6 16:09:29 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 6 Aug 2014 14:09:29 +0000
Subject: [R-sig-ME] lmer not working
In-Reply-To: <53E1FA1C.9040802@sms.ed.ac.uk>
References: <53E1FA1C.9040802@sms.ed.ac.uk>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3AC9668@inbomail.inbo.be>

Dear Georgina,

Have to tried to run your code in a fresh session? Can you provide a reproducible example of your problem and the output of sessionInfo()?

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Georgina Brennan
Verzonden: woensdag 6 augustus 2014 11:49
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] lmer not working

Dear list,

I am using the lme4 package on R studio (v.0.98.994)****. I haven't used it in a while but I have been regularly updating my packages.  Recently I attempted to run a simple mixed model:>
lmer(mean.perDay~complexity+(1|regime),data) and I get the following error message:

Error in get(name, envir = asNamespace(pkg), inherits = FALSE) :
   object '.setDummyField' not found


My question is, has anyone else faced any difficulty using lmer and if so can you advise me on how to fix my problem?  I am a PC (windows 7) user.

Thanks,

Georgina

* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From steve.walker at utoronto.ca  Wed Aug  6 16:30:20 2014
From: steve.walker at utoronto.ca (Steve Walker)
Date: Wed, 06 Aug 2014 10:30:20 -0400
Subject: [R-sig-ME] lmer not working
In-Reply-To: <AA818EAD2576BC488B4F623941DA7427F3AC9668@inbomail.inbo.be>
References: <53E1FA1C.9040802@sms.ed.ac.uk>
	<AA818EAD2576BC488B4F623941DA7427F3AC9668@inbomail.inbo.be>
Message-ID: <53E23BFC.8070203@utoronto.ca>

Hi Georgina,

I agree with Thierry that sessionInfo() would be very useful, 
particularly given that this particular issue has been known to occur 
_only_ for R version 3.0.0 (e.g. 3.0.1 is fine).  The following links 
may be helpful:

https://github.com/lme4/lme4/issues/54
http://comments.gmane.org/gmane.comp.lang.r.lme4.devel/10720

So unfortunately you might need to just update R.

Cheers,
Steve

On 2014-08-06, 10:09 AM, ONKELINX, Thierry wrote:
> Dear Georgina,
>
> Have to tried to run your code in a fresh session? Can you provide a reproducible example of your problem and the output of sessionInfo()?
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> + 32 2 525 02 51
> + 32 54 43 61 85
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
>
> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Georgina Brennan
> Verzonden: woensdag 6 augustus 2014 11:49
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] lmer not working
>
> Dear list,
>
> I am using the lme4 package on R studio (v.0.98.994)****. I haven't used it in a while but I have been regularly updating my packages.  Recently I attempted to run a simple mixed model:>
> lmer(mean.perDay~complexity+(1|regime),data) and I get the following error message:
>
> Error in get(name, envir = asNamespace(pkg), inherits = FALSE) :
>     object '.setDummyField' not found
>
>
> My question is, has anyone else faced any difficulty using lmer and if so can you advise me on how to fix my problem?  I am a PC (windows 7) user.
>
> Thanks,
>
> Georgina
>
> * * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
> Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
> The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


From Thierry.ONKELINX at inbo.be  Wed Aug  6 16:42:25 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 6 Aug 2014 14:42:25 +0000
Subject: [R-sig-ME] lmer not working
In-Reply-To: <201408061421.s76EL812019851@lmtp1.ucs.ed.ac.uk>
References: <201408061421.s76EL812019851@lmtp1.ucs.ed.ac.uk>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3AC96E0@inbomail.inbo.be>

Dear Georgina,

Please the mailing list in cc. Someone else might join the discussion.

sessionInfo() gives all loaded packages and their version. That helps to see which versions you used.

Your code seems OK. So if it works in a clean session (try stand-alone R as well), then the data object might be the culprit. It's hard to diagnose the problem without it. See http://adv-r.had.co.nz/Reproducibility.html for more info on how to make a reproducible example. Note that it doesn't have to be the actual dataset. A dummy dataset that replicates the problem is OK.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: Georgina Brennan [mailto:g.l.brennan at sms.ed.ac.uk]
Verzonden: woensdag 6 augustus 2014 16:21
Aan: ONKELINX, Thierry
Onderwerp: RE: [R-sig-ME] lmer not working

Hi Thierry,

Thanks for your email. This is the first time I've emailed a group with an R problem and so I've never had to forward and examples of my data. For this reason can you tell me exactly what I need to send you for it to be a reproducible example?

Thanks,

Georgina

On 6 Aug 2014 15:09, "ONKELINX, Thierry" <Thierry.ONKELINX at inbo.be> wrote:
>
> Dear Georgina,
>
> Have to tried to run your code in a fresh session? Can you provide a reproducible example of your problem and the output of sessionInfo()?
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and Forest team Biometrie & Kwaliteitszorg / team Biometrics & Quality
> Assurance Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> + 32 2 525 02 51
> + 32 54 43 61 85
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
>
> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org
> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Georgina
> Brennan
> Verzonden: woensdag 6 augustus 2014 11:49
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] lmer not working
>
> Dear list,
>
> I am using the lme4 package on R studio (v.0.98.994)****. I haven't
> used it in a while but I have been regularly updating my packages.
> Recently I attempted to run a simple mixed model:>
> lmer(mean.perDay~complexity+(1|regime),data) and I get the following error message:
>
> Error in get(name, envir = asNamespace(pkg), inherits = FALSE) :
>    object '.setDummyField' not found
>
>
> My question is, has anyone else faced any difficulty using lmer and if so can you advise me on how to fix my problem?  I am a PC (windows 7) user.
>
> Thanks,
>
> Georgina
>
> * * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * *
> * Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
> The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.
>

--
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.

* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.

From steve.walker at utoronto.ca  Wed Aug  6 18:19:10 2014
From: steve.walker at utoronto.ca (Steve Walker)
Date: Wed, 06 Aug 2014 12:19:10 -0400
Subject: [R-sig-ME] autocorrelated errors
In-Reply-To: <CAErODj_WeH+EEhE1zsfFRSYCZQ6sPJFQVumeOGkzO_EjVAngYw@mail.gmail.com>
References: <CAErODj_WeH+EEhE1zsfFRSYCZQ6sPJFQVumeOGkzO_EjVAngYw@mail.gmail.com>
Message-ID: <53E2557E.90300@utoronto.ca>

Hi Paul,

tl;dr  There is some work in this direction, but unfortunately it is 
still somewhat experimental.

1. It is currently not possible to fit models with correlated residuals, 
per se, in lme4.  This is because the c++ machinery in lme4 only allows 
for observation weights (heterogeneous variance), not correlations.

2. Having said that, there is enough of this machinery exposed to fit 
models with flexible covariance structures in the random effects 
covariance matrix, if you are willing to write code for these 
structures.  There is currently no API on how to do this, although such 
an API is a long-term goal.

3. The flexLambda branch of lme4 on github is currently being developed 
specifically to facilitate the development of such flexible covariance 
structures.  It can be installed with:  install_github("lme4", user = 
"lme4", ref = "flexLambda").  However, this branch is not stable and 
should be considered experimental.

4. Fabian Scheipl has implemented AR1, compound symmetry, and diagonal 
structures in flexLambda (see 
https://github.com/lme4/lme4/blob/flexLambda/R/reGenerators.R).  Note 
however that there are no special functions for interpreting the output 
of such structures (e.g. plot, summary, etc...), and so unfortunately at 
this point you have to "know what you are doing".

5. All of these structures in flexLambda take place in the relative 
covariance factor for the random-effects, Lambda, and not in the 
residual variance, sigma^2.  One might be tempted to set the residual 
variance to zero, and handle residual variance in the relative 
covariance factor, Lambda.  Then one could construct a covariance 
structure that is effectively for the residuals, but using Lambda 
instead of sigma^2.  One challenge here is that lme4 machinery cannot 
handle models with zero residual variance (i.e. sigma^2 = 0) -- roughly 
because sigma^2 scales both the residual variance and the random-effects 
covariance matrix.  One may carefully set prior weights to get around 
this (https://github.com/lme4/lme4/issues/224#issuecomment-50510943), 
but this is somewhat hackish.

6. The modular approach to lmer and glmer may also be useful, if you 
just want to hack some specific model fits.  See ?modular and the 
Appendix of the lmer preprint (http://arxiv.org/abs/1406.5823).  The 
main difference between the modular and flexLambda approaches is how the 
covariance parameters are mapped into Lambda (see the last paragraph on 
p. 20 of the preprint for more details).

Cheers,
Steve


On 2014-08-05, 7:23 PM, Paul Johnson wrote:
> Sorry to bother you, but
>
> I ask here every year or so if anybody is working on lme4 with time or
> spatially correlated random errors. Bring corStruct back to life?
>
> If nobody is, maybe we could start a project together? I'm getting
> great & fast estimates from lme4 with the cross sectional models, but
> to work on longitudinal panels, we need some AR(1) error terms, or
> such.
>
> pj
>


From smit.reuben at gmail.com  Wed Aug  6 19:33:04 2014
From: smit.reuben at gmail.com (Reuben Smit)
Date: Wed, 6 Aug 2014 12:33:04 -0500
Subject: [R-sig-ME] Model diagnostics for a glmmadmb negative binomial
Message-ID: <CAFFAEtjoa8o55bJnaW=Xn4Cpxyf2Dd1dCTADTtcvVqZnEvjMfg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140806/03c9471a/attachment.pl>

From pauljohn32 at gmail.com  Wed Aug  6 19:44:07 2014
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Wed, 6 Aug 2014 12:44:07 -0500
Subject: [R-sig-ME] autocorrelated errors
In-Reply-To: <53E2557E.90300@utoronto.ca>
References: <CAErODj_WeH+EEhE1zsfFRSYCZQ6sPJFQVumeOGkzO_EjVAngYw@mail.gmail.com>
	<53E2557E.90300@utoronto.ca>
Message-ID: <CAErODj9D0TshRM=Rb0Ft7fBS7+vDAZV8my0_NFow25V4d7e3Gw@mail.gmail.com>

That's a terrific email. Thanks so much. Clearly, people thinking ahead.
I'll check out the flexLambda branch.

I was searching CRAN and found a poisson model with conditional
heteroskedasticity  ("acp" : Autoregressive Conditional Poisson). It
made me day dream of finding any "one unit" regression model and just
throwing it at a multi-level tool like lmer.  I'm pretty sure that's
what the Stata package gllaam does, it fits everything, but is super
slow.  So maybe I should be more careful what I wish for.



On Wed, Aug 6, 2014 at 11:19 AM, Steve Walker <steve.walker at utoronto.ca> wrote:
> Hi Paul,
>
> tl;dr  There is some work in this direction, but unfortunately it is still
> somewhat experimental.
>
> 1. It is currently not possible to fit models with correlated residuals, per
> se, in lme4.  This is because the c++ machinery in lme4 only allows for
> observation weights (heterogeneous variance), not correlations.
>
> 2. Having said that, there is enough of this machinery exposed to fit models
> with flexible covariance structures in the random effects covariance matrix,
> if you are willing to write code for these structures.  There is currently
> no API on how to do this, although such an API is a long-term goal.
>
> 3. The flexLambda branch of lme4 on github is currently being developed
> specifically to facilitate the development of such flexible covariance
> structures.  It can be installed with:  install_github("lme4", user =
> "lme4", ref = "flexLambda").  However, this branch is not stable and should
> be considered experimental.
>
> 4. Fabian Scheipl has implemented AR1, compound symmetry, and diagonal
> structures in flexLambda (see
> https://github.com/lme4/lme4/blob/flexLambda/R/reGenerators.R).  Note
> however that there are no special functions for interpreting the output of
> such structures (e.g. plot, summary, etc...), and so unfortunately at this
> point you have to "know what you are doing".
>
> 5. All of these structures in flexLambda take place in the relative
> covariance factor for the random-effects, Lambda, and not in the residual
> variance, sigma^2.  One might be tempted to set the residual variance to
> zero, and handle residual variance in the relative covariance factor,
> Lambda.  Then one could construct a covariance structure that is effectively
> for the residuals, but using Lambda instead of sigma^2.  One challenge here
> is that lme4 machinery cannot handle models with zero residual variance
> (i.e. sigma^2 = 0) -- roughly because sigma^2 scales both the residual
> variance and the random-effects covariance matrix.  One may carefully set
> prior weights to get around this
> (https://github.com/lme4/lme4/issues/224#issuecomment-50510943), but this is
> somewhat hackish.
>
> 6. The modular approach to lmer and glmer may also be useful, if you just
> want to hack some specific model fits.  See ?modular and the Appendix of the
> lmer preprint (http://arxiv.org/abs/1406.5823).  The main difference between
> the modular and flexLambda approaches is how the covariance parameters are
> mapped into Lambda (see the last paragraph on p. 20 of the preprint for more
> details).
>
> Cheers,
> Steve
>
>
>
> On 2014-08-05, 7:23 PM, Paul Johnson wrote:
>>
>> Sorry to bother you, but
>>
>> I ask here every year or so if anybody is working on lme4 with time or
>> spatially correlated random errors. Bring corStruct back to life?
>>
>> If nobody is, maybe we could start a project together? I'm getting
>> great & fast estimates from lme4 with the cross sectional models, but
>> to work on longitudinal panels, we need some AR(1) error terms, or
>> such.
>>
>> pj
>>
>



-- 
Paul E. Johnson
Professor, Political Science      Assoc. Director
1541 Lilac Lane, Room 504      Center for Research Methods
University of Kansas                 University of Kansas
http://pj.freefaculty.org               http://quant.ku.edu


From zofia.taranu at gmail.com  Thu Aug  7 16:13:39 2014
From: zofia.taranu at gmail.com (Zofia Ecaterina Taranu)
Date: Thu, 7 Aug 2014 10:13:39 -0400
Subject: [R-sig-ME] tolPwrss threshold
Message-ID: <BB38D68A-BD4E-4D0F-AE6C-EF8965264E8D@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140807/d2686434/attachment.pl>

From shankarlanke at gmail.com  Fri Aug  8 01:17:12 2014
From: shankarlanke at gmail.com (Shankar Lanke)
Date: Thu, 7 Aug 2014 17:17:12 -0600
Subject: [R-sig-ME] Summary of Subgroups
Message-ID: <CAKFdi_uLmpB=eWrUPuutXBjquF4Y2fYzN_zHL2_fXp1ONK48yA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140807/a9574c36/attachment.pl>

From bbolker at gmail.com  Fri Aug  8 01:40:33 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 07 Aug 2014 19:40:33 -0400
Subject: [R-sig-ME] Summary of Subgroups
In-Reply-To: <CAKFdi_uLmpB=eWrUPuutXBjquF4Y2fYzN_zHL2_fXp1ONK48yA@mail.gmail.com>
References: <CAKFdi_uLmpB=eWrUPuutXBjquF4Y2fYzN_zHL2_fXp1ONK48yA@mail.gmail.com>
Message-ID: <53E40E71.5040807@gmail.com>

On 14-08-07 07:17 PM, Shankar Lanke wrote:
> Dear R group,
> 
> I have a query about summarizing the sub groups. I want to calculate mean
> or median of  BMI & SWTZ of ID 1 to 3 as shown in below table. Actually I
> have 4500 ID's.
> I appreciate your assistance and guidance.
> 
>   ID BMI SWTZ  1 22.3 97.7  1 22.3 116  1 22.3 116  1 22.3 110.8  1 22.3
> 110.8  2 27.3 135.8  2 23 119  2 29.4 65.4  2 29.4 65.4  2 29.4 65.4  3 22.3
> 128.1  3 22.3 128.1  3 22.3 128.1  3 22.3 128.1  3 22.3 114.7
> 
> Thank you very much in advance.
> 

  This seems to be a basic R question, not particularly mixed-model related?

  I would try

library("plyr")
ddply(your_data,"ID",summarise,meanBMI=mean(BMI),medBMI=median(BMI),
        meanSWTZ=mean(SWTZ),medSWTZ=median(SWTZ))

There are many other ways to do this, some faster.
Follow-ups to r-help or stackoverflow please.

  Ben Bolker


From chris at trickysolutions.com.au  Fri Aug  8 01:50:55 2014
From: chris at trickysolutions.com.au (Chris Howden)
Date: Fri, 8 Aug 2014 09:50:55 +1000
Subject: [R-sig-ME] Summary of Subgroups
In-Reply-To: <CAKFdi_uLmpB=eWrUPuutXBjquF4Y2fYzN_zHL2_fXp1ONK48yA@mail.gmail.com>
References: <CAKFdi_uLmpB=eWrUPuutXBjquF4Y2fYzN_zHL2_fXp1ONK48yA@mail.gmail.com>
Message-ID: <-7601849205934115670@unknownmsgid>

Have a look at aggregate in base r or ddply in plyr package.

Chris Howden
Founding Partner
Tricky Solutions
Tricky Solutions 4 Tricky Problems
Evidence Based Strategic Development, IP Commercialisation and
Innovation, Data Analysis, Modelling and Training

(mobile) 0410 689 945
(fax / office)
chris at trickysolutions.com.au

Disclaimer: The information in this email and any attachments to it are
confidential and may contain legally privileged information. If you are not
the named or intended recipient, please delete this communication and
contact us immediately. Please note you are not authorised to copy,
use or disclose this communication or any attachments without our
consent. Although this email has been checked by anti-virus software,
there is a risk that email messages may be corrupted or infected by
viruses or other
interferences. No responsibility is accepted for such interference. Unless
expressly stated, the views of the writer are not those of the
company. Tricky Solutions always does our best to provide accurate
forecasts and analyses based on the data supplied, however it is
possible that some important predictors were not included in the data
sent to us. Information provided by us should not be solely relied
upon when making decisions and clients should use their own judgement.

> On 8 Aug 2014, at 9:19, Shankar Lanke <shankarlanke at gmail.com> wrote:
>
> Dear R group,
>
> I have a query about summarizing the sub groups. I want to calculate mean
> or median of  BMI & SWTZ of ID 1 to 3 as shown in below table. Actually I
> have 4500 ID's.
> I appreciate your assistance and guidance.
>
>  ID BMI SWTZ  1 22.3 97.7  1 22.3 116  1 22.3 116  1 22.3 110.8  1 22.3
> 110.8  2 27.3 135.8  2 23 119  2 29.4 65.4  2 29.4 65.4  2 29.4 65.4  3 22.3
> 128.1  3 22.3 128.1  3 22.3 128.1  3 22.3 128.1  3 22.3 114.7
>
> Thank you very much in advance.
> --
> Regards,
>
>    [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Fri Aug  8 02:03:32 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 7 Aug 2014 20:03:32 -0400
Subject: [R-sig-ME] tolPwrss threshold
In-Reply-To: <BB38D68A-BD4E-4D0F-AE6C-EF8965264E8D@gmail.com>
References: <BB38D68A-BD4E-4D0F-AE6C-EF8965264E8D@gmail.com>
Message-ID: <CABghstRS4W=cbSR_f--Uq+Zc9TXXLPGpWrBmp--nPpaCNp-3pA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140807/f5b820b6/attachment.pl>

From bbolker at gmail.com  Fri Aug  8 02:16:48 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 7 Aug 2014 20:16:48 -0400
Subject: [R-sig-ME] Model diagnostics for a glmmadmb negative binomial
In-Reply-To: <CAFFAEtjoa8o55bJnaW=Xn4Cpxyf2Dd1dCTADTtcvVqZnEvjMfg@mail.gmail.com>
References: <CAFFAEtjoa8o55bJnaW=Xn4Cpxyf2Dd1dCTADTtcvVqZnEvjMfg@mail.gmail.com>
Message-ID: <CABghstT5yKXzNZDY7GHbFX+Oer2SwoCGyX0mwhCyW+sc7vWg7Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140807/6aacd346/attachment.pl>

From smit.reuben at gmail.com  Fri Aug  8 19:05:41 2014
From: smit.reuben at gmail.com (Reuben Smit)
Date: Fri, 8 Aug 2014 12:05:41 -0500
Subject: [R-sig-ME] Non-conformable arguments while predicting with
	glmmadmb_model
Message-ID: <CAFFAEtgsFN1OJcSRmj3sYvsPq+4AhmvnVeuqTMUaXU0dLLmN4w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140808/52cedda6/attachment.pl>

From bbolker at gmail.com  Fri Aug  8 19:33:54 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 08 Aug 2014 13:33:54 -0400
Subject: [R-sig-ME] Non-conformable arguments while predicting with
	glmmadmb_model
In-Reply-To: <CAFFAEtgsFN1OJcSRmj3sYvsPq+4AhmvnVeuqTMUaXU0dLLmN4w@mail.gmail.com>
References: <CAFFAEtgsFN1OJcSRmj3sYvsPq+4AhmvnVeuqTMUaXU0dLLmN4w@mail.gmail.com>
Message-ID: <53E50A02.9070508@gmail.com>

On 14-08-08 01:05 PM, Reuben Smit wrote:
> I am attempting to do an observed versus predicted assessment of a negative
> binomial glmm.
> 
> My first step was to simply use the predict( ) function with my glmmadmb
> object on the dataset used to generate the model:
> 
> glmm_dataset$prediction<-predict(glmmadmb_object, glmm_dataset,
> type="response")
> 
> But the error message results:
> Error in X %*% beta : non-conformable arguments
> 
> What has baffled me is that when I use the same glmmadmb_object to predict
> onto newdata, in the same way above, it runs the predictions fine, with no
> error message and credible results.
> 
> Does anybody have ideas about what is going on here?
> 

  Reproducible example please?

  Ben Bolker


From henrik.singmann at psychologie.uni-freiburg.de  Sat Aug  9 20:12:14 2014
From: henrik.singmann at psychologie.uni-freiburg.de (Henrik Singmann)
Date: Sat, 09 Aug 2014 20:12:14 +0200
Subject: [R-sig-ME] Group size in mixed/multilevel model: How to obtain
	weighted effects.
Message-ID: <53E6647E.40207@psychologie.uni-freiburg.de>

Dear list,

I have a relatively basic question regarding the influence of group size in a simple mixed model with 1 grouping factor (i.e., a one-level multilevel model). My data has one numerical DV, one numerical IV, and one grouping factor with 19 levels. Importantly, the number of observations in each group dramatically differs, from 5 to 136 (complete data and code is given below).

My problem is that it seems that (a) only the small groups show an effect and not the large groups and furthermore (b) results of a simple mixed model are not taking into account that the larger groups do not show an effect but tend to reflect something like an unweighted means (i.e., weighing the effect of each groups identically).

In other words: When looking at the data the overall or weighted mean (i.e., not taking grouping into account) and overall correlation between DV and IV are basically 0: Mean = -0.2 and r = -0.04.
In contrast, unweighted means (i.e., same weight for each group) show rather strong effects: Mean = -1.1 and r = -.26. Now it seems that the mixed model points strongly towards the unweighted means although there are dramatic differences in group sizes. The estimates mean is -1.0 and the estimated effect of the IV is also substantial.

After removing the four smallest groups which amount to less than 4% of all data points and are basically the only ones showing a dramatic effect, the values become much more reasonable. Estimated mean = -0.5 and effect of IV also smaller.

My question is what to do in such a situation:
- Is it a good reasons to remove small groups because of this?
- Is there a way to take group size into account like in a meta-analysis?
- Is there literature discussing this issue?

Thanks in advance,
Henrik


###### Complete example code ######

require(lattice)  # for plot of data
require(lme4)
require(plyr)  # for unweighted means
dat <- read.table("http://pastebin.com/raw.php?i=KiQ1kkew")

#plot data
dat_print <- within(dat, levels(group) <- paste0(levels(group), ", n= ", table(group)))
xyplot(dv ~ iv|group, dat_print, panel = function(x, y) {
          panel.xyplot(x, y)
          panel.abline(lm(y ~ x))
        })  # number is group size

# weighted means
cor(dat$dv, dat$iv)
mean(dat$dv)

# unweighted means:
mean(daply(dat, .(group), function(x) cor(x$dv, x$iv)))
mean(daply(dat, .(group), function(x) mean(x$dv)))


# full model:
summary(lmer(dv~I(scale(iv, scale=FALSE))+(iv|group), dat))

# model with small groups removed:
groups_exclude <- c("b", "c", "d", "s")
ndat <- dat[!(dat$group %in% groups_exclude),]
summary(lmer(dv~I(scale(iv, scale=FALSE))+(iv|group), ndat))



-- 
Dr. Henrik Singmann
PostDoc
Albert-Ludwigs-Universit?t Freiburg, Germany
http://www.psychologie.uni-freiburg.de/Members/singmann


From jake987722 at hotmail.com  Sun Aug 10 01:13:15 2014
From: jake987722 at hotmail.com (Jake Westfall)
Date: Sat, 9 Aug 2014 17:13:15 -0600
Subject: [R-sig-ME] Group size in mixed/multilevel model: How to obtain
 weighted effects.
In-Reply-To: <53E6647E.40207@psychologie.uni-freiburg.de>
References: <53E6647E.40207@psychologie.uni-freiburg.de>
Message-ID: <BAY172-W44A571071071EC88520221CBEF0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140809/46146037/attachment.pl>

From s1163484 at sms.ed.ac.uk  Thu Aug  7 13:40:04 2014
From: s1163484 at sms.ed.ac.uk (Georgina Brennan)
Date: Thu, 07 Aug 2014 12:40:04 +0100
Subject: [R-sig-ME] lmer not working
In-Reply-To: <53E23BFC.8070203@utoronto.ca>
References: <53E1FA1C.9040802@sms.ed.ac.uk>
	<AA818EAD2576BC488B4F623941DA7427F3AC9668@inbomail.inbo.be>
	<53E23BFC.8070203@utoronto.ca>
Message-ID: <53E36594.4080404@sms.ed.ac.uk>

Hi all,

Thanks very much for your advise.  Updating R has solved my problem.  
Although I have been keeping my R studio up to date I neglected my R 
installation.

Thanks again,

Georgina

On 06/08/2014 15:30, Steve Walker wrote:
> Hi Georgina,
>
> I agree with Thierry that sessionInfo() would be very useful, 
> particularly given that this particular issue has been known to occur 
> _only_ for R version 3.0.0 (e.g. 3.0.1 is fine).  The following links 
> may be helpful:
>
> https://github.com/lme4/lme4/issues/54
> http://comments.gmane.org/gmane.comp.lang.r.lme4.devel/10720
>
> So unfortunately you might need to just update R.
>
> Cheers,
> Steve
>
> On 2014-08-06, 10:09 AM, ONKELINX, Thierry wrote:
>> Dear Georgina,
>>
>> Have to tried to run your code in a fresh session? Can you provide a 
>> reproducible example of your problem and the output of sessionInfo()?
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for 
>> Nature and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>> + 32 2 525 02 51
>> + 32 54 43 61 85
>> Thierry.Onkelinx at inbo.be
>> www.inbo.be
>>
>> To call in the statistician after the experiment is done may be no 
>> more than asking him to perform a post-mortem examination: he may be 
>> able to say what the experiment died of.
>> ~ Sir Ronald Aylmer Fisher
>>
>> The plural of anecdote is not data.
>> ~ Roger Brinner
>>
>> The combination of some data and an aching desire for an answer does 
>> not ensure that a reasonable answer can be extracted from a given 
>> body of data.
>> ~ John Tukey
>>
>>
>> -----Oorspronkelijk bericht-----
>> Van: r-sig-mixed-models-bounces at r-project.org 
>> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Georgina 
>> Brennan
>> Verzonden: woensdag 6 augustus 2014 11:49
>> Aan: r-sig-mixed-models at r-project.org
>> Onderwerp: [R-sig-ME] lmer not working
>>
>> Dear list,
>>
>> I am using the lme4 package on R studio (v.0.98.994)****. I haven't 
>> used it in a while but I have been regularly updating my packages.  
>> Recently I attempted to run a simple mixed model:>
>> lmer(mean.perDay~complexity+(1|regime),data) and I get the following 
>> error message:
>>
>> Error in get(name, envir = asNamespace(pkg), inherits = FALSE) :
>>     object '.setDummyField' not found
>>
>>
>> My question is, has anyone else faced any difficulty using lmer and 
>> if so can you advise me on how to fix my problem?  I am a PC (windows 
>> 7) user.
>>
>> Thanks,
>>
>> Georgina
>>
>> * * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
>> Dit bericht en eventuele bijlagen geven enkel de visie van de 
>> schrijver weer en binden het INBO onder geen enkel beding, zolang dit 
>> bericht niet bevestigd is door een geldig ondertekend document.
>> The views expressed in this message and any annex are purely those of 
>> the writer and may not be regarded as stating an official position of 
>> INBO, as long as the message is not confirmed by a duly signed document.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
>


-- 
Georgina Brennan
Collins Lab
Institute of Evolutionary Biology
University of Edinburgh

Webpage: http://www.smallbutmighty.bio.ed.ac.uk


The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From henrik.singmann at psychologie.uni-freiburg.de  Sun Aug 10 18:16:38 2014
From: henrik.singmann at psychologie.uni-freiburg.de (Henrik Singmann)
Date: Sun, 10 Aug 2014 18:16:38 +0200
Subject: [R-sig-ME] Group size in mixed/multilevel model: How to obtain
 weighted effects.
In-Reply-To: <BAY172-W44A571071071EC88520221CBEF0@phx.gbl>
References: <53E6647E.40207@psychologie.uni-freiburg.de>
	<BAY172-W44A571071071EC88520221CBEF0@phx.gbl>
Message-ID: <53E79AE6.4040505@psychologie.uni-freiburg.de>

Hi Jake,

I fully agree that what the model does is not necessarily wrong. It may well be that the groups should be treated equally. However in my case, each data point corresponds to one participant and each group to one study (with somewhat different characteristics). Hence, I would like to obtain the weighted estimate and rather treat each data point equal (and not each group).

Your idea of specifically modeling group size is quite appealing. I am however somewhat unsure on how to interpret the "grand mean of the group sizes". Is this the "weighted effect estimate" in which each data point (i.e., participant) is weighted equally? Given that this is how the grand mean of the group size is created it seems to be the case.

Thanks for the pointer to the paper. Will read it carefully.

Cheers,
Henrik


PS: For interested readers, this is how to obtain the estimate with "grand mean of group sizes":

dat <- within(dat, {
   size <- table(group)[paste(group)]
   ivC <- iv - mean(iv)
   sizeC <- size - mean(size)  # "mean(sizes)" is the grand mean of group sizes
})
summary(lmer(dv ~ ivC*sizeC + (ivC|group), data=dat))


Am 10.08.2014 01:13, schrieb Jake Westfall:
> Hi Henrik,
>
> It's not obvious to me that what the model is doing is necessarily "wrong." In your data, the effect of IV on DV depends on group size. One possibility is to model this relationship explicitly by including group size as predictor in the model which interacts with IV.
>
> dat <- within(dat, {
>    size <- table(group)[paste(group)]
>    ivC <- iv - mean(iv)
>    sizeC <- size - mean(table(group))
> })
> summary(lmer(dv ~ ivC*sizeC + (ivC|group), data=dat))
>
> There is a size*IV interaction, t = 2.39. At the average group size (n=46) there is a negative effect of IV on DV, t = -2.82. At the grand mean of the group sizes (n=85; larger groups have more influence here), there is not a reliable relationship, t = -0.62.
>
> You could also try looking at separating out the within-group and between-group effects of the IV, as described by Bell & Jones (2014) and others.
>
> Bell, A., & Jones, K. (2014). Explaining fixed effects:
> Random effects modeling of time-series cross-sectional and panel data. Political Science Research and Methods.
>
> Jake
>
>> Date: Sat, 9 Aug 2014 20:12:14 +0200
>> From: henrik.singmann at psychologie.uni-freiburg.de
>> To: r-sig-mixed-models at r-project.org
>> Subject: [R-sig-ME] Group size in mixed/multilevel model: How to obtain	weighted effects.
>>
>> Dear list,
>>
>> I have a relatively basic question regarding the influence of group size in a simple mixed model with 1 grouping factor (i.e., a one-level multilevel model). My data has one numerical DV, one numerical IV, and one grouping factor with 19 levels. Importantly, the number of observations in each group dramatically differs, from 5 to 136 (complete data and code is given below).
>>
>> My problem is that it seems that (a) only the small groups show an effect and not the large groups and furthermore (b) results of a simple mixed model are not taking into account that the larger groups do not show an effect but tend to reflect something like an unweighted means (i.e., weighing the effect of each groups identically).
>>
>> In other words: When looking at the data the overall or weighted mean (i.e., not taking grouping into account) and overall correlation between DV and IV are basically 0: Mean = -0.2 and r = -0.04.
>> In contrast, unweighted means (i.e., same weight for each group) show rather strong effects: Mean = -1.1 and r = -.26. Now it seems that the mixed model points strongly towards the unweighted means although there are dramatic differences in group sizes. The estimates mean is -1.0 and the estimated effect of the IV is also substantial.
>>
>> After removing the four smallest groups which amount to less than 4% of all data points and are basically the only ones showing a dramatic effect, the values become much more reasonable. Estimated mean = -0.5 and effect of IV also smaller.
>>
>> My question is what to do in such a situation:
>> - Is it a good reasons to remove small groups because of this?
>> - Is there a way to take group size into account like in a meta-analysis?
>> - Is there literature discussing this issue?
>>
>> Thanks in advance,
>> Henrik
>>
>>
>> ###### Complete example code ######
>>
>> require(lattice)  # for plot of data
>> require(lme4)
>> require(plyr)  # for unweighted means
>> dat <- read.table("http://pastebin.com/raw.php?i=KiQ1kkew")
>>
>> #plot data
>> dat_print <- within(dat, levels(group) <- paste0(levels(group), ", n= ", table(group)))
>> xyplot(dv ~ iv|group, dat_print, panel = function(x, y) {
>>            panel.xyplot(x, y)
>>            panel.abline(lm(y ~ x))
>>          })  # number is group size
>>
>> # weighted means
>> cor(dat$dv, dat$iv)
>> mean(dat$dv)
>>
>> # unweighted means:
>> mean(daply(dat, .(group), function(x) cor(x$dv, x$iv)))
>> mean(daply(dat, .(group), function(x) mean(x$dv)))
>>
>>
>> # full model:
>> summary(lmer(dv~I(scale(iv, scale=FALSE))+(iv|group), dat))
>>
>> # model with small groups removed:
>> groups_exclude <- c("b", "c", "d", "s")
>> ndat <- dat[!(dat$group %in% groups_exclude),]
>> summary(lmer(dv~I(scale(iv, scale=FALSE))+(iv|group), ndat))
>>
>>
>>
>> --
>> Dr. Henrik Singmann
>> PostDoc
>> Albert-Ludwigs-Universit?t Freiburg, Germany
>> http://www.psychologie.uni-freiburg.de/Members/singmann
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>   		 	   		
> 	[[alternative HTML version deleted]]
>
>
>

-- 
Dr. Henrik Singmann
Albert-Ludwigs-Universit?t Freiburg, Germany
http://www.psychologie.uni-freiburg.de/Members/singmann


From jake987722 at hotmail.com  Sun Aug 10 18:41:55 2014
From: jake987722 at hotmail.com (Jake Westfall)
Date: Sun, 10 Aug 2014 10:41:55 -0600
Subject: [R-sig-ME] Group size in mixed/multilevel model: How to obtain
 weighted effects.
In-Reply-To: <53E79AE6.4040505@psychologie.uni-freiburg.de>
References: <53E6647E.40207@psychologie.uni-freiburg.de>,
	<BAY172-W44A571071071EC88520221CBEF0@phx.gbl>,
	<53E79AE6.4040505@psychologie.uni-freiburg.de>
Message-ID: <BAY172-W93E643663C80A4C63AB85CBEC0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140810/d3fc43c3/attachment.pl>

From bbolker at gmail.com  Mon Aug 11 05:34:12 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 10 Aug 2014 23:34:12 -0400
Subject: [R-sig-ME] using Poisson glmer for non-integer data
In-Reply-To: <2908_1407719354_s7B19Dr1027441_CACaB4B7r18KjL5N5LeT-4etP4u_64Pkji93y7fhFacR0qGRrYA@mail.gmail.com>
References: <2908_1407719354_s7B19Dr1027441_CACaB4B7r18KjL5N5LeT-4etP4u_64Pkji93y7fhFacR0qGRrYA@mail.gmail.com>
Message-ID: <53E839B4.5000400@mcmaster.ca>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1


 [cc'ing to r-sig-mixed-models]

  I don't think it's crazy to use a Poisson distribution with
non-integer response values in some cases, but you're correct that
non-integer response values don't work in lme4 at present.  In
principle we could dig down and fix the problem (feel free to post an
issue at https://github.com/lme4/lme4/issues, with a simple
reproducible example ...) but I have to say it's not very high on our
list, because these are (usually? often?) cases where the original
model is somewhat suspect anyway.  I can suggest the following
workarounds:

  * try another package such as glmmML or glmmPQL
  * use an offset that characterizes the total lifespan; if you use
offset(log(lifespan)) that will effectively model success per unit
lifespan, and if you include log(lifespan) as a predictor (with the
standard log link) that will effectively model success as proportional
to (lifespan)^b, where b is a parameter to be estimated.

  Other discussion of Poisson with non-integer values

http://www.r-bloggers.com/poisson-regression-on-non-integers/
http://stats.stackexchange.com/questions/38530/how-does-a-poisson-distribution-work-when-modeling-continuous-data-and-does-it-r/38588#38588
http://stats.stackexchange.com/questions/70054/how-is-it-possible-that-poisson-glm-accepts-non-integer-numbers

  sincerely
    Ben Bolker

On 14-08-10 09:08 PM, Christina Painting wrote:
> Dear Prof Bolker,
> 
> I'm a behavioural ecologist at the University of Auckland in New 
> Zealand, and I currently have a masters student who is tackling
> some lifetime mating success data for the NZ giraffe weevil.
> 
> We were hoping you might be able to offer us some advice on an
> issue we are having using the /lme4/ R package. Our response
> variable is the average mating success of a giraffe weevil for its
> lifetime (total success/lifespan) and we are looking at this in
> relation to body size and time of year. Using your 2008 TREE paper
> on using GLMMs we figured out that the best method to use was a
> model with Poisson distribution with Laplace approximation because
> av. mating success is non-normally distrubited, can't be fixed with
> standard transformations and has a mean <5. However, because the
> data are not integers we have run into problems, with the models
> returning warnings about the data being non-integer, and then we
> can't get log-lik and AIC values.
> 
> Reading online on various forums that you have been part of
> suggests we aren't the only ones having this problem, and I
> wondered if you had any solutions to this problem, or could suggest
> another method to use that would be robust to our average measure
> of mating success?
> 
> We would greatly appreciate any advice you can offer, and thank you
> in advance
> 
> Kind regards, Chrissie Painting
> 
> *Dr Chrissie Painting* Post Doctoral Researcher School of
> Biological Sciences University of Auckland 
> cpai015 at aucklanduni.ac.nz <mailto:cpai015 at aucklanduni.ac.nz> 
> https://sites.google.com/site/paintingchristina/ Mobile: +64 27 306
> 1610

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJT6Dm0AAoJEOCV5YRblxUH7WQH/RYNGkliTnUkVyzCrnA0MNl9
sPTR6Vkz7Hdxm8YdHzuSHa1pzyyVmkuVMQP4IW9nD2II872nJxjTJgmC13Ji2bCj
dgV+HPTg2yQeYZqh6NQXWGvTWjrn8rQwzKF/2sxn5l3YWk5T13egy6lw2DI5FQVi
+xnOFMBkcnTQ3eysuO+8zaJFN6550IKQ6UT79D8hQ2TiHEXGrq2DeHVmp8Uqr2UY
f4Mx4G+NBRjmdtYoeQpgK3baRw1uoOI40GcQRPUHzUVaVJVXxk1QfrDiReK8yErs
Mg+lxV7ylMgv0J0+prqBsS7wibeSN8k31ghXWQ9MrnxKusdlsbcicKQQ5dbmgTU=
=5+8D
-----END PGP SIGNATURE-----


From bokony.veronika at agrar.mta.hu  Sun Aug 10 16:14:57 2014
From: bokony.veronika at agrar.mta.hu (Bokony Veronika)
Date: Sun, 10 Aug 2014 16:14:57 +0200 (CEST)
Subject: [R-sig-ME] confidence intervals for random slopes
In-Reply-To: <1691693583.3097022.1407678920732.JavaMail.zimbra@agrar.mta.hu>
Message-ID: <1547889392.3097072.1407680097073.JavaMail.zimbra@agrar.mta.hu>

Dear all,

let me ask your advice about calculating confidence intervals for random slopes. I have a random intercept & random slope model like this:

lme(Y ~ X * fixfactor, random=~X|randomfactor)

where randomfactor has 9 levels. For each of these 9 levels, I can calculate the slope of X from the fixed and random effect estimates. I would like to add some measure of uncertainty to each of these 9 estimates, i.e. an SE or CI for each random slope. The random effects SD which is given by the lme summary output is not what I'm interested in. I got a very general tip that I could calculate credible intervals from posterior distributions using a bayesian approach, but I found no evident way of extracting these from MCMCglmm either.

I would be very grateful for any working example that can achieve this.

Best regards,

Veronika


Veronika B?kony PhD
"Lend?let" Evolutionary Ecology Research Group
Plant Protection Institute, Centre for Agricultural Research 
Hungarian Academy of Sciences
Herman Ott? ?t 15.
H-1022 Budapest, Hungary
+36 1 3918609
http://www.nki.hu/lendulet-evolucios-okologiai-kutatocsoport
http://ornithology.limnologia.hu/people/veronika-bokony/


From hughes.dupond at gmx.de  Mon Aug 11 18:13:45 2014
From: hughes.dupond at gmx.de (Lionel)
Date: Mon, 11 Aug 2014 18:13:45 +0200
Subject: [R-sig-ME] confidence intervals for random slopes
In-Reply-To: <1547889392.3097072.1407680097073.JavaMail.zimbra@agrar.mta.hu>
References: <1547889392.3097072.1407680097073.JavaMail.zimbra@agrar.mta.hu>
Message-ID: <53E8EBB9.4080900@gmx.de>

Dear Veronika,

The sim function from the arm package might be what you are looking for, 
there are some nice example at the end of the help page (?sim). It is 
then easy to extract from the simulation the credible intervals for the 
coefficient that do not vary per group (like fixfactor in your example), 
something like 
quantile(fixef(model.sim)[,"fixfactor.level2"],probs=c(0.025,0.5,0.975)) 
will do the job. For coefficient varying per group (like the slope of X) 
I am less sure but something like: 
quantile(ranef(model.sim)$randomfactor[,1,"X"],probs=c(0.025,0.5,0.975) 
would give you a credible interval for the random effect on the slope of 
X for group 1 (ie the interaction between the slope of X and the group 
1). I am not sure about how to combine this with the credible intervals 
from the slope in itself: 
quantile(fixef(model.sim)[,"X"],probs=c(0.025,0.5,0.975)).

I am very interested to see if other people on the list have other 
suggestion since I have been thinking about this for some time ...

Yours,
Lionel


On 10/08/2014 16:14, Bokony Veronika wrote:
> Dear all,
>
> let me ask your advice about calculating confidence intervals for random slopes. I have a random intercept & random slope model like this:
>
> lme(Y ~ X * fixfactor, random=~X|randomfactor)
>
> where randomfactor has 9 levels. For each of these 9 levels, I can calculate the slope of X from the fixed and random effect estimates. I would like to add some measure of uncertainty to each of these 9 estimates, i.e. an SE or CI for each random slope. The random effects SD which is given by the lme summary output is not what I'm interested in. I got a very general tip that I could calculate credible intervals from posterior distributions using a bayesian approach, but I found no evident way of extracting these from MCMCglmm either.
>
> I would be very grateful for any working example that can achieve this.
>
> Best regards,
>
> Veronika
>
>
> Veronika B?kony PhD
> "Lend?let" Evolutionary Ecology Research Group
> Plant Protection Institute, Centre for Agricultural Research
> Hungarian Academy of Sciences
> Herman Ott? ?t 15.
> H-1022 Budapest, Hungary
> +36 1 3918609
> http://www.nki.hu/lendulet-evolucios-okologiai-kutatocsoport
> http://ornithology.limnologia.hu/people/veronika-bokony/
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Mon Aug 11 18:29:31 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 11 Aug 2014 12:29:31 -0400
Subject: [R-sig-ME] confidence intervals for random slopes
In-Reply-To: <1547889392.3097072.1407680097073.JavaMail.zimbra@agrar.mta.hu>
References: <1547889392.3097072.1407680097073.JavaMail.zimbra@agrar.mta.hu>
Message-ID: <53E8EF6B.5040508@gmail.com>

On 14-08-10 10:14 AM, Bokony Veronika wrote:
> Dear all,
> 
> let me ask your advice about calculating confidence intervals for
> random slopes. I have a random intercept & random slope model like
> this:
> 
> lme(Y ~ X * fixfactor, random=~X|randomfactor)
> 
> where randomfactor has 9 levels. For each of these 9 levels, I can
> calculate the slope of X from the fixed and random effect estimates.
> I would like to add some measure of uncertainty to each of these 9
> estimates, i.e. an SE or CI for each random slope. The random effects
> SD which is given by the lme summary output is not what I'm
> interested in. I got a very general tip that I could calculate
> credible intervals from posterior distributions using a bayesian
> approach, but I found no evident way of extracting these from
> MCMCglmm either.
> 
> I would be very grateful for any working example that can achieve
> this.


library(lme4)
fm1 <- lmer(Reaction ~ Days + (Days | Subject), sleepstudy)
rslopes <- coef(fm1)$Subject[,"Days"]
varfix <- vcov(fm1)["Days","Days"]
re <- ranef(fm1,condVar=TRUE)
varcm <- attr(re$Subject,"postVar")[2,2,]
vartot <- varfix+varcm
library(plotrix)
plotCI(1:length(rslopes),rslopes,2*sqrt(vartot))

  Note that this approach ignores correlation between the conditional
mean/BLUP and the fixed-effect estimate, a topic which has been
previously debated on this list ...

Now with MCMCglmm, for comparison:

library(MCMCglmm)
## turns out we have to specify a slightly more informative prior ...
priorb <- list(R = list(V = diag(1), nu = 0.002),
      G = list(G1 = list(V = diag(2), nu = 0.002)))
fm2 <- MCMCglmm(Reaction~Days,random=~us(1+Days):Subject,
                data=sleepstudy,prior=priorb, pr=TRUE, verbose=FALSE)

fslope <- fm2$Sol[,"Days"]  ## fixed slope
## slope random effects
rslopes2 <- fm2$Sol[,grep("Subject\\.Days\\.Subject",colnames(fm2$Sol))]
dim(rslopes2)
allslopes <- sweep(rslopes2,1,fslope,"+")  ## fixed + random
allslopemean <- colMeans(allslopes)
allsd <- apply(allslopes,2,sd)

Compare:

plotCI(1:length(rslopes),rslopes,2*sqrt(vartot))
plotCI(1:length(rslopes),allslopemean,2*allsd,col=2,add=TRUE)


From spatrick at glos.ac.uk  Mon Aug 11 19:34:05 2014
From: spatrick at glos.ac.uk (PATRICK, Samantha)
Date: Mon, 11 Aug 2014 17:34:05 +0000
Subject: [R-sig-ME] Bivariate MCMCglmm with repeated measures
Message-ID: <4a47ae02f8a14cb2b24d3b88e03938e6@glos.ac.uk>

Hi

I running a bivariate GLMM, where both of my response variables have repeated measures.  A dummy data set would look like this:

Individual     Presence    Stage
1                      0                       1
1                      1                        1
1                      1                        2
1                      1                        2
2                     1                         1
2                     0                        1
2                     0                        1
2                     1                         2
2                     0                        2

There are a series of individuals.  For each individual we have measures presence/absence repeatedly during life stage 1 and then again repeatedly during life stage 2.

For a straight forward bivariate model, with a single measure per  individual (or repeated measures during only one life stage), the data could be set up like this:

Individual      Presence stage 1          Presence stage 2

However because I have repeated measures for both stages I am struggling to find out how to code the data so MCMCglmm can run.

Does anyone have any experience with this kind of data structure?  I can?t find anything on the R list.

Many Thanks

Sam

Dr Samantha Patrick
Research Fellow
Biosciences QU116
Francis Close Hall Campus
University of Gloucestershire
Cheltenham, GL50 4AZ, UK

Research Associate: OxNav, University of Oxford

******From 1st August - 14th November 2014 I will be
based in Montr?al, which is 5 hours behind GMT  ******

Tel: 07740 472 719
Skype: sammy_patrick
https://sites.google.com/site/samanthacpatrick/

-
?In the top 5 in the Green League Table; committed to sustainability?
This email is confidential to the intended recipient. If you have received it in error please notify the sender and delete it from your computer.
The University of Gloucestershire is a company limited by guarantee registered in England and Wales.  Registered number: 06023243.  Registered office: The Park, Cheltenham, GL50 2RH
Please consider the environment before printing this email.
-

From j.hadfield at ed.ac.uk  Mon Aug 11 20:47:00 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 11 Aug 2014 19:47:00 +0100
Subject: [R-sig-ME] Bivariate MCMCglmm with repeated measures
In-Reply-To: <4a47ae02f8a14cb2b24d3b88e03938e6@glos.ac.uk>
References: <4a47ae02f8a14cb2b24d3b88e03938e6@glos.ac.uk>
Message-ID: <20140811194700.12405iyy8lmx6m80@www.staffmail.ed.ac.uk>

Hi Sam,

One option would be

random = ~us(stage):Individual, rcov=~units

where the random term is a 2x2 covariance matrix (between individual  
variances for each stage and the covariance between them). There is  
only a single residual variance in my model - but this is OK, with  
binary data it can't be estimated so there is no point trying to  
estimates separate residual variances for each stage. You will need to  
fix the residual variance at something though (I use 1).

If you only have Individual level covariates (i.e. no  
observation-level covariates) then you could group your binary  
responses into a binomial response and fit the model

random=NULL, rcov = ~us(stage):units

This will give (nearly) the same answers as the first model if you  
rescale the (co)variances as described in the CourseNotes.  It will be  
much faster too.

You might also want to consider models that deal with temporal  
autocorrelation, but these are not implemented in MCMCglmm.

Cheers,

Jarrod
Quoting "PATRICK, Samantha" <spatrick at glos.ac.uk> on Mon, 11 Aug 2014  
17:34:05 +0000:

> Hi
>
> I running a bivariate GLMM, where both of my response variables have  
> repeated measures.  A dummy data set would look like this:
>
> Individual     Presence    Stage
> 1                      0                       1
> 1                      1                        1
> 1                      1                        2
> 1                      1                        2
> 2                     1                         1
> 2                     0                        1
> 2                     0                        1
> 2                     1                         2
> 2                     0                        2
>
> There are a series of individuals.  For each individual we have  
> measures presence/absence repeatedly during life stage 1 and then  
> again repeatedly during life stage 2.
>
> For a straight forward bivariate model, with a single measure per   
> individual (or repeated measures during only one life stage), the  
> data could be set up like this:
>
> Individual      Presence stage 1          Presence stage 2
>
> However because I have repeated measures for both stages I am  
> struggling to find out how to code the data so MCMCglmm can run.
>
> Does anyone have any experience with this kind of data structure?  I  
> can?t find anything on the R list.
>
> Many Thanks
>
> Sam
>
> Dr Samantha Patrick
> Research Fellow
> Biosciences QU116
> Francis Close Hall Campus
> University of Gloucestershire
> Cheltenham, GL50 4AZ, UK
>
> Research Associate: OxNav, University of Oxford
>
> ******From 1st August - 14th November 2014 I will be
> based in Montr?al, which is 5 hours behind GMT  ******
>
> Tel: 07740 472 719
> Skype: sammy_patrick
> https://sites.google.com/site/samanthacpatrick/
>
> -
> ?In the top 5 in the Green League Table; committed to sustainability?
> This email is confidential to the intended recipient. If you have  
> received it in error please notify the sender and delete it from  
> your computer.
> The University of Gloucestershire is a company limited by guarantee  
> registered in England and Wales.  Registered number: 06023243.   
> Registered office: The Park, Cheltenham, GL50 2RH
> Please consider the environment before printing this email.
> -
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From gustaf.granath at gmail.com  Mon Aug 11 23:38:53 2014
From: gustaf.granath at gmail.com (Gustaf Granath)
Date: Mon, 11 Aug 2014 17:38:53 -0400
Subject: [R-sig-ME] Random slope/intercept without correlation in lmer
Message-ID: <53E937ED.70707@gmail.com>

Hi
I want to model random slope and intercept without a correlation between 
the two. Is it possible to do this in lmer when the predictor is a factor?

For example, imagine that x has 2 levels (control and treatment). In 
nlme, I have been modeling uncorrelated intercept and slope like this:
lme(y ~ x, random=list(x = pdDiag(~ group)) ) where group is a random 
factor.
It gives me the random intercept and random slope (i.e. variation in 
treatment effect among groups).

In lmer, I think the corresponding model is defined as:
lmer( y ~ x + (x||rand) and I guess this gives me differences (variation 
in differences to the intercept), but it includes a covariance term.

Is it possible to reproduce the above lme() model in lmer?

I have a strong feeling that Im missing something here. Most of the 
literature on this subject (and R-list questions) deals with continuous 
variables so pls let me know if there is a good source on this topic.

Below follows a small example.

Cheers

Gustaf


set.seed(1)
treat = rep(c(0, 1), each = 5, 10)
group = rep(1:10, each = 10)
rand.int = rep( rnorm( 10, 0, 1), each = 10)
rand.slop = rep( rnorm(10, 0, 1), each = 10)
e = rnorm(100, 0, 0.5)
y = 10 + rand.int + treat + rand.slop*treat + e
treat = factor(treat)

#lmer
library(lme4)
# with correlation between intercept and slope
mod = lmer(y ~ treat + (treat|group) )
# without correlation between intercept and slope
# gives lots of error msgs
mod2 = lmer(y ~ treat + (treat||group) )
summary(mod)
summary(mod2)
# var-covar matrix
VarCorr(mod)$group
VarCorr(mod2)$group.1 #still a covariance term

#nlme
# without correlation
library(nlme)
lme.mod <- lme(y ~ treat, random=list(group = pdDiag(~ treat)) )
summary(lme.mod)
getVarCov(lme.mod)

-- 
Gustaf Granath (PhD)
Post doc
McMaster University
School of Geography & Earth Sciences


From russell-lenth at uiowa.edu  Mon Aug 11 23:55:30 2014
From: russell-lenth at uiowa.edu (Lenth, Russell V)
Date: Mon, 11 Aug 2014 21:55:30 +0000
Subject: [R-sig-ME] confidence intervals for random slopes
Message-ID: <51F0C7C54B032A42A23B74A088E7141C2E5D7480@itsnt443.iowa.uiowa.edu>

CIs for the slopes in the fixed part may be obtained easily via the lsmeans package:

    fm <- lme(Y ~ X * fixfactor, random=~X|randomfactor)
    require("lsmeans")
    lstrends(fm, "fixfactor", var="X")

You may also obtain pairwise comparisons by calling 'pairs' with the result of the last statement


Russell V. Lenth  -  Professor Emeritus
Department of Statistics and Actuarial Science   
The University of Iowa  -  Iowa City, IA 52242  USA   
Voice (319)335-0712 (Dept. office)  -  FAX (319)335-3017




-----Original Message-----

Message: 1
Date: Sun, 10 Aug 2014 16:14:57 +0200 (CEST)
From: Bokony Veronika <bokony.veronika at agrar.mta.hu>

Dear all,

let me ask your advice about calculating confidence intervals for random slopes. I have a random intercept & random slope model like this:

lme(Y ~ X * fixfactor, random=~X|randomfactor)

where randomfactor has 9 levels. For each of these 9 levels, I can calculate the slope of X from the fixed and random effect estimates. I would like to add some measure of uncertainty to each of these 9 estimates, i.e. an SE or CI for each random slope. The random effects SD which is given by the lme summary output is not what I'm interested in. I got a very general tip that I could calculate credible intervals from posterior distributions using a bayesian approach, but I found no evident way of extracting these from MCMCglmm either.

I would be very grateful for any working example that can achieve this.

Best regards,

Veronika


Veronika B?kony PhD
"Lend?let" Evolutionary Ecology Research Group Plant Protection Institute, Centre for Agricultural Research Hungarian Academy of Sciences Herman Ott? ?t 15.
H-1022 Budapest, Hungary
+36 1 3918609
http://www.nki.hu/lendulet-evolucios-okologiai-kutatocsoport
http://ornithology.limnologia.hu/people/veronika-bokony/


From bbolker at gmail.com  Tue Aug 12 00:42:44 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 11 Aug 2014 15:42:44 -0700
Subject: [R-sig-ME] Random slope/intercept without correlation in lmer
In-Reply-To: <53E937ED.70707@gmail.com>
References: <53E937ED.70707@gmail.com>
Message-ID: <CABghstSrn3FsL_-mmGYeZVW3MTB-PQFew62bEbhSqJh0egQZLw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20140811/3fe422f0/attachment.pl>

From steve.walker at utoronto.ca  Tue Aug 12 03:19:03 2014
From: steve.walker at utoronto.ca (Steve Walker)
Date: Mon, 11 Aug 2014 21:19:03 -0400
Subject: [R-sig-ME] Random slope/intercept without correlation in lmer
In-Reply-To: <CABghstSrn3FsL_-mmGYeZVW3MTB-PQFew62bEbhSqJh0egQZLw@mail.gmail.com>
References: <53E937ED.70707@gmail.com>
	<CABghstSrn3FsL_-mmGYeZVW3MTB-PQFew62bEbhSqJh0egQZLw@mail.gmail.com>
Message-ID: <53E96B87.3040904@utoronto.ca>

The `dummy` function in lme4 might be useful.  Here's the example from 
the ?dummy help file:

data(Orthodont,package="nlme")
      lmer(distance ~ age + (age|Subject) +
           (0+dummy(Sex, "Female")|Subject), data = Orthodont)

Here's another example:

lmer(distance ~ dummy(Sex, "Female") +
      (dummy(Sex, "Female") || Subject),
      data = Orthodont)

Cheers,
Steve



On 2014-08-11, 6:42 PM, Ben Bolker wrote:
> All you need to do is set up your own dummy variable (e.g.
> ntreat=as.numeric(treat)-1, or ntreat=as.numeric(treat=="1"), or
> ntreat=(original treat variable before using factor(treat) and then use
> (ntreat||group) or (1|group)+(0+ntreat|group)
>
>   This is related but not identical to the last example in ?lmer ; it's
> caused by an interaction between the way that R constructs model matrices
> from factors and the way lme4 uses that functionality.
>
>
>
> On Mon, Aug 11, 2014 at 2:38 PM, Gustaf Granath <gustaf.granath at gmail.com>
> wrote:
>
>> Hi
>> I want to model random slope and intercept without a correlation between
>> the two. Is it possible to do this in lmer when the predictor is a factor?
>>
>> For example, imagine that x has 2 levels (control and treatment). In nlme,
>> I have been modeling uncorrelated intercept and slope like this:
>> lme(y ~ x, random=list(x = pdDiag(~ group)) ) where group is a random
>> factor.
>> It gives me the random intercept and random slope (i.e. variation in
>> treatment effect among groups).
>>
>> In lmer, I think the corresponding model is defined as:
>> lmer( y ~ x + (x||rand) and I guess this gives me differences (variation
>> in differences to the intercept), but it includes a covariance term.
>>
>> Is it possible to reproduce the above lme() model in lmer?
>>
>> I have a strong feeling that Im missing something here. Most of the
>> literature on this subject (and R-list questions) deals with continuous
>> variables so pls let me know if there is a good source on this topic.
>>
>> Below follows a small example.
>>
>> Cheers
>>
>> Gustaf
>>
>>
>> set.seed(1)
>> treat = rep(c(0, 1), each = 5, 10)
>> group = rep(1:10, each = 10)
>> rand.int = rep( rnorm( 10, 0, 1), each = 10)
>> rand.slop = rep( rnorm(10, 0, 1), each = 10)
>> e = rnorm(100, 0, 0.5)
>> y = 10 + rand.int + treat + rand.slop*treat + e
>> treat = factor(treat)
>>
>> #lmer
>> library(lme4)
>> # with correlation between intercept and slope
>> mod = lmer(y ~ treat + (treat|group) )
>> # without correlation between intercept and slope
>> # gives lots of error msgs
>> mod2 = lmer(y ~ treat + (treat||group) )
>> summary(mod)
>> summary(mod2)
>> # var-covar matrix
>> VarCorr(mod)$group
>> VarCorr(mod2)$group.1 #still a covariance term
>>
>> #nlme
>> # without correlation
>> library(nlme)
>> lme.mod <- lme(y ~ treat, random=list(group = pdDiag(~ treat)) )
>> summary(lme.mod)
>> getVarCov(lme.mod)
>>
>> --
>> Gustaf Granath (PhD)
>> Post doc
>> McMaster University
>> School of Geography & Earth Sciences
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


From coanil at posteo.org  Tue Aug 12 04:46:28 2014
From: coanil at posteo.org (Michael Cone)
Date: Tue, 12 Aug 2014 04:46:28 +0200
Subject: [R-sig-ME] Specifying a repeated-measure design with 3 fully
 crossed within-subject factors
Message-ID: <6043f0e5bf9794272587cb1d975b07d5@posteo.de>

Dear list,

I'm trying to specify the appropriate random effects structure for a 
repeated-measure design with multiple, fully crossed within-subject 
factors.

F1, F2 & F3 are fully crossed factors, repeated several times (> 100, 
but not fully balanced) for each subject (each subject saw each unique 
combination of F1xF2xF3 several times, order not important). Subjects 
are nested within sex. F1 has 4 levels, F2 10 levels, and F3 40 levels.

I am interested in F1, F2, F3 and sex as fixed factors, but trying to 
account for the massive amount of pseudo-replication within the data 
set.

I tried to do my homework, and, for a simple repeated measure on 
different subjects characterized by sex, something like
meas ~ 1 + (1 | sex/subject)
would be appropriate. I am having a hard time, though, extending this 
to my design, where a repeated measure on a few subjects was repeated 
for each combination of factors F1, F2, and F3. Is it simply
meas ~ 1  + (1 | sex/subject) + (1 | F1) + (1 | F2) + (1 | F3)?

I apologize if this is something obvious. I'm new to mixed models & 
lmer and wasn't able to find a similar enough example despite quite some 
perusing.

Many thanks,
Michael


From gustaf.granath at gmail.com  Tue Aug 12 16:40:31 2014
From: gustaf.granath at gmail.com (Gustaf Granath)
Date: Tue, 12 Aug 2014 10:40:31 -0400
Subject: [R-sig-ME] Random slope/intercept without correlation in lmer
In-Reply-To: <53E96B87.3040904@utoronto.ca>
References: <53E937ED.70707@gmail.com>
	<CABghstSrn3FsL_-mmGYeZVW3MTB-PQFew62bEbhSqJh0egQZLw@mail.gmail.com>
	<53E96B87.3040904@utoronto.ca>
Message-ID: <53EA275F.2040104@gmail.com>

Thanks. Works perfectly.

For more than 2 levels I guess nlme is still the way to go if you want 
to manipulate the covariances structure.

Gustaf

> The `dummy` function in lme4 might be useful.  Here's the example from 
> the ?dummy help file:
>
> data(Orthodont,package="nlme")
>      lmer(distance ~ age + (age|Subject) +
>           (0+dummy(Sex, "Female")|Subject), data = Orthodont)
>
> Here's another example:
>
> lmer(distance ~ dummy(Sex, "Female") +
>      (dummy(Sex, "Female") || Subject),
>      data = Orthodont)
>
> Cheers,
> Steve
>
>
>
> On 2014-08-11, 6:42 PM, Ben Bolker wrote:
>> All you need to do is set up your own dummy variable (e.g.
>> ntreat=as.numeric(treat)-1, or ntreat=as.numeric(treat=="1"), or
>> ntreat=(original treat variable before using factor(treat) and then use
>> (ntreat||group) or (1|group)+(0+ntreat|group)
>>
>>   This is related but not identical to the last example in ?lmer ; it's
>> caused by an interaction between the way that R constructs model 
>> matrices
>> from factors and the way lme4 uses that functionality.
>>
>>
>>
>> On Mon, Aug 11, 2014 at 2:38 PM, Gustaf Granath 
>> <gustaf.granath at gmail.com>
>> wrote:
>>
>>> Hi
>>> I want to model random slope and intercept without a correlation 
>>> between
>>> the two. Is it possible to do this in lmer when the predictor is a 
>>> factor?
>>>
>>> For example, imagine that x has 2 levels (control and treatment). In 
>>> nlme,
>>> I have been modeling uncorrelated intercept and slope like this:
>>> lme(y ~ x, random=list(x = pdDiag(~ group)) ) where group is a random
>>> factor.
>>> It gives me the random intercept and random slope (i.e. variation in
>>> treatment effect among groups).
>>>
>>> In lmer, I think the corresponding model is defined as:
>>> lmer( y ~ x + (x||rand) and I guess this gives me differences 
>>> (variation
>>> in differences to the intercept), but it includes a covariance term.
>>>
>>> Is it possible to reproduce the above lme() model in lmer?
>>>
>>> I have a strong feeling that Im missing something here. Most of the
>>> literature on this subject (and R-list questions) deals with continuous
>>> variables so pls let me know if there is a good source on this topic.
>>>
>>> Below follows a small example.
>>>
>>> Cheers
>>>
>>> Gustaf
>>>
>>>
>>> set.seed(1)
>>> treat = rep(c(0, 1), each = 5, 10)
>>> group = rep(1:10, each = 10)
>>> rand.int = rep( rnorm( 10, 0, 1), each = 10)
>>> rand.slop = rep( rnorm(10, 0, 1), each = 10)
>>> e = rnorm(100, 0, 0.5)
>>> y = 10 + rand.int + treat + rand.slop*treat + e
>>> treat = factor(treat)
>>>
>>> #lmer
>>> library(lme4)
>>> # with correlation between intercept and slope
>>> mod = lmer(y ~ treat + (treat|group) )
>>> # without correlation between intercept and slope
>>> # gives lots of error msgs
>>> mod2 = lmer(y ~ treat + (treat||group) )
>>> summary(mod)
>>> summary(mod2)
>>> # var-covar matrix
>>> VarCorr(mod)$group
>>> VarCorr(mod2)$group.1 #still a covariance term
>>>
>>> #nlme
>>> # without correlation
>>> library(nlme)
>>> lme.mod <- lme(y ~ treat, random=list(group = pdDiag(~ treat)) )
>>> summary(lme.mod)
>>> getVarCov(lme.mod)
>>>
>>> -- 
>>> Gustaf Granath (PhD)
>>> Post doc
>>> McMaster University
>>> School of Geography & Earth Sciences
>>
>


From jake987722 at hotmail.com  Tue Aug 12 17:45:48 2014
From: jake987722 at hotmail.com (Jake Westfall)
Date: Tue, 12 Aug 2014 09:45:48 -0600
Subject: [R-sig-ME] Random slope/intercept without correlation in lmer
In-Reply-To: <53EA275F.2040104@gmail.com>
References: <53E937ED.70707@gmail.com>,
	<CABghstSrn3FsL_-mmGYeZVW3MTB-PQFew62bEbhSqJh0egQZLw@mail.gmail.com>,
	<53E96B87.3040904@utoronto.ca>, <53EA275F.2040104@gmail.com>
Message-ID: <BAY172-W36B18502D97709CC7B3C76CBEA0@phx.gbl>

In my opinion it is best as a general rule of thumb to always manually code your factors into numeric objects before passing them to a model fitting function, whether it is lmer() or lm() or whatever. The R Gods in their wisdom gave us factor objects in an attempt to make life easier for us, but in my experience factors often just get in the way or lead to unexpected results. The present issues are just another example.

Jake

> From: gustaf.granath at gmail.com
> Date: Tue, 12 Aug 2014 10:40:31 -0400
> To: steve.walker at utoronto.ca; bbolker at gmail.com
> CC: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Random slope/intercept without correlation in lmer
> 
> Thanks. Works perfectly.
> 
> For more than 2 levels I guess nlme is still the way to go if you want 
> to manipulate the covariances structure.
> 
> Gustaf
> 
> > The `dummy` function in lme4 might be useful.  Here's the example from 
> > the ?dummy help file:
> >
> > data(Orthodont,package="nlme")
> >      lmer(distance ~ age + (age|Subject) +
> >           (0+dummy(Sex, "Female")|Subject), data = Orthodont)
> >
> > Here's another example:
> >
> > lmer(distance ~ dummy(Sex, "Female") +
> >      (dummy(Sex, "Female") || Subject),
> >      data = Orthodont)
> >
> > Cheers,
> > Steve
> >
> >
> >
> > On 2014-08-11, 6:42 PM, Ben Bolker wrote:
> >> All you need to do is set up your own dummy variable (e.g.
> >> ntreat=as.numeric(treat)-1, or ntreat=as.numeric(treat=="1"), or
> >> ntreat=(original treat variable before using factor(treat) and then use
> >> (ntreat||group) or (1|group)+(0+ntreat|group)
> >>
> >>   This is related but not identical to the last example in ?lmer ; it's
> >> caused by an interaction between the way that R constructs model 
> >> matrices
> >> from factors and the way lme4 uses that functionality.
> >>
> >>
> >>
> >> On Mon, Aug 11, 2014 at 2:38 PM, Gustaf Granath 
> >> <gustaf.granath at gmail.com>
> >> wrote:
> >>
> >>> Hi
> >>> I want to model random slope and intercept without a correlation 
> >>> between
> >>> the two. Is it possible to do this in lmer when the predictor is a 
> >>> factor?
> >>>
> >>> For example, imagine that x has 2 levels (control and treatment). In 
> >>> nlme,
> >>> I have been modeling uncorrelated intercept and slope like this:
> >>> lme(y ~ x, random=list(x = pdDiag(~ group)) ) where group is a random
> >>> factor.
> >>> It gives me the random intercept and random slope (i.e. variation in
> >>> treatment effect among groups).
> >>>
> >>> In lmer, I think the corresponding model is defined as:
> >>> lmer( y ~ x + (x||rand) and I guess this gives me differences 
> >>> (variation
> >>> in differences to the intercept), but it includes a covariance term.
> >>>
> >>> Is it possible to reproduce the above lme() model in lmer?
> >>>
> >>> I have a strong feeling that Im missing something here. Most of the
> >>> literature on this subject (and R-list questions) deals with continuous
> >>> variables so pls let me know if there is a good source on this topic.
> >>>
> >>> Below follows a small example.
> >>>
> >>> Cheers
> >>>
> >>> Gustaf
> >>>
> >>>
> >>> set.seed(1)
> >>> treat = rep(c(0, 1), each = 5, 10)
> >>> group = rep(1:10, each = 10)
> >>> rand.int = rep( rnorm( 10, 0, 1), each = 10)
> >>> rand.slop = rep( rnorm(10, 0, 1), each = 10)
> >>> e = rnorm(100, 0, 0.5)
> >>> y = 10 + rand.int + treat + rand.slop*treat + e
> >>> treat = factor(treat)
> >>>
> >>> #lmer
> >>> library(lme4)
> >>> # with correlation between intercept and slope
> >>> mod = lmer(y ~ treat + (treat|group) )
> >>> # without correlation between intercept and slope
> >>> # gives lots of error msgs
> >>> mod2 = lmer(y ~ treat + (treat||group) )
> >>> summary(mod)
> >>> summary(mod2)
> >>> # var-covar matrix
> >>> VarCorr(mod)$group
> >>> VarCorr(mod2)$group.1 #still a covariance term
> >>>
> >>> #nlme
> >>> # without correlation
> >>> library(nlme)
> >>> lme.mod <- lme(y ~ treat, random=list(group = pdDiag(~ treat)) )
> >>> summary(lme.mod)
> >>> getVarCov(lme.mod)
> >>>
> >>> -- 
> >>> Gustaf Granath (PhD)
> >>> Post doc
> >>> McMaster University
> >>> School of Geography & Earth Sciences
> >>
> >
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
 		 	   		  
	[[alternative HTML version deleted]]


From aurorepaligot at hotmail.com  Tue Aug 12 18:05:56 2014
From: aurorepaligot at hotmail.com (Aurore Paligot)
Date: Tue, 12 Aug 2014 18:05:56 +0200
Subject: [R-sig-ME] Random effect variance = zero
Message-ID: <DUB115-W580F8EC49DBAE6A235C3A9B9EA0@phx.gbl>

Hello Everybody, I am new at using mixed models, and I would like some advice about some results that I obtained and that seem counter-intuitive to me.  As an output of a test, I obtainded a variance of zero for a random factor. 

Data
I am looking at the distance between the hands in symmetrical signs of a sign language. This is my dependent  variable. I have four signers (speakers), recorded in four different contexts. I have 320 observations in total : 20 for each signer in each context. 
Research question
I want to see whether there is a relationship between the distance between the hands and the context of use (more or less formal). Context is defined here as a fixed factor with four levels : C1, C2, C3, C4. 
Formula
Context.model = lmer (Distance ~ Context + (1|Signer), data=context) 
Results
For the random factor "Signer", the variance and standard deviation are both equal to zero: 
Linear mixed model fit by REML ['lmerMod']Formula: Ecart ~ Contexte + (1 | Locuteur)   Data: context
REML criterion at convergence: 2986.4
Scaled residuals:     Min      1Q  Median      3Q     Max -1.6085 -0.5709 -0.1486  0.2404  7.0084 
Random effects: Groups   Name        Variance Std.Dev. Locuteur (Intercept)   0.0     0.00    Residual                       725.7    26.94   Number of obs: 319, groups:  Locuteur, 4
Fixed effects:            Estimate Std. Error t value(Intercept)  4.10312    3.01187   1.362ContexteC2  14.60662    4.27288   3.418ContexteC3  -0.09983    4.27288  -0.023ContexteC4  23.22922    4.24626   5.471
Correlation of Fixed Effects:           (Intr) CntxC2 CntxC3ContexteC2 -0.705              ContexteC3 -0.705  0.497       ContexteC4 -0.709  0.500  0.500
Questions 
How is it possible?  Can it be considered as a reasonable output? 
I found this information about the variance estimates of zero. Could this explanation apply to my study? 

"It is possible to end up with a school variance estimate of zero. This fact often puzzles the researcher since each school will most certainly not have the same mean test result. An estimated among-school variance being zero, however, does not mean that each school has the same mean, but rather that the clustering of the students within schools does not help explain any of the overall variability present in test results. In this case, test results of students can be considered as all independent of each other regardless if they are from the same school or not. "( http://www.cscu.cornell.edu/news/statnews/stnews69.pdf )
If not, where could the problem come from? Is the formula that I used correct? Is a mixed-model appropriate for this type of question? 
I would really appreciate some clarification if someone already faced this type of problem ! 

Best regards, 
Aurore 		 	   		  
	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue Aug 12 18:32:27 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 12 Aug 2014 12:32:27 -0400
Subject: [R-sig-ME] Random slope/intercept without correlation in lmer
In-Reply-To: <BAY172-W36B18502D97709CC7B3C76CBEA0@phx.gbl>
References: <53E937ED.70707@gmail.com>
	<CABghstSrn3FsL_-mmGYeZVW3MTB-PQFew62bEbhSqJh0egQZLw@mail.gmail.com>
	<53E96B87.3040904@utoronto.ca> <53EA275F.2040104@gmail.com>
	<BAY172-W36B18502D97709CC7B3C76CBEA0@phx.gbl>
Message-ID: <CABghstRnPQOZFP1yeUHMjCL1qDv=dtpx76f1iV=AwjeDN=9bzA@mail.gmail.com>

Worth pointing out (maybe) that flexLambda branch should make this easier
too.  Don't have time to generate an example right now (and fL still needs
lots of work -- we really need to get our head above water to do more
development work!  Pull requests welcome ...)

  Ben B.


On Tue, Aug 12, 2014 at 11:45 AM, Jake Westfall <jake987722 at hotmail.com>
wrote:

> In my opinion it is best as a general rule of thumb to always manually
> code your factors into numeric objects before passing them to a model
> fitting function, whether it is lmer() or lm() or whatever. The R Gods in
> their wisdom gave us factor objects in an attempt to make life easier for
> us, but in my experience factors often just get in the way or lead to
> unexpected results. The present issues are just another example.
>
> Jake
>
> > From: gustaf.granath at gmail.com
> > Date: Tue, 12 Aug 2014 10:40:31 -0400
> > To: steve.walker at utoronto.ca; bbolker at gmail.com
> > CC: r-sig-mixed-models at r-project.org
> > Subject: Re: [R-sig-ME] Random slope/intercept without correlation in
> lmer
> >
> > Thanks. Works perfectly.
> >
> > For more than 2 levels I guess nlme is still the way to go if you want
> > to manipulate the covariances structure.
> >
> > Gustaf
> >
> > > The `dummy` function in lme4 might be useful.  Here's the example from
> > > the ?dummy help file:
> > >
> > > data(Orthodont,package="nlme")
> > >      lmer(distance ~ age + (age|Subject) +
> > >           (0+dummy(Sex, "Female")|Subject), data = Orthodont)
> > >
> > > Here's another example:
> > >
> > > lmer(distance ~ dummy(Sex, "Female") +
> > >      (dummy(Sex, "Female") || Subject),
> > >      data = Orthodont)
> > >
> > > Cheers,
> > > Steve
> > >
> > >
> > >
> > > On 2014-08-11, 6:42 PM, Ben Bolker wrote:
> > >> All you need to do is set up your own dummy variable (e.g.
> > >> ntreat=as.numeric(treat)-1, or ntreat=as.numeric(treat=="1"), or
> > >> ntreat=(original treat variable before using factor(treat) and then
> use
> > >> (ntreat||group) or (1|group)+(0+ntreat|group)
> > >>
> > >>   This is related but not identical to the last example in ?lmer ;
> it's
> > >> caused by an interaction between the way that R constructs model
> > >> matrices
> > >> from factors and the way lme4 uses that functionality.
> > >>
> > >>
> > >>
> > >> On Mon, Aug 11, 2014 at 2:38 PM, Gustaf Granath
> > >> <gustaf.granath at gmail.com>
> > >> wrote:
> > >>
> > >>> Hi
> > >>> I want to model random slope and intercept without a correlation
> > >>> between
> > >>> the two. Is it possible to do this in lmer when the predictor is a
> > >>> factor?
> > >>>
> > >>> For example, imagine that x has 2 levels (control and treatment). In
> > >>> nlme,
> > >>> I have been modeling uncorrelated intercept and slope like this:
> > >>> lme(y ~ x, random=list(x = pdDiag(~ group)) ) where group is a random
> > >>> factor.
> > >>> It gives me the random intercept and random slope (i.e. variation in
> > >>> treatment effect among groups).
> > >>>
> > >>> In lmer, I think the corresponding model is defined as:
> > >>> lmer( y ~ x + (x||rand) and I guess this gives me differences
> > >>> (variation
> > >>> in differences to the intercept), but it includes a covariance term.
> > >>>
> > >>> Is it possible to reproduce the above lme() model in lmer?
> > >>>
> > >>> I have a strong feeling that Im missing something here. Most of the
> > >>> literature on this subject (and R-list questions) deals with
> continuous
> > >>> variables so pls let me know if there is a good source on this topic.
> > >>>
> > >>> Below follows a small example.
> > >>>
> > >>> Cheers
> > >>>
> > >>> Gustaf
> > >>>
> > >>>
> > >>> set.seed(1)
> > >>> treat = rep(c(0, 1), each = 5, 10)
> > >>> group = rep(1:10, each = 10)
> > >>> rand.int = rep( rnorm( 10, 0, 1), each = 10)
> > >>> rand.slop = rep( rnorm(10, 0, 1), each = 10)
> > >>> e = rnorm(100, 0, 0.5)
> > >>> y = 10 + rand.int + treat + rand.slop*treat + e
> > >>> treat = factor(treat)
> > >>>
> > >>> #lmer
> > >>> library(lme4)
> > >>> # with correlation between intercept and slope
> > >>> mod = lmer(y ~ treat + (treat|group) )
> > >>> # without correlation between intercept and slope
> > >>> # gives lots of error msgs
> > >>> mod2 = lmer(y ~ treat + (treat||group) )
> > >>> summary(mod)
> > >>> summary(mod2)
> > >>> # var-covar matrix
> > >>> VarCorr(mod)$group
> > >>> VarCorr(mod2)$group.1 #still a covariance term
> > >>>
> > >>> #nlme
> > >>> # without correlation
> > >>> library(nlme)
> > >>> lme.mod <- lme(y ~ treat, random=list(group = pdDiag(~ treat)) )
> > >>> summary(lme.mod)
> > >>> getVarCov(lme.mod)
> > >>>
> > >>> --
> > >>> Gustaf Granath (PhD)
> > >>> Post doc
> > >>> McMaster University
> > >>> School of Geography & Earth Sciences
> > >>
> > >
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue Aug 12 18:35:10 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 12 Aug 2014 12:35:10 -0400
Subject: [R-sig-ME] Random effect variance = zero
In-Reply-To: <DUB115-W580F8EC49DBAE6A235C3A9B9EA0@phx.gbl>
References: <DUB115-W580F8EC49DBAE6A235C3A9B9EA0@phx.gbl>
Message-ID: <CABghstSiVwJQ2y=ZATnPC4Xq3ggcBPh3bwjZPHgdmFyvKBnC4w@mail.gmail.com>

Short answer: yes, very common outcome, especially with small numbers of
random effects groups (e.g. <5).  See http://glmm.wikidot.com/faq ; blme
package for 'regularizing' fits so this doesn't happen (at the expense of
changing the statistical model slightly); http://rpubs.com/bbolker/4187 .


On Tue, Aug 12, 2014 at 12:05 PM, Aurore Paligot <aurorepaligot at hotmail.com>
wrote:

> Hello Everybody, I am new at using mixed models, and I would like some
> advice about some results that I obtained and that seem counter-intuitive
> to me.  As an output of a test, I obtainded a variance of zero for a random
> factor.
>
> Data
> I am looking at the distance between the hands in symmetrical signs of a
> sign language. This is my dependent  variable. I have four signers
> (speakers), recorded in four different contexts. I have 320 observations in
> total : 20 for each signer in each context.
> Research question
> I want to see whether there is a relationship between the distance between
> the hands and the context of use (more or less formal). Context is defined
> here as a fixed factor with four levels : C1, C2, C3, C4.
> Formula
> Context.model = lmer (Distance ~ Context + (1|Signer), data=context)
> Results
> For the random factor "Signer", the variance and standard deviation are
> both equal to zero:
> Linear mixed model fit by REML ['lmerMod']Formula: Ecart ~ Contexte + (1 |
> Locuteur)   Data: context
> REML criterion at convergence: 2986.4
> Scaled residuals:     Min      1Q  Median      3Q     Max -1.6085 -0.5709
> -0.1486  0.2404  7.0084
> Random effects: Groups   Name        Variance Std.Dev. Locuteur
> (Intercept)   0.0     0.00    Residual                       725.7    26.94
>   Number of obs: 319, groups:  Locuteur, 4
> Fixed effects:            Estimate Std. Error t value(Intercept)  4.10312
>    3.01187   1.362ContexteC2  14.60662    4.27288   3.418ContexteC3
>  -0.09983    4.27288  -0.023ContexteC4  23.22922    4.24626   5.471
> Correlation of Fixed Effects:           (Intr) CntxC2 CntxC3ContexteC2
> -0.705              ContexteC3 -0.705  0.497       ContexteC4 -0.709  0.500
>  0.500
> Questions
> How is it possible?  Can it be considered as a reasonable output?
> I found this information about the variance estimates of zero. Could this
> explanation apply to my study?
>
> "It is possible to end up with a school variance estimate of zero. This
> fact often puzzles the researcher since each school will most certainly not
> have the same mean test result. An estimated among-school variance being
> zero, however, does not mean that each school has the same mean, but rather
> that the clustering of the students within schools does not help explain
> any of the overall variability present in test results. In this case, test
> results of students can be considered as all independent of each other
> regardless if they are from the same school or not. "(
> http://www.cscu.cornell.edu/news/statnews/stnews69.pdf )
> If not, where could the problem come from? Is the formula that I used
> correct? Is a mixed-model appropriate for this type of question?
> I would really appreciate some clarification if someone already faced this
> type of problem !
>
> Best regards,
> Aurore
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From aurorepaligot at hotmail.com  Wed Aug 13 11:00:02 2014
From: aurorepaligot at hotmail.com (Aurore Paligot)
Date: Wed, 13 Aug 2014 11:00:02 +0200
Subject: [R-sig-ME] Random effect variance = zero
In-Reply-To: <CABghstSiVwJQ2y=ZATnPC4Xq3ggcBPh3bwjZPHgdmFyvKBnC4w@mail.gmail.com>
References: <DUB115-W580F8EC49DBAE6A235C3A9B9EA0@phx.gbl>,
	<CABghstSiVwJQ2y=ZATnPC4Xq3ggcBPh3bwjZPHgdmFyvKBnC4w@mail.gmail.com>
Message-ID: <DUB115-W101027A96EA3E4E028BF8AEB9EB0@phx.gbl>

Thank you very much, Ben, for your answer and the useful links. Blme sounds like a great solution, I will retry with this package.
Best regards, 
Aurore

Date: Tue, 12 Aug 2014 12:35:10 -0400
Subject: Re: [R-sig-ME] Random effect variance = zero
From: bbolker at gmail.com
To: aurorepaligot at hotmail.com
CC: r-sig-mixed-models at r-project.org


Short answer: yes, very common outcome, especially with small numbers of random effects groups (e.g. <5).  See http://glmm.wikidot.com/faq ; blme package for 'regularizing' fits so this doesn't happen (at the expense of changing the statistical model slightly); http://rpubs.com/bbolker/4187 .



On Tue, Aug 12, 2014 at 12:05 PM, Aurore Paligot <aurorepaligot at hotmail.com> wrote:

Hello Everybody, I am new at using mixed models, and I would like some advice about some results that I obtained and that seem counter-intuitive to me.  As an output of a test, I obtainded a variance of zero for a random factor.




Data

I am looking at the distance between the hands in symmetrical signs of a sign language. This is my dependent  variable. I have four signers (speakers), recorded in four different contexts. I have 320 observations in total : 20 for each signer in each context.


Research question

I want to see whether there is a relationship between the distance between the hands and the context of use (more or less formal). Context is defined here as a fixed factor with four levels : C1, C2, C3, C4.

Formula

Context.model = lmer (Distance ~ Context + (1|Signer), data=context)

Results

For the random factor "Signer", the variance and standard deviation are both equal to zero:

Linear mixed model fit by REML ['lmerMod']Formula: Ecart ~ Contexte + (1 | Locuteur)   Data: context

REML criterion at convergence: 2986.4

Scaled residuals:     Min      1Q  Median      3Q     Max -1.6085 -0.5709 -0.1486  0.2404  7.0084

Random effects: Groups   Name        Variance Std.Dev. Locuteur (Intercept)   0.0     0.00    Residual                       725.7    26.94   Number of obs: 319, groups:  Locuteur, 4

Fixed effects:            Estimate Std. Error t value(Intercept)  4.10312    3.01187   1.362ContexteC2  14.60662    4.27288   3.418ContexteC3  -0.09983    4.27288  -0.023ContexteC4  23.22922    4.24626   5.471

Correlation of Fixed Effects:           (Intr) CntxC2 CntxC3ContexteC2 -0.705              ContexteC3 -0.705  0.497       ContexteC4 -0.709  0.500  0.500

Questions

How is it possible?  Can it be considered as a reasonable output?

I found this information about the variance estimates of zero. Could this explanation apply to my study?



"It is possible to end up with a school variance estimate of zero. This fact often puzzles the researcher since each school will most certainly not have the same mean test result. An estimated among-school variance being zero, however, does not mean that each school has the same mean, but rather that the clustering of the students within schools does not help explain any of the overall variability present in test results. In this case, test results of students can be considered as all independent of each other regardless if they are from the same school or not. "( http://www.cscu.cornell.edu/news/statnews/stnews69.pdf )


If not, where could the problem come from? Is the formula that I used correct? Is a mixed-model appropriate for this type of question?

I would really appreciate some clarification if someone already faced this type of problem !



Best regards,

Aurore

        [[alternative HTML version deleted]]



_______________________________________________

R-sig-mixed-models at r-project.org mailing list

https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


 		 	   		  
	[[alternative HTML version deleted]]


From spatrick at glos.ac.uk  Wed Aug 13 15:53:58 2014
From: spatrick at glos.ac.uk (PATRICK, Samantha)
Date: Wed, 13 Aug 2014 13:53:58 +0000
Subject: [R-sig-ME] Bivariate MCMCglmm with repeated measures
In-Reply-To: <20140811194700.12405iyy8lmx6m80@www.staffmail.ed.ac.uk>
References: <4a47ae02f8a14cb2b24d3b88e03938e6@glos.ac.uk>,
	<20140811194700.12405iyy8lmx6m80@www.staffmail.ed.ac.uk>
Message-ID: <17c25b5bd3524c79af6d968a2279b3b9@glos.ac.uk>

Hi Jarrod

Thanks for getting back to me.  By simplifying the data, I left out the fact that there is a temporal pattern (Time).  There is an interaction between Time * Stage on Presence.  During stage one, Presence increases linearly with Time; during stage two Presence decreases linearly with time.   Stage one and two are mutually exclusive: Time 1-5 is always stage 1 and Time 6-10 always stage 2.   This was why I was originally to fit a bivariate model, so I could calculate the covariance between the slopes.

Following the method you suggested  I have been able to progress towards this.  The following model, if I understand correctly, fits an intercept (stage; two level factor) and a two population slopes (One in stage 1 and one in stage 2) and then a random intercept and slope during stage one and another random intercept and slope during stage two.  The 4x4  covariance matrix estimates the covariance between both intercepts and both slopes.
### this prior is not optimised in anyway - it is just a starting point
prior2.1 <- list(G = list(G1 = list(V=diag(4), nu=2, alpha.mu=c(0,0,0,0), alpha.V=diag(4)*1000)),
                          R = list(V=1, fix=1))

## full model
model2.1 <- MCMCglmm(Presence~ stage +  at.level(stage,1):Time + at.level(stage,2):Time ,

             random = ~us(at.level(stage ,1)+ at.level(stage ,1):Time  +
                                 at.level(stage ,2) +at.level(stage ,2):Time):Individual,

             rcov = ~units, family = "categorical",

              data = Data2, prior = prior2.1, verbose = FALSE, pr=T)

I then extended this model to allow the covariance structure to vary between the sexes:

##prior
prior2.2<- list(G = list(G1 = list(V=diag(8), nu=2, alpha.mu=c(0,0,0,0,0,0,0,0), alpha.V=diag(8)*1000)),
                          R = list(V=1, fix=1))

## full model
model2.2<- MCMCglmm(Presence~ stage +  at.level(stage,1):Time + at.level(stage,2):Time  ,
                     random = ~us(at.level(stage,1):at.level(Sex,1)+
                                    at.level(stage,1):at.level(Sex,2)+
                                    at.level(stage,1):at.level(Sex,1):Time +
                                    at.level(stage,1):at.level(Sex,2):Time  +
                                    at.level(stage,2):at.level(Sex,1)+
                                    at.level(stage,2):at.level(Sex,2)+
                                    at.level(stage,2):at.level(Sex,1):Time  +
                                    at.level(stage,2):at.level(Sex,2):Time ):Individual,
                     rcov = ~units, family = "categorical",
                     data = Data2, prior = prior2.2, verbose = FALSE, pr=T)

So I am left with one question: In essence the data lends itself to a piecewise regression, such that the end point of the slope in stage one is the start point for stage two.  Is it possible to fit this at the individual level? By this I mean that the random slope for individual 1 at stage two begins where and the slope for stage one ends. I have struggled to find anyone doing this.

I have included the full models and simulated data below (runs in first model only) in case anyone else is working on this kind of problem.

Thanks

Sam


### Data


Time
        Presence        Stage    Individual
1       1       1       1
2       1       1       1
3       0       1       1
4       1       1       1
5       1       1       1
6       0       2       1
7       0       2       1
8       1       2       1
9       0       2       1
10      1       2       1
1       0       1       2
2       1       1       2
3       0       1       2
4       1       1       2
5       1       1       2
6       1       2       2
7       0       2       2
8       0       2       2
9       0       2       2
10      1       2       2
1       0       1       3
2       1       1       3
3       1       1       3
4       1       1       3
5       1       1       3
6       0       2       3
7       0       2       3
8       1       2       3
9       1       2       3
10      1       2       3
1       0       1       4
2       1       1       4
3       1       1       4
4       1       1       4
5       1       1       4
6       1       2       4
7       1       2       4
8       0       2       4
9       0       2       4
10      0       2       4
1       1       1       5
2       0       1       5
3       0       1       5
4       1       1       5
5       1       1       5
6       1       2       5
7       1       2       5
8       1       2       5
9       1       2       5
10      0       2       5


Dr Samantha Patrick
Research Fellow
Biosciences QU116
Francis Close Hall Campus
University of Gloucestershire
Cheltenham, GL50 4AZ, UK

Research Associate: OxNav, University of Oxford

******From 1st August - 14th November 2014 I will be
based in Montr?al, which is 5 hours behind GMT  ******

Tel: 07740 472 719
Skype: sammy_patrick
https://sites.google.com/site/samanthacpatrick/

From: Jarrod Hadfield<mailto:j.hadfield at ed.ac.uk>
Sent: ?Monday?, ?11? ?August? ?2014 ?14?:?47
To: Samantha Patrick<mailto:spatrick at glos.ac.uk>
Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>

Hi Sam,

One option would be

random = ~us(stage):Individual, rcov=~units

where the random term is a 2x2 covariance matrix (between individual
variances for each stage and the covariance between them). There is
only a single residual variance in my model - but this is OK, with
binary data it can't be estimated so there is no point trying to
estimates separate residual variances for each stage. You will need to
fix the residual variance at something though (I use 1).

If you only have Individual level covariates (i.e. no
observation-level covariates) then you could group your binary
responses into a binomial response and fit the model

random=NULL, rcov = ~us(stage):units

This will give (nearly) the same answers as the first model if you
rescale the (co)variances as described in the CourseNotes.  It will be
much faster too.

You might also want to consider models that deal with temporal
autocorrelation, but these are not implemented in MCMCglmm.

Cheers,

Jarrod
Quoting "PATRICK, Samantha" <spatrick at glos.ac.uk> on Mon, 11 Aug 2014
17:34:05 +0000:

> Hi
>
> I running a bivariate GLMM, where both of my response variables have
> repeated measures.  A dummy data set would look like this:
>
> Individual     Presence    Stage
> 1                      0                       1
> 1                      1                        1
> 1                      1                        2
> 1                      1                        2
> 2                     1                         1
> 2                     0                        1
> 2                     0                        1
> 2                     1                         2
> 2                     0                        2
>
> There are a series of individuals.  For each individual we have
> measures presence/absence repeatedly during life stage 1 and then
> again repeatedly during life stage 2.
>
> For a straight forward bivariate model, with a single measure per
> individual (or repeated measures during only one life stage), the
> data could be set up like this:
>
> Individual      Presence stage 1          Presence stage 2
>
> However because I have repeated measures for both stages I am
> struggling to find out how to code the data so MCMCglmm can run.
>
> Does anyone have any experience with this kind of data structure?  I
> can?t find anything on the R list.
>
> Many Thanks
>
> Sam
>
> Dr Samantha Patrick
> Research Fellow
> Biosciences QU116
> Francis Close Hall Campus
> University of Gloucestershire
> Cheltenham, GL50 4AZ, UK
>
> Research Associate: OxNav, University of Oxford
>
> ******From 1st August - 14th November 2014 I will be
> based in Montr?al, which is 5 hours behind GMT  ******
>
> Tel: 07740 472 719
> Skype: sammy_patrick
> https://sites.google.com/site/samanthacpatrick/
>
> -
> ?In the top 5 in the Green League Table; committed to sustainability?
> This email is confidential to the intended recipient. If you have
> received it in error please notify the sender and delete it from
> your computer.
> The University of Gloucestershire is a company limited by guarantee
> registered in England and Wales.  Registered number: 06023243.
> Registered office: The Park, Cheltenham, GL50 2RH
> Please consider the environment before printing this email.
> -
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


--
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


-
?In the top 5 in the Green League Table; committed to sustainability?
This email is confidential to the intended recipient. If you have received it in error please notify the sender and delete it from your computer.
The University of Gloucestershire is a company limited by guarantee registered in England and Wales.  Registered number: 06023243.  Registered office: The Park, Cheltenham, GL50 2RH
Please consider the environment before printing this email.
-


From j.hadfield at ed.ac.uk  Wed Aug 13 16:09:11 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 13 Aug 2014 15:09:11 +0100
Subject: [R-sig-ME] Bivariate MCMCglmm with repeated measures
In-Reply-To: <17c25b5bd3524c79af6d968a2279b3b9@glos.ac.uk>
References: <4a47ae02f8a14cb2b24d3b88e03938e6@glos.ac.uk>,
	<20140811194700.12405iyy8lmx6m80@www.staffmail.ed.ac.uk>
	<17c25b5bd3524c79af6d968a2279b3b9@glos.ac.uk>
Message-ID: <20140813150911.84117at8y8bgkhcs@www.staffmail.ed.ac.uk>

Hi,

To do piecewise random regression forcing the two regression to `join'  
you could centre your covariate (Time) at the breakpoint. Then use:

random = ~us(1 + at.level(stage,1):Time+at.level(stage,2):Time):Individual

The first variance is the variance in the new intercepts (the value at  
the breakpoint) and the other two variances are the variances in  
slopes that emanate from either side of the breakpoint.

Bear in mind you will need a lot of data to get precise estimates from  
such a complex model, particularly if you want to break it up by sex  
too.

Cheers,

Jarrod




Quoting "PATRICK, Samantha" <spatrick at glos.ac.uk> on Wed, 13 Aug 2014  
13:53:58 +0000:

> Hi Jarrod
>
> Thanks for getting back to me.  By simplifying the data, I left out  
> the fact that there is a temporal pattern (Time).  There is an  
> interaction between Time * Stage on Presence.  During stage one,  
> Presence increases linearly with Time; during stage two Presence  
> decreases linearly with time.   Stage one and two are mutually  
> exclusive: Time 1-5 is always stage 1 and Time 6-10 always stage 2.   
>  This was why I was originally to fit a bivariate model, so I could  
> calculate the covariance between the slopes.
>
> Following the method you suggested  I have been able to progress  
> towards this.  The following model, if I understand correctly, fits  
> an intercept (stage; two level factor) and a two population slopes  
> (One in stage 1 and one in stage 2) and then a random intercept and  
> slope during stage one and another random intercept and slope during  
> stage two.  The 4x4  covariance matrix estimates the covariance  
> between both intercepts and both slopes.
> ### this prior is not optimised in anyway - it is just a starting point
> prior2.1 <- list(G = list(G1 = list(V=diag(4), nu=2,  
> alpha.mu=c(0,0,0,0), alpha.V=diag(4)*1000)),
>                           R = list(V=1, fix=1))
>
> ## full model
> model2.1 <- MCMCglmm(Presence~ stage +  at.level(stage,1):Time +  
> at.level(stage,2):Time ,
>
>              random = ~us(at.level(stage ,1)+ at.level(stage ,1):Time  +
>                                  at.level(stage ,2) +at.level(stage  
> ,2):Time):Individual,
>
>              rcov = ~units, family = "categorical",
>
>               data = Data2, prior = prior2.1, verbose = FALSE, pr=T)
>
> I then extended this model to allow the covariance structure to vary  
> between the sexes:
>
> ##prior
> prior2.2<- list(G = list(G1 = list(V=diag(8), nu=2,  
> alpha.mu=c(0,0,0,0,0,0,0,0), alpha.V=diag(8)*1000)),
>                           R = list(V=1, fix=1))
>
> ## full model
> model2.2<- MCMCglmm(Presence~ stage +  at.level(stage,1):Time +  
> at.level(stage,2):Time  ,
>                      random = ~us(at.level(stage,1):at.level(Sex,1)+
>                                     at.level(stage,1):at.level(Sex,2)+
>                                     at.level(stage,1):at.level(Sex,1):Time +
>                                     at.level(stage,1):at.level(Sex,2):Time  +
>                                     at.level(stage,2):at.level(Sex,1)+
>                                     at.level(stage,2):at.level(Sex,2)+
>                                     at.level(stage,2):at.level(Sex,1):Time  +
>                                      
> at.level(stage,2):at.level(Sex,2):Time ):Individual,
>                      rcov = ~units, family = "categorical",
>                      data = Data2, prior = prior2.2, verbose = FALSE, pr=T)
>
> So I am left with one question: In essence the data lends itself to  
> a piecewise regression, such that the end point of the slope in  
> stage one is the start point for stage two.  Is it possible to fit  
> this at the individual level? By this I mean that the random slope  
> for individual 1 at stage two begins where and the slope for stage  
> one ends. I have struggled to find anyone doing this.
>
> I have included the full models and simulated data below (runs in  
> first model only) in case anyone else is working on this kind of  
> problem.
>
> Thanks
>
> Sam
>
>
> ### Data
>
>
> Time
>         Presence        Stage    Individual
> 1       1       1       1
> 2       1       1       1
> 3       0       1       1
> 4       1       1       1
> 5       1       1       1
> 6       0       2       1
> 7       0       2       1
> 8       1       2       1
> 9       0       2       1
> 10      1       2       1
> 1       0       1       2
> 2       1       1       2
> 3       0       1       2
> 4       1       1       2
> 5       1       1       2
> 6       1       2       2
> 7       0       2       2
> 8       0       2       2
> 9       0       2       2
> 10      1       2       2
> 1       0       1       3
> 2       1       1       3
> 3       1       1       3
> 4       1       1       3
> 5       1       1       3
> 6       0       2       3
> 7       0       2       3
> 8       1       2       3
> 9       1       2       3
> 10      1       2       3
> 1       0       1       4
> 2       1       1       4
> 3       1       1       4
> 4       1       1       4
> 5       1       1       4
> 6       1       2       4
> 7       1       2       4
> 8       0       2       4
> 9       0       2       4
> 10      0       2       4
> 1       1       1       5
> 2       0       1       5
> 3       0       1       5
> 4       1       1       5
> 5       1       1       5
> 6       1       2       5
> 7       1       2       5
> 8       1       2       5
> 9       1       2       5
> 10      0       2       5
>
>
> Dr Samantha Patrick
> Research Fellow
> Biosciences QU116
> Francis Close Hall Campus
> University of Gloucestershire
> Cheltenham, GL50 4AZ, UK
>
> Research Associate: OxNav, University of Oxford
>
> ******From 1st August - 14th November 2014 I will be
> based in Montr?al, which is 5 hours behind GMT  ******
>
> Tel: 07740 472 719
> Skype: sammy_patrick
> https://sites.google.com/site/samanthacpatrick/
>
> From: Jarrod Hadfield<mailto:j.hadfield at ed.ac.uk>
> Sent: ?Monday?, ?11? ?August? ?2014 ?14?:?47
> To: Samantha Patrick<mailto:spatrick at glos.ac.uk>
> Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
>
> Hi Sam,
>
> One option would be
>
> random = ~us(stage):Individual, rcov=~units
>
> where the random term is a 2x2 covariance matrix (between individual
> variances for each stage and the covariance between them). There is
> only a single residual variance in my model - but this is OK, with
> binary data it can't be estimated so there is no point trying to
> estimates separate residual variances for each stage. You will need to
> fix the residual variance at something though (I use 1).
>
> If you only have Individual level covariates (i.e. no
> observation-level covariates) then you could group your binary
> responses into a binomial response and fit the model
>
> random=NULL, rcov = ~us(stage):units
>
> This will give (nearly) the same answers as the first model if you
> rescale the (co)variances as described in the CourseNotes.  It will be
> much faster too.
>
> You might also want to consider models that deal with temporal
> autocorrelation, but these are not implemented in MCMCglmm.
>
> Cheers,
>
> Jarrod
> Quoting "PATRICK, Samantha" <spatrick at glos.ac.uk> on Mon, 11 Aug 2014
> 17:34:05 +0000:
>
>> Hi
>>
>> I running a bivariate GLMM, where both of my response variables have
>> repeated measures.  A dummy data set would look like this:
>>
>> Individual     Presence    Stage
>> 1                      0                       1
>> 1                      1                        1
>> 1                      1                        2
>> 1                      1                        2
>> 2                     1                         1
>> 2                     0                        1
>> 2                     0                        1
>> 2                     1                         2
>> 2                     0                        2
>>
>> There are a series of individuals.  For each individual we have
>> measures presence/absence repeatedly during life stage 1 and then
>> again repeatedly during life stage 2.
>>
>> For a straight forward bivariate model, with a single measure per
>> individual (or repeated measures during only one life stage), the
>> data could be set up like this:
>>
>> Individual      Presence stage 1          Presence stage 2
>>
>> However because I have repeated measures for both stages I am
>> struggling to find out how to code the data so MCMCglmm can run.
>>
>> Does anyone have any experience with this kind of data structure?  I
>> can?t find anything on the R list.
>>
>> Many Thanks
>>
>> Sam
>>
>> Dr Samantha Patrick
>> Research Fellow
>> Biosciences QU116
>> Francis Close Hall Campus
>> University of Gloucestershire
>> Cheltenham, GL50 4AZ, UK
>>
>> Research Associate: OxNav, University of Oxford
>>
>> ******From 1st August - 14th November 2014 I will be
>> based in Montr?al, which is 5 hours behind GMT  ******
>>
>> Tel: 07740 472 719
>> Skype: sammy_patrick
>> https://sites.google.com/site/samanthacpatrick/
>>
>> -
>> ?In the top 5 in the Green League Table; committed to sustainability?
>> This email is confidential to the intended recipient. If you have
>> received it in error please notify the sender and delete it from
>> your computer.
>> The University of Gloucestershire is a company limited by guarantee
>> registered in England and Wales.  Registered number: 06023243.
>> Registered office: The Park, Cheltenham, GL50 2RH
>> Please consider the environment before printing this email.
>> -
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>
> -
> ?In the top 5 in the Green League Table; committed to sustainability?
> This email is confidential to the intended recipient. If you have  
> received it in error please notify the sender and delete it from  
> your computer.
> The University of Gloucestershire is a company limited by guarantee  
> registered in England and Wales.  Registered number: 06023243.   
> Registered office: The Park, Cheltenham, GL50 2RH
> Please consider the environment before printing this email.
> -
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From szymonmarian.drobniak at uzh.ch  Wed Aug 13 18:03:15 2014
From: szymonmarian.drobniak at uzh.ch (Szymek Drobniak)
Date: Wed, 13 Aug 2014 18:03:15 +0200
Subject: [R-sig-ME] Multivariate multinomial in MCMCglmm
Message-ID: <CANXb-o7QWVAV2pZS=WiYF_u7vz6EitwCOOd9o5fyZThDGMarUA@mail.gmail.com>

Dear List Members,

I'm wondering if you have experience (if it's passible in the first place)
in fitting a mixed model with multiple multinomial responses in MCMCglmm. I
was trying to fit such model but I bumped into the truble of what the
"trait" dummy variable does actually index in such a model?

In a "univariate" multinomial model (which actually already is
multivariate) like the one below the trait variable indexes single odds
ratios for 2nd/3rd... category against the 1st category. Is it possible to
extend this into a situation with more than one multinomial variables?


cheers,
Szymek

require(MCMCglmm)

mydata <- data.frame(response1 = c(sample(c("a","b","c"), replace=T, size =
100)),
                     covariate = rnorm(100), random =
gl(20,5,labels=letters[1:20]))


K <- length(levels(mydata$response1))
I <- diag(K-1)
J <- matrix(0,K-1,K-1) + 1
IJ <- 1/K*(I+J)

size=2
prior <- list(R=list(V=IJ, fix=1),
              G=list(G1=list(V=IJ, nu=K-1+0.002)),
              B=list(mu=rep(0,size*(K-1)), V=kronecker(IJ,
diag(size))*(1.7+pi^2/3)))

model <- MCMCglmm(response1~trait*covariate-1, random=~us(trait):random,
rcov=~us(trait):units,
                  family="categorical", data=mydata, prior=prior)

#######################################

## now what to do with the 2nd response variable?

mydata$response2 <- as.factor(c(sample(c("w","x","y","z"), replace=T, size
= 100)))


-- 

*Dr Szymon Drobniak*
Anthropological Institute and Museum
Office Y42-K-66
University of Z?rich - Irchel
Winterthurerstrasse 190
CH-8057 Z?rich, Switzerland

	[[alternative HTML version deleted]]


From bokony.veronika at agrar.mta.hu  Wed Aug 13 11:15:48 2014
From: bokony.veronika at agrar.mta.hu (Veronika Bokony)
Date: Wed, 13 Aug 2014 09:15:48 +0000 (UTC)
Subject: [R-sig-ME] confidence intervals for random slopes
References: <1691693583.3097022.1407678920732.JavaMail.zimbra@agrar.mta.hu>
	<1547889392.3097072.1407680097073.JavaMail.zimbra@agrar.mta.hu>
Message-ID: <loom.20140813T110813-314@post.gmane.org>

Dear all,
thank you very much for the responses. With Ben Bolker's example I can now 
calculate the SD for each of my random slopes. I have one remaining 
question though: how do I turn these into SE? Do I use the sample size per 
each level of random factor? (I have different sample size for 
each "subject".) Or is it more tricky with these mixed models?
Thanks and bests,
Veronika


From j.hadfield at ed.ac.uk  Wed Aug 13 19:20:59 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 13 Aug 2014 18:20:59 +0100
Subject: [R-sig-ME] Multivariate multinomial in MCMCglmm
In-Reply-To: <CANXb-o7QWVAV2pZS=WiYF_u7vz6EitwCOOd9o5fyZThDGMarUA@mail.gmail.com>
References: <CANXb-o7QWVAV2pZS=WiYF_u7vz6EitwCOOd9o5fyZThDGMarUA@mail.gmail.com>
Message-ID: <20140813182059.191770ciwuyoi2o0@www.staffmail.ed.ac.uk>

Hi Szymek,

cbind(response1, response2)~trait ...

If we use the notation A.B to denote log odds ratios for category A in  
response B, then the traits in order are 2.1, 3.1, 2.2, 3.2, 4.2. You  
can use things like at.level(trait, 1:2) and at.level(trait, 3:5) if  
you only want to fit effects for one of the responses.

Note that the prior G1=list(V=IJ, nu=K-1+0.002))  is likely to have a  
large effect.

Cheers,

Jarrod


Quoting Szymek Drobniak <szymonmarian.drobniak at uzh.ch> on Wed, 13 Aug  
2014 18:03:15 +0200:

> Dear List Members,
>
> I'm wondering if you have experience (if it's passible in the first place)
> in fitting a mixed model with multiple multinomial responses in MCMCglmm. I
> was trying to fit such model but I bumped into the truble of what the
> "trait" dummy variable does actually index in such a model?
>
> In a "univariate" multinomial model (which actually already is
> multivariate) like the one below the trait variable indexes single odds
> ratios for 2nd/3rd... category against the 1st category. Is it possible to
> extend this into a situation with more than one multinomial variables?
>
>
> cheers,
> Szymek
>
> require(MCMCglmm)
>
> mydata <- data.frame(response1 = c(sample(c("a","b","c"), replace=T, size =
> 100)),
>                      covariate = rnorm(100), random =
> gl(20,5,labels=letters[1:20]))
>
>
> K <- length(levels(mydata$response1))
> I <- diag(K-1)
> J <- matrix(0,K-1,K-1) + 1
> IJ <- 1/K*(I+J)
>
> size=2
> prior <- list(R=list(V=IJ, fix=1),
>               G=list(G1=list(V=IJ, nu=K-1+0.002)),
>               B=list(mu=rep(0,size*(K-1)), V=kronecker(IJ,
> diag(size))*(1.7+pi^2/3)))
>
> model <- MCMCglmm(response1~trait*covariate-1, random=~us(trait):random,
> rcov=~us(trait):units,
>                   family="categorical", data=mydata, prior=prior)
>
> #######################################
>
> ## now what to do with the 2nd response variable?
>
> mydata$response2 <- as.factor(c(sample(c("w","x","y","z"), replace=T, size
> = 100)))
>
>
> --
>
> *Dr Szymon Drobniak*
> Anthropological Institute and Museum
> Office Y42-K-66
> University of Z?rich - Irchel
> Winterthurerstrasse 190
> CH-8057 Z?rich, Switzerland
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From yuki_himawari at hotmail.com  Thu Aug 14 00:13:49 2014
From: yuki_himawari at hotmail.com (yuki fujita)
Date: Wed, 13 Aug 2014 22:13:49 +0000
Subject: [R-sig-ME] PredictSE.mer error message
Message-ID: <BAY172-W435F8C14E4830570A3DE599EEB0@phx.gbl>

Hi

I am running glmer model with binomial distribution and want to get confidence interval using fixed effect for each treatments. 
However I get the error message I don't really understand therefore I don't know how to modify the code. 

My model is 

model_2b <- glmer(cbind(NumberCorrect,10-NumberCorrect)~ ADHDYN + EmotionType + (1 | ID),
                  family="binomial",data = data)

and here is the summary output

Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
 Family: binomial  ( logit )
Formula: cbind(NumberCorrect, 10 - NumberCorrect) ~ ADHDYN + EmotionType +      (1 | ID)
   Data: data

     AIC      BIC   logLik deviance df.resid 
  2000.5   2034.5   -992.3   1984.5      508 

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-3.4809 -0.7256  0.1760  0.7238  3.4354 

Random effects:
 Groups Name        Variance Std.Dev.
 ID     (Intercept) 0.1337   0.3656  
Number of obs: 516, groups:  ID, 86

Fixed effects:
             Estimate Std. Error z value Pr(>|z|)    
(Intercept)   1.15637    0.10193  11.345  < 2e-16 ***
ADHDYNYES    -0.27728    0.10236  -2.709  0.00675 ** 
EmotionType2  2.04670    0.17845  11.469  < 2e-16 ***
EmotionType3 -0.24761    0.10744  -2.305  0.02119 *  
EmotionType4 -1.79462    0.10811 -16.600  < 2e-16 ***
EmotionType5 -0.04793    0.10939  -0.438  0.66129    
EmotionType6 -1.01871    0.10445  -9.753  < 2e-16 ***
---

And I used the code below to get CI's but got error message.

> predictSE.mer(model_2b, NEWdata,se.fit=TRUE, type="response",level=0, print.matrix=FALSE)
Error in predictSE.mer(model_2b, NEWdata, se.fit = TRUE, type = "response",  : 
  no slot of name "offset" for this object of class "glmerMod"
Can you please guide me where I am getting wrong? I noted the sd of random effect is quite large- so might be worth to do the simulation. I heard about MCMCsamp but is this the way to go?

Thank you kindly
Yuki


 		 	   		  
	[[alternative HTML version deleted]]


From jake987722 at hotmail.com  Thu Aug 14 00:21:02 2014
From: jake987722 at hotmail.com (Jake Westfall)
Date: Wed, 13 Aug 2014 16:21:02 -0600
Subject: [R-sig-ME] PredictSE.mer error message
In-Reply-To: <BAY172-W435F8C14E4830570A3DE599EEB0@phx.gbl>
References: <BAY172-W435F8C14E4830570A3DE599EEB0@phx.gbl>
Message-ID: <BAY172-W309DBE877586226C90A919CBEB0@phx.gbl>

Apparently predictSE.mer() is a function from the "AICcmodavg" package (it doesn't come with lme4). You should take this up with the maintainer of that package.

Jake

> From: yuki_himawari at hotmail.com
> To: r-sig-mixed-models at r-project.org
> Date: Wed, 13 Aug 2014 22:13:49 +0000
> Subject: [R-sig-ME] PredictSE.mer error message
> 
> Hi
> 
> I am running glmer model with binomial distribution and want to get confidence interval using fixed effect for each treatments. 
> However I get the error message I don't really understand therefore I don't know how to modify the code. 
> 
> My model is 
> 
> model_2b <- glmer(cbind(NumberCorrect,10-NumberCorrect)~ ADHDYN + EmotionType + (1 | ID),
>                   family="binomial",data = data)
> 
> and here is the summary output
> 
> Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
>  Family: binomial  ( logit )
> Formula: cbind(NumberCorrect, 10 - NumberCorrect) ~ ADHDYN + EmotionType +      (1 | ID)
>    Data: data
> 
>      AIC      BIC   logLik deviance df.resid 
>   2000.5   2034.5   -992.3   1984.5      508 
> 
> Scaled residuals: 
>     Min      1Q  Median      3Q     Max 
> -3.4809 -0.7256  0.1760  0.7238  3.4354 
> 
> Random effects:
>  Groups Name        Variance Std.Dev.
>  ID     (Intercept) 0.1337   0.3656  
> Number of obs: 516, groups:  ID, 86
> 
> Fixed effects:
>              Estimate Std. Error z value Pr(>|z|)    
> (Intercept)   1.15637    0.10193  11.345  < 2e-16 ***
> ADHDYNYES    -0.27728    0.10236  -2.709  0.00675 ** 
> EmotionType2  2.04670    0.17845  11.469  < 2e-16 ***
> EmotionType3 -0.24761    0.10744  -2.305  0.02119 *  
> EmotionType4 -1.79462    0.10811 -16.600  < 2e-16 ***
> EmotionType5 -0.04793    0.10939  -0.438  0.66129    
> EmotionType6 -1.01871    0.10445  -9.753  < 2e-16 ***
> ---
> 
> And I used the code below to get CI's but got error message.
> 
> > predictSE.mer(model_2b, NEWdata,se.fit=TRUE, type="response",level=0, print.matrix=FALSE)
> Error in predictSE.mer(model_2b, NEWdata, se.fit = TRUE, type = "response",  : 
>   no slot of name "offset" for this object of class "glmerMod"
> Can you please guide me where I am getting wrong? I noted the sd of random effect is quite large- so might be worth to do the simulation. I heard about MCMCsamp but is this the way to go?
> 
> Thank you kindly
> Yuki
> 
> 
>  		 	   		  
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
 		 	   		  
	[[alternative HTML version deleted]]


From marcoplebani85 at gmail.com  Thu Aug 14 12:54:25 2014
From: marcoplebani85 at gmail.com (Marco Plebani)
Date: Thu, 14 Aug 2014 12:54:25 +0200
Subject: [R-sig-ME] Random effect variance = zero
In-Reply-To: <mailman.7.1407924002.3188.r-sig-mixed-models@r-project.org>
References: <mailman.7.1407924002.3188.r-sig-mixed-models@r-project.org>
Message-ID: <FFEEF13B-AE33-4DC1-91BD-AA3C1C159B76@gmail.com>

Dear list members,

Package blme has been suggested for fixing issues with random effect variance = zero in other occasions, but I do not understand the rationale behind it. What does blme that lme4 does not? In which way do the two approaches differ? In particular:
- what is the prior information that blme is using, and
- how comes that blme still estimates parameter values and assign p-values to them? According to my (very limited) knowledge of bayesian stats the outcome of the analysis should be an updated distribution of the possible parameter values.

The available documentation about blme is limited and/or I could not find it. I realize that my question on blme hides another, much broader, on how bayesian stats work; regarding the latter, a suggestion of a good, practice-oriented reference book would be appreciated.

Thank you in advance,

Marco

-----
Marco Plebani, PhD candidate (Ecology) at the University of Zurich
Institute of Evolutionary Biology and Environmental Studies
http://www.ieu.uzh.ch/staff/phd/plebani.html

On 13/ago/2014, at 12:00, r-sig-mixed-models-request at r-project.org wrote:

> Date: Tue, 12 Aug 2014 12:35:10 -0400
> Subject: Re: [R-sig-ME] Random effect variance = zero
> From: bbolker at gmail.com
> To: aurorepaligot at hotmail.com
> CC: r-sig-mixed-models at r-project.org
> 
> 
> Short answer: yes, very common outcome, especially with small numbers of random effects groups (e.g. <5).  See http://glmm.wikidot.com/faq ; blme package for 'regularizing' fits so this doesn't happen (at the expense of changing the statistical model slightly); http://rpubs.com/bbolker/4187 .
> 
> 
> 
> On Tue, Aug 12, 2014 at 12:05 PM, Aurore Paligot <aurorepaligot at hotmail.com> wrote:
> 
> Hello Everybody, I am new at using mixed models, and I would like some advice about some results that I obtained and that seem counter-intuitive to me.  As an output of a test, I obtainded a variance of zero for a random factor.
> 
> [?] How is it possible?  Can it be considered as a reasonable output?
> 
> I found this information about the variance estimates of zero. Could this explanation apply to my study?
> 
> "It is possible to end up with a school variance estimate of zero. This fact often puzzles the researcher since each school will most certainly not have the same mean test result. An estimated among-school variance being zero, however, does not mean that each school has the same mean, but rather that the clustering of the students within schools does not help explain any of the overall variability present in test results. In this case, test results of students can be considered as all independent of each other regardless if they are from the same school or not. "( http://www.cscu.cornell.edu/news/statnews/stnews69.pdf )
> 
> If not, where could the problem come from? Is the formula that I used correct? Is a mixed-model appropriate for this type of question?
> 
> I would really appreciate some clarification if someone already faced this type of problem !
> 
> Best regards,
> 
> Aurore


From paul.johnson at glasgow.ac.uk  Thu Aug 14 15:15:55 2014
From: paul.johnson at glasgow.ac.uk (Paul Johnson)
Date: Thu, 14 Aug 2014 13:15:55 +0000
Subject: [R-sig-ME] "bootstrap runs failed" in bootMer within confint.merMod
Message-ID: <00A92C99-9997-4820-8F0D-803427324DDE@glasgow.ac.uk>

Hi,

I?ve been using confint.merMod to get 95% CIs by parametric bootstrapping, and have been getting the warnings of the type "In bootMer(object, bootFun, nsim = nsim, ...) : some bootstrap runs failed (30/100)?. (I realise than 100 samples are too few - this is just an example). The function still returns CIs using the bootstrap samples that didn?t fail, but I don?t think these CIs are valid as the failures are very unlikely to be a random sample. Here?s an example using the grouseticks data set that comes with lme4 (see ?grouseticks). I chose this data set because it?s a classic example data set so presumably isn?t pathological, but I?ve been encountering the same problem with other apparently healthy glmer fits.

> library(lme4)
> full_mod1  <- glmer(TICKS ~ YEAR+scale(HEIGHT)+(1|BROOD)+(1|INDEX)+(1|LOCATION), family="poisson", data=grouseticks)
> set.seed(12345)
> confint(full_mod1, method = "boot", boot.type = "basic", nsim = 100, parallel = "multicore", ncpus = 8)
Computing bootstrap confidence intervals ...
                                2.5 %     97.5 %
sd_(Intercept)|INDEX     0.4624700492  0.6550336
sd_(Intercept)|BROOD     0.5740796527  1.0482547
sd_(Intercept)|LOCATION  0.2497343230  1.0574176
(Intercept)             -0.0002611865  0.7208569
YEAR96                   0.7770837606  1.5857202
YEAR97                  -1.4648325648 -0.4484355
scale(HEIGHT)           -1.1335522182 -0.5879858
Warning message:
In bootMer(object, bootFun, nsim = nsim, ...) :
  some bootstrap runs failed (30/100)

(NB I scaled height to prevent a warning but it makes no difference to the likelihood.)

I tried to replicate the problem using bootMer directly to produce fixed effect estimates from 10 samples:

> bootMer(full_mod1, fixef, nsim = 10)$t
      (Intercept)    YEAR96     YEAR97 scale(HEIGHT)
 [1,]   0.6387534 0.7467317 -1.1291369    -0.8741711
 [2,]          NA        NA         NA            NA
 [3,]   0.1920928 1.3666922 -0.5821328    -0.6742498
 [4,]          NA        NA         NA            NA
 [5,]          NA        NA         NA            NA
 [6,]   0.5312426 0.9639612 -1.1041643    -0.7550492
 [7,]          NA        NA         NA            NA
 [8,]   0.2328530 1.1016917 -0.8010541    -0.8480263
 [9,]   0.2685594 1.2806690 -0.7452719    -0.8302675
[10,]   0.1726928 1.1423894 -0.8989542    -1.0344128
Warning message:
In bootMer(full_mod1, fixef, nsim = 10) : some bootstrap runs failed (4/10)

?and get the same problem, not surprisingly. Here?s a manual version of what (I believe) bootMer is doing:


> simTICKS.tab <- simulate(full_mod1, nsim=10)
> t(apply(simTICKS.tab, 2, function(simTICKS) fixef(glmer(simTICKS ~ YEAR+scale(HEIGHT)+(1|BROOD)+(1|INDEX)+(1|LOCATION), family="poisson", data=grouseticks))))
       (Intercept)    YEAR96     YEAR97 scale(HEIGHT)
sim_1    0.1793276 1.2265976 -0.5753168    -0.6435871
sim_2    0.3918824 1.4583529 -0.8958396    -0.8513233
sim_3    0.2565916 1.1230342 -0.9369728    -1.0817019
sim_4    0.3507285 1.1865904 -1.0654895    -0.9193403
sim_5    0.5688213 0.7291811 -0.9734654    -0.8575988
sim_6    0.6160919 1.0552260 -1.5139770    -1.0050926
sim_7    0.1594954 1.1342809 -1.0624134    -0.8107930
sim_8    0.7956874 0.8290606 -1.2491060    -1.0024299
sim_9    0.3081545 1.2677562 -1.0398100    -0.9458849
sim_10   0.4325345 0.9390844 -0.9241206    -0.7341589

?no errors, not even a warning. The discrepancy between bootMer and the DIY version above appears to arise from the bootMer fitting function, refit, being less tolerant of warning signs (non-convergence?) than glmer, which can be seen by putting refit into the DIY bootstrap:

> t(apply(simTICKS.tab, 2, function(simTICKS) fixef(refit(full_mod1, simTICKS))))
Warning messages:
1: In pwrssUpdate(pp, resp, tolPwrss, GQmat, compDev, fac, verbose) :
  Cholmod warning 'not positive definite' at file:../Cholesky/t_cholmod_rowfac.c, line 431
2: In pwrssUpdate(pp, resp, tolPwrss, GQmat, compDev, fac, verbose) :
  Cholmod warning 'not positive definite' at file:../Cholesky/t_cholmod_rowfac.c, line 431
Error in t(apply(simTICKS.tab, 2, function(simTICKS) fixef(refit(full_mod1,  : 
  error in evaluating the argument 'x' in selecting a method for function 't': Error in t(apply(simTICKS.tab, 2, function(simTICKS) fixef(refit(full_mod1,  : 
  (maxstephalfit) PIRLS step-halvings failed to reduce deviance in pwrssUpdate

My questions are: 

Should I trust the error- and warning-free DIY bootstrap results? I would say ?yes?, on the (slightly vague) basis that glmer produced no warnings, and that the original model fits well to what is a pretty information-rich data set. So is bootMer being oversensitive? I?m aware that there have been some teething problems with the optimisers and convergence checks in lme4 1.0+ ? are these ongoing? I?m writing a tutorial document in which I?d like to demonstrate parametric bootstrapping for CIs. I could use the DIY approach, but I?d much rather use confint, so it would be great if there was a simple fix to this problem.

Thanks in advance,
Paul Johnson 
(the Glasgow one, not the Kansas or Oxford ones)

> sessionInfo()
R version 3.1.1 (2014-07-10)
Platform: x86_64-apple-darwin13.1.0 (64-bit)

locale:
[1] en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8

attached base packages:
[1] parallel  stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] lme4_1.1-7   Rcpp_0.11.2  Matrix_1.1-4

loaded via a namespace (and not attached):
[1] boot_1.3-11     grid_3.1.1      lattice_0.20-29 MASS_7.3-33     minqa_1.2.3     nlme_3.1-117    nloptr_1.0.0    splines_3.1.1   tools_3.1.1    
 


From bates at stat.wisc.edu  Thu Aug 14 17:12:43 2014
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 14 Aug 2014 10:12:43 -0500
Subject: [R-sig-ME] Random effect variance = zero
In-Reply-To: <FFEEF13B-AE33-4DC1-91BD-AA3C1C159B76@gmail.com>
References: <mailman.7.1407924002.3188.r-sig-mixed-models@r-project.org>
	<FFEEF13B-AE33-4DC1-91BD-AA3C1C159B76@gmail.com>
Message-ID: <CAO7JsnT10Uu9uk_11-mDukXRiJ3N1xkOrkvnTP1Hecu6Yt3bow@mail.gmail.com>

On Thu, Aug 14, 2014 at 5:54 AM, Marco Plebani <marcoplebani85 at gmail.com>
wrote:

> Dear list members,
>
> Package blme has been suggested for fixing issues with random effect
> variance = zero in other occasions, but I do not understand the rationale
> behind it. What does blme that lme4 does not? In which way do the two
> approaches differ? In particular:
>

I appreciate your asking these questions.  Personally, I don't regard
random-effect variances being estimated as zero as an issue that needs to
be "fixed".  To me this is a situation where the data indicate that the
model should be simplified, in the sense that the random effects term can
be removed without substantial loss of fidelity to the data.

The maximum likelihood or the REML criterion can be viewed as a trade-off
between model simplicity and fidelity to the data.  In cases where the
model converges to boundary conditions, such as a variance component
estimate of zero, the simpler model does not fit significantly worse than
the model with the random effects present.

>From the context of the data we may "know" (or at least expect) that there
is variability between the groups that we should take into account.  An
estimate of zero does not indicate that there is no variability in the
groups; it indicates that there is not excess variability beyond what would
be induced by the residual, or per-observation, variability.  If you
simulate 50 observations, say from a Gaussian distribution, and arbitrarily
divide them into 10 groups of 5 there will be variability in the means of
these 10 groups, even though there was no explicit group-to-group
variability added to the simulation.

An estimate of zero for a variance component is a property of the model,
not of the underlying mechanism generating the data.  Remember George Box's
famous statement that "All models are wrong; some models are useful."

This is why I feel uncomfortable with assigning a prior that will have the
effect of pulling the estimate of a variance component away from zero. To
me, this is overruling the data.  If the data do not contain sufficient
information to distinguish between the model fits with and without the
random effects then to me that indicates that you should report it as such.
This doesn't mean that you have affirmed the null hypothesis of the
between-group variance being zero.  It is much more likely that there is
insufficient data to estimate the parameters in a model of this level of
complexity.  Don't confuse absence of evidence with evidence of absence.

Estimation of variance and covariance components requires a large number of
groups.  It is important to realize this.  It is also important to realize
that in most cases you are not terribly interested in precise estimates of
variance components.  Sometimes you are but a substantial portion of the
time you are using  random effects to model subject-to-subject variability,
etc. and if the data don't provide sufficient subject-to-subject
variability to support the model then drop down to a simpler model.  This
works in the case of a zero variance component; other cases with variances
and covariances in which the covariance matrix has a singular estimate are
more difficult to handle.

In a Bayesian framework the choice of prior can allow you to pull the
parameter estimates away from uncomfortable values.  But it is this choice
that I find uncomfortable.  Suppose I analyze data using one prior and
reach some conclusions and then you analyze the same data with a different
choice of prior and reach other conclusions.  Are our conclusions based on
the data or on our prior beliefs?

In most cases this doesn't happen.  If the likelihood is much less diffuse
than the prior then the posterior distribution is dominated by the data,
not the prior. But it is exactly in the boundary cases that the likelihood
is very diffuse and the information is coming from the prior, not the data.
 To me, this is a red flag.  Assigning a prior to pull back parameter
estimates from problematic values is, in my opinion, overruling the data.

I feel that the choice of prior should be justified on grounds other than
"it gives me the results that I want".  That is too harsh a criticism - no
reputable investigator would do such a thing on purpose but they may do so
by accident.  As with many concepts in statistics, the mathematics to
investigate the properties of priors is subtle and difficult.  Box and Tiao
in their book "Bayesian Inference in Statistical Analysis" appeal to the
concept of "data translated likelihood" to justify a locally uniform prior
on the logarithm of a variance.  This means that the prior pushes the
estimate of a standard deviation or variance towards zero, not away from
zero.

I do admit that I haven't kept up with the literature on Bayesian inference
so there may be better justifications for prior distributions on variance
components and covariance matrices for random effects.  I do think,
however, that there should be some justification outside the context of the
data for a choice of prior, especially in cases where the prior dominates
the likelihood.  In practice this means the cases where the estimates are
on the boundary or where the information on the variance components is very
diffuse.  Unfortunately, those cases are more common than we would like.
You must have a large number of groups before you can hope to have
precision on the estimate of a single variance component.  You must have a
very large number of groups before you can hope for precision of an
estimate of a covariance matrix for random effects.

- what is the prior information that blme is using, and
> - how comes that blme still estimates parameter values and assign p-values
> to them? According to my (very limited) knowledge of bayesian stats the
> outcome of the analysis should be an updated distribution of the possible
> parameter values.
>
> The available documentation about blme is limited and/or I could not find
> it. I realize that my question on blme hides another, much broader, on how
> bayesian stats work; regarding the latter, a suggestion of a good,
> practice-oriented reference book would be appreciated.
>
> Thank you in advance,
>
> Marco
>
> -----
> Marco Plebani, PhD candidate (Ecology) at the University of Zurich
> Institute of Evolutionary Biology and Environmental Studies
> http://www.ieu.uzh.ch/staff/phd/plebani.html
>
> On 13/ago/2014, at 12:00, r-sig-mixed-models-request at r-project.org wrote:
>
> > Date: Tue, 12 Aug 2014 12:35:10 -0400
> > Subject: Re: [R-sig-ME] Random effect variance = zero
> > From: bbolker at gmail.com
> > To: aurorepaligot at hotmail.com
> > CC: r-sig-mixed-models at r-project.org
> >
> >
> > Short answer: yes, very common outcome, especially with small numbers of
> random effects groups (e.g. <5).  See http://glmm.wikidot.com/faq ; blme
> package for 'regularizing' fits so this doesn't happen (at the expense of
> changing the statistical model slightly); http://rpubs.com/bbolker/4187 .
> >
> >
> >
> > On Tue, Aug 12, 2014 at 12:05 PM, Aurore Paligot <
> aurorepaligot at hotmail.com> wrote:
> >
> > Hello Everybody, I am new at using mixed models, and I would like some
> advice about some results that I obtained and that seem counter-intuitive
> to me.  As an output of a test, I obtainded a variance of zero for a random
> factor.
> >
> > [?] How is it possible?  Can it be considered as a reasonable output?
> >
> > I found this information about the variance estimates of zero. Could
> this explanation apply to my study?
> >
> > "It is possible to end up with a school variance estimate of zero. This
> fact often puzzles the researcher since each school will most certainly not
> have the same mean test result. An estimated among-school variance being
> zero, however, does not mean that each school has the same mean, but rather
> that the clustering of the students within schools does not help explain
> any of the overall variability present in test results. In this case, test
> results of students can be considered as all independent of each other
> regardless if they are from the same school or not. "(
> http://www.cscu.cornell.edu/news/statnews/stnews69.pdf )
> >
> > If not, where could the problem come from? Is the formula that I used
> correct? Is a mixed-model appropriate for this type of question?
> >
> > I would really appreciate some clarification if someone already faced
> this type of problem !
> >
> > Best regards,
> >
> > Aurore
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

	[[alternative HTML version deleted]]


From saoirse.preston at gmail.com  Thu Aug 14 17:11:50 2014
From: saoirse.preston at gmail.com (Saoirse Preston)
Date: Thu, 14 Aug 2014 16:11:50 +0100
Subject: [R-sig-ME] random vs fixed effects and glmer model simplification
Message-ID: <CAEC03ba6aqNDBtO5ZkXL-zoMDGWhg19vFoQFcvh7guXoJv39Fw@mail.gmail.com>

Dear List,

I'm new to statistics and R so apologies for the beginner question.

I have a dataset with count data from a large sample of people and I am
trying to specify the most appropriate model. I am not sure whether I
should be using a mixed model or not. I have been more specific below, but
I suppose my general question is how do you decide whether a factor is
fixed or random? I read in Crawley's R book that generally fixed effects
vary in mean over factor levels whereas random effects vary in variance
over factor levels, but this definition does not seem to be consistent over
the various (and sometimes dubious) internet sources I've found on the
subject.

More specifically -

I have poisson-distributed data on the number of hours people spend doing
various activities with their children, and I have this data from various
years and countries, and from mothers and fathers, and I have data on how
many hours a week they work. So, I have come up with 2 potential models:

Model 1
glm(hours ~ parent * work + year + country, family="poisson")
# then go on to do model simplification with
anova(model,model2,test="Chisq")

Model 2
glmer(hours ~ parent * work + (1|year) + (1|country), family="poisson")

where hours is a poisson-distributed numeric ranging from 0-35, parent is a
two level factor (mother or father), work is a numeric ranging from 0-52,
year is a factor with 11 levels (2004-2014) and country is a factor with 6
levels (6 country names).

I suppose I have a few questions from this. First, does anyone know which
of these models is most appropriate? Given the Crawley definition above, my
data do vary in mean over year and country, so they should be fixed
effects, but as I mentioned above, I am not sure about this definition.
Second, if the best model is in fact the mixed model, how do I go about
model simplification for this? I read in the documentation that you
shouldn't just do model simpification on the model as it is, but should add
REML=F beforehand, but I get error messages for this.

Once again, please accept my apologies for any stupid questions - this is
all very new to me and I'd be grateful for any pointers and constructive
criticism!!

Thanks very much

Saoirse.

(PhD student)

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Thu Aug 14 17:21:07 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 14 Aug 2014 11:21:07 -0400
Subject: [R-sig-ME] Random effect variance = zero
In-Reply-To: <FFEEF13B-AE33-4DC1-91BD-AA3C1C159B76@gmail.com>
References: <mailman.7.1407924002.3188.r-sig-mixed-models@r-project.org>
	<FFEEF13B-AE33-4DC1-91BD-AA3C1C159B76@gmail.com>
Message-ID: <53ECD3E3.6000203@gmail.com>

On 14-08-14 06:54 AM, Marco Plebani wrote:
> Dear list members,
> 
> Package blme has been suggested for fixing issues with random effect
> variance = zero in other occasions, but I do not understand the
> rationale behind it. What does blme that lme4 does not? In which way
> do the two approaches differ? In particular: - what is the prior
> information that blme is using, and - how comes that blme still
> estimates parameter values and assign p-values to them? According to
> my (very limited) knowledge of bayesian stats the outcome of the
> analysis should be an updated distribution of the possible parameter
> values.
> 
> The available documentation about blme is limited and/or I could not
> find it. I realize that my question on blme hides another, much
> broader, on how bayesian stats work; regarding the latter, a
> suggestion of a good, practice-oriented reference book would be
> appreciated.
> 
> Thank you in advance,
> 
> Marco

 (Started writing this before Doug's comments, which I agree are [as
usual] thoughtful and sensible but think represent one point of view.)

  For a start, there's a paper that describes the approach in detail:
Chung, Yeojin and Rabe-Hesketh, Sophia and Dorie, Vincent and Gelman,
Andrew and Liu, Jingche. "A Nondegenerate Penalized Likelihood Estimator
for Variance Parameters in Multilevel Models". Psychometrika
doi:10.1007/s11336-013-9328-2

  As for the p-values; I would say that in this context they're not
particularly philosophically coherent but do still represent a rough
measure of strength of evidence ...

  cheers
    Ben Bolker


> 
> ----- Marco Plebani, PhD candidate (Ecology) at the University of
> Zurich Institute of Evolutionary Biology and Environmental Studies 
> http://www.ieu.uzh.ch/staff/phd/plebani.html
> 
> On 13/ago/2014, at 12:00, r-sig-mixed-models-request at r-project.org
> wrote:
> 
>> Date: Tue, 12 Aug 2014 12:35:10 -0400 Subject: Re: [R-sig-ME]
>> Random effect variance = zero From: bbolker at gmail.com To:
>> aurorepaligot at hotmail.com CC: r-sig-mixed-models at r-project.org
>> 
>> 
>> Short answer: yes, very common outcome, especially with small
>> numbers of random effects groups (e.g. <5).  See
>> http://glmm.wikidot.com/faq ; blme package for 'regularizing' fits
>> so this doesn't happen (at the expense of changing the statistical
>> model slightly); http://rpubs.com/bbolker/4187 .
>> 
>> 
>> 
>> On Tue, Aug 12, 2014 at 12:05 PM, Aurore Paligot
>> <aurorepaligot at hotmail.com> wrote:
>> 
>> Hello Everybody, I am new at using mixed models, and I would like
>> some advice about some results that I obtained and that seem
>> counter-intuitive to me.  As an output of a test, I obtainded a
>> variance of zero for a random factor.
>> 
>> [?] How is it possible?  Can it be considered as a reasonable
>> output?
>> 
>> I found this information about the variance estimates of zero.
>> Could this explanation apply to my study?
>> 
>> "It is possible to end up with a school variance estimate of zero.
>> This fact often puzzles the researcher since each school will most
>> certainly not have the same mean test result. An estimated
>> among-school variance being zero, however, does not mean that each
>> school has the same mean, but rather that the clustering of the
>> students within schools does not help explain any of the overall
>> variability present in test results. In this case, test results of
>> students can be considered as all independent of each other
>> regardless if they are from the same school or not. "(
>> http://www.cscu.cornell.edu/news/statnews/stnews69.pdf )
>> 
>> If not, where could the problem come from? Is the formula that I
>> used correct? Is a mixed-model appropriate for this type of
>> question?
>> 
>> I would really appreciate some clarification if someone already
>> faced this type of problem !
>> 
>> Best regards,
>> 
>> Aurore
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From M.Fairbrother at bristol.ac.uk  Thu Aug 14 17:44:16 2014
From: M.Fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Thu, 14 Aug 2014 16:44:16 +0100
Subject: [R-sig-ME] random vs fixed effects and glmer model
	simplification
Message-ID: <CAAH-yP_zM4ZVjvQvjc2rGRK2QmzmC2szEq=T7mS-n0mG6BzAuQ@mail.gmail.com>

Dear Saoirse,

This is not a stupid question.

You actually have a three-level data structure: individuals nested within
country-years (N=66) nested within countries (N=6). But with only six
higher-level units, although a multilevel model might converge with your
data, it makes more sense to use country fixed effects, and also to include
time as a variable too (with year dummies, or perhaps just a linear effect,
or quadratic).

*If* you had more higher level units, your glmer call would *almost* make
sense. You would want something more like:
glmer(hours ~ parent * work + year + (1|countryyear) + (1|country),
family="poisson")
where "countryyear" is an indicator variable, for example made up of
"country*1000+year" or something.

Two recent papers in Political Science Research and Methods (by myself, and
by two colleagues) will show you why:
http://dx.doi.org/10.1017/psrm.2013.24
http://dx.doi.org/10.1017/psrm.2014.7

But, again, with only six countries, just a fixed effects model all you can
do.

- Malcolm



>
> Date: Thu, 14 Aug 2014 16:11:50 +0100
> From: Saoirse Preston <saoirse.preston at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] random vs fixed effects and glmer model
>         simplification
>
> Dear List,
>
> I'm new to statistics and R so apologies for the beginner question.
>
> I have a dataset with count data from a large sample of people and I am
> trying to specify the most appropriate model. I am not sure whether I
> should be using a mixed model or not. I have been more specific below, but
> I suppose my general question is how do you decide whether a factor is
> fixed or random? I read in Crawley's R book that generally fixed effects
> vary in mean over factor levels whereas random effects vary in variance
> over factor levels, but this definition does not seem to be consistent
over
> the various (and sometimes dubious) internet sources I've found on the
> subject.
>
> More specifically -
>
> I have poisson-distributed data on the number of hours people spend doing
> various activities with their children, and I have this data from various
> years and countries, and from mothers and fathers, and I have data on how
> many hours a week they work. So, I have come up with 2 potential models:
>
> Model 1
> glm(hours ~ parent * work + year + country, family="poisson")
> # then go on to do model simplification with
> anova(model,model2,test="Chisq")
>
> Model 2
> glmer(hours ~ parent * work + (1|year) + (1|country), family="poisson")
>
> where hours is a poisson-distributed numeric ranging from 0-35, parent is
a
> two level factor (mother or father), work is a numeric ranging from 0-52,
> year is a factor with 11 levels (2004-2014) and country is a factor with 6
> levels (6 country names).
>
> I suppose I have a few questions from this. First, does anyone know which
> of these models is most appropriate? Given the Crawley definition above,
my
> data do vary in mean over year and country, so they should be fixed
> effects, but as I mentioned above, I am not sure about this definition.
> Second, if the best model is in fact the mixed model, how do I go about
> model simplification for this? I read in the documentation that you
> shouldn't just do model simpification on the model as it is, but should
add
> REML=F beforehand, but I get error messages for this.
>
> Once again, please accept my apologies for any stupid questions - this is
> all very new to me and I'd be grateful for any pointers and constructive
> criticism!!
>
> Thanks very much
>
> Saoirse.
>
> (PhD student)

	[[alternative HTML version deleted]]


From deter088 at umn.edu  Thu Aug 14 20:08:58 2014
From: deter088 at umn.edu (Charles Determan Jr)
Date: Thu, 14 Aug 2014 13:08:58 -0500
Subject: [R-sig-ME] lmer random and fixed effect?
Message-ID: <CAOLJph=trQmab2xKg5MDE+Sw14i-hVtBqFKpiE0Q8Wv9pG9QmA@mail.gmail.com>

Greetings,

I have been looking more into mixed models recently and have run into a
situation that confuses me.  I was initially under the impression that
fixed and random effect variables are separate, however can they be both in
an lmer model and if so why would you do so?

Such as example is with the following dataset:
lmm.data <- read.table("
http://www.unt.edu/rss/class/Jon/R_SC/Module9/lmm.data.txt",
                       header=TRUE, sep=",", na.strings="NA", dec=".",
strip.white=TRUE)

Reading online, I have found the following model:
require(lme4)
fit <- lmer(formula = extro~open+agree+social+class+(1|school/class), data
= lmm.data)

Everything runs fine but I am confused as to what this actually means or if
it is even appropriate.

Thank you for any insight,
Regards,

-- 
Dr. Charles Determan, PhD
Integrated Biosciences

	[[alternative HTML version deleted]]


From Farrar.David at epa.gov  Thu Aug 14 20:25:35 2014
From: Farrar.David at epa.gov (Farrar, David)
Date: Thu, 14 Aug 2014 18:25:35 +0000
Subject: [R-sig-ME] lmer random and fixed effect?
In-Reply-To: <CAOLJph=trQmab2xKg5MDE+Sw14i-hVtBqFKpiE0Q8Wv9pG9QmA@mail.gmail.com>
References: <CAOLJph=trQmab2xKg5MDE+Sw14i-hVtBqFKpiE0Q8Wv9pG9QmA@mail.gmail.com>
Message-ID: <daae1ee287c645f69c08669bcbd874af@BY1PR09MB0392.namprd09.prod.outlook.com>



A split-plot design is an example where both are used.  You may find helpful the discussion of that design "the R book."

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Charles Determan Jr
Sent: Thursday, August 14, 2014 2:09 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] lmer random and fixed effect?

Greetings,

I have been looking more into mixed models recently and have run into a situation that confuses me.  I was initially under the impression that fixed and random effect variables are separate, however can they be both in an lmer model and if so why would you do so?

Such as example is with the following dataset:
lmm.data <- read.table("
http://www.unt.edu/rss/class/Jon/R_SC/Module9/lmm.data.txt",
                       header=TRUE, sep=",", na.strings="NA", dec=".",
strip.white=TRUE)

Reading online, I have found the following model:
require(lme4)
fit <- lmer(formula = extro~open+agree+social+class+(1|school/class), data = lmm.data)

Everything runs fine but I am confused as to what this actually means or if it is even appropriate.

Thank you for any insight,
Regards,

--
Dr. Charles Determan, PhD
Integrated Biosciences

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Thu Aug 14 22:59:01 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 14 Aug 2014 16:59:01 -0400
Subject: [R-sig-ME] lmer random and fixed effect?
In-Reply-To: <daae1ee287c645f69c08669bcbd874af@BY1PR09MB0392.namprd09.prod.outlook.com>
References: <CAOLJph=trQmab2xKg5MDE+Sw14i-hVtBqFKpiE0Q8Wv9pG9QmA@mail.gmail.com>
	<daae1ee287c645f69c08669bcbd874af@BY1PR09MB0392.namprd09.prod.outlook.com>
Message-ID: <53ED2315.8070600@gmail.com>

  In this example:

lmer(formula = extro~open+agree+social+class+(1|school/class),
     data = lmm.data)

  'class' is included as a fixed effect, and the random effects grouping
variable is specified as school/class, which means "class nested within
school", i.e. the same as school+school:class (where : denotes
interaction).  Note that class itself is *not* included as a
random-effects grouping variable.   This model specification would make
sense if (1) levels of the class variable are defined across schools
(i.e. class #1 in school #1 has something in common with class #1 in
school #2); (2) it makes sense to treat class as a fixed effect, i.e. we
have a fairly small number of classes and/or we want to make inferences
about the values of particular classes contrasts among specific classes
(and not just the variation among classes)


On 14-08-14 02:25 PM, Farrar, David wrote:
> 
> 
> A split-plot design is an example where both are used.  You may find
> helpful the discussion of that design "the R book."
> 
> -----Original Message----- From:
> r-sig-mixed-models-bounces at r-project.org
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of
> Charles Determan Jr Sent: Thursday, August 14, 2014 2:09 PM To:
> r-sig-mixed-models at r-project.org Subject: [R-sig-ME] lmer random and
> fixed effect?
> 
> Greetings,
> 
> I have been looking more into mixed models recently and have run into
> a situation that confuses me.  I was initially under the impression
> that fixed and random effect variables are separate, however can they
> be both in an lmer model and if so why would you do so?
> 
> Such as example is with the following dataset: lmm.data <-
> read.table(" 
> http://www.unt.edu/rss/class/Jon/R_SC/Module9/lmm.data.txt", 
> header=TRUE, sep=",", na.strings="NA", dec=".", strip.white=TRUE)
> 
> Reading online, I have found the following model: require(lme4) fit
> <- lmer(formula = extro~open+agree+social+class+(1|school/class),
> data = lmm.data)
> 
> Everything runs fine but I am confused as to what this actually means
> or if it is even appropriate.
> 
> Thank you for any insight, Regards,
> 
> -- Dr. Charles Determan, PhD Integrated Biosciences
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From Farrar.David at epa.gov  Fri Aug 15 00:17:47 2014
From: Farrar.David at epa.gov (Farrar, David)
Date: Thu, 14 Aug 2014 22:17:47 +0000
Subject: [R-sig-ME] lmer random and fixed effect?
In-Reply-To: <53ED2315.8070600@gmail.com>
References: <CAOLJph=trQmab2xKg5MDE+Sw14i-hVtBqFKpiE0Q8Wv9pG9QmA@mail.gmail.com>
	<daae1ee287c645f69c08669bcbd874af@BY1PR09MB0392.namprd09.prod.outlook.com>
	<53ED2315.8070600@gmail.com>
Message-ID: <fb8215f375114bbc91540233c738631e@BY1PR09MB0392.namprd09.prod.outlook.com>


In agreement, I think, I hazard a guess that the research questions relate to levels of open, agree, and social which have been measured at the class or school level.   Could a correct specification be ~ open + agree + social + (1 | school/class) ? 
The school part could get a little tricky as follows.   It could be asked "did you see any difference between east schools and west schools?" etc.  The possibilities seem to be to evaluate the school blups or add in and test an east-west fixed factor.  Seems either way you could easily get into a multiple-testing problem by commenting extensively.  If you submit speculations based on blups for publication, you might be asked why they are not formally tested.  How do editors respond to interpretations based on blups?  


-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Ben Bolker
Sent: Thursday, August 14, 2014 4:59 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] lmer random and fixed effect?

  In this example:

lmer(formula = extro~open+agree+social+class+(1|school/class),
     data = lmm.data)

  'class' is included as a fixed effect, and the random effects grouping variable is specified as school/class, which means "class nested within school", i.e. the same as school+school:class (where : denotes interaction).  Note that class itself is *not* included as a
random-effects grouping variable.   This model specification would make
sense if (1) levels of the class variable are defined across schools (i.e. class #1 in school #1 has something in common with class #1 in school #2); (2) it makes sense to treat class as a fixed effect, i.e. we have a fairly small number of classes and/or we want to make inferences about the values of particular classes contrasts among specific classes (and not just the variation among classes)


On 14-08-14 02:25 PM, Farrar, David wrote:
> 
> 
> A split-plot design is an example where both are used.  You may find 
> helpful the discussion of that design "the R book."
> 
> -----Original Message----- From:
> r-sig-mixed-models-bounces at r-project.org
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Charles 
> Determan Jr Sent: Thursday, August 14, 2014 2:09 PM To:
> r-sig-mixed-models at r-project.org Subject: [R-sig-ME] lmer random and 
> fixed effect?
> 
> Greetings,
> 
> I have been looking more into mixed models recently and have run into 
> a situation that confuses me.  I was initially under the impression 
> that fixed and random effect variables are separate, however can they 
> be both in an lmer model and if so why would you do so?
> 
> Such as example is with the following dataset: lmm.data <- 
> read.table("
> http://www.unt.edu/rss/class/Jon/R_SC/Module9/lmm.data.txt",
> header=TRUE, sep=",", na.strings="NA", dec=".", strip.white=TRUE)
> 
> Reading online, I have found the following model: require(lme4) fit
> <- lmer(formula = extro~open+agree+social+class+(1|school/class),
> data = lmm.data)
> 
> Everything runs fine but I am confused as to what this actually means 
> or if it is even appropriate.
> 
> Thank you for any insight, Regards,
> 
> -- Dr. Charles Determan, PhD Integrated Biosciences
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Fri Aug 15 07:52:59 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 15 Aug 2014 05:52:59 +0000 (UTC)
Subject: [R-sig-ME] Random effect variance = zero
References: <mailman.7.1407924002.3188.r-sig-mixed-models@r-project.org>
	<FFEEF13B-AE33-4DC1-91BD-AA3C1C159B76@gmail.com>
	<53ECD3E3.6000203@gmail.com>
Message-ID: <loom.20140815T075057-805@post.gmane.org>

Ben Bolker <bbolker at ...> writes:

> 
> On 14-08-14 06:54 AM, Marco Plebani wrote:
> > Dear list members,
> > 
> > Package blme has been suggested for fixing issues with random effect
> > variance = zero in other occasions, but I do not understand the
> > rationale behind it. What does blme that lme4 does not? In which way
> > do the two approaches differ? In particular: - what is the prior
> > information that blme is using, and - how comes that blme still
> > estimates parameter values and assign p-values to them? According to
> > my (very limited) knowledge of bayesian stats the outcome of the
> > analysis should be an updated distribution of the possible parameter
> > values.
> > 
> > The available documentation about blme is limited and/or I could not
> > find it. I realize that my question on blme hides another, much
> > broader, on how bayesian stats work; regarding the latter, a
> > suggestion of a good, practice-oriented reference book would be
> > appreciated.
> > 
> > Thank you in advance,
> > 
> > Marco
> 
>  (Started writing this before Doug's comments, which I agree are [as
> usual] thoughtful and sensible but think represent one point of view.)
> 
>   For a start, there's a paper that describes the approach in detail:
> Chung, Yeojin and Rabe-Hesketh, Sophia and Dorie, Vincent and Gelman,
> Andrew and Liu, Jingche. "A Nondegenerate Penalized Likelihood Estimator
> for Variance Parameters in Multilevel Models". Psychometrika
> doi:10.1007/s11336-013-9328-2
> 
>   As for the p-values; I would say that in this context they're not
> particularly philosophically coherent but do still represent a rough
> measure of strength of evidence ...
> 
>   cheers
>     Ben Bolker
> 


  PS Andrew Gelman has a thoughtful post on this subject (the fact
that in many practical cases there's insufficient information in the
data to determine the among-group variance) from a Bayesian perspective
(a "stalwart" Bayesian view, using informative priors, rather than
a "cringing" Bayesian view that tries to come up with a weakly
informative prior that fixes (?) the problem (?) of zero variances ...)

http://andrewgelman.com/2014/08/11/
   discussion-sander-greenland-posterior-predictive-checks/
(broken URL to make Gmane happy)


From john.maindonald at anu.edu.au  Fri Aug 15 09:16:00 2014
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Fri, 15 Aug 2014 07:16:00 +0000
Subject: [R-sig-ME] Random effect variance = zero
In-Reply-To: <CAO7JsnT10Uu9uk_11-mDukXRiJ3N1xkOrkvnTP1Hecu6Yt3bow@mail.gmail.com>
References: <mailman.7.1407924002.3188.r-sig-mixed-models@r-project.org>
	<FFEEF13B-AE33-4DC1-91BD-AA3C1C159B76@gmail.com>
	<CAO7JsnT10Uu9uk_11-mDukXRiJ3N1xkOrkvnTP1Hecu6Yt3bow@mail.gmail.com>
Message-ID: <1A048228-CB6D-423E-A88A-96954FB7B904@anu.edu.au>

I have argued the issue of possible negative ?variance? components previously.  
There are cases where the ability to fit a negative variance component will lead
to something like the correct variance-covariance matrix.  If that is what the data
say, then the software should allow them to make their voice heard, and they 
should be listened to.

Scientists who misunderstand what blocking is about will on occasion choose 
blocks that maximise within block variability, e.g., at right angles to a stream
rather than parallel to the stream.  

One needs to distinguish the case where there is no reason to choose any other
estimate than zero, and the case where, with the model as formulated, a negative
component of variance (e.g., a negative between block variance) is somewhere 
needed in order to get the variance-covariance matrix right.

I am talking about what happens on the way to a final meaningful (one hopes)
modelling of the data.  At the end of the day, one would prefer not to have to give
a meaning to negative variances!  

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


On 15 Aug 2014, at 1:12, Douglas Bates <bates at stat.wisc.edu> wrote:

> On Thu, Aug 14, 2014 at 5:54 AM, Marco Plebani <marcoplebani85 at gmail.com>
> wrote:
> 
>> Dear list members,
>> 
>> Package blme has been suggested for fixing issues with random effect
>> variance = zero in other occasions, but I do not understand the rationale
>> behind it. What does blme that lme4 does not? In which way do the two
>> approaches differ? In particular:
>> 
> 
> I appreciate your asking these questions.  Personally, I don't regard
> random-effect variances being estimated as zero as an issue that needs to
> be "fixed".  To me this is a situation where the data indicate that the
> model should be simplified, in the sense that the random effects term can
> be removed without substantial loss of fidelity to the data.
> 
> The maximum likelihood or the REML criterion can be viewed as a trade-off
> between model simplicity and fidelity to the data.  In cases where the
> model converges to boundary conditions, such as a variance component
> estimate of zero, the simpler model does not fit significantly worse than
> the model with the random effects present.
> 
>> From the context of the data we may "know" (or at least expect) that there
> is variability between the groups that we should take into account.  An
> estimate of zero does not indicate that there is no variability in the
> groups; it indicates that there is not excess variability beyond what would
> be induced by the residual, or per-observation, variability.  If you
> simulate 50 observations, say from a Gaussian distribution, and arbitrarily
> divide them into 10 groups of 5 there will be variability in the means of
> these 10 groups, even though there was no explicit group-to-group
> variability added to the simulation.
> 
> An estimate of zero for a variance component is a property of the model,
> not of the underlying mechanism generating the data.  Remember George Box's
> famous statement that "All models are wrong; some models are useful."
> 
> This is why I feel uncomfortable with assigning a prior that will have the
> effect of pulling the estimate of a variance component away from zero. To
> me, this is overruling the data.  If the data do not contain sufficient
> information to distinguish between the model fits with and without the
> random effects then to me that indicates that you should report it as such.
> This doesn't mean that you have affirmed the null hypothesis of the
> between-group variance being zero.  It is much more likely that there is
> insufficient data to estimate the parameters in a model of this level of
> complexity.  Don't confuse absence of evidence with evidence of absence.
> 
> Estimation of variance and covariance components requires a large number of
> groups.  It is important to realize this.  It is also important to realize
> that in most cases you are not terribly interested in precise estimates of
> variance components.  Sometimes you are but a substantial portion of the
> time you are using  random effects to model subject-to-subject variability,
> etc. and if the data don't provide sufficient subject-to-subject
> variability to support the model then drop down to a simpler model.  This
> works in the case of a zero variance component; other cases with variances
> and covariances in which the covariance matrix has a singular estimate are
> more difficult to handle.
> 
> In a Bayesian framework the choice of prior can allow you to pull the
> parameter estimates away from uncomfortable values.  But it is this choice
> that I find uncomfortable.  Suppose I analyze data using one prior and
> reach some conclusions and then you analyze the same data with a different
> choice of prior and reach other conclusions.  Are our conclusions based on
> the data or on our prior beliefs?
> 
> In most cases this doesn't happen.  If the likelihood is much less diffuse
> than the prior then the posterior distribution is dominated by the data,
> not the prior. But it is exactly in the boundary cases that the likelihood
> is very diffuse and the information is coming from the prior, not the data.
> To me, this is a red flag.  Assigning a prior to pull back parameter
> estimates from problematic values is, in my opinion, overruling the data.
> 
> I feel that the choice of prior should be justified on grounds other than
> "it gives me the results that I want".  That is too harsh a criticism - no
> reputable investigator would do such a thing on purpose but they may do so
> by accident.  As with many concepts in statistics, the mathematics to
> investigate the properties of priors is subtle and difficult.  Box and Tiao
> in their book "Bayesian Inference in Statistical Analysis" appeal to the
> concept of "data translated likelihood" to justify a locally uniform prior
> on the logarithm of a variance.  This means that the prior pushes the
> estimate of a standard deviation or variance towards zero, not away from
> zero.
> 
> I do admit that I haven't kept up with the literature on Bayesian inference
> so there may be better justifications for prior distributions on variance
> components and covariance matrices for random effects.  I do think,
> however, that there should be some justification outside the context of the
> data for a choice of prior, especially in cases where the prior dominates
> the likelihood.  In practice this means the cases where the estimates are
> on the boundary or where the information on the variance components is very
> diffuse.  Unfortunately, those cases are more common than we would like.
> You must have a large number of groups before you can hope to have
> precision on the estimate of a single variance component.  You must have a
> very large number of groups before you can hope for precision of an
> estimate of a covariance matrix for random effects.
> 
> - what is the prior information that blme is using, and
>> - how comes that blme still estimates parameter values and assign p-values
>> to them? According to my (very limited) knowledge of bayesian stats the
>> outcome of the analysis should be an updated distribution of the possible
>> parameter values.
>> 
>> The available documentation about blme is limited and/or I could not find
>> it. I realize that my question on blme hides another, much broader, on how
>> bayesian stats work; regarding the latter, a suggestion of a good,
>> practice-oriented reference book would be appreciated.
>> 
>> Thank you in advance,
>> 
>> Marco
>> 
>> -----
>> Marco Plebani, PhD candidate (Ecology) at the University of Zurich
>> Institute of Evolutionary Biology and Environmental Studies
>> http://www.ieu.uzh.ch/staff/phd/plebani.html
>> 
>> On 13/ago/2014, at 12:00, r-sig-mixed-models-request at r-project.org wrote:
>> 
>>> Date: Tue, 12 Aug 2014 12:35:10 -0400
>>> Subject: Re: [R-sig-ME] Random effect variance = zero
>>> From: bbolker at gmail.com
>>> To: aurorepaligot at hotmail.com
>>> CC: r-sig-mixed-models at r-project.org
>>> 
>>> 
>>> Short answer: yes, very common outcome, especially with small numbers of
>> random effects groups (e.g. <5).  See http://glmm.wikidot.com/faq ; blme
>> package for 'regularizing' fits so this doesn't happen (at the expense of
>> changing the statistical model slightly); http://rpubs.com/bbolker/4187 .
>>> 
>>> 
>>> 
>>> On Tue, Aug 12, 2014 at 12:05 PM, Aurore Paligot <
>> aurorepaligot at hotmail.com> wrote:
>>> 
>>> Hello Everybody, I am new at using mixed models, and I would like some
>> advice about some results that I obtained and that seem counter-intuitive
>> to me.  As an output of a test, I obtainded a variance of zero for a random
>> factor.
>>> 
>>> [?] How is it possible?  Can it be considered as a reasonable output?
>>> 
>>> I found this information about the variance estimates of zero. Could
>> this explanation apply to my study?
>>> 
>>> "It is possible to end up with a school variance estimate of zero. This
>> fact often puzzles the researcher since each school will most certainly not
>> have the same mean test result. An estimated among-school variance being
>> zero, however, does not mean that each school has the same mean, but rather
>> that the clustering of the students within schools does not help explain
>> any of the overall variability present in test results. In this case, test
>> results of students can be considered as all independent of each other
>> regardless if they are from the same school or not. "(
>> http://www.cscu.cornell.edu/news/statnews/stnews69.pdf )
>>> 
>>> If not, where could the problem come from? Is the formula that I used
>> correct? Is a mixed-model appropriate for this type of question?
>>> 
>>> I would really appreciate some clarification if someone already faced
>> this type of problem !
>>> 
>>> Best regards,
>>> 
>>> Aurore
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From zournyque at gmail.com  Fri Aug 15 11:30:39 2014
From: zournyque at gmail.com (florian k.)
Date: Fri, 15 Aug 2014 11:30:39 +0200
Subject: [R-sig-ME] =?utf-8?q?=5BR=5D_lqmm_-_package=3A_Error_in_f=28arg?=
	=?utf-8?q?=2C_=E2=80=A6=29_=3A_NA/NaN/Inf_in_foreign_function_call?=
	=?utf-8?q?_=28arg_1=29?=
Message-ID: <CAM9anWo+Lhycx3uOKdzPxJQsj1A1Xu6pSPCw0fAkQ3GirSx-6Q@mail.gmail.com>

Dear mailing list,

I keep getting the following error when trying to compute linear
quantile mixed models using the lqmm package:

 "NA/NaN/Inf in foreign function call (arg 1)"

For better readability I posted my question on stackoverflow:

http://stackoverflow.com/questions/25323880/error-in-farg-na-nan-inf-in-foreign-function-call-arg-1-r-lqmm-pa

I would be very thankful if any of you could help me! Thank you for your time!

Best Greetings,
Florian


From jeff at jeffreyevans.org  Fri Aug 15 17:48:06 2014
From: jeff at jeffreyevans.org (Jeffrey Evans)
Date: Fri, 15 Aug 2014 11:48:06 -0400
Subject: [R-sig-ME] bootMer: 2 questions about generating standard errors in
	lme4
Message-ID: <53EE2BB6.6010707@jeffreyevans.org>

Hi all,

I am trying to generate standard errors for the predicted values from a 
binomial GLMM in lme4. There have been a number of posts about using 
bootMer to accomplish this, but the obtuse language in the help file and 
in these posts continues to befuddle me, and the responses often seem 
tailored to specific cases (e.g. 
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2013q3/020663.html). 
My questions are:

(1) Could someone please help tailor a response for my specific case?
(2) Can bootMer be run in parallel on a multi-core windows machine? I 
found some code fragments on the web from Ben Bolker that appear to 
attempt this using snow, but it doesn't seem to be implemented in the 
current version of lme4. http://ms.mcmaster.ca/~bolker/misc/bootMer_min.Rout

My model has one fixed categorical effect (site), and random effects for 
the experimental unit (ID) and year (Year):

     m1 = glmer(cbind(S,F) ~ site + (1|ID) + (1|Year), 
data=dat,family="binomial")

where S and F are the numbers of successes and failures, respectively 
and year is coded as a factor.

I want marginal predictions for each site, which I can generate with the 
predict function, but how do I get standard errors for those predictions 
which incorporate variance due to year?

# generate marginal predictions
pred = 
predict(m1,newdata=data.frame(site=unique(dat$site)),REform=NA,type="response")

# are these options correct?
predSE = bootMer(m1, predict, use.u=T,type="parametric",nsim = 
10,.progress="txt")

I'm not sure how to choose use.u and type or whether just using predict 
as the function is sufficient. In a past comment, Ben Bolker talked 
about using FUN=predict vs. FUN=sumulate, but I'm not sure what the 
difference is. 
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2013q3/020663.html

What if I want the predictions back-transformed to the data scale (i.e. 
as probabilities)?

Any guidance is appreciated.

Many thanks,
Jeff Evans


From bbolker at gmail.com  Fri Aug 15 23:34:32 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 15 Aug 2014 14:34:32 -0700
Subject: [R-sig-ME] bootMer: 2 questions about generating standard
 errors in lme4
In-Reply-To: <53EE2BB6.6010707@jeffreyevans.org>
References: <53EE2BB6.6010707@jeffreyevans.org>
Message-ID: <CABghstT_FOuH-v851Z-dMZwYp683a+c-fkbT+OhR8BM+YH6yUw@mail.gmail.com>

On Fri, Aug 15, 2014 at 8:48 AM, Jeffrey Evans <jeff at jeffreyevans.org>
wrote:

> Hi all,
>
> I am trying to generate standard errors for the predicted values from a
> binomial GLMM in lme4. There have been a number of posts about using
> bootMer to accomplish this, but the obtuse language in the help file



If you'd like to give specific suggestions that would help improve the help
file that would be great ...


> and in these posts continues to befuddle me, and the responses often seem
> tailored to specific cases (e.g. https://stat.ethz.ch/
> pipermail/r-sig-mixed-models/2013q3/020663.html). My questions are:
>
> (1) Could someone please help tailor a response for my specific case?
> (2) Can bootMer be run in parallel on a multi-core windows machine? I
> found some code fragments on the web from Ben Bolker that appear to attempt
> this using snow, but it doesn't seem to be implemented in the current
> version of lme4. http://ms.mcmaster.ca/~bolker/misc/bootMer_min.Rout
>
>
 It should, I think (I could be wrong, I haven't tried it lately or looked
back at the code).  Did you try?  "doesn't seem to be implemented" -- do
you get an error message?  What error message?



> My model has one fixed categorical effect (site), and random effects for
> the experimental unit (ID) and year (Year):
>
>     m1 = glmer(cbind(S,F) ~ site + (1|ID) + (1|Year),
> data=dat,family="binomial")
>
> where S and F are the numbers of successes and failures, respectively and
> year is coded as a factor.
>
> I want marginal predictions for each site, which I can generate with the
> predict function, but how do I get standard errors for those predictions
> which incorporate variance due to year?
>
> # generate marginal predictions
> pred = predict(m1,newdata=data.frame(site=unique(dat$site)),REform=
> NA,type="response")
>

  Minor point: re.form is preferred to REform , we're hoping to deprecate
REform in the future.



> # are these options correct?
> predSE = bootMer(m1, predict, use.u=T,type="parametric",nsim =
> 10,.progress="txt")
>

    You'll have to think about it carefully for yourself,  but I think it
would be better *not* to condition on the estimated conditional modes for
ID and Year; I would use

nd <- data.frame(site=unique(dat$site))
predictFun <- function(x)
predict(x,newdata=nd,re.form=~(1|Year),type="response")
predBoot <- bootMer(m1, predictFun, use.u=FALSE, ...)


> I'm not sure how to choose use.u and type or whether just using predict as
> the function is sufficient. In a past comment, Ben Bolker talked about
> using FUN=predict vs. FUN=sumulate, but I'm not sure what the difference
> is. https://stat.ethz.ch/pipermail/r-sig-mixed-models/2013q3/020663.html
>

   the difference between predict() and simulate() would essentially be the
difference between confidence intervals (not including residual variance)
and prediction intervals.

>
> What if I want the predictions back-transformed to the data scale (i.e. as
> probabilities)?
>

  Isn't this what you're already getting?

  Can you give a simple reproducible example?

	[[alternative HTML version deleted]]


From zournyque at gmail.com  Sat Aug 16 18:02:58 2014
From: zournyque at gmail.com (florian k.)
Date: Sat, 16 Aug 2014 18:02:58 +0200
Subject: [R-sig-ME]
	=?utf-8?q?=5BR=5D_lqmm_-_package=3A_Error_in_f=28arg?=
	=?utf-8?q?=2C_=E2=80=A6=29_=3A_NA/NaN/Inf_in_foreign_function_call?=
	=?utf-8?q?_=28arg_1=29?=
In-Reply-To: <CAM9anWqLRbSny04=mw1rFqsHb3KwbicwOrwCFmEyR2ah+J2XgA@mail.gmail.com>
References: <CAM9anWo+Lhycx3uOKdzPxJQsj1A1Xu6pSPCw0fAkQ3GirSx-6Q@mail.gmail.com>
	<CAM9anWqLRbSny04=mw1rFqsHb3KwbicwOrwCFmEyR2ah+J2XgA@mail.gmail.com>
Message-ID: <CAM9anWo6hHKjzNSHEmnrJ4nj2Kk=992m4W=DZFJDDC1y5L+4Dg@mail.gmail.com>

Dear mailing list,

After some requests I finally managed to make my error reproducible -
please find the dataset here:

https://dl.dropboxusercontent.com/u/79415744/mixedModelDataSet.txt

require("lqmm")

stackoverflow <- read.table("mixedModelDataSet.txt",  sep="\t", header
= TRUE ) # import

mixMoGs15 <- lqmm(gsDeviationMio ~ aoi, random =  ~ 1, group = vpName,
data = stackoverflow, tau = 0.15)

Thanks in advance for your help,
Best,
Florian

On Sat, Aug 16, 2014 at 5:57 PM, florian k. <zournyque at gmail.com> wrote:
> Dear mailing list,
>
> After some requests I finally managed to make my error reproducible -
> find the data set attached
>
> require("lqmm")
>
> stackoverflow <- read.table("mixedModelDataSet.txt",  sep="\t", header
> = TRUE ) # import
>
> mixMoGs15 <- lqmm(gsDeviationMio ~ aoi, random =  ~ 1, group = vpName,
> data = stackoverflow, tau = 0.15)
>
> Thanks in advance for your help,
> Best,
> Florian
>
> On Fri, Aug 15, 2014 at 11:30 AM, florian k. <zournyque at gmail.com> wrote:
>> Dear mailing list,
>>
>> I keep getting the following error when trying to compute linear
>> quantile mixed models using the lqmm package:
>>
>>  "NA/NaN/Inf in foreign function call (arg 1)"
>>
>> For better readability I posted my question on stackoverflow:
>>
>> http://stackoverflow.com/questions/25323880/error-in-farg-na-nan-inf-in-foreign-function-call-arg-1-r-lqmm-pa
>>
>> I would be very thankful if any of you could help me! Thank you for your time!
>>
>> Best Greetings,
>> Florian


From bbolker at gmail.com  Sun Aug 17 00:45:05 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 16 Aug 2014 15:45:05 -0700
Subject: [R-sig-ME]
	=?utf-8?q?=5BR=5D_lqmm_-_package=3A_Error_in_f=28arg?=
	=?utf-8?q?=2C_=E2=80=A6=29_=3A_NA/NaN/Inf_in_foreign_function_call?=
	=?utf-8?q?_=28arg_1=29?=
In-Reply-To: <CAM9anWo6hHKjzNSHEmnrJ4nj2Kk=992m4W=DZFJDDC1y5L+4Dg@mail.gmail.com>
References: <CAM9anWo+Lhycx3uOKdzPxJQsj1A1Xu6pSPCw0fAkQ3GirSx-6Q@mail.gmail.com>
	<CAM9anWqLRbSny04=mw1rFqsHb3KwbicwOrwCFmEyR2ah+J2XgA@mail.gmail.com>
	<CAM9anWo6hHKjzNSHEmnrJ4nj2Kk=992m4W=DZFJDDC1y5L+4Dg@mail.gmail.com>
Message-ID: <CABghstSo=eqVKdLXrLUjfLcKb_GKWE1sK8kn+wXSHTOsaStDmA@mail.gmail.com>

I did some poking around and couldn't figure it out -- it fails fairly deep
inside the function (options(error=recover) is useful ...).  I would ask
the maintainer (see maintainer("lqmm")).

  However, I wonder why you're pulling out these big guns for this
problem.  With only 4 random effects groups, you won't get much shrinkage,
and with so many data points all comparisons will probably be statistically
significant.  Why not just compute the quantiles you're interested in
across groups?


require("lqmm")
stackoverflow <- read.table("mixedModelDataSet.txt",
                            sep="\t", header = TRUE ) # import

so2 <- stackoverflow[complete.cases(stackoverflow),]
mixMoGs15 <- lqmm(gsDeviationMio ~ aoi, random =  ~ 1, group = vpName,
                  data = so2, tau = 0.15)

library(ggplot2); theme_set(theme_bw())
ggplot(so2,aes(x=aoi,y=gsDeviationMio,colour=vpName))+geom_point()
ggplot(so2,aes(x=aoi,y=gsDeviationMio,colour=vpName))+geom_boxplot()
ggplot(so2,aes(x=aoi,y=gsDeviationMio,colour=vpName,fill=vpName))+
    geom_violin()
with(so2,tapply(gsDeviationMio,list(vpName,aoi),quantile,0.15))
with(so2,table(vpName,aoi))



On Sat, Aug 16, 2014 at 9:02 AM, florian k. <zournyque at gmail.com> wrote:

> Dear mailing list,
>
> After some requests I finally managed to make my error reproducible -
> please find the dataset here:
>
> https://dl.dropboxusercontent.com/u/79415744/mixedModelDataSet.txt
>
> require("lqmm")
>
> stackoverflow <- read.table("mixedModelDataSet.txt",  sep="\t", header
> = TRUE ) # import
>
> mixMoGs15 <- lqmm(gsDeviationMio ~ aoi, random =  ~ 1, group = vpName,
> data = stackoverflow, tau = 0.15)
>
> Thanks in advance for your help,
> Best,
> Florian
>
> On Sat, Aug 16, 2014 at 5:57 PM, florian k. <zournyque at gmail.com> wrote:
> > Dear mailing list,
> >
> > After some requests I finally managed to make my error reproducible -
> > find the data set attached
> >
> > require("lqmm")
> >
> > stackoverflow <- read.table("mixedModelDataSet.txt",  sep="\t", header
> > = TRUE ) # import
> >
> > mixMoGs15 <- lqmm(gsDeviationMio ~ aoi, random =  ~ 1, group = vpName,
> > data = stackoverflow, tau = 0.15)
> >
> > Thanks in advance for your help,
> > Best,
> > Florian
> >
> > On Fri, Aug 15, 2014 at 11:30 AM, florian k. <zournyque at gmail.com>
> wrote:
> >> Dear mailing list,
> >>
> >> I keep getting the following error when trying to compute linear
> >> quantile mixed models using the lqmm package:
> >>
> >>  "NA/NaN/Inf in foreign function call (arg 1)"
> >>
> >> For better readability I posted my question on stackoverflow:
> >>
> >>
> http://stackoverflow.com/questions/25323880/error-in-farg-na-nan-inf-in-foreign-function-call-arg-1-r-lqmm-pa
> >>
> >> I would be very thankful if any of you could help me! Thank you for
> your time!
> >>
> >> Best Greetings,
> >> Florian
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From zournyque at gmail.com  Sun Aug 17 10:00:18 2014
From: zournyque at gmail.com (florian k.)
Date: Sun, 17 Aug 2014 10:00:18 +0200
Subject: [R-sig-ME]
	=?utf-8?q?=5BR=5D_lqmm_-_package=3A_Error_in_f=28arg?=
	=?utf-8?q?=2C_=E2=80=A6=29_=3A_NA/NaN/Inf_in_foreign_function_call?=
	=?utf-8?q?_=28arg_1=29?=
In-Reply-To: <CABghstSo=eqVKdLXrLUjfLcKb_GKWE1sK8kn+wXSHTOsaStDmA@mail.gmail.com>
References: <CAM9anWo+Lhycx3uOKdzPxJQsj1A1Xu6pSPCw0fAkQ3GirSx-6Q@mail.gmail.com>
	<CAM9anWqLRbSny04=mw1rFqsHb3KwbicwOrwCFmEyR2ah+J2XgA@mail.gmail.com>
	<CAM9anWo6hHKjzNSHEmnrJ4nj2Kk=992m4W=DZFJDDC1y5L+4Dg@mail.gmail.com>
	<CABghstSo=eqVKdLXrLUjfLcKb_GKWE1sK8kn+wXSHTOsaStDmA@mail.gmail.com>
Message-ID: <CAM9anWrHw1Fp9GD+7DXpDV7RexSWGDyWyC7GfnuL6A+ssPgQLA@mail.gmail.com>

Hi Ben,

thank you for your time and effort, I will contact the project
maintainer as you suggested. I provided only a simplified version of
my model and dataset to reproduce the error. My original model has
twenty variables and the dataset has 42 subjects with around 400k
observations.

The plots you created look beautiful but I am not sure whether I
understand your code completely. Especially those two lines:
with(so2,tapply(gsDeviationMio,list(vpName,aoi),quantile,0.15))
with(so2,table(vpName,aoi))

However I think they will be hard to absorb when I do the same
procedure for all of my 42 test subjects. So here is some background
information:

Being a psychology student and still a novice to R and statistics in
general, I am not even sure whether the "big gun" is the right method
here. So here is some context. The data was obtained in a flight
simulator. The gsDeviationMio variable is a measurement for how far a
pilot deviates from his original landing course. 0 is no deviation, so
perfect landing course - higher or lower numbers indicate deviation. I
multiplied all values with 1 million as the values usually oscillate
between 0 and 1 and I had some issues with rounding going on when
calculating quantile regressions. Now I want to investigate the
relationship between a pilot's eye movements and the flying
performance. Variable Aoi are areas of interest so in other words
where the pilot is looking at.

First I calculated linear models and quantile regressions for RMSD
course deviations, now I want to investigate single observations.
Therefore I learned I need to delve into mixed models. I soon
calculated my first linear mixed model. (I guess I should apply a
transformation here, so how about square rooting everything to get rid
of the negative values of gsDeviationMio?).

The problem is theoretically average flight performance is not that
interesting, I am much more interested in predictors for either very
good or very bad flight performance. Therefore I wanted to use lqmm. I
hope this makes sense?

Hope you have a nice Sunday,
Florian

On Sun, Aug 17, 2014 at 12:45 AM, Ben Bolker <bbolker at gmail.com> wrote:
> I did some poking around and couldn't figure it out -- it fails fairly deep
> inside the function (options(error=recover) is useful ...).  I would ask the
> maintainer (see maintainer("lqmm")).
>
>   However, I wonder why you're pulling out these big guns for this problem.
> With only 4 random effects groups, you won't get much shrinkage, and with so
> many data points all comparisons will probably be statistically significant.
> Why not just compute the quantiles you're interested in across groups?
>
>
> require("lqmm")
> stackoverflow <- read.table("mixedModelDataSet.txt",
>                             sep="\t", header = TRUE ) # import
>
> so2 <- stackoverflow[complete.cases(stackoverflow),]
>
> mixMoGs15 <- lqmm(gsDeviationMio ~ aoi, random =  ~ 1, group = vpName,
>                   data = so2, tau = 0.15)
>
> library(ggplot2); theme_set(theme_bw())
> ggplot(so2,aes(x=aoi,y=gsDeviationMio,colour=vpName))+geom_point()
> ggplot(so2,aes(x=aoi,y=gsDeviationMio,colour=vpName))+geom_boxplot()
> ggplot(so2,aes(x=aoi,y=gsDeviationMio,colour=vpName,fill=vpName))+
>     geom_violin()
> with(so2,tapply(gsDeviationMio,list(vpName,aoi),quantile,0.15))
> with(so2,table(vpName,aoi))
>
>
>
> On Sat, Aug 16, 2014 at 9:02 AM, florian k. <zournyque at gmail.com> wrote:
>>
>> Dear mailing list,
>>
>> After some requests I finally managed to make my error reproducible -
>> please find the dataset here:
>>
>> https://dl.dropboxusercontent.com/u/79415744/mixedModelDataSet.txt
>>
>> require("lqmm")
>>
>> stackoverflow <- read.table("mixedModelDataSet.txt",  sep="\t", header
>> = TRUE ) # import
>>
>> mixMoGs15 <- lqmm(gsDeviationMio ~ aoi, random =  ~ 1, group = vpName,
>> data = stackoverflow, tau = 0.15)
>>
>> Thanks in advance for your help,
>> Best,
>> Florian
>>
>> On Sat, Aug 16, 2014 at 5:57 PM, florian k. <zournyque at gmail.com> wrote:
>> > Dear mailing list,
>> >
>> > After some requests I finally managed to make my error reproducible -
>> > find the data set attached
>> >
>> > require("lqmm")
>> >
>> > stackoverflow <- read.table("mixedModelDataSet.txt",  sep="\t", header
>> > = TRUE ) # import
>> >
>> > mixMoGs15 <- lqmm(gsDeviationMio ~ aoi, random =  ~ 1, group = vpName,
>> > data = stackoverflow, tau = 0.15)
>> >
>> > Thanks in advance for your help,
>> > Best,
>> > Florian
>> >
>> > On Fri, Aug 15, 2014 at 11:30 AM, florian k. <zournyque at gmail.com>
>> > wrote:
>> >> Dear mailing list,
>> >>
>> >> I keep getting the following error when trying to compute linear
>> >> quantile mixed models using the lqmm package:
>> >>
>> >>  "NA/NaN/Inf in foreign function call (arg 1)"
>> >>
>> >> For better readability I posted my question on stackoverflow:
>> >>
>> >>
>> >> http://stackoverflow.com/questions/25323880/error-in-farg-na-nan-inf-in-foreign-function-call-arg-1-r-lqmm-pa
>> >>
>> >> I would be very thankful if any of you could help me! Thank you for
>> >> your time!
>> >>
>> >> Best Greetings,
>> >> Florian
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


From E.W.Tobi at lumc.nl  Mon Aug 18 11:20:18 2014
From: E.W.Tobi at lumc.nl (E.W.Tobi at lumc.nl)
Date: Mon, 18 Aug 2014 09:20:18 +0000
Subject: [R-sig-ME] discrepency paired test and lmer()
Message-ID: <85454AB97CEF1347BD44F61CAF585E8A6222422B@mail-mb1.lumcnet.prod.intern>

Dear All, as my previous question was posted at the height of the vacation period I would like to repost the following issue I am encountering:


I am trying to test a continues, normally distributed, variable (Y) within sibling pairs which are discordant, or concordant, for an exposure, also including singleton exposed or unexposed down the line.
The inclusion of singletons excludes a simple lm() model like:
lm(Y~exposure+family_id)
To account for the family relationship

I tried starting simple, by making the model comparable to the simple lm model when including only the discordant and concordant pairs... leaving the singletons out the mix for now... but this has already proven surprisingly hard.
If I test the discordant sibling pairs only, the following models yields the exact same outcome as a paired t-test and lm(Y~exposure+fam_id), as it should.
lmer(Y~exposure+(1|family_id))
However, adding exposure concordant pairs to the discordant pairs set (non-exposed & non-exposed : "0"-"0" pairs....) yields completely different results between lmer and lm.

Overall, the t-values are (much) higher than with lm(). I am tasting many Y's.. (my field is genomics), so this inflation is very apparent when the plotting the expected versus observed t-statistics. Typically the 'lambda' (the coefficient describing the relation between observed en expected statistic) is 1.2-1.6.

Does anybody have an idea on why  lm() and lmer() differ in their t-value estimates when exposure concordant pairs are added?
And how to make a model resembling the more simple paired test?

To make things more complicated, we also have strong evidence that not all exposed siblings within a discordant pair will respond the same amounts of Y, but that the response is variable.
Therefore I added exposure status also as random slope, to keep things 'maximal'.

A standardized example:
library(lme4.0)  # I am using the old stable version, but the inflation is also apparent in the new version.

set.seed(20289457)
# normally distributed variable, with added 'effect' to part of the individuals (exposed within certain sibling pairs)
Y <- rnorm(n=200, m=0.25, sd=0.06)+c(rnorm(n=50,m=0.05,sd=0.03),rep(0,150))
family_id <- as.factor(rep(seq(1,100,by=1),2))
exposure <- c(rep(1,50),rep(0,150))
siblingtype <- c(rep(1,50),rep(0,50),rep(1,50),rep(0,50))  # this variable is added to distinguish discordant exposure from concordant exposure pairs

dataset <- data.frame(Y,family_id,exposure, siblingtype)

# first we take a look at the outcome in the exposure discordant pairs.
coefficients(summary(lm(Y~exposure+family_id, data=dataset, subset= siblingtype==1)))[c(1,2),]
t.test(Y[1:50],Y[101:150],paired=T)
lmer(Y~exposure+(1|family_id), data=dataset, subset= siblingtype==1)
lmer(Y~exposure+(1+exposure|family_id), data=dataset, subset= siblingtype==1)
# all have identical t-values; paired tests are identical to the mixed models

# the unexposed-unexposed pairs have:
t.test(Y[51:100],Y[151:200],paired=T)
# no evidence for a difference, which should boost confidence on observed difference?

coefficients(summary(lm(Y~exposure+family_id, data=dataset)))[c(1,2),]
# indeed, in a simple lm() the t-value increases.
lmer(Y~exposure+(1|family_id), data=dataset)
# also in a lmer, but now with much greater t-value: of note after testing 100K's of Y's I can definitely say that this is an inflated statistic!
lmer(Y~exposure+(1+exposure|family_id), data=dataset)
# adding the random intercept somewhat downplays this increase. But the outcome is not identical. The inflation remains!
# off note, in my real data the Corr of the random effects is ~0.2-0.3, close to the 'theoretical' 0.25 for full siblings in genetic studies (however Y is not a genetic marker and may thus deviate somewhat from 0.25)


sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=Dutch_Netherlands.1252  LC_CTYPE=Dutch_Netherlands.1252    LC_MONETARY=Dutch_Netherlands.1252
[4] LC_NUMERIC=C                       LC_TIME=Dutch_Netherlands.1252

attached base packages:
[1] splines   stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] coxme_2.2-3       bdsmatrix_1.3-1   survival_2.37-7   gee_4.13-18       nlme_3.1-117      lme4.0_0.999999-4 lattice_0.20-29
[8] Matrix_1.1-4      plyr_1.8.1

loaded via a namespace (and not attached):
[1] grid_3.0.2   Rcpp_0.11.2  stats4_3.0.2 tools_3.0.2


Any insight is highly appreciated.


Best wishes,
Tobi


	[[alternative HTML version deleted]]


From i.m.s.white at ed.ac.uk  Mon Aug 18 12:47:45 2014
From: i.m.s.white at ed.ac.uk (i white)
Date: Mon, 18 Aug 2014 11:47:45 +0100
Subject: [R-sig-ME] discrepency paired test and lmer()
In-Reply-To: <85454AB97CEF1347BD44F61CAF585E8A6222422B@mail-mb1.lumcnet.prod.intern>
References: <85454AB97CEF1347BD44F61CAF585E8A6222422B@mail-mb1.lumcnet.prod.intern>
Message-ID: <53F1D9D1.9020403@ed.ac.uk>

You should not be using lm. Data are balanced, so you could use aov with 
Error() term, which should agree with lmer.

aov(Y ~ exposure + Error(family_id), data = dataset)

The analysis of variance (source, d.f.) is

Concordant versus Discordant       1
Between families within SibTypes  98
Within families                  100

lm will test 'concordant versus discordant' against the 'within 
families' mean square. aov and lmer test against the 'between families 
within SibTypes' mean square.

I don't see how you get a t statistic for 'concordant versus discordant' 
if you only analyse discordant pairs.


On 08/18/2014 10:20 AM, E.W.Tobi at lumc.nl wrote:
> Dear All, as my previous question was posted at the height of the vacation period I would like to repost the following issue I am encountering:
>
>
> I am trying to test a continues, normally distributed, variable (Y) within sibling pairs which are discordant, or concordant, for an exposure, also including singleton exposed or unexposed down the line.
> The inclusion of singletons excludes a simple lm() model like:
> lm(Y~exposure+family_id)
> To account for the family relationship
>
> I tried starting simple, by making the model comparable to the simple lm model when including only the discordant and concordant pairs... leaving the singletons out the mix for now... but this has already proven surprisingly hard.
> If I test the discordant sibling pairs only, the following models yields the exact same outcome as a paired t-test and lm(Y~exposure+fam_id), as it should.
> lmer(Y~exposure+(1|family_id))
> However, adding exposure concordant pairs to the discordant pairs set (non-exposed & non-exposed : "0"-"0" pairs....) yields completely different results between lmer and lm.
>
> Overall, the t-values are (much) higher than with lm(). I am tasting many Y's.. (my field is genomics), so this inflation is very apparent when the plotting the expected versus observed t-statistics. Typically the 'lambda' (the coefficient describing the relation between observed en expected statistic) is 1.2-1.6.
>
> Does anybody have an idea on why  lm() and lmer() differ in their t-value estimates when exposure concordant pairs are added?
> And how to make a model resembling the more simple paired test?
>
> To make things more complicated, we also have strong evidence that not all exposed siblings within a discordant pair will respond the same amounts of Y, but that the response is variable.
> Therefore I added exposure status also as random slope, to keep things 'maximal'.
>
> A standardized example:
> library(lme4.0)  # I am using the old stable version, but the inflation is also apparent in the new version.
>
> set.seed(20289457)
> # normally distributed variable, with added 'effect' to part of the individuals (exposed within certain sibling pairs)
> Y <- rnorm(n=200, m=0.25, sd=0.06)+c(rnorm(n=50,m=0.05,sd=0.03),rep(0,150))
> family_id <- as.factor(rep(seq(1,100,by=1),2))
> exposure <- c(rep(1,50),rep(0,150))
> siblingtype <- c(rep(1,50),rep(0,50),rep(1,50),rep(0,50))  # this variable is added to distinguish discordant exposure from concordant exposure pairs
>
> dataset <- data.frame(Y,family_id,exposure, siblingtype)
>
> # first we take a look at the outcome in the exposure discordant pairs.
> coefficients(summary(lm(Y~exposure+family_id, data=dataset, subset= siblingtype==1)))[c(1,2),]
> t.test(Y[1:50],Y[101:150],paired=T)
> lmer(Y~exposure+(1|family_id), data=dataset, subset= siblingtype==1)
> lmer(Y~exposure+(1+exposure|family_id), data=dataset, subset= siblingtype==1)
> # all have identical t-values; paired tests are identical to the mixed models
>
> # the unexposed-unexposed pairs have:
> t.test(Y[51:100],Y[151:200],paired=T)
> # no evidence for a difference, which should boost confidence on observed difference?
>
> coefficients(summary(lm(Y~exposure+family_id, data=dataset)))[c(1,2),]
> # indeed, in a simple lm() the t-value increases.
> lmer(Y~exposure+(1|family_id), data=dataset)
> # also in a lmer, but now with much greater t-value: of note after testing 100K's of Y's I can definitely say that this is an inflated statistic!
> lmer(Y~exposure+(1+exposure|family_id), data=dataset)
> # adding the random intercept somewhat downplays this increase. But the outcome is not identical. The inflation remains!
> # off note, in my real data the Corr of the random effects is ~0.2-0.3, close to the 'theoretical' 0.25 for full siblings in genetic studies (however Y is not a genetic marker and may thus deviate somewhat from 0.25)
>
>
> sessionInfo()
> R version 3.0.2 (2013-09-25)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=Dutch_Netherlands.1252  LC_CTYPE=Dutch_Netherlands.1252    LC_MONETARY=Dutch_Netherlands.1252
> [4] LC_NUMERIC=C                       LC_TIME=Dutch_Netherlands.1252
>
> attached base packages:
> [1] splines   stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] coxme_2.2-3       bdsmatrix_1.3-1   survival_2.37-7   gee_4.13-18       nlme_3.1-117      lme4.0_0.999999-4 lattice_0.20-29
> [8] Matrix_1.1-4      plyr_1.8.1
>
> loaded via a namespace (and not attached):
> [1] grid_3.0.2   Rcpp_0.11.2  stats4_3.0.2 tools_3.0.2
>
>
> Any insight is highly appreciated.
>
>
> Best wishes,
> Tobi
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From richabharti74 at gmail.com  Mon Aug 18 14:49:52 2014
From: richabharti74 at gmail.com (Richa Bharti)
Date: Mon, 18 Aug 2014 14:49:52 +0200
Subject: [R-sig-ME] (no subject)
Message-ID: <CAHAAfB98iJOztJbFzqDXpJSyCFzyc7W0N6N5Si8mVh7kXReohQ@mail.gmail.com>

Dear All,

I have Cage effect in my data and would like to remove this effect for
further analysis, do anyone know how to over come from this effect with
lmer model.

Looking forward for reply!!


*
<http://www.jnu.ac.in/main.asp?sendval=SchoolOfComputationalandIntegrativeSciences>*

	[[alternative HTML version deleted]]


From jeff at jeffreyevans.org  Mon Aug 18 21:57:00 2014
From: jeff at jeffreyevans.org (Jeffrey Evans)
Date: Mon, 18 Aug 2014 15:57:00 -0400
Subject: [R-sig-ME] bootMer: 2 questions about generating standard
 errors in lme4
In-Reply-To: <CABghstT_FOuH-v851Z-dMZwYp683a+c-fkbT+OhR8BM+YH6yUw@mail.gmail.com>
References: <53EE2BB6.6010707@jeffreyevans.org>
	<CABghstT_FOuH-v851Z-dMZwYp683a+c-fkbT+OhR8BM+YH6yUw@mail.gmail.com>
Message-ID: <53F25A8C.5020907@jeffreyevans.org>

And as always, one should always check for the latest version of lme4. 
The older version I had didn't support parallel processing in bootMer.

Jeff

On 8/15/2014 5:34 PM, Ben Bolker wrote:
>
>
>
> On Fri, Aug 15, 2014 at 8:48 AM, Jeffrey Evans <jeff at jeffreyevans.org 
> <mailto:jeff at jeffreyevans.org>> wrote:
>
>     Hi all,
>
>     I am trying to generate standard errors for the predicted values
>     from a binomial GLMM in lme4. There have been a number of posts
>     about using bootMer to accomplish this, but the obtuse language in
>     the help file 
>
>
>
> If you'd like to give specific suggestions that would help improve the 
> help file that would be great ...
>
>     and in these posts continues to befuddle me, and the responses
>     often seem tailored to specific cases (e.g.
>     https://stat.ethz.ch/pipermail/r-sig-mixed-models/2013q3/020663.html).
>     My questions are:
>
>     (1) Could someone please help tailor a response for my specific case?
>     (2) Can bootMer be run in parallel on a multi-core windows
>     machine? I found some code fragments on the web from Ben Bolker
>     that appear to attempt this using snow, but it doesn't seem to be
>     implemented in the current version of lme4.
>     http://ms.mcmaster.ca/~bolker/misc/bootMer_min.Rout
>     <http://ms.mcmaster.ca/%7Ebolker/misc/bootMer_min.Rout>
>
>
>  It should, I think (I could be wrong, I haven't tried it lately or 
> looked back at the code).  Did you try? "doesn't seem to be 
> implemented" -- do you get an error message?  What error message?
>
>     My model has one fixed categorical effect (site), and random
>     effects for the experimental unit (ID) and year (Year):
>
>         m1 = glmer(cbind(S,F) ~ site + (1|ID) + (1|Year),
>     data=dat,family="binomial")
>
>     where S and F are the numbers of successes and failures,
>     respectively and year is coded as a factor.
>
>     I want marginal predictions for each site, which I can generate
>     with the predict function, but how do I get standard errors for
>     those predictions which incorporate variance due to year?
>
>     # generate marginal predictions
>     pred =
>     predict(m1,newdata=data.frame(site=unique(dat$site)),REform=NA,type="response")
>
>
>   Minor point: re.form is preferred to REform , we're hoping to 
> deprecate REform in the future.
>
>
>     # are these options correct?
>     predSE = bootMer(m1, predict, use.u=T,type="parametric",nsim =
>     10,.progress="txt")
>
>
>     You'll have to think about it carefully for yourself,  but I think 
> it would be better *not* to condition on the estimated conditional 
> modes for ID and Year; I would use
>
> nd <- data.frame(site=unique(dat$site))
> predictFun <- function(x) 
> predict(x,newdata=nd,re.form=~(1|Year),type="response")
> predBoot <- bootMer(m1, predictFun, use.u=FALSE, ...)
>
>
>     I'm not sure how to choose use.u and type or whether just using
>     predict as the function is sufficient. In a past comment, Ben
>     Bolker talked about using FUN=predict vs. FUN=sumulate, but I'm
>     not sure what the difference is.
>     https://stat.ethz.ch/pipermail/r-sig-mixed-models/2013q3/020663.html
>
>
>    the difference between predict() and simulate() would essentially 
> be the difference between confidence intervals (not including residual 
> variance) and prediction intervals.
>
>
>     What if I want the predictions back-transformed to the data scale
>     (i.e. as probabilities)?
>
>
>   Isn't this what you're already getting?
>
>   Can you give a simple reproducible example?


	[[alternative HTML version deleted]]


From cosimo2000 at gmail.com  Tue Aug 19 03:46:48 2014
From: cosimo2000 at gmail.com (Diego Carmona)
Date: Mon, 18 Aug 2014 20:46:48 -0500
Subject: [R-sig-ME] looking for differencies in G structure among factor
	levels using MCMCglmm
Message-ID: <CAPTtXmAvr0uNp5w_zE1KaE6ZTRNyLEB55ci0z-1YWCXyN7-NXA@mail.gmail.com>

 I am working with a multi-trait MCMCglmm model. The model has four plant
traits,
a three levels treatment is considered as a ?fixed? factor and, as a random
factor,
I included the term family (64 full maternal siblings).
What I am willing to know is the syntax that allow me to estimate the
genetic variance-covariance matrices
for each treatment.

In general, I am looking for differences in G structure among factor
levels. I guess that it should be
something like

G-structure: ~ us (trait):fam
             ~ us (trait):fam:tratA
          ~ us (trait):fam:tratB
             ~ us (trait):fam:tratC

R-structure: ~us(trait):units



This was my last attempt.

prior2<-list(G=list(G1=list(V=phen.var1/4,n=2),
                      G2=list(V=phen.var1/4,n=2)),
                      R=list(V=phen.var1/4,n=2))

bayes.global1<-MCMCglmm(cbind(crece,
R,flor,frutos)~trait+trat+trait:trat-1,random =
~us(trait):fam+us(trait):fam:trat2,
rcov = ~us(trait):units, family = c("gaussian", "gaussian","gaussian",
"poisson"),
data = na.omit(basep), prior = prior2, verbose = FALSE,singular.ok=TRUE,
nitt=13000, thin=10, burnin=3000)

This is part of the summary.


 G-structure:  ~us(trait):fam

                   post.mean   l-95% CI  u-95% CI eff.samp
crece:crece.fam    0.0043452  0.0015103 8.050e-03   1000.0
R:crece.fam       -0.0002719 -0.0014696 9.586e-04   1000.0
flor:crece.fam     0.0436852 -0.0689005 1.670e-01   1000.0
frutos:crece.fam   0.0053743 -0.0247571 4.286e-02   1000.0
etc...

    ~us(trait):fam:trat2

                         post.mean   l-95% CI  u-95% CI eff.samp
crece:crece.fam:trat2    0.0039826  0.0015898 6.967e-03    655.9
R:crece.fam:trat2       -0.0001361 -0.0010399 8.509e-04    900.4
flor:crece.fam:trat2     0.0237493 -0.0580506 1.238e-01    588.7
frutos:crece.fam:trat2   0.0046849 -0.0135320 2.080e-02   1000.0
etc...

 R-structure:  ~us(trait):units

                     post.mean  l-95% CI  u-95% CI eff.samp
crece:crece.units    0.0454059  0.038990  0.051924    848.7
R:crece.units       -0.0008172 -0.002948  0.001473   1000.0
flor:crece.units    -0.0084173 -0.201620  0.199751   1000.0
frutos:crece.units   0.0729428  0.048952  0.096300   1000.0
crece:R.units       -0.0008172 -0.002948  0.001473   1000.0


Location effects: cbind(crece, R, flor, frutos) ~ trait + trat2 +
trait:trat2 - 1

                   post.mean  l-95% CI  u-95% CI eff.samp  pMCMC
traitcrece          0.708005  0.660129  0.754760     1000 <0.001 ***
traitR              1.310004  1.287974  1.332702     1000 <0.001 ***
traitflor          56.262578 54.290430 58.332811     1000 <0.001 ***
traitfrutos         1.675350  1.189332  2.296322     1000 <0.001 ***
trat22              0.005729 -0.057418  0.058968     1000  0.810
trat23              0.014290 -0.045559  0.070862     1000  0.652
traitR:trat22      -0.134281 -0.199170 -0.061456     1421 <0.001 ***
traitflor:trat22   -3.233360 -5.507265 -0.632871     1263  0.014 *
traitfrutos:trat22  0.008789 -0.417274  0.505621     1000  0.998
traitR:trat23      -0.111668 -0.179654 -0.047945     1000 <0.001 ***
traitflor:trat23   -0.210391 -2.620701  2.472176     1000  0.912
traitfrutos:trat23 -0.145282 -0.724167  0.288831     1000  0.570

Many thanks

Muchas Gracias

	[[alternative HTML version deleted]]


From marcoplebani85 at gmail.com  Tue Aug 19 12:14:16 2014
From: marcoplebani85 at gmail.com (Marco Plebani)
Date: Tue, 19 Aug 2014 12:14:16 +0200
Subject: [R-sig-ME] Random effect variance = zero
Message-ID: <E5ED7F84-9685-49DD-A70C-36B2AE652703@gmail.com>

Dear list members,

Thank you all for the useful feedback.
For reference, here are two other recent threads closely linked to the one discussed here (i.e. https://stat.ethz.ch/pipermail/r-sig-mixed-models/2014q3/022496.html ):
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2014q3/022359.html (?Same variable as both fixed and random?)
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2014q3/022389.html (?Mixed effect models for a study with no (real)	replication?)
They sort of built up to the issue raised by Aurore.

Cheers,

Marco

-----
Marco Plebani, PhD candidate (Ecology) at the University of Zurich
Institute of Evolutionary Biology and Environmental Studies
http://www.ieu.uzh.ch/staff/phd/plebani.html
http://marcoplebani.com/


From gemma.palomar at yahoo.es  Tue Aug 19 14:51:03 2014
From: gemma.palomar at yahoo.es (=?iso-8859-1?Q?Gemma_Palomar_Garc=EDa?=)
Date: Tue, 19 Aug 2014 14:51:03 +0200
Subject: [R-sig-ME] Trivariate MCMCglmm
Message-ID: <EBEF92EC-8236-4671-AF91-D38831CA0856@yahoo.es>


Hello,

We are using MCMCglmm package with a dataset of 1063 toads. We have three different characters: infection rate, fresh body weight and development rate and we would like to infer additive variance, dominance and maternal effect which it is possible with our breeding design. We want to study heritability and genetic correlations between the characters. The three were normalized with a logarithmic transformation and block was used as random factor to control the variation caused by the position of the containers.

Inferring dominance effect, we used nadiv package to obtain dominance matrix:

library(nadiv)
pedDom=read.table("Ped_Dom.txt",header=T)
Dom<-makeD(pedDom)
Dinv=Dom$Dinv
data$dom=data$animal

The construction of the trivariate model was the following:

model3.2=MCMCglmm(cbind(Infection_rate,Weight,Developm)~trait-1, 
                  random = ~us(trait):animal+us(trait):Mother
                  +us(trait):Block+us(trait):dom,
                  rcov=~us(trait):units,
                  ginverse=list(dom=Dinv), 
                  family = c("gaussian", "gaussian","gaussian"),
                  pedigree = pedDom,data = data, nitt = 5000000, 
                  thin = 100, burnin = 5000, prior = prior3.2)

And we used this prior:

prior3.2=list(G = list(G1 = list(V = diag(3), n = 2.002),
                       G2 = list(V = diag(3), n = 2.002),
                       G3 = list(V = diag(3), n = 2.002),
                       G4 = list(V = diag(3), n = 2.002)),
              R = list(V = diag(3), n = 2.002))

We obtained very bad mixing but DIC is lower than DIC of the model without dominance. Scaling the variables doesn?t seem to improve the model. Any advice of the model or the prior will be welcome to improve the mixing. 

On the other hand, characters with high dominance effects have a change in additive effects in the model without dominance. Additive effects are highly reduced when dominance is added to the model. Is this an overestimation of the additive variance in the model without dominance caused by its lack?

Thank you,

Gemma Palomar
PhD student of University of Oviedo, Spain






	[[alternative HTML version deleted]]


From coanil at posteo.org  Tue Aug 19 17:38:42 2014
From: coanil at posteo.org (Michael Cone)
Date: Tue, 19 Aug 2014 17:38:42 +0200
Subject: [R-sig-ME] Specifying a repeated-measure design with 3 fully
 crossed within-subject factors
In-Reply-To: <6043f0e5bf9794272587cb1d975b07d5@posteo.de>
References: <6043f0e5bf9794272587cb1d975b07d5@posteo.de>
Message-ID: <99814074c6214e1d24ab8b27bd8f8e5d@posteo.de>

So, maybe I abstracted this a little bit too much. The following is an 
example I took from
Tamhane, A. C. and Hayter, A. J. (2004) Comparing Variances of Several 
Measurement Methods Using a Randomized Block Design with Repeat 
Measurements: A Case Study. In Advances in Ranking and Selection, 
Multiple Comparisons, and Reliability, Balakrishnan, N., Kannan, N. and 
Nagaraja, H. N. (Editors), Birkhauser, Boston, 165?178.

---
The insertion gain of a hearing aid is defined as the difference 
between the sound pressure level (SPL) measured at the eardrum of the 
wearer with the hearing aid in place and the SPL at the eardrum with no 
aid in place, the stimulus being the same under both conditions.

The study measured the insertion gain of a hearing aid at different 
loudspeaker locations. The standard practice was to locate the 
loadspeaker in the ear-level horizontal plane of the subject. It was 
claimed that loudspeaker locations above the horizontal plane would 
yield more precise (less variable) results.

The study compared the following loudspeaker locations:
- Location 0: 0? azimuth, 0? elevation (Standard/Control)
- Location 1: 45? azimuth, 0? elevation (New)
- Location 2: 0? azimuth, 90? elevation (New)
- Location 3: 45? azimuth 45? elevation (new)
There were 10 subjects with five replicate measurements of insertion 
gain at each of the four loudspeaker locations.
The investigator was primarily interested in comparing the 
within-subject variances for different loudspeaker locations
---

Imagine this study being conducted with 4 different kinds of auditory 
stimuli, each presented at the same combinations of azimuth and 
elevation, with replicate measurements, all presented to 5 subjects. A 
minimal reproducible example:

df <- expand.grid(meas.num = seq(1, 10),
                   elevation = c(0, 15, 30, 45, 60, 75, 90),
                   azimuth = c(0, 15, 30, 45),
                   stimuli = c("stim1", "stim2", "stim3", "stim4"),
                   subject = c("subj1", "subj2", "subj3", "subj4", 
"subj5",
                   "subj6"))
df$sex <- "m"
df[df$subject %in% c("subj1", "subj2", "subj3"), ]$sex <- "f"
df$val <- rnorm(nrow(df), mean=10, sd=5)  # dummy measurement values

Here, I would be interested in comparing
(1) the overall within-subject variances for each stimulus, as well as
(2) the within-subject variances between differing combinations of 
azimuth & elevation both within the same stimulus and between differing 
stimuli,
both within each sex and for both sexes.

I would greatly appreciate any comments, questions, or pointers in the 
right direction.

Michael


From s06mw3 at abdn.ac.uk  Wed Aug 20 12:13:18 2014
From: s06mw3 at abdn.ac.uk (Matthew Wolak)
Date: Wed, 20 Aug 2014 11:13:18 +0100
Subject: [R-sig-ME] Trivariate MCMCglmm
In-Reply-To: <EBEF92EC-8236-4671-AF91-D38831CA0856@yahoo.es>
References: <EBEF92EC-8236-4671-AF91-D38831CA0856@yahoo.es>
Message-ID: <53F474BE.6070104@abdn.ac.uk>

Dear Gemma,

I can offer a couple of quick things to check. First, do you have any inbreeding occurring in your study design? This could cause the additive effects to change depending on the presence of the dominance term in the model.

You might also want to consider a larger thinning interval. It is hard to say anything particularly useful without knowing more information or having quantitative descriptors of the model [e.g., what is the output from: autocorr(model3.2) or the effective sample sizes for each random effect?]. However, I suspect the autocorrelation between thinned samples is probably pretty high. Depending on what autocorr(model3.2) tells you, you might want to consider changing the following three arguments like so:

   nitt = 5005000, burnin = 5000, thin = 5000

It might also be hard for the model to separate dominance and maternal effects from one another, but it is hard to say without knowing more about the breeding design. In general, you could be pushing the model too hard with 3 traits, 4 random terms, and only 1063 animals. If you don't have much missing phenotypic data, univariate models might be a lot easier to start with so that you can see if dominance and/or maternal effects are even necessary to include in the trivariate model.

I was a little uncertain about your statement:

"On the other hand, characters with high dominance effects have a change in additive effects in the model without dominance. Additive effects are highly reduced when dominance is added to the model. Is this an overestimation of the additive variance in the model without dominance caused by its lack?"

To be clear, are you being careful to use precise language when talking about the individual animal effects for the additive or dominance "effects" (i.e., the model BLUPs) versus the model estimate of the variance in these effects when talking about the "additive variance"?

Sincerely,
Matthew

....................................................
Dr. Matthew E. Wolak
School of Biological Sciences
Zoology Building
University of Aberdeen
Tillydrone Avenue
Aberdeen AB24 2TZ
office phone: +44 (0)1224 273255

On 19/08/14 13:51, Gemma Palomar Garc?a wrote:


Hello,

We are using MCMCglmm package with a dataset of 1063 toads. We have three different characters: infection rate, fresh body weight and development rate and we would like to infer additive variance, dominance and maternal effect which it is possible with our breeding design. We want to study heritability and genetic correlations between the characters. The three were normalized with a logarithmic transformation and block was used as random factor to control the variation caused by the position of the containers.

Inferring dominance effect, we used nadiv package to obtain dominance matrix:

library(nadiv)
pedDom=read.table("Ped_Dom.txt",header=T)
Dom<-makeD(pedDom)
Dinv=Dom$Dinv
data$dom=data$animal

The construction of the trivariate model was the following:

model3.2=MCMCglmm(cbind(Infection_rate,Weight,Developm)~trait-1,
                  random = ~us(trait):animal+us(trait):Mother
                  +us(trait):Block+us(trait):dom,
                  rcov=~us(trait):units,
                  ginverse=list(dom=Dinv),
                  family = c("gaussian", "gaussian","gaussian"),
                  pedigree = pedDom,data = data, nitt = 5000000,
                  thin = 100, burnin = 5000, prior = prior3.2)

And we used this prior:

prior3.2=list(G = list(G1 = list(V = diag(3), n = 2.002),
                       G2 = list(V = diag(3), n = 2.002),
                       G3 = list(V = diag(3), n = 2.002),
                       G4 = list(V = diag(3), n = 2.002)),
              R = list(V = diag(3), n = 2.002))

We obtained very bad mixing but DIC is lower than DIC of the model without dominance. Scaling the variables doesn?t seem to improve the model. Any advice of the model or the prior will be welcome to improve the mixing.

On the other hand, characters with high dominance effects have a change in additive effects in the model without dominance. Additive effects are highly reduced when dominance is added to the model. Is this an overestimation of the additive variance in the model without dominance caused by its lack?

Thank you,

Gemma Palomar
PhD student of University of Oviedo, Spain






        [[alternative HTML version deleted]]





_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models




The University of Aberdeen is a charity registered in Scotland, No SC013683.
Tha Oilthigh Obar Dheathain na charthannas cl?raichte ann an Alba, ?ir. SC013683.

	[[alternative HTML version deleted]]


From roelofcoster at gmail.com  Wed Aug 20 15:09:07 2014
From: roelofcoster at gmail.com (Roelof Coster)
Date: Wed, 20 Aug 2014 15:09:07 +0200
Subject: [R-sig-ME] Model tree with random effects
Message-ID: <CAPTd6_tzQhse_Q68ZTDC1YY+r_wkoLOaUqWCOBM-C_h+Hw2bKw@mail.gmail.com>

Hello,

Is there a way to make a model tree with the inclusion of a random effect?
I am aware of REEMtree, but that package does only regression trees, not
model trees. On the other hand, there is the party package, but that one
does not include random effects.

Thanks! Roelof Coster

	[[alternative HTML version deleted]]


From s06mw3 at abdn.ac.uk  Wed Aug 20 18:13:27 2014
From: s06mw3 at abdn.ac.uk (Matthew Wolak)
Date: Wed, 20 Aug 2014 17:13:27 +0100
Subject: [R-sig-ME] Trivariate MCMCglmm
In-Reply-To: <AD88BC7D-E107-43E2-90C3-8565D81C17A3@yahoo.es>
References: <EBEF92EC-8236-4671-AF91-D38831CA0856@yahoo.es>
	<53F474BE.6070104@abdn.ac.uk>
	<AD88BC7D-E107-43E2-90C3-8565D81C17A3@yahoo.es>
Message-ID: <53F4C927.90203@abdn.ac.uk>

Hi Gemma,

(included the R-sig-ME list in reply - to keep any other interested parties in the loop)

Your type of breeding design is such that it should be able to separate dominance and maternal effects (but you probably already knew that). However, the number of female and male pairings you have might be on the lower end for the number of families (<30) necessary to disentangle additive, dominance, and maternal effects. Also, you only have 7 levels of "mother" to estimate the maternal variance, which might also be on the low side. Further, depending on how the blocking is set up in comparison to the breeding design, you might have some trouble separating the block effect from either the additive, dominance, or maternal effects. This could be compounded if the number of blocks is low (if this is really low, you could consider putting block as a fixed effect - perhaps others might have better opinions about this).

I think you might want to decide whether you are more interested in the estimation of additive, dominance, and maternal variances for each trait or you are more interested in the genetic correlation between traits. I think you will have trouble doing both. If you feel safe that your field sampling and subsequent pairing was such that you aren't mating 1st- or 2nd- order relatives in the breeding design, you can assume all individuals are outbred. In that case, genetically speaking the dominance effects won't contribute to the additive genetic variance and so a model without dominance genetic variance should still give you a decent estimate of the narrow-sense heritability (dominance variance will go into the residual variance and not additive genetic variance). However, if your statistical model isn't very good then all bets are off concerning which variance component the dominance effects will contribute to (hence, results from the statistical model might be different from what the underlying genetics are really doing - simulations could be used to investigate this, see code later on). Considerations for this latter point have to do with both the study design and your model in MCMCglmm.

To further check the MCMCglmm model, one thing is to see which variance components are hard to separate by looking at the sampling correlation among posterior samples of the variance components. A quick and dirty way to do this is simply: cor(model3.2$VCV). Variance components where you have a large absolute value for the correlation means the model might be having a hard time deciding between these two terms when it comes to partitioning the phenotypic variance.

Alternatively, since you are modeling your data as Gaussian (as long as this is an appropriate decision), have you thought or tried a REML implementation of the a mixed model (e.g., the programs WOMBAT or ASReml for an animal model OR lme4 for a non-animal model mixed model) instead of MCMCglmm? This might allow you to fiddle around with your models a little faster and keep you from worrying too much about priors, thinning intervals and model convergence, etc. (that is not to say REML animal models don't have their own issues). Also, you should be able to use a basic mixed model (i.e., something you could code in lme4 or nlme) to estimate observed variance components (maternal, paternal, maternal:paternal, and block variances) and use these to obtain estimates of the causal (genetic) variances (using the Cockerham and Weir bio-model).

If this is an experiment that you could repeat again, you might want to consider the benefit of doing another replicate (or three!). You could use some of the functions in the nadiv package to help you figure out how many more replicates would be needed to achieve what you want (or alternatively, you can do an a posteriori investigation into your data using these same functions). Below is a brief example - warning: I made a few assumptions that might not accurately reflect the way the experiment was designed. I find the following kind of code extremely helpful, because I know what the answer will be (I simulated it!) and then see if a particular study design and model can give me back the right answer! Alternatively, one can see the changes in estimates when effects are not modeled, but they do contribute to the phenotype. See below for a "simple" example.

Sincerely,
Matthew


###################################
rm(list = ls())
library(nadiv)

# 7 females each mated to 4 males, where 2 females share 2 males

# First, create the mating pairs, then use pedPrep() to create the pedigree
# Assume 38 offspring per pairing = 1064 (1063 tadpoles in the original data)
# !!****   Assume offspring from 2 males shared a block   ***!!!
fdf <- data.frame(id = as.factor(seq.int(1064)),
    dam = rep(rep(paste0("f", seq.int(7)), each = 4), each = 38),
    sire = rep(paste0("m", c(1,2,3,4,3,4,5,6,5,6,7,8,7,8,9,10,9,10,11,12,11,12,13,14,13,14,15,16)), each = 38),
    block = rep(c(1,2,2,3,3,4,4,5,5,6,6,7,7,8), each = 38*2))


# Make the pedigree
fped <- prepPed(fdf[, 1:3])

# Make the additive and dominance genetic relatedness matrices for simulation
Dout <- makeD(fped, invertD = TRUE, returnA = TRUE)
D <- Dout$D
Dinv <- Dout$Dinv # Hang on to so we can estimate Vd in MCMCglmm
A <- Dout$A
listDinv <- Dout$listDinv # Hang on to so we can estimate Vd in ASReml


# Specify the additive genetic, dominance, maternal, block, and residual variance-covariance matrices for the three traits
# Taken loosely from the output of the preliminary model (with very low ESS and high autocorrelation - so these could be WAY off!)
Ga <- matrix(c(11000, -5700, 4500,
          -5700,  7500,-2000,
           4500,  -2000, 3000), 3, 3)
Gd <- matrix(c(3000, 7000, -3500,
           7000, 38000, 500,
           -3500, 500, 24000), 3, 3)
Gm <- matrix(c(1700, 2600, 200,
        2600, 10000, 400,
        200, 400, 800), 3, 3)
Gb <- matrix(c(1200, -400, 400,
        -400, 200, -100,
        400, -100, 350), 3, 3)
Gr <- matrix(c(12300, -1000, 9000,
        -1000, 500, -500,
        9000, -500, 8000), 3, 3)

# Now, create matrices (3 columns, 1 for each trait) of random effects
add <- grfx(nrow(fped), G = Ga, incidence = A)[!is.na(fped$dam), ]
dom <- grfx(nrow(fped), G = Gd, incidence = D)[!is.na(fped$dam), ]
mat <- drfx(G = Gm, fac = "dam", dataf = fdf)$fx
blo <- drfx(G = Gb, fac = "block", dataf = fdf)$fx
res <- grfx(nrow(fped), G = Gr)[!is.na(fped$dam), ]
# Note, cov(add) should look a lot like Ga; similarly for cov(dom) and Gd

# make a matrix of trait means (taken from preliminary MCMCglmm model)
mus <- matrix(c(992.9, 992.1, 986.0), nrow = nrow(fdf), ncol = 3, byrow = TRUE)


# Now create sets of three traits that have either residual effects plus:
#     additive and block effects (ABR)
#     additive, maternal, and block effects (AMBR)
#     additive, dominance, and block effects (ADBR)
#     additive, dominance, maternal, and block effects (ADMBR)

# create temporary matrix as a placeholder
traits <- matrix(NA, nrow = nrow(fdf), ncol = 3*4)
colnames(traits) <- paste0(c("i", "w", "d"), rep(c("ABR", "AMBR", "ADBR", "ADMBR"), each = 3))
# Now, add the empty matrix to our main data frame
fdf <- cbind(fdf, traits)

# Fill in the traits with their phenotypic values (phenotype as a function of a mean + random effects
fdf[, paste0(c("i", "w", "d"), "ABR")] <- mus + add + blo + res
fdf[, paste0(c("i", "w", "d"), "AMBR")] <- mus + add + mat + blo + res
fdf[, paste0(c("i", "w", "d"), "ADBR")] <- mus + add + dom + blo + res
fdf[, paste0(c("i", "w", "d"), "ADMBR")] <- mus + add + dom + mat + blo + res


# Now, analyses can be conducted on the traits. For example, if one wants to see if additive and dominance genetic variances can be estimated then we do a model like:
#    ADBR ~ trait - 1, random = ~ us(trait):id + us(trait):idd + us(trait):block
# and perhaps compare this to a model without dominance effects (but dominance effects do contribute to the trait:
#    ADBR ~ trait - 1, random = ~ us(trait):id + us(trait):block



....................................................
Dr. Matthew E. Wolak
School of Biological Sciences
Zoology Building
University of Aberdeen
Tillydrone Avenue
Aberdeen AB24 2TZ
office phone: +44 (0)1224 273255

On 20/08/14 12:03, Gemma Palomar Garc?a wrote:
Dear Matthew,

Thank you for your reply. I explain you a little bit more about our design: we crossed 7 females with 16 males in the lab, each females was crossed with 4 males sharing 2 males with the next female. At the end each female was crossed with 4 males and each male with 2 females. We obtained 1063 tadpoles. Females and Males were adults sampled in the field, therefore, the inbreeding possibility is very low. Do you think that this design is enough to separate dominance and maternal effects?

As you suspect, autocorrelation is high and effective sample size is low in some random factors, I attach the summary of the model.
I also did univariate models and I obtained better autocorrelation and effective sample size. Univariate models with all the random factors (i.e. dominance and maternal effect) also had low DIC. However, I would like to obtain genetic correlation so at least I need bivariate models.

I will try to explain better about additive variance and dominance. The model without dominance as random effect (only animal, maternal and block) had high heritability for weight and development rate and the model with all the random effects (animal, maternal, dominance and block) has low heritability but high dominance for these traits. There is a big change in the estimation of the additive variance between the two models.

I am going to try with larger thinning interval, thank you. If you have any other suggestion I will be pleased to try it.

Best,

Gemma Palomar









El 20/08/2014, a las 12:13, Matthew Wolak <s06mw3 at abdn.ac.uk<mailto:s06mw3 at abdn.ac.uk>> escribi?:

Dear Gemma,

I can offer a couple of quick things to check. First, do you have any inbreeding occurring in your study design? This could cause the additive effects to change depending on the presence of the dominance term in the model.

You might also want to consider a larger thinning interval. It is hard to say anything particularly useful without knowing more information or having quantitative descriptors of the model [e.g., what is the output from: autocorr(model3.2) or the effective sample sizes for each random effect?]. However, I suspect the autocorrelation between thinned samples is probably pretty high. Depending on what autocorr(model3.2) tells you, you might want to consider changing the following three arguments like so:

   nitt = 5005000, burnin = 5000, thin = 5000

It might also be hard for the model to separate dominance and maternal effects from one another, but it is hard to say without knowing more about the breeding design. In general, you could be pushing the model too hard with 3 traits, 4 random terms, and only 1063 animals. If you don't have much missing phenotypic data, univariate models might be a lot easier to start with so that you can see if dominance and/or maternal effects are even necessary to include in the trivariate model.

I was a little uncertain about your statement:

"On the other hand, characters with high dominance effects have a change in additive effects in the model without dominance. Additive effects are highly reduced when dominance is added to the model. Is this an overestimation of the additive variance in the model without dominance caused by its lack?"

To be clear, are you being careful to use precise language when talking about the individual animal effects for the additive or dominance "effects" (i.e., the model BLUPs) versus the model estimate of the variance in these effects when talking about the "additive variance"?

Sincerely,
Matthew

....................................................
Dr. Matthew E. Wolak
School of Biological Sciences
Zoology Building
University of Aberdeen
Tillydrone Avenue
Aberdeen AB24 2TZ
office phone: +44 (0)1224 273255

On 19/08/14 13:51, Gemma Palomar Garc?a wrote:

Hello,

We are using MCMCglmm package with a dataset of 1063 toads. We have three different characters: infection rate, fresh body weight and development rate and we would like to infer additive variance, dominance and maternal effect which it is possible with our breeding design. We want to study heritability and genetic correlations between the characters. The three were normalized with a logarithmic transformation and block was used as random factor to control the variation caused by the position of the containers.

Inferring dominance effect, we used nadiv package to obtain dominance matrix:

library(nadiv)
pedDom=read.table("Ped_Dom.txt",header=T)
Dom<-makeD(pedDom)
Dinv=Dom$Dinv
data$dom=data$animal

The construction of the trivariate model was the following:

model3.2=MCMCglmm(cbind(Infection_rate,Weight,Developm)~trait-1,
                  random = ~us(trait):animal+us(trait):Mother
                  +us(trait):Block+us(trait):dom,
                  rcov=~us(trait):units,
                  ginverse=list(dom=Dinv),
                  family = c("gaussian", "gaussian","gaussian"),
                  pedigree = pedDom,data = data, nitt = 5000000,
                  thin = 100, burnin = 5000, prior = prior3.2)

And we used this prior:

prior3.2=list(G = list(G1 = list(V = diag(3), n = 2.002),
                       G2 = list(V = diag(3), n = 2.002),
                       G3 = list(V = diag(3), n = 2.002),
                       G4 = list(V = diag(3), n = 2.002)),
              R = list(V = diag(3), n = 2.002))

We obtained very bad mixing but DIC is lower than DIC of the model without dominance. Scaling the variables doesn?t seem to improve the model. Any advice of the model or the prior will be welcome to improve the mixing.

On the other hand, characters with high dominance effects have a change in additive effects in the model without dominance. Additive effects are highly reduced when dominance is added to the model. Is this an overestimation of the additive variance in the model without dominance caused by its lack?

Thank you,

Gemma Palomar
PhD student of University of Oviedo, Spain






        [[alternative HTML version deleted]]





_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models




The University of Aberdeen is a charity registered in Scotland, No SC013683.
Tha Oilthigh Obar Dheathain na charthannas cl?raichte ann an Alba, ?ir. SC013683.




The University of Aberdeen is a charity registered in Scotland, No SC013683.
Tha Oilthigh Obar Dheathain na charthannas cl?raichte ann an Alba, ?ir. SC013683.

	[[alternative HTML version deleted]]


From ukoether at uke.de  Wed Aug 20 19:30:30 2014
From: ukoether at uke.de (=?UTF-8?B?VWxmIEvDtnRoZXI=?=)
Date: Wed, 20 Aug 2014 19:30:30 +0200
Subject: [R-sig-ME] Getting intraclass correlations from a binomial mixed
 model with logit link
Message-ID: <53F4DB36.8010506@uke.de>

Dear list members,

I am asking you for help on interpretating the random effects from a
binomial model (strictly 0-1 responses) with a logit link:

Random effects:
 Groups                     Name        Variance Std.Dev.
 ID                         (Intercept) 0.1475   0.3840  
 Item:Emotion               (Intercept) 2.7546   1.6597  
 Emotion                    (Intercept) 0.6822   0.8259  
Number of obs: 4788, groups:  ID, 114; Item:Emotion, 42; Emotion, 7


I would like to get an ICC for each random intercept, but there are some
conceptional problems here I cannot solve yet:

1.) ID and Item are completely crossed random effects, but Items are
nested within Emotion, so I do not know if I just can get an ICC for
each variance component via

sigma-ID^2 / (sigma-ID^2 + sigma-Item:Emotion^2 + sigma-Emotion^2 +
(pi^2/3))

with pi^2/3 as the "residual variance"-equivalent term for a binomial
logit model. The variance parts for the other random intercepts would be
calculated accordingly.

I read the Papers from Goldstein (2002) and Browne (2005) about
partitioning the variance but did not find any concrete hints about such
a model which consists of crossed and nested random effects.

2.) As a side question, I would like to know if one can get these ICCs
(if it is possible to get in the first place) on the probability scale
and not on the logit scale as presented in the model output? I assume
that just applying the inverse link function on the ICC would be no good
idea, but this is just a feeling... Does anyone know, why that is wrong?

Thanks for your help,

kind regards, Ulf

-- 
________________________________________

Dipl.-Psych. Ulf K?ther

PEPP-Team 
Klinik f?r Psychiatrie und Psychotherapie
Universit?tsklinikum Hamburg-Eppendorf
Martinistr. 52
20246 Hamburg

PEPP-Team:
Tel.: +49 (0) 40 7410 53248
pepp at uke.de

Pers?nlich:
Tel.: +49 (0) 40 7410 55851
Mobil: (9) 55851
ukoether at uke.de
________________________________________

--

DANKE F?R 125 JAHRE ENGAGEMENT UND VERTRAUEN.
www.uke.de/125
_____________________________________________________________________

Besuchen Sie uns auf: www.uke.de
_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg
Vorstandsmitglieder: Prof. Dr. Christian Gerloff (Vertreter des Vorsitzenden), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Rainer Schoppik
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed Aug 20 21:28:17 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 20 Aug 2014 11:28:17 -0800
Subject: [R-sig-ME] [Lme4-authors] installing 1.1-7
In-Reply-To: <814C875B0EFFDF48A761B449E5EF9C9407FA3483@EX2010-MBX2.ds.strath.ac.uk>
References: <814C875B0EFFDF48A761B449E5EF9C9407FA3391@EX2010-MBX2.ds.strath.ac.uk>
	<814C875B0EFFDF48A761B449E5EF9C9407FA33EF@EX2010-MBX2.ds.strath.ac.uk>
	<CABghstQkzqbrOT-6Ypf8ZtA+TSj_WS_tbWJ+9yruEuC4rZ9CUA@mail.gmail.com>
	<814C875B0EFFDF48A761B449E5EF9C9407FA3483@EX2010-MBX2.ds.strath.ac.uk>
Message-ID: <CABghstS00hDS_UTj6pyfHnDsZZu_jyJxKWtLed9uzVvrvezO7Q@mail.gmail.com>

[taking the liberty of cc'ing this to r-sig-mixed-models]

 Have you tried

install.packages("optextras",
repos="http://R-Forge.R-project.org",type="source")
?

(this may require you to go further down the rabbit hole and install
compilation tools, see the R FAQ for your operating system ...)



On Wed, Aug 20, 2014 at 11:10 AM, Kumiko Fukumura <
kumiko.fukumura at strath.ac.uk> wrote:

> Thank you very much for your reply.  I've just used the following:
>
>
>
> > install.packages("lme4",
> +    repos=c("http://lme4.r-forge.r-project.org/repos",
> +           getOption("repos")[["CRAN"]]))
>
>
>
> And the programme seems to be working, though I'm not entirely sure if
> this is the 1.1-7 (it says "lme4" but not "lme.1.1.-7").
>

  packageVersion("lme4")  should tell you what you have (or sessionInfo())

>
>
>
> Also, having separately installed "optimx", I still cannot use the
> optimiser, and got a message that I now need to install "optextras". So I
> tried the folllwing:
>
>
  Can you be a little bit more specific about what you're trying to do?
For basic use of lme4 you shouldn't need optimx ...



>
> install.packages("optextras", repos="http://R-Forge.R-project.org")
>
>
>
> But I got a message that says:  "package ?optextras? is available as a
> source package but not as a binary
>
> Warning message: package ?optextras? is not available (for R version
> 3.1.1)"
>
>
>
> Could you perhaps please give me an advice where I could find an
> appropriate "optextras"?
>
>
>
> Many thanks,
>
>
>
> Kumiko
>
>
>
> ________________________________
> From: Ben Bolker [bbolker at gmail.com]
> Sent: 20 August 2014 19:25
> To: Kumiko Fukumura
> Cc: lme4-authors at lists.r-forge.r-project.org
> Subject: Re: [Lme4-authors] installing 1.1-7
>
>   Copying lme4 into the library folder is probably not the best way to
> install a package.
>
> If you install.packages("lme4"), R should automatically detect and install
> dependencies for you.
>
>   It does look like minqa is up to data/available:
>
> http://cran.us.r-project.org/web/packages/minqa/index.html
>
> On Wed, Aug 20, 2014 at 7:22 AM, Kumiko Fukumura <
> kumiko.fukumura at strath.ac.uk<mailto:kumiko.fukumura at strath.ac.uk>> wrote:
> Hi there,
>
>
>
> I'm trying to install lme4.1.1-7.  I've been using a very old R (R
> 2.14.1), so I installed a newer version of R (3.1.1).
>
>
>
> Then I downloaded lme4.1.1-7 from https://github.com/lme4/lme4/releases
> and copied it into the library folder in R.
>
>
>
> When I ran "library(lme4)", I get the following error message.
>
>
>
> Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck
> = vI[[j]]) :
>   there is no package called ?minqa?
> Error: package or namespace load failed for ?lme4?
>
>
>
> I seem to be missing something critical, but I have no clue.  I've also
> tried to use the newer version of lme4 in R 2.15.0, 2.15.1, 2.15.2, but
> have been unsuccessful (it has been hard to find the right version of other
> components).
>
>
>
> It'd be very helpful if you could give me some guidance.
>
>
>
> Best wishes
>
>
>
> Kumiko
>
>
>
>
>
>
>
>
> _______________________________________________
> Lme4-authors mailing list
> Lme4-authors at lists.r-forge.r-project.org<mailto:
> Lme4-authors at lists.r-forge.r-project.org>
> https://lists.r-forge.r-project.org/cgi-bin/mailman/listinfo/lme4-authors
>
>

	[[alternative HTML version deleted]]


From jake987722 at hotmail.com  Wed Aug 20 21:30:43 2014
From: jake987722 at hotmail.com (Jake Westfall)
Date: Wed, 20 Aug 2014 13:30:43 -0600
Subject: [R-sig-ME] Getting intraclass correlations from a binomial
 mixed model with logit link
In-Reply-To: <53F4DB36.8010506@uke.de>
References: <53F4DB36.8010506@uke.de>
Message-ID: <BAY172-W527E2CCAF9327B92957264CBD20@phx.gbl>

Hi Ulf,

1. You can compute the following intraclass correlations. Let S (short for Subject) be the ID random intercept variance, I be the Item:Emotion random intercept variance, and E be the Emotion random intercept variance.


Correlation between responses with same Emotion, different Items, different IDs:
E / (S + I + E + pi^2/3)

Correlation between responses with same Emotion, same Items, different IDs:
(E + I) / (S + I + E + pi^2/3)

Correlation between responses with different Emotions, different Items, same IDs:
S / (S + I + E + pi^2/3)

Correlation between responses with same Emotions, different Items, same IDs:
(S + E) / (S + I + E + pi^2/3)

Correlation between responses with same Emotions, same Items, same IDs:
(S + I + E) / (S + I + E + pi^2/3)

2. The ICCs above are based on taking a latent variable view of the model. That is, we assume the responses arise from an underlying latent variable with a logistic distribution, and this logistic variable gets dichotomized around some threshold, so that we observe 0 below the threshold and 1 above the threshold. The ICCs above estimate various expected correlations in the value of this latent logistic variable. 

As hinted above, the intraclass correlation coefficient is, well, a bona fide correlation coefficient. So taking the inverse logit of a correlation doesn't really make sense.

The latent variable approach is nice because we don't have to specify a particular value of the predictor at which to assess the ICC. If you just want to talk about correlations involving the actually observed binary variable, with no latent variable baggage, you can do that, but you have to specify the expected value of Y that you're interested in (e.g., specify the values of all the predictors). That's because the variance of a binary variable depends on the mean, so accordingly the ICC is different for different expected Y values. In my opinion the notion of ICC loses its usefulness and intuitive appeal in this context. But if you want to compute it anyway, you can follow the simulation advice offered by Goldstein, Browne, & Rasbash, 2002, section 3.2.

http://www.bris.ac.uk/cmm/research/pvmm.pdf

Jake

> Date: Wed, 20 Aug 2014 19:30:30 +0200
> From: ukoether at uke.de
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Getting intraclass correlations from a binomial mixed model with logit link
> 
> Dear list members,
> 
> I am asking you for help on interpretating the random effects from a
> binomial model (strictly 0-1 responses) with a logit link:
> 
> Random effects:
>  Groups                     Name        Variance Std.Dev.
>  ID                         (Intercept) 0.1475   0.3840  
>  Item:Emotion               (Intercept) 2.7546   1.6597  
>  Emotion                    (Intercept) 0.6822   0.8259  
> Number of obs: 4788, groups:  ID, 114; Item:Emotion, 42; Emotion, 7
> 
> 
> I would like to get an ICC for each random intercept, but there are some
> conceptional problems here I cannot solve yet:
> 
> 1.) ID and Item are completely crossed random effects, but Items are
> nested within Emotion, so I do not know if I just can get an ICC for
> each variance component via
> 
> sigma-ID^2 / (sigma-ID^2 + sigma-Item:Emotion^2 + sigma-Emotion^2 +
> (pi^2/3))
> 
> with pi^2/3 as the "residual variance"-equivalent term for a binomial
> logit model. The variance parts for the other random intercepts would be
> calculated accordingly.
> 
> I read the Papers from Goldstein (2002) and Browne (2005) about
> partitioning the variance but did not find any concrete hints about such
> a model which consists of crossed and nested random effects.
> 
> 2.) As a side question, I would like to know if one can get these ICCs
> (if it is possible to get in the first place) on the probability scale
> and not on the logit scale as presented in the model output? I assume
> that just applying the inverse link function on the ICC would be no good
> idea, but this is just a feeling... Does anyone know, why that is wrong?
> 
> Thanks for your help,
> 
> kind regards, Ulf
> 
> -- 
> ________________________________________
> 
> Dipl.-Psych. Ulf K?ther
> 
> PEPP-Team 
> Klinik f?r Psychiatrie und Psychotherapie
> Universit?tsklinikum Hamburg-Eppendorf
> Martinistr. 52
> 20246 Hamburg
> 
> PEPP-Team:
> Tel.: +49 (0) 40 7410 53248
> pepp at uke.de
> 
> Pers?nlich:
> Tel.: +49 (0) 40 7410 55851
> Mobil: (9) 55851
> ukoether at uke.de
> ________________________________________
> 
> --
> 
> DANKE F?R 125 JAHRE ENGAGEMENT UND VERTRAUEN.
> www.uke.de/125
> _____________________________________________________________________
> 
> Besuchen Sie uns auf: www.uke.de
> _____________________________________________________________________
> 
> Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg
> Vorstandsmitglieder: Prof. Dr. Christian Gerloff (Vertreter des Vorsitzenden), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Rainer Schoppik
> _____________________________________________________________________
> 
> SAVE PAPER - THINK BEFORE PRINTING
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
 		 	   		  
	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed Aug 20 21:38:39 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 20 Aug 2014 11:38:39 -0800
Subject: [R-sig-ME] (no subject)
In-Reply-To: <CAHAAfB98iJOztJbFzqDXpJSyCFzyc7W0N6N5Si8mVh7kXReohQ@mail.gmail.com>
References: <CAHAAfB98iJOztJbFzqDXpJSyCFzyc7W0N6N5Si8mVh7kXReohQ@mail.gmail.com>
Message-ID: <CABghstQgocGcOggHH5hQkB3OGc+uRv=XvdgcH9DFnhAtRpmtgg@mail.gmail.com>

 You could mean one of two things: (1, less likely) you have multiple cages
(blocks) in your experiment -- provided you have a reasonable (>5?) number
of cages, you could add Cage as a random effect; (2, more likely) if there
is a difference between uncaged and caged controls, add Cage as a fixed
effect.

  hard to say a lot more without more details of your experimental design.



On Mon, Aug 18, 2014 at 4:49 AM, Richa Bharti <richabharti74 at gmail.com>
wrote:

> Dear All,
>
> I have Cage effect in my data and would like to remove this effect for
> further analysis, do anyone know how to over come from this effect with
> lmer model.
>
> Looking forward for reply!!
>
>
> *
> <
> http://www.jnu.ac.in/main.asp?sendval=SchoolOfComputationalandIntegrativeSciences
> >*
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From jake987722 at hotmail.com  Wed Aug 20 22:13:17 2014
From: jake987722 at hotmail.com (Jake Westfall)
Date: Wed, 20 Aug 2014 14:13:17 -0600
Subject: [R-sig-ME] Getting intraclass correlations from a binomial
 mixed model with logit link
In-Reply-To: <53F4FDA5.2010002@uke.de>
References: <53F4DB36.8010506@uke.de>
	<BAY172-W527E2CCAF9327B92957264CBD20@phx.gbl>, <53F4FDA5.2010002@uke.de>
Message-ID: <BAY172-W33D89D67D63A2493D41890CBD20@phx.gbl>

Ulf,

More or less yes, but two things are worth emphasizing. First, although it is possible to construct a ratio like I / (S + I + E + pi^2/3) -- which you'll notice I did not put in my list -- I think the interpretation of this ratio would be dubious. It is tempting to say that it is the correlation for responses with the same Items, different Emotions, different Subjects. But note that you never actually observed any Items with more than one Emotion, so it's not totally clear that such a leap is warranted. Indeed, for this particular example (I guess these are items on a questionnaire of some kind), even the conceptual meaning of such a correlation is dubious, since it's not clear how the Items could be associated with different Emotions (although in other contexts this might not be hard to imagine). Second, all of this only works as long as there are only random intercepts in the model. As soon as there are random slopes as well, then everything becomes far more complicated and confusing and I basically would recommend not reporting ICCs in those cases.

Jake

Date: Wed, 20 Aug 2014 21:57:25 +0200
From: ukoether at uke.de
To: jake987722 at hotmail.com
Subject: Re: [R-sig-ME] Getting intraclass correlations from a binomial mixed model with logit link


  
    
  
  
    Dear Jake,

    

    thank you for the great answer! So, all in all, it is just as in the
    strictly nested random effects case and one has not to worry about
    mixing crossed and nested effects if I am understanding everything
    correctly. Nice!

    

    Regarding changing to a "manifest" variable instead of the latent
    variable view, that seems now clear to me. 

    

    To follow up on this for others who might be interested:

    Another paper addressing this issue seems to Rodriguez & Elo
    (2003), "Intra-class correlation in random-effects models for binary
    data", The Stata Journal, who also give functions in Stata to
    estimate the manifest ICC (thanks to Ben Pelzer for the hint). 

    One more paper that I found right after mailing to the list, is
    Nakagawa & Schielzeth (2010). "Repeatability for Gaussian and
    non-Gaussian

    data: a practical guide for biologists", Biological Reviews, who
    also wrote an R-package for this, "rptR"...

    

    Thanks again!

    

    Am 20.08.2014 um 21:30 schrieb Jake
      Westfall:

    
    
      Hi Ulf,

1. You can compute the following intraclass correlations. Let S (short for Subject) be the ID random intercept variance, I be the Item:Emotion random intercept variance, and E be the Emotion random intercept variance.


Correlation between responses with same Emotion, different Items, different IDs:
E / (S + I + E + pi^2/3)

Correlation between responses with same Emotion, same Items, different IDs:
(E + I) / (S + I + E + pi^2/3)

Correlation between responses with different Emotions, different Items, same IDs:
S / (S + I + E + pi^2/3)

Correlation between responses with same Emotions, different Items, same IDs:
(S + E) / (S + I + E + pi^2/3)

Correlation between responses with same Emotions, same Items, same IDs:
(S + I + E) / (S + I + E + pi^2/3)

2. The ICCs above are based on taking a latent variable view of the model. That is, we assume the responses arise from an underlying latent variable with a logistic distribution, and this logistic variable gets dichotomized around some threshold, so that we observe 0 below the threshold and 1 above the threshold. The ICCs above estimate various expected correlations in the value of this latent logistic variable. 

As hinted above, the intraclass correlation coefficient is, well, a bona fide correlation coefficient. So taking the inverse logit of a correlation doesn't really make sense.

The latent variable approach is nice because we don't have to specify a particular value of the predictor at which to assess the ICC. If you just want to talk about correlations involving the actually observed binary variable, with no latent variable baggage, you can do that, but you have to specify the expected value of Y that you're interested in (e.g., specify the values of all the predictors). That's because the variance of a binary variable depends on the mean, so accordingly the ICC is different for different expected Y values. In my opinion the notion of ICC loses its usefulness and intuitive appeal in this context. But if you want to compute it anyway, you can follow the simulation advice offered by Goldstein, Browne, & Rasbash, 2002, section 3.2.

http://www.bris.ac.uk/cmm/research/pvmm.pdf

Jake


      
        Date: Wed, 20 Aug 2014 19:30:30 +0200
From: ukoether at uke.de
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Getting intraclass correlations from a binomial mixed model with logit link

Dear list members,

I am asking you for help on interpretating the random effects from a
binomial model (strictly 0-1 responses) with a logit link:

Random effects:
 Groups                     Name        Variance Std.Dev.
 ID                         (Intercept) 0.1475   0.3840  
 Item:Emotion               (Intercept) 2.7546   1.6597  
 Emotion                    (Intercept) 0.6822   0.8259  
Number of obs: 4788, groups:  ID, 114; Item:Emotion, 42; Emotion, 7


I would like to get an ICC for each random intercept, but there are some
conceptional problems here I cannot solve yet:

1.) ID and Item are completely crossed random effects, but Items are
nested within Emotion, so I do not know if I just can get an ICC for
each variance component via

sigma-ID^2 / (sigma-ID^2 + sigma-Item:Emotion^2 + sigma-Emotion^2 +
(pi^2/3))

with pi^2/3 as the "residual variance"-equivalent term for a binomial
logit model. The variance parts for the other random intercepts would be
calculated accordingly.

I read the Papers from Goldstein (2002) and Browne (2005) about
partitioning the variance but did not find any concrete hints about such
a model which consists of crossed and nested random effects.

2.) As a side question, I would like to know if one can get these ICCs
(if it is possible to get in the first place) on the probability scale
and not on the logit scale as presented in the model output? I assume
that just applying the inverse link function on the ICC would be no good
idea, but this is just a feeling... Does anyone know, why that is wrong?

Thanks for your help,

kind regards, Ulf

-- 
________________________________________

Dipl.-Psych. Ulf K?ther

PEPP-Team 
Klinik f?r Psychiatrie und Psychotherapie
Universit?tsklinikum Hamburg-Eppendorf
Martinistr. 52
20246 Hamburg

PEPP-Team:
Tel.: +49 (0) 40 7410 53248
pepp at uke.de

Pers?nlich:
Tel.: +49 (0) 40 7410 55851
Mobil: (9) 55851
ukoether at uke.de
________________________________________

--

DANKE F?R 125 JAHRE ENGAGEMENT UND VERTRAUEN.
www.uke.de/125
_____________________________________________________________________

Besuchen Sie uns auf: www.uke.de
_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg
Vorstandsmitglieder: Prof. Dr. Christian Gerloff (Vertreter des Vorsitzenden), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Rainer Schoppik
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

      
       		 	   		  
	[[alternative HTML version deleted]]


      

      
      

      _______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

    
    

    -- 
________________________________________

Dipl.-Psych. Ulf K?ther

PEPP-Team 
Klinik f?r Psychiatrie und Psychotherapie
Universit?tsklinikum Hamburg-Eppendorf
Martinistr. 52
20246 Hamburg

PEPP-Team:
Tel.: +49 (0) 40 7410 53248
pepp at uke.de

Pers?nlich:
Tel.: +49 (0) 40 7410 55851
Mobil: (9) 55851
ukoether at uke.de
________________________________________
  

DANKE F?R 125 JAHRE ENGAGEMENT UND VERTRAUEN.

www.uke.de/125
Besuchen Sie uns auf: www.uke.de

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg

Vorstandsmitglieder: Prof. Dr. Christian Gerloff (Vertreter des Vorsitzenden), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Rainer Schoppik

SAVE PAPER - THINK BEFORE PRINTING 		 	   		  
	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed Aug 20 23:52:49 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 20 Aug 2014 13:52:49 -0800
Subject: [R-sig-ME] GlMM for ordinal and pseudo replication
In-Reply-To: <CADGhagh9Cjz6YUjFSmYQRu+nAWnc4qVOOHyg6nji2Mebzb42XA@mail.gmail.com>
References: <CADGhaggs2FvpjPe_s-+qH0CWnemyJYNWqxFDbD=MiLKXUhA8kg@mail.gmail.com>
	<CABghstRDx+MrRkTHROO-iriKVP353uuN2jS1AQ6YrqB09au1HQ@mail.gmail.com>
	<CADGhagh9Cjz6YUjFSmYQRu+nAWnc4qVOOHyg6nji2Mebzb42XA@mail.gmail.com>
Message-ID: <CABghstT54Xs00G2dAHne8eSQkPR5CKBJ7uyEQND+rA1eH-LR-g@mail.gmail.com>

   As I said, I think the ordinal package would serve you well.

   If you have *more specific* questions about your analysis, you can ask
on the r-sig-mixed-models at r-project.org mailing list.

  sincerely
    Ben Bolker



On Wed, Aug 20, 2014 at 11:54 AM, Mehdi Abedi <abedimail at gmail.com> wrote:

> Dear Ben,
> Thanks for your guidance. I know just multinominal package. I am not still
> sure which model fit to this kind of  ordinal data with pseudo replication.
> All the best,
> Mehdi
>
>
> On Thu, Aug 21, 2014 at 12:16 AM, Ben Bolker <bbolker at gmail.com> wrote:
>
>> Please send questions to r-sig-mixed-models at r-project.org wherever
>> possible (although I'm not 100% sure which attachments will make it to the
>> list -- I think CSV might be OK).  Have you looked at the very fine ordinal
>> package on CRAN?
>>
>>   cheers
>>     Ben Bolker
>>
>>
>>
>> On Wed, Aug 20, 2014 at 11:02 AM, Mehdi Abedi <abedimail at gmail.com>
>> wrote:
>>
>>> Dear Ben,
>>> I searched in lme4 package, however, i couldn't find solution yet.
>>> I want to compare 11 soil surface indicators among different treatments.
>>> Data are ordinal from 0-5. In addition i have pseudo replication.
>>> Can i do glm with family of binomial here? or mixed model of treatments
>>> and species?!
>>>
>>> Warm regards
>>> Mehdi
>>>
>>> --
>>>
>>>
>>> *Mehdi Abedi Department of Range Management*
>>>
>>> *Faculty of Natural Resources & Marine Sciences *
>>>
>>> *Tarbiat Modares University (TMU) *
>>>
>>> *46417-76489, Noor*
>>>
>>> *Mazandaran, IRAN *
>>>
>>> *mehdi.abedi at modares.ac.ir <Mehdi.abedi at tmu.ac.ir>*
>>>
>>> *Homepage
>>> <http://www.modares.ac.ir/en/Schools/nat/Academic_Staff/~mehdi.abedi>*
>>>
>>> *Tel: +98-122-6253101 <%2B98-122-6253101> *
>>>
>>> *Fax: +98-122-6253499 <%2B98-122-6253499>*
>>>
>>
>>
>
>
> --
>
>
> *Mehdi Abedi Department of Range Management*
>
> *Faculty of Natural Resources & Marine Sciences *
>
> *Tarbiat Modares University (TMU) *
>
> *46417-76489, Noor*
>
> *Mazandaran, IRAN *
>
> *mehdi.abedi at modares.ac.ir <Mehdi.abedi at tmu.ac.ir>*
>
> *Homepage
> <http://www.modares.ac.ir/en/Schools/nat/Academic_Staff/~mehdi.abedi>*
>
> *Tel: +98-122-6253101 <%2B98-122-6253101> *
>
> *Fax: +98-122-6253499 <%2B98-122-6253499>*
>

	[[alternative HTML version deleted]]


From m.niu at imperial.ac.uk  Thu Aug 21 10:42:01 2014
From: m.niu at imperial.ac.uk (Niu, Mu)
Date: Thu, 21 Aug 2014 08:42:01 +0000
Subject: [R-sig-ME] question about lme4 and nlme
Message-ID: <3A83E1FED93C4446AF8BD7C32B3B05570D4397FB@icexch-m6.ic.ac.uk>


Dear Prof Bolker

I am a post-doc from school of public health at imperial college london. I would like to use lme4 and nlme package do some statistical gentics work. I got some problem when I run my lme model.

I would like use the fixed effect model with fixed weights on variance. Can I use random effect random= (~1|family) and weights = varIdent(fix=c(het=2), form = ~ 1 | categories)) at the same time?

As a example, I have n patients, their weights  are the dependent variable, my fixed effect model is
    modelN <- try(lme(Weight ~ fixeEffect, random=(~1|family), data=sim, method="REML", na.action=na.omit), silent=T)

because we have the genotype of patients, we categorized the patients into two group (homo , hete) based their gene expression, and we assume the patient in hete group should have twice bigger variance as homo group. we use varIdent function to present our assumption. Is the syntax right?
modelF <- try(lme(Weight ~ fixeEffect, random= (~1|family), data=sim, method="REML", na.action=na.omit, weights = varIdent(fix=c(het=2), form = ~ 1 | categories)), silent=T)

However,if we do not include sibling into our data and only use one member of the family, (the covariance matrix is diagonal), modelF is better modelN. If we include the sibling data and we have two member from each family( the covariance matrix become block diagonal) , modelF is not better than modelN. I do not know why more information about the family make the model fail?
Thank you very much for your help

Regards
Mu Niu




	[[alternative HTML version deleted]]


From gemma.palomar at yahoo.es  Thu Aug 21 15:35:18 2014
From: gemma.palomar at yahoo.es (=?iso-8859-1?Q?Gemma_Palomar_Garc=EDa?=)
Date: Thu, 21 Aug 2014 15:35:18 +0200
Subject: [R-sig-ME] Trivariate MCMCglmm
In-Reply-To: <53F4C927.90203@abdn.ac.uk>
References: <EBEF92EC-8236-4671-AF91-D38831CA0856@yahoo.es>
	<53F474BE.6070104@abdn.ac.uk>
	<AD88BC7D-E107-43E2-90C3-8565D81C17A3@yahoo.es>
	<53F4C927.90203@abdn.ac.uk>
Message-ID: <2D978C50-1763-4C8F-8566-4B6706D6A90B@yahoo.es>

Hi Matthew,

Thank you, your comments and suggestions have been really helpful. You have clarified me a lot of concepts and I am very grateful. We will try different approaches and we will see what fits better at the end. 
We tried with lmer in lme4 package and these models didn?t fit totally with univariate models of MCMCglmm, what reminds me a question: What about fully crossed random factors in lmer? Some ?mixed model experts" told me that lmer can only be run with fully crossed random factors and all mothers are not crossed with all fathers, do you think this can be a problem?
I will download WOMBAT and try with it.

Thank you again,

Gemma Palomar

PhD student, University of Oviedo, Spain



El 20/08/2014, a las 18:13, Matthew Wolak <s06mw3 at abdn.ac.uk> escribi?:

> Hi Gemma,
> 
> (included the R-sig-ME list in reply - to keep any other interested parties in the loop)
> 
> Your type of breeding design is such that it should be able to separate dominance and maternal effects (but you probably already knew that). However, the number of female and male pairings you have might be on the lower end for the number of families (<30) necessary to disentangle additive, dominance, and maternal effects. Also, you only have 7 levels of "mother" to estimate the maternal variance, which might also be on the low side. Further, depending on how the blocking is set up in comparison to the breeding design, you might have some trouble separating the block effect from either the additive, dominance, or maternal effects. This could be compounded if the number of blocks is low (if this is really low, you could consider putting block as a fixed effect - perhaps others might have better opinions about this).
> 
> I think you might want to decide whether you are more interested in the estimation of additive, dominance, and maternal variances for each trait or you are more interested in the genetic correlation between traits. I think you will have trouble doing both. If you feel safe that your field sampling and subsequent pairing was such that you aren't mating 1st- or 2nd- order relatives in the breeding design, you can assume all individuals are outbred. In that case, genetically speaking the dominance effects won't contribute to the additive genetic variance and so a model without dominance genetic variance should still give you a decent estimate of the narrow-sense heritability (dominance variance will go into the residual variance and not additive genetic variance). However, if your statistical model isn't very good then all bets are off concerning which variance component the dominance effects will contribute to (hence, results from the statistical model might be different from what the underlying genetics are really doing - simulations could be used to investigate this, see code later on). Considerations for this latter point have to do with both the study design and your model in MCMCglmm. 
> 
> To further check the MCMCglmm model, one thing is to see which variance components are hard to separate by looking at the sampling correlation among posterior samples of the variance components. A quick and dirty way to do this is simply: cor(model3.2$VCV). Variance components where you have a large absolute value for the correlation means the model might be having a hard time deciding between these two terms when it comes to partitioning the phenotypic variance. 
> 
> Alternatively, since you are modeling your data as Gaussian (as long as this is an appropriate decision), have you thought or tried a REML implementation of the a mixed model (e.g., the programs WOMBAT or ASReml for an animal model OR lme4 for a non-animal model mixed model) instead of MCMCglmm? This might allow you to fiddle around with your models a little faster and keep you from worrying too much about priors, thinning intervals and model convergence, etc. (that is not to say REML animal models don't have their own issues). Also, you should be able to use a basic mixed model (i.e., something you could code in lme4 or nlme) to estimate observed variance components (maternal, paternal, maternal:paternal, and block variances) and use these to obtain estimates of the causal (genetic) variances (using the Cockerham and Weir bio-model).
> 
> If this is an experiment that you could repeat again, you might want to consider the benefit of doing another replicate (or three!). You could use some of the functions in the nadiv package to help you figure out how many more replicates would be needed to achieve what you want (or alternatively, you can do an a posteriori investigation into your data using these same functions). Below is a brief example - warning: I made a few assumptions that might not accurately reflect the way the experiment was designed. I find the following kind of code extremely helpful, because I know what the answer will be (I simulated it!) and then see if a particular study design and model can give me back the right answer! Alternatively, one can see the changes in estimates when effects are not modeled, but they do contribute to the phenotype. See below for a "simple" example.
> 
> Sincerely,
> Matthew
> 
> 
> ###################################
> rm(list = ls())
> library(nadiv)
> 
> # 7 females each mated to 4 males, where 2 females share 2 males
> 
> # First, create the mating pairs, then use pedPrep() to create the pedigree
> # Assume 38 offspring per pairing = 1064 (1063 tadpoles in the original data)
> # !!****   Assume offspring from 2 males shared a block   ***!!!
> fdf <- data.frame(id = as.factor(seq.int(1064)),
>     dam = rep(rep(paste0("f", seq.int(7)), each = 4), each = 38),
>     sire = rep(paste0("m", c(1,2,3,4,3,4,5,6,5,6,7,8,7,8,9,10,9,10,11,12,11,12,13,14,13,14,15,16)), each = 38), 
>     block = rep(c(1,2,2,3,3,4,4,5,5,6,6,7,7,8), each = 38*2))
> 
> 
> # Make the pedigree
> fped <- prepPed(fdf[, 1:3])
> 
> # Make the additive and dominance genetic relatedness matrices for simulation
> Dout <- makeD(fped, invertD = TRUE, returnA = TRUE)
> D <- Dout$D
> Dinv <- Dout$Dinv # Hang on to so we can estimate Vd in MCMCglmm
> A <- Dout$A
> listDinv <- Dout$listDinv # Hang on to so we can estimate Vd in ASReml
> 
> 
> # Specify the additive genetic, dominance, maternal, block, and residual variance-covariance matrices for the three traits
> # Taken loosely from the output of the preliminary model (with very low ESS and high autocorrelation - so these could be WAY off!)
> Ga <- matrix(c(11000, -5700, 4500,
>           -5700,  7500,-2000,
>            4500,  -2000, 3000), 3, 3)
> Gd <- matrix(c(3000, 7000, -3500,
>            7000, 38000, 500,
>            -3500, 500, 24000), 3, 3)
> Gm <- matrix(c(1700, 2600, 200,
>         2600, 10000, 400,
>         200, 400, 800), 3, 3)    
> Gb <- matrix(c(1200, -400, 400,
>         -400, 200, -100,
>         400, -100, 350), 3, 3)
> Gr <- matrix(c(12300, -1000, 9000,
>         -1000, 500, -500,
>         9000, -500, 8000), 3, 3)
> 
> # Now, create matrices (3 columns, 1 for each trait) of random effects
> add <- grfx(nrow(fped), G = Ga, incidence = A)[!is.na(fped$dam), ]
> dom <- grfx(nrow(fped), G = Gd, incidence = D)[!is.na(fped$dam), ]
> mat <- drfx(G = Gm, fac = "dam", dataf = fdf)$fx
> blo <- drfx(G = Gb, fac = "block", dataf = fdf)$fx
> res <- grfx(nrow(fped), G = Gr)[!is.na(fped$dam), ]
> # Note, cov(add) should look a lot like Ga; similarly for cov(dom) and Gd
> 
> # make a matrix of trait means (taken from preliminary MCMCglmm model)
> mus <- matrix(c(992.9, 992.1, 986.0), nrow = nrow(fdf), ncol = 3, byrow = TRUE)
> 
> 
> # Now create sets of three traits that have either residual effects plus:
> #     additive and block effects (ABR)
> #     additive, maternal, and block effects (AMBR)
> #     additive, dominance, and block effects (ADBR)
> #     additive, dominance, maternal, and block effects (ADMBR)
> 
> # create temporary matrix as a placeholder
> traits <- matrix(NA, nrow = nrow(fdf), ncol = 3*4)
> colnames(traits) <- paste0(c("i", "w", "d"), rep(c("ABR", "AMBR", "ADBR", "ADMBR"), each = 3))
> # Now, add the empty matrix to our main data frame
> fdf <- cbind(fdf, traits)
> 
> # Fill in the traits with their phenotypic values (phenotype as a function of a mean + random effects
> fdf[, paste0(c("i", "w", "d"), "ABR")] <- mus + add + blo + res
> fdf[, paste0(c("i", "w", "d"), "AMBR")] <- mus + add + mat + blo + res
> fdf[, paste0(c("i", "w", "d"), "ADBR")] <- mus + add + dom + blo + res
> fdf[, paste0(c("i", "w", "d"), "ADMBR")] <- mus + add + dom + mat + blo + res
> 
> 
> # Now, analyses can be conducted on the traits. For example, if one wants to see if additive and dominance genetic variances can be estimated then we do a model like:
> #    ADBR ~ trait - 1, random = ~ us(trait):id + us(trait):idd + us(trait):block 
> # and perhaps compare this to a model without dominance effects (but dominance effects do contribute to the trait:
> #    ADBR ~ trait - 1, random = ~ us(trait):id + us(trait):block
> 
> 
> ....................................................
> Dr. Matthew E. Wolak
> School of Biological Sciences
> Zoology Building
> University of Aberdeen
> Tillydrone Avenue
> Aberdeen AB24 2TZ
> office phone: +44 (0)1224 273255
> On 20/08/14 12:03, Gemma Palomar Garc?a wrote:
>> Dear Matthew,
>> 
>> Thank you for your reply. I explain you a little bit more about our design: we crossed 7 females with 16 males in the lab, each females was crossed with 4 males sharing 2 males with the next female. At the end each female was crossed with 4 males and each male with 2 females. We obtained 1063 tadpoles. Females and Males were adults sampled in the field, therefore, the inbreeding possibility is very low. Do you think that this design is enough to separate dominance and maternal effects?
>> 
>> As you suspect, autocorrelation is high and effective sample size is low in some random factors, I attach the summary of the model.
>> I also did univariate models and I obtained better autocorrelation and effective sample size. Univariate models with all the random factors (i.e. dominance and maternal effect) also had low DIC. However, I would like to obtain genetic correlation so at least I need bivariate models. 
>> 
>> I will try to explain better about additive variance and dominance. The model without dominance as random effect (only animal, maternal and block) had high heritability for weight and development rate and the model with all the random effects (animal, maternal, dominance and block) has low heritability but high dominance for these traits. There is a big change in the estimation of the additive variance between the two models. 
>> 
>> I am going to try with larger thinning interval, thank you. If you have any other suggestion I will be pleased to try it.
>> 
>> Best,
>> 
>> Gemma Palomar
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> El 20/08/2014, a las 12:13, Matthew Wolak <s06mw3 at abdn.ac.uk> escribi?:
>> 
>>> Dear Gemma,
>>> 
>>> I can offer a couple of quick things to check. First, do you have any inbreeding occurring in your study design? This could cause the additive effects to change depending on the presence of the dominance term in the model. 
>>> 
>>> You might also want to consider a larger thinning interval. It is hard to say anything particularly useful without knowing more information or having quantitative descriptors of the model [e.g., what is the output from: autocorr(model3.2) or the effective sample sizes for each random effect?]. However, I suspect the autocorrelation between thinned samples is probably pretty high. Depending on what autocorr(model3.2) tells you, you might want to consider changing the following three arguments like so:
>>> 
>>>    nitt = 5005000, burnin = 5000, thin = 5000
>>> 
>>> It might also be hard for the model to separate dominance and maternal effects from one another, but it is hard to say without knowing more about the breeding design. In general, you could be pushing the model too hard with 3 traits, 4 random terms, and only 1063 animals. If you don't have much missing phenotypic data, univariate models might be a lot easier to start with so that you can see if dominance and/or maternal effects are even necessary to include in the trivariate model.
>>> 
>>> I was a little uncertain about your statement: 
>>> 
>>> "On the other hand, characters with high dominance effects have a change in additive effects in the model without dominance. Additive effects are highly reduced when dominance is added to the model. Is this an overestimation of the additive variance in the model without dominance caused by its lack?"
>>> 
>>> To be clear, are you being careful to use precise language when talking about the individual animal effects for the additive or dominance "effects" (i.e., the model BLUPs) versus the model estimate of the variance in these effects when talking about the "additive variance"?
>>> 
>>> Sincerely,
>>> Matthew
>>> ....................................................
>>> Dr. Matthew E. Wolak
>>> School of Biological Sciences
>>> Zoology Building
>>> University of Aberdeen
>>> Tillydrone Avenue
>>> Aberdeen AB24 2TZ
>>> office phone: +44 (0)1224 273255
>>> On 19/08/14 13:51, Gemma Palomar Garc?a wrote:
>>>> Hello,
>>>> 
>>>> We are using MCMCglmm package with a dataset of 1063 toads. We have three different characters: infection rate, fresh body weight and development rate and we would like to infer additive variance, dominance and maternal effect which it is possible with our breeding design. We want to study heritability and genetic correlations between the characters. The three were normalized with a logarithmic transformation and block was used as random factor to control the variation caused by the position of the containers.
>>>> 
>>>> Inferring dominance effect, we used nadiv package to obtain dominance matrix:
>>>> 
>>>> library(nadiv)
>>>> pedDom=read.table("Ped_Dom.txt",header=T)
>>>> Dom<-makeD(pedDom)
>>>> Dinv=Dom$Dinv
>>>> data$dom=data$animal
>>>> 
>>>> The construction of the trivariate model was the following:
>>>> 
>>>> model3.2=MCMCglmm(cbind(Infection_rate,Weight,Developm)~trait-1, 
>>>>                   random = ~us(trait):animal+us(trait):Mother
>>>>                   +us(trait):Block+us(trait):dom,
>>>>                   rcov=~us(trait):units,
>>>>                   ginverse=list(dom=Dinv), 
>>>>                   family = c("gaussian", "gaussian","gaussian"),
>>>>                   pedigree = pedDom,data = data, nitt = 5000000, 
>>>>                   thin = 100, burnin = 5000, prior = prior3.2)
>>>> 
>>>> And we used this prior:
>>>> 
>>>> prior3.2=list(G = list(G1 = list(V = diag(3), n = 2.002),
>>>>                        G2 = list(V = diag(3), n = 2.002),
>>>>                        G3 = list(V = diag(3), n = 2.002),
>>>>                        G4 = list(V = diag(3), n = 2.002)),
>>>>               R = list(V = diag(3), n = 2.002))
>>>> 
>>>> We obtained very bad mixing but DIC is lower than DIC of the model without dominance. Scaling the variables doesn?t seem to improve the model. Any advice of the model or the prior will be welcome to improve the mixing. 
>>>> 
>>>> On the other hand, characters with high dominance effects have a change in additive effects in the model without dominance. Additive effects are highly reduced when dominance is added to the model. Is this an overestimation of the additive variance in the model without dominance caused by its lack?
>>>> 
>>>> Thank you,
>>>> 
>>>> Gemma Palomar
>>>> PhD student of University of Oviedo, Spain
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 	[[alternative HTML version deleted]]
>>>> 
>>>> 
>>>> 
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
>>> 
>>> 
>>> The University of Aberdeen is a charity registered in Scotland, No SC013683.
>>> Tha Oilthigh Obar Dheathain na charthannas cl?raichte ann an Alba, ?ir. SC013683.
>> 
> 
> 
> 
> The University of Aberdeen is a charity registered in Scotland, No SC013683.
> Tha Oilthigh Obar Dheathain na charthannas cl?raichte ann an Alba, ?ir. SC013683.


	[[alternative HTML version deleted]]


From abedimail at gmail.com  Thu Aug 21 09:46:02 2014
From: abedimail at gmail.com (Mehdi Abedi)
Date: Thu, 21 Aug 2014 12:16:02 +0430
Subject: [R-sig-ME] Mixed model for ordinal data with pseudo replication
Message-ID: <CADGhaggsED7AtMdmX=kU9b03frDzRD9BzBwfH1yHfmcUeCy_yw@mail.gmail.com>

Dear all,
I want to compare 11 soil surface indicator in different treatments and if
possible for species. It would be my pleasure to have your advice for my
data analysis. First, i have two factors including treatments and species
which each treatments include different species. Can we use mixed model for
data analysis?!

 In addition, these 11 soil indicator are ordinal from 0-5 and also has
pseudo replication. Do you have suggestion for data analysis with lme4 or
other proper models?

You can find in the attached file my data as csv file.
Warm regards,
Mehdi

-- 


*Mehdi Abedi Department of Range Management*

*Faculty of Natural Resources & Marine Sciences *

*Tarbiat Modares University (TMU) *

*46417-76489, Noor*

*Mazandaran, IRAN *

*mehdi.abedi at modares.ac.ir <Mehdi.abedi at tmu.ac.ir>*

*Homepage
<http://www.modares.ac.ir/en/Schools/nat/Academic_Staff/~mehdi.abedi>*

*Tel: +98-122-6253101 *

*Fax: +98-122-6253499*

From roelofcoster at gmail.com  Fri Aug 22 13:37:51 2014
From: roelofcoster at gmail.com (Roelof Coster)
Date: Fri, 22 Aug 2014 13:37:51 +0200
Subject: [R-sig-ME] Deviance residuals don't sum up to deviance
Message-ID: <CAPTd6_uPRT0aDX_rJZhfB9Ejd3uzU6QOGDXp+HjKCZOgp0hteg@mail.gmail.com>

Hello,

I fitted a logistic regression model with glmer. In the resulting model,
the reported deviance is not the same as the sum of the squares of the
residual deviances. The deviance is 3909, the sum of square deviance
residuals is 3747.

These two should be equal, shouldn't they? The difference seems too large
for a roundoff error, I think.

My data are 150k observations and the fitted probabilities are generally
very small (between 1e-7 and 1e-2, median 1e-4).

Thanks! Roelof Coster

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Fri Aug 22 13:58:52 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 22 Aug 2014 13:58:52 +0200
Subject: [R-sig-ME] Deviance residuals don't sum up to deviance
In-Reply-To: <CAPTd6_uPRT0aDX_rJZhfB9Ejd3uzU6QOGDXp+HjKCZOgp0hteg@mail.gmail.com>
References: <CAPTd6_uPRT0aDX_rJZhfB9Ejd3uzU6QOGDXp+HjKCZOgp0hteg@mail.gmail.com>
Message-ID: <21495.12412.668147.425818@stat.math.ethz.ch>


> Hello,
> I fitted a logistic regression model with glmer. In the resulting model,
> the reported deviance is not the same as the sum of the squares of the
> residual deviances. The deviance is 3909, the sum of square deviance
> residuals is 3747.

> These two should be equal, shouldn't they? The difference seems too large
> for a roundoff error, I think.

> My data are 150k observations and the fitted probabilities are generally
> very small (between 1e-7 and 1e-2, median 1e-4).

Can you at least show the exact R function calls that you did to
produce it?  Even better,
can you please use the 'gm1' from the first example in
help(glmer),

  (gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
                data = cbpp, family = binomial))

and now show how you compute these to sums with *reproducible* R
code.  That way we (the readers of R-SIG-ME) can be motivated
much more to help you.


> Thanks! Roelof Coster

You are welcome ;-)
Martin Maechler


From roelofcoster at gmail.com  Fri Aug 22 15:07:04 2014
From: roelofcoster at gmail.com (Roelof Coster)
Date: Fri, 22 Aug 2014 15:07:04 +0200
Subject: [R-sig-ME] Deviance residuals don't sum up to deviance
In-Reply-To: <21495.12412.668147.425818@stat.math.ethz.ch>
References: <CAPTd6_uPRT0aDX_rJZhfB9Ejd3uzU6QOGDXp+HjKCZOgp0hteg@mail.gmail.com>
	<21495.12412.668147.425818@stat.math.ethz.ch>
Message-ID: <CAPTd6_sH6kxsaiy5xXjug5X+G-Rws_ssihEp_+6-QfcqS5yEhQ@mail.gmail.com>

Thanks for the suggestion!

I can use the example which you suggest:

> gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
data = cbpp, family = binomial)
> deviance(gm1)
[1] 184.0531
> sum(residuals(gm1, type= "deviance")^2)
[1] 73.47428

So here is what I don't understand: these deviance residuals, squared,
don't add up to the total deviance as I expected they would.

Best regards, Roelof Coster




2014-08-22 13:58 GMT+02:00 Martin Maechler <maechler at stat.math.ethz.ch>:

>
> > Hello,
> > I fitted a logistic regression model with glmer. In the resulting model,
> > the reported deviance is not the same as the sum of the squares of the
> > residual deviances. The deviance is 3909, the sum of square deviance
> > residuals is 3747.
>
> > These two should be equal, shouldn't they? The difference seems too large
> > for a roundoff error, I think.
>
> > My data are 150k observations and the fitted probabilities are generally
> > very small (between 1e-7 and 1e-2, median 1e-4).
>
> Can you at least show the exact R function calls that you did to
> produce it?  Even better,
> can you please use the 'gm1' from the first example in
> help(glmer),
>
>   (gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
>                 data = cbpp, family = binomial))
>
> and now show how you compute these to sums with *reproducible* R
> code.  That way we (the readers of R-SIG-ME) can be motivated
> much more to help you.
>
>
> > Thanks! Roelof Coster
>
> You are welcome ;-)
> Martin Maechler
>

	[[alternative HTML version deleted]]


From steve.walker at utoronto.ca  Fri Aug 22 15:49:00 2014
From: steve.walker at utoronto.ca (Steve Walker)
Date: Fri, 22 Aug 2014 09:49:00 -0400
Subject: [R-sig-ME] Deviance residuals don't sum up to deviance
In-Reply-To: <CAPTd6_sH6kxsaiy5xXjug5X+G-Rws_ssihEp_+6-QfcqS5yEhQ@mail.gmail.com>
References: <CAPTd6_uPRT0aDX_rJZhfB9Ejd3uzU6QOGDXp+HjKCZOgp0hteg@mail.gmail.com>	<21495.12412.668147.425818@stat.math.ethz.ch>
	<CAPTd6_sH6kxsaiy5xXjug5X+G-Rws_ssihEp_+6-QfcqS5yEhQ@mail.gmail.com>
Message-ID: <53F74A4C.9080208@utoronto.ca>

Does this document by Ben Bolker clear it up?

https://github.com/lme4/lme4/blob/master/misc/notes/deviance.rmd

Steve

On 2014-08-22, 9:07 AM, Roelof Coster wrote:
> Thanks for the suggestion!
>
> I can use the example which you suggest:
>
>> gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
> data = cbpp, family = binomial)
>> deviance(gm1)
> [1] 184.0531
>> sum(residuals(gm1, type= "deviance")^2)
> [1] 73.47428
>
> So here is what I don't understand: these deviance residuals, squared,
> don't add up to the total deviance as I expected they would.
>
> Best regards, Roelof Coster
>
>
>
>
> 2014-08-22 13:58 GMT+02:00 Martin Maechler <maechler at stat.math.ethz.ch>:
>
>>
>>> Hello,
>>> I fitted a logistic regression model with glmer. In the resulting model,
>>> the reported deviance is not the same as the sum of the squares of the
>>> residual deviances. The deviance is 3909, the sum of square deviance
>>> residuals is 3747.
>>
>>> These two should be equal, shouldn't they? The difference seems too large
>>> for a roundoff error, I think.
>>
>>> My data are 150k observations and the fitted probabilities are generally
>>> very small (between 1e-7 and 1e-2, median 1e-4).
>>
>> Can you at least show the exact R function calls that you did to
>> produce it?  Even better,
>> can you please use the 'gm1' from the first example in
>> help(glmer),
>>
>>    (gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
>>                  data = cbpp, family = binomial))
>>
>> and now show how you compute these to sums with *reproducible* R
>> code.  That way we (the readers of R-SIG-ME) can be motivated
>> much more to help you.
>>
>>
>>> Thanks! Roelof Coster
>>
>> You are welcome ;-)
>> Martin Maechler
>>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


From steve.walker at utoronto.ca  Fri Aug 22 16:09:45 2014
From: steve.walker at utoronto.ca (Steve Walker)
Date: Fri, 22 Aug 2014 10:09:45 -0400
Subject: [R-sig-ME] Deviance residuals don't sum up to deviance
In-Reply-To: <53F74A4C.9080208@utoronto.ca>
References: <CAPTd6_uPRT0aDX_rJZhfB9Ejd3uzU6QOGDXp+HjKCZOgp0hteg@mail.gmail.com>	<21495.12412.668147.425818@stat.math.ethz.ch>	<CAPTd6_sH6kxsaiy5xXjug5X+G-Rws_ssihEp_+6-QfcqS5yEhQ@mail.gmail.com>
	<53F74A4C.9080208@utoronto.ca>
Message-ID: <53F74F29.1030907@utoronto.ca>

I just remembered that this bug is actually fixed in the development 
version of lme4 on github,

 > gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
+ data = cbpp, family = binomial)
 > deviance(gm1)
[1] 73.47428
 > sum(residuals(gm1, type= "deviance")^2)
[1] 73.47428

So this will be fixed in the next lme4 release to CRAN.

Cheers,
Steve



On 2014-08-22, 9:49 AM, Steve Walker wrote:
> Does this document by Ben Bolker clear it up?
>
> https://github.com/lme4/lme4/blob/master/misc/notes/deviance.rmd
>
> Steve
>
> On 2014-08-22, 9:07 AM, Roelof Coster wrote:
>> Thanks for the suggestion!
>>
>> I can use the example which you suggest:
>>
>>> gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
>> data = cbpp, family = binomial)
>>> deviance(gm1)
>> [1] 184.0531
>>> sum(residuals(gm1, type= "deviance")^2)
>> [1] 73.47428
>>
>> So here is what I don't understand: these deviance residuals, squared,
>> don't add up to the total deviance as I expected they would.
>>
>> Best regards, Roelof Coster
>>
>>
>>
>>
>> 2014-08-22 13:58 GMT+02:00 Martin Maechler <maechler at stat.math.ethz.ch>:
>>
>>>
>>>> Hello,
>>>> I fitted a logistic regression model with glmer. In the resulting
>>>> model,
>>>> the reported deviance is not the same as the sum of the squares of the
>>>> residual deviances. The deviance is 3909, the sum of square deviance
>>>> residuals is 3747.
>>>
>>>> These two should be equal, shouldn't they? The difference seems too
>>>> large
>>>> for a roundoff error, I think.
>>>
>>>> My data are 150k observations and the fitted probabilities are
>>>> generally
>>>> very small (between 1e-7 and 1e-2, median 1e-4).
>>>
>>> Can you at least show the exact R function calls that you did to
>>> produce it?  Even better,
>>> can you please use the 'gm1' from the first example in
>>> help(glmer),
>>>
>>>    (gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 |
>>> herd),
>>>                  data = cbpp, family = binomial))
>>>
>>> and now show how you compute these to sums with *reproducible* R
>>> code.  That way we (the readers of R-SIG-ME) can be motivated
>>> much more to help you.
>>>
>>>
>>>> Thanks! Roelof Coster
>>>
>>> You are welcome ;-)
>>> Martin Maechler
>>>
>>
>>     [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


From bates at stat.wisc.edu  Fri Aug 22 18:27:58 2014
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 22 Aug 2014 11:27:58 -0500
Subject: [R-sig-ME] RE : Generalized mixed effects models
In-Reply-To: <F052D2D4358DB94597A8570CD69DB2C90997A8E0228C@MAILBANK.ensae.fr>
References: <F052D2D4358DB94597A8570CD69DB2C90997A8E02271@MAILBANK.ensae.fr>
	<CAO7JsnTXQDfdsQQ-q2r_=HGNeMEArgEBmk-+C7+1aqC4VdnaBQ@mail.gmail.com>
	<F052D2D4358DB94597A8570CD69DB2C90997A8E0228C@MAILBANK.ensae.fr>
Message-ID: <CAO7JsnSwj_C+_tBp1ZGpVP+2=RtQKKjqCbvthJDL=C6FYZRPMQ@mail.gmail.com>

Questions like this are better sent to the R-SIG-Mixed-Models at R-project.org
mailing list as there are many people who read that list and are able to
respond faster than I am.

I have taken the liberty of cc:'ing the list on this reply.


On Fri, Aug 22, 2014 at 10:43 AM, PLUQUET Thibault <
Thibault.PLUQUET at ensae-paristech.fr> wrote:

> Good afternoon,
>
> I'm a French student. I'm sorry to disturb you. I know for generalized
> linear mixed models we , first, have to do the penalized iteratively
> reweighted least squares, bu why ? I understad why for linear mixed models
> but for generalized linear mixed models , I don't understand why we have
> the matrix W and the formula of the discrepancy function .
>

Evaluating the likelihood for generalized linear mixed models requires
integrating the conditional distribution of the random effects evaluated at
the current parameter values.  For a linear mixed model this integral has a
closed form, because of the properties of the multivariate Gaussian
distribution and the fact that the conditional mean of the response vector
is a linear function of the random effects.  In a generalized linear mixed
model the conditional mean response is a nonlinear function (the inverse
link) of the linear predictor and hence a nonlinear function of the random
effects and the conditional distribution of the response given the random
effects is not Gaussian.  There is no closed form expression for the
integral over the random effects, in general.

There have been many different approaches to approximating this integral.
In the lme4 package we use a Laplacian approximation at the conditional
mode of the random effects or an adaptive Gauss-Hermite quadrature. Both
approaches require determining the conditional mode of the random effects
given the observed data and the current values of the model parameters. We
use the penalized iteratively re-weighted least squares (PIRLS) algorithm
to determine the conditional mode.  The weights are part of the PIRLS
algorithm.

	[[alternative HTML version deleted]]


From Thibault.PLUQUET at ensae-paristech.fr  Fri Aug 22 18:43:42 2014
From: Thibault.PLUQUET at ensae-paristech.fr (PLUQUET Thibault)
Date: Fri, 22 Aug 2014 18:43:42 +0200
Subject: [R-sig-ME] glmer
Message-ID: <F052D2D4358DB94597A8570CD69DB2C90997A8E0228F@MAILBANK.ensae.fr>

Hi,

I'm a french student in Statistics. I have a question on generalized linear mixed models.For the estimation, we have to do the penalized least squares but I don't understand why this method ? I know why we use the penalized least squares for lieanr mixed models . But , I don't understand why there is the matrix W in this method and how to get the discrepancy function.

Thank you for your help, 


Sincerely 


PLUQUET Thibault 

From josipa at iptpo.hr  Fri Aug 22 12:25:34 2014
From: josipa at iptpo.hr (=?iso-8859-2?Q?Josipa_Perkovi=E6?=)
Date: Fri, 22 Aug 2014 12:25:34 +0200
Subject: [R-sig-ME] help on choosin right model for data
Message-ID: <000001cfbdf3$689a77d0$39cf6770$@iptpo.hr>

 

I would appreciate if you could help me choose different R packages and
writing model to analyze

what I believe to be unequally spaced repeated measurement data. 

My data consists of data on PAR (photosinthetically active radiation)
-average and maximum daily PAR, collected successively every 10 min with
data loggers.

Sensors were positioned above different mulches (sub factor in three levels)
with differently fertilized plant canopy (main factor in 4 levels), so there
are two different factors influencing AVG and MAX PAR.

Also since sensors weren't positioned in repetitions I divided data in every
10 min, 15 min and 25 min sequence for AVG and MAX for each sensor.  

So the experiment is two-factorial (fertilizers (4) and mulch (3) ) but has
time dimension too.

More like a split-split plot.

 

What kind of package should I choose, longitudinal? And how to write a model
?

 

I'm so very sorry for my poor knowledge on statistics, I'm not a
statistician.

I' would be very grateful if you could guide me to the write way to handle
my data and to write a model.

 

 

Sincerely,

 

 

Josipa Perkovi?

Dipl.ing.agr

Science novice

Institute for Agriculture and Tourism, Porec

Croatia

 


	[[alternative HTML version deleted]]


From rubenarslan at gmail.com  Mon Aug 25 16:58:06 2014
From: rubenarslan at gmail.com (Ruben Arslan)
Date: Mon, 25 Aug 2014 16:58:06 +0200
Subject: [R-sig-ME] parallel MCMCglmm, RNGstreams, starting values & priors
In-Reply-To: <4CD76FE1-D3F5-4980-9122-B0AC0D44FF81@gmail.com>
References: <4CD76FE1-D3F5-4980-9122-B0AC0D44FF81@gmail.com>
Message-ID: <0E12EB43-72BC-42AC-9E74-9DF53DB42217@gmail.com>

Dear list,

sorry for bumping my old post, I hope to elicit a response with a more focused question:

When does MCMCglmm automatically start from different values when using doMPI/foreach?

I have done some tests with models of varying complexity. For example, the script in my last
post (using "zapoisson") yielded 40 identical chains:
> identical(mcmclist[1], mcmclist[30])
TRUE 

A simpler (?) model (using "ztpoisson" and no specified prior), however, yielded different chains 
and I could use them to calculate gelman.diag()

Changing my script to the version below, i.e. seeding foreach using .options.mpi=list( seed= 1337) 
so as to make RNGstreams reproducible (or so I  thought), led to different chains even for the 
"zapoisson" model.

In no case have I (successfully) tried to supplant the default of MCMCglmm's "start" argument.
Is starting my models from different RNGsubstreams inadequate compared to manipulating
the start argument explicitly? If so, is there any worked example of explicit starting value manipulation
in parallel computation?
I've browsed the MCMCglmm source to understand how the default starting values are generated,
but didn't find any differences with respect to RNG for the two families "ztpoisson" and "zapoisson"
(granted, I did not dig very deep).

Best regards,

Ruben Arslan


# bsub -q mpi -W 12:00 -n 41 -R np20 mpirun -H localhost -n 41 R --slave -f "/usr/users/rarslan/rpqa/rpqa_main/rpqa_children_parallel.R"

library(doMPI)
cl <- startMPIcluster(verbose=T,workdir="/usr/users/rarslan/rpqa/rpqa_main/")
registerDoMPI(cl)
Children_mcmc1 = foreach(i=1:clusterSize(cl),.options.mpi = list(seed=1337) ) %dopar% {
	library(MCMCglmm);library(data.table)
	load("/usr/users/rarslan/rpqa/rpqa1.rdata")
	
	nitt = 130000; thin = 100; burnin = 30000
	prior.m5d.2 = list(
		R = list(V = diag(c(1,1)), nu = 0.002),
		G=list(list(V=diag(c(1,1e-6)),nu=0.002))
	)
	
	rpqa.1 = na.omit(rpqa.1[spouses>0, list(idParents, children, male, urban, spouses, paternalage.mean, paternalage.factor)])
	(m1 = MCMCglmm( children ~ trait * (male + urban + spouses + paternalage.mean + paternalage.factor),
						rcov=~us(trait):units,
						random=~us(trait):idParents,
						family="zapoisson",
						prior = prior.m5d.2,
						data=rpqa.1, 
						pr = F, saveX = F, saveZ = F,
						nitt=nitt,thin=thin,burnin=burnin))
}

library(coda)
mcmclist = mcmc.list(lapply(Children_mcmc1,FUN=function(x) { x$Sol}))
save(Children_mcmc1,mcmclist, file = "/usr/users/rarslan/rpqa/rpqa_main/rpqa_mcmc_kids_za.rdata")
closeCluster(cl)
mpi.quit()

 

On 04 Aug 2014, at 20:25, Ruben Arslan <rubenarslan at gmail.com> wrote:

> Dear list,
> 
> would someone be willing to share her or his efforts in parallelising a MCMCglmm analysis?
> 
> I had something viable using harvestr that seemed to properly initialise
> the starting values from different random number streams (which is desirable,
> as far as I could find out), but I ended up being unable to use harvestr, because
> it uses an old version of plyr, where parallelisation works only for multicore, not for
> MPI.
> 
> I pasted my working version, that does not do anything about starting values or RNG
> at the end of this email. I can try to fumble further in the dark or try to update harvestr,
> but maybe someone has gone through all this already.
> 
> I'd also appreciate any tips for elegantly post-processing such parallel data, as some of my usual
> extraction functions and routines are hampered by the fact that some coda functions
> do not aggregate results over chains. (What I get from a single-chain summary in MCMCglmm
> is a bit more comprehensive, than what I managed to cobble together with my own extraction
> functions).
> 
> The reason I'm parallelising my analyses is that I'm having trouble getting a good effective
> sample size for any parameter having to do with the many zeroes in my data.
> Any pointers are very appreciated, I'm quite inexperienced with MCMCglmm.
> 
> Best wishes
> 
> Ruben
> 
> # bsub -q mpi-short -W 2:00 -n 42 -R np20 mpirun -H localhost -n 41 R --slave -f "rpqa/rpqa_main/rpqa_children_parallel.r"
> library(doMPI)
> cl <- startMPIcluster()
> registerDoMPI(cl)
> Children_mcmc1 = foreach(i=1:40) %dopar% {
> 	library(MCMCglmm)
> 	load("rpqa1.rdata")
> 	
> 	nitt = 40000; thin = 100; burnin = 10000
> 	prior = list(
> 		R = list(V = diag(c(1,1)), nu = 0.002),
> 		G=list(list(V=diag(c(1,1e-6)),nu=0.002))
> 	)
> 	
> 	MCMCglmm( children ~ trait -1 + at.level(trait,1):male + at.level(trait,1):urban + at.level(trait,1):spouses + at.level(trait,1):paternalage.mean + at.level(trait,1):paternalage.factor,
> 		rcov=~us(trait):units,
> 		random=~us(trait):idParents,
> 		family="zapoisson",
> 		prior = prior,
> 		data=rpqa.1, 
> 		pr = F, saveX = T, saveZ = T,
> 		nitt=nitt,thin=thin,burnin=burnin)
> }
> 
> library(coda)
> mcmclist = mcmc.list(lapply(Children_mcmc1,FUN=function(x) { x$Sol}))
> save(Children_mcmc1,mcmclist, file = "rpqa_mcmc_kids_za.rdata")
> closeCluster(cl)
> mpi.quit()
> 
> 
> --
> Ruben C. Arslan
> 
> Georg August University G?ttingen
> Biological Personality Psychology and Psychological Assessment
> Georg Elias M?ller Institute of Psychology
> Go?lerstr. 14
> 37073 G?ttingen
> Germany
> Tel.: +49 551 3920704
> https://psych.uni-goettingen.de/en/biopers/team/arslan
> 
> 
> 


	[[alternative HTML version deleted]]


From spatrick at glos.ac.uk  Mon Aug 25 17:16:27 2014
From: spatrick at glos.ac.uk (PATRICK, Samantha)
Date: Mon, 25 Aug 2014 15:16:27 +0000
Subject: [R-sig-ME] How to fix the value of random intercepts (lmer/MCMCglmm)
Message-ID: <048718e40aa941909a85c46e6e979df6@glos.ac.uk>

Hi All

I am fitting a basic linear regression, where I want to estimate a single population intercept and slope.  In addition I am fitting random intercepts and slopes such that:

lmer (Y ~Intercept + Continuous Variable + (Continuous Variable |Indiviudal Group))

However the exact value of the individual group intercepts is known from the data set.  The reasons for this are a little involved but essentially Y is a cumulative total and so at the intercept I want to fit the actual cumulative total at this point for each individual.  It is important as the slope per individual needs to be constrained to pass through the actual intercept per individual.

So I want to fit this model, estimating the population intercept and slope.  I then want to fix the individual group deviation from the population intercept (random intercepts), and from this model extract estimates of individual group random slopes.

I have been unable to find any examples of fixing intercepts, unless they are fixed as a constant.  Is it possible to code the model in such a way? The model can be run in MCMCglmm or lmer  which ever package would allow me to constrain the intercepts.

Thanks

Sam?


Dr Samantha Patrick
Research Fellow
Biosciences QU116
Francis Close Hall Campus
University of Gloucestershire
Cheltenham, GL50 4AZ, UK

Research Associate: OxNav, University of Oxford

******From 1st August - 14th November 2014 I will be
based in Montr?al, which is 5 hours behind GMT  ******

Tel: 07740 472 719
Skype: sammy_patrick
https://sites.google.com/site/samanthacpatrick/

-
?In the top 5 in the Green League Table; committed to sustainability?
This email is confidential to the intended recipient. If you have received it in error please notify the sender and delete it from your computer.
The University of Gloucestershire is a company limited by guarantee registered in England and Wales.  Registered number: 06023243.  Registered office: The Park, Cheltenham, GL50 2RH
Please consider the environment before printing this email.
-

From j.hadfield at ed.ac.uk  Mon Aug 25 17:29:07 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 25 Aug 2014 16:29:07 +0100
Subject: [R-sig-ME] parallel MCMCglmm, RNGstreams,
 starting values & priors
In-Reply-To: <0E12EB43-72BC-42AC-9E74-9DF53DB42217@gmail.com>
References: <4CD76FE1-D3F5-4980-9122-B0AC0D44FF81@gmail.com>
	<0E12EB43-72BC-42AC-9E74-9DF53DB42217@gmail.com>
Message-ID: <20140825162907.10475jpywlu1wzs4@www.staffmail.ed.ac.uk>

Hi Ruben,

I do not think the issue is with the starting values, because even if  
the same starting values were used the chains would still differ  
because of the randomness in the Markov Chain (if I interpret your  
`identical' test correctly). This just involves a call to  
GetRNGstate() in the C++ code (L 871 of MCMCglmm.cc) so I think for  
some reason doMPI/foreach is not doing what you expect. I am not  
familiar with doMPI and am in the middle of writing lectures so  
haven't got time to look into it carefully. Outside of the context of  
doMPI I get the behaviour I expect:


l<-rnorm(200, -1, sqrt(1))
t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
y<-rpois(200,exp(l)-t)+1
# generate zero-truncated data with an intercept of -1

dat<-data.frame(y=y)
set.seed(1)
m1<-MCMCglmm(y~1, family="ztpoisson", data=dat)
set.seed(2)
m2<-MCMCglmm(y~1, family="ztpoisson", data=dat)
set.seed(2)
m3<-MCMCglmm(y~1, family="ztpoisson", data=dat)

plot(mcmc.list(m1$Sol, m2$Sol))
# different, as expected
plot(mcmc.list(m2$Sol, m3$Sol))
# the same, as expected





Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25 Aug 2014  
16:58:06 +0200:

> Dear list,
>
> sorry for bumping my old post, I hope to elicit a response with a  
> more focused question:
>
> When does MCMCglmm automatically start from different values when  
> using doMPI/foreach?
>
> I have done some tests with models of varying complexity. For  
> example, the script in my last
> post (using "zapoisson") yielded 40 identical chains:
>> identical(mcmclist[1], mcmclist[30])
> TRUE
>
> A simpler (?) model (using "ztpoisson" and no specified prior),  
> however, yielded different chains
> and I could use them to calculate gelman.diag()
>
> Changing my script to the version below, i.e. seeding foreach using  
> .options.mpi=list( seed= 1337)
> so as to make RNGstreams reproducible (or so I  thought), led to  
> different chains even for the
> "zapoisson" model.
>
> In no case have I (successfully) tried to supplant the default of  
> MCMCglmm's "start" argument.
> Is starting my models from different RNGsubstreams inadequate  
> compared to manipulating
> the start argument explicitly? If so, is there any worked example of  
> explicit starting value manipulation
> in parallel computation?
> I've browsed the MCMCglmm source to understand how the default  
> starting values are generated,
> but didn't find any differences with respect to RNG for the two  
> families "ztpoisson" and "zapoisson"
> (granted, I did not dig very deep).
>
> Best regards,
>
> Ruben Arslan
>
>
> # bsub -q mpi -W 12:00 -n 41 -R np20 mpirun -H localhost -n 41 R  
> --slave -f  
> "/usr/users/rarslan/rpqa/rpqa_main/rpqa_children_parallel.R"
>
> library(doMPI)
> cl <- startMPIcluster(verbose=T,workdir="/usr/users/rarslan/rpqa/rpqa_main/")
> registerDoMPI(cl)
> Children_mcmc1 = foreach(i=1:clusterSize(cl),.options.mpi =  
> list(seed=1337) ) %dopar% {
> 	library(MCMCglmm);library(data.table)
> 	load("/usr/users/rarslan/rpqa/rpqa1.rdata")
>
> 	nitt = 130000; thin = 100; burnin = 30000
> 	prior.m5d.2 = list(
> 		R = list(V = diag(c(1,1)), nu = 0.002),
> 		G=list(list(V=diag(c(1,1e-6)),nu=0.002))
> 	)
>
> 	rpqa.1 = na.omit(rpqa.1[spouses>0, list(idParents, children, male,  
> urban, spouses, paternalage.mean, paternalage.factor)])
> 	(m1 = MCMCglmm( children ~ trait * (male + urban + spouses +  
> paternalage.mean + paternalage.factor),
> 						rcov=~us(trait):units,
> 						random=~us(trait):idParents,
> 						family="zapoisson",
> 						prior = prior.m5d.2,
> 						data=rpqa.1,
> 						pr = F, saveX = F, saveZ = F,
> 						nitt=nitt,thin=thin,burnin=burnin))
> }
>
> library(coda)
> mcmclist = mcmc.list(lapply(Children_mcmc1,FUN=function(x) { x$Sol}))
> save(Children_mcmc1,mcmclist, file =  
> "/usr/users/rarslan/rpqa/rpqa_main/rpqa_mcmc_kids_za.rdata")
> closeCluster(cl)
> mpi.quit()
>
>
>
> On 04 Aug 2014, at 20:25, Ruben Arslan <rubenarslan at gmail.com> wrote:
>
>> Dear list,
>>
>> would someone be willing to share her or his efforts in  
>> parallelising a MCMCglmm analysis?
>>
>> I had something viable using harvestr that seemed to properly initialise
>> the starting values from different random number streams (which is  
>> desirable,
>> as far as I could find out), but I ended up being unable to use  
>> harvestr, because
>> it uses an old version of plyr, where parallelisation works only  
>> for multicore, not for
>> MPI.
>>
>> I pasted my working version, that does not do anything about  
>> starting values or RNG
>> at the end of this email. I can try to fumble further in the dark  
>> or try to update harvestr,
>> but maybe someone has gone through all this already.
>>
>> I'd also appreciate any tips for elegantly post-processing such  
>> parallel data, as some of my usual
>> extraction functions and routines are hampered by the fact that  
>> some coda functions
>> do not aggregate results over chains. (What I get from a  
>> single-chain summary in MCMCglmm
>> is a bit more comprehensive, than what I managed to cobble together  
>> with my own extraction
>> functions).
>>
>> The reason I'm parallelising my analyses is that I'm having trouble  
>> getting a good effective
>> sample size for any parameter having to do with the many zeroes in my data.
>> Any pointers are very appreciated, I'm quite inexperienced with MCMCglmm.
>>
>> Best wishes
>>
>> Ruben
>>
>> # bsub -q mpi-short -W 2:00 -n 42 -R np20 mpirun -H localhost -n 41  
>> R --slave -f "rpqa/rpqa_main/rpqa_children_parallel.r"
>> library(doMPI)
>> cl <- startMPIcluster()
>> registerDoMPI(cl)
>> Children_mcmc1 = foreach(i=1:40) %dopar% {
>> 	library(MCMCglmm)
>> 	load("rpqa1.rdata")
>>
>> 	nitt = 40000; thin = 100; burnin = 10000
>> 	prior = list(
>> 		R = list(V = diag(c(1,1)), nu = 0.002),
>> 		G=list(list(V=diag(c(1,1e-6)),nu=0.002))
>> 	)
>>
>> 	MCMCglmm( children ~ trait -1 + at.level(trait,1):male +  
>> at.level(trait,1):urban + at.level(trait,1):spouses +  
>> at.level(trait,1):paternalage.mean +  
>> at.level(trait,1):paternalage.factor,
>> 		rcov=~us(trait):units,
>> 		random=~us(trait):idParents,
>> 		family="zapoisson",
>> 		prior = prior,
>> 		data=rpqa.1,
>> 		pr = F, saveX = T, saveZ = T,
>> 		nitt=nitt,thin=thin,burnin=burnin)
>> }
>>
>> library(coda)
>> mcmclist = mcmc.list(lapply(Children_mcmc1,FUN=function(x) { x$Sol}))
>> save(Children_mcmc1,mcmclist, file = "rpqa_mcmc_kids_za.rdata")
>> closeCluster(cl)
>> mpi.quit()
>>
>>
>> --
>> Ruben C. Arslan
>>
>> Georg August University G?ttingen
>> Biological Personality Psychology and Psychological Assessment
>> Georg Elias M?ller Institute of Psychology
>> Go?lerstr. 14
>> 37073 G?ttingen
>> Germany
>> Tel.: +49 551 3920704
>> https://psych.uni-goettingen.de/en/biopers/team/arslan
>>
>>
>>
>
>
> 	[[alternative HTML version deleted]]
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From j.hadfield at ed.ac.uk  Mon Aug 25 17:33:16 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 25 Aug 2014 16:33:16 +0100
Subject: [R-sig-ME] How to fix the value of random intercepts
 (lmer/MCMCglmm)
In-Reply-To: <048718e40aa941909a85c46e6e979df6@glos.ac.uk>
References: <048718e40aa941909a85c46e6e979df6@glos.ac.uk>
Message-ID: <20140825163316.123943xivaifhwsg@www.staffmail.ed.ac.uk>

Hi Sam,

You could do this in MCMCglmm but it sounds like it might (possibly)  
be a bad idea. Could you give more details on how Y is actually  
obtained?

Cheers,

Jarrod


Quoting "PATRICK, Samantha" <spatrick at glos.ac.uk> on Mon, 25 Aug 2014  
15:16:27 +0000:

> Hi All
>
> I am fitting a basic linear regression, where I want to estimate a  
> single population intercept and slope.  In addition I am fitting  
> random intercepts and slopes such that:
>
> lmer (Y ~Intercept + Continuous Variable + (Continuous Variable  
> |Indiviudal Group))
>
> However the exact value of the individual group intercepts is known  
> from the data set.  The reasons for this are a little involved but  
> essentially Y is a cumulative total and so at the intercept I want  
> to fit the actual cumulative total at this point for each  
> individual.  It is important as the slope per individual needs to be  
> constrained to pass through the actual intercept per individual.
>
> So I want to fit this model, estimating the population intercept and  
> slope.  I then want to fix the individual group deviation from the  
> population intercept (random intercepts), and from this model  
> extract estimates of individual group random slopes.
>
> I have been unable to find any examples of fixing intercepts, unless  
> they are fixed as a constant.  Is it possible to code the model in  
> such a way? The model can be run in MCMCglmm or lmer  which ever  
> package would allow me to constrain the intercepts.
>
> Thanks
>
> Sam?
>
>
> Dr Samantha Patrick
> Research Fellow
> Biosciences QU116
> Francis Close Hall Campus
> University of Gloucestershire
> Cheltenham, GL50 4AZ, UK
>
> Research Associate: OxNav, University of Oxford
>
> ******From 1st August - 14th November 2014 I will be
> based in Montr?al, which is 5 hours behind GMT  ******
>
> Tel: 07740 472 719
> Skype: sammy_patrick
> https://sites.google.com/site/samanthacpatrick/
>
> -
> ?In the top 5 in the Green League Table; committed to sustainability?
> This email is confidential to the intended recipient. If you have  
> received it in error please notify the sender and delete it from  
> your computer.
> The University of Gloucestershire is a company limited by guarantee  
> registered in England and Wales.  Registered number: 06023243.   
> Registered office: The Park, Cheltenham, GL50 2RH
> Please consider the environment before printing this email.
> -
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From spatrick at glos.ac.uk  Mon Aug 25 17:41:30 2014
From: spatrick at glos.ac.uk (PATRICK, Samantha)
Date: Mon, 25 Aug 2014 15:41:30 +0000
Subject: [R-sig-ME] How to fix the value of random intercepts
 (lmer/MCMCglmm)
In-Reply-To: <20140825163316.123943xivaifhwsg@www.staffmail.ed.ac.uk>
References: <048718e40aa941909a85c46e6e979df6@glos.ac.uk>,
	<20140825163316.123943xivaifhwsg@www.staffmail.ed.ac.uk>
Message-ID: <d242866fceb549f0b15f8ac1d2a12817@glos.ac.uk>

Hi Jarrod

The structure of the data is:

Y = Cumulative number of offspring.
X = Age.  Age is mean centred so the intercept is at 22 years old.  This is where the intercepts are fitted and for each individual I have an exact number of offspring at this age.

I want to examine how the number of offspring increases with age.  I am using random slopes to examine within individual changes with age.  If I don't constrain the intercept at the individual level then the slope does not represent the actual increase with age, and you get results that are largely driven by the age at last sampling.   If I constrain the intercepts, as I understand, the slope will represent the actual increase in fitness with age for each individual.

Happy to post data if this is not clear enough/it would help.

Thanks

Sam


Dr Samantha Patrick
Research Fellow
Biosciences QU116
Francis Close Hall Campus
University of Gloucestershire
Cheltenham, GL50 4AZ, UK

Research Associate: OxNav, University of Oxford

******From 1st August - 14th November 2014 I will be
based in Montr?al, which is 5 hours behind GMT  ******

Tel: 07740 472 719
Skype: sammy_patrick
https://sites.google.com/site/samanthacpatrick/

From: Jarrod Hadfield<mailto:j.hadfield at ed.ac.uk>
Sent: ?Monday?, ?25? ?August? ?2014 ?11?:?33
To: Samantha Patrick<mailto:spatrick at glos.ac.uk>
Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>

Hi Sam,

You could do this in MCMCglmm but it sounds like it might (possibly)
be a bad idea. Could you give more details on how Y is actually
obtained?

Cheers,

Jarrod


Quoting "PATRICK, Samantha" <spatrick at glos.ac.uk> on Mon, 25 Aug 2014
15:16:27 +0000:

> Hi All
>
> I am fitting a basic linear regression, where I want to estimate a
> single population intercept and slope.  In addition I am fitting
> random intercepts and slopes such that:
>
> lmer (Y ~Intercept + Continuous Variable + (Continuous Variable
> |Indiviudal Group))
>
> However the exact value of the individual group intercepts is known
> from the data set.  The reasons for this are a little involved but
> essentially Y is a cumulative total and so at the intercept I want
> to fit the actual cumulative total at this point for each
> individual.  It is important as the slope per individual needs to be
> constrained to pass through the actual intercept per individual.
>
> So I want to fit this model, estimating the population intercept and
> slope.  I then want to fix the individual group deviation from the
> population intercept (random intercepts), and from this model
> extract estimates of individual group random slopes.
>
> I have been unable to find any examples of fixing intercepts, unless
> they are fixed as a constant.  Is it possible to code the model in
> such a way? The model can be run in MCMCglmm or lmer  which ever
> package would allow me to constrain the intercepts.
>
> Thanks
>
> Sam?
>
>
> Dr Samantha Patrick
> Research Fellow
> Biosciences QU116
> Francis Close Hall Campus
> University of Gloucestershire
> Cheltenham, GL50 4AZ, UK
>
> Research Associate: OxNav, University of Oxford
>
> ******From 1st August - 14th November 2014 I will be
> based in Montr?al, which is 5 hours behind GMT  ******
>
> Tel: 07740 472 719
> Skype: sammy_patrick
> https://sites.google.com/site/samanthacpatrick/
>
> -
> ?In the top 5 in the Green League Table; committed to sustainability?
> This email is confidential to the intended recipient. If you have
> received it in error please notify the sender and delete it from
> your computer.
> The University of Gloucestershire is a company limited by guarantee
> registered in England and Wales.  Registered number: 06023243.
> Registered office: The Park, Cheltenham, GL50 2RH
> Please consider the environment before printing this email.
> -
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



--
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


-
?In the top 5 in the Green League Table; committed to sustainability?
This email is confidential to the intended recipient. If you have received it in error please notify the sender and delete it from your computer.
The University of Gloucestershire is a company limited by guarantee registered in England and Wales.  Registered number: 06023243.  Registered office: The Park, Cheltenham, GL50 2RH
Please consider the environment before printing this email.
-

From j.hadfield at ed.ac.uk  Mon Aug 25 17:54:18 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 25 Aug 2014 16:54:18 +0100
Subject: [R-sig-ME] How to fix the value of random intercepts
 (lmer/MCMCglmm)
In-Reply-To: <d242866fceb549f0b15f8ac1d2a12817@glos.ac.uk>
References: <048718e40aa941909a85c46e6e979df6@glos.ac.uk>,
	<20140825163316.123943xivaifhwsg@www.staffmail.ed.ac.uk>
	<d242866fceb549f0b15f8ac1d2a12817@glos.ac.uk>
Message-ID: <20140825165418.11286locesd0ihc8@www.staffmail.ed.ac.uk>

Hi,

There will be strong dependencies between observations not captured in  
the model and this is likely to result in spurious results.

To see this, take Y(x) as the cumulative number of offspring at age x,  
and y(x) as the number of offspring produced at age x then Y(1) =  
y(1), Y(2) = y(1) + y(2), Y(3) = y(1) + y(2) + y(3) and so on...

Why not model the number of offspring at each age (i.e. y(x)), and  
then work out the consequences of this model for total number of  
offspring at a given age ?  For example, if the regression of y(x) on  
age is zero, then Y(x) increases linearly, and if the regression is  
negative it is decelerating etc.

Cheers,

Jarrod



Quoting "PATRICK, Samantha" <spatrick at glos.ac.uk> on Mon, 25 Aug 2014  
15:41:30 +0000:

> Hi Jarrod
>
> The structure of the data is:
>
> Y = Cumulative number of offspring.
> X = Age.  Age is mean centred so the intercept is at 22 years old.   
> This is where the intercepts are fitted and for each individual I  
> have an exact number of offspring at this age.
>
> I want to examine how the number of offspring increases with age.  I  
> am using random slopes to examine within individual changes with  
> age.  If I don't constrain the intercept at the individual level  
> then the slope does not represent the actual increase with age, and  
> you get results that are largely driven by the age at last sampling.  
>   If I constrain the intercepts, as I understand, the slope will  
> represent the actual increase in fitness with age for each individual.
>
> Happy to post data if this is not clear enough/it would help.
>
> Thanks
>
> Sam
>
>
> Dr Samantha Patrick
> Research Fellow
> Biosciences QU116
> Francis Close Hall Campus
> University of Gloucestershire
> Cheltenham, GL50 4AZ, UK
>
> Research Associate: OxNav, University of Oxford
>
> ******From 1st August - 14th November 2014 I will be
> based in Montr?al, which is 5 hours behind GMT  ******
>
> Tel: 07740 472 719
> Skype: sammy_patrick
> https://sites.google.com/site/samanthacpatrick/
>
> From: Jarrod Hadfield<mailto:j.hadfield at ed.ac.uk>
> Sent: ?Monday?, ?25? ?August? ?2014 ?11?:?33
> To: Samantha Patrick<mailto:spatrick at glos.ac.uk>
> Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
>
> Hi Sam,
>
> You could do this in MCMCglmm but it sounds like it might (possibly)
> be a bad idea. Could you give more details on how Y is actually
> obtained?
>
> Cheers,
>
> Jarrod
>
>
> Quoting "PATRICK, Samantha" <spatrick at glos.ac.uk> on Mon, 25 Aug 2014
> 15:16:27 +0000:
>
>> Hi All
>>
>> I am fitting a basic linear regression, where I want to estimate a
>> single population intercept and slope.  In addition I am fitting
>> random intercepts and slopes such that:
>>
>> lmer (Y ~Intercept + Continuous Variable + (Continuous Variable
>> |Indiviudal Group))
>>
>> However the exact value of the individual group intercepts is known
>> from the data set.  The reasons for this are a little involved but
>> essentially Y is a cumulative total and so at the intercept I want
>> to fit the actual cumulative total at this point for each
>> individual.  It is important as the slope per individual needs to be
>> constrained to pass through the actual intercept per individual.
>>
>> So I want to fit this model, estimating the population intercept and
>> slope.  I then want to fix the individual group deviation from the
>> population intercept (random intercepts), and from this model
>> extract estimates of individual group random slopes.
>>
>> I have been unable to find any examples of fixing intercepts, unless
>> they are fixed as a constant.  Is it possible to code the model in
>> such a way? The model can be run in MCMCglmm or lmer  which ever
>> package would allow me to constrain the intercepts.
>>
>> Thanks
>>
>> Sam?
>>
>>
>> Dr Samantha Patrick
>> Research Fellow
>> Biosciences QU116
>> Francis Close Hall Campus
>> University of Gloucestershire
>> Cheltenham, GL50 4AZ, UK
>>
>> Research Associate: OxNav, University of Oxford
>>
>> ******From 1st August - 14th November 2014 I will be
>> based in Montr?al, which is 5 hours behind GMT  ******
>>
>> Tel: 07740 472 719
>> Skype: sammy_patrick
>> https://sites.google.com/site/samanthacpatrick/
>>
>> -
>> ?In the top 5 in the Green League Table; committed to sustainability?
>> This email is confidential to the intended recipient. If you have
>> received it in error please notify the sender and delete it from
>> your computer.
>> The University of Gloucestershire is a company limited by guarantee
>> registered in England and Wales.  Registered number: 06023243.
>> Registered office: The Park, Cheltenham, GL50 2RH
>> Please consider the environment before printing this email.
>> -
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>
> -
> ?In the top 5 in the Green League Table; committed to sustainability?
> This email is confidential to the intended recipient. If you have  
> received it in error please notify the sender and delete it from  
> your computer.
> The University of Gloucestershire is a company limited by guarantee  
> registered in England and Wales.  Registered number: 06023243.   
> Registered office: The Park, Cheltenham, GL50 2RH
> Please consider the environment before printing this email.
> -
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From rubenarslan at gmail.com  Mon Aug 25 18:00:08 2014
From: rubenarslan at gmail.com (Ruben Arslan)
Date: Mon, 25 Aug 2014 18:00:08 +0200
Subject: [R-sig-ME] parallel MCMCglmm, RNGstreams,
	starting values & priors
In-Reply-To: <20140825162907.10475jpywlu1wzs4@www.staffmail.ed.ac.uk>
References: <4CD76FE1-D3F5-4980-9122-B0AC0D44FF81@gmail.com>
	<0E12EB43-72BC-42AC-9E74-9DF53DB42217@gmail.com>
	<20140825162907.10475jpywlu1wzs4@www.staffmail.ed.ac.uk>
Message-ID: <0A463095-8656-49B7-9619-E557DD449E21@gmail.com>

Dear Jarrod,

thanks for the quick reply. Please, don't waste time looking into doMPI ? I am happy that I
get the expected result, when I specify that reproducible seed, whyever that may be. 
I'm pretty sure that is the deciding factor, because I tested it explicitly, I just have no idea
how/why it interacts with the choice of family. 

That said, is setting up different RNG streams for my workers (now that it works) __sufficient__ 
so that I get independent chains and can use gelman.diag() for convergence diagnostics? 
Or should I still tinker with the starting values myself? 
I've never found a worked example of supplying starting values and am thus a bit lost.

Sorry for sending further questions, I hope someone else takes pity while 
you're busy with lectures.

Best wishes

Ruben



On 25 Aug 2014, at 17:29, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:

> Hi Ruben,
> 
> I do not think the issue is with the starting values, because even if the same starting values were used the chains would still differ because of the randomness in the Markov Chain (if I interpret your `identical' test correctly). This just involves a call to GetRNGstate() in the C++ code (L 871 ofMCMCglmm.cc) so I think for some reason doMPI/foreach is not doing what you expect. I am not familiar with doMPI and am in the middle of writing lectures so haven't got time to look into it carefully. Outside of the context of doMPI I get the behaviour I expect:
> 
> 
> l<-rnorm(200, -1, sqrt(1))
> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
> y<-rpois(200,exp(l)-t)+1
> # generate zero-truncated data with an intercept of -1
> 
> dat<-data.frame(y=y)
> set.seed(1)
> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat)
> set.seed(2)
> m2<-MCMCglmm(y~1, family="ztpoisson", data=dat)
> set.seed(2)
> m3<-MCMCglmm(y~1, family="ztpoisson", data=dat)
> 
> plot(mcmc.list(m1$Sol, m2$Sol))
> # different, as expected
> plot(mcmc.list(m2$Sol, m3$Sol))
> # the same, as expected
> 
> 
> 
> 
> 
> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25 Aug 2014 16:58:06 +0200:
> 
>> Dear list,
>> 
>> sorry for bumping my old post, I hope to elicit a response with a more focused question:
>> 
>> When does MCMCglmm automatically start from different values when using doMPI/foreach?
>> 
>> I have done some tests with models of varying complexity. For example, the script in my last
>> post (using "zapoisson") yielded 40 identical chains:
>>> identical(mcmclist[1], mcmclist[30])
>> TRUE
>> 
>> A simpler (?) model (using "ztpoisson" and no specified prior), however, yielded different chains
>> and I could use them to calculate gelman.diag()
>> 
>> Changing my script to the version below, i.e. seeding foreach using .options.mpi=list( seed= 1337)
>> so as to make RNGstreams reproducible (or so I  thought), led to different chains even for the
>> "zapoisson" model.
>> 
>> In no case have I (successfully) tried to supplant the default of MCMCglmm's "start" argument.
>> Is starting my models from different RNGsubstreams inadequate compared to manipulating
>> the start argument explicitly? If so, is there any worked example of explicit starting value manipulation
>> in parallel computation?
>> I've browsed the MCMCglmm source to understand how the default starting values are generated,
>> but didn't find any differences with respect to RNG for the two families "ztpoisson" and "zapoisson"
>> (granted, I did not dig very deep).
>> 
>> Best regards,
>> 
>> Ruben Arslan
>> 
>> 
>> # bsub -q mpi -W 12:00 -n 41 -R np20 mpirun -H localhost -n 41 R --slave -f "/usr/users/rarslan/rpqa/rpqa_main/rpqa_children_parallel.R"
>> 
>> library(doMPI)
>> cl <- startMPIcluster(verbose=T,workdir="/usr/users/rarslan/rpqa/rpqa_main/")
>> registerDoMPI(cl)
>> Children_mcmc1 = foreach(i=1:clusterSize(cl),.options.mpi = list(seed=1337) ) %dopar% {
>> 	library(MCMCglmm);library(data.table)
>> 	load("/usr/users/rarslan/rpqa/rpqa1.rdata")
>> 
>> 	nitt = 130000; thin = 100; burnin = 30000
>> 	prior.m5d.2 = list(
>> 		R = list(V = diag(c(1,1)), nu = 0.002),
>> 		G=list(list(V=diag(c(1,1e-6)),nu=0.002))
>> 	)
>> 
>> 	rpqa.1 = na.omit(rpqa.1[spouses>0, list(idParents, children, male, urban, spouses, paternalage.mean, paternalage.factor)])
>> 	(m1 = MCMCglmm( children ~ trait * (male + urban + spouses + paternalage.mean + paternalage.factor),
>> 						rcov=~us(trait):units,
>> 						random=~us(trait):idParents,
>> 						family="zapoisson",
>> 						prior = prior.m5d.2,
>> 						data=rpqa.1,
>> 						pr = F, saveX = F, saveZ = F,
>> 						nitt=nitt,thin=thin,burnin=burnin))
>> }
>> 
>> library(coda)
>> mcmclist = mcmc.list(lapply(Children_mcmc1,FUN=function(x) { x$Sol}))
>> save(Children_mcmc1,mcmclist, file = "/usr/users/rarslan/rpqa/rpqa_main/rpqa_mcmc_kids_za.rdata")
>> closeCluster(cl)
>> mpi.quit()
>> 
>> 
>> 
>> On 04 Aug 2014, at 20:25, Ruben Arslan <rubenarslan at gmail.com> wrote:
>> 
>>> Dear list,
>>> 
>>> would someone be willing to share her or his efforts in parallelising a MCMCglmm analysis?
>>> 
>>> I had something viable using harvestr that seemed to properly initialise
>>> the starting values from different random number streams (which is desirable,
>>> as far as I could find out), but I ended up being unable to use harvestr, because
>>> it uses an old version of plyr, where parallelisation works only for multicore, not for
>>> MPI.
>>> 
>>> I pasted my working version, that does not do anything about starting values or RNG
>>> at the end of this email. I can try to fumble further in the dark or try to update harvestr,
>>> but maybe someone has gone through all this already.
>>> 
>>> I'd also appreciate any tips for elegantly post-processing such parallel data, as some of my usual
>>> extraction functions and routines are hampered by the fact that some coda functions
>>> do not aggregate results over chains. (What I get from a single-chain summary in MCMCglmm
>>> is a bit more comprehensive, than what I managed to cobble together with my own extraction
>>> functions).
>>> 
>>> The reason I'm parallelising my analyses is that I'm having trouble getting a good effective
>>> sample size for any parameter having to do with the many zeroes in my data.
>>> Any pointers are very appreciated, I'm quite inexperienced with MCMCglmm.
>>> 
>>> Best wishes
>>> 
>>> Ruben
>>> 
>>> # bsub -q mpi-short -W 2:00 -n 42 -R np20 mpirun -H localhost -n 41 R --slave -f "rpqa/rpqa_main/rpqa_children_parallel.r"
>>> library(doMPI)
>>> cl <- startMPIcluster()
>>> registerDoMPI(cl)
>>> Children_mcmc1 = foreach(i=1:40) %dopar% {
>>> 	library(MCMCglmm)
>>> 	load("rpqa1.rdata")
>>> 
>>> 	nitt = 40000; thin = 100; burnin = 10000
>>> 	prior = list(
>>> 		R = list(V = diag(c(1,1)), nu = 0.002),
>>> 		G=list(list(V=diag(c(1,1e-6)),nu=0.002))
>>> 	)
>>> 
>>> 	MCMCglmm( children ~ trait -1 + at.level(trait,1):male + at.level(trait,1):urban + at.level(trait,1):spouses + at.level(trait,1):paternalage.mean + at.level(trait,1):paternalage.factor,
>>> 		rcov=~us(trait):units,
>>> 		random=~us(trait):idParents,
>>> 		family="zapoisson",
>>> 		prior = prior,
>>> 		data=rpqa.1,
>>> 		pr = F, saveX = T, saveZ = T,
>>> 		nitt=nitt,thin=thin,burnin=burnin)
>>> }
>>> 
>>> library(coda)
>>> mcmclist = mcmc.list(lapply(Children_mcmc1,FUN=function(x) { x$Sol}))
>>> save(Children_mcmc1,mcmclist, file = "rpqa_mcmc_kids_za.rdata")
>>> closeCluster(cl)
>>> mpi.quit()
>>> 
>>> 
>>> --
>>> Ruben C. Arslan
>>> 
>>> Georg August University G?ttingen
>>> Biological Personality Psychology and Psychological Assessment
>>> Georg Elias M?ller Institute of Psychology
>>> Go?lerstr. 14
>>> 37073 G?ttingen
>>> Germany
>>> Tel.: +49 551 3920704
>>> https://psych.uni-goettingen.de/en/biopers/team/arslan
>>> 
>>> 
>>> 
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> 
> 
> 
> 
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.


	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Aug 25 18:06:37 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 25 Aug 2014 12:06:37 -0400
Subject: [R-sig-ME] How to fix the value of random intercepts
	(lmer/MCMCglmm)
In-Reply-To: <20140825163316.123943xivaifhwsg@www.staffmail.ed.ac.uk>
References: <048718e40aa941909a85c46e6e979df6@glos.ac.uk>
	<20140825163316.123943xivaifhwsg@www.staffmail.ed.ac.uk>
Message-ID: <53FB5F0D.8010003@gmail.com>

  Fitting a cumulative distribution is sometimes statistically dicey,
since the successive values will be correlated; is there a reason you
can't take first differences?

  Technically speaking, to do this in lme4 I think you would want to use
a slope-only model and include an intercept for individuals as an offset:

lmer (Y ~Intercept + Continuous Variable +
    offset(indiv_intercept)+
   (Continuous Variable +0|Individual)




On 14-08-25 11:33 AM, Jarrod Hadfield wrote:
> Hi Sam,
> 
> You could do this in MCMCglmm but it sounds like it might (possibly) be
> a bad idea. Could you give more details on how Y is actually obtained?
> 
> Cheers,
> 
> Jarrod
> 
> 
> Quoting "PATRICK, Samantha" <spatrick at glos.ac.uk> on Mon, 25 Aug 2014
> 15:16:27 +0000:
> 
>> Hi All
>>
>> I am fitting a basic linear regression, where I want to estimate a
>> single population intercept and slope.  In addition I am fitting
>> random intercepts and slopes such that:
>>
>> lmer (Y ~Intercept + Continuous Variable + (Continuous Variable
>> |Indiviudal Group))
>>
>> However the exact value of the individual group intercepts is known
>> from the data set.  The reasons for this are a little involved but
>> essentially Y is a cumulative total and so at the intercept I want to
>> fit the actual cumulative total at this point for each individual.  It
>> is important as the slope per individual needs to be constrained to
>> pass through the actual intercept per individual.
>>
>> So I want to fit this model, estimating the population intercept and
>> slope.  I then want to fix the individual group deviation from the
>> population intercept (random intercepts), and from this model extract
>> estimates of individual group random slopes.
>>
>> I have been unable to find any examples of fixing intercepts, unless
>> they are fixed as a constant.  Is it possible to code the model in
>> such a way? The model can be run in MCMCglmm or lmer  which ever
>> package would allow me to constrain the intercepts.
>>
>> Thanks
>>
>> Sam?
>>
>>
>> Dr Samantha Patrick
>> Research Fellow
>> Biosciences QU116
>> Francis Close Hall Campus
>> University of Gloucestershire
>> Cheltenham, GL50 4AZ, UK
>>
>> Research Associate: OxNav, University of Oxford
>>


From steve.walker at utoronto.ca  Mon Aug 25 18:14:09 2014
From: steve.walker at utoronto.ca (Steve Walker)
Date: Mon, 25 Aug 2014 12:14:09 -0400
Subject: [R-sig-ME] How to fix the value of random intercepts
	(lmer/MCMCglmm)
In-Reply-To: <53FB5F0D.8010003@gmail.com>
References: <048718e40aa941909a85c46e6e979df6@glos.ac.uk>	<20140825163316.123943xivaifhwsg@www.staffmail.ed.ac.uk>
	<53FB5F0D.8010003@gmail.com>
Message-ID: <53FB60D1.10401@utoronto.ca>

On 2014-08-25, 12:06 PM, Ben Bolker wrote:
>    Fitting a cumulative distribution is sometimes statistically dicey,
> since the successive values will be correlated; is there a reason you
> can't take first differences?
>
>    Technically speaking, to do this in lme4 I think you would want to use
> a slope-only model and include an intercept for individuals as an offset:
>
> lmer (Y ~Intercept + Continuous Variable +
>      offset(indiv_intercept)+
>     (Continuous Variable +0|Individual)
>

In case its useful, you can compute the `indiv_intercept` variable with 
(for example),

set.seed(1)
(individual <- factor(rep(letters[1:5], 4)))
(intercepts <- setNames(rnorm(5), letters[1:5]))
intercepts[as.character(individual)]

Cheers,
Steve

>
>
>
> On 14-08-25 11:33 AM, Jarrod Hadfield wrote:
>> Hi Sam,
>>
>> You could do this in MCMCglmm but it sounds like it might (possibly) be
>> a bad idea. Could you give more details on how Y is actually obtained?
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>> Quoting "PATRICK, Samantha" <spatrick at glos.ac.uk> on Mon, 25 Aug 2014
>> 15:16:27 +0000:
>>
>>> Hi All
>>>
>>> I am fitting a basic linear regression, where I want to estimate a
>>> single population intercept and slope.  In addition I am fitting
>>> random intercepts and slopes such that:
>>>
>>> lmer (Y ~Intercept + Continuous Variable + (Continuous Variable
>>> |Indiviudal Group))
>>>
>>> However the exact value of the individual group intercepts is known
>>> from the data set.  The reasons for this are a little involved but
>>> essentially Y is a cumulative total and so at the intercept I want to
>>> fit the actual cumulative total at this point for each individual.  It
>>> is important as the slope per individual needs to be constrained to
>>> pass through the actual intercept per individual.
>>>
>>> So I want to fit this model, estimating the population intercept and
>>> slope.  I then want to fix the individual group deviation from the
>>> population intercept (random intercepts), and from this model extract
>>> estimates of individual group random slopes.
>>>
>>> I have been unable to find any examples of fixing intercepts, unless
>>> they are fixed as a constant.  Is it possible to code the model in
>>> such a way? The model can be run in MCMCglmm or lmer  which ever
>>> package would allow me to constrain the intercepts.
>>>
>>> Thanks
>>>
>>> Sam?
>>>
>>>
>>> Dr Samantha Patrick
>>> Research Fellow
>>> Biosciences QU116
>>> Francis Close Hall Campus
>>> University of Gloucestershire
>>> Cheltenham, GL50 4AZ, UK
>>>
>>> Research Associate: OxNav, University of Oxford
>>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From j.hadfield at ed.ac.uk  Mon Aug 25 18:14:14 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 25 Aug 2014 17:14:14 +0100
Subject: [R-sig-ME] parallel MCMCglmm, RNGstreams,
 starting values & priors
In-Reply-To: <0A463095-8656-49B7-9619-E557DD449E21@gmail.com>
References: <4CD76FE1-D3F5-4980-9122-B0AC0D44FF81@gmail.com>
	<0E12EB43-72BC-42AC-9E74-9DF53DB42217@gmail.com>
	<20140825162907.10475jpywlu1wzs4@www.staffmail.ed.ac.uk>
	<0A463095-8656-49B7-9619-E557DD449E21@gmail.com>
Message-ID: <20140825171414.10872gnlopk1we68@www.staffmail.ed.ac.uk>

Hi Ruben,

You will need to provide over-dispersed starting values for  
multiple-chain convergence diagnostics to be useful (GLMM are so  
simple I am generally happy if the output of a single run looks  
reasonable).

With non-Gaussian data everything is Gibbs sampled conditional on the  
latent variables, so you only need to pass them:

l<-rnorm(200, -1, sqrt(1))
t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
y<-rpois(200,exp(l)-t)+1
# generate zero-truncated data with an intercept of -1

dat<-data.frame(y=y)
set.seed(1)
m1<-MCMCglmm(y~1, family="ztpoisson", data=dat, start=list(Liab=l))
# use true latent variable as starting values
set.seed(1)
m2<-MCMCglmm(y~1, family="ztpoisson", data=dat, start=list(Liab=rnorm(200)))
# use some very bad starting values

plot(mcmc.list(m1$Sol, m2$Sol))
# not identical despite the same seed because of different starting  
values but clearly sampling the same posterior distribution:

gelman.diag(mcmc.list(m1$Sol, m2$Sol))

Cheers,

Jarrod

Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25 Aug 2014  
18:00:08 +0200:

> Dear Jarrod,
>
> thanks for the quick reply. Please, don't waste time looking into  
> doMPI ? I am happy that I
> get the expected result, when I specify that reproducible seed,  
> whyever that may be.
> I'm pretty sure that is the deciding factor, because I tested it  
> explicitly, I just have no idea
> how/why it interacts with the choice of family.
>
> That said, is setting up different RNG streams for my workers (now  
> that it works) __sufficient__
> so that I get independent chains and can use gelman.diag() for  
> convergence diagnostics?
> Or should I still tinker with the starting values myself?
> I've never found a worked example of supplying starting values and  
> am thus a bit lost.
>
> Sorry for sending further questions, I hope someone else takes pity while
> you're busy with lectures.
>
> Best wishes
>
> Ruben
>
>
>
> On 25 Aug 2014, at 17:29, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>
>> Hi Ruben,
>>
>> I do not think the issue is with the starting values, because even  
>> if the same starting values were used the chains would still differ  
>> because of the randomness in the Markov Chain (if I interpret your  
>> `identical' test correctly). This just involves a call to  
>> GetRNGstate() in the C++ code (L 871 ofMCMCglmm.cc) so I think for  
>> some reason doMPI/foreach is not doing what you expect. I am not  
>> familiar with doMPI and am in the middle of writing lectures so  
>> haven't got time to look into it carefully. Outside of the context  
>> of doMPI I get the behaviour I expect:
>>
>>
>> l<-rnorm(200, -1, sqrt(1))
>> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
>> y<-rpois(200,exp(l)-t)+1
>> # generate zero-truncated data with an intercept of -1
>>
>> dat<-data.frame(y=y)
>> set.seed(1)
>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>> set.seed(2)
>> m2<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>> set.seed(2)
>> m3<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>
>> plot(mcmc.list(m1$Sol, m2$Sol))
>> # different, as expected
>> plot(mcmc.list(m2$Sol, m3$Sol))
>> # the same, as expected
>>
>>
>>
>>
>>
>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25 Aug 2014  
>> 16:58:06 +0200:
>>
>>> Dear list,
>>>
>>> sorry for bumping my old post, I hope to elicit a response with a  
>>> more focused question:
>>>
>>> When does MCMCglmm automatically start from different values when  
>>> using doMPI/foreach?
>>>
>>> I have done some tests with models of varying complexity. For  
>>> example, the script in my last
>>> post (using "zapoisson") yielded 40 identical chains:
>>>> identical(mcmclist[1], mcmclist[30])
>>> TRUE
>>>
>>> A simpler (?) model (using "ztpoisson" and no specified prior),  
>>> however, yielded different chains
>>> and I could use them to calculate gelman.diag()
>>>
>>> Changing my script to the version below, i.e. seeding foreach  
>>> using .options.mpi=list( seed= 1337)
>>> so as to make RNGstreams reproducible (or so I  thought), led to  
>>> different chains even for the
>>> "zapoisson" model.
>>>
>>> In no case have I (successfully) tried to supplant the default of  
>>> MCMCglmm's "start" argument.
>>> Is starting my models from different RNGsubstreams inadequate  
>>> compared to manipulating
>>> the start argument explicitly? If so, is there any worked example  
>>> of explicit starting value manipulation
>>> in parallel computation?
>>> I've browsed the MCMCglmm source to understand how the default  
>>> starting values are generated,
>>> but didn't find any differences with respect to RNG for the two  
>>> families "ztpoisson" and "zapoisson"
>>> (granted, I did not dig very deep).
>>>
>>> Best regards,
>>>
>>> Ruben Arslan
>>>
>>>
>>> # bsub -q mpi -W 12:00 -n 41 -R np20 mpirun -H localhost -n 41 R  
>>> --slave -f  
>>> "/usr/users/rarslan/rpqa/rpqa_main/rpqa_children_parallel.R"
>>>
>>> library(doMPI)
>>> cl <-  
>>> startMPIcluster(verbose=T,workdir="/usr/users/rarslan/rpqa/rpqa_main/")
>>> registerDoMPI(cl)
>>> Children_mcmc1 = foreach(i=1:clusterSize(cl),.options.mpi =  
>>> list(seed=1337) ) %dopar% {
>>> 	library(MCMCglmm);library(data.table)
>>> 	load("/usr/users/rarslan/rpqa/rpqa1.rdata")
>>>
>>> 	nitt = 130000; thin = 100; burnin = 30000
>>> 	prior.m5d.2 = list(
>>> 		R = list(V = diag(c(1,1)), nu = 0.002),
>>> 		G=list(list(V=diag(c(1,1e-6)),nu=0.002))
>>> 	)
>>>
>>> 	rpqa.1 = na.omit(rpqa.1[spouses>0, list(idParents, children,  
>>> male, urban, spouses, paternalage.mean, paternalage.factor)])
>>> 	(m1 = MCMCglmm( children ~ trait * (male + urban + spouses +  
>>> paternalage.mean + paternalage.factor),
>>> 						rcov=~us(trait):units,
>>> 						random=~us(trait):idParents,
>>> 						family="zapoisson",
>>> 						prior = prior.m5d.2,
>>> 						data=rpqa.1,
>>> 						pr = F, saveX = F, saveZ = F,
>>> 						nitt=nitt,thin=thin,burnin=burnin))
>>> }
>>>
>>> library(coda)
>>> mcmclist = mcmc.list(lapply(Children_mcmc1,FUN=function(x) { x$Sol}))
>>> save(Children_mcmc1,mcmclist, file =  
>>> "/usr/users/rarslan/rpqa/rpqa_main/rpqa_mcmc_kids_za.rdata")
>>> closeCluster(cl)
>>> mpi.quit()
>>>
>>>
>>>
>>> On 04 Aug 2014, at 20:25, Ruben Arslan <rubenarslan at gmail.com> wrote:
>>>
>>>> Dear list,
>>>>
>>>> would someone be willing to share her or his efforts in  
>>>> parallelising a MCMCglmm analysis?
>>>>
>>>> I had something viable using harvestr that seemed to properly initialise
>>>> the starting values from different random number streams (which  
>>>> is desirable,
>>>> as far as I could find out), but I ended up being unable to use  
>>>> harvestr, because
>>>> it uses an old version of plyr, where parallelisation works only  
>>>> for multicore, not for
>>>> MPI.
>>>>
>>>> I pasted my working version, that does not do anything about  
>>>> starting values or RNG
>>>> at the end of this email. I can try to fumble further in the dark  
>>>> or try to update harvestr,
>>>> but maybe someone has gone through all this already.
>>>>
>>>> I'd also appreciate any tips for elegantly post-processing such  
>>>> parallel data, as some of my usual
>>>> extraction functions and routines are hampered by the fact that  
>>>> some coda functions
>>>> do not aggregate results over chains. (What I get from a  
>>>> single-chain summary in MCMCglmm
>>>> is a bit more comprehensive, than what I managed to cobble  
>>>> together with my own extraction
>>>> functions).
>>>>
>>>> The reason I'm parallelising my analyses is that I'm having  
>>>> trouble getting a good effective
>>>> sample size for any parameter having to do with the many zeroes  
>>>> in my data.
>>>> Any pointers are very appreciated, I'm quite inexperienced with MCMCglmm.
>>>>
>>>> Best wishes
>>>>
>>>> Ruben
>>>>
>>>> # bsub -q mpi-short -W 2:00 -n 42 -R np20 mpirun -H localhost -n  
>>>> 41 R --slave -f "rpqa/rpqa_main/rpqa_children_parallel.r"
>>>> library(doMPI)
>>>> cl <- startMPIcluster()
>>>> registerDoMPI(cl)
>>>> Children_mcmc1 = foreach(i=1:40) %dopar% {
>>>> 	library(MCMCglmm)
>>>> 	load("rpqa1.rdata")
>>>>
>>>> 	nitt = 40000; thin = 100; burnin = 10000
>>>> 	prior = list(
>>>> 		R = list(V = diag(c(1,1)), nu = 0.002),
>>>> 		G=list(list(V=diag(c(1,1e-6)),nu=0.002))
>>>> 	)
>>>>
>>>> 	MCMCglmm( children ~ trait -1 + at.level(trait,1):male +  
>>>> at.level(trait,1):urban + at.level(trait,1):spouses +  
>>>> at.level(trait,1):paternalage.mean +  
>>>> at.level(trait,1):paternalage.factor,
>>>> 		rcov=~us(trait):units,
>>>> 		random=~us(trait):idParents,
>>>> 		family="zapoisson",
>>>> 		prior = prior,
>>>> 		data=rpqa.1,
>>>> 		pr = F, saveX = T, saveZ = T,
>>>> 		nitt=nitt,thin=thin,burnin=burnin)
>>>> }
>>>>
>>>> library(coda)
>>>> mcmclist = mcmc.list(lapply(Children_mcmc1,FUN=function(x) { x$Sol}))
>>>> save(Children_mcmc1,mcmclist, file = "rpqa_mcmc_kids_za.rdata")
>>>> closeCluster(cl)
>>>> mpi.quit()
>>>>
>>>>
>>>> --
>>>> Ruben C. Arslan
>>>>
>>>> Georg August University G?ttingen
>>>> Biological Personality Psychology and Psychological Assessment
>>>> Georg Elias M?ller Institute of Psychology
>>>> Go?lerstr. 14
>>>> 37073 G?ttingen
>>>> Germany
>>>> Tel.: +49 551 3920704
>>>> https://psych.uni-goettingen.de/en/biopers/team/arslan
>>>>
>>>>
>>>>
>>>
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>>
>>
>>
>>
>> --
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From j.hadfield at ed.ac.uk  Mon Aug 25 18:29:36 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 25 Aug 2014 17:29:36 +0100
Subject: [R-sig-ME] parallel MCMCglmm, RNGstreams,
 starting values & priors
In-Reply-To: <20140825171414.10872gnlopk1we68@www.staffmail.ed.ac.uk>
References: <4CD76FE1-D3F5-4980-9122-B0AC0D44FF81@gmail.com>
	<0E12EB43-72BC-42AC-9E74-9DF53DB42217@gmail.com>
	<20140825162907.10475jpywlu1wzs4@www.staffmail.ed.ac.uk>
	<0A463095-8656-49B7-9619-E557DD449E21@gmail.com>
	<20140825171414.10872gnlopk1we68@www.staffmail.ed.ac.uk>
Message-ID: <20140825172936.15916weehiwjyc08@www.staffmail.ed.ac.uk>

Hi Ruben,

Sorry  - I was wrong when I said that everything is Gibbs sampled  
conditional on the latent variables. The location effects (fixed and  
random effects) are also sampled conditional on the (co)variance  
components so you should add them to the starting values. In the case  
where the true values are used:

m1<-MCMCglmm(y~1, family="ztpoisson", data=dat, start=list(Liab=l,R=1))

Cheers,

Jarrod



Quoting Jarrod Hadfield <j.hadfield at ed.ac.uk> on Mon, 25 Aug 2014  
17:14:14 +0100:

> Hi Ruben,
>
> You will need to provide over-dispersed starting values for  
> multiple-chain convergence diagnostics to be useful (GLMM are so  
> simple I am generally happy if the output of a single run looks  
> reasonable).
>
> With non-Gaussian data everything is Gibbs sampled conditional on  
> the latent variables, so you only need to pass them:
>
> l<-rnorm(200, -1, sqrt(1))
> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
> y<-rpois(200,exp(l)-t)+1
> # generate zero-truncated data with an intercept of -1
>
> dat<-data.frame(y=y)
> set.seed(1)
> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat, start=list(Liab=l))
> # use true latent variable as starting values
> set.seed(1)
> m2<-MCMCglmm(y~1, family="ztpoisson", data=dat, start=list(Liab=rnorm(200)))
> # use some very bad starting values
>
> plot(mcmc.list(m1$Sol, m2$Sol))
> # not identical despite the same seed because of different starting  
> values but clearly sampling the same posterior distribution:
>
> gelman.diag(mcmc.list(m1$Sol, m2$Sol))
>
> Cheers,
>
> Jarrod
>
> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25 Aug 2014  
> 18:00:08 +0200:
>
>> Dear Jarrod,
>>
>> thanks for the quick reply. Please, don't waste time looking into  
>> doMPI ? I am happy that I
>> get the expected result, when I specify that reproducible seed,  
>> whyever that may be.
>> I'm pretty sure that is the deciding factor, because I tested it  
>> explicitly, I just have no idea
>> how/why it interacts with the choice of family.
>>
>> That said, is setting up different RNG streams for my workers (now  
>> that it works) __sufficient__
>> so that I get independent chains and can use gelman.diag() for  
>> convergence diagnostics?
>> Or should I still tinker with the starting values myself?
>> I've never found a worked example of supplying starting values and  
>> am thus a bit lost.
>>
>> Sorry for sending further questions, I hope someone else takes pity while
>> you're busy with lectures.
>>
>> Best wishes
>>
>> Ruben
>>
>>
>>
>> On 25 Aug 2014, at 17:29, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>
>>> Hi Ruben,
>>>
>>> I do not think the issue is with the starting values, because even  
>>> if the same starting values were used the chains would still  
>>> differ because of the randomness in the Markov Chain (if I  
>>> interpret your `identical' test correctly). This just involves a  
>>> call to GetRNGstate() in the C++ code (L 871 ofMCMCglmm.cc) so I  
>>> think for some reason doMPI/foreach is not doing what you expect.  
>>> I am not familiar with doMPI and am in the middle of writing  
>>> lectures so haven't got time to look into it carefully. Outside of  
>>> the context of doMPI I get the behaviour I expect:
>>>
>>>
>>> l<-rnorm(200, -1, sqrt(1))
>>> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
>>> y<-rpois(200,exp(l)-t)+1
>>> # generate zero-truncated data with an intercept of -1
>>>
>>> dat<-data.frame(y=y)
>>> set.seed(1)
>>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>> set.seed(2)
>>> m2<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>> set.seed(2)
>>> m3<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>
>>> plot(mcmc.list(m1$Sol, m2$Sol))
>>> # different, as expected
>>> plot(mcmc.list(m2$Sol, m3$Sol))
>>> # the same, as expected
>>>
>>>
>>>
>>>
>>>
>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25 Aug 2014  
>>> 16:58:06 +0200:
>>>
>>>> Dear list,
>>>>
>>>> sorry for bumping my old post, I hope to elicit a response with a  
>>>> more focused question:
>>>>
>>>> When does MCMCglmm automatically start from different values when  
>>>> using doMPI/foreach?
>>>>
>>>> I have done some tests with models of varying complexity. For  
>>>> example, the script in my last
>>>> post (using "zapoisson") yielded 40 identical chains:
>>>>> identical(mcmclist[1], mcmclist[30])
>>>> TRUE
>>>>
>>>> A simpler (?) model (using "ztpoisson" and no specified prior),  
>>>> however, yielded different chains
>>>> and I could use them to calculate gelman.diag()
>>>>
>>>> Changing my script to the version below, i.e. seeding foreach  
>>>> using .options.mpi=list( seed= 1337)
>>>> so as to make RNGstreams reproducible (or so I  thought), led to  
>>>> different chains even for the
>>>> "zapoisson" model.
>>>>
>>>> In no case have I (successfully) tried to supplant the default of  
>>>> MCMCglmm's "start" argument.
>>>> Is starting my models from different RNGsubstreams inadequate  
>>>> compared to manipulating
>>>> the start argument explicitly? If so, is there any worked example  
>>>> of explicit starting value manipulation
>>>> in parallel computation?
>>>> I've browsed the MCMCglmm source to understand how the default  
>>>> starting values are generated,
>>>> but didn't find any differences with respect to RNG for the two  
>>>> families "ztpoisson" and "zapoisson"
>>>> (granted, I did not dig very deep).
>>>>
>>>> Best regards,
>>>>
>>>> Ruben Arslan
>>>>
>>>>
>>>> # bsub -q mpi -W 12:00 -n 41 -R np20 mpirun -H localhost -n 41 R  
>>>> --slave -f  
>>>> "/usr/users/rarslan/rpqa/rpqa_main/rpqa_children_parallel.R"
>>>>
>>>> library(doMPI)
>>>> cl <-  
>>>> startMPIcluster(verbose=T,workdir="/usr/users/rarslan/rpqa/rpqa_main/")
>>>> registerDoMPI(cl)
>>>> Children_mcmc1 = foreach(i=1:clusterSize(cl),.options.mpi =  
>>>> list(seed=1337) ) %dopar% {
>>>> 	library(MCMCglmm);library(data.table)
>>>> 	load("/usr/users/rarslan/rpqa/rpqa1.rdata")
>>>>
>>>> 	nitt = 130000; thin = 100; burnin = 30000
>>>> 	prior.m5d.2 = list(
>>>> 		R = list(V = diag(c(1,1)), nu = 0.002),
>>>> 		G=list(list(V=diag(c(1,1e-6)),nu=0.002))
>>>> 	)
>>>>
>>>> 	rpqa.1 = na.omit(rpqa.1[spouses>0, list(idParents, children,  
>>>> male, urban, spouses, paternalage.mean, paternalage.factor)])
>>>> 	(m1 = MCMCglmm( children ~ trait * (male + urban + spouses +  
>>>> paternalage.mean + paternalage.factor),
>>>> 						rcov=~us(trait):units,
>>>> 						random=~us(trait):idParents,
>>>> 						family="zapoisson",
>>>> 						prior = prior.m5d.2,
>>>> 						data=rpqa.1,
>>>> 						pr = F, saveX = F, saveZ = F,
>>>> 						nitt=nitt,thin=thin,burnin=burnin))
>>>> }
>>>>
>>>> library(coda)
>>>> mcmclist = mcmc.list(lapply(Children_mcmc1,FUN=function(x) { x$Sol}))
>>>> save(Children_mcmc1,mcmclist, file =  
>>>> "/usr/users/rarslan/rpqa/rpqa_main/rpqa_mcmc_kids_za.rdata")
>>>> closeCluster(cl)
>>>> mpi.quit()
>>>>
>>>>
>>>>
>>>> On 04 Aug 2014, at 20:25, Ruben Arslan <rubenarslan at gmail.com> wrote:
>>>>
>>>>> Dear list,
>>>>>
>>>>> would someone be willing to share her or his efforts in  
>>>>> parallelising a MCMCglmm analysis?
>>>>>
>>>>> I had something viable using harvestr that seemed to properly initialise
>>>>> the starting values from different random number streams (which  
>>>>> is desirable,
>>>>> as far as I could find out), but I ended up being unable to use  
>>>>> harvestr, because
>>>>> it uses an old version of plyr, where parallelisation works only  
>>>>> for multicore, not for
>>>>> MPI.
>>>>>
>>>>> I pasted my working version, that does not do anything about  
>>>>> starting values or RNG
>>>>> at the end of this email. I can try to fumble further in the  
>>>>> dark or try to update harvestr,
>>>>> but maybe someone has gone through all this already.
>>>>>
>>>>> I'd also appreciate any tips for elegantly post-processing such  
>>>>> parallel data, as some of my usual
>>>>> extraction functions and routines are hampered by the fact that  
>>>>> some coda functions
>>>>> do not aggregate results over chains. (What I get from a  
>>>>> single-chain summary in MCMCglmm
>>>>> is a bit more comprehensive, than what I managed to cobble  
>>>>> together with my own extraction
>>>>> functions).
>>>>>
>>>>> The reason I'm parallelising my analyses is that I'm having  
>>>>> trouble getting a good effective
>>>>> sample size for any parameter having to do with the many zeroes  
>>>>> in my data.
>>>>> Any pointers are very appreciated, I'm quite inexperienced with MCMCglmm.
>>>>>
>>>>> Best wishes
>>>>>
>>>>> Ruben
>>>>>
>>>>> # bsub -q mpi-short -W 2:00 -n 42 -R np20 mpirun -H localhost -n  
>>>>> 41 R --slave -f "rpqa/rpqa_main/rpqa_children_parallel.r"
>>>>> library(doMPI)
>>>>> cl <- startMPIcluster()
>>>>> registerDoMPI(cl)
>>>>> Children_mcmc1 = foreach(i=1:40) %dopar% {
>>>>> 	library(MCMCglmm)
>>>>> 	load("rpqa1.rdata")
>>>>>
>>>>> 	nitt = 40000; thin = 100; burnin = 10000
>>>>> 	prior = list(
>>>>> 		R = list(V = diag(c(1,1)), nu = 0.002),
>>>>> 		G=list(list(V=diag(c(1,1e-6)),nu=0.002))
>>>>> 	)
>>>>>
>>>>> 	MCMCglmm( children ~ trait -1 + at.level(trait,1):male +  
>>>>> at.level(trait,1):urban + at.level(trait,1):spouses +  
>>>>> at.level(trait,1):paternalage.mean +  
>>>>> at.level(trait,1):paternalage.factor,
>>>>> 		rcov=~us(trait):units,
>>>>> 		random=~us(trait):idParents,
>>>>> 		family="zapoisson",
>>>>> 		prior = prior,
>>>>> 		data=rpqa.1,
>>>>> 		pr = F, saveX = T, saveZ = T,
>>>>> 		nitt=nitt,thin=thin,burnin=burnin)
>>>>> }
>>>>>
>>>>> library(coda)
>>>>> mcmclist = mcmc.list(lapply(Children_mcmc1,FUN=function(x) { x$Sol}))
>>>>> save(Children_mcmc1,mcmclist, file = "rpqa_mcmc_kids_za.rdata")
>>>>> closeCluster(cl)
>>>>> mpi.quit()
>>>>>
>>>>>
>>>>> --
>>>>> Ruben C. Arslan
>>>>>
>>>>> Georg August University G?ttingen
>>>>> Biological Personality Psychology and Psychological Assessment
>>>>> Georg Elias M?ller Institute of Psychology
>>>>> Go?lerstr. 14
>>>>> 37073 G?ttingen
>>>>> Germany
>>>>> Tel.: +49 551 3920704
>>>>> https://psych.uni-goettingen.de/en/biopers/team/arslan
>>>>>
>>>>>
>>>>>
>>>>
>>>>
>>>> 	[[alternative HTML version deleted]]
>>>>
>>>>
>>>
>>>
>>>
>>> --
>>> The University of Edinburgh is a charitable body, registered in
>>> Scotland, with registration number SC005336.
>>
>>
>
>
>
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From rubenarslan at gmail.com  Mon Aug 25 21:52:30 2014
From: rubenarslan at gmail.com (Ruben Arslan)
Date: Mon, 25 Aug 2014 21:52:30 +0200
Subject: [R-sig-ME] parallel MCMCglmm, RNGstreams,
	starting values & priors
In-Reply-To: <8D35B834-0D31-486A-B5FB-0F279761FDB2@gmail.com>
References: <4CD76FE1-D3F5-4980-9122-B0AC0D44FF81@gmail.com>
	<0E12EB43-72BC-42AC-9E74-9DF53DB42217@gmail.com>
	<20140825162907.10475jpywlu1wzs4@www.staffmail.ed.ac.uk>
	<0A463095-8656-49B7-9619-E557DD449E21@gmail.com>
	<20140825171414.10872gnlopk1we68@www.staffmail.ed.ac.uk>
	<20140825172936.15916weehiwjyc08@www.staffmail.ed.ac.uk>
	<8D35B834-0D31-486A-B5FB-0F279761FDB2@gmail.com>
Message-ID: <49D60399-6902-45AC-80A9-9F3C35532228@gmail.com>

Hi Jarrod,

thanks for these pointers. 

>> You will need to provide over-dispersed starting values for multiple-chain convergence diagnostics to be useful (GLMM are so simple I am generally happy if the output of a single run looks reasonable).

Oh, I would be happy with single chains, but since computation would take weeks this way, I wanted to parallelise and I would use the multi-chain convergence as a criterion that my parallelisation was proper
and is as informative as a single long chain. There don't seem to be any such checks built-in ? I was analysing my 40 chains for a bit longer than I like to admit until I noticed they were identical (effectiveSize 
and summary.mcmc.list did not yell at me for this).

>> # use some very bad starting values
I get that these values are bad, but that is the goal for my multi-chain aim, right?

I can apply this to my zero-truncated model, but am again getting stuck with the zero-altered one.
Maybe I need only specify the Liab values for this? 
At least I'm getting nowhere with specifying R and G starting values here. When I got an error, I always
went to the MCMCglmm source to understand why the checks failed, but I didn't always understand
what was being checked and couldn't get it to work.

Here's a failing example:

l<-rnorm(200, -1, sqrt(1))
t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
g = sample(letters[1:10], size = 200, replace = T)
pred = rnorm(200)
y<-rpois(200,exp(l)-t)
y[1:40] = 0
# generate zero-altered data with an intercept of -1

dat<-data.frame(y=y, g = g, pred = pred)
set.seed(1)
start_true = list(Liab=l, R = 1, G = 1 )
m1<-MCMCglmm(y~1 + pred,random = ~ g, family="zapoisson",rcov=~us(trait):units, data=dat, start= start_true)

# use true latent variable as starting values
set.seed(1)
# use some very bad starting values
start_rand = list(Liab=rnorm(200), R = rpois(1, 1)+1, G = rpois(1, 1)+1 )
m2<-MCMCglmm(y~1 + pred,random = ~ g,rcov=~us(trait):units,  family="zapoisson", data=dat, start = start_rand)

Best,

Ruben

On 25 Aug 2014, at 18:29, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:

> Hi Ruben,
> 
> Sorry  - I was wrong when I said that everything is Gibbs sampled conditional on the latent variables. The location effects (fixed and random effects) are also sampled conditional on the (co)variance components so you should add them to the starting values. In the case where the true values are used:
> 
> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat, start=list(Liab=l,R=1))
> 
> Cheers,
> 
> Jarrod
> 
> 
> 
> Quoting Jarrod Hadfield <j.hadfield at ed.ac.uk> on Mon, 25 Aug 2014 17:14:14 +0100:
> 
>> Hi Ruben,
>> 
>> You will need to provide over-dispersed starting values for multiple-chain convergence diagnostics to be useful (GLMM are so simple I am generally happy if the output of a single run looks reasonable).
>> 
>> With non-Gaussian data everything is Gibbs sampled conditional on the latent variables, so you only need to pass them:
>> 
>> l<-rnorm(200, -1, sqrt(1))
>> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
>> y<-rpois(200,exp(l)-t)+1
>> # generate zero-truncated data with an intercept of -1
>> 
>> dat<-data.frame(y=y)
>> set.seed(1)
>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat, start=list(Liab=l))
>> # use true latent variable as starting values
>> set.seed(1)
>> m2<-MCMCglmm(y~1, family="ztpoisson", data=dat, start=list(Liab=rnorm(200)))
>> # use some very bad starting values
>> 
>> plot(mcmc.list(m1$Sol, m2$Sol))
>> # not identical despite the same seed because of different starting values but clearly sampling the same posterior distribution:
>> 
>> gelman.diag(mcmc.list(m1$Sol, m2$Sol))
>> 
>> Cheers,
>> 
>> Jarrod
>> 
>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25 Aug 2014 18:00:08 +0200:
>> 
>>> Dear Jarrod,
>>> 
>>> thanks for the quick reply. Please, don't waste time looking into doMPI ? I am happy that I
>>> get the expected result, when I specify that reproducible seed, whyever that may be.
>>> I'm pretty sure that is the deciding factor, because I tested it explicitly, I just have no idea
>>> how/why it interacts with the choice of family.
>>> 
>>> That said, is setting up different RNG streams for my workers (now that it works) __sufficient__
>>> so that I get independent chains and can use gelman.diag() for convergence diagnostics?
>>> Or should I still tinker with the starting values myself?
>>> I've never found a worked example of supplying starting values and am thus a bit lost.
>>> 
>>> Sorry for sending further questions, I hope someone else takes pity while
>>> you're busy with lectures.
>>> 
>>> Best wishes
>>> 
>>> Ruben
>>> 
>>> 
>>> 
>>> On 25 Aug 2014, at 17:29, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>> 
>>>> Hi Ruben,
>>>> 
>>>> I do not think the issue is with the starting values, because even if the same starting values were used the chains would still differ because of the randomness in the Markov Chain (if I interpret your `identical' test correctly). This just involves a call to GetRNGstate() in the C++ code (L 871 ofMCMCglmm.cc) so I think for some reason doMPI/foreach is not doing what you expect. I am not familiar with doMPI and am in the middle of writing lectures so haven't got time to look into it carefully. Outside of the context of doMPI I get the behaviour I expect:
>>>> 
>>>> 
>>>> l<-rnorm(200, -1, sqrt(1))
>>>> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
>>>> y<-rpois(200,exp(l)-t)+1
>>>> # generate zero-truncated data with an intercept of -1
>>>> 
>>>> dat<-data.frame(y=y)
>>>> set.seed(1)
>>>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>> set.seed(2)
>>>> m2<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>> set.seed(2)
>>>> m3<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>> 
>>>> plot(mcmc.list(m1$Sol, m2$Sol))
>>>> # different, as expected
>>>> plot(mcmc.list(m2$Sol, m3$Sol))
>>>> # the same, as expected
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25 Aug 2014 16:58:06 +0200:
>>>> 
>>>>> Dear list,
>>>>> 
>>>>> sorry for bumping my old post, I hope to elicit a response with a more focused question:
>>>>> 
>>>>> When does MCMCglmm automatically start from different values when using doMPI/foreach?
>>>>> 
>>>>> I have done some tests with models of varying complexity. For example, the script in my last
>>>>> post (using "zapoisson") yielded 40 identical chains:
>>>>>> identical(mcmclist[1], mcmclist[30])
>>>>> TRUE
>>>>> 
>>>>> A simpler (?) model (using "ztpoisson" and no specified prior), however, yielded different chains
>>>>> and I could use them to calculate gelman.diag()
>>>>> 
>>>>> Changing my script to the version below, i.e. seeding foreach using .options.mpi=list( seed= 1337)
>>>>> so as to make RNGstreams reproducible (or so I  thought), led to different chains even for the
>>>>> "zapoisson" model.
>>>>> 
>>>>> In no case have I (successfully) tried to supplant the default of MCMCglmm's "start" argument.
>>>>> Is starting my models from different RNGsubstreams inadequate compared to manipulating
>>>>> the start argument explicitly? If so, is there any worked example of explicit starting value manipulation
>>>>> in parallel computation?
>>>>> I've browsed the MCMCglmm source to understand how the default starting values are generated,
>>>>> but didn't find any differences with respect to RNG for the two families "ztpoisson" and "zapoisson"
>>>>> (granted, I did not dig very deep).
>>>>> 
>>>>> Best regards,
>>>>> 
>>>>> Ruben Arslan
>>>>> 
>>>>> 
>>>>> # bsub -q mpi -W 12:00 -n 41 -R np20 mpirun -H localhost -n 41 R --slave -f "/usr/users/rarslan/rpqa/rpqa_main/rpqa_children_parallel.R"
>>>>> 
>>>>> library(doMPI)
>>>>> cl <- startMPIcluster(verbose=T,workdir="/usr/users/rarslan/rpqa/rpqa_main/")
>>>>> registerDoMPI(cl)
>>>>> Children_mcmc1 = foreach(i=1:clusterSize(cl),.options.mpi = list(seed=1337) ) %dopar% {
>>>>> 	library(MCMCglmm);library(data.table)
>>>>> 	load("/usr/users/rarslan/rpqa/rpqa1.rdata")
>>>>> 
>>>>> 	nitt = 130000; thin = 100; burnin = 30000
>>>>> 	prior.m5d.2 = list(
>>>>> 		R = list(V = diag(c(1,1)), nu = 0.002),
>>>>> 		G=list(list(V=diag(c(1,1e-6)),nu=0.002))
>>>>> 	)
>>>>> 
>>>>> 	rpqa.1 = na.omit(rpqa.1[spouses>0, list(idParents, children, male, urban, spouses, paternalage.mean, paternalage.factor)])
>>>>> 	(m1 = MCMCglmm( children ~ trait * (male + urban + spouses + paternalage.mean + paternalage.factor),
>>>>> 						rcov=~us(trait):units,
>>>>> 						random=~us(trait):idParents,
>>>>> 						family="zapoisson",
>>>>> 						prior = prior.m5d.2,
>>>>> 						data=rpqa.1,
>>>>> 						pr = F, saveX = F, saveZ = F,
>>>>> 						nitt=nitt,thin=thin,burnin=burnin))
>>>>> }
>>>>> 
>>>>> library(coda)
>>>>> mcmclist = mcmc.list(lapply(Children_mcmc1,FUN=function(x) { x$Sol}))
>>>>> save(Children_mcmc1,mcmclist, file = "/usr/users/rarslan/rpqa/rpqa_main/rpqa_mcmc_kids_za.rdata")
>>>>> closeCluster(cl)
>>>>> mpi.quit()
>>>>> 
>>>>> 
>>>>> 
>>>>> On 04 Aug 2014, at 20:25, Ruben Arslan <rubenarslan at gmail.com> wrote:
>>>>> 
>>>>>> Dear list,
>>>>>> 
>>>>>> would someone be willing to share her or his efforts in parallelising a MCMCglmm analysis?
>>>>>> 
>>>>>> I had something viable using harvestr that seemed to properly initialise
>>>>>> the starting values from different random number streams (which is desirable,
>>>>>> as far as I could find out), but I ended up being unable to use harvestr, because
>>>>>> it uses an old version of plyr, where parallelisation works only for multicore, not for
>>>>>> MPI.
>>>>>> 
>>>>>> I pasted my working version, that does not do anything about starting values or RNG
>>>>>> at the end of this email. I can try to fumble further in the dark or try to update harvestr,
>>>>>> but maybe someone has gone through all this already.
>>>>>> 
>>>>>> I'd also appreciate any tips for elegantly post-processing such parallel data, as some of my usual
>>>>>> extraction functions and routines are hampered by the fact that some coda functions
>>>>>> do not aggregate results over chains. (What I get from a single-chain summary in MCMCglmm
>>>>>> is a bit more comprehensive, than what I managed to cobble together with my own extraction
>>>>>> functions).
>>>>>> 
>>>>>> The reason I'm parallelising my analyses is that I'm having trouble getting a good effective
>>>>>> sample size for any parameter having to do with the many zeroes in my data.
>>>>>> Any pointers are very appreciated, I'm quite inexperienced with MCMCglmm.
>>>>>> 
>>>>>> Best wishes
>>>>>> 
>>>>>> Ruben
>>>>>> 
>>>>>> # bsub -q mpi-short -W 2:00 -n 42 -R np20 mpirun -H localhost -n 41 R --slave -f "rpqa/rpqa_main/rpqa_children_parallel.r"
>>>>>> library(doMPI)
>>>>>> cl <- startMPIcluster()
>>>>>> registerDoMPI(cl)
>>>>>> Children_mcmc1 = foreach(i=1:40) %dopar% {
>>>>>> 	library(MCMCglmm)
>>>>>> 	load("rpqa1.rdata")
>>>>>> 
>>>>>> 	nitt = 40000; thin = 100; burnin = 10000
>>>>>> 	prior = list(
>>>>>> 		R = list(V = diag(c(1,1)), nu = 0.002),
>>>>>> 		G=list(list(V=diag(c(1,1e-6)),nu=0.002))
>>>>>> 	)
>>>>>> 
>>>>>> 	MCMCglmm( children ~ trait -1 + at.level(trait,1):male + at.level(trait,1):urban + at.level(trait,1):spouses + at.level(trait,1):paternalage.mean + at.level(trait,1):paternalage.factor,
>>>>>> 		rcov=~us(trait):units,
>>>>>> 		random=~us(trait):idParents,
>>>>>> 		family="zapoisson",
>>>>>> 		prior = prior,
>>>>>> 		data=rpqa.1,
>>>>>> 		pr = F, saveX = T, saveZ = T,
>>>>>> 		nitt=nitt,thin=thin,burnin=burnin)
>>>>>> }
>>>>>> 
>>>>>> library(coda)
>>>>>> mcmclist = mcmc.list(lapply(Children_mcmc1,FUN=function(x) { x$Sol}))
>>>>>> save(Children_mcmc1,mcmclist, file = "rpqa_mcmc_kids_za.rdata")
>>>>>> closeCluster(cl)
>>>>>> mpi.quit()
>>>>>> 
>>>>>> 
>>>>>> --
>>>>>> Ruben C. Arslan
>>>>>> 
>>>>>> Georg August University G?ttingen
>>>>>> Biological Personality Psychology and Psychological Assessment
>>>>>> Georg Elias M?ller Institute of Psychology
>>>>>> Go?lerstr. 14
>>>>>> 37073 G?ttingen
>>>>>> Germany
>>>>>> Tel.: +49 551 3920704
>>>>>> https://psych.uni-goettingen.de/en/biopers/team/arslan
>>>>>> 
>>>>>> 
>>>>>> 
>>>>> 
>>>>> 
>>>>> 	[[alternative HTML version deleted]]
>>>>> 
>>>>> 
>>>> 
>>>> 
>>>> 
>>>> --
>>>> The University of Edinburgh is a charitable body, registered in
>>>> Scotland, with registration number SC005336.
>>> 
>>> 
>> 
>> 
>> 
>> -- 
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> 
> 
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
> 
> 



	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Tue Aug 26 13:04:34 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 26 Aug 2014 12:04:34 +0100
Subject: [R-sig-ME] parallel MCMCglmm, RNGstreams,
 starting values & priors
In-Reply-To: <49D60399-6902-45AC-80A9-9F3C35532228@gmail.com>
References: <4CD76FE1-D3F5-4980-9122-B0AC0D44FF81@gmail.com>
	<0E12EB43-72BC-42AC-9E74-9DF53DB42217@gmail.com>
	<20140825162907.10475jpywlu1wzs4@www.staffmail.ed.ac.uk>
	<0A463095-8656-49B7-9619-E557DD449E21@gmail.com>
	<20140825171414.10872gnlopk1we68@www.staffmail.ed.ac.uk>
	<20140825172936.15916weehiwjyc08@www.staffmail.ed.ac.uk>
	<8D35B834-0D31-486A-B5FB-0F279761FDB2@gmail.com>
	<49D60399-6902-45AC-80A9-9F3C35532228@gmail.com>
Message-ID: <20140826120434.14613hxqhgwbhq80@www.staffmail.ed.ac.uk>

Hi Ruben,

There are 400 liabilities in a zapoisson model (2 per datum). This  
code should work:

g <-sample(letters[1:10], size = 200, replace = T)
pred <- rnorm(200)

l1<-rnorm(200, -1, sqrt(1))
l2<-rnorm(200, -1, sqrt(1))

y<-VGAM::rzapois(200, exp(l1), exp(-exp(l2)))

# generate zero-altered data with an intercept of -1 (because the  
intercept and variance are the same for both processes this is just  
standard Poisson)

dat<-data.frame(y=y, g = g, pred = pred)


start.1<-list(liab=c(l1,l2), R = list(R1=diag(2)), G=list(G1=diag(2)))
prior.1<-list(R=list(V=diag(2), nu=1.002, fix=2),  
G=list(G1=list(V=diag(2), nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000)))

m1<-MCMCglmm(y~trait + pred:trait, random=~us(trait):g,  
family="zapoisson",rcov=~idh(trait):units, data=dat, prior=prior.1,  
start= start.1)

However, there are 2 bugs in the current version of MCMCglmm that  
return an error message when the documentation implies it should be  
fine:

a) it should be possible to have R=diag(2) rather than R =  
list(R1=diag(2)). This bug cropped up when I implemented  
block-diagonal R structures. It can be fixed by inserting:

           if(!is.list(start$R)){
              start$R<-list(R1=start$R)
           }

on L514 of MCMCglmm.R below

           if(!is.list(prior$R[[1]])){
              prior$R<-list(R1=prior$R)
           }

b) rcov=~trait:units models for zi/za models will return an error when  
passing starting values. To fix this insert

          if(diagR==3){
            if(dim(start)[1]!=1){
              stop("V is the wrong dimension for some strart$G/start$R  
elements")
            }
            start<-diag(sum(nfl))*start[1]
          }

on L90 of priorfromat.R below

          if(is.matrix(start)==FALSE){
            start<-as.matrix(start)
          }

I will put these in the new version.

Cheers,

Jarrod







Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25 Aug 2014  
21:52:30 +0200:

> Hi Jarrod,
>
> thanks for these pointers.
>
>>> You will need to provide over-dispersed starting values for  
>>> multiple-chain convergence diagnostics to be useful (GLMM are so  
>>> simple I am generally happy if the output of a single run looks  
>>> reasonable).
>
> Oh, I would be happy with single chains, but since computation would  
> take weeks this way, I wanted to parallelise and I would use the  
> multi-chain convergence as a criterion that my parallelisation was  
> proper
> and is as informative as a single long chain. There don't seem to be  
> any such checks built-in ? I was analysing my 40 chains for a bit  
> longer than I like to admit until I noticed they were identical  
> (effectiveSize
> and summary.mcmc.list did not yell at me for this).
>
>>> # use some very bad starting values
> I get that these values are bad, but that is the goal for my  
> multi-chain aim, right?
>
> I can apply this to my zero-truncated model, but am again getting  
> stuck with the zero-altered one.
> Maybe I need only specify the Liab values for this?
> At least I'm getting nowhere with specifying R and G starting values  
> here. When I got an error, I always
> went to the MCMCglmm source to understand why the checks failed, but  
> I didn't always understand
> what was being checked and couldn't get it to work.
>
> Here's a failing example:
>
> l<-rnorm(200, -1, sqrt(1))
> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
> g = sample(letters[1:10], size = 200, replace = T)
> pred = rnorm(200)
> y<-rpois(200,exp(l)-t)
> y[1:40] = 0
> # generate zero-altered data with an intercept of -1
>
> dat<-data.frame(y=y, g = g, pred = pred)
> set.seed(1)
> start_true = list(Liab=l, R = 1, G = 1 )
> m1<-MCMCglmm(y~1 + pred,random = ~ g,  
> family="zapoisson",rcov=~us(trait):units, data=dat, start= start_true)
>
> # use true latent variable as starting values
> set.seed(1)
> # use some very bad starting values
> start_rand = list(Liab=rnorm(200), R = rpois(1, 1)+1, G = rpois(1, 1)+1 )
> m2<-MCMCglmm(y~1 + pred,random = ~ g,rcov=~us(trait):units,   
> family="zapoisson", data=dat, start = start_rand)
>
> Best,
>
> Ruben
>
> On 25 Aug 2014, at 18:29, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>
>> Hi Ruben,
>>
>> Sorry  - I was wrong when I said that everything is Gibbs sampled  
>> conditional on the latent variables. The location effects (fixed  
>> and random effects) are also sampled conditional on the  
>> (co)variance components so you should add them to the starting  
>> values. In the case where the true values are used:
>>
>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat, start=list(Liab=l,R=1))
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>> Quoting Jarrod Hadfield <j.hadfield at ed.ac.uk> on Mon, 25 Aug 2014  
>> 17:14:14 +0100:
>>
>>> Hi Ruben,
>>>
>>> You will need to provide over-dispersed starting values for  
>>> multiple-chain convergence diagnostics to be useful (GLMM are so  
>>> simple I am generally happy if the output of a single run looks  
>>> reasonable).
>>>
>>> With non-Gaussian data everything is Gibbs sampled conditional on  
>>> the latent variables, so you only need to pass them:
>>>
>>> l<-rnorm(200, -1, sqrt(1))
>>> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
>>> y<-rpois(200,exp(l)-t)+1
>>> # generate zero-truncated data with an intercept of -1
>>>
>>> dat<-data.frame(y=y)
>>> set.seed(1)
>>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat, start=list(Liab=l))
>>> # use true latent variable as starting values
>>> set.seed(1)
>>> m2<-MCMCglmm(y~1, family="ztpoisson", data=dat,  
>>> start=list(Liab=rnorm(200)))
>>> # use some very bad starting values
>>>
>>> plot(mcmc.list(m1$Sol, m2$Sol))
>>> # not identical despite the same seed because of different  
>>> starting values but clearly sampling the same posterior  
>>> distribution:
>>>
>>> gelman.diag(mcmc.list(m1$Sol, m2$Sol))
>>>
>>> Cheers,
>>>
>>> Jarrod
>>>
>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25 Aug 2014  
>>> 18:00:08 +0200:
>>>
>>>> Dear Jarrod,
>>>>
>>>> thanks for the quick reply. Please, don't waste time looking into  
>>>> doMPI ? I am happy that I
>>>> get the expected result, when I specify that reproducible seed,  
>>>> whyever that may be.
>>>> I'm pretty sure that is the deciding factor, because I tested it  
>>>> explicitly, I just have no idea
>>>> how/why it interacts with the choice of family.
>>>>
>>>> That said, is setting up different RNG streams for my workers  
>>>> (now that it works) __sufficient__
>>>> so that I get independent chains and can use gelman.diag() for  
>>>> convergence diagnostics?
>>>> Or should I still tinker with the starting values myself?
>>>> I've never found a worked example of supplying starting values  
>>>> and am thus a bit lost.
>>>>
>>>> Sorry for sending further questions, I hope someone else takes pity while
>>>> you're busy with lectures.
>>>>
>>>> Best wishes
>>>>
>>>> Ruben
>>>>
>>>>
>>>>
>>>> On 25 Aug 2014, at 17:29, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>>>
>>>>> Hi Ruben,
>>>>>
>>>>> I do not think the issue is with the starting values, because  
>>>>> even if the same starting values were used the chains would  
>>>>> still differ because of the randomness in the Markov Chain (if I  
>>>>> interpret your `identical' test correctly). This just involves a  
>>>>> call to GetRNGstate() in the C++ code (L 871 ofMCMCglmm.cc) so I  
>>>>> think for some reason doMPI/foreach is not doing what you  
>>>>> expect. I am not familiar with doMPI and am in the middle of  
>>>>> writing lectures so haven't got time to look into it carefully.  
>>>>> Outside of the context of doMPI I get the behaviour I expect:
>>>>>
>>>>>
>>>>> l<-rnorm(200, -1, sqrt(1))
>>>>> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
>>>>> y<-rpois(200,exp(l)-t)+1
>>>>> # generate zero-truncated data with an intercept of -1
>>>>>
>>>>> dat<-data.frame(y=y)
>>>>> set.seed(1)
>>>>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>>> set.seed(2)
>>>>> m2<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>>> set.seed(2)
>>>>> m3<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>>>
>>>>> plot(mcmc.list(m1$Sol, m2$Sol))
>>>>> # different, as expected
>>>>> plot(mcmc.list(m2$Sol, m3$Sol))
>>>>> # the same, as expected
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25 Aug 2014  
>>>>> 16:58:06 +0200:
>>>>>
>>>>>> Dear list,
>>>>>>
>>>>>> sorry for bumping my old post, I hope to elicit a response with  
>>>>>> a more focused question:
>>>>>>
>>>>>> When does MCMCglmm automatically start from different values  
>>>>>> when using doMPI/foreach?
>>>>>>
>>>>>> I have done some tests with models of varying complexity. For  
>>>>>> example, the script in my last
>>>>>> post (using "zapoisson") yielded 40 identical chains:
>>>>>>> identical(mcmclist[1], mcmclist[30])
>>>>>> TRUE
>>>>>>
>>>>>> A simpler (?) model (using "ztpoisson" and no specified prior),  
>>>>>> however, yielded different chains
>>>>>> and I could use them to calculate gelman.diag()
>>>>>>
>>>>>> Changing my script to the version below, i.e. seeding foreach  
>>>>>> using .options.mpi=list( seed= 1337)
>>>>>> so as to make RNGstreams reproducible (or so I  thought), led  
>>>>>> to different chains even for the
>>>>>> "zapoisson" model.
>>>>>>
>>>>>> In no case have I (successfully) tried to supplant the default  
>>>>>> of MCMCglmm's "start" argument.
>>>>>> Is starting my models from different RNGsubstreams inadequate  
>>>>>> compared to manipulating
>>>>>> the start argument explicitly? If so, is there any worked  
>>>>>> example of explicit starting value manipulation
>>>>>> in parallel computation?
>>>>>> I've browsed the MCMCglmm source to understand how the default  
>>>>>> starting values are generated,
>>>>>> but didn't find any differences with respect to RNG for the two  
>>>>>> families "ztpoisson" and "zapoisson"
>>>>>> (granted, I did not dig very deep).
>>>>>>
>>>>>> Best regards,
>>>>>>
>>>>>> Ruben Arslan
>>>>>>
>>>>>>
>>>>>> # bsub -q mpi -W 12:00 -n 41 -R np20 mpirun -H localhost -n 41  
>>>>>> R --slave -f  
>>>>>> "/usr/users/rarslan/rpqa/rpqa_main/rpqa_children_parallel.R"
>>>>>>
>>>>>> library(doMPI)
>>>>>> cl <-  
>>>>>> startMPIcluster(verbose=T,workdir="/usr/users/rarslan/rpqa/rpqa_main/")
>>>>>> registerDoMPI(cl)
>>>>>> Children_mcmc1 = foreach(i=1:clusterSize(cl),.options.mpi =  
>>>>>> list(seed=1337) ) %dopar% {
>>>>>> 	library(MCMCglmm);library(data.table)
>>>>>> 	load("/usr/users/rarslan/rpqa/rpqa1.rdata")
>>>>>>
>>>>>> 	nitt = 130000; thin = 100; burnin = 30000
>>>>>> 	prior.m5d.2 = list(
>>>>>> 		R = list(V = diag(c(1,1)), nu = 0.002),
>>>>>> 		G=list(list(V=diag(c(1,1e-6)),nu=0.002))
>>>>>> 	)
>>>>>>
>>>>>> 	rpqa.1 = na.omit(rpqa.1[spouses>0, list(idParents, children,  
>>>>>> male, urban, spouses, paternalage.mean, paternalage.factor)])
>>>>>> 	(m1 = MCMCglmm( children ~ trait * (male + urban + spouses +  
>>>>>> paternalage.mean + paternalage.factor),
>>>>>> 						rcov=~us(trait):units,
>>>>>> 						random=~us(trait):idParents,
>>>>>> 						family="zapoisson",
>>>>>> 						prior = prior.m5d.2,
>>>>>> 						data=rpqa.1,
>>>>>> 						pr = F, saveX = F, saveZ = F,
>>>>>> 						nitt=nitt,thin=thin,burnin=burnin))
>>>>>> }
>>>>>>
>>>>>> library(coda)
>>>>>> mcmclist = mcmc.list(lapply(Children_mcmc1,FUN=function(x) { x$Sol}))
>>>>>> save(Children_mcmc1,mcmclist, file =  
>>>>>> "/usr/users/rarslan/rpqa/rpqa_main/rpqa_mcmc_kids_za.rdata")
>>>>>> closeCluster(cl)
>>>>>> mpi.quit()
>>>>>>
>>>>>>
>>>>>>
>>>>>> On 04 Aug 2014, at 20:25, Ruben Arslan <rubenarslan at gmail.com> wrote:
>>>>>>
>>>>>>> Dear list,
>>>>>>>
>>>>>>> would someone be willing to share her or his efforts in  
>>>>>>> parallelising a MCMCglmm analysis?
>>>>>>>
>>>>>>> I had something viable using harvestr that seemed to properly  
>>>>>>> initialise
>>>>>>> the starting values from different random number streams  
>>>>>>> (which is desirable,
>>>>>>> as far as I could find out), but I ended up being unable to  
>>>>>>> use harvestr, because
>>>>>>> it uses an old version of plyr, where parallelisation works  
>>>>>>> only for multicore, not for
>>>>>>> MPI.
>>>>>>>
>>>>>>> I pasted my working version, that does not do anything about  
>>>>>>> starting values or RNG
>>>>>>> at the end of this email. I can try to fumble further in the  
>>>>>>> dark or try to update harvestr,
>>>>>>> but maybe someone has gone through all this already.
>>>>>>>
>>>>>>> I'd also appreciate any tips for elegantly post-processing  
>>>>>>> such parallel data, as some of my usual
>>>>>>> extraction functions and routines are hampered by the fact  
>>>>>>> that some coda functions
>>>>>>> do not aggregate results over chains. (What I get from a  
>>>>>>> single-chain summary in MCMCglmm
>>>>>>> is a bit more comprehensive, than what I managed to cobble  
>>>>>>> together with my own extraction
>>>>>>> functions).
>>>>>>>
>>>>>>> The reason I'm parallelising my analyses is that I'm having  
>>>>>>> trouble getting a good effective
>>>>>>> sample size for any parameter having to do with the many  
>>>>>>> zeroes in my data.
>>>>>>> Any pointers are very appreciated, I'm quite inexperienced  
>>>>>>> with MCMCglmm.
>>>>>>>
>>>>>>> Best wishes
>>>>>>>
>>>>>>> Ruben
>>>>>>>
>>>>>>> # bsub -q mpi-short -W 2:00 -n 42 -R np20 mpirun -H localhost  
>>>>>>> -n 41 R --slave -f "rpqa/rpqa_main/rpqa_children_parallel.r"
>>>>>>> library(doMPI)
>>>>>>> cl <- startMPIcluster()
>>>>>>> registerDoMPI(cl)
>>>>>>> Children_mcmc1 = foreach(i=1:40) %dopar% {
>>>>>>> 	library(MCMCglmm)
>>>>>>> 	load("rpqa1.rdata")
>>>>>>>
>>>>>>> 	nitt = 40000; thin = 100; burnin = 10000
>>>>>>> 	prior = list(
>>>>>>> 		R = list(V = diag(c(1,1)), nu = 0.002),
>>>>>>> 		G=list(list(V=diag(c(1,1e-6)),nu=0.002))
>>>>>>> 	)
>>>>>>>
>>>>>>> 	MCMCglmm( children ~ trait -1 + at.level(trait,1):male +  
>>>>>>> at.level(trait,1):urban + at.level(trait,1):spouses +  
>>>>>>> at.level(trait,1):paternalage.mean +  
>>>>>>> at.level(trait,1):paternalage.factor,
>>>>>>> 		rcov=~us(trait):units,
>>>>>>> 		random=~us(trait):idParents,
>>>>>>> 		family="zapoisson",
>>>>>>> 		prior = prior,
>>>>>>> 		data=rpqa.1,
>>>>>>> 		pr = F, saveX = T, saveZ = T,
>>>>>>> 		nitt=nitt,thin=thin,burnin=burnin)
>>>>>>> }
>>>>>>>
>>>>>>> library(coda)
>>>>>>> mcmclist = mcmc.list(lapply(Children_mcmc1,FUN=function(x) { x$Sol}))
>>>>>>> save(Children_mcmc1,mcmclist, file = "rpqa_mcmc_kids_za.rdata")
>>>>>>> closeCluster(cl)
>>>>>>> mpi.quit()
>>>>>>>
>>>>>>>
>>>>>>> --
>>>>>>> Ruben C. Arslan
>>>>>>>
>>>>>>> Georg August University G?ttingen
>>>>>>> Biological Personality Psychology and Psychological Assessment
>>>>>>> Georg Elias M?ller Institute of Psychology
>>>>>>> Go?lerstr. 14
>>>>>>> 37073 G?ttingen
>>>>>>> Germany
>>>>>>> Tel.: +49 551 3920704
>>>>>>> https://psych.uni-goettingen.de/en/biopers/team/arslan
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>
>>>>>>
>>>>>> 	[[alternative HTML version deleted]]
>>>>>>
>>>>>>
>>>>>
>>>>>
>>>>>
>>>>> --
>>>>> The University of Edinburgh is a charitable body, registered in
>>>>> Scotland, with registration number SC005336.
>>>>
>>>>
>>>
>>>
>>>
>>> --
>>> The University of Edinburgh is a charitable body, registered in
>>> Scotland, with registration number SC005336.
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>>
>> --
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>>
>
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From samantha.cox at plymouth.ac.uk  Tue Aug 26 19:33:38 2014
From: samantha.cox at plymouth.ac.uk (Samantha Cox)
Date: Tue, 26 Aug 2014 17:33:38 +0000
Subject: [R-sig-ME] Binomial GLMM or GAMM with random intercept and temporal
	correlation
Message-ID: <7AEB852E418272489F0B582BAC54FCC83E230C53@TIS102.uopnet.plymouth.ac.uk>

Dear mixed models mailing list,

I am trying to model some binomial data (0/1) as a function of sex (0/1) and DistanceToFeature (continuous km's) with an interaction between the two.  My data is nested and I therefore want to include a random intercept for InidividualID and within that I want to include an AR1 correlation structure as the data is serially/temporally auto-correlated.  I understand any correlation structure should be nested within the random effect.

So far I have tried running the model using glmmPQL as

glmmPQL(Y ~ DistanceToFeature * Sex + (1|InidividualID), correlation=corAR1(form=~1|IndividualID/ContinuousBout), family='binomial', data='birds')

(note - ContinuousBout is an ID for where there are time gaps in the data).

However, although this runs, am I right in understanding that I should not use PQL estimation with binomial data as it gives biased results?  Does anyone know of a way I can model this?

I understand that this is also the case if I wish to use GAMM (as later I will be modelling a non-linear explanatory as well)?

Additionally I will also be running a similar set up but where the data are not equally spaced in time (and therefore an AR1 structure would not apply). Can anyone give a recommendation of a modelling framework for this also.

Any help would be much appreciated.

Thank you

Sam


________________________________
[http://www.plymouth.ac.uk/images/email_footer.gif]<http://www.plymouth.ac.uk/worldclass>

This email and any files with it are confidential and intended solely for the use of the recipient to whom it is addressed. If you are not the intended recipient then copying, distribution or other use of the information contained is strictly prohibited and you should not rely on it. If you have received this email in error please let the sender know immediately and delete it from your system(s). Internet emails are not necessarily secure. While we take every care, Plymouth University accepts no responsibility for viruses and it is your responsibility to scan emails and their attachments. Plymouth University does not accept responsibility for any changes made after it was sent. Nothing in this email or its attachments constitutes an order for goods or services unless accompanied by an official order form.

	[[alternative HTML version deleted]]


From rubenarslan at gmail.com  Wed Aug 27 19:23:42 2014
From: rubenarslan at gmail.com (Ruben Arslan)
Date: Wed, 27 Aug 2014 19:23:42 +0200
Subject: [R-sig-ME] parallel MCMCglmm, RNGstreams,
	starting values & priors
In-Reply-To: <20140826120434.14613hxqhgwbhq80@www.staffmail.ed.ac.uk>
References: <4CD76FE1-D3F5-4980-9122-B0AC0D44FF81@gmail.com>
	<0E12EB43-72BC-42AC-9E74-9DF53DB42217@gmail.com>
	<20140825162907.10475jpywlu1wzs4@www.staffmail.ed.ac.uk>
	<0A463095-8656-49B7-9619-E557DD449E21@gmail.com>
	<20140825171414.10872gnlopk1we68@www.staffmail.ed.ac.uk>
	<20140825172936.15916weehiwjyc08@www.staffmail.ed.ac.uk>
	<8D35B834-0D31-486A-B5FB-0F279761FDB2@gmail.com>
	<49D60399-6902-45AC-80A9-9F3C35532228@gmail.com>
	<20140826120434.14613hxqhgwbhq80@www.staffmail.ed.ac.uk>
Message-ID: <8557AE32-AFC9-4FD2-9C88-2D118B484637@gmail.com>

Hi Jarrod,

thanks again. I was able to get it running with your advice.
Some points of confusion remain:

- You wrote that zi/za models would return an error with rcov = ~trait:units + starting values. This did not happen in my case, so I didn't build MCMCglmm myself with your suggested edits. Also, have you considered putting your own MCMCglmm repo on Github? Your users would be able to install pre-releases and I'd think you'd get some time-saving pull requests too.
- In my attempts to get my models to run properly, I messed up a prior and did not use fix=2 in my prior specification for my za models. This led to crappy convergence, it's much better now and for some of my simpler models I think I won't need parallel chains. I'm reminded of Gelman's folk theorem of statistical computing.
- I followed your advice, but of course I could not set the true values as starting values, but wanted to set random, bad starting values. I pasted below what I arrived at, I'm especially unsure whether I specified the starting values for G and R properly (I think not).
	start <- list(
		liab=c(rnorm( nrow(krmh.1)*2 )), 
		R = list(R1 = diag(rpois(2, 1)+1)),
		G = list(G1 = diag(rpois(2, 1)+1))
	)


However, even though I may not need multiple chains for some of my simpler models, I've now run into conflicting diagnostics. The geweke.diag for each chain (and examination of the traces) gives 
satisfactory diagnostics. Comparing multiple chains using gelman.diag, however, leads to one bad guy, namely the traitza_children:spouses interaction.
I think this implies that I've got some starting value dependence for this parameter, that won't be easily rectified through longer burnin?
Do you have any ideas how to rectify this?
I am currently doing sequential analyses on episodes of selection and in historical human data only those who marry have a chance at having kids. I exclude the unmarried
from my sample where I predict number of children, because I examine that in a previous model and the zero-inflation (65% zeros, median w/o unmarried = 4) when including the unmarried is so excessive. 
Number of spouses is easily the strongest predictor in the model, but only serves as a covariate here. Since my other estimates are stable across chains and runs and agree well across models and with theory, I'm 
inclined to shrug this off. But probably I shouldn't ignore this sign of non-convergence?

> gelman.diag(mcmc_1)
Potential scale reduction factors:

                                           Point est. Upper C.I.
(Intercept)                                      1.00       1.00
traitza_children                                 1.27       1.39
male                                             1.00       1.00
spouses                                          1.00       1.00
paternalage.mean                                 1.00       1.00
paternalage.factor(25,30]                        1.00       1.00
paternalage.factor(30,35]                        1.00       1.00
paternalage.factor(35,40]                        1.00       1.00
paternalage.factor(40,45]                        1.00       1.00
paternalage.factor(45,50]                        1.00       1.00
paternalage.factor(50,55]                        1.00       1.00
paternalage.factor(55,90]                        1.00       1.00
traitza_children:male                            1.22       1.32
traitza_children:spouses                         1.83       2.13
traitza_children:paternalage.mean                1.02       1.02
traitza_children:paternalage.factor(25,30]       1.03       1.05
traitza_children:paternalage.factor(30,35]       1.05       1.08
traitza_children:paternalage.factor(35,40]       1.10       1.15
traitza_children:paternalage.factor(40,45]       1.12       1.17
traitza_children:paternalage.factor(45,50]       1.19       1.28
traitza_children:paternalage.factor(50,55]       1.12       1.18
traitza_children:paternalage.factor(55,90]       1.11       1.17

Multivariate psrf

7.27


Best regards,

Ruben


On 26 Aug 2014, at 13:04, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:

> Hi Ruben,
> 
> There are 400 liabilities in a zapoisson model (2 per datum). This code should work:
> 
> g <-sample(letters[1:10], size = 200, replace = T)
> pred <- rnorm(200)
> 
> l1<-rnorm(200, -1, sqrt(1))
> l2<-rnorm(200, -1, sqrt(1))
> 
> y<-VGAM::rzapois(200, exp(l1), exp(-exp(l2)))
> 
> # generate zero-altered data with an intercept of -1 (because the intercept and variance are the same for both processes this is just standard Poisson)
> 
> dat<-data.frame(y=y, g = g, pred = pred)
> 
> 
> start.1<-list(liab=c(l1,l2), R = list(R1=diag(2)), G=list(G1=diag(2)))
> prior.1<-list(R=list(V=diag(2), nu=1.002, fix=2), G=list(G1=list(V=diag(2), nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000)))
> 
> m1<-MCMCglmm(y~trait + pred:trait, random=~us(trait):g, family="zapoisson",rcov=~idh(trait):units, data=dat, prior=prior.1, start= start.1)
> 
> However, there are 2 bugs in the current version of MCMCglmm that return an error message when the documentation implies it should be fine:
> 
> a) it should be possible to have R=diag(2) rather than R = list(R1=diag(2)). This bug cropped up when I implemented block-diagonal R structures. It can be fixed by inserting:
> 
>          if(!is.list(start$R)){
>             start$R<-list(R1=start$R)
>          }
> 
> on L514 of MCMCglmm.R below
> 
>          if(!is.list(prior$R[[1]])){
>             prior$R<-list(R1=prior$R)
>          }
> 
> b) rcov=~trait:units models for zi/za models will return an error when passing starting values. To fix this insert
> 
>         if(diagR==3){
>           if(dim(start)[1]!=1){
>             stop("V is the wrong dimension for some strart$G/start$R elements")
>           }
>           start<-diag(sum(nfl))*start[1]
>         }
> 
> on L90 of priorfromat.R below
> 
>         if(is.matrix(start)==FALSE){
>           start<-as.matrix(start)
>         }
> 
> I will put these in the new version.
> 
> Cheers,
> 
> Jarrod
> 
> 
> 
> 
> 
> 
> 
> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25 Aug 2014 21:52:30 +0200:
> 
>> Hi Jarrod,
>> 
>> thanks for these pointers.
>> 
>>>> You will need to provide over-dispersed starting values for multiple-chain convergence diagnostics to be useful (GLMM are so simple I am generally happy if the output of a single run looks reasonable).
>> 
>> Oh, I would be happy with single chains, but since computation would take weeks this way, I wanted to parallelise and I would use the multi-chain convergence as a criterion that my parallelisation was proper
>> and is as informative as a single long chain. There don't seem to be any such checks built-in ? I was analysing my 40 chains for a bit longer than I like to admit until I noticed they were identical (effectiveSize
>> and summary.mcmc.list did not yell at me for this).
>> 
>>>> # use some very bad starting values
>> I get that these values are bad, but that is the goal for my multi-chain aim, right?
>> 
>> I can apply this to my zero-truncated model, but am again getting stuck with the zero-altered one.
>> Maybe I need only specify the Liab values for this?
>> At least I'm getting nowhere with specifying R and G starting values here. When I got an error, I always
>> went to the MCMCglmm source to understand why the checks failed, but I didn't always understand
>> what was being checked and couldn't get it to work.
>> 
>> Here's a failing example:
>> 
>> l<-rnorm(200, -1, sqrt(1))
>> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
>> g = sample(letters[1:10], size = 200, replace = T)
>> pred = rnorm(200)
>> y<-rpois(200,exp(l)-t)
>> y[1:40] = 0
>> # generate zero-altered data with an intercept of -1
>> 
>> dat<-data.frame(y=y, g = g, pred = pred)
>> set.seed(1)
>> start_true = list(Liab=l, R = 1, G = 1 )
>> m1<-MCMCglmm(y~1 + pred,random = ~ g, family="zapoisson",rcov=~us(trait):units, data=dat, start= start_true)
>> 
>> # use true latent variable as starting values
>> set.seed(1)
>> # use some very bad starting values
>> start_rand = list(Liab=rnorm(200), R = rpois(1, 1)+1, G = rpois(1, 1)+1 )
>> m2<-MCMCglmm(y~1 + pred,random = ~ g,rcov=~us(trait):units,  family="zapoisson", data=dat, start = start_rand)
>> 
>> Best,
>> 
>> Ruben
>> 
>> On 25 Aug 2014, at 18:29, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>> 
>>> Hi Ruben,
>>> 
>>> Sorry  - I was wrong when I said that everything is Gibbs sampled conditional on the latent variables. The location effects (fixed and random effects) are also sampled conditional on the (co)variance components so you should add them to the starting values. In the case where the true values are used:
>>> 
>>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat, start=list(Liab=l,R=1))
>>> 
>>> Cheers,
>>> 
>>> Jarrod
>>> 
>>> 
>>> 
>>> Quoting Jarrod Hadfield <j.hadfield at ed.ac.uk> on Mon, 25 Aug 2014 17:14:14 +0100:
>>> 
>>>> Hi Ruben,
>>>> 
>>>> You will need to provide over-dispersed starting values for multiple-chain convergence diagnostics to be useful (GLMM are so simple I am generally happy if the output of a single run looks reasonable).
>>>> 
>>>> With non-Gaussian data everything is Gibbs sampled conditional on the latent variables, so you only need to pass them:
>>>> 
>>>> l<-rnorm(200, -1, sqrt(1))
>>>> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
>>>> y<-rpois(200,exp(l)-t)+1
>>>> # generate zero-truncated data with an intercept of -1
>>>> 
>>>> dat<-data.frame(y=y)
>>>> set.seed(1)
>>>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat, start=list(Liab=l))
>>>> # use true latent variable as starting values
>>>> set.seed(1)
>>>> m2<-MCMCglmm(y~1, family="ztpoisson", data=dat, start=list(Liab=rnorm(200)))
>>>> # use some very bad starting values
>>>> 
>>>> plot(mcmc.list(m1$Sol, m2$Sol))
>>>> # not identical despite the same seed because of different starting values but clearly sampling the same posterior distribution:
>>>> 
>>>> gelman.diag(mcmc.list(m1$Sol, m2$Sol))
>>>> 
>>>> Cheers,
>>>> 
>>>> Jarrod
>>>> 
>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25 Aug 2014 18:00:08 +0200:
>>>> 
>>>>> Dear Jarrod,
>>>>> 
>>>>> thanks for the quick reply. Please, don't waste time looking into doMPI ? I am happy that I
>>>>> get the expected result, when I specify that reproducible seed, whyever that may be.
>>>>> I'm pretty sure that is the deciding factor, because I tested it explicitly, I just have no idea
>>>>> how/why it interacts with the choice of family.
>>>>> 
>>>>> That said, is setting up different RNG streams for my workers (now that it works) __sufficient__
>>>>> so that I get independent chains and can use gelman.diag() for convergence diagnostics?
>>>>> Or should I still tinker with the starting values myself?
>>>>> I've never found a worked example of supplying starting values and am thus a bit lost.
>>>>> 
>>>>> Sorry for sending further questions, I hope someone else takes pity while
>>>>> you're busy with lectures.
>>>>> 
>>>>> Best wishes
>>>>> 
>>>>> Ruben
>>>>> 
>>>>> 
>>>>> 
>>>>> On 25 Aug 2014, at 17:29, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>>>> 
>>>>>> Hi Ruben,
>>>>>> 
>>>>>> I do not think the issue is with the starting values, because even if the same starting values were used the chains would still differ because of the randomness in the Markov Chain (if I interpret your `identical' test correctly). This just involves a call to GetRNGstate() in the C++ code (L 871 ofMCMCglmm.cc) so I think for some reason doMPI/foreach is not doing what you expect. I am not familiar with doMPI and am in the middle of writing lectures so haven't got time to look into it carefully. Outside of the context of doMPI I get the behaviour I expect:
>>>>>> 
>>>>>> 
>>>>>> l<-rnorm(200, -1, sqrt(1))
>>>>>> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
>>>>>> y<-rpois(200,exp(l)-t)+1
>>>>>> # generate zero-truncated data with an intercept of -1
>>>>>> 
>>>>>> dat<-data.frame(y=y)
>>>>>> set.seed(1)
>>>>>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>>>> set.seed(2)
>>>>>> m2<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>>>> set.seed(2)
>>>>>> m3<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>>>> 
>>>>>> plot(mcmc.list(m1$Sol, m2$Sol))
>>>>>> # different, as expected
>>>>>> plot(mcmc.list(m2$Sol, m3$Sol))
>>>>>> # the same, as expected
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25 Aug 2014 16:58:06 +0200:
>>>>>> 
>>>>>>> Dear list,
>>>>>>> 
>>>>>>> sorry for bumping my old post, I hope to elicit a response with a more focused question:
>>>>>>> 
>>>>>>> When does MCMCglmm automatically start from different values when using doMPI/foreach?
>>>>>>> 
>>>>>>> I have done some tests with models of varying complexity. For example, the script in my last
>>>>>>> post (using "zapoisson") yielded 40 identical chains:
>>>>>>>> identical(mcmclist[1], mcmclist[30])
>>>>>>> TRUE
>>>>>>> 
>>>>>>> A simpler (?) model (using "ztpoisson" and no specified prior), however, yielded different chains
>>>>>>> and I could use them to calculate gelman.diag()
>>>>>>> 
>>>>>>> Changing my script to the version below, i.e. seeding foreach using .options.mpi=list( seed= 1337)
>>>>>>> so as to make RNGstreams reproducible (or so I  thought), led to different chains even for the
>>>>>>> "zapoisson" model.
>>>>>>> 
>>>>>>> In no case have I (successfully) tried to supplant the default of MCMCglmm's "start" argument.
>>>>>>> Is starting my models from different RNGsubstreams inadequate compared to manipulating
>>>>>>> the start argument explicitly? If so, is there any worked example of explicit starting value manipulation
>>>>>>> in parallel computation?
>>>>>>> I've browsed the MCMCglmm source to understand how the default starting values are generated,
>>>>>>> but didn't find any differences with respect to RNG for the two families "ztpoisson" and "zapoisson"
>>>>>>> (granted, I did not dig very deep).
>>>>>>> 
>>>>>>> Best regards,
>>>>>>> 
>>>>>>> Ruben Arslan
>>>>>>> 
>>>>>>> 
>>>>>>> # bsub -q mpi -W 12:00 -n 41 -R np20 mpirun -H localhost -n 41 R --slave -f "/usr/users/rarslan/rpqa/rpqa_main/rpqa_children_parallel.R"
>>>>>>> 
>>>>>>> library(doMPI)
>>>>>>> cl <- startMPIcluster(verbose=T,workdir="/usr/users/rarslan/rpqa/rpqa_main/")
>>>>>>> registerDoMPI(cl)
>>>>>>> Children_mcmc1 = foreach(i=1:clusterSize(cl),.options.mpi = list(seed=1337) ) %dopar% {
>>>>>>> 	library(MCMCglmm);library(data.table)
>>>>>>> 	load("/usr/users/rarslan/rpqa/rpqa1.rdata")
>>>>>>> 
>>>>>>> 	nitt = 130000; thin = 100; burnin = 30000
>>>>>>> 	prior.m5d.2 = list(
>>>>>>> 		R = list(V = diag(c(1,1)), nu = 0.002),
>>>>>>> 		G=list(list(V=diag(c(1,1e-6)),nu=0.002))
>>>>>>> 	)
>>>>>>> 
>>>>>>> 	rpqa.1 = na.omit(rpqa.1[spouses>0, list(idParents, children, male, urban, spouses, paternalage.mean, paternalage.factor)])
>>>>>>> 	(m1 = MCMCglmm( children ~ trait * (male + urban + spouses + paternalage.mean + paternalage.factor),
>>>>>>> 						rcov=~us(trait):units,
>>>>>>> 						random=~us(trait):idParents,
>>>>>>> 						family="zapoisson",
>>>>>>> 						prior = prior.m5d.2,
>>>>>>> 						data=rpqa.1,
>>>>>>> 						pr = F, saveX = F, saveZ = F,
>>>>>>> 						nitt=nitt,thin=thin,burnin=burnin))
>>>>>>> }
>>>>>>> 
>>>>>>> library(coda)
>>>>>>> mcmclist = mcmc.list(lapply(Children_mcmc1,FUN=function(x) { x$Sol}))
>>>>>>> save(Children_mcmc1,mcmclist, file = "/usr/users/rarslan/rpqa/rpqa_main/rpqa_mcmc_kids_za.rdata")
>>>>>>> closeCluster(cl)
>>>>>>> mpi.quit()
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> On 04 Aug 2014, at 20:25, Ruben Arslan <rubenarslan at gmail.com> wrote:
>>>>>>> 
>>>>>>>> Dear list,
>>>>>>>> 
>>>>>>>> would someone be willing to share her or his efforts in parallelising a MCMCglmm analysis?
>>>>>>>> 
>>>>>>>> I had something viable using harvestr that seemed to properly initialise
>>>>>>>> the starting values from different random number streams (which is desirable,
>>>>>>>> as far as I could find out), but I ended up being unable to use harvestr, because
>>>>>>>> it uses an old version of plyr, where parallelisation works only for multicore, not for
>>>>>>>> MPI.
>>>>>>>> 
>>>>>>>> I pasted my working version, that does not do anything about starting values or RNG
>>>>>>>> at the end of this email. I can try to fumble further in the dark or try to update harvestr,
>>>>>>>> but maybe someone has gone through all this already.
>>>>>>>> 
>>>>>>>> I'd also appreciate any tips for elegantly post-processing such parallel data, as some of my usual
>>>>>>>> extraction functions and routines are hampered by the fact that some coda functions
>>>>>>>> do not aggregate results over chains. (What I get from a single-chain summary in MCMCglmm
>>>>>>>> is a bit more comprehensive, than what I managed to cobble together with my own extraction
>>>>>>>> functions).
>>>>>>>> 
>>>>>>>> The reason I'm parallelising my analyses is that I'm having trouble getting a good effective
>>>>>>>> sample size for any parameter having to do with the many zeroes in my data.
>>>>>>>> Any pointers are very appreciated, I'm quite inexperienced with MCMCglmm.
>>>>>>>> 
>>>>>>>> Best wishes
>>>>>>>> 
>>>>>>>> Ruben
>>>>>>>> 
>>>>>>>> # bsub -q mpi-short -W 2:00 -n 42 -R np20 mpirun -H localhost -n 41 R --slave -f "rpqa/rpqa_main/rpqa_children_parallel.r"
>>>>>>>> library(doMPI)
>>>>>>>> cl <- startMPIcluster()
>>>>>>>> registerDoMPI(cl)
>>>>>>>> Children_mcmc1 = foreach(i=1:40) %dopar% {
>>>>>>>> 	library(MCMCglmm)
>>>>>>>> 	load("rpqa1.rdata")
>>>>>>>> 
>>>>>>>> 	nitt = 40000; thin = 100; burnin = 10000
>>>>>>>> 	prior = list(
>>>>>>>> 		R = list(V = diag(c(1,1)), nu = 0.002),
>>>>>>>> 		G=list(list(V=diag(c(1,1e-6)),nu=0.002))
>>>>>>>> 	)
>>>>>>>> 
>>>>>>>> 	MCMCglmm( children ~ trait -1 + at.level(trait,1):male + at.level(trait,1):urban + at.level(trait,1):spouses + at.level(trait,1):paternalage.mean + at.level(trait,1):paternalage.factor,
>>>>>>>> 		rcov=~us(trait):units,
>>>>>>>> 		random=~us(trait):idParents,
>>>>>>>> 		family="zapoisson",
>>>>>>>> 		prior = prior,
>>>>>>>> 		data=rpqa.1,
>>>>>>>> 		pr = F, saveX = T, saveZ = T,
>>>>>>>> 		nitt=nitt,thin=thin,burnin=burnin)
>>>>>>>> }
>>>>>>>> 
>>>>>>>> library(coda)
>>>>>>>> mcmclist = mcmc.list(lapply(Children_mcmc1,FUN=function(x) { x$Sol}))
>>>>>>>> save(Children_mcmc1,mcmclist, file = "rpqa_mcmc_kids_za.rdata")
>>>>>>>> closeCluster(cl)
>>>>>>>> mpi.quit()
>>>>>>>> 
>>>>>>>> 
>>>>>>>> --
>>>>>>>> Ruben C. Arslan
>>>>>>>> 
>>>>>>>> Georg August University G?ttingen
>>>>>>>> Biological Personality Psychology and Psychological Assessment
>>>>>>>> Georg Elias M?ller Institute of Psychology
>>>>>>>> Go?lerstr. 14
>>>>>>>> 37073 G?ttingen
>>>>>>>> Germany
>>>>>>>> Tel.: +49 551 3920704
>>>>>>>> https://psych.uni-goettingen.de/en/biopers/team/arslan
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 	[[alternative HTML version deleted]]
>>>>>>> 
>>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> --
>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>> Scotland, with registration number SC005336.
>>>>> 
>>>>> 
>>>> 
>>>> 
>>>> 
>>>> --
>>>> The University of Edinburgh is a charitable body, registered in
>>>> Scotland, with registration number SC005336.
>>>> 
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>> 
>>> 
>>> 
>>> 
>>> --
>>> The University of Edinburgh is a charitable body, registered in
>>> Scotland, with registration number SC005336.
>>> 
>>> 
>> 
>> 
>> 
> 
> 
> 
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
> 
> 


	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Wed Aug 27 19:39:59 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 27 Aug 2014 18:39:59 +0100
Subject: [R-sig-ME] parallel MCMCglmm, RNGstreams,
 starting values & priors
In-Reply-To: <8557AE32-AFC9-4FD2-9C88-2D118B484637@gmail.com>
References: <4CD76FE1-D3F5-4980-9122-B0AC0D44FF81@gmail.com>
	<0E12EB43-72BC-42AC-9E74-9DF53DB42217@gmail.com>
	<20140825162907.10475jpywlu1wzs4@www.staffmail.ed.ac.uk>
	<0A463095-8656-49B7-9619-E557DD449E21@gmail.com>
	<20140825171414.10872gnlopk1we68@www.staffmail.ed.ac.uk>
	<20140825172936.15916weehiwjyc08@www.staffmail.ed.ac.uk>
	<8D35B834-0D31-486A-B5FB-0F279761FDB2@gmail.com>
	<49D60399-6902-45AC-80A9-9F3C35532228@gmail.com>
	<20140826120434.14613hxqhgwbhq80@www.staffmail.ed.ac.uk>
	<8557AE32-AFC9-4FD2-9C88-2D118B484637@gmail.com>
Message-ID: <20140827183959.18662zc6hw5jj20w@www.staffmail.ed.ac.uk>

Hi Ruben,

1) it did not return an error with rcov = ~trait:units because you  
used R1=rpois(2,1)+1 and yet this specification only fits a single  
variance (not a 2x2 covariance matrix). R1=rpois(2,1)+1 is a bit of a  
weird specification since it has to be integer. I would obtain  
starting values using rIW().

2) yes, that will prevent convergence

3) a) how many effective samples do you have for each parameter? and  
b) are you getting extreme category problems/numerical issues? If you  
store the latent variables (pl=TUE) what is their range for the Zi/za  
part?

Cheers,

Jarrod






Quoting Ruben Arslan <rubenarslan at gmail.com> on Wed, 27 Aug 2014  
19:23:42 +0200:

> Hi Jarrod,
>
> thanks again. I was able to get it running with your advice.
> Some points of confusion remain:
>
> - You wrote that zi/za models would return an error with rcov =  
> ~trait:units + starting values. This did not happen in my case, so I  
> didn't build MCMCglmm myself with your suggested edits. Also, have  
> you considered putting your own MCMCglmm repo on Github? Your users  
> would be able to install pre-releases and I'd think you'd get some  
> time-saving pull requests too.
> - In my attempts to get my models to run properly, I messed up a  
> prior and did not use fix=2 in my prior specification for my za  
> models. This led to crappy convergence, it's much better now and for  
> some of my simpler models I think I won't need parallel chains. I'm  
> reminded of Gelman's folk theorem of statistical computing.
> - I followed your advice, but of course I could not set the true  
> values as starting values, but wanted to set random, bad starting  
> values. I pasted below what I arrived at, I'm especially unsure  
> whether I specified the starting values for G and R properly (I  
> think not).
> 	start <- list(
> 		liab=c(rnorm( nrow(krmh.1)*2 )),
> 		R = list(R1 = diag(rpois(2, 1)+1)),
> 		G = list(G1 = diag(rpois(2, 1)+1))
> 	)
>
>
> However, even though I may not need multiple chains for some of my  
> simpler models, I've now run into conflicting diagnostics. The  
> geweke.diag for each chain (and examination of the traces) gives
> satisfactory diagnostics. Comparing multiple chains using  
> gelman.diag, however, leads to one bad guy, namely the  
> traitza_children:spouses interaction.
> I think this implies that I've got some starting value dependence  
> for this parameter, that won't be easily rectified through longer  
> burnin?
> Do you have any ideas how to rectify this?
> I am currently doing sequential analyses on episodes of selection  
> and in historical human data only those who marry have a chance at  
> having kids. I exclude the unmarried
> from my sample where I predict number of children, because I examine  
> that in a previous model and the zero-inflation (65% zeros, median  
> w/o unmarried = 4) when including the unmarried is so excessive.
> Number of spouses is easily the strongest predictor in the model,  
> but only serves as a covariate here. Since my other estimates are  
> stable across chains and runs and agree well across models and with  
> theory, I'm
> inclined to shrug this off. But probably I shouldn't ignore this  
> sign of non-convergence?
>
>> gelman.diag(mcmc_1)
> Potential scale reduction factors:
>
>                                            Point est. Upper C.I.
> (Intercept)                                      1.00       1.00
> traitza_children                                 1.27       1.39
> male                                             1.00       1.00
> spouses                                          1.00       1.00
> paternalage.mean                                 1.00       1.00
> paternalage.factor(25,30]                        1.00       1.00
> paternalage.factor(30,35]                        1.00       1.00
> paternalage.factor(35,40]                        1.00       1.00
> paternalage.factor(40,45]                        1.00       1.00
> paternalage.factor(45,50]                        1.00       1.00
> paternalage.factor(50,55]                        1.00       1.00
> paternalage.factor(55,90]                        1.00       1.00
> traitza_children:male                            1.22       1.32
> traitza_children:spouses                         1.83       2.13
> traitza_children:paternalage.mean                1.02       1.02
> traitza_children:paternalage.factor(25,30]       1.03       1.05
> traitza_children:paternalage.factor(30,35]       1.05       1.08
> traitza_children:paternalage.factor(35,40]       1.10       1.15
> traitza_children:paternalage.factor(40,45]       1.12       1.17
> traitza_children:paternalage.factor(45,50]       1.19       1.28
> traitza_children:paternalage.factor(50,55]       1.12       1.18
> traitza_children:paternalage.factor(55,90]       1.11       1.17
>
> Multivariate psrf
>
> 7.27
>
>
> Best regards,
>
> Ruben
>
>
> On 26 Aug 2014, at 13:04, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>
>> Hi Ruben,
>>
>> There are 400 liabilities in a zapoisson model (2 per datum). This  
>> code should work:
>>
>> g <-sample(letters[1:10], size = 200, replace = T)
>> pred <- rnorm(200)
>>
>> l1<-rnorm(200, -1, sqrt(1))
>> l2<-rnorm(200, -1, sqrt(1))
>>
>> y<-VGAM::rzapois(200, exp(l1), exp(-exp(l2)))
>>
>> # generate zero-altered data with an intercept of -1 (because the  
>> intercept and variance are the same for both processes this is just  
>> standard Poisson)
>>
>> dat<-data.frame(y=y, g = g, pred = pred)
>>
>>
>> start.1<-list(liab=c(l1,l2), R = list(R1=diag(2)), G=list(G1=diag(2)))
>> prior.1<-list(R=list(V=diag(2), nu=1.002, fix=2),  
>> G=list(G1=list(V=diag(2), nu=2, alpha.mu=c(0,0),  
>> alpha.V=diag(2)*1000)))
>>
>> m1<-MCMCglmm(y~trait + pred:trait, random=~us(trait):g,  
>> family="zapoisson",rcov=~idh(trait):units, data=dat, prior=prior.1,  
>> start= start.1)
>>
>> However, there are 2 bugs in the current version of MCMCglmm that  
>> return an error message when the documentation implies it should be  
>> fine:
>>
>> a) it should be possible to have R=diag(2) rather than R =  
>> list(R1=diag(2)). This bug cropped up when I implemented  
>> block-diagonal R structures. It can be fixed by inserting:
>>
>>          if(!is.list(start$R)){
>>             start$R<-list(R1=start$R)
>>          }
>>
>> on L514 of MCMCglmm.R below
>>
>>          if(!is.list(prior$R[[1]])){
>>             prior$R<-list(R1=prior$R)
>>          }
>>
>> b) rcov=~trait:units models for zi/za models will return an error  
>> when passing starting values. To fix this insert
>>
>>         if(diagR==3){
>>           if(dim(start)[1]!=1){
>>             stop("V is the wrong dimension for some  
>> strart$G/start$R elements")
>>           }
>>           start<-diag(sum(nfl))*start[1]
>>         }
>>
>> on L90 of priorfromat.R below
>>
>>         if(is.matrix(start)==FALSE){
>>           start<-as.matrix(start)
>>         }
>>
>> I will put these in the new version.
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>>
>>
>>
>>
>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25 Aug 2014  
>> 21:52:30 +0200:
>>
>>> Hi Jarrod,
>>>
>>> thanks for these pointers.
>>>
>>>>> You will need to provide over-dispersed starting values for  
>>>>> multiple-chain convergence diagnostics to be useful (GLMM are so  
>>>>> simple I am generally happy if the output of a single run looks  
>>>>> reasonable).
>>>
>>> Oh, I would be happy with single chains, but since computation  
>>> would take weeks this way, I wanted to parallelise and I would use  
>>> the multi-chain convergence as a criterion that my parallelisation  
>>> was proper
>>> and is as informative as a single long chain. There don't seem to  
>>> be any such checks built-in ? I was analysing my 40 chains for a  
>>> bit longer than I like to admit until I noticed they were  
>>> identical (effectiveSize
>>> and summary.mcmc.list did not yell at me for this).
>>>
>>>>> # use some very bad starting values
>>> I get that these values are bad, but that is the goal for my  
>>> multi-chain aim, right?
>>>
>>> I can apply this to my zero-truncated model, but am again getting  
>>> stuck with the zero-altered one.
>>> Maybe I need only specify the Liab values for this?
>>> At least I'm getting nowhere with specifying R and G starting  
>>> values here. When I got an error, I always
>>> went to the MCMCglmm source to understand why the checks failed,  
>>> but I didn't always understand
>>> what was being checked and couldn't get it to work.
>>>
>>> Here's a failing example:
>>>
>>> l<-rnorm(200, -1, sqrt(1))
>>> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
>>> g = sample(letters[1:10], size = 200, replace = T)
>>> pred = rnorm(200)
>>> y<-rpois(200,exp(l)-t)
>>> y[1:40] = 0
>>> # generate zero-altered data with an intercept of -1
>>>
>>> dat<-data.frame(y=y, g = g, pred = pred)
>>> set.seed(1)
>>> start_true = list(Liab=l, R = 1, G = 1 )
>>> m1<-MCMCglmm(y~1 + pred,random = ~ g,  
>>> family="zapoisson",rcov=~us(trait):units, data=dat, start=  
>>> start_true)
>>>
>>> # use true latent variable as starting values
>>> set.seed(1)
>>> # use some very bad starting values
>>> start_rand = list(Liab=rnorm(200), R = rpois(1, 1)+1, G = rpois(1, 1)+1 )
>>> m2<-MCMCglmm(y~1 + pred,random = ~ g,rcov=~us(trait):units,   
>>> family="zapoisson", data=dat, start = start_rand)
>>>
>>> Best,
>>>
>>> Ruben
>>>
>>> On 25 Aug 2014, at 18:29, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>>
>>>> Hi Ruben,
>>>>
>>>> Sorry  - I was wrong when I said that everything is Gibbs sampled  
>>>> conditional on the latent variables. The location effects (fixed  
>>>> and random effects) are also sampled conditional on the  
>>>> (co)variance components so you should add them to the starting  
>>>> values. In the case where the true values are used:
>>>>
>>>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat, start=list(Liab=l,R=1))
>>>>
>>>> Cheers,
>>>>
>>>> Jarrod
>>>>
>>>>
>>>>
>>>> Quoting Jarrod Hadfield <j.hadfield at ed.ac.uk> on Mon, 25 Aug 2014  
>>>> 17:14:14 +0100:
>>>>
>>>>> Hi Ruben,
>>>>>
>>>>> You will need to provide over-dispersed starting values for  
>>>>> multiple-chain convergence diagnostics to be useful (GLMM are so  
>>>>> simple I am generally happy if the output of a single run looks  
>>>>> reasonable).
>>>>>
>>>>> With non-Gaussian data everything is Gibbs sampled conditional  
>>>>> on the latent variables, so you only need to pass them:
>>>>>
>>>>> l<-rnorm(200, -1, sqrt(1))
>>>>> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
>>>>> y<-rpois(200,exp(l)-t)+1
>>>>> # generate zero-truncated data with an intercept of -1
>>>>>
>>>>> dat<-data.frame(y=y)
>>>>> set.seed(1)
>>>>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat, start=list(Liab=l))
>>>>> # use true latent variable as starting values
>>>>> set.seed(1)
>>>>> m2<-MCMCglmm(y~1, family="ztpoisson", data=dat,  
>>>>> start=list(Liab=rnorm(200)))
>>>>> # use some very bad starting values
>>>>>
>>>>> plot(mcmc.list(m1$Sol, m2$Sol))
>>>>> # not identical despite the same seed because of different  
>>>>> starting values but clearly sampling the same posterior  
>>>>> distribution:
>>>>>
>>>>> gelman.diag(mcmc.list(m1$Sol, m2$Sol))
>>>>>
>>>>> Cheers,
>>>>>
>>>>> Jarrod
>>>>>
>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25 Aug 2014  
>>>>> 18:00:08 +0200:
>>>>>
>>>>>> Dear Jarrod,
>>>>>>
>>>>>> thanks for the quick reply. Please, don't waste time looking  
>>>>>> into doMPI ? I am happy that I
>>>>>> get the expected result, when I specify that reproducible seed,  
>>>>>> whyever that may be.
>>>>>> I'm pretty sure that is the deciding factor, because I tested  
>>>>>> it explicitly, I just have no idea
>>>>>> how/why it interacts with the choice of family.
>>>>>>
>>>>>> That said, is setting up different RNG streams for my workers  
>>>>>> (now that it works) __sufficient__
>>>>>> so that I get independent chains and can use gelman.diag() for  
>>>>>> convergence diagnostics?
>>>>>> Or should I still tinker with the starting values myself?
>>>>>> I've never found a worked example of supplying starting values  
>>>>>> and am thus a bit lost.
>>>>>>
>>>>>> Sorry for sending further questions, I hope someone else takes  
>>>>>> pity while
>>>>>> you're busy with lectures.
>>>>>>
>>>>>> Best wishes
>>>>>>
>>>>>> Ruben
>>>>>>
>>>>>>
>>>>>>
>>>>>> On 25 Aug 2014, at 17:29, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>>>>>
>>>>>>> Hi Ruben,
>>>>>>>
>>>>>>> I do not think the issue is with the starting values, because  
>>>>>>> even if the same starting values were used the chains would  
>>>>>>> still differ because of the randomness in the Markov Chain (if  
>>>>>>> I interpret your `identical' test correctly). This just  
>>>>>>> involves a call to GetRNGstate() in the C++ code (L 871  
>>>>>>> ofMCMCglmm.cc) so I think for some reason doMPI/foreach is not  
>>>>>>> doing what you expect. I am not familiar with doMPI and am in  
>>>>>>> the middle of writing lectures so haven't got time to look  
>>>>>>> into it carefully. Outside of the context of doMPI I get the  
>>>>>>> behaviour I expect:
>>>>>>>
>>>>>>>
>>>>>>> l<-rnorm(200, -1, sqrt(1))
>>>>>>> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
>>>>>>> y<-rpois(200,exp(l)-t)+1
>>>>>>> # generate zero-truncated data with an intercept of -1
>>>>>>>
>>>>>>> dat<-data.frame(y=y)
>>>>>>> set.seed(1)
>>>>>>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>>>>> set.seed(2)
>>>>>>> m2<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>>>>> set.seed(2)
>>>>>>> m3<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>>>>>
>>>>>>> plot(mcmc.list(m1$Sol, m2$Sol))
>>>>>>> # different, as expected
>>>>>>> plot(mcmc.list(m2$Sol, m3$Sol))
>>>>>>> # the same, as expected
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25 Aug  
>>>>>>> 2014 16:58:06 +0200:
>>>>>>>
>>>>>>>> Dear list,
>>>>>>>>
>>>>>>>> sorry for bumping my old post, I hope to elicit a response  
>>>>>>>> with a more focused question:
>>>>>>>>
>>>>>>>> When does MCMCglmm automatically start from different values  
>>>>>>>> when using doMPI/foreach?
>>>>>>>>
>>>>>>>> I have done some tests with models of varying complexity. For  
>>>>>>>> example, the script in my last
>>>>>>>> post (using "zapoisson") yielded 40 identical chains:
>>>>>>>>> identical(mcmclist[1], mcmclist[30])
>>>>>>>> TRUE
>>>>>>>>
>>>>>>>> A simpler (?) model (using "ztpoisson" and no specified  
>>>>>>>> prior), however, yielded different chains
>>>>>>>> and I could use them to calculate gelman.diag()
>>>>>>>>
>>>>>>>> Changing my script to the version below, i.e. seeding foreach  
>>>>>>>> using .options.mpi=list( seed= 1337)
>>>>>>>> so as to make RNGstreams reproducible (or so I  thought), led  
>>>>>>>> to different chains even for the
>>>>>>>> "zapoisson" model.
>>>>>>>>
>>>>>>>> In no case have I (successfully) tried to supplant the  
>>>>>>>> default of MCMCglmm's "start" argument.
>>>>>>>> Is starting my models from different RNGsubstreams inadequate  
>>>>>>>> compared to manipulating
>>>>>>>> the start argument explicitly? If so, is there any worked  
>>>>>>>> example of explicit starting value manipulation
>>>>>>>> in parallel computation?
>>>>>>>> I've browsed the MCMCglmm source to understand how the  
>>>>>>>> default starting values are generated,
>>>>>>>> but didn't find any differences with respect to RNG for the  
>>>>>>>> two families "ztpoisson" and "zapoisson"
>>>>>>>> (granted, I did not dig very deep).
>>>>>>>>
>>>>>>>> Best regards,
>>>>>>>>
>>>>>>>> Ruben Arslan
>>>>>>>>
>>>>>>>>
>>>>>>>> # bsub -q mpi -W 12:00 -n 41 -R np20 mpirun -H localhost -n  
>>>>>>>> 41 R --slave -f  
>>>>>>>> "/usr/users/rarslan/rpqa/rpqa_main/rpqa_children_parallel.R"
>>>>>>>>
>>>>>>>> library(doMPI)
>>>>>>>> cl <-  
>>>>>>>> startMPIcluster(verbose=T,workdir="/usr/users/rarslan/rpqa/rpqa_main/")
>>>>>>>> registerDoMPI(cl)
>>>>>>>> Children_mcmc1 = foreach(i=1:clusterSize(cl),.options.mpi =  
>>>>>>>> list(seed=1337) ) %dopar% {
>>>>>>>> 	library(MCMCglmm);library(data.table)
>>>>>>>> 	load("/usr/users/rarslan/rpqa/rpqa1.rdata")
>>>>>>>>
>>>>>>>> 	nitt = 130000; thin = 100; burnin = 30000
>>>>>>>> 	prior.m5d.2 = list(
>>>>>>>> 		R = list(V = diag(c(1,1)), nu = 0.002),
>>>>>>>> 		G=list(list(V=diag(c(1,1e-6)),nu=0.002))
>>>>>>>> 	)
>>>>>>>>
>>>>>>>> 	rpqa.1 = na.omit(rpqa.1[spouses>0, list(idParents, children,  
>>>>>>>> male, urban, spouses, paternalage.mean, paternalage.factor)])
>>>>>>>> 	(m1 = MCMCglmm( children ~ trait * (male + urban + spouses +  
>>>>>>>> paternalage.mean + paternalage.factor),
>>>>>>>> 						rcov=~us(trait):units,
>>>>>>>> 						random=~us(trait):idParents,
>>>>>>>> 						family="zapoisson",
>>>>>>>> 						prior = prior.m5d.2,
>>>>>>>> 						data=rpqa.1,
>>>>>>>> 						pr = F, saveX = F, saveZ = F,
>>>>>>>> 						nitt=nitt,thin=thin,burnin=burnin))
>>>>>>>> }
>>>>>>>>
>>>>>>>> library(coda)
>>>>>>>> mcmclist = mcmc.list(lapply(Children_mcmc1,FUN=function(x) { x$Sol}))
>>>>>>>> save(Children_mcmc1,mcmclist, file =  
>>>>>>>> "/usr/users/rarslan/rpqa/rpqa_main/rpqa_mcmc_kids_za.rdata")
>>>>>>>> closeCluster(cl)
>>>>>>>> mpi.quit()
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> On 04 Aug 2014, at 20:25, Ruben Arslan <rubenarslan at gmail.com> wrote:
>>>>>>>>
>>>>>>>>> Dear list,
>>>>>>>>>
>>>>>>>>> would someone be willing to share her or his efforts in  
>>>>>>>>> parallelising a MCMCglmm analysis?
>>>>>>>>>
>>>>>>>>> I had something viable using harvestr that seemed to  
>>>>>>>>> properly initialise
>>>>>>>>> the starting values from different random number streams  
>>>>>>>>> (which is desirable,
>>>>>>>>> as far as I could find out), but I ended up being unable to  
>>>>>>>>> use harvestr, because
>>>>>>>>> it uses an old version of plyr, where parallelisation works  
>>>>>>>>> only for multicore, not for
>>>>>>>>> MPI.
>>>>>>>>>
>>>>>>>>> I pasted my working version, that does not do anything about  
>>>>>>>>> starting values or RNG
>>>>>>>>> at the end of this email. I can try to fumble further in the  
>>>>>>>>> dark or try to update harvestr,
>>>>>>>>> but maybe someone has gone through all this already.
>>>>>>>>>
>>>>>>>>> I'd also appreciate any tips for elegantly post-processing  
>>>>>>>>> such parallel data, as some of my usual
>>>>>>>>> extraction functions and routines are hampered by the fact  
>>>>>>>>> that some coda functions
>>>>>>>>> do not aggregate results over chains. (What I get from a  
>>>>>>>>> single-chain summary in MCMCglmm
>>>>>>>>> is a bit more comprehensive, than what I managed to cobble  
>>>>>>>>> together with my own extraction
>>>>>>>>> functions).
>>>>>>>>>
>>>>>>>>> The reason I'm parallelising my analyses is that I'm having  
>>>>>>>>> trouble getting a good effective
>>>>>>>>> sample size for any parameter having to do with the many  
>>>>>>>>> zeroes in my data.
>>>>>>>>> Any pointers are very appreciated, I'm quite inexperienced  
>>>>>>>>> with MCMCglmm.
>>>>>>>>>
>>>>>>>>> Best wishes
>>>>>>>>>
>>>>>>>>> Ruben
>>>>>>>>>
>>>>>>>>> # bsub -q mpi-short -W 2:00 -n 42 -R np20 mpirun -H  
>>>>>>>>> localhost -n 41 R --slave -f  
>>>>>>>>> "rpqa/rpqa_main/rpqa_children_parallel.r"
>>>>>>>>> library(doMPI)
>>>>>>>>> cl <- startMPIcluster()
>>>>>>>>> registerDoMPI(cl)
>>>>>>>>> Children_mcmc1 = foreach(i=1:40) %dopar% {
>>>>>>>>> 	library(MCMCglmm)
>>>>>>>>> 	load("rpqa1.rdata")
>>>>>>>>>
>>>>>>>>> 	nitt = 40000; thin = 100; burnin = 10000
>>>>>>>>> 	prior = list(
>>>>>>>>> 		R = list(V = diag(c(1,1)), nu = 0.002),
>>>>>>>>> 		G=list(list(V=diag(c(1,1e-6)),nu=0.002))
>>>>>>>>> 	)
>>>>>>>>>
>>>>>>>>> 	MCMCglmm( children ~ trait -1 + at.level(trait,1):male +  
>>>>>>>>> at.level(trait,1):urban + at.level(trait,1):spouses +  
>>>>>>>>> at.level(trait,1):paternalage.mean +  
>>>>>>>>> at.level(trait,1):paternalage.factor,
>>>>>>>>> 		rcov=~us(trait):units,
>>>>>>>>> 		random=~us(trait):idParents,
>>>>>>>>> 		family="zapoisson",
>>>>>>>>> 		prior = prior,
>>>>>>>>> 		data=rpqa.1,
>>>>>>>>> 		pr = F, saveX = T, saveZ = T,
>>>>>>>>> 		nitt=nitt,thin=thin,burnin=burnin)
>>>>>>>>> }
>>>>>>>>>
>>>>>>>>> library(coda)
>>>>>>>>> mcmclist = mcmc.list(lapply(Children_mcmc1,FUN=function(x) { x$Sol}))
>>>>>>>>> save(Children_mcmc1,mcmclist, file = "rpqa_mcmc_kids_za.rdata")
>>>>>>>>> closeCluster(cl)
>>>>>>>>> mpi.quit()
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> --
>>>>>>>>> Ruben C. Arslan
>>>>>>>>>
>>>>>>>>> Georg August University G?ttingen
>>>>>>>>> Biological Personality Psychology and Psychological Assessment
>>>>>>>>> Georg Elias M?ller Institute of Psychology
>>>>>>>>> Go?lerstr. 14
>>>>>>>>> 37073 G?ttingen
>>>>>>>>> Germany
>>>>>>>>> Tel.: +49 551 3920704
>>>>>>>>> https://psych.uni-goettingen.de/en/biopers/team/arslan
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> 	[[alternative HTML version deleted]]
>>>>>>>>
>>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> --
>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>> Scotland, with registration number SC005336.
>>>>>>
>>>>>>
>>>>>
>>>>>
>>>>>
>>>>> --
>>>>> The University of Edinburgh is a charitable body, registered in
>>>>> Scotland, with registration number SC005336.
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>
>>>>
>>>>
>>>> --
>>>> The University of Edinburgh is a charitable body, registered in
>>>> Scotland, with registration number SC005336.
>>>>
>>>>
>>>
>>>
>>>
>>
>>
>>
>> --
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>>
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From r.travitzki at gmail.com  Thu Aug 28 13:01:15 2014
From: r.travitzki at gmail.com (Rodrigo Travitzki)
Date: Thu, 28 Aug 2014 12:01:15 +0100
Subject: [R-sig-ME] multilevel analysis with sample weighted data
Message-ID: <53FF0BFB.6060001@gmail.com>

Dear R masters,
I'm looking for a R package to do multilevel analysis of a weighted data 
(is a weigthed sample of brazilian educational data) but could not find 
it. There is just a "weights" option in lme(), but is not about 
frequency (or probability) weigths in data. In some foruns, no response 
either.
So, could you please confirm this information for me? There is any R 
package/function which do this? I really don't want to use proprietary 
software, but if there is no option, I'll need to do so.
Thank you very much.

Best wishes,
Rodrigo Travitzki


From bbolker at gmail.com  Thu Aug 28 15:52:58 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 28 Aug 2014 09:52:58 -0400
Subject: [R-sig-ME] multilevel analysis with sample weighted data
In-Reply-To: <53FF0BFB.6060001@gmail.com>
References: <53FF0BFB.6060001@gmail.com>
Message-ID: <53FF343A.1060207@gmail.com>

On 14-08-28 07:01 AM, Rodrigo Travitzki wrote:
> Dear R masters,
> I'm looking for a R package to do multilevel analysis of a weighted data
> (is a weigthed sample of brazilian educational data) but could not find
> it. There is just a "weights" option in lme(), but is not about
> frequency (or probability) weigths in data. In some foruns, no response
> either.
> So, could you please confirm this information for me? There is any R
> package/function which do this? I really don't want to use proprietary
> software, but if there is no option, I'll need to do so.
> Thank you very much.
> 
> Best wishes,
> Rodrigo Travitzki

  It depends a little bit what you want to do/the meaning of the
weights.  I have successfully used weights=varFixed(~I(1/n))
[inverse-variance weighting based on the number of samples per group] in
lme; alternatively, you could use weights=n in lmer (from the lme4
package) to get an equivalent result.

If you want to deal with survey weighting, the story seems to be
considerably more complicated -- I don't claim to understand it, but
Andrew Gelman (a fairly prominent applied Bayesian statistician) claims
that it's "a mess" (to use his phrase).  If the weights represent
probability of inclusion in a survey, I believe he would recommend
model-based inference -- that is, fit an unweighted multilevel
regression model and then use post-stratification/weighting to make
predictions (see http://andrewgelman.com/?s=survey+weights for various
discussion and links to papers).

  good luck,
    Ben Bolker


From rubenarslan at gmail.com  Thu Aug 28 18:45:30 2014
From: rubenarslan at gmail.com (Ruben Arslan)
Date: Thu, 28 Aug 2014 18:45:30 +0200
Subject: [R-sig-ME] parallel MCMCglmm, RNGstreams,
	starting values & priors
In-Reply-To: <20140827183959.18662zc6hw5jj20w@www.staffmail.ed.ac.uk>
References: <4CD76FE1-D3F5-4980-9122-B0AC0D44FF81@gmail.com>
	<0E12EB43-72BC-42AC-9E74-9DF53DB42217@gmail.com>
	<20140825162907.10475jpywlu1wzs4@www.staffmail.ed.ac.uk>
	<0A463095-8656-49B7-9619-E557DD449E21@gmail.com>
	<20140825171414.10872gnlopk1we68@www.staffmail.ed.ac.uk>
	<20140825172936.15916weehiwjyc08@www.staffmail.ed.ac.uk>
	<8D35B834-0D31-486A-B5FB-0F279761FDB2@gmail.com>
	<49D60399-6902-45AC-80A9-9F3C35532228@gmail.com>
	<20140826120434.14613hxqhgwbhq80@www.staffmail.ed.ac.uk>
	<8557AE32-AFC9-4FD2-9C88-2D118B484637@gmail.com>
	<20140827183959.18662zc6hw5jj20w@www.staffmail.ed.ac.uk>
Message-ID: <2D00600E-5287-4FE1-B605-82C0CBA286ED@gmail.com>

Hi Jarrod,

> 1) it did not return an error with rcov = ~trait:units because you used R1=rpois(2,1)+1 and yet this specification only fits a single variance (not a 2x2 covariance matrix). R1=rpois(2,1)+1 is a bit of a weird specification since it has to be integer. I would obtain starting values using rIW().

I agree it's a weird specification, I was a bit lost and thought I could get away with just putting some random numbers in the starting value.
I didn't do R1=rpois(2,1)+1 though, I did R1=diag(rpois(2,1)+1), so I got a 2x2 matrix, but yes, bound to be integer.
I didn't know starting values should come from a conjugate distribution, though that probably means I didn't think about it much.

I'm now doing
start <- list(
	liab=c(rnorm( nrow(krmh.1)*2 )), 
	R = list(R1 = rIW( diag(2), nrow(krmh.1)) ),
	G = list(G1 = rIW( diag(2), nrow(krmh.1)) )
)

Is this what you had in mind?
I am especially unsure if I am supposed to use such a low sampling variability (my sample size is probably not even relevant for the starting values) and if I should start from diag(2).

And, I am still happily confused that this specification still doesn't lead to errors with respect to rcov = ~trait:units . Does this mean I'm doing it wrong?

> 3) a) how many effective samples do you have for each parameter? and b) are you getting extreme category problems/numerical issues? If you store the latent variables (pl=TUE) what is their range for the Zi/za part?

My parallel run using the above starting values isn't finished yet.
a) After applying the above starting values I get, for the location effects 1600-2000 samples for a 2000 sample chain (with thin set to 50). G and R-structure are from 369 (za_children.idParents) to 716 (and 0 for the fixed part).
Effective sample sizes were similar for my run using the starting values for G/R that I drew from rpois, and using 40 chains I of course get  
b) I don't think I am getting extreme categories. I would probably be getting extreme categories if I included the forever-alones (they almost never have children), but this way no. 
I wasn't sure how to examine the range of the latents separately for the za part, but for a single chain it looks okay:
> quantile(as.numeric(m1$Liab),probs = c(0,0.01,0,0.99,1))
       0%        1%        0%       99%      100% 
-4.934111 -1.290728 -4.934111  3.389847  7.484206 

Well, all considered now that I use the above starting value specification I get slightly different estimates for all za-coefficients. Nothing major, but still leading me to
think my estimates aren't exactly independent of the starting values I use. I'll see what the parallel run yields.

Thanks a lot,

Ruben

> 
> Cheers,
> 
> Jarrod
> 
> 
> 
> 
> 
> 
> Quoting Ruben Arslan <rubenarslan at gmail.com> on Wed, 27 Aug 2014 19:23:42 +0200:
> 
>> Hi Jarrod,
>> 
>> thanks again. I was able to get it running with your advice.
>> Some points of confusion remain:
>> 
>> - You wrote that zi/za models would return an error with rcov = ~trait:units + starting values. This did not happen in my case, so I didn't build MCMCglmm myself with your suggested edits. Also, have you considered putting your own MCMCglmm repo on Github? Your users would be able to install pre-releases and I'd think you'd get some time-saving pull requests too.
>> - In my attempts to get my models to run properly, I messed up a prior and did not use fix=2 in my prior specification for my za models. This led to crappy convergence, it's much better now and for some of my simpler models I think I won't need parallel chains. I'm reminded of Gelman's folk theorem of statistical computing.
>> - I followed your advice, but of course I could not set the true values as starting values, but wanted to set random, bad starting values. I pasted below what I arrived at, I'm especially unsure whether I specified the starting values for G and R properly (I think not).
>> 	start <- list(
>> 		liab=c(rnorm( nrow(krmh.1)*2 )),
>> 		R = list(R1 = diag(rpois(2, 1)+1)),
>> 		G = list(G1 = diag(rpois(2, 1)+1))
>> 	)
>> 
>> 
>> However, even though I may not need multiple chains for some of my simpler models, I've now run into conflicting diagnostics. The geweke.diag for each chain (and examination of the traces) gives
>> satisfactory diagnostics. Comparing multiple chains using gelman.diag, however, leads to one bad guy, namely the traitza_children:spouses interaction.
>> I think this implies that I've got some starting value dependence for this parameter, that won't be easily rectified through longer burnin?
>> Do you have any ideas how to rectify this?
>> I am currently doing sequential analyses on episodes of selection and in historical human data only those who marry have a chance at having kids. I exclude the unmarried
>> from my sample where I predict number of children, because I examine that in a previous model and the zero-inflation (65% zeros, median w/o unmarried = 4) when including the unmarried is so excessive.
>> Number of spouses is easily the strongest predictor in the model, but only serves as a covariate here. Since my other estimates are stable across chains and runs and agree well across models and with theory, I'm
>> inclined to shrug this off. But probably I shouldn't ignore this sign of non-convergence?
>> 
>>> gelman.diag(mcmc_1)
>> Potential scale reduction factors:
>> 
>>                                           Point est. Upper C.I.
>> (Intercept)                                      1.00       1.00
>> traitza_children                                 1.27       1.39
>> male                                             1.00       1.00
>> spouses                                          1.00       1.00
>> paternalage.mean                                 1.00       1.00
>> paternalage.factor(25,30]                        1.00       1.00
>> paternalage.factor(30,35]                        1.00       1.00
>> paternalage.factor(35,40]                        1.00       1.00
>> paternalage.factor(40,45]                        1.00       1.00
>> paternalage.factor(45,50]                        1.00       1.00
>> paternalage.factor(50,55]                        1.00       1.00
>> paternalage.factor(55,90]                        1.00       1.00
>> traitza_children:male                            1.22       1.32
>> traitza_children:spouses                         1.83       2.13
>> traitza_children:paternalage.mean                1.02       1.02
>> traitza_children:paternalage.factor(25,30]       1.03       1.05
>> traitza_children:paternalage.factor(30,35]       1.05       1.08
>> traitza_children:paternalage.factor(35,40]       1.10       1.15
>> traitza_children:paternalage.factor(40,45]       1.12       1.17
>> traitza_children:paternalage.factor(45,50]       1.19       1.28
>> traitza_children:paternalage.factor(50,55]       1.12       1.18
>> traitza_children:paternalage.factor(55,90]       1.11       1.17
>> 
>> Multivariate psrf
>> 
>> 7.27
>> 
>> 
>> Best regards,
>> 
>> Ruben
>> 
>> 
>> On 26 Aug 2014, at 13:04, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>> 
>>> Hi Ruben,
>>> 
>>> There are 400 liabilities in a zapoisson model (2 per datum). This code should work:
>>> 
>>> g <-sample(letters[1:10], size = 200, replace = T)
>>> pred <- rnorm(200)
>>> 
>>> l1<-rnorm(200, -1, sqrt(1))
>>> l2<-rnorm(200, -1, sqrt(1))
>>> 
>>> y<-VGAM::rzapois(200, exp(l1), exp(-exp(l2)))
>>> 
>>> # generate zero-altered data with an intercept of -1 (because the intercept and variance are the same for both processes this is just standard Poisson)
>>> 
>>> dat<-data.frame(y=y, g = g, pred = pred)
>>> 
>>> 
>>> start.1<-list(liab=c(l1,l2), R = list(R1=diag(2)), G=list(G1=diag(2)))
>>> prior.1<-list(R=list(V=diag(2), nu=1.002, fix=2), G=list(G1=list(V=diag(2), nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000)))
>>> 
>>> m1<-MCMCglmm(y~trait + pred:trait, random=~us(trait):g, family="zapoisson",rcov=~idh(trait):units, data=dat, prior=prior.1, start= start.1)
>>> 
>>> However, there are 2 bugs in the current version of MCMCglmm that return an error message when the documentation implies it should be fine:
>>> 
>>> a) it should be possible to have R=diag(2) rather than R = list(R1=diag(2)). This bug cropped up when I implemented block-diagonal R structures. It can be fixed by inserting:
>>> 
>>>         if(!is.list(start$R)){
>>>            start$R<-list(R1=start$R)
>>>         }
>>> 
>>> on L514 of MCMCglmm.R below
>>> 
>>>         if(!is.list(prior$R[[1]])){
>>>            prior$R<-list(R1=prior$R)
>>>         }
>>> 
>>> b) rcov=~trait:units models for zi/za models will return an error when passing starting values. To fix this insert
>>> 
>>>        if(diagR==3){
>>>          if(dim(start)[1]!=1){
>>>            stop("V is the wrong dimension for some strart$G/start$R elements")
>>>          }
>>>          start<-diag(sum(nfl))*start[1]
>>>        }
>>> 
>>> on L90 of priorfromat.R below
>>> 
>>>        if(is.matrix(start)==FALSE){
>>>          start<-as.matrix(start)
>>>        }
>>> 
>>> I will put these in the new version.
>>> 
>>> Cheers,
>>> 
>>> Jarrod
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25 Aug 2014 21:52:30 +0200:
>>> 
>>>> Hi Jarrod,
>>>> 
>>>> thanks for these pointers.
>>>> 
>>>>>> You will need to provide over-dispersed starting values for multiple-chain convergence diagnostics to be useful (GLMM are so simple I am generally happy if the output of a single run looks reasonable).
>>>> 
>>>> Oh, I would be happy with single chains, but since computation would take weeks this way, I wanted to parallelise and I would use the multi-chain convergence as a criterion that my parallelisation was proper
>>>> and is as informative as a single long chain. There don't seem to be any such checks built-in ? I was analysing my 40 chains for a bit longer than I like to admit until I noticed they were identical (effectiveSize
>>>> and summary.mcmc.list did not yell at me for this).
>>>> 
>>>>>> # use some very bad starting values
>>>> I get that these values are bad, but that is the goal for my multi-chain aim, right?
>>>> 
>>>> I can apply this to my zero-truncated model, but am again getting stuck with the zero-altered one.
>>>> Maybe I need only specify the Liab values for this?
>>>> At least I'm getting nowhere with specifying R and G starting values here. When I got an error, I always
>>>> went to the MCMCglmm source to understand why the checks failed, but I didn't always understand
>>>> what was being checked and couldn't get it to work.
>>>> 
>>>> Here's a failing example:
>>>> 
>>>> l<-rnorm(200, -1, sqrt(1))
>>>> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
>>>> g = sample(letters[1:10], size = 200, replace = T)
>>>> pred = rnorm(200)
>>>> y<-rpois(200,exp(l)-t)
>>>> y[1:40] = 0
>>>> # generate zero-altered data with an intercept of -1
>>>> 
>>>> dat<-data.frame(y=y, g = g, pred = pred)
>>>> set.seed(1)
>>>> start_true = list(Liab=l, R = 1, G = 1 )
>>>> m1<-MCMCglmm(y~1 + pred,random = ~ g, family="zapoisson",rcov=~us(trait):units, data=dat, start= start_true)
>>>> 
>>>> # use true latent variable as starting values
>>>> set.seed(1)
>>>> # use some very bad starting values
>>>> start_rand = list(Liab=rnorm(200), R = rpois(1, 1)+1, G = rpois(1, 1)+1 )
>>>> m2<-MCMCglmm(y~1 + pred,random = ~ g,rcov=~us(trait):units,  family="zapoisson", data=dat, start = start_rand)
>>>> 
>>>> Best,
>>>> 
>>>> Ruben
>>>> 
>>>> On 25 Aug 2014, at 18:29, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>>> 
>>>>> Hi Ruben,
>>>>> 
>>>>> Sorry  - I was wrong when I said that everything is Gibbs sampled conditional on the latent variables. The location effects (fixed and random effects) are also sampled conditional on the (co)variance components so you should add them to the starting values. In the case where the true values are used:
>>>>> 
>>>>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat, start=list(Liab=l,R=1))
>>>>> 
>>>>> Cheers,
>>>>> 
>>>>> Jarrod
>>>>> 
>>>>> 
>>>>> 
>>>>> Quoting Jarrod Hadfield <j.hadfield at ed.ac.uk> on Mon, 25 Aug 2014 17:14:14 +0100:
>>>>> 
>>>>>> Hi Ruben,
>>>>>> 
>>>>>> You will need to provide over-dispersed starting values for multiple-chain convergence diagnostics to be useful (GLMM are so simple I am generally happy if the output of a single run looks reasonable).
>>>>>> 
>>>>>> With non-Gaussian data everything is Gibbs sampled conditional on the latent variables, so you only need to pass them:
>>>>>> 
>>>>>> l<-rnorm(200, -1, sqrt(1))
>>>>>> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
>>>>>> y<-rpois(200,exp(l)-t)+1
>>>>>> # generate zero-truncated data with an intercept of -1
>>>>>> 
>>>>>> dat<-data.frame(y=y)
>>>>>> set.seed(1)
>>>>>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat, start=list(Liab=l))
>>>>>> # use true latent variable as starting values
>>>>>> set.seed(1)
>>>>>> m2<-MCMCglmm(y~1, family="ztpoisson", data=dat, start=list(Liab=rnorm(200)))
>>>>>> # use some very bad starting values
>>>>>> 
>>>>>> plot(mcmc.list(m1$Sol, m2$Sol))
>>>>>> # not identical despite the same seed because of different starting values but clearly sampling the same posterior distribution:
>>>>>> 
>>>>>> gelman.diag(mcmc.list(m1$Sol, m2$Sol))
>>>>>> 
>>>>>> Cheers,
>>>>>> 
>>>>>> Jarrod
>>>>>> 
>>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25 Aug 2014 18:00:08 +0200:
>>>>>> 
>>>>>>> Dear Jarrod,
>>>>>>> 
>>>>>>> thanks for the quick reply. Please, don't waste time looking into doMPI ? I am happy that I
>>>>>>> get the expected result, when I specify that reproducible seed, whyever that may be.
>>>>>>> I'm pretty sure that is the deciding factor, because I tested it explicitly, I just have no idea
>>>>>>> how/why it interacts with the choice of family.
>>>>>>> 
>>>>>>> That said, is setting up different RNG streams for my workers (now that it works) __sufficient__
>>>>>>> so that I get independent chains and can use gelman.diag() for convergence diagnostics?
>>>>>>> Or should I still tinker with the starting values myself?
>>>>>>> I've never found a worked example of supplying starting values and am thus a bit lost.
>>>>>>> 
>>>>>>> Sorry for sending further questions, I hope someone else takes pity while
>>>>>>> you're busy with lectures.
>>>>>>> 
>>>>>>> Best wishes
>>>>>>> 
>>>>>>> Ruben
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> On 25 Aug 2014, at 17:29, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>>>>>> 
>>>>>>>> Hi Ruben,
>>>>>>>> 
>>>>>>>> I do not think the issue is with the starting values, because even if the same starting values were used the chains would still differ because of the randomness in the Markov Chain (if I interpret your `identical' test correctly). This just involves a call to GetRNGstate() in the C++ code (L 871 ofMCMCglmm.cc) so I think for some reason doMPI/foreach is not doing what you expect. I am not familiar with doMPI and am in the middle of writing lectures so haven't got time to look into it carefully. Outside of the context of doMPI I get the behaviour I expect:
>>>>>>>> 
>>>>>>>> 
>>>>>>>> l<-rnorm(200, -1, sqrt(1))
>>>>>>>> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
>>>>>>>> y<-rpois(200,exp(l)-t)+1
>>>>>>>> # generate zero-truncated data with an intercept of -1
>>>>>>>> 
>>>>>>>> dat<-data.frame(y=y)
>>>>>>>> set.seed(1)
>>>>>>>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>>>>>> set.seed(2)
>>>>>>>> m2<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>>>>>> set.seed(2)
>>>>>>>> m3<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>>>>>> 
>>>>>>>> plot(mcmc.list(m1$Sol, m2$Sol))
>>>>>>>> # different, as expected
>>>>>>>> plot(mcmc.list(m2$Sol, m3$Sol))
>>>>>>>> # the same, as expected
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25 Aug 2014 16:58:06 +0200:
>>>>>>>> 
>>>>>>>>> Dear list,
>>>>>>>>> 
>>>>>>>>> sorry for bumping my old post, I hope to elicit a response with a more focused question:
>>>>>>>>> 
>>>>>>>>> When does MCMCglmm automatically start from different values when using doMPI/foreach?
>>>>>>>>> 
>>>>>>>>> I have done some tests with models of varying complexity. For example, the script in my last
>>>>>>>>> post (using "zapoisson") yielded 40 identical chains:
>>>>>>>>>> identical(mcmclist[1], mcmclist[30])
>>>>>>>>> TRUE
>>>>>>>>> 
>>>>>>>>> A simpler (?) model (using "ztpoisson" and no specified prior), however, yielded different chains
>>>>>>>>> and I could use them to calculate gelman.diag()
>>>>>>>>> 
>>>>>>>>> Changing my script to the version below, i.e. seeding foreach using .options.mpi=list( seed= 1337)
>>>>>>>>> so as to make RNGstreams reproducible (or so I  thought), led to different chains even for the
>>>>>>>>> "zapoisson" model.
>>>>>>>>> 
>>>>>>>>> In no case have I (successfully) tried to supplant the default of MCMCglmm's "start" argument.
>>>>>>>>> Is starting my models from different RNGsubstreams inadequate compared to manipulating
>>>>>>>>> the start argument explicitly? If so, is there any worked example of explicit starting value manipulation
>>>>>>>>> in parallel computation?
>>>>>>>>> I've browsed the MCMCglmm source to understand how the default starting values are generated,
>>>>>>>>> but didn't find any differences with respect to RNG for the two families "ztpoisson" and "zapoisson"
>>>>>>>>> (granted, I did not dig very deep).
>>>>>>>>> 
>>>>>>>>> Best regards,
>>>>>>>>> 
>>>>>>>>> Ruben Arslan
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> # bsub -q mpi -W 12:00 -n 41 -R np20 mpirun -H localhost -n 41 R --slave -f "/usr/users/rarslan/rpqa/rpqa_main/rpqa_children_parallel.R"
>>>>>>>>> 
>>>>>>>>> library(doMPI)
>>>>>>>>> cl <- startMPIcluster(verbose=T,workdir="/usr/users/rarslan/rpqa/rpqa_main/")
>>>>>>>>> registerDoMPI(cl)
>>>>>>>>> Children_mcmc1 = foreach(i=1:clusterSize(cl),.options.mpi = list(seed=1337) ) %dopar% {
>>>>>>>>> 	library(MCMCglmm);library(data.table)
>>>>>>>>> 	load("/usr/users/rarslan/rpqa/rpqa1.rdata")
>>>>>>>>> 
>>>>>>>>> 	nitt = 130000; thin = 100; burnin = 30000
>>>>>>>>> 	prior.m5d.2 = list(
>>>>>>>>> 		R = list(V = diag(c(1,1)), nu = 0.002),
>>>>>>>>> 		G=list(list(V=diag(c(1,1e-6)),nu=0.002))
>>>>>>>>> 	)
>>>>>>>>> 
>>>>>>>>> 	rpqa.1 = na.omit(rpqa.1[spouses>0, list(idParents, children, male, urban, spouses, paternalage.mean, paternalage.factor)])
>>>>>>>>> 	(m1 = MCMCglmm( children ~ trait * (male + urban + spouses + paternalage.mean + paternalage.factor),
>>>>>>>>> 						rcov=~us(trait):units,
>>>>>>>>> 						random=~us(trait):idParents,
>>>>>>>>> 						family="zapoisson",
>>>>>>>>> 						prior = prior.m5d.2,
>>>>>>>>> 						data=rpqa.1,
>>>>>>>>> 						pr = F, saveX = F, saveZ = F,
>>>>>>>>> 						nitt=nitt,thin=thin,burnin=burnin))
>>>>>>>>> }
>>>>>>>>> 
>>>>>>>>> library(coda)
>>>>>>>>> mcmclist = mcmc.list(lapply(Children_mcmc1,FUN=function(x) { x$Sol}))
>>>>>>>>> save(Children_mcmc1,mcmclist, file = "/usr/users/rarslan/rpqa/rpqa_main/rpqa_mcmc_kids_za.rdata")
>>>>>>>>> closeCluster(cl)
>>>>>>>>> mpi.quit()
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> On 04 Aug 2014, at 20:25, Ruben Arslan <rubenarslan at gmail.com> wrote:
>>>>>>>>> 
>>>>>>>>>> Dear list,
>>>>>>>>>> 
>>>>>>>>>> would someone be willing to share her or his efforts in parallelising a MCMCglmm analysis?
>>>>>>>>>> 
>>>>>>>>>> I had something viable using harvestr that seemed to properly initialise
>>>>>>>>>> the starting values from different random number streams (which is desirable,
>>>>>>>>>> as far as I could find out), but I ended up being unable to use harvestr, because
>>>>>>>>>> it uses an old version of plyr, where parallelisation works only for multicore, not for
>>>>>>>>>> MPI.
>>>>>>>>>> 
>>>>>>>>>> I pasted my working version, that does not do anything about starting values or RNG
>>>>>>>>>> at the end of this email. I can try to fumble further in the dark or try to update harvestr,
>>>>>>>>>> but maybe someone has gone through all this already.
>>>>>>>>>> 
>>>>>>>>>> I'd also appreciate any tips for elegantly post-processing such parallel data, as some of my usual
>>>>>>>>>> extraction functions and routines are hampered by the fact that some coda functions
>>>>>>>>>> do not aggregate results over chains. (What I get from a single-chain summary in MCMCglmm
>>>>>>>>>> is a bit more comprehensive, than what I managed to cobble together with my own extraction
>>>>>>>>>> functions).
>>>>>>>>>> 
>>>>>>>>>> The reason I'm parallelising my analyses is that I'm having trouble getting a good effective
>>>>>>>>>> sample size for any parameter having to do with the many zeroes in my data.
>>>>>>>>>> Any pointers are very appreciated, I'm quite inexperienced with MCMCglmm.
>>>>>>>>>> 
>>>>>>>>>> Best wishes
>>>>>>>>>> 
>>>>>>>>>> Ruben
>>>>>>>>>> 
>>>>>>>>>> # bsub -q mpi-short -W 2:00 -n 42 -R np20 mpirun -H localhost -n 41 R --slave -f "rpqa/rpqa_main/rpqa_children_parallel.r"
>>>>>>>>>> library(doMPI)
>>>>>>>>>> cl <- startMPIcluster()
>>>>>>>>>> registerDoMPI(cl)
>>>>>>>>>> Children_mcmc1 = foreach(i=1:40) %dopar% {
>>>>>>>>>> 	library(MCMCglmm)
>>>>>>>>>> 	load("rpqa1.rdata")
>>>>>>>>>> 
>>>>>>>>>> 	nitt = 40000; thin = 100; burnin = 10000
>>>>>>>>>> 	prior = list(
>>>>>>>>>> 		R = list(V = diag(c(1,1)), nu = 0.002),
>>>>>>>>>> 		G=list(list(V=diag(c(1,1e-6)),nu=0.002))
>>>>>>>>>> 	)
>>>>>>>>>> 
>>>>>>>>>> 	MCMCglmm( children ~ trait -1 + at.level(trait,1):male + at.level(trait,1):urban + at.level(trait,1):spouses + at.level(trait,1):paternalage.mean + at.level(trait,1):paternalage.factor,
>>>>>>>>>> 		rcov=~us(trait):units,
>>>>>>>>>> 		random=~us(trait):idParents,
>>>>>>>>>> 		family="zapoisson",
>>>>>>>>>> 		prior = prior,
>>>>>>>>>> 		data=rpqa.1,
>>>>>>>>>> 		pr = F, saveX = T, saveZ = T,
>>>>>>>>>> 		nitt=nitt,thin=thin,burnin=burnin)
>>>>>>>>>> }
>>>>>>>>>> 
>>>>>>>>>> library(coda)
>>>>>>>>>> mcmclist = mcmc.list(lapply(Children_mcmc1,FUN=function(x) { x$Sol}))
>>>>>>>>>> save(Children_mcmc1,mcmclist, file = "rpqa_mcmc_kids_za.rdata")
>>>>>>>>>> closeCluster(cl)
>>>>>>>>>> mpi.quit()
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> --
>>>>>>>>>> Ruben C. Arslan
>>>>>>>>>> 
>>>>>>>>>> Georg August University G?ttingen
>>>>>>>>>> Biological Personality Psychology and Psychological Assessment
>>>>>>>>>> Georg Elias M?ller Institute of Psychology
>>>>>>>>>> Go?lerstr. 14
>>>>>>>>>> 37073 G?ttingen
>>>>>>>>>> Germany
>>>>>>>>>> Tel.: +49 551 3920704
>>>>>>>>>> https://psych.uni-goettingen.de/en/biopers/team/arslan
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> 	[[alternative HTML version deleted]]
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> --
>>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>>> Scotland, with registration number SC005336.
>>>>>>> 
>>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> --
>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>> Scotland, with registration number SC005336.
>>>>>> 
>>>>>> _______________________________________________
>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> --
>>>>> The University of Edinburgh is a charitable body, registered in
>>>>> Scotland, with registration number SC005336.
>>>>> 
>>>>> 
>>>> 
>>>> 
>>>> 
>>> 
>>> 
>>> 
>>> --
>>> The University of Edinburgh is a charitable body, registered in
>>> Scotland, with registration number SC005336.
>>> 
>>> 
>> 
>> 
> 
> 
> 
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
> 
> 


From j.hadfield at ed.ac.uk  Thu Aug 28 19:05:51 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 28 Aug 2014 18:05:51 +0100
Subject: [R-sig-ME] parallel MCMCglmm, RNGstreams,
 starting values & priors
In-Reply-To: <2D00600E-5287-4FE1-B605-82C0CBA286ED@gmail.com>
References: <4CD76FE1-D3F5-4980-9122-B0AC0D44FF81@gmail.com>
	<0E12EB43-72BC-42AC-9E74-9DF53DB42217@gmail.com>
	<20140825162907.10475jpywlu1wzs4@www.staffmail.ed.ac.uk>
	<0A463095-8656-49B7-9619-E557DD449E21@gmail.com>
	<20140825171414.10872gnlopk1we68@www.staffmail.ed.ac.uk>
	<20140825172936.15916weehiwjyc08@www.staffmail.ed.ac.uk>
	<8D35B834-0D31-486A-B5FB-0F279761FDB2@gmail.com>
	<49D60399-6902-45AC-80A9-9F3C35532228@gmail.com>
	<20140826120434.14613hxqhgwbhq80@www.staffmail.ed.ac.uk>
	<8557AE32-AFC9-4FD2-9C88-2D118B484637@gmail.com>
	<20140827183959.18662zc6hw5jj20w@www.staffmail.ed.ac.uk>
	<2D00600E-5287-4FE1-B605-82C0CBA286ED@gmail.com>
Message-ID: <20140828180551.74212a0xoeoihn6s@www.staffmail.ed.ac.uk>

Hi Ruben,

It might be hard to detect (near) ECPs with so many fixed effects (can  
you post the model summary (and give us the mean and standard  
deviation of any continuous covariates)). Also, the complementary  
log-log link (which is the za specification) is non-symmetric and runs  
into problems outside the range -35 to 3.5 so there may be a problem  
there, particularly if you use rcov=~trait:units and the Poisson part  
is highly over-dispersed.  You could try rcov=~idh(trait):units and  
fix the non-identifiable za residual variance to something smaller  
than 1 (say 0.5)  - it will mix slower but it will reduce the chance  
of over/underflow.

Cheers,

Jarrod




Quoting Ruben Arslan <rubenarslan at gmail.com> on Thu, 28 Aug 2014  
18:45:30 +0200:

> Hi Jarrod,
>
>> 1) it did not return an error with rcov = ~trait:units because you  
>> used R1=rpois(2,1)+1 and yet this specification only fits a single  
>> variance (not a 2x2 covariance matrix). R1=rpois(2,1)+1 is a bit of  
>> a weird specification since it has to be integer. I would obtain  
>> starting values using rIW().
>
> I agree it's a weird specification, I was a bit lost and thought I  
> could get away with just putting some random numbers in the starting  
> value.
> I didn't do R1=rpois(2,1)+1 though, I did R1=diag(rpois(2,1)+1), so  
> I got a 2x2 matrix, but yes, bound to be integer.
> I didn't know starting values should come from a conjugate  
> distribution, though that probably means I didn't think about it much.
>
> I'm now doing
> start <- list(
> 	liab=c(rnorm( nrow(krmh.1)*2 )),
> 	R = list(R1 = rIW( diag(2), nrow(krmh.1)) ),
> 	G = list(G1 = rIW( diag(2), nrow(krmh.1)) )
> )
>
> Is this what you had in mind?
> I am especially unsure if I am supposed to use such a low sampling  
> variability (my sample size is probably not even relevant for the  
> starting values) and if I should start from diag(2).
>
> And, I am still happily confused that this specification still  
> doesn't lead to errors with respect to rcov = ~trait:units . Does  
> this mean I'm doing it wrong?
>
>> 3) a) how many effective samples do you have for each parameter?  
>> and b) are you getting extreme category problems/numerical issues?  
>> If you store the latent variables (pl=TUE) what is their range for  
>> the Zi/za part?
>
> My parallel run using the above starting values isn't finished yet.
> a) After applying the above starting values I get, for the location  
> effects 1600-2000 samples for a 2000 sample chain (with thin set to  
> 50). G and R-structure are from 369 (za_children.idParents) to 716  
> (and 0 for the fixed part).
> Effective sample sizes were similar for my run using the starting  
> values for G/R that I drew from rpois, and using 40 chains I of  
> course get
> b) I don't think I am getting extreme categories. I would probably  
> be getting extreme categories if I included the forever-alones (they  
> almost never have children), but this way no.
> I wasn't sure how to examine the range of the latents separately for  
> the za part, but for a single chain it looks okay:
>> quantile(as.numeric(m1$Liab),probs = c(0,0.01,0,0.99,1))
>        0%        1%        0%       99%      100%
> -4.934111 -1.290728 -4.934111  3.389847  7.484206
>
> Well, all considered now that I use the above starting value  
> specification I get slightly different estimates for all  
> za-coefficients. Nothing major, but still leading me to
> think my estimates aren't exactly independent of the starting values  
> I use. I'll see what the parallel run yields.
>
> Thanks a lot,
>
> Ruben
>
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>>
>>
>>
>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Wed, 27 Aug 2014  
>> 19:23:42 +0200:
>>
>>> Hi Jarrod,
>>>
>>> thanks again. I was able to get it running with your advice.
>>> Some points of confusion remain:
>>>
>>> - You wrote that zi/za models would return an error with rcov =  
>>> ~trait:units + starting values. This did not happen in my case, so  
>>> I didn't build MCMCglmm myself with your suggested edits. Also,  
>>> have you considered putting your own MCMCglmm repo on Github? Your  
>>> users would be able to install pre-releases and I'd think you'd  
>>> get some time-saving pull requests too.
>>> - In my attempts to get my models to run properly, I messed up a  
>>> prior and did not use fix=2 in my prior specification for my za  
>>> models. This led to crappy convergence, it's much better now and  
>>> for some of my simpler models I think I won't need parallel  
>>> chains. I'm reminded of Gelman's folk theorem of statistical  
>>> computing.
>>> - I followed your advice, but of course I could not set the true  
>>> values as starting values, but wanted to set random, bad starting  
>>> values. I pasted below what I arrived at, I'm especially unsure  
>>> whether I specified the starting values for G and R properly (I  
>>> think not).
>>> 	start <- list(
>>> 		liab=c(rnorm( nrow(krmh.1)*2 )),
>>> 		R = list(R1 = diag(rpois(2, 1)+1)),
>>> 		G = list(G1 = diag(rpois(2, 1)+1))
>>> 	)
>>>
>>>
>>> However, even though I may not need multiple chains for some of my  
>>> simpler models, I've now run into conflicting diagnostics. The  
>>> geweke.diag for each chain (and examination of the traces) gives
>>> satisfactory diagnostics. Comparing multiple chains using  
>>> gelman.diag, however, leads to one bad guy, namely the  
>>> traitza_children:spouses interaction.
>>> I think this implies that I've got some starting value dependence  
>>> for this parameter, that won't be easily rectified through longer  
>>> burnin?
>>> Do you have any ideas how to rectify this?
>>> I am currently doing sequential analyses on episodes of selection  
>>> and in historical human data only those who marry have a chance at  
>>> having kids. I exclude the unmarried
>>> from my sample where I predict number of children, because I  
>>> examine that in a previous model and the zero-inflation (65%  
>>> zeros, median w/o unmarried = 4) when including the unmarried is  
>>> so excessive.
>>> Number of spouses is easily the strongest predictor in the model,  
>>> but only serves as a covariate here. Since my other estimates are  
>>> stable across chains and runs and agree well across models and  
>>> with theory, I'm
>>> inclined to shrug this off. But probably I shouldn't ignore this  
>>> sign of non-convergence?
>>>
>>>> gelman.diag(mcmc_1)
>>> Potential scale reduction factors:
>>>
>>>                                           Point est. Upper C.I.
>>> (Intercept)                                      1.00       1.00
>>> traitza_children                                 1.27       1.39
>>> male                                             1.00       1.00
>>> spouses                                          1.00       1.00
>>> paternalage.mean                                 1.00       1.00
>>> paternalage.factor(25,30]                        1.00       1.00
>>> paternalage.factor(30,35]                        1.00       1.00
>>> paternalage.factor(35,40]                        1.00       1.00
>>> paternalage.factor(40,45]                        1.00       1.00
>>> paternalage.factor(45,50]                        1.00       1.00
>>> paternalage.factor(50,55]                        1.00       1.00
>>> paternalage.factor(55,90]                        1.00       1.00
>>> traitza_children:male                            1.22       1.32
>>> traitza_children:spouses                         1.83       2.13
>>> traitza_children:paternalage.mean                1.02       1.02
>>> traitza_children:paternalage.factor(25,30]       1.03       1.05
>>> traitza_children:paternalage.factor(30,35]       1.05       1.08
>>> traitza_children:paternalage.factor(35,40]       1.10       1.15
>>> traitza_children:paternalage.factor(40,45]       1.12       1.17
>>> traitza_children:paternalage.factor(45,50]       1.19       1.28
>>> traitza_children:paternalage.factor(50,55]       1.12       1.18
>>> traitza_children:paternalage.factor(55,90]       1.11       1.17
>>>
>>> Multivariate psrf
>>>
>>> 7.27
>>>
>>>
>>> Best regards,
>>>
>>> Ruben
>>>
>>>
>>> On 26 Aug 2014, at 13:04, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>>
>>>> Hi Ruben,
>>>>
>>>> There are 400 liabilities in a zapoisson model (2 per datum).  
>>>> This code should work:
>>>>
>>>> g <-sample(letters[1:10], size = 200, replace = T)
>>>> pred <- rnorm(200)
>>>>
>>>> l1<-rnorm(200, -1, sqrt(1))
>>>> l2<-rnorm(200, -1, sqrt(1))
>>>>
>>>> y<-VGAM::rzapois(200, exp(l1), exp(-exp(l2)))
>>>>
>>>> # generate zero-altered data with an intercept of -1 (because the  
>>>> intercept and variance are the same for both processes this is  
>>>> just standard Poisson)
>>>>
>>>> dat<-data.frame(y=y, g = g, pred = pred)
>>>>
>>>>
>>>> start.1<-list(liab=c(l1,l2), R = list(R1=diag(2)), G=list(G1=diag(2)))
>>>> prior.1<-list(R=list(V=diag(2), nu=1.002, fix=2),  
>>>> G=list(G1=list(V=diag(2), nu=2, alpha.mu=c(0,0),  
>>>> alpha.V=diag(2)*1000)))
>>>>
>>>> m1<-MCMCglmm(y~trait + pred:trait, random=~us(trait):g,  
>>>> family="zapoisson",rcov=~idh(trait):units, data=dat,  
>>>> prior=prior.1, start= start.1)
>>>>
>>>> However, there are 2 bugs in the current version of MCMCglmm that  
>>>> return an error message when the documentation implies it should  
>>>> be fine:
>>>>
>>>> a) it should be possible to have R=diag(2) rather than R =  
>>>> list(R1=diag(2)). This bug cropped up when I implemented  
>>>> block-diagonal R structures. It can be fixed by inserting:
>>>>
>>>>         if(!is.list(start$R)){
>>>>            start$R<-list(R1=start$R)
>>>>         }
>>>>
>>>> on L514 of MCMCglmm.R below
>>>>
>>>>         if(!is.list(prior$R[[1]])){
>>>>            prior$R<-list(R1=prior$R)
>>>>         }
>>>>
>>>> b) rcov=~trait:units models for zi/za models will return an error  
>>>> when passing starting values. To fix this insert
>>>>
>>>>        if(diagR==3){
>>>>          if(dim(start)[1]!=1){
>>>>            stop("V is the wrong dimension for some  
>>>> strart$G/start$R elements")
>>>>          }
>>>>          start<-diag(sum(nfl))*start[1]
>>>>        }
>>>>
>>>> on L90 of priorfromat.R below
>>>>
>>>>        if(is.matrix(start)==FALSE){
>>>>          start<-as.matrix(start)
>>>>        }
>>>>
>>>> I will put these in the new version.
>>>>
>>>> Cheers,
>>>>
>>>> Jarrod
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25 Aug 2014  
>>>> 21:52:30 +0200:
>>>>
>>>>> Hi Jarrod,
>>>>>
>>>>> thanks for these pointers.
>>>>>
>>>>>>> You will need to provide over-dispersed starting values for  
>>>>>>> multiple-chain convergence diagnostics to be useful (GLMM are  
>>>>>>> so simple I am generally happy if the output of a single run  
>>>>>>> looks reasonable).
>>>>>
>>>>> Oh, I would be happy with single chains, but since computation  
>>>>> would take weeks this way, I wanted to parallelise and I would  
>>>>> use the multi-chain convergence as a criterion that my  
>>>>> parallelisation was proper
>>>>> and is as informative as a single long chain. There don't seem  
>>>>> to be any such checks built-in ? I was analysing my 40 chains  
>>>>> for a bit longer than I like to admit until I noticed they were  
>>>>> identical (effectiveSize
>>>>> and summary.mcmc.list did not yell at me for this).
>>>>>
>>>>>>> # use some very bad starting values
>>>>> I get that these values are bad, but that is the goal for my  
>>>>> multi-chain aim, right?
>>>>>
>>>>> I can apply this to my zero-truncated model, but am again  
>>>>> getting stuck with the zero-altered one.
>>>>> Maybe I need only specify the Liab values for this?
>>>>> At least I'm getting nowhere with specifying R and G starting  
>>>>> values here. When I got an error, I always
>>>>> went to the MCMCglmm source to understand why the checks failed,  
>>>>> but I didn't always understand
>>>>> what was being checked and couldn't get it to work.
>>>>>
>>>>> Here's a failing example:
>>>>>
>>>>> l<-rnorm(200, -1, sqrt(1))
>>>>> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
>>>>> g = sample(letters[1:10], size = 200, replace = T)
>>>>> pred = rnorm(200)
>>>>> y<-rpois(200,exp(l)-t)
>>>>> y[1:40] = 0
>>>>> # generate zero-altered data with an intercept of -1
>>>>>
>>>>> dat<-data.frame(y=y, g = g, pred = pred)
>>>>> set.seed(1)
>>>>> start_true = list(Liab=l, R = 1, G = 1 )
>>>>> m1<-MCMCglmm(y~1 + pred,random = ~ g,  
>>>>> family="zapoisson",rcov=~us(trait):units, data=dat, start=  
>>>>> start_true)
>>>>>
>>>>> # use true latent variable as starting values
>>>>> set.seed(1)
>>>>> # use some very bad starting values
>>>>> start_rand = list(Liab=rnorm(200), R = rpois(1, 1)+1, G = rpois(1, 1)+1 )
>>>>> m2<-MCMCglmm(y~1 + pred,random = ~ g,rcov=~us(trait):units,   
>>>>> family="zapoisson", data=dat, start = start_rand)
>>>>>
>>>>> Best,
>>>>>
>>>>> Ruben
>>>>>
>>>>> On 25 Aug 2014, at 18:29, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>>>>
>>>>>> Hi Ruben,
>>>>>>
>>>>>> Sorry  - I was wrong when I said that everything is Gibbs  
>>>>>> sampled conditional on the latent variables. The location  
>>>>>> effects (fixed and random effects) are also sampled conditional  
>>>>>> on the (co)variance components so you should add them to the  
>>>>>> starting values. In the case where the true values are used:
>>>>>>
>>>>>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat, start=list(Liab=l,R=1))
>>>>>>
>>>>>> Cheers,
>>>>>>
>>>>>> Jarrod
>>>>>>
>>>>>>
>>>>>>
>>>>>> Quoting Jarrod Hadfield <j.hadfield at ed.ac.uk> on Mon, 25 Aug  
>>>>>> 2014 17:14:14 +0100:
>>>>>>
>>>>>>> Hi Ruben,
>>>>>>>
>>>>>>> You will need to provide over-dispersed starting values for  
>>>>>>> multiple-chain convergence diagnostics to be useful (GLMM are  
>>>>>>> so simple I am generally happy if the output of a single run  
>>>>>>> looks reasonable).
>>>>>>>
>>>>>>> With non-Gaussian data everything is Gibbs sampled conditional  
>>>>>>> on the latent variables, so you only need to pass them:
>>>>>>>
>>>>>>> l<-rnorm(200, -1, sqrt(1))
>>>>>>> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
>>>>>>> y<-rpois(200,exp(l)-t)+1
>>>>>>> # generate zero-truncated data with an intercept of -1
>>>>>>>
>>>>>>> dat<-data.frame(y=y)
>>>>>>> set.seed(1)
>>>>>>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat, start=list(Liab=l))
>>>>>>> # use true latent variable as starting values
>>>>>>> set.seed(1)
>>>>>>> m2<-MCMCglmm(y~1, family="ztpoisson", data=dat,  
>>>>>>> start=list(Liab=rnorm(200)))
>>>>>>> # use some very bad starting values
>>>>>>>
>>>>>>> plot(mcmc.list(m1$Sol, m2$Sol))
>>>>>>> # not identical despite the same seed because of different  
>>>>>>> starting values but clearly sampling the same posterior  
>>>>>>> distribution:
>>>>>>>
>>>>>>> gelman.diag(mcmc.list(m1$Sol, m2$Sol))
>>>>>>>
>>>>>>> Cheers,
>>>>>>>
>>>>>>> Jarrod
>>>>>>>
>>>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25 Aug  
>>>>>>> 2014 18:00:08 +0200:
>>>>>>>
>>>>>>>> Dear Jarrod,
>>>>>>>>
>>>>>>>> thanks for the quick reply. Please, don't waste time looking  
>>>>>>>> into doMPI ? I am happy that I
>>>>>>>> get the expected result, when I specify that reproducible  
>>>>>>>> seed, whyever that may be.
>>>>>>>> I'm pretty sure that is the deciding factor, because I tested  
>>>>>>>> it explicitly, I just have no idea
>>>>>>>> how/why it interacts with the choice of family.
>>>>>>>>
>>>>>>>> That said, is setting up different RNG streams for my workers  
>>>>>>>> (now that it works) __sufficient__
>>>>>>>> so that I get independent chains and can use gelman.diag()  
>>>>>>>> for convergence diagnostics?
>>>>>>>> Or should I still tinker with the starting values myself?
>>>>>>>> I've never found a worked example of supplying starting  
>>>>>>>> values and am thus a bit lost.
>>>>>>>>
>>>>>>>> Sorry for sending further questions, I hope someone else  
>>>>>>>> takes pity while
>>>>>>>> you're busy with lectures.
>>>>>>>>
>>>>>>>> Best wishes
>>>>>>>>
>>>>>>>> Ruben
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> On 25 Aug 2014, at 17:29, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>>>>>>>
>>>>>>>>> Hi Ruben,
>>>>>>>>>
>>>>>>>>> I do not think the issue is with the starting values,  
>>>>>>>>> because even if the same starting values were used the  
>>>>>>>>> chains would still differ because of the randomness in the  
>>>>>>>>> Markov Chain (if I interpret your `identical' test  
>>>>>>>>> correctly). This just involves a call to GetRNGstate() in  
>>>>>>>>> the C++ code (L 871 ofMCMCglmm.cc) so I think for some  
>>>>>>>>> reason doMPI/foreach is not doing what you expect. I am not  
>>>>>>>>> familiar with doMPI and am in the middle of writing lectures  
>>>>>>>>> so haven't got time to look into it carefully. Outside of  
>>>>>>>>> the context of doMPI I get the behaviour I expect:
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> l<-rnorm(200, -1, sqrt(1))
>>>>>>>>> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
>>>>>>>>> y<-rpois(200,exp(l)-t)+1
>>>>>>>>> # generate zero-truncated data with an intercept of -1
>>>>>>>>>
>>>>>>>>> dat<-data.frame(y=y)
>>>>>>>>> set.seed(1)
>>>>>>>>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>>>>>>> set.seed(2)
>>>>>>>>> m2<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>>>>>>> set.seed(2)
>>>>>>>>> m3<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>>>>>>>
>>>>>>>>> plot(mcmc.list(m1$Sol, m2$Sol))
>>>>>>>>> # different, as expected
>>>>>>>>> plot(mcmc.list(m2$Sol, m3$Sol))
>>>>>>>>> # the same, as expected
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25 Aug  
>>>>>>>>> 2014 16:58:06 +0200:
>>>>>>>>>
>>>>>>>>>> Dear list,
>>>>>>>>>>
>>>>>>>>>> sorry for bumping my old post, I hope to elicit a response  
>>>>>>>>>> with a more focused question:
>>>>>>>>>>
>>>>>>>>>> When does MCMCglmm automatically start from different  
>>>>>>>>>> values when using doMPI/foreach?
>>>>>>>>>>
>>>>>>>>>> I have done some tests with models of varying complexity.  
>>>>>>>>>> For example, the script in my last
>>>>>>>>>> post (using "zapoisson") yielded 40 identical chains:
>>>>>>>>>>> identical(mcmclist[1], mcmclist[30])
>>>>>>>>>> TRUE
>>>>>>>>>>
>>>>>>>>>> A simpler (?) model (using "ztpoisson" and no specified  
>>>>>>>>>> prior), however, yielded different chains
>>>>>>>>>> and I could use them to calculate gelman.diag()
>>>>>>>>>>
>>>>>>>>>> Changing my script to the version below, i.e. seeding  
>>>>>>>>>> foreach using .options.mpi=list( seed= 1337)
>>>>>>>>>> so as to make RNGstreams reproducible (or so I  thought),  
>>>>>>>>>> led to different chains even for the
>>>>>>>>>> "zapoisson" model.
>>>>>>>>>>
>>>>>>>>>> In no case have I (successfully) tried to supplant the  
>>>>>>>>>> default of MCMCglmm's "start" argument.
>>>>>>>>>> Is starting my models from different RNGsubstreams  
>>>>>>>>>> inadequate compared to manipulating
>>>>>>>>>> the start argument explicitly? If so, is there any worked  
>>>>>>>>>> example of explicit starting value manipulation
>>>>>>>>>> in parallel computation?
>>>>>>>>>> I've browsed the MCMCglmm source to understand how the  
>>>>>>>>>> default starting values are generated,
>>>>>>>>>> but didn't find any differences with respect to RNG for the  
>>>>>>>>>> two families "ztpoisson" and "zapoisson"
>>>>>>>>>> (granted, I did not dig very deep).
>>>>>>>>>>
>>>>>>>>>> Best regards,
>>>>>>>>>>
>>>>>>>>>> Ruben Arslan
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> # bsub -q mpi -W 12:00 -n 41 -R np20 mpirun -H localhost -n  
>>>>>>>>>> 41 R --slave -f  
>>>>>>>>>> "/usr/users/rarslan/rpqa/rpqa_main/rpqa_children_parallel.R"
>>>>>>>>>>
>>>>>>>>>> library(doMPI)
>>>>>>>>>> cl <-  
>>>>>>>>>> startMPIcluster(verbose=T,workdir="/usr/users/rarslan/rpqa/rpqa_main/")
>>>>>>>>>> registerDoMPI(cl)
>>>>>>>>>> Children_mcmc1 = foreach(i=1:clusterSize(cl),.options.mpi =  
>>>>>>>>>> list(seed=1337) ) %dopar% {
>>>>>>>>>> 	library(MCMCglmm);library(data.table)
>>>>>>>>>> 	load("/usr/users/rarslan/rpqa/rpqa1.rdata")
>>>>>>>>>>
>>>>>>>>>> 	nitt = 130000; thin = 100; burnin = 30000
>>>>>>>>>> 	prior.m5d.2 = list(
>>>>>>>>>> 		R = list(V = diag(c(1,1)), nu = 0.002),
>>>>>>>>>> 		G=list(list(V=diag(c(1,1e-6)),nu=0.002))
>>>>>>>>>> 	)
>>>>>>>>>>
>>>>>>>>>> 	rpqa.1 = na.omit(rpqa.1[spouses>0, list(idParents,  
>>>>>>>>>> children, male, urban, spouses, paternalage.mean,  
>>>>>>>>>> paternalage.factor)])
>>>>>>>>>> 	(m1 = MCMCglmm( children ~ trait * (male + urban + spouses  
>>>>>>>>>> + paternalage.mean + paternalage.factor),
>>>>>>>>>> 						rcov=~us(trait):units,
>>>>>>>>>> 						random=~us(trait):idParents,
>>>>>>>>>> 						family="zapoisson",
>>>>>>>>>> 						prior = prior.m5d.2,
>>>>>>>>>> 						data=rpqa.1,
>>>>>>>>>> 						pr = F, saveX = F, saveZ = F,
>>>>>>>>>> 						nitt=nitt,thin=thin,burnin=burnin))
>>>>>>>>>> }
>>>>>>>>>>
>>>>>>>>>> library(coda)
>>>>>>>>>> mcmclist = mcmc.list(lapply(Children_mcmc1,FUN=function(x)  
>>>>>>>>>> { x$Sol}))
>>>>>>>>>> save(Children_mcmc1,mcmclist, file =  
>>>>>>>>>> "/usr/users/rarslan/rpqa/rpqa_main/rpqa_mcmc_kids_za.rdata")
>>>>>>>>>> closeCluster(cl)
>>>>>>>>>> mpi.quit()
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> On 04 Aug 2014, at 20:25, Ruben Arslan  
>>>>>>>>>> <rubenarslan at gmail.com> wrote:
>>>>>>>>>>
>>>>>>>>>>> Dear list,
>>>>>>>>>>>
>>>>>>>>>>> would someone be willing to share her or his efforts in  
>>>>>>>>>>> parallelising a MCMCglmm analysis?
>>>>>>>>>>>
>>>>>>>>>>> I had something viable using harvestr that seemed to  
>>>>>>>>>>> properly initialise
>>>>>>>>>>> the starting values from different random number streams  
>>>>>>>>>>> (which is desirable,
>>>>>>>>>>> as far as I could find out), but I ended up being unable  
>>>>>>>>>>> to use harvestr, because
>>>>>>>>>>> it uses an old version of plyr, where parallelisation  
>>>>>>>>>>> works only for multicore, not for
>>>>>>>>>>> MPI.
>>>>>>>>>>>
>>>>>>>>>>> I pasted my working version, that does not do anything  
>>>>>>>>>>> about starting values or RNG
>>>>>>>>>>> at the end of this email. I can try to fumble further in  
>>>>>>>>>>> the dark or try to update harvestr,
>>>>>>>>>>> but maybe someone has gone through all this already.
>>>>>>>>>>>
>>>>>>>>>>> I'd also appreciate any tips for elegantly post-processing  
>>>>>>>>>>> such parallel data, as some of my usual
>>>>>>>>>>> extraction functions and routines are hampered by the fact  
>>>>>>>>>>> that some coda functions
>>>>>>>>>>> do not aggregate results over chains. (What I get from a  
>>>>>>>>>>> single-chain summary in MCMCglmm
>>>>>>>>>>> is a bit more comprehensive, than what I managed to cobble  
>>>>>>>>>>> together with my own extraction
>>>>>>>>>>> functions).
>>>>>>>>>>>
>>>>>>>>>>> The reason I'm parallelising my analyses is that I'm  
>>>>>>>>>>> having trouble getting a good effective
>>>>>>>>>>> sample size for any parameter having to do with the many  
>>>>>>>>>>> zeroes in my data.
>>>>>>>>>>> Any pointers are very appreciated, I'm quite inexperienced  
>>>>>>>>>>> with MCMCglmm.
>>>>>>>>>>>
>>>>>>>>>>> Best wishes
>>>>>>>>>>>
>>>>>>>>>>> Ruben
>>>>>>>>>>>
>>>>>>>>>>> # bsub -q mpi-short -W 2:00 -n 42 -R np20 mpirun -H  
>>>>>>>>>>> localhost -n 41 R --slave -f  
>>>>>>>>>>> "rpqa/rpqa_main/rpqa_children_parallel.r"
>>>>>>>>>>> library(doMPI)
>>>>>>>>>>> cl <- startMPIcluster()
>>>>>>>>>>> registerDoMPI(cl)
>>>>>>>>>>> Children_mcmc1 = foreach(i=1:40) %dopar% {
>>>>>>>>>>> 	library(MCMCglmm)
>>>>>>>>>>> 	load("rpqa1.rdata")
>>>>>>>>>>>
>>>>>>>>>>> 	nitt = 40000; thin = 100; burnin = 10000
>>>>>>>>>>> 	prior = list(
>>>>>>>>>>> 		R = list(V = diag(c(1,1)), nu = 0.002),
>>>>>>>>>>> 		G=list(list(V=diag(c(1,1e-6)),nu=0.002))
>>>>>>>>>>> 	)
>>>>>>>>>>>
>>>>>>>>>>> 	MCMCglmm( children ~ trait -1 + at.level(trait,1):male +  
>>>>>>>>>>> at.level(trait,1):urban + at.level(trait,1):spouses +  
>>>>>>>>>>> at.level(trait,1):paternalage.mean +  
>>>>>>>>>>> at.level(trait,1):paternalage.factor,
>>>>>>>>>>> 		rcov=~us(trait):units,
>>>>>>>>>>> 		random=~us(trait):idParents,
>>>>>>>>>>> 		family="zapoisson",
>>>>>>>>>>> 		prior = prior,
>>>>>>>>>>> 		data=rpqa.1,
>>>>>>>>>>> 		pr = F, saveX = T, saveZ = T,
>>>>>>>>>>> 		nitt=nitt,thin=thin,burnin=burnin)
>>>>>>>>>>> }
>>>>>>>>>>>
>>>>>>>>>>> library(coda)
>>>>>>>>>>> mcmclist = mcmc.list(lapply(Children_mcmc1,FUN=function(x)  
>>>>>>>>>>> { x$Sol}))
>>>>>>>>>>> save(Children_mcmc1,mcmclist, file = "rpqa_mcmc_kids_za.rdata")
>>>>>>>>>>> closeCluster(cl)
>>>>>>>>>>> mpi.quit()
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>> --
>>>>>>>>>>> Ruben C. Arslan
>>>>>>>>>>>
>>>>>>>>>>> Georg August University G?ttingen
>>>>>>>>>>> Biological Personality Psychology and Psychological Assessment
>>>>>>>>>>> Georg Elias M?ller Institute of Psychology
>>>>>>>>>>> Go?lerstr. 14
>>>>>>>>>>> 37073 G?ttingen
>>>>>>>>>>> Germany
>>>>>>>>>>> Tel.: +49 551 3920704
>>>>>>>>>>> https://psych.uni-goettingen.de/en/biopers/team/arslan
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> 	[[alternative HTML version deleted]]
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> --
>>>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>>>> Scotland, with registration number SC005336.
>>>>>>>>
>>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> --
>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>> Scotland, with registration number SC005336.
>>>>>>>
>>>>>>> _______________________________________________
>>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> --
>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>> Scotland, with registration number SC005336.
>>>>>>
>>>>>>
>>>>>
>>>>>
>>>>>
>>>>
>>>>
>>>>
>>>> --
>>>> The University of Edinburgh is a charitable body, registered in
>>>> Scotland, with registration number SC005336.
>>>>
>>>>
>>>
>>>
>>
>>
>>
>> --
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>>
>
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From rubenarslan at gmail.com  Thu Aug 28 19:59:16 2014
From: rubenarslan at gmail.com (Ruben Arslan)
Date: Thu, 28 Aug 2014 19:59:16 +0200
Subject: [R-sig-ME] parallel MCMCglmm, RNGstreams,
	starting values & priors
In-Reply-To: <20140828180551.74212a0xoeoihn6s@www.staffmail.ed.ac.uk>
References: <4CD76FE1-D3F5-4980-9122-B0AC0D44FF81@gmail.com>
	<0E12EB43-72BC-42AC-9E74-9DF53DB42217@gmail.com>
	<20140825162907.10475jpywlu1wzs4@www.staffmail.ed.ac.uk>
	<0A463095-8656-49B7-9619-E557DD449E21@gmail.com>
	<20140825171414.10872gnlopk1we68@www.staffmail.ed.ac.uk>
	<20140825172936.15916weehiwjyc08@www.staffmail.ed.ac.uk>
	<8D35B834-0D31-486A-B5FB-0F279761FDB2@gmail.com>
	<49D60399-6902-45AC-80A9-9F3C35532228@gmail.com>
	<20140826120434.14613hxqhgwbhq80@www.staffmail.ed.ac.uk>
	<8557AE32-AFC9-4FD2-9C88-2D118B484637@gmail.com>
	<20140827183959.18662zc6hw5jj20w@www.staffmail.ed.ac.uk>
	<2D00600E-5287-4FE1-B605-82C0CBA286ED@gmail.com>
	<20140828180551.74212a0xoeoihn6s@www.staffmail.ed.ac.uk>
Message-ID: <BBB5F7E3-75FE-4BA3-82B4-49DAA64873A4@gmail.com>

Sure! Thanks a lot. 
I am using ~idh(trait):units already, sorry for saying that incorrectly in my last email. 
These models aren't the final thing, I will replace the paternalage.factor variable
with its linear equivalent if that seems defensible (does so far) and in this model it seems
okay to remove the za-effects for all predictors except spouses.
So a final model would have fewer fixed effects. I also have datasets of 200k+ and 5m+,
but I'm learning MCMCglmm with this smaller one because my wrong turns take less time.

I've uploaded a comparison coef plot of two models:
http://i.imgur.com/sHUfnmd.png
m7 is with the default starting values, m1 is with the specification I sent in my last email. I don't
know if such differences are something to worry about.

I don't know what qualifies as highly overdispersed, here's a plot of the outcome for ever
married people (slate=real data):
http://imgur.com/14MywgZ
here's with everybody born (incl. some stillborn etc.):
http://imgur.com/knRGa1v
I guess my approach (generating an overdispersed poisson with the parameters from
the data and checking if it has as excess zeroes) is not the best way to diagnose zero-inflation,
but especially in the second case it seems fairly clear-cut.

Best regards,

Ruben

> summary(m1)

 Iterations = 50001:149951
 Thinning interval  = 50
 Sample size  = 2000 

 DIC: 31249.73 

 G-structure:  ~idh(trait):idParents

                      post.mean  l-95% CI u-95% CI eff.samp
children.idParents     0.006611 4.312e-08   0.0159    523.9
za_children.idParents  0.193788 7.306e-02   0.3283    369.3

 R-structure:  ~idh(trait):units

                  post.mean l-95% CI u-95% CI eff.samp
children.units       0.1285   0.1118   0.1452    716.1
za_children.units    0.9950   0.9950   0.9950      0.0

 Location effects: children ~ trait * (male + spouses + paternalage.mean + paternalage.factor) 

                                            post.mean   l-95% CI   u-95% CI eff.samp  pMCMC    
(Intercept)                                 1.3413364  1.2402100  1.4326099     1789 <5e-04 ***
traitza_children                           -0.8362879 -1.2007980 -0.5016730     1669 <5e-04 ***
male                                        0.0994902  0.0679050  0.1297394     2000 <5e-04 ***
spouses                                     0.1236033  0.0839000  0.1624939     2000 <5e-04 ***
paternalage.mean                            0.0533892  0.0119569  0.0933960     2000  0.015 *  
paternalage.factor(25,30]                  -0.0275822 -0.1116421  0.0537359     1842  0.515    
paternalage.factor(30,35]                  -0.0691025 -0.1463214  0.0122393     1871  0.097 .  
paternalage.factor(35,40]                  -0.1419933 -0.2277379 -0.0574678     1845 <5e-04 ***
paternalage.factor(40,45]                  -0.1364952 -0.2362714 -0.0451874     1835  0.007 ** 
paternalage.factor(45,50]                  -0.1445342 -0.2591767 -0.0421178     1693  0.008 ** 
paternalage.factor(50,55]                  -0.1302972 -0.2642965  0.0077061     2000  0.064 .  
paternalage.factor(55,90]                  -0.3407879 -0.5168972 -0.1493652     1810 <5e-04 ***
traitza_children:male                       0.0926888 -0.0147379  0.2006142     1901  0.098 .  
traitza_children:spouses                    0.5531197  0.3870616  0.7314289     1495 <5e-04 ***
traitza_children:paternalage.mean           0.0051463 -0.1279396  0.1460099     1617  0.960    
traitza_children:paternalage.factor(25,30] -0.1538957 -0.4445749  0.1462955     1781  0.321    
traitza_children:paternalage.factor(30,35] -0.1747883 -0.4757851  0.1162476     1998  0.261    
traitza_children:paternalage.factor(35,40] -0.2261843 -0.5464379  0.0892582     1755  0.166    
traitza_children:paternalage.factor(40,45] -0.2807543 -0.6079678  0.0650281     1721  0.100 .  
traitza_children:paternalage.factor(45,50] -0.4905843 -0.8649214 -0.1244174     1735  0.010 ** 
traitza_children:paternalage.factor(50,55] -0.4648579 -0.9215759 -0.0002083     1687  0.054 .  
traitza_children:paternalage.factor(55,90] -0.3945406 -1.0230155  0.2481568     1793  0.195    
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

> describe(krmh.1[spouses>0,])
                    vars    n mean   sd median trimmed  mad   min   max range skew kurtosis   se
children               2 6829 3.81 2.93   4.00    3.61 2.97  0.00 16.00 16.00 0.47    -0.46 0.04
male                   3 6829 0.46 0.50   0.00    0.45 0.00  0.00  1.00  1.00 0.14    -1.98 0.01
spouses                4 6829 1.14 0.38   1.00    1.03 0.00  1.00  4.00  3.00 2.87     8.23 0.00
paternalage            5 6829 3.65 0.80   3.57    3.60 0.80  1.83  7.95  6.12 0.69     0.70 0.01
paternalage_c          6 6829 0.00 0.80  -0.08   -0.05 0.80 -1.82  4.30  6.12 0.69     0.70 0.01
paternalage.mean       7 6829 0.00 0.68  -0.08   -0.05 0.59 -1.74  4.30  6.04 0.95     1.97 0.01
paternalage.diff       8 6829 0.00 0.42   0.00   -0.01 0.38 -1.51  1.48  2.99 0.17     0.17 0.01

> table(krmh.1$paternalage.factor)

 [0,25] (25,30] (30,35] (35,40] (40,45] (45,50] (50,55] (55,90] 
    309    1214    1683    1562    1039     623     269     130 

On 28 Aug 2014, at 19:05, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:

> Hi Ruben,
> 
> It might be hard to detect (near) ECPs with so many fixed effects (can you post the model summary (and give us the mean and standard deviation of any continuous covariates)). Also, the complementary log-log link (which is the za specification) is non-symmetric and runs into problems outside the range -35 to 3.5 so there may be a problem there, particularly if you use rcov=~trait:units and the Poisson part is highly over-dispersed.  You could try rcov=~idh(trait):units and fix the non-identifiable za residual variance to something smaller than 1 (say 0.5)  - it will mix slower but it will reduce the chance of over/underflow.
> 
> Cheers,
> 
> Jarrod
> 
> 
> 
> 
> Quoting Ruben Arslan <rubenarslan at gmail.com> on Thu, 28 Aug 2014 18:45:30 +0200:
> 
>> Hi Jarrod,
>> 
>>> 1) it did not return an error with rcov = ~trait:units because you used R1=rpois(2,1)+1 and yet this specification only fits a single variance (not a 2x2 covariance matrix). R1=rpois(2,1)+1 is a bit of a weird specification since it has to be integer. I would obtain starting values using rIW().
>> 
>> I agree it's a weird specification, I was a bit lost and thought I could get away with just putting some random numbers in the starting value.
>> I didn't do R1=rpois(2,1)+1 though, I did R1=diag(rpois(2,1)+1), so I got a 2x2 matrix, but yes, bound to be integer.
>> I didn't know starting values should come from a conjugate distribution, though that probably means I didn't think about it much.
>> 
>> I'm now doing
>> start <- list(
>> 	liab=c(rnorm( nrow(krmh.1)*2 )),
>> 	R = list(R1 = rIW( diag(2), nrow(krmh.1)) ),
>> 	G = list(G1 = rIW( diag(2), nrow(krmh.1)) )
>> )
>> 
>> Is this what you had in mind?
>> I am especially unsure if I am supposed to use such a low sampling variability (my sample size is probably not even relevant for the starting values) and if I should start from diag(2).
>> 
>> And, I am still happily confused that this specification still doesn't lead to errors with respect to rcov = ~trait:units . Does this mean I'm doing it wrong?
>> 
>>> 3) a) how many effective samples do you have for each parameter? and b) are you getting extreme category problems/numerical issues? If you store the latent variables (pl=TUE) what is their range for the Zi/za part?
>> 
>> My parallel run using the above starting values isn't finished yet.
>> a) After applying the above starting values I get, for the location effects 1600-2000 samples for a 2000 sample chain (with thin set to 50). G and R-structure are from 369 (za_children.idParents) to 716 (and 0 for the fixed part).
>> Effective sample sizes were similar for my run using the starting values for G/R that I drew from rpois, and using 40 chains I of course get
>> b) I don't think I am getting extreme categories. I would probably be getting extreme categories if I included the forever-alones (they almost never have children), but this way no.
>> I wasn't sure how to examine the range of the latents separately for the za part, but for a single chain it looks okay:
>>> quantile(as.numeric(m1$Liab),probs = c(0,0.01,0,0.99,1))
>>       0%        1%        0%       99%      100%
>> -4.934111 -1.290728 -4.934111  3.389847  7.484206
>> 
>> Well, all considered now that I use the above starting value specification I get slightly different estimates for all za-coefficients. Nothing major, but still leading me to
>> think my estimates aren't exactly independent of the starting values I use. I'll see what the parallel run yields.
>> 
>> Thanks a lot,
>> 
>> Ruben
>> 
>>> 
>>> Cheers,
>>> 
>>> Jarrod
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Wed, 27 Aug 2014 19:23:42 +0200:
>>> 
>>>> Hi Jarrod,
>>>> 
>>>> thanks again. I was able to get it running with your advice.
>>>> Some points of confusion remain:
>>>> 
>>>> - You wrote that zi/za models would return an error with rcov = ~trait:units + starting values. This did not happen in my case, so I didn't build MCMCglmm myself with your suggested edits. Also, have you considered putting your own MCMCglmm repo on Github? Your users would be able to install pre-releases and I'd think you'd get some time-saving pull requests too.
>>>> - In my attempts to get my models to run properly, I messed up a prior and did not use fix=2 in my prior specification for my za models. This led to crappy convergence, it's much better now and for some of my simpler models I think I won't need parallel chains. I'm reminded of Gelman's folk theorem of statistical computing.
>>>> - I followed your advice, but of course I could not set the true values as starting values, but wanted to set random, bad starting values. I pasted below what I arrived at, I'm especially unsure whether I specified the starting values for G and R properly (I think not).
>>>> 	start <- list(
>>>> 		liab=c(rnorm( nrow(krmh.1)*2 )),
>>>> 		R = list(R1 = diag(rpois(2, 1)+1)),
>>>> 		G = list(G1 = diag(rpois(2, 1)+1))
>>>> 	)
>>>> 
>>>> 
>>>> However, even though I may not need multiple chains for some of my simpler models, I've now run into conflicting diagnostics. The geweke.diag for each chain (and examination of the traces) gives
>>>> satisfactory diagnostics. Comparing multiple chains using gelman.diag, however, leads to one bad guy, namely the traitza_children:spouses interaction.
>>>> I think this implies that I've got some starting value dependence for this parameter, that won't be easily rectified through longer burnin?
>>>> Do you have any ideas how to rectify this?
>>>> I am currently doing sequential analyses on episodes of selection and in historical human data only those who marry have a chance at having kids. I exclude the unmarried
>>>> from my sample where I predict number of children, because I examine that in a previous model and the zero-inflation (65% zeros, median w/o unmarried = 4) when including the unmarried is so excessive.
>>>> Number of spouses is easily the strongest predictor in the model, but only serves as a covariate here. Since my other estimates are stable across chains and runs and agree well across models and with theory, I'm
>>>> inclined to shrug this off. But probably I shouldn't ignore this sign of non-convergence?
>>>> 
>>>>> gelman.diag(mcmc_1)
>>>> Potential scale reduction factors:
>>>> 
>>>>                                          Point est. Upper C.I.
>>>> (Intercept)                                      1.00       1.00
>>>> traitza_children                                 1.27       1.39
>>>> male                                             1.00       1.00
>>>> spouses                                          1.00       1.00
>>>> paternalage.mean                                 1.00       1.00
>>>> paternalage.factor(25,30]                        1.00       1.00
>>>> paternalage.factor(30,35]                        1.00       1.00
>>>> paternalage.factor(35,40]                        1.00       1.00
>>>> paternalage.factor(40,45]                        1.00       1.00
>>>> paternalage.factor(45,50]                        1.00       1.00
>>>> paternalage.factor(50,55]                        1.00       1.00
>>>> paternalage.factor(55,90]                        1.00       1.00
>>>> traitza_children:male                            1.22       1.32
>>>> traitza_children:spouses                         1.83       2.13
>>>> traitza_children:paternalage.mean                1.02       1.02
>>>> traitza_children:paternalage.factor(25,30]       1.03       1.05
>>>> traitza_children:paternalage.factor(30,35]       1.05       1.08
>>>> traitza_children:paternalage.factor(35,40]       1.10       1.15
>>>> traitza_children:paternalage.factor(40,45]       1.12       1.17
>>>> traitza_children:paternalage.factor(45,50]       1.19       1.28
>>>> traitza_children:paternalage.factor(50,55]       1.12       1.18
>>>> traitza_children:paternalage.factor(55,90]       1.11       1.17
>>>> 
>>>> Multivariate psrf
>>>> 
>>>> 7.27
>>>> 
>>>> 
>>>> Best regards,
>>>> 
>>>> Ruben
>>>> 
>>>> 
>>>> On 26 Aug 2014, at 13:04, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>>> 
>>>>> Hi Ruben,
>>>>> 
>>>>> There are 400 liabilities in a zapoisson model (2 per datum). This code should work:
>>>>> 
>>>>> g <-sample(letters[1:10], size = 200, replace = T)
>>>>> pred <- rnorm(200)
>>>>> 
>>>>> l1<-rnorm(200, -1, sqrt(1))
>>>>> l2<-rnorm(200, -1, sqrt(1))
>>>>> 
>>>>> y<-VGAM::rzapois(200, exp(l1), exp(-exp(l2)))
>>>>> 
>>>>> # generate zero-altered data with an intercept of -1 (because the intercept and variance are the same for both processes this is just standard Poisson)
>>>>> 
>>>>> dat<-data.frame(y=y, g = g, pred = pred)
>>>>> 
>>>>> 
>>>>> start.1<-list(liab=c(l1,l2), R = list(R1=diag(2)), G=list(G1=diag(2)))
>>>>> prior.1<-list(R=list(V=diag(2), nu=1.002, fix=2), G=list(G1=list(V=diag(2), nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000)))
>>>>> 
>>>>> m1<-MCMCglmm(y~trait + pred:trait, random=~us(trait):g, family="zapoisson",rcov=~idh(trait):units, data=dat, prior=prior.1, start= start.1)
>>>>> 
>>>>> However, there are 2 bugs in the current version of MCMCglmm that return an error message when the documentation implies it should be fine:
>>>>> 
>>>>> a) it should be possible to have R=diag(2) rather than R = list(R1=diag(2)). This bug cropped up when I implemented block-diagonal R structures. It can be fixed by inserting:
>>>>> 
>>>>>        if(!is.list(start$R)){
>>>>>           start$R<-list(R1=start$R)
>>>>>        }
>>>>> 
>>>>> on L514 of MCMCglmm.R below
>>>>> 
>>>>>        if(!is.list(prior$R[[1]])){
>>>>>           prior$R<-list(R1=prior$R)
>>>>>        }
>>>>> 
>>>>> b) rcov=~trait:units models for zi/za models will return an error when passing starting values. To fix this insert
>>>>> 
>>>>>       if(diagR==3){
>>>>>         if(dim(start)[1]!=1){
>>>>>           stop("V is the wrong dimension for some strart$G/start$R elements")
>>>>>         }
>>>>>         start<-diag(sum(nfl))*start[1]
>>>>>       }
>>>>> 
>>>>> on L90 of priorfromat.R below
>>>>> 
>>>>>       if(is.matrix(start)==FALSE){
>>>>>         start<-as.matrix(start)
>>>>>       }
>>>>> 
>>>>> I will put these in the new version.
>>>>> 
>>>>> Cheers,
>>>>> 
>>>>> Jarrod
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25 Aug 2014 21:52:30 +0200:
>>>>> 
>>>>>> Hi Jarrod,
>>>>>> 
>>>>>> thanks for these pointers.
>>>>>> 
>>>>>>>> You will need to provide over-dispersed starting values for multiple-chain convergence diagnostics to be useful (GLMM are so simple I am generally happy if the output of a single run looks reasonable).
>>>>>> 
>>>>>> Oh, I would be happy with single chains, but since computation would take weeks this way, I wanted to parallelise and I would use the multi-chain convergence as a criterion that my parallelisation was proper
>>>>>> and is as informative as a single long chain. There don't seem to be any such checks built-in ? I was analysing my 40 chains for a bit longer than I like to admit until I noticed they were identical (effectiveSize
>>>>>> and summary.mcmc.list did not yell at me for this).
>>>>>> 
>>>>>>>> # use some very bad starting values
>>>>>> I get that these values are bad, but that is the goal for my multi-chain aim, right?
>>>>>> 
>>>>>> I can apply this to my zero-truncated model, but am again getting stuck with the zero-altered one.
>>>>>> Maybe I need only specify the Liab values for this?
>>>>>> At least I'm getting nowhere with specifying R and G starting values here. When I got an error, I always
>>>>>> went to the MCMCglmm source to understand why the checks failed, but I didn't always understand
>>>>>> what was being checked and couldn't get it to work.
>>>>>> 
>>>>>> Here's a failing example:
>>>>>> 
>>>>>> l<-rnorm(200, -1, sqrt(1))
>>>>>> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
>>>>>> g = sample(letters[1:10], size = 200, replace = T)
>>>>>> pred = rnorm(200)
>>>>>> y<-rpois(200,exp(l)-t)
>>>>>> y[1:40] = 0
>>>>>> # generate zero-altered data with an intercept of -1
>>>>>> 
>>>>>> dat<-data.frame(y=y, g = g, pred = pred)
>>>>>> set.seed(1)
>>>>>> start_true = list(Liab=l, R = 1, G = 1 )
>>>>>> m1<-MCMCglmm(y~1 + pred,random = ~ g, family="zapoisson",rcov=~us(trait):units, data=dat, start= start_true)
>>>>>> 
>>>>>> # use true latent variable as starting values
>>>>>> set.seed(1)
>>>>>> # use some very bad starting values
>>>>>> start_rand = list(Liab=rnorm(200), R = rpois(1, 1)+1, G = rpois(1, 1)+1 )
>>>>>> m2<-MCMCglmm(y~1 + pred,random = ~ g,rcov=~us(trait):units,  family="zapoisson", data=dat, start = start_rand)
>>>>>> 
>>>>>> Best,
>>>>>> 
>>>>>> Ruben
>>>>>> 
>>>>>> On 25 Aug 2014, at 18:29, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>>>>> 
>>>>>>> Hi Ruben,
>>>>>>> 
>>>>>>> Sorry  - I was wrong when I said that everything is Gibbs sampled conditional on the latent variables. The location effects (fixed and random effects) are also sampled conditional on the (co)variance components so you should add them to the starting values. In the case where the true values are used:
>>>>>>> 
>>>>>>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat, start=list(Liab=l,R=1))
>>>>>>> 
>>>>>>> Cheers,
>>>>>>> 
>>>>>>> Jarrod
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> Quoting Jarrod Hadfield <j.hadfield at ed.ac.uk> on Mon, 25 Aug 2014 17:14:14 +0100:
>>>>>>> 
>>>>>>>> Hi Ruben,
>>>>>>>> 
>>>>>>>> You will need to provide over-dispersed starting values for multiple-chain convergence diagnostics to be useful (GLMM are so simple I am generally happy if the output of a single run looks reasonable).
>>>>>>>> 
>>>>>>>> With non-Gaussian data everything is Gibbs sampled conditional on the latent variables, so you only need to pass them:
>>>>>>>> 
>>>>>>>> l<-rnorm(200, -1, sqrt(1))
>>>>>>>> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
>>>>>>>> y<-rpois(200,exp(l)-t)+1
>>>>>>>> # generate zero-truncated data with an intercept of -1
>>>>>>>> 
>>>>>>>> dat<-data.frame(y=y)
>>>>>>>> set.seed(1)
>>>>>>>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat, start=list(Liab=l))
>>>>>>>> # use true latent variable as starting values
>>>>>>>> set.seed(1)
>>>>>>>> m2<-MCMCglmm(y~1, family="ztpoisson", data=dat, start=list(Liab=rnorm(200)))
>>>>>>>> # use some very bad starting values
>>>>>>>> 
>>>>>>>> plot(mcmc.list(m1$Sol, m2$Sol))
>>>>>>>> # not identical despite the same seed because of different starting values but clearly sampling the same posterior distribution:
>>>>>>>> 
>>>>>>>> gelman.diag(mcmc.list(m1$Sol, m2$Sol))
>>>>>>>> 
>>>>>>>> Cheers,
>>>>>>>> 
>>>>>>>> Jarrod
>>>>>>>> 
>>>>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25 Aug 2014 18:00:08 +0200:
>>>>>>>> 
>>>>>>>>> Dear Jarrod,
>>>>>>>>> 
>>>>>>>>> thanks for the quick reply. Please, don't waste time looking into doMPI ? I am happy that I
>>>>>>>>> get the expected result, when I specify that reproducible seed, whyever that may be.
>>>>>>>>> I'm pretty sure that is the deciding factor, because I tested it explicitly, I just have no idea
>>>>>>>>> how/why it interacts with the choice of family.
>>>>>>>>> 
>>>>>>>>> That said, is setting up different RNG streams for my workers (now that it works) __sufficient__
>>>>>>>>> so that I get independent chains and can use gelman.diag() for convergence diagnostics?
>>>>>>>>> Or should I still tinker with the starting values myself?
>>>>>>>>> I've never found a worked example of supplying starting values and am thus a bit lost.
>>>>>>>>> 
>>>>>>>>> Sorry for sending further questions, I hope someone else takes pity while
>>>>>>>>> you're busy with lectures.
>>>>>>>>> 
>>>>>>>>> Best wishes
>>>>>>>>> 
>>>>>>>>> Ruben
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> On 25 Aug 2014, at 17:29, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>>>>>>>> 
>>>>>>>>>> Hi Ruben,
>>>>>>>>>> 
>>>>>>>>>> I do not think the issue is with the starting values, because even if the same starting values were used the chains would still differ because of the randomness in the Markov Chain (if I interpret your `identical' test correctly). This just involves a call to GetRNGstate() in the C++ code (L 871 ofMCMCglmm.cc) so I think for some reason doMPI/foreach is not doing what you expect. I am not familiar with doMPI and am in the middle of writing lectures so haven't got time to look into it carefully. Outside of the context of doMPI I get the behaviour I expect:
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> l<-rnorm(200, -1, sqrt(1))
>>>>>>>>>> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
>>>>>>>>>> y<-rpois(200,exp(l)-t)+1
>>>>>>>>>> # generate zero-truncated data with an intercept of -1
>>>>>>>>>> 
>>>>>>>>>> dat<-data.frame(y=y)
>>>>>>>>>> set.seed(1)
>>>>>>>>>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>>>>>>>> set.seed(2)
>>>>>>>>>> m2<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>>>>>>>> set.seed(2)
>>>>>>>>>> m3<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>>>>>>>> 
>>>>>>>>>> plot(mcmc.list(m1$Sol, m2$Sol))
>>>>>>>>>> # different, as expected
>>>>>>>>>> plot(mcmc.list(m2$Sol, m3$Sol))
>>>>>>>>>> # the same, as expected
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25 Aug 2014 16:58:06 +0200:
>>>>>>>>>> 
>>>>>>>>>>> Dear list,
>>>>>>>>>>> 
>>>>>>>>>>> sorry for bumping my old post, I hope to elicit a response with a more focused question:
>>>>>>>>>>> 
>>>>>>>>>>> When does MCMCglmm automatically start from different values when using doMPI/foreach?
>>>>>>>>>>> 
>>>>>>>>>>> I have done some tests with models of varying complexity. For example, the script in my last
>>>>>>>>>>> post (using "zapoisson") yielded 40 identical chains:
>>>>>>>>>>>> identical(mcmclist[1], mcmclist[30])
>>>>>>>>>>> TRUE
>>>>>>>>>>> 
>>>>>>>>>>> A simpler (?) model (using "ztpoisson" and no specified prior), however, yielded different chains
>>>>>>>>>>> and I could use them to calculate gelman.diag()
>>>>>>>>>>> 
>>>>>>>>>>> Changing my script to the version below, i.e. seeding foreach using .options.mpi=list( seed= 1337)
>>>>>>>>>>> so as to make RNGstreams reproducible (or so I  thought), led to different chains even for the
>>>>>>>>>>> "zapoisson" model.
>>>>>>>>>>> 
>>>>>>>>>>> In no case have I (successfully) tried to supplant the default of MCMCglmm's "start" argument.
>>>>>>>>>>> Is starting my models from different RNGsubstreams inadequate compared to manipulating
>>>>>>>>>>> the start argument explicitly? If so, is there any worked example of explicit starting value manipulation
>>>>>>>>>>> in parallel computation?
>>>>>>>>>>> I've browsed the MCMCglmm source to understand how the default starting values are generated,
>>>>>>>>>>> but didn't find any differences with respect to RNG for the two families "ztpoisson" and "zapoisson"
>>>>>>>>>>> (granted, I did not dig very deep).
>>>>>>>>>>> 
>>>>>>>>>>> Best regards,
>>>>>>>>>>> 
>>>>>>>>>>> Ruben Arslan
>>>>>>>>>>> 
>>>>>>>>>>> 
>>>>>>>>>>> # bsub -q mpi -W 12:00 -n 41 -R np20 mpirun -H localhost -n 41 R --slave -f "/usr/users/rarslan/rpqa/rpqa_main/rpqa_children_parallel.R"
>>>>>>>>>>> 
>>>>>>>>>>> library(doMPI)
>>>>>>>>>>> cl <- startMPIcluster(verbose=T,workdir="/usr/users/rarslan/rpqa/rpqa_main/")
>>>>>>>>>>> registerDoMPI(cl)
>>>>>>>>>>> Children_mcmc1 = foreach(i=1:clusterSize(cl),.options.mpi = list(seed=1337) ) %dopar% {
>>>>>>>>>>> 	library(MCMCglmm);library(data.table)
>>>>>>>>>>> 	load("/usr/users/rarslan/rpqa/rpqa1.rdata")
>>>>>>>>>>> 
>>>>>>>>>>> 	nitt = 130000; thin = 100; burnin = 30000
>>>>>>>>>>> 	prior.m5d.2 = list(
>>>>>>>>>>> 		R = list(V = diag(c(1,1)), nu = 0.002),
>>>>>>>>>>> 		G=list(list(V=diag(c(1,1e-6)),nu=0.002))
>>>>>>>>>>> 	)
>>>>>>>>>>> 
>>>>>>>>>>> 	rpqa.1 = na.omit(rpqa.1[spouses>0, list(idParents, children, male, urban, spouses, paternalage.mean, paternalage.factor)])
>>>>>>>>>>> 	(m1 = MCMCglmm( children ~ trait * (male + urban + spouses + paternalage.mean + paternalage.factor),
>>>>>>>>>>> 						rcov=~us(trait):units,
>>>>>>>>>>> 						random=~us(trait):idParents,
>>>>>>>>>>> 						family="zapoisson",
>>>>>>>>>>> 						prior = prior.m5d.2,
>>>>>>>>>>> 						data=rpqa.1,
>>>>>>>>>>> 						pr = F, saveX = F, saveZ = F,
>>>>>>>>>>> 						nitt=nitt,thin=thin,burnin=burnin))
>>>>>>>>>>> }
>>>>>>>>>>> 
>>>>>>>>>>> library(coda)
>>>>>>>>>>> mcmclist = mcmc.list(lapply(Children_mcmc1,FUN=function(x) { x$Sol}))
>>>>>>>>>>> save(Children_mcmc1,mcmclist, file = "/usr/users/rarslan/rpqa/rpqa_main/rpqa_mcmc_kids_za.rdata")
>>>>>>>>>>> closeCluster(cl)
>>>>>>>>>>> mpi.quit()
>>>>>>>>>>> 
>>>>>>>>>>> 
>>>>>>>>>>> 
>>>>>>>>>>> On 04 Aug 2014, at 20:25, Ruben Arslan <rubenarslan at gmail.com> wrote:
>>>>>>>>>>> 
>>>>>>>>>>>> Dear list,
>>>>>>>>>>>> 
>>>>>>>>>>>> would someone be willing to share her or his efforts in parallelising a MCMCglmm analysis?
>>>>>>>>>>>> 
>>>>>>>>>>>> I had something viable using harvestr that seemed to properly initialise
>>>>>>>>>>>> the starting values from different random number streams (which is desirable,
>>>>>>>>>>>> as far as I could find out), but I ended up being unable to use harvestr, because
>>>>>>>>>>>> it uses an old version of plyr, where parallelisation works only for multicore, not for
>>>>>>>>>>>> MPI.
>>>>>>>>>>>> 
>>>>>>>>>>>> I pasted my working version, that does not do anything about starting values or RNG
>>>>>>>>>>>> at the end of this email. I can try to fumble further in the dark or try to update harvestr,
>>>>>>>>>>>> but maybe someone has gone through all this already.
>>>>>>>>>>>> 
>>>>>>>>>>>> I'd also appreciate any tips for elegantly post-processing such parallel data, as some of my usual
>>>>>>>>>>>> extraction functions and routines are hampered by the fact that some coda functions
>>>>>>>>>>>> do not aggregate results over chains. (What I get from a single-chain summary in MCMCglmm
>>>>>>>>>>>> is a bit more comprehensive, than what I managed to cobble together with my own extraction
>>>>>>>>>>>> functions).
>>>>>>>>>>>> 
>>>>>>>>>>>> The reason I'm parallelising my analyses is that I'm having trouble getting a good effective
>>>>>>>>>>>> sample size for any parameter having to do with the many zeroes in my data.
>>>>>>>>>>>> Any pointers are very appreciated, I'm quite inexperienced with MCMCglmm.
>>>>>>>>>>>> 
>>>>>>>>>>>> Best wishes
>>>>>>>>>>>> 
>>>>>>>>>>>> Ruben
>>>>>>>>>>>> 
>>>>>>>>>>>> # bsub -q mpi-short -W 2:00 -n 42 -R np20 mpirun -H localhost -n 41 R --slave -f "rpqa/rpqa_main/rpqa_children_parallel.r"
>>>>>>>>>>>> library(doMPI)
>>>>>>>>>>>> cl <- startMPIcluster()
>>>>>>>>>>>> registerDoMPI(cl)
>>>>>>>>>>>> Children_mcmc1 = foreach(i=1:40) %dopar% {
>>>>>>>>>>>> 	library(MCMCglmm)
>>>>>>>>>>>> 	load("rpqa1.rdata")
>>>>>>>>>>>> 
>>>>>>>>>>>> 	nitt = 40000; thin = 100; burnin = 10000
>>>>>>>>>>>> 	prior = list(
>>>>>>>>>>>> 		R = list(V = diag(c(1,1)), nu = 0.002),
>>>>>>>>>>>> 		G=list(list(V=diag(c(1,1e-6)),nu=0.002))
>>>>>>>>>>>> 	)
>>>>>>>>>>>> 
>>>>>>>>>>>> 	MCMCglmm( children ~ trait -1 + at.level(trait,1):male + at.level(trait,1):urban + at.level(trait,1):spouses + at.level(trait,1):paternalage.mean + at.level(trait,1):paternalage.factor,
>>>>>>>>>>>> 		rcov=~us(trait):units,
>>>>>>>>>>>> 		random=~us(trait):idParents,
>>>>>>>>>>>> 		family="zapoisson",
>>>>>>>>>>>> 		prior = prior,
>>>>>>>>>>>> 		data=rpqa.1,
>>>>>>>>>>>> 		pr = F, saveX = T, saveZ = T,
>>>>>>>>>>>> 		nitt=nitt,thin=thin,burnin=burnin)
>>>>>>>>>>>> }
>>>>>>>>>>>> 
>>>>>>>>>>>> library(coda)
>>>>>>>>>>>> mcmclist = mcmc.list(lapply(Children_mcmc1,FUN=function(x) { x$Sol}))
>>>>>>>>>>>> save(Children_mcmc1,mcmclist, file = "rpqa_mcmc_kids_za.rdata")
>>>>>>>>>>>> closeCluster(cl)
>>>>>>>>>>>> mpi.quit()
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> --
>>>>>>>>>>>> Ruben C. Arslan
>>>>>>>>>>>> 
>>>>>>>>>>>> Georg August University G?ttingen
>>>>>>>>>>>> Biological Personality Psychology and Psychological Assessment
>>>>>>>>>>>> Georg Elias M?ller Institute of Psychology
>>>>>>>>>>>> Go?lerstr. 14
>>>>>>>>>>>> 37073 G?ttingen
>>>>>>>>>>>> Germany
>>>>>>>>>>>> Tel.: +49 551 3920704
>>>>>>>>>>>> https://psych.uni-goettingen.de/en/biopers/team/arslan
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>> 
>>>>>>>>>>> 
>>>>>>>>>>> 	[[alternative HTML version deleted]]
>>>>>>>>>>> 
>>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> --
>>>>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>>>>> Scotland, with registration number SC005336.
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> --
>>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>>> Scotland, with registration number SC005336.
>>>>>>>> 
>>>>>>>> _______________________________________________
>>>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> --
>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>> Scotland, with registration number SC005336.
>>>>>>> 
>>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> --
>>>>> The University of Edinburgh is a charitable body, registered in
>>>>> Scotland, with registration number SC005336.
>>>>> 
>>>>> 
>>>> 
>>>> 
>>> 
>>> 
>>> 
>>> --
>>> The University of Edinburgh is a charitable body, registered in
>>> Scotland, with registration number SC005336.
>>> 
>>> 
>> 
>> 
>> 
> 
> 
> 
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
> 
> 


	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Thu Aug 28 20:59:57 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 28 Aug 2014 19:59:57 +0100
Subject: [R-sig-ME] parallel MCMCglmm, RNGstreams,
 starting values & priors
In-Reply-To: <BBB5F7E3-75FE-4BA3-82B4-49DAA64873A4@gmail.com>
References: <4CD76FE1-D3F5-4980-9122-B0AC0D44FF81@gmail.com>
	<0E12EB43-72BC-42AC-9E74-9DF53DB42217@gmail.com>
	<20140825162907.10475jpywlu1wzs4@www.staffmail.ed.ac.uk>
	<0A463095-8656-49B7-9619-E557DD449E21@gmail.com>
	<20140825171414.10872gnlopk1we68@www.staffmail.ed.ac.uk>
	<20140825172936.15916weehiwjyc08@www.staffmail.ed.ac.uk>
	<8D35B834-0D31-486A-B5FB-0F279761FDB2@gmail.com>
	<49D60399-6902-45AC-80A9-9F3C35532228@gmail.com>
	<20140826120434.14613hxqhgwbhq80@www.staffmail.ed.ac.uk>
	<8557AE32-AFC9-4FD2-9C88-2D118B484637@gmail.com>
	<20140827183959.18662zc6hw5jj20w@www.staffmail.ed.ac.uk>
	<2D00600E-5287-4FE1-B605-82C0CBA286ED@gmail.com>
	<20140828180551.74212a0xoeoihn6s@www.staffmail.ed.ac.uk>
	<BBB5F7E3-75FE-4BA3-82B4-49DAA64873A4@gmail.com>
Message-ID: <20140828195957.68171hjra56vrrr4@www.staffmail.ed.ac.uk>

Hi,

The posteriors for the two models look pretty close to me. Are the  
scale reduction factors really as high as previously reported? Before  
you had 1.83 for traitza_children:spouses, but the plot suggests that  
it should be close to 1?

Cheers,

Jarrod




Quoting Ruben Arslan <rubenarslan at gmail.com> on Thu, 28 Aug 2014  
19:59:16 +0200:

> Sure! Thanks a lot.
> I am using ~idh(trait):units already, sorry for saying that  
> incorrectly in my last email.
> These models aren't the final thing, I will replace the  
> paternalage.factor variable
> with its linear equivalent if that seems defensible (does so far)  
> and in this model it seems
> okay to remove the za-effects for all predictors except spouses.
> So a final model would have fewer fixed effects. I also have  
> datasets of 200k+ and 5m+,
> but I'm learning MCMCglmm with this smaller one because my wrong  
> turns take less time.
>
> I've uploaded a comparison coef plot of two models:
> http://i.imgur.com/sHUfnmd.png
> m7 is with the default starting values, m1 is with the specification  
> I sent in my last email. I don't
> know if such differences are something to worry about.
>
> I don't know what qualifies as highly overdispersed, here's a plot  
> of the outcome for ever
> married people (slate=real data):
> http://imgur.com/14MywgZ
> here's with everybody born (incl. some stillborn etc.):
> http://imgur.com/knRGa1v
> I guess my approach (generating an overdispersed poisson with the  
> parameters from
> the data and checking if it has as excess zeroes) is not the best  
> way to diagnose zero-inflation,
> but especially in the second case it seems fairly clear-cut.
>
> Best regards,
>
> Ruben
>
>> summary(m1)
>
>  Iterations = 50001:149951
>  Thinning interval  = 50
>  Sample size  = 2000
>
>  DIC: 31249.73
>
>  G-structure:  ~idh(trait):idParents
>
>                       post.mean  l-95% CI u-95% CI eff.samp
> children.idParents     0.006611 4.312e-08   0.0159    523.9
> za_children.idParents  0.193788 7.306e-02   0.3283    369.3
>
>  R-structure:  ~idh(trait):units
>
>                   post.mean l-95% CI u-95% CI eff.samp
> children.units       0.1285   0.1118   0.1452    716.1
> za_children.units    0.9950   0.9950   0.9950      0.0
>
>  Location effects: children ~ trait * (male + spouses +  
> paternalage.mean + paternalage.factor)
>
>                                             post.mean   l-95% CI    
> u-95% CI eff.samp  pMCMC
> (Intercept)                                 1.3413364  1.2402100   
> 1.4326099     1789 <5e-04 ***
> traitza_children                           -0.8362879 -1.2007980  
> -0.5016730     1669 <5e-04 ***
> male                                        0.0994902  0.0679050   
> 0.1297394     2000 <5e-04 ***
> spouses                                     0.1236033  0.0839000   
> 0.1624939     2000 <5e-04 ***
> paternalage.mean                            0.0533892  0.0119569   
> 0.0933960     2000  0.015 *
> paternalage.factor(25,30]                  -0.0275822 -0.1116421   
> 0.0537359     1842  0.515
> paternalage.factor(30,35]                  -0.0691025 -0.1463214   
> 0.0122393     1871  0.097 .
> paternalage.factor(35,40]                  -0.1419933 -0.2277379  
> -0.0574678     1845 <5e-04 ***
> paternalage.factor(40,45]                  -0.1364952 -0.2362714  
> -0.0451874     1835  0.007 **
> paternalage.factor(45,50]                  -0.1445342 -0.2591767  
> -0.0421178     1693  0.008 **
> paternalage.factor(50,55]                  -0.1302972 -0.2642965   
> 0.0077061     2000  0.064 .
> paternalage.factor(55,90]                  -0.3407879 -0.5168972  
> -0.1493652     1810 <5e-04 ***
> traitza_children:male                       0.0926888 -0.0147379   
> 0.2006142     1901  0.098 .
> traitza_children:spouses                    0.5531197  0.3870616   
> 0.7314289     1495 <5e-04 ***
> traitza_children:paternalage.mean           0.0051463 -0.1279396   
> 0.1460099     1617  0.960
> traitza_children:paternalage.factor(25,30] -0.1538957 -0.4445749   
> 0.1462955     1781  0.321
> traitza_children:paternalage.factor(30,35] -0.1747883 -0.4757851   
> 0.1162476     1998  0.261
> traitza_children:paternalage.factor(35,40] -0.2261843 -0.5464379   
> 0.0892582     1755  0.166
> traitza_children:paternalage.factor(40,45] -0.2807543 -0.6079678   
> 0.0650281     1721  0.100 .
> traitza_children:paternalage.factor(45,50] -0.4905843 -0.8649214  
> -0.1244174     1735  0.010 **
> traitza_children:paternalage.factor(50,55] -0.4648579 -0.9215759  
> -0.0002083     1687  0.054 .
> traitza_children:paternalage.factor(55,90] -0.3945406 -1.0230155   
> 0.2481568     1793  0.195
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
>> describe(krmh.1[spouses>0,])
>                     vars    n mean   sd median trimmed  mad   min    
> max range skew kurtosis   se
> children               2 6829 3.81 2.93   4.00    3.61 2.97  0.00  
> 16.00 16.00 0.47    -0.46 0.04
> male                   3 6829 0.46 0.50   0.00    0.45 0.00  0.00   
> 1.00  1.00 0.14    -1.98 0.01
> spouses                4 6829 1.14 0.38   1.00    1.03 0.00  1.00   
> 4.00  3.00 2.87     8.23 0.00
> paternalage            5 6829 3.65 0.80   3.57    3.60 0.80  1.83   
> 7.95  6.12 0.69     0.70 0.01
> paternalage_c          6 6829 0.00 0.80  -0.08   -0.05 0.80 -1.82   
> 4.30  6.12 0.69     0.70 0.01
> paternalage.mean       7 6829 0.00 0.68  -0.08   -0.05 0.59 -1.74   
> 4.30  6.04 0.95     1.97 0.01
> paternalage.diff       8 6829 0.00 0.42   0.00   -0.01 0.38 -1.51   
> 1.48  2.99 0.17     0.17 0.01
>
>> table(krmh.1$paternalage.factor)
>
>  [0,25] (25,30] (30,35] (35,40] (40,45] (45,50] (50,55] (55,90]
>     309    1214    1683    1562    1039     623     269     130
>
> On 28 Aug 2014, at 19:05, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>
>> Hi Ruben,
>>
>> It might be hard to detect (near) ECPs with so many fixed effects  
>> (can you post the model summary (and give us the mean and standard  
>> deviation of any continuous covariates)). Also, the complementary  
>> log-log link (which is the za specification) is non-symmetric and  
>> runs into problems outside the range -35 to 3.5 so there may be a  
>> problem there, particularly if you use rcov=~trait:units and the  
>> Poisson part is highly over-dispersed.  You could try  
>> rcov=~idh(trait):units and fix the non-identifiable za residual  
>> variance to something smaller than 1 (say 0.5)  - it will mix  
>> slower but it will reduce the chance of over/underflow.
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>>
>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Thu, 28 Aug 2014  
>> 18:45:30 +0200:
>>
>>> Hi Jarrod,
>>>
>>>> 1) it did not return an error with rcov = ~trait:units because  
>>>> you used R1=rpois(2,1)+1 and yet this specification only fits a  
>>>> single variance (not a 2x2 covariance matrix). R1=rpois(2,1)+1 is  
>>>> a bit of a weird specification since it has to be integer. I  
>>>> would obtain starting values using rIW().
>>>
>>> I agree it's a weird specification, I was a bit lost and thought I  
>>> could get away with just putting some random numbers in the  
>>> starting value.
>>> I didn't do R1=rpois(2,1)+1 though, I did R1=diag(rpois(2,1)+1),  
>>> so I got a 2x2 matrix, but yes, bound to be integer.
>>> I didn't know starting values should come from a conjugate  
>>> distribution, though that probably means I didn't think about it  
>>> much.
>>>
>>> I'm now doing
>>> start <- list(
>>> 	liab=c(rnorm( nrow(krmh.1)*2 )),
>>> 	R = list(R1 = rIW( diag(2), nrow(krmh.1)) ),
>>> 	G = list(G1 = rIW( diag(2), nrow(krmh.1)) )
>>> )
>>>
>>> Is this what you had in mind?
>>> I am especially unsure if I am supposed to use such a low sampling  
>>> variability (my sample size is probably not even relevant for the  
>>> starting values) and if I should start from diag(2).
>>>
>>> And, I am still happily confused that this specification still  
>>> doesn't lead to errors with respect to rcov = ~trait:units . Does  
>>> this mean I'm doing it wrong?
>>>
>>>> 3) a) how many effective samples do you have for each parameter?  
>>>> and b) are you getting extreme category problems/numerical  
>>>> issues? If you store the latent variables (pl=TUE) what is their  
>>>> range for the Zi/za part?
>>>
>>> My parallel run using the above starting values isn't finished yet.
>>> a) After applying the above starting values I get, for the  
>>> location effects 1600-2000 samples for a 2000 sample chain (with  
>>> thin set to 50). G and R-structure are from 369  
>>> (za_children.idParents) to 716 (and 0 for the fixed part).
>>> Effective sample sizes were similar for my run using the starting  
>>> values for G/R that I drew from rpois, and using 40 chains I of  
>>> course get
>>> b) I don't think I am getting extreme categories. I would probably  
>>> be getting extreme categories if I included the forever-alones  
>>> (they almost never have children), but this way no.
>>> I wasn't sure how to examine the range of the latents separately  
>>> for the za part, but for a single chain it looks okay:
>>>> quantile(as.numeric(m1$Liab),probs = c(0,0.01,0,0.99,1))
>>>       0%        1%        0%       99%      100%
>>> -4.934111 -1.290728 -4.934111  3.389847  7.484206
>>>
>>> Well, all considered now that I use the above starting value  
>>> specification I get slightly different estimates for all  
>>> za-coefficients. Nothing major, but still leading me to
>>> think my estimates aren't exactly independent of the starting  
>>> values I use. I'll see what the parallel run yields.
>>>
>>> Thanks a lot,
>>>
>>> Ruben
>>>
>>>>
>>>> Cheers,
>>>>
>>>> Jarrod
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Wed, 27 Aug 2014  
>>>> 19:23:42 +0200:
>>>>
>>>>> Hi Jarrod,
>>>>>
>>>>> thanks again. I was able to get it running with your advice.
>>>>> Some points of confusion remain:
>>>>>
>>>>> - You wrote that zi/za models would return an error with rcov =  
>>>>> ~trait:units + starting values. This did not happen in my case,  
>>>>> so I didn't build MCMCglmm myself with your suggested edits.  
>>>>> Also, have you considered putting your own MCMCglmm repo on  
>>>>> Github? Your users would be able to install pre-releases and I'd  
>>>>> think you'd get some time-saving pull requests too.
>>>>> - In my attempts to get my models to run properly, I messed up a  
>>>>> prior and did not use fix=2 in my prior specification for my za  
>>>>> models. This led to crappy convergence, it's much better now and  
>>>>> for some of my simpler models I think I won't need parallel  
>>>>> chains. I'm reminded of Gelman's folk theorem of statistical  
>>>>> computing.
>>>>> - I followed your advice, but of course I could not set the true  
>>>>> values as starting values, but wanted to set random, bad  
>>>>> starting values. I pasted below what I arrived at, I'm  
>>>>> especially unsure whether I specified the starting values for G  
>>>>> and R properly (I think not).
>>>>> 	start <- list(
>>>>> 		liab=c(rnorm( nrow(krmh.1)*2 )),
>>>>> 		R = list(R1 = diag(rpois(2, 1)+1)),
>>>>> 		G = list(G1 = diag(rpois(2, 1)+1))
>>>>> 	)
>>>>>
>>>>>
>>>>> However, even though I may not need multiple chains for some of  
>>>>> my simpler models, I've now run into conflicting diagnostics.  
>>>>> The geweke.diag for each chain (and examination of the traces)  
>>>>> gives
>>>>> satisfactory diagnostics. Comparing multiple chains using  
>>>>> gelman.diag, however, leads to one bad guy, namely the  
>>>>> traitza_children:spouses interaction.
>>>>> I think this implies that I've got some starting value  
>>>>> dependence for this parameter, that won't be easily rectified  
>>>>> through longer burnin?
>>>>> Do you have any ideas how to rectify this?
>>>>> I am currently doing sequential analyses on episodes of  
>>>>> selection and in historical human data only those who marry have  
>>>>> a chance at having kids. I exclude the unmarried
>>>>> from my sample where I predict number of children, because I  
>>>>> examine that in a previous model and the zero-inflation (65%  
>>>>> zeros, median w/o unmarried = 4) when including the unmarried is  
>>>>> so excessive.
>>>>> Number of spouses is easily the strongest predictor in the  
>>>>> model, but only serves as a covariate here. Since my other  
>>>>> estimates are stable across chains and runs and agree well  
>>>>> across models and with theory, I'm
>>>>> inclined to shrug this off. But probably I shouldn't ignore this  
>>>>> sign of non-convergence?
>>>>>
>>>>>> gelman.diag(mcmc_1)
>>>>> Potential scale reduction factors:
>>>>>
>>>>>                                          Point est. Upper C.I.
>>>>> (Intercept)                                      1.00       1.00
>>>>> traitza_children                                 1.27       1.39
>>>>> male                                             1.00       1.00
>>>>> spouses                                          1.00       1.00
>>>>> paternalage.mean                                 1.00       1.00
>>>>> paternalage.factor(25,30]                        1.00       1.00
>>>>> paternalage.factor(30,35]                        1.00       1.00
>>>>> paternalage.factor(35,40]                        1.00       1.00
>>>>> paternalage.factor(40,45]                        1.00       1.00
>>>>> paternalage.factor(45,50]                        1.00       1.00
>>>>> paternalage.factor(50,55]                        1.00       1.00
>>>>> paternalage.factor(55,90]                        1.00       1.00
>>>>> traitza_children:male                            1.22       1.32
>>>>> traitza_children:spouses                         1.83       2.13
>>>>> traitza_children:paternalage.mean                1.02       1.02
>>>>> traitza_children:paternalage.factor(25,30]       1.03       1.05
>>>>> traitza_children:paternalage.factor(30,35]       1.05       1.08
>>>>> traitza_children:paternalage.factor(35,40]       1.10       1.15
>>>>> traitza_children:paternalage.factor(40,45]       1.12       1.17
>>>>> traitza_children:paternalage.factor(45,50]       1.19       1.28
>>>>> traitza_children:paternalage.factor(50,55]       1.12       1.18
>>>>> traitza_children:paternalage.factor(55,90]       1.11       1.17
>>>>>
>>>>> Multivariate psrf
>>>>>
>>>>> 7.27
>>>>>
>>>>>
>>>>> Best regards,
>>>>>
>>>>> Ruben
>>>>>
>>>>>
>>>>> On 26 Aug 2014, at 13:04, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>>>>
>>>>>> Hi Ruben,
>>>>>>
>>>>>> There are 400 liabilities in a zapoisson model (2 per datum).  
>>>>>> This code should work:
>>>>>>
>>>>>> g <-sample(letters[1:10], size = 200, replace = T)
>>>>>> pred <- rnorm(200)
>>>>>>
>>>>>> l1<-rnorm(200, -1, sqrt(1))
>>>>>> l2<-rnorm(200, -1, sqrt(1))
>>>>>>
>>>>>> y<-VGAM::rzapois(200, exp(l1), exp(-exp(l2)))
>>>>>>
>>>>>> # generate zero-altered data with an intercept of -1 (because  
>>>>>> the intercept and variance are the same for both processes this  
>>>>>> is just standard Poisson)
>>>>>>
>>>>>> dat<-data.frame(y=y, g = g, pred = pred)
>>>>>>
>>>>>>
>>>>>> start.1<-list(liab=c(l1,l2), R = list(R1=diag(2)), G=list(G1=diag(2)))
>>>>>> prior.1<-list(R=list(V=diag(2), nu=1.002, fix=2),  
>>>>>> G=list(G1=list(V=diag(2), nu=2, alpha.mu=c(0,0),  
>>>>>> alpha.V=diag(2)*1000)))
>>>>>>
>>>>>> m1<-MCMCglmm(y~trait + pred:trait, random=~us(trait):g,  
>>>>>> family="zapoisson",rcov=~idh(trait):units, data=dat,  
>>>>>> prior=prior.1, start= start.1)
>>>>>>
>>>>>> However, there are 2 bugs in the current version of MCMCglmm  
>>>>>> that return an error message when the documentation implies it  
>>>>>> should be fine:
>>>>>>
>>>>>> a) it should be possible to have R=diag(2) rather than R =  
>>>>>> list(R1=diag(2)). This bug cropped up when I implemented  
>>>>>> block-diagonal R structures. It can be fixed by inserting:
>>>>>>
>>>>>>        if(!is.list(start$R)){
>>>>>>           start$R<-list(R1=start$R)
>>>>>>        }
>>>>>>
>>>>>> on L514 of MCMCglmm.R below
>>>>>>
>>>>>>        if(!is.list(prior$R[[1]])){
>>>>>>           prior$R<-list(R1=prior$R)
>>>>>>        }
>>>>>>
>>>>>> b) rcov=~trait:units models for zi/za models will return an  
>>>>>> error when passing starting values. To fix this insert
>>>>>>
>>>>>>       if(diagR==3){
>>>>>>         if(dim(start)[1]!=1){
>>>>>>           stop("V is the wrong dimension for some  
>>>>>> strart$G/start$R elements")
>>>>>>         }
>>>>>>         start<-diag(sum(nfl))*start[1]
>>>>>>       }
>>>>>>
>>>>>> on L90 of priorfromat.R below
>>>>>>
>>>>>>       if(is.matrix(start)==FALSE){
>>>>>>         start<-as.matrix(start)
>>>>>>       }
>>>>>>
>>>>>> I will put these in the new version.
>>>>>>
>>>>>> Cheers,
>>>>>>
>>>>>> Jarrod
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25 Aug  
>>>>>> 2014 21:52:30 +0200:
>>>>>>
>>>>>>> Hi Jarrod,
>>>>>>>
>>>>>>> thanks for these pointers.
>>>>>>>
>>>>>>>>> You will need to provide over-dispersed starting values for  
>>>>>>>>> multiple-chain convergence diagnostics to be useful (GLMM  
>>>>>>>>> are so simple I am generally happy if the output of a single  
>>>>>>>>> run looks reasonable).
>>>>>>>
>>>>>>> Oh, I would be happy with single chains, but since computation  
>>>>>>> would take weeks this way, I wanted to parallelise and I would  
>>>>>>> use the multi-chain convergence as a criterion that my  
>>>>>>> parallelisation was proper
>>>>>>> and is as informative as a single long chain. There don't seem  
>>>>>>> to be any such checks built-in ? I was analysing my 40 chains  
>>>>>>> for a bit longer than I like to admit until I noticed they  
>>>>>>> were identical (effectiveSize
>>>>>>> and summary.mcmc.list did not yell at me for this).
>>>>>>>
>>>>>>>>> # use some very bad starting values
>>>>>>> I get that these values are bad, but that is the goal for my  
>>>>>>> multi-chain aim, right?
>>>>>>>
>>>>>>> I can apply this to my zero-truncated model, but am again  
>>>>>>> getting stuck with the zero-altered one.
>>>>>>> Maybe I need only specify the Liab values for this?
>>>>>>> At least I'm getting nowhere with specifying R and G starting  
>>>>>>> values here. When I got an error, I always
>>>>>>> went to the MCMCglmm source to understand why the checks  
>>>>>>> failed, but I didn't always understand
>>>>>>> what was being checked and couldn't get it to work.
>>>>>>>
>>>>>>> Here's a failing example:
>>>>>>>
>>>>>>> l<-rnorm(200, -1, sqrt(1))
>>>>>>> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
>>>>>>> g = sample(letters[1:10], size = 200, replace = T)
>>>>>>> pred = rnorm(200)
>>>>>>> y<-rpois(200,exp(l)-t)
>>>>>>> y[1:40] = 0
>>>>>>> # generate zero-altered data with an intercept of -1
>>>>>>>
>>>>>>> dat<-data.frame(y=y, g = g, pred = pred)
>>>>>>> set.seed(1)
>>>>>>> start_true = list(Liab=l, R = 1, G = 1 )
>>>>>>> m1<-MCMCglmm(y~1 + pred,random = ~ g,  
>>>>>>> family="zapoisson",rcov=~us(trait):units, data=dat, start=  
>>>>>>> start_true)
>>>>>>>
>>>>>>> # use true latent variable as starting values
>>>>>>> set.seed(1)
>>>>>>> # use some very bad starting values
>>>>>>> start_rand = list(Liab=rnorm(200), R = rpois(1, 1)+1, G =  
>>>>>>> rpois(1, 1)+1 )
>>>>>>> m2<-MCMCglmm(y~1 + pred,random = ~ g,rcov=~us(trait):units,   
>>>>>>> family="zapoisson", data=dat, start = start_rand)
>>>>>>>
>>>>>>> Best,
>>>>>>>
>>>>>>> Ruben
>>>>>>>
>>>>>>> On 25 Aug 2014, at 18:29, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>>>>>>
>>>>>>>> Hi Ruben,
>>>>>>>>
>>>>>>>> Sorry  - I was wrong when I said that everything is Gibbs  
>>>>>>>> sampled conditional on the latent variables. The location  
>>>>>>>> effects (fixed and random effects) are also sampled  
>>>>>>>> conditional on the (co)variance components so you should add  
>>>>>>>> them to the starting values. In the case where the true  
>>>>>>>> values are used:
>>>>>>>>
>>>>>>>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat,  
>>>>>>>> start=list(Liab=l,R=1))
>>>>>>>>
>>>>>>>> Cheers,
>>>>>>>>
>>>>>>>> Jarrod
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> Quoting Jarrod Hadfield <j.hadfield at ed.ac.uk> on Mon, 25 Aug  
>>>>>>>> 2014 17:14:14 +0100:
>>>>>>>>
>>>>>>>>> Hi Ruben,
>>>>>>>>>
>>>>>>>>> You will need to provide over-dispersed starting values for  
>>>>>>>>> multiple-chain convergence diagnostics to be useful (GLMM  
>>>>>>>>> are so simple I am generally happy if the output of a single  
>>>>>>>>> run looks reasonable).
>>>>>>>>>
>>>>>>>>> With non-Gaussian data everything is Gibbs sampled  
>>>>>>>>> conditional on the latent variables, so you only need to  
>>>>>>>>> pass them:
>>>>>>>>>
>>>>>>>>> l<-rnorm(200, -1, sqrt(1))
>>>>>>>>> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
>>>>>>>>> y<-rpois(200,exp(l)-t)+1
>>>>>>>>> # generate zero-truncated data with an intercept of -1
>>>>>>>>>
>>>>>>>>> dat<-data.frame(y=y)
>>>>>>>>> set.seed(1)
>>>>>>>>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat, start=list(Liab=l))
>>>>>>>>> # use true latent variable as starting values
>>>>>>>>> set.seed(1)
>>>>>>>>> m2<-MCMCglmm(y~1, family="ztpoisson", data=dat,  
>>>>>>>>> start=list(Liab=rnorm(200)))
>>>>>>>>> # use some very bad starting values
>>>>>>>>>
>>>>>>>>> plot(mcmc.list(m1$Sol, m2$Sol))
>>>>>>>>> # not identical despite the same seed because of different  
>>>>>>>>> starting values but clearly sampling the same posterior  
>>>>>>>>> distribution:
>>>>>>>>>
>>>>>>>>> gelman.diag(mcmc.list(m1$Sol, m2$Sol))
>>>>>>>>>
>>>>>>>>> Cheers,
>>>>>>>>>
>>>>>>>>> Jarrod
>>>>>>>>>
>>>>>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25 Aug  
>>>>>>>>> 2014 18:00:08 +0200:
>>>>>>>>>
>>>>>>>>>> Dear Jarrod,
>>>>>>>>>>
>>>>>>>>>> thanks for the quick reply. Please, don't waste time  
>>>>>>>>>> looking into doMPI ? I am happy that I
>>>>>>>>>> get the expected result, when I specify that reproducible  
>>>>>>>>>> seed, whyever that may be.
>>>>>>>>>> I'm pretty sure that is the deciding factor, because I  
>>>>>>>>>> tested it explicitly, I just have no idea
>>>>>>>>>> how/why it interacts with the choice of family.
>>>>>>>>>>
>>>>>>>>>> That said, is setting up different RNG streams for my  
>>>>>>>>>> workers (now that it works) __sufficient__
>>>>>>>>>> so that I get independent chains and can use gelman.diag()  
>>>>>>>>>> for convergence diagnostics?
>>>>>>>>>> Or should I still tinker with the starting values myself?
>>>>>>>>>> I've never found a worked example of supplying starting  
>>>>>>>>>> values and am thus a bit lost.
>>>>>>>>>>
>>>>>>>>>> Sorry for sending further questions, I hope someone else  
>>>>>>>>>> takes pity while
>>>>>>>>>> you're busy with lectures.
>>>>>>>>>>
>>>>>>>>>> Best wishes
>>>>>>>>>>
>>>>>>>>>> Ruben
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> On 25 Aug 2014, at 17:29, Jarrod Hadfield  
>>>>>>>>>> <j.hadfield at ed.ac.uk> wrote:
>>>>>>>>>>
>>>>>>>>>>> Hi Ruben,
>>>>>>>>>>>
>>>>>>>>>>> I do not think the issue is with the starting values,  
>>>>>>>>>>> because even if the same starting values were used the  
>>>>>>>>>>> chains would still differ because of the randomness in the  
>>>>>>>>>>> Markov Chain (if I interpret your `identical' test  
>>>>>>>>>>> correctly). This just involves a call to GetRNGstate() in  
>>>>>>>>>>> the C++ code (L 871 ofMCMCglmm.cc) so I think for some  
>>>>>>>>>>> reason doMPI/foreach is not doing what you expect. I am  
>>>>>>>>>>> not familiar with doMPI and am in the middle of writing  
>>>>>>>>>>> lectures so haven't got time to look into it carefully.  
>>>>>>>>>>> Outside of the context of doMPI I get the behaviour I  
>>>>>>>>>>> expect:
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>> l<-rnorm(200, -1, sqrt(1))
>>>>>>>>>>> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
>>>>>>>>>>> y<-rpois(200,exp(l)-t)+1
>>>>>>>>>>> # generate zero-truncated data with an intercept of -1
>>>>>>>>>>>
>>>>>>>>>>> dat<-data.frame(y=y)
>>>>>>>>>>> set.seed(1)
>>>>>>>>>>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>>>>>>>>> set.seed(2)
>>>>>>>>>>> m2<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>>>>>>>>> set.seed(2)
>>>>>>>>>>> m3<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>>>>>>>>>
>>>>>>>>>>> plot(mcmc.list(m1$Sol, m2$Sol))
>>>>>>>>>>> # different, as expected
>>>>>>>>>>> plot(mcmc.list(m2$Sol, m3$Sol))
>>>>>>>>>>> # the same, as expected
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25  
>>>>>>>>>>> Aug 2014 16:58:06 +0200:
>>>>>>>>>>>
>>>>>>>>>>>> Dear list,
>>>>>>>>>>>>
>>>>>>>>>>>> sorry for bumping my old post, I hope to elicit a  
>>>>>>>>>>>> response with a more focused question:
>>>>>>>>>>>>
>>>>>>>>>>>> When does MCMCglmm automatically start from different  
>>>>>>>>>>>> values when using doMPI/foreach?
>>>>>>>>>>>>
>>>>>>>>>>>> I have done some tests with models of varying complexity.  
>>>>>>>>>>>> For example, the script in my last
>>>>>>>>>>>> post (using "zapoisson") yielded 40 identical chains:
>>>>>>>>>>>>> identical(mcmclist[1], mcmclist[30])
>>>>>>>>>>>> TRUE
>>>>>>>>>>>>
>>>>>>>>>>>> A simpler (?) model (using "ztpoisson" and no specified  
>>>>>>>>>>>> prior), however, yielded different chains
>>>>>>>>>>>> and I could use them to calculate gelman.diag()
>>>>>>>>>>>>
>>>>>>>>>>>> Changing my script to the version below, i.e. seeding  
>>>>>>>>>>>> foreach using .options.mpi=list( seed= 1337)
>>>>>>>>>>>> so as to make RNGstreams reproducible (or so I  thought),  
>>>>>>>>>>>> led to different chains even for the
>>>>>>>>>>>> "zapoisson" model.
>>>>>>>>>>>>
>>>>>>>>>>>> In no case have I (successfully) tried to supplant the  
>>>>>>>>>>>> default of MCMCglmm's "start" argument.
>>>>>>>>>>>> Is starting my models from different RNGsubstreams  
>>>>>>>>>>>> inadequate compared to manipulating
>>>>>>>>>>>> the start argument explicitly? If so, is there any worked  
>>>>>>>>>>>> example of explicit starting value manipulation
>>>>>>>>>>>> in parallel computation?
>>>>>>>>>>>> I've browsed the MCMCglmm source to understand how the  
>>>>>>>>>>>> default starting values are generated,
>>>>>>>>>>>> but didn't find any differences with respect to RNG for  
>>>>>>>>>>>> the two families "ztpoisson" and "zapoisson"
>>>>>>>>>>>> (granted, I did not dig very deep).
>>>>>>>>>>>>
>>>>>>>>>>>> Best regards,
>>>>>>>>>>>>
>>>>>>>>>>>> Ruben Arslan
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>> # bsub -q mpi -W 12:00 -n 41 -R np20 mpirun -H localhost  
>>>>>>>>>>>> -n 41 R --slave -f  
>>>>>>>>>>>> "/usr/users/rarslan/rpqa/rpqa_main/rpqa_children_parallel.R"
>>>>>>>>>>>>
>>>>>>>>>>>> library(doMPI)
>>>>>>>>>>>> cl <-  
>>>>>>>>>>>> startMPIcluster(verbose=T,workdir="/usr/users/rarslan/rpqa/rpqa_main/")
>>>>>>>>>>>> registerDoMPI(cl)
>>>>>>>>>>>> Children_mcmc1 = foreach(i=1:clusterSize(cl),.options.mpi  
>>>>>>>>>>>> = list(seed=1337) ) %dopar% {
>>>>>>>>>>>> 	library(MCMCglmm);library(data.table)
>>>>>>>>>>>> 	load("/usr/users/rarslan/rpqa/rpqa1.rdata")
>>>>>>>>>>>>
>>>>>>>>>>>> 	nitt = 130000; thin = 100; burnin = 30000
>>>>>>>>>>>> 	prior.m5d.2 = list(
>>>>>>>>>>>> 		R = list(V = diag(c(1,1)), nu = 0.002),
>>>>>>>>>>>> 		G=list(list(V=diag(c(1,1e-6)),nu=0.002))
>>>>>>>>>>>> 	)
>>>>>>>>>>>>
>>>>>>>>>>>> 	rpqa.1 = na.omit(rpqa.1[spouses>0, list(idParents,  
>>>>>>>>>>>> children, male, urban, spouses, paternalage.mean,  
>>>>>>>>>>>> paternalage.factor)])
>>>>>>>>>>>> 	(m1 = MCMCglmm( children ~ trait * (male + urban +  
>>>>>>>>>>>> spouses + paternalage.mean + paternalage.factor),
>>>>>>>>>>>> 						rcov=~us(trait):units,
>>>>>>>>>>>> 						random=~us(trait):idParents,
>>>>>>>>>>>> 						family="zapoisson",
>>>>>>>>>>>> 						prior = prior.m5d.2,
>>>>>>>>>>>> 						data=rpqa.1,
>>>>>>>>>>>> 						pr = F, saveX = F, saveZ = F,
>>>>>>>>>>>> 						nitt=nitt,thin=thin,burnin=burnin))
>>>>>>>>>>>> }
>>>>>>>>>>>>
>>>>>>>>>>>> library(coda)
>>>>>>>>>>>> mcmclist =  
>>>>>>>>>>>> mcmc.list(lapply(Children_mcmc1,FUN=function(x) { x$Sol}))
>>>>>>>>>>>> save(Children_mcmc1,mcmclist, file =  
>>>>>>>>>>>> "/usr/users/rarslan/rpqa/rpqa_main/rpqa_mcmc_kids_za.rdata")
>>>>>>>>>>>> closeCluster(cl)
>>>>>>>>>>>> mpi.quit()
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>> On 04 Aug 2014, at 20:25, Ruben Arslan  
>>>>>>>>>>>> <rubenarslan at gmail.com> wrote:
>>>>>>>>>>>>
>>>>>>>>>>>>> Dear list,
>>>>>>>>>>>>>
>>>>>>>>>>>>> would someone be willing to share her or his efforts in  
>>>>>>>>>>>>> parallelising a MCMCglmm analysis?
>>>>>>>>>>>>>
>>>>>>>>>>>>> I had something viable using harvestr that seemed to  
>>>>>>>>>>>>> properly initialise
>>>>>>>>>>>>> the starting values from different random number streams  
>>>>>>>>>>>>> (which is desirable,
>>>>>>>>>>>>> as far as I could find out), but I ended up being unable  
>>>>>>>>>>>>> to use harvestr, because
>>>>>>>>>>>>> it uses an old version of plyr, where parallelisation  
>>>>>>>>>>>>> works only for multicore, not for
>>>>>>>>>>>>> MPI.
>>>>>>>>>>>>>
>>>>>>>>>>>>> I pasted my working version, that does not do anything  
>>>>>>>>>>>>> about starting values or RNG
>>>>>>>>>>>>> at the end of this email. I can try to fumble further in  
>>>>>>>>>>>>> the dark or try to update harvestr,
>>>>>>>>>>>>> but maybe someone has gone through all this already.
>>>>>>>>>>>>>
>>>>>>>>>>>>> I'd also appreciate any tips for elegantly  
>>>>>>>>>>>>> post-processing such parallel data, as some of my usual
>>>>>>>>>>>>> extraction functions and routines are hampered by the  
>>>>>>>>>>>>> fact that some coda functions
>>>>>>>>>>>>> do not aggregate results over chains. (What I get from a  
>>>>>>>>>>>>> single-chain summary in MCMCglmm
>>>>>>>>>>>>> is a bit more comprehensive, than what I managed to  
>>>>>>>>>>>>> cobble together with my own extraction
>>>>>>>>>>>>> functions).
>>>>>>>>>>>>>
>>>>>>>>>>>>> The reason I'm parallelising my analyses is that I'm  
>>>>>>>>>>>>> having trouble getting a good effective
>>>>>>>>>>>>> sample size for any parameter having to do with the many  
>>>>>>>>>>>>> zeroes in my data.
>>>>>>>>>>>>> Any pointers are very appreciated, I'm quite  
>>>>>>>>>>>>> inexperienced with MCMCglmm.
>>>>>>>>>>>>>
>>>>>>>>>>>>> Best wishes
>>>>>>>>>>>>>
>>>>>>>>>>>>> Ruben
>>>>>>>>>>>>>
>>>>>>>>>>>>> # bsub -q mpi-short -W 2:00 -n 42 -R np20 mpirun -H  
>>>>>>>>>>>>> localhost -n 41 R --slave -f  
>>>>>>>>>>>>> "rpqa/rpqa_main/rpqa_children_parallel.r"
>>>>>>>>>>>>> library(doMPI)
>>>>>>>>>>>>> cl <- startMPIcluster()
>>>>>>>>>>>>> registerDoMPI(cl)
>>>>>>>>>>>>> Children_mcmc1 = foreach(i=1:40) %dopar% {
>>>>>>>>>>>>> 	library(MCMCglmm)
>>>>>>>>>>>>> 	load("rpqa1.rdata")
>>>>>>>>>>>>>
>>>>>>>>>>>>> 	nitt = 40000; thin = 100; burnin = 10000
>>>>>>>>>>>>> 	prior = list(
>>>>>>>>>>>>> 		R = list(V = diag(c(1,1)), nu = 0.002),
>>>>>>>>>>>>> 		G=list(list(V=diag(c(1,1e-6)),nu=0.002))
>>>>>>>>>>>>> 	)
>>>>>>>>>>>>>
>>>>>>>>>>>>> 	MCMCglmm( children ~ trait -1 + at.level(trait,1):male  
>>>>>>>>>>>>> + at.level(trait,1):urban + at.level(trait,1):spouses +  
>>>>>>>>>>>>> at.level(trait,1):paternalage.mean +  
>>>>>>>>>>>>> at.level(trait,1):paternalage.factor,
>>>>>>>>>>>>> 		rcov=~us(trait):units,
>>>>>>>>>>>>> 		random=~us(trait):idParents,
>>>>>>>>>>>>> 		family="zapoisson",
>>>>>>>>>>>>> 		prior = prior,
>>>>>>>>>>>>> 		data=rpqa.1,
>>>>>>>>>>>>> 		pr = F, saveX = T, saveZ = T,
>>>>>>>>>>>>> 		nitt=nitt,thin=thin,burnin=burnin)
>>>>>>>>>>>>> }
>>>>>>>>>>>>>
>>>>>>>>>>>>> library(coda)
>>>>>>>>>>>>> mcmclist =  
>>>>>>>>>>>>> mcmc.list(lapply(Children_mcmc1,FUN=function(x) { x$Sol}))
>>>>>>>>>>>>> save(Children_mcmc1,mcmclist, file = "rpqa_mcmc_kids_za.rdata")
>>>>>>>>>>>>> closeCluster(cl)
>>>>>>>>>>>>> mpi.quit()
>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>> --
>>>>>>>>>>>>> Ruben C. Arslan
>>>>>>>>>>>>>
>>>>>>>>>>>>> Georg August University G?ttingen
>>>>>>>>>>>>> Biological Personality Psychology and Psychological Assessment
>>>>>>>>>>>>> Georg Elias M?ller Institute of Psychology
>>>>>>>>>>>>> Go?lerstr. 14
>>>>>>>>>>>>> 37073 G?ttingen
>>>>>>>>>>>>> Germany
>>>>>>>>>>>>> Tel.: +49 551 3920704
>>>>>>>>>>>>> https://psych.uni-goettingen.de/en/biopers/team/arslan
>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>> 	[[alternative HTML version deleted]]
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>> --
>>>>>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>>>>>> Scotland, with registration number SC005336.
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> --
>>>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>>>> Scotland, with registration number SC005336.
>>>>>>>>>
>>>>>>>>> _______________________________________________
>>>>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> --
>>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>>> Scotland, with registration number SC005336.
>>>>>>>>
>>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> --
>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>> Scotland, with registration number SC005336.
>>>>>>
>>>>>>
>>>>>
>>>>>
>>>>
>>>>
>>>>
>>>> --
>>>> The University of Edinburgh is a charitable body, registered in
>>>> Scotland, with registration number SC005336.
>>>>
>>>>
>>>
>>>
>>>
>>
>>
>>
>> --
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>>
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From rubenarslan at gmail.com  Thu Aug 28 22:44:47 2014
From: rubenarslan at gmail.com (Ruben Arslan)
Date: Thu, 28 Aug 2014 22:44:47 +0200
Subject: [R-sig-ME] parallel MCMCglmm, RNGstreams,
	starting values & priors
In-Reply-To: <20140828195957.68171hjra56vrrr4@www.staffmail.ed.ac.uk>
References: <4CD76FE1-D3F5-4980-9122-B0AC0D44FF81@gmail.com>
	<0E12EB43-72BC-42AC-9E74-9DF53DB42217@gmail.com>
	<20140825162907.10475jpywlu1wzs4@www.staffmail.ed.ac.uk>
	<0A463095-8656-49B7-9619-E557DD449E21@gmail.com>
	<20140825171414.10872gnlopk1we68@www.staffmail.ed.ac.uk>
	<20140825172936.15916weehiwjyc08@www.staffmail.ed.ac.uk>
	<8D35B834-0D31-486A-B5FB-0F279761FDB2@gmail.com>
	<49D60399-6902-45AC-80A9-9F3C35532228@gmail.com>
	<20140826120434.14613hxqhgwbhq80@www.staffmail.ed.ac.uk>
	<8557AE32-AFC9-4FD2-9C88-2D118B484637@gmail.com>
	<20140827183959.18662zc6hw5jj20w@www.staffmail.ed.ac.uk>
	<2D00600E-5287-4FE1-B605-82C0CBA286ED@gmail.com>
	<20140828180551.74212a0xoeoihn6s@www.staffmail.ed.ac.uk>
	<BBB5F7E3-75FE-4BA3-82B4-49DAA64873A4@gmail.com>
	<20140828195957.68171hjra56vrrr4@www.staffmail.ed.ac.uk>
Message-ID: <E5B149F2-7773-4E2D-854C-3275A352A245@gmail.com>

Hi Jarrod,

those two matched up quite well yes. I just completed another 20 chains, using more variable
starting values. There's still two fixed effects traitza_children:spouses  and :male which haven't converged
according to multi-chain (gelman), but have according to geweke.
The offending traces: http://imgur.com/Qm6Ovfr
These specific effects aren't of interest to me, so if this doesn't affect the rest of my estimates, I can be happy
with this, but I can't conclude that, can I?

I'm now also doing a run to see how it deals with the more intensely zero-inflated data when including
the unmarried.

Thanks a lot for all that help,

Ruben

> gelman.diag(mcmclist)
Potential scale reduction factors:

                                           Point est. Upper C.I.
(Intercept)                                      1.00       1.00
traitza_children                                 1.40       1.65
male                                             1.00       1.00
spouses                                          1.00       1.00
paternalage.mean                                 1.00       1.00
paternalage.factor(25,30]                        1.00       1.00
paternalage.factor(30,35]                        1.00       1.00
paternalage.factor(35,40]                        1.00       1.00
paternalage.factor(40,45]                        1.00       1.00
paternalage.factor(45,50]                        1.00       1.00
paternalage.factor(50,55]                        1.00       1.00
paternalage.factor(55,90]                        1.00       1.00
traitza_children:male                            1.33       1.54
traitza_children:spouses                         2.21       2.83
traitza_children:paternalage.mean                1.01       1.02
traitza_children:paternalage.factor(25,30]       1.05       1.08
traitza_children:paternalage.factor(30,35]       1.08       1.13
traitza_children:paternalage.factor(35,40]       1.15       1.25
traitza_children:paternalage.factor(40,45]       1.15       1.26
traitza_children:paternalage.factor(45,50]       1.26       1.43
traitza_children:paternalage.factor(50,55]       1.15       1.25
traitza_children:paternalage.factor(55,90]       1.14       1.23

Multivariate psrf

8.99

> summary(mcmclist)

Iterations = 100001:149951
Thinning interval = 50 
Number of chains = 20 
Sample size per chain = 1000 

1. Empirical mean and standard deviation for each variable,
   plus standard error of the mean:

                                               Mean      SD  Naive SE Time-series SE
(Intercept)                                 1.36326 0.04848 0.0003428      0.0003542
traitza_children                           -0.76679 0.28738 0.0020321      0.0016682
male                                        0.09980 0.01633 0.0001155      0.0001222
spouses                                     0.12333 0.01957 0.0001384      0.0001414
paternalage.mean                            0.07215 0.02194 0.0001551      0.0001596
paternalage.factor(25,30]                  -0.03381 0.04184 0.0002959      0.0003066
paternalage.factor(30,35]                  -0.08380 0.04270 0.0003019      0.0003118
paternalage.factor(35,40]                  -0.16502 0.04569 0.0003231      0.0003289
paternalage.factor(40,45]                  -0.16738 0.05090 0.0003599      0.0003697
paternalage.factor(45,50]                  -0.18383 0.05880 0.0004158      0.0004242
paternalage.factor(50,55]                  -0.18241 0.07277 0.0005146      0.0005302
paternalage.factor(55,90]                  -0.40612 0.09875 0.0006983      0.0007467
traitza_children:male                       0.12092 0.08223 0.0005815      0.0004697
traitza_children:spouses                    0.64881 0.21132 0.0014942      0.0008511
traitza_children:paternalage.mean          -0.02741 0.08550 0.0006046      0.0006221
traitza_children:paternalage.factor(25,30] -0.17296 0.18680 0.0013209      0.0013750
traitza_children:paternalage.factor(30,35] -0.19027 0.19267 0.0013624      0.0013901
traitza_children:paternalage.factor(35,40] -0.24911 0.21282 0.0015049      0.0014391
traitza_children:paternalage.factor(40,45] -0.29772 0.23403 0.0016548      0.0015956
traitza_children:paternalage.factor(45,50] -0.51782 0.28589 0.0020215      0.0017602
traitza_children:paternalage.factor(50,55] -0.46126 0.32064 0.0022673      0.0021397
traitza_children:paternalage.factor(55,90] -0.38612 0.41461 0.0029317      0.0027396

2. Quantiles for each variable:

                                               2.5%      25%      50%      75%      97.5%
(Intercept)                                 1.26883  1.33106  1.36322  1.39575  1.4589722
traitza_children                           -1.20696 -0.95751 -0.81076 -0.63308 -0.0365042
male                                        0.06785  0.08878  0.09970  0.11085  0.1320168
spouses                                     0.08467  0.11030  0.12343  0.13643  0.1617869
paternalage.mean                            0.02950  0.05751  0.07202  0.08683  0.1153881
paternalage.factor(25,30]                  -0.11581 -0.06174 -0.03397 -0.00574  0.0473783
paternalage.factor(30,35]                  -0.16656 -0.11250 -0.08358 -0.05519  0.0003065
paternalage.factor(35,40]                  -0.25518 -0.19530 -0.16500 -0.13440 -0.0757366
paternalage.factor(40,45]                  -0.26887 -0.20164 -0.16675 -0.13335 -0.0677407
paternalage.factor(45,50]                  -0.30080 -0.22320 -0.18339 -0.14440 -0.0687967
paternalage.factor(50,55]                  -0.32663 -0.23034 -0.18227 -0.13317 -0.0415547
paternalage.factor(55,90]                  -0.60202 -0.47303 -0.40454 -0.33994 -0.2139128
traitza_children:male                      -0.01083  0.06634  0.11024  0.16109  0.3295892
traitza_children:spouses                    0.37857  0.51072  0.59398  0.71395  1.2127940
traitza_children:paternalage.mean          -0.19138 -0.08250 -0.02985  0.02493  0.1468989
traitza_children:paternalage.factor(25,30] -0.57457 -0.28481 -0.16489 -0.05151  0.1728148
traitza_children:paternalage.factor(30,35] -0.61499 -0.30350 -0.17736 -0.06299  0.1555147
traitza_children:paternalage.factor(35,40] -0.74251 -0.36752 -0.22966 -0.10777  0.1151897
traitza_children:paternalage.factor(40,45] -0.84165 -0.42691 -0.27729 -0.14322  0.1032436
traitza_children:paternalage.factor(45,50] -1.21782 -0.66568 -0.48420 -0.32873 -0.0476720
traitza_children:paternalage.factor(50,55] -1.21327 -0.63623 -0.43432 -0.24957  0.0955360
traitza_children:paternalage.factor(55,90] -1.33772 -0.62227 -0.35364 -0.11050  0.3361684

> effectiveSize(mcmclist)
                               (Intercept)                           traitza_children 
                                  18814.05                                   16359.33 
                                      male                                    spouses 
                                  18132.98                                   19547.05 
                          paternalage.mean                  paternalage.factor(25,30] 
                                  19238.72                                   18974.81 
                 paternalage.factor(30,35]                  paternalage.factor(35,40] 
                                  18874.33                                   19406.63 
                 paternalage.factor(40,45]                  paternalage.factor(45,50] 
                                  19075.18                                   19401.77 
                 paternalage.factor(50,55]                  paternalage.factor(55,90] 
                                  18960.11                                   17893.23 
                     traitza_children:male                   traitza_children:spouses 
                                  18545.55                                   14438.51 
         traitza_children:paternalage.mean traitza_children:paternalage.factor(25,30] 
                                  18464.09                                   16943.43 
traitza_children:paternalage.factor(30,35] traitza_children:paternalage.factor(35,40] 
                                  16827.44                                   17230.04 
traitza_children:paternalage.factor(40,45] traitza_children:paternalage.factor(45,50] 
                                  17144.78                                   18191.67 
traitza_children:paternalage.factor(50,55] traitza_children:paternalage.factor(55,90] 
                                  17466.60                                   18540.59 


### current script:

# bsub -q mpi -W 24:00 -n 21 -R np20 mpirun -H localhost -n 21 R --slave -f "/usr/users/rarslan/rpqa/krmh_main/children.R"
setwd("/usr/users/rarslan/rpqa/")
library(doMPI)
cl <- startMPIcluster(verbose=T,workdir="/usr/users/rarslan/rpqa/krmh_main/")
registerDoMPI(cl)
Children = foreach(i=1:clusterSize(cl),.options.mpi = list(seed=1337) ) %dopar% {
	library(MCMCglmm);library(data.table)
    setwd("/usr/users/rarslan/rpqa/krmh_main/")
	source("../1 - extraction functions.r")
    load("../krmh1.rdata")

	krmh.1 = recenter.pat(na.omit(krmh.1[spouses>0, list(idParents, children, male, spouses, paternalage)]))
	
	samples = 1000
	thin = 50; burnin = 100000
	nitt = samples * thin + burnin

	prior <- list(
		R=list(V=diag(2), nu=1.002, fix=2), 
		G=list(G1=list(V=diag(2), nu=1, alpha.mu=c(0,0), alpha.V=diag(2)*1000))
	)
	
	start <- list(
		liab=c(rnorm( nrow(krmh.1)*2 )), 
		R = list(R1 = rIW(diag(2), 10 )),
		G = list(G1 = rIW(diag(2), 10 ))
	)
					 
	( m1 = MCMCglmm( children ~ trait * (male + spouses + paternalage.mean + paternalage.factor),
						rcov=~idh(trait):units,
						random=~idh(trait):idParents,
						family="zapoisson",
						start = start,
						prior = prior,
						data=krmh.1, 
						pr = F, saveX = F, saveZ = F,
						nitt=nitt,thin=thin,burnin=burnin)
	)
		m1$Residual$nrt<-2
	m1
}

save(Children,file = "Children.rdata")
closeCluster(cl)
mpi.quit()

On 28 Aug 2014, at 20:59, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:

> Hi,
> 
> The posteriors for the two models look pretty close to me. Are the scale reduction factors really as high as previously reported? Before you had 1.83 for traitza_children:spouses, but the plot suggests that it should be close to 1?
> 
> Cheers,
> 
> Jarrod
> 
> 
> 
> 
> Quoting Ruben Arslan <rubenarslan at gmail.com> on Thu, 28 Aug 2014 19:59:16 +0200:
> 
>> Sure! Thanks a lot.
>> I am using ~idh(trait):units already, sorry for saying that incorrectly in my last email.
>> These models aren't the final thing, I will replace the paternalage.factor variable
>> with its linear equivalent if that seems defensible (does so far) and in this model it seems
>> okay to remove the za-effects for all predictors except spouses.
>> So a final model would have fewer fixed effects. I also have datasets of 200k+ and 5m+,
>> but I'm learning MCMCglmm with this smaller one because my wrong turns take less time.
>> 
>> I've uploaded a comparison coef plot of two models:
>> http://i.imgur.com/sHUfnmd.png
>> m7 is with the default starting values, m1 is with the specification I sent in my last email. I don't
>> know if such differences are something to worry about.
>> 
>> I don't know what qualifies as highly overdispersed, here's a plot of the outcome for ever
>> married people (slate=real data):
>> http://imgur.com/14MywgZ
>> here's with everybody born (incl. some stillborn etc.):
>> http://imgur.com/knRGa1v
>> I guess my approach (generating an overdispersed poisson with the parameters from
>> the data and checking if it has as excess zeroes) is not the best way to diagnose zero-inflation,
>> but especially in the second case it seems fairly clear-cut.
>> 
>> Best regards,
>> 
>> Ruben
>> 
>>> summary(m1)
>> 
>> Iterations = 50001:149951
>> Thinning interval  = 50
>> Sample size  = 2000
>> 
>> DIC: 31249.73
>> 
>> G-structure:  ~idh(trait):idParents
>> 
>>                      post.mean  l-95% CI u-95% CI eff.samp
>> children.idParents     0.006611 4.312e-08   0.0159    523.9
>> za_children.idParents  0.193788 7.306e-02   0.3283    369.3
>> 
>> R-structure:  ~idh(trait):units
>> 
>>                  post.mean l-95% CI u-95% CI eff.samp
>> children.units       0.1285   0.1118   0.1452    716.1
>> za_children.units    0.9950   0.9950   0.9950      0.0
>> 
>> Location effects: children ~ trait * (male + spouses + paternalage.mean + paternalage.factor)
>> 
>>                                            post.mean   l-95% CI   u-95% CI eff.samp  pMCMC
>> (Intercept)                                 1.3413364  1.2402100  1.4326099     1789 <5e-04 ***
>> traitza_children                           -0.8362879 -1.2007980 -0.5016730     1669 <5e-04 ***
>> male                                        0.0994902  0.0679050  0.1297394     2000 <5e-04 ***
>> spouses                                     0.1236033  0.0839000  0.1624939     2000 <5e-04 ***
>> paternalage.mean                            0.0533892  0.0119569  0.0933960     2000  0.015 *
>> paternalage.factor(25,30]                  -0.0275822 -0.1116421  0.0537359     1842  0.515
>> paternalage.factor(30,35]                  -0.0691025 -0.1463214  0.0122393     1871  0.097 .
>> paternalage.factor(35,40]                  -0.1419933 -0.2277379 -0.0574678     1845 <5e-04 ***
>> paternalage.factor(40,45]                  -0.1364952 -0.2362714 -0.0451874     1835  0.007 **
>> paternalage.factor(45,50]                  -0.1445342 -0.2591767 -0.0421178     1693  0.008 **
>> paternalage.factor(50,55]                  -0.1302972 -0.2642965  0.0077061     2000  0.064 .
>> paternalage.factor(55,90]                  -0.3407879 -0.5168972 -0.1493652     1810 <5e-04 ***
>> traitza_children:male                       0.0926888 -0.0147379  0.2006142     1901  0.098 .
>> traitza_children:spouses                    0.5531197  0.3870616  0.7314289     1495 <5e-04 ***
>> traitza_children:paternalage.mean           0.0051463 -0.1279396  0.1460099     1617  0.960
>> traitza_children:paternalage.factor(25,30] -0.1538957 -0.4445749  0.1462955     1781  0.321
>> traitza_children:paternalage.factor(30,35] -0.1747883 -0.4757851  0.1162476     1998  0.261
>> traitza_children:paternalage.factor(35,40] -0.2261843 -0.5464379  0.0892582     1755  0.166
>> traitza_children:paternalage.factor(40,45] -0.2807543 -0.6079678  0.0650281     1721  0.100 .
>> traitza_children:paternalage.factor(45,50] -0.4905843 -0.8649214 -0.1244174     1735  0.010 **
>> traitza_children:paternalage.factor(50,55] -0.4648579 -0.9215759 -0.0002083     1687  0.054 .
>> traitza_children:paternalage.factor(55,90] -0.3945406 -1.0230155  0.2481568     1793  0.195
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> 
>>> describe(krmh.1[spouses>0,])
>>                    vars    n mean   sd median trimmed  mad   min   max range skew kurtosis   se
>> children               2 6829 3.81 2.93   4.00    3.61 2.97  0.00 16.00 16.00 0.47    -0.46 0.04
>> male                   3 6829 0.46 0.50   0.00    0.45 0.00  0.00  1.00  1.00 0.14    -1.98 0.01
>> spouses                4 6829 1.14 0.38   1.00    1.03 0.00  1.00  4.00  3.00 2.87     8.23 0.00
>> paternalage            5 6829 3.65 0.80   3.57    3.60 0.80  1.83  7.95  6.12 0.69     0.70 0.01
>> paternalage_c          6 6829 0.00 0.80  -0.08   -0.05 0.80 -1.82  4.30  6.12 0.69     0.70 0.01
>> paternalage.mean       7 6829 0.00 0.68  -0.08   -0.05 0.59 -1.74  4.30  6.04 0.95     1.97 0.01
>> paternalage.diff       8 6829 0.00 0.42   0.00   -0.01 0.38 -1.51  1.48  2.99 0.17     0.17 0.01
>> 
>>> table(krmh.1$paternalage.factor)
>> 
>> [0,25] (25,30] (30,35] (35,40] (40,45] (45,50] (50,55] (55,90]
>>    309    1214    1683    1562    1039     623     269     130
>> 
>> On 28 Aug 2014, at 19:05, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>> 
>>> Hi Ruben,
>>> 
>>> It might be hard to detect (near) ECPs with so many fixed effects (can you post the model summary (and give us the mean and standard deviation of any continuous covariates)). Also, the complementary log-log link (which is the za specification) is non-symmetric and runs into problems outside the range -35 to 3.5 so there may be a problem there, particularly if you use rcov=~trait:units and the Poisson part is highly over-dispersed.  You could try rcov=~idh(trait):units and fix the non-identifiable za residual variance to something smaller than 1 (say 0.5)  - it will mix slower but it will reduce the chance of over/underflow.
>>> 
>>> Cheers,
>>> 
>>> Jarrod
>>> 
>>> 
>>> 
>>> 
>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Thu, 28 Aug 2014 18:45:30 +0200:
>>> 
>>>> Hi Jarrod,
>>>> 
>>>>> 1) it did not return an error with rcov = ~trait:units because you used R1=rpois(2,1)+1 and yet this specification only fits a single variance (not a 2x2 covariance matrix). R1=rpois(2,1)+1 is a bit of a weird specification since it has to be integer. I would obtain starting values using rIW().
>>>> 
>>>> I agree it's a weird specification, I was a bit lost and thought I could get away with just putting some random numbers in the starting value.
>>>> I didn't do R1=rpois(2,1)+1 though, I did R1=diag(rpois(2,1)+1), so I got a 2x2 matrix, but yes, bound to be integer.
>>>> I didn't know starting values should come from a conjugate distribution, though that probably means I didn't think about it much.
>>>> 
>>>> I'm now doing
>>>> start <- list(
>>>> 	liab=c(rnorm( nrow(krmh.1)*2 )),
>>>> 	R = list(R1 = rIW( diag(2), nrow(krmh.1)) ),
>>>> 	G = list(G1 = rIW( diag(2), nrow(krmh.1)) )
>>>> )
>>>> 
>>>> Is this what you had in mind?
>>>> I am especially unsure if I am supposed to use such a low sampling variability (my sample size is probably not even relevant for the starting values) and if I should start from diag(2).
>>>> 
>>>> And, I am still happily confused that this specification still doesn't lead to errors with respect to rcov = ~trait:units . Does this mean I'm doing it wrong?
>>>> 
>>>>> 3) a) how many effective samples do you have for each parameter? and b) are you getting extreme category problems/numerical issues? If you store the latent variables (pl=TUE) what is their range for the Zi/za part?
>>>> 
>>>> My parallel run using the above starting values isn't finished yet.
>>>> a) After applying the above starting values I get, for the location effects 1600-2000 samples for a 2000 sample chain (with thin set to 50). G and R-structure are from 369 (za_children.idParents) to 716 (and 0 for the fixed part).
>>>> Effective sample sizes were similar for my run using the starting values for G/R that I drew from rpois, and using 40 chains I of course get
>>>> b) I don't think I am getting extreme categories. I would probably be getting extreme categories if I included the forever-alones (they almost never have children), but this way no.
>>>> I wasn't sure how to examine the range of the latents separately for the za part, but for a single chain it looks okay:
>>>>> quantile(as.numeric(m1$Liab),probs = c(0,0.01,0,0.99,1))
>>>>      0%        1%        0%       99%      100%
>>>> -4.934111 -1.290728 -4.934111  3.389847  7.484206
>>>> 
>>>> Well, all considered now that I use the above starting value specification I get slightly different estimates for all za-coefficients. Nothing major, but still leading me to
>>>> think my estimates aren't exactly independent of the starting values I use. I'll see what the parallel run yields.
>>>> 
>>>> Thanks a lot,
>>>> 
>>>> Ruben
>>>> 
>>>>> 
>>>>> Cheers,
>>>>> 
>>>>> Jarrod
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Wed, 27 Aug 2014 19:23:42 +0200:
>>>>> 
>>>>>> Hi Jarrod,
>>>>>> 
>>>>>> thanks again. I was able to get it running with your advice.
>>>>>> Some points of confusion remain:
>>>>>> 
>>>>>> - You wrote that zi/za models would return an error with rcov = ~trait:units + starting values. This did not happen in my case, so I didn't build MCMCglmm myself with your suggested edits. Also, have you considered putting your own MCMCglmm repo on Github? Your users would be able to install pre-releases and I'd think you'd get some time-saving pull requests too.
>>>>>> - In my attempts to get my models to run properly, I messed up a prior and did not use fix=2 in my prior specification for my za models. This led to crappy convergence, it's much better now and for some of my simpler models I think I won't need parallel chains. I'm reminded of Gelman's folk theorem of statistical computing.
>>>>>> - I followed your advice, but of course I could not set the true values as starting values, but wanted to set random, bad starting values. I pasted below what I arrived at, I'm especially unsure whether I specified the starting values for G and R properly (I think not).
>>>>>> 	start <- list(
>>>>>> 		liab=c(rnorm( nrow(krmh.1)*2 )),
>>>>>> 		R = list(R1 = diag(rpois(2, 1)+1)),
>>>>>> 		G = list(G1 = diag(rpois(2, 1)+1))
>>>>>> 	)
>>>>>> 
>>>>>> 
>>>>>> However, even though I may not need multiple chains for some of my simpler models, I've now run into conflicting diagnostics. The geweke.diag for each chain (and examination of the traces) gives
>>>>>> satisfactory diagnostics. Comparing multiple chains using gelman.diag, however, leads to one bad guy, namely the traitza_children:spouses interaction.
>>>>>> I think this implies that I've got some starting value dependence for this parameter, that won't be easily rectified through longer burnin?
>>>>>> Do you have any ideas how to rectify this?
>>>>>> I am currently doing sequential analyses on episodes of selection and in historical human data only those who marry have a chance at having kids. I exclude the unmarried
>>>>>> from my sample where I predict number of children, because I examine that in a previous model and the zero-inflation (65% zeros, median w/o unmarried = 4) when including the unmarried is so excessive.
>>>>>> Number of spouses is easily the strongest predictor in the model, but only serves as a covariate here. Since my other estimates are stable across chains and runs and agree well across models and with theory, I'm
>>>>>> inclined to shrug this off. But probably I shouldn't ignore this sign of non-convergence?
>>>>>> 
>>>>>>> gelman.diag(mcmc_1)
>>>>>> Potential scale reduction factors:
>>>>>> 
>>>>>>                                         Point est. Upper C.I.
>>>>>> (Intercept)                                      1.00       1.00
>>>>>> traitza_children                                 1.27       1.39
>>>>>> male                                             1.00       1.00
>>>>>> spouses                                          1.00       1.00
>>>>>> paternalage.mean                                 1.00       1.00
>>>>>> paternalage.factor(25,30]                        1.00       1.00
>>>>>> paternalage.factor(30,35]                        1.00       1.00
>>>>>> paternalage.factor(35,40]                        1.00       1.00
>>>>>> paternalage.factor(40,45]                        1.00       1.00
>>>>>> paternalage.factor(45,50]                        1.00       1.00
>>>>>> paternalage.factor(50,55]                        1.00       1.00
>>>>>> paternalage.factor(55,90]                        1.00       1.00
>>>>>> traitza_children:male                            1.22       1.32
>>>>>> traitza_children:spouses                         1.83       2.13
>>>>>> traitza_children:paternalage.mean                1.02       1.02
>>>>>> traitza_children:paternalage.factor(25,30]       1.03       1.05
>>>>>> traitza_children:paternalage.factor(30,35]       1.05       1.08
>>>>>> traitza_children:paternalage.factor(35,40]       1.10       1.15
>>>>>> traitza_children:paternalage.factor(40,45]       1.12       1.17
>>>>>> traitza_children:paternalage.factor(45,50]       1.19       1.28
>>>>>> traitza_children:paternalage.factor(50,55]       1.12       1.18
>>>>>> traitza_children:paternalage.factor(55,90]       1.11       1.17
>>>>>> 
>>>>>> Multivariate psrf
>>>>>> 
>>>>>> 7.27
>>>>>> 
>>>>>> 
>>>>>> Best regards,
>>>>>> 
>>>>>> Ruben
>>>>>> 
>>>>>> 
>>>>>> On 26 Aug 2014, at 13:04, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>>>>> 
>>>>>>> Hi Ruben,
>>>>>>> 
>>>>>>> There are 400 liabilities in a zapoisson model (2 per datum). This code should work:
>>>>>>> 
>>>>>>> g <-sample(letters[1:10], size = 200, replace = T)
>>>>>>> pred <- rnorm(200)
>>>>>>> 
>>>>>>> l1<-rnorm(200, -1, sqrt(1))
>>>>>>> l2<-rnorm(200, -1, sqrt(1))
>>>>>>> 
>>>>>>> y<-VGAM::rzapois(200, exp(l1), exp(-exp(l2)))
>>>>>>> 
>>>>>>> # generate zero-altered data with an intercept of -1 (because the intercept and variance are the same for both processes this is just standard Poisson)
>>>>>>> 
>>>>>>> dat<-data.frame(y=y, g = g, pred = pred)
>>>>>>> 
>>>>>>> 
>>>>>>> start.1<-list(liab=c(l1,l2), R = list(R1=diag(2)), G=list(G1=diag(2)))
>>>>>>> prior.1<-list(R=list(V=diag(2), nu=1.002, fix=2), G=list(G1=list(V=diag(2), nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000)))
>>>>>>> 
>>>>>>> m1<-MCMCglmm(y~trait + pred:trait, random=~us(trait):g, family="zapoisson",rcov=~idh(trait):units, data=dat, prior=prior.1, start= start.1)
>>>>>>> 
>>>>>>> However, there are 2 bugs in the current version of MCMCglmm that return an error message when the documentation implies it should be fine:
>>>>>>> 
>>>>>>> a) it should be possible to have R=diag(2) rather than R = list(R1=diag(2)). This bug cropped up when I implemented block-diagonal R structures. It can be fixed by inserting:
>>>>>>> 
>>>>>>>       if(!is.list(start$R)){
>>>>>>>          start$R<-list(R1=start$R)
>>>>>>>       }
>>>>>>> 
>>>>>>> on L514 of MCMCglmm.R below
>>>>>>> 
>>>>>>>       if(!is.list(prior$R[[1]])){
>>>>>>>          prior$R<-list(R1=prior$R)
>>>>>>>       }
>>>>>>> 
>>>>>>> b) rcov=~trait:units models for zi/za models will return an error when passing starting values. To fix this insert
>>>>>>> 
>>>>>>>      if(diagR==3){
>>>>>>>        if(dim(start)[1]!=1){
>>>>>>>          stop("V is the wrong dimension for some strart$G/start$R elements")
>>>>>>>        }
>>>>>>>        start<-diag(sum(nfl))*start[1]
>>>>>>>      }
>>>>>>> 
>>>>>>> on L90 of priorfromat.R below
>>>>>>> 
>>>>>>>      if(is.matrix(start)==FALSE){
>>>>>>>        start<-as.matrix(start)
>>>>>>>      }
>>>>>>> 
>>>>>>> I will put these in the new version.
>>>>>>> 
>>>>>>> Cheers,
>>>>>>> 
>>>>>>> Jarrod
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25 Aug 2014 21:52:30 +0200:
>>>>>>> 
>>>>>>>> Hi Jarrod,
>>>>>>>> 
>>>>>>>> thanks for these pointers.
>>>>>>>> 
>>>>>>>>>> You will need to provide over-dispersed starting values for multiple-chain convergence diagnostics to be useful (GLMM are so simple I am generally happy if the output of a single run looks reasonable).
>>>>>>>> 
>>>>>>>> Oh, I would be happy with single chains, but since computation would take weeks this way, I wanted to parallelise and I would use the multi-chain convergence as a criterion that my parallelisation was proper
>>>>>>>> and is as informative as a single long chain. There don't seem to be any such checks built-in ? I was analysing my 40 chains for a bit longer than I like to admit until I noticed they were identical (effectiveSize
>>>>>>>> and summary.mcmc.list did not yell at me for this).
>>>>>>>> 
>>>>>>>>>> # use some very bad starting values
>>>>>>>> I get that these values are bad, but that is the goal for my multi-chain aim, right?
>>>>>>>> 
>>>>>>>> I can apply this to my zero-truncated model, but am again getting stuck with the zero-altered one.
>>>>>>>> Maybe I need only specify the Liab values for this?
>>>>>>>> At least I'm getting nowhere with specifying R and G starting values here. When I got an error, I always
>>>>>>>> went to the MCMCglmm source to understand why the checks failed, but I didn't always understand
>>>>>>>> what was being checked and couldn't get it to work.
>>>>>>>> 
>>>>>>>> Here's a failing example:
>>>>>>>> 
>>>>>>>> l<-rnorm(200, -1, sqrt(1))
>>>>>>>> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
>>>>>>>> g = sample(letters[1:10], size = 200, replace = T)
>>>>>>>> pred = rnorm(200)
>>>>>>>> y<-rpois(200,exp(l)-t)
>>>>>>>> y[1:40] = 0
>>>>>>>> # generate zero-altered data with an intercept of -1
>>>>>>>> 
>>>>>>>> dat<-data.frame(y=y, g = g, pred = pred)
>>>>>>>> set.seed(1)
>>>>>>>> start_true = list(Liab=l, R = 1, G = 1 )
>>>>>>>> m1<-MCMCglmm(y~1 + pred,random = ~ g, family="zapoisson",rcov=~us(trait):units, data=dat, start= start_true)
>>>>>>>> 
>>>>>>>> # use true latent variable as starting values
>>>>>>>> set.seed(1)
>>>>>>>> # use some very bad starting values
>>>>>>>> start_rand = list(Liab=rnorm(200), R = rpois(1, 1)+1, G = rpois(1, 1)+1 )
>>>>>>>> m2<-MCMCglmm(y~1 + pred,random = ~ g,rcov=~us(trait):units,  family="zapoisson", data=dat, start = start_rand)
>>>>>>>> 
>>>>>>>> Best,
>>>>>>>> 
>>>>>>>> Ruben
>>>>>>>> 
>>>>>>>> On 25 Aug 2014, at 18:29, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>>>>>>> 
>>>>>>>>> Hi Ruben,
>>>>>>>>> 
>>>>>>>>> Sorry  - I was wrong when I said that everything is Gibbs sampled conditional on the latent variables. The location effects (fixed and random effects) are also sampled conditional on the (co)variance components so you should add them to the starting values. In the case where the true values are used:
>>>>>>>>> 
>>>>>>>>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat, start=list(Liab=l,R=1))
>>>>>>>>> 
>>>>>>>>> Cheers,
>>>>>>>>> 
>>>>>>>>> Jarrod
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> Quoting Jarrod Hadfield <j.hadfield at ed.ac.uk> on Mon, 25 Aug 2014 17:14:14 +0100:
>>>>>>>>> 
>>>>>>>>>> Hi Ruben,
>>>>>>>>>> 
>>>>>>>>>> You will need to provide over-dispersed starting values for multiple-chain convergence diagnostics to be useful (GLMM are so simple I am generally happy if the output of a single run looks reasonable).
>>>>>>>>>> 
>>>>>>>>>> With non-Gaussian data everything is Gibbs sampled conditional on the latent variables, so you only need to pass them:
>>>>>>>>>> 
>>>>>>>>>> l<-rnorm(200, -1, sqrt(1))
>>>>>>>>>> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
>>>>>>>>>> y<-rpois(200,exp(l)-t)+1
>>>>>>>>>> # generate zero-truncated data with an intercept of -1
>>>>>>>>>> 
>>>>>>>>>> dat<-data.frame(y=y)
>>>>>>>>>> set.seed(1)
>>>>>>>>>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat, start=list(Liab=l))
>>>>>>>>>> # use true latent variable as starting values
>>>>>>>>>> set.seed(1)
>>>>>>>>>> m2<-MCMCglmm(y~1, family="ztpoisson", data=dat, start=list(Liab=rnorm(200)))
>>>>>>>>>> # use some very bad starting values
>>>>>>>>>> 
>>>>>>>>>> plot(mcmc.list(m1$Sol, m2$Sol))
>>>>>>>>>> # not identical despite the same seed because of different starting values but clearly sampling the same posterior distribution:
>>>>>>>>>> 
>>>>>>>>>> gelman.diag(mcmc.list(m1$Sol, m2$Sol))
>>>>>>>>>> 
>>>>>>>>>> Cheers,
>>>>>>>>>> 
>>>>>>>>>> Jarrod
>>>>>>>>>> 
>>>>>>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25 Aug 2014 18:00:08 +0200:
>>>>>>>>>> 
>>>>>>>>>>> Dear Jarrod,
>>>>>>>>>>> 
>>>>>>>>>>> thanks for the quick reply. Please, don't waste time looking into doMPI ? I am happy that I
>>>>>>>>>>> get the expected result, when I specify that reproducible seed, whyever that may be.
>>>>>>>>>>> I'm pretty sure that is the deciding factor, because I tested it explicitly, I just have no idea
>>>>>>>>>>> how/why it interacts with the choice of family.
>>>>>>>>>>> 
>>>>>>>>>>> That said, is setting up different RNG streams for my workers (now that it works) __sufficient__
>>>>>>>>>>> so that I get independent chains and can use gelman.diag() for convergence diagnostics?
>>>>>>>>>>> Or should I still tinker with the starting values myself?
>>>>>>>>>>> I've never found a worked example of supplying starting values and am thus a bit lost.
>>>>>>>>>>> 
>>>>>>>>>>> Sorry for sending further questions, I hope someone else takes pity while
>>>>>>>>>>> you're busy with lectures.
>>>>>>>>>>> 
>>>>>>>>>>> Best wishes
>>>>>>>>>>> 
>>>>>>>>>>> Ruben
>>>>>>>>>>> 
>>>>>>>>>>> 
>>>>>>>>>>> 
>>>>>>>>>>> On 25 Aug 2014, at 17:29, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>>>>>>>>>> 
>>>>>>>>>>>> Hi Ruben,
>>>>>>>>>>>> 
>>>>>>>>>>>> I do not think the issue is with the starting values, because even if the same starting values were used the chains would still differ because of the randomness in the Markov Chain (if I interpret your `identical' test correctly). This just involves a call to GetRNGstate() in the C++ code (L 871 ofMCMCglmm.cc) so I think for some reason doMPI/foreach is not doing what you expect. I am not familiar with doMPI and am in the middle of writing lectures so haven't got time to look into it carefully. Outside of the context of doMPI I get the behaviour I expect:
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> l<-rnorm(200, -1, sqrt(1))
>>>>>>>>>>>> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
>>>>>>>>>>>> y<-rpois(200,exp(l)-t)+1
>>>>>>>>>>>> # generate zero-truncated data with an intercept of -1
>>>>>>>>>>>> 
>>>>>>>>>>>> dat<-data.frame(y=y)
>>>>>>>>>>>> set.seed(1)
>>>>>>>>>>>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>>>>>>>>>> set.seed(2)
>>>>>>>>>>>> m2<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>>>>>>>>>> set.seed(2)
>>>>>>>>>>>> m3<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>>>>>>>>>> 
>>>>>>>>>>>> plot(mcmc.list(m1$Sol, m2$Sol))
>>>>>>>>>>>> # different, as expected
>>>>>>>>>>>> plot(mcmc.list(m2$Sol, m3$Sol))
>>>>>>>>>>>> # the same, as expected
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25 Aug 2014 16:58:06 +0200:
>>>>>>>>>>>> 
>>>>>>>>>>>>> Dear list,
>>>>>>>>>>>>> 
>>>>>>>>>>>>> sorry for bumping my old post, I hope to elicit a response with a more focused question:
>>>>>>>>>>>>> 
>>>>>>>>>>>>> When does MCMCglmm automatically start from different values when using doMPI/foreach?
>>>>>>>>>>>>> 
>>>>>>>>>>>>> I have done some tests with models of varying complexity. For example, the script in my last
>>>>>>>>>>>>> post (using "zapoisson") yielded 40 identical chains:
>>>>>>>>>>>>>> identical(mcmclist[1], mcmclist[30])
>>>>>>>>>>>>> TRUE
>>>>>>>>>>>>> 
>>>>>>>>>>>>> A simpler (?) model (using "ztpoisson" and no specified prior), however, yielded different chains
>>>>>>>>>>>>> and I could use them to calculate gelman.diag()
>>>>>>>>>>>>> 
>>>>>>>>>>>>> Changing my script to the version below, i.e. seeding foreach using .options.mpi=list( seed= 1337)
>>>>>>>>>>>>> so as to make RNGstreams reproducible (or so I  thought), led to different chains even for the
>>>>>>>>>>>>> "zapoisson" model.
>>>>>>>>>>>>> 
>>>>>>>>>>>>> In no case have I (successfully) tried to supplant the default of MCMCglmm's "start" argument.
>>>>>>>>>>>>> Is starting my models from different RNGsubstreams inadequate compared to manipulating
>>>>>>>>>>>>> the start argument explicitly? If so, is there any worked example of explicit starting value manipulation
>>>>>>>>>>>>> in parallel computation?
>>>>>>>>>>>>> I've browsed the MCMCglmm source to understand how the default starting values are generated,
>>>>>>>>>>>>> but didn't find any differences with respect to RNG for the two families "ztpoisson" and "zapoisson"
>>>>>>>>>>>>> (granted, I did not dig very deep).
>>>>>>>>>>>>> 
>>>>>>>>>>>>> Best regards,
>>>>>>>>>>>>> 
>>>>>>>>>>>>> Ruben Arslan
>>>>>>>>>>>>> 
>>>>>>>>>>>>> 
>>>>>>>>>>>>> # bsub -q mpi -W 12:00 -n 41 -R np20 mpirun -H localhost -n 41 R --slave -f "/usr/users/rarslan/rpqa/rpqa_main/rpqa_children_parallel.R"
>>>>>>>>>>>>> 
>>>>>>>>>>>>> library(doMPI)
>>>>>>>>>>>>> cl <- startMPIcluster(verbose=T,workdir="/usr/users/rarslan/rpqa/rpqa_main/")
>>>>>>>>>>>>> registerDoMPI(cl)
>>>>>>>>>>>>> Children_mcmc1 = foreach(i=1:clusterSize(cl),.options.mpi = list(seed=1337) ) %dopar% {
>>>>>>>>>>>>> 	library(MCMCglmm);library(data.table)
>>>>>>>>>>>>> 	load("/usr/users/rarslan/rpqa/rpqa1.rdata")
>>>>>>>>>>>>> 
>>>>>>>>>>>>> 	nitt = 130000; thin = 100; burnin = 30000
>>>>>>>>>>>>> 	prior.m5d.2 = list(
>>>>>>>>>>>>> 		R = list(V = diag(c(1,1)), nu = 0.002),
>>>>>>>>>>>>> 		G=list(list(V=diag(c(1,1e-6)),nu=0.002))
>>>>>>>>>>>>> 	)
>>>>>>>>>>>>> 
>>>>>>>>>>>>> 	rpqa.1 = na.omit(rpqa.1[spouses>0, list(idParents, children, male, urban, spouses, paternalage.mean, paternalage.factor)])
>>>>>>>>>>>>> 	(m1 = MCMCglmm( children ~ trait * (male + urban + spouses + paternalage.mean + paternalage.factor),
>>>>>>>>>>>>> 						rcov=~us(trait):units,
>>>>>>>>>>>>> 						random=~us(trait):idParents,
>>>>>>>>>>>>> 						family="zapoisson",
>>>>>>>>>>>>> 						prior = prior.m5d.2,
>>>>>>>>>>>>> 						data=rpqa.1,
>>>>>>>>>>>>> 						pr = F, saveX = F, saveZ = F,
>>>>>>>>>>>>> 						nitt=nitt,thin=thin,burnin=burnin))
>>>>>>>>>>>>> }
>>>>>>>>>>>>> 
>>>>>>>>>>>>> library(coda)
>>>>>>>>>>>>> mcmclist = mcmc.list(lapply(Children_mcmc1,FUN=function(x) { x$Sol}))
>>>>>>>>>>>>> save(Children_mcmc1,mcmclist, file = "/usr/users/rarslan/rpqa/rpqa_main/rpqa_mcmc_kids_za.rdata")
>>>>>>>>>>>>> closeCluster(cl)
>>>>>>>>>>>>> mpi.quit()
>>>>>>>>>>>>> 
>>>>>>>>>>>>> 
>>>>>>>>>>>>> 
>>>>>>>>>>>>> On 04 Aug 2014, at 20:25, Ruben Arslan <rubenarslan at gmail.com> wrote:
>>>>>>>>>>>>> 
>>>>>>>>>>>>>> Dear list,
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> would someone be willing to share her or his efforts in parallelising a MCMCglmm analysis?
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> I had something viable using harvestr that seemed to properly initialise
>>>>>>>>>>>>>> the starting values from different random number streams (which is desirable,
>>>>>>>>>>>>>> as far as I could find out), but I ended up being unable to use harvestr, because
>>>>>>>>>>>>>> it uses an old version of plyr, where parallelisation works only for multicore, not for
>>>>>>>>>>>>>> MPI.
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> I pasted my working version, that does not do anything about starting values or RNG
>>>>>>>>>>>>>> at the end of this email. I can try to fumble further in the dark or try to update harvestr,
>>>>>>>>>>>>>> but maybe someone has gone through all this already.
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> I'd also appreciate any tips for elegantly post-processing such parallel data, as some of my usual
>>>>>>>>>>>>>> extraction functions and routines are hampered by the fact that some coda functions
>>>>>>>>>>>>>> do not aggregate results over chains. (What I get from a single-chain summary in MCMCglmm
>>>>>>>>>>>>>> is a bit more comprehensive, than what I managed to cobble together with my own extraction
>>>>>>>>>>>>>> functions).
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> The reason I'm parallelising my analyses is that I'm having trouble getting a good effective
>>>>>>>>>>>>>> sample size for any parameter having to do with the many zeroes in my data.
>>>>>>>>>>>>>> Any pointers are very appreciated, I'm quite inexperienced with MCMCglmm.
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> Best wishes
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> Ruben
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> # bsub -q mpi-short -W 2:00 -n 42 -R np20 mpirun -H localhost -n 41 R --slave -f "rpqa/rpqa_main/rpqa_children_parallel.r"
>>>>>>>>>>>>>> library(doMPI)
>>>>>>>>>>>>>> cl <- startMPIcluster()
>>>>>>>>>>>>>> registerDoMPI(cl)
>>>>>>>>>>>>>> Children_mcmc1 = foreach(i=1:40) %dopar% {
>>>>>>>>>>>>>> 	library(MCMCglmm)
>>>>>>>>>>>>>> 	load("rpqa1.rdata")
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> 	nitt = 40000; thin = 100; burnin = 10000
>>>>>>>>>>>>>> 	prior = list(
>>>>>>>>>>>>>> 		R = list(V = diag(c(1,1)), nu = 0.002),
>>>>>>>>>>>>>> 		G=list(list(V=diag(c(1,1e-6)),nu=0.002))
>>>>>>>>>>>>>> 	)
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> 	MCMCglmm( children ~ trait -1 + at.level(trait,1):male + at.level(trait,1):urban + at.level(trait,1):spouses + at.level(trait,1):paternalage.mean + at.level(trait,1):paternalage.factor,
>>>>>>>>>>>>>> 		rcov=~us(trait):units,
>>>>>>>>>>>>>> 		random=~us(trait):idParents,
>>>>>>>>>>>>>> 		family="zapoisson",
>>>>>>>>>>>>>> 		prior = prior,
>>>>>>>>>>>>>> 		data=rpqa.1,
>>>>>>>>>>>>>> 		pr = F, saveX = T, saveZ = T,
>>>>>>>>>>>>>> 		nitt=nitt,thin=thin,burnin=burnin)
>>>>>>>>>>>>>> }
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> library(coda)
>>>>>>>>>>>>>> mcmclist = mcmc.list(lapply(Children_mcmc1,FUN=function(x) { x$Sol}))
>>>>>>>>>>>>>> save(Children_mcmc1,mcmclist, file = "rpqa_mcmc_kids_za.rdata")
>>>>>>>>>>>>>> closeCluster(cl)
>>>>>>>>>>>>>> mpi.quit()
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> --
>>>>>>>>>>>>>> Ruben C. Arslan
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> Georg August University G?ttingen
>>>>>>>>>>>>>> Biological Personality Psychology and Psychological Assessment
>>>>>>>>>>>>>> Georg Elias M?ller Institute of Psychology
>>>>>>>>>>>>>> Go?lerstr. 14
>>>>>>>>>>>>>> 37073 G?ttingen
>>>>>>>>>>>>>> Germany
>>>>>>>>>>>>>> Tel.: +49 551 3920704
>>>>>>>>>>>>>> https://psych.uni-goettingen.de/en/biopers/team/arslan
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> 
>>>>>>>>>>>>> 
>>>>>>>>>>>>> 
>>>>>>>>>>>>> 	[[alternative HTML version deleted]]
>>>>>>>>>>>>> 
>>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> --
>>>>>>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>>>>>>> Scotland, with registration number SC005336.
>>>>>>>>>>> 
>>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> --
>>>>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>>>>> Scotland, with registration number SC005336.
>>>>>>>>>> 
>>>>>>>>>> _______________________________________________
>>>>>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> --
>>>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>>>> Scotland, with registration number SC005336.
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> --
>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>> Scotland, with registration number SC005336.
>>>>>>> 
>>>>>>> 
>>>>>> 
>>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> --
>>>>> The University of Edinburgh is a charitable body, registered in
>>>>> Scotland, with registration number SC005336.
>>>>> 
>>>>> 
>>>> 
>>>> 
>>>> 
>>> 
>>> 
>>> 
>>> --
>>> The University of Edinburgh is a charitable body, registered in
>>> Scotland, with registration number SC005336.
>>> 
>>> 
>> 
>> 
> 
> 
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
> 
> 


	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Fri Aug 29 09:04:42 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 29 Aug 2014 08:04:42 +0100
Subject: [R-sig-ME] parallel MCMCglmm, RNGstreams,
 starting values & priors
In-Reply-To: <E5B149F2-7773-4E2D-854C-3275A352A245@gmail.com>
References: <4CD76FE1-D3F5-4980-9122-B0AC0D44FF81@gmail.com>
	<0E12EB43-72BC-42AC-9E74-9DF53DB42217@gmail.com>
	<20140825162907.10475jpywlu1wzs4@www.staffmail.ed.ac.uk>
	<0A463095-8656-49B7-9619-E557DD449E21@gmail.com>
	<20140825171414.10872gnlopk1we68@www.staffmail.ed.ac.uk>
	<20140825172936.15916weehiwjyc08@www.staffmail.ed.ac.uk>
	<8D35B834-0D31-486A-B5FB-0F279761FDB2@gmail.com>
	<49D60399-6902-45AC-80A9-9F3C35532228@gmail.com>
	<20140826120434.14613hxqhgwbhq80@www.staffmail.ed.ac.uk>
	<8557AE32-AFC9-4FD2-9C88-2D118B484637@gmail.com>
	<20140827183959.18662zc6hw5jj20w@www.staffmail.ed.ac.uk>
	<2D00600E-5287-4FE1-B605-82C0CBA286ED@gmail.com>
	<20140828180551.74212a0xoeoihn6s@www.staffmail.ed.ac.uk>
	<BBB5F7E3-75FE-4BA3-82B4-49DAA64873A4@gmail.com>
	<20140828195957.68171hjra56vrrr4@www.staffmail.ed.ac.uk>
	<E5B149F2-7773-4E2D-854C-3275A352A245@gmail.com>
Message-ID: <20140829080442.1833246y8pj3itq8@www.staffmail.ed.ac.uk>

Hi Ruben,

Can you share your data and I will take a look. Its definitely not  
Monte Carlo error.

Cheers,

Jarrod


Quoting Ruben Arslan <rubenarslan at gmail.com> on Thu, 28 Aug 2014  
22:44:47 +0200:

> Hi Jarrod,
>
> those two matched up quite well yes. I just completed another 20  
> chains, using more variable
> starting values. There's still two fixed effects  
> traitza_children:spouses  and :male which haven't converged
> according to multi-chain (gelman), but have according to geweke.
> The offending traces: http://imgur.com/Qm6Ovfr
> These specific effects aren't of interest to me, so if this doesn't  
> affect the rest of my estimates, I can be happy
> with this, but I can't conclude that, can I?
>
> I'm now also doing a run to see how it deals with the more intensely  
> zero-inflated data when including
> the unmarried.
>
> Thanks a lot for all that help,
>
> Ruben
>
>> gelman.diag(mcmclist)
> Potential scale reduction factors:
>
>                                            Point est. Upper C.I.
> (Intercept)                                      1.00       1.00
> traitza_children                                 1.40       1.65
> male                                             1.00       1.00
> spouses                                          1.00       1.00
> paternalage.mean                                 1.00       1.00
> paternalage.factor(25,30]                        1.00       1.00
> paternalage.factor(30,35]                        1.00       1.00
> paternalage.factor(35,40]                        1.00       1.00
> paternalage.factor(40,45]                        1.00       1.00
> paternalage.factor(45,50]                        1.00       1.00
> paternalage.factor(50,55]                        1.00       1.00
> paternalage.factor(55,90]                        1.00       1.00
> traitza_children:male                            1.33       1.54
> traitza_children:spouses                         2.21       2.83
> traitza_children:paternalage.mean                1.01       1.02
> traitza_children:paternalage.factor(25,30]       1.05       1.08
> traitza_children:paternalage.factor(30,35]       1.08       1.13
> traitza_children:paternalage.factor(35,40]       1.15       1.25
> traitza_children:paternalage.factor(40,45]       1.15       1.26
> traitza_children:paternalage.factor(45,50]       1.26       1.43
> traitza_children:paternalage.factor(50,55]       1.15       1.25
> traitza_children:paternalage.factor(55,90]       1.14       1.23
>
> Multivariate psrf
>
> 8.99
>
>> summary(mcmclist)
>
> Iterations = 100001:149951
> Thinning interval = 50
> Number of chains = 20
> Sample size per chain = 1000
>
> 1. Empirical mean and standard deviation for each variable,
>    plus standard error of the mean:
>
>                                                Mean      SD  Naive  
> SE Time-series SE
> (Intercept)                                 1.36326 0.04848  
> 0.0003428      0.0003542
> traitza_children                           -0.76679 0.28738  
> 0.0020321      0.0016682
> male                                        0.09980 0.01633  
> 0.0001155      0.0001222
> spouses                                     0.12333 0.01957  
> 0.0001384      0.0001414
> paternalage.mean                            0.07215 0.02194  
> 0.0001551      0.0001596
> paternalage.factor(25,30]                  -0.03381 0.04184  
> 0.0002959      0.0003066
> paternalage.factor(30,35]                  -0.08380 0.04270  
> 0.0003019      0.0003118
> paternalage.factor(35,40]                  -0.16502 0.04569  
> 0.0003231      0.0003289
> paternalage.factor(40,45]                  -0.16738 0.05090  
> 0.0003599      0.0003697
> paternalage.factor(45,50]                  -0.18383 0.05880  
> 0.0004158      0.0004242
> paternalage.factor(50,55]                  -0.18241 0.07277  
> 0.0005146      0.0005302
> paternalage.factor(55,90]                  -0.40612 0.09875  
> 0.0006983      0.0007467
> traitza_children:male                       0.12092 0.08223  
> 0.0005815      0.0004697
> traitza_children:spouses                    0.64881 0.21132  
> 0.0014942      0.0008511
> traitza_children:paternalage.mean          -0.02741 0.08550  
> 0.0006046      0.0006221
> traitza_children:paternalage.factor(25,30] -0.17296 0.18680  
> 0.0013209      0.0013750
> traitza_children:paternalage.factor(30,35] -0.19027 0.19267  
> 0.0013624      0.0013901
> traitza_children:paternalage.factor(35,40] -0.24911 0.21282  
> 0.0015049      0.0014391
> traitza_children:paternalage.factor(40,45] -0.29772 0.23403  
> 0.0016548      0.0015956
> traitza_children:paternalage.factor(45,50] -0.51782 0.28589  
> 0.0020215      0.0017602
> traitza_children:paternalage.factor(50,55] -0.46126 0.32064  
> 0.0022673      0.0021397
> traitza_children:paternalage.factor(55,90] -0.38612 0.41461  
> 0.0029317      0.0027396
>
> 2. Quantiles for each variable:
>
>                                                2.5%      25%       
> 50%      75%      97.5%
> (Intercept)                                 1.26883  1.33106   
> 1.36322  1.39575  1.4589722
> traitza_children                           -1.20696 -0.95751  
> -0.81076 -0.63308 -0.0365042
> male                                        0.06785  0.08878   
> 0.09970  0.11085  0.1320168
> spouses                                     0.08467  0.11030   
> 0.12343  0.13643  0.1617869
> paternalage.mean                            0.02950  0.05751   
> 0.07202  0.08683  0.1153881
> paternalage.factor(25,30]                  -0.11581 -0.06174  
> -0.03397 -0.00574  0.0473783
> paternalage.factor(30,35]                  -0.16656 -0.11250  
> -0.08358 -0.05519  0.0003065
> paternalage.factor(35,40]                  -0.25518 -0.19530  
> -0.16500 -0.13440 -0.0757366
> paternalage.factor(40,45]                  -0.26887 -0.20164  
> -0.16675 -0.13335 -0.0677407
> paternalage.factor(45,50]                  -0.30080 -0.22320  
> -0.18339 -0.14440 -0.0687967
> paternalage.factor(50,55]                  -0.32663 -0.23034  
> -0.18227 -0.13317 -0.0415547
> paternalage.factor(55,90]                  -0.60202 -0.47303  
> -0.40454 -0.33994 -0.2139128
> traitza_children:male                      -0.01083  0.06634   
> 0.11024  0.16109  0.3295892
> traitza_children:spouses                    0.37857  0.51072   
> 0.59398  0.71395  1.2127940
> traitza_children:paternalage.mean          -0.19138 -0.08250  
> -0.02985  0.02493  0.1468989
> traitza_children:paternalage.factor(25,30] -0.57457 -0.28481  
> -0.16489 -0.05151  0.1728148
> traitza_children:paternalage.factor(30,35] -0.61499 -0.30350  
> -0.17736 -0.06299  0.1555147
> traitza_children:paternalage.factor(35,40] -0.74251 -0.36752  
> -0.22966 -0.10777  0.1151897
> traitza_children:paternalage.factor(40,45] -0.84165 -0.42691  
> -0.27729 -0.14322  0.1032436
> traitza_children:paternalage.factor(45,50] -1.21782 -0.66568  
> -0.48420 -0.32873 -0.0476720
> traitza_children:paternalage.factor(50,55] -1.21327 -0.63623  
> -0.43432 -0.24957  0.0955360
> traitza_children:paternalage.factor(55,90] -1.33772 -0.62227  
> -0.35364 -0.11050  0.3361684
>
>> effectiveSize(mcmclist)
>                                (Intercept)                            
> traitza_children
>                                   18814.05                            
>         16359.33
>                                       male                            
>          spouses
>                                   18132.98                            
>         19547.05
>                           paternalage.mean                   
> paternalage.factor(25,30]
>                                   19238.72                            
>         18974.81
>                  paternalage.factor(30,35]                   
> paternalage.factor(35,40]
>                                   18874.33                            
>         19406.63
>                  paternalage.factor(40,45]                   
> paternalage.factor(45,50]
>                                   19075.18                            
>         19401.77
>                  paternalage.factor(50,55]                   
> paternalage.factor(55,90]
>                                   18960.11                            
>         17893.23
>                      traitza_children:male                    
> traitza_children:spouses
>                                   18545.55                            
>         14438.51
>          traitza_children:paternalage.mean  
> traitza_children:paternalage.factor(25,30]
>                                   18464.09                            
>         16943.43
> traitza_children:paternalage.factor(30,35]  
> traitza_children:paternalage.factor(35,40]
>                                   16827.44                            
>         17230.04
> traitza_children:paternalage.factor(40,45]  
> traitza_children:paternalage.factor(45,50]
>                                   17144.78                            
>         18191.67
> traitza_children:paternalage.factor(50,55]  
> traitza_children:paternalage.factor(55,90]
>                                   17466.60                            
>         18540.59
>
>
> ### current script:
>
> # bsub -q mpi -W 24:00 -n 21 -R np20 mpirun -H localhost -n 21 R  
> --slave -f "/usr/users/rarslan/rpqa/krmh_main/children.R"
> setwd("/usr/users/rarslan/rpqa/")
> library(doMPI)
> cl <- startMPIcluster(verbose=T,workdir="/usr/users/rarslan/rpqa/krmh_main/")
> registerDoMPI(cl)
> Children = foreach(i=1:clusterSize(cl),.options.mpi =  
> list(seed=1337) ) %dopar% {
> 	library(MCMCglmm);library(data.table)
>     setwd("/usr/users/rarslan/rpqa/krmh_main/")
> 	source("../1 - extraction functions.r")
>     load("../krmh1.rdata")
>
> 	krmh.1 = recenter.pat(na.omit(krmh.1[spouses>0, list(idParents,  
> children, male, spouses, paternalage)]))
>
> 	samples = 1000
> 	thin = 50; burnin = 100000
> 	nitt = samples * thin + burnin
>
> 	prior <- list(
> 		R=list(V=diag(2), nu=1.002, fix=2),
> 		G=list(G1=list(V=diag(2), nu=1, alpha.mu=c(0,0), alpha.V=diag(2)*1000))
> 	)
>
> 	start <- list(
> 		liab=c(rnorm( nrow(krmh.1)*2 )),
> 		R = list(R1 = rIW(diag(2), 10 )),
> 		G = list(G1 = rIW(diag(2), 10 ))
> 	)
>
> 	( m1 = MCMCglmm( children ~ trait * (male + spouses +  
> paternalage.mean + paternalage.factor),
> 						rcov=~idh(trait):units,
> 						random=~idh(trait):idParents,
> 						family="zapoisson",
> 						start = start,
> 						prior = prior,
> 						data=krmh.1,
> 						pr = F, saveX = F, saveZ = F,
> 						nitt=nitt,thin=thin,burnin=burnin)
> 	)
> 		m1$Residual$nrt<-2
> 	m1
> }
>
> save(Children,file = "Children.rdata")
> closeCluster(cl)
> mpi.quit()
>
> On 28 Aug 2014, at 20:59, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>
>> Hi,
>>
>> The posteriors for the two models look pretty close to me. Are the  
>> scale reduction factors really as high as previously reported?  
>> Before you had 1.83 for traitza_children:spouses, but the plot  
>> suggests that it should be close to 1?
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>>
>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Thu, 28 Aug 2014  
>> 19:59:16 +0200:
>>
>>> Sure! Thanks a lot.
>>> I am using ~idh(trait):units already, sorry for saying that  
>>> incorrectly in my last email.
>>> These models aren't the final thing, I will replace the  
>>> paternalage.factor variable
>>> with its linear equivalent if that seems defensible (does so far)  
>>> and in this model it seems
>>> okay to remove the za-effects for all predictors except spouses.
>>> So a final model would have fewer fixed effects. I also have  
>>> datasets of 200k+ and 5m+,
>>> but I'm learning MCMCglmm with this smaller one because my wrong  
>>> turns take less time.
>>>
>>> I've uploaded a comparison coef plot of two models:
>>> http://i.imgur.com/sHUfnmd.png
>>> m7 is with the default starting values, m1 is with the  
>>> specification I sent in my last email. I don't
>>> know if such differences are something to worry about.
>>>
>>> I don't know what qualifies as highly overdispersed, here's a plot  
>>> of the outcome for ever
>>> married people (slate=real data):
>>> http://imgur.com/14MywgZ
>>> here's with everybody born (incl. some stillborn etc.):
>>> http://imgur.com/knRGa1v
>>> I guess my approach (generating an overdispersed poisson with the  
>>> parameters from
>>> the data and checking if it has as excess zeroes) is not the best  
>>> way to diagnose zero-inflation,
>>> but especially in the second case it seems fairly clear-cut.
>>>
>>> Best regards,
>>>
>>> Ruben
>>>
>>>> summary(m1)
>>>
>>> Iterations = 50001:149951
>>> Thinning interval  = 50
>>> Sample size  = 2000
>>>
>>> DIC: 31249.73
>>>
>>> G-structure:  ~idh(trait):idParents
>>>
>>>                      post.mean  l-95% CI u-95% CI eff.samp
>>> children.idParents     0.006611 4.312e-08   0.0159    523.9
>>> za_children.idParents  0.193788 7.306e-02   0.3283    369.3
>>>
>>> R-structure:  ~idh(trait):units
>>>
>>>                  post.mean l-95% CI u-95% CI eff.samp
>>> children.units       0.1285   0.1118   0.1452    716.1
>>> za_children.units    0.9950   0.9950   0.9950      0.0
>>>
>>> Location effects: children ~ trait * (male + spouses +  
>>> paternalage.mean + paternalage.factor)
>>>
>>>                                            post.mean   l-95% CI    
>>> u-95% CI eff.samp  pMCMC
>>> (Intercept)                                 1.3413364  1.2402100   
>>> 1.4326099     1789 <5e-04 ***
>>> traitza_children                           -0.8362879 -1.2007980  
>>> -0.5016730     1669 <5e-04 ***
>>> male                                        0.0994902  0.0679050   
>>> 0.1297394     2000 <5e-04 ***
>>> spouses                                     0.1236033  0.0839000   
>>> 0.1624939     2000 <5e-04 ***
>>> paternalage.mean                            0.0533892  0.0119569   
>>> 0.0933960     2000  0.015 *
>>> paternalage.factor(25,30]                  -0.0275822 -0.1116421   
>>> 0.0537359     1842  0.515
>>> paternalage.factor(30,35]                  -0.0691025 -0.1463214   
>>> 0.0122393     1871  0.097 .
>>> paternalage.factor(35,40]                  -0.1419933 -0.2277379  
>>> -0.0574678     1845 <5e-04 ***
>>> paternalage.factor(40,45]                  -0.1364952 -0.2362714  
>>> -0.0451874     1835  0.007 **
>>> paternalage.factor(45,50]                  -0.1445342 -0.2591767  
>>> -0.0421178     1693  0.008 **
>>> paternalage.factor(50,55]                  -0.1302972 -0.2642965   
>>> 0.0077061     2000  0.064 .
>>> paternalage.factor(55,90]                  -0.3407879 -0.5168972  
>>> -0.1493652     1810 <5e-04 ***
>>> traitza_children:male                       0.0926888 -0.0147379   
>>> 0.2006142     1901  0.098 .
>>> traitza_children:spouses                    0.5531197  0.3870616   
>>> 0.7314289     1495 <5e-04 ***
>>> traitza_children:paternalage.mean           0.0051463 -0.1279396   
>>> 0.1460099     1617  0.960
>>> traitza_children:paternalage.factor(25,30] -0.1538957 -0.4445749   
>>> 0.1462955     1781  0.321
>>> traitza_children:paternalage.factor(30,35] -0.1747883 -0.4757851   
>>> 0.1162476     1998  0.261
>>> traitza_children:paternalage.factor(35,40] -0.2261843 -0.5464379   
>>> 0.0892582     1755  0.166
>>> traitza_children:paternalage.factor(40,45] -0.2807543 -0.6079678   
>>> 0.0650281     1721  0.100 .
>>> traitza_children:paternalage.factor(45,50] -0.4905843 -0.8649214  
>>> -0.1244174     1735  0.010 **
>>> traitza_children:paternalage.factor(50,55] -0.4648579 -0.9215759  
>>> -0.0002083     1687  0.054 .
>>> traitza_children:paternalage.factor(55,90] -0.3945406 -1.0230155   
>>> 0.2481568     1793  0.195
>>> ---
>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>
>>>> describe(krmh.1[spouses>0,])
>>>                    vars    n mean   sd median trimmed  mad   min    
>>> max range skew kurtosis   se
>>> children               2 6829 3.81 2.93   4.00    3.61 2.97  0.00  
>>> 16.00 16.00 0.47    -0.46 0.04
>>> male                   3 6829 0.46 0.50   0.00    0.45 0.00  0.00   
>>> 1.00  1.00 0.14    -1.98 0.01
>>> spouses                4 6829 1.14 0.38   1.00    1.03 0.00  1.00   
>>> 4.00  3.00 2.87     8.23 0.00
>>> paternalage            5 6829 3.65 0.80   3.57    3.60 0.80  1.83   
>>> 7.95  6.12 0.69     0.70 0.01
>>> paternalage_c          6 6829 0.00 0.80  -0.08   -0.05 0.80 -1.82   
>>> 4.30  6.12 0.69     0.70 0.01
>>> paternalage.mean       7 6829 0.00 0.68  -0.08   -0.05 0.59 -1.74   
>>> 4.30  6.04 0.95     1.97 0.01
>>> paternalage.diff       8 6829 0.00 0.42   0.00   -0.01 0.38 -1.51   
>>> 1.48  2.99 0.17     0.17 0.01
>>>
>>>> table(krmh.1$paternalage.factor)
>>>
>>> [0,25] (25,30] (30,35] (35,40] (40,45] (45,50] (50,55] (55,90]
>>>    309    1214    1683    1562    1039     623     269     130
>>>
>>> On 28 Aug 2014, at 19:05, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>>
>>>> Hi Ruben,
>>>>
>>>> It might be hard to detect (near) ECPs with so many fixed effects  
>>>> (can you post the model summary (and give us the mean and  
>>>> standard deviation of any continuous covariates)). Also, the  
>>>> complementary log-log link (which is the za specification) is  
>>>> non-symmetric and runs into problems outside the range -35 to 3.5  
>>>> so there may be a problem there, particularly if you use  
>>>> rcov=~trait:units and the Poisson part is highly over-dispersed.   
>>>> You could try rcov=~idh(trait):units and fix the non-identifiable  
>>>> za residual variance to something smaller than 1 (say 0.5)  - it  
>>>> will mix slower but it will reduce the chance of over/underflow.
>>>>
>>>> Cheers,
>>>>
>>>> Jarrod
>>>>
>>>>
>>>>
>>>>
>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Thu, 28 Aug 2014  
>>>> 18:45:30 +0200:
>>>>
>>>>> Hi Jarrod,
>>>>>
>>>>>> 1) it did not return an error with rcov = ~trait:units because  
>>>>>> you used R1=rpois(2,1)+1 and yet this specification only fits a  
>>>>>> single variance (not a 2x2 covariance matrix). R1=rpois(2,1)+1  
>>>>>> is a bit of a weird specification since it has to be integer. I  
>>>>>> would obtain starting values using rIW().
>>>>>
>>>>> I agree it's a weird specification, I was a bit lost and thought  
>>>>> I could get away with just putting some random numbers in the  
>>>>> starting value.
>>>>> I didn't do R1=rpois(2,1)+1 though, I did R1=diag(rpois(2,1)+1),  
>>>>> so I got a 2x2 matrix, but yes, bound to be integer.
>>>>> I didn't know starting values should come from a conjugate  
>>>>> distribution, though that probably means I didn't think about it  
>>>>> much.
>>>>>
>>>>> I'm now doing
>>>>> start <- list(
>>>>> 	liab=c(rnorm( nrow(krmh.1)*2 )),
>>>>> 	R = list(R1 = rIW( diag(2), nrow(krmh.1)) ),
>>>>> 	G = list(G1 = rIW( diag(2), nrow(krmh.1)) )
>>>>> )
>>>>>
>>>>> Is this what you had in mind?
>>>>> I am especially unsure if I am supposed to use such a low  
>>>>> sampling variability (my sample size is probably not even  
>>>>> relevant for the starting values) and if I should start from  
>>>>> diag(2).
>>>>>
>>>>> And, I am still happily confused that this specification still  
>>>>> doesn't lead to errors with respect to rcov = ~trait:units .  
>>>>> Does this mean I'm doing it wrong?
>>>>>
>>>>>> 3) a) how many effective samples do you have for each  
>>>>>> parameter? and b) are you getting extreme category  
>>>>>> problems/numerical issues? If you store the latent variables  
>>>>>> (pl=TUE) what is their range for the Zi/za part?
>>>>>
>>>>> My parallel run using the above starting values isn't finished yet.
>>>>> a) After applying the above starting values I get, for the  
>>>>> location effects 1600-2000 samples for a 2000 sample chain (with  
>>>>> thin set to 50). G and R-structure are from 369  
>>>>> (za_children.idParents) to 716 (and 0 for the fixed part).
>>>>> Effective sample sizes were similar for my run using the  
>>>>> starting values for G/R that I drew from rpois, and using 40  
>>>>> chains I of course get
>>>>> b) I don't think I am getting extreme categories. I would  
>>>>> probably be getting extreme categories if I included the  
>>>>> forever-alones (they almost never have children), but this way no.
>>>>> I wasn't sure how to examine the range of the latents separately  
>>>>> for the za part, but for a single chain it looks okay:
>>>>>> quantile(as.numeric(m1$Liab),probs = c(0,0.01,0,0.99,1))
>>>>>      0%        1%        0%       99%      100%
>>>>> -4.934111 -1.290728 -4.934111  3.389847  7.484206
>>>>>
>>>>> Well, all considered now that I use the above starting value  
>>>>> specification I get slightly different estimates for all  
>>>>> za-coefficients. Nothing major, but still leading me to
>>>>> think my estimates aren't exactly independent of the starting  
>>>>> values I use. I'll see what the parallel run yields.
>>>>>
>>>>> Thanks a lot,
>>>>>
>>>>> Ruben
>>>>>
>>>>>>
>>>>>> Cheers,
>>>>>>
>>>>>> Jarrod
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Wed, 27 Aug  
>>>>>> 2014 19:23:42 +0200:
>>>>>>
>>>>>>> Hi Jarrod,
>>>>>>>
>>>>>>> thanks again. I was able to get it running with your advice.
>>>>>>> Some points of confusion remain:
>>>>>>>
>>>>>>> - You wrote that zi/za models would return an error with rcov  
>>>>>>> = ~trait:units + starting values. This did not happen in my  
>>>>>>> case, so I didn't build MCMCglmm myself with your suggested  
>>>>>>> edits. Also, have you considered putting your own MCMCglmm  
>>>>>>> repo on Github? Your users would be able to install  
>>>>>>> pre-releases and I'd think you'd get some time-saving pull  
>>>>>>> requests too.
>>>>>>> - In my attempts to get my models to run properly, I messed up  
>>>>>>> a prior and did not use fix=2 in my prior specification for my  
>>>>>>> za models. This led to crappy convergence, it's much better  
>>>>>>> now and for some of my simpler models I think I won't need  
>>>>>>> parallel chains. I'm reminded of Gelman's folk theorem of  
>>>>>>> statistical computing.
>>>>>>> - I followed your advice, but of course I could not set the  
>>>>>>> true values as starting values, but wanted to set random, bad  
>>>>>>> starting values. I pasted below what I arrived at, I'm  
>>>>>>> especially unsure whether I specified the starting values for  
>>>>>>> G and R properly (I think not).
>>>>>>> 	start <- list(
>>>>>>> 		liab=c(rnorm( nrow(krmh.1)*2 )),
>>>>>>> 		R = list(R1 = diag(rpois(2, 1)+1)),
>>>>>>> 		G = list(G1 = diag(rpois(2, 1)+1))
>>>>>>> 	)
>>>>>>>
>>>>>>>
>>>>>>> However, even though I may not need multiple chains for some  
>>>>>>> of my simpler models, I've now run into conflicting  
>>>>>>> diagnostics. The geweke.diag for each chain (and examination  
>>>>>>> of the traces) gives
>>>>>>> satisfactory diagnostics. Comparing multiple chains using  
>>>>>>> gelman.diag, however, leads to one bad guy, namely the  
>>>>>>> traitza_children:spouses interaction.
>>>>>>> I think this implies that I've got some starting value  
>>>>>>> dependence for this parameter, that won't be easily rectified  
>>>>>>> through longer burnin?
>>>>>>> Do you have any ideas how to rectify this?
>>>>>>> I am currently doing sequential analyses on episodes of  
>>>>>>> selection and in historical human data only those who marry  
>>>>>>> have a chance at having kids. I exclude the unmarried
>>>>>>> from my sample where I predict number of children, because I  
>>>>>>> examine that in a previous model and the zero-inflation (65%  
>>>>>>> zeros, median w/o unmarried = 4) when including the unmarried  
>>>>>>> is so excessive.
>>>>>>> Number of spouses is easily the strongest predictor in the  
>>>>>>> model, but only serves as a covariate here. Since my other  
>>>>>>> estimates are stable across chains and runs and agree well  
>>>>>>> across models and with theory, I'm
>>>>>>> inclined to shrug this off. But probably I shouldn't ignore  
>>>>>>> this sign of non-convergence?
>>>>>>>
>>>>>>>> gelman.diag(mcmc_1)
>>>>>>> Potential scale reduction factors:
>>>>>>>
>>>>>>>                                         Point est. Upper C.I.
>>>>>>> (Intercept)                                      1.00       1.00
>>>>>>> traitza_children                                 1.27       1.39
>>>>>>> male                                             1.00       1.00
>>>>>>> spouses                                          1.00       1.00
>>>>>>> paternalage.mean                                 1.00       1.00
>>>>>>> paternalage.factor(25,30]                        1.00       1.00
>>>>>>> paternalage.factor(30,35]                        1.00       1.00
>>>>>>> paternalage.factor(35,40]                        1.00       1.00
>>>>>>> paternalage.factor(40,45]                        1.00       1.00
>>>>>>> paternalage.factor(45,50]                        1.00       1.00
>>>>>>> paternalage.factor(50,55]                        1.00       1.00
>>>>>>> paternalage.factor(55,90]                        1.00       1.00
>>>>>>> traitza_children:male                            1.22       1.32
>>>>>>> traitza_children:spouses                         1.83       2.13
>>>>>>> traitza_children:paternalage.mean                1.02       1.02
>>>>>>> traitza_children:paternalage.factor(25,30]       1.03       1.05
>>>>>>> traitza_children:paternalage.factor(30,35]       1.05       1.08
>>>>>>> traitza_children:paternalage.factor(35,40]       1.10       1.15
>>>>>>> traitza_children:paternalage.factor(40,45]       1.12       1.17
>>>>>>> traitza_children:paternalage.factor(45,50]       1.19       1.28
>>>>>>> traitza_children:paternalage.factor(50,55]       1.12       1.18
>>>>>>> traitza_children:paternalage.factor(55,90]       1.11       1.17
>>>>>>>
>>>>>>> Multivariate psrf
>>>>>>>
>>>>>>> 7.27
>>>>>>>
>>>>>>>
>>>>>>> Best regards,
>>>>>>>
>>>>>>> Ruben
>>>>>>>
>>>>>>>
>>>>>>> On 26 Aug 2014, at 13:04, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>>>>>>
>>>>>>>> Hi Ruben,
>>>>>>>>
>>>>>>>> There are 400 liabilities in a zapoisson model (2 per datum).  
>>>>>>>> This code should work:
>>>>>>>>
>>>>>>>> g <-sample(letters[1:10], size = 200, replace = T)
>>>>>>>> pred <- rnorm(200)
>>>>>>>>
>>>>>>>> l1<-rnorm(200, -1, sqrt(1))
>>>>>>>> l2<-rnorm(200, -1, sqrt(1))
>>>>>>>>
>>>>>>>> y<-VGAM::rzapois(200, exp(l1), exp(-exp(l2)))
>>>>>>>>
>>>>>>>> # generate zero-altered data with an intercept of -1 (because  
>>>>>>>> the intercept and variance are the same for both processes  
>>>>>>>> this is just standard Poisson)
>>>>>>>>
>>>>>>>> dat<-data.frame(y=y, g = g, pred = pred)
>>>>>>>>
>>>>>>>>
>>>>>>>> start.1<-list(liab=c(l1,l2), R = list(R1=diag(2)), G=list(G1=diag(2)))
>>>>>>>> prior.1<-list(R=list(V=diag(2), nu=1.002, fix=2),  
>>>>>>>> G=list(G1=list(V=diag(2), nu=2, alpha.mu=c(0,0),  
>>>>>>>> alpha.V=diag(2)*1000)))
>>>>>>>>
>>>>>>>> m1<-MCMCglmm(y~trait + pred:trait, random=~us(trait):g,  
>>>>>>>> family="zapoisson",rcov=~idh(trait):units, data=dat,  
>>>>>>>> prior=prior.1, start= start.1)
>>>>>>>>
>>>>>>>> However, there are 2 bugs in the current version of MCMCglmm  
>>>>>>>> that return an error message when the documentation implies  
>>>>>>>> it should be fine:
>>>>>>>>
>>>>>>>> a) it should be possible to have R=diag(2) rather than R =  
>>>>>>>> list(R1=diag(2)). This bug cropped up when I implemented  
>>>>>>>> block-diagonal R structures. It can be fixed by inserting:
>>>>>>>>
>>>>>>>>       if(!is.list(start$R)){
>>>>>>>>          start$R<-list(R1=start$R)
>>>>>>>>       }
>>>>>>>>
>>>>>>>> on L514 of MCMCglmm.R below
>>>>>>>>
>>>>>>>>       if(!is.list(prior$R[[1]])){
>>>>>>>>          prior$R<-list(R1=prior$R)
>>>>>>>>       }
>>>>>>>>
>>>>>>>> b) rcov=~trait:units models for zi/za models will return an  
>>>>>>>> error when passing starting values. To fix this insert
>>>>>>>>
>>>>>>>>      if(diagR==3){
>>>>>>>>        if(dim(start)[1]!=1){
>>>>>>>>          stop("V is the wrong dimension for some  
>>>>>>>> strart$G/start$R elements")
>>>>>>>>        }
>>>>>>>>        start<-diag(sum(nfl))*start[1]
>>>>>>>>      }
>>>>>>>>
>>>>>>>> on L90 of priorfromat.R below
>>>>>>>>
>>>>>>>>      if(is.matrix(start)==FALSE){
>>>>>>>>        start<-as.matrix(start)
>>>>>>>>      }
>>>>>>>>
>>>>>>>> I will put these in the new version.
>>>>>>>>
>>>>>>>> Cheers,
>>>>>>>>
>>>>>>>> Jarrod
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25 Aug  
>>>>>>>> 2014 21:52:30 +0200:
>>>>>>>>
>>>>>>>>> Hi Jarrod,
>>>>>>>>>
>>>>>>>>> thanks for these pointers.
>>>>>>>>>
>>>>>>>>>>> You will need to provide over-dispersed starting values  
>>>>>>>>>>> for multiple-chain convergence diagnostics to be useful  
>>>>>>>>>>> (GLMM are so simple I am generally happy if the output of  
>>>>>>>>>>> a single run looks reasonable).
>>>>>>>>>
>>>>>>>>> Oh, I would be happy with single chains, but since  
>>>>>>>>> computation would take weeks this way, I wanted to  
>>>>>>>>> parallelise and I would use the multi-chain convergence as a  
>>>>>>>>> criterion that my parallelisation was proper
>>>>>>>>> and is as informative as a single long chain. There don't  
>>>>>>>>> seem to be any such checks built-in ? I was analysing my 40  
>>>>>>>>> chains for a bit longer than I like to admit until I noticed  
>>>>>>>>> they were identical (effectiveSize
>>>>>>>>> and summary.mcmc.list did not yell at me for this).
>>>>>>>>>
>>>>>>>>>>> # use some very bad starting values
>>>>>>>>> I get that these values are bad, but that is the goal for my  
>>>>>>>>> multi-chain aim, right?
>>>>>>>>>
>>>>>>>>> I can apply this to my zero-truncated model, but am again  
>>>>>>>>> getting stuck with the zero-altered one.
>>>>>>>>> Maybe I need only specify the Liab values for this?
>>>>>>>>> At least I'm getting nowhere with specifying R and G  
>>>>>>>>> starting values here. When I got an error, I always
>>>>>>>>> went to the MCMCglmm source to understand why the checks  
>>>>>>>>> failed, but I didn't always understand
>>>>>>>>> what was being checked and couldn't get it to work.
>>>>>>>>>
>>>>>>>>> Here's a failing example:
>>>>>>>>>
>>>>>>>>> l<-rnorm(200, -1, sqrt(1))
>>>>>>>>> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
>>>>>>>>> g = sample(letters[1:10], size = 200, replace = T)
>>>>>>>>> pred = rnorm(200)
>>>>>>>>> y<-rpois(200,exp(l)-t)
>>>>>>>>> y[1:40] = 0
>>>>>>>>> # generate zero-altered data with an intercept of -1
>>>>>>>>>
>>>>>>>>> dat<-data.frame(y=y, g = g, pred = pred)
>>>>>>>>> set.seed(1)
>>>>>>>>> start_true = list(Liab=l, R = 1, G = 1 )
>>>>>>>>> m1<-MCMCglmm(y~1 + pred,random = ~ g,  
>>>>>>>>> family="zapoisson",rcov=~us(trait):units, data=dat, start=  
>>>>>>>>> start_true)
>>>>>>>>>
>>>>>>>>> # use true latent variable as starting values
>>>>>>>>> set.seed(1)
>>>>>>>>> # use some very bad starting values
>>>>>>>>> start_rand = list(Liab=rnorm(200), R = rpois(1, 1)+1, G =  
>>>>>>>>> rpois(1, 1)+1 )
>>>>>>>>> m2<-MCMCglmm(y~1 + pred,random = ~ g,rcov=~us(trait):units,   
>>>>>>>>> family="zapoisson", data=dat, start = start_rand)
>>>>>>>>>
>>>>>>>>> Best,
>>>>>>>>>
>>>>>>>>> Ruben
>>>>>>>>>
>>>>>>>>> On 25 Aug 2014, at 18:29, Jarrod Hadfield  
>>>>>>>>> <j.hadfield at ed.ac.uk> wrote:
>>>>>>>>>
>>>>>>>>>> Hi Ruben,
>>>>>>>>>>
>>>>>>>>>> Sorry  - I was wrong when I said that everything is Gibbs  
>>>>>>>>>> sampled conditional on the latent variables. The location  
>>>>>>>>>> effects (fixed and random effects) are also sampled  
>>>>>>>>>> conditional on the (co)variance components so you should  
>>>>>>>>>> add them to the starting values. In the case where the true  
>>>>>>>>>> values are used:
>>>>>>>>>>
>>>>>>>>>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat,  
>>>>>>>>>> start=list(Liab=l,R=1))
>>>>>>>>>>
>>>>>>>>>> Cheers,
>>>>>>>>>>
>>>>>>>>>> Jarrod
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> Quoting Jarrod Hadfield <j.hadfield at ed.ac.uk> on Mon, 25  
>>>>>>>>>> Aug 2014 17:14:14 +0100:
>>>>>>>>>>
>>>>>>>>>>> Hi Ruben,
>>>>>>>>>>>
>>>>>>>>>>> You will need to provide over-dispersed starting values  
>>>>>>>>>>> for multiple-chain convergence diagnostics to be useful  
>>>>>>>>>>> (GLMM are so simple I am generally happy if the output of  
>>>>>>>>>>> a single run looks reasonable).
>>>>>>>>>>>
>>>>>>>>>>> With non-Gaussian data everything is Gibbs sampled  
>>>>>>>>>>> conditional on the latent variables, so you only need to  
>>>>>>>>>>> pass them:
>>>>>>>>>>>
>>>>>>>>>>> l<-rnorm(200, -1, sqrt(1))
>>>>>>>>>>> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
>>>>>>>>>>> y<-rpois(200,exp(l)-t)+1
>>>>>>>>>>> # generate zero-truncated data with an intercept of -1
>>>>>>>>>>>
>>>>>>>>>>> dat<-data.frame(y=y)
>>>>>>>>>>> set.seed(1)
>>>>>>>>>>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat, start=list(Liab=l))
>>>>>>>>>>> # use true latent variable as starting values
>>>>>>>>>>> set.seed(1)
>>>>>>>>>>> m2<-MCMCglmm(y~1, family="ztpoisson", data=dat,  
>>>>>>>>>>> start=list(Liab=rnorm(200)))
>>>>>>>>>>> # use some very bad starting values
>>>>>>>>>>>
>>>>>>>>>>> plot(mcmc.list(m1$Sol, m2$Sol))
>>>>>>>>>>> # not identical despite the same seed because of different  
>>>>>>>>>>> starting values but clearly sampling the same posterior  
>>>>>>>>>>> distribution:
>>>>>>>>>>>
>>>>>>>>>>> gelman.diag(mcmc.list(m1$Sol, m2$Sol))
>>>>>>>>>>>
>>>>>>>>>>> Cheers,
>>>>>>>>>>>
>>>>>>>>>>> Jarrod
>>>>>>>>>>>
>>>>>>>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25  
>>>>>>>>>>> Aug 2014 18:00:08 +0200:
>>>>>>>>>>>
>>>>>>>>>>>> Dear Jarrod,
>>>>>>>>>>>>
>>>>>>>>>>>> thanks for the quick reply. Please, don't waste time  
>>>>>>>>>>>> looking into doMPI ? I am happy that I
>>>>>>>>>>>> get the expected result, when I specify that reproducible  
>>>>>>>>>>>> seed, whyever that may be.
>>>>>>>>>>>> I'm pretty sure that is the deciding factor, because I  
>>>>>>>>>>>> tested it explicitly, I just have no idea
>>>>>>>>>>>> how/why it interacts with the choice of family.
>>>>>>>>>>>>
>>>>>>>>>>>> That said, is setting up different RNG streams for my  
>>>>>>>>>>>> workers (now that it works) __sufficient__
>>>>>>>>>>>> so that I get independent chains and can use  
>>>>>>>>>>>> gelman.diag() for convergence diagnostics?
>>>>>>>>>>>> Or should I still tinker with the starting values myself?
>>>>>>>>>>>> I've never found a worked example of supplying starting  
>>>>>>>>>>>> values and am thus a bit lost.
>>>>>>>>>>>>
>>>>>>>>>>>> Sorry for sending further questions, I hope someone else  
>>>>>>>>>>>> takes pity while
>>>>>>>>>>>> you're busy with lectures.
>>>>>>>>>>>>
>>>>>>>>>>>> Best wishes
>>>>>>>>>>>>
>>>>>>>>>>>> Ruben
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>> On 25 Aug 2014, at 17:29, Jarrod Hadfield  
>>>>>>>>>>>> <j.hadfield at ed.ac.uk> wrote:
>>>>>>>>>>>>
>>>>>>>>>>>>> Hi Ruben,
>>>>>>>>>>>>>
>>>>>>>>>>>>> I do not think the issue is with the starting values,  
>>>>>>>>>>>>> because even if the same starting values were used the  
>>>>>>>>>>>>> chains would still differ because of the randomness in  
>>>>>>>>>>>>> the Markov Chain (if I interpret your `identical' test  
>>>>>>>>>>>>> correctly). This just involves a call to GetRNGstate()  
>>>>>>>>>>>>> in the C++ code (L 871 ofMCMCglmm.cc) so I think for  
>>>>>>>>>>>>> some reason doMPI/foreach is not doing what you expect.  
>>>>>>>>>>>>> I am not familiar with doMPI and am in the middle of  
>>>>>>>>>>>>> writing lectures so haven't got time to look into it  
>>>>>>>>>>>>> carefully. Outside of the context of doMPI I get the  
>>>>>>>>>>>>> behaviour I expect:
>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>> l<-rnorm(200, -1, sqrt(1))
>>>>>>>>>>>>> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
>>>>>>>>>>>>> y<-rpois(200,exp(l)-t)+1
>>>>>>>>>>>>> # generate zero-truncated data with an intercept of -1
>>>>>>>>>>>>>
>>>>>>>>>>>>> dat<-data.frame(y=y)
>>>>>>>>>>>>> set.seed(1)
>>>>>>>>>>>>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>>>>>>>>>>> set.seed(2)
>>>>>>>>>>>>> m2<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>>>>>>>>>>> set.seed(2)
>>>>>>>>>>>>> m3<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>>>>>>>>>>>
>>>>>>>>>>>>> plot(mcmc.list(m1$Sol, m2$Sol))
>>>>>>>>>>>>> # different, as expected
>>>>>>>>>>>>> plot(mcmc.list(m2$Sol, m3$Sol))
>>>>>>>>>>>>> # the same, as expected
>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25  
>>>>>>>>>>>>> Aug 2014 16:58:06 +0200:
>>>>>>>>>>>>>
>>>>>>>>>>>>>> Dear list,
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> sorry for bumping my old post, I hope to elicit a  
>>>>>>>>>>>>>> response with a more focused question:
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> When does MCMCglmm automatically start from different  
>>>>>>>>>>>>>> values when using doMPI/foreach?
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> I have done some tests with models of varying  
>>>>>>>>>>>>>> complexity. For example, the script in my last
>>>>>>>>>>>>>> post (using "zapoisson") yielded 40 identical chains:
>>>>>>>>>>>>>>> identical(mcmclist[1], mcmclist[30])
>>>>>>>>>>>>>> TRUE
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> A simpler (?) model (using "ztpoisson" and no specified  
>>>>>>>>>>>>>> prior), however, yielded different chains
>>>>>>>>>>>>>> and I could use them to calculate gelman.diag()
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> Changing my script to the version below, i.e. seeding  
>>>>>>>>>>>>>> foreach using .options.mpi=list( seed= 1337)
>>>>>>>>>>>>>> so as to make RNGstreams reproducible (or so I   
>>>>>>>>>>>>>> thought), led to different chains even for the
>>>>>>>>>>>>>> "zapoisson" model.
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> In no case have I (successfully) tried to supplant the  
>>>>>>>>>>>>>> default of MCMCglmm's "start" argument.
>>>>>>>>>>>>>> Is starting my models from different RNGsubstreams  
>>>>>>>>>>>>>> inadequate compared to manipulating
>>>>>>>>>>>>>> the start argument explicitly? If so, is there any  
>>>>>>>>>>>>>> worked example of explicit starting value manipulation
>>>>>>>>>>>>>> in parallel computation?
>>>>>>>>>>>>>> I've browsed the MCMCglmm source to understand how the  
>>>>>>>>>>>>>> default starting values are generated,
>>>>>>>>>>>>>> but didn't find any differences with respect to RNG for  
>>>>>>>>>>>>>> the two families "ztpoisson" and "zapoisson"
>>>>>>>>>>>>>> (granted, I did not dig very deep).
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> Best regards,
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> Ruben Arslan
>>>>>>>>>>>>>>
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> # bsub -q mpi -W 12:00 -n 41 -R np20 mpirun -H  
>>>>>>>>>>>>>> localhost -n 41 R --slave -f  
>>>>>>>>>>>>>> "/usr/users/rarslan/rpqa/rpqa_main/rpqa_children_parallel.R"
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> library(doMPI)
>>>>>>>>>>>>>> cl <-  
>>>>>>>>>>>>>> startMPIcluster(verbose=T,workdir="/usr/users/rarslan/rpqa/rpqa_main/")
>>>>>>>>>>>>>> registerDoMPI(cl)
>>>>>>>>>>>>>> Children_mcmc1 =  
>>>>>>>>>>>>>> foreach(i=1:clusterSize(cl),.options.mpi =  
>>>>>>>>>>>>>> list(seed=1337) ) %dopar% {
>>>>>>>>>>>>>> 	library(MCMCglmm);library(data.table)
>>>>>>>>>>>>>> 	load("/usr/users/rarslan/rpqa/rpqa1.rdata")
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> 	nitt = 130000; thin = 100; burnin = 30000
>>>>>>>>>>>>>> 	prior.m5d.2 = list(
>>>>>>>>>>>>>> 		R = list(V = diag(c(1,1)), nu = 0.002),
>>>>>>>>>>>>>> 		G=list(list(V=diag(c(1,1e-6)),nu=0.002))
>>>>>>>>>>>>>> 	)
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> 	rpqa.1 = na.omit(rpqa.1[spouses>0, list(idParents,  
>>>>>>>>>>>>>> children, male, urban, spouses, paternalage.mean,  
>>>>>>>>>>>>>> paternalage.factor)])
>>>>>>>>>>>>>> 	(m1 = MCMCglmm( children ~ trait * (male + urban +  
>>>>>>>>>>>>>> spouses + paternalage.mean + paternalage.factor),
>>>>>>>>>>>>>> 						rcov=~us(trait):units,
>>>>>>>>>>>>>> 						random=~us(trait):idParents,
>>>>>>>>>>>>>> 						family="zapoisson",
>>>>>>>>>>>>>> 						prior = prior.m5d.2,
>>>>>>>>>>>>>> 						data=rpqa.1,
>>>>>>>>>>>>>> 						pr = F, saveX = F, saveZ = F,
>>>>>>>>>>>>>> 						nitt=nitt,thin=thin,burnin=burnin))
>>>>>>>>>>>>>> }
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> library(coda)
>>>>>>>>>>>>>> mcmclist =  
>>>>>>>>>>>>>> mcmc.list(lapply(Children_mcmc1,FUN=function(x) {  
>>>>>>>>>>>>>> x$Sol}))
>>>>>>>>>>>>>> save(Children_mcmc1,mcmclist, file =  
>>>>>>>>>>>>>> "/usr/users/rarslan/rpqa/rpqa_main/rpqa_mcmc_kids_za.rdata")
>>>>>>>>>>>>>> closeCluster(cl)
>>>>>>>>>>>>>> mpi.quit()
>>>>>>>>>>>>>>
>>>>>>>>>>>>>>
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> On 04 Aug 2014, at 20:25, Ruben Arslan  
>>>>>>>>>>>>>> <rubenarslan at gmail.com> wrote:
>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> Dear list,
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> would someone be willing to share her or his efforts  
>>>>>>>>>>>>>>> in parallelising a MCMCglmm analysis?
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> I had something viable using harvestr that seemed to  
>>>>>>>>>>>>>>> properly initialise
>>>>>>>>>>>>>>> the starting values from different random number  
>>>>>>>>>>>>>>> streams (which is desirable,
>>>>>>>>>>>>>>> as far as I could find out), but I ended up being  
>>>>>>>>>>>>>>> unable to use harvestr, because
>>>>>>>>>>>>>>> it uses an old version of plyr, where parallelisation  
>>>>>>>>>>>>>>> works only for multicore, not for
>>>>>>>>>>>>>>> MPI.
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> I pasted my working version, that does not do anything  
>>>>>>>>>>>>>>> about starting values or RNG
>>>>>>>>>>>>>>> at the end of this email. I can try to fumble further  
>>>>>>>>>>>>>>> in the dark or try to update harvestr,
>>>>>>>>>>>>>>> but maybe someone has gone through all this already.
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> I'd also appreciate any tips for elegantly  
>>>>>>>>>>>>>>> post-processing such parallel data, as some of my usual
>>>>>>>>>>>>>>> extraction functions and routines are hampered by the  
>>>>>>>>>>>>>>> fact that some coda functions
>>>>>>>>>>>>>>> do not aggregate results over chains. (What I get from  
>>>>>>>>>>>>>>> a single-chain summary in MCMCglmm
>>>>>>>>>>>>>>> is a bit more comprehensive, than what I managed to  
>>>>>>>>>>>>>>> cobble together with my own extraction
>>>>>>>>>>>>>>> functions).
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> The reason I'm parallelising my analyses is that I'm  
>>>>>>>>>>>>>>> having trouble getting a good effective
>>>>>>>>>>>>>>> sample size for any parameter having to do with the  
>>>>>>>>>>>>>>> many zeroes in my data.
>>>>>>>>>>>>>>> Any pointers are very appreciated, I'm quite  
>>>>>>>>>>>>>>> inexperienced with MCMCglmm.
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> Best wishes
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> Ruben
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> # bsub -q mpi-short -W 2:00 -n 42 -R np20 mpirun -H  
>>>>>>>>>>>>>>> localhost -n 41 R --slave -f  
>>>>>>>>>>>>>>> "rpqa/rpqa_main/rpqa_children_parallel.r"
>>>>>>>>>>>>>>> library(doMPI)
>>>>>>>>>>>>>>> cl <- startMPIcluster()
>>>>>>>>>>>>>>> registerDoMPI(cl)
>>>>>>>>>>>>>>> Children_mcmc1 = foreach(i=1:40) %dopar% {
>>>>>>>>>>>>>>> 	library(MCMCglmm)
>>>>>>>>>>>>>>> 	load("rpqa1.rdata")
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> 	nitt = 40000; thin = 100; burnin = 10000
>>>>>>>>>>>>>>> 	prior = list(
>>>>>>>>>>>>>>> 		R = list(V = diag(c(1,1)), nu = 0.002),
>>>>>>>>>>>>>>> 		G=list(list(V=diag(c(1,1e-6)),nu=0.002))
>>>>>>>>>>>>>>> 	)
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> 	MCMCglmm( children ~ trait -1 +  
>>>>>>>>>>>>>>> at.level(trait,1):male + at.level(trait,1):urban +  
>>>>>>>>>>>>>>> at.level(trait,1):spouses +  
>>>>>>>>>>>>>>> at.level(trait,1):paternalage.mean +  
>>>>>>>>>>>>>>> at.level(trait,1):paternalage.factor,
>>>>>>>>>>>>>>> 		rcov=~us(trait):units,
>>>>>>>>>>>>>>> 		random=~us(trait):idParents,
>>>>>>>>>>>>>>> 		family="zapoisson",
>>>>>>>>>>>>>>> 		prior = prior,
>>>>>>>>>>>>>>> 		data=rpqa.1,
>>>>>>>>>>>>>>> 		pr = F, saveX = T, saveZ = T,
>>>>>>>>>>>>>>> 		nitt=nitt,thin=thin,burnin=burnin)
>>>>>>>>>>>>>>> }
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> library(coda)
>>>>>>>>>>>>>>> mcmclist =  
>>>>>>>>>>>>>>> mcmc.list(lapply(Children_mcmc1,FUN=function(x) {  
>>>>>>>>>>>>>>> x$Sol}))
>>>>>>>>>>>>>>> save(Children_mcmc1,mcmclist, file = "rpqa_mcmc_kids_za.rdata")
>>>>>>>>>>>>>>> closeCluster(cl)
>>>>>>>>>>>>>>> mpi.quit()
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> --
>>>>>>>>>>>>>>> Ruben C. Arslan
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> Georg August University G?ttingen
>>>>>>>>>>>>>>> Biological Personality Psychology and Psychological Assessment
>>>>>>>>>>>>>>> Georg Elias M?ller Institute of Psychology
>>>>>>>>>>>>>>> Go?lerstr. 14
>>>>>>>>>>>>>>> 37073 G?ttingen
>>>>>>>>>>>>>>> Germany
>>>>>>>>>>>>>>> Tel.: +49 551 3920704
>>>>>>>>>>>>>>> https://psych.uni-goettingen.de/en/biopers/team/arslan
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> 	[[alternative HTML version deleted]]
>>>>>>>>>>>>>>
>>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>> --
>>>>>>>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>>>>>>>> Scotland, with registration number SC005336.
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>> --
>>>>>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>>>>>> Scotland, with registration number SC005336.
>>>>>>>>>>>
>>>>>>>>>>> _______________________________________________
>>>>>>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> --
>>>>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>>>>> Scotland, with registration number SC005336.
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> --
>>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>>> Scotland, with registration number SC005336.
>>>>>>>>
>>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> --
>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>> Scotland, with registration number SC005336.
>>>>>>
>>>>>>
>>>>>
>>>>>
>>>>>
>>>>
>>>>
>>>>
>>>> --
>>>> The University of Edinburgh is a charitable body, registered in
>>>> Scotland, with registration number SC005336.
>>>>
>>>>
>>>
>>>
>>
>>
>> --
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>>
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From j.hadfield at ed.ac.uk  Fri Aug 29 09:13:33 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 29 Aug 2014 08:13:33 +0100
Subject: [R-sig-ME] parallel MCMCglmm, RNGstreams,
 starting values & priors
In-Reply-To: <20140829080442.1833246y8pj3itq8@www.staffmail.ed.ac.uk>
References: <4CD76FE1-D3F5-4980-9122-B0AC0D44FF81@gmail.com>
	<0E12EB43-72BC-42AC-9E74-9DF53DB42217@gmail.com>
	<20140825162907.10475jpywlu1wzs4@www.staffmail.ed.ac.uk>
	<0A463095-8656-49B7-9619-E557DD449E21@gmail.com>
	<20140825171414.10872gnlopk1we68@www.staffmail.ed.ac.uk>
	<20140825172936.15916weehiwjyc08@www.staffmail.ed.ac.uk>
	<8D35B834-0D31-486A-B5FB-0F279761FDB2@gmail.com>
	<49D60399-6902-45AC-80A9-9F3C35532228@gmail.com>
	<20140826120434.14613hxqhgwbhq80@www.staffmail.ed.ac.uk>
	<8557AE32-AFC9-4FD2-9C88-2D118B484637@gmail.com>
	<20140827183959.18662zc6hw5jj20w@www.staffmail.ed.ac.uk>
	<2D00600E-5287-4FE1-B605-82C0CBA286ED@gmail.com>
	<20140828180551.74212a0xoeoihn6s@www.staffmail.ed.ac.uk>
	<BBB5F7E3-75FE-4BA3-82B4-49DAA64873A4@gmail.com>
	<20140828195957.68171hjra56vrrr4@www.staffmail.ed.ac.uk>
	<E5B149F2-7773-4E2D-854C-3275A352A245@gmail.com>
	<20140829080442.1833246y8pj3itq8@www.staffmail.ed.ac.uk>
Message-ID: <20140829081333.16792k7qrimekagw@www.staffmail.ed.ac.uk>

Hi Ruben,

Actually I might know what it is. When you sample different starting  
values do you inadvertently sample a new residual variance for the  
unidentified za part? You need to make sure that this is always fixed  
at the same value (otherwise the model is different). This is not a  
problem under the trait:units specification.

Cheers,

Jarrod.



Quoting Jarrod Hadfield <j.hadfield at ed.ac.uk> on Fri, 29 Aug 2014  
08:04:42 +0100:

> Hi Ruben,
>
> Can you share your data and I will take a look. Its definitely not  
> Monte Carlo error.
>
> Cheers,
>
> Jarrod
>
>
> Quoting Ruben Arslan <rubenarslan at gmail.com> on Thu, 28 Aug 2014  
> 22:44:47 +0200:
>
>> Hi Jarrod,
>>
>> those two matched up quite well yes. I just completed another 20  
>> chains, using more variable
>> starting values. There's still two fixed effects  
>> traitza_children:spouses  and :male which haven't converged
>> according to multi-chain (gelman), but have according to geweke.
>> The offending traces: http://imgur.com/Qm6Ovfr
>> These specific effects aren't of interest to me, so if this doesn't  
>> affect the rest of my estimates, I can be happy
>> with this, but I can't conclude that, can I?
>>
>> I'm now also doing a run to see how it deals with the more  
>> intensely zero-inflated data when including
>> the unmarried.
>>
>> Thanks a lot for all that help,
>>
>> Ruben
>>
>>> gelman.diag(mcmclist)
>> Potential scale reduction factors:
>>
>>                                           Point est. Upper C.I.
>> (Intercept)                                      1.00       1.00
>> traitza_children                                 1.40       1.65
>> male                                             1.00       1.00
>> spouses                                          1.00       1.00
>> paternalage.mean                                 1.00       1.00
>> paternalage.factor(25,30]                        1.00       1.00
>> paternalage.factor(30,35]                        1.00       1.00
>> paternalage.factor(35,40]                        1.00       1.00
>> paternalage.factor(40,45]                        1.00       1.00
>> paternalage.factor(45,50]                        1.00       1.00
>> paternalage.factor(50,55]                        1.00       1.00
>> paternalage.factor(55,90]                        1.00       1.00
>> traitza_children:male                            1.33       1.54
>> traitza_children:spouses                         2.21       2.83
>> traitza_children:paternalage.mean                1.01       1.02
>> traitza_children:paternalage.factor(25,30]       1.05       1.08
>> traitza_children:paternalage.factor(30,35]       1.08       1.13
>> traitza_children:paternalage.factor(35,40]       1.15       1.25
>> traitza_children:paternalage.factor(40,45]       1.15       1.26
>> traitza_children:paternalage.factor(45,50]       1.26       1.43
>> traitza_children:paternalage.factor(50,55]       1.15       1.25
>> traitza_children:paternalage.factor(55,90]       1.14       1.23
>>
>> Multivariate psrf
>>
>> 8.99
>>
>>> summary(mcmclist)
>>
>> Iterations = 100001:149951
>> Thinning interval = 50
>> Number of chains = 20
>> Sample size per chain = 1000
>>
>> 1. Empirical mean and standard deviation for each variable,
>>   plus standard error of the mean:
>>
>>                                               Mean      SD  Naive  
>> SE Time-series SE
>> (Intercept)                                 1.36326 0.04848  
>> 0.0003428      0.0003542
>> traitza_children                           -0.76679 0.28738  
>> 0.0020321      0.0016682
>> male                                        0.09980 0.01633  
>> 0.0001155      0.0001222
>> spouses                                     0.12333 0.01957  
>> 0.0001384      0.0001414
>> paternalage.mean                            0.07215 0.02194  
>> 0.0001551      0.0001596
>> paternalage.factor(25,30]                  -0.03381 0.04184  
>> 0.0002959      0.0003066
>> paternalage.factor(30,35]                  -0.08380 0.04270  
>> 0.0003019      0.0003118
>> paternalage.factor(35,40]                  -0.16502 0.04569  
>> 0.0003231      0.0003289
>> paternalage.factor(40,45]                  -0.16738 0.05090  
>> 0.0003599      0.0003697
>> paternalage.factor(45,50]                  -0.18383 0.05880  
>> 0.0004158      0.0004242
>> paternalage.factor(50,55]                  -0.18241 0.07277  
>> 0.0005146      0.0005302
>> paternalage.factor(55,90]                  -0.40612 0.09875  
>> 0.0006983      0.0007467
>> traitza_children:male                       0.12092 0.08223  
>> 0.0005815      0.0004697
>> traitza_children:spouses                    0.64881 0.21132  
>> 0.0014942      0.0008511
>> traitza_children:paternalage.mean          -0.02741 0.08550  
>> 0.0006046      0.0006221
>> traitza_children:paternalage.factor(25,30] -0.17296 0.18680  
>> 0.0013209      0.0013750
>> traitza_children:paternalage.factor(30,35] -0.19027 0.19267  
>> 0.0013624      0.0013901
>> traitza_children:paternalage.factor(35,40] -0.24911 0.21282  
>> 0.0015049      0.0014391
>> traitza_children:paternalage.factor(40,45] -0.29772 0.23403  
>> 0.0016548      0.0015956
>> traitza_children:paternalage.factor(45,50] -0.51782 0.28589  
>> 0.0020215      0.0017602
>> traitza_children:paternalage.factor(50,55] -0.46126 0.32064  
>> 0.0022673      0.0021397
>> traitza_children:paternalage.factor(55,90] -0.38612 0.41461  
>> 0.0029317      0.0027396
>>
>> 2. Quantiles for each variable:
>>
>>                                               2.5%      25%       
>> 50%      75%      97.5%
>> (Intercept)                                 1.26883  1.33106   
>> 1.36322  1.39575  1.4589722
>> traitza_children                           -1.20696 -0.95751  
>> -0.81076 -0.63308 -0.0365042
>> male                                        0.06785  0.08878   
>> 0.09970  0.11085  0.1320168
>> spouses                                     0.08467  0.11030   
>> 0.12343  0.13643  0.1617869
>> paternalage.mean                            0.02950  0.05751   
>> 0.07202  0.08683  0.1153881
>> paternalage.factor(25,30]                  -0.11581 -0.06174  
>> -0.03397 -0.00574  0.0473783
>> paternalage.factor(30,35]                  -0.16656 -0.11250  
>> -0.08358 -0.05519  0.0003065
>> paternalage.factor(35,40]                  -0.25518 -0.19530  
>> -0.16500 -0.13440 -0.0757366
>> paternalage.factor(40,45]                  -0.26887 -0.20164  
>> -0.16675 -0.13335 -0.0677407
>> paternalage.factor(45,50]                  -0.30080 -0.22320  
>> -0.18339 -0.14440 -0.0687967
>> paternalage.factor(50,55]                  -0.32663 -0.23034  
>> -0.18227 -0.13317 -0.0415547
>> paternalage.factor(55,90]                  -0.60202 -0.47303  
>> -0.40454 -0.33994 -0.2139128
>> traitza_children:male                      -0.01083  0.06634   
>> 0.11024  0.16109  0.3295892
>> traitza_children:spouses                    0.37857  0.51072   
>> 0.59398  0.71395  1.2127940
>> traitza_children:paternalage.mean          -0.19138 -0.08250  
>> -0.02985  0.02493  0.1468989
>> traitza_children:paternalage.factor(25,30] -0.57457 -0.28481  
>> -0.16489 -0.05151  0.1728148
>> traitza_children:paternalage.factor(30,35] -0.61499 -0.30350  
>> -0.17736 -0.06299  0.1555147
>> traitza_children:paternalage.factor(35,40] -0.74251 -0.36752  
>> -0.22966 -0.10777  0.1151897
>> traitza_children:paternalage.factor(40,45] -0.84165 -0.42691  
>> -0.27729 -0.14322  0.1032436
>> traitza_children:paternalage.factor(45,50] -1.21782 -0.66568  
>> -0.48420 -0.32873 -0.0476720
>> traitza_children:paternalage.factor(50,55] -1.21327 -0.63623  
>> -0.43432 -0.24957  0.0955360
>> traitza_children:paternalage.factor(55,90] -1.33772 -0.62227  
>> -0.35364 -0.11050  0.3361684
>>
>>> effectiveSize(mcmclist)
>>                               (Intercept)                            
>> traitza_children
>>                                  18814.05                            
>>         16359.33
>>                                      male                            
>>          spouses
>>                                  18132.98                            
>>         19547.05
>>                          paternalage.mean                   
>> paternalage.factor(25,30]
>>                                  19238.72                            
>>         18974.81
>>                 paternalage.factor(30,35]                   
>> paternalage.factor(35,40]
>>                                  18874.33                            
>>         19406.63
>>                 paternalage.factor(40,45]                   
>> paternalage.factor(45,50]
>>                                  19075.18                            
>>         19401.77
>>                 paternalage.factor(50,55]                   
>> paternalage.factor(55,90]
>>                                  18960.11                            
>>         17893.23
>>                     traitza_children:male                    
>> traitza_children:spouses
>>                                  18545.55                            
>>         14438.51
>>         traitza_children:paternalage.mean  
>> traitza_children:paternalage.factor(25,30]
>>                                  18464.09                            
>>         16943.43
>> traitza_children:paternalage.factor(30,35]  
>> traitza_children:paternalage.factor(35,40]
>>                                  16827.44                            
>>         17230.04
>> traitza_children:paternalage.factor(40,45]  
>> traitza_children:paternalage.factor(45,50]
>>                                  17144.78                            
>>         18191.67
>> traitza_children:paternalage.factor(50,55]  
>> traitza_children:paternalage.factor(55,90]
>>                                  17466.60                            
>>         18540.59
>>
>>
>> ### current script:
>>
>> # bsub -q mpi -W 24:00 -n 21 -R np20 mpirun -H localhost -n 21 R  
>> --slave -f "/usr/users/rarslan/rpqa/krmh_main/children.R"
>> setwd("/usr/users/rarslan/rpqa/")
>> library(doMPI)
>> cl <-  
>> startMPIcluster(verbose=T,workdir="/usr/users/rarslan/rpqa/krmh_main/")
>> registerDoMPI(cl)
>> Children = foreach(i=1:clusterSize(cl),.options.mpi =  
>> list(seed=1337) ) %dopar% {
>> 	library(MCMCglmm);library(data.table)
>>    setwd("/usr/users/rarslan/rpqa/krmh_main/")
>> 	source("../1 - extraction functions.r")
>>    load("../krmh1.rdata")
>>
>> 	krmh.1 = recenter.pat(na.omit(krmh.1[spouses>0, list(idParents,  
>> children, male, spouses, paternalage)]))
>>
>> 	samples = 1000
>> 	thin = 50; burnin = 100000
>> 	nitt = samples * thin + burnin
>>
>> 	prior <- list(
>> 		R=list(V=diag(2), nu=1.002, fix=2),
>> 		G=list(G1=list(V=diag(2), nu=1, alpha.mu=c(0,0), alpha.V=diag(2)*1000))
>> 	)
>>
>> 	start <- list(
>> 		liab=c(rnorm( nrow(krmh.1)*2 )),
>> 		R = list(R1 = rIW(diag(2), 10 )),
>> 		G = list(G1 = rIW(diag(2), 10 ))
>> 	)
>>
>> 	( m1 = MCMCglmm( children ~ trait * (male + spouses +  
>> paternalage.mean + paternalage.factor),
>> 						rcov=~idh(trait):units,
>> 						random=~idh(trait):idParents,
>> 						family="zapoisson",
>> 						start = start,
>> 						prior = prior,
>> 						data=krmh.1,
>> 						pr = F, saveX = F, saveZ = F,
>> 						nitt=nitt,thin=thin,burnin=burnin)
>> 	)
>> 		m1$Residual$nrt<-2
>> 	m1
>> }
>>
>> save(Children,file = "Children.rdata")
>> closeCluster(cl)
>> mpi.quit()
>>
>> On 28 Aug 2014, at 20:59, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>
>>> Hi,
>>>
>>> The posteriors for the two models look pretty close to me. Are the  
>>> scale reduction factors really as high as previously reported?  
>>> Before you had 1.83 for traitza_children:spouses, but the plot  
>>> suggests that it should be close to 1?
>>>
>>> Cheers,
>>>
>>> Jarrod
>>>
>>>
>>>
>>>
>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Thu, 28 Aug 2014  
>>> 19:59:16 +0200:
>>>
>>>> Sure! Thanks a lot.
>>>> I am using ~idh(trait):units already, sorry for saying that  
>>>> incorrectly in my last email.
>>>> These models aren't the final thing, I will replace the  
>>>> paternalage.factor variable
>>>> with its linear equivalent if that seems defensible (does so far)  
>>>> and in this model it seems
>>>> okay to remove the za-effects for all predictors except spouses.
>>>> So a final model would have fewer fixed effects. I also have  
>>>> datasets of 200k+ and 5m+,
>>>> but I'm learning MCMCglmm with this smaller one because my wrong  
>>>> turns take less time.
>>>>
>>>> I've uploaded a comparison coef plot of two models:
>>>> http://i.imgur.com/sHUfnmd.png
>>>> m7 is with the default starting values, m1 is with the  
>>>> specification I sent in my last email. I don't
>>>> know if such differences are something to worry about.
>>>>
>>>> I don't know what qualifies as highly overdispersed, here's a  
>>>> plot of the outcome for ever
>>>> married people (slate=real data):
>>>> http://imgur.com/14MywgZ
>>>> here's with everybody born (incl. some stillborn etc.):
>>>> http://imgur.com/knRGa1v
>>>> I guess my approach (generating an overdispersed poisson with the  
>>>> parameters from
>>>> the data and checking if it has as excess zeroes) is not the best  
>>>> way to diagnose zero-inflation,
>>>> but especially in the second case it seems fairly clear-cut.
>>>>
>>>> Best regards,
>>>>
>>>> Ruben
>>>>
>>>>> summary(m1)
>>>>
>>>> Iterations = 50001:149951
>>>> Thinning interval  = 50
>>>> Sample size  = 2000
>>>>
>>>> DIC: 31249.73
>>>>
>>>> G-structure:  ~idh(trait):idParents
>>>>
>>>>                     post.mean  l-95% CI u-95% CI eff.samp
>>>> children.idParents     0.006611 4.312e-08   0.0159    523.9
>>>> za_children.idParents  0.193788 7.306e-02   0.3283    369.3
>>>>
>>>> R-structure:  ~idh(trait):units
>>>>
>>>>                 post.mean l-95% CI u-95% CI eff.samp
>>>> children.units       0.1285   0.1118   0.1452    716.1
>>>> za_children.units    0.9950   0.9950   0.9950      0.0
>>>>
>>>> Location effects: children ~ trait * (male + spouses +  
>>>> paternalage.mean + paternalage.factor)
>>>>
>>>>                                           post.mean   l-95% CI    
>>>> u-95% CI eff.samp  pMCMC
>>>> (Intercept)                                 1.3413364  1.2402100   
>>>> 1.4326099     1789 <5e-04 ***
>>>> traitza_children                           -0.8362879 -1.2007980  
>>>> -0.5016730     1669 <5e-04 ***
>>>> male                                        0.0994902  0.0679050   
>>>> 0.1297394     2000 <5e-04 ***
>>>> spouses                                     0.1236033  0.0839000   
>>>> 0.1624939     2000 <5e-04 ***
>>>> paternalage.mean                            0.0533892  0.0119569   
>>>> 0.0933960     2000  0.015 *
>>>> paternalage.factor(25,30]                  -0.0275822 -0.1116421   
>>>> 0.0537359     1842  0.515
>>>> paternalage.factor(30,35]                  -0.0691025 -0.1463214   
>>>> 0.0122393     1871  0.097 .
>>>> paternalage.factor(35,40]                  -0.1419933 -0.2277379  
>>>> -0.0574678     1845 <5e-04 ***
>>>> paternalage.factor(40,45]                  -0.1364952 -0.2362714  
>>>> -0.0451874     1835  0.007 **
>>>> paternalage.factor(45,50]                  -0.1445342 -0.2591767  
>>>> -0.0421178     1693  0.008 **
>>>> paternalage.factor(50,55]                  -0.1302972 -0.2642965   
>>>> 0.0077061     2000  0.064 .
>>>> paternalage.factor(55,90]                  -0.3407879 -0.5168972  
>>>> -0.1493652     1810 <5e-04 ***
>>>> traitza_children:male                       0.0926888 -0.0147379   
>>>> 0.2006142     1901  0.098 .
>>>> traitza_children:spouses                    0.5531197  0.3870616   
>>>> 0.7314289     1495 <5e-04 ***
>>>> traitza_children:paternalage.mean           0.0051463 -0.1279396   
>>>> 0.1460099     1617  0.960
>>>> traitza_children:paternalage.factor(25,30] -0.1538957 -0.4445749   
>>>> 0.1462955     1781  0.321
>>>> traitza_children:paternalage.factor(30,35] -0.1747883 -0.4757851   
>>>> 0.1162476     1998  0.261
>>>> traitza_children:paternalage.factor(35,40] -0.2261843 -0.5464379   
>>>> 0.0892582     1755  0.166
>>>> traitza_children:paternalage.factor(40,45] -0.2807543 -0.6079678   
>>>> 0.0650281     1721  0.100 .
>>>> traitza_children:paternalage.factor(45,50] -0.4905843 -0.8649214  
>>>> -0.1244174     1735  0.010 **
>>>> traitza_children:paternalage.factor(50,55] -0.4648579 -0.9215759  
>>>> -0.0002083     1687  0.054 .
>>>> traitza_children:paternalage.factor(55,90] -0.3945406 -1.0230155   
>>>> 0.2481568     1793  0.195
>>>> ---
>>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>>
>>>>> describe(krmh.1[spouses>0,])
>>>>                   vars    n mean   sd median trimmed  mad   min    
>>>> max range skew kurtosis   se
>>>> children               2 6829 3.81 2.93   4.00    3.61 2.97  0.00  
>>>> 16.00 16.00 0.47    -0.46 0.04
>>>> male                   3 6829 0.46 0.50   0.00    0.45 0.00  0.00  
>>>>  1.00  1.00 0.14    -1.98 0.01
>>>> spouses                4 6829 1.14 0.38   1.00    1.03 0.00  1.00  
>>>>  4.00  3.00 2.87     8.23 0.00
>>>> paternalage            5 6829 3.65 0.80   3.57    3.60 0.80  1.83  
>>>>  7.95  6.12 0.69     0.70 0.01
>>>> paternalage_c          6 6829 0.00 0.80  -0.08   -0.05 0.80 -1.82  
>>>>  4.30  6.12 0.69     0.70 0.01
>>>> paternalage.mean       7 6829 0.00 0.68  -0.08   -0.05 0.59 -1.74  
>>>>  4.30  6.04 0.95     1.97 0.01
>>>> paternalage.diff       8 6829 0.00 0.42   0.00   -0.01 0.38 -1.51  
>>>>  1.48  2.99 0.17     0.17 0.01
>>>>
>>>>> table(krmh.1$paternalage.factor)
>>>>
>>>> [0,25] (25,30] (30,35] (35,40] (40,45] (45,50] (50,55] (55,90]
>>>>   309    1214    1683    1562    1039     623     269     130
>>>>
>>>> On 28 Aug 2014, at 19:05, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>>>
>>>>> Hi Ruben,
>>>>>
>>>>> It might be hard to detect (near) ECPs with so many fixed  
>>>>> effects (can you post the model summary (and give us the mean  
>>>>> and standard deviation of any continuous covariates)). Also, the  
>>>>> complementary log-log link (which is the za specification) is  
>>>>> non-symmetric and runs into problems outside the range -35 to  
>>>>> 3.5 so there may be a problem there, particularly if you use  
>>>>> rcov=~trait:units and the Poisson part is highly over-dispersed.  
>>>>>  You could try rcov=~idh(trait):units and fix the  
>>>>> non-identifiable za residual variance to something smaller than  
>>>>> 1 (say 0.5)  - it will mix slower but it will reduce the chance  
>>>>> of over/underflow.
>>>>>
>>>>> Cheers,
>>>>>
>>>>> Jarrod
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Thu, 28 Aug 2014  
>>>>> 18:45:30 +0200:
>>>>>
>>>>>> Hi Jarrod,
>>>>>>
>>>>>>> 1) it did not return an error with rcov = ~trait:units because  
>>>>>>> you used R1=rpois(2,1)+1 and yet this specification only fits  
>>>>>>> a single variance (not a 2x2 covariance matrix).  
>>>>>>> R1=rpois(2,1)+1 is a bit of a weird specification since it has  
>>>>>>> to be integer. I would obtain starting values using rIW().
>>>>>>
>>>>>> I agree it's a weird specification, I was a bit lost and  
>>>>>> thought I could get away with just putting some random numbers  
>>>>>> in the starting value.
>>>>>> I didn't do R1=rpois(2,1)+1 though, I did  
>>>>>> R1=diag(rpois(2,1)+1), so I got a 2x2 matrix, but yes, bound to  
>>>>>> be integer.
>>>>>> I didn't know starting values should come from a conjugate  
>>>>>> distribution, though that probably means I didn't think about  
>>>>>> it much.
>>>>>>
>>>>>> I'm now doing
>>>>>> start <- list(
>>>>>> 	liab=c(rnorm( nrow(krmh.1)*2 )),
>>>>>> 	R = list(R1 = rIW( diag(2), nrow(krmh.1)) ),
>>>>>> 	G = list(G1 = rIW( diag(2), nrow(krmh.1)) )
>>>>>> )
>>>>>>
>>>>>> Is this what you had in mind?
>>>>>> I am especially unsure if I am supposed to use such a low  
>>>>>> sampling variability (my sample size is probably not even  
>>>>>> relevant for the starting values) and if I should start from  
>>>>>> diag(2).
>>>>>>
>>>>>> And, I am still happily confused that this specification still  
>>>>>> doesn't lead to errors with respect to rcov = ~trait:units .  
>>>>>> Does this mean I'm doing it wrong?
>>>>>>
>>>>>>> 3) a) how many effective samples do you have for each  
>>>>>>> parameter? and b) are you getting extreme category  
>>>>>>> problems/numerical issues? If you store the latent variables  
>>>>>>> (pl=TUE) what is their range for the Zi/za part?
>>>>>>
>>>>>> My parallel run using the above starting values isn't finished yet.
>>>>>> a) After applying the above starting values I get, for the  
>>>>>> location effects 1600-2000 samples for a 2000 sample chain  
>>>>>> (with thin set to 50). G and R-structure are from 369  
>>>>>> (za_children.idParents) to 716 (and 0 for the fixed part).
>>>>>> Effective sample sizes were similar for my run using the  
>>>>>> starting values for G/R that I drew from rpois, and using 40  
>>>>>> chains I of course get
>>>>>> b) I don't think I am getting extreme categories. I would  
>>>>>> probably be getting extreme categories if I included the  
>>>>>> forever-alones (they almost never have children), but this way  
>>>>>> no.
>>>>>> I wasn't sure how to examine the range of the latents  
>>>>>> separately for the za part, but for a single chain it looks okay:
>>>>>>> quantile(as.numeric(m1$Liab),probs = c(0,0.01,0,0.99,1))
>>>>>>     0%        1%        0%       99%      100%
>>>>>> -4.934111 -1.290728 -4.934111  3.389847  7.484206
>>>>>>
>>>>>> Well, all considered now that I use the above starting value  
>>>>>> specification I get slightly different estimates for all  
>>>>>> za-coefficients. Nothing major, but still leading me to
>>>>>> think my estimates aren't exactly independent of the starting  
>>>>>> values I use. I'll see what the parallel run yields.
>>>>>>
>>>>>> Thanks a lot,
>>>>>>
>>>>>> Ruben
>>>>>>
>>>>>>>
>>>>>>> Cheers,
>>>>>>>
>>>>>>> Jarrod
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Wed, 27 Aug  
>>>>>>> 2014 19:23:42 +0200:
>>>>>>>
>>>>>>>> Hi Jarrod,
>>>>>>>>
>>>>>>>> thanks again. I was able to get it running with your advice.
>>>>>>>> Some points of confusion remain:
>>>>>>>>
>>>>>>>> - You wrote that zi/za models would return an error with rcov  
>>>>>>>> = ~trait:units + starting values. This did not happen in my  
>>>>>>>> case, so I didn't build MCMCglmm myself with your suggested  
>>>>>>>> edits. Also, have you considered putting your own MCMCglmm  
>>>>>>>> repo on Github? Your users would be able to install  
>>>>>>>> pre-releases and I'd think you'd get some time-saving pull  
>>>>>>>> requests too.
>>>>>>>> - In my attempts to get my models to run properly, I messed  
>>>>>>>> up a prior and did not use fix=2 in my prior specification  
>>>>>>>> for my za models. This led to crappy convergence, it's much  
>>>>>>>> better now and for some of my simpler models I think I won't  
>>>>>>>> need parallel chains. I'm reminded of Gelman's folk theorem  
>>>>>>>> of statistical computing.
>>>>>>>> - I followed your advice, but of course I could not set the  
>>>>>>>> true values as starting values, but wanted to set random, bad  
>>>>>>>> starting values. I pasted below what I arrived at, I'm  
>>>>>>>> especially unsure whether I specified the starting values for  
>>>>>>>> G and R properly (I think not).
>>>>>>>> 	start <- list(
>>>>>>>> 		liab=c(rnorm( nrow(krmh.1)*2 )),
>>>>>>>> 		R = list(R1 = diag(rpois(2, 1)+1)),
>>>>>>>> 		G = list(G1 = diag(rpois(2, 1)+1))
>>>>>>>> 	)
>>>>>>>>
>>>>>>>>
>>>>>>>> However, even though I may not need multiple chains for some  
>>>>>>>> of my simpler models, I've now run into conflicting  
>>>>>>>> diagnostics. The geweke.diag for each chain (and examination  
>>>>>>>> of the traces) gives
>>>>>>>> satisfactory diagnostics. Comparing multiple chains using  
>>>>>>>> gelman.diag, however, leads to one bad guy, namely the  
>>>>>>>> traitza_children:spouses interaction.
>>>>>>>> I think this implies that I've got some starting value  
>>>>>>>> dependence for this parameter, that won't be easily rectified  
>>>>>>>> through longer burnin?
>>>>>>>> Do you have any ideas how to rectify this?
>>>>>>>> I am currently doing sequential analyses on episodes of  
>>>>>>>> selection and in historical human data only those who marry  
>>>>>>>> have a chance at having kids. I exclude the unmarried
>>>>>>>> from my sample where I predict number of children, because I  
>>>>>>>> examine that in a previous model and the zero-inflation (65%  
>>>>>>>> zeros, median w/o unmarried = 4) when including the unmarried  
>>>>>>>> is so excessive.
>>>>>>>> Number of spouses is easily the strongest predictor in the  
>>>>>>>> model, but only serves as a covariate here. Since my other  
>>>>>>>> estimates are stable across chains and runs and agree well  
>>>>>>>> across models and with theory, I'm
>>>>>>>> inclined to shrug this off. But probably I shouldn't ignore  
>>>>>>>> this sign of non-convergence?
>>>>>>>>
>>>>>>>>> gelman.diag(mcmc_1)
>>>>>>>> Potential scale reduction factors:
>>>>>>>>
>>>>>>>>                                        Point est. Upper C.I.
>>>>>>>> (Intercept)                                      1.00       1.00
>>>>>>>> traitza_children                                 1.27       1.39
>>>>>>>> male                                             1.00       1.00
>>>>>>>> spouses                                          1.00       1.00
>>>>>>>> paternalage.mean                                 1.00       1.00
>>>>>>>> paternalage.factor(25,30]                        1.00       1.00
>>>>>>>> paternalage.factor(30,35]                        1.00       1.00
>>>>>>>> paternalage.factor(35,40]                        1.00       1.00
>>>>>>>> paternalage.factor(40,45]                        1.00       1.00
>>>>>>>> paternalage.factor(45,50]                        1.00       1.00
>>>>>>>> paternalage.factor(50,55]                        1.00       1.00
>>>>>>>> paternalage.factor(55,90]                        1.00       1.00
>>>>>>>> traitza_children:male                            1.22       1.32
>>>>>>>> traitza_children:spouses                         1.83       2.13
>>>>>>>> traitza_children:paternalage.mean                1.02       1.02
>>>>>>>> traitza_children:paternalage.factor(25,30]       1.03       1.05
>>>>>>>> traitza_children:paternalage.factor(30,35]       1.05       1.08
>>>>>>>> traitza_children:paternalage.factor(35,40]       1.10       1.15
>>>>>>>> traitza_children:paternalage.factor(40,45]       1.12       1.17
>>>>>>>> traitza_children:paternalage.factor(45,50]       1.19       1.28
>>>>>>>> traitza_children:paternalage.factor(50,55]       1.12       1.18
>>>>>>>> traitza_children:paternalage.factor(55,90]       1.11       1.17
>>>>>>>>
>>>>>>>> Multivariate psrf
>>>>>>>>
>>>>>>>> 7.27
>>>>>>>>
>>>>>>>>
>>>>>>>> Best regards,
>>>>>>>>
>>>>>>>> Ruben
>>>>>>>>
>>>>>>>>
>>>>>>>> On 26 Aug 2014, at 13:04, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>>>>>>>
>>>>>>>>> Hi Ruben,
>>>>>>>>>
>>>>>>>>> There are 400 liabilities in a zapoisson model (2 per  
>>>>>>>>> datum). This code should work:
>>>>>>>>>
>>>>>>>>> g <-sample(letters[1:10], size = 200, replace = T)
>>>>>>>>> pred <- rnorm(200)
>>>>>>>>>
>>>>>>>>> l1<-rnorm(200, -1, sqrt(1))
>>>>>>>>> l2<-rnorm(200, -1, sqrt(1))
>>>>>>>>>
>>>>>>>>> y<-VGAM::rzapois(200, exp(l1), exp(-exp(l2)))
>>>>>>>>>
>>>>>>>>> # generate zero-altered data with an intercept of -1  
>>>>>>>>> (because the intercept and variance are the same for both  
>>>>>>>>> processes this is just standard Poisson)
>>>>>>>>>
>>>>>>>>> dat<-data.frame(y=y, g = g, pred = pred)
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> start.1<-list(liab=c(l1,l2), R = list(R1=diag(2)),  
>>>>>>>>> G=list(G1=diag(2)))
>>>>>>>>> prior.1<-list(R=list(V=diag(2), nu=1.002, fix=2),  
>>>>>>>>> G=list(G1=list(V=diag(2), nu=2, alpha.mu=c(0,0),  
>>>>>>>>> alpha.V=diag(2)*1000)))
>>>>>>>>>
>>>>>>>>> m1<-MCMCglmm(y~trait + pred:trait, random=~us(trait):g,  
>>>>>>>>> family="zapoisson",rcov=~idh(trait):units, data=dat,  
>>>>>>>>> prior=prior.1, start= start.1)
>>>>>>>>>
>>>>>>>>> However, there are 2 bugs in the current version of MCMCglmm  
>>>>>>>>> that return an error message when the documentation implies  
>>>>>>>>> it should be fine:
>>>>>>>>>
>>>>>>>>> a) it should be possible to have R=diag(2) rather than R =  
>>>>>>>>> list(R1=diag(2)). This bug cropped up when I implemented  
>>>>>>>>> block-diagonal R structures. It can be fixed by inserting:
>>>>>>>>>
>>>>>>>>>      if(!is.list(start$R)){
>>>>>>>>>         start$R<-list(R1=start$R)
>>>>>>>>>      }
>>>>>>>>>
>>>>>>>>> on L514 of MCMCglmm.R below
>>>>>>>>>
>>>>>>>>>      if(!is.list(prior$R[[1]])){
>>>>>>>>>         prior$R<-list(R1=prior$R)
>>>>>>>>>      }
>>>>>>>>>
>>>>>>>>> b) rcov=~trait:units models for zi/za models will return an  
>>>>>>>>> error when passing starting values. To fix this insert
>>>>>>>>>
>>>>>>>>>     if(diagR==3){
>>>>>>>>>       if(dim(start)[1]!=1){
>>>>>>>>>         stop("V is the wrong dimension for some  
>>>>>>>>> strart$G/start$R elements")
>>>>>>>>>       }
>>>>>>>>>       start<-diag(sum(nfl))*start[1]
>>>>>>>>>     }
>>>>>>>>>
>>>>>>>>> on L90 of priorfromat.R below
>>>>>>>>>
>>>>>>>>>     if(is.matrix(start)==FALSE){
>>>>>>>>>       start<-as.matrix(start)
>>>>>>>>>     }
>>>>>>>>>
>>>>>>>>> I will put these in the new version.
>>>>>>>>>
>>>>>>>>> Cheers,
>>>>>>>>>
>>>>>>>>> Jarrod
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25 Aug  
>>>>>>>>> 2014 21:52:30 +0200:
>>>>>>>>>
>>>>>>>>>> Hi Jarrod,
>>>>>>>>>>
>>>>>>>>>> thanks for these pointers.
>>>>>>>>>>
>>>>>>>>>>>> You will need to provide over-dispersed starting values  
>>>>>>>>>>>> for multiple-chain convergence diagnostics to be useful  
>>>>>>>>>>>> (GLMM are so simple I am generally happy if the output of  
>>>>>>>>>>>> a single run looks reasonable).
>>>>>>>>>>
>>>>>>>>>> Oh, I would be happy with single chains, but since  
>>>>>>>>>> computation would take weeks this way, I wanted to  
>>>>>>>>>> parallelise and I would use the multi-chain convergence as  
>>>>>>>>>> a criterion that my parallelisation was proper
>>>>>>>>>> and is as informative as a single long chain. There don't  
>>>>>>>>>> seem to be any such checks built-in ? I was analysing my 40  
>>>>>>>>>> chains for a bit longer than I like to admit until I  
>>>>>>>>>> noticed they were identical (effectiveSize
>>>>>>>>>> and summary.mcmc.list did not yell at me for this).
>>>>>>>>>>
>>>>>>>>>>>> # use some very bad starting values
>>>>>>>>>> I get that these values are bad, but that is the goal for  
>>>>>>>>>> my multi-chain aim, right?
>>>>>>>>>>
>>>>>>>>>> I can apply this to my zero-truncated model, but am again  
>>>>>>>>>> getting stuck with the zero-altered one.
>>>>>>>>>> Maybe I need only specify the Liab values for this?
>>>>>>>>>> At least I'm getting nowhere with specifying R and G  
>>>>>>>>>> starting values here. When I got an error, I always
>>>>>>>>>> went to the MCMCglmm source to understand why the checks  
>>>>>>>>>> failed, but I didn't always understand
>>>>>>>>>> what was being checked and couldn't get it to work.
>>>>>>>>>>
>>>>>>>>>> Here's a failing example:
>>>>>>>>>>
>>>>>>>>>> l<-rnorm(200, -1, sqrt(1))
>>>>>>>>>> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
>>>>>>>>>> g = sample(letters[1:10], size = 200, replace = T)
>>>>>>>>>> pred = rnorm(200)
>>>>>>>>>> y<-rpois(200,exp(l)-t)
>>>>>>>>>> y[1:40] = 0
>>>>>>>>>> # generate zero-altered data with an intercept of -1
>>>>>>>>>>
>>>>>>>>>> dat<-data.frame(y=y, g = g, pred = pred)
>>>>>>>>>> set.seed(1)
>>>>>>>>>> start_true = list(Liab=l, R = 1, G = 1 )
>>>>>>>>>> m1<-MCMCglmm(y~1 + pred,random = ~ g,  
>>>>>>>>>> family="zapoisson",rcov=~us(trait):units, data=dat, start=  
>>>>>>>>>> start_true)
>>>>>>>>>>
>>>>>>>>>> # use true latent variable as starting values
>>>>>>>>>> set.seed(1)
>>>>>>>>>> # use some very bad starting values
>>>>>>>>>> start_rand = list(Liab=rnorm(200), R = rpois(1, 1)+1, G =  
>>>>>>>>>> rpois(1, 1)+1 )
>>>>>>>>>> m2<-MCMCglmm(y~1 + pred,random = ~ g,rcov=~us(trait):units,  
>>>>>>>>>>  family="zapoisson", data=dat, start = start_rand)
>>>>>>>>>>
>>>>>>>>>> Best,
>>>>>>>>>>
>>>>>>>>>> Ruben
>>>>>>>>>>
>>>>>>>>>> On 25 Aug 2014, at 18:29, Jarrod Hadfield  
>>>>>>>>>> <j.hadfield at ed.ac.uk> wrote:
>>>>>>>>>>
>>>>>>>>>>> Hi Ruben,
>>>>>>>>>>>
>>>>>>>>>>> Sorry  - I was wrong when I said that everything is Gibbs  
>>>>>>>>>>> sampled conditional on the latent variables. The location  
>>>>>>>>>>> effects (fixed and random effects) are also sampled  
>>>>>>>>>>> conditional on the (co)variance components so you should  
>>>>>>>>>>> add them to the starting values. In the case where the  
>>>>>>>>>>> true values are used:
>>>>>>>>>>>
>>>>>>>>>>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat,  
>>>>>>>>>>> start=list(Liab=l,R=1))
>>>>>>>>>>>
>>>>>>>>>>> Cheers,
>>>>>>>>>>>
>>>>>>>>>>> Jarrod
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>> Quoting Jarrod Hadfield <j.hadfield at ed.ac.uk> on Mon, 25  
>>>>>>>>>>> Aug 2014 17:14:14 +0100:
>>>>>>>>>>>
>>>>>>>>>>>> Hi Ruben,
>>>>>>>>>>>>
>>>>>>>>>>>> You will need to provide over-dispersed starting values  
>>>>>>>>>>>> for multiple-chain convergence diagnostics to be useful  
>>>>>>>>>>>> (GLMM are so simple I am generally happy if the output of  
>>>>>>>>>>>> a single run looks reasonable).
>>>>>>>>>>>>
>>>>>>>>>>>> With non-Gaussian data everything is Gibbs sampled  
>>>>>>>>>>>> conditional on the latent variables, so you only need to  
>>>>>>>>>>>> pass them:
>>>>>>>>>>>>
>>>>>>>>>>>> l<-rnorm(200, -1, sqrt(1))
>>>>>>>>>>>> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
>>>>>>>>>>>> y<-rpois(200,exp(l)-t)+1
>>>>>>>>>>>> # generate zero-truncated data with an intercept of -1
>>>>>>>>>>>>
>>>>>>>>>>>> dat<-data.frame(y=y)
>>>>>>>>>>>> set.seed(1)
>>>>>>>>>>>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat,  
>>>>>>>>>>>> start=list(Liab=l))
>>>>>>>>>>>> # use true latent variable as starting values
>>>>>>>>>>>> set.seed(1)
>>>>>>>>>>>> m2<-MCMCglmm(y~1, family="ztpoisson", data=dat,  
>>>>>>>>>>>> start=list(Liab=rnorm(200)))
>>>>>>>>>>>> # use some very bad starting values
>>>>>>>>>>>>
>>>>>>>>>>>> plot(mcmc.list(m1$Sol, m2$Sol))
>>>>>>>>>>>> # not identical despite the same seed because of  
>>>>>>>>>>>> different starting values but clearly sampling the same  
>>>>>>>>>>>> posterior distribution:
>>>>>>>>>>>>
>>>>>>>>>>>> gelman.diag(mcmc.list(m1$Sol, m2$Sol))
>>>>>>>>>>>>
>>>>>>>>>>>> Cheers,
>>>>>>>>>>>>
>>>>>>>>>>>> Jarrod
>>>>>>>>>>>>
>>>>>>>>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25  
>>>>>>>>>>>> Aug 2014 18:00:08 +0200:
>>>>>>>>>>>>
>>>>>>>>>>>>> Dear Jarrod,
>>>>>>>>>>>>>
>>>>>>>>>>>>> thanks for the quick reply. Please, don't waste time  
>>>>>>>>>>>>> looking into doMPI ? I am happy that I
>>>>>>>>>>>>> get the expected result, when I specify that  
>>>>>>>>>>>>> reproducible seed, whyever that may be.
>>>>>>>>>>>>> I'm pretty sure that is the deciding factor, because I  
>>>>>>>>>>>>> tested it explicitly, I just have no idea
>>>>>>>>>>>>> how/why it interacts with the choice of family.
>>>>>>>>>>>>>
>>>>>>>>>>>>> That said, is setting up different RNG streams for my  
>>>>>>>>>>>>> workers (now that it works) __sufficient__
>>>>>>>>>>>>> so that I get independent chains and can use  
>>>>>>>>>>>>> gelman.diag() for convergence diagnostics?
>>>>>>>>>>>>> Or should I still tinker with the starting values myself?
>>>>>>>>>>>>> I've never found a worked example of supplying starting  
>>>>>>>>>>>>> values and am thus a bit lost.
>>>>>>>>>>>>>
>>>>>>>>>>>>> Sorry for sending further questions, I hope someone else  
>>>>>>>>>>>>> takes pity while
>>>>>>>>>>>>> you're busy with lectures.
>>>>>>>>>>>>>
>>>>>>>>>>>>> Best wishes
>>>>>>>>>>>>>
>>>>>>>>>>>>> Ruben
>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>> On 25 Aug 2014, at 17:29, Jarrod Hadfield  
>>>>>>>>>>>>> <j.hadfield at ed.ac.uk> wrote:
>>>>>>>>>>>>>
>>>>>>>>>>>>>> Hi Ruben,
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> I do not think the issue is with the starting values,  
>>>>>>>>>>>>>> because even if the same starting values were used the  
>>>>>>>>>>>>>> chains would still differ because of the randomness in  
>>>>>>>>>>>>>> the Markov Chain (if I interpret your `identical' test  
>>>>>>>>>>>>>> correctly). This just involves a call to GetRNGstate()  
>>>>>>>>>>>>>> in the C++ code (L 871 ofMCMCglmm.cc) so I think for  
>>>>>>>>>>>>>> some reason doMPI/foreach is not doing what you expect.  
>>>>>>>>>>>>>> I am not familiar with doMPI and am in the middle of  
>>>>>>>>>>>>>> writing lectures so haven't got time to look into it  
>>>>>>>>>>>>>> carefully. Outside of the context of doMPI I get the  
>>>>>>>>>>>>>> behaviour I expect:
>>>>>>>>>>>>>>
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> l<-rnorm(200, -1, sqrt(1))
>>>>>>>>>>>>>> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
>>>>>>>>>>>>>> y<-rpois(200,exp(l)-t)+1
>>>>>>>>>>>>>> # generate zero-truncated data with an intercept of -1
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> dat<-data.frame(y=y)
>>>>>>>>>>>>>> set.seed(1)
>>>>>>>>>>>>>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>>>>>>>>>>>> set.seed(2)
>>>>>>>>>>>>>> m2<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>>>>>>>>>>>> set.seed(2)
>>>>>>>>>>>>>> m3<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> plot(mcmc.list(m1$Sol, m2$Sol))
>>>>>>>>>>>>>> # different, as expected
>>>>>>>>>>>>>> plot(mcmc.list(m2$Sol, m3$Sol))
>>>>>>>>>>>>>> # the same, as expected
>>>>>>>>>>>>>>
>>>>>>>>>>>>>>
>>>>>>>>>>>>>>
>>>>>>>>>>>>>>
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25  
>>>>>>>>>>>>>> Aug 2014 16:58:06 +0200:
>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> Dear list,
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> sorry for bumping my old post, I hope to elicit a  
>>>>>>>>>>>>>>> response with a more focused question:
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> When does MCMCglmm automatically start from different  
>>>>>>>>>>>>>>> values when using doMPI/foreach?
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> I have done some tests with models of varying  
>>>>>>>>>>>>>>> complexity. For example, the script in my last
>>>>>>>>>>>>>>> post (using "zapoisson") yielded 40 identical chains:
>>>>>>>>>>>>>>>> identical(mcmclist[1], mcmclist[30])
>>>>>>>>>>>>>>> TRUE
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> A simpler (?) model (using "ztpoisson" and no  
>>>>>>>>>>>>>>> specified prior), however, yielded different chains
>>>>>>>>>>>>>>> and I could use them to calculate gelman.diag()
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> Changing my script to the version below, i.e. seeding  
>>>>>>>>>>>>>>> foreach using .options.mpi=list( seed= 1337)
>>>>>>>>>>>>>>> so as to make RNGstreams reproducible (or so I   
>>>>>>>>>>>>>>> thought), led to different chains even for the
>>>>>>>>>>>>>>> "zapoisson" model.
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> In no case have I (successfully) tried to supplant the  
>>>>>>>>>>>>>>> default of MCMCglmm's "start" argument.
>>>>>>>>>>>>>>> Is starting my models from different RNGsubstreams  
>>>>>>>>>>>>>>> inadequate compared to manipulating
>>>>>>>>>>>>>>> the start argument explicitly? If so, is there any  
>>>>>>>>>>>>>>> worked example of explicit starting value manipulation
>>>>>>>>>>>>>>> in parallel computation?
>>>>>>>>>>>>>>> I've browsed the MCMCglmm source to understand how the  
>>>>>>>>>>>>>>> default starting values are generated,
>>>>>>>>>>>>>>> but didn't find any differences with respect to RNG  
>>>>>>>>>>>>>>> for the two families "ztpoisson" and "zapoisson"
>>>>>>>>>>>>>>> (granted, I did not dig very deep).
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> Best regards,
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> Ruben Arslan
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> # bsub -q mpi -W 12:00 -n 41 -R np20 mpirun -H  
>>>>>>>>>>>>>>> localhost -n 41 R --slave -f  
>>>>>>>>>>>>>>> "/usr/users/rarslan/rpqa/rpqa_main/rpqa_children_parallel.R"
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> library(doMPI)
>>>>>>>>>>>>>>> cl <-  
>>>>>>>>>>>>>>> startMPIcluster(verbose=T,workdir="/usr/users/rarslan/rpqa/rpqa_main/")
>>>>>>>>>>>>>>> registerDoMPI(cl)
>>>>>>>>>>>>>>> Children_mcmc1 =  
>>>>>>>>>>>>>>> foreach(i=1:clusterSize(cl),.options.mpi =  
>>>>>>>>>>>>>>> list(seed=1337) ) %dopar% {
>>>>>>>>>>>>>>> 	library(MCMCglmm);library(data.table)
>>>>>>>>>>>>>>> 	load("/usr/users/rarslan/rpqa/rpqa1.rdata")
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> 	nitt = 130000; thin = 100; burnin = 30000
>>>>>>>>>>>>>>> 	prior.m5d.2 = list(
>>>>>>>>>>>>>>> 		R = list(V = diag(c(1,1)), nu = 0.002),
>>>>>>>>>>>>>>> 		G=list(list(V=diag(c(1,1e-6)),nu=0.002))
>>>>>>>>>>>>>>> 	)
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> 	rpqa.1 = na.omit(rpqa.1[spouses>0, list(idParents,  
>>>>>>>>>>>>>>> children, male, urban, spouses, paternalage.mean,  
>>>>>>>>>>>>>>> paternalage.factor)])
>>>>>>>>>>>>>>> 	(m1 = MCMCglmm( children ~ trait * (male + urban +  
>>>>>>>>>>>>>>> spouses + paternalage.mean + paternalage.factor),
>>>>>>>>>>>>>>> 						rcov=~us(trait):units,
>>>>>>>>>>>>>>> 						random=~us(trait):idParents,
>>>>>>>>>>>>>>> 						family="zapoisson",
>>>>>>>>>>>>>>> 						prior = prior.m5d.2,
>>>>>>>>>>>>>>> 						data=rpqa.1,
>>>>>>>>>>>>>>> 						pr = F, saveX = F, saveZ = F,
>>>>>>>>>>>>>>> 						nitt=nitt,thin=thin,burnin=burnin))
>>>>>>>>>>>>>>> }
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> library(coda)
>>>>>>>>>>>>>>> mcmclist =  
>>>>>>>>>>>>>>> mcmc.list(lapply(Children_mcmc1,FUN=function(x) {  
>>>>>>>>>>>>>>> x$Sol}))
>>>>>>>>>>>>>>> save(Children_mcmc1,mcmclist, file =  
>>>>>>>>>>>>>>> "/usr/users/rarslan/rpqa/rpqa_main/rpqa_mcmc_kids_za.rdata")
>>>>>>>>>>>>>>> closeCluster(cl)
>>>>>>>>>>>>>>> mpi.quit()
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> On 04 Aug 2014, at 20:25, Ruben Arslan  
>>>>>>>>>>>>>>> <rubenarslan at gmail.com> wrote:
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> Dear list,
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> would someone be willing to share her or his efforts  
>>>>>>>>>>>>>>>> in parallelising a MCMCglmm analysis?
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> I had something viable using harvestr that seemed to  
>>>>>>>>>>>>>>>> properly initialise
>>>>>>>>>>>>>>>> the starting values from different random number  
>>>>>>>>>>>>>>>> streams (which is desirable,
>>>>>>>>>>>>>>>> as far as I could find out), but I ended up being  
>>>>>>>>>>>>>>>> unable to use harvestr, because
>>>>>>>>>>>>>>>> it uses an old version of plyr, where parallelisation  
>>>>>>>>>>>>>>>> works only for multicore, not for
>>>>>>>>>>>>>>>> MPI.
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> I pasted my working version, that does not do  
>>>>>>>>>>>>>>>> anything about starting values or RNG
>>>>>>>>>>>>>>>> at the end of this email. I can try to fumble further  
>>>>>>>>>>>>>>>> in the dark or try to update harvestr,
>>>>>>>>>>>>>>>> but maybe someone has gone through all this already.
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> I'd also appreciate any tips for elegantly  
>>>>>>>>>>>>>>>> post-processing such parallel data, as some of my usual
>>>>>>>>>>>>>>>> extraction functions and routines are hampered by the  
>>>>>>>>>>>>>>>> fact that some coda functions
>>>>>>>>>>>>>>>> do not aggregate results over chains. (What I get  
>>>>>>>>>>>>>>>> from a single-chain summary in MCMCglmm
>>>>>>>>>>>>>>>> is a bit more comprehensive, than what I managed to  
>>>>>>>>>>>>>>>> cobble together with my own extraction
>>>>>>>>>>>>>>>> functions).
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> The reason I'm parallelising my analyses is that I'm  
>>>>>>>>>>>>>>>> having trouble getting a good effective
>>>>>>>>>>>>>>>> sample size for any parameter having to do with the  
>>>>>>>>>>>>>>>> many zeroes in my data.
>>>>>>>>>>>>>>>> Any pointers are very appreciated, I'm quite  
>>>>>>>>>>>>>>>> inexperienced with MCMCglmm.
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> Best wishes
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> Ruben
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> # bsub -q mpi-short -W 2:00 -n 42 -R np20 mpirun -H  
>>>>>>>>>>>>>>>> localhost -n 41 R --slave -f  
>>>>>>>>>>>>>>>> "rpqa/rpqa_main/rpqa_children_parallel.r"
>>>>>>>>>>>>>>>> library(doMPI)
>>>>>>>>>>>>>>>> cl <- startMPIcluster()
>>>>>>>>>>>>>>>> registerDoMPI(cl)
>>>>>>>>>>>>>>>> Children_mcmc1 = foreach(i=1:40) %dopar% {
>>>>>>>>>>>>>>>> 	library(MCMCglmm)
>>>>>>>>>>>>>>>> 	load("rpqa1.rdata")
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> 	nitt = 40000; thin = 100; burnin = 10000
>>>>>>>>>>>>>>>> 	prior = list(
>>>>>>>>>>>>>>>> 		R = list(V = diag(c(1,1)), nu = 0.002),
>>>>>>>>>>>>>>>> 		G=list(list(V=diag(c(1,1e-6)),nu=0.002))
>>>>>>>>>>>>>>>> 	)
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> 	MCMCglmm( children ~ trait -1 +  
>>>>>>>>>>>>>>>> at.level(trait,1):male + at.level(trait,1):urban +  
>>>>>>>>>>>>>>>> at.level(trait,1):spouses +  
>>>>>>>>>>>>>>>> at.level(trait,1):paternalage.mean +  
>>>>>>>>>>>>>>>> at.level(trait,1):paternalage.factor,
>>>>>>>>>>>>>>>> 		rcov=~us(trait):units,
>>>>>>>>>>>>>>>> 		random=~us(trait):idParents,
>>>>>>>>>>>>>>>> 		family="zapoisson",
>>>>>>>>>>>>>>>> 		prior = prior,
>>>>>>>>>>>>>>>> 		data=rpqa.1,
>>>>>>>>>>>>>>>> 		pr = F, saveX = T, saveZ = T,
>>>>>>>>>>>>>>>> 		nitt=nitt,thin=thin,burnin=burnin)
>>>>>>>>>>>>>>>> }
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> library(coda)
>>>>>>>>>>>>>>>> mcmclist =  
>>>>>>>>>>>>>>>> mcmc.list(lapply(Children_mcmc1,FUN=function(x) {  
>>>>>>>>>>>>>>>> x$Sol}))
>>>>>>>>>>>>>>>> save(Children_mcmc1,mcmclist, file =  
>>>>>>>>>>>>>>>> "rpqa_mcmc_kids_za.rdata")
>>>>>>>>>>>>>>>> closeCluster(cl)
>>>>>>>>>>>>>>>> mpi.quit()
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> --
>>>>>>>>>>>>>>>> Ruben C. Arslan
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> Georg August University G?ttingen
>>>>>>>>>>>>>>>> Biological Personality Psychology and Psychological Assessment
>>>>>>>>>>>>>>>> Georg Elias M?ller Institute of Psychology
>>>>>>>>>>>>>>>> Go?lerstr. 14
>>>>>>>>>>>>>>>> 37073 G?ttingen
>>>>>>>>>>>>>>>> Germany
>>>>>>>>>>>>>>>> Tel.: +49 551 3920704
>>>>>>>>>>>>>>>> https://psych.uni-goettingen.de/en/biopers/team/arslan
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> 	[[alternative HTML version deleted]]
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>
>>>>>>>>>>>>>>
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> --
>>>>>>>>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>>>>>>>>> Scotland, with registration number SC005336.
>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>> --
>>>>>>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>>>>>>> Scotland, with registration number SC005336.
>>>>>>>>>>>>
>>>>>>>>>>>> _______________________________________________
>>>>>>>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>> --
>>>>>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>>>>>> Scotland, with registration number SC005336.
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> --
>>>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>>>> Scotland, with registration number SC005336.
>>>>>>>>>
>>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> --
>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>> Scotland, with registration number SC005336.
>>>>>>>
>>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>
>>>>>
>>>>>
>>>>> --
>>>>> The University of Edinburgh is a charitable body, registered in
>>>>> Scotland, with registration number SC005336.
>>>>>
>>>>>
>>>>
>>>>
>>>
>>>
>>> --
>>> The University of Edinburgh is a charitable body, registered in
>>> Scotland, with registration number SC005336.
>>>
>>>
>>
>>
>
>
>
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From r.travitzki at gmail.com  Fri Aug 29 10:23:05 2014
From: r.travitzki at gmail.com (Rodrigo Travitzki)
Date: Fri, 29 Aug 2014 09:23:05 +0100
Subject: [R-sig-ME] multilevel analysis with sample weighted data
In-Reply-To: <53FF343A.1060207@gmail.com>
References: <53FF0BFB.6060001@gmail.com> <53FF343A.1060207@gmail.com>
Message-ID: <54003869.70904@gmail.com>

On 28-08-2014 14:52, Ben Bolker wrote:
> On 14-08-28 07:01 AM, Rodrigo Travitzki wrote:
>> Dear R masters,
>> I'm looking for a R package to do multilevel analysis of a weighted data
>> (is a weigthed sample of brazilian educational data) but could not find
>> it. There is just a "weights" option in lme(), but is not about
>> frequency (or probability) weigths in data. In some foruns, no response
>> either.
>> So, could you please confirm this information for me? There is any R
>> package/function which do this? I really don't want to use proprietary
>> software, but if there is no option, I'll need to do so.
>> Thank you very much.
>>
>> Best wishes,
>> Rodrigo Travitzki
>    It depends a little bit what you want to do/the meaning of the
> weights.  I have successfully used weights=varFixed(~I(1/n))
> [inverse-variance weighting based on the number of samples per group] in
> lme; alternatively, you could use weights=n in lmer (from the lme4
> package) to get an equivalent result.
>
> If you want to deal with survey weighting, the story seems to be
> considerably more complicated -- I don't claim to understand it, but
> Andrew Gelman (a fairly prominent applied Bayesian statistician) claims
> that it's "a mess" (to use his phrase).  If the weights represent
> probability of inclusion in a survey, I believe he would recommend
> model-based inference -- that is, fit an unweighted multilevel
> regression model and then use post-stratification/weighting to make
> predictions (see http://andrewgelman.com/?s=survey+weights for various
> discussion and links to papers).
>
>    good luck,
>      Ben Bolker
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

Thanks, Ben!

It seems the problem is far more deeper than I expected.. Now I'm 
wondering how can this issue be so 'easy managed' in some proprietary 
softwares, like MLwiN, where you just need to insert the weights and voil?!
Anyway, I will read carefully the link you sent and see what can be done.

Rodrigo


From rubenarslan at gmail.com  Fri Aug 29 11:07:21 2014
From: rubenarslan at gmail.com (Ruben Arslan)
Date: Fri, 29 Aug 2014 11:07:21 +0200
Subject: [R-sig-ME] parallel MCMCglmm, RNGstreams,
	starting values & priors
In-Reply-To: <20140829081333.16792k7qrimekagw@www.staffmail.ed.ac.uk>
References: <4CD76FE1-D3F5-4980-9122-B0AC0D44FF81@gmail.com>
	<0E12EB43-72BC-42AC-9E74-9DF53DB42217@gmail.com>
	<20140825162907.10475jpywlu1wzs4@www.staffmail.ed.ac.uk>
	<0A463095-8656-49B7-9619-E557DD449E21@gmail.com>
	<20140825171414.10872gnlopk1we68@www.staffmail.ed.ac.uk>
	<20140825172936.15916weehiwjyc08@www.staffmail.ed.ac.uk>
	<8D35B834-0D31-486A-B5FB-0F279761FDB2@gmail.com>
	<49D60399-6902-45AC-80A9-9F3C35532228@gmail.com>
	<20140826120434.14613hxqhgwbhq80@www.staffmail.ed.ac.uk>
	<8557AE32-AFC9-4FD2-9C88-2D118B484637@gmail.com>
	<20140827183959.18662zc6hw5jj20w@www.staffmail.ed.ac.uk>
	<2D00600E-5287-4FE1-B605-82C0CBA286ED@gmail.com>
	<20140828180551.74212a0xoeoihn6s@www.staffmail.ed.ac.uk>
	<BBB5F7E3-75FE-4BA3-82B4-49DAA64873A4@gmail.com>
	<20140828195957.68171hjra56vrrr4@www.staffmail.ed.ac.uk>
	<E5B149F2-7773-4E2D-854C-3275A352A245@gmail.com>
	<20140829080442.1833246y8pj3itq8@www.staffmail.ed.ac.uk>
	<20140829081333.16792k7qrimekagw@www.staffmail.ed.ac.uk>
Message-ID: <7F4CEBA1-CFF9-4FBA-883B-8263CAC018EE@gmail.com>

Hi Jarrod,

that was exactly it. I hadn't checked the $VCV mcmclist, but I'll do so in the future
as the mistake is blindingly obvious that way: http://imgur.com/nlA0QwZ

After adding fix=2 to R1 in my starting values, my parallel chains converged as well.

For future amateurs reading this:
prior <- list(
	R=list(V=diag(2), nu=1.002, fix=2), 
	G=list(G1=list(V=diag(2), nu=1, alpha.mu=c(0,0), alpha.V=diag(2)*1000))
)

start <- list(
	liab=c(rnorm( nrow(krmh.1)*2 )), 
	R = list(R1 = rIW(diag(2), 10 , fix = 2)), ### FIX=2 HERE AS WELL
	G = list(G1 = rIW(diag(2), 10 ))
)

Thank you so much. This sort of remote diagnosis with this little information
seems borderline psychic to me.
Now, onwards to modelling the pedigrees :-)

Best wishes,

Ruben

PS.: I never actually figured out what kind of variability to use for rIW() in my starting values, 
but it doesn't seem to matter and that's what I should want I suppose. Actually, even with the mis-specified
starting values my posterior looked pretty similar to now.

On 29 Aug 2014, at 09:13, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:

> Hi Ruben,
> 
> Actually I might know what it is. When you sample different starting values do you inadvertently sample a new residual variance for the unidentified za part? You need to make sure that this is always fixed at the same value (otherwise the model is different). This is not a problem under the trait:units specification.
> 
> Cheers,
> 
> Jarrod.
> 
> 
> 
> Quoting Jarrod Hadfield <j.hadfield at ed.ac.uk> on Fri, 29 Aug 2014 08:04:42 +0100:
> 
>> Hi Ruben,
>> 
>> Can you share your data and I will take a look. Its definitely not Monte Carlo error.
>> 
>> Cheers,
>> 
>> Jarrod
>> 
>> 
>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Thu, 28 Aug 2014 22:44:47 +0200:
>> 
>>> Hi Jarrod,
>>> 
>>> those two matched up quite well yes. I just completed another 20 chains, using more variable
>>> starting values. There's still two fixed effects traitza_children:spouses  and :male which haven't converged
>>> according to multi-chain (gelman), but have according to geweke.
>>> The offending traces: http://imgur.com/Qm6Ovfr
>>> These specific effects aren't of interest to me, so if this doesn't affect the rest of my estimates, I can be happy
>>> with this, but I can't conclude that, can I?
>>> 
>>> I'm now also doing a run to see how it deals with the more intensely zero-inflated data when including
>>> the unmarried.
>>> 
>>> Thanks a lot for all that help,
>>> 
>>> Ruben
>>> 
>>>> gelman.diag(mcmclist)
>>> Potential scale reduction factors:
>>> 
>>>                                          Point est. Upper C.I.
>>> (Intercept)                                      1.00       1.00
>>> traitza_children                                 1.40       1.65
>>> male                                             1.00       1.00
>>> spouses                                          1.00       1.00
>>> paternalage.mean                                 1.00       1.00
>>> paternalage.factor(25,30]                        1.00       1.00
>>> paternalage.factor(30,35]                        1.00       1.00
>>> paternalage.factor(35,40]                        1.00       1.00
>>> paternalage.factor(40,45]                        1.00       1.00
>>> paternalage.factor(45,50]                        1.00       1.00
>>> paternalage.factor(50,55]                        1.00       1.00
>>> paternalage.factor(55,90]                        1.00       1.00
>>> traitza_children:male                            1.33       1.54
>>> traitza_children:spouses                         2.21       2.83
>>> traitza_children:paternalage.mean                1.01       1.02
>>> traitza_children:paternalage.factor(25,30]       1.05       1.08
>>> traitza_children:paternalage.factor(30,35]       1.08       1.13
>>> traitza_children:paternalage.factor(35,40]       1.15       1.25
>>> traitza_children:paternalage.factor(40,45]       1.15       1.26
>>> traitza_children:paternalage.factor(45,50]       1.26       1.43
>>> traitza_children:paternalage.factor(50,55]       1.15       1.25
>>> traitza_children:paternalage.factor(55,90]       1.14       1.23
>>> 
>>> Multivariate psrf
>>> 
>>> 8.99
>>> 
>>>> summary(mcmclist)
>>> 
>>> Iterations = 100001:149951
>>> Thinning interval = 50
>>> Number of chains = 20
>>> Sample size per chain = 1000
>>> 
>>> 1. Empirical mean and standard deviation for each variable,
>>>  plus standard error of the mean:
>>> 
>>>                                              Mean      SD  Naive SE Time-series SE
>>> (Intercept)                                 1.36326 0.04848 0.0003428      0.0003542
>>> traitza_children                           -0.76679 0.28738 0.0020321      0.0016682
>>> male                                        0.09980 0.01633 0.0001155      0.0001222
>>> spouses                                     0.12333 0.01957 0.0001384      0.0001414
>>> paternalage.mean                            0.07215 0.02194 0.0001551      0.0001596
>>> paternalage.factor(25,30]                  -0.03381 0.04184 0.0002959      0.0003066
>>> paternalage.factor(30,35]                  -0.08380 0.04270 0.0003019      0.0003118
>>> paternalage.factor(35,40]                  -0.16502 0.04569 0.0003231      0.0003289
>>> paternalage.factor(40,45]                  -0.16738 0.05090 0.0003599      0.0003697
>>> paternalage.factor(45,50]                  -0.18383 0.05880 0.0004158      0.0004242
>>> paternalage.factor(50,55]                  -0.18241 0.07277 0.0005146      0.0005302
>>> paternalage.factor(55,90]                  -0.40612 0.09875 0.0006983      0.0007467
>>> traitza_children:male                       0.12092 0.08223 0.0005815      0.0004697
>>> traitza_children:spouses                    0.64881 0.21132 0.0014942      0.0008511
>>> traitza_children:paternalage.mean          -0.02741 0.08550 0.0006046      0.0006221
>>> traitza_children:paternalage.factor(25,30] -0.17296 0.18680 0.0013209      0.0013750
>>> traitza_children:paternalage.factor(30,35] -0.19027 0.19267 0.0013624      0.0013901
>>> traitza_children:paternalage.factor(35,40] -0.24911 0.21282 0.0015049      0.0014391
>>> traitza_children:paternalage.factor(40,45] -0.29772 0.23403 0.0016548      0.0015956
>>> traitza_children:paternalage.factor(45,50] -0.51782 0.28589 0.0020215      0.0017602
>>> traitza_children:paternalage.factor(50,55] -0.46126 0.32064 0.0022673      0.0021397
>>> traitza_children:paternalage.factor(55,90] -0.38612 0.41461 0.0029317      0.0027396
>>> 
>>> 2. Quantiles for each variable:
>>> 
>>>                                              2.5%      25%      50%      75%      97.5%
>>> (Intercept)                                 1.26883  1.33106  1.36322  1.39575  1.4589722
>>> traitza_children                           -1.20696 -0.95751 -0.81076 -0.63308 -0.0365042
>>> male                                        0.06785  0.08878  0.09970  0.11085  0.1320168
>>> spouses                                     0.08467  0.11030  0.12343  0.13643  0.1617869
>>> paternalage.mean                            0.02950  0.05751  0.07202  0.08683  0.1153881
>>> paternalage.factor(25,30]                  -0.11581 -0.06174 -0.03397 -0.00574  0.0473783
>>> paternalage.factor(30,35]                  -0.16656 -0.11250 -0.08358 -0.05519  0.0003065
>>> paternalage.factor(35,40]                  -0.25518 -0.19530 -0.16500 -0.13440 -0.0757366
>>> paternalage.factor(40,45]                  -0.26887 -0.20164 -0.16675 -0.13335 -0.0677407
>>> paternalage.factor(45,50]                  -0.30080 -0.22320 -0.18339 -0.14440 -0.0687967
>>> paternalage.factor(50,55]                  -0.32663 -0.23034 -0.18227 -0.13317 -0.0415547
>>> paternalage.factor(55,90]                  -0.60202 -0.47303 -0.40454 -0.33994 -0.2139128
>>> traitza_children:male                      -0.01083  0.06634  0.11024  0.16109  0.3295892
>>> traitza_children:spouses                    0.37857  0.51072  0.59398  0.71395  1.2127940
>>> traitza_children:paternalage.mean          -0.19138 -0.08250 -0.02985  0.02493  0.1468989
>>> traitza_children:paternalage.factor(25,30] -0.57457 -0.28481 -0.16489 -0.05151  0.1728148
>>> traitza_children:paternalage.factor(30,35] -0.61499 -0.30350 -0.17736 -0.06299  0.1555147
>>> traitza_children:paternalage.factor(35,40] -0.74251 -0.36752 -0.22966 -0.10777  0.1151897
>>> traitza_children:paternalage.factor(40,45] -0.84165 -0.42691 -0.27729 -0.14322  0.1032436
>>> traitza_children:paternalage.factor(45,50] -1.21782 -0.66568 -0.48420 -0.32873 -0.0476720
>>> traitza_children:paternalage.factor(50,55] -1.21327 -0.63623 -0.43432 -0.24957  0.0955360
>>> traitza_children:paternalage.factor(55,90] -1.33772 -0.62227 -0.35364 -0.11050  0.3361684
>>> 
>>>> effectiveSize(mcmclist)
>>>                              (Intercept)                           traitza_children
>>>                                 18814.05                                   16359.33
>>>                                     male                                    spouses
>>>                                 18132.98                                   19547.05
>>>                         paternalage.mean                  paternalage.factor(25,30]
>>>                                 19238.72                                   18974.81
>>>                paternalage.factor(30,35]                  paternalage.factor(35,40]
>>>                                 18874.33                                   19406.63
>>>                paternalage.factor(40,45]                  paternalage.factor(45,50]
>>>                                 19075.18                                   19401.77
>>>                paternalage.factor(50,55]                  paternalage.factor(55,90]
>>>                                 18960.11                                   17893.23
>>>                    traitza_children:male                   traitza_children:spouses
>>>                                 18545.55                                   14438.51
>>>        traitza_children:paternalage.mean traitza_children:paternalage.factor(25,30]
>>>                                 18464.09                                   16943.43
>>> traitza_children:paternalage.factor(30,35] traitza_children:paternalage.factor(35,40]
>>>                                 16827.44                                   17230.04
>>> traitza_children:paternalage.factor(40,45] traitza_children:paternalage.factor(45,50]
>>>                                 17144.78                                   18191.67
>>> traitza_children:paternalage.factor(50,55] traitza_children:paternalage.factor(55,90]
>>>                                 17466.60                                   18540.59
>>> 
>>> 
>>> ### current script:
>>> 
>>> # bsub -q mpi -W 24:00 -n 21 -R np20 mpirun -H localhost -n 21 R --slave -f "/usr/users/rarslan/rpqa/krmh_main/children.R"
>>> setwd("/usr/users/rarslan/rpqa/")
>>> library(doMPI)
>>> cl <- startMPIcluster(verbose=T,workdir="/usr/users/rarslan/rpqa/krmh_main/")
>>> registerDoMPI(cl)
>>> Children = foreach(i=1:clusterSize(cl),.options.mpi = list(seed=1337) ) %dopar% {
>>> 	library(MCMCglmm);library(data.table)
>>>   setwd("/usr/users/rarslan/rpqa/krmh_main/")
>>> 	source("../1 - extraction functions.r")
>>>   load("../krmh1.rdata")
>>> 
>>> 	krmh.1 = recenter.pat(na.omit(krmh.1[spouses>0, list(idParents, children, male, spouses, paternalage)]))
>>> 
>>> 	samples = 1000
>>> 	thin = 50; burnin = 100000
>>> 	nitt = samples * thin + burnin
>>> 
>>> 	prior <- list(
>>> 		R=list(V=diag(2), nu=1.002, fix=2),
>>> 		G=list(G1=list(V=diag(2), nu=1, alpha.mu=c(0,0), alpha.V=diag(2)*1000))
>>> 	)
>>> 
>>> 	start <- list(
>>> 		liab=c(rnorm( nrow(krmh.1)*2 )),
>>> 		R = list(R1 = rIW(diag(2), 10 )),
>>> 		G = list(G1 = rIW(diag(2), 10 ))
>>> 	)
>>> 
>>> 	( m1 = MCMCglmm( children ~ trait * (male + spouses + paternalage.mean + paternalage.factor),
>>> 						rcov=~idh(trait):units,
>>> 						random=~idh(trait):idParents,
>>> 						family="zapoisson",
>>> 						start = start,
>>> 						prior = prior,
>>> 						data=krmh.1,
>>> 						pr = F, saveX = F, saveZ = F,
>>> 						nitt=nitt,thin=thin,burnin=burnin)
>>> 	)
>>> 		m1$Residual$nrt<-2
>>> 	m1
>>> }
>>> 
>>> save(Children,file = "Children.rdata")
>>> closeCluster(cl)
>>> mpi.quit()
>>> 
>>> On 28 Aug 2014, at 20:59, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>> 
>>>> Hi,
>>>> 
>>>> The posteriors for the two models look pretty close to me. Are the scale reduction factors really as high as previously reported? Before you had 1.83 for traitza_children:spouses, but the plot suggests that it should be close to 1?
>>>> 
>>>> Cheers,
>>>> 
>>>> Jarrod
>>>> 
>>>> 
>>>> 
>>>> 
>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Thu, 28 Aug 2014 19:59:16 +0200:
>>>> 
>>>>> Sure! Thanks a lot.
>>>>> I am using ~idh(trait):units already, sorry for saying that incorrectly in my last email.
>>>>> These models aren't the final thing, I will replace the paternalage.factor variable
>>>>> with its linear equivalent if that seems defensible (does so far) and in this model it seems
>>>>> okay to remove the za-effects for all predictors except spouses.
>>>>> So a final model would have fewer fixed effects. I also have datasets of 200k+ and 5m+,
>>>>> but I'm learning MCMCglmm with this smaller one because my wrong turns take less time.
>>>>> 
>>>>> I've uploaded a comparison coef plot of two models:
>>>>> http://i.imgur.com/sHUfnmd.png
>>>>> m7 is with the default starting values, m1 is with the specification I sent in my last email. I don't
>>>>> know if such differences are something to worry about.
>>>>> 
>>>>> I don't know what qualifies as highly overdispersed, here's a plot of the outcome for ever
>>>>> married people (slate=real data):
>>>>> http://imgur.com/14MywgZ
>>>>> here's with everybody born (incl. some stillborn etc.):
>>>>> http://imgur.com/knRGa1v
>>>>> I guess my approach (generating an overdispersed poisson with the parameters from
>>>>> the data and checking if it has as excess zeroes) is not the best way to diagnose zero-inflation,
>>>>> but especially in the second case it seems fairly clear-cut.
>>>>> 
>>>>> Best regards,
>>>>> 
>>>>> Ruben
>>>>> 
>>>>>> summary(m1)
>>>>> 
>>>>> Iterations = 50001:149951
>>>>> Thinning interval  = 50
>>>>> Sample size  = 2000
>>>>> 
>>>>> DIC: 31249.73
>>>>> 
>>>>> G-structure:  ~idh(trait):idParents
>>>>> 
>>>>>                    post.mean  l-95% CI u-95% CI eff.samp
>>>>> children.idParents     0.006611 4.312e-08   0.0159    523.9
>>>>> za_children.idParents  0.193788 7.306e-02   0.3283    369.3
>>>>> 
>>>>> R-structure:  ~idh(trait):units
>>>>> 
>>>>>                post.mean l-95% CI u-95% CI eff.samp
>>>>> children.units       0.1285   0.1118   0.1452    716.1
>>>>> za_children.units    0.9950   0.9950   0.9950      0.0
>>>>> 
>>>>> Location effects: children ~ trait * (male + spouses + paternalage.mean + paternalage.factor)
>>>>> 
>>>>>                                          post.mean   l-95% CI   u-95% CI eff.samp  pMCMC
>>>>> (Intercept)                                 1.3413364  1.2402100  1.4326099     1789 <5e-04 ***
>>>>> traitza_children                           -0.8362879 -1.2007980 -0.5016730     1669 <5e-04 ***
>>>>> male                                        0.0994902  0.0679050  0.1297394     2000 <5e-04 ***
>>>>> spouses                                     0.1236033  0.0839000  0.1624939     2000 <5e-04 ***
>>>>> paternalage.mean                            0.0533892  0.0119569  0.0933960     2000  0.015 *
>>>>> paternalage.factor(25,30]                  -0.0275822 -0.1116421  0.0537359     1842  0.515
>>>>> paternalage.factor(30,35]                  -0.0691025 -0.1463214  0.0122393     1871  0.097 .
>>>>> paternalage.factor(35,40]                  -0.1419933 -0.2277379 -0.0574678     1845 <5e-04 ***
>>>>> paternalage.factor(40,45]                  -0.1364952 -0.2362714 -0.0451874     1835  0.007 **
>>>>> paternalage.factor(45,50]                  -0.1445342 -0.2591767 -0.0421178     1693  0.008 **
>>>>> paternalage.factor(50,55]                  -0.1302972 -0.2642965  0.0077061     2000  0.064 .
>>>>> paternalage.factor(55,90]                  -0.3407879 -0.5168972 -0.1493652     1810 <5e-04 ***
>>>>> traitza_children:male                       0.0926888 -0.0147379  0.2006142     1901  0.098 .
>>>>> traitza_children:spouses                    0.5531197  0.3870616  0.7314289     1495 <5e-04 ***
>>>>> traitza_children:paternalage.mean           0.0051463 -0.1279396  0.1460099     1617  0.960
>>>>> traitza_children:paternalage.factor(25,30] -0.1538957 -0.4445749  0.1462955     1781  0.321
>>>>> traitza_children:paternalage.factor(30,35] -0.1747883 -0.4757851  0.1162476     1998  0.261
>>>>> traitza_children:paternalage.factor(35,40] -0.2261843 -0.5464379  0.0892582     1755  0.166
>>>>> traitza_children:paternalage.factor(40,45] -0.2807543 -0.6079678  0.0650281     1721  0.100 .
>>>>> traitza_children:paternalage.factor(45,50] -0.4905843 -0.8649214 -0.1244174     1735  0.010 **
>>>>> traitza_children:paternalage.factor(50,55] -0.4648579 -0.9215759 -0.0002083     1687  0.054 .
>>>>> traitza_children:paternalage.factor(55,90] -0.3945406 -1.0230155  0.2481568     1793  0.195
>>>>> ---
>>>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>>> 
>>>>>> describe(krmh.1[spouses>0,])
>>>>>                  vars    n mean   sd median trimmed  mad   min   max range skew kurtosis   se
>>>>> children               2 6829 3.81 2.93   4.00    3.61 2.97  0.00 16.00 16.00 0.47    -0.46 0.04
>>>>> male                   3 6829 0.46 0.50   0.00    0.45 0.00  0.00  1.00  1.00 0.14    -1.98 0.01
>>>>> spouses                4 6829 1.14 0.38   1.00    1.03 0.00  1.00  4.00  3.00 2.87     8.23 0.00
>>>>> paternalage            5 6829 3.65 0.80   3.57    3.60 0.80  1.83  7.95  6.12 0.69     0.70 0.01
>>>>> paternalage_c          6 6829 0.00 0.80  -0.08   -0.05 0.80 -1.82  4.30  6.12 0.69     0.70 0.01
>>>>> paternalage.mean       7 6829 0.00 0.68  -0.08   -0.05 0.59 -1.74  4.30  6.04 0.95     1.97 0.01
>>>>> paternalage.diff       8 6829 0.00 0.42   0.00   -0.01 0.38 -1.51  1.48  2.99 0.17     0.17 0.01
>>>>> 
>>>>>> table(krmh.1$paternalage.factor)
>>>>> 
>>>>> [0,25] (25,30] (30,35] (35,40] (40,45] (45,50] (50,55] (55,90]
>>>>>  309    1214    1683    1562    1039     623     269     130
>>>>> 
>>>>> On 28 Aug 2014, at 19:05, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>>>> 
>>>>>> Hi Ruben,
>>>>>> 
>>>>>> It might be hard to detect (near) ECPs with so many fixed effects (can you post the model summary (and give us the mean and standard deviation of any continuous covariates)). Also, the complementary log-log link (which is the za specification) is non-symmetric and runs into problems outside the range -35 to 3.5 so there may be a problem there, particularly if you use rcov=~trait:units and the Poisson part is highly over-dispersed.  You could try rcov=~idh(trait):units and fix the non-identifiable za residual variance to something smaller than 1 (say 0.5)  - it will mix slower but it will reduce the chance of over/underflow.
>>>>>> 
>>>>>> Cheers,
>>>>>> 
>>>>>> Jarrod
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Thu, 28 Aug 2014 18:45:30 +0200:
>>>>>> 
>>>>>>> Hi Jarrod,
>>>>>>> 
>>>>>>>> 1) it did not return an error with rcov = ~trait:units because you used R1=rpois(2,1)+1 and yet this specification only fits a single variance (not a 2x2 covariance matrix). R1=rpois(2,1)+1 is a bit of a weird specification since it has to be integer. I would obtain starting values using rIW().
>>>>>>> 
>>>>>>> I agree it's a weird specification, I was a bit lost and thought I could get away with just putting some random numbers in the starting value.
>>>>>>> I didn't do R1=rpois(2,1)+1 though, I did R1=diag(rpois(2,1)+1), so I got a 2x2 matrix, but yes, bound to be integer.
>>>>>>> I didn't know starting values should come from a conjugate distribution, though that probably means I didn't think about it much.
>>>>>>> 
>>>>>>> I'm now doing
>>>>>>> start <- list(
>>>>>>> 	liab=c(rnorm( nrow(krmh.1)*2 )),
>>>>>>> 	R = list(R1 = rIW( diag(2), nrow(krmh.1)) ),
>>>>>>> 	G = list(G1 = rIW( diag(2), nrow(krmh.1)) )
>>>>>>> )
>>>>>>> 
>>>>>>> Is this what you had in mind?
>>>>>>> I am especially unsure if I am supposed to use such a low sampling variability (my sample size is probably not even relevant for the starting values) and if I should start from diag(2).
>>>>>>> 
>>>>>>> And, I am still happily confused that this specification still doesn't lead to errors with respect to rcov = ~trait:units . Does this mean I'm doing it wrong?
>>>>>>> 
>>>>>>>> 3) a) how many effective samples do you have for each parameter? and b) are you getting extreme category problems/numerical issues? If you store the latent variables (pl=TUE) what is their range for the Zi/za part?
>>>>>>> 
>>>>>>> My parallel run using the above starting values isn't finished yet.
>>>>>>> a) After applying the above starting values I get, for the location effects 1600-2000 samples for a 2000 sample chain (with thin set to 50). G and R-structure are from 369 (za_children.idParents) to 716 (and 0 for the fixed part).
>>>>>>> Effective sample sizes were similar for my run using the starting values for G/R that I drew from rpois, and using 40 chains I of course get
>>>>>>> b) I don't think I am getting extreme categories. I would probably be getting extreme categories if I included the forever-alones (they almost never have children), but this way no.
>>>>>>> I wasn't sure how to examine the range of the latents separately for the za part, but for a single chain it looks okay:
>>>>>>>> quantile(as.numeric(m1$Liab),probs = c(0,0.01,0,0.99,1))
>>>>>>>    0%        1%        0%       99%      100%
>>>>>>> -4.934111 -1.290728 -4.934111  3.389847  7.484206
>>>>>>> 
>>>>>>> Well, all considered now that I use the above starting value specification I get slightly different estimates for all za-coefficients. Nothing major, but still leading me to
>>>>>>> think my estimates aren't exactly independent of the starting values I use. I'll see what the parallel run yields.
>>>>>>> 
>>>>>>> Thanks a lot,
>>>>>>> 
>>>>>>> Ruben
>>>>>>> 
>>>>>>>> 
>>>>>>>> Cheers,
>>>>>>>> 
>>>>>>>> Jarrod
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Wed, 27 Aug 2014 19:23:42 +0200:
>>>>>>>> 
>>>>>>>>> Hi Jarrod,
>>>>>>>>> 
>>>>>>>>> thanks again. I was able to get it running with your advice.
>>>>>>>>> Some points of confusion remain:
>>>>>>>>> 
>>>>>>>>> - You wrote that zi/za models would return an error with rcov = ~trait:units + starting values. This did not happen in my case, so I didn't build MCMCglmm myself with your suggested edits. Also, have you considered putting your own MCMCglmm repo on Github? Your users would be able to install pre-releases and I'd think you'd get some time-saving pull requests too.
>>>>>>>>> - In my attempts to get my models to run properly, I messed up a prior and did not use fix=2 in my prior specification for my za models. This led to crappy convergence, it's much better now and for some of my simpler models I think I won't need parallel chains. I'm reminded of Gelman's folk theorem of statistical computing.
>>>>>>>>> - I followed your advice, but of course I could not set the true values as starting values, but wanted to set random, bad starting values. I pasted below what I arrived at, I'm especially unsure whether I specified the starting values for G and R properly (I think not).
>>>>>>>>> 	start <- list(
>>>>>>>>> 		liab=c(rnorm( nrow(krmh.1)*2 )),
>>>>>>>>> 		R = list(R1 = diag(rpois(2, 1)+1)),
>>>>>>>>> 		G = list(G1 = diag(rpois(2, 1)+1))
>>>>>>>>> 	)
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> However, even though I may not need multiple chains for some of my simpler models, I've now run into conflicting diagnostics. The geweke.diag for each chain (and examination of the traces) gives
>>>>>>>>> satisfactory diagnostics. Comparing multiple chains using gelman.diag, however, leads to one bad guy, namely the traitza_children:spouses interaction.
>>>>>>>>> I think this implies that I've got some starting value dependence for this parameter, that won't be easily rectified through longer burnin?
>>>>>>>>> Do you have any ideas how to rectify this?
>>>>>>>>> I am currently doing sequential analyses on episodes of selection and in historical human data only those who marry have a chance at having kids. I exclude the unmarried
>>>>>>>>> from my sample where I predict number of children, because I examine that in a previous model and the zero-inflation (65% zeros, median w/o unmarried = 4) when including the unmarried is so excessive.
>>>>>>>>> Number of spouses is easily the strongest predictor in the model, but only serves as a covariate here. Since my other estimates are stable across chains and runs and agree well across models and with theory, I'm
>>>>>>>>> inclined to shrug this off. But probably I shouldn't ignore this sign of non-convergence?
>>>>>>>>> 
>>>>>>>>>> gelman.diag(mcmc_1)
>>>>>>>>> Potential scale reduction factors:
>>>>>>>>> 
>>>>>>>>>                                       Point est. Upper C.I.
>>>>>>>>> (Intercept)                                      1.00       1.00
>>>>>>>>> traitza_children                                 1.27       1.39
>>>>>>>>> male                                             1.00       1.00
>>>>>>>>> spouses                                          1.00       1.00
>>>>>>>>> paternalage.mean                                 1.00       1.00
>>>>>>>>> paternalage.factor(25,30]                        1.00       1.00
>>>>>>>>> paternalage.factor(30,35]                        1.00       1.00
>>>>>>>>> paternalage.factor(35,40]                        1.00       1.00
>>>>>>>>> paternalage.factor(40,45]                        1.00       1.00
>>>>>>>>> paternalage.factor(45,50]                        1.00       1.00
>>>>>>>>> paternalage.factor(50,55]                        1.00       1.00
>>>>>>>>> paternalage.factor(55,90]                        1.00       1.00
>>>>>>>>> traitza_children:male                            1.22       1.32
>>>>>>>>> traitza_children:spouses                         1.83       2.13
>>>>>>>>> traitza_children:paternalage.mean                1.02       1.02
>>>>>>>>> traitza_children:paternalage.factor(25,30]       1.03       1.05
>>>>>>>>> traitza_children:paternalage.factor(30,35]       1.05       1.08
>>>>>>>>> traitza_children:paternalage.factor(35,40]       1.10       1.15
>>>>>>>>> traitza_children:paternalage.factor(40,45]       1.12       1.17
>>>>>>>>> traitza_children:paternalage.factor(45,50]       1.19       1.28
>>>>>>>>> traitza_children:paternalage.factor(50,55]       1.12       1.18
>>>>>>>>> traitza_children:paternalage.factor(55,90]       1.11       1.17
>>>>>>>>> 
>>>>>>>>> Multivariate psrf
>>>>>>>>> 
>>>>>>>>> 7.27
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> Best regards,
>>>>>>>>> 
>>>>>>>>> Ruben
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> On 26 Aug 2014, at 13:04, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>>>>>>>> 
>>>>>>>>>> Hi Ruben,
>>>>>>>>>> 
>>>>>>>>>> There are 400 liabilities in a zapoisson model (2 per datum). This code should work:
>>>>>>>>>> 
>>>>>>>>>> g <-sample(letters[1:10], size = 200, replace = T)
>>>>>>>>>> pred <- rnorm(200)
>>>>>>>>>> 
>>>>>>>>>> l1<-rnorm(200, -1, sqrt(1))
>>>>>>>>>> l2<-rnorm(200, -1, sqrt(1))
>>>>>>>>>> 
>>>>>>>>>> y<-VGAM::rzapois(200, exp(l1), exp(-exp(l2)))
>>>>>>>>>> 
>>>>>>>>>> # generate zero-altered data with an intercept of -1 (because the intercept and variance are the same for both processes this is just standard Poisson)
>>>>>>>>>> 
>>>>>>>>>> dat<-data.frame(y=y, g = g, pred = pred)
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> start.1<-list(liab=c(l1,l2), R = list(R1=diag(2)), G=list(G1=diag(2)))
>>>>>>>>>> prior.1<-list(R=list(V=diag(2), nu=1.002, fix=2), G=list(G1=list(V=diag(2), nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000)))
>>>>>>>>>> 
>>>>>>>>>> m1<-MCMCglmm(y~trait + pred:trait, random=~us(trait):g, family="zapoisson",rcov=~idh(trait):units, data=dat, prior=prior.1, start= start.1)
>>>>>>>>>> 
>>>>>>>>>> However, there are 2 bugs in the current version of MCMCglmm that return an error message when the documentation implies it should be fine:
>>>>>>>>>> 
>>>>>>>>>> a) it should be possible to have R=diag(2) rather than R = list(R1=diag(2)). This bug cropped up when I implemented block-diagonal R structures. It can be fixed by inserting:
>>>>>>>>>> 
>>>>>>>>>>     if(!is.list(start$R)){
>>>>>>>>>>        start$R<-list(R1=start$R)
>>>>>>>>>>     }
>>>>>>>>>> 
>>>>>>>>>> on L514 of MCMCglmm.R below
>>>>>>>>>> 
>>>>>>>>>>     if(!is.list(prior$R[[1]])){
>>>>>>>>>>        prior$R<-list(R1=prior$R)
>>>>>>>>>>     }
>>>>>>>>>> 
>>>>>>>>>> b) rcov=~trait:units models for zi/za models will return an error when passing starting values. To fix this insert
>>>>>>>>>> 
>>>>>>>>>>    if(diagR==3){
>>>>>>>>>>      if(dim(start)[1]!=1){
>>>>>>>>>>        stop("V is the wrong dimension for some strart$G/start$R elements")
>>>>>>>>>>      }
>>>>>>>>>>      start<-diag(sum(nfl))*start[1]
>>>>>>>>>>    }
>>>>>>>>>> 
>>>>>>>>>> on L90 of priorfromat.R below
>>>>>>>>>> 
>>>>>>>>>>    if(is.matrix(start)==FALSE){
>>>>>>>>>>      start<-as.matrix(start)
>>>>>>>>>>    }
>>>>>>>>>> 
>>>>>>>>>> I will put these in the new version.
>>>>>>>>>> 
>>>>>>>>>> Cheers,
>>>>>>>>>> 
>>>>>>>>>> Jarrod
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25 Aug 2014 21:52:30 +0200:
>>>>>>>>>> 
>>>>>>>>>>> Hi Jarrod,
>>>>>>>>>>> 
>>>>>>>>>>> thanks for these pointers.
>>>>>>>>>>> 
>>>>>>>>>>>>> You will need to provide over-dispersed starting values for multiple-chain convergence diagnostics to be useful (GLMM are so simple I am generally happy if the output of a single run looks reasonable).
>>>>>>>>>>> 
>>>>>>>>>>> Oh, I would be happy with single chains, but since computation would take weeks this way, I wanted to parallelise and I would use the multi-chain convergence as a criterion that my parallelisation was proper
>>>>>>>>>>> and is as informative as a single long chain. There don't seem to be any such checks built-in ? I was analysing my 40 chains for a bit longer than I like to admit until I noticed they were identical (effectiveSize
>>>>>>>>>>> and summary.mcmc.list did not yell at me for this).
>>>>>>>>>>> 
>>>>>>>>>>>>> # use some very bad starting values
>>>>>>>>>>> I get that these values are bad, but that is the goal for my multi-chain aim, right?
>>>>>>>>>>> 
>>>>>>>>>>> I can apply this to my zero-truncated model, but am again getting stuck with the zero-altered one.
>>>>>>>>>>> Maybe I need only specify the Liab values for this?
>>>>>>>>>>> At least I'm getting nowhere with specifying R and G starting values here. When I got an error, I always
>>>>>>>>>>> went to the MCMCglmm source to understand why the checks failed, but I didn't always understand
>>>>>>>>>>> what was being checked and couldn't get it to work.
>>>>>>>>>>> 
>>>>>>>>>>> Here's a failing example:
>>>>>>>>>>> 
>>>>>>>>>>> l<-rnorm(200, -1, sqrt(1))
>>>>>>>>>>> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
>>>>>>>>>>> g = sample(letters[1:10], size = 200, replace = T)
>>>>>>>>>>> pred = rnorm(200)
>>>>>>>>>>> y<-rpois(200,exp(l)-t)
>>>>>>>>>>> y[1:40] = 0
>>>>>>>>>>> # generate zero-altered data with an intercept of -1
>>>>>>>>>>> 
>>>>>>>>>>> dat<-data.frame(y=y, g = g, pred = pred)
>>>>>>>>>>> set.seed(1)
>>>>>>>>>>> start_true = list(Liab=l, R = 1, G = 1 )
>>>>>>>>>>> m1<-MCMCglmm(y~1 + pred,random = ~ g, family="zapoisson",rcov=~us(trait):units, data=dat, start= start_true)
>>>>>>>>>>> 
>>>>>>>>>>> # use true latent variable as starting values
>>>>>>>>>>> set.seed(1)
>>>>>>>>>>> # use some very bad starting values
>>>>>>>>>>> start_rand = list(Liab=rnorm(200), R = rpois(1, 1)+1, G = rpois(1, 1)+1 )
>>>>>>>>>>> m2<-MCMCglmm(y~1 + pred,random = ~ g,rcov=~us(trait):units,  family="zapoisson", data=dat, start = start_rand)
>>>>>>>>>>> 
>>>>>>>>>>> Best,
>>>>>>>>>>> 
>>>>>>>>>>> Ruben
>>>>>>>>>>> 
>>>>>>>>>>> On 25 Aug 2014, at 18:29, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>>>>>>>>>> 
>>>>>>>>>>>> Hi Ruben,
>>>>>>>>>>>> 
>>>>>>>>>>>> Sorry  - I was wrong when I said that everything is Gibbs sampled conditional on the latent variables. The location effects (fixed and random effects) are also sampled conditional on the (co)variance components so you should add them to the starting values. In the case where the true values are used:
>>>>>>>>>>>> 
>>>>>>>>>>>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat, start=list(Liab=l,R=1))
>>>>>>>>>>>> 
>>>>>>>>>>>> Cheers,
>>>>>>>>>>>> 
>>>>>>>>>>>> Jarrod
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> Quoting Jarrod Hadfield <j.hadfield at ed.ac.uk> on Mon, 25 Aug 2014 17:14:14 +0100:
>>>>>>>>>>>> 
>>>>>>>>>>>>> Hi Ruben,
>>>>>>>>>>>>> 
>>>>>>>>>>>>> You will need to provide over-dispersed starting values for multiple-chain convergence diagnostics to be useful (GLMM are so simple I am generally happy if the output of a single run looks reasonable).
>>>>>>>>>>>>> 
>>>>>>>>>>>>> With non-Gaussian data everything is Gibbs sampled conditional on the latent variables, so you only need to pass them:
>>>>>>>>>>>>> 
>>>>>>>>>>>>> l<-rnorm(200, -1, sqrt(1))
>>>>>>>>>>>>> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
>>>>>>>>>>>>> y<-rpois(200,exp(l)-t)+1
>>>>>>>>>>>>> # generate zero-truncated data with an intercept of -1
>>>>>>>>>>>>> 
>>>>>>>>>>>>> dat<-data.frame(y=y)
>>>>>>>>>>>>> set.seed(1)
>>>>>>>>>>>>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat, start=list(Liab=l))
>>>>>>>>>>>>> # use true latent variable as starting values
>>>>>>>>>>>>> set.seed(1)
>>>>>>>>>>>>> m2<-MCMCglmm(y~1, family="ztpoisson", data=dat, start=list(Liab=rnorm(200)))
>>>>>>>>>>>>> # use some very bad starting values
>>>>>>>>>>>>> 
>>>>>>>>>>>>> plot(mcmc.list(m1$Sol, m2$Sol))
>>>>>>>>>>>>> # not identical despite the same seed because of different starting values but clearly sampling the same posterior distribution:
>>>>>>>>>>>>> 
>>>>>>>>>>>>> gelman.diag(mcmc.list(m1$Sol, m2$Sol))
>>>>>>>>>>>>> 
>>>>>>>>>>>>> Cheers,
>>>>>>>>>>>>> 
>>>>>>>>>>>>> Jarrod
>>>>>>>>>>>>> 
>>>>>>>>>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25 Aug 2014 18:00:08 +0200:
>>>>>>>>>>>>> 
>>>>>>>>>>>>>> Dear Jarrod,
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> thanks for the quick reply. Please, don't waste time looking into doMPI ? I am happy that I
>>>>>>>>>>>>>> get the expected result, when I specify that reproducible seed, whyever that may be.
>>>>>>>>>>>>>> I'm pretty sure that is the deciding factor, because I tested it explicitly, I just have no idea
>>>>>>>>>>>>>> how/why it interacts with the choice of family.
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> That said, is setting up different RNG streams for my workers (now that it works) __sufficient__
>>>>>>>>>>>>>> so that I get independent chains and can use gelman.diag() for convergence diagnostics?
>>>>>>>>>>>>>> Or should I still tinker with the starting values myself?
>>>>>>>>>>>>>> I've never found a worked example of supplying starting values and am thus a bit lost.
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> Sorry for sending further questions, I hope someone else takes pity while
>>>>>>>>>>>>>> you're busy with lectures.
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> Best wishes
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> Ruben
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> On 25 Aug 2014, at 17:29, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> Hi Ruben,
>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> I do not think the issue is with the starting values, because even if the same starting values were used the chains would still differ because of the randomness in the Markov Chain (if I interpret your `identical' test correctly). This just involves a call to GetRNGstate() in the C++ code (L 871 ofMCMCglmm.cc) so I think for some reason doMPI/foreach is not doing what you expect. I am not familiar with doMPI and am in the middle of writing lectures so haven't got time to look into it carefully. Outside of the context of doMPI I get the behaviour I expect:
>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> l<-rnorm(200, -1, sqrt(1))
>>>>>>>>>>>>>>> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
>>>>>>>>>>>>>>> y<-rpois(200,exp(l)-t)+1
>>>>>>>>>>>>>>> # generate zero-truncated data with an intercept of -1
>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> dat<-data.frame(y=y)
>>>>>>>>>>>>>>> set.seed(1)
>>>>>>>>>>>>>>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>>>>>>>>>>>>> set.seed(2)
>>>>>>>>>>>>>>> m2<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>>>>>>>>>>>>> set.seed(2)
>>>>>>>>>>>>>>> m3<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> plot(mcmc.list(m1$Sol, m2$Sol))
>>>>>>>>>>>>>>> # different, as expected
>>>>>>>>>>>>>>> plot(mcmc.list(m2$Sol, m3$Sol))
>>>>>>>>>>>>>>> # the same, as expected
>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25 Aug 2014 16:58:06 +0200:
>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>> Dear list,
>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>> sorry for bumping my old post, I hope to elicit a response with a more focused question:
>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>> When does MCMCglmm automatically start from different values when using doMPI/foreach?
>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>> I have done some tests with models of varying complexity. For example, the script in my last
>>>>>>>>>>>>>>>> post (using "zapoisson") yielded 40 identical chains:
>>>>>>>>>>>>>>>>> identical(mcmclist[1], mcmclist[30])
>>>>>>>>>>>>>>>> TRUE
>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>> A simpler (?) model (using "ztpoisson" and no specified prior), however, yielded different chains
>>>>>>>>>>>>>>>> and I could use them to calculate gelman.diag()
>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>> Changing my script to the version below, i.e. seeding foreach using .options.mpi=list( seed= 1337)
>>>>>>>>>>>>>>>> so as to make RNGstreams reproducible (or so I  thought), led to different chains even for the
>>>>>>>>>>>>>>>> "zapoisson" model.
>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>> In no case have I (successfully) tried to supplant the default of MCMCglmm's "start" argument.
>>>>>>>>>>>>>>>> Is starting my models from different RNGsubstreams inadequate compared to manipulating
>>>>>>>>>>>>>>>> the start argument explicitly? If so, is there any worked example of explicit starting value manipulation
>>>>>>>>>>>>>>>> in parallel computation?
>>>>>>>>>>>>>>>> I've browsed the MCMCglmm source to understand how the default starting values are generated,
>>>>>>>>>>>>>>>> but didn't find any differences with respect to RNG for the two families "ztpoisson" and "zapoisson"
>>>>>>>>>>>>>>>> (granted, I did not dig very deep).
>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>> Best regards,
>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>> Ruben Arslan
>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>> # bsub -q mpi -W 12:00 -n 41 -R np20 mpirun -H localhost -n 41 R --slave -f "/usr/users/rarslan/rpqa/rpqa_main/rpqa_children_parallel.R"
>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>> library(doMPI)
>>>>>>>>>>>>>>>> cl <- startMPIcluster(verbose=T,workdir="/usr/users/rarslan/rpqa/rpqa_main/")
>>>>>>>>>>>>>>>> registerDoMPI(cl)
>>>>>>>>>>>>>>>> Children_mcmc1 = foreach(i=1:clusterSize(cl),.options.mpi = list(seed=1337) ) %dopar% {
>>>>>>>>>>>>>>>> 	library(MCMCglmm);library(data.table)
>>>>>>>>>>>>>>>> 	load("/usr/users/rarslan/rpqa/rpqa1.rdata")
>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>> 	nitt = 130000; thin = 100; burnin = 30000
>>>>>>>>>>>>>>>> 	prior.m5d.2 = list(
>>>>>>>>>>>>>>>> 		R = list(V = diag(c(1,1)), nu = 0.002),
>>>>>>>>>>>>>>>> 		G=list(list(V=diag(c(1,1e-6)),nu=0.002))
>>>>>>>>>>>>>>>> 	)
>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>> 	rpqa.1 = na.omit(rpqa.1[spouses>0, list(idParents, children, male, urban, spouses, paternalage.mean, paternalage.factor)])
>>>>>>>>>>>>>>>> 	(m1 = MCMCglmm( children ~ trait * (male + urban + spouses + paternalage.mean + paternalage.factor),
>>>>>>>>>>>>>>>> 						rcov=~us(trait):units,
>>>>>>>>>>>>>>>> 						random=~us(trait):idParents,
>>>>>>>>>>>>>>>> 						family="zapoisson",
>>>>>>>>>>>>>>>> 						prior = prior.m5d.2,
>>>>>>>>>>>>>>>> 						data=rpqa.1,
>>>>>>>>>>>>>>>> 						pr = F, saveX = F, saveZ = F,
>>>>>>>>>>>>>>>> 						nitt=nitt,thin=thin,burnin=burnin))
>>>>>>>>>>>>>>>> }
>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>> library(coda)
>>>>>>>>>>>>>>>> mcmclist = mcmc.list(lapply(Children_mcmc1,FUN=function(x) { x$Sol}))
>>>>>>>>>>>>>>>> save(Children_mcmc1,mcmclist, file = "/usr/users/rarslan/rpqa/rpqa_main/rpqa_mcmc_kids_za.rdata")
>>>>>>>>>>>>>>>> closeCluster(cl)
>>>>>>>>>>>>>>>> mpi.quit()
>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>> On 04 Aug 2014, at 20:25, Ruben Arslan <rubenarslan at gmail.com> wrote:
>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>> Dear list,
>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>> would someone be willing to share her or his efforts in parallelising a MCMCglmm analysis?
>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>> I had something viable using harvestr that seemed to properly initialise
>>>>>>>>>>>>>>>>> the starting values from different random number streams (which is desirable,
>>>>>>>>>>>>>>>>> as far as I could find out), but I ended up being unable to use harvestr, because
>>>>>>>>>>>>>>>>> it uses an old version of plyr, where parallelisation works only for multicore, not for
>>>>>>>>>>>>>>>>> MPI.
>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>> I pasted my working version, that does not do anything about starting values or RNG
>>>>>>>>>>>>>>>>> at the end of this email. I can try to fumble further in the dark or try to update harvestr,
>>>>>>>>>>>>>>>>> but maybe someone has gone through all this already.
>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>> I'd also appreciate any tips for elegantly post-processing such parallel data, as some of my usual
>>>>>>>>>>>>>>>>> extraction functions and routines are hampered by the fact that some coda functions
>>>>>>>>>>>>>>>>> do not aggregate results over chains. (What I get from a single-chain summary in MCMCglmm
>>>>>>>>>>>>>>>>> is a bit more comprehensive, than what I managed to cobble together with my own extraction
>>>>>>>>>>>>>>>>> functions).
>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>> The reason I'm parallelising my analyses is that I'm having trouble getting a good effective
>>>>>>>>>>>>>>>>> sample size for any parameter having to do with the many zeroes in my data.
>>>>>>>>>>>>>>>>> Any pointers are very appreciated, I'm quite inexperienced with MCMCglmm.
>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>> Best wishes
>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>> Ruben
>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>> # bsub -q mpi-short -W 2:00 -n 42 -R np20 mpirun -H localhost -n 41 R --slave -f "rpqa/rpqa_main/rpqa_children_parallel.r"
>>>>>>>>>>>>>>>>> library(doMPI)
>>>>>>>>>>>>>>>>> cl <- startMPIcluster()
>>>>>>>>>>>>>>>>> registerDoMPI(cl)
>>>>>>>>>>>>>>>>> Children_mcmc1 = foreach(i=1:40) %dopar% {
>>>>>>>>>>>>>>>>> 	library(MCMCglmm)
>>>>>>>>>>>>>>>>> 	load("rpqa1.rdata")
>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>> 	nitt = 40000; thin = 100; burnin = 10000
>>>>>>>>>>>>>>>>> 	prior = list(
>>>>>>>>>>>>>>>>> 		R = list(V = diag(c(1,1)), nu = 0.002),
>>>>>>>>>>>>>>>>> 		G=list(list(V=diag(c(1,1e-6)),nu=0.002))
>>>>>>>>>>>>>>>>> 	)
>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>> 	MCMCglmm( children ~ trait -1 + at.level(trait,1):male + at.level(trait,1):urban + at.level(trait,1):spouses + at.level(trait,1):paternalage.mean + at.level(trait,1):paternalage.factor,
>>>>>>>>>>>>>>>>> 		rcov=~us(trait):units,
>>>>>>>>>>>>>>>>> 		random=~us(trait):idParents,
>>>>>>>>>>>>>>>>> 		family="zapoisson",
>>>>>>>>>>>>>>>>> 		prior = prior,
>>>>>>>>>>>>>>>>> 		data=rpqa.1,
>>>>>>>>>>>>>>>>> 		pr = F, saveX = T, saveZ = T,
>>>>>>>>>>>>>>>>> 		nitt=nitt,thin=thin,burnin=burnin)
>>>>>>>>>>>>>>>>> }
>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>> library(coda)
>>>>>>>>>>>>>>>>> mcmclist = mcmc.list(lapply(Children_mcmc1,FUN=function(x) { x$Sol}))
>>>>>>>>>>>>>>>>> save(Children_mcmc1,mcmclist, file = "rpqa_mcmc_kids_za.rdata")
>>>>>>>>>>>>>>>>> closeCluster(cl)
>>>>>>>>>>>>>>>>> mpi.quit()
>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>> --
>>>>>>>>>>>>>>>>> Ruben C. Arslan
>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>> Georg August University G?ttingen
>>>>>>>>>>>>>>>>> Biological Personality Psychology and Psychological Assessment
>>>>>>>>>>>>>>>>> Georg Elias M?ller Institute of Psychology
>>>>>>>>>>>>>>>>> Go?lerstr. 14
>>>>>>>>>>>>>>>>> 37073 G?ttingen
>>>>>>>>>>>>>>>>> Germany
>>>>>>>>>>>>>>>>> Tel.: +49 551 3920704
>>>>>>>>>>>>>>>>> https://psych.uni-goettingen.de/en/biopers/team/arslan
>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>> 	[[alternative HTML version deleted]]
>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> --
>>>>>>>>>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>>>>>>>>>> Scotland, with registration number SC005336.
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> 
>>>>>>>>>>>>> 
>>>>>>>>>>>>> 
>>>>>>>>>>>>> 
>>>>>>>>>>>>> --
>>>>>>>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>>>>>>>> Scotland, with registration number SC005336.
>>>>>>>>>>>>> 
>>>>>>>>>>>>> _______________________________________________
>>>>>>>>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> --
>>>>>>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>>>>>>> Scotland, with registration number SC005336.
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>> 
>>>>>>>>>>> 
>>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> --
>>>>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>>>>> Scotland, with registration number SC005336.
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> --
>>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>>> Scotland, with registration number SC005336.
>>>>>>>> 
>>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> --
>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>> Scotland, with registration number SC005336.
>>>>>> 
>>>>>> 
>>>>> 
>>>>> 
>>>> 
>>>> 
>>>> --
>>>> The University of Edinburgh is a charitable body, registered in
>>>> Scotland, with registration number SC005336.
>>>> 
>>>> 
>>> 
>>> 
>> 
>> 
>> 
>> -- 
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> 
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
> 
> 


	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Fri Aug 29 12:02:59 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 29 Aug 2014 11:02:59 +0100
Subject: [R-sig-ME] parallel MCMCglmm, RNGstreams,
 starting values & priors
In-Reply-To: <7F4CEBA1-CFF9-4FBA-883B-8263CAC018EE@gmail.com>
References: <4CD76FE1-D3F5-4980-9122-B0AC0D44FF81@gmail.com>
	<0E12EB43-72BC-42AC-9E74-9DF53DB42217@gmail.com>
	<20140825162907.10475jpywlu1wzs4@www.staffmail.ed.ac.uk>
	<0A463095-8656-49B7-9619-E557DD449E21@gmail.com>
	<20140825171414.10872gnlopk1we68@www.staffmail.ed.ac.uk>
	<20140825172936.15916weehiwjyc08@www.staffmail.ed.ac.uk>
	<8D35B834-0D31-486A-B5FB-0F279761FDB2@gmail.com>
	<49D60399-6902-45AC-80A9-9F3C35532228@gmail.com>
	<20140826120434.14613hxqhgwbhq80@www.staffmail.ed.ac.uk>
	<8557AE32-AFC9-4FD2-9C88-2D118B484637@gmail.com>
	<20140827183959.18662zc6hw5jj20w@www.staffmail.ed.ac.uk>
	<2D00600E-5287-4FE1-B605-82C0CBA286ED@gmail.com>
	<20140828180551.74212a0xoeoihn6s@www.staffmail.ed.ac.uk>
	<BBB5F7E3-75FE-4BA3-82B4-49DAA64873A4@gmail.com>
	<20140828195957.68171hjra56vrrr4@www.staffmail.ed.ac.uk>
	<E5B149F2-7773-4E2D-854C-3275A352A245@gmail.com>
	<20140829080442.1833246y8pj3itq8@www.staffmail.ed.ac.uk>
	<20140829081333.16792k7qrimekagw@www.staffmail.ed.ac.uk>
	<7F4CEBA1-CFF9-4FBA-883B-8263CAC018EE@gmail.com>
Message-ID: <20140829110259.60094j3omtxmddkw@www.staffmail.ed.ac.uk>

Hi,

You need to make sure that they are fixed at the same value, not just fixed.

Cheers,

Jarrod



Quoting Ruben Arslan <rubenarslan at gmail.com> on Fri, 29 Aug 2014  
11:07:21 +0200:

> Hi Jarrod,
>
> that was exactly it. I hadn't checked the $VCV mcmclist, but I'll do  
> so in the future
> as the mistake is blindingly obvious that way: http://imgur.com/nlA0QwZ
>
> After adding fix=2 to R1 in my starting values, my parallel chains  
> converged as well.
>
> For future amateurs reading this:
> prior <- list(
> 	R=list(V=diag(2), nu=1.002, fix=2),
> 	G=list(G1=list(V=diag(2), nu=1, alpha.mu=c(0,0), alpha.V=diag(2)*1000))
> )
>
> start <- list(
> 	liab=c(rnorm( nrow(krmh.1)*2 )),
> 	R = list(R1 = rIW(diag(2), 10 , fix = 2)), ### FIX=2 HERE AS WELL
> 	G = list(G1 = rIW(diag(2), 10 ))
> )
>
> Thank you so much. This sort of remote diagnosis with this little information
> seems borderline psychic to me.
> Now, onwards to modelling the pedigrees :-)
>
> Best wishes,
>
> Ruben
>
> PS.: I never actually figured out what kind of variability to use  
> for rIW() in my starting values,
> but it doesn't seem to matter and that's what I should want I  
> suppose. Actually, even with the mis-specified
> starting values my posterior looked pretty similar to now.
>
> On 29 Aug 2014, at 09:13, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>
>> Hi Ruben,
>>
>> Actually I might know what it is. When you sample different  
>> starting values do you inadvertently sample a new residual variance  
>> for the unidentified za part? You need to make sure that this is  
>> always fixed at the same value (otherwise the model is different).  
>> This is not a problem under the trait:units specification.
>>
>> Cheers,
>>
>> Jarrod.
>>
>>
>>
>> Quoting Jarrod Hadfield <j.hadfield at ed.ac.uk> on Fri, 29 Aug 2014  
>> 08:04:42 +0100:
>>
>>> Hi Ruben,
>>>
>>> Can you share your data and I will take a look. Its definitely not  
>>> Monte Carlo error.
>>>
>>> Cheers,
>>>
>>> Jarrod
>>>
>>>
>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Thu, 28 Aug 2014  
>>> 22:44:47 +0200:
>>>
>>>> Hi Jarrod,
>>>>
>>>> those two matched up quite well yes. I just completed another 20  
>>>> chains, using more variable
>>>> starting values. There's still two fixed effects  
>>>> traitza_children:spouses  and :male which haven't converged
>>>> according to multi-chain (gelman), but have according to geweke.
>>>> The offending traces: http://imgur.com/Qm6Ovfr
>>>> These specific effects aren't of interest to me, so if this  
>>>> doesn't affect the rest of my estimates, I can be happy
>>>> with this, but I can't conclude that, can I?
>>>>
>>>> I'm now also doing a run to see how it deals with the more  
>>>> intensely zero-inflated data when including
>>>> the unmarried.
>>>>
>>>> Thanks a lot for all that help,
>>>>
>>>> Ruben
>>>>
>>>>> gelman.diag(mcmclist)
>>>> Potential scale reduction factors:
>>>>
>>>>                                          Point est. Upper C.I.
>>>> (Intercept)                                      1.00       1.00
>>>> traitza_children                                 1.40       1.65
>>>> male                                             1.00       1.00
>>>> spouses                                          1.00       1.00
>>>> paternalage.mean                                 1.00       1.00
>>>> paternalage.factor(25,30]                        1.00       1.00
>>>> paternalage.factor(30,35]                        1.00       1.00
>>>> paternalage.factor(35,40]                        1.00       1.00
>>>> paternalage.factor(40,45]                        1.00       1.00
>>>> paternalage.factor(45,50]                        1.00       1.00
>>>> paternalage.factor(50,55]                        1.00       1.00
>>>> paternalage.factor(55,90]                        1.00       1.00
>>>> traitza_children:male                            1.33       1.54
>>>> traitza_children:spouses                         2.21       2.83
>>>> traitza_children:paternalage.mean                1.01       1.02
>>>> traitza_children:paternalage.factor(25,30]       1.05       1.08
>>>> traitza_children:paternalage.factor(30,35]       1.08       1.13
>>>> traitza_children:paternalage.factor(35,40]       1.15       1.25
>>>> traitza_children:paternalage.factor(40,45]       1.15       1.26
>>>> traitza_children:paternalage.factor(45,50]       1.26       1.43
>>>> traitza_children:paternalage.factor(50,55]       1.15       1.25
>>>> traitza_children:paternalage.factor(55,90]       1.14       1.23
>>>>
>>>> Multivariate psrf
>>>>
>>>> 8.99
>>>>
>>>>> summary(mcmclist)
>>>>
>>>> Iterations = 100001:149951
>>>> Thinning interval = 50
>>>> Number of chains = 20
>>>> Sample size per chain = 1000
>>>>
>>>> 1. Empirical mean and standard deviation for each variable,
>>>>  plus standard error of the mean:
>>>>
>>>>                                              Mean      SD  Naive  
>>>> SE Time-series SE
>>>> (Intercept)                                 1.36326 0.04848  
>>>> 0.0003428      0.0003542
>>>> traitza_children                           -0.76679 0.28738  
>>>> 0.0020321      0.0016682
>>>> male                                        0.09980 0.01633  
>>>> 0.0001155      0.0001222
>>>> spouses                                     0.12333 0.01957  
>>>> 0.0001384      0.0001414
>>>> paternalage.mean                            0.07215 0.02194  
>>>> 0.0001551      0.0001596
>>>> paternalage.factor(25,30]                  -0.03381 0.04184  
>>>> 0.0002959      0.0003066
>>>> paternalage.factor(30,35]                  -0.08380 0.04270  
>>>> 0.0003019      0.0003118
>>>> paternalage.factor(35,40]                  -0.16502 0.04569  
>>>> 0.0003231      0.0003289
>>>> paternalage.factor(40,45]                  -0.16738 0.05090  
>>>> 0.0003599      0.0003697
>>>> paternalage.factor(45,50]                  -0.18383 0.05880  
>>>> 0.0004158      0.0004242
>>>> paternalage.factor(50,55]                  -0.18241 0.07277  
>>>> 0.0005146      0.0005302
>>>> paternalage.factor(55,90]                  -0.40612 0.09875  
>>>> 0.0006983      0.0007467
>>>> traitza_children:male                       0.12092 0.08223  
>>>> 0.0005815      0.0004697
>>>> traitza_children:spouses                    0.64881 0.21132  
>>>> 0.0014942      0.0008511
>>>> traitza_children:paternalage.mean          -0.02741 0.08550  
>>>> 0.0006046      0.0006221
>>>> traitza_children:paternalage.factor(25,30] -0.17296 0.18680  
>>>> 0.0013209      0.0013750
>>>> traitza_children:paternalage.factor(30,35] -0.19027 0.19267  
>>>> 0.0013624      0.0013901
>>>> traitza_children:paternalage.factor(35,40] -0.24911 0.21282  
>>>> 0.0015049      0.0014391
>>>> traitza_children:paternalage.factor(40,45] -0.29772 0.23403  
>>>> 0.0016548      0.0015956
>>>> traitza_children:paternalage.factor(45,50] -0.51782 0.28589  
>>>> 0.0020215      0.0017602
>>>> traitza_children:paternalage.factor(50,55] -0.46126 0.32064  
>>>> 0.0022673      0.0021397
>>>> traitza_children:paternalage.factor(55,90] -0.38612 0.41461  
>>>> 0.0029317      0.0027396
>>>>
>>>> 2. Quantiles for each variable:
>>>>
>>>>                                              2.5%      25%       
>>>> 50%      75%      97.5%
>>>> (Intercept)                                 1.26883  1.33106   
>>>> 1.36322  1.39575  1.4589722
>>>> traitza_children                           -1.20696 -0.95751  
>>>> -0.81076 -0.63308 -0.0365042
>>>> male                                        0.06785  0.08878   
>>>> 0.09970  0.11085  0.1320168
>>>> spouses                                     0.08467  0.11030   
>>>> 0.12343  0.13643  0.1617869
>>>> paternalage.mean                            0.02950  0.05751   
>>>> 0.07202  0.08683  0.1153881
>>>> paternalage.factor(25,30]                  -0.11581 -0.06174  
>>>> -0.03397 -0.00574  0.0473783
>>>> paternalage.factor(30,35]                  -0.16656 -0.11250  
>>>> -0.08358 -0.05519  0.0003065
>>>> paternalage.factor(35,40]                  -0.25518 -0.19530  
>>>> -0.16500 -0.13440 -0.0757366
>>>> paternalage.factor(40,45]                  -0.26887 -0.20164  
>>>> -0.16675 -0.13335 -0.0677407
>>>> paternalage.factor(45,50]                  -0.30080 -0.22320  
>>>> -0.18339 -0.14440 -0.0687967
>>>> paternalage.factor(50,55]                  -0.32663 -0.23034  
>>>> -0.18227 -0.13317 -0.0415547
>>>> paternalage.factor(55,90]                  -0.60202 -0.47303  
>>>> -0.40454 -0.33994 -0.2139128
>>>> traitza_children:male                      -0.01083  0.06634   
>>>> 0.11024  0.16109  0.3295892
>>>> traitza_children:spouses                    0.37857  0.51072   
>>>> 0.59398  0.71395  1.2127940
>>>> traitza_children:paternalage.mean          -0.19138 -0.08250  
>>>> -0.02985  0.02493  0.1468989
>>>> traitza_children:paternalage.factor(25,30] -0.57457 -0.28481  
>>>> -0.16489 -0.05151  0.1728148
>>>> traitza_children:paternalage.factor(30,35] -0.61499 -0.30350  
>>>> -0.17736 -0.06299  0.1555147
>>>> traitza_children:paternalage.factor(35,40] -0.74251 -0.36752  
>>>> -0.22966 -0.10777  0.1151897
>>>> traitza_children:paternalage.factor(40,45] -0.84165 -0.42691  
>>>> -0.27729 -0.14322  0.1032436
>>>> traitza_children:paternalage.factor(45,50] -1.21782 -0.66568  
>>>> -0.48420 -0.32873 -0.0476720
>>>> traitza_children:paternalage.factor(50,55] -1.21327 -0.63623  
>>>> -0.43432 -0.24957  0.0955360
>>>> traitza_children:paternalage.factor(55,90] -1.33772 -0.62227  
>>>> -0.35364 -0.11050  0.3361684
>>>>
>>>>> effectiveSize(mcmclist)
>>>>                              (Intercept)                           
>>>>  traitza_children
>>>>                                 18814.05                           
>>>>          16359.33
>>>>                                     male                           
>>>>           spouses
>>>>                                 18132.98                           
>>>>          19547.05
>>>>                         paternalage.mean                   
>>>> paternalage.factor(25,30]
>>>>                                 19238.72                           
>>>>          18974.81
>>>>                paternalage.factor(30,35]                   
>>>> paternalage.factor(35,40]
>>>>                                 18874.33                           
>>>>          19406.63
>>>>                paternalage.factor(40,45]                   
>>>> paternalage.factor(45,50]
>>>>                                 19075.18                           
>>>>          19401.77
>>>>                paternalage.factor(50,55]                   
>>>> paternalage.factor(55,90]
>>>>                                 18960.11                           
>>>>          17893.23
>>>>                    traitza_children:male                    
>>>> traitza_children:spouses
>>>>                                 18545.55                           
>>>>          14438.51
>>>>        traitza_children:paternalage.mean  
>>>> traitza_children:paternalage.factor(25,30]
>>>>                                 18464.09                           
>>>>          16943.43
>>>> traitza_children:paternalage.factor(30,35]  
>>>> traitza_children:paternalage.factor(35,40]
>>>>                                 16827.44                           
>>>>          17230.04
>>>> traitza_children:paternalage.factor(40,45]  
>>>> traitza_children:paternalage.factor(45,50]
>>>>                                 17144.78                           
>>>>          18191.67
>>>> traitza_children:paternalage.factor(50,55]  
>>>> traitza_children:paternalage.factor(55,90]
>>>>                                 17466.60                           
>>>>          18540.59
>>>>
>>>>
>>>> ### current script:
>>>>
>>>> # bsub -q mpi -W 24:00 -n 21 -R np20 mpirun -H localhost -n 21 R  
>>>> --slave -f "/usr/users/rarslan/rpqa/krmh_main/children.R"
>>>> setwd("/usr/users/rarslan/rpqa/")
>>>> library(doMPI)
>>>> cl <-  
>>>> startMPIcluster(verbose=T,workdir="/usr/users/rarslan/rpqa/krmh_main/")
>>>> registerDoMPI(cl)
>>>> Children = foreach(i=1:clusterSize(cl),.options.mpi =  
>>>> list(seed=1337) ) %dopar% {
>>>> 	library(MCMCglmm);library(data.table)
>>>>   setwd("/usr/users/rarslan/rpqa/krmh_main/")
>>>> 	source("../1 - extraction functions.r")
>>>>   load("../krmh1.rdata")
>>>>
>>>> 	krmh.1 = recenter.pat(na.omit(krmh.1[spouses>0, list(idParents,  
>>>> children, male, spouses, paternalage)]))
>>>>
>>>> 	samples = 1000
>>>> 	thin = 50; burnin = 100000
>>>> 	nitt = samples * thin + burnin
>>>>
>>>> 	prior <- list(
>>>> 		R=list(V=diag(2), nu=1.002, fix=2),
>>>> 		G=list(G1=list(V=diag(2), nu=1, alpha.mu=c(0,0), alpha.V=diag(2)*1000))
>>>> 	)
>>>>
>>>> 	start <- list(
>>>> 		liab=c(rnorm( nrow(krmh.1)*2 )),
>>>> 		R = list(R1 = rIW(diag(2), 10 )),
>>>> 		G = list(G1 = rIW(diag(2), 10 ))
>>>> 	)
>>>>
>>>> 	( m1 = MCMCglmm( children ~ trait * (male + spouses +  
>>>> paternalage.mean + paternalage.factor),
>>>> 						rcov=~idh(trait):units,
>>>> 						random=~idh(trait):idParents,
>>>> 						family="zapoisson",
>>>> 						start = start,
>>>> 						prior = prior,
>>>> 						data=krmh.1,
>>>> 						pr = F, saveX = F, saveZ = F,
>>>> 						nitt=nitt,thin=thin,burnin=burnin)
>>>> 	)
>>>> 		m1$Residual$nrt<-2
>>>> 	m1
>>>> }
>>>>
>>>> save(Children,file = "Children.rdata")
>>>> closeCluster(cl)
>>>> mpi.quit()
>>>>
>>>> On 28 Aug 2014, at 20:59, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>>>
>>>>> Hi,
>>>>>
>>>>> The posteriors for the two models look pretty close to me. Are  
>>>>> the scale reduction factors really as high as previously  
>>>>> reported? Before you had 1.83 for traitza_children:spouses, but  
>>>>> the plot suggests that it should be close to 1?
>>>>>
>>>>> Cheers,
>>>>>
>>>>> Jarrod
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Thu, 28 Aug 2014  
>>>>> 19:59:16 +0200:
>>>>>
>>>>>> Sure! Thanks a lot.
>>>>>> I am using ~idh(trait):units already, sorry for saying that  
>>>>>> incorrectly in my last email.
>>>>>> These models aren't the final thing, I will replace the  
>>>>>> paternalage.factor variable
>>>>>> with its linear equivalent if that seems defensible (does so  
>>>>>> far) and in this model it seems
>>>>>> okay to remove the za-effects for all predictors except spouses.
>>>>>> So a final model would have fewer fixed effects. I also have  
>>>>>> datasets of 200k+ and 5m+,
>>>>>> but I'm learning MCMCglmm with this smaller one because my  
>>>>>> wrong turns take less time.
>>>>>>
>>>>>> I've uploaded a comparison coef plot of two models:
>>>>>> http://i.imgur.com/sHUfnmd.png
>>>>>> m7 is with the default starting values, m1 is with the  
>>>>>> specification I sent in my last email. I don't
>>>>>> know if such differences are something to worry about.
>>>>>>
>>>>>> I don't know what qualifies as highly overdispersed, here's a  
>>>>>> plot of the outcome for ever
>>>>>> married people (slate=real data):
>>>>>> http://imgur.com/14MywgZ
>>>>>> here's with everybody born (incl. some stillborn etc.):
>>>>>> http://imgur.com/knRGa1v
>>>>>> I guess my approach (generating an overdispersed poisson with  
>>>>>> the parameters from
>>>>>> the data and checking if it has as excess zeroes) is not the  
>>>>>> best way to diagnose zero-inflation,
>>>>>> but especially in the second case it seems fairly clear-cut.
>>>>>>
>>>>>> Best regards,
>>>>>>
>>>>>> Ruben
>>>>>>
>>>>>>> summary(m1)
>>>>>>
>>>>>> Iterations = 50001:149951
>>>>>> Thinning interval  = 50
>>>>>> Sample size  = 2000
>>>>>>
>>>>>> DIC: 31249.73
>>>>>>
>>>>>> G-structure:  ~idh(trait):idParents
>>>>>>
>>>>>>                    post.mean  l-95% CI u-95% CI eff.samp
>>>>>> children.idParents     0.006611 4.312e-08   0.0159    523.9
>>>>>> za_children.idParents  0.193788 7.306e-02   0.3283    369.3
>>>>>>
>>>>>> R-structure:  ~idh(trait):units
>>>>>>
>>>>>>                post.mean l-95% CI u-95% CI eff.samp
>>>>>> children.units       0.1285   0.1118   0.1452    716.1
>>>>>> za_children.units    0.9950   0.9950   0.9950      0.0
>>>>>>
>>>>>> Location effects: children ~ trait * (male + spouses +  
>>>>>> paternalage.mean + paternalage.factor)
>>>>>>
>>>>>>                                          post.mean   l-95% CI    
>>>>>> u-95% CI eff.samp  pMCMC
>>>>>> (Intercept)                                 1.3413364   
>>>>>> 1.2402100  1.4326099     1789 <5e-04 ***
>>>>>> traitza_children                           -0.8362879  
>>>>>> -1.2007980 -0.5016730     1669 <5e-04 ***
>>>>>> male                                        0.0994902   
>>>>>> 0.0679050  0.1297394     2000 <5e-04 ***
>>>>>> spouses                                     0.1236033   
>>>>>> 0.0839000  0.1624939     2000 <5e-04 ***
>>>>>> paternalage.mean                            0.0533892   
>>>>>> 0.0119569  0.0933960     2000  0.015 *
>>>>>> paternalage.factor(25,30]                  -0.0275822  
>>>>>> -0.1116421  0.0537359     1842  0.515
>>>>>> paternalage.factor(30,35]                  -0.0691025  
>>>>>> -0.1463214  0.0122393     1871  0.097 .
>>>>>> paternalage.factor(35,40]                  -0.1419933  
>>>>>> -0.2277379 -0.0574678     1845 <5e-04 ***
>>>>>> paternalage.factor(40,45]                  -0.1364952  
>>>>>> -0.2362714 -0.0451874     1835  0.007 **
>>>>>> paternalage.factor(45,50]                  -0.1445342  
>>>>>> -0.2591767 -0.0421178     1693  0.008 **
>>>>>> paternalage.factor(50,55]                  -0.1302972  
>>>>>> -0.2642965  0.0077061     2000  0.064 .
>>>>>> paternalage.factor(55,90]                  -0.3407879  
>>>>>> -0.5168972 -0.1493652     1810 <5e-04 ***
>>>>>> traitza_children:male                       0.0926888  
>>>>>> -0.0147379  0.2006142     1901  0.098 .
>>>>>> traitza_children:spouses                    0.5531197   
>>>>>> 0.3870616  0.7314289     1495 <5e-04 ***
>>>>>> traitza_children:paternalage.mean           0.0051463  
>>>>>> -0.1279396  0.1460099     1617  0.960
>>>>>> traitza_children:paternalage.factor(25,30] -0.1538957  
>>>>>> -0.4445749  0.1462955     1781  0.321
>>>>>> traitza_children:paternalage.factor(30,35] -0.1747883  
>>>>>> -0.4757851  0.1162476     1998  0.261
>>>>>> traitza_children:paternalage.factor(35,40] -0.2261843  
>>>>>> -0.5464379  0.0892582     1755  0.166
>>>>>> traitza_children:paternalage.factor(40,45] -0.2807543  
>>>>>> -0.6079678  0.0650281     1721  0.100 .
>>>>>> traitza_children:paternalage.factor(45,50] -0.4905843  
>>>>>> -0.8649214 -0.1244174     1735  0.010 **
>>>>>> traitza_children:paternalage.factor(50,55] -0.4648579  
>>>>>> -0.9215759 -0.0002083     1687  0.054 .
>>>>>> traitza_children:paternalage.factor(55,90] -0.3945406  
>>>>>> -1.0230155  0.2481568     1793  0.195
>>>>>> ---
>>>>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>>>>
>>>>>>> describe(krmh.1[spouses>0,])
>>>>>>                  vars    n mean   sd median trimmed  mad   min   
>>>>>>  max range skew kurtosis   se
>>>>>> children               2 6829 3.81 2.93   4.00    3.61 2.97   
>>>>>> 0.00 16.00 16.00 0.47    -0.46 0.04
>>>>>> male                   3 6829 0.46 0.50   0.00    0.45 0.00   
>>>>>> 0.00  1.00  1.00 0.14    -1.98 0.01
>>>>>> spouses                4 6829 1.14 0.38   1.00    1.03 0.00   
>>>>>> 1.00  4.00  3.00 2.87     8.23 0.00
>>>>>> paternalage            5 6829 3.65 0.80   3.57    3.60 0.80   
>>>>>> 1.83  7.95  6.12 0.69     0.70 0.01
>>>>>> paternalage_c          6 6829 0.00 0.80  -0.08   -0.05 0.80  
>>>>>> -1.82  4.30  6.12 0.69     0.70 0.01
>>>>>> paternalage.mean       7 6829 0.00 0.68  -0.08   -0.05 0.59  
>>>>>> -1.74  4.30  6.04 0.95     1.97 0.01
>>>>>> paternalage.diff       8 6829 0.00 0.42   0.00   -0.01 0.38  
>>>>>> -1.51  1.48  2.99 0.17     0.17 0.01
>>>>>>
>>>>>>> table(krmh.1$paternalage.factor)
>>>>>>
>>>>>> [0,25] (25,30] (30,35] (35,40] (40,45] (45,50] (50,55] (55,90]
>>>>>>  309    1214    1683    1562    1039     623     269     130
>>>>>>
>>>>>> On 28 Aug 2014, at 19:05, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>>>>>
>>>>>>> Hi Ruben,
>>>>>>>
>>>>>>> It might be hard to detect (near) ECPs with so many fixed  
>>>>>>> effects (can you post the model summary (and give us the mean  
>>>>>>> and standard deviation of any continuous covariates)). Also,  
>>>>>>> the complementary log-log link (which is the za specification)  
>>>>>>> is non-symmetric and runs into problems outside the range -35  
>>>>>>> to 3.5 so there may be a problem there, particularly if you  
>>>>>>> use rcov=~trait:units and the Poisson part is highly  
>>>>>>> over-dispersed.  You could try rcov=~idh(trait):units and fix  
>>>>>>> the non-identifiable za residual variance to something smaller  
>>>>>>> than 1 (say 0.5)  - it will mix slower but it will reduce the  
>>>>>>> chance of over/underflow.
>>>>>>>
>>>>>>> Cheers,
>>>>>>>
>>>>>>> Jarrod
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Thu, 28 Aug  
>>>>>>> 2014 18:45:30 +0200:
>>>>>>>
>>>>>>>> Hi Jarrod,
>>>>>>>>
>>>>>>>>> 1) it did not return an error with rcov = ~trait:units  
>>>>>>>>> because you used R1=rpois(2,1)+1 and yet this specification  
>>>>>>>>> only fits a single variance (not a 2x2 covariance matrix).  
>>>>>>>>> R1=rpois(2,1)+1 is a bit of a weird specification since it  
>>>>>>>>> has to be integer. I would obtain starting values using rIW().
>>>>>>>>
>>>>>>>> I agree it's a weird specification, I was a bit lost and  
>>>>>>>> thought I could get away with just putting some random  
>>>>>>>> numbers in the starting value.
>>>>>>>> I didn't do R1=rpois(2,1)+1 though, I did  
>>>>>>>> R1=diag(rpois(2,1)+1), so I got a 2x2 matrix, but yes, bound  
>>>>>>>> to be integer.
>>>>>>>> I didn't know starting values should come from a conjugate  
>>>>>>>> distribution, though that probably means I didn't think about  
>>>>>>>> it much.
>>>>>>>>
>>>>>>>> I'm now doing
>>>>>>>> start <- list(
>>>>>>>> 	liab=c(rnorm( nrow(krmh.1)*2 )),
>>>>>>>> 	R = list(R1 = rIW( diag(2), nrow(krmh.1)) ),
>>>>>>>> 	G = list(G1 = rIW( diag(2), nrow(krmh.1)) )
>>>>>>>> )
>>>>>>>>
>>>>>>>> Is this what you had in mind?
>>>>>>>> I am especially unsure if I am supposed to use such a low  
>>>>>>>> sampling variability (my sample size is probably not even  
>>>>>>>> relevant for the starting values) and if I should start from  
>>>>>>>> diag(2).
>>>>>>>>
>>>>>>>> And, I am still happily confused that this specification  
>>>>>>>> still doesn't lead to errors with respect to rcov =  
>>>>>>>> ~trait:units . Does this mean I'm doing it wrong?
>>>>>>>>
>>>>>>>>> 3) a) how many effective samples do you have for each  
>>>>>>>>> parameter? and b) are you getting extreme category  
>>>>>>>>> problems/numerical issues? If you store the latent variables  
>>>>>>>>> (pl=TUE) what is their range for the Zi/za part?
>>>>>>>>
>>>>>>>> My parallel run using the above starting values isn't finished yet.
>>>>>>>> a) After applying the above starting values I get, for the  
>>>>>>>> location effects 1600-2000 samples for a 2000 sample chain  
>>>>>>>> (with thin set to 50). G and R-structure are from 369  
>>>>>>>> (za_children.idParents) to 716 (and 0 for the fixed part).
>>>>>>>> Effective sample sizes were similar for my run using the  
>>>>>>>> starting values for G/R that I drew from rpois, and using 40  
>>>>>>>> chains I of course get
>>>>>>>> b) I don't think I am getting extreme categories. I would  
>>>>>>>> probably be getting extreme categories if I included the  
>>>>>>>> forever-alones (they almost never have children), but this  
>>>>>>>> way no.
>>>>>>>> I wasn't sure how to examine the range of the latents  
>>>>>>>> separately for the za part, but for a single chain it looks  
>>>>>>>> okay:
>>>>>>>>> quantile(as.numeric(m1$Liab),probs = c(0,0.01,0,0.99,1))
>>>>>>>>    0%        1%        0%       99%      100%
>>>>>>>> -4.934111 -1.290728 -4.934111  3.389847  7.484206
>>>>>>>>
>>>>>>>> Well, all considered now that I use the above starting value  
>>>>>>>> specification I get slightly different estimates for all  
>>>>>>>> za-coefficients. Nothing major, but still leading me to
>>>>>>>> think my estimates aren't exactly independent of the starting  
>>>>>>>> values I use. I'll see what the parallel run yields.
>>>>>>>>
>>>>>>>> Thanks a lot,
>>>>>>>>
>>>>>>>> Ruben
>>>>>>>>
>>>>>>>>>
>>>>>>>>> Cheers,
>>>>>>>>>
>>>>>>>>> Jarrod
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Wed, 27 Aug  
>>>>>>>>> 2014 19:23:42 +0200:
>>>>>>>>>
>>>>>>>>>> Hi Jarrod,
>>>>>>>>>>
>>>>>>>>>> thanks again. I was able to get it running with your advice.
>>>>>>>>>> Some points of confusion remain:
>>>>>>>>>>
>>>>>>>>>> - You wrote that zi/za models would return an error with  
>>>>>>>>>> rcov = ~trait:units + starting values. This did not happen  
>>>>>>>>>> in my case, so I didn't build MCMCglmm myself with your  
>>>>>>>>>> suggested edits. Also, have you considered putting your own  
>>>>>>>>>> MCMCglmm repo on Github? Your users would be able to  
>>>>>>>>>> install pre-releases and I'd think you'd get some  
>>>>>>>>>> time-saving pull requests too.
>>>>>>>>>> - In my attempts to get my models to run properly, I messed  
>>>>>>>>>> up a prior and did not use fix=2 in my prior specification  
>>>>>>>>>> for my za models. This led to crappy convergence, it's much  
>>>>>>>>>> better now and for some of my simpler models I think I  
>>>>>>>>>> won't need parallel chains. I'm reminded of Gelman's folk  
>>>>>>>>>> theorem of statistical computing.
>>>>>>>>>> - I followed your advice, but of course I could not set the  
>>>>>>>>>> true values as starting values, but wanted to set random,  
>>>>>>>>>> bad starting values. I pasted below what I arrived at, I'm  
>>>>>>>>>> especially unsure whether I specified the starting values  
>>>>>>>>>> for G and R properly (I think not).
>>>>>>>>>> 	start <- list(
>>>>>>>>>> 		liab=c(rnorm( nrow(krmh.1)*2 )),
>>>>>>>>>> 		R = list(R1 = diag(rpois(2, 1)+1)),
>>>>>>>>>> 		G = list(G1 = diag(rpois(2, 1)+1))
>>>>>>>>>> 	)
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> However, even though I may not need multiple chains for  
>>>>>>>>>> some of my simpler models, I've now run into conflicting  
>>>>>>>>>> diagnostics. The geweke.diag for each chain (and  
>>>>>>>>>> examination of the traces) gives
>>>>>>>>>> satisfactory diagnostics. Comparing multiple chains using  
>>>>>>>>>> gelman.diag, however, leads to one bad guy, namely the  
>>>>>>>>>> traitza_children:spouses interaction.
>>>>>>>>>> I think this implies that I've got some starting value  
>>>>>>>>>> dependence for this parameter, that won't be easily  
>>>>>>>>>> rectified through longer burnin?
>>>>>>>>>> Do you have any ideas how to rectify this?
>>>>>>>>>> I am currently doing sequential analyses on episodes of  
>>>>>>>>>> selection and in historical human data only those who marry  
>>>>>>>>>> have a chance at having kids. I exclude the unmarried
>>>>>>>>>> from my sample where I predict number of children, because  
>>>>>>>>>> I examine that in a previous model and the zero-inflation  
>>>>>>>>>> (65% zeros, median w/o unmarried = 4) when including the  
>>>>>>>>>> unmarried is so excessive.
>>>>>>>>>> Number of spouses is easily the strongest predictor in the  
>>>>>>>>>> model, but only serves as a covariate here. Since my other  
>>>>>>>>>> estimates are stable across chains and runs and agree well  
>>>>>>>>>> across models and with theory, I'm
>>>>>>>>>> inclined to shrug this off. But probably I shouldn't ignore  
>>>>>>>>>> this sign of non-convergence?
>>>>>>>>>>
>>>>>>>>>>> gelman.diag(mcmc_1)
>>>>>>>>>> Potential scale reduction factors:
>>>>>>>>>>
>>>>>>>>>>                                       Point est. Upper C.I.
>>>>>>>>>> (Intercept)                                      1.00       1.00
>>>>>>>>>> traitza_children                                 1.27       1.39
>>>>>>>>>> male                                             1.00       1.00
>>>>>>>>>> spouses                                          1.00       1.00
>>>>>>>>>> paternalage.mean                                 1.00       1.00
>>>>>>>>>> paternalage.factor(25,30]                        1.00       1.00
>>>>>>>>>> paternalage.factor(30,35]                        1.00       1.00
>>>>>>>>>> paternalage.factor(35,40]                        1.00       1.00
>>>>>>>>>> paternalage.factor(40,45]                        1.00       1.00
>>>>>>>>>> paternalage.factor(45,50]                        1.00       1.00
>>>>>>>>>> paternalage.factor(50,55]                        1.00       1.00
>>>>>>>>>> paternalage.factor(55,90]                        1.00       1.00
>>>>>>>>>> traitza_children:male                            1.22       1.32
>>>>>>>>>> traitza_children:spouses                         1.83       2.13
>>>>>>>>>> traitza_children:paternalage.mean                1.02       1.02
>>>>>>>>>> traitza_children:paternalage.factor(25,30]       1.03       1.05
>>>>>>>>>> traitza_children:paternalage.factor(30,35]       1.05       1.08
>>>>>>>>>> traitza_children:paternalage.factor(35,40]       1.10       1.15
>>>>>>>>>> traitza_children:paternalage.factor(40,45]       1.12       1.17
>>>>>>>>>> traitza_children:paternalage.factor(45,50]       1.19       1.28
>>>>>>>>>> traitza_children:paternalage.factor(50,55]       1.12       1.18
>>>>>>>>>> traitza_children:paternalage.factor(55,90]       1.11       1.17
>>>>>>>>>>
>>>>>>>>>> Multivariate psrf
>>>>>>>>>>
>>>>>>>>>> 7.27
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> Best regards,
>>>>>>>>>>
>>>>>>>>>> Ruben
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> On 26 Aug 2014, at 13:04, Jarrod Hadfield  
>>>>>>>>>> <j.hadfield at ed.ac.uk> wrote:
>>>>>>>>>>
>>>>>>>>>>> Hi Ruben,
>>>>>>>>>>>
>>>>>>>>>>> There are 400 liabilities in a zapoisson model (2 per  
>>>>>>>>>>> datum). This code should work:
>>>>>>>>>>>
>>>>>>>>>>> g <-sample(letters[1:10], size = 200, replace = T)
>>>>>>>>>>> pred <- rnorm(200)
>>>>>>>>>>>
>>>>>>>>>>> l1<-rnorm(200, -1, sqrt(1))
>>>>>>>>>>> l2<-rnorm(200, -1, sqrt(1))
>>>>>>>>>>>
>>>>>>>>>>> y<-VGAM::rzapois(200, exp(l1), exp(-exp(l2)))
>>>>>>>>>>>
>>>>>>>>>>> # generate zero-altered data with an intercept of -1  
>>>>>>>>>>> (because the intercept and variance are the same for both  
>>>>>>>>>>> processes this is just standard Poisson)
>>>>>>>>>>>
>>>>>>>>>>> dat<-data.frame(y=y, g = g, pred = pred)
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>> start.1<-list(liab=c(l1,l2), R = list(R1=diag(2)),  
>>>>>>>>>>> G=list(G1=diag(2)))
>>>>>>>>>>> prior.1<-list(R=list(V=diag(2), nu=1.002, fix=2),  
>>>>>>>>>>> G=list(G1=list(V=diag(2), nu=2, alpha.mu=c(0,0),  
>>>>>>>>>>> alpha.V=diag(2)*1000)))
>>>>>>>>>>>
>>>>>>>>>>> m1<-MCMCglmm(y~trait + pred:trait, random=~us(trait):g,  
>>>>>>>>>>> family="zapoisson",rcov=~idh(trait):units, data=dat,  
>>>>>>>>>>> prior=prior.1, start= start.1)
>>>>>>>>>>>
>>>>>>>>>>> However, there are 2 bugs in the current version of  
>>>>>>>>>>> MCMCglmm that return an error message when the  
>>>>>>>>>>> documentation implies it should be fine:
>>>>>>>>>>>
>>>>>>>>>>> a) it should be possible to have R=diag(2) rather than R =  
>>>>>>>>>>> list(R1=diag(2)). This bug cropped up when I implemented  
>>>>>>>>>>> block-diagonal R structures. It can be fixed by inserting:
>>>>>>>>>>>
>>>>>>>>>>>     if(!is.list(start$R)){
>>>>>>>>>>>        start$R<-list(R1=start$R)
>>>>>>>>>>>     }
>>>>>>>>>>>
>>>>>>>>>>> on L514 of MCMCglmm.R below
>>>>>>>>>>>
>>>>>>>>>>>     if(!is.list(prior$R[[1]])){
>>>>>>>>>>>        prior$R<-list(R1=prior$R)
>>>>>>>>>>>     }
>>>>>>>>>>>
>>>>>>>>>>> b) rcov=~trait:units models for zi/za models will return  
>>>>>>>>>>> an error when passing starting values. To fix this insert
>>>>>>>>>>>
>>>>>>>>>>>    if(diagR==3){
>>>>>>>>>>>      if(dim(start)[1]!=1){
>>>>>>>>>>>        stop("V is the wrong dimension for some  
>>>>>>>>>>> strart$G/start$R elements")
>>>>>>>>>>>      }
>>>>>>>>>>>      start<-diag(sum(nfl))*start[1]
>>>>>>>>>>>    }
>>>>>>>>>>>
>>>>>>>>>>> on L90 of priorfromat.R below
>>>>>>>>>>>
>>>>>>>>>>>    if(is.matrix(start)==FALSE){
>>>>>>>>>>>      start<-as.matrix(start)
>>>>>>>>>>>    }
>>>>>>>>>>>
>>>>>>>>>>> I will put these in the new version.
>>>>>>>>>>>
>>>>>>>>>>> Cheers,
>>>>>>>>>>>
>>>>>>>>>>> Jarrod
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25  
>>>>>>>>>>> Aug 2014 21:52:30 +0200:
>>>>>>>>>>>
>>>>>>>>>>>> Hi Jarrod,
>>>>>>>>>>>>
>>>>>>>>>>>> thanks for these pointers.
>>>>>>>>>>>>
>>>>>>>>>>>>>> You will need to provide over-dispersed starting values  
>>>>>>>>>>>>>> for multiple-chain convergence diagnostics to be useful  
>>>>>>>>>>>>>> (GLMM are so simple I am generally happy if the output  
>>>>>>>>>>>>>> of a single run looks reasonable).
>>>>>>>>>>>>
>>>>>>>>>>>> Oh, I would be happy with single chains, but since  
>>>>>>>>>>>> computation would take weeks this way, I wanted to  
>>>>>>>>>>>> parallelise and I would use the multi-chain convergence  
>>>>>>>>>>>> as a criterion that my parallelisation was proper
>>>>>>>>>>>> and is as informative as a single long chain. There don't  
>>>>>>>>>>>> seem to be any such checks built-in ? I was analysing my  
>>>>>>>>>>>> 40 chains for a bit longer than I like to admit until I  
>>>>>>>>>>>> noticed they were identical (effectiveSize
>>>>>>>>>>>> and summary.mcmc.list did not yell at me for this).
>>>>>>>>>>>>
>>>>>>>>>>>>>> # use some very bad starting values
>>>>>>>>>>>> I get that these values are bad, but that is the goal for  
>>>>>>>>>>>> my multi-chain aim, right?
>>>>>>>>>>>>
>>>>>>>>>>>> I can apply this to my zero-truncated model, but am again  
>>>>>>>>>>>> getting stuck with the zero-altered one.
>>>>>>>>>>>> Maybe I need only specify the Liab values for this?
>>>>>>>>>>>> At least I'm getting nowhere with specifying R and G  
>>>>>>>>>>>> starting values here. When I got an error, I always
>>>>>>>>>>>> went to the MCMCglmm source to understand why the checks  
>>>>>>>>>>>> failed, but I didn't always understand
>>>>>>>>>>>> what was being checked and couldn't get it to work.
>>>>>>>>>>>>
>>>>>>>>>>>> Here's a failing example:
>>>>>>>>>>>>
>>>>>>>>>>>> l<-rnorm(200, -1, sqrt(1))
>>>>>>>>>>>> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
>>>>>>>>>>>> g = sample(letters[1:10], size = 200, replace = T)
>>>>>>>>>>>> pred = rnorm(200)
>>>>>>>>>>>> y<-rpois(200,exp(l)-t)
>>>>>>>>>>>> y[1:40] = 0
>>>>>>>>>>>> # generate zero-altered data with an intercept of -1
>>>>>>>>>>>>
>>>>>>>>>>>> dat<-data.frame(y=y, g = g, pred = pred)
>>>>>>>>>>>> set.seed(1)
>>>>>>>>>>>> start_true = list(Liab=l, R = 1, G = 1 )
>>>>>>>>>>>> m1<-MCMCglmm(y~1 + pred,random = ~ g,  
>>>>>>>>>>>> family="zapoisson",rcov=~us(trait):units, data=dat,  
>>>>>>>>>>>> start= start_true)
>>>>>>>>>>>>
>>>>>>>>>>>> # use true latent variable as starting values
>>>>>>>>>>>> set.seed(1)
>>>>>>>>>>>> # use some very bad starting values
>>>>>>>>>>>> start_rand = list(Liab=rnorm(200), R = rpois(1, 1)+1, G =  
>>>>>>>>>>>> rpois(1, 1)+1 )
>>>>>>>>>>>> m2<-MCMCglmm(y~1 + pred,random = ~  
>>>>>>>>>>>> g,rcov=~us(trait):units,  family="zapoisson", data=dat,  
>>>>>>>>>>>> start = start_rand)
>>>>>>>>>>>>
>>>>>>>>>>>> Best,
>>>>>>>>>>>>
>>>>>>>>>>>> Ruben
>>>>>>>>>>>>
>>>>>>>>>>>> On 25 Aug 2014, at 18:29, Jarrod Hadfield  
>>>>>>>>>>>> <j.hadfield at ed.ac.uk> wrote:
>>>>>>>>>>>>
>>>>>>>>>>>>> Hi Ruben,
>>>>>>>>>>>>>
>>>>>>>>>>>>> Sorry  - I was wrong when I said that everything is  
>>>>>>>>>>>>> Gibbs sampled conditional on the latent variables. The  
>>>>>>>>>>>>> location effects (fixed and random effects) are also  
>>>>>>>>>>>>> sampled conditional on the (co)variance components so  
>>>>>>>>>>>>> you should add them to the starting values. In the case  
>>>>>>>>>>>>> where the true values are used:
>>>>>>>>>>>>>
>>>>>>>>>>>>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat,  
>>>>>>>>>>>>> start=list(Liab=l,R=1))
>>>>>>>>>>>>>
>>>>>>>>>>>>> Cheers,
>>>>>>>>>>>>>
>>>>>>>>>>>>> Jarrod
>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>> Quoting Jarrod Hadfield <j.hadfield at ed.ac.uk> on Mon, 25  
>>>>>>>>>>>>> Aug 2014 17:14:14 +0100:
>>>>>>>>>>>>>
>>>>>>>>>>>>>> Hi Ruben,
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> You will need to provide over-dispersed starting values  
>>>>>>>>>>>>>> for multiple-chain convergence diagnostics to be useful  
>>>>>>>>>>>>>> (GLMM are so simple I am generally happy if the output  
>>>>>>>>>>>>>> of a single run looks reasonable).
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> With non-Gaussian data everything is Gibbs sampled  
>>>>>>>>>>>>>> conditional on the latent variables, so you only need  
>>>>>>>>>>>>>> to pass them:
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> l<-rnorm(200, -1, sqrt(1))
>>>>>>>>>>>>>> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
>>>>>>>>>>>>>> y<-rpois(200,exp(l)-t)+1
>>>>>>>>>>>>>> # generate zero-truncated data with an intercept of -1
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> dat<-data.frame(y=y)
>>>>>>>>>>>>>> set.seed(1)
>>>>>>>>>>>>>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat,  
>>>>>>>>>>>>>> start=list(Liab=l))
>>>>>>>>>>>>>> # use true latent variable as starting values
>>>>>>>>>>>>>> set.seed(1)
>>>>>>>>>>>>>> m2<-MCMCglmm(y~1, family="ztpoisson", data=dat,  
>>>>>>>>>>>>>> start=list(Liab=rnorm(200)))
>>>>>>>>>>>>>> # use some very bad starting values
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> plot(mcmc.list(m1$Sol, m2$Sol))
>>>>>>>>>>>>>> # not identical despite the same seed because of  
>>>>>>>>>>>>>> different starting values but clearly sampling the same  
>>>>>>>>>>>>>> posterior distribution:
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> gelman.diag(mcmc.list(m1$Sol, m2$Sol))
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> Cheers,
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> Jarrod
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25  
>>>>>>>>>>>>>> Aug 2014 18:00:08 +0200:
>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> Dear Jarrod,
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> thanks for the quick reply. Please, don't waste time  
>>>>>>>>>>>>>>> looking into doMPI ? I am happy that I
>>>>>>>>>>>>>>> get the expected result, when I specify that  
>>>>>>>>>>>>>>> reproducible seed, whyever that may be.
>>>>>>>>>>>>>>> I'm pretty sure that is the deciding factor, because I  
>>>>>>>>>>>>>>> tested it explicitly, I just have no idea
>>>>>>>>>>>>>>> how/why it interacts with the choice of family.
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> That said, is setting up different RNG streams for my  
>>>>>>>>>>>>>>> workers (now that it works) __sufficient__
>>>>>>>>>>>>>>> so that I get independent chains and can use  
>>>>>>>>>>>>>>> gelman.diag() for convergence diagnostics?
>>>>>>>>>>>>>>> Or should I still tinker with the starting values myself?
>>>>>>>>>>>>>>> I've never found a worked example of supplying  
>>>>>>>>>>>>>>> starting values and am thus a bit lost.
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> Sorry for sending further questions, I hope someone  
>>>>>>>>>>>>>>> else takes pity while
>>>>>>>>>>>>>>> you're busy with lectures.
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> Best wishes
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> Ruben
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> On 25 Aug 2014, at 17:29, Jarrod Hadfield  
>>>>>>>>>>>>>>> <j.hadfield at ed.ac.uk> wrote:
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> Hi Ruben,
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> I do not think the issue is with the starting values,  
>>>>>>>>>>>>>>>> because even if the same starting values were used  
>>>>>>>>>>>>>>>> the chains would still differ because of the  
>>>>>>>>>>>>>>>> randomness in the Markov Chain (if I interpret your  
>>>>>>>>>>>>>>>> `identical' test correctly). This just involves a  
>>>>>>>>>>>>>>>> call to GetRNGstate() in the C++ code (L 871  
>>>>>>>>>>>>>>>> ofMCMCglmm.cc) so I think for some reason  
>>>>>>>>>>>>>>>> doMPI/foreach is not doing what you expect. I am not  
>>>>>>>>>>>>>>>> familiar with doMPI and am in the middle of writing  
>>>>>>>>>>>>>>>> lectures so haven't got time to look into it  
>>>>>>>>>>>>>>>> carefully. Outside of the context of doMPI I get the  
>>>>>>>>>>>>>>>> behaviour I expect:
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> l<-rnorm(200, -1, sqrt(1))
>>>>>>>>>>>>>>>> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
>>>>>>>>>>>>>>>> y<-rpois(200,exp(l)-t)+1
>>>>>>>>>>>>>>>> # generate zero-truncated data with an intercept of -1
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> dat<-data.frame(y=y)
>>>>>>>>>>>>>>>> set.seed(1)
>>>>>>>>>>>>>>>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>>>>>>>>>>>>>> set.seed(2)
>>>>>>>>>>>>>>>> m2<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>>>>>>>>>>>>>> set.seed(2)
>>>>>>>>>>>>>>>> m3<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> plot(mcmc.list(m1$Sol, m2$Sol))
>>>>>>>>>>>>>>>> # different, as expected
>>>>>>>>>>>>>>>> plot(mcmc.list(m2$Sol, m3$Sol))
>>>>>>>>>>>>>>>> # the same, as expected
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon,  
>>>>>>>>>>>>>>>> 25 Aug 2014 16:58:06 +0200:
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>> Dear list,
>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>> sorry for bumping my old post, I hope to elicit a  
>>>>>>>>>>>>>>>>> response with a more focused question:
>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>> When does MCMCglmm automatically start from  
>>>>>>>>>>>>>>>>> different values when using doMPI/foreach?
>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>> I have done some tests with models of varying  
>>>>>>>>>>>>>>>>> complexity. For example, the script in my last
>>>>>>>>>>>>>>>>> post (using "zapoisson") yielded 40 identical chains:
>>>>>>>>>>>>>>>>>> identical(mcmclist[1], mcmclist[30])
>>>>>>>>>>>>>>>>> TRUE
>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>> A simpler (?) model (using "ztpoisson" and no  
>>>>>>>>>>>>>>>>> specified prior), however, yielded different chains
>>>>>>>>>>>>>>>>> and I could use them to calculate gelman.diag()
>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>> Changing my script to the version below, i.e.  
>>>>>>>>>>>>>>>>> seeding foreach using .options.mpi=list( seed= 1337)
>>>>>>>>>>>>>>>>> so as to make RNGstreams reproducible (or so I   
>>>>>>>>>>>>>>>>> thought), led to different chains even for the
>>>>>>>>>>>>>>>>> "zapoisson" model.
>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>> In no case have I (successfully) tried to supplant  
>>>>>>>>>>>>>>>>> the default of MCMCglmm's "start" argument.
>>>>>>>>>>>>>>>>> Is starting my models from different RNGsubstreams  
>>>>>>>>>>>>>>>>> inadequate compared to manipulating
>>>>>>>>>>>>>>>>> the start argument explicitly? If so, is there any  
>>>>>>>>>>>>>>>>> worked example of explicit starting value manipulation
>>>>>>>>>>>>>>>>> in parallel computation?
>>>>>>>>>>>>>>>>> I've browsed the MCMCglmm source to understand how  
>>>>>>>>>>>>>>>>> the default starting values are generated,
>>>>>>>>>>>>>>>>> but didn't find any differences with respect to RNG  
>>>>>>>>>>>>>>>>> for the two families "ztpoisson" and "zapoisson"
>>>>>>>>>>>>>>>>> (granted, I did not dig very deep).
>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>> Best regards,
>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>> Ruben Arslan
>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>> # bsub -q mpi -W 12:00 -n 41 -R np20 mpirun -H  
>>>>>>>>>>>>>>>>> localhost -n 41 R --slave -f  
>>>>>>>>>>>>>>>>> "/usr/users/rarslan/rpqa/rpqa_main/rpqa_children_parallel.R"
>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>> library(doMPI)
>>>>>>>>>>>>>>>>> cl <-  
>>>>>>>>>>>>>>>>> startMPIcluster(verbose=T,workdir="/usr/users/rarslan/rpqa/rpqa_main/")
>>>>>>>>>>>>>>>>> registerDoMPI(cl)
>>>>>>>>>>>>>>>>> Children_mcmc1 =  
>>>>>>>>>>>>>>>>> foreach(i=1:clusterSize(cl),.options.mpi =  
>>>>>>>>>>>>>>>>> list(seed=1337) ) %dopar% {
>>>>>>>>>>>>>>>>> 	library(MCMCglmm);library(data.table)
>>>>>>>>>>>>>>>>> 	load("/usr/users/rarslan/rpqa/rpqa1.rdata")
>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>> 	nitt = 130000; thin = 100; burnin = 30000
>>>>>>>>>>>>>>>>> 	prior.m5d.2 = list(
>>>>>>>>>>>>>>>>> 		R = list(V = diag(c(1,1)), nu = 0.002),
>>>>>>>>>>>>>>>>> 		G=list(list(V=diag(c(1,1e-6)),nu=0.002))
>>>>>>>>>>>>>>>>> 	)
>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>> 	rpqa.1 = na.omit(rpqa.1[spouses>0, list(idParents,  
>>>>>>>>>>>>>>>>> children, male, urban, spouses, paternalage.mean,  
>>>>>>>>>>>>>>>>> paternalage.factor)])
>>>>>>>>>>>>>>>>> 	(m1 = MCMCglmm( children ~ trait * (male + urban +  
>>>>>>>>>>>>>>>>> spouses + paternalage.mean + paternalage.factor),
>>>>>>>>>>>>>>>>> 						rcov=~us(trait):units,
>>>>>>>>>>>>>>>>> 						random=~us(trait):idParents,
>>>>>>>>>>>>>>>>> 						family="zapoisson",
>>>>>>>>>>>>>>>>> 						prior = prior.m5d.2,
>>>>>>>>>>>>>>>>> 						data=rpqa.1,
>>>>>>>>>>>>>>>>> 						pr = F, saveX = F, saveZ = F,
>>>>>>>>>>>>>>>>> 						nitt=nitt,thin=thin,burnin=burnin))
>>>>>>>>>>>>>>>>> }
>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>> library(coda)
>>>>>>>>>>>>>>>>> mcmclist =  
>>>>>>>>>>>>>>>>> mcmc.list(lapply(Children_mcmc1,FUN=function(x) {  
>>>>>>>>>>>>>>>>> x$Sol}))
>>>>>>>>>>>>>>>>> save(Children_mcmc1,mcmclist, file =  
>>>>>>>>>>>>>>>>> "/usr/users/rarslan/rpqa/rpqa_main/rpqa_mcmc_kids_za.rdata")
>>>>>>>>>>>>>>>>> closeCluster(cl)
>>>>>>>>>>>>>>>>> mpi.quit()
>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>> On 04 Aug 2014, at 20:25, Ruben Arslan  
>>>>>>>>>>>>>>>>> <rubenarslan at gmail.com> wrote:
>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>> Dear list,
>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>> would someone be willing to share her or his  
>>>>>>>>>>>>>>>>>> efforts in parallelising a MCMCglmm analysis?
>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>> I had something viable using harvestr that seemed  
>>>>>>>>>>>>>>>>>> to properly initialise
>>>>>>>>>>>>>>>>>> the starting values from different random number  
>>>>>>>>>>>>>>>>>> streams (which is desirable,
>>>>>>>>>>>>>>>>>> as far as I could find out), but I ended up being  
>>>>>>>>>>>>>>>>>> unable to use harvestr, because
>>>>>>>>>>>>>>>>>> it uses an old version of plyr, where  
>>>>>>>>>>>>>>>>>> parallelisation works only for multicore, not for
>>>>>>>>>>>>>>>>>> MPI.
>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>> I pasted my working version, that does not do  
>>>>>>>>>>>>>>>>>> anything about starting values or RNG
>>>>>>>>>>>>>>>>>> at the end of this email. I can try to fumble  
>>>>>>>>>>>>>>>>>> further in the dark or try to update harvestr,
>>>>>>>>>>>>>>>>>> but maybe someone has gone through all this already.
>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>> I'd also appreciate any tips for elegantly  
>>>>>>>>>>>>>>>>>> post-processing such parallel data, as some of my  
>>>>>>>>>>>>>>>>>> usual
>>>>>>>>>>>>>>>>>> extraction functions and routines are hampered by  
>>>>>>>>>>>>>>>>>> the fact that some coda functions
>>>>>>>>>>>>>>>>>> do not aggregate results over chains. (What I get  
>>>>>>>>>>>>>>>>>> from a single-chain summary in MCMCglmm
>>>>>>>>>>>>>>>>>> is a bit more comprehensive, than what I managed to  
>>>>>>>>>>>>>>>>>> cobble together with my own extraction
>>>>>>>>>>>>>>>>>> functions).
>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>> The reason I'm parallelising my analyses is that  
>>>>>>>>>>>>>>>>>> I'm having trouble getting a good effective
>>>>>>>>>>>>>>>>>> sample size for any parameter having to do with the  
>>>>>>>>>>>>>>>>>> many zeroes in my data.
>>>>>>>>>>>>>>>>>> Any pointers are very appreciated, I'm quite  
>>>>>>>>>>>>>>>>>> inexperienced with MCMCglmm.
>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>> Best wishes
>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>> Ruben
>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>> # bsub -q mpi-short -W 2:00 -n 42 -R np20 mpirun -H  
>>>>>>>>>>>>>>>>>> localhost -n 41 R --slave -f  
>>>>>>>>>>>>>>>>>> "rpqa/rpqa_main/rpqa_children_parallel.r"
>>>>>>>>>>>>>>>>>> library(doMPI)
>>>>>>>>>>>>>>>>>> cl <- startMPIcluster()
>>>>>>>>>>>>>>>>>> registerDoMPI(cl)
>>>>>>>>>>>>>>>>>> Children_mcmc1 = foreach(i=1:40) %dopar% {
>>>>>>>>>>>>>>>>>> 	library(MCMCglmm)
>>>>>>>>>>>>>>>>>> 	load("rpqa1.rdata")
>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>> 	nitt = 40000; thin = 100; burnin = 10000
>>>>>>>>>>>>>>>>>> 	prior = list(
>>>>>>>>>>>>>>>>>> 		R = list(V = diag(c(1,1)), nu = 0.002),
>>>>>>>>>>>>>>>>>> 		G=list(list(V=diag(c(1,1e-6)),nu=0.002))
>>>>>>>>>>>>>>>>>> 	)
>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>> 	MCMCglmm( children ~ trait -1 +  
>>>>>>>>>>>>>>>>>> at.level(trait,1):male + at.level(trait,1):urban +  
>>>>>>>>>>>>>>>>>> at.level(trait,1):spouses +  
>>>>>>>>>>>>>>>>>> at.level(trait,1):paternalage.mean +  
>>>>>>>>>>>>>>>>>> at.level(trait,1):paternalage.factor,
>>>>>>>>>>>>>>>>>> 		rcov=~us(trait):units,
>>>>>>>>>>>>>>>>>> 		random=~us(trait):idParents,
>>>>>>>>>>>>>>>>>> 		family="zapoisson",
>>>>>>>>>>>>>>>>>> 		prior = prior,
>>>>>>>>>>>>>>>>>> 		data=rpqa.1,
>>>>>>>>>>>>>>>>>> 		pr = F, saveX = T, saveZ = T,
>>>>>>>>>>>>>>>>>> 		nitt=nitt,thin=thin,burnin=burnin)
>>>>>>>>>>>>>>>>>> }
>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>> library(coda)
>>>>>>>>>>>>>>>>>> mcmclist =  
>>>>>>>>>>>>>>>>>> mcmc.list(lapply(Children_mcmc1,FUN=function(x) {  
>>>>>>>>>>>>>>>>>> x$Sol}))
>>>>>>>>>>>>>>>>>> save(Children_mcmc1,mcmclist, file =  
>>>>>>>>>>>>>>>>>> "rpqa_mcmc_kids_za.rdata")
>>>>>>>>>>>>>>>>>> closeCluster(cl)
>>>>>>>>>>>>>>>>>> mpi.quit()
>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>> --
>>>>>>>>>>>>>>>>>> Ruben C. Arslan
>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>> Georg August University G?ttingen
>>>>>>>>>>>>>>>>>> Biological Personality Psychology and Psychological  
>>>>>>>>>>>>>>>>>> Assessment
>>>>>>>>>>>>>>>>>> Georg Elias M?ller Institute of Psychology
>>>>>>>>>>>>>>>>>> Go?lerstr. 14
>>>>>>>>>>>>>>>>>> 37073 G?ttingen
>>>>>>>>>>>>>>>>>> Germany
>>>>>>>>>>>>>>>>>> Tel.: +49 551 3920704
>>>>>>>>>>>>>>>>>> https://psych.uni-goettingen.de/en/biopers/team/arslan
>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>> 	[[alternative HTML version deleted]]
>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> --
>>>>>>>>>>>>>>>> The University of Edinburgh is a charitable body,  
>>>>>>>>>>>>>>>> registered in
>>>>>>>>>>>>>>>> Scotland, with registration number SC005336.
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>
>>>>>>>>>>>>>>
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> --
>>>>>>>>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>>>>>>>>> Scotland, with registration number SC005336.
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> _______________________________________________
>>>>>>>>>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>> --
>>>>>>>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>>>>>>>> Scotland, with registration number SC005336.
>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>> --
>>>>>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>>>>>> Scotland, with registration number SC005336.
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> --
>>>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>>>> Scotland, with registration number SC005336.
>>>>>>>>>
>>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> --
>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>> Scotland, with registration number SC005336.
>>>>>>>
>>>>>>>
>>>>>>
>>>>>>
>>>>>
>>>>>
>>>>> --
>>>>> The University of Edinburgh is a charitable body, registered in
>>>>> Scotland, with registration number SC005336.
>>>>>
>>>>>
>>>>
>>>>
>>>
>>>
>>>
>>> --
>>> The University of Edinburgh is a charitable body, registered in
>>> Scotland, with registration number SC005336.
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>> --
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>>
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From rubenarslan at gmail.com  Fri Aug 29 12:14:44 2014
From: rubenarslan at gmail.com (Ruben Arslan)
Date: Fri, 29 Aug 2014 12:14:44 +0200
Subject: [R-sig-ME] parallel MCMCglmm, RNGstreams,
	starting values & priors
In-Reply-To: <20140829110259.60094j3omtxmddkw@www.staffmail.ed.ac.uk>
References: <4CD76FE1-D3F5-4980-9122-B0AC0D44FF81@gmail.com>
	<0E12EB43-72BC-42AC-9E74-9DF53DB42217@gmail.com>
	<20140825162907.10475jpywlu1wzs4@www.staffmail.ed.ac.uk>
	<0A463095-8656-49B7-9619-E557DD449E21@gmail.com>
	<20140825171414.10872gnlopk1we68@www.staffmail.ed.ac.uk>
	<20140825172936.15916weehiwjyc08@www.staffmail.ed.ac.uk>
	<8D35B834-0D31-486A-B5FB-0F279761FDB2@gmail.com>
	<49D60399-6902-45AC-80A9-9F3C35532228@gmail.com>
	<20140826120434.14613hxqhgwbhq80@www.staffmail.ed.ac.uk>
	<8557AE32-AFC9-4FD2-9C88-2D118B484637@gmail.com>
	<20140827183959.18662zc6hw5jj20w@www.staffmail.ed.ac.uk>
	<2D00600E-5287-4FE1-B605-82C0CBA286ED@gmail.com>
	<20140828180551.74212a0xoeoihn6s@www.staffmail.ed.ac.uk>
	<BBB5F7E3-75FE-4BA3-82B4-49DAA64873A4@gmail.com>
	<20140828195957.68171hjra56vrrr4@www.staffmail.ed.ac.uk>
	<E5B149F2-7773-4E2D-854C-3275A352A245@gmail.com>
	<20140829080442.1833246y8pj3itq8@www.staffmail.ed.ac.uk>
	<20140829081333.16792k7qrimekagw@www.staffmail.ed.ac.uk>
	<7F4CEBA1-CFF9-4FBA-883B-8263CAC018EE@gmail.com>
	<20140829110259.60094j3omtxmddkw@www.staffmail.ed.ac.uk>
Message-ID: <406437CD-C96A-4875-B77B-2114F889EB3D@gmail.com>

That's what I did, I think.

equality = c()
for(i in 1:1000)
{
	prior <- list(
		R=list(V=diag(2), nu=1.002, fix=2), 
		G=list(G1=list(V=diag(2), nu=1, alpha.mu=c(0,0), alpha.V=diag(2)*1000))
	)
	
	start <- list(
		liab=c(rnorm( nrow(krmh.1)*2 )), 
		R = list(R1 = rIW(diag(2), 10 , fix = 2)), ### FIX=2 HERE AS WELL
		G = list(G1 = rIW(diag(2), 10 ))
	)
	equality[i] = prior$R$V[2,2]==start$R$R1[2,2]
}
all(equality==T)


On 29 Aug 2014, at 12:02, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:

> Hi,
> 
> You need to make sure that they are fixed at the same value, not just fixed.
> 
> Cheers,
> 
> Jarrod
> 
> 
> 
> Quoting Ruben Arslan <rubenarslan at gmail.com> on Fri, 29 Aug 2014 11:07:21 +0200:
> 
>> Hi Jarrod,
>> 
>> that was exactly it. I hadn't checked the $VCV mcmclist, but I'll do so in the future
>> as the mistake is blindingly obvious that way: http://imgur.com/nlA0QwZ
>> 
>> After adding fix=2 to R1 in my starting values, my parallel chains converged as well.
>> 
>> For future amateurs reading this:
>> prior <- list(
>> 	R=list(V=diag(2), nu=1.002, fix=2),
>> 	G=list(G1=list(V=diag(2), nu=1, alpha.mu=c(0,0), alpha.V=diag(2)*1000))
>> )
>> 
>> start <- list(
>> 	liab=c(rnorm( nrow(krmh.1)*2 )),
>> 	R = list(R1 = rIW(diag(2), 10 , fix = 2)), ### FIX=2 HERE AS WELL
>> 	G = list(G1 = rIW(diag(2), 10 ))
>> )
>> 
>> Thank you so much. This sort of remote diagnosis with this little information
>> seems borderline psychic to me.
>> Now, onwards to modelling the pedigrees :-)
>> 
>> Best wishes,
>> 
>> Ruben
>> 
>> PS.: I never actually figured out what kind of variability to use for rIW() in my starting values,
>> but it doesn't seem to matter and that's what I should want I suppose. Actually, even with the mis-specified
>> starting values my posterior looked pretty similar to now.
>> 
>> On 29 Aug 2014, at 09:13, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>> 
>>> Hi Ruben,
>>> 
>>> Actually I might know what it is. When you sample different starting values do you inadvertently sample a new residual variance for the unidentified za part? You need to make sure that this is always fixed at the same value (otherwise the model is different). This is not a problem under the trait:units specification.
>>> 
>>> Cheers,
>>> 
>>> Jarrod.
>>> 
>>> 
>>> 
>>> Quoting Jarrod Hadfield <j.hadfield at ed.ac.uk> on Fri, 29 Aug 2014 08:04:42 +0100:
>>> 
>>>> Hi Ruben,
>>>> 
>>>> Can you share your data and I will take a look. Its definitely not Monte Carlo error.
>>>> 
>>>> Cheers,
>>>> 
>>>> Jarrod
>>>> 
>>>> 
>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Thu, 28 Aug 2014 22:44:47 +0200:
>>>> 
>>>>> Hi Jarrod,
>>>>> 
>>>>> those two matched up quite well yes. I just completed another 20 chains, using more variable
>>>>> starting values. There's still two fixed effects traitza_children:spouses  and :male which haven't converged
>>>>> according to multi-chain (gelman), but have according to geweke.
>>>>> The offending traces: http://imgur.com/Qm6Ovfr
>>>>> These specific effects aren't of interest to me, so if this doesn't affect the rest of my estimates, I can be happy
>>>>> with this, but I can't conclude that, can I?
>>>>> 
>>>>> I'm now also doing a run to see how it deals with the more intensely zero-inflated data when including
>>>>> the unmarried.
>>>>> 
>>>>> Thanks a lot for all that help,
>>>>> 
>>>>> Ruben
>>>>> 
>>>>>> gelman.diag(mcmclist)
>>>>> Potential scale reduction factors:
>>>>> 
>>>>>                                         Point est. Upper C.I.
>>>>> (Intercept)                                      1.00       1.00
>>>>> traitza_children                                 1.40       1.65
>>>>> male                                             1.00       1.00
>>>>> spouses                                          1.00       1.00
>>>>> paternalage.mean                                 1.00       1.00
>>>>> paternalage.factor(25,30]                        1.00       1.00
>>>>> paternalage.factor(30,35]                        1.00       1.00
>>>>> paternalage.factor(35,40]                        1.00       1.00
>>>>> paternalage.factor(40,45]                        1.00       1.00
>>>>> paternalage.factor(45,50]                        1.00       1.00
>>>>> paternalage.factor(50,55]                        1.00       1.00
>>>>> paternalage.factor(55,90]                        1.00       1.00
>>>>> traitza_children:male                            1.33       1.54
>>>>> traitza_children:spouses                         2.21       2.83
>>>>> traitza_children:paternalage.mean                1.01       1.02
>>>>> traitza_children:paternalage.factor(25,30]       1.05       1.08
>>>>> traitza_children:paternalage.factor(30,35]       1.08       1.13
>>>>> traitza_children:paternalage.factor(35,40]       1.15       1.25
>>>>> traitza_children:paternalage.factor(40,45]       1.15       1.26
>>>>> traitza_children:paternalage.factor(45,50]       1.26       1.43
>>>>> traitza_children:paternalage.factor(50,55]       1.15       1.25
>>>>> traitza_children:paternalage.factor(55,90]       1.14       1.23
>>>>> 
>>>>> Multivariate psrf
>>>>> 
>>>>> 8.99
>>>>> 
>>>>>> summary(mcmclist)
>>>>> 
>>>>> Iterations = 100001:149951
>>>>> Thinning interval = 50
>>>>> Number of chains = 20
>>>>> Sample size per chain = 1000
>>>>> 
>>>>> 1. Empirical mean and standard deviation for each variable,
>>>>> plus standard error of the mean:
>>>>> 
>>>>>                                             Mean      SD  Naive SE Time-series SE
>>>>> (Intercept)                                 1.36326 0.04848 0.0003428      0.0003542
>>>>> traitza_children                           -0.76679 0.28738 0.0020321      0.0016682
>>>>> male                                        0.09980 0.01633 0.0001155      0.0001222
>>>>> spouses                                     0.12333 0.01957 0.0001384      0.0001414
>>>>> paternalage.mean                            0.07215 0.02194 0.0001551      0.0001596
>>>>> paternalage.factor(25,30]                  -0.03381 0.04184 0.0002959      0.0003066
>>>>> paternalage.factor(30,35]                  -0.08380 0.04270 0.0003019      0.0003118
>>>>> paternalage.factor(35,40]                  -0.16502 0.04569 0.0003231      0.0003289
>>>>> paternalage.factor(40,45]                  -0.16738 0.05090 0.0003599      0.0003697
>>>>> paternalage.factor(45,50]                  -0.18383 0.05880 0.0004158      0.0004242
>>>>> paternalage.factor(50,55]                  -0.18241 0.07277 0.0005146      0.0005302
>>>>> paternalage.factor(55,90]                  -0.40612 0.09875 0.0006983      0.0007467
>>>>> traitza_children:male                       0.12092 0.08223 0.0005815      0.0004697
>>>>> traitza_children:spouses                    0.64881 0.21132 0.0014942      0.0008511
>>>>> traitza_children:paternalage.mean          -0.02741 0.08550 0.0006046      0.0006221
>>>>> traitza_children:paternalage.factor(25,30] -0.17296 0.18680 0.0013209      0.0013750
>>>>> traitza_children:paternalage.factor(30,35] -0.19027 0.19267 0.0013624      0.0013901
>>>>> traitza_children:paternalage.factor(35,40] -0.24911 0.21282 0.0015049      0.0014391
>>>>> traitza_children:paternalage.factor(40,45] -0.29772 0.23403 0.0016548      0.0015956
>>>>> traitza_children:paternalage.factor(45,50] -0.51782 0.28589 0.0020215      0.0017602
>>>>> traitza_children:paternalage.factor(50,55] -0.46126 0.32064 0.0022673      0.0021397
>>>>> traitza_children:paternalage.factor(55,90] -0.38612 0.41461 0.0029317      0.0027396
>>>>> 
>>>>> 2. Quantiles for each variable:
>>>>> 
>>>>>                                             2.5%      25%      50%      75%      97.5%
>>>>> (Intercept)                                 1.26883  1.33106  1.36322  1.39575  1.4589722
>>>>> traitza_children                           -1.20696 -0.95751 -0.81076 -0.63308 -0.0365042
>>>>> male                                        0.06785  0.08878  0.09970  0.11085  0.1320168
>>>>> spouses                                     0.08467  0.11030  0.12343  0.13643  0.1617869
>>>>> paternalage.mean                            0.02950  0.05751  0.07202  0.08683  0.1153881
>>>>> paternalage.factor(25,30]                  -0.11581 -0.06174 -0.03397 -0.00574  0.0473783
>>>>> paternalage.factor(30,35]                  -0.16656 -0.11250 -0.08358 -0.05519  0.0003065
>>>>> paternalage.factor(35,40]                  -0.25518 -0.19530 -0.16500 -0.13440 -0.0757366
>>>>> paternalage.factor(40,45]                  -0.26887 -0.20164 -0.16675 -0.13335 -0.0677407
>>>>> paternalage.factor(45,50]                  -0.30080 -0.22320 -0.18339 -0.14440 -0.0687967
>>>>> paternalage.factor(50,55]                  -0.32663 -0.23034 -0.18227 -0.13317 -0.0415547
>>>>> paternalage.factor(55,90]                  -0.60202 -0.47303 -0.40454 -0.33994 -0.2139128
>>>>> traitza_children:male                      -0.01083  0.06634  0.11024  0.16109  0.3295892
>>>>> traitza_children:spouses                    0.37857  0.51072  0.59398  0.71395  1.2127940
>>>>> traitza_children:paternalage.mean          -0.19138 -0.08250 -0.02985  0.02493  0.1468989
>>>>> traitza_children:paternalage.factor(25,30] -0.57457 -0.28481 -0.16489 -0.05151  0.1728148
>>>>> traitza_children:paternalage.factor(30,35] -0.61499 -0.30350 -0.17736 -0.06299  0.1555147
>>>>> traitza_children:paternalage.factor(35,40] -0.74251 -0.36752 -0.22966 -0.10777  0.1151897
>>>>> traitza_children:paternalage.factor(40,45] -0.84165 -0.42691 -0.27729 -0.14322  0.1032436
>>>>> traitza_children:paternalage.factor(45,50] -1.21782 -0.66568 -0.48420 -0.32873 -0.0476720
>>>>> traitza_children:paternalage.factor(50,55] -1.21327 -0.63623 -0.43432 -0.24957  0.0955360
>>>>> traitza_children:paternalage.factor(55,90] -1.33772 -0.62227 -0.35364 -0.11050  0.3361684
>>>>> 
>>>>>> effectiveSize(mcmclist)
>>>>>                             (Intercept)                           traitza_children
>>>>>                                18814.05                                   16359.33
>>>>>                                    male                                    spouses
>>>>>                                18132.98                                   19547.05
>>>>>                        paternalage.mean                  paternalage.factor(25,30]
>>>>>                                19238.72                                   18974.81
>>>>>               paternalage.factor(30,35]                  paternalage.factor(35,40]
>>>>>                                18874.33                                   19406.63
>>>>>               paternalage.factor(40,45]                  paternalage.factor(45,50]
>>>>>                                19075.18                                   19401.77
>>>>>               paternalage.factor(50,55]                  paternalage.factor(55,90]
>>>>>                                18960.11                                   17893.23
>>>>>                   traitza_children:male                   traitza_children:spouses
>>>>>                                18545.55                                   14438.51
>>>>>       traitza_children:paternalage.mean traitza_children:paternalage.factor(25,30]
>>>>>                                18464.09                                   16943.43
>>>>> traitza_children:paternalage.factor(30,35] traitza_children:paternalage.factor(35,40]
>>>>>                                16827.44                                   17230.04
>>>>> traitza_children:paternalage.factor(40,45] traitza_children:paternalage.factor(45,50]
>>>>>                                17144.78                                   18191.67
>>>>> traitza_children:paternalage.factor(50,55] traitza_children:paternalage.factor(55,90]
>>>>>                                17466.60                                   18540.59
>>>>> 
>>>>> 
>>>>> ### current script:
>>>>> 
>>>>> # bsub -q mpi -W 24:00 -n 21 -R np20 mpirun -H localhost -n 21 R --slave -f "/usr/users/rarslan/rpqa/krmh_main/children.R"
>>>>> setwd("/usr/users/rarslan/rpqa/")
>>>>> library(doMPI)
>>>>> cl <- startMPIcluster(verbose=T,workdir="/usr/users/rarslan/rpqa/krmh_main/")
>>>>> registerDoMPI(cl)
>>>>> Children = foreach(i=1:clusterSize(cl),.options.mpi = list(seed=1337) ) %dopar% {
>>>>> 	library(MCMCglmm);library(data.table)
>>>>>  setwd("/usr/users/rarslan/rpqa/krmh_main/")
>>>>> 	source("../1 - extraction functions.r")
>>>>>  load("../krmh1.rdata")
>>>>> 
>>>>> 	krmh.1 = recenter.pat(na.omit(krmh.1[spouses>0, list(idParents, children, male, spouses, paternalage)]))
>>>>> 
>>>>> 	samples = 1000
>>>>> 	thin = 50; burnin = 100000
>>>>> 	nitt = samples * thin + burnin
>>>>> 
>>>>> 	prior <- list(
>>>>> 		R=list(V=diag(2), nu=1.002, fix=2),
>>>>> 		G=list(G1=list(V=diag(2), nu=1, alpha.mu=c(0,0), alpha.V=diag(2)*1000))
>>>>> 	)
>>>>> 
>>>>> 	start <- list(
>>>>> 		liab=c(rnorm( nrow(krmh.1)*2 )),
>>>>> 		R = list(R1 = rIW(diag(2), 10 )),
>>>>> 		G = list(G1 = rIW(diag(2), 10 ))
>>>>> 	)
>>>>> 
>>>>> 	( m1 = MCMCglmm( children ~ trait * (male + spouses + paternalage.mean + paternalage.factor),
>>>>> 						rcov=~idh(trait):units,
>>>>> 						random=~idh(trait):idParents,
>>>>> 						family="zapoisson",
>>>>> 						start = start,
>>>>> 						prior = prior,
>>>>> 						data=krmh.1,
>>>>> 						pr = F, saveX = F, saveZ = F,
>>>>> 						nitt=nitt,thin=thin,burnin=burnin)
>>>>> 	)
>>>>> 		m1$Residual$nrt<-2
>>>>> 	m1
>>>>> }
>>>>> 
>>>>> save(Children,file = "Children.rdata")
>>>>> closeCluster(cl)
>>>>> mpi.quit()
>>>>> 
>>>>> On 28 Aug 2014, at 20:59, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>>>> 
>>>>>> Hi,
>>>>>> 
>>>>>> The posteriors for the two models look pretty close to me. Are the scale reduction factors really as high as previously reported? Before you had 1.83 for traitza_children:spouses, but the plot suggests that it should be close to 1?
>>>>>> 
>>>>>> Cheers,
>>>>>> 
>>>>>> Jarrod
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Thu, 28 Aug 2014 19:59:16 +0200:
>>>>>> 
>>>>>>> Sure! Thanks a lot.
>>>>>>> I am using ~idh(trait):units already, sorry for saying that incorrectly in my last email.
>>>>>>> These models aren't the final thing, I will replace the paternalage.factor variable
>>>>>>> with its linear equivalent if that seems defensible (does so far) and in this model it seems
>>>>>>> okay to remove the za-effects for all predictors except spouses.
>>>>>>> So a final model would have fewer fixed effects. I also have datasets of 200k+ and 5m+,
>>>>>>> but I'm learning MCMCglmm with this smaller one because my wrong turns take less time.
>>>>>>> 
>>>>>>> I've uploaded a comparison coef plot of two models:
>>>>>>> http://i.imgur.com/sHUfnmd.png
>>>>>>> m7 is with the default starting values, m1 is with the specification I sent in my last email. I don't
>>>>>>> know if such differences are something to worry about.
>>>>>>> 
>>>>>>> I don't know what qualifies as highly overdispersed, here's a plot of the outcome for ever
>>>>>>> married people (slate=real data):
>>>>>>> http://imgur.com/14MywgZ
>>>>>>> here's with everybody born (incl. some stillborn etc.):
>>>>>>> http://imgur.com/knRGa1v
>>>>>>> I guess my approach (generating an overdispersed poisson with the parameters from
>>>>>>> the data and checking if it has as excess zeroes) is not the best way to diagnose zero-inflation,
>>>>>>> but especially in the second case it seems fairly clear-cut.
>>>>>>> 
>>>>>>> Best regards,
>>>>>>> 
>>>>>>> Ruben
>>>>>>> 
>>>>>>>> summary(m1)
>>>>>>> 
>>>>>>> Iterations = 50001:149951
>>>>>>> Thinning interval  = 50
>>>>>>> Sample size  = 2000
>>>>>>> 
>>>>>>> DIC: 31249.73
>>>>>>> 
>>>>>>> G-structure:  ~idh(trait):idParents
>>>>>>> 
>>>>>>>                   post.mean  l-95% CI u-95% CI eff.samp
>>>>>>> children.idParents     0.006611 4.312e-08   0.0159    523.9
>>>>>>> za_children.idParents  0.193788 7.306e-02   0.3283    369.3
>>>>>>> 
>>>>>>> R-structure:  ~idh(trait):units
>>>>>>> 
>>>>>>>               post.mean l-95% CI u-95% CI eff.samp
>>>>>>> children.units       0.1285   0.1118   0.1452    716.1
>>>>>>> za_children.units    0.9950   0.9950   0.9950      0.0
>>>>>>> 
>>>>>>> Location effects: children ~ trait * (male + spouses + paternalage.mean + paternalage.factor)
>>>>>>> 
>>>>>>>                                         post.mean   l-95% CI   u-95% CI eff.samp  pMCMC
>>>>>>> (Intercept)                                 1.3413364  1.2402100  1.4326099     1789 <5e-04 ***
>>>>>>> traitza_children                           -0.8362879 -1.2007980 -0.5016730     1669 <5e-04 ***
>>>>>>> male                                        0.0994902  0.0679050  0.1297394     2000 <5e-04 ***
>>>>>>> spouses                                     0.1236033  0.0839000  0.1624939     2000 <5e-04 ***
>>>>>>> paternalage.mean                            0.0533892  0.0119569  0.0933960     2000  0.015 *
>>>>>>> paternalage.factor(25,30]                  -0.0275822 -0.1116421  0.0537359     1842  0.515
>>>>>>> paternalage.factor(30,35]                  -0.0691025 -0.1463214  0.0122393     1871  0.097 .
>>>>>>> paternalage.factor(35,40]                  -0.1419933 -0.2277379 -0.0574678     1845 <5e-04 ***
>>>>>>> paternalage.factor(40,45]                  -0.1364952 -0.2362714 -0.0451874     1835  0.007 **
>>>>>>> paternalage.factor(45,50]                  -0.1445342 -0.2591767 -0.0421178     1693  0.008 **
>>>>>>> paternalage.factor(50,55]                  -0.1302972 -0.2642965  0.0077061     2000  0.064 .
>>>>>>> paternalage.factor(55,90]                  -0.3407879 -0.5168972 -0.1493652     1810 <5e-04 ***
>>>>>>> traitza_children:male                       0.0926888 -0.0147379  0.2006142     1901  0.098 .
>>>>>>> traitza_children:spouses                    0.5531197  0.3870616  0.7314289     1495 <5e-04 ***
>>>>>>> traitza_children:paternalage.mean           0.0051463 -0.1279396  0.1460099     1617  0.960
>>>>>>> traitza_children:paternalage.factor(25,30] -0.1538957 -0.4445749  0.1462955     1781  0.321
>>>>>>> traitza_children:paternalage.factor(30,35] -0.1747883 -0.4757851  0.1162476     1998  0.261
>>>>>>> traitza_children:paternalage.factor(35,40] -0.2261843 -0.5464379  0.0892582     1755  0.166
>>>>>>> traitza_children:paternalage.factor(40,45] -0.2807543 -0.6079678  0.0650281     1721  0.100 .
>>>>>>> traitza_children:paternalage.factor(45,50] -0.4905843 -0.8649214 -0.1244174     1735  0.010 **
>>>>>>> traitza_children:paternalage.factor(50,55] -0.4648579 -0.9215759 -0.0002083     1687  0.054 .
>>>>>>> traitza_children:paternalage.factor(55,90] -0.3945406 -1.0230155  0.2481568     1793  0.195
>>>>>>> ---
>>>>>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>>>>> 
>>>>>>>> describe(krmh.1[spouses>0,])
>>>>>>>                 vars    n mean   sd median trimmed  mad   min   max range skew kurtosis   se
>>>>>>> children               2 6829 3.81 2.93   4.00    3.61 2.97  0.00 16.00 16.00 0.47    -0.46 0.04
>>>>>>> male                   3 6829 0.46 0.50   0.00    0.45 0.00  0.00  1.00  1.00 0.14    -1.98 0.01
>>>>>>> spouses                4 6829 1.14 0.38   1.00    1.03 0.00  1.00  4.00  3.00 2.87     8.23 0.00
>>>>>>> paternalage            5 6829 3.65 0.80   3.57    3.60 0.80  1.83  7.95  6.12 0.69     0.70 0.01
>>>>>>> paternalage_c          6 6829 0.00 0.80  -0.08   -0.05 0.80 -1.82  4.30  6.12 0.69     0.70 0.01
>>>>>>> paternalage.mean       7 6829 0.00 0.68  -0.08   -0.05 0.59 -1.74  4.30  6.04 0.95     1.97 0.01
>>>>>>> paternalage.diff       8 6829 0.00 0.42   0.00   -0.01 0.38 -1.51  1.48  2.99 0.17     0.17 0.01
>>>>>>> 
>>>>>>>> table(krmh.1$paternalage.factor)
>>>>>>> 
>>>>>>> [0,25] (25,30] (30,35] (35,40] (40,45] (45,50] (50,55] (55,90]
>>>>>>> 309    1214    1683    1562    1039     623     269     130
>>>>>>> 
>>>>>>> On 28 Aug 2014, at 19:05, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>>>>>> 
>>>>>>>> Hi Ruben,
>>>>>>>> 
>>>>>>>> It might be hard to detect (near) ECPs with so many fixed effects (can you post the model summary (and give us the mean and standard deviation of any continuous covariates)). Also, the complementary log-log link (which is the za specification) is non-symmetric and runs into problems outside the range -35 to 3.5 so there may be a problem there, particularly if you use rcov=~trait:units and the Poisson part is highly over-dispersed.  You could try rcov=~idh(trait):units and fix the non-identifiable za residual variance to something smaller than 1 (say 0.5)  - it will mix slower but it will reduce the chance of over/underflow.
>>>>>>>> 
>>>>>>>> Cheers,
>>>>>>>> 
>>>>>>>> Jarrod
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Thu, 28 Aug 2014 18:45:30 +0200:
>>>>>>>> 
>>>>>>>>> Hi Jarrod,
>>>>>>>>> 
>>>>>>>>>> 1) it did not return an error with rcov = ~trait:units because you used R1=rpois(2,1)+1 and yet this specification only fits a single variance (not a 2x2 covariance matrix). R1=rpois(2,1)+1 is a bit of a weird specification since it has to be integer. I would obtain starting values using rIW().
>>>>>>>>> 
>>>>>>>>> I agree it's a weird specification, I was a bit lost and thought I could get away with just putting some random numbers in the starting value.
>>>>>>>>> I didn't do R1=rpois(2,1)+1 though, I did R1=diag(rpois(2,1)+1), so I got a 2x2 matrix, but yes, bound to be integer.
>>>>>>>>> I didn't know starting values should come from a conjugate distribution, though that probably means I didn't think about it much.
>>>>>>>>> 
>>>>>>>>> I'm now doing
>>>>>>>>> start <- list(
>>>>>>>>> 	liab=c(rnorm( nrow(krmh.1)*2 )),
>>>>>>>>> 	R = list(R1 = rIW( diag(2), nrow(krmh.1)) ),
>>>>>>>>> 	G = list(G1 = rIW( diag(2), nrow(krmh.1)) )
>>>>>>>>> )
>>>>>>>>> 
>>>>>>>>> Is this what you had in mind?
>>>>>>>>> I am especially unsure if I am supposed to use such a low sampling variability (my sample size is probably not even relevant for the starting values) and if I should start from diag(2).
>>>>>>>>> 
>>>>>>>>> And, I am still happily confused that this specification still doesn't lead to errors with respect to rcov = ~trait:units . Does this mean I'm doing it wrong?
>>>>>>>>> 
>>>>>>>>>> 3) a) how many effective samples do you have for each parameter? and b) are you getting extreme category problems/numerical issues? If you store the latent variables (pl=TUE) what is their range for the Zi/za part?
>>>>>>>>> 
>>>>>>>>> My parallel run using the above starting values isn't finished yet.
>>>>>>>>> a) After applying the above starting values I get, for the location effects 1600-2000 samples for a 2000 sample chain (with thin set to 50). G and R-structure are from 369 (za_children.idParents) to 716 (and 0 for the fixed part).
>>>>>>>>> Effective sample sizes were similar for my run using the starting values for G/R that I drew from rpois, and using 40 chains I of course get
>>>>>>>>> b) I don't think I am getting extreme categories. I would probably be getting extreme categories if I included the forever-alones (they almost never have children), but this way no.
>>>>>>>>> I wasn't sure how to examine the range of the latents separately for the za part, but for a single chain it looks okay:
>>>>>>>>>> quantile(as.numeric(m1$Liab),probs = c(0,0.01,0,0.99,1))
>>>>>>>>>   0%        1%        0%       99%      100%
>>>>>>>>> -4.934111 -1.290728 -4.934111  3.389847  7.484206
>>>>>>>>> 
>>>>>>>>> Well, all considered now that I use the above starting value specification I get slightly different estimates for all za-coefficients. Nothing major, but still leading me to
>>>>>>>>> think my estimates aren't exactly independent of the starting values I use. I'll see what the parallel run yields.
>>>>>>>>> 
>>>>>>>>> Thanks a lot,
>>>>>>>>> 
>>>>>>>>> Ruben
>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> Cheers,
>>>>>>>>>> 
>>>>>>>>>> Jarrod
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Wed, 27 Aug 2014 19:23:42 +0200:
>>>>>>>>>> 
>>>>>>>>>>> Hi Jarrod,
>>>>>>>>>>> 
>>>>>>>>>>> thanks again. I was able to get it running with your advice.
>>>>>>>>>>> Some points of confusion remain:
>>>>>>>>>>> 
>>>>>>>>>>> - You wrote that zi/za models would return an error with rcov = ~trait:units + starting values. This did not happen in my case, so I didn't build MCMCglmm myself with your suggested edits. Also, have you considered putting your own MCMCglmm repo on Github? Your users would be able to install pre-releases and I'd think you'd get some time-saving pull requests too.
>>>>>>>>>>> - In my attempts to get my models to run properly, I messed up a prior and did not use fix=2 in my prior specification for my za models. This led to crappy convergence, it's much better now and for some of my simpler models I think I won't need parallel chains. I'm reminded of Gelman's folk theorem of statistical computing.
>>>>>>>>>>> - I followed your advice, but of course I could not set the true values as starting values, but wanted to set random, bad starting values. I pasted below what I arrived at, I'm especially unsure whether I specified the starting values for G and R properly (I think not).
>>>>>>>>>>> 	start <- list(
>>>>>>>>>>> 		liab=c(rnorm( nrow(krmh.1)*2 )),
>>>>>>>>>>> 		R = list(R1 = diag(rpois(2, 1)+1)),
>>>>>>>>>>> 		G = list(G1 = diag(rpois(2, 1)+1))
>>>>>>>>>>> 	)
>>>>>>>>>>> 
>>>>>>>>>>> 
>>>>>>>>>>> However, even though I may not need multiple chains for some of my simpler models, I've now run into conflicting diagnostics. The geweke.diag for each chain (and examination of the traces) gives
>>>>>>>>>>> satisfactory diagnostics. Comparing multiple chains using gelman.diag, however, leads to one bad guy, namely the traitza_children:spouses interaction.
>>>>>>>>>>> I think this implies that I've got some starting value dependence for this parameter, that won't be easily rectified through longer burnin?
>>>>>>>>>>> Do you have any ideas how to rectify this?
>>>>>>>>>>> I am currently doing sequential analyses on episodes of selection and in historical human data only those who marry have a chance at having kids. I exclude the unmarried
>>>>>>>>>>> from my sample where I predict number of children, because I examine that in a previous model and the zero-inflation (65% zeros, median w/o unmarried = 4) when including the unmarried is so excessive.
>>>>>>>>>>> Number of spouses is easily the strongest predictor in the model, but only serves as a covariate here. Since my other estimates are stable across chains and runs and agree well across models and with theory, I'm
>>>>>>>>>>> inclined to shrug this off. But probably I shouldn't ignore this sign of non-convergence?
>>>>>>>>>>> 
>>>>>>>>>>>> gelman.diag(mcmc_1)
>>>>>>>>>>> Potential scale reduction factors:
>>>>>>>>>>> 
>>>>>>>>>>>                                      Point est. Upper C.I.
>>>>>>>>>>> (Intercept)                                      1.00       1.00
>>>>>>>>>>> traitza_children                                 1.27       1.39
>>>>>>>>>>> male                                             1.00       1.00
>>>>>>>>>>> spouses                                          1.00       1.00
>>>>>>>>>>> paternalage.mean                                 1.00       1.00
>>>>>>>>>>> paternalage.factor(25,30]                        1.00       1.00
>>>>>>>>>>> paternalage.factor(30,35]                        1.00       1.00
>>>>>>>>>>> paternalage.factor(35,40]                        1.00       1.00
>>>>>>>>>>> paternalage.factor(40,45]                        1.00       1.00
>>>>>>>>>>> paternalage.factor(45,50]                        1.00       1.00
>>>>>>>>>>> paternalage.factor(50,55]                        1.00       1.00
>>>>>>>>>>> paternalage.factor(55,90]                        1.00       1.00
>>>>>>>>>>> traitza_children:male                            1.22       1.32
>>>>>>>>>>> traitza_children:spouses                         1.83       2.13
>>>>>>>>>>> traitza_children:paternalage.mean                1.02       1.02
>>>>>>>>>>> traitza_children:paternalage.factor(25,30]       1.03       1.05
>>>>>>>>>>> traitza_children:paternalage.factor(30,35]       1.05       1.08
>>>>>>>>>>> traitza_children:paternalage.factor(35,40]       1.10       1.15
>>>>>>>>>>> traitza_children:paternalage.factor(40,45]       1.12       1.17
>>>>>>>>>>> traitza_children:paternalage.factor(45,50]       1.19       1.28
>>>>>>>>>>> traitza_children:paternalage.factor(50,55]       1.12       1.18
>>>>>>>>>>> traitza_children:paternalage.factor(55,90]       1.11       1.17
>>>>>>>>>>> 
>>>>>>>>>>> Multivariate psrf
>>>>>>>>>>> 
>>>>>>>>>>> 7.27
>>>>>>>>>>> 
>>>>>>>>>>> 
>>>>>>>>>>> Best regards,
>>>>>>>>>>> 
>>>>>>>>>>> Ruben
>>>>>>>>>>> 
>>>>>>>>>>> 
>>>>>>>>>>> On 26 Aug 2014, at 13:04, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>>>>>>>>>> 
>>>>>>>>>>>> Hi Ruben,
>>>>>>>>>>>> 
>>>>>>>>>>>> There are 400 liabilities in a zapoisson model (2 per datum). This code should work:
>>>>>>>>>>>> 
>>>>>>>>>>>> g <-sample(letters[1:10], size = 200, replace = T)
>>>>>>>>>>>> pred <- rnorm(200)
>>>>>>>>>>>> 
>>>>>>>>>>>> l1<-rnorm(200, -1, sqrt(1))
>>>>>>>>>>>> l2<-rnorm(200, -1, sqrt(1))
>>>>>>>>>>>> 
>>>>>>>>>>>> y<-VGAM::rzapois(200, exp(l1), exp(-exp(l2)))
>>>>>>>>>>>> 
>>>>>>>>>>>> # generate zero-altered data with an intercept of -1 (because the intercept and variance are the same for both processes this is just standard Poisson)
>>>>>>>>>>>> 
>>>>>>>>>>>> dat<-data.frame(y=y, g = g, pred = pred)
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> start.1<-list(liab=c(l1,l2), R = list(R1=diag(2)), G=list(G1=diag(2)))
>>>>>>>>>>>> prior.1<-list(R=list(V=diag(2), nu=1.002, fix=2), G=list(G1=list(V=diag(2), nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*1000)))
>>>>>>>>>>>> 
>>>>>>>>>>>> m1<-MCMCglmm(y~trait + pred:trait, random=~us(trait):g, family="zapoisson",rcov=~idh(trait):units, data=dat, prior=prior.1, start= start.1)
>>>>>>>>>>>> 
>>>>>>>>>>>> However, there are 2 bugs in the current version of MCMCglmm that return an error message when the documentation implies it should be fine:
>>>>>>>>>>>> 
>>>>>>>>>>>> a) it should be possible to have R=diag(2) rather than R = list(R1=diag(2)). This bug cropped up when I implemented block-diagonal R structures. It can be fixed by inserting:
>>>>>>>>>>>> 
>>>>>>>>>>>>    if(!is.list(start$R)){
>>>>>>>>>>>>       start$R<-list(R1=start$R)
>>>>>>>>>>>>    }
>>>>>>>>>>>> 
>>>>>>>>>>>> on L514 of MCMCglmm.R below
>>>>>>>>>>>> 
>>>>>>>>>>>>    if(!is.list(prior$R[[1]])){
>>>>>>>>>>>>       prior$R<-list(R1=prior$R)
>>>>>>>>>>>>    }
>>>>>>>>>>>> 
>>>>>>>>>>>> b) rcov=~trait:units models for zi/za models will return an error when passing starting values. To fix this insert
>>>>>>>>>>>> 
>>>>>>>>>>>>   if(diagR==3){
>>>>>>>>>>>>     if(dim(start)[1]!=1){
>>>>>>>>>>>>       stop("V is the wrong dimension for some strart$G/start$R elements")
>>>>>>>>>>>>     }
>>>>>>>>>>>>     start<-diag(sum(nfl))*start[1]
>>>>>>>>>>>>   }
>>>>>>>>>>>> 
>>>>>>>>>>>> on L90 of priorfromat.R below
>>>>>>>>>>>> 
>>>>>>>>>>>>   if(is.matrix(start)==FALSE){
>>>>>>>>>>>>     start<-as.matrix(start)
>>>>>>>>>>>>   }
>>>>>>>>>>>> 
>>>>>>>>>>>> I will put these in the new version.
>>>>>>>>>>>> 
>>>>>>>>>>>> Cheers,
>>>>>>>>>>>> 
>>>>>>>>>>>> Jarrod
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25 Aug 2014 21:52:30 +0200:
>>>>>>>>>>>> 
>>>>>>>>>>>>> Hi Jarrod,
>>>>>>>>>>>>> 
>>>>>>>>>>>>> thanks for these pointers.
>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> You will need to provide over-dispersed starting values for multiple-chain convergence diagnostics to be useful (GLMM are so simple I am generally happy if the output of a single run looks reasonable).
>>>>>>>>>>>>> 
>>>>>>>>>>>>> Oh, I would be happy with single chains, but since computation would take weeks this way, I wanted to parallelise and I would use the multi-chain convergence as a criterion that my parallelisation was proper
>>>>>>>>>>>>> and is as informative as a single long chain. There don't seem to be any such checks built-in ? I was analysing my 40 chains for a bit longer than I like to admit until I noticed they were identical (effectiveSize
>>>>>>>>>>>>> and summary.mcmc.list did not yell at me for this).
>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> # use some very bad starting values
>>>>>>>>>>>>> I get that these values are bad, but that is the goal for my multi-chain aim, right?
>>>>>>>>>>>>> 
>>>>>>>>>>>>> I can apply this to my zero-truncated model, but am again getting stuck with the zero-altered one.
>>>>>>>>>>>>> Maybe I need only specify the Liab values for this?
>>>>>>>>>>>>> At least I'm getting nowhere with specifying R and G starting values here. When I got an error, I always
>>>>>>>>>>>>> went to the MCMCglmm source to understand why the checks failed, but I didn't always understand
>>>>>>>>>>>>> what was being checked and couldn't get it to work.
>>>>>>>>>>>>> 
>>>>>>>>>>>>> Here's a failing example:
>>>>>>>>>>>>> 
>>>>>>>>>>>>> l<-rnorm(200, -1, sqrt(1))
>>>>>>>>>>>>> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
>>>>>>>>>>>>> g = sample(letters[1:10], size = 200, replace = T)
>>>>>>>>>>>>> pred = rnorm(200)
>>>>>>>>>>>>> y<-rpois(200,exp(l)-t)
>>>>>>>>>>>>> y[1:40] = 0
>>>>>>>>>>>>> # generate zero-altered data with an intercept of -1
>>>>>>>>>>>>> 
>>>>>>>>>>>>> dat<-data.frame(y=y, g = g, pred = pred)
>>>>>>>>>>>>> set.seed(1)
>>>>>>>>>>>>> start_true = list(Liab=l, R = 1, G = 1 )
>>>>>>>>>>>>> m1<-MCMCglmm(y~1 + pred,random = ~ g, family="zapoisson",rcov=~us(trait):units, data=dat, start= start_true)
>>>>>>>>>>>>> 
>>>>>>>>>>>>> # use true latent variable as starting values
>>>>>>>>>>>>> set.seed(1)
>>>>>>>>>>>>> # use some very bad starting values
>>>>>>>>>>>>> start_rand = list(Liab=rnorm(200), R = rpois(1, 1)+1, G = rpois(1, 1)+1 )
>>>>>>>>>>>>> m2<-MCMCglmm(y~1 + pred,random = ~ g,rcov=~us(trait):units,  family="zapoisson", data=dat, start = start_rand)
>>>>>>>>>>>>> 
>>>>>>>>>>>>> Best,
>>>>>>>>>>>>> 
>>>>>>>>>>>>> Ruben
>>>>>>>>>>>>> 
>>>>>>>>>>>>> On 25 Aug 2014, at 18:29, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>>>>>>>>>>>> 
>>>>>>>>>>>>>> Hi Ruben,
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> Sorry  - I was wrong when I said that everything is Gibbs sampled conditional on the latent variables. The location effects (fixed and random effects) are also sampled conditional on the (co)variance components so you should add them to the starting values. In the case where the true values are used:
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat, start=list(Liab=l,R=1))
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> Cheers,
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> Jarrod
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> Quoting Jarrod Hadfield <j.hadfield at ed.ac.uk> on Mon, 25 Aug 2014 17:14:14 +0100:
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> Hi Ruben,
>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> You will need to provide over-dispersed starting values for multiple-chain convergence diagnostics to be useful (GLMM are so simple I am generally happy if the output of a single run looks reasonable).
>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> With non-Gaussian data everything is Gibbs sampled conditional on the latent variables, so you only need to pass them:
>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> l<-rnorm(200, -1, sqrt(1))
>>>>>>>>>>>>>>> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
>>>>>>>>>>>>>>> y<-rpois(200,exp(l)-t)+1
>>>>>>>>>>>>>>> # generate zero-truncated data with an intercept of -1
>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> dat<-data.frame(y=y)
>>>>>>>>>>>>>>> set.seed(1)
>>>>>>>>>>>>>>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat, start=list(Liab=l))
>>>>>>>>>>>>>>> # use true latent variable as starting values
>>>>>>>>>>>>>>> set.seed(1)
>>>>>>>>>>>>>>> m2<-MCMCglmm(y~1, family="ztpoisson", data=dat, start=list(Liab=rnorm(200)))
>>>>>>>>>>>>>>> # use some very bad starting values
>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> plot(mcmc.list(m1$Sol, m2$Sol))
>>>>>>>>>>>>>>> # not identical despite the same seed because of different starting values but clearly sampling the same posterior distribution:
>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> gelman.diag(mcmc.list(m1$Sol, m2$Sol))
>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> Cheers,
>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> Jarrod
>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25 Aug 2014 18:00:08 +0200:
>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>> Dear Jarrod,
>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>> thanks for the quick reply. Please, don't waste time looking into doMPI ? I am happy that I
>>>>>>>>>>>>>>>> get the expected result, when I specify that reproducible seed, whyever that may be.
>>>>>>>>>>>>>>>> I'm pretty sure that is the deciding factor, because I tested it explicitly, I just have no idea
>>>>>>>>>>>>>>>> how/why it interacts with the choice of family.
>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>> That said, is setting up different RNG streams for my workers (now that it works) __sufficient__
>>>>>>>>>>>>>>>> so that I get independent chains and can use gelman.diag() for convergence diagnostics?
>>>>>>>>>>>>>>>> Or should I still tinker with the starting values myself?
>>>>>>>>>>>>>>>> I've never found a worked example of supplying starting values and am thus a bit lost.
>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>> Sorry for sending further questions, I hope someone else takes pity while
>>>>>>>>>>>>>>>> you're busy with lectures.
>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>> Best wishes
>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>> Ruben
>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>> On 25 Aug 2014, at 17:29, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>> Hi Ruben,
>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>> I do not think the issue is with the starting values, because even if the same starting values were used the chains would still differ because of the randomness in the Markov Chain (if I interpret your `identical' test correctly). This just involves a call to GetRNGstate() in the C++ code (L 871 ofMCMCglmm.cc) so I think for some reason doMPI/foreach is not doing what you expect. I am not familiar with doMPI and am in the middle of writing lectures so haven't got time to look into it carefully. Outside of the context of doMPI I get the behaviour I expect:
>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>> l<-rnorm(200, -1, sqrt(1))
>>>>>>>>>>>>>>>>> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
>>>>>>>>>>>>>>>>> y<-rpois(200,exp(l)-t)+1
>>>>>>>>>>>>>>>>> # generate zero-truncated data with an intercept of -1
>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>> dat<-data.frame(y=y)
>>>>>>>>>>>>>>>>> set.seed(1)
>>>>>>>>>>>>>>>>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>>>>>>>>>>>>>>> set.seed(2)
>>>>>>>>>>>>>>>>> m2<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>>>>>>>>>>>>>>> set.seed(2)
>>>>>>>>>>>>>>>>> m3<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>> plot(mcmc.list(m1$Sol, m2$Sol))
>>>>>>>>>>>>>>>>> # different, as expected
>>>>>>>>>>>>>>>>> plot(mcmc.list(m2$Sol, m3$Sol))
>>>>>>>>>>>>>>>>> # the same, as expected
>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25 Aug 2014 16:58:06 +0200:
>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>> Dear list,
>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>> sorry for bumping my old post, I hope to elicit a response with a more focused question:
>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>> When does MCMCglmm automatically start from different values when using doMPI/foreach?
>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>> I have done some tests with models of varying complexity. For example, the script in my last
>>>>>>>>>>>>>>>>>> post (using "zapoisson") yielded 40 identical chains:
>>>>>>>>>>>>>>>>>>> identical(mcmclist[1], mcmclist[30])
>>>>>>>>>>>>>>>>>> TRUE
>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>> A simpler (?) model (using "ztpoisson" and no specified prior), however, yielded different chains
>>>>>>>>>>>>>>>>>> and I could use them to calculate gelman.diag()
>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>> Changing my script to the version below, i.e. seeding foreach using .options.mpi=list( seed= 1337)
>>>>>>>>>>>>>>>>>> so as to make RNGstreams reproducible (or so I  thought), led to different chains even for the
>>>>>>>>>>>>>>>>>> "zapoisson" model.
>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>> In no case have I (successfully) tried to supplant the default of MCMCglmm's "start" argument.
>>>>>>>>>>>>>>>>>> Is starting my models from different RNGsubstreams inadequate compared to manipulating
>>>>>>>>>>>>>>>>>> the start argument explicitly? If so, is there any worked example of explicit starting value manipulation
>>>>>>>>>>>>>>>>>> in parallel computation?
>>>>>>>>>>>>>>>>>> I've browsed the MCMCglmm source to understand how the default starting values are generated,
>>>>>>>>>>>>>>>>>> but didn't find any differences with respect to RNG for the two families "ztpoisson" and "zapoisson"
>>>>>>>>>>>>>>>>>> (granted, I did not dig very deep).
>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>> Best regards,
>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>> Ruben Arslan
>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>> # bsub -q mpi -W 12:00 -n 41 -R np20 mpirun -H localhost -n 41 R --slave -f "/usr/users/rarslan/rpqa/rpqa_main/rpqa_children_parallel.R"
>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>> library(doMPI)
>>>>>>>>>>>>>>>>>> cl <- startMPIcluster(verbose=T,workdir="/usr/users/rarslan/rpqa/rpqa_main/")
>>>>>>>>>>>>>>>>>> registerDoMPI(cl)
>>>>>>>>>>>>>>>>>> Children_mcmc1 = foreach(i=1:clusterSize(cl),.options.mpi = list(seed=1337) ) %dopar% {
>>>>>>>>>>>>>>>>>> 	library(MCMCglmm);library(data.table)
>>>>>>>>>>>>>>>>>> 	load("/usr/users/rarslan/rpqa/rpqa1.rdata")
>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>> 	nitt = 130000; thin = 100; burnin = 30000
>>>>>>>>>>>>>>>>>> 	prior.m5d.2 = list(
>>>>>>>>>>>>>>>>>> 		R = list(V = diag(c(1,1)), nu = 0.002),
>>>>>>>>>>>>>>>>>> 		G=list(list(V=diag(c(1,1e-6)),nu=0.002))
>>>>>>>>>>>>>>>>>> 	)
>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>> 	rpqa.1 = na.omit(rpqa.1[spouses>0, list(idParents, children, male, urban, spouses, paternalage.mean, paternalage.factor)])
>>>>>>>>>>>>>>>>>> 	(m1 = MCMCglmm( children ~ trait * (male + urban + spouses + paternalage.mean + paternalage.factor),
>>>>>>>>>>>>>>>>>> 						rcov=~us(trait):units,
>>>>>>>>>>>>>>>>>> 						random=~us(trait):idParents,
>>>>>>>>>>>>>>>>>> 						family="zapoisson",
>>>>>>>>>>>>>>>>>> 						prior = prior.m5d.2,
>>>>>>>>>>>>>>>>>> 						data=rpqa.1,
>>>>>>>>>>>>>>>>>> 						pr = F, saveX = F, saveZ = F,
>>>>>>>>>>>>>>>>>> 						nitt=nitt,thin=thin,burnin=burnin))
>>>>>>>>>>>>>>>>>> }
>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>> library(coda)
>>>>>>>>>>>>>>>>>> mcmclist = mcmc.list(lapply(Children_mcmc1,FUN=function(x) { x$Sol}))
>>>>>>>>>>>>>>>>>> save(Children_mcmc1,mcmclist, file = "/usr/users/rarslan/rpqa/rpqa_main/rpqa_mcmc_kids_za.rdata")
>>>>>>>>>>>>>>>>>> closeCluster(cl)
>>>>>>>>>>>>>>>>>> mpi.quit()
>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>> On 04 Aug 2014, at 20:25, Ruben Arslan <rubenarslan at gmail.com> wrote:
>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>>> Dear list,
>>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>>> would someone be willing to share her or his efforts in parallelising a MCMCglmm analysis?
>>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>>> I had something viable using harvestr that seemed to properly initialise
>>>>>>>>>>>>>>>>>>> the starting values from different random number streams (which is desirable,
>>>>>>>>>>>>>>>>>>> as far as I could find out), but I ended up being unable to use harvestr, because
>>>>>>>>>>>>>>>>>>> it uses an old version of plyr, where parallelisation works only for multicore, not for
>>>>>>>>>>>>>>>>>>> MPI.
>>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>>> I pasted my working version, that does not do anything about starting values or RNG
>>>>>>>>>>>>>>>>>>> at the end of this email. I can try to fumble further in the dark or try to update harvestr,
>>>>>>>>>>>>>>>>>>> but maybe someone has gone through all this already.
>>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>>> I'd also appreciate any tips for elegantly post-processing such parallel data, as some of my usual
>>>>>>>>>>>>>>>>>>> extraction functions and routines are hampered by the fact that some coda functions
>>>>>>>>>>>>>>>>>>> do not aggregate results over chains. (What I get from a single-chain summary in MCMCglmm
>>>>>>>>>>>>>>>>>>> is a bit more comprehensive, than what I managed to cobble together with my own extraction
>>>>>>>>>>>>>>>>>>> functions).
>>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>>> The reason I'm parallelising my analyses is that I'm having trouble getting a good effective
>>>>>>>>>>>>>>>>>>> sample size for any parameter having to do with the many zeroes in my data.
>>>>>>>>>>>>>>>>>>> Any pointers are very appreciated, I'm quite inexperienced with MCMCglmm.
>>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>>> Best wishes
>>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>>> Ruben
>>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>>> # bsub -q mpi-short -W 2:00 -n 42 -R np20 mpirun -H localhost -n 41 R --slave -f "rpqa/rpqa_main/rpqa_children_parallel.r"
>>>>>>>>>>>>>>>>>>> library(doMPI)
>>>>>>>>>>>>>>>>>>> cl <- startMPIcluster()
>>>>>>>>>>>>>>>>>>> registerDoMPI(cl)
>>>>>>>>>>>>>>>>>>> Children_mcmc1 = foreach(i=1:40) %dopar% {
>>>>>>>>>>>>>>>>>>> 	library(MCMCglmm)
>>>>>>>>>>>>>>>>>>> 	load("rpqa1.rdata")
>>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>>> 	nitt = 40000; thin = 100; burnin = 10000
>>>>>>>>>>>>>>>>>>> 	prior = list(
>>>>>>>>>>>>>>>>>>> 		R = list(V = diag(c(1,1)), nu = 0.002),
>>>>>>>>>>>>>>>>>>> 		G=list(list(V=diag(c(1,1e-6)),nu=0.002))
>>>>>>>>>>>>>>>>>>> 	)
>>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>>> 	MCMCglmm( children ~ trait -1 + at.level(trait,1):male + at.level(trait,1):urban + at.level(trait,1):spouses + at.level(trait,1):paternalage.mean + at.level(trait,1):paternalage.factor,
>>>>>>>>>>>>>>>>>>> 		rcov=~us(trait):units,
>>>>>>>>>>>>>>>>>>> 		random=~us(trait):idParents,
>>>>>>>>>>>>>>>>>>> 		family="zapoisson",
>>>>>>>>>>>>>>>>>>> 		prior = prior,
>>>>>>>>>>>>>>>>>>> 		data=rpqa.1,
>>>>>>>>>>>>>>>>>>> 		pr = F, saveX = T, saveZ = T,
>>>>>>>>>>>>>>>>>>> 		nitt=nitt,thin=thin,burnin=burnin)
>>>>>>>>>>>>>>>>>>> }
>>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>>> library(coda)
>>>>>>>>>>>>>>>>>>> mcmclist = mcmc.list(lapply(Children_mcmc1,FUN=function(x) { x$Sol}))
>>>>>>>>>>>>>>>>>>> save(Children_mcmc1,mcmclist, file = "rpqa_mcmc_kids_za.rdata")
>>>>>>>>>>>>>>>>>>> closeCluster(cl)
>>>>>>>>>>>>>>>>>>> mpi.quit()
>>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>>> --
>>>>>>>>>>>>>>>>>>> Ruben C. Arslan
>>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>>> Georg August University G?ttingen
>>>>>>>>>>>>>>>>>>> Biological Personality Psychology and Psychological Assessment
>>>>>>>>>>>>>>>>>>> Georg Elias M?ller Institute of Psychology
>>>>>>>>>>>>>>>>>>> Go?lerstr. 14
>>>>>>>>>>>>>>>>>>> 37073 G?ttingen
>>>>>>>>>>>>>>>>>>> Germany
>>>>>>>>>>>>>>>>>>> Tel.: +49 551 3920704
>>>>>>>>>>>>>>>>>>> https://psych.uni-goettingen.de/en/biopers/team/arslan
>>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>> 	[[alternative HTML version deleted]]
>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>>> --
>>>>>>>>>>>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>>>>>>>>>>>> Scotland, with registration number SC005336.
>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> --
>>>>>>>>>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>>>>>>>>>> Scotland, with registration number SC005336.
>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> _______________________________________________
>>>>>>>>>>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> --
>>>>>>>>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>>>>>>>>> Scotland, with registration number SC005336.
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> 
>>>>>>>>>>>>> 
>>>>>>>>>>>>> 
>>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> --
>>>>>>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>>>>>>> Scotland, with registration number SC005336.
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>> 
>>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> --
>>>>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>>>>> Scotland, with registration number SC005336.
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> --
>>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>>> Scotland, with registration number SC005336.
>>>>>>>> 
>>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> --
>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>> Scotland, with registration number SC005336.
>>>>>> 
>>>>>> 
>>>>> 
>>>>> 
>>>> 
>>>> 
>>>> 
>>>> --
>>>> The University of Edinburgh is a charitable body, registered in
>>>> Scotland, with registration number SC005336.
>>>> 
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>> 
>>> 
>>> 
>>> --
>>> The University of Edinburgh is a charitable body, registered in
>>> Scotland, with registration number SC005336.
>>> 
>>> 
>> 
>> 
> 
> 
> 
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
> 
> 


From christianvanbrauner at gmail.com  Fri Aug 29 13:31:03 2014
From: christianvanbrauner at gmail.com (Christian Brauner)
Date: Fri, 29 Aug 2014 13:31:03 +0200
Subject: [R-sig-ME] Random effects in clmm() of package ordinal
Message-ID: <20140829113102.GA4000@gmail.com>

Hello,

fitting linear mixed models it is often suggested that testing for random
effects is not the best idea; mainly because the value of the random
effects parameters lie at the boundary of the parameter space. Hence, it
is preferred to not test for random effects and rather judge the inclusion
of a random effect by the design of the experiment. Or if one really wants
to do this use computation intensive methods like parametric bootstraps
etc. I have adapted the strategy of not testing for random effects with
linear mixed models.

Now I'm in a situation were I need to analyse ordinal data in a repeated
measures design. The package I decided would best suit this purpose is the
ordinal package (suggestions of alternatives are of course welcome). And
this got me wondering about random effects again. I was testing a random
effect (in fact by accidence as I did a faulty automated regexp
substitution) and it got a p of 0.99. More precisely I was testing for the
significance of a random slope in contrast to only including a random
intercept. As the boundary-of-parameter-space argument is about maximum
likelihood estimation in general it also applies to the proportional odds
cummulative mixed model. But, and here is were I'm unsure what to do in
this particular case the inclusion of a random slope in the clmm will turn
a p of 0.004 into 0.1 for my main effect. In contrast all other methods
(e.g.  treating my response not as an ordered factor but as a continuous
variable and using a repeated measures anova) will give me a p of 0.004.
This is the only reason why I'm concerned about this. This difference
worries me and I'm unsure of what to do. Is it advisable to test here for
a random effect?

Best,
Christian


From j.hadfield at ed.ac.uk  Fri Aug 29 13:51:52 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 29 Aug 2014 12:51:52 +0100
Subject: [R-sig-ME] parallel MCMCglmm, RNGstreams,
 starting values & priors
In-Reply-To: <406437CD-C96A-4875-B77B-2114F889EB3D@gmail.com>
References: <4CD76FE1-D3F5-4980-9122-B0AC0D44FF81@gmail.com>
	<0E12EB43-72BC-42AC-9E74-9DF53DB42217@gmail.com>
	<20140825162907.10475jpywlu1wzs4@www.staffmail.ed.ac.uk>
	<0A463095-8656-49B7-9619-E557DD449E21@gmail.com>
	<20140825171414.10872gnlopk1we68@www.staffmail.ed.ac.uk>
	<20140825172936.15916weehiwjyc08@www.staffmail.ed.ac.uk>
	<8D35B834-0D31-486A-B5FB-0F279761FDB2@gmail.com>
	<49D60399-6902-45AC-80A9-9F3C35532228@gmail.com>
	<20140826120434.14613hxqhgwbhq80@www.staffmail.ed.ac.uk>
	<8557AE32-AFC9-4FD2-9C88-2D118B484637@gmail.com>
	<20140827183959.18662zc6hw5jj20w@www.staffmail.ed.ac.uk>
	<2D00600E-5287-4FE1-B605-82C0CBA286ED@gmail.com>
	<20140828180551.74212a0xoeoihn6s@www.staffmail.ed.ac.uk>
	<BBB5F7E3-75FE-4BA3-82B4-49DAA64873A4@gmail.com>
	<20140828195957.68171hjra56vrrr4@www.staffmail.ed.ac.uk>
	<E5B149F2-7773-4E2D-854C-3275A352A245@gmail.com>
	<20140829080442.1833246y8pj3itq8@www.staffmail.ed.ac.uk>
	<20140829081333.16792k7qrimekagw@www.staffmail.ed.ac.uk>
	<7F4CEBA1-CFF9-4FBA-883B-8263CAC018EE@gmail.com>
	<20140829110259.60094j3omtxmddkw@www.staffmail.ed.ac.uk>
	<406437CD-C96A-4875-B77B-2114F889EB3D@gmail.com>
Message-ID: <20140829125152.11446r30n8dgm8ow@www.staffmail.ed.ac.uk>

Hi,

sorry - I forgot what my own rIW code does!

Jarrod


Quoting Ruben Arslan <rubenarslan at gmail.com> on Fri, 29 Aug 2014  
12:14:44 +0200:

> That's what I did, I think.
>
> equality = c()
> for(i in 1:1000)
> {
> 	prior <- list(
> 		R=list(V=diag(2), nu=1.002, fix=2),
> 		G=list(G1=list(V=diag(2), nu=1, alpha.mu=c(0,0), alpha.V=diag(2)*1000))
> 	)
>
> 	start <- list(
> 		liab=c(rnorm( nrow(krmh.1)*2 )),
> 		R = list(R1 = rIW(diag(2), 10 , fix = 2)), ### FIX=2 HERE AS WELL
> 		G = list(G1 = rIW(diag(2), 10 ))
> 	)
> 	equality[i] = prior$R$V[2,2]==start$R$R1[2,2]
> }
> all(equality==T)
>
>
> On 29 Aug 2014, at 12:02, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>
>> Hi,
>>
>> You need to make sure that they are fixed at the same value, not just fixed.
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Fri, 29 Aug 2014  
>> 11:07:21 +0200:
>>
>>> Hi Jarrod,
>>>
>>> that was exactly it. I hadn't checked the $VCV mcmclist, but I'll  
>>> do so in the future
>>> as the mistake is blindingly obvious that way: http://imgur.com/nlA0QwZ
>>>
>>> After adding fix=2 to R1 in my starting values, my parallel chains  
>>> converged as well.
>>>
>>> For future amateurs reading this:
>>> prior <- list(
>>> 	R=list(V=diag(2), nu=1.002, fix=2),
>>> 	G=list(G1=list(V=diag(2), nu=1, alpha.mu=c(0,0), alpha.V=diag(2)*1000))
>>> )
>>>
>>> start <- list(
>>> 	liab=c(rnorm( nrow(krmh.1)*2 )),
>>> 	R = list(R1 = rIW(diag(2), 10 , fix = 2)), ### FIX=2 HERE AS WELL
>>> 	G = list(G1 = rIW(diag(2), 10 ))
>>> )
>>>
>>> Thank you so much. This sort of remote diagnosis with this little  
>>> information
>>> seems borderline psychic to me.
>>> Now, onwards to modelling the pedigrees :-)
>>>
>>> Best wishes,
>>>
>>> Ruben
>>>
>>> PS.: I never actually figured out what kind of variability to use  
>>> for rIW() in my starting values,
>>> but it doesn't seem to matter and that's what I should want I  
>>> suppose. Actually, even with the mis-specified
>>> starting values my posterior looked pretty similar to now.
>>>
>>> On 29 Aug 2014, at 09:13, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>>
>>>> Hi Ruben,
>>>>
>>>> Actually I might know what it is. When you sample different  
>>>> starting values do you inadvertently sample a new residual  
>>>> variance for the unidentified za part? You need to make sure that  
>>>> this is always fixed at the same value (otherwise the model is  
>>>> different). This is not a problem under the trait:units  
>>>> specification.
>>>>
>>>> Cheers,
>>>>
>>>> Jarrod.
>>>>
>>>>
>>>>
>>>> Quoting Jarrod Hadfield <j.hadfield at ed.ac.uk> on Fri, 29 Aug 2014  
>>>> 08:04:42 +0100:
>>>>
>>>>> Hi Ruben,
>>>>>
>>>>> Can you share your data and I will take a look. Its definitely  
>>>>> not Monte Carlo error.
>>>>>
>>>>> Cheers,
>>>>>
>>>>> Jarrod
>>>>>
>>>>>
>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Thu, 28 Aug 2014  
>>>>> 22:44:47 +0200:
>>>>>
>>>>>> Hi Jarrod,
>>>>>>
>>>>>> those two matched up quite well yes. I just completed another  
>>>>>> 20 chains, using more variable
>>>>>> starting values. There's still two fixed effects  
>>>>>> traitza_children:spouses  and :male which haven't converged
>>>>>> according to multi-chain (gelman), but have according to geweke.
>>>>>> The offending traces: http://imgur.com/Qm6Ovfr
>>>>>> These specific effects aren't of interest to me, so if this  
>>>>>> doesn't affect the rest of my estimates, I can be happy
>>>>>> with this, but I can't conclude that, can I?
>>>>>>
>>>>>> I'm now also doing a run to see how it deals with the more  
>>>>>> intensely zero-inflated data when including
>>>>>> the unmarried.
>>>>>>
>>>>>> Thanks a lot for all that help,
>>>>>>
>>>>>> Ruben
>>>>>>
>>>>>>> gelman.diag(mcmclist)
>>>>>> Potential scale reduction factors:
>>>>>>
>>>>>>                                         Point est. Upper C.I.
>>>>>> (Intercept)                                      1.00       1.00
>>>>>> traitza_children                                 1.40       1.65
>>>>>> male                                             1.00       1.00
>>>>>> spouses                                          1.00       1.00
>>>>>> paternalage.mean                                 1.00       1.00
>>>>>> paternalage.factor(25,30]                        1.00       1.00
>>>>>> paternalage.factor(30,35]                        1.00       1.00
>>>>>> paternalage.factor(35,40]                        1.00       1.00
>>>>>> paternalage.factor(40,45]                        1.00       1.00
>>>>>> paternalage.factor(45,50]                        1.00       1.00
>>>>>> paternalage.factor(50,55]                        1.00       1.00
>>>>>> paternalage.factor(55,90]                        1.00       1.00
>>>>>> traitza_children:male                            1.33       1.54
>>>>>> traitza_children:spouses                         2.21       2.83
>>>>>> traitza_children:paternalage.mean                1.01       1.02
>>>>>> traitza_children:paternalage.factor(25,30]       1.05       1.08
>>>>>> traitza_children:paternalage.factor(30,35]       1.08       1.13
>>>>>> traitza_children:paternalage.factor(35,40]       1.15       1.25
>>>>>> traitza_children:paternalage.factor(40,45]       1.15       1.26
>>>>>> traitza_children:paternalage.factor(45,50]       1.26       1.43
>>>>>> traitza_children:paternalage.factor(50,55]       1.15       1.25
>>>>>> traitza_children:paternalage.factor(55,90]       1.14       1.23
>>>>>>
>>>>>> Multivariate psrf
>>>>>>
>>>>>> 8.99
>>>>>>
>>>>>>> summary(mcmclist)
>>>>>>
>>>>>> Iterations = 100001:149951
>>>>>> Thinning interval = 50
>>>>>> Number of chains = 20
>>>>>> Sample size per chain = 1000
>>>>>>
>>>>>> 1. Empirical mean and standard deviation for each variable,
>>>>>> plus standard error of the mean:
>>>>>>
>>>>>>                                             Mean      SD  Naive  
>>>>>> SE Time-series SE
>>>>>> (Intercept)                                 1.36326 0.04848  
>>>>>> 0.0003428      0.0003542
>>>>>> traitza_children                           -0.76679 0.28738  
>>>>>> 0.0020321      0.0016682
>>>>>> male                                        0.09980 0.01633  
>>>>>> 0.0001155      0.0001222
>>>>>> spouses                                     0.12333 0.01957  
>>>>>> 0.0001384      0.0001414
>>>>>> paternalage.mean                            0.07215 0.02194  
>>>>>> 0.0001551      0.0001596
>>>>>> paternalage.factor(25,30]                  -0.03381 0.04184  
>>>>>> 0.0002959      0.0003066
>>>>>> paternalage.factor(30,35]                  -0.08380 0.04270  
>>>>>> 0.0003019      0.0003118
>>>>>> paternalage.factor(35,40]                  -0.16502 0.04569  
>>>>>> 0.0003231      0.0003289
>>>>>> paternalage.factor(40,45]                  -0.16738 0.05090  
>>>>>> 0.0003599      0.0003697
>>>>>> paternalage.factor(45,50]                  -0.18383 0.05880  
>>>>>> 0.0004158      0.0004242
>>>>>> paternalage.factor(50,55]                  -0.18241 0.07277  
>>>>>> 0.0005146      0.0005302
>>>>>> paternalage.factor(55,90]                  -0.40612 0.09875  
>>>>>> 0.0006983      0.0007467
>>>>>> traitza_children:male                       0.12092 0.08223  
>>>>>> 0.0005815      0.0004697
>>>>>> traitza_children:spouses                    0.64881 0.21132  
>>>>>> 0.0014942      0.0008511
>>>>>> traitza_children:paternalage.mean          -0.02741 0.08550  
>>>>>> 0.0006046      0.0006221
>>>>>> traitza_children:paternalage.factor(25,30] -0.17296 0.18680  
>>>>>> 0.0013209      0.0013750
>>>>>> traitza_children:paternalage.factor(30,35] -0.19027 0.19267  
>>>>>> 0.0013624      0.0013901
>>>>>> traitza_children:paternalage.factor(35,40] -0.24911 0.21282  
>>>>>> 0.0015049      0.0014391
>>>>>> traitza_children:paternalage.factor(40,45] -0.29772 0.23403  
>>>>>> 0.0016548      0.0015956
>>>>>> traitza_children:paternalage.factor(45,50] -0.51782 0.28589  
>>>>>> 0.0020215      0.0017602
>>>>>> traitza_children:paternalage.factor(50,55] -0.46126 0.32064  
>>>>>> 0.0022673      0.0021397
>>>>>> traitza_children:paternalage.factor(55,90] -0.38612 0.41461  
>>>>>> 0.0029317      0.0027396
>>>>>>
>>>>>> 2. Quantiles for each variable:
>>>>>>
>>>>>>                                             2.5%      25%       
>>>>>> 50%      75%      97.5%
>>>>>> (Intercept)                                 1.26883  1.33106   
>>>>>> 1.36322  1.39575  1.4589722
>>>>>> traitza_children                           -1.20696 -0.95751  
>>>>>> -0.81076 -0.63308 -0.0365042
>>>>>> male                                        0.06785  0.08878   
>>>>>> 0.09970  0.11085  0.1320168
>>>>>> spouses                                     0.08467  0.11030   
>>>>>> 0.12343  0.13643  0.1617869
>>>>>> paternalage.mean                            0.02950  0.05751   
>>>>>> 0.07202  0.08683  0.1153881
>>>>>> paternalage.factor(25,30]                  -0.11581 -0.06174  
>>>>>> -0.03397 -0.00574  0.0473783
>>>>>> paternalage.factor(30,35]                  -0.16656 -0.11250  
>>>>>> -0.08358 -0.05519  0.0003065
>>>>>> paternalage.factor(35,40]                  -0.25518 -0.19530  
>>>>>> -0.16500 -0.13440 -0.0757366
>>>>>> paternalage.factor(40,45]                  -0.26887 -0.20164  
>>>>>> -0.16675 -0.13335 -0.0677407
>>>>>> paternalage.factor(45,50]                  -0.30080 -0.22320  
>>>>>> -0.18339 -0.14440 -0.0687967
>>>>>> paternalage.factor(50,55]                  -0.32663 -0.23034  
>>>>>> -0.18227 -0.13317 -0.0415547
>>>>>> paternalage.factor(55,90]                  -0.60202 -0.47303  
>>>>>> -0.40454 -0.33994 -0.2139128
>>>>>> traitza_children:male                      -0.01083  0.06634   
>>>>>> 0.11024  0.16109  0.3295892
>>>>>> traitza_children:spouses                    0.37857  0.51072   
>>>>>> 0.59398  0.71395  1.2127940
>>>>>> traitza_children:paternalage.mean          -0.19138 -0.08250  
>>>>>> -0.02985  0.02493  0.1468989
>>>>>> traitza_children:paternalage.factor(25,30] -0.57457 -0.28481  
>>>>>> -0.16489 -0.05151  0.1728148
>>>>>> traitza_children:paternalage.factor(30,35] -0.61499 -0.30350  
>>>>>> -0.17736 -0.06299  0.1555147
>>>>>> traitza_children:paternalage.factor(35,40] -0.74251 -0.36752  
>>>>>> -0.22966 -0.10777  0.1151897
>>>>>> traitza_children:paternalage.factor(40,45] -0.84165 -0.42691  
>>>>>> -0.27729 -0.14322  0.1032436
>>>>>> traitza_children:paternalage.factor(45,50] -1.21782 -0.66568  
>>>>>> -0.48420 -0.32873 -0.0476720
>>>>>> traitza_children:paternalage.factor(50,55] -1.21327 -0.63623  
>>>>>> -0.43432 -0.24957  0.0955360
>>>>>> traitza_children:paternalage.factor(55,90] -1.33772 -0.62227  
>>>>>> -0.35364 -0.11050  0.3361684
>>>>>>
>>>>>>> effectiveSize(mcmclist)
>>>>>>                             (Intercept)                          
>>>>>>   traitza_children
>>>>>>                                18814.05                          
>>>>>>           16359.33
>>>>>>                                    male                          
>>>>>>            spouses
>>>>>>                                18132.98                          
>>>>>>           19547.05
>>>>>>                        paternalage.mean                   
>>>>>> paternalage.factor(25,30]
>>>>>>                                19238.72                          
>>>>>>           18974.81
>>>>>>               paternalage.factor(30,35]                   
>>>>>> paternalage.factor(35,40]
>>>>>>                                18874.33                          
>>>>>>           19406.63
>>>>>>               paternalage.factor(40,45]                   
>>>>>> paternalage.factor(45,50]
>>>>>>                                19075.18                          
>>>>>>           19401.77
>>>>>>               paternalage.factor(50,55]                   
>>>>>> paternalage.factor(55,90]
>>>>>>                                18960.11                          
>>>>>>           17893.23
>>>>>>                   traitza_children:male                    
>>>>>> traitza_children:spouses
>>>>>>                                18545.55                          
>>>>>>           14438.51
>>>>>>       traitza_children:paternalage.mean  
>>>>>> traitza_children:paternalage.factor(25,30]
>>>>>>                                18464.09                          
>>>>>>           16943.43
>>>>>> traitza_children:paternalage.factor(30,35]  
>>>>>> traitza_children:paternalage.factor(35,40]
>>>>>>                                16827.44                          
>>>>>>           17230.04
>>>>>> traitza_children:paternalage.factor(40,45]  
>>>>>> traitza_children:paternalage.factor(45,50]
>>>>>>                                17144.78                          
>>>>>>           18191.67
>>>>>> traitza_children:paternalage.factor(50,55]  
>>>>>> traitza_children:paternalage.factor(55,90]
>>>>>>                                17466.60                          
>>>>>>           18540.59
>>>>>>
>>>>>>
>>>>>> ### current script:
>>>>>>
>>>>>> # bsub -q mpi -W 24:00 -n 21 -R np20 mpirun -H localhost -n 21  
>>>>>> R --slave -f "/usr/users/rarslan/rpqa/krmh_main/children.R"
>>>>>> setwd("/usr/users/rarslan/rpqa/")
>>>>>> library(doMPI)
>>>>>> cl <-  
>>>>>> startMPIcluster(verbose=T,workdir="/usr/users/rarslan/rpqa/krmh_main/")
>>>>>> registerDoMPI(cl)
>>>>>> Children = foreach(i=1:clusterSize(cl),.options.mpi =  
>>>>>> list(seed=1337) ) %dopar% {
>>>>>> 	library(MCMCglmm);library(data.table)
>>>>>>  setwd("/usr/users/rarslan/rpqa/krmh_main/")
>>>>>> 	source("../1 - extraction functions.r")
>>>>>>  load("../krmh1.rdata")
>>>>>>
>>>>>> 	krmh.1 = recenter.pat(na.omit(krmh.1[spouses>0,  
>>>>>> list(idParents, children, male, spouses, paternalage)]))
>>>>>>
>>>>>> 	samples = 1000
>>>>>> 	thin = 50; burnin = 100000
>>>>>> 	nitt = samples * thin + burnin
>>>>>>
>>>>>> 	prior <- list(
>>>>>> 		R=list(V=diag(2), nu=1.002, fix=2),
>>>>>> 		G=list(G1=list(V=diag(2), nu=1, alpha.mu=c(0,0),  
>>>>>> alpha.V=diag(2)*1000))
>>>>>> 	)
>>>>>>
>>>>>> 	start <- list(
>>>>>> 		liab=c(rnorm( nrow(krmh.1)*2 )),
>>>>>> 		R = list(R1 = rIW(diag(2), 10 )),
>>>>>> 		G = list(G1 = rIW(diag(2), 10 ))
>>>>>> 	)
>>>>>>
>>>>>> 	( m1 = MCMCglmm( children ~ trait * (male + spouses +  
>>>>>> paternalage.mean + paternalage.factor),
>>>>>> 						rcov=~idh(trait):units,
>>>>>> 						random=~idh(trait):idParents,
>>>>>> 						family="zapoisson",
>>>>>> 						start = start,
>>>>>> 						prior = prior,
>>>>>> 						data=krmh.1,
>>>>>> 						pr = F, saveX = F, saveZ = F,
>>>>>> 						nitt=nitt,thin=thin,burnin=burnin)
>>>>>> 	)
>>>>>> 		m1$Residual$nrt<-2
>>>>>> 	m1
>>>>>> }
>>>>>>
>>>>>> save(Children,file = "Children.rdata")
>>>>>> closeCluster(cl)
>>>>>> mpi.quit()
>>>>>>
>>>>>> On 28 Aug 2014, at 20:59, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>>>>>
>>>>>>> Hi,
>>>>>>>
>>>>>>> The posteriors for the two models look pretty close to me. Are  
>>>>>>> the scale reduction factors really as high as previously  
>>>>>>> reported? Before you had 1.83 for traitza_children:spouses,  
>>>>>>> but the plot suggests that it should be close to 1?
>>>>>>>
>>>>>>> Cheers,
>>>>>>>
>>>>>>> Jarrod
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Thu, 28 Aug  
>>>>>>> 2014 19:59:16 +0200:
>>>>>>>
>>>>>>>> Sure! Thanks a lot.
>>>>>>>> I am using ~idh(trait):units already, sorry for saying that  
>>>>>>>> incorrectly in my last email.
>>>>>>>> These models aren't the final thing, I will replace the  
>>>>>>>> paternalage.factor variable
>>>>>>>> with its linear equivalent if that seems defensible (does so  
>>>>>>>> far) and in this model it seems
>>>>>>>> okay to remove the za-effects for all predictors except spouses.
>>>>>>>> So a final model would have fewer fixed effects. I also have  
>>>>>>>> datasets of 200k+ and 5m+,
>>>>>>>> but I'm learning MCMCglmm with this smaller one because my  
>>>>>>>> wrong turns take less time.
>>>>>>>>
>>>>>>>> I've uploaded a comparison coef plot of two models:
>>>>>>>> http://i.imgur.com/sHUfnmd.png
>>>>>>>> m7 is with the default starting values, m1 is with the  
>>>>>>>> specification I sent in my last email. I don't
>>>>>>>> know if such differences are something to worry about.
>>>>>>>>
>>>>>>>> I don't know what qualifies as highly overdispersed, here's a  
>>>>>>>> plot of the outcome for ever
>>>>>>>> married people (slate=real data):
>>>>>>>> http://imgur.com/14MywgZ
>>>>>>>> here's with everybody born (incl. some stillborn etc.):
>>>>>>>> http://imgur.com/knRGa1v
>>>>>>>> I guess my approach (generating an overdispersed poisson with  
>>>>>>>> the parameters from
>>>>>>>> the data and checking if it has as excess zeroes) is not the  
>>>>>>>> best way to diagnose zero-inflation,
>>>>>>>> but especially in the second case it seems fairly clear-cut.
>>>>>>>>
>>>>>>>> Best regards,
>>>>>>>>
>>>>>>>> Ruben
>>>>>>>>
>>>>>>>>> summary(m1)
>>>>>>>>
>>>>>>>> Iterations = 50001:149951
>>>>>>>> Thinning interval  = 50
>>>>>>>> Sample size  = 2000
>>>>>>>>
>>>>>>>> DIC: 31249.73
>>>>>>>>
>>>>>>>> G-structure:  ~idh(trait):idParents
>>>>>>>>
>>>>>>>>                   post.mean  l-95% CI u-95% CI eff.samp
>>>>>>>> children.idParents     0.006611 4.312e-08   0.0159    523.9
>>>>>>>> za_children.idParents  0.193788 7.306e-02   0.3283    369.3
>>>>>>>>
>>>>>>>> R-structure:  ~idh(trait):units
>>>>>>>>
>>>>>>>>               post.mean l-95% CI u-95% CI eff.samp
>>>>>>>> children.units       0.1285   0.1118   0.1452    716.1
>>>>>>>> za_children.units    0.9950   0.9950   0.9950      0.0
>>>>>>>>
>>>>>>>> Location effects: children ~ trait * (male + spouses +  
>>>>>>>> paternalage.mean + paternalage.factor)
>>>>>>>>
>>>>>>>>                                         post.mean   l-95% CI   
>>>>>>>>  u-95% CI eff.samp  pMCMC
>>>>>>>> (Intercept)                                 1.3413364   
>>>>>>>> 1.2402100  1.4326099     1789 <5e-04 ***
>>>>>>>> traitza_children                           -0.8362879  
>>>>>>>> -1.2007980 -0.5016730     1669 <5e-04 ***
>>>>>>>> male                                        0.0994902   
>>>>>>>> 0.0679050  0.1297394     2000 <5e-04 ***
>>>>>>>> spouses                                     0.1236033   
>>>>>>>> 0.0839000  0.1624939     2000 <5e-04 ***
>>>>>>>> paternalage.mean                            0.0533892   
>>>>>>>> 0.0119569  0.0933960     2000  0.015 *
>>>>>>>> paternalage.factor(25,30]                  -0.0275822  
>>>>>>>> -0.1116421  0.0537359     1842  0.515
>>>>>>>> paternalage.factor(30,35]                  -0.0691025  
>>>>>>>> -0.1463214  0.0122393     1871  0.097 .
>>>>>>>> paternalage.factor(35,40]                  -0.1419933  
>>>>>>>> -0.2277379 -0.0574678     1845 <5e-04 ***
>>>>>>>> paternalage.factor(40,45]                  -0.1364952  
>>>>>>>> -0.2362714 -0.0451874     1835  0.007 **
>>>>>>>> paternalage.factor(45,50]                  -0.1445342  
>>>>>>>> -0.2591767 -0.0421178     1693  0.008 **
>>>>>>>> paternalage.factor(50,55]                  -0.1302972  
>>>>>>>> -0.2642965  0.0077061     2000  0.064 .
>>>>>>>> paternalage.factor(55,90]                  -0.3407879  
>>>>>>>> -0.5168972 -0.1493652     1810 <5e-04 ***
>>>>>>>> traitza_children:male                       0.0926888  
>>>>>>>> -0.0147379  0.2006142     1901  0.098 .
>>>>>>>> traitza_children:spouses                    0.5531197   
>>>>>>>> 0.3870616  0.7314289     1495 <5e-04 ***
>>>>>>>> traitza_children:paternalage.mean           0.0051463  
>>>>>>>> -0.1279396  0.1460099     1617  0.960
>>>>>>>> traitza_children:paternalage.factor(25,30] -0.1538957  
>>>>>>>> -0.4445749  0.1462955     1781  0.321
>>>>>>>> traitza_children:paternalage.factor(30,35] -0.1747883  
>>>>>>>> -0.4757851  0.1162476     1998  0.261
>>>>>>>> traitza_children:paternalage.factor(35,40] -0.2261843  
>>>>>>>> -0.5464379  0.0892582     1755  0.166
>>>>>>>> traitza_children:paternalage.factor(40,45] -0.2807543  
>>>>>>>> -0.6079678  0.0650281     1721  0.100 .
>>>>>>>> traitza_children:paternalage.factor(45,50] -0.4905843  
>>>>>>>> -0.8649214 -0.1244174     1735  0.010 **
>>>>>>>> traitza_children:paternalage.factor(50,55] -0.4648579  
>>>>>>>> -0.9215759 -0.0002083     1687  0.054 .
>>>>>>>> traitza_children:paternalage.factor(55,90] -0.3945406  
>>>>>>>> -1.0230155  0.2481568     1793  0.195
>>>>>>>> ---
>>>>>>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>>>>>>
>>>>>>>>> describe(krmh.1[spouses>0,])
>>>>>>>>                 vars    n mean   sd median trimmed  mad   min  
>>>>>>>>   max range skew kurtosis   se
>>>>>>>> children               2 6829 3.81 2.93   4.00    3.61 2.97   
>>>>>>>> 0.00 16.00 16.00 0.47    -0.46 0.04
>>>>>>>> male                   3 6829 0.46 0.50   0.00    0.45 0.00   
>>>>>>>> 0.00  1.00  1.00 0.14    -1.98 0.01
>>>>>>>> spouses                4 6829 1.14 0.38   1.00    1.03 0.00   
>>>>>>>> 1.00  4.00  3.00 2.87     8.23 0.00
>>>>>>>> paternalage            5 6829 3.65 0.80   3.57    3.60 0.80   
>>>>>>>> 1.83  7.95  6.12 0.69     0.70 0.01
>>>>>>>> paternalage_c          6 6829 0.00 0.80  -0.08   -0.05 0.80  
>>>>>>>> -1.82  4.30  6.12 0.69     0.70 0.01
>>>>>>>> paternalage.mean       7 6829 0.00 0.68  -0.08   -0.05 0.59  
>>>>>>>> -1.74  4.30  6.04 0.95     1.97 0.01
>>>>>>>> paternalage.diff       8 6829 0.00 0.42   0.00   -0.01 0.38  
>>>>>>>> -1.51  1.48  2.99 0.17     0.17 0.01
>>>>>>>>
>>>>>>>>> table(krmh.1$paternalage.factor)
>>>>>>>>
>>>>>>>> [0,25] (25,30] (30,35] (35,40] (40,45] (45,50] (50,55] (55,90]
>>>>>>>> 309    1214    1683    1562    1039     623     269     130
>>>>>>>>
>>>>>>>> On 28 Aug 2014, at 19:05, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>>>>>>>>
>>>>>>>>> Hi Ruben,
>>>>>>>>>
>>>>>>>>> It might be hard to detect (near) ECPs with so many fixed  
>>>>>>>>> effects (can you post the model summary (and give us the  
>>>>>>>>> mean and standard deviation of any continuous covariates)).  
>>>>>>>>> Also, the complementary log-log link (which is the za  
>>>>>>>>> specification) is non-symmetric and runs into problems  
>>>>>>>>> outside the range -35 to 3.5 so there may be a problem  
>>>>>>>>> there, particularly if you use rcov=~trait:units and the  
>>>>>>>>> Poisson part is highly over-dispersed.  You could try  
>>>>>>>>> rcov=~idh(trait):units and fix the non-identifiable za  
>>>>>>>>> residual variance to something smaller than 1 (say 0.5)  -  
>>>>>>>>> it will mix slower but it will reduce the chance of  
>>>>>>>>> over/underflow.
>>>>>>>>>
>>>>>>>>> Cheers,
>>>>>>>>>
>>>>>>>>> Jarrod
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Thu, 28 Aug  
>>>>>>>>> 2014 18:45:30 +0200:
>>>>>>>>>
>>>>>>>>>> Hi Jarrod,
>>>>>>>>>>
>>>>>>>>>>> 1) it did not return an error with rcov = ~trait:units  
>>>>>>>>>>> because you used R1=rpois(2,1)+1 and yet this  
>>>>>>>>>>> specification only fits a single variance (not a 2x2  
>>>>>>>>>>> covariance matrix). R1=rpois(2,1)+1 is a bit of a weird  
>>>>>>>>>>> specification since it has to be integer. I would obtain  
>>>>>>>>>>> starting values using rIW().
>>>>>>>>>>
>>>>>>>>>> I agree it's a weird specification, I was a bit lost and  
>>>>>>>>>> thought I could get away with just putting some random  
>>>>>>>>>> numbers in the starting value.
>>>>>>>>>> I didn't do R1=rpois(2,1)+1 though, I did  
>>>>>>>>>> R1=diag(rpois(2,1)+1), so I got a 2x2 matrix, but yes,  
>>>>>>>>>> bound to be integer.
>>>>>>>>>> I didn't know starting values should come from a conjugate  
>>>>>>>>>> distribution, though that probably means I didn't think  
>>>>>>>>>> about it much.
>>>>>>>>>>
>>>>>>>>>> I'm now doing
>>>>>>>>>> start <- list(
>>>>>>>>>> 	liab=c(rnorm( nrow(krmh.1)*2 )),
>>>>>>>>>> 	R = list(R1 = rIW( diag(2), nrow(krmh.1)) ),
>>>>>>>>>> 	G = list(G1 = rIW( diag(2), nrow(krmh.1)) )
>>>>>>>>>> )
>>>>>>>>>>
>>>>>>>>>> Is this what you had in mind?
>>>>>>>>>> I am especially unsure if I am supposed to use such a low  
>>>>>>>>>> sampling variability (my sample size is probably not even  
>>>>>>>>>> relevant for the starting values) and if I should start  
>>>>>>>>>> from diag(2).
>>>>>>>>>>
>>>>>>>>>> And, I am still happily confused that this specification  
>>>>>>>>>> still doesn't lead to errors with respect to rcov =  
>>>>>>>>>> ~trait:units . Does this mean I'm doing it wrong?
>>>>>>>>>>
>>>>>>>>>>> 3) a) how many effective samples do you have for each  
>>>>>>>>>>> parameter? and b) are you getting extreme category  
>>>>>>>>>>> problems/numerical issues? If you store the latent  
>>>>>>>>>>> variables (pl=TUE) what is their range for the Zi/za part?
>>>>>>>>>>
>>>>>>>>>> My parallel run using the above starting values isn't finished yet.
>>>>>>>>>> a) After applying the above starting values I get, for the  
>>>>>>>>>> location effects 1600-2000 samples for a 2000 sample chain  
>>>>>>>>>> (with thin set to 50). G and R-structure are from 369  
>>>>>>>>>> (za_children.idParents) to 716 (and 0 for the fixed part).
>>>>>>>>>> Effective sample sizes were similar for my run using the  
>>>>>>>>>> starting values for G/R that I drew from rpois, and using  
>>>>>>>>>> 40 chains I of course get
>>>>>>>>>> b) I don't think I am getting extreme categories. I would  
>>>>>>>>>> probably be getting extreme categories if I included the  
>>>>>>>>>> forever-alones (they almost never have children), but this  
>>>>>>>>>> way no.
>>>>>>>>>> I wasn't sure how to examine the range of the latents  
>>>>>>>>>> separately for the za part, but for a single chain it looks  
>>>>>>>>>> okay:
>>>>>>>>>>> quantile(as.numeric(m1$Liab),probs = c(0,0.01,0,0.99,1))
>>>>>>>>>>   0%        1%        0%       99%      100%
>>>>>>>>>> -4.934111 -1.290728 -4.934111  3.389847  7.484206
>>>>>>>>>>
>>>>>>>>>> Well, all considered now that I use the above starting  
>>>>>>>>>> value specification I get slightly different estimates for  
>>>>>>>>>> all za-coefficients. Nothing major, but still leading me to
>>>>>>>>>> think my estimates aren't exactly independent of the  
>>>>>>>>>> starting values I use. I'll see what the parallel run yields.
>>>>>>>>>>
>>>>>>>>>> Thanks a lot,
>>>>>>>>>>
>>>>>>>>>> Ruben
>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>> Cheers,
>>>>>>>>>>>
>>>>>>>>>>> Jarrod
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Wed, 27  
>>>>>>>>>>> Aug 2014 19:23:42 +0200:
>>>>>>>>>>>
>>>>>>>>>>>> Hi Jarrod,
>>>>>>>>>>>>
>>>>>>>>>>>> thanks again. I was able to get it running with your advice.
>>>>>>>>>>>> Some points of confusion remain:
>>>>>>>>>>>>
>>>>>>>>>>>> - You wrote that zi/za models would return an error with  
>>>>>>>>>>>> rcov = ~trait:units + starting values. This did not  
>>>>>>>>>>>> happen in my case, so I didn't build MCMCglmm myself with  
>>>>>>>>>>>> your suggested edits. Also, have you considered putting  
>>>>>>>>>>>> your own MCMCglmm repo on Github? Your users would be  
>>>>>>>>>>>> able to install pre-releases and I'd think you'd get some  
>>>>>>>>>>>> time-saving pull requests too.
>>>>>>>>>>>> - In my attempts to get my models to run properly, I  
>>>>>>>>>>>> messed up a prior and did not use fix=2 in my prior  
>>>>>>>>>>>> specification for my za models. This led to crappy  
>>>>>>>>>>>> convergence, it's much better now and for some of my  
>>>>>>>>>>>> simpler models I think I won't need parallel chains. I'm  
>>>>>>>>>>>> reminded of Gelman's folk theorem of statistical computing.
>>>>>>>>>>>> - I followed your advice, but of course I could not set  
>>>>>>>>>>>> the true values as starting values, but wanted to set  
>>>>>>>>>>>> random, bad starting values. I pasted below what I  
>>>>>>>>>>>> arrived at, I'm especially unsure whether I specified the  
>>>>>>>>>>>> starting values for G and R properly (I think not).
>>>>>>>>>>>> 	start <- list(
>>>>>>>>>>>> 		liab=c(rnorm( nrow(krmh.1)*2 )),
>>>>>>>>>>>> 		R = list(R1 = diag(rpois(2, 1)+1)),
>>>>>>>>>>>> 		G = list(G1 = diag(rpois(2, 1)+1))
>>>>>>>>>>>> 	)
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>> However, even though I may not need multiple chains for  
>>>>>>>>>>>> some of my simpler models, I've now run into conflicting  
>>>>>>>>>>>> diagnostics. The geweke.diag for each chain (and  
>>>>>>>>>>>> examination of the traces) gives
>>>>>>>>>>>> satisfactory diagnostics. Comparing multiple chains using  
>>>>>>>>>>>> gelman.diag, however, leads to one bad guy, namely the  
>>>>>>>>>>>> traitza_children:spouses interaction.
>>>>>>>>>>>> I think this implies that I've got some starting value  
>>>>>>>>>>>> dependence for this parameter, that won't be easily  
>>>>>>>>>>>> rectified through longer burnin?
>>>>>>>>>>>> Do you have any ideas how to rectify this?
>>>>>>>>>>>> I am currently doing sequential analyses on episodes of  
>>>>>>>>>>>> selection and in historical human data only those who  
>>>>>>>>>>>> marry have a chance at having kids. I exclude the unmarried
>>>>>>>>>>>> from my sample where I predict number of children,  
>>>>>>>>>>>> because I examine that in a previous model and the  
>>>>>>>>>>>> zero-inflation (65% zeros, median w/o unmarried = 4) when  
>>>>>>>>>>>> including the unmarried is so excessive.
>>>>>>>>>>>> Number of spouses is easily the strongest predictor in  
>>>>>>>>>>>> the model, but only serves as a covariate here. Since my  
>>>>>>>>>>>> other estimates are stable across chains and runs and  
>>>>>>>>>>>> agree well across models and with theory, I'm
>>>>>>>>>>>> inclined to shrug this off. But probably I shouldn't  
>>>>>>>>>>>> ignore this sign of non-convergence?
>>>>>>>>>>>>
>>>>>>>>>>>>> gelman.diag(mcmc_1)
>>>>>>>>>>>> Potential scale reduction factors:
>>>>>>>>>>>>
>>>>>>>>>>>>                                      Point est. Upper C.I.
>>>>>>>>>>>> (Intercept)                                      1.00       1.00
>>>>>>>>>>>> traitza_children                                 1.27       1.39
>>>>>>>>>>>> male                                             1.00       1.00
>>>>>>>>>>>> spouses                                          1.00       1.00
>>>>>>>>>>>> paternalage.mean                                 1.00       1.00
>>>>>>>>>>>> paternalage.factor(25,30]                        1.00       1.00
>>>>>>>>>>>> paternalage.factor(30,35]                        1.00       1.00
>>>>>>>>>>>> paternalage.factor(35,40]                        1.00       1.00
>>>>>>>>>>>> paternalage.factor(40,45]                        1.00       1.00
>>>>>>>>>>>> paternalage.factor(45,50]                        1.00       1.00
>>>>>>>>>>>> paternalage.factor(50,55]                        1.00       1.00
>>>>>>>>>>>> paternalage.factor(55,90]                        1.00       1.00
>>>>>>>>>>>> traitza_children:male                            1.22       1.32
>>>>>>>>>>>> traitza_children:spouses                         1.83       2.13
>>>>>>>>>>>> traitza_children:paternalage.mean                1.02       1.02
>>>>>>>>>>>> traitza_children:paternalage.factor(25,30]       1.03       1.05
>>>>>>>>>>>> traitza_children:paternalage.factor(30,35]       1.05       1.08
>>>>>>>>>>>> traitza_children:paternalage.factor(35,40]       1.10       1.15
>>>>>>>>>>>> traitza_children:paternalage.factor(40,45]       1.12       1.17
>>>>>>>>>>>> traitza_children:paternalage.factor(45,50]       1.19       1.28
>>>>>>>>>>>> traitza_children:paternalage.factor(50,55]       1.12       1.18
>>>>>>>>>>>> traitza_children:paternalage.factor(55,90]       1.11       1.17
>>>>>>>>>>>>
>>>>>>>>>>>> Multivariate psrf
>>>>>>>>>>>>
>>>>>>>>>>>> 7.27
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>> Best regards,
>>>>>>>>>>>>
>>>>>>>>>>>> Ruben
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>> On 26 Aug 2014, at 13:04, Jarrod Hadfield  
>>>>>>>>>>>> <j.hadfield at ed.ac.uk> wrote:
>>>>>>>>>>>>
>>>>>>>>>>>>> Hi Ruben,
>>>>>>>>>>>>>
>>>>>>>>>>>>> There are 400 liabilities in a zapoisson model (2 per  
>>>>>>>>>>>>> datum). This code should work:
>>>>>>>>>>>>>
>>>>>>>>>>>>> g <-sample(letters[1:10], size = 200, replace = T)
>>>>>>>>>>>>> pred <- rnorm(200)
>>>>>>>>>>>>>
>>>>>>>>>>>>> l1<-rnorm(200, -1, sqrt(1))
>>>>>>>>>>>>> l2<-rnorm(200, -1, sqrt(1))
>>>>>>>>>>>>>
>>>>>>>>>>>>> y<-VGAM::rzapois(200, exp(l1), exp(-exp(l2)))
>>>>>>>>>>>>>
>>>>>>>>>>>>> # generate zero-altered data with an intercept of -1  
>>>>>>>>>>>>> (because the intercept and variance are the same for  
>>>>>>>>>>>>> both processes this is just standard Poisson)
>>>>>>>>>>>>>
>>>>>>>>>>>>> dat<-data.frame(y=y, g = g, pred = pred)
>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>> start.1<-list(liab=c(l1,l2), R = list(R1=diag(2)),  
>>>>>>>>>>>>> G=list(G1=diag(2)))
>>>>>>>>>>>>> prior.1<-list(R=list(V=diag(2), nu=1.002, fix=2),  
>>>>>>>>>>>>> G=list(G1=list(V=diag(2), nu=2, alpha.mu=c(0,0),  
>>>>>>>>>>>>> alpha.V=diag(2)*1000)))
>>>>>>>>>>>>>
>>>>>>>>>>>>> m1<-MCMCglmm(y~trait + pred:trait, random=~us(trait):g,  
>>>>>>>>>>>>> family="zapoisson",rcov=~idh(trait):units, data=dat,  
>>>>>>>>>>>>> prior=prior.1, start= start.1)
>>>>>>>>>>>>>
>>>>>>>>>>>>> However, there are 2 bugs in the current version of  
>>>>>>>>>>>>> MCMCglmm that return an error message when the  
>>>>>>>>>>>>> documentation implies it should be fine:
>>>>>>>>>>>>>
>>>>>>>>>>>>> a) it should be possible to have R=diag(2) rather than R  
>>>>>>>>>>>>> = list(R1=diag(2)). This bug cropped up when I  
>>>>>>>>>>>>> implemented block-diagonal R structures. It can be fixed  
>>>>>>>>>>>>> by inserting:
>>>>>>>>>>>>>
>>>>>>>>>>>>>    if(!is.list(start$R)){
>>>>>>>>>>>>>       start$R<-list(R1=start$R)
>>>>>>>>>>>>>    }
>>>>>>>>>>>>>
>>>>>>>>>>>>> on L514 of MCMCglmm.R below
>>>>>>>>>>>>>
>>>>>>>>>>>>>    if(!is.list(prior$R[[1]])){
>>>>>>>>>>>>>       prior$R<-list(R1=prior$R)
>>>>>>>>>>>>>    }
>>>>>>>>>>>>>
>>>>>>>>>>>>> b) rcov=~trait:units models for zi/za models will return  
>>>>>>>>>>>>> an error when passing starting values. To fix this insert
>>>>>>>>>>>>>
>>>>>>>>>>>>>   if(diagR==3){
>>>>>>>>>>>>>     if(dim(start)[1]!=1){
>>>>>>>>>>>>>       stop("V is the wrong dimension for some  
>>>>>>>>>>>>> strart$G/start$R elements")
>>>>>>>>>>>>>     }
>>>>>>>>>>>>>     start<-diag(sum(nfl))*start[1]
>>>>>>>>>>>>>   }
>>>>>>>>>>>>>
>>>>>>>>>>>>> on L90 of priorfromat.R below
>>>>>>>>>>>>>
>>>>>>>>>>>>>   if(is.matrix(start)==FALSE){
>>>>>>>>>>>>>     start<-as.matrix(start)
>>>>>>>>>>>>>   }
>>>>>>>>>>>>>
>>>>>>>>>>>>> I will put these in the new version.
>>>>>>>>>>>>>
>>>>>>>>>>>>> Cheers,
>>>>>>>>>>>>>
>>>>>>>>>>>>> Jarrod
>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon, 25  
>>>>>>>>>>>>> Aug 2014 21:52:30 +0200:
>>>>>>>>>>>>>
>>>>>>>>>>>>>> Hi Jarrod,
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> thanks for these pointers.
>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> You will need to provide over-dispersed starting  
>>>>>>>>>>>>>>>> values for multiple-chain convergence diagnostics to  
>>>>>>>>>>>>>>>> be useful (GLMM are so simple I am generally happy if  
>>>>>>>>>>>>>>>> the output of a single run looks reasonable).
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> Oh, I would be happy with single chains, but since  
>>>>>>>>>>>>>> computation would take weeks this way, I wanted to  
>>>>>>>>>>>>>> parallelise and I would use the multi-chain convergence  
>>>>>>>>>>>>>> as a criterion that my parallelisation was proper
>>>>>>>>>>>>>> and is as informative as a single long chain. There  
>>>>>>>>>>>>>> don't seem to be any such checks built-in ? I was  
>>>>>>>>>>>>>> analysing my 40 chains for a bit longer than I like to  
>>>>>>>>>>>>>> admit until I noticed they were identical (effectiveSize
>>>>>>>>>>>>>> and summary.mcmc.list did not yell at me for this).
>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> # use some very bad starting values
>>>>>>>>>>>>>> I get that these values are bad, but that is the goal  
>>>>>>>>>>>>>> for my multi-chain aim, right?
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> I can apply this to my zero-truncated model, but am  
>>>>>>>>>>>>>> again getting stuck with the zero-altered one.
>>>>>>>>>>>>>> Maybe I need only specify the Liab values for this?
>>>>>>>>>>>>>> At least I'm getting nowhere with specifying R and G  
>>>>>>>>>>>>>> starting values here. When I got an error, I always
>>>>>>>>>>>>>> went to the MCMCglmm source to understand why the  
>>>>>>>>>>>>>> checks failed, but I didn't always understand
>>>>>>>>>>>>>> what was being checked and couldn't get it to work.
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> Here's a failing example:
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> l<-rnorm(200, -1, sqrt(1))
>>>>>>>>>>>>>> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
>>>>>>>>>>>>>> g = sample(letters[1:10], size = 200, replace = T)
>>>>>>>>>>>>>> pred = rnorm(200)
>>>>>>>>>>>>>> y<-rpois(200,exp(l)-t)
>>>>>>>>>>>>>> y[1:40] = 0
>>>>>>>>>>>>>> # generate zero-altered data with an intercept of -1
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> dat<-data.frame(y=y, g = g, pred = pred)
>>>>>>>>>>>>>> set.seed(1)
>>>>>>>>>>>>>> start_true = list(Liab=l, R = 1, G = 1 )
>>>>>>>>>>>>>> m1<-MCMCglmm(y~1 + pred,random = ~ g,  
>>>>>>>>>>>>>> family="zapoisson",rcov=~us(trait):units, data=dat,  
>>>>>>>>>>>>>> start= start_true)
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> # use true latent variable as starting values
>>>>>>>>>>>>>> set.seed(1)
>>>>>>>>>>>>>> # use some very bad starting values
>>>>>>>>>>>>>> start_rand = list(Liab=rnorm(200), R = rpois(1, 1)+1, G  
>>>>>>>>>>>>>> = rpois(1, 1)+1 )
>>>>>>>>>>>>>> m2<-MCMCglmm(y~1 + pred,random = ~  
>>>>>>>>>>>>>> g,rcov=~us(trait):units,  family="zapoisson", data=dat,  
>>>>>>>>>>>>>> start = start_rand)
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> Best,
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> Ruben
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> On 25 Aug 2014, at 18:29, Jarrod Hadfield  
>>>>>>>>>>>>>> <j.hadfield at ed.ac.uk> wrote:
>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> Hi Ruben,
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> Sorry  - I was wrong when I said that everything is  
>>>>>>>>>>>>>>> Gibbs sampled conditional on the latent variables. The  
>>>>>>>>>>>>>>> location effects (fixed and random effects) are also  
>>>>>>>>>>>>>>> sampled conditional on the (co)variance components so  
>>>>>>>>>>>>>>> you should add them to the starting values. In the  
>>>>>>>>>>>>>>> case where the true values are used:
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat,  
>>>>>>>>>>>>>>> start=list(Liab=l,R=1))
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> Cheers,
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> Jarrod
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> Quoting Jarrod Hadfield <j.hadfield at ed.ac.uk> on Mon,  
>>>>>>>>>>>>>>> 25 Aug 2014 17:14:14 +0100:
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> Hi Ruben,
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> You will need to provide over-dispersed starting  
>>>>>>>>>>>>>>>> values for multiple-chain convergence diagnostics to  
>>>>>>>>>>>>>>>> be useful (GLMM are so simple I am generally happy if  
>>>>>>>>>>>>>>>> the output of a single run looks reasonable).
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> With non-Gaussian data everything is Gibbs sampled  
>>>>>>>>>>>>>>>> conditional on the latent variables, so you only need  
>>>>>>>>>>>>>>>> to pass them:
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> l<-rnorm(200, -1, sqrt(1))
>>>>>>>>>>>>>>>> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
>>>>>>>>>>>>>>>> y<-rpois(200,exp(l)-t)+1
>>>>>>>>>>>>>>>> # generate zero-truncated data with an intercept of -1
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> dat<-data.frame(y=y)
>>>>>>>>>>>>>>>> set.seed(1)
>>>>>>>>>>>>>>>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat,  
>>>>>>>>>>>>>>>> start=list(Liab=l))
>>>>>>>>>>>>>>>> # use true latent variable as starting values
>>>>>>>>>>>>>>>> set.seed(1)
>>>>>>>>>>>>>>>> m2<-MCMCglmm(y~1, family="ztpoisson", data=dat,  
>>>>>>>>>>>>>>>> start=list(Liab=rnorm(200)))
>>>>>>>>>>>>>>>> # use some very bad starting values
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> plot(mcmc.list(m1$Sol, m2$Sol))
>>>>>>>>>>>>>>>> # not identical despite the same seed because of  
>>>>>>>>>>>>>>>> different starting values but clearly sampling the  
>>>>>>>>>>>>>>>> same posterior distribution:
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> gelman.diag(mcmc.list(m1$Sol, m2$Sol))
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> Cheers,
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> Jarrod
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on Mon,  
>>>>>>>>>>>>>>>> 25 Aug 2014 18:00:08 +0200:
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>> Dear Jarrod,
>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>> thanks for the quick reply. Please, don't waste time  
>>>>>>>>>>>>>>>>> looking into doMPI ? I am happy that I
>>>>>>>>>>>>>>>>> get the expected result, when I specify that  
>>>>>>>>>>>>>>>>> reproducible seed, whyever that may be.
>>>>>>>>>>>>>>>>> I'm pretty sure that is the deciding factor, because  
>>>>>>>>>>>>>>>>> I tested it explicitly, I just have no idea
>>>>>>>>>>>>>>>>> how/why it interacts with the choice of family.
>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>> That said, is setting up different RNG streams for  
>>>>>>>>>>>>>>>>> my workers (now that it works) __sufficient__
>>>>>>>>>>>>>>>>> so that I get independent chains and can use  
>>>>>>>>>>>>>>>>> gelman.diag() for convergence diagnostics?
>>>>>>>>>>>>>>>>> Or should I still tinker with the starting values myself?
>>>>>>>>>>>>>>>>> I've never found a worked example of supplying  
>>>>>>>>>>>>>>>>> starting values and am thus a bit lost.
>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>> Sorry for sending further questions, I hope someone  
>>>>>>>>>>>>>>>>> else takes pity while
>>>>>>>>>>>>>>>>> you're busy with lectures.
>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>> Best wishes
>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>> Ruben
>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>> On 25 Aug 2014, at 17:29, Jarrod Hadfield  
>>>>>>>>>>>>>>>>> <j.hadfield at ed.ac.uk> wrote:
>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>> Hi Ruben,
>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>> I do not think the issue is with the starting  
>>>>>>>>>>>>>>>>>> values, because even if the same starting values  
>>>>>>>>>>>>>>>>>> were used the chains would still differ because of  
>>>>>>>>>>>>>>>>>> the randomness in the Markov Chain (if I interpret  
>>>>>>>>>>>>>>>>>> your `identical' test correctly). This just  
>>>>>>>>>>>>>>>>>> involves a call to GetRNGstate() in the C++ code (L  
>>>>>>>>>>>>>>>>>> 871 ofMCMCglmm.cc) so I think for some reason  
>>>>>>>>>>>>>>>>>> doMPI/foreach is not doing what you expect. I am  
>>>>>>>>>>>>>>>>>> not familiar with doMPI and am in the middle of  
>>>>>>>>>>>>>>>>>> writing lectures so haven't got time to look into  
>>>>>>>>>>>>>>>>>> it carefully. Outside of the context of doMPI I get  
>>>>>>>>>>>>>>>>>> the behaviour I expect:
>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>> l<-rnorm(200, -1, sqrt(1))
>>>>>>>>>>>>>>>>>> t<-(-log(1-runif(200)*(1-exp(-exp(l)))))
>>>>>>>>>>>>>>>>>> y<-rpois(200,exp(l)-t)+1
>>>>>>>>>>>>>>>>>> # generate zero-truncated data with an intercept of -1
>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>> dat<-data.frame(y=y)
>>>>>>>>>>>>>>>>>> set.seed(1)
>>>>>>>>>>>>>>>>>> m1<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>>>>>>>>>>>>>>>> set.seed(2)
>>>>>>>>>>>>>>>>>> m2<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>>>>>>>>>>>>>>>> set.seed(2)
>>>>>>>>>>>>>>>>>> m3<-MCMCglmm(y~1, family="ztpoisson", data=dat)
>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>> plot(mcmc.list(m1$Sol, m2$Sol))
>>>>>>>>>>>>>>>>>> # different, as expected
>>>>>>>>>>>>>>>>>> plot(mcmc.list(m2$Sol, m3$Sol))
>>>>>>>>>>>>>>>>>> # the same, as expected
>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>> Quoting Ruben Arslan <rubenarslan at gmail.com> on  
>>>>>>>>>>>>>>>>>> Mon, 25 Aug 2014 16:58:06 +0200:
>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>> Dear list,
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>> sorry for bumping my old post, I hope to elicit a  
>>>>>>>>>>>>>>>>>>> response with a more focused question:
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>> When does MCMCglmm automatically start from  
>>>>>>>>>>>>>>>>>>> different values when using doMPI/foreach?
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>> I have done some tests with models of varying  
>>>>>>>>>>>>>>>>>>> complexity. For example, the script in my last
>>>>>>>>>>>>>>>>>>> post (using "zapoisson") yielded 40 identical chains:
>>>>>>>>>>>>>>>>>>>> identical(mcmclist[1], mcmclist[30])
>>>>>>>>>>>>>>>>>>> TRUE
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>> A simpler (?) model (using "ztpoisson" and no  
>>>>>>>>>>>>>>>>>>> specified prior), however, yielded different chains
>>>>>>>>>>>>>>>>>>> and I could use them to calculate gelman.diag()
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>> Changing my script to the version below, i.e.  
>>>>>>>>>>>>>>>>>>> seeding foreach using .options.mpi=list( seed= 1337)
>>>>>>>>>>>>>>>>>>> so as to make RNGstreams reproducible (or so I   
>>>>>>>>>>>>>>>>>>> thought), led to different chains even for the
>>>>>>>>>>>>>>>>>>> "zapoisson" model.
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>> In no case have I (successfully) tried to supplant  
>>>>>>>>>>>>>>>>>>> the default of MCMCglmm's "start" argument.
>>>>>>>>>>>>>>>>>>> Is starting my models from different RNGsubstreams  
>>>>>>>>>>>>>>>>>>> inadequate compared to manipulating
>>>>>>>>>>>>>>>>>>> the start argument explicitly? If so, is there any  
>>>>>>>>>>>>>>>>>>> worked example of explicit starting value  
>>>>>>>>>>>>>>>>>>> manipulation
>>>>>>>>>>>>>>>>>>> in parallel computation?
>>>>>>>>>>>>>>>>>>> I've browsed the MCMCglmm source to understand how  
>>>>>>>>>>>>>>>>>>> the default starting values are generated,
>>>>>>>>>>>>>>>>>>> but didn't find any differences with respect to  
>>>>>>>>>>>>>>>>>>> RNG for the two families "ztpoisson" and "zapoisson"
>>>>>>>>>>>>>>>>>>> (granted, I did not dig very deep).
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>> Best regards,
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>> Ruben Arslan
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>> # bsub -q mpi -W 12:00 -n 41 -R np20 mpirun -H  
>>>>>>>>>>>>>>>>>>> localhost -n 41 R --slave -f  
>>>>>>>>>>>>>>>>>>> "/usr/users/rarslan/rpqa/rpqa_main/rpqa_children_parallel.R"
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>> library(doMPI)
>>>>>>>>>>>>>>>>>>> cl <-  
>>>>>>>>>>>>>>>>>>> startMPIcluster(verbose=T,workdir="/usr/users/rarslan/rpqa/rpqa_main/")
>>>>>>>>>>>>>>>>>>> registerDoMPI(cl)
>>>>>>>>>>>>>>>>>>> Children_mcmc1 =  
>>>>>>>>>>>>>>>>>>> foreach(i=1:clusterSize(cl),.options.mpi =  
>>>>>>>>>>>>>>>>>>> list(seed=1337) ) %dopar% {
>>>>>>>>>>>>>>>>>>> 	library(MCMCglmm);library(data.table)
>>>>>>>>>>>>>>>>>>> 	load("/usr/users/rarslan/rpqa/rpqa1.rdata")
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>> 	nitt = 130000; thin = 100; burnin = 30000
>>>>>>>>>>>>>>>>>>> 	prior.m5d.2 = list(
>>>>>>>>>>>>>>>>>>> 		R = list(V = diag(c(1,1)), nu = 0.002),
>>>>>>>>>>>>>>>>>>> 		G=list(list(V=diag(c(1,1e-6)),nu=0.002))
>>>>>>>>>>>>>>>>>>> 	)
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>> 	rpqa.1 = na.omit(rpqa.1[spouses>0,  
>>>>>>>>>>>>>>>>>>> list(idParents, children, male, urban, spouses,  
>>>>>>>>>>>>>>>>>>> paternalage.mean, paternalage.factor)])
>>>>>>>>>>>>>>>>>>> 	(m1 = MCMCglmm( children ~ trait * (male + urban  
>>>>>>>>>>>>>>>>>>> + spouses + paternalage.mean + paternalage.factor),
>>>>>>>>>>>>>>>>>>> 						rcov=~us(trait):units,
>>>>>>>>>>>>>>>>>>> 						random=~us(trait):idParents,
>>>>>>>>>>>>>>>>>>> 						family="zapoisson",
>>>>>>>>>>>>>>>>>>> 						prior = prior.m5d.2,
>>>>>>>>>>>>>>>>>>> 						data=rpqa.1,
>>>>>>>>>>>>>>>>>>> 						pr = F, saveX = F, saveZ = F,
>>>>>>>>>>>>>>>>>>> 						nitt=nitt,thin=thin,burnin=burnin))
>>>>>>>>>>>>>>>>>>> }
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>> library(coda)
>>>>>>>>>>>>>>>>>>> mcmclist =  
>>>>>>>>>>>>>>>>>>> mcmc.list(lapply(Children_mcmc1,FUN=function(x) {  
>>>>>>>>>>>>>>>>>>> x$Sol}))
>>>>>>>>>>>>>>>>>>> save(Children_mcmc1,mcmclist, file =  
>>>>>>>>>>>>>>>>>>> "/usr/users/rarslan/rpqa/rpqa_main/rpqa_mcmc_kids_za.rdata")
>>>>>>>>>>>>>>>>>>> closeCluster(cl)
>>>>>>>>>>>>>>>>>>> mpi.quit()
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>> On 04 Aug 2014, at 20:25, Ruben Arslan  
>>>>>>>>>>>>>>>>>>> <rubenarslan at gmail.com> wrote:
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>> Dear list,
>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>> would someone be willing to share her or his  
>>>>>>>>>>>>>>>>>>>> efforts in parallelising a MCMCglmm analysis?
>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>> I had something viable using harvestr that seemed  
>>>>>>>>>>>>>>>>>>>> to properly initialise
>>>>>>>>>>>>>>>>>>>> the starting values from different random number  
>>>>>>>>>>>>>>>>>>>> streams (which is desirable,
>>>>>>>>>>>>>>>>>>>> as far as I could find out), but I ended up being  
>>>>>>>>>>>>>>>>>>>> unable to use harvestr, because
>>>>>>>>>>>>>>>>>>>> it uses an old version of plyr, where  
>>>>>>>>>>>>>>>>>>>> parallelisation works only for multicore, not for
>>>>>>>>>>>>>>>>>>>> MPI.
>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>> I pasted my working version, that does not do  
>>>>>>>>>>>>>>>>>>>> anything about starting values or RNG
>>>>>>>>>>>>>>>>>>>> at the end of this email. I can try to fumble  
>>>>>>>>>>>>>>>>>>>> further in the dark or try to update harvestr,
>>>>>>>>>>>>>>>>>>>> but maybe someone has gone through all this already.
>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>> I'd also appreciate any tips for elegantly  
>>>>>>>>>>>>>>>>>>>> post-processing such parallel data, as some of my  
>>>>>>>>>>>>>>>>>>>> usual
>>>>>>>>>>>>>>>>>>>> extraction functions and routines are hampered by  
>>>>>>>>>>>>>>>>>>>> the fact that some coda functions
>>>>>>>>>>>>>>>>>>>> do not aggregate results over chains. (What I get  
>>>>>>>>>>>>>>>>>>>> from a single-chain summary in MCMCglmm
>>>>>>>>>>>>>>>>>>>> is a bit more comprehensive, than what I managed  
>>>>>>>>>>>>>>>>>>>> to cobble together with my own extraction
>>>>>>>>>>>>>>>>>>>> functions).
>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>> The reason I'm parallelising my analyses is that  
>>>>>>>>>>>>>>>>>>>> I'm having trouble getting a good effective
>>>>>>>>>>>>>>>>>>>> sample size for any parameter having to do with  
>>>>>>>>>>>>>>>>>>>> the many zeroes in my data.
>>>>>>>>>>>>>>>>>>>> Any pointers are very appreciated, I'm quite  
>>>>>>>>>>>>>>>>>>>> inexperienced with MCMCglmm.
>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>> Best wishes
>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>> Ruben
>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>> # bsub -q mpi-short -W 2:00 -n 42 -R np20 mpirun  
>>>>>>>>>>>>>>>>>>>> -H localhost -n 41 R --slave -f  
>>>>>>>>>>>>>>>>>>>> "rpqa/rpqa_main/rpqa_children_parallel.r"
>>>>>>>>>>>>>>>>>>>> library(doMPI)
>>>>>>>>>>>>>>>>>>>> cl <- startMPIcluster()
>>>>>>>>>>>>>>>>>>>> registerDoMPI(cl)
>>>>>>>>>>>>>>>>>>>> Children_mcmc1 = foreach(i=1:40) %dopar% {
>>>>>>>>>>>>>>>>>>>> 	library(MCMCglmm)
>>>>>>>>>>>>>>>>>>>> 	load("rpqa1.rdata")
>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>> 	nitt = 40000; thin = 100; burnin = 10000
>>>>>>>>>>>>>>>>>>>> 	prior = list(
>>>>>>>>>>>>>>>>>>>> 		R = list(V = diag(c(1,1)), nu = 0.002),
>>>>>>>>>>>>>>>>>>>> 		G=list(list(V=diag(c(1,1e-6)),nu=0.002))
>>>>>>>>>>>>>>>>>>>> 	)
>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>> 	MCMCglmm( children ~ trait -1 +  
>>>>>>>>>>>>>>>>>>>> at.level(trait,1):male + at.level(trait,1):urban  
>>>>>>>>>>>>>>>>>>>> + at.level(trait,1):spouses +  
>>>>>>>>>>>>>>>>>>>> at.level(trait,1):paternalage.mean +  
>>>>>>>>>>>>>>>>>>>> at.level(trait,1):paternalage.factor,
>>>>>>>>>>>>>>>>>>>> 		rcov=~us(trait):units,
>>>>>>>>>>>>>>>>>>>> 		random=~us(trait):idParents,
>>>>>>>>>>>>>>>>>>>> 		family="zapoisson",
>>>>>>>>>>>>>>>>>>>> 		prior = prior,
>>>>>>>>>>>>>>>>>>>> 		data=rpqa.1,
>>>>>>>>>>>>>>>>>>>> 		pr = F, saveX = T, saveZ = T,
>>>>>>>>>>>>>>>>>>>> 		nitt=nitt,thin=thin,burnin=burnin)
>>>>>>>>>>>>>>>>>>>> }
>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>> library(coda)
>>>>>>>>>>>>>>>>>>>> mcmclist =  
>>>>>>>>>>>>>>>>>>>> mcmc.list(lapply(Children_mcmc1,FUN=function(x) {  
>>>>>>>>>>>>>>>>>>>> x$Sol}))
>>>>>>>>>>>>>>>>>>>> save(Children_mcmc1,mcmclist, file =  
>>>>>>>>>>>>>>>>>>>> "rpqa_mcmc_kids_za.rdata")
>>>>>>>>>>>>>>>>>>>> closeCluster(cl)
>>>>>>>>>>>>>>>>>>>> mpi.quit()
>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>> --
>>>>>>>>>>>>>>>>>>>> Ruben C. Arslan
>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>> Georg August University G?ttingen
>>>>>>>>>>>>>>>>>>>> Biological Personality Psychology and  
>>>>>>>>>>>>>>>>>>>> Psychological Assessment
>>>>>>>>>>>>>>>>>>>> Georg Elias M?ller Institute of Psychology
>>>>>>>>>>>>>>>>>>>> Go?lerstr. 14
>>>>>>>>>>>>>>>>>>>> 37073 G?ttingen
>>>>>>>>>>>>>>>>>>>> Germany
>>>>>>>>>>>>>>>>>>>> Tel.: +49 551 3920704
>>>>>>>>>>>>>>>>>>>> https://psych.uni-goettingen.de/en/biopers/team/arslan
>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>> 	[[alternative HTML version deleted]]
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>> --
>>>>>>>>>>>>>>>>>> The University of Edinburgh is a charitable body,  
>>>>>>>>>>>>>>>>>> registered in
>>>>>>>>>>>>>>>>>> Scotland, with registration number SC005336.
>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> --
>>>>>>>>>>>>>>>> The University of Edinburgh is a charitable body,  
>>>>>>>>>>>>>>>> registered in
>>>>>>>>>>>>>>>> Scotland, with registration number SC005336.
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> _______________________________________________
>>>>>>>>>>>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>>>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> --
>>>>>>>>>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>>>>>>>>>> Scotland, with registration number SC005336.
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>
>>>>>>>>>>>>>>
>>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>> --
>>>>>>>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>>>>>>>> Scotland, with registration number SC005336.
>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>> --
>>>>>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>>>>>> Scotland, with registration number SC005336.
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> --
>>>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>>>> Scotland, with registration number SC005336.
>>>>>>>>>
>>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> --
>>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>>> Scotland, with registration number SC005336.
>>>>>>>
>>>>>>>
>>>>>>
>>>>>>
>>>>>
>>>>>
>>>>>
>>>>> --
>>>>> The University of Edinburgh is a charitable body, registered in
>>>>> Scotland, with registration number SC005336.
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>
>>>>
>>>> --
>>>> The University of Edinburgh is a charitable body, registered in
>>>> Scotland, with registration number SC005336.
>>>>
>>>>
>>>
>>>
>>
>>
>>
>> --
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>>
>
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From bbolker at gmail.com  Fri Aug 29 14:49:43 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 29 Aug 2014 08:49:43 -0400
Subject: [R-sig-ME] Random effects in clmm() of package ordinal
In-Reply-To: <20140829113102.GA4000@gmail.com>
References: <20140829113102.GA4000@gmail.com>
Message-ID: <540076E7.2090302@gmail.com>

On 14-08-29 07:31 AM, Christian Brauner wrote:
> Hello,
> 
> fitting linear mixed models it is often suggested that testing for random
> effects is not the best idea; mainly because the value of the random
> effects parameters lie at the boundary of the parameter space. Hence, it
> is preferred to not test for random effects and rather judge the inclusion
> of a random effect by the design of the experiment. Or if one really wants
> to do this use computation intensive methods like parametric bootstraps
> etc. I have adapted the strategy of not testing for random effects with
> linear mixed models.
> 
> Now I'm in a situation were I need to analyse ordinal data in a repeated
> measures design. The package I decided would best suit this purpose is the
> ordinal package (suggestions of alternatives are of course welcome). And
> this got me wondering about random effects again. I was testing a random
> effect (in fact by accidence as I did a faulty automated regexp
> substitution) and it got a p of 0.99. More precisely I was testing for the
> significance of a random slope in contrast to only including a random
> intercept. As the boundary-of-parameter-space argument is about maximum
> likelihood estimation in general it also applies to the proportional odds
> cummulative mixed model. But, and here is were I'm unsure what to do in
> this particular case the inclusion of a random slope in the clmm will turn
> a p of 0.004 into 0.1 for my main effect. In contrast all other methods
> (e.g.  treating my response not as an ordered factor but as a continuous
> variable and using a repeated measures anova) will give me a p of 0.004.
> This is the only reason why I'm concerned about this. This difference
> worries me and I'm unsure of what to do. Is it advisable to test here for
> a random effect?
> 
> Best,
> Christian
> 

  It sounds like something else is going on.  In my experience the
advice to not test random effects is based more on philosophy (the
random effects are often a nuisance variable that is implicit in the
experimental design, and is generally considered necessary for
appropriate inference -- see e.g. Hurlbert 1984 _Ecology_ on
"sacrificial pseudoreplication") than on the difficulties of inference
for random effects (boundary effects, finite-size effects, etc.).  A
large p-value either means that the point estimate of the RE variance is
small, or that its confidence interval is very large (or both);
especially in the former case, it is indeed surprising that its
inclusion should change inference so much.

  That's about as much as I think it's possible to say without more
detail.  I would suggest double-checking your data and model diagnostics
(is there something funny about the data and model fit?) and comparing
point estimates and confidence intervals from the different fits to try
to understand what the different models are saying about the data (not
just why the p-value changes so much).
Are you using different types of p-value estimation in different models
(Wald vs LRT vs ... ?) ?  Are you inducing complete separation or severe
imbalance by including the RE?  Is one of your random-effect levels
confounded with your main effect (an example along these lines came up
on the list a few months ago:
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2014q2/022188.html )?

  good luck
    Ben Bolker


From corey.sparks at utsa.edu  Fri Aug 29 17:55:22 2014
From: corey.sparks at utsa.edu (Corey Sparks)
Date: Fri, 29 Aug 2014 15:55:22 +0000
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 92, Issue 45
In-Reply-To: <mailman.641.1409303265.15062.r-sig-mixed-models@r-project.org>
References: <mailman.641.1409303265.15062.r-sig-mixed-models@r-project.org>
Message-ID: <BB1C4E67-A2B4-4497-904A-C0D46ED1B403@utsa.edu>

This is something that I encounter a lot in my own work. I?m guessing you?re like me and you?re not interested in prediction, but you are interested in making sure your regression coefficients are correctly estimated using survey design weights, and your standard errors for these are also corrected for survey design (clustering/stratification). There was a thread about this last year that I contributed to. Here is the link to that:
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2014q2/021994.html

I made an example and put it on Rpubs:
http://rpubs.com/corey_sparks/27276

Let me know if this helps
Best,
Corey

Corey Sparks
Associate Professor
Department of Demography
College of Public Policy
501 West Cesar E Chavez Blvd
Monterrey Building 2.270C
San Antonio, TX 78207
corey.sparks 'at' utsa.edu
coreysparks.weebly.com


> 
> ----------------------------------------------------------------------
> 
> Message: 1
> Date: Fri, 29 Aug 2014 09:23:05 +0100
> From: Rodrigo Travitzki <r.travitzki at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] multilevel analysis with sample weighted data
> Message-ID: <54003869.70904 at gmail.com>
> Content-Type: text/plain; charset=windows-1252; format=flowed
> 
> On 28-08-2014 14:52, Ben Bolker wrote:
>> On 14-08-28 07:01 AM, Rodrigo Travitzki wrote:
>>> Dear R masters,
>>> I'm looking for a R package to do multilevel analysis of a weighted data
>>> (is a weigthed sample of brazilian educational data) but could not find
>>> it. There is just a "weights" option in lme(), but is not about
>>> frequency (or probability) weigths in data. In some foruns, no response
>>> either.
>>> So, could you please confirm this information for me? There is any R
>>> package/function which do this? I really don't want to use proprietary
>>> software, but if there is no option, I'll need to do so.
>>> Thank you very much.
>>> 
>>> Best wishes,
>>> Rodrigo Travitzki
>>   It depends a little bit what you want to do/the meaning of the
>> weights.  I have successfully used weights=varFixed(~I(1/n))
>> [inverse-variance weighting based on the number of samples per group] in
>> lme; alternatively, you could use weights=n in lmer (from the lme4
>> package) to get an equivalent result.
>> 
>> If you want to deal with survey weighting, the story seems to be
>> considerably more complicated -- I don't claim to understand it, but
>> Andrew Gelman (a fairly prominent applied Bayesian statistician) claims
>> that it's "a mess" (to use his phrase).  If the weights represent
>> probability of inclusion in a survey, I believe he would recommend
>> model-based inference -- that is, fit an unweighted multilevel
>> regression model and then use post-stratification/weighting to make
>> predictions (see http://andrewgelman.com/?s=survey+weights for various
>> discussion and links to papers).
>> 
>>   good luck,
>>     Ben Bolker
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> Thanks, Ben!
> 
> It seems the problem is far more deeper than I expected.. Now I'm 
> wondering how can this issue be so 'easy managed' in some proprietary 
> softwares, like MLwiN, where you just need to insert the weights and voil?!
> Anyway, I will read carefully the link you sent and see what can be done.
> 
> Rodrigo
> 
> 
> 


From corey.sparks at utsa.edu  Fri Aug 29 18:14:46 2014
From: corey.sparks at utsa.edu (Corey Sparks)
Date: Fri, 29 Aug 2014 16:14:46 +0000
Subject: [R-sig-ME] multilevel analysis with sample weighted data
In-Reply-To: <BB1C4E67-A2B4-4497-904A-C0D46ED1B403@utsa.edu>
References: <mailman.641.1409303265.15062.r-sig-mixed-models@r-project.org>
	<BB1C4E67-A2B4-4497-904A-C0D46ED1B403@utsa.edu>
Message-ID: <3EB5224B-3EB6-420F-9B3E-6017B9EC53E2@utsa.edu>


> This is something that I encounter a lot in my own work. I?m guessing you?re like me and you?re not interested in prediction, but you are interested in making sure your regression coefficients are correctly estimated using survey design weights, and your standard errors for these are also corrected for survey design (clustering/stratification). There was a thread about this last year that I contributed to. Here is the link to that:
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2014q2/021994.html
> 
> I made an example and put it on Rpubs:
> http://rpubs.com/corey_sparks/27276
> 
> Let me know if this helps
> Best,
> Corey
> 
> Corey Sparks
> Associate Professor
> Department of Demography
> College of Public Policy
> 501 West Cesar E Chavez Blvd
> Monterrey Building 2.270C
> San Antonio, TX 78207
> corey.sparks 'at' utsa.edu
> coreysparks.weebly.com
> 
> 
>> 
>> ----------------------------------------------------------------------
>> 
>> Message: 1
>> Date: Fri, 29 Aug 2014 09:23:05 +0100
>> From: Rodrigo Travitzki <r.travitzki at gmail.com>
>> To: r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] multilevel analysis with sample weighted data
>> Message-ID: <54003869.70904 at gmail.com>
>> Content-Type: text/plain; charset=windows-1252; format=flowed
>> 
>> On 28-08-2014 14:52, Ben Bolker wrote:
>>> On 14-08-28 07:01 AM, Rodrigo Travitzki wrote:
>>>> Dear R masters,
>>>> I'm looking for a R package to do multilevel analysis of a weighted data
>>>> (is a weigthed sample of brazilian educational data) but could not find
>>>> it. There is just a "weights" option in lme(), but is not about
>>>> frequency (or probability) weigths in data. In some foruns, no response
>>>> either.
>>>> So, could you please confirm this information for me? There is any R
>>>> package/function which do this? I really don't want to use proprietary
>>>> software, but if there is no option, I'll need to do so.
>>>> Thank you very much.
>>>> 
>>>> Best wishes,
>>>> Rodrigo Travitzki
>>>  It depends a little bit what you want to do/the meaning of the
>>> weights.  I have successfully used weights=varFixed(~I(1/n))
>>> [inverse-variance weighting based on the number of samples per group] in
>>> lme; alternatively, you could use weights=n in lmer (from the lme4
>>> package) to get an equivalent result.
>>> 
>>> If you want to deal with survey weighting, the story seems to be
>>> considerably more complicated -- I don't claim to understand it, but
>>> Andrew Gelman (a fairly prominent applied Bayesian statistician) claims
>>> that it's "a mess" (to use his phrase).  If the weights represent
>>> probability of inclusion in a survey, I believe he would recommend
>>> model-based inference -- that is, fit an unweighted multilevel
>>> regression model and then use post-stratification/weighting to make
>>> predictions (see http://andrewgelman.com/?s=survey+weights for various
>>> discussion and links to papers).
>>> 
>>>  good luck,
>>>    Ben Bolker
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
>> Thanks, Ben!
>> 
>> It seems the problem is far more deeper than I expected.. Now I'm 
>> wondering how can this issue be so 'easy managed' in some proprietary 
>> softwares, like MLwiN, where you just need to insert the weights and voil?!
>> Anyway, I will read carefully the link you sent and see what can be done.
>> 
>> Rodrigo
>> 
>> 
>> 
> 
> 


From M.Fairbrother at bristol.ac.uk  Fri Aug 29 18:41:26 2014
From: M.Fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Fri, 29 Aug 2014 09:41:26 -0700
Subject: [R-sig-ME] Random effects in clmm() of package ordinal
Message-ID: <CAAH-yP_5mNa46HJaumKpin3Mrv14xgkftcfqhnbATD36VxnWHg@mail.gmail.com>

Hi Christian,

The ordinal package (which is otherwise very handy) does not allow for
random slopes (only random intercepts), so I don't think you can have
tested what you think you tested using that package.

You could try the MCMCglmm package instead, which allows for ordinal models
*and* random slopes.

Regarding random slopes more generally, Barr et al.'s (2013) paper "Random
effects structure for confirmatory hypothesis testing: Keep it maximal"
shows pretty definitively that not allowing for random slopes can often be
anticonservative. So if there's a gap between the p values you get with and
without random slopes, I'd be more inclined to trust the value *with*
random slopes.

Hope that's useful.

Cheers,
Malcolm




> Date: Fri, 29 Aug 2014 13:31:03 +0200
> From: Christian Brauner <christianvanbrauner at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Random effects in clmm() of package ordinal
>
> Hello,
>
> fitting linear mixed models it is often suggested that testing for random
> effects is not the best idea; mainly because the value of the random
> effects parameters lie at the boundary of the parameter space. Hence, it
> is preferred to not test for random effects and rather judge the inclusion
> of a random effect by the design of the experiment. Or if one really wants
> to do this use computation intensive methods like parametric bootstraps
> etc. I have adapted the strategy of not testing for random effects with
> linear mixed models.
>
> Now I'm in a situation were I need to analyse ordinal data in a repeated
> measures design. The package I decided would best suit this purpose is the
> ordinal package (suggestions of alternatives are of course welcome). And
> this got me wondering about random effects again. I was testing a random
> effect (in fact by accidence as I did a faulty automated regexp
> substitution) and it got a p of 0.99. More precisely I was testing for the
> significance of a random slope in contrast to only including a random
> intercept. As the boundary-of-parameter-space argument is about maximum
> likelihood estimation in general it also applies to the proportional odds
> cummulative mixed model. But, and here is were I'm unsure what to do in
> this particular case the inclusion of a random slope in the clmm will turn
> a p of 0.004 into 0.1 for my main effect. In contrast all other methods
> (e.g.  treating my response not as an ordered factor but as a continuous
> variable and using a repeated measures anova) will give me a p of 0.004.
> This is the only reason why I'm concerned about this. This difference
> worries me and I'm unsure of what to do. Is it advisable to test here for
> a random effect?
>
> Best,
> Christian
>

	[[alternative HTML version deleted]]


From christianvanbrauner at gmail.com  Fri Aug 29 19:20:42 2014
From: christianvanbrauner at gmail.com (Christian Brauner)
Date: Fri, 29 Aug 2014 19:20:42 +0200
Subject: [R-sig-ME] Random effects in clmm() of package ordinal
In-Reply-To: <CAAH-yP_5mNa46HJaumKpin3Mrv14xgkftcfqhnbATD36VxnWHg@mail.gmail.com>
References: <CAAH-yP_5mNa46HJaumKpin3Mrv14xgkftcfqhnbATD36VxnWHg@mail.gmail.com>
Message-ID: <20140829172041.GA11350@gmail.com>

Hi Malcolm,

Interesting. I just read the reference manual for the ordinal package (v.
July 2, 2014) and indeed at the beginning it states "random slopes (random
coefficient models) are not yet implemented" (p. 3). If this i indeed true
then I'm puzzled by some things:
(a) later on he explains the usage of the extractor function VarCorr() for
class "clmm" and states "[...] a model can contain a random intercept (one
column) or a random intercept and a random slope (two columns) for the
same grouping factor" (p. 52).
(b) at first glance this seems inconsistent with the output of clmm():

library(ordinal)
fm2 <- clmm(rating ~ temp + contact + (temp | judge),
            data = wine,
            Hess = TRUE)

Now look at

summary(fm2)

Random effects:
 Groups Name        Variance Std.Dev. Corr
 judge  (Intercept) 1.15608  1.0752
        tempwarm    0.02801  0.1674   0.649
Number of groups:  judge 9

and

ranef(fm2)

> ranef(fm2)
$judge
  (Intercept)    tempwarm
1  1.61166859  0.20664909
2 -0.49269459 -0.06317359
3  0.93254466  0.11957142
4 -0.08571746 -0.01099074
5  0.13893821  0.01781474
6  0.44710565  0.05732815
7 -1.77974875 -0.22820043
8 -0.26589478 -0.03409318
9 -0.51044493 -0.06544955

that looks like a random intercept and random slope model.

What I accidently did in my models (illustrating here with his example) is
not to replace "temp" in the fixed part but in the ranom part:
fm2 <- clmm(rating ~ temp + contact + (temp | judge),
            data = wine,
            Hess = TRUE)
fm2a <- clmm(rating ~ temp + contact + (1 | judge),
             data = wine,
             Hess = TRUE)
anova(fm2a, fm2)

The anova output is fairly similar to mine; the p is extremely high as
well.

All the standard stuff works without a warning, e.g.:
fm2b <- clmm(rating ~ temp + contact + (1 | judge) + (temp + 0 | judge),
             data = wine,
             Hess = TRUE)

So what is happening here? Anybody got an idea?

Best,
Christian



On Fri, Aug 29, 2014 at 09:41:26AM -0700, Malcolm Fairbrother wrote:
> Hi Christian,
> 
> The ordinal package (which is otherwise very handy) does not allow for
> random slopes (only random intercepts), so I don't think you can have
> tested what you think you tested using that package.
> 
> You could try the MCMCglmm package instead, which allows for ordinal models
> *and* random slopes.
> 
> Regarding random slopes more generally, Barr et al.'s (2013) paper "Random
> effects structure for confirmatory hypothesis testing: Keep it maximal"
> shows pretty definitively that not allowing for random slopes can often be
> anticonservative. So if there's a gap between the p values you get with and
> without random slopes, I'd be more inclined to trust the value *with*
> random slopes.
> 
> Hope that's useful.
> 
> Cheers,
> Malcolm
> 
> 
> 
> 
> > Date: Fri, 29 Aug 2014 13:31:03 +0200
> > From: Christian Brauner <christianvanbrauner at gmail.com>
> > To: r-sig-mixed-models at r-project.org
> > Subject: [R-sig-ME] Random effects in clmm() of package ordinal
> >
> > Hello,
> >
> > fitting linear mixed models it is often suggested that testing for random
> > effects is not the best idea; mainly because the value of the random
> > effects parameters lie at the boundary of the parameter space. Hence, it
> > is preferred to not test for random effects and rather judge the inclusion
> > of a random effect by the design of the experiment. Or if one really wants
> > to do this use computation intensive methods like parametric bootstraps
> > etc. I have adapted the strategy of not testing for random effects with
> > linear mixed models.
> >
> > Now I'm in a situation were I need to analyse ordinal data in a repeated
> > measures design. The package I decided would best suit this purpose is the
> > ordinal package (suggestions of alternatives are of course welcome). And
> > this got me wondering about random effects again. I was testing a random
> > effect (in fact by accidence as I did a faulty automated regexp
> > substitution) and it got a p of 0.99. More precisely I was testing for the
> > significance of a random slope in contrast to only including a random
> > intercept. As the boundary-of-parameter-space argument is about maximum
> > likelihood estimation in general it also applies to the proportional odds
> > cummulative mixed model. But, and here is were I'm unsure what to do in
> > this particular case the inclusion of a random slope in the clmm will turn
> > a p of 0.004 into 0.1 for my main effect. In contrast all other methods
> > (e.g.  treating my response not as an ordered factor but as a continuous
> > variable and using a repeated measures anova) will give me a p of 0.004.
> > This is the only reason why I'm concerned about this. This difference
> > worries me and I'm unsure of what to do. Is it advisable to test here for
> > a random effect?
> >
> > Best,
> > Christian
> >


From j.hadfield at ed.ac.uk  Fri Aug 29 19:51:07 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 29 Aug 2014 18:51:07 +0100
Subject: [R-sig-ME] Random effects in clmm() of package ordinal
In-Reply-To: <20140829172041.GA11350@gmail.com>
References: <CAAH-yP_5mNa46HJaumKpin3Mrv14xgkftcfqhnbATD36VxnWHg@mail.gmail.com>
	<20140829172041.GA11350@gmail.com>
Message-ID: <20140829185107.95481bu4vjfiwha8@www.staffmail.ed.ac.uk>

Hi Christian,

I think clmm is dealing with the random 'slopes' correctly (or at  
least it gives the same estimates as MCMCglmm) when temp is  
categorical (see below). Without knowing much about clmm I can imagine  
it might fail when temp is truly continuous because the variance of  
each latent variable varies as a function of the covariate and so (in  
the probit case) the cdf of the normal (i.e. the probit link) would  
need to be evaluated using different standard deviations.

Cheers,

Jarrod

fm2 <- clmm(rating ~ temp + contact + (temp-1 | judge),
? ? ? ? ? ? data = wine, link="probit",
? ? ? ? ? ? Hess = TRUE)

# note that I have changed temp|judge to temp-1|judge because I think  
it makes more sense with categorical variables.  Also I have used  
probit link in order to compare it to MCMCglmm's "threshold".

prior2=list(R=list(V=1, fix=1), G=list(G1=list(V=diag(2), nu=2,  
alpha.V=diag(2)*100, alpha.mu=c(0,0))))

fm2.mcmc <- MCMCglmm(rating ~ temp + contact, random=~us(temp):judge,  
data = wine,family="threshold", prior=prior2, nitt=13000*10,  
thin=10*5, burnin=3000*10, verbose=FALSE)


par(mfrow=c(2,2))
hist(fm2.mcmc$Sol[,2], breaks=50)
abline(v=coef(fm2)[5], col="red")
hist(fm2.mcmc$Sol[,3], breaks=50)
abline(v=coef(fm2)[6], col="red")
hist(fm2.mcmc$VCV[,1], breaks=50)
abline(v=VarCorr(fm2)$judge[1], col="red")
hist(fm2.mcmc$VCV[,4], breaks=50)
abline(v=VarCorr(fm2)$judge[4], col="red")




Quoting Christian Brauner <christianvanbrauner at gmail.com> on Fri, 29  
Aug 2014 19:20:42 +0200:

> Hi Malcolm,
>
> Interesting. I just read the reference manual for the ordinal package (v.
> July 2, 2014) and indeed at the beginning it states "random slopes (random
> coefficient models) are not yet implemented" (p. 3). If this i indeed true
> then I'm puzzled by some things:
> (a) later on he explains the usage of the extractor function VarCorr() for
> class "clmm" and states "[...] a model can contain a random intercept (one
> column) or a random intercept and a random slope (two columns) for the
> same grouping factor" (p. 52).
> (b) at first glance this seems inconsistent with the output of clmm():
>
> library(ordinal)
> fm2 <- clmm(rating ~ temp + contact + (temp | judge),
>             data = wine,
>             Hess = TRUE)
>
> Now look at
>
> summary(fm2)
>
> Random effects:
>  Groups Name        Variance Std.Dev. Corr
>  judge  (Intercept) 1.15608  1.0752
>         tempwarm    0.02801  0.1674   0.649
> Number of groups:  judge 9
>
> and
>
> ranef(fm2)
>
>> ranef(fm2)
> $judge
>   (Intercept)    tempwarm
> 1  1.61166859  0.20664909
> 2 -0.49269459 -0.06317359
> 3  0.93254466  0.11957142
> 4 -0.08571746 -0.01099074
> 5  0.13893821  0.01781474
> 6  0.44710565  0.05732815
> 7 -1.77974875 -0.22820043
> 8 -0.26589478 -0.03409318
> 9 -0.51044493 -0.06544955
>
> that looks like a random intercept and random slope model.
>
> What I accidently did in my models (illustrating here with his example) is
> not to replace "temp" in the fixed part but in the ranom part:
> fm2 <- clmm(rating ~ temp + contact + (temp | judge),
>             data = wine,
>             Hess = TRUE)
> fm2a <- clmm(rating ~ temp + contact + (1 | judge),
>              data = wine,
>              Hess = TRUE)
> anova(fm2a, fm2)
>
> The anova output is fairly similar to mine; the p is extremely high as
> well.
>
> All the standard stuff works without a warning, e.g.:
> fm2b <- clmm(rating ~ temp + contact + (1 | judge) + (temp + 0 | judge),
>              data = wine,
>              Hess = TRUE)
>
> So what is happening here? Anybody got an idea?
>
> Best,
> Christian
>
>
>
> On Fri, Aug 29, 2014 at 09:41:26AM -0700, Malcolm Fairbrother wrote:
>> Hi Christian,
>>
>> The ordinal package (which is otherwise very handy) does not allow for
>> random slopes (only random intercepts), so I don't think you can have
>> tested what you think you tested using that package.
>>
>> You could try the MCMCglmm package instead, which allows for ordinal models
>> *and* random slopes.
>>
>> Regarding random slopes more generally, Barr et al.'s (2013) paper "Random
>> effects structure for confirmatory hypothesis testing: Keep it maximal"
>> shows pretty definitively that not allowing for random slopes can often be
>> anticonservative. So if there's a gap between the p values you get with and
>> without random slopes, I'd be more inclined to trust the value *with*
>> random slopes.
>>
>> Hope that's useful.
>>
>> Cheers,
>> Malcolm
>>
>>
>>
>>
>> > Date: Fri, 29 Aug 2014 13:31:03 +0200
>> > From: Christian Brauner <christianvanbrauner at gmail.com>
>> > To: r-sig-mixed-models at r-project.org
>> > Subject: [R-sig-ME] Random effects in clmm() of package ordinal
>> >
>> > Hello,
>> >
>> > fitting linear mixed models it is often suggested that testing for random
>> > effects is not the best idea; mainly because the value of the random
>> > effects parameters lie at the boundary of the parameter space. Hence, it
>> > is preferred to not test for random effects and rather judge the inclusion
>> > of a random effect by the design of the experiment. Or if one really wants
>> > to do this use computation intensive methods like parametric bootstraps
>> > etc. I have adapted the strategy of not testing for random effects with
>> > linear mixed models.
>> >
>> > Now I'm in a situation were I need to analyse ordinal data in a repeated
>> > measures design. The package I decided would best suit this purpose is the
>> > ordinal package (suggestions of alternatives are of course welcome). And
>> > this got me wondering about random effects again. I was testing a random
>> > effect (in fact by accidence as I did a faulty automated regexp
>> > substitution) and it got a p of 0.99. More precisely I was testing for the
>> > significance of a random slope in contrast to only including a random
>> > intercept. As the boundary-of-parameter-space argument is about maximum
>> > likelihood estimation in general it also applies to the proportional odds
>> > cummulative mixed model. But, and here is were I'm unsure what to do in
>> > this particular case the inclusion of a random slope in the clmm will turn
>> > a p of 0.004 into 0.1 for my main effect. In contrast all other methods
>> > (e.g.  treating my response not as an ordered factor but as a continuous
>> > variable and using a repeated measures anova) will give me a p of 0.004.
>> > This is the only reason why I'm concerned about this. This difference
>> > worries me and I'm unsure of what to do. Is it advisable to test here for
>> > a random effect?
>> >
>> > Best,
>> > Christian
>> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From bbolker at gmail.com  Sat Aug 30 04:10:34 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 30 Aug 2014 02:10:34 +0000 (UTC)
Subject: [R-sig-ME] help on choosin right model for data
References: <000001cfbdf3$689a77d0$39cf6770$@iptpo.hr>
Message-ID: <loom.20140830T040446-860@post.gmane.org>

Josipa Perkovi? <josipa at ...> writes:

> I would appreciate if you could help me choose different R packages and
> writing model to analyze
> 
> what I believe to be unequally spaced repeated measurement data. 
> 
> My data consists of data on PAR (photosinthetically active radiation)
> -average and maximum daily PAR, collected successively every 10 min with
> data loggers.
> 
> Sensors were positioned above different mulches 
> (sub factor in three levels)
> with differently fertilized plant canopy 
> (main factor in 4 levels), so there
> are two different factors influencing AVG and MAX PAR.
> 
> Also since sensors weren't positioned in repetitions
>  I divided data in every
> 10 min, 15 min and 25 min sequence for AVG and MAX 
> for each sensor.  
> 
> So the experiment is two-factorial (fertilizers (4) 
> and mulch (3) ) but has
> time dimension too.
> 

  Are there multiple sensors within each mulch*fertilizer
combination?  If so, I would suggest starting with something lme,
and using something like

  avg_PAR ~ mulch*fertilizer , random = ~1|sensorID,
correlation=corAR1(form=~1|time)

Don't know how much of the day your data covers, but you might want
a term like

 cos(2*pi*time)+sin(2*pi*time)

or

  ns(time,5)  [a 5-knot spline; you'll need library(splines) first

where time is fraction-of-day [0,1] in the first case, scaling doesn't
matter in the second case.

 You might also need to consider a long-term time trend (linear or
quadratic or spline).

  You should definitely graph your data.

  Pinheiro and Bates (2000) might be useful.

 Ben Bolker


From christianvanbrauner at gmail.com  Sat Aug 30 14:54:32 2014
From: christianvanbrauner at gmail.com (Christian Brauner)
Date: Sat, 30 Aug 2014 14:54:32 +0200
Subject: [R-sig-ME] Analysing data with an ordinal response
Message-ID: <20140830125431.GA3571@gmail.com>

Hello,

I've posted yesterday investigating about random effects in proportional
odds cummulative mixed effects model; specifically about clmm() from the
ordinal package. I was doing some more reading about categorical data
analysis (e.g. Agresti (2010): Analysis of Ordinal Categorical Data).
Additionally to analysing data with an ordinal response with the help
aforementioned models it seems some people suggest e.g. to use the glmer()
function from lme4 to fit a whole range of models.

The data:
---------
My data looks as follows:
(1) ordinal response: a five point scale with 1<2<3<4<5 (1 being worst, 3
being neutral, 5 being best)
(2) one single categorical predictor "type" with 5 levels
(3) subjects as random effects term which I would specify in lme4 syntax:
(type | subjects) with intercept and slope for every subject.

Every subject saw 320 items (40 for level 1, 40 for level 2, 40 for level
3, 160 for level 4) and rated every single one of them. The dataset seems
quite nice and as it only contains a single predictor is very good to get
acquainted with categorical data analysis. So as I pointed out yesterday
in my mail
(https://stat.ethz.ch/pipermail/r-sig-mixed-models/2014q3/022582.html) I
used proportional odds cummulative mixed effects models which seems a good
choice.

Alternative methods to proportional odds mixed effects models that can
also acount for random effects and for which R packages exist?:
----------------------------------------------------------------------
However, I was wondering if there are alternative ways of analysing such
data apart from treating the response as a continuous variable and using
lmer() or aov(). And if there are any recommendation or advice people can
give here. This is mainly because I'm somewhat uncomfortable with using
MCMCglmm when I'm not doing a full-blown Bayesian analysis and I'm not
sure about clmm() in the ordinal package when it does state in its
reference manual that vector valued random effects cannot be fit. I can
see me having a hard time explaining this to publishers.

Fitting multiple glmer()'s to subsets of the orginal data?
----------------------------------------------------------
Here is an alternative I read about (I think on Stackoverflow by Ben). One
could split a dataset with an ordinal response into subsets that each only
contain two levels of the ordinal response. There are some questions I
have about this. How would you split that dataset into subsets given a 5
point ordinal response?  (Does subset A with levels 1 and 2, subset B with
levels 2 and 3, subset C with levels 3 and 4, subset D with levels 4 and 5
seems like a good choice because of the ordering?) I tried this with the
wine data set from the ordinal package. But this will ungraciously fail
because of convergence failures, model unidentifiability etc. (I'm using
lme4 1.1.8). Here is the wine example:

library(ordinal) # because of the wine dataset
library(lme4)
sub12 <- wine$rating %in% grep("[1-2]", wine$rating, value = TRUE)
sub12 <- subset(wine, subset = sub)
sub12$rating <- factor(sub12$rating, ordered = FALSE)
glmer12 <- glmer(rating ~ temp + contact + (temp | judge),
                 data = sub12,
                 family = binomial)

# Substituting (1 | judge) for (temp | judge) won't make it better

# Will give no warning
glm12 <- glm(rating ~ temp + contact,
             data = sub12,
             family = binomial)

sub23 <- wine$rating %in% grep("[2-3]", wine$rating, value = TRUE)
sub23 <- subset(wine, subset = sub)
sub23$rating <- factor(sub23$rating, ordered = FALSE)

glmer23 <- glmer(rating ~ temp + contact + (temp | judge),
                 data = sub23,
                 family = binomial)

sub34 <- wine$rating %in% grep("[3-4]", wine$rating, value = TRUE)
sub34 <- subset(wine, subset = sub)
sub34$rating <- factor(sub34$rating, ordered = FALSE)
glmer34 <- glmer(rating ~ temp + contact + (temp | judge),
                 data = sub34,
                 family = binomial)

Of course the wine dataset is rather tiny and mine won't but how likely am
I to run in similar problem if I analyse ordinal data this way?

Best,
Christian


From drmccloy at uw.edu  Mon Sep  1 11:19:32 2014
From: drmccloy at uw.edu (Dan McCloy)
Date: Mon, 1 Sep 2014 17:19:32 +0800
Subject: [R-sig-ME] glmer error: contrasts can only be applied to factors of
	2 or more levels
Message-ID: <CAOE0pYn5s7rtPPe52sdYncCRS2VD_vK98_m3Q00cVr1rmV773A@mail.gmail.com>

I'm getting the following error, despite the fact that all my fixed
effects were converted to factors and had their contrast attributes
set prior to calling glmer.

Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
  contrasts can be applied only to factors with 2 or more levels
Calls: glmer ... model.matrix -> model.matrix.default -> contrasts<-

Here is the model specification:
glmer(press ~ truth*adj*idn*num + (1|subj), data=wl,
family=binomial(link="probit"))

Here are the predictors. As you can see, they are all already factors
and have contrasts set, so I can't figure out why glmer is trying to
set contrasts anyway, much less why it thinks any of these have fewer
than two levels:

R> head(wl$truth)
[1] neither neither neither neither neither neither
attr(,"contrasts")
        target foil
neither      0    0
target       1    0
foil         0    1
Levels: neither target foil
R> head(wl$adj)
[1] TRUE TRUE TRUE TRUE TRUE TRUE
attr(,"contrasts")
      TRUE
TRUE     1
FALSE   -1
Levels: TRUE FALSE
R> head(wl$idn)
[1] FALSE FALSE FALSE FALSE FALSE FALSE
attr(,"contrasts")
      TRUE
TRUE     1
FALSE   -1
Levels: TRUE FALSE
R> head(wl$num)
[1] six six six six six six
attr(,"contrasts")
      three
three     1
six      -1
Levels: three six

Here is the session info:
R version 3.1.1 (2014-07-10)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_1.1-7   Rcpp_0.11.2  Matrix_1.1-4

loaded via a namespace (and not attached):
[1] grid_3.1.1      lattice_0.20-29 MASS_7.3-34     minqa_1.2.3
nlme_3.1-117    nloptr_1.0.4    splines_3.1.1     tools_3.1.1

Can anybody shed some light on what is going on here, and / or how to
work around it?  I've run similar models with very similar data on
slightly older versions of lme4 (but still >1.0) and never run into
this, so I'm wondering if a bug was introduced in the latest version.
-- dan

Daniel McCloy
http://dan.mccloy.info/
Postdoctoral Research Fellow
Institute for Learning and Brain Sciences
University of Washington


From christianvanbrauner at gmail.com  Mon Sep  1 16:36:31 2014
From: christianvanbrauner at gmail.com (Christian Brauner)
Date: Mon, 1 Sep 2014 16:36:31 +0200
Subject: [R-sig-ME] Random effects in clmm() of package ordinal
In-Reply-To: <20140829185107.95481bu4vjfiwha8@www.staffmail.ed.ac.uk>
References: <CAAH-yP_5mNa46HJaumKpin3Mrv14xgkftcfqhnbATD36VxnWHg@mail.gmail.com>
	<20140829172041.GA11350@gmail.com>
	<20140829185107.95481bu4vjfiwha8@www.staffmail.ed.ac.uk>
Message-ID: <20140901143630.GA20267@gmail.com>

Hi Jarrod,
Hi Malcolm,

Thank you Jarrod! In the meantime I wrote Rune and asked him whether
clmm() is currently able to fit random slope models and if he could update
his reference manual should this be the case. He answered that it is
indeed possible to fit random slope models with clmm(). In order to get a
an up to date version including a reference manual which does reflect
these changes one should download the ordinal package from r-forge:

install.packages("ordinal",
                 repos = "http://r-forge.r-project.org",
                 type = "source")

Best,
Christian

On Fri, Aug 29, 2014 at 06:51:07PM +0100, Jarrod Hadfield wrote:
> Hi Christian,
> 
> I think clmm is dealing with the random 'slopes' correctly (or at least it
> gives the same estimates as MCMCglmm) when temp is categorical (see below).
> Without knowing much about clmm I can imagine it might fail when temp is
> truly continuous because the variance of each latent variable varies as a
> function of the covariate and so (in the probit case) the cdf of the normal
> (i.e. the probit link) would need to be evaluated using different standard
> deviations.
> 
> Cheers,
> 
> Jarrod
> 
> fm2 <- clmm(rating ~ temp + contact + (temp-1 | judge),
> ? ? ? ? ? ? data = wine, link="probit",
> ? ? ? ? ? ? Hess = TRUE)
> 
> # note that I have changed temp|judge to temp-1|judge because I think it
> makes more sense with categorical variables.  Also I have used probit link
> in order to compare it to MCMCglmm's "threshold".
> 
> prior2=list(R=list(V=1, fix=1), G=list(G1=list(V=diag(2), nu=2,
> alpha.V=diag(2)*100, alpha.mu=c(0,0))))
> 
> fm2.mcmc <- MCMCglmm(rating ~ temp + contact, random=~us(temp):judge, data =
> wine,family="threshold", prior=prior2, nitt=13000*10, thin=10*5,
> burnin=3000*10, verbose=FALSE)
> 
> 
> par(mfrow=c(2,2))
> hist(fm2.mcmc$Sol[,2], breaks=50)
> abline(v=coef(fm2)[5], col="red")
> hist(fm2.mcmc$Sol[,3], breaks=50)
> abline(v=coef(fm2)[6], col="red")
> hist(fm2.mcmc$VCV[,1], breaks=50)
> abline(v=VarCorr(fm2)$judge[1], col="red")
> hist(fm2.mcmc$VCV[,4], breaks=50)
> abline(v=VarCorr(fm2)$judge[4], col="red")
> 
> 
> 
> 
> Quoting Christian Brauner <christianvanbrauner at gmail.com> on Fri, 29 Aug
> 2014 19:20:42 +0200:
> 
> >Hi Malcolm,
> >
> >Interesting. I just read the reference manual for the ordinal package (v.
> >July 2, 2014) and indeed at the beginning it states "random slopes (random
> >coefficient models) are not yet implemented" (p. 3). If this i indeed true
> >then I'm puzzled by some things:
> >(a) later on he explains the usage of the extractor function VarCorr() for
> >class "clmm" and states "[...] a model can contain a random intercept (one
> >column) or a random intercept and a random slope (two columns) for the
> >same grouping factor" (p. 52).
> >(b) at first glance this seems inconsistent with the output of clmm():
> >
> >library(ordinal)
> >fm2 <- clmm(rating ~ temp + contact + (temp | judge),
> >            data = wine,
> >            Hess = TRUE)
> >
> >Now look at
> >
> >summary(fm2)
> >
> >Random effects:
> > Groups Name        Variance Std.Dev. Corr
> > judge  (Intercept) 1.15608  1.0752
> >        tempwarm    0.02801  0.1674   0.649
> >Number of groups:  judge 9
> >
> >and
> >
> >ranef(fm2)
> >
> >>ranef(fm2)
> >$judge
> >  (Intercept)    tempwarm
> >1  1.61166859  0.20664909
> >2 -0.49269459 -0.06317359
> >3  0.93254466  0.11957142
> >4 -0.08571746 -0.01099074
> >5  0.13893821  0.01781474
> >6  0.44710565  0.05732815
> >7 -1.77974875 -0.22820043
> >8 -0.26589478 -0.03409318
> >9 -0.51044493 -0.06544955
> >
> >that looks like a random intercept and random slope model.
> >
> >What I accidently did in my models (illustrating here with his example) is
> >not to replace "temp" in the fixed part but in the ranom part:
> >fm2 <- clmm(rating ~ temp + contact + (temp | judge),
> >            data = wine,
> >            Hess = TRUE)
> >fm2a <- clmm(rating ~ temp + contact + (1 | judge),
> >             data = wine,
> >             Hess = TRUE)
> >anova(fm2a, fm2)
> >
> >The anova output is fairly similar to mine; the p is extremely high as
> >well.
> >
> >All the standard stuff works without a warning, e.g.:
> >fm2b <- clmm(rating ~ temp + contact + (1 | judge) + (temp + 0 | judge),
> >             data = wine,
> >             Hess = TRUE)
> >
> >So what is happening here? Anybody got an idea?
> >
> >Best,
> >Christian
> >
> >
> >
> >On Fri, Aug 29, 2014 at 09:41:26AM -0700, Malcolm Fairbrother wrote:
> >>Hi Christian,
> >>
> >>The ordinal package (which is otherwise very handy) does not allow for
> >>random slopes (only random intercepts), so I don't think you can have
> >>tested what you think you tested using that package.
> >>
> >>You could try the MCMCglmm package instead, which allows for ordinal models
> >>*and* random slopes.
> >>
> >>Regarding random slopes more generally, Barr et al.'s (2013) paper "Random
> >>effects structure for confirmatory hypothesis testing: Keep it maximal"
> >>shows pretty definitively that not allowing for random slopes can often be
> >>anticonservative. So if there's a gap between the p values you get with and
> >>without random slopes, I'd be more inclined to trust the value *with*
> >>random slopes.
> >>
> >>Hope that's useful.
> >>
> >>Cheers,
> >>Malcolm
> >>
> >>
> >>
> >>
> >>> Date: Fri, 29 Aug 2014 13:31:03 +0200
> >>> From: Christian Brauner <christianvanbrauner at gmail.com>
> >>> To: r-sig-mixed-models at r-project.org
> >>> Subject: [R-sig-ME] Random effects in clmm() of package ordinal
> >>>
> >>> Hello,
> >>>
> >>> fitting linear mixed models it is often suggested that testing for random
> >>> effects is not the best idea; mainly because the value of the random
> >>> effects parameters lie at the boundary of the parameter space. Hence, it
> >>> is preferred to not test for random effects and rather judge the inclusion
> >>> of a random effect by the design of the experiment. Or if one really wants
> >>> to do this use computation intensive methods like parametric bootstraps
> >>> etc. I have adapted the strategy of not testing for random effects with
> >>> linear mixed models.
> >>>
> >>> Now I'm in a situation were I need to analyse ordinal data in a repeated
> >>> measures design. The package I decided would best suit this purpose is the
> >>> ordinal package (suggestions of alternatives are of course welcome). And
> >>> this got me wondering about random effects again. I was testing a random
> >>> effect (in fact by accidence as I did a faulty automated regexp
> >>> substitution) and it got a p of 0.99. More precisely I was testing for the
> >>> significance of a random slope in contrast to only including a random
> >>> intercept. As the boundary-of-parameter-space argument is about maximum
> >>> likelihood estimation in general it also applies to the proportional odds
> >>> cummulative mixed model. But, and here is were I'm unsure what to do in
> >>> this particular case the inclusion of a random slope in the clmm will turn
> >>> a p of 0.004 into 0.1 for my main effect. In contrast all other methods
> >>> (e.g.  treating my response not as an ordered factor but as a continuous
> >>> variable and using a repeated measures anova) will give me a p of 0.004.
> >>> This is the only reason why I'm concerned about this. This difference
> >>> worries me and I'm unsure of what to do. Is it advisable to test here for
> >>> a random effect?
> >>>
> >>> Best,
> >>> Christian
> >>>
> >
> >_______________________________________________
> >R-sig-mixed-models at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
> 
> 
> 
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
> 
>


From bbolker at gmail.com  Mon Sep  1 23:36:28 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 1 Sep 2014 21:36:28 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?glmer_error=3A_contrasts_can_only_be_applied?=
	=?utf-8?q?_to_factors_of=092_or_more_levels?=
References: <CAOE0pYn5s7rtPPe52sdYncCRS2VD_vK98_m3Q00cVr1rmV773A@mail.gmail.com>
Message-ID: <loom.20140901T232337-67@post.gmane.org>

Dan McCloy <drmccloy at ...> writes:

> 
> I'm getting the following error, despite the fact that all my fixed
> effects were converted to factors and had their contrast attributes
> set prior to calling glmer.
> 
> Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
>   contrasts can be applied only to factors with 2 or more levels
> Calls: glmer ... model.matrix -> model.matrix.default -> contrasts<-
> 
> Here is the model specification:
> glmer(press ~ truth*adj*idn*num + (1|subj), data=wl,
> family=binomial(link="probit"))
> 
> Here are the predictors. As you can see, they are all already factors
> and have contrasts set, so I can't figure out why glmer is trying to
> set contrasts anyway, much less why it thinks any of these have fewer
> than two levels:
> 
> R> head(wl$truth)
> [1] neither neither neither neither neither neither
> attr(,"contrasts")
>         target foil
> neither      0    0
> target       1    0
> foil         0    1
> Levels: neither target foil
> R> head(wl$adj)
> [1] TRUE TRUE TRUE TRUE TRUE TRUE
> attr(,"contrasts")
>       TRUE
> TRUE     1
> FALSE   -1
> Levels: TRUE FALSE
> R> head(wl$idn)
> [1] FALSE FALSE FALSE FALSE FALSE FALSE
> attr(,"contrasts")
>       TRUE
> TRUE     1
> FALSE   -1
> Levels: TRUE FALSE
> R> head(wl$num)
> [1] six six six six six six
> attr(,"contrasts")
>       three
> three     1
> six      -1
> Levels: three six
> 
> Here is the session info:
> R version 3.1.1 (2014-07-10)
> Platform: x86_64-pc-linux-gnu (64-bit)

[snip]

> other attached packages:
> [1] lme4_1.1-7   Rcpp_0.11.2  Matrix_1.1-4
> 

[snip]

> Can anybody shed some light on what is going on here, and / or how to
> work around it?  I've run similar models with very similar data on
> slightly older versions of lme4 (but still >1.0) and never run into
> this, so I'm wondering if a bug was introduced in the latest version.

Unfortunately it's really hard to say without a reproducible example.
I haven't encountered anything like this before and don't
see anything obviously wrong either (which is about the only
way that it is *ever* possible to debug without a reproducible example ...)
A couple of semi-wild guesses:

* some of your factors despite having >1 level may only have a single
level _represented_
* you may have a pattern of NA values that leads to the reduced (non-NA)
data set having only a single factor level within it.

What are the results of 

fvars <- c("truth","adj","idn","num")
lapply(na.omit(wl)[,fvars], table)?

(the cross-classification would be useful too)
?

It would be great if you could come up with a reproducible example.


From drmccloy at uw.edu  Tue Sep  2 01:11:40 2014
From: drmccloy at uw.edu (Dan McCloy)
Date: Tue, 2 Sep 2014 07:11:40 +0800
Subject: [R-sig-ME] glmer error: contrasts can only be applied to
 factors of 2 or more levels
In-Reply-To: <CAOE0pYn5s7rtPPe52sdYncCRS2VD_vK98_m3Q00cVr1rmV773A@mail.gmail.com>
References: <CAOE0pYn5s7rtPPe52sdYncCRS2VD_vK98_m3Q00cVr1rmV773A@mail.gmail.com>
Message-ID: <CAOE0pYnv2_r=AhmW4CiE=zR2U=qpFwhxBNFwAQt4f3iDXfq7jQ@mail.gmail.com>

Never mind this one.  As usual, I was making a silly mistake due to
the late hour, and Ben Bolker knew just what to suggest to illuminate
my error.  Indeed, I had mis-typed one of the level names in one of
the factors, yielding only one level represented when it got passed to
glmer and run through na.omit().
-- dan

On Mon, Sep 1, 2014 at 5:19 PM, Dan McCloy <drmccloy at uw.edu> wrote:
> I'm getting the following error, despite the fact that all my fixed
> effects were converted to factors and had their contrast attributes
> set prior to calling glmer.
>
> Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
>   contrasts can be applied only to factors with 2 or more levels
> Calls: glmer ... model.matrix -> model.matrix.default -> contrasts<-
>
> Here is the model specification:
> glmer(press ~ truth*adj*idn*num + (1|subj), data=wl,
> family=binomial(link="probit"))
>
> Here are the predictors. As you can see, they are all already factors
> and have contrasts set, so I can't figure out why glmer is trying to
> set contrasts anyway, much less why it thinks any of these have fewer
> than two levels:
>
> R> head(wl$truth)
> [1] neither neither neither neither neither neither
> attr(,"contrasts")
>         target foil
> neither      0    0
> target       1    0
> foil         0    1
> Levels: neither target foil
> R> head(wl$adj)
> [1] TRUE TRUE TRUE TRUE TRUE TRUE
> attr(,"contrasts")
>       TRUE
> TRUE     1
> FALSE   -1
> Levels: TRUE FALSE
> R> head(wl$idn)
> [1] FALSE FALSE FALSE FALSE FALSE FALSE
> attr(,"contrasts")
>       TRUE
> TRUE     1
> FALSE   -1
> Levels: TRUE FALSE
> R> head(wl$num)
> [1] six six six six six six
> attr(,"contrasts")
>       three
> three     1
> six      -1
> Levels: three six
>
> Here is the session info:
> R version 3.1.1 (2014-07-10)
> Platform: x86_64-pc-linux-gnu (64-bit)
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
> LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
> LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] lme4_1.1-7   Rcpp_0.11.2  Matrix_1.1-4
>
> loaded via a namespace (and not attached):
> [1] grid_3.1.1      lattice_0.20-29 MASS_7.3-34     minqa_1.2.3
> nlme_3.1-117    nloptr_1.0.4    splines_3.1.1     tools_3.1.1
>
> Can anybody shed some light on what is going on here, and / or how to
> work around it?  I've run similar models with very similar data on
> slightly older versions of lme4 (but still >1.0) and never run into
> this, so I'm wondering if a bug was introduced in the latest version.
> -- dan
>
> Daniel McCloy
> http://dan.mccloy.info/
> Postdoctoral Research Fellow
> Institute for Learning and Brain Sciences
> University of Washington


From bbolker at gmail.com  Tue Sep  2 01:18:12 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 01 Sep 2014 19:18:12 -0400
Subject: [R-sig-ME] glmer error: contrasts can only be applied to
 factors of 2 or more levels
In-Reply-To: <CAOE0pYnv2_r=AhmW4CiE=zR2U=qpFwhxBNFwAQt4f3iDXfq7jQ@mail.gmail.com>
References: <CAOE0pYn5s7rtPPe52sdYncCRS2VD_vK98_m3Q00cVr1rmV773A@mail.gmail.com>
	<CAOE0pYnv2_r=AhmW4CiE=zR2U=qpFwhxBNFwAQt4f3iDXfq7jQ@mail.gmail.com>
Message-ID: <5404FEB4.8020807@gmail.com>

On 14-09-01 07:11 PM, Dan McCloy wrote:
> Never mind this one.  As usual, I was making a silly mistake due to
> the late hour, and Ben Bolker knew just what to suggest to illuminate
> my error.  Indeed, I had mis-typed one of the level names in one of
> the factors, yielding only one level represented when it got passed to
> glmer and run through na.omit().
> -- dan

   It might be creepying nannyism (this term has unfortunate political
associations, but I don't know of a better term to indicate the drive to
incorporate more and more checks to make sure that users aren't doing
something silly ... "creeping featurism" is a standard software term,
but I want a term that is more specific to user input screening), but
... it might be feasible to add a tryCatch loop around this invocation
of model.matrix that would indicate *which* factor had only a single
level, which might be helpful for debugging purposes ... or we could add
this error to
https://github.com/lme4/lme4/blob/24772d2a31c10a7fd6f77f6110fca8786573a9aa/man/troubleshooting.Rd
...

> 
> On Mon, Sep 1, 2014 at 5:19 PM, Dan McCloy <drmccloy at uw.edu> wrote:
>> I'm getting the following error, despite the fact that all my fixed
>> effects were converted to factors and had their contrast attributes
>> set prior to calling glmer.
>>
>> Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
>>   contrasts can be applied only to factors with 2 or more levels
>> Calls: glmer ... model.matrix -> model.matrix.default -> contrasts<-
>>
>> Here is the model specification:
>> glmer(press ~ truth*adj*idn*num + (1|subj), data=wl,
>> family=binomial(link="probit"))
>>
>> Here are the predictors. As you can see, they are all already factors
>> and have contrasts set, so I can't figure out why glmer is trying to
>> set contrasts anyway, much less why it thinks any of these have fewer
>> than two levels:
>>
>> R> head(wl$truth)
>> [1] neither neither neither neither neither neither
>> attr(,"contrasts")
>>         target foil
>> neither      0    0
>> target       1    0
>> foil         0    1
>> Levels: neither target foil
>> R> head(wl$adj)
>> [1] TRUE TRUE TRUE TRUE TRUE TRUE
>> attr(,"contrasts")
>>       TRUE
>> TRUE     1
>> FALSE   -1
>> Levels: TRUE FALSE
>> R> head(wl$idn)
>> [1] FALSE FALSE FALSE FALSE FALSE FALSE
>> attr(,"contrasts")
>>       TRUE
>> TRUE     1
>> FALSE   -1
>> Levels: TRUE FALSE
>> R> head(wl$num)
>> [1] six six six six six six
>> attr(,"contrasts")
>>       three
>> three     1
>> six      -1
>> Levels: three six
>>
>> Here is the session info:
>> R version 3.1.1 (2014-07-10)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>>
>> locale:
>>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>> LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>> LC_PAPER=en_US.UTF-8       LC_NAME=C
>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] lme4_1.1-7   Rcpp_0.11.2  Matrix_1.1-4
>>
>> loaded via a namespace (and not attached):
>> [1] grid_3.1.1      lattice_0.20-29 MASS_7.3-34     minqa_1.2.3
>> nlme_3.1-117    nloptr_1.0.4    splines_3.1.1     tools_3.1.1
>>
>> Can anybody shed some light on what is going on here, and / or how to
>> work around it?  I've run similar models with very similar data on
>> slightly older versions of lme4 (but still >1.0) and never run into
>> this, so I'm wondering if a bug was introduced in the latest version.
>> -- dan
>>
>> Daniel McCloy
>> http://dan.mccloy.info/
>> Postdoctoral Research Fellow
>> Institute for Learning and Brain Sciences
>> University of Washington
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From s.smith.7 at research.gla.ac.uk  Tue Sep  2 18:36:31 2014
From: s.smith.7 at research.gla.ac.uk (Shona Smith)
Date: Tue, 2 Sep 2014 17:36:31 +0100
Subject: [R-sig-ME] Post model fitting checks in Metafor (rma.mv)
Message-ID: <A1BEFC2CBCCA0D41B8E5D8BEC98C0C0871B0690D63@CMS04.campus.gla.ac.uk>

Hi all,

I am currently conducting a meta-analysis using rma.mv in metafor.  My model uses Hedges? d (converted to g) and includes 3 moderators (age-3 levels; treatment-5 levels; biomarker-3 levels).  I have included 3 random effects: species nested within taxonomic class (since I have more than one study for some species, and species are spread over 7 taxonomic classes) and study separately.  So my code is as follows:

rma.mv(yi, vi, mods = ~ Age + Treatment + Biomarker, random = list(~ 1 | Study, ~ Species | Taxonomic.class), data=mydata)

I was wondering what the best method for post model fitting checks was in rma.mv?  I know in the reference manual it mentions profile.rma to create a plot of the restricted log likelihood and I have done so.  However, I wondered if I need to plot all 3 variables (sigma2, tau2 and rho) and also how I know which value to specify for each?  Am I correct in that I should see a clear peak in each graph?  Is there anything else I should be looking for?

For post model fitting checks should I also look at residual normality and residual against fitted values, as would be done for a typical mixed model?  I think the standardised residuals are best for this ? I can get them with rstandard.rma.mv, but it does not allow me to plot them. 

Finally, when I include the intercept in the model, I can see if there are significant differences among moderator levels.  However, I was wondering what the output includes when the intercept is not included: is this the overall effect size estimates for each moderator level?

Kind regards,
Shona


Shona Smith
PhD Student

Room 321
Institute of Biodiversity, Animal Health and Comparative Medicine
Graham Kerr Building
University of Glasgow
Glasgow G12 8QQ

From Andreas.Meid at med.uni-heidelberg.de  Tue Sep  2 14:47:13 2014
From: Andreas.Meid at med.uni-heidelberg.de (Meid, Andreas)
Date: Tue, 2 Sep 2014 12:47:13 +0000
Subject: [R-sig-ME] WG: lme4: prediction for glmer model
In-Reply-To: <5405B96F.40709@gmail.com>
References: <E6E104DDF549DB429B330D529CDACA1F60CBF514@EXC16.ads.krz.uni-heidelberg.de>
	<5405B96F.40709@gmail.com>
Message-ID: <E6E104DDF549DB429B330D529CDACA1F60CBF553@EXC16.ads.krz.uni-heidelberg.de>

Dear lme4-group members,

I'm trying to make prediction plots for visualizing effects according to http://www.ats.ucla.edu/stat/r/dae/melogit.htm. I'm worried about strange prediction plots after adapting the example code to my glmer model. More precisely, I obtain differing lines for predictions and their quartiles. I wonder if something basic is wrong. 
Is there a solution to obtain CI for predictions? Maybe the simulate function of the lme4 package is right? Or do I have to apply bootstrap function? In any case, I wonder how this is to be accomplished. I attached my files so that you can take a look at them. Hopefully, you can help.

Many thanks and best wishes,

Andreas


-----Urspr?ngliche Nachricht-----
Von: Ben Bolker [mailto:bbolker at gmail.com] 
Gesendet: Dienstag, 2. September 2014 14:35
An: Meid, Andreas
Cc: lme4-authors at lists.r-forge.r-project.org
Betreff: Re: lme4: prediction for glmer model

  Can you please send this to r-sig-mixed-models at r-project.org ?  (Be aware that your .RData files probably won't make it through to the list.)

  thanks
    Ben Bolker


On 14-09-02 06:06 AM, Meid, Andreas wrote:
> Dear Ben,
> 
>  
> 
> your recently helped me with another issue about my glmer model. This 
> time I'm trying to make prediction plots for visualizing effects 
> according to http://www.ats.ucla.edu/stat/r/dae/melogit.htm. I'm 
> worried about strange prediction plots after adapting the example code 
> to my glmer model. More precisely, I obtain differing lines for 
> predictions and their quartiles. I wonder if something basic is wrong.
> 
> Is there a solution to obtain CI for predictions? Maybe the simulate 
> function of the lme4 package is right? Or do I have to apply bootstrap 
> function? In any case, I wonder how this is to be accomplished. I 
> attached my files so that you can take a look at them. Hopefully, you 
> can help.
> 
>  
> 
> Many thanks and best wishes,
> 
>  
> 
> Andreas
> 
>  
> 
> 
> *Andreas Meid*
> Heidelberg University Hospital
> Dept. of Clinical Pharmacology & Pharmacoepidemiology Im Neuenheimer 
> Feld 410
> 69120 Heidelberg
> Germany
> Phone: +49(0)6221 / 56-37113, Fax: +49(0)6221 / 56-4642
> Homepage: http://www.klinikum.uni-heidelberg.de/clinpharm
> Expert system: Drug dosing in renal failurehttp://www.dosing.de 
> <http://www.dosing.de>
> 
>  
> 


From ukoether at uke.de  Tue Sep  2 20:36:11 2014
From: ukoether at uke.de (=?UTF-8?B?VWxmIEvDtnRoZXI=?=)
Date: Tue, 2 Sep 2014 20:36:11 +0200
Subject: [R-sig-ME] zeroinflated poisson GLM(M) in JAGS
Message-ID: <54060E1B.2070802@uke.de>

Dear list members,

although this question does not directly aim at a mixed effects model, I
am posting the link to my question on stackoverflow here in the hope
that someone has the time to look at it and any clue about what I am
doing wrong. Since I want to extend the model to a GLMM as soon as I can
overcome this annoying hurdle, I hope that this question is still in
some way appropriate for this list. If not, please ignore this mail!

I am really stuck with a problem regarding zero-inflated GLMs in JAGS,
and no one answered my question on stackoverflow.com yet:

http://stackoverflow.com/questions/25410676/how-to-obtain-new-samples-from-zip-or-zinb-model-for-bayesian-p-value

Thank you very much!

-- 
________________________________________

Dipl.-Psych. Ulf K?ther

PEPP-Team 
Klinik f?r Psychiatrie und Psychotherapie
Universit?tsklinikum Hamburg-Eppendorf
Martinistr. 52
20246 Hamburg

PEPP-Team:
Tel.: +49 (0) 40 7410 53248
pepp at uke.de

Pers?nlich:
Tel.: +49 (0) 40 7410 55851
Mobil: (9) 55851
ukoether at uke.de
________________________________________

--

DANKE F?R 125 JAHRE ENGAGEMENT UND VERTRAUEN.
www.uke.de/125
_____________________________________________________________________

Besuchen Sie uns auf: www.uke.de
_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg
Vorstandsmitglieder: Prof. Dr. Christian Gerloff (Vertreter des Vorsitzenden), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Rainer Schoppik
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

From wolfgang.viechtbauer at maastrichtuniversity.nl  Wed Sep  3 11:28:04 2014
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Wed, 3 Sep 2014 11:28:04 +0200
Subject: [R-sig-ME] Post model fitting checks in Metafor (rma.mv)
In-Reply-To: <A1BEFC2CBCCA0D41B8E5D8BEC98C0C0871B0690D63@CMS04.campus.gla.ac.uk>
References: <A1BEFC2CBCCA0D41B8E5D8BEC98C0C0871B0690D63@CMS04.campus.gla.ac.uk>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730DCA27C088@UM-MAIL4112.unimaas.nl>

Dear Shona,

The profile() function in metafor allows you to examine the profiled (restricted) log-likelihood for a particular parameter. So, ideally, you should do this for each variance component and correlation in the model (in your case, sigma2, tau2 and rho). I am not sure what you mean by: " how I know which value to specify for each?" After you have fitted your model and stored the results in, let's say, 'res', then just do:

par(mfrow=c(3,1))
profile(res, sigma2=1)
profile(res, tau2=1)
profile(res, rho=1)

to get all three profile plots. And yes, the functions should peak at the parameter estimates. If a function is flat, then this suggests that the model is overparameterized.

You could also look at how quickly the log-likelihood drops off as you move away from the parameter estimate. The bounds of a 95% profile likelihood CI for a particular parameter would be those two values from the x-axis where the log-likelihood has dropped by 3.84/2. You could add 

abline(h = logLik(res) - qchisq(.95, df=1)/2, lty="dotted")

to the figures to see that cutoff. Depending on how much data you have, you may find that those CIs are quite wide. You may have to increase the x-axis range, in case the cutoff isn't reached within the range chosen by default by the profile function (use the 'xlim' argument).

Indeed, you could also look at the (standardized) residuals. Use

rstandard(res)$z

to get those values. Or:

plot(fitted(res), rstandard(res)$z, pch=19)

to create a fitted values versus standardized residuals plot.

As for the interpretation of the results when you exclude the intercept (i.e., mods = ~ Age + Treatment + Biomarker - 1), you will get the estimated (average) effect for each level of 'Age', but the coefficients for 'Treatment' and 'Biomarker' are still going to be contrasts that indicate how much higher/lower the (average) effect is for the levels indicated, relative to the reference level.

I hope this helps!

Best,
Wolfgang

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-
> models-bounces at r-project.org] On Behalf Of Shona Smith
> Sent: Tuesday, September 02, 2014 18:37
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Post model fitting checks in Metafor (rma.mv)
> 
> Hi all,
> 
> I am currently conducting a meta-analysis using rma.mv in metafor.  My
> model uses Hedges' d (converted to g) and includes 3 moderators (age-3
> levels; treatment-5 levels; biomarker-3 levels).  I have included 3
> random effects: species nested within taxonomic class (since I have more
> than one study for some species, and species are spread over 7 taxonomic
> classes) and study separately.  So my code is as follows:
> 
> rma.mv(yi, vi, mods = ~ Age + Treatment + Biomarker, random = list(~ 1 |
> Study, ~ Species | Taxonomic.class), data=mydata)
> 
> I was wondering what the best method for post model fitting checks was in
> rma.mv?  I know in the reference manual it mentions profile.rma to create
> a plot of the restricted log likelihood and I have done so.  However, I
> wondered if I need to plot all 3 variables (sigma2, tau2 and rho) and
> also how I know which value to specify for each?  Am I correct in that I
> should see a clear peak in each graph?  Is there anything else I should
> be looking for?
> 
> For post model fitting checks should I also look at residual normality
> and residual against fitted values, as would be done for a typical mixed
> model?  I think the standardised residuals are best for this - I can get
> them with rstandard.rma.mv, but it does not allow me to plot them.
> 
> Finally, when I include the intercept in the model, I can see if there
> are significant differences among moderator levels.  However, I was
> wondering what the output includes when the intercept is not included: is
> this the overall effect size estimates for each moderator level?
> 
> Kind regards,
> Shona
> 
> 
> Shona Smith
> PhD Student
> 
> Room 321
> Institute of Biodiversity, Animal Health and Comparative Medicine
> Graham Kerr Building
> University of Glasgow
> Glasgow G12 8QQ
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From wolfgang.viechtbauer at maastrichtuniversity.nl  Wed Sep  3 15:32:13 2014
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Wed, 3 Sep 2014 15:32:13 +0200
Subject: [R-sig-ME] Post model fitting checks in Metafor (rma.mv)
In-Reply-To: <A1BEFC2CBCCA0D41B8E5D8BEC98C0C0871B0690D66@CMS04.campus.gla.ac.uk>
References: <A1BEFC2CBCCA0D41B8E5D8BEC98C0C0871B0690D63@CMS04.campus.gla.ac.uk>,
	<077E31A57DA26E46AB0D493C9966AC730DCA27C088@UM-MAIL4112.unimaas.nl>
	<A1BEFC2CBCCA0D41B8E5D8BEC98C0C0871B0690D66@CMS04.campus.gla.ac.uk>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730DCA27C1C9@UM-MAIL4112.unimaas.nl>

Regarding the profile plot for sigma2: I am not quite sure I understand. Does it 'peak' at zero? So, is the estimate (essentially) zero then? That would be okay (essentially means that the variability due to 'Study' is no larger than what would be expected due to the other variance components and/or sampling variability). The issue of zero variance components was also recently (and also in past) discussed on this list (not with respect to meta-analysis, but it's the same issue).

Regarding the resid-fitted plot: So, looks like you have some missings, so the two vectors end up being of different length. This should do it:

options(na.action = "na.pass")
plot(fitted(res), rstandard(res)$z, pch=19)

Also explained here: http://www.metafor-project.org/doku.php/tips:handling_missing_data

Regarding overall effects: I personally don't think an 'overall' effect makes much sense when the effect size appears to be related to a number of moderators/covariates. Take the simplest situation, where the true effect is of size theta_1 for level 1 of a dichotomous covariate and theta_2 for level 2. Now suppose we ignore that covariate and fit a random-effects model. Essentially, that is a misfitted model, because the model assumes normally distributed true effects (and not two point massess). Also, where the 'average' effect then falls depends on how many studies in the sample are at level 1 and at level 2 of that covariate. That doesn't seem that sensible to me. So, instead, we can fit the model with the covariate and then compute predicted values, for example, for level 1 or level 2. Or, if you really want an 'overall' effect, we could use a sort of 'lsmeans' approach and say: Let's assume that in the population of studies, 50% are at level 1 and 50% at level 2, so let's compute the predicted effect for such a population (essentially fill in 0.5 for the 'dummy' variable when computing the predicted value). But I would then describe explicitly that this is what was done (as it makes clear what the assumption is about the population of studies).

I discuss this issue a bit in this article:

Viechtbauer, W. (2007). Accounting for heterogeneity via random-effects models and moderator analyses in meta-analysis. Zeitschrift f?r Psychologie / Journal of Psychology, 215(2), 104-121.

(not the 'lsmeans' idea, but the problem of fitting random-effects models when there is a relevant moderators/covariate). If you can't access the article, let me know and I'll send you a copy if you are interested.

Best,
Wolfgang

> -----Original Message-----
> From: Shona Smith [mailto:s.smith.7 at research.gla.ac.uk]
> Sent: Wednesday, September 03, 2014 13:39
> To: Viechtbauer Wolfgang (STAT); r-sig-mixed-models at r-project.org
> Subject: RE: Post model fitting checks in Metafor (rma.mv)
> 
> Hi Wolfgang,
> 
> Thanks for such a useful and quick reply.  The sigma2 profile plot does
> not have a peak - but it's not flat, it seems to just decline (even when
> I expand the x axis values) - I wondered what this meant?  The other two
> look fine, although tau2 drops off much more gradually than rho (which is
> quite a steep drop) after the parameter estimate.  What would be the
> ideal plot?
> 
> I can now plot the standardised residuals but fitted against residuals
> gives me an error:
> 
> plot(fitted(res), rstandard(res)$z, pch=19)
> Error in xy.coords(x, y, xlabel, ylabel, log) :
>   'x' and 'y' lengths differ
> 
> The fitted values seem to have the row number alongside each value,
> whiles the standardised residuals don't - so perhaps this is the problem?
> 
> Finally, I also wondered if it is possible to get an overall effect size
> estimate for my response variable?  I notice other studies have carried
> out a separate meta-analysis to obtain this, before looking at
> moderators, but I wasn't sure if this was correct.
> 
> Thanks again,
> Shona
> 
> 
> Shona Smith
> PhD Researcher
> 
> Room 321
> Institute of Biodiversity, Animal Health and Comparative Medicine
> Graham Kerr Building
> University of Glasgow
> Glasgow G12 8QQ
> ________________________________________
> From: Viechtbauer Wolfgang (STAT)
> [wolfgang.viechtbauer at maastrichtuniversity.nl]
> Sent: 03 September 2014 10:28
> To: Shona Smith; r-sig-mixed-models at r-project.org
> Subject: RE: Post model fitting checks in Metafor (rma.mv)
> 
> Dear Shona,
> 
> The profile() function in metafor allows you to examine the profiled
> (restricted) log-likelihood for a particular parameter. So, ideally, you
> should do this for each variance component and correlation in the model
> (in your case, sigma2, tau2 and rho). I am not sure what you mean by: "
> how I know which value to specify for each?" After you have fitted your
> model and stored the results in, let's say, 'res', then just do:
> 
> par(mfrow=c(3,1))
> profile(res, sigma2=1)
> profile(res, tau2=1)
> profile(res, rho=1)
> 
> to get all three profile plots. And yes, the functions should peak at the
> parameter estimates. If a function is flat, then this suggests that the
> model is overparameterized.
> 
> You could also look at how quickly the log-likelihood drops off as you
> move away from the parameter estimate. The bounds of a 95% profile
> likelihood CI for a particular parameter would be those two values from
> the x-axis where the log-likelihood has dropped by 3.84/2. You could add
> 
> abline(h = logLik(res) - qchisq(.95, df=1)/2, lty="dotted")
> 
> to the figures to see that cutoff. Depending on how much data you have,
> you may find that those CIs are quite wide. You may have to increase the
> x-axis range, in case the cutoff isn't reached within the range chosen by
> default by the profile function (use the 'xlim' argument).
> 
> Indeed, you could also look at the (standardized) residuals. Use
> 
> rstandard(res)$z
> 
> to get those values. Or:
> 
> plot(fitted(res), rstandard(res)$z, pch=19)
> 
> to create a fitted values versus standardized residuals plot.
> 
> As for the interpretation of the results when you exclude the intercept
> (i.e., mods = ~ Age + Treatment + Biomarker - 1), you will get the
> estimated (average) effect for each level of 'Age', but the coefficients
> for 'Treatment' and 'Biomarker' are still going to be contrasts that
> indicate how much higher/lower the (average) effect is for the levels
> indicated, relative to the reference level.
> 
> I hope this helps!
> 
> Best,
> Wolfgang
> 
> > -----Original Message-----
> > From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-
> > models-bounces at r-project.org] On Behalf Of Shona Smith
> > Sent: Tuesday, September 02, 2014 18:37
> > To: r-sig-mixed-models at r-project.org
> > Subject: [R-sig-ME] Post model fitting checks in Metafor (rma.mv)
> >
> > Hi all,
> >
> > I am currently conducting a meta-analysis using rma.mv in metafor.  My
> > model uses Hedges' d (converted to g) and includes 3 moderators (age-3
> > levels; treatment-5 levels; biomarker-3 levels).  I have included 3
> > random effects: species nested within taxonomic class (since I have
> more
> > than one study for some species, and species are spread over 7
> taxonomic
> > classes) and study separately.  So my code is as follows:
> >
> > rma.mv(yi, vi, mods = ~ Age + Treatment + Biomarker, random = list(~ 1
> |
> > Study, ~ Species | Taxonomic.class), data=mydata)
> >
> > I was wondering what the best method for post model fitting checks was
> in
> > rma.mv?  I know in the reference manual it mentions profile.rma to
> create
> > a plot of the restricted log likelihood and I have done so.  However, I
> > wondered if I need to plot all 3 variables (sigma2, tau2 and rho) and
> > also how I know which value to specify for each?  Am I correct in that
> I
> > should see a clear peak in each graph?  Is there anything else I should
> > be looking for?
> >
> > For post model fitting checks should I also look at residual normality
> > and residual against fitted values, as would be done for a typical
> mixed
> > model?  I think the standardised residuals are best for this - I can
> get
> > them with rstandard.rma.mv, but it does not allow me to plot them.
> >
> > Finally, when I include the intercept in the model, I can see if there
> > are significant differences among moderator levels.  However, I was
> > wondering what the output includes when the intercept is not included:
> is
> > this the overall effect size estimates for each moderator level?
> >
> > Kind regards,
> > Shona
> >
> >
> > Shona Smith
> > PhD Student
> >
> > Room 321
> > Institute of Biodiversity, Animal Health and Comparative Medicine
> > Graham Kerr Building
> > University of Glasgow
> > Glasgow G12 8QQ
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From s.smith.7 at research.gla.ac.uk  Wed Sep  3 13:38:46 2014
From: s.smith.7 at research.gla.ac.uk (Shona Smith)
Date: Wed, 3 Sep 2014 12:38:46 +0100
Subject: [R-sig-ME] Post model fitting checks in Metafor (rma.mv)
In-Reply-To: <077E31A57DA26E46AB0D493C9966AC730DCA27C088@UM-MAIL4112.unimaas.nl>
References: <A1BEFC2CBCCA0D41B8E5D8BEC98C0C0871B0690D63@CMS04.campus.gla.ac.uk>,
	<077E31A57DA26E46AB0D493C9966AC730DCA27C088@UM-MAIL4112.unimaas.nl>
Message-ID: <A1BEFC2CBCCA0D41B8E5D8BEC98C0C0871B0690D66@CMS04.campus.gla.ac.uk>

Hi Wolfgang,

Thanks for such a useful and quick reply.  The sigma2 profile plot does not have a peak - but it?s not flat, it seems to just decline (even when I expand the x axis values) ? I wondered what this meant?  The other two look fine, although tau2 drops off much more gradually than rho (which is quite a steep drop) after the parameter estimate.  What would be the ideal plot?

I can now plot the standardised residuals but fitted against residuals gives me an error:

plot(fitted(res), rstandard(res)$z, pch=19)
Error in xy.coords(x, y, xlabel, ylabel, log) : 
  'x' and 'y' lengths differ

The fitted values seem to have the row number alongside each value, whiles the standardised residuals don?t ? so perhaps this is the problem?

Finally, I also wondered if it is possible to get an overall effect size estimate for my response variable?  I notice other studies have carried out a separate meta-analysis to obtain this, before looking at moderators, but I wasn?t sure if this was correct.

Thanks again,
Shona


Shona Smith
PhD Researcher

Room 321
Institute of Biodiversity, Animal Health and Comparative Medicine
Graham Kerr Building
University of Glasgow
Glasgow G12 8QQ
________________________________________
From: Viechtbauer Wolfgang (STAT) [wolfgang.viechtbauer at maastrichtuniversity.nl]
Sent: 03 September 2014 10:28
To: Shona Smith; r-sig-mixed-models at r-project.org
Subject: RE: Post model fitting checks in Metafor (rma.mv)

Dear Shona,

The profile() function in metafor allows you to examine the profiled (restricted) log-likelihood for a particular parameter. So, ideally, you should do this for each variance component and correlation in the model (in your case, sigma2, tau2 and rho). I am not sure what you mean by: " how I know which value to specify for each?" After you have fitted your model and stored the results in, let's say, 'res', then just do:

par(mfrow=c(3,1))
profile(res, sigma2=1)
profile(res, tau2=1)
profile(res, rho=1)

to get all three profile plots. And yes, the functions should peak at the parameter estimates. If a function is flat, then this suggests that the model is overparameterized.

You could also look at how quickly the log-likelihood drops off as you move away from the parameter estimate. The bounds of a 95% profile likelihood CI for a particular parameter would be those two values from the x-axis where the log-likelihood has dropped by 3.84/2. You could add

abline(h = logLik(res) - qchisq(.95, df=1)/2, lty="dotted")

to the figures to see that cutoff. Depending on how much data you have, you may find that those CIs are quite wide. You may have to increase the x-axis range, in case the cutoff isn't reached within the range chosen by default by the profile function (use the 'xlim' argument).

Indeed, you could also look at the (standardized) residuals. Use

rstandard(res)$z

to get those values. Or:

plot(fitted(res), rstandard(res)$z, pch=19)

to create a fitted values versus standardized residuals plot.

As for the interpretation of the results when you exclude the intercept (i.e., mods = ~ Age + Treatment + Biomarker - 1), you will get the estimated (average) effect for each level of 'Age', but the coefficients for 'Treatment' and 'Biomarker' are still going to be contrasts that indicate how much higher/lower the (average) effect is for the levels indicated, relative to the reference level.

I hope this helps!

Best,
Wolfgang

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-
> models-bounces at r-project.org] On Behalf Of Shona Smith
> Sent: Tuesday, September 02, 2014 18:37
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Post model fitting checks in Metafor (rma.mv)
>
> Hi all,
>
> I am currently conducting a meta-analysis using rma.mv in metafor.  My
> model uses Hedges' d (converted to g) and includes 3 moderators (age-3
> levels; treatment-5 levels; biomarker-3 levels).  I have included 3
> random effects: species nested within taxonomic class (since I have more
> than one study for some species, and species are spread over 7 taxonomic
> classes) and study separately.  So my code is as follows:
>
> rma.mv(yi, vi, mods = ~ Age + Treatment + Biomarker, random = list(~ 1 |
> Study, ~ Species | Taxonomic.class), data=mydata)
>
> I was wondering what the best method for post model fitting checks was in
> rma.mv?  I know in the reference manual it mentions profile.rma to create
> a plot of the restricted log likelihood and I have done so.  However, I
> wondered if I need to plot all 3 variables (sigma2, tau2 and rho) and
> also how I know which value to specify for each?  Am I correct in that I
> should see a clear peak in each graph?  Is there anything else I should
> be looking for?
>
> For post model fitting checks should I also look at residual normality
> and residual against fitted values, as would be done for a typical mixed
> model?  I think the standardised residuals are best for this - I can get
> them with rstandard.rma.mv, but it does not allow me to plot them.
>
> Finally, when I include the intercept in the model, I can see if there
> are significant differences among moderator levels.  However, I was
> wondering what the output includes when the intercept is not included: is
> this the overall effect size estimates for each moderator level?
>
> Kind regards,
> Shona
>
>
> Shona Smith
> PhD Student
>
> Room 321
> Institute of Biodiversity, Animal Health and Comparative Medicine
> Graham Kerr Building
> University of Glasgow
> Glasgow G12 8QQ
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From s.smith.7 at research.gla.ac.uk  Wed Sep  3 19:24:14 2014
From: s.smith.7 at research.gla.ac.uk (Shona Smith)
Date: Wed, 3 Sep 2014 18:24:14 +0100
Subject: [R-sig-ME] Post model fitting checks in Metafor (rma.mv)
In-Reply-To: <077E31A57DA26E46AB0D493C9966AC730DCA27C1C9@UM-MAIL4112.unimaas.nl>
References: <A1BEFC2CBCCA0D41B8E5D8BEC98C0C0871B0690D63@CMS04.campus.gla.ac.uk>,
	<077E31A57DA26E46AB0D493C9966AC730DCA27C088@UM-MAIL4112.unimaas.nl>
	<A1BEFC2CBCCA0D41B8E5D8BEC98C0C0871B0690D66@CMS04.campus.gla.ac.uk>,
	<077E31A57DA26E46AB0D493C9966AC730DCA27C1C9@UM-MAIL4112.unimaas.nl>
Message-ID: <A1BEFC2CBCCA0D41B8E5D8BEC98C0C0871B0690D67@CMS04.campus.gla.ac.uk>

Hi Wolfgang,

This definitely makes sense thanks ? to look at an ?overall effect? without the moderators sort of defeats the purpose of putting them there in the first place.  I was able to download your paper so I can have a wee look at that too, thanks.  I think I shall stick with extracting predicted values for specific levels of moderators.  I tried the predict function and realise I need to code the factor levels myself, but am a little confused about how to do so.  To see how the factors were coded in the model, I used: 

predict(res, addx=TRUE)

Then I know I can use ?newmods? to put in the codes for the factor levels I would like a predicted value for.  There were a lot of ?1?s and ?0?s (one for each observation and level of factor) so how can I use this to code my factor levels?

As for the profile plot for sigma2, I suppose it peaks at ~0.05 but it is just a straight line, declining from an REML value of ~ -71 (at Sigma2 = ~0.05) to an REML value of ~ -72.5 (at Sigma2 = 1).  

Of course missing values were the problem with the residual against fitted plot, it was silly of me to miss this.  Thanks!

Kind regards,
Shona


Shona Smith
PhD Researcher

Room 321
Institute of Biodiversity, Animal Health and Comparative Medicine
Graham Kerr Building
University of Glasgow
Glasgow G12 8QQ
________________________________________
From: Viechtbauer Wolfgang (STAT) [wolfgang.viechtbauer at maastrichtuniversity.nl]
Sent: 03 September 2014 14:32
To: Shona Smith; r-sig-mixed-models at r-project.org
Subject: RE: Post model fitting checks in Metafor (rma.mv)

Regarding the profile plot for sigma2: I am not quite sure I understand. Does it 'peak' at zero? So, is the estimate (essentially) zero then? That would be okay (essentially means that the variability due to 'Study' is no larger than what would be expected due to the other variance components and/or sampling variability). The issue of zero variance components was also recently (and also in past) discussed on this list (not with respect to meta-analysis, but it's the same issue).

Regarding the resid-fitted plot: So, looks like you have some missings, so the two vectors end up being of different length. This should do it:

options(na.action = "na.pass")
plot(fitted(res), rstandard(res)$z, pch=19)

Also explained here: http://www.metafor-project.org/doku.php/tips:handling_missing_data

Regarding overall effects: I personally don't think an 'overall' effect makes much sense when the effect size appears to be related to a number of moderators/covariates. Take the simplest situation, where the true effect is of size theta_1 for level 1 of a dichotomous covariate and theta_2 for level 2. Now suppose we ignore that covariate and fit a random-effects model. Essentially, that is a misfitted model, because the model assumes normally distributed true effects (and not two point massess). Also, where the 'average' effect then falls depends on how many studies in the sample are at level 1 and at level 2 of that covariate. That doesn't seem that sensible to me. So, instead, we can fit the model with the covariate and then compute predicted values, for example, for level 1 or level 2. Or, if you really want an 'overall' effect, we could use a sort of 'lsmeans' approach and say: Let's assume that in the population of studies, 50% are at level 1 and 50% at level 2, so let's compute the predicted effect for such a population (essentially fill in 0.5 for the 'dummy' variable when computing the predicted value). But I would then describe explicitly that this is what was done (as it makes clear what the assumption is about the population of studies).

I discuss this issue a bit in this article:

Viechtbauer, W. (2007). Accounting for heterogeneity via random-effects models and moderator analyses in meta-analysis. Zeitschrift f?r Psychologie / Journal of Psychology, 215(2), 104-121.

(not the 'lsmeans' idea, but the problem of fitting random-effects models when there is a relevant moderators/covariate). If you can't access the article, let me know and I'll send you a copy if you are interested.

Best,
Wolfgang

> -----Original Message-----
> From: Shona Smith [mailto:s.smith.7 at research.gla.ac.uk]
> Sent: Wednesday, September 03, 2014 13:39
> To: Viechtbauer Wolfgang (STAT); r-sig-mixed-models at r-project.org
> Subject: RE: Post model fitting checks in Metafor (rma.mv)
>
> Hi Wolfgang,
>
> Thanks for such a useful and quick reply.  The sigma2 profile plot does
> not have a peak - but it's not flat, it seems to just decline (even when
> I expand the x axis values) - I wondered what this meant?  The other two
> look fine, although tau2 drops off much more gradually than rho (which is
> quite a steep drop) after the parameter estimate.  What would be the
> ideal plot?
>
> I can now plot the standardised residuals but fitted against residuals
> gives me an error:
>
> plot(fitted(res), rstandard(res)$z, pch=19)
> Error in xy.coords(x, y, xlabel, ylabel, log) :
>   'x' and 'y' lengths differ
>
> The fitted values seem to have the row number alongside each value,
> whiles the standardised residuals don't - so perhaps this is the problem?
>
> Finally, I also wondered if it is possible to get an overall effect size
> estimate for my response variable?  I notice other studies have carried
> out a separate meta-analysis to obtain this, before looking at
> moderators, but I wasn't sure if this was correct.
>
> Thanks again,
> Shona
>
>
> Shona Smith
> PhD Researcher
>
> Room 321
> Institute of Biodiversity, Animal Health and Comparative Medicine
> Graham Kerr Building
> University of Glasgow
> Glasgow G12 8QQ
> ________________________________________
> From: Viechtbauer Wolfgang (STAT)
> [wolfgang.viechtbauer at maastrichtuniversity.nl]
> Sent: 03 September 2014 10:28
> To: Shona Smith; r-sig-mixed-models at r-project.org
> Subject: RE: Post model fitting checks in Metafor (rma.mv)
>
> Dear Shona,
>
> The profile() function in metafor allows you to examine the profiled
> (restricted) log-likelihood for a particular parameter. So, ideally, you
> should do this for each variance component and correlation in the model
> (in your case, sigma2, tau2 and rho). I am not sure what you mean by: "
> how I know which value to specify for each?" After you have fitted your
> model and stored the results in, let's say, 'res', then just do:
>
> par(mfrow=c(3,1))
> profile(res, sigma2=1)
> profile(res, tau2=1)
> profile(res, rho=1)
>
> to get all three profile plots. And yes, the functions should peak at the
> parameter estimates. If a function is flat, then this suggests that the
> model is overparameterized.
>
> You could also look at how quickly the log-likelihood drops off as you
> move away from the parameter estimate. The bounds of a 95% profile
> likelihood CI for a particular parameter would be those two values from
> the x-axis where the log-likelihood has dropped by 3.84/2. You could add
>
> abline(h = logLik(res) - qchisq(.95, df=1)/2, lty="dotted")
>
> to the figures to see that cutoff. Depending on how much data you have,
> you may find that those CIs are quite wide. You may have to increase the
> x-axis range, in case the cutoff isn't reached within the range chosen by
> default by the profile function (use the 'xlim' argument).
>
> Indeed, you could also look at the (standardized) residuals. Use
>
> rstandard(res)$z
>
> to get those values. Or:
>
> plot(fitted(res), rstandard(res)$z, pch=19)
>
> to create a fitted values versus standardized residuals plot.
>
> As for the interpretation of the results when you exclude the intercept
> (i.e., mods = ~ Age + Treatment + Biomarker - 1), you will get the
> estimated (average) effect for each level of 'Age', but the coefficients
> for 'Treatment' and 'Biomarker' are still going to be contrasts that
> indicate how much higher/lower the (average) effect is for the levels
> indicated, relative to the reference level.
>
> I hope this helps!
>
> Best,
> Wolfgang
>
> > -----Original Message-----
> > From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-
> > models-bounces at r-project.org] On Behalf Of Shona Smith
> > Sent: Tuesday, September 02, 2014 18:37
> > To: r-sig-mixed-models at r-project.org
> > Subject: [R-sig-ME] Post model fitting checks in Metafor (rma.mv)
> >
> > Hi all,
> >
> > I am currently conducting a meta-analysis using rma.mv in metafor.  My
> > model uses Hedges' d (converted to g) and includes 3 moderators (age-3
> > levels; treatment-5 levels; biomarker-3 levels).  I have included 3
> > random effects: species nested within taxonomic class (since I have
> more
> > than one study for some species, and species are spread over 7
> taxonomic
> > classes) and study separately.  So my code is as follows:
> >
> > rma.mv(yi, vi, mods = ~ Age + Treatment + Biomarker, random = list(~ 1
> |
> > Study, ~ Species | Taxonomic.class), data=mydata)
> >
> > I was wondering what the best method for post model fitting checks was
> in
> > rma.mv?  I know in the reference manual it mentions profile.rma to
> create
> > a plot of the restricted log likelihood and I have done so.  However, I
> > wondered if I need to plot all 3 variables (sigma2, tau2 and rho) and
> > also how I know which value to specify for each?  Am I correct in that
> I
> > should see a clear peak in each graph?  Is there anything else I should
> > be looking for?
> >
> > For post model fitting checks should I also look at residual normality
> > and residual against fitted values, as would be done for a typical
> mixed
> > model?  I think the standardised residuals are best for this - I can
> get
> > them with rstandard.rma.mv, but it does not allow me to plot them.
> >
> > Finally, when I include the intercept in the model, I can see if there
> > are significant differences among moderator levels.  However, I was
> > wondering what the output includes when the intercept is not included:
> is
> > this the overall effect size estimates for each moderator level?
> >
> > Kind regards,
> > Shona
> >
> >
> > Shona Smith
> > PhD Student
> >
> > Room 321
> > Institute of Biodiversity, Animal Health and Comparative Medicine
> > Graham Kerr Building
> > University of Glasgow
> > Glasgow G12 8QQ
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From wolfgang.viechtbauer at maastrichtuniversity.nl  Wed Sep  3 19:40:40 2014
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Wed, 3 Sep 2014 19:40:40 +0200
Subject: [R-sig-ME] Post model fitting checks in Metafor (rma.mv)
In-Reply-To: <A1BEFC2CBCCA0D41B8E5D8BEC98C0C0871B0690D67@CMS04.campus.gla.ac.uk>
References: <A1BEFC2CBCCA0D41B8E5D8BEC98C0C0871B0690D63@CMS04.campus.gla.ac.uk>,
	<077E31A57DA26E46AB0D493C9966AC730DCA27C088@UM-MAIL4112.unimaas.nl>
	<A1BEFC2CBCCA0D41B8E5D8BEC98C0C0871B0690D66@CMS04.campus.gla.ac.uk>,
	<077E31A57DA26E46AB0D493C9966AC730DCA27C1C9@UM-MAIL4112.unimaas.nl>
	<A1BEFC2CBCCA0D41B8E5D8BEC98C0C0871B0690D67@CMS04.campus.gla.ac.uk>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730DCA27C28F@UM-MAIL4112.unimaas.nl>

By default (check options("contrasts")), R should use treatment contrasts (see help(contr.treatment)). So, one level of each factor is chosen as the reference level and you get coefficients that indicate the contrasts with this reference level. So, if you use 'mods = ~ Age + Treatment + Biomarker' and Age has 3 levels, Treatment has 5 levels, and Biomarker has 3 levels, then you should get 2+4+2=8 coefficients. So:

predict(res, newmods=c(1,0, 0,0,0,0, 0,0))

would give you the predicted effect for the second level of Age, reference level for Treatment, and reference level for Biomarker. And

predict(res, newmods=c(0,1, 0,0,1,0, 1,0))

would be for the third level of Age, fourth level of Treatment, and second level of Biomarker. And so on ...

You may also want to take a look at this tutorial:

http://www.metafor-project.org/doku.php/tips:testing_factors_lincoms

It doesn't cover multiple factors (I'll add one to the website soon), but should help to clarify things a bit. Also, some things won't work for 'rma.mv' models at this point (e.g., the anova() function or permutation tests). But you can use predict(), linearHypothesis() from the 'car' package, and glht() from the 'multcomp' package.

Best,
Wolfgang

> -----Original Message-----
> From: Shona Smith [mailto:s.smith.7 at research.gla.ac.uk]
> Sent: Wednesday, September 03, 2014 19:24
> To: Viechtbauer Wolfgang (STAT); r-sig-mixed-models at r-project.org
> Subject: RE: Post model fitting checks in Metafor (rma.mv)
> 
> Hi Wolfgang,
> 
> This definitely makes sense thanks - to look at an 'overall effect'
> without the moderators sort of defeats the purpose of putting them there
> in the first place.  I was able to download your paper so I can have a
> wee look at that too, thanks.  I think I shall stick with extracting
> predicted values for specific levels of moderators.  I tried the predict
> function and realise I need to code the factor levels myself, but am a
> little confused about how to do so.  To see how the factors were coded in
> the model, I used:
> 
> predict(res, addx=TRUE)
> 
> Then I know I can use 'newmods' to put in the codes for the factor levels
> I would like a predicted value for.  There were a lot of '1's and '0's
> (one for each observation and level of factor) so how can I use this to
> code my factor levels?
> 
> As for the profile plot for sigma2, I suppose it peaks at ~0.05 but it is
> just a straight line, declining from an REML value of ~ -71 (at Sigma2 =
> ~0.05) to an REML value of ~ -72.5 (at Sigma2 = 1).
> 
> Of course missing values were the problem with the residual against
> fitted plot, it was silly of me to miss this.  Thanks!
> 
> Kind regards,
> Shona
> 
> 
> Shona Smith
> PhD Researcher
> 
> Room 321
> Institute of Biodiversity, Animal Health and Comparative Medicine
> Graham Kerr Building
> University of Glasgow
> Glasgow G12 8QQ
> ________________________________________
> From: Viechtbauer Wolfgang (STAT)
> [wolfgang.viechtbauer at maastrichtuniversity.nl]
> Sent: 03 September 2014 14:32
> To: Shona Smith; r-sig-mixed-models at r-project.org
> Subject: RE: Post model fitting checks in Metafor (rma.mv)
> 
> Regarding the profile plot for sigma2: I am not quite sure I understand.
> Does it 'peak' at zero? So, is the estimate (essentially) zero then? That
> would be okay (essentially means that the variability due to 'Study' is
> no larger than what would be expected due to the other variance
> components and/or sampling variability). The issue of zero variance
> components was also recently (and also in past) discussed on this list
> (not with respect to meta-analysis, but it's the same issue).
> 
> Regarding the resid-fitted plot: So, looks like you have some missings,
> so the two vectors end up being of different length. This should do it:
> 
> options(na.action = "na.pass")
> plot(fitted(res), rstandard(res)$z, pch=19)
> 
> Also explained here: http://www.metafor-
> project.org/doku.php/tips:handling_missing_data
> 
> Regarding overall effects: I personally don't think an 'overall' effect
> makes much sense when the effect size appears to be related to a number
> of moderators/covariates. Take the simplest situation, where the true
> effect is of size theta_1 for level 1 of a dichotomous covariate and
> theta_2 for level 2. Now suppose we ignore that covariate and fit a
> random-effects model. Essentially, that is a misfitted model, because the
> model assumes normally distributed true effects (and not two point
> massess). Also, where the 'average' effect then falls depends on how many
> studies in the sample are at level 1 and at level 2 of that covariate.
> That doesn't seem that sensible to me. So, instead, we can fit the model
> with the covariate and then compute predicted values, for example, for
> level 1 or level 2. Or, if you really want an 'overall' effect, we could
> use a sort of 'lsmeans' approach and say: Let's assume that in the
> population of studies, 50% are at level 1 and 50% at level 2, so let's
> compute the predicted effect for such a population (essentially fill in
> 0.5 for the 'dummy' variable when computing the predicted value). But I
> would then describe explicitly that this is what was done (as it makes
> clear what the assumption is about the population of studies).
> 
> I discuss this issue a bit in this article:
> 
> Viechtbauer, W. (2007). Accounting for heterogeneity via random-effects
> models and moderator analyses in meta-analysis. Zeitschrift f?r
> Psychologie / Journal of Psychology, 215(2), 104-121.
> 
> (not the 'lsmeans' idea, but the problem of fitting random-effects models
> when there is a relevant moderators/covariate). If you can't access the
> article, let me know and I'll send you a copy if you are interested.
> 
> Best,
> Wolfgang
> 
> > -----Original Message-----
> > From: Shona Smith [mailto:s.smith.7 at research.gla.ac.uk]
> > Sent: Wednesday, September 03, 2014 13:39
> > To: Viechtbauer Wolfgang (STAT); r-sig-mixed-models at r-project.org
> > Subject: RE: Post model fitting checks in Metafor (rma.mv)
> >
> > Hi Wolfgang,
> >
> > Thanks for such a useful and quick reply.  The sigma2 profile plot does
> > not have a peak - but it's not flat, it seems to just decline (even
> when
> > I expand the x axis values) - I wondered what this meant?  The other
> two
> > look fine, although tau2 drops off much more gradually than rho (which
> is
> > quite a steep drop) after the parameter estimate.  What would be the
> > ideal plot?
> >
> > I can now plot the standardised residuals but fitted against residuals
> > gives me an error:
> >
> > plot(fitted(res), rstandard(res)$z, pch=19)
> > Error in xy.coords(x, y, xlabel, ylabel, log) :
> >   'x' and 'y' lengths differ
> >
> > The fitted values seem to have the row number alongside each value,
> > whiles the standardised residuals don't - so perhaps this is the
> problem?
> >
> > Finally, I also wondered if it is possible to get an overall effect
> size
> > estimate for my response variable?  I notice other studies have carried
> > out a separate meta-analysis to obtain this, before looking at
> > moderators, but I wasn't sure if this was correct.
> >
> > Thanks again,
> > Shona
> >
> >
> > Shona Smith
> > PhD Researcher
> >
> > Room 321
> > Institute of Biodiversity, Animal Health and Comparative Medicine
> > Graham Kerr Building
> > University of Glasgow
> > Glasgow G12 8QQ
> > ________________________________________
> > From: Viechtbauer Wolfgang (STAT)
> > [wolfgang.viechtbauer at maastrichtuniversity.nl]
> > Sent: 03 September 2014 10:28
> > To: Shona Smith; r-sig-mixed-models at r-project.org
> > Subject: RE: Post model fitting checks in Metafor (rma.mv)
> >
> > Dear Shona,
> >
> > The profile() function in metafor allows you to examine the profiled
> > (restricted) log-likelihood for a particular parameter. So, ideally,
> you
> > should do this for each variance component and correlation in the model
> > (in your case, sigma2, tau2 and rho). I am not sure what you mean by: "
> > how I know which value to specify for each?" After you have fitted your
> > model and stored the results in, let's say, 'res', then just do:
> >
> > par(mfrow=c(3,1))
> > profile(res, sigma2=1)
> > profile(res, tau2=1)
> > profile(res, rho=1)
> >
> > to get all three profile plots. And yes, the functions should peak at
> the
> > parameter estimates. If a function is flat, then this suggests that the
> > model is overparameterized.
> >
> > You could also look at how quickly the log-likelihood drops off as you
> > move away from the parameter estimate. The bounds of a 95% profile
> > likelihood CI for a particular parameter would be those two values from
> > the x-axis where the log-likelihood has dropped by 3.84/2. You could
> add
> >
> > abline(h = logLik(res) - qchisq(.95, df=1)/2, lty="dotted")
> >
> > to the figures to see that cutoff. Depending on how much data you have,
> > you may find that those CIs are quite wide. You may have to increase
> the
> > x-axis range, in case the cutoff isn't reached within the range chosen
> by
> > default by the profile function (use the 'xlim' argument).
> >
> > Indeed, you could also look at the (standardized) residuals. Use
> >
> > rstandard(res)$z
> >
> > to get those values. Or:
> >
> > plot(fitted(res), rstandard(res)$z, pch=19)
> >
> > to create a fitted values versus standardized residuals plot.
> >
> > As for the interpretation of the results when you exclude the intercept
> > (i.e., mods = ~ Age + Treatment + Biomarker - 1), you will get the
> > estimated (average) effect for each level of 'Age', but the
> coefficients
> > for 'Treatment' and 'Biomarker' are still going to be contrasts that
> > indicate how much higher/lower the (average) effect is for the levels
> > indicated, relative to the reference level.
> >
> > I hope this helps!
> >
> > Best,
> > Wolfgang
> >
> > > -----Original Message-----
> > > From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-
> > > models-bounces at r-project.org] On Behalf Of Shona Smith
> > > Sent: Tuesday, September 02, 2014 18:37
> > > To: r-sig-mixed-models at r-project.org
> > > Subject: [R-sig-ME] Post model fitting checks in Metafor (rma.mv)
> > >
> > > Hi all,
> > >
> > > I am currently conducting a meta-analysis using rma.mv in metafor.
> My
> > > model uses Hedges' d (converted to g) and includes 3 moderators (age-
> 3
> > > levels; treatment-5 levels; biomarker-3 levels).  I have included 3
> > > random effects: species nested within taxonomic class (since I have
> > more
> > > than one study for some species, and species are spread over 7
> > taxonomic
> > > classes) and study separately.  So my code is as follows:
> > >
> > > rma.mv(yi, vi, mods = ~ Age + Treatment + Biomarker, random = list(~
> 1
> > |
> > > Study, ~ Species | Taxonomic.class), data=mydata)
> > >
> > > I was wondering what the best method for post model fitting checks
> was
> > in
> > > rma.mv?  I know in the reference manual it mentions profile.rma to
> > create
> > > a plot of the restricted log likelihood and I have done so.  However,
> I
> > > wondered if I need to plot all 3 variables (sigma2, tau2 and rho) and
> > > also how I know which value to specify for each?  Am I correct in
> that
> > I
> > > should see a clear peak in each graph?  Is there anything else I
> should
> > > be looking for?
> > >
> > > For post model fitting checks should I also look at residual
> normality
> > > and residual against fitted values, as would be done for a typical
> > mixed
> > > model?  I think the standardised residuals are best for this - I can
> > get
> > > them with rstandard.rma.mv, but it does not allow me to plot them.
> > >
> > > Finally, when I include the intercept in the model, I can see if
> there
> > > are significant differences among moderator levels.  However, I was
> > > wondering what the output includes when the intercept is not
> included:
> > is
> > > this the overall effect size estimates for each moderator level?
> > >
> > > Kind regards,
> > > Shona
> > >
> > >
> > > Shona Smith
> > > PhD Student
> > >
> > > Room 321
> > > Institute of Biodiversity, Animal Health and Comparative Medicine
> > > Graham Kerr Building
> > > University of Glasgow
> > > Glasgow G12 8QQ
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From highstat at highstat.com  Wed Sep  3 22:32:55 2014
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Wed, 03 Sep 2014 21:32:55 +0100
Subject: [R-sig-ME] Four available places on GLMM course in Banff
Message-ID: <54077AF7.6000402@highstat.com>

There are four remaining places on the following course:


Course: Introduction to MCMC, Linear mixed effects models and GLMM with R
When: 22-26 September, 2014
Where: Parks Canada, Banff, Canada
Flyer: http://www.highstat.com/Courses/Flyer2014_09Banff.pdf

Course website: http://www.highstat.com/statscourse.htm


Kind regards,

Alain Zuur

-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From ilkka.j.leppanen at aalto.fi  Thu Sep  4 15:34:16 2014
From: ilkka.j.leppanen at aalto.fi (=?iso-8859-1?Q?Lepp=E4nen_Ilkka?=)
Date: Thu, 4 Sep 2014 13:34:16 +0000
Subject: [R-sig-ME] Nested random effect or unbalanced design?
Message-ID: <E3CB7456C16E0E44B1EA994D6EFA6747ED0C@EXMDB08.org.aalto.fi>

Dear list, 

I am using lmer to identify a mixed effects model, but I am puzzled by whether my design has nested random effects or whether it is just unbalanced.

I have an experiment where subjects are repeatedly measured a physiological variable A. Each subject sees a specific level of a variable B once every time they are measured. Theory goes that higher B gives higher A. 

The trick is that levels of B are drawn randomly from some distribution for each subject. These draws are not reproducible in other experiments, so B should be incorporated somehow as a random effect.

Now if I want to know how B affects A as a random effect, I start from the model 

(M1) A ~ (1|B) + time + (1|subject)

But in this model the random effect B has a very low variance. So I specify B as a fixed effect with the model

(M2) A ~ B + time + (1|subject)

This model is desirable because I am mostly interested in stating how B affects A as a fixed effect, not as a nuisance.

However, if I understand nesting correctly, (M2) is not sufficient because subjects are nested in B. As a toy example, B has levels 1,2,3,4,5 and there are five repeated measurements. Subject 1 sees B={1,2,3,2,2}, subject 2 sees B={4,2,1,1,2}, subject 3 sees B={1,2,3,4,5}, and subject 4 sees only one level B={4,4,4,4,4}. A cross-tabulation of this looks like 
> xtabs(~ B+subject, sparse=T)
5 x 4 sparse Matrix of class "dgCMatrix"
  S1 S2 S3 S4
1  1  2  1  .
2  3  2  1  .
3  1  .  1  .
4  .  1  1  5
5  .  .  1  .

Therefore, because each subject sees their unique set of levels of B, I would use the model with nested random effects

(M3) A ~ B + time + (1|subject) + (1|B:subject)

Here I get the result that the variance of the random effect B:subject is very small relative to variance of B or the residual. A likelihood ratio test does not see (M3) different than the simpler model (M2).

If I decide to go with (M2), I try to keep randomness maximal by examining the random slopes

(M4) A ~ B + time + (1+B|subject)

But here, the random intercept and slope are highly or perfectly correlated. My interpretation of this situation is that the by-subject random slopes are unidentifiable because of the nesting; for example, S4 in the toy example cannot have a "slope" for B.

How should I proceed? Should I just forget about the fact that B is a random effect and pretend that my design is unbalanced? 

Thank you in advance,

Ilkka Lepp?nen
Aalto University




From M.Brewer at bioss.ac.uk  Thu Sep  4 16:05:54 2014
From: M.Brewer at bioss.ac.uk (Mark J Brewer)
Date: Thu, 4 Sep 2014 15:05:54 +0100
Subject: [R-sig-ME] Nested random effect or unbalanced design?
In-Reply-To: <E3CB7456C16E0E44B1EA994D6EFA6747ED0C@EXMDB08.org.aalto.fi>
References: <E3CB7456C16E0E44B1EA994D6EFA6747ED0C@EXMDB08.org.aalto.fi>
Message-ID: <001101cfc849$57bbd890$073389b0$@bioss.ac.uk>

Dear Ilkka,

I don't see B as a random effect, even if it is a random stimulus. If I
understand correctly, in your toy example B has a fixed set of 5 levels,
changing the nature of which would change the experiment - and you are
directly interested in how B affects A (or more specifically, how means
change, rather than a variance summary).

Correlations are often high in the manner you describe for M4; this is a
complex model with many parameters - e.g. this is allowing a separate
relationship between A and B for every subject. You should still be able to
test formally for a difference between M2 and M4.

Best wishes,

Mark

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Lepp?nen
Ilkka
Sent: 04 September 2014 14:34
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Nested random effect or unbalanced design?

Dear list, 

I am using lmer to identify a mixed effects model, but I am puzzled by
whether my design has nested random effects or whether it is just
unbalanced.

I have an experiment where subjects are repeatedly measured a physiological
variable A. Each subject sees a specific level of a variable B once every
time they are measured. Theory goes that higher B gives higher A. 

The trick is that levels of B are drawn randomly from some distribution for
each subject. These draws are not reproducible in other experiments, so B
should be incorporated somehow as a random effect.

Now if I want to know how B affects A as a random effect, I start from the
model 

(M1) A ~ (1|B) + time + (1|subject)

But in this model the random effect B has a very low variance. So I specify
B as a fixed effect with the model

(M2) A ~ B + time + (1|subject)

This model is desirable because I am mostly interested in stating how B
affects A as a fixed effect, not as a nuisance.

However, if I understand nesting correctly, (M2) is not sufficient because
subjects are nested in B. As a toy example, B has levels 1,2,3,4,5 and there
are five repeated measurements. Subject 1 sees B={1,2,3,2,2}, subject 2 sees
B={4,2,1,1,2}, subject 3 sees B={1,2,3,4,5}, and subject 4 sees only one
level B={4,4,4,4,4}. A cross-tabulation of this looks like 
> xtabs(~ B+subject, sparse=T)
5 x 4 sparse Matrix of class "dgCMatrix"
  S1 S2 S3 S4
1  1  2  1  .
2  3  2  1  .
3  1  .  1  .
4  .  1  1  5
5  .  .  1  .

Therefore, because each subject sees their unique set of levels of B, I
would use the model with nested random effects

(M3) A ~ B + time + (1|subject) + (1|B:subject)

Here I get the result that the variance of the random effect B:subject is
very small relative to variance of B or the residual. A likelihood ratio
test does not see (M3) different than the simpler model (M2).

If I decide to go with (M2), I try to keep randomness maximal by examining
the random slopes

(M4) A ~ B + time + (1+B|subject)

But here, the random intercept and slope are highly or perfectly correlated.
My interpretation of this situation is that the by-subject random slopes are
unidentifiable because of the nesting; for example, S4 in the toy example
cannot have a "slope" for B.

How should I proceed? Should I just forget about the fact that B is a random
effect and pretend that my design is unbalanced? 

Thank you in advance,

Ilkka Lepp?nen
Aalto University



_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Biomathematics and Statistics Scotland (BioSS) is formally part of The
James Hutton Institute (JHI), a registered Scottish charity No. SC041796
and a company limited by guarantee No. SC374831

From s.smith.7 at research.gla.ac.uk  Thu Sep  4 19:38:24 2014
From: s.smith.7 at research.gla.ac.uk (Shona Smith)
Date: Thu, 4 Sep 2014 18:38:24 +0100
Subject: [R-sig-ME] Post model fitting checks in Metafor (rma.mv)
In-Reply-To: <077E31A57DA26E46AB0D493C9966AC730DCA27C28F@UM-MAIL4112.unimaas.nl>
References: <A1BEFC2CBCCA0D41B8E5D8BEC98C0C0871B0690D63@CMS04.campus.gla.ac.uk>,
	<077E31A57DA26E46AB0D493C9966AC730DCA27C088@UM-MAIL4112.unimaas.nl>
	<A1BEFC2CBCCA0D41B8E5D8BEC98C0C0871B0690D66@CMS04.campus.gla.ac.uk>,
	<077E31A57DA26E46AB0D493C9966AC730DCA27C1C9@UM-MAIL4112.unimaas.nl>
	<A1BEFC2CBCCA0D41B8E5D8BEC98C0C0871B0690D67@CMS04.campus.gla.ac.uk>,
	<077E31A57DA26E46AB0D493C9966AC730DCA27C28F@UM-MAIL4112.unimaas.nl>
Message-ID: <A1BEFC2CBCCA0D41B8E5D8BEC98C0C0871B0690D68@CMS04.campus.gla.ac.uk>

Hi Wolfgang,

Thanks very much for all your help, and explaining everything so clearly.

Kind regards,
Shona


Shona Smith
PhD Researcher

Room 321
Institute of Biodiversity, Animal Health and Comparative Medicine
Graham Kerr Building
University of Glasgow
Glasgow G12 8QQ
________________________________________
From: Viechtbauer Wolfgang (STAT) [wolfgang.viechtbauer at maastrichtuniversity.nl]
Sent: 03 September 2014 18:40
To: Shona Smith; r-sig-mixed-models at r-project.org
Subject: RE: Post model fitting checks in Metafor (rma.mv)

By default (check options("contrasts")), R should use treatment contrasts (see help(contr.treatment)). So, one level of each factor is chosen as the reference level and you get coefficients that indicate the contrasts with this reference level. So, if you use 'mods = ~ Age + Treatment + Biomarker' and Age has 3 levels, Treatment has 5 levels, and Biomarker has 3 levels, then you should get 2+4+2=8 coefficients. So:

predict(res, newmods=c(1,0, 0,0,0,0, 0,0))

would give you the predicted effect for the second level of Age, reference level for Treatment, and reference level for Biomarker. And

predict(res, newmods=c(0,1, 0,0,1,0, 1,0))

would be for the third level of Age, fourth level of Treatment, and second level of Biomarker. And so on ...

You may also want to take a look at this tutorial:

http://www.metafor-project.org/doku.php/tips:testing_factors_lincoms

It doesn't cover multiple factors (I'll add one to the website soon), but should help to clarify things a bit. Also, some things won't work for 'rma.mv' models at this point (e.g., the anova() function or permutation tests). But you can use predict(), linearHypothesis() from the 'car' package, and glht() from the 'multcomp' package.

Best,
Wolfgang

> -----Original Message-----
> From: Shona Smith [mailto:s.smith.7 at research.gla.ac.uk]
> Sent: Wednesday, September 03, 2014 19:24
> To: Viechtbauer Wolfgang (STAT); r-sig-mixed-models at r-project.org
> Subject: RE: Post model fitting checks in Metafor (rma.mv)
>
> Hi Wolfgang,
>
> This definitely makes sense thanks - to look at an 'overall effect'
> without the moderators sort of defeats the purpose of putting them there
> in the first place.  I was able to download your paper so I can have a
> wee look at that too, thanks.  I think I shall stick with extracting
> predicted values for specific levels of moderators.  I tried the predict
> function and realise I need to code the factor levels myself, but am a
> little confused about how to do so.  To see how the factors were coded in
> the model, I used:
>
> predict(res, addx=TRUE)
>
> Then I know I can use 'newmods' to put in the codes for the factor levels
> I would like a predicted value for.  There were a lot of '1's and '0's
> (one for each observation and level of factor) so how can I use this to
> code my factor levels?
>
> As for the profile plot for sigma2, I suppose it peaks at ~0.05 but it is
> just a straight line, declining from an REML value of ~ -71 (at Sigma2 =
> ~0.05) to an REML value of ~ -72.5 (at Sigma2 = 1).
>
> Of course missing values were the problem with the residual against
> fitted plot, it was silly of me to miss this.  Thanks!
>
> Kind regards,
> Shona
>
>
> Shona Smith
> PhD Researcher
>
> Room 321
> Institute of Biodiversity, Animal Health and Comparative Medicine
> Graham Kerr Building
> University of Glasgow
> Glasgow G12 8QQ
> ________________________________________
> From: Viechtbauer Wolfgang (STAT)
> [wolfgang.viechtbauer at maastrichtuniversity.nl]
> Sent: 03 September 2014 14:32
> To: Shona Smith; r-sig-mixed-models at r-project.org
> Subject: RE: Post model fitting checks in Metafor (rma.mv)
>
> Regarding the profile plot for sigma2: I am not quite sure I understand.
> Does it 'peak' at zero? So, is the estimate (essentially) zero then? That
> would be okay (essentially means that the variability due to 'Study' is
> no larger than what would be expected due to the other variance
> components and/or sampling variability). The issue of zero variance
> components was also recently (and also in past) discussed on this list
> (not with respect to meta-analysis, but it's the same issue).
>
> Regarding the resid-fitted plot: So, looks like you have some missings,
> so the two vectors end up being of different length. This should do it:
>
> options(na.action = "na.pass")
> plot(fitted(res), rstandard(res)$z, pch=19)
>
> Also explained here: http://www.metafor-
> project.org/doku.php/tips:handling_missing_data
>
> Regarding overall effects: I personally don't think an 'overall' effect
> makes much sense when the effect size appears to be related to a number
> of moderators/covariates. Take the simplest situation, where the true
> effect is of size theta_1 for level 1 of a dichotomous covariate and
> theta_2 for level 2. Now suppose we ignore that covariate and fit a
> random-effects model. Essentially, that is a misfitted model, because the
> model assumes normally distributed true effects (and not two point
> massess). Also, where the 'average' effect then falls depends on how many
> studies in the sample are at level 1 and at level 2 of that covariate.
> That doesn't seem that sensible to me. So, instead, we can fit the model
> with the covariate and then compute predicted values, for example, for
> level 1 or level 2. Or, if you really want an 'overall' effect, we could
> use a sort of 'lsmeans' approach and say: Let's assume that in the
> population of studies, 50% are at level 1 and 50% at level 2, so let's
> compute the predicted effect for such a population (essentially fill in
> 0.5 for the 'dummy' variable when computing the predicted value). But I
> would then describe explicitly that this is what was done (as it makes
> clear what the assumption is about the population of studies).
>
> I discuss this issue a bit in this article:
>
> Viechtbauer, W. (2007). Accounting for heterogeneity via random-effects
> models and moderator analyses in meta-analysis. Zeitschrift f?r
> Psychologie / Journal of Psychology, 215(2), 104-121.
>
> (not the 'lsmeans' idea, but the problem of fitting random-effects models
> when there is a relevant moderators/covariate). If you can't access the
> article, let me know and I'll send you a copy if you are interested.
>
> Best,
> Wolfgang
>
> > -----Original Message-----
> > From: Shona Smith [mailto:s.smith.7 at research.gla.ac.uk]
> > Sent: Wednesday, September 03, 2014 13:39
> > To: Viechtbauer Wolfgang (STAT); r-sig-mixed-models at r-project.org
> > Subject: RE: Post model fitting checks in Metafor (rma.mv)
> >
> > Hi Wolfgang,
> >
> > Thanks for such a useful and quick reply.  The sigma2 profile plot does
> > not have a peak - but it's not flat, it seems to just decline (even
> when
> > I expand the x axis values) - I wondered what this meant?  The other
> two
> > look fine, although tau2 drops off much more gradually than rho (which
> is
> > quite a steep drop) after the parameter estimate.  What would be the
> > ideal plot?
> >
> > I can now plot the standardised residuals but fitted against residuals
> > gives me an error:
> >
> > plot(fitted(res), rstandard(res)$z, pch=19)
> > Error in xy.coords(x, y, xlabel, ylabel, log) :
> >   'x' and 'y' lengths differ
> >
> > The fitted values seem to have the row number alongside each value,
> > whiles the standardised residuals don't - so perhaps this is the
> problem?
> >
> > Finally, I also wondered if it is possible to get an overall effect
> size
> > estimate for my response variable?  I notice other studies have carried
> > out a separate meta-analysis to obtain this, before looking at
> > moderators, but I wasn't sure if this was correct.
> >
> > Thanks again,
> > Shona
> >
> >
> > Shona Smith
> > PhD Researcher
> >
> > Room 321
> > Institute of Biodiversity, Animal Health and Comparative Medicine
> > Graham Kerr Building
> > University of Glasgow
> > Glasgow G12 8QQ
> > ________________________________________
> > From: Viechtbauer Wolfgang (STAT)
> > [wolfgang.viechtbauer at maastrichtuniversity.nl]
> > Sent: 03 September 2014 10:28
> > To: Shona Smith; r-sig-mixed-models at r-project.org
> > Subject: RE: Post model fitting checks in Metafor (rma.mv)
> >
> > Dear Shona,
> >
> > The profile() function in metafor allows you to examine the profiled
> > (restricted) log-likelihood for a particular parameter. So, ideally,
> you
> > should do this for each variance component and correlation in the model
> > (in your case, sigma2, tau2 and rho). I am not sure what you mean by: "
> > how I know which value to specify for each?" After you have fitted your
> > model and stored the results in, let's say, 'res', then just do:
> >
> > par(mfrow=c(3,1))
> > profile(res, sigma2=1)
> > profile(res, tau2=1)
> > profile(res, rho=1)
> >
> > to get all three profile plots. And yes, the functions should peak at
> the
> > parameter estimates. If a function is flat, then this suggests that the
> > model is overparameterized.
> >
> > You could also look at how quickly the log-likelihood drops off as you
> > move away from the parameter estimate. The bounds of a 95% profile
> > likelihood CI for a particular parameter would be those two values from
> > the x-axis where the log-likelihood has dropped by 3.84/2. You could
> add
> >
> > abline(h = logLik(res) - qchisq(.95, df=1)/2, lty="dotted")
> >
> > to the figures to see that cutoff. Depending on how much data you have,
> > you may find that those CIs are quite wide. You may have to increase
> the
> > x-axis range, in case the cutoff isn't reached within the range chosen
> by
> > default by the profile function (use the 'xlim' argument).
> >
> > Indeed, you could also look at the (standardized) residuals. Use
> >
> > rstandard(res)$z
> >
> > to get those values. Or:
> >
> > plot(fitted(res), rstandard(res)$z, pch=19)
> >
> > to create a fitted values versus standardized residuals plot.
> >
> > As for the interpretation of the results when you exclude the intercept
> > (i.e., mods = ~ Age + Treatment + Biomarker - 1), you will get the
> > estimated (average) effect for each level of 'Age', but the
> coefficients
> > for 'Treatment' and 'Biomarker' are still going to be contrasts that
> > indicate how much higher/lower the (average) effect is for the levels
> > indicated, relative to the reference level.
> >
> > I hope this helps!
> >
> > Best,
> > Wolfgang
> >
> > > -----Original Message-----
> > > From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-
> > > models-bounces at r-project.org] On Behalf Of Shona Smith
> > > Sent: Tuesday, September 02, 2014 18:37
> > > To: r-sig-mixed-models at r-project.org
> > > Subject: [R-sig-ME] Post model fitting checks in Metafor (rma.mv)
> > >
> > > Hi all,
> > >
> > > I am currently conducting a meta-analysis using rma.mv in metafor.
> My
> > > model uses Hedges' d (converted to g) and includes 3 moderators (age-
> 3
> > > levels; treatment-5 levels; biomarker-3 levels).  I have included 3
> > > random effects: species nested within taxonomic class (since I have
> > more
> > > than one study for some species, and species are spread over 7
> > taxonomic
> > > classes) and study separately.  So my code is as follows:
> > >
> > > rma.mv(yi, vi, mods = ~ Age + Treatment + Biomarker, random = list(~
> 1
> > |
> > > Study, ~ Species | Taxonomic.class), data=mydata)
> > >
> > > I was wondering what the best method for post model fitting checks
> was
> > in
> > > rma.mv?  I know in the reference manual it mentions profile.rma to
> > create
> > > a plot of the restricted log likelihood and I have done so.  However,
> I
> > > wondered if I need to plot all 3 variables (sigma2, tau2 and rho) and
> > > also how I know which value to specify for each?  Am I correct in
> that
> > I
> > > should see a clear peak in each graph?  Is there anything else I
> should
> > > be looking for?
> > >
> > > For post model fitting checks should I also look at residual
> normality
> > > and residual against fitted values, as would be done for a typical
> > mixed
> > > model?  I think the standardised residuals are best for this - I can
> > get
> > > them with rstandard.rma.mv, but it does not allow me to plot them.
> > >
> > > Finally, when I include the intercept in the model, I can see if
> there
> > > are significant differences among moderator levels.  However, I was
> > > wondering what the output includes when the intercept is not
> included:
> > is
> > > this the overall effect size estimates for each moderator level?
> > >
> > > Kind regards,
> > > Shona
> > >
> > >
> > > Shona Smith
> > > PhD Student
> > >
> > > Room 321
> > > Institute of Biodiversity, Animal Health and Comparative Medicine
> > > Graham Kerr Building
> > > University of Glasgow
> > > Glasgow G12 8QQ
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Fri Sep  5 03:20:57 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 04 Sep 2014 21:20:57 -0400
Subject: [R-sig-ME] glmmADMB - User Guide
In-Reply-To: <801_1409878534_s850tXOh024068_20140905005524.BF37A187524@r-forge.r-project.org>
References: <801_1409878534_s850tXOh024068_20140905005524.BF37A187524@r-forge.r-project.org>
Message-ID: <54090FF9.2010504@mcmaster.ca>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 14-09-04 08:55 PM, Leo Yanes wrote:
> Dear Ben, I have recently began to use glmmADMB but cannot find a
> user guide or detailed documentation to help me learn the package
> well. Could you please send me materials or point me in the right
> direction? Many thanks in advance. Leo
> 
> L.Yanes at acilallen.com.au
> 

  I'm cc'ing this to the r-sig-mixed-models list in case anyone there
has additional ideas.

  I would suggest starting with the glmmADMB vignette:

library(glmmADMB)
vignette("glmmADMB",package="glmmADMB")

  In addition to that, you may find more general materials on GLMMs
useful:

  Bolker et al 2009 TREE
  Bolker et al 2013 Methods in Ecology and Evolution

both available via http://ms.mcmaster.ca/~bolker/bb-pubs.html
(username: bbpapers, password: research)

 http://rpubs.com/bbolker/glmmchapter
 http://glmm.wikidot.com/faq
http://glmm.wdfiles.com/local--files/examples/Banta_2011_part1.pdf
http://glmm.wdfiles.com/local--files/examples/Banta_2011_part2.pdf

 It may be that none of those are what you're looking for, but that's
what there is  ...


-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJUCQ/5AAoJEOCV5YRblxUHRZMIAKMfvbedXvWZfE6R5GenjcID
rWFLlXjDvH9NZmjNqriO2JKKJg4TLO+r5WeXCCaAH2jeZ0U84wRm3TGpuLe1fRq2
+52QrdTKTKHFNDsCTm0aC+5Ipzh2QGVhkleYm4X4Z4OAnH9hLg0dAFqIDxdUHMOG
MsdXfDVvHI1MLlUxfoGlqI32j0tDaUKuLlVyWdS0Xj0vD31TppHntgumO74KSxdm
BJBcaMfLDYi0zhgjq1Zijla2a05j9VHBE+FLQ2QY+CjF2UYGHCS11mLEEpeHhniO
XaApTSVFOV0CeIB6Igs46HRHBOgZmYH3RiQtJX++UCm9Ntty8DkBhnd0/2xM1Fw=
=k42A
-----END PGP SIGNATURE-----


From moskante at gmail.com  Fri Sep  5 12:22:01 2014
From: moskante at gmail.com (Alessandro Moscatelli)
Date: Fri, 5 Sep 2014 12:22:01 +0200
Subject: [R-sig-ME] family() in probit-glmer
Message-ID: <CAN5G=1g6nc0BNwUpfvtetbJnLqQh5zASxAaRY9Ljs-N4TJ2zVQ@mail.gmail.com>

Dear all,

I have a problem using the function family(). I am using lme4 version 1.1-7
running on R 3.1.0
I fit a glmer model with a probit link function:

formula.mod = cbind(Longer, Total - Longer) ~ X * condition + (1 + X|
Subject)
mod1 <- glmer(formula = formula.mod, family = binomial(link = "probit"),
data = datafr)
> mod1
Generalized linear mixed model fit by maximum likelihood (Laplace
Approximation) ['glmerMod']
 Family: binomial  ( probit )
Formula: cbind(Longer, Total - Longer) ~ X * condition + (1 + X | Subject)
   Data: datafr
      AIC       BIC    logLik  deviance  df.resid
 330.1026  348.8775 -158.0513  316.1026       101
Random effects:
 Groups  Name        Std.Dev. Corr
 Subject (Intercept) 1.452885
         X           0.001128 -0.99
Number of obs: 108, groups:  Subject, 6
Fixed Effects:
 (Intercept)             X    conditionB  X:conditionB
  -7.1760859     0.0090841    -0.2190119     0.0001522

However, using the family() function:
> family(mod1)

Family: binomial
Link function: logit

Does anyone has the same problem? Is it a bug? For Now I solved the problem
using:
> summary(mod1)$link
[1] "probit"

Best
Alessandro

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Fri Sep  5 16:51:31 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 05 Sep 2014 10:51:31 -0400
Subject: [R-sig-ME] family() in probit-glmer
In-Reply-To: <CAN5G=1g6nc0BNwUpfvtetbJnLqQh5zASxAaRY9Ljs-N4TJ2zVQ@mail.gmail.com>
References: <CAN5G=1g6nc0BNwUpfvtetbJnLqQh5zASxAaRY9Ljs-N4TJ2zVQ@mail.gmail.com>
Message-ID: <5409CDF3.9090706@gmail.com>

   This does indeed look like a bug, now fixed
<https://github.com/lme4/lme4/commit/7f7350751ef1dfbd1598c24d4075fe18ea005860>
.  Thanks.

  In the meantime, you could also extract the family and associated
information via model at resp$family (although we do encourage everyone to
use the accessor methods when they work!)

  Ben Bolker


On 14-09-05 06:22 AM, Alessandro Moscatelli wrote:
> Dear all,
> 
> I have a problem using the function family(). I am using lme4 version 1.1-7
> running on R 3.1.0
> I fit a glmer model with a probit link function:
> 
> formula.mod = cbind(Longer, Total - Longer) ~ X * condition + (1 + X|
> Subject)
> mod1 <- glmer(formula = formula.mod, family = binomial(link = "probit"),
> data = datafr)
>> mod1
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) ['glmerMod']
>  Family: binomial  ( probit )
> Formula: cbind(Longer, Total - Longer) ~ X * condition + (1 + X | Subject)
>    Data: datafr
>       AIC       BIC    logLik  deviance  df.resid
>  330.1026  348.8775 -158.0513  316.1026       101
> Random effects:
>  Groups  Name        Std.Dev. Corr
>  Subject (Intercept) 1.452885
>          X           0.001128 -0.99
> Number of obs: 108, groups:  Subject, 6
> Fixed Effects:
>  (Intercept)             X    conditionB  X:conditionB
>   -7.1760859     0.0090841    -0.2190119     0.0001522
> 
> However, using the family() function:
>> family(mod1)
> 
> Family: binomial
> Link function: logit
> 
> Does anyone has the same problem? Is it a bug? For Now I solved the problem
> using:
>> summary(mod1)$link
> [1] "probit"
> 
> Best
> Alessandro
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From abedimail at gmail.com  Fri Sep  5 17:49:46 2014
From: abedimail at gmail.com (Mehdi Abedi)
Date: Fri, 5 Sep 2014 20:19:46 +0430
Subject: [R-sig-ME] Mixed model for ordinal data with pseudo replication
In-Reply-To: <CADGhaggsED7AtMdmX=kU9b03frDzRD9BzBwfH1yHfmcUeCy_yw@mail.gmail.com>
References: <CADGhaggsED7AtMdmX=kU9b03frDzRD9BzBwfH1yHfmcUeCy_yw@mail.gmail.com>
Message-ID: <CADGhagjVqENJXr5DEvZsp3FkT5ZDS1CiSAa3_AsGs5UwV9aFFw@mail.gmail.com>

Dear all,
I checked my previous mail and add more details about data. My data include:

1.Grassland management treatment: it include 6 grassland management
treatments including grazing, exclosure from grazing, plowing and planting
sites.

2. Plant functional groups: it include 5 functional group including
annuals, perennial grasses, perennial forbs, half shrubs and shrubs. These
groups were selected in each treatments. therefore you can find different
groups in treatments depend to concurrence in certain treatments.

  Treatments  Functional group  Grazing Half shrub  Grazing Perrenial forb
Grazing Perrenial forb  Grazing Shrub  Grazing Bare soil  Exclusure Perrenial
grass  Exclusure Half shrub
 Exclusure Perrenial forb  Exclusure Bare soil  Exclusure Perrenial grass
Plowing Annual  Plowing Annual  Plowing Perrenial grass  planting Half shrub
planting Annual  planting Half shrub  planting Half shrub  planting Half
shrub

3. 11 soil surface indicators measured with 5 replicate in each functional
groups. These data are ordinal from 0-5 expect for one indicator which is
continuous.


I am interested to have a model for each 11 indicator separately which
treatments is fixed effect and functional groups may be as random effect (i
am not sure is it just simple random effect or may i need to consider as
nested..).

It would be my pleasure to have your advice.
Warm regards,
Mehdi


On Thu, Aug 21, 2014 at 12:16 PM, Mehdi Abedi <abedimail at gmail.com> wrote:

> Dear all,
> I want to compare 11 soil surface indicator in different treatments and if
> possible for species. It would be my pleasure to have your advice for my
> data analysis. First, i have two factors including treatments and species
> which each treatments include different species. Can we use mixed model for
> data analysis?!
>
>  In addition, these 11 soil indicator are ordinal from 0-5 and also has
> pseudo replication. Do you have suggestion for data analysis with lme4 or
> other proper models?
>
> You can find in the attached file my data as csv file.
> Warm regards,
> Mehdi
>
>


-- 


*Mehdi Abedi Department of Range Management*

*Faculty of Natural Resources & Marine Sciences *

*Tarbiat Modares University (TMU) *

*46417-76489, Noor*

*Mazandaran, IRAN *

*mehdi.abedi at modares.ac.ir <Mehdi.abedi at tmu.ac.ir>*

*Homepage
<http://www.modares.ac.ir/en/Schools/nat/Academic_Staff/~mehdi.abedi>*

*Tel: +98-122-6253101 *

*Fax: +98-122-6253499*

	[[alternative HTML version deleted]]


From prachi.sanghavi at gmail.com  Fri Sep  5 20:19:36 2014
From: prachi.sanghavi at gmail.com (Prachi Sanghavi)
Date: Fri, 5 Sep 2014 14:19:36 -0400
Subject: [R-sig-ME] glmer takes long time even after restricting iterations
Message-ID: <B6D924DB-93DC-4747-AC99-91CD227F4DF6@gmail.com>

Hello!

I have a fairly complex multilevel, multivariate logistic model that I am trying to fit.  In both models below, the variables injury, AMI, stroke, and resp are binary, as well as ALS and most other variables.  There are a total of about 400,000 observations.  When I try to fit the model (Original Model), I get several warnings, and I have pasted these below.  I am largely concerned about number 4.  I think this problem is due to having too many parameters in the model, and so I removed several interactions that were unnecessary anyway (Modified Model).  I ran the Modified Model with a fixed number of iterations, and it finished these quickly enough (maybe 20 minutes?).  But then it took another 19 hours to actually stop running, during which time I suspect R was doing various checks that led to the warnings.  I'm not sure.  When the Modified Model finished, it produced the warnings below.

My biggest problem right now is the amount of time it takes for R to stop running, even after restricting the number of iterations to 100.  Because of this problem, it is impractical to try to figure out how to address the warnings.

Can somebody please help me figure out why R is taking so long, even after it has finished the 100 iterations?  And what can I do about it?

Thank you!!

Prachi Sanghavi
Harvard University


Original Model and Warnings:

AMI_county_final_2 <- glmer(ALS ~ -1 + AMI + (injury + stroke + resp)*(FEMALE + AGE + MTUS_CNT + Asian + Black + Hispanic + Other + Custodial + Nursing + Scene + WhiteHigh + BlackHigh + BlackLow + IntegratedHigh + IntegratedLow + combinedscore + Year06 + Year07 + Year08 + Year09 + Year10 + Metro + Per_College_Plus + Per_Gen_Prac + Any_MedSchlAff + Any_Trauma) + (-1 + injury + AMI + stroke + resp | fullcounty), family=binomial, data=rbind(IARS,IARS2), verbose=2, control=glmerControl(optCtrl=list(maxfun=100)))

Warning messages:
1: In (function (fn, par, lower = rep.int(-Inf, n), upper = rep.int(Inf,  :
  failure to converge in 10000 evaluations
2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model failed to converge with max|grad| = 480.605 (tol = 0.001)
3: In if (resHess$code != 0) { :
  the condition has length > 1 and only the first element will be used
4: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model is nearly unidentifiable: very large eigenvalue
 - Rescale variables?;Model is nearly unidentifiable: large eigenvalue ratio
 - Rescale variables?

Modified Model and Warnings:

AMI_county_final_2 <- glmer(ALS ~ -1 + Year06 + Year07 + Year08 + Year09 + Year10 + Metro + AMI + (injury + stroke + resp)*(FEMALE + AGE + MTUS_CNT + Asian + Black + Hispanic + Other + Custodial + Nursing + Scene + WhiteHigh + BlackHigh + BlackLow + IntegratedHigh + IntegratedLow + combinedscore) + (-1 + injury + AMI + stroke + resp | fullcounty), family=binomial, data=rbind(IARS,IARS2), verbose=2, control=glmerControl(optCtrl=list(maxfun=100)))

Warning messages:
1: In commonArgs(par, fn, control, environment()) :
  maxfun < 10 * length(par)^2 is not recommended.
2: In optwrap(optimizer, devfun, start, rho$lower, control = control,  :
  convergence code 1 from bobyqa: bobyqa -- maximum number of function evaluations exceeded
3: In (function (fn, par, lower = rep.int(-Inf, n), upper = rep.int(Inf,  :
  failure to converge in 100 evaluations
4: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model failed to converge with max|grad| = 15923.5 (tol = 0.001)
5: In if (resHess$code != 0) { :
  the condition has length > 1 and only the first element will be used
6: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model is nearly unidentifiable: very large eigenvalue
 - Rescale variables?;Model is nearly unidentifiable: large eigenvalue ratio
 - Rescale variables?
	[[alternative HTML version deleted]]


From bates at stat.wisc.edu  Fri Sep  5 23:05:02 2014
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 5 Sep 2014 16:05:02 -0500
Subject: [R-sig-ME] glmer takes long time even after restricting
	iterations
In-Reply-To: <B6D924DB-93DC-4747-AC99-91CD227F4DF6@gmail.com>
References: <B6D924DB-93DC-4747-AC99-91CD227F4DF6@gmail.com>
Message-ID: <CAO7JsnRx+e5jNfVnm5PZ=MBb+10sCYwG+JAvadOpgFkE2NEZhA@mail.gmail.com>

I will take it as a compliment that you have sufficient confidence in our
software to try to fit such a model.  :-)

Sadly, even with 400,000 observations it is highly unlikely you would be
able to converge to parameter estimates for these modesl and even more
unlikely that the estimates would be meaningful.

The optimization in glmer is different than the optimization in lmer.  For
a linear mixed model the optimization is over the parameters in the
relative covariance matrix only.  In this case it looks like there would be
15 such parameters.  The optimization problem involving even these
parameters would be difficult, as it is likely that the solution will be on
the boundary of the feasible region, representing a singular covariance
matrix.  For glmer the optimization is much more difficult because it is
over the concatenation of the fixed-effects parameters and the covariance
parameters.  I lost track of what the number of fixed-effects parameters is
but that number is large.  As you have seen the first model failed to
converge in 100,000 iterations.  That is not encouraging.

Regarding the warning messages I will let Ben or Steve respond as they know
more about the convergence checks than I do.  I believe those diagnostics
involve creating a finite-difference approximation to the gradient vector
and the Hessian matrix.  The approximation of the Hessian matrix at the
optimum is probably where the time is being spent.

The best advice is to simplify the model.  You say that ALS is a binary
variable, which means that even with 400,000 observations you have only
400,000 bits of information to which to fit the model.  That's not a lot.
 A continuous response provides much more information per observation than
a binary response.

Try to fit the fixed-effects only using glm.  I'm confident that most of
the coefficients will not be significant.

On Fri, Sep 5, 2014 at 1:19 PM, Prachi Sanghavi <prachi.sanghavi at gmail.com>
wrote:

> Hello!
>
> I have a fairly complex multilevel, multivariate logistic model that I am
> trying to fit.  In both models below, the variables injury, AMI, stroke,
> and resp are binary, as well as ALS and most other variables.  There are a
> total of about 400,000 observations.  When I try to fit the model (Original
> Model), I get several warnings, and I have pasted these below.  I am
> largely concerned about number 4.  I think this problem is due to having
> too many parameters in the model, and so I removed several interactions
> that were unnecessary anyway (Modified Model).  I ran the Modified Model
> with a fixed number of iterations, and it finished these quickly enough
> (maybe 20 minutes?).  But then it took another 19 hours to actually stop
> running, during which time I suspect R was doing various checks that led to
> the warnings.  I'm not sure.  When the Modified Model finished, it produced
> the warnings below.
>
> My biggest problem right now is the amount of time it takes for R to stop
> running, even after restricting the number of iterations to 100.  Because
> of this problem, it is impractical to try to figure out how to address the
> warnings.
>
> Can somebody please help me figure out why R is taking so long, even after
> it has finished the 100 iterations?  And what can I do about it?
>
> Thank you!!
>
> Prachi Sanghavi
> Harvard University
>
>
> Original Model and Warnings:
>
> AMI_county_final_2 <- glmer(ALS ~ -1 + AMI + (injury + stroke +
> resp)*(FEMALE + AGE + MTUS_CNT + Asian + Black + Hispanic + Other +
> Custodial + Nursing + Scene + WhiteHigh + BlackHigh + BlackLow +
> IntegratedHigh + IntegratedLow + combinedscore + Year06 + Year07 + Year08 +
> Year09 + Year10 + Metro + Per_College_Plus + Per_Gen_Prac + Any_MedSchlAff
> + Any_Trauma) + (-1 + injury + AMI + stroke + resp | fullcounty),
> family=binomial, data=rbind(IARS,IARS2), verbose=2,
> control=glmerControl(optCtrl=list(maxfun=100)))
>
> Warning messages:
> 1: In (function (fn, par, lower = rep.int(-Inf, n), upper = rep.int(Inf,
> :
>   failure to converge in 10000 evaluations
> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model failed to converge with max|grad| = 480.605 (tol = 0.001)
> 3: In if (resHess$code != 0) { :
>   the condition has length > 1 and only the first element will be used
> 4: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model is nearly unidentifiable: very large eigenvalue
>  - Rescale variables?;Model is nearly unidentifiable: large eigenvalue
> ratio
>  - Rescale variables?
>
> Modified Model and Warnings:
>
> AMI_county_final_2 <- glmer(ALS ~ -1 + Year06 + Year07 + Year08 + Year09 +
> Year10 + Metro + AMI + (injury + stroke + resp)*(FEMALE + AGE + MTUS_CNT +
> Asian + Black + Hispanic + Other + Custodial + Nursing + Scene + WhiteHigh
> + BlackHigh + BlackLow + IntegratedHigh + IntegratedLow + combinedscore) +
> (-1 + injury + AMI + stroke + resp | fullcounty), family=binomial,
> data=rbind(IARS,IARS2), verbose=2,
> control=glmerControl(optCtrl=list(maxfun=100)))
>
> Warning messages:
> 1: In commonArgs(par, fn, control, environment()) :
>   maxfun < 10 * length(par)^2 is not recommended.
> 2: In optwrap(optimizer, devfun, start, rho$lower, control = control,  :
>   convergence code 1 from bobyqa: bobyqa -- maximum number of function
> evaluations exceeded
> 3: In (function (fn, par, lower = rep.int(-Inf, n), upper = rep.int(Inf,
> :
>   failure to converge in 100 evaluations
> 4: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model failed to converge with max|grad| = 15923.5 (tol = 0.001)
> 5: In if (resHess$code != 0) { :
>   the condition has length > 1 and only the first element will be used
> 6: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model is nearly unidentifiable: very large eigenvalue
>  - Rescale variables?;Model is nearly unidentifiable: large eigenvalue
> ratio
>  - Rescale variables?
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Fri Sep  5 23:34:11 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 05 Sep 2014 17:34:11 -0400
Subject: [R-sig-ME] glmer takes long time even after restricting
	iterations
In-Reply-To: <CAO7JsnRx+e5jNfVnm5PZ=MBb+10sCYwG+JAvadOpgFkE2NEZhA@mail.gmail.com>
References: <B6D924DB-93DC-4747-AC99-91CD227F4DF6@gmail.com>
	<CAO7JsnRx+e5jNfVnm5PZ=MBb+10sCYwG+JAvadOpgFkE2NEZhA@mail.gmail.com>
Message-ID: <540A2C53.3040600@gmail.com>

On 14-09-05 05:05 PM, Douglas Bates wrote:
> I will take it as a compliment that you have sufficient confidence in our
> software to try to fit such a model.  :-)
> 
> Sadly, even with 400,000 observations it is highly unlikely you would be
> able to converge to parameter estimates for these modesl and even more
> unlikely that the estimates would be meaningful.
> 
> The optimization in glmer is different than the optimization in lmer.  For
> a linear mixed model the optimization is over the parameters in the
> relative covariance matrix only.  In this case it looks like there would be
> 15 such parameters.  The optimization problem involving even these
> parameters would be difficult, as it is likely that the solution will be on
> the boundary of the feasible region, representing a singular covariance
> matrix.  For glmer the optimization is much more difficult because it is
> over the concatenation of the fixed-effects parameters and the covariance
> parameters.  I lost track of what the number of fixed-effects parameters is
> but that number is large.  As you have seen the first model failed to
> converge in 100,000 iterations.  That is not encouraging.
> 
> Regarding the warning messages I will let Ben or Steve respond as they know
> more about the convergence checks than I do.  I believe those diagnostics
> involve creating a finite-difference approximation to the gradient vector
> and the Hessian matrix.  The approximation of the Hessian matrix at the
> optimum is probably where the time is being spent.
> 

  For speeding things up I would try setting nAGQ=0, and setting

control=glmerControl(check.conv.grad="ignore",check.conv.singular="ignore",
                     check.conv.hess="ignore")

-- this should deactivate the Hessian and gradient computations
(although at some point you will probably want to go back to testing these!)

  It looks like you have 79 fixed-effect parameters, plus what looks
like 10 random-effect parameters (this is a quick count, and assumes
that all your variables are numeric) -- this means that the Hessian
computation will have to do approximately 4000 (n*(n+1)/2) function
evaluations ...

   You can also try using the bobyqa implementation from nloptr, with
appropriate convergence settings, as described here:

https://github.com/lme4/lme4/issues/150#issuecomment-45813306

I believe these are the same settings that are implemented in ?nloptwrap.


> The best advice is to simplify the model.  You say that ALS is a binary
> variable, which means that even with 400,000 observations you have only
> 400,000 bits of information to which to fit the model.  That's not a lot.
>  A continuous response provides much more information per observation than
> a binary response.
> 
> Try to fit the fixed-effects only using glm.  I'm confident that most of
> the coefficients will not be significant.
> 
> On Fri, Sep 5, 2014 at 1:19 PM, Prachi Sanghavi <prachi.sanghavi at gmail.com>
> wrote:
> 
>> Hello!
>>
>> I have a fairly complex multilevel, multivariate logistic model that I am
>> trying to fit.  In both models below, the variables injury, AMI, stroke,
>> and resp are binary, as well as ALS and most other variables.  There are a
>> total of about 400,000 observations.  When I try to fit the model (Original
>> Model), I get several warnings, and I have pasted these below.  I am
>> largely concerned about number 4.  I think this problem is due to having
>> too many parameters in the model, and so I removed several interactions
>> that were unnecessary anyway (Modified Model).  I ran the Modified Model
>> with a fixed number of iterations, and it finished these quickly enough
>> (maybe 20 minutes?).  But then it took another 19 hours to actually stop
>> running, during which time I suspect R was doing various checks that led to
>> the warnings.  I'm not sure.  When the Modified Model finished, it produced
>> the warnings below.
>>
>> My biggest problem right now is the amount of time it takes for R to stop
>> running, even after restricting the number of iterations to 100.  Because
>> of this problem, it is impractical to try to figure out how to address the
>> warnings.
>>
>> Can somebody please help me figure out why R is taking so long, even after
>> it has finished the 100 iterations?  And what can I do about it?
>>
>> Thank you!!
>>
>> Prachi Sanghavi
>> Harvard University
>>
>>
>> Original Model and Warnings:
>>

>> AMI_county_final_2 <- glmer(ALS ~ -1 + AMI + (injury + stroke +
>> resp)*(FEMALE + AGE + MTUS_CNT + Asian + Black + Hispanic + Other +
>> Custodial + Nursing + Scene + WhiteHigh + BlackHigh + BlackLow +
>> IntegratedHigh + IntegratedLow + combinedscore + Year06 + Year07 + Year08 +
>> Year09 + Year10 + Metro + Per_College_Plus + Per_Gen_Prac + Any_MedSchlAff
>> + Any_Trauma) + (-1 + injury + AMI + stroke + resp | fullcounty),
>> family=binomial, data=rbind(IARS,IARS2), verbose=2,
>> control=glmerControl(optCtrl=list(maxfun=100)))
>>
>> Warning messages:
>> 1: In (function (fn, par, lower = rep.int(-Inf, n), upper = rep.int(Inf,
>> :
>>   failure to converge in 10000 evaluations
>> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>>   Model failed to converge with max|grad| = 480.605 (tol = 0.001)
>> 3: In if (resHess$code != 0) { :
>>   the condition has length > 1 and only the first element will be used
>> 4: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>>   Model is nearly unidentifiable: very large eigenvalue
>>  - Rescale variables?;Model is nearly unidentifiable: large eigenvalue
>> ratio
>>  - Rescale variables?
>>
>> Modified Model and Warnings:
>>
>> AMI_county_final_2 <- glmer(ALS ~ -1 + Year06 + Year07 + Year08 + Year09 +
>> Year10 + Metro + AMI + (injury + stroke + resp)*(FEMALE + AGE + MTUS_CNT +
>> Asian + Black + Hispanic + Other + Custodial + Nursing + Scene + WhiteHigh
>> + BlackHigh + BlackLow + IntegratedHigh + IntegratedLow + combinedscore) +
>> (-1 + injury + AMI + stroke + resp | fullcounty), family=binomial,
>> data=rbind(IARS,IARS2), verbose=2,
>> control=glmerControl(optCtrl=list(maxfun=100)))
>>
>> Warning messages:
>> 1: In commonArgs(par, fn, control, environment()) :
>>   maxfun < 10 * length(par)^2 is not recommended.
>> 2: In optwrap(optimizer, devfun, start, rho$lower, control = control,  :
>>   convergence code 1 from bobyqa: bobyqa -- maximum number of function
>> evaluations exceeded
>> 3: In (function (fn, par, lower = rep.int(-Inf, n), upper = rep.int(Inf,
>> :
>>   failure to converge in 100 evaluations
>> 4: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>>   Model failed to converge with max|grad| = 15923.5 (tol = 0.001)
>> 5: In if (resHess$code != 0) { :
>>   the condition has length > 1 and only the first element will be used
>> 6: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>>   Model is nearly unidentifiable: very large eigenvalue
>>  - Rescale variables?;Model is nearly unidentifiable: large eigenvalue
>> ratio
>>  - Rescale variables?
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From john.maindonald at anu.edu.au  Mon Sep  8 06:56:49 2014
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Mon, 8 Sep 2014 04:56:49 +0000
Subject: [R-sig-ME] lmer() with 'na.action=na.exclude'; error with summary()
Message-ID: <46A3E0AE-C63E-4D8D-83C4-71E797125839@anu.edu.au>

The following demonstrates the issue:

> library(DAAG)
> science.lmer <- lmer(like ~ sex + PrivPub + (1 | school) + 
+                      (1 | school:class), data = science,  
+                      na.action=na.exclude) 
> summary(science.lmer)
Linear mixed model fit by REML ['lmerMod']
Formula: like ~ sex + PrivPub + (1 | school) + (1 | school:class)
   Data: science

REML criterion at convergence: 5546.5

Scaled residuals: 
Error in quantile.default(resids) : 
  missing values and NaN's not allowed if 'na.rm' is FALSE
> ## Suppress details of residuals
> summary(science.lmer, show.resids=FALSE)
Linear mixed model fit by REML ['lmerMod']
Formula: like ~ sex + PrivPub + (1 | school) + (1 | school:class)
   Data: science

REML criterion at convergence: 5546.5

Scaled residuals: 
Error in quantile.default(resids) : 
  missing values and NaN's not allowed if 'na.rm' is FALSE
> 

With na.action = na.omit, there is no problem.

> sessionInfo()
R version 3.1.1 Patched (2014-08-22 r66458)
Platform: x86_64-apple-darwin10.8.0 (64-bit)

locale:
[1] en_AU.UTF-8/en_AU.UTF-8/en_AU.UTF-8/C/en_AU.UTF-8/en_AU.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] lme4_1.1-7      Rcpp_0.11.2     Matrix_1.1-4    DAAG_1.20       lattice_0.20-29

loaded via a namespace (and not attached):
[1] grid_3.1.1          latticeExtra_0.6-26 MASS_7.3-34         minqa_1.2.3         nlme_3.1-117       
[6] nloptr_1.0.4        RColorBrewer_1.0-5  splines_3.1.1       tools_3.1.1    

I doubt that there is an intention for summary.merMod() to throw an error
lmer() has been called with 'na.action=na.exclude?.  It should certainly not 
throw an error with the argument 'show.resids=FALSE?.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


From Tom.Wilding at sams.ac.uk  Mon Sep  8 17:11:36 2014
From: Tom.Wilding at sams.ac.uk (Tom Wilding)
Date: Mon, 8 Sep 2014 15:11:36 +0000
Subject: [R-sig-ME] Influence of the random effects on fixed effect
 estimates in mixed models and interpretation of fixed effects in relation
 to random effects.
Message-ID: <C3CE30FD1A1CBF469C59A5551FF29C199BD02D6E@Verbiage1.sams.local>

Dear All
I have previously asked this question on StackExchange with no feedback thus far.
http://stats.stackexchange.com/questions/112030/why-and-how-does-the-inclusion-of-random-effects-in-mixed-models-influence-the-f

I would like to repeat this question here as ongoing research has not revealed any answers.  My question is about the influence that the random terms have on the fixed effect (e.g. intercept) estimates and how to interpret the intercepts when different random terms (e.g. random intercept v random slope) are included in the model.


The following code can be run to illustrate my question:

library(lme4)
library(faraway)
data(epilepsy)
log(mean(epilepsy$seizures))#expected intercept in intercept only model = 2.5544
(Ep1a=glm(seizures~1,family=poisson,data=epilepsy))#intercept term =2.554 as expected.
(Ep1b=glmer(seizures~1+(1|id),family=poisson,data=epilepsy))#intercept term =2.214.

My understanding is that the inclusion of the random term (id) tells the model that there is a repeated measure across subject (in this case). I can understand that this allows for the non-independence of the data: there are fewer than n=295 independent data points. But why does the fixed-effect intercept value decrease? Is the decrease in this case because the model has 'more confidence' in the observations from 'id' which were lower than the mean?  If so, is this because the variance =mean in a Poisson distribution?

I note from the following website: http://www.danielezrajohnson.com/glasgow_workshop.R the following in relation to a model unrelated to the one i've specified above (suggest you search for "average speaker"):

"...this model has random effects for speaker and word. The fixed effects reported are for a sort of average speaker and word. However, word, especially, tends to be a very skewed variable. There will always be a few very common words, that may favor or disfavor the response. The mixed model largely counteracts this weighting."

In my real example (for more details see the StackExchange question, link above), all the coefficients are considerably less (2-3 units in log scale) than the corresponding mean values for those factor combinations as apparent in the raw data.  I'm struggling to justify this but in attempting to do this I've run some simulations (albeit run using nlme - clunky code available from me which plots the raw data and various models).  In a simulation where there are two random 'sites' (I appreciate that this is many fewer than 'allowed'), where there is a random slope effect and where an intercept-only model allowing a random slope is fitted, the fixed-effect intercept term is the Y-axis value where the slopes for these two 'sites' meet (i.e. cross).  I had anticipated it to the be mean of the slope-intercepts at the predictor value of zero.  This means that if the two random slopes happen to run in near parallel then the intercept term output by the model can be 'way-off' - the individual regression lines cross at some distance from the mean value of the data set.  I'm not sure what this means in terms of a more realistic 10 plus sites (or the >300 I have in my real data set) - but I note that my real data is zero-inflated and wonder if additional weight is given to those sites with characterised by low counts, possibly because the variance associated with low values is also low??

What is represented by the intercept (and other terms in a factorial model) in relation to the random effects?  Any pointers on this would be much appreciated.

Thanks

Tom.

The Scottish Association for Marine Science (SAMS) is registered in Scotland as a Company Limited by Guarantee (SC009292) and is a registered charity (9206). SAMS has an actively trading wholly owned subsidiary company: SAMS Research Services Ltd a Limited Company (SC224404). All Companies in the group are registered in Scotland and share a registered office at Scottish Marine Institute, Oban Argyll PA37 1QA. The content of this message may contain personal views which are not the views of SAMS unless specifically stated. Please note that all email traffic is monitored for purposes of security and spam filtering. As such individual emails may be examined in more detail.

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Mon Sep  8 17:33:14 2014
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 08 Sep 2014 16:33:14 +0100
Subject: [R-sig-ME] Influence of the random effects on fixed effect
 estimates in mixed models and interpretation of fixed effects in relation
 to random effects.
In-Reply-To: <C3CE30FD1A1CBF469C59A5551FF29C199BD02D6E@Verbiage1.sams.local>
References: <C3CE30FD1A1CBF469C59A5551FF29C199BD02D6E@Verbiage1.sams.local>
Message-ID: <20140908163314.733242sk9sw88g8w@www.staffmail.ed.ac.uk>

Hi Tom,

You need to add half the variance:

fixef(Ep1b)+0.5*VarCorr(Ep1b)[[1]][1]

Figures 2.4 and 2.5 in the MCMCglmm CourseNotes try to explain  
visually/verbally why this is necessary, and Section 2.5 gives a bit  
more detail for the general case.

Cheers,

Jarrod



Quoting Tom Wilding <Tom.Wilding at sams.ac.uk> on Mon, 8 Sep 2014  
15:11:36 +0000:

> Dear All
> I have previously asked this question on StackExchange with no  
> feedback thus far.
> http://stats.stackexchange.com/questions/112030/why-and-how-does-the-inclusion-of-random-effects-in-mixed-models-influence-the-f
>
> I would like to repeat this question here as ongoing research has  
> not revealed any answers.  My question is about the influence that  
> the random terms have on the fixed effect (e.g. intercept) estimates  
> and how to interpret the intercepts when different random terms  
> (e.g. random intercept v random slope) are included in the model.
>
>
> The following code can be run to illustrate my question:
>
> library(lme4)
> library(faraway)
> data(epilepsy)
> log(mean(epilepsy$seizures))#expected intercept in intercept only  
> model = 2.5544
> (Ep1a=glm(seizures~1,family=poisson,data=epilepsy))#intercept term  
> =2.554 as expected.
> (Ep1b=glmer(seizures~1+(1|id),family=poisson,data=epilepsy))#intercept term  
> =2.214.
>
> My understanding is that the inclusion of the random term (id) tells  
> the model that there is a repeated measure across subject (in this  
> case). I can understand that this allows for the non-independence of  
> the data: there are fewer than n=295 independent data points. But  
> why does the fixed-effect intercept value decrease? Is the decrease  
> in this case because the model has 'more confidence' in the  
> observations from 'id' which were lower than the mean?  If so, is  
> this because the variance =mean in a Poisson distribution?
>
> I note from the following website:  
> http://www.danielezrajohnson.com/glasgow_workshop.R the following in  
> relation to a model unrelated to the one i've specified above  
> (suggest you search for "average speaker"):
>
> "...this model has random effects for speaker and word. The fixed  
> effects reported are for a sort of average speaker and word.  
> However, word, especially, tends to be a very skewed variable. There  
> will always be a few very common words, that may favor or disfavor  
> the response. The mixed model largely counteracts this weighting."
>
> In my real example (for more details see the StackExchange question,  
> link above), all the coefficients are considerably less (2-3 units  
> in log scale) than the corresponding mean values for those factor  
> combinations as apparent in the raw data.  I'm struggling to justify  
> this but in attempting to do this I've run some simulations (albeit  
> run using nlme - clunky code available from me which plots the raw  
> data and various models).  In a simulation where there are two  
> random 'sites' (I appreciate that this is many fewer than  
> 'allowed'), where there is a random slope effect and where an  
> intercept-only model allowing a random slope is fitted, the  
> fixed-effect intercept term is the Y-axis value where the slopes for  
> these two 'sites' meet (i.e. cross).  I had anticipated it to the be  
> mean of the slope-intercepts at the predictor value of zero.  This  
> means that if the two random slopes happen to run in near parallel  
> then the intercept term output by the model can be 'way-off' - the i!
>  ndividual regression lines cross at some distance from the mean  
> value of the data set.  I'm not sure what this means in terms of a  
> more realistic 10 plus sites (or the >300 I have in my real data  
> set) - but I note that my real data is zero-inflated and wonder if  
> additional weight is given to those sites with characterised by low  
> counts, possibly because the variance associated with low values is  
> also low??
>
> What is represented by the intercept (and other terms in a factorial  
> model) in relation to the random effects?  Any pointers on this  
> would be much appreciated.
>
> Thanks
>
> Tom.
>
> The Scottish Association for Marine Science (SAMS) is registered in  
> Scotland as a Company Limited by Guarantee (SC009292) and is a  
> registered charity (9206). SAMS has an actively trading wholly owned  
> subsidiary company: SAMS Research Services Ltd a Limited Company  
> (SC224404). All Companies in the group are registered in Scotland  
> and share a registered office at Scottish Marine Institute, Oban  
> Argyll PA37 1QA. The content of this message may contain personal  
> views which are not the views of SAMS unless specifically stated.  
> Please note that all email traffic is monitored for purposes of  
> security and spam filtering. As such individual emails may be  
> examined in more detail.
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From bbolker at gmail.com  Mon Sep  8 18:50:01 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 8 Sep 2014 16:50:01 +0000 (UTC)
Subject: [R-sig-ME] lmer() with 'na.action=na.exclude';
	error with summary()
References: <46A3E0AE-C63E-4D8D-83C4-71E797125839@anu.edu.au>
Message-ID: <loom.20140908T183459-671@post.gmane.org>

John Maindonald <john.maindonald at ...> writes:

> 
> The following demonstrates the issue:
> 
> > library(DAAG)
> > science.lmer <- lmer(like ~ sex + PrivPub + (1 | school) + 
> +                      (1 | school:class), data = science,  
> +                      na.action=na.exclude) 
> > summary(science.lmer)
> Linear mixed model fit by REML ['lmerMod']

 [snip]
 
> Scaled residuals: 
> Error in quantile.default(resids) : 
>   missing values and NaN's not allowed if 'na.rm' is FALSE
> > ## Suppress details of residuals


> > summary(science.lmer, show.resids=FALSE)

  This is a confusion between the arguments of the summary method
(summary.merMod) and the *print method* (print.summary.merMod).
We should add a warning to summary that says it is discarding
unused arguments (the ... in the model definition is only there
for compatibility with the summary() generic method).

  print(summary(science.lmer), show.resids=FALSE)

works fine.

> 
> I doubt that there is an intention for summary.merMod() to throw an error
> lmer() has been called with 'na.action=na.exclude?.  
> It should certainly not 
> throw an error with the argument 'show.resids=FALSE?.

   Now I'm wondering whether the correct behaviour when there are
NAs in the (extended) residuals is 

  1 omit NAs from the residual quantile calculation (easiest)
  2 return NA values for all quantiles of the residual
  3 return the quantiles plus a statement of the number of NAs.

Any good reason not to just do #1?


From john.maindonald at anu.edu.au  Tue Sep  9 01:31:14 2014
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Mon, 8 Sep 2014 23:31:14 +0000
Subject: [R-sig-ME] lmer() with 'na.action=na.exclude';
 error with summary()
In-Reply-To: <loom.20140908T183459-671@post.gmane.org>
References: <46A3E0AE-C63E-4D8D-83C4-71E797125839@anu.edu.au>
	<loom.20140908T183459-671@post.gmane.org>
Message-ID: <58829D35-CD4C-4AE2-B76D-19874E7BC676@anu.edu.au>

On 9 Sep 2014, at 2:50, Ben Bolker <bbolker at gmail.com> wrote:

> John Maindonald <john.maindonald at ...> writes:
> 
>> 
>> The following demonstrates the issue:
>> 
>>> library(DAAG)
>>> science.lmer <- lmer(like ~ sex + PrivPub + (1 | school) + 
>> +                      (1 | school:class), data = science,  
>> +                      na.action=na.exclude) 
>>> summary(science.lmer)
>> Linear mixed model fit by REML ['lmerMod']
> 
> [snip]
> 
>> Scaled residuals: 
>> Error in quantile.default(resids) : 
>>  missing values and NaN's not allowed if 'na.rm' is FALSE
>>> ## Suppress details of residuals
> 
> 
>>> summary(science.lmer, show.resids=FALSE)
> 
>  This is a confusion between the arguments of the summary method
> (summary.merMod) and the *print method* (print.summary.merMod).
> We should add a warning to summary that says it is discarding
> unused arguments (the ... in the model definition is only there
> for compatibility with the summary() generic method).
> 
>  print(summary(science.lmer), show.resids=FALSE)
> 
> works fine.

That is a subtlety that I had not contemplated.  It is not in forming
the summary object, but in printing it that the problem is evident.

> I doubt that there is an intention for summary.merMod() to throw an error
>> lmer() has been called with 'na.action=na.exclude?.  
>> It should certainly not 
>> throw an error with the argument 'show.resids=FALSE?.
> 
>   Now I'm wondering whether the correct behaviour when there are
> NAs in the (extended) residuals is 
> 
>  1 omit NAs from the residual quantile calculation (easiest)

I see no reason not to choose (1),  At the time we prepared the 3rd edition of 
'Data Analysis and Graphics using R?, this was the behaviour. My understanding 
of ?na.action=na.exclude? has been that the result is as for ?na.action=na.omit?, 
except that residuals match up with the original observations, with NAs inserted
as necessary.  In other words, the change from  ?na.action=na.omit? to
?na.action=na.exclude? is all about wharf appears when one explicitly
calculates and returns residuals, not about what happens when summary 
information (quantiles, not the residuals themselves!) is printed.

This strategy also simplifies documenting and describing what is done.

>  2 return NA values for all quantiles of the residual
>  3 return the quantiles plus a statement of the number of NAs.
> 
> Any good reason not to just do #1?

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.

> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From paul.johnson at glasgow.ac.uk  Tue Sep  9 10:46:29 2014
From: paul.johnson at glasgow.ac.uk (Paul Johnson)
Date: Tue, 9 Sep 2014 08:46:29 +0000
Subject: [R-sig-ME] "bootstrap runs failed" in bootMer within
 confint.merMod
In-Reply-To: <00A92C99-9997-4820-8F0D-803427324DDE@glasgow.ac.uk>
References: <00A92C99-9997-4820-8F0D-803427324DDE@glasgow.ac.uk>
Message-ID: <615F1529-96DE-47D2-B696-E872195BE981@glasgow.ac.uk>

An update on this question: it's now an issue on github, at https://github.com/lme4/lme4/issues/231

Thanks to Ben Bolker for following this up - see the comments for updates on progress.

Paul Johnson


On 14 Aug 2014, at 14:15, Paul Johnson <Paul.Johnson at glasgow.ac.uk> wrote:

> Hi,
> 
> I?ve been using confint.merMod to get 95% CIs by parametric bootstrapping, and have been getting the warnings of the type "In bootMer(object, bootFun, nsim = nsim, ...) : some bootstrap runs failed (30/100)?. (I realise than 100 samples are too few - this is just an example). The function still returns CIs using the bootstrap samples that didn?t fail, but I don?t think these CIs are valid as the failures are very unlikely to be a random sample. Here?s an example using the grouseticks data set that comes with lme4 (see ?grouseticks). I chose this data set because it?s a classic example data set so presumably isn?t pathological, but I?ve been encountering the same problem with other apparently healthy glmer fits.
> 
>> library(lme4)
>> full_mod1  <- glmer(TICKS ~ YEAR+scale(HEIGHT)+(1|BROOD)+(1|INDEX)+(1|LOCATION), family="poisson", data=grouseticks)
>> set.seed(12345)
>> confint(full_mod1, method = "boot", boot.type = "basic", nsim = 100, parallel = "multicore", ncpus = 8)
> Computing bootstrap confidence intervals ...
>                                2.5 %     97.5 %
> sd_(Intercept)|INDEX     0.4624700492  0.6550336
> sd_(Intercept)|BROOD     0.5740796527  1.0482547
> sd_(Intercept)|LOCATION  0.2497343230  1.0574176
> (Intercept)             -0.0002611865  0.7208569
> YEAR96                   0.7770837606  1.5857202
> YEAR97                  -1.4648325648 -0.4484355
> scale(HEIGHT)           -1.1335522182 -0.5879858
> Warning message:
> In bootMer(object, bootFun, nsim = nsim, ...) :
>  some bootstrap runs failed (30/100)
> 
> (NB I scaled height to prevent a warning but it makes no difference to the likelihood.)
> 
> I tried to replicate the problem using bootMer directly to produce fixed effect estimates from 10 samples:
> 
>> bootMer(full_mod1, fixef, nsim = 10)$t
>      (Intercept)    YEAR96     YEAR97 scale(HEIGHT)
> [1,]   0.6387534 0.7467317 -1.1291369    -0.8741711
> [2,]          NA        NA         NA            NA
> [3,]   0.1920928 1.3666922 -0.5821328    -0.6742498
> [4,]          NA        NA         NA            NA
> [5,]          NA        NA         NA            NA
> [6,]   0.5312426 0.9639612 -1.1041643    -0.7550492
> [7,]          NA        NA         NA            NA
> [8,]   0.2328530 1.1016917 -0.8010541    -0.8480263
> [9,]   0.2685594 1.2806690 -0.7452719    -0.8302675
> [10,]   0.1726928 1.1423894 -0.8989542    -1.0344128
> Warning message:
> In bootMer(full_mod1, fixef, nsim = 10) : some bootstrap runs failed (4/10)
> 
> ?and get the same problem, not surprisingly. Here?s a manual version of what (I believe) bootMer is doing:
> 
> 
>> simTICKS.tab <- simulate(full_mod1, nsim=10)
>> t(apply(simTICKS.tab, 2, function(simTICKS) fixef(glmer(simTICKS ~ YEAR+scale(HEIGHT)+(1|BROOD)+(1|INDEX)+(1|LOCATION), family="poisson", data=grouseticks))))
>       (Intercept)    YEAR96     YEAR97 scale(HEIGHT)
> sim_1    0.1793276 1.2265976 -0.5753168    -0.6435871
> sim_2    0.3918824 1.4583529 -0.8958396    -0.8513233
> sim_3    0.2565916 1.1230342 -0.9369728    -1.0817019
> sim_4    0.3507285 1.1865904 -1.0654895    -0.9193403
> sim_5    0.5688213 0.7291811 -0.9734654    -0.8575988
> sim_6    0.6160919 1.0552260 -1.5139770    -1.0050926
> sim_7    0.1594954 1.1342809 -1.0624134    -0.8107930
> sim_8    0.7956874 0.8290606 -1.2491060    -1.0024299
> sim_9    0.3081545 1.2677562 -1.0398100    -0.9458849
> sim_10   0.4325345 0.9390844 -0.9241206    -0.7341589
> 
> ?no errors, not even a warning. The discrepancy between bootMer and the DIY version above appears to arise from the bootMer fitting function, refit, being less tolerant of warning signs (non-convergence?) than glmer, which can be seen by putting refit into the DIY bootstrap:
> 
>> t(apply(simTICKS.tab, 2, function(simTICKS) fixef(refit(full_mod1, simTICKS))))
> Warning messages:
> 1: In pwrssUpdate(pp, resp, tolPwrss, GQmat, compDev, fac, verbose) :
>  Cholmod warning 'not positive definite' at file:../Cholesky/t_cholmod_rowfac.c, line 431
> 2: In pwrssUpdate(pp, resp, tolPwrss, GQmat, compDev, fac, verbose) :
>  Cholmod warning 'not positive definite' at file:../Cholesky/t_cholmod_rowfac.c, line 431
> Error in t(apply(simTICKS.tab, 2, function(simTICKS) fixef(refit(full_mod1,  : 
>  error in evaluating the argument 'x' in selecting a method for function 't': Error in t(apply(simTICKS.tab, 2, function(simTICKS) fixef(refit(full_mod1,  : 
>  (maxstephalfit) PIRLS step-halvings failed to reduce deviance in pwrssUpdate
> 
> My questions are: 
> 
> Should I trust the error- and warning-free DIY bootstrap results? I would say ?yes?, on the (slightly vague) basis that glmer produced no warnings, and that the original model fits well to what is a pretty information-rich data set. So is bootMer being oversensitive? I?m aware that there have been some teething problems with the optimisers and convergence checks in lme4 1.0+ ? are these ongoing? I?m writing a tutorial document in which I?d like to demonstrate parametric bootstrapping for CIs. I could use the DIY approach, but I?d much rather use confint, so it would be great if there was a simple fix to this problem.
> 
> Thanks in advance,
> Paul Johnson 
> (the Glasgow one, not the Kansas or Oxford ones)
> 
>> sessionInfo()
> R version 3.1.1 (2014-07-10)
> Platform: x86_64-apple-darwin13.1.0 (64-bit)
> 
> locale:
> [1] en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8
> 
> attached base packages:
> [1] parallel  stats     graphics  grDevices utils     datasets  methods   base     
> 
> other attached packages:
> [1] lme4_1.1-7   Rcpp_0.11.2  Matrix_1.1-4
> 
> loaded via a namespace (and not attached):
> [1] boot_1.3-11     grid_3.1.1      lattice_0.20-29 MASS_7.3-33     minqa_1.2.3     nlme_3.1-117    nloptr_1.0.0    splines_3.1.1   tools_3.1.1    
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From maechler at stat.math.ethz.ch  Tue Sep  9 16:02:20 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 9 Sep 2014 16:02:20 +0200
Subject: [R-sig-ME] lmer() with 'na.action=na.exclude';
 error with summary()
In-Reply-To: <58829D35-CD4C-4AE2-B76D-19874E7BC676@anu.edu.au>
References: <46A3E0AE-C63E-4D8D-83C4-71E797125839@anu.edu.au>
	<loom.20140908T183459-671@post.gmane.org>
	<58829D35-CD4C-4AE2-B76D-19874E7BC676@anu.edu.au>
Message-ID: <21519.2156.912727.92542@stat.math.ethz.ch>

>>>>> John Maindonald <john.maindonald at anu.edu.au>
>>>>>     on Mon, 8 Sep 2014 23:31:14 +0000 writes:

    > On 9 Sep 2014, at 2:50, Ben Bolker <bbolker at gmail.com>
    > wrote:
    >> John Maindonald <john.maindonald at ...> writes:
    >> 
    >>> 
    >>> The following demonstrates the issue:
    >>> 
    >>>> library(DAAG) science.lmer <- lmer(like ~ sex + PrivPub
    >>>> + (1 | school) +
    >>> + (1 | school:class), data = science, +
    >>> na.action=na.exclude)
    >>>> summary(science.lmer)
    >>> Linear mixed model fit by REML ['lmerMod']
    >> 
    >> [snip]
    >> 
    >>> Scaled residuals: Error in quantile.default(resids) :
    >>> missing values and NaN's not allowed if 'na.rm' is FALSE
    >>>> ## Suppress details of residuals
    >> 
    >> 
    >>>> summary(science.lmer, show.resids=FALSE)
    >> 
    >> This is a confusion between the arguments of the summary
    >> method (summary.merMod) and the *print method*
    >> (print.summary.merMod).  We should add a warning to
    >> summary that says it is discarding unused arguments (the
    >> ... in the model definition is only there for
    >> compatibility with the summary() generic method).
    >> 
    >> print(summary(science.lmer), show.resids=FALSE)
    >> 
    >> works fine.

    > That is a subtlety that I had not contemplated.  It is not
    > in forming the summary object, but in printing it that the
    > problem is evident.

    >> I doubt that there is an intention for summary.merMod()
    >> to throw an error
    >>> lmer() has been called with 'na.action=na.exclude?.  It
    >>> should certainly not throw an error with the argument
    >>> 'show.resids=FALSE?.
    >> 
    >> Now I'm wondering whether the correct behaviour when
    >> there are NAs in the (extended) residuals is
    >> 
    >> 1 omit NAs from the residual quantile calculation
    >> (easiest)

       > I see no reason not to choose (1), At the time we prepared
       > the 3rd edition of 'Data Analysis and Graphics using R?,
       > this was the behaviour. My understanding of
       > ?na.action=na.exclude? has been that the result is as for
       > ?na.action=na.omit?, except that residuals match up with
       > the original observations, with NAs inserted as necessary.
       > In other words, the change from ?na.action=na.omit? to
       > ?na.action=na.exclude? is all about wharf appears when one
       > explicitly calculates and returns residuals, not about
       > what happens when summary information (quantiles, not the
       > residuals themselves!) is printed.

       > This strategy also simplifies documenting and describing
       > what is done.

    >> 2 return NA values for all quantiles of the residual 

    >> 3 return the quantiles plus a statement of the number of NAs.
    >> 
    >> Any good reason not to just do #1?

We should  follow the behavior of lm()
in all such cases of doubt unless we have very very strong
reasons not to follow lm().
It has been *the* example and motivator to a big extent AFAIR
for the  na.action  semantics when they were introduced (in S).

Martin

    > John Maindonald email: john.maindonald at anu.edu.au phone :
    > +61 2 (6125)3473 fax : +61 2(6125)5549 Centre for
    > Mathematics & Its Applications, Room 1194, John Dedman
    > Mathematical Sciences Building (Building 27) Australian
    > National University, Canberra ACT 0200.


From bbolker at gmail.com  Tue Sep  9 16:05:47 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 09 Sep 2014 10:05:47 -0400
Subject: [R-sig-ME] lmer() with 'na.action=na.exclude';
	error with summary()
In-Reply-To: <21519.2156.912727.92542@stat.math.ethz.ch>
References: <46A3E0AE-C63E-4D8D-83C4-71E797125839@anu.edu.au>	<loom.20140908T183459-671@post.gmane.org>	<58829D35-CD4C-4AE2-B76D-19874E7BC676@anu.edu.au>
	<21519.2156.912727.92542@stat.math.ethz.ch>
Message-ID: <540F093B.2070104@gmail.com>

On 14-09-09 10:02 AM, Martin Maechler wrote:
>>>>>> John Maindonald <john.maindonald at anu.edu.au>
>>>>>>     on Mon, 8 Sep 2014 23:31:14 +0000 writes:
> 
>     > On 9 Sep 2014, at 2:50, Ben Bolker <bbolker at gmail.com>
>     > wrote:
>     >> John Maindonald <john.maindonald at ...> writes:
>     >> 
>     >>> 
>     >>> The following demonstrates the issue:
>     >>> 
>     >>>> library(DAAG) science.lmer <- lmer(like ~ sex + PrivPub
>     >>>> + (1 | school) +
>     >>> + (1 | school:class), data = science, +
>     >>> na.action=na.exclude)
>     >>>> summary(science.lmer)
>     >>> Linear mixed model fit by REML ['lmerMod']
>     >> 
>     >> [snip]
>     >> 
>     >>> Scaled residuals: Error in quantile.default(resids) :
>     >>> missing values and NaN's not allowed if 'na.rm' is FALSE
>     >>>> ## Suppress details of residuals
>     >> 
>     >> 
>     >>>> summary(science.lmer, show.resids=FALSE)
>     >> 
>     >> This is a confusion between the arguments of the summary
>     >> method (summary.merMod) and the *print method*
>     >> (print.summary.merMod).  We should add a warning to
>     >> summary that says it is discarding unused arguments (the
>     >> ... in the model definition is only there for
>     >> compatibility with the summary() generic method).
>     >> 
>     >> print(summary(science.lmer), show.resids=FALSE)
>     >> 
>     >> works fine.
> 
>     > That is a subtlety that I had not contemplated.  It is not
>     > in forming the summary object, but in printing it that the
>     > problem is evident.
> 
>     >> I doubt that there is an intention for summary.merMod()
>     >> to throw an error
>     >>> lmer() has been called with 'na.action=na.exclude?.  It
>     >>> should certainly not throw an error with the argument
>     >>> 'show.resids=FALSE?.
>     >> 
>     >> Now I'm wondering whether the correct behaviour when
>     >> there are NAs in the (extended) residuals is
>     >> 
>     >> 1 omit NAs from the residual quantile calculation
>     >> (easiest)
> 
>        > I see no reason not to choose (1), At the time we prepared
>        > the 3rd edition of 'Data Analysis and Graphics using R?,
>        > this was the behaviour. My understanding of
>        > ?na.action=na.exclude? has been that the result is as for
>        > ?na.action=na.omit?, except that residuals match up with
>        > the original observations, with NAs inserted as necessary.
>        > In other words, the change from ?na.action=na.omit? to
>        > ?na.action=na.exclude? is all about wharf appears when one
>        > explicitly calculates and returns residuals, not about
>        > what happens when summary information (quantiles, not the
>        > residuals themselves!) is printed.
> 
>        > This strategy also simplifies documenting and describing
>        > what is done.
> 
>     >> 2 return NA values for all quantiles of the residual 
> 
>     >> 3 return the quantiles plus a statement of the number of NAs.
>     >> 
>     >> Any good reason not to just do #1?
> 
> We should  follow the behavior of lm()
> in all such cases of doubt unless we have very very strong
> reasons not to follow lm().
> It has been *the* example and motivator to a big extent AFAIR
> for the  na.action  semantics when they were introduced (in S).

  I just checked, and it definitely na.omits (it pulls out the
'residuals' component from the summary object).

  I've already pushed a fix along these lines (different implementation,
but same behaviour) to Github, although I haven't pushed tests or
updated the NEWS file ...

  Ben

> 
> Martin
> 
>     > John Maindonald email: john.maindonald at anu.edu.au phone :
>     > +61 2 (6125)3473 fax : +61 2(6125)5549 Centre for
>     > Mathematics & Its Applications, Room 1194, John Dedman
>     > Mathematical Sciences Building (Building 27) Australian
>     > National University, Canberra ACT 0200.
>


From ljyanes at gmail.com  Mon Sep  8 03:28:25 2014
From: ljyanes at gmail.com (Leo Yanes)
Date: Mon, 8 Sep 2014 11:28:25 +1000
Subject: [R-sig-ME] Errors message from glmmADMB package: Zero Inflated,
 Negative Binomial for large panel dataset
Message-ID: <CANThQJM_-o3t7NtW0QbK8gb0ZEcENiipBhpLcYRi6ufZZCtVBw@mail.gmail.com>

Colleagues,

I have a large panel dataset (7.8 million observations, of which 7.2
million are zeroes), and when I try to estimate a zero-inflated, negative
binomial using the glmmADMB package, I get an error message and am at a
loss.

The dataset has been declared as panel using the 'plm' package, and is
called 'pdat' (in use below). The time variable is 'month' (29 months of
data) and the panel identifier is 'studentbin' (~270k studentbins). The
estimation is about counts for student commencements ('commence') as a
function of subsidy rates for each student bin over time, amongst other
independent variables. All up, the .RData file is about ~200Mb of hard
drive space.
Here is the code:
*> fit_zinb <- glmmadmb ( commence ~ subsidy + month + (1|studentbin),
data=pdat, zeroInflation=TRUE, family="nbinom")*

and here is the error message:
Error in II[, ii] = II[, ii] + REmat$codes[[i]] :
number of items to replace is not a multiple of replacement length
In addition: Warning messages:
1: In `[.data.frame`(object, !omit, , drop = FALSE) :
Reached total allocation of 8097Mb: see help(memory.size)
2: In `[.data.frame`(object, !omit, , drop = FALSE) :
Reached total allocation of 8097Mb: see help(memory.size)
3: In glmmadmb ( commence ~ subsidy + month + (1 | studentbin), data =
pdat, :
NAs removed in constructing fixed-effect model frame: you should probably
remove them manually, e.g. with na.omit()
4: In II[, ii] + REmat$codes[[i]] :
longer object length is not a multiple of shorter object length

Any proposed solutions or leads will be most welcome, including alternative
packages which could work for this estimation problem.

Thanks in advance for any help,

Leo Yanes

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue Sep  9 20:16:20 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 09 Sep 2014 14:16:20 -0400
Subject: [R-sig-ME] Errors message from glmmADMB package: Zero Inflated,
 Negative Binomial for large panel dataset
In-Reply-To: <CANThQJM_-o3t7NtW0QbK8gb0ZEcENiipBhpLcYRi6ufZZCtVBw@mail.gmail.com>
References: <CANThQJM_-o3t7NtW0QbK8gb0ZEcENiipBhpLcYRi6ufZZCtVBw@mail.gmail.com>
Message-ID: <540F43F4.8010808@gmail.com>

On 14-09-07 09:28 PM, Leo Yanes wrote:
> Colleagues,
> 
> I have a large panel dataset (7.8 million observations, of which 7.2
> million are zeroes), and when I try to estimate a zero-inflated, negative
> binomial using the glmmADMB package, I get an error message and am at a
> loss.
> 
> The dataset has been declared as panel using the 'plm' package

  I'm not sure what that means, but I'm pretty sure that it's ignored by
glmmADMB (and lme4).

  I think this data set is simply not going to work with glmmADMB, which
tries to construct a *dense* Z model matrix.  I hope you realize that
this is an ambitious project!

, and is
> called 'pdat' (in use below). The time variable is 'month' (29 months of
> data) and the panel identifier is 'studentbin' (~270k studentbins). The
> estimation is about counts for student commencements ('commence') as a
> function of subsidy rates for each student bin over time, amongst other
> independent variables. All up, the .RData file is about ~200Mb of hard
> drive space.
> Here is the code:
> *> fit_zinb <- glmmadmb ( commence ~ subsidy + month + (1|studentbin),
> data=pdat, zeroInflation=TRUE, family="nbinom")*
> 

  Some questions and suggestions:

(1) run a hurdle model in glmer (i.e. two-stage: binomial 0 vs. positive
followed by a negative binomial analysis of the positive data only),
ignoring the fact that the second (NB) stage will be truncated (use
glmer.nb for the second stage). Run simulations etc. to figure out how
much that matters.

(2) Use expectation-maximization code (zipme at
https://groups.nceas.ucsb.edu/non-linear-modeling/projects/owls/R/owls_R_funs.R
) to fit a zero-inflated Poisson model, then correct for overdispersion
in the Poisson model in some reasonable way (e.g. compute the
overdispersion parameter phi via (sum(dev resids^2)/df.residual) and
inflate the standard errors by the square root of phi)

(3) hand-code your model in TMB (see https://github.com/adcomp) or AD
Model Builder, using the fact that you have a simple/nested design to
avoid constructing a gigantic random-effects model matrix (Z), i.e. your
code would be of the form

  eta[i] <- beta0+beta1*subsidy[i]+beta2*month[i]+u[studentbin[i]]
...

However, you'll still have to deal with the fact that you're doing
nonlinear optimization of a model with 270,000 (!) parameters ...

I don't know if anyone has come up with an iterative map/reduce
formulation for simple (single scalar random effect, or at least nested)
mixed models, but I would certainly be interested/that seems like a good
thing to do. (For this case, it should be possible to break the PWRSS
calculation up into independent blocks ...)


From morrisong at missouri.edu  Tue Sep  9 20:56:51 2014
From: morrisong at missouri.edu (Morrison, Ginnie D.)
Date: Tue, 9 Sep 2014 18:56:51 +0000
Subject: [R-sig-ME] Using lmer on an augmented alpha square model
Message-ID: <1EE7532B8A3B5C4B9B8D89578232346F4B5D1ADF@UM-MBX-N02.um.umsystem.edu>

Hello,
This question is actually several questions rolled into one. I'm starting to analyze data from an experiment setup as an augmented design. There are a number of effects to keep track of and a good deal of nesting. To give a snapshot of the data:

     >head(data)
     Relative_Date Gen Check3 Environment GinnieEntry Trial Entry Block_uni
    1            68  S0      0           1        1362     1   681     5:1:1
    2            70  S1      0           1        1361     1   681     5:1:1
    3            72  S0      0           1        1360     1   680     5:1:1
    4            72  S1      0           1        1359     1   680     5:1:1
    5            71  S0      0           1        1282     1   641     5:1:1
    6            72  S1      0           1        1281     1   641     5:1:1

    >str(data)
    'data.frame':    5040 obs. of  8 variables:
 $ Relative_Date: num  68 70 72 72 71 72 68 69 67 71 ...
 $ Gen          : Factor w/ 2 levels "S0","S1": 1 2 1 2 1 2 1 2 1 2 ...
 $ Check3       : Factor w/ 3 levels "0","2000","2001": 1 1 1 1 1 1 1 1 1 1 ...
 $ Environment  : Factor w/ 3 levels "1","2","3": 1 1 1 1 1 1 1 1 1 1 ...
 $ GinnieEntry  : Factor w/ 1850 levels "1","2","3","4",..: 1362 1361 1360 1359 1282 1281 1538 1537 1264 1263 ...
 $ Trial        : Factor w/ 2 levels "1","0": 1 1 1 1 1 1 1 1 1 1 ...
 $ Entry        : int  681 681 680 680 641 641 769 769 632 632 ...
 $ Block_uni    : Factor w/ 210 levels "1:1:2","1:1:3",..: 127 127 127 127 127 127 127 127 127 127 ...

Checks are either: you're not a check, or you're Check 1 or 2. Each Entry has two GinnieEntries, one of which is Gen S0, the other S1. Trial indicates if you are in the trial (not a check), or not. GinnieEntries should be kept paired as they are related, which is part of what we're interested in.

To the best of my understanding, an appropriate model, if were ignoring Entry for now, would be:

   >lmm1<-lmer(Relative_Date~Gen+Check3+(1|Environment)+(1|GinnieEntry:Trial)+(1|Block_uni),data=data)

However, there is the issue of the GinnieEntry being nested within Entry, which, if I understand correctly, you cannot explicitly model with lme4. I understand that this is due to how lmer does the random effects analysis. So to see what happens when I add in the Entry:Trial term, I ran 3 more models:
    >lmm2<-lmer(Relative_Date~Gen+Check3+(1|Environment)+(1|GinnieEntry:Trial)+(1|Entry)+(1|Block_uni),data=data)

    >lmm3<-lmer(Relative_Date~Gen+Check3+(1|Environment)+(1|GinnieEntry)+(1|Entry:Trial)+(1|Block_uni),data=data)

    >lmm4<-lmer(Relative_Date~Gen+Check3+(1|Environment)+(1|GinnieEntry)+(1|Entry)+(1|Block_uni),data=data)

The scary thing is that all the random effects (and fixed effects) remain the same between all models. Which is to say,
ranef(lmm1)$'GinnieEntry:Trial' == ranef(lmm2)$'GinnieEntry:Trial' == ranef(lmm3)$'GinnieEntry' == ranef(lmm4)$'GinnieEntry'
(which goes for Environment, Entry in the same way, and Block_uni). Is this an artifact of my data? Do I not understand the whole Trial:Entry type of interaction? Is there something up with the way nesting works? Or have I formatted the data (I assume Check3 or Trial) in such a way that I am not doing what I think I am? Any insight into this would be great--this is the first time I'm working with an augmented experiment, and most of the programming documentation I can find uses SAS for such an analysis. I can provide more info as needed.
Thank you,
Ginnie Morrison
Post-doctoral Fellow
University of Missouri, Columbia

	[[alternative HTML version deleted]]


From mrahmankufmrt at gmail.com  Wed Sep 10 10:28:18 2014
From: mrahmankufmrt at gmail.com (Moshiur Rahman)
Date: Wed, 10 Sep 2014 16:28:18 +0800
Subject: [R-sig-ME] Warning message in glmmADMB
Message-ID: <CAGNSkSng5Q1ff+NR9_KfQq699vLNb=Wga1XRKjD0SLoYMzOnkQ@mail.gmail.com>

Dear R mixed model experts,

Can anyone one confirm me if I get a warning message using glmmADMB for the
significance tests of random effects by comparing models with LRTs? I'm
using glmmADMB version 0.8.0 in R (version 3.1.0) and getting the following
warning message:

"Warning message:
In anova.glmmadmb(m1, m2) :
  rearranging models in order of increasing complexity"

Just for your kind information, I found an explanation from Ben Bolker
where he says that the updated version will fix / clarify this problem (
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2012q1/017920.html). Is
it the version that I'm using?

I'm using this glmmADMB model for my zeroinflated and poisson data. If it
is not the appropriate model because of this warning, could you please
suggest me an alternative model (e.g. MCMCglmm)?

If I asked something odd/silly for this group,  sorry for that and please
ignore it.

?Thanks in advance,

Moshi

	[[alternative HTML version deleted]]


From ukoether at uke.de  Wed Sep 10 10:46:46 2014
From: ukoether at uke.de (=?UTF-8?B?VWxmIEvDtnRoZXI=?=)
Date: Wed, 10 Sep 2014 10:46:46 +0200
Subject: [R-sig-ME] Warning message in glmmADMB
In-Reply-To: <CAGNSkSng5Q1ff+NR9_KfQq699vLNb=Wga1XRKjD0SLoYMzOnkQ@mail.gmail.com>
References: <CAGNSkSng5Q1ff+NR9_KfQq699vLNb=Wga1XRKjD0SLoYMzOnkQ@mail.gmail.com>
Message-ID: <54100FF6.2040700@uke.de>

Dear Moshi,

just rearrange the tested models (as it is stated in the warning), e.g.:

anova(m2,m1)

and the warning should go away. It's only that the warning informs you
about the changed order of the models listed by the anova-result with
the smaller model (less df) being listed first. It does not say anything
about an inappropriate test...

Kind regards, Ulf


Am 10.09.2014 um 10:28 schrieb Moshiur Rahman:
> Dear R mixed model experts,
> 
> Can anyone one confirm me if I get a warning message using glmmADMB for the
> significance tests of random effects by comparing models with LRTs? I'm
> using glmmADMB version 0.8.0 in R (version 3.1.0) and getting the following
> warning message:
> 
> "Warning message:
> In anova.glmmadmb(m1, m2) :
>   rearranging models in order of increasing complexity"
> 
> Just for your kind information, I found an explanation from Ben Bolker
> where he says that the updated version will fix / clarify this problem (
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2012q1/017920.html). Is
> it the version that I'm using?
> 
> I'm using this glmmADMB model for my zeroinflated and poisson data. If it
> is not the appropriate model because of this warning, could you please
> suggest me an alternative model (e.g. MCMCglmm)?
> 
> If I asked something odd/silly for this group,  sorry for that and please
> ignore it.
> 
> ?Thanks in advance,
> 
> Moshi
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
________________________________________

Dipl.-Psych. Ulf K?ther

PEPP-Team
Klinik f?r Psychiatrie und Psychotherapie
Universit?tsklinikum Hamburg-Eppendorf
Martinistr. 52
20246 Hamburg

Tel.: +49 (0) 40 7410 53248
Email: pepp at uke.de

Pers?nlich:
Tel.: +49 (0) 40 7410 55851
Mobil: (9) 55851
Email: ukoether at uke.de
________________________________________
--

DANKE F?R 125 JAHRE ENGAGEMENT UND VERTRAUEN.
www.uke.de/125
_____________________________________________________________________

Besuchen Sie uns auf: www.uke.de
_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg
Vorstandsmitglieder: Prof. Dr. Christian Gerloff (Vertreter des Vorsitzenden), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Rainer Schoppik
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

From Thierry.ONKELINX at inbo.be  Wed Sep 10 10:55:03 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 10 Sep 2014 08:55:03 +0000
Subject: [R-sig-ME] Using lmer on an augmented alpha square model
In-Reply-To: <1EE7532B8A3B5C4B9B8D89578232346F4B5D1ADF@UM-MBX-N02.um.umsystem.edu>
References: <1EE7532B8A3B5C4B9B8D89578232346F4B5D1ADF@UM-MBX-N02.um.umsystem.edu>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3AEA828@inbomail.inbo.be>

Dear Ginnie,

I presume that each GinnieEntry has only one trial? Otherwise it is impossible to have ranef(lmm2)$'GinnieEntry:Trial' == ranef(lmm3)$'GinnieEntry' If you have only one trial per GinnieEntry then (1|GinnieEntry) and (1|GinnieEntry:Trial) represent exactly the same information.

(1|Entry/GinnieEntry) is the notation for GinnieEntry nested in Entry. You can write this as (1|Entry) + (1|Entry:GinnieEntry). In case that the levels of GinnieEntry are unique (= used in only one Entry) then you have implicit nesting and (1|Entry) + (1|GinnieEntry) has the same interpretation as (1|Entry/GinnieEntry)

We will need a reproducible example to figure out why all models yield the same random effects.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Morrison, Ginnie D.
Verzonden: dinsdag 9 september 2014 20:57
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Using lmer on an augmented alpha square model

Hello,
This question is actually several questions rolled into one. I'm starting to analyze data from an experiment setup as an augmented design. There are a number of effects to keep track of and a good deal of nesting. To give a snapshot of the data:

     >head(data)
     Relative_Date Gen Check3 Environment GinnieEntry Trial Entry Block_uni
    1            68  S0      0           1        1362     1   681     5:1:1
    2            70  S1      0           1        1361     1   681     5:1:1
    3            72  S0      0           1        1360     1   680     5:1:1
    4            72  S1      0           1        1359     1   680     5:1:1
    5            71  S0      0           1        1282     1   641     5:1:1
    6            72  S1      0           1        1281     1   641     5:1:1

    >str(data)
    'data.frame':    5040 obs. of  8 variables:
 $ Relative_Date: num  68 70 72 72 71 72 68 69 67 71 ...
 $ Gen          : Factor w/ 2 levels "S0","S1": 1 2 1 2 1 2 1 2 1 2 ...
 $ Check3       : Factor w/ 3 levels "0","2000","2001": 1 1 1 1 1 1 1 1 1 1 ...
 $ Environment  : Factor w/ 3 levels "1","2","3": 1 1 1 1 1 1 1 1 1 1 ...
 $ GinnieEntry  : Factor w/ 1850 levels "1","2","3","4",..: 1362 1361 1360 1359 1282 1281 1538 1537 1264 1263 ...
 $ Trial        : Factor w/ 2 levels "1","0": 1 1 1 1 1 1 1 1 1 1 ...
 $ Entry        : int  681 681 680 680 641 641 769 769 632 632 ...
 $ Block_uni    : Factor w/ 210 levels "1:1:2","1:1:3",..: 127 127 127 127 127 127 127 127 127 127 ...

Checks are either: you're not a check, or you're Check 1 or 2. Each Entry has two GinnieEntries, one of which is Gen S0, the other S1. Trial indicates if you are in the trial (not a check), or not. GinnieEntries should be kept paired as they are related, which is part of what we're interested in.

To the best of my understanding, an appropriate model, if were ignoring Entry for now, would be:

   >lmm1<-lmer(Relative_Date~Gen+Check3+(1|Environment)+(1|GinnieEntry:Trial)+(1|Block_uni),data=data)

However, there is the issue of the GinnieEntry being nested within Entry, which, if I understand correctly, you cannot explicitly model with lme4. I understand that this is due to how lmer does the random effects analysis. So to see what happens when I add in the Entry:Trial term, I ran 3 more models:
    >lmm2<-lmer(Relative_Date~Gen+Check3+(1|Environment)+(1|GinnieEntry:Trial)+(1|Entry)+(1|Block_uni),data=data)

    >lmm3<-lmer(Relative_Date~Gen+Check3+(1|Environment)+(1|GinnieEntry)+(1|Entry:Trial)+(1|Block_uni),data=data)

    >lmm4<-lmer(Relative_Date~Gen+Check3+(1|Environment)+(1|GinnieEntry)+(1|Entry)+(1|Block_uni),data=data)

The scary thing is that all the random effects (and fixed effects) remain the same between all models. Which is to say, ranef(lmm1)$'GinnieEntry:Trial' == ranef(lmm2)$'GinnieEntry:Trial' == ranef(lmm3)$'GinnieEntry' == ranef(lmm4)$'GinnieEntry'
(which goes for Environment, Entry in the same way, and Block_uni). Is this an artifact of my data? Do I not understand the whole Trial:Entry type of interaction? Is there something up with the way nesting works? Or have I formatted the data (I assume Check3 or Trial) in such a way that I am not doing what I think I am? Any insight into this would be great--this is the first time I'm working with an augmented experiment, and most of the programming documentation I can find uses SAS for such an analysis. I can provide more info as needed.
Thank you,
Ginnie Morrison
Post-doctoral Fellow
University of Missouri, Columbia

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From mrahmankufmrt at gmail.com  Wed Sep 10 11:02:35 2014
From: mrahmankufmrt at gmail.com (Moshiur Rahman)
Date: Wed, 10 Sep 2014 17:02:35 +0800
Subject: [R-sig-ME] Warning message in glmmADMB
In-Reply-To: <54100FF6.2040700@uke.de>
References: <CAGNSkSng5Q1ff+NR9_KfQq699vLNb=Wga1XRKjD0SLoYMzOnkQ@mail.gmail.com>
	<54100FF6.2040700@uke.de>
Message-ID: <CAGNSkSk-rAbEMT8kEaKauBBxMRQQpDt7LVnjLWs-MHnW9eqgGA@mail.gmail.com>

Thanks a lot Ulf for your very quick response and confirmation.

Cheers,

Moshi

On Wed, Sep 10, 2014 at 4:46 PM, Ulf K?ther <ukoether at uke.de> wrote:

> Dear Moshi,
>
> just rearrange the tested models (as it is stated in the warning), e.g.:
>
> anova(m2,m1)
>
> and the warning should go away. It's only that the warning informs you
> about the changed order of the models listed by the anova-result with
> the smaller model (less df) being listed first. It does not say anything
> about an inappropriate test...
>
> Kind regards, Ulf
>
>
> Am 10.09.2014 um 10:28 schrieb Moshiur Rahman:
> > Dear R mixed model experts,
> >
> > Can anyone one confirm me if I get a warning message using glmmADMB for
> the
> > significance tests of random effects by comparing models with LRTs? I'm
> > using glmmADMB version 0.8.0 in R (version 3.1.0) and getting the
> following
> > warning message:
> >
> > "Warning message:
> > In anova.glmmadmb(m1, m2) :
> >   rearranging models in order of increasing complexity"
> >
> > Just for your kind information, I found an explanation from Ben Bolker
> > where he says that the updated version will fix / clarify this problem (
> > https://stat.ethz.ch/pipermail/r-sig-mixed-models/2012q1/017920.html).
> Is
> > it the version that I'm using?
> >
> > I'm using this glmmADMB model for my zeroinflated and poisson data. If it
> > is not the appropriate model because of this warning, could you please
> > suggest me an alternative model (e.g. MCMCglmm)?
> >
> > If I asked something odd/silly for this group,  sorry for that and please
> > ignore it.
> >
> > ?Thanks in advance,
> >
> > Moshi
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> --
> ________________________________________
>
> Dipl.-Psych. Ulf K?ther
>
> PEPP-Team
> Klinik f?r Psychiatrie und Psychotherapie
> Universit?tsklinikum Hamburg-Eppendorf
> Martinistr. 52
> 20246 Hamburg
>
> Tel.: +49 (0) 40 7410 53248
> Email: pepp at uke.de
>
> Pers?nlich:
> Tel.: +49 (0) 40 7410 55851
> Mobil: (9) 55851
> Email: ukoether at uke.de
> ________________________________________
> --
>
> DANKE F?R 125 JAHRE ENGAGEMENT UND VERTRAUEN.
> www.uke.de/125
> _____________________________________________________________________
>
> Besuchen Sie uns auf: www.uke.de
> _____________________________________________________________________
>
> Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen
> Rechts; Gerichtsstand: Hamburg
> Vorstandsmitglieder: Prof. Dr. Christian Gerloff (Vertreter des
> Vorsitzenden), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Rainer Schoppik
> _____________________________________________________________________
>
> SAVE PAPER - THINK BEFORE PRINTING
>



-- 
MD. MOSHIUR RAHMAN
PhD Candidate
School of Animal Biology/Zoology (M092)
University of Western Australia
35 Stirling Hwy, Crawley, WA, 6009
Australia.
Mob.: 061-425205507

	[[alternative HTML version deleted]]


From starzynski at uni-heidelberg.de  Wed Sep 10 11:56:34 2014
From: starzynski at uni-heidelberg.de (Christian Starzynski)
Date: Wed, 10 Sep 2014 11:56:34 +0200
Subject: [R-sig-ME] Comparisons of models with and without a threshold
Message-ID: <54102052.2010908@uni-heidelberg.de>

Dear All

I have data from multiple subjects that leads to the assumption that the
dependent variable stays constant up to some value of the independent
variable (here x=3) and decreases linearly for bigger x. I'd like to
test a model with a threshold behavior with a purely linear model.

Here is a minimal example
##example start
library(lme4)
#generate some data
#threshold set at k=3
data <- data.frame(subj=rep(c("A", "B", "C"), each=10), x=rep(seq(1,10),
times=3), y=0)
data[data$subj=="A",]$y <- c(rnorm(3, mean=0.5, sd=0.1), rnorm(7,
mean=-1, sd=0.1)*seq(4,10))
data[data$subj=="B",]$y <- c(rnorm(3, mean=1, sd=0.1), rnorm(7, mean=-1,
sd=0.1)*seq(4,10))
data[data$subj=="C",]$y <- c(rnorm(3, mean=2, sd=0.1), rnorm(7, mean=-1,
sd=0.1)*seq(4,10))
data <- transform(data, k=as.numeric(x>3))

#model without threshold
fm0 <- lmer(y ~ x + (1|subj), data=data, REML=F)

#model with threshold
fm1 <- lmer(y ~ x:k + (1|subj), data=data, REML=F)
##example end

-Is it valid to use a likelihood ratio test as done in anova(fm0, fm1)
to show the better fit of the threshold model?

-If(yes){Is it correct to adjust the p-value by add 1 to df of the
threshold model because k is a free parameter?}

-else{May I use BIC instead? Do I need to adjust df}


Thanks in advance!

Christian

-- 
Christian Starzynski

Neurologische Klinik
Universit?tsklinikum Heidelberg
Im Neuenheimer Feld 400
69120 Heidelberg


From barbara.baraibar at udl.cat  Wed Sep 10 13:27:44 2014
From: barbara.baraibar at udl.cat (=?ISO-8859-1?Q?B=E1rbara_Baraibar_Padr=F3?=)
Date: Wed, 10 Sep 2014 13:27:44 +0200
Subject: [R-sig-ME] GLMM for repeated measures in space and time series
Message-ID: <541035B0.3080500@hbj.udl.cat>

Hello,

I'm trying to choose the correct model to analyze my data and I need 
some help. I'm measuring seed predation (I leave 1 gram of seeds for 48 
in the field and after 48 hours I take what is left and weigh it again). 
I do this in the same 50 petri dishes (stations), 25 of which have one 
weed species and the other 25 have another and repeat the same in 3 
different fields during 3 months. So, I have a nested design with:

Fixed effects: Weed_species, Date (time)

Random effects: Station, Field

My results are a bit weird in the sense that I have a lot of dishes with 
100% seeds predated and some with 0% predated and few in the middle.

My boss says that my response variable follows a binomial distribution 
because each seed can be either predated or not, so I have constructed a 
response variable with a success column 
(seeds_predated/initial_seedweight) and a failure column 
(initial_seedweight-seeds_predated)/initial_seedweight

I have tried a GLMM like the one below and I would like to know if the 
model is ok for this kind of data (repeated measures in space and in 
different times) and how I can validate the model. I have done a Binned 
residuals plot and almost all my residuals fit within the intervals, do 
I need to do something else?

Thank you very much!!!

success<- seeds_predated/initial_seedweight

failure <- (initial_seedweight-seeds_predated)/initial_seedweight

resposta<- cbind (success, failure)

GLMM1<-glmer(resposta ~ Weed_species + Data + (1|Station/Field), 
family=binomial)

Warning message:In eval(expr, envir, enclos) : non-integer counts in a 
binomial glm!

Generalized linear mixed model fit by maximum likelihood 
['glmerMod']Family: binomial ( logit )Formula: Depredacio ~ Especie + 
Data + (1 | Station/Camp)
AICBIClogLikdeviance
479.6651501.8878 -233.8326467.6651

Random effects:
GroupsNameVarianceStd.Dev.
Camp:Station (Intercept) 5.036e-10 2.244e-05
Station(Intercept) 0.000e+00 0.000e+00
Number of obs: 300, groups: Camp:Station, 100; Station, 50

Fixed effects:
      Estimate Std. Error z value Pr(>|z|)
(Intercept)-0.41330.1787-2.3130.02072 *
EspecieLolium0.50080.21002.3850.01709 *
Data2-0.84620.2681-3.1560.00160 **
Data30.74700.25412.9400.00328 **
---Signif. codes:0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' '1

Correlation of Fixed Effects:
(Intr) EspcLl Data2
EspecieLolm -0.600
Data2-0.404 -0.037
Data3-0.4730.0380.299

-- 
Barbara Baraibar Padro
ETSEA- Universitat de Lleida
Dep. Hortofruticultura, Botanica i Jardineria
Av. Rovira Roure 191
25198 Lleida (Spain)
Telf: +34 973 702912


From josipa at iptpo.hr  Wed Sep 10 11:15:39 2014
From: josipa at iptpo.hr (Josipa =?utf-8?b?UGVya292acSH?=)
Date: Wed, 10 Sep 2014 09:15:39 +0000 (UTC)
Subject: [R-sig-ME] help on choosin right model for data
References: <000001cfbdf3$689a77d0$39cf6770$@iptpo.hr>
	<loom.20140830T040446-860@post.gmane.org>
Message-ID: <loom.20140910T110518-856@post.gmane.org>

Thank you for your answer.

The problem is I don't have multiple sensors for each mulch*fertilizer
combination. So no repetitions.
Technically it was not suitable ti have so many sensors in the field.
For each combination (there are 12 of them : 4 fertilizers x 3 mulches) I
set up only one sensor in the field but I made sure everything was in the
same repetition (If you remember experiment is a two factorial split-plot in
three repetitions).

Also sensors collected data through the whole day, every 10 minutes, for the
whole vegetative seson (3,5 monts).

Josipa Perkovic


From bbolker at gmail.com  Wed Sep 10 20:52:29 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 10 Sep 2014 14:52:29 -0400
Subject: [R-sig-ME] Confidence intervals
In-Reply-To: <9866_1410348417_s8ABQvPO010284_54103578.7020609@rwth-aachen.de>
References: <9866_1410348417_s8ABQvPO010284_54103578.7020609@rwth-aachen.de>
Message-ID: <54109DED.2080201@mcmaster.ca>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 14-09-10 07:26 AM, Maik Theelen wrote:
> Dear Ben Bolker,
> 
> I am trying to calculate CI?s for the fixed effects in a lmer
> model.

  Relatively simple questions should *very* preferably be sent to the
r-sig-mixed-models mailing list (cc'd here), please ...

> I am now using the following code
> 
> FUN <- function(fit) { return(fixef(fit)) }
> 
> result <- bootMer(Model, FUN, nsim = 5000)
> 
> bCI.1 <- boot.ci(result, index=1, type="perc") bCI.2 <-
> boot.ci(result, index=1, type="perc") bCI.3 <- boot.ci(result,
> index=1, type="perc") bCI.4 <- boot.ci(result, index=1,
> type="perc")
> 
> Would this be a correct way?

  Are you sure you want index=1 in each case?  Maybe you want
index={1,2,3,4}?

  5000 sims seems like overkill unless your model is very unstable

> 
> When I use *confint* I get the following warning:
> 
> In norm.inter(t, alpha) : extreme order statistics used as
> endpoints

  I don't know exactly why this warning occurs -- you would probably
need to dig in a little bit more and/or read Davison & Hinkley's book
on which the boot package is based? (based on brief googling, it seems
as though your distributions may be badly behaved/need *more*
bootstrap samples).  Plotting the bootstrap distribution, as shown in
example("bootMer"), might be a good idea.


> 
> I would highly appreciate it if you would find the time to answer
> my question.
> 
> Kind Regards,
> 
> Maik Theelen



-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJUEJ3tAAoJEOCV5YRblxUHlrIIALcA15zLu3cMMu9R7WlLo4LQ
M9CeC59ASSRdsVzW3h3LV5etsvku5XmigBMJQEi4MMfdz6avpw6ZQddRoNeHmjKb
4vJXCgO2a7sbTpz48E15ZA1YFxcDp82dxqIIrm2E2zdP4vQYXdqyAWFSuvbr4qg5
LC3DnqtSdwIR0+2XDPN6stN+Au+iWZPZ18hgfIv83xN2D7rP0GGLh9/GaSeaCXuQ
5BJLyEnoQSo9rWpySznBshSK5187orRB2dHKECL2E7AKWs4WTaPazm6QtzhDK34r
O26WN5RHDkvEDr6n3ZtWp/lAP7yo4w6FyPvASFr573S/VGiVAXpWEs64TfIt38k=
=+jy7
-----END PGP SIGNATURE-----


From Maik.Theelen at rwth-aachen.de  Wed Sep 10 21:58:39 2014
From: Maik.Theelen at rwth-aachen.de (Theelen, Maik Matheus Paul)
Date: Wed, 10 Sep 2014 19:58:39 +0000
Subject: [R-sig-ME] Confidence intervals
In-Reply-To: <54109DED.2080201@mcmaster.ca>
References: <9866_1410348417_s8ABQvPO010284_54103578.7020609@rwth-aachen.de>,
	<54109DED.2080201@mcmaster.ca>
Message-ID: <01946E85F389EF42ADD3DE83A3560B3B3B246318@MBX-W1.rwth-ad.de>

Dear Ben,

Thank you very much for the answer. Yes, index should indeed be 1 2 3 4 (it was a typo).
Next time I will send it to the r-sig-mixed-models mailing list.

Would the method that I used be pretty much be the same as using confint with method = boot?

Kind regards,

Maik
________________________________________
Van: Ben Bolker [bbolker at gmail.com]
Verzonden: woensdag 10 september 2014 20:52
Aan: Theelen, Maik Matheus Paul; r-sig-mixed-models at r-project.org
Onderwerp: Re: Confidence intervals

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 14-09-10 07:26 AM, Maik Theelen wrote:
> Dear Ben Bolker,
>
> I am trying to calculate CI?s for the fixed effects in a lmer
> model.

  Relatively simple questions should *very* preferably be sent to the
r-sig-mixed-models mailing list (cc'd here), please ...

> I am now using the following code
>
> FUN <- function(fit) { return(fixef(fit)) }
>
> result <- bootMer(Model, FUN, nsim = 5000)
>
> bCI.1 <- boot.ci(result, index=1, type="perc") bCI.2 <-
> boot.ci(result, index=1, type="perc") bCI.3 <- boot.ci(result,
> index=1, type="perc") bCI.4 <- boot.ci(result, index=1,
> type="perc")
>
> Would this be a correct way?

  Are you sure you want index=1 in each case?  Maybe you want
index={1,2,3,4}?

  5000 sims seems like overkill unless your model is very unstable

>
> When I use *confint* I get the following warning:
>
> In norm.inter(t, alpha) : extreme order statistics used as
> endpoints

  I don't know exactly why this warning occurs -- you would probably
need to dig in a little bit more and/or read Davison & Hinkley's book
on which the boot package is based? (based on brief googling, it seems
as though your distributions may be badly behaved/need *more*
bootstrap samples).  Plotting the bootstrap distribution, as shown in
example("bootMer"), might be a good idea.


>
> I would highly appreciate it if you would find the time to answer
> my question.
>
> Kind Regards,
>
> Maik Theelen



-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJUEJ3tAAoJEOCV5YRblxUHlrIIALcA15zLu3cMMu9R7WlLo4LQ
M9CeC59ASSRdsVzW3h3LV5etsvku5XmigBMJQEi4MMfdz6avpw6ZQddRoNeHmjKb
4vJXCgO2a7sbTpz48E15ZA1YFxcDp82dxqIIrm2E2zdP4vQYXdqyAWFSuvbr4qg5
LC3DnqtSdwIR0+2XDPN6stN+Au+iWZPZ18hgfIv83xN2D7rP0GGLh9/GaSeaCXuQ
5BJLyEnoQSo9rWpySznBshSK5187orRB2dHKECL2E7AKWs4WTaPazm6QtzhDK34r
O26WN5RHDkvEDr6n3ZtWp/lAP7yo4w6FyPvASFr573S/VGiVAXpWEs64TfIt38k=
=+jy7
-----END PGP SIGNATURE-----


From chris at trickysolutions.com.au  Thu Sep 11 01:59:00 2014
From: chris at trickysolutions.com.au (Chris Howden)
Date: Thu, 11 Sep 2014 09:59:00 +1000
Subject: [R-sig-ME] GLMM for repeated measures in space and time series
In-Reply-To: <541035B0.3080500@hbj.udl.cat>
References: <541035B0.3080500@hbj.udl.cat>
Message-ID: <8058581975766643105@unknownmsgid>

Hi Barbara,

The SD explained by your random effects is very small, it actually
looks to be 0 for station! So you may not need them at all, or at
least not the station one.

Also although your raw seed eaten data does follow a binomial
distribution you aren't modelling the counts ie number of seeds
predated. You are modelling the percentage predated, which is why you
are getting the warning message saying your response isn't an integer.
I'm not entirely sure how glmer handles this, it may be rounding your
percentages to the nearest integer, or may not be. You may want to
consider modelling the actual percentages using some other model
better suited to this? Possible a beta distribution (although I don't
think they can handle 0 and 100?s, but that can be solved by
adding/subtracting a very small amount). Or maybe even modelling the
weight consumed? Or even splitting it into 3 (or more) categories ie
all eaten, non eaten, some eaten.

Chris Howden
Founding Partner
Tricky Solutions
Tricky Solutions 4 Tricky Problems
Evidence Based Strategic Development, IP Commercialisation and
Innovation, Data Analysis, Modelling and Training

(mobile) 0410 689 945
(fax / office)
chris at trickysolutions.com.au

Disclaimer: The information in this email and any attachments to it are
confidential and may contain legally privileged information. If you are not
the named or intended recipient, please delete this communication and
contact us immediately. Please note you are not authorised to copy,
use or disclose this communication or any attachments without our
consent. Although this email has been checked by anti-virus software,
there is a risk that email messages may be corrupted or infected by
viruses or other
interferences. No responsibility is accepted for such interference. Unless
expressly stated, the views of the writer are not those of the
company. Tricky Solutions always does our best to provide accurate
forecasts and analyses based on the data supplied, however it is
possible that some important predictors were not included in the data
sent to us. Information provided by us should not be solely relied
upon when making decisions and clients should use their own judgement.

> On 11 Sep 2014, at 0:42, "B?rbara Baraibar Padr?" <barbara.baraibar at udl.cat> wrote:
>
> Hello,
>
> I'm trying to choose the correct model to analyze my data and I need some help. I'm measuring seed predation (I leave 1 gram of seeds for 48 in the field and after 48 hours I take what is left and weigh it again). I do this in the same 50 petri dishes (stations), 25 of which have one weed species and the other 25 have another and repeat the same in 3 different fields during 3 months. So, I have a nested design with:
>
> Fixed effects: Weed_species, Date (time)
>
> Random effects: Station, Field
>
> My results are a bit weird in the sense that I have a lot of dishes with 100% seeds predated and some with 0% predated and few in the middle.
>
> My boss says that my response variable follows a binomial distribution because each seed can be either predated or not, so I have constructed a response variable with a success column (seeds_predated/initial_seedweight) and a failure column (initial_seedweight-seeds_predated)/initial_seedweight
>
> I have tried a GLMM like the one below and I would like to know if the model is ok for this kind of data (repeated measures in space and in different times) and how I can validate the model. I have done a Binned residuals plot and almost all my residuals fit within the intervals, do I need to do something else?
>
> Thank you very much!!!
>
> success<- seeds_predated/initial_seedweight
>
> failure <- (initial_seedweight-seeds_predated)/initial_seedweight
>
> resposta<- cbind (success, failure)
>
> GLMM1<-glmer(resposta ~ Weed_species + Data + (1|Station/Field), family=binomial)
>
> Warning message:In eval(expr, envir, enclos) : non-integer counts in a binomial glm!
>
> Generalized linear mixed model fit by maximum likelihood ['glmerMod']Family: binomial ( logit )Formula: Depredacio ~ Especie + Data + (1 | Station/Camp)
> AICBIClogLikdeviance
> 479.6651501.8878 -233.8326467.6651
>
> Random effects:
> GroupsNameVarianceStd.Dev.
> Camp:Station (Intercept) 5.036e-10 2.244e-05
> Station(Intercept) 0.000e+00 0.000e+00
> Number of obs: 300, groups: Camp:Station, 100; Station, 50
>
> Fixed effects:
>     Estimate Std. Error z value Pr(>|z|)
> (Intercept)-0.41330.1787-2.3130.02072 *
> EspecieLolium0.50080.21002.3850.01709 *
> Data2-0.84620.2681-3.1560.00160 **
> Data30.74700.25412.9400.00328 **
> ---Signif. codes:0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' '1
>
> Correlation of Fixed Effects:
> (Intr) EspcLl Data2
> EspecieLolm -0.600
> Data2-0.404 -0.037
> Data3-0.4730.0380.299
>
> --
> Barbara Baraibar Padro
> ETSEA- Universitat de Lleida
> Dep. Hortofruticultura, Botanica i Jardineria
> Av. Rovira Roure 191
> 25198 Lleida (Spain)
> Telf: +34 973 702912
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Thu Sep 11 02:30:38 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 10 Sep 2014 20:30:38 -0400
Subject: [R-sig-ME] GLMM for repeated measures in space and time series
In-Reply-To: <8058581975766643105@unknownmsgid>
References: <541035B0.3080500@hbj.udl.cat> <8058581975766643105@unknownmsgid>
Message-ID: <CABghstQ_c=mwh+M-fK4o2ykT+8TMQ=+pPR03+cBLPfRnYE7gGA@mail.gmail.com>

Just a quick comment:

On Wed, Sep 10, 2014 at 7:59 PM, Chris Howden <chris at trickysolutions.com.au>
wrote:

> Hi Barbara,
>
> The SD explained by your random effects is very small, it actually
> looks to be 0 for station! So you may not need them at all, or at
> least not the station one.
>

  But this may not be worth worrying about until after you've sorted out
the correct model syntax (see below).


>
> Also although your raw seed eaten data does follow a binomial
> distribution you aren't modelling the counts ie number of seeds
> predated. You are modelling the percentage predated, which is why you
> are getting the warning message saying your response isn't an integer.
> I'm not entirely sure how glmer handles this, it may be rounding your
> percentages to the nearest integer, or may not be.


  It doesn't round, but the answers may not make sense.


> You may want to
> consider modelling the actual percentages using some other model
> better suited to this? Possible a beta distribution (although I don't
> think they can handle 0 and 100?s, but that can be solved by
> adding/subtracting a very small amount). Or maybe even modelling the
> weight consumed? Or even splitting it into 3 (or more) categories ie
> all eaten, non eaten, some eaten.
>

  These are all possible, but the most-likely-correct solution is to
specify the total number exposed at any given time in the 'weights'
argument, and/or specify the response variable as cbind(eaten,not_eaten)


> Chris Howden
> Founding Partner
> Tricky Solutions
> Tricky Solutions 4 Tricky Problems
> Evidence Based Strategic Development, IP Commercialisation and
> Innovation, Data Analysis, Modelling and Training
>
> (mobile) 0410 689 945
> (fax / office)
> chris at trickysolutions.com.au
>

[snip]


> > On 11 Sep 2014, at 0:42, "B?rbara Baraibar Padr?" <
> barbara.baraibar at udl.cat> wrote:
> >
> > Hello,
> >
> > I'm trying to choose the correct model to analyze my data and I need
> some help. I'm measuring seed predation (I leave 1 gram of seeds for 48 in
> the field and after 48 hours I take what is left and weigh it again). I do
> this in the same 50 petri dishes (stations), 25 of which have one weed
> species and the other 25 have another and repeat the same in 3 different
> fields during 3 months. So, I have a nested design with:
> >
> > Fixed effects: Weed_species, Date (time)
> >
> > Random effects: Station, Field
> >
> > My results are a bit weird in the sense that I have a lot of dishes with
> 100% seeds predated and some with 0% predated and few in the middle.
> >
> > My boss says that my response variable follows a binomial distribution
> because each seed can be either predated or not, so I have constructed a
> response variable with a success column (seeds_predated/initial_seedweight)
> and a failure column (initial_seedweight-seeds_predated)/initial_seedweight
> >
> > I have tried a GLMM like the one below and I would like to know if the
> model is ok for this kind of data (repeated measures in space and in
> different times) and how I can validate the model. I have done a Binned
> residuals plot and almost all my residuals fit within the intervals, do I
> need to do something else?
> >
> > Thank you very much!!!
> >
> > success<- seeds_predated/initial_seedweight
> >
> > failure <- (initial_seedweight-seeds_predated)/initial_seedweight
> >
> > resposta<- cbind (success, failure)
> >
> > GLMM1<-glmer(resposta ~ Weed_species + Data + (1|Station/Field),
> family=binomial)
> >
> > Warning message:In eval(expr, envir, enclos) : non-integer counts in a
> binomial glm!
> >
> > Generalized linear mixed model fit by maximum likelihood
> ['glmerMod']Family: binomial ( logit )Formula: Depredacio ~ Especie + Data
> + (1 | Station/Camp)
> > AICBIClogLikdeviance
> > 479.6651501.8878 -233.8326467.6651
> >
> > Random effects:
> > GroupsNameVarianceStd.Dev.
> > Camp:Station (Intercept) 5.036e-10 2.244e-05
> > Station(Intercept) 0.000e+00 0.000e+00
> > Number of obs: 300, groups: Camp:Station, 100; Station, 50
> >
> > Fixed effects:
> >     Estimate Std. Error z value Pr(>|z|)
> > (Intercept)-0.41330.1787-2.3130.02072 *
> > EspecieLolium0.50080.21002.3850.01709 *
> > Data2-0.84620.2681-3.1560.00160 **
> > Data30.74700.25412.9400.00328 **
> > ---Signif. codes:0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' '1
> >
> > Correlation of Fixed Effects:
> > (Intr) EspcLl Data2
> > EspecieLolm -0.600
> > Data2-0.404 -0.037
> > Data3-0.4730.0380.299
> >
> > --
> > Barbara Baraibar Padro
> > ETSEA- Universitat de Lleida
> > Dep. Hortofruticultura, Botanica i Jardineria
> > Av. Rovira Roure 191
> > 25198 Lleida (Spain)
> > Telf: +34 973 702912
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From lorenz.gygax at agroscope.admin.ch  Thu Sep 11 11:16:05 2014
From: lorenz.gygax at agroscope.admin.ch (lorenz.gygax at agroscope.admin.ch)
Date: Thu, 11 Sep 2014 09:16:05 +0000
Subject: [R-sig-ME] Confidence interval for relative contribution of random
 effect variance
Message-ID: <B291F8F571C9494EA3EAF8C8B471333F22E0C28A@WBF-C7001.bk.evdad.admin.ch>

Dear all,

earlier this year, I started to look into how I could estimate the relative contribution of the between-subjects variability relative to several levels of (summed) within-subject variabilities in the context of mixed models. Because I am using nlme and lme4 since quite a while that is where I started to look. In the end, I would like to have not only a point estimate but also a measure of precision, that is, either a confidence or credible interval.

When I started to look into this, I came across a two-year old suggestion by Ben Bolker that relied on mcmcsamp (http://stats.stackexchange.com/questions/30797/posterior-simulations-of-the-variances-with-the-mcmcsamp-function) which I liked because the Markov-chain would allow me to calculate the measure of interest for each simulation step and accordingly calculate e.g. an HPD-interval of the ratio of between- versus the (summed) within-subject variability.

Now, doing some more research in the R-archives, help files and vignettes, I realize that I have been off the sig-mixed-models list for too long (due to work load and yes, I will try to be better in future ;-) and that mcmcsamp is no longer supported/developed. On the other hand the function confint () now exists. Many thanks to the developers!

A side-line: Using the confint function on one of my models and comparing the confidence intervals with the point-estimates from the summary of the same model, it seems that confint reports confidence intervals for the estimated standard deviations of the random effects as well as of the error-variability whereas summary reports the standard deviations for the random effects but the variance for the residuals. Is this correct? I seem to remember some such discussion but could not find any note online that would have verified this fact. Page 31 in "Fitting linear mixed-effects models using lme4" discusses this part of the summary output but seems to be using the terms standard deviation and variance somewhat interchangeably (or, more likely, I failed to read it correctly).

Now, apart from this aspect, can confint be tweaked to calculate not only the confidence interval of the 'raw' parameters but also for some function of the parameters? If not, do I need to move to an implementation using MCMC methods (MCMCglmm, Bugs-type of approaches, STAN or Laplaces-Demon) to reach my aim or do you have another (simpler) suggestion?

Many thanks and regards, Lorenz
-
Lorenz Gygax, PD Dr. sc. nat., Scientist
Federal Food Safety and Veterinary Office FFSVO
Centre for Proper Housing of Ruminants and Pigs
T?nikon, CH-8356 Ettenhausen, Switzerland


From Thierry.ONKELINX at inbo.be  Thu Sep 11 12:10:22 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 11 Sep 2014 10:10:22 +0000
Subject: [R-sig-ME] Using lmer on an augmented alpha square model
In-Reply-To: <1EE7532B8A3B5C4B9B8D89578232346F4B5D1BBC@UM-MBX-N02.um.umsystem.edu>
References: <1EE7532B8A3B5C4B9B8D89578232346F4B5D1ADF@UM-MBX-N02.um.umsystem.edu>,
	<AA818EAD2576BC488B4F623941DA7427F3AEA828@inbomail.inbo.be>
	<1EE7532B8A3B5C4B9B8D89578232346F4B5D1BBC@UM-MBX-N02.um.umsystem.edu>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3AEABFD@inbomail.inbo.be>

Dear Ginnie,

Please keep the mailing list in cc.

Your models are essentially identical due to the design of your data. Hence you get identical random effects. You'll need to do some reading up on implicit and explicit nesting of data.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: Morrison, Ginnie D. [mailto:morrisong at missouri.edu]
Verzonden: woensdag 10 september 2014 14:20
Aan: ONKELINX, Thierry
Onderwerp: RE: Using lmer on an augmented alpha square model

Dear Theirry,
Yes, one trial for each GinnieEntry, my apologies. I am including an, unfortunately large dataframe (144 rows). This is simply so a sample model will converge! The random effects show the same effect of all being equal again. I am receiving some outside advice on the modeling, but whatever the case maybe, I am curious about the identical random effects.
Thank you for your time!
Ginnie

Large data from dump():
x <-

**data stripped**

________________________________________
From: ONKELINX, Thierry [Thierry.ONKELINX at inbo.be]
Sent: Wednesday, September 10, 2014 3:55 AM
To: Morrison, Ginnie D.; r-sig-mixed-models at r-project.org
Subject: RE: Using lmer on an augmented alpha square model

Dear Ginnie,

I presume that each GinnieEntry has only one trial? Otherwise it is impossible to have ranef(lmm2)$'GinnieEntry:Trial' == ranef(lmm3)$'GinnieEntry' If you have only one trial per GinnieEntry then (1|GinnieEntry) and (1|GinnieEntry:Trial) represent exactly the same information.

(1|Entry/GinnieEntry) is the notation for GinnieEntry nested in Entry. You can write this as (1|Entry) + (1|Entry:GinnieEntry). In case that the levels of GinnieEntry are unique (= used in only one Entry) then you have implicit nesting and (1|Entry) + (1|GinnieEntry) has the same interpretation as (1|Entry/GinnieEntry)

We will need a reproducible example to figure out why all models yield the same random effects.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Morrison, Ginnie D.
Verzonden: dinsdag 9 september 2014 20:57
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Using lmer on an augmented alpha square model

Hello,
This question is actually several questions rolled into one. I'm starting to analyze data from an experiment setup as an augmented design. There are a number of effects to keep track of and a good deal of nesting. To give a snapshot of the data:

     >head(data)
     Relative_Date Gen Check3 Environment GinnieEntry Trial Entry Block_uni
    1            68  S0      0           1        1362     1   681     5:1:1
    2            70  S1      0           1        1361     1   681     5:1:1
    3            72  S0      0           1        1360     1   680     5:1:1
    4            72  S1      0           1        1359     1   680     5:1:1
    5            71  S0      0           1        1282     1   641     5:1:1
    6            72  S1      0           1        1281     1   641     5:1:1

    >str(data)
    'data.frame':    5040 obs. of  8 variables:
 $ Relative_Date: num  68 70 72 72 71 72 68 69 67 71 ...
 $ Gen          : Factor w/ 2 levels "S0","S1": 1 2 1 2 1 2 1 2 1 2 ...
 $ Check3       : Factor w/ 3 levels "0","2000","2001": 1 1 1 1 1 1 1 1 1 1 ...
 $ Environment  : Factor w/ 3 levels "1","2","3": 1 1 1 1 1 1 1 1 1 1 ...
 $ GinnieEntry  : Factor w/ 1850 levels "1","2","3","4",..: 1362 1361 1360 1359 1282 1281 1538 1537 1264 1263 ...
 $ Trial        : Factor w/ 2 levels "1","0": 1 1 1 1 1 1 1 1 1 1 ...
 $ Entry        : int  681 681 680 680 641 641 769 769 632 632 ...
 $ Block_uni    : Factor w/ 210 levels "1:1:2","1:1:3",..: 127 127 127 127 127 127 127 127 127 127 ...

Checks are either: you're not a check, or you're Check 1 or 2. Each Entry has two GinnieEntries, one of which is Gen S0, the other S1. Trial indicates if you are in the trial (not a check), or not. GinnieEntries should be kept paired as they are related, which is part of what we're interested in.

To the best of my understanding, an appropriate model, if were ignoring Entry for now, would be:

   >lmm1<-lmer(Relative_Date~Gen+Check3+(1|Environment)+(1|GinnieEntry:Trial)+(1|Block_uni),data=data)

However, there is the issue of the GinnieEntry being nested within Entry, which, if I understand correctly, you cannot explicitly model with lme4. I understand that this is due to how lmer does the random effects analysis. So to see what happens when I add in the Entry:Trial term, I ran 3 more models:
    >lmm2<-lmer(Relative_Date~Gen+Check3+(1|Environment)+(1|GinnieEntry:Trial)+(1|Entry)+(1|Block_uni),data=data)

    >lmm3<-lmer(Relative_Date~Gen+Check3+(1|Environment)+(1|GinnieEntry)+(1|Entry:Trial)+(1|Block_uni),data=data)

    >lmm4<-lmer(Relative_Date~Gen+Check3+(1|Environment)+(1|GinnieEntry)+(1|Entry)+(1|Block_uni),data=data)

The scary thing is that all the random effects (and fixed effects) remain the same between all models. Which is to say, ranef(lmm1)$'GinnieEntry:Trial' == ranef(lmm2)$'GinnieEntry:Trial' == ranef(lmm3)$'GinnieEntry' == ranef(lmm4)$'GinnieEntry'
(which goes for Environment, Entry in the same way, and Block_uni). Is this an artifact of my data? Do I not understand the whole Trial:Entry type of interaction? Is there something up with the way nesting works? Or have I formatted the data (I assume Check3 or Trial) in such a way that I am not doing what I think I am? Any insight into this would be great--this is the first time I'm working with an augmented experiment, and most of the programming documentation I can find uses SAS for such an analysis. I can provide more info as needed.
Thank you,
Ginnie Morrison
Post-doctoral Fellow
University of Missouri, Columbia

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From bates at stat.wisc.edu  Thu Sep 11 18:12:04 2014
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 11 Sep 2014 11:12:04 -0500
Subject: [R-sig-ME] Question about linear mixed model
In-Reply-To: <D0371663.2EB6%hung-chih.ku@utsouthwestern.edu>
References: <D0371663.2EB6%hung-chih.ku@utsouthwestern.edu>
Message-ID: <CAO7JsnT7MQOANsJ809vm6+q3LP9N6yZsAUpawZ-Nf=HafOxAag@mail.gmail.com>

I recommend sending questions like this to the
R-SIG-Mixed-Models at R-project.org mailing list which I have cc:'d on this
reply.  Many of those who read that list can reply faster than I am able to.

On Thu, Sep 11, 2014 at 9:06 AM, Hung-Chih Ku <
Hung-Chih.Ku at utsouthwestern.edu> wrote:

>  Dear Dr. Bates,
>
>  My name is Hung-Chih Ku and I am a postdoctoral fellow at UT
> Southwestern Medical Center. I am trying to estimate variance components
> from a linear mixed model Y=Xa+Zb+e where Z is an nxp unstructured matrix.
> The following is an example of R code.
>
>   n <- 50
>
> p <- 5
>
> X <- runif(n)
>
> Z <- NULL
>
> for (i in 1:p) {
>
> Z <- cbind(Z, rbinom(n, 2, .3))
>
> }
>
> a <- 0.5
>
> b <- rnorm(p)
>
> e<- rnorm(n)
>
> Y <- X*a + Z*b + e
>
> library(nlme)
>
> group=rep(1,n)
>
>  fit <- lme(Y~X, random=list(group=pdIdent(~-1+Z)))
>
>  VarCorr(fit)
>
>  However, when n and p increase, let's say n=1000 and p=500, the lme will
> be taking a long time to estimate two variances (variances of b and e). Is
> there a way to speed up? Thank you for your time and I am looking forward
> to hearing from you.
>

When n=1000 and p=500 you are trying to estimate 500,000 random effects
coefficients from 1000 observations which seems a bit optimistic  You may
want to reexamine your model specification.  It doesn't make sense to me.

	[[alternative HTML version deleted]]


From Hung-Chih.Ku at utsouthwestern.edu  Thu Sep 11 18:22:00 2014
From: Hung-Chih.Ku at utsouthwestern.edu (Hung-Chih Ku)
Date: Thu, 11 Sep 2014 16:22:00 +0000
Subject: [R-sig-ME] Question about linear mixed model
Message-ID: <D037365C.2EC6%hung-chih.ku@utsouthwestern.edu>

Dear all,

I am trying to estimate variance components from a linear mixed model Y=Xa+Zb+e where Z is an nxp unstructured matrix. The following is an example of R code.


n <- 50

p <- 5

X <- runif(n)

Z <- NULL

for (i in 1:p) {

Z <- cbind(Z, rbinom(n, 2, .3))

}

a <- 0.5

b <- rnorm(p)

e<- rnorm(n)

Y <- X*a + Z*b + e

library(nlme)

group=rep(1,n)

fit <- lme(Y~X, random=list(group=pdIdent(~-1+Z)))

VarCorr(fit)

However, when n and p increase, let's say n=1000 and p=500, the lme will be taking a long time to estimate two variances (variances of b and e). Is there a way to speed up?

Thanks a lot,

Best wishes,
Hung-Chih Ku

Postdoctoral fellow
UT Southwestern Medical Center


________________________________

UT Southwestern Medical Center
The future of medicine, today.

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Fri Sep 12 00:24:44 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 11 Sep 2014 22:24:44 +0000 (UTC)
Subject: [R-sig-ME] Confidence interval for relative contribution of
	random effect variance
References: <B291F8F571C9494EA3EAF8C8B471333F22E0C28A@WBF-C7001.bk.evdad.admin.ch>
Message-ID: <loom.20140912T001218-369@post.gmane.org>

 <lorenz.gygax at ...> writes:

> 
> Dear all,

> earlier this year, I started to look into how I could estimate the
> relative contribution of the between-subjects variability relative
> to several levels of (summed) within-subject variabilities in the
> context of mixed models. Because I am using nlme and lme4 since
> quite a while that is where I started to look. In the end, I would
> like to have not only a point estimate but also a measure of
> precision, that is, either a confidence or credible interval.
 
> When I started to look into this, I came across a two-year old
> suggestion by Ben Bolker that relied on mcmcsamp
> (http://stats.stackexchange.com/questions/30797/
>   posterior-simulations-of-the-variances-with-the-mcmcsamp-function)
> which I liked because the Markov-chain would allow me to calculate
> the measure of interest for each simulation step and accordingly
> calculate e.g. an HPD-interval of the ratio of between- versus the
> (summed) within-subject variability.
 
> Now, doing some more research in the R-archives, help files and
> vignettes, I realize that I have been off the sig-mixed-models list
> for too long (due to work load and yes, I will try to be better in
> future and that mcmcsamp is no longer supported/developed. On the
> other hand the function confint () now exists. Many thanks to the
> developers!
 
> A side-line: Using the confint function on one of my models and
> comparing the confidence intervals with the point-estimates from the
> summary of the same model, it seems that confint reports confidence
> intervals for the estimated standard deviations of the random
> effects as well as of the error-variability whereas summary reports
> the standard deviations for the random effects but the variance for
> the residuals. Is this correct? I seem to remember some such
> discussion but could not find any note online that would have
> verified this fact. Page 31 in "Fitting linear mixed-effects models
> using lme4" discusses this part of the summary output but seems to
> be using the terms standard deviation and variance somewhat
> interchangeably (or, more likely, I failed to read it correctly).

   Hmmm.  The output of 

fm1 <- lmer(Reaction ~ Days + (Days | Subject), sleepstudy)
summary(fm1)

gives


Random effects:
 Groups   Name        Variance Std.Dev. Corr
 Subject  (Intercept) 612.09   24.740       
          Days         35.07    5.922   0.07
 Residual             654.94   25.592       
Number of obs: 180, groups:  Subject, 18

  which shows both the variance and the standard deviation (i.e.
*not* the uncertainty estimate, just the point estimate of the
variability on both the variance and the standard deviation scales)
 
> Now, apart from this aspect, can confint be tweaked to calculate not
> only the confidence interval of the 'raw' parameters but also for
> some function of the parameters? If not, do I need to move to an
> implementation using MCMC methods (MCMCglmm, Bugs-type of
> approaches, STAN or Laplaces-Demon) to reach my aim or do you have
> another (simpler) suggestion?
 
  You can compute parametric bootstrap confidence intervals of
any quantity you want by applying boot.ci() to the results of bootMer()
(bootMer()'s second argument is the summary function, which you
can define however you like).  This is computationally expensive,
though (even more expensive than MCMC-type computations).

  In principle you might be able to use likelihood profiling
(which is what the default confint() method uses) to compute
profile likelihood confidence intervals of arbitrary quantities,
but you would need to be able to constrain an optimization algorithm
to the specified values (i.e., you would need to set nonlinear
equality constraints; there are functions in nloptr and elsewhere
(many of them called auglag()) that implement an augmented Lagrange
multiplier algorithm for such constraints, but I haven't tried it
out to see how it works.

The advantage of parametric bootstrap/MCMC approaches is that
you also get a finite-size-appropriate result; likelihood profiling
would inherit the asymptotic assumptions of the likelihood ratio test.

glmmADMB still implements a post-hoc MCMC sampling strategy simpler
to mcmcsamp (but you would be on your own for making sure the
chain was well-behaved, etc.)

  Ben Bolker


From bbolker at gmail.com  Fri Sep 12 00:25:25 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 11 Sep 2014 22:25:25 +0000 (UTC)
Subject: [R-sig-ME] Confidence intervals
References: <9866_1410348417_s8ABQvPO010284_54103578.7020609@rwth-aachen.de>,
	<54109DED.2080201@mcmaster.ca>
	<01946E85F389EF42ADD3DE83A3560B3B3B246318@MBX-W1.rwth-ad.de>
Message-ID: <loom.20140912T002500-686@post.gmane.org>

Theelen, Maik Matheus Paul <Maik.Theelen at ...> writes:

> 
> Dear Ben,
> 
> Thank you very much for the answer. Yes, index
>  should indeed be 1 2 3 4 (it was a typo).
> Next time I will send it to the r-sig-mixed-models mailing list.
> 
> Would the method that I used be pretty much be 
> the same as using confint with method = boot?

   Yes, that's right.

  Ben Bolker


From markpayneatwork at gmail.com  Fri Sep 12 12:12:23 2014
From: markpayneatwork at gmail.com (Mark Payne)
Date: Fri, 12 Sep 2014 12:12:23 +0200
Subject: [R-sig-ME] Multiple independent random effects
Message-ID: <CAGBzUO8+XR7borNEZnWb2iaAJ5U5qCnAO5r1rmQSGWen1dN0EQ@mail.gmail.com>

Hi,

I have a mixed-effects model in lme4 like so

mdl <- lmer(T ~1 + (1|A) + (1|B),...)

where the factors A and B are being modelled as independent random effects.
However, there is also heteroscedasticity in the problem, where the
variance of T depends on a third grouping factor, lets called it C.

I can fit such a model in the nlme package, using  the
weights=varIdent(form=~1| C)  argument, but this package doesn't seem to
easily support independent random effects of the form shown above...

How can I get the best of both worlds here?

Mark

	[[alternative HTML version deleted]]


From helios.derosario at ibv.upv.es  Fri Sep 12 12:16:58 2014
From: helios.derosario at ibv.upv.es (Helios de Rosario)
Date: Fri, 12 Sep 2014 12:16:58 +0200
Subject: [R-sig-ME] link function with glmer and inverse.gaussian family
Message-ID: <5412E43A0200000C0001F348@mailhost.biomec.upv.es>

Hello, I did this:

> mod1 <- glmer(y ~ x + (1|block), data=dat,
family=inverse.gaussian(log))
> getFamily(mod1)

Family: inverse.gaussian 
Link function: 1/mu^2 

I had expected that the link function would be "log", as I entered it
explicitly. If I fit a glm (without random effects), I do get:

> mod2<- glm(y ~ x, data=dat, family=inverse.gaussian(log))
> getFamily(mod2)

Family: inverse.gaussian 
Link function: log

Is there a reason for that different behaviour of the functions?

Thanks
Helios De Rosario 



SABEMOS QU? HICIMOS EN 2013
365 d?as de Innovaci?n
ANUARIO DE BIOMEC?NICA
http://www.ibv.org/anuario2013
______________________________

INSTITUTO DE BIOMEC?NICA DE VALENCIA
Universidad Polit?cnica de Valencia ? Edificio 9C
Camino de Vera s/n ? 46022 VALENCIA (ESPA?A)
Tel. +34 96 387 91 60 ? Fax +34 96 387 91 69
www.ibv.org

Antes de imprimir este e-mail piense bien si es necesario hacerlo.
En cumplimiento de la Ley Org?nica 15/1999 reguladora de la Protecci?n
de Datos de Car?cter Personal, le informamos de que el presente mensaje
contiene informaci?n confidencial, siendo para uso exclusivo del
destinatario arriba indicado. En caso de no ser usted el destinatario
del mismo le informamos que su recepci?n no le autoriza a su divulgaci?n
o reproducci?n por cualquier medio, debiendo destruirlo de inmediato,
rog?ndole lo notifique al remitente.


From lorenz.gygax at agroscope.admin.ch  Fri Sep 12 13:05:45 2014
From: lorenz.gygax at agroscope.admin.ch (lorenz.gygax at agroscope.admin.ch)
Date: Fri, 12 Sep 2014 11:05:45 +0000
Subject: [R-sig-ME] Confidence interval for relative contribution
	of	random effect variance
In-Reply-To: <loom.20140912T001218-369@post.gmane.org>
References: <B291F8F571C9494EA3EAF8C8B471333F22E0C28A@WBF-C7001.bk.evdad.admin.ch>
	<loom.20140912T001218-369@post.gmane.org>
Message-ID: <B291F8F571C9494EA3EAF8C8B471333F22E0D70B@WBF-C7001.bk.evdad.admin.ch>

Dear Ben,

Many thanks for your input.

[... snip]

> > Now, apart from this aspect, can confint be tweaked to calculate not
> > only the confidence interval of the 'raw' parameters but also for
> > some function of the parameters? If not, do I need to move to an
> > implementation using MCMC methods (MCMCglmm, Bugs-type of
> > approaches, STAN or Laplaces-Demon) to reach my aim or do you have
> > another (simpler) suggestion?
> 
>   You can compute parametric bootstrap confidence intervals of
> any quantity you want by applying boot.ci() to the results of bootMer()
> (bootMer()'s second argument is the summary function, which you
> can define however you like).  This is computationally expensive,
> though (even more expensive than MCMC-type computations).

Ok. The latter may not be such an issue. This sounds doable and I will be looking into it! (And I can report back on my success ...)

>   In principle you might be able to use likelihood profiling
> (which is what the default confint() method uses) to compute
> profile likelihood confidence intervals of arbitrary quantities,
> but you would need to be able to constrain an optimization algorithm
> to the specified values (i.e., you would need to set nonlinear
> equality constraints; there are functions in nloptr and elsewhere
> (many of them called auglag()) that implement an augmented Lagrange
> multiplier algorithm for such constraints, but I haven't tried it
> out to see how it works.

This sound rather daunting and I fear that I am not up to this ...

> The advantage of parametric bootstrap/MCMC approaches is that
> you also get a finite-size-appropriate result; likelihood profiling
> would inherit the asymptotic assumptions of the likelihood ratio test.
> 
> glmmADMB still implements a post-hoc MCMC sampling strategy simpler
> to mcmcsamp (but you would be on your own for making sure the
> chain was well-behaved, etc.)

Ok that would be another avenue.

Many thanks again! Regards, Lorenz


From lorenz.gygax at agroscope.admin.ch  Fri Sep 12 13:20:42 2014
From: lorenz.gygax at agroscope.admin.ch (lorenz.gygax at agroscope.admin.ch)
Date: Fri, 12 Sep 2014 11:20:42 +0000
Subject: [R-sig-ME] Seeming discrepancy between summary and confint;
 was: Confidence interval for relative contribution of random effect
 variance
Message-ID: <B291F8F571C9494EA3EAF8C8B471333F22E0D731@WBF-C7001.bk.evdad.admin.ch>

[snip ...]

> > A side-line: Using the confint function on one of my models and
> > comparing the confidence intervals with the point-estimates from the
> > summary of the same model, it seems that confint reports confidence
> > intervals for the estimated standard deviations of the random
> > effects as well as of the error-variability whereas summary reports
> > the standard deviations for the random effects but the variance for
> > the residuals. Is this correct? I seem to remember some such
> > discussion but could not find any note online that would have
> > verified this fact. Page 31 in "Fitting linear mixed-effects models
> > using lme4" discusses this part of the summary output but seems to
> > be using the terms standard deviation and variance somewhat
> > interchangeably (or, more likely, I failed to read it correctly).
> 
>    Hmmm.  The output of
> 
> fm1 <- lmer(Reaction ~ Days + (Days | Subject), sleepstudy)
> summary(fm1)
> 
> gives
> 
> 
> Random effects:
>  Groups   Name        Variance Std.Dev. Corr
>  Subject  (Intercept) 612.09   24.740
>           Days         35.07    5.922   0.07
>  Residual             654.94   25.592
> Number of obs: 180, groups:  Subject, 18
> 
>   which shows both the variance and the standard deviation (i.e.
> *not* the uncertainty estimate, just the point estimate of the
> variability on both the variance and the standard deviation scales)

Ok. I admit that I was not very clear perhaps. Let me show an example. I am currently on lme4 version 1.1-7 in R 3.0.1 (my employer is just now updating to 3.1.1 but that always takes a while - so if that was an issue of not having the most recent version, I apologise in advance):

In the example which struck me odd, this was my model

HHbT.fin.lmer <- lmer (HHbT ~ valN +
                       (1 | ID/part/val), fNIRS.df, REML= FALSE)

in which the response is a transformed change in blood deoxy-hemoglobin concentration modelled by a fixed effect (three types of conditions, modelled as a linear predictor in which stimuli have been applied repeatedly) and a nested intercept random effect that accounts for the subject-to-subject variation (ID), the part-to-part variation (three different parts in the experiment) and the type of stimulus. (I am using REML= FALSE because I am conducting come model selection for the fixed effects based on information criteria.)

If I do the summary () this is what I get for the random effects part of the output.

Random effects:
 Groups        Name        Variance Std.Dev.
 val:(part:ID) (Intercept) 0.4599   0.6782  
 part:ID       (Intercept) 0.1773   0.4211  
 ID            (Intercept) 0.1278   0.3575  
 Residual                  9.4302   3.0709  
Number of obs: 1833, groups:  val:(part:ID), 214; part:ID, 72; ID, 25:


If I do

confint (HHbT.fin.lmer, method= 'profile')

I get

                  2.5 %     97.5 %
.sig01       0.41713241  0.9210729
.sig02       0.00000000  0.7535615
.sig03       0.00000000  0.6697109
.sigma       2.96898087  3.1786606

Where the above listed variances for the random effects fit nicely into the confidence intervals (.sig0x) but not the value for the residuals / .sigma where the variance from the summary seems to be approximately squared in respect to the confidence interval.

I guess, I am missing out on something, but on what?

Thanks for further advice.

Regards, Lorenz


From maechler at stat.math.ethz.ch  Fri Sep 12 14:50:55 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 12 Sep 2014 14:50:55 +0200
Subject: [R-sig-ME] Seeming discrepancy between summary and confint;
 was: Confidence interval for relative contribution of random effect
 variance
In-Reply-To: <B291F8F571C9494EA3EAF8C8B471333F22E0D731@WBF-C7001.bk.evdad.admin.ch>
References: <B291F8F571C9494EA3EAF8C8B471333F22E0D731@WBF-C7001.bk.evdad.admin.ch>
Message-ID: <21522.60463.593065.594393@stat.math.ethz.ch>

>>>>>   <lorenz.gygax at agroscope.admin.ch>
>>>>>     on Fri, 12 Sep 2014 11:20:42 +0000 writes:

    > [snip ...]
    >> > A side-line: Using the confint function on one of my models and
    >> > comparing the confidence intervals with the point-estimates from the
    >> > summary of the same model, it seems that confint reports confidence
    >> > intervals for the estimated standard deviations of the random
    >> > effects as well as of the error-variability whereas summary reports
    >> > the standard deviations for the random effects but the variance for
    >> > the residuals. Is this correct? I seem to remember some such
    >> > discussion but could not find any note online that would have
    >> > verified this fact. Page 31 in "Fitting linear mixed-effects models
    >> > using lme4" discusses this part of the summary output but seems to
    >> > be using the terms standard deviation and variance somewhat
    >> > interchangeably (or, more likely, I failed to read it correctly).
    >> 
    >> Hmmm.  The output of
    >> 
    >> fm1 <- lmer(Reaction ~ Days + (Days | Subject), sleepstudy)
    >> summary(fm1)
    >> 
    >> gives
    >> 
    >> 
    >> Random effects:
    >> Groups   Name        Variance Std.Dev. Corr
    >> Subject  (Intercept) 612.09   24.740
    >> Days         35.07    5.922   0.07
    >> Residual             654.94   25.592
    >> Number of obs: 180, groups:  Subject, 18
    >> 
    >> which shows both the variance and the standard deviation (i.e.
    >> *not* the uncertainty estimate, just the point estimate of the
    >> variability on both the variance and the standard deviation scales)

    > Ok. I admit that I was not very clear perhaps. Let me show an example. I am currently on lme4 version 1.1-7 in R 3.0.1 (my employer is just now updating to 3.1.1 but that always takes a while - so if that was an issue of not having the most recent version, I apologise in advance):

    > In the example which struck me odd, this was my model

    > HHbT.fin.lmer <- lmer (HHbT ~ valN +
    > (1 | ID/part/val), fNIRS.df, REML= FALSE)

    > in which the response is a transformed change in blood deoxy-hemoglobin concentration modelled by a fixed effect (three types of conditions, modelled as a linear predictor in which stimuli have been applied repeatedly) and a nested intercept random effect that accounts for the subject-to-subject variation (ID), the part-to-part variation (three different parts in the experiment) and the type of stimulus. (I am using REML= FALSE because I am conducting come model selection for the fixed effects based on information criteria.)

    > If I do the summary () this is what I get for the random effects part of the output.

    > Random effects:
    > Groups        Name        Variance Std.Dev.
    > val:(part:ID) (Intercept) 0.4599   0.6782  
    > part:ID       (Intercept) 0.1773   0.4211  
    > ID            (Intercept) 0.1278   0.3575  
    > Residual                  9.4302   3.0709  
    > Number of obs: 1833, groups:  val:(part:ID), 214; part:ID, 72; ID, 25:


    > If I do

    > confint (HHbT.fin.lmer, method= 'profile')

    > I get

    > 2.5 %     97.5 %
    > .sig01       0.41713241  0.9210729
    > .sig02       0.00000000  0.7535615
    > .sig03       0.00000000  0.6697109
    > .sigma       2.96898087  3.1786606

    > Where the above listed variances for the random effects fit nicely into the confidence intervals (.sig0x) but not the value for the residuals / .sigma where the variance from the summary seems to be approximately squared in respect to the confidence interval.

    > I guess, I am missing out on something, but on what?

Yes, the conf.ints are for the sigmas as their name suggest, and
sigmas are standard deviations aka  sqrt(<variances>).

You're welcome 
und herzlichen eidgen?ssischen Gruss,
Martin


From coanil at posteo.org  Fri Sep 12 14:59:51 2014
From: coanil at posteo.org (Michael Cone)
Date: Fri, 12 Sep 2014 14:59:51 +0200
Subject: [R-sig-ME] Multiple independent random effects
In-Reply-To: <CAGBzUO8+XR7borNEZnWb2iaAJ5U5qCnAO5r1rmQSGWen1dN0EQ@mail.gmail.com>
References: <CAGBzUO8+XR7borNEZnWb2iaAJ5U5qCnAO5r1rmQSGWen1dN0EQ@mail.gmail.com>
Message-ID: <d658a15eea62bf776b6eec97fedd1a26@posteo.de>

Mark, I don't think that's possible with lme4/lmer right now.

Michael

Am 12.09.2014 12:12 schrieb Mark Payne:
> Hi,
> 
> I have a mixed-effects model in lme4 like so
> 
> mdl <- lmer(T ~1 + (1|A) + (1|B),...)
> 
> where the factors A and B are being modelled as independent random 
> effects.
> However, there is also heteroscedasticity in the problem, where the
> variance of T depends on a third grouping factor, lets called it C.
> 
> I can fit such a model in the nlme package, using  the
> weights=varIdent(form=~1| C)  argument, but this package doesn't seem 
> to
> easily support independent random effects of the form shown above...
> 
> How can I get the best of both worlds here?
> 
> Mark
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Fri Sep 12 15:45:30 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 12 Sep 2014 09:45:30 -0400
Subject: [R-sig-ME] link function with glmer and inverse.gaussian family
In-Reply-To: <5412E43A0200000C0001F348@mailhost.biomec.upv.es>
References: <5412E43A0200000C0001F348@mailhost.biomec.upv.es>
Message-ID: <5412F8FA.7050508@gmail.com>

On 14-09-12 06:16 AM, Helios de Rosario wrote:
> Hello, I did this:
> 
>> mod1 <- glmer(y ~ x + (1|block), data=dat,
> family=inverse.gaussian(log))
>> getFamily(mod1)
> 
> Family: inverse.gaussian 
> Link function: 1/mu^2 
> 
> I had expected that the link function would be "log", as I entered it
> explicitly. If I fit a glm (without random effects), I do get:
> 
>> mod2<- glm(y ~ x, data=dat, family=inverse.gaussian(log))
>> getFamily(mod2)
> 
> Family: inverse.gaussian 
> Link function: log
> 
> Is there a reason for that different behaviour of the functions?
> 
> Thanks
> Helios De Rosario 

This is a bug that affects reporting (not the actual fit), which was
reported and fixed quite recently (see
http://article.gmane.org/gmane.comp.lang.r.lme4.devel/12374 for
information and workarounds)


From lorenz.gygax at agroscope.admin.ch  Fri Sep 12 16:52:11 2014
From: lorenz.gygax at agroscope.admin.ch (lorenz.gygax at agroscope.admin.ch)
Date: Fri, 12 Sep 2014 14:52:11 +0000
Subject: [R-sig-ME] Seeming discrepancy between summary and confint;
 was: Confidence interval for relative contribution of random effect
 variance
In-Reply-To: <21522.60463.593065.594393@stat.math.ethz.ch>
References: <B291F8F571C9494EA3EAF8C8B471333F22E0D731@WBF-C7001.bk.evdad.admin.ch>,
	<21522.60463.593065.594393@stat.math.ethz.ch>
Message-ID: <0E9ABD58-4796-42CD-BE03-F2624CA69CEA@agroscope.admin.ch>

Dear Martin,

Many thanks for this explanation which, of course, is very reasonable ;-)

But - and I may be real slow on this - why is the same seemingly not true for the random effects as well (summary and confint give the same absolute values)?

Cheers, Lorenz


Am 12.09.2014 um 14:51 schrieb "Martin Maechler" <maechler at stat.math.ethz.ch>:

>>>>>>  <lorenz.gygax at agroscope.admin.ch>
>>>>>>    on Fri, 12 Sep 2014 11:20:42 +0000 writes:
> 
>> [snip ...]
>>>> A side-line: Using the confint function on one of my models and
>>>> comparing the confidence intervals with the point-estimates from the
>>>> summary of the same model, it seems that confint reports confidence
>>>> intervals for the estimated standard deviations of the random
>>>> effects as well as of the error-variability whereas summary reports
>>>> the standard deviations for the random effects but the variance for
>>>> the residuals. Is this correct? I seem to remember some such
>>>> discussion but could not find any note online that would have
>>>> verified this fact. Page 31 in "Fitting linear mixed-effects models
>>>> using lme4" discusses this part of the summary output but seems to
>>>> be using the terms standard deviation and variance somewhat
>>>> interchangeably (or, more likely, I failed to read it correctly).
>>> 
>>> Hmmm.  The output of
>>> 
>>> fm1 <- lmer(Reaction ~ Days + (Days | Subject), sleepstudy)
>>> summary(fm1)
>>> 
>>> gives
>>> 
>>> 
>>> Random effects:
>>> Groups   Name        Variance Std.Dev. Corr
>>> Subject  (Intercept) 612.09   24.740
>>> Days         35.07    5.922   0.07
>>> Residual             654.94   25.592
>>> Number of obs: 180, groups:  Subject, 18
>>> 
>>> which shows both the variance and the standard deviation (i.e.
>>> *not* the uncertainty estimate, just the point estimate of the
>>> variability on both the variance and the standard deviation scales)
> 
>> Ok. I admit that I was not very clear perhaps. Let me show an example. I am currently on lme4 version 1.1-7 in R 3.0.1 (my employer is just now updating to 3.1.1 but that always takes a while - so if that was an issue of not having the most recent version, I apologise in advance):
> 
>> In the example which struck me odd, this was my model
> 
>> HHbT.fin.lmer <- lmer (HHbT ~ valN +
>> (1 | ID/part/val), fNIRS.df, REML= FALSE)
> 
>> in which the response is a transformed change in blood deoxy-hemoglobin concentration modelled by a fixed effect (three types of conditions, modelled as a linear predictor in which stimuli have been applied repeatedly) and a nested intercept random effect that accounts for the subject-to-subject variation (ID), the part-to-part variation (three different parts in the experiment) and the type of stimulus. (I am using REML= FALSE because I am conducting come model selection for the fixed effects based on information criteria.)
> 
>> If I do the summary () this is what I get for the random effects part of the output.
> 
>> Random effects:
>> Groups        Name        Variance Std.Dev.
>> val:(part:ID) (Intercept) 0.4599   0.6782  
>> part:ID       (Intercept) 0.1773   0.4211  
>> ID            (Intercept) 0.1278   0.3575  
>> Residual                  9.4302   3.0709  
>> Number of obs: 1833, groups:  val:(part:ID), 214; part:ID, 72; ID, 25:
> 
> 
>> If I do
> 
>> confint (HHbT.fin.lmer, method= 'profile')
> 
>> I get
> 
>> 2.5 %     97.5 %
>> .sig01       0.41713241  0.9210729
>> .sig02       0.00000000  0.7535615
>> .sig03       0.00000000  0.6697109
>> .sigma       2.96898087  3.1786606
> 
>> Where the above listed variances for the random effects fit nicely into the confidence intervals (.sig0x) but not the value for the residuals / .sigma where the variance from the summary seems to be approximately squared in respect to the confidence interval.
> 
>> I guess, I am missing out on something, but on what?
> 
> Yes, the conf.ints are for the sigmas as their name suggest, and
> sigmas are standard deviations aka  sqrt(<variances>).
> 
> You're welcome 
> und herzlichen eidgen?ssischen Gruss,
> Martin


From emmanuel.curis at parisdescartes.fr  Fri Sep 12 17:54:55 2014
From: emmanuel.curis at parisdescartes.fr (Emmanuel Curis)
Date: Fri, 12 Sep 2014 17:54:55 +0200
Subject: [R-sig-ME] Seeming discrepancy between summary and confint;
 was: Confidence interval for relative contribution of random effect
 variance
In-Reply-To: <0E9ABD58-4796-42CD-BE03-F2624CA69CEA@agroscope.admin.ch>
References: <B291F8F571C9494EA3EAF8C8B471333F22E0D731@WBF-C7001.bk.evdad.admin.ch>
	<21522.60463.593065.594393@stat.math.ethz.ch>
	<0E9ABD58-4796-42CD-BE03-F2624CA69CEA@agroscope.admin.ch>
Message-ID: <20140912155455.GB21520@info124.pharmacie.univ-paris5.fr>

Double check your results, you will see that there is agreement also
for random effects: the column to use is Std. Dev. which is indeed in
the confidence intervals given by confint --- just like standard
deviation for the residuals.

It just happen that confidence intervals are so wide, that they also
include the Variance value, but thats ? bad luck ?.

On Fri, Sep 12, 2014 at 02:52:11PM +0000, lorenz.gygax at agroscope.admin.ch wrote:
? Dear Martin,
? 
? Many thanks for this explanation which, of course, is very reasonable ;-)
? 
? But - and I may be real slow on this - why is the same seemingly not true for the random effects as well (summary and confint give the same absolute values)?
? 
? Cheers, Lorenz

? >> If I do the summary () this is what I get for the random effects part of the output.
? > 
? >> Random effects:
? >> Groups        Name        Variance Std.Dev.
? >> val:(part:ID) (Intercept) 0.4599   0.6782  
? >> part:ID       (Intercept) 0.1773   0.4211  
? >> ID            (Intercept) 0.1278   0.3575  
? >> Residual                  9.4302   3.0709  
? >> Number of obs: 1833, groups:  val:(part:ID), 214; part:ID, 72; ID, 25:
? > 
? > 
? >> If I do
? > 
? >> confint (HHbT.fin.lmer, method= 'profile')
? > 
? >> I get
? > 
? >> 2.5 %     97.5 %
? >> .sig01       0.41713241  0.9210729
? >> .sig02       0.00000000  0.7535615
? >> .sig03       0.00000000  0.6697109
? >> .sigma       2.96898087  3.1786606
? > 
? >> Where the above listed variances for the random effects fit nicely into the confidence intervals (.sig0x) but not the value for the residuals / .sigma where the variance from the summary seems to be approximately squared in respect to the confidence interval.

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From lorenz.gygax at agroscope.admin.ch  Fri Sep 12 18:10:03 2014
From: lorenz.gygax at agroscope.admin.ch (lorenz.gygax at agroscope.admin.ch)
Date: Fri, 12 Sep 2014 16:10:03 +0000
Subject: [R-sig-ME] Seeming discrepancy between summary and confint;
 was: Confidence interval for relative contribution of random effect
 variance
In-Reply-To: <20140912155455.GB21520@info124.pharmacie.univ-paris5.fr>
References: <B291F8F571C9494EA3EAF8C8B471333F22E0D731@WBF-C7001.bk.evdad.admin.ch>
	<21522.60463.593065.594393@stat.math.ethz.ch>
	<0E9ABD58-4796-42CD-BE03-F2624CA69CEA@agroscope.admin.ch>,
	<20140912155455.GB21520@info124.pharmacie.univ-paris5.fr>
Message-ID: <F3DAC24D-DDCE-4B73-847D-EBF984D68BBD@agroscope.admin.ch>

Dear Emmanuel,

Thank you! Stupid me ...

A nice weekend to all of you! Lorenz



> Am 12.09.2014 um 17:55 schrieb "Emmanuel Curis" <emmanuel.curis at parisdescartes.fr>:
> 
> Double check your results, you will see that there is agreement also
> for random effects: the column to use is Std. Dev. which is indeed in
> the confidence intervals given by confint --- just like standard
> deviation for the residuals.
> 
> It just happen that confidence intervals are so wide, that they also
> include the Variance value, but thats ? bad luck ?.
> 
> On Fri, Sep 12, 2014 at 02:52:11PM +0000, lorenz.gygax at agroscope.admin.ch wrote:
> ? Dear Martin,
> ? 
> ? Many thanks for this explanation which, of course, is very reasonable ;-)
> ? 
> ? But - and I may be real slow on this - why is the same seemingly not true for the random effects as well (summary and confint give the same absolute values)?
> ? 
> ? Cheers, Lorenz
> 
> ? >> If I do the summary () this is what I get for the random effects part of the output.
> ? > 
> ? >> Random effects:
> ? >> Groups        Name        Variance Std.Dev.
> ? >> val:(part:ID) (Intercept) 0.4599   0.6782  
> ? >> part:ID       (Intercept) 0.1773   0.4211  
> ? >> ID            (Intercept) 0.1278   0.3575  
> ? >> Residual                  9.4302   3.0709  
> ? >> Number of obs: 1833, groups:  val:(part:ID), 214; part:ID, 72; ID, 25:
> ? > 
> ? > 
> ? >> If I do
> ? > 
> ? >> confint (HHbT.fin.lmer, method= 'profile')
> ? > 
> ? >> I get
> ? > 
> ? >> 2.5 %     97.5 %
> ? >> .sig01       0.41713241  0.9210729
> ? >> .sig02       0.00000000  0.7535615
> ? >> .sig03       0.00000000  0.6697109
> ? >> .sigma       2.96898087  3.1786606
> ? > 
> ? >> Where the above listed variances for the random effects fit nicely into the confidence intervals (.sig0x) but not the value for the residuals / .sigma where the variance from the summary seems to be approximately squared in respect to the confidence interval.
> 
> -- 
>                                Emmanuel CURIS
>                                emmanuel.curis at parisdescartes.fr
> 
> Page WWW: http://emmanuel.curis.online.fr/index.html


From drmasoodmohd at gmail.com  Fri Sep 12 18:20:34 2014
From: drmasoodmohd at gmail.com (Mohd Masood)
Date: Sat, 13 Sep 2014 00:20:34 +0800
Subject: [R-sig-ME] SE and CI for ICC
Message-ID: <CALho=DacTOsNJOnE7T3vRjtVsnLDxHomN1RTN+yHinr_wGUWBw@mail.gmail.com>

I am using random intercept logistic model (in lme4) to calculated
Intraclass correlation coefficient (ICC). lme4 only provides point
estimates and standard deviation (not standard errors) of variance
estimates.These
point estimates can be used to calculated point estimates for ICC. The
problem is how can I calculate standard error and confidence interval for
ICC. I couldn't find any literature showing formula to calculate confidence
interval around ICC.  Or is it not possible to calculate SE and CI for ICC
due to skewed sampling distribution (Please see PMCID: PMC3426610).

Thanks
Masood

	[[alternative HTML version deleted]]


From shana.caro at sjc.ox.ac.uk  Fri Sep 12 17:58:04 2014
From: shana.caro at sjc.ox.ac.uk (Shana Caro)
Date: Fri, 12 Sep 2014 15:58:04 +0000
Subject: [R-sig-ME] MCMCglmm multi-variate response for animal model
Message-ID: <D038CBA4.4600%shana.caro@sjc.ox.ac.uk>

Hi,

I am trying to fit a bivariate response model for a phylogenetic meta-analysis. I am looking at two behaviours (y1 in offspring and y2 in adults), and trying to determine if certain life history traits (x1 and x2) influence those behaviours. Logically, I would expect y1 and y2 to covary within species, which is why I want to fit a bivariate response model instead of 2 univariate models.

I am not certain if my data are in an appropriate format for a bivariate MCMCglmm, or if the model I am trying to run is actually telling me what I think it is. Apologies for a very beginner-type question.

My data is in this form:

Animal Study y1 y2 sample size x1 x2
species1 study1 0.05 n/a 20 yes poor
species1 study2 n/a 0.20 35 yes good
species2 study3 n/a -0.10 15 no normal
species2 study3 n/a -0.50 25 no normal
species3 study4 0.75 n/a 40 no good

?etc

Y1 and y2 are Z-transformed correlations. The life history traits are factors: x1 is a categorical yes/no, and x2 is an ordered categorical poor/normal/good. Each row has either y1 or y2 (never both). Each species can have multiple effect sizes, from multiple studies. Not every species/study has data on both y1 and y2 (41 species have both, 32 have data on only y1, and 20 have data on only y2; 93 total species), but I believe MCMCglmm will impute data (missing at random). Most species have 1-3 studies, and most studies have 1-5 effect sizes. I cannot collapse my data to 1 value per species or study, because x1 and x2 vary within species and study. Not every species has an effect size for every combination of x1:x2. N is the sample size of the study, and I am using 1/(n-3) for the mev argument.

Essentially, the outputs I want are:

  *   The contrast between the levels of x1 (for y1 controlling for y2, and vice versa)
  *   Whether the slope of x2 is different than 0 (for y1 controlling for y2, and vice versa)
  *   Whether there is an interaction between x1 and x2 (for y1 controlling for y2, and vice versa)
  *   The species-level correlation between y1 and y2 (controlling for x1 and x2).

The model I?ve run is:

prior = list(R=list(V = diag(2)/3, nu = 2), G=list(G1 = list(V = diag(2)/3, nu = 2), G2 = list(V = diag(2)/3, nu = 2)))

Model <- MCMCglmm(cbind( y1, y2 ) ~ trait * x1 * x2 - 1,
                         random = ~ us(trait):animal + us(trait):study,
                         rcov = ~ us(trait):units,
                         prior = prior,
                         mev = variance,
                         pedigree = tree,
                         data = data,
                         family = c("gaussian","gaussian"), verbose=F, pr=T, slice=T, nitt=600000, burnin=100000, thin=100)

Am I correct in this interpretation of the post.means for this model?

  *   Trait y1: the intercept for y1
  *   Trait y2: the intercept for y2
  *   x1: the contrast for x1.no for y1
  *   x2 (linear): the slope for y1 from x2
  *   Trait y2:x1: the contrast for x1.no for y2
  *   Trait y2:x2 (linear): the slope for y2 from x2
  *   x1:x2 (linear): the interaction between x1 and x2 for y1
  *   Trait y2:x1:x2: the interaction between x1 and x2 for y2

Thank you!

Shana Caro

Shana.Caro at zoo.ox.ac.uk




	[[alternative HTML version deleted]]


From bbolker at gmail.com  Fri Sep 12 21:57:06 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 12 Sep 2014 19:57:06 +0000 (UTC)
Subject: [R-sig-ME] SE and CI for ICC
References: <CALho=DacTOsNJOnE7T3vRjtVsnLDxHomN1RTN+yHinr_wGUWBw@mail.gmail.com>
Message-ID: <loom.20140912T215326-401@post.gmane.org>

Mohd Masood <drmasoodmohd at ...> writes:

> 
> I am using random intercept logistic model (in lme4) to calculated
> Intraclass correlation coefficient (ICC). lme4 only provides point
> estimates and standard deviation (not standard errors) of variance
> estimates.These
> point estimates can be used to calculated point estimates for ICC. The
> problem is how can I calculate standard error and confidence interval for
> ICC. I couldn't find any literature showing formula to
> calculate confidence
> interval around ICC.  Or is it not possible to calculate 
> SE and CI for ICC
> due to skewed sampling distribution (Please see PMCID: PMC3426610).
> 
> Thanks
> Masood
> 


  Some possibilities:

 * If you want the standard deviations of the variance estimates
(keeping the strong caveats about non-Normal sampling distributions
in mind), you could adapt the approach shown in 
http://rpubs.com/bbolker/varwald  (presumably formulas
for confidence intervals
of the ICC based on the variances of the estimates of the RE variances
are using the delta method?  I don't know this literature)

 * as suggested in a previous e-mail, it might be possible to
compute profile confidence intervals on the ICCs by using 
nloptr::auglag or some other optimization framework that allows
nonlinear equality constraints.

 * or via parametric bootstrap/bootMer ...


From bbolker at gmail.com  Fri Sep 12 22:00:30 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 12 Sep 2014 20:00:30 +0000 (UTC)
Subject: [R-sig-ME] Multiple independent random effects
References: <CAGBzUO8+XR7borNEZnWb2iaAJ5U5qCnAO5r1rmQSGWen1dN0EQ@mail.gmail.com>
	<d658a15eea62bf776b6eec97fedd1a26@posteo.de>
Message-ID: <loom.20140912T215724-855@post.gmane.org>

Michael Cone <coanil at ...> writes:

> 
> Mark, I don't think that's possible with lme4/lmer right now.
> 
> Michael

  It's possible, but not easy.
  http://rpubs.com/bbolker/varfac shows how to set up 
formulae/model structures that allow for different RE variances,
or different residual variances, across different levels of a
fixed treatment factor.

  Basically, you have to set up an observation-level random
effect and dummy variables for each level of C other than
the first, then add

 (0+cLevel2|obs) + (0+cLevel3|obs) + (0+cLevel4|obs) ...

or equivalently you can use

 (0+dummy(C,"level2")|obs) + (0+dummy(C,"level3")|obs) + ...

  This is more elegantly doable with the flexLambda development
branch ...

> 
> Am 12.09.2014 12:12 schrieb Mark Payne:
> > Hi,
> > 
> > I have a mixed-effects model in lme4 like so
> > 
> > mdl <- lmer(T ~1 + (1|A) + (1|B),...)
> > 
> > where the factors A and B are being modelled as independent random 
> > effects.
> > However, there is also heteroscedasticity in the problem, where the
> > variance of T depends on a third grouping factor, lets called it C.
> > 
> > I can fit such a model in the nlme package, using  the
> > weights=varIdent(form=~1| C)  argument, but this package doesn't seem 
> > to
> > easily support independent random effects of the form shown above...
> > 
> > How can I get the best of both worlds here?
> > 
> > Mark


From datkins at u.washington.edu  Sat Sep 13 00:18:07 2014
From: datkins at u.washington.edu (David Atkins)
Date: Fri, 12 Sep 2014 15:18:07 -0700
Subject: [R-sig-ME] SE and CI for ICC
In-Reply-To: <loom.20140912T215326-401@post.gmane.org>
References: <loom.20140912T215326-401@post.gmane.org>
Message-ID: <5413711F.8080009@u.washington.edu>


Masood--

If memory serves, the following article might be helpful (and, I believe 
had associated R code):

http://www.ncbi.nlm.nih.gov/pubmed/20569253

Biol Rev Camb Philos Soc. 2010 Nov;85(4):935-56. doi: 
10.1111/j.1469-185X.2010.00141.x.

Repeatability for Gaussian and non-Gaussian data: a practical guide for 
biologists.

Nakagawa S1, Schielzeth H.

[Note that repeatability = ICC]

Hope that helps.

cheers, Dave

-- 
Dave Atkins, PhD

Research Professor
Department of Psychiatry and Behavioral Science
University of Washington
datkins at u.washington.edu
http://depts.washington.edu/cshrb/david-atkins/#more-48

"You can never solve a problem on the level on which it was created."
(attributed to) Albert Einstein

Mohd Masood <drmasoodmohd at ...> writes:

 >
 > I am using random intercept logistic model (in lme4) to calculated
 > Intraclass correlation coefficient (ICC). lme4 only provides point
 > estimates and standard deviation (not standard errors) of variance
 > estimates.These
 > point estimates can be used to calculated point estimates for ICC. The
 > problem is how can I calculate standard error and confidence interval for
 > ICC. I couldn't find any literature showing formula to
 > calculate confidence
 > interval around ICC.  Or is it not possible to calculate
 > SE and CI for ICC
 > due to skewed sampling distribution (Please see PMCID: PMC3426610).
 >
 > Thanks
 > Masood
 >


   Some possibilities:

  * If you want the standard deviations of the variance estimates
(keeping the strong caveats about non-Normal sampling distributions
in mind), you could adapt the approach shown in
http://rpubs.com/bbolker/varwald  (presumably formulas
for confidence intervals
of the ICC based on the variances of the estimates of the RE variances
are using the delta method?  I don't know this literature)

  * as suggested in a previous e-mail, it might be possible to
compute profile confidence intervals on the ICCs by using
nloptr::auglag or some other optimization framework that allows
nonlinear equality constraints.

  * or via parametric bootstrap/bootMer ...


From marklhc at gmail.com  Sat Sep 13 08:36:44 2014
From: marklhc at gmail.com (Mark Lai)
Date: Sat, 13 Sep 2014 01:36:44 -0500
Subject: [R-sig-ME] SE and CI for ICC
In-Reply-To: <CALho=DacTOsNJOnE7T3vRjtVsnLDxHomN1RTN+yHinr_wGUWBw@mail.gmail.com>
References: <CALho=DacTOsNJOnE7T3vRjtVsnLDxHomN1RTN+yHinr_wGUWBw@mail.gmail.com>
Message-ID: <5413E5FC.2020501@gmail.com>

Hi Masood,

I think you can do a parametric bootstrap for the ICC with the bootMer 
method in lme4. You will need to define the function for obtaining the 
ICC, and then from the bootstrap resamples you can construct your 
confidence intervals (e.g, by taking the 2.5 and the 97.5 percentiles).

Hope this helps,

Mark

On 09/12/2014 11:20 AM, Mohd Masood wrote:
> I am using random intercept logistic model (in lme4) to calculated
> Intraclass correlation coefficient (ICC). lme4 only provides point
> estimates and standard deviation (not standard errors) of variance
> estimates.These
> point estimates can be used to calculated point estimates for ICC. The
> problem is how can I calculate standard error and confidence interval for
> ICC. I couldn't find any literature showing formula to calculate confidence
> interval around ICC.  Or is it not possible to calculate SE and CI for ICC
> due to skewed sampling distribution (Please see PMCID: PMC3426610).
>
> Thanks
> Masood
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From coanil at posteo.org  Sat Sep 13 09:59:12 2014
From: coanil at posteo.org (Michael Cone)
Date: Sat, 13 Sep 2014 09:59:12 +0200
Subject: [R-sig-ME] SE and CI for ICC
In-Reply-To: <5413711F.8080009@u.washington.edu>
References: <loom.20140912T215326-401@post.gmane.org>
	<5413711F.8080009@u.washington.edu>
Message-ID: <4725a3b46410eaf61a3846dc3fb98bdf@posteo.de>

Dave,
I am trying to learn more about repeatability and method comparisons 
right now, and this article was helpful for me. Thanks.
Do you happen to know of a similar review on modeling method comparison 
studies when reference values are known?

Michael

Am 13.09.2014 00:18 schrieb David Atkins:
> Masood--
> 
> If memory serves, the following article might be helpful (and, I
> believe had associated R code):
> 
> http://www.ncbi.nlm.nih.gov/pubmed/20569253
> 
> Biol Rev Camb Philos Soc. 2010 Nov;85(4):935-56. doi:
> 10.1111/j.1469-185X.2010.00141.x.
> 
> Repeatability for Gaussian and non-Gaussian data: a practical guide
> for biologists.
> 
> Nakagawa S1, Schielzeth H.
> 
> [Note that repeatability = ICC]
> 
> Hope that helps.
> 
> cheers, Dave
> 
> --
> Dave Atkins, PhD
> 
> Research Professor
> Department of Psychiatry and Behavioral Science
> University of Washington
> datkins at u.washington.edu
> http://depts.washington.edu/cshrb/david-atkins/#more-48
> 
> "You can never solve a problem on the level on which it was created."
> (attributed to) Albert Einstein
> 
> Mohd Masood <drmasoodmohd at ...> writes:
> 
>> 
>> I am using random intercept logistic model (in lme4) to calculated
>> Intraclass correlation coefficient (ICC). lme4 only provides point
>> estimates and standard deviation (not standard errors) of variance
>> estimates.These
>> point estimates can be used to calculated point estimates for ICC. 
>> The
>> problem is how can I calculate standard error and confidence interval 
>> for
>> ICC. I couldn't find any literature showing formula to
>> calculate confidence
>> interval around ICC.  Or is it not possible to calculate
>> SE and CI for ICC
>> due to skewed sampling distribution (Please see PMCID: PMC3426610).
>> 
>> Thanks
>> Masood
>> 
> 
> 
>   Some possibilities:
> 
>  * If you want the standard deviations of the variance estimates
> (keeping the strong caveats about non-Normal sampling distributions
> in mind), you could adapt the approach shown in
> http://rpubs.com/bbolker/varwald  (presumably formulas
> for confidence intervals
> of the ICC based on the variances of the estimates of the RE variances
> are using the delta method?  I don't know this literature)
> 
>  * as suggested in a previous e-mail, it might be possible to
> compute profile confidence intervals on the ICCs by using
> nloptr::auglag or some other optimization framework that allows
> nonlinear equality constraints.
> 
>  * or via parametric bootstrap/bootMer ...
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From maechler at stat.math.ethz.ch  Sat Sep 13 16:32:17 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 13 Sep 2014 16:32:17 +0200
Subject: [R-sig-ME] SE and CI for ICC
In-Reply-To: <CALho=DacTOsNJOnE7T3vRjtVsnLDxHomN1RTN+yHinr_wGUWBw@mail.gmail.com>
References: <CALho=DacTOsNJOnE7T3vRjtVsnLDxHomN1RTN+yHinr_wGUWBw@mail.gmail.com>
Message-ID: <21524.21873.753635.712320@stat.math.ethz.ch>

>>>>> Mohd Masood <drmasoodmohd at gmail.com>
>>>>>     on Sat, 13 Sep 2014 00:20:34 +0800 writes:

    > I am using random intercept logistic model (in lme4) to calculated
    > Intraclass correlation coefficient (ICC). lme4 only provides point
    > estimates and standard deviation (not standard errors) of variance
    > estimates.

Hmm, this is not true:

  > require(lme4)
  > summary(fm1 <- lmer(Reaction ~ Days + (Days | Subject), sleepstudy))
  Linear mixed model fit by REML ['lmerMod']
  Formula: Reaction ~ Days + (Days | Subject)
     Data: sleepstudy

  REML criterion at convergence: 1743.6

  Scaled residuals: 
      Min      1Q  Median      3Q     Max 
  -3.9536 -0.4634  0.0231  0.4634  5.1793 

  Random effects:
   Groups   Name        Variance Std.Dev. Corr
   Subject  (Intercept) 612.09   24.740       
	    Days         35.07    5.922   0.07
   Residual             654.94   25.592       
  Number of obs: 180, groups:  Subject, 18

  Fixed effects:
	      Estimate Std. Error t value
  (Intercept)  251.405      6.825   36.84
  Days          10.467      1.546    6.77

  Correlation of Fixed Effects:
       (Intr)
  Days -0.138
  > pfm1 <- profile(fm1) # the main computation for the confint() below:
  > confint(pfm1)
		    2.5 %     97.5 %
  .sig01       14.3814761  37.715996
  .sig02       -0.4815007   0.684986
  .sig03        3.8011641   8.753383
  .sigma       22.8982669  28.857997
  (Intercept) 237.6806955 265.129515
  Days          7.3586533  13.575919
  > confint(pfm1, level = 0.99)
		   0.5 %      99.5 %
  .sig01       11.697963  43.9249121
  .sig02       -0.611183   0.8620229
  .sig03        3.313161  10.1306220
  .sigma       22.149064  30.0282535
  (Intercept) 232.619539 270.1906680
  Days          6.212281  14.7222899
  > 

does provide confidence intervals (CI) also for all variance
parameters, not just the fixed effects 

and you should really also look at

  require(lattice)
  xyplot(pfm1)  

which shows you confidence intervals to a couple of levels simultaneously,
and notably also visualizes how (un)reasonable a Gaussian
approximation to the sigma's would be.

Martin Maechler, ETH Zurich

    > These point estimates can be used to calculated point estimates for ICC. The
    > problem is how can I calculate standard error and confidence interval for
    > ICC. I couldn't find any literature showing formula to calculate confidence
    > interval around ICC.  Or is it not possible to calculate SE and CI for ICC
    > due to skewed sampling distribution (Please see PMCID: PMC3426610).

    > Thanks
    > Masood

    > [[alternative HTML version deleted]]

    > _______________________________________________
    > R-sig-mixed-models at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From coanil at posteo.org  Sun Sep 14 20:03:58 2014
From: coanil at posteo.org (Michael Cone)
Date: Sun, 14 Sep 2014 20:03:58 +0200
Subject: [R-sig-ME] Obscure convergence warning in optwrap() - convergence
 code 3 from bobyqa
Message-ID: <f124da5ce3261fbb432dc0fc9998248c@posteo.de>

Using lmer (1.1.7, compiled today from the github master branch), I got 
the following warning:

In optwrap(object at optinfo$optimizer, ff, x0, lower = lower, control = 
control$optCtrl,  :
   convergence code 3 from bobyqa: bobyqa -- a trust region step failed 
to reduce q

These warnings are thrown while calculating bootstrap confidence 
intervals with confint() for a simple repeated-measures model. The 
warnings seem to depend on the numerical value of the dependent variable 
(see code below).

Likelihood profiling also throws warnings:

1: In optwrap(optimizer, devfun, x at theta, lower = x at lower, calc.derivs 
= TRUE) :
   convergence code 3 from bobyqa: bobyqa -- a trust region step failed 
to reduce q
2: In optwrap(optimizer, par = start, fn = function(x) dd(mkpar(npar1,  
:
   convergence code 3 from bobyqa: bobyqa -- a trust region step failed 
to reduce q
3: In optwrap(optimizer, par = thopt, fn = mkdevfun(rho, 0L), lower = 
fitted at lower) :
   convergence code 3 from bobyqa: bobyqa -- a trust region step failed 
to reduce q

Someone encountered the same warnings in 2013 and, on Ben Bolker's 
suggestion, tracked down the Fortran code responsible, but apparently 
couldn?t identify the problem.
http://stats.stackexchange.com/questions/89945/meaning-of-a-convergence-warning-in-glmer

Here's an example:

set.seed(12345)
## 30 subjects, 1000 repeated measures on each
subj.true <- rep(rnorm(30, 16000, 3500), each=1000)
df <- data.frame(subj = as.factor(rep(LETTERS[1:30], each=1000)),
                  subj.true = subj.true,
                  meas = subj.true + rnorm(30000, 0, 1200))
## this works without errors
fm1 <- lmer(meas ~ 1 + (1|subj), data=df)
boot.pp <- confint(fm1, method="boot", nsim=200)
## this throws 12 identical 'convergence code 3' warnings
df$pct <- 100*(df$meas - df$subj.true)/df$subj.true
fm2 <- lmer(pct ~ 1 + (1|subj), data=df)
boot.pp2 <- confint(fm2, method="boot", nsim=200)
## likelihood profiling gives 3 warnings
lr.pp2 <- confint(fm2)

Is this something obvious/known? I apologize if so, but I didn't find 
much regarding this on the web.

> sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_1.1-7       Rcpp_0.11.2      Matrix_1.1-2     data.table_1.9.2

loaded via a namespace (and not attached):
  [1] boot_1.3-9      compiler_3.0.2  grid_3.0.2      lattice_0.20-24
  [5] MASS_7.3-29     minqa_1.2.3     nlme_3.1-113    nloptr_1.0.4
  [9] plyr_1.8.1      reshape2_1.4    splines_3.0.2   stringr_0.6.2
[13] tools_3.0.2


Michael


From ken.beath at mq.edu.au  Mon Sep 15 06:21:37 2014
From: ken.beath at mq.edu.au (Ken Beath)
Date: Mon, 15 Sep 2014 14:21:37 +1000
Subject: [R-sig-ME] Problem with profile and glmer
Message-ID: <CAF5_5cyKQEyuVG8N4V=V+AWCjMUK9PqqhRpKyN1ZNk2eOPnasQ@mail.gmail.com>

With the following code

library(lme4)
data(cbpp)

testprofile <- function(herd,incidence,size,period) {
  thedata <- data.frame(herd,incidence,size,period)
  gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
              data = thedata, family = binomial)
  pr4 <- profile(gm1)
}

testprofile(cbpp$incidence,cbpp$incidence,cbpp$size,cbpp$period)

I get the error in profile " Error: 'data' not found, but variables found
in environment of formula: try specifying 'formula' as a formula rather
than a string in the original model"

I have tried with as.formula for the formula. The profile and glmer work
fine when they are called outside the function.
-- 

*Ken Beath*
Lecturer
Statistics Department
MACQUARIE UNIVERSITY NSW 2109, Australia

Phone: +61 (0)2 9850 8516

Building E4A, room 526
http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/

CRICOS Provider No 00002J
This message is intended for the addressee named and may...{{dropped:9}}


From lorenz.gygax at agroscope.admin.ch  Mon Sep 15 08:15:19 2014
From: lorenz.gygax at agroscope.admin.ch (lorenz.gygax at agroscope.admin.ch)
Date: Mon, 15 Sep 2014 06:15:19 +0000
Subject: [R-sig-ME] Confidence interval for relative contribution of
 random effect variance
Message-ID: <B291F8F571C9494EA3EAF8C8B471333F22E0ED9F@WBF-C7001.bk.evdad.admin.ch>

Dear all,

based on Bens suggestion (and it has come up again in another post) I made a first try in using bootMer and boot.ci.

> [... snip]
> 
> > > Now, apart from this aspect, can confint be tweaked to calculate not
> > > only the confidence interval of the 'raw' parameters but also for
> > > some function of the parameters? If not, do I need to move to an
> > > implementation using MCMC methods (MCMCglmm, Bugs-type of
> > > approaches, STAN or Laplaces-Demon) to reach my aim or do you have
> > > another (simpler) suggestion?
> >
> >   You can compute parametric bootstrap confidence intervals of
> > any quantity you want by applying boot.ci() to the results of bootMer()
> > (bootMer()'s second argument is the summary function, which you
> > can define however you like).  This is computationally expensive,
> > though (even more expensive than MCMC-type computations).
> 
> Ok. The latter may not be such an issue. This sounds doable and I will be looking
> into it! (And I can report back on my success ...)

I first defined a function that calculates the quotient of the within-subject variance (given by the variable 'ID' in my typical models) relative to the summed within-subject variance (subject is on the highest nesting level in the nested random effects that I currently use):

withinVar.fn <- function (mer.obj, subj= 'ID') {
    vars <- as.data.frame (VarCorr (mer.obj))
    vars [vars [, 'grp'] == subj, 'vcov'] / sum (vars [vars [, 'grp'] != subj, 'vcov'])
}

Then you can run the bootstrap and calculate the confidence interval:

HHbT.boot <- bootMer (HHbT.fin.lmer, withinVar.fn, nsim= 1000, parallel= 'multicore', ncpus= 2)
boot.ci (HHbT.boot, type= 'perc')

I was a bit worried about the distribution of my variable of interest being a quotient and also tried log-ing the division. At least in this example, the distribution seems even worse with the transformation and the results of the percentile confidence interval using the non-transformed quotient seems to give quite reasonable results.

Any hints to where I may have been (too) na?ve in my approach are appreciated.

Many thanks again. Regards, Lorenz


From emmanuel.curis at parisdescartes.fr  Mon Sep 15 09:23:32 2014
From: emmanuel.curis at parisdescartes.fr (Emmanuel Curis)
Date: Mon, 15 Sep 2014 09:23:32 +0200
Subject: [R-sig-ME] Problem with profile and glmer
In-Reply-To: <CAF5_5cyKQEyuVG8N4V=V+AWCjMUK9PqqhRpKyN1ZNk2eOPnasQ@mail.gmail.com>
References: <CAF5_5cyKQEyuVG8N4V=V+AWCjMUK9PqqhRpKyN1ZNk2eOPnasQ@mail.gmail.com>
Message-ID: <20140915072332.GA22544@info124.pharmacie.univ-paris5.fr>

It works with replacing

 thedata <- data.frame(herd,incidence,size,period)

with 

 thedata <<- data.frame(herd,incidence,size,period)

 so it seems that when searching for thedata, glmer searches in the
 parent environnement of testprofile() and not in the local
 environnement of testprofile().

I guess it has to do with the line

glmod <- eval(mc, parent.frame(1L))

but my knowledge stops here...

Hope that will help as a workaround until developpers find a fix for
that...

On Mon, Sep 15, 2014 at 02:21:37PM +1000, Ken Beath wrote:
? With the following code
? 
? library(lme4)
? data(cbpp)
? 
? testprofile <- function(herd,incidence,size,period) {
?   thedata <- data.frame(herd,incidence,size,period)
?   gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
?               data = thedata, family = binomial)
?   pr4 <- profile(gm1)
? }
? 
? testprofile(cbpp$incidence,cbpp$incidence,cbpp$size,cbpp$period)
? 
? I get the error in profile " Error: 'data' not found, but variables found
? in environment of formula: try specifying 'formula' as a formula rather
? than a string in the original model"
? 
? I have tried with as.formula for the formula. The profile and glmer work
? fine when they are called outside the function.
? -- 
? 
? *Ken Beath*
? Lecturer
? Statistics Department
? MACQUARIE UNIVERSITY NSW 2109, Australia
? 
? Phone: +61 (0)2 9850 8516
? 
? Building E4A, room 526
? http://stat.mq.edu.au/our_staff/staff_-_alphabetical/staff/beath,_ken/
? 
? CRICOS Provider No 00002J
? This message is intended for the addressee named and may...{{dropped:9}}
? 
? _______________________________________________
? R-sig-mixed-models at r-project.org mailing list
? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From nirmala.liyanage at sydney.edu.au  Mon Sep 15 09:47:51 2014
From: nirmala.liyanage at sydney.edu.au (Nirmala Liyanage)
Date: Mon, 15 Sep 2014 07:47:51 +0000
Subject: [R-sig-ME] Is there a way to include both time correlation term and
 spatial correlation term in single lme model?
Message-ID: <101AB1D030993746A4290F1D7F0F67B4B9ECE6A4@ex-mbx-pro-05>

Dear All,
I have an irregular time series dataset of soil moisture measured over two years period on a forest soil in Australia which I collected as a student. I suspect my dataset has a temporal and spatial correlation structure.  The data were collected in seven sampling events (first two within six months apart, second and third within year and after that approximately one month apart between sampling).  Data were also collected in two soil depths.  I have six predictor variables and I want to add both spatial and temporal correlation in a single model.  The summary of the model I tried, which only includes spatial correlation and time as a random effect, is as follows.


ARSMC7Gaus.lme <- lme(LogMC~V1 + V2 +V3 + V4 + V5  + V6 + as.factor(SDepth), random = ~1|Time,correlation = corGaus(1, form = ~xmga+ymga, nugget = TRUE), data=ARSMC6)



summary (ARSMC7Gaus.lme)

Linear mixed-effects model fit by REML
Data: ARSMC6
       AIC      BIC   logLik
  -488.679 -441.782 256.3395

Random effects:
Formula: ~1 | Time
        (Intercept)  Residual
StdDev:  0.01643712 0.1243742

Correlation Structure: Gaussian spatial correlation
Formula: ~xmga + ymga | Time
 Parameter estimate(s):
    range    nugget
1.5809160 0.3307183
Fixed effects: LogMC ~ V1 + V2 + V3 + V4 + V5 + V6 + as.factor(SDepth)
                        Value Std.Error  DF    t-value p-value
(Intercept)          3.728646 0.4874570 365   7.649179  0.0000
V1                   0.001482 0.0004610   3   3.214425  0.0488
V2                   0.005831 0.0020212 365   2.884979  0.0041
V3                  -0.061032 0.0060525   3 -10.083730  0.0021
V4                   0.002323 0.0001736   3  13.381117  0.0009
V5                   0.008451 0.0029611 365   2.853999  0.0046
V6                   0.003676 0.0005210 365   7.054582  0.0000
as.factor(SDepth)15 -0.029451 0.0080961 365  -3.637632  0.0003
Correlation:
                    (Intr)  V1     V2     V3     V4     V5     V6
V1                  -0.101
V2                   0.181  0.000
V3                   0.276 -0.017 -0.001
V4                   0.732 -0.128  0.001  0.402
V5                  -0.488 -0.013 -0.097  0.001  0.011
V6                  -0.657 -0.031 -0.328  0.001  0.027  0.688
as.factor(SDepth)15 -0.096  0.048 -0.097  0.047 -0.094  0.009  0.030

Standardized Within-Group Residuals:
        Min          Q1         Med          Q3         Max
-3.55288638 -0.60507563 -0.04411639  0.54770394  3.87767186

Number of Observations: 376
Number of Groups: 7

Above model is significantly different from the null model (without spatial structure and time as a random effect).


               Model df       AIC       BIC   logLik   Test L.Ratio p-value

ARSMC7.lme         1 10 -396.4002 -357.3194 208.2001

ARSMC7Gaus.lme     2 12 -488.6790 -441.7820 256.3395 1 vs 2 96.2788  <.0001

I used R 3.0.1 and package nlme

Note; to make this model to work I had to add 0.05cm to x coordinate of the second soil depth (shift from original x coordinates of all second depth values). Otherwise I got following error message (##Error in getCovariate.corSpatial(object, data = data) :
##cannot have zero distances in "corSpatial")

My questions are
1. Ideally, we would like to have time as a correlation term in the model and no random effect (i.e. gls). Is there a way that I could also include time as a correlation term in addition to the spatial correlation term?
2. Currently Time is coded as 1-7 but they are not recorded in regular time intervals. What is the best way to put that in to the model?

Thank you very much,
Kind regards,
Nir


	[[alternative HTML version deleted]]


From Thierry.ONKELINX at inbo.be  Mon Sep 15 10:01:56 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 15 Sep 2014 08:01:56 +0000
Subject: [R-sig-ME] Is there a way to include both time correlation term
 and spatial correlation term in single lme model?
In-Reply-To: <101AB1D030993746A4290F1D7F0F67B4B9ECE6A4@ex-mbx-pro-05>
References: <101AB1D030993746A4290F1D7F0F67B4B9ECE6A4@ex-mbx-pro-05>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3AEC476@inbomail.inbo.be>

Dear Nir,

I doubt that 7 irregular time points allows to estimate a sensible autocorrelation structure...

The INLA package allows models with multiple random effects. Each random effect can have a different correlation structure. Note that with INLA the random effects are correlated whereas nlme adds a correlation structure to the residuals.

You can find the INLA package at r-inla.org

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Nirmala Liyanage
Verzonden: maandag 15 september 2014 9:48
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Is there a way to include both time correlation term and spatial correlation term in single lme model?

Dear All,
I have an irregular time series dataset of soil moisture measured over two years period on a forest soil in Australia which I collected as a student. I suspect my dataset has a temporal and spatial correlation structure.  The data were collected in seven sampling events (first two within six months apart, second and third within year and after that approximately one month apart between sampling).  Data were also collected in two soil depths.  I have six predictor variables and I want to add both spatial and temporal correlation in a single model.  The summary of the model I tried, which only includes spatial correlation and time as a random effect, is as follows.


ARSMC7Gaus.lme <- lme(LogMC~V1 + V2 +V3 + V4 + V5  + V6 + as.factor(SDepth), random = ~1|Time,correlation = corGaus(1, form = ~xmga+ymga, nugget = TRUE), data=ARSMC6)



summary (ARSMC7Gaus.lme)

Linear mixed-effects model fit by REML
Data: ARSMC6
       AIC      BIC   logLik
  -488.679 -441.782 256.3395

Random effects:
Formula: ~1 | Time
        (Intercept)  Residual
StdDev:  0.01643712 0.1243742

Correlation Structure: Gaussian spatial correlation
Formula: ~xmga + ymga | Time
 Parameter estimate(s):
    range    nugget
1.5809160 0.3307183
Fixed effects: LogMC ~ V1 + V2 + V3 + V4 + V5 + V6 + as.factor(SDepth)
                        Value Std.Error  DF    t-value p-value
(Intercept)          3.728646 0.4874570 365   7.649179  0.0000
V1                   0.001482 0.0004610   3   3.214425  0.0488
V2                   0.005831 0.0020212 365   2.884979  0.0041
V3                  -0.061032 0.0060525   3 -10.083730  0.0021
V4                   0.002323 0.0001736   3  13.381117  0.0009
V5                   0.008451 0.0029611 365   2.853999  0.0046
V6                   0.003676 0.0005210 365   7.054582  0.0000
as.factor(SDepth)15 -0.029451 0.0080961 365  -3.637632  0.0003
Correlation:
                    (Intr)  V1     V2     V3     V4     V5     V6
V1                  -0.101
V2                   0.181  0.000
V3                   0.276 -0.017 -0.001
V4                   0.732 -0.128  0.001  0.402
V5                  -0.488 -0.013 -0.097  0.001  0.011
V6                  -0.657 -0.031 -0.328  0.001  0.027  0.688
as.factor(SDepth)15 -0.096  0.048 -0.097  0.047 -0.094  0.009  0.030

Standardized Within-Group Residuals:
        Min          Q1         Med          Q3         Max
-3.55288638 -0.60507563 -0.04411639  0.54770394  3.87767186

Number of Observations: 376
Number of Groups: 7

Above model is significantly different from the null model (without spatial structure and time as a random effect).


               Model df       AIC       BIC   logLik   Test L.Ratio p-value

ARSMC7.lme         1 10 -396.4002 -357.3194 208.2001

ARSMC7Gaus.lme     2 12 -488.6790 -441.7820 256.3395 1 vs 2 96.2788  <.0001

I used R 3.0.1 and package nlme

Note; to make this model to work I had to add 0.05cm to x coordinate of the second soil depth (shift from original x coordinates of all second depth values). Otherwise I got following error message (##Error in getCovariate.corSpatial(object, data = data) :
##cannot have zero distances in "corSpatial")

My questions are
1. Ideally, we would like to have time as a correlation term in the model and no random effect (i.e. gls). Is there a way that I could also include time as a correlation term in addition to the spatial correlation term?
2. Currently Time is coded as 1-7 but they are not recorded in regular time intervals. What is the best way to put that in to the model?

Thank you very much,
Kind regards,
Nir


        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From markpayneatwork at gmail.com  Mon Sep 15 21:00:44 2014
From: markpayneatwork at gmail.com (Mark Payne)
Date: Mon, 15 Sep 2014 21:00:44 +0200
Subject: [R-sig-ME] Multiple independent random effects
In-Reply-To: <loom.20140912T215724-855@post.gmane.org>
References: <CAGBzUO8+XR7borNEZnWb2iaAJ5U5qCnAO5r1rmQSGWen1dN0EQ@mail.gmail.com>
	<d658a15eea62bf776b6eec97fedd1a26@posteo.de>
	<loom.20140912T215724-855@post.gmane.org>
Message-ID: <CAGBzUO-3u-UfMqkWENtQdc-jH+f7ci5Eib4HqEbfmUUDAA7BZQ@mail.gmail.com>

Thanks for the replies. The quick fix of course is to just convert the
random effects to fixed effects and do the rest with gls()  which works in
this situation quite acceptably. But I'm surprised about this - is there a
technical constraint that means that the two can't be combined? Or is it
just a matter of history?

Mark

On 12 September 2014 22:00, Ben Bolker <bbolker at gmail.com> wrote:

> Michael Cone <coanil at ...> writes:
>
> >
> > Mark, I don't think that's possible with lme4/lmer right now.
> >
> > Michael
>
>   It's possible, but not easy.
>   http://rpubs.com/bbolker/varfac shows how to set up
> formulae/model structures that allow for different RE variances,
> or different residual variances, across different levels of a
> fixed treatment factor.
>
>   Basically, you have to set up an observation-level random
> effect and dummy variables for each level of C other than
> the first, then add
>
>  (0+cLevel2|obs) + (0+cLevel3|obs) + (0+cLevel4|obs) ...
>
> or equivalently you can use
>
>  (0+dummy(C,"level2")|obs) + (0+dummy(C,"level3")|obs) + ...
>
>   This is more elegantly doable with the flexLambda development
> branch ...
>
> >
> > Am 12.09.2014 12:12 schrieb Mark Payne:
> > > Hi,
> > >
> > > I have a mixed-effects model in lme4 like so
> > >
> > > mdl <- lmer(T ~1 + (1|A) + (1|B),...)
> > >
> > > where the factors A and B are being modelled as independent random
> > > effects.
> > > However, there is also heteroscedasticity in the problem, where the
> > > variance of T depends on a third grouping factor, lets called it C.
> > >
> > > I can fit such a model in the nlme package, using  the
> > > weights=varIdent(form=~1| C)  argument, but this package doesn't seem
> > > to
> > > easily support independent random effects of the form shown above...
> > >
> > > How can I get the best of both worlds here?
> > >
> > > Mark
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From nirmala.liyanage at sydney.edu.au  Tue Sep 16 12:50:35 2014
From: nirmala.liyanage at sydney.edu.au (Nirmala Liyanage)
Date: Tue, 16 Sep 2014 10:50:35 +0000
Subject: [R-sig-ME] Is there a way to include both time correlation term
 and spatial correlation term in a single lme model?
Message-ID: <101AB1D030993746A4290F1D7F0F67B4B9ED2F71@ex-mbx-pro-05>

Dear Thierry,
Thank you very much.
Is there way to handle multiple soil depths without shifting x coordinate values?
kind Regards,
Nirmala
________________________________________
From: ONKELINX, Thierry [Thierry.ONKELINX at inbo.be]
Sent: Monday, 15 September 2014 6:01 PM
To: Nirmala Liyanage; r-sig-mixed-models at r-project.org
Subject: RE: [R-sig-ME] Is there a way to include both time correlation term and spatial correlation term in single lme model?

Dear Nir,

I doubt that 7 irregular time points allows to estimate a sensible autocorrelation structure...

The INLA package allows models with multiple random effects. Each random effect can have a different correlation structure. Note that with INLA the random effects are correlated whereas nlme adds a correlation structure to the residuals.

You can find the INLA package at r-inla.org

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Nirmala Liyanage
Verzonden: maandag 15 september 2014 9:48
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Is there a way to include both time correlation term and spatial correlation term in single lme model?

Dear All,
I have an irregular time series dataset of soil moisture measured over two years period on a forest soil in Australia which I collected as a student. I suspect my dataset has a temporal and spatial correlation structure.  The data were collected in seven sampling events (first two within six months apart, second and third within year and after that approximately one month apart between sampling).  Data were also collected in two soil depths.  I have six predictor variables and I want to add both spatial and temporal correlation in a single model.  The summary of the model I tried, which only includes spatial correlation and time as a random effect, is as follows.


ARSMC7Gaus.lme <- lme(LogMC~V1 + V2 +V3 + V4 + V5  + V6 + as.factor(SDepth), random = ~1|Time,correlation = corGaus(1, form = ~xmga+ymga, nugget = TRUE), data=ARSMC6)



summary (ARSMC7Gaus.lme)

Linear mixed-effects model fit by REML
Data: ARSMC6
       AIC      BIC   logLik
  -488.679 -441.782 256.3395

Random effects:
Formula: ~1 | Time
        (Intercept)  Residual
StdDev:  0.01643712 0.1243742

Correlation Structure: Gaussian spatial correlation
Formula: ~xmga + ymga | Time
 Parameter estimate(s):
    range    nugget
1.5809160 0.3307183
Fixed effects: LogMC ~ V1 + V2 + V3 + V4 + V5 + V6 + as.factor(SDepth)
                        Value Std.Error  DF    t-value p-value
(Intercept)          3.728646 0.4874570 365   7.649179  0.0000
V1                   0.001482 0.0004610   3   3.214425  0.0488
V2                   0.005831 0.0020212 365   2.884979  0.0041
V3                  -0.061032 0.0060525   3 -10.083730  0.0021
V4                   0.002323 0.0001736   3  13.381117  0.0009
V5                   0.008451 0.0029611 365   2.853999  0.0046
V6                   0.003676 0.0005210 365   7.054582  0.0000
as.factor(SDepth)15 -0.029451 0.0080961 365  -3.637632  0.0003
Correlation:
                    (Intr)  V1     V2     V3     V4     V5     V6
V1                  -0.101
V2                   0.181  0.000
V3                   0.276 -0.017 -0.001
V4                   0.732 -0.128  0.001  0.402
V5                  -0.488 -0.013 -0.097  0.001  0.011
V6                  -0.657 -0.031 -0.328  0.001  0.027  0.688
as.factor(SDepth)15 -0.096  0.048 -0.097  0.047 -0.094  0.009  0.030

Standardized Within-Group Residuals:
        Min          Q1         Med          Q3         Max
-3.55288638 -0.60507563 -0.04411639  0.54770394  3.87767186

Number of Observations: 376
Number of Groups: 7

Above model is significantly different from the null model (without spatial structure and time as a random effect).


               Model df       AIC       BIC   logLik   Test L.Ratio p-value

ARSMC7.lme         1 10 -396.4002 -357.3194 208.2001

ARSMC7Gaus.lme     2 12 -488.6790 -441.7820 256.3395 1 vs 2 96.2788  <.0001

I used R 3.0.1 and package nlme

Note; to make this model to work I had to add 0.05cm to x coordinate of the second soil depth (shift from original x coordinates of all second depth values). Otherwise I got following error message (##Error in getCovariate.corSpatial(object, data = data) :
##cannot have zero distances in "corSpatial")

My questions are
1. Ideally, we would like to have time as a correlation term in the model and no random effect (i.e. gls). Is there a way that I could also include time as a correlation term in addition to the spatial correlation term?
2. Currently Time is coded as 1-7 but they are not recorded in regular time intervals. What is the best way to put that in to the model?

Thank you very much,
Kind regards,
Nir


        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From Thierry.ONKELINX at inbo.be  Tue Sep 16 12:57:42 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 16 Sep 2014 10:57:42 +0000
Subject: [R-sig-ME] Is there a way to include both time correlation term
 and spatial correlation term in a single lme model?
In-Reply-To: <101AB1D030993746A4290F1D7F0F67B4B9ED2F71@ex-mbx-pro-05>
References: <101AB1D030993746A4290F1D7F0F67B4B9ED2F71@ex-mbx-pro-05>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3AEEA4C@inbomail.inbo.be>

Yes. INLA handles that by adding a random effect for location (with spatial autocorrelation in the levels of the random effect).

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: Nirmala Liyanage [mailto:nirmala.liyanage at sydney.edu.au]
Verzonden: dinsdag 16 september 2014 12:51
Aan: ONKELINX, Thierry
CC: r-sig-mixed-models at r-project.org
Onderwerp: RE: [R-sig-ME] Is there a way to include both time correlation term and spatial correlation term in a single lme model?

Dear Thierry,
Thank you very much.
Is there way to handle multiple soil depths without shifting x coordinate values?
kind Regards,
Nirmala
________________________________________
From: ONKELINX, Thierry [Thierry.ONKELINX at inbo.be]
Sent: Monday, 15 September 2014 6:01 PM
To: Nirmala Liyanage; r-sig-mixed-models at r-project.org
Subject: RE: [R-sig-ME] Is there a way to include both time correlation term and spatial correlation term in single lme model?

Dear Nir,

I doubt that 7 irregular time points allows to estimate a sensible autocorrelation structure...

The INLA package allows models with multiple random effects. Each random effect can have a different correlation structure. Note that with INLA the random effects are correlated whereas nlme adds a correlation structure to the residuals.

You can find the INLA package at r-inla.org

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Nirmala Liyanage
Verzonden: maandag 15 september 2014 9:48
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Is there a way to include both time correlation term and spatial correlation term in single lme model?

Dear All,
I have an irregular time series dataset of soil moisture measured over two years period on a forest soil in Australia which I collected as a student. I suspect my dataset has a temporal and spatial correlation structure.  The data were collected in seven sampling events (first two within six months apart, second and third within year and after that approximately one month apart between sampling).  Data were also collected in two soil depths.  I have six predictor variables and I want to add both spatial and temporal correlation in a single model.  The summary of the model I tried, which only includes spatial correlation and time as a random effect, is as follows.


ARSMC7Gaus.lme <- lme(LogMC~V1 + V2 +V3 + V4 + V5  + V6 + as.factor(SDepth), random = ~1|Time,correlation = corGaus(1, form = ~xmga+ymga, nugget = TRUE), data=ARSMC6)



summary (ARSMC7Gaus.lme)

Linear mixed-effects model fit by REML
Data: ARSMC6
       AIC      BIC   logLik
  -488.679 -441.782 256.3395

Random effects:
Formula: ~1 | Time
        (Intercept)  Residual
StdDev:  0.01643712 0.1243742

Correlation Structure: Gaussian spatial correlation
Formula: ~xmga + ymga | Time
 Parameter estimate(s):
    range    nugget
1.5809160 0.3307183
Fixed effects: LogMC ~ V1 + V2 + V3 + V4 + V5 + V6 + as.factor(SDepth)
                        Value Std.Error  DF    t-value p-value
(Intercept)          3.728646 0.4874570 365   7.649179  0.0000
V1                   0.001482 0.0004610   3   3.214425  0.0488
V2                   0.005831 0.0020212 365   2.884979  0.0041
V3                  -0.061032 0.0060525   3 -10.083730  0.0021
V4                   0.002323 0.0001736   3  13.381117  0.0009
V5                   0.008451 0.0029611 365   2.853999  0.0046
V6                   0.003676 0.0005210 365   7.054582  0.0000
as.factor(SDepth)15 -0.029451 0.0080961 365  -3.637632  0.0003
Correlation:
                    (Intr)  V1     V2     V3     V4     V5     V6
V1                  -0.101
V2                   0.181  0.000
V3                   0.276 -0.017 -0.001
V4                   0.732 -0.128  0.001  0.402
V5                  -0.488 -0.013 -0.097  0.001  0.011
V6                  -0.657 -0.031 -0.328  0.001  0.027  0.688
as.factor(SDepth)15 -0.096  0.048 -0.097  0.047 -0.094  0.009  0.030

Standardized Within-Group Residuals:
        Min          Q1         Med          Q3         Max
-3.55288638 -0.60507563 -0.04411639  0.54770394  3.87767186

Number of Observations: 376
Number of Groups: 7

Above model is significantly different from the null model (without spatial structure and time as a random effect).


               Model df       AIC       BIC   logLik   Test L.Ratio p-value

ARSMC7.lme         1 10 -396.4002 -357.3194 208.2001

ARSMC7Gaus.lme     2 12 -488.6790 -441.7820 256.3395 1 vs 2 96.2788  <.0001

I used R 3.0.1 and package nlme

Note; to make this model to work I had to add 0.05cm to x coordinate of the second soil depth (shift from original x coordinates of all second depth values). Otherwise I got following error message (##Error in getCovariate.corSpatial(object, data = data) :
##cannot have zero distances in "corSpatial")

My questions are
1. Ideally, we would like to have time as a correlation term in the model and no random effect (i.e. gls). Is there a way that I could also include time as a correlation term in addition to the spatial correlation term?
2. Currently Time is coded as 1-7 but they are not recorded in regular time intervals. What is the best way to put that in to the model?

Thank you very much,
Kind regards,
Nir


        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * * Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From stefan.vandongen at uantwerpen.be  Wed Sep 17 12:17:22 2014
From: stefan.vandongen at uantwerpen.be (Van Dongen Stefan)
Date: Wed, 17 Sep 2014 10:17:22 +0000
Subject: [R-sig-ME] informative prior for one variance
Message-ID: <B4D4B84E4C26984690619D21577874EAA622A929@xmail32.ad.ua.ac.be>

Dear list members,

We are currently running a tri-variate model in MCMCglmm in order to estimate repeatabilities of and correlations among three behavioral traits. For one variance-component, we have prior data, and thus we would like to use an informative prior distribution for that one component only. Is that possible in MCMCglmm?

many thanks and kind regards

Stefan


-------------------------------------------------------------------------------------------------------------------------
Prof. Dr. Stefan Van Dongen
Evolutionary Ecology - Department of Biology - University of Antwerp (http://www.ua.ac.be/eveco)
StatUA Statistics Center, University of Antwerp (http://www.ua.ac.be/statua)
Groenenborgerlaan 171 - B-2020 Antwerp - Belgium

room V324b, building V, campus Groenenborger
Tel: + 32 3 265 33 36
Fax: + 32 3 265 34 74
http://www.ua.ac.be/stefan.vandongen
--------------------------------------------------------------------------------------------------------------------------


	[[alternative HTML version deleted]]


From stefan.vandongen at uantwerpen.be  Wed Sep 17 12:21:16 2014
From: stefan.vandongen at uantwerpen.be (Van Dongen Stefan)
Date: Wed, 17 Sep 2014 10:21:16 +0000
Subject: [R-sig-ME] distributions and correlations
Message-ID: <B4D4B84E4C26984690619D21577874EAA622A93A@xmail32.ad.ua.ac.be>

Dear all,

In the tri-variate model of behavioral traits from my previous question, one is normally distributed, the others binomial. I am aware of the Nakagawa & Schielzeth (2010) paper on intra-class correlations for non-gaussian data, but am now looking for an extention of that to calculate intra- and inter-observer reliabilities, and for phenotypic correlations between the behavioral traits with different distributions. Any help would be greatly appreciated

kind regards

Stefan

-------------------------------------------------------------------------------------------------------------------------
Prof. Dr. Stefan Van Dongen
Evolutionary Ecology - Department of Biology - University of Antwerp (http://www.ua.ac.be/eveco)
StatUA Statistics Center, University of Antwerp (http://www.ua.ac.be/statua)
Groenenborgerlaan 171 - B-2020 Antwerp - Belgium

room V324b, building V, campus Groenenborger
Tel: + 32 3 265 33 36
Fax: + 32 3 265 34 74
http://www.ua.ac.be/stefan.vandongen
--------------------------------------------------------------------------------------------------------------------------


	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed Sep 17 22:37:53 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 17 Sep 2014 16:37:53 -0400
Subject: [R-sig-ME] predict.merMod
In-Reply-To: <CA+8zgHLZ-SQ4P=u1kGYXk0++XJZsWBJO_DxZfv3RYM9fTm59Dw@mail.gmail.com>
References: <CA+8zgHJ_tTUxTT+EW3L_oh9La9eq4iQQ8_y+uG4NvOyt4OZ11w@mail.gmail.com>
	<53FFB79A.3050709@gmail.com>
	<CA+8zgHLZ-SQ4P=u1kGYXk0++XJZsWBJO_DxZfv3RYM9fTm59Dw@mail.gmail.com>
Message-ID: <CABghstSW4eS++58AwSQ5Dmn1wnewZzR5btStuduHGLkrLzU5Dg@mail.gmail.com>

On Wed, Sep 17, 2014 at 3:22 PM, Alex Whitworth <whitworth.alex at gmail.com>
wrote:

> Dr Bolker,
>
> I tried installing the development / github version of lme4 today and ran
> into an error. R system messages copied below. Any help would be
> appreciated.
>

  I'm cc'ing this to r-sig-mixed-models in case anyone has an idea.
  In the meantime,
* I'm also posting a Windows binary of the latest development version
(today's github version), as built by CRAN's win-builder, to
http://lme4.r-forge.r-project.org/repos/ ; it will take up to 24 hours to
show up there
* I've also put a version at
http://ms.mcmaster.ca/~bolker/R/bin/windows/contrib/3.1/ , available
immediately

  You can install this under R 3.1.* with an appropriate
install.packages(...,repos=...) incantation, or download the .zip file and
install it locally.


>
> On a second note, I'm still working on my "hacked" version of the predict
> function predict.merMod2() . I've solved one of the issues I was running
> into but am still working on an issue related to the random effects for
> grouping variables that are of type factor.
>

  (What other kinds of grouping variables are there ...  ?)



> I hope to be able to solve this / put the solution on stackoverflow in the
> near-ish future.
>

  I'm hoping that the predict.merMod in the development version will solve
all your problems, or that if it doesn't you can create a small
reproducible example and I can fix it centrally.  Provide that you're not
trying to do something really weird/baroque, it makes more sense to have
the package Just Work than to have a proliferation of individual
fixes/workarounds.


>
>
>
> -------------------------------------------------------------------------------------------------------------------
> Restarting R session...
>
> > devtools::install_github("lme4","lme4")
> Installing github repo lme4/master from lme4
> Downloading master.zip from
> https://github.com/lme4/lme4/archive/master.zip
> Installing package from
> C:\Users\alewit\AppData\Local\Temp\RtmpYHOfgM/master.zip
> Installing lme4
> "C:/PROGRA~1/R/R-31~1.1/bin/x64/R" --vanilla CMD build  \
>
> "C:\Users\alewit\AppData\Local\Temp\RtmpYHOfgM\devtools138845a711f6\lme4-master"
> --no-manual  \
>   --no-resave-data
>
> * checking for file
> 'C:\Users\alewit\AppData\Local\Temp\RtmpYHOfgM\devtools138845a711f6\lme4-master/DESCRIPTION'
> ... OK
> * preparing 'lme4':
> * checking DESCRIPTION meta-information ... OK
> * cleaning src
> Warning in cleanup_pkg(pkgdir, Log) :
>   unable to run 'make clean' in 'src'
> * installing the package to build vignettes
> Warning: running command '"C:/PROGRA~1/R/R-31~1.1/bin/x64/Rcmd.exe"
> INSTALL -l "C:\Users\alewit\AppData\Local\Temp\Rtmp2ppmfo\Rinst13c46423bb3"
> --no-multiarch
> "C:/Users/alewit/AppData/Local/Temp/Rtmp2ppmfo/Rbuild13c45c0e2b4e/lme4"'
> had status 1
>       -----------------------------------
> * installing *source* package 'lme4' ...
> ** libs
> Warning: running command 'make -f "Makevars.win" -f
> "C:/PROGRA~1/R/R-31~1.1/etc/x64/Makeconf" -f
> "C:/PROGRA~1/R/R-31~1.1/share/make/winshlib.mk"
> SHLIB_LDFLAGS='$(SHLIB_CXXLDFLAGS)' SHLIB_LD='$(SHLIB_CXXLD)'
> SHLIB="lme4.dll" WIN=64 TCLBIN=64 OBJECTS="external.o glmFamily.o
> mcmcsamp.o optimizer.o predModule.o respModule.o"' had status 127
> ERROR: compilation failed for package 'lme4'
> * removing
> 'C:/Users/alewit/AppData/Local/Temp/Rtmp2ppmfo/Rinst13c46423bb3/lme4'
>       -----------------------------------
> ERROR: package installation failed
> Error: Command failed (1)
>

  I'm not  sure what's going on here.  Googling for "status 127" suggests
that it's a pretty generic error code, so it doesn't give a lot of clues.
Is it possible you're having permissions errors (hinted at by "unable to
run 'make clean' in 'src'"?  What happens if you try disabling vignette
building using build_vignettes=FALSE in your install_github() ?

  Are you able to install other packages from github?


> Alex Whitworth
> whitworth.alex at gmail.com
> (c) 828.429.7478
>
> On Thu, Aug 28, 2014 at 4:13 PM, Ben Bolker <bbolker at gmail.com> wrote:
>
>> On 14-08-28 06:46 PM, Alex Whitworth wrote:
>> > Dr. Bolker,
>> >
>> > Could you please take a look at the function I have posted on
>> > StackOverflow
>> > <
>> http://stackoverflow.com/questions/25538199/design-matrix-for-mlm-from-librarylme4-with-fixed-and-random-effects
>> >?
>> > I believe that it is working correctly and would appreciate your review.
>> >
>> > Thanks,
>> >
>> > Alex Whitworth
>> > whitworth.alex at gmail.com <mailto:whitworth.alex at gmail.com>
>> >
>>
>>   I saw that.  I will look at it if I have a chance.  I am
>> simultaneously impressed by your incentive and ability to solve your own
>> problems and a little bit frustrated at our inability to communicate
>> very effectively: I think your problems could probably be fixed by a
>> fairly minor adjustment to predict.merMod , which is likely better
>> tested and handles a wider range of cases.  On the other hand, if you
>> needed the solution right away ...  ( a workaround that occurred to me
>> would be to make predictions on an augmented set of new data that
>> included all of the factor levels, then throw away the ones you don't
>> want).
>>
>>   If you want to test your function thoroughly, you can try the tests
>> outlined in
>>
>> https://github.com/lme4/lme4/blob/master/tests/predsim.R
>> https://github.com/lme4/lme4/blob/master/inst/tests/test-methods.R
>> (search in this one for context("predict"))
>>
>>  By the way, getting standard errors of predictions that account
>> properly for uncertainty in the random-effects parameters is (alas) a
>> considerably harder problem ...
>>
>>   cheers
>>     Ben Bolker
>>
>>
>

	[[alternative HTML version deleted]]


From whitworth.alex at gmail.com  Thu Sep 18 17:05:58 2014
From: whitworth.alex at gmail.com (Alex Whitworth)
Date: Thu, 18 Sep 2014 08:05:58 -0700
Subject: [R-sig-ME] predict.merMod
In-Reply-To: <CABghstSW4eS++58AwSQ5Dmn1wnewZzR5btStuduHGLkrLzU5Dg@mail.gmail.com>
References: <CA+8zgHJ_tTUxTT+EW3L_oh9La9eq4iQQ8_y+uG4NvOyt4OZ11w@mail.gmail.com>
	<53FFB79A.3050709@gmail.com>
	<CA+8zgHLZ-SQ4P=u1kGYXk0++XJZsWBJO_DxZfv3RYM9fTm59Dw@mail.gmail.com>
	<CABghstSW4eS++58AwSQ5Dmn1wnewZzR5btStuduHGLkrLzU5Dg@mail.gmail.com>
Message-ID: <CA+8zgH+8Ua0riy8P82GG-pzJd2hbiCaxm1_46Rku_txRGw=R2w@mail.gmail.com>

I've tried installing from github on my personal computer as well (in case
there was something with my work network causing a problem). I ran into the
same error. I am able to install other github packages--for example, my
(admittedly very small) package on nongaussian mixture
modeling: devtools::install_github("emclustr","crossfitAL").

I'll re-attempt the binary today--currently having some problems
downloading it.

Regarding question #2 (my hacked function), I completely agree that a
proliferation of predict.merMod functions is undesirable. the random
component of my model is as follows

lmer(... (0 + <logical> + <factor> |subject/school), data= ...)

The issue is selecting the appropriate columns of the random effects
data-frame { ranef(object)[[1]] } when the intercept term is
suppressed--but allowing flexibility in the function when the intercept is
not suppressed. It's made more difficult by the factor variable having 3-4
levels.

Alex



Alex Whitworth
whitworth.alex at gmail.com
(c) 828.429.7478

On Wed, Sep 17, 2014 at 1:37 PM, Ben Bolker <bbolker at gmail.com> wrote:

>
>
> On Wed, Sep 17, 2014 at 3:22 PM, Alex Whitworth <whitworth.alex at gmail.com>
> wrote:
>
>> Dr Bolker,
>>
>> I tried installing the development / github version of lme4 today and ran
>> into an error. R system messages copied below. Any help would be
>> appreciated.
>>
>
>   I'm cc'ing this to r-sig-mixed-models in case anyone has an idea.
>   In the meantime,
> * I'm also posting a Windows binary of the latest development version
> (today's github version), as built by CRAN's win-builder, to
> http://lme4.r-forge.r-project.org/repos/ ; it will take up to 24 hours to
> show up there
> * I've also put a version at
> http://ms.mcmaster.ca/~bolker/R/bin/windows/contrib/3.1/ , available
> immediately
>
>   You can install this under R 3.1.* with an appropriate
> install.packages(...,repos=...) incantation, or download the .zip file and
> install it locally.
>
>
>>
>> On a second note, I'm still working on my "hacked" version of the predict
>> function predict.merMod2() . I've solved one of the issues I was running
>> into but am still working on an issue related to the random effects for
>> grouping variables that are of type factor.
>>
>
>   (What other kinds of grouping variables are there ...  ?)
>
>
>
>> I hope to be able to solve this / put the solution on stackoverflow in
>> the near-ish future.
>>
>
>   I'm hoping that the predict.merMod in the development version will solve
> all your problems, or that if it doesn't you can create a small
> reproducible example and I can fix it centrally.  Provide that you're not
> trying to do something really weird/baroque, it makes more sense to have
> the package Just Work than to have a proliferation of individual
> fixes/workarounds.
>
>
>>
>>
>>
>> -------------------------------------------------------------------------------------------------------------------
>> Restarting R session...
>>
>> > devtools::install_github("lme4","lme4")
>> Installing github repo lme4/master from lme4
>> Downloading master.zip from
>> https://github.com/lme4/lme4/archive/master.zip
>> Installing package from
>> C:\Users\alewit\AppData\Local\Temp\RtmpYHOfgM/master.zip
>> Installing lme4
>> "C:/PROGRA~1/R/R-31~1.1/bin/x64/R" --vanilla CMD build  \
>>
>> "C:\Users\alewit\AppData\Local\Temp\RtmpYHOfgM\devtools138845a711f6\lme4-master"
>> --no-manual  \
>>   --no-resave-data
>>
>> * checking for file
>> 'C:\Users\alewit\AppData\Local\Temp\RtmpYHOfgM\devtools138845a711f6\lme4-master/DESCRIPTION'
>> ... OK
>> * preparing 'lme4':
>> * checking DESCRIPTION meta-information ... OK
>> * cleaning src
>> Warning in cleanup_pkg(pkgdir, Log) :
>>   unable to run 'make clean' in 'src'
>> * installing the package to build vignettes
>> Warning: running command '"C:/PROGRA~1/R/R-31~1.1/bin/x64/Rcmd.exe"
>> INSTALL -l "C:\Users\alewit\AppData\Local\Temp\Rtmp2ppmfo\Rinst13c46423bb3"
>> --no-multiarch
>> "C:/Users/alewit/AppData/Local/Temp/Rtmp2ppmfo/Rbuild13c45c0e2b4e/lme4"'
>> had status 1
>>       -----------------------------------
>> * installing *source* package 'lme4' ...
>> ** libs
>> Warning: running command 'make -f "Makevars.win" -f
>> "C:/PROGRA~1/R/R-31~1.1/etc/x64/Makeconf" -f
>> "C:/PROGRA~1/R/R-31~1.1/share/make/winshlib.mk"
>> SHLIB_LDFLAGS='$(SHLIB_CXXLDFLAGS)' SHLIB_LD='$(SHLIB_CXXLD)'
>> SHLIB="lme4.dll" WIN=64 TCLBIN=64 OBJECTS="external.o glmFamily.o
>> mcmcsamp.o optimizer.o predModule.o respModule.o"' had status 127
>> ERROR: compilation failed for package 'lme4'
>> * removing
>> 'C:/Users/alewit/AppData/Local/Temp/Rtmp2ppmfo/Rinst13c46423bb3/lme4'
>>       -----------------------------------
>> ERROR: package installation failed
>> Error: Command failed (1)
>>
>
>   I'm not  sure what's going on here.  Googling for "status 127" suggests
> that it's a pretty generic error code, so it doesn't give a lot of clues.
> Is it possible you're having permissions errors (hinted at by "unable to
> run 'make clean' in 'src'"?  What happens if you try disabling vignette
> building using build_vignettes=FALSE in your install_github() ?
>
>   Are you able to install other packages from github?
>
>
>> Alex Whitworth
>> whitworth.alex at gmail.com
>> (c) 828.429.7478
>>
>> On Thu, Aug 28, 2014 at 4:13 PM, Ben Bolker <bbolker at gmail.com> wrote:
>>
>>> On 14-08-28 06:46 PM, Alex Whitworth wrote:
>>> > Dr. Bolker,
>>> >
>>> > Could you please take a look at the function I have posted on
>>> > StackOverflow
>>> > <
>>> http://stackoverflow.com/questions/25538199/design-matrix-for-mlm-from-librarylme4-with-fixed-and-random-effects
>>> >?
>>> > I believe that it is working correctly and would appreciate your
>>> review.
>>> >
>>> > Thanks,
>>> >
>>> > Alex Whitworth
>>> > whitworth.alex at gmail.com <mailto:whitworth.alex at gmail.com>
>>> >
>>>
>>>   I saw that.  I will look at it if I have a chance.  I am
>>> simultaneously impressed by your incentive and ability to solve your own
>>> problems and a little bit frustrated at our inability to communicate
>>> very effectively: I think your problems could probably be fixed by a
>>> fairly minor adjustment to predict.merMod , which is likely better
>>> tested and handles a wider range of cases.  On the other hand, if you
>>> needed the solution right away ...  ( a workaround that occurred to me
>>> would be to make predictions on an augmented set of new data that
>>> included all of the factor levels, then throw away the ones you don't
>>> want).
>>>
>>>   If you want to test your function thoroughly, you can try the tests
>>> outlined in
>>>
>>> https://github.com/lme4/lme4/blob/master/tests/predsim.R
>>> https://github.com/lme4/lme4/blob/master/inst/tests/test-methods.R
>>> (search in this one for context("predict"))
>>>
>>>  By the way, getting standard errors of predictions that account
>>> properly for uncertainty in the random-effects parameters is (alas) a
>>> considerably harder problem ...
>>>
>>>   cheers
>>>     Ben Bolker
>>>
>>>
>>
>

	[[alternative HTML version deleted]]


From john.maindonald at anu.edu.au  Mon Sep 22 10:55:32 2014
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Mon, 22 Sep 2014 08:55:32 +0000
Subject: [R-sig-ME] =?windows-1252?q?xyplot=28=29_method_for_profile=A0obj?=
 =?windows-1252?q?ects=3A_error_from_use_of_the_scales_argument?=
Message-ID: <9BB98094-9EA2-4876-B8A9-27FCE05E90B8@anu.edu.au>

I take it that I should be able to supply a ?scales' argument in these circumstances:

> fm01ML <- lmer(Yield ~ 1|Batch, Dyestuff, REML = FALSE)
> tpr  <- profile(fm01ML, optimizer="Nelder_Mead", which="beta_")
> xyplot(tpr, scales=list(tck=0.4))
Error in xyplot.formula(scales = list(tck = 0.4), x = zeta ~ pval | pnm,  : 
  formal argument "scales" matched by multiple actual arguments

These are, incidentally, elegant plots.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


From highstat at highstat.com  Mon Sep 22 14:42:24 2014
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Mon, 22 Sep 2014 06:42:24 -0600
Subject: [R-sig-ME] Course Lisbon: Introduction to Linear mixed effects
 models, GLMM and MCMC with R
Message-ID: <54201930.5030407@highstat.com>

Apologies for cross-posting


We would like to announce the following statistics course:

Course:   Introduction to Linear mixed effects models,  GLMM and MCMC with R
Location: Lisbon, Portugal
Date:       9 - 13 February, 2015

Course website: http://www.highstat.com/statscourse.htm
Course flyer: http://www.highstat.com/Courses/Flyer2015_2Lisbon_GLMM.pdf


Kind regards,

Alain Zuur


-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From spatrick at glos.ac.uk  Mon Sep 22 20:39:12 2014
From: spatrick at glos.ac.uk (PATRICK, Samantha)
Date: Mon, 22 Sep 2014 18:39:12 +0000
Subject: [R-sig-ME] Within group estimate of autocorrelation
In-Reply-To: <CA+8zgH+8Ua0riy8P82GG-pzJd2hbiCaxm1_46Rku_txRGw=R2w@mail.gmail.com>
References: <CA+8zgHJ_tTUxTT+EW3L_oh9La9eq4iQQ8_y+uG4NvOyt4OZ11w@mail.gmail.com>
	<53FFB79A.3050709@gmail.com>
	<CA+8zgHLZ-SQ4P=u1kGYXk0++XJZsWBJO_DxZfv3RYM9fTm59Dw@mail.gmail.com>
	<CABghstSW4eS++58AwSQ5Dmn1wnewZzR5btStuduHGLkrLzU5Dg@mail.gmail.com>,
	<CA+8zgH+8Ua0riy8P82GG-pzJd2hbiCaxm1_46Rku_txRGw=R2w@mail.gmail.com>
Message-ID: <89A06A313CF21543AC6BE0F5AACCE68734F46D8D@C18760.chelt.local>

Hi

I have a model which fits an corAR1 autocorrelation structure and the code tells the model that time is nested within individual:

fit0<-lme(Respone~1,
random=~1|indiv,
correlation=corAR1(form=~time|indiv),
data=Data2, method = "REML")

>From this I get a Phi single estimate of the autocorrelation.  However  I want to have an estimate of the autocorrelation for each individual.  I have checked but can not find any code to extract this value.

So my first question is: Is it possible to extract an estimate of autocorrelation per individual or does the model not save/calculate this?
And second, if it isn't possible, I wondered if there is any way to use the weights function to group individuals.

If I add the code:  weights=varIdent(form=~1|group), I can fit multiple residual variance terms so I wondered if this could be used to estimate a Phi value per group, by somehow structuring the model so it fits an autocorrelation for each residual variance group?

The solution does not need to be lme necessarily - I?m open to any suggestions!

Many Thanks

Sam


Dr Samantha Patrick
Research Fellow
Biosciences QU116
Francis Close Hall Campus
University of Gloucestershire
Cheltenham, GL50 4AZ, UK

Research Associate: OxNav, University of Oxford

******From 1st August - 14th November 2014 I will be
based in Montr?al, which is 5 hours behind GMT  ******

Tel: 07740 472 719
Skype: sammy_patrick
https://sites.google.com/site/samanthacpatrick/

From: Alex Whitworth<mailto:whitworth.alex at gmail.com>
Sent: ?Thursday?, ?18? ?September? ?2014 ?11?:?21
To: Ben Bolker<mailto:bbolker at gmail.com>
Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>

I've tried installing from github on my personal computer as well (in case
there was something with my work network causing a problem). I ran into the
same error. I am able to install other github packages--for example, my
(admittedly very small) package on nongaussian mixture
modeling: devtools::install_github("emclustr","crossfitAL").

I'll re-attempt the binary today--currently having some problems
downloading it.

Regarding question #2 (my hacked function), I completely agree that a
proliferation of predict.merMod functions is undesirable. the random
component of my model is as follows

lmer(... (0 + <logical> + <factor> |subject/school), data= ...)

The issue is selecting the appropriate columns of the random effects
data-frame { ranef(object)[[1]] } when the intercept term is
suppressed--but allowing flexibility in the function when the intercept is
not suppressed. It's made more difficult by the factor variable having 3-4
levels.

Alex



Alex Whitworth
whitworth.alex at gmail.com
(c) 828.429.7478

On Wed, Sep 17, 2014 at 1:37 PM, Ben Bolker <bbolker at gmail.com> wrote:

>
>
> On Wed, Sep 17, 2014 at 3:22 PM, Alex Whitworth <whitworth.alex at gmail.com>
> wrote:
>
>> Dr Bolker,
>>
>> I tried installing the development / github version of lme4 today and ran
>> into an error. R system messages copied below. Any help would be
>> appreciated.
>>
>
>   I'm cc'ing this to r-sig-mixed-models in case anyone has an idea.
>   In the meantime,
> * I'm also posting a Windows binary of the latest development version
> (today's github version), as built by CRAN's win-builder, to
> http://lme4.r-forge.r-project.org/repos/ ; it will take up to 24 hours to
> show up there
> * I've also put a version at
> http://ms.mcmaster.ca/~bolker/R/bin/windows/contrib/3.1/ , available
> immediately
>
>   You can install this under R 3.1.* with an appropriate
> install.packages(...,repos=...) incantation, or download the .zip file and
> install it locally.
>
>
>>
>> On a second note, I'm still working on my "hacked" version of the predict
>> function predict.merMod2() . I've solved one of the issues I was running
>> into but am still working on an issue related to the random effects for
>> grouping variables that are of type factor.
>>
>
>   (What other kinds of grouping variables are there ...  ?)
>
>
>
>> I hope to be able to solve this / put the solution on stackoverflow in
>> the near-ish future.
>>
>
>   I'm hoping that the predict.merMod in the development version will solve
> all your problems, or that if it doesn't you can create a small
> reproducible example and I can fix it centrally.  Provide that you're not
> trying to do something really weird/baroque, it makes more sense to have
> the package Just Work than to have a proliferation of individual
> fixes/workarounds.
>
>
>>
>>
>>
>> -------------------------------------------------------------------------------------------------------------------
>> Restarting R session...
>>
>> > devtools::install_github("lme4","lme4")
>> Installing github repo lme4/master from lme4
>> Downloading master.zip from
>> https://github.com/lme4/lme4/archive/master.zip
>> Installing package from
>> C:\Users\alewit\AppData\Local\Temp\RtmpYHOfgM/master.zip
>> Installing lme4
>> "C:/PROGRA~1/R/R-31~1.1/bin/x64/R" --vanilla CMD build  \
>>
>> "C:\Users\alewit\AppData\Local\Temp\RtmpYHOfgM\devtools138845a711f6\lme4-master"
>> --no-manual  \
>>   --no-resave-data
>>
>> * checking for file
>> 'C:\Users\alewit\AppData\Local\Temp\RtmpYHOfgM\devtools138845a711f6\lme4-master/DESCRIPTION'
>> ... OK
>> * preparing 'lme4':
>> * checking DESCRIPTION meta-information ... OK
>> * cleaning src
>> Warning in cleanup_pkg(pkgdir, Log) :
>>   unable to run 'make clean' in 'src'
>> * installing the package to build vignettes
>> Warning: running command '"C:/PROGRA~1/R/R-31~1.1/bin/x64/Rcmd.exe"
>> INSTALL -l "C:\Users\alewit\AppData\Local\Temp\Rtmp2ppmfo\Rinst13c46423bb3"
>> --no-multiarch
>> "C:/Users/alewit/AppData/Local/Temp/Rtmp2ppmfo/Rbuild13c45c0e2b4e/lme4"'
>> had status 1
>>       -----------------------------------
>> * installing *source* package 'lme4' ...
>> ** libs
>> Warning: running command 'make -f "Makevars.win" -f
>> "C:/PROGRA~1/R/R-31~1.1/etc/x64/Makeconf" -f
>> "C:/PROGRA~1/R/R-31~1.1/share/make/winshlib.mk"
>> SHLIB_LDFLAGS='$(SHLIB_CXXLDFLAGS)' SHLIB_LD='$(SHLIB_CXXLD)'
>> SHLIB="lme4.dll" WIN=64 TCLBIN=64 OBJECTS="external.o glmFamily.o
>> mcmcsamp.o optimizer.o predModule.o respModule.o"' had status 127
>> ERROR: compilation failed for package 'lme4'
>> * removing
>> 'C:/Users/alewit/AppData/Local/Temp/Rtmp2ppmfo/Rinst13c46423bb3/lme4'
>>       -----------------------------------
>> ERROR: package installation failed
>> Error: Command failed (1)
>>
>
>   I'm not  sure what's going on here.  Googling for "status 127" suggests
> that it's a pretty generic error code, so it doesn't give a lot of clues.
> Is it possible you're having permissions errors (hinted at by "unable to
> run 'make clean' in 'src'"?  What happens if you try disabling vignette
> building using build_vignettes=FALSE in your install_github() ?
>
>   Are you able to install other packages from github?
>
>
>> Alex Whitworth
>> whitworth.alex at gmail.com
>> (c) 828.429.7478
>>
>> On Thu, Aug 28, 2014 at 4:13 PM, Ben Bolker <bbolker at gmail.com> wrote:
>>
>>> On 14-08-28 06:46 PM, Alex Whitworth wrote:
>>> > Dr. Bolker,
>>> >
>>> > Could you please take a look at the function I have posted on
>>> > StackOverflow
>>> > <
>>> http://stackoverflow.com/questions/25538199/design-matrix-for-mlm-from-librarylme4-with-fixed-and-random-effects
>>> >?
>>> > I believe that it is working correctly and would appreciate your
>>> review.
>>> >
>>> > Thanks,
>>> >
>>> > Alex Whitworth
>>> > whitworth.alex at gmail.com <mailto:whitworth.alex at gmail.com>
>>> >
>>>
>>>   I saw that.  I will look at it if I have a chance.  I am
>>> simultaneously impressed by your incentive and ability to solve your own
>>> problems and a little bit frustrated at our inability to communicate
>>> very effectively: I think your problems could probably be fixed by a
>>> fairly minor adjustment to predict.merMod , which is likely better
>>> tested and handles a wider range of cases.  On the other hand, if you
>>> needed the solution right away ...  ( a workaround that occurred to me
>>> would be to make predictions on an augmented set of new data that
>>> included all of the factor levels, then throw away the ones you don't
>>> want).
>>>
>>>   If you want to test your function thoroughly, you can try the tests
>>> outlined in
>>>
>>> https://github.com/lme4/lme4/blob/master/tests/predsim.R
>>> https://github.com/lme4/lme4/blob/master/inst/tests/test-methods.R
>>> (search in this one for context("predict"))
>>>
>>>  By the way, getting standard errors of predictions that account
>>> properly for uncertainty in the random-effects parameters is (alas) a
>>> considerably harder problem ...
>>>
>>>   cheers
>>>     Ben Bolker
>>>
>>>
>>
>

 [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
-
?In the top 5 in the Green League Table; committed to sustainability?
This email is confidential to the intended recipient. If you have received it in error please notify the sender and delete it from your computer.
The University of Gloucestershire is a company limited by guarantee registered in England and Wales.  Registered number: 06023243.  Registered office: The Park, Cheltenham, GL50 2RH
Please consider the environment before printing this email.
-


From bbolker at gmail.com  Mon Sep 22 20:47:20 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 22 Sep 2014 14:47:20 -0400
Subject: [R-sig-ME] Within group estimate of autocorrelation
In-Reply-To: <89A06A313CF21543AC6BE0F5AACCE68734F46D8D@C18760.chelt.local>
References: <CA+8zgHJ_tTUxTT+EW3L_oh9La9eq4iQQ8_y+uG4NvOyt4OZ11w@mail.gmail.com>	<53FFB79A.3050709@gmail.com>	<CA+8zgHLZ-SQ4P=u1kGYXk0++XJZsWBJO_DxZfv3RYM9fTm59Dw@mail.gmail.com>	<CABghstSW4eS++58AwSQ5Dmn1wnewZzR5btStuduHGLkrLzU5Dg@mail.gmail.com>,
	<CA+8zgH+8Ua0riy8P82GG-pzJd2hbiCaxm1_46Rku_txRGw=R2w@mail.gmail.com>
	<89A06A313CF21543AC6BE0F5AACCE68734F46D8D@C18760.chelt.local>
Message-ID: <54206EB8.4090903@gmail.com>

On 14-09-22 02:39 PM, PATRICK, Samantha wrote:
> Hi

> I have a model which fits an corAR1 autocorrelation structure and
>  the code tells the model that time is nested within individual:

> fit0<-lme(Respone~1,
> random=~1|indiv,
> correlation=corAR1(form=~time|indiv),
> data=Data2, method = "REML")

>>From this I get a Phi single estimate of the autocorrelation.
  However I want to have an estimate of the autocorrelation for each
  individual.  I have checked but can not find any code to extract
  this value.

The model assumes that autocorrelation structure is homogeneous
across individuals.

>  So my first question is: Is it possible to extract an estimate of
> autocorrelation per individual or does the model not save/calculate
> this?

  So, the answer is: no/correct.

> And second, if it isn't possible, I wondered if there is any way to
  use the weights function to group individuals.

>  If I add the code: weights=varIdent(form=~1|group), I can fit
> multiple residual variance terms so I wondered if this could be used
> to estimate a Phi value per group, by somehow structuring the model
> so it fits an autocorrelation for each residual variance group?


> The solution does not need to be lme necessarily - I?m open to any
  suggestions!


Perhaps just use acf() along with your favourite by-group tool
in R (plyr, aggregate, dplyr, data.table, for loop ...)
to compute/extract the first-order autocorrelation parameter for each
individual?  Or you could use

gls(Response~1,correlation=corAR1(form~time),...)

for each individual and similarly return the autocorrelation parameter
per individual.

  I hope you have a reasonably large number of observations per
individual ...


From ndusit at gmail.com  Mon Sep 22 04:54:05 2014
From: ndusit at gmail.com (Dusit Ngoprasert)
Date: Mon, 22 Sep 2014 09:54:05 +0700
Subject: [R-sig-ME] glmer and model evaluation
Message-ID: <5599507594804BE0BE59971CEDE9D01E@Soy>

Dear all

My data is binary (0 & 1) responses with years as a random intercept. I am
using AIC approaches to select the best explain model. Next step, I would
like to evaluate my best model using AUC.

Is there any package or ways to calculate AUC? I used PresenceAbsence
package for glm() before, but I am not sure that it is work with glmer().  

 

Best,

Dusit

.......................................................................

Dusit Ngoprasert

 

Conservation Ecology Program

Pilot Plant Development and Training Institute

King Mongkut's University of Technology Thonburi (Bangkhuntien Campus)

49 Soi Tientalay 25, Bangkhuntien-Chaitalay Road, Thakham, Bangkhuntien,
Bangkok, Thailand 10150

Tel. +66 2 470 7571

Fax. +66 2 452 3455

E-mail: ndusit at gmail.com

           dusit.ngo at kmutt.ac.th

 

 



---
This email is free from viruses and malware because avast! Antivirus protection is active.


	[[alternative HTML version deleted]]


From roelofcoster at gmail.com  Mon Sep 22 23:43:53 2014
From: roelofcoster at gmail.com (Roelof Coster)
Date: Mon, 22 Sep 2014 23:43:53 +0200
Subject: [R-sig-ME] Distribution of deviance residuals
Message-ID: <CAPTd6_sYnEkuJX8bHJuHvbSntfxmaVWKjx=WrUocDXPcE-+0Ag@mail.gmail.com>

Hello,

What is the theoretical distribution of the residual deviances of a
well-fitting logistic regression mixed model?

The background of my question is as follows: I am looking for a way to
combine the ideas from regression tree modelling (aka model trees) and
mixed models. I have a data set to which I want to fit a logistic
regression model. My data come in groups, so I need a random effect to
account for those groups.

The mob function in the party package does what I need, but only for
fixed-effects models. As I understand it, that function arranges the data
according to the levels of a certain categorical predictor. Next, it looks
at the sequence obtained by cumulating the deviance residuals. Then a
hypothesis test is done to assess whether this sequence can plausibly be a
Brownian motion. If it isn't a Brownian motion, that is an indication that
the data set should be splitted in two and that two separate models should
be fitted. This process is repeated so that a binary tree is produced, with
a logistic regression model for a part of the data in each leaf of the tree.

I would be grateful for any advice on how this technique can be made to
work for my problem.

Best regards,

Roelof Coster

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue Sep 23 00:06:10 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 22 Sep 2014 22:06:10 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?xyplot=28=29_method_for_profile=C2=A0objects?=
	=?utf-8?q?=3A_error_from_use_of_the_scales_argument?=
References: <9BB98094-9EA2-4876-B8A9-27FCE05E90B8@anu.edu.au>
Message-ID: <loom.20140923T000422-601@post.gmane.org>

John Maindonald <john.maindonald at ...> writes:

 
> I take it that I should be able to supply a ?scales' argument in
  these circumstances:
 
> > fm01ML <- lmer(Yield ~ 1|Batch, Dyestuff, REML = FALSE)
> > tpr  <- profile(fm01ML, optimizer="Nelder_Mead", which="beta_")
> > xyplot(tpr, scales=list(tck=0.4))
> Error in xyplot.formula(scales = list(tck = 0.4), x = zeta ~ pval | pnm,  : 
>   formal argument "scales" matched by multiple actual arguments
> 
> These are, incidentally, elegant plots.
> 
> John Maindonald             email: john.maindonald at ...
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.

  This should be fixed in latest Github commit
https://github.com/lme4/lme4/commit/1fdf0d93c75a7a5421f899cf69291753842f171c
(oops, I notice I forgot to update documentation!)

The internal code is clunkier than I'd like.  Oh well.

  Ben Bolker


From bbolker at gmail.com  Tue Sep 23 00:21:43 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 22 Sep 2014 18:21:43 -0400
Subject: [R-sig-ME] Fwd: RE: [R] Help with lsmeans
In-Reply-To: <51F0C7C54B032A42A23B74A088E7141C2E64D68B@itsnt443.iowa.uiowa.edu>
References: <51F0C7C54B032A42A23B74A088E7141C2E64D68B@itsnt443.iowa.uiowa.edu>
Message-ID: <5420A0F7.3030406@gmail.com>


  (Discussion of possible interest to others on r-sig-mixed-models about
running lsmeans::ref.grid for large data sets ...)

-------- Forwarded Message --------
Subject: 	RE: [R] Help with lsmeans
Date: 	Mon, 22 Sep 2014 22:05:54 +0000
From: 	Lenth, Russell V <russell-lenth at uiowa.edu>
To: 	Ben Bolker <bbolker at gmail.com>, Dan Dillon <dgdillon at gmail.com>,
S?ren H?jsgaard <sorenh at math.aau.dk>



All:



Thanks for calling this to my attention.



There **is** a way to disable that time-consuming step? just set the
*lsmeans* option disable.pbrtest to TRUE. Here?s Ben?s example, run both
ways, showing the timing and the covariance matrix obtained:



> system.time(rr <- ref.grid(m2))

   user  system elapsed

  13.39    1.66   15.05

> rr at V

              (Intercept)             x

(Intercept)  9.900968e-05 -0.0001482768

x           -1.482768e-04  0.0002955296



> lsm.options(disable.pbkrtest=TRUE)

> system.time(rrd <- ref.grid(m2))

   user  system elapsed

   0.11    0.00    0.10

> rrd at V

              (Intercept)             x

(Intercept)  9.900036e-05 -0.0001482582

x           -1.482582e-04  0.0002954926



In the second result, the V matrix is just the result of vcov(mm)instead
of vcovAdj(mm). Note also that you can also set the degrees of freedom
to any desired value in the lsmeans or ref.grid call:



> lsmeans(m2, "x", at = list(x = c(.3,.5,.7)), options = list(df = 24))

   x      lsmean          SE df     lower.CL   upper.CL

 0.3 0.009617796 0.006053079 24 -0.002875145 0.02211074

 0.5 0.006692900 0.004961380 24 -0.003546885 0.01693269

 0.7 0.003768004 0.006019155 24 -0.008654921 0.01619093



Confidence level used: 0.95



(Setting df to NAwill produce asymptotic results.)



Hope this helps.



Russ





*From:*Ben Bolker [mailto:bbolker at gmail.com]
*Sent:* Monday, September 22, 2014 3:06 PM
*To:* Dan Dillon; S?ren H?jsgaard; Lenth, Russell V
*Subject:* Re: [R] Help with lsmeans



PS: smaller example, showing the same thing (and the equivalent just
with pbkrtest)



library("lme4")
library("lsmeans")
set.seed(101)
dd <- data.frame(y=rnorm(4e4),x=runif(4e4),f=gl(n=200,k=200))
m2 <- lmer(y~x+(1|f),data=dd)
m0 <- lmer(y~1+(1|f),data=dd)
rr <- ref.grid(m2)
library("pbkrtest")
kk <- KRmodcomp(m2,m0)



On Mon, Sep 22, 2014 at 11:09 AM, Dan Dillon <dgdillon at gmail.com
<mailto:dgdillon at gmail.com>> wrote:

    Hi Ben. Apologies if I should be sending this to the list instead of
    directly you, but I am still having trouble with lsmeans and wonder
    if you can help. I have attached my data and list my code below. In
    a nutshell, lsmeans works fine when I direct it towards a logistic
    model where my DV is accuracy (coded 0 or 1), but it hangs for
    hours, uses up all the application memory on my machine, and does
    not generate a result when I direct it towards a linear model where
    my DV is RT (response time).



    I took your advice and tried working with subsets of the data, and
    found that lsmeans can handle the RT model if the data set is small
    enough. I have data from four sites: US, UK, JP, and SA. If I run a
    model on RT data from three cases from the US, lsmeans runs for ~1
    minute and generates a result. If I scale up and use all the data
    from just the US and UK sites, lsmeans works for 20+ minutes but
    gives a result. However, if I throw all the RT data at it, lsmeans
    hangs for hours and uses up all my application memory without
    generating a result. By contrast, if I use all the data but accuracy
    is the DV (i.e., logistic model), I get an answer in seconds.



    If you have any other ideas or thoughts here, I would greatly
    appreciate it. I am new to R and lme4, and I come from a tradition
    (experimental psychology) where many reviewers will want to see
    follow-up test for interactions. lsmeans looks like the right tool
    for the job, so I'd love to get it running for both my accuracy and
    RT data.



    Thanks for any help you can provide--code below.



    Dan Dillon





    # The data are from a flanker task, where stimuli are congruent or
    incongruent (CON or INC). I have two groups of subjects.



    flk = read.csv('my_data.csv')

    flk$group <- as.factor(flk$group)

    fm.acc <- glmer(accuracy ~ site + group*stimulus + (1|subject),
    family = binomial, data = flk)

    acc.rg <- ref.grid(fm.acc) # Works fine

    print(acc.rg) # Works fine

    lsmeans(fm.acc, ~group|stimulus) # Works fine



    flk$accuracy <- as.factor(flk$accuracy) # I want to include accuracy
    as a factor in the RT model

    fm.rt <- lmer(rt ~ site + group*stimulus*accuracy + (1|subject),
    data = flk) # Works fine, model results look good

    rt.rg <- ref.grid(fm.rt) # Does not work, hangs for hours.





    On Tue, Aug 26, 2014 at 5:07 PM, Ben Bolker <bbolker at gmail.com
    <mailto:bbolker at gmail.com>> wrote:

        Dan Dillon <dgdillon <at> gmail.com <http://gmail.com>> writes:

        >
        > Colleagues:
        >

         [snip]

        >
        > My data are from a behavioral experiment in which two groups
        of subjects
        > complete 200+ trials of a task with two conditions. Each
        subject is tested
        > in one of four separate locations. I record accuracy (0 or 1)
        and response
        > time (RT) on each trial--these are the DVs for the two
        regressions. Thus,
        > my dataframe has columns "location", "group", "subject", "trial",
        > "condition", "accuracy", and "RT".
        >
        > The regression model for accuracy looks like this:
        >
        > acc.fm <http://acc.fm> = glmer(accuracy ~ location +
        group*condition + (1|subject),
        > family=binomial, data=my_data)
        >
        > The results look as expected and I'm using lsmeans to do some
        follow-up
        > analyses. For example, to compare accuracy by group and
        condition, I'm
        > doing this:
        >
        > acc.lsm <- lsmeans(acc.fm <http://acc.fm>, ~group|condition)
        >
        > pairs(acc.lsm)
        >
        >

         [snip]

        > Here is my model for the RT data
        > (RT is a continuous variable so no logistic regression here):
        >
        > rt.fm <http://rt.fm> = lmer(rt ~ location +
        group*condition*accuracy + (1|subject),
        > data=my_data)
        >
        > The results from this regression look fine, but if I try this
        . . .
        >
        > rt.lsm <- lsmeans(rt.fm <http://rt.fm> ~ group|condition)
        >
        > . . . or if I try to specify a reference grid like this . . .
        >
        > rt.rg <- ref.grid(rt.fm <http://rt.fm>)
        >
        > . . . my machine hangs.
        >

          [snip]

          It's a little hard to say without a reproducible example, and
        this question would probably be slightly more appropriate for
        r-sig-mixed-models at r-project.org
        <mailto:r-sig-mixed-models at r-project.org> (although I can't
        actually tell
        for sure whether it is an lme4-specific problem or a more general
        ls.means::ref.grid question), but: how big a reference is ref.grid()
        trying to construct?  Is it fairly high-resolution/high-dimensional?
        I would probably try some experiments with small subsets of your
        data
        to see how the results scale.

        ______________________________________________
        R-help at r-project.org <mailto:R-help at r-project.org> mailing list
        https://stat.ethz.ch/mailman/listinfo/r-help
        PLEASE do read the posting guide
        http://www.R-project.org/posting-guide.html
        and provide commented, minimal, self-contained, reproducible code.


From bbolker at gmail.com  Tue Sep 23 15:33:07 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 23 Sep 2014 09:33:07 -0400
Subject: [R-sig-ME] FW: methods for glmerMod object
In-Reply-To: <12FBEC6941E0384FBC2BBCAAEAD349588E8FFE94@KRYPTON.lan.ablynx.com>
References: <12FBEC6941E0384FBC2BBCAAEAD349588E8FFE94@KRYPTON.lan.ablynx.com>
Message-ID: <54217693.60701@gmail.com>

On 14-09-23 09:14 AM, Roel Straetemans wrote:

[cc'ing to r-sig-mixed-models]

> I have applied a repeated logistic regression using the glmer function
> from the package. I was wondering about all the methods that could be
> used with the produced objects. Therefore I typed:
> 
>  
> 
>> methods(class="glmerMod")
> 
> no methods were found
> 
>  

   This is an understandable confusion. Although the class() of
a fitted glmer model is "glmerMod", this is actually a superset of
the "merMod" class.  (To be honest I don't know how I would have
 figured that out if I didn't already know ...)

> methods(class="merMod")
 [1] anova.merMod*        as.function.merMod*  coef.merMod*
 [4] confint.merMod       deviance.merMod*     df.residual.merMod*
 [7] dim.merMod*          drop1.merMod*        extractAIC.merMod*
[10] family.merMod*       fitted.merMod*       fixef.merMod*
[13] formula.merMod*      hatvalues.merMod*    isGLMM.merMod*
[16] isLMM.merMod*        isNLMM.merMod*       isREML.merMod*
[19] logLik.merMod*       model.frame.merMod*  model.matrix.merMod*
[22] ngrps.merMod*        nobs.merMod*         plot.merMod*
[25] predict.merMod*      print.merMod*        profile.merMod*
[28] qqmath.merMod*       ranef.merMod*        refit.merMod*
[31] refitML.merMod*      residuals.merMod*    sigma.merMod*
[34] simulate.merMod*     summary.merMod*      terms.merMod*
[37] update.merMod*       VarCorr.merMod*      vcov.merMod
[40] weights.merMod*


From Vahid.Nassiri at kuleuven.be  Tue Sep 23 14:39:36 2014
From: Vahid.Nassiri at kuleuven.be (Vahid Nassiri)
Date: Tue, 23 Sep 2014 12:39:36 +0000
Subject: [R-sig-ME] Subject-wise gradient and Hessian
Message-ID: <065A1A972EC9B24886EBACC6D5C0BF23145DF3CD@ICTS-S-MBX1.luna.kuleuven.be>

Dear all,

I just use these simple codes to obtain gradient and Hessian of the fitted model to Orthodont data (for example) for different parameters,

> fm1 <- lmer(scale(distance)~Sex*I(scale(age))+(I(scale(age))|Subject), data=Orthodont)
> fm1 at optinfo$derivs$gradient
[1] 1.578826e-07 1.200391e-06 4.504841e-08
> fm1 at optinfo$derivs$Hessian
           [,1]       [,2]       [,3]
[1,]  30.766258  -4.868289 -13.459066
[2,]  -4.868289 128.743919   1.404892
[3,] -13.459066   1.404892  58.653149

So, it seems I have seven parameters, 4 fixed effects, 2 random effects, and one error variance, he so why I get a 3 \times 3 Hessian and 3 \times 1 gradient?

I also tried to use:

> fm1_update <- update(fm1,devFunOnly=TRUE)
> params <- unlist(getME(fm1,c("theta","beta")))
> grad(fm1_update,params)
(7!=3)
Error: theta size mismatch
>

But you see the error I got, it only works fine when I just include "theta" and not the fixed effects "beta"

I wonder if anyone have an idea about how I can obtain gradient and Hessian for all the parameters in the model.

Afterward, I would try to find a way to calculate these quantities by subject. That would be probably possible by fitting a new model for each subject, but starting from fitted values and just for one iteration. But that is the next step after I know how I can obtain gradient and Hessian for each parameter at the first place.

Thanks!
Vahid.

	[[alternative HTML version deleted]]


From bates at stat.wisc.edu  Tue Sep 23 17:11:13 2014
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 23 Sep 2014 10:11:13 -0500
Subject: [R-sig-ME] Subject-wise gradient and Hessian
In-Reply-To: <065A1A972EC9B24886EBACC6D5C0BF23145DF3CD@ICTS-S-MBX1.luna.kuleuven.be>
References: <065A1A972EC9B24886EBACC6D5C0BF23145DF3CD@ICTS-S-MBX1.luna.kuleuven.be>
Message-ID: <CAO7JsnRtx9C0MuBSnr7zB7CQriwDYLD_wO6WQObNJjCsZJEP4w@mail.gmail.com>

The function being optimized when fitting a linear mixed-effects model is
the profiled deviance or the profiled REML criterion.  Details are given in
http://arxiv.org/abs/1406.5823.  The term "profiled" means that,
conditional on values of parameters that determine the relative covariance
matrix of the random effects, the optimal values of the fixed-effects
coefficients and the residual variance parameter, can be determined from
the solution of a penalized least-squares problem.  This reduces the
complexity of the optimization problem considerably and leads to faster and
more robust algorithms for fitting such models.

However, it also means that parameters being optimized are indirectly
related to what we view as the statistically meaningful parameters in the
model.  If you need the gradient and Hessian with respect to the
fixed-effects parameters or the variance components you should write the
objective function in terms of those parameters.

On Tue, Sep 23, 2014 at 7:39 AM, Vahid Nassiri <Vahid.Nassiri at kuleuven.be>
wrote:

> Dear all,
>
> I just use these simple codes to obtain gradient and Hessian of the fitted
> model to Orthodont data (for example) for different parameters,
>
> > fm1 <- lmer(scale(distance)~Sex*I(scale(age))+(I(scale(age))|Subject),
> data=Orthodont)
> > fm1 at optinfo$derivs$gradient
> [1] 1.578826e-07 1.200391e-06 4.504841e-08
> > fm1 at optinfo$derivs$Hessian
>            [,1]       [,2]       [,3]
> [1,]  30.766258  -4.868289 -13.459066
> [2,]  -4.868289 128.743919   1.404892
> [3,] -13.459066   1.404892  58.653149
>
> So, it seems I have seven parameters, 4 fixed effects, 2 random effects,
> and one error variance, he so why I get a 3 \times 3 Hessian and 3 \times 1
> gradient?
>
> I also tried to use:
>
> > fm1_update <- update(fm1,devFunOnly=TRUE)
> > params <- unlist(getME(fm1,c("theta","beta")))
> > grad(fm1_update,params)
> (7!=3)
> Error: theta size mismatch
> >
>
> But you see the error I got, it only works fine when I just include
> "theta" and not the fixed effects "beta"
>
> I wonder if anyone have an idea about how I can obtain gradient and
> Hessian for all the parameters in the model.
>
> Afterward, I would try to find a way to calculate these quantities by
> subject. That would be probably possible by fitting a new model for each
> subject, but starting from fitted values and just for one iteration. But
> that is the next step after I know how I can obtain gradient and Hessian
> for each parameter at the first place.
>
> Thanks!
> Vahid.
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From Vahid.Nassiri at kuleuven.be  Tue Sep 23 17:30:55 2014
From: Vahid.Nassiri at kuleuven.be (Vahid Nassiri)
Date: Tue, 23 Sep 2014 15:30:55 +0000
Subject: [R-sig-ME] Subject-wise gradient and Hessian
In-Reply-To: <CAO7JsnRtx9C0MuBSnr7zB7CQriwDYLD_wO6WQObNJjCsZJEP4w@mail.gmail.com>
References: <065A1A972EC9B24886EBACC6D5C0BF23145DF3CD@ICTS-S-MBX1.luna.kuleuven.be>,
	<CAO7JsnRtx9C0MuBSnr7zB7CQriwDYLD_wO6WQObNJjCsZJEP4w@mail.gmail.com>
Message-ID: <065A1A972EC9B24886EBACC6D5C0BF23145DF43F@ICTS-S-MBX1.luna.kuleuven.be>

Thanks for the paper and the explanations,

But can I change the objective function myself?
Like something should be changed in "lmer" itself, or when I update it with "devFunOnly=TRUE" ?

Vahid.
________________________________
From: dmbates at gmail.com [dmbates at gmail.com] on behalf of Douglas Bates [bates at stat.wisc.edu]
Sent: Tuesday, September 23, 2014 5:11 PM
To: Vahid Nassiri
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Subject-wise gradient and Hessian

The function being optimized when fitting a linear mixed-effects model is the profiled deviance or the profiled REML criterion.  Details are given in http://arxiv.org/abs/1406.5823.  The term "profiled" means that, conditional on values of parameters that determine the relative covariance matrix of the random effects, the optimal values of the fixed-effects coefficients and the residual variance parameter, can be determined from the solution of a penalized least-squares problem.  This reduces the complexity of the optimization problem considerably and leads to faster and more robust algorithms for fitting such models.

However, it also means that parameters being optimized are indirectly related to what we view as the statistically meaningful parameters in the model.  If you need the gradient and Hessian with respect to the fixed-effects parameters or the variance components you should write the objective function in terms of those parameters.

On Tue, Sep 23, 2014 at 7:39 AM, Vahid Nassiri <Vahid.Nassiri at kuleuven.be<mailto:Vahid.Nassiri at kuleuven.be>> wrote:
Dear all,

I just use these simple codes to obtain gradient and Hessian of the fitted model to Orthodont data (for example) for different parameters,

> fm1 <- lmer(scale(distance)~Sex*I(scale(age))+(I(scale(age))|Subject), data=Orthodont)
> fm1 at optinfo$derivs$gradient
[1] 1.578826e-07 1.200391e-06 4.504841e-08
> fm1 at optinfo$derivs$Hessian
           [,1]       [,2]       [,3]
[1,]  30.766258  -4.868289 -13.459066
[2,]  -4.868289 128.743919   1.404892
[3,] -13.459066   1.404892  58.653149

So, it seems I have seven parameters, 4 fixed effects, 2 random effects, and one error variance, he so why I get a 3 \times 3 Hessian and 3 \times 1 gradient?

I also tried to use:

> fm1_update <- update(fm1,devFunOnly=TRUE)
> params <- unlist(getME(fm1,c("theta","beta")))
> grad(fm1_update,params)
(7!=3)
Error: theta size mismatch
>

But you see the error I got, it only works fine when I just include "theta" and not the fixed effects "beta"

I wonder if anyone have an idea about how I can obtain gradient and Hessian for all the parameters in the model.

Afterward, I would try to find a way to calculate these quantities by subject. That would be probably possible by fitting a new model for each subject, but starting from fitted values and just for one iteration. But that is the next step after I know how I can obtain gradient and Hessian for each parameter at the first place.

Thanks!
Vahid.

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From bates at stat.wisc.edu  Tue Sep 23 17:41:04 2014
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 23 Sep 2014 10:41:04 -0500
Subject: [R-sig-ME] Subject-wise gradient and Hessian
In-Reply-To: <065A1A972EC9B24886EBACC6D5C0BF23145DF43F@ICTS-S-MBX1.luna.kuleuven.be>
References: <065A1A972EC9B24886EBACC6D5C0BF23145DF3CD@ICTS-S-MBX1.luna.kuleuven.be>
	<CAO7JsnRtx9C0MuBSnr7zB7CQriwDYLD_wO6WQObNJjCsZJEP4w@mail.gmail.com>
	<065A1A972EC9B24886EBACC6D5C0BF23145DF43F@ICTS-S-MBX1.luna.kuleuven.be>
Message-ID: <CAO7JsnThgSmAqt1rGGs7iDqNzkPmE-J5vrTL=BY97w4JzDMt+w@mail.gmail.com>

On Tue, Sep 23, 2014 at 10:30 AM, Vahid Nassiri <Vahid.Nassiri at kuleuven.be>
wrote:

>  Thanks for the paper and the explanations,
>
>  But can I change the objective function myself?
> Like something should be changed in "lmer" itself, or when I update it
> with "devFunOnly=TRUE" ?
>

It is not trivial to do.  I would start with the lme4pureR package, which
may exist only on github

install.packages("devtools")
devtools::install_github("lme4/lme4pureR")

to see how the profiled deviance or profiled REML criterion is evaluated.


>
>  Vahid.
>  ------------------------------
> *From:* dmbates at gmail.com [dmbates at gmail.com] on behalf of Douglas Bates [
> bates at stat.wisc.edu]
> *Sent:* Tuesday, September 23, 2014 5:11 PM
> *To:* Vahid Nassiri
> *Cc:* r-sig-mixed-models at r-project.org
> *Subject:* Re: [R-sig-ME] Subject-wise gradient and Hessian
>
>   The function being optimized when fitting a linear mixed-effects model
> is the profiled deviance or the profiled REML criterion.  Details are given
> in http://arxiv.org/abs/1406.5823.  The term "profiled" means that,
> conditional on values of parameters that determine the relative covariance
> matrix of the random effects, the optimal values of the fixed-effects
> coefficients and the residual variance parameter, can be determined from
> the solution of a penalized least-squares problem.  This reduces the
> complexity of the optimization problem considerably and leads to faster and
> more robust algorithms for fitting such models.
>
>  However, it also means that parameters being optimized are indirectly
> related to what we view as the statistically meaningful parameters in the
> model.  If you need the gradient and Hessian with respect to the
> fixed-effects parameters or the variance components you should write the
> objective function in terms of those parameters.
>
> On Tue, Sep 23, 2014 at 7:39 AM, Vahid Nassiri <Vahid.Nassiri at kuleuven.be>
> wrote:
>
>> Dear all,
>>
>> I just use these simple codes to obtain gradient and Hessian of the
>> fitted model to Orthodont data (for example) for different parameters,
>>
>> > fm1 <- lmer(scale(distance)~Sex*I(scale(age))+(I(scale(age))|Subject),
>> data=Orthodont)
>> > fm1 at optinfo$derivs$gradient
>> [1] 1.578826e-07 1.200391e-06 4.504841e-08
>> > fm1 at optinfo$derivs$Hessian
>>            [,1]       [,2]       [,3]
>> [1,]  30.766258  -4.868289 -13.459066
>> [2,]  -4.868289 128.743919   1.404892
>> [3,] -13.459066   1.404892  58.653149
>>
>> So, it seems I have seven parameters, 4 fixed effects, 2 random effects,
>> and one error variance, he so why I get a 3 \times 3 Hessian and 3 \times 1
>> gradient?
>>
>> I also tried to use:
>>
>> > fm1_update <- update(fm1,devFunOnly=TRUE)
>> > params <- unlist(getME(fm1,c("theta","beta")))
>> > grad(fm1_update,params)
>> (7!=3)
>> Error: theta size mismatch
>> >
>>
>> But you see the error I got, it only works fine when I just include
>> "theta" and not the fixed effects "beta"
>>
>> I wonder if anyone have an idea about how I can obtain gradient and
>> Hessian for all the parameters in the model.
>>
>> Afterward, I would try to find a way to calculate these quantities by
>> subject. That would be probably possible by fitting a new model for each
>> subject, but starting from fitted values and just for one iteration. But
>> that is the next step after I know how I can obtain gradient and Hessian
>> for each parameter at the first place.
>>
>> Thanks!
>> Vahid.
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue Sep 23 19:42:22 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 23 Sep 2014 13:42:22 -0400
Subject: [R-sig-ME] Subject-wise gradient and Hessian
In-Reply-To: <CAO7JsnThgSmAqt1rGGs7iDqNzkPmE-J5vrTL=BY97w4JzDMt+w@mail.gmail.com>
References: <065A1A972EC9B24886EBACC6D5C0BF23145DF3CD@ICTS-S-MBX1.luna.kuleuven.be>	<CAO7JsnRtx9C0MuBSnr7zB7CQriwDYLD_wO6WQObNJjCsZJEP4w@mail.gmail.com>	<065A1A972EC9B24886EBACC6D5C0BF23145DF43F@ICTS-S-MBX1.luna.kuleuven.be>
	<CAO7JsnThgSmAqt1rGGs7iDqNzkPmE-J5vrTL=BY97w4JzDMt+w@mail.gmail.com>
Message-ID: <5421B0FE.4050302@gmail.com>

  I agree that it's not going to be very easy, but I would suggest that
the code at
https://github.com/lme4/lme4/blob/master/misc/notes/laplDiag.Rmd would
be a good starting point: what this function does (for GLMMs) is to
compute the deviance residuals for a particular set of conditional mode
offsets and sum them by group.  You could probably adapt this approach
to compute the gradient and Hessian of the deviance residuals by
individual ...

On 14-09-23 11:41 AM, Douglas Bates wrote:
> On Tue, Sep 23, 2014 at 10:30 AM, Vahid Nassiri <Vahid.Nassiri at kuleuven.be>
> wrote:
> 
>>  Thanks for the paper and the explanations,
>>
>>  But can I change the objective function myself?
>> Like something should be changed in "lmer" itself, or when I update it
>> with "devFunOnly=TRUE" ?
>>
> 
> It is not trivial to do.  I would start with the lme4pureR package, which
> may exist only on github
> 
> install.packages("devtools")
> devtools::install_github("lme4/lme4pureR")
> 
> to see how the profiled deviance or profiled REML criterion is evaluated.
> 
> 
>>
>>  Vahid.
>>  ------------------------------
>> *From:* dmbates at gmail.com [dmbates at gmail.com] on behalf of Douglas Bates [
>> bates at stat.wisc.edu]
>> *Sent:* Tuesday, September 23, 2014 5:11 PM
>> *To:* Vahid Nassiri
>> *Cc:* r-sig-mixed-models at r-project.org
>> *Subject:* Re: [R-sig-ME] Subject-wise gradient and Hessian
>>
>>   The function being optimized when fitting a linear mixed-effects model
>> is the profiled deviance or the profiled REML criterion.  Details are given
>> in http://arxiv.org/abs/1406.5823.  The term "profiled" means that,
>> conditional on values of parameters that determine the relative covariance
>> matrix of the random effects, the optimal values of the fixed-effects
>> coefficients and the residual variance parameter, can be determined from
>> the solution of a penalized least-squares problem.  This reduces the
>> complexity of the optimization problem considerably and leads to faster and
>> more robust algorithms for fitting such models.
>>
>>  However, it also means that parameters being optimized are indirectly
>> related to what we view as the statistically meaningful parameters in the
>> model.  If you need the gradient and Hessian with respect to the
>> fixed-effects parameters or the variance components you should write the
>> objective function in terms of those parameters.
>>
>> On Tue, Sep 23, 2014 at 7:39 AM, Vahid Nassiri <Vahid.Nassiri at kuleuven.be>
>> wrote:
>>
>>> Dear all,
>>>
>>> I just use these simple codes to obtain gradient and Hessian of the
>>> fitted model to Orthodont data (for example) for different parameters,
>>>
>>>> fm1 <- lmer(scale(distance)~Sex*I(scale(age))+(I(scale(age))|Subject),
>>> data=Orthodont)
>>>> fm1 at optinfo$derivs$gradient
>>> [1] 1.578826e-07 1.200391e-06 4.504841e-08
>>>> fm1 at optinfo$derivs$Hessian
>>>            [,1]       [,2]       [,3]
>>> [1,]  30.766258  -4.868289 -13.459066
>>> [2,]  -4.868289 128.743919   1.404892
>>> [3,] -13.459066   1.404892  58.653149
>>>
>>> So, it seems I have seven parameters, 4 fixed effects, 2 random effects,
>>> and one error variance, he so why I get a 3 \times 3 Hessian and 3 \times 1
>>> gradient?
>>>
>>> I also tried to use:
>>>
>>>> fm1_update <- update(fm1,devFunOnly=TRUE)
>>>> params <- unlist(getME(fm1,c("theta","beta")))
>>>> grad(fm1_update,params)
>>> (7!=3)
>>> Error: theta size mismatch
>>>>
>>>
>>> But you see the error I got, it only works fine when I just include
>>> "theta" and not the fixed effects "beta"
>>>
>>> I wonder if anyone have an idea about how I can obtain gradient and
>>> Hessian for all the parameters in the model.
>>>
>>> Afterward, I would try to find a way to calculate these quantities by
>>> subject. That would be probably possible by fitting a new model for each
>>> subject, but starting from fitted values and just for one iteration. But
>>> that is the next step after I know how I can obtain gradient and Hessian
>>> for each parameter at the first place.
>>>
>>> Thanks!
>>> Vahid.
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From bbolker at gmail.com  Wed Sep 24 21:50:22 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 24 Sep 2014 19:50:22 +0000 (UTC)
Subject: [R-sig-ME] Distribution of deviance residuals
References: <CAPTd6_sYnEkuJX8bHJuHvbSntfxmaVWKjx=WrUocDXPcE-+0Ag@mail.gmail.com>
Message-ID: <loom.20140924T214256-612@post.gmane.org>

Roelof Coster <roelofcoster at ...> writes:

> 
> Hello,
> 
> What is the theoretical distribution of the residual deviances of a
> well-fitting logistic regression mixed model?
> 
> The background of my question is as follows: I am looking for a way to
> combine the ideas from regression tree modelling (aka model trees) and
> mixed models. I have a data set to which I want to fit a logistic
> regression model. My data come in groups, so I need a random effect to
> account for those groups.
> 
> The mob function in the party package does what I need, but only for
> fixed-effects models. As I understand it, that function arranges the data
> according to the levels of a certain categorical predictor. Next, it looks
> at the sequence obtained by cumulating the deviance residuals. Then a
> hypothesis test is done to assess whether this sequence can plausibly be a
> Brownian motion. If it isn't a Brownian motion, that is an indication that
> the data set should be splitted in two and that two separate models should
> be fitted. This process is repeated so that a binary tree is produced,
> with
> a logistic regression model for a part of the
> data in each leaf of the tree.
> 
> I would be grateful for any advice on how this technique can be made to
> work for my problem.


  Do you mean the deviance residuals (i.e. the per-observation contributions
to the deviance, or the signed square root of the contribution) or the total
residual deviance (i.e., the sum of squared deviance residuals)?
   If the former, I think you're probably in trouble -- empirically,
the distribution of residuals is usually pretty ugly, and theoretically
I can't think of a reason it should be nice.  If the latter, then
you can presumably just rely on asymptotic theory which would say
(I'm being sloppy here of course) that the sum of squares of lots of
iid things should be chi-square distributed (and then eventually
Normal).
  For what it's worth, a great deal of the theory of GLMMs is inherited
from GLM theory, so if you can solve your problem or find a solution
for a plain old *non*-mixed logistic regression, it is likely to work
reasonably well for a mixed logistic regression as well (provided you
have a reasonable number of levels of the random effect/your estimate
isn't singular).  (Conversely if it's known to be nasty for ordinary
logistic regression you're probably screwed.)

  As always I'm happy to be corrected by more sensible/knowledgeable
people.


From alku at dtu.dk  Wed Sep 24 22:21:34 2014
From: alku at dtu.dk (Alexandra Kuznetsova)
Date: Wed, 24 Sep 2014 20:21:34 +0000
Subject: [R-sig-ME] sums of squares and F values in anova
Message-ID: <0566E17B6DEC62459078112371B7508E1D90CE@ait-pex02mbx05.win.dtu.dk>

Dear lme4 authors,

I have a question regarding the calculation of sums of squares in anova for lmerMod object. I know that there were some discussions regarding how they are calculated (but still remains unclear to me..).

As far as I understand the way they are calculated is similar to the way they are calculated in lm objects, that is transforming Y into orthogonal Q space, and then computing sums of squares for the independent effects.

I have found in your  JSS paper "Fitting linear mixed effects models using lme4" some explanations (in equations 67 and 68). Would it be possible to give some more comments on these equations? 
And what about the partial (type 3) sums of squares -  is there a way to calculate them using the same way?

Hope my questions were clear!
Thank you in advance!

Alexandra Kuznetsova

From bbolker at gmail.com  Wed Sep 24 23:14:31 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 24 Sep 2014 17:14:31 -0400
Subject: [R-sig-ME] sums of squares and F values in anova
In-Reply-To: <0566E17B6DEC62459078112371B7508E1D90CE@ait-pex02mbx05.win.dtu.dk>
References: <0566E17B6DEC62459078112371B7508E1D90CE@ait-pex02mbx05.win.dtu.dk>
Message-ID: <54233437.9060101@gmail.com>

On 14-09-24 04:21 PM, Alexandra Kuznetsova wrote:
> Dear lme4 authors,
> 
> I have a question regarding the calculation of sums of squares in
> anova for lmerMod object. I know that there were some discussions
> regarding how they are calculated (but still remains unclear to
> me..).
> 
> As far as I understand the way they are calculated is similar to the
> way they are calculated in lm objects, that is transforming Y into
> orthogonal Q space, and then computing sums of squares for the
> independent effects.
> 
> I have found in your  JSS paper "Fitting linear mixed effects models
> using lme4" some explanations (in equations 67 and 68). Would it be
> possible to give some more comments on these equations? And what
> about the partial (type 3) sums of squares -  is there a way to
> calculate them using the same way?
> 
> Hope my questions were clear! Thank you in advance!

  I'm not sure exactly what your questions are.  Could you please
clarify (sorry!) what you mean about partial sums of squares?  Here's an
example showing that the results of lme4's anova.merMod and base R's:
anova.lm do in fact agree for a model with the random effects variance
forced to (almost) zero.  At the risk of further muddying the water,
I'll point out that car::Anova(fit,type="II") and
car::Anova(fit,type="III") give two different answers for this problem,
neither of which matches the computation below ...

===================
fit <- lm(sr ~ ., data = LifeCycleSavings)
anova(fit)


## construct lmer model with near-zero variance
LC2 <- transform(LifeCycleSavings,f=factor(1:2)) ## bogus
library("lme4")
form <- sr ~ pop15 + pop75 + dpi + ddpi + (1|f)  ## hack
## to avoid (Error in terms.formula(formula(x, fixed.only = TRUE)) :
##   '.' in formula and no 'data' argument)

lmod <- lFormula(form, data=LC2)
d2 <- lmer(form, data=LC2,devFunOnly=TRUE)
llik <- d2(1e-5)
fit2 <- mkMerMod(environment(d2),opt=list(par=1e-5,
                           fval=llik,
                           feval=1,
                           conv=0,
                           message=NULL),
                         lmod$reTrms, fr = lmod$fr)
all.equal(coef(fit),fixef(fit2))
anova(fit2)   ## practically equal to anova(fit) above
==================

For those following along, the paper is at
http://arxiv.org/abs/1406.5823 (or http://arxiv.org/pdf/1406.5823v1 for
a direct link to the PDF), and the raw LaTeX for the specific section is:

===============
To understand how these quantities are computed, let $\bm R_i$ contain
the rows of $\bm R_X$ (Equation~\ref{eq:blockCholeskyDecomp}) associated
with the $i$th fixed-effects term.  Then the sum of squares for term
$i$ is,
\begin{equation}
  \label{eq:SS}
  SS_i = \widehat{\bm\beta}\trans\bm R_i\trans \bm R_i \widehat{\bm\beta}
\end{equation}
If $DF_i$ is the number of columns in $\bm R_i$, then the
$F$~statistic for term $i$ is,
\begin{equation}
  \label{eq:Fstat}
  F_i = \frac{SS_i}{\widehat{\sigma}^2 DF_i}
\end{equation}


> 
> Alexandra Kuznetsova _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From jfox at mcmaster.ca  Thu Sep 25 00:03:43 2014
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 24 Sep 2014 18:03:43 -0400
Subject: [R-sig-ME] sums of squares and F values in anova
In-Reply-To: <54233437.9060101@gmail.com>
References: <0566E17B6DEC62459078112371B7508E1D90CE@ait-pex02mbx05.win.dtu.dk>
	<54233437.9060101@gmail.com>
Message-ID: <web-528500534@cgpsrv2.cis.mcmaster.ca>

Dear Ben,

anova() computes sequential ("type I") tests, so one wouldn't for correlated Xs expect the result to be the same as the "type II" or "type III" tests computed by Anova(), which, however, for an additive model should be the same as each other. You *would* expect the last test in the sequence produced by anova() to be the same as the corresponding type-II or -III test. 

In the case of LMMs fit by lmer(), Anova() computes Wald F-tests using the Kenward-Roger coefficient covariance matrix and Satterthwaite df; for the data/model in your example, that should produce a small difference in the F-statistics.

Here's what I get for your example:

------------- snip ----------

> anova(fit)
Analysis of Variance Table

Response: sr
          Df Sum Sq Mean Sq F value    Pr(>F)    
pop15      1 204.12 204.118 14.1157 0.0004922 ***
pop75      1  53.34  53.343  3.6889 0.0611255 .  
dpi        1  12.40  12.401  0.8576 0.3593551    
ddpi       1  63.05  63.054  4.3605 0.0424711 *  
Residuals 45 650.71  14.460                      
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

> anova(fit2) ## practically equal to anova(fit) above
Analysis of Variance Table
      Df  Sum Sq Mean Sq F value
pop15  1 204.118 204.118 14.1157
pop75  1  53.343  53.343  3.6889
dpi    1  12.401  12.401  0.8576
ddpi   1  63.054  63.054  4.3605


> Anova(fit)
Anova Table (Type II tests)

Response: sr
          Sum Sq Df F value   Pr(>F)   
pop15     147.01  1 10.1666 0.002603 **
pop75      35.24  1  2.4367 0.125530   
dpi         1.89  1  0.1309 0.719173   
ddpi       63.05  1  4.3605 0.042471 * 
Residuals 650.71 45 
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1  

> Anova(fit, type=3)
Anova Table (Type III tests)

Response: sr
            Sum Sq Df F value    Pr(>F)    
(Intercept) 218.16  1 15.0867 0.0003338 ***
pop15       147.01  1 10.1666 0.0026030 ** 
pop75        35.24  1  2.4367 0.1255298    
dpi           1.89  1  0.1309 0.7191732    
ddpi         63.05  1  4.3605 0.0424711 *  
Residuals   650.71 45                      
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 

> Anova(fit2)
Analysis of Deviance Table (Type II Wald chisquare tests)

Response: sr
        Chisq Df Pr(>Chisq)   
pop15 10.1666  1    0.00143 **
pop75  2.4367  1    0.11852   
dpi    0.1309  1    0.71748   
ddpi   4.3605  1    0.03678 * 
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

> Anova(fit2, test="F")
Loading required package: pbkrtest
Loading required package: MASS
Analysis of Deviance Table (Type II Wald F tests with Kenward-Roger df)

Response: sr
            F Df Df.res  Pr(>F)   
pop15 10.1519  1 44.031 0.00265 **
pop75  2.4326  1 44.036 0.12599   
dpi    0.1245  1 44.811 0.72588   
ddpi   4.2179  1 44.600 0.04589 * 
---                  
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

> Anova(fit2, test="F", type=3)
Analysis of Deviance Table (Type III Wald F tests with Kenward-Roger df)

Response: sr
                  F Df Df.res    Pr(>F)    
(Intercept) 14.9643  1 44.560 0.0003538 ***
pop15       10.1519  1 44.031 0.0026503 ** 
pop75        2.4326  1 44.036 0.1259919    
dpi          0.1245  1 44.811 0.7258840    
ddpi         4.2179  1 44.600 0.0458898 *  
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

----------------- snip ----------

These results are as expected.

Best,
 John

On Wed, 24 Sep 2014 17:14:31 -0400
 Ben Bolker <bbolker at gmail.com> wrote:
> On 14-09-24 04:21 PM, Alexandra Kuznetsova wrote:
> > Dear lme4 authors,
> > 
> > I have a question regarding the calculation of sums of squares in
> > anova for lmerMod object. I know that there were some discussions
> > regarding how they are calculated (but still remains unclear to
> > me..).
> > 
> > As far as I understand the way they are calculated is similar to the
> > way they are calculated in lm objects, that is transforming Y into
> > orthogonal Q space, and then computing sums of squares for the
> > independent effects.
> > 
> > I have found in your  JSS paper "Fitting linear mixed effects models
> > using lme4" some explanations (in equations 67 and 68). Would it be
> > possible to give some more comments on these equations? And what
> > about the partial (type 3) sums of squares -  is there a way to
> > calculate them using the same way?
> > 
> > Hope my questions were clear! Thank you in advance!
> 
>   I'm not sure exactly what your questions are.  Could you please
> clarify (sorry!) what you mean about partial sums of squares?  Here's an
> example showing that the results of lme4's anova.merMod and base R's:
> anova.lm do in fact agree for a model with the random effects variance
> forced to (almost) zero.  At the risk of further muddying the water,
> I'll point out that car::Anova(fit,type="II") and
> car::Anova(fit,type="III") give two different answers for this problem,
> neither of which matches the computation below ...
> 
> ===================
> fit <- lm(sr ~ ., data = LifeCycleSavings)
> anova(fit)
> 
> 
> ## construct lmer model with near-zero variance
> LC2 <- transform(LifeCycleSavings,f=factor(1:2)) ## bogus
> library("lme4")
> form <- sr ~ pop15 + pop75 + dpi + ddpi + (1|f)  ## hack
> ## to avoid (Error in terms.formula(formula(x, fixed.only = TRUE)) :
> ##   '.' in formula and no 'data' argument)
> 
> lmod <- lFormula(form, data=LC2)
> d2 <- lmer(form, data=LC2,devFunOnly=TRUE)
> llik <- d2(1e-5)
> fit2 <- mkMerMod(environment(d2),opt=list(par=1e-5,
>                            fval=llik,
>                            feval=1,
>                            conv=0,
>                            message=NULL),
>                          lmod$reTrms, fr = lmod$fr)
> all.equal(coef(fit),fixef(fit2))
> anova(fit2)   ## practically equal to anova(fit) above
> ==================
> 
> For those following along, the paper is at
> http://arxiv.org/abs/1406.5823 (or http://arxiv.org/pdf/1406.5823v1 for
> a direct link to the PDF), and the raw LaTeX for the specific section is:
> 
> ===============
> To understand how these quantities are computed, let $\bm R_i$ contain
> the rows of $\bm R_X$ (Equation~\ref{eq:blockCholeskyDecomp}) associated
> with the $i$th fixed-effects term.  Then the sum of squares for term
> $i$ is,
> \begin{equation}
>   \label{eq:SS}
>   SS_i = \widehat{\bm\beta}\trans\bm R_i\trans \bm R_i \widehat{\bm\beta}
> \end{equation}
> If $DF_i$ is the number of columns in $\bm R_i$, then the
> $F$~statistic for term $i$ is,
> \begin{equation}
>   \label{eq:Fstat}
>   F_i = \frac{SS_i}{\widehat{\sigma}^2 DF_i}
> \end{equation}
> 
> 
> > 
> > Alexandra Kuznetsova _______________________________________________ 
> > R-sig-mixed-models at r-project.org mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From coanil at posteo.org  Thu Sep 25 14:11:04 2014
From: coanil at posteo.org (Michael Cone)
Date: Thu, 25 Sep 2014 14:11:04 +0200
Subject: [R-sig-ME] Confidence interval for sum of coefficients
Message-ID: <14644c74d26e578b64eb4697fed609a5@posteo.de>

Hello,

I suspect this to be simple, but I can't figure it out.

> library(lme4)
> data(Machines)
> fm1 <- lmer(score ~ Machine + (Machine | Worker), data = Machines)
> summary(fm1)
Fixed effects:
             Estimate Std. Error t value
(Intercept)   52.356      1.681  31.151
MachineB       7.967      2.421   3.291
MachineC      13.917      1.540   9.036
> confint(fm1)
                  2.5 %     97.5 %
[...]
(Intercept) 48.7964047 55.9147119
MachineB     2.8401623 13.0931789
MachineC    10.6552809 17.1780575

[and 14 warnings, but it's just an example:
In optwrap(optimizer, par = start, fn = function(x) dd(mkpar(npar1,  ... 
:
convergence code 1 from bobyqa: bobyqa -- maximum number of function 
evaluations exceeded
...
In profile.merMod(object, signames = oldNames, ...) : non-monotonic 
profile]

I'd like to have confidence intervals for the overall score of MachineA, 
MachineB, and MachineB. MachineA is easy (CI of the intercept), but how 
do I combine the CI of the intercept with the CI of the MachineB 
parameter, and likewise the CI of the intercept with the parameter of 
MachineC? Can I simply add the lower and upper bounds of the two 
intervals or is this naive?

Thank you for your time,

Michael


From lorenz.gygax at agroscope.admin.ch  Thu Sep 25 14:35:40 2014
From: lorenz.gygax at agroscope.admin.ch (lorenz.gygax at agroscope.admin.ch)
Date: Thu, 25 Sep 2014 12:35:40 +0000
Subject: [R-sig-ME] Confidence interval for sum of coefficients
In-Reply-To: <14644c74d26e578b64eb4697fed609a5@posteo.de>
References: <14644c74d26e578b64eb4697fed609a5@posteo.de>
Message-ID: <B291F8F571C9494EA3EAF8C8B471333F22E15A5E@WBF-C7001.bk.evdad.admin.ch>

Dear Michael,

This is possibly not what you should do. As has been recently suggested to me on this list, you could use bootMer with a function that computes the sum(s) that you are interested in. Then use boot.ci from the boot package to estimate the confidence intervals

Best wishes, Lorenz

> -----Urspr?ngliche Nachricht-----
> Von: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
> bounces at r-project.org] Im Auftrag von Michael Cone
> Gesendet: Donnerstag, 25. September 2014 14:11
> An: r-sig-mixed-models at r-project.org
> Betreff: [R-sig-ME] Confidence interval for sum of coefficients
> 
> Hello,
> 
> I suspect this to be simple, but I can't figure it out.
> 
> > library(lme4)
> > data(Machines)
> > fm1 <- lmer(score ~ Machine + (Machine | Worker), data = Machines)
> > summary(fm1)
> Fixed effects:
>              Estimate Std. Error t value
> (Intercept)   52.356      1.681  31.151
> MachineB       7.967      2.421   3.291
> MachineC      13.917      1.540   9.036
> > confint(fm1)
>                   2.5 %     97.5 %
> [...]
> (Intercept) 48.7964047 55.9147119
> MachineB     2.8401623 13.0931789
> MachineC    10.6552809 17.1780575
> 
> [and 14 warnings, but it's just an example:
> In optwrap(optimizer, par = start, fn = function(x) dd(mkpar(npar1,  ...
> :
> convergence code 1 from bobyqa: bobyqa -- maximum number of function
> evaluations exceeded
> ...
> In profile.merMod(object, signames = oldNames, ...) : non-monotonic
> profile]
> 
> I'd like to have confidence intervals for the overall score of MachineA,
> MachineB, and MachineB. MachineA is easy (CI of the intercept), but how
> do I combine the CI of the intercept with the CI of the MachineB
> parameter, and likewise the CI of the intercept with the parameter of
> MachineC? Can I simply add the lower and upper bounds of the two
> intervals or is this naive?
> 
> Thank you for your time,
> 
> Michael
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From coanil at posteo.org  Thu Sep 25 14:40:54 2014
From: coanil at posteo.org (Michael Cone)
Date: Thu, 25 Sep 2014 14:40:54 +0200
Subject: [R-sig-ME] Confidence interval for sum of coefficients
In-Reply-To: <B291F8F571C9494EA3EAF8C8B471333F22E15A5E@WBF-C7001.bk.evdad.admin.ch>
References: <14644c74d26e578b64eb4697fed609a5@posteo.de>
	<B291F8F571C9494EA3EAF8C8B471333F22E15A5E@WBF-C7001.bk.evdad.admin.ch>
Message-ID: <d3ac282bc0648a0b9ca75ceb1aea4c32@posteo.de>

Dear Lorenz,

ah, thank you for pointing this out, I really should have read the list 
more carefully. I will look into the relevant conversation.

Kind regards
Michael

Am 25.09.2014 14:35 schrieb lorenz.gygax at agroscope.admin.ch:
> Dear Michael,
> 
> This is possibly not what you should do. As has been recently
> suggested to me on this list, you could use bootMer with a function
> that computes the sum(s) that you are interested in. Then use boot.ci
> from the boot package to estimate the confidence intervals
> 
> Best wishes, Lorenz
> 
>> -----Urspr?ngliche Nachricht-----
>> Von: r-sig-mixed-models-bounces at r-project.org 
>> [mailto:r-sig-mixed-models-
>> bounces at r-project.org] Im Auftrag von Michael Cone
>> Gesendet: Donnerstag, 25. September 2014 14:11
>> An: r-sig-mixed-models at r-project.org
>> Betreff: [R-sig-ME] Confidence interval for sum of coefficients
>> 
>> Hello,
>> 
>> I suspect this to be simple, but I can't figure it out.
>> 
>> > library(lme4)
>> > data(Machines)
>> > fm1 <- lmer(score ~ Machine + (Machine | Worker), data = Machines)
>> > summary(fm1)
>> Fixed effects:
>>              Estimate Std. Error t value
>> (Intercept)   52.356      1.681  31.151
>> MachineB       7.967      2.421   3.291
>> MachineC      13.917      1.540   9.036
>> > confint(fm1)
>>                   2.5 %     97.5 %
>> [...]
>> (Intercept) 48.7964047 55.9147119
>> MachineB     2.8401623 13.0931789
>> MachineC    10.6552809 17.1780575
>> 
>> [and 14 warnings, but it's just an example:
>> In optwrap(optimizer, par = start, fn = function(x) dd(mkpar(npar1,  
>> ...
>> :
>> convergence code 1 from bobyqa: bobyqa -- maximum number of function
>> evaluations exceeded
>> ...
>> In profile.merMod(object, signames = oldNames, ...) : non-monotonic
>> profile]
>> 
>> I'd like to have confidence intervals for the overall score of 
>> MachineA,
>> MachineB, and MachineB. MachineA is easy (CI of the intercept), but 
>> how
>> do I combine the CI of the intercept with the CI of the MachineB
>> parameter, and likewise the CI of the intercept with the parameter of
>> MachineC? Can I simply add the lower and upper bounds of the two
>> intervals or is this naive?
>> 
>> Thank you for your time,
>> 
>> Michael
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From coanil at posteo.org  Thu Sep 25 15:26:14 2014
From: coanil at posteo.org (Michael Cone)
Date: Thu, 25 Sep 2014 15:26:14 +0200
Subject: [R-sig-ME] Confidence interval for sum of coefficients
In-Reply-To: <14644c74d26e578b64eb4697fed609a5@posteo.de>
References: <14644c74d26e578b64eb4697fed609a5@posteo.de>
Message-ID: <976d7ec07c97b4b64ea7d9bac129f98a@posteo.de>

Dear list,

Lorenz has pointed out to me Ben's suggestion to bootstrap the sums (or 
any linear combiantion) of coefficients I'm interested in. This may be 
the general approach, but I struggle to see why it would be illegitimate 
to simply change the reference level for the treatment contrast coding, 
fit the model again and run confint() a second time (and do so again for 
MachineC):

> Machines$Machine <- relevel(Machines$Machine, 'B')
> fm2 <- lmer(score ~ Machine + (Machine | Worker), data = Machines)
> summary(fm2)
Fixed effects:
             Estimate Std. Error t value
(Intercept)   60.322      3.529  17.096
MachineA      -7.967      2.421  -3.291
MachineC       5.950      2.446   2.432
> confint(fm2)
(Intercept)  52.8500103 67.7944456
MachineA    -13.0931710 -2.8401544
MachineC      0.7692323 11.1307757

Now the CI of the intercept is the confidence interval for the overall 
score of MachineB. Adding lower and upper bounds from fm1 would have 
given somewhat similar, but somewhat wider intervals.
(I probably have a lack of understanding as to how CIs can be calculated 
with. Is there an inuitive explanation for why the bounds don't add?)

> Machines$Machine <- relevel(Machines$Machine, 'C')
> fm3 <- lmer(score ~ Machine + (Machine | Worker), data = Machines)
> summary(fm3)
Fixed effects:
             Estimate Std. Error t value
(Intercept)   66.272      1.806   36.69
MachineB      -5.950      2.446   -2.43
MachineA     -13.917      1.540   -9.04
> confint(fm3)
(Intercept)  62.4471752  70.0972752
MachineB    -11.1307677  -0.7692243
MachineA    -17.1780524 -10.6552759

Thanks, and best wishes
Michael

Am 25.09.2014 14:11 schrieb Michael Cone:
> Hello,
> 
> I suspect this to be simple, but I can't figure it out.
> 
>> library(lme4)
>> data(Machines)
>> fm1 <- lmer(score ~ Machine + (Machine | Worker), data = Machines)
>> summary(fm1)
> Fixed effects:
>             Estimate Std. Error t value
> (Intercept)   52.356      1.681  31.151
> MachineB       7.967      2.421   3.291
> MachineC      13.917      1.540   9.036
>> confint(fm1)
>                  2.5 %     97.5 %
> [...]
> (Intercept) 48.7964047 55.9147119
> MachineB     2.8401623 13.0931789
> MachineC    10.6552809 17.1780575
> 
> [and 14 warnings, but it's just an example:
> In optwrap(optimizer, par = start, fn = function(x) dd(mkpar(npar1,  
> ... :
> convergence code 1 from bobyqa: bobyqa -- maximum number of function
> evaluations exceeded
> ...
> In profile.merMod(object, signames = oldNames, ...) : non-monotonic 
> profile]
> 
> I'd like to have confidence intervals for the overall score of
> MachineA, MachineB, and MachineB. MachineA is easy (CI of the
> intercept), but how do I combine the CI of the intercept with the CI
> of the MachineB parameter, and likewise the CI of the intercept with
> the parameter of MachineC? Can I simply add the lower and upper bounds
> of the two intervals or is this naive?
> 
> Thank you for your time,
> 
> Michael
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From doogan.1 at osu.edu  Thu Sep 25 16:17:17 2014
From: doogan.1 at osu.edu (Doogan, Nathan)
Date: Thu, 25 Sep 2014 14:17:17 +0000
Subject: [R-sig-ME] Confidence interval for sum of coefficients
In-Reply-To: <976d7ec07c97b4b64ea7d9bac129f98a@posteo.de>
References: <14644c74d26e578b64eb4697fed609a5@posteo.de>
	<976d7ec07c97b4b64ea7d9bac129f98a@posteo.de>
Message-ID: <69AD021970EB5C4181A53E9C165E0A6976D3935E@CIO-KRC-D1MBX05.osuad.osu.edu>

Is there an issue with using the variance sum law and the var-covar matrix  to sum two parameters and estimate the variance of the sum? i.e., add their variances and covariances as expressed in the variance covariance matrix of the parameter estimates, probably obtained with vcov(modelObj).

Or is this too simplistic for a mixed model?

-Nate

--
Nathan J. Doogan, Ph.D.  | College of Public Health
Post-Doctoral Researcher | The Ohio State University



-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Michael Cone
Sent: Thursday, September 25, 2014 9:26 AM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Confidence interval for sum of coefficients

Dear list,

Lorenz has pointed out to me Ben's suggestion to bootstrap the sums (or any linear combiantion) of coefficients I'm interested in. This may be the general approach, but I struggle to see why it would be illegitimate to simply change the reference level for the treatment contrast coding, fit the model again and run confint() a second time (and do so again for
MachineC):

> Machines$Machine <- relevel(Machines$Machine, 'B')
> fm2 <- lmer(score ~ Machine + (Machine | Worker), data = Machines)
> summary(fm2)
Fixed effects:
             Estimate Std. Error t value
(Intercept)   60.322      3.529  17.096
MachineA      -7.967      2.421  -3.291
MachineC       5.950      2.446   2.432
> confint(fm2)
(Intercept)  52.8500103 67.7944456
MachineA    -13.0931710 -2.8401544
MachineC      0.7692323 11.1307757

Now the CI of the intercept is the confidence interval for the overall score of MachineB. Adding lower and upper bounds from fm1 would have given somewhat similar, but somewhat wider intervals.
(I probably have a lack of understanding as to how CIs can be calculated with. Is there an inuitive explanation for why the bounds don't add?)

> Machines$Machine <- relevel(Machines$Machine, 'C')
> fm3 <- lmer(score ~ Machine + (Machine | Worker), data = Machines)
> summary(fm3)
Fixed effects:
             Estimate Std. Error t value
(Intercept)   66.272      1.806   36.69
MachineB      -5.950      2.446   -2.43
MachineA     -13.917      1.540   -9.04
> confint(fm3)
(Intercept)  62.4471752  70.0972752
MachineB    -11.1307677  -0.7692243
MachineA    -17.1780524 -10.6552759

Thanks, and best wishes
Michael

Am 25.09.2014 14:11 schrieb Michael Cone:
> Hello,
> 
> I suspect this to be simple, but I can't figure it out.
> 
>> library(lme4)
>> data(Machines)
>> fm1 <- lmer(score ~ Machine + (Machine | Worker), data = Machines)
>> summary(fm1)
> Fixed effects:
>             Estimate Std. Error t value
> (Intercept)   52.356      1.681  31.151
> MachineB       7.967      2.421   3.291
> MachineC      13.917      1.540   9.036
>> confint(fm1)
>                  2.5 %     97.5 %
> [...]
> (Intercept) 48.7964047 55.9147119
> MachineB     2.8401623 13.0931789
> MachineC    10.6552809 17.1780575
> 
> [and 14 warnings, but it's just an example:
> In optwrap(optimizer, par = start, fn = function(x) dd(mkpar(npar1, 
> ... :
> convergence code 1 from bobyqa: bobyqa -- maximum number of function 
> evaluations exceeded ...
> In profile.merMod(object, signames = oldNames, ...) : non-monotonic 
> profile]
> 
> I'd like to have confidence intervals for the overall score of 
> MachineA, MachineB, and MachineB. MachineA is easy (CI of the 
> intercept), but how do I combine the CI of the intercept with the CI 
> of the MachineB parameter, and likewise the CI of the intercept with 
> the parameter of MachineC? Can I simply add the lower and upper bounds 
> of the two intervals or is this naive?
> 
> Thank you for your time,
> 
> Michael
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Thu Sep 25 16:26:19 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 25 Sep 2014 10:26:19 -0400
Subject: [R-sig-ME] Confidence interval for sum of coefficients
In-Reply-To: <69AD021970EB5C4181A53E9C165E0A6976D3935E@CIO-KRC-D1MBX05.osuad.osu.edu>
References: <14644c74d26e578b64eb4697fed609a5@posteo.de>	<976d7ec07c97b4b64ea7d9bac129f98a@posteo.de>
	<69AD021970EB5C4181A53E9C165E0A6976D3935E@CIO-KRC-D1MBX05.osuad.osu.edu>
Message-ID: <5424260B.3060703@gmail.com>

On 14-09-25 10:17 AM, Doogan, Nathan wrote:
> Is there an issue with using the variance sum law and the var-covar
> matrix  to sum two parameters and estimate the variance of the sum?
> i.e., add their variances and covariances as expressed in the
> variance covariance matrix of the parameter estimates, probably
> obtained with vcov(modelObj).
> 
> Or is this too simplistic for a mixed model?
> 
> -Nate
> 
> -- Nathan J. Doogan, Ph.D.  | College of Public Health Post-Doctoral
> Researcher | The Ohio State University
> 


  That was exactly what I was going to suggest (but hadn't gotten around
to it).  It's slightly less accurate than parametric bootstrapping or
likelihood profiling (the former is computationally straightforward, the
latter would have to be implemented more or less from scratch), but
should be fine in many cases.

 To be more specific, if you have a linear combination of parameters in
mind (e.g. lincomb <- c(1,1,1) for adding all three parameters), you want

lincomb %*% vcov(fitted_model) %*% lincomb

(R should take care of the transposition where necessary, I think)
to get the variance.

By the way, I don't think it makes any sense at all to add confidence
intervals; as one example, imagine that two quantities have estimated
values of 1 and 2 with confidence intervals {-1,3} and {1,3}; should the
net confidence intervals actually be {0,6} ... ?  Or add many values
with lower bounds at zero -- should the joint lower bound really be
zero?  If you want to add something, add *variances* and convert to std
errors and from there to CIs ...


> 
> 
> -----Original Message----- From:
> r-sig-mixed-models-bounces at r-project.org
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of
> Michael Cone Sent: Thursday, September 25, 2014 9:26 AM To:
> r-sig-mixed-models at r-project.org Subject: Re: [R-sig-ME] Confidence
> interval for sum of coefficients
> 
> Dear list,
> 
> Lorenz has pointed out to me Ben's suggestion to bootstrap the sums
> (or any linear combiantion) of coefficients I'm interested in. This
> may be the general approach, but I struggle to see why it would be
> illegitimate to simply change the reference level for the treatment
> contrast coding, fit the model again and run confint() a second time
> (and do so again for MachineC):
> 
>> Machines$Machine <- relevel(Machines$Machine, 'B') fm2 <-
>> lmer(score ~ Machine + (Machine | Worker), data = Machines) 
>> summary(fm2)
> Fixed effects: Estimate Std. Error t value (Intercept)   60.322
> 3.529  17.096 MachineA      -7.967      2.421  -3.291 MachineC
> 5.950      2.446   2.432
>> confint(fm2)
> (Intercept)  52.8500103 67.7944456 MachineA    -13.0931710
> -2.8401544 MachineC      0.7692323 11.1307757
> 
> Now the CI of the intercept is the confidence interval for the
> overall score of MachineB. Adding lower and upper bounds from fm1
> would have given somewhat similar, but somewhat wider intervals. (I
> probably have a lack of understanding as to how CIs can be calculated
> with. Is there an inuitive explanation for why the bounds don't
> add?)
> 
>> Machines$Machine <- relevel(Machines$Machine, 'C') fm3 <-
>> lmer(score ~ Machine + (Machine | Worker), data = Machines) 
>> summary(fm3)
> Fixed effects: Estimate Std. Error t value (Intercept)   66.272
> 1.806   36.69 MachineB      -5.950      2.446   -2.43 MachineA
> -13.917      1.540   -9.04
>> confint(fm3)
> (Intercept)  62.4471752  70.0972752 MachineB    -11.1307677
> -0.7692243 MachineA    -17.1780524 -10.6552759
> 
> Thanks, and best wishes Michael
> 
> Am 25.09.2014 14:11 schrieb Michael Cone:
>> Hello,
>> 
>> I suspect this to be simple, but I can't figure it out.
>> 
>>> library(lme4) data(Machines) fm1 <- lmer(score ~ Machine +
>>> (Machine | Worker), data = Machines) summary(fm1)
>> Fixed effects: Estimate Std. Error t value (Intercept)   52.356
>> 1.681  31.151 MachineB       7.967      2.421   3.291 MachineC
>> 13.917      1.540   9.036
>>> confint(fm1)
>> 2.5 %     97.5 % [...] (Intercept) 48.7964047 55.9147119 MachineB
>> 2.8401623 13.0931789 MachineC    10.6552809 17.1780575
>> 
>> [and 14 warnings, but it's just an example: In optwrap(optimizer,
>> par = start, fn = function(x) dd(mkpar(npar1, ... : convergence
>> code 1 from bobyqa: bobyqa -- maximum number of function 
>> evaluations exceeded ... In profile.merMod(object, signames =
>> oldNames, ...) : non-monotonic profile]
>> 
>> I'd like to have confidence intervals for the overall score of 
>> MachineA, MachineB, and MachineB. MachineA is easy (CI of the 
>> intercept), but how do I combine the CI of the intercept with the
>> CI of the MachineB parameter, and likewise the CI of the intercept
>> with the parameter of MachineC? Can I simply add the lower and
>> upper bounds of the two intervals or is this naive?
>> 
>> Thank you for your time,
>> 
>> Michael
>> 
>> _______________________________________________ 
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From russell-lenth at uiowa.edu  Thu Sep 25 17:43:36 2014
From: russell-lenth at uiowa.edu (Lenth, Russell V)
Date: Thu, 25 Sep 2014 15:43:36 +0000
Subject: [R-sig-ME] Confidence interval for sum of coefficients
Message-ID: <51F0C7C54B032A42A23B74A088E7141C2E6544DF@itsnt443.iowa.uiowa.edu>

An easy way to get the results you want based on the adjusted variance-covariance matrix is:

    library(lsmeans)
    lsmeans(fm1, "Machines")

The adjustments and d.f. are made using pbkrtest's 'vcovAdj' and 'Lb_ddf' functions.

Russ Lenth

-----Original Message-----
Message: 1
Date: Thu, 25 Sep 2014 14:11:04 +0200
From: Michael Cone <coanil at posteo.org>
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Confidence interval for sum of coefficients
Message-ID: <14644c74d26e578b64eb4697fed609a5 at posteo.de>
Content-Type: text/plain; charset=US-ASCII; format=flowed

Hello,

I suspect this to be simple, but I can't figure it out.

> library(lme4)
> data(Machines)
> fm1 <- lmer(score ~ Machine + (Machine | Worker), data = Machines)
> summary(fm1)
Fixed effects:
             Estimate Std. Error t value
(Intercept)   52.356      1.681  31.151
MachineB       7.967      2.421   3.291
MachineC      13.917      1.540   9.036
> confint(fm1)
                  2.5 %     97.5 %
[...]
(Intercept) 48.7964047 55.9147119
MachineB     2.8401623 13.0931789
MachineC    10.6552809 17.1780575

[and 14 warnings, but it's just an example:
In optwrap(optimizer, par = start, fn = function(x) dd(mkpar(npar1,  ... 
:
convergence code 1 from bobyqa: bobyqa -- maximum number of function evaluations exceeded ...
In profile.merMod(object, signames = oldNames, ...) : non-monotonic profile]

I'd like to have confidence intervals for the overall score of MachineA, MachineB, and MachineB. MachineA is easy (CI of the intercept), but how do I combine the CI of the intercept with the CI of the MachineB parameter, and likewise the CI of the intercept with the parameter of MachineC? Can I simply add the lower and upper bounds of the two intervals or is this naive?

Thank you for your time,

Michael


From coanil at posteo.org  Fri Sep 26 07:37:48 2014
From: coanil at posteo.org (Michael Cone)
Date: Fri, 26 Sep 2014 07:37:48 +0200
Subject: [R-sig-ME] Confidence interval for sum of coefficients
In-Reply-To: <5424260B.3060703@gmail.com>
References: <14644c74d26e578b64eb4697fed609a5@posteo.de>
	<976d7ec07c97b4b64ea7d9bac129f98a@posteo.de>
	<69AD021970EB5C4181A53E9C165E0A6976D3935E@CIO-KRC-D1MBX05.osuad.osu.edu>
	<5424260B.3060703@gmail.com>
Message-ID: <d066f448f3785d873fca7b1052e7df3e@posteo.de>

Dear Ben, Nathan,

thank you for the suggestions and explanations, that makes perfect 
sense. I come from a non-statistical background, and, lacking the 
basics, sometimes hit sort of a brick wall in my understanding.

Kind regards,
Michael




On 25.09.2014 16:26, Ben Bolker wrote:
> On 14-09-25 10:17 AM, Doogan, Nathan wrote:
>> Is there an issue with using the variance sum law and the var-covar
>> matrix  to sum two parameters and estimate the variance of the sum?
>> i.e., add their variances and covariances as expressed in the
>> variance covariance matrix of the parameter estimates, probably
>> obtained with vcov(modelObj).
>> 
>> Or is this too simplistic for a mixed model?
>> 
>> -Nate
>> 
>> -- Nathan J. Doogan, Ph.D.  | College of Public Health Post-Doctoral
>> Researcher | The Ohio State University
>> 
> 
> 
>   That was exactly what I was going to suggest (but hadn't gotten 
> around
> to it).  It's slightly less accurate than parametric bootstrapping or
> likelihood profiling (the former is computationally straightforward, 
> the
> latter would have to be implemented more or less from scratch), but
> should be fine in many cases.
> 
>  To be more specific, if you have a linear combination of parameters in
> mind (e.g. lincomb <- c(1,1,1) for adding all three parameters), you 
> want
> 
> lincomb %*% vcov(fitted_model) %*% lincomb
> 
> (R should take care of the transposition where necessary, I think)
> to get the variance.
> 
> By the way, I don't think it makes any sense at all to add confidence
> intervals; as one example, imagine that two quantities have estimated
> values of 1 and 2 with confidence intervals {-1,3} and {1,3}; should 
> the
> net confidence intervals actually be {0,6} ... ?  Or add many values
> with lower bounds at zero -- should the joint lower bound really be
> zero?  If you want to add something, add *variances* and convert to std
> errors and from there to CIs ...
> 
> 
>> 
>> 
>> -----Original Message----- From:
>> r-sig-mixed-models-bounces at r-project.org
>> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of
>> Michael Cone Sent: Thursday, September 25, 2014 9:26 AM To:
>> r-sig-mixed-models at r-project.org Subject: Re: [R-sig-ME] Confidence
>> interval for sum of coefficients
>> 
>> Dear list,
>> 
>> Lorenz has pointed out to me Ben's suggestion to bootstrap the sums
>> (or any linear combiantion) of coefficients I'm interested in. This
>> may be the general approach, but I struggle to see why it would be
>> illegitimate to simply change the reference level for the treatment
>> contrast coding, fit the model again and run confint() a second time
>> (and do so again for MachineC):
>> 
>>> Machines$Machine <- relevel(Machines$Machine, 'B') fm2 <-
>>> lmer(score ~ Machine + (Machine | Worker), data = Machines)
>>> summary(fm2)
>> Fixed effects: Estimate Std. Error t value (Intercept)   60.322
>> 3.529  17.096 MachineA      -7.967      2.421  -3.291 MachineC
>> 5.950      2.446   2.432
>>> confint(fm2)
>> (Intercept)  52.8500103 67.7944456 MachineA    -13.0931710
>> -2.8401544 MachineC      0.7692323 11.1307757
>> 
>> Now the CI of the intercept is the confidence interval for the
>> overall score of MachineB. Adding lower and upper bounds from fm1
>> would have given somewhat similar, but somewhat wider intervals. (I
>> probably have a lack of understanding as to how CIs can be calculated
>> with. Is there an inuitive explanation for why the bounds don't
>> add?)
>> 
>>> Machines$Machine <- relevel(Machines$Machine, 'C') fm3 <-
>>> lmer(score ~ Machine + (Machine | Worker), data = Machines)
>>> summary(fm3)
>> Fixed effects: Estimate Std. Error t value (Intercept)   66.272
>> 1.806   36.69 MachineB      -5.950      2.446   -2.43 MachineA
>> -13.917      1.540   -9.04
>>> confint(fm3)
>> (Intercept)  62.4471752  70.0972752 MachineB    -11.1307677
>> -0.7692243 MachineA    -17.1780524 -10.6552759
>> 
>> Thanks, and best wishes Michael
>> 
>> Am 25.09.2014 14:11 schrieb Michael Cone:
>>> Hello,
>>> 
>>> I suspect this to be simple, but I can't figure it out.
>>> 
>>>> library(lme4) data(Machines) fm1 <- lmer(score ~ Machine +
>>>> (Machine | Worker), data = Machines) summary(fm1)
>>> Fixed effects: Estimate Std. Error t value (Intercept)   52.356
>>> 1.681  31.151 MachineB       7.967      2.421   3.291 MachineC
>>> 13.917      1.540   9.036
>>>> confint(fm1)
>>> 2.5 %     97.5 % [...] (Intercept) 48.7964047 55.9147119 MachineB
>>> 2.8401623 13.0931789 MachineC    10.6552809 17.1780575
>>> 
>>> [and 14 warnings, but it's just an example: In optwrap(optimizer,
>>> par = start, fn = function(x) dd(mkpar(npar1, ... : convergence
>>> code 1 from bobyqa: bobyqa -- maximum number of function
>>> evaluations exceeded ... In profile.merMod(object, signames =
>>> oldNames, ...) : non-monotonic profile]
>>> 
>>> I'd like to have confidence intervals for the overall score of
>>> MachineA, MachineB, and MachineB. MachineA is easy (CI of the
>>> intercept), but how do I combine the CI of the intercept with the
>>> CI of the MachineB parameter, and likewise the CI of the intercept
>>> with the parameter of MachineC? Can I simply add the lower and
>>> upper bounds of the two intervals or is this naive?
>>> 
>>> Thank you for your time,
>>> 
>>> Michael
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From coanil at posteo.org  Fri Sep 26 07:40:35 2014
From: coanil at posteo.org (Michael Cone)
Date: Fri, 26 Sep 2014 07:40:35 +0200
Subject: [R-sig-ME] Confidence interval for sum of coefficients
In-Reply-To: <51F0C7C54B032A42A23B74A088E7141C2E6544DF@itsnt443.iowa.uiowa.edu>
References: <51F0C7C54B032A42A23B74A088E7141C2E6544DF@itsnt443.iowa.uiowa.edu>
Message-ID: <0f055378cc51002e26ac945d294eac5b@posteo.de>

Dear Russ,

thank you for the suggestion, I will have a look at the lsmeans package.

Best wishes,
Michael

On 25.09.2014 17:43, Lenth, Russell V wrote:
> An easy way to get the results you want based on the adjusted
> variance-covariance matrix is:
> 
>     library(lsmeans)
>     lsmeans(fm1, "Machines")
> 
> The adjustments and d.f. are made using pbkrtest's 'vcovAdj' and
> 'Lb_ddf' functions.
> 
> Russ Lenth
> 
> -----Original Message-----
> Message: 1
> Date: Thu, 25 Sep 2014 14:11:04 +0200
> From: Michael Cone <coanil at posteo.org>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Confidence interval for sum of coefficients
> Message-ID: <14644c74d26e578b64eb4697fed609a5 at posteo.de>
> Content-Type: text/plain; charset=US-ASCII; format=flowed
> 
> Hello,
> 
> I suspect this to be simple, but I can't figure it out.
> 
>> library(lme4)
>> data(Machines)
>> fm1 <- lmer(score ~ Machine + (Machine | Worker), data = Machines)
>> summary(fm1)
> Fixed effects:
>              Estimate Std. Error t value
> (Intercept)   52.356      1.681  31.151
> MachineB       7.967      2.421   3.291
> MachineC      13.917      1.540   9.036
>> confint(fm1)
>                   2.5 %     97.5 %
> [...]
> (Intercept) 48.7964047 55.9147119
> MachineB     2.8401623 13.0931789
> MachineC    10.6552809 17.1780575
> 
> [and 14 warnings, but it's just an example:
> In optwrap(optimizer, par = start, fn = function(x) dd(mkpar(npar1,  
> ...
> :
> convergence code 1 from bobyqa: bobyqa -- maximum number of function
> evaluations exceeded ...
> In profile.merMod(object, signames = oldNames, ...) : non-monotonic 
> profile]
> 
> I'd like to have confidence intervals for the overall score of
> MachineA, MachineB, and MachineB. MachineA is easy (CI of the
> intercept), but how do I combine the CI of the intercept with the CI
> of the MachineB parameter, and likewise the CI of the intercept with
> the parameter of MachineC? Can I simply add the lower and upper bounds
> of the two intervals or is this naive?
> 
> Thank you for your time,
> 
> Michael
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From jonlopez.research at gmail.com  Sat Sep 27 19:35:17 2014
From: jonlopez.research at gmail.com (Jon Lopez)
Date: Sat, 27 Sep 2014 19:35:17 +0200
Subject: [R-sig-ME] How can I estimate deviance explained of a mixed gamm?
Message-ID: <CAPypr8oWvzCq7u1o_5qXgfbm6pU0zrCfAfnRwkYjfokXjRWeEg@mail.gmail.com>

Dear mixed modelers,

I have already asked about this issue but never recived an answer
back. So I will try again.
I have been modelling fish biomass according to some environmental
parameters using mixed
effect models (gamm4 package). I don't want to bore you with the
details of my models since
I believe that they are not significant to the point of this message.
However, please feel
free to ask me about anything in case you think it is important. I
have some GAMM
candidates already. I am able to get AIC, BIC, R-sq, ... scores for
these models but,
unfortunately, I can't obtain deviance explained from them.

I have found an interesting procedure to try to derive it, published by
Gilman and colleagues in 2012. Here is the complete reference in case any
of you want to take a look to it:

"Gilman, E., Chaloupka, M., Read, A., Dalzell, P., Holetschek, J., Curtice,
C., 2012. Hawaii longline tuna fishery temporal trends in standardized
catch rates and length distributions and effects on pelagic and seamount
ecosystems. Aquatic Conservation: Marine and Freshwater Ecosystems 22(4),
446-488."

Nevertheless, the procedure explained in the paper above do not provide us
with the exact score. Thus, I have been considering other options like
using the deviance explained of a equivalent GAM with the random effect as
a spline term [s(x, bs="re")] but I don't know how accurate it would be.

Do you think both options can be used as an approximation for the
GAMM's deviance
explained? What are your feelings on that?

Any suggestion would be appreciated,

Thousands of thanks,

Jon Lopez

---------------------------------
PhD candidate
AZTI-Tecnalia, Spain

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Sat Sep 27 21:17:27 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 27 Sep 2014 15:17:27 -0400
Subject: [R-sig-ME] How can I estimate deviance explained of a mixed
	gamm?
In-Reply-To: <CAPypr8oWvzCq7u1o_5qXgfbm6pU0zrCfAfnRwkYjfokXjRWeEg@mail.gmail.com>
References: <CAPypr8oWvzCq7u1o_5qXgfbm6pU0zrCfAfnRwkYjfokXjRWeEg@mail.gmail.com>
Message-ID: <54270D47.6090904@gmail.com>

On 14-09-27 01:35 PM, Jon Lopez wrote:
> Dear mixed modelers,

> I have already asked about this issue but never recived an answer
> back. So I will try again.  I have been modelling fish biomass
> according to some environmental parameters using mixed effect models
> (gamm4 package). I don't want to bore you with the details of my
> models since I believe that they are not significant to the point of
> this message.  However, please feel free to ask me about anything in
> case you think it is important. I have some GAMM candidates
> already. I am able to get AIC, BIC, R-sq, ... scores for these
> models but, unfortunately, I can't obtain deviance explained from
> them.

> I have found an interesting procedure to try to derive it, published by
> Gilman and colleagues in 2012. Here is the complete reference in case any
> of you want to take a look to it:
> 
> "Gilman, E., Chaloupka, M., Read, A., Dalzell, P., Holetschek, J., Curtice,
> C., 2012. Hawaii longline tuna fishery temporal trends in standardized
> catch rates and length distributions and effects on pelagic and seamount
> ecosystems. Aquatic Conservation: Marine and Freshwater Ecosystems 22(4),
> 446-488."
> 
> Nevertheless, the procedure explained in the paper above do not provide us
> with the exact score. Thus, I have been considering other options like
> using the deviance explained of a equivalent GAM with the random effect as
> a spline term [s(x, bs="re")] but I don't know how accurate it would be.

> Do you think both options can be used as an approximation for the
> GAMM's deviance explained? What are your feelings on that?

  The problem with determining "accuracy" is that we don't really
know what you're trying to measure when you say you want to quantify
"deviance explained".  The variety of solutions for computing measures
of goodness of fit for GLMs (Nagelkerke, Cox and Snell, etc.), for
LMMs, and for GLMMs suggests that the problem is more of defining
a sensible metric than computing it.  So can you be more precise
about what you want?

  I don't know.  *If* the deviances returned by gamm4 and lme4
are comparable (I don't know whether they are), then presumably
you just compute them both?

For reference, the Gilman et al. paper says:

There is no accepted way to formally estimate model fit for GAMMs
(Wood, 2006; Zuur et al., 2009). We developed and implemented an
approach by fitting an equivalent GAM to derive the percentage
deviance explained (a measure of GAM goodness-of-fit: see Hastie and
Tibshirani, 1990), and to evaluate the importance of explicitly
accounting for trip- and set-specific heterogeneity (the random
effects attributable to the sampling design constraints) using a
GAMM. This method had the following steps: (i) fit a GAM using the
same data and fixed effect variables as used in the GAMM and extract
the deviance residuals; (ii) fit a linear mixed effects model to the
residuals using a constant parameter only model with both trip and set
as the random effects; (iii) fit a linear fixed effects model to the
residuals using a constant parameter only model; and (iv) compare the
fit of the two linear models using Akaike Information Criterion (AIC)
and a log-likelihood ratio test (Wood, 2006). A smaller comparative
AIC value indicates a relatively better fitting model, and the formal
log-likelihood ratio test determines if the difference in deviance
between the GAMM (linear mixed effects regression) and GAM (linear
regression) models was significant. Hence, using both AIC as a guide
and the log-likelihood ratio test as a formal test we determined
whether inclusion of random effects was necessary. If the inclusion of
the random effects was found to be necessary, then we expect the GAMM
would account for more of the deviance than the equivalent GAM.


From 2nuzzbot at gmail.com  Sun Sep 28 17:41:57 2014
From: 2nuzzbot at gmail.com (Etn)
Date: Sun, 28 Sep 2014 16:41:57 +0100
Subject: [R-sig-ME] individual Linear mixed models
Message-ID: <CAJ0DVYySnrK2-Kz6cD=GxTiPnKZTYVVhzAk5z_TapUd3u5o6Fg@mail.gmail.com>

Hi all,

I would be very grateful if you could please give any advice...
I am running a linear mixed model on a complete randomised block experiment

blocks = 11
treatments = 5 (A,B,C,D,E)
data recorded on days 1, 2, 11 and 18

I'm interested in looking at the difference between treatments on a
particular day
e.g. difference between treatments on day 1
(I am not interested in the difference between treatments on day 1 versus
day 11 etc.)

My question is: Is it OK to run linear mixed regression models on each day
individually? as I'm not concerned with the changes over time.....
(Results for individual days show a difference between treatments on day 1
and day 2, and no difference between treatments on day 11 and 18 - this
follows with what would be expected in reality)

fit <- lme(y ~ Treatment,  random = ~1|block)

Following this I run a tukey HSD to find comparison between treatments


Is this the correct approach ? any advice is greatly appreciated

Aside: I did try a more complicated model:
fit <- lme(y ~ Treatment*day,  random = ~1|block/day)
however none of the treatments were significant and it only showed that day
11 and day 8 were significantly different)



Many thanks

Etn

	[[alternative HTML version deleted]]


From Thierry.ONKELINX at inbo.be  Mon Sep 29 11:26:43 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 29 Sep 2014 09:26:43 +0000
Subject: [R-sig-ME] individual Linear mixed models
In-Reply-To: <CAJ0DVYySnrK2-Kz6cD=GxTiPnKZTYVVhzAk5z_TapUd3u5o6Fg@mail.gmail.com>
References: <CAJ0DVYySnrK2-Kz6cD=GxTiPnKZTYVVhzAk5z_TapUd3u5o6Fg@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3AF6A1B@inbomail.inbo.be>

Another option would be to fit the model lme(y ~ Treatment*Day,  random = ~1|block) and then use the multcomp package to test the contrasts that you are interested in. E.g. only pairwise difference between treatment within the same day. You'll need to specify those contrasts manually.

This model uses all available data to estimate the block effect.

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Etn
Verzonden: zondag 28 september 2014 17:42
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] individual Linear mixed models

Hi all,

I would be very grateful if you could please give any advice...
I am running a linear mixed model on a complete randomised block experiment

blocks = 11
treatments = 5 (A,B,C,D,E)
data recorded on days 1, 2, 11 and 18

I'm interested in looking at the difference between treatments on a particular day e.g. difference between treatments on day 1 (I am not interested in the difference between treatments on day 1 versus day 11 etc.)

My question is: Is it OK to run linear mixed regression models on each day individually? as I'm not concerned with the changes over time.....
(Results for individual days show a difference between treatments on day 1 and day 2, and no difference between treatments on day 11 and 18 - this follows with what would be expected in reality)

fit <- lme(y ~ Treatment,  random = ~1|block)

Following this I run a tukey HSD to find comparison between treatments


Is this the correct approach ? any advice is greatly appreciated

Aside: I did try a more complicated model:
fit <- lme(y ~ Treatment*day,  random = ~1|block/day) however none of the treatments were significant and it only showed that day
11 and day 8 were significantly different)



Many thanks

Etn

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From coanil at posteo.org  Mon Sep 29 13:03:38 2014
From: coanil at posteo.org (Michael Cone)
Date: Mon, 29 Sep 2014 13:03:38 +0200
Subject: [R-sig-ME]
 =?utf-8?q?How_can_I_estimate_deviance_explained_of_a_m?=
 =?utf-8?q?ixed_gamm=3F?=
In-Reply-To: <CAPypr8oWvzCq7u1o_5qXgfbm6pU0zrCfAfnRwkYjfokXjRWeEg@mail.gmail.com>
References: <CAPypr8oWvzCq7u1o_5qXgfbm6pU0zrCfAfnRwkYjfokXjRWeEg@mail.gmail.com>
Message-ID: <4eb0f7cbace96792aa5cc64f32a62b7e@posteo.de>

Hello Jon,

if I understand you correctly, you are looking for a metric like R^2 - 
"variation in the outcomes accounted for by the model". I don't have 
anything insightful to answer myself, but maybe this, by Douglas Bates, 
is relevant: 
http://marc.info/?l=r-sig-mixed-models&m=126719474831488&w=2

I quote:

"Assuming that one wants to define an R^2 measure, I think an argument
could be made for treating the penalized residual sum of squares from
a linear mixed model in the same way that we consider the residual sum
of squares from a linear model.  Or one could use just the residual
sum of squares without the penalty or the minimum residual sum of
squares obtainable from a given set of terms, which corresponds to an
infinite precision matrix.  I don't know, really.  It depends on what
you are trying to characterize.

In other words, what's the purpose?  What aspect of the R^2 for a
linear model are you trying to generalize?

I'm sorry if I sound argumentative but discussions like this sometimes
frustrate me.  A linear mixed model does not behave exactly like a
linear model without random effects so a measure that may be
appropriate for the linear model does not necessarily generalize.  I'm
not saying that this is the case but if the request is "I don't care
what the number means or if indeed it means anything at all, just give
me a number I can report", that's not the style of statistics I
practice.

I regard Bill Venables' wonderful unpublished paper "Exegeses on
Linear Models" (just put the name in a search engine to find a copy -
there is only one paper with "Exegeses" and "Linear Models" in the
title) as required reading for statisticians.  As Bill emphasizes in
that paper, statistics is not just a collection of formulas (many of
which are based on approximations).  It's about models and comparing
how well different models fit the observed data.  If we start with a
formula and only ask ourselves "How do we generalize this formula?"
we're missing the point.  We should start at the model.

In a linear model the R^2 statistic is a dimensionless comparison of
the quality of the current model fit, as measured by the residual sum
of squares, to the fit one would obtain from a trivial model.  When
the current model can be shown to contain a model with an intercept
term only (and whose coefficient will be estimated by the mean
response) then that model fit is the trivial model.  Otherwise the
trivial model is a prediction of zero for each response.  We know that
the trivial model will produce a greater residual sum of squares than
the current model fit because the models are nested.  The R^2 is the
proportion of variability not accounted for by the trivial model but
accounted for by the current model (my apologies to my grammar
teachers for having juxtaposed prepositions).

The interesting point there is that when you think of the
relationships between models you can determine how you handle the case
of a model that does not have an intercept term.  If you start from
the formula instead you can end up calculating a negative R^2 because
you compare models that are not nested.  Such nonsensical results are
often reported.  (I think it was the Mathematica documentation that
gave a careful explanation of why you get a negative R^2 instead of
recognizing that the formula they were using did not apply in certain
cases.)

It may be that there is a sensible measure of the quality of fit from
a linear mixed model that generalizes the R^2 from a linear model.  I
don't see an obvious candidate but I will freely admit that I haven't
thought much about the problem.  I would ask others who are thinking
about this to consider both the "what" and the "why".  George
Mallory's justification of "because it's there" for attempting to
climb Everest is perhaps a good justification for such endeavors
(Mallory may have questioned his rationale as he lay freezing to death
on the mountain).  I don't think it is a good justification for
manipulating formulas."

Best regards,
Michael

On 27.09.2014 19:35, Jon Lopez wrote:
> Dear mixed modelers,
> 
> I have already asked about this issue but never recived an answer
> back. So I will try again.
> I have been modelling fish biomass according to some environmental
> parameters using mixed
> effect models (gamm4 package). I don't want to bore you with the
> details of my models since
> I believe that they are not significant to the point of this message.
> However, please feel
> free to ask me about anything in case you think it is important. I
> have some GAMM
> candidates already. I am able to get AIC, BIC, R-sq, ... scores for
> these models but,
> unfortunately, I can't obtain deviance explained from them.
> 
> I have found an interesting procedure to try to derive it, published by
> Gilman and colleagues in 2012. Here is the complete reference in case 
> any
> of you want to take a look to it:
> 
> "Gilman, E., Chaloupka, M., Read, A., Dalzell, P., Holetschek, J., 
> Curtice,
> C., 2012. Hawaii longline tuna fishery temporal trends in standardized
> catch rates and length distributions and effects on pelagic and 
> seamount
> ecosystems. Aquatic Conservation: Marine and Freshwater Ecosystems 
> 22(4),
> 446-488."
> 
> Nevertheless, the procedure explained in the paper above do not provide 
> us
> with the exact score. Thus, I have been considering other options like
> using the deviance explained of a equivalent GAM with the random effect 
> as
> a spline term [s(x, bs="re")] but I don't know how accurate it would 
> be.
> 
> Do you think both options can be used as an approximation for the
> GAMM's deviance
> explained? What are your feelings on that?
> 
> Any suggestion would be appreciated,
> 
> Thousands of thanks,
> 
> Jon Lopez
> 
> ---------------------------------
> PhD candidate
> AZTI-Tecnalia, Spain
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From 2nuzzbot at gmail.com  Mon Sep 29 13:17:46 2014
From: 2nuzzbot at gmail.com (Etn)
Date: Mon, 29 Sep 2014 12:17:46 +0100
Subject: [R-sig-ME] individual Linear mixed models
In-Reply-To: <AA818EAD2576BC488B4F623941DA7427F3AF6A1B@inbomail.inbo.be>
References: <CAJ0DVYySnrK2-Kz6cD=GxTiPnKZTYVVhzAk5z_TapUd3u5o6Fg@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA7427F3AF6A1B@inbomail.inbo.be>
Message-ID: <CAJ0DVYzVBuFi-+7zp7OLhm=n3ZO-xA8BOJ-HkAFCV6srmrMFmQ@mail.gmail.com>

Thank you very much, your answer is greatly appreciated

On Mon, Sep 29, 2014 at 10:26 AM, ONKELINX, Thierry <
Thierry.ONKELINX at inbo.be> wrote:

> Another option would be to fit the model lme(y ~ Treatment*Day,  random =
> ~1|block) and then use the multcomp package to test the contrasts that you
> are interested in. E.g. only pairwise difference between treatment within
> the same day. You'll need to specify those contrasts manually.
>
> This model uses all available data to estimate the block effect.
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> + 32 2 525 02 51
> + 32 54 43 61 85
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org [mailto:
> r-sig-mixed-models-bounces at r-project.org] Namens Etn
> Verzonden: zondag 28 september 2014 17:42
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] individual Linear mixed models
>
> Hi all,
>
> I would be very grateful if you could please give any advice...
> I am running a linear mixed model on a complete randomised block experiment
>
> blocks = 11
> treatments = 5 (A,B,C,D,E)
> data recorded on days 1, 2, 11 and 18
>
> I'm interested in looking at the difference between treatments on a
> particular day e.g. difference between treatments on day 1 (I am not
> interested in the difference between treatments on day 1 versus day 11 etc.)
>
> My question is: Is it OK to run linear mixed regression models on each day
> individually? as I'm not concerned with the changes over time.....
> (Results for individual days show a difference between treatments on day 1
> and day 2, and no difference between treatments on day 11 and 18 - this
> follows with what would be expected in reality)
>
> fit <- lme(y ~ Treatment,  random = ~1|block)
>
> Following this I run a tukey HSD to find comparison between treatments
>
>
> Is this the correct approach ? any advice is greatly appreciated
>
> Aside: I did try a more complicated model:
> fit <- lme(y ~ Treatment*day,  random = ~1|block/day) however none of the
> treatments were significant and it only showed that day
> 11 and day 8 were significantly different)
>
>
>
> Many thanks
>
> Etn
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> * * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
> Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver
> weer en binden het INBO onder geen enkel beding, zolang dit bericht niet
> bevestigd is door een geldig ondertekend document.
> The views expressed in this message and any annex are purely those of the
> writer and may not be regarded as stating an official position of INBO, as
> long as the message is not confirmed by a duly signed document.
>

	[[alternative HTML version deleted]]


From Farrar.David at epa.gov  Tue Sep 30 17:18:01 2014
From: Farrar.David at epa.gov (Farrar, David)
Date: Tue, 30 Sep 2014 15:18:01 +0000
Subject: [R-sig-ME] sums of squares and F values in anova
In-Reply-To: <web-528500534@cgpsrv2.cis.mcmaster.ca>
References: <0566E17B6DEC62459078112371B7508E1D90CE@ait-pex02mbx05.win.dtu.dk>
	<54233437.9060101@gmail.com> <web-528500534@cgpsrv2.cis.mcmaster.ca>
Message-ID: <f107089d88e94a59ae6b1e24d6c742ef@BY1PR09MB0392.namprd09.prod.outlook.com>


John,

Regarding K-R etc. it's good to know that I can get up-to-date statistical tests on lmer() output.  I can use this in a current analysis.  For a literature citation, I can say that statistical tests were conducted using the car package.  However, current documentation indicates that Anova can be used with lmer(), and that pbkrtest is recommended along with car.  One may therefore infer what is likely going on.  It might be good to see a more direct statement in ?Anova.  

Any thoughts about literature citation?  

fwiw I'm a fan of car and the associated text.

I may also do some parametric bootstrapping. 

David Farrar, 

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of John Fox
Sent: Wednesday, September 24, 2014 6:04 PM
To: Ben Bolker
Cc: r-sig-mixed-models at r-project.org; Alexandra Kuznetsova
Subject: Re: [R-sig-ME] sums of squares and F values in anova

Dear Ben,

anova() computes sequential ("type I") tests, so one wouldn't for correlated Xs expect the result to be the same as the "type II" or "type III" tests computed by Anova(), which, however, for an additive model should be the same as each other. You *would* expect the last test in the sequence produced by anova() to be the same as the corresponding type-II or -III test. 

In the case of LMMs fit by lmer(), Anova() computes Wald F-tests using the Kenward-Roger coefficient covariance matrix and Satterthwaite df; for the data/model in your example, that should produce a small difference in the F-statistics.

Here's what I get for your example:

------------- snip ----------

> anova(fit)
Analysis of Variance Table

Response: sr
          Df Sum Sq Mean Sq F value    Pr(>F)    
pop15      1 204.12 204.118 14.1157 0.0004922 ***
pop75      1  53.34  53.343  3.6889 0.0611255 .  
dpi        1  12.40  12.401  0.8576 0.3593551    
ddpi       1  63.05  63.054  4.3605 0.0424711 *  
Residuals 45 650.71  14.460                      
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

> anova(fit2) ## practically equal to anova(fit) above
Analysis of Variance Table
      Df  Sum Sq Mean Sq F value
pop15  1 204.118 204.118 14.1157
pop75  1  53.343  53.343  3.6889
dpi    1  12.401  12.401  0.8576
ddpi   1  63.054  63.054  4.3605


> Anova(fit)
Anova Table (Type II tests)

Response: sr
          Sum Sq Df F value   Pr(>F)   
pop15     147.01  1 10.1666 0.002603 **
pop75      35.24  1  2.4367 0.125530   
dpi         1.89  1  0.1309 0.719173   
ddpi       63.05  1  4.3605 0.042471 * 
Residuals 650.71 45
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1  

> Anova(fit, type=3)
Anova Table (Type III tests)

Response: sr
            Sum Sq Df F value    Pr(>F)    
(Intercept) 218.16  1 15.0867 0.0003338 ***
pop15       147.01  1 10.1666 0.0026030 ** 
pop75        35.24  1  2.4367 0.1255298    
dpi           1.89  1  0.1309 0.7191732    
ddpi         63.05  1  4.3605 0.0424711 *  
Residuals   650.71 45                      
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

> Anova(fit2)
Analysis of Deviance Table (Type II Wald chisquare tests)

Response: sr
        Chisq Df Pr(>Chisq)   
pop15 10.1666  1    0.00143 **
pop75  2.4367  1    0.11852   
dpi    0.1309  1    0.71748   
ddpi   4.3605  1    0.03678 * 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

> Anova(fit2, test="F")
Loading required package: pbkrtest
Loading required package: MASS
Analysis of Deviance Table (Type II Wald F tests with Kenward-Roger df)

Response: sr
            F Df Df.res  Pr(>F)   
pop15 10.1519  1 44.031 0.00265 **
pop75  2.4326  1 44.036 0.12599   
dpi    0.1245  1 44.811 0.72588   
ddpi   4.2179  1 44.600 0.04589 * 
---                  
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

> Anova(fit2, test="F", type=3)
Analysis of Deviance Table (Type III Wald F tests with Kenward-Roger df)

Response: sr
                  F Df Df.res    Pr(>F)    
(Intercept) 14.9643  1 44.560 0.0003538 ***
pop15       10.1519  1 44.031 0.0026503 ** 
pop75        2.4326  1 44.036 0.1259919    
dpi          0.1245  1 44.811 0.7258840    
ddpi         4.2179  1 44.600 0.0458898 *  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

----------------- snip ----------

These results are as expected.

Best,
 John

On Wed, 24 Sep 2014 17:14:31 -0400
 Ben Bolker <bbolker at gmail.com> wrote:
> On 14-09-24 04:21 PM, Alexandra Kuznetsova wrote:
> > Dear lme4 authors,
> > 
> > I have a question regarding the calculation of sums of squares in 
> > anova for lmerMod object. I know that there were some discussions 
> > regarding how they are calculated (but still remains unclear to 
> > me..).
> > 
> > As far as I understand the way they are calculated is similar to the 
> > way they are calculated in lm objects, that is transforming Y into 
> > orthogonal Q space, and then computing sums of squares for the 
> > independent effects.
> > 
> > I have found in your  JSS paper "Fitting linear mixed effects models 
> > using lme4" some explanations (in equations 67 and 68). Would it be 
> > possible to give some more comments on these equations? And what 
> > about the partial (type 3) sums of squares -  is there a way to 
> > calculate them using the same way?
> > 
> > Hope my questions were clear! Thank you in advance!
> 
>   I'm not sure exactly what your questions are.  Could you please 
> clarify (sorry!) what you mean about partial sums of squares?  Here's 
> an example showing that the results of lme4's anova.merMod and base R's:
> anova.lm do in fact agree for a model with the random effects variance 
> forced to (almost) zero.  At the risk of further muddying the water, 
> I'll point out that car::Anova(fit,type="II") and
> car::Anova(fit,type="III") give two different answers for this 
> problem, neither of which matches the computation below ...
> 
> ===================
> fit <- lm(sr ~ ., data = LifeCycleSavings)
> anova(fit)
> 
> 
> ## construct lmer model with near-zero variance
> LC2 <- transform(LifeCycleSavings,f=factor(1:2)) ## bogus
> library("lme4")
> form <- sr ~ pop15 + pop75 + dpi + ddpi + (1|f)  ## hack ## to avoid 
> (Error in terms.formula(formula(x, fixed.only = TRUE)) :
> ##   '.' in formula and no 'data' argument)
> 
> lmod <- lFormula(form, data=LC2)
> d2 <- lmer(form, data=LC2,devFunOnly=TRUE) llik <- d2(1e-5)
> fit2 <- mkMerMod(environment(d2),opt=list(par=1e-5,
>                            fval=llik,
>                            feval=1,
>                            conv=0,
>                            message=NULL),
>                          lmod$reTrms, fr = lmod$fr)
> all.equal(coef(fit),fixef(fit2))
> anova(fit2)   ## practically equal to anova(fit) above
> ==================
> 
> For those following along, the paper is at
> http://arxiv.org/abs/1406.5823 (or http://arxiv.org/pdf/1406.5823v1 
> for a direct link to the PDF), and the raw LaTeX for the specific section is:
> 
> ===============
> To understand how these quantities are computed, let $\bm R_i$ contain 
> the rows of $\bm R_X$ (Equation~\ref{eq:blockCholeskyDecomp}) 
> associated with the $i$th fixed-effects term.  Then the sum of squares 
> for term $i$ is, \begin{equation}
>   \label{eq:SS}
>   SS_i = \widehat{\bm\beta}\trans\bm R_i\trans \bm R_i 
> \widehat{\bm\beta} \end{equation} If $DF_i$ is the number of columns 
> in $\bm R_i$, then the $F$~statistic for term $i$ is, \begin{equation}
>   \label{eq:Fstat}
>   F_i = \frac{SS_i}{\widehat{\sigma}^2 DF_i} \end{equation}
> 
> 
> > 
> > Alexandra Kuznetsova _______________________________________________ 
> > R-sig-mixed-models at r-project.org mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From highstat at highstat.com  Tue Sep 30 18:39:55 2014
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Tue, 30 Sep 2014 17:39:55 +0100
Subject: [R-sig-ME] Course Halifax: Introduction to Linear mixed effects
 models, GLMM and MCMC with R
Message-ID: <542ADCDB.5030101@highstat.com>

Apologies for cross-posting


We would like to announce the following statistics course:

Course:   Introduction to Linear mixed effects models,  GLMM and MCMC 
with R
Location: Halifax, Canada
Date:      19 - 23 January 2015
Remaining seats: 10

Course website: http://www.highstat.com/statscourse.htm
Course flyer: http://www.highstat.com/Courses/Flyer2015_01Halifax.pdf


Kind regards,

Alain Zuur


-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL: www.highstat.com


	[[alternative HTML version deleted]]


From zxuiowa at iastate.edu  Mon Sep 29 23:19:26 2014
From: zxuiowa at iastate.edu (Zhanyou Xu)
Date: Mon, 29 Sep 2014 16:19:26 -0500
Subject: [R-sig-ME] Fwd: [Lme4-authors] LME4 and Lmer model
In-Reply-To: <5429AD74.8060604@gmail.com>
References: <A8B4A7C261862C4F9D1173A948685588100EE3BBAC@USETCMSXMB03.NAFTA.SYNGENTA.ORG>
	<5429AD74.8060604@gmail.com>
Message-ID: <CAExDaCLyi+ARZpvX4S_GmYpzopKxCJryuB2BJBk2FT2Gj2qMNw@mail.gmail.com>

 Dear Sir/Madam,

We are running lmer to calculate Best Linear Unbiased prediction (BLUP),
and we have 10 groups of data, each group has groupID and 42 individual.
We want to get BLUP values for each individual material within each
group. In SAS, there is a BY statement and we can get BLUP value for
each individuals within a group. We are wondering whether there is a
similar R code that we can calculate the BLUPs for each group similar
like BY statement in SAS? Below is the R code we pare testing for your
reference. Thank you very much in advance!

Zhanyou



---------- Forwarded message ----------
From: Ben Bolker <bbolker at gmail.com>
Date: Mon, Sep 29, 2014 at 2:05 PM
Subject: Re: [Lme4-authors] LME4 and Lmer model
To: zhanyou.xu at syngenta.com,
"lme4-authors at lists.r-forge.r-project.org"
<lme4-authors at lists.r-forge.r-project.org>,
marcia.almeida_de_macedo at syngenta.com, zxuiowa at iastate.edu,
lme4-authors at r-forge.wu-wien.ac.at


On 14-09-29 11:30 AM, zhanyou.xu at syngenta.com wrote:
> Dear Ben and all LME4 authors,
>
> We are running lmer to calculate Best Linear Unbiased prediction (BLUP),
> and we have 10 groups of data, each group has groupID and 42 individual.
> We want to get BLUP values for each individual material within each
> group. In SAS, there is a BY statement and we can get BLUP value for
> each individuals within a group. We are wondering whether there is a
> similar R code that we can calculate the BLUPs for each group similar
> like by statement in SAS? Below is the R code we pare testing for your
> reference. Thank you very much in advance!
>


    Take a look at ranef() and coef().  If you have further questions,
could you please send them to r-sig-mixed-models at r-project.org ?

  I can believe that "%in%" works as a nesting indicator, but it is more
typical/I am more familiar with REPNO:HOSEID ...  (I'm also curious why
you need to ignore the greater-than-1-level check ...)

  thanks
   Ben Bolker


>
> Zhanyou
>
>
>
>
>
> Milkvarcomp =  lmer(YGSMN~ (1|ANIMALID) + (1|HOSEID) +
> (1|REPNO%in%HOSEID) + (1|MINRNG%in%HOSEID) +
>
>                 (1|MINROW%in%HOSEID)+
> (1|ANIMALID:HOSEID),control=lmerControl(check.nlev.gtr.1="ignore"),
> data=Stage3Data)
>
>
> ------------------------------------------------------------------------
> /This message may contain confidential information. If you are not the
> designated recipient, please notify the sender immediately, and delete
> the original and any copies. Any use of the message by you is prohibited./
>
>
> _______________________________________________
> Lme4-authors mailing list
> Lme4-authors at lists.r-forge.r-project.org
> https://lists.r-forge.r-project.org/cgi-bin/mailman/listinfo/lme4-authors
>


