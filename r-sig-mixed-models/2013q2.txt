From bbolker at gmail.com  Tue Apr  2 09:01:15 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 02 Apr 2013 03:01:15 -0400
Subject: [R-sig-ME] Newest lme4 package?
In-Reply-To: <CAGLqYw3fp7jDwkr5QLG_x4vc51=O_ggAka=wHnaW+yp7uXvgZA@mail.gmail.com>
References: <18021_1364583390_r2TIuTh5012792_CAGLqYw35LDa3a9MUCpTPO5EOX9Ua5UshBKKfzcNbo0uD+bQFzA@mail.gmail.com>
	<51566590.4050803@mcmaster.ca>
	<CAGLqYw3fp7jDwkr5QLG_x4vc51=O_ggAka=wHnaW+yp7uXvgZA@mail.gmail.com>
Message-ID: <515A823B.20102@gmail.com>

On 13-04-01 05:43 PM, Kimberly Brewitt wrote:
> Hi Ben,
> 
> I was able to install RCppEigen, but I got an error when trying to
> install lme4 through R-forge with the code you sent, perhaps due to
> the version of R I have. Which version will this package run with (on
> a mac). Here's the warning message I got:
> 
> Warning: unable to access index for repository
> http://lme4.r-forge.r-project.org/bin/macosx/leopard/contrib/2.15
> Warning message:
> package ?lme4? is not available (for R version 2.15.3)
> 
> Thanks,
> Kim
> 
> 

 [snip]

>>
>>   If you do
>>
>> install.packages("lme4",repos="http://lme4.r-forge.r-project.org")
>>
>> you should get the development version that has profiling.  You may
>> have to
>>
>> install.packages("RcppEigen")
>>
>> first to install dependencies ...
>>   Let me know if that works.
>>
>>  Ben Bolker

  Oops, that should be

install.packages("lme4",repos="http://lme4.r-forge.r-project.org/repos")

[cc'ing to r-sig-mixed-models]


From baud-bovy.gabriel at hsr.it  Tue Apr  2 22:52:34 2013
From: baud-bovy.gabriel at hsr.it (Gabriel Baud-Bovy)
Date: Tue, 02 Apr 2013 22:52:34 +0200
Subject: [R-sig-ME] lmer and semi-definite covariance matrices for random
	effects
Message-ID: <515B4512.5060900@hsr.it>

Dear all,

I am trying to use pedigreemm approach to analyze twin data. The model
includes semidefinite covariance matrices for random effects of the
form  sigma*corA

where corA is semi-definite. In this example,

      [,1] [,2] [,3] [,4]
[1,]    1    1  0.0  0.0
[2,]    1    1  0.0  0.0
[3,]    0    0  1.0  0.5
[4,]    0    0  0.5  1.0

the two blocks represent the covariance structure for the additive 
genetic component
of a monozygote and dizygote pairs of twins respectively. A real example 
might involve
1000 pairs. In this case, this matrix would be 2000 x 2000 and coded as 
a sparse
symmetric matrix ("dsCMatrix").

I have seen that covariance matrices can given to lmer using the 
pedigreemm:::ZStar
function. I found an  example with positive definite matrices here :

http://dysci.wisc.edu/sglpge/posters/Using%20the%20R%20package%20pedigreemm%20for%20traditional%20and%20marker-based%20genetic%20evaluations%20-%20An%20application%20to%20a%20wheat%20population%20-%20Vazquez.pdf

The problem is that ZStar requires the Cholesky factor of corA and, if I 
am nost mistaken, the chol
function in the Matrix package deals only with positive definite matrices.

My questions are

1) can lmer deal with semi-definite covariance matrix for the random 
effects ?

2) how can compute the required Cholesky decomposition for a 
semi-definite symmetric
and sparse matrix ?

One reason I am asking the first question is that D. Bates wrote in the 
vignette (PLS versus GLS)
that it is important to allow for a positive semidefinite covariance 
matrix of the random effects and
the implementation vignette says also that this covariance matrix is 
positive semidefinite (p. 3).
However,  in another older document (MixedEffects.pdf) from 2004, I see 
a mention that these matrices
are restricted to being positive definite and, I also do find obvious 
way of compute the Cholesky
factor of a positive semidefinite matrix.

http://cran.r-project.org/web/packages/lme4/vignettes/PLSvGLS.pdf
http://cran.r-project.org/web/packages/lme4/vignettes/Implementation.pdf
http://pages.cs.wisc.edu/~bates/reports/MixedEffects.pdf

Thank you,

Gabriel

P.S. I found that I could specify my model with the regress function 
(regress package)
but it does not work well with large dataset because it uses dense 
matrices. I
also tried with the lmekin (package coxme) but it gives an error message 
because
the matrix is not positive definite.


-- 
---------------------------------------------------------------------
Gabriel Baud-Bovy               tel.: (+39) 02 2643 4839 (office)
UHSR University                       (+39) 02 2643 3429 (laboratory)
via Olgettina, 58                     (+39) 02 2643 4891 (secretary)
20132 Milan, Italy               fax: (+39) 02 2643 4892


From David.Duffy at qimr.edu.au  Wed Apr  3 09:35:00 2013
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Wed, 3 Apr 2013 17:35:00 +1000
Subject: [R-sig-ME] lmer and semi-definite covariance matrices for
 randomeffects
In-Reply-To: <515B4512.5060900@hsr.it>
References: <515B4512.5060900@hsr.it>
Message-ID: <alpine.LMD.2.00.1304031732310.20922@orpheus.qimr.edu.au>

On Wed, 3 Apr 2013, Gabriel Baud-Bovy wrote:

> Dear all,
>
> I am trying to use pedigreemm approach to analyze twin data. The model
> includes semidefinite covariance matrices for random effects of the
> form  sigma*corA

Not completely satisfactory, but we just added a ridge constant.

| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v


From i.m.s.white at ed.ac.uk  Wed Apr  3 13:57:01 2013
From: i.m.s.white at ed.ac.uk (i white)
Date: Wed, 03 Apr 2013 12:57:01 +0100
Subject: [R-sig-ME] lmer and semi-definite covariance matrices for
 random effects
In-Reply-To: <515B4512.5060900@hsr.it>
References: <515B4512.5060900@hsr.it>
Message-ID: <515C190D.9070804@ed.ac.uk>

Another possibility might be (e.g.) to treat observations on monozygotic 
twins as repeated measurements on the same individual. This reduces the 
effective number of individuals and the size of the genetic covariance 
matrix. This smaller matrix should be positive definite.

On 04/02/2013 09:52 PM, Gabriel Baud-Bovy wrote:
> Dear all,
>
> I am trying to use pedigreemm approach to analyze twin data. The model
> includes semidefinite covariance matrices for random effects of the
> form  sigma*corA
>
> where corA is semi-definite. In this example,
>
>       [,1] [,2] [,3] [,4]
> [1,]    1    1  0.0  0.0
> [2,]    1    1  0.0  0.0
> [3,]    0    0  1.0  0.5
> [4,]    0    0  0.5  1.0
>
> the two blocks represent the covariance structure for the additive
> genetic component
> of a monozygote and dizygote pairs of twins respectively. A real example
> might involve
> 1000 pairs. In this case, this matrix would be 2000 x 2000 and coded as
> a sparse
> symmetric matrix ("dsCMatrix").
>
> I have seen that covariance matrices can given to lmer using the
> pedigreemm:::ZStar
> function. I found an  example with positive definite matrices here :
>
> http://dysci.wisc.edu/sglpge/posters/Using%20the%20R%20package%20pedigreemm%20for%20traditional%20and%20marker-based%20genetic%20evaluations%20-%20An%20application%20to%20a%20wheat%20population%20-%20Vazquez.pdf
>
>
> The problem is that ZStar requires the Cholesky factor of corA and, if I
> am nost mistaken, the chol
> function in the Matrix package deals only with positive definite matrices.
>
> My questions are
>
> 1) can lmer deal with semi-definite covariance matrix for the random
> effects ?
>
> 2) how can compute the required Cholesky decomposition for a
> semi-definite symmetric
> and sparse matrix ?
>
> One reason I am asking the first question is that D. Bates wrote in the
> vignette (PLS versus GLS)
> that it is important to allow for a positive semidefinite covariance
> matrix of the random effects and
> the implementation vignette says also that this covariance matrix is
> positive semidefinite (p. 3).
> However,  in another older document (MixedEffects.pdf) from 2004, I see
> a mention that these matrices
> are restricted to being positive definite and, I also do find obvious
> way of compute the Cholesky
> factor of a positive semidefinite matrix.
>
> http://cran.r-project.org/web/packages/lme4/vignettes/PLSvGLS.pdf
> http://cran.r-project.org/web/packages/lme4/vignettes/Implementation.pdf
> http://pages.cs.wisc.edu/~bates/reports/MixedEffects.pdf
>
> Thank you,
>
> Gabriel
>
> P.S. I found that I could specify my model with the regress function
> (regress package)
> but it does not work well with large dataset because it uses dense
> matrices. I
> also tried with the lmekin (package coxme) but it gives an error message
> because
> the matrix is not positive definite.
>
>

-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From ludovicofrate at hotmail.it  Wed Apr  3 16:28:25 2013
From: ludovicofrate at hotmail.it (Ludovico Frate)
Date: Wed, 3 Apr 2013 16:28:25 +0200
Subject: [R-sig-ME] longitudinal data/repeated measure
Message-ID: <DUB105-W570A8238CEB68C80694045D6D80@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130403/90f59b14/attachment.pl>

From zacksteel at gmail.com  Wed Apr  3 21:58:46 2013
From: zacksteel at gmail.com (Zack Steel)
Date: Wed, 3 Apr 2013 12:58:46 -0700
Subject: [R-sig-ME] Low intercept estimate in a binomial glmm
Message-ID: <CAG+hMtm+gDomkSXW4th4_b6X-e0=mJVFT6VsH93bsARC74rnEQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130403/32628bed/attachment.pl>

From j.hadfield at ed.ac.uk  Wed Apr  3 22:16:45 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 03 Apr 2013 21:16:45 +0100
Subject: [R-sig-ME] Low intercept estimate in a binomial glmm
In-Reply-To: <CAG+hMtm+gDomkSXW4th4_b6X-e0=mJVFT6VsH93bsARC74rnEQ@mail.gmail.com>
References: <CAG+hMtm+gDomkSXW4th4_b6X-e0=mJVFT6VsH93bsARC74rnEQ@mail.gmail.com>
Message-ID: <20130403211645.434179gcanzz5m4o@www.staffmail.ed.ac.uk>

Hi,

plogis(-2.3776295) is the mode not the mean.

An approximation for the mean is:

c2<-((16*sqrt(3))/(15*pi))^2

plogis(-2.3776295/sqrt(1+c2*4.6432))

and this should be closer to the observed mean.

Cheers,

Jarrod



Quoting Zack Steel <zacksteel at gmail.com> on Wed, 3 Apr 2013 12:58:46 -0700:

> Hello all,
>
> I am running a glmer using the lme4 package and the binomial family and am
> getting somewhat unexpected results, which I'm hoping someone can help me
> make sense of. My data look something like the following:
>
> id        group      successes   total         fe1_center     fe2_center
> 1713    A              0                  11          -0.0911       -17.2868
> 1717    A              0                  155        -0.0911       -17.2886
> 2272    B              49                 49          -0.0911      -32.2868
> 2289    B              7                   22          -0.2416      -32.2868
> 1487    B              0                   20          0.0537        2.7132
> 8199    C              10                127        -0.2416       -59.2868
> .....
>
> Where my response variable is the proportional of successes. I have
> centered the two fixed effects variables to alleviate some problems of
> multicollinearity and am also interested in their interaction. The data are
> clustered spatially within groups so I am using group as a random/grouping
> variable. When running the glmm, the coefficients of the fixed effects and
> their interaction seem reasonable (see below). However, when plotting the
> predictions vs. the response the curve is consistently lower than i would
> expect. E.g., the predicted proportion is lower than the mean proportion of
> the data across the full range of data.
>
> #running the model
> resp = cbind(data$successes, (data$total - data$successes))
> model = glmer( resp ~ fe1_c * fe2_c + (1|group) ,
>              data=data, family = binomial, REML=F)
> summary(model)
>
>
> Random effects:
>  Groups Name            Variance   Std.Dev.
>  group  (Intercept)       4.6432      2.1548
> Number of obs: 12271, groups: group, 392
>
> Fixed effects:
>                                       Estimate Std. Error              z
> value    Pr(>|z|)
> (Intercept)                      -2.3776295    0.1112830     -21.37
> <2e-16 ***
> fe1_c                             -0.8771395    0.0362946     -24.17
> <2e-16 ***
> fe2_c                              0.0109161    0.0001074      101.65
> <2e-16 ***
> fe1_c:fe2_c                   -0.0528655    0.0010090     -52.39     <2e-16
> ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>                      (Intr)     fe1_c    fe2_c
> fe1_c            -0.012
> fe2_c             0.000  -0.687
> fe1_c:fe2_c  -0.022   0.411   -0.071
>
> I suspect my problem has something to do with how the "average" intercept
> is estimated (-2.378). Since I have centered my predictor variables I would
> expect the intercept to be equal to the grand mean (is this a correct
> assumption?), but in fact it is quite a bit lower.
>
> mean(data$successes/data$total)   # equal to 0.2008
> logistic (-2.3776295)                        # equal to 0.0849
>
> Perhaps the model is weighting the unique group intercepts differently
> leading to something other than a true average intercept? My group sizes
> vary greatly (data comes from messy observations, not experiments) so could
> this be affecting the estimate?
>
> Any incite you could give me would be much appreciated. Thank you for the
> help.
> Zack
>
>
> --
> Zack Steel
> Landscape Ecologist
> University of California, Davis
> zacksteel at gmail.com
>
> 	[[alternative HTML version deleted]]
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From lborger at cebc.cnrs.fr  Wed Apr  3 22:58:04 2013
From: lborger at cebc.cnrs.fr (lborger)
Date: Wed, 03 Apr 2013 22:58:04 +0200
Subject: [R-sig-ME] Low intercept estimate in a binomial glmm
In-Reply-To: <20130403211645.434179gcanzz5m4o@www.staffmail.ed.ac.uk>
References: <CAG+hMtm+gDomkSXW4th4_b6X-e0=mJVFT6VsH93bsARC74rnEQ@mail.gmail.com>
	<20130403211645.434179gcanzz5m4o@www.staffmail.ed.ac.uk>
Message-ID: <WC20130403205804.9100F5@cebc.cnrs.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130403/10801dd7/attachment.pl>

From j.hadfield at ed.ac.uk  Wed Apr  3 23:25:15 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 03 Apr 2013 22:25:15 +0100
Subject: [R-sig-ME] Low intercept estimate in a binomial glmm
In-Reply-To: <WC20130403205804.9100F5@cebc.cnrs.fr>
References: <CAG+hMtm+gDomkSXW4th4_b6X-e0=mJVFT6VsH93bsARC74rnEQ@mail.gmail.com>
	<20130403211645.434179gcanzz5m4o@www.staffmail.ed.ac.uk>
	<WC20130403205804.9100F5@cebc.cnrs.fr>
Message-ID: <20130403222515.86813sqxmxzwdso4@www.staffmail.ed.ac.uk>

Hi,

I think the Diggle approximation is more accurate:

sd<-seq(0,4,length=100)
x<-(-2.3776295)

Emu<-sapply(sd, function(sd){mean(plogis(rnorm(10000, x,sd)))})

plot(Emu~sd) # simulated expectations

c2<-((16*sqrt(3))/(15*pi))^2

lines(plogis(x/sqrt(1+c2*sd^2))~sd, col="red")
lines(plogis(x+0.5*sd)~sd, col="blue")

# approximations for the expectation

Cheers,

Jarrod



Quoting lborger <lborger at cebc.cnrs.fr> on Wed, 03 Apr 2013 22:58:04 +0200:

> Hello,
>
> you could also simply add 0.5*2.1548 - i.e. the estimated sd of the random
> effect divided by two (or sum of those if more than one random effect). It
> ends up being nearly equally distant from the mean as with Jarrods formula,
> only slightly larger instead of smaller:
>
> plogis(-2.3776295+0.5*2.1548)
> [1] 0.2141264
>
> Happy to be told otherwise, in case this is not a generally appropriate
> solution!
>
>
> Cheers,
> Luca
>
> -----Original Message-----
> From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
> To: Zack Steel <zacksteel at gmail.com>
> Cc: r-sig-mixed-models at r-project.org
> Date: Wed, 03 Apr 2013 21:16:45 +0100
> Subject: Re: [R-sig-ME] Low intercept estimate in a binomial glmm
>
>
> Hi,
>
> plogis(-2.3776295) is the mode not the mean.
>
> An approximation for the mean is:
>
> c2<-((16*sqrt(3))/(15*pi))^2
>
> plogis(-2.3776295/sqrt(1+c2*4.6432))
>
> and this should be closer to the observed mean.
>
> Cheers,
>
> Jarrod
>
>
>
> Quoting Zack Steel <zacksteel at gmail.com> on Wed, 3 Apr 2013 12:58:46 -0700:
>
>> Hello all,
>>
>> I am running a glmer using the lme4 package and the binomial family and am
>> getting somewhat unexpected results, which I'm hoping someone can help me
>> make sense of. My data look something like the following:
>>
>> id        group      successes   total         fe1_center     fe2_center
>> 1713    A              0                  11          -0.0911
> -17.2868
>> 1717    A              0                  155        -0.0911
> -17.2886
>> 2272    B              49                 49          -0.0911
> -32.2868
>> 2289    B              7                   22          -0.2416
> -32.2868
>> 1487    B              0                   20          0.0537
> 2.7132
>> 8199    C              10                127        -0.2416       -59.2868
>> .....
>>
>> Where my response variable is the proportional of successes. I have
>> centered the two fixed effects variables to alleviate some problems of
>> multicollinearity and am also interested in their interaction. The data
> are
>> clustered spatially within groups so I am using group as a random/grouping
>> variable. When running the glmm, the coefficients of the fixed effects and
>> their interaction seem reasonable (see below). However, when plotting the
>> predictions vs. the response the curve is consistently lower than i would
>> expect. E.g., the predicted proportion is lower than the mean proportion
> of
>> the data across the full range of data.
>>
>> #running the model
>> resp = cbind(data$successes, (data$total - data$successes))
>> model = glmer( resp ~ fe1_c * fe2_c + (1|group) ,
>>              data=data, family = binomial, REML=F)
>> summary(model)
>>
>>
>> Random effects:
>>  Groups Name            Variance   Std.Dev.
>>  group  (Intercept)       4.6432      2.1548
>> Number of obs: 12271, groups: group, 392
>>
>> Fixed effects:
>>                                       Estimate Std. Error              z
>> value    Pr(>|z|)
>> (Intercept)                      -2.3776295    0.1112830     -21.37
>> <2e-16 ***
>> fe1_c                             -0.8771395    0.0362946     -24.17
>> <2e-16 ***
>> fe2_c                              0.0109161    0.0001074      101.65
>> <2e-16 ***
>> fe1_c:fe2_c                   -0.0528655    0.0010090     -52.39
> <2e-16
>> ***
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>> Correlation of Fixed Effects:
>>                      (Intr)     fe1_c    fe2_c
>> fe1_c            -0.012
>> fe2_c             0.000  -0.687
>> fe1_c:fe2_c  -0.022   0.411   -0.071
>>
>> I suspect my problem has something to do with how the "average" intercept
>> is estimated (-2.378). Since I have centered my predictor variables I
> would
>> expect the intercept to be equal to the grand mean (is this a correct
>> assumption?), but in fact it is quite a bit lower.
>>
>> mean(data$successes/data$total)   # equal to 0.2008
>> logistic (-2.3776295)                        # equal to 0.0849
>>
>> Perhaps the model is weighting the unique group intercepts differently
>> leading to something other than a true average intercept? My group sizes
>> vary greatly (data comes from messy observations, not experiments) so
> could
>> this be affecting the estimate?
>>
>> Any incite you could give me would be much appreciated. Thank you for the
>> help.
>> Zack
>>
>>
>> --
>> Zack Steel
>> Landscape Ecologist
>> University of California, Davis
>> zacksteel at gmail.com
>>
>>    [[alternative HTML version deleted]]
>>
>>
>
>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> [https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models]



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From lborger at cebc.cnrs.fr  Wed Apr  3 23:59:30 2013
From: lborger at cebc.cnrs.fr (lborger)
Date: Wed, 03 Apr 2013 23:59:30 +0200
Subject: [R-sig-ME] Low intercept estimate in a binomial glmm
In-Reply-To: <20130403222515.86813sqxmxzwdso4@www.staffmail.ed.ac.uk>
References: <CAG+hMtm+gDomkSXW4th4_b6X-e0=mJVFT6VsH93bsARC74rnEQ@mail.gmail.com>
	<20130403211645.434179gcanzz5m4o@www.staffmail.ed.ac.uk>
	<WC20130403205804.9100F5@cebc.cnrs.fr>
	<20130403222515.86813sqxmxzwdso4@www.staffmail.ed.ac.uk>
Message-ID: <WC20130403215930.0200FD@cebc.cnrs.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130403/f7d8ec77/attachment.pl>

From zacksteel at gmail.com  Wed Apr  3 22:45:18 2013
From: zacksteel at gmail.com (Zack Steel)
Date: Wed, 3 Apr 2013 13:45:18 -0700
Subject: [R-sig-ME] Low intercept estimate in a binomial glmm
In-Reply-To: <20130403211645.434179gcanzz5m4o@www.staffmail.ed.ac.uk>
References: <CAG+hMtm+gDomkSXW4th4_b6X-e0=mJVFT6VsH93bsARC74rnEQ@mail.gmail.com>
	<20130403211645.434179gcanzz5m4o@www.staffmail.ed.ac.uk>
Message-ID: <CAG+hMtkCYzEcbX0R7Ssu8UYqYvnp1HeHgNKSgNBj2eUOcB_r0Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130403/67b251cd/attachment.pl>

From bbolker at gmail.com  Thu Apr  4 04:20:03 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 4 Apr 2013 02:20:03 +0000 (UTC)
Subject: [R-sig-ME] Low intercept estimate in a binomial glmm
References: <CAG+hMtm+gDomkSXW4th4_b6X-e0=mJVFT6VsH93bsARC74rnEQ@mail.gmail.com>
	<20130403211645.434179gcanzz5m4o@www.staffmail.ed.ac.uk>
	<WC20130403205804.9100F5@cebc.cnrs.fr>
	<20130403222515.86813sqxmxzwdso4@www.staffmail.ed.ac.uk>
	<WC20130403215930.0200FD@cebc.cnrs.fr>
Message-ID: <loom.20130404T041715-386@post.gmane.org>

lborger <lborger at ...> writes:


> Cool! Might be nice to include into glmm.wikidot.com/faq?

  Be my guest -- it's a wiki after all ... (I've written most
of it, but there have been a few very welcome edits, in addition
to a whole bunch of commercial spam that I have to keep going
in and weeding ...)

> -----Original Message-----
> From: Jarrod Hadfield <j.hadfield at ...>

[snip]
> 
> I think the Diggle approximation is more accurate:
> 
> sd<-seq(0,4,length=100)
> x<-(-2.3776295)
> 
> Emu<-sapply(sd, function(sd){mean(plogis(rnorm(10000, x,sd)))})
> plot(Emu~sd) # simulated expectations
> c2<-((16*sqrt(3))/(15*pi))^2
> lines(plogis(x/sqrt(1+c2*sd^2))~sd, col="red")
> lines(plogis(x+0.5*sd)~sd, col="blue")
> 
> # approximations for the expectation


From David.Duffy at qimr.edu.au  Thu Apr  4 07:21:15 2013
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Thu, 4 Apr 2013 15:21:15 +1000
Subject: [R-sig-ME] lmer and semi-definite covariance matrices for
 randomeffects
In-Reply-To: <515C0FCB.5000809@iit.it>
References: <515B4512.5060900@hsr.it>
	<alpine.LMD.2.00.1304031732310.20922@orpheus.qimr.edu.au>
	<515C0FCB.5000809@iit.it>
Message-ID: <alpine.LMD.2.00.1304041504270.14233@orpheus.qimr.edu.au>

On Wed, 3 Apr 2013, Gabriel Baud-Bovy wrote:

> Thank you for your suggestion. Still, I am wondering whether lmer could
> fit the model in principle and, if not, why. Here is my current 
> understanding:
[SNIP]
> What I am missing is a clear statement of why a covariance
> structure of the form sigma*CorA where CorA is  semi-definite
> positive will not work (if it does not). Which step in the computation
> of the loglikelihood by lmer cannot be done in this case.

AIUI, the details of the algorithms tend to shift around in the 
development versions. My very simple minded understanding of these matters 
is that one encounters these kinds of problems when one preinverts the 
component matrices for efficiency (so CorA is SPD, but Va*CorA+Ve*I 
isn't).

Cheers, David Duffy.


From lamprianou at yahoo.com  Thu Apr  4 10:18:39 2013
From: lamprianou at yahoo.com (Iasonas Lamprianou)
Date: Thu, 4 Apr 2013 01:18:39 -0700 (PDT)
Subject: [R-sig-ME] no-normal dependent variable
In-Reply-To: <mailman.11.1365052884.4595.r-sig-mixed-models@r-project.org>
References: <mailman.11.1365052884.4595.r-sig-mixed-models@r-project.org>
Message-ID: <1365063519.14070.YahooMailNeo@web160105.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130404/c3d889eb/attachment.pl>

From Thierry.ONKELINX at inbo.be  Thu Apr  4 10:24:09 2013
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 4 Apr 2013 08:24:09 +0000
Subject: [R-sig-ME] longitudinal data/repeated measure
In-Reply-To: <DUB105-W570A8238CEB68C80694045D6D80@phx.gbl>
References: <DUB105-W570A8238CEB68C80694045D6D80@phx.gbl>
Message-ID: <AA818EAD2576BC488B4F623941DA7427C28B0611@inbomail.inbo.be>

Dear Ludovico,

Use time as a factor.

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Ludovico Frate
Verzonden: woensdag 3 april 2013 16:28
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] longitudinal data/repeated measure

Hi there,I need advice in longitudinal data/repeated measure analysis. In particular, I have some difficults about the fixed effect of time in these type of studies. With only two repeated measures, taken on the same subject two times (2001 and 2012) and if I want to detect if the response variable is different between the two measures  (2001 and 2012), how should I treat the time effect? As a continuos variable or a grouping factor?The measure were taken in 2001 and in 2012. If I explicit time as a continuous variable the model (linear mixed model) doesn't reach the convergence, because in this case, the intercept represent the measurement at time 0. Perhaps I should assign the value of 0 and 11 respectively to 2001 and 2012, or treat time as a grouping factor (time a and time b)?Thanks in advanceLudovico

Ludovico
Frate

PhD student (University of Molise - Italy) Environmetrics Lab
http://www.distat.unimol.it/STAT/environmetrica/organico/collaboratori/ludovico-frate-1
Department of Biosciences and Territory - DiBT Universit? del Molise.
Contrada Fonte
Lappone,
86090 -  Pesche (IS)
ITALIA.
Cel: ++39
3333767557
Fax: ++39 (0874) 404123
E-mail ludovico.frate at unimol.it
ludovicofrate at hotmail.it

        [[alternative HTML version deleted]]

* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From ludovicofrate at hotmail.it  Thu Apr  4 11:13:49 2013
From: ludovicofrate at hotmail.it (Ludovico Frate)
Date: Thu, 4 Apr 2013 11:13:49 +0200
Subject: [R-sig-ME] longitudinal data/repeated measure
In-Reply-To: <AA818EAD2576BC488B4F623941DA7427C28B0611@inbomail.inbo.be>
References: <DUB105-W570A8238CEB68C80694045D6D80@phx.gbl>,
	<AA818EAD2576BC488B4F623941DA7427C28B0611@inbomail.inbo.be>
Message-ID: <DUB105-W505FD3E6EA76E1948013DFD6D90@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130404/85de092f/attachment.pl>

From stevedrd at yahoo.com  Thu Apr  4 11:58:55 2013
From: stevedrd at yahoo.com (Steve Denham)
Date: Thu, 4 Apr 2013 02:58:55 -0700 (PDT)
Subject: [R-sig-ME] Low intercept estimate in a binomial glmm
In-Reply-To: <CAG+hMtm+gDomkSXW4th4_b6X-e0=mJVFT6VsH93bsARC74rnEQ@mail.gmail.com>
References: <CAG+hMtm+gDomkSXW4th4_b6X-e0=mJVFT6VsH93bsARC74rnEQ@mail.gmail.com>
Message-ID: <1365069535.8236.YahooMailNeo@web140604.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130404/20391fb9/attachment.pl>

From smilodon2000 at hotmail.com  Thu Apr  4 20:43:51 2013
From: smilodon2000 at hotmail.com (john benson)
Date: Thu, 4 Apr 2013 18:43:51 +0000
Subject: [R-sig-ME] MCMCglmm:interaction bt continuous variable and
 categorical random effect
In-Reply-To: <CANz9Z_LkjvvPn+NVOvQD+t+7dP-=TG6W4Pj1ZQKnKho+SMJVUA@mail.gmail.com>
References: <BAY173-W242BAF93B79C0E73BC5F7BDCDD0@phx.gbl>,
	<CANz9Z_LkjvvPn+NVOvQD+t+7dP-=TG6W4Pj1ZQKnKho+SMJVUA@mail.gmail.com>
Message-ID: <BAY173-W22136EBD2DF22AA392F8BDCD90@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130404/e7353bdb/attachment.pl>

From pauljohn32 at gmail.com  Fri Apr  5 00:48:16 2013
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Thu, 4 Apr 2013 17:48:16 -0500
Subject: [R-sig-ME] how to write formula interface for my mlm data simulator?
Message-ID: <CAErODj8AHwK=Q5BTnroTE-Pu+fV9ygL=pOZYd=K3HtVjJO111w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130404/096c43af/attachment.pl>

From bbolker at gmail.com  Fri Apr  5 05:48:48 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 5 Apr 2013 03:48:48 +0000 (UTC)
Subject: [R-sig-ME] no-normal dependent variable
References: <mailman.11.1365052884.4595.r-sig-mixed-models@r-project.org>
	<1365063519.14070.YahooMailNeo@web160105.mail.bf1.yahoo.com>
Message-ID: <loom.20130405T053742-127@post.gmane.org>

Iasonas Lamprianou <lamprianou at ...> writes:

> Hi all, a very quick question.


> In the context of mixed effects linear models, the theory tells us
> that we should not worry if the distribution of the dependent
> variable is not normal (e.g. if it is uniform, or skewed) as long as
> the residuals are normally and randomly distributed (and in a
> homoscedastic way): the estimates should be consistent, but the
> standard errors might be inflated. So, if a reviewer worries too
> much about the standard errors, is there a way to use lmer or lme to
> compute robust standard errors for my fixed and/or random effects?
> It seems that neither lme4 nor nlme currently support this, but
> there might be some other software out there to do the trick.

  I may be missing something here: if so, sorry.

  As I understand it the theory of mixed models doesn't say *anything*
about the *marginal* distribution of the response variable (I prefer
"predictor"/"response" to "independent"/"dependent"); it *only* refers
to the conditional distribution (= distribution of the residuals)
(and to the distribution of the random effects, but that's a tangent).

  But perhaps you are referring to the conditional distribution
being non-normal?

  You might try seeing whether the vcovHC function from the sandwich
package can be adapted, although I was unsuccessful at my first
attempt ...


From pauljohn32 at gmail.com  Fri Apr  5 07:40:56 2013
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Fri, 5 Apr 2013 00:40:56 -0500
Subject: [R-sig-ME] Low intercept estimate in a binomial glmm
In-Reply-To: <CAG+hMtm+gDomkSXW4th4_b6X-e0=mJVFT6VsH93bsARC74rnEQ@mail.gmail.com>
References: <CAG+hMtm+gDomkSXW4th4_b6X-e0=mJVFT6VsH93bsARC74rnEQ@mail.gmail.com>
Message-ID: <CAErODj8XitE4BqRFdg7mRtTZUkxfb9LHU-GXMYFqJGO+O8k+3Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130405/2102f3ba/attachment.pl>

From pauljohn32 at gmail.com  Fri Apr  5 08:09:00 2013
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Fri, 5 Apr 2013 01:09:00 -0500
Subject: [R-sig-ME] mixed model negative bionomial
In-Reply-To: <CAM9kYqgF-D5QJDK3k1CEZ2NjsjweEHUjbswU6sErqhiLHhQf8w@mail.gmail.com>
References: <59311B7BAD60F14E99B53F85C5413E221CE38A24@WDCWASP435.network.maf.govt.nz>
	<loom.20130328T025435-767@post.gmane.org>
	<CAM9kYqgF-D5QJDK3k1CEZ2NjsjweEHUjbswU6sErqhiLHhQf8w@mail.gmail.com>
Message-ID: <CAErODj9AcLGPWMLXps7brzH1Wk=VPpgdn8O9sQteizw0HUnhvg@mail.gmail.com>

Hi

I refitted with his data, making the change in the formula suggested.

It appears "underdispersed" rather than over, if the relevant
benchmark is 120, you expect deviance to be about that same value.
Isn't that how you would read it?

> sick2.glmm <- glmer(cbind(NSick,(Ntest - NSick)) ~ Breed + (1 | Farm), data = dat,
+ family = binomial)
> summary(sick2.glmm)
Generalized linear mixed model fit by the Laplace approximation
Formula: cbind(NSick, (Ntest - NSick)) ~ Breed + (1 | Farm)
   Data: dat
   AIC   BIC logLik deviance
 88.99 100.1  -40.5    80.99
Random effects:
 Groups Name        Variance Std.Dev.
 Farm   (Intercept)  0        0
Number of obs: 120, groups: Farm, 4

Fixed effects:
               Estimate Std. Error z value Pr(>|z|)
(Intercept)     -3.9404     0.2524 -15.610   <2e-16 ***
BreedPerindale  -0.7601     0.5153  -1.475   0.1402
BreedRomney     -0.9463     0.4813  -1.966   0.0493 *
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
            (Intr) BrdPrn
BreedPerndl -0.490
BreedRomney -0.524  0.257


And if one of these is underdispersed, is one supposed to change something?

Ever see this article? It will make you re-think. Maybe even
second-guess things you thought you knew.

Skrondal, A. and Rabe-Hesketh, S. (2007). Redundant overdispersion
parameters in multilevel models for categorical responses. Journal of
Educational and Behavioral Statistics 32, 419-430.

which you can retrieve from the GLLAAM website
(http://www.gllamm.org/sophia.html).

On Fri, Mar 29, 2013 at 5:33 PM, Philippi, Tom <tom_philippi at nps.gov> wrote:
> Andy--
> Also, check your glmer() formula.  I believe that for family=binomial, the
> response is specified as cbind(success,failure) and not
> cbind(success,trials) as in SAS.  Your example code
> glmer(cbind(dat$NSick,dat$Ntest)) might need to be cbind(NSick,NWell) or
> cbind(NSick,Ntest-NSick).  I don't suggest that this will eliminate all of
> your overdispersion, but if your Ntest is really the number of individuals
> at risk in each group, your coding will inflate the number of
> non-responses.
>
> Tom
>
>
> On Wed, Mar 27, 2013 at 6:58 PM, Ben Bolker <bbolker at gmail.com> wrote:
>
>> Andrew McFadden (Andy <Andrew.McFadden at ...> writes:
>>
>> >
>> > Hi all
>>
>> > Really appreciate a hand here. I am trying to model some data with a
>> > bionomial outcome. I believe that I need to use a negative bionomial
>> > distribution as there were a lot of samples where a large number of
>> > zeros were present i.e. none sick and when modelled using a
>> > bionomial distribution in the lme4 package the residuals were
>> > extremely high. Hence the attempted use of gamlss package.
>>
>>   I can't help with gamlss at the moment, but: the negative binomial
>> is *not* an appropriate generalization of the binomial (unless you
>> have low probabilities everywhere and want to approximate the binomial
>> by a Poisson, in which case you would then get a NB).  Beta-binomial
>> is to binomial and NB is to Poisson.  You can model overdispersion
>> (which is *one* route to many zeros -- another is simply very low
>> overall prevalence, and a third is zero-inflation) in various ways:
>> see http://glmm.wikidot.com/faq ...
>>
>> > I have had difficulty coding the model for the gamlss package,
>> > perhaps I have done something wrong. Also I would like to include
>> > the denominator in the outcome as the sample size varied per group
>> > i.e. in the lme4 package I coded it as:
>> > glmer(cbind(dat$NSick,dat$Ntest); but couldn't seem to do this in
>> > gamlss.
>>
>> > The data below is "made up data", but reflects the analysis I am
>> > doing i.e. data clustered within farm (hence the need for a random
>> > effect), Lots of zero outcome (and the need to use a negative
>> > bionomial equation).
>>
>>  Overdispersion can be modeled in various packages; glmmADMB handles
>> zero-inflation (although it's not well tested for binomial models,
>> so check your results especially carefully).
>>
>>   Ben Bolker
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
> -------------------------------------------
> Tom Philippi, Ph.D.
> Quantitative Ecologist & Data Therapist
> Inventory and Monitoring Program
> National Park Service
> (619) 523-4576
> Tom_Philippi at nps.gov
> http://science.nature.nps.gov/im/monitor
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Paul E. Johnson
Professor, Political Science      Assoc. Director
1541 Lilac Lane, Room 504      Center for Research Methods
University of Kansas                 University of Kansas
http://pj.freefaculty.org               http://quant.ku.edu


From john.maindonald at anu.edu.au  Fri Apr  5 08:24:48 2013
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Fri, 5 Apr 2013 17:24:48 +1100
Subject: [R-sig-ME] Low intercept estimate in a binomial glmm
In-Reply-To: <CAErODj8XitE4BqRFdg7mRtTZUkxfb9LHU-GXMYFqJGO+O8k+3Q@mail.gmail.com>
References: <CAG+hMtm+gDomkSXW4th4_b6X-e0=mJVFT6VsH93bsARC74rnEQ@mail.gmail.com>
	<CAErODj8XitE4BqRFdg7mRtTZUkxfb9LHU-GXMYFqJGO+O8k+3Q@mail.gmail.com>
Message-ID: <FB7EC589-A448-4153-AEC5-F2638B51F444@anu.edu.au>

Surely it is an issue of how you define multi-collinearity.

Centering is a simple re-parameterisation that, like any
other  re-parameterisation, makes no difference to the
predicted values and their standard errors (well, it will
make some small difference to the numerical computational
error, but with modern software that should be of scant
consequence).  Re-parameterisation may however give
parameters that are much more interpretable, with much
reduced correlations and standard errors   That is the
primary reason, if there is one, for doing it.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 05/04/2013, at 4:40 PM, Paul Johnson <pauljohn32 at gmail.com> wrote:

> On Wed, Apr 3, 2013 at 2:58 PM, Zack Steel <zacksteel at gmail.com> wrote:
> 
>> Hello all,
>> 
>> I am running a glmer using the lme4 package and the binomial family and am
>> getting somewhat unexpected results, which I'm hoping someone can help me
>> make sense of. My data look something like the following:
>> 
>> id        group      successes   total         fe1_center     fe2_center
>> 1713    A              0                  11          -0.0911
>> -17.2868
>> 1717    A              0                  155        -0.0911       -17.2886
>> 2272    B              49                 49          -0.0911      -32.2868
>> 2289    B              7                   22          -0.2416
>> -32.2868
>> 1487    B              0                   20          0.0537        2.7132
>> 8199    C              10                127        -0.2416       -59.2868
>> .....
>> 
>> Where my response variable is the proportional of successes. I have
>> centered the two fixed effects variables to alleviate some problems of
>> multicollinearity and am also interested in their interaction.
> 
> 
> I'm just interrupting to say that is incorrect. Centering does not
> alleviate multicollinearity. It just shifts the y axis. It alters the
> location at which the point estimates are provided, sometimes making people
> think they are "better" because the ratio of estimate to std.error
> changes.  But there really is no difference.
> 
> I got angry about it a couple of years ago when I was told I needed to
> teach mean centering in a regression class. That advice is fairly widely
> distributed, but it is just wrong.  I wrote functions meanCenter and
> residualCenter in the rockchalk package so this would be easier for people
> to see.  The evidence is in the vignette
> 
> http://pj.freefaculty.org/R/rockchalk.pdf
> 
> scroll down to page 22. There's a very clear publication of this.
> 
> Echambadi, R., & Hess, J. D. (2007). Mean-Centering Does Not Alleviate
> Collinearity Problems in
> Moderated Multiple Regression Models. Marketing Science, 26(3), 438?445.
> doi: 10.1287/mksc.1060.0263
> 
> I'm absolutely completely positive their argument is correct for linear
> models. How might the GLM's transformation via the link affect that?  Well,
> it doesn't affect multicollinearity on the right hand side at all. And
> that's the main point. It may be that the QR decomposition that insulates
> OLS from numerical roundoff is not relevant in IRLS algorithms for GLM. But
> I bet it is.
> 
> Now, coming back to your question about why, when your fixed effects are
> set to the mean, is your estimated probability value so much lower than the
> observed proportion of successes.
> 
> Can I suggest the culprit is your random effect? You may be forgetting the
> model is nonlinear.  In your story, the predicted value is low, you are on
> the bottom of the S shaped curve.  Now add a symmetric amount of noise on
> either side of the linear predictor.  The noise on the left has a very
> small effect on predicted probability, it is pushing you further down the
> slope you've already slid down.  But the other half of the noise is
> positive, and it is pushing you up the steep part of the S shaped curve.
> 
> I think this is the point at which people start talking about "average
> marginal effect"...
> 
> pj
> 
> The data are
>> clustered spatially within groups so I am using group as a random/grouping
>> variable. When running the glmm, the coefficients of the fixed effects and
>> their interaction seem reasonable (see below). However, when plotting the
>> predictions vs. the response the curve is consistently lower than i would
>> expect. E.g., the predicted proportion is lower than the mean proportion of
>> the data across the full range of data.
>> 
>> #running the model
>> resp = cbind(data$successes, (data$total - data$successes))
>> model = glmer( resp ~ fe1_c * fe2_c + (1|group) ,
>>             data=data, family = binomial, REML=F)
>> summary(model)
>> 
>> 
>> Random effects:
>> Groups Name            Variance   Std.Dev.
>> group  (Intercept)       4.6432      2.1548
>> Number of obs: 12271, groups: group, 392
>> 
>> Fixed effects:
>>                                      Estimate Std. Error              z
>> value    Pr(>|z|)
>> (Intercept)                      -2.3776295    0.1112830     -21.37
>> <2e-16 ***
>> fe1_c                             -0.8771395    0.0362946     -24.17
>> <2e-16 ***
>> fe2_c                              0.0109161    0.0001074      101.65
>> <2e-16 ***
>> fe1_c:fe2_c                   -0.0528655    0.0010090     -52.39     <2e-16
>> ***
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> 
>> Correlation of Fixed Effects:
>>                     (Intr)     fe1_c    fe2_c
>> fe1_c            -0.012
>> fe2_c             0.000  -0.687
>> fe1_c:fe2_c  -0.022   0.411   -0.071
>> 
>> I suspect my problem has something to do with how the "average" intercept
>> is estimated (-2.378). Since I have centered my predictor variables I would
>> expect the intercept to be equal to the grand mean (is this a correct
>> assumption?), but in fact it is quite a bit lower.
>> 
>> mean(data$successes/data$total)   # equal to 0.2008
>> logistic (-2.3776295)                        # equal to 0.0849
>> 
>> Perhaps the model is weighting the unique group intercepts differently
>> leading to something other than a true average intercept? My group sizes
>> vary greatly (data comes from messy observations, not experiments) so could
>> this be affecting the estimate?
>> 
>> Any incite you could give me would be much appreciated. Thank you for the
>> help.
>> Zack
>> 
>> 
>> --
>> Zack Steel
>> Landscape Ecologist
>> University of California, Davis
>> zacksteel at gmail.com
>> 
>>        [[alternative HTML version deleted]]
>> 
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
>> 
> 
> 
> -- 
> Paul E. Johnson
> Professor, Political Science      Assoc. Director
> 1541 Lilac Lane, Room 504      Center for Research Methods
> University of Kansas                 University of Kansas
> http://pj.freefaculty.org               http://quant.ku.edu
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Sat Apr  6 02:49:49 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 6 Apr 2013 00:49:49 +0000 (UTC)
Subject: [R-sig-ME] Low intercept estimate in a binomial glmm
References: <CAG+hMtm+gDomkSXW4th4_b6X-e0=mJVFT6VsH93bsARC74rnEQ@mail.gmail.com>
	<CAErODj8XitE4BqRFdg7mRtTZUkxfb9LHU-GXMYFqJGO+O8k+3Q@mail.gmail.com>
	<FB7EC589-A448-4153-AEC5-F2638B51F444@anu.edu.au>
Message-ID: <loom.20130406T023536-652@post.gmane.org>

John Maindonald <john.maindonald at ...> writes:

> 
> Surely it is an issue of how you define multi-collinearity.
> 
> Centering is a simple re-parameterisation that, like any
> other  re-parameterisation, makes no difference to the
> predicted values and their standard errors (well, it will
> make some small difference to the numerical computational
> error, but with modern software that should be of scant
> consequence).  Re-parameterisation may however give
> parameters that are much more interpretable, with much
> reduced correlations and standard errors   That is the
> primary reason, if there is one, for doing it.
> 

  ... but unfortunately centering often *can* make a difference
in GLMM fitting with lme4.  It would be nice eventually to
do *internal* orthogonalization of the fixed-effects design
matrix (or at least allow a switch for it), to make hand-centering/
scaling/orthogonalization unnecessary, but for the time
being there really are cases where centering matters.

  Ben Bolker


From john.maindonald at anu.edu.au  Sat Apr  6 22:44:40 2013
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Sun, 7 Apr 2013 06:44:40 +1000
Subject: [R-sig-ME] Low intercept estimate in a binomial glmm
In-Reply-To: <loom.20130406T023536-652@post.gmane.org>
References: <CAG+hMtm+gDomkSXW4th4_b6X-e0=mJVFT6VsH93bsARC74rnEQ@mail.gmail.com>
	<CAErODj8XitE4BqRFdg7mRtTZUkxfb9LHU-GXMYFqJGO+O8k+3Q@mail.gmail.com>
	<FB7EC589-A448-4153-AEC5-F2638B51F444@anu.edu.au>
	<loom.20130406T023536-652@post.gmane.org>
Message-ID: <99A24655-47AB-4E11-9D0E-C8F913A87F3E@anu.edu.au>

Well, yes, not necessarily of scant consequence when general
optimisation algorithms are used!

Also, note that type III sums of squares are defined with respect to
a specific parameterisation.  Do not use them unless in the rare
event that one can make a good case for a particular choice of 
parameterisation! 

Random effects are defined with respect to a particular 
parameterisation. 

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 06/04/2013, at 11:49 AM, Ben Bolker <bbolker at gmail.com> wrote:

> John Maindonald <john.maindonald at ...> writes:
> 
>> 
>> Surely it is an issue of how you define multi-collinearity.
>> 
>> Centering is a simple re-parameterisation that, like any
>> other  re-parameterisation, makes no difference to the
>> predicted values and their standard errors (well, it will
>> make some small difference to the numerical computational
>> error, but with modern software that should be of scant
>> consequence).  Re-parameterisation may however give
>> parameters that are much more interpretable, with much
>> reduced correlations and standard errors   That is the
>> primary reason, if there is one, for doing it.
>> 
> 
>  ... but unfortunately centering often *can* make a difference
> in GLMM fitting with lme4.  It would be nice eventually to
> do *internal* orthogonalization of the fixed-effects design
> matrix (or at least allow a switch for it), to make hand-centering/
> scaling/orthogonalization unnecessary, but for the time
> being there really are cases where centering matters.
> 
>  Ben Bolker
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From baron at psych.upenn.edu  Sat Apr  6 22:47:56 2013
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Sat, 6 Apr 2013 16:47:56 -0400
Subject: [R-sig-ME] development version of lme4 on Fedora 18
Message-ID: <20130406204756.GA5123@psych.upenn.edu>

If anyone in the world aside from me wants to get the development
version of lme4 from
http://lme4.r-forge.r-project.org/repos/src/contrib/
working on Fedora 18, with the Fedora rpm version of R (not yet
updated to 3.0), you have to re-install the minqa package, in addition
to updating the usual ones such as Matrix.

Jon
-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron


From rossahmed at googlemail.com  Sun Apr  7 14:55:03 2013
From: rossahmed at googlemail.com (Ross Ahmed)
Date: Sun, 07 Apr 2013 13:55:03 +0100
Subject: [R-sig-ME] Visualising mixed effects model
Message-ID: <CD872B37.45F9%rossahmed@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130407/8449f874/attachment.pl>

From rossahmed at googlemail.com  Sun Apr  7 18:16:10 2013
From: rossahmed at googlemail.com (Ross Ahmed)
Date: Sun, 07 Apr 2013 17:16:10 +0100
Subject: [R-sig-ME] Visualising mixed effects model
In-Reply-To: <CAKFxdiQ_SUn1ppQDS8QHuf7Z6bwJ=uYg-==ty4m6ZwvavRZBjw@mail.gmail.com>
Message-ID: <CD875A41.4627%rossahmed@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130407/f38a2fe8/attachment.pl>

From jwiley.psych at gmail.com  Sun Apr  7 18:24:23 2013
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Sun, 7 Apr 2013 09:24:23 -0700
Subject: [R-sig-ME] Visualising mixed effects model
In-Reply-To: <CD872B37.45F9%rossahmed@gmail.com>
References: <CD872B37.45F9%rossahmed@gmail.com>
Message-ID: <CANz9Z_KxnaxEOpL1n+675dD2bu9+_rDsOKzJtreex0jeunjrMA@mail.gmail.com>

Hi Ross,

If Subject is a factor, I do not think that it makes any sense to both
add it as a fixed effect, and have a random intercept by subject.  You
do not have a random Subject effect, you have a random intercept by
Subject.  Perhaps the former would make sense if, say, subjects were
nested within sites, but as is I doubt very much it is what you hope
it is.

The first model seems to do what you describe, which is condition
reaction estimates on days, as well as allow individual variability by
Subject.  You could extract the conditional models from the model
using ranef(m1), which would give you individual subject estimates.
If you add subject in as a fixed effect and it is a factor, every
subject will already have their own intercept, so there will be
nothing left over to be accounted for by the random (1 | Subject), and
really you could go back to a fixed effects model:

lm(Reaction ~ Days + Subject, data = sleepstudy)

Cheers,

Josh


On Sun, Apr 7, 2013 at 5:55 AM, Ross Ahmed <rossahmed at googlemail.com> wrote:
> Using the ?sleepstudy? dataset, I find this plot?
>
> library(ggplot2)
> ggplot(sleepstudy, aes(Days, Reaction, group=Subject, colour=Subject)) +
> geom_point() + geom_path()
>
> ?really help me understand this model?
>
> library(lme4)
> (m1 <- lmer(Reaction ~ Days + (1 | Subject), sleepstudy))
>
> However, I cannot wrap my head round how to visualise this model?
>
> (m2 <- lmer(Reaction ~ Days + Subject + (1 | Subject), sleep study))
>
> ?in which ?Subject? is specified as both a fixed effect and mixed effect.
> Any clues as to how to plot this model?
>
> Thanks
> Ross
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
University of California, Los Angeles
http://joshuawiley.com/
Senior Analyst - Elkhart Group Ltd.
http://elkhartgroup.com


From mauritsvzb at gmail.com  Mon Apr  8 09:40:18 2013
From: mauritsvzb at gmail.com (Maurits Van Zinnicq Bergmann)
Date: Mon, 8 Apr 2013 09:40:18 +0200
Subject: [R-sig-ME] Checking for outliers in a glmer (lme4 package) with 3
	random factors
Message-ID: <C27DEDBB-27BF-4E68-B976-614D77E26DB7@gmail.com>

Hi everyone, 

I have a question relating to the checking for outliers and / or influential points in my dataset using a `glmer` model with 3 random variables. I'm investigating the detection rate (`SumDetections`) of receivers over increasing distance (`sc.c.distance`), and the effect of environmental influences on this (`depth`, `temperature` and `wind`) and how this differs between different transmitters used, controlling for random effects of `receiver ID`, `replicate` and `area`. I found that the `influence.ME` might be of help, so I checked it out.  

In the manual I read that this package is only able to delete levels of 1 single grouping factor or 1 data point per time over the whole data set. Unless I read the package info incorrectly, this package cannot do what I'm looking for. I'm looking for a way to check for outliers nested within 4 grouping layers. 

How my data is organized is as follows: First my data discerns between `Areas`. Within areas, multiple `replicates` were done. Each replicate consisted of 5 `distances` at which the detection rate was tested. For each distance, 20 `receivers` were tested. These experiments were repeated over several days.

My model looks like this:

    m <- lmer(SumDetections ~ tm + sc.c.distance + tm:sc.c.distance + c.tm.depth + 
                 c.receiver.depth + c.temp + c.wind + (1|replicate) + (1|SUR.ID) + (1|Area) + (1|Day), 
                 data = df3, family = poisson)

My questions are:  

 - Is it possible to check for outliers of which the data is nested within 3 layers with use of influence.me? 
 - If so, how should I specify the command to get what I'm looking for, and how should I interpret the returned data by the Cook's distance or dfbetas? 
 - If not, is there another package that allows me to check for outliers?

Thanks in advance for your help.
Cheers,

From diegobilski at gmail.com  Tue Apr  9 04:11:57 2013
From: diegobilski at gmail.com (Diego Bilski)
Date: Mon, 8 Apr 2013 23:11:57 -0300
Subject: [R-sig-ME] zero inflated - glm.fit warning
Message-ID: <CA+ViX4rHfVHw4a7ON1t76EahNrQ+fRCKSj2sBVGgyDKiuHNfqg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130408/799f0b75/attachment.pl>

From mcasals at aspb.cat  Tue Apr  9 11:25:28 2013
From: mcasals at aspb.cat (=?ISO-8859-1?Q?Mart=ED_Casals?=)
Date: Tue, 9 Apr 2013 11:25:28 +0200
Subject: [R-sig-ME] zero inflated - glm.fit warning
In-Reply-To: <CA+ViX4rHfVHw4a7ON1t76EahNrQ+fRCKSj2sBVGgyDKiuHNfqg@mail.gmail.com>
References: <CA+ViX4rHfVHw4a7ON1t76EahNrQ+fRCKSj2sBVGgyDKiuHNfqg@mail.gmail.com>
Message-ID: <CADtmEn4nkU24ZQgv51b27NJfJ=-cC66pic7JgH6r1PHE86E6Zw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130409/8414dc8a/attachment.pl>

From f.calboli at imperial.ac.uk  Tue Apr  9 12:46:00 2013
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Tue, 9 Apr 2013 11:46:00 +0100
Subject: [R-sig-ME] lme4 binary for OSX
Message-ID: <617EEC67-FF20-4388-B245-C11B09DA02E2@imperial.ac.uk>

Dear All,

I tried to use the package manager in the GUI to connect to http://lme4.r-forge.r-project.org/repos, but I get:

Warning: unable to access index for repository http://lme4.r-forge.r-project.org/repos/bin/macosx/contrib/3.0

I noticed that there is a binary here:

http://lme4.r-forge.r-project.org/repos/bin/macosx/leopard/contrib/3.0/

(i.e. the GUI package manager is not resolving the right address I presume).

Hence I have two questions.  Does the R-forge lme4 page need a tweak?  Is that binary the latest and greatest, safe to use with R 3.0.0 on a 64-bit mac running OS 10.8.3?

Best wishes

F

PS I CC'd Simon and Hans-J?rg in case the problem is not on the r-forge page but on how the GUI resolves the address.


From Thierry.ONKELINX at inbo.be  Tue Apr  9 14:21:50 2013
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 9 Apr 2013 12:21:50 +0000
Subject: [R-sig-ME] lme4 binary for OSX
In-Reply-To: <617EEC67-FF20-4388-B245-C11B09DA02E2@imperial.ac.uk>
References: <617EEC67-FF20-4388-B245-C11B09DA02E2@imperial.ac.uk>
Message-ID: <AA818EAD2576BC488B4F623941DA7427C28B5123@inbomail.inbo.be>

Dear Federico,

It seems that R-forge isn't yet updated to R 3.0.0. Hence the packages are not available for R 3.0.0

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Federico Calboli
Verzonden: dinsdag 9 april 2013 12:46
Aan: <r-sig-mixed-models at r-project.org> list
CC: Simon Urbanek; Hans-J?rg Bibiko
Onderwerp: [R-sig-ME] lme4 binary for OSX

Dear All,

I tried to use the package manager in the GUI to connect to http://lme4.r-forge.r-project.org/repos, but I get:

Warning: unable to access index for repository http://lme4.r-forge.r-project.org/repos/bin/macosx/contrib/3.0

I noticed that there is a binary here:

http://lme4.r-forge.r-project.org/repos/bin/macosx/leopard/contrib/3.0/

(i.e. the GUI package manager is not resolving the right address I presume).

Hence I have two questions.  Does the R-forge lme4 page need a tweak?  Is that binary the latest and greatest, safe to use with R 3.0.0 on a 64-bit mac running OS 10.8.3?

Best wishes

F

PS I CC'd Simon and Hans-J?rg in case the problem is not on the r-forge page but on how the GUI resolves the address.

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From f.calboli at imperial.ac.uk  Tue Apr  9 14:27:38 2013
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Tue, 9 Apr 2013 13:27:38 +0100
Subject: [R-sig-ME] lme4 binary for OSX
In-Reply-To: <AA818EAD2576BC488B4F623941DA7427C28B5123@inbomail.inbo.be>
References: <617EEC67-FF20-4388-B245-C11B09DA02E2@imperial.ac.uk>
	<AA818EAD2576BC488B4F623941DA7427C28B5123@inbomail.inbo.be>
Message-ID: <430AD838-03E5-4026-8193-9868B0F52449@imperial.ac.uk>

Dear Thierry,

thank you for letting me know.  I though this link

http://lme4.r-forge.r-project.org/repos/bin/macosx/leopard/contrib/3.0/

on the lme4 page meant it was, but that's not the case then.

BW

F


On 9 Apr 2013, at 13:21, "ONKELINX, Thierry" <Thierry.ONKELINX at inbo.be> wrote:

> Dear Federico,
> 
> It seems that R-forge isn't yet updated to R 3.0.0. Hence the packages are not available for R 3.0.0
> 
> Best regards,
> 
> Thierry
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> + 32 2 525 02 51
> + 32 54 43 61 85
> Thierry.Onkelinx at inbo.be
> www.inbo.be
> 
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
> 
> The plural of anecdote is not data.
> ~ Roger Brinner
> 
> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> 
> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Federico Calboli
> Verzonden: dinsdag 9 april 2013 12:46
> Aan: <r-sig-mixed-models at r-project.org> list
> CC: Simon Urbanek; Hans-J?rg Bibiko
> Onderwerp: [R-sig-ME] lme4 binary for OSX
> 
> Dear All,
> 
> I tried to use the package manager in the GUI to connect to http://lme4.r-forge.r-project.org/repos, but I get:
> 
> Warning: unable to access index for repository http://lme4.r-forge.r-project.org/repos/bin/macosx/contrib/3.0
> 
> I noticed that there is a binary here:
> 
> http://lme4.r-forge.r-project.org/repos/bin/macosx/leopard/contrib/3.0/
> 
> (i.e. the GUI package manager is not resolving the right address I presume).
> 
> Hence I have two questions.  Does the R-forge lme4 page need a tweak?  Is that binary the latest and greatest, safe to use with R 3.0.0 on a 64-bit mac running OS 10.8.3?
> 
> Best wishes
> 
> F
> 
> PS I CC'd Simon and Hans-J?rg in case the problem is not on the r-forge page but on how the GUI resolves the address.
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> * * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
> Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
> The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From bbolker at gmail.com  Wed Apr 10 01:47:43 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 9 Apr 2013 23:47:43 +0000 (UTC)
Subject: [R-sig-ME] lme4 binary for OSX
References: <617EEC67-FF20-4388-B245-C11B09DA02E2@imperial.ac.uk>
	<AA818EAD2576BC488B4F623941DA7427C28B5123@inbomail.inbo.be>
	<430AD838-03E5-4026-8193-9868B0F52449@imperial.ac.uk>
Message-ID: <loom.20130410T012731-490@post.gmane.org>

Federico Calboli <f.calboli at ...> writes:

> 
> Dear Thierry,
> 
> thank you for letting me know.  I though this link
> 
> http://lme4.r-forge.r-project.org/repos/bin/macosx/leopard/contrib/3.0/
> 
> on the lme4 page meant it was, but that's not the case then.
> 
> BW
> 
> F
> 
> On 9 Apr 2013, at 13:21, "ONKELINX, Thierry" <Thierry.ONKELINX at ...> wrote:
> 
> > Dear Federico,

> > It seems that R-forge isn't yet updated to R 3.0.0. Hence the
>    packages are not available for R 3.0.0

> > Best regards,
> > 
> > Thierry

  lme4 status report, R-3.0.0 related:

** STABLE version (lme4 on CRAN, lme4.0 on r-forge)

The MacOS binary build (only) on CRAN was missing because of some
failed (relatively obscure) tests -- problem still not diagnosed, but
for now I have commented these tests out.  I've updated lme4.0 on
r-forge (it's still building, see status at
<http://r-forge.r-project.org/R/?group_id=60>) and have submitted the
updated version _as lme4_ to CRAN: if all goes well that should
propagate shortly (but not yet checked by the powers-that-be, so
there could still be some glitches to resolve)

I don't know if lme4.0-on-r-forge will be available for 3.0.0
or not once it successfully builds.

** DEVELOPMENT version (lme4 on github, and at lme4.r-forge repository)

BINARIES

I have added a recent MacOS binary at
http://lme4.r-forge.r-project.org/repos/bin/macosx/contrib/3.0/ .
This appears to be the correct path (install.packages(...) worked for
me on MacOS/R-3.0.0). I am still trying to sort the repository tree
out properly: the path above works, but 
http://cran.r-project.org/doc/manuals/R-admin.html#
Setting-up-a-package-repository (broken URL!) suggests that MacOS
binaries should be "located at bin/macosx/snowleopard/contrib/3.y for
R versions 3.y.z" ... so I have added a copy there as well.

SOURCE

Still available on github for those with compile tools and devtools
package installed:

library("devtools")
install_github("lme4",user="lme4")


From nic43614 at gmail.com  Wed Apr 10 13:47:09 2013
From: nic43614 at gmail.com (Nico N)
Date: Wed, 10 Apr 2013 21:47:09 +1000
Subject: [R-sig-ME] MCMCglmm multivariate multilevel meta-analysis
Message-ID: <CAAM7jk1O+L7zFhnYak9ScoY0qYW2dARN74XaS5326xm9pid+sQ@mail.gmail.com>

Hey everyone,

Presently, I am trying to conduct a multivariate multilevel
meta-analysis using the MCMCglmm package.

However, I encountered the following problem and I was hoping to
obtain some advice.

The following example would describe my situation. The dependent
variable is some performance measure, which is captured in two
different ways (2 different measures for the same construct).

Hence, I have two measures for each student, similar to the
multi-response model examples in the MCMCglmm tutorial notes.

Moreover, I have a big data set with students nested in schools, and
schools nested in countries (3 additional levels).

In sum, I require four levels (sorry, social science jargon I think):
level 1= measures, level2=students, level3=schools, and
level4=country.

I only would like to have random-intercepts for each level above the
measure-level.


Now I think there may be two ways. Originally, the data is in the
"wide" format. That is:

Columns headers are the following:  student, school, country, measure
1, measure 2, var1 ,  var2, predictor1, predictor 2,?   (for
simplicity, let's assume two predictors only - both only fixed
effects).


Var2 and var2 are the known variances for the two measures of
interest. The variances need to be provided to the first level of the
model, while the estimated covariance matrix is fixed to 1. As far as
I understood, the "mev" command does this.

Now, given the "wide" format, I noticed that MCMCglmm seems to have a
convenient way to estimate measure-specific intercepts through the
"trait"-command (i.e., without changing the data).

If I am not wrong, the code would be as follows.


prior = list(R = list( V =diag(2), n=2,fix = 1), G = list(

                       G1 = list ( V = diag(2), n = 2),

                       G2 = list ( V = diag(2), n = 2),

                       G3 = list ( V = diag(2), n = 2) ))

model1 <- MCMCglmm( cbind(measure1, measure2) ~ -1 + trait +

                               predictor1 +

                               predictor2 ,

                       random = ~us(trait):student +

                               us(trait):school +

                               idh(trait):country + ,

                       rcov = ~idh(trait):units,

                       prior=prior,

                       data = dataset,

                       mev= ?????,

                       family = c("gaussian","gaussian"))


However, I was wondering how I can provide the variances to this model
with two measures? In my case, I would need a 2xn matrix and I am not
sure whether the "mev" command can handle this. Has anyone ever tried
something like this?

I guess there would be an alternative, in case "mev" must be a 1xn
vector: I guess I could create the stacked (or long) data myself
before running the model. Then, as Hox (2010) recommends, one can
create dummy variables indicating to which measure the dependent
variable column (DV) refers to.

In my case: MD1 for measure 1 and MD2 for measure2. Then, each
predictor would have to be multiplied with these two dummies, such
that it looks like the following table (pred=predictor):

DV  	measure	var	MD1	MD2	student  school	country  pred1
pred2	pred1XMD1 pred1XMD2    pred2XMD1   pred2XMD2
3.4	1		0.2	1	0	1		1	1		2	1.3	2		   0		             1.3	    0
5.6	2		0.4	0	1	1		1	1		3	1.4	0		   3		             0	           1.4
6.7	1		0.5	1	0	2		1	1		4	1.4	4		   0		             1.4	    0
4.5	2		0.3	0	1	2		1	1		4	1	0		   4		              0	            1
5.5	1		0.5	1	0	3		1	1		2	1.9	2		   0		             1.9	    0
4.5	2		0.7	0	1	3		1	1		4	1.6	0		   4		             0	          1.6
6.7	1		0.6	1	0	4		2	1		2	1.7	2		   0		             1.7	    0
4.5	2		0.6	0	1	4		2	1		4	1.3	0		   4		              0	1.3


Then, the following code should work (with same prior):


model2 <- MCMCglmm( DV ~ -1 + MD1 + MD2 +

                               pred1xMD1 +

                               pred1xMD2 +

                               pred2xMD1 +

                               pred2xMD2 +,

                       random = ~us(MD1+MD2):student +

                               us(MD1+MD2):school  +

                               idh(MD1+MD2):country + ,

                       rcov = ~idh(MD1+MD2):units,

                       prior=prior,

                       data = dataset,

                       mev= dataset$var,

                       family = "gaussian"))



Now I wanted to check whether this seems sensible within the Bayesian
framework? ? I generally would prefer a solution for the
"model1"-approach above as I have many more predictors than in this
example.

I would highly appreciate any comment! I can imagine that other people
may be interested in conducing a similar hierarchical multiresponse
meta-analysis.


Best regards

Nico

PhD-candidate


From Tyler.Hallman at oregonstate.edu  Wed Apr 10 16:22:30 2013
From: Tyler.Hallman at oregonstate.edu (Hallman, Tyler)
Date: Wed, 10 Apr 2013 14:22:30 +0000
Subject: [R-sig-ME] GLMM question in lme4
Message-ID: <C166DB602CA3824F931AA26E6A3578502AA7D65F@EX2.oregonstate.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130410/e869e7d8/attachment.pl>

From bbolker at gmail.com  Thu Apr 11 03:04:11 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 11 Apr 2013 01:04:11 +0000 (UTC)
Subject: [R-sig-ME] GLMM question in lme4
References: <C166DB602CA3824F931AA26E6A3578502AA7D65F@EX2.oregonstate.edu>
Message-ID: <loom.20130411T025708-911@post.gmane.org>

Hallman, Tyler <Tyler.Hallman at ...> writes:

> 
> To Whom it May Concern,
 
> I am currently analyzing the data from a toxicity test and I want to
> use a glmm with the lmer function in the lme4 package.

>  Experimental Design: I exposed beakers of larval amphibians to
> different concentrations of metals contaminants at different
> temperatures. I'm primarily concerned with the effect of temperature
> on toxicity. I ran the test for 4 days and my response variable is
> proportional data (percent mortality) because I recorded the number
> dead per beaker. I therefore have percent mortality for each beaker
> at 0, 24, 48, 72, and 96 hours. I had 3 replicates of each
> treatment.

> Statistics: I want to incorporate time into the model and need to
> include the autocorrelation due to time (violation of the assumption
> of independence). I also have to account for the response variable
> being proportional with lots of 0's and 1's.

> So far it looks like I have to do something like this:
> 
> m1<-lmer(PercentMortality~Time*Concentration*Temperature+(1|BeakerNumber),
> family=binomial)

  This is a good start.  

(minor) In the current release lmer(...,family=binomial)
automatically calls glmer(), but in future releases you will have to
call glmer() explicitly.

(major) I'm surprised you're not getting warnings about
"non-integer #successes in a binomial glm", if you have more
than one individual per beaker.  Take a closer look at the
?glm help page for the format of binomial response variables
(hint: either cbind(n.dead,n.notdead)~... or prop~..., weights=n.exposed)

You might want (Time|BeakerNumber), to allow for different trajectories
through time in each beaker.

These models don't explicitly account for continuous temporal
autocorrelation (e.g. an autoregressive-order-1 (AR1) model would
be the simplest case), but that is actually a little bit tricky
in the GLMM case -- you would probably need to use AD Model Builder
or WinBUGS or some more general tool for that.  Given that you
have only 5 time points, and not a gigantic data set, that might
not be a huge problem.  You could check the residuals for evidence
of autocorrelation.

However, the models *do* account for the overall correlation of
observations within beakers.

You may also want to add an observation-level random effect
to account for overdispersion.

> I'm not sure if this accounts for the non-independence between times
> though. Do you have any suggestions as to the code I should use for
> this? Any help would be greatly appreciated as I've been having
> trouble finding examples of this type of analysis.


From j.hadfield at ed.ac.uk  Thu Apr 11 07:59:18 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 11 Apr 2013 06:59:18 +0100
Subject: [R-sig-ME] MCMCglmm multivariate multilevel meta-analysis
In-Reply-To: <CAAM7jk1O+L7zFhnYak9ScoY0qYW2dARN74XaS5326xm9pid+sQ@mail.gmail.com>
References: <CAAM7jk1O+L7zFhnYak9ScoY0qYW2dARN74XaS5326xm9pid+sQ@mail.gmail.com>
Message-ID: <20130411065918.105624xy76x578sg@www.staffmail.ed.ac.uk>

Hi Nico,

You should just be able to pass c(dataset$var1, dataset$var2) to mev.  
If you have sampling covariances between the measures then its a bit  
more complicated, but I think you don't?

There's also an in-built function for creating the dummy variables:  
at.level(trait,1):predictor1 fits an effect of predictor1 for trait 1,  
if you want to fit separate predictor1 effects for both traits you can  
just use trait:predictor1.

Cheers,

Jarrod



Quoting Nico N <nic43614 at gmail.com> on Wed, 10 Apr 2013 21:47:09 +1000:

> Hey everyone,
>
> Presently, I am trying to conduct a multivariate multilevel
> meta-analysis using the MCMCglmm package.
>
> However, I encountered the following problem and I was hoping to
> obtain some advice.
>
> The following example would describe my situation. The dependent
> variable is some performance measure, which is captured in two
> different ways (2 different measures for the same construct).
>
> Hence, I have two measures for each student, similar to the
> multi-response model examples in the MCMCglmm tutorial notes.
>
> Moreover, I have a big data set with students nested in schools, and
> schools nested in countries (3 additional levels).
>
> In sum, I require four levels (sorry, social science jargon I think):
> level 1= measures, level2=students, level3=schools, and
> level4=country.
>
> I only would like to have random-intercepts for each level above the
> measure-level.
>
>
> Now I think there may be two ways. Originally, the data is in the
> "wide" format. That is:
>
> Columns headers are the following:  student, school, country, measure
> 1, measure 2, var1 ,  var2, predictor1, predictor 2,?   (for
> simplicity, let's assume two predictors only - both only fixed
> effects).
>
>
> Var2 and var2 are the known variances for the two measures of
> interest. The variances need to be provided to the first level of the
> model, while the estimated covariance matrix is fixed to 1. As far as
> I understood, the "mev" command does this.
>
> Now, given the "wide" format, I noticed that MCMCglmm seems to have a
> convenient way to estimate measure-specific intercepts through the
> "trait"-command (i.e., without changing the data).
>
> If I am not wrong, the code would be as follows.
>
>
> prior = list(R = list( V =diag(2), n=2,fix = 1), G = list(
>
>                        G1 = list ( V = diag(2), n = 2),
>
>                        G2 = list ( V = diag(2), n = 2),
>
>                        G3 = list ( V = diag(2), n = 2) ))
>
> model1 <- MCMCglmm( cbind(measure1, measure2) ~ -1 + trait +
>
>                                predictor1 +
>
>                                predictor2 ,
>
>                        random = ~us(trait):student +
>
>                                us(trait):school +
>
>                                idh(trait):country + ,
>
>                        rcov = ~idh(trait):units,
>
>                        prior=prior,
>
>                        data = dataset,
>
>                        mev= ?????,
>
>                        family = c("gaussian","gaussian"))
>
>
> However, I was wondering how I can provide the variances to this model
> with two measures? In my case, I would need a 2xn matrix and I am not
> sure whether the "mev" command can handle this. Has anyone ever tried
> something like this?
>
> I guess there would be an alternative, in case "mev" must be a 1xn
> vector: I guess I could create the stacked (or long) data myself
> before running the model. Then, as Hox (2010) recommends, one can
> create dummy variables indicating to which measure the dependent
> variable column (DV) refers to.
>
> In my case: MD1 for measure 1 and MD2 for measure2. Then, each
> predictor would have to be multiplied with these two dummies, such
> that it looks like the following table (pred=predictor):
>
> DV  	measure	var	MD1	MD2	student  school	country  pred1
> pred2	pred1XMD1 pred1XMD2    pred2XMD1   pred2XMD2
> 3.4	1		0.2	1	0	1		1	1		2	1.3	2		   0		             1.3	    0
> 5.6	2		0.4	0	1	1		1	1		3	1.4	0		   3		             0	           1.4
> 6.7	1		0.5	1	0	2		1	1		4	1.4	4		   0		             1.4	    0
> 4.5	2		0.3	0	1	2		1	1		4	1	0		   4		              0	            1
> 5.5	1		0.5	1	0	3		1	1		2	1.9	2		   0		             1.9	    0
> 4.5	2		0.7	0	1	3		1	1		4	1.6	0		   4		             0	          1.6
> 6.7	1		0.6	1	0	4		2	1		2	1.7	2		   0		             1.7	    0
> 4.5	2		0.6	0	1	4		2	1		4	1.3	0		   4		              0	1.3
>
>
> Then, the following code should work (with same prior):
>
>
> model2 <- MCMCglmm( DV ~ -1 + MD1 + MD2 +
>
>                                pred1xMD1 +
>
>                                pred1xMD2 +
>
>                                pred2xMD1 +
>
>                                pred2xMD2 +,
>
>                        random = ~us(MD1+MD2):student +
>
>                                us(MD1+MD2):school  +
>
>                                idh(MD1+MD2):country + ,
>
>                        rcov = ~idh(MD1+MD2):units,
>
>                        prior=prior,
>
>                        data = dataset,
>
>                        mev= dataset$var,
>
>                        family = "gaussian"))
>
>
>
> Now I wanted to check whether this seems sensible within the Bayesian
> framework? ? I generally would prefer a solution for the
> "model1"-approach above as I have many more predictors than in this
> example.
>
> I would highly appreciate any comment! I can imagine that other people
> may be interested in conducing a similar hierarchical multiresponse
> meta-analysis.
>
>
> Best regards
>
> Nico
>
> PhD-candidate
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From Pie.Mueller at unibas.ch  Thu Apr 11 16:01:38 2013
From: Pie.Mueller at unibas.ch (Pie.Mueller at unibas.ch)
Date: Thu, 11 Apr 2013 16:01:38 +0200
Subject: [R-sig-ME] =?iso-8859-1?q?AUTO=3A_Pie_M=FCller_is_out_of_the_offi?=
 =?iso-8859-1?q?ce=2E_=28returning__15=2E04=2E2013=29?=
Message-ID: <OFFEC66243.D5B9D2CF-ONC1257B4A.004D0DE1-C1257B4A.004D0DE1@LocalDomain>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130411/28d5f7e7/attachment.pl>

From pauljohn32 at gmail.com  Thu Apr 11 17:42:17 2013
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Thu, 11 Apr 2013 10:42:17 -0500
Subject: [R-sig-ME] Ben's Point about Centering and GLMM (was: Re: Low
 intercept estimate in a binomial glmm
Message-ID: <CAErODj8fJ_nji1PLivKff9egqEC9pbXau3hz7rqoJMWg_tTxCQ@mail.gmail.com>

On Fri, Apr 5, 2013 at 1:24 AM, John Maindonald
<john.maindonald at anu.edu.au> wrote:
> Surely it is an issue of how you define multi-collinearity.
>
I don't think so. The definition is the same, but multi-collinearity's
effect is different for every point in the X space.  I mean, the
elevation in variance estimates due to multi-collinearity depends on
where you place the y axis. The point estimates that appear in
regression output are different when you center because you move the y
axis about by centering.  But if you fit in one spot, and then project
the answer over to the other spot, the answer you get about slope,
standard error, etc is all the same. In either model.

Centering appeals to many practitioners because it seems to give
parameters with smaller standard errors, but its an illusion.
Uncertainty about predictions is hour-glass shaped in the X space, and
if you go into the middle, you have less uncertainty.

> Re-parameterisation may however give
> parameters that are much more interpretable, with much
> reduced correlations and standard errors   That is the
> primary reason, if there is one, for doing it.
>

I think that's a mistake, and have the examples in the rockchalk
vignette to demonstrate it.  If you say "what is the slope when
observed X = x", and "what is the uncertainty of your estimate when X
= x?" all of these models give exactly the same answer.

But back to Ben's point about GLMM.  That's an eye opener.

I'd like to make a working example of the problem that centering
affects estimates (beyond rounding error).  I need to know a test case
that is likely to produce the effect mentioned before I can go any
further.

pj
--
Paul E. Johnson
Professor, Political Science      Assoc. Director
1541 Lilac Lane, Room 504      Center for Research Methods
University of Kansas                 University of Kansas
http://pj.freefaculty.org               http://quant.ku.edu


From john.maindonald at anu.edu.au  Thu Apr 11 21:23:13 2013
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Fri, 12 Apr 2013 05:23:13 +1000
Subject: [R-sig-ME] Ben's Point about Centering and GLMM (was: Re: Low
	intercept estimate in a binomial glmm
In-Reply-To: <CAErODj8fJ_nji1PLivKff9egqEC9pbXau3hz7rqoJMWg_tTxCQ@mail.gmail.com>
References: <CAErODj8fJ_nji1PLivKff9egqEC9pbXau3hz7rqoJMWg_tTxCQ@mail.gmail.com>
Message-ID: <F843B9E8-5B3A-439F-B504-F3C1EE668452@anu.edu.au>

A quick response, and any further discussion had better proceed
in a more appropriate place (though this affects mixed models as
much as linear models): 

For the nihills data in the DAAG package:

nihills$gradient <- with(nihills , climb/dist)
lognihills <- log( nihills )
names(lognihills) <- paste("l", names(nihills), sep="")

lognihills.lm <- lm(ltime ~ ldist + lclimb, data=lognihills) 
round(coef( lognihills.lm) ,3)
(Intercept)       ldist      lclimb 
    -4.961       0.681       0.466 

lognigrad.lm <- lm(ltime ~ ldist + lgradient , data=lognihills) 
round(coef( lognigrad.lm) ,3)
(Intercept)       ldist   lgradient 
    -4.961       1.147       0.466 

I have no interest in how the time may change with distance when
climb is held constant (as races get longer the gradient reduces, and 
hence the somewhat counter-intuitive coefficient of 0.681 for list)

The coefficient of 1.147 for ldist when gradient is held constant does
make sense -- as races get longer the relative rate of increase of
time with distance increases.

Sure, the predicted values and SEs of predicted values are the 
same in the two cases, if one translates from one space to the other.
That does not affect my point. 

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 12/04/2013, at 1:42 AM, Paul Johnson <pauljohn32 at gmail.com> wrote:

> On Fri, Apr 5, 2013 at 1:24 AM, John Maindonald
> <john.maindonald at anu.edu.au> wrote:
>> Surely it is an issue of how you define multi-collinearity.
>> 
> I don't think so. The definition is the same, but multi-collinearity's
> effect is different for every point in the X space.  I mean, the
> elevation in variance estimates due to multi-collinearity depends on
> where you place the y axis. The point estimates that appear in
> regression output are different when you center because you move the y
> axis about by centering.  But if you fit in one spot, and then project
> the answer over to the other spot, the answer you get about slope,
> standard error, etc is all the same. In either model.
> 
> Centering appeals to many practitioners because it seems to give
> parameters with smaller standard errors, but its an illusion.
> Uncertainty about predictions is hour-glass shaped in the X space, and
> if you go into the middle, you have less uncertainty.
> 
>> Re-parameterisation may however give
>> parameters that are much more interpretable, with much
>> reduced correlations and standard errors   That is the
>> primary reason, if there is one, for doing it.
>> 
> 
> I think that's a mistake, and have the examples in the rockchalk
> vignette to demonstrate it.  If you say "what is the slope when
> observed X = x", and "what is the uncertainty of your estimate when X
> = x?" all of these models give exactly the same answer.
> 
> But back to Ben's point about GLMM.  That's an eye opener.
> 
> I'd like to make a working example of the problem that centering
> affects estimates (beyond rounding error).  I need to know a test case
> that is likely to produce the effect mentioned before I can go any
> further.
> 
> pj
> --
> Paul E. Johnson
> Professor, Political Science      Assoc. Director
> 1541 Lilac Lane, Room 504      Center for Research Methods
> University of Kansas                 University of Kansas
> http://pj.freefaculty.org               http://quant.ku.edu


From bbolker at gmail.com  Thu Apr 11 21:35:00 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 11 Apr 2013 19:35:00 +0000 (UTC)
Subject: [R-sig-ME] Ben's Point about Centering and GLMM (was: Re: Low
	intercept estimate in a binomial glmm
References: <CAErODj8fJ_nji1PLivKff9egqEC9pbXau3hz7rqoJMWg_tTxCQ@mail.gmail.com>
Message-ID: <loom.20130411T202449-806@post.gmane.org>

Paul Johnson <pauljohn32 at ...> writes:

> 
> On Fri, Apr 5, 2013 at 1:24 AM, John Maindonald
> <john.maindonald at ...> wrote:
> > Surely it is an issue of how you define multi-collinearity.
> >
> I don't think so. The definition is the same, but multi-collinearity's
> effect is different for every point in the X space.  I mean, the
> elevation in variance estimates due to multi-collinearity depends on
> where you place the y axis. The point estimates that appear in
> regression output are different when you center because you move the y
> axis about by centering.  But if you fit in one spot, and then project
> the answer over to the other spot, the answer you get about slope,
> standard error, etc is all the same. In either model.
> 
> Centering appeals to many practitioners because it seems to give
> parameters with smaller standard errors, but its an illusion.
> Uncertainty about predictions is hour-glass shaped in the X space, and
> if you go into the middle, you have less uncertainty.
> 
> > Re-parameterisation may however give
> > parameters that are much more interpretable, with much
> > reduced correlations and standard errors   That is the
> > primary reason, if there is one, for doing it.
> >
> 
> I think that's a mistake, and have the examples in the rockchalk
> vignette to demonstrate it.  If you say "what is the slope when
> observed X = x", and "what is the uncertainty of your estimate when X
> = x?" all of these models give exactly the same answer.
> 
> But back to Ben's point about GLMM.  That's an eye opener.
> 
> I'd like to make a working example of the problem that centering
> affects estimates (beyond rounding error).  I need to know a test case
> that is likely to produce the effect mentioned before I can go any
> further.
> 
> pj
> --
> Paul E. Johnson
> Professor, Political Science      Assoc. Director
> 1541 Lilac Lane, Room 504      Center for Research Methods
> University of Kansas                 University of Kansas
> http://pj.freefaculty.org               http://quant.ku.edu

  I had to work a little harder than I expected, and it's more
extreme/has less effect than I would like, but in this example
stable lme4 gives a convergence warning and gives an intercept
that is a little bit off (although admittedly about 0.5%);
development lme4 actually handles it OK.

Messier data sets will probably behave worse than this (i.e. the
effect will be bigger).  For other/better examples, you might troll
through list archives to find people complaining about convergence
warnings ...  Maybe someone will come forward with an example.
(I used to have a problem if I didn't center the HEIGHT variable in the
Elston tick data example (see ?grouseticks in development lme4),
but things seem to have improved since the last time I tried
it a few years ago ...)

set.seed(101)
nblock <- 5
nrep <- 5
xr <- 4
mx <- 10000
sl <- 2
d <- expand.grid(x=mx+(-xr:xr),grp=LETTERS[1:nblock],rep=1:nrep)
u <- rnorm(nblock,sd=1)
d$eta <- with(d,1+(x-mx)*sl+u[grp])
d$y <- rpois(nrow(d),exp(d$eta))

ff <- function(model,corr=TRUE,shift=mx) {
    f <- fixef(model)
    if (corr) f + c(f[2]*shift,0) else f
}
library(lme4.0)
g1 <- glmer(y~x+(1|grp),data=d,family=poisson)
## false convergence warning
(f1 <- ff(g1))
g2 <- glmer(y~I(x-mx)+(1|grp),data=d,family=poisson)
(f2 <- ff(g2,FALSE))
detach("package:lme4.0",unload=TRUE)
library(lme4)
g3 <- glmer(y~x+(1|grp),data=d,family=poisson)
(f3 <- ff(g3))
g4 <- glmer(y~I(x-mx)+(1|grp),data=d,family=poisson)
(f4 <- ff(g4,FALSE))
cbind(f1,f2,f3,f4)

## stable-lme4, uncentered and centered;
## devel-lme4, uncentered and centered
##                   f1       f2       f3       f4
## (Intercept) 1.014301 1.019990 1.019982 1.019984
## x           1.999046 1.999055 1.999056 1.999056


From eric.d.stolen at nasa.gov  Fri Apr 12 02:45:21 2013
From: eric.d.stolen at nasa.gov (Stolen, D Eric  (KSC-IHA-4400)[InoMedic Health Applications, Inc.])
Date: Thu, 11 Apr 2013 19:45:21 -0500
Subject: [R-sig-ME] How to include temporal autocorrelation in GLMM?
Message-ID: <C4F0189B45EA6A43903ADBB756D6F2D2E5F87B1871@NDMSSCC08.ndc.nasa.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130411/09ad970f/attachment.pl>

From nic43614 at gmail.com  Fri Apr 12 05:17:20 2013
From: nic43614 at gmail.com (Nico N)
Date: Fri, 12 Apr 2013 13:17:20 +1000
Subject: [R-sig-ME] MCMCglmm multivariate multilevel meta-analysis
In-Reply-To: <20130411065918.105624xy76x578sg@www.staffmail.ed.ac.uk>
References: <CAAM7jk1O+L7zFhnYak9ScoY0qYW2dARN74XaS5326xm9pid+sQ@mail.gmail.com>
	<20130411065918.105624xy76x578sg@www.staffmail.ed.ac.uk>
Message-ID: <CAAM7jk1M4CrEyRBV-7DFwQAAQedu=NURhCVFPpizCGVaLqy=dQ@mail.gmail.com>

Hi Jarrod,

Thank you very much for your help - and also for writing and sharing
this highly flexible and powerful program (OMG - it's so fast in
comparison to WINBUGS)!

The code with the suggested matrix for the variances works!

You are right, in my case, I do not have information on covariances
and only provide the known variances to the meta-analysis.

Thanks too for the tips regarding the separate predictors for the
traits (this was very helpful information).

Cheers
Nico



On Thu, Apr 11, 2013 at 3:59 PM, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
> Hi Nico,
>
> You should just be able to pass c(dataset$var1, dataset$var2) to mev. If you
> have sampling covariances between the measures then its a bit more
> complicated, but I think you don't?
>
> There's also an in-built function for creating the dummy variables:
> at.level(trait,1):predictor1 fits an effect of predictor1 for trait 1, if
> you want to fit separate predictor1 effects for both traits you can just use
> trait:predictor1.
>
> Cheers,
>
> Jarrod
>
>
>
>
> Quoting Nico N <nic43614 at gmail.com> on Wed, 10 Apr 2013 21:47:09 +1000:
>
>> Hey everyone,
>>
>> Presently, I am trying to conduct a multivariate multilevel
>> meta-analysis using the MCMCglmm package.
>>
>> However, I encountered the following problem and I was hoping to
>> obtain some advice.
>>
>> The following example would describe my situation. The dependent
>> variable is some performance measure, which is captured in two
>> different ways (2 different measures for the same construct).
>>
>> Hence, I have two measures for each student, similar to the
>> multi-response model examples in the MCMCglmm tutorial notes.
>>
>> Moreover, I have a big data set with students nested in schools, and
>> schools nested in countries (3 additional levels).
>>
>> In sum, I require four levels (sorry, social science jargon I think):
>> level 1= measures, level2=students, level3=schools, and
>> level4=country.
>>
>> I only would like to have random-intercepts for each level above the
>> measure-level.
>>
>>
>> Now I think there may be two ways. Originally, the data is in the
>> "wide" format. That is:
>>
>> Columns headers are the following:  student, school, country, measure
>> 1, measure 2, var1 ,  var2, predictor1, predictor 2,?   (for
>> simplicity, let's assume two predictors only - both only fixed
>> effects).
>>
>>
>> Var2 and var2 are the known variances for the two measures of
>> interest. The variances need to be provided to the first level of the
>> model, while the estimated covariance matrix is fixed to 1. As far as
>> I understood, the "mev" command does this.
>>
>> Now, given the "wide" format, I noticed that MCMCglmm seems to have a
>> convenient way to estimate measure-specific intercepts through the
>> "trait"-command (i.e., without changing the data).
>>
>> If I am not wrong, the code would be as follows.
>>
>>
>> prior = list(R = list( V =diag(2), n=2,fix = 1), G = list(
>>
>>                        G1 = list ( V = diag(2), n = 2),
>>
>>                        G2 = list ( V = diag(2), n = 2),
>>
>>                        G3 = list ( V = diag(2), n = 2) ))
>>
>> model1 <- MCMCglmm( cbind(measure1, measure2) ~ -1 + trait +
>>
>>                                predictor1 +
>>
>>                                predictor2 ,
>>
>>                        random = ~us(trait):student +
>>
>>                                us(trait):school +
>>
>>                                idh(trait):country + ,
>>
>>                        rcov = ~idh(trait):units,
>>
>>                        prior=prior,
>>
>>                        data = dataset,
>>
>>                        mev= ?????,
>>
>>                        family = c("gaussian","gaussian"))
>>
>>
>> However, I was wondering how I can provide the variances to this model
>> with two measures? In my case, I would need a 2xn matrix and I am not
>> sure whether the "mev" command can handle this. Has anyone ever tried
>> something like this?
>>
>> I guess there would be an alternative, in case "mev" must be a 1xn
>> vector: I guess I could create the stacked (or long) data myself
>> before running the model. Then, as Hox (2010) recommends, one can
>> create dummy variables indicating to which measure the dependent
>> variable column (DV) refers to.
>>
>> In my case: MD1 for measure 1 and MD2 for measure2. Then, each
>> predictor would have to be multiplied with these two dummies, such
>> that it looks like the following table (pred=predictor):
>>
>> DV      measure var     MD1     MD2     student  school country  pred1
>> pred2   pred1XMD1 pred1XMD2    pred2XMD1   pred2XMD2
>> 3.4     1               0.2     1       0       1               1       1
>> 2       1.3     2                  0                         1.3
>> 0
>> 5.6     2               0.4     0       1       1               1       1
>> 3       1.4     0                  3                         0
>> 1.4
>> 6.7     1               0.5     1       0       2               1       1
>> 4       1.4     4                  0                         1.4
>> 0
>> 4.5     2               0.3     0       1       2               1       1
>> 4       1       0                  4                          0
>> 1
>> 5.5     1               0.5     1       0       3               1       1
>> 2       1.9     2                  0                         1.9
>> 0
>> 4.5     2               0.7     0       1       3               1       1
>> 4       1.6     0                  4                         0
>> 1.6
>> 6.7     1               0.6     1       0       4               2       1
>> 2       1.7     2                  0                         1.7
>> 0
>> 4.5     2               0.6     0       1       4               2       1
>> 4       1.3     0                  4                          0 1.3
>>
>>
>> Then, the following code should work (with same prior):
>>
>>
>> model2 <- MCMCglmm( DV ~ -1 + MD1 + MD2 +
>>
>>                                pred1xMD1 +
>>
>>                                pred1xMD2 +
>>
>>                                pred2xMD1 +
>>
>>                                pred2xMD2 +,
>>
>>                        random = ~us(MD1+MD2):student +
>>
>>                                us(MD1+MD2):school  +
>>
>>                                idh(MD1+MD2):country + ,
>>
>>                        rcov = ~idh(MD1+MD2):units,
>>
>>                        prior=prior,
>>
>>                        data = dataset,
>>
>>                        mev= dataset$var,
>>
>>                        family = "gaussian"))
>>
>>
>>
>> Now I wanted to check whether this seems sensible within the Bayesian
>> framework? ? I generally would prefer a solution for the
>> "model1"-approach above as I have many more predictors than in this
>> example.
>>
>> I would highly appreciate any comment! I can imagine that other people
>> may be interested in conducing a similar hierarchical multiresponse
>> meta-analysis.
>>
>>
>> Best regards
>>
>> Nico
>>
>> PhD-candidate
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>


From pauljohn32 at gmail.com  Fri Apr 12 17:33:52 2013
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Fri, 12 Apr 2013 10:33:52 -0500
Subject: [R-sig-ME] New Variant of Same Question: bias corrected logit
	estimates
Message-ID: <CAErODj-VqA7SzrB5pfNDoLh7ETNAJv-X70Fiqf12o3Nxx1Wt5w@mail.gmail.com>

Dear R-sig-mixed:

I was struck today by the way the Internet has accelerated research.
At one time, it might have taken a month or two to track down the
articles on this problem and conclude I need to ask for advice. Now,
however, I realize the need within hours.

Recall the question that started us debating a few days ago was a
logistic regression in which OP noticed the mis-match between the
predicted probability of success and the observed fraction.  We were
debating that, and it had completely slipped my mind that there is a
separate literature on exactly that kind of problem. Yesterday,
somebody else asked me to estimate a logit model in which there were
more than 40000 cases but only a few hundred "successes". That's what
reminded me of the "rare events" problem and logistic regression
parameter estimate bias.

And I think that's the issue that we need to clear up with glmer. What
do you think? Since multilevel model can be seen as a penalized ML
estimation (ala Pinheiro and Bates, or as explained in Simon Wood,
Generalized Additive Models), are we able to get a bias-corrected
variant?

Furthermore, could lme4's predict method be made to produce "good"
confidence intervals.  And that leads down a separate path to a huge
hassle about competing ways to estimate CI's in glm and the possible
need to appy extra corrections in some special cases. I'll write down
that problem to ask you about it later if you help me understand this
one.

Here's my brief novel on what I've been Googling about for the past 10
hours or so. If it helps you, let me know. If you think I'm wrong,
especially urgently let me know.

To the political science audience, that's a "rare events" logistic
regression problem, our most heavily cited methods paper on that is:

King, G., & Zeng, L. (2001). Logistic Regression in Rare Events Data.
Political Analysis, 9(2), 137?163.
http://pan.oxfordjournals.org/content/9/2/137.abstract

Logistic parameter estimates (mainly the intercept) are wrong and
estimated probabilities are wrong. King & Zeng provided Stata code for
a function "relogit" and later adapted same for R (package: Zelig).
Zelig tries to re-organize the whole regression experience for the R
user, and I didn't want that, so I started looking into the various
corrections to see if I couldn't write an adapter to take a glm or a
glmer output and "bias correct" it. It appears, superficially at
least, that I only need to adjust the intercept estimate by a
weighting factor, which would be super easy to do.

Quite by chance, I found this blog post by Paul Allison, and its
really interesting!

Logistic Regression for Rare Events (2012-02-13)
http://www.statisticalhorizons.com/logistic-regression-for-rare-events

And, wow, is it subtle. Read that over a few times, see if you agree
with me. In a kind way, he says the "rare events" business is a red
herring, and instead we need bias-corrected logistic regression
estimates. Use David Firth's method. The part about the  "prior
correction of the intercept" discussed in King and Zeng, is not the
best approach. Instead, we should see this as a symptom of the more
general problem that ML estimates are biased and the bias is greatest
when there are not too many "successes".  Allison suggests an
estimator proposed by David Firth, which used penalized ML.

Firth D. Bias reduction of maximum likelihood estimates. Biometrika
1993; 80:27?38

I don't think King and Zeng disagree, they also propose an option to
bias-correct the whole vector of coefficients. That bias correction
ends up addressing the more general problem. In the Stata module for
relogit (the version I found was dated 1999-10-28), it says ""Relogit
for Stata does not yet support the FIRTH option", but it does have an
alternative weighting correction.

While fiddling around to see if I could implement that, I learned it
has been done in R:

logistf: Firth's bias reduced logistic regression

http://cran.r-project.org/web/packages/logistf/index.html

That is often discussed as a solution to the problem of separation, as
on the UCLA stats website,
(http://www.ats.ucla.edu/stat/mult_pkg/faq/general/complete_separation_logit_models.htm)

Georg Heinze and Michael Schemper, A solution to the problem of
separation in logistic regression, Statistics in Medicine, 2002, vol.
21 2409-2419.

But it is a two-fer, so far as I can tell. We get bias correction and
separation-proofness.

Heinze, G., & Puhr, R. (2010). Bias-reduced and separation-proof
conditional logistic regression with small or sparse data sets.
Statistics in medicine, 29(7-8), 770?777. doi:10.1002/sim.3794

The part I don't understand (yet) is how the bias correction links to
mixed models. And that's why I'm asking you.

OK?

--
Paul E. Johnson
Professor, Political Science      Assoc. Director
1541 Lilac Lane, Room 504      Center for Research Methods
University of Kansas                 University of Kansas
http://pj.freefaculty.org               http://quant.ku.edu


From bbolker at gmail.com  Fri Apr 12 22:28:28 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 12 Apr 2013 20:28:28 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?New_Variant_of_Same_Question=3A_bias_correct?=
	=?utf-8?q?ed_logit=09estimates?=
References: <CAErODj-VqA7SzrB5pfNDoLh7ETNAJv-X70Fiqf12o3Nxx1Wt5w@mail.gmail.com>
Message-ID: <loom.20130412T222208-948@post.gmane.org>

Paul Johnson <pauljohn32 at ...> writes:

> 
> Dear R-sig-mixed:
> 
> I was struck today by the way the Internet has accelerated research.
> At one time, it might have taken a month or two to track down the
> articles on this problem and conclude I need to ask for advice. Now,
> however, I realize the need within hours.
> 
> Recall the question that started us debating a few days ago was a
> logistic regression in which OP noticed the mis-match between the
> predicted probability of success and the observed fraction.  We were
> debating that, and it had completely slipped my mind that there is a
> separate literature on exactly that kind of problem. Yesterday,
> somebody else asked me to estimate a logit model in which there were
> more than 40000 cases but only a few hundred "successes". That's what
> reminded me of the "rare events" problem and logistic regression
> parameter estimate bias.
> 
> And I think that's the issue that we need to clear up with glmer. What
> do you think? Since multilevel model can be seen as a penalized ML
> estimation (ala Pinheiro and Bates, or as explained in Simon Wood,
> Generalized Additive Models), are we able to get a bias-corrected
> variant?

  I don't really know the answer to the full question, but I would
venture this:

  * There is no explicit bias-reduction capacity built into the
fixed-effects estimation component of glmer
 * I'm aware of Firth's algorithm and have used the R implementations
but haven't read the paper/don't know the details
 * glmer does handle some of the typical problems with 'rare events'
by doing shrinkage across random effects, but if the events are
rare in the *entire* data set (and not just in individual/small/
undersample regions), I don't think that will help
 * Vince Dorie and Andrew Gelman's blme package, or Jarrod Hadfield's
MCMCglmm package, could be used with more or less informative priors
to achieve a degree of shrinkage.

  I don't know whether there's a clever way to adapt glmer
itself to do shrinkage/bias correction on a single sample.

  Hopefully others with more knowledge will chime in.


From datkins at u.washington.edu  Sat Apr 13 02:01:28 2013
From: datkins at u.washington.edu (David Atkins)
Date: Fri, 12 Apr 2013 17:01:28 -0700
Subject: [R-sig-ME] New Variant of Same Question: bias corrected logit
 estimates
In-Reply-To: <CAErODj-VqA7SzrB5pfNDoLh7ETNAJv-X70Fiqf12o3Nxx1Wt5w@mail.gmail.com>
References: <CAErODj-VqA7SzrB5pfNDoLh7ETNAJv-X70Fiqf12o3Nxx1Wt5w@mail.gmail.com>
Message-ID: <5168A058.6030605@u.washington.edu>


Paul--

I should state upfront that I didn't read the previous thread closely, 
but I *thought* that the primary issue related to conditional vs. 
marginal effects -- where GLMMs (with non-identity link) functions yield 
conditional fixed-effects (i.e., they do not 'average over' the 
random-effects, but are conditional on particular values of the 
random-effects).

This shows up periodically on the listserv, e.g.,

https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q1/015736.html

Though, perhaps your point below was in the later traffic in that thread 
(and if so, please disregard!).

cheers, Dave
-- 
Dave Atkins, PhD

Department of Psychiatry and Behavioral Science
University of Washington
datkins at u.washington.edu
206-616-3879 	
http://depts.washington.edu/cshrb/

"We are drowning in information and starving for knowledge."
Rutherford Roger


Paul wrote:

Dear R-sig-mixed:

I was struck today by the way the Internet has accelerated research.
At one time, it might have taken a month or two to track down the
articles on this problem and conclude I need to ask for advice. Now,
however, I realize the need within hours.

Recall the question that started us debating a few days ago was a
logistic regression in which OP noticed the mis-match between the
predicted probability of success and the observed fraction.  We were
debating that, and it had completely slipped my mind that there is a
separate literature on exactly that kind of problem. Yesterday,
somebody else asked me to estimate a logit model in which there were
more than 40000 cases but only a few hundred "successes". That's what
reminded me of the "rare events" problem and logistic regression
parameter estimate bias.

And I think that's the issue that we need to clear up with glmer. What
do you think? Since multilevel model can be seen as a penalized ML
estimation (ala Pinheiro and Bates, or as explained in Simon Wood,
Generalized Additive Models), are we able to get a bias-corrected
variant?

Furthermore, could lme4's predict method be made to produce "good"
confidence intervals.  And that leads down a separate path to a huge
hassle about competing ways to estimate CI's in glm and the possible
need to appy extra corrections in some special cases. I'll write down
that problem to ask you about it later if you help me understand this
one.

Here's my brief novel on what I've been Googling about for the past 10
hours or so. If it helps you, let me know. If you think I'm wrong,
especially urgently let me know.

To the political science audience, that's a "rare events" logistic
regression problem, our most heavily cited methods paper on that is:

King, G., & Zeng, L. (2001). Logistic Regression in Rare Events Data.
Political Analysis, 9(2), 137?163.
http://pan.oxfordjournals.org/content/9/2/137.abstract

Logistic parameter estimates (mainly the intercept) are wrong and
estimated probabilities are wrong. King & Zeng provided Stata code for
a function "relogit" and later adapted same for R (package: Zelig).
Zelig tries to re-organize the whole regression experience for the R
user, and I didn't want that, so I started looking into the various
corrections to see if I couldn't write an adapter to take a glm or a
glmer output and "bias correct" it. It appears, superficially at
least, that I only need to adjust the intercept estimate by a
weighting factor, which would be super easy to do.

Quite by chance, I found this blog post by Paul Allison, and its
really interesting!

Logistic Regression for Rare Events (2012-02-13)
http://www.statisticalhorizons.com/logistic-regression-for-rare-events

And, wow, is it subtle. Read that over a few times, see if you agree
with me. In a kind way, he says the "rare events" business is a red
herring, and instead we need bias-corrected logistic regression
estimates. Use David Firth's method. The part about the  "prior
correction of the intercept" discussed in King and Zeng, is not the
best approach. Instead, we should see this as a symptom of the more
general problem that ML estimates are biased and the bias is greatest
when there are not too many "successes".  Allison suggests an
estimator proposed by David Firth, which used penalized ML.

Firth D. Bias reduction of maximum likelihood estimates. Biometrika
1993; 80:27?38

I don't think King and Zeng disagree, they also propose an option to
bias-correct the whole vector of coefficients. That bias correction
ends up addressing the more general problem. In the Stata module for
relogit (the version I found was dated 1999-10-28), it says ""Relogit
for Stata does not yet support the FIRTH option", but it does have an
alternative weighting correction.

While fiddling around to see if I could implement that, I learned it
has been done in R:

logistf: Firth's bias reduced logistic regression

http://cran.r-project.org/web/packages/logistf/index.html

That is often discussed as a solution to the problem of separation, as
on the UCLA stats website,
(http://www.ats.ucla.edu/stat/mult_pkg/faq/general/complete_separation_logit_models.htm)

Georg Heinze and Michael Schemper, A solution to the problem of
separation in logistic regression, Statistics in Medicine, 2002, vol.
21 2409-2419.

But it is a two-fer, so far as I can tell. We get bias correction and
separation-proofness.

Heinze, G., & Puhr, R. (2010). Bias-reduced and separation-proof
conditional logistic regression with small or sparse data sets.
Statistics in medicine, 29(7-8), 770?777. doi:10.1002/sim.3794

The part I don't understand (yet) is how the bias correction links to
mixed models. And that's why I'm asking you.

OK?

--
Paul E. Johnson
Professor, Political Science      Assoc. Director
1541 Lilac Lane, Room 504      Center for Research Methods
University of Kansas                 University of Kansas
http://pj.freefaculty.org               http://quant.ku.edu


From clivelists at googlemail.com  Sat Apr 13 01:11:59 2013
From: clivelists at googlemail.com (Clive Nicholas)
Date: Sat, 13 Apr 2013 00:11:59 +0100
Subject: [R-sig-ME] Solution to fitting -lme4- models with lagged variables
Message-ID: <CAHs5aThc5h+zv4od8PcYiOOtvrFiGt_LOLAjUxa87Lo1SgHUVw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130413/2f4c8e18/attachment.pl>

From bbolker at gmail.com  Sun Apr 14 18:10:54 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 14 Apr 2013 16:10:54 +0000 (UTC)
Subject: [R-sig-ME] Solution to fitting -lme4- models with lagged
	variables
References: <CAHs5aThc5h+zv4od8PcYiOOtvrFiGt_LOLAjUxa87Lo1SgHUVw@mail.gmail.com>
Message-ID: <loom.20130414T180736-942@post.gmane.org>

Clive Nicholas <clivelists at ...> writes:

[snip]
 
> > library(lme4)
> >
> dd=transform(Dyestuff,lagY1=c(NA,head(Yield,-1)),
>                       lagY2=c(rep(NA,2),head(Yield,-2)),
>                         lagY3=c(rep(NA,3),head(Yield,-3)))

  The stuff below is a little bit redundant: if you use

(fit=lmer(Yield~1+lagY1+lagY2+lagY3+(1|Batch),data=dd,REML=T))

then you don't need the other definitions of the lag variables.

  Even more compactly you could define a function:

mylag <- function(x,lag) {
  c(rep(NA,lag),head(x,-lag))
}

dd=transform(Dyestuff,lagY1=mylag(Yield,1),
                      lagY2=mylag(Yield,2),
                      lagY3=mylag(Yield,3))

It's (IMO) a bit of a pity that the built-in lag() function
only works with the (fairly limited) built-in time-series
functionality in R ...


From torrensleyre at hotmail.com  Mon Apr 15 07:36:58 2013
From: torrensleyre at hotmail.com (Graeme Armstrong)
Date: Mon, 15 Apr 2013 15:36:58 +1000
Subject: [R-sig-ME] Power test in PAMM
Message-ID: <SNT129-W6006623F106AD046B592B2CBCC0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130415/a65b96be/attachment.pl>

From nospamjehol-lists at yahoo.fr  Mon Apr 15 06:59:07 2013
From: nospamjehol-lists at yahoo.fr (nospamjehol-lists at yahoo.fr)
Date: Mon, 15 Apr 2013 05:59:07 +0100 (BST)
Subject: [R-sig-ME] Random effect on main effect only when testing
	interaction
Message-ID: <1366001947.7998.YahooMailNeo@web133203.mail.ir2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130415/3df8fdb1/attachment.pl>

From aidan.macnamara at gmail.com  Mon Apr 15 15:30:12 2013
From: aidan.macnamara at gmail.com (Aidan MacNamara)
Date: Mon, 15 Apr 2013 14:30:12 +0100
Subject: [R-sig-ME] lme4 and mcmcsamp
Message-ID: <CACMT3uCOcDh7wcrweReWAi10L88W8ssR0W_Oav+1eRx75Zx78w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130415/4462f259/attachment.pl>

From djmuser at gmail.com  Tue Apr 16 03:48:53 2013
From: djmuser at gmail.com (Dennis Murphy)
Date: Mon, 15 Apr 2013 18:48:53 -0700
Subject: [R-sig-ME] lme4 and mcmcsamp
In-Reply-To: <CACMT3uCOcDh7wcrweReWAi10L88W8ssR0W_Oav+1eRx75Zx78w@mail.gmail.com>
References: <CACMT3uCOcDh7wcrweReWAi10L88W8ssR0W_Oav+1eRx75Zx78w@mail.gmail.com>
Message-ID: <CADv2QyGjbQDAa7a=0pVrWmwHuF2V62Nn_7_jnhbPeNbC9kcugw@mail.gmail.com>

See
http://glmm.wikidot.com/faq

especially the paragraph with the small header 'Status of mcmcsamp'.

Dennis

On Mon, Apr 15, 2013 at 6:30 AM, Aidan MacNamara
<aidan.macnamara at gmail.com> wrote:
> Dear all,
>
> Sorry if I'm missing something but for lme4 0.99999911-2, R 3.0 with OSX
> (10.8.3), lme4::mcmcsamp doesn't seem to be present anymore (the
> documentation for the function is there but not the function?). Is this
> function phased out or maybe it's more straightforward?
>
> Many thanks, Aidan
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Tue Apr 16 06:07:05 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 16 Apr 2013 04:07:05 +0000 (UTC)
Subject: [R-sig-ME] How to include temporal autocorrelation in GLMM?
References: <C4F0189B45EA6A43903ADBB756D6F2D2E5F87B1871@NDMSSCC08.ndc.nasa.gov>
Message-ID: <loom.20130416T055915-773@post.gmane.org>

Stolen, D Eric  (KSC-IHA-4400)[InoMedic Health Applications, Inc.]
<eric.d.stolen at ...> writes:

>  Dear List; I am analyzing a large data set on lemon shark
> detection/nondetection on a sonic telemetry array. The response
> variable is binomial and I am using a GLMM to account for the
> effects of individual shark (49 levels) and month nested within year
> (over 4 years). We considered several a priori structures for the
> fixed effects and model selection based on AIC showed a clear winner
> among the a priori models:
 
> glmer(detect ~ dalCat + dtemp3d + daylength + (1|shark) +
  (1|Year/month), family = binomial, data = Lemon3)

> However, the detection/nondetection was measured daily and using
> acf() on the residuals of the best GLMM, there is evidence of
> correlation over the range of 1-4 days for many of the sharks. To
> remedy this I thought of creating a set of variables which code the
> detection/nondetection for the previous 1-7 days and including them
> among the fixed effects. I created these variables, then compared
> AIC of models with all the fixed effects in the previous best model,
> plus none, 1, 2,..etc. of these autocorrelation variables.  The
> model with autocorrelation variables for previous 1-4 days was best,
> and all models with these variables outperformed the models without
> them (based on AIC). The effect sizes for the fixed effects from the
> previously considered best model are all reduced but still signific
> ant (they have decent SE). I don't think that this approach is
> correcting for the autocorrelation in regards to the variance, but
> perhaps they give more reliable estimates of effect size and SE.
 
> My questions are: does this approach make sense, and does anyone
>  know of any references that used this approach?


  It makes sense to me.   The only potential difficulty is that
it relates the _detection_ on day d to _detection_ on days d-1, d-2, ...
It would make more sense, but would be considerably more difficult
(I think you'd need WinBUGS or Stan or your own MCMC code of some sort),
to relate a latent variable giving the _presence_ on day d to _presence_
on previous days.  In other words, this works fine as long as you
assume that there is no observation error (no chance of detection
failure, or [perhaps less likely] false positives).

  Ben Bolker


From joseph.bulbulia at icloud.com  Tue Apr 16 07:07:12 2013
From: joseph.bulbulia at icloud.com (Joseph Bulbulia)
Date: Tue, 16 Apr 2013 17:07:12 +1200
Subject: [R-sig-ME] How to deal with outcomes assessed by raters?
Message-ID: <C573AAD4-980C-4F5A-88F2-C9D8BCBC93FA@icloud.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130416/44919dfd/attachment.pl>

From chris at trickysolutions.com.au  Tue Apr 16 08:17:08 2013
From: chris at trickysolutions.com.au (Chris Howden)
Date: Tue, 16 Apr 2013 16:17:08 +1000
Subject: [R-sig-ME] How to deal with outcomes assessed by raters?
In-Reply-To: <C573AAD4-980C-4F5A-88F2-C9D8BCBC93FA@icloud.com>
References: <C573AAD4-980C-4F5A-88F2-C9D8BCBC93FA@icloud.com>
Message-ID: <52044a24049fa4dfd982b055810b0c3d@mail.gmail.com>

I'm no expert, but I believe that with only 4 judges that's not enough to
get an accurate estimate of the variability associated with judges.

So U may be better to include them as fixed effects with 4 levels.

That said if U just want a random intercept for each judge and don't want
an accurate measure of their variance it may still be OK to include them
as a random effect? But I'm a little unclear on this point myself.

Chris Howden B.Sc. (Hons) GStat.
Founding Partner
Evidence Based Strategic Development, IP Commercialisation and Innovation,
Data Analysis, Modelling and Training
(mobile) 0410 689 945
(fax) +612 4782 9023
chris at trickysolutions.com.au




Disclaimer: The information in this email and any attachments to it are
confidential and may contain legally privileged information.?If you are
not the named or intended recipient, please delete this communication and
contact us immediately.?Please note you are not authorised to copy, use or
disclose this communication or any attachments without our consent.
Although this email has been checked by anti-virus software, there is a
risk that email messages may be corrupted or infected by viruses or other
interferences. No responsibility is accepted for such interference. Unless
expressly stated, the views of the writer are not those of the company.
Tricky Solutions always does our best to provide accurate forecasts and
analyses based on the data supplied, however it is possible that some
important predictors were not included in the data sent to us. Information
provided by us should not be solely relied upon when making decisions and
clients should use their own judgement.


-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Joseph
Bulbulia
Sent: Tuesday, 16 April 2013 3:07 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] How to deal with outcomes assessed by raters?

Hi all,

Id like to model emotional dynamics in a highly arousing firewalk ritual.


Four judges rated images from 42 participants for arousal and valence. The
predictor variables are ritual phase and role.

Question 1
Any thoughts about how best to handle the rater assessments?

Specifically, is it nuts to explicitly include a component for raters in
the random component of the model?

E.g.

library(MCMCglmm)
prior.fw.0 = list(
  B = list(mu=rep(0,4),V = diag(4)*1e+10),
  R = list(V =diag(2), fix = 1),
  G = list(G1 = list(V = diag(2), n = 2, alpha.mu = c(0,0), alpha.V =
diag(2)*1000),
           G2 = list (V = diag(2),n = 2, alpha.mu = c(0,0), alpha.V =
diag(2)*1000),
           G3 = list (V = diag(2),  fix=1)))


firemodel.test <-MCMCglmm(cbind(arousal, valence) ~ trait:role:trait:phase
-1,
                          random = ~us(trait):phase:id
                          + idh(trait):event:id
                          + idh(trait):rater,
                          rcov= ~ idh(trait):units,
                          family = rep("ordinal",2),
                          data=Firewalkdata, burnin=5000,
                          thin = 10,
                          nitt=20000,
                          prior=prior.fw.0)



Thanks everyone. Very grateful for and advice.

Joseph


Disclaimer
I'm new to GLMMs,so apologies if this doesn't make sense.

Data sample below
(Only 20 data points, just to get a sense of the structure)

Firewalkdata <- structure(list(obs = c("1", "2", "3", "4", "5", "6", "7",
"8", "9", "10", "11", "12", "13", "14", "15", "16", "17", "18", "19",
"20"), id = structure(c(24L, 4L, 26L, 37L, 32L, 3L, 20L, 9L, 3L, 2L, 5L,
19L, 23L, 28L, 29L, 8L, 3L, 18L, 40L, 26L), .Label = c("a", "b", "c", "d",
"e", "f", "g", "h", "i", "j", "k", "l", "m", "n", "o", "p", "pa", "pb",
"pc", "pd", "pe", "pf", "pg", "ph", "pi", "pj", "pk", "pl", "pm", "pn",
"po", "pp", "q", "r", "s", "t", "u", "v", "w", "x", "y"), class =
"factor"), phase = c(1, 2, 5, 5, 2, 3, 1, 4, 5, 2, 5, 1, 5, 4, 3, 4, 5, 3,
2, 4), event = structure(c(11L, 4L, 13L, 21L, 22L, 3L, 4L, 9L, 3L, 2L, 5L,
3L, 9L, 16L, 17L, 8L, 3L, 2L, 24L, 13L), .Label = c("a", "b", "c", "d",
"e", "f", "g", "h", "i", "j", "k", "l", "m", "n", "o", "p", "q", "r", "s",
"t", "u", "v", "w", "x", "y"), class = "factor"), role = structure(c(2L,
1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 1L,
2L), .Label = c("FW", "PS"), class = "factor"), dyad = structure(c(2L, 2L,
2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L),
.Label = c("n", "y"), class = "factor"), gender = structure(c(1L, 2L, 2L,
2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 2L, 2L),
.Label = c("f", "m"), class = "factor"), rater = structure(c(4L, 1L, 3L,
1L, 3L, 4L, 1L, 2L, 4L, 3L, 4L, 3L, 4L, 1L, 1L, 4L, 4L, 1L, 4L, 4L),
.Label = c("rat1", "rat2", "rat3", "rat4"), class = "factor"),
    arousal = c(4, 5, NA, 6, 6, 6, 4, 4, 7, 4, 3, 7, 5, 5, 5,
    6, 5, NA, 4, 6), valence = c(4, 3, NA, 2, 6, 1, 2, 6, 3,
    5, 5, 7, 5, 2, 2, 1, 4, NA, 4, 6)), .Names = c("obs", "id", "phase",
"event", "role", "dyad", "gender", "rater", "arousal", "valence"),
row.names = c(3977L, 83L, 2996L, 525L, 3134L, 3213L, 726L, 1267L, 3221L,
2134L, 3273L, 2801L, 3975L, 944L, 964L, 3344L, 3223L, 688L, 3758L, 4041L),
class = "data.frame")


IMAGE SAMPLE (for the curious)
https://www.dropbox.com/s/xmbci5814h73i0l/4_MF_e5.png

GRAPH bootstrapped means
https://www.dropbox.com/s/509sgh5zqxq18tn/Figure_FireWalk.pdf

Crude overview of the design
https://www.dropbox.com/s/0o0a9kkrh5ttsd2/plot.plan.emotions_firewalk.pdf




Joseph Bulbulia
Senior Lecturer, Religious Studies
Faculty of Humanities and Social Sciences Victoria University, New Zealand
+64 21 95 94 23
http://www.metaphysicalclub.com




	[[alternative HTML version deleted]]


From David.Duffy at qimr.edu.au  Tue Apr 16 10:05:07 2013
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Tue, 16 Apr 2013 18:05:07 +1000
Subject: [R-sig-ME] How to deal with outcomes assessed by raters?
In-Reply-To: <C573AAD4-980C-4F5A-88F2-C9D8BCBC93FA@icloud.com>
References: <C573AAD4-980C-4F5A-88F2-C9D8BCBC93FA@icloud.com>
Message-ID: <alpine.LMD.2.00.1304161746450.25458@orpheus.qimr.edu.au>

On Tue, 16 Apr 2013, Joseph Bulbulia wrote:

> Hi all,
>
> I?d like to model emotional dynamics in a highly arousing firewalk ritual.
>
> Four judges rated images from 42 participants for arousal and valence. The predictor variables are ritual ?phase? and ?role.?
>
> Question 1
> Any thoughts about how best to handle the rater assessments?
>
> Specifically, is it nuts to explicitly include a component for raters in the random component of the model?

So what do the inter-rater agreements look like?  I presume rater is 
actually a nuisance variable?  The path model I would usually use would 
have phase and role acting on the averaged-over-raters a and v 
scores (measurement model bit).

Just 2c, David Duffy.


From joseph.bulbulia at icloud.com  Tue Apr 16 11:50:39 2013
From: joseph.bulbulia at icloud.com (Joseph Bulbulia)
Date: Tue, 16 Apr 2013 21:50:39 +1200
Subject: [R-sig-ME] How to deal with outcomes assessed by raters?
In-Reply-To: <alpine.LMD.2.00.1304161746450.25458@orpheus.qimr.edu.au>
References: <C573AAD4-980C-4F5A-88F2-C9D8BCBC93FA@icloud.com>
	<alpine.LMD.2.00.1304161746450.25458@orpheus.qimr.edu.au>
Message-ID: <69C7CCF0-DCFB-47C5-9EAF-86FD473FE0E2@icloud.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130416/c2cf1fcf/attachment.pl>

From elinorjochum at hotmail.com  Tue Apr 16 01:38:14 2013
From: elinorjochum at hotmail.com (Elinor McGrath)
Date: Mon, 15 Apr 2013 16:38:14 -0700
Subject: [R-sig-ME] Residuals in lmer and glmmADMB
Message-ID: <BLU174-W28081614EDC674AD913D7ECACC0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130415/c49ce5eb/attachment.pl>

From nicolas.gavoille at univ-rennes1.fr  Tue Apr 16 13:09:03 2013
From: nicolas.gavoille at univ-rennes1.fr (Nicolas Gavoille)
Date: Tue, 16 Apr 2013 13:09:03 +0200
Subject: [R-sig-ME] Question about Multilevel ZIP model with glmmADMB
Message-ID: <20130416130903.1380794w1p6bkpjj@webmail.univ-rennes1.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130416/ab345408/attachment.pl>

From pharriso at uwaterloo.ca  Tue Apr 16 16:59:33 2013
From: pharriso at uwaterloo.ca (Philip Harrison)
Date: Tue, 16 Apr 2013 10:59:33 -0400
Subject: [R-sig-ME] lme4 crossed random effects predictions
Message-ID: <20130416105933.15004mrxvpj0p668@www.nexusmail.uwaterloo.ca>

Hi,

I am attempting to reproduce the code from glmm wikidot in order to  
get predictions for a crossed random effects model made in lme4  
http://glmm.wikidot.com/faq

library(lme4)
library(ggplot2) # Plotting
data("Orthodont",package="MEMSS")
fm1 <- lmer(
     formula = distance ~ age*Sex + (age|Subject)
     , data = Orthodont
)
newdat <- expand.grid(
     age=c(8,10,12,14)
     , Sex=c("Male","Female")
     , distance = 0
)
mm <- model.matrix(terms(fm1),newdat)
newdat$distance <- mm %*% fixef(fm1)
pvar1 <- diag(mm %*% tcrossprod(vcov(fm1),mm))
tvar1 <- pvar1+VarCorr(fm1)$Subject[1]  ## must be adapted for more  
complex models

anyone have any ideas on how I might adapt the tvar1 code for a  
partially crossed random effects model effects model. ie a  
(1|subjecti)+(1|subjectj) random effect structure?

I am actually going to use the multcomp package to look at significant  
differences between my categorical fixed effects levels- but i would  
like to get a visualisation of the data with the prediction method.

Thanks for your time

Phil H


From richard.asturia at gmail.com  Tue Apr 16 19:58:18 2013
From: richard.asturia at gmail.com (Richard Asturia)
Date: Tue, 16 Apr 2013 14:58:18 -0300
Subject: [R-sig-ME] Cross-level interaction must include constitutive terms
 of interactions in the following code?
Message-ID: <CA+xNL7p+7jL74S1JwAgu+FgRo7i+D2OzNEUg=By=iOu-BpAzPQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130416/a96c8ce8/attachment.pl>

From mauritsvzb at gmail.com  Wed Apr 17 15:22:40 2013
From: mauritsvzb at gmail.com (Maurits van Zinnicq Bergmann)
Date: Wed, 17 Apr 2013 15:22:40 +0200
Subject: [R-sig-ME] Checking for outliers in a glmer (lme4 package)
 containing multiple random factors
Message-ID: <CAH1d=mfddHop4p=x1tuhjO9MtZZ7zYS8ibVd_j4yJoASE6eMZg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130417/b254cbce/attachment.pl>

From fvargas.reeve at gmail.com  Wed Apr 17 16:43:33 2013
From: fvargas.reeve at gmail.com (Felipe Vargas Reeve)
Date: Wed, 17 Apr 2013 11:43:33 -0300
Subject: [R-sig-ME] How can I optimize the performance of mixed models?
Message-ID: <CABFQCKnfM3cA95vdkrDh9n94UWwrECvKe840=nGX+LeLg00feg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130417/626254d5/attachment.pl>

From malsburg at gmail.com  Wed Apr 17 17:40:32 2013
From: malsburg at gmail.com (Titus von der Malsburg)
Date: Wed, 17 Apr 2013 17:40:32 +0200
Subject: [R-sig-ME] How can I optimize the performance of mixed models?
In-Reply-To: <CABFQCKnfM3cA95vdkrDh9n94UWwrECvKe840=nGX+LeLg00feg@mail.gmail.com>
References: <CABFQCKnfM3cA95vdkrDh9n94UWwrECvKe840=nGX+LeLg00feg@mail.gmail.com>
Message-ID: <877gk1rwr3.fsf@gmail.com>



Packages like parallel allow you to create temporary copies the current
R process such that the various copies can work on different problems
(using differnt cores).  Technically, that's similar to running several
instances of R in parallel, just more convenient because R automatically
collects the results of the parallel computations in the parent process. 

As you suspected, the execution of a single function like lmer can't be
split up with these packages.  Automatic parallelization of code written
for a single execution thread is a very hard problem.  In many cases
it's even impossible.  Therefore, in order to make use of several cores,
lmer would have to be rewritten in some way, which may also not be
trivial.  So, I'm afraid it's currently not possible to use several
cores and it's very likely going to stay that way for at least some
time.

For now, I can offer only two ideas: 1.) If you have to run several
models, e.g. for different dependent variables, you can use parallel to
fit these models concurrently, each on one core.  2.) If your models are
fit on very large data sets, it may happen that your computer is running
out of RAM.  In this case, the operating system will extend the RAM
using disk space.  The problem with that is that hard disks are several
orders of magnitude slower than RAM and therefore everything will slow
down to a crawl.  The solution is then to extend the RAM of your
computer.  RAM is cheap but you have to make sure that you have a 64 bit
operating system.  32 bit operating systems can't make use of RAM
capacities larger than 4 GB.  There is probably an upper limit to how
much RAM R can use but I don't know that from the top of my head.  If
your problem really is RAM, then extending RAM will give you a
tremendous speed-up.

Good luck!

  Titus

Felipe Vargas Reeve writes:
>    Hi everyone, I want to know if somebody can help me with this: A
> methodology to increase the performance of R to achieve the convergence in
> lmer or nlme moldels.
>
>    Actually even if the computer presents more than one core I have read
> that R works with only one of them. Also I have read about the existence of
> packages (Eg. parallel) that can improve the speed of the computer. This is
> based in using all the cores of the pc, but I think this works for
> independent functions and it does not optimize only one process like in the
> case of the linear mixed model.
>
> Thanks for your help guys,
>
> Regards
> Felipe.
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Dr. Titus von der Malsburg
DFG Research Group 868: Mind and Brain Dynamics
Dept. of Linguistics, University of Potsdam
http://www.ling.uni-potsdam.de/~malsburg/


From adeline.buisset at gmail.com  Wed Apr 17 18:50:06 2013
From: adeline.buisset at gmail.com (adeline buisset)
Date: Wed, 17 Apr 2013 18:50:06 +0200
Subject: [R-sig-ME] Trouble with random effect in nlme
Message-ID: <CAOFar=KLWR7_a6kvJsNtHLaM0=WG=acVJ4zBvHgL29_Edt15eA@mail.gmail.com>

Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : non disponible
URL : <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130417/c9ffcebe/attachment.pl>

From Yan.Boulanger at RNCan-NRCan.gc.ca  Wed Apr 17 20:14:11 2013
From: Yan.Boulanger at RNCan-NRCan.gc.ca (Boulanger, Yan)
Date: Wed, 17 Apr 2013 18:14:11 +0000
Subject: [R-sig-ME] Unbalanced design mixed models
Message-ID: <D3557409FD94BA41AE028A1E573716D646FAA59D@S-BSC-MBX2.nrn.nrcan.gc.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130417/38a45bb8/attachment.pl>

From pauljohn32 at gmail.com  Thu Apr 18 06:08:39 2013
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Wed, 17 Apr 2013 23:08:39 -0500
Subject: [R-sig-ME] Unbalanced design mixed models
In-Reply-To: <D3557409FD94BA41AE028A1E573716D646FAA59D@S-BSC-MBX2.nrn.nrcan.gc.ca>
References: <D3557409FD94BA41AE028A1E573716D646FAA59D@S-BSC-MBX2.nrn.nrcan.gc.ca>
Message-ID: <CAErODj-7E8JV=jd+jqy3RTCwwmYka3MRiGSxJm0yQZGSZ=-3TA@mail.gmail.com>

Hi, I've wondered the same thing.  Others who can actually explain
*why* the estimator of the variance component is consistent even when
sample groups are badly unbalanced will hopefully speak up. I can't
justify it, but I've stared pretty hard at some of the classic
articles on it. The last two below are classics, by a frequent
participant in this list :)  I expect that if you sharpen up your
question a bit, you could ask again and get very sharp answers.

Harville, D. A. (1977). Maximum Likelihood Approaches to Variance
Component Estimation and to Related Problems. Journal of the American
Statistical Association, 72(358), 320?338. doi:10.2307/2286796

Jennrich, R. I., & Schluchter, M. D. (1986). Unbalanced
Repeated-Measures Models with Structured Covariance Matrices.
Biometrics, 42(4), 805?820. doi:10.2307/2530695

Pinheiro, J. C., & Bates, D. M. (1995). Approximations to the
Log-Likelihood Function in the Nonlinear Mixed-Effects Model. Journal
of Computational and Graphical Statistics, 4(1), 12?35.
doi:10.2307/1390625

Lindstrom, M. J., & Bates, D. M. (1988). Newton-Raphson and EM
Algorithms for Linear Mixed-Effects Models for Repeated-Measures Data.
Journal of the American Statistical Association, 83(404), 1014?1022.
doi:10.2307/2290128

pj


On Wed, Apr 17, 2013 at 1:14 PM, Boulanger, Yan
<Yan.Boulanger at rncan-nrcan.gc.ca> wrote:
> Hi folks,
>
> This seems a very (I mean very...) basic mixed model question but I would like to have your feeling about this. I start from scratch with mixed models. I'm fitting this very simple mixed model:
>
> fm1 <- lmer(dbh_tree ~ log(age_tree) + (1|plot_name), PICE.MAR_tree)
>
> where dbh_tree is the diameter at breast height of a tree, age_tree the age of the tree at bh, plot_name is the plot where the tree was sampled and PICE.MAR_tree, my dataset. This is not an experimental setup where a fixed number of trees was sampled per plot. Indeed, some plots have as high as 150 trees (very few...) whereas others has only 1... At that is the (well one of the...) problem. How may I fit a mixed model where, in several cases, well, maybe 50%, there is only 1 tree per level of the random factor ? So, no variation within the random factor... I could forget the random factor but of course, this would lead to "partial" pseudoreplication. On the other hand, I could drop all plots with only one tree but this would discard about half of the plots. Am I right when I say that the coefficients (for the fixed variables) are unbiased when not considering the random factor ? Indeed, I'm not interested in CI but "only" to fixed variable coefficients.
>
> Many thanks,
>
> Yan
>
> Yan Boulanger, Postdoctoral Visiting Fellow
> Ressources Naturelles Canada, Canadian Forest Service
> Centre de Foresterie des Laurentides
> 1055, rue du P.E.P.S.
> C.P. 10380, succ. Sainte-Foy
> Qu?bec (Qu?bec) Canada
> G1V 4C7
> Tel. : +1 418 649-6859
>
>
>
>         [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Paul E. Johnson
Professor, Political Science      Assoc. Director
1541 Lilac Lane, Room 504      Center for Research Methods
University of Kansas                 University of Kansas
http://pj.freefaculty.org               http://quant.ku.edu


From baud-bovy.gabriel at hsr.it  Thu Apr 18 07:33:31 2013
From: baud-bovy.gabriel at hsr.it (Gabriel Baud-Bovy)
Date: Thu, 18 Apr 2013 14:33:31 +0900
Subject: [R-sig-ME] How can I optimize the performance of mixed models?
In-Reply-To: <877gk1rwr3.fsf@gmail.com>
References: <CABFQCKnfM3cA95vdkrDh9n94UWwrECvKe840=nGX+LeLg00feg@mail.gmail.com>
	<877gk1rwr3.fsf@gmail.com>
Message-ID: <516F85AB.70903@hsr.it>

Another idea might be to use parallellization for bootsrap.
Best,
Gabriel

On 4/18/2013 12:40 AM, Titus von der Malsburg wrote:
>
> Packages like parallel allow you to create temporary copies the current
> R process such that the various copies can work on different problems
> (using differnt cores).  Technically, that's similar to running several
> instances of R in parallel, just more convenient because R automatically
> collects the results of the parallel computations in the parent process.
>
> As you suspected, the execution of a single function like lmer can't be
> split up with these packages.  Automatic parallelization of code written
> for a single execution thread is a very hard problem.  In many cases
> it's even impossible.  Therefore, in order to make use of several cores,
> lmer would have to be rewritten in some way, which may also not be
> trivial.  So, I'm afraid it's currently not possible to use several
> cores and it's very likely going to stay that way for at least some
> time.
>
> For now, I can offer only two ideas: 1.) If you have to run several
> models, e.g. for different dependent variables, you can use parallel to
> fit these models concurrently, each on one core.  2.) If your models are
> fit on very large data sets, it may happen that your computer is running
> out of RAM.  In this case, the operating system will extend the RAM
> using disk space.  The problem with that is that hard disks are several
> orders of magnitude slower than RAM and therefore everything will slow
> down to a crawl.  The solution is then to extend the RAM of your
> computer.  RAM is cheap but you have to make sure that you have a 64 bit
> operating system.  32 bit operating systems can't make use of RAM
> capacities larger than 4 GB.  There is probably an upper limit to how
> much RAM R can use but I don't know that from the top of my head.  If
> your problem really is RAM, then extending RAM will give you a
> tremendous speed-up.
>
> Good luck!
>
>    Titus
>
> Felipe Vargas Reeve writes:
>>     Hi everyone, I want to know if somebody can help me with this: A
>> methodology to increase the performance of R to achieve the convergence in
>> lmer or nlme moldels.
>>
>>     Actually even if the computer presents more than one core I have read
>> that R works with only one of them. Also I have read about the existence of
>> packages (Eg. parallel) that can improve the speed of the computer. This is
>> based in using all the cores of the pc, but I think this works for
>> independent functions and it does not optimize only one process like in the
>> case of the linear mixed model.
>>
>> Thanks for your help guys,
>>
>> Regards
>> Felipe.
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
---------------------------------------------------------------------
Gabriel Baud-Bovy               tel.: (+39) 02 2643 4839 (office)
UHSR University                       (+39) 02 2643 3429 (laboratory)
via Olgettina, 58                     (+39) 02 2643 4891 (secretary)
20132 Milan, Italy               fax: (+39) 02 2643 4892


From bates at stat.wisc.edu  Thu Apr 18 18:49:22 2013
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 18 Apr 2013 11:49:22 -0500
Subject: [R-sig-ME] How can I optimize the performance of mixed models?
In-Reply-To: <516F85AB.70903@hsr.it>
References: <CABFQCKnfM3cA95vdkrDh9n94UWwrECvKe840=nGX+LeLg00feg@mail.gmail.com>
	<877gk1rwr3.fsf@gmail.com> <516F85AB.70903@hsr.it>
Message-ID: <CAO7JsnSkwpGUe07WzDFrihiQeuY1H8FRer6ppM9cjY326ktdTA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130418/ed7b07e2/attachment.pl>

From bates at stat.wisc.edu  Thu Apr 18 19:06:53 2013
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 18 Apr 2013 12:06:53 -0500
Subject: [R-sig-ME] Unbalanced design mixed models
In-Reply-To: <D3557409FD94BA41AE028A1E573716D646FAA59D@S-BSC-MBX2.nrn.nrcan.gc.ca>
References: <D3557409FD94BA41AE028A1E573716D646FAA59D@S-BSC-MBX2.nrn.nrcan.gc.ca>
Message-ID: <CAO7JsnSEmedawMAtpuiLAtd886oFcTBCfOtJj-bJ8GR44FdLKg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130418/6f125353/attachment.pl>

From A.Robinson at ms.unimelb.edu.au  Fri Apr 19 02:57:21 2013
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Fri, 19 Apr 2013 10:57:21 +1000
Subject: [R-sig-ME] How to deal with outcomes assessed by raters?
In-Reply-To: <69C7CCF0-DCFB-47C5-9EAF-86FD473FE0E2@icloud.com>
References: <C573AAD4-980C-4F5A-88F2-C9D8BCBC93FA@icloud.com>
	<alpine.LMD.2.00.1304161746450.25458@orpheus.qimr.edu.au>
	<69C7CCF0-DCFB-47C5-9EAF-86FD473FE0E2@icloud.com>
Message-ID: <CAHyGmd6SF7bpYEL6ChwJa7+1ZMOb2vqvZYXOTfgfS=NrgoPTgw@mail.gmail.com>

Hi Joseph,

thanks for this detailed summary.  Based on my understanding, I think
that it is defensible to include the raters as random effects in the
model, and I think that doing so provides a more faithful
representation of your experimental design than would excluding them.

Definitely not nuts.

On the niggles: I'm not sure what exactly you mean by "averaging over
the ratings".  It sounds risky to me.

Cheers

Andrew

On Tue, Apr 16, 2013 at 7:50 PM, Joseph Bulbulia
<joseph.bulbulia at icloud.com> wrote:
> Hi all,
>
> Two of you asked for more information.  Sorry for the long-winded account, written in haste.
>
> THE QUASI EXPERIMENT
> * The fire-walking ritual consisted of a series of 26 ordeals by fire.
> * Each fire-walker traversed a burning bed of coals (677 Celsius -- I actually measured it with a pyrometer. Such instruments exit!).
> * In sixteen of these events, fire-walkers were carrying a passenger.
> * Total duration of each fire-walk = < 5 seconds, which we carved up into five phases.
>
> I constructed a make-shift plot plan of the ritual here (following ideas in Walter Stroup's recent book on GLMMs).  Not sure I'm happy with it, but it will give you the gist.
>
> https://www.dropbox.com/s/0o0a9kkrh5ttsd2/plot.plan.emotions_firewalk.pdf
> Hypotheses 1:
> Anthropologists have long maintained that rituals cause a melding of emotions, what they call "collective effervescence". You've felt this surely.  Being connected with others at a big event ? This "merge" model predicts that arousal and valence will tend to be coupled among participants, irrespective of ritual roles.  (In another paper, we demonstrated heart rhythm coupling among fire walkers and observers; the study was published in 2011.)
>
> Hypothesis 2:
> Another anthropological tradition predicts differentiation in emotions depending on ritual role.  This "verge" model predicts that ritual participants who undertake a rite of passage will express different emotions. Think of a PhD thesis defence. The candidate's ordeal is the inquisitor's delight! (In our heart rhythm paper we also found differences in synchrony which were predicted by ritual role and social distance. This study is just a follow up using another biomarker.)
>
> To assess whether emotional dynamics merge or verge, we sampled images for each ritual participant (n=42, 26 firewalkers and 16 passengers) at five different phases of the fire-walk.
>
> There's evidence of cultural variability in emotions, so the images were independently rated by four judges from the part of Spain, roughly from the area where the ritual happened.
>
> (Note: if I could do this over again, I'd get more raters, but this sort of number is typical in psychological research: it is probably OK for the task a hand, which does not require exact estimates, only rough assessments of trends among each ritual group).
>
> See how you do here.  Merge or Verge?
> https://www.dropbox.com/s/xmbci5814h73i0l/4_MF_e5.png
>
> Images were rated for ?valence? and ?arousal? on Likert scales from 1-7.  I didn't run an ICC because I wasn't sure whether this is appropriate for ordinal data (If anyone knows I'd be grateful, but I didn't want to bog down the list with too many questions).  Kendall's coefficient of concordance was 0.513.   As is typical in emotions research, then, judgements were not all that concordant.  But again noisy signals are ok in the context of this study.  There's a larger philosophical discussion about whether emotions are intrinsically vague and context-dependent creatures.  We can set that to the side though.  Crude signals, in this case, are fine.
>
>
> The Model
>   Fixed effects for Phase x Role strongly improve the intercept only model, and show merge for arousal and verge for valence. This finding is supported in all other models.
>   Random slopes for participants by Phase do better than random intercepts and slopes.
>   Random effects for Events improve the model, but there's no improvement by including effects for Dyadic pairs.
>   I used an ordinal family because the data are ordinal.
>   I fixed the R variance to 1 because this is what Jarrod Hadfield's Course Notes recommend, and he is a man who knows what he's talking about.
>
> Key point
> Nothing hangs on putting raters into the model!!   The outcome remains the same with respect to the hypotheses.  I could leave them out (and probably will).  However it seems to me that the raters are somehow part of the effect, in a way that is very roughly analogous to meta-analysis studies. (However I did not attempt MEV? seemed a bit extreme, but who knows?!!)
>
>
> Other niggles
> My psychologist collaborator (experienced with LMMs using HLM and MPLUS)  suggested averaging over the ratings. This is standard practice in psychology. In fact, psychologist do this all the time wherever they have highly correlated measures for the same trait (e.g. personality).
> This strikes me as OK for most purposes, but it is also odd, because you loose a signal for the variance of your measures.
>
> Again, sorry for stealing time.  Thanks for any help.
>
>
>
>
>
> On 16/04/2013, at 8:05 PM, David Duffy <David.Duffy at qimr.edu.au> wrote:
>
>> On Tue, 16 Apr 2013, Joseph Bulbulia wrote:
>>
>>> Hi all,
>>>
>>> I?d like to model emotional dynamics in a highly arousing firewalk ritual.
>>>
>>> Four judges rated images from 42 participants for arousal and valence. The predictor variables are ritual ?phase? and ?role.?
>>>
>>> Question 1
>>> Any thoughts about how best to handle the rater assessments?
>>>
>>> Specifically, is it nuts to explicitly include a component for raters in the random component of the model?
>>
>> So what do the inter-rater agreements look like?  I presume rater is actually a nuisance variable?  The path model I would usually use would have phase and role acting on the averaged-over-raters a and v scores (measurement model bit).
>>
>> Just 2c, David Duffy.
>
>
>         [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Andrew Robinson
Deputy Director, ACERA
Senior Lecturer in Applied Statistics                      Tel: +61-3-8344-6410
Department of Mathematics and Statistics            Fax: +61-3-8344 4599
University of Melbourne, VIC 3010 Australia
Email: a.robinson at ms.unimelb.edu.au    Website: http://www.ms.unimelb.edu.au

FAwR: http://www.ms.unimelb.edu.au/~andrewpr/FAwR/
SPuR: http://www.ms.unimelb.edu.au/spuRs/


From joseph.bulbulia at icloud.com  Fri Apr 19 06:57:42 2013
From: joseph.bulbulia at icloud.com (Joseph Bulbulia)
Date: Fri, 19 Apr 2013 16:57:42 +1200
Subject: [R-sig-ME] How to deal with outcomes assessed by raters?
In-Reply-To: <CAHyGmd6SF7bpYEL6ChwJa7+1ZMOb2vqvZYXOTfgfS=NrgoPTgw@mail.gmail.com>
References: <C573AAD4-980C-4F5A-88F2-C9D8BCBC93FA@icloud.com>
	<alpine.LMD.2.00.1304161746450.25458@orpheus.qimr.edu.au>
	<69C7CCF0-DCFB-47C5-9EAF-86FD473FE0E2@icloud.com>
	<CAHyGmd6SF7bpYEL6ChwJa7+1ZMOb2vqvZYXOTfgfS=NrgoPTgw@mail.gmail.com>
Message-ID: <3722B1B8-D84E-4237-95B1-DCC7E49EA05A@icloud.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130419/a90e12f0/attachment.pl>

From lamprianou at yahoo.com  Fri Apr 19 11:36:02 2013
From: lamprianou at yahoo.com (Iasonas Lamprianou)
Date: Fri, 19 Apr 2013 02:36:02 -0700 (PDT)
Subject: [R-sig-ME] strange interaction  behavior in lme4
In-Reply-To: <mailman.5.1366192802.9381.r-sig-mixed-models@r-project.org>
References: <mailman.5.1366192802.9381.r-sig-mixed-models@r-project.org>
Message-ID: <1366364162.83832.YahooMailNeo@web160104.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130419/9374d055/attachment.pl>

From philippe.matter at env.ethz.ch  Fri Apr 19 12:49:54 2013
From: philippe.matter at env.ethz.ch (Matter  Philippe)
Date: Fri, 19 Apr 2013 10:49:54 +0000
Subject: [R-sig-ME] Anova tables for the coxme() function?
Message-ID: <043E064F801DB641965FA495A6CA966709150296@MBX21.d.ethz.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130419/33572ec4/attachment.pl>

From ludovicofrate at hotmail.it  Fri Apr 19 17:28:34 2013
From: ludovicofrate at hotmail.it (Ludovico Frate)
Date: Fri, 19 Apr 2013 17:28:34 +0200
Subject: [R-sig-ME] generalized mixed model
Message-ID: <DUB105-W54B12FA3C439C95FB62063D6C80@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130419/633c61cc/attachment.pl>

From e.tsuda at yahoo.com.br  Fri Apr 19 17:53:15 2013
From: e.tsuda at yahoo.com.br (=?iso-8859-1?Q?=C9rika_Tsuda?=)
Date: Fri, 19 Apr 2013 08:53:15 -0700 (PDT)
Subject: [R-sig-ME] problem with nested mixed model
In-Reply-To: <1366386193.99504.YahooMailNeo@web162701.mail.bf1.yahoo.com>
References: <1366386193.99504.YahooMailNeo@web162701.mail.bf1.yahoo.com>
Message-ID: <1366386795.66630.YahooMailNeo@web162705.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130419/c5f81068/attachment.pl>

From seth at swbigelow.net  Fri Apr 19 19:16:25 2013
From: seth at swbigelow.net (Seth Bigelow)
Date: Fri, 19 Apr 2013 13:16:25 -0400
Subject: [R-sig-ME] problem with nested mixed model
In-Reply-To: <1366386795.66630.YahooMailNeo@web162705.mail.bf1.yahoo.com>
References: <1366386193.99504.YahooMailNeo@web162701.mail.bf1.yahoo.com>
	<1366386795.66630.YahooMailNeo@web162705.mail.bf1.yahoo.com>
Message-ID: <002401ce3d21$a08d1a20$e1a74e60$@net>

Well, if it were me, I would begin with the simplest reasonable model:

M1 <- lme(altura~ vegetation*bromeliad, random=~1|site)

(You don't have to put vegetation + bromeliad + vegetation*bromeliad, just
vegetation*bromeliad will do)

Then also do the more complicated model:

M2 <- lme(altura ~ vegetation*bromeliad, random=~1|vegetation/site)...

(I think this is better syntax than the way you had it before)

...and do a likelihood ratio test to see if there is an improvement in fit
by nesting site within vegetation.

anova(M1,M2)

You should be checking residuals for these models -- Chapter 1 in Pinheiro &
Bates has all this. The quantiles of your residuals look rather unbalanced,
some kind of transformation may be necessary

Boa sorte

-Seth



-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of ?rika Tsuda
Sent: Friday, April 19, 2013 11:53 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] problem with nested mixed model





Hi guys, 


I am trying to fit a nested mixed model using the lme function but not sure
on how to state a random factor is nested within another factor. 

Here is my sampling design: 

I measured height of seedlings (my response variable called height) in two
different vegetation strata (herbaceous and shrubby), this is my factor
vegetation, which I believe is fixed. 


At each strata I collected in three different site, this is my factor site,
which I believe is random and nested whithin vegetation. 


Also, at each vegetation strata I collected seedlings inside and outside
bromeliads, this is my factor bromeliad, which I believe is fixed and
orthogonal to vegetation. 


So, I tried to model this using the function lme as follows: 


model<-
lme(height~vegetation+bromeliad+vegetation*bromeliad+(vegetation/site),
~1|site, data=altura)


Resulting in: 


Linear mixed-effects model fit by REML Data: altura  AIC      BIC    logLik
13290.98 13342.81 -6635.491 Random effects: Formula: ~1 | site (Intercept)
Residual
StdDev:    4.682701  36.8902 Fixed effects: height ~ vegetation + bromeliad
+ vegetation * bromeliad + (vegetation/site)  Value Std.Error   DF   t-value
p-value
(Intercept)                  57.37983  5.856448 1314  9.797718  0.0000
vegetationHERB              -21.48592  4.363718 1314 -4.923764  0.0000
bromeliadBRO                  6.73168  2.441297 1314  2.757421  0.0059
vegetationHERB:bromeliadBRO  12.72138  5.274164 1314  2.412019  0.0160
vegetationARB:sitea2          5.41959  7.776715 1314  0.696900  0.4860
vegetationHERB:sitea2         0.05141  9.265842 1314  0.005549  0.9956
vegetationARB:sitea3          1.69237  7.570281 1314  0.223555  0.8231
vegetationHERB:sitea3       -14.65097  7.692126 1314 -1.904672  0.0570
Correlation:  (Intr) vgHERB brmBRO vHERB:B vARB:2 vHERB:2 vARB:3
vegetationHERB              -0.484

bromeliadBRO                -0.202  0.271

vegetationHERB:bromeliadBRO  0.093 -0.282 -0.463

vegetationARB:sitea2        -0.722  0.323 -0.002  0.001

vegetationHERB:sitea2       -0.404 -0.144  0.000 -0.032   0.609

vegetationARB:sitea3        -0.742  0.332 -0.001  0.000   0.559  0.313

vegetationHERB:sitea3       -0.487 -0.176  0.000 -0.024   0.367  0.394
0.753 Standardized Within-Group Residuals: Min         Q1        Med
Q3        Max 
-1.7492750 -0.5854722 -0.2114832  0.3335703  7.7013967  Number of
Observations: 1324 Number of Groups: 3 

When I ask the anova table, I get: 

numDF denDF  F-value p-value
(Intercept)              1  1314 350.5013  <.0001
vegetation               1  1314 155.3877  <.0001
bromeliad                1  1314  18.7275  <.0001
vegetation:bromeliad     1  1314   5.3803  0.0205
vegetation:site          4  1314   2.6398  0.0325

Based on this results I guess the analysis is right, however I am not sure
if I assigned the random and fixed factors properly. 
Also, I am not sure if the factor sites is nested whithin vegetation.
Another thing I dont know is what does the number 1 in ~1|sitemeans, since
when I changed for 0 the results is the same, but the models fails if I
remove this number.

Sorry by the big message, and thank you very much for your attention. 



----Irika Tiemi Tsuda
Bisloga, MSc. em Ecologia
Laboratsrio de Ecologia Vegetal

Universidade Federal de Santa Catarina
(48) 9165-8822/ (48) 3721-5520
	[[alternative HTML version deleted]]


From Yan.Boulanger at RNCan-NRCan.gc.ca  Sat Apr 20 20:40:39 2013
From: Yan.Boulanger at RNCan-NRCan.gc.ca (Boulanger, Yan)
Date: Sat, 20 Apr 2013 18:40:39 +0000
Subject: [R-sig-ME] RE :  Unbalanced design mixed models
In-Reply-To: <CAO7JsnSEmedawMAtpuiLAtd886oFcTBCfOtJj-bJ8GR44FdLKg@mail.gmail.com>
References: <D3557409FD94BA41AE028A1E573716D646FAA59D@S-BSC-MBX2.nrn.nrcan.gc.ca>,
	<CAO7JsnSEmedawMAtpuiLAtd886oFcTBCfOtJj-bJ8GR44FdLKg@mail.gmail.com>
Message-ID: <D3557409FD94BA41AE028A1E573716D646FB0BEA@S-BSC-MBX1.nrn.nrcan.gc.ca>

Thanks Douglas,

But statistically speaking, including the plots with only one individual in this context is incorrect right?

Many thanks!

Yan
________________________________
De : dmbates at gmail.com [dmbates at gmail.com] de la part de Douglas Bates [bates at stat.wisc.edu]
Date d'envoi : jeudi 18 avril 2013 13:06
? : Boulanger, Yan
Cc: r-sig-mixed-models at r-project.org
Objet : Re: [R-sig-ME] Unbalanced design mixed models

On Wed, Apr 17, 2013 at 1:14 PM, Boulanger, Yan <Yan.Boulanger at rncan-nrcan.gc.ca<mailto:Yan.Boulanger at rncan-nrcan.gc.ca>> wrote:
Hi folks,

This seems a very (I mean very...) basic mixed model question but I would like to have your feeling about this. I start from scratch with mixed models. I'm fitting this very simple mixed model:

fm1 <- lmer(dbh_tree ~ log(age_tree) + (1|plot_name), PICE.MAR_tree)

where dbh_tree is the diameter at breast height of a tree, age_tree the age of the tree at bh, plot_name is the plot where the tree was sampled and PICE.MAR_tree, my dataset. This is not an experimental setup where a fixed number of trees was sampled per plot. Indeed, some plots have as high as 150 trees (very few...) whereas others has only 1... At that is the (well one of the...) problem. How may I fit a mixed model where, in several cases, well, maybe 50%, there is only 1 tree per level of the random factor ? So, no variation within the random factor... I could forget the random factor but of course, this would lead to "partial" pseudoreplication. On the other hand, I could drop all plots with only one tree but this would discard about half of the plots. Am I right when I say that the coefficients (for the fixed variables) are unbiased when not considering the random factor ? Indeed, I'm not interested in CI but "only" to fixed variable coefficients.

I think you will find that there is very little difference in the model fits whether you include or exclude the single-observation groups.  Try it and see.


From ep311508 at ohio.edu  Sat Apr 20 22:14:12 2013
From: ep311508 at ohio.edu (Price, Emily)
Date: Sat, 20 Apr 2013 16:14:12 -0400
Subject: [R-sig-ME] comparing results across software packages
Message-ID: <21D4FC5FDE197F4D942D0CF404BE76A330A22AF505@EXMAIL1.ohio.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130420/d79f8ec6/attachment.pl>

From S.Ellison at LGCGroup.com  Sun Apr 21 14:25:09 2013
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Sun, 21 Apr 2013 13:25:09 +0100
Subject: [R-sig-ME] RE :  Unbalanced design mixed models
In-Reply-To: <D3557409FD94BA41AE028A1E573716D646FB0BEA@S-BSC-MBX1.nrn.nrcan.gc.ca>
References: <D3557409FD94BA41AE028A1E573716D646FAA59D@S-BSC-MBX2.nrn.nrcan.gc.ca>
	<CAO7JsnSEmedawMAtpuiLAtd886oFcTBCfOtJj-bJ8GR44FdLKg@mail.gmail.com>
	<D3557409FD94BA41AE028A1E573716D646FB0BEA@S-BSC-MBX1.nrn.nrcan.gc.ca>
Message-ID: <579770AB-F72D-4A35-BD6A-BEDCED80B33F@LGCGroup.com>

>> But statistically speaking, including the plots with only one individual in this context
> is incorrect right?

Why would that be incorrect? Each isolated point will still contribute to the fixed effect coefficient(s). And a likelihood for that observation still exists, based on a distribution which includes  the single 'residual' variance and the between-plot variance. As long as you have at least one plot with replication you'll have separable estimates of both variances. 

A practical problem is that with the plot variance estimate coming from very few plots it might not be a very good estimate. I'd also worry that you may have heteroscedasticity from plot to plot, and if so you'll not be able to build plot-specific variances  into the model without replication in every plot. However, if your simple model is sufficient to explain the error structure, that isn't a problem.

S Ellison



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From bbolker at gmail.com  Tue Apr 23 21:19:20 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 23 Apr 2013 19:19:20 +0000 (UTC)
Subject: [R-sig-ME] comparing results across software packages
References: <21D4FC5FDE197F4D942D0CF404BE76A330A22AF505@EXMAIL1.ohio.edu>
Message-ID: <loom.20130423T211342-873@post.gmane.org>

Price, Emily <ep311508 at ...> writes:

> 
> Dear R-sig-mixed-models,
 
> My colleague and I are trying to verify results of running
> hierarchical generalized linear models in STATA and R.  In STATA to
> designate the number of trials we used binomial(10). To do this in R
> we created a variable that was 10 for every observation call trial.
> We ran the model two ways in R with and without the offset
> command. The following are our commands in STATA and R respectively:
 
> Xtmelogit dv classb trt_lam, || id_lam: trt_lam, 
   covariance(unstructured) binomial(10)

> glm22 <- glmmadmb(formula=dv~trt.f + classb.f + offset(trial) +
>  (trt.f|id.f), data=lam_hlm, family="binomial",
>  link="logit",corStruct="full")
 
> glm_off <- glmmadmb(formula=dv~trt.f + classb.f + (trt.f|id.f), 
 data=lam_hlm, family="binomial", link="logit",corStruct="full")
 
> Our results for the fixed effects, random effects and log likelihood
> are different between R and STATA for both R models. We are not sure
> why they are so different and were wondering if this issue has been
> encountered before and if additional assistance could help explain
> this.
 
> Emily Price and Christine Crumbacher

  Three comments here:

(1) I don't think a logit-offset is the way to add information about
the number of trials.  The standard R approach is to use

glmmadmb(formula=cbind(dv,trial-dv)~trt.f + classb.f + 
  (trt.f|id.f), 
 data=lam_hlm, family="binomial", link="logit",corStruct="full")

(2) There is a bug in the current (and previous!!) versions of glmmADMB,
which I haven't dealt with yet -- it doesn't really fit unstructured
variance-covariance matrices, it always defaults to diagonal
v-cov matrices.  You can wait a few days (I will bump this up the
priority list); in the meanwhile it might be worth comparing with
the diagonal covariance structure to see if you get the right
STATA/R comparison.

(3) lme4 should also be able to handle this model, either with


glmmadmb(cbind(dv,trial-dv)~trt.f + classb.f + 
  (trt.f|id.f), 
 data=lam_hlm, family=binomial(link="logit"))

(unstructured variance-covariance matrix is the default) or

glmmadmb(dv/trial~trt.f + classb.f + 
  (trt.f|id.f), weights=trial,
 data=lam_hlm, family=binomial(link="logit"))

(I think glmmML can also do this one).

  Ben Bolker


From bbolker at gmail.com  Tue Apr 23 21:30:34 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 23 Apr 2013 19:30:34 +0000 (UTC)
Subject: [R-sig-ME] comparing results across software packages
References: <21D4FC5FDE197F4D942D0CF404BE76A330A22AF505@EXMAIL1.ohio.edu>
	<loom.20130423T211342-873@post.gmane.org>
Message-ID: <loom.20130423T212948-762@post.gmane.org>

Ben Bolker <bbolker at ...> writes:

> 
> Price, Emily <ep311508 <at> ...> writes:
> 
> > 
> > Dear R-sig-mixed-models,
> 

  [ MAJOR SNIPPAGE]

  Doug Bates points out that I meant to use glmer() and 
not glmmadmb() below:

> 
> (3) lme4 should also be able to handle this model, either with
> 
glmer(cbind(dv,trial-dv)~trt.f + classb.f + 
   (trt.f|id.f), 
  data=lam_hlm, family=binomial(link="logit"))
> 
> (unstructured variance-covariance matrix is the default) or

glmer(dv/trial~trt.f + classb.f + 
   (trt.f|id.f), weights=trial,
  data=lam_hlm, family=binomial(link="logit"))
 
> (I think glmmML can also do this one).
> 
>   Ben Bolker
> 
>


From jmmartelo at fc.ul.pt  Tue Apr 23 22:14:52 2013
From: jmmartelo at fc.ul.pt (joana martelo)
Date: Tue, 23 Apr 2013 21:14:52 +0100
Subject: [R-sig-ME] GLMM or GLM?
Message-ID: <003501ce405f$37b23620$a716a260$@ul.pt>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130423/f068b366/attachment.pl>

From baud-bovy.gabriel at hsr.it  Tue Apr 23 23:54:52 2013
From: baud-bovy.gabriel at hsr.it (Gabriel Baud-Bovy)
Date: Tue, 23 Apr 2013 23:54:52 +0200
Subject: [R-sig-ME] GLMM or GLM?
In-Reply-To: <003501ce405f$37b23620$a716a260$@ul.pt>
References: <003501ce405f$37b23620$a716a260$@ul.pt>
Message-ID: <5177032C.2010408@hsr.it>

On 4/23/2013 10:14 PM, joana martelo wrote:
> Dear list
>
>   
>
> I'm trying to model the relationship between prey capture success by fish
> and fish size, density and velocity, but I?m not sure which statistical
> method to use ? GLMM or GLM? Capture success was collected during trials
> that consisted in sending a prey every x min, which could be captured or not
> by individual fish. A total of 20 prey was send in each trial.
>
>   
Are density and velocity fish characteristics ? see below.
>
> Method A: GLMM
>
>   
>
> I used fish.id as a random effect and the behavior of fish (0 no capture, 1-
> capture) as the response variable. One of my models looks like this:
>
>   
>
> Model1<-glmer(capture~fish size + density
> velocity+(1|fish.id.),family=binomial,data=cap)
>
>   
>
>   
>
> Method B: GLM
>
>   
>
> The response variable was the proportion of prey captured by each fish and
> one of my models:
>
>   
>
> Model1<-glm(prop.capture~fish size + density
> velocity,family=binomial,data=cap)
>
>   

>
>   
>
> I used model selection using Akaike weights to examine the performance of
> each model.  Results were similar with both methods, but I think I lose a
> bit of biological information if I use A: 1) I can't model average which may
> mean a loss of information when I have many interpretable models as I have
> with both approaches, 2) I lose the "fish size" effect which is an important
> bit of biological information (i.e. larger fish have higher capture success
> rates). However, A might be more appropriate for my type of data, even
> though I?m not interested in variation within fish but among fish ?.
>
1. Fitting ungrouped or grouped (proportions) data should give the same 
results if
done correctly. You should not loose any information.

For glm, a typical response is a two-column matrix with the columns 
giving the numbers of successes and failures. If
you use proportions, you should also use the weights argument to 
indicate the number of cases.

2. To me, the first model seems more correct if  the model includes 
within-subject/fish
factors (density or velocity ?)

3. If you have only between-subject variables, then the GLM model is 
correct
(see 10.3 in Zuur et al., 2009, Mixed Effects Models and Extensions in 
Ecology with R).

My 2 cents.

Gabriel

>   
>
> Can anyone help?
>
>   
>
> Thanks in advance!
>
>   
>
>   
>
> Joana Martelo, PhD Student
>
> Centro de Biologia Ambiental
>
> Departamento de Biologia Animal
>
> Faculdade de Ci?ncias, Edificio C2,5?Piso,Sala 2.5.15B
>
> 1749-016 Lisboa, Portugal
>
>   <http://ffishgul.fc.ul.pt/> http://ffishgul.fc.ul.pt
>
> Por favor pense na sua responsabilidade ambiental antes de imprimir este
> email
>
>   
>
>   
>
>   
>
>   
>
>
> 	[[alternative HTML version deleted]]
>


-- 
---------------------------------------------------------------------
Gabriel Baud-Bovy               tel.: (+39) 02 2643 4839 (office)
UHSR University                       (+39) 02 2643 3429 (laboratory)
via Olgettina, 58                     (+39) 02 2643 4891 (secretary)
20132 Milan, Italy               fax: (+39) 02 2643 4892


From ruthkelly123 at gmail.com  Wed Apr 24 13:50:06 2013
From: ruthkelly123 at gmail.com (Ruth Kelly)
Date: Wed, 24 Apr 2013 12:50:06 +0100
Subject: [R-sig-ME] Model selection of fixed effects in glmmADMB
Message-ID: <CA+wU5KEYHvzRUh+gYgFB0MVA3rr1DtzyQExQ2D-0PMtxS=Yhkw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130424/6b38a16e/attachment.pl>

From Lara.Reichmann at austin.utexas.edu  Thu Apr 25 15:34:29 2013
From: Lara.Reichmann at austin.utexas.edu (Lara Reichmann)
Date: Thu, 25 Apr 2013 13:34:29 +0000
Subject: [R-sig-ME] how to interpret non-linear mixed effect model results
Message-ID: <830D6E53-880C-4D7F-B574-1217A41D4A39@austin.utexas.edu>

Dear list,

I used the nlme function to analyze the effect of Fertilization (2 levels) and Species (4 levels) on leaf CO2 uptake for 31 different plants under different light conditions (PARi). CO2 uptake follows an exponential model with parameters A, B and C. First, I looked at the between-plant variation to choose the appropriate structure of the random effects, where A and B resulted highly correlated, thus I only used A and C to create the random effect structure. Then, a plot of the predicted random effects against covariates showed a  possible interaction between Fertilization and Species for the parameter A, but not clear for C. 
I finally run a model with Species and Fertilization as fixed effects, but I need help to interpret the results, i.e. whether the parameters A and C differ among Species and Fertilization. I think that the table shows a Fertilization effect on A, and a significant species effect but in quadratic combination of the levels? Is this the correct interpretation? How do I proceed from here to find out which plant species are different form the rest in the parameters A and C? I copied the contrasts that R creates below the nlme result. 

I imagine this is pretty straight forward but I am fairly new with non-linear mixed models and the possibilities in R.

Thanks!
Lara


Nonlinear mixed-effects model fit by maximum likelihood
  Model: Photo ~ A * (1 - exp(-C * PARi/A)) - B 
 Data: lightresponse 
       AIC      BIC   logLik
  1018.412 1097.743 -488.206

Random effects:
 Formula: list(A ~ 1, C ~ 1)
 Level: Subject2
 Structure: General positive-definite, Log-Cholesky parametrization
              StdDev      Corr  
A.(Intercept) 6.862964403 A.(In)
C.(Intercept) 0.009835824 0.026 
Residual      0.760129991       

Fixed effects: list(A + C ~ Species * Fert, B ~ 1) 
                       Value Std.Error  DF   t-value p-value
A.(Intercept)      24.799122  1.279099 276 19.387956  0.0000
A.Species.L        -2.715205  2.510509 276 -1.081536  0.2804
A.Species.Q        -5.082033  2.553854 276 -1.989946  0.0476
A.Species.C        -1.480629  2.596444 276 -0.570253  0.5690
A.Fert.L            9.502754  1.805936 276  5.261954  0.0000
A.Species.L:Fert.L  0.027821  3.550408 276  0.007836  0.9938
A.Species.Q:Fert.L -5.784219  3.611704 276 -1.601521  0.1104
A.Species.C:Fert.L -4.650500  3.671944 276 -1.266495  0.2064
C.(Intercept)       0.067437  0.002208 276 30.548919  0.0000
C.Species.L        -0.008292  0.003958 276 -2.094717  0.0371
C.Species.Q        -0.006519  0.004061 276 -1.605485  0.1095
C.Species.C         0.002977  0.004160 276  0.715493  0.4749
C.Fert.L           -0.000825  0.002886 276 -0.285688  0.7753
C.Species.L:Fert.L -0.013529  0.005600 276 -2.415831  0.0163
C.Species.Q:Fert.L  0.004215  0.005744 276  0.733708  0.4637
C.Species.C:Fert.L  0.009809  0.005887 276  1.666258  0.0968
B     


contrasts(lightresponse$Species)
             .L   .Q         .C
[1,] -0.6708204  0.5 -0.2236068
[2,] -0.2236068 -0.5  0.6708204
[3,]  0.2236068 -0.5 -0.6708204
[4,]  0.6708204  0.5  0.2236068

 contrasts(lightresponse$Fert)
             .L
[1,] -0.7071068
[2,]  0.7071068

From adeline.buisset at gmail.com  Fri Apr 26 15:57:12 2013
From: adeline.buisset at gmail.com (adeline buisset)
Date: Fri, 26 Apr 2013 15:57:12 +0200
Subject: [R-sig-ME] How to include a second random effect in non linear
	mixed effects regression?
Message-ID: <CAOFar=KhEy9sm8+kSOdZcN+xr_S1LMvTGCtvr+qSM+TRNb35wQ@mail.gmail.com>

Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : non disponible
URL : <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130426/95c9553b/attachment.pl>

From vanni.rovera at gmail.com  Fri Apr 26 16:23:11 2013
From: vanni.rovera at gmail.com (Vanni Rovera)
Date: Fri, 26 Apr 2013 16:23:11 +0200
Subject: [R-sig-ME] Make a 'between-and-within-factors' ANOVA with lmer
	function
Message-ID: <CACd0PJxB1vmr5Q37zLjOe299qPmjXiey6qdR7CEX5i4jSL9K7w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130426/8b81a9ba/attachment.pl>

From lborger at cebc.cnrs.fr  Fri Apr 26 19:14:10 2013
From: lborger at cebc.cnrs.fr (lborger)
Date: Fri, 26 Apr 2013 19:14:10 +0200
Subject: [R-sig-ME] Make a 'between-and-within-factors' ANOVA with
	lmer	function
In-Reply-To: <CACd0PJxB1vmr5Q37zLjOe299qPmjXiey6qdR7CEX5i4jSL9K7w@mail.gmail.com>
References: <CACd0PJxB1vmr5Q37zLjOe299qPmjXiey6qdR7CEX5i4jSL9K7w@mail.gmail.com>
Message-ID: <WC20130426171410.760345@cebc.cnrs.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130426/683ecef2/attachment.pl>

From seth at swbigelow.net  Fri Apr 26 19:59:17 2013
From: seth at swbigelow.net (Seth Bigelow)
Date: Fri, 26 Apr 2013 13:59:17 -0400
Subject: [R-sig-ME] how to interpret non-linear mixed effect model
	results
In-Reply-To: <830D6E53-880C-4D7F-B574-1217A41D4A39@austin.utexas.edu>
References: <830D6E53-880C-4D7F-B574-1217A41D4A39@austin.utexas.edu>
Message-ID: <000c01ce42a7$c7331b30$55995190$@net>

Lara, 

Since no one else has replied I will take your question as an opportunity
for advancing my own learning -- it has motivated me to work through the
'Soybean' example in Pinheiro & Bates, which seems to have the same number
of covariates and parameters as your problem. In looking at your output, it
appears that nlme is mistakenly trying to fit a series of linear, quadratic,
and cubic polynomials to a species by parameter interaction. I don't think
this is what is wanted, is it? At least, the output is very different from
that provided by the final Soybean model (p. 294, model fm4Soy.nlme), which
is reasonably interpretable. I could not hazard any guesses about solutions
to the problem without seeing your input code & some kind of dataset

--Seth  



-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Lara
Reichmann
Sent: Thursday, April 25, 2013 9:34 AM
To: <r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] how to interpret non-linear mixed effect model results

Dear list,

I used the nlme function to analyze the effect of Fertilization (2 levels)
and Species (4 levels) on leaf CO2 uptake for 31 different plants under
different light conditions (PARi). CO2 uptake follows an exponential model
with parameters A, B and C. First, I looked at the between-plant variation
to choose the appropriate structure of the random effects, where A and B
resulted highly correlated, thus I only used A and C to create the random
effect structure. Then, a plot of the predicted random effects against
covariates showed a  possible interaction between Fertilization and Species
for the parameter A, but not clear for C. 
I finally run a model with Species and Fertilization as fixed effects, but I
need help to interpret the results, i.e. whether the parameters A and C
differ among Species and Fertilization. I think that the table shows a
Fertilization effect on A, and a significant species effect but in quadratic
combination of the levels? Is this the correct interpretation? How do I
proceed from here to find out which plant species are different form the
rest in the parameters A and C? I copied the contrasts that R creates below
the nlme result. 

I imagine this is pretty straight forward but I am fairly new with
non-linear mixed models and the possibilities in R.

Thanks!
Lara


Nonlinear mixed-effects model fit by maximum likelihood
  Model: Photo ~ A * (1 - exp(-C * PARi/A)) - B
 Data: lightresponse 
       AIC      BIC   logLik
  1018.412 1097.743 -488.206

Random effects:
 Formula: list(A ~ 1, C ~ 1)
 Level: Subject2
 Structure: General positive-definite, Log-Cholesky parametrization
              StdDev      Corr  
A.(Intercept) 6.862964403 A.(In)
C.(Intercept) 0.009835824 0.026 
Residual      0.760129991       

Fixed effects: list(A + C ~ Species * Fert, B ~ 1) 
                       Value Std.Error  DF   t-value p-value
A.(Intercept)      24.799122  1.279099 276 19.387956  0.0000
A.Species.L        -2.715205  2.510509 276 -1.081536  0.2804
A.Species.Q        -5.082033  2.553854 276 -1.989946  0.0476
A.Species.C        -1.480629  2.596444 276 -0.570253  0.5690
A.Fert.L            9.502754  1.805936 276  5.261954  0.0000
A.Species.L:Fert.L  0.027821  3.550408 276  0.007836  0.9938
A.Species.Q:Fert.L -5.784219  3.611704 276 -1.601521  0.1104
A.Species.C:Fert.L -4.650500  3.671944 276 -1.266495  0.2064
C.(Intercept)       0.067437  0.002208 276 30.548919  0.0000
C.Species.L        -0.008292  0.003958 276 -2.094717  0.0371
C.Species.Q        -0.006519  0.004061 276 -1.605485  0.1095
C.Species.C         0.002977  0.004160 276  0.715493  0.4749
C.Fert.L           -0.000825  0.002886 276 -0.285688  0.7753
C.Species.L:Fert.L -0.013529  0.005600 276 -2.415831  0.0163
C.Species.Q:Fert.L  0.004215  0.005744 276  0.733708  0.4637
C.Species.C:Fert.L  0.009809  0.005887 276  1.666258  0.0968
B     


contrasts(lightresponse$Species)
             .L   .Q         .C
[1,] -0.6708204  0.5 -0.2236068
[2,] -0.2236068 -0.5  0.6708204
[3,]  0.2236068 -0.5 -0.6708204
[4,]  0.6708204  0.5  0.2236068

 contrasts(lightresponse$Fert)
             .L
[1,] -0.7071068
[2,]  0.7071068
_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From fvargas.reeve at gmail.com  Fri Apr 26 20:14:21 2013
From: fvargas.reeve at gmail.com (Felipe Vargas Reeve)
Date: Fri, 26 Apr 2013 15:14:21 -0300
Subject: [R-sig-ME] Overlapping matrix pre lmer or nlme
Message-ID: <CABFQCKktNhRGgrAL9oMopJ6rOGtqZP65YTcD8YBSu2UymJ0rvQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130426/d7642feb/attachment.pl>

From vanni.rovera at gmail.com  Sat Apr 27 12:10:13 2013
From: vanni.rovera at gmail.com (Vanni Rovera)
Date: Sat, 27 Apr 2013 12:10:13 +0200
Subject: [R-sig-ME] Make a 'between-and-within-factors' ANOVA with lmer
	function
In-Reply-To: <WC20130426171410.760345@cebc.cnrs.fr>
References: <CACd0PJxB1vmr5Q37zLjOe299qPmjXiey6qdR7CEX5i4jSL9K7w@mail.gmail.com>
	<WC20130426171410.760345@cebc.cnrs.fr>
Message-ID: <CACd0PJxyh0DQCgKP04zxEO892E1OH_hJP6NPeWY+i+QvhC=paw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130427/7051ea98/attachment.pl>

From raoul.schorer at gmail.com  Sun Apr 28 15:39:01 2013
From: raoul.schorer at gmail.com (Raoul Schorer)
Date: Sun, 28 Apr 2013 15:39:01 +0200
Subject: [R-sig-ME] lmer in a retrospective case-matched cohort study with
	repeated measures
Message-ID: <CAB7dDT87rRth6ykT_u5APz=FYZRZP0OW=o+PVUXbBWJB=EUeOw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130428/aec28c15/attachment.pl>

From Pie.Mueller at unibas.ch  Sun Apr 28 16:01:38 2013
From: Pie.Mueller at unibas.ch (Pie.Mueller at unibas.ch)
Date: Sun, 28 Apr 2013 16:01:38 +0200
Subject: [R-sig-ME] =?iso-8859-1?q?AUTO=3A_Pie_M=FCller_is_out_of_the_offi?=
 =?iso-8859-1?q?ce=2E_=28returning__30=2E04=2E2013=29?=
Message-ID: <OF09D2D1AD.6F074D43-ONC1257B5B.004D0DD7-C1257B5B.004D0DD8@LocalDomain>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130428/1eb15c5f/attachment.pl>

From pdalgd at gmail.com  Mon Apr 29 01:47:14 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 29 Apr 2013 01:47:14 +0200
Subject: [R-sig-ME] Make a 'between-and-within-factors' ANOVA with
	lmer	function
In-Reply-To: <loom.20130324T204802-986@post.gmane.org>
References: <CACd0PJxKXymxieWZtocJ_bHeKQcWk_BBUseWD+jtXAqjTWrjcQ@mail.gmail.com>
	<DA60DB44-8E80-46DB-B43B-EB00EF638F2E@ed.ac.uk>
	<loom.20130324T204802-986@post.gmane.org>
Message-ID: <D8A1DFDF-2698-43BC-9639-6B5982072606@gmail.com>


On Mar 24, 2013, at 23:02 , Ben Bolker wrote:

> ian m s white <i.m.s.white at ...> writes:
> 
>> 
>> I reckon lmer can figure out for itself what is between and what is within
> subjects, so
>> 
>> lmer(DV ~ IV1*IV2*IV3*IV4 + (1|Subject))
>> 
>> should fit the same model as your ANOVA.
> 
>  If you want to allow for variation in the IV3 and IV4 effects among
> subjects you might want
> 
> lmer(DV ~ IV1*IV2*IV3*IV4 + (IV3*IV4|Subject))
> 
>  You might want to use lme rather than lme4 for the purposes of
> getting calculated denominator df and p-values, which lmer won't
> give you ...

[Sorry, I realize this a month old, but I didn't see the thread until now.]

Be careful! There are cases where "calculated" is about the most positive thing you can say about the df output from lme(), and I suspect this could be one of them. I'd go for lme4 plus the pbkrtest package.

Here's a simple example (you may need to re-simulate a couple of times to get both error terms with positive estimated variance; or be a little smarter.)

> y <- rnorm(99)
> s <- factor(rep(1:4,c(23,23,23,30)))
> x <- rep(0:1,c(46,53))
> summary(lme(y~x,random=~1|s))
Linear mixed-effects model fit by REML
...
Fixed effects: y ~ x 
                 Value Std.Error DF    t-value p-value
(Intercept)  0.1933857 0.2454292 95  0.7879488  0.4327
x           -0.3227735 0.3437836  2 -0.9388859  0.4469
...

Notice that the intercept is very close to the average of the two first levels of s, so mostly influenced by the between-subject variation. So you'd expect DF around 2, not 95.

The lme() function makes this sort of mistakes when it cannot detect that a regression variable is a coarsening of a random effect term. It does this successfully for x, but not for the intercept. In more complex models, it can affect main effects as well. If you try to fool lme() into fitting crossed random effects, it will get the wrong degrees of freedom, even in a perfectly balanced design.

That's basically the reason Doug Bates removed DF from the lmer() output: The heuristics weren't good enough, and when they got it wrong, they could turn single digit df to something on the order of the total number of observation.

Compare

> summary(fit1 <- lmer(y~x+(1|s)))
Linear mixed model fit by REML 
Formula: y ~ x + (1 | s) 
   AIC   BIC logLik deviance REMLdev
 279.7 290.1 -135.9    269.7   271.7
Random effects:
 Groups   Name        Variance Std.Dev.
 s        (Intercept) 0.082749 0.28766 
 Residual             0.867608 0.93145 
Number of obs: 99, groups: s, 4

Fixed effects:
            Estimate Std. Error t value
(Intercept)   0.1934     0.2454   0.788
x            -0.3228     0.3437  -0.939

Correlation of Fixed Effects:
  (Intr)
x -0.714

> fit2 <- lmer(y~x-1+(1|s))
> KRmodcomp(fit1, fit2)
F-test with Kenward-Roger approximation; computing time: 0.13 sec.
large : y ~ xx + (1 | s)
small : y ~ x - 1 + (1 | s)
        stat    ndf    ddf F.scaling p.value
Ftest 0.6207 1.0000 2.0783         1  0.5106

  


-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ludovicofrate at hotmail.it  Mon Apr 29 14:07:51 2013
From: ludovicofrate at hotmail.it (Ludovico Frate)
Date: Mon, 29 Apr 2013 14:07:51 +0200
Subject: [R-sig-ME] model selection in glmmPQL
Message-ID: <DUB105-W5462E676A09BE3673FA1ECD6B20@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130429/f10aaf22/attachment.pl>

From jwiley.psych at gmail.com  Mon Apr 29 19:08:20 2013
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Mon, 29 Apr 2013 10:08:20 -0700
Subject: [R-sig-ME] poor mixing in MCMCglmm
Message-ID: <CANz9Z_Kf9x7_P4_8arz6cExUrLxShpB4w7eFtZLgzpRAnbs2Vg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130429/ab3ac450/attachment.pl>

From issac.shams at wayne.edu  Mon Apr 29 22:48:23 2013
From: issac.shams at wayne.edu (Issac Shams)
Date: Mon, 29 Apr 2013 16:48:23 -0400 (EDT)
Subject: [R-sig-ME] MCMCglmm prediction intervals with exponential
	distribution
In-Reply-To: <1844612081.8686061.1367266996086.JavaMail.root@wayne.edu>
Message-ID: <1227885128.8690854.1367268503551.JavaMail.root@wayne.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130429/41cb176a/attachment.pl>

From brw_atw at yahoo.com  Tue Apr 30 01:11:55 2013
From: brw_atw at yahoo.com (Ben Wilson)
Date: Mon, 29 Apr 2013 16:11:55 -0700 (PDT)
Subject: [R-sig-ME] Identifying the random effect associated with each
	residual from a GLMM
Message-ID: <1367277115.23904.YahooMailNeo@web160504.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130429/6ce5584d/attachment.pl>

From doggene at earthlink.net  Tue Apr 30 16:30:19 2013
From: doggene at earthlink.net (Liz Hare)
Date: Tue, 30 Apr 2013 10:30:19 -0400
Subject: [R-sig-ME] MCMCglmm and estimated breeding values
Message-ID: <517FD57B.7040605@earthlink.net>

Hello,

Does rbv in MCMCglmm provide estimated breeding values? What does the 
"random" in Random Estimation of breeding values mean? Sorry but I can't 
find documentation on this. If this is not a way to get EBVs, is there a 
way?

How do I specify which trait I want breeding values for?

The syntax suggested in the MCMCglmm documentation gives an opportunity 
to give a pedigree name, but not a trait, or information about the model 
just fitted.

Thanks,
Liz


-- 
Liz Hare PhD
Dog Genetics LLC
doggene at earthlink.net
http://www.doggenetics.com


From Yan.Boulanger at RNCan-NRCan.gc.ca  Tue Apr 30 19:21:32 2013
From: Yan.Boulanger at RNCan-NRCan.gc.ca (Boulanger, Yan)
Date: Tue, 30 Apr 2013 17:21:32 +0000
Subject: [R-sig-ME] Convergence problem
In-Reply-To: <1367277115.23904.YahooMailNeo@web160504.mail.bf1.yahoo.com>
References: <1367277115.23904.YahooMailNeo@web160504.mail.bf1.yahoo.com>
Message-ID: <D3557409FD94BA41AE028A1E573716D646FBAFBA@S-BSC-MBX2.nrn.nrcan.gc.ca>

Hi folks, 

I'm new to nlme and I'm trying to fit a somewhat simple mixed regression model:

PICE.MAR_tree_dbh_model <- lme(log(dbh_tree) ~ Temp+Prec+I(Prec/age_tree)+I(Temp/age_tree), weights = varPower(form =~fitted(.)) , random= ~1|plot_name, data=PICE.MAR_tree, method="REML")


However, convergence is never reached:

  (Error in lme.formula(log(dbh_tree) ~ Temp + Prec + I(Prec/age_tree) +  : 
  maximum number of iterations (lmeControl(maxIter)) reached without convergence)

 Here's the structure of my data. dbh_tree and age_tree is measured on the tree which is nested in plot_name (random effect). Temp and Prec are measured at the plot level. I have also a very unbalanced setup with sometimes only 1 tree per plot and others where there are as much as 150 trees. Maybe the syntax is not right.

Thank you!

Yan Boulanger




>Yan Boulanger, Postdoctoral Visiting Fellow
>Ressources Naturelles Canada, Canadian Forest Service
>Centre de Foresterie des Laurentides
>1055, rue du P.E.P.S.
>C.P. 10380, succ. Sainte-Foy
>Qu?bec (Qu?bec) Canada
>G1V 4C7 
>Tel. : +1 418 649-6859


From barbaramsp at gmail.com  Tue Apr 30 18:45:39 2013
From: barbaramsp at gmail.com (Barbara Silva)
Date: Tue, 30 Apr 2013 17:45:39 +0100
Subject: [R-sig-ME] Doubts mixed linear model with tweedie
Message-ID: <CAC36UXZAUwBPu3C2dCqQ44cFa4x1EcEz5G7q2v1tZqTFV=vYgA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130430/ecb95e69/attachment.pl>

From kalakouentin at gmail.com  Tue Apr 30 20:01:13 2013
From: kalakouentin at gmail.com (Pantelis Hadjipantelis)
Date: Tue, 30 Apr 2013 19:01:13 +0100
Subject: [R-sig-ME] Convergence problem
In-Reply-To: <D3557409FD94BA41AE028A1E573716D646FBAFBA@S-BSC-MBX2.nrn.nrcan.gc.ca>
References: <1367277115.23904.YahooMailNeo@web160504.mail.bf1.yahoo.com>
	<D3557409FD94BA41AE028A1E573716D646FBAFBA@S-BSC-MBX2.nrn.nrcan.gc.ca>
Message-ID: <CAH2DVQFcpPQpY2W=8QvALEskokPP5zppW=MHZmDshXaw9_phgQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130430/cf4161a2/attachment.pl>

From Yan.Boulanger at RNCan-NRCan.gc.ca  Tue Apr 30 20:09:33 2013
From: Yan.Boulanger at RNCan-NRCan.gc.ca (Boulanger, Yan)
Date: Tue, 30 Apr 2013 18:09:33 +0000
Subject: [R-sig-ME] Convergence problem
In-Reply-To: <CAH2DVQFcpPQpY2W=8QvALEskokPP5zppW=MHZmDshXaw9_phgQ@mail.gmail.com>
References: <1367277115.23904.YahooMailNeo@web160504.mail.bf1.yahoo.com>
	<D3557409FD94BA41AE028A1E573716D646FBAFBA@S-BSC-MBX2.nrn.nrcan.gc.ca>
	<CAH2DVQFcpPQpY2W=8QvALEskokPP5zppW=MHZmDshXaw9_phgQ@mail.gmail.com>
Message-ID: <D3557409FD94BA41AE028A1E573716D646FBB00E@S-BSC-MBX2.nrn.nrcan.gc.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130430/ee465d8f/attachment.pl>

From kalakouentin at gmail.com  Tue Apr 30 20:56:35 2013
From: kalakouentin at gmail.com (Pantelis Hadjipantelis)
Date: Tue, 30 Apr 2013 19:56:35 +0100
Subject: [R-sig-ME] Convergence problem
In-Reply-To: <D3557409FD94BA41AE028A1E573716D646FBB00E@S-BSC-MBX2.nrn.nrcan.gc.ca>
References: <1367277115.23904.YahooMailNeo@web160504.mail.bf1.yahoo.com>
	<D3557409FD94BA41AE028A1E573716D646FBAFBA@S-BSC-MBX2.nrn.nrcan.gc.ca>
	<CAH2DVQFcpPQpY2W=8QvALEskokPP5zppW=MHZmDshXaw9_phgQ@mail.gmail.com>
	<D3557409FD94BA41AE028A1E573716D646FBB00E@S-BSC-MBX2.nrn.nrcan.gc.ca>
Message-ID: <CAH2DVQHNkiWaHB0HL77FxcHrGDu7g=ZB3DCr7qGjiBhbxv2Dvg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130430/fbf5c6aa/attachment.pl>

From fci201 at exeter.ac.uk  Wed May  1 15:20:38 2013
From: fci201 at exeter.ac.uk (Ingleby, Fiona)
Date: Wed, 1 May 2013 13:20:38 +0000
Subject: [R-sig-ME] MCMCglmm with datasets of different lengths
Message-ID: <FD6F6B8A5C87974AA3DC10E3656878B10FADC7@VMEXCHANGEMBS6B.isad.isadroot.ex.ac.uk>

Hi everyone,

I'm having some difficulty fitting a particular model in MCMCglmm and I'm wondering if it's possible, and if so, if anyone could help me figure out how to go about it.

I started with one dataset with four traits (trait1, trait2, trait3 and trait4) measured in males and females from 30 families. So, I fitted the following model:

prior <- list( R=list(V=diag(4)/4,nu=0.5), G=list(G1=list(V=diag(8)/8,nu=0.5)) )
model <- MCMCglmm( cbind(trait1, trait2,trait3,trait4) ~ sex:trait-1,random=~us(sex:trait):family,
             rcov=~us(trait):units,prior=prior,data=data,family=rep("gaussian",4),
             nitt=400000,burnin=20000,thin=25,pr=T)

This is fine. However, I have additional data that I'd like to use to fit a more complicated model if possible. I have size data for males and females from these families, but these data are not from the same individuals as the original data, and the datasets are different sizes. The easiest way around this would be to work with family means, but before I make do with that, I wanted to check if there was a way of using the individual data.

I wondered if this would be possible by specifying a model which does not estimate the covariances between individuals (since not all the traits were measured on the same individuals, I want to avoid this) but at the family level instead. So I've tried adding size into the model above as a covariate, and specifying the covariance matrix at the family level, like this:

prior <- list( R=list(V=diag(4)/4,nu=0.5), G=list(G1=list(V=diag(8)/8,nu=0.5)) )
model <- MCMCglmm( cbind(trait1, trait2,trait3,trait4) ~ size:sex:trait-1,random=~us(sex:trait):family,
                  rcov=~us(trait):family,prior=prior,data=data,family=rep("gaussian",4),
                  nitt=400000,burnin=20000,thin=25,pr=T)

but the error message states that the 'R-structure does not define unique residual for each data point', which makes sense, but I'm not sure how else to go about this. Also, I'm worried this whole analysis is flawed anyway due to the underlying problem that the data for size is a smaller dataset than for the other data (although the number of families is the same). At the moment I have got round this by adding 'NA' values into the size dataset, but this feels like a bad idea. At the very least, I guess it means that even if I figure out the model specification, I will then get errors about the missing data.

I've been told that this model should be possible in SAS by using the family term at the individual level to avoid the individual covariances being calculated, and this is what I'm trying to translate into MCMCglmm, but I don't understand enough about this analysis to know how to do it or even if it's possible, so I'm hoping someone might be able to offer me some advice.

Thanks very much in advance,

Fiona


From David.Duffy at qimr.edu.au  Thu May  2 00:53:14 2013
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Thu, 2 May 2013 08:53:14 +1000
Subject: [R-sig-ME] MCMCglmm with datasets of different lengths
In-Reply-To: <FD6F6B8A5C87974AA3DC10E3656878B10FADC7@VMEXCHANGEMBS6B.isad.isadroot.ex.ac.uk>
References: <FD6F6B8A5C87974AA3DC10E3656878B10FADC7@VMEXCHANGEMBS6B.isad.isadroot.ex.ac.uk>
Message-ID: <alpine.LMD.2.00.1305020847060.6711@orpheus.qimr.edu.au>

On Wed, 1 May 2013, Ingleby, Fiona wrote:

> I started with one dataset with four traits (trait1, trait2, trait3 and 
> trait4) measured in males and females from 30 families.
[...]
> This is fine. However, I have additional data that I'd like to use to 
> fit a more complicated model if possible. I have size data for males and 
> females from these families, but these data are not from the same 
> individuals as the original data.

Generally, as long as you have the relationships of individuals between 
the two sets, then the model should be identified (eg estimate genetic 
correlation between traits expressed only in males and females).  So maybe 
try the five trait model directly..

Just 2c, David Duffy,

| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v


From tomasnote at gmail.com  Thu May  2 05:56:56 2013
From: tomasnote at gmail.com (Tomas Note)
Date: Thu, 2 May 2013 00:56:56 -0300
Subject: [R-sig-ME] Calculating HPD for marginal effects of interactions of
	lmer models
Message-ID: <CACbRMV6O9t18E-Q_EAZVFGxCcfmAuaeVN-ojPyynEKSYYiL+BQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130502/4700b2ed/attachment.pl>

From jwiley.psych at gmail.com  Thu May  2 06:11:20 2013
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Wed, 1 May 2013 21:11:20 -0700
Subject: [R-sig-ME] Calculating HPD for marginal effects of interactions
 of lmer models
In-Reply-To: <CACbRMV6O9t18E-Q_EAZVFGxCcfmAuaeVN-ojPyynEKSYYiL+BQ@mail.gmail.com>
References: <CACbRMV6O9t18E-Q_EAZVFGxCcfmAuaeVN-ojPyynEKSYYiL+BQ@mail.gmail.com>
Message-ID: <CANz9Z_LhXLFGYxyhs-tjwbHMsop_MwOCe0P9TCkfpFfz0iKQww@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130501/32d52331/attachment.pl>

From fci201 at exeter.ac.uk  Thu May  2 10:51:40 2013
From: fci201 at exeter.ac.uk (Ingleby, Fiona)
Date: Thu, 2 May 2013 08:51:40 +0000
Subject: [R-sig-ME] MCMCglmm with datasets of different lengths
Message-ID: <FD6F6B8A5C87974AA3DC10E3656878B10FCE34@VMEXCHANGEMBS6B.isad.isadroot.ex.ac.uk>


Thanks for the reply, David. I don't think I explained myself clearly enough as I don't think the model with the five traits as response variables would give me what I'm looking for. I want to include the size measurements as a covariate, something along the lines of the second model I attempted to fit (although obviously this model was incorrect) with the basic form

cbind(trait1, trait2,trait3,trait4) ~ size:sex:trait-1, random=~us(sex:trait):family, rcov=~us(trait):family

I'm hoping to be able to extract the variance-covariance matrix at the family level for each of the four traits in each sex (this is why I have tried to fit the random terms as above), as well as get an estimate for the relationship between size and each of the four traits in each sex (and so that is why I've fitted the fixed effects as above). Like I say, I don't actually know if this is possible in MCMCglmm, but I just thought I would check.

Thanks again,

Fiona


Dr Fiona C Ingleby
Postdoctoral Research Fellow 
University of Sussex
Email: F.Ingleby at sussex.ac.uk
Website: fionaingleby.weebly.com


On 1 May 2013, at 23:53, David Duffy <David.Duffy at qimr.edu.au> wrote:

On Wed, 1 May 2013, Ingleby, Fiona wrote:

I started with one dataset with four traits (trait1, trait2, trait3 and trait4) measured in males and females from 30 families.
[...]
This is fine. However, I have additional data that I'd like to use to fit a more complicated model if possible. I have size data for males and females from these families, but these data are not from the same individuals as the original data.

Generally, as long as you have the relationships of individuals between the two sets, then the model should be identified (eg estimate genetic correlation between traits expressed only in males and females).  So maybe try the five trait model directly..

Just 2c, David Duffy,

| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v


From ommo1 at hotmail.com  Thu May  2 17:00:59 2013
From: ommo1 at hotmail.com (Omnia Abdulrazeg)
Date: Thu, 2 May 2013 15:00:59 +0000
Subject: [R-sig-ME] mixed effects model: R error
Message-ID: <DUB106-W35751F9BE2CBBFE544B21FEBD0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130502/b894046d/attachment.pl>

From joeking1809 at yahoo.com  Fri May  3 01:13:05 2013
From: joeking1809 at yahoo.com (Joe King)
Date: Thu, 2 May 2013 16:13:05 -0700 (PDT)
Subject: [R-sig-ME] Re; skolenik
Message-ID: <1367536385.17814.BPMail_high_noncarrier@web160405.mail.bf1.yahoo.com>


to: dona56 at go.com; msvedder69 at hotmail.com; flatrock4u at aol.com

referral program http://profoffice.net/modules/tvxup.php
















____________
From: Joe King 5/3/2013 12:12:48 AM


From josh.dorrough at naturalregen.com.au  Fri May  3 02:52:09 2013
From: josh.dorrough at naturalregen.com.au (Josh Dorrough)
Date: Fri, 3 May 2013 10:52:09 +1000
Subject: [R-sig-ME] Fwd: Appropriate random effects structure ?
In-Reply-To: <CA+VpQ+g1XVX7xthxN+jei+TvYZ3x99OvV+=62rxQGUXZj3n9eg@mail.gmail.com>
References: <CA+VpQ+gBSh7Fr_Z_A7te9Z1o=j=hVZnYg3vizFYXUumchxuZKA@mail.gmail.com>
	<CA+VpQ+g1XVX7xthxN+jei+TvYZ3x99OvV+=62rxQGUXZj3n9eg@mail.gmail.com>
Message-ID: <CA+VpQ+jwNasFC0j==8h6qNr8F_xb43UiGszyX9ZCtPD1K6CW0g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130503/6094c2d7/attachment.pl>

From David.Duffy at qimr.edu.au  Fri May  3 05:53:52 2013
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Fri, 3 May 2013 13:53:52 +1000
Subject: [R-sig-ME] MCMCglmm with datasets of different lengths
In-Reply-To: <FD6F6B8A5C87974AA3DC10E3656878B10FCE34@VMEXCHANGEMBS6B.isad.isadroot.ex.ac.uk>
References: <FD6F6B8A5C87974AA3DC10E3656878B10FCE34@VMEXCHANGEMBS6B.isad.isadroot.ex.ac.uk>
Message-ID: <alpine.LMD.2.00.1305031346430.25419@orpheus.qimr.edu.au>

On Thu, 2 May 2013, Ingleby, Fiona wrote:

> Thanks for the reply, David. I don't think I explained myself clearly 
> enough as I don't think the model with the five traits as response 
> variables would give me what I'm looking for. I want to include the size 
> measurements as a covariate

If the five trait model works, I think you could extract all the 
coefficients you are interested in from the genetic and environmental 
covariance matrices (eg partial out size from G and E respectively).  If 
there is a genetic correlation between size and T1-4, regressing it out 
can be misleading if genetic effects are your main interest.  To fit 
phenotypic causative pathways in a full model probably requires something 
like OpenMx, where you can specify it as a path model.


From fci201 at exeter.ac.uk  Fri May  3 10:14:37 2013
From: fci201 at exeter.ac.uk (Ingleby, Fiona)
Date: Fri, 3 May 2013 08:14:37 +0000
Subject: [R-sig-ME] MCMCglmm with datasets of different lengths
Message-ID: <FD6F6B8A5C87974AA3DC10E3656878B10FCE8A@VMEXCHANGEMBS6B.isad.isadroot.ex.ac.uk>

Thanks, that makes sense and might in fact be a simpler way of looking at it - I'll give it a go.

Fiona



On 3 May 2013, at 04:53, David Duffy <David.Duffy at qimr.edu.au> wrote:

On Thu, 2 May 2013, Ingleby, Fiona wrote:

Thanks for the reply, David. I don't think I explained myself clearly enough as I don't think the model with the five traits as response variables would give me what I'm looking for. I want to include the size measurements as a covariate

If the five trait model works, I think you could extract all the coefficients you are interested in from the genetic and environmental covariance matrices (eg partial out size from G and E respectively).  If there is a genetic correlation between size and T1-4, regressing it out can be misleading if genetic effects are your main interest.  To fit phenotypic causative pathways in a full model probably requires something like OpenMx, where you can specify it as a path model.


From gybrg at leeds.ac.uk  Fri May  3 12:37:13 2013
From: gybrg at leeds.ac.uk (Benjamin Gillespie)
Date: Fri, 3 May 2013 11:37:13 +0100
Subject: [R-sig-ME] Which model to use?
Message-ID: <894643FDEA3A854A89B3E828737E2B1FFC6F5F0CE8@HERMES8.ds.leeds.ac.uk>

Hi there,

I'd greatly appreciate some advice on the following:

I have 5 indicies for 70 spatially correlated sites within a river catchment. The indices vary in nature: some are counts (i.e. species richness) and others are continuous scores. I also have a number of explanatory factors which I wish to include in my model. My models look roughly like this: index1~explanatory_factor1+explanatory_factor2+explanatory_factor2.

I've been reading Zuur et al 2009 to figure out which may be the most appropriate model to use for analysis. Initially, I thought it would be best to use a mixed model with appropriate family (e.g. poisson /quasipoisson for count indicies) and treat site ID (1, 2, 3,...70) as a random factor to account for the spatial correlation between sites. However, this didn't work (Error in R: "Number of levels of a grouping factor for the random effects must be less than the number of observations").

Alternatively, I have used GLS with spatial correlation and variance structures introduced to account for the spatial dependence and heterogeneity where appropriate - this approach seems to work well and I get results as expected, however, is GLS appropriate for count data? (I can't find anything from a google search or in Zuur et al 2009).

Many thanks in advance, please let me know if you would like further information,


Ben Gillespie, Research Postgraduate
o-------------------------------------------------------------------o
School of Geography, University of Leeds, Leeds, LS2 9JT
o-------------------------------------------------------------------o
http://www.geog.leeds.ac.uk/
o-------------------------------------o
@RiversBenG
o--------------o

From Yan.Boulanger at RNCan-NRCan.gc.ca  Fri May  3 20:36:54 2013
From: Yan.Boulanger at RNCan-NRCan.gc.ca (Boulanger, Yan)
Date: Fri, 3 May 2013 18:36:54 +0000
Subject: [R-sig-ME] Ok with a "small amount" of non-normality?
Message-ID: <D3557409FD94BA41AE028A1E573716D646FBC5FD@S-BSC-MBX2.nrn.nrcan.gc.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130503/ca523ee8/attachment.pl>

From jehredy at yahoo.fr  Fri May  3 20:56:50 2013
From: jehredy at yahoo.fr (Jehredy)
Date: Fri, 3 May 2013 20:56:50 +0200
Subject: [R-sig-ME] Approximate standard error for variance component
	with lmer
Message-ID: <B91B9112-3902-41FE-80D1-DD402A11E4DB@yahoo.fr>

Salut Julien,
Te souviens tu de moi?
Si oui, j aimerais avoir des news de toi.
Pas facile de te trouver sur le web...
Tiens moi au courant.

Best regards,

Jehredy Maatoug

jehredy at yahoo.fr
jehredy at hotmail.com
Tel : + 33 6 01 21 08 31


From bates at stat.wisc.edu  Fri May  3 22:43:59 2013
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 3 May 2013 15:43:59 -0500
Subject: [R-sig-ME] Approximate standard error for variance component
	with lmer
In-Reply-To: <B91B9112-3902-41FE-80D1-DD402A11E4DB@yahoo.fr>
References: <B91B9112-3902-41FE-80D1-DD402A11E4DB@yahoo.fr>
Message-ID: <CAO7JsnSGb93XV4uVnwCv07fu+B4=5qddDCe0AN2zHR2-JnYMaw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130503/ddd23e94/attachment.pl>

From mlespera at uvic.ca  Fri May  3 22:56:29 2013
From: mlespera at uvic.ca (Mary Lesperance)
Date: Fri, 3 May 2013 20:56:29 +0000
Subject: [R-sig-ME] lme4: log likelihoods for glmer using Laplace approx
 versus Gauss-Hermite, binary data
Message-ID: <FC0A836C9525454EA6BE92352B987660084BE2@opah.uvic.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130503/9532a5de/attachment.pl>

From john.maindonald at anu.edu.au  Sat May  4 02:10:05 2013
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Sat, 4 May 2013 10:10:05 +1000
Subject: [R-sig-ME] Ok with a "small amount" of non-normality?
In-Reply-To: <D3557409FD94BA41AE028A1E573716D646FBC5FD@S-BSC-MBX2.nrn.nrcan.gc.ca>
References: <D3557409FD94BA41AE028A1E573716D646FBC5FD@S-BSC-MBX2.nrn.nrcan.gc.ca>
Message-ID: <D7403566-F33A-44C2-9087-31E7E73ABE0B@anu.edu.au>

The question that you ask does not admit of an easy answer!
Hopefully the following will shed light on the general tack to be taken.

One can do simulations and check the effect of one or other level of
skewness (usually skewness to the right) on the parameter estimates.

The residuals (whether level 0 or level 1 in your case) are rarely the
right quantities to check for normality.  The way they are offered as
a source of insight in the Pinheiro and Bates book seems to me 
misleading in this respect.  

Consider a split plot design, with treatments estimated at the level of
plots within blocks, as in the kiwishade dataset in the DAAG package.
What matters for comparing treatments is the (approximate) normality
of what in the Genstat world would be called effects at the plot level.  
There are just 12 of these.  They can for this balanced design be 
obtained by basing the analysis on the plot means; they are the 
residuals from that analysis.

Any skewness at the subplot level gets somewhat averaged out.
(There are 4 subplot values per plot.)    The residuals from the lme
model, whether at the subplot or plot level, will exaggerate any 
skewness that may be due to variation between subplots.  Even in this
simple case, these 'effect' estimates are correlated, which somewhat
complicates the checking for normality. 

Direct checks for the distribution of the relevant quantities get quite messy
for unbalanced designs.  Bootstrap methods, having regard to the 
covariance structure, might be considered.  Or make a stab at the
distributions of the relevant component effects (now as in an lme or lmer
sense), and simulate.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 04/05/2013, at 4:36 AM, "Boulanger, Yan" <Yan.Boulanger at rncan-nrcan.gc.ca> wrote:

> Hi folks,
> This may be more of a "philosophical"- student question. In Zuur et al. (2009). "Mixed effects models and extensions in ecology with R", it is mentioned on page 20 that "[...] we can get away with a small amount of non-normality"
> I'm little bit puzzled when I face this kind of affirmation in a textbook. What is really "a small amount"?  Of course, it depends on your "judgement"...  In my case, I have level0 and level1 residuals that are unskewed and that show a relatively modest kurtosis (unbiased) of about 2.5 - 3.0. My models are based on several tens of thousands of individuals and normality tests (e.g., shapiro.test) always fail for residuals. QQ-plot show these rather long tails which correspond to "some" outliers (considering my data, there are several hundreds of "outliers" in this case). Homoscedaticity, when considering or not random effects, is not violated so I wondered if I could rely on these model's estimates considering the non-normality of the residuals. My judgement in this case would be that the departure from normality is not that high and this might not be a problem. But, as an ecologist, not a statistician, I have hard time to convince myself on this...  Any thoughts?
> 
> Thanks
> 
> Yan
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From ommo1 at hotmail.com  Sat May  4 14:28:34 2013
From: ommo1 at hotmail.com (Omnia Abdulrazeg)
Date: Sat, 4 May 2013 12:28:34 +0000
Subject: [R-sig-ME] groupedData plots (nlme)
Message-ID: <DUB106-W77C637E203DC970D144B8FEBF0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130504/ebfb4849/attachment.pl>

From 538280 at gmail.com  Sat May  4 18:32:31 2013
From: 538280 at gmail.com (Greg Snow)
Date: Sat, 4 May 2013 10:32:31 -0600
Subject: [R-sig-ME] Ok with a "small amount" of non-normality?
In-Reply-To: <D3557409FD94BA41AE028A1E573716D646FBC5FD@S-BSC-MBX2.nrn.nrcan.gc.ca>
References: <D3557409FD94BA41AE028A1E573716D646FBC5FD@S-BSC-MBX2.nrn.nrcan.gc.ca>
Message-ID: <CAFEqCdx7n2tjpiUrequ=DZqbNZ3DPdRca+H+vs9JqLaA+JcFUg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130504/42395816/attachment.pl>

From john.maindonald at anu.edu.au  Sun May  5 01:31:11 2013
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Sun, 5 May 2013 09:31:11 +1000
Subject: [R-sig-ME] Ok with a "small amount" of non-normality?
In-Reply-To: <CAFEqCdx7n2tjpiUrequ=DZqbNZ3DPdRca+H+vs9JqLaA+JcFUg@mail.gmail.com>
References: <D3557409FD94BA41AE028A1E573716D646FBC5FD@S-BSC-MBX2.nrn.nrcan.gc.ca>
	<CAFEqCdx7n2tjpiUrequ=DZqbNZ3DPdRca+H+vs9JqLaA+JcFUg@mail.gmail.com>
Message-ID: <5A3637A4-7FB5-4428-A906-7DE9E226E237@anu.edu.au>

One recourse I'd temporarily forgotten is to examine the sampling 
distributions of the parameter estimates that are given by mcmcsamp().  
You can check these for approximate normality, and you can derive 
credible intervals that do not depend on normality assumptions (but 
they will depend somewhat on the mcmcsamp() choice of prior).

Also, long-tailedness or kurtosis at a crucial level in the design may
I think lead to inefficient estimates, even though the sampling
distributions of parameter estimates appear close to normal.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 05/05/2013, at 2:32 AM, Greg Snow <538280 at gmail.com> wrote:

> To expand on John's answer, I would agree that simulation is the way to go.
> With simulation you can see how much your lack of normality affects the
> results that you are actually interested in (generally the results of a
> test or confidence interval).  This post:
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q1/001819.html shows
> some examples of using simulation with mixed effects models to determine if
> the p-values are behaving properly and also show one method of adjustment
> (using simulations) for still doing the tests when the formulas based on
> the normal assumption don't work.
> 
> 
> On Fri, May 3, 2013 at 12:36 PM, Boulanger, Yan <
> Yan.Boulanger at rncan-nrcan.gc.ca> wrote:
> 
>> Hi folks,
>> This may be more of a "philosophical"- student question. In Zuur et al.
>> (2009). "Mixed effects models and extensions in ecology with R", it is
>> mentioned on page 20 that "[...] we can get away with a small amount of
>> non-normality"
>> I'm little bit puzzled when I face this kind of affirmation in a textbook.
>> What is really "a small amount"?  Of course, it depends on your
>> "judgement"...  In my case, I have level0 and level1 residuals that are
>> unskewed and that show a relatively modest kurtosis (unbiased) of about 2.5
>> - 3.0. My models are based on several tens of thousands of individuals and
>> normality tests (e.g., shapiro.test) always fail for residuals. QQ-plot
>> show these rather long tails which correspond to "some" outliers
>> (considering my data, there are several hundreds of "outliers" in this
>> case). Homoscedaticity, when considering or not random effects, is not
>> violated so I wondered if I could rely on these model's estimates
>> considering the non-normality of the residuals. My judgement in this case
>> would be that the departure from normality is not that high and this might
>> not be a problem. But, as an ecologist, not a statistician, I have hard
>> time to convince myself on this...  Any thoughts?
>> 
>> Thanks
>> 
>> Yan
>> 
>> 
>> 
>> 
>>        [[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> 
> 
> -- 
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From mensurationist at gmail.com  Sat May  4 00:36:54 2013
From: mensurationist at gmail.com (Andrew Robinson)
Date: Sat, 4 May 2013 08:36:54 +1000
Subject: [R-sig-ME] Ok with a "small amount" of non-normality?
In-Reply-To: <D3557409FD94BA41AE028A1E573716D646FBC5FD@S-BSC-MBX2.nrn.nrcan.gc.ca>
References: <D3557409FD94BA41AE028A1E573716D646FBC5FD@S-BSC-MBX2.nrn.nrcan.gc.ca>
Message-ID: <F256FBDC-3EDB-4E44-A778-2670D2828EB2@gmail.com>

What are you doing with the estimates, Yan?  

Cheers 

Andrew 

--
Andrew Robinson
Deputy Director, ACERA
Senior Lecturer, Department of Mathematics and Statistics
The University of Melbourne
Parkville 3010 Victoria
Australia

http://ms.unimelb.edu.au/~andrewpr

On 04/05/2013, at 4:36 AM, "Boulanger, Yan" <Yan.Boulanger at RNCan-NRCan.gc.ca> wrote:

> Hi folks,
> This may be more of a "philosophical"- student question. In Zuur et al. (2009). "Mixed effects models and extensions in ecology with R", it is mentioned on page 20 that "[...] we can get away with a small amount of non-normality"
> I'm little bit puzzled when I face this kind of affirmation in a textbook. What is really "a small amount"?  Of course, it depends on your "judgement"...  In my case, I have level0 and level1 residuals that are unskewed and that show a relatively modest kurtosis (unbiased) of about 2.5 - 3.0. My models are based on several tens of thousands of individuals and normality tests (e.g., shapiro.test) always fail for residuals. QQ-plot show these rather long tails which correspond to "some" outliers (considering my data, there are several hundreds of "outliers" in this case). Homoscedaticity, when considering or not random effects, is not violated so I wondered if I could rely on these model's estimates considering the non-normality of the residuals. My judgement in this case would be that the departure from normality is not that high and this might not be a problem. But, as an ecologist, not a statistician, I have hard time to convince myself on this...  Any thoughts?
> 
> Thanks
> 
> Yan
> 
> 
> 
> 
>    [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From paulidealiste at aol.com  Mon May  6 12:16:11 2013
From: paulidealiste at aol.com (Milos Blagojevic)
Date: Mon, 6 May 2013 06:16:11 -0400 (EDT)
Subject: [R-sig-ME] lme4 with proportion data and lack of fir otherwise
Message-ID: <8D01859DE085C0B-2368-8E4C@webmail-d292.sysops.aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130506/1a1750a1/attachment.pl>

From soner.iscan2 at gmail.com  Mon May  6 12:36:00 2013
From: soner.iscan2 at gmail.com (Soner Iscan)
Date: Mon, 6 May 2013 12:36:00 +0200
Subject: [R-sig-ME] parameter estimation in lmer model
Message-ID: <CAMzhJjwyFX9gE8KWNf_fz_g2quJ9oHqzPytJGz6to1OmgiB48A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130506/05a73452/attachment.pl>

From Yan.Boulanger at RNCan-NRCan.gc.ca  Mon May  6 15:57:31 2013
From: Yan.Boulanger at RNCan-NRCan.gc.ca (Boulanger, Yan)
Date: Mon, 6 May 2013 13:57:31 +0000
Subject: [R-sig-ME] Ok with a "small amount" of non-normality?
In-Reply-To: <5A3637A4-7FB5-4428-A906-7DE9E226E237@anu.edu.au>
References: <D3557409FD94BA41AE028A1E573716D646FBC5FD@S-BSC-MBX2.nrn.nrcan.gc.ca>
	<CAFEqCdx7n2tjpiUrequ=DZqbNZ3DPdRca+H+vs9JqLaA+JcFUg@mail.gmail.com>
	<5A3637A4-7FB5-4428-A906-7DE9E226E237@anu.edu.au>
Message-ID: <D3557409FD94BA41AE028A1E573716D646FBC794@S-BSC-MBX2.nrn.nrcan.gc.ca>

Hi John, Greg et al.

Thank you very much for these insights! This will greatly help!

Yan 


>Yan Boulanger, Postdoctoral Visiting Fellow
>Ressources Naturelles Canada, Canadian Forest Service
>Centre de Foresterie des Laurentides
>1055, rue du P.E.P.S.
>C.P. 10380, succ. Sainte-Foy
>Qu?bec (Qu?bec) Canada
>G1V 4C7 
>Tel. : +1 418 649-6859

-----Original Message-----
From: John Maindonald [mailto:john.maindonald at anu.edu.au] 
Sent: 4 mai 2013 19:31
To: Greg Snow
Cc: Boulanger, Yan; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Ok with a "small amount" of non-normality?

One recourse I'd temporarily forgotten is to examine the sampling distributions of the parameter estimates that are given by mcmcsamp().  
You can check these for approximate normality, and you can derive credible intervals that do not depend on normality assumptions (but they will depend somewhat on the mcmcsamp() choice of prior).

Also, long-tailedness or kurtosis at a crucial level in the design may I think lead to inefficient estimates, even though the sampling distributions of parameter estimates appear close to normal.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194, John Dedman Mathematical Sciences Building (Building 27) Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 05/05/2013, at 2:32 AM, Greg Snow <538280 at gmail.com> wrote:

> To expand on John's answer, I would agree that simulation is the way to go.
> With simulation you can see how much your lack of normality affects 
> the results that you are actually interested in (generally the results 
> of a test or confidence interval).  This post:
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q1/001819.html 
> shows some examples of using simulation with mixed effects models to 
> determine if the p-values are behaving properly and also show one 
> method of adjustment (using simulations) for still doing the tests 
> when the formulas based on the normal assumption don't work.
> 
> 
> On Fri, May 3, 2013 at 12:36 PM, Boulanger, Yan < 
> Yan.Boulanger at rncan-nrcan.gc.ca> wrote:
> 
>> Hi folks,
>> This may be more of a "philosophical"- student question. In Zuur et al.
>> (2009). "Mixed effects models and extensions in ecology with R", it 
>> is mentioned on page 20 that "[...] we can get away with a small 
>> amount of non-normality"
>> I'm little bit puzzled when I face this kind of affirmation in a textbook.
>> What is really "a small amount"?  Of course, it depends on your 
>> "judgement"...  In my case, I have level0 and level1 residuals that 
>> are unskewed and that show a relatively modest kurtosis (unbiased) of 
>> about 2.5
>> - 3.0. My models are based on several tens of thousands of 
>> individuals and normality tests (e.g., shapiro.test) always fail for 
>> residuals. QQ-plot show these rather long tails which correspond to 
>> "some" outliers (considering my data, there are several hundreds of 
>> "outliers" in this case). Homoscedaticity, when considering or not 
>> random effects, is not violated so I wondered if I could rely on 
>> these model's estimates considering the non-normality of the 
>> residuals. My judgement in this case would be that the departure from 
>> normality is not that high and this might not be a problem. But, as 
>> an ecologist, not a statistician, I have hard time to convince myself on this...  Any thoughts?
>> 
>> Thanks
>> 
>> Yan
>> 
>> 
>> 
>> 
>>        [[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> 
> 
> --
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From ann.gerteis at edu.uni-graz.at  Mon May  6 16:15:17 2013
From: ann.gerteis at edu.uni-graz.at (Gerteis, Ann Kathrin Sophie (1114xxx))
Date: Mon, 6 May 2013 16:15:17 +0200
Subject: [R-sig-ME] MLM Output in nlme: Searching for coefficients to
 bootstrap mediation in a MLM with random intercept & random slope (to use
 with code generator at www.quantpsy.org)
Message-ID: <A6969B5C0E9BC14782100B5D92843FEEB28C092ECF@MSTUDAS.stud.ad.uni-graz.at>


Hi folks,

I have a question concerning the output of a multilevel model in nlme, which I want to test for mediation with a monte carlo simulation (using the r-code generator at http://www.quantpsy.org/medmc/medmc111.htm). 
I tried to figure it out myself, but now I managed to get myself really confused and basically I'm stuck at the moment. So I need advice from someone with more expertise in MLM and maybe bootstrapping (and surely statistics in gerneral, I fear).

-[- additional info concerning the data and the basic model -]-  
I'm modeling a physiological parameter (heart-rate variability) with some biobehavioral and psychological (control-)variables (v1-v9) and  psychological dependent variables (M and Y). The data stems from an ambulatory assessment with randomly repeated measures over 3 days from pairs of subjects. Therefore, the basic model is a multilevel model with a random intercept, a nested random slope and an autoregressive error structure:

basic<-lme(ln_rmssd~gz_v1+gz_v2+v3+v4+gz_v5+gz_v6+v7+v8+Y+M, random=~home|dyad/person/day, correlation=corCAR1(form=~time|dyad/person/day), na.action=na.omit). 

[Since the dataset is rather big and I'm not sure if you really need data to help, I'll not include conrcete data for now. If you think data would be necessary I could provide some]


-[- My Question -]-
I haven't been able to find and/or extract all of the requested input coefficients from my nmle-output. Quantpsy.org requests 7 input variables for the bootstrap. 
For the following 2 input coefficients I'm neither sure what they are nor do I know how to extract them from my nmle object:
        
        ?aj,bj  (= "point estimate of level-2 covariances of mediator and independent variable")

        ?^2?aj,bj  (="expected variability in the level-2 covariance between the aj and bj slopes over repeated sampling", should be somewhere in the ACM for the random effects - but how do I get that?)

For the following 5 I think I know how to aquire those:
        mean(aj) & mean(bj)  
             = Parameter estimates for the relation between mediator and independent variable, extracted via the summary() for
med1<-M~Y, random=~home|dyad/person/day, correlation=corCAR1(form=~time|dyad/person/day), na.action=na.omit)  and for
med2<-ln_rmssd~v1+...+v9+Y+M, random=~home|dyad/person/day, correlation=corCAR1(form=~time|dyad/person/day), na.action=na.omit)

         ?^2a, ?^2b  & ?a,b   
             = from the asymptotic covariance Matrix of the fixed effects (extracted with vcov() for med2)

One last thought: I know I could use the sobel() function, but afaik sobel calculates on the assumption of normal distributed errors, whereas the bootstrap simulates the error structure within the empirical data. Furthermore, with sobel() I can neither integrate the control variables (necessary for the prediction of ln_rmssd) nor the nesting of the data into the calculation for the mediation effect. At least, as far as I understood the whole thing...

A slight bump over the head and a "How-To"-advice for dummies would be highly appreciated!

Thank you,
Ann Kathrin


--
Gesundheitspsychologie, KFU Graz
T  +43 (0) 316 380 4950
E  ann.gerteis at edu.uni-graz.at

From Yan.Boulanger at RNCan-NRCan.gc.ca  Mon May  6 19:54:04 2013
From: Yan.Boulanger at RNCan-NRCan.gc.ca (Boulanger, Yan)
Date: Mon, 6 May 2013 17:54:04 +0000
Subject: [R-sig-ME] Forcing mixed models through origin
Message-ID: <D3557409FD94BA41AE028A1E573716D646FBC85D@S-BSC-MBX2.nrn.nrcan.gc.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130506/d6221ec5/attachment.pl>

From marko.bachl at uni-hohenheim.de  Mon May  6 20:19:15 2013
From: marko.bachl at uni-hohenheim.de (Marko Bachl)
Date: Mon, 6 May 2013 20:19:15 +0200
Subject: [R-sig-ME] Fixed covariates in nlmer()
In-Reply-To: <OFB0FB486E.2DEB7EEB-ONCA257B56.002869D8-CA257B56.0029267D@LocalDomain>
References: <OFB0FB486E.2DEB7EEB-ONCA257B56.002869D8-CA257B56.0029267D@LocalDomain>
Message-ID: <CAE5vbrv-V-3OcqLUfojNCoPyZMUX7w+8d6uhGvh9cPvXFSBp0g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130506/8043f895/attachment.pl>

From hughsturrock at hotmail.com  Tue May  7 01:41:53 2013
From: hughsturrock at hotmail.com (Hugh Sturrock)
Date: Tue, 7 May 2013 00:41:53 +0100
Subject: [R-sig-ME] Spatially autocorrelated random effects
Message-ID: <DUB116-W7ABA590FEFAFC8F6E7580C8B90@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130507/32bf5df2/attachment.pl>

From seth at swbigelow.net  Tue May  7 15:39:43 2013
From: seth at swbigelow.net (Seth Bigelow)
Date: Tue, 7 May 2013 09:39:43 -0400
Subject: [R-sig-ME] lme4 with proportion data and lack of fir otherwise
In-Reply-To: <8D01859DE085C0B-2368-8E4C@webmail-d292.sysops.aol.com>
References: <8D01859DE085C0B-2368-8E4C@webmail-d292.sysops.aol.com>
Message-ID: <000d01ce4b28$55fe5770$01fb0650$@net>

Since your dependent variable consists of proportions, you might try
summarizing it with a diversity index like the Shannon-Weaver-Wiener, i.e.,
Index = -Sum(p[i]*log(p[i])), where p[i] is the proportion of meadow,
forest, or ploughland. Then making a model using the index as a continuous,
independent variable. Since this index is a measure of 'information', and
will tend to be largest when the 3 landscape types are in even proportions,
you can even make an argument that there should be a correlation between
landscape information content, and whatever cranial dimensions you are
measuring...

--Seth




-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Milos
Blagojevic
Sent: Monday, May 06, 2013 6:16 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] lme4 with proportion data and lack of fir otherwise



Hi all,


This is my first post on this list that is motivated by a mixed-effect
problems I experience with my data. I have a dataset with 50 cranial
measurements that was reduced by PCA to six common variables (this step may
be optional for the model). My aim is to formulate a good statistical model
using either individual PC scores or individual characters as dependent
variables. Predictors are environmental variables, population density, total
area and proportions of forest, meadow and plowland expressed as ratios that
add up to one. The last predictors are the most important for my hypotheses.



Since every individual has its own PC score or length value but all
environmental variables are the same for all individuals that belong to the
same population my only solution was to use a mixed-effect model that will
control for this perfect correlations in predictor variables. Random term
should thus be population and predictors should be entered into a model like
this


lmer(PC1 ~ fore * mead * plo + (1|pop), data = PCscores) where predictors
are proportions. Other predictors excluded. 



Anovas (car type II) report no significance in any of the model terms (I
know this is not the right way of interpreting lmer models).


I would appreciate any idea on model formulation and a possible graphic
representation of these results.  



This is the output

  
Linear mixed model fit by REML
Formula: PC1s ~ fore * mead * plo + (1 | pop) 
   Data: PCscoresLog
  AIC  BIC logLik deviance REMLdev
 2979 3023  -1480     3018    2959
Random effects:
 Groups   Name        Variance Std.Dev.
 pop      (Intercept)  3.0171  1.7370  
 Residual             11.5588  3.3998  
Number of obs: 567, groups: pop, 12

Fixed effects:
              Estimate Std. Error t value
(Intercept)    -55.405    147.496  -0.376
fore            45.983    146.222   0.314
mead             4.128    162.703   0.025
plo             55.533    147.743   0.376
fore:mead       98.644    187.813   0.525
fore:plo        16.972     29.573   0.574
mead:plo        71.979    128.921   0.558
fore:mead:plo -115.183    129.659  -0.888

Correlation of Fixed Effects:
            (Intr) fore   mead   plo    for:md for:pl med:pl
fore        -0.998                                          
mead        -0.796  0.832                                   
plo         -1.000  0.998  0.798                            
fore:mead   -0.182  0.117 -0.449  0.177                     
fore:plo    -0.065  0.066  0.223  0.059 -0.227              
mead:plo    -0.173  0.111 -0.455  0.168  0.992 -0.236       
fore:med:pl  0.236 -0.237 -0.307 -0.229  0.117 -0.887  0.10



Thanks in advance,


Milos Blagojevic,
Faculty Of Science,
Kragujevac,
Serbia
email: paulidealiste at aol.com



	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From Sarah.Donegan at liverpool.ac.uk  Tue May  7 15:32:25 2013
From: Sarah.Donegan at liverpool.ac.uk (Donegan, Sarah)
Date: Tue, 7 May 2013 13:32:25 +0000
Subject: [R-sig-ME] variance structure of random effects using lme
Message-ID: <9EED70DACB090F46AAB9C07362D62F7A52C85538@BHEXMBX1.livad.liv.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130507/2ba26b2f/attachment.pl>

From seth at swbigelow.net  Wed May  8 15:47:34 2013
From: seth at swbigelow.net (Seth Bigelow)
Date: Wed, 8 May 2013 09:47:34 -0400
Subject: [R-sig-ME] lme4 with proportion data and lack of fir otherwise
In-Reply-To: <8D0197402CA6FFC-11E8-1708A@webmail-vm007.sysops.aol.com>
References: <8D01859DE085C0B-2368-8E4C@webmail-d292.sysops.aol.com>
	<000d01ce4b28$55fe5770$01fb0650$@net>
	<8D0197402CA6FFC-11E8-1708A@webmail-vm007.sysops.aol.com>
Message-ID: <001801ce4bf2$99d7d230$cd877690$@net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130508/2480363f/attachment.pl>

From fci201 at exeter.ac.uk  Wed May  8 17:15:03 2013
From: fci201 at exeter.ac.uk (Ingleby, Fiona)
Date: Wed, 8 May 2013 15:15:03 +0000
Subject: [R-sig-ME] MCMCglmm model with 2 datasets
Message-ID: <FD6F6B8A5C87974AA3DC10E3656878B110322F@VMEXCHANGEMBS6A.isad.isadroot.ex.ac.uk>

Hi everyone,

I posted a similar problem a few weeks ago, so I apologise for some repetition. In response to my previous email, someone helped me simplify my problem a bit, but unfortunately I'm still having difficulty so I'd really appreciate any further help anyone can offer.

I have two datasets, one with four traits measured in male and female individuals from a set of families, and the second dataset with another trait measured in males and females from the same set of families, but using different individuals (and different sample sizes) from those families.

I started with this model, using only the data from the larger dataset with four traits:

prior <- list( R=list(V=diag(4)/4,nu=0.5), G=list(G1=list(V=diag(8)/8,nu=0.5)) )
model <- MCMCglmm( cbind(trait1, trait2,trait3,trait4) ~ sex:trait-1,random=~us(sex:trait):family,
             rcov=~us(trait):units,prior=prior,data=data,family=rep("gaussian",4),
             nitt=400000,burnin=20000,thin=25,pr=T)

So far, pretty straightforward. My problem is that I would like to be able, if possible, to analyse this data along with the fifth trait from the second dataset. So I'm thinking along these lines:

prior <- list( R=list(V=diag(5)/5,nu=0.5), G=list(G1=list(V=diag(10)/10,nu=0.5)) )
model <- MCMCglmm( cbind(trait1, trait2,trait3,trait4, TRAIT5) ~ sex:trait-1,random=~us(sex:trait):family,
             rcov=~us(trait):units,prior=prior,data=data,family=rep("gaussian",5),
             nitt=400000,burnin=20000,thin=25,pr=T)

Which of course wouldn't be a problem if (a) the datasets were the same length, and (b) the data for the 5 traits had been measured on the same individuals. Since they are not, I'm left with two problems. 

I don't want to estimate the individual level covariances between traits, since they are measured on different individuals. But if I try to specify a model without the individual-level ('units') term, then I get an error message stating that unique residuals have not been defined for each datapoint. Is there a way of doing this?

My second problem is of course the different lengths of datasets. I tried to get around this by filling in the shorter dataset with NA missing data values within each family, but I'm not sure that this is a good idea, as the missing data values are read as if they are associated with the corresponding row of the bigger dataset and I'm worried this will bias the results. If anyone can think of a different way of going about this then I would be very grateful.

Thanks again,

Fiona 


From volker.dellwo at uzh.ch  Wed May  8 18:04:07 2013
From: volker.dellwo at uzh.ch (Volker Dellwo)
Date: Wed, 08 May 2013 18:04:07 +0200
Subject: [R-sig-ME] mixed-models problem
Message-ID: <518A7777.5020509@uzh.ch>

Dear R people,

I am new to R and mixed models and receive rather strange and 
contradictory results for a data analysis. Below is some R code with 
detailed comments. The data file is attached to the mail.

I would be very grateful for any suggestions!! I appreciate that this is 
probably a longer question than typically found on this list but it is 
important to me. So if anyone wants to offer me some paid assistance 
with this problem (e.g via Skype) I am more than happy to receive your 
suggestions.

With many many thanks in advance for your help!
Yours,
Volker

### R code starts here ####

# In an experiment, 15 speakers read a text consisting of 7 sentences 
under 5 different intended tempo categories, so we have three factors: 
tempo, speaker and sentence. We measured the percentage over which 
speech is vocalic (%V) for each sentence so N = 525 (15 speakers x 5 
tempos x 7 sentences). I am now particularly interested in between 
speaker differences of %V. Here is what I did:

rm(list = ls())
bt.data <- read.table("/Users/Flok/Desktop/BonnTempoData.txt",header=TRUE);

speaker <- factor(bt.data$speaker);
sentence <- factor(bt.data$sentence);
tempo <- factor(bt.data$tempo);
percentV <- bt.data$percentV
percentV_zScore <- bt.data$percentV_zScore

summary(speaker)
summary(sentence)
summary(tempo)
length(percentV)

     # (1) Descriptives:

             # Descriptively the differences between speakers seem 
strong. Sentence differences also look strong but there seems to be no 
difference in %V between the five different tempo conditions as you can 
see in the following box-plots:
             boxplot(percentV ~ tempo)
             boxplot(percentV ~ speaker)
             boxplot(percentV ~ sentence)

     # (2) Inferentials:

             #Inferentially I first tried an ANOVA which basically 
confrims all the descriptive results above. But then, ANOVA does not 
seem to be an appropriate model here as the assumption of data 
independence is violated (each subject reads the same sentences 
repeatedly). So I have been recommended to use linear mixed models, 
which apparently gets more and more popular in my field. These models, 
however, tell me a very differnt story of what I can see in the data:

         # (2.1) Use lme4 package for analysis:
         library(lme4);
         library(languageR);

             # Surprisingly there is a strong effect of tempo:
             modelA <- lmer(percentV ~ tempo + (1|speaker) + 
(1|sentence), data=bt.data);
             pvals.modelA <- pvals.fnc(modelA);
             print(pvals.modelA)

             # Again, surprisingly there is no effect of seaker:
             modelB <- lmer(percentV ~ speaker + (1|tempo) + 
(1|sentence), data=bt.data);
             pvals.modelB <- pvals.fnc(modelB);
             print(pvals.modelB)

             # And again, no effect of sentence:
             modelC <- lmer(percentV ~ sentence + (1|tempo) + 
(1|sentence), data=bt.data);
             pvals.modelC <- pvals.fnc(modelC);
             print(pvals.modelC)

             # Comparing two models with and without speaker as a fixed 
effect comes to the same result:
             modelD <- lmer(percentV ~ 1 + (1|tempo) + (1|sentence), 
data=bt.data);
             anova.BvsD <- anova(modelB, modelD);
             print(anova.BvsD)

         # (2.2) Using the nlme package:
         library(nlme);

             # Now someone suggested to me to test the effects of 
speaker by adding speaker and sentence as a random factor in one model 
and excluding them consecutively in others and the comparing the models. 
When I do that, speaker is significant:

             modelA <- lme(percentV ~ tempo, 
random=list((~1|speaker),(~1|sentence)), data=bt.data, 
na.action=na.omit, method="ML");

             modelB <- lme(percentV ~ tempo, random=list((~1|sentence)), 
data=bt.data, na.action=na.omit, method="ML");

             modelC <- lme(percentV ~ tempo, random=list((~1|sentence)), 
data=bt.data, na.action=na.omit, method="ML");

             # Now we still get main effects for tempo:
             anova.modelA <- anova(modelA)
             print(anova.modelA)

             # But we also get effects for speaker and tempo when 
contrasting the models:
             comparison.AvsB <- anova(modelA, modelB);
             print(comparison.AvsB)
             comparison.AvsC <- anova(modelA, modelC);
             print(comparison.AvsC)

# So I have two questions:

     # (a) Why are the effects of the mixed-models so much different 
from what I can see descriptively? I would certainly not expect an 
effect of tempo here at all but possibly speaker and/or sentence.

     # (b) Why do I get to categorically different results depending in 
the method I choose (2.1: speaker and sentence are not significant, 2.2 
speaker and sentence are significant)

# I'm extremely greatful for any comments and/or help!


-------------- next part --------------
speaker	tempo	sentence	percentV	percentV_zScore
10	1	1	38.90868389	-0.581041923
10	1	2	46.89079638	0.010657968
10	1	3	45.07412233	-0.572797337
10	1	4	42.79976052	0.346660179
10	1	5	43.63491409	-0.529863443
10	1	6	34.5906477	-0.795338428
10	1	7	43.2971423	0.094017374
11	1	1	38.67466301	-0.634629198
11	1	2	40.71810932	-1.205531824
11	1	3	47.32369919	-0.104662568
11	1	4	34.60527629	-1.161789475
11	1	5	42.16068757	-0.867815669
11	1	6	34.9158439	-0.70743823
11	1	7	41.38990857	-0.354609154
12	1	1	39.02359271	-0.554729526
12	1	2	29.17358286	-3.480122311
12	1	3	40.58417884	-1.507150235
12	1	4	32.93516835	-1.469224778
12	1	5	39.58336524	-1.458641984
12	1	6	34.80753081	-0.736715148
12	1	7	37.87122487	-1.182286867
13	1	1	42.69462396	0.285881601
13	1	2	40.78154473	-1.193033297
13	1	3	50.13424228	0.480208732
13	1	4	42.01176398	0.20160491
13	1	5	46.46312379	0.118476386
13	1	6	38.58510967	0.284360513
13	1	7	47.0012523	0.965311742
14	1	1	42.8129084	0.312966964
14	1	2	48.0707615	0.243143679
14	1	3	48.77469408	0.197288066
14	1	4	38.5214839	-0.440889678
14	1	5	46.24096508	0.067548643
14	1	6	33.13491189	-1.188822314
14	1	7	43.25311914	0.083662083
15	1	1	46.52104222	1.162074025
15	1	2	52.92729754	1.200015381
15	1	3	54.21750703	1.329932177
15	1	4	47.7835631	1.264084029
15	1	5	50.18060798	0.970673824
15	1	6	40.41895495	0.780046996
15	1	7	46.90765539	0.943295533
16	1	1	46.34613543	1.12202299
16	1	2	56.68248055	1.939890124
16	1	3	53.89094	1.261973893
16	1	4	42.13591365	0.224458519
16	1	5	39.90129401	-1.385759877
16	1	6	39.46997063	0.523537515
16	1	7	58.23507935	3.60777383
17	1	1	37.49588084	-0.904552644
17	1	2	49.2611641	0.477685861
17	1	3	40.40458695	-1.544523133
17	1	4	30.66076707	-1.887899063
17	1	5	42.94087871	-0.688964366
17	1	6	30.6927427	-1.848938121
17	1	7	38.03601603	-1.143524086
18	1	1	42.75660142	0.30007351
18	1	2	37.50192341	-1.839209256
18	1	3	44.27988005	-0.738078387
18	1	4	30.79265403	-1.863621167
18	1	5	40.65326721	-1.213377266
18	1	6	33.7055995	-1.03456604
18	1	7	40.98608657	-0.449597649
19	1	1	41.92621739	0.109928016
19	1	2	53.88913844	1.389524597
19	1	3	53.65088256	1.212018172
19	1	4	48.56991745	1.408837002
19	1	5	51.95226977	1.376810223
19	1	6	43.43645378	1.595673809
19	1	7	49.06236192	1.450133523
20	1	1	44.43762595	0.685002929
20	1	2	48.04944731	0.238944195
20	1	3	53.87776918	1.259233057
20	1	4	47.84846523	1.276031285
20	1	5	49.35131913	0.780567345
20	1	6	41.86015416	1.169601653
20	1	7	47.70362943	1.130527472
21	1	1	40.98264462	-0.106136005
21	1	2	46.52395216	-0.061620472
21	1	3	50.93643644	0.647144559
21	1	4	36.8403171	-0.750360709
21	1	5	46.26733929	0.073594675
21	1	6	39.4548309	0.519445263
21	1	7	47.36590281	1.051086176
22	1	1	41.68567373	0.054847123
22	1	2	43.45765766	-0.665765157
22	1	3	44.04044034	-0.787905558
22	1	4	38.60152009	-0.426156529
22	1	5	43.1317074	-0.645218729
22	1	6	31.0583696	-1.750109547
22	1	7	40.41968015	-0.582829851
23	1	1	33.70000224	-1.773751944
23	1	2	39.44211244	-1.456938445
23	1	3	47.62971097	-0.040981813
23	1	4	39.20669486	-0.314755292
23	1	5	43.14575774	-0.641997823
23	1	6	37.46279979	-0.018998687
23	1	7	45.17027309	0.534622082
24	1	1	40.74892025	-0.159655382
24	1	2	39.00559153	-1.542945117
24	1	3	46.53480493	-0.268830701
24	1	4	36.59664158	-0.795216766
24	1	5	42.93288387	-0.690797107
24	1	6	35.9294384	-0.433464685
24	1	7	40.0175229	-0.677426757
10	2	1	40.61593487	-0.190107041
10	2	2	48.90090604	0.406705076
10	2	3	45.78686163	-0.424476979
10	2	4	38.17144245	-0.505325693
10	2	5	49.92442719	0.911946847
10	2	6	32.88943368	-1.255174818
10	2	7	43.94697113	0.246872498
11	2	1	37.06278539	-1.003725011
11	2	2	41.50464241	-1.050563088
11	2	3	48.75643158	0.193487657
11	2	4	39.77709313	-0.209755753
11	2	5	44.26694402	-0.384976669
11	2	6	35.73153805	-0.486956946
11	2	7	38.26654645	-1.089297874
12	2	1	38.36162898	-0.706309297
12	2	2	43.87322264	-0.583887381
12	2	3	40.70057494	-1.482928318
12	2	4	35.23153482	-1.046507117
12	2	5	39.47231161	-1.484099961
12	2	6	34.48706438	-0.823336891
12	2	7	40.9343592	-0.461765152
13	2	1	37.13684856	-0.986765655
13	2	2	46.00701363	-0.163471636
13	2	3	51.14176536	0.68987331
13	2	4	40.97237614	0.010273255
13	2	5	46.41551545	0.107562633
13	2	6	38.42606318	0.241370412
13	2	7	47.7483321	1.141042598
14	2	1	35.08426879	-1.456775654
14	2	2	48.65456255	0.358168607
14	2	3	41.7295252	-1.268804763
14	2	4	38.11688181	-0.515369276
14	2	5	44.71619888	-0.281989319
14	2	6	34.81606418	-0.734408588
14	2	7	44.46330003	0.368325281
15	2	1	49.22592826	1.78145238
15	2	2	46.16399411	-0.132542147
15	2	3	57.25149972	1.96130312
15	2	4	45.11197175	0.772294561
15	2	5	54.68057104	2.002247006
15	2	6	38.06616592	0.144090555
15	2	7	48.1591487	1.237676389
16	2	1	47.86379265	1.469543746
16	2	2	47.10840744	0.053533357
16	2	3	49.80432767	0.41155382
16	2	4	37.75029327	-0.582851296
16	2	5	45.61035639	-0.077012325
16	2	6	31.24365964	-1.700025841
16	2	7	47.8504308	1.16505863
17	2	1	36.62722943	-1.103460796
17	2	2	44.24219911	-0.511188828
17	2	3	42.2432044	-1.161908619
17	2	4	30.54025358	-1.91008332
17	2	5	42.96862513	-0.682603768
17	2	6	34.55079063	-0.806111752
17	2	7	37.06146441	-1.3727617
18	2	1	37.72604128	-0.851849354
18	2	2	38.13167509	-1.715130786
18	2	3	45.24463637	-0.53731353
18	2	4	34.51455433	-1.178489673
18	2	5	39.65049437	-1.44325328
18	2	6	34.01121183	-0.951959344
18	2	7	40.17003543	-0.641552198
19	2	1	42.61893148	0.268549157
19	2	2	52.90346681	1.195320068
19	2	3	51.95715269	0.859554625
19	2	4	47.98563207	1.301281107
19	2	5	53.81823345	1.804564421
19	2	6	41.19799375	0.990620379
19	2	7	47.06651322	0.980662656
20	2	1	41.46750524	0.004889809
20	2	2	50.30337067	0.683029335
20	2	3	50.31834647	0.518520636
20	2	4	46.3506281	1.000307782
20	2	5	48.86323046	0.668677719
20	2	6	40.20762372	0.722924383
20	2	7	43.3100392	0.09705103
21	2	1	41.1510144	-0.06758185
21	2	2	49.56332308	0.537219524
21	2	3	52.75585918	1.025764673
21	2	4	42.93992713	0.372462202
21	2	5	45.44190073	-0.115629161
21	2	6	39.76252862	0.602615637
21	2	7	47.27001628	1.028531394
22	2	1	40.36274437	-0.248083871
22	2	2	46.44787779	-0.076609222
22	2	3	42.03580596	-1.205068034
22	2	4	35.91343466	-0.920982247
22	2	5	42.85608329	-0.7084029
22	2	6	35.12614063	-0.650595242
22	2	7	41.19896057	-0.399524644
23	2	1	34.48721641	-1.593491698
23	2	2	47.36714683	0.104512162
23	2	3	48.57905002	0.156574726
23	2	4	38.21041225	-0.49815209
23	2	5	45.38553188	-0.128551178
23	2	6	34.16434614	-0.9105673
23	2	7	46.21530536	0.780438414
24	2	1	36.13480982	-1.216217505
24	2	2	42.68335359	-0.818324438
24	2	3	42.524971	-1.103273263
24	2	4	37.07422767	-0.707302195
24	2	5	43.41114767	-0.581159739
24	2	6	32.33720783	-1.404440896
24	2	7	40.64684279	-0.529395819
10	3	1	41.60401651	0.036148843
10	3	2	47.78801377	0.187434569
10	3	3	48.71615153	0.185105418
10	3	4	40.30255334	-0.113028461
10	3	5	50.03537458	0.937380466
10	3	6	35.55761296	-0.533968719
10	3	7	41.79220635	-0.259979193
11	3	1	40.20427112	-0.284371868
11	3	2	51.13403253	0.846692658
11	3	3	48.10545938	0.058020971
11	3	4	42.73956871	0.335580005
11	3	5	47.38783101	0.330456609
11	3	6	36.76742443	-0.206957928
11	3	7	41.34687347	-0.36473203
12	3	1	36.82352642	-1.058511727
12	3	2	45.54286113	-0.254922495
12	3	3	40.5950885	-1.504879944
12	3	4	34.23831665	-1.229339808
12	3	5	45.41526087	-0.121736093
12	3	6	35.20932005	-0.628111931
12	3	7	36.68148884	-1.46214095
13	3	1	39.12927049	-0.530530898
13	3	2	46.0497498	-0.15505143
13	3	3	46.01292904	-0.377432569
13	3	4	41.06228917	0.026824545
13	3	5	45.79679272	-0.034273592
13	3	6	38.43230879	0.243058593
13	3	7	45.42833892	0.595325275
14	3	1	38.80750883	-0.604209495
14	3	2	45.37650959	-0.287698342
14	3	3	45.37131723	-0.510951365
14	3	4	32.97599949	-1.461708538
14	3	5	46.89851182	0.218284898
14	3	6	33.35101572	-1.13040967
14	3	7	40.30358057	-0.610139219
15	3	1	52.30806873	2.487216346
15	3	2	57.61333685	2.123294517
15	3	3	52.29655698	0.930184328
15	3	4	47.92218784	1.289602225
15	3	5	55.33797459	2.152950437
15	3	6	40.98619758	0.933372092
15	3	7	46.64572848	0.881684122
16	3	1	44.93007909	0.797767315
16	3	2	48.37466705	0.303021464
16	3	3	52.4178145	0.955417901
16	3	4	41.98524757	0.196723741
16	3	5	45.50432277	-0.101319512
16	3	6	39.70561346	0.587231528
16	3	7	42.36967972	-0.124143783
17	3	1	40.43492165	-0.231556355
17	3	2	41.84095754	-0.98429972
17	3	3	45.03022104	-0.581933154
17	3	4	37.19672449	-0.684752846
17	3	5	40.47425433	-1.254414243
17	3	6	36.35019691	-0.319734096
17	3	7	34.90373158	-1.880311547
18	3	1	32.24685639	-2.106500561
18	3	2	40.45859567	-1.25666318
18	3	3	43.68961816	-0.860911316
18	3	4	36.66671219	-0.782318091
18	3	5	41.89772556	-0.928097176
18	3	6	32.60373024	-1.332400163
18	3	7	40.88012554	-0.474522194
19	3	1	42.01104394	0.129352023
19	3	2	52.95841525	1.206146429
19	3	3	49.2727081	0.3009243
19	3	4	43.77066145	0.525384689
19	3	5	50.20742648	0.976821708
19	3	6	38.74729003	0.328197696
19	3	7	39.99347344	-0.683083759
20	3	1	42.02080408	0.131586949
20	3	2	44.55145484	-0.450256909
20	3	3	55.30997409	1.557273514
20	3	4	46.81359192	1.08553067
20	3	5	52.19313581	1.432026441
20	3	6	38.74432976	0.327397539
20	3	7	44.97075369	0.487690395
21	3	1	43.5613332	0.484345024
21	3	2	49.42870689	0.510696417
21	3	3	53.9742568	1.279312039
21	3	4	44.65460526	0.688102036
21	3	5	45.27539708	-0.153798519
21	3	6	41.99749968	1.206726005
21	3	7	46.93612591	0.949992473
22	3	1	40.75444294	-0.15839077
22	3	2	47.68951023	0.168026652
22	3	3	43.35066375	-0.931447401
22	3	4	38.13753868	-0.511566737
22	3	5	43.40914222	-0.581619467
22	3	6	35.71808341	-0.490593721
22	3	7	42.55764775	-0.079929253
23	3	1	40.06442369	-0.316394835
23	3	2	49.1488156	0.455550104
23	3	3	51.90064498	0.847795425
23	3	4	44.83359977	0.721051541
23	3	5	48.95085962	0.688765859
23	3	6	42.17319055	1.254215064
23	3	7	44.43427933	0.361498925
24	3	1	44.59802164	0.721731138
24	3	2	45.66201795	-0.23144531
24	3	3	48.26683992	0.091604107
24	3	4	45.17983688	0.784787248
24	3	5	44.57489842	-0.314381089
24	3	6	38.06660941	0.144210429
24	3	7	37.99402653	-1.153401009
10	4	1	42.19785906	0.172129885
10	4	2	48.79755694	0.38634245
10	4	3	46.49533194	-0.277044991
10	4	4	42.26207788	0.247682968
10	4	5	48.96483251	0.691969011
10	4	6	38.44936291	0.247668305
10	4	7	40.33791401	-0.602063181
11	4	1	38.04948749	-0.777785019
11	4	2	44.17964214	-0.523514277
11	4	3	50.56095808	0.569007877
11	4	4	40.63627216	-0.051597134
11	4	5	48.98769487	0.697209986
11	4	6	37.04826053	-0.131048221
11	4	7	35.56463652	-1.724851057
12	4	1	38.91653207	-0.579244808
12	4	2	42.56884263	-0.84088626
12	4	3	44.56578435	-0.678581978
12	4	4	36.45167356	-0.821902638
12	4	5	42.65453245	-0.754606489
12	4	6	35.67166142	-0.503141536
12	4	7	39.16257806	-0.878530025
13	4	1	42.12922586	0.15641391
13	4	2	48.34107936	0.296403762
13	4	3	47.53859808	-0.059942316
13	4	4	43.90908207	0.550865307
13	4	5	48.84105024	0.663593117
13	4	6	41.2234703	0.997506663
13	4	7	47.05547293	0.978065717
14	4	1	38.9985276	-0.560469062
14	4	2	45.5988676	-0.243887675
14	4	3	45.48091288	-0.488144617
14	4	4	40.83653834	-0.014731915
14	4	5	42.21617048	-0.855096747
14	4	6	34.81413473	-0.734930114
14	4	7	39.6240949	-0.769970336
15	4	1	49.74391288	1.900063095
15	4	2	50.42392221	0.706781317
15	4	3	55.69911278	1.6382529
15	4	4	48.24092404	1.348275534
15	4	5	53.46575742	1.723762686
15	4	6	43.38251827	1.581095098
15	4	7	48.42893652	1.301136872
16	4	1	46.66940007	1.196045747
16	4	2	49.20454545	0.466530425
16	4	3	51.83218269	0.833548487
16	4	4	41.20014338	0.052200899
16	4	5	46.90933243	0.220765419
16	4	6	39.28662695	0.473979907
16	4	7	43.98556758	0.255951298
17	4	1	38.15363945	-0.753935783
17	4	2	47.79528697	0.188867591
17	4	3	42.84947734	-1.035743806
17	4	4	43.18569744	0.417703871
17	4	5	43.75078006	-0.503302284
17	4	6	35.55992423	-0.533343983
17	4	7	37.24308153	-1.330041054
18	4	1	39.4765874	-0.451000533
18	4	2	40.63659175	-1.221593037
18	4	3	44.0703638	-0.781678515
18	4	4	34.09279392	-1.256127793
18	4	5	40.57971014	-1.230239514
18	4	6	36.87080477	-0.17901433
18	4	7	39.23500238	-0.86149411
19	4	1	44.41372106	0.679529068
19	4	2	52.88146222	1.190984557
19	4	3	48.25397907	0.088927775
19	4	4	43.18270228	0.417152519
19	4	5	51.32281051	1.232512751
19	4	6	41.67685256	1.12005542
19	4	7	47.49792292	1.082140432
20	4	1	47.31804173	1.344574964
20	4	2	52.59193357	1.133939418
20	4	3	52.25913471	0.922396791
20	4	4	49.52844116	1.5852831
20	4	5	52.22049296	1.438297805
20	4	6	43.96076205	1.737393795
20	4	7	46.99633963	0.964156164
21	4	1	38.36013479	-0.706651444
21	4	2	47.33185583	0.09755886
21	4	3	53.1140966	1.100313534
21	4	4	48.91125011	1.471669893
21	4	5	48.84921152	0.665464012
21	4	6	41.49882703	1.071935303
21	4	7	44.33567115	0.338303946
22	4	1	38.44471446	-0.687283969
22	4	2	44.32141149	-0.495581802
22	4	3	40.49546335	-1.525611842
22	4	4	34.1220246	-1.250746976
22	4	5	40.61342283	-1.222511205
22	4	6	36.43752972	-0.296128127
22	4	7	42.1861335	-0.167318201
23	4	1	42.22408535	0.178135312
23	4	2	45.07333676	-0.34743176
23	4	3	51.3409185	0.731316886
23	4	4	46.83097049	1.088729737
23	4	5	48.4423706	0.57219965
23	4	6	42.45438734	1.330222268
23	4	7	44.25540877	0.319424335
24	4	1	41.84957467	0.09237798
24	4	2	43.14064941	-0.728224535
24	4	3	45.55837444	-0.472024941
24	4	4	39.55544497	-0.25055699
24	4	5	44.88775091	-0.24266267
24	4	6	41.43430368	1.054494708
24	4	7	36.88290721	-1.414762581
10	5	1	40.54202887	-0.207030407
10	5	2	54.46217548	1.502428717
10	5	3	43.86217537	-0.825002327
10	5	4	40.94422691	0.005091514
10	5	5	50.30651651	0.999537143
10	5	6	39.8383409	0.623107619
10	5	7	42.18074837	-0.168584911
11	5	1	49.32255653	1.803578806
11	5	2	53.28661096	1.270810046
11	5	3	48.81929128	0.2065687
11	5	4	44.23579802	0.611007538
11	5	5	47.23339427	0.295053474
11	5	6	39.44499674	0.5167871
11	5	7	42.61689526	-0.065992835
12	5	1	41.57652066	0.029852705
12	5	2	49.29952297	0.485243619
12	5	3	36.70744098	-2.313895633
12	5	4	30.62123136	-1.895176841
12	5	5	40.58737816	-1.228481696
12	5	6	30.55885286	-1.885128406
12	5	7	39.81511895	-0.725036957
13	5	1	45.47159307	0.921765901
13	5	2	44.52479339	-0.455509952
13	5	3	51.55328742	0.775510652
13	5	4	40.16246911	-0.138815319
13	5	5	44.35352197	-0.365129509
13	5	6	41.15455459	0.978878818
13	5	7	45.30482663	0.56627226
14	5	1	39.61716537	-0.418810286
14	5	2	51.23588809	0.866761014
14	5	3	45.44613351	-0.49538217
14	5	4	40.97205513	0.010214165
14	5	5	46.4782587	0.121945919
14	5	6	42.00962347	1.210003053
14	5	7	39.01070487	-0.914254195
15	5	1	56.60055566	3.47013151
15	5	2	52.79120294	1.173200987
15	5	3	52.65467384	1.004708101
15	5	4	50.46742951	1.758133106
15	5	5	50.67547283	1.084116824
15	5	6	43.13359362	1.513811022
15	5	7	48.92550143	1.417940695
16	5	1	48.14918748	1.534894882
16	5	2	51.42680327	0.904376577
16	5	3	53.78497894	1.239923499
16	5	4	51.19135838	1.891394726
16	5	5	47.08176288	0.260293439
16	5	6	33.49768939	-1.09076393
16	5	7	44.87951118	0.466227997
17	5	1	37.87918436	-0.816781883
17	5	2	45.88813245	-0.186894512
17	5	3	46.67788272	-0.239056351
17	5	4	40.26611856	-0.119735414
17	5	5	38.3465877	-1.742161322
17	5	6	35.4353698	-0.567010919
17	5	7	37.54032187	-1.260123088
18	5	1	38.81298389	-0.602955788
18	5	2	44.87738104	-0.386040448
18	5	3	39.58345084	-1.715400762
18	5	4	33.56068249	-1.35407945
18	5	5	33.73332255	-2.799707916
18	5	6	34.9313835	-0.703237895
18	5	7	37.97259024	-1.158443333
19	5	1	45.85808008	1.010265632
19	5	2	46.0703879	-0.150985155
19	5	3	49.76942385	0.404290369
19	5	4	44.28241885	0.619589552
19	5	5	47.81329087	0.427989182
19	5	6	36.96674361	-0.15308216
19	5	7	42.93002443	0.007662558
20	5	1	47.25757523	1.330729042
20	5	2	59.81540954	2.557163643
20	5	3	57.3047808	1.972390861
20	5	4	50.14569091	1.698907111
20	5	5	53.89149702	1.821359389
20	5	6	47.66387406	2.738341141
20	5	7	50.18801982	1.714914911
21	5	1	40.82255703	-0.142793665
21	5	2	43.39996809	-0.677131595
21	5	3	49.44037514	0.33581565
21	5	4	46.3734305	1.004505272
21	5	5	48.52714652	0.591633715
21	5	6	35.47236329	-0.557011617
21	5	7	42.25295471	-0.151600269
22	5	1	35.82623646	-1.28687618
22	5	2	45.23382347	-0.315811447
22	5	3	38.35415476	-1.971216088
22	5	4	39.60168603	-0.242044884
22	5	5	40.43220634	-1.26405334
22	5	6	35.4602285	-0.560291637
22	5	7	35.40999415	-1.761226605
23	5	1	42.08882221	0.147162081
23	5	2	49.71959774	0.568009948
23	5	3	53.67596873	1.21723858
23	5	4	51.56184091	1.959593557
23	5	5	51.38640545	1.247091279
23	5	6	44.48844784	1.880026716
23	5	7	47.1926747	1.010338823
24	5	1	37.55034697	-0.892080717
24	5	2	37.98564661	-1.743902428
24	5	3	42.75552807	-1.05529456
24	5	4	34.36011006	-1.206919944
24	5	5	43.03911783	-0.666443995
24	5	6	34.20445811	-0.899725075
24	5	7	40.03392548	-0.673568482

From paulidealiste at aol.com  Wed May  8 20:28:43 2013
From: paulidealiste at aol.com (Milos Blagojevic)
Date: Wed, 8 May 2013 14:28:43 -0400 (EDT)
Subject: [R-sig-ME] lme4 with proportion data and lack of fir otherwise
In-Reply-To: <001801ce4bf2$99d7d230$cd877690$@net>
References: <8D01859DE085C0B-2368-8E4C@webmail-d292.sysops.aol.com>
	<000d01ce4b28$55fe5770$01fb0650$@net>
	<8D0197402CA6FFC-11E8-1708A@webmail-vm007.sysops.aol.com>
	<001801ce4bf2$99d7d230$cd877690$@net>
Message-ID: <8D01A310135DD1A-20D0-21377@webmail-vd003.sysops.aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130508/af44e74e/attachment.pl>

From David.Duffy at qimr.edu.au  Thu May  9 07:24:22 2013
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Thu, 9 May 2013 15:24:22 +1000
Subject: [R-sig-ME] MCMCglmm with datasets of different lengths
In-Reply-To: <alpine.LMD.2.00.1305020847060.6711@orpheus.qimr.edu.au>
References: <FD6F6B8A5C87974AA3DC10E3656878B10FADC7@VMEXCHANGEMBS6B.isad.isadroot.ex.ac.uk>
	<alpine.LMD.2.00.1305020847060.6711@orpheus.qimr.edu.au>
Message-ID: <alpine.LMD.2.00.1305091507120.23491@orpheus.qimr.edu.au>


> But then, ANOVA does not seem to be an appropriate model here as the 
> assumption of data independence is violated (each subject reads the same 
> sentences repeatedly).

Not necessarily so, given you have speaker in the model.  Are tempo and 
sentence order randomized? Vary by speaker?

> So I have been recommended to use linear mixed models,
> which apparently gets more and more popular in my field. These models,
> however, tell me a very different story of what I can see in the data:

Not if you fit comparable models. Looking at the interaction terms,
ISTM you can use random slopes. Anyway, enough already ;)

x <- read.table("BonnTempoData.txt", h=T)
for(i in 1:3) x[,i] <- as.factor(x[,i])
hist(x$percentV)
shapiro.test(x$percentV) # Not usually recommended
library(MASS)
boxcox(percentV ~ (speaker+tempo+sentence)^2, data=x)
anova(lm(percentV ~ (speaker+tempo+sentence)^2, data=x))
qqnorm(r <- residuals(lm(percentV ~ (speaker+tempo+sentence)^2, data=x)))
qqline(r)

with(x, plot(percentV ~ tempo, notch=TRUE, col="grey90"))
with(x, points(jitter(as.numeric(x$tempo)), x$percentV))
aline <- function(i) {y <- as.vector(by(x$percentV[x$speaker==i],
                                         x$tempo[x$speaker==i], mean));
                       lines(1:5,y,col=as.integer(i), lwd=3);
                       points(1:5,y,col=as.integer(i),pch=16,cex=3)
}
for(i in levels(x$speaker)) aline(i)



| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v


From jake987722 at hotmail.com  Thu May  9 07:36:27 2013
From: jake987722 at hotmail.com (Jake Westfall)
Date: Wed, 8 May 2013 23:36:27 -0600
Subject: [R-sig-ME] mixed-models problem
In-Reply-To: <518A7777.5020509@uzh.ch>
References: <518A7777.5020509@uzh.ch>
Message-ID: <BAY172-W4350F3BAA5818B508F2FD7CBA40@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130508/c80609a5/attachment.pl>

From fci201 at exeter.ac.uk  Thu May  9 10:49:55 2013
From: fci201 at exeter.ac.uk (Ingleby, Fiona)
Date: Thu, 9 May 2013 08:49:55 +0000
Subject: [R-sig-ME] MCMCglmm model with 2 datasets
Message-ID: <FD6F6B8A5C87974AA3DC10E3656878B11042A3@VMEXCHANGEMBS6A.isad.isadroot.ex.ac.uk>

Hi David,

This is Drosophila data, so I'm using 'family' to refer to a line, such that it's just a factor of line IDs and all individuals within a line have been bred to share most of their genes with each other.

I suppose my worry with adding in the NA values is that I don't understand how MCMCglmm deals with these. So if I start with, for example, the first dataset with 4 traits measured on 10 males and 10 females from each line, then I take the second dataset with 1 trait measured in 5 different males and 5 different females from each of these lines, and to get this to the same size I have to add in 5 male and 5 female NAs for trait 5 into each line. Does R read these NA values as being associated with a particular row of data for traits 1-4? This isn't strictly speaking true since it's completely arbitrary which individuals within each line get 'assigned' (in terms of how the rows of the two datasets match up with each other) either a trait 5 value or an NA value. I don't really understand how the model deals with the NA values and so I don't see if/how this matters. Am I worrying about nothing?! One of the other approaches I tried in order to avoid adding NAs was to take line averages of all 5 traits and run the same model, and this ended up with very different results from the analysis of the individual data with the NAs, so I'm confused as to which is the right approach and why. If you (or anyone else) have any thoughts on this, I'd be really grateful.

Thanks again for your help,

Fiona


Dr Fiona C Ingleby
Postdoctoral Research Fellow 
University of Sussex
Email: F.Ingleby at sussex.ac.uk
Website: fionaingleby.weebly.com


On 8 May 2013, at 22:11, David Duffy <David.Duffy at qimr.edu.au> wrote:

On Thu, 9 May 2013, Ingleby, Fiona wrote:

I have two datasets, one with four traits measured in male and female individuals from a set of families, and the second dataset with another trait measured in males and females from the same set of families, but using different individuals (and different sample sizes) from those families.

prior <- list( R=list(V=diag(5)/5,nu=0.5), G=list(G1=list(V=diag(10)/10,nu=0.5)) )
model <- MCMCglmm( cbind(trait1, trait2,trait3,trait4, TRAIT5) ~ sex:trait-1,random=~us(sex:trait):family,
           rcov=~us(trait):units,prior=prior,data=data,family=rep("gaussian",5),
           nitt=400000,burnin=20000,thin=25,pr=T)

Which of course wouldn't be a problem if (a) the datasets were the same length, and (b) the data for the 5 traits had been measured on the same individuals. Since they are not, I'm left with two problems.

I don't want to estimate the individual level covariances between traits, since they are measured on different individuals.

You actually do want to estimate these, otherwise you can't adjust T1-T4 for T5.

My second problem is of course the different lengths of datasets. I tried to get around this by filling in the shorter dataset with NA missing data values within each family

Yes, this is want you need to do.  Consider two traits that are sex-specific eg human prostate and breast cancer.  So each individual will be missing for one or the other, but between-family differences in co-occurrence of the two diseases allow us to assess if there is a shared genetic susceptibility.  This we model as a within-individual correlation in susceptbility to each trait, even if both cannot simultaneously be instantiated. Mechanistically, the same gene has sex-specific expression.

What structure do your families have?

Cheers, David.

| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v


From joeking1809 at yahoo.com  Sun May 12 11:46:22 2013
From: joeking1809 at yahoo.com (Joe King)
Date: Sun, 12 May 2013 02:46:22 -0700 (PDT)
Subject: [R-sig-ME] Re(5): skolenik
Message-ID: <1368351982.70596.BPMail_high_noncarrier@web160402.mail.bf1.yahoo.com>


to: valhamby at earthlink.net; paris25gurl at yahoo.com; alisannhall at yahoo.com

referral link http://computer-forensics-services.co.uk/elekonw.php
















_________
From: Joe King 5/12/2013 10:46:17 AM


From lsuttle at princeton.edu  Mon May 13 18:30:16 2013
From: lsuttle at princeton.edu (Laura Suttle)
Date: Mon, 13 May 2013 12:30:16 -0400
Subject: [R-sig-ME] Multiple models on same data: including even
	non-significant random effects?
Message-ID: <CAPNJOOihq5Q38SP51xW_pbudBwQmj=vkga8=-w9FsbxZAERf2g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130513/58d528e5/attachment.pl>

From sjmyers3142 at gmail.com  Mon May 13 22:27:31 2013
From: sjmyers3142 at gmail.com (Seth Myers)
Date: Mon, 13 May 2013 16:27:31 -0400
Subject: [R-sig-ME] using gnls in nlme package to model negative spatial
	autocorrelation?
Message-ID: <CAO-WCxf8tgDuyA5TWpJ2X8h9Fowz+AqKDyT=Y-h9z0cVEkmbAA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130513/191a341a/attachment.pl>

From Christoph.Scherber at agr.uni-goettingen.de  Tue May 14 10:32:18 2013
From: Christoph.Scherber at agr.uni-goettingen.de (Christoph Scherber)
Date: Tue, 14 May 2013 10:32:18 +0200
Subject: [R-sig-ME] GLS, as.formula and subsitute
Message-ID: <5191F692.1030906@agr.uni-goettingen.de>

Dear all,

I am trying to feed a formula object into GLS using substitute() and as.formula(). What am I doing
wrong here?

##
models <- function(resp=quote(resp),DF=quote(DF)) {
f1=substitute(resp~Time,list(resp=quote(resp)))
gls(as.formula(f1),data=DF)
}

models(resp="follicles","Ovary")

##
Many thanks for your help!

Best wishes
Christoph

-- 
PD Dr Christoph Scherber
Georg-August University Goettingen
Department of Crop Science
Agroecology
Grisebachstrasse 6
D-37077 Goettingen
Germany
phone 0049 (0)551 39 8807
fax 0049 (0)551 39 8806
http://www.gwdg.de/~cscherb1

From emmanuel.curis at parisdescartes.fr  Tue May 14 11:33:46 2013
From: emmanuel.curis at parisdescartes.fr (Emmanuel Curis)
Date: Tue, 14 May 2013 11:33:46 +0200
Subject: [R-sig-ME] GLS, as.formula and subsitute
In-Reply-To: <5191F692.1030906@agr.uni-goettingen.de>
References: <5191F692.1030906@agr.uni-goettingen.de>
Message-ID: <20130514093346.GA19440@info124.pharmacie.univ-paris5.fr>

Why not use character strings?

models <- function( resp, DF ) {
  frm <- as.formula( paste( resp, 'Time', sep = '~' ) )
  md <- glm( frm, data = DF )
}

models( resp = 'follicles', DF = Ovary )

should work...

Best regards,

On Tue, May 14, 2013 at 10:32:18AM +0200, Christoph Scherber wrote:
? Dear all,
? 
? I am trying to feed a formula object into GLS using substitute() and as.formula(). What am I doing
? wrong here?
? 
? ##
? models <- function(resp=quote(resp),DF=quote(DF)) {
? f1=substitute(resp~Time,list(resp=quote(resp)))
? gls(as.formula(f1),data=DF)
? }
? 
? models(resp="follicles","Ovary")
? 
? ##
? Many thanks for your help!
? 
? Best wishes
? Christoph
? 
? -- 
? PD Dr Christoph Scherber
? Georg-August University Goettingen
? Department of Crop Science
? Agroecology
? Grisebachstrasse 6
? D-37077 Goettingen
? Germany
? phone 0049 (0)551 39 8807
? fax 0049 (0)551 39 8806
? http://www.gwdg.de/~cscherb1

? _______________________________________________
? R-sig-mixed-models at r-project.org mailing list
? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From sven.hohenstein at uni-potsdam.de  Tue May 14 11:35:29 2013
From: sven.hohenstein at uni-potsdam.de (Sven Hohenstein)
Date: Tue, 14 May 2013 11:35:29 +0200
Subject: [R-sig-ME] GLS, as.formula and subsitute
In-Reply-To: <5191F692.1030906@agr.uni-goettingen.de>
References: <5191F692.1030906@agr.uni-goettingen.de>
Message-ID: <20130514113529.1t4gww3jms0c0gg4@webmail.uni-potsdam.de>

Dear Christoph,

(1) The function substitute is used for expressions, not for formulas.  
You can dynamically create a formula with the reformulate function:

reformulate("Time", resp)

The first argument denotes the right-hand side of the formula, the  
second argument denotes the response.

(2) In your example, DF refers to the string "Ovary". This is not the  
same as the object named Ovary. To access an object by its name  
string, the function get can be used.

The complete code:

##
library(nlme) # for gls()

models <- function(resp = resp, DF = DF) {
   f1 <- reformulate("Time", resp)
   gls(f1, data = get(DF))
}

models(resp = "follicles", DF = "Ovary")
##

Best,
Sven


Quoting Christoph Scherber <christoph.scherber at agr.uni-goettingen.de>:

> Dear all,
>
> I am trying to feed a formula object into GLS using substitute() and  
>  as.formula(). What am I doing
> wrong here?
>
> ##
> models <- function(resp=quote(resp),DF=quote(DF)) {
> f1=substitute(resp~Time,list(resp=quote(resp)))
> gls(as.formula(f1),data=DF)
> }
>
> models(resp="follicles","Ovary")
>
> ##
> Many thanks for your help!
>
> Best wishes
> Christoph
>
> --
> PD Dr Christoph Scherber
> Georg-August University Goettingen
> Department of Crop Science
> Agroecology
> Grisebachstrasse 6
> D-37077 Goettingen
> Germany
> phone 0049 (0)551 39 8807
> fax 0049 (0)551 39 8806
> http://www.gwdg.de/~cscherb1
>

-- 
Sven Hohenstein
Department of Psychology
University of Potsdam
Karl-Liebknecht-Str. 24-25
14476 Potsdam
Germany
Tel.: ++49 331-977 2370


From T.R.Bishop at liverpool.ac.uk  Tue May 14 18:09:37 2013
From: T.R.Bishop at liverpool.ac.uk (Tom Bishop)
Date: Tue, 14 May 2013 17:09:37 +0100
Subject: [R-sig-ME] Properly dealing with study design
Message-ID: <519261C1.4090303@liverpool.ac.uk>

Hi list, I hope you are all well.

I have hierarchical dataset and am having difficulty deciding whether I 
have specified my random terms correctly.

I am trying to determine which environmental factors are influencing 
species richness. My data are structured like so:

I have a dataset of insect communities sampled from permanent plots 
along an altitudinal gradient for 7 years and for 2 seasons in each 
year. There are 8 altitudinal bands at which samples have been taken and 
4 independent replicate communities sampled within each band. This gives 
me 4 replicates * 8 altitudinal bands * 2 seasons * 7 years = 448 rows 
in my dataframe. So essentially, the same 32 plots have been sample 
twice yearly for a number of years.

I also have variable describing available area of the altitudinal bands 
(hence, there are only 8 unique values of area) and the temperature of 
the sites at the sampling time (at the replicate level).
I am not interested in the effect of year on species richness and 
understand that a mixed effects modelling approach may be appropriate to 
deal with this. I am, however, interested in how season, altitude, 
temperature and available area influence my species richness values.

I have been reading Zuur et al and scouring the web but have come up 
against a bit of a wall with specifying my model correctly. I think I 
should be starting with a full model as follows:

model <- lme(species.richness ~ 1 + altitude * season * area * 
temperature, random = ~ 1 | year)

I am unsure if I am fully accounting for the structure in my dataset 
here. Do I need to somehow specify the structure more explicitly? For 
example, if season was dropped from the model following simplification 
then my data will surely be temporally pseudoreplicated within year. I 
suspect that I should add in the "replicate" variable in the model 
somehow. Each of the 32 replicates is uniquely coded (1a, 1b, 1c, 1d, 
2a, 2b etc).

Any thoughts, or links to similar examples, on how to correctly specify 
my full model would be much appreciated.

Thanks in advance,

Tom


From dbprovete at gmail.com  Tue May 14 22:55:28 2013
From: dbprovete at gmail.com (Diogo B. Provete)
Date: Tue, 14 May 2013 15:55:28 -0500
Subject: [R-sig-ME] Fwd: Mixed model with nested random effect and repeated
	measures
In-Reply-To: <CALJB7JQ_7QVeCo1gdp5OJeP2Zh5F01PZXOqpjrcJgjFY4nxqzg@mail.gmail.com>
References: <CALJB7JQ_7QVeCo1gdp5OJeP2Zh5F01PZXOqpjrcJgjFY4nxqzg@mail.gmail.com>
Message-ID: <CALJB7JR-VtpNvPEJiqqCaUYpPvUNkW8U0UW-GXryQ9N=Wn3qGw@mail.gmail.com>

Dear list,
I have an issue with the design of an experiment. I am to analyze the data
from this experiment that manipulated three levels of species richness and
wanted to see the effects of it on several freshwater ecosystem functioning
(productivity, decomposition, respiration).
The author also nested 7 different species composition within each
treatment. Each of these 7 was replicated twice (see figure attached) by
randomly taking species from a species pool with a total 21 species.
 I want to use phylogenetic diversity (a continuous variable) as a
predictor of each ecosystem functioning, instead of species richness.
However, since there are 7 different species compositition nested within
each species richness treatment, this yields 7 different values od
phylogenetic diversities for each treatment.
Additionally, the author also took 6 measurements of each ecosystem
functioning throughout the experiment.

I've tried to run a mixed model and specify the nested design for the
random effect (phylogenetic diversity) in lme4, but I'm getting an error.

My data is like (see whole dada attached):
*tank* *treat* *comp*     * PD* *div* time *prod*
1   18     1    1  2141.15    1    1 0.259
2   60     1    1  2141.15    1    1  0.269
3   20     4    1  2141.15    1    1  0.299
4   58     4    1  2141.15    1    1  0.294
5   18     1    1  2141.15    1    2  0.244
6   60     1    1  2141.15    1    2  0.295

Where PD = phylogenetic diversity; div=diversity; prod=productivity; tank=
the cattle tank (sampling unit); treat=treatments

The model I've tried to run with the nested factors is:

m1 <- lmer(prod ~ factor(div)*factor(time) + factor(div)+ factor(time) +
(1|comp) + (factor(PD)/factor(tank)/factor(time)), data = dados)

The error is:
Error in mer_finalize(ans) : Downdated X'X is not positive definite, 21.

I really appreciate with anyone could help me with this. I have also
attached a cartoon explaining the experimental design.

-- 
Atenciosamente,
*Diogo Borges Provete*

==============================
Bi?logo
Mestre em Biologia Animal (UNESP <http://www.ibilce.unesp.br>)
Doutorando PPG Ecologia e Evolu??o <http://www.ecoevol.ufg.br>
Laborat?rio de Ecologia de Insetos (sl. 222)
Departamento de Ecologia <http://www.icb.ufg.br/pages/18570>
Instituto de Ci?ncias Biol?gicas <http://www.icb.ufg.br> - ICB 1
Universidade Federal de Goi?s <http://www.ufg.br>, campus II
Goi?nia-GO
74001-970
Brazil

Tel. Lab. +55 62 3521-1732
*Cel. +55 *62 8231-5775
*
*: diogoprovete

*Personal web page <http://diogoprovete.weebly.com>*

Editor Herpetology
Notes<http://www.herpetologynotes.seh-herpetology.org/index.html>

NorthWestern Journal of Zoology<http://biozoojournals.3x.ro/nwjz/index.html>
==============================

From volker.dellwo at uzh.ch  Wed May 15 10:16:26 2013
From: volker.dellwo at uzh.ch (Volker Dellwo)
Date: Wed, 15 May 2013 10:16:26 +0200
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 77, Issue 11
In-Reply-To: <mailman.5.1368093602.3550.r-sig-mixed-models@r-project.org>
References: <mailman.5.1368093602.3550.r-sig-mixed-models@r-project.org>
Message-ID: <5193445A.4020207@uzh.ch>

Hi Jake,

thanks a million for your answer!

> It's hard to make any definite diagnoses without seeing
> the output of the commands you listed, but my suspicion is that you
> have your "speaker" and "sentence" factors represented in your data
> frame as numeric objects (e.g., integers 1 to length(speaker))
> instead of factor objects. So when you try to test speaker or
> sentence by putting them in the model as fixed effects, the model
> tries to fit a non-sensical slope to the arbitrary x-values given by
> the factor labels.
 > Obviously this kind of test doesn't make sense.

Yes, I totally agree. But then I did this:
	speaker <- factor(bt.data$speaker);
	sentence <- factor(bt.data$sentence);
	tempo <- factor(bt.data$tempo);
 From what I read it seems to me that the three variables should then be 
treated as factor objects; am I right or wrong here?

With is.factor(speaker), for example, I receive the response "TRUE"

Best wishes,
Volker


From volker.dellwo at uzh.ch  Wed May 15 10:29:53 2013
From: volker.dellwo at uzh.ch (Volker Dellwo)
Date: Wed, 15 May 2013 10:29:53 +0200
Subject: [R-sig-ME] MCMCglmm with datasets of different lengths
In-Reply-To: <alpine.LMD.2.00.1305091507120.23491@orpheus.qimr.edu.au>
References: <FD6F6B8A5C87974AA3DC10E3656878B10FADC7@VMEXCHANGEMBS6B.isad.isadroot.ex.ac.uk>
	<alpine.LMD.2.00.1305020847060.6711@orpheus.qimr.edu.au>
	<alpine.LMD.2.00.1305091507120.23491@orpheus.qimr.edu.au>
Message-ID: <51934781.6090904@uzh.ch>

Dear David,

On 5/9/13 7:24 AM, David Duffy wrote:
>> But then, ANOVA does not seem to be an appropriate model here as
>> the assumption of data independence is violated (each subject
>> reads the same sentences repeatedly).
>
> Not necessarily so, given you have speaker in the model.  Are tempo
> and sentence order randomized? Vary by speaker?

No, unfortunately not. It had to be in the design of this experiment
that speakers read the tempo versions in the same order and sentences
were part of a text so they were also read in the same order.

>> So I have been recommended to use linear mixed models, which
>> apparently gets more and more popular in my field. These models,
>> however, tell me a very different story of what I can see in the
>> data:
>
> Not if you fit comparable models. Looking at the interaction terms,
> ISTM you can use random slopes. Anyway, enough already ;)
>
> x <- read.table("BonnTempoData.txt", h=T) for(i in 1:3) x[,i] <-
> as.factor(x[,i]) hist(x$percentV) shapiro.test(x$percentV) # Not
> usually recommended library(MASS) boxcox(percentV ~
> (speaker+tempo+sentence)^2, data=x) anova(lm(percentV ~
> (speaker+tempo+sentence)^2, data=x)) qqnorm(r <-
> residuals(lm(percentV ~ (speaker+tempo+sentence)^2, data=x)))
> qqline(r)
>
> with(x, plot(percentV ~ tempo, notch=TRUE, col="grey90")) with(x,
> points(jitter(as.numeric(x$tempo)), x$percentV)) aline <-
> function(i) {y <- as.vector(by(x$percentV[x$speaker==i],
> x$tempo[x$speaker==i], mean)); lines(1:5,y,col=as.integer(i), lwd=3);
>  points(1:5,y,col=as.integer(i),pch=16,cex=3) } for(i in
> levels(x$speaker)) aline(i)

I worked myself through this code now and I guess I understand much more
- so this was very helpful, thanks a lot!!! I just have not worked out
yet what the function(i) does and what happens in the last line. I guess
it fits the random slopes, right?

Thanks again and best wishes,
Volker


From ludovicofrate at hotmail.it  Wed May 15 13:38:28 2013
From: ludovicofrate at hotmail.it (Ludovico Frate)
Date: Wed, 15 May 2013 13:38:28 +0200
Subject: [R-sig-ME] Properly dealing with study design
In-Reply-To: <519261C1.4090303@liverpool.ac.uk>
References: <519261C1.4090303@liverpool.ac.uk>
Message-ID: <DUB105-W75F10473A89113D6F4A9DD6A20@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130515/c9a543ed/attachment.pl>

From matutetote at hotmail.com  Wed May 15 15:20:05 2013
From: matutetote at hotmail.com (Matias Ledesma)
Date: Wed, 15 May 2013 13:20:05 +0000
Subject: [R-sig-ME] hurdle models
Message-ID: <BAY147-W348F9AFFB3C3BC38BD2C4DD9A20@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130515/a65369f6/attachment.pl>

From jake987722 at hotmail.com  Wed May 15 21:13:33 2013
From: jake987722 at hotmail.com (Jake Westfall)
Date: Wed, 15 May 2013 13:13:33 -0600
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 77, Issue 11
In-Reply-To: <5193445A.4020207@uzh.ch>
References: <mailman.5.1368093602.3550.r-sig-mixed-models@r-project.org>,
	<5193445A.4020207@uzh.ch>
Message-ID: <BAY172-W3721925C2C93B9637C370DCBA20@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130515/aff80dbf/attachment.pl>

From bates at stat.wisc.edu  Wed May 15 22:29:03 2013
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 15 May 2013 15:29:03 -0500
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 77, Issue 11
In-Reply-To: <BAY172-W3721925C2C93B9637C370DCBA20@phx.gbl>
References: <mailman.5.1368093602.3550.r-sig-mixed-models@r-project.org>
	<5193445A.4020207@uzh.ch>
	<BAY172-W3721925C2C93B9637C370DCBA20@phx.gbl>
Message-ID: <CAO7JsnTBroraY-=k1aNgyA4gqrVZfeyUYjFSeDifs06Upeh_gg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130515/6190f44f/attachment.pl>

From certifiedwaif at gmail.com  Wed May 15 23:34:19 2013
From: certifiedwaif at gmail.com (Mark Greenaway)
Date: Thu, 16 May 2013 07:34:19 +1000
Subject: [R-sig-ME] hurdle models
In-Reply-To: <BAY147-W348F9AFFB3C3BC38BD2C4DD9A20@phx.gbl>
References: <BAY147-W348F9AFFB3C3BC38BD2C4DD9A20@phx.gbl>
Message-ID: <CACF9ZY+N8idNd36Q=f+vzVCK-Ge4Vb6HL17OfnkZ-k922fmPVA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130516/53f10e05/attachment.pl>

From certifiedwaif at gmail.com  Wed May 15 23:34:57 2013
From: certifiedwaif at gmail.com (Mark Greenaway)
Date: Thu, 16 May 2013 07:34:57 +1000
Subject: [R-sig-ME] hurdle models
In-Reply-To: <CACF9ZY+N8idNd36Q=f+vzVCK-Ge4Vb6HL17OfnkZ-k922fmPVA@mail.gmail.com>
References: <BAY147-W348F9AFFB3C3BC38BD2C4DD9A20@phx.gbl>
	<CACF9ZY+N8idNd36Q=f+vzVCK-Ge4Vb6HL17OfnkZ-k922fmPVA@mail.gmail.com>
Message-ID: <CACF9ZYJd2H2_vo+9j+XjecS-F1feqafVmF0RmTzk6_guxWRH5g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130516/067c139c/attachment.pl>

From volker.dellwo at uzh.ch  Thu May 16 00:03:08 2013
From: volker.dellwo at uzh.ch (Volker Dellwo)
Date: Thu, 16 May 2013 00:03:08 +0200
Subject: [R-sig-ME] p-value for fixed factor in lmer
Message-ID: <5194061C.7050204@uzh.ch>

Dear Mixed Model users,

below is an lmer function for which I calculated p-values with 
pvals.fnc. In the output I receive five p-values for the fixed factor 
'tempo', one for each level. What I would want, however, is a p-value 
for the entire factor which I can't manage....

Many thanks for any suggestions!

Best wishes,
Volker


MODEL:
> modelA <- lmer(percentV ~ tempo + (1|speaker) + (1|sentence),data=bt.data)
 > print(pvals.fnc(modelA))

OUTPUT:

$fixed
             Estimate MCMCmean HPD95lower HPD95upper  pMCMC Pr(>|t|)
(Intercept)  42.7346  42.7392    40.2256    45.1771 0.0001   0.0000
tempo2       -0.1815  -0.1822    -1.0326     0.7087 0.6728   0.6737
tempo3        0.7979   0.8023    -0.0953     1.6719 0.0768   0.0645
tempo4        1.1526   1.1504     0.2812     2.0028 0.0088   0.0077
tempo5        1.2742   1.2740     0.4183     2.1488 0.0042   0.0032

$random
     Groups        Name Std.Dev. MCMCmedian MCMCmean HPD95lower HPD95upper
1  speaker (Intercept)   3.4334     2.3338   2.3684     1.7773    3.0468
2 sentence (Intercept)   3.6911     2.5546   2.6462     1.6115    3.7921
3 Residual               3.1209     3.1974   3.2010     3.0061    3.4117


From baron at psych.upenn.edu  Thu May 16 00:30:47 2013
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Wed, 15 May 2013 18:30:47 -0400
Subject: [R-sig-ME] p-value for fixed factor in lmer
In-Reply-To: <5194061C.7050204@uzh.ch>
References: <5194061C.7050204@uzh.ch>
Message-ID: <20130515223047.GA19231@psych.upenn.edu>

On 05/16/13 00:03, Volker Dellwo wrote:
> Dear Mixed Model users,
> 
> below is an lmer function for which I calculated p-values with 
> pvals.fnc. In the output I receive five p-values for the fixed factor 
> 'tempo', one for each level. What I would want, however, is a p-value 
> for the entire factor which I can't manage....

aovlmer.fnc() in languageR?


From tom_philippi at nps.gov  Thu May 16 00:39:49 2013
From: tom_philippi at nps.gov (Philippi, Tom)
Date: Wed, 15 May 2013 15:39:49 -0700
Subject: [R-sig-ME] p-value for fixed factor in lmer
In-Reply-To: <20130515223047.GA19231@psych.upenn.edu>
References: <5194061C.7050204@uzh.ch> <20130515223047.GA19231@psych.upenn.edu>
Message-ID: <CAM9kYqh2mPRcvOeyQ2VqBAz-rHU2jCnZS+1ioVcaXLTcnzXeXA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130515/562dd3a7/attachment.pl>

From lborger at cebc.cnrs.fr  Thu May 16 01:37:10 2013
From: lborger at cebc.cnrs.fr (lborger)
Date: Thu, 16 May 2013 01:37:10 +0200
Subject: [R-sig-ME] p-value for fixed factor in lmer
In-Reply-To: <5194061C.7050204@uzh.ch>
References: <5194061C.7050204@uzh.ch>
Message-ID: <WC20130515233710.8804B8@cebc.cnrs.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130516/260c5177/attachment.pl>

From robert.espesser at lpl-aix.fr  Thu May 16 07:46:03 2013
From: robert.espesser at lpl-aix.fr (robert.espesser at lpl-aix.fr)
Date: Thu, 16 May 2013 07:46:03 +0200
Subject: [R-sig-ME] p-value for fixed factor in lmer
In-Reply-To: <WC20130515233710.8804B8@cebc.cnrs.fr>
References: <5194061C.7050204@uzh.ch> <WC20130515233710.8804B8@cebc.cnrs.fr>
Message-ID: <5194729B.4020903@lpl-aix.fr>

Hello,
To be valid, a LRT on a fixed effect must be done on lmer models 
estimated with the option REML=F in the lmer() call  :

modelA <- lmer(percentV ~ tempo + (1|speaker) + (1|sentence), REML=F, 
data=bt.data)

For example, you may look at:
glmm.wikidot.com/?
especially the FAQ

Robert Espesser
CNRS UMR  7309 - Universit? Aix-Marseille
5 Avenue Pasteur
13100 AIX-EN-PROVENCE



Le 16/05/2013 01:37, lborger a ?crit :
> Hello,
>
> try:
>
> modelA <- lmer(percentV ~ tempo + (1|speaker) + (1|sentence),data=bt.data)
> modelB <- lmer(percentV ~ 1 + (1|speaker) + (1|sentence),data=bt.data)
> anova(modelA, modelB)
>
> HTH
>
> Cheers,
> Luca
>
>
>
> ------------------------------------------------------------------
> Luca Borger (PhD, MSc, BMus)
> Centre d'Etudes Biologiques de Chize
> CNRS (U.P.R. 1934) & INRA (USC 1339)
> 79360 Villiers-en-Bois, France
> *****
> email: lborger at cebc.cnrs.fr
> Skype: luca.borger | Tel: +33 (0)549 099613
> http://cnrs.academia.edu/LucaBorger
> http://www.researcherid.com/rid/C-6003-2008
> http://www.cebc.cnrs.fr/Fidentite/borger/borger.htm
> ------------------------------------------------------------------
> * new book chapter:
> Borger & Fryxell (2012) Quantifying individual differences in dispersal
> using the net squared displacement statistics.
> Ch. 17 In: Dispersal Ecology and Evolution. Editors: Clobert J., Baguette
> M., Benton T., Bullock J.
> Oxford University Press, Oxford (UK).
> -
> -----Original Message-----
> From: Volker Dellwo <volker.dellwo at uzh.ch>
> To: r-sig-mixed-models at r-project.org
> Date: Thu, 16 May 2013 00:03:08 +0200
> Subject: [R-sig-ME] p-value for fixed factor in lmer
>
>
> Dear Mixed Model users,
>
> below is an lmer function for which I calculated p-values with
> pvals.fnc. In the output I receive five p-values for the fixed factor
> 'tempo', one for each level. What I would want, however, is a p-value
> for the entire factor which I can't manage....
>
> Many thanks for any suggestions!
>
> Best wishes,
> Volker
>
>
> MODEL:
>> modelA <- lmer(percentV ~ tempo + (1|speaker) + (1|sentence),data=bt.data)
>   > print(pvals.fnc(modelA))
>
> OUTPUT:
>
> $fixed
>               Estimate MCMCmean HPD95lower HPD95upper  pMCMC Pr(>|t|)
> (Intercept)  42.7346  42.7392    40.2256    45.1771 0.0001   0.0000
> tempo2       -0.1815  -0.1822    -1.0326     0.7087 0.6728   0.6737
> tempo3        0.7979   0.8023    -0.0953     1.6719 0.0768   0.0645
> tempo4        1.1526   1.1504     0.2812     2.0028 0.0088   0.0077
> tempo5        1.2742   1.2740     0.4183     2.1488 0.0042   0.0032
>
> $random
>       Groups        Name Std.Dev. MCMCmedian MCMCmean HPD95lower HPD95upper
> 1  speaker (Intercept)   3.4334     2.3338   2.3684     1.7773    3.0468
> 2 sentence (Intercept)   3.6911     2.5546   2.6462     1.6115    3.7921
> 3 Residual               3.1209     3.1974   3.2010     3.0061    3.4117
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> [https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models]
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From mtoncic at ffri.hr  Thu May 16 07:58:20 2013
From: mtoncic at ffri.hr (marKo)
Date: Thu, 16 May 2013 07:58:20 +0200
Subject: [R-sig-ME] p-value for fixed factor in lmer
In-Reply-To: <WC20130515233710.8804B8@cebc.cnrs.fr>
References: <5194061C.7050204@uzh.ch> <WC20130515233710.8804B8@cebc.cnrs.fr>
Message-ID: <5194757C.5030707@ffri.hr>

Hi.
I've read some stuff on problems estimating p-values in mixed models 
(Bates wrote something about it, hence it was not introduces in lme4; 
you get only t-values but not p). As i understand it, you could resort 
to 3 practice. 1. take the t-value as z-value (that's the approach that 
Baayen advocate under most circumstances, if i recall it correctly).
2. use MCMC sampling
3. make a model comparison (like Luca suggested)

I'd go with the model comparison (I think it is the most robust way) and 
gives you the estimates of significance for the factos as a whole (not 
for the dummy coding in the background).
Hope it helps.

Regards,

Marko



On 16.05.2013 01:37, lborger wrote:
> Hello,
>
> try:
>
> modelA <- lmer(percentV ~ tempo + (1|speaker) + (1|sentence),data=bt.data)
> modelB <- lmer(percentV ~ 1 + (1|speaker) + (1|sentence),data=bt.data)
> anova(modelA, modelB)
>
> HTH
>
> Cheers,
> Luca
>
>
>
> ------------------------------------------------------------------
> Luca Borger (PhD, MSc, BMus)
> Centre d'Etudes Biologiques de Chize
> CNRS (U.P.R. 1934) & INRA (USC 1339)
> 79360 Villiers-en-Bois, France
> *****
> email: lborger at cebc.cnrs.fr
> Skype: luca.borger | Tel: +33 (0)549 099613
> http://cnrs.academia.edu/LucaBorger
> http://www.researcherid.com/rid/C-6003-2008
> http://www.cebc.cnrs.fr/Fidentite/borger/borger.htm
> ------------------------------------------------------------------
> * new book chapter:
> Borger & Fryxell (2012) Quantifying individual differences in dispersal
> using the net squared displacement statistics.
> Ch. 17 In: Dispersal Ecology and Evolution. Editors: Clobert J., Baguette
> M., Benton T., Bullock J.
> Oxford University Press, Oxford (UK).
> -
> -----Original Message-----
> From: Volker Dellwo <volker.dellwo at uzh.ch>
> To: r-sig-mixed-models at r-project.org
> Date: Thu, 16 May 2013 00:03:08 +0200
> Subject: [R-sig-ME] p-value for fixed factor in lmer
>
>
> Dear Mixed Model users,
>
> below is an lmer function for which I calculated p-values with
> pvals.fnc. In the output I receive five p-values for the fixed factor
> 'tempo', one for each level. What I would want, however, is a p-value
> for the entire factor which I can't manage....
>
> Many thanks for any suggestions!
>
> Best wishes,
> Volker
>
>
> MODEL:
>> modelA <- lmer(percentV ~ tempo + (1|speaker) + (1|sentence),data=bt.data)
>   > print(pvals.fnc(modelA))
>
> OUTPUT:
>
> $fixed
>               Estimate MCMCmean HPD95lower HPD95upper  pMCMC Pr(>|t|)
> (Intercept)  42.7346  42.7392    40.2256    45.1771 0.0001   0.0000
> tempo2       -0.1815  -0.1822    -1.0326     0.7087 0.6728   0.6737
> tempo3        0.7979   0.8023    -0.0953     1.6719 0.0768   0.0645
> tempo4        1.1526   1.1504     0.2812     2.0028 0.0088   0.0077
> tempo5        1.2742   1.2740     0.4183     2.1488 0.0042   0.0032
>
> $random
>       Groups        Name Std.Dev. MCMCmedian MCMCmean HPD95lower HPD95upper
> 1  speaker (Intercept)   3.4334     2.3338   2.3684     1.7773    3.0468
> 2 sentence (Intercept)   3.6911     2.5546   2.6462     1.6115    3.7921
> 3 Residual               3.1209     3.1974   3.2010     3.0061    3.4117
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> [https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models]
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From henrik.singmann at psychologie.uni-freiburg.de  Thu May 16 13:56:15 2013
From: henrik.singmann at psychologie.uni-freiburg.de (Henrik Singmann)
Date: Thu, 16 May 2013 13:56:15 +0200
Subject: [R-sig-ME] p-value for fixed factor in lmer
In-Reply-To: <5194061C.7050204@uzh.ch>
References: <5194061C.7050204@uzh.ch>
Message-ID: <5194C95F.20908@psychologie.uni-freiburg.de>

Alternatives to the options mentioned:

- function mixed() in package afex (disclaimer: I am the author of said package)

modelA <- mixed(percentV ~ tempo + (1|speaker) + (1|sentence),data=bt.data)

- anova(..., test = "F") in package car (author is John Fox):

modelA <- lmer(percentV ~ tempo + (1|speaker) + (1|sentence),data=bt.data)
anova(modelA, test = "F")

Both use KRmodcomp from pbkrtest to obtain p-values (which was mentioned by Tom Philippi) and should return the exact same values.

Benefit over pvals.fnc is that the random effects can include random slopes!

Cheers,
Henrik  


Am 16/05/2013 00:03, schrieb Volker Dellwo:
> Dear Mixed Model users,
>
> below is an lmer function for which I calculated p-values with pvals.fnc. In the output I receive five p-values for the fixed factor 'tempo', one for each level. What I would want, however, is a p-value for the entire factor which I can't manage....
>
> Many thanks for any suggestions!
>
> Best wishes,
> Volker
>
>
> MODEL:
>> modelA <- lmer(percentV ~ tempo + (1|speaker) + (1|sentence),data=bt.data)
>  > print(pvals.fnc(modelA))
>
> OUTPUT:
>
> $fixed
>              Estimate MCMCmean HPD95lower HPD95upper  pMCMC Pr(>|t|)
> (Intercept)  42.7346  42.7392    40.2256    45.1771 0.0001   0.0000
> tempo2       -0.1815  -0.1822    -1.0326     0.7087 0.6728   0.6737
> tempo3        0.7979   0.8023    -0.0953     1.6719 0.0768   0.0645
> tempo4        1.1526   1.1504     0.2812     2.0028 0.0088   0.0077
> tempo5        1.2742   1.2740     0.4183     2.1488 0.0042   0.0032
>
> $random
>      Groups        Name Std.Dev. MCMCmedian MCMCmean HPD95lower HPD95upper
> 1  speaker (Intercept)   3.4334     2.3338   2.3684     1.7773    3.0468
> 2 sentence (Intercept)   3.6911     2.5546   2.6462     1.6115    3.7921
> 3 Residual               3.1209     3.1974   3.2010     3.0061    3.4117
>

-- 
Dipl. Psych. Henrik Singmann
PhD Student
Albert-Ludwigs-Universit?t Freiburg, Germany
http://www.psychologie.uni-freiburg.de/Members/singmann


From bates at stat.wisc.edu  Thu May 16 15:46:03 2013
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 16 May 2013 08:46:03 -0500
Subject: [R-sig-ME] p-value for fixed factor in lmer
In-Reply-To: <5194C95F.20908@psychologie.uni-freiburg.de>
References: <5194061C.7050204@uzh.ch>
	<5194C95F.20908@psychologie.uni-freiburg.de>
Message-ID: <CAO7JsnT-nB_ktcLwU75GDCS8br85p_EnwYVgJ6fdD8Wysd-Q9A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130516/aa859dae/attachment.pl>

From hughsturrock at hotmail.com  Thu May 16 23:11:24 2013
From: hughsturrock at hotmail.com (Hugh Sturrock)
Date: Thu, 16 May 2013 22:11:24 +0100
Subject: [R-sig-ME] [R-sig-Geo] Spatially autocorrelated random effects
 in logistic regression.
In-Reply-To: <CAO-WCxdO+OvwPFCp2=gJxGAgpd4+E+=DmJGMuPEAcm3bpMhUvQ@mail.gmail.com>
References: <CAO-WCxcD-ZFFR=0ntwv6T51XzbHz=nO8pafOAsUjSCwisQsAfQ@mail.gmail.com>,
	<DUB116-W11686EB57268A72BEAFA9D4C8A30@phx.gbl>,
	<CAO-WCxdGzvGhK-q815kDRLLShoZeroMQ09qzK_eqm3i_Bo-7qw@mail.gmail.com>,
	<DUB116-W318E1AEAA62C73C43C893EC8A30@phx.gbl>,
	<CAO-WCxdOszb+w=OEOqbR9DDorMrp5D7F0S06f_FsWDm_dTWD+g@mail.gmail.com>,
	<DUB116-W44DA838ED7A341787F0C1EC8A30@phx.gbl>,
	<CAO-WCxdO+OvwPFCp2=gJxGAgpd4+E+=DmJGMuPEAcm3bpMhUvQ@mail.gmail.com>
Message-ID: <DUB116-W1401B431BB3532D4DE4524CC8A30@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130516/c57a1e8d/attachment.pl>

From bbolker at gmail.com  Fri May 17 04:40:37 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 17 May 2013 02:40:37 +0000 (UTC)
Subject: [R-sig-ME] hurdle models
References: <BAY147-W348F9AFFB3C3BC38BD2C4DD9A20@phx.gbl>
	<CACF9ZY+N8idNd36Q=f+vzVCK-Ge4Vb6HL17OfnkZ-k922fmPVA@mail.gmail.com>
Message-ID: <loom.20130517T043926-328@post.gmane.org>

Mark Greenaway <certifiedwaif at ...> writes:

> 
> Also, as this is the mixed models list, if you'd like to fit hurdle or zero
> inflated models with random effects etc. you can use MCMCglmm. It works very
> well.
> 
> Mark

 glmmADMB has these capabilities too ... the syntax for fitting
zero-inflated models is simpler but less flexible than MCMCglmm's.


From sjmyers3142 at gmail.com  Fri May 17 05:09:46 2013
From: sjmyers3142 at gmail.com (Seth Myers)
Date: Thu, 16 May 2013 23:09:46 -0400
Subject: [R-sig-ME] searching nlme source code to try turning off range
	bounds of > 0 for corExp
Message-ID: <CAO-WCxciVt7mWvQ+k2763Dzn79LNOD_v7ZeFDFpjLS2cc=kK2A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130516/61cb9e25/attachment.pl>

From paulidealiste at aol.com  Fri May 17 15:00:37 2013
From: paulidealiste at aol.com (Milos Blagojevic)
Date: Fri, 17 May 2013 09:00:37 -0400 (EDT)
Subject: [R-sig-ME] GLM model evaluation
Message-ID: <8D02115A94A30EA-1A0C-3A395@Webmail-d104.sysops.aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130517/c97e1f37/attachment.pl>

From xav.harrison at gmail.com  Fri May 17 18:04:40 2013
From: xav.harrison at gmail.com (Xavier Harrison)
Date: Fri, 17 May 2013 17:04:40 +0100
Subject: [R-sig-ME] Multivariate Response Model in MCMCglmm - Estimating
	Posterior Correlation Between Traits
Message-ID: <0C529B85-0B83-4EA1-9838-CE1A388CEEF9@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130517/1cda195a/attachment.pl>

From bbolker at gmail.com  Fri May 17 19:28:25 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 17 May 2013 17:28:25 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?searching_nlme_source_code_to_try_turning_of?=
	=?utf-8?q?f_range=09bounds_of_=3E_0_for_corExp?=
References: <CAO-WCxciVt7mWvQ+k2763Dzn79LNOD_v7ZeFDFpjLS2cc=kK2A@mail.gmail.com>
Message-ID: <loom.20130517T192504-749@post.gmane.org>

Seth Myers <sjmyers3142 at ...> writes:

> 
> Hi,
> 
> I have correlated residuals that are well described by an exponential
> function.  However, they exhibit negative spatial autocorrelation at short
> lags that decreases to little spatial autocorrelation at longer lags.  I
> have fit exponential functions to the residual variograms that fit well,
> but the range must be negative to achieve the fit.  I have been searching
> the nlme source code for an hour, and have found corExp (and corStruct and
> similar things) mentioned multiple time, but have not found how to
> eliminate the condition that the range be > 0.  Can anyone point me
> generally in the correct direction?  I will likely cause a cascade of
> errors if I even get that first part to work.  But just trying to move in
> some direction for now.  Thanks. -Seth Myers
> 

  There's probably not a range bound; my guess (not looking at the
code at this moment, but I have looked at it before) is that the
range parameter is estimated on the log scale, which would mean
that you'd have to do more serious architectural changes to get it
to work.  Anyway, putting a negative range in the exponential variogram
function sounds REALLY dicey to me.

  I'm sorry I haven't chimed in on this before.  My thought would
be that the best way to proceed would be to write your own corStruct.
Furthermore, the way I would approach that (rather than trying to
use the built-in e.g. corExp functionality as a guide, since the
nlme code for this stuff is pretty baroque) would to be look at
user-contributed corStructs: there are some in the ape package
(based on phylogenetic distance), and I think maybe some in the
ramps (?) package. You could use library("sos"); findFn("corStruct")
and see if you get anywhere with that ...

  good luck
    Ben Bolker


From bbolker at gmail.com  Fri May 17 19:31:39 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 17 May 2013 13:31:39 -0400
Subject: [R-sig-ME] slightly OT: SAS help
Message-ID: <5196697B.6010709@gmail.com>


  As regular readers here might imagine, I get a lot of off-list
requests for help on mixed models.  I've just gotten a request from
someone who's using SAS PROC GLIMMIX to do this.  I could probably help
them, but on principle I ask that these requests be sent to a public list.
   Does anyone have suggestions for a good
(friendly/experienced/helpful) web SAS-oriented mailing list on mixed
models etc.?

  thanks
    Ben Bolker


From agoijman at cnia.inta.gov.ar  Fri May 17 19:35:19 2013
From: agoijman at cnia.inta.gov.ar (Andrea Goijman)
Date: Fri, 17 May 2013 13:35:19 -0400
Subject: [R-sig-ME] Problems running lmer
Message-ID: <CA+vCKnUDnm8AVP921G9Mex_wvHacXTqCckfAZ9aE7-OvjfwBmA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130517/c596074c/attachment.pl>

From paulidealiste at aol.com  Fri May 17 19:51:28 2013
From: paulidealiste at aol.com (Milos Blagojevic)
Date: Fri, 17 May 2013 13:51:28 -0400 (EDT)
Subject: [R-sig-ME] plots for GLM email sorry
Message-ID: <8D0213E4AE2ED69-1DA4-2ADB7@webmail-m155.sysops.aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130517/6dc7dfe5/attachment.pl>

From jbaldwin at fs.fed.us  Fri May 17 20:32:40 2013
From: jbaldwin at fs.fed.us (Baldwin, Jim -FS)
Date: Fri, 17 May 2013 18:32:40 +0000
Subject: [R-sig-ME] slightly OT: SAS help
In-Reply-To: <5196697B.6010709@gmail.com>
References: <5196697B.6010709@gmail.com>
Message-ID: <DDC5EC9B78340042B0D5A0C3789D4569199D9500@001FSN2MPN1-061.001f.mgd2.msft.net>

The following (just like this public list) can be friendly/experienced/helpful:

https://communities.sas.com/community/support-communities/sas_statistical_procedures

Jim Baldwin


-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Ben Bolker
Sent: Friday, May 17, 2013 10:32 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] slightly OT: SAS help


  As regular readers here might imagine, I get a lot of off-list requests for help on mixed models.  I've just gotten a request from someone who's using SAS PROC GLIMMIX to do this.  I could probably help them, but on principle I ask that these requests be sent to a public list.
   Does anyone have suggestions for a good
(friendly/experienced/helpful) web SAS-oriented mailing list on mixed models etc.?

  thanks
    Ben Bolker

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models





This electronic message contains information generated by the USDA solely for the intended recipients. Any unauthorized interception of this message or the use or disclosure of the information it contains may violate the law and subject the violator to civil or criminal penalties. If you believe you have received this message in error, please notify the sender and delete the email immediately.


From tom_philippi at nps.gov  Fri May 17 22:07:39 2013
From: tom_philippi at nps.gov (Philippi, Tom)
Date: Fri, 17 May 2013 13:07:39 -0700
Subject: [R-sig-ME] Problems running lmer
In-Reply-To: <CA+vCKnUDnm8AVP921G9Mex_wvHacXTqCckfAZ9aE7-OvjfwBmA@mail.gmail.com>
References: <CA+vCKnUDnm8AVP921G9Mex_wvHacXTqCckfAZ9aE7-OvjfwBmA@mail.gmail.com>
Message-ID: <CAM9kYqgq8HYtft12aAd807tJqHCWHyrQ7-pSygZ6HUaGFccDtg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130517/63e698a5/attachment.pl>

From agoijman at cnia.inta.gov.ar  Fri May 17 22:34:07 2013
From: agoijman at cnia.inta.gov.ar (Andrea Goijman)
Date: Fri, 17 May 2013 16:34:07 -0400
Subject: [R-sig-ME] Problems running lmer
In-Reply-To: <CAM9kYqgq8HYtft12aAd807tJqHCWHyrQ7-pSygZ6HUaGFccDtg@mail.gmail.com>
References: <CA+vCKnUDnm8AVP921G9Mex_wvHacXTqCckfAZ9aE7-OvjfwBmA@mail.gmail.com>
	<CAM9kYqgq8HYtft12aAd807tJqHCWHyrQ7-pSygZ6HUaGFccDtg@mail.gmail.com>
Message-ID: <CA+vCKnXu+fwomG2W0VacOr2Q27asaYsHB2qU=7GcG+5OsUpVig@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130517/3166f221/attachment.pl>

From djnordlund at frontier.com  Fri May 17 22:50:04 2013
From: djnordlund at frontier.com (Daniel Nordlund)
Date: Fri, 17 May 2013 13:50:04 -0700
Subject: [R-sig-ME] slightly OT: SAS help
In-Reply-To: <5196697B.6010709@gmail.com>
References: <5196697B.6010709@gmail.com>
Message-ID: <E75E830037AD4E718411368CC0AA8B9C@Aragorn>

The SAS-L mailing list is not mixed models specific, but there are statisticians on the list who know Proc GLIMMIX and could probably assist.  We are a reasonably friendly group.  One must subscribe to the mailing list, but can request no mail and just use the SAS-L archives website site to read and respond to posts.

Link to sign up

http://listserv.uga.edu/cgi-bin/wa?SUBED1=sas-l&A=1


SAL-L archives for reading and posting.

http://listserv.uga.edu/archives/sas-l.html


Hope this is helpful,

Dan

Daniel Nordlund
Bothell, WA USA
 
> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
> bounces at r-project.org] On Behalf Of Ben Bolker
> Sent: Friday, May 17, 2013 10:32 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] slightly OT: SAS help
> 
> 
>   As regular readers here might imagine, I get a lot of off-list
> requests for help on mixed models.  I've just gotten a request from
> someone who's using SAS PROC GLIMMIX to do this.  I could probably help
> them, but on principle I ask that these requests be sent to a public list.
>    Does anyone have suggestions for a good
> (friendly/experienced/helpful) web SAS-oriented mailing list on mixed
> models etc.?
> 
>   thanks
>     Ben Bolker
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From Hugo.Mildenberger at web.de  Sat May 18 09:59:12 2013
From: Hugo.Mildenberger at web.de (Hugo.Mildenberger at web.de)
Date: Sat, 18 May 2013 09:59:12 +0200
Subject: [R-sig-ME] Problems running lmer
In-Reply-To: <CA+vCKnXu+fwomG2W0VacOr2Q27asaYsHB2qU=7GcG+5OsUpVig@mail.gmail.com>
References: <CA+vCKnUDnm8AVP921G9Mex_wvHacXTqCckfAZ9aE7-OvjfwBmA@mail.gmail.com>
	<CAM9kYqgq8HYtft12aAd807tJqHCWHyrQ7-pSygZ6HUaGFccDtg@mail.gmail.com>
	<CA+vCKnXu+fwomG2W0VacOr2Q27asaYsHB2qU=7GcG+5OsUpVig@mail.gmail.com>
Message-ID: <20130518095912.718b46359ad7c618c1eb918d@zotac.lan>

Andrea, Tom,

I was able to reproduce the problem here. Apart from an unfortunate model specification, the technical reason is a stack overflow which sometimes does not even result in an error message (the program gets killed instead). From the kernel logs I can see that R tried to allocate 13 mega bytes of stack space. Using gdb on the core dump shows that this must have happened in function mer_optimize() at lmer.c:1719. 
 

   > # varying intercept by route, species fixed effect
   > m1 <-  lmer(cbind(punto6,5) ~ sp + (1|route) ,family=binomial,data = d)

   > # varying intercept by site within route, species fixed effect
   > m2 <-  lmer(cbind(punto6,5) ~ sp + (site|route) ,family=binomial,data = d)

   Error: segfault from C stack overflow

   > sessionInfo()
   R version 3.0.0 (2013-04-03)
   Platform: x86_64-pc-linux-gnu (64-bit)

   [...]

   other attached packages:
   [1] lme4_0.999999-2 Matrix_1.0-12   lattice_0.20-15

   loaded via a namespace (and not attached):
   [1] grid_3.0.0   nlme_3.1-109 stats4_3.0.0


Best





On Fri, 17 May 2013 16:34:07 -0400
Andrea Goijman <agoijman at cnia.inta.gov.ar> wrote:

> Tom,
> 
> Thanks for your response!
> R just stops working. No error message.
> It looks like I'm fitting the wrong model, and I'm not understanding where
> the 550 levels of site are coming from (I see that is the number with
> str(d)).
> 
> Here is what I want to do... As a first step I want to evaluate if there is
> autocorrelation of the response variable between sites within each route
> (for each species separately). I just want to know if the sites within
> routes are more similar to each other than sites from different routes or
> not. What is the correct model for that?
> 
> Here is the session Info
> 
> Thanks!
> 
> sessionInfo()
> 
> R version 2.15.1 (2012-06-22)
> Platform: x86_64-pc-mingw32/x64 (64-bit)
> 
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] lme4_0.999999-0 Matrix_1.0-6    lattice_0.20-6
> 
> loaded via a namespace (and not attached):
> [1] grid_2.15.1   nlme_3.1-104  stats4_2.15.1
> 
> 
> On Fri, May 17, 2013 at 4:07 PM, Philippi, Tom <tom_philippi at nps.gov> wrote:
> 
> > Andrea--
> > "Crashes" is not particularly informative.  Was there an error message?
> >  Also,
> > sessionInfo() would help the real experts know which versions of R and
> > lme4 you are running, and on what hardware.
> >
> > That said, I'm not sure what you expect from or mean by your
> > (1+site|route) random effect.  Both site and route are factors, so a
> > "slope" for site is actually N-1 coefficients for unordered levels of sites
> > within each route.  Given that you appear to have one observation for each
> > sp by site combination (7sp*42site=294 observations), and sp is a factor
> > included as a main effect, your model appears to fit more parameters than
> > you have observations.
> >
> > And, at least for the data you included, you have 550 levels of site, but
> > only 294 observations.
> > str(d)
> >
> > I hope that this gets you pointed in the right direction for solving your
> > problem.
> > Tom
> >
> >
> >
> > On Fri, May 17, 2013 at 10:35 AM, Andrea Goijman <
> > agoijman at cnia.inta.gov.ar> wrote:
> >
> >> Dear R list,
> >>
> >> I'm attaching a sample of my data which consists on the presence/absence
> >> ("punto6", binomial n=5 occasions)
> >> of different species ("sp"), on different sites ("site") within routes
> >> ('route").
> >>
> >> First, I want to be able to find if there is autocorrelation of the
> >> response variable between
> >> the sites within each route. For this I start testing 2 models, but when I
> >> try to run the second model,
> >> to test for the random effects of sites within routes R stops working!
> >>
> >> I'm not being able to find out why r is crashing... and whay am I doing
> >> wrong.
> >>
> >> Thanks!
> >>
> >> Andrea
> >>
> >> #######################################################
> >> #dput(d)
> >>
> >> d<-structure(list(site = structure(c(55L, 56L, 57L, 58L, 59L, 60L,
> >> 55L, 56L, 57L, 58L, 59L, 60L, 55L, 56L, 57L, 58L, 59L, 60L, 55L,
> >> 56L, 57L, 58L, 59L, 60L, 55L, 56L, 57L, 58L, 59L, 60L, 55L, 56L,
> >> 57L, 58L, 59L, 60L, 55L, 56L, 57L, 58L, 59L, 60L, 229L, 230L,
> >> 231L, 232L, 233L, 234L, 229L, 230L, 231L, 232L, 233L, 234L, 229L,
> >> 230L, 231L, 232L, 233L, 234L, 229L, 230L, 231L, 232L, 233L, 234L,
> >> 229L, 230L, 231L, 232L, 233L, 234L, 229L, 230L, 231L, 232L, 233L,
> >> 234L, 229L, 230L, 231L, 232L, 233L, 234L, 331L, 332L, 333L, 334L,
> >> 335L, 336L, 331L, 332L, 333L, 334L, 335L, 336L, 331L, 332L, 333L,
> >> 334L, 335L, 336L, 331L, 332L, 333L, 334L, 335L, 336L, 331L, 332L,
> >> 333L, 334L, 335L, 336L, 331L, 332L, 333L, 334L, 335L, 336L, 331L,
> >> 332L, 333L, 334L, 335L, 336L, 389L, 390L, 391L, 392L, 393L, 394L,
> >> 389L, 390L, 391L, 392L, 393L, 394L, 389L, 390L, 391L, 392L, 393L,
> >> 394L, 389L, 390L, 391L, 392L, 393L, 394L, 389L, 390L, 391L, 392L,
> >> 393L, 394L, 389L, 390L, 391L, 392L, 393L, 394L, 389L, 390L, 391L,
> >> 392L, 393L, 394L, 205L, 206L, 207L, 208L, 209L, 210L, 205L, 206L,
> >> 207L, 208L, 209L, 210L, 205L, 206L, 207L, 208L, 209L, 210L, 205L,
> >> 206L, 207L, 208L, 209L, 210L, 205L, 206L, 207L, 208L, 209L, 210L,
> >> 205L, 206L, 207L, 208L, 209L, 210L, 205L, 206L, 207L, 208L, 209L,
> >> 210L, 163L, 164L, 165L, 166L, 167L, 168L, 163L, 164L, 165L, 166L,
> >> 167L, 168L, 163L, 164L, 165L, 166L, 167L, 168L, 163L, 164L, 165L,
> >> 166L, 167L, 168L, 163L, 164L, 165L, 166L, 167L, 168L, 163L, 164L,
> >> 165L, 166L, 167L, 168L, 163L, 164L, 165L, 166L, 167L, 168L, 247L,
> >> 248L, 249L, 250L, 251L, 252L, 247L, 248L, 249L, 250L, 251L, 252L,
> >> 247L, 248L, 249L, 250L, 251L, 252L, 247L, 248L, 249L, 250L, 251L,
> >> 252L, 247L, 248L, 249L, 250L, 251L, 252L, 247L, 248L, 249L, 250L,
> >> 251L, 252L, 247L, 248L, 249L, 250L, 251L, 252L), .Label = c("102-1",
> >> "102-2", "102-3", "102-4", "102-5", "102-6", "1023-1", "1023-2",
> >> "1023-3", "1023-4", "1023-5", "1023-6", "1027-1", "1027-2", "1027-3",
> >> "1027-4", "1027-5", "1027-6", "1028-1", "1028-2", "1028-3", "1028-4",
> >> "1028-5", "1028-6", "1032-1", "1032-2", "1032-3", "1032-4", "1032-5",
> >> "1032-6", "1034-1", "1034-2", "1034-3", "1034-4", "1034-5", "1034-6",
> >> "1036-1", "1036-2", "1036-3", "1036-4", "1036-5", "1036-6", "1041-1",
> >> "1041-2", "1041-3", "1041-4", "1041-5", "1041-6", "1046-1", "1046-2",
> >> "1046-3", "1046-4", "1046-5", "1046-6", "105-1", "105-2", "105-3",
> >> "105-4", "105-5", "105-6", "107-1", "107-2", "107-3", "107-4",
> >> "107-5", "107-6", "108-1", "108-2", "108-3", "108-4", "108-5",
> >> "108-6", "1101-1", "1101-2", "1101-3", "1101-4", "1101-5", "1101-6",
> >> "1104-1", "1104-2", "1104-3", "1104-4", "1104-5", "1104-6", "1108-1",
> >> "1108-2", "1108-3", "1108-4", "1108-5", "1108-6", "111-1", "111-2",
> >> "111-3", "111-4", "111-5", "111-6", "1113-1", "1113-2", "1113-3",
> >> "1113-4", "1113-5", "1113-6", "1116-1", "1116-2", "1116-3", "1116-4",
> >> "1116-5", "1116-6", "1121-1", "1121-2", "1121-3", "1121-4", "1121-5",
> >> "1121-6", "1204-1", "1204-2", "1204-3", "1204-4", "1204-5", "1204-6",
> >> "1205-1", "1205-2", "1205-3", "1205-4", "1205-5", "1205-6", "1207-1",
> >> "1207-2", "1207-3", "1207-4", "1207-5", "1207-6", "1212-1", "1212-2",
> >> "1212-3", "1212-4", "1212-5", "1212-6", "202-1", "202-2", "202-3",
> >> "202-4", "202-5", "202-6", "205-1", "205-2", "205-3", "205-4",
> >> "205-5", "205-6", "207-1", "207-2", "207-3", "207-4", "207-5",
> >> "207-6", "208-1", "208-2", "208-3", "208-4", "208-5", "208-6",
> >> "211-1", "211-2", "211-3", "211-4", "211-5", "211-6", "213-1",
> >> "213-2", "213-3", "213-4", "213-5", "213-6", "214-1", "214-2",
> >> "214-3", "214-4", "214-5", "214-6", "217-1", "217-2", "217-3",
> >> "217-4", "217-5", "217-6", "218-1", "218-2", "218-3", "218-4",
> >> "218-5", "218-6", "219-1", "219-2", "219-3", "219-4", "219-5",
> >> "219-6", "223-1", "223-2", "223-3", "223-4", "223-5", "223-6",
> >> "302-1", "302-2", "302-3", "302-4", "302-5", "302-6", "305-1",
> >> "305-2", "305-3", "305-4", "305-5", "305-6", "308-1", "308-2",
> >> "308-3", "308-4", "308-5", "308-6", "311-1", "311-2", "311-3",
> >> "311-4", "311-5", "311-6", "401-1", "401-2", "401-3", "401-4",
> >> "401-5", "401-6", "402-1", "402-2", "402-3", "402-4", "402-5",
> >> "402-6", "405-1", "405-2", "405-3", "405-4", "405-5", "405-6",
> >> "407-1", "407-2", "407-3", "407-4", "407-5", "407-6", "408-1",
> >> "408-2", "408-3", "408-4", "408-5", "408-6", "410-1", "410-2",
> >> "410-3", "410-4", "410-5", "410-6", "411-1", "411-2", "411-3",
> >> "411-4", "411-5", "411-6", "414-1", "414-2", "414-3", "414-4",
> >> "414-5", "414-6", "416-1", "416-2", "416-3", "416-4", "416-5",
> >> "416-6", "417-1", "417-2", "417-3", "417-4", "417-5", "417-6",
> >> "420-1", "420-2", "420-3", "420-4", "420-5", "420-6", "423-1",
> >> "423-2", "423-3", "423-4", "423-5", "423-6", "501-1", "501-2",
> >> "501-3", "501-4", "501-5", "501-6", "502-1", "502-2", "502-3",
> >> "502-4", "502-5", "502-6", "504-1", "504-2", "504-3", "504-4",
> >> "504-5", "504-6", "505-1", "505-2", "505-3", "505-4", "505-5",
> >> "505-6", "507-1", "507-2", "507-3", "507-4", "507-5", "507-6",
> >> "508-1", "508-2", "508-3", "508-4", "508-5", "508-6", "511-1",
> >> "511-2", "511-3", "511-4", "511-5", "511-6", "602-1", "602-2",
> >> "602-3", "602-4", "602-5", "602-6", "604-1", "604-2", "604-3",
> >> "604-4", "604-5", "604-6", "605-1", "605-2", "605-3", "605-4",
> >> "605-5", "605-6", "608-1", "608-2", "608-3", "608-4", "608-5",
> >> "608-6", "611-1", "611-2", "611-3", "611-4", "611-5", "611-6",
> >> "613-1", "613-2", "613-3", "613-4", "613-5", "613-6", "614-1",
> >> "614-2", "614-3", "614-4", "617-1", "617-2", "617-3", "617-4",
> >> "617-5", "617-6", "620-1", "620-2", "620-3", "620-4", "620-5",
> >> "620-6", "623-1", "623-2", "623-3", "623-4", "623-5", "623-6",
> >> "702-1", "702-2", "702-3", "702-4", "702-5", "702-6", "705-1",
> >> "705-2", "705-3", "705-4", "705-5", "705-6", "708-1", "708-2",
> >> "708-3", "708-4", "708-5", "708-6", "712-1", "712-2", "712-3",
> >> "712-4", "712-5", "712-6", "713-1", "713-2", "713-3", "713-4",
> >> "713-5", "713-6", "715-1", "715-2", "715-3", "715-4", "715-5",
> >> "715-6", "717-1", "717-2", "717-3", "717-4", "717-5", "717-6",
> >> "718-1", "718-2", "718-3", "718-4", "718-5", "718-6", "803-1",
> >> "803-2", "803-3", "803-4", "803-5", "803-6", "807-1", "807-2",
> >> "807-3", "807-4", "807-5", "807-6", "809-1", "809-2", "809-3",
> >> "809-4", "809-5", "809-6", "812-1", "812-2", "812-3", "812-4",
> >> "812-5", "812-6", "814-1", "814-2", "814-3", "814-4", "814-5",
> >> "814-6", "818-1", "818-2", "818-3", "818-4", "818-5", "818-6",
> >> "820-1", "820-2", "820-3", "820-4", "820-5", "820-6", "823-1",
> >> "823-2", "823-3", "823-4", "823-5", "823-6", "825-1", "825-2",
> >> "825-3", "825-4", "825-5", "825-6", "903-1", "903-2", "903-3",
> >> "903-4", "903-5", "903-6", "907-1", "907-2", "907-3", "907-4",
> >> "907-5", "907-6", "909-1", "909-2", "909-3", "909-4", "909-5",
> >> "909-6", "913-1", "913-2", "913-3", "913-4", "913-5", "913-6",
> >> "915-1", "915-2", "915-3", "915-4", "915-5", "915-6", "920-1",
> >> "920-2", "920-3", "920-4", "920-5", "920-6", "925-1", "925-2",
> >> "925-3", "925-4", "925-5", "925-6", "926-1", "926-2", "926-3",
> >> "926-4", "926-5", "926-6"), class = "factor"), sp = structure(c(4L,
> >> 4L, 4L, 4L, 4L, 4L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L,
> >> 2L, 3L, 3L, 3L, 3L, 3L, 3L, 6L, 6L, 6L, 6L, 6L, 6L, 7L, 7L, 7L,
> >> 7L, 7L, 7L, 5L, 5L, 5L, 5L, 5L, 5L, 4L, 4L, 4L, 4L, 4L, 4L, 1L,
> >> 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L,
> >> 3L, 6L, 6L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 7L, 7L, 5L, 5L, 5L,
> >> 5L, 5L, 5L, 4L, 4L, 4L, 4L, 4L, 4L, 1L, 1L, 1L, 1L, 1L, 1L, 2L,
> >> 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 6L, 6L, 6L, 6L, 6L,
> >> 6L, 7L, 7L, 7L, 7L, 7L, 7L, 5L, 5L, 5L, 5L, 5L, 5L, 4L, 4L, 4L,
> >> 4L, 4L, 4L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 3L,
> >> 3L, 3L, 3L, 3L, 3L, 6L, 6L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 7L,
> >> 7L, 5L, 5L, 5L, 5L, 5L, 5L, 4L, 4L, 4L, 4L, 4L, 4L, 1L, 1L, 1L,
> >> 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 6L,
> >> 6L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 7L, 7L, 5L, 5L, 5L, 5L, 5L,
> >> 5L, 4L, 4L, 4L, 4L, 4L, 4L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
> >> 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 6L, 6L, 6L, 6L, 6L, 6L, 7L,
> >> 7L, 7L, 7L, 7L, 7L, 5L, 5L, 5L, 5L, 5L, 5L, 4L, 4L, 4L, 4L, 4L,
> >> 4L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L,
> >> 3L, 3L, 3L, 6L, 6L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 7L, 7L, 5L,
> >> 5L, 5L, 5L, 5L, 5L), .Label = c("LEAN", "MICH", "SPCU", "STSU",
> >> "TRAE", "TYSA", "ZOCA"), class = "factor"), route = c("105",
> >> "105", "105", "105", "105", "105", "105", "105", "105", "105",
> >> "105", "105", "105", "105", "105", "105", "105", "105", "105",
> >> "105", "105", "105", "105", "105", "105", "105", "105", "105",
> >> "105", "105", "105", "105", "105", "105", "105", "105", "105",
> >> "105", "105", "105", "105", "105", "401", "401", "401", "401",
> >> "401", "401", "401", "401", "401", "401", "401", "401", "401",
> >> "401", "401", "401", "401", "401", "401", "401", "401", "401",
> >> "401", "401", "401", "401", "401", "401", "401", "401", "401",
> >> "401", "401", "401", "401", "401", "401", "401", "401", "401",
> >> "401", "401", "508", "508", "508", "508", "508", "508", "508",
> >> "508", "508", "508", "508", "508", "508", "508", "508", "508",
> >> "508", "508", "508", "508", "508", "508", "508", "508", "508",
> >> "508", "508", "508", "508", "508", "508", "508", "508", "508",
> >> "508", "508", "508", "508", "508", "508", "508", "508", "620",
> >> "620", "620", "620", "620", "620", "620", "620", "620", "620",
> >> "620", "620", "620", "620", "620", "620", "620", "620", "620",
> >> "620", "620", "620", "620", "620", "620", "620", "620", "620",
> >> "620", "620", "620", "620", "620", "620", "620", "620", "620",
> >> "620", "620", "620", "620", "620", "302", "302", "302", "302",
> >> "302", "302", "302", "302", "302", "302", "302", "302", "302",
> >> "302", "302", "302", "302", "302", "302", "302", "302", "302",
> >> "302", "302", "302", "302", "302", "302", "302", "302", "302",
> >> "302", "302", "302", "302", "302", "302", "302", "302", "302",
> >> "302", "302", "211", "211", "211", "211", "211", "211", "211",
> >> "211", "211", "211", "211", "211", "211", "211", "211", "211",
> >> "211", "211", "211", "211", "211", "211", "211", "211", "211",
> >> "211", "211", "211", "211", "211", "211", "211", "211", "211",
> >> "211", "211", "211", "211", "211", "211", "211", "211", "407",
> >> "407", "407", "407", "407", "407", "407", "407", "407", "407",
> >> "407", "407", "407", "407", "407", "407", "407", "407", "407",
> >> "407", "407", "407", "407", "407", "407", "407", "407", "407",
> >> "407", "407", "407", "407", "407", "407", "407", "407", "407",
> >> "407", "407", "407", "407", "407"), punto6 = c(3, 5, 3, 2, 2,
> >> 2, 0, 0, 0, 0, 0, 0, 3, 3, 5, 4, 5, 2, 1, 0, 0, 1, 1, 2, 1, 1,
> >> 0, 2, 1, 0, 0, 0, 0, 0, 0, 3, 0, 0, 2, 3, 3, 1, 3, 2, 2, 3, 3,
> >> 2, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 1, 1, 1, 1, 1, 0, 2, 1, 2,
> >> 1, 2, 2, 0, 4, 2, 2, 2, 0, 3, 2, 0, 2, 0, 2, 2, 0, 0, 1, 0, 0,
> >> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,
> >> 2, 2, 0, 0, 0, 1, 1, 1, 1, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 1, 0,
> >> 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 2,
> >> 2, 1, 0, 2, 1, 1, 5, 1, 3, 1, 0, 0, 1, 1, 0, 2, 2, 4, 5, 4, 4,
> >> 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0,
> >> 1, 4, 2, 1, 0, 2, 0, 1, 1, 0, 1, 0, 2, 3, 1, 1, 1, 1, 1, 2, 2,
> >> 1, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 3, 0, 0, 1, 0, 1, 0, 0, 1, 3,
> >> 1, 3, 4, 2, 4, 5, 5, 3, 3, 3, 0, 0, 0, 0, 0, 1, 1, 3, 0, 0, 1,
> >> 2, 0, 0, 0, 0, 0, 0, 2, 1, 1, 4, 2, 0, 1, 2, 1, 2, 2, 2, 2, 1,
> >> 3, 0, 1, 0, 2, 3, 3, 2, 1, 4, 1, 0, 1, 1, 1, 1)), .Names = c("site",
> >> "sp", "route", "punto6"), class = "data.frame", row.names = c(NA,
> >> -294L))
> >>
> >> d
> >>
> >> library(lme4)
> >>
> >> # varying intercept by route, species fixed effect
> >> m1 <-  lmer(cbind(punto6,5) ~ sp + (1|route) ,family=binomial,data = d)
> >>
> >> # varying intercept by site within route, species fixed effect
> >> m2 <-  lmer(cbind(punto6,5) ~ sp + (site|route) ,family=binomial,data = d)
> >>  ### CRASHES!
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
> >
> >
> >
> 
> 
> -- 
> -----
> Lic. Andrea Paula Goijman, PhD Candidate
> Grupo Ecolog_a y Gesti_n Ambiental de la Biodiversidad
> IRB - INTA Castelar, Argentina
> agoijman at cnia.inta.gov.ar
>  <http://inta.gob.ar/personas/goijman.andrea/>
> http://inta.gob.ar/personas/goijman.andrea/
> 
> D.B. Warnell School of Forestry and Natural Resources
> University of Georgia
> Athens, GA 30602 USA
> Tel. +706.206.4805
> andreapg at uga.edu
> 
> 	[[alternative HTML version deleted]]
> 


-- 
Hugo Mildenberger <hm at zotac.lan>


From a.hayward at sheffield.ac.uk  Mon May 20 09:59:58 2013
From: a.hayward at sheffield.ac.uk (Adam Hayward)
Date: Mon, 20 May 2013 08:59:58 +0100
Subject: [R-sig-ME] Fixing residual variance in MCMCglmm
Message-ID: <CALQiR08sOASeBbAsyHTSRDgnujbxLJfU0rqdSepLx3xRq2dk6A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130520/286d2c67/attachment.pl>

From Julia.Sommerfeld at utas.edu.au  Mon May 20 11:06:38 2013
From: Julia.Sommerfeld at utas.edu.au (Julia Sommerfeld)
Date: Mon, 20 May 2013 11:06:38 +0200
Subject: [R-sig-ME] Question about Multilevel ZIP model with glmmADMB
Message-ID: <CAOCHjhSe2RaxUnuM96G+QLg4xqv5uRL31+O_wyzFgAJ1=J8Hhw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130520/4ad0a223/attachment.pl>

From stevedrd at yahoo.com  Mon May 20 12:02:00 2013
From: stevedrd at yahoo.com (Steve Denham)
Date: Mon, 20 May 2013 03:02:00 -0700 (PDT)
Subject: [R-sig-ME] slightly OT: SAS help
In-Reply-To: <5196697B.6010709@gmail.com>
References: <5196697B.6010709@gmail.com>
Message-ID: <1369044120.63385.YahooMailNeo@web140604.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130520/3a846a86/attachment.pl>

From Julia.Sommerfeld at utas.edu.au  Mon May 20 12:19:11 2013
From: Julia.Sommerfeld at utas.edu.au (Julia Sommerfeld)
Date: Mon, 20 May 2013 12:19:11 +0200
Subject: [R-sig-ME] previous posts about error message in glmmADMB
Message-ID: <CAOCHjhTc38==KKBeWVAfqJoNytSd+Q_P84dHwpq5wfDFkhdKkA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130520/36f366bc/attachment.pl>

From c.acharya at duke.edu  Mon May 20 07:42:36 2013
From: c.acharya at duke.edu (Chaitanya Acharya)
Date: Mon, 20 May 2013 05:42:36 +0000
Subject: [R-sig-ME] multivariate mixed model question
Message-ID: <2CF10C10-8829-4304-BEBA-1CF4AAE564AE@duke.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130520/a8aa8c41/attachment.pl>

From bbolker at gmail.com  Mon May 20 20:45:19 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 20 May 2013 18:45:19 +0000 (UTC)
Subject: [R-sig-ME] previous posts about error message in glmmADMB
References: <CAOCHjhTc38==KKBeWVAfqJoNytSd+Q_P84dHwpq5wfDFkhdKkA@mail.gmail.com>
Message-ID: <loom.20130520T202757-964@post.gmane.org>

Julia Sommerfeld <Julia.Sommerfeld at ...> writes:

> 
> Dear list,
> 
> I'm trying to fit a glmmadmb, but I'm always getting the following error
> message:
> 
> *mod <- glmmadmb(anzahl_round~wea1*seg + offset(log(flaeche)) + (1|day_ID)
> + (1|seg), zeroInflation=TRUE, family="poisson", data=dat1)  *
> 
> *Parameters were estimated, but not standard errors were not: the most
> likely problem is that the curvature at MLE was zero or negative
> Error in glmmadmb(anzahl_round ~ wea1 * seg + offset(log(flaeche)) + (1 |
> :
>   The function maximizer failed (couldn't find STD file) Troubleshooting
> steps include (1) run with 'save.dir' set and inspect output files; (2)
> change run parameters: see '?admbControl'

 [snip]

> Previous posts suggested to run "..., save.dir="tmp",
> admb.opts=admbControl(run=FALSE), ...".  However, when I run this example
> provided in an older post (see old post below), I get another error
> message 'run=FALSE'
> specified, STD file not found: stopping
> 

  Let me try to explain in a little more detail.

 debug=TRUE is just a generic debugging option; you don't
need it if you don't want to see explicitly where glmmADMB
is looking for the binary files, putting the results, etc.

 setting 'save.dir' *and* setting 'run=FALSE' is intended
for (1) the case where you want to look at the model setup
files yourself, or send them to an AD Model Builder guru,
because glmmADMB is running out of memory or otherwise doing
something funny, or (2) the case where you have already run ADMB 
(and the output files exist in your save-directory) and just
want to read the output files into ADMB.

  It's a bit hard to diagnose precisely what is happening when
the curvature of the MLE is zero/negative (technically, the
second-derivative matrix of the likelihood surface is 
non-positive definite).  Very often the problem is overfitting
(you are trying to fit a model that is more complex than
your data can accommodate), but sometimes there is something
else wrong with the model, and sometimes it's not your fault
at all -- the numerics are just a little too sensitive.  If you
send me the 'dat1' data set I can try to see if there is
something that can be tweaked to make the model succeed
with these data.

  For future reference, it can help to give
summary(dat1) so we can see what your variables are, how
many levels the grouping variables day_ID and seg
have, etc ...


From Julia.Sommerfeld at utas.edu.au  Tue May 21 08:25:44 2013
From: Julia.Sommerfeld at utas.edu.au (Julia Sommerfeld)
Date: Tue, 21 May 2013 08:25:44 +0200
Subject: [R-sig-ME] previous posts about error message in glmmADMB
Message-ID: <CAOCHjhSvtFtcNavUHbVURpT56juj-Q_BeXQTDhZf9F80dW5TZw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130521/e3dc75d3/attachment.pl>

From thomas.merkling at univ-tlse3.fr  Tue May 21 10:08:01 2013
From: thomas.merkling at univ-tlse3.fr (Thomas Merkling)
Date: Tue, 21 May 2013 10:08:01 +0200
Subject: [R-sig-ME] multivariate MCMCglmm problem
Message-ID: <519B2B61.2020300@univ-tlse3.fr>

Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : non disponible
URL : <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130521/197ed691/attachment.pl>

From filipescpcarvalho at yahoo.com  Tue May 21 12:02:20 2013
From: filipescpcarvalho at yahoo.com (Filipe Carvalho)
Date: Tue, 21 May 2013 03:02:20 -0700 (PDT)
Subject: [R-sig-ME] Enc: getting residuals from model averaging
In-Reply-To: <1369069570.54337.YahooMailNeo@web161404.mail.bf1.yahoo.com>
References: <1369069570.54337.YahooMailNeo@web161404.mail.bf1.yahoo.com>
Message-ID: <1369130540.20258.YahooMailNeo@web161404.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130521/46394e0b/attachment.pl>

From raphael.royaute at gmail.com  Tue May 21 15:10:54 2013
From: raphael.royaute at gmail.com (Raphael Royaute)
Date: Tue, 21 May 2013 09:10:54 -0400
Subject: [R-sig-ME]  multivariate MCMCglmm problem
Message-ID: <CADx9CcrOsMDk-nVp9=h-5GNXwpbM8vzME_=OP=9_2TX6386nJw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130521/320289f5/attachment.pl>

From andrew.mcaleavey at gmail.com  Tue May 21 17:41:04 2013
From: andrew.mcaleavey at gmail.com (Andrew McAleavey)
Date: Tue, 21 May 2013 11:41:04 -0400
Subject: [R-sig-ME] categorical random effects correlation in lme4
Message-ID: <CANgPp9=db6FY5ZxWVCF+x_DziktHrYTkvFjCvuwELtmeyHvoLQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130521/106e0057/attachment.pl>

From bbolker at gmail.com  Tue May 21 19:07:30 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 21 May 2013 13:07:30 -0400
Subject: [R-sig-ME] previous posts about error message in glmmADMB
In-Reply-To: <CAOCHjhTc38==KKBeWVAfqJoNytSd+Q_P84dHwpq5wfDFkhdKkA@mail.gmail.com>
References: <CAOCHjhTc38==KKBeWVAfqJoNytSd+Q_P84dHwpq5wfDFkhdKkA@mail.gmail.com>
Message-ID: <519BA9D2.4000101@gmail.com>

On 13-05-20 06:19 AM, Julia Sommerfeld wrote:
> Dear list,
> 
> I'm trying to fit a glmmadmb, but I'm always getting the following error
> message:
> 
> *mod <- glmmadmb(anzahl_round~wea1*seg + offset(log(flaeche)) +
> (1|day_ID) + (1|seg), zeroInflation=TRUE, family="poisson", data=dat1)  *
> 
> /Parameters were estimated, but not standard errors were not: the most
> likely problem is that the curvature at MLE was zero or negative
> Error in glmmadmb(anzahl_round ~ wea1 * seg + offset(log(flaeche)) + (1
> |  :
>   The function maximizer failed (couldn't find STD file) Troubleshooting
> steps include (1) run with 'save.dir' set and inspect output files; (2)
> change run parameters: see '?admbControl'
> In addition: Warning message:
> running command 'C:\Windows\system32\cmd.exe /c
> "C:/Users/Hawksbill/Documents/R/win-library/3.0/glmmADMB/bin/windows32/glmmadmb.exe"
> -maxfn 500 -maxph 5 -noinit -shess' had status 1 /
> 

  Update:

I can replicate this problem, and we are working on a tweak that will
allow glmmADMB to fit this model.  However, in the meantime I have some
advice ...

 This case is similar to the previous one posted here.  The essential
problem is that the data are highly overdispersed (with or without
zero-inflation), so that estimates of the predicted Poisson mean
underflow to zero, which throws off the estimation.  In the absence of
being able to fit the ZIP, you can confirm pretty well that the ZINB is
a better model by looking at the summary of the ZINB and seeing that the
estimated alpha (overdispersion parameter) is small, with a small
standard error -- therefore NB will be better than Poisson.

  A couple of other points to note, though:

* you should not be trying to fit seg as both a fixed and a random
factor. By putting wea1*seg in the formula, you are implicitly including
the main effects of wea1 and seg and their interaction (the interaction
alone would be written wea1:seg.  You might want ~wea1+wea1:seg ?

* the results of fitting ZINB and NB are a little weird, possibly for
this reason (the NB fits better [has a lower negative log-likelihood]
than the ZINB, which should be impossible)

* you might also want to check the mean-variance scaling/consider
family="nbinom1"

* in all the models I fitted (ZIP, P, ZINB, NB) the 1|seg variance comes
out as zero, again probably because of the redundancy described above.
Even when you don't have redundancy in your model this sort of thing
happens sometimes, indicating that your random-effects model is slightly
overfitted.


From Julia.Sommerfeld at utas.edu.au  Tue May 21 19:12:06 2013
From: Julia.Sommerfeld at utas.edu.au (Julia Sommerfeld)
Date: Tue, 21 May 2013 19:12:06 +0200
Subject: [R-sig-ME] Inference from glmmadmb output - bayesian inference not
	possible?
Message-ID: <CAOCHjhS6dOna__0tiF9Rt9vFEdnJoPP+_yJJn1EOD4uNg+6=KQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130521/a3b8bc28/attachment.pl>

From M.Fairbrother at bristol.ac.uk  Tue May 21 19:30:00 2013
From: M.Fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Tue, 21 May 2013 18:30:00 +0100
Subject: [R-sig-ME] categorical random effects correlation in lme4
Message-ID: <CAAH-yP-B9YonPMkzYaB0XpDyX8--MYQTa17=g+m0zKb1QHh43A@mail.gmail.com>

Dear Andrew,

What if you drop the "0 +" bit? So:

 lmer(DI ~ first_di + factor(white) + (factor(white) | primary_ther),
rem3post, REML=F)

or

 lmer(DI ~ first_di + white + (white | primary_ther), rem3post, REML=F)

Including "0 +" means you're not estimating a random intercept for
"primary_ther", which it sounds like you need/want. Instead, you're
getting two random slopes, which I guess are perfectly correlated
because they're two sides of the same coin (the coin being your binary
dummy variable "white").

If that doesn't solve the problem, it might help for you to post the
results of "str(rem3post)" (i.e., your dataset) as well.

Cheers,
Malcolm




> Date: Tue, 21 May 2013 11:41:04 -0400
> From: Andrew McAleavey <andrew.mcaleavey at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] categorical random effects correlation in lme4
>
> Hi,
>
> I'm currently investigating a question of relative effectiveness of
> therapists, and the particular question is whether some therapists are
> differentially effective with white versus racial/ethnic minority clients
> (this is coded as a binary variable called "white" in this data). We have
> conceptualized this as a cross-level random effect, so the model has one
> random effect for therapist intercept and one effect for the difference in
> effectiveness between their white and nonwhite clients.
>
> I am relatively new to lme4, but I think I have specified the model
> correctly (the fixed effects represent client pretreatment severity and the
> nonsignificant fixed effect of binary race; they don't seem to impact the
> estimation problem). Here's the model of interest:
>>print(fm1_ml <- lmer(DI ~ first_di + white + (0 +
> factor(white)|primary_ther), rem3post, REML=F), corr=F)
>
> The problem is that the two random effects are appearing to correlate at r
> = 1.000. I think this is an estimation problem, and probably indicates that
> the random variables aren't accounting for all that much variance. I'm
> dubious of interpreting this model, therefore. However, when comparing it
> to the random intercepts only model using the LRT, there is a significant
> difference, suggesting that even though the explained variance is (very)
> small, it may be worth including:
>> anova(fm1_a_ml, fm1_ml)
> Data: rem3post
> Models:
> fm1_a_ml: DI ~ first_di + factor(white) + (1 | primary_ther)
> fm1_ml: DI ~ first_di + factor(white) + (0 + factor(white) | primary_ther)
>                 Df    AIC      BIC      logLik     Chisq    Chi Df
> Pr(>Chisq)
> fm1_a_ml   5    4982.7  5011.3  -2486.3
> fm1_ml      7    4979.9   5019.9  -2482.9  6.7871      2        0.03359 *
>
> My question is basically this: How should I interpret these results? There
> are significant differences between therapists in terms of their relative
> effectiveness with white vs. nonwhite clients, but they're just small? Or
> is even this not justified? Would it be safer to say that there are likely
> no estimable differences? Am I missing something else?
>
> Thanks a lot,
> Andrew McAleavey
>
> Here's the model of interest output:
>> print(fm1_ml <- lmer(DI ~ first_di + factor(white) + (0 +
> factor(white)|primary_ther), rem3post, REML=F), corr=F)
> Linear mixed model fit by maximum likelihood
> Formula: DI ~ first_di + factor(white) + (0 + factor(white) | primary_ther)
>    Data: rem3post
>   AIC  BIC logLik deviance REMLdev
>  4980 5020  -2483     4966    4983
> Random effects:
>  Groups       Name              Variance        Std.Dev.   Corr
>  primary_ther factor(white)    0 0.0417050  0.204218
>                  factor(white)1     0.0044086     0.066397   1.000
>  Residual                            0.5099596     0.714115
> Number of obs: 2263, groups: primary_ther, 192
>
> Fixed effects:
>                      Estimate Std. Error t value
> (Intercept)        0.45138    0.06007   7.514
> first_di             0.48009    0.02360   20.338
> factor(white)1   0.01140    0.03298   0.346
>
> --
> Andrew McAleavey, M.S.
> Department of Psychology
> The Pennsylvania State University
> 346 Moore Building
> University Park, PA 16802
> aam239 at psu.edu


From David.Duffy at qimr.edu.au  Wed May 22 02:29:55 2013
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Wed, 22 May 2013 10:29:55 +1000
Subject: [R-sig-ME] multivariate MCMCglmm problem
In-Reply-To: <CADx9CcrOsMDk-nVp9=h-5GNXwpbM8vzME_=OP=9_2TX6386nJw@mail.gmail.com>
References: <CADx9CcrOsMDk-nVp9=h-5GNXwpbM8vzME_=OP=9_2TX6386nJw@mail.gmail.com>
Message-ID: <alpine.LMD.2.00.1305220926510.13922@orpheus.qimr.edu.au>

On Tue, 21 May 2013, Raphael Royaute wrote in response to Thomas Merkling:

> For alternatives to Bayesian approaches with multivariate MM, I only know
> of ASReml, which you can install for free on windows OS.

Aside from ASReml, there are a few free R and non-R programs that can be 
used to fit a multi-trait mixed model (I reckon it is always nice to get 
two different packages to give the same answer :)). These include:

Sabre (http://sabre.lancs.ac.uk/) and
RSabre (http://sabre.lancs.ac.uk/sabreRuse_intro.html)

Wombat (http://didgeridoo.une.edu.au/km/wombat.php)

MatVec (perhaps http://statistics.unl.edu/faculty/steve/software/matvec/)

DMU (http://www.dmu.agrsci.dk/)

Mendel (http://www.genetics.ucla.edu/software/mendel)

The last four are genetics packages, but they will happily run this 
problem.

| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v


From henrik.singmann at psychologie.uni-freiburg.de  Wed May 22 11:56:55 2013
From: henrik.singmann at psychologie.uni-freiburg.de (Henrik Singmann)
Date: Wed, 22 May 2013 11:56:55 +0200
Subject: [R-sig-ME] categorical random effects correlation in lme4
In-Reply-To: <CANgPp9=db6FY5ZxWVCF+x_DziktHrYTkvFjCvuwELtmeyHvoLQ@mail.gmail.com>
References: <CANgPp9=db6FY5ZxWVCF+x_DziktHrYTkvFjCvuwELtmeyHvoLQ@mail.gmail.com>
Message-ID: <519C9667.6030205@psychologie.uni-freiburg.de>

Hi Andrew,

I think one of the problems is that in your model fm1_ml does not what you want. In this model you only estimate the random slopes but *not* the random intercepts for the prmiary_ther. As the lme4 faq (http://glmm.wikidot.com/faq) explains:

(0+x|group): 	random slope of x within group: no variation in intercept

What you want is one of the following:

(x|group): 	random slope of x within group with correlated intercept
(1|group) + (0+x|group): 	uncorrelated random intercept and random slope within group


I hope this helps,
Henrik


Am 21/05/2013 17:41, schrieb Andrew McAleavey:
> Hi,
>
> I'm currently investigating a question of relative effectiveness of
> therapists, and the particular question is whether some therapists are
> differentially effective with white versus racial/ethnic minority clients
> (this is coded as a binary variable called "white" in this data). We have
> conceptualized this as a cross-level random effect, so the model has one
> random effect for therapist intercept and one effect for the difference in
> effectiveness between their white and nonwhite clients.
>
> I am relatively new to lme4, but I think I have specified the model
> correctly (the fixed effects represent client pretreatment severity and the
> nonsignificant fixed effect of binary race; they don't seem to impact the
> estimation problem). Here's the model of interest:
>> print(fm1_ml <- lmer(DI ~ first_di + white + (0 +
> factor(white)|primary_ther), rem3post, REML=F), corr=F)
>
> The problem is that the two random effects are appearing to correlate at r
> = 1.000. I think this is an estimation problem, and probably indicates that
> the random variables aren't accounting for all that much variance. I'm
> dubious of interpreting this model, therefore. However, when comparing it
> to the random intercepts only model using the LRT, there is a significant
> difference, suggesting that even though the explained variance is (very)
> small, it may be worth including:
>> anova(fm1_a_ml, fm1_ml)
> Data: rem3post
> Models:
> fm1_a_ml: DI ~ first_di + factor(white) + (1 | primary_ther)
> fm1_ml: DI ~ first_di + factor(white) + (0 + factor(white) | primary_ther)
>                  Df    AIC      BIC      logLik     Chisq    Chi Df
> Pr(>Chisq)
> fm1_a_ml   5    4982.7  5011.3  -2486.3
> fm1_ml      7    4979.9   5019.9  -2482.9  6.7871      2        0.03359 *
>
> My question is basically this: How should I interpret these results? There
> are significant differences between therapists in terms of their relative
> effectiveness with white vs. nonwhite clients, but they're just small? Or
> is even this not justified? Would it be safer to say that there are likely
> no estimable differences? Am I missing something else?
>
> Thanks a lot,
> Andrew McAleavey
>
> Here's the model of interest output:
>> print(fm1_ml <- lmer(DI ~ first_di + factor(white) + (0 +
> factor(white)|primary_ther), rem3post, REML=F), corr=F)
> Linear mixed model fit by maximum likelihood
> Formula: DI ~ first_di + factor(white) + (0 + factor(white) | primary_ther)
>     Data: rem3post
>    AIC  BIC logLik deviance REMLdev
>   4980 5020  -2483     4966    4983
> Random effects:
>   Groups       Name              Variance        Std.Dev.   Corr
>   primary_ther factor(white)    0 0.0417050  0.204218
>                   factor(white)1     0.0044086     0.066397   1.000
>   Residual                            0.5099596     0.714115
> Number of obs: 2263, groups: primary_ther, 192
>
> Fixed effects:
>                       Estimate Std. Error t value
> (Intercept)        0.45138    0.06007   7.514
> first_di             0.48009    0.02360   20.338
> factor(white)1   0.01140    0.03298   0.346
>

-- 
Dipl. Psych. Henrik Singmann
PhD Student
Albert-Ludwigs-Universit?t Freiburg, Germany
http://www.psychologie.uni-freiburg.de/Members/singmann


From Julia.Sommerfeld at utas.edu.au  Wed May 22 14:58:44 2013
From: Julia.Sommerfeld at utas.edu.au (Julia Sommerfeld)
Date: Wed, 22 May 2013 14:58:44 +0200
Subject: [R-sig-ME] previous posts about error message in glmmADMB
In-Reply-To: <519BA9D2.4000101@gmail.com>
References: <CAOCHjhTc38==KKBeWVAfqJoNytSd+Q_P84dHwpq5wfDFkhdKkA@mail.gmail.com>
	<519BA9D2.4000101@gmail.com>
Message-ID: <CAOCHjhQDn=QDo62AVX=DpsMmOGQsE=GE8MnM3Z8mLJuXmz97TA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130522/37071509/attachment.pl>

From aam239 at psu.edu  Wed May 22 20:22:15 2013
From: aam239 at psu.edu (Andrew McAleavey)
Date: Wed, 22 May 2013 14:22:15 -0400
Subject: [R-sig-ME] categorical random effects correlation in lme4
In-Reply-To: <CAAH-yP-B9YonPMkzYaB0XpDyX8--MYQTa17=g+m0zKb1QHh43A@mail.gmail.com>
References: <CAAH-yP-B9YonPMkzYaB0XpDyX8--MYQTa17=g+m0zKb1QHh43A@mail.gmail.com>
Message-ID: <CANgPp9k_UpmdRB8erbtCtvV_eAJ2UiXcZEwqAFLomKKXzAZwFA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130522/7656932c/attachment.pl>

From helios.derosario at ibv.upv.es  Wed May 22 23:10:41 2013
From: helios.derosario at ibv.upv.es (Helios de Rosario)
Date: Wed, 22 May 2013 23:10:41 +0200
Subject: [R-sig-ME] "contrasts apply only to factors" in post-hoc analysis
 afer lmer fitting
Message-ID: <519D50710200000C00015C97@mailhost.biomec.upv.es>

Hello, sorry to catch up this message so long after the original post.

> 
> Hi everyone,
> 
> I am applying  generalized linear mixed model to RNA-seq data under
> quasi-poisson distribution. Here is the an example:
>
> > ts.da
>    value tp tpf  treat cellline obs_effect
> 1     73  6  T6   ETOH        A          1
> 2     54  6  T6   ETOH        B          2
> 3     62 12 T12   ETOH        A          3
> 4     54 12 T12   ETOH        B          4
> 5     54 24 T24   ETOH        A          5
> 6     56 24 T24   ETOH        B          6
> 7     31 48 T48   ETOH        A          7
> 8     82 48 T48   ETOH        B          8
> 9     72  6  T6 shMYCN        C          9
> 10    95  6  T6 shMYCN        D         10
> 11    64 12 T12 shMYCN        C         11
> 12    90 12 T12 shMYCN        D         12
> 13    51 24 T24 shMYCN        C         13
> 14    64 24 T24 shMYCN        D         14
> 15    46 48 T48 shMYCN        C         15
> 16    63 48 T48 shMYCN        D         16
>

[snip]

> The specified model worked fine:
> possionmix.full <- lmer(value ~ tpf * treat + (1|cellline)
+(1|obs_effect)
> ,data=ts.da, family=poisson)
>

 [snip]
 
> Then I tried to to post-hoc analysis with "phia":
> > testInteractions(possionmix.full)
> Error in `contrasts<-`(`*tmp*`, value = "contr.treatment") : contrasts
> apply only to factors
> 
> I am pretty sure that tpf and treat are factors:
> 
> > ts.da$tpf
>  [1] T6  T6  T12 T12 T24 T24 T48 T48 T6  T6  T12 T12 T24 T24 T48 T48
> Levels: T6 T12 T24 T48
> 
> > ts.da$treat
>  [1] ETOH   ETOH   ETOH   ETOH   ETOH   ETOH   ETOH   ETOH   shMYCN
shMYCN
> [11] shMYCN shMYCN shMYCN shMYCN shMYCN shMYCN
> Levels: ETOH shMYCN
> 

Yes, that's an unfortunate bug in testFactors(), that caused that
problem under some
circumstances for mixed models. I have solved it, and will be fixed in
the next release of phia soon.

Best regards
Helios De Rosario

INSTITUTO DE BIOMEC?NICA DE VALENCIA
Universidad Polit?cnica de Valencia ? Edificio 9C
Camino de Vera s/n ? 46022 VALENCIA (ESPA?A)
Tel. +34 96 387 91 60 ? Fax +34 96 387 91 69
www.ibv.org

  Antes de imprimir este e-mail piense bien si es necesario hacerlo.
En cumplimiento de la Ley Org?nica 15/1999 reguladora de la Protecci?n
de Datos de Car?cter Personal, le informamos de que el presente mensaje
contiene informaci?n confidencial, siendo para uso exclusivo del
destinatario arriba indicado. En caso de no ser usted el destinatario
del mismo le informamos que su recepci?n no le autoriza a su divulgaci?n
o reproducci?n por cualquier medio, debiendo destruirlo de inmediato,
rog?ndole lo notifique al remitente.


From M.Fairbrother at bristol.ac.uk  Thu May 23 09:21:46 2013
From: M.Fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Thu, 23 May 2013 08:21:46 +0100
Subject: [R-sig-ME] categorical random effects correlation in lme4
In-Reply-To: <CANgPp9k_UpmdRB8erbtCtvV_eAJ2UiXcZEwqAFLomKKXzAZwFA@mail.gmail.com>
References: <CAAH-yP-B9YonPMkzYaB0XpDyX8--MYQTa17=g+m0zKb1QHh43A@mail.gmail.com>
	<CANgPp9k_UpmdRB8erbtCtvV_eAJ2UiXcZEwqAFLomKKXzAZwFA@mail.gmail.com>
Message-ID: <CAAH-yP_iNfR89itF29eTioOhouZqmdoyhc-sGaOOn=aXO3hmmw@mail.gmail.com>

Hmm, sorry, I'm not sure in that case. Others on this list may be able
to give you better advice, but my guess is that you don't have enough
information in the data (as you originally suggested). Do you have a
mix of white and nonwhite clients for each therapist? Are the numbers
of clients per therapist very unbalanced?

- Malcolm



On 22 May 2013 19:22, Andrew McAleavey <aam239 at psu.edu> wrote:
> Hi Malcolm & Henrik & all,
>
> Thanks for the help! I've tried some of these before, but tried even more
> now. I think I'm unfortunately still stuck on this, and I think a part of
> the reason is that dropping the random intercepts seems weird but I think it
> is necessary and helpful with a categorical fixed/random interaction.
>
> I know that removing the random intercept seems weird, but my understanding
> is that eliminating the intercept when modeling a categorical random slope
> helps interpretation, but doesn't change the model substantively. The
> variance of the random slope parameter for "white" changes and the
> correlation flips to -1.000 when you add in the intercept, but the model is
> actually equivalent. That is, without the intercept in the model, the random
> white=0 effect actually is the random intercept for therapists. See model
> fit below.
>
> As I understand it, by removing the intercept when using a categorical
> random/fixed interaction effect, you get a more interpretable value, namely
> variance in the differences between the reference group and the target group
> attributable to therapists. I believe that the variance shown when the
> intercept is included is too large, since it actually describes all variance
> associated with the categorical variable as deviations from an "average"
> client who doesn't exist.
>
> When estimating the model suggested by Henrik [(1|primary_ther) +
> (0+white|primary_ther)], two things seem odd to me. First, the intercept is
> forced to be uncorrelated with the slopes - this is not theoretically
> necessary. The other is that there are three random effects being estimated
> now, which is too many (with a two level categorical effect, only one
> parameter is necessary). Unless I'm wrong about something else, I don't
> think I can treat this the way I would a continuous variable. I think this
> is redundant and See below again.
>
> So I suppose I'm still stuck with the original question, since I don't think
> these solutions hold with a categorical effect. Am I just missing something
> else, or maybe the suggestions ought to hold for categorical effects and
> it's something else causing difficulties?
>
> Thanks a lot,
> Andrew
>
> Here's the model adding back in the random intercepts but including the
> white random effect:
>> print(fm1_ml_int <- lmer(DI ~ first_di + factor(white) +
>> (factor(white)|primary_ther), rem3post, REML=F), corr=F)
> Linear mixed model fit by maximum likelihood
> Formula: DI ~ first_di + factor(white) + (factor(white) | primary_ther)
>    Data: rem3post
>   AIC  BIC logLik deviance REMLdev
>  4980 5020  -2483     4966    4983
> Random effects:
>  Groups       Name           Variance Std.Dev. Corr
>  primary_ther (Intercept)    0.041708 0.20423
>               factor(white)1     0.018995 0.13782  -1.000
>  Residual                         0.509959 0.71411
> Number of obs: 2263, groups: primary_ther, 192
>
> Fixed effects:
>                Estimate Std. Error t value
> (Intercept)       0.45138    0.06007   7.514
> first_di            0.48009    0.02360  20.338
> factor(white)1  0.01140    0.03298   0.346
>
> Here's the difference test of interest, they appear to be equivalent models:
>> anova(fm1_ml, fm1_ml_int)
> Data: rem3post
> Models:
> fm1_ml: DI ~ first_di + factor(white) + (0 + factor(white) | primary_ther)
> fm1_ml_int: DI ~ first_di + factor(white) + (factor(white) | primary_ther)
>                  Df    AIC    BIC  logLik Chisq Chi Df Pr(>Chisq)
> fm1_ml       7 4979.9 5019.9 -2482.9
> fm1_ml_int  7 4979.9 5019.9 -2482.9     0      0          1
>
> And here's a version of the model with uncorrelated intercept and slopes
> (the bigger model has a singular convergence, as anticipated in these
> slides:http://lme4.r-forge.r-project.org/slides/2011-03-16-Amsterdam/2Longitudinal.pdf):
> Formula: DI ~ 1 + (1 | primary_ther) + (0 + factor(white) | primary_ther)
>    Data: rem3post_2
>   AIC  BIC logLik deviance REMLdev
>  5027 5062  -2508     5015    5022
> Random effects:
>  Groups       Name           Variance          Std.Dev.     Corr
>  primary_ther (Intercept)       1.7240e-06  0.001313
>  primary_ther factor(white)0  4.6543e-02  0.215738
>                     factor(white)1  6.9851e-03  0.083577   0.752
>  Residual                            5.1870e-01  0.720212
> Number of obs: 2263, groups: primary_ther, 192
>
> Fixed effects:
>             Estimate Std. Error t value
> (Intercept)  1.48466    0.01791   82.91
>
>
> On Tue, May 21, 2013 at 1:30 PM, Malcolm Fairbrother
> <M.Fairbrother at bristol.ac.uk> wrote:
>>
>> Dear Andrew,
>>
>> What if you drop the "0 +" bit? So:
>>
>>  lmer(DI ~ first_di + factor(white) + (factor(white) | primary_ther),
>> rem3post, REML=F)
>>
>> or
>>
>>  lmer(DI ~ first_di + white + (white | primary_ther), rem3post, REML=F)
>>
>> Including "0 +" means you're not estimating a random intercept for
>> "primary_ther", which it sounds like you need/want. Instead, you're
>> getting two random slopes, which I guess are perfectly correlated
>> because they're two sides of the same coin (the coin being your binary
>> dummy variable "white").
>>
>> If that doesn't solve the problem, it might help for you to post the
>> results of "str(rem3post)" (i.e., your dataset) as well.
>>
>> Cheers,
>> Malcolm
>>
>>
>>
>>
>> > Date: Tue, 21 May 2013 11:41:04 -0400
>> > From: Andrew McAleavey <andrew.mcaleavey at gmail.com>
>> > To: r-sig-mixed-models at r-project.org
>> > Subject: [R-sig-ME] categorical random effects correlation in lme4
>> >
>> > Hi,
>> >
>> > I'm currently investigating a question of relative effectiveness of
>> > therapists, and the particular question is whether some therapists are
>> > differentially effective with white versus racial/ethnic minority
>> > clients
>> > (this is coded as a binary variable called "white" in this data). We
>> > have
>> > conceptualized this as a cross-level random effect, so the model has one
>> > random effect for therapist intercept and one effect for the difference
>> > in
>> > effectiveness between their white and nonwhite clients.
>> >
>> > I am relatively new to lme4, but I think I have specified the model
>> > correctly (the fixed effects represent client pretreatment severity and
>> > the
>> > nonsignificant fixed effect of binary race; they don't seem to impact
>> > the
>> > estimation problem). Here's the model of interest:
>> >>print(fm1_ml <- lmer(DI ~ first_di + white + (0 +
>> > factor(white)|primary_ther), rem3post, REML=F), corr=F)
>> >
>> > The problem is that the two random effects are appearing to correlate at
>> > r
>> > = 1.000. I think this is an estimation problem, and probably indicates
>> > that
>> > the random variables aren't accounting for all that much variance. I'm
>> > dubious of interpreting this model, therefore. However, when comparing
>> > it
>> > to the random intercepts only model using the LRT, there is a
>> > significant
>> > difference, suggesting that even though the explained variance is (very)
>> > small, it may be worth including:
>> >> anova(fm1_a_ml, fm1_ml)
>> > Data: rem3post
>> > Models:
>> > fm1_a_ml: DI ~ first_di + factor(white) + (1 | primary_ther)
>> > fm1_ml: DI ~ first_di + factor(white) + (0 + factor(white) |
>> > primary_ther)
>> >                 Df    AIC      BIC      logLik     Chisq    Chi Df
>> > Pr(>Chisq)
>> > fm1_a_ml   5    4982.7  5011.3  -2486.3
>> > fm1_ml      7    4979.9   5019.9  -2482.9  6.7871      2        0.03359
>> > *
>> >
>> > My question is basically this: How should I interpret these results?
>> > There
>> > are significant differences between therapists in terms of their
>> > relative
>> > effectiveness with white vs. nonwhite clients, but they're just small?
>> > Or
>> > is even this not justified? Would it be safer to say that there are
>> > likely
>> > no estimable differences? Am I missing something else?
>> >
>> > Thanks a lot,
>> > Andrew McAleavey
>> >
>> > Here's the model of interest output:
>> >> print(fm1_ml <- lmer(DI ~ first_di + factor(white) + (0 +
>> > factor(white)|primary_ther), rem3post, REML=F), corr=F)
>> > Linear mixed model fit by maximum likelihood
>> > Formula: DI ~ first_di + factor(white) + (0 + factor(white) |
>> > primary_ther)
>> >    Data: rem3post
>> >   AIC  BIC logLik deviance REMLdev
>> >  4980 5020  -2483     4966    4983
>> > Random effects:
>> >  Groups       Name              Variance        Std.Dev.   Corr
>> >  primary_ther factor(white)    0 0.0417050  0.204218
>> >                  factor(white)1     0.0044086     0.066397   1.000
>> >  Residual                            0.5099596     0.714115
>> > Number of obs: 2263, groups: primary_ther, 192
>> >
>> > Fixed effects:
>> >                      Estimate Std. Error t value
>> > (Intercept)        0.45138    0.06007   7.514
>> > first_di             0.48009    0.02360   20.338
>> > factor(white)1   0.01140    0.03298   0.346
>> >
>> > --
>> > Andrew McAleavey, M.S.
>> > Department of Psychology
>> > The Pennsylvania State University
>> > 346 Moore Building
>> > University Park, PA 16802
>> > aam239 at psu.edu
>
>
>
>
> --
> Andrew McAleavey, M.S.
> Department of Psychology
> The Pennsylvania State University
> 346 Moore Building
> University Park, PA 16802
> aam239 at psu.edu


From rfaustinol at gmail.com  Thu May 23 15:43:09 2013
From: rfaustinol at gmail.com (Ricardo Lima)
Date: Thu, 23 May 2013 14:43:09 +0100
Subject: [R-sig-ME] zero-inflated models with spatial autocorrelation
Message-ID: <CADDBpO2=FsXNz3r-fYYgqK_xb8uF1oDyDPpV1D1ziwkT4KKqEA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130523/17ba8fd9/attachment.pl>

From aam239 at psu.edu  Thu May 23 14:14:19 2013
From: aam239 at psu.edu (Andrew McAleavey)
Date: Thu, 23 May 2013 08:14:19 -0400
Subject: [R-sig-ME] categorical random effects correlation in lme4
In-Reply-To: <CAAH-yP_iNfR89itF29eTioOhouZqmdoyhc-sGaOOn=aXO3hmmw@mail.gmail.com>
References: <CAAH-yP-B9YonPMkzYaB0XpDyX8--MYQTa17=g+m0zKb1QHh43A@mail.gmail.com>
	<CANgPp9k_UpmdRB8erbtCtvV_eAJ2UiXcZEwqAFLomKKXzAZwFA@mail.gmail.com>
	<CAAH-yP_iNfR89itF29eTioOhouZqmdoyhc-sGaOOn=aXO3hmmw@mail.gmail.com>
Message-ID: <CANgPp9nxzBOQqJ7M5wFSJKq4SCt5RxC5C7-SCmNv4U+bK7fN5A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130523/3c363b58/attachment.pl>

From bbolker at gmail.com  Thu May 23 17:44:13 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 23 May 2013 15:44:13 +0000 (UTC)
Subject: [R-sig-ME] zero-inflated models with spatial autocorrelation
References: <CADDBpO2=FsXNz3r-fYYgqK_xb8uF1oDyDPpV1D1ziwkT4KKqEA@mail.gmail.com>
Message-ID: <loom.20130523T173802-691@post.gmane.org>

Ricardo Lima <rfaustinol at ...> writes:

> 
> Hi,
> 
> Is there any R package that allows to create zero-inflated models with
> spatial autocorrelation?
> 
> Best regards,
> RICARDO Lima

  Not really, if you mean continuous (geostatistical-style) spatial
autocorrelation. In principle, you can code it yourself in AD Model
Builder, or WinBUGS, or Stan ...

http://www.admb-project.org/examples/spatial-models

  This (and even the simpler case of a 'proper' GLMM with spatial
autocorrelation in a latent observation-level random variable) is
a surprisingly missing component in the available R toolbox, as far
as I know.  INLA _might_ do the simpler (non-ZI) case.  I have thought
about some ways to implement this in the development version of lme4,
but so far it's a gleam in my eye.

  I would also check out

http://www.highstat.com/book4.htm


From henrik.singmann at psychologie.uni-freiburg.de  Thu May 23 23:21:37 2013
From: henrik.singmann at psychologie.uni-freiburg.de (Henrik Singmann)
Date: Thu, 23 May 2013 23:21:37 +0200
Subject: [R-sig-ME] categorical random effects correlation in lme4
In-Reply-To: <CANgPp9k_UpmdRB8erbtCtvV_eAJ2UiXcZEwqAFLomKKXzAZwFA@mail.gmail.com>
References: <CAAH-yP-B9YonPMkzYaB0XpDyX8--MYQTa17=g+m0zKb1QHh43A@mail.gmail.com>
	<CANgPp9k_UpmdRB8erbtCtvV_eAJ2UiXcZEwqAFLomKKXzAZwFA@mail.gmail.com>
Message-ID: <519E8861.4080107@psychologie.uni-freiburg.de>

Hi Andrew,

in Baayen, Davidson, & Bates (2008) they discuss a situation very similar to yours and in which they perform similar steps as you have done (full model has a correlation of slopes of -1, then remove correlation between random slopes, and then remove random slopes altogether) and then decide for the smallest model (only random intercepts) as it provides the best account in terms of a LRT .

In your case it now seems to be the case that the full model and intercept only model are identical (as predicted by slide 38 of the presentation you linked).

So you basically only have the options between:
- a model with (0 + factor(white) | primary_ther) [or equivalently (factor(white) | primary_ther)],
- (1|primary_ther) + (0+white|primary_ther) [as I suggested and which should have less random parameters as the model before, which is done by Baayen et al. (2008), and also recommended by Barr et al. (2013) in case of nonconvergence],
- and the random intercept only model (1 | primary_ther).

What does the LRT [i.e., anova()] now say to these three options?

I hope this helps and I really liked the Barr article (also I would not trust their recommendation on how to obtain p-values but resort on either afex or car::Anova(..., test = "F") which are equivalent).

I hope that helps and sorry if you did also this already,
Henrik

Note: Baayen et al use slightly different syntax.

References:
Baayen, R. H., Davidson, D. J., & Bates, D. M. (2008). Mixed-effects modeling with crossed random effects for subjects and items. Journal of Memory and Language, 59(4), 390?412. doi:10.1016/j.jml.2007.12.005

Barr, D. J., Levy, R., Scheepers, C., & Tily, H. J. (2013). Random effects structure for confirmatory hypothesis testing: Keep it maximal. Journal of Memory and Language, 68(3), 255?278. doi:10.1016/j.jml.2012.11.001



Am 22/05/2013 20:22, schrieb Andrew McAleavey:
> Hi Malcolm & Henrik & all,
>
> Thanks for the help! I've tried some of these before, but tried even more
> now. I think I'm unfortunately still stuck on this, and I think a part of
> the reason is that dropping the random intercepts seems weird but I think
> it is necessary and helpful with a categorical fixed/random interaction.
>
> I know that removing the random intercept seems weird, but my understanding
> is that eliminating the intercept when modeling a categorical random slope
> helps interpretation, but doesn't change the model substantively. The
> variance of the random slope parameter for "white" changes and the
> correlation flips to -1.000 when you add in the intercept, but the model is
> actually equivalent. That is, without the intercept in the model, the
> random white=0 effect actually is the random intercept for therapists. See
> model fit below.
>
> As I understand it, by removing the intercept when using a categorical
> random/fixed interaction effect, you get a more interpretable value, namely
> variance in the differences between the reference group and the target
> group attributable to therapists. I believe that the variance shown when
> the intercept is included is too large, since it actually describes all
> variance associated with the categorical variable as deviations from an
> "average" client who doesn't exist.
>
> When estimating the model suggested by Henrik [(1|primary_ther) +
> (0+white|primary_ther)], two things seem odd to me. First, the intercept is
> forced to be uncorrelated with the slopes - this is not theoretically
> necessary. The other is that there are three random effects being estimated
> now, which is too many (with a two level categorical effect, only one
> parameter is necessary). Unless I'm wrong about something else, I don't
> think I can treat this the way I would a continuous variable. I think this
> is redundant and See below again.
>
> So I suppose I'm still stuck with the original question, since I don't
> think these solutions hold with a categorical effect. Am I just missing
> something else, or maybe the suggestions ought to hold for categorical
> effects and it's something else causing difficulties?
>
> Thanks a lot,
> Andrew
>
> Here's the model adding back in the random intercepts but including the
> white random effect:
>> print(fm1_ml_int <- lmer(DI ~ first_di + factor(white) +
> (factor(white)|primary_ther), rem3post, REML=F), corr=F)
> Linear mixed model fit by maximum likelihood
> Formula: DI ~ first_di + factor(white) + (factor(white) | primary_ther)
>     Data: rem3post
>    AIC  BIC logLik deviance REMLdev
>   4980 5020  -2483     4966    4983
> Random effects:
>   Groups       Name           Variance Std.Dev. Corr
>   primary_ther (Intercept)    0.041708 0.20423
>                factor(white)1     0.018995 0.13782  -1.000
>   Residual                         0.509959 0.71411
> Number of obs: 2263, groups: primary_ther, 192
>
> Fixed effects:
>                 Estimate Std. Error t value
> (Intercept)       0.45138    0.06007   7.514
> first_di            0.48009    0.02360  20.338
> factor(white)1  0.01140    0.03298   0.346
>
> Here's the difference test of interest, they appear to be equivalent models:
>> anova(fm1_ml, fm1_ml_int)
> Data: rem3post
> Models:
> fm1_ml: DI ~ first_di + factor(white) + (0 + factor(white) | primary_ther)
> fm1_ml_int: DI ~ first_di + factor(white) + (factor(white) | primary_ther)
>                   Df    AIC    BIC  logLik Chisq Chi Df Pr(>Chisq)
> fm1_ml       7 4979.9 5019.9 -2482.9
> fm1_ml_int  7 4979.9 5019.9 -2482.9     0      0          1
>
> And here's a version of the model with uncorrelated intercept and slopes
> (the bigger model has a singular convergence, as anticipated in these
> slides:
> http://lme4.r-forge.r-project.org/slides/2011-03-16-Amsterdam/2Longitudinal.pdf
> ):
> Formula: DI ~ 1 + (1 | primary_ther) + (0 + factor(white) | primary_ther)
>     Data: rem3post_2
>    AIC  BIC logLik deviance REMLdev
>   5027 5062  -2508     5015    5022
> Random effects:
>   Groups       Name           Variance          Std.Dev.     Corr
>   primary_ther (Intercept)       1.7240e-06  0.001313
>   primary_ther factor(white)0  4.6543e-02  0.215738
>                      factor(white)1  6.9851e-03  0.083577   0.752
>   Residual                            5.1870e-01  0.720212
> Number of obs: 2263, groups: primary_ther, 192
>
> Fixed effects:
>              Estimate Std. Error t value
> (Intercept)  1.48466    0.01791   82.91
>
>
> On Tue, May 21, 2013 at 1:30 PM, Malcolm Fairbrother <
> M.Fairbrother at bristol.ac.uk> wrote:
>
>> Dear Andrew,
>>
>> What if you drop the "0 +" bit? So:
>>
>>   lmer(DI ~ first_di + factor(white) + (factor(white) | primary_ther),
>> rem3post, REML=F)
>>
>> or
>>
>>   lmer(DI ~ first_di + white + (white | primary_ther), rem3post, REML=F)
>>
>> Including "0 +" means you're not estimating a random intercept for
>> "primary_ther", which it sounds like you need/want. Instead, you're
>> getting two random slopes, which I guess are perfectly correlated
>> because they're two sides of the same coin (the coin being your binary
>> dummy variable "white").
>>
>> If that doesn't solve the problem, it might help for you to post the
>> results of "str(rem3post)" (i.e., your dataset) as well.
>>
>> Cheers,
>> Malcolm
>>
>>
>>
>>
>>> Date: Tue, 21 May 2013 11:41:04 -0400
>>> From: Andrew McAleavey <andrew.mcaleavey at gmail.com>
>>> To: r-sig-mixed-models at r-project.org
>>> Subject: [R-sig-ME] categorical random effects correlation in lme4
>>>
>>> Hi,
>>>
>>> I'm currently investigating a question of relative effectiveness of
>>> therapists, and the particular question is whether some therapists are
>>> differentially effective with white versus racial/ethnic minority clients
>>> (this is coded as a binary variable called "white" in this data). We have
>>> conceptualized this as a cross-level random effect, so the model has one
>>> random effect for therapist intercept and one effect for the difference
>> in
>>> effectiveness between their white and nonwhite clients.
>>>
>>> I am relatively new to lme4, but I think I have specified the model
>>> correctly (the fixed effects represent client pretreatment severity and
>> the
>>> nonsignificant fixed effect of binary race; they don't seem to impact the
>>> estimation problem). Here's the model of interest:
>>>> print(fm1_ml <- lmer(DI ~ first_di + white + (0 +
>>> factor(white)|primary_ther), rem3post, REML=F), corr=F)
>>>
>>> The problem is that the two random effects are appearing to correlate at
>> r
>>> = 1.000. I think this is an estimation problem, and probably indicates
>> that
>>> the random variables aren't accounting for all that much variance. I'm
>>> dubious of interpreting this model, therefore. However, when comparing it
>>> to the random intercepts only model using the LRT, there is a significant
>>> difference, suggesting that even though the explained variance is (very)
>>> small, it may be worth including:
>>>> anova(fm1_a_ml, fm1_ml)
>>> Data: rem3post
>>> Models:
>>> fm1_a_ml: DI ~ first_di + factor(white) + (1 | primary_ther)
>>> fm1_ml: DI ~ first_di + factor(white) + (0 + factor(white) |
>> primary_ther)
>>>                  Df    AIC      BIC      logLik     Chisq    Chi Df
>>> Pr(>Chisq)
>>> fm1_a_ml   5    4982.7  5011.3  -2486.3
>>> fm1_ml      7    4979.9   5019.9  -2482.9  6.7871      2        0.03359 *
>>>
>>> My question is basically this: How should I interpret these results?
>> There
>>> are significant differences between therapists in terms of their relative
>>> effectiveness with white vs. nonwhite clients, but they're just small? Or
>>> is even this not justified? Would it be safer to say that there are
>> likely
>>> no estimable differences? Am I missing something else?
>>>
>>> Thanks a lot,
>>> Andrew McAleavey
>>>
>>> Here's the model of interest output:
>>>> print(fm1_ml <- lmer(DI ~ first_di + factor(white) + (0 +
>>> factor(white)|primary_ther), rem3post, REML=F), corr=F)
>>> Linear mixed model fit by maximum likelihood
>>> Formula: DI ~ first_di + factor(white) + (0 + factor(white) |
>> primary_ther)
>>>     Data: rem3post
>>>    AIC  BIC logLik deviance REMLdev
>>>   4980 5020  -2483     4966    4983
>>> Random effects:
>>>   Groups       Name              Variance        Std.Dev.   Corr
>>>   primary_ther factor(white)    0 0.0417050  0.204218
>>>                   factor(white)1     0.0044086     0.066397   1.000
>>>   Residual                            0.5099596     0.714115
>>> Number of obs: 2263, groups: primary_ther, 192
>>>
>>> Fixed effects:
>>>                       Estimate Std. Error t value
>>> (Intercept)        0.45138    0.06007   7.514
>>> first_di             0.48009    0.02360   20.338
>>> factor(white)1   0.01140    0.03298   0.346
>>>
>>> --
>>> Andrew McAleavey, M.S.
>>> Department of Psychology
>>> The Pennsylvania State University
>>> 346 Moore Building
>>> University Park, PA 16802
>>> aam239 at psu.edu
>>
>
>
>

-- 
Dipl. Psych. Henrik Singmann
PhD Student
Albert-Ludwigs-Universit?t Freiburg, Germany
http://www.psychologie.uni-freiburg.de/Members/singmann


From henrik.singmann at psychologie.uni-freiburg.de  Thu May 23 23:22:46 2013
From: henrik.singmann at psychologie.uni-freiburg.de (Henrik Singmann)
Date: Thu, 23 May 2013 23:22:46 +0200
Subject: [R-sig-ME] categorical random effects correlation in lme4
In-Reply-To: <CANgPp9k_UpmdRB8erbtCtvV_eAJ2UiXcZEwqAFLomKKXzAZwFA@mail.gmail.com>
References: <CAAH-yP-B9YonPMkzYaB0XpDyX8--MYQTa17=g+m0zKb1QHh43A@mail.gmail.com>
	<CANgPp9k_UpmdRB8erbtCtvV_eAJ2UiXcZEwqAFLomKKXzAZwFA@mail.gmail.com>
Message-ID: <519E88A6.30209@psychologie.uni-freiburg.de>

Hi Andrew,

in Baayen, Davidson, & Bates (2008) they discuss a situation very similar to yours and in which they perform similar steps as you have done (full model has a correlation of slopes of -1, then remove correlation between random slopes, and then remove random slopes altogether) and then decide for the smallest model (only random intercepts) as it provides the best account in terms of a LRT .

In your case it now seems to be the case that the full model and intercept only model are identical (as predicted by slide 38 of the presentation you linked).

So you basically only have the options between:
- a model with (0 + factor(white) | primary_ther) [or equivalently (factor(white) | primary_ther)],
- (1|primary_ther) + (0+white|primary_ther) [as I suggested and which should have less random parameters as the model before, which is done by Baayen et al. (2008), and also recommended by Barr et al. (2013) in case of nonconvergence],
- and the random intercept only model (1 | primary_ther).

What does the LRT [i.e., anova()] now say to these three options?

I hope this helps and I really liked the Barr article (also I would not trust their recommendation on how to obtain p-values but resort on either afex or car::Anova(..., test = "F") which are equivalent).

I hope that helps and sorry if you did also this already,
Henrik

Note: Baayen et al use slightly different syntax.

References:
Baayen, R. H., Davidson, D. J., & Bates, D. M. (2008). Mixed-effects modeling with crossed random effects for subjects and items. Journal of Memory and Language, 59(4), 390?412. doi:10.1016/j.jml.2007.12.005

Barr, D. J., Levy, R., Scheepers, C., & Tily, H. J. (2013). Random effects structure for confirmatory hypothesis testing: Keep it maximal. Journal of Memory and Language, 68(3), 255?278. doi:10.1016/j.jml.2012.11.001


Am 22/05/2013 20:22, schrieb Andrew McAleavey:
> Hi Malcolm & Henrik & all,
>
> Thanks for the help! I've tried some of these before, but tried even more
> now. I think I'm unfortunately still stuck on this, and I think a part of
> the reason is that dropping the random intercepts seems weird but I think
> it is necessary and helpful with a categorical fixed/random interaction.
>
> I know that removing the random intercept seems weird, but my understanding
> is that eliminating the intercept when modeling a categorical random slope
> helps interpretation, but doesn't change the model substantively. The
> variance of the random slope parameter for "white" changes and the
> correlation flips to -1.000 when you add in the intercept, but the model is
> actually equivalent. That is, without the intercept in the model, the
> random white=0 effect actually is the random intercept for therapists. See
> model fit below.
>
> As I understand it, by removing the intercept when using a categorical
> random/fixed interaction effect, you get a more interpretable value, namely
> variance in the differences between the reference group and the target
> group attributable to therapists. I believe that the variance shown when
> the intercept is included is too large, since it actually describes all
> variance associated with the categorical variable as deviations from an
> "average" client who doesn't exist.
>
> When estimating the model suggested by Henrik [(1|primary_ther) +
> (0+white|primary_ther)], two things seem odd to me. First, the intercept is
> forced to be uncorrelated with the slopes - this is not theoretically
> necessary. The other is that there are three random effects being estimated
> now, which is too many (with a two level categorical effect, only one
> parameter is necessary). Unless I'm wrong about something else, I don't
> think I can treat this the way I would a continuous variable. I think this
> is redundant and See below again.
>
> So I suppose I'm still stuck with the original question, since I don't
> think these solutions hold with a categorical effect. Am I just missing
> something else, or maybe the suggestions ought to hold for categorical
> effects and it's something else causing difficulties?
>
> Thanks a lot,
> Andrew
>
> Here's the model adding back in the random intercepts but including the
> white random effect:
>> print(fm1_ml_int <- lmer(DI ~ first_di + factor(white) +
> (factor(white)|primary_ther), rem3post, REML=F), corr=F)
> Linear mixed model fit by maximum likelihood
> Formula: DI ~ first_di + factor(white) + (factor(white) | primary_ther)
>     Data: rem3post
>    AIC  BIC logLik deviance REMLdev
>   4980 5020  -2483     4966    4983
> Random effects:
>   Groups       Name           Variance Std.Dev. Corr
>   primary_ther (Intercept)    0.041708 0.20423
>                factor(white)1     0.018995 0.13782  -1.000
>   Residual                         0.509959 0.71411
> Number of obs: 2263, groups: primary_ther, 192
>
> Fixed effects:
>                 Estimate Std. Error t value
> (Intercept)       0.45138    0.06007   7.514
> first_di            0.48009    0.02360  20.338
> factor(white)1  0.01140    0.03298   0.346
>
> Here's the difference test of interest, they appear to be equivalent models:
>> anova(fm1_ml, fm1_ml_int)
> Data: rem3post
> Models:
> fm1_ml: DI ~ first_di + factor(white) + (0 + factor(white) | primary_ther)
> fm1_ml_int: DI ~ first_di + factor(white) + (factor(white) | primary_ther)
>                   Df    AIC    BIC  logLik Chisq Chi Df Pr(>Chisq)
> fm1_ml       7 4979.9 5019.9 -2482.9
> fm1_ml_int  7 4979.9 5019.9 -2482.9     0      0          1
>
> And here's a version of the model with uncorrelated intercept and slopes
> (the bigger model has a singular convergence, as anticipated in these
> slides:
> http://lme4.r-forge.r-project.org/slides/2011-03-16-Amsterdam/2Longitudinal.pdf
> ):
> Formula: DI ~ 1 + (1 | primary_ther) + (0 + factor(white) | primary_ther)
>     Data: rem3post_2
>    AIC  BIC logLik deviance REMLdev
>   5027 5062  -2508     5015    5022
> Random effects:
>   Groups       Name           Variance          Std.Dev.     Corr
>   primary_ther (Intercept)       1.7240e-06  0.001313
>   primary_ther factor(white)0  4.6543e-02  0.215738
>                      factor(white)1  6.9851e-03  0.083577   0.752
>   Residual                            5.1870e-01  0.720212
> Number of obs: 2263, groups: primary_ther, 192
>
> Fixed effects:
>              Estimate Std. Error t value
> (Intercept)  1.48466    0.01791   82.91
>
>
> On Tue, May 21, 2013 at 1:30 PM, Malcolm Fairbrother <
> M.Fairbrother at bristol.ac.uk> wrote:
>
>> Dear Andrew,
>>
>> What if you drop the "0 +" bit? So:
>>
>>   lmer(DI ~ first_di + factor(white) + (factor(white) | primary_ther),
>> rem3post, REML=F)
>>
>> or
>>
>>   lmer(DI ~ first_di + white + (white | primary_ther), rem3post, REML=F)
>>
>> Including "0 +" means you're not estimating a random intercept for
>> "primary_ther", which it sounds like you need/want. Instead, you're
>> getting two random slopes, which I guess are perfectly correlated
>> because they're two sides of the same coin (the coin being your binary
>> dummy variable "white").
>>
>> If that doesn't solve the problem, it might help for you to post the
>> results of "str(rem3post)" (i.e., your dataset) as well.
>>
>> Cheers,
>> Malcolm
>>
>>
>>
>>
>>> Date: Tue, 21 May 2013 11:41:04 -0400
>>> From: Andrew McAleavey <andrew.mcaleavey at gmail.com>
>>> To: r-sig-mixed-models at r-project.org
>>> Subject: [R-sig-ME] categorical random effects correlation in lme4
>>>
>>> Hi,
>>>
>>> I'm currently investigating a question of relative effectiveness of
>>> therapists, and the particular question is whether some therapists are
>>> differentially effective with white versus racial/ethnic minority clients
>>> (this is coded as a binary variable called "white" in this data). We have
>>> conceptualized this as a cross-level random effect, so the model has one
>>> random effect for therapist intercept and one effect for the difference
>> in
>>> effectiveness between their white and nonwhite clients.
>>>
>>> I am relatively new to lme4, but I think I have specified the model
>>> correctly (the fixed effects represent client pretreatment severity and
>> the
>>> nonsignificant fixed effect of binary race; they don't seem to impact the
>>> estimation problem). Here's the model of interest:
>>>> print(fm1_ml <- lmer(DI ~ first_di + white + (0 +
>>> factor(white)|primary_ther), rem3post, REML=F), corr=F)
>>>
>>> The problem is that the two random effects are appearing to correlate at
>> r
>>> = 1.000. I think this is an estimation problem, and probably indicates
>> that
>>> the random variables aren't accounting for all that much variance. I'm
>>> dubious of interpreting this model, therefore. However, when comparing it
>>> to the random intercepts only model using the LRT, there is a significant
>>> difference, suggesting that even though the explained variance is (very)
>>> small, it may be worth including:
>>>> anova(fm1_a_ml, fm1_ml)
>>> Data: rem3post
>>> Models:
>>> fm1_a_ml: DI ~ first_di + factor(white) + (1 | primary_ther)
>>> fm1_ml: DI ~ first_di + factor(white) + (0 + factor(white) |
>> primary_ther)
>>>                  Df    AIC      BIC      logLik     Chisq    Chi Df
>>> Pr(>Chisq)
>>> fm1_a_ml   5    4982.7  5011.3  -2486.3
>>> fm1_ml      7    4979.9   5019.9  -2482.9  6.7871      2        0.03359 *
>>>
>>> My question is basically this: How should I interpret these results?
>> There
>>> are significant differences between therapists in terms of their relative
>>> effectiveness with white vs. nonwhite clients, but they're just small? Or
>>> is even this not justified? Would it be safer to say that there are
>> likely
>>> no estimable differences? Am I missing something else?
>>>
>>> Thanks a lot,
>>> Andrew McAleavey
>>>
>>> Here's the model of interest output:
>>>> print(fm1_ml <- lmer(DI ~ first_di + factor(white) + (0 +
>>> factor(white)|primary_ther), rem3post, REML=F), corr=F)
>>> Linear mixed model fit by maximum likelihood
>>> Formula: DI ~ first_di + factor(white) + (0 + factor(white) |
>> primary_ther)
>>>     Data: rem3post
>>>    AIC  BIC logLik deviance REMLdev
>>>   4980 5020  -2483     4966    4983
>>> Random effects:
>>>   Groups       Name              Variance        Std.Dev.   Corr
>>>   primary_ther factor(white)    0 0.0417050  0.204218
>>>                   factor(white)1     0.0044086     0.066397   1.000
>>>   Residual                            0.5099596     0.714115
>>> Number of obs: 2263, groups: primary_ther, 192
>>>
>>> Fixed effects:
>>>                       Estimate Std. Error t value
>>> (Intercept)        0.45138    0.06007   7.514
>>> first_di             0.48009    0.02360   20.338
>>> factor(white)1   0.01140    0.03298   0.346
>>>
>>> --
>>> Andrew McAleavey, M.S.
>>> Department of Psychology
>>> The Pennsylvania State University
>>> 346 Moore Building
>>> University Park, PA 16802
>>> aam239 at psu.edu
>>
>
>
>

-- 
Dipl. Psych. Henrik Singmann
PhD Student
Albert-Ludwigs-Universit?t Freiburg, Germany
http://www.psychologie.uni-freiburg.de/Members/singmann


From rfaustinol at gmail.com  Fri May 24 10:31:25 2013
From: rfaustinol at gmail.com (Ricardo Lima)
Date: Fri, 24 May 2013 09:31:25 +0100
Subject: [R-sig-ME] zero-inflated models with spatial autocorrelation
In-Reply-To: <loom.20130523T173802-691@post.gmane.org>
References: <CADDBpO2=FsXNz3r-fYYgqK_xb8uF1oDyDPpV1D1ziwkT4KKqEA@mail.gmail.com>
	<loom.20130523T173802-691@post.gmane.org>
Message-ID: <CADDBpO0kib_ccYbvL=59-ODcYjRDkhvqNqKSPoJZ2pfLHAJJqQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130524/d8fc327c/attachment.pl>

From bagchi.r at gmail.com  Fri May 24 10:44:04 2013
From: bagchi.r at gmail.com (robert bagchi)
Date: Fri, 24 May 2013 10:44:04 +0200
Subject: [R-sig-ME] Subject: Re: zero-inflated models with spatial
	autocorrelation
Message-ID: <CAFJ9WUA017mgGhfUfsEaDnwU=R2F7MHdRSPLtOH-vNWOd+NixQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130524/048a5513/attachment.pl>

From i.r.cleasby at gmail.com  Fri May 24 11:53:21 2013
From: i.r.cleasby at gmail.com (Ian Cleasby)
Date: Fri, 24 May 2013 10:53:21 +0100
Subject: [R-sig-ME] MCMCglmm different random effects specifications
Message-ID: <CADcUn7C1kmz14hmVFmhnNpGvXhsstcfaWUtzuZht4S6bMyNbig@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130524/be8584ac/attachment.pl>

From M.Fairbrother at bristol.ac.uk  Fri May 24 16:02:17 2013
From: M.Fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Fri, 24 May 2013 15:02:17 +0100
Subject: [R-sig-ME] zero-inflated models with spatial autocorrelation
Message-ID: <CAAH-yP-unBGK83+K3q56+LQCBwYuAFgrCYMXNiCbMsg1NHv0EQ@mail.gmail.com>

Dear Ben and Ricardo,

Can I just clarify: Are you talking about similar functionality to
that in nlme... but, per Ricardo's query, with zero-inflation?

Aside from the issue of zero-inflation, one thing that is limiting
about nlme is that it only allows for spatial autocorrelation at the
lowest level. That is, each observation has to have a unique location.
It would be great to have functionality in lme4 that allows for
observations to be nested in *groupings* that have known locations...
so the locations of two lowest-level observations need not be unique.

Just trying to reinforce Ben's gleam!

Cheers,
Malcolm


> Date: Fri, 24 May 2013 09:31:25 +0100
> From: Ricardo Lima <rfaustinol at gmail.com>
> To: Ben Bolker <bbolker at gmail.com>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] zero-inflated models with spatial
>         autocorrelation
>
> Thanks for the quick reply!
>
> Yes, I meant continuous spatial autocorrelation. It is indeed surprising
> that no package in R can do this, when this is such a big issue when it
> comes to analysing ecological data.
>
> Best regards,
> RICARDO.
>
>
>
>
>
> 2013/5/23 Ben Bolker <bbolker at gmail.com>
>
>> Ricardo Lima <rfaustinol at ...> writes:
>>
>> >
>> > Hi,
>> >
>> > Is there any R package that allows to create zero-inflated models with
>> > spatial autocorrelation?
>> >
>> > Best regards,
>> > RICARDO Lima
>>
>>   Not really, if you mean continuous (geostatistical-style) spatial
>> autocorrelation. In principle, you can code it yourself in AD Model
>> Builder, or WinBUGS, or Stan ...
>>
>> http://www.admb-project.org/examples/spatial-models
>>
>>   This (and even the simpler case of a 'proper' GLMM with spatial
>> autocorrelation in a latent observation-level random variable) is
>> a surprisingly missing component in the available R toolbox, as far
>> as I know.  INLA _might_ do the simpler (non-ZI) case.  I have thought
>> about some ways to implement this in the development version of lme4,
>> but so far it's a gleam in my eye.
>>
>>   I would also check out
>>
>> http://www.highstat.com/book4.htm


From stwebvanuatu at yahoo.com.au  Mon May 27 14:13:33 2013
From: stwebvanuatu at yahoo.com.au (Stephen T)
Date: Mon, 27 May 2013 05:13:33 -0700 (PDT)
Subject: [R-sig-ME] Testing for differences in random effects between two
	groups
Message-ID: <1369656813.43515.YahooMailNeo@web124901.mail.ne1.yahoo.com>

Hello, 
?
I am trying to apply linear models to some observational data.?
The data are not balanced.?

Basically, I am wish to describe sexual and individual signatures in calls of a bird species. I have many call recordings and measured several acoustic variables from each recording.

Here's an analysis for one variable: 
?
> lmer(MH11~SEX+(1|BIRD)+(1|NIGHT), data=calls) 
Linear mixed model fit by REML? 
Formula: MH11 ~ SEX + (1 | BIRD) + (1 | NIGHT)? 
?? Data: calls? 
? AIC? BIC logLik deviance REMLdev 
?3662 3681? -1826???? 3663??? 3652 
Random effects: 
?Groups?? Name??????? Variance Std.Dev. 
?NIGHT??? (Intercept)? 652.77? 25.549?? 
?BIRD???? (Intercept) 1083.67? 32.919?? 
?Residual????????????? 966.50? 31.089?? 
Number of obs: 356, groups: NIGHT, 138; BIRD, 57 
?
Fixed effects: 
??????????? Estimate Std. Error t value 
(Intercept)? 445.059????? 8.212?? 54.19 
SEXM????????? 94.779???? 10.588??? 8.95 
?
Correlation of Fixed Effects: 
???? (Intr) 
SEXM -0.776 
?
SEX is a fixed effect (Female/Male). BIRD (individuals) and NIGHT are random effects.?
The nesting is SEX/BIRD/NIGHT/CALL.

There is a clear difference between-SEXes (fixed effect), i.e. SEXF and SEX
M have different voices.

Secondly, there is some interesting variation between-BIRDs. Individual BIRDs have different voices.


What if the BIRD random effect was not the same in both SEXF and SEXM groups? That would confound the model. Since there is a fixed effect (sexual signature), perhaps the random effect (individual signature) is different between groups SEXF and SEXM as well (unexpected, but should be tested).

I'm not sure how to test for differences between groups in the random effects. One possibility is to split SEXF and SEXM and run separate lmer models. How would I the compare the results? Another is to compare the distributions of random effects between SEXF and SEXM (a two-sample test?). 
?
I would appreciate some advice on how to proceed?

Stephen from Australia.


From b.berkhout at gmail.com  Mon May 27 04:48:31 2013
From: b.berkhout at gmail.com (Boris Berkhout)
Date: Mon, 27 May 2013 14:48:31 +1200
Subject: [R-sig-ME] Error in glmmADMB
Message-ID: <CAGj+D-m9oeq19cbM7g8cVO=+pwEGM1DKLPxVYM+ohW=E5TDjYA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130527/13cab4e3/attachment.pl>

From bbolker at gmail.com  Mon May 27 21:30:43 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 27 May 2013 19:30:43 +0000 (UTC)
Subject: [R-sig-ME] Error in glmmADMB
References: <CAGj+D-m9oeq19cbM7g8cVO=+pwEGM1DKLPxVYM+ohW=E5TDjYA@mail.gmail.com>
Message-ID: <loom.20130527T195555-63@post.gmane.org>

Boris Berkhout <b.berkhout at ...> writes:

> 
> Dear list members,
> 
> I am trying to fit a glmmADMB model on my data, but even after trying
> several things and reading different posts on forums I can't seem to fix
> the problem I am encountering. My response variable is the proportion of
> individuals surviving at a certain timepoint. The model looks like this:
> 
> glmmSing8 =
> > glmmadmb(survF~temperature*snail*tank*plate+(1|plate:replicate)+(1|week),
> > data=SurvSing8, family="binomial", zeroInflation=TRUE)
> >
> 

 If you want to fit a binomial model, you need to specify the
_number_ surviving and the total (denominator), as in

glmmadmb(cbind(nSurv,nTotal) ~ ....)

in your case this might? be cbind(dead_cc,total) ?

otherwise I'm afraid the results won't make sense.  (glmer() has syntax
proportion~..., weights=nTotal , so that you can use the proportion as
the response variable, but I haven't implemented a similar
syntax for glmmADMB ...

  Are you sure you need zero-inflation in the binomial?  Did you try
it first with zeroInflation=FALSE?

  I'm also afraid that with snail crossed with everything else you'll
be overfitting your model: what is

ncol(model.matrix(~temperature*snail*tank*plate,data=SurvSing8))

?

In this case you are fitting the _interaction_ between snail and
the three-way interaction of temperature, tank, plate.  Was each
snail really measured in all combinations of temperature, tank,
and plate???
 

 [snip]
 
> 'snail' is a fixed effect, because I want to distinguish between snails and
> 'plate' and 'tank' are fixed effects, because they only have two and three
> levels respectively. A summary of my data looks like this:
> 
> > summary(SurvSing8)
> >      snail      temperature    plate   tank         week
> > replicate        time
> >  Y33    : 59   Min.   :15.00   1:287   1:189   13     : 97   7      : 77
> > Min.   :8
> >  Y64    : 59   1st Qu.:15.00   2:285   2:218   16     : 92   8      : 75
> > 1st Qu.:8
> >  Y40    : 55   Median :20.00           3:165   5      : 81   2      : 74
> > Median :8
> >  Y48    : 53   Mean   :17.53                   6      : 73   3      : 73
> > Mean   :8
> >  Y30    : 45   3rd Qu.:20.00                   7      : 64   4      : 71
> > 3rd Qu.:8
> >  Y51    : 45   Max.   :20.00                   8      : 64   1      : 69
> > Max.   :8
> >  (Other):256                                   (Other):101
> > (Other):133
> >      total         dead_cc          survF
> >  Min.   :10.0   Min.   : 0.00   Min.   :0.0000
> >  1st Qu.:13.0   1st Qu.: 6.75   1st Qu.:0.3820
> >  Median :20.0   Median :10.00   Median :0.5410
> >  Mean   :22.9   Mean   :11.83   Mean   :0.5346
> >  3rd Qu.:29.0   3rd Qu.:16.00   3rd Qu.:0.7037
> >  Max.   :78.0   Max.   :53.00   Max.   :1.0000
> >
> 
> Kind regards,
> Boris Berkhout
> 
> 	[[alternative HTML version deleted]]
> 
>


From jprice5 at utk.edu  Tue May 28 13:53:17 2013
From: jprice5 at utk.edu (Price, Josh)
Date: Tue, 28 May 2013 11:53:17 +0000
Subject: [R-sig-ME] Duplicating SAS Proc HPMixed results in lme 4 and
	lmerTest
Message-ID: <F53AF3421CBEB943916FDE724B0FF22C09203447@kmbx1.utk.tennessee.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130528/6a25a95d/attachment.pl>

From lborger at cebc.cnrs.fr  Tue May 28 14:27:57 2013
From: lborger at cebc.cnrs.fr (lborger)
Date: Tue, 28 May 2013 14:27:57 +0200
Subject: [R-sig-ME] Duplicating SAS Proc HPMixed results in lme 4
	and	lmerTest
In-Reply-To: <F53AF3421CBEB943916FDE724B0FF22C09203447@kmbx1.utk.tennessee.edu>
References: <F53AF3421CBEB943916FDE724B0FF22C09203447@kmbx1.utk.tennessee.edu>
Message-ID: <WC20130528122757.930186@cebc.cnrs.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130528/da3f7c85/attachment.pl>

From kari0020 at uni.flinders.edu.au  Tue May 28 05:50:21 2013
From: kari0020 at uni.flinders.edu.au (Champika Shyamalie Kariyawasam)
Date: Tue, 28 May 2013 03:50:21 +0000
Subject: [R-sig-ME] request
Message-ID: <6BE01C2A2779524CA4D2DCC242CF5F963DF91901@SIXPRD0111MB395.apcprd01.prod.exchangelabs.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130528/b4f79f24/attachment.pl>

From jprice5 at utk.edu  Tue May 28 14:32:32 2013
From: jprice5 at utk.edu (Price, Josh)
Date: Tue, 28 May 2013 12:32:32 +0000
Subject: [R-sig-ME] Duplicating SAS Proc HPMixed results in lme 4
	and	lmerTest
In-Reply-To: <WC20130528122757.930186@cebc.cnrs.fr>
References: <F53AF3421CBEB943916FDE724B0FF22C09203447@kmbx1.utk.tennessee.edu>
	<WC20130528122757.930186@cebc.cnrs.fr>
Message-ID: <F53AF3421CBEB943916FDE724B0FF22C092034EE@kmbx1.utk.tennessee.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130528/3b190b05/attachment.pl>

From lborger at cebc.cnrs.fr  Tue May 28 14:55:52 2013
From: lborger at cebc.cnrs.fr (lborger)
Date: Tue, 28 May 2013 14:55:52 +0200
Subject: [R-sig-ME] Duplicating SAS Proc HPMixed results in lme 4
	and	lmerTest
In-Reply-To: <F53AF3421CBEB943916FDE724B0FF22C092034EE@kmbx1.utk.tennessee.edu>
References: <F53AF3421CBEB943916FDE724B0FF22C09203447@kmbx1.utk.tennessee.edu>
	<WC20130528122757.930186@cebc.cnrs.fr>
	<F53AF3421CBEB943916FDE724B0FF22C092034EE@kmbx1.utk.tennessee.edu>
Message-ID: <WC20130528125552.330188@cebc.cnrs.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130528/3ec3623b/attachment.pl>

From stwebvanuatu at yahoo.com.au  Tue May 28 15:06:29 2013
From: stwebvanuatu at yahoo.com.au (Stephen T)
Date: Tue, 28 May 2013 06:06:29 -0700 (PDT)
Subject: [R-sig-ME] Testing for differences in random effects between
	two groups
In-Reply-To: <76D55427-C67F-4747-B7AE-7102DC3BA7DE@stanford.edu>
References: <1369656813.43515.YahooMailNeo@web124901.mail.ne1.yahoo.com>
	<6255A6DA-9705-4D99-92C8-E08E6ED7B62E@stanford.edu>
	<1369662494.3093.YahooMailNeo@web124906.mail.ne1.yahoo.com>
	<76D55427-C67F-4747-B7AE-7102DC3BA7DE@stanford.edu>
Message-ID: <1369746389.5769.YahooMailNeo@web124903.mail.ne1.yahoo.com>

Yes, I think this is what I want.
?
Here's an example: 
?
> # homoscedastic model 
> # I checked and these results match lmer 
> model1=lme(MH11~SEX, random=~1|BIRD/NIGHT, data=calls) 
> model1 
Linear mixed-effects model fit by REML 
? Data: calls? 
? Log-restricted-likelihood: -1825.803 
? Fixed: MH11 ~ SEX? 
(Intercept)??????? SEXM? 
? 445.05914??? 94.77928? 
?
Random effects: 
?Formula: ~1 | BIRD 
??????? (Intercept) 
StdDev:??? 32.91933 
?
?Formula: ~1 | NIGHT %in% BIRD 
??????? (Intercept) Residual 
StdDev:??? 25.54875 31.08874 
?
Number of Observations: 356 
Number of Groups:? 
?????????? BIRD NIGHT %in% BIRD? 
???????????? 57???????????? 138? 
> # heteroscedastic model? 
> model2=lme(MH11~SEX, random=~1|BIRD/NIGHT, data=calls, weights=varIdent(form=~1|SEX)) 
> model2 
Linear mixed-effects model fit by REML 
? Data: calls? 
? Log-restricted-likelihood: -1811.211 
? Fixed: MH11 ~ SEX? 
(Intercept)??????? SEXM? 
? 445.06240??? 94.67614? 
?
Random effects: 
?Formula: ~1 | BIRD 
??????? (Intercept) 
StdDev:??? 32.77675 
?
?Formula: ~1 | NIGHT %in% BIRD 
??????? (Intercept) Residual 
StdDev:??? 22.54168 36.82237 
?
Variance function: 
?Structure: Different standard deviations per stratum 
?Formula: ~1 | SEX? 
?Parameter estimates: 
??????? M???????? F? 
1.0000000 0.5704416? 
Number of Observations: 356 
Number of Groups:? 
?????????? BIRD NIGHT %in% BIRD? 
???????????? 57???????????? 138? 
# likelihood ratio test 
# I have read that one should actually use method="ML" in the model1 and model2 for this test 
> anova(model1, model2) 
?????? Model df????? AIC????? BIC??? logLik?? Test? L.Ratio p-value 
model1???? 1? 5 3661.606 3680.953 -1825.803???????????????????????? 
model2???? 2? 6 3634.421 3657.637 -1811.210 1 vs 2 29.18513? <.0001 
?
I will now have to read up on interpretation of nlme results. 
?
The variance function results always sets SEXM = 1, which is unexpected because F is the first factor. 

Anyhow, model2 indicated that SEXF sd was about 0.57 times SEXM, correct me if I'm wrong? I calculated a mean sd ratio = 0.58 directly from the data, ignoring NIGHT effects. Indeed, boxplots suggest that SEXM measurements were more variable than SEXF measurements. 
?
More about what I am doing: model2 seems appropriate for my study. Looking at the box plots, I can see a shift between the groups SEXF and SEXM. Secondly, there is variation between- and within- individual BIRDs. Between-BIRD variation suggests individual vocal signatures. Some of the within-BIRD variation might be because different stimuli (call playbacks) were used on different NIGHTs to elicit responses, i.e. producing different excitedness in responses from the BIRDs. Thirdly, the groups SEXF and SEXM are heteroscedastic as noted above. 
?
I hope to make some good progress now and maximise the value of my hard-earned data. 
?
Thank you very much, Ewart.



----- Original Message -----
From: Ewart Thomas <ethomas at stanford.edu>
To: Stephen T <stwebvanuatu at yahoo.com.au>
Cc: 
Sent: Tuesday, 28 May 2013 4:26 AM
Subject: Re: [R-sig-ME] Testing for differences in random effects between two groups

stephen, see if this site is useful: http://permalink.gmane.org/gmane.comp.lang.r.lme4.devel/7108

your code might look like:

library(nlme) 

model1 = lme(MH11 ~ SEX, random = ~ 1 | BIRD / NIGHT, data = calls)
model2 = lme(MH11 ~ SEX, random = ~ 1 | BIRD / NIGHT, data = calls, weights = varIdent(form = ~ 1 | SEX))

# Test if equal var model is sig worse than unequal var model
anova(model1, model2)

good luck!
ewart

On May 27, 2013, at 6:48 AM, Stephen T wrote:

> Thanks,
> 
> I hope that when I hit reply this message also goes to the mailing list. Please correct me if it doesn't.
> 
> 
> I am weak on model definition and don't understand the output from lmer here.
> 
> 
> The first model you suggested is equivalent to:
>> lmer(MH11~SEX+(1|SEX/BIRD/NIGHT), data=calls) 
> Linear mixed model fit by REML? 
> Formula: MH11 ~ SEX + (1 | SEX/BIRD/NIGHT)? 
>? ? Data: calls? 
>?  AIC? BIC logLik deviance REMLdev 
>? 3664 3687? -1826? ?  3664? ? 3652 
> Random effects: 
>? Groups? ? ? ? ?  Name? ? ? ? Variance Std.Dev. 
>? NIGHT:(BIRD:SEX) (Intercept)? 652.770 25.5494? 
>? BIRD:SEX? ? ? ?  (Intercept) 1083.670 32.9191? 
>? SEX? ? ? ? ? ? ? (Intercept)?  14.479? 3.8052? 
>? Residual? ? ? ? ? ? ? ? ? ? ? 966.500 31.0886? 
> Number of obs: 356, groups: NIGHT:(BIRD:SEX), 138; BIRD:SEX, 57; SEX, 2 
>? 
> Fixed effects: 
>? ? ? ? ? ?  Estimate Std. Error t value 
> (Intercept)? 445.059? ? ? 9.052?  49.17 
> SEXM? ? ? ? ? 94.779? ?  11.878? ? 7.98 
>? 
> Correlation of Fixed Effects: 
>? ? ? (Intr) 
> SEXM -0.762
> 
> The above results show the correct nesting structure. Your code actually returned NIGHT and not NIGHT:(BIRD:SEX) but the numbers are the same.
> 
> The SEX random effect above is clearly not important but how to interpret the results?
> I was hoping to see something like this:
> NIGHT
> BIRD:SEXF
> BIRD:SEXM
> Residual
> Then I could do a likelihood ratio test of the above versus the simpler model. Or is the small SEX random effect variance itself the result I am seeking???
> 
> 
> The next model below has split the BIRD:SEX effect in two. It looks like a bit of a mess:
>> lmer(MH11~SEX+(1|SEX/BIRD)+(1|SEX/BIRD/NIGHT), data=calls) 
> Linear mixed model fit by REML? 
> Formula: MH11 ~ SEX + (1 | SEX/BIRD) + (1 | SEX/BIRD/NIGHT)? 
>? ? Data: calls? 
>?  AIC? BIC logLik deviance REMLdev 
>? 3668 3699? -1826? ?  3664? ? 3652 
> Random effects: 
>? Groups? ? ? ? ?  Name? ? ? ? Variance Std.Dev. 
>? NIGHT:(BIRD:SEX) (Intercept) 652.762? 25.5492? 
>? BIRD:SEX? ? ? ?  (Intercept) 541.811? 23.2768? 
>? BIRD:SEX? ? ? ?  (Intercept) 541.867? 23.2780? 
>? SEX? ? ? ? ? ? ? (Intercept)? 14.473?  3.8043? 
>? SEX? ? ? ? ? ? ? (Intercept)? 14.475?  3.8046? 
>? Residual? ? ? ? ? ? ? ? ? ?  966.502? 31.0886? 
> Number of obs: 356, groups: NIGHT:(BIRD:SEX), 138; BIRD:SEX, 57; SEX, 2 
>? 
> Fixed effects: 
>? ? ? ? ? ?  Estimate Std. Error t value 
> (Intercept)? 445.059? ? ? 9.803?  45.40 
> SEXM? ? ? ? ? 94.779? ?  13.016? ? 7.28 
>? 
> Correlation of Fixed Effects: 
>? ? ? (Intr) 
> SEXM -0.753 
> 
> 
> ----- Original Message -----
> From: Ewart Thomas <ethomas at stanford.edu>
> To: Stephen T <stwebvanuatu at yahoo.com.au>
> Cc: 
> Sent: Monday, 27 May 2013 10:34 PM
> Subject: Re: [R-sig-ME] Testing for differences in random effects between two groups
> 
> stephen, try inserting the nesting structure into the model:
> 
> model1 = lmer(MH11 ~ SEX + (1 | SEX / BIRD) + (1 | NIGHT), data = calls),
> 
> or even 
> 
> model2 = lmer(MH11 ~ SEX + (1 | SEX / BIRD) + (1 | SEX / BIRD / NIGHT), data = calls),
> 
> i think model2 is the correct model.? hope that works.
> ewart
> 
> On May 27, 2013, at 5:13 AM, Stephen T wrote:
> 
>> Hello, 
>>? 
>> I am trying to apply linear models to some observational data. 
>> The data are not balanced. 
>> 
>> Basically, I am wish to describe sexual and individual signatures in calls of a bird species. I have many call recordings and measured several acoustic variables from each recording.
>> 
>> Here's an analysis for one variable: 
>>? 
>>> lmer(MH11~SEX+(1|BIRD)+(1|NIGHT), data=calls) 
>> Linear mixed model fit by REML? 
>> Formula: MH11 ~ SEX + (1 | BIRD) + (1 | NIGHT)? 
>>? ?  Data: calls? 
>>? ? AIC? BIC logLik deviance REMLdev 
>>?  3662 3681? -1826? ?  3663? ? 3652 
>> Random effects: 
>>?  Groups?  Name? ? ? ? Variance Std.Dev. 
>>?  NIGHT? ? (Intercept)? 652.77? 25.549? 
>>?  BIRD? ?  (Intercept) 1083.67? 32.919? 
>>?  Residual? ? ? ? ? ? ? 966.50? 31.089? 
>> Number of obs: 356, groups: NIGHT, 138; BIRD, 57 
>>? 
>> Fixed effects: 
>>? ? ? ? ? ? ? Estimate Std. Error t value 
>> (Intercept)? 445.059? ? ? 8.212?  54.19 
>> SEXM? ? ? ? ? 94.779? ?  10.588? ? 8.95 
>>? 
>> Correlation of Fixed Effects: 
>>? ? ?  (Intr) 
>> SEXM -0.776 
>>? 
>> SEX is a fixed effect (Female/Male). BIRD (individuals) and NIGHT are random effects. 
>> The nesting is SEX/BIRD/NIGHT/CALL.
>> 
>> There is a clear difference between-SEXes (fixed effect), i.e. SEXF and SEX
>> M have different voices.
>> 
>> Secondly, there is some interesting variation between-BIRDs. Individual BIRDs have different voices.
>> 
>> 
>> What if the BIRD random effect was not the same in both SEXF and SEXM groups? That would confound the model. Since there is a fixed effect (sexual signature), perhaps the random effect (individual signature) is different between groups SEXF and SEXM as well (unexpected, but should be tested).
>> 
>> I'm not sure how to test for differences between groups in the random effects. One possibility is to split SEXF and SEXM and run separate lmer models. How would I the compare the results? Another is to compare the distributions of random effects between SEXF and SEXM (a two-sample test?). 
>>? 
>> I would appreciate some advice on how to proceed?
>> 
>> Stephen from Australia.
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 



From seth at swbigelow.net  Tue May 28 16:19:36 2013
From: seth at swbigelow.net (Seth Bigelow)
Date: Tue, 28 May 2013 10:19:36 -0400
Subject: [R-sig-ME] request
In-Reply-To: <6BE01C2A2779524CA4D2DCC242CF5F963DF91901@SIXPRD0111MB395.apcprd01.prod.exchangelabs.com>
References: <6BE01C2A2779524CA4D2DCC242CF5F963DF91901@SIXPRD0111MB395.apcprd01.prod.exchangelabs.com>
Message-ID: <000c01ce5bae$62cfdd70$286f9850$@net>

Shyam, I have found Dave Atkin's tutorial to be very helpful in a situation
that may be similar to the one you describe. I was at a loss to understand
the estimated coefficients in poisson regression before reading it. It seems
to be behind a paywall ($11.95), though it was not the last time I checked.
--Seth 

A tutorial on count regression and zero-altered count models for
longitudinal substance use data.
By Atkins, David C.; Baldwin, Scott A.; Zheng, Cheng; Gallop, Robert J.;
Neighbors, Clayton
Psychology of Addictive Behaviors, Vol 27(1), Mar 2013, 166-177.

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Champika
Shyamalie Kariyawasam
Sent: Monday, May 27, 2013 11:50 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] request

Hi all

I am using generalized linear mixed model fit by the laplace approximation
(family poisson) to analize my data. I have seed number (dependent variable)
as a function of study site in two lations in two countries. i ran the model
in R . But i need some assistance to interpret my data. Any source,
reference or result of previous work welcome.

thanks in advance

shyam

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Tue May 28 18:13:57 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 28 May 2013 16:13:57 +0000 (UTC)
Subject: [R-sig-ME] Error in glmmADMB
References: <CAGj+D-m9oeq19cbM7g8cVO=+pwEGM1DKLPxVYM+ohW=E5TDjYA@mail.gmail.com>
	<loom.20130527T195555-63@post.gmane.org>
Message-ID: <loom.20130528T180826-414@post.gmane.org>

Ben Bolker <bbolker at ...> writes:

> 
> Boris Berkhout <b.berkhout <at> ...> writes:
> 
> > 
> > Dear list members,
> > 
> > I am trying to fit a glmmADMB model on my data, but even after trying
> > several things and reading different posts on forums I can't seem to fix
> > the problem I am encountering. My response variable is the proportion of
> > individuals surviving at a certain timepoint. The model looks like this:
> > 
> > glmmSing8 =
> > > glmmadmb(survF~temperature*snail*tank*plate+
> (1|plate:replicate)+(1|week),
> > > data=SurvSing8, family="binomial", zeroInflation=TRUE)
> > >
> > 
> 

  For the record, it looks like (based on off-list conversations)
this problem was caused by a degenerate design matrix (i.e., some
predictor variables were perfectly multicollinear).  I will be adding
a check for this situation to glmmADMB, but in the precise cause
will always have to be diagnosed and dealt with by the user ...

  Ben Bolker


From longrob604 at gmail.com  Tue May 28 18:44:35 2013
From: longrob604 at gmail.com (W Robert Long)
Date: Tue, 28 May 2013 17:44:35 +0100
Subject: [R-sig-ME] Design Matrix for Random effects
In-Reply-To: <000c01ce5bae$62cfdd70$286f9850$@net>
References: <6BE01C2A2779524CA4D2DCC242CF5F963DF91901@SIXPRD0111MB395.apcprd01.prod.exchangelabs.com>
	<000c01ce5bae$62cfdd70$286f9850$@net>
Message-ID: <51A4DEF3.4020401@gmail.com>

Hi all

I would like to obtain the design matrix for the random effects, without 
running (g)lmer first.

Could anyone help me do that ? For example, working with the sleepstudy 
dataset

sm1 <- lmer(Reaction ~ Days + (Days|Subject), data=sleepstudy)

sm1 at Zt is the transpose of the matrix I require, but I would like to 
obtain it without running lmer.

Thanks
Robert Long


From steve.walker at utoronto.ca  Tue May 28 19:29:29 2013
From: steve.walker at utoronto.ca (Steve Walker)
Date: Tue, 28 May 2013 13:29:29 -0400
Subject: [R-sig-ME] Design Matrix for Random effects
In-Reply-To: <51A4DEF3.4020401@gmail.com>
References: <6BE01C2A2779524CA4D2DCC242CF5F963DF91901@SIXPRD0111MB395.apcprd01.prod.exchangelabs.com>
	<000c01ce5bae$62cfdd70$286f9850$@net> <51A4DEF3.4020401@gmail.com>
Message-ID: <51A4E979.9040607@utoronto.ca>

Hi Robert,

In stable (i.e. cran) lme4, Zt can be obtained without fitting the model 
using this command:

lmer(Reaction ~ Days + (Days|Subject), data=sleepstudy, doFit = 
FALSE)$FL$trms[[1]]$Zt

In development (i.e. github) lme4, you can use this command:

lFormula(Reaction ~ Days + (Days|Subject), data=sleepstudy)$reTrms$Zt

or these two:

dv <- lmer(Reaction ~ Days + (Days|Subject), data=sleepstudy, devFunOnly 
= TRUE)
environment(dv)$pp$Zt

Cheers,
Steve




On 2013-05-28 12:44 PM, W Robert Long wrote:
> Hi all
>
> I would like to obtain the design matrix for the random effects, 
> without running (g)lmer first.
>
> Could anyone help me do that ? For example, working with the 
> sleepstudy dataset
>
> sm1 <- lmer(Reaction ~ Days + (Days|Subject), data=sleepstudy)
>
> sm1 at Zt is the transpose of the matrix I require, but I would like to 
> obtain it without running lmer.
>
> Thanks
> Robert Long
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From longrob604 at gmail.com  Tue May 28 19:55:30 2013
From: longrob604 at gmail.com (W Robert Long)
Date: Tue, 28 May 2013 18:55:30 +0100
Subject: [R-sig-ME] Design Matrix for Random effects
In-Reply-To: <51A4E979.9040607@utoronto.ca>
References: <6BE01C2A2779524CA4D2DCC242CF5F963DF91901@SIXPRD0111MB395.apcprd01.prod.exchangelabs.com>
	<000c01ce5bae$62cfdd70$286f9850$@net>
	<51A4DEF3.4020401@gmail.com> <51A4E979.9040607@utoronto.ca>
Message-ID: <51A4EF92.8000802@gmail.com>

Hi Steve

That's great. Thanks a lot :-)

RL

On 28/05/2013 18:29, Steve Walker wrote:
> Hi Robert,
>
> In stable (i.e. cran) lme4, Zt can be obtained without fitting the model
> using this command:
>
> lmer(Reaction ~ Days + (Days|Subject), data=sleepstudy, doFit =
> FALSE)$FL$trms[[1]]$Zt
>
> In development (i.e. github) lme4, you can use this command:
>
> lFormula(Reaction ~ Days + (Days|Subject), data=sleepstudy)$reTrms$Zt
>
> or these two:
>
> dv <- lmer(Reaction ~ Days + (Days|Subject), data=sleepstudy, devFunOnly
> = TRUE)
> environment(dv)$pp$Zt
>
> Cheers,
> Steve
>
>
>
>
> On 2013-05-28 12:44 PM, W Robert Long wrote:
>> Hi all
>>
>> I would like to obtain the design matrix for the random effects,
>> without running (g)lmer first.
>>
>> Could anyone help me do that ? For example, working with the
>> sleepstudy dataset
>>
>> sm1 <- lmer(Reaction ~ Days + (Days|Subject), data=sleepstudy)
>>
>> sm1 at Zt is the transpose of the matrix I require, but I would like to
>> obtain it without running lmer.
>>
>> Thanks
>> Robert Long
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From smckinney at bccrc.ca  Wed May 29 00:49:58 2013
From: smckinney at bccrc.ca (Steven McKinney)
Date: Tue, 28 May 2013 15:49:58 -0700
Subject: [R-sig-ME] request
In-Reply-To: <000c01ce5bae$62cfdd70$286f9850$@net>
References: <6BE01C2A2779524CA4D2DCC242CF5F963DF91901@SIXPRD0111MB395.apcprd01.prod.exchangelabs.com>,
	<000c01ce5bae$62cfdd70$286f9850$@net>
Message-ID: <DCE81E14EB74504B971DAD4D2DB0356B0CB926DEB4@crcmail4.BCCRC.CA>



What appears to be a preprint copy is available at

   http://www.ats.ucla.edu/stat/paperexamples/atkins/Modeling_Infrequent_Counts_JFP2007_-_WEB.pdf



Steven McKinney

Statistician
Molecular Oncology and Breast Cancer Program
British Columbia Cancer Research Centre


________________________________________
From: r-sig-mixed-models-bounces at r-project.org [r-sig-mixed-models-bounces at r-project.org] On Behalf Of Seth Bigelow [seth at swbigelow.net]
Sent: May 28, 2013 7:19 AM
To: 'Champika Shyamalie Kariyawasam'; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] request

Shyam, I have found Dave Atkin's tutorial to be very helpful in a situation
that may be similar to the one you describe. I was at a loss to understand
the estimated coefficients in poisson regression before reading it. It seems
to be behind a paywall ($11.95), though it was not the last time I checked.
--Seth

A tutorial on count regression and zero-altered count models for
longitudinal substance use data.
By Atkins, David C.; Baldwin, Scott A.; Zheng, Cheng; Gallop, Robert J.;
Neighbors, Clayton
Psychology of Addictive Behaviors, Vol 27(1), Mar 2013, 166-177.

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Champika
Shyamalie Kariyawasam
Sent: Monday, May 27, 2013 11:50 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] request

Hi all

I am using generalized linear mixed model fit by the laplace approximation
(family poisson) to analize my data. I have seed number (dependent variable)
as a function of study site in two lations in two countries. i ran the model
in R . But i need some assistance to interpret my data. Any source,
reference or result of previous work welcome.

thanks in advance

shyam

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From dwinsemius at comcast.net  Wed May 29 02:30:44 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 28 May 2013 17:30:44 -0700
Subject: [R-sig-ME] request
In-Reply-To: <DCE81E14EB74504B971DAD4D2DB0356B0CB926DEB4@crcmail4.BCCRC.CA>
References: <6BE01C2A2779524CA4D2DCC242CF5F963DF91901@SIXPRD0111MB395.apcprd01.prod.exchangelabs.com>,
	<000c01ce5bae$62cfdd70$286f9850$@net>
	<DCE81E14EB74504B971DAD4D2DB0356B0CB926DEB4@crcmail4.BCCRC.CA>
Message-ID: <2675EB14-7E81-4C89-94D1-CFF0F993A99E@comcast.net>


On May 28, 2013, at 3:49 PM, Steven McKinney wrote:

> 
> 
> What appears to be a preprint copy is available at
> 
>   http://www.ats.ucla.edu/stat/paperexamples/atkins/Modeling_Infrequent_Counts_JFP2007_-_WEB.pdf
> 

This article contains what I consider to be unfortunate advice:

"One consequence of this is that using a simple transformation allows us to interpret regression coefficients in the Poisson model as the percentage change in the expected counts:

100*[e?*? ?1] (5) where ? is the regression coefficient from the Poisson regression and ? is the units of change in

the predictor (e.g., for one unit of change in the predictor, ? = 1)."

This advice (which is repeating a misinterpretation foisted by the SAS Stats Manual) fails to recognize that the scale of interpretation is not symmetric upon "inversion" or "complementation" of the predictors. So if the predictor is a 1/0 variable, then one coding of a variable with a coefficient of log(2)  might be "interpreted" as a 100% change(say for "married"==1),  whereas the reverse coding ( alternately coded "not married" ==1)  would be "interpreted" as a 50% change. Ironically this advice occurs immediately after the distinction between linear scales and multiplicative scales. It is the multiplicative scale that invalidates that "percentage change" interpretation simply because the range from a "null"-value of 0 to the low end of possible values os "100%" whereas the range to the high end is unlimited upward.

(The correct interpretation is for the exponentiated coefficient to be seen as a relative risk or a multiplicative factor that creates a predicted count or rate relative to the Intercept or baseline estimate. There is really no need to subtract one if one realizes that a factor of 1 will not change any estimate if the result is being multiplied by a baseline value.)

If the advice were couched in more limited manner such that it were resticted to small coefficients and sufficient caveats about its approximate nature were offers, I would be less offended. It bothers me to see this further source of misinterpretation cited as an authority.

> 
> 
> Steven McKinney
> 
> Statistician
> Molecular Oncology and Breast Cancer Program
> British Columbia Cancer Research Centre
> 
> 
> ________________________________________
> From: r-sig-mixed-models-bounces at r-project.org [r-sig-mixed-models-bounces at r-project.org] On Behalf Of Seth Bigelow [seth at swbigelow.net]
> Sent: May 28, 2013 7:19 AM
> To: 'Champika Shyamalie Kariyawasam'; r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] request
> 
> Shyam, I have found Dave Atkin's tutorial to be very helpful in a situation
> that may be similar to the one you describe. I was at a loss to understand
> the estimated coefficients in poisson regression before reading it. It seems
> to be behind a paywall ($11.95), though it was not the last time I checked.
> --Seth
> 
> A tutorial on count regression and zero-altered count models for
> longitudinal substance use data.
> By Atkins, David C.; Baldwin, Scott A.; Zheng, Cheng; Gallop, Robert J.;
> Neighbors, Clayton
> Psychology of Addictive Behaviors, Vol 27(1), Mar 2013, 166-177.
> 
> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Champika
> Shyamalie Kariyawasam
> Sent: Monday, May 27, 2013 11:50 PM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] request
> 
> Hi all
> 
> I am using generalized linear mixed model fit by the laplace approximation
> (family poisson) to analize my data. I have seed number (dependent variable)
> as a function of study site in two lations in two countries. i ran the model
> in R . But i need some assistance to interpret my data. Any source,
> reference or result of previous work welcome.
> 
> thanks in advance
> 
> shyam


David Winsemius
Alameda, CA, USA


From henrik.singmann at psychologie.uni-freiburg.de  Wed May 29 12:12:11 2013
From: henrik.singmann at psychologie.uni-freiburg.de (Henrik Singmann)
Date: Wed, 29 May 2013 12:12:11 +0200
Subject: [R-sig-ME] Design Matrix for Random effects
In-Reply-To: <51A4EF92.8000802@gmail.com>
References: <6BE01C2A2779524CA4D2DCC242CF5F963DF91901@SIXPRD0111MB395.apcprd01.prod.exchangelabs.com>
	<000c01ce5bae$62cfdd70$286f9850$@net>
	<51A4DEF3.4020401@gmail.com> <51A4E979.9040607@utoronto.ca>
	<51A4EF92.8000802@gmail.com>
Message-ID: <51A5D47B.7000307@psychologie.uni-freiburg.de>

Hi Robert,

A further problem could be that R is somewhat reluctant to fit models with interactions but without main effects.
I asked this on SO quite some time ago (with nice answers from regulars on this list, Ben Bolker and Joshua Wiley): http://stackoverflow.com/q/11335923/289572

Even if you specify to exclude the main effects in presence of interaction, their parameters will be there. In your data:

require(lme4)
cutsim <- read.csv(file="cutsim.csv", header=T)
cutsim$Species <- as.factor(cutsim$Species)
cutsim$Farm <- as.factor(cutsim$Farm)

# model without main effect:
model2 <- lmer(Yield ~ Species + Species:Farm + (1|Animal), data=cutsim, doFit = FALSE, REML=TRUE)
length(model2$fr$fixef)
# 500 fixed effects parameters

# model with main effect
model3 <- lmer(Yield ~ Species*Farm + (1|Animal), data=cutsim, doFit = FALSE, REML=TRUE)
length(model3$fr$fixef)
# 500 fixed effects parameters

Cheers,
Henrik


Am 28/05/2013 19:55, schrieb W Robert Long:
> Hi Steve
>
> That's great. Thanks a lot :-)
>
> RL
>
> On 28/05/2013 18:29, Steve Walker wrote:
>> Hi Robert,
>>
>> In stable (i.e. cran) lme4, Zt can be obtained without fitting the model
>> using this command:
>>
>> lmer(Reaction ~ Days + (Days|Subject), data=sleepstudy, doFit =
>> FALSE)$FL$trms[[1]]$Zt
>>
>> In development (i.e. github) lme4, you can use this command:
>>
>> lFormula(Reaction ~ Days + (Days|Subject), data=sleepstudy)$reTrms$Zt
>>
>> or these two:
>>
>> dv <- lmer(Reaction ~ Days + (Days|Subject), data=sleepstudy, devFunOnly
>> = TRUE)
>> environment(dv)$pp$Zt
>>
>> Cheers,
>> Steve
>>
>>
>>
>>
>> On 2013-05-28 12:44 PM, W Robert Long wrote:
>>> Hi all
>>>
>>> I would like to obtain the design matrix for the random effects,
>>> without running (g)lmer first.
>>>
>>> Could anyone help me do that ? For example, working with the
>>> sleepstudy dataset
>>>
>>> sm1 <- lmer(Reaction ~ Days + (Days|Subject), data=sleepstudy)
>>>
>>> sm1 at Zt is the transpose of the matrix I require, but I would like to
>>> obtain it without running lmer.
>>>
>>> Thanks
>>> Robert Long
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

-- 
Dipl. Psych. Henrik Singmann
PhD Student
Albert-Ludwigs-Universit?t Freiburg, Germany
http://www.psychologie.uni-freiburg.de/Members/singmann


From a.hayward at sheffield.ac.uk  Wed May 29 14:37:07 2013
From: a.hayward at sheffield.ac.uk (Adam Hayward)
Date: Wed, 29 May 2013 13:37:07 +0100
Subject: [R-sig-ME] MCMCglmm bivariate random regression
Message-ID: <CALQiR082W-Fha+Yrds_nwO_CvVYeYiUx9QwS95e9W9nyUXZ7fA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130529/5a9ac9c1/attachment.pl>

From bates at stat.wisc.edu  Wed May 29 17:08:29 2013
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 29 May 2013 10:08:29 -0500
Subject: [R-sig-ME] Duplicating SAS Proc HPMixed results in lme 4 and
	lmerTest
In-Reply-To: <WC20130528125552.330188@cebc.cnrs.fr>
References: <F53AF3421CBEB943916FDE724B0FF22C09203447@kmbx1.utk.tennessee.edu>
	<WC20130528122757.930186@cebc.cnrs.fr>
	<F53AF3421CBEB943916FDE724B0FF22C092034EE@kmbx1.utk.tennessee.edu>
	<WC20130528125552.330188@cebc.cnrs.fr>
Message-ID: <CAO7JsnQ6MDZakCnxCwYgerdNDBpZrKSFa7G09U6KkF1EH5-6SQ@mail.gmail.com>

I enclose an R source file and the output from running this code in batch
mode using

R CMD BATCH --vanilla cutsim.R

As Luca mentioned, it is important to convert the categorical variables
Animal, Farm and Species to factors in R before fitting models.  In general
it is advisable to check the structure of a data frame, using the str()
function, and a summary of the columns, using summary(), before fitting
models.  This is especially important when dealing with large data sets.

One additional check that I did was to check whether Animal is nested
within Species, which one would expect to be true, and also nested within
Farm.  By extracting the unique rows of the subset of the data frame formed
by taking only the Animal, Species and Farm columns and looking at the row
count we see that there are 10000 rows which is the number of distinct
Animals.  Thus Species and Farm are nested within Animal. (If they weren't
there would be more than 10000 rows.)

The first model that I fit has a fixed-effect for Species and random
effects for Animal and Farm:Species.  I know you wanted to model
Farm:Species as a fixed effect but with 500 levels I would generally use a
random effect for that factor.  The next model is the one you wanted to
fit.  As suggested by Luca, it will take a long time and use a lot of
memory.  This is because there are fixed-effects for over 500 coefficients.
 The model matrix for the fixed-effects is very sparse (over 99% of the
elements are zeros) but it is being treated as a dense matrix.  This is why
fitting the model takes over 10 times as long as the previous model fit.

To test the significance of the Farm:Species interaction I fit the model
without the term and compare it to the model with the term.  In this case
the evidence of the significance of the term is overwhelming, although that
could be seen from the first model fit too.  The reason I use maximum
likelihood fits for the models is to allow the likelihood ratio test.

From jprice5 at utk.edu  Wed May 29 19:28:46 2013
From: jprice5 at utk.edu (Price, Josh)
Date: Wed, 29 May 2013 17:28:46 +0000
Subject: [R-sig-ME] Duplicating SAS Proc HPMixed results in lme 4 and
 lmerTest
In-Reply-To: <CAO7JsnQ6MDZakCnxCwYgerdNDBpZrKSFa7G09U6KkF1EH5-6SQ@mail.gmail.com>
References: <F53AF3421CBEB943916FDE724B0FF22C09203447@kmbx1.utk.tennessee.edu>
	<WC20130528122757.930186@cebc.cnrs.fr>
	<F53AF3421CBEB943916FDE724B0FF22C092034EE@kmbx1.utk.tennessee.edu>
	<WC20130528125552.330188@cebc.cnrs.fr>
	<CAO7JsnQ6MDZakCnxCwYgerdNDBpZrKSFa7G09U6KkF1EH5-6SQ@mail.gmail.com>
Message-ID: <F53AF3421CBEB943916FDE724B0FF22C09204AF7@kmbx1.utk.tennessee.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130529/aec1455c/attachment.pl>

From hans.ekbrand at gmail.com  Thu May 30 01:31:54 2013
From: hans.ekbrand at gmail.com (Hans Ekbrand)
Date: Thu, 30 May 2013 01:31:54 +0200
Subject: [R-sig-ME] random slope models with several terms with the same
 grouping variable
Message-ID: <20130529233153.GA4587@samir>

Dear list,

I am trying to model the probability of poverty at the individual
level using predictors at the country level. The dependent variable is
measuring poverty is cdepidxs, and individuals are nested in
household/cluster/country. ("cluster" is a small area consisting of a
few hundred households).

I want to test the effect of three predictors variables at the country
level: loggdp, wbgi_gee, and killed.per.million. In a random intercept
version with these variables as fixed terms they all come out as
significant:

## If you want to load the data set example.data, use 
(load(url("http://dl.dropboxusercontent.com/u/99038959/data/example.data.RData")))

lmer(cdepidxs ~ (1|country) + (1|cluster) + (1|household) + loggdp + wbgi_gee + killed.per.million, data = example.data)

Now, I want to test if the effect of these three predictors vary by a dicotomous grouping variable rural (measuringing whether the cluster is a rural or urban), so I want a random slope for each the conditioned on the variable rural:

lmer(cdepidxs ~ (1|country) + (1|cluster) + (1|household) + (loggdp|rural) + (wbgi_gee|rural) + (killed.per.million|rural), data = example.data)

I ran this model, but I don't understand how to interpret the unique intercept I got for each of them. I thought I might missed to include a term for rural, so I tried a new version with a term for a random interept for rural included on its own:

lmer(cdepidxs ~ (1|country) + (1|cluster) + (1|household) + (loggdp|rural) + (wbgi_gee|rural) + (killed.per.million|rural) + (1|rural), data = example.data)

But the intercept of that term turned out to be almost zero. In fact, it looks like one of the predictors, wgbi_gee "got" all the intercept as the other intercepts are practically zero.

> summary(my.fit)
Linear mixed model fit by REML 
Formula: formula 
   Data: my.df 
     AIC     BIC   logLik deviance REMLdev
 4007625 4007812 -2003797  4007595 4007595
Random effects:
 Groups    Name               Variance   Std.Dev.   Corr  
 household (Intercept)        3.9593e-01 6.2923e-01       
 cluster   (Intercept)        3.3303e-01 5.7709e-01       
 country   (Intercept)        1.7662e-01 4.2026e-01       
 rural     (Intercept)        3.0174e-01 5.4931e-01       
           wbgi_gee           2.0499e-03 4.5276e-02 1.000 
 rural     (Intercept)        4.0165e-25 6.3376e-13       
 rural     (Intercept)        1.7462e-24 1.3214e-12       
           killed.per.million 6.9565e-02 2.6375e-01 0.000 
 rural     (Intercept)        1.4500e-24 1.2042e-12       
           loggdp             2.1524e-01 4.6393e-01 0.000 
 Residual                     2.4374e-01 4.9370e-01       
Number of obs: 1999809, groups: household, 658191; cluster, 39150; country, 69; rural, 2

Fixed effects:
            Estimate Std. Error t value
(Intercept)   4.7075     0.5519   8.529

> ranef(my.fit, whichel = "rural")
$rural
    (Intercept)   wbgi_gee   (Intercept)   (Intercept) killed.per.million   (Intercept)     loggdp
no    -2.011992 -0.1658346 -2.584028e-24 -1.122397e-23        0.001312586 -9.360747e-24 -0.2788045
yes    1.481114  0.1220780  2.583515e-24  1.128187e-23        0.006438184  9.257922e-24 -0.6008917

Should I specifically specify that I don't want a random intercept for each of the variables loggdp, wgbi_gee and killed.per.million? Like this?

lmer(cdepidxs ~ (1|country) + (1|cluster) + (1|household) + (0+loggdp|rural) + (0+wbgi_gee|rural) + (0+killed.per.million|rural) + (1|rural), data = example.data)


From stwebvanuatu at yahoo.com.au  Thu May 30 13:37:58 2013
From: stwebvanuatu at yahoo.com.au (Stephen T)
Date: Thu, 30 May 2013 04:37:58 -0700 (PDT)
Subject: [R-sig-ME] Separating random effects variance for two groups
Message-ID: <1369913878.86046.YahooMailNeo@web124906.mail.ne1.yahoo.com>

 
Hello (again),

Is it possible to separate random effects between groups?


I have heteroscedastic models, because variance in the group SEXM (males) is greater than in the group SEXF (females). The residual plots have improved.


Here's an example:


model=lme(MH11~SEX,
random=~1|BIRD/NIGHT, data=calls, weights=varIdent(form=~1|SEX)) 

...

Random effects: 

? Formula: ~1 | BIRD 
????? (Intercept) 
?StdDev:??? 32.77675 
?
?Formula: ~1 | NIGHT %in% BIRD 
??????? (Intercept) Residual 
?StdDev:??? 22.54168 36.82237 
?
?Variance function: 
? Structure: Different standard deviations per stratum 
? Formula: ~1 | SEX 
? Parameter estimates: 
??????? M??????? F 
?1.0000000 0.5704416?
...

I have extracted the residuals(model), ranef(model, level1) and ranef(model, level2) from the above and computed sds for groups SEXF and SEXM. It appears that the Variance function ratio result is only for the residuals:

i.e. Residual^2 ~ sdSEXM^2 + sdSEXF^2 = sdSEXM^2(1 + ratio^2)
where sds are computed from residuals(model)

For random effects, BIRD and NIGHT, the ratio of sdSEXF and sdSEXM is often wide of the Variance function result.


What I would really like to check is whether the random effects variances for the group BIRD (i.e. different subject) differs between groups SEXF and SEXM. The biological question is: are individual signatures encoded differently in females and males?


What I'm thinking of now is to run two models, for groups SEXF and SEXM. Then I can compare confidence intervals for the random effects. Separate models would also remove the need for weights. Trying to dissect the above output or modify seems more difficult.


Any corrections, suggestions?


Stephen.



From hans.ekbrand at gmail.com  Thu May 30 15:26:13 2013
From: hans.ekbrand at gmail.com (Hans Ekbrand)
Date: Thu, 30 May 2013 15:26:13 +0200
Subject: [R-sig-ME] random slope models with several terms with the same
 grouping variable
In-Reply-To: <20130529233153.GA4587@samir>
References: <20130529233153.GA4587@samir>
Message-ID: <20130530132612.GA10614@samir>

On Thu, May 30, 2013 at 01:31:53AM +0200, Hans Ekbrand wrote:
> Dear list,
> 
> I am trying to model the probability of poverty at the individual
> level using predictors at the country level. The dependent variable is
> measuring poverty is cdepidxs, and individuals are nested in
> household/cluster/country. ("cluster" is a small area consisting of a
> few hundred households).
> 
> I want to test the effect of three predictors variables at the country
> level: loggdp, wbgi_gee, and killed.per.million. In a random intercept
> version with these variables as fixed terms they all come out as
> significant:
> 
> ## If you want to load the data set example.data, use 
> (load(url("http://dl.dropboxusercontent.com/u/99038959/data/example.data.RData")))

...

> Should I specifically specify that I don't want a random intercept for each of the variables loggdp, wgbi_gee and killed.per.million? Like this?
> 
> lmer(cdepidxs ~ (1|country) + (1|cluster) + (1|household) + (0+loggdp|rural) + (0+wbgi_gee|rural) + (0+killed.per.million|rural) + (1|rural), data = example.data)

After thinking about it one more time, I came to the conclusion that "rural" should be a fixed term, and then the problem just goes away:

lmer(cdepidxs ~ (1|country) + (1|cluster) + (1|household) + loggdp*rural + wbgi_gee*rural + killed.per.million*rural, data = example.data)

work just fine.


From rhtardin at gmail.com  Thu May 30 17:12:10 2013
From: rhtardin at gmail.com (Rodrigo Tardin)
Date: Thu, 30 May 2013 12:12:10 -0300
Subject: [R-sig-ME] Confidence intervals in GAMM4
Message-ID: <CAE5HZZ+h=qE4Ntrn=1ofwyxU24WrJQCPYki2Px34UgsEPn+1sw@mail.gmail.com>

Um texto embutido e sem conjunto de caracteres especificado foi limpo...
Nome: n?o dispon?vel
Url: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130530/7b14bdfe/attachment.pl>

From daniela at uoregon.edu  Thu May 30 23:30:16 2013
From: daniela at uoregon.edu (Daniel Anderson)
Date: Thu, 30 May 2013 14:30:16 -0700
Subject: [R-sig-ME] LMER False Convergence (8)
Message-ID: <407C1C84-C54B-482C-96F6-043662AC9D78@uoregon.edu>

Dear all, 

I am trying to fit a cross-classified growth model with the lme4 package. The model is cross-classified because students moved between schools during the three years of the study (for a similar application, see Luo & Kwok, 2012). I have estimated the following model with both lme4 and the HLM software.

m.1<-lmer(MthScale ~ Clock + (Clock | mastid) + (Clock | School), data=dta2, REML = F, verbose = T)

where, 
MthScale is a mathematics achievement test, 
Clock is a time variable coded 0, 1, 2,
mastid = id for students,
School = id for schools.

When I fit the model I get the following error message "In mer_finalize(ans) : false convergence (8)". Yet, my results are quite similar to the results I obtained from the HLM software, which gave me no such error (see attached).

I have seen that some people have had success using David Hughes approach (http://davidhughjones.blogspot.com/2009/11/lme-false-convergence.html), but that did not work for me. I also read that it could be a result of the optimizer not reaching its predefined minimum, but that the result is likely to be a minimum (https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q1/015743.html). Finally, I tried fitting the following much simpler model, and still received the same error message:

m.2<-lmer(MthScale ~ Clock + (Clock | mastid), data=dta2, REML = F, verbose = T)

So, my questions are (a) are there any other ideas for getting the model to converge without the warning message, and/or (b) is it safe to continue with model building despite the warning?

Below is the output from the verbose = T argument. I've also attached a word document comparing the estimates between lme4 and the HLM software.

M.1<-lmer(MthScale ~ Clock + (Clock | mastid) + (Clock | School), data=dta2, 
+ REML = F, verbose = T)
 0:     754814.32:  1.01846 0.785304  0.00000 0.120908 0.0932292  0.00000
 1:     732113.86:  1.70314 0.384148 0.360769 0.600647 0.191005 0.0204139
 2:     723310.96:  1.68742 0.358177 0.164101 0.604350 0.200466 0.0158740
 3:     722264.35:  1.71511 0.320882 0.0856711 0.608439 0.211105 0.0130309
 4:     721675.24:  1.77901 0.280868 0.136016 0.614167 0.224845 0.0103563
 5:     721117.85:  1.90428 0.192638 0.0428979 0.608443 0.261661 -0.00547840
 6:     720620.64:  2.03047 0.133416 0.127071 0.663862 0.301313 -0.0567497
 7:     720235.93:  2.11910 0.209014 0.0676060 0.782523 0.253309 -0.0739699
 8:     720186.03:  2.08768 0.189996 0.0772091 0.804431 0.319605 -0.0664654
 9:     720183.13:  2.05956 0.147005 0.0884886 0.790482 0.261332 -0.0624898
10:     720173.52:  2.05849 0.146184 0.0791790 0.790283 0.263354 -0.0624119
11:     720168.15:  2.05605 0.139973 0.0832560 0.785274 0.265621 -0.0613035
12:     720166.44:  2.05367 0.134041 0.0812404 0.778806 0.267586 -0.0598906
13:     720166.44:  2.05367 0.134041 0.0812401 0.778806 0.267586 -0.0598905
14:     720166.44:  2.05367 0.134041 0.0812401 0.778806 0.267586 -0.0598905
Warning message:
In mer_finalize(ans) : false convergence (8)

Thanks,
--
Daniel Anderson
Research Assistant
Behavioral Research and Teaching
University of Oregon

From bbolker at gmail.com  Fri May 31 03:55:41 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 31 May 2013 01:55:41 +0000 (UTC)
Subject: [R-sig-ME] LMER False Convergence (8)
References: <407C1C84-C54B-482C-96F6-043662AC9D78@uoregon.edu>
Message-ID: <loom.20130531T034937-580@post.gmane.org>

Daniel Anderson <daniela at ...> writes:

> Dear all, 
 
> I am trying to fit a cross-classified growth model with the lme4
> package. The model is cross-classified because students moved
> between schools during the three years of the study (for a similar
> application, see Luo & Kwok, 2012). I have estimated the following
> model with both lme4 and the HLM software.
 
> m.1<-lmer(MthScale ~ Clock + (Clock | mastid) + (Clock | School), 
> data=dta2, REML = F, verbose = T)
> 
> where, 
> MthScale is a mathematics achievement test, 
> Clock is a time variable coded 0, 1, 2,
> mastid = id for students,
> School = id for schools.


>  When I fit the model I get the following error message "In
> mer_finalize(ans) : false convergence (8)". Yet, my results are
> quite similar to the results I obtained from the HLM software, which
> gave me no such error (see attached).
 
> I have seen that some people have had success using David Hughes
> approach
> (http://davidhughjones.blogspot.com/2009/11/lme-false-convergence.html),
> but that did not work for me. I also read that it could be a result
> of the optimizer not reaching its predefined minimum, but that the
> result is likely to be a minimum
> (https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q1/015743.html).
>  Finally, I tried

> fitting the following much simpler model, and still received the
>  same error message:
 
> m.2<-lmer(MthScale ~ Clock + (Clock | mastid),
>  data=dta2, REML = F, verbose = T)
> 
> So, my questions are (a) are there any other ideas for
>   getting the model to converge without the warning
> message, and/or (b) is it safe to continue with model 
> building despite the warning?
 
> Below is the output from the verbose = T argument. I've also
> attached a word document comparing the estimates between lme4 and
> the HLM software.

The Word document didn't make it to the list, I think (probably
got stripped by the mailing list software).  Any chance of
attaching as a text file?

  If the estimates from HLM and lme4 are close (i.e. the differences
are much smaller than the estimated standard errors), then I can't
see any reason to worry very much ...

  Are you willing to give the development version of lme4
a try?  It's slightly more robust and eminently more tunable.
I think you should be able to install it via

install.packages("lme4",repos=c("http://lme4.r-forge.r-project.org/repos",
         getOption("repos")))


From c.acharya at duke.edu  Fri May 31 01:45:14 2013
From: c.acharya at duke.edu (Chaitanya Acharya)
Date: Thu, 30 May 2013 23:45:14 +0000
Subject: [R-sig-ME] help with simulations
Message-ID: <17F51BEF-B85F-4325-A6F8-E2A20F962138@duke.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130530/c80fe4d8/attachment.pl>

From djauoregon at gmail.com  Fri May 31 16:40:34 2013
From: djauoregon at gmail.com (Daniel Anderson)
Date: Fri, 31 May 2013 07:40:34 -0700
Subject: [R-sig-ME] LMER False Convergence (8)
In-Reply-To: <mailman.4.1369994402.26551.r-sig-mixed-models@r-project.org>
References: <mailman.4.1369994402.26551.r-sig-mixed-models@r-project.org>
Message-ID: <97CE2057-0F5D-421C-AFFA-76EFBA2A929A@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130531/0924c508/attachment.pl>

From arzhetsk at medicine.bsd.uchicago.edu  Fri May 31 16:46:21 2013
From: arzhetsk at medicine.bsd.uchicago.edu (Rzhetsky, Andrey [BSD] - MED)
Date: Fri, 31 May 2013 14:46:21 +0000
Subject: [R-sig-ME] three-levels of nesting in poisson mixed effect
	regression?
Message-ID: <CDCE21EC.E429%arzhetsk@medicine.bsd.uchicago.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130531/0bf9261f/attachment.pl>

From bbolker at gmail.com  Fri May 31 19:37:17 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 31 May 2013 17:37:17 +0000 (UTC)
Subject: [R-sig-ME] LMER False Convergence (8)
References: <mailman.4.1369994402.26551.r-sig-mixed-models@r-project.org>
	<97CE2057-0F5D-421C-AFFA-76EFBA2A929A@gmail.com>
Message-ID: <loom.20130531T193031-227@post.gmane.org>

Daniel Anderson <djauoregon at ...> writes:

>

 [snip]

> I tried installing the source version of lme4, as you suggested,
>  but still did not have success. I did get the
> following error message, however, so if the -3 
> version is significantly
> different than the -2 version I
> was able to install then it could still be an option. 
> 
> Warning: unable to access index for repository
> http://lme4.r-forge.r-project.org/repos/bin/windows/contrib/3.0
> 
>   There is a binary version available (and will be installed) but the
>   source version is later:
>          binary       source
> lme4 0.999999-2 0.99999911-3

  I've added a more recent binary; it may take up to 24 hours for the
r-forge repository to update.
If you're in a big hurry you can download the zip file from

https://r-forge.r-project.org/scm/viewvc.php/*checkout*/www/repos/bin/windows/
     contrib/3.0/
    lme4_0.99999911-3.zip?revision=1816&root=lme4

(URL broken to make Gmane happy, sorry)

and install it using repos=NULL

  The differences you're seeing below wouldn't worry me *very* much --
the results are certainly qualitatively similar -- but it would be
nice if the devel verion of lme4 happened to match HLM even more
closely (it's not guaranteed of course that HLM is right and lme4 is
wrong, but HLM has probably still been more thoroughly tested ...)
 

> 
> Thanks again for your help,
> Daniel
> 
> Parameter                            HLM                            lme4
> 
> Fixed Effects                                                      
> Intercept                         251.032824 (0.102705)   251.03099  (0.10443)
> Growth                               5.911175 (0.04071)     5.90961 (0.03776
> Variance Components                                                      
       
> Student intercept              41.38687                              41.51581
> Student slope                     0.50270                             0.45086
> Within student                   9.78905                              9.84352
> School intercept                 5.72659                              5.97047
> School slope                       0.85956                            0.72623
> 

  [snip]


From c.acharya at duke.edu  Fri May 31 21:33:19 2013
From: c.acharya at duke.edu (Chaitanya Acharya)
Date: Fri, 31 May 2013 19:33:19 +0000
Subject: [R-sig-ME] help with simulations
In-Reply-To: <2EEE8D94-6788-457B-9888-E352C862A0D6@stanford.edu>
References: <17F51BEF-B85F-4325-A6F8-E2A20F962138@duke.edu>
	<2EEE8D94-6788-457B-9888-E352C862A0D6@stanford.edu>
Message-ID: <B6202245-9069-42DE-A07F-133C6D565356@duke.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130531/3a2535de/attachment.pl>

From bbolker at gmail.com  Sat Jun  1 00:09:40 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 31 May 2013 22:09:40 +0000 (UTC)
Subject: [R-sig-ME] Design Matrix for Random effects
References: <6BE01C2A2779524CA4D2DCC242CF5F963DF91901@SIXPRD0111MB395.apcprd01.prod.exchangelabs.com>
	<000c01ce5bae$62cfdd70$286f9850$@net>
	<51A4DEF3.4020401@gmail.com> <51A4E979.9040607@utoronto.ca>
Message-ID: <loom.20130601T000441-537@post.gmane.org>

Steve Walker <steve.walker at ...> writes:

> 
> Hi Robert,
> 
> In stable (i.e. cran) lme4, Zt can be obtained without fitting the model 
> using this command:
> 
> lmer(Reaction ~ Days + (Days|Subject), data=sleepstudy, doFit = 
> FALSE)$FL$trms[[1]]$Zt
> 
> In development (i.e. github) lme4, you can use this command:
> 
> lFormula(Reaction ~ Days + (Days|Subject), data=sleepstudy)$reTrms$Zt
> 
> or these two:
> 
> dv <- lmer(Reaction ~ Days + (Days|Subject), data=sleepstudy, 
> devFunOnly 
> = TRUE)
> environment(dv)$pp$Zt
> 
> Cheers,
> Steve
> 

  It can be done even one step more directly:

mkReTrms(list(quote(Days|Subject)),sleepstudy)$Zt

the slightly convoluted form of the first argument is because
mkReTrms (see ?mkReTrms) wants a list of the random-effects
bits extracted from the formula, so it needs to be a list
of 'language' objects.  Alternatively:

mkReTrms(findbars(~(Days|Subject)),sleepstudy)$Zt

 I have a minor preference for these because they depend
a little less on the detailed form in which things are
stored in the package.

  Ben Bolker


From daniela at uoregon.edu  Sat Jun  1 00:36:47 2013
From: daniela at uoregon.edu (Daniel Anderson)
Date: Fri, 31 May 2013 15:36:47 -0700
Subject: [R-sig-ME] LMER False Convergence (8)
In-Reply-To: <mailman.6499.1370028818.4595.r-sig-mixed-models@r-project.org>
References: <mailman.6499.1370028818.4595.r-sig-mixed-models@r-project.org>
Message-ID: <4004BD1D-5C89-4399-856F-7950C47D480B@uoregon.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130531/2bfb0e48/attachment.pl>

From bbolker at gmail.com  Sat Jun  1 00:44:26 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 31 May 2013 22:44:26 +0000 (UTC)
Subject: [R-sig-ME] LMER False Convergence (8)
References: <mailman.6499.1370028818.4595.r-sig-mixed-models@r-project.org>
	<4004BD1D-5C89-4399-856F-7950C47D480B@uoregon.edu>
Message-ID: <loom.20130601T004237-519@post.gmane.org>

Daniel Anderson <daniela at ...> writes:

> 
> Thanks again Ben, I went ahead and used the zip file from the
> link you sent to install lme4-3. This time I did
> not get the convergence warning. However, the verbose=T 
> statement did not appear to work (i.e., it didn't
> print the iteration history). Probably not a big deal,
>  but I thought it was odd and wondered if it might also
> not be printing the warning message despite having the same issue.

  Well, this is a development version, so there might be something
funny -- I'll check.

> 
> Below, I've placed my results from the same model for all 
> three programs: HLM, lme4-2, and lme4-3. I also
> added the correlation between the variance components into
>  this table, because with lme4-3 I get an
> estimated correlation between the random student intercept/slope 
> of 1.0 (which was not the case with the
> other programs). 
> 
> So, at this point I think I'm going to run with lme4-2,
> and just ignore the convergence warning, unless you'd
> suggest otherwise?

  That seems perfectly reasonable.  Would it be possible for you
to send your data so we can have a look and see what's happening?
(Ideally you could send it in an anonymized form so that we could
use it for tests/examples in future versions of the package, but
for now just having it for private use among the lme4 developers
would be great.)

  thanks
    Ben


From daniela at uoregon.edu  Sat Jun  1 19:26:49 2013
From: daniela at uoregon.edu (Daniel Anderson)
Date: Sat, 1 Jun 2013 10:26:49 -0700
Subject: [R-sig-ME] LMER False Convergence (8)
In-Reply-To: <mailman.4.1370080802.8429.r-sig-mixed-models@r-project.org>
References: <mailman.4.1370080802.8429.r-sig-mixed-models@r-project.org>
Message-ID: <F43B594A-7F19-4746-BA32-D2A7218B954E@uoregon.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130601/01de565a/attachment.pl>

From arzhetsk at medicine.bsd.uchicago.edu  Sat Jun  1 21:41:22 2013
From: arzhetsk at medicine.bsd.uchicago.edu (Rzhetsky, Andrey [BSD] - MED)
Date: Sat, 1 Jun 2013 19:41:22 +0000
Subject: [R-sig-ME] three-levels of nesting in poisson mixed effect
	regression?
Message-ID: <CDCFB88E.E506%arzhetsk@medicine.bsd.uchicago.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130601/034204dd/attachment.pl>

From bbolker at gmail.com  Sat Jun  1 22:49:31 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 1 Jun 2013 20:49:31 +0000 (UTC)
Subject: [R-sig-ME] LMER False Convergence (8)
References: <mailman.4.1370080802.8429.r-sig-mixed-models@r-project.org>
	<F43B594A-7F19-4746-BA32-D2A7218B954E@uoregon.edu>
Message-ID: <loom.20130601T223939-816@post.gmane.org>

Daniel Anderson <daniela at ...> writes:

> 
> Hey Ben, I would love to provide the dataset but 
> unfortunately I don't think it's possible. It's an entire
> state's educational accountability testing data and the state 
> that we got the it from has required we use
> all sorts of securities when accessing it. It's kind of silly 
> how many regulations they have on it
> actually, considering it is already completely de-identified,
>  but such is life. Thanks again for all
> your help though, I really appreciate it.
> 
> Daniel

  There are a few other things we can try remotely to determine
whether the correlation=1 is correct (and HLM and the old version
of lme4 are getting not-quite-the-right answer) or the smaller
correlation of around 0.87 is more correct -- it would just
have been easier to do the experimentation myself rather than
by remote control, as it were.

  Some of the steps (without going into detail) are

(1) compare deviances estimated from the different methods;
if they look like they're estimated on the same scale, see whether
how the devel-lme4 deviance compares to the others
(2) construct a likelihood profile and see if the correlation
parameter is really maximum at the edge
(3) try starting lme4 from the parameters estimated by the other
programs, and/or evaluating the deviance at those parameters
(this might require some reparameterization/hacking)

  I'm happy to continue the conversation offline.  (I have
a vested interest in making sure that the development version
of lme4 does _not_ do worse than the currently released version
under any examples that I can find out about ...)


> 
> > From: Ben Bolker <bbolker at ...>
> > Subject: Re: [R-sig-ME] LMER False Convergence (8)
> > Date: May 31, 2013 3:44:26 PM PDT
> > To: r-sig-mixed-models at ...
> > 
> > 
> > Daniel Anderson <daniela <at> ...> writes:
> > 
> >> 
> >> Thanks again Ben, I went ahead and used the zip file from the
> >> link you sent to install lme4-3. This time I did
> >> not get the convergence warning. However, the verbose=T 
> >> statement did not appear to work (i.e., it didn't
> >> print the iteration history). Probably not a big deal,
> >> but I thought it was odd and wondered if it might also
> >> not be printing the warning message despite having the same issue.
> > 
> >  Well, this is a development version, so there might be something
> > funny -- I'll check.
> > 
> >> 
> >> Below, I've placed my results from the same model for all 
> >> three programs: HLM, lme4-2, and lme4-3. I also
> >> added the correlation between the variance components into
> >> this table, because with lme4-3 I get an
> >> estimated correlation between the random student intercept/slope 
> >> of 1.0 (which was not the case with the
> >> other programs). 
> >> 
> >> So, at this point I think I'm going to run with lme4-2,
> >> and just ignore the convergence warning, unless you'd
> >> suggest otherwise?
> > 
> >  That seems perfectly reasonable.  Would it be possible for you
> > to send your data so we can have a look and see what's happening?
> > (Ideally you could send it in an anonymized form so that we could
> > use it for tests/examples in future versions of the package, but
> > for now just having it for private use among the lme4 developers
> > would be great.)
> > 
> >  thanks
> >    Ben
> > 
> > 
> > 
> > 
> > _______________________________________________
> > R-sig-mixed-models mailing list
> > R-sig-mixed-models at ...
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> Thanks,
> --
> Daniel Anderson
> Research Assistant
> Behavioral Research and Teaching
> University of Oregon
> 
> 	[[alternative HTML version deleted]]
> 
>


From arzhetsk at medicine.bsd.uchicago.edu  Sat Jun  1 21:04:49 2013
From: arzhetsk at medicine.bsd.uchicago.edu (Rzhetsky, Andrey [BSD] - MED)
Date: Sat, 1 Jun 2013 19:04:49 +0000
Subject: [R-sig-ME] three-levels of nesting in poisson mixed effect
	regression?
Message-ID: <CDCFAED6.E4F7%arzhetsk@medicine.bsd.uchicago.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130601/476488d6/attachment.pl>

From christerwi at gmail.com  Sun Jun  2 18:44:23 2013
From: christerwi at gmail.com (Christoph Terwitte)
Date: Sun, 2 Jun 2013 18:44:23 +0200
Subject: [R-sig-ME] MCMCglmm evaluates distributions differently for
	different orderings of (unordered) response variables
Message-ID: <F40C48E2-C7AE-4A6F-AEF4-C8DA816F93BC@gmail.com>

Dear list members,

I am evaluating subject choices between three possible responses in three conditions. 
Each of 10 subject made the choice in six variations in the three conditions. I therefore want to include subject-offsets in my model, as well as variation-offsets (variations are repeated between conditions). I also factor out condition-specific subject preferences, even though this has little effect on the model outcomes. 
I have had some success modeling the outcome with MCMCglmm, but, to my surprise, the outcome of the MCMCglmm model depends on the ordering of the outcome factor (unordered  in my data frame). below are the summaries of two (converged) MCMCglmm models that I expected to give me the same results: note that the calls are the same, as are the data frames.

Any insights why this happens, if there are more appropriate packages for my purposes, or how to better interpret my results would be greatly appreciated.
Thank you, list!

Christoph
ps: since I am new to the list, i do not know if I can attach code or data frame files? any advice there, too, would be appreciated!
pps: these are my data, script, and summaries:

data frame summary:
> str(christerwi.data)
'data.frame':	154 obs. of  4 variables:
 $ subject  : Factor w/ 10 levels "CC","ChDe","CiDe",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ theme    : Factor w/ 12 levels "sonnenaufgang",..: 12 12 12 11 11 11 10 10 10 9 ...
 $ condition: Factor w/ 3 levels "base","test1",..: 2 1 3 2 1 3 2 1 3 2 ...
 $ choice   : Factor w/ 3 levels "a","b","c": 1 3 1 2 2 1 2 1 1 2 ?

> head(christerwi.data,4)
   subject     theme condition choice
5       CC bauernhof     test1      a
9       CC bauernhof      base      c
14      CC bauernhof     test2      a
19      CC    buffet     test1      b

> with(christerwi.data, table(condition, choice))
         choice
condition  a  b  c
    base  24 16 13
    test1 30 10  6
    test2 26 24  5

# for prior specification
k <- 3
I <- diag(k-1)
J <- matrix(rep(1, (k-1)^2), c(k-1, k-1))

# here is the model specification:
mcmcglmm.christerwi<-MCMCglmm(fixed=choice~condition, random = ~idh(condition):subject+subject+theme,data = christerwi.data,rcov = ~us(trait):units,
                              family = "categorical",nitt = 200000,burnin = 5000,thin=150,singular.ok=TRUE, verbose=FALSE,
                              prior=list(R = list(fix=1,V = (1/3)*(I+J)),
                                         G = list(G1 = list(V = diag(3)*0.2,nu = 1),
                                                  G2 = list(V = 0.2, nu = 1), 
                                                  G3 = list(V = 0.2, nu = 1))))

autocorrelation(mcmcglmm.christerwi$Sol) shows that the autocorrelation between successive draws with this combination of 'nitt', 'burnin', and 'thin' is below 0.1. :
, , (Intercept)

          (Intercept) conditiontest1 conditiontest2
Lag 0     1.000000000   -0.610678249    -0.65585856
Lag 100   0.030298125   -0.031276267    -0.01295414 (truncated)

# the same is true of all VCV draws.

# and now the summary indicates that the distribution differences are not significant between the various levels:
summary(mcmcglmm.christerwi)
?
 Location effects: choice ~ condition 

               post.mean l-95% CI u-95% CI eff.samp  pMCMC  
(Intercept)     -0.57857 -1.67346  0.43472     1527 0.2290  
conditiontest1  -1.03532 -2.33849  0.02690     1456 0.0634 .
conditiontest2  -0.05335 -1.08068  1.10419     1333 0.8841  

# NOW BUILD MODEL ON REORDERED OUTCOME VARIABLE:
> christerwi.data$choice<-relevel(christerwi.data$choice, ref='c')
> with(christerwi.data, table(condition, choice))
         choice
condition  c  a  b
    base  13 24 16
    test1  6 30 10
    test2  5 26 24

# now running the same model as above on this data:
mcmcglmm.christerwi.c<-MCMCglmm(fixed=choice~condition, random = ~idh(condition):subject+subject+theme,data = christerwi.data,rcov = ~us(trait):units,
                                family = "categorical",nitt = 300000,burnin = 10000,thin=200,singular.ok=TRUE, verbose=FALSE,
                                prior=list(R = list(fix=1,V = (1/3)*(I+J)),
                                           G = list(G1 = list(V = diag(3)*0.2,nu = 1),
                                                    G2 = list(V = 0.2, nu = 1), 
                                                    G3 = list(V = 0.2, nu = 1))))


# after again verifying the low autocorrelation between successive draws, I check the summary and find this:
summary(mcmcglmm.christerwi.c)
 Location effects: choice ~ condition 

               post.mean l-95% CI u-95% CI eff.samp pMCMC  
(Intercept)      1.03562 -0.56164  2.78721   1047.5 0.183  
conditiontest1   1.47854 -1.01625  3.61806    696.1 0.139  
conditiontest2   1.75178 -0.08553  3.60983   1322.5 0.051 .

From jwiley.psych at gmail.com  Sun Jun  2 23:49:23 2013
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Sun, 2 Jun 2013 14:49:23 -0700
Subject: [R-sig-ME] issues with weights in glmer (or glmmADMB)
Message-ID: <CANz9Z_LeTTMYG6vnL=Wt3PDk9A1AkuOxvGx_HgyU==NqJMudKA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130602/0fac1005/attachment.pl>

From Thierry.ONKELINX at inbo.be  Mon Jun  3 13:28:24 2013
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 3 Jun 2013 11:28:24 +0000
Subject: [R-sig-ME] issues with weights in glmer (or glmmADMB)
In-Reply-To: <CANz9Z_LeTTMYG6vnL=Wt3PDk9A1AkuOxvGx_HgyU==NqJMudKA@mail.gmail.com>
References: <CANz9Z_LeTTMYG6vnL=Wt3PDk9A1AkuOxvGx_HgyU==NqJMudKA@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA7427C2B1D5B1@inbomail.inbo.be>

Dear Joshua,

The weights in a binomial glmer are used to indicate the sample size when the response is a proportion. Hence the effect on the standard errors.

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Joshua Wiley
Verzonden: zondag 2 juni 2013 23:49
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] issues with weights in glmer (or glmmADMB)

Hi All,

I have been working with a random effects binomial model (many thousands of observations, although rates of the event are low ~ .1).  I tried using analytic weights, but the results are odd --- the standard errors get much larger in some cases (e.g., 10 fold, while coefficient estimates do not change too much --- weights were scaled to sum to 1).

My other thought was to try the model using glmmADMB, but it looks like it does not support analytic weights.

IIRC, MCMCglmm also does not support weights, so I think the only other option would be glmmPQL from the MASS package.  That's not too bad as a rough approach, but would prefer a true likelihood or Bayesian approach (really, given the dataset size, a likelihood).

Thanks for any suggestions.

Cheers,

Josh


--
Joshua Wiley
Ph.D. Student, Health Psychology
University of California, Los Angeles
http://joshuawiley.com/
Senior Analyst - Elkhart Group Ltd.
http://elkhartgroup.com

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From Thierry.ONKELINX at inbo.be  Mon Jun  3 13:35:28 2013
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 3 Jun 2013 11:35:28 +0000
Subject: [R-sig-ME] three-levels of nesting in poisson mixed
	effect	regression?
In-Reply-To: <CDCFAED6.E4F7%arzhetsk@medicine.bsd.uchicago.edu>
References: <CDCFAED6.E4F7%arzhetsk@medicine.bsd.uchicago.edu>
Message-ID: <AA818EAD2576BC488B4F623941DA7427C2B1D648@inbomail.inbo.be>

Dear Andrey,

Don't use dummy variables, use a factor instead.

Then your formula reduces to

Outcomes ~ offset(log(N)) + 0 + disease:(Gender  + FE1 + FE2 + FE3) +  (0 + disease|State) + (0 + disease|County)

Gender is not suitable as random effect because it has to few levels.

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Rzhetsky, Andrey [BSD] - MED
Verzonden: zaterdag 1 juni 2013 21:05
Aan: R-SIG-Mixed-Models at R-Project.org
Onderwerp: [R-sig-ME] three-levels of nesting in poisson mixed effect regression?

Could you please help me out with notation in lme4?

I am trying to implement a bivariate county-level outcome (Poisson response with county-level offset N) over incidence of 2 diseases, dis1 and dis2, using dummy binary indicators, dis1 and dis2, and fixed effects duplicated as dis1*fixed_eff_i and dis2*fixed_eff_i.

My data is nested at several levels: states, counties, and diseases (also genders?).  Could you please help me to check/define notation  that would reflect most faithfully the 3-level structure?

This is what I have now.

Out  <- glmer(formula = Outcomes ~ 1 + offset(log(N)) + (0 + dis1|State) + (0 + dis2|County) + (0 + dis1|State) + (0 + dis2|County) + dis1.Gender + dis2.Gender + (other fixed effects), naGQ = 7,verbose=FALSE,family=poisson,REML=FALSE,data=data,na.action = na.exclude, maxIter=200000, maxFn=10000000)")

Would be very grateful for any clarification/correction.

Thank you!

Andrey


        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From spatrick at cebc.cnrs.fr  Mon Jun  3 14:15:25 2013
From: spatrick at cebc.cnrs.fr (spatrick)
Date: Mon, 03 Jun 2013 14:15:25 +0200
Subject: [R-sig-ME] Piecewise regression/threshold models
Message-ID: <WC20130603121525.840159@cebc.cnrs.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130603/0d796dd3/attachment.pl>

From strathe at sund.ku.dk  Mon Jun  3 10:25:55 2013
From: strathe at sund.ku.dk (Anders Bjerring Strathe)
Date: Mon, 3 Jun 2013 08:25:55 +0000
Subject: [R-sig-ME] MCMCglmm and left-censored data
Message-ID: <D3DE3F1835C46041B40A30A77D8EBC9C45585B06@P2KITMBX02WC01.unicph.domain>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130603/75080482/attachment.pl>

From j.hadfield at ed.ac.uk  Mon Jun  3 16:52:08 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 03 Jun 2013 15:52:08 +0100
Subject: [R-sig-ME] MCMCglmm and left-censored data
In-Reply-To: <D3DE3F1835C46041B40A30A77D8EBC9C45585B06@P2KITMBX02WC01.unicph.domain>
References: <D3DE3F1835C46041B40A30A77D8EBC9C45585B06@P2KITMBX02WC01.unicph.domain>
Message-ID: <20130603155208.78674259lfhcrzqc@www.staffmail.ed.ac.uk>

Hi,

If you add:

data$ymax<-ifelse(data$y <= log(0.4), log(0.4), data$y)

and then fit cbind(ymin, ymax) as the response you should get the  
answer you expect. In your simulation ymax is the actual value of y,  
whereas in my simulation actual values less than log(0.4) are missing  
but known to be less than log(0.4). Values greater than log(0.4) are  
uncensored. I think this is the usual definition of left-censoring (?).

Cheers,

Jarrod



Quoting Anders Bjerring Strathe <strathe at sund.ku.dk> on Mon, 3 Jun  
2013 08:25:55 +0000:

> Dear all,
>
> I am trying to fit a linear mixed model for left censored Gaussian  
> data that originates from a pedigreed population. I have used  
> MCMCglmm in the past and I want to use it for this problem as well.  
> I have simulated some data in order to understand how MCMCglmm  
> syntax should be specified.
>
> The tutorial states that for left censored data use -Inf in the 1st  
> column and for right censored data use Inf in the second column. If  
> a particular data point is not censored have the same value in both  
> columns.
>
> The R-code for my simple simulation is given below. I have  
> implemented the model in OpenBUGS and it works well by returning  
> estimates that correspond well with the true. I could fit the animal  
> model with OpenBUGS, but I have >10.000 records and it is easy (to  
> compared to BUGS) to fit an animal model with MCMCglmm, thanks to  
> Jarrod Had?eld? I get biased results with MCMCglmm and hence I think  
> that the syntax is not correct and I hope that some of you could  
> show me how it is done?
>
> Thanks a lot in advance,
> Anders Strathe
>
> # R-code
> sim <- function(N=2, M=100, cv.beta=0.75, cv.err=0.15){
>   beta <- rep(rnorm(M, mean=0, sd=cv.beta), each=N)
>   err  <- rnorm(M*N, mean=0, sd=cv.err)
>   y <- log(0.8) + beta + err
>   data.frame(grp=rep(1:M, each=N), y)
> }
>
>
> data <- sim(M=1000)
> data$ymin <- ifelse(data$y <= log(0.4), -Inf, data$y)
>
> p.var <- var(data$y, na.rm=TRUE)
> prior <- list(G=list(G1=list(V=matrix(p.var/2),n=1)),  
> R=list(V=matrix(p.var/2),n=1))
>
> m1 <- MCMCglmm(cbind(ymin, y) ~ 1, random = ~ grp,  
> family="cengaussian", data=data,
>                prior=prior, nitt=20000, thin=1, burnin=10000,
>                start= list(G=runif(1, 0, 100), R=runif(1, 0, 100)),  
> verbose=FALSE)
>
> summary(sqrt(m1$VCV))[[1]]
>
> # TRUE values: cv.beta=0.75 (grp);  cv.err=0.15 (units)
>
> # OpenBUGS model:
> model
> {
>     for (i in 1:N) {
>         y[i] ~ dnorm(beta[id[i]], tau)C( , LQD[i])
>     }
>     for (j in 1:M) {
>         beta[j] ~ dnorm(alpha, tau.id)
>     }
>     tau ~ dgamma(0.001, 0.001)
>     sigma <- 1/sqrt(tau)
>     tau.id ~ dgamma(0.001, 0.001)
>     sigma.id <- 1/sqrt(tau.id)
>     alpha ~ dnorm(0.00000E+00, 1.00000E-06)
>     mu <- exp(alpha)
> }
>
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From jwiley.psych at gmail.com  Mon Jun  3 17:08:03 2013
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Mon, 3 Jun 2013 08:08:03 -0700
Subject: [R-sig-ME] issues with weights in glmer (or glmmADMB)
In-Reply-To: <AA818EAD2576BC488B4F623941DA7427C2B1D5B1@inbomail.inbo.be>
References: <CANz9Z_LeTTMYG6vnL=Wt3PDk9A1AkuOxvGx_HgyU==NqJMudKA@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA7427C2B1D5B1@inbomail.inbo.be>
Message-ID: <CANz9Z_LK1wjhk64HFfJazbmdrrgPMGKg+vhDrPxo+LtsDhKv4Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130603/4af897e8/attachment.pl>

From j.hadfield at ed.ac.uk  Mon Jun  3 17:12:46 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 03 Jun 2013 16:12:46 +0100
Subject: [R-sig-ME] MCMCglmm evaluates distributions differently for
 different orderings of (unordered) response variables
In-Reply-To: <F40C48E2-C7AE-4A6F-AEF4-C8DA816F93BC@gmail.com>
References: <F40C48E2-C7AE-4A6F-AEF4-C8DA816F93BC@gmail.com>
Message-ID: <20130603161246.92353vhtl0i8xjsw@www.staffmail.ed.ac.uk>

Hi,

You should expect different answers depending on which category you  
have as base-line using the model you have. The model has two  
responses (trait): trait 1 is log(Pr(c1))-log(Pr(c3)) and trait 2 is  
log(Pr(c2))-log(Pr(c3)). These are the log-odds ratio of being c1  
versus c3 and the log-odds ratio of being c2 versus c3, where c3 is  
the base-line category. These two responses are indexed by the  
categorical variable `trait' in MCMCglmm.

Currently, you have ~condition as a fixed effect, which means that the  
intercept and the effect of condition is the same for the two  
responses. Depending on the choices you probably want something along  
the lines of ~trait:condition-1 so that separate effects are fitted  
for each.

~theme assumes that the between-theme variances for the two log-odds  
ratios are the same and the correlation between them is one. More  
likely you want or us(trait):theme (they have different variances and  
the correlation is to be estimated).

Only under the fully parameterised model (everything interacted with  
trait in the fixed effects, and us(trait): for the random effects)  
should you expect the models to be equivalent and not depend on the  
choice of base-line category. Even then they will be  
reparameterisations of each other and you will have to do some   
post-analysis manipulation to get the same set of numbers.

Cheers,

Jarrod







Quoting Christoph Terwitte <christerwi at gmail.com> on Sun, 2 Jun 2013  
18:44:23 +0200:

> Dear list members,
>
> I am evaluating subject choices between three possible responses in  
> three conditions.
> Each of 10 subject made the choice in six variations in the three  
> conditions. I therefore want to include subject-offsets in my model,  
> as well as variation-offsets (variations are repeated between  
> conditions). I also factor out condition-specific subject  
> preferences, even though this has little effect on the model outcomes.
> I have had some success modeling the outcome with MCMCglmm, but, to  
> my surprise, the outcome of the MCMCglmm model depends on the  
> ordering of the outcome factor (unordered  in my data frame). below  
> are the summaries of two (converged) MCMCglmm models that I expected  
> to give me the same results: note that the calls are the same, as  
> are the data frames.
>
> Any insights why this happens, if there are more appropriate  
> packages for my purposes, or how to better interpret my results  
> would be greatly appreciated.
> Thank you, list!
>
> Christoph
> ps: since I am new to the list, i do not know if I can attach code  
> or data frame files? any advice there, too, would be appreciated!
> pps: these are my data, script, and summaries:
>
> data frame summary:
>> str(christerwi.data)
> 'data.frame':	154 obs. of  4 variables:
>  $ subject  : Factor w/ 10 levels "CC","ChDe","CiDe",..: 1 1 1 1 1 1  
> 1 1 1 1 ...
>  $ theme    : Factor w/ 12 levels "sonnenaufgang",..: 12 12 12 11 11  
> 11 10 10 10 9 ...
>  $ condition: Factor w/ 3 levels "base","test1",..: 2 1 3 2 1 3 2 1 3 2 ...
>  $ choice   : Factor w/ 3 levels "a","b","c": 1 3 1 2 2 1 2 1 1 2 ?
>
>> head(christerwi.data,4)
>    subject     theme condition choice
> 5       CC bauernhof     test1      a
> 9       CC bauernhof      base      c
> 14      CC bauernhof     test2      a
> 19      CC    buffet     test1      b
>
>> with(christerwi.data, table(condition, choice))
>          choice
> condition  a  b  c
>     base  24 16 13
>     test1 30 10  6
>     test2 26 24  5
>
> # for prior specification
> k <- 3
> I <- diag(k-1)
> J <- matrix(rep(1, (k-1)^2), c(k-1, k-1))
>
> # here is the model specification:
> mcmcglmm.christerwi<-MCMCglmm(fixed=choice~condition, random =  
> ~idh(condition):subject+subject+theme,data = christerwi.data,rcov =  
> ~us(trait):units,
>                               family = "categorical",nitt =  
> 200000,burnin = 5000,thin=150,singular.ok=TRUE, verbose=FALSE,
>                               prior=list(R = list(fix=1,V = (1/3)*(I+J)),
>                                          G = list(G1 = list(V =  
> diag(3)*0.2,nu = 1),
>                                                   G2 = list(V = 0.2, nu = 1),
>                                                   G3 = list(V = 0.2,  
> nu = 1))))
>
> autocorrelation(mcmcglmm.christerwi$Sol) shows that the  
> autocorrelation between successive draws with this combination of  
> 'nitt', 'burnin', and 'thin' is below 0.1. :
> , , (Intercept)
>
>           (Intercept) conditiontest1 conditiontest2
> Lag 0     1.000000000   -0.610678249    -0.65585856
> Lag 100   0.030298125   -0.031276267    -0.01295414 (truncated)
>
> # the same is true of all VCV draws.
>
> # and now the summary indicates that the distribution differences  
> are not significant between the various levels:
> summary(mcmcglmm.christerwi)
> ?
>  Location effects: choice ~ condition
>
>                post.mean l-95% CI u-95% CI eff.samp  pMCMC
> (Intercept)     -0.57857 -1.67346  0.43472     1527 0.2290
> conditiontest1  -1.03532 -2.33849  0.02690     1456 0.0634 .
> conditiontest2  -0.05335 -1.08068  1.10419     1333 0.8841
>
> # NOW BUILD MODEL ON REORDERED OUTCOME VARIABLE:
>> christerwi.data$choice<-relevel(christerwi.data$choice, ref='c')
>> with(christerwi.data, table(condition, choice))
>          choice
> condition  c  a  b
>     base  13 24 16
>     test1  6 30 10
>     test2  5 26 24
>
> # now running the same model as above on this data:
> mcmcglmm.christerwi.c<-MCMCglmm(fixed=choice~condition, random =  
> ~idh(condition):subject+subject+theme,data = christerwi.data,rcov =  
> ~us(trait):units,
>                                 family = "categorical",nitt =  
> 300000,burnin = 10000,thin=200,singular.ok=TRUE, verbose=FALSE,
>                                 prior=list(R = list(fix=1,V = (1/3)*(I+J)),
>                                            G = list(G1 = list(V =  
> diag(3)*0.2,nu = 1),
>                                                     G2 = list(V =  
> 0.2, nu = 1),
>                                                     G3 = list(V =  
> 0.2, nu = 1))))
>
>
> # after again verifying the low autocorrelation between successive  
> draws, I check the summary and find this:
> summary(mcmcglmm.christerwi.c)
>  Location effects: choice ~ condition
>
>                post.mean l-95% CI u-95% CI eff.samp pMCMC
> (Intercept)      1.03562 -0.56164  2.78721   1047.5 0.183
> conditiontest1   1.47854 -1.01625  3.61806    696.1 0.139
> conditiontest2   1.75178 -0.08553  3.60983   1322.5 0.051 .
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From j.hadfield at ed.ac.uk  Mon Jun  3 17:40:33 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 03 Jun 2013 16:40:33 +0100
Subject: [R-sig-ME] MCMCglmm bivariate random regression
In-Reply-To: <CALQiR082W-Fha+Yrds_nwO_CvVYeYiUx9QwS95e9W9nyUXZ7fA@mail.gmail.com>
References: <CALQiR082W-Fha+Yrds_nwO_CvVYeYiUx9QwS95e9W9nyUXZ7fA@mail.gmail.com>
Message-ID: <20130603164033.19887ga6pourmlc0@www.staffmail.ed.ac.uk>

Dear Adam,

This is a complex model and I'm not sure MCMCglmm is going to be able  
to do all that you wish of it.

The key thing that you point out is that you want to estimate the  
covariance between the individual effect of a repeated measured trait  
and the residual of a non-repeated measure trait. In ASReml you can  
achieve this by having random=~us(individual) and  
rcov=~idh(trait):units, and then fix the residual (units) variance in  
the second (non-repeated measure trait) to zero.

In MCMCglmm this is not possible because the chain will not mix. I  
have suggested in the past that for these types of model the `units'  
variance could be left unfixed and the residual variance in the  
non-repeated trait estimated as the sum of the two variances, which is  
identifiable.  Alternatively the units variance could be fixed at  
something which is less than the minimum value of V_2-(C^2)/V_1  that  
has support in the posterior. Here V_2 is the residual variance in  
LBS, C is the covariance between residual LBS and the individual  
effect on body size, and V_1 is the variance of the individual effects  
on body size. By ensuring that the units variance is fixed at value  
less than this you will not have the problem that the correlation  
estimate hits the boundary conditions of -1/1.  I have not tried  
either of these solutions so you need to do some work to make sure  
what I say is sensible.

For the second problem I think you can switch syntax to  
~idh(EQ:trait):units and the LBS variances will be in position 5:8 and  
can be fixed. I keep meaning to allow direct products in the  
R-structure which should make this type of model easier to fit.

The model is complex so be careful!

Jarrod







Quoting Adam Hayward <a.hayward at sheffield.ac.uk> on Wed, 29 May 2013  
13:37:07 +0100:

> Dear list users,
>
> I wonder if anyone would be able to help me with a problem which I've been
> trying to solve for quite some time. I want to run a bivariate random
> regression, where the two dependent variables are body weight and lifetime
> breeding success. Body weight is measured multiple times per individual,
> while LBS is measured once. I then want to fit two random slopes in the
> individual-level variance component for body weight- I x A and I x E. The
> key is then to estimate the individual-level covariances involving LBS to
> look for evidence of selection on body weight and individual slopes of
> weight on A and E. Finally, I would like to fix the residual variance in
> LBS to close to zero (I appreciate that it is impossible to fix it to
> exactly zero), but I would like the residual variance in body weight to
> vary across four quartiles of E (EQ).
>
> I've been having two issues. Firstly, how to fix the residual variance in
> LBS to zero, while allowing that for body weight to vary freely. The
> problem is that when I specify "rcov = ~idh(trait:EQ):units", the resulting
> 8 x 8 VCV matrix (where only the variances are estimated), rather than
> havig elements 1-4 being the four residual variances in weight and elements
> 5-8 being those for LBS, has the weight variances at the diagonal locations
> 1,3,5, and 7 and those for LBS at 2,4,6, and 8. In the former scenario, it
> would be easy to fix the residual variances in LBS by using V = 0.001, fix
> = 5 in the prior specification, but since the weight and LBS residual
> variances alternate, this is not possible. I am yet to find a way to fix
> specific variances in the residual structure. I have been able to do this
> in ASReml, but the distribution of LBS is far from Gaussian, hence checking
> it in MCMCglmm.
>
> The second issue is that I have found it very difficult (even without
> fixing residual variances in any way) to obtain satisfactory diagnostics-
> in particular, the autocorrelation is very high for the individual VCV
> components involving LBS and the random slopes, even with a run as long as
> 10 million iterations. I though that treating LBS as zero-inflated could
> help, but have been unable it work out how to incorporate the necessary
> zipoisson prior specifications into a bivariate model.
>
> If anyone has any thoughts on fixing individual elements of the R
> structure, or on sue of zipossion errors in bivariate models, I'd be very
> grateful and pleased to hear from you.
>
> Many thanks and best wishes,
> Adam
>
> A "basic" model is shown below. Nothing is fixed, but it illustrates the
> structure of the model:
>
> prior.x0 = list (R = list (V = diag(8), n = 0.002),
>               G = list (G1 = list (V = diag(4), n = 0.002),
>                         G2 = list (V = 1, n = 0.002),
>                         G3 = list (V = diag(2), n = 0.002),
>                 G4 = list (V = 1, n = 0.002)))
>
> model.x0<-MCMCglmm(cbind(WT, LBS) ~ trait-1 + some fixed effects,
>       random = ~ us(trait + at.level(trait,1):E + at.level(trait,1):Age):ID
> + us(at.level(trait,1)):Year + us(trait):MumID + us(at.level(trait,2)):BY,
>       rcov = ~idh(trait:EQ):units, data = data, family = c("gaussian",
> "poisson"), nitt = , burnin = , thin = ,
>       DIC = TRUE, prior = prior.x0, verbose = TRUE)
>
>
>
>
>
>
>
>
>
>
> --
> Adam Hayward
> Post-Doctoral Research Associate
> Department of Animal and Plant Sciences
> Alfred Denny Building
> University of Sheffield
> Western Bank
> Sheffield S10 2TN
> UK
> http://www.huli.group.shef.ac.uk/adam-personal.html
> http://adhayward.wordpress.com/
> https://twitter.com/adhayward18
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From j.hadfield at ed.ac.uk  Mon Jun  3 17:54:05 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 03 Jun 2013 16:54:05 +0100
Subject: [R-sig-ME] MCMCglmm different random effects specifications
In-Reply-To: <CADcUn7C1kmz14hmVFmhnNpGvXhsstcfaWUtzuZht4S6bMyNbig@mail.gmail.com>
References: <CADcUn7C1kmz14hmVFmhnNpGvXhsstcfaWUtzuZht4S6bMyNbig@mail.gmail.com>
Message-ID: <20130603165405.47284ze2211c2348@www.staffmail.ed.ac.uk>

Hi Ian,

Your interpretation of the models makes sense. Note that mc1 is a  
special case of mc2 when all cells of the mc2 covariance matrix are  
identical (i.e. homogeneous variances and correlations of 1). In  
general I would fit mc3 rather than mc2 to be on the safe side:  
especially if different observers take measurements in different years  
(and vary in how good they are). The 2x2 covariance matrix of  
intercepts and slopes in mc2a can also be turned into a year by year  
covariance matrix as in mc2/mc3. Have Y as the year x year covariance  
matrix and V as the intercept/slope covariance matrix. Y[i,j] =  
V[1,1]+(year[i]+year[j])*V[1,2]+year[i]*year[j]*V[2,2]. As you point  
out mc4 would be pushing the data a little hard  - a double  
hierarchical model would probably be used in this instance where the  
individual-level variances are assumed to come from some distribution  
such as gamma or log-normal.

Cheers,

Jarrod




Quoting Ian Cleasby <i.r.cleasby at gmail.com> on Fri, 24 May 2013  
10:53:21 +0100:

> Hi,
>
> I was looking to ask a question about how one could specify and interpret
> models in MCMCglmm when looking at the between-group variability in a
> particular response variable which has been measured across different time
> periods.
>
> The examples I am working with at the moment come from studies in which we
> have repeated measures of individuals behaviour both within a year and
> across 3 years. One thing we were interested in was the consistency of the
> behavioural response both within and between years So imagine we have
> measured 10 individuals 10 different times across 3 years, giving us
> 10*10*3 = 300 total observations for a response variable y that is normally
> distributed.
>
> A relatively simple model might be:
>
>
> mc1 <-MCMCglmm(y ~ as.factor(Year), random =~ Individual, data= Data)
>
> however if I wanted to allow the between individual variance to vary by
> year I could go:
>
> mc2 <-MCMCglmm(y ~ as.factor(Year), random =~ us(as.factor(Year)):
> Individual, data= Data)
>
>
> Now, as I understand it the us structure allows me to estimate different
> between individual variances for each year but it also gives me some
> co-variances as well and it was these covariances that I wanted to be sure
> about. Following the example from the blue tits analysis in chapter 3 of
> the MCMCglmm course notes I thought that the covariances between different
> years would give an indication of whether measurements from the same
> individual but from different years were really independent. Could I then
> use this covariance between years convert it to a correlation in order to
> say whether individuals show a consistent response across years?
>
> Alternatively you could maybe year as numeric and have a continuous random
> slope approach and look at the correlation between intercept and slope?
>
>
> mc2a <-MCMCglmm(y ~ as.numeric(Year), random =~ us(1+as.numeric(Year)):
> Individual, data= Data)
>
> although I find interpretation of the correlation between slopes and
> intercepts tricky at times.
>
>
> Also, for further extensions it'd be relatively straightforward to allow
> the residual variance to differ across years as well
>
>
> mc3 <-MCMCglmm(y ~ as.factor(Year), random =~ us(as.factor(Year)):
> Individual, rcov=~idh(as.factor(Year)), data= Data)
>
> but I wasn't sure whether you'd be able to extend to further to different
> individuals
>
> e.g
>
> mc4 <-MCMCglmm(y ~ as.factor(Year), random =~ us(as.factor(Year)):
> Individual, rcov=~idh(Individual), data= Data)
>
> mainly due to a lack of samples per individual from which to estimate
> variance?
>
>
>
> Any help, advice or suggestions greatly appreciated.
>
> Thanks
>
> Ian
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From j.hadfield at ed.ac.uk  Mon Jun  3 17:54:10 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 03 Jun 2013 16:54:10 +0100
Subject: [R-sig-ME] MCMCglmm different random effects specifications
In-Reply-To: <CADcUn7C1kmz14hmVFmhnNpGvXhsstcfaWUtzuZht4S6bMyNbig@mail.gmail.com>
References: <CADcUn7C1kmz14hmVFmhnNpGvXhsstcfaWUtzuZht4S6bMyNbig@mail.gmail.com>
Message-ID: <20130603165410.1505174e5s55fqcg@www.staffmail.ed.ac.uk>

Hi Ian,

Your interpretation of the models makes sense. Note that mc1 is a  
special case of mc2 when all cells of the mc2 covariance matrix are  
identical (i.e. homogeneous variances and correlations of 1). In  
general I would fit mc3 rather than mc2 to be on the safe side:  
especially if different observers take measurements in different years  
(and vary in how good they are). The 2x2 covariance matrix of  
intercepts and slopes in mc2a can also be turned into a year by year  
covariance matrix as in mc2/mc3. Have Y as the year x year covariance  
matrix and V as the intercept/slope covariance matrix. Y[i,j] =  
V[1,1]+(year[i]+year[j])*V[1,2]+year[i]*year[j]*V[2,2]. As you point  
out mc4 would be pushing the data a little hard  - a double  
hierarchical model would probably be used in this instance where the  
individual-level variances are assumed to come from some distribution  
such as gamma or log-normal.

Cheers,

Jarrod




Quoting Ian Cleasby <i.r.cleasby at gmail.com> on Fri, 24 May 2013  
10:53:21 +0100:

> Hi,
>
> I was looking to ask a question about how one could specify and interpret
> models in MCMCglmm when looking at the between-group variability in a
> particular response variable which has been measured across different time
> periods.
>
> The examples I am working with at the moment come from studies in which we
> have repeated measures of individuals behaviour both within a year and
> across 3 years. One thing we were interested in was the consistency of the
> behavioural response both within and between years So imagine we have
> measured 10 individuals 10 different times across 3 years, giving us
> 10*10*3 = 300 total observations for a response variable y that is normally
> distributed.
>
> A relatively simple model might be:
>
>
> mc1 <-MCMCglmm(y ~ as.factor(Year), random =~ Individual, data= Data)
>
> however if I wanted to allow the between individual variance to vary by
> year I could go:
>
> mc2 <-MCMCglmm(y ~ as.factor(Year), random =~ us(as.factor(Year)):
> Individual, data= Data)
>
>
> Now, as I understand it the us structure allows me to estimate different
> between individual variances for each year but it also gives me some
> co-variances as well and it was these covariances that I wanted to be sure
> about. Following the example from the blue tits analysis in chapter 3 of
> the MCMCglmm course notes I thought that the covariances between different
> years would give an indication of whether measurements from the same
> individual but from different years were really independent. Could I then
> use this covariance between years convert it to a correlation in order to
> say whether individuals show a consistent response across years?
>
> Alternatively you could maybe year as numeric and have a continuous random
> slope approach and look at the correlation between intercept and slope?
>
>
> mc2a <-MCMCglmm(y ~ as.numeric(Year), random =~ us(1+as.numeric(Year)):
> Individual, data= Data)
>
> although I find interpretation of the correlation between slopes and
> intercepts tricky at times.
>
>
> Also, for further extensions it'd be relatively straightforward to allow
> the residual variance to differ across years as well
>
>
> mc3 <-MCMCglmm(y ~ as.factor(Year), random =~ us(as.factor(Year)):
> Individual, rcov=~idh(as.factor(Year)), data= Data)
>
> but I wasn't sure whether you'd be able to extend to further to different
> individuals
>
> e.g
>
> mc4 <-MCMCglmm(y ~ as.factor(Year), random =~ us(as.factor(Year)):
> Individual, rcov=~idh(Individual), data= Data)
>
> mainly due to a lack of samples per individual from which to estimate
> variance?
>
>
>
> Any help, advice or suggestions greatly appreciated.
>
> Thanks
>
> Ian
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From j.hadfield at ed.ac.uk  Mon Jun  3 18:05:37 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 03 Jun 2013 17:05:37 +0100
Subject: [R-sig-ME] Multivariate Response Model in MCMCglmm - Estimating
 Posterior Correlation Between Traits
In-Reply-To: <0C529B85-0B83-4EA1-9838-CE1A388CEEF9@gmail.com>
References: <0C529B85-0B83-4EA1-9838-CE1A388CEEF9@gmail.com>
Message-ID: <20130603170537.19063iabhxz3f9wk@www.staffmail.ed.ac.uk>

Hi,

1) If you only have one observation per individual you should drop the  
random effects (random=~us(trait):Bird) and have  
rcov=~us(trait):units. The posterior correlation can be found as  
posterior.cor(mc2$VCV). You could estimate both if the Bird effects  
are structured by a pedigree, but I think this is not the case.

2) The effective sample sizes are good enough that the MCMC  
approximation to the  posterior should be fairly accurate for many  
summary statistics (e.g. posterior mean).  Following the suggestion in  
1) you should get (many) more effective samples per iteration.

3) You need to add one to each of the variances prior to calculating  
the correlation in the model as you have specified it. Better to  
follow suggestion 1)

4) This is probably because you are fitting a non-identifiable set of  
parameters - try running with suggestion 1).

Sorry I took so long to answer this  - I am in the field.

Cheers,

Jarrod








Quoting Xavier Harrison <xav.harrison at gmail.com> on Fri, 17 May 2013  
17:04:40 +0100:

> Hi All
>
> I am trying to fit a bivariate response model to estimate the  
> covariance between two traits (Mass and Number of Offspring), after  
> controlling for several variables that I know affect these traits. I  
> know that Mass is affected by body size (skull length) and day of  
> season (cycle day); and suspect that number of offspring (JuvFuture)  
> is affected by NAO (njs). I have strong reason to expect a positive  
> covariance between Mass and Offspring Number, as the animals are  
> capital breeders and fuel reproductive effort from fat stores. The  
> dataset is small - 213 individuals, each measured only once, which I  
> suspect may cause problems with this kind of model. Nevertheless,  
> the modelled covariates come out as significant and in the direction  
> of effect I would expect. My questions largely pertain to the  
> estimation of the posterior correlation between traits once  
> controlling for the covariates. Questions are below, and prior,  
> model and calculation code are below that.
>
> 1 ) As I only have a single observation per individual, am I right  
> in thinking that I cannot estimate both the G and R matrix  
> simultaneously, and therefore must fix the residual matrix to a  
> small positive value like 1?
>
> 2) Should I be worried that the effective sample size for the  
> 'JuvFuture' variance is approx. half of the total expected effective  
> sample size? Is this an issue of my own (potentially poor) model  
> specification?
>
> 3) The 95% credible intervals for the mass/offspring covariance  
> cross zero, which I take to mean that one cannot accurately state  
> that there is positive covariance between the two traits. However,  
> when I scale the covariance to a correlation (code below) I get a  
> positive mean value with credible intervals that approach, but do  
> not cross zero. Is this sufficient to conclude significant posterior  
> correlation between traits once controlling for the covariates in  
> the model?
>
> 4) Assuming all so far is ok / not heretical, I have been testing  
> out sensitivity of the model to priors. If I try the parameter  
> expanded priors Jarrod Hadfield has previously suggested for such  
> models (list(V=diag(2), nu=2, alpha.mu=c(0,0), alpha.V=diag(2)*a))  
> for the G structure, I get some wild results, with a mean  
> correlation of 0.99 and then a CI of -0.8 to 0.999, so very  
> asymmetric and suspiciously high. For a previous, unrelated model I  
> ran, these priors worked well. Are the current priors ('prior 3'  
> below), overwhelming the data somehow to 'force' a positive  
> correlation? The symmetry of the CIs around the mean for prior3 are  
> more reassuring than the hugely asymmetric CIs on the parameter  
> expanded priors, but that could just reflect a lack of understanding  
> on my part.
>
>  Any help greatly appreciated.
>
> Xav
>
>
>
> #Prior
> prior3 <- list( R=list(V=diag(2),fix=1), G=list(G1=list(V=diag(2),nu=0.5)) )
>
> #Model
> mc2<-MCMCglmm(cbind(Mass,JuvFuture)~trait-1  
> +at.level(trait,1):poly(cycleday,2)+at.level(trait,1):Skull +  
> at.level(trait,2):njs ,random=~us(trait):Bird   
> ,rcov=~idh(trait):units,prior=prior3,data=allstage,family=c("gaussian","poisson"),verbose=F,pr=T,nitt=250000,burnin=50000,thin=50)
>
> #Estimate Mode and 95% CI of Posterior Correlation
> posterior.mode(mc2$VCV[,2] / (sqrt(mc2$VCV[,1]) * sqrt(mc2$VCV[,4])))
> HPDinterval(mc2$VCV[,2] / (sqrt(mc2$VCV[,1]) * sqrt(mc2$VCV[,4])))
> 	#Gives mean = 0.47; 95%CI = 0.06 - 0.85
>
> #Output
>  Iterations = 50001:249951
>  Thinning interval  = 50
>  Sample size  = 4000
>
>  DIC: 1334.423
>
>  G-structure:  ~us(trait):Bird
>
>                          post.mean   l-95% CI  u-95% CI eff.samp
> Mass:Mass.Bird           9009.4427 7341.21278 1.080e+04     4000
> JuvFuture:Mass.Bird        21.6487   -1.59616 4.626e+01     2988
> Mass:JuvFuture.Bird        21.6487   -1.59616 4.626e+01     2988
> JuvFuture:JuvFuture.Bird    0.2813    0.05117 5.705e-01     2206
>
>  R-structure:  ~idh(trait):units
>
>                 post.mean l-95% CI u-95% CI eff.samp
> Mass.units              1        1        1        0
> JuvFuture.units         1        1        1        0
>
>  Location effects: cbind(Mass, JuvFuture) ~ trait - 1 +  
> at.level(trait, 1):poly(cycleday, 2) + at.level(trait, 1):Skull +  
> at.level(trait, 2):njs
>
>                                       post.mean  l-95% CI  u-95% CI  
> eff.samp  pMCMC
> traitMass                             -134.0018 -532.3044  311.4352   
>    4000 0.5155
> traitJuvFuture                          -0.7929   -1.0669   -0.5184   
>    3119 <3e-04 ***
> at.level(trait, 1):poly(cycleday, 2)1 2515.7841 2256.6187 2781.0072   
>    4231 <3e-04 ***
> at.level(trait, 1):poly(cycleday, 2)2  407.4622  136.2618  660.5247   
>    4000 0.0015 **
> at.level(trait, 1):Skull                21.9526   16.9723   26.6290   
>    4000 <3e-04 ***
> at.level(trait, 2):njs                  -0.9975   -1.3345   -0.7135   
>    3841 <3e-04 ***
> ---
>
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From j.hadfield at ed.ac.uk  Mon Jun  3 18:10:01 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 03 Jun 2013 17:10:01 +0100
Subject: [R-sig-ME] MCMCglmm and estimated breeding values
In-Reply-To: <517FD57B.7040605@earthlink.net>
References: <517FD57B.7040605@earthlink.net>
Message-ID: <20130603171001.21385z3ljk5jlgxw@www.staffmail.ed.ac.uk>

Hi,

rbv does not provide estaimted breeding values it simulates random  
breeding values down a pedigree (conditional on the genetic  
(co)variances provided).

To get the posterior distribution of breeding values you need to use  
MCMCglmm and specify pr=TRUE (this saves the random effects including  
the breeding values).

Cheers,

Jarrod




Quoting Liz Hare <doggene at earthlink.net> on Tue, 30 Apr 2013 10:30:19 -0400:

> Hello,
>
> Does rbv in MCMCglmm provide estimated breeding values? What does  
> the "random" in Random Estimation of breeding values mean? Sorry but  
> I can't find documentation on this. If this is not a way to get  
> EBVs, is there a way?
>
> How do I specify which trait I want breeding values for?
>
> The syntax suggested in the MCMCglmm documentation gives an  
> opportunity to give a pedigree name, but not a trait, or information  
> about the model just fitted.
>
> Thanks,
> Liz
>
>
> -- 
> Liz Hare PhD
> Dog Genetics LLC
> doggene at earthlink.net
> http://www.doggenetics.com
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From Steve.Candy at aad.gov.au  Tue Jun  4 02:14:11 2013
From: Steve.Candy at aad.gov.au (Steve Candy)
Date: Tue, 4 Jun 2013 10:14:11 +1000
Subject: [R-sig-ME] issues with weights in glmer (or glmmADMB)
 [SEC=UNCLASSIFIED]
Message-ID: <410C0E47580EB147811BB64E83936A3F68E1F7C66E@EX2K7-CCR.AAD.GOV.AU>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130604/3a7bf666/attachment.pl>

From andrewdigby at mac.com  Tue Jun  4 09:22:37 2013
From: andrewdigby at mac.com (Andrew Digby)
Date: Tue, 04 Jun 2013 19:22:37 +1200
Subject: [R-sig-ME] Autocorrelation in a GAMM for nightly time series
References: <F85D7C52-8C41-4E5E-AECD-039B0DDD9769@vuw.ac.nz>
Message-ID: <D73B95B3-5DEA-4490-9E76-07421398801A@mac.com>


Dear List,

I'm analysing call counts of a nocturnal species in response to temporal and environmental effects. Over a period of 3 years I divide each night into 10 equal-length blocks, and count the calls of each sex in each block. 

I then fit the following negative binomial GAM using mgcv:

gam(ncalls ~ sex + year + s(month) + s(time of night) + s(moon) + s(temperature) + s(rain) + offset(blocklength), family=negbin(c(1,5)), data=dc)

Where 'time of night' = 1-10 = the block number during the night, and blocklength = the length of that block (this changes throughout the year; hence the offset). 

Not surprisingly, the acf shows significant correlation between adjacent time blocks, with a periodicity of 10. This is because counts in a particular block will be similar to those in the blocks immediately before and after, and also to the same block on other nights (the species has a quite regular pattern of decreasing call rates as the night progresses).

To address these autocorrelation problems, I've tried various ARMA correlations, with correlation between time of night blocks, grouped by day (or week) and sex:

gamm( .., correlation=corARMA(form=~TimeofNight | DayofYearSex), p, q)  (p=1:3, q=0:3)
gamm( .., correlation=corARMA(form=~TimeofNight | WeekofYearSex), p, q)

This improves the ACF, but there are still correlations between residuals at same time of night - e.g. peaks every 10 lags.

My questions are:
1) Can I rely on the ACF when my time series isn't actually consecutive time bins, since it only includes each night (not full days). This means, for example, that the time lag between observations 9 & 10 (~1 hour) is much longer than that between 10 & 11 (~12 hours = daytime)?
2) (if yes to the above) How can I construct a correlation structure in a GAMM which allows for correlation between adjacent time bins within each night, and between the same time bin on different nights? 

Many thanks,

Andrew


From angel at mpi-marburg.mpg.de  Tue Jun  4 14:46:13 2013
From: angel at mpi-marburg.mpg.de (Roey Angel)
Date: Tue, 04 Jun 2013 14:46:13 +0200
Subject: [R-sig-ME] Mixed effects model with a distance matrix as a random
	effect
Message-ID: <51ADE195.9060006@mpi-marburg.mpg.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130604/3d6b03fe/attachment.pl>

From calliebaird at gmail.com  Tue Jun  4 16:01:07 2013
From: calliebaird at gmail.com (Callie Baird)
Date: Tue, 4 Jun 2013 10:01:07 -0400
Subject: [R-sig-ME] Negative Variance
Message-ID: <CANa-dmxp8-E9p8bceoc6rnpsAHQDyjd1rX0MBMJyPURvF1pbJQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130604/43ec324a/attachment.pl>

From klasen at mpipz.mpg.de  Tue Jun  4 16:23:59 2013
From: klasen at mpipz.mpg.de (Jonas Klasen)
Date: Tue, 04 Jun 2013 16:23:59 +0200
Subject: [R-sig-ME] Mixed effects model with a distance matrix as a
 random effect
In-Reply-To: <51ADE195.9060006@mpi-marburg.mpg.de>
References: <51ADE195.9060006@mpi-marburg.mpg.de>
Message-ID: <51ADF87F.5060304@mpipz.mpg.de>

Hi Roey,
do you mean as Z-matrix or as var-covar relationship matrix? For the 
later see lmekin (coxme package). There you can specify a similarity 
matrix (K) for a random effect (u):
u ~ N(0, sigma_u^2 K)

or one of the following packages: regress, rrBLUP, EMMA 
(http://mouse.cs.ucla.edu/emma/)

Bests
Jonas

On Tue 04 Jun 2013 02:46:13 PM CEST, Roey Angel wrote:
> Hi,
> I'm trying to build a mixed-effects model in which I'd like to include
> either a distance matrix as a random effect.
> The troubles I've had are that function lmer() in package lme4 only accepts a data frame column as a random factor and not a distance matrix.
>
> Is there a way around it?
>
> Thanks in advance
> Roey
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--
__________________________________________________

 Jonas Klasen
 PhD student
 Genome Plasticity and Computational Genetics
 Max Planck Institute for Plant Breeding Research


From bbolker at gmail.com  Tue Jun  4 17:42:57 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 4 Jun 2013 15:42:57 +0000 (UTC)
Subject: [R-sig-ME] issues with weights in glmer (or glmmADMB)
	[SEC=UNCLASSIFIED]
References: <410C0E47580EB147811BB64E83936A3F68E1F7C66E@EX2K7-CCR.AAD.GOV.AU>
Message-ID: <loom.20130604T145428-990@post.gmane.org>

Steve Candy <Steve.Candy at ...> writes:

> 
> I am yet to see any response from the developers/maintainers of
> lme4 with respect to my posting from 25
> Feburary on the R-sig-mixed-models Digest, Vol 74, Issue 40
> 
> 5. Re: lmer residual variance estimate with prior weights (lmer
> 
>       wrong, lme and asreml correct) [SEC=UNCLASSIFIED] (Steve Candy)
> 
> The regression coefficients from lmer are correct 
> but the standard errors are way too small in my example
> with prior (or "analytical") weights where it 
> was not appropriate to scale the weights to sum to 1.
> As previous postings note, using prior weights of sample 
> sizes when binomial proportions are the response
> variable is a special case but I am not confident to use lmer 
> with prior weights until the issue my above
> posting raises gets some traction.

   Sorry this slipped through the cracks.  We will take a look;
if you can (re)post the query at https://github.com/lme4/lme4/issues?state=open
(the new site for bug/feature requests) that would help us out ...

  cheers
    Ben Bolke


From bates at stat.wisc.edu  Tue Jun  4 17:46:24 2013
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 4 Jun 2013 10:46:24 -0500
Subject: [R-sig-ME] Negative Variance
In-Reply-To: <CANa-dmxp8-E9p8bceoc6rnpsAHQDyjd1rX0MBMJyPURvF1pbJQ@mail.gmail.com>
References: <CANa-dmxp8-E9p8bceoc6rnpsAHQDyjd1rX0MBMJyPURvF1pbJQ@mail.gmail.com>
Message-ID: <CAO7JsnQnrvJVprpGWmbujzLTN+DZC1CSf4REsXX4jJkkNw94iw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130604/83d25de6/attachment.pl>

From bbolker at gmail.com  Tue Jun  4 17:44:51 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 4 Jun 2013 15:44:51 +0000 (UTC)
Subject: [R-sig-ME] Negative Variance
References: <CANa-dmxp8-E9p8bceoc6rnpsAHQDyjd1rX0MBMJyPURvF1pbJQ@mail.gmail.com>
Message-ID: <loom.20130604T174312-293@post.gmane.org>

Callie Baird <calliebaird at ...> writes:

> 
> I am trying to fit multilevel models, allowing negative variance estimates.
>  Is there a way to allow negative variance estimates as in nobound in SAS?
> 
> Thanks,
> 
> Rachel Baird
> 

  I don't know of one.  This is typically a 'feature' of 
method-of-moments estimators; most of the approaches I know of
that are implemented in R use Bayesian or (restricted) maximum
likelihood approaches for which negative variances would be
completely nonsensical ...

  Just out of curiosity, why would you _want_ negative variance
estimates ... ?  The only reason I can think of would be to
match previous estimates ...

  Ben Bolker


From j.hadfield at ed.ac.uk  Tue Jun  4 18:00:03 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 04 Jun 2013 17:00:03 +0100
Subject: [R-sig-ME] Negative Variance
In-Reply-To: <loom.20130604T174312-293@post.gmane.org>
References: <CANa-dmxp8-E9p8bceoc6rnpsAHQDyjd1rX0MBMJyPURvF1pbJQ@mail.gmail.com>
	<loom.20130604T174312-293@post.gmane.org>
Message-ID: <20130604170003.145836zbgp4djri8@www.staffmail.ed.ac.uk>

Hi,

Negative variance estimates could make sense if viewed as covariances.  
For example, you could imagine controlling the amount of food for a  
nest of chicks very carefully such that negative correlations between  
the weights of nest-mates exist because of competition (if I take a  
large slice of the pie you're left with a little slice). Having a  
negative estimate of the nest variance would then make sense if viewed  
as an estimate of the covariance. asreml-R will allow you to let the  
variance go negative (or model them as residual correlations if you  
prefer).

Cheers,

Jarrod


Quoting Ben Bolker <bbolker at gmail.com> on Tue, 4 Jun 2013 15:44:51  
+0000 (UTC):

> Callie Baird <calliebaird at ...> writes:
>
>>
>> I am trying to fit multilevel models, allowing negative variance estimates.
>>  Is there a way to allow negative variance estimates as in nobound in SAS?
>>
>> Thanks,
>>
>> Rachel Baird
>>
>
>   I don't know of one.  This is typically a 'feature' of
> method-of-moments estimators; most of the approaches I know of
> that are implemented in R use Bayesian or (restricted) maximum
> likelihood approaches for which negative variances would be
> completely nonsensical ...
>
>   Just out of curiosity, why would you _want_ negative variance
> estimates ... ?  The only reason I can think of would be to
> match previous estimates ...
>
>   Ben Bolker
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From calliebaird at gmail.com  Tue Jun  4 18:00:28 2013
From: calliebaird at gmail.com (Callie Baird)
Date: Tue, 4 Jun 2013 12:00:28 -0400
Subject: [R-sig-ME] Negative Variance
In-Reply-To: <CAO7JsnQnrvJVprpGWmbujzLTN+DZC1CSf4REsXX4jJkkNw94iw@mail.gmail.com>
References: <CANa-dmxp8-E9p8bceoc6rnpsAHQDyjd1rX0MBMJyPURvF1pbJQ@mail.gmail.com>
	<CAO7JsnQnrvJVprpGWmbujzLTN+DZC1CSf4REsXX4jJkkNw94iw@mail.gmail.com>
Message-ID: <CANa-dmwAAv7SXe-3NYpsAsbS6pwndAweZcQLRENNdd3JM2N7Kg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130604/5b53431d/attachment.pl>

From bbolker at gmail.com  Tue Jun  4 18:20:48 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 04 Jun 2013 12:20:48 -0400
Subject: [R-sig-ME] Negative Variance
In-Reply-To: <20130604170003.145836zbgp4djri8@www.staffmail.ed.ac.uk>
References: <CANa-dmxp8-E9p8bceoc6rnpsAHQDyjd1rX0MBMJyPURvF1pbJQ@mail.gmail.com>
	<loom.20130604T174312-293@post.gmane.org>
	<20130604170003.145836zbgp4djri8@www.staffmail.ed.ac.uk>
Message-ID: <51AE13E0.3010804@gmail.com>

On 13-06-04 12:00 PM, Jarrod Hadfield wrote:
> Hi,
> 
> Negative variance estimates could make sense if viewed as covariances.
> For example, you could imagine controlling the amount of food for a nest
> of chicks very carefully such that negative correlations between the
> weights of nest-mates exist because of competition (if I take a large
> slice of the pie you're left with a little slice). Having a negative
> estimate of the nest variance would then make sense if viewed as an
> estimate of the covariance. asreml-R will allow you to let the variance
> go negative (or model them as residual correlations if you prefer).
> 
> Cheers,
> 
> Jarrod


  OK.  lme won't let variances go negative, but it will allow you to
estimate negative residual correlations:

lme(prevalence~sex,random=list(tripsite=pdCompSymm(~sex-1)),data=g6)

 is one example I quickly pulled out of a previous analysis (correlation
between male and female prevalences measured within a trip:site
combination, which could be either positive or negative).

  So far this is not easily done in lme4::lmer.




> 
> 
> Quoting Ben Bolker <bbolker at gmail.com> on Tue, 4 Jun 2013 15:44:51 +0000
> (UTC):
> 
>> Callie Baird <calliebaird at ...> writes:
>>
>>>
>>> I am trying to fit multilevel models, allowing negative variance
>>> estimates.
>>>  Is there a way to allow negative variance estimates as in nobound in
>>> SAS?
>>>
>>> Thanks,
>>>
>>> Rachel Baird
>>>
>>
>>   I don't know of one.  This is typically a 'feature' of
>> method-of-moments estimators; most of the approaches I know of
>> that are implemented in R use Bayesian or (restricted) maximum
>> likelihood approaches for which negative variances would be
>> completely nonsensical ...
>>
>>   Just out of curiosity, why would you _want_ negative variance
>> estimates ... ?  The only reason I can think of would be to
>> match previous estimates ...
>>
>>   Ben Bolker
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
> 
>


From pierces1 at msu.edu  Tue Jun  4 18:28:12 2013
From: pierces1 at msu.edu (Steven J. Pierce)
Date: Tue, 4 Jun 2013 12:28:12 -0400
Subject: [R-sig-ME] Mixed effects model with a distance matrix as a
	random	effect
In-Reply-To: <51ADE195.9060006@mpi-marburg.mpg.de>
References: <51ADE195.9060006@mpi-marburg.mpg.de>
Message-ID: <007701ce6140$81fb3bd0$85f1b370$@msu.edu>

You could also consider using a geostatistical model such as found in the
spBayes package. 

Steve 


-----Original Message-----
From: Roey Angel [mailto:angel at mpi-marburg.mpg.de] 
Sent: Tuesday, June 04, 2013 8:46 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Mixed effects model with a distance matrix as a random
effect

Hi,
I'm trying to build a mixed-effects model in which I'd like to include
either a distance matrix as a random effect.
The troubles I've had are that function lmer() in package lme4 only accepts
a data frame column as a random factor and not a distance matrix.

Is there a way around it?

Thanks in advance
Roey


	[[alternative HTML version deleted]]


From oceancurrents at gmail.com  Tue Jun  4 20:11:49 2013
From: oceancurrents at gmail.com (D Gill)
Date: Tue, 4 Jun 2013 14:11:49 -0400
Subject: [R-sig-ME] nlme: varIdent
Message-ID: <CAE65Z9M1bBWLcQpETiROTNxma8k3V_EyJHz+NTTi85ACso+9VA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130604/d2f2dbe9/attachment.pl>

From han.yi.query at gmail.com  Tue Jun  4 22:45:03 2013
From: han.yi.query at gmail.com (Han-Gyol Yi)
Date: Tue, 4 Jun 2013 15:45:03 -0500
Subject: [R-sig-ME] Maximal specification of random effects
Message-ID: <CAFvp_hK0fsmKxZPWN+7ekLUrjDxDGTn6ksKR=SS1WiM-nCO1mA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130604/b96cac2f/attachment.pl>

From bbolker at gmail.com  Tue Jun  4 23:28:46 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 4 Jun 2013 21:28:46 +0000 (UTC)
Subject: [R-sig-ME] Negative Variance
References: <CANa-dmxp8-E9p8bceoc6rnpsAHQDyjd1rX0MBMJyPURvF1pbJQ@mail.gmail.com>
	<CAO7JsnQnrvJVprpGWmbujzLTN+DZC1CSf4REsXX4jJkkNw94iw@mail.gmail.com>
	<CANa-dmwAAv7SXe-3NYpsAsbS6pwndAweZcQLRENNdd3JM2N7Kg@mail.gmail.com>
Message-ID: <loom.20130604T231841-300@post.gmane.org>

Callie Baird <calliebaird at ...> writes:

> 
> I would like to analyze the results of allowing negative variance as part
> of a simulation study, to understand if and how the negative variance 
> cases
> differ from the convergent cases.
> 
> If there is no way to do so already written, does anyone have
>  an idea how I
> might alter the code to allow negative variance estimates?
> 
> Thanks,
> 
> Rachel Baird

 1. I assume you don't mean that you're going to simulate with
negative variances (since, even accepting Jarrod's arguments about
when a negative _estimate_ of variance would be meaningful, it would
be hard to imagine a sensible way of _simulating_ with negative
variances) ...  if you're doing a simulation that includes cases with
negative variance estimates, that presumably means that you're going
to be exploring fitting as done by some software package (AS-REML,
SAS) that _does_ allow fitting of negative variances.  If so, why not
use those packages?

 2. As discussed elsewhere in this thread, negative variance estimates
would typically correspond to a case of negative within-group
correlations.  You can see whether the correlation parameter is
negative by fitting with pdCompSymm() (again, as mentioned elsewhere)
-- that would probably correspond to "negative variance cases" as
estimated by some other packages.  To me this seems reasonable, and
very much your best bet if you are going to stick with R and
nlme/lme4.

 3. It would be **very difficult** to modify the nlme or lme4 code to
allow for negative variances -- they're simply not set up in a way
that allows that case to make any sense.  lme4's code would probably
(figuratively) blow up if you tried to compute a deviance for a
negative variance; lme effectively fits the variances on a log scale
and would probably similarly blow up if you went to the (large) effort
of changing to a linear scale.

It's possible (???) that someone has written method-of-moments
variance estimators in some other R package that would either do what
you want or be modifiable, but I'm not aware of it.


From bbolker at gmail.com  Tue Jun  4 23:31:12 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 4 Jun 2013 21:31:12 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?issues_with_weights_in_glmer_=28or_glmmADMB?=
	=?utf-8?b?KQlbU0VDPVVOQ0xBU1NJRklFRF0=?=
References: <410C0E47580EB147811BB64E83936A3F68E1F7C66E@EX2K7-CCR.AAD.GOV.AU>
	<loom.20130604T145428-990@post.gmane.org>
Message-ID: <loom.20130604T232917-453@post.gmane.org>

Ben Bolker <bbolker at ...> writes:

> 
> Steve Candy <Steve.Candy <at> ...> writes:
> 
> > 
> > I am yet to see any response from the developers/maintainers of
> > lme4 with respect to my posting from 25
> > Feburary on the R-sig-mixed-models Digest, Vol 74, Issue 40
> > 
> > 5. Re: lmer residual variance estimate with prior weights (lmer

  [snip]
> 
>    Sorry this slipped through the cracks.  We will take a look;
> if you can (re)post the query at 
> https://github.com/lme4/lme4/issues?state=open
> (the new site for bug/feature requests) that would help us out ...

  PS I looked back at your previous post, and you don't provide a
reproducible example.  If you can either provide your data or (very
much preferably) a minimal reproducible example
<http://tinyurl.com/reproducible-000>, that will save us time and
greatly increase the probability that we will be able to tackle this
in the near future ...

  cheers
    Ben Bolker


From laurent_step at yahoo.fr  Wed Jun  5 00:08:36 2013
From: laurent_step at yahoo.fr (laurent stephane)
Date: Tue, 4 Jun 2013 23:08:36 +0100 (BST)
Subject: [R-sig-ME] Negative Variance
In-Reply-To: <loom.20130604T231841-300@post.gmane.org>
References: <CANa-dmxp8-E9p8bceoc6rnpsAHQDyjd1rX0MBMJyPURvF1pbJQ@mail.gmail.com>
	<CAO7JsnQnrvJVprpGWmbujzLTN+DZC1CSf4REsXX4jJkkNw94iw@mail.gmail.com>
	<CANa-dmwAAv7SXe-3NYpsAsbS6pwndAweZcQLRENNdd3JM2N7Kg@mail.gmail.com>
	<loom.20130604T231841-300@post.gmane.org>
Message-ID: <1370383716.70149.YahooMailNeo@web171704.mail.ir2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130604/051efa73/attachment.pl>

From laurent_step at yahoo.fr  Wed Jun  5 00:26:18 2013
From: laurent_step at yahoo.fr (laurent stephane)
Date: Tue, 4 Jun 2013 23:26:18 +0100 (BST)
Subject: [R-sig-ME] Negative Variance
In-Reply-To: <CAO7JsnQnrvJVprpGWmbujzLTN+DZC1CSf4REsXX4jJkkNw94iw@mail.gmail.com>
References: <CANa-dmxp8-E9p8bceoc6rnpsAHQDyjd1rX0MBMJyPURvF1pbJQ@mail.gmail.com>
	<CAO7JsnQnrvJVprpGWmbujzLTN+DZC1CSf4REsXX4jJkkNw94iw@mail.gmail.com>
Message-ID: <1370384778.60460.YahooMailNeo@web171705.mail.ir2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130604/0c127aa6/attachment.pl>

From M.Fairbrother at bristol.ac.uk  Wed Jun  5 00:49:39 2013
From: M.Fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Tue, 4 Jun 2013 23:49:39 +0100
Subject: [R-sig-ME] Maximal specification of random effects
Message-ID: <CAAH-yP8Tds4DbgwqO7cvFq+P+ySqVzCoYJSY=oHRfROWTPz=XQ@mail.gmail.com>

Hi Han-Gyol,

I'm personally yet to see any context in which it makes sense to
include a variable on *both* sides of the "|", so I for one am
sceptical of "(1 + item | subject) + (1 + trial + environment |
item)".

(Note for parsimony's sake this is equivalent to "(item | subject) +
(trial + environment | item)" since random intercepts are included by
default.)

Others may disagree, but I don't even see a lot of reason to include
random intercepts for category, context, and batch (given the small
numbers of each). If anything, I'd fit the model as:

outcome ~ trial * environment * category * context * batch + (1 | subject)

Check to see whether you need all the interactions -- maybe not. And
the model may not even converge, though with 6*80 observations per
subject, I think it has a good chance of doing so.

If you want to keep it maximal, my view would be:

outcome ~ trial * environment * category * context * batch + (trial *
category * context * batch | subject)

Though you may have to simplify further, again for convergence's sake.
Relevant substantive theory, setting REML to FALSE, and comparing
nested models with likelihood ratio tests should together help you
decide how complex a model to keep.

Cheers,
Malcolm




> Date: Tue, 4 Jun 2013 15:45:03 -0500
> From: Han-Gyol Yi <han.yi.query at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Maximal specification of random effects
>
> Hello,
>
> We have an experiment of which results have been submitted for review in a
> journal. We are using lmer to analyze the data. In specifying the random
> effects, we have been suggested to "keep it maximal", per Barr et al.
> (2013). However, given our design, it has not been trivial for me to
> construct such a model.
>
> The experiment is a learning experiment in which each subject is presented
> with a random succession of stimuli, which must be categorized. The
> subjects do not know of the category structure beforehand. For instance, at
> trial number 1, subject #999 receives a stimulus #32, which is in category
> X. At trial number 2, stimulus #41 is presented, which is in category Y,
> and so forth, for 480 trials per subject.
>
> There are four categories of stimuli in total (e.g., W,X,Y,Z). Each
> category is embedded in five contexts (e.g., O,P,Q,R,S), which in turn are
> from four separate batches (e.g., A,B,C,D). This is relevant because
> although the target of learning is the category, each instance will vary
> according to the context and batch where they come from. In other words,
> the subjects must be able to abstract out categorical information from the
> variance caused by each context and batch, and otherwise they will not be
> successful in the learning task. This gives us 80 stimuli in total:
>
> WOA, WOB, WOC, WOD, WPA, WPB, ... ZSA, ZSB, ZSC, ZSD.
>
>
> Each random sequence of all 80 stimuli are repeated six times, and for each
> trial we have correct/incorrect outcome of the subjects' responses.
>
> Additionally -- and most importantly -- each subject is assigned to only
> one of the two learning environments, making the overall design a
> between-subjects analysis. What we are interested in is how the two
> learning environments affect the rate and/or final level of achievement of
> learning across succeeding trials. Consequently, the data are constructed
> such as the following, with columns delimited by commas:
>
> subject, environment, trial, category, context, batch, outcome
>> ...
>> 999, conducive, 180, W, R, C, incorrect
>> 999, conducive, 181, X, O, D, correct
>> ...
>> 333, adverse, 4, Z, O, C, correct
>> ...
>
>
> and so forth, with (n of subjects) x 480 rows in total.
>
> To recap, I have one b/n subjects variable ("environment": conducive vs.
> adverse) and one w/n subjects variable ("trial": 1 to 480, mean centered to
> 0) that I am interested in as fixed effects. Category, context, batch are
> random effects, where outcome is my dependent variable.
>
> The formula I have been using is this:
>
> outcome ~ trial * environment + (1 | category) + (1 | context) + (1 |
>> batch) + (1 | subject)
>
>
> However, per the suggestion, I want to specify a design-driven maximal
> model of random effects. One possible option I have considered is to treat
> each stimulus as an instance of 80 items total, disregarding the systematic
> variation coming from context and batch, so something like the following:
>
> outcome ~ trial * environment + (1 + item | subject) + (1 + trial +
>> environment | item)
>
>
> I am not allowing the trial slope to vary by each subject because I think
> that's confounded with the between-subjects environment variable. This
> makes some sense to me, but I cannot be sure it is valid. Of course, if it
> is invalid, then I have four random effects and to specify all permutations
> of such sound either daunting or absurd to me.
>
> I am aware that the "keep it maximal" approach may not be everyone's
> favorite, but in this case I certainly want to consider such a perspective.
> My questions are as follows, given the limited information regarding our
> study design that I have provided here:
>
>    1. Is there a reason to discard either of the data-driven or
>    design-driven model specification approach?
>    2. In case the design-driven approach is to be used, what would make
>    "the most sense" in terms of specifying a maximal model?
>    3. In case the data-driven approach is to be used, how extensive should
>    my search be, until I conclude that all possibilities have been exhausted
>    and I am confident that I have the most complex model as justified by the
>    data?
>
> I appreciate your reading this long note. Please let me know should
> necessary details be wanting, or if I have unintentionally rephrased a
> question that has already been asked and answered previously.
>
> Best regards,
> Han-Gyol Yi


From c.ryan.king at gmail.com  Wed Jun  5 00:56:19 2013
From: c.ryan.king at gmail.com (Ryan King)
Date: Tue, 4 Jun 2013 17:56:19 -0500
Subject: [R-sig-ME] Negative Variance
Message-ID: <CAEQ+J24-RDk7omzRVc9HL=+byCvOQMY5D4UeX7_naJBfDmbCSg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130604/2cf7cc4c/attachment.pl>

From john.maindonald at anu.edu.au  Wed Jun  5 00:56:27 2013
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Wed, 5 Jun 2013 08:56:27 +1000
Subject: [R-sig-ME] Negative Variance
In-Reply-To: <loom.20130604T174312-293@post.gmane.org>
References: <CANa-dmxp8-E9p8bceoc6rnpsAHQDyjd1rX0MBMJyPURvF1pbJQ@mail.gmail.com>
	<loom.20130604T174312-293@post.gmane.org>
Message-ID: <A9279BDD-FB46-4924-B93E-45EB6FA59743@anu.edu.au>

Negative variance estimates can be very useful in alerting that the
variance-covariance structure is not what one expects.  Or they may
allow the simplest way of specifying the overall variance-covariance
structure, short of specifying the variance-covariance structure in
some detail.

I was told of an experiment where the experimenters had chosen 
blocks to be at right angles to the river bank, accordingly maximising
between plot variance.  This came to light, in data analysed away
from the scene of the original trial, when the block variance was
estimated as negative -- a very useful diagnostic.  Certainly, one can 
check on such a possibility by specifying a suitable variance-covariance 
structure, but how many analysts will take that trouble?

Or one has results from each of two eyes per person.  After allowing
for any systematic left/right difference, are two eyes from the same
individual more or less different than two eyes from different 
individuals?  I doubt that there is a general answer that applies to all
types of eye measurements.

The job of computer output, in my view, is to be as informative as
possible while keeping the output as terse as possible.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 05/06/2013, at 1:44 AM, Ben Bolker <bbolker at gmail.com> wrote:

> Callie Baird <calliebaird at ...> writes:
> 
>> 
>> I am trying to fit multilevel models, allowing negative variance estimates.
>> Is there a way to allow negative variance estimates as in nobound in SAS?
>> 
>> Thanks,
>> 
>> Rachel Baird
>> 
> 
>  I don't know of one.  This is typically a 'feature' of 
> method-of-moments estimators; most of the approaches I know of
> that are implemented in R use Bayesian or (restricted) maximum
> likelihood approaches for which negative variances would be
> completely nonsensical ...
> 
>  Just out of curiosity, why would you _want_ negative variance
> estimates ... ?  The only reason I can think of would be to
> match previous estimates ...
> 
>  Ben Bolker
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From Steve.Candy at aad.gov.au  Wed Jun  5 01:24:20 2013
From: Steve.Candy at aad.gov.au (Steve Candy)
Date: Wed, 5 Jun 2013 09:24:20 +1000
Subject: [R-sig-ME] Re: issues with weights in glmer (or glmmADMB)
 [SEC=UNCLASSIFIED]
Message-ID: <410C0E47580EB147811BB64E83936A3F68E1F7C761@EX2K7-CCR.AAD.GOV.AU>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130605/492514d3/attachment.pl>

From bbolker at gmail.com  Wed Jun  5 03:05:26 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 5 Jun 2013 01:05:26 +0000 (UTC)
Subject: [R-sig-ME] Negative Variance
References: <CANa-dmxp8-E9p8bceoc6rnpsAHQDyjd1rX0MBMJyPURvF1pbJQ@mail.gmail.com>
	<loom.20130604T174312-293@post.gmane.org>
	<A9279BDD-FB46-4924-B93E-45EB6FA59743@anu.edu.au>
Message-ID: <loom.20130605T025644-911@post.gmane.org>

John Maindonald <john.maindonald at ...> writes:

> 
> Negative variance estimates can be very useful in alerting that the
> variance-covariance structure is not what one expects.  Or they may
> allow the simplest way of specifying the overall variance-covariance
> structure, short of specifying the variance-covariance structure in
> some detail.
> 
> I was told of an experiment where the experimenters had chosen 
> blocks to be at right angles to the river bank, accordingly maximising
> between plot variance.  This came to light, in data analysed away
> from the scene of the original trial, when the block variance was
> estimated as negative -- a very useful diagnostic.  Certainly, one can 
> check on such a possibility by specifying a suitable variance-covariance 
> structure, but how many analysts will take that trouble?

  I don't quite get the geometry you're talking about, but
I take the general point that diagnostics are good and that
one wouldn't necessarily think to consider negative correlation.
  
> Or one has results from each of two eyes per person.  After allowing
> for any systematic left/right difference, are two eyes from the same
> individual more or less different than two eyes from different 
> individuals?  I doubt that there is a general answer that applies to all
> types of eye measurements.

  I find this one a little bit less convincing -- here it would
seem to be perfectly natural to fit a model that allowed for
positive or negative correlation.

  The fact remains that, whether or not it's a good idea,
 this is very hard to do in nlme/lme4 for
structural reasons. Luckily people are suggesting alternative
packages.  (Anyone who would like to edit 
http://glmm.wikidot.com/pkg-comparison accordingly is welcome
to do so ...)

  I don't think "how do I estimate negative variances?" has quite
risen to the level of a FAQ yet, so I won't bother adding it
to http://glmm.wikidot.com/faq (although again, if anyone wants
to take the initiative to do so I wouldn't complain).

    Ben Bolker


From bbolker at gmail.com  Wed Jun  5 03:14:37 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 5 Jun 2013 01:14:37 +0000 (UTC)
Subject: [R-sig-ME] nlme: varIdent
References: <CAE65Z9M1bBWLcQpETiROTNxma8k3V_EyJHz+NTTi85ACso+9VA@mail.gmail.com>
Message-ID: <loom.20130605T031041-601@post.gmane.org>

D Gill <oceancurrents at ...> writes:

> 
> Hello,  I am a student working on fisheries data using a mixed linear
> model. I have a question about the varIdent function. I have information on
> 140 fishers at nine sites, where the only random effect is for the site. As
> I do not have equal variances between sites, is it correct to use the
> varIdent argument for the sites? Do I lose any information by doing it this
> way?
> 
> M1<-lme(resp~......,random = ~1|Site,weights = varIdent(form =~1|Site) ))
> 

  This seems reasonable to me.  However, note that you might
want to consider (variable*site) interactions of any predictor variables
that vary within sites (see e.g. Schielzeth and Forstmeier 2009) [e.g.
if your measurement is total catch, effort is a covariate, and CPUE
varies among sites, you would want effort|Site in your random
effects specification].
   I'm assuming you have a single measurement for each fisher -- 
otherwise you should also add a random effect for fishers ...

  Ben Bolker


From bbolker at gmail.com  Wed Jun  5 03:35:51 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 5 Jun 2013 01:35:51 +0000 (UTC)
Subject: [R-sig-ME] Autocorrelation in a GAMM for nightly time series
References: <F85D7C52-8C41-4E5E-AECD-039B0DDD9769@vuw.ac.nz>
	<D73B95B3-5DEA-4490-9E76-07421398801A@mac.com>
Message-ID: <loom.20130605T032637-397@post.gmane.org>

Andrew Digby <andrewdigby at ...> writes:

> I'm analysing call counts of a nocturnal species in 
> response to temporal and environmental effects. Over a
> period of 3 years I divide each night into 10 equal-length blocks, 
> and count the calls of each sex in each
> block. 

 [snip]

> gam(ncalls ~ sex + year + s(month) + s(time of night) +
>  s(moon) + s(temperature) + s(rain) +
> offset(blocklength), family=negbin(c(1,5)), data=dc)
 
> Where 'time of night' = 1-10 = the block number during the night,
> and blocklength = the length of that block (this changes throughout
> the year; hence the offset).
 
> Not surprisingly, the acf shows significant correlation between
> adjacent time blocks, with a periodicity of 10. This is because
> counts in a particular block will be similar to those in the blocks
> immediately before and after, and also to the same block on other
> nights (the species has a quite regular pattern of decreasing call
> rates as the night progresses).
 
> To address these autocorrelation problems, I've tried various 
> ARMA correlations, with correlation
> between time of night blocks, grouped by day (or week) and sex:
> 
> gamm( .., correlation=corARMA(form=~TimeofNight | DayofYearSex), p, q) 
>  (p=1:3, q=0:3)
> gamm( .., correlation=corARMA(form=~TimeofNight | WeekofYearSex), p, q)
 
> This improves the ACF, but there are still correlations between
> residuals at same time of night - e.g. peaks every 10 lags.
 
> 1) Can I rely on the ACF when my time series isn't actually
> consecutive time bins, since it only includes each night (not full
> days). This means, for example, that the time lag between
> observations 9 & 10 (~1 hour) is much longer than that between 10 &
> 11 (~12 hours = daytime)?

> 2) (if yes to the above) How can I construct a correlation structure
> in a GAMM which allows for correlation between adjacent time bins
> within each night, and between the same time bin on different
> nights?

  I think you can use corCAR1, which is intended for continuous-time
models, but it's limited -- it does only exponential correlations
in time (analogous to corAR1). 

  If you have enough data/computational power, you might try 
a 2D spline (tensor product? I don't quite remember) to allow
for a gradually changing nocturnal time pattern over the course
of the year (i.e something like s(timeofnight,dayofyear)) --
not entirely clear to me why you're fitting s(month) rather than
s(dayofyear), unless you only have one observation per month?

In general my experience is that when I find myself fitting
high-order ARMA models (i.e. more than a couple of lags in total),
it's because there's some systematic pattern that I failed to
capture in the fixed-effects part of the model. Your mileage may
of course vary.

  Ben Bolker


From john.maindonald at anu.edu.au  Wed Jun  5 03:45:13 2013
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Wed, 5 Jun 2013 11:45:13 +1000
Subject: [R-sig-ME] Negative Variance
In-Reply-To: <loom.20130605T025644-911@post.gmane.org>
References: <CANa-dmxp8-E9p8bceoc6rnpsAHQDyjd1rX0MBMJyPURvF1pbJQ@mail.gmail.com>
	<loom.20130604T174312-293@post.gmane.org>
	<A9279BDD-FB46-4924-B93E-45EB6FA59743@anu.edu.au>
	<loom.20130605T025644-911@post.gmane.org>
Message-ID: <6C1A3D6B-E7C2-4136-A511-BFEE53D983CF@anu.edu.au>

A variance components model that has a variance structure 

  block variance + plot (within block) variance + subplot (within plot) variance

makes sense only if blocks take out some part of the variation, i.e., variation
between plots within blocks is (in the absence of treatment effects) smaller
than variation between plots in different blocks.  Similarly for subplots
within/between plots.  

If on the contrary, there is more variation between between plots within blocks
than between plots in different blocks (this is likely to happen if there is a 
nutrient or fertility or moisture gradient within blocks), then a model that has
the form on the second line above will if allowed account for this by returning
a negative block component of variance estimate.  It does this in order to get
a plausible variance-covariance structure.

Of course, once a gradient has been identified, it can be accommodated in the
model.  This does not however undo all the malign effects of an unfortunate
experimental design.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 05/06/2013, at 11:05 AM, Ben Bolker <bbolker at gmail.com> wrote:

> John Maindonald <john.maindonald at ...> writes:
> 
>> 
>> Negative variance estimates can be very useful in alerting that the
>> variance-covariance structure is not what one expects.  Or they may
>> allow the simplest way of specifying the overall variance-covariance
>> structure, short of specifying the variance-covariance structure in
>> some detail.
>> 
>> I was told of an experiment where the experimenters had chosen 
>> blocks to be at right angles to the river bank, accordingly maximising
>> between plot variance.  This came to light, in data analysed away
>> from the scene of the original trial, when the block variance was
>> estimated as negative -- a very useful diagnostic.  Certainly, one can 
>> check on such a possibility by specifying a suitable variance-covariance 
>> structure, but how many analysts will take that trouble?
> 
>  I don't quite get the geometry you're talking about, but
> I take the general point that diagnostics are good and that
> one wouldn't necessarily think to consider negative correlation.
> 
>> Or one has results from each of two eyes per person.  After allowing
>> for any systematic left/right difference, are two eyes from the same
>> individual more or less different than two eyes from different 
>> individuals?  I doubt that there is a general answer that applies to all
>> types of eye measurements.
> 
>  I find this one a little bit less convincing -- here it would
> seem to be perfectly natural to fit a model that allowed for
> positive or negative correlation.
> 
>  The fact remains that, whether or not it's a good idea,
> this is very hard to do in nlme/lme4 for
> structural reasons. Luckily people are suggesting alternative
> packages.  (Anyone who would like to edit 
> http://glmm.wikidot.com/pkg-comparison accordingly is welcome
> to do so ...)
> 
>  I don't think "how do I estimate negative variances?" has quite
> risen to the level of a FAQ yet, so I won't bother adding it
> to http://glmm.wikidot.com/faq (although again, if anyone wants
> to take the initiative to do so I wouldn't complain).
> 
>    Ben Bolker
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From davidcostantini at libero.it  Wed Jun  5 12:16:18 2013
From: davidcostantini at libero.it (davidcostantini at libero.it)
Date: Wed, 5 Jun 2013 12:16:18 +0200 (CEST)
Subject: [R-sig-ME] Application of coxme
Message-ID: <720873.10550301370427378501.JavaMail.defaultUser@defaultHost>

Dear All
I am trying to use the coxme function to compare survival among 6 experimental 
groups.
I have a fixed factor (group), a random factor (brood), and a censoring 
variable (0 = still alive;
1 = dead). My response variable is the age of the dead individual or of the 
individual still
alive at the end of the experiment.
I have tried to use this function:

coxme (Surv(time,status) ~ group, random=~1|nest, data=females)

Time would be the age, while status is the censoring variable.
R gives me an output and says that the random argument of coxme is 
depreciated.
I wonder if anyone of you may let me know if this function is correct and why
the random factor is depreciated. 

Cheers
David

>----Messaggio originale----
>Da: r-sig-mixed-models-request at r-project.org
>Data: 05/06/2013 12.00
>A: <r-sig-mixed-models at r-project.org>
>Ogg: R-sig-mixed-models Digest, Vol 78, Issue 11
>
>Send R-sig-mixed-models mailing list submissions to
>	r-sig-mixed-models at r-project.org
>
>To subscribe or unsubscribe via the World Wide Web, visit
>	https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>or, via email, send a message with subject or body 'help' to
>	r-sig-mixed-models-request at r-project.org
>
>You can reach the person managing the list at
>	r-sig-mixed-models-owner at r-project.org
>
>When replying, please edit your Subject line so it is more specific
>than "Re: Contents of R-sig-mixed-models digest..."
>
>
>Today's Topics:
>
>   1. Re: nlme: varIdent (Ben Bolker)
>   2. Re: Autocorrelation in a GAMM for nightly time series (Ben Bolker)
>   3. Re: Negative Variance (John Maindonald)
>
>
>----------------------------------------------------------------------
>
>Message: 1
>Date: Wed, 5 Jun 2013 01:14:37 +0000 (UTC)
>From: Ben Bolker <bbolker at gmail.com>
>To: r-sig-mixed-models at r-project.org
>Subject: Re: [R-sig-ME] nlme: varIdent
>Message-ID: <loom.20130605T031041-601 at post.gmane.org>
>Content-Type: text/plain; charset=us-ascii
>
>D Gill <oceancurrents at ...> writes:
>
>> 
>> Hello,  I am a student working on fisheries data using a mixed linear
>> model. I have a question about the varIdent function. I have information on
>> 140 fishers at nine sites, where the only random effect is for the site. As
>> I do not have equal variances between sites, is it correct to use the
>> varIdent argument for the sites? Do I lose any information by doing it this
>> way?
>> 
>> M1<-lme(resp~......,random = ~1|Site,weights = varIdent(form =~1|Site) ))
>> 
>
>  This seems reasonable to me.  However, note that you might
>want to consider (variable*site) interactions of any predictor variables
>that vary within sites (see e.g. Schielzeth and Forstmeier 2009) [e.g.
>if your measurement is total catch, effort is a covariate, and CPUE
>varies among sites, you would want effort|Site in your random
>effects specification].
>   I'm assuming you have a single measurement for each fisher -- 
>otherwise you should also add a random effect for fishers ...
>
>  Ben Bolker
>
>
>
>------------------------------
>
>Message: 2
>Date: Wed, 5 Jun 2013 01:35:51 +0000 (UTC)
>From: Ben Bolker <bbolker at gmail.com>
>To: r-sig-mixed-models at r-project.org
>Subject: Re: [R-sig-ME] Autocorrelation in a GAMM for nightly time
>	series
>Message-ID: <loom.20130605T032637-397 at post.gmane.org>
>Content-Type: text/plain; charset=us-ascii
>
>Andrew Digby <andrewdigby at ...> writes:
>
>> I'm analysing call counts of a nocturnal species in 
>> response to temporal and environmental effects. Over a
>> period of 3 years I divide each night into 10 equal-length blocks, 
>> and count the calls of each sex in each
>> block. 
>
> [snip]
>
>> gam(ncalls ~ sex + year + s(month) + s(time of night) +
>>  s(moon) + s(temperature) + s(rain) +
>> offset(blocklength), family=negbin(c(1,5)), data=dc)
> 
>> Where 'time of night' = 1-10 = the block number during the night,
>> and blocklength = the length of that block (this changes throughout
>> the year; hence the offset).
> 
>> Not surprisingly, the acf shows significant correlation between
>> adjacent time blocks, with a periodicity of 10. This is because
>> counts in a particular block will be similar to those in the blocks
>> immediately before and after, and also to the same block on other
>> nights (the species has a quite regular pattern of decreasing call
>> rates as the night progresses).
> 
>> To address these autocorrelation problems, I've tried various 
>> ARMA correlations, with correlation
>> between time of night blocks, grouped by day (or week) and sex:
>> 
>> gamm( .., correlation=corARMA(form=~TimeofNight | DayofYearSex), p, q) 
>>  (p=1:3, q=0:3)
>> gamm( .., correlation=corARMA(form=~TimeofNight | WeekofYearSex), p, q)
> 
>> This improves the ACF, but there are still correlations between
>> residuals at same time of night - e.g. peaks every 10 lags.
> 
>> 1) Can I rely on the ACF when my time series isn't actually
>> consecutive time bins, since it only includes each night (not full
>> days). This means, for example, that the time lag between
>> observations 9 & 10 (~1 hour) is much longer than that between 10 &
>> 11 (~12 hours = daytime)?
>
>> 2) (if yes to the above) How can I construct a correlation structure
>> in a GAMM which allows for correlation between adjacent time bins
>> within each night, and between the same time bin on different
>> nights?
>
>  I think you can use corCAR1, which is intended for continuous-time
>models, but it's limited -- it does only exponential correlations
>in time (analogous to corAR1). 
>
>  If you have enough data/computational power, you might try 
>a 2D spline (tensor product? I don't quite remember) to allow
>for a gradually changing nocturnal time pattern over the course
>of the year (i.e something like s(timeofnight,dayofyear)) --
>not entirely clear to me why you're fitting s(month) rather than
>s(dayofyear), unless you only have one observation per month?
>
>In general my experience is that when I find myself fitting
>high-order ARMA models (i.e. more than a couple of lags in total),
>it's because there's some systematic pattern that I failed to
>capture in the fixed-effects part of the model. Your mileage may
>of course vary.
>
>  Ben Bolker
>
>
>
>------------------------------
>
>Message: 3
>Date: Wed, 5 Jun 2013 11:45:13 +1000
>From: John Maindonald <john.maindonald at anu.edu.au>
>To: Ben Bolker <bbolker at gmail.com>
>Cc: r-sig-mixed-models at r-project.org
>Subject: Re: [R-sig-ME] Negative Variance
>Message-ID: <6C1A3D6B-E7C2-4136-A511-BFEE53D983CF at anu.edu.au>
>Content-Type: text/plain; charset=us-ascii
>
>A variance components model that has a variance structure 
>
>  block variance + plot (within block) variance + subplot (within plot) 
variance
>
>makes sense only if blocks take out some part of the variation, i.e., 
variation
>between plots within blocks is (in the absence of treatment effects) smaller
>than variation between plots in different blocks.  Similarly for subplots
>within/between plots.  
>
>If on the contrary, there is more variation between between plots within 
blocks
>than between plots in different blocks (this is likely to happen if there is 
a 
>nutrient or fertility or moisture gradient within blocks), then a model that 
has
>the form on the second line above will if allowed account for this by 
returning
>a negative block component of variance estimate.  It does this in order to 
get
>a plausible variance-covariance structure.
>
>Of course, once a gradient has been identified, it can be accommodated in the
>model.  This does not however undo all the malign effects of an unfortunate
>experimental design.
>
>John Maindonald             email: john.maindonald at anu.edu.au
>phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>Centre for Mathematics & Its Applications, Room 1194,
>John Dedman Mathematical Sciences Building (Building 27)
>Australian National University, Canberra ACT 0200.
>http://www.maths.anu.edu.au/~johnm
>
>On 05/06/2013, at 11:05 AM, Ben Bolker <bbolker at gmail.com> wrote:
>
>> John Maindonald <john.maindonald at ...> writes:
>> 
>>> 
>>> Negative variance estimates can be very useful in alerting that the
>>> variance-covariance structure is not what one expects.  Or they may
>>> allow the simplest way of specifying the overall variance-covariance
>>> structure, short of specifying the variance-covariance structure in
>>> some detail.
>>> 
>>> I was told of an experiment where the experimenters had chosen 
>>> blocks to be at right angles to the river bank, accordingly maximising
>>> between plot variance.  This came to light, in data analysed away
>>> from the scene of the original trial, when the block variance was
>>> estimated as negative -- a very useful diagnostic.  Certainly, one can 
>>> check on such a possibility by specifying a suitable variance-covariance 
>>> structure, but how many analysts will take that trouble?
>> 
>>  I don't quite get the geometry you're talking about, but
>> I take the general point that diagnostics are good and that
>> one wouldn't necessarily think to consider negative correlation.
>> 
>>> Or one has results from each of two eyes per person.  After allowing
>>> for any systematic left/right difference, are two eyes from the same
>>> individual more or less different than two eyes from different 
>>> individuals?  I doubt that there is a general answer that applies to all
>>> types of eye measurements.
>> 
>>  I find this one a little bit less convincing -- here it would
>> seem to be perfectly natural to fit a model that allowed for
>> positive or negative correlation.
>> 
>>  The fact remains that, whether or not it's a good idea,
>> this is very hard to do in nlme/lme4 for
>> structural reasons. Luckily people are suggesting alternative
>> packages.  (Anyone who would like to edit 
>> http://glmm.wikidot.com/pkg-comparison accordingly is welcome
>> to do so ...)
>> 
>>  I don't think "how do I estimate negative variances?" has quite
>> risen to the level of a FAQ yet, so I won't bother adding it
>> to http://glmm.wikidot.com/faq (although again, if anyone wants
>> to take the initiative to do so I wouldn't complain).
>> 
>>    Ben Bolker
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
>------------------------------
>
>_______________________________________________
>R-sig-mixed-models mailing list
>R-sig-mixed-models at r-project.org
>https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>End of R-sig-mixed-models Digest, Vol 78, Issue 11
>**************************************************
>


From klasen at mpipz.mpg.de  Wed Jun  5 14:02:00 2013
From: klasen at mpipz.mpg.de (Jonas Klasen)
Date: Wed, 05 Jun 2013 14:02:00 +0200
Subject: [R-sig-ME] Application of coxme
In-Reply-To: <720873.10550301370427378501.JavaMail.defaultUser@defaultHost>
References: <720873.10550301370427378501.JavaMail.defaultUser@defaultHost>
Message-ID: <51AF28B8.4030403@mpipz.mpg.de>

Hi David,
coxme now uses the lme4 syntax or you have to specify fixed and random:

coxme (Surv(time,status) ~ group + (1|nest), data=females) # or

coxme (fixed=Surv(time,status) ~ group, random=~1|nest, data=females)

Jonas

On Wed 05 Jun 2013 12:16:18 PM CEST, davidcostantini at libero.it wrote:
> Dear All
> I am trying to use the coxme function to compare survival among 6 experimental
> groups.
> I have a fixed factor (group), a random factor (brood), and a censoring
> variable (0 = still alive;
> 1 = dead). My response variable is the age of the dead individual or of the
> individual still
> alive at the end of the experiment.
> I have tried to use this function:
>
> coxme (Surv(time,status) ~ group, random=~1|nest, data=females)
>
> Time would be the age, while status is the censoring variable.
> R gives me an output and says that the random argument of coxme is
> depreciated.
> I wonder if anyone of you may let me know if this function is correct and why
> the random factor is depreciated.
>
> Cheers
> David
>
>> ----Messaggio originale----
>> Da: r-sig-mixed-models-request at r-project.org
>> Data: 05/06/2013 12.00
>> A: <r-sig-mixed-models at r-project.org>
>> Ogg: R-sig-mixed-models Digest, Vol 78, Issue 11
>>
>> Send R-sig-mixed-models mailing list submissions to
>> 	r-sig-mixed-models at r-project.org
>>
>> To subscribe or unsubscribe via the World Wide Web, visit
>> 	https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> or, via email, send a message with subject or body 'help' to
>> 	r-sig-mixed-models-request at r-project.org
>>
>> You can reach the person managing the list at
>> 	r-sig-mixed-models-owner at r-project.org
>>
>> When replying, please edit your Subject line so it is more specific
>> than "Re: Contents of R-sig-mixed-models digest..."
>>
>>
>> Today's Topics:
>>
>>    1. Re: nlme: varIdent (Ben Bolker)
>>    2. Re: Autocorrelation in a GAMM for nightly time series (Ben Bolker)
>>    3. Re: Negative Variance (John Maindonald)
>>
>>
>> ----------------------------------------------------------------------
>>
>> Message: 1
>> Date: Wed, 5 Jun 2013 01:14:37 +0000 (UTC)
>> From: Ben Bolker <bbolker at gmail.com>
>> To: r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] nlme: varIdent
>> Message-ID: <loom.20130605T031041-601 at post.gmane.org>
>> Content-Type: text/plain; charset=us-ascii
>>
>> D Gill <oceancurrents at ...> writes:
>>
>>>
>>> Hello,  I am a student working on fisheries data using a mixed linear
>>> model. I have a question about the varIdent function. I have information on
>>> 140 fishers at nine sites, where the only random effect is for the site. As
>>> I do not have equal variances between sites, is it correct to use the
>>> varIdent argument for the sites? Do I lose any information by doing it this
>>> way?
>>>
>>> M1<-lme(resp~......,random = ~1|Site,weights = varIdent(form =~1|Site) ))
>>>
>>
>>   This seems reasonable to me.  However, note that you might
>> want to consider (variable*site) interactions of any predictor variables
>> that vary within sites (see e.g. Schielzeth and Forstmeier 2009) [e.g.
>> if your measurement is total catch, effort is a covariate, and CPUE
>> varies among sites, you would want effort|Site in your random
>> effects specification].
>>    I'm assuming you have a single measurement for each fisher --
>> otherwise you should also add a random effect for fishers ...
>>
>>   Ben Bolker
>>
>>
>>
>> ------------------------------
>>
>> Message: 2
>> Date: Wed, 5 Jun 2013 01:35:51 +0000 (UTC)
>> From: Ben Bolker <bbolker at gmail.com>
>> To: r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] Autocorrelation in a GAMM for nightly time
>> 	series
>> Message-ID: <loom.20130605T032637-397 at post.gmane.org>
>> Content-Type: text/plain; charset=us-ascii
>>
>> Andrew Digby <andrewdigby at ...> writes:
>>
>>> I'm analysing call counts of a nocturnal species in
>>> response to temporal and environmental effects. Over a
>>> period of 3 years I divide each night into 10 equal-length blocks,
>>> and count the calls of each sex in each
>>> block.
>>
>> [snip]
>>
>>> gam(ncalls ~ sex + year + s(month) + s(time of night) +
>>>   s(moon) + s(temperature) + s(rain) +
>>> offset(blocklength), family=negbin(c(1,5)), data=dc)
>>
>>> Where 'time of night' = 1-10 = the block number during the night,
>>> and blocklength = the length of that block (this changes throughout
>>> the year; hence the offset).
>>
>>> Not surprisingly, the acf shows significant correlation between
>>> adjacent time blocks, with a periodicity of 10. This is because
>>> counts in a particular block will be similar to those in the blocks
>>> immediately before and after, and also to the same block on other
>>> nights (the species has a quite regular pattern of decreasing call
>>> rates as the night progresses).
>>
>>> To address these autocorrelation problems, I've tried various
>>> ARMA correlations, with correlation
>>> between time of night blocks, grouped by day (or week) and sex:
>>>
>>> gamm( .., correlation=corARMA(form=~TimeofNight | DayofYearSex), p, q)
>>>   (p=1:3, q=0:3)
>>> gamm( .., correlation=corARMA(form=~TimeofNight | WeekofYearSex), p, q)
>>
>>> This improves the ACF, but there are still correlations between
>>> residuals at same time of night - e.g. peaks every 10 lags.
>>
>>> 1) Can I rely on the ACF when my time series isn't actually
>>> consecutive time bins, since it only includes each night (not full
>>> days). This means, for example, that the time lag between
>>> observations 9 & 10 (~1 hour) is much longer than that between 10 &
>>> 11 (~12 hours = daytime)?
>>
>>> 2) (if yes to the above) How can I construct a correlation structure
>>> in a GAMM which allows for correlation between adjacent time bins
>>> within each night, and between the same time bin on different
>>> nights?
>>
>>   I think you can use corCAR1, which is intended for continuous-time
>> models, but it's limited -- it does only exponential correlations
>> in time (analogous to corAR1).
>>
>>   If you have enough data/computational power, you might try
>> a 2D spline (tensor product? I don't quite remember) to allow
>> for a gradually changing nocturnal time pattern over the course
>> of the year (i.e something like s(timeofnight,dayofyear)) --
>> not entirely clear to me why you're fitting s(month) rather than
>> s(dayofyear), unless you only have one observation per month?
>>
>> In general my experience is that when I find myself fitting
>> high-order ARMA models (i.e. more than a couple of lags in total),
>> it's because there's some systematic pattern that I failed to
>> capture in the fixed-effects part of the model. Your mileage may
>> of course vary.
>>
>>   Ben Bolker
>>
>>
>>
>> ------------------------------
>>
>> Message: 3
>> Date: Wed, 5 Jun 2013 11:45:13 +1000
>> From: John Maindonald <john.maindonald at anu.edu.au>
>> To: Ben Bolker <bbolker at gmail.com>
>> Cc: r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] Negative Variance
>> Message-ID: <6C1A3D6B-E7C2-4136-A511-BFEE53D983CF at anu.edu.au>
>> Content-Type: text/plain; charset=us-ascii
>>
>> A variance components model that has a variance structure
>>
>>   block variance + plot (within block) variance + subplot (within plot)
> variance
>>
>> makes sense only if blocks take out some part of the variation, i.e.,
> variation
>> between plots within blocks is (in the absence of treatment effects) smaller
>> than variation between plots in different blocks.  Similarly for subplots
>> within/between plots.
>>
>> If on the contrary, there is more variation between between plots within
> blocks
>> than between plots in different blocks (this is likely to happen if there is
> a
>> nutrient or fertility or moisture gradient within blocks), then a model that
> has
>> the form on the second line above will if allowed account for this by
> returning
>> a negative block component of variance estimate.  It does this in order to
> get
>> a plausible variance-covariance structure.
>>
>> Of course, once a gradient has been identified, it can be accommodated in the
>> model.  This does not however undo all the malign effects of an unfortunate
>> experimental design.
>>
>> John Maindonald             email: john.maindonald at anu.edu.au
>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>> Centre for Mathematics & Its Applications, Room 1194,
>> John Dedman Mathematical Sciences Building (Building 27)
>> Australian National University, Canberra ACT 0200.
>> http://www.maths.anu.edu.au/~johnm
>>
>> On 05/06/2013, at 11:05 AM, Ben Bolker <bbolker at gmail.com> wrote:
>>
>>> John Maindonald <john.maindonald at ...> writes:
>>>
>>>>
>>>> Negative variance estimates can be very useful in alerting that the
>>>> variance-covariance structure is not what one expects.  Or they may
>>>> allow the simplest way of specifying the overall variance-covariance
>>>> structure, short of specifying the variance-covariance structure in
>>>> some detail.
>>>>
>>>> I was told of an experiment where the experimenters had chosen
>>>> blocks to be at right angles to the river bank, accordingly maximising
>>>> between plot variance.  This came to light, in data analysed away
>>>> from the scene of the original trial, when the block variance was
>>>> estimated as negative -- a very useful diagnostic.  Certainly, one can
>>>> check on such a possibility by specifying a suitable variance-covariance
>>>> structure, but how many analysts will take that trouble?
>>>
>>>   I don't quite get the geometry you're talking about, but
>>> I take the general point that diagnostics are good and that
>>> one wouldn't necessarily think to consider negative correlation.
>>>
>>>> Or one has results from each of two eyes per person.  After allowing
>>>> for any systematic left/right difference, are two eyes from the same
>>>> individual more or less different than two eyes from different
>>>> individuals?  I doubt that there is a general answer that applies to all
>>>> types of eye measurements.
>>>
>>>   I find this one a little bit less convincing -- here it would
>>> seem to be perfectly natural to fit a model that allowed for
>>> positive or negative correlation.
>>>
>>>   The fact remains that, whether or not it's a good idea,
>>> this is very hard to do in nlme/lme4 for
>>> structural reasons. Luckily people are suggesting alternative
>>> packages.  (Anyone who would like to edit
>>> http://glmm.wikidot.com/pkg-comparison accordingly is welcome
>>> to do so ...)
>>>
>>>   I don't think "how do I estimate negative variances?" has quite
>>> risen to the level of a FAQ yet, so I won't bother adding it
>>> to http://glmm.wikidot.com/faq (although again, if anyone wants
>>> to take the initiative to do so I wouldn't complain).
>>>
>>>     Ben Bolker
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>> ------------------------------
>>
>> _______________________________________________
>> R-sig-mixed-models mailing list
>> R-sig-mixed-models at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>> End of R-sig-mixed-models Digest, Vol 78, Issue 11
>> **************************************************
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--
__________________________________________________

 Jonas Klasen
 PhD student
 Genome Plasticity and Computational Genetics
 Max Planck Institute for Plant Breeding Research


From antinyan at unive.it  Wed Jun  5 11:31:57 2013
From: antinyan at unive.it (Armenak ANTINYAN)
Date: Wed, 5 Jun 2013 11:31:57 +0200
Subject: [R-sig-ME] Question Regarding model Fit in lme4 package
Message-ID: <CA+3NkPMc9g-WNAgBrY7ADomUDUXts06pM1mPHbj1e7hwMNYAcQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130605/aabc9d29/attachment.pl>

From bussmann.1 at buckeyemail.osu.edu  Wed Jun  5 02:55:17 2013
From: bussmann.1 at buckeyemail.osu.edu (Samuel Bussmann)
Date: Wed, 5 Jun 2013 00:55:17 +0000
Subject: [R-sig-ME] fitting glmer after using doFit=FALSE
In-Reply-To: <9718C2ECAD3F874E9730276F099ACBF90AD95C7C@SN2PRD0106MB178.prod.exchangelabs.com>
References: <9718C2ECAD3F874E9730276F099ACBF90AD95C7C@SN2PRD0106MB178.prod.exchangelabs.com>
Message-ID: <9718C2ECAD3F874E9730276F099ACBF90AD9D3CD@SN2PRD0106MB178.prod.exchangelabs.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130605/d67c401b/attachment.pl>

From bbolker at gmail.com  Wed Jun  5 16:56:36 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 5 Jun 2013 14:56:36 +0000 (UTC)
Subject: [R-sig-ME] fitting glmer after using doFit=FALSE
References: <9718C2ECAD3F874E9730276F099ACBF90AD95C7C@SN2PRD0106MB178.prod.exchangelabs.com>
	<9718C2ECAD3F874E9730276F099ACBF90AD9D3CD@SN2PRD0106MB178.prod.exchangelabs.com>
Message-ID: <loom.20130605T160759-473@post.gmane.org>

Samuel Bussmann <bussmann.1 at ...> writes:

>  I have a question concerning the lme4 package -- specifically the
> glmer function.  I am attempting to use doFit=FALSE to output and
> make edits to model matrices in order to accommodate a special form
> of the random effect. I can't seem to find out what function is used
> to fit the updated model matrices. I tried update and refit with
> no success. Any advice you could offer would be much appreciated.

Based on a look inside the lmer function, which has the following
snippet:

    if (doFit) {
        ans <- do.call(lmer_finalize, ans)
        ans at call <- mc
    }

It looks like this is what you want:

library("lme4.0") ## this is equivalent to CRAN-lme4
tmp <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy, doFit=FALSE)
ans <- do.call(lme4.0:::lmer_finalize, tmp)

I would also encourage you to try the development version
of lme4, which you can install from github:

library("devtools")
install_github("lme4","lme4")

   It offers finer control of the details of the construction
and fitting process (help("modular"))

  Ben Bolker


From gavin.simpson at ucl.ac.uk  Wed Jun  5 19:36:11 2013
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Wed, 5 Jun 2013 11:36:11 -0600
Subject: [R-sig-ME] Confidence intervals in GAMM4
In-Reply-To: <CAE5HZZ+h=qE4Ntrn=1ofwyxU24WrJQCPYki2Px34UgsEPn+1sw@mail.gmail.com>
References: <CAE5HZZ+h=qE4Ntrn=1ofwyxU24WrJQCPYki2Px34UgsEPn+1sw@mail.gmail.com>
Message-ID: <1370453771.3634.56.camel@haul.biol.uregina.ca>

On Thu, 2013-05-30 at 12:12 -0300, Rodrigo Tardin wrote:
> Hi all,
> 
<snip />
> 
> I searched in R for confidence intervals in GAMM4 but I did not find it. I
> could obtain variance and std deviation for the random and fixed effects
> Groups Name             Variance            Std.Dev.
>  RANDOM (Intercept)  1.4973e+01        3.8694319
>  Xr.0   s(DISTCOAST)  4.7361e-02        0.2176263
>  Xr     s(DEPTH)          1.9779e-06        0.0014064
> 
> 
> Here it is my model.
> n3 <- gamm4(OCC_BIN~s(DEPTH)+s(DISTANCE_TO_COAST)+offset(RT),random = ~
> (1|RANDOM),correlation=corAR1(),method="ML", family=binomial,data=bryde3)

Unfortunately, this is *totally* wrong. There is no `correlation`
argument in `gamm4()` nor `glmer()`, which is the underlying fitting
function. That this didn't raise an error is due to `gamm4()` etc having
argument `...` which silently mops up any left over, non-used arguments.

`gamm()` in package *mgcv* does have a `correlation` argument but that
will fit your binomial GLMM via PQL which isn't such a good solution for
such models.

In nlme:::lme there was a function intervals() which could provide the
CI on the REs - see if there is an equivalent for lme4:::glmer. IIRC
Doug has something on this in his in-prep book on mixed effects models
via lme4, see chapter 1 in
http://lme4.r-forge.r-project.org/lMMwR/lrgprt.pdf

That presumes that you sort out the AR(1) business; you can't do that in
glmer().

Options are to move back to mgcv::gamm() but as I said, PQL isn't great
of binomial models. If your REs are simple, then mgcv::gam() can be
used. Again this doesn't have a correlation argument but ?magic (after
loading mgcv) has an example of including the correlation in the fit via
some jiggery-pokery. Alternatively and related to gam() is mgcv::bam()
which can take a known AR(1) parameter into account during the fitting.
This fits the AR(1) given the ordering of the data, which is what
`correlation=corAR1()` would have done - perhaps this just plain won't
work in nlme:::lme if you don't specify any ordering variable? - but I'm
not sure that will be correct given that your data are strictly time
ordered.

HTH

G

> The OFFSET is the boat route (the number of times the boat searched for
> whales in each 2x2km grid)
> RANDOM is the individual whale as done in previous studies (Hazen et al
> 2009 - MEPS - doi:10.3354/meps08108)
> 
> Can someone help me, please?
> Sincerely,
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Gavin Simpson, PhD                          [t] +1 306 337 8863
Adjunct Professor, Department of Biology    [f] +1 306 337 2410
Institute of Environmental Change & Society [e] gavin.simpson at uregina.ca
523 Research and Innovation Centre          [tw] @ucfagls
University of Regina
Regina, SK S4S 0A2, Canada


From sas0025 at auburn.edu  Wed Jun  5 23:16:45 2013
From: sas0025 at auburn.edu (Stephen Sefick)
Date: Wed, 05 Jun 2013 16:16:45 -0500
Subject: [R-sig-ME] Mixed Effects Model
Message-ID: <51AFAABD.7080809@auburn.edu>

Hello all:

This is my first foray into mixed effects modelling and I have a couple 
of questions.

I have data that I would like to analyize and I believe that a mixed 
effects model is the proper thing to use:

fixed effects isolate (factor); response plant height

nested factors:
Time Point (TP) nested in Exp
Plant nested in TP

non-nested factor:
Position (leaf position)

I have explicitly nested the TP in Exp by creating an interaction factor 
TP:Exp=EX_TP and explicitly nested TP in PLANT and Exp with the factor 
variable Exp:TP:PLANT=TP_PLANT

I have used the code

lmer(HEIGHT~ISO+(1|EX)+(1|EX_TP)+(1|TP_PLANT)+(1|POSITION), data=z)

to fit this model.  I believe this is the correct specification.  Is 
this correct?

I would also like to be able to fit this in lme (to be used to create a 
decision tree in package REEM tree).  I would like to use the REEM tree 
package to investigate metal concentrations in the data predicting 
isolate incorperating the experimental structure.

Please let me know if any more information is needed to help answer my 
questions.  Thank you in advance for all of the help.
kindest regards,

-- 
Stephen Sefick
**************************************************
Auburn University
Biological Sciences
331 Funchess Hall
Auburn, Alabama
36849
**************************************************
sas0025 at auburn.edu
http://www.auburn.edu/~sas0025
**************************************************

Let's not spend our time and resources thinking about things that are so 
little or so large that all they really do for us is puff us up and make 
us feel like gods.  We are mammals, and have not exhausted the annoying 
little problems of being mammals.

                                 -K. Mullis

"A big computer, a complex algorithm and a long time does not equal 
science."

                               -Robert Gentleman


From andrewdigby at mac.com  Thu Jun  6 06:29:26 2013
From: andrewdigby at mac.com (Andrew Digby)
Date: Thu, 06 Jun 2013 16:29:26 +1200
Subject: [R-sig-ME] Autocorrelation in a GAMM for nightly time series
In-Reply-To: <mailman.4.1370426402.24358.r-sig-mixed-models@r-project.org>
References: <mailman.4.1370426402.24358.r-sig-mixed-models@r-project.org>
Message-ID: <58EEFFFA-7F32-48DD-B7C4-AE13FE86B793@mac.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130606/d24baeb6/attachment.pl>

From Thierry.ONKELINX at inbo.be  Thu Jun  6 16:12:56 2013
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 6 Jun 2013 14:12:56 +0000
Subject: [R-sig-ME] Mixed Effects Model
In-Reply-To: <51AFAABD.7080809@auburn.edu>
References: <51AFAABD.7080809@auburn.edu>
Message-ID: <AA818EAD2576BC488B4F623941DA7427C2B1FB96@inbomail.inbo.be>

Dear Stefan,

Your model specification seems to be correct.

Nested random effects are straightforward in lme

lme(HEIGHT~ISO, random =  ~ 1|EX/EX_TP/TP_PLANT, data=z)

Crossed random effects are harder to do. I think it can be done with the pdBlocked function

Best regards,

Thierry


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Stephen Sefick
Verzonden: woensdag 5 juni 2013 23:17
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Mixed Effects Model

Hello all:

This is my first foray into mixed effects modelling and I have a couple of questions.

I have data that I would like to analyize and I believe that a mixed effects model is the proper thing to use:

fixed effects isolate (factor); response plant height

nested factors:
Time Point (TP) nested in Exp
Plant nested in TP

non-nested factor:
Position (leaf position)

I have explicitly nested the TP in Exp by creating an interaction factor TP:Exp=EX_TP and explicitly nested TP in PLANT and Exp with the factor variable Exp:TP:PLANT=TP_PLANT

I have used the code

lmer(HEIGHT~ISO+(1|EX)+(1|EX_TP)+(1|TP_PLANT)+(1|POSITION), data=z)

to fit this model.  I believe this is the correct specification.  Is this correct?

I would also like to be able to fit this in lme (to be used to create a decision tree in package REEM tree).  I would like to use the REEM tree package to investigate metal concentrations in the data predicting isolate incorperating the experimental structure.

Please let me know if any more information is needed to help answer my questions.  Thank you in advance for all of the help.
kindest regards,

--
Stephen Sefick
**************************************************
Auburn University
Biological Sciences
331 Funchess Hall
Auburn, Alabama
36849
**************************************************
sas0025 at auburn.edu
http://www.auburn.edu/~sas0025
**************************************************

Let's not spend our time and resources thinking about things that are so little or so large that all they really do for us is puff us up and make us feel like gods.  We are mammals, and have not exhausted the annoying little problems of being mammals.

                                 -K. Mullis

"A big computer, a complex algorithm and a long time does not equal science."

                               -Robert Gentleman

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From gavin.simpson at ucl.ac.uk  Thu Jun  6 16:42:05 2013
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Thu, 6 Jun 2013 08:42:05 -0600
Subject: [R-sig-ME] Autocorrelation in a GAMM for nightly time series
In-Reply-To: <58EEFFFA-7F32-48DD-B7C4-AE13FE86B793@mac.com>
References: <mailman.4.1370426402.24358.r-sig-mixed-models@r-project.org>
	<58EEFFFA-7F32-48DD-B7C4-AE13FE86B793@mac.com>
Message-ID: <1370529725.3743.30.camel@haul.biol.uregina.ca>

On Thu, 2013-06-06 at 16:29 +1200, Andrew Digby wrote:
> > 
> > From: Ben Bolker <bbolker at gmail.com>
> > Subject: Re: [R-sig-ME] Autocorrelation in a GAMM for nightly time series
> > Date: 5 June 2013 13:35:51 NZST
> > To: r-sig-mixed-models at r-project.org
> > 
> > 
> > Andrew Digby <andrewdigby at ...> writes:
> > 
> >> I'm analysing call counts of a nocturnal species in 
> >> response to temporal and environmental effects. Over a
> >> period of 3 years I divide each night into 10 equal-length blocks, 
> >> and count the calls of each sex in each
> >> block. 
> > 
> > [snip]
<snip/>
> 
> Thanks very much for that, Ben. The amount of help you provide through
> these forums is truly impressive!
<snip />
> So thanks to your help the model is improved, although the
> autocorrelation problem remains. I have a couple of remaining
> questions regarding this, which I'd really appreciate advice with: 

Can I just check that you are using the normalised residuals here? The
default for `resid()` will give you deviance? residuals and won't take
the covariance matrix into account. The normalised residuals will do
that:

resid(mod$lme, type = "normalised")

See ?resid.lme with the nlme package loaded.

This often catches peoples out (me included) at first.

G

> 1) ACF confidence intervals: because I have a large dataset (~40,000
> counts in ~11,000 bins), the 95% confidence intervals of the acf
> [acf(resid(gamm.model, type='n')] are tiny: about +/- 0.01. So while
> the peaks in the ACF  exceed these, they're still small correlations:
> ~0.1. Because my data have lots of time gaps in them, since they're
> just lots of nights merged together, can I rely on these confidence
> intervals and ACF calculation? Am I overstating the importance of the
> ACF? When I construct a variogram (as per Zuur et al's 2009 book),
> it's pretty flat, suggesting that there are no major independence
> problems.
> 
> 2) This model seems to need a complex correlation structure: an AR
> correlation between time bins in the same night (TimeofNight |
> NightofYear), AND correlation (AR?) between the same time bin on
> different nights (1 | TimeofNight). Several sources warn against using
> over-complicated correlation structures. But if the ACF shows residual
> autocorrelation with more basic structures, isn't a more realistic
> structure needed; or am I putting too much emphasis on the ACF CIs
> (question 1)?
> 
> Again, many thanks.
> 
> Andrew
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 


-- 
Gavin Simpson, PhD                          [t] +1 306 337 8863
Adjunct Professor, Department of Biology    [f] +1 306 337 2410
Institute of Environmental Change & Society [e] gavin.simpson at uregina.ca
523 Research and Innovation Centre          [tw] @ucfagls
University of Regina
Regina, SK S4S 0A2, Canada

%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Dr. Gavin Simpson             [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From han.yi.query at gmail.com  Thu Jun  6 18:24:37 2013
From: han.yi.query at gmail.com (Han-Gyol Yi)
Date: Thu, 6 Jun 2013 11:24:37 -0500
Subject: [R-sig-ME] Maximal specification of random effects
In-Reply-To: <CAAH-yP8Tds4DbgwqO7cvFq+P+ySqVzCoYJSY=oHRfROWTPz=XQ@mail.gmail.com>
References: <CAAH-yP8Tds4DbgwqO7cvFq+P+ySqVzCoYJSY=oHRfROWTPz=XQ@mail.gmail.com>
Message-ID: <CAFvp_hK=N80-g=564kMwZuEguJy8jNQtkJWNj9wbs1Yemwxwkg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130606/d28f65ae/attachment.pl>

From broog731 at newschool.edu  Thu Jun  6 20:01:50 2013
From: broog731 at newschool.edu (Geoff Brookshire)
Date: Thu, 6 Jun 2013 14:01:50 -0400
Subject: [R-sig-ME] Maximal specification of random effects
In-Reply-To: <CAFvp_hK=N80-g=564kMwZuEguJy8jNQtkJWNj9wbs1Yemwxwkg@mail.gmail.com>
References: <CAAH-yP8Tds4DbgwqO7cvFq+P+ySqVzCoYJSY=oHRfROWTPz=XQ@mail.gmail.com>
	<CAFvp_hK=N80-g=564kMwZuEguJy8jNQtkJWNj9wbs1Yemwxwkg@mail.gmail.com>
Message-ID: <CAE1hoOom2Ybat8NYsgmxmzDbok=qw2y95ZHu7HDZf6uF80G8Nw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130606/b33fc20b/attachment.pl>

From han.yi.query at gmail.com  Thu Jun  6 21:01:07 2013
From: han.yi.query at gmail.com (Han-Gyol Yi)
Date: Thu, 6 Jun 2013 14:01:07 -0500
Subject: [R-sig-ME] Maximal specification of random effects
In-Reply-To: <CAE1hoOrU20WKmJahkVD8LjGRVQfGW8_n+ygB_Hnu8-tnODsROA@mail.gmail.com>
References: <CAAH-yP8Tds4DbgwqO7cvFq+P+ySqVzCoYJSY=oHRfROWTPz=XQ@mail.gmail.com>
	<CAFvp_hK=N80-g=564kMwZuEguJy8jNQtkJWNj9wbs1Yemwxwkg@mail.gmail.com>
	<CAE1hoOrU20WKmJahkVD8LjGRVQfGW8_n+ygB_Hnu8-tnODsROA@mail.gmail.com>
Message-ID: <CAFvp_h+zP9SO3UZjzj03MEwMKHMEd7Mkn3ORcWXK1_b1jx5uOA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130606/42ec93a7/attachment.pl>

From ssefick at gmail.com  Thu Jun  6 20:52:00 2013
From: ssefick at gmail.com (Stephen Sefick)
Date: Thu, 06 Jun 2013 13:52:00 -0500
Subject: [R-sig-ME] Mixed Effects Model
In-Reply-To: <425cc7d9cdb947899d02224c7e718f4d@CH1PRD0202HT012.namprd02.prod.outlook.com>
References: <51AFAABD.7080809@auburn.edu>
	<425cc7d9cdb947899d02224c7e718f4d@CH1PRD0202HT012.namprd02.prod.outlook.com>
Message-ID: <51B0DA50.5090603@gmail.com>

Thierry,

Thank you for the help.  I needed to also include a PLANT:POSITION 
nesting to account for pseudoreplication within plant.

part of the output reads:

  PLANT_POSITION (Intercept) 3.5074e-16 1.8728e-08
  TP_PLANT       (Intercept) 5.7686e+00 2.4018e+00
  EX_TP          (Intercept) 0.0000e+00 0.0000e+00
  EX             (Intercept) 0.0000e+00 0.0000e+00
  Residual                   1.3626e+01 3.6913e+00

My interpretation of this table is that EX and EX_TP are not important 
and I can drop them from the model because they do not account for any 
variation in the response, correct?  Does it effect the estimates to 
leave these in the model?

many thanks,

Stephen


On Thu 06 Jun 2013 09:12:56 AM CDT, ONKELINX, Thierry wrote:
>
> Dear Stefan,
>
> Your model specification seems to be correct.
>
> Nested random effects are straightforward in lme
>
> lme(HEIGHT~ISO, random = ~ 1|EX/EX_TP/TP_PLANT, data=z)
>
> Crossed random effects are harder to do. I think it can be done with 
> the pdBlocked function
>
> Best regards,
>
> Thierry
>
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature 
> and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> + 32 2 525 02 51
> + 32 54 43 61 85
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> To call in the statistician after the experiment is done may be no 
> more than asking him to perform a post-mortem examination: he may be 
> able to say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does 
> not ensure that a reasonable answer can be extracted from a given body 
> of data.
> ~ John Tukey
>
> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Stephen Sefick
> Verzonden: woensdag 5 juni 2013 23:17
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] Mixed Effects Model
>
> Hello all:
>
> This is my first foray into mixed effects modelling and I have a 
> couple of questions.
>
> I have data that I would like to analyize and I believe that a mixed 
> effects model is the proper thing to use:
>
> fixed effects isolate (factor); response plant height
>
> nested factors:
> Time Point (TP) nested in Exp
> Plant nested in TP
>
> non-nested factor:
> Position (leaf position)
>
> I have explicitly nested the TP in Exp by creating an interaction 
> factor TP:Exp=EX_TP and explicitly nested TP in PLANT and Exp with the 
> factor variable Exp:TP:PLANT=TP_PLANT
>
> I have used the code
>
> lmer(HEIGHT~ISO+(1|EX)+(1|EX_TP)+(1|TP_PLANT)+(1|POSITION), data=z)
>
> to fit this model. I believe this is the correct specification. Is 
> this correct?
>
> I would also like to be able to fit this in lme (to be used to create 
> a decision tree in package REEM tree). I would like to use the REEM 
> tree package to investigate metal concentrations in the data 
> predicting isolate incorperating the experimental structure.
>
> Please let me know if any more information is needed to help answer my 
> questions. Thank you in advance for all of the help.
> kindest regards,
>
> --
> Stephen Sefick
> **************************************************
> Auburn University
> Biological Sciences
> 331 Funchess Hall
> Auburn, Alabama
> 36849
> **************************************************
> sas0025 at auburn.edu
> http://www.auburn.edu/~sas0025
> **************************************************
>
> Let's not spend our time and resources thinking about things that are 
> so little or so large that all they really do for us is puff us up and 
> make us feel like gods. We are mammals, and have not exhausted the 
> annoying little problems of being mammals.
>
> -K. Mullis
>
> "A big computer, a complex algorithm and a long time does not equal 
> science."
>
> -Robert Gentleman
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> * * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
> Dit bericht en eventuele bijlagen geven enkel de visie van de 
> schrijver weer en binden het INBO onder geen enkel beding, zolang dit 
> bericht niet bevestigd is door een geldig ondertekend document.
> The views expressed in this message and any annex are purely those of 
> the writer and may not be regarded as stating an official position of 
> INBO, as long as the message is not confirmed by a duly signed document.
>


From andrewdigby at mac.com  Thu Jun  6 23:38:36 2013
From: andrewdigby at mac.com (Andrew Digby)
Date: Fri, 07 Jun 2013 09:38:36 +1200
Subject: [R-sig-ME] Autocorrelation in a GAMM for nightly time series
In-Reply-To: <1370529725.3743.30.camel@haul.biol.uregina.ca>
References: <mailman.4.1370426402.24358.r-sig-mixed-models@r-project.org>
	<58EEFFFA-7F32-48DD-B7C4-AE13FE86B793@mac.com>
	<1370529725.3743.30.camel@haul.biol.uregina.ca>
Message-ID: <EABF5426-C906-4EE7-B8B1-618E6A673672@mac.com>


On 7/06/2013, at 02:42 , Gavin Simpson <gavin.simpson at ucl.ac.uk> wrote:

> On Thu, 2013-06-06 at 16:29 +1200, Andrew Digby wrote:
>>> 
>>> From: Ben Bolker <bbolker at gmail.com>
>>> Subject: Re: [R-sig-ME] Autocorrelation in a GAMM for nightly time series
>>> Date: 5 June 2013 13:35:51 NZST
>>> To: r-sig-mixed-models at r-project.org
>>> 
>>> 
>>> Andrew Digby <andrewdigby at ...> writes:
>>> 
>>>> I'm analysing call counts of a nocturnal species in 
>>>> response to temporal and environmental effects. Over a
>>>> period of 3 years I divide each night into 10 equal-length blocks, 
>>>> and count the calls of each sex in each
>>>> block. 
>>> 
>>> [snip]
> <snip/>
>> 
>> Thanks very much for that, Ben. The amount of help you provide through
>> these forums is truly impressive!
> <snip />
>> So thanks to your help the model is improved, although the
>> autocorrelation problem remains. I have a couple of remaining
>> questions regarding this, which I'd really appreciate advice with: 
> 
> Can I just check that you are using the normalised residuals here? The
> default for `resid()` will give you deviance? residuals and won't take
> the covariance matrix into account. The normalised residuals will do
> that:
> 
> resid(mod$lme, type = "normalised")
> 
> See ?resid.lme with the nlme package loaded.
> 
> This often catches peoples out (me included) at first.
> 
> G
> 
> 

Yes, unfortunately I am using type='normalized'. Thanks for the tip though!

Andrew


From sas0025 at auburn.edu  Fri Jun  7 01:02:13 2013
From: sas0025 at auburn.edu (Stephen Sefick)
Date: Thu, 06 Jun 2013 18:02:13 -0500
Subject: [R-sig-ME] TukeyHSD after lmer repeated measures
Message-ID: <51B114F5.2040303@auburn.edu>

I fit this model:

repeated_measure_height <- lmer(HEIGHT~ISO+(TIME|EX_PLANT), data=x)

I would like to test if the mean levels of ISO are sig diff. from each 
other (Is the difference greater than of less than 0).

Thank you for all of the help in advance.
kindest regards,


-- 
Stephen Sefick
**************************************************
Auburn University
Biological Sciences
331 Funchess Hall
Auburn, Alabama
36849
**************************************************
sas0025 at auburn.edu
http://www.auburn.edu/~sas0025
**************************************************

Let's not spend our time and resources thinking about things that are so 
little or so large that all they really do for us is puff us up and make 
us feel like gods.  We are mammals, and have not exhausted the annoying 
little problems of being mammals.

                                 -K. Mullis

"A big computer, a complex algorithm and a long time does not equal 
science."

                               -Robert Gentleman


From Thierry.ONKELINX at inbo.be  Fri Jun  7 16:43:35 2013
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Fri, 7 Jun 2013 14:43:35 +0000
Subject: [R-sig-ME] Mixed Effects Model
In-Reply-To: <51B0DA50.5090603@gmail.com>
References: <51AFAABD.7080809@auburn.edu>
	<425cc7d9cdb947899d02224c7e718f4d@CH1PRD0202HT012.namprd02.prod.outlook.com>
	<51B0DA50.5090603@gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA7427C2B22D94@inbomail.inbo.be>

Dear Stephen,

I prefer to keep those random effects in the model because they reflect the design of the experiment.

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: Stephen Sefick [mailto:ssefick at gmail.com]
Verzonden: donderdag 6 juni 2013 20:52
Aan: ONKELINX, Thierry
CC: Stephen Sefick; r-sig-mixed-models at r-project.org
Onderwerp: Re: [R-sig-ME] Mixed Effects Model

Thierry,

Thank you for the help.  I needed to also include a PLANT:POSITION nesting to account for pseudoreplication within plant.

part of the output reads:

  PLANT_POSITION (Intercept) 3.5074e-16 1.8728e-08
  TP_PLANT       (Intercept) 5.7686e+00 2.4018e+00
  EX_TP          (Intercept) 0.0000e+00 0.0000e+00
  EX             (Intercept) 0.0000e+00 0.0000e+00
  Residual                   1.3626e+01 3.6913e+00

My interpretation of this table is that EX and EX_TP are not important and I can drop them from the model because they do not account for any variation in the response, correct?  Does it effect the estimates to leave these in the model?

many thanks,

Stephen


On Thu 06 Jun 2013 09:12:56 AM CDT, ONKELINX, Thierry wrote:
>
> Dear Stefan,
>
> Your model specification seems to be correct.
>
> Nested random effects are straightforward in lme
>
> lme(HEIGHT~ISO, random = ~ 1|EX/EX_TP/TP_PLANT, data=z)
>
> Crossed random effects are harder to do. I think it can be done with
> the pdBlocked function
>
> Best regards,
>
> Thierry
>
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and Forest team Biometrie & Kwaliteitszorg / team Biometrics & Quality
> Assurance Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> + 32 2 525 02 51
> + 32 54 43 61 85
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body
> of data.
> ~ John Tukey
>
> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org
> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Stephen
> Sefick
> Verzonden: woensdag 5 juni 2013 23:17
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] Mixed Effects Model
>
> Hello all:
>
> This is my first foray into mixed effects modelling and I have a
> couple of questions.
>
> I have data that I would like to analyize and I believe that a mixed
> effects model is the proper thing to use:
>
> fixed effects isolate (factor); response plant height
>
> nested factors:
> Time Point (TP) nested in Exp
> Plant nested in TP
>
> non-nested factor:
> Position (leaf position)
>
> I have explicitly nested the TP in Exp by creating an interaction
> factor TP:Exp=EX_TP and explicitly nested TP in PLANT and Exp with the
> factor variable Exp:TP:PLANT=TP_PLANT
>
> I have used the code
>
> lmer(HEIGHT~ISO+(1|EX)+(1|EX_TP)+(1|TP_PLANT)+(1|POSITION), data=z)
>
> to fit this model. I believe this is the correct specification. Is
> this correct?
>
> I would also like to be able to fit this in lme (to be used to create
> a decision tree in package REEM tree). I would like to use the REEM
> tree package to investigate metal concentrations in the data
> predicting isolate incorperating the experimental structure.
>
> Please let me know if any more information is needed to help answer my
> questions. Thank you in advance for all of the help.
> kindest regards,
>
> --
> Stephen Sefick
> **************************************************
> Auburn University
> Biological Sciences
> 331 Funchess Hall
> Auburn, Alabama
> 36849
> **************************************************
> sas0025 at auburn.edu
> http://www.auburn.edu/~sas0025
> **************************************************
>
> Let's not spend our time and resources thinking about things that are
> so little or so large that all they really do for us is puff us up and
> make us feel like gods. We are mammals, and have not exhausted the
> annoying little problems of being mammals.
>
> -K. Mullis
>
> "A big computer, a complex algorithm and a long time does not equal
> science."
>
> -Robert Gentleman
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> * * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * *
> * Dit bericht en eventuele bijlagen geven enkel de visie van de
> schrijver weer en binden het INBO onder geen enkel beding, zolang dit
> bericht niet bevestigd is door een geldig ondertekend document.
> The views expressed in this message and any annex are purely those of
> the writer and may not be regarded as stating an official position of
> INBO, as long as the message is not confirmed by a duly signed document.
>


* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.

From megifford at ualr.edu  Fri Jun  7 20:44:47 2013
From: megifford at ualr.edu (Matthew Gifford)
Date: Fri, 7 Jun 2013 13:44:47 -0500
Subject: [R-sig-ME] MCMCglmm bivariate model - among individual covariance
Message-ID: <D387E21E-C9F4-4E58-9531-48E5FDB6DCC9@ualr.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130607/29d05e0a/attachment.pl>

From gavin.simpson at ucl.ac.uk  Fri Jun  7 21:54:26 2013
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Fri, 7 Jun 2013 13:54:26 -0600
Subject: [R-sig-ME] TukeyHSD after lmer repeated measures
In-Reply-To: <51B114F5.2040303@auburn.edu>
References: <51B114F5.2040303@auburn.edu>
Message-ID: <1370634866.23179.10.camel@haul.biol.uregina.ca>

On Thu, 2013-06-06 at 18:02 -0500, Stephen Sefick wrote:
> I fit this model:
> 
> repeated_measure_height <- lmer(HEIGHT~ISO+(TIME|EX_PLANT), data=x)
> 
> I would like to test if the mean levels of ISO are sig diff. from each 
> other (Is the difference greater than of less than 0).
> 
> Thank you for all of the help in advance.
> kindest regards,

Take a look at the multcomp package.

HTH

G

-- 
Gavin Simpson, PhD                          [t] +1 306 337 8863
Adjunct Professor, Department of Biology    [f] +1 306 337 2410
Institute of Environmental Change & Society [e] gavin.simpson at uregina.ca
523 Research and Innovation Centre          [tw] @ucfagls
University of Regina
Regina, SK S4S 0A2, Canada


From emmanuel.curis at parisdescartes.fr  Sat Jun  8 17:32:49 2013
From: emmanuel.curis at parisdescartes.fr (Emmanuel Curis)
Date: Sat, 8 Jun 2013 17:32:49 +0200
Subject: [R-sig-ME] How to analyze a 2x2 crossover with baseline in R?
Message-ID: <20130608153249.GA22563@info124.pharmacie.univ-paris5.fr>

Hello,

I have to test for the effect of a treatment in a crossover design
with the two sequences TP/PT (T = treatment, P = placebo), but with
also a single baseline measurement, before period 1. Sample data are
given at the end of this message.

I can do the analysis without the baseline measurement, but when I try
to include in it in the model, lme fails with the message

> lme( X7_SRF ~ Traitement + Periode, random = ~ 1|Numero,
       data = donnees,
       control = list( msVerbose = TRUE ) )
Erreur dans MEEM(object, conLin, control$niterEM) : 
  Singularit? rencontr?e en r?solution inverse au niveau 0, bloc 1

which should be in English something like ? Error in MEEM(...).
Singularity encountred when backsolving at level 0, bloc 1 ?.

lmer also fails complaing for a non-definite matrix.

I guess this is related to the fact that period J0 is confounded with
treatment = Baseline, as seen in 

> with( donnees, table( Periode, Traitement ) )
       Traitement
Periode Baseline Treatment Placebo
     J0       16         0       0
     M1        0         8       8
     M2        0         8       7

as may also suggest the fact that not using both Periode and
Traitement makes lme succeeds.

But how to write the model to fit, trying to reproduce the whole
time-evolution of the patient outcome knowing the time and the
condition? Does it make sense anyway, or fit periode 1 vs baseline and
period 2 vs periode 1 the only way to to something?

When I use lm, using the patient as a fixed effect, it seems to work
(some coefficients are NA, in agreement with the above problem I
guess), and results suggests there is no period or sequence effect,
especially if considering
but I am not very satisfied with it...

> anova( lm( X7_SRF ~ Traitement + Periode + Sequence + Numero,
             data = donnees ) ) )
Analysis of Variance Table

Response: X7_SRF
           Df Sum Sq Mean Sq F value  Pr(>F)    
Traitement  2 106533   53266    4,36 0,02248 *  
Periode     1  10721   10721    0,88 0,35694    
Sequence    1   2542    2542    0,21 0,65182    
Numero     14 829085   59220    4,85 0,00019 ***
Residuals  28 342135   12219                    

Same thing using aov, but there is a (slight) unbalance since one
patient leaved before the end, so how far can it be trusted?

> summary( aov( X7_SRF ~ Traitement + Periode + Sequence + Error(Numero),
                data = donnees ) ) )
Error: Numero
           Df Sum Sq Mean Sq F value Pr(>F)
Traitement  1  79638   79638    1,36   0,27
Sequence    1     24      24    0,00   0,98
Residuals  13 763423   58725               

Error: Within
           Df Sum Sq Mean Sq F value Pr(>F)  
Traitement  2 101121   50561    4,14  0,027 *
Periode     1   4673    4673    0,38  0,541  
Residuals  28 342135   12219                 

Thanks in advance for your advices,

The data:
> donnees
   X7_SRF Periode Sequence Traitement Numero
1     548      J0 Groupe A   Baseline      1
2     351      M1 Groupe A  Treatment      1
3     418      M2 Groupe A    Placebo      1
4     300      J0 Groupe A   Baseline     10
5     180      M1 Groupe A  Treatment     10
6     153      M2 Groupe A    Placebo     10
7     652      J0 Groupe A   Baseline     11
8     638      M1 Groupe A  Treatment     11
10    491      J0 Groupe B   Baseline     12
11    488      M1 Groupe B    Placebo     12
12    443      M2 Groupe B  Treatment     12
13    376      J0 Groupe B   Baseline     14
14    466      M1 Groupe B    Placebo     14
15    447      M2 Groupe B  Treatment     14
16    638      J0 Groupe A   Baseline     15
17    628      M1 Groupe A  Treatment     15
18    872      M2 Groupe A    Placebo     15
19    459      J0 Groupe A   Baseline     16
20    191      M1 Groupe A  Treatment     16
21    206      M2 Groupe A    Placebo     16
22    731      J0 Groupe B   Baseline     17
23    536      M1 Groupe B    Placebo     17
24    584      M2 Groupe B  Treatment     17
25    462      J0 Groupe B   Baseline      2
26    373      M1 Groupe B    Placebo      2
27    400      M2 Groupe B  Treatment      2
28    197      J0 Groupe B   Baseline      3
29    291      M1 Groupe B    Placebo      3
30    160      M2 Groupe B  Treatment      3
31    768      J0 Groupe B   Baseline      4
32    260      M1 Groupe B    Placebo      4
33    238      M2 Groupe B  Treatment      4
34    606      J0 Groupe A   Baseline      5
35    629      M1 Groupe A  Treatment      5
36    350      M2 Groupe A    Placebo      5
37    424      J0 Groupe A   Baseline      6
38    304      M1 Groupe A  Treatment      6
39    439      M2 Groupe A    Placebo      6
40    538      J0 Groupe A   Baseline      7
41    511      M1 Groupe A  Treatment      7
42    501      M2 Groupe A    Placebo      7
43    524      J0 Groupe B   Baseline      8
44    601      M1 Groupe B    Placebo      8
45    298      M2 Groupe B  Treatment      8
46    511      J0 Groupe B   Baseline      9
47    513      M1 Groupe B    Placebo      9
48    444      M2 Groupe B  Treatment      9

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From bbolker at gmail.com  Mon Jun 10 20:09:16 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 10 Jun 2013 18:09:16 +0000 (UTC)
Subject: [R-sig-ME] How to analyze a 2x2 crossover with baseline in R?
References: <20130608153249.GA22563@info124.pharmacie.univ-paris5.fr>
Message-ID: <loom.20130610T193524-232@post.gmane.org>

Emmanuel Curis <emmanuel.curis at ...> writes:

> 
> Hello,
> 
> I have to test for the effect of a treatment in a crossover design
> with the two sequences TP/PT (T = treatment, P = placebo), but with
> also a single baseline measurement, before period 1. Sample data are
> given at the end of this message.
> 
> I can do the analysis without the baseline measurement, but when I try
> to include in it in the model, lme fails with the message
> 

> Erreur dans MEEM(object, conLin, control$niterEM) : 
>   Singularit? rencontr?e en r?solution inverse au niveau 0, bloc 1
> 
> which should be in English something like ? Error in MEEM(...).
> Singularity encountred when backsolving at level 0, bloc 1 ?.
> 
> lmer also fails complaing for a non-definite matrix.
> 
> I guess this is related to the fact that period J0 is confounded with
> treatment = Baseline, as seen in 
> 
> > with( donnees, table( Periode, Traitement ) )
>        Traitement
> Periode Baseline Treatment Placebo
>      J0       16         0       0
>      M1        0         8       8
>      M2        0         8       7
> 
> as may also suggest the fact that not using both Periode and
> Traitement makes lme succeeds.
> 
> But how to write the model to fit, trying to reproduce the whole
> time-evolution of the patient outcome knowing the time and the
> condition? Does it make sense anyway, or fit periode 1 vs baseline and
> period 2 vs periode 1 the only way to to something?
> 
> When I use lm, using the patient as a fixed effect, it seems to work
> (some coefficients are NA, in agreement with the above problem I
> guess), and results suggests there is no period or sequence effect,
> especially if considering
> but I am not very satisfied with it...
> 

  The basic recipe here is to collapse your analysis into
a one-way analysis and then (hopefully) to reconstruct the
desired the contrasts.  I started to do this (below), but didn't
have quite enough time to finish it ...

donnees <- read.table(header=TRUE,
text="X7_SRF Periode Sequence Traitement Numero
548      J0 Groupe.A   Baseline      1
351      M1 Groupe.A  Treatment      1
418      M2 Groupe.A    Placebo      1
300      J0 Groupe.A   Baseline     10
180      M1 Groupe.A  Treatment     10
153      M2 Groupe.A    Placebo     10
652      J0 Groupe.A   Baseline     11
638      M1 Groupe.A  Treatment     11
491      J0 Groupe.B   Baseline     12
488      M1 Groupe.B    Placebo     12
443      M2 Groupe.B  Treatment     12
376      J0 Groupe.B   Baseline     14
466      M1 Groupe.B    Placebo     14
447      M2 Groupe.B  Treatment     14
638      J0 Groupe.A   Baseline     15
628      M1 Groupe.A  Treatment     15
872      M2 Groupe.A    Placebo     15
459      J0 Groupe.A   Baseline     16
191      M1 Groupe.A  Treatment     16
206      M2 Groupe.A    Placebo     16
731      J0 Groupe.B   Baseline     17
536      M1 Groupe.B    Placebo     17
584      M2 Groupe.B  Treatment     17
462      J0 Groupe.B   Baseline      2
373      M1 Groupe.B    Placebo      2
400      M2 Groupe.B  Treatment      2
197      J0 Groupe.B   Baseline      3
291      M1 Groupe.B    Placebo      3
160      M2 Groupe.B  Treatment      3
768      J0 Groupe.B   Baseline      4
260      M1 Groupe.B    Placebo      4
238      M2 Groupe.B  Treatment      4
606      J0 Groupe.A   Baseline      5
629      M1 Groupe.A  Treatment      5
350      M2 Groupe.A    Placebo      5
424      J0 Groupe.A   Baseline      6
304      M1 Groupe.A  Treatment      6
439      M2 Groupe.A    Placebo      6
538      J0 Groupe.A   Baseline      7
511      M1 Groupe.A  Treatment      7
501      M2 Groupe.A    Placebo      7
524      J0 Groupe.B   Baseline      8
601      M1 Groupe.B    Placebo      8
298      M2 Groupe.B  Treatment      8
511      J0 Groupe.B   Baseline      9
513      M1 Groupe.B    Placebo      9
444      M2 Groupe.B  Treatment      9")

library("nlme")
try(m1 <- lme( X7_SRF ~ Traitement + Periode, random = ~ 1|Numero,
       data = donnees,
       control = list( msVerbose = TRUE ) ))

donnees <- transform(donnees,TP=interaction(Traitement,Periode,drop=TRUE))

m2 <- lme( X7_SRF ~ TP, random = ~ 1|Numero,
       data = donnees,
       control = list( msVerbose = TRUE ) )
summary(m2)$tTable

I didn't succeed in the rest of this, but see
http://www.math.mcmaster.ca/~bolker/classes/s4c03/hw/hw2_s4c03.pdf
OR:
http://stackoverflow.com/questions/9335708/
   contrasts-for-lm-using-contrast-package
(broken URL)

for more information ...

contr1 <- matrix(
                 c(1,0,0,0,0,             # baseline
                    -1,1/2,1/2,0,0,       # baseline vs M1
                    0,-1/2,-1/2,1/2,1/2, # M1 vs M2
                   -1,1/2,0,1/2,0,       # baseline vs placebo
                    0,-1/2,1/2,-1/2,1/2), # placebo vs treatment
                    ## 0,1/2,-1/2,-1/2,1/2), # interaction:
                                          # (T2-P2)-(T1-P1) = T2+P1-T1-P2
              byrow=TRUE,ncol=5,
      dimnames=list(c("b","b_vs_M1","M1_vs_M2","b_vs_P","P_vs_T"),
                      c("B","PM1","TM1","PM2","TM2")))
                  
solve(contr1)


From rhtardin at gmail.com  Tue Jun 11 14:02:22 2013
From: rhtardin at gmail.com (Rodrigo Tardin)
Date: Tue, 11 Jun 2013 09:02:22 -0300
Subject: [R-sig-ME] Confidence intervals in GAMM4
In-Reply-To: <1370453771.3634.56.camel@haul.biol.uregina.ca>
References: <CAE5HZZ+h=qE4Ntrn=1ofwyxU24WrJQCPYki2Px34UgsEPn+1sw@mail.gmail.com>
	<1370453771.3634.56.camel@haul.biol.uregina.ca>
Message-ID: <CAE5HZZKkEmyCYre6NgJb3fciLX5pA8ZwkhaAuaXTR4=htY2ZWw@mail.gmail.com>

Um texto embutido e sem conjunto de caracteres especificado foi limpo...
Nome: n?o dispon?vel
Url: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130611/2c509498/attachment.pl>

From gavin.simpson at ucl.ac.uk  Tue Jun 11 18:08:21 2013
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Tue, 11 Jun 2013 10:08:21 -0600
Subject: [R-sig-ME] Confidence intervals in GAMM4
In-Reply-To: <CAE5HZZKkEmyCYre6NgJb3fciLX5pA8ZwkhaAuaXTR4=htY2ZWw@mail.gmail.com>
References: <CAE5HZZ+h=qE4Ntrn=1ofwyxU24WrJQCPYki2Px34UgsEPn+1sw@mail.gmail.com>
	<1370453771.3634.56.camel@haul.biol.uregina.ca>
	<CAE5HZZKkEmyCYre6NgJb3fciLX5pA8ZwkhaAuaXTR4=htY2ZWw@mail.gmail.com>
Message-ID: <1370966901.18170.4.camel@haul.biol.uregina.ca>

On Tue, 2013-06-11 at 09:02 -0300, Rodrigo Tardin wrote:
> Hi Gavin and other member of the list
> 
> Thanks a lot for your response. You are right about the correlation
> structure. I was not aware, thank you.
> One other question that may look like very basic:
> Without the correlation structure (that as you said, does not exist in
> GAMM4 or lme4) in the mixed model, does it account for autocorrelation or
> no, without any specification of correlation structure it does not account
> for autcorrelation in the residuals. Because my data do have a problem of
> autocorrelation on the residuals.

There is an induced correlation due to the random effect - all
observations within a level of RANDOM have the same estimated
correlation, IIRC. The AR(1) you hoped to specify would have that
correlation decline by the absolute power of the separation in time
(i.e. exponentially), so they are different.

If the residuals are correlated then you should do something about it if
you can as it may change which terms are significant in the model (as
standard errors are to narrow), and also with GAMMs where the smoothness
of the splines is determined from the data the procedure may tend to
under-smooth the data because it assumes that they are less correlated
than they really are.

HTH

G

> Thanks in advance
> Rodrigo
> 
> 
> 2013/6/5 Gavin Simpson <gavin.simpson at ucl.ac.uk>
> 
> > On Thu, 2013-05-30 at 12:12 -0300, Rodrigo Tardin wrote:
> > > Hi all,
> > >
> > <snip />
> > >
> > > I searched in R for confidence intervals in GAMM4 but I did not find it.
> > I
> > > could obtain variance and std deviation for the random and fixed effects
> > > Groups Name             Variance            Std.Dev.
> > >  RANDOM (Intercept)  1.4973e+01        3.8694319
> > >  Xr.0   s(DISTCOAST)  4.7361e-02        0.2176263
> > >  Xr     s(DEPTH)          1.9779e-06        0.0014064
> > >
> > >
> > > Here it is my model.
> > > n3 <- gamm4(OCC_BIN~s(DEPTH)+s(DISTANCE_TO_COAST)+offset(RT),random = ~
> > > (1|RANDOM),correlation=corAR1(),method="ML", family=binomial,data=bryde3)
> >
> > Unfortunately, this is *totally* wrong. There is no `correlation`
> > argument in `gamm4()` nor `glmer()`, which is the underlying fitting
> > function. That this didn't raise an error is due to `gamm4()` etc having
> > argument `...` which silently mops up any left over, non-used arguments.
> >
> > `gamm()` in package *mgcv* does have a `correlation` argument but that
> > will fit your binomial GLMM via PQL which isn't such a good solution for
> > such models.
> >
> > In nlme:::lme there was a function intervals() which could provide the
> > CI on the REs - see if there is an equivalent for lme4:::glmer. IIRC
> > Doug has something on this in his in-prep book on mixed effects models
> > via lme4, see chapter 1 in
> > http://lme4.r-forge.r-project.org/lMMwR/lrgprt.pdf
> >
> > That presumes that you sort out the AR(1) business; you can't do that in
> > glmer().
> >
> > Options are to move back to mgcv::gamm() but as I said, PQL isn't great
> > of binomial models. If your REs are simple, then mgcv::gam() can be
> > used. Again this doesn't have a correlation argument but ?magic (after
> > loading mgcv) has an example of including the correlation in the fit via
> > some jiggery-pokery. Alternatively and related to gam() is mgcv::bam()
> > which can take a known AR(1) parameter into account during the fitting.
> > This fits the AR(1) given the ordering of the data, which is what
> > `correlation=corAR1()` would have done - perhaps this just plain won't
> > work in nlme:::lme if you don't specify any ordering variable? - but I'm
> > not sure that will be correct given that your data are strictly time
> > ordered.
> >
> > HTH
> >
> > G
> >
> > > The OFFSET is the boat route (the number of times the boat searched for
> > > whales in each 2x2km grid)
> > > RANDOM is the individual whale as done in previous studies (Hazen et al
> > > 2009 - MEPS - doi:10.3354/meps08108)
> > >
> > > Can someone help me, please?
> > > Sincerely,
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> > --
> > Gavin Simpson, PhD                          [t] +1 306 337 8863
> > Adjunct Professor, Department of Biology    [f] +1 306 337 2410
> > Institute of Environmental Change & Society [e] gavin.simpson at uregina.ca
> > 523 Research and Innovation Centre          [tw] @ucfagls
> > University of Regina
> > Regina, SK S4S 0A2, Canada
> >
> >
> >
> >
> 
> 
> Hi Gavin and other member of the list
> 
> 
> Thanks a lot for your response. You are right about the correlation
> structure. I was not aware, thank you.
> One other question that may look like very basic:
> Without the correlation structure (that as you said, does not exist in
> GAMM4 or lme4) in the mixed model, does it account for autocorrelation
> or no, without any specification of correlation structure it does not
> account for autcorrelation in the residuals. Because my data do have a
> problem of autocorrelation on the residuals.
> 
> 
> Thanks in advance
> Rodrigo
> 
> 
> 2013/6/5 Gavin Simpson <gavin.simpson at ucl.ac.uk>
>         On Thu, 2013-05-30 at 12:12 -0300, Rodrigo Tardin wrote:
>         > Hi all,
>         >
>         <snip />
>         >
>         > I searched in R for confidence intervals in GAMM4 but I did
>         not find it. I
>         > could obtain variance and std deviation for the random and
>         fixed effects
>         > Groups Name             Variance            Std.Dev.
>         >  RANDOM (Intercept)  1.4973e+01        3.8694319
>         >  Xr.0   s(DISTCOAST)  4.7361e-02        0.2176263
>         >  Xr     s(DEPTH)          1.9779e-06        0.0014064
>         >
>         >
>         > Here it is my model.
>         > n3 <-
>         gamm4(OCC_BIN~s(DEPTH)+s(DISTANCE_TO_COAST)+offset(RT),random
>         = ~
>         > (1|RANDOM),correlation=corAR1(),method="ML",
>         family=binomial,data=bryde3)
>         
>         
>         Unfortunately, this is *totally* wrong. There is no
>         `correlation`
>         argument in `gamm4()` nor `glmer()`, which is the underlying
>         fitting
>         function. That this didn't raise an error is due to `gamm4()`
>         etc having
>         argument `...` which silently mops up any left over, non-used
>         arguments.
>         
>         `gamm()` in package *mgcv* does have a `correlation` argument
>         but that
>         will fit your binomial GLMM via PQL which isn't such a good
>         solution for
>         such models.
>         
>         In nlme:::lme there was a function intervals() which could
>         provide the
>         CI on the REs - see if there is an equivalent for
>         lme4:::glmer. IIRC
>         Doug has something on this in his in-prep book on mixed
>         effects models
>         via lme4, see chapter 1 in
>         http://lme4.r-forge.r-project.org/lMMwR/lrgprt.pdf
>         
>         That presumes that you sort out the AR(1) business; you can't
>         do that in
>         glmer().
>         
>         Options are to move back to mgcv::gamm() but as I said, PQL
>         isn't great
>         of binomial models. If your REs are simple, then mgcv::gam()
>         can be
>         used. Again this doesn't have a correlation argument
>         but ?magic (after
>         loading mgcv) has an example of including the correlation in
>         the fit via
>         some jiggery-pokery. Alternatively and related to gam() is
>         mgcv::bam()
>         which can take a known AR(1) parameter into account during the
>         fitting.
>         This fits the AR(1) given the ordering of the data, which is
>         what
>         `correlation=corAR1()` would have done - perhaps this just
>         plain won't
>         work in nlme:::lme if you don't specify any ordering variable?
>         - but I'm
>         not sure that will be correct given that your data are
>         strictly time
>         ordered.
>         
>         HTH
>         
>         G
>         
>         > The OFFSET is the boat route (the number of times the boat
>         searched for
>         > whales in each 2x2km grid)
>         > RANDOM is the individual whale as done in previous studies
>         (Hazen et al
>         > 2009 - MEPS - doi:10.3354/meps08108)
>         >
>         > Can someone help me, please?
>         > Sincerely,
>         
>         > _______________________________________________
>         > R-sig-mixed-models at r-project.org mailing list
>         > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>         
>         --
>         Gavin Simpson, PhD                          [t] +1 306 337
>         8863
>         Adjunct Professor, Department of Biology    [f] +1 306 337
>         2410
>         Institute of Environmental Change & Society [e]
>         gavin.simpson at uregina.ca
>         523 Research and Innovation Centre          [tw] @ucfagls
>         University of Regina
>         Regina, SK S4S 0A2, Canada
>         
>         
>         
> 
> 
> 
> 
> -- 
> Rodrigo Tardin
> 
> Doutorando em Ecologia e Conserva??o - IBRAG - UERJ
> Mestre em Biologia Animal - PPGBA - UFRRJ
> Especialista em Doc?ncia do Ensino Superior - IAVM
> Laborat?rio de Bioac?stica e Ecologia de Cet?ceos - UFRRJ/ IF/ DCA

-- 
Gavin Simpson, PhD                          [t] +1 306 337 8863
Adjunct Professor, Department of Biology    [f] +1 306 337 2410
Institute of Environmental Change & Society [e] gavin.simpson at uregina.ca
523 Research and Innovation Centre          [tw] @ucfagls
University of Regina
Regina, SK S4S 0A2, Canada


From jwiley.psych at gmail.com  Tue Jun 11 18:42:35 2013
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Tue, 11 Jun 2013 09:42:35 -0700
Subject: [R-sig-ME] Confidence intervals in GAMM4
In-Reply-To: <1370966901.18170.4.camel@haul.biol.uregina.ca>
References: <CAE5HZZ+h=qE4Ntrn=1ofwyxU24WrJQCPYki2Px34UgsEPn+1sw@mail.gmail.com>
	<1370453771.3634.56.camel@haul.biol.uregina.ca>
	<CAE5HZZKkEmyCYre6NgJb3fciLX5pA8ZwkhaAuaXTR4=htY2ZWw@mail.gmail.com>
	<1370966901.18170.4.camel@haul.biol.uregina.ca>
Message-ID: <CANz9Z_KAWU+8=T3e=wUiruTMZ8kvq=prYjTk9Tpo6xaWmn4Ogw@mail.gmail.com>

Hi Rodrigo,

If you have some knowledge about relations among the residuals, rather
than put a structure on the residuals, I would propose you try to it
into the model.

If within your level 2 units, you believe there are residual
correlations over time, this argues for a time effect in the model.
If you already have time in the model, and the residuals are still
correlated, then I would say either:

1) The treatment of time is insufficient --- for example using a
linear effect when you need some other functional form (since you are
using gams anyway, why not put a smooth term on time?)
2) Making the time effect a random effect

This should effectively take an effect that used to have nowhere to go
but the residuals and explicitly put it into the model.

Cheers,

Josh



On Tue, Jun 11, 2013 at 9:08 AM, Gavin Simpson <gavin.simpson at ucl.ac.uk> wrote:
> On Tue, 2013-06-11 at 09:02 -0300, Rodrigo Tardin wrote:
>> Hi Gavin and other member of the list
>>
>> Thanks a lot for your response. You are right about the correlation
>> structure. I was not aware, thank you.
>> One other question that may look like very basic:
>> Without the correlation structure (that as you said, does not exist in
>> GAMM4 or lme4) in the mixed model, does it account for autocorrelation or
>> no, without any specification of correlation structure it does not account
>> for autcorrelation in the residuals. Because my data do have a problem of
>> autocorrelation on the residuals.
>
> There is an induced correlation due to the random effect - all
> observations within a level of RANDOM have the same estimated
> correlation, IIRC. The AR(1) you hoped to specify would have that
> correlation decline by the absolute power of the separation in time
> (i.e. exponentially), so they are different.
>
> If the residuals are correlated then you should do something about it if
> you can as it may change which terms are significant in the model (as
> standard errors are to narrow), and also with GAMMs where the smoothness
> of the splines is determined from the data the procedure may tend to
> under-smooth the data because it assumes that they are less correlated
> than they really are.
>
> HTH
>
> G
>
>> Thanks in advance
>> Rodrigo
>>
>>
>> 2013/6/5 Gavin Simpson <gavin.simpson at ucl.ac.uk>
>>
>> > On Thu, 2013-05-30 at 12:12 -0300, Rodrigo Tardin wrote:
>> > > Hi all,
>> > >
>> > <snip />
>> > >
>> > > I searched in R for confidence intervals in GAMM4 but I did not find it.
>> > I
>> > > could obtain variance and std deviation for the random and fixed effects
>> > > Groups Name             Variance            Std.Dev.
>> > >  RANDOM (Intercept)  1.4973e+01        3.8694319
>> > >  Xr.0   s(DISTCOAST)  4.7361e-02        0.2176263
>> > >  Xr     s(DEPTH)          1.9779e-06        0.0014064
>> > >
>> > >
>> > > Here it is my model.
>> > > n3 <- gamm4(OCC_BIN~s(DEPTH)+s(DISTANCE_TO_COAST)+offset(RT),random = ~
>> > > (1|RANDOM),correlation=corAR1(),method="ML", family=binomial,data=bryde3)
>> >
>> > Unfortunately, this is *totally* wrong. There is no `correlation`
>> > argument in `gamm4()` nor `glmer()`, which is the underlying fitting
>> > function. That this didn't raise an error is due to `gamm4()` etc having
>> > argument `...` which silently mops up any left over, non-used arguments.
>> >
>> > `gamm()` in package *mgcv* does have a `correlation` argument but that
>> > will fit your binomial GLMM via PQL which isn't such a good solution for
>> > such models.
>> >
>> > In nlme:::lme there was a function intervals() which could provide the
>> > CI on the REs - see if there is an equivalent for lme4:::glmer. IIRC
>> > Doug has something on this in his in-prep book on mixed effects models
>> > via lme4, see chapter 1 in
>> > http://lme4.r-forge.r-project.org/lMMwR/lrgprt.pdf
>> >
>> > That presumes that you sort out the AR(1) business; you can't do that in
>> > glmer().
>> >
>> > Options are to move back to mgcv::gamm() but as I said, PQL isn't great
>> > of binomial models. If your REs are simple, then mgcv::gam() can be
>> > used. Again this doesn't have a correlation argument but ?magic (after
>> > loading mgcv) has an example of including the correlation in the fit via
>> > some jiggery-pokery. Alternatively and related to gam() is mgcv::bam()
>> > which can take a known AR(1) parameter into account during the fitting.
>> > This fits the AR(1) given the ordering of the data, which is what
>> > `correlation=corAR1()` would have done - perhaps this just plain won't
>> > work in nlme:::lme if you don't specify any ordering variable? - but I'm
>> > not sure that will be correct given that your data are strictly time
>> > ordered.
>> >
>> > HTH
>> >
>> > G
>> >
>> > > The OFFSET is the boat route (the number of times the boat searched for
>> > > whales in each 2x2km grid)
>> > > RANDOM is the individual whale as done in previous studies (Hazen et al
>> > > 2009 - MEPS - doi:10.3354/meps08108)
>> > >
>> > > Can someone help me, please?
>> > > Sincerely,
>> > > _______________________________________________
>> > > R-sig-mixed-models at r-project.org mailing list
>> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>> > --
>> > Gavin Simpson, PhD                          [t] +1 306 337 8863
>> > Adjunct Professor, Department of Biology    [f] +1 306 337 2410
>> > Institute of Environmental Change & Society [e] gavin.simpson at uregina.ca
>> > 523 Research and Innovation Centre          [tw] @ucfagls
>> > University of Regina
>> > Regina, SK S4S 0A2, Canada
>> >
>> >
>> >
>> >
>>
>>
>> Hi Gavin and other member of the list
>>
>>
>> Thanks a lot for your response. You are right about the correlation
>> structure. I was not aware, thank you.
>> One other question that may look like very basic:
>> Without the correlation structure (that as you said, does not exist in
>> GAMM4 or lme4) in the mixed model, does it account for autocorrelation
>> or no, without any specification of correlation structure it does not
>> account for autcorrelation in the residuals. Because my data do have a
>> problem of autocorrelation on the residuals.
>>
>>
>> Thanks in advance
>> Rodrigo
>>
>>
>> 2013/6/5 Gavin Simpson <gavin.simpson at ucl.ac.uk>
>>         On Thu, 2013-05-30 at 12:12 -0300, Rodrigo Tardin wrote:
>>         > Hi all,
>>         >
>>         <snip />
>>         >
>>         > I searched in R for confidence intervals in GAMM4 but I did
>>         not find it. I
>>         > could obtain variance and std deviation for the random and
>>         fixed effects
>>         > Groups Name             Variance            Std.Dev.
>>         >  RANDOM (Intercept)  1.4973e+01        3.8694319
>>         >  Xr.0   s(DISTCOAST)  4.7361e-02        0.2176263
>>         >  Xr     s(DEPTH)          1.9779e-06        0.0014064
>>         >
>>         >
>>         > Here it is my model.
>>         > n3 <-
>>         gamm4(OCC_BIN~s(DEPTH)+s(DISTANCE_TO_COAST)+offset(RT),random
>>         = ~
>>         > (1|RANDOM),correlation=corAR1(),method="ML",
>>         family=binomial,data=bryde3)
>>
>>
>>         Unfortunately, this is *totally* wrong. There is no
>>         `correlation`
>>         argument in `gamm4()` nor `glmer()`, which is the underlying
>>         fitting
>>         function. That this didn't raise an error is due to `gamm4()`
>>         etc having
>>         argument `...` which silently mops up any left over, non-used
>>         arguments.
>>
>>         `gamm()` in package *mgcv* does have a `correlation` argument
>>         but that
>>         will fit your binomial GLMM via PQL which isn't such a good
>>         solution for
>>         such models.
>>
>>         In nlme:::lme there was a function intervals() which could
>>         provide the
>>         CI on the REs - see if there is an equivalent for
>>         lme4:::glmer. IIRC
>>         Doug has something on this in his in-prep book on mixed
>>         effects models
>>         via lme4, see chapter 1 in
>>         http://lme4.r-forge.r-project.org/lMMwR/lrgprt.pdf
>>
>>         That presumes that you sort out the AR(1) business; you can't
>>         do that in
>>         glmer().
>>
>>         Options are to move back to mgcv::gamm() but as I said, PQL
>>         isn't great
>>         of binomial models. If your REs are simple, then mgcv::gam()
>>         can be
>>         used. Again this doesn't have a correlation argument
>>         but ?magic (after
>>         loading mgcv) has an example of including the correlation in
>>         the fit via
>>         some jiggery-pokery. Alternatively and related to gam() is
>>         mgcv::bam()
>>         which can take a known AR(1) parameter into account during the
>>         fitting.
>>         This fits the AR(1) given the ordering of the data, which is
>>         what
>>         `correlation=corAR1()` would have done - perhaps this just
>>         plain won't
>>         work in nlme:::lme if you don't specify any ordering variable?
>>         - but I'm
>>         not sure that will be correct given that your data are
>>         strictly time
>>         ordered.
>>
>>         HTH
>>
>>         G
>>
>>         > The OFFSET is the boat route (the number of times the boat
>>         searched for
>>         > whales in each 2x2km grid)
>>         > RANDOM is the individual whale as done in previous studies
>>         (Hazen et al
>>         > 2009 - MEPS - doi:10.3354/meps08108)
>>         >
>>         > Can someone help me, please?
>>         > Sincerely,
>>
>>         > _______________________________________________
>>         > R-sig-mixed-models at r-project.org mailing list
>>         > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>         --
>>         Gavin Simpson, PhD                          [t] +1 306 337
>>         8863
>>         Adjunct Professor, Department of Biology    [f] +1 306 337
>>         2410
>>         Institute of Environmental Change & Society [e]
>>         gavin.simpson at uregina.ca
>>         523 Research and Innovation Centre          [tw] @ucfagls
>>         University of Regina
>>         Regina, SK S4S 0A2, Canada
>>
>>
>>
>>
>>
>>
>>
>> --
>> Rodrigo Tardin
>>
>> Doutorando em Ecologia e Conserva??o - IBRAG - UERJ
>> Mestre em Biologia Animal - PPGBA - UFRRJ
>> Especialista em Doc?ncia do Ensino Superior - IAVM
>> Laborat?rio de Bioac?stica e Ecologia de Cet?ceos - UFRRJ/ IF/ DCA
>
> --
> Gavin Simpson, PhD                          [t] +1 306 337 8863
> Adjunct Professor, Department of Biology    [f] +1 306 337 2410
> Institute of Environmental Change & Society [e] gavin.simpson at uregina.ca
> 523 Research and Innovation Centre          [tw] @ucfagls
> University of Regina
> Regina, SK S4S 0A2, Canada
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
University of California, Los Angeles
http://joshuawiley.com/
Senior Analyst - Elkhart Group Ltd.
http://elkhartgroup.com


From emmanuel.curis at parisdescartes.fr  Tue Jun 11 19:58:44 2013
From: emmanuel.curis at parisdescartes.fr (Emmanuel Curis)
Date: Tue, 11 Jun 2013 19:58:44 +0200
Subject: [R-sig-ME] How to analyze a 2x2 crossover with baseline in R?
In-Reply-To: <loom.20130610T193524-232@post.gmane.org>
References: <20130608153249.GA22563@info124.pharmacie.univ-paris5.fr>
	<loom.20130610T193524-232@post.gmane.org>
Message-ID: <20130611175844.GW26032@info124.pharmacie.univ-paris5.fr>

Hello,

Thank you very much for the hint and the sample code. I'll make some
tests with this, and take the time to carefully write the needed
contrasts, including in addition the Sequence effect...

On Mon, Jun 10, 2013 at 06:09:16PM +0000, Ben Bolker wrote:
? Emmanuel Curis <emmanuel.curis at ...> writes:
? 
?   The basic recipe here is to collapse your analysis into
? a one-way analysis and then (hopefully) to reconstruct the
? desired the contrasts.  I started to do this (below), but didn't
? have quite enough time to finish it ...
? 
? 
? library("nlme")
? try(m1 <- lme( X7_SRF ~ Traitement + Periode, random = ~ 1|Numero,
?        data = donnees,
?        control = list( msVerbose = TRUE ) ))
? 
? donnees <- transform(donnees,TP=interaction(Traitement,Periode,drop=TRUE))
? 
? m2 <- lme( X7_SRF ~ TP, random = ~ 1|Numero,
?        data = donnees,
?        control = list( msVerbose = TRUE ) )
? summary(m2)$tTable
? 
? I didn't succeed in the rest of this, but see
? http://www.math.mcmaster.ca/~bolker/classes/s4c03/hw/hw2_s4c03.pdf
? OR:
? http://stackoverflow.com/questions/9335708/
?    contrasts-for-lm-using-contrast-package
? (broken URL)
? 
? for more information ...
? 
? contr1 <- matrix(
?                  c(1,0,0,0,0,             # baseline
?                     -1,1/2,1/2,0,0,       # baseline vs M1
?                     0,-1/2,-1/2,1/2,1/2, # M1 vs M2
?                    -1,1/2,0,1/2,0,       # baseline vs placebo
?                     0,-1/2,1/2,-1/2,1/2), # placebo vs treatment
?                     ## 0,1/2,-1/2,-1/2,1/2), # interaction:
?                                           # (T2-P2)-(T1-P1) = T2+P1-T1-P2
?               byrow=TRUE,ncol=5,
?       dimnames=list(c("b","b_vs_M1","M1_vs_M2","b_vs_P","P_vs_T"),
?                       c("B","PM1","TM1","PM2","TM2")))
?                   
? solve(contr1)
? 
? _______________________________________________
? R-sig-mixed-models at r-project.org mailing list
? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From jbufford at hawaii.edu  Wed Jun 12 03:19:08 2013
From: jbufford at hawaii.edu (Jennifer Bufford)
Date: Tue, 11 Jun 2013 18:19:08 -0700
Subject: [R-sig-ME] Heteroscedasticity, lme4 and nlme
Message-ID: <CAHhx=4GY6fRL7frbKrqjmdCz3SYEvd2cZQtgjtGQ2zHWrZTLjQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130611/392c70b9/attachment.pl>

From highstat at highstat.com  Wed Jun 12 08:19:10 2013
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Wed, 12 Jun 2013 07:19:10 +0100
Subject: [R-sig-ME] Confidence intervals in GAMM4
In-Reply-To: <mailman.7729.1370968964.4595.r-sig-mixed-models@r-project.org>
References: <mailman.7729.1370968964.4595.r-sig-mixed-models@r-project.org>
Message-ID: <51B812DE.3000001@highstat.com>



> ----------------------------------------------------------------------
>
> Message: 1
> Date: Tue, 11 Jun 2013 09:02:22 -0300
> From: Rodrigo Tardin <rhtardin at gmail.com>
> To: Gavin Simpson <gavin.simpson at ucl.ac.uk>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Confidence intervals in GAMM4
> Message-ID:
> 	<CAE5HZZKkEmyCYre6NgJb3fciLX5pA8ZwkhaAuaXTR4=htY2ZWw at mail.gmail.com>
> Content-Type: text/plain
>
> Hi Gavin and other member of the list
>
> Thanks a lot for your response. You are right about the correlation
> structure. I was not aware, thank you.
> One other question that may look like very basic:
> Without the correlation structure (that as you said, does not exist in
> GAMM4 or lme4) in the mixed model, does it account for autocorrelation or
> no, without any specification of correlation structure it does not account
> for autcorrelation in the residuals. Because my data do have a problem of
> autocorrelation on the residuals.

Hello,
Here is an alternative (and probably the only) approach:

1. Write your smoother as X * beta + Z * b (e.g. using an O'Sullivan spline)
2. Add more covariates to your predictor function (if needed)
3. Add random effects to the predictor function, and also an 
auto-regressive correlation structure on the residuals in the predictor 
function.
4. Put the whole thing in JAGS and let it run for a while

Plenty of papers are available for step 1...see for example:

ON SEMIPARAMETRIC REGRESSION WITH O?SULLIVAN PENALIZED SPLINES
M. P. WAND AND J. T. ORMEROD

They also provide R code for such smoothers. No need to dive into the 
underlying stats.


Steps 3 & 4 are described in our upcoming book
'Beginner's Guide to GLM & GLMM with R"
Zuur, Hilbe, Ieno

available next week

Other smoother options are described in 'A Beginner's Guide to GAM', 
Zuur (2012)
Or in Wood (2006), or Ruppert et al. (2003). Plus a whole bunch of 
papers from Wand.


Alain
> Thanks in advance
> Rodrigo




-- 

Dr. Alain F. Zuur
First author of:

1. Analysing Ecological Data (2007).
Zuur, AF, Ieno, EN and Smith, GM. Springer. 680 p.
URL: www.springer.com/0-387-45967-7


2. Mixed effects models and extensions in ecology with R. (2009).
Zuur, AF, Ieno, EN, Walker, N, Saveliev, AA, and Smith, GM. Springer.
http://www.springer.com/life+sci/ecology/book/978-0-387-87457-9


3. A Beginner's Guide to R (2009).
Zuur, AF, Ieno, EN, Meesters, EHWG. Springer
http://www.springer.com/statistics/computational/book/978-0-387-93836-3


4. Zero Inflated Models and Generalized Linear Mixed Models with R. (2012) Zuur, Saveliev, Ieno.
http://www.highstat.com/book4.htm

Other books: http://www.highstat.com/books.htm


Statistical consultancy, courses, data analysis and software
Highland Statistics Ltd.
6 Laverock road
UK - AB41 6FN Newburgh
Tel: 0044 1358 788177
Email: highstat at highstat.com
URL: www.highstat.com
URL: www.brodgar.com


From rwwiley at gmail.com  Wed Jun 12 19:37:14 2013
From: rwwiley at gmail.com (Bob Wiley)
Date: Wed, 12 Jun 2013 13:37:14 -0400
Subject: [R-sig-ME] conceptualizing items + subject analysis
Message-ID: <CAH08405WGQMLW2aoECVTOwDavZJkRLsaoPYv4E77m+g+vqjuCw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130612/c596f4cc/attachment.pl>

From bbolker at gmail.com  Wed Jun 12 21:54:36 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 12 Jun 2013 19:54:36 +0000 (UTC)
Subject: [R-sig-ME] Heteroscedasticity, lme4 and nlme
References: <CAHhx=4GY6fRL7frbKrqjmdCz3SYEvd2cZQtgjtGQ2zHWrZTLjQ@mail.gmail.com>
Message-ID: <loom.20130612T214345-576@post.gmane.org>

Jennifer Bufford <jbufford at ...> writes:

>

[snip]
 
> I am working on my dissertation and using mixed models for quite a bit of
> my analysis. Here are some details about my experiment and data:

> I grew seedlings of 21 species in two sites, 10 blocks per site, and 2
> plots per block either with or without competition ("Weeds").  I am also
> including phylogenetic family (3 families) and invasiveness (3
> categories).  I have site and family as fixed effects because I understand
> there aren't enough categories to reliably estimate them as random
> effects.  I have several potential continuous covariates as well.  My model
> includes all possible two-way interactions, fixed and random, and I am
> reducing the model using the likelihood ratio test.  My goal in reducing
> the model is to improve clarity and avoid over-fitting.  I have both
> continuous (transformed) and binomial response variables.
> 
> Here's a full (unreduced) model without covariates:
> RGR.simple <- lmer(RGR ~ Inv + Weeds + Site + Fam + Inv:Weeds + Inv:Site +
> Weeds:Site + Weeds:Fam + Site:Fam + (1|Blk) + (1|Plot) + (1|Sp) + (0 +
> Site|Sp) + (0+Weeds|Sp), fdatRGR, family="gaussian")

  You don't need family="gaussian" here, and you might be able to
write the fixed-effect part of your formula more compactly as

RGR ~ (Inv + Weeds + Site + Fam)^2 + ... 

 I assume that the plots are uniquely labeled.

> My data are extremely unbalanced. I have heteroscedasticity in the
> residuals of my full and reduced models, as seen both by plotting and using
> leveneTest (package car).

  That's unfortunate.  I know your data are already growth relative
to size, but does log-transforming your data help?

> I have several questions, which center largely around the issue of
> heteroscedasticity:
> 
> I have both crossed random effects and serious heteroscedasticity.  I'd
> like to implement a non-homogeneous variance structure, but as far as I can
> tell, that can only be done in lme (from nlme), not in lmer (from lme4).
> Is that right?  I have heard that there are some work-arounds to get
> crossed random effects in lme.  
  
  Yes, see pp 163ff of Pinheiro and Bates 2000 (this is referenced
in http://glmm.wikidot.com/faq)

> Would that be the best solution in this
> situation?  If I specified an alternate variance structure by species,
> should residuals by species be homogenous (ie non-significant Levene's
> Test) or not?

  I don't think they would need to be

> I've also gotten a bit confused about random interactions.  lme4 allows
> much more complex random effects - would that in some way help account for
> heteroscedasticity?  If so, it hasn't worked for my data, but I want to
> understand what the random effects are doing.  In other words, what is the
> difference between specifying a variance structure (e.g. varIDent(form =
> ~1|Species) and including vector-valued random effects (e.g.
> (Competition|Species))?  My model statistics (ie LRT and AIC) tell me that
> many of the models are better with these complex random effects, but that
> also restricts my movement from lme4 to nlme.

  varIdent(form=~1|Species) says that the residual variance differs
among species.

  (Competition|Species) says that the effect of competition varies
among species.

> There is a weights function in lmer, but I know it is not the same as the
> weights function in lme.  If I use the weights term in lmer to specify
> weighting by the scaled reciprocal of species variance, that would give
> species with smaller variances a greater "say" in the model - is that
> right?  Weighting this way does fix my heteroscedasticity problems, but I'm
> not sure if it is a valid approach.

  I'm not sure if this works: also, there's likely to be some
correlation between the different parts of the variance structure
(e.g. between estimates of differences in residual variances among species
and estimates of the random-effects variances)

  Everything you've said so far seems reasonable, but I'm still a bit
worried that you're working with too complex a model.  Can you think
of plausible ways to simplify that you would be comfortable with?

  Another option, if you really want to do complex variance models
like this, is to build your own in WinBUGS/AD Model Builder -- then
you really know exactly what's going on.

   If you can, it would be worth simulating some data that are
as complex as the models you're trying to fit, and see if you can
get reasonable answers ...


From Andrew.McFadden at mpi.govt.nz  Wed Jun 12 22:42:28 2013
From: Andrew.McFadden at mpi.govt.nz (Andrew McFadden (Andy))
Date: Wed, 12 Jun 2013 20:42:28 +0000
Subject: [R-sig-ME] MLWIN in R_error message_Error in read.dta(IGLSfile):
 unable to open file: 'No such file or directory'
Message-ID: <59311B7BAD60F14E99B53F85C5413E221CEAD120@WDCWASP435.network.maf.govt.nz>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130612/94c3dcd6/attachment.pl>

From bbolker at gmail.com  Thu Jun 13 01:15:37 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 12 Jun 2013 23:15:37 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?MLWIN_in_R=5Ferrormessage=5FError_in_read=2E?=
	=?utf-8?q?dta=28IGLSfile=29=3A_unable_to_open_file=3A_=27No_such_f?=
	=?utf-8?q?ile_or_directory=27?=
References: <59311B7BAD60F14E99B53F85C5413E221CEAD120@WDCWASP435.network.maf.govt.nz>
Message-ID: <loom.20130613T011232-401@post.gmane.org>

Andrew McFadden (Andy <Andrew.McFadden at ...> writes:

> I am trying to run MLWIN within R. I have used an example put
> together by the developers of the package (R2MLwiN) but get an error
> message that I cant figure out. Really appreciate a hand
 
> I get the following message:
> 
> Cannot find worksheet: Settings/Temp/RtmpYpbSae/macrofile_103829e77324.txt
> Cannot find macro: C:/DOCUME~1/mcfaddena/Local
> Execution completed
> Error in read.dta(IGLSfile) :
>   unable to open file: 'No such file or directory'
> 

 [snip]

  I'm going to take a guess that you're having a problem with
file paths containing spaces, but it's really going to be hard
for me to tell since I don't have MLwiN installed.  I would suggest:
(1) contacting the package maintainer and (2) if you have the
expertise, trying the usual R debugging tricks [?traceback,
?browser, options(error=recover)] to see where the problem is.

  Ben Bolker


From baron at psych.upenn.edu  Thu Jun 13 15:00:51 2013
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Thu, 13 Jun 2013 09:00:51 -0400
Subject: [R-sig-ME] conceptualizing items + subject analysis
In-Reply-To: <CAH08405WGQMLW2aoECVTOwDavZJkRLsaoPYv4E77m+g+vqjuCw@mail.gmail.com>
References: <CAH08405WGQMLW2aoECVTOwDavZJkRLsaoPYv4E77m+g+vqjuCw@mail.gmail.com>
Message-ID: <20130613130051.GA28954@psych.upenn.edu>

On 06/12/13 13:37, Bob Wiley wrote:
> Hello,
> 
> Let me start by briefly explaining my dataset and the question I'm trying
> to answer:
> Subjects saw pairs of letters and responded either "same" or "different"
> (e.g. they saw "L L" and responded "same" or "L R" and responded
> "different") and I have measures for both accuracy and response time.
> 
> .I want to predict their reaction time on correct "different" responses
> based off of several factors:
> pixels - the pixel overlap of the two letters
> alphabet - their proximity in the alphabet
> identity - whether or not they have the same name, like "r R" or "g G"
> 
> Each pair has been coded with a value on all of these measures, for example:
> "r R" gets a 0.13 on pixels, a 0 on alphabet, and a 1 on identity,
> while
> "E F" gets 0.64 on pixels, a 1 on alphabet, and a 0 on identity
> 
> So of course I have this large data set of 24*990 observations (less
> incorrect responses). But I've gotten confused now about how best to
> predict the reaction time on these factors, accounting for the random
> effects... I was thinking the R model would be:
> 
> fit = lmer ( rt ~ pixels + alphabet + identity + (1|Subject) + (1|Pair))
> 
> The model does run, and in fact all factors come out significant. But I
> have two concerns:
> 1. That entering the data/defining the model this way is not correct.

Why not?

The only problem I can see is a substantive one, and I'm not sure
about it. Because you are looking at "different" responses only, Ee
would be "yes" but EE or ee would be "no". Thus, you have
same/different confounded to some extent with
same-case/different-case. Similarly, same-case/different-case might be
confounded with pixels. Subjects might carry out (simultaneous)
comparisons of same-different visually (V), same-different in identity
(I), and same-different in case (C). The results of C would determine
the relevance of I or V. Thus, you might want to look at what happens
if you include a term for C, and terms for its interaction with V and
C. (Not sure this is exactly right, but something like this.)

Also, I'm not sure how to handle possible individual
differences. Subjects may differ in the relative speeds of V, I, and
C, and thus in the efficiency of different strategies. If you thought
that subjects might reasonably differ in the direction of various
effects, then you might want to include random slopes. But if your
hypotheses are correctly one-tailed (and I think they are), then I
don't see that you need to do this. With data like these, you could
also test individual subjects. (See
http://www.sas.upenn.edu/~baron/papers/sinica.pdf.)

And you might want to include a term for the order of a given trial in
the sequence of trials. Subjects get faster throughout an
experiment. So including such a term can reduce the variance otherwise
attributed to "error" and make the other comparisons more
sensitive. In my experience, if you use the log of RT as the dependent
variable (usually a good idea anyway, unless you are testing additive
factors), then the effect of order is close to linear.

> 2. That I need  to determine some goodness of fit for the model and
> contribution of these factors, the MCMC p-value not being sufficient to
> defend the inclusion of all of these variables

Here I'm afraid I can't help because I don't understand the
problem. There are lots of outputs aside from MCMC p-values. And I
don't understand why a low p-value is not sufficient for inclusion.

> Any advice or pointing out of my mistakes will be much appreciated. Thank
> you!
> 
> Bob, JHU
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron
Editor: Judgment and Decision Making (http://journal.sjdm.org)


From jake987722 at hotmail.com  Thu Jun 13 19:41:07 2013
From: jake987722 at hotmail.com (Jake Westfall)
Date: Thu, 13 Jun 2013 11:41:07 -0600
Subject: [R-sig-ME] conceptualizing items + subject analysis
In-Reply-To: <20130613130051.GA28954@psych.upenn.edu>
References: <CAH08405WGQMLW2aoECVTOwDavZJkRLsaoPYv4E77m+g+vqjuCw@mail.gmail.com>,
	<20130613130051.GA28954@psych.upenn.edu>
Message-ID: <BAY172-W52982D6C2D8548322B842CB870@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130613/649ad104/attachment.pl>

From donald at uchicago.edu  Thu Jun 13 22:48:13 2013
From: donald at uchicago.edu (Donald Edward Frederick)
Date: Thu, 13 Jun 2013 15:48:13 -0500
Subject: [R-sig-ME] Psychometric curves with glmm
Message-ID: <CAP4wOgAu5vMp+Ca7QOJFSxOHWiUHjdcm-jtfXrTh1d_JCF3x4w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130613/d6398466/attachment.pl>

From rwwiley at gmail.com  Fri Jun 14 00:21:31 2013
From: rwwiley at gmail.com (Bob Wiley)
Date: Thu, 13 Jun 2013 18:21:31 -0400
Subject: [R-sig-ME] conceptualizing items + subject analysis
In-Reply-To: <BAY172-W52982D6C2D8548322B842CB870@phx.gbl>
References: <CAH08405WGQMLW2aoECVTOwDavZJkRLsaoPYv4E77m+g+vqjuCw@mail.gmail.com>
	<20130613130051.GA28954@psych.upenn.edu>
	<BAY172-W52982D6C2D8548322B842CB870@phx.gbl>
Message-ID: <CAH08404JVKQNt1jtBTaCpx-+2QTU2szVc8k8cOFRoNtGr+znAw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130613/ec1c2d81/attachment.pl>

From John.Morrongiello at csiro.au  Fri Jun 14 08:17:22 2013
From: John.Morrongiello at csiro.au (John.Morrongiello at csiro.au)
Date: Fri, 14 Jun 2013 06:17:22 +0000
Subject: [R-sig-ME] GAMM and GLMM for time to event data
Message-ID: <2547E22D246F3945BB491BDD8257C2E756BE5A11@exmbx06-cdc.nexus.csiro.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130614/d5c9c940/attachment.pl>

From ken.knoblauch at inserm.fr  Fri Jun 14 09:10:01 2013
From: ken.knoblauch at inserm.fr (Ken Knoblauch)
Date: Fri, 14 Jun 2013 07:10:01 +0000 (UTC)
Subject: [R-sig-ME] Psychometric curves with glmm
References: <CAP4wOgAu5vMp+Ca7QOJFSxOHWiUHjdcm-jtfXrTh1d_JCF3x4w@mail.gmail.com>
Message-ID: <loom.20130614T085527-717@post.gmane.org>

Donald Edward Frederick <donald at ...> writes:

> 
> Hello all,
> 
......
> Rats (n=8) are trained to discriminate between two stimuli (A,B).
> Each rat is tested on four (4) different stimulus pairs (
> (A1,B1),(A2,B2),...).
> Each rat is tested on each pair for three days. The stimulus pair
> presentation order is randomly selected.
> Each day consists of ~300 trials evenly split between the two stimuli.
> 
> I would like to construct a psychometric curve of performance against
> sampling duration. The rats select their own 'sampling duration' for each
> presentation on each trial. I am interested in knowing if there is a
> general effect where stimulus sampling duration predicts performance (I
> expect a sigmoidal relationship). I also want to model the effects of the
> stimulus set, the stimulus (A,B), and day when accounting for the random
> effects (Subject, StimulusSet, Day).
> 
.....
> My current model is:
> 
> glmer(Correct ~
> SampleDuration+StimulusSet+Stimulus+Day+(StimulusSet:Day|Subject),
> family=binomial(link="logit"), data=g)
> 
> When I run this, my results are not unexpected, but I'm always leery of
> this. I *think* that this model fits the fixed effects of 
(SampleDuration,
> StimulusSet,Stimulus, and Day). Additionally, I fit a 
random intercept for
> each subject and a random slope for each subject that varies by
> StimulusSet:Day.
> 
> I expect that there are some individual differences 
between the Subjects. I
> also expect that there will be differences between 
StimulusSets and Days.
> Specifically, some StimulusSets are easier than others and there is
> learning from Day 1 to Day 3.
> 
> Does this all make sense, or, have I ventured down a terrible path?
> 
> Thanks
> 
> Donald
> 

A couple of thoughts.

Is Correct a binary variable representing the response on individual
trials, i.e., taking on two values, say 0/1?  or is it either the
proportion of correct responses or the number?  If it is the
proportion then you want to include a weights argument with
the number of trials and if it is the number, then it would
be better that Correct is a 2 column matrix with Correct
and Incorrect columns.

Is this a two-alternative forced-choice situation, i.e., 
would the sigmoids lower asymptote be expected to
be at 0.5 instead of 0?  If so, you might consider using
the mafc.logit link function from the psyphy package
but you would have to use the development version
of lme4 for it to work.

Since rats choose SampleDuration, do you want it to be
a random slope term as well?

Your random term, (StimulusSet:Day|Subject), gives the overall
variability for subject within each combination of StimulusSet and Day.
You might want to consider terms like (1 | Subject/Day) that
give a random intercept for both Subject and Subject:Day. This is
equivalent to having terms (1 | Subject) + (1 | Subject:Day).
You would have to think more deeply as to how to include all of the
terms in your experiment but that might get you started.

Hope that is helpful.

best,

Ken

-- 
Kenneth Knoblauch
Inserm U846
Stem-cell and Brain Research Institute
Department of Integrative Neurosciences
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.sbri.fr/members/kenneth-knoblauch.html


From wolfgang.viechtbauer at maastrichtuniversity.nl  Tue Jun 18 16:24:23 2013
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Tue, 18 Jun 2013 16:24:23 +0200
Subject: [R-sig-ME] Logistic Regression for Matched Case-Control Data
Message-ID: <077E31A57DA26E46AB0D493C9966AC730D7BA1B129@UM-MAIL4112.unimaas.nl>

Dear All,

I am trying to wrap my head around using logistic random-effects regression models for the analysis of matched data and the results I obtain with lmer() when using this approach. So, let's say we have dichotomous outcomes for matched subjects in 2 groups (could also be repeated measurements on a single subject -- the idea is the same). We can write the subject-specific model as:

P(Y_ij = 1) = alpha_i + beta x_ij,

where Y_ij is the observed outcome (either 1 or 0) for subject j (either 1 or 2) for pair i (j = 1, ..., n), x_ij=0 for group 1, x_ij=1 for group 2, alpha_i is the intercept for pair i, and beta is the log(OR). Estimating this model with fixed intercepts is problematic, so the usual approach is to use a conditional logistic model (conditioning on Y_i1 + Y_i2). The conditional ML estimator of beta (and its SE) can actually be given in closed form, so we can easily check the results. Alternatively, we can treat the data for a single pair as a 2x2 table (with 2 subjects) and use the Cochran-Mantel-Haenszel test for the stratified 2x2 table data. This is in fact identical to McNemar's test for the same data. Here is an example:

########################################################################

library(survival)
library(metafor)

### number of pairs
n <- 100

### create some data
ai <- c(rep(0,n/2), rep(1,n/2))
bi <- 1-ai
ci <- c(rep(0,42), rep(1,8), rep(0,18), rep(1,32))
di <- 1-ci

### matched pair data
tab <- table(ai,ci)
tab

### McNemar's test
mcnemar.test(table(ai,ci))

### conditional ML estimator of log(OR) and corresponding SE
round(log(tab[2,1]/tab[1,2]),4)
round(sqrt(1/tab[2,1] + 1/tab[1,2]),4)

### n x 2 x 2 stratified data analysis with CMH test
rma.mh(ai=ai, bi=bi, ci=ci, di=di, measure="OR")

### change data to long format 
event <- c(rbind(ai,ci))
group <- rep(c(1,0), times=n)
id    <- rep(1:n, each=2)

### conditional logistic model
summary(clogit(event ~ group + strata(id)))

########################################################################

So, all matches up as expected. An alternative approach to estimating the model above is described, for example, in Agresti (2002), chapter 10 (esp. 10.2.4). Here, the alpha_i values are treated as random effects, typically assumed to be drawn from N(mu, sigma^2). So, let's try out this approach, using lmer():

########################################################################

library(lme4)
lmer(event ~ group + (1 | id), family=binomial, nAGQ=21)

########################################################################

According to Agresti (2002; see also Neuhaus et al., 1994), this should yield the same estimate of beta for matched pairs with a non-negative sample log odds ratio (as in this example). With the right number of quadrature points (e.g., nAGQ=21), this does indeed yield the same value. But this appears to depend highly on what value of nAGQ is chosen. Also, the SE is different. I tried fitting the same model in some other software to compare results. For example, in Stata using xtmelogit, I get results that match up completely with those from the other approaches, including the SE of hat(beta).

So, I am wondering if the high dependence of lmer() on the number of quadrature points in this particular application is expected. And is there an explanation for why the SE of hat(beta) is different in lmer()? I realize that clusters of size 2 is probably not something that lmer() was meant for, but the theory apparently says that the results should match up, so I am wondering if there is an intuitive explanation for what is going on here.

Best,
Wolfgang

References

Agresti, A. (2002). Categorical data analysis (2nd ed.). Wiley.

Neuhaus, J. M., Kalbfleisch, J. D., Hauck, W. W. (1994). Conditions for consistent estimation in mixed-effects models for binary matched-pairs data. Canadian Journal of Statistics, 22(1), 139-148.

--   
Wolfgang Viechtbauer, Ph.D., Statistician   
Department of Psychiatry and Psychology   
School for Mental Health and Neuroscience   
Faculty of Health, Medicine, and Life Sciences   
Maastricht University, P.O. Box 616 (VIJV1)   
6200 MD Maastricht, The Netherlands   
+31 (43) 388-4170 | http://www.wvbauer.com   


From bbolker at gmail.com  Tue Jun 18 16:48:38 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 18 Jun 2013 14:48:38 +0000 (UTC)
Subject: [R-sig-ME] Logistic Regression for Matched Case-Control Data
References: <077E31A57DA26E46AB0D493C9966AC730D7BA1B129@UM-MAIL4112.unimaas.nl>
Message-ID: <loom.20130618T164126-218@post.gmane.org>

Viechtbauer Wolfgang (STAT <wolfgang.viechtbauer at ...> writes:

> 
> Dear All,
 
> I am trying to wrap my head around using logistic random-effects
> regression models for the analysis of matched data and the results I
> obtain with lmer() when using this approach. So, let's say we have
> dichotomous outcomes for matched subjects in 2 groups (could also be
> repeated measurements on a single subject -- the idea is the
> same). We can write the subject-specific model as:
 
> P(Y_ij = 1) = alpha_i + beta x_ij,
 
> where Y_ij is the observed outcome (either 1 or 0) for subject j
> (either 1 or 2) for pair i (j = 1, ..., n), x_ij=0 for group 1,
> x_ij=1 for group 2, alpha_i is the intercept for pair i, and beta is
> the log(OR). Estimating this model with fixed intercepts is
> problematic, so the usual approach is to use a conditional logistic
> model (conditioning on Y_i1 + Y_i2).

 [snip snip snip to make Gmane happy]

> library(lme4)
> lmer(event ~ group + (1 | id), family=binomial, nAGQ=21)

> According to Agresti (2002; see also Neuhaus et al., 1994), this
> should yield the same estimate of beta for matched pairs with a
> non-negative sample log odds ratio (as in this example). With the
> right number of quadrature points (e.g., nAGQ=21), this does indeed
> yield the same value. But this appears to depend highly on what
> value of nAGQ is chosen. Also, the SE is different. I tried fitting
> the same model in some other software to compare results. For
> example, in Stata using xtmelogit, I get results that match up
> completely with those from the other approaches, including the SE of
> hat(beta).
 
> So, I am wondering if the high dependence of lmer() on the number of
> quadrature points in this particular application is expected. And is
> there an explanation for why the SE of hat(beta) is different in
> lmer()? I realize that clusters of size 2 is probably not something
> that lmer() was meant for, but the theory apparently says that the
> results should match up, so I am wondering if there is an intuitive
> explanation for what is going on here.

  With the development version of lme4 (which might ?? be more stable
?) I get values of the fixed effect of 0.8109 (plus or minus about
3e-5) as long as nAGQ >= 9 ...  for lme4.0 (which should be equivalent
to the CRAN version) it seems to take _slightly_ higher nAGQ to get
precise answers, but it still doesn't seem that sensitive to me.
(Might vary across platforms?)  However, I can't speak to the standard
error of hat(beta) ...


From rossahmed at googlemail.com  Tue Jun 18 17:43:28 2013
From: rossahmed at googlemail.com (Ross Ahmed)
Date: Tue, 18 Jun 2013 16:43:28 +0100
Subject: [R-sig-ME] varying intercept and varying slope models
Message-ID: <CDE63EB0.50F3%rossahmed@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130618/7a04ba79/attachment.pl>

From bates at stat.wisc.edu  Tue Jun 18 18:18:33 2013
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 18 Jun 2013 11:18:33 -0500
Subject: [R-sig-ME] varying intercept and varying slope models
In-Reply-To: <CDE63EB0.50F3%rossahmed@gmail.com>
References: <CDE63EB0.50F3%rossahmed@gmail.com>
Message-ID: <CAO7JsnREOtCzbOB6MLaPfgQW4i2YsBYNuC5rcnDVj8YAFD8NBQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130618/ebe484f1/attachment.pl>

From bates at stat.wisc.edu  Tue Jun 18 18:21:11 2013
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 18 Jun 2013 11:21:11 -0500
Subject: [R-sig-ME] varying intercept and varying slope models
In-Reply-To: <CAO7JsnREOtCzbOB6MLaPfgQW4i2YsBYNuC5rcnDVj8YAFD8NBQ@mail.gmail.com>
References: <CDE63EB0.50F3%rossahmed@gmail.com>
	<CAO7JsnREOtCzbOB6MLaPfgQW4i2YsBYNuC5rcnDVj8YAFD8NBQ@mail.gmail.com>
Message-ID: <CAO7JsnT8-z=6kTHtb88=a4AgATF_-k63t6i1dBcDBm2E6cONoA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130618/2c821714/attachment.pl>

From nrf5017 at psu.edu  Tue Jun 18 21:04:30 2013
From: nrf5017 at psu.edu (Nate Fronk)
Date: Tue, 18 Jun 2013 15:04:30 -0400
Subject: [R-sig-ME] Parameter expansion with MCMCglmm
Message-ID: <1371582270l.696388l.0l@psu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130618/da9e1981/attachment.pl>

From wolfgang.viechtbauer at maastrichtuniversity.nl  Wed Jun 19 12:01:24 2013
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Wed, 19 Jun 2013 12:01:24 +0200
Subject: [R-sig-ME] Logistic Regression for Matched Case-Control Data
In-Reply-To: <loom.20130618T164126-218@post.gmane.org>
References: <077E31A57DA26E46AB0D493C9966AC730D7BA1B129@UM-MAIL4112.unimaas.nl>
	<loom.20130618T164126-218@post.gmane.org>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730D7BA1B2FC@UM-MAIL4112.unimaas.nl>

Thanks for looking into this. Yes, for nAGQ values above ~10, it's indeed pretty stable, regardless of the version, and it does give the right value. I was just worried about the behavior for a smaller number of quadrature points. But maybe this is nothing unusual when using glmer() for this application. However, the SE is always off, regardless of the nAGQ value.

I also tried fitting the same model with the glmmML() function from the package with the same name:

library(glmmML)
glmmML(event ~ group, cluster=id, family=binomial, method="ghq", n.points=21)

This gives b1=.8109 with SE=.4249 as expected. So, at least with respect to the SE, glmer() is doing something different here.

Best,
Wolfgang

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-
> bounces at r-project.org] On Behalf Of Ben Bolker
> Sent: Tuesday, June 18, 2013 16:49
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Logistic Regression for Matched Case-Control Data
> 
> Viechtbauer Wolfgang (STAT <wolfgang.viechtbauer at ...> writes:
> 
> >
> > Dear All,
> 
> > I am trying to wrap my head around using logistic random-effects
> > regression models for the analysis of matched data and the results I
> > obtain with lmer() when using this approach. So, let's say we have
> > dichotomous outcomes for matched subjects in 2 groups (could also be
> > repeated measurements on a single subject -- the idea is the
> > same). We can write the subject-specific model as:
> 
> > P(Y_ij = 1) = alpha_i + beta x_ij,
> 
> > where Y_ij is the observed outcome (either 1 or 0) for subject j
> > (either 1 or 2) for pair i (j = 1, ..., n), x_ij=0 for group 1,
> > x_ij=1 for group 2, alpha_i is the intercept for pair i, and beta is
> > the log(OR). Estimating this model with fixed intercepts is
> > problematic, so the usual approach is to use a conditional logistic
> > model (conditioning on Y_i1 + Y_i2).
> 
>  [snip snip snip to make Gmane happy]
> 
> > library(lme4)
> > lmer(event ~ group + (1 | id), family=binomial, nAGQ=21)
> 
> > According to Agresti (2002; see also Neuhaus et al., 1994), this
> > should yield the same estimate of beta for matched pairs with a
> > non-negative sample log odds ratio (as in this example). With the
> > right number of quadrature points (e.g., nAGQ=21), this does indeed
> > yield the same value. But this appears to depend highly on what
> > value of nAGQ is chosen. Also, the SE is different. I tried fitting
> > the same model in some other software to compare results. For
> > example, in Stata using xtmelogit, I get results that match up
> > completely with those from the other approaches, including the SE of
> > hat(beta).
> 
> > So, I am wondering if the high dependence of lmer() on the number of
> > quadrature points in this particular application is expected. And is
> > there an explanation for why the SE of hat(beta) is different in
> > lmer()? I realize that clusters of size 2 is probably not something
> > that lmer() was meant for, but the theory apparently says that the
> > results should match up, so I am wondering if there is an intuitive
> > explanation for what is going on here.
> 
>   With the development version of lme4 (which might ?? be more stable
> ?) I get values of the fixed effect of 0.8109 (plus or minus about
> 3e-5) as long as nAGQ >= 9 ...  for lme4.0 (which should be equivalent
> to the CRAN version) it seems to take _slightly_ higher nAGQ to get
> precise answers, but it still doesn't seem that sensitive to me.
> (Might vary across platforms?)  However, I can't speak to the standard
> error of hat(beta) ...
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From paul.johnson at glasgow.ac.uk  Wed Jun 19 14:17:11 2013
From: paul.johnson at glasgow.ac.uk (Paul Johnson)
Date: Wed, 19 Jun 2013 13:17:11 +0100
Subject: [R-sig-ME] making inferences about overdispersion in nbinom glmmabmb
Message-ID: <28253226-B05C-474F-8945-EDF046EEA7C4@glasgow.ac.uk>

Hi,

I'm fitting negative binomial GLMMs in glmmadmb using  glmmabmb(?, family = "nbinom"). I'm interested in making inferences about the amount of overdispersion in each model, and comparing overdispersion between models. The outcome is mosquito count and the different models are different designs of mosquito trap. Each model fit gives an estimate of alpha (the [inverse] overdispersion parameter) and sd_alpha, the standard error of alpha. It's tempting to use the standard error of alpha to construct CIs, test for differences, etc, but I have no idea if this is justified. It seems over-optimistic to assume that sampling error in alpha is approximately normally distributed. Are there conditions (e.g large sample size) where this assumption is justified?

Thanks for your help,
Paul Johnson


From j.o.villar at ibv.uio.no  Wed Jun 19 10:39:40 2013
From: j.o.villar at ibv.uio.no (Jaime Otero Villar)
Date: Wed, 19 Jun 2013 10:39:40 +0200
Subject: [R-sig-ME] Interpretation of random slope in gamm
Message-ID: <754FCB47-AFBD-4C72-A588-0A9FE0724BBE@ulrik.uio.no>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130619/e192ecde/attachment.pl>

From jwiley.psych at gmail.com  Thu Jun 20 04:52:19 2013
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Wed, 19 Jun 2013 19:52:19 -0700
Subject: [R-sig-ME] making inferences about overdispersion in nbinom
	glmmabmb
In-Reply-To: <28253226-B05C-474F-8945-EDF046EEA7C4@glasgow.ac.uk>
References: <28253226-B05C-474F-8945-EDF046EEA7C4@glasgow.ac.uk>
Message-ID: <CANz9Z_+K8f+iM9tJ2OCuEVRmhkAzaP7T2gNfngLqNMPAuCnsgg@mail.gmail.com>

Hi Paul,

Standard errors on variance components do not provide a consistent
means to assess either significance or create confidence intervals.
In part because variances are fundamentally bounded, so you really
cannot expect symmetric intervals.  Of course if they are large
enough, that may not be an issue, but as a general principle,
encouraging the use of standard errors assuming a standard normal is
not going to work well.

If you are bound to a frequentist world, a likelihood ratio test is
probably a good choice with a free and constrained estimate.  To
generate confidence intervals, a good approach can be used based on
profile likelihoods.  I am sure these are presented elsewhere, but
Terry Therneau has a good presentation of the technique and theory in
his text on survival models.

Below is an alternative Bayesian approach.  The parameterization of
course is slightly different as this uses MCMCglmm and a non zero
residual variance rather than negative binomial model, but the
posterior allows valid examination and computation of confidence
intervals and presentation of the distribution.  Note for larger
values, it is not an issue, but in the last example (admittedly chosen
as a degenerate case) normal based confidence intervals would perform
quite poorly.

Best,

Josh


require(MASS)
require(MCMCglmm)

set.seed(10)
d <- data.frame(x = rnorm(1000))

d <- within(d, {
  y1 = rnegbin(1000, 2 + .5 * x, 1)
  y2 = rnegbin(1000, 2 + .5 * x, 4)
  y3 = rnegbin(1000, 2 + .5 * x, 16)
})

m <- list(
  t1 = MCMCglmm(y1 ~ x, data = d, family = "poisson", nitt=1e5, verbose=FALSE),
  t4 = MCMCglmm(y2 ~ x, data = d, family = "poisson", nitt=1e5, verbose=FALSE),
  t16 = MCMCglmm(y3 ~ x, data = d, family = "poisson", nitt=1e5, verbose=FALSE))

plot(m$t1$VCV)
plot(m$t4$VCV)
plot(m$t16$VCV)

HPDinterval(m$t1$VCV)
HPDinterval(m$t4$VCV)
HPDinterval(m$t16$VCV)

p <- function(x) {
  hist(x, freq=FALSE)
  lines(seq(min(x), max(x), length.out = 1000),
  dnorm(seq(min(x), max(x), length.out = 1000), mean= mean(x), sd = sd(x)),
  type = "l", col = "blue")
}

p(m$t1$VCV[, 1])
p(m$t4$VCV[, 1])
p(m$t16$VCV[, 1])



On Wed, Jun 19, 2013 at 5:17 AM, Paul Johnson
<paul.johnson at glasgow.ac.uk> wrote:
> Hi,
>
> I'm fitting negative binomial GLMMs in glmmadmb using  glmmabmb(?, family = "nbinom"). I'm interested in making inferences about the amount of overdispersion in each model, and comparing overdispersion between models. The outcome is mosquito count and the different models are different designs of mosquito trap. Each model fit gives an estimate of alpha (the [inverse] overdispersion parameter) and sd_alpha, the standard error of alpha. It's tempting to use the standard error of alpha to construct CIs, test for differences, etc, but I have no idea if this is justified. It seems over-optimistic to assume that sampling error in alpha is approximately normally distributed. Are there conditions (e.g large sample size) where this assumption is justified?
>
> Thanks for your help,
> Paul Johnson
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
University of California, Los Angeles
http://joshuawiley.com/
Senior Analyst - Elkhart Group Ltd.
http://elkhartgroup.com


From highstat at highstat.com  Thu Jun 20 14:29:03 2013
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Thu, 20 Jun 2013 13:29:03 +0100
Subject: [R-sig-ME] New book: Beginner's Guide to GLM and GLMM with R
Message-ID: <51C2F58F.4050002@highstat.com>

Members of this mailing list may be interested in the following new book:


Beginner's Guide to GLM and GLMM with R.
- A frequentist and Bayesian perspective for ecologists -

Zuur AF, Hilbe JM and Ieno EN


This book is only available from:
http://www.highstat.com/BGGLM.htm



This book presents Generalized Linear Models (GLM) and Generalized 
Linear Mixed Models (GLMM) based on both frequency-based and Bayesian 
concepts. Using ecological data from real-world studies, the text 
introduces the reader to the basics of GLM and mixed effects models, 
with demonstrations of binomial, gamma, Poisson, negative binomial 
regression, and beta and beta-binomial GLMs and GLMMs. The book uses the 
functions glm, lmer, glmer, glmmADMB, and also JAGS from within R. JAGS 
results are compared with frequentist results.

R code to construct, fit, interpret, and comparatively evaluate models 
is provided at every stage. Otherwise challenging procedures are 
presented in a clear and comprehensible manner with each step of the 
modelling process explained in detail, and all code is provided so that 
it can be reproduced by the reader.

Readers of this book have free access to:

Chapter 1 of Zero Inflated Models and Generalized Linear Mixed Models 
with R. (2012a) Zuur, Saveliev, Ieno.
Chapter 1 of Beginner's Guide to Generalized Additive Models with R. 
(2012b) Zuur, AF.


Keywords
Introduction to GLM
Poisson GLM and Negative binomial GLM for count data
Binomial GLM for binary data
Binomial GLM for proportional data
Other distributions
GLM applied to red squirrel data
Bayesian approach ? running the Poisson GLM
Running JAGS via R
Applying a negative binomial GLM in JAGS
GLM applied to presence-absence Polychaeta data
Model selection using AIC, DIC and BIC in jags
Introduction to mixed effects models
GLMM applied on honeybee pollination data
Poisson GLMM using glmer and JAGS
Negative binomial GLMM using glmmADMD and JAGS
GLMM with auto-regressive correlation
GLMM for strictly positive data: biomass of rainforest trees
gamma GLM using a frequentist approach
Fitting a gamma GLM using JAGS
Truncated Gaussian linear regression
Tobit model in JAGS
Tobit model with random effects in JAGS
Binomial, beta-binomial, and beta GLMM applied to cheetah data

Kind regards,

Alain Zuur




-- 

Dr. Alain F. Zuur
First author of:

1. Analysing Ecological Data (2007).
Zuur, AF, Ieno, EN and Smith, GM. Springer. 680 p.
URL: www.springer.com/0-387-45967-7


2. Mixed effects models and extensions in ecology with R. (2009).
Zuur, AF, Ieno, EN, Walker, N, Saveliev, AA, and Smith, GM. Springer.
http://www.springer.com/life+sci/ecology/book/978-0-387-87457-9


3. A Beginner's Guide to R (2009).
Zuur, AF, Ieno, EN, Meesters, EHWG. Springer
http://www.springer.com/statistics/computational/book/978-0-387-93836-3


4. Zero Inflated Models and Generalized Linear Mixed Models with R. (2012) Zuur, Saveliev, Ieno.
http://www.highstat.com/book4.htm

Other books: http://www.highstat.com/books.htm


Statistical consultancy, courses, data analysis and software
Highland Statistics Ltd.
6 Laverock road
UK - AB41 6FN Newburgh
Tel: 0044 1358 788177
Email: highstat at highstat.com
URL: www.highstat.com
URL: www.brodgar.com


From paul.johnson at glasgow.ac.uk  Fri Jun 21 10:43:50 2013
From: paul.johnson at glasgow.ac.uk (Paul Johnson)
Date: Fri, 21 Jun 2013 09:43:50 +0100
Subject: [R-sig-ME] making inferences about overdispersion in nbinom
 glmmabmb
In-Reply-To: <CANz9Z_+K8f+iM9tJ2OCuEVRmhkAzaP7T2gNfngLqNMPAuCnsgg@mail.gmail.com>
References: <28253226-B05C-474F-8945-EDF046EEA7C4@glasgow.ac.uk>
	<CANz9Z_+K8f+iM9tJ2OCuEVRmhkAzaP7T2gNfngLqNMPAuCnsgg@mail.gmail.com>
Message-ID: <D883DDCE-2275-436B-89AA-5E5516788C5E@glasgow.ac.uk>

Thanks very much for these suggestions and for the code, Josh and Dave. As far as I remember MCMCglmm allows the residual variance to differ between groups, so I guess I could estimate the separate variances in the same model (the only reason for fitting separate models using glmmadmb was because it doesn't allow this). 

Best wishes,
Paul


On 20 Jun 2013, at 03:52, Joshua Wiley <jwiley.psych at gmail.com> wrote:

> Hi Paul,
> 
> Standard errors on variance components do not provide a consistent
> means to assess either significance or create confidence intervals.
> In part because variances are fundamentally bounded, so you really
> cannot expect symmetric intervals.  Of course if they are large
> enough, that may not be an issue, but as a general principle,
> encouraging the use of standard errors assuming a standard normal is
> not going to work well.
> 
> If you are bound to a frequentist world, a likelihood ratio test is
> probably a good choice with a free and constrained estimate.  To
> generate confidence intervals, a good approach can be used based on
> profile likelihoods.  I am sure these are presented elsewhere, but
> Terry Therneau has a good presentation of the technique and theory in
> his text on survival models.
> 
> Below is an alternative Bayesian approach.  The parameterization of
> course is slightly different as this uses MCMCglmm and a non zero
> residual variance rather than negative binomial model, but the
> posterior allows valid examination and computation of confidence
> intervals and presentation of the distribution.  Note for larger
> values, it is not an issue, but in the last example (admittedly chosen
> as a degenerate case) normal based confidence intervals would perform
> quite poorly.
> 
> Best,
> 
> Josh
> 
> 
> require(MASS)
> require(MCMCglmm)
> 
> set.seed(10)
> d <- data.frame(x = rnorm(1000))
> 
> d <- within(d, {
>  y1 = rnegbin(1000, 2 + .5 * x, 1)
>  y2 = rnegbin(1000, 2 + .5 * x, 4)
>  y3 = rnegbin(1000, 2 + .5 * x, 16)
> })
> 
> m <- list(
>  t1 = MCMCglmm(y1 ~ x, data = d, family = "poisson", nitt=1e5, verbose=FALSE),
>  t4 = MCMCglmm(y2 ~ x, data = d, family = "poisson", nitt=1e5, verbose=FALSE),
>  t16 = MCMCglmm(y3 ~ x, data = d, family = "poisson", nitt=1e5, verbose=FALSE))
> 
> plot(m$t1$VCV)
> plot(m$t4$VCV)
> plot(m$t16$VCV)
> 
> HPDinterval(m$t1$VCV)
> HPDinterval(m$t4$VCV)
> HPDinterval(m$t16$VCV)
> 
> p <- function(x) {
>  hist(x, freq=FALSE)
>  lines(seq(min(x), max(x), length.out = 1000),
>  dnorm(seq(min(x), max(x), length.out = 1000), mean= mean(x), sd = sd(x)),
>  type = "l", col = "blue")
> }
> 
> p(m$t1$VCV[, 1])
> p(m$t4$VCV[, 1])
> p(m$t16$VCV[, 1])
> 
> 
> 
> On Wed, Jun 19, 2013 at 5:17 AM, Paul Johnson
> <paul.johnson at glasgow.ac.uk> wrote:
>> Hi,
>> 
>> I'm fitting negative binomial GLMMs in glmmadmb using  glmmabmb(?, family = "nbinom"). I'm interested in making inferences about the amount of overdispersion in each model, and comparing overdispersion between models. The outcome is mosquito count and the different models are different designs of mosquito trap. Each model fit gives an estimate of alpha (the [inverse] overdispersion parameter) and sd_alpha, the standard error of alpha. It's tempting to use the standard error of alpha to construct CIs, test for differences, etc, but I have no idea if this is justified. It seems over-optimistic to assume that sampling error in alpha is approximately normally distributed. Are there conditions (e.g large sample size) where this assumption is justified?
>> 
>> Thanks for your help,
>> Paul Johnson
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 
> -- 
> Joshua Wiley
> Ph.D. Student, Health Psychology
> University of California, Los Angeles
> http://joshuawiley.com/
> Senior Analyst - Elkhart Group Ltd.
> http://elkhartgroup.com


From jwiley.psych at gmail.com  Fri Jun 21 18:55:02 2013
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Fri, 21 Jun 2013 09:55:02 -0700
Subject: [R-sig-ME] making inferences about overdispersion in nbinom
	glmmabmb
In-Reply-To: <D883DDCE-2275-436B-89AA-5E5516788C5E@glasgow.ac.uk>
References: <28253226-B05C-474F-8945-EDF046EEA7C4@glasgow.ac.uk>
	<CANz9Z_+K8f+iM9tJ2OCuEVRmhkAzaP7T2gNfngLqNMPAuCnsgg@mail.gmail.com>
	<D883DDCE-2275-436B-89AA-5E5516788C5E@glasgow.ac.uk>
Message-ID: <CANz9Z_+vSYE6LWmGmu7-PPjdXz-82Tj9fCPhQCwxPBAd4VyX1g@mail.gmail.com>

Hi Paul,

Sure you can estimate separate overdispersion parameters by some
grouping variable in MCMCglmm.  Then just plot those densities, or the
HPD intervals.

Actually, if you can put them together, you can go a step further,
because you can fit two models:

1) allow separate overdispersion parameters by group
2) do not allow separate overdispersion parameters by group

and then compare the DIC, which should put you on really solid footing
for drawing some inference about whether they are the same or
importantly different.

Cheers,

Josh



On Fri, Jun 21, 2013 at 1:43 AM, Paul Johnson
<paul.johnson at glasgow.ac.uk> wrote:
> Thanks very much for these suggestions and for the code, Josh and Dave. As far as I remember MCMCglmm allows the residual variance to differ between groups, so I guess I could estimate the separate variances in the same model (the only reason for fitting separate models using glmmadmb was because it doesn't allow this).
>
> Best wishes,
> Paul
>
>
> On 20 Jun 2013, at 03:52, Joshua Wiley <jwiley.psych at gmail.com> wrote:
>
>> Hi Paul,
>>
>> Standard errors on variance components do not provide a consistent
>> means to assess either significance or create confidence intervals.
>> In part because variances are fundamentally bounded, so you really
>> cannot expect symmetric intervals.  Of course if they are large
>> enough, that may not be an issue, but as a general principle,
>> encouraging the use of standard errors assuming a standard normal is
>> not going to work well.
>>
>> If you are bound to a frequentist world, a likelihood ratio test is
>> probably a good choice with a free and constrained estimate.  To
>> generate confidence intervals, a good approach can be used based on
>> profile likelihoods.  I am sure these are presented elsewhere, but
>> Terry Therneau has a good presentation of the technique and theory in
>> his text on survival models.
>>
>> Below is an alternative Bayesian approach.  The parameterization of
>> course is slightly different as this uses MCMCglmm and a non zero
>> residual variance rather than negative binomial model, but the
>> posterior allows valid examination and computation of confidence
>> intervals and presentation of the distribution.  Note for larger
>> values, it is not an issue, but in the last example (admittedly chosen
>> as a degenerate case) normal based confidence intervals would perform
>> quite poorly.
>>
>> Best,
>>
>> Josh
>>
>>
>> require(MASS)
>> require(MCMCglmm)
>>
>> set.seed(10)
>> d <- data.frame(x = rnorm(1000))
>>
>> d <- within(d, {
>>  y1 = rnegbin(1000, 2 + .5 * x, 1)
>>  y2 = rnegbin(1000, 2 + .5 * x, 4)
>>  y3 = rnegbin(1000, 2 + .5 * x, 16)
>> })
>>
>> m <- list(
>>  t1 = MCMCglmm(y1 ~ x, data = d, family = "poisson", nitt=1e5, verbose=FALSE),
>>  t4 = MCMCglmm(y2 ~ x, data = d, family = "poisson", nitt=1e5, verbose=FALSE),
>>  t16 = MCMCglmm(y3 ~ x, data = d, family = "poisson", nitt=1e5, verbose=FALSE))
>>
>> plot(m$t1$VCV)
>> plot(m$t4$VCV)
>> plot(m$t16$VCV)
>>
>> HPDinterval(m$t1$VCV)
>> HPDinterval(m$t4$VCV)
>> HPDinterval(m$t16$VCV)
>>
>> p <- function(x) {
>>  hist(x, freq=FALSE)
>>  lines(seq(min(x), max(x), length.out = 1000),
>>  dnorm(seq(min(x), max(x), length.out = 1000), mean= mean(x), sd = sd(x)),
>>  type = "l", col = "blue")
>> }
>>
>> p(m$t1$VCV[, 1])
>> p(m$t4$VCV[, 1])
>> p(m$t16$VCV[, 1])
>>
>>
>>
>> On Wed, Jun 19, 2013 at 5:17 AM, Paul Johnson
>> <paul.johnson at glasgow.ac.uk> wrote:
>>> Hi,
>>>
>>> I'm fitting negative binomial GLMMs in glmmadmb using  glmmabmb(?, family = "nbinom"). I'm interested in making inferences about the amount of overdispersion in each model, and comparing overdispersion between models. The outcome is mosquito count and the different models are different designs of mosquito trap. Each model fit gives an estimate of alpha (the [inverse] overdispersion parameter) and sd_alpha, the standard error of alpha. It's tempting to use the standard error of alpha to construct CIs, test for differences, etc, but I have no idea if this is justified. It seems over-optimistic to assume that sampling error in alpha is approximately normally distributed. Are there conditions (e.g large sample size) where this assumption is justified?
>>>
>>> Thanks for your help,
>>> Paul Johnson
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>> --
>> Joshua Wiley
>> Ph.D. Student, Health Psychology
>> University of California, Los Angeles
>> http://joshuawiley.com/
>> Senior Analyst - Elkhart Group Ltd.
>> http://elkhartgroup.com
>



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
University of California, Los Angeles
http://joshuawiley.com/
Senior Analyst - Elkhart Group Ltd.
http://elkhartgroup.com


From highstat at highstat.com  Sat Jun 22 13:01:59 2013
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Sat, 22 Jun 2013 12:01:59 +0100
Subject: [R-sig-ME] making inferences about overdispersion in nbinom
	glmmabmb
In-Reply-To: <mailman.3.1371895201.23183.r-sig-mixed-models@r-project.org>
References: <mailman.3.1371895201.23183.r-sig-mixed-models@r-project.org>
Message-ID: <51C58427.4000103@highstat.com>



>>>
>>> On Wed, Jun 19, 2013 at 5:17 AM, Paul Johnson
>>> <paul.johnson at glasgow.ac.uk> wrote:
>>>> Hi,
>>>>
>>>> I'm fitting negative binomial GLMMs in glmmadmb using  glmmabmb(?, family = "nbinom"). I'm interested in making inferences about the amount of overdispersion in each model, and comparing overdispersion between models.

Paul

What about combining the data for these models...apply one model on all 
data (assuming you don't have too many data sets...i.e. creating too 
many interactions.....and then apply models with one alpha....and a 
model with multiple alphas, where alpha is the alpha in:

Y_i ~ NB(mu,alpha)
E(Y_i) ~ mu_i
var(Y_i) = mu_i + alpha * mu_i^2
log(mu_i) = covariate stuff + random stuff


In our 'Beginner's Guide to GLM and GLMM with R' we show how you can 
model alpha as a function of covariates in NB GLM (this is called 
heterogeneous negative binomial GLMs.....it is using the package 
msme...from Hilbe and Robinson, 2013). The beginner's Guide to GLM and 
GLMM  book also contains JAGS code..and it mentions somewhere how you 
can model the alpha parameter as a function of covariates in JAGS. It 
would actually be very simple to do this.

So...you fit:

Y_i ~ NB(mu,alpha)
E(Y_i) ~ mu_i
var(Y_i) = mu_i + alpha * mu_i^2
log(mu_i) = covariate stuff + random stuff

on one the combined data set...and also

Y_i ~ NB(mu, function(alphas))
E(Y_i) ~ mu_i
var(Y_i) = mu_i + alpha * mu_i^2
log(mu_i) = covariate stuff + random stuff

on the same combined data set. And you compare them. The easiest option 
is to use one alpha per data set....but it can also be something more 
complex (like things in that are done in varExp, varPower, varIdent). 
The only problem that may arise is that too many data sets means too 
many interactions in your covariate stuff.


However..as a word of warning....overdispersion quite often means that 
there is something else going wrong..e.g. zero inflation, non-linear 
patterns, outliers, wrong link function, missing interactions, missing 
covariates, dependency, etc, etc. See Beginner's Guide to GLM and GLMM 
with R for flowcharts and a long list of options to fix the problem. 
Only apply NB GLM(M) if you cannot pinpoint any reason for overdispersion.

Alain



   Joseph Hilbe and Andrew Robinson (2013). msme: Functions and Datasets 
for "Methods of
   Statistical Model Estimation".. R package version 0.4.2.
   http://CRAN.R-project.org/package=msme

A BibTeX entry for LaTeX users is

   @Manual{,
     title = {msme: Functions and Datasets for "Methods of Statistical Model
Estimation".},
     author = {Joseph Hilbe and Andrew Robinson},
     year = {2013},
     note = {R package version 0.4.2},
     url = {http://CRAN.R-project.org/package=msme},
   }








>>>>   The outcome is mosquito count and the different models are different designs of mosquito trap. Each model fit gives an estimate of alpha (the [inverse] overdispersion parameter) and sd_alpha, the standard error of alpha. It's tempting to use the standard error of alpha to construct CIs, test for differences, etc, but I have no idea if this is justified. It seems over-optimistic to assume that sampling error in alpha is approximately normally distributed. Are there conditions (e.g large sample size) where this assumption is justified?
>>>>
>>>> Thanks for your help,
>>>> Paul Johnson
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>> --
>>> Joshua Wiley
>>> Ph.D. Student, Health Psychology
>>> University of California, Los Angeles
>>> http://joshuawiley.com/
>>> Senior Analyst - Elkhart Group Ltd.
>>> http://elkhartgroup.com
>
>


-- 

Dr. Alain F. Zuur
First author of:

1. Analysing Ecological Data (2007).
Zuur, AF, Ieno, EN and Smith, GM. Springer. 680 p.
URL: www.springer.com/0-387-45967-7


2. Mixed effects models and extensions in ecology with R. (2009).
Zuur, AF, Ieno, EN, Walker, N, Saveliev, AA, and Smith, GM. Springer.
http://www.springer.com/life+sci/ecology/book/978-0-387-87457-9


3. A Beginner's Guide to R (2009).
Zuur, AF, Ieno, EN, Meesters, EHWG. Springer
http://www.springer.com/statistics/computational/book/978-0-387-93836-3


4. Zero Inflated Models and Generalized Linear Mixed Models with R. (2012) Zuur, Saveliev, Ieno.
http://www.highstat.com/book4.htm

Other books: http://www.highstat.com/books.htm


Statistical consultancy, courses, data analysis and software
Highland Statistics Ltd.
6 Laverock road
UK - AB41 6FN Newburgh
Tel: 0044 1358 788177
Email: highstat at highstat.com
URL: www.highstat.com
URL: www.brodgar.com


From j.hadfield at ed.ac.uk  Sun Jun 23 16:31:26 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sun, 23 Jun 2013 15:31:26 +0100
Subject: [R-sig-ME] Parameter expansion with MCMCglmm
In-Reply-To: <1371582270l.696388l.0l@psu.edu>
References: <1371582270l.696388l.0l@psu.edu>
Message-ID: <20130623153126.10233nga0ylmdocg@www.staffmail.ed.ac.uk>

Hi,

Is the error meassage

Error in priorformat(if (NOpriorG) { :   V is the wrong dimension for  
some prior$G/prior$R elements

or

Error in priorformat(if (NOpriorG) { :  alpha.V is the wrong dimension  
for some prior$G/prior$R elements

?

I think it should be the latter. If so alpha.V should be a 4x4 matrix  
rather than a scalar, and alpha.mu should be a vector of length 4  
rather than a scalar.

Cheers,

Jarrod.




Quoting Nate Fronk <nrf5017 at psu.edu> on Tue, 18 Jun 2013 15:04:30 -0400:

>
>
> Hello all,
> I am trying to analyze a Before-After Control-Impact experiment. However, my
> model is not converging well and I am attempting to use a prior with  
> parameter
> expansion. I'm using count data (birds per point), well pad density per unit
> area, and time (1=before, 2=after).
>
> prior<list(R=list(V=diag(1),nu=0.002),G=list(G1=list(V=diag(1),nu=0.002,alpha.mu=0,alpha.V=625),G2=list(V=diag(1),nu=0.002,alpha.mu=0,alpha.V=625),G3=list(V=diag(4),nu=0.002,alpha.mu=0,alpha.V=625)))
> modelA<-MCMCglmm(Count~Density*Time,random=~ Block + Block:Point  
> +idh(1+Density*Time):Species,family="poisson",pr=TRUE,prior=prior,data=edge,nitt=40000)
> When trying to use the prior I get the following message:
> Error in priorformat(if (NOpriorG) { :   V is the wrong dimension  
> for some prior$G/prior$R elements
> I realize that my V= value may be wrong but I'm unsure about what  
> the value actually should be. Should I be using my covariance  
> matrix?  Any help anyone could offer would be greatly appreciated.
> Thank you,
> Nate Fronk
> Penn State University
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From j.hadfield at ed.ac.uk  Sun Jun 23 16:31:35 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sun, 23 Jun 2013 15:31:35 +0100
Subject: [R-sig-ME] Parameter expansion with MCMCglmm
In-Reply-To: <1371582270l.696388l.0l@psu.edu>
References: <1371582270l.696388l.0l@psu.edu>
Message-ID: <20130623153135.895562uyz11axrgo@www.staffmail.ed.ac.uk>

Hi,

Is the error message

Error in priorformat(if (NOpriorG) { :   V is the wrong dimension for  
some prior$G/prior$R elements

or

Error in priorformat(if (NOpriorG) { :  alpha.V is the wrong dimension  
for some prior$G/prior$R elements

?

I think it should be the latter. If so alpha.V should be a 4x4 matrix  
rather than a scalar, and alpha.mu should be a vector of length 4  
rather than a scalar.

Cheers,

Jarrod.




Quoting Nate Fronk <nrf5017 at psu.edu> on Tue, 18 Jun 2013 15:04:30 -0400:

>
>
> Hello all,
> I am trying to analyze a Before-After Control-Impact experiment. However, my
> model is not converging well and I am attempting to use a prior with  
> parameter
> expansion. I'm using count data (birds per point), well pad density per unit
> area, and time (1=before, 2=after).
>
> prior<list(R=list(V=diag(1),nu=0.002),G=list(G1=list(V=diag(1),nu=0.002,alpha.mu=0,alpha.V=625),G2=list(V=diag(1),nu=0.002,alpha.mu=0,alpha.V=625),G3=list(V=diag(4),nu=0.002,alpha.mu=0,alpha.V=625)))
> modelA<-MCMCglmm(Count~Density*Time,random=~ Block + Block:Point  
> +idh(1+Density*Time):Species,family="poisson",pr=TRUE,prior=prior,data=edge,nitt=40000)
> When trying to use the prior I get the following message:
> Error in priorformat(if (NOpriorG) { :   V is the wrong dimension  
> for some prior$G/prior$R elements
> I realize that my V= value may be wrong but I'm unsure about what  
> the value actually should be. Should I be using my covariance  
> matrix?  Any help anyone could offer would be greatly appreciated.
> Thank you,
> Nate Fronk
> Penn State University
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From frazer_sinclair at yahoo.co.uk  Mon Jun 24 11:07:56 2013
From: frazer_sinclair at yahoo.co.uk (Frazer Sinclair)
Date: Mon, 24 Jun 2013 10:07:56 +0100 (BST)
Subject: [R-sig-ME] MCMCglmm models stored as elements in a list
Message-ID: <1372064876.42422.YahooMailNeo@web28805.mail.ir2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130624/3d2e9049/attachment.pl>

From sven.hohenstein at uni-potsdam.de  Mon Jun 24 11:40:34 2013
From: sven.hohenstein at uni-potsdam.de (Sven Hohenstein)
Date: Mon, 24 Jun 2013 11:40:34 +0200
Subject: [R-sig-ME] MCMCglmm models stored as elements in a list
In-Reply-To: <1372064876.42422.YahooMailNeo@web28805.mail.ir2.yahoo.com>
References: <1372064876.42422.YahooMailNeo@web28805.mail.ir2.yahoo.com>
Message-ID: <20130624114034.4n5lg2444c00gw88@webmail.uni-potsdam.de>

Hi,

> require(MCMCglmm)
> Ndata <- data.frame(y = rnorm(5, mean = 0, sd = sqrt(1)))
> m1 <- MCMCglmm(y ~ 1, data = Ndata,verbose = FALSE)
> m2<- MCMCglmm(y ~ 1, data = Ndata,verbose = FALSE)
> m3<- MCMCglmm(y ~ 1, data = Ndata,verbose = FALSE)
> r<-list(c(m1,m2,m3))

You should not combine your objects with the c() function since this  
removes the model class from the objects. A list containing the three  
models can be created with the following command:

r <- list(m1, m2, m3)

Once you have this list, you can apply a function to all of its  
elements with lapply():

lapply(r, summary)

You can also select a single list element by its index:

summary(r[[1]])

Best,

Sven


-- 
Sven Hohenstein
Department of Psychology
University of Potsdam
Karl-Liebknecht-Str. 24-25
14476 Potsdam
Germany
Tel.: ++49 331-977 2370


From tommy.gaillard40 at gmail.com  Mon Jun 24 12:45:18 2013
From: tommy.gaillard40 at gmail.com (tommy gaillard)
Date: Mon, 24 Jun 2013 12:45:18 +0200
Subject: [R-sig-ME] standardized parameter estimates in random regression
	model
Message-ID: <CAAnnU-R42AwGAqcakDFCyzXhHeDVRJX3diqXGmGamJE5s0tKFQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130624/079969af/attachment.pl>

From bbolker at gmail.com  Mon Jun 24 16:42:00 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 24 Jun 2013 14:42:00 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?standardized_parameter_estimates_in_random_r?=
	=?utf-8?q?egression=09model?=
References: <CAAnnU-R42AwGAqcakDFCyzXhHeDVRJX3diqXGmGamJE5s0tKFQ@mail.gmail.com>
Message-ID: <loom.20130624T163154-301@post.gmane.org>

tommy gaillard <tommy.gaillard40 at ...> writes:

> 
>  Dear all,
> 
>  I am currently trying to quantify between-individual differences in
> intercept and slope of vigilance behavior.
>  Here is my model:
> model<-lmer(logfreq_vig~logdensity+logbiomasstrue+(1|Idtag),
> na.action=na.omit, data=tabimpala)
> 
> I would need to obtain the value of Vi (estimator of the intercept
> deviation) and Vs (=estimator of the slope deviation)
>  with their Confidence
> Interval.
>    I have tried the scale function and the lm.beta function 
> to standardize
> the variables but it is not working...
>   Does someone would have an idea to obtain those values?

  You should probably tell us what package the lm.beta function is
from ... sos::findFn() tells me that there are two in contributed packages
(QuantPsyc and scaleCoef). scaleCoef has been archived ...


Looking at what QuantPsyc::lm.beta actually does:

lm.beta <- function (MOD)  {
    b <- summary(MOD)$coef[-1, 1]
    sx <- sapply(MOD$model[-1], sd)
    sy <- sapply(MOD$model[1], sd)
    beta <- b * sx/sy
    return(beta)
}

The lme4 equivalent steps would be:

library(lme4)
fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
b <- fixef(fm1)[-1]     ## get coefficients except intercept
mf <- model.frame(fm1)  ## pull out original data
sx <- sapply(mf[names(b)],sd)  ## calc sd of input variables
sy <- sd(mf[[1]])              ## sd of response
b*sx/sy

Note that this is a bit fragile (as is the original lm.beta()): it assumes

* the model has an intercept
* all the predictors are continuous responses (no factors,
  interactions, etc etc)
* the response is stored as the first column of the model frame

It might be worth writing a more robust version of this at some point.

  It's good to give reproducible examples of what you want to do
(and specify what's not working -- don't just say "it's not working")


From tommy.gaillard40 at gmail.com  Mon Jun 24 18:24:47 2013
From: tommy.gaillard40 at gmail.com (tommy gaillard)
Date: Mon, 24 Jun 2013 18:24:47 +0200
Subject: [R-sig-ME] standardized parameter estimates in random
	regression model
In-Reply-To: <loom.20130624T163154-301@post.gmane.org>
References: <CAAnnU-R42AwGAqcakDFCyzXhHeDVRJX3diqXGmGamJE5s0tKFQ@mail.gmail.com>
	<loom.20130624T163154-301@post.gmane.org>
Message-ID: <CAAnnU-Q4kjqKQVmejNx=-qNGdN7qZfCDFnSyoyspa5P_7V81ew@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130624/11e40d51/attachment.pl>

From ybc2 at cornell.edu  Mon Jun 24 19:42:18 2013
From: ybc2 at cornell.edu (Brenda Chang)
Date: Mon, 24 Jun 2013 13:42:18 -0400
Subject: [R-sig-ME] nlme package nonlinear mixed model error when fitting
	only fixed effects
Message-ID: <CABXqi-z=Fo-zdL+TCAjLkVGqdqF41Ybbbw0cfYtvuPq_3TtGpg@mail.gmail.com>

Dear all,

I am getting the error "Error in eval(expr, envir, enclos) : object 'a' not
found" when I want to model fixed effects in the *nlme package*:

library(nlme)
metdata <- read.csv("metdataf.csv", header=TRUE)
Model <- function(times=times, a=a, b=b, g=g) {
   a + b*exp(-g*times)
}
ModelG <- deriv(
   body(Model)[[2]],
   namevec = c("a", "b", "g"),
   function.arg=Model
)
fit.fixednlme <- nlme(conc~ModelG(times=times, a=a, b=b, g=g),
                  fixed=times~1,
                  data=metdata,
                  start=c(a=0,b=1,g=0))

I created a custom function of the form alpha+beta*exp(-gamma*time) that I
want nlme to use. I also tried the code below in the* lme4 package* but it
gave me a different error "Error: object of type 'symbol' is not subsettable
"

fit.fixedlme4 <- nlmer(conc ~ ModelG(times, a, b, g), data=metdata,
start=c(a=0,
b=1,g=0), verbose=TRUE)

Thank you so much in advance,

Best,

Brenda

From ABaggett at umhb.edu  Mon Jun 24 20:17:09 2013
From: ABaggett at umhb.edu (Baggett, Aaron)
Date: Mon, 24 Jun 2013 18:17:09 +0000
Subject: [R-sig-ME] Multinomial Outcomes
Message-ID: <CF4FCABB-C621-41B3-B2A9-E3709B818E99@umhb.edu>

Hi all:

I'm searching for an R package or function that can handle a multinomial outcome in a hierarchical generalized linear mixed model.

Thanks,

Aaron Baggett
Dept. of Psychology
University of Mary Hardin-Baylor
(254) 295-4553


From andreas.karpf at univ-paris1.fr  Mon Jun 24 20:34:01 2013
From: andreas.karpf at univ-paris1.fr (Andreas Karpf)
Date: Mon, 24 Jun 2013 20:34:01 +0200
Subject: [R-sig-ME] Multinomial Outcomes
In-Reply-To: <CF4FCABB-C621-41B3-B2A9-E3709B818E99@umhb.edu>
References: <CF4FCABB-C621-41B3-B2A9-E3709B818E99@umhb.edu>
Message-ID: <CAKA9Mw7svZ759E_hwzDP_DvhHaCihD=hY6WTsHOBOYikko84GA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130624/c1452a48/attachment.pl>

From andreas.karpf at univ-paris1.fr  Mon Jun 24 12:06:26 2013
From: andreas.karpf at univ-paris1.fr (Andreas Karpf)
Date: Mon, 24 Jun 2013 12:06:26 +0200
Subject: [R-sig-ME] MCMCglmm models stored as elements in a list
In-Reply-To: <1372064876.42422.YahooMailNeo@web28805.mail.ir2.yahoo.com>
References: <1372064876.42422.YahooMailNeo@web28805.mail.ir2.yahoo.com>
Message-ID: <CAKA9Mw7LuRMiGAKXX+TNKATRTWXDj221VwWagB=85uSm7RypnA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130624/f4310ca1/attachment.pl>

From robert.espesser at lpl-aix.fr  Tue Jun 25 18:40:19 2013
From: robert.espesser at lpl-aix.fr (espesser)
Date: Tue, 25 Jun 2013 18:40:19 +0200
Subject: [R-sig-ME] Multinomial Outcomes
In-Reply-To: <CAKA9Mw7svZ759E_hwzDP_DvhHaCihD=hY6WTsHOBOYikko84GA@mail.gmail.com>
References: <CF4FCABB-C621-41B3-B2A9-E3709B818E99@umhb.edu>
	<CAKA9Mw7svZ759E_hwzDP_DvhHaCihD=hY6WTsHOBOYikko84GA@mail.gmail.com>
Message-ID: <51C9C7F3.2000406@lpl-aix.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130625/574399f7/attachment.pl>

From yc2800 at columbia.edu  Tue Jun 25 19:06:57 2013
From: yc2800 at columbia.edu (Brenda Chang)
Date: Tue, 25 Jun 2013 13:06:57 -0400
Subject: [R-sig-ME] Fwd: nlme package nonlinear mixed model errors - fixed
	effects only
Message-ID: <CABXqi-zVno_StHyVBrOD4iWR9ZRiJeWzMhaKpLL-yAoL3H8G+A@mail.gmail.com>

Hi,

I am trying to use nlme and lme4 packages to perform a nonlinear mixed
effects model, but just with the fixed effects first. (The fixed with
random effects models do work). I created a custom model of the form alpha
+ beta*exp(-gamma*time) with the y variable as "conc".

I would very much appreciate any help or suggestions!

Thank you!

Brenda


library(nlme)
library(lme4)
metdata <- read.csv("metdatf.csv", header=TRUE)
Model <- function(times=times, a=a, b=b, g=g) {
   a + b*exp(-g*times)
}
ModelG <- deriv(
   body(Model)[[2]],
   namevec = c("a", "b", "g"),
   function.arg=Model
)
#use nlme package
fit.fixednlme <- nlme(conc~ModelG(times=times, a=a, b=b, g=g),
                  fixed=times~1,
                  data=metdata,
                  start=c(a=0,b=1,g=0))
#gives error: Error in eval(expr, envir, enclos) : object 'a' not found

#use lme4 package
fit.fixedlme4 <- nlmer(conc ~ ModelG(times, a, b, g), data=metdata,
start=c(a=0,
b=1,g=0), verbose=TRUE)
#gives error: Error: object of type 'symbol' is not subsettable

---------- Forwarded message ----------
From: Brenda Chang <ybc2 at cornell.edu>
Date: Mon, Jun 24, 2013 at 1:42 PM
Subject: nlme package nonlinear mixed model error when fitting only fixed
effects
To: r-sig-mixed-models at r-project.org


Dear all,

I am getting the error "Error in eval(expr, envir, enclos) : object 'a' not
found" when I want to model fixed effects in the *nlme package*:

library(nlme)
metdata <- read.csv("metdataf.csv", header=TRUE)
Model <- function(times=times, a=a, b=b, g=g) {
   a + b*exp(-g*times)
}
ModelG <- deriv(
   body(Model)[[2]],
   namevec = c("a", "b", "g"),
   function.arg=Model
)
fit.fixednlme <- nlme(conc~ModelG(times=times, a=a, b=b, g=g),
                  fixed=times~1,
                  data=metdata,
                  start=c(a=0,b=1,g=0))

I created a custom function of the form alpha+beta*exp(-gamma*time) that I
want nlme to use. I also tried the code below in the* lme4 package* but it
gave me a different error "Error: object of type 'symbol' is not subsettable
"

fit.fixedlme4 <- nlmer(conc ~ ModelG(times, a, b, g), data=metdata,
start=c(a=0,
b=1,g=0), verbose=TRUE)

Thank you so much in advance,

Best,

Brenda

From henrik.singmann at psychologie.uni-freiburg.de  Wed Jun 26 08:04:08 2013
From: henrik.singmann at psychologie.uni-freiburg.de (Henrik Singmann)
Date: Wed, 26 Jun 2013 08:04:08 +0200
Subject: [R-sig-ME] Bug in anova.mer with models in a list (CRAN lme4 and
	lme4.0 only)
Message-ID: <kqe08i$j0n$1@ger.gmane.org>

Hi all,

there seems to be a bug in the anova method for mer objects with two models when both models are inside a list:

require(lme4)

# from ?lmer
fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
fm2 <- lmer(Reaction ~ Days + (1|Subject) + (0+Days|Subject), sleepstudy)

# both models inside a list do not work:
anova(list(fm1)[[1]], list(fm2)[[1]])

## Error in names(mods) <- sapply(as.list(mCall)[c(FALSE, TRUE, modp)], as.character) :
##   'names' attribute [6] must be the same length as the vector [2]

# no list or one list works:
anova(fm1, fm2)
anova(list(fm1)[[1]], fm2)
anova(fm1, list(fm2)[[1]])

This bug most likely resides in the sapply statement on lines 1029 and 1030 in lmer.R (CRAN tar.gz of lme4):
names(mods) <- sapply(as.list(mCall)[c(FALSE, TRUE, modp)],
				    as.character)
mods is only of length 2, but the sapply call evaluates to:
      object
[1,] "[["        "[["
[2,] "list(fm1)" "list(fm2)"
[3,] "1"         "1"


This problem occurs for both CRAN lme4 and r-forge lme4.0, but not lme4 devel from github.

I do not think this bug is critical and it is relatively easy to circumvent (i.e., simply assign one of the list models to a non-list object prior) but couldn't find it documented somewhere, so I thought it would be nice to report it.

Cheers,
Henrik


-- 
Dipl. Psych. Henrik Singmann
PhD Student
Albert-Ludwigs-Universit?t Freiburg, Germany
http://www.psychologie.uni-freiburg.de/Members/singmann


From James.Grecian at glasgow.ac.uk  Wed Jun 26 16:33:12 2013
From: James.Grecian at glasgow.ac.uk (James Grecian)
Date: Wed, 26 Jun 2013 15:33:12 +0100
Subject: [R-sig-ME] Comparing random effects with exactRLRT
Message-ID: <1E74325F1E320E4FAAEB051976822A0D3C009FD645@CMS03.campus.gla.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130626/3af41079/attachment.pl>

From Friso.muijsers at uni-oldenburg.de  Wed Jun 26 17:29:26 2013
From: Friso.muijsers at uni-oldenburg.de (Friso Muijsers)
Date: Wed, 26 Jun 2013 17:29:26 +0200
Subject: [R-sig-ME] LME - varComb and varIdent
Message-ID: <51CB08D6.60003@uni-oldenburg.de>

Hello,

I'm quite new to LMEs and have a question to which I did not find an 
answer in the archives or in the P&B chapter 5 (allthough I have 
problems undestanding the latter, fully).
Im trying to fit a linear mixed model to my data (DV = numerical, IV = 
numerical and factorial).
I have some issues with variance heterogeneity within two of my factors:

1) experimental type, two levels: "lab" and "field")
2) system, two levels: "marine" and "limnic"

When adding both variance structures to my models, my results differ 
slightly, depending on whether I use "weights = 
varIdent(form=~1|system*exp.type)" or "weights = 
varComb(varIdent(form=~1|exp.type), varIdent(form=~1|system))".
Which approach would be the better one? What does the " * " exactly do? 
It somehow uses one additional df.

                             Model     df      AIC BIC            
logLik               Test       L.Ratio p-value
lmaicresisa         1             14     127.1082     160.2804 -49.55408
lmaicresisb         2             15     128.8289     164.3707 -49.41447 
     1 vs 2      0.279231         0.5972


And a general question: I've seen (read) many people arguing that one 
should not use the varFunc too excessively. With only one varIdent 
Factor, my models have indeed much better p-values (all though I 
understand that those are less relevant in LME) but my AIC and LogLik 
increase. Should I use the more parsimonious model with both variance 
factors (as indicated by AIC) ? Are the low p-values with 2 
var-functions an indication of a bad model? QQ-Plots indicate a slightly 
better model fit with 2 var-functions.

It is difficult to add a nice example here, since my data are relatively 
complex (meta-analysis). If it is necessary, I can try to create a 
comparable dataset, allthough not sure how to.

This is my model:

lmresisc = 
lme(resis.log~evenness+exp.type+exp.type:evenness+org.type.merged+org.type.merged:evenness+system+log(exact.duration)+system2,
                        random =~1|authors.year,
                        data = 
data[(!is.na(data$evenness)&!is.na(data$resis.log)),], weights = 
varIdent(form=~1|system*exp.type), method = "ML")
         summary(lmresisc)
         lmaicresisc = stepAIC(lmresisc)
         summary(lmaicresisc)

This is the last step of the stepAIC:

Step:  AIC=128.83
resis.log ~ evenness + exp.type + org.type.merged + system +
     log(exact.duration) + evenness:exp.type + evenness:org.type.merged

                                                    Df    AIC
<none>                                               128.83
- evenness:exp.type                1       129.38
- system                                    1       132.48
- evenness:org.type.merged  2        133.55
- log(exact.duration)                1        134.20


and this is the summary of the final model

       Value                 Std.Error     DF    t-value p-value
(Intercept) -1.963651         0.6959103     62     -2.8217014  0.0064
evenness                                                   -2.231725     
     1.4724964     62     -1.5156064  0.1347
exp.typelab                                                -0.487326     
     0.9387122       7     -0.5191437  0.6197
org.type.mergedheterotroph                   -2.245062 1.3380510       7 
     -1.6778601  0.1373
org.type.mergedmixed                            -2.494429 1.1662591   
     7     -2.1388289  0.0698
systemmarine                                            0.505430     
0.2204285       7      2.2929430  0.0556
log(exact.duration)                                    0.406731     
0.1536198     62      2.6476456  0.0103
evenness:exp.typelab                               2.295373 1.4621236 
     62      1.5698901  0.1215
evenness:org.type.mergedheterotroph   3.686948         1.6697807 62      
2.2080430  0.0309
evenness:org.type.mergedmixed            5.930363         2.0642291     
62      2.8729191  0.0056


I hope I gave enough information, please forgive me, if not. This is my 
first question here, so i'm not sure about that.
Thanks in advance!

Friso

-- 
Friso Muijsers

Institute for Chemistry and Biology of the Marine Environment (ICBM)
Carl-von-Ossietzky University Oldenburg
Schleusenstrasse 1
26382 Wilhemshaven


From Friso.muijsers at uni-oldenburg.de  Wed Jun 26 17:33:33 2013
From: Friso.muijsers at uni-oldenburg.de (Friso Muijsers)
Date: Wed, 26 Jun 2013 17:33:33 +0200
Subject: [R-sig-ME] LME - varComb and varIdent
In-Reply-To: <51CB08D6.60003@uni-oldenburg.de>
References: <51CB08D6.60003@uni-oldenburg.de>
Message-ID: <51CB09CD.4010602@uni-oldenburg.de>

Am 6/26/2013 5:29 PM, schrieb Friso Muijsers:
> Hello,
>
> I'm quite new to LMEs and have a question to which I did not find an 
> answer in the archives or in the P&B chapter 5 (allthough I have 
> problems undestanding the latter, fully).
> Im trying to fit a linear mixed model to my data (DV = numerical, IV = 
> numerical and factorial).
> I have some issues with variance heterogeneity within two of my factors:
>
> 1) experimental type, two levels: "lab" and "field")
> 2) system, two levels: "marine" and "limnic"
>
> When adding both variance structures to my models, my results differ 
> slightly, depending on whether I use "weights = 
> varIdent(form=~1|system*exp.type)" or "weights = 
> varComb(varIdent(form=~1|exp.type), varIdent(form=~1|system))".
> Which approach would be the better one? What does the " * " exactly 
> do? It somehow uses one additional df.
>
>                             Model     df      AIC BIC 
> logLik               Test       L.Ratio p-value
> lmaicresisa         1             14     127.1082     160.2804 -49.55408
> lmaicresisb         2             15     128.8289     164.3707 
> -49.41447     1 vs 2      0.279231         0.5972
>
>
> And a general question: I've seen (read) many people arguing that one 
> should not use the varFunc too excessively. With only one varIdent 
> Factor, my models have indeed much better p-values (all though I 
> understand that those are less relevant in LME) but my AIC and LogLik 
> increase. Should I use the more parsimonious model with both variance 
> factors (as indicated by AIC) ? Are the low p-values with 2 
> var-functions an indication of a bad model? QQ-Plots indicate a 
> slightly better model fit with 2 var-functions.
>
> It is difficult to add a nice example here, since my data are 
> relatively complex (meta-analysis). If it is necessary, I can try to 
> create a comparable dataset, allthough not sure how to.
>
> This is my model:
>
> lmresisc = 
> lme(resis.log~evenness+exp.type+exp.type:evenness+org.type.merged+org.type.merged:evenness+system+log(exact.duration)+system2,
>                        random =~1|authors.year,
>                        data = 
> data[(!is.na(data$evenness)&!is.na(data$resis.log)),], weights = 
> varIdent(form=~1|system*exp.type), method = "ML")
>         summary(lmresisc)
>         lmaicresisc = stepAIC(lmresisc)
>         summary(lmaicresisc)
>
> This is the last step of the stepAIC:
>
> Step:  AIC=128.83
> resis.log ~ evenness + exp.type + org.type.merged + system +
>     log(exact.duration) + evenness:exp.type + evenness:org.type.merged
>
>                                                    Df    AIC
> <none>                                               128.83
> - evenness:exp.type                1       129.38
> - system                                    1       132.48
> - evenness:org.type.merged  2        133.55
> - log(exact.duration)                1        134.20
>
>
> and this is the summary of the final model
>
>       Value                 Std.Error     DF    t-value p-value
> (Intercept) -1.963651         0.6959103     62     -2.8217014 0.0064
> evenness -2.231725         1.4724964     62     -1.5156064  0.1347
> exp.typelab -0.487326         0.9387122       7     -0.5191437  0.6197
> org.type.mergedheterotroph                   -2.245062 1.3380510       
> 7     -1.6778601  0.1373
> org.type.mergedmixed                            -2.494429 1.1662591   
>     7     -2.1388289  0.0698
> systemmarine 0.505430     0.2204285       7      2.2929430  0.0556
> log(exact.duration) 0.406731     0.1536198     62      2.6476456  0.0103
> evenness:exp.typelab                               2.295373 1.4621236 
>     62      1.5698901  0.1215
> evenness:org.type.mergedheterotroph   3.686948         1.6697807 
> 62      2.2080430  0.0309
> evenness:org.type.mergedmixed            5.930363 2.0642291     
> 62      2.8729191  0.0056
>
>
> I hope I gave enough information, please forgive me, if not. This is 
> my first question here, so i'm not sure about that.
> Thanks in advance!
>
> Friso
>
Sorry for messing up the table structure:

Another try:

Step:  AIC=128.83
resis.log ~ evenness + exp.type + org.type.merged + system +
     log(exact.duration) + evenness:exp.type + evenness:org.type.merged

                            Df    AIC
<none>                        128.83
- evenness:exp.type         1 129.38
- system                    1 132.48
- evenness:org.type.merged  2 133.55
- log(exact.duration)       1 134.20


and this is the summary of the final model

                                         Value Std.Error DF t-value p-value
(Intercept)                         -1.963651 0.6959103 62 -2.8217014  
0.0064
evenness                            -2.231725 1.4724964 62 -1.5156064  
0.1347
exp.typelab                         -0.487326 0.9387122  7 -0.5191437  
0.6197
org.type.mergedheterotroph          -2.245062 1.3380510  7 -1.6778601  
0.1373
org.type.mergedmixed                -2.494429 1.1662591  7 -2.1388289  
0.0698
systemmarine                         0.505430 0.2204285  7 2.2929430  0.0556
log(exact.duration)                  0.406731 0.1536198 62 2.6476456  0.0103
evenness:exp.typelab                 2.295373 1.4621236 62 1.5698901  0.1215
evenness:org.type.mergedheterotroph  3.686948 1.6697807 62 2.2080430  0.0309
evenness:org.type.mergedmixed        5.930363 2.0642291 62 2.8729191  0.0056

-- 
Friso Muijsers

Institute for Chemistry and Biology of the Marine Environment (ICBM)
Carl-von-Ossietzky University Oldenburg
Schleusenstrasse 1
26382 Wilhemshaven


From tommy.gaillard40 at gmail.com  Thu Jun 27 10:30:58 2013
From: tommy.gaillard40 at gmail.com (tommy gaillard)
Date: Thu, 27 Jun 2013 10:30:58 +0200
Subject: [R-sig-ME] Assessing between-individual differences in both
 intercept and slope of variable factors
Message-ID: <CAAnnU-S3T_XmroXWSpw=HH_Mt3PL4Mj3UDdmsTbXOgVS3RxkBA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130627/ef404387/attachment.pl>

From thomas.debray at gmail.com  Thu Jun 27 11:59:33 2013
From: thomas.debray at gmail.com (Thomas Debray)
Date: Thu, 27 Jun 2013 11:59:33 +0200
Subject: [R-sig-ME] standard error of random effects variance
Message-ID: <CACKhmtOzGTb=FAt3o8Wkj3XNE3tgVfeqQffs1HQ_=pH3hgtA3Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130627/2e1a3382/attachment.pl>

From justin.grace at kcl.ac.uk  Thu Jun 27 12:32:30 2013
From: justin.grace at kcl.ac.uk (Grace, Justin)
Date: Thu, 27 Jun 2013 10:32:30 +0000
Subject: [R-sig-ME] prediction and online learning
Message-ID: <A042DBD144258E4E99FFFB9970610C991A6CC4EE@AMSPRD0310MB349.eurprd03.prod.outlook.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130627/30befca2/attachment.pl>

From tommy.gaillard40 at gmail.com  Thu Jun 27 14:21:24 2013
From: tommy.gaillard40 at gmail.com (tommy gaillard)
Date: Thu, 27 Jun 2013 14:21:24 +0200
Subject: [R-sig-ME] standard error of random effects variance
In-Reply-To: <CACKhmtOzGTb=FAt3o8Wkj3XNE3tgVfeqQffs1HQ_=pH3hgtA3Q@mail.gmail.com>
References: <CACKhmtOzGTb=FAt3o8Wkj3XNE3tgVfeqQffs1HQ_=pH3hgtA3Q@mail.gmail.com>
Message-ID: <CAAnnU-ThF-BPkDwsJBhbfo_-U9CMWtqHaCGXXxMAtVS15Gxseg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130627/8eb7cea9/attachment.pl>

From thomas.debray at gmail.com  Thu Jun 27 14:40:38 2013
From: thomas.debray at gmail.com (Thomas Debray)
Date: Thu, 27 Jun 2013 14:40:38 +0200
Subject: [R-sig-ME] standard error of random effects variance
In-Reply-To: <CAAnnU-ThF-BPkDwsJBhbfo_-U9CMWtqHaCGXXxMAtVS15Gxseg@mail.gmail.com>
References: <CACKhmtOzGTb=FAt3o8Wkj3XNE3tgVfeqQffs1HQ_=pH3hgtA3Q@mail.gmail.com>
	<CAAnnU-ThF-BPkDwsJBhbfo_-U9CMWtqHaCGXXxMAtVS15Gxseg@mail.gmail.com>
Message-ID: <CACKhmtNn+C1PuCLjtqQc2rWMiPCE64-7G=gNXLPZsHWTazj_9A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130627/48f84adc/attachment.pl>

From markpayneatwork at gmail.com  Thu Jun 27 18:47:12 2013
From: markpayneatwork at gmail.com (Mark Payne)
Date: Thu, 27 Jun 2013 18:47:12 +0200
Subject: [R-sig-ME] Model validation for Presence / Absence (binomial) GLMs
Message-ID: <CAGBzUO-14sW=1DJFE_YTnHkF+NsNecG2b4Hr4sgT3nvaiyG=SQ@mail.gmail.com>

Dear R-sig-me,

How can I validate the fit of a bionomial (presence/absence) GLM?

Normally in linear modelling there is a nice array of tools
(tukey-anscombe, QQ plots, residuals vs explanatory variables,
correlation plots) that can be used to convince yourself that the fit
is ok. But when you start dealing with a bionomial (presence absence)
GLM, the whole thing kind of breaks down and starts getting ugly. For
a poisson GLM, you can go for pearson residuals - but what would be
the equivalent for a bionomial GLM? Does anyone have suggestions how
to approach this problem? Are there any "best-practices" that I am
unaware of in this regard?

Best wishes,

Mark


From hughsturrock at hotmail.com  Thu Jun 27 20:17:50 2013
From: hughsturrock at hotmail.com (Hugh Sturrock)
Date: Thu, 27 Jun 2013 19:17:50 +0100
Subject: [R-sig-ME] Model validation for Presence / Absence (binomial)
 GLMs
In-Reply-To: <CAGBzUO-14sW=1DJFE_YTnHkF+NsNecG2b4Hr4sgT3nvaiyG=SQ@mail.gmail.com>
References: <CAGBzUO-14sW=1DJFE_YTnHkF+NsNecG2b4Hr4sgT3nvaiyG=SQ@mail.gmail.com>
Message-ID: <DUB116-W31EF6379F1455384CB9BB3C8750@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130627/98259f26/attachment.pl>

From mpa at aqua.dtu.dk  Thu Jun 27 22:21:26 2013
From: mpa at aqua.dtu.dk (Mark Payne)
Date: Thu, 27 Jun 2013 20:21:26 +0000
Subject: [R-sig-ME] Model validation for Presence / Absence (binomial)
 GLMs
In-Reply-To: <DUB116-W31EF6379F1455384CB9BB3C8750@phx.gbl>
References: <CAGBzUO-14sW=1DJFE_YTnHkF+NsNecG2b4Hr4sgT3nvaiyG=SQ@mail.gmail.com>,
	<DUB116-W31EF6379F1455384CB9BB3C8750@phx.gbl>
Message-ID: <F94133E16E08E04D8D83797785A94EA211B7C6@ait-pex02mbx05.win.dtu.dk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130627/d6d22610/attachment.pl>

From chris at trickysolutions.com.au  Fri Jun 28 02:05:56 2013
From: chris at trickysolutions.com.au (Chris Howden)
Date: Fri, 28 Jun 2013 10:05:56 +1000
Subject: [R-sig-ME] Model validation for Presence / Absence (binomial)
	GLMs
In-Reply-To: <F94133E16E08E04D8D83797785A94EA211B7C6@ait-pex02mbx05.win.dtu.dk>
References: <CAGBzUO-14sW=1DJFE_YTnHkF+NsNecG2b4Hr4sgT3nvaiyG=SQ@mail.gmail.com>
	<DUB116-W31EF6379F1455384CB9BB3C8750@phx.gbl>
	<F94133E16E08E04D8D83797785A94EA211B7C6@ait-pex02mbx05.win.dtu.dk>
Message-ID: <-27859136898391847@unknownmsgid>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130628/1a74d55f/attachment.pl>

From bbolker at gmail.com  Fri Jun 28 03:46:43 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 28 Jun 2013 01:46:43 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?Model_validation_for_Presence_/_Absence_=28b?=
	=?utf-8?q?inomial=29=09GLMs?=
References: <CAGBzUO-14sW=1DJFE_YTnHkF+NsNecG2b4Hr4sgT3nvaiyG=SQ@mail.gmail.com>
	<DUB116-W31EF6379F1455384CB9BB3C8750@phx.gbl>
	<F94133E16E08E04D8D83797785A94EA211B7C6@ait-pex02mbx05.win.dtu.dk>
	<-27859136898391847@unknownmsgid>
Message-ID: <loom.20130628T034003-708@post.gmane.org>

Chris Howden <chris at ...> writes:

> 
> This is something I always battle with given the plethora of great model
> fitting methods available for other models.
> 
> I always use a variant of Hugh's suggestion and look at the % of correct
> predictions between models as a quick model fitting statistic.
> 
> And for overdispersion I believe one way is to fit individual level random
> effects and see if this is a substantively better model. There is more on
> this in the wiki http://glmm.wikidot.com/faq

  Yes, but this is unidentifiable for Bernoulli responses (as also
explained there).

  It's not as systematic, but where possible I like to compare 
parametric fits to a less-parametric fit, either a (marginal)
GAM fit or binning the data and computing (marginal) mean proportions (and
possibly binomial CIs) within bins (the latter is essentially
the basis of the Hosmer-Lemeshow test).  The effects of other
variables might lead to either a false positive or a false
negative when comparing non-parametric marginal to parametric
conditional predictions, but it's a start.

  Ben Bolker


From ken.knoblauch at inserm.fr  Fri Jun 28 06:12:50 2013
From: ken.knoblauch at inserm.fr (Ken Knonlauch)
Date: Fri, 28 Jun 2013 04:12:50 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?Model_validation_for_Presence_/_Absence_=28b?=
	=?utf-8?q?inomial=29=09GLMs?=
References: <CAGBzUO-14sW=1DJFE_YTnHkF+NsNecG2b4Hr4sgT3nvaiyG=SQ@mail.gmail.com>
	<DUB116-W31EF6379F1455384CB9BB3C8750@phx.gbl>
	<F94133E16E08E04D8D83797785A94EA211B7C6@ait-pex02mbx05.win.dtu.dk>
	<-27859136898391847@unknownmsgid>
	<loom.20130628T034003-708@post.gmane.org>
Message-ID: <loom.20130628T060912-404@post.gmane.org>

Ben Bolker <bbolker at ...> writes:

> 
> Chris Howden <chris <at> ...> writes:
> 
> > 
> > This is something I always battle with given the plethora of great model
> > fitting methods available for other models.
> > 
> > I always use a variant of Hugh's suggestion and look at the % of correct
> > predictions between models as a quick model fitting statistic.
> > 
> > And for overdispersion I believe one way is to fit individual level random
> > effects and see if this is a substantively better model. There is more on
> > this in the wiki http://glmm.wikidot.com/faq

--- snip ---



Also see the binomTools package on CRAN for some diagnostic tests 
for binomial models. 

Ken


From bbolker at gmail.com  Sat Jun 29 06:12:51 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 29 Jun 2013 00:12:51 -0400
Subject: [R-sig-ME] Beware flying pigs
Message-ID: <51CE5EC3.80705@ufl.edu>

The lme4 developers are happy to announce a scheduled release of lme4
version 1.0 (!!). We plan a feature freeze on July 8 and a release on
August 1.

We strongly encourage all users, and especially downstream package
maintainers, to try out the development version and post issues at
<https://github.com/lme4/lme4/issues>, or report them to
lme4-authors at r-project.org . (Discussing them on this list is also
encouraged, but please e-mail or post an issue as well.)  Downstream
package maintainers are also encouraged to check
<http://htmlpreview.github.io/?https://github.com/lme4/lme4/blob/master/misc/pkgtests/lme4_compat_report.html>.

See
<https://github.com/lme4/lme4/blob/master/misc/notes/release_notes.md>
for release notes, including instructions for installing via
install_github() or from the http://lme4.r-forge.r-project.org/repos
repository.

  Ben Bolker, on behalf of lme4-authors


From Tom.Wenseleers at bio.kuleuven.be  Sat Jun 29 15:49:18 2013
From: Tom.Wenseleers at bio.kuleuven.be (Tom Wenseleers)
Date: Sat, 29 Jun 2013 13:49:18 +0000
Subject: [R-sig-ME] Question on mixed model design to analyze microarray data
Message-ID: <37EFC97028F3E44082ACC5CBEC00563011278C50@ICTS-S-MBX7.luna.kuleuven.be>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130629/cbff4376/attachment.pl>

From bbolker at gmail.com  Sat Jun 29 17:57:53 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 29 Jun 2013 15:57:53 +0000 (UTC)
Subject: [R-sig-ME] Question on mixed model design to analyze microarray
	data
References: <37EFC97028F3E44082ACC5CBEC00563011278C50@ICTS-S-MBX7.luna.kuleuven.be>
Message-ID: <loom.20130629T174242-532@post.gmane.org>

Tom Wenseleers <Tom.Wenseleers at ...> writes:

> 
> Dear all,
> I was just trying to analyse some microarray gene expression
> data using mixed models in R.
> Based on the SAS code given here
> http://support.sas.com/documentation/cdl/en/
> statug/63033/HTML/default/viewer.htm#statug_hpmixed_sect035.htm

 (URL broken, sorry)

>    proc hpmixed data=microarray;
>       class marray dye trt gene pin dip;
>       model log2i = dye trt gene dye*gene trt*gene pin;
>       random marray marray*gene dip(marray) pin*marray;
>       test trt;
>    run;
> 
> I wanted to try to run the equivalent model in 
> R using lmer and then test significance using lmerTest and/or
> lsmeans. Am I correct that the correct syntax would
> be
> lmer(log2i~dye+trt+gene+dye:gene+trt:gene+pin+(1|marray)+
> (gene|marray)+(1|marray/dip)+(pin|marray), data=microarray)
> (gene has about 10 000 levels and marray 10, would this run in lmer?)

  I think you probably want a random effect of 

(1|marray) + (1|marray:gene) + (1|marray:pin)+(1|marray:dip)

or equivalently

(1|marray/gene) + (1|marray:pin) + (1|marray:dip)

 you almost certainly _don't_ want (gene|marray), which will try
to fit correlations among gene effects by microarray (i.e a 10K by 10K
correlation matrix), which will explode your computer.  At a quick
read I'm not quite sure what distinction the SAS authors are making
between "X by Y" and "X within Y": I would code "X by Y" as
(1|X) + (1|Y) + (1|X:Y)  [ (1|X*Y) might work, but I haven't tried it ]
and "X within Y" as (1|Y/X) or (1|Y) + (1|Y:X)
> 
> Also, would it be possible in any way to allow 
> variances across treatment (trt) groups to be unequal? Or is
> that only possible in nlme/lme?
> (but that wouldn't allow for such complex random effect designs, right?)

  Not at present in lmer.  You might be able to code these
random effects in nlme (see the relevant pages of Pinheiro &
Bates 2000, referenced in http://glmm.wikidot.com/faq under
"Crossed random effects", but lme4 is likely to be a lot faster.


From sjmyers3142 at gmail.com  Sun Jun 30 19:56:27 2013
From: sjmyers3142 at gmail.com (Seth Myers)
Date: Sun, 30 Jun 2013 13:56:27 -0400
Subject: [R-sig-ME] partial residuals or another method to check nonlinear
 model spec.? (emails keep bouncing)
Message-ID: <CAO-WCxf-LGycF+5q57xARcTUdd8TbxPgKw8_+CA=CWiSMw3EKg@mail.gmail.com>

Hi,

Hi,

This might be a double post because my previous entry bounced.  If so,
I apoogize.

I have not found a method to extract partial residuals plots given a
nonlinear model employed in gnls.

My dependent variable is bound between 0 and 1 but can take on
fractional values such as 0.75, and a logistic function of a few
variables seems to do well when predictions are plotted against the
dependent variable.

Right now, the terms are simply entered as being linear within the
model (I might not be stating that precisely, but the model is simply

y=1/(1+exp1(b0 +b1*X1))

if only one independent variable were included).

I suppose I could use splines and see what transformations or other
models are suggested by them.  Given that the dependent is not binary,
I might be able to transform the dependent variable using a link
function and then simply run a linear model and extract partial
residuals from it.  But I am not sure if this can be justified. Is
there a better and/or easier approach someone could recommend?


