From j@de@ @end|ng |rom uc@d@edu  Tue Oct  1 08:25:21 2019
From: j@de@ @end|ng |rom uc@d@edu (Ades, James)
Date: Tue, 1 Oct 2019 06:25:21 +0000
Subject: [R-sig-ME] Large mixed & crossed-effect model looking at
 educational spending on crime rates with error messages
In-Reply-To: <a278d0c3-f462-8e50-64a4-3b8d40f04986@mpi.nl>
References: <3969F144-2738-4733-B9E2-EDA2E3375418@UCSD.edu>
 <CAJuCY5xNAMirpyR+qy=Li4kGv-ys97AEis=fRyRgDf4WP+6RaQ@mail.gmail.com>
 <1AD83B84-C39B-4EE8-B50F-2E988419054C@UCSD.edu>
 <CAJuCY5yZhtkNrPf1rriStgR0Fp=NgN2bD2r6rVSUG9NV0sX6Sw@mail.gmail.com>
 <CD530BD0-2D53-4EB3-B003-5596665D7A86@UCSD.edu>
 <CAJuCY5wL4V4Fpgu39A8d_SZAazDcfCnwc1QU7piTffBkuGuuQQ@mail.gmail.com>
 <DBAF8D75-2563-4A00-B5BA-0107D2625946@UCSD.edu>
 <CABghstQdPD_vYBW5vbB1xVLnSWCmGvd5iRd5pb9efMYYdt=DJQ@mail.gmail.com>
 <23b89902-4345-5aec-299d-48d194591bed@mpi.nl>
 <61BCB906-022A-473D-BA01-583E961E3B41@UCSD.edu>
 <a278d0c3-f462-8e50-64a4-3b8d40f04986@mpi.nl>
Message-ID: <0B21F4E6-E765-4CF5-B2B3-4B905376C959@UCSD.edu>

Re default optimizer: haha...yes, that makes sense:)

Re multicollinearity with race: it?s not crucial that I include all races in the same model?I could run each race separately in different models and report those effects.

Re year-spending: when I look at correlation in a strict sense they are roughly .35 correlated. In a non-strict sense, it?s actually the other way around?including year in the model changes the effect of spending (which is really what I?m trying to measure). I see what you?re saying with regard to the actual source of variation, but can?t it be the case that one thing isn?t vaguely related to another, and that the actual source of variation is the two variables. In such a case, aren?t there ways to parse that covariance, such that you gain a better understanding of each variable?s effect on variance?

Also, just want to make sure: if you don?t have a dependent observation for a given condition, you would have to remove that entire row, correct? The mixed-model wouldn?t be able to work around that? This is what i learned in stats class, but if I?m doing this wrong, I think this might also be affecting correlation.

Thanks, Philip!

James



On Sep 29, 2019, at 3:06 AM, Phillip Alday <phillip.alday at mpi.nl<mailto:phillip.alday at mpi.nl>> wrote:

The default optimizer in lme4 is the default for a reason. :) While
there's no free lunch or single best optimizer for every situation, the
default was chosen based on our experience about which optimizer works
performs well across a wide range of models and datasets.

Multicollinearity in mixed-effects models works pretty much exactly the
same way as it does in fixed-effects (i.e. regular/not mixed) regression
and so the way it's addressed (converting to PC basis, residualization,
etc.) In your case, you could omit one race and then the remaining races
will be linearly independent, albeit still correlated with another. This
correlation isn't great and will inflate your standard errors, but then
at least your design matrix won't be rank deficient.

Regarding year-spending: Are you using 'correlated' in a strict sense,
e.g. that spending tends to go up year-by-year? Or do just mean that
including spending in the model changes the effect of year? (I think the
latter weakly implies the former, but it's a different perspective.)
Either way, the changing coefficient isn't terribly surprising. In
'human' terms: if you don't have the option of attributing something to
the actual source of variation, but you do have something that is
vaguely related to it, then you will attribute it to that. However, if
you're ever given the chance to attribute it to the actual source, you
will do that and your attribution to the vaguely-related thing will change.

Best,
Phillip

On 29/09/2019 03:20, Ades, James wrote:
Thanks, Ben and Philip!

So I think I was conflating having a continuous dependent variable,
which could then be broken up into different categories with dummy
variables (for instance, if I wanted to look at how wealth affects the
distribution of race in an area, I could create a model like lmer(total
people ~ race + per capita income + ?) with creating something similar
with a fixed factor (which I guess can?t be done).

I did try running the variables independently, which worked, I just
thought there was a way to combine races, and then per that logic,
thought that since race variables repeated within place (city/town), I
could nest it within PLACE_ID. But realized that the percent race as a
fixed effect (as an output) didn?t really make sense?hence my confusion.
So I guess somewhere in there my logic was afoul.

Regarding Nelmed-Mead: that?s odd...I recall reading somewhere that it
was actually quicker and more likely to converge. Good to know. I read
through the lme4 package details here:
https://cran.r-project.org/web/packages/lme4/lme4.pdf Would you
recommend then optimx? Or Nloptr/bobyqa? (which I think is the default).

Regarding multicollinearity: is there an article you could send me on
dealing with multicollinearity in mixed-effect models? I?ve perused the
internet, but haven?t been able to find a great how to and dealing with
it, such that you can better parse the effects of different variables (I
know that one can use PCA, but that fundamentally alters the process,
and isn?t there a way of averaging variables such that you minimize
collinearity?).

One thing I?m currently dealing with in my model is that year as a fixed
effect is correlated with a district?s spending, such that if I remove
year, district spending has a negative effect on crime, but including
year as a fixed effect alters the spending regression coefficient to be
positive (just north of zero). Though here, specifically, I?m not sure
if this is technically collinearity, or if time as a fixed factor is
merely controlling, here, for crime change over time, where a model
without year as a fixed factor would be looking at the effect of
district spending on crime (similar to a model where years are averaged
together). Does that make sense? Is that interpretation accurate?

Thanks much!

James


On Sep 28, 2019, at 8:09 AM, Phillip Alday <phillip.alday at mpi.nl<mailto:phillip.alday at mpi.nl>
<mailto:phillip.alday at mpi.nl>> wrote:

ink the answer to your proximal question about per_race is that
you would need five *different* numerical varia


	[[alternative HTML version deleted]]


From ph||||p@@|d@y @end|ng |rom mp|@n|  Tue Oct  1 09:15:16 2019
From: ph||||p@@|d@y @end|ng |rom mp|@n| (Phillip Alday)
Date: Tue, 1 Oct 2019 09:15:16 +0200
Subject: [R-sig-ME] Large mixed & crossed-effect model looking at
 educational spending on crime rates with error messages
In-Reply-To: <0B21F4E6-E765-4CF5-B2B3-4B905376C959@UCSD.edu>
References: <3969F144-2738-4733-B9E2-EDA2E3375418@UCSD.edu>
 <CAJuCY5xNAMirpyR+qy=Li4kGv-ys97AEis=fRyRgDf4WP+6RaQ@mail.gmail.com>
 <1AD83B84-C39B-4EE8-B50F-2E988419054C@UCSD.edu>
 <CAJuCY5yZhtkNrPf1rriStgR0Fp=NgN2bD2r6rVSUG9NV0sX6Sw@mail.gmail.com>
 <CD530BD0-2D53-4EB3-B003-5596665D7A86@UCSD.edu>
 <CAJuCY5wL4V4Fpgu39A8d_SZAazDcfCnwc1QU7piTffBkuGuuQQ@mail.gmail.com>
 <DBAF8D75-2563-4A00-B5BA-0107D2625946@UCSD.edu>
 <CABghstQdPD_vYBW5vbB1xVLnSWCmGvd5iRd5pb9efMYYdt=DJQ@mail.gmail.com>
 <23b89902-4345-5aec-299d-48d194591bed@mpi.nl>
 <61BCB906-022A-473D-BA01-583E961E3B41@UCSD.edu>
 <a278d0c3-f462-8e50-64a4-3b8d40f04986@mpi.nl>
 <0B21F4E6-E765-4CF5-B2B3-4B905376C959@UCSD.edu>
Message-ID: <1741bbc0-830b-0807-6756-bf3dcd9aab75@mpi.nl>



On 01/10/2019 08:25, Ades, James wrote:
I see what you?re saying
> with regard to the actual source of variation, but can?t it be the case
> that one thing isn?t vaguely related to another, and that the actual
> source of variation is the two variables. In such a case, aren?t there
> ways to parse that covariance, such that you gain a better understanding
> of each variable?s effect on variance? 

This is non trivial in the general case. If you know something about the
latent structure, then things like structural equation models may help,
see e.g.

https://www.johnmyleswhite.com/notebook/2016/02/25/a-variant-on-statistically-controlling-for-confounding-constructs-is-harder-than-you-think/

which provides an alternative presentation of

Westfall, J. & Yarkoni, T. (2016): Statistically Controlling for
Confounding Constructs Is Harder than You Think PLoS ONE, , 11 , 1-22

Remember, linear regression -- fixed or mixed effect -- isn't sufficient
to make causal conclusions without additional assumptions. The issue
with collinearity (as long as its not perfect / leads to rank
deficiency) is not so much in the estimates as in the standard errors,
which get inflated by the covariance. There are several classical
approaches to dealing with this (such as residualization), but they all
have pros and cons. (Oversimplifying a bit) Residualization for example
attributes only the residual variance from the first predictor to the
second predictor -- i.e. all of the shared variance is attributed to the
first predictor. Regularized regression (e.g. LASSO, ridge, elastic net)
may help, especially with prediction. Equivalently, in a Bayesian
framework, appropriate choice of priors may help to pull the estimates
apart.

But all of these comments aren't specific to the mixed-model case, so
that opens up the set of resources you can turn to. ;)


> Also, just want to make sure: if you don?t have a dependent observation
> for a given condition, you would have to remove that entire row,
> correct? The mixed-model wouldn?t be able to work around that? This is
> what i learned in stats class, but if I?m doing this wrong, I think this
> might also be affecting correlation.

If I understand you correctly, you're asking what happens when your
response variable (y) is missing for a given combination of predictors
(x's)? Depending on the exact structure of the missing data, multiple
imputation might help you there, but generally if a particular case
never occurs (say "12 hours of sunlight but with winter temperatures"
for a model predicting plant growth derived from observations taken
outside but which you want to use to predict in a greenhouse), it's hard
to make inferences about that complete interaction. lme4 by default
drops incomplete cases (i.e. any rows in the dataframe where there is an
NA *for variables used in the model*).

Phillip

> 
> Thanks, Philip!
> 
> James
> 
> 
> 
>> On Sep 29, 2019, at 3:06 AM, Phillip Alday <phillip.alday at mpi.nl
>> <mailto:phillip.alday at mpi.nl>> wrote:
>>
>> The default optimizer in lme4 is the default for a reason. :) While
>> there's no free lunch or single best optimizer for every situation, the
>> default was chosen based on our experience about which optimizer works
>> performs well across a wide range of models and datasets.
>>
>> Multicollinearity in mixed-effects models works pretty much exactly the
>> same way as it does in fixed-effects (i.e. regular/not mixed) regression
>> and so the way it's addressed (converting to PC basis, residualization,
>> etc.) In your case, you could omit one race and then the remaining races
>> will be linearly independent, albeit still correlated with another. This
>> correlation isn't great and will inflate your standard errors, but then
>> at least your design matrix won't be rank deficient.
>>
>> Regarding year-spending: Are you using 'correlated' in a strict sense,
>> e.g. that spending tends to go up year-by-year? Or do just mean that
>> including spending in the model changes the effect of year? (I think the
>> latter weakly implies the former, but it's a different perspective.)
>> Either way, the changing coefficient isn't terribly surprising. In
>> 'human' terms: if you don't have the option of attributing something to
>> the actual source of variation, but you do have something that is
>> vaguely related to it, then you will attribute it to that. However, if
>> you're ever given the chance to attribute it to the actual source, you
>> will do that and your attribution to the vaguely-related thing will
>> change.
>>
>> Best,
>> Phillip
>>
>> On 29/09/2019 03:20, Ades, James wrote:
>>> Thanks, Ben and Philip!
>>>
>>> So I think I was conflating having a continuous dependent variable,
>>> which could then be broken up into different categories with dummy
>>> variables (for instance, if I wanted to look at how wealth affects the
>>> distribution of race in an area, I could create a model like lmer(total
>>> people ~ race + per capita income + ?) with creating something similar
>>> with a fixed factor (which I guess can?t be done).
>>>
>>> I did try running the variables independently, which worked, I just
>>> thought there was a way to combine races, and then per that logic,
>>> thought that since race variables repeated within place (city/town), I
>>> could nest it within PLACE_ID. But realized that the percent race as a
>>> fixed effect (as an output) didn?t really make sense?hence my confusion.
>>> So I guess somewhere in there my logic was afoul.
>>>
>>> Regarding Nelmed-Mead: that?s odd...I recall reading somewhere that it
>>> was actually quicker and more likely to converge. Good to know. I read
>>> through the lme4 package details here:
>>> https://cran.r-project.org/web/packages/lme4/lme4.pdf Would you
>>> recommend then optimx? Or Nloptr/bobyqa? (which I think is the default).
>>>
>>> Regarding multicollinearity: is there an article you could send me on
>>> dealing with multicollinearity in mixed-effect models? I?ve perused the
>>> internet, but haven?t been able to find a great how to and dealing with
>>> it, such that you can better parse the effects of different variables (I
>>> know that one can use PCA, but that fundamentally alters the process,
>>> and isn?t there a way of averaging variables such that you minimize
>>> collinearity?).
>>>
>>> One thing I?m currently dealing with in my model is that year as a fixed
>>> effect is correlated with a district?s spending, such that if I remove
>>> year, district spending has a negative effect on crime, but including
>>> year as a fixed effect alters the spending regression coefficient to be
>>> positive (just north of zero). Though here, specifically, I?m not sure
>>> if this is technically collinearity, or if time as a fixed factor is
>>> merely controlling, here, for crime change over time, where a model
>>> without year as a fixed factor would be looking at the effect of
>>> district spending on crime (similar to a model where years are averaged
>>> together). Does that make sense? Is that interpretation accurate?
>>>
>>> Thanks much!
>>>
>>> James
>>>
>>>
>>>> On Sep 28, 2019, at 8:09 AM, Phillip Alday <phillip.alday at mpi.nl
>>>> <mailto:phillip.alday at mpi.nl>
>>>> <mailto:phillip.alday at mpi.nl>> wrote:
>>>>
>>>>> ink the answer to your proximal question about per_race is that
>>>>> you would need five *different* numerical varia
>


From m@tthi@s@suter m@iii@g oii @groscope@@dmi@@ch  Wed Oct  2 15:50:19 2019
From: m@tthi@s@suter m@iii@g oii @groscope@@dmi@@ch (m@tthi@s@suter m@iii@g oii @groscope@@dmi@@ch)
Date: Wed, 2 Oct 2019 13:50:19 +0000
Subject: [R-sig-ME] Random-effects variance-covariance matrix in lmer?
Message-ID: <83e615e4412d405db0d32a139828388c@agroscope.admin.ch>

Hi all

I'm looking for a way to specify a more complex variance-covariance matrix for the random effects in lmer(). For example, in lme() (nlme package), there are the pdMat classes to specify e.g. a compound symmetry (pdCompSym) or a multiple of an identity (pdIdent) structure for the variance-covariance matrix of random effects. Is there a possibility to code an equivalent for lmer()? I'm specifically interested in "compound symmetry" and "multiple of an identity".

I assume that Douglas Bates or Ben Bolker have a distinct answer on that.

Thanks in advance,
Matthias


---------------------------------------------------------
Matthias Suter, Dr.sc.nat.
Forage Production and Grassland Systems

Agroscope
Reckenholzstrasse 191, CH-8046 Z?rich

Phone +41 58 468 75 90
Fax      +41 58 468 72 01
matthias.suter at agroscope.admin.ch
www.agroscope.ch
---------------------------------------------------------


	[[alternative HTML version deleted]]


From ph||||p@@|d@y @end|ng |rom mp|@n|  Wed Oct  2 16:29:41 2019
From: ph||||p@@|d@y @end|ng |rom mp|@n| (Phillip Alday)
Date: Wed, 2 Oct 2019 16:29:41 +0200
Subject: [R-sig-ME] Random-effects variance-covariance matrix in lmer?
In-Reply-To: <83e615e4412d405db0d32a139828388c@agroscope.admin.ch>
References: <83e615e4412d405db0d32a139828388c@agroscope.admin.ch>
Message-ID: <524786bd-0926-20f9-53bf-b5e9281cfaa3@mpi.nl>

This is a frequent question for lme4 and MixedModels.jl and the answer
is....

it's not going to be supported in any mainstream release of either
package in the foreseeable future.

You can however still get some of these structures by clever
specification of the random effects.

For example:

data(Machines,package="nlme")
library("lme4")

m <- lmer(score ~ 1 + Machine + (0+Machine|Worker), Machines)

# with compound symmetry
m_cs <- lmer(score ~ 1 + Machine + (1|Worker) + (1|Worker:Machine),
Machines)

# pdDiag -- for continuous variables, you could just use the || syntax

m_diag <- lmer(score ~ 1 + Machine + (0+dummy(Machine,"A")|Worker) +
(0+dummy(Machine,"B")|Worker) + (0+dummy(Machine,"C")|Worker), Machines)

I'll leave pdIdent as an exercise for the OP. ;)

Best,
Phillip

On 02/10/2019 15:50, matthias.suter at agroscope.admin.ch wrote:
> Hi all
> 
> I'm looking for a way to specify a more complex variance-covariance matrix for the random effects in lmer(). For example, in lme() (nlme package), there are the pdMat classes to specify e.g. a compound symmetry (pdCompSym) or a multiple of an identity (pdIdent) structure for the variance-covariance matrix of random effects. Is there a possibility to code an equivalent for lmer()? I'm specifically interested in "compound symmetry" and "multiple of an identity".
> 
> I assume that Douglas Bates or Ben Bolker have a distinct answer on that.
> 
> Thanks in advance,
> Matthias
> 
> 
> ---------------------------------------------------------
> Matthias Suter, Dr.sc.nat.
> Forage Production and Grassland Systems
> 
> Agroscope
> Reckenholzstrasse 191, CH-8046 Z?rich
> 
> Phone +41 58 468 75 90
> Fax      +41 58 468 72 01
> matthias.suter at agroscope.admin.ch
> www.agroscope.ch
> ---------------------------------------------------------
> 
> 
> 	[[alternative HTML version deleted]]
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From mo|||eebrook@ @end|ng |rom gm@||@com  Wed Oct  2 16:39:43 2019
From: mo|||eebrook@ @end|ng |rom gm@||@com (Mollie Brooks)
Date: Wed, 2 Oct 2019 16:39:43 +0200
Subject: [R-sig-ME] Random-effects variance-covariance matrix in lmer?
In-Reply-To: <524786bd-0926-20f9-53bf-b5e9281cfaa3@mpi.nl>
References: <83e615e4412d405db0d32a139828388c@agroscope.admin.ch>
 <524786bd-0926-20f9-53bf-b5e9281cfaa3@mpi.nl>
Message-ID: <9D41F7B4-59E6-40A4-AEF2-8A717CE11679@gmail.com>

There are additional random effect variance-covariance structures available in glmmTMB, including compound symmetry. 
They?re documented here
https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html <https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html>

cheers,
Mollie


> On 2Oct 2019, at 16:29, Phillip Alday <phillip.alday at mpi.nl> wrote:
> 
> This is a frequent question for lme4 and MixedModels.jl and the answer
> is....
> 
> it's not going to be supported in any mainstream release of either
> package in the foreseeable future.
> 
> You can however still get some of these structures by clever
> specification of the random effects.
> 
> For example:
> 
> data(Machines,package="nlme")
> library("lme4")
> 
> m <- lmer(score ~ 1 + Machine + (0+Machine|Worker), Machines)
> 
> # with compound symmetry
> m_cs <- lmer(score ~ 1 + Machine + (1|Worker) + (1|Worker:Machine),
> Machines)
> 
> # pdDiag -- for continuous variables, you could just use the || syntax
> 
> m_diag <- lmer(score ~ 1 + Machine + (0+dummy(Machine,"A")|Worker) +
> (0+dummy(Machine,"B")|Worker) + (0+dummy(Machine,"C")|Worker), Machines)
> 
> I'll leave pdIdent as an exercise for the OP. ;)
> 
> Best,
> Phillip
> 
> On 02/10/2019 15:50, matthias.suter at agroscope.admin.ch wrote:
>> Hi all
>> 
>> I'm looking for a way to specify a more complex variance-covariance matrix for the random effects in lmer(). For example, in lme() (nlme package), there are the pdMat classes to specify e.g. a compound symmetry (pdCompSym) or a multiple of an identity (pdIdent) structure for the variance-covariance matrix of random effects. Is there a possibility to code an equivalent for lmer()? I'm specifically interested in "compound symmetry" and "multiple of an identity".
>> 
>> I assume that Douglas Bates or Ben Bolker have a distinct answer on that.
>> 
>> Thanks in advance,
>> Matthias
>> 
>> 
>> ---------------------------------------------------------
>> Matthias Suter, Dr.sc.nat.
>> Forage Production and Grassland Systems
>> 
>> Agroscope
>> Reckenholzstrasse 191, CH-8046 Z?rich
>> 
>> Phone +41 58 468 75 90
>> Fax      +41 58 468 72 01
>> matthias.suter at agroscope.admin.ch
>> www.agroscope.ch
>> ---------------------------------------------------------
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From m@tthi@s@suter m@iii@g oii @groscope@@dmi@@ch  Wed Oct  2 16:52:54 2019
From: m@tthi@s@suter m@iii@g oii @groscope@@dmi@@ch (m@tthi@s@suter m@iii@g oii @groscope@@dmi@@ch)
Date: Wed, 2 Oct 2019 14:52:54 +0000
Subject: [R-sig-ME] Random-effects variance-covariance matrix in lmer?
In-Reply-To: <524786bd-0926-20f9-53bf-b5e9281cfaa3@mpi.nl>
References: <83e615e4412d405db0d32a139828388c@agroscope.admin.ch>
 <524786bd-0926-20f9-53bf-b5e9281cfaa3@mpi.nl>
Message-ID: <af651b34901943fb9ed03301057d368d@agroscope.admin.ch>

Thanks, Philipp.

I was a aware of the pdDiag and the pdCorSym solution, and so I specifically asked for pdCompSym and pdIdent ...

As for your compound symmetry suggestion, it is not quite clear to me. Up to now, I would have named "(1|Worker:Machine)" a random interaction term, specifying a distinct level for each worker*machine combination (and that's what is given by ranef(m_cs). How does this relate to the covariance in the compound symmetry, where also a multiple of identity is fit to diagonal?

I have also tried to sort out the pdIdent equivalent, using similar coding as you suggest below, but was not successful so far. Do you know a similar solution?

Thanks again,
Matthias 




-----Urspr?ngliche Nachricht-----
Von: Phillip Alday <phillip.alday at mpi.nl> 
Gesendet: Mittwoch, 2. Oktober 2019 16:30
An: Suter Matthias Agroscope <matthias.suter at agroscope.admin.ch>; r-sig-mixed-models at r-project.org
Betreff: Re: [R-sig-ME] Random-effects variance-covariance matrix in lmer?

This is a frequent question for lme4 and MixedModels.jl and the answer is....

it's not going to be supported in any mainstream release of either package in the foreseeable future.

You can however still get some of these structures by clever specification of the random effects.

For example:

data(Machines,package="nlme")
library(lme4)

m <- lmer(score ~ 1 + Machine + (0+Machine|Worker), Machines)

# with compound symmetry
m_cs <- lmer(score ~ 1 + Machine + (1|Worker) + (1|Worker:Machine),
Machines)

# pdDiag -- for continuous variables, you could just use the || syntax

m_diag <- lmer(score ~ 1 + Machine + (0+dummy(Machine,"A")|Worker) +
(0+dummy(Machine,"B")|Worker) + (0+dummy(Machine,"C")|Worker), Machines)

I'll leave pdIdent as an exercise for the OP. ;)

Best,
Phillip

On 02/10/2019 15:50, matthias.suter at agroscope.admin.ch wrote:
> Hi all
> 
> I'm looking for a way to specify a more complex variance-covariance matrix for the random effects in lmer(). For example, in lme() (nlme package), there are the pdMat classes to specify e.g. a compound symmetry (pdCompSym) or a multiple of an identity (pdIdent) structure for the variance-covariance matrix of random effects. Is there a possibility to code an equivalent for lmer()? I'm specifically interested in "compound symmetry" and "multiple of an identity".
> 
> I assume that Douglas Bates or Ben Bolker have a distinct answer on that.
> 
> Thanks in advance,
> Matthias
> 
> 
> ---------------------------------------------------------
> Matthias Suter, Dr.sc.nat.
> Forage Production and Grassland Systems
> 
> Agroscope
> Reckenholzstrasse 191, CH-8046 Z rich
> 
> Phone +41 58 468 75 90
> Fax      +41 58 468 72 01
> matthias.suter at agroscope.admin.ch
> www.agroscope.ch
> ---------------------------------------------------------
> 
> 
> 	[[alternative HTML version deleted]]
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

From ph||||p@@|d@y @end|ng |rom mp|@n|  Thu Oct  3 09:45:46 2019
From: ph||||p@@|d@y @end|ng |rom mp|@n| (Phillip Alday)
Date: Thu, 3 Oct 2019 09:45:46 +0200
Subject: [R-sig-ME] Random-effects variance-covariance matrix in lmer?
In-Reply-To: <af651b34901943fb9ed03301057d368d@agroscope.admin.ch>
References: <83e615e4412d405db0d32a139828388c@agroscope.admin.ch>
 <524786bd-0926-20f9-53bf-b5e9281cfaa3@mpi.nl>
 <af651b34901943fb9ed03301057d368d@agroscope.admin.ch>
Message-ID: <cdc98bd3-4c72-ab06-e0e1-4a5bb0dbb880@mpi.nl>

On 02/10/2019 16:52, matthias.suter at agroscope.admin.ch wrote:
> Thanks, Philipp.
> 
> I was a aware of the pdDiag and the pdCorSym solution, and so I specifically asked for pdCompSym and pdIdent ...
> 
> As for your compound symmetry suggestion, it is not quite clear to me. Up to now, I would have named "(1|Worker:Machine)" a random interaction term, specifying a distinct level for each worker*machine combination (and that's what is given by ranef(m_cs). How does this relate to the covariance in the compound symmetry, where also a multiple of identity is fit to diagonal?

I stole this example from an old presentation of Doug Bates:

http://pages.stat.wisc.edu/~bates/UseR2008/WorkshopD.pdf

This is one of those things that my uni math instructors used to say
"Convince yourself this is true". I hated it at the time, but I don't
have the time to think about how to articulate this better than
"thinking about what is being allowed in terms of geometry". Sorry. :(

> 
> I have also tried to sort out the pdIdent equivalent, using similar coding as you suggest below, but was not successful so far. Do you know a similar solution?

I don't off the top of my head. pdIdent really isn't relevant to my day
job so I don't think about it much. I think it might be relatively
straightforward to do in MixedModels.jl via something similar to the new
zerocorr! function in the dev version, but it's not a priority for me.
Pull-requests always welcome. (Slightly higher but still not terribly so
on my priority list is documenting the internal fields of ReMat
structure to make the logic of such modifications somewhat more obvious.)

Phillip

> Thanks again,
> Matthias 
> 
> 
> 
> 
> -----Urspr?ngliche Nachricht-----
> Von: Phillip Alday <phillip.alday at mpi.nl> 
> Gesendet: Mittwoch, 2. Oktober 2019 16:30
> An: Suter Matthias Agroscope <matthias.suter at agroscope.admin.ch>; r-sig-mixed-models at r-project.org
> Betreff: Re: [R-sig-ME] Random-effects variance-covariance matrix in lmer?
> 
> This is a frequent question for lme4 and MixedModels.jl and the answer is....
> 
> it's not going to be supported in any mainstream release of either package in the foreseeable future.
> 
> You can however still get some of these structures by clever specification of the random effects.
> 
> For example:
> 
> data(Machines,package="nlme")
> library(lme4)
> 
> m <- lmer(score ~ 1 + Machine + (0+Machine|Worker), Machines)
> 
> # with compound symmetry
> m_cs <- lmer(score ~ 1 + Machine + (1|Worker) + (1|Worker:Machine),
> Machines)
> 
> # pdDiag -- for continuous variables, you could just use the || syntax
> 
> m_diag <- lmer(score ~ 1 + Machine + (0+dummy(Machine,"A")|Worker) +
> (0+dummy(Machine,"B")|Worker) + (0+dummy(Machine,"C")|Worker), Machines)
> 
> I'll leave pdIdent as an exercise for the OP. ;)
> 
> Best,
> Phillip
> 
> On 02/10/2019 15:50, matthias.suter at agroscope.admin.ch wrote:
>> Hi all
>>
>> I'm looking for a way to specify a more complex variance-covariance matrix for the random effects in lmer(). For example, in lme() (nlme package), there are the pdMat classes to specify e.g. a compound symmetry (pdCompSym) or a multiple of an identity (pdIdent) structure for the variance-covariance matrix of random effects. Is there a possibility to code an equivalent for lmer()? I'm specifically interested in "compound symmetry" and "multiple of an identity".
>>
>> I assume that Douglas Bates or Ben Bolker have a distinct answer on that.
>>
>> Thanks in advance,
>> Matthias
>>
>>
>> ---------------------------------------------------------
>> Matthias Suter, Dr.sc.nat.
>> Forage Production and Grassland Systems
>>
>> Agroscope
>> Reckenholzstrasse 191, CH-8046 Z rich
>>
>> Phone +41 58 468 75 90
>> Fax      +41 58 468 72 01
>> matthias.suter at agroscope.admin.ch
>> www.agroscope.ch
>> ---------------------------------------------------------
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>


From |brom@no77 @end|ng |rom gm@||@com  Sat Oct  5 10:00:54 2019
From: |brom@no77 @end|ng |rom gm@||@com (Francesco Romano)
Date: Sat, 5 Oct 2019 10:00:54 +0200
Subject: [R-sig-ME] Help with determining effect sizes
Message-ID: <CABX-QoGmcSVwUwJeM-wuMKCT8YwBYxLA1A6JtqY+C6PXEOXLzw@mail.gmail.com>

Dear all,

A journal has asked that I determine the effect sizes for a series of
dummy-coded contrasts from the following ME model:

RT ~ Group * Grammaticality + (1 + Grammaticality | Participant) +
    (1 + Group | item)

Here RT is my continuous outcome variable measured in milliseconds, Group
is a factor with 3 levels (NS, L2, and HL), and Grammaticality a factor
with 2 levels (gr and ungr). After relevelling ?NOTE: I am deliberately
omitting the call for each new relevelled model here? I obtained a series
of contrasts which are tabulated below (not sure you can view this whole):


Reference level

Contrasts

Estimate

(ms)

Effect size

(Cohen?s *d*)

SE

df

*t*

*p*

HL

GR vs UNGR

 -213



89

72.13

-2.399

< .05*

L2

GR vs UNGR

 -408



90

74.18

-4.513

< .001***

L1

GR vs UNGR

-111



73

70.02

-1.520

> .05



HL > L2

 -25



191

43.48

-.135

> .05

GR

L1 > HL

 400



175

43.81

2.286

< .05*



L1 > L2

 374



179

43.59

2.092

< .05*



HL > L2

 -219



179

42.70

-1.226

> .05

UNGR

L1 > HL

 298



164

43

1.817

> .05



L1> L2

77



166

42.03

.469

> .05

How would I go about determining the Cohen's *d* for each of the contrasts?

The model call is:

Linear mixed model fit by REML. t-tests use Satterthwaite's method
['lmerModLmerTest']
Formula: RT ~ Group * Grammaticality + (1 + Grammaticality | Participant) +

    (1 + Group | item)
   Data: RTanalysis

REML criterion at convergence: 52800

Scaled residuals:
    Min      1Q  Median      3Q     Max
-2.1696 -0.6536 -0.1654  0.5060  5.0134

Random effects:
 Groups      Name               Variance Std.Dev. Corr
 item        (Intercept)         71442   267.29
             GroupL2              1144    33.82    0.80
             GroupNS              9951    99.76   -0.43 -0.88
 Participant (Intercept)        235216   484.99
             Grammaticalityungr  50740   225.25   -0.39
 Residual                       378074   614.88
Number of obs: 3342, groups:  item, 144; Participant, 46

Fixed effects:
                           Estimate Std. Error      df t value Pr(>|t|)
(Intercept)                 2801.98     136.70   48.85  20.498   <2e-16 ***
GroupL2                      -25.86     191.20   43.48  -0.135   0.8931
GroupNS                     -400.63     175.22   43.81  -2.286   0.0271 *
Grammaticalityungr          -213.87      89.17   72.13  -2.399   0.0190 *
GroupL2:Grammaticalityungr  -194.57     107.25   42.55  -1.814   0.0767 .
GroupNS:Grammaticalityungr   102.31      99.39   43.45   1.029   0.3090
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
            (Intr) GropL2 GropNS Grmmtc GrL2:G
GroupL2     -0.672
GroupNS     -0.744  0.526
Grmmtcltyng -0.404  0.222  0.260
GrpL2:Grmmt  0.259 -0.391 -0.205 -0.589
GrpNS:Grmmt  0.299 -0.202 -0.392 -0.702  0.540
convergence code: 0
Model failed to converge with max|grad| = 0.0477764 (tol = 0.002, component
1)

The distribution of the outcome is fairly normal and the overall mean,
without considering the two fixed effects, is very close to the means of
each of the three groups (without considering the effect of Grammaticality)
as well as the means of the two levels of grammaticality (without
considering the effect of group).

The package simR can simulate data to determine power, amongst other things,
but I am not sure how to do this for models with interactions such as mine.

Use of simR is recommended in Brysbaert and Stevens (2018)
https://www.journalofcognition.org/articles/10.5334/joc.10/. Perhaps there
is a simpler way of extracting *d *from the stats I already know?

Any help would be greatly appreciated,

Francesco

	[[alternative HTML version deleted]]


From M@@rten@Jung @end|ng |rom m@||box@tu-dre@den@de  Sat Oct  5 12:13:35 2019
From: M@@rten@Jung @end|ng |rom m@||box@tu-dre@den@de (Maarten Jung)
Date: Sat, 5 Oct 2019 12:13:35 +0200
Subject: [R-sig-ME] Help with determining effect sizes
In-Reply-To: <75802c862c7c4c3faeacf8ce786a48f2@MSX-L104.msx.ad.zih.tu-dresden.de>
References: <75802c862c7c4c3faeacf8ce786a48f2@MSX-L104.msx.ad.zih.tu-dresden.de>
Message-ID: <CAHr4DyfwG=buarX37H1jULhtPex7zHyptDt-g-NWjsXPP36hGQ@mail.gmail.com>

Dear Francesco,

I don't think there is a "standard" way to calculate effect sizes for
linear mixed models due to the way the variance is partitioned (see
e.g. [1]).
One way to compute something similar to Cohen's d would be to divide
the difference between the estimated means of two conditions by a
rough estimate of the standard deviation of the response variable
which you can get by
sd(predict(your_model_name))

Best,
Maarten

[1] https://afex.singmann.science/forums/topic/compute-effect-sizes-for-mixed-objects#post-295


On Sat, Oct 5, 2019 at 10:01 AM Francesco Romano <fbromano77 at gmail.com> wrote:
>
> Dear all,
>
> A journal has asked that I determine the effect sizes for a series of
> dummy-coded contrasts from the following ME model:
>
> RT ~ Group * Grammaticality + (1 + Grammaticality | Participant) +
>     (1 + Group | item)
>
> Here RT is my continuous outcome variable measured in milliseconds, Group
> is a factor with 3 levels (NS, L2, and HL), and Grammaticality a factor
> with 2 levels (gr and ungr). After relevelling ?NOTE: I am deliberately
> omitting the call for each new relevelled model here? I obtained a series
> of contrasts which are tabulated below (not sure you can view this whole):
>
>
> Reference level
>
> Contrasts
>
> Estimate
>
> (ms)
>
> Effect size
>
> (Cohen?s *d*)
>
> SE
>
> df
>
> *t*
>
> *p*
>
> HL
>
> GR vs UNGR
>
>  -213
>
>
>
> 89
>
> 72.13
>
> -2.399
>
> < .05*
>
> L2
>
> GR vs UNGR
>
>  -408
>
>
>
> 90
>
> 74.18
>
> -4.513
>
> < .001***
>
> L1
>
> GR vs UNGR
>
> -111
>
>
>
> 73
>
> 70.02
>
> -1.520
>
> > .05
>
>
>
> HL > L2
>
>  -25
>
>
>
> 191
>
> 43.48
>
> -.135
>
> > .05
>
> GR
>
> L1 > HL
>
>  400
>
>
>
> 175
>
> 43.81
>
> 2.286
>
> < .05*
>
>
>
> L1 > L2
>
>  374
>
>
>
> 179
>
> 43.59
>
> 2.092
>
> < .05*
>
>
>
> HL > L2
>
>  -219
>
>
>
> 179
>
> 42.70
>
> -1.226
>
> > .05
>
> UNGR
>
> L1 > HL
>
>  298
>
>
>
> 164
>
> 43
>
> 1.817
>
> > .05
>
>
>
> L1> L2
>
> 77
>
>
>
> 166
>
> 42.03
>
> .469
>
> > .05
>
> How would I go about determining the Cohen's *d* for each of the contrasts?
>
> The model call is:
>
> Linear mixed model fit by REML. t-tests use Satterthwaite's method
> ['lmerModLmerTest']
> Formula: RT ~ Group * Grammaticality + (1 + Grammaticality | Participant) +
>
>     (1 + Group | item)
>    Data: RTanalysis
>
> REML criterion at convergence: 52800
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -2.1696 -0.6536 -0.1654  0.5060  5.0134
>
> Random effects:
>  Groups      Name               Variance Std.Dev. Corr
>  item        (Intercept)         71442   267.29
>              GroupL2              1144    33.82    0.80
>              GroupNS              9951    99.76   -0.43 -0.88
>  Participant (Intercept)        235216   484.99
>              Grammaticalityungr  50740   225.25   -0.39
>  Residual                       378074   614.88
> Number of obs: 3342, groups:  item, 144; Participant, 46
>
> Fixed effects:
>                            Estimate Std. Error      df t value Pr(>|t|)
> (Intercept)                 2801.98     136.70   48.85  20.498   <2e-16 ***
> GroupL2                      -25.86     191.20   43.48  -0.135   0.8931
> GroupNS                     -400.63     175.22   43.81  -2.286   0.0271 *
> Grammaticalityungr          -213.87      89.17   72.13  -2.399   0.0190 *
> GroupL2:Grammaticalityungr  -194.57     107.25   42.55  -1.814   0.0767 .
> GroupNS:Grammaticalityungr   102.31      99.39   43.45   1.029   0.3090
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>             (Intr) GropL2 GropNS Grmmtc GrL2:G
> GroupL2     -0.672
> GroupNS     -0.744  0.526
> Grmmtcltyng -0.404  0.222  0.260
> GrpL2:Grmmt  0.259 -0.391 -0.205 -0.589
> GrpNS:Grmmt  0.299 -0.202 -0.392 -0.702  0.540
> convergence code: 0
> Model failed to converge with max|grad| = 0.0477764 (tol = 0.002, component
> 1)
>
> The distribution of the outcome is fairly normal and the overall mean,
> without considering the two fixed effects, is very close to the means of
> each of the three groups (without considering the effect of Grammaticality)
> as well as the means of the two levels of grammaticality (without
> considering the effect of group).
>
> The package simR can simulate data to determine power, amongst other things,
> but I am not sure how to do this for models with interactions such as mine.
>
> Use of simR is recommended in Brysbaert and Stevens (2018)
> https://www.journalofcognition.org/articles/10.5334/joc.10/. Perhaps there
> is a simpler way of extracting *d *from the stats I already know?
>
> Any help would be greatly appreciated,
>
> Francesco
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From j|@ver|@@|mo @end|ng |rom gm@||@com  Sat Oct  5 13:08:09 2019
From: j|@ver|@@|mo @end|ng |rom gm@||@com (=?ISO-8859-1?Q?Jo=E3o_Ver=EDssimo?=)
Date: Sat, 05 Oct 2019 13:08:09 +0200
Subject: [R-sig-ME] Help with determining effect sizes
In-Reply-To: <CAHr4DyfwG=buarX37H1jULhtPex7zHyptDt-g-NWjsXPP36hGQ@mail.gmail.com>
References: <75802c862c7c4c3faeacf8ce786a48f2@MSX-L104.msx.ad.zih.tu-dresden.de>
 <CAHr4DyfwG=buarX37H1jULhtPex7zHyptDt-g-NWjsXPP36hGQ@mail.gmail.com>
Message-ID: <dde0e6e8f528e769d173df78cf113b06789684b4.camel@gmail.com>

See the web app by Jake Westfall:
https://jakewestfall.shinyapps.io/crossedpower/

And their JEP:General paper:
http://doi.org/10.1037/xge0000014

If I'm not mistaken, you would standardise the estimates of differences
by the sum of all variances (random intercepts and slopes + residual),
but you'll need to make sure that's the right formula (given your
desgin).

Jo?o

On Sat, 2019-10-05 at 12:13 +0200, Maarten Jung wrote:
> Dear Francesco,
> 
> I don't think there is a "standard" way to calculate effect sizes for
> linear mixed models due to the way the variance is partitioned (see
> e.g. [1]).
> One way to compute something similar to Cohen's d would be to divide
> the difference between the estimated means of two conditions by a
> rough estimate of the standard deviation of the response variable
> which you can get by
> sd(predict(your_model_name))
> 
> Best,
> Maarten
> 
> [1] 
> https://afex.singmann.science/forums/topic/compute-effect-sizes-for-mixed-objects#post-295
> 
> 
> On Sat, Oct 5, 2019 at 10:01 AM Francesco Romano <
> fbromano77 at gmail.com> wrote:
> > 
> > Dear all,
> > 
> > A journal has asked that I determine the effect sizes for a series
> > of
> > dummy-coded contrasts from the following ME model:
> > 
> > RT ~ Group * Grammaticality + (1 + Grammaticality | Participant) +
> >     (1 + Group | item)
> > 
> > Here RT is my continuous outcome variable measured in milliseconds,
> > Group
> > is a factor with 3 levels (NS, L2, and HL), and Grammaticality a
> > factor
> > with 2 levels (gr and ungr). After relevelling ?NOTE: I am
> > deliberately
> > omitting the call for each new relevelled model here? I obtained a
> > series
> > of contrasts which are tabulated below (not sure you can view this
> > whole):
> > 
> > 
> > Reference level
> > 
> > Contrasts
> > 
> > Estimate
> > 
> > (ms)
> > 
> > Effect size
> > 
> > (Cohen?s *d*)
> > 
> > SE
> > 
> > df
> > 
> > *t*
> > 
> > *p*
> > 
> > HL
> > 
> > GR vs UNGR
> > 
> >  -213
> > 
> > 
> > 
> > 89
> > 
> > 72.13
> > 
> > -2.399
> > 
> > < .05*
> > 
> > L2
> > 
> > GR vs UNGR
> > 
> >  -408
> > 
> > 
> > 
> > 90
> > 
> > 74.18
> > 
> > -4.513
> > 
> > < .001***
> > 
> > L1
> > 
> > GR vs UNGR
> > 
> > -111
> > 
> > 
> > 
> > 73
> > 
> > 70.02
> > 
> > -1.520
> > 
> > > .05
> > 
> > 
> > 
> > HL > L2
> > 
> >  -25
> > 
> > 
> > 
> > 191
> > 
> > 43.48
> > 
> > -.135
> > 
> > > .05
> > 
> > GR
> > 
> > L1 > HL
> > 
> >  400
> > 
> > 
> > 
> > 175
> > 
> > 43.81
> > 
> > 2.286
> > 
> > < .05*
> > 
> > 
> > 
> > L1 > L2
> > 
> >  374
> > 
> > 
> > 
> > 179
> > 
> > 43.59
> > 
> > 2.092
> > 
> > < .05*
> > 
> > 
> > 
> > HL > L2
> > 
> >  -219
> > 
> > 
> > 
> > 179
> > 
> > 42.70
> > 
> > -1.226
> > 
> > > .05
> > 
> > UNGR
> > 
> > L1 > HL
> > 
> >  298
> > 
> > 
> > 
> > 164
> > 
> > 43
> > 
> > 1.817
> > 
> > > .05
> > 
> > 
> > 
> > L1> L2
> > 
> > 77
> > 
> > 
> > 
> > 166
> > 
> > 42.03
> > 
> > .469
> > 
> > > .05
> > 
> > How would I go about determining the Cohen's *d* for each of the
> > contrasts?
> > 
> > The model call is:
> > 
> > Linear mixed model fit by REML. t-tests use Satterthwaite's method
> > ['lmerModLmerTest']
> > Formula: RT ~ Group * Grammaticality + (1 + Grammaticality |
> > Participant) +
> > 
> >     (1 + Group | item)
> >    Data: RTanalysis
> > 
> > REML criterion at convergence: 52800
> > 
> > Scaled residuals:
> >     Min      1Q  Median      3Q     Max
> > -2.1696 -0.6536 -0.1654  0.5060  5.0134
> > 
> > Random effects:
> >  Groups      Name               Variance Std.Dev. Corr
> >  item        (Intercept)         71442   267.29
> >              GroupL2              1144    33.82    0.80
> >              GroupNS              9951    99.76   -0.43 -0.88
> >  Participant (Intercept)        235216   484.99
> >              Grammaticalityungr  50740   225.25   -0.39
> >  Residual                       378074   614.88
> > Number of obs: 3342, groups:  item, 144; Participant, 46
> > 
> > Fixed effects:
> >                            Estimate Std. Error      df t value
> > Pr(>|t|)
> > (Intercept)                 2801.98     136.70   48.85  20.498   <2
> > e-16 ***
> > GroupL2                      -25.86     191.20   43.48  -
> > 0.135   0.8931
> > GroupNS                     -400.63     175.22   43.81  -
> > 2.286   0.0271 *
> > Grammaticalityungr          -213.87      89.17   72.13  -
> > 2.399   0.0190 *
> > GroupL2:Grammaticalityungr  -194.57     107.25   42.55  -
> > 1.814   0.0767 .
> > GroupNS:Grammaticalityungr   102.31      99.39   43.45   1.029   0.
> > 3090
> > ---
> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> > 
> > Correlation of Fixed Effects:
> >             (Intr) GropL2 GropNS Grmmtc GrL2:G
> > GroupL2     -0.672
> > GroupNS     -0.744  0.526
> > Grmmtcltyng -0.404  0.222  0.260
> > GrpL2:Grmmt  0.259 -0.391 -0.205 -0.589
> > GrpNS:Grmmt  0.299 -0.202 -0.392 -0.702  0.540
> > convergence code: 0
> > Model failed to converge with max|grad| = 0.0477764 (tol = 0.002,
> > component
> > 1)
> > 
> > The distribution of the outcome is fairly normal and the overall
> > mean,
> > without considering the two fixed effects, is very close to the
> > means of
> > each of the three groups (without considering the effect of
> > Grammaticality)
> > as well as the means of the two levels of grammaticality (without
> > considering the effect of group).
> > 
> > The package simR can simulate data to determine power, amongst
> > other things,
> > but I am not sure how to do this for models with interactions such
> > as mine.
> > 
> > Use of simR is recommended in Brysbaert and Stevens (2018)
> > https://www.journalofcognition.org/articles/10.5334/joc.10/.
> > Perhaps there
> > is a simpler way of extracting *d *from the stats I already know?
> > 
> > Any help would be greatly appreciated,
> > 
> > Francesco
> > 
> >         [[alternative HTML version deleted]]
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From M@@rten@Jung @end|ng |rom m@||box@tu-dre@den@de  Sat Oct  5 14:10:26 2019
From: M@@rten@Jung @end|ng |rom m@||box@tu-dre@den@de (Maarten Jung)
Date: Sat, 5 Oct 2019 14:10:26 +0200
Subject: [R-sig-ME] Help with determining effect sizes
In-Reply-To: <dde0e6e8f528e769d173df78cf113b06789684b4.camel@gmail.com>
References: <75802c862c7c4c3faeacf8ce786a48f2@MSX-L104.msx.ad.zih.tu-dresden.de>
 <CAHr4DyfwG=buarX37H1jULhtPex7zHyptDt-g-NWjsXPP36hGQ@mail.gmail.com>
 <dde0e6e8f528e769d173df78cf113b06789684b4.camel@gmail.com>
Message-ID: <CAHr4Dyd+4=CV+jnigtDVVm7KGwQk9pCAAsGnXOiOjfiOaTGyig@mail.gmail.com>

As far as I remember, the formulas in Westfall, Kenny, and Judd (2014) (and
thus probably the calculations in the web app) are based on models with
contrast-coded predictors only.

Best, Maarten

On Sat, 5 Oct 2019, 13:10 Jo?o Ver?ssimo <jl.verissimo at gmail.com> wrote:

> See the web app by Jake Westfall:
> https://jakewestfall.shinyapps.io/crossedpower/
>
> And their JEP:General paper:
> http://doi.org/10.1037/xge0000014
>
> If I'm not mistaken, you would standardise the estimates of differences
> by the sum of all variances (random intercepts and slopes + residual),
> but you'll need to make sure that's the right formula (given your
> desgin).
>
> Jo?o
>
> On Sat, 2019-10-05 at 12:13 +0200, Maarten Jung wrote:
> > Dear Francesco,
> >
> > I don't think there is a "standard" way to calculate effect sizes for
> > linear mixed models due to the way the variance is partitioned (see
> > e.g. [1]).
> > One way to compute something similar to Cohen's d would be to divide
> > the difference between the estimated means of two conditions by a
> > rough estimate of the standard deviation of the response variable
> > which you can get by
> > sd(predict(your_model_name))
> >
> > Best,
> > Maarten
> >
> > [1]
> >
> https://afex.singmann.science/forums/topic/compute-effect-sizes-for-mixed-objects#post-295
> >
> >
> > On Sat, Oct 5, 2019 at 10:01 AM Francesco Romano <
> > fbromano77 at gmail.com> wrote:
> > >
> > > Dear all,
> > >
> > > A journal has asked that I determine the effect sizes for a series
> > > of
> > > dummy-coded contrasts from the following ME model:
> > >
> > > RT ~ Group * Grammaticality + (1 + Grammaticality | Participant) +
> > >     (1 + Group | item)
> > >
> > > Here RT is my continuous outcome variable measured in milliseconds,
> > > Group
> > > is a factor with 3 levels (NS, L2, and HL), and Grammaticality a
> > > factor
> > > with 2 levels (gr and ungr). After relevelling ?NOTE: I am
> > > deliberately
> > > omitting the call for each new relevelled model here? I obtained a
> > > series
> > > of contrasts which are tabulated below (not sure you can view this
> > > whole):
> > >
> > >
> > > Reference level
> > >
> > > Contrasts
> > >
> > > Estimate
> > >
> > > (ms)
> > >
> > > Effect size
> > >
> > > (Cohen?s *d*)
> > >
> > > SE
> > >
> > > df
> > >
> > > *t*
> > >
> > > *p*
> > >
> > > HL
> > >
> > > GR vs UNGR
> > >
> > >  -213
> > >
> > >
> > >
> > > 89
> > >
> > > 72.13
> > >
> > > -2.399
> > >
> > > < .05*
> > >
> > > L2
> > >
> > > GR vs UNGR
> > >
> > >  -408
> > >
> > >
> > >
> > > 90
> > >
> > > 74.18
> > >
> > > -4.513
> > >
> > > < .001***
> > >
> > > L1
> > >
> > > GR vs UNGR
> > >
> > > -111
> > >
> > >
> > >
> > > 73
> > >
> > > 70.02
> > >
> > > -1.520
> > >
> > > > .05
> > >
> > >
> > >
> > > HL > L2
> > >
> > >  -25
> > >
> > >
> > >
> > > 191
> > >
> > > 43.48
> > >
> > > -.135
> > >
> > > > .05
> > >
> > > GR
> > >
> > > L1 > HL
> > >
> > >  400
> > >
> > >
> > >
> > > 175
> > >
> > > 43.81
> > >
> > > 2.286
> > >
> > > < .05*
> > >
> > >
> > >
> > > L1 > L2
> > >
> > >  374
> > >
> > >
> > >
> > > 179
> > >
> > > 43.59
> > >
> > > 2.092
> > >
> > > < .05*
> > >
> > >
> > >
> > > HL > L2
> > >
> > >  -219
> > >
> > >
> > >
> > > 179
> > >
> > > 42.70
> > >
> > > -1.226
> > >
> > > > .05
> > >
> > > UNGR
> > >
> > > L1 > HL
> > >
> > >  298
> > >
> > >
> > >
> > > 164
> > >
> > > 43
> > >
> > > 1.817
> > >
> > > > .05
> > >
> > >
> > >
> > > L1> L2
> > >
> > > 77
> > >
> > >
> > >
> > > 166
> > >
> > > 42.03
> > >
> > > .469
> > >
> > > > .05
> > >
> > > How would I go about determining the Cohen's *d* for each of the
> > > contrasts?
> > >
> > > The model call is:
> > >
> > > Linear mixed model fit by REML. t-tests use Satterthwaite's method
> > > ['lmerModLmerTest']
> > > Formula: RT ~ Group * Grammaticality + (1 + Grammaticality |
> > > Participant) +
> > >
> > >     (1 + Group | item)
> > >    Data: RTanalysis
> > >
> > > REML criterion at convergence: 52800
> > >
> > > Scaled residuals:
> > >     Min      1Q  Median      3Q     Max
> > > -2.1696 -0.6536 -0.1654  0.5060  5.0134
> > >
> > > Random effects:
> > >  Groups      Name               Variance Std.Dev. Corr
> > >  item        (Intercept)         71442   267.29
> > >              GroupL2              1144    33.82    0.80
> > >              GroupNS              9951    99.76   -0.43 -0.88
> > >  Participant (Intercept)        235216   484.99
> > >              Grammaticalityungr  50740   225.25   -0.39
> > >  Residual                       378074   614.88
> > > Number of obs: 3342, groups:  item, 144; Participant, 46
> > >
> > > Fixed effects:
> > >                            Estimate Std. Error      df t value
> > > Pr(>|t|)
> > > (Intercept)                 2801.98     136.70   48.85  20.498   <2
> > > e-16 ***
> > > GroupL2                      -25.86     191.20   43.48  -
> > > 0.135   0.8931
> > > GroupNS                     -400.63     175.22   43.81  -
> > > 2.286   0.0271 *
> > > Grammaticalityungr          -213.87      89.17   72.13  -
> > > 2.399   0.0190 *
> > > GroupL2:Grammaticalityungr  -194.57     107.25   42.55  -
> > > 1.814   0.0767 .
> > > GroupNS:Grammaticalityungr   102.31      99.39   43.45   1.029   0.
> > > 3090
> > > ---
> > > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> > >
> > > Correlation of Fixed Effects:
> > >             (Intr) GropL2 GropNS Grmmtc GrL2:G
> > > GroupL2     -0.672
> > > GroupNS     -0.744  0.526
> > > Grmmtcltyng -0.404  0.222  0.260
> > > GrpL2:Grmmt  0.259 -0.391 -0.205 -0.589
> > > GrpNS:Grmmt  0.299 -0.202 -0.392 -0.702  0.540
> > > convergence code: 0
> > > Model failed to converge with max|grad| = 0.0477764 (tol = 0.002,
> > > component
> > > 1)
> > >
> > > The distribution of the outcome is fairly normal and the overall
> > > mean,
> > > without considering the two fixed effects, is very close to the
> > > means of
> > > each of the three groups (without considering the effect of
> > > Grammaticality)
> > > as well as the means of the two levels of grammaticality (without
> > > considering the effect of group).
> > >
> > > The package simR can simulate data to determine power, amongst
> > > other things,
> > > but I am not sure how to do this for models with interactions such
> > > as mine.
> > >
> > > Use of simR is recommended in Brysbaert and Stevens (2018)
> > > https://www.journalofcognition.org/articles/10.5334/joc.10/.
> > > Perhaps there
> > > is a simpler way of extracting *d *from the stats I already know?
> > >
> > > Any help would be greatly appreciated,
> > >
> > > Francesco
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From M@@rten@Jung @end|ng |rom m@||box@tu-dre@den@de  Sat Oct  5 21:57:37 2019
From: M@@rten@Jung @end|ng |rom m@||box@tu-dre@den@de (Maarten Jung)
Date: Sat, 5 Oct 2019 21:57:37 +0200
Subject: [R-sig-ME] Help with determining effect sizes
In-Reply-To: <52823a41761141dba3d53f96d61a6464@MSX-L104.msx.ad.zih.tu-dresden.de>
References: <75802c862c7c4c3faeacf8ce786a48f2@MSX-L104.msx.ad.zih.tu-dresden.de>
 <CAHr4DyfwG=buarX37H1jULhtPex7zHyptDt-g-NWjsXPP36hGQ@mail.gmail.com>
 <52823a41761141dba3d53f96d61a6464@MSX-L104.msx.ad.zih.tu-dresden.de>
Message-ID: <CAHr4Dyc4Xkwu_TqnBpBLN0DhdU9oH6cWKTUp4do=zNVfKeMFAQ@mail.gmail.com>

Hi Francesco,

You already got the unstandardized effect sizes - these simply are the
estimated reaction time differences ("Contrasts Estimate (ms)" in your
table).
If you standardize these differences by dividing by a measure of variation,
e.g. an estimate of the standard deviation of your response variable, you
get so called standardized effect sizes. I guess the latter is what your
reviewer is looking for but (as also mentioned in [1]) one can argue that
this standardization has its own pitfalls.

Best,
Maarten

On Sat, 5 Oct 2019, 21:05 Francesco Romano <fbromano77 at gmail.com> wrote:

> Hi Maarten,
>
> Thank you so much for your suggestions. In the source that you
> recommended, a paper is mentioned that advises reporting unstandardised
> effect sizes but I?m not sure how to do that. Is it the same as the
> division you explained in your message? If so, how would I obtain the
> estimated means for the specific contrasts in my table?
>
> Francesco
>
> On Sat, Oct 5, 2019 at 12:13 PM Maarten Jung <
> Maarten.Jung at mailbox.tu-dresden.de> wrote:
>
>> Dear Francesco,
>>
>> I don't think there is a "standard" way to calculate effect sizes for
>> linear mixed models due to the way the variance is partitioned (see
>> e.g. [1]).
>> One way to compute something similar to Cohen's d would be to divide
>> the difference between the estimated means of two conditions by a
>> rough estimate of the standard deviation of the response variable
>> which you can get by
>> sd(predict(your_model_name))
>>
>> Best,
>> Maarten
>>
>> [1]
>> https://afex.singmann.science/forums/topic/compute-effect-sizes-for-mixed-objects#post-295
>>
>>
>> On Sat, Oct 5, 2019 at 10:01 AM Francesco Romano <fbromano77 at gmail.com>
>> wrote:
>> >
>> > Dear all,
>> >
>> > A journal has asked that I determine the effect sizes for a series of
>> > dummy-coded contrasts from the following ME model:
>> >
>> > RT ~ Group * Grammaticality + (1 + Grammaticality | Participant) +
>> >     (1 + Group | item)
>> >
>> > Here RT is my continuous outcome variable measured in milliseconds,
>> Group
>> > is a factor with 3 levels (NS, L2, and HL), and Grammaticality a factor
>> > with 2 levels (gr and ungr). After relevelling ?NOTE: I am deliberately
>> > omitting the call for each new relevelled model here? I obtained a
>> series
>> > of contrasts which are tabulated below (not sure you can view this
>> whole):
>> >
>> >
>> > Reference level
>> >
>> > Contrasts
>> >
>> > Estimate
>> >
>> > (ms)
>> >
>> > Effect size
>> >
>> > (Cohen?s *d*)
>> >
>> > SE
>> >
>> > df
>> >
>> > *t*
>> >
>> > *p*
>> >
>> > HL
>> >
>> > GR vs UNGR
>> >
>> >  -213
>> >
>> >
>> >
>> > 89
>> >
>> > 72.13
>> >
>> > -2.399
>> >
>> > < .05*
>> >
>> > L2
>> >
>> > GR vs UNGR
>> >
>> >  -408
>> >
>> >
>> >
>> > 90
>> >
>> > 74.18
>> >
>> > -4.513
>> >
>> > < .001***
>> >
>> > L1
>> >
>> > GR vs UNGR
>> >
>> > -111
>> >
>> >
>> >
>> > 73
>> >
>> > 70.02
>> >
>> > -1.520
>> >
>> > > .05
>> >
>> >
>> >
>> > HL > L2
>> >
>> >  -25
>> >
>> >
>> >
>> > 191
>> >
>> > 43.48
>> >
>> > -.135
>> >
>> > > .05
>> >
>> > GR
>> >
>> > L1 > HL
>> >
>> >  400
>> >
>> >
>> >
>> > 175
>> >
>> > 43.81
>> >
>> > 2.286
>> >
>> > < .05*
>> >
>> >
>> >
>> > L1 > L2
>> >
>> >  374
>> >
>> >
>> >
>> > 179
>> >
>> > 43.59
>> >
>> > 2.092
>> >
>> > < .05*
>> >
>> >
>> >
>> > HL > L2
>> >
>> >  -219
>> >
>> >
>> >
>> > 179
>> >
>> > 42.70
>> >
>> > -1.226
>> >
>> > > .05
>> >
>> > UNGR
>> >
>> > L1 > HL
>> >
>> >  298
>> >
>> >
>> >
>> > 164
>> >
>> > 43
>> >
>> > 1.817
>> >
>> > > .05
>> >
>> >
>> >
>> > L1> L2
>> >
>> > 77
>> >
>> >
>> >
>> > 166
>> >
>> > 42.03
>> >
>> > .469
>> >
>> > > .05
>> >
>> > How would I go about determining the Cohen's *d* for each of the
>> contrasts?
>> >
>> > The model call is:
>> >
>> > Linear mixed model fit by REML. t-tests use Satterthwaite's method
>> > ['lmerModLmerTest']
>> > Formula: RT ~ Group * Grammaticality + (1 + Grammaticality |
>> Participant) +
>> >
>> >     (1 + Group | item)
>> >    Data: RTanalysis
>> >
>> > REML criterion at convergence: 52800
>> >
>> > Scaled residuals:
>> >     Min      1Q  Median      3Q     Max
>> > -2.1696 -0.6536 -0.1654  0.5060  5.0134
>> >
>> > Random effects:
>> >  Groups      Name               Variance Std.Dev. Corr
>> >  item        (Intercept)         71442   267.29
>> >              GroupL2              1144    33.82    0.80
>> >              GroupNS              9951    99.76   -0.43 -0.88
>> >  Participant (Intercept)        235216   484.99
>> >              Grammaticalityungr  50740   225.25   -0.39
>> >  Residual                       378074   614.88
>> > Number of obs: 3342, groups:  item, 144; Participant, 46
>> >
>> > Fixed effects:
>> >                            Estimate Std. Error      df t value Pr(>|t|)
>> > (Intercept)                 2801.98     136.70   48.85  20.498   <2e-16
>> ***
>> > GroupL2                      -25.86     191.20   43.48  -0.135   0.8931
>> > GroupNS                     -400.63     175.22   43.81  -2.286   0.0271
>> *
>> > Grammaticalityungr          -213.87      89.17   72.13  -2.399   0.0190
>> *
>> > GroupL2:Grammaticalityungr  -194.57     107.25   42.55  -1.814   0.0767
>> .
>> > GroupNS:Grammaticalityungr   102.31      99.39   43.45   1.029   0.3090
>> > ---
>> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> >
>> > Correlation of Fixed Effects:
>> >             (Intr) GropL2 GropNS Grmmtc GrL2:G
>> > GroupL2     -0.672
>> > GroupNS     -0.744  0.526
>> > Grmmtcltyng -0.404  0.222  0.260
>> > GrpL2:Grmmt  0.259 -0.391 -0.205 -0.589
>> > GrpNS:Grmmt  0.299 -0.202 -0.392 -0.702  0.540
>> > convergence code: 0
>> > Model failed to converge with max|grad| = 0.0477764 (tol = 0.002,
>> component
>> > 1)
>> >
>> > The distribution of the outcome is fairly normal and the overall mean,
>> > without considering the two fixed effects, is very close to the means of
>> > each of the three groups (without considering the effect of
>> Grammaticality)
>> > as well as the means of the two levels of grammaticality (without
>> > considering the effect of group).
>> >
>> > The package simR can simulate data to determine power, amongst other
>> things,
>> > but I am not sure how to do this for models with interactions such as
>> mine.
>> >
>> > Use of simR is recommended in Brysbaert and Stevens (2018)
>> > https://www.journalofcognition.org/articles/10.5334/joc.10/. Perhaps
>> there
>> > is a simpler way of extracting *d *from the stats I already know?
>> >
>> > Any help would be greatly appreciated,
>> >
>> > Francesco
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> --
> Inviato da Gmail Mobile
>

	[[alternative HTML version deleted]]


From gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de  Mon Oct  7 19:12:22 2019
From: gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de (Gerrit Eichner)
Date: Mon, 7 Oct 2019 19:12:22 +0200
Subject: [R-sig-ME] 
 allFit fails after removing object with starting values
 for model parameters from workspace
In-Reply-To: <b20b92b4-0621-71f8-2008-354e4cb6ba56@math.uni-giessen.de>
References: <966f5f5a-5c3c-9edc-4b7b-b16f8f47e4d2@math.uni-giessen.de>
 <87d6a72d-ff55-45e1-c3b6-1cf815372078@gmail.com>
 <b20b92b4-0621-71f8-2008-354e4cb6ba56@math.uni-giessen.de>
Message-ID: <dac46509-6d60-ea60-f139-1732f88f6d97@math.uni-giessen.de>

Dear Ben and other lmer-experts,

if I extend my setting a little bit, a new/similar problem appears.
For some reasons I would like to change the control structures and
"hardwire" that as in:

lmerCtrl <- lmerControl(optCtrl = list(xtol_abs = 1e-9,
                                        ftol_abs = 1e-9))

theta <- c(1, 0.01, 0.2)
fm <- eval(bquote(
      lmer(Reaction ~ Days + (Days | Subject), data = sleepstudy,
           start = .(theta),
           control = .(lmerCtrl))  # THIS IS NEW.
  ))


Then allFit "goes on strike" again, now complaining about unused
arguments:

allFit(fm, verbose = FALSE)
Error in (function (optimizer = "nloptwrap", restart_edge = TRUE, 
boundary.tol = 1e-05,  :
   unused arguments (checkControl = list("ignore", "stop", "ignore", 
"stop", "stop", "message+drop.cols", "warning", "stop"), checkConv = 
list(list("warning", 0.002, NULL), list("message", 1e-04), 
list("warning", 1e-06)))


Any ideas how to circumvent this?

   Best regards  --  Gerrit

---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
http://www.uni-giessen.de/eichner
---------------------------------------------------------------------

Am 08.08.2019 um 15:41 schrieb Gerrit Eichner:
> Thx a lot, Ben, for the fast reply which clearly explains the
> cause of my problem. I've just found a solution which works for
> me (and which is not as simple as "don't delete theta" ;-) ):
> I "hardwire" theta's value into the function call:
> 
> theta <- c(1, 0.01, 0.2)
> fm <- eval(bquote(
>  ?? lmer(Reaction ~ Days + (Days | Subject), data = sleepstudy,
>  ??????? start = .(theta))
>  ?? ))
> 
> rm(theta)
> allFit(fm, verbose = FALSE)
> 
> 
> Works like a "charm", at least in my current workflow. :-)
> 
>  ?Thanks once more? --? Gerrit
> 
> ---------------------------------------------------------------------
> Dr. Gerrit Eichner?????????????????? Mathematical Institute, Room 212
> gerrit.eichner at math.uni-giessen.de?? Justus-Liebig-University Giessen
> Tel: +49-(0)641-99-32104????????? Arndtstr. 2, 35392 Giessen, Germany
> http://www.uni-giessen.de/eichner
> ---------------------------------------------------------------------
> 
> Am 08.08.2019 um 15:26 schrieb Ben Bolker:
>>
>> ?? This is not surprising, as allFit() uses update(), which tries to
>> re-evaluate the function ... at the very least allFit needs a
>> documentation update with that hint ... (I also notice at a glance that
>> the allFit docs seem to be incomplete anyway).
>>
>> ?? If you say more about your workflow we might be able to find a way to
>> help.? (If your workflow is this simple then the answer would be "well
>> then don't delete theta" ...)
>>
>> ?? cheers
>> ???? Ben Bolker
>>
>>
>> On 2019-08-08 9:06 a.m., Gerrit Eichner wrote:
>>> Dear lmer-experts,
>>>
>>> if I refit a fitted model with all available optimizers AFTER
>>> removing the object which contains the starting values for the
>>> parameters of the model as in
>>>
>>> theta <- c(1, 0.01, 0.2)
>>> fm <- lmer(Reaction ~ Days + (Days | Subject), data = sleepstudy,
>>> ??????????? start = theta)
>>> rm(theta)
>>> allFit(fm, verbose = FALSE)
>>>
>>> none of the optimizers succeeds:
>>>
>>> original model:
>>> Reaction ~ Days + (Days | Subject)
>>> optimizers (7): bobyqa, Nelder_Mead, nlminbwrap, nmkbw, optimx.L-BFGS-B,
>>> nloptwrap.NLOPT_LN_N...
>>> 7 optimizer(s) failed
>>> differences in negative log-likelihoods:
>>> max= -Inf ; std dev= NA
>>> Warning messages:
>>> 1: In min(nllvec) : no non-missing arguments to min; returning Inf
>>> 2: In max(nllvec - min(nllvec)) :
>>> ?? no non-missing arguments to max; returning -Inf
>>>
>>>
>>> If I don't remove theta from my workspace everything works fine.
>>> Is there a workaround for this - from my perspective - unwanted
>>> behaviour? (I have situations where allFit is used in a different
>>> environment from the one wherein the model was fit, e.g., after
>>> fitting the model the object which contains the fit is saved and
>>> later loaded in another R-session to be processed by allFit.)
>>> I could, of course, save theta everytime as well ... Any ideas?
>>>
>>> ??Best regards? --? Gerrit
>>>
>>> ---------------------------------------------------------------------
>>> Dr. Gerrit Eichner?????????????????? Mathematical Institute, Room 212
>>> gerrit.eichner at math.uni-giessen.de?? Justus-Liebig-University Giessen
>>> Tel: +49-(0)641-99-32104????????? Arndtstr. 2, 35392 Giessen, Germany
>>> http://www.uni-giessen.de/eichner
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbo|ker @end|ng |rom gm@||@com  Mon Oct  7 20:13:55 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 7 Oct 2019 14:13:55 -0400
Subject: [R-sig-ME] 
 allFit fails after removing object with starting values
 for model parameters from workspace
In-Reply-To: <dac46509-6d60-ea60-f139-1732f88f6d97@math.uni-giessen.de>
References: <966f5f5a-5c3c-9edc-4b7b-b16f8f47e4d2@math.uni-giessen.de>
 <87d6a72d-ff55-45e1-c3b6-1cf815372078@gmail.com>
 <b20b92b4-0621-71f8-2008-354e4cb6ba56@math.uni-giessen.de>
 <dac46509-6d60-ea60-f139-1732f88f6d97@math.uni-giessen.de>
Message-ID: <64f15d49-edb6-aa3e-559f-6aeebf781a5d@gmail.com>

  This works for me in the latest *development* version of lme4
(probably fixed since around the end of August).  Does devel version
work for you?  Maybe getting to be time for a new release (it's been 6
months: here's what's changed ...
https://github.com/lme4/lme4/blob/master/inst/NEWS.Rd )

On 2019-10-07 1:12 p.m., Gerrit Eichner wrote:
> Dear Ben and other lmer-experts,
> 
> if I extend my setting a little bit, a new/similar problem appears.
> For some reasons I would like to change the control structures and
> "hardwire" that as in:
> 
> lmerCtrl <- lmerControl(optCtrl = list(xtol_abs = 1e-9,
> ?????????????????????????????????????? ftol_abs = 1e-9))
> 
> theta <- c(1, 0.01, 0.2)
> fm <- eval(bquote(
> ???? lmer(Reaction ~ Days + (Days | Subject), data = sleepstudy,
> ????????? start = .(theta),
> ????????? control = .(lmerCtrl))? # THIS IS NEW.
> ?))
> 
> 
> Then allFit "goes on strike" again, now complaining about unused
> arguments:
> 
> allFit(fm, verbose = FALSE)
> Error in (function (optimizer = "nloptwrap", restart_edge = TRUE,
> boundary.tol = 1e-05,? :
> ? unused arguments (checkControl = list("ignore", "stop", "ignore",
> "stop", "stop", "message+drop.cols", "warning", "stop"), checkConv =
> list(list("warning", 0.002, NULL), list("message", 1e-04),
> list("warning", 1e-06)))
> 
> 
> Any ideas how to circumvent this?
> 
> ? Best regards? --? Gerrit
> 
> ---------------------------------------------------------------------
> Dr. Gerrit Eichner?????????????????? Mathematical Institute, Room 212
> gerrit.eichner at math.uni-giessen.de?? Justus-Liebig-University Giessen
> Tel: +49-(0)641-99-32104????????? Arndtstr. 2, 35392 Giessen, Germany
> http://www.uni-giessen.de/eichner
> ---------------------------------------------------------------------
> 
> Am 08.08.2019 um 15:41 schrieb Gerrit Eichner:
>> Thx a lot, Ben, for the fast reply which clearly explains the
>> cause of my problem. I've just found a solution which works for
>> me (and which is not as simple as "don't delete theta" ;-) ):
>> I "hardwire" theta's value into the function call:
>>
>> theta <- c(1, 0.01, 0.2)
>> fm <- eval(bquote(
>> ??? lmer(Reaction ~ Days + (Days | Subject), data = sleepstudy,
>> ???????? start = .(theta))
>> ??? ))
>>
>> rm(theta)
>> allFit(fm, verbose = FALSE)
>>
>>
>> Works like a "charm", at least in my current workflow. :-)
>>
>> ??Thanks once more? --? Gerrit
>>
>> ---------------------------------------------------------------------
>> Dr. Gerrit Eichner?????????????????? Mathematical Institute, Room 212
>> gerrit.eichner at math.uni-giessen.de?? Justus-Liebig-University Giessen
>> Tel: +49-(0)641-99-32104????????? Arndtstr. 2, 35392 Giessen, Germany
>> http://www.uni-giessen.de/eichner
>> ---------------------------------------------------------------------
>>
>> Am 08.08.2019 um 15:26 schrieb Ben Bolker:
>>>
>>> ?? This is not surprising, as allFit() uses update(), which tries to
>>> re-evaluate the function ... at the very least allFit needs a
>>> documentation update with that hint ... (I also notice at a glance that
>>> the allFit docs seem to be incomplete anyway).
>>>
>>> ?? If you say more about your workflow we might be able to find a way to
>>> help.? (If your workflow is this simple then the answer would be "well
>>> then don't delete theta" ...)
>>>
>>> ?? cheers
>>> ???? Ben Bolker
>>>
>>>
>>> On 2019-08-08 9:06 a.m., Gerrit Eichner wrote:
>>>> Dear lmer-experts,
>>>>
>>>> if I refit a fitted model with all available optimizers AFTER
>>>> removing the object which contains the starting values for the
>>>> parameters of the model as in
>>>>
>>>> theta <- c(1, 0.01, 0.2)
>>>> fm <- lmer(Reaction ~ Days + (Days | Subject), data = sleepstudy,
>>>> ??????????? start = theta)
>>>> rm(theta)
>>>> allFit(fm, verbose = FALSE)
>>>>
>>>> none of the optimizers succeeds:
>>>>
>>>> original model:
>>>> Reaction ~ Days + (Days | Subject)
>>>> optimizers (7): bobyqa, Nelder_Mead, nlminbwrap, nmkbw,
>>>> optimx.L-BFGS-B,
>>>> nloptwrap.NLOPT_LN_N...
>>>> 7 optimizer(s) failed
>>>> differences in negative log-likelihoods:
>>>> max= -Inf ; std dev= NA
>>>> Warning messages:
>>>> 1: In min(nllvec) : no non-missing arguments to min; returning Inf
>>>> 2: In max(nllvec - min(nllvec)) :
>>>> ?? no non-missing arguments to max; returning -Inf
>>>>
>>>>
>>>> If I don't remove theta from my workspace everything works fine.
>>>> Is there a workaround for this - from my perspective - unwanted
>>>> behaviour? (I have situations where allFit is used in a different
>>>> environment from the one wherein the model was fit, e.g., after
>>>> fitting the model the object which contains the fit is saved and
>>>> later loaded in another R-session to be processed by allFit.)
>>>> I could, of course, save theta everytime as well ... Any ideas?
>>>>
>>>> ??Best regards? --? Gerrit
>>>>
>>>> ---------------------------------------------------------------------
>>>> Dr. Gerrit Eichner?????????????????? Mathematical Institute, Room 212
>>>> gerrit.eichner at math.uni-giessen.de?? Justus-Liebig-University Giessen
>>>> Tel: +49-(0)641-99-32104????????? Arndtstr. 2, 35392 Giessen, Germany
>>>> http://www.uni-giessen.de/eichner
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From g@@d|o @end|ng |rom po@t@bgu@@c@||  Tue Oct  8 10:28:45 2019
From: g@@d|o @end|ng |rom po@t@bgu@@c@|| (Mario Garrido)
Date: Tue, 8 Oct 2019 10:28:45 +0200
Subject: [R-sig-ME] Export several lme outputs to a single excel file
In-Reply-To: <20190925205548.GF22724@info124.pharmacie.univ-paris5.fr>
References: <CAHzBVpLYYAu8tc6Tku2Wmooi=PqJdai8s326Mb8x=DzozKCUVQ@mail.gmail.com>
 <20190925205548.GF22724@info124.pharmacie.univ-paris5.fr>
Message-ID: <CAHzBVp+qQqCG24qhBk6Fu1pTtVAg_VZcb9w_A9jj9srefrYNkw@mail.gmail.com>

Dear Emmanuel Curis,
your approach was working perfectly, but at some point w gives me the
error. when introduced the new column
I have no problem in running model, the errors appears when introducing
extra $Md column. I wonder whether the problem is the * of the
significance, but is not, also is not due to character strings since my
variables are recognized as factors. I have no missing data in my
matrix,... And, as I said, problem only arise when I introduced the new
column

Thanks in advanxe
> anova(TempLight_StdzDiff_3trt_earlypeak)-> r15
> r15
Analysis of Variance Table

Response: StdzDiff
          Df  Sum Sq Mean Sq F value  Pr(>F)
Trtmnt     2   0.991  0.4953  0.2382 0.78891
sp         2  13.781  6.8904  3.3134 0.04407 *
Trtmnt:sp  4   4.123  1.0306  0.4956 0.73898
Residuals 53 110.217  2.0796
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> r15$Md<- "TempLight_StdzDiff_3trt_earlypeak"
> r15
Analysis of Variance Table

Response: StdzDiff
          Df  Sum Sq Mean Sq F value  Pr(>F) Md
Trtmnt     2   0.991  0.4953  0.2382 0.78891
sp         2  13.781  6.8904  3.3134 0.04407
Trtmnt:sp  4   4.123  1.0306  0.4956 0.73898
Residuals 53 110.217  2.0796
Warning message:
In data.matrix(x) : NAs introducidos por coerci?n



El mi?., 25 sept. 2019 a las 22:55, Emmanuel Curis (<
emmanuel.curis at parisdescartes.fr>) escribi?:

> Dear Mario,
>
> Since anova( ) results are basically data.frames, a simple way could
> be to add a column to identify the model, then row-bind the results.
>
> Something like (using examples in the lme man page)
>
> # First model
> fm1 <- lme(distance ~ age, data = Orthodont)
> anova( fm1 ) -> r1
> r1$Md <- 1
>
> # Second model
> fm2 <- lme(distance ~ age + Sex, data = Orthodont, random = ~ 1)
> anova( fm2 ) -> r2
> r2$Md <- 2
>
> # Bind results
> r <- rbind( r1, r2 )
>
> # Export
> write.xlsx( r, "your_file.xlsx" )
>
> For more model, can be adapted with do.call( rbind, list_of_results)
> and either a for or lapply to generate the additional
> columns... Depends on how you obtain your several models.
>
> Best regards,
>
> NB: note that, to avoid duplicate row names, terms with the same name
> will be incremented - see the results of the example above.  You can
> avoid this by explicely add the term names in the data.frame ---
> r1$Terms <- rownames( r1 ) --- and removing the row names of the final
> result.
>
>
> On Wed, Sep 25, 2019 at 01:33:46PM +0200, Mario Garrido wrote:
> ? Dear users,
> ? it is not such an statistical question but how to export results
> ? I fit several *lme* model s and I know how can I export the data to
> excel,
> ? this way:
> ? lme1 <- lme(Mean ~ x*y, data = Data, random = ~ 1|factor(ID))
> ? anova(lme1)->resultslme1
> ? And to export to excel since keep the data in ordered in rows/columns
> ? write.xlsx( resultslme1  ,"C:/Users/Desktop/resultslme1.xlsx")
> ?
> ? What I want to do is to export output from several lme at the same time,
> ? and adding the name/reference of the model. Something like this
> ? lme1
> ?   numDF denDF F.value p.value
> ? (Intercept) 1 78 653,6152 0
> ? x 2 78 0,822612 0,443057
> ? y 2 39 0,479357 0,622781
> ? x:y 4 78 2,593825 0,042787
> ?
> ? lme2
> ?   numDF denDF F.value p.value
> ? (Intercept) 1 78 653,6152 0
> ? x 2 78 0,822612 0,443057
> ? y 2 39 0,479357 0,622781
> ? x:y 4 78 2,593825 0,042787
> ?
> ?
> ? I tried with merge, abind, paste,... but I did not find the solution
> ?
> ? Thanks in advance
> ?
> ? --
> ? Mario Garrido Escudero, PhD
> ? Dr. Hadas Hawlena Lab
> ? Mitrani Department of Desert Ecology
> ? Jacob Blaustein Institutes for Desert Research
> ? Ben-Gurion University of the Negev
> ? Midreshet Ben-Gurion 84990 ISRAEL
> ?
> ? gaiarrido at gmail.com; gaadio at post.bgu.ac.il
> ? phone: (+972) 08-659-6854
> ?
> ?       [[alternative HTML version deleted]]
> ?
> ? _______________________________________________
> ? R-sig-mixed-models at r-project.org mailing list
> ? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> --
>                                 Emmanuel CURIS
>                                 emmanuel.curis at parisdescartes.fr
>
> Page WWW: http://emmanuel.curis.online.fr/index.html
>


-- 
Mario Garrido Escudero, PhD
Dr. Hadas Hawlena Lab
Mitrani Department of Desert Ecology
Jacob Blaustein Institutes for Desert Research
Ben-Gurion University of the Negev
Midreshet Ben-Gurion 84990 ISRAEL

gaiarrido at gmail.com; gaadio at post.bgu.ac.il
phone: (+972) 08-659-6854

	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Tue Oct  8 11:07:49 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Tue, 8 Oct 2019 22:07:49 +1300
Subject: [R-sig-ME] [FORGED] Re: Export several lme outputs to a single
 excel file
In-Reply-To: <CAHzBVp+qQqCG24qhBk6Fu1pTtVAg_VZcb9w_A9jj9srefrYNkw@mail.gmail.com>
References: <CAHzBVpLYYAu8tc6Tku2Wmooi=PqJdai8s326Mb8x=DzozKCUVQ@mail.gmail.com>
 <20190925205548.GF22724@info124.pharmacie.univ-paris5.fr>
 <CAHzBVp+qQqCG24qhBk6Fu1pTtVAg_VZcb9w_A9jj9srefrYNkw@mail.gmail.com>
Message-ID: <a5a79f10-8ea3-df15-a606-26073b3dafe7@auckland.ac.nz>


On 8/10/19 9:28 PM, Mario Garrido wrote:

> Dear Emmanuel Curis,
> your approach was working perfectly, but at some point w gives me the
> error. when introduced the new column
> I have no problem in running model, the errors appears when introducing
> extra $Md column. I wonder whether the problem is the * of the
> significance, but is not, also is not due to character strings since my
> variables are recognized as factors. I have no missing data in my
> matrix,... And, as I said, problem only arise when I introduced the new
> column
> 
> Thanks in advanxe
>> anova(TempLight_StdzDiff_3trt_earlypeak)-> r15
>> r15
> Analysis of Variance Table
> 
> Response: StdzDiff
>            Df  Sum Sq Mean Sq F value  Pr(>F)
> Trtmnt     2   0.991  0.4953  0.2382 0.78891
> sp         2  13.781  6.8904  3.3134 0.04407 *
> Trtmnt:sp  4   4.123  1.0306  0.4956 0.73898
> Residuals 53 110.217  2.0796
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> r15$Md<- "TempLight_StdzDiff_3trt_earlypeak"
>> r15
> Analysis of Variance Table
> 
> Response: StdzDiff
>            Df  Sum Sq Mean Sq F value  Pr(>F) Md
> Trtmnt     2   0.991  0.4953  0.2382 0.78891
> sp         2  13.781  6.8904  3.3134 0.04407
> Trtmnt:sp  4   4.123  1.0306  0.4956 0.73898
> Residuals 53 110.217  2.0796
> Warning message:
> In data.matrix(x) : NAs introducidos por coerci?n

This is a "generic" problem; it is not peculiar to your model nor to 
models fitted using lme, or other mixed modelling software.

Consider the following example:

set.seed(42)
x <- 1:20
y <- rnorm(20)
fit <- lm(y ~ x)
m   <- anova(fit)
m$newColumn <- "yeeeeks"
m

This produces:

> Analysis of Variance Table
> 
> Response: y
>           Df Sum Sq Mean Sq F value  Pr(>F) newColumn
> x          1  4.113  4.1130  2.5865 0.12518          
> Residuals 18 28.624  1.5902                          
> Warning message:
> In data.matrix(x) : NAs introduced by coercion

The "reason" is that m is (in the first instance) of class "anova" and 
there are (not unreasonably) certain restrictions as to how you can 
treat an object of this class.

A work-around to get something like what you appear to want could be:

set.seed(42)
x <- 1:20
y <- rnorm(20)
fit <- lm(y ~ x)
m   <- anova(fit)
m   <- cbind(m,newColumn=c("yeeeks",rep("",nrow(m)-1)))
m

However m is now of class "data.frame" whence it is printed by the 
method print.data.frame() rather than print.anova().  Consequently NAs 
show up in the output of the print method:

           Df      Sum Sq    Mean Sq    F value    Pr(>F) newColumn
x          1  0.04176282 0.04176282 0.03784897 0.8479256    yeeeks
Residuals 18 19.86132473 1.10340693         NA        NA

You could just live with those NAs, or you could convert the "F value" 
and "Pr(>F)" columns from numeric to character mode and replace the NAs 
by null strings "".

HTH

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From j@de@ @end|ng |rom uc@d@edu  Tue Oct  8 23:49:03 2019
From: j@de@ @end|ng |rom uc@d@edu (Ades, James)
Date: Tue, 8 Oct 2019 21:49:03 +0000
Subject: [R-sig-ME] Large mixed & crossed-effect model looking at
 educational spending on crime rates with error messages
In-Reply-To: <1741bbc0-830b-0807-6756-bf3dcd9aab75@mpi.nl>
References: <3969F144-2738-4733-B9E2-EDA2E3375418@UCSD.edu>
 <CAJuCY5xNAMirpyR+qy=Li4kGv-ys97AEis=fRyRgDf4WP+6RaQ@mail.gmail.com>
 <1AD83B84-C39B-4EE8-B50F-2E988419054C@UCSD.edu>
 <CAJuCY5yZhtkNrPf1rriStgR0Fp=NgN2bD2r6rVSUG9NV0sX6Sw@mail.gmail.com>
 <CD530BD0-2D53-4EB3-B003-5596665D7A86@UCSD.edu>
 <CAJuCY5wL4V4Fpgu39A8d_SZAazDcfCnwc1QU7piTffBkuGuuQQ@mail.gmail.com>
 <DBAF8D75-2563-4A00-B5BA-0107D2625946@UCSD.edu>
 <CABghstQdPD_vYBW5vbB1xVLnSWCmGvd5iRd5pb9efMYYdt=DJQ@mail.gmail.com>
 <23b89902-4345-5aec-299d-48d194591bed@mpi.nl>
 <61BCB906-022A-473D-BA01-583E961E3B41@UCSD.edu>
 <a278d0c3-f462-8e50-64a4-3b8d40f04986@mpi.nl>
 <0B21F4E6-E765-4CF5-B2B3-4B905376C959@UCSD.edu>
 <1741bbc0-830b-0807-6756-bf3dcd9aab75@mpi.nl>
Message-ID: <5D8D81F7-D024-4DDD-A2E2-AAD974221912@UCSD.edu>

Thanks, Philip.

I took some time to read more about covariance/multicollinearity. I found two papers pretty informative/easy to digest, for anyone interested in or struggling with this topic. The second papers concerns mostly hierarchical models.

https://www.ncbi.nlm.nih.gov/pubmed/23017962
https://www.sciencedirect.com/science/article/pii/S0049089X15000885?via%3Dihub

I?ve had some experience with BRMS, so maybe that is something to try in order to implement priors. I also looked into linear growth curve analysis.

Re my last question, I think you understand most of what I?m saying. Referring to my dataset, crime counts are the dv. If a police department reports crime counts for some years but not for others, would that be imputable? As it is now, I?ve filtered out all rows for which there is no crime count, under the impression that there was little to be done for predictors/explanatory variables with no dv. Am I mistaken?

I know that lme4 drops incomplete cases (winnowing the sample), but is the information for some of these predictors imputable, such that I maintain more rows that do have a dependent variable?let?s say I?m missing one value for median income for one city for one year?lme4 would remove this entire row; but is that information imputable, such that lme4 doesn?t remove that row?

Re the unreliability of Nelder Mead?what?s weird is that whereas the lme4 default optimizer fails to converge, Nelder Mead does. I know that that doesn?t necessarily imply accuracy, but in such situations would the results of Nelder Mead be questionable? Would it be better to opt for a simpler model, perhaps with a random slope without intercepts that works with the default--something like ( 0 + year | place_id )?

As always, thanks much!

James



On Oct 1, 2019, at 12:15 AM, Phillip Alday <phillip.alday at mpi.nl<mailto:phillip.alday at mpi.nl>> wrote:



On 01/10/2019 08:25, Ades, James wrote:
I see what you?re saying
with regard to the actual source of variation, but can?t it be the case
that one thing isn?t vaguely related to another, and that the actual
source of variation is the two variables. In such a case, aren?t there
ways to parse that covariance, such that you gain a better understanding
of each variable?s effect on variance?

This is non trivial in the general case. If you know something about the
latent structure, then things like structural equation models may help,
see e.g.

https://www.johnmyleswhite.com/notebook/2016/02/25/a-variant-on-statistically-controlling-for-confounding-constructs-is-harder-than-you-think/

which provides an alternative presentation of

Westfall, J. & Yarkoni, T. (2016): Statistically Controlling for
Confounding Constructs Is Harder than You Think PLoS ONE, , 11 , 1-22

Remember, linear regression -- fixed or mixed effect -- isn't sufficient
to make causal conclusions without additional assumptions. The issue
with collinearity (as long as its not perfect / leads to rank
deficiency) is not so much in the estimates as in the standard errors,
which get inflated by the covariance. There are several classical
approaches to dealing with this (such as residualization), but they all
have pros and cons. (Oversimplifying a bit) Residualization for example
attributes only the residual variance from the first predictor to the
second predictor -- i.e. all of the shared variance is attributed to the
first predictor. Regularized regression (e.g. LASSO, ridge, elastic net)
may help, especially with prediction. Equivalently, in a Bayesian
framework, appropriate choice of priors may help to pull the estimates
apart.

But all of these comments aren't specific to the mixed-model case, so
that opens up the set of resources you can turn to. ;)


Also, just want to make sure: if you don?t have a dependent observation
for a given condition, you would have to remove that entire row,
correct? The mixed-model wouldn?t be able to work around that? This is
what i learned in stats class, but if I?m doing this wrong, I think this
might also be affecting correlation.

If I understand you correctly, you're asking what happens when your
response variable (y) is missing for a given combination of predictors
(x's)? Depending on the exact structure of the missing data, multiple
imputation might help you there, but generally if a particular case
never occurs (say "12 hours of sunlight but with winter temperatures"
for a model predicting plant growth derived from observations taken
outside but which you want to use to predict in a greenhouse), it's hard
to make inferences about that complete interaction. lme4 by default
drops incomplete cases (i.e. any rows in the dataframe where there is an
NA *for variables used in the model*).

Phillip


Thanks, Philip!

James



On Sep 29, 2019, at 3:06 AM, Phillip Alday <phillip.alday at mpi.nl<mailto:phillip.alday at mpi.nl>
<mailto:phillip.alday at mpi.nl>> wrote:

The default optimizer in lme4 is the default for a reason. :) While
there's no free lunch or single best optimizer for every situation, the
default was chosen based on our experience about which optimizer works
performs well across a wide range of models and datasets.

Multicollinearity in mixed-effects models works pretty much exactly the
same way as it does in fixed-effects (i.e. regular/not mixed) regression
and so the way it's addressed (converting to PC basis, residualization,
etc.) In your case, you could omit one race and then the remaining races
will be linearly independent, albeit still correlated with another. This
correlation isn't great and will inflate your standard errors, but then
at least your design matrix won't be rank deficient.

Regarding year-spending: Are you using 'correlated' in a strict sense,
e.g. that spending tends to go up year-by-year? Or do just mean that
including spending in the model changes the effect of year? (I think the
latter weakly implies the former, but it's a different perspective.)
Either way, the changing coefficient isn't terribly surprising. In
'human' terms: if you don't have the option of attributing something to
the actual source of variation, but you do have something that is
vaguely related to it, then you will attribute it to that. However, if
you're ever given the chance to attribute it to the actual source, you
will do that and your attribution to the vaguely-related thing will
change.

Best,
Phillip

On 29/09/2019 03:20, Ades, James wrote:
Thanks, Ben and Philip!

So I think I was conflating having a continuous dependent variable,
which could then be broken up into different categories with dummy
variables (for instance, if I wanted to look at how wealth affects the
distribution of race in an area, I could create a model like lmer(total
people ~ race + per capita income + ?) with creating something similar
with a fixed factor (which I guess can?t be done).

I did try running the variables independently, which worked, I just
thought there was a way to combine races, and then per that logic,
thought that since race variables repeated within place (city/town), I
could nest it within PLACE_ID. But realized that the percent race as a
fixed effect (as an output) didn?t really make sense?hence my confusion.
So I guess somewhere in there my logic was afoul.

Regarding Nelmed-Mead: that?s odd...I recall reading somewhere that it
was actually quicker and more likely to converge. Good to know. I read
through the lme4 package details here:
https://cran.r-project.org/web/packages/lme4/lme4.pdf Would you
recommend then optimx? Or Nloptr/bobyqa? (which I think is the default).

Regarding multicollinearity: is there an article you could send me on
dealing with multicollinearity in mixed-effect models? I?ve perused the
internet, but haven?t been able to find a great how to and dealing with
it, such that you can better parse the effects of different variables (I
know that one can use PCA, but that fundamentally alters the process,
and isn?t there a way of averaging variables such that you minimize
collinearity?).

One thing I?m currently dealing with in my model is that year as a fixed
effect is correlated with a district?s spending, such that if I remove
year, district spending has a negative effect on crime, but including
year as a fixed effect alters the spending regression coefficient to be
positive (just north of zero). Though here, specifically, I?m not sure
if this is technically collinearity, or if time as a fixed factor is
merely controlling, here, for crime change over time, where a model
without year as a fixed factor would be looking at the effect of
district spending on crime (similar to a model where years are averaged
together). Does that make sense? Is that interpretation accurate?

Thanks much!

James


On Sep 28, 2019, at 8:09 AM, Phillip Alday <phillip.alday at mpi.nl<mailto:phillip.alday at mpi.nl>
<mailto:phillip.alday at mpi.nl>
<mailto:phillip.alday at mpi.nl>> wrote:

ink the answer to your proximal question about per_race is that
you would need five *different* numerical varia


	[[alternative HTML version deleted]]


From @nce||@@07 @end|ng |rom gm@||@com  Sat Oct  5 19:42:55 2019
From: @nce||@@07 @end|ng |rom gm@||@com (=?UTF-8?Q?Andrea_C=C3=A9spedes?=)
Date: Sat, 5 Oct 2019 11:42:55 -0600
Subject: [R-sig-ME] Help with multilevel model Poisson
Message-ID: <CA+pj98j8CmtxC6+m_=2TmruYc+B=O7CRRsm4A8TUb_qJbOEzMw@mail.gmail.com>

Hello



I am currently working the shrinkage phenomenon in multilevel models.



I have a problem of convergence in the model when I add more random
coefficients to the models, after three coefficients,I have this error
message:



 Warning message:

In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :

  Model failed to converge with max|grad| = 0.0278398 (tol = 0.001,
component 1)



I have a three-level model, with Poisson distribution, the structure is: to
my subject (rat) I register the vocalizations emitted in four specific
moments of an experiment that is repeated for three days. And I have 31
subjects. All my variables are dichotomous.



I tried several alternatives to solve that error, but the only effective
thing was to specify the optimizer = ?bobyqa? and more iterations, for my
luck it worked,

F.aleat.int <- glmer(y ~ 1+DIA2+DIA3+M1+M4+M5+M6+M9+M10+M11+ (1 |
ID_DIA:ID_SUJ) + (1+M1+M5+M11 | ID_SUJ), family=poisson, data=base,
control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e4)))

But the estimates of random effects are much greater than the obtained
using other packages (MCMCglmm, glmmLasso, glmmsr and hglm),

For example, for one variable I have 2.1 and in the other packages I have
0.8

How can I explain that:

-        Due to the nature of the model? Or the optimizer as such?

-        Would you appreciate it if you could tell me how I can solve that?

-        Is it because all my variables are dichotomous?



Regards

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Wed Oct  9 17:04:42 2019
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Wed, 9 Oct 2019 17:04:42 +0200
Subject: [R-sig-ME] Help with multilevel model Poisson
In-Reply-To: <CA+pj98j8CmtxC6+m_=2TmruYc+B=O7CRRsm4A8TUb_qJbOEzMw@mail.gmail.com>
References: <CA+pj98j8CmtxC6+m_=2TmruYc+B=O7CRRsm4A8TUb_qJbOEzMw@mail.gmail.com>
Message-ID: <CAJuCY5xqYk28ui1hJE=Z0=Mg=UYvShT3GGqxH=YkdL6b5ytuAg@mail.gmail.com>

Dear Andrea,

How many observation per subject? 12? That is too few to fit a random slope
model with 10 parameters.

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op wo 9 okt. 2019 om 16:38 schreef Andrea C?spedes <ancelis.07 at gmail.com>:

> Hello
>
>
>
> I am currently working the shrinkage phenomenon in multilevel models.
>
>
>
> I have a problem of convergence in the model when I add more random
> coefficients to the models, after three coefficients,I have this error
> message:
>
>
>
>  Warning message:
>
> In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>
>   Model failed to converge with max|grad| = 0.0278398 (tol = 0.001,
> component 1)
>
>
>
> I have a three-level model, with Poisson distribution, the structure is: to
> my subject (rat) I register the vocalizations emitted in four specific
> moments of an experiment that is repeated for three days. And I have 31
> subjects. All my variables are dichotomous.
>
>
>
> I tried several alternatives to solve that error, but the only effective
> thing was to specify the optimizer = ?bobyqa? and more iterations, for my
> luck it worked,
>
> F.aleat.int <- glmer(y ~ 1+DIA2+DIA3+M1+M4+M5+M6+M9+M10+M11+ (1 |
> ID_DIA:ID_SUJ) + (1+M1+M5+M11 | ID_SUJ), family=poisson, data=base,
> control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e4)))
>
> But the estimates of random effects are much greater than the obtained
> using other packages (MCMCglmm, glmmLasso, glmmsr and hglm),
>
> For example, for one variable I have 2.1 and in the other packages I have
> 0.8
>
> How can I explain that:
>
> -        Due to the nature of the model? Or the optimizer as such?
>
> -        Would you appreciate it if you could tell me how I can solve that?
>
> -        Is it because all my variables are dichotomous?
>
>
>
> Regards
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From jmg5214 @end|ng |rom gm@||@com  Thu Oct  3 18:54:19 2019
From: jmg5214 @end|ng |rom gm@||@com (Jason Gleditsch)
Date: Thu, 3 Oct 2019 11:54:19 -0500
Subject: [R-sig-ME] Convergence Warnings Using dredge with glmmTMB
Message-ID: <5d9627bb.1c69fb81.4eb23.7f79@mx.google.com>

Hi,

I am trying to relate bird counts from point counts of a bird community to various 
environmental variables. Then I want to estimate the abundance of each species at each 
survey location in order to run community level analyses. To do all of this I am first 
running a glmmTMB (family = Poisson) model with count as the response. For the zi part of the 
model, I just have a random intercept varying with site. For the count part of the model
I have 'nuisance' variables that may influence detection (i.e. since_sr, wind, rain, month).
The random factors in the count part is site again and observer (obs). All of the explanatory
variables have been standardized (x-mean/sd) so that comparisons of the betas can be made 
within and across species. The code for the model is:

# CODE #
m <- glmmTMB(count ~ wind + rain + since_sr + month + (1|obs) + (1|site),
	data = tmp,
	ziformula = ~ (1|site),
	family = "poisson")
# END CODE #

I then am using the dredge function from the package MuMIn to run all combinations of the 
fixed effects. I then select the top model (in essence selecting the variables that 
influence detection the most) and use the update function to include the environmental
variables of interest (which I think is just adding them to the count part). The code for
this is:

# CODE #
dd <- dredge(m)
out <- get.models(dd, subset = 1)[[1]]
m.env <- update(out, . ~ . + X.1 + X.2 + X.3 + X.4 + X.5 + X.6 + X.6_2)  
#Note X.6_2 is the standardized square of the unstandardized X.6 and they are correlated
# END CODE #

I use dredge again to average the top models that have 95% of the cumulative weight. The 
code I use is:

# CODE #
vars <- names(out$frame)[2:(length(names(out$frame))-2)]    #Get 'nuisance' variable names
vars <- paste("cond(", vars,")", sep="")                                          #Make sure they match the glmmTMB format

d.env <- dredge(m.env, fixed= vars, subset=dc(cond(X.6), cond(X.6_2)))
top <- get.models(d.env, subset=cumsum(weight) <= .95)
avgm <- model.avg(top)
ci <- confint(avgm)
out.env <- data.frame(cbind(avgm$coefficients[1,]), ci)
# END CODE #

I am running this code for 16 species and everything works fine for 13 of them. However, 3 of 
the species (Sp03, Sp13, Sp14) return the following warnings (many times):

"In nlminb(start = par, objective = fn, gradient = gr,  ... :
   NA/NaN function evaluation"

"In fitTMB(TMBStruc) :
   Model convergence problem; non-positive-definite Hessian matrix. See vignette('troubleshooting')"

The frustrating thing is that these warnings only occur during the dredge function and subsequent 
get.models and model.avg functions. Therefore, I am not sure what is causing these issues. It does 
not seem like overparameterization is creating these issues since the global model runs just fine 
for every species. However, for Sp03 and Sp13 it could most certainly be that I do not have enough
data for them (only seen in <10% of surveys). For Sp14 the data is very similar to other species
that the models run just fine for (i.e. Sp01, Sp03, Sp06, Sp07, Sp09, Sp16). In fact, some of those
species have less data than Sp14. I have already tried using nbinom2 as the family and I get the 
same errors for Sp14. If you can provide any help with these warnings, I would really appreciate it.

I have to be careful about disseminating the data so if you need the data please contact me directly

Thanks,

Jason 
(e-mail: jmg5214 [at] gmail.com)

Summary of standardized data:
site = factor of 7 levels
obs = factor of 14 levels
since_sr = numeric (min=-1.7712; med=-0.1685; mean=0; max=4.6646)
wind = numeric (min=-1.0024; med=-0.3418; mean=0; max=3.6218)
rain = numeric (min=-0.3569; med=-0.3569; mean=0; max=5.7002)
month = factor of 12 levels
X.1 = numeric (min=-1.2878; med=-0.2288; mean=0; max=3.3103)
X.2 = numeric (min=-2.4687; med=0.2644; mean=0; max=1.4032)
X.3 = numeric (min=-1.4766; med=-0.1016; mean=0; max=1.8235)
X.4 = numeric (min=-1.9055; med=-0.1650; mean=0; max=1.2247)
X.5 = numeric (min=-1.68630; med=0.07525; mean=0; max=1.30377)
X.6 = numeric (min=-1.35405; med=0.04783; mean=0; max=2.60061)
X.6_2 = numeric (min=-0.8385; med=-0.1876; mean=0; max=3.2626)



	[[alternative HTML version deleted]]


From ben@ke|cey @end|ng |rom gm@||@com  Tue Oct  8 15:27:43 2019
From: ben@ke|cey @end|ng |rom gm@||@com (Ben Kelcey)
Date: Tue, 8 Oct 2019 09:27:43 -0400
Subject: [R-sig-ME] UCincinnati Assistant Professor in Research Methods
 Position
Message-ID: <CA+cAXnsLP9rQ6GP14fGsqRee7yuHuZP0v1jCf2KcT7b2pWgUJg@mail.gmail.com>

Call for Applications for:
Assistant Professor of Research Methods
College of Education, Criminal Justice, and Human Services
University of Cincinnati

The School of Education in the College of Education, Criminal Justice, and
Human Services is seeking applications for a tenure-track assistant
professor position specializing in research, teaching and mentoring related
to advanced research methodologies (e.g., quantitative/measurement,
qualitative, statistics) in the context of education and social science
research.  The prospective faculty member will have a primary appointment
within the Research Methods area in the School of Education and is expected
to maintain an active research agenda, teach introductory and advanced
graduate courses in research methods and/or statistics, mentor graduate
students, and contribute to service activities. The Research Methods area
trains graduate students primarily through the Educational Studies MA and
PhD programs across multiple concentrations (Quantitative and Mixed Methods
Research Methodologies; Educational and Community Based Action Research)
and serves the University with a significant range of Research Methods
course offerings and through a wealth of research and training
collaborations. The position begins on August 17, 2020.

Minimum Qualifications:  Applicants must have an earned doctorate in a
methods-focused field (e.g., education studies, education psychology,
education, psychology, sociology, economics, statistics) from an accredited
university by August 31, 2020 as well as evidence of scholarship (e.g.,
publications in journals, presentations at (inter)national conferences) and
teaching (e.g., as the instructor or teacher assistant) in advanced
research methods and/or statistics that is commensurate with time since
degree.

Preferred Qualifications:  We are seeking an innovative methodologist with
a strong record of scholarship related to advanced research methodologies
who can contribute to a research methods program that values diverse
methodological approaches. Evidence of effective oral and written
communication about research methods is preferred.

Responsibilities: Responsibilities for this position include: (1) Conduct
and support research consistent with the Research Methods area and the
School of Education; (2) maintain an active research agenda and disseminate
research results; (3) teach research methods courses, mentor students and
supervise student research; (4) engage in university, professional, and
program service, including participation in continuous program improvement
and new program development, as appropriate.

Application requirements:
All applicants should submit the following materials
https://jobs.uc.edu/job/Cincinnati-Assistant-Professor%2C-Research-Methods-OH-45201/598245900/


1) A cover letter describing their qualifications
2) A curriculum vitae
3) A research statement
4) A teaching statement
5) Names and contact information for three references


Review of applications will commence October 21st, 2019

Please send inquiries regarding the position to the search chair
Ben Kelcey
Associate Professor of Quantitative Methodologies
University of Cincinnati
kelceybn at ucmail.uc.edu
513 556 3608

Inquiries regarding the application submission process should be directed
to
Kourtney Johnson
fieldskw at ucmail.uc.edu
513-556-6515

	[[alternative HTML version deleted]]


From @nce||@@07 @end|ng |rom gm@||@com  Wed Oct  9 18:06:53 2019
From: @nce||@@07 @end|ng |rom gm@||@com (=?UTF-8?Q?Andrea_C=C3=A9spedes?=)
Date: Wed, 9 Oct 2019 10:06:53 -0600
Subject: [R-sig-ME] Help with multilevel model Poisson
In-Reply-To: <CAJuCY5xqYk28ui1hJE=Z0=Mg=UYvShT3GGqxH=YkdL6b5ytuAg@mail.gmail.com>
References: <CA+pj98j8CmtxC6+m_=2TmruYc+B=O7CRRsm4A8TUb_qJbOEzMw@mail.gmail.com>
 <CAJuCY5xqYk28ui1hJE=Z0=Mg=UYvShT3GGqxH=YkdL6b5ytuAg@mail.gmail.com>
Message-ID: <CA+pj98iyX8dNCpwkCjUojH6PbDcjy2BVncLTS6Z_yjYYqvCVNQ@mail.gmail.com>

Hi everyone

No, it?s 12 observations per day and it?s three days, so I have 36
observations per subject

Thanks


El mi?., 9 oct. 2019 a las 9:04, Thierry Onkelinx (<thierry.onkelinx at inbo.be>)
escribi?:

> Dear Andrea,
>
> How many observation per subject? 12? That is too few to fit a random
> slope model with 10 parameters.
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be>
>
>
> Op wo 9 okt. 2019 om 16:38 schreef Andrea C?spedes <ancelis.07 at gmail.com>:
>
>> Hello
>>
>>
>>
>> I am currently working the shrinkage phenomenon in multilevel models.
>>
>>
>>
>> I have a problem of convergence in the model when I add more random
>> coefficients to the models, after three coefficients,I have this error
>> message:
>>
>>
>>
>>  Warning message:
>>
>> In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>>
>>   Model failed to converge with max|grad| = 0.0278398 (tol = 0.001,
>> component 1)
>>
>>
>>
>> I have a three-level model, with Poisson distribution, the structure is:
>> to
>> my subject (rat) I register the vocalizations emitted in four specific
>> moments of an experiment that is repeated for three days. And I have 31
>> subjects. All my variables are dichotomous.
>>
>>
>>
>> I tried several alternatives to solve that error, but the only effective
>> thing was to specify the optimizer = ?bobyqa? and more iterations, for my
>> luck it worked,
>>
>> F.aleat.int <- glmer(y ~ 1+DIA2+DIA3+M1+M4+M5+M6+M9+M10+M11+ (1 |
>> ID_DIA:ID_SUJ) + (1+M1+M5+M11 | ID_SUJ), family=poisson, data=base,
>> control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e4)))
>>
>> But the estimates of random effects are much greater than the obtained
>> using other packages (MCMCglmm, glmmLasso, glmmsr and hglm),
>>
>> For example, for one variable I have 2.1 and in the other packages I have
>> 0.8
>>
>> How can I explain that:
>>
>> -        Due to the nature of the model? Or the optimizer as such?
>>
>> -        Would you appreciate it if you could tell me how I can solve
>> that?
>>
>> -        Is it because all my variables are dichotomous?
>>
>>
>>
>> Regards
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Wed Oct  9 21:03:11 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Wed, 9 Oct 2019 15:03:11 -0400
Subject: [R-sig-ME] UCincinnati Assistant Professor in Research Methods
 Position
In-Reply-To: <CA+cAXnsLP9rQ6GP14fGsqRee7yuHuZP0v1jCf2KcT7b2pWgUJg@mail.gmail.com>
References: <CA+cAXnsLP9rQ6GP14fGsqRee7yuHuZP0v1jCf2KcT7b2pWgUJg@mail.gmail.com>
Message-ID: <CABghstRZ+Ho9F6QLSigc1gMHC3jsN9_NyiTWa38Cg5H83CPS_g@mail.gmail.com>

 This seems marginally off-topic for this list.  I guess
**occasional** relevant job ads are OK and even useful, but maybe give
us a shortened version and a link to the full ad?

On Wed, Oct 9, 2019 at 11:18 AM Ben Kelcey <ben.kelcey at gmail.com> wrote:
>
> Call for Applications for:
> Assistant Professor of Research Methods
> College of Education, Criminal Justice, and Human Services
> University of Cincinnati
>
> The School of Education in the College of Education, Criminal Justice, and
> Human Services is seeking applications for a tenure-track assistant
> professor position specializing in research, teaching and mentoring related
> to advanced research methodologies (e.g., quantitative/measurement,
> qualitative, statistics) in the context of education and social science
> research.  The prospective faculty member will have a primary appointment
> within the Research Methods area in the School of Education and is expected
> to maintain an active research agenda, teach introductory and advanced
> graduate courses in research methods and/or statistics, mentor graduate
> students, and contribute to service activities. The Research Methods area
> trains graduate students primarily through the Educational Studies MA and
> PhD programs across multiple concentrations (Quantitative and Mixed Methods
> Research Methodologies; Educational and Community Based Action Research)
> and serves the University with a significant range of Research Methods
> course offerings and through a wealth of research and training
> collaborations. The position begins on August 17, 2020.
>
> Minimum Qualifications:  Applicants must have an earned doctorate in a
> methods-focused field (e.g., education studies, education psychology,
> education, psychology, sociology, economics, statistics) from an accredited
> university by August 31, 2020 as well as evidence of scholarship (e.g.,
> publications in journals, presentations at (inter)national conferences) and
> teaching (e.g., as the instructor or teacher assistant) in advanced
> research methods and/or statistics that is commensurate with time since
> degree.
>
> Preferred Qualifications:  We are seeking an innovative methodologist with
> a strong record of scholarship related to advanced research methodologies
> who can contribute to a research methods program that values diverse
> methodological approaches. Evidence of effective oral and written
> communication about research methods is preferred.
>
> Responsibilities: Responsibilities for this position include: (1) Conduct
> and support research consistent with the Research Methods area and the
> School of Education; (2) maintain an active research agenda and disseminate
> research results; (3) teach research methods courses, mentor students and
> supervise student research; (4) engage in university, professional, and
> program service, including participation in continuous program improvement
> and new program development, as appropriate.
>
> Application requirements:
> All applicants should submit the following materials
> https://jobs.uc.edu/job/Cincinnati-Assistant-Professor%2C-Research-Methods-OH-45201/598245900/
>
>
> 1) A cover letter describing their qualifications
> 2) A curriculum vitae
> 3) A research statement
> 4) A teaching statement
> 5) Names and contact information for three references
>
>
> Review of applications will commence October 21st, 2019
>
> Please send inquiries regarding the position to the search chair
> Ben Kelcey
> Associate Professor of Quantitative Methodologies
> University of Cincinnati
> kelceybn at ucmail.uc.edu
> 513 556 3608
>
> Inquiries regarding the application submission process should be directed
> to
> Kourtney Johnson
> fieldskw at ucmail.uc.edu
> 513-556-6515
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbo|ker @end|ng |rom gm@||@com  Wed Oct  9 21:04:50 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Wed, 9 Oct 2019 15:04:50 -0400
Subject: [R-sig-ME] Random-effects variance-covariance matrix in lmer?
In-Reply-To: <83e615e4412d405db0d32a139828388c@agroscope.admin.ch>
References: <83e615e4412d405db0d32a139828388c@agroscope.admin.ch>
Message-ID: <3407d29e-1290-d454-221a-f94ffa9b6581@gmail.com>


  It can be hacked with a little bit of effort: I just added a document
describing this here:
https://bbolker.github.io/mixedmodels-misc/notes/varmats.html (also see
the .rmd version of the same thing).
	

On 2019-10-02 9:50 a.m., matthias.suter at agroscope.admin.ch wrote:
> Hi all
> 
> I'm looking for a way to specify a more complex variance-covariance matrix for the random effects in lmer(). For example, in lme() (nlme package), there are the pdMat classes to specify e.g. a compound symmetry (pdCompSym) or a multiple of an identity (pdIdent) structure for the variance-covariance matrix of random effects. Is there a possibility to code an equivalent for lmer()? I'm specifically interested in "compound symmetry" and "multiple of an identity".
> 
> I assume that Douglas Bates or Ben Bolker have a distinct answer on that.
> 
> Thanks in advance,
> Matthias
> 
> 
> ---------------------------------------------------------
> Matthias Suter, Dr.sc.nat.
> Forage Production and Grassland Systems
> 
> Agroscope
> Reckenholzstrasse 191, CH-8046 Z?rich
> 
> Phone +41 58 468 75 90
> Fax      +41 58 468 72 01
> matthias.suter at agroscope.admin.ch
> www.agroscope.ch
> ---------------------------------------------------------
> 
> 
> 	[[alternative HTML version deleted]]
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From th|erry@onke||nx @end|ng |rom |nbo@be  Thu Oct 10 09:29:33 2019
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Thu, 10 Oct 2019 09:29:33 +0200
Subject: [R-sig-ME] Help with multilevel model Poisson
In-Reply-To: <CA+pj98iyX8dNCpwkCjUojH6PbDcjy2BVncLTS6Z_yjYYqvCVNQ@mail.gmail.com>
References: <CA+pj98j8CmtxC6+m_=2TmruYc+B=O7CRRsm4A8TUb_qJbOEzMw@mail.gmail.com>
 <CAJuCY5xqYk28ui1hJE=Z0=Mg=UYvShT3GGqxH=YkdL6b5ytuAg@mail.gmail.com>
 <CA+pj98iyX8dNCpwkCjUojH6PbDcjy2BVncLTS6Z_yjYYqvCVNQ@mail.gmail.com>
Message-ID: <CAJuCY5zqKSm=-8F0mCA0cb0VdK783UyVbdt=QCJqgc3zJLnBrw@mail.gmail.com>

36 observations per level is still very little to fit a 10 parameter random
effect

Op wo 9 okt. 2019 18:07 schreef Andrea C?spedes <ancelis.07 at gmail.com>:

> Hi everyone
>
> No, it?s 12 observations per day and it?s three days, so I have 36
> observations per subject
>
> Thanks
>
>
> El mi?., 9 oct. 2019 a las 9:04, Thierry Onkelinx (<
> thierry.onkelinx at inbo.be>) escribi?:
>
>> Dear Andrea,
>>
>> How many observation per subject? 12? That is too few to fit a random
>> slope model with 10 parameters.
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>> AND FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be
>> Havenlaan 88 bus 73, 1000 Brussel
>> www.inbo.be
>>
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>>
>> <https://www.inbo.be>
>>
>>
>> Op wo 9 okt. 2019 om 16:38 schreef Andrea C?spedes <ancelis.07 at gmail.com
>> >:
>>
>>> Hello
>>>
>>>
>>>
>>> I am currently working the shrinkage phenomenon in multilevel models.
>>>
>>>
>>>
>>> I have a problem of convergence in the model when I add more random
>>> coefficients to the models, after three coefficients,I have this error
>>> message:
>>>
>>>
>>>
>>>  Warning message:
>>>
>>> In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>>>
>>>   Model failed to converge with max|grad| = 0.0278398 (tol = 0.001,
>>> component 1)
>>>
>>>
>>>
>>> I have a three-level model, with Poisson distribution, the structure is:
>>> to
>>> my subject (rat) I register the vocalizations emitted in four specific
>>> moments of an experiment that is repeated for three days. And I have 31
>>> subjects. All my variables are dichotomous.
>>>
>>>
>>>
>>> I tried several alternatives to solve that error, but the only effective
>>> thing was to specify the optimizer = ?bobyqa? and more iterations, for my
>>> luck it worked,
>>>
>>> F.aleat.int <- glmer(y ~ 1+DIA2+DIA3+M1+M4+M5+M6+M9+M10+M11+ (1 |
>>> ID_DIA:ID_SUJ) + (1+M1+M5+M11 | ID_SUJ), family=poisson, data=base,
>>> control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e4)))
>>>
>>> But the estimates of random effects are much greater than the obtained
>>> using other packages (MCMCglmm, glmmLasso, glmmsr and hglm),
>>>
>>> For example, for one variable I have 2.1 and in the other packages I have
>>> 0.8
>>>
>>> How can I explain that:
>>>
>>> -        Due to the nature of the model? Or the optimizer as such?
>>>
>>> -        Would you appreciate it if you could tell me how I can solve
>>> that?
>>>
>>> -        Is it because all my variables are dichotomous?
>>>
>>>
>>>
>>> Regards
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>

	[[alternative HTML version deleted]]


From gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de  Thu Oct 10 14:02:39 2019
From: gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de (Gerrit Eichner)
Date: Thu, 10 Oct 2019 14:02:39 +0200
Subject: [R-sig-ME] 
 allFit fails after removing object with starting values
 for model parameters from workspace
In-Reply-To: <64f15d49-edb6-aa3e-559f-6aeebf781a5d@gmail.com>
References: <64f15d49-edb6-aa3e-559f-6aeebf781a5d@gmail.com>
Message-ID: <56138d5a-0ae9-7da9-8b3a-41cc4f39d284@math.uni-giessen.de>

Hi, Ben,

in fact, it does work in the latest development version.
I apparently missed to try that one; sorry for bothering
and. Thank you very much once more for your efforts!

  Best regards  --  Gerrit

---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
http://www.uni-giessen.de/eichner
---------------------------------------------------------------------


  This works for me in the latest *development* version of lme4
(probably fixed since around the end of August).  Does devel version
work for you?  Maybe getting to be time for a new release (it's been 6
months: here's what's changed ...
https://github.com/lme4/lme4/blob/master/inst/NEWS.Rd )

On 2019-10-07 1:12 p.m., Gerrit Eichner wrote:
 > Dear Ben and other lmer-experts,
 >
 > if I extend my setting a little bit, a new/similar problem appears.
 > For some reasons I would like to change the control structures and
 > "hardwire" that as in:
 >
 > lmerCtrl <- lmerControl(optCtrl = list(xtol_abs = 1e-9,
 >                                        ftol_abs = 1e-9))
 >
 > theta <- c(1, 0.01, 0.2)
 > fm <- eval(bquote(
 >      lmer(Reaction ~ Days + (Days | Subject), data = sleepstudy,
 >           start = .(theta),
 >           control = .(lmerCtrl))  # THIS IS NEW.
 >  ))
 >
 >
 > Then allFit "goes on strike" again, now complaining about unused
 > arguments:
 >
 > allFit(fm, verbose = FALSE)
 > Error in (function (optimizer = "nloptwrap", restart_edge = TRUE,
 > boundary.tol = 1e-05,  :
 >   unused arguments (checkControl = list("ignore", "stop", "ignore",
 > "stop", "stop", "message+drop.cols", "warning", "stop"), checkConv =
 > list(list("warning", 0.002, NULL), list("message", 1e-04),
 > list("warning", 1e-06)))
 >
 >
 > Any ideas how to circumvent this?
 >
 >   Best regards  --  Gerrit
 >
 > ---------------------------------------------------------------------
 > Dr. Gerrit Eichner                   Mathematical Institute, Room 212
 > gerrit.eichner using math.uni-giessen.de   Justus-Liebig-University 
Giessen
 > Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
 > http://www.uni-giessen.de/eichner
 > ---------------------------------------------------------------------
 >
 > Am 08.08.2019 um 15:41 schrieb Gerrit Eichner:
 >> Thx a lot, Ben, for the fast reply which clearly explains the
 >> cause of my problem. I've just found a solution which works for
 >> me (and which is not as simple as "don't delete theta" ;-) ):
 >> I "hardwire" theta's value into the function call:
 >>
 >> theta <- c(1, 0.01, 0.2)
 >> fm <- eval(bquote(
 >>     lmer(Reaction ~ Days + (Days | Subject), data = sleepstudy,
 >>          start = .(theta))
 >>     ))
 >>
 >> rm(theta)
 >> allFit(fm, verbose = FALSE)
 >>
 >>
 >> Works like a "charm", at least in my current workflow. :-)
 >>
 >>   Thanks once more  --  Gerrit
 >>
 >> ---------------------------------------------------------------------
 >> Dr. Gerrit Eichner                   Mathematical Institute, Room 212
 >> gerrit.eichner using math.uni-giessen.de   Justus-Liebig-University 
Giessen
 >> Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
 >> http://www.uni-giessen.de/eichner
 >> ---------------------------------------------------------------------
 >>
 >> Am 08.08.2019 um 15:26 schrieb Ben Bolker:
 >>>
 >>>    This is not surprising, as allFit() uses update(), which tries to
 >>> re-evaluate the function ... at the very least allFit needs a
 >>> documentation update with that hint ... (I also notice at a glance that
 >>> the allFit docs seem to be incomplete anyway).
 >>>
 >>>    If you say more about your workflow we might be able to find a 
way to
 >>> help.  (If your workflow is this simple then the answer would be "well
 >>> then don't delete theta" ...)
 >>>
 >>>    cheers
 >>>      Ben Bolker
 >>>
 >>>
 >>> On 2019-08-08 9:06 a.m., Gerrit Eichner wrote:
 >>>> Dear lmer-experts,
 >>>>
 >>>> if I refit a fitted model with all available optimizers AFTER
 >>>> removing the object which contains the starting values for the
 >>>> parameters of the model as in
 >>>>
 >>>> theta <- c(1, 0.01, 0.2)
 >>>> fm <- lmer(Reaction ~ Days + (Days | Subject), data = sleepstudy,
 >>>>             start = theta)
 >>>> rm(theta)
 >>>> allFit(fm, verbose = FALSE)
 >>>>
 >>>> none of the optimizers succeeds:
 >>>>
 >>>> original model:
 >>>> Reaction ~ Days + (Days | Subject)
 >>>> optimizers (7): bobyqa, Nelder_Mead, nlminbwrap, nmkbw,
 >>>> optimx.L-BFGS-B,
 >>>> nloptwrap.NLOPT_LN_N...
 >>>> 7 optimizer(s) failed
 >>>> differences in negative log-likelihoods:
 >>>> max= -Inf ; std dev= NA
 >>>> Warning messages:
 >>>> 1: In min(nllvec) : no non-missing arguments to min; returning Inf
 >>>> 2: In max(nllvec - min(nllvec)) :
 >>>>    no non-missing arguments to max; returning -Inf
 >>>>
 >>>>
 >>>> If I don't remove theta from my workspace everything works fine.
 >>>> Is there a workaround for this - from my perspective - unwanted
 >>>> behaviour? (I have situations where allFit is used in a different
 >>>> environment from the one wherein the model was fit, e.g., after
 >>>> fitting the model the object which contains the fit is saved and
 >>>> later loaded in another R-session to be processed by allFit.)
 >>>> I could, of course, save theta everytime as well ... Any ideas?
 >>>>
 >>>>   Best regards  --  Gerrit
 >>>>


From |@@ch@|er @end|ng |rom @tudent@ru@n|  Thu Oct 10 15:11:05 2019
From: |@@ch@|er @end|ng |rom @tudent@ru@n| (=?utf-8?B?U2Now6RmZXIsIEwuIChMZW5hKQ==?=)
Date: Thu, 10 Oct 2019 13:11:05 +0000
Subject: [R-sig-ME] Effect sizes for mixed-effects models
Message-ID: <FCB43A7B-1E0C-4E2D-A3A0-9E6160F53012@student.ru.nl>

Hi everyone,
I am writing to ask two questions related to the calculation of effect sizes for mixed-effects models for a meta-analysis.
To derive effect sizes for mixed-effects models, we generally follow the Hedges 2007 paper (https://journals.sagepub.com/doi/abs/10.3102/1076998606298043?journalCode=jebb) and a blogpost by Jake Westfall on effect-size calculations for within-subjects designs (http://jakewestfall.org/blog/index.php/2016/03/25/five-different-cohens-d-statistics-for-within-subject-designs/):
1.     Variance for complex mixed-effects models
While the calculation of Cohen?s d is unproblematic (formula 8 on page 346 in Hedges, 2007), the calculation of the respective variance turned out to be difficult for complex study designs. Hedge?s provided the following formula () to derive V(dw):
V(dw) = ((NT + NC) / (NT * NC)) * ((1+(n-1)p)/(1-p)) + ((dw^2) / (2(N ? M)))
with NT referring to the number of observations in the treatment group, NC referring to the number of observations in the control group, N referring to the total number of observations (NT + NC  = N), n referring to the number of observations per cluster, p referring to the ICC, and M referring to the number of clusters.
 For our meta-analysis, we want to derive the variance related to Cohen?s d for a mixed-subjects design with some participant conducting a task only in the control condition and other participants conducting the task in the control and in the experimental condition (within-subjects design). Since the number of observations per cluster differs (some participants have 30 observations, others have 60) we decided to use the variance formula for unequal cluster sample sizes in which n is substituted with the cluster sample size ? (formula 18 on page 350):
? = ((NC * ?mTi = 1 (nTi)^2) / (NT * N)) +  ((NT * ?mCi = 1 (nCi)^2) / (NC * N))
iWhile we expected that this formula would yield an unequal cluster sample size between 30 and 60, it gives us a value of 30 (which is equal to the cluster sample size if this would be a between-subjects design). This suggests that the formula cannot account for the participants which are both in the control and the experimental condition. Do you have any advice on how we could derive an accurate variance estimate for such a design?
2. Turning Cohen?s d into Hedge?s g for mixed-models
Finally, we want to transform Cohen?s d into Hedge?s g using:
 g(d) = d * (1- ((3) / (4 * df - 1))
We are uncertain how to best estimate the dfs in our mixed-models. We considered using Kenward-Roger approximated dfs but this does not seem feasible since we only have access to parts of the raw data-sets used to derive dw and V{dw}. Potentially, another option would be to estimate the dfs via the effective sample size. This seems more feasible since the authors of primary papers provided us with the ICC related to each model. What do you think about this option?
If you have any thoughts on this, we would greatly appreciate it if you could let us know what you think. Thank you for taking the time to consider our request, and please don?t hesitate to reach out if anything is unclear.
Thank you very much and best regards,
Lena Sch?fer
On behalf of a collaborative team that additionally includes Leah Somerville (head of the Affective Neuroscience and Development Laboratory), Katherine Powers (former postdoc in the Affective Neuroscience and Development Laboratory) and Bernd Figner (Radboud University).


	[[alternative HTML version deleted]]


From d@|dhu @end|ng |rom uc@|g@ry@c@  Thu Oct 10 21:56:21 2019
From: d@|dhu @end|ng |rom uc@|g@ry@c@ (David Sidhu)
Date: Thu, 10 Oct 2019 19:56:21 +0000
Subject: [R-sig-ME] Question about interpreting interaction of effects coded
 predictors
Message-ID: <715BC51F-85E6-4A76-8309-0E2D0878E582@ucalgary.ca>

Hi There

I have run a mixed effects logistic regression with two dichotomous predictors and their interaction. These predictors were effects coded (i.e., -1, 1).
Can I simply interpret the term for the interaction that is provided by a model summary? Or, is there another step that is necessary for testing the interaction that includes an ANOVA function? (A reviewer suggested the latter.)

I have attached some code for running an analysis of the sort I?m talking about.

Thanks very much!
Dave



require(lme4) require(lmerTest) require(data.table) Subject <- rep(1:30, each = 12) Item <- rep(1:12, times = 30) IV1 <- rep(rep(c("A", "B"), each = 6), times = 10) IV2 <- rep(c("A", "B"),times = 180) DV <- sample(c(0,1), replace = TRUE, size = 360) data <- as.data.table(cbind(Subject, Item, IV1, IV2, DV)) data$IV1 <- as.factor(data$IV1) data$IV2 <- as.factor(data$IV2) data$DV <- as.factor(data$DV) contrasts(data$IV1) <- c(1, -1) contrasts(data$IV2) <- c(1, -1) m <- glmer(DV ~ IV1*IV2 + (1|Subject) + (1|Item), family = "binomial", data = data) summary(m)

---
David M. Sidhu<http://davidmsidhu.com>, PhD
Postdoctoral Associate
Department of Psychology
University of Calgary







	[[alternative HTML version deleted]]


From D@v|d@Du||y @end|ng |rom q|mrbergho|er@edu@@u  Fri Oct 11 01:34:32 2019
From: D@v|d@Du||y @end|ng |rom q|mrbergho|er@edu@@u (David Duffy)
Date: Thu, 10 Oct 2019 23:34:32 +0000
Subject: [R-sig-ME] Effect sizes for mixed-effects models
In-Reply-To: <FCB43A7B-1E0C-4E2D-A3A0-9E6160F53012@student.ru.nl>
References: <FCB43A7B-1E0C-4E2D-A3A0-9E6160F53012@student.ru.nl>
Message-ID: <9a17fdab2af544f7b3287efb1594a64e@qimrberghofer.edu.au>


> we want to derive the variance related to Cohen?s d for a mixed-subjects design with some participant conducting a task 
> only in the control condition and other participants conducting the task in the control and in the experimental condition 
> (within-subjects design).  

> [...] we only have access to parts of the raw data-sets 

Do you have the raw data or appropriate summary statistics from this mixed-subjects study? Could you get it? I think the "usual" approach would be to use a conservative lower bound for the effective sample size.

Cheers, David Duffy.

From ph||||p@@|d@y @end|ng |rom mp|@n|  Fri Oct 11 02:04:01 2019
From: ph||||p@@|d@y @end|ng |rom mp|@n| (Phillip Alday)
Date: Fri, 11 Oct 2019 10:34:01 +1030
Subject: [R-sig-ME] 
 Question about interpreting interaction of effects coded predictors
In-Reply-To: <715BC51F-85E6-4A76-8309-0E2D0878E582@ucalgary.ca>
References: <715BC51F-85E6-4A76-8309-0E2D0878E582@ucalgary.ca>
Message-ID: <ed8a7319-ffea-5bd8-1153-4d225a48fc23@mpi.nl>

Thanks for the MWE, Dave, but please try to use plain-text (instead of
HTML) formatted email because it tends to preserve the linebreaks better
on the list.

You don't need to something like an ANOVA or analysis of deviance, you
can interpret appropriately coded contrasts (like you have) directly
from the model summary.

See e.g. https://arxiv.org/abs/1807.10451

In your particular case, it's easy to show that you get the same answer
as you would with a Type II analysis of deviance:

> coef(summary(m))
               Estimate Std. Error    z value  Pr(>|z|)
(Intercept)  0.12290954  0.1069286  1.1494541 0.2503688
IV11        -0.05570847  0.1059129 -0.5259840 0.5988993
IV21        -0.10058387  0.1059290 -0.9495401 0.3423460
IV11:IV21   -0.05570841  0.1059128 -0.5259836 0.5988996

> Anova(m, type=2)
Analysis of Deviance Table (Type II Wald chisquare tests)

Response: DV
         Chisq Df Pr(>Chisq)
IV1     0.2791  1     0.5973
IV2     0.9020  1     0.3422
IV1:IV2 0.2767  1     0.5989


or even using drop1, which will do the likelihood-ratio test for you
(the other meaning of anova() in R):

> drop1(m, test="Chisq")
boundary (singular) fit: see ?isSingular
Single term deletions

Model:
DV ~ IV1 * IV2 + (1 | Subject) + (1 | Item)
        Df    AIC     LRT Pr(Chi)
<none>     508.26
IV1:IV2  1 506.53 0.27678  0.5988


One small t> drop1(m, test="Chisq")
boundary (singular) fit: see ?isSingular
Single term deletions

Model:
DV ~ IV1 * IV2 + (1 | Subject) + (1 | Item)
        Df    AIC     LRT Pr(Chi)
<none>     508.26
IV1:IV2  1 506.53 0.27678  0.5988



Two more small tips for you:

1. Don't automatically include lmerTest whenever you want to use
mixed-effects models. It doesn't actually add any extra functionality
for glmer() and the extra degrees of freedom estimation it provides for
lmer() aren't universally seen as a good thing. (The Kenward-Roger
approximation depends on inverting a large matrix and the the
Satterthwaite approximation isn't much better than just treating the t
values as z values when you have typically sized psycholinguistic datasets.)

2. Don't automatically include data.table. You don't need it for your
example. :)

Best,
Phillip

On 11/10/2019 06:26, David Sidhu wrote:
> Hi There
> 
> I have run a mixed effects logistic regression with two dichotomous predictors and their interaction. These predictors were effects coded (i.e., -1, 1).
> Can I simply interpret the term for the interaction that is provided by a model summary? Or, is there another step that is necessary for testing the interaction that includes an ANOVA function? (A reviewer suggested the latter.)
> 
> I have attached some code for running an analysis of the sort I?m talking about.
> 
> Thanks very much!
> Dave
> 
> 
> 
> require(lme4) require(lmerTest) require(data.table) Subject <- rep(1:30, each = 12) Item <- rep(1:12, times = 30) IV1 <- rep(rep(c("A", "B"), each = 6), times = 10) IV2 <- rep(c("A", "B"),times = 180) DV <- sample(c(0,1), replace = TRUE, size = 360) data <- as.data.table(cbind(Subject, Item, IV1, IV2, DV)) data$IV1 <- as.factor(data$IV1) data$IV2 <- as.factor(data$IV2) data$DV <- as.factor(data$DV) contrasts(data$IV1) <- c(1, -1) contrasts(data$IV2) <- c(1, -1) m <- glmer(DV ~ IV1*IV2 + (1|Subject) + (1|Item), family = "binomial", data = data) summary(m)
> 
> ---
> David M. Sidhu<http://davidmsidhu.com>, PhD
> Postdoctoral Associate
> Department of Psychology
> University of Calgary
> 
> 
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From ph||||p@@|d@y @end|ng |rom mp|@n|  Fri Oct 11 02:40:27 2019
From: ph||||p@@|d@y @end|ng |rom mp|@n| (Phillip Alday)
Date: Fri, 11 Oct 2019 11:10:27 +1030
Subject: [R-sig-ME] Large mixed & crossed-effect model looking at
 educational spending on crime rates with error messages
In-Reply-To: <5D8D81F7-D024-4DDD-A2E2-AAD974221912@UCSD.edu>
References: <3969F144-2738-4733-B9E2-EDA2E3375418@UCSD.edu>
 <CAJuCY5xNAMirpyR+qy=Li4kGv-ys97AEis=fRyRgDf4WP+6RaQ@mail.gmail.com>
 <1AD83B84-C39B-4EE8-B50F-2E988419054C@UCSD.edu>
 <CAJuCY5yZhtkNrPf1rriStgR0Fp=NgN2bD2r6rVSUG9NV0sX6Sw@mail.gmail.com>
 <CD530BD0-2D53-4EB3-B003-5596665D7A86@UCSD.edu>
 <CAJuCY5wL4V4Fpgu39A8d_SZAazDcfCnwc1QU7piTffBkuGuuQQ@mail.gmail.com>
 <DBAF8D75-2563-4A00-B5BA-0107D2625946@UCSD.edu>
 <CABghstQdPD_vYBW5vbB1xVLnSWCmGvd5iRd5pb9efMYYdt=DJQ@mail.gmail.com>
 <23b89902-4345-5aec-299d-48d194591bed@mpi.nl>
 <61BCB906-022A-473D-BA01-583E961E3B41@UCSD.edu>
 <a278d0c3-f462-8e50-64a4-3b8d40f04986@mpi.nl>
 <0B21F4E6-E765-4CF5-B2B3-4B905376C959@UCSD.edu>
 <1741bbc0-830b-0807-6756-bf3dcd9aab75@mpi.nl>
 <5D8D81F7-D024-4DDD-A2E2-AAD974221912@UCSD.edu>
Message-ID: <dbafa5fc-b4e3-1a15-c192-6fbe95619cdc@mpi.nl>



On 09/10/2019 08:19, Ades, James wrote:
> Thanks, Philip.
> 
> I took some time to read more about covariance/multicollinearity. I
> found two papers pretty informative/easy to digest, for anyone
> interested in or struggling with this topic. The second papers concerns
> mostly hierarchical models.
> 
> https://www.ncbi.nlm.nih.gov/pubmed/23017962
> https://www.sciencedirect.com/science/article/pii/S0049089X15000885?via%3Dihub
> 
> I?ve had some experience with BRMS, so maybe that is something to try in
> order to implement priors. I also looked into linear growth curve analysis.
> 
> Re my last question, I think you understand most of what I?m saying.
> Referring to my dataset, crime counts are the dv. If a police department
> reports crime counts for some years but not for others, would that be
> imputable? As it is now, I?ve filtered out all rows for which there is
> no crime count, under the impression that there was little to be done
> for predictors/explanatory variables with no dv. Am I mistaken?

Imputation really isn't my area of expertise, but I think you predict
unseen DVs, not impute them.

> 
> I know that lme4 drops incomplete cases (winnowing the sample), but is
> the information for some of these predictors imputable, such that I
> maintain more rows that do have a dependent variable?let?s say I?m
> missing one value for median income for one city for one year?lme4 would
> remove this entire row; but is that information imputable, such that
> lme4 doesn?t remove that row?

lme4 won't do the imputation for you. Check out the mice package. brms
also has support doing imputation as part of its model with the mi()
function. See ?brmsformula.


> Re the unreliability of Nelder Mead?what?s weird is that whereas the
> lme4 default optimizer fails to converge, Nelder Mead does. I know that
> that doesn?t necessarily imply accuracy, but in such situations would
> the results of Nelder Mead be questionable? 

No, there's simply no free lunch when it comes to optimization. Some
optimizers will work better in some situations. See ?convergence and
?allFit and make sure to check out how well the converged model actual
fits your data.


> Would it be better to opt
> for a simpler model, perhaps with a random slope without intercepts that
> works with the default--something like ( 0 + year | place_id )?

I would tend to keep random intercepts in the model. Check out ?rePCA
and the following articles for some ideas about how to simplify your model:

https://arxiv.org/abs/1506.04967

https://nextjournal.com/dmbates/complexity-in-fitting-linear-mixed-models/

Phillip

> 
> As always, thanks much!
> 
> James
> 
> 
> 
>> On Oct 1, 2019, at 12:15 AM, Phillip Alday <phillip.alday at mpi.nl
>> <mailto:phillip.alday at mpi.nl>> wrote:
>>
>>
>>
>> On 01/10/2019 08:25, Ades, James wrote:
>> I see what you?re saying
>>> with regard to the actual source of variation, but can?t it be the case
>>> that one thing isn?t vaguely related to another, and that the actual
>>> source of variation is the two variables. In such a case, aren?t there
>>> ways to parse that covariance, such that you gain a better understanding
>>> of each variable?s effect on variance??
>>
>> This is non trivial in the general case. If you know something about the
>> latent structure, then things like structural equation models may help,
>> see e.g.
>>
>> https://www.johnmyleswhite.com/notebook/2016/02/25/a-variant-on-statistically-controlling-for-confounding-constructs-is-harder-than-you-think/
>>
>> which provides an alternative presentation of
>>
>> Westfall, J. & Yarkoni, T. (2016): Statistically Controlling for
>> Confounding Constructs Is Harder than You Think PLoS ONE, , 11 , 1-22
>>
>> Remember, linear regression -- fixed or mixed effect -- isn't sufficient
>> to make causal conclusions without additional assumptions. The issue
>> with collinearity (as long as its not perfect / leads to rank
>> deficiency) is not so much in the estimates as in the standard errors,
>> which get inflated by the covariance. There are several classical
>> approaches to dealing with this (such as residualization), but they all
>> have pros and cons. (Oversimplifying a bit) Residualization for example
>> attributes only the residual variance from the first predictor to the
>> second predictor -- i.e. all of the shared variance is attributed to the
>> first predictor. Regularized regression (e.g. LASSO, ridge, elastic net)
>> may help, especially with prediction. Equivalently, in a Bayesian
>> framework, appropriate choice of priors may help to pull the estimates
>> apart.
>>
>> But all of these comments aren't specific to the mixed-model case, so
>> that opens up the set of resources you can turn to. ;)
>>
>>
>>> Also, just want to make sure: if you don?t have a dependent observation
>>> for a given condition, you would have to remove that entire row,
>>> correct? The mixed-model wouldn?t be able to work around that? This is
>>> what i learned in stats class, but if I?m doing this wrong, I think this
>>> might also be affecting correlation.
>>
>> If I understand you correctly, you're asking what happens when your
>> response variable (y) is missing for a given combination of predictors
>> (x's)? Depending on the exact structure of the missing data, multiple
>> imputation might help you there, but generally if a particular case
>> never occurs (say "12 hours of sunlight but with winter temperatures"
>> for a model predicting plant growth derived from observations taken
>> outside but which you want to use to predict in a greenhouse), it's hard
>> to make inferences about that complete interaction. lme4 by default
>> drops incomplete cases (i.e. any rows in the dataframe where there is an
>> NA *for variables used in the model*).
>>
>> Phillip
>>
>>>
>>> Thanks, Philip!
>>>
>>> James
>>>
>>>
>>>
>>>> On Sep 29, 2019, at 3:06 AM, Phillip Alday <phillip.alday at mpi.nl
>>>> <mailto:phillip.alday at mpi.nl>
>>>> <mailto:phillip.alday at mpi.nl>> wrote:
>>>>
>>>> The default optimizer in lme4 is the default for a reason. :) While
>>>> there's no free lunch or single best optimizer for every situation, the
>>>> default was chosen based on our experience about which optimizer works
>>>> performs well across a wide range of models and datasets.
>>>>
>>>> Multicollinearity in mixed-effects models works pretty much exactly the
>>>> same way as it does in fixed-effects (i.e. regular/not mixed) regression
>>>> and so the way it's addressed (converting to PC basis, residualization,
>>>> etc.) In your case, you could omit one race and then the remaining races
>>>> will be linearly independent, albeit still correlated with another. This
>>>> correlation isn't great and will inflate your standard errors, but then
>>>> at least your design matrix won't be rank deficient.
>>>>
>>>> Regarding year-spending: Are you using 'correlated' in a strict sense,
>>>> e.g. that spending tends to go up year-by-year? Or do just mean that
>>>> including spending in the model changes the effect of year? (I think the
>>>> latter weakly implies the former, but it's a different perspective.)
>>>> Either way, the changing coefficient isn't terribly surprising. In
>>>> 'human' terms: if you don't have the option of attributing something to
>>>> the actual source of variation, but you do have something that is
>>>> vaguely related to it, then you will attribute it to that. However, if
>>>> you're ever given the chance to attribute it to the actual source, you
>>>> will do that and your attribution to the vaguely-related thing will
>>>> change.
>>>>
>>>> Best,
>>>> Phillip
>>>>
>>>> On 29/09/2019 03:20, Ades, James wrote:
>>>>> Thanks, Ben and Philip!
>>>>>
>>>>> So I think I was conflating having a continuous dependent variable,
>>>>> which could then be broken up into different categories with dummy
>>>>> variables (for instance, if I wanted to look at how wealth affects the
>>>>> distribution of race in an area, I could create a model like lmer(total
>>>>> people ~ race + per capita income + ?) with creating something similar
>>>>> with a fixed factor (which I guess can?t be done).
>>>>>
>>>>> I did try running the variables independently, which worked, I just
>>>>> thought there was a way to combine races, and then per that logic,
>>>>> thought that since race variables repeated within place (city/town), I
>>>>> could nest it within PLACE_ID. But realized that the percent race as a
>>>>> fixed effect (as an output) didn?t really make sense?hence my
>>>>> confusion.
>>>>> So I guess somewhere in there my logic was afoul.
>>>>>
>>>>> Regarding Nelmed-Mead: that?s odd...I recall reading somewhere that it
>>>>> was actually quicker and more likely to converge. Good to know. I read
>>>>> through the lme4 package details here:
>>>>> https://cran.r-project.org/web/packages/lme4/lme4.pdf Would you
>>>>> recommend then optimx? Or Nloptr/bobyqa? (which I think is the
>>>>> default).
>>>>>
>>>>> Regarding multicollinearity: is there an article you could send me on
>>>>> dealing with multicollinearity in mixed-effect models? I?ve perused the
>>>>> internet, but haven?t been able to find a great how to and dealing with
>>>>> it, such that you can better parse the effects of different
>>>>> variables (I
>>>>> know that one can use PCA, but that fundamentally alters the process,
>>>>> and isn?t there a way of averaging variables such that you minimize
>>>>> collinearity?).
>>>>>
>>>>> One thing I?m currently dealing with in my model is that year as a
>>>>> fixed
>>>>> effect is correlated with a district?s spending, such that if I remove
>>>>> year, district spending has a negative effect on crime, but including
>>>>> year as a fixed effect alters the spending regression coefficient to be
>>>>> positive (just north of zero). Though here, specifically, I?m not sure
>>>>> if this is technically collinearity, or if time as a fixed factor is
>>>>> merely controlling, here, for crime change over time, where a model
>>>>> without year as a fixed factor would be looking at the effect of
>>>>> district spending on crime (similar to a model where years are averaged
>>>>> together). Does that make sense? Is that interpretation accurate?
>>>>>
>>>>> Thanks much!
>>>>>
>>>>> James
>>>>>
>>>>>
>>>>>> On Sep 28, 2019, at 8:09 AM, Phillip Alday <phillip.alday at mpi.nl
>>>>>> <mailto:phillip.alday at mpi.nl>
>>>>>> <mailto:phillip.alday at mpi.nl>
>>>>>> <mailto:phillip.alday at mpi.nl>> wrote:
>>>>>>
>>>>>>> ink the answer to your proximal question about per_race is that
>>>>>>> you would need five *different* numerical varia
>


From ph||||p@@|d@y @end|ng |rom mp|@n|  Fri Oct 11 08:05:46 2019
From: ph||||p@@|d@y @end|ng |rom mp|@n| (Phillip Alday)
Date: Fri, 11 Oct 2019 16:35:46 +1030
Subject: [R-sig-ME] Effect sizes for mixed-effects models
In-Reply-To: <FCB43A7B-1E0C-4E2D-A3A0-9E6160F53012@student.ru.nl>
References: <FCB43A7B-1E0C-4E2D-A3A0-9E6160F53012@student.ru.nl>
Message-ID: <8c39f98b-c636-afc7-8244-dd4655c0607a@mpi.nl>

On 10/10/2019 23:41, Sch?fer, L. (Lena) wrote:
> We are uncertain how to best estimate the dfs in our mixed-models. We considered using Kenward-Roger approximated dfs but this does not seem feasible since we only have access to parts of the raw data-sets used to derive dw and V{dw}.


You have 30-60 observations per participant, but how many participants?
If it's the typical 20+ in psychology, I would use the easiest
approximation of all for denominator degrees of freedom: treat them as
infinite, i.e. treat the t values as z values. The Kenward-Roger
approximation really doesn't really change your results for non trivial
datasets and the implementation in R (in pbkrtest, which lmerTest and
car::Anova() use internally) computes a matrix inverse for an n x n
matrix, where n is the total number of observations. This is
computationally painful for non trivial n with minimal benefit.

Best (from next door at the MPI),

Phillip


From gu|||@ume@|mon@@2 @end|ng |rom gm@||@com  Fri Oct 11 12:00:31 2019
From: gu|||@ume@|mon@@2 @end|ng |rom gm@||@com (Guillaume Adeux)
Date: Fri, 11 Oct 2019 12:00:31 +0200
Subject: [R-sig-ME] glmmTMB hurdle model interpretation + post hoc with
 emmeans
Message-ID: <CAENiVe9RmPoGm62xvtBSf0kXdWM7pjq5+UUFt2oNLNP7BjzsGg@mail.gmail.com>

Hi everyone,

I'm trying to analyze the influence of tillage regimes (CT:conventional,
RT:reduced, NT, no-till) on the density of blackgrass (Alopecurus
myosuroides). The thing with this species (as many other weed species), is
that it is often observed in patches (aggregated distribution). Therefore,
even in plots where the weed is present, a lot of quadrats will have 0
values (17 out of 48 observations). Based on these elements, hurdle models
seem like an appropriate way to distinguish presence/absence and density
when present (am I mistaking?).

My experiment was the following:
- 4 blocks
- 3 tillage strips within each block (CT, RT, NT)
- 4 pseudoreplications within each strip

#Reproducing the data frame#
block=c(rep(c(rep("B1",4),rep("B2",4)),3),rep(c(rep("B3",4),rep("B4",4)),3))

tillage=rep(c(rep("CT",8),rep("NT",8),rep("RT",8)),2)
surf_quadrat=as.numeric(as.character(rep(0.36,48)))
ALOMY=as.numeric(c(0,1,1,3,3,1,1,14,0,0,4,0,0,0,0,26,11,1,0,6,2,3,0,11,1,0,0,2,1,0,1,20,4,0,0,1,0,3,34,150,5,0,0,1,3,5,97,135))
weed_density=data.frame(block=block,tillage=tillage,surf_quadrat=surf_quadrat,ALOMY=ALOMY)

#Required packages#
require("glmmTMB")
require("lme4")
require("emmeans")

#Is there truly excess zeroes?#
sum(weed_density$ALOMY<1) #17
sum(weed_density$ALOMY>1) #21
mod_ALOMYpoisson=glmer(ALOMY~block+tillage+offset(log(surf_quadrat))+(1|block:tillage),data=weed_density,family="poisson")
mu <- predict(mod_ALOMYpoisson, type = "response")
exp <- sum(dpois(x = 0, lambda = mu))
round(exp)
    # 7 zeroes are predicted instead of 17

#Comparison between zero inflated and hurdle#
mod_ALOMY_zipoisson0=glmmTMB(ALOMY~block+tillage+offset(log(surf_quadrat))+(1|
block
:tillage),data=weed_density,family=list(family="poisson",link="log"),ziformula=~1)
mod_ALOMY_zipoisson=glmmTMB(ALOMY~ block
+tillage+offset(log(surf_quadrat))+(1| block
:tillage),data=weed_density,family=list(family="poisson",link="log"),ziformula=~
block +tillage)
mod_ALOMY_zineg1=glmmTMB(ALOMY~ block
+tillage+offset(log(surf_quadrat))+(1| block
:tillage),data=weed_density,family=list(family="nbinom1",link="log"),ziformula=~
block +tillage)
mod_ALOMY_zineg2=glmmTMB(ALOMY~ block
+tillage+offset(log(surf_quadrat))+(1| block
:tillage),data=weed_density,family=list(family="nbinom2",link="log"),ziformula=~
block +tillage)
mod_ALOMY_hurdlepois=glmmTMB(ALOMY~ block
+tillage+offset(log(surf_quadrat))+(1| block
:tillage),data=weed_density,family=list(family="truncated_poisson",link="log"),ziformula=~
block +tillage)
mod_ALOMY_hurdleneg2=glmmTMB(ALOMY~ block
+tillage+offset(log(surf_quadrat))+(1| block
:tillage),data=weed_density,family=list(family="truncated_nbinom2",link="log"),ziformula=~block
+tillage)            #truncated_nbinom1 doesn't converge

AIC(mod_ALOMYpoisson,mod_ALOMY_zipoisson0,mod_ALOMY_zipoisson,mod_ALOMY_zineg1,mod_ALOMY_zineg2,mod_ALOMY_hurdlepois,mod_ALOMY_hurdleneg2)
mod_ALOMY_hurdleneg2 # seems to be the best fit

#Significance of tillage effects#
Anova(mod_ALOMY_hurdleneg2,type="III")

#Post hoc analysis#
emmeans(mod_ALOMY_hurdleneg2,~tillage,offset=1,type="response")
pairs(emmeans(mod_ALOMY_hurdleneg2,~tillage)) # pairwise contrasts are on
the verge of significance
cld(emmeans(mod_ALOMY_hurdleneg2,~tillage))

So based on this script, emmeans states that blackgrass density is 7.5
plants/m? in CT, 48 in NT and 40 in RT. The ranking is coherent with the
litterature and field observations.
Is the conclusion this simple or am I overlooking the two components of the
model (conditional, zero inflation). Should any other aspects of the model
be presented for scientific publication (i.e. predictions taking into
account different components of the model)?

Any documentation and/or help is welcome :).

Thank you once again for your help.

Sincerely,

Guillaume ADEUX

	[[alternative HTML version deleted]]


From |@v@d@@||k @end|ng |rom |et@ru@n|  Fri Oct 11 12:06:50 2019
From: |@v@d@@||k @end|ng |rom |et@ru@n| (Slik, F.W.P. van der)
Date: Fri, 11 Oct 2019 10:06:50 +0000
Subject: [R-sig-ME] ggplot, loess function without 95%CI option
Message-ID: <1aabca0e8fde490195ec1ebd31aa0ca3@EXPRD07.hosting.ru.nl>

Hi listers,

In ggplot, the loess function is only available with SE. The 95%CI option (level=.95) is unavailable, unfortunately.
I think there is demand for such an option. Well, at least I would like to make use of it.
Several contributors to stackoverflow have expressed their need and some of them have tried to program a workaround for this issue:
https://stackoverflow.com/questions/19643234/fill-region-between-two-loess-smoothed-lines-in-r-with-ggplot,
https://stackoverflow.com/questions/44736600/confidence-interval-band-for-a-loess-to-replicate-geom-smooth
Unfortunately, their workarounds have their shortcomings.

Has anyone a solution for the missing 95%CI option for loess in ggplot? It would be wonderful if the 95%CI band would look like the se band in the ggplot.
Thanks in advance.

Cheers, Frans van der Slik


	[[alternative HTML version deleted]]


From |@@ch@|er @end|ng |rom @tudent@ru@n|  Fri Oct 11 17:45:18 2019
From: |@@ch@|er @end|ng |rom @tudent@ru@n| (=?utf-8?B?U2Now6RmZXIsIEwuIChMZW5hKQ==?=)
Date: Fri, 11 Oct 2019 15:45:18 +0000
Subject: [R-sig-ME] Effect sizes for mixed-effects models
In-Reply-To: <8c39f98b-c636-afc7-8244-dd4655c0607a@mpi.nl>
References: <FCB43A7B-1E0C-4E2D-A3A0-9E6160F53012@student.ru.nl>
 <8c39f98b-c636-afc7-8244-dd4655c0607a@mpi.nl>
Message-ID: <41E833D5-4561-4E88-A0A5-27B6092AC2CE@student.ru.nl>

Hi Phillip, 

Thank you for your response; this was very helpful. The studies analyzed using mixed-effects models have a minimum of 24 participants. Setting the degrees of freedom equal to infinity (i.e., Cohen?s d = Hedge?s g) seems to be justifiable in that case. 

Thanks, 
Lena 



> Am 11.10.2019 um 02:05 schrieb Phillip Alday <phillip.alday at mpi.nl>:
> 
> On 10/10/2019 23:41, Sch?fer, L. (Lena) wrote:
>> We are uncertain how to best estimate the dfs in our mixed-models. We considered using Kenward-Roger approximated dfs but this does not seem feasible since we only have access to parts of the raw data-sets used to derive dw and V{dw}.
> 
> 
> You have 30-60 observations per participant, but how many participants?
> If it's the typical 20+ in psychology, I would use the easiest
> approximation of all for denominator degrees of freedom: treat them as
> infinite, i.e. treat the t values as z values. The Kenward-Roger
> approximation really doesn't really change your results for non trivial
> datasets and the implementation in R (in pbkrtest, which lmerTest and
> car::Anova() use internally) computes a matrix inverse for an n x n
> matrix, where n is the total number of observations. This is
> computationally painful for non trivial n with minimal benefit.
> 
> Best (from next door at the MPI),
> 
> Phillip


From |@@ch@|er @end|ng |rom @tudent@ru@n|  Fri Oct 11 18:01:30 2019
From: |@@ch@|er @end|ng |rom @tudent@ru@n| (=?utf-8?B?U2Now6RmZXIsIEwuIChMZW5hKQ==?=)
Date: Fri, 11 Oct 2019 16:01:30 +0000
Subject: [R-sig-ME] Effect sizes for mixed-effects models
In-Reply-To: <9a17fdab2af544f7b3287efb1594a64e@qimrberghofer.edu.au>
References: <FCB43A7B-1E0C-4E2D-A3A0-9E6160F53012@student.ru.nl>
 <9a17fdab2af544f7b3287efb1594a64e@qimrberghofer.edu.au>
Message-ID: <470E0E7B-86B8-4DA6-803A-AB3B045B00A1@student.ru.nl>

Hi David,

Thank you for your response! We have the raw data for some studies but only info on the sample/cluster size, the lme4 output and the respective ICC for other studies. Since we are conducting a meta-analysis, we cannot get access to all data-sets (eg., problems with data protection, unpublished data-sets). However, using the info on the sample and cluster size and the ICC, we can derive the effective sample size (Aarts, Verhage, Veenvliet, Dolan, & van der Sluis, 2014) related to the study.

I am not sure what you are referring to with *lower bound for the effective sample size*. Is this value calculated using another formula or is it essentially equal to the number of participants (as suggested by Phillip Alday)?

Thank you for a clarification!

Best,
Lena



Am 10.10.2019 um 19:34 schrieb David Duffy <David.Duffy at qimrberghofer.edu.au<mailto:David.Duffy at qimrberghofer.edu.au>>:


we want to derive the variance related to Cohen?s d for a mixed-subjects design with some participant conducting a task
only in the control condition and other participants conducting the task in the control and in the experimental condition
(within-subjects design).

[...] we only have access to parts of the raw data-sets

Do you have the raw data or appropriate summary statistics from this mixed-subjects study? Could you get it? I think the "usual" approach would be to use a conservative lower bound for the effective sample size.

Cheers, David Duffy.


	[[alternative HTML version deleted]]


From |@|@n @end|ng |rom vu@n|  Mon Oct 14 17:08:06 2019
From: |@|@n @end|ng |rom vu@n| (Fan, L.)
Date: Mon, 14 Oct 2019 15:08:06 +0000
Subject: [R-sig-ME] Models and Power Analysis for Within-subject Design in
 LMER
Message-ID: <0f262bf6f1624850b747d37cfa7d0780@vu.nl>

Hi,
This is Lei from VU Amsterdam.
Recently I am proposing a new within-subject study based on my former results of a between-subject one. As planning for the proposal, I found it is a little bit confuse in creating the model.
In the first between-subject study, I used a basic model like this with some other random slopes:
Emotion Value ~ Emotion Type * WTR + (1|Subject) + (1|Scenario)
Each participant would have one WTR index and finish 2 emotion assessments based on one single scenario from the pool.  The EV and ET were created as repeated measure format originally from the emotion assessments. The effect we focused on is the interaction.
In the new study, we would like to make the study within-subject, by asking the participants to repeat the procedure for 3 times with different scenarios and WTR conditions (here the conditions are as a manipulation for maximum the rage of the WTRs, not as an IV). Then, here comes the questions:
1. I tried to draw the model for the new study, but it seemed to be the same as the between-subject one. Does it mean that I make mistakes in creating the model?
2. Using the current model for calculating the sample size, the result should be the same for the required observations as for the between-subject design (model never changed). Should not it be smaller as the design is within-subject? The only possibility is the model did not count the within part. How can I make it work?
3. As for the between-subject study, we used a data simulation approach to calculate the sample size. Here, as it is a follow-up study, is there some other more convincing way to conduct the a-prior power analysis?

Thanks a lot in advance!

Best,
Lei Fan

	[[alternative HTML version deleted]]


From ph||||p@@|d@y @end|ng |rom mp|@n|  Tue Oct 15 06:54:50 2019
From: ph||||p@@|d@y @end|ng |rom mp|@n| (Phillip Alday)
Date: Tue, 15 Oct 2019 15:24:50 +1030
Subject: [R-sig-ME] ggplot, loess function without 95%CI option
In-Reply-To: <1aabca0e8fde490195ec1ebd31aa0ca3@EXPRD07.hosting.ru.nl>
References: <1aabca0e8fde490195ec1ebd31aa0ca3@EXPRD07.hosting.ru.nl>
Message-ID: <c171be80-b9d7-f64e-f322-329b54d90006@mpi.nl>

This isn't really the appropriate forum for that question because the
question has nothing to do with mixed-effects models.

That said, it really helps to just read the documentation:

https://www.rdocumentation.org/packages/ggplot2/versions/3.2.1/topics/geom_smooth

The default for loess in modern ggplot2 is indeed the 95% CI. You can
adjust this with the level option, e.g.

library(ggplot2)
ggplot(mtcars, aes(x = mpg, y = hp)) +
? geom_point() +
? geom_smooth(method = 'loess', fill='darkred', level=0.68) +

? geom_smooth(method = 'loess')

Note that level=0.68 corresponds to the SE case and provides a shaded
area about half as wide as the the default case, which is in line with
the Wald approximation that 95% CI = ?2 * SE.


Best,

Phillip


On 11/10/2019 20:36, Slik, F.W.P. van der wrote:
> Hi listers,
>
> In ggplot, the loess function is only available with SE. The 95%CI option (level=.95) is unavailable, unfortunately.
> I think there is demand for such an option. Well, at least I would like to make use of it.
> Several contributors to stackoverflow have expressed their need and some of them have tried to program a workaround for this issue:
> https://stackoverflow.com/questions/19643234/fill-region-between-two-loess-smoothed-lines-in-r-with-ggplot,
> https://stackoverflow.com/questions/44736600/confidence-interval-band-for-a-loess-to-replicate-geom-smooth
> Unfortunately, their workarounds have their shortcomings.
>
> Has anyone a solution for the missing 95%CI option for loess in ggplot? It would be wonderful if the 95%CI band would look like the se band in the ggplot.
> Thanks in advance.
>
> Cheers, Frans van der Slik
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From cperk @end|ng |rom terpm@||@umd@edu  Tue Oct 15 15:12:54 2019
From: cperk @end|ng |rom terpm@||@umd@edu (Carrie Perkins)
Date: Tue, 15 Oct 2019 09:12:54 -0400
Subject: [R-sig-ME] most conservative df for mixed effects anova
Message-ID: <CAPtr_T4Gn5zhD6xtvRR9ckTV+=nhDSi6xG_v0qiXUg2aw28s-w@mail.gmail.com>

Hello!

I have data from an experiment and would like to run an anova with fixed
and random effects in R. Here is information on the data:

In the experiment, 3 replicates of 48 plant genotypes were planted into
each of 4 salinity treatments. This resulted in a total of 144 individuals
per treatment, amounting to a grand total of 576 individuals in the whole
experiment. Within each treatment, random sets of 24 plants were grouped
into a total of 6 pools to make it easier to monitor salinity levels. I
would like to model these pools as random Experimental Units.

I would like to make Experimental Unit the random effect and look at the
treatment X genotype interaction as fixed effects.

lmer_model_3 <- aov(Y~Genotype*Treatment + Error(1|Experimental Unit),
data=dataframe)

What would be the most conservative method for calculating degrees of
freedom for the random effects term of an anova? When I've tried
researching this question online, I find a lot of information on
calculating degrees of freedom for basic 1- and 2-way anovas (which I
understand) but I can't find clear guidance on how to calculate the degrees
of freedom for anovas with random effects.

Thank you!

Sincerely,
Carrie Perkins

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Wed Oct 16 09:31:14 2019
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Wed, 16 Oct 2019 09:31:14 +0200
Subject: [R-sig-ME] most conservative df for mixed effects anova
In-Reply-To: <CAPtr_T4Gn5zhD6xtvRR9ckTV+=nhDSi6xG_v0qiXUg2aw28s-w@mail.gmail.com>
References: <CAPtr_T4Gn5zhD6xtvRR9ckTV+=nhDSi6xG_v0qiXUg2aw28s-w@mail.gmail.com>
Message-ID: <CAJuCY5ydZvPE6w9cg1uuyPMTD=2_BGyKVARokVa6vxnhLoWSJQ@mail.gmail.com>

Dear Carrie,

The most conservative number IMHO is the sum of the number fixed effects
parameters and the number of random effects parameters (in case of a random
intercept: 1 level = 1 parameter). Het most liberate number would replace
the number random effects parameters with the number of random effect
hyperparameters (a random intercept = 1 variance = 1 hyperparameter).

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op di 15 okt. 2019 om 15:20 schreef Carrie Perkins <cperk at terpmail.umd.edu>:

> Hello!
>
> I have data from an experiment and would like to run an anova with fixed
> and random effects in R. Here is information on the data:
>
> In the experiment, 3 replicates of 48 plant genotypes were planted into
> each of 4 salinity treatments. This resulted in a total of 144 individuals
> per treatment, amounting to a grand total of 576 individuals in the whole
> experiment. Within each treatment, random sets of 24 plants were grouped
> into a total of 6 pools to make it easier to monitor salinity levels. I
> would like to model these pools as random Experimental Units.
>
> I would like to make Experimental Unit the random effect and look at the
> treatment X genotype interaction as fixed effects.
>
> lmer_model_3 <- aov(Y~Genotype*Treatment + Error(1|Experimental Unit),
> data=dataframe)
>
> What would be the most conservative method for calculating degrees of
> freedom for the random effects term of an anova? When I've tried
> researching this question online, I find a lot of information on
> calculating degrees of freedom for basic 1- and 2-way anovas (which I
> understand) but I can't find clear guidance on how to calculate the degrees
> of freedom for anovas with random effects.
>
> Thank you!
>
> Sincerely,
> Carrie Perkins
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From ntuzov @end|ng |rom ntuzov@com  Wed Oct 16 15:51:10 2019
From: ntuzov @end|ng |rom ntuzov@com (Nik Tuzov)
Date: Wed, 16 Oct 2019 13:51:10 +0000 (UTC)
Subject: [R-sig-ME] most conservative df for mixed effects anova (Carrie
 Perkins)
References: <738130388.1575956.1571233870040.ref@mail.yahoo.com>
Message-ID: <738130388.1575956.1571233870040@mail.yahoo.com>

 Hello Carrie:
Strictly speaking, the term conservative or aggressive should apply to the p-values rather than to the degrees of freedom.I assume you are asking what approach generates the largest p-value for your fixed effect of interest.In theory, one can't answer that question in advance.??
If methods X and Y result in n and m df for the error term, where n > m, it doesn't imply that X will produce a smaller p-value than Y,even though it's often in case in practice.
That being said, a method that is likely to be conservative should have df <= (count of experimental units less the count of fixedparameters in the model) <= (count of experimental units less one).
Regards,Nik Tuzov





    On Wednesday, October 16, 2019, 5:02:31 AM CDT, r-sig-mixed-models-request at r-project.org <r-sig-mixed-models-request at r-project.org> wrote:  
 
 Send R-sig-mixed-models mailing list submissions to
??? r-sig-mixed-models at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
??? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
or, via email, send a message with subject or body 'help' to
??? r-sig-mixed-models-request at r-project.org

You can reach the person managing the list at
??? r-sig-mixed-models-owner at r-project.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-mixed-models digest..."


Today's Topics:

? 1. most conservative df for mixed effects anova (Carrie Perkins)
? 2. Re: most conservative df for mixed effects anova
? ? ? (Thierry Onkelinx)

----------------------------------------------------------------------

Message: 1
Date: Tue, 15 Oct 2019 09:12:54 -0400
From: Carrie Perkins <cperk at terpmail.umd.edu>
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] most conservative df for mixed effects anova
Message-ID:
??? <CAPtr_T4Gn5zhD6xtvRR9ckTV+=nhDSi6xG_v0qiXUg2aw28s-w at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

Hello!

I have data from an experiment and would like to run an anova with fixed
and random effects in R. Here is information on the data:

In the experiment, 3 replicates of 48 plant genotypes were planted into
each of 4 salinity treatments. This resulted in a total of 144 individuals
per treatment, amounting to a grand total of 576 individuals in the whole
experiment. Within each treatment, random sets of 24 plants were grouped
into a total of 6 pools to make it easier to monitor salinity levels. I
would like to model these pools as random Experimental Units.

I would like to make Experimental Unit the random effect and look at the
treatment X genotype interaction as fixed effects.

lmer_model_3 <- aov(Y~Genotype*Treatment + Error(1|Experimental Unit),
data=dataframe)

What would be the most conservative method for calculating degrees of
freedom for the random effects term of an anova? When I've tried
researching this question online, I find a lot of information on
calculating degrees of freedom for basic 1- and 2-way anovas (which I
understand) but I can't find clear guidance on how to calculate the degrees
of freedom for anovas with random effects.

Thank you!

Sincerely,
Carrie Perkins

??? [[alternative HTML version deleted]]




------------------------------

Message: 2
Date: Wed, 16 Oct 2019 09:31:14 +0200
From: Thierry Onkelinx <thierry.onkelinx at inbo.be>
To: Carrie Perkins <cperk at terpmail.umd.edu>
Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] most conservative df for mixed effects anova
Message-ID:
??? <CAJuCY5ydZvPE6w9cg1uuyPMTD=2_BGyKVARokVa6vxnhLoWSJQ at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

Dear Carrie,

The most conservative number IMHO is the sum of the number fixed effects
parameters and the number of random effects parameters (in case of a random
intercept: 1 level = 1 parameter). Het most liberate number would replace
the number random effects parameters with the number of random effect
hyperparameters (a random intercept = 1 variance = 1 hyperparameter).

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op di 15 okt. 2019 om 15:20 schreef Carrie Perkins <cperk at terpmail.umd.edu>:

> Hello!
>
> I have data from an experiment and would like to run an anova with fixed
> and random effects in R. Here is information on the data:
>
> In the experiment, 3 replicates of 48 plant genotypes were planted into
> each of 4 salinity treatments. This resulted in a total of 144 individuals
> per treatment, amounting to a grand total of 576 individuals in the whole
> experiment. Within each treatment, random sets of 24 plants were grouped
> into a total of 6 pools to make it easier to monitor salinity levels. I
> would like to model these pools as random Experimental Units.
>
> I would like to make Experimental Unit the random effect and look at the
> treatment X genotype interaction as fixed effects.
>
> lmer_model_3 <- aov(Y~Genotype*Treatment + Error(1|Experimental Unit),
> data=dataframe)
>
> What would be the most conservative method for calculating degrees of
> freedom for the random effects term of an anova? When I've tried
> researching this question online, I find a lot of information on
> calculating degrees of freedom for basic 1- and 2-way anovas (which I
> understand) but I can't find clear guidance on how to calculate the degrees
> of freedom for anovas with random effects.
>
> Thank you!
>
> Sincerely,
> Carrie Perkins
>
>? ? ? ? [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

??? [[alternative HTML version deleted]]




------------------------------

Subject: Digest Footer

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


------------------------------

End of R-sig-mixed-models Digest, Vol 154, Issue 17
***************************************************
  
	[[alternative HTML version deleted]]


From M@@rten@Jung @end|ng |rom m@||box@tu-dre@den@de  Wed Oct 16 16:56:33 2019
From: M@@rten@Jung @end|ng |rom m@||box@tu-dre@den@de (Maarten Jung)
Date: Wed, 16 Oct 2019 16:56:33 +0200
Subject: [R-sig-ME] 
 What is the appropriate zero-correlation parameter model
 for factors in lmer?
In-Reply-To: <CAG_uk925yU88bmdfheifETi8X-yBuV=TUQeL_SgWpidp7NBcew@mail.gmail.com>
References: <CAHr4Dyc8KsC_bgaYpPUZoTtqWr5PSZE+eRXEmvk4bsegE8Y_xA@mail.gmail.com>
 <CAG+WrEyjWpwi=wPrv08m4u3NKC8qss+oLTeWPviUE+h5BFU83Q@mail.gmail.com>
 <CAG+WrEwHX4cSvJmYaxjBBJ5SkCVqu0u-dtw-WvvMxbTzFDB9xg@mail.gmail.com>
 <CAHr4DycBbv=ukEdb+BJEjc75s4hCXVQEbZXpgpQF=Ys1oxhh+w@mail.gmail.com>
 <CAG+WrEyThCufKKM5Vuwu=3=jjkqw-q3WaY8j6Q_HAJ4fdbuHfQ@mail.gmail.com>
 <CAG+WrEwpGxDbN6Gif2TiP80XZZZPqeNgwoFZEuuvVSGp808YxA@mail.gmail.com>
 <CAG_uk925yU88bmdfheifETi8X-yBuV=TUQeL_SgWpidp7NBcew@mail.gmail.com>
Message-ID: <CAHr4DydqJUsnge0-pMh1Ua+O6gvWE7yv3yhAoMTqwinFNOpnjQ@mail.gmail.com>

Dear list,

After going through the posts [1] and [2] again, I identified the
following nesting structure (arrows indicate nesting) as the one I
want to go with for modelling some new data:

m1 -> m2a/m2b/m2c -> m3 -> m4

library("lme4")
data("Machines", package = "MEMSS")
d <- Machines
mat <- model.matrix(~ 0 + Machine, d)
A <- mat[, 1]
B <- mat[, 2]
C <- mat[, 3]

m1 <- lmer(score ~ Machine + (0 + Machine | Worker), d)

m2a <- lmer(score ~ Machine + (1 | Worker) +
                              (0 + dummy(Machine, "A") | Worker) +
                              (0 + dummy(Machine, "B") | Worker) +
                              (0 + dummy(Machine, "C") | Worker), d)

m2b <- lmer(score ~ Machine + (1 | Worker) + (0 + A + B + C || Worker), d)

m2c <- afex::lmer_alt(score ~ Machine + (1 | Worker) + (0 + Machine ||
Worker), d)

# m2a, m2b, and m2c are equivalent
all.equal(logLik(m2a), logLik(m2b), logLik(m2c))

m3 <- lmer(score ~ Machine + (1 | Worker) + (1 | Worker:Machine), d)

m4 <- lmer(score ~ Machine + (1 | Worker), d)

In my new data there are multiple observations per cell of a (at
least) 2x3 within-subjects design.
I know that m1 (denoting the two factors with f1 and f2, respectively)
would look like

lmer(y ~ f1*f2 + (1 + f1*f2 | subject), data)

and I think that m3 should be

lmer(y ~ f1*f2 + (1 | subject) + (1 | f1:subject) + (1 | f2:subject), data)

but I'm struggling to figure out what m2a (or m2b/m2c) would look like
in the (at least) 2-factorial case.
I would be grateful if someone could provide the appropriate syntax
and even more so if it would be as easy as the one in m2c (which I
think would be much simpler than the one need for m2a or m2b).

Best,
Maarten

[1] https://stat.ethz.ch/pipermail/r-sig-mixed-models/2018q2/026775.html
[2] https://stats.stackexchange.com/questions/345842/what-is-the-appropriate-zero-correlation-parameter-model-for-factors-in-lmer


From ud|t@@b@n@@|17 @end|ng |rom |mper|@|@@c@uk  Wed Oct 16 19:33:23 2019
From: ud|t@@b@n@@|17 @end|ng |rom |mper|@|@@c@uk (Bansal, Udita)
Date: Wed, 16 Oct 2019 17:33:23 +0000
Subject: [R-sig-ME] glmmTMB negbinom not working with spatial autocorrelation
Message-ID: <AE37DD61-576C-43AE-BF94-030BB9E50849@ic.ac.uk>

Hello all,

I had been running a mixed model with poisson distribution of the following type, with a spatial autocorrelation term, which works fine:

Y(count data) ~ x1 + square(x1) + x2 + square(x2) + exp( ) + (1|population/species)

I realized that my dataset has a lot of small values (mostly 1 and 2) and some large values, so that the data is highly skewed and over dispersed. So I tried to run the following negbinom1 model:

Y(count data) ~ x1 + square(x1) + x2 + square(x2) + exp( ) + (1|population/species) + ziformula = ~.

This time the model doesn?t run and says it cannot find one of the independent variables in the dataset. If I remove that variable from the model then it says so for another variable and so on. If I remove the factor for spatial autocorrelation, the model seems to work fine. Can anyone tell me what?s happening and if what I am doing is appropriate for a highly skewed and over dispersed dataset?

Thank you
Udita Bansal
Project Assistant
Centre for Ecological Sciences
Indian Institute of Science
India


	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Thu Oct 17 03:20:37 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Wed, 16 Oct 2019 21:20:37 -0400
Subject: [R-sig-ME] glmmTMB negbinom not working with spatial
 autocorrelation
In-Reply-To: <AE37DD61-576C-43AE-BF94-030BB9E50849@ic.ac.uk>
References: <AE37DD61-576C-43AE-BF94-030BB9E50849@ic.ac.uk>
Message-ID: <0e3ee30a-ca44-e76d-11d0-20aa64851446@gmail.com>



  Did you really try to fit a model with

+ ziformula = ~.

in the formula? Or do you mean that you fitted a zero-inflated negative
binomial (i.e.

  y ~ ....,  ziformula=~., family=nbinom1, ... ) ?

 This is surprising behaviour.

 * Does it work in a clean R session?
 * Does your model work with any alternative families (e.g. nbinom2) or
simplifications (e.g. leave out the zero-inflation, or make ziformula =
~1 ) ?
 * Can you post a minimal reproducible example? The code below works
(sort of -- convergence problems with the second model, but these are
related to the data and don't sound like what you described).


===
set.seed(101)
library(glmmTMB)
library(lme4)
n <- 400
dd <- expand.grid(population=letters[1:20],
                  species=LETTERS[1:10],
                  rep=seq(n/(10*20)))
dd <- transform(dd,
                b1=rnorm(n),
                b2=rnorm(n),
                x=rnorm(n),
                y=rnorm(n))
dd$eta <- simulate(~poly(b1,2)+poly(b2,2)+
                       (1|population/species),
                   family=gaussian,
                   newdata=dd,
                   newparam=list(beta=rep(1,5),
                                 theta=rep(1,2),
                                 sigma=1))[[1]]
dd$resp <- rnbinom(n, mu=exp(dd$eta), size=1)
dd <- transform(dd,
                pos=numFactor(x,y),
                group=factor(1))
model1 <- glmmTMB(resp ~ poly(b1,2) + poly(b2,2) + exp(pos + 0|group ) +
            (1|population/species), data = dd,
        family=poisson,
        verbose=TRUE)

model2 <- update(model1, family=nbinom1)


On 2019-10-16 1:33 p.m., Bansal, Udita wrote:
> Hello all,
> 
> I had been running a mixed model with poisson distribution of the following type, with a spatial autocorrelation term, which works fine:
> 
> Y(count data) ~ x1 + square(x1) + x2 + square(x2) + exp( ) + (1|population/species)
> 
> I realized that my dataset has a lot of small values (mostly 1 and 2) and some large values, so that the data is highly skewed and over dispersed. So I tried to run the following negbinom1 model:
> 
> Y(count data) ~ x1 + square(x1) + x2 + square(x2) + exp( ) + (1|population/species) + ziformula = ~.
> 
> This time the model doesn?t run and says it cannot find one of the independent variables in the dataset. If I remove that variable from the model then it says so for another variable and so on. If I remove the factor for spatial autocorrelation, the model seems to work fine. Can anyone tell me what?s happening and if what I am doing is appropriate for a highly skewed and over dispersed dataset?
> 
> Thank you
> Udita Bansal
> Project Assistant
> Centre for Ecological Sciences
> Indian Institute of Science
> India
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From r@turner @end|ng |rom @uck|@nd@@c@nz  Mon Oct 21 02:58:52 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Mon, 21 Oct 2019 13:58:52 +1300
Subject: [R-sig-ME] Error from glmer() that I do not understand.
Message-ID: <ffb0aeda-477c-100f-f130-ba5dff908a79@auckland.ac.nz>


Dear All,

In the course of some convoluted floundering around, I got a rather 
unexpected error from glmer().  Here are the data set and the call:

Xdemo <- structure(list(Dead = c(4, 26, 71, 34, 67, 68, 32, 39, 2, 15,
64, 26, 29, 0, 11, 10, 89, 87, 30, 121, 2, 9, 20, 0, 4, 30, 21,
21, 48, 54, 0, 47, 73, 87, 33, 73, 41, 39, 0, 25, 33, 19, 53,
39, 20, 3, 26, 26, 80, 79, 9, 35, 39, 40, 81, 80, 103, 7, 63,
92, 89, 40, 76, 0, 30, 29, 44, 64, 24, 72, 49, 0, 72, 73, 78,
46, 3, 21, 34, 29, 25, 37, 52, 64, 49, 0, 11, 11, 0, 17, 13,
56, 28, 3, 19, 23, 21, 26, 33), Alive = c(50, 22, 16, 6, 6, 1,
1, 0, 45, 5, 3, 0, 0, 55, 70, 18, 24, 4, 0, 0, 27, 11, 1, 35,
23, 17, 0, 0, 0, 0, 30, 12, 4, 1, 0, 0, 0, 0, 35, 29, 11, 6,
5, 2, 0, 61, 21, 7, 1, 0, 13, 0, 0, 0, 0, 0, 0, 26, 0, 0, 0,
0, 0, 26, 30, 5, 0, 0, 0, 0, 0, 74, 24, 11, 0, 0, 18, 11, 0,
0, 14, 6, 6, 8, 0, 40, 17, 9, 22, 38, 11, 2, 0, 51, 10, 5, 3,
0, 0), Rep = structure(c(6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 12L,
12L, 12L, 12L, 12L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 3L, 3L,
3L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 15L, 15L, 15L, 15L, 4L, 4L, 4L,
4L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 16L, 16L, 16L, 16L, 16L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 7L, 7L, 7L, 7L, 7L, 7L, 13L, 13L,
13L, 13L, 13L, 13L, 13L, 13L, 5L, 5L, 5L, 5L, 5L, 11L, 11L, 11L,
11L, 17L, 17L, 17L, 17L, 17L, 2L, 2L, 2L, 8L, 8L, 8L, 8L, 8L,
14L, 14L, 14L, 14L, 14L, 14L), .Label = c("1", "2", "3", "4",
"5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15",
"16", "17", "18"), class = "factor"), Dose = c(0, 15, 30, 45,
55, 65, 75, 85, 0, 30, 40, 60, 80, 0, 10, 20, 30, 40, 60, 80,
0, 10, 35, 0, 10, 20, 35, 40, 45, 50, 0, 25, 30, 35, 30, 45,
50, 55, 0, 15, 20, 25, 30, 35, 40, 0, 10, 15, 25, 35, 0, 10,
15, 18, 21, 24, 27, 0, 10, 18, 21, 24, 37, 0, 8, 12, 15, 18,
22, 20, 24, 0, 10, 14, 26, 30, 0, 4, 8, 13, 4, 8, 10, 12, 18,
0, 6, 9, 0, 3, 6, 13, 18, 0, 6, 8, 10, 12, 14), Trt = structure(c(6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L), .Label = c("16hour10deg", "16hour20deg", "16hour5deg",
"8hour10deg", "8hour20deg", "8hour5deg"), class = "factor")), class = 
"data.frame", row.names = c(1L,
2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 11L, 12L, 14L, 15L, 16L, 17L,
18L, 19L, 20L, 22L, 23L, 24L, 25L, 26L, 28L, 29L, 30L, 31L, 32L,
33L, 34L, 35L, 38L, 39L, 40L, 43L, 45L, 46L, 47L, 48L, 49L, 50L,
51L, 52L, 53L, 54L, 55L, 56L, 57L, 59L, 61L, 63L, 64L, 65L, 66L,
67L, 68L, 69L, 71L, 72L, 73L, 74L, 75L, 76L, 77L, 78L, 79L, 80L,
81L, 82L, 83L, 84L, 85L, 87L, 88L, 90L, 91L, 92L, 93L, 94L, 95L,
98L, 99L, 100L, 101L, 104L, 105L, 106L, 107L, 111L, 112L, 113L,
115L, 116L, 117L, 120L, 121L, 122L, 123L, 124L))

library(lme4)
fit <- glmer(cbind(Dead,Alive) ~ (Trt+0)/Dose +
              (Dose | Rep),
               data=Xdemo,
               family=binomial(link="logit"),nAGQ=0)

This throws the error:

> Error in pwrssUpdate(pp, resp, tol = tolPwrss, GQmat = GHrule(0L), compDev = compDev,  : 
>   (maxstephalfit) PIRLS step-halvings failed to reduce deviance in pwrssUpdate

Setting nAGQ=1 makes no difference.

The data set "Xdemo" does not seem to me to be unduly weird.  It is 
reasonably balanced, with reasonably large values of the binomial sample 
sizes.  There are 99 observations in total, which again seems to me to 
be a reasonable number.

Is there anything that I can do about this error, or do I just have to 
live with it?

Thanks for any advice.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From bbo|ker @end|ng |rom gm@||@com  Mon Oct 21 03:54:18 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sun, 20 Oct 2019 21:54:18 -0400
Subject: [R-sig-ME] Error from glmer() that I do not understand.
In-Reply-To: <ffb0aeda-477c-100f-f130-ba5dff908a79@auckland.ac.nz>
References: <ffb0aeda-477c-100f-f130-ba5dff908a79@auckland.ac.nz>
Message-ID: <d875ec81-7252-b230-4c5b-b54ad0fcc888@gmail.com>


 Great question (as usual). It is possible to fit with glmer - by
skipping the "nAGQ0" step completely, which usually helps but sometimes
hurts - but you also have to tweak starting values (see below). Not
immediately obvious to me why this is a particularly tough problem;
glmmTMB and GLMMadaptive can do it ...

library(lme4)

## 'works', but crazy answer
fit <- glmer(cbind(Dead,Alive) ~ (Trt+0)/Dose +
             (Dose | Rep),
              data=Xdemo,
             family=binomial(link="logit"),
             control=glmerControl(nAGQ0initStep = FALSE))


## in this case starting with GLM fixed-effect estimates
##  seems to work OK (switched optimizers too)
fit0 <- glm(cbind(Dead,Alive) ~ (Trt+0)/Dose,
              data=Xdemo,
              family=binomial(link="logit"))
summary(coef(fit0))
fit5 <- update(fit,
               start=list(fixef=coef(fit0),theta=c(1,0,1)),
               control=glmerControl(nAGQ0initStep = FALSE,
                                    optimizer="nloptwrap"))

## cross-check with glmmTMB

library(glmmTMB)
fit2 <- glmmTMB(cbind(Dead,Alive) ~ (Trt+0)/Dose +
             (Dose | Rep),
              data=Xdemo,
             family=binomial(link="logit"))

nrow(Xdemo) ## 99
length(fixef(fit2)$cond + getME(fit2,"theta")) ## 12

library(GLMMadaptive)
## tried to do this with GLMMadaptive,
##
https://hypatia.math.ethz.ch/pipermail/r-sig-mixed-models/2019q3/028057.html
fit3 <- mixed_model(cbind(Dead,Alive) ~ (Trt+0)/Dose,
                    random = ~ Dose | Rep,
                    data=Xdemo,
                    family=binomial(link="logit"))

fit4 <- MASS::glmmPQL(cbind(Dead,Alive) ~ (Trt+0)/Dose,
                    random = ~ Dose | Rep,
                    data=Xdemo,
                    family=binomial(link="logit"))

## comparison.  first glmer fit is terrible.
## glmmPQL is a little farther off from others (not surprising ...)

cbind(glmer=fixef(fit),glmmTMB=fixef(fit2)$cond,
      glmer2=fixef(fit5),
      GLMMadaptive=fixef(fit3),
      glmmPQL=fixef(fit4))

Xdemo <- transform(Xdemo,
                    n= Alive+Dead,
                    prop=Dead/(Alive+Dead))

library(ggplot2)
ggplot(Xdemo,aes(Dose,prop,colour=Trt)) +
    geom_point(aes(size=n),alpha=0.5) +
    geom_line(aes(group=Rep),alpha=0.5)





On 2019-10-20 8:58 p.m., Rolf Turner wrote:
> 
> Xdemo <- structure(list(Dead = c(4, 26, 71, 34, 67, 68, 32, 39, 2, 15,
> 64, 26, 29, 0, 11, 10, 89, 87, 30, 121, 2, 9, 20, 0, 4, 30, 21,
> 21, 48, 54, 0, 47, 73, 87, 33, 73, 41, 39, 0, 25, 33, 19, 53,
> 39, 20, 3, 26, 26, 80, 79, 9, 35, 39, 40, 81, 80, 103, 7, 63,
> 92, 89, 40, 76, 0, 30, 29, 44, 64, 24, 72, 49, 0, 72, 73, 78,
> 46, 3, 21, 34, 29, 25, 37, 52, 64, 49, 0, 11, 11, 0, 17, 13,
> 56, 28, 3, 19, 23, 21, 26, 33), Alive = c(50, 22, 16, 6, 6, 1,
> 1, 0, 45, 5, 3, 0, 0, 55, 70, 18, 24, 4, 0, 0, 27, 11, 1, 35,
> 23, 17, 0, 0, 0, 0, 30, 12, 4, 1, 0, 0, 0, 0, 35, 29, 11, 6,
> 5, 2, 0, 61, 21, 7, 1, 0, 13, 0, 0, 0, 0, 0, 0, 26, 0, 0, 0,
> 0, 0, 26, 30, 5, 0, 0, 0, 0, 0, 74, 24, 11, 0, 0, 18, 11, 0,
> 0, 14, 6, 6, 8, 0, 40, 17, 9, 22, 38, 11, 2, 0, 51, 10, 5, 3,
> 0, 0), Rep = structure(c(6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 12L,
> 12L, 12L, 12L, 12L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 3L, 3L,
> 3L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 15L, 15L, 15L, 15L, 4L, 4L, 4L,
> 4L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 16L, 16L, 16L, 16L, 16L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 7L, 7L, 7L, 7L, 7L, 7L, 13L, 13L,
> 13L, 13L, 13L, 13L, 13L, 13L, 5L, 5L, 5L, 5L, 5L, 11L, 11L, 11L,
> 11L, 17L, 17L, 17L, 17L, 17L, 2L, 2L, 2L, 8L, 8L, 8L, 8L, 8L,
> 14L, 14L, 14L, 14L, 14L, 14L), .Label = c("1", "2", "3", "4",
> "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15",
> "16", "17", "18"), class = "factor"), Dose = c(0, 15, 30, 45,
> 55, 65, 75, 85, 0, 30, 40, 60, 80, 0, 10, 20, 30, 40, 60, 80,
> 0, 10, 35, 0, 10, 20, 35, 40, 45, 50, 0, 25, 30, 35, 30, 45,
> 50, 55, 0, 15, 20, 25, 30, 35, 40, 0, 10, 15, 25, 35, 0, 10,
> 15, 18, 21, 24, 27, 0, 10, 18, 21, 24, 37, 0, 8, 12, 15, 18,
> 22, 20, 24, 0, 10, 14, 26, 30, 0, 4, 8, 13, 4, 8, 10, 12, 18,
> 0, 6, 9, 0, 3, 6, 13, 18, 0, 6, 8, 10, 12, 14), Trt = structure(c(6L,
> 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
> 6L, 6L, 6L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
> 5L, 5L, 5L, 5L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L), .Label = c("16hour10deg", "16hour20deg", "16hour5deg",
> "8hour10deg", "8hour20deg", "8hour5deg"), class = "factor")), class =
> "data.frame", row.names = c(1L,
> 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 11L, 12L, 14L, 15L, 16L, 17L,
> 18L, 19L, 20L, 22L, 23L, 24L, 25L, 26L, 28L, 29L, 30L, 31L, 32L,
> 33L, 34L, 35L, 38L, 39L, 40L, 43L, 45L, 46L, 47L, 48L, 49L, 50L,
> 51L, 52L, 53L, 54L, 55L, 56L, 57L, 59L, 61L, 63L, 64L, 65L, 66L,
> 67L, 68L, 69L, 71L, 72L, 73L, 74L, 75L, 76L, 77L, 78L, 79L, 80L,
> 81L, 82L, 83L, 84L, 85L, 87L, 88L, 90L, 91L, 92L, 93L, 94L, 95L,
> 98L, 99L, 100L, 101L, 104L, 105L, 106L, 107L, 111L, 112L, 113L,
> 115L, 116L, 117L, 120L, 121L, 122L, 123L, 124L))
> 
> library(lme4)
> fit <- glmer(cbind(Dead,Alive) ~ (Trt+0)/Dose +
> ???????????? (Dose | Rep),
> ????????????? data=Xdemo,
> ????????????? family=binomial(link="logit"),nAGQ=0)
> 
> This throws the error:
> 
>> Error in pwrssUpdate(pp, resp, tol = tolPwrss, GQmat = GHrule(0L),
>> compDev = compDev,? : ? (maxstephalfit) PIRLS step-halvings failed to
>> reduce deviance in pwrssUpdate
> 
> Setting nAGQ=1 makes no difference.


From ph||||p@@|d@y @end|ng |rom mp|@n|  Mon Oct 21 04:20:20 2019
From: ph||||p@@|d@y @end|ng |rom mp|@n| (Phillip Alday)
Date: Mon, 21 Oct 2019 12:50:20 +1030
Subject: [R-sig-ME] Error from glmer() that I do not understand.
In-Reply-To: <d875ec81-7252-b230-4c5b-b54ad0fcc888@gmail.com>
References: <ffb0aeda-477c-100f-f130-ba5dff908a79@auckland.ac.nz>
 <d875ec81-7252-b230-4c5b-b54ad0fcc888@gmail.com>
Message-ID: <1b86dda4-3238-2ecd-2656-99f65c0027c9@mpi.nl>

Without taking the time to actually look in more detail about what's
going on here:

The initial nAGQ=0 / only optimize over theta and not over beta step can
do weird things for the nAGQ > 0 / optimizer over theta and beta step
when the initial fit is on the boundary. Is that what's happening here?

On 21/10/2019 12:24, Ben Bolker wrote:
>  Great question (as usual). It is possible to fit with glmer - by
> skipping the "nAGQ0" step completely, which usually helps but sometimes
> hurts - but you also have to tweak starting values (see below). Not
> immediately obvious to me why this is a particularly tough problem;
> glmmTMB and GLMMadaptive can do it ...
>
> library(lme4)
>
> ## 'works', but crazy answer
> fit <- glmer(cbind(Dead,Alive) ~ (Trt+0)/Dose +
>              (Dose | Rep),
>               data=Xdemo,
>              family=binomial(link="logit"),
>              control=glmerControl(nAGQ0initStep = FALSE))
>
>
> ## in this case starting with GLM fixed-effect estimates
> ##  seems to work OK (switched optimizers too)
> fit0 <- glm(cbind(Dead,Alive) ~ (Trt+0)/Dose,
>               data=Xdemo,
>               family=binomial(link="logit"))
> summary(coef(fit0))
> fit5 <- update(fit,
>                start=list(fixef=coef(fit0),theta=c(1,0,1)),
>                control=glmerControl(nAGQ0initStep = FALSE,
>                                     optimizer="nloptwrap"))
>
> ## cross-check with glmmTMB
>
> library(glmmTMB)
> fit2 <- glmmTMB(cbind(Dead,Alive) ~ (Trt+0)/Dose +
>              (Dose | Rep),
>               data=Xdemo,
>              family=binomial(link="logit"))
>
> nrow(Xdemo) ## 99
> length(fixef(fit2)$cond + getME(fit2,"theta")) ## 12
>
> library(GLMMadaptive)
> ## tried to do this with GLMMadaptive,
> ##
> https://hypatia.math.ethz.ch/pipermail/r-sig-mixed-models/2019q3/028057.html
> fit3 <- mixed_model(cbind(Dead,Alive) ~ (Trt+0)/Dose,
>                     random = ~ Dose | Rep,
>                     data=Xdemo,
>                     family=binomial(link="logit"))
>
> fit4 <- MASS::glmmPQL(cbind(Dead,Alive) ~ (Trt+0)/Dose,
>                     random = ~ Dose | Rep,
>                     data=Xdemo,
>                     family=binomial(link="logit"))
>
> ## comparison.  first glmer fit is terrible.
> ## glmmPQL is a little farther off from others (not surprising ...)
>
> cbind(glmer=fixef(fit),glmmTMB=fixef(fit2)$cond,
>       glmer2=fixef(fit5),
>       GLMMadaptive=fixef(fit3),
>       glmmPQL=fixef(fit4))
>
> Xdemo <- transform(Xdemo,
>                     n= Alive+Dead,
>                     prop=Dead/(Alive+Dead))
>
> library(ggplot2)
> ggplot(Xdemo,aes(Dose,prop,colour=Trt)) +
>     geom_point(aes(size=n),alpha=0.5) +
>     geom_line(aes(group=Rep),alpha=0.5)
>
>
>
>
>
> On 2019-10-20 8:58 p.m., Rolf Turner wrote:
>> Xdemo <- structure(list(Dead = c(4, 26, 71, 34, 67, 68, 32, 39, 2, 15,
>> 64, 26, 29, 0, 11, 10, 89, 87, 30, 121, 2, 9, 20, 0, 4, 30, 21,
>> 21, 48, 54, 0, 47, 73, 87, 33, 73, 41, 39, 0, 25, 33, 19, 53,
>> 39, 20, 3, 26, 26, 80, 79, 9, 35, 39, 40, 81, 80, 103, 7, 63,
>> 92, 89, 40, 76, 0, 30, 29, 44, 64, 24, 72, 49, 0, 72, 73, 78,
>> 46, 3, 21, 34, 29, 25, 37, 52, 64, 49, 0, 11, 11, 0, 17, 13,
>> 56, 28, 3, 19, 23, 21, 26, 33), Alive = c(50, 22, 16, 6, 6, 1,
>> 1, 0, 45, 5, 3, 0, 0, 55, 70, 18, 24, 4, 0, 0, 27, 11, 1, 35,
>> 23, 17, 0, 0, 0, 0, 30, 12, 4, 1, 0, 0, 0, 0, 35, 29, 11, 6,
>> 5, 2, 0, 61, 21, 7, 1, 0, 13, 0, 0, 0, 0, 0, 0, 26, 0, 0, 0,
>> 0, 0, 26, 30, 5, 0, 0, 0, 0, 0, 74, 24, 11, 0, 0, 18, 11, 0,
>> 0, 14, 6, 6, 8, 0, 40, 17, 9, 22, 38, 11, 2, 0, 51, 10, 5, 3,
>> 0, 0), Rep = structure(c(6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 12L,
>> 12L, 12L, 12L, 12L, 18L, 18L, 18L, 18L, 18L, 18L, 18L, 3L, 3L,
>> 3L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 15L, 15L, 15L, 15L, 4L, 4L, 4L,
>> 4L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 16L, 16L, 16L, 16L, 16L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 7L, 7L, 7L, 7L, 7L, 7L, 13L, 13L,
>> 13L, 13L, 13L, 13L, 13L, 13L, 5L, 5L, 5L, 5L, 5L, 11L, 11L, 11L,
>> 11L, 17L, 17L, 17L, 17L, 17L, 2L, 2L, 2L, 8L, 8L, 8L, 8L, 8L,
>> 14L, 14L, 14L, 14L, 14L, 14L), .Label = c("1", "2", "3", "4",
>> "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15",
>> "16", "17", "18"), class = "factor"), Dose = c(0, 15, 30, 45,
>> 55, 65, 75, 85, 0, 30, 40, 60, 80, 0, 10, 20, 30, 40, 60, 80,
>> 0, 10, 35, 0, 10, 20, 35, 40, 45, 50, 0, 25, 30, 35, 30, 45,
>> 50, 55, 0, 15, 20, 25, 30, 35, 40, 0, 10, 15, 25, 35, 0, 10,
>> 15, 18, 21, 24, 27, 0, 10, 18, 21, 24, 37, 0, 8, 12, 15, 18,
>> 22, 20, 24, 0, 10, 14, 26, 30, 0, 4, 8, 13, 4, 8, 10, 12, 18,
>> 0, 6, 9, 0, 3, 6, 13, 18, 0, 6, 8, 10, 12, 14), Trt = structure(c(6L,
>> 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
>> 6L, 6L, 6L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>> 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>> 4L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
>> 5L, 5L, 5L, 5L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L), .Label = c("16hour10deg", "16hour20deg", "16hour5deg",
>> "8hour10deg", "8hour20deg", "8hour5deg"), class = "factor")), class =
>> "data.frame", row.names = c(1L,
>> 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 11L, 12L, 14L, 15L, 16L, 17L,
>> 18L, 19L, 20L, 22L, 23L, 24L, 25L, 26L, 28L, 29L, 30L, 31L, 32L,
>> 33L, 34L, 35L, 38L, 39L, 40L, 43L, 45L, 46L, 47L, 48L, 49L, 50L,
>> 51L, 52L, 53L, 54L, 55L, 56L, 57L, 59L, 61L, 63L, 64L, 65L, 66L,
>> 67L, 68L, 69L, 71L, 72L, 73L, 74L, 75L, 76L, 77L, 78L, 79L, 80L,
>> 81L, 82L, 83L, 84L, 85L, 87L, 88L, 90L, 91L, 92L, 93L, 94L, 95L,
>> 98L, 99L, 100L, 101L, 104L, 105L, 106L, 107L, 111L, 112L, 113L,
>> 115L, 116L, 117L, 120L, 121L, 122L, 123L, 124L))
>>
>> library(lme4)
>> fit <- glmer(cbind(Dead,Alive) ~ (Trt+0)/Dose +
>> ???????????? (Dose | Rep),
>> ????????????? data=Xdemo,
>> ????????????? family=binomial(link="logit"),nAGQ=0)
>>
>> This throws the error:
>>
>>> Error in pwrssUpdate(pp, resp, tol = tolPwrss, GQmat = GHrule(0L),
>>> compDev = compDev,? : ? (maxstephalfit) PIRLS step-halvings failed to
>>> reduce deviance in pwrssUpdate
>> Setting nAGQ=1 makes no difference.
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From r@turner @end|ng |rom @uck|@nd@@c@nz  Mon Oct 21 06:25:14 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Mon, 21 Oct 2019 17:25:14 +1300
Subject: [R-sig-ME] Error from glmer() that I do not understand.
In-Reply-To: <d875ec81-7252-b230-4c5b-b54ad0fcc888@gmail.com>
References: <ffb0aeda-477c-100f-f130-ba5dff908a79@auckland.ac.nz>
 <d875ec81-7252-b230-4c5b-b54ad0fcc888@gmail.com>
Message-ID: <5c5ac346-c188-2d9b-afe4-30b6c6bb75f0@auckland.ac.nz>

On 21/10/19 2:54 PM, Ben Bolker wrote:
> 
>   Great question (as usual). It is possible to fit with glmer - by
> skipping the "nAGQ0" step completely, which usually helps but sometimes
> hurts - but you also have to tweak starting values (see below). Not
> immediately obvious to me why this is a particularly tough problem;
> glmmTMB and GLMMadaptive can do it ...
> 
> library(lme4)
> 
> ## 'works', but crazy answer
> fit <- glmer(cbind(Dead,Alive) ~ (Trt+0)/Dose +
>               (Dose | Rep),
>                data=Xdemo,
>               family=binomial(link="logit"),
>               control=glmerControl(nAGQ0initStep = FALSE))
> 
> 
> ## in this case starting with GLM fixed-effect estimates
> ##  seems to work OK (switched optimizers too)
> fit0 <- glm(cbind(Dead,Alive) ~ (Trt+0)/Dose,
>                data=Xdemo,
>                family=binomial(link="logit"))
> summary(coef(fit0))
> fit5 <- update(fit,
>                 start=list(fixef=coef(fit0),theta=c(1,0,1)),
>                 control=glmerControl(nAGQ0initStep = FALSE,
>                                      optimizer="nloptwrap"))
> 
> ## cross-check with glmmTMB
> 
> library(glmmTMB)
> fit2 <- glmmTMB(cbind(Dead,Alive) ~ (Trt+0)/Dose +
>               (Dose | Rep),
>                data=Xdemo,
>               family=binomial(link="logit"))
> 
> nrow(Xdemo) ## 99
> length(fixef(fit2)$cond + getME(fit2,"theta")) ## 12
> 
> library(GLMMadaptive)
> ## tried to do this with GLMMadaptive,
> ##
> https://hypatia.math.ethz.ch/pipermail/r-sig-mixed-models/2019q3/028057.html
> fit3 <- mixed_model(cbind(Dead,Alive) ~ (Trt+0)/Dose,
>                      random = ~ Dose | Rep,
>                      data=Xdemo,
>                      family=binomial(link="logit"))
> 
> fit4 <- MASS::glmmPQL(cbind(Dead,Alive) ~ (Trt+0)/Dose,
>                      random = ~ Dose | Rep,
>                      data=Xdemo,
>                      family=binomial(link="logit"))
> 
> ## comparison.  first glmer fit is terrible.
> ## glmmPQL is a little farther off from others (not surprising ...)
> 
> cbind(glmer=fixef(fit),glmmTMB=fixef(fit2)$cond,
>        glmer2=fixef(fit5),
>        GLMMadaptive=fixef(fit3),
>        glmmPQL=fixef(fit4))
> 
> Xdemo <- transform(Xdemo,
>                      n= Alive+Dead,
>                      prop=Dead/(Alive+Dead))
> 
> library(ggplot2)
> ggplot(Xdemo,aes(Dose,prop,colour=Trt)) +
>      geom_point(aes(size=n),alpha=0.5) +
>      geom_line(aes(group=Rep),alpha=0.5)

Thanks Ben for the very thorough answer.  (How on earth do you find the 
time to respond the way you do?)

The error that I described actually arose in the context of a fairly big
(by my standards) simulation study.  Such errors seemed to arise very 
frequently and the randomness of the data make it difficult to keep the 
misbehaviour under control.  I need the simulations to run reliably and
not crash in the middle of a test sequence.

I may have to set things up to catch errors and if there is one to 
switch the fitting method from glmer() to mixed_model() --- or vice 
versa.  (I'm sure that GLMMadaptive will crash unexpectedly with certain 
simulated data sets, just as lme4 does.)

Life never does go smoothly! :-)

Thanks again.

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From @|te@@ed@c2 @end|ng |rom gm@||@com  Mon Oct 21 13:20:20 2019
From: @|te@@ed@c2 @end|ng |rom gm@||@com (C. AMAL D. GLELE)
Date: Mon, 21 Oct 2019 11:20:20 +0000
Subject: [R-sig-ME] Error message when handling complete separation
Message-ID: <CANrzCv3KN9Zh8qF4knGo2x+CRUgcx4xybeyHWFaVd+uRm+s7gg@mail.gmail.com>

Hi, all.
When trying to handle a complete separation case
( initialmodel<-glmer(resp~treatment+(1|net),family=binomial,data=mydata) ,
where: treatment is a factor with 4 levels; net has 4 levels;
resp<-cbind(,)
Warning message:
unable to evaluate scaled gradient Hessian is numerically singular:
parameters are not uniquely determined
Outputs: huge estimates, huges sderror and p-value=1 everywhere
)
to solve this, I tried the following fit;
mod2kisBW_unsep1<-
bglmer(respkisBW~treatment+(1|net),data=conedata1kisBW,family=binomial,fixef.prior
= normal(cov=diag(9,4)))
but, I get the error message below:

Error in length(value <- as.numeric(value)) == 1L :
  pwrssUpdate did not converge in (maxit) iterations

1) what are the possible causes of such a problem?
2) how can I figure it out?
Thanks, in advance.
Regards,

	[[alternative HTML version deleted]]


From d@r|zopou|o@ @end|ng |rom er@@mu@mc@n|  Mon Oct 21 15:32:06 2019
From: d@r|zopou|o@ @end|ng |rom er@@mu@mc@n| (D. Rizopoulos)
Date: Mon, 21 Oct 2019 13:32:06 +0000
Subject: [R-sig-ME] Error message when handling complete separation
In-Reply-To: <CANrzCv3KN9Zh8qF4knGo2x+CRUgcx4xybeyHWFaVd+uRm+s7gg@mail.gmail.com>
References: <CANrzCv3KN9Zh8qF4knGo2x+CRUgcx4xybeyHWFaVd+uRm+s7gg@mail.gmail.com>
Message-ID: <7a2960f2a7244c82a5b97cd701f645ad@erasmusmc.nl>

In GLMMadaptive you can solve separation issues by including a penalty term for the coefficients. You may find an example on how to do this at the bottom of this vignette: https://drizopoulos.github.io/GLMMadaptive/articles/GLMMadaptive_basics.html


Best,
Dimitris

From: C. AMAL D. GLELE <altessedac2 at gmail.com<mailto:altessedac2 at gmail.com>>
Date: Monday, 21 Oct 2019, 13:21
To: R SIG Mixed Models <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
Subject: [R-sig-ME] Error message when handling complete separation

Hi, all.
When trying to handle a complete separation case
( initialmodel<-glmer(resp~treatment+(1|net),family=binomial,data=mydata) ,
where: treatment is a factor with 4 levels; net has 4 levels;
resp<-cbind(,)
Warning message:
unable to evaluate scaled gradient Hessian is numerically singular:
parameters are not uniquely determined
Outputs: huge estimates, huges sderror and p-value=1 everywhere
)
to solve this, I tried the following fit;
mod2kisBW_unsep1<-
bglmer(respkisBW~treatment+(1|net),data=conedata1kisBW,family=binomial,fixef.prior
= normal(cov=diag(9,4)))
but, I get the error message below:

Error in length(value <- as.numeric(value)) == 1L :
  pwrssUpdate did not converge in (maxit) iterations

1) what are the possible causes of such a problem?
2) how can I figure it out?
Thanks, in advance.
Regards,

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7Cdf91bdf080be490a9aeb08d75618c929%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637072536761480378&amp;sdata=o6YoF5%2BXMcfDkQWjq7iKPVcKi3AjK6Wpq2InrrjA5Os%3D&amp;reserved=0

	[[alternative HTML version deleted]]


From ch|@r@||n| @end|ng |rom gm@||@com  Sat Oct 19 13:52:13 2019
From: ch|@r@||n| @end|ng |rom gm@||@com (Chiara Fini)
Date: Sat, 19 Oct 2019 13:52:13 +0200
Subject: [R-sig-ME] Logit model in R
Message-ID: <CAFJ8kB481_N-Au9tqh6wEub0+GapKFC2AjC_4j=Q4HFKnyYOOQ@mail.gmail.com>

Hi, I am a post doc in cognitive science,
I would like to ask which code i have to write in R to calculate the
percentage of categorial responses "Yes" or "Not" delivered for each of my
15 perceptual stimuli.
Many thanks,
Chiara

	[[alternative HTML version deleted]]


From @m@|@d@hounto @end|ng |rom gm@||@com  Mon Oct 21 17:40:42 2019
From: @m@|@d@hounto @end|ng |rom gm@||@com (Amal Dahounto)
Date: Mon, 21 Oct 2019 15:40:42 +0000
Subject: [R-sig-ME] Error message when handling complete separation
In-Reply-To: <7a2960f2a7244c82a5b97cd701f645ad@erasmusmc.nl>
References: <CANrzCv3KN9Zh8qF4knGo2x+CRUgcx4xybeyHWFaVd+uRm+s7gg@mail.gmail.com>
 <7a2960f2a7244c82a5b97cd701f645ad@erasmusmc.nl>
Message-ID: <CA+DVwCs_eAYbgDUEqfHbZTEGG9cHzNdid2sBOzXFdJkxVT=iXA@mail.gmail.com>

Ok;
thank you so much for reply and your suggestion.
Regards,

Le lun. 21 oct. 2019 ? 13:32, D. Rizopoulos <d.rizopoulos at erasmusmc.nl> a
?crit :

> In GLMMadaptive you can solve separation issues by including a penalty
> term for the coefficients. You may find an example on how to do this at the
> bottom of this vignette:
> https://drizopoulos.github.io/GLMMadaptive/articles/GLMMadaptive_basics.html
>
>
> Best,
> Dimitris
>
> *From: *C. AMAL D. GLELE <altessedac2 at gmail.com>
> *Date: *Monday, 21 Oct 2019, 13:21
> *To: *R SIG Mixed Models <r-sig-mixed-models at r-project.org>
> *Subject: *[R-sig-ME] Error message when handling complete separation
>
> Hi, all.
> When trying to handle a complete separation case
> ( initialmodel<-glmer(resp~treatment+(1|net),family=binomial,data=mydata) ,
> where: treatment is a factor with 4 levels; net has 4 levels;
> resp<-cbind(,)
> Warning message:
> unable to evaluate scaled gradient Hessian is numerically singular:
> parameters are not uniquely determined
> Outputs: huge estimates, huges sderror and p-value=1 everywhere
> )
> to solve this, I tried the following fit;
> mod2kisBW_unsep1<-
>
> bglmer(respkisBW~treatment+(1|net),data=conedata1kisBW,family=binomial,fixef.prior
> = normal(cov=diag(9,4)))
> but, I get the error message below:
>
> Error in length(value <- as.numeric(value)) == 1L :
>   pwrssUpdate did not converge in (maxit) iterations
>
> 1) what are the possible causes of such a problem?
> 2) how can I figure it out?
> Thanks, in advance.
> Regards,
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
>
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7Cdf91bdf080be490a9aeb08d75618c929%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637072536761480378&amp;sdata=o6YoF5%2BXMcfDkQWjq7iKPVcKi3AjK6Wpq2InrrjA5Os%3D&amp;reserved=0
>


-- 

Amal DAHOUNTO GLELE C.



*BioStatistician, Data ManagerElectronicDataCapture(EDC) Systems
ManagerGeographic Information System (GIS) Manager*Institut Pierre Richet
(IPR) BOUAKE/CI

*Vector Control Products Evaluation Centre (VCPEC)*T?l:(+225)
89051825;42519613
*Skype: coliasso*

	[[alternative HTML version deleted]]


From |jrhur|ey @end|ng |rom gm@||@com  Mon Oct 21 18:47:35 2019
From: |jrhur|ey @end|ng |rom gm@||@com (landon hurley)
Date: Mon, 21 Oct 2019 12:47:35 -0400
Subject: [R-sig-ME] Logit model in R
In-Reply-To: <CAFJ8kB481_N-Au9tqh6wEub0+GapKFC2AjC_4j=Q4HFKnyYOOQ@mail.gmail.com>
References: <CAFJ8kB481_N-Au9tqh6wEub0+GapKFC2AjC_4j=Q4HFKnyYOOQ@mail.gmail.com>
Message-ID: <05b53c66-daf5-8963-8a29-48add54649e7@gmail.com>


Chiara,

> I would like to ask which code i have to write in R to calculate the
> percentage of categorial responses "Yes" or "Not" delivered for each of my
> 15 perceptual stimuli.

Typically the mean of a sequence of binary yes/no questions would be
sufficient to answer this question. Take the m x n data set matrix D
with n> 15 and apply the code

colMeans(D[,1:15])

to compute the mean of each column vector. The sequence 1:15 denotes the
list sequence from the number 1 to the number 15, increasing by 1 at
each step. If the 15 stimuli are not in sequential order, then they must
be identified by the index sequence c(a,b,...,o) for which each letter
is replaced by the respective column number of matrix D. Alternatively,
the indices can be column names instead of numbers, for which each
number must be enclosed in a separate " " quote string.

colMeans(D[,c(a,b,...,o)])

As a side note, you may wish to consider that since this is a mailing
list for mixed models, it would be perhaps advisable to perhaps consider
Stack Exchange or some other mailing list or other forum strictly
devoted to performing basic operations in R. Also, since your email
message has nothing to do with the implementation of a logit model in R,
perhaps a better choice of email subject header would benefit in
directing individuals to addressing your question.

If you are interested in ultimately performing a regression upon a
categorical unordered outcome measure, then I would recommend
investigating the glm function in R, with the family operation set to
'binomial'.

best,
> Many thanks,
> Chiara
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 


-- 
Violence is the last refuge of the incompetent.


From bbo|ker @end|ng |rom gm@||@com  Mon Oct 21 20:57:58 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 21 Oct 2019 14:57:58 -0400
Subject: [R-sig-ME] Error message when handling complete separation
In-Reply-To: <CA+DVwCs_eAYbgDUEqfHbZTEGG9cHzNdid2sBOzXFdJkxVT=iXA@mail.gmail.com>
References: <CANrzCv3KN9Zh8qF4knGo2x+CRUgcx4xybeyHWFaVd+uRm+s7gg@mail.gmail.com>
 <7a2960f2a7244c82a5b97cd701f645ad@erasmusmc.nl>
 <CA+DVwCs_eAYbgDUEqfHbZTEGG9cHzNdid2sBOzXFdJkxVT=iXA@mail.gmail.com>
Message-ID: <19aebf93-c75c-ec2b-0207-4292e485ac16@gmail.com>

   This might be fixable/hackable with bglmer, but we'd need a
reproducible example.  (Does tightening the prior help at all, e.g.
normal(cov=diag(4,4)) ?)

On 2019-10-21 11:40 a.m., Amal Dahounto wrote:
> Ok;
> thank you so much for reply and your suggestion.
> Regards,
> 
> Le lun. 21 oct. 2019 ? 13:32, D. Rizopoulos <d.rizopoulos at erasmusmc.nl> a
> ?crit :
> 
>> In GLMMadaptive you can solve separation issues by including a penalty
>> term for the coefficients. You may find an example on how to do this at the
>> bottom of this vignette:
>> https://drizopoulos.github.io/GLMMadaptive/articles/GLMMadaptive_basics.html
>>
>>
>> Best,
>> Dimitris
>>
>> *From: *C. AMAL D. GLELE <altessedac2 at gmail.com>
>> *Date: *Monday, 21 Oct 2019, 13:21
>> *To: *R SIG Mixed Models <r-sig-mixed-models at r-project.org>
>> *Subject: *[R-sig-ME] Error message when handling complete separation
>>
>> Hi, all.
>> When trying to handle a complete separation case
>> ( initialmodel<-glmer(resp~treatment+(1|net),family=binomial,data=mydata) ,
>> where: treatment is a factor with 4 levels; net has 4 levels;
>> resp<-cbind(,)
>> Warning message:
>> unable to evaluate scaled gradient Hessian is numerically singular:
>> parameters are not uniquely determined
>> Outputs: huge estimates, huges sderror and p-value=1 everywhere
>> )
>> to solve this, I tried the following fit;
>> mod2kisBW_unsep1<-
>>
>> bglmer(respkisBW~treatment+(1|net),data=conedata1kisBW,family=binomial,fixef.prior
>> = normal(cov=diag(9,4)))
>> but, I get the error message below:
>>
>> Error in length(value <- as.numeric(value)) == 1L :
>>   pwrssUpdate did not converge in (maxit) iterations
>>
>> 1) what are the possible causes of such a problem?
>> 2) how can I figure it out?
>> Thanks, in advance.
>> Regards,
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>>
>> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7Cdf91bdf080be490a9aeb08d75618c929%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637072536761480378&amp;sdata=o6YoF5%2BXMcfDkQWjq7iKPVcKi3AjK6Wpq2InrrjA5Os%3D&amp;reserved=0
>>
> 
>


From ph||||p@@|d@y @end|ng |rom mp|@n|  Tue Oct 22 04:04:26 2019
From: ph||||p@@|d@y @end|ng |rom mp|@n| (Phillip Alday)
Date: Tue, 22 Oct 2019 12:34:26 +1030
Subject: [R-sig-ME] Logit model in R
In-Reply-To: <05b53c66-daf5-8963-8a29-48add54649e7@gmail.com>
References: <CAFJ8kB481_N-Au9tqh6wEub0+GapKFC2AjC_4j=Q4HFKnyYOOQ@mail.gmail.com>
 <05b53c66-daf5-8963-8a29-48add54649e7@gmail.com>
Message-ID: <5c54172c-d037-8d31-f84e-866a79ac9d52@mpi.nl>

Also, since you emphasize that you're in cognitive science, it might
make sense to take a look at the following papers, which would bring
this closer to the topic of mixed models:

Jaeger, T. F. (2008). Categorical Data Analysis: Away from ANOVAs
(Transformation or Not) and Towards Logit Mixed Models. Journal of
Memory and Language , 59 (4), 434?446. doi:10.1016/j.jml.2007.11.007

Davidson, D. J., & Martin, A. E. (2013). Modeling accuracy as a function
of response time with the generalized linear mixed effects model. Acta
Psychologica , 144 , 83?96.

Best,

Phillip

On 22/10/2019 03:17, landon hurley wrote:
> Chiara,
>
>> I would like to ask which code i have to write in R to calculate the
>> percentage of categorial responses "Yes" or "Not" delivered for each of my
>> 15 perceptual stimuli.
> Typically the mean of a sequence of binary yes/no questions would be
> sufficient to answer this question. Take the m x n data set matrix D
> with n> 15 and apply the code
>
> colMeans(D[,1:15])
>
> to compute the mean of each column vector. The sequence 1:15 denotes the
> list sequence from the number 1 to the number 15, increasing by 1 at
> each step. If the 15 stimuli are not in sequential order, then they must
> be identified by the index sequence c(a,b,...,o) for which each letter
> is replaced by the respective column number of matrix D. Alternatively,
> the indices can be column names instead of numbers, for which each
> number must be enclosed in a separate " " quote string.
>
> colMeans(D[,c(a,b,...,o)])
>
> As a side note, you may wish to consider that since this is a mailing
> list for mixed models, it would be perhaps advisable to perhaps consider
> Stack Exchange or some other mailing list or other forum strictly
> devoted to performing basic operations in R. Also, since your email
> message has nothing to do with the implementation of a logit model in R,
> perhaps a better choice of email subject header would benefit in
> directing individuals to addressing your question.
>
> If you are interested in ultimately performing a regression upon a
> categorical unordered outcome measure, then I would recommend
> investigating the glm function in R, with the family operation set to
> 'binomial'.
>
> best,
>> Many thanks,
>> Chiara
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>


From M@@rten@Jung @end|ng |rom m@||box@tu-dre@den@de  Tue Oct 22 22:01:06 2019
From: M@@rten@Jung @end|ng |rom m@||box@tu-dre@den@de (Maarten Jung)
Date: Tue, 22 Oct 2019 22:01:06 +0200
Subject: [R-sig-ME] Appropriate model reduction sequence for factorial
 design in glmmTMB
Message-ID: <CAHr4Dyc=7aizpvnSLKyZ7pb5a81Dj85OVNsyT5Ke4OP75tW4Jw@mail.gmail.com>

Dear list,

Sorry for basically restating my question here [1], but I think it
might be worth a separate thread as it might well be much easier to
answer with glmmTMB.

After going through the posts [2] and [3] again, I identified the
following nesting structure (arrows indicate nesting) as the one I
want to go with for modelling some new data:

m1 -> m2a/m2b/m2c -> m3 -> m4

#######################################################

library("lme4")
data("Machines", package = "MEMSS")
d <- Machines
mat <- model.matrix(~ 0 + Machine, d)
A <- mat[, 1]
B <- mat[, 2]
C <- mat[, 3]

m1 <- lmer(score ~ Machine + (0 + Machine | Worker), d)

m2a <- lmer(score ~ Machine + (1 | Worker) + (0 + dummy(Machine, "A")
| Worker) +

   (0 + dummy(Machine, "B") | Worker) +

   (0 + dummy(Machine, "C") | Worker), d)

m2b <- lmer(score ~ Machine + (1 | Worker) + (0 + A + B + C || Worker), d)

m2c <- afex::lmer_alt(score ~ Machine + (1 | Worker) + (0 + Machine ||
Worker), d)

# m2a, m2b, and m2c are equivalent
all.equal(logLik(m2a), logLik(m2b), logLik(m2c))

m3 <- lmer(score ~ Machine + (1 | Worker) + (1 | Worker:Machine), d)

m4 <- lmer(score ~ Machine + (1 | Worker), d)

#######################################################

In my new data there are multiple observations per cell of a (at
least) 2x3 within-subjects design.
I know that m1 (denoting the two factors with f1 and f2, respectively)
would look like

lmer(y ~ f1*f2 + (1 + f1*f2 | subject), data)

and I think like this in glmmTMB syntax

glmmTMB(y ~ f1*f2 + us(f1*f2 | subject), data, REML = TRUE)

So now I'm struggling to figure out what m2a (or m2b/m2c) and m3 would
look like in the (at least) 2-factorial case.
My guess is that m2 would look like this in glmmTMB syntax

glmmTMB(y ~ f1*f2 + (1 | subject) + diag(0 + f1*f2 | subject), data,
REML = TRUE)

and that this might correspond to the following afex:lmer_alt() model

afex::lmer_alt(y ~ f1*f2 + (1 | subject) + (0 +  f1*f2 || subject ), data)

But I'm not sure about m3.

I would be grateful if someone could provide the appropriate glmmTMB
syntax (additionally or alternatively, lmer/afex::lmer_alt syntax is
still welcome in the other thread).

Best,
Maarten

[1] https://stat.ethz.ch/pipermail/r-sig-mixed-models/2019q4/028222.html
[2] https://stat.ethz.ch/pipermail/r-sig-mixed-models/2018q2/026775.html
[3] https://stats.stackexchange.com/questions/345842/what-is-the-appropriate-zero-correlation-parameter-model-for-factors-in-lmer


From j@de@ @end|ng |rom uc@d@edu  Wed Oct 23 06:33:35 2019
From: j@de@ @end|ng |rom uc@d@edu (Ades, James)
Date: Wed, 23 Oct 2019 04:33:35 +0000
Subject: [R-sig-ME] Question regarding random factor accounting for scores
 scaled by grade
Message-ID: <E9302445-7461-47D4-B223-B4D25172C154@UCSD.edu>

Hi all:

I?m looking at SBAC standardized test scores (math in one model and English in the other) for middle schoolers (as the dependent variable) and then executive function task scores and demographic factors as explanatory variables.

So in a simple model looking at the relationship between a stroop task and the SBAC math variable I?d have the model:

model <- lmer(math.score ~ School + Ethnicity + Language.Fluency*attendance + Parent.Ed.Lvl +SpEd + t4.minus + eff.rt.stroop + (t4.minus|pid) + (1|grade) + (1|Teacher), data = ace, na.action = 'na.exclude', control = lmerControl(optimizer = "nloptwrap", calc.derivs = FALSE), REML = FALSE)

where t4.minus is the time in between timepoints (there were four, and they varied from participant to participant), pid is the participant, and eff.rt.stroop is the efficiency stroop score.

Since there are four timepoints over two years, there are ultimately six grades: 3rd graders who then become 4th graders,  fifth graders who then become sixth graders, and seventh graders who then become eighth graders.

My question is whether this random factor of grade would not only account for natural variance between grades (with the random intercept) but would also, in a principled and valid way, account for the fact that SBAC score falls on a continuous scale (between 2000-3000) that increases with each grade, such that an equivalent score of 2381 in 3rd grade would be 2411 in 4th grade. Explained (better?) here: http://www.smarterbalanced.org/assessments/scores/.

Thanks much,

James


Have uploaded 10 rows here: https://drive.google.com/open?id=17FJjeln3Ipg0-uq0wQL9tWkJRnHTqdt6


	[[alternative HTML version deleted]]


From ch|@r@||n| @end|ng |rom gm@||@com  Tue Oct 22 09:02:39 2019
From: ch|@r@||n| @end|ng |rom gm@||@com (Chiara Fini)
Date: Tue, 22 Oct 2019 09:02:39 +0200
Subject: [R-sig-ME] Logit model in R
In-Reply-To: <5c54172c-d037-8d31-f84e-866a79ac9d52@mpi.nl>
References: <CAFJ8kB481_N-Au9tqh6wEub0+GapKFC2AjC_4j=Q4HFKnyYOOQ@mail.gmail.com>
 <05b53c66-daf5-8963-8a29-48add54649e7@gmail.com>
 <5c54172c-d037-8d31-f84e-866a79ac9d52@mpi.nl>
Message-ID: <CAFJ8kB4-YbSomi5WLuuUERJ1NjrmRxvvLBQjx46nxZ5OH-Aw6A@mail.gmail.com>

Thanks a lot for the helpful hints,
Chiara

Il giorno mar 22 ott 2019 alle ore 04:05 Phillip Alday <phillip.alday at mpi.nl>
ha scritto:

> Also, since you emphasize that you're in cognitive science, it might
> make sense to take a look at the following papers, which would bring
> this closer to the topic of mixed models:
>
> Jaeger, T. F. (2008). Categorical Data Analysis: Away from ANOVAs
> (Transformation or Not) and Towards Logit Mixed Models. Journal of
> Memory and Language , 59 (4), 434?446. doi:10.1016/j.jml.2007.11.007
>
> Davidson, D. J., & Martin, A. E. (2013). Modeling accuracy as a function
> of response time with the generalized linear mixed effects model. Acta
> Psychologica , 144 , 83?96.
>
> Best,
>
> Phillip
>
> On 22/10/2019 03:17, landon hurley wrote:
> > Chiara,
> >
> >> I would like to ask which code i have to write in R to calculate the
> >> percentage of categorial responses "Yes" or "Not" delivered for each of
> my
> >> 15 perceptual stimuli.
> > Typically the mean of a sequence of binary yes/no questions would be
> > sufficient to answer this question. Take the m x n data set matrix D
> > with n> 15 and apply the code
> >
> > colMeans(D[,1:15])
> >
> > to compute the mean of each column vector. The sequence 1:15 denotes the
> > list sequence from the number 1 to the number 15, increasing by 1 at
> > each step. If the 15 stimuli are not in sequential order, then they must
> > be identified by the index sequence c(a,b,...,o) for which each letter
> > is replaced by the respective column number of matrix D. Alternatively,
> > the indices can be column names instead of numbers, for which each
> > number must be enclosed in a separate " " quote string.
> >
> > colMeans(D[,c(a,b,...,o)])
> >
> > As a side note, you may wish to consider that since this is a mailing
> > list for mixed models, it would be perhaps advisable to perhaps consider
> > Stack Exchange or some other mailing list or other forum strictly
> > devoted to performing basic operations in R. Also, since your email
> > message has nothing to do with the implementation of a logit model in R,
> > perhaps a better choice of email subject header would benefit in
> > directing individuals to addressing your question.
> >
> > If you are interested in ultimately performing a regression upon a
> > categorical unordered outcome measure, then I would recommend
> > investigating the glm function in R, with the family operation set to
> > 'binomial'.
> >
> > best,
> >> Many thanks,
> >> Chiara
> >>
> >>      [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From Ju||@n@G@v|r|@Lopez @end|ng |rom un|ge@ch  Thu Oct 24 15:05:33 2019
From: Ju||@n@G@v|r|@Lopez @end|ng |rom un|ge@ch (Julian Gaviria Lopez)
Date: Thu, 24 Oct 2019 13:05:33 +0000
Subject: [R-sig-ME] About computing covariances between two fixed effects
 with 4 and 5 levels respectively.
In-Reply-To: <f2ded4c701724c56b987f6f42e081b62@unige.ch>
References: <f4d6cae2e09d4335a627dd093bdc37d0@unige.ch>,
 <f2ded4c701724c56b987f6f42e081b62@unige.ch>
Message-ID: <ee6e0316ec60433ea6f5bdca0df8320d@unige.ch>

Hello,


I want to assess the correlation of 4 kinds of brain activation patterns (CAP: c1, c2, c3, c4) from 20 subjects, across 5 different conditions (Condition: base,  neu, pneu, aff, paff). In total, the count data contains 380 observations, and has the next structure:


     ID       Observations         CAP          Condition

     1                  6                       c1              base

    ...                 ...                      ...                 ...

    20                 0                       c1              base

    ...                 ...                       ...                 ...

     1                  3                       c4              base

    ...                 ...                       ...                 ...

   20                  0                       c4             base

    1                   4                       c1              neu

    ...                 ...                       ...                ...

   20                  2                       c1              neu

    ...                 ...                       ...                ...

    1                   0                       c4              neu

    ...                 ...                       ...                ...

   20                  5                       c4              neu

    ...                 ...                       ...                ...

   20                  0                       c4              paff


I am trying to compute the covariance structures proposed by Kasper Kristensen:

https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html


When I compute the unstructured covariance:

> fit.us <- glmmTMB(Observations ~ us(CAP + 0 | Condition), data=sdf, ziformula=~1)

I obtain the following result:
> VarCorr(fit.us)
Conditional model:
 Groups    Name     Std.Dev. Corr
Condition  c1         0.86527
                    c2         0.34487   0.116
                    c3         0.16450  -0.951  0.164
                    c4         0.36269   0.414 -0.719 -0.545
 Residual           1.98011


As you might appreciate, the results are either wrong or uncompleted, since the right output would yield a 5x4 cov matrix, expressing the correlation of the CAPs (c1, c2, c3, c4) across all the conditions (base, neu, pneu, aff, paff). One rapid solution is to compute the cov matrix per condition. However, apart of  being penalized by model deficiency (I guess),  the problem is still present, since the question to answer is how the brain activation patterns (CAP) are correlated across all conditions (e.g. correlation between "CAP c1 - Condition aff",  and "CAP c4 - Condition paff").

Thanks in advance for any comment on this regard.

Best,

Julian Gaviria
Neurology and Imaging of cognition lab (Labnic)
University of Geneva. Campus Biotech.
9 Chemin des Mines, 1202 Geneva, CH
Tel: +41 22 379 0380
Email: Julian.GaviriaLopez at unige.ch

	[[alternative HTML version deleted]]


From @|te@@ed@c2 @end|ng |rom gm@||@com  Thu Oct 24 19:23:19 2019
From: @|te@@ed@c2 @end|ng |rom gm@||@com (C. AMAL D. GLELE)
Date: Thu, 24 Oct 2019 17:23:19 +0000
Subject: [R-sig-ME] glmmadmb_scan()_error
Message-ID: <CANrzCv0r7jmaqOxZPeC0Em+1COecv_hVb3+S+FFPe0OGDOx_tQ@mail.gmail.com>

Hi, all.
I didn't use my glmmadmb function since about 2 months(it was working fine
just before);
but now, I'm getting the following error message
"Error in scan(text = rr[numLines], quiet = TRUE) :
  scan() expected 'a real', got 'obs'
"
 when trying to fit:
model<-glmmadmb(total~treatment+(1|day)+(1|fhut), data=mydata,
family="nbinom")
but, no problem when I replace glmmadmb by glmmTMB and family by "nbinom1"
Note:
I'm using the same computer
Thanks for your help

<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
Garanti
sans virus. www.avast.com
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Thu Oct 24 23:13:34 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 24 Oct 2019 17:13:34 -0400
Subject: [R-sig-ME] glmmadmb_scan()_error
In-Reply-To: <CANrzCv0r7jmaqOxZPeC0Em+1COecv_hVb3+S+FFPe0OGDOx_tQ@mail.gmail.com>
References: <CANrzCv0r7jmaqOxZPeC0Em+1COecv_hVb3+S+FFPe0OGDOx_tQ@mail.gmail.com>
Message-ID: <ce4f51a9-65aa-26a1-4b05-954b09282a02@gmail.com>


   It's kind of impossible to debug this without a reproducible example.

   The best place for this would be the glmmadmb issues list on GitHub:
https://github.com/bbolker/glmmadmb/issues

   But I have to admit that I'm less and less inclined to spend time on
glmmadmb bugs when, as far as I know, glmmADMB is dominated by glmmTMB
(i.e., I don't know of anything glmmADMB can do that glmmTMB can't do at
least as well, and as you point out below, it's easy to switch).  Maybe
if you wanted to maintain *exact* numerical equivalence with previous
results ...

On 2019-10-24 1:23 p.m., C. AMAL D. GLELE wrote:
> Hi, all.
> I didn't use my glmmadmb function since about 2 months(it was working fine
> just before);
> but now, I'm getting the following error message
> "Error in scan(text = rr[numLines], quiet = TRUE) :
>   scan() expected 'a real', got 'obs'
> "
>  when trying to fit:
> model<-glmmadmb(total~treatment+(1|day)+(1|fhut), data=mydata,
> family="nbinom")
> but, no problem when I replace glmmadmb by glmmTMB and family by "nbinom1"
> Note:
> I'm using the same computer
> Thanks for your help
> 
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
> Garanti
> sans virus. www.avast.com
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
> <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From th|erry@onke||nx @end|ng |rom |nbo@be  Fri Oct 25 10:30:47 2019
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Fri, 25 Oct 2019 10:30:47 +0200
Subject: [R-sig-ME] 
 About computing covariances between two fixed effects
 with 4 and 5 levels respectively.
In-Reply-To: <ee6e0316ec60433ea6f5bdca0df8320d@unige.ch>
References: <f4d6cae2e09d4335a627dd093bdc37d0@unige.ch>
 <f2ded4c701724c56b987f6f42e081b62@unige.ch>
 <ee6e0316ec60433ea6f5bdca0df8320d@unige.ch>
Message-ID: <CAJuCY5w=2kshXeSwEAQ-HKq7RMsBn5PA8gcReqeWeqqRA+_x2g@mail.gmail.com>

Dear Julian,

The described covariance structures relate to a _random_ effect. You are
looking for _fixed_ effect covariances.

You are probably looking for a model like glmmTMB(Observations ~ CAP *
Condition + (1|ID), data=sdf, ziformula=~1)

I'd also recommend to contact a local statistician about your problem.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op do 24 okt. 2019 om 15:05 schreef Julian Gaviria Lopez <
Julian.GaviriaLopez at unige.ch>:

> Hello,
>
>
> I want to assess the correlation of 4 kinds of brain activation patterns
> (CAP: c1, c2, c3, c4) from 20 subjects, across 5 different conditions
> (Condition: base,  neu, pneu, aff, paff). In total, the count data contains
> 380 observations, and has the next structure:
>
>
>      ID       Observations         CAP          Condition
>
>      1                  6                       c1              base
>
>     ...                 ...                      ...                 ...
>
>     20                 0                       c1              base
>
>     ...                 ...                       ...                 ...
>
>      1                  3                       c4              base
>
>     ...                 ...                       ...                 ...
>
>    20                  0                       c4             base
>
>     1                   4                       c1              neu
>
>     ...                 ...                       ...                ...
>
>    20                  2                       c1              neu
>
>     ...                 ...                       ...                ...
>
>     1                   0                       c4              neu
>
>     ...                 ...                       ...                ...
>
>    20                  5                       c4              neu
>
>     ...                 ...                       ...                ...
>
>    20                  0                       c4              paff
>
>
> I am trying to compute the covariance structures proposed by Kasper
> Kristensen:
>
> https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html
>
>
> When I compute the unstructured covariance:
>
> > fit.us <- glmmTMB(Observations ~ us(CAP + 0 | Condition), data=sdf,
> ziformula=~1)
>
> I obtain the following result:
> > VarCorr(fit.us)
> Conditional model:
>  Groups    Name     Std.Dev. Corr
> Condition  c1         0.86527
>                     c2         0.34487   0.116
>                     c3         0.16450  -0.951  0.164
>                     c4         0.36269   0.414 -0.719 -0.545
>  Residual           1.98011
>
>
> As you might appreciate, the results are either wrong or uncompleted,
> since the right output would yield a 5x4 cov matrix, expressing the
> correlation of the CAPs (c1, c2, c3, c4) across all the conditions (base,
> neu, pneu, aff, paff). One rapid solution is to compute the cov matrix per
> condition. However, apart of  being penalized by model deficiency (I
> guess),  the problem is still present, since the question to answer is how
> the brain activation patterns (CAP) are correlated across all conditions
> (e.g. correlation between "CAP c1 - Condition aff",  and "CAP c4 -
> Condition paff").
>
> Thanks in advance for any comment on this regard.
>
> Best,
>
> Julian Gaviria
> Neurology and Imaging of cognition lab (Labnic)
> University of Geneva. Campus Biotech.
> 9 Chemin des Mines, 1202 Geneva, CH
> Tel: +41 22 379 0380
> Email: Julian.GaviriaLopez at unige.ch
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From g@@d|o @end|ng |rom po@t@bgu@@c@||  Mon Oct 28 10:33:02 2019
From: g@@d|o @end|ng |rom po@t@bgu@@c@|| (Mario Garrido)
Date: Mon, 28 Oct 2019 10:33:02 +0100
Subject: [R-sig-ME] Problems using Anova functions 'type = 2' or 'type = 3'
 from car package with lme
Message-ID: <CAHzBVp+HrRJUCWBLWwLRxAMb1Be0_3y5d5Ne_Juwqy7gfJ1gkw@mail.gmail.com>

Hello,
I use lme to create a linear mixed effects model with three fixed factors
(Treatment, species and Period) and one random factor (individual identity,
ExpID).
After creating the model, I tried to apply Anova from car package to
compute results with both Type II and III Sum of Squares, but I get the
error stated below:
I have UNBALANCED data, more data from sp1 than for the others
These are the data types.

> str(Data)
'data.frame':   496 obs. of  27 variables:
 $ Trtmnt2     : Factor w/ 2 levels "Control","Treated": 2 2 2 2 2 2 2 2 1
1 ...
 $ ExpID       : Factor w/ 62 levels "EA1","EA10","EA11",..: 1 1 1 1 1 1 1
1 10 10 ...
 $ sp          : Factor w/ 3 levels "sp1","sp2","sp3": 2 2 2 2 2 2 2 2 2 2
...
 $ Period      : Factor w/ 5 levels "Before","earlypeak",..: 1 5 2 4 3 5 4
3 1 2 ...
 $ StdzDiff    : num  -51.1 -53.2 -49 22.9 ...

Here is the code to generate the model
> library(car)
> options(contrasts = c("contr.sum", "contr.poly"))

> model<- lme(StdzDiff ~ Trtmnt2*sp*Period, data = Data, random = ~
1|factor(ExpID))
> Anova(model, type=2)  #with type = 3, I have the same problems
Error in I.p[subs.relatives, , drop = FALSE] :
  subscript out of bounds

I have no problems with 'default' anova. But, I get the same error working
with the following code
model<- lme(StdzDiff ~ Trtmnt2*sp*Period, data =
DataFreqDark_StdzDiff_peakAll, random = ~
1|factor(ExpID),contrasts=list(Trtmnt2=contr.sum, sp=contr.sum,
Period=contr.sum))

My questions:
1) What is my error?
2) If Anova from car cannot deal with lme, how can I apply Type III to my
model?
3) To confirm, if I define nothing, anova with lme, is type I by default?

Thanks!

	[[alternative HTML version deleted]]


From g@@d|o @end|ng |rom po@t@bgu@@c@||  Mon Oct 28 11:18:44 2019
From: g@@d|o @end|ng |rom po@t@bgu@@c@|| (Mario Garrido)
Date: Mon, 28 Oct 2019 11:18:44 +0100
Subject: [R-sig-ME] 
 Problems using Anova functions 'type = 2' or 'type = 3'
 from car package with lme
In-Reply-To: <CAHzBVp+HrRJUCWBLWwLRxAMb1Be0_3y5d5Ne_Juwqy7gfJ1gkw@mail.gmail.com>
References: <CAHzBVp+HrRJUCWBLWwLRxAMb1Be0_3y5d5Ne_Juwqy7gfJ1gkw@mail.gmail.com>
Message-ID: <CAHzBVpK=gZ=+YYZuOx4fN4Y+0T9q3gZzaeKL6sYP9xNxidhpyg@mail.gmail.com>

Hi,
I think I have found the solution using:
anova.lme(model,type = "sequential") # same results as anova(model); it
seems logical, since Type I is sequential
anova.lme(model,type = "marginal") # as far as I know, sorry of Im wrong,
Type III is also called marginal

Cheers!

El lun., 28 oct. 2019 a las 10:33, Mario Garrido (<gaadio at post.bgu.ac.il>)
escribi?:

> Hello,
> I use lme to create a linear mixed effects model with three fixed factors
> (Treatment, species and Period) and one random factor (individual identity,
> ExpID).
> After creating the model, I tried to apply Anova from car package to
> compute results with both Type II and III Sum of Squares, but I get the
> error stated below:
> I have UNBALANCED data, more data from sp1 than for the others
> These are the data types.
>
> > str(Data)
> 'data.frame':   496 obs. of  27 variables:
>  $ Trtmnt2     : Factor w/ 2 levels "Control","Treated": 2 2 2 2 2 2 2 2 1
> 1 ...
>  $ ExpID       : Factor w/ 62 levels "EA1","EA10","EA11",..: 1 1 1 1 1 1 1
> 1 10 10 ...
>  $ sp          : Factor w/ 3 levels "sp1","sp2","sp3": 2 2 2 2 2 2 2 2 2 2
> ...
>  $ Period      : Factor w/ 5 levels "Before","earlypeak",..: 1 5 2 4 3 5 4
> 3 1 2 ...
>  $ StdzDiff    : num  -51.1 -53.2 -49 22.9 ...
>
> Here is the code to generate the model
> > library(car)
> > options(contrasts = c("contr.sum", "contr.poly"))
>
> > model<- lme(StdzDiff ~ Trtmnt2*sp*Period, data = Data, random = ~
> 1|factor(ExpID))
> > Anova(model, type=2)  #with type = 3, I have the same problems
> Error in I.p[subs.relatives, , drop = FALSE] :
>   subscript out of bounds
>
> I have no problems with 'default' anova. But, I get the same error
> working with the following code
> model<- lme(StdzDiff ~ Trtmnt2*sp*Period, data =
> DataFreqDark_StdzDiff_peakAll, random = ~
> 1|factor(ExpID),contrasts=list(Trtmnt2=contr.sum, sp=contr.sum,
> Period=contr.sum))
>
> My questions:
> 1) What is my error?
> 2) If Anova from car cannot deal with lme, how can I apply Type III to my
> model?
> 3) To confirm, if I define nothing, anova with lme, is type I by default?
>
> Thanks!
>


-- 
Mario Garrido Escudero, PhD
Dr. Hadas Hawlena Lab
Mitrani Department of Desert Ecology
Jacob Blaustein Institutes for Desert Research
Ben-Gurion University of the Negev
Midreshet Ben-Gurion 84990 ISRAEL

gaiarrido at gmail.com; gaadio at post.bgu.ac.il
phone: (+972) 08-659-6854

	[[alternative HTML version deleted]]


From Ju||@n@G@v|r|@Lopez @end|ng |rom un|ge@ch  Mon Oct 28 12:23:14 2019
From: Ju||@n@G@v|r|@Lopez @end|ng |rom un|ge@ch (Julian Gaviria Lopez)
Date: Mon, 28 Oct 2019 11:23:14 +0000
Subject: [R-sig-ME] 
 Problems using Anova functions 'type = 2' or 'type = 3'
 from car package with lme
In-Reply-To: <CAHzBVpK=gZ=+YYZuOx4fN4Y+0T9q3gZzaeKL6sYP9xNxidhpyg@mail.gmail.com>
References: <CAHzBVp+HrRJUCWBLWwLRxAMb1Be0_3y5d5Ne_Juwqy7gfJ1gkw@mail.gmail.com>,
 <CAHzBVpK=gZ=+YYZuOx4fN4Y+0T9q3gZzaeKL6sYP9xNxidhpyg@mail.gmail.com>
Message-ID: <0a4c0b07a09d4c8c86fa6880692fd51a@unige.ch>

Hi Mario,


Glad to hear you found the solution.  Unfortunately I can not validate it, since I am not a stats expert. I was  thinking that maybe the emmeans package could help you for the post-hoc contrasts, and the interaction analysis:

https://cran.rstudio.com/web/packages/emmeans/vignettes/interactions.html


P.D. The statistician from my dept.  encourages us to work always with ANOVA type II.  Maybe further information about it might be found not here,  but in another list, such as stack overflow.


Best,

Julian Gaviria
Neurology and Imaging of cognition lab (Labnic)
University of Geneva. Campus Biotech.
9 Chemin des Mines, 1202 Geneva, CH
Tel: +41 22 379 0380
Email: Julian.GaviriaLopez at unige.ch
________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Mario Garrido <gaadio at post.bgu.ac.il>
Sent: Monday, October 28, 2019 11:18:44 AM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Problems using Anova functions 'type = 2' or 'type = 3' from car package with lme

Hi,
I think I have found the solution using:
anova.lme(model,type = "sequential") # same results as anova(model); it
seems logical, since Type I is sequential
anova.lme(model,type = "marginal") # as far as I know, sorry of Im wrong,
Type III is also called marginal

Cheers!

El lun., 28 oct. 2019 a las 10:33, Mario Garrido (<gaadio at post.bgu.ac.il>)
escribi?:

> Hello,
> I use lme to create a linear mixed effects model with three fixed factors
> (Treatment, species and Period) and one random factor (individual identity,
> ExpID).
> After creating the model, I tried to apply Anova from car package to
> compute results with both Type II and III Sum of Squares, but I get the
> error stated below:
> I have UNBALANCED data, more data from sp1 than for the others
> These are the data types.
>
> > str(Data)
> 'data.frame':   496 obs. of  27 variables:
>  $ Trtmnt2     : Factor w/ 2 levels "Control","Treated": 2 2 2 2 2 2 2 2 1
> 1 ...
>  $ ExpID       : Factor w/ 62 levels "EA1","EA10","EA11",..: 1 1 1 1 1 1 1
> 1 10 10 ...
>  $ sp          : Factor w/ 3 levels "sp1","sp2","sp3": 2 2 2 2 2 2 2 2 2 2
> ...
>  $ Period      : Factor w/ 5 levels "Before","earlypeak",..: 1 5 2 4 3 5 4
> 3 1 2 ...
>  $ StdzDiff    : num  -51.1 -53.2 -49 22.9 ...
>
> Here is the code to generate the model
> > library(car)
> > options(contrasts = c("contr.sum", "contr.poly"))
>
> > model<- lme(StdzDiff ~ Trtmnt2*sp*Period, data = Data, random = ~
> 1|factor(ExpID))
> > Anova(model, type=2)  #with type = 3, I have the same problems
> Error in I.p[subs.relatives, , drop = FALSE] :
>   subscript out of bounds
>
> I have no problems with 'default' anova. But, I get the same error
> working with the following code
> model<- lme(StdzDiff ~ Trtmnt2*sp*Period, data =
> DataFreqDark_StdzDiff_peakAll, random = ~
> 1|factor(ExpID),contrasts=list(Trtmnt2=contr.sum, sp=contr.sum,
> Period=contr.sum))
>
> My questions:
> 1) What is my error?
> 2) If Anova from car cannot deal with lme, how can I apply Type III to my
> model?
> 3) To confirm, if I define nothing, anova with lme, is type I by default?
>
> Thanks!
>


--
Mario Garrido Escudero, PhD
Dr. Hadas Hawlena Lab
Mitrani Department of Desert Ecology
Jacob Blaustein Institutes for Desert Research
Ben-Gurion University of the Negev
Midreshet Ben-Gurion 84990 ISRAEL

gaiarrido at gmail.com; gaadio at post.bgu.ac.il
phone: (+972) 08-659-6854

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From Ju||@n@G@v|r|@Lopez @end|ng |rom un|ge@ch  Mon Oct 28 14:22:42 2019
From: Ju||@n@G@v|r|@Lopez @end|ng |rom un|ge@ch (Julian Gaviria Lopez)
Date: Mon, 28 Oct 2019 13:22:42 +0000
Subject: [R-sig-ME] 
 About computing covariances between two fixed effects
 with 4 and 5 levels respectively.
In-Reply-To: <CAJuCY5w=2kshXeSwEAQ-HKq7RMsBn5PA8gcReqeWeqqRA+_x2g@mail.gmail.com>
References: <f4d6cae2e09d4335a627dd093bdc37d0@unige.ch>
 <f2ded4c701724c56b987f6f42e081b62@unige.ch>
 <ee6e0316ec60433ea6f5bdca0df8320d@unige.ch>,
 <CAJuCY5w=2kshXeSwEAQ-HKq7RMsBn5PA8gcReqeWeqqRA+_x2g@mail.gmail.com>
Message-ID: <e363de2b3e074735aff032462b058240@unige.ch>

Dear Thierry,


Thank you so much for your comment. In fact, it was the first step of the analysis:

Mol<- glmmTMB(Observations ~ CAP * Condition  + (1|ID), data=mDATA, ziformula=~ 1, family=nbinom1)

I aimed to investigate  the differences between the CAPs (CAP: c1, c2, c3, c4), across 5 conditions (Condition: base, neu, pneu, aff, paff). For this purpose, implemented the Anova function (glmmTMB), and the emmeans package for assessing the interactions.

Another question to answer is how related (i.e., Pearson coefficients for normally distributed and independent data)  are those CAPs to each other,  across conditions (Condition: neu, pneu, aff, paff), being from the same individuals (N=20).  In the previous email, you were right when pointing my confusion between fixed  and random effects.  So, I went on solving my problem, and I found two alternative solutions:

1)   Taking the previous model:
Mol<- glmmTMB(Observations ~ CAP * Condition  + (1|ID), data=mDATA, ziformula=~ 1, family=nbinom1)

We can compute the corr/cov

(vcov(Mol)$cond)

I assume that the output covariance structure is autoregresive (AR1).(Question aside: Is there any way to change the structure when using his function?)

2) Following the previously cited vignette:
https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html

I found the following alternative:
fit.us <- glmmTMB(Observations ~ us(CAP * Condition +  0 | group), data=mDATA)

Where the"group "variable" is just a 1 in every row of the data, and "us" corresponds to the"heterogeneous unstructured" covariance structure.

Regardless of the method, I obtain a correlation values (-1 to 1), of the covariances of the random effect (ID). Therefore, my questions to solve are:
1) Would it be right to interpret the output "correlation" values as the evaluation of the relationship between the factors "CAP" and "Condition" (fixed effects), based on the number of counts  reported in "Observations" (random effect)?

2) I do not manage to obtain the cov/corr values from the intercept. For instance, if the intercept values corresponds to"CAP:c1, Condition: base" how can I obtain the corr/cov values corresponding to the regressors from itself? e.g.:

CAP:c1, Condition: base" - CAP:c1, Condition: neu"
CAP:c1, Condition: base" - CAP:c1, Condition: pneu"
CAP:c1, Condition: base" - CAP:c1, Condition: aff"
CAP:c1, Condition: base" - CAP:c1, Condition: paff"

Thank you so much in advance for any comment.



Julian Gaviria
Neurology and Imaging of cognition lab (Labnic)
University of Geneva. Campus Biotech.
9 Chemin des Mines, 1202 Geneva, CH
Tel: +41 22 379 0380
Email: Julian.GaviriaLopez at unige.ch
________________________________
From: Thierry Onkelinx <thierry.onkelinx at inbo.be>
Sent: Friday, October 25, 2019 10:30:47 AM
To: Julian Gaviria Lopez
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] About computing covariances between two fixed effects with 4 and 5 levels respectively.

Dear Julian,

The described covariance structures relate to a _random_ effect. You are looking for _fixed_ effect covariances.

You are probably looking for a model like glmmTMB(Observations ~ CAP * Condition + (1|ID), data=sdf, ziformula=~1)

I'd also recommend to contact a local statistician about your problem.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be<http://www.inbo.be>

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

[https://inbo-website-prd-532750756126.s3-eu-west-1.amazonaws.com/inbologoleeuw_nl.png]<https://www.inbo.be>


Op do 24 okt. 2019 om 15:05 schreef Julian Gaviria Lopez <Julian.GaviriaLopez at unige.ch<mailto:Julian.GaviriaLopez at unige.ch>>:
Hello,


I want to assess the correlation of 4 kinds of brain activation patterns (CAP: c1, c2, c3, c4) from 20 subjects, across 5 different conditions (Condition: base,  neu, pneu, aff, paff). In total, the count data contains 380 observations, and has the next structure:


     ID       Observations         CAP          Condition

     1                  6                       c1              base

    ...                 ...                      ...                 ...

    20                 0                       c1              base

    ...                 ...                       ...                 ...

     1                  3                       c4              base

    ...                 ...                       ...                 ...

   20                  0                       c4             base

    1                   4                       c1              neu

    ...                 ...                       ...                ...

   20                  2                       c1              neu

    ...                 ...                       ...                ...

    1                   0                       c4              neu

    ...                 ...                       ...                ...

   20                  5                       c4              neu

    ...                 ...                       ...                ...

   20                  0                       c4              paff


I am trying to compute the covariance structures proposed by Kasper Kristensen:

https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html


When I compute the unstructured covariance:

> fit.us<http://fit.us> <- glmmTMB(Observations ~ us(CAP + 0 | Condition), data=sdf, ziformula=~1)

I obtain the following result:
> VarCorr(fit.us<http://fit.us>)
Conditional model:
 Groups    Name     Std.Dev. Corr
Condition  c1         0.86527
                    c2         0.34487   0.116
                    c3         0.16450  -0.951  0.164
                    c4         0.36269   0.414 -0.719 -0.545
 Residual           1.98011


As you might appreciate, the results are either wrong or uncompleted, since the right output would yield a 5x4 cov matrix, expressing the correlation of the CAPs (c1, c2, c3, c4) across all the conditions (base, neu, pneu, aff, paff). One rapid solution is to compute the cov matrix per condition. However, apart of  being penalized by model deficiency (I guess),  the problem is still present, since the question to answer is how the brain activation patterns (CAP) are correlated across all conditions (e.g. correlation between "CAP c1 - Condition aff",  and "CAP c4 - Condition paff").

Thanks in advance for any comment on this regard.

Best,

Julian Gaviria
Neurology and Imaging of cognition lab (Labnic)
University of Geneva. Campus Biotech.
9 Chemin des Mines, 1202 Geneva, CH
Tel: +41 22 379 0380
Email: Julian.GaviriaLopez at unige.ch<mailto:Julian.GaviriaLopez at unige.ch>

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From g@@d|o @end|ng |rom po@t@bgu@@c@||  Mon Oct 28 15:11:28 2019
From: g@@d|o @end|ng |rom po@t@bgu@@c@|| (Mario Garrido)
Date: Mon, 28 Oct 2019 15:11:28 +0100
Subject: [R-sig-ME] 
 Problems using Anova functions 'type = 2' or 'type = 3'
 from car package with lme
In-Reply-To: <0a4c0b07a09d4c8c86fa6880692fd51a@unige.ch>
References: <CAHzBVp+HrRJUCWBLWwLRxAMb1Be0_3y5d5Ne_Juwqy7gfJ1gkw@mail.gmail.com>
 <CAHzBVpK=gZ=+YYZuOx4fN4Y+0T9q3gZzaeKL6sYP9xNxidhpyg@mail.gmail.com>
 <0a4c0b07a09d4c8c86fa6880692fd51a@unige.ch>
Message-ID: <CAHzBVpJmKbEZrD1Srq1PJGpL8WcMpgg1Qw2CU6EvVbc36J2K8Q@mail.gmail.com>

Thanks Julian,
for your clarification and the recommendation of this package. It would be
great if at any moment the statistician from your working place, or any
other expert in this forum, can tell us:
*1. Why Type II is better?* I personally read different reasons in favour
or against its use. Also, I read about using Type III, but since Im not an
expert, I decide to go for Type III since STATISTICA, SPSS and other
softwares use it.
*2. What's different from Type II and Type III?* In my trials, I see that
both do not depend on the order we 'enter' the data, but differences on the
F and P-value of the main effects when there is an interaction in the
model. In any place I read that Type III is better when we have a
significant interaction while Type II when not. In any case
3. due to marginality principle, neither with Type II or Type III we can
interpret the main effects when are involved in an interaction, right?
4. *Do this affects also interactions? *when a higher-order interaction in
present, lower order ones can be interpreted?

Thanks

El lun., 28 oct. 2019 a las 12:23, Julian Gaviria Lopez (<
Julian.GaviriaLopez at unige.ch>) escribi?:

> Hi Mario,
>
>
> Glad to hear you found the solution.  Unfortunately I can not validate it,
> since I am not a stats expert. I was  thinking that maybe the emmeans
> package could help you for the post-hoc contrasts, and the interaction
> analysis:
>
> https://cran.rstudio.com/web/packages/emmeans/vignettes/interactions.html
>
>
> P.D. The statistician from my dept.  encourages us to work always
> with ANOVA type II.  Maybe further information about it might be found not
> here,  but in another list, such as stack overflow.
>
>
> Best,
>
> Julian Gaviria
> Neurology and Imaging of cognition lab (Labnic)
> University of Geneva. Campus Biotech.
> 9 Chemin des Mines, 1202 Geneva, CH
> Tel: +41 22 379 0380
> Email: Julian.GaviriaLopez at unige.ch
> ------------------------------
> *From:* R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on
> behalf of Mario Garrido <gaadio at post.bgu.ac.il>
> *Sent:* Monday, October 28, 2019 11:18:44 AM
> *To:* r-sig-mixed-models at r-project.org
> *Subject:* Re: [R-sig-ME] Problems using Anova functions 'type = 2' or
> 'type = 3' from car package with lme
>
> Hi,
> I think I have found the solution using:
> anova.lme(model,type = "sequential") # same results as anova(model); it
> seems logical, since Type I is sequential
> anova.lme(model,type = "marginal") # as far as I know, sorry of Im wrong,
> Type III is also called marginal
>
> Cheers!
>
> El lun., 28 oct. 2019 a las 10:33, Mario Garrido (<gaadio at post.bgu.ac.il>)
> escribi?:
>
> > Hello,
> > I use lme to create a linear mixed effects model with three fixed factors
> > (Treatment, species and Period) and one random factor (individual
> identity,
> > ExpID).
> > After creating the model, I tried to apply Anova from car package to
> > compute results with both Type II and III Sum of Squares, but I get the
> > error stated below:
> > I have UNBALANCED data, more data from sp1 than for the others
> > These are the data types.
> >
> > > str(Data)
> > 'data.frame':   496 obs. of  27 variables:
> >  $ Trtmnt2     : Factor w/ 2 levels "Control","Treated": 2 2 2 2 2 2 2 2
> 1
> > 1 ...
> >  $ ExpID       : Factor w/ 62 levels "EA1","EA10","EA11",..: 1 1 1 1 1 1
> 1
> > 1 10 10 ...
> >  $ sp          : Factor w/ 3 levels "sp1","sp2","sp3": 2 2 2 2 2 2 2 2 2
> 2
> > ...
> >  $ Period      : Factor w/ 5 levels "Before","earlypeak",..: 1 5 2 4 3 5
> 4
> > 3 1 2 ...
> >  $ StdzDiff    : num  -51.1 -53.2 -49 22.9 ...
> >
> > Here is the code to generate the model
> > > library(car)
> > > options(contrasts = c("contr.sum", "contr.poly"))
> >
> > > model<- lme(StdzDiff ~ Trtmnt2*sp*Period, data = Data, random = ~
> > 1|factor(ExpID))
> > > Anova(model, type=2)  #with type = 3, I have the same problems
> > Error in I.p[subs.relatives, , drop = FALSE] :
> >   subscript out of bounds
> >
> > I have no problems with 'default' anova. But, I get the same error
> > working with the following code
> > model<- lme(StdzDiff ~ Trtmnt2*sp*Period, data =
> > DataFreqDark_StdzDiff_peakAll, random = ~
> > 1|factor(ExpID),contrasts=list(Trtmnt2=contr.sum, sp=contr.sum,
> > Period=contr.sum))
> >
> > My questions:
> > 1) What is my error?
> > 2) If Anova from car cannot deal with lme, how can I apply Type III to my
> > model?
> > 3) To confirm, if I define nothing, anova with lme, is type I by default?
> >
> > Thanks!
> >
>
>
> --
> Mario Garrido Escudero, PhD
> Dr. Hadas Hawlena Lab
> Mitrani Department of Desert Ecology
> Jacob Blaustein Institutes for Desert Research
> Ben-Gurion University of the Negev
> Midreshet Ben-Gurion 84990 ISRAEL
>
> gaiarrido at gmail.com; gaadio at post.bgu.ac.il
> phone: (+972) 08-659-6854
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
Mario Garrido Escudero, PhD
Dr. Hadas Hawlena Lab
Mitrani Department of Desert Ecology
Jacob Blaustein Institutes for Desert Research
Ben-Gurion University of the Negev
Midreshet Ben-Gurion 84990 ISRAEL

gaiarrido at gmail.com; gaadio at post.bgu.ac.il
phone: (+972) 08-659-6854

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Mon Oct 28 17:23:43 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 28 Oct 2019 12:23:43 -0400
Subject: [R-sig-ME] 
 Problems using Anova functions 'type = 2' or 'type = 3'
 from car package with lme
In-Reply-To: <CAHzBVpJmKbEZrD1Srq1PJGpL8WcMpgg1Qw2CU6EvVbc36J2K8Q@mail.gmail.com>
References: <CAHzBVp+HrRJUCWBLWwLRxAMb1Be0_3y5d5Ne_Juwqy7gfJ1gkw@mail.gmail.com>
 <CAHzBVpK=gZ=+YYZuOx4fN4Y+0T9q3gZzaeKL6sYP9xNxidhpyg@mail.gmail.com>
 <0a4c0b07a09d4c8c86fa6880692fd51a@unige.ch>
 <CAHzBVpJmKbEZrD1Srq1PJGpL8WcMpgg1Qw2CU6EvVbc36J2K8Q@mail.gmail.com>
Message-ID: <0fdae896-3299-d79f-12ae-ab4bd2b9bdec@gmail.com>



On 2019-10-28 10:11 a.m., Mario Garrido wrote:
> Thanks Julian,
> for your clarification and the recommendation of this package. It would be
> great if at any moment the statistician from your working place, or any
> other expert in this forum, can tell us:
> *1. Why Type II is better?* I personally read different reasons in favour
> or against its use. Also, I read about using Type III, but since Im not an
> expert, I decide to go for Type III since STATISTICA, SPSS and other
> softwares use it.

   There are long arguments about this (see e.g. Venables "exegeses on
linear models", old papers by Nelder et al).  Type 3 can violate the
principle of marginality; type 2 doesn't.  Results of type 3 depend on
the parameterization/contrasts used, and *may* lead to silly tests (or
to not testing what you think you're testing).


> *2. What's different from Type II and Type III?* In my trials, I see that
> both do not depend on the order we 'enter' the data, but differences on the
> F and P-value of the main effects when there is an interaction in the
> model. In any place I read that Type III is better when we have a
> significant interaction while Type II when not. 

  type 3 tests lower-level effects in the presence of higher-level ones.
 Whether you think this makes sense depends on your statistical
philosophy and what you're doing.  It is indeed true that the difference
only emerges in models with interactions.  Tests of the highest-level
interaction in the model should be identical with type 2 vs type 3.

  My personal philosophy is that I try never to base any decision about
statistical procedure (e.g. type 2 vs 3) on whether some component of
the model statistically significant or not.


In any case
> 3. due to marginality principle, neither with Type II or Type III we can
> interpret the main effects when are involved in an interaction, right?

  If you hold to the principle of marginality strictly, yes.


> 4. *Do this affects also interactions? *when a higher-order interaction in
> present, lower order ones can be interpreted?

  Principle of marginality says you shouldn't interpret a *lower-level*
effect in the presence of a *higher-level* effect involving the same
terms (so, if A:B:C interaction is in your model, don't interpret A:B,
B:C, A:C, A, B, or C).

  I don't personally hold strongly to the principle of marginality.  My
rule would be "if you aren't sure exactly what your test of a given
effect means, then don't interpret it".  That means that a type-3 test
*could* be OK, if you know what parameterization you're using and
therefore what hypothesis the test actually corresponds to.  If you'd
rather not think about all this stuff, then never use type 3 (which
violates the principle of marginality).


> 
> Thanks
> 
> El lun., 28 oct. 2019 a las 12:23, Julian Gaviria Lopez (<
> Julian.GaviriaLopez at unige.ch>) escribi?:
> 
>> Hi Mario,
>>
>>
>> Glad to hear you found the solution.  Unfortunately I can not validate it,
>> since I am not a stats expert. I was  thinking that maybe the emmeans
>> package could help you for the post-hoc contrasts, and the interaction
>> analysis:
>>
>> https://cran.rstudio.com/web/packages/emmeans/vignettes/interactions.html
>>
>>
>> P.D. The statistician from my dept.  encourages us to work always
>> with ANOVA type II.  Maybe further information about it might be found not
>> here,  but in another list, such as stack overflow.
>>
>>
>> Best,
>>
>> Julian Gaviria
>> Neurology and Imaging of cognition lab (Labnic)
>> University of Geneva. Campus Biotech.
>> 9 Chemin des Mines, 1202 Geneva, CH
>> Tel: +41 22 379 0380
>> Email: Julian.GaviriaLopez at unige.ch
>> ------------------------------
>> *From:* R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on
>> behalf of Mario Garrido <gaadio at post.bgu.ac.il>
>> *Sent:* Monday, October 28, 2019 11:18:44 AM
>> *To:* r-sig-mixed-models at r-project.org
>> *Subject:* Re: [R-sig-ME] Problems using Anova functions 'type = 2' or
>> 'type = 3' from car package with lme
>>
>> Hi,
>> I think I have found the solution using:
>> anova.lme(model,type = "sequential") # same results as anova(model); it
>> seems logical, since Type I is sequential
>> anova.lme(model,type = "marginal") # as far as I know, sorry of Im wrong,
>> Type III is also called marginal
>>
>> Cheers!
>>
>> El lun., 28 oct. 2019 a las 10:33, Mario Garrido (<gaadio at post.bgu.ac.il>)
>> escribi?:
>>
>>> Hello,
>>> I use lme to create a linear mixed effects model with three fixed factors
>>> (Treatment, species and Period) and one random factor (individual
>> identity,
>>> ExpID).
>>> After creating the model, I tried to apply Anova from car package to
>>> compute results with both Type II and III Sum of Squares, but I get the
>>> error stated below:
>>> I have UNBALANCED data, more data from sp1 than for the others
>>> These are the data types.
>>>
>>>> str(Data)
>>> 'data.frame':   496 obs. of  27 variables:
>>>  $ Trtmnt2     : Factor w/ 2 levels "Control","Treated": 2 2 2 2 2 2 2 2
>> 1
>>> 1 ...
>>>  $ ExpID       : Factor w/ 62 levels "EA1","EA10","EA11",..: 1 1 1 1 1 1
>> 1
>>> 1 10 10 ...
>>>  $ sp          : Factor w/ 3 levels "sp1","sp2","sp3": 2 2 2 2 2 2 2 2 2
>> 2
>>> ...
>>>  $ Period      : Factor w/ 5 levels "Before","earlypeak",..: 1 5 2 4 3 5
>> 4
>>> 3 1 2 ...
>>>  $ StdzDiff    : num  -51.1 -53.2 -49 22.9 ...
>>>
>>> Here is the code to generate the model
>>>> library(car)
>>>> options(contrasts = c("contr.sum", "contr.poly"))
>>>
>>>> model<- lme(StdzDiff ~ Trtmnt2*sp*Period, data = Data, random = ~
>>> 1|factor(ExpID))
>>>> Anova(model, type=2)  #with type = 3, I have the same problems
>>> Error in I.p[subs.relatives, , drop = FALSE] :
>>>   subscript out of bounds
>>>
>>> I have no problems with 'default' anova. But, I get the same error
>>> working with the following code
>>> model<- lme(StdzDiff ~ Trtmnt2*sp*Period, data =
>>> DataFreqDark_StdzDiff_peakAll, random = ~
>>> 1|factor(ExpID),contrasts=list(Trtmnt2=contr.sum, sp=contr.sum,
>>> Period=contr.sum))
>>>
>>> My questions:
>>> 1) What is my error?
>>> 2) If Anova from car cannot deal with lme, how can I apply Type III to my
>>> model?
>>> 3) To confirm, if I define nothing, anova with lme, is type I by default?
>>>
>>> Thanks!
>>>
>>
>>
>> --
>> Mario Garrido Escudero, PhD
>> Dr. Hadas Hawlena Lab
>> Mitrani Department of Desert Ecology
>> Jacob Blaustein Institutes for Desert Research
>> Ben-Gurion University of the Negev
>> Midreshet Ben-Gurion 84990 ISRAEL
>>
>> gaiarrido at gmail.com; gaadio at post.bgu.ac.il
>> phone: (+972) 08-659-6854
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
>


From g@@d|o @end|ng |rom po@t@bgu@@c@||  Tue Oct 29 18:55:34 2019
From: g@@d|o @end|ng |rom po@t@bgu@@c@|| (Mario Garrido)
Date: Tue, 29 Oct 2019 18:55:34 +0100
Subject: [R-sig-ME] [FORGED] Re: Export several lme outputs to a single
 excel file
In-Reply-To: <a5a79f10-8ea3-df15-a606-26073b3dafe7@auckland.ac.nz>
References: <CAHzBVpLYYAu8tc6Tku2Wmooi=PqJdai8s326Mb8x=DzozKCUVQ@mail.gmail.com>
 <20190925205548.GF22724@info124.pharmacie.univ-paris5.fr>
 <CAHzBVp+qQqCG24qhBk6Fu1pTtVAg_VZcb9w_A9jj9srefrYNkw@mail.gmail.com>
 <a5a79f10-8ea3-df15-a606-26073b3dafe7@auckland.ac.nz>
Message-ID: <CAHzBVpKPpzDhUpcFXH-yuq9YSRMTC9gHGAUyycyKMRQsrRveGA@mail.gmail.com>

Hi again,
after adding a column with the name using the command $Md to Anova models,
I tried to do the same, but for any reason is not working.
I create a series of model and make them compete:
> lmeGPBYPGAlowNULL <- lme(StdzDiff ~ 1, data = DataBM_GP_StdzDiffGAlow,
random = ~ 1|factor(ExpID),method="ML")
> lmeGPBYPGAlowOnlyT <- lme(StdzDiff ~ Trtmnt2, data =
DataBM_GP_StdzDiffGAlow, random = ~ 1|factor(ExpID),method="ML")
> (msAICc <- model.sel(lmeGPBYPGAlowNULL,lmeGPBYPGAlowOnlyT))
Model selection table
                   (Intrc) Trtm2 df  logLik  AICc delta weight
lmeGPBYPGAlowNULL    3.367        3 -73.434 154.4  0.00   0.83
lmeGPBYPGAlowOnlyT   3.367     +  4 -73.433 157.5  3.17   0.17
Models ranked by AICc(x)
Random terms (all models):
?1 | factor(ExpID)?

Then I get the results of the Model selection, and a column with the name.
> BM_MuMIn_GP_ByP_GAlow<-(msAICc <-
model.sel(lmeGPBYPGAlowNULL,lmeGPBYPGAlowOnlyT))
> BM_MuMIn_GP_ByP_GAlow$Md<-"BM GP MuMIn By periods GAlow"

It seems that there is no problem. And t confirm I run it
> BM_MuMIn_GP_ByP_GAlow
Model selection table
                   (Intrc) Trtm2 df  logLik  AICc delta weight
              Md
lmeGPBYPGAlowNULL    3.367        3 -73.434 154.4  0.00   0.83 BM GP MuMIn
By periods GAlow
lmeGPBYPGAlowOnlyT   3.367     +  4 -73.433 157.5  3.17   0.17 BM GP MuMIn
By periods GAlow
Models ranked by AICc(x)
Random terms (all models):
?1 | factor(ExpID)?

*BUT*, when I do the same with other objects with the same amount of
columns, etc and bind them, the column Md doesnt appear
> BM_MuMIn_GP_AllP_results <-
rbind(BM_MuMIn_GP_AllP_peakAll,BM_MuMIn_GP_AllP_earlypeak,BM_MuMIn_GP_AllP_latepeak)
> BM_MuMIn_GP_AllP_results
Model selection table
                     (Int) Tr2 Prd Prd:Tr2 df   logLik  AICc delta weight
lmeGPAllPearlypNULL  1.547                  3 -261.853 530.0  0.00  0.521
lmeGPAllPpAllNULL    1.441                  3 -262.736 531.8  1.77  0.215
lmeGPAllPearlypOnlyT 1.547   +              4 -261.824 532.1  2.14  0.178
lmeGPAllPpAllOnlyT   1.441   +              4 -262.714 533.9  3.92  0.073
lmeGPAllPlatepNULL   1.229                  3 -266.356 539.0  9.01  0.006
lmeGPAllPlatepOnlyT  1.229   +              4 -266.346 541.2 11.19  0.002
lmeGPAllPearlyp2wTP  1.587   +   +       + 10 -259.508 541.9 11.95  0.001
lmeGPAllPearlyp2wTP1 1.587   +   +       + 10 -259.508 541.9 11.95  0.001
lmeGPAllPpAll2wTP    1.484   +   +       + 10 -260.089 543.1 13.11  0.001
lmeGPAllPpAll2wTP1   1.484   +   +       + 10 -260.089 543.1 13.11  0.001
lmeGPAllPlatep2wTP   1.277   +   +       + 10 -262.725 548.4 18.39  0.000
lmeGPAllPlatep2wTP1  1.277   +   +       + 10 -262.725 548.4 18.39  0.000


But still each object have the Md column
> BM_MuMIn_GP_AllP_peakAll
Model selection table
                   (Int) Tr2 Prd Prd:Tr2 df   logLik  AICc delta weight
                                  Md
lmeGPAllPpAllNULL  1.441                  3 -262.736 531.8  0.00  0.742 BM
GP MuMIn All periods Interact peakAll
lmeGPAllPpAllOnlyT 1.441   +              4 -262.714 533.9  2.16  0.252 BM
GP MuMIn All periods Interact peakAll
lmeGPAllPpAll2wTP  1.484   +   +       + 10 -260.089 543.1 11.35  0.003 BM
GP MuMIn All periods Interact peakAll
lmeGPAllPpAll2wTP1 1.484   +   +       + 10 -260.089 543.1 11.35  0.003 BM
GP MuMIn All periods Interact peakAll
Models ranked by AICc(x)
Random terms (all models):
?1 | factor(ExpID)?
> BM_MuMIn_GP_AllP_earlypeak
Model selection table
                     (Int) Tr2 Prd Prd:Tr2 df   logLik  AICc delta weight
                                      Md
lmeGPAllPearlypNULL  1.547                  3 -261.853 530.0  0.00  0.742
BM GP MuMIn All periods Interact earlypeak
lmeGPAllPearlypOnlyT 1.547   +              4 -261.824 532.1  2.14  0.254
BM GP MuMIn All periods Interact earlypeak
lmeGPAllPearlyp2wTP  1.587   +   +       + 10 -259.508 541.9 11.95  0.002
BM GP MuMIn All periods Interact earlypeak
lmeGPAllPearlyp2wTP1 1.587   +   +       + 10 -259.508 541.9 11.95  0.002
BM GP MuMIn All periods Interact earlypeak
Models ranked by AICc(x)
Random terms (all models):
?1 | factor(ExpID)?
> BM_MuMIn_GP_AllP_latepeak
Model selection table
                    (Int) Tr2 Prd Prd:Tr2 df   logLik  AICc delta weight
                                     Md
lmeGPAllPlatepNULL  1.229                  3 -266.356 539.0  0.00  0.738 BM
GP MuMIn All periods Interact latepeak
lmeGPAllPlatepOnlyT 1.229   +              4 -266.346 541.2  2.18  0.248 BM
GP MuMIn All periods Interact latepeak
lmeGPAllPlatep2wTP  1.277   +   +       + 10 -262.725 548.4  9.38  0.007 BM
GP MuMIn All periods Interact latepeak
lmeGPAllPlatep2wTP1 1.277   +   +       + 10 -262.725 548.4  9.38  0.007 BM
GP MuMIn All periods Interact latepeak
Models ranked by AICc(x)
Random terms (all models):
?1 | factor(ExpID)?



El mar., 8 oct. 2019 a las 11:08, Rolf Turner (<r.turner at auckland.ac.nz>)
escribi?:

>
> On 8/10/19 9:28 PM, Mario Garrido wrote:
>
> > Dear Emmanuel Curis,
> > your approach was working perfectly, but at some point w gives me the
> > error. when introduced the new column
> > I have no problem in running model, the errors appears when introducing
> > extra $Md column. I wonder whether the problem is the * of the
> > significance, but is not, also is not due to character strings since my
> > variables are recognized as factors. I have no missing data in my
> > matrix,... And, as I said, problem only arise when I introduced the new
> > column
> >
> > Thanks in advanxe
> >> anova(TempLight_StdzDiff_3trt_earlypeak)-> r15
> >> r15
> > Analysis of Variance Table
> >
> > Response: StdzDiff
> >            Df  Sum Sq Mean Sq F value  Pr(>F)
> > Trtmnt     2   0.991  0.4953  0.2382 0.78891
> > sp         2  13.781  6.8904  3.3134 0.04407 *
> > Trtmnt:sp  4   4.123  1.0306  0.4956 0.73898
> > Residuals 53 110.217  2.0796
> > ---
> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >> r15$Md<- "TempLight_StdzDiff_3trt_earlypeak"
> >> r15
> > Analysis of Variance Table
> >
> > Response: StdzDiff
> >            Df  Sum Sq Mean Sq F value  Pr(>F) Md
> > Trtmnt     2   0.991  0.4953  0.2382 0.78891
> > sp         2  13.781  6.8904  3.3134 0.04407
> > Trtmnt:sp  4   4.123  1.0306  0.4956 0.73898
> > Residuals 53 110.217  2.0796
> > Warning message:
> > In data.matrix(x) : NAs introducidos por coerci?n
>
> This is a "generic" problem; it is not peculiar to your model nor to
> models fitted using lme, or other mixed modelling software.
>
> Consider the following example:
>
> set.seed(42)
> x <- 1:20
> y <- rnorm(20)
> fit <- lm(y ~ x)
> m   <- anova(fit)
> m$newColumn <- "yeeeeks"
> m
>
> This produces:
>
> > Analysis of Variance Table
> >
> > Response: y
> >           Df Sum Sq Mean Sq F value  Pr(>F) newColumn
> > x          1  4.113  4.1130  2.5865 0.12518
> > Residuals 18 28.624  1.5902
> > Warning message:
> > In data.matrix(x) : NAs introduced by coercion
>
> The "reason" is that m is (in the first instance) of class "anova" and
> there are (not unreasonably) certain restrictions as to how you can
> treat an object of this class.
>
> A work-around to get something like what you appear to want could be:
>
> set.seed(42)
> x <- 1:20
> y <- rnorm(20)
> fit <- lm(y ~ x)
> m   <- anova(fit)
> m   <- cbind(m,newColumn=c("yeeeks",rep("",nrow(m)-1)))
> m
>
> However m is now of class "data.frame" whence it is printed by the
> method print.data.frame() rather than print.anova().  Consequently NAs
> show up in the output of the print method:
>
>            Df      Sum Sq    Mean Sq    F value    Pr(>F) newColumn
> x          1  0.04176282 0.04176282 0.03784897 0.8479256    yeeeks
> Residuals 18 19.86132473 1.10340693         NA        NA
>
> You could just live with those NAs, or you could convert the "F value"
> and "Pr(>F)" columns from numeric to character mode and replace the NAs
> by null strings "".
>
> HTH
>
> cheers,
>
> Rolf Turner
>
> --
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>


-- 
Mario Garrido Escudero, PhD
Dr. Hadas Hawlena Lab
Mitrani Department of Desert Ecology
Jacob Blaustein Institutes for Desert Research
Ben-Gurion University of the Negev
Midreshet Ben-Gurion 84990 ISRAEL

gaiarrido at gmail.com; gaadio at post.bgu.ac.il
phone: (+972) 08-659-6854

	[[alternative HTML version deleted]]


From |brom@no77 @end|ng |rom gm@||@com  Thu Oct 31 15:36:49 2019
From: |brom@no77 @end|ng |rom gm@||@com (Francesco Romano)
Date: Thu, 31 Oct 2019 15:36:49 +0100
Subject: [R-sig-ME] Running corrections for multiple comparisons in glmer
Message-ID: <CABX-QoEjCVPB44-ZJZ7F7aAZSs2SgxJUajOcvkvVHU6YtEY0uw@mail.gmail.com>

Dear all,

A reviewer has asked me to apply a correction to multiple comparisons
conducted for a logistic mixed effect regression with binary outcome. The
model is:

glmer(outcome ~ factor1 * factor2 + (1|RE1) + (1|RE2), family =binomial,
data = data)

where factor 1 has two levels and factor 2 has three. Could you advise on
how to run this and how to report the adjusted p-values in the same table?
At the moment, my table has the following 6 headings:

Reference level

Contrasts

Estimate

SE

Wald *z*

*p*


Many thanks in advance,

Frank

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Thu Oct 31 15:58:14 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 31 Oct 2019 10:58:14 -0400
Subject: [R-sig-ME] 
 Running corrections for multiple comparisons in glmer
In-Reply-To: <CABX-QoEjCVPB44-ZJZ7F7aAZSs2SgxJUajOcvkvVHU6YtEY0uw@mail.gmail.com>
References: <CABX-QoEjCVPB44-ZJZ7F7aAZSs2SgxJUajOcvkvVHU6YtEY0uw@mail.gmail.com>
Message-ID: <e2a08ceb-0079-1fff-1220-60cf704830ba@gmail.com>



 you could  "just" use p.adjust(), something like this:

library(lme4)
gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
                   data = cbpp, family = binomial)
cc <- coef(summary(gm1))
cc <- cbind(cc,adjust.p=p.adjust(cc[,"Pr(>|z|)"],"holm"))


  The general machinery in the multcomp package (especially the glht
function) should work.

This looks useful:

https://thebiobucket.blogspot.com/2011/06/glmm-with-custom-multiple-comparisons.html

  The bottom line is that most standard multiple-comparisons or
pairwise-comparisons machinery should "just work" with glmer fits.
(There are some open questions about what you're doing: it's a bit
unusual for people to apply multiple comparisons corrections on a set of
"only" 6 parameters specified a priori: Tukey adjustments to post hoc
pairwise comparisons are much more common ...)

On 2019-10-31 10:36 a.m., Francesco Romano wrote:
> Dear all,
> 
> A reviewer has asked me to apply a correction to multiple comparisons
> conducted for a logistic mixed effect regression with binary outcome. The
> model is:
> 
> glmer(outcome ~ factor1 * factor2 + (1|RE1) + (1|RE2), family =binomial,
> data = data)
> 
> where factor 1 has two levels and factor 2 has three. Could you advise on
> how to run this and how to report the adjusted p-values in the same table?
> At the moment, my table has the following 6 headings:
> 
> Reference level
> 
> Contrasts
> 
> Estimate
> 
> SE
> 
> Wald *z*
> 
> *p*
> 
> 
> Many thanks in advance,
> 
> Frank
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From @ndre@p@rd@|@@ouz@ @end|ng |rom gm@||@com  Thu Oct 31 18:39:23 2019
From: @ndre@p@rd@|@@ouz@ @end|ng |rom gm@||@com (=?UTF-8?Q?Andr=C3=A9_Pardal?=)
Date: Thu, 31 Oct 2019 17:39:23 +0000
Subject: [R-sig-ME] Advice on repeated-measures mixed model (lmer)
Message-ID: <CAFxBq7x6iRxuSTgT+=wp0Dry-a9bgAnipK2BOqZVBJ0=TfrX+g@mail.gmail.com>

Hey everyone,

I am wondering if someone could advice me on a repeated-measure mixed model
analysis.

So, I carried out an experiment of effect of contamination by antifouling
paint on predator-prey interaction (snails and barnacles).

I have the repeated-measures of number of barnacles consume through time in
different treatments (AP and control) in each replicate (cages). See
structure of my dataframe below. (Everything is balanced.)

> str(consumption)
'data.frame': 96 obs. of  9 variables:
 $ tr            : Factor w/ 2 levels "antifouling paint",..: 1 1 1 1 1 1 1
1 1 1 ...
 $ replicate  : Factor w/ 16 levels "AP1","AP2","AP3",..: 1 2 3 4 5 6 7 8 1
2 ...
 $ time        : int  0 0 0 0 0 0 0 0 27 27 ...
 $ cons        : int  0 0 0 0 0 0 0 0 19 37 ...
 $ cons_pc   : num  0 0 0 0 0 ...

1) My first doubt is about day 0. In day 0 there is no consumption, so I
have a lot of zeros what is giving me trouble to meet a normal
distribution. My doubt here is if I should/could (or not) to remove day 0
from analysis. I did some tests and removed day 0, and I got far better
normal distribution.

2) I am running the following mixed-model, but I am not sure if it is
right. As consumption is 0 in day 0, I am running a mixed-model with
varying slope only. Also, what I want is set a model in each the slope
varies randomly per replicate through time. That's what I am running:

*m1 = lmer(cons_pc ~ tr*time + (time-1|replicate), data= consumption)*

Alternatively, I could have:

*m2 = lmer(cons_pc ~ tr*time + (1+time|replicate), data= consumption)*#
intercept and slope varying per replicate
*m3 = lmer(cons_pc ~ tr*time + (1|replicate), data= consumption)* #
intercept only varying per replicate

I think the first model is the right one, but I am not sure. Anyone could
confirm?

I ran all of them as a test and all of them work, and the first one is the
best one (according to AIC score and LR-test).

Thanks very much in advance.

My best,

Andre.
-- 

Visiting PhD student
School of Ocean Sciences
Bangor University
Menai Bridge, Anglesey, UK

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Sat Nov  2 02:00:03 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 1 Nov 2019 21:00:03 -0400
Subject: [R-sig-ME] Your response to my R-sig-ME question
In-Reply-To: <CABX-QoEXOJCLbJktFLw78dba=1nkgvEsK08XfVbMVPwaG3G=GQ@mail.gmail.com>
References: <CABX-QoEXOJCLbJktFLw78dba=1nkgvEsK08XfVbMVPwaG3G=GQ@mail.gmail.com>
Message-ID: <c5952d23-0ab9-e201-f775-5c90d89f5dff@gmail.com>


  [cc'ing r-sig-mixed-models]

  Honestly, it looks to me like you *do* need multiple-comparisons
corrections here. I can't give you detailed advice about how to do it;
emmeans does the pairwise comparisons, but it's not immediately obvious
how to do correction for *multiple* sets of pairwise comparisons.
(Perhaps you could get away with only doing the corrections at the level
of sets of pairwise comparisons.)  As I mentioned before, this is not a
particularly mixed-model-related question.  You could try CrossValidated
(https://stats.stackexchange.com).  The emmeans and multcomp packages
will probably be what you need in terms of machinery.

  sincerely
   Ben Bolker


On 2019-11-01 6:40 a.m., Francesco Romano wrote:
> Dear Ben,
> 
> 
> Apologies for emailing directly about this but there seems to be a
> problem with my subscription settings to the list at the moment. Had it
> not been for Ian Dworkin's message content, I never would have known you
> had also replied.
> 
> Fortunately, I managed to fetch your message from the r-sig-ME
> repository which I copy below:
> 
> "you could "just" use p.adjust(), something like this: library(lme4) gm1
> <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd), data
> = cbpp, family = binomial) cc <- coef(summary(gm1)) cc <-
> cbind(cc,adjust.p=p.adjust(cc[,"Pr(>|z|)"],"holm")) The general
> machinery in the multcomp package (especially the glht function) should
> work. This looks useful:
> https://thebiobucket.blogspot.com/2011/06/glmm-with-custom-multiple-comparisons.html
> The bottom line is that most standard multiple-comparisons or
> pairwise-comparisons machinery should "just work" with glmer fits.
> (There are some open questions about what you're doing: it's a bit
> unusual for people to apply multiple comparisons corrections on a set of
> "only" 6 parameters specified a priori: Tukey adjustments to post hoc
> pairwise comparisons are much more common ...)"
> 
> To fully understand your advice about using the multcomp package and/or
> tukey adjustments, I need to put this better into perspective for you. I
> have attached the table whose results the editor of the journal is
> requesting multiple comparison corrections for. All the pairwise
> comparisons had no a-priori hypotheses about them. It was simply a
> matter of ascertaining whether there were any significant differences
> between each pair of groups (factor 1) for a given level of complexity
> (factor 2) and vice versa, for each pair of levels of complexity at a
> given level of group. I did this by looking at simple effects and
> re-leveling.
> 
> Honestly, it is the first time someone asks me to apply corrections so I
> am not too sure either. What I would like, though, is to offer a cogent
> response as to why that should not be necessary.
> 
> Any help is much appreciated,
> 
> Frank Romano On 2019-10-31 10:36 a.m., Francesco Romano wrote: >/Dear
> all, />//>/A reviewer has asked me to apply a correction to multiple
> comparisons />/conducted for a logistic mixed effect regression with
> binary outcome. The />/model is: />//>/glmer(outcome ~ factor1 * factor2
> + (1|RE1) + (1|RE2), family =binomial, />/data = data) />//>/where
> factor 1 has two levels and factor 2 has three. Could you advise on
> />/how to run this and how to report the adjusted p-values in the same
> table? />/At the moment, my table has the following 6 headings:
> />//>/Reference level />//>/Contrasts />//>/Estimate />//>/SE />//>/Wald
> *z* />//>/*p* />//>//>/Many thanks in advance, />//>/Frank />//
> 
> 
> 
> Best,
> 
> Frank


From je@@|c@821112 @end|ng |rom gm@||@com  Sat Nov  2 19:40:15 2019
From: je@@|c@821112 @end|ng |rom gm@||@com (Chia-Yu Chen)
Date: Sat, 2 Nov 2019 19:40:15 +0100
Subject: [R-sig-ME] Doubtful significance in mixed effect model
Message-ID: <78B7183F-D5C1-4622-BA8A-B1852C5AD8AB@gmail.com>

Hi,

I have a problem on the significance of age and sex when running glmer on my longitudinal data. 

My data
A longitudinal data where each patient is tested at 3 timepoints (here, define as ?case?). There are different treatments between cases. Along with ?case?, other factors include age, sex and drug dosages. So it looked something like this (there are 23 patients, each has 3 cases)

Patient   Case   Age   Sex   DrugA   DrugB   Value
    1            1        10      0        5           10         20
    1            2        10      0       10           0          30
    1            3        10      0       15           0          55

What I want to do
The goal of this study is to show that ?value? is significantly different across ?cases?. Age, sex, drugA, drugB are all potential confounders. Here I want to see if either of these factors has confounding effects, that is, whether adding these factors to the model will be better or not.

How I did it
First, I constructed 2 nested models, and then I compared the 2 models with likelihood test. If m2 is better than m1, then I assume this factor has significance for value. Since it?s a longitudinal data, the ?patient? is treated as random factor. I ran through the factors one by one, here take ?sex? for example:

m1 <- lme4::glmer(data = subdata, formula =  value ~  Case + (1 | Patient))
m2 <- lme4::glmer(data = subdata, formula =  value ~  Case + (1 | Patient) + ( Sex | Patient))
p_value  <- lmtest::lrtest (m1, m2)$"Pr(>Chisq)"[2]

My Question
I expected that m2 shouldn?t be better than m1 for sex and age, because for each patient they didn?t change over 3 cases. I thought by specifying "( Sex | Patient)? in the model would tell R that sex doesn?t change for each patient, and thus it doesn?t have any predictive ability for the value. However, lrtest showed that for some patients, m2 is better than m1, meaning that age or sex is significant. I?m wondering is there anything wrong in my codes? Doesn?t ( Sex | Patient) tell R that sex doesn?t change for each patient? How should I code so that m2 won?t be better than m1 for sex and age? Or is there any better way doing this?
I?ve tried many combinations of the code, but I still can?t solve this problem. Could anyone give me some advices? Any suggestion is appreciated! Thank you in advance.

Best,
Chia-Yu





	[[alternative HTML version deleted]]


From ru@@e||-|enth @end|ng |rom u|ow@@edu  Sat Nov  2 23:25:37 2019
From: ru@@e||-|enth @end|ng |rom u|ow@@edu (Lenth, Russell V)
Date: Sat, 2 Nov 2019 22:25:37 +0000
Subject: [R-sig-ME] Your response to my R-sig-ME question
Message-ID: <DM6PR04MB438084D57E44BFBA85B23DD7F17D0@DM6PR04MB4380.namprd04.prod.outlook.com>

If the question is how to do multiplicity adjustments for multiple sets of comparisons in 'emmeans', that is pretty simple to do. For example, starting with

    library("emmeans")
    emm <- emmeans(model, ~ factor1 | factor2)

By default,

    pairs(emm, by = "factor1")

will apply the Tukey adjustment to the pairwise comparisons of factor2 for each level of factor1, SEPARATELY. If instead, you want to multiplicity-adjust all of those simple comparisons as one family, summarize those results after removing the 'by' variable:

    summary(pairs(emm, by = "factor1"), by = NULL, adjust = "mvt")

(Note that the Tukey adjustment is not appropriate for that family because it is not ONE set of pairwise comparisons. The mvt adjustment is the same adjustment that the multcomp package appluies by default.)

You of course may also want simple comparisons of factor1 for each level of factor2; just reverse the roles of the two factors in the above.

If you want to combine both of those families into a single family consisting of all simple comparisons of both factor2|factor1 and factor1|factor2, that can be done as well via 'rbind':

    allcmps <- pairs(emm, simple = "each")   # creates a list of two emmGrid objects
    summary(do.call(rbind, allcmps), adjust = "mvt")

I hope that helps

Russ

Russell V. Lenth? -? Professor Emeritus
Department of Statistics and Actuarial Science?? 
The University of Iowa ?-? Iowa City, IA 52242? USA?? 
Voice (319)335-0712 (Dept. office)? -? FAX (319)335-3017



-----Original Message-----

Date: Fri, 1 Nov 2019 21:00:03 -0400
From: Ben Bolker <bbolker at gmail.com>
To: Francesco Romano <fbromano77 at gmail.com>
Cc: "r-sig-mixed-models at r-project.org"
	<r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Your response to my R-sig-ME question
Message-ID: <c5952d23-0ab9-e201-f775-5c90d89f5dff at gmail.com>
Content-Type: text/plain; charset="utf-8"


  [cc'ing r-sig-mixed-models]

  Honestly, it looks to me like you *do* need multiple-comparisons corrections here. I can't give you detailed advice about how to do it; emmeans does the pairwise comparisons, but it's not immediately obvious how to do correction for *multiple* sets of pairwise comparisons.
(Perhaps you could get away with only doing the corrections at the level of sets of pairwise comparisons.)  As I mentioned before, this is not a particularly mixed-model-related question.  You could try CrossValidated (https://stats.stackexchange.com).  The emmeans and multcomp packages will probably be what you need in terms of machinery.

  sincerely
   Ben Bolker


From th|erry@onke||nx @end|ng |rom |nbo@be  Mon Nov  4 09:33:48 2019
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Mon, 4 Nov 2019 09:33:48 +0100
Subject: [R-sig-ME] Doubtful significance in mixed effect model
In-Reply-To: <78B7183F-D5C1-4622-BA8A-B1852C5AD8AB@gmail.com>
References: <78B7183F-D5C1-4622-BA8A-B1852C5AD8AB@gmail.com>
Message-ID: <CAJuCY5wmo1u8qjdKU+4Ov5De4VuMYNOXs-n28C0PXikkoTZqFg@mail.gmail.com>

Dear Chia-Yu,

(A|B) defines a random slope along A within each level of grouping factor
B. In maths you can write it as b_i0 + b_i1 * A with b_i0 the random
intercept and b_i1 the random slope for level i from B.
Random slopes are only relevant is the variable A as different values
**within** levels of B. So if age and sex don't change within patient, it
doesn't make sense to add them as a random effect.

A good exploratory data analysis and common sense is a better way to look
for confounding factors.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op za 2 nov. 2019 om 19:41 schreef Chia-Yu Chen <jessica821112 at gmail.com>:

> Hi,
>
> I have a problem on the significance of age and sex when running glmer on
> my longitudinal data.
>
> My data
> A longitudinal data where each patient is tested at 3 timepoints (here,
> define as ?case?). There are different treatments between cases. Along with
> ?case?, other factors include age, sex and drug dosages. So it looked
> something like this (there are 23 patients, each has 3 cases)
>
> Patient   Case   Age   Sex   DrugA   DrugB   Value
>     1            1        10      0        5           10         20
>     1            2        10      0       10           0          30
>     1            3        10      0       15           0          55
>
> What I want to do
> The goal of this study is to show that ?value? is significantly different
> across ?cases?. Age, sex, drugA, drugB are all potential confounders. Here
> I want to see if either of these factors has confounding effects, that is,
> whether adding these factors to the model will be better or not.
>
> How I did it
> First, I constructed 2 nested models, and then I compared the 2 models
> with likelihood test. If m2 is better than m1, then I assume this factor
> has significance for value. Since it?s a longitudinal data, the ?patient?
> is treated as random factor. I ran through the factors one by one, here
> take ?sex? for example:
>
> m1 <- lme4::glmer(data = subdata, formula =  value ~  Case + (1 | Patient))
> m2 <- lme4::glmer(data = subdata, formula =  value ~  Case + (1 | Patient)
> + ( Sex | Patient))
> p_value  <- lmtest::lrtest (m1, m2)$"Pr(>Chisq)"[2]
>
> My Question
> I expected that m2 shouldn?t be better than m1 for sex and age, because
> for each patient they didn?t change over 3 cases. I thought by specifying
> "( Sex | Patient)? in the model would tell R that sex doesn?t change for
> each patient, and thus it doesn?t have any predictive ability for the
> value. However, lrtest showed that for some patients, m2 is better than m1,
> meaning that age or sex is significant. I?m wondering is there anything
> wrong in my codes? Doesn?t ( Sex | Patient) tell R that sex doesn?t change
> for each patient? How should I code so that m2 won?t be better than m1 for
> sex and age? Or is there any better way doing this?
> I?ve tried many combinations of the code, but I still can?t solve this
> problem. Could anyone give me some advices? Any suggestion is appreciated!
> Thank you in advance.
>
> Best,
> Chia-Yu
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Mon Nov  4 09:46:00 2019
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Mon, 4 Nov 2019 09:46:00 +0100
Subject: [R-sig-ME] Advice on repeated-measures mixed model (lmer)
In-Reply-To: <CAFxBq7x6iRxuSTgT+=wp0Dry-a9bgAnipK2BOqZVBJ0=TfrX+g@mail.gmail.com>
References: <CAFxBq7x6iRxuSTgT+=wp0Dry-a9bgAnipK2BOqZVBJ0=TfrX+g@mail.gmail.com>
Message-ID: <CAJuCY5w2Jn-DZFM_T1W6oVkUCjgEQwPmiMMP4AC1y-JB6n9u+Q@mail.gmail.com>

Dear Andre,

Q1: you have count data, they don't follow a normal distribution. Use a
Poisson or negative binomial distribution.
Q2: confirming the best model without access to the data is not possible.
Plot the predictions of the models, so you get an idea of different
structures that they model. See what makes sense for your data and what not.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op do 31 okt. 2019 om 18:39 schreef Andr? Pardal <
andre.pardal.souza at gmail.com>:

> Hey everyone,
>
> I am wondering if someone could advice me on a repeated-measure mixed model
> analysis.
>
> So, I carried out an experiment of effect of contamination by antifouling
> paint on predator-prey interaction (snails and barnacles).
>
> I have the repeated-measures of number of barnacles consume through time in
> different treatments (AP and control) in each replicate (cages). See
> structure of my dataframe below. (Everything is balanced.)
>
> > str(consumption)
> 'data.frame': 96 obs. of  9 variables:
>  $ tr            : Factor w/ 2 levels "antifouling paint",..: 1 1 1 1 1 1 1
> 1 1 1 ...
>  $ replicate  : Factor w/ 16 levels "AP1","AP2","AP3",..: 1 2 3 4 5 6 7 8 1
> 2 ...
>  $ time        : int  0 0 0 0 0 0 0 0 27 27 ...
>  $ cons        : int  0 0 0 0 0 0 0 0 19 37 ...
>  $ cons_pc   : num  0 0 0 0 0 ...
>
> 1) My first doubt is about day 0. In day 0 there is no consumption, so I
> have a lot of zeros what is giving me trouble to meet a normal
> distribution. My doubt here is if I should/could (or not) to remove day 0
> from analysis. I did some tests and removed day 0, and I got far better
> normal distribution.
>
> 2) I am running the following mixed-model, but I am not sure if it is
> right. As consumption is 0 in day 0, I am running a mixed-model with
> varying slope only. Also, what I want is set a model in each the slope
> varies randomly per replicate through time. That's what I am running:
>
> *m1 = lmer(cons_pc ~ tr*time + (time-1|replicate), data= consumption)*
>
> Alternatively, I could have:
>
> *m2 = lmer(cons_pc ~ tr*time + (1+time|replicate), data= consumption)*#
> intercept and slope varying per replicate
> *m3 = lmer(cons_pc ~ tr*time + (1|replicate), data= consumption)* #
> intercept only varying per replicate
>
> I think the first model is the right one, but I am not sure. Anyone could
> confirm?
>
> I ran all of them as a test and all of them work, and the first one is the
> best one (according to AIC score and LR-test).
>
> Thanks very much in advance.
>
> My best,
>
> Andre.
> --
>
> Visiting PhD student
> School of Ocean Sciences
> Bangor University
> Menai Bridge, Anglesey, UK
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From dm|ch| @end|ng |rom un|-pot@d@m@de  Mon Nov  4 11:20:44 2019
From: dm|ch| @end|ng |rom un|-pot@d@m@de (Diana Michl)
Date: Mon, 4 Nov 2019 11:20:44 +0100
Subject: [R-sig-ME] Fwd: Re:  Doubtful significance in mixed effect model
In-Reply-To: <B70D9BF0-FECC-4347-9A37-66BF36F6EACC@gmail.com>
References: <B70D9BF0-FECC-4347-9A37-66BF36F6EACC@gmail.com>
Message-ID: <b8582bff-c3c9-0e4e-f94f-ad82df1bb673@uni-potsdam.de>

Sorry I forgot to send my response below to the entire list.

Glad I could help.

Best



-------- Weitergeleitete Nachricht --------
Betreff: 	Re: [R-sig-ME] Doubtful significance in mixed effect model
Datum: 	Mon, 4 Nov 2019 00:24:33 +0100
Von: 	Chia-Yu Chen <jessica821112 at gmail.com>
An: 	Diana Michl <dmichl at uni-potsdam.de>



Dear Diana,

Thank you so much for your reply! I didn?t know my syntax was wrong 
until I read your explanations. They are really helpful, and I have 
solved my problem by specifying that age and sex are nested within 
patient. Thank you once again :)

Best wishes,
Chia-Yu

> On Nov 2, 2019, at 21:54, Diana Michl <dmichl at uni-potsdam.de 
> <mailto:dmichl at uni-potsdam.de>> wrote:
>
> Hi Chia-Yu,
>
> (Sex | Patient) isn't right exactly because sex does not change within 
> a patient. What you probably mean is (1|sex/patient), the / implies 
> that sex is nested within patient. What you wrote means pretty much 
> the opposite, that sex does vary by patient and that you want a 
> different intercept for sex for each patient.
>
> If sex varies BY anything at all, it's definitely not the patient. You 
> might need to tell us what sex varies by. Or you write (1 | sex) if 
> you want different intercepts for sex. _However,_ it seems to me it 
> makes more sense to include sex as fixed effect!
>
> Secondly, if you want a random effect like (sex |...) at all, you 
> should include sex as a fixed effect in addition, anyway.
>
> So this is probably your best choice:
>
> lme4::glmer(data = subdata, formula =  value ~  Case + Sex + (1 | Patient)
>
> or, only if it makes sense:
>
> lme4::glmer(data = subdata, formula =  value ~  Case + Sex + (1 | Patient) + ( Sex | ...?))
>
> or, also only if it really makes sense:
>
> m2 <- lme4::glmer(data = subdata, formula =  value ~  Case + (1 | Patient) + ( 1 | Sex))
>
> Diana
>   
> Am 02.11.2019 um 19:40 schrieb Chia-Yu Chen:
>> Hi,
>>
>> I have a problem on the significance of age and sex when running glmer on my longitudinal data.
>>
>> My data
>> A longitudinal data where each patient is tested at 3 timepoints (here, define as ?case?). There are different treatments between cases. Along with ?case?, other factors include age, sex and drug dosages. So it looked something like this (there are 23 patients, each has 3 cases)
>>
>> Patient   Case   Age   Sex   DrugA   DrugB   Value
>>      1            1        10      0        5           10         20
>>      1            2        10      0       10           0          30
>>      1            3        10      0       15           0          55
>>
>> What I want to do
>> The goal of this study is to show that ?value? is significantly different across ?cases?. Age, sex, drugA, drugB are all potential confounders. Here I want to see if either of these factors has confounding effects, that is, whether adding these factors to the model will be better or not.
>>
>> How I did it
>> First, I constructed 2 nested models, and then I compared the 2 models with likelihood test. If m2 is better than m1, then I assume this factor has significance for value. Since it?s a longitudinal data, the ?patient? is treated as random factor. I ran through the factors one by one, here take ?sex? for example:
>>
>> m1 <- lme4::glmer(data = subdata, formula =  value ~  Case + (1 | Patient))
>> m2 <- lme4::glmer(data = subdata, formula =  value ~  Case + (1 | Patient) + ( Sex | Patient))
>> p_value  <- lmtest::lrtest (m1, m2)$"Pr(>Chisq)"[2]
>>
>> My Question
>> I expected that m2 shouldn?t be better than m1 for sex and age, because for each patient they didn?t change over 3 cases. I thought by specifying "( Sex | Patient)? in the model would tell R that sex doesn?t change for each patient, and thus it doesn?t have any predictive ability for the value. However, lrtest showed that for some patients, m2 is better than m1, meaning that age or sex is significant. I?m wondering is there anything wrong in my codes? Doesn?t ( Sex | Patient) tell R that sex doesn?t change for each patient? How should I code so that m2 won?t be better than m1 for sex and age? Or is there any better way doing this?
>> I?ve tried many combinations of the code, but I still can?t solve this problem. Could anyone give me some advices? Any suggestion is appreciated! Thank you in advance.
>>
>> Best,
>> Chia-Yu
>>
>>
>>
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org  mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> -- 
> Diana Michl, M.A.
> PhD candidate
> International Experimental Linguistics
> Universit?t Potsdam/FU Berlin
> uni-potsdam.de/en/ling/staff-list/diana-michl.html 
> <http://uni-potsdam.de/en/ling/staff-list/diana-michl.html>
>
> #Recently published:
> Michl, D. (2019). Metonymies are more literal than metaphors: evidence 
> from ratings of German idioms. Language and Cognition, 11(1), 98?124. 
> https://doi.org/10.1017/langcog.2019.7
> Michl, D. (2019). Speedy Metonymy, Tricky Metaphor, Irrelevant 
> Compositionality: How Nonliteralness Affects Idioms in Reading and 
> Rating. Journal of Psycholinguistic Research, 2(1), 56?82.
> https://doi.org/10.1007/s10936-019-09658-7
>


	[[alternative HTML version deleted]]


From tor@ten@h@u||e @end|ng |rom gm@||@com  Thu Nov  7 14:12:33 2019
From: tor@ten@h@u||e @end|ng |rom gm@||@com (Torsten Hauffe)
Date: Thu, 7 Nov 2019 14:12:33 +0100
Subject: [R-sig-ME] Subjecting data to differential equations deSolve
Message-ID: <CAGCrCxav2ZMC0Pq+migjo+19n6jFP6e8rYiupZDMak9oWffvhQ@mail.gmail.com>

Dear list,

My apologies if this question doesn't fit the scope of the mailing list.

I try to solve some differential equations with the deSolve::ode and need
to feed some values at certain time-points into the equations.

Anyone has a guess why the results are off by factor 10?

Thanks for any input and cheers,
Torsten

Here is a simplified reproducible example:

# Time of observations
ObsTime <- c(1.9, 2.0, 2.1, 3.9, 4.0, 4.1, 9.9, 10.0, 10.1, 23.9, 24.0,
24.1)

# Value of the observations
Obs <- c(0, 6, 0, 0, 3, 0, 0, 3, 0, 0, 3, 0)

# following the second example of ode(), it needs a function from where
values could be obtained as function of time
obs3Func <- approxfun(ObsTime, Obs, method = "constant", rule = 2)

# Subjecting the time to the approx-function works
obs3Func(ObsTime)

# A simple function that I expect to return the cumulative sum of Obs (i.e.
15)
Test_rhs <- function(t, x, parms, obsFunc)
{
  with(as.list(c(parms, x)), {
    Sa <- obsFunc(t)
    list(Sa * s)
  })
}

Test <- ode(y = 0,
            times = seq(0, 65, by = 0.1),
            func = Test_rhs,
            parms = list(s = 1),
            obsFunc = obs3Func)

# Using s = 1, the results are off (my expectation) by factor 10
plot(Test)

# With s = 10 the result is as expected but I don't know why
Test2 <- ode(y = 0,
            times = seq(0, 65, by = 0.1),
            func = Test_rhs,
            parms = list(s = 1),
            obsFunc = obs3Func)
plot(Test2)
# Changepoints & values
Time <- c(2, 4, 10, 24)
abline(v = Time, lty = 2, col = "grey")
points(ObsTime, cumsum(Obs), pch = 19)

	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Thu Nov  7 23:01:50 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Fri, 8 Nov 2019 11:01:50 +1300
Subject: [R-sig-ME] [FORGED] Subjecting data to differential equations
 deSolve
In-Reply-To: <CAGCrCxav2ZMC0Pq+migjo+19n6jFP6e8rYiupZDMak9oWffvhQ@mail.gmail.com>
References: <CAGCrCxav2ZMC0Pq+migjo+19n6jFP6e8rYiupZDMak9oWffvhQ@mail.gmail.com>
Message-ID: <71688763-b4a5-f25b-de8e-5bc9a2aa0d37@auckland.ac.nz>


Maybe I'm obtuse (some would say that there's no "maybe" about it! :-) ) 
but I cannot for the life of me see what this question has to do with 
mixed models.

Why not ask it on plain vanilla r-help???

cheers,

Rolf Turner

On 8/11/19 2:12 AM, Torsten Hauffe wrote:
> Dear list,
> 
> My apologies if this question doesn't fit the scope of the mailing list.
> 
> I try to solve some differential equations with the deSolve::ode and need
> to feed some values at certain time-points into the equations.
> 
> Anyone has a guess why the results are off by factor 10?
> 
> Thanks for any input and cheers,
> Torsten
> 
> Here is a simplified reproducible example:
> 
> # Time of observations
> ObsTime <- c(1.9, 2.0, 2.1, 3.9, 4.0, 4.1, 9.9, 10.0, 10.1, 23.9, 24.0,
> 24.1)
> 
> # Value of the observations
> Obs <- c(0, 6, 0, 0, 3, 0, 0, 3, 0, 0, 3, 0)
> 
> # following the second example of ode(), it needs a function from where
> values could be obtained as function of time
> obs3Func <- approxfun(ObsTime, Obs, method = "constant", rule = 2)
> 
> # Subjecting the time to the approx-function works
> obs3Func(ObsTime)
> 
> # A simple function that I expect to return the cumulative sum of Obs (i.e.
> 15)
> Test_rhs <- function(t, x, parms, obsFunc)
> {
>    with(as.list(c(parms, x)), {
>      Sa <- obsFunc(t)
>      list(Sa * s)
>    })
> }
> 
> Test <- ode(y = 0,
>              times = seq(0, 65, by = 0.1),
>              func = Test_rhs,
>              parms = list(s = 1),
>              obsFunc = obs3Func)
> 
> # Using s = 1, the results are off (my expectation) by factor 10
> plot(Test)
> 
> # With s = 10 the result is as expected but I don't know why
> Test2 <- ode(y = 0,
>              times = seq(0, 65, by = 0.1),
>              func = Test_rhs,
>              parms = list(s = 1),
>              obsFunc = obs3Func)
> plot(Test2)
> # Changepoints & values
> Time <- c(2, 4, 10, 24)
> abline(v = Time, lty = 2, col = "grey")
> points(ObsTime, cumsum(Obs), pch = 19)


From tr|chter @end|ng |rom un|-bremen@de  Fri Nov  8 17:03:33 2019
From: tr|chter @end|ng |rom un|-bremen@de (Tim Richter-Heitmann)
Date: Fri, 8 Nov 2019 17:03:33 +0100
Subject: [R-sig-ME] mixed models with very few measurements by subject
Message-ID: <237f9963-64ad-1d7f-0332-f038d6964347@uni-bremen.de>

Dear list,

sorry for bothering.

I was presented this type of data:

Abundance = my response variable, 300 observations per species, no NAs

habitat_type = a fixed effect, a factor with 9 levels.

sample_location = a random effect, a factor with 150? levels. I assume 
there is enough unmeasured variability to warrant this as a random factor

landscape = another random factor of three levels, in which 
sample_location is nested within.

Notice that not every sample_location or landscape contains all levels 
of habitat_type.

Every sample_location was measured twice with an interval of 1 year 
inbetween.? In principle, this can be coded as factor as well, to 
account for temporal variability. Initial analysis showed there is very 
little temporal variability.

But then i am left with only one observation per location, and i was 
reading 
(https://stats.stackexchange.com/questions/242821/how-will-random-effects-with-only-1-observation-affect-a-generalized-linear-mixe) 
that this way

residual errors and random effects may be confounded. Landscape has 50 
observations, but only three groups, which i think is also not a wise 
option, as per 
https://stats.stackexchange.com/questions/37647/what-is-the-minimum-recommended-number-of-groups-for-a-random-effects-factor.

I am interested in Abundance ~ habitat_type and if there are differences 
in abundance means. I first totally ignored the existence of 
sample_location:

mod <- aov(Abundance~habitat_type); res <- glht(mod, 
mcp(habitat_type="Tukey", vcov=vcovHC).

And then i compared this to

 ?amod <- lme(fixed=Abundance~habitat_type, data = D, random = 
~1|sample_location , method="ML") ;? means <- emmeans(amod, ~habitat_type)

There are very few differences between the two approaches. I also 
ignored landscape at this level.

My Questions:

1. Are sample_location (many subjects, few observations) and landscape 
(few groups, many observations) suitable candidates to be modelled as a 
random effect?

2. Can their nestedness save me, and how would i code 
Landscape:sample_location?

3. Would it better to code the locations as coordinates and check for 
different correlation structures in gls?


Thank you for your kind advice!


-- 
Dr. Tim Richter-Heitmann

University of Bremen
Microbial Ecophysiology Group (AG Friedrich)
FB02 - Biologie/Chemie
Leobener Stra?e (NW2 A2130)
D-28359 Bremen
Tel.: 0049(0)421 218-63062
Fax: 0049(0)421 218-63069


From cvonende @end|ng |rom n|u@edu  Fri Nov  8 17:56:40 2019
From: cvonende @end|ng |rom n|u@edu (Carl Von Ende)
Date: Fri, 8 Nov 2019 16:56:40 +0000
Subject: [R-sig-ME] solve some differential equations with the deSolve
Message-ID: <B0286AA1-FF96-43F5-AC26-EF6E284D9366@niu.edu>

Hi Torsten,

You are in luck. There is a R mailing list for deSolve.  I believe it is moderated by Thomas Petzoldt.  Here is the link to subscribe to it, if you wish.   

https://stat.ethz.ch/mailman/listinfo/r-sig-dynamic-models

This is the address of the mailing list. 

r-sig-dynamic-models at r-project.org



Best Regards, 

Carl von Ende
Dept. Biol. Sciences
Northern Ill. Univ. 
DeKalb, IL 60115



?On 11/8/19, 5:02 AM, "R-sig-mixed-models on behalf of r-sig-mixed-models-request at r-project.org" <r-sig-mixed-models-bounces at r-project.org on behalf of r-sig-mixed-models-request at r-project.org> wrote:

    Send R-sig-mixed-models mailing list submissions to
    	r-sig-mixed-models at r-project.org
    
    To subscribe or unsubscribe via the World Wide Web, visit
    	https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
    or, via email, send a message with subject or body 'help' to
    	r-sig-mixed-models-request at r-project.org
    
    You can reach the person managing the list at
    	r-sig-mixed-models-owner at r-project.org
    
    When replying, please edit your Subject line so it is more specific
    than "Re: Contents of R-sig-mixed-models digest..."
    
    
    Today's Topics:
    
       1. Subjecting data to differential equations deSolve (Torsten Hauffe)
       2. Re: [FORGED] Subjecting data to differential equations
          deSolve (Rolf Turner)
    
    ----------------------------------------------------------------------
    
    Message: 1
    Date: Thu, 7 Nov 2019 14:12:33 +0100
    From: Torsten Hauffe <torsten.hauffe at gmail.com>
    To: R-mixed models mailing list <r-sig-mixed-models at r-project.org>
    Subject: [R-sig-ME] Subjecting data to differential equations deSolve
    Message-ID:
    	<CAGCrCxav2ZMC0Pq+migjo+19n6jFP6e8rYiupZDMak9oWffvhQ at mail.gmail.com>
    Content-Type: text/plain; charset="utf-8"
    
    Dear list,
    
    My apologies if this question doesn't fit the scope of the mailing list.
    
    I try to solve some differential equations with the deSolve::ode and need
    to feed some values at certain time-points into the equations.
    
    Anyone has a guess why the results are off by factor 10?
    
    Thanks for any input and cheers,
    Torsten
    
    Here is a simplified reproducible example:
    
    # Time of observations
    ObsTime <- c(1.9, 2.0, 2.1, 3.9, 4.0, 4.1, 9.9, 10.0, 10.1, 23.9, 24.0,
    24.1)
    
    # Value of the observations
    Obs <- c(0, 6, 0, 0, 3, 0, 0, 3, 0, 0, 3, 0)
    
    # following the second example of ode(), it needs a function from where
    values could be obtained as function of time
    obs3Func <- approxfun(ObsTime, Obs, method = "constant", rule = 2)
    
    # Subjecting the time to the approx-function works
    obs3Func(ObsTime)
    
    # A simple function that I expect to return the cumulative sum of Obs (i.e.
    15)
    Test_rhs <- function(t, x, parms, obsFunc)
    {
      with(as.list(c(parms, x)), {
        Sa <- obsFunc(t)
        list(Sa * s)
      })
    }
    
    Test <- ode(y = 0,
                times = seq(0, 65, by = 0.1),
                func = Test_rhs,
                parms = list(s = 1),
                obsFunc = obs3Func)
    
    # Using s = 1, the results are off (my expectation) by factor 10
    plot(Test)
    
    # With s = 10 the result is as expected but I don't know why
    Test2 <- ode(y = 0,
                times = seq(0, 65, by = 0.1),
                func = Test_rhs,
                parms = list(s = 1),
                obsFunc = obs3Func)
    plot(Test2)
    # Changepoints & values
    Time <- c(2, 4, 10, 24)
    abline(v = Time, lty = 2, col = "grey")
    points(ObsTime, cumsum(Obs), pch = 19)
    
    	[[alternative HTML version deleted]]
    
    
    
    
    ------------------------------
    
    Message: 2
    Date: Fri, 8 Nov 2019 11:01:50 +1300
    From: Rolf Turner <r.turner at auckland.ac.nz>
    To: Torsten Hauffe <torsten.hauffe at gmail.com>, R-mixed models mailing
    	list <r-sig-mixed-models at r-project.org>
    Subject: Re: [R-sig-ME] [FORGED] Subjecting data to differential
    	equations deSolve
    Message-ID: <71688763-b4a5-f25b-de8e-5bc9a2aa0d37 at auckland.ac.nz>
    Content-Type: text/plain; charset="utf-8"; Format="flowed"
    
    
    Maybe I'm obtuse (some would say that there's no "maybe" about it! :-) ) 
    but I cannot for the life of me see what this question has to do with 
    mixed models.
    
    Why not ask it on plain vanilla r-help???
    
    cheers,
    
    Rolf Turner
    
    On 8/11/19 2:12 AM, Torsten Hauffe wrote:
    > Dear list,
    > 
    > My apologies if this question doesn't fit the scope of the mailing list.
    > 
    > I try to solve some differential equations with the deSolve::ode and need
    > to feed some values at certain time-points into the equations.
    > 
    > Anyone has a guess why the results are off by factor 10?
    > 
    > Thanks for any input and cheers,
    > Torsten
    > 
    > Here is a simplified reproducible example:
    > 
    > # Time of observations
    > ObsTime <- c(1.9, 2.0, 2.1, 3.9, 4.0, 4.1, 9.9, 10.0, 10.1, 23.9, 24.0,
    > 24.1)
    > 
    > # Value of the observations
    > Obs <- c(0, 6, 0, 0, 3, 0, 0, 3, 0, 0, 3, 0)
    > 
    > # following the second example of ode(), it needs a function from where
    > values could be obtained as function of time
    > obs3Func <- approxfun(ObsTime, Obs, method = "constant", rule = 2)
    > 
    > # Subjecting the time to the approx-function works
    > obs3Func(ObsTime)
    > 
    > # A simple function that I expect to return the cumulative sum of Obs (i.e.
    > 15)
    > Test_rhs <- function(t, x, parms, obsFunc)
    > {
    >    with(as.list(c(parms, x)), {
    >      Sa <- obsFunc(t)
    >      list(Sa * s)
    >    })
    > }
    > 
    > Test <- ode(y = 0,
    >              times = seq(0, 65, by = 0.1),
    >              func = Test_rhs,
    >              parms = list(s = 1),
    >              obsFunc = obs3Func)
    > 
    > # Using s = 1, the results are off (my expectation) by factor 10
    > plot(Test)
    > 
    > # With s = 10 the result is as expected but I don't know why
    > Test2 <- ode(y = 0,
    >              times = seq(0, 65, by = 0.1),
    >              func = Test_rhs,
    >              parms = list(s = 1),
    >              obsFunc = obs3Func)
    > plot(Test2)
    > # Changepoints & values
    > Time <- c(2, 4, 10, 24)
    > abline(v = Time, lty = 2, col = "grey")
    > points(ObsTime, cumsum(Obs), pch = 19)
    
    
    
    
    ------------------------------
    
    Subject: Digest Footer
    
    _______________________________________________
    R-sig-mixed-models mailing list
    R-sig-mixed-models at r-project.org
    https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
    
    
    ------------------------------
    
    End of R-sig-mixed-models Digest, Vol 155, Issue 5
    **************************************************
    


From th|erry@onke||nx @end|ng |rom |nbo@be  Sat Nov  9 13:23:05 2019
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Sat, 9 Nov 2019 13:23:05 +0100
Subject: [R-sig-ME] mixed models with very few measurements by subject
In-Reply-To: <237f9963-64ad-1d7f-0332-f038d6964347@uni-bremen.de>
References: <237f9963-64ad-1d7f-0332-f038d6964347@uni-bremen.de>
Message-ID: <CAJuCY5xfiTSfNM1x4S4tnmMctgybhPEHje5ZZUXNo_NZK=G6pg@mail.gmail.com>

Dear Tim,

Abundance is probably a count variable. If so, consider using a
distribution that handles count variables (e.g. Poisson, negative binomial,
...).

I'll use lme4 notation.

1 . You can either use landscape + (1|sample_location) or
just (1|sample_location). The main difference is the first model fit the
common landscape effect via the landscape variable whereas those effects
are handled by (1|sample_location) in the second model (given
sample_location is nested in landscape).
2. Since you have only three landscape classes, I recommend to keep the
landscape as a fixed effect
3. You could fit a variogram on the BLUP of the sample_location to see if
there is spatial autocorrelation. The value of take spatial autocorrelation
into account will depend on the strength of the spatial autocorrelation.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op vr 8 nov. 2019 om 17:04 schreef Tim Richter-Heitmann <
trichter at uni-bremen.de>:

> Dear list,
>
> sorry for bothering.
>
> I was presented this type of data:
>
> Abundance = my response variable, 300 observations per species, no NAs
>
> habitat_type = a fixed effect, a factor with 9 levels.
>
> sample_location = a random effect, a factor with 150  levels. I assume
> there is enough unmeasured variability to warrant this as a random factor
>
> landscape = another random factor of three levels, in which
> sample_location is nested within.
>
> Notice that not every sample_location or landscape contains all levels
> of habitat_type.
>
> Every sample_location was measured twice with an interval of 1 year
> inbetween.  In principle, this can be coded as factor as well, to
> account for temporal variability. Initial analysis showed there is very
> little temporal variability.
>
> But then i am left with only one observation per location, and i was
> reading
> (
> https://stats.stackexchange.com/questions/242821/how-will-random-effects-with-only-1-observation-affect-a-generalized-linear-mixe)
>
> that this way
>
> residual errors and random effects may be confounded. Landscape has 50
> observations, but only three groups, which i think is also not a wise
> option, as per
>
> https://stats.stackexchange.com/questions/37647/what-is-the-minimum-recommended-number-of-groups-for-a-random-effects-factor
> .
>
> I am interested in Abundance ~ habitat_type and if there are differences
> in abundance means. I first totally ignored the existence of
> sample_location:
>
> mod <- aov(Abundance~habitat_type); res <- glht(mod,
> mcp(habitat_type="Tukey", vcov=vcovHC).
>
> And then i compared this to
>
>   amod <- lme(fixed=Abundance~habitat_type, data = D, random =
> ~1|sample_location , method="ML") ;  means <- emmeans(amod, ~habitat_type)
>
> There are very few differences between the two approaches. I also
> ignored landscape at this level.
>
> My Questions:
>
> 1. Are sample_location (many subjects, few observations) and landscape
> (few groups, many observations) suitable candidates to be modelled as a
> random effect?
>
> 2. Can their nestedness save me, and how would i code
> Landscape:sample_location?
>
> 3. Would it better to code the locations as coordinates and check for
> different correlation structures in gls?
>
>
> Thank you for your kind advice!
>
>
> --
> Dr. Tim Richter-Heitmann
>
> University of Bremen
> Microbial Ecophysiology Group (AG Friedrich)
> FB02 - Biologie/Chemie
> Leobener Stra?e (NW2 A2130)
> D-28359 Bremen
> Tel.: 0049(0)421 218-63062
> Fax: 0049(0)421 218-63069
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From jk|ng@ton @end|ng |rom ||ngu|@t@um@@@@edu  Sun Nov 10 19:15:48 2019
From: jk|ng@ton @end|ng |rom ||ngu|@t@um@@@@edu (John Kingston)
Date: Sun, 10 Nov 2019 13:15:48 -0500
Subject: [R-sig-ME] a question about partitioning effects
Message-ID: <fca30459879acee26dc6b904983d1c70@umail.it.umass.edu>

I have a data set in which a group of listeners were asked to categorize 
a series of sounds that stepped incrementally from an [s] to a [sh], as 
in "see" and "she". Members of this series were followed by one of three 
vowels, each one spoken by one of four speakers. Call these the 
"stimulus" characteristics. Past work predicts how differences between 
the vowels and speakers' voices would influence listeners' choice of [s] 
or [sh] as the category to which a particular step in the series 
belongs, and those predictions are clearly confirmed by the results.

In addition to these stimulus characteristics and their predicted 
effects, I also have "listener" characteristics, namely, their gender -- 
there are 23 women and 24 men -- and their scores on Simon Baron-Cohen's 
Autism Spectrum Questionnaire -- it provides a total AQ score and scores 
on five subsets of questions for each listener.

The interest in this study is how a listener's gender and their total AQ 
or subset scores influence the effects of stimulus characteristics on 
their categorization performance. In a mixed effects logistic regression 
model like this, I would ordinarily represent differences between 
listeners as a random effect, but here I also want to include the gender 
and total and subset AQ scores as fixed effects, in interactions with 
the fixed effects that represent the stimulus characteristics.

I should add that I have an analogous data set collected from a 
different group of listeners, evenly divided between women and men, in 
which the stimulus characteristics are the same but the other listener 
characteristics are scores from the five subsets of the Big Five 
personality questionnaire. As the subsets measure what are supposed to 
be independent personality traits, there is no total Big Five score. So 
my question is more general; namely, how do I model the effects of these 
measures of listeners' personality traits while also capturing 
uncontrolled differences between listeners?

-- 
John Kingston
Professor
Linguistics Department
University of Massachusetts
Integrative Learning Center N434
650 N. Pleasant St.
Amherst, MA 01003
1-413-545-6833, fax -2792
jkingston at linguist.umass.edu
http://blogs.umass.edu/jkingstn/


From m@|| @end|ng |rom johnh@m@n@org  Mon Nov 11 00:00:59 2019
From: m@|| @end|ng |rom johnh@m@n@org (John Haman)
Date: Sun, 10 Nov 2019 18:00:59 -0500
Subject: [R-sig-ME] a question about partitioning effects
In-Reply-To: <fca30459879acee26dc6b904983d1c70@umail.it.umass.edu>
References: <fca30459879acee26dc6b904983d1c70@umail.it.umass.edu>
Message-ID: <0c253e50-af59-369a-d4fd-0442bd3528b0@johnhaman.org>

I'm curious about the basis for the logistic regression model here. A 
correct response seems to imply that there is a true categorization (or 
coarsening) of sounds on the gradient from [s] to [sh]. Is there? Or is 
the correct classification in the eye of the researcher?

To try to answer your actual question, have you thought about modeling 
the data as

glmer(category ~ AQ*gender*stimulus_char + (1 | listener))

or some variation thereof? This would treat AQ, gender, and stimulus as 
fixed effects and supply a random intercept for each listener.

-John

On 11/10/19 1:15 PM, John Kingston wrote:
> I have a data set in which a group of listeners were asked to 
> categorize a series of sounds that stepped incrementally from an [s] 
> to a [sh], as in "see" and "she". Members of this series were followed 
> by one of three vowels, each one spoken by one of four speakers. Call 
> these the "stimulus" characteristics. Past work predicts how 
> differences between the vowels and speakers' voices would influence 
> listeners' choice of [s] or [sh] as the category to which a particular 
> step in the series belongs, and those predictions are clearly 
> confirmed by the results.
>
> In addition to these stimulus characteristics and their predicted 
> effects, I also have "listener" characteristics, namely, their gender 
> -- there are 23 women and 24 men -- and their scores on Simon 
> Baron-Cohen's Autism Spectrum Questionnaire -- it provides a total AQ 
> score and scores on five subsets of questions for each listener.
>
> The interest in this study is how a listener's gender and their total 
> AQ or subset scores influence the effects of stimulus characteristics 
> on their categorization performance. In a mixed effects logistic 
> regression model like this, I would ordinarily represent differences 
> between listeners as a random effect, but here I also want to include 
> the gender and total and subset AQ scores as fixed effects, in 
> interactions with the fixed effects that represent the stimulus 
> characteristics.
>
> I should add that I have an analogous data set collected from a 
> different group of listeners, evenly divided between women and men, in 
> which the stimulus characteristics are the same but the other listener 
> characteristics are scores from the five subsets of the Big Five 
> personality questionnaire. As the subsets measure what are supposed to 
> be independent personality traits, there is no total Big Five score. 
> So my question is more general; namely, how do I model the effects of 
> these measures of listeners' personality traits while also capturing 
> uncontrolled differences between listeners?
>


From jk|ng@ton @end|ng |rom ||ngu|@t@um@@@@edu  Mon Nov 11 18:28:08 2019
From: jk|ng@ton @end|ng |rom ||ngu|@t@um@@@@edu (John Kingston)
Date: Mon, 11 Nov 2019 12:28:08 -0500
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 155, Issue 8
In-Reply-To: <mailman.17945.9.1573470001.10306.r-sig-mixed-models@r-project.org>
References: <mailman.17945.9.1573470001.10306.r-sig-mixed-models@r-project.org>
Message-ID: <2fb941a257d98e442bee78bcbc7c01e7@umail.it.umass.edu>

Responding to John Haman:

Thank you for your comments.

I've modeled these results using a logistic regression because the 
sounds at the two ends of the series are an unambiguous [s] and an 
unambiguous [sh], respectively. In English, the native language of all 
the listeners, these two sounds can be analyzed as contrasting in their 
value for just one distinctive feature, [s] is [+anterior] and [sh] is 
[-anterior]. This feature refers to the position of the tongue tip and 
blade. The intermediate steps between the endpoints were made by mixing 
the original [s] and [sh] waveforms in complementary proportions. So 
with respect to both linguistic and physical characteristics of these 
sounds, it's possible to treat responses as binomially distributed.

I have tried a model like the one suggested. My question is whether it's 
possible to interpret the interactions between listener gender and AQ 
scores with stimulus characteristics when other uncontrolled listener 
characteristics are accounted for in the random effect. A model like the 
one proposed, in which there's a random effect of listener on the 
intercept, doesn't strike me as hard to interpret, but what if I wanted 
to examine random effects of listener on the slopes of the fixed effects 
and their interactions? For example, is it still possible to treat a 
random effect of listeners on the interactions of listener gender by a 
stimulus characteristic as accounting for uncontrolled idiosyncrasies of 
those listeners on that interaction?

Best,
John

On 2019-11-11 06:00, r-sig-mixed-models-request at r-project.org wrote:
> Send R-sig-mixed-models mailing list submissions to
> 	r-sig-mixed-models at r-project.org
> 
> To subscribe or unsubscribe via the World Wide Web, visit
> 	https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> or, via email, send a message with subject or body 'help' to
> 	r-sig-mixed-models-request at r-project.org
> 
> You can reach the person managing the list at
> 	r-sig-mixed-models-owner at r-project.org
> 
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-sig-mixed-models digest..."
> 
> 
> Today's Topics:
> 
>    1. a question about partitioning effects (John Kingston)
>    2. Re: a question about partitioning effects (John Haman)
> 
> ----------------------------------------------------------------------
> 
> Message: 1
> Date: Sun, 10 Nov 2019 13:15:48 -0500
> From: John Kingston <jkingston at linguist.umass.edu>
> To: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] a question about partitioning effects
> Message-ID: <fca30459879acee26dc6b904983d1c70 at umail.it.umass.edu>
> Content-Type: text/plain; charset="us-ascii"; Format="flowed"
> 
> I have a data set in which a group of listeners were asked to 
> categorize
> a series of sounds that stepped incrementally from an [s] to a [sh], as
> in "see" and "she". Members of this series were followed by one of 
> three
> vowels, each one spoken by one of four speakers. Call these the
> "stimulus" characteristics. Past work predicts how differences between
> the vowels and speakers' voices would influence listeners' choice of 
> [s]
> or [sh] as the category to which a particular step in the series
> belongs, and those predictions are clearly confirmed by the results.
> 
> In addition to these stimulus characteristics and their predicted
> effects, I also have "listener" characteristics, namely, their gender 
> --
> there are 23 women and 24 men -- and their scores on Simon 
> Baron-Cohen's
> Autism Spectrum Questionnaire -- it provides a total AQ score and 
> scores
> on five subsets of questions for each listener.
> 
> The interest in this study is how a listener's gender and their total 
> AQ
> or subset scores influence the effects of stimulus characteristics on
> their categorization performance. In a mixed effects logistic 
> regression
> model like this, I would ordinarily represent differences between
> listeners as a random effect, but here I also want to include the 
> gender
> and total and subset AQ scores as fixed effects, in interactions with
> the fixed effects that represent the stimulus characteristics.
> 
> I should add that I have an analogous data set collected from a
> different group of listeners, evenly divided between women and men, in
> which the stimulus characteristics are the same but the other listener
> characteristics are scores from the five subsets of the Big Five
> personality questionnaire. As the subsets measure what are supposed to
> be independent personality traits, there is no total Big Five score. So
> my question is more general; namely, how do I model the effects of 
> these
> measures of listeners' personality traits while also capturing
> uncontrolled differences between listeners?
> 
> --
> John Kingston
> Professor
> Linguistics Department
> University of Massachusetts
> Integrative Learning Center N434
> 650 N. Pleasant St.
> Amherst, MA 01003
> 1-413-545-6833, fax -2792
> jkingston at linguist.umass.edu
> http://blogs.umass.edu/jkingstn/
> 
> 
> 
> 
> ------------------------------
> 
> Message: 2
> Date: Sun, 10 Nov 2019 18:00:59 -0500
> From: John Haman <mail at johnhaman.org>
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] a question about partitioning effects
> Message-ID: <0c253e50-af59-369a-d4fd-0442bd3528b0 at johnhaman.org>
> Content-Type: text/plain; charset="utf-8"; Format="flowed"
> 
> I'm curious about the basis for the logistic regression model here. A
> correct response seems to imply that there is a true categorization (or
> coarsening) of sounds on the gradient from [s] to [sh]. Is there? Or is
> the correct classification in the eye of the researcher?
> 
> To try to answer your actual question, have you thought about modeling
> the data as
> 
> glmer(category ~ AQ*gender*stimulus_char + (1 | listener))
> 
> or some variation thereof? This would treat AQ, gender, and stimulus as
> fixed effects and supply a random intercept for each listener.
> 
> -John
> 
> On 11/10/19 1:15 PM, John Kingston wrote:
>> I have a data set in which a group of listeners were asked to
>> categorize a series of sounds that stepped incrementally from an [s]
>> to a [sh], as in "see" and "she". Members of this series were followed
>> by one of three vowels, each one spoken by one of four speakers. Call
>> these the "stimulus" characteristics. Past work predicts how
>> differences between the vowels and speakers' voices would influence
>> listeners' choice of [s] or [sh] as the category to which a particular
>> step in the series belongs, and those predictions are clearly
>> confirmed by the results.
>> 
>> In addition to these stimulus characteristics and their predicted
>> effects, I also have "listener" characteristics, namely, their gender
>> -- there are 23 women and 24 men -- and their scores on Simon
>> Baron-Cohen's Autism Spectrum Questionnaire -- it provides a total AQ
>> score and scores on five subsets of questions for each listener.
>> 
>> The interest in this study is how a listener's gender and their total
>> AQ or subset scores influence the effects of stimulus characteristics
>> on their categorization performance. In a mixed effects logistic
>> regression model like this, I would ordinarily represent differences
>> between listeners as a random effect, but here I also want to include
>> the gender and total and subset AQ scores as fixed effects, in
>> interactions with the fixed effects that represent the stimulus
>> characteristics.
>> 
>> I should add that I have an analogous data set collected from a
>> different group of listeners, evenly divided between women and men, in
>> which the stimulus characteristics are the same but the other listener
>> characteristics are scores from the five subsets of the Big Five
>> personality questionnaire. As the subsets measure what are supposed to
>> be independent personality traits, there is no total Big Five score.
>> So my question is more general; namely, how do I model the effects of
>> these measures of listeners' personality traits while also capturing
>> uncontrolled differences between listeners?
>> 
> 
> 
> 
> 
> ------------------------------
> 
> Subject: Digest Footer
> 
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> ------------------------------
> 
> End of R-sig-mixed-models Digest, Vol 155, Issue 8
> **************************************************

-- 
John Kingston
Professor
Linguistics Department
University of Massachusetts
Integrative Learning Center N434
650 N. Pleasant St.
Amherst, MA 01003
1-413-545-6833, fax -2792
jkingston at linguist.umass.edu
http://blogs.umass.edu/jkingstn/


From c@c@voeten @end|ng |rom hum@|e|denun|v@n|  Mon Nov 11 20:47:34 2019
From: c@c@voeten @end|ng |rom hum@|e|denun|v@n| (Voeten, C.C.)
Date: Mon, 11 Nov 2019 19:47:34 +0000
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 155, Issue 8
In-Reply-To: <2fb941a257d98e442bee78bcbc7c01e7@umail.it.umass.edu>
References: <mailman.17945.9.1573470001.10306.r-sig-mixed-models@r-project.org>
 <2fb941a257d98e442bee78bcbc7c01e7@umail.it.umass.edu>
Message-ID: <D14049CE02C4F54D95360EEC06CE45C50FB3333C@SPMXM08.VUW.leidenuniv.nl>

Dear John,

Random slopes by listener for gender and AQ score are unnecessary/don't make sense, as these reflect listener-specific characteristics and hence are already taken into account by the random intercept. However, you may want to consider a random slope (stimulus_char|listener) as well -- that would give you the 'maximal model' sensu Barr et al 2013. I recommend using a likelihood-ratio test (with its p-value divided by 2, see Pinheiro & Bates 2000) to see if the random-slope model is a significant improvement over the random-intercept model.

By the way, for a model with only one random factor like yours, function mixed_model from package GLMMadaptive will give slightly more accurate results than glmer.

Greetings from a fellow phonologist/phonetician,
Cesko

> -----Oorspronkelijk bericht-----
> Van: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org>
> Namens John Kingston
> Verzonden: maandag 11 november 2019 18:28
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: Re: [R-sig-ME] R-sig-mixed-models Digest, Vol 155, Issue 8
> 
> Responding to John Haman:
> 
> Thank you for your comments.
> 
> I've modeled these results using a logistic regression because the sounds at
> the two ends of the series are an unambiguous [s] and an unambiguous [sh],
> respectively. In English, the native language of all the listeners, these two
> sounds can be analyzed as contrasting in their value for just one distinctive
> feature, [s] is [+anterior] and [sh] is [-anterior]. This feature refers to the
> position of the tongue tip and blade. The intermediate steps between the
> endpoints were made by mixing the original [s] and [sh] waveforms in
> complementary proportions. So with respect to both linguistic and physical
> characteristics of these sounds, it's possible to treat responses as binomially
> distributed.
> 
> I have tried a model like the one suggested. My question is whether it's
> possible to interpret the interactions between listener gender and AQ scores
> with stimulus characteristics when other uncontrolled listener characteristics
> are accounted for in the random effect. A model like the one proposed, in
> which there's a random effect of listener on the intercept, doesn't strike me
> as hard to interpret, but what if I wanted to examine random effects of
> listener on the slopes of the fixed effects and their interactions? For
> example, is it still possible to treat a random effect of listeners on the
> interactions of listener gender by a stimulus characteristic as accounting for
> uncontrolled idiosyncrasies of those listeners on that interaction?
> 
> Best,
> John
> 
> On 2019-11-11 06:00, r-sig-mixed-models-request at r-project.org wrote:
> > Send R-sig-mixed-models mailing list submissions to
> > 	r-sig-mixed-models at r-project.org
> >
> > To subscribe or unsubscribe via the World Wide Web, visit
> > 	https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > or, via email, send a message with subject or body 'help' to
> > 	r-sig-mixed-models-request at r-project.org
> >
> > You can reach the person managing the list at
> > 	r-sig-mixed-models-owner at r-project.org
> >
> > When replying, please edit your Subject line so it is more specific
> > than "Re: Contents of R-sig-mixed-models digest..."
> >
> >
> > Today's Topics:
> >
> >    1. a question about partitioning effects (John Kingston)
> >    2. Re: a question about partitioning effects (John Haman)
> >
> > ----------------------------------------------------------------------
> >
> > Message: 1
> > Date: Sun, 10 Nov 2019 13:15:48 -0500
> > From: John Kingston <jkingston at linguist.umass.edu>
> > To: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
> > Subject: [R-sig-ME] a question about partitioning effects
> > Message-ID: <fca30459879acee26dc6b904983d1c70 at umail.it.umass.edu>
> > Content-Type: text/plain; charset="us-ascii"; Format="flowed"
> >
> > I have a data set in which a group of listeners were asked to
> > categorize a series of sounds that stepped incrementally from an [s]
> > to a [sh], as in "see" and "she". Members of this series were followed
> > by one of three vowels, each one spoken by one of four speakers. Call
> > these the "stimulus" characteristics. Past work predicts how
> > differences between the vowels and speakers' voices would influence
> > listeners' choice of [s] or [sh] as the category to which a particular
> > step in the series belongs, and those predictions are clearly
> > confirmed by the results.
> >
> > In addition to these stimulus characteristics and their predicted
> > effects, I also have "listener" characteristics, namely, their gender
> > --
> > there are 23 women and 24 men -- and their scores on Simon
> > Baron-Cohen's Autism Spectrum Questionnaire -- it provides a total AQ
> > score and scores on five subsets of questions for each listener.
> >
> > The interest in this study is how a listener's gender and their total
> > AQ or subset scores influence the effects of stimulus characteristics
> > on their categorization performance. In a mixed effects logistic
> > regression model like this, I would ordinarily represent differences
> > between listeners as a random effect, but here I also want to include
> > the gender and total and subset AQ scores as fixed effects, in
> > interactions with the fixed effects that represent the stimulus
> > characteristics.
> >
> > I should add that I have an analogous data set collected from a
> > different group of listeners, evenly divided between women and men, in
> > which the stimulus characteristics are the same but the other listener
> > characteristics are scores from the five subsets of the Big Five
> > personality questionnaire. As the subsets measure what are supposed to
> > be independent personality traits, there is no total Big Five score.
> > So my question is more general; namely, how do I model the effects of
> > these measures of listeners' personality traits while also capturing
> > uncontrolled differences between listeners?
> >
> > --
> > John Kingston
> > Professor
> > Linguistics Department
> > University of Massachusetts
> > Integrative Learning Center N434
> > 650 N. Pleasant St.
> > Amherst, MA 01003
> > 1-413-545-6833, fax -2792
> > jkingston at linguist.umass.edu
> > http://blogs.umass.edu/jkingstn/
> >
> >
> >
> >
> > ------------------------------
> >
> > Message: 2
> > Date: Sun, 10 Nov 2019 18:00:59 -0500
> > From: John Haman <mail at johnhaman.org>
> > To: r-sig-mixed-models at r-project.org
> > Subject: Re: [R-sig-ME] a question about partitioning effects
> > Message-ID: <0c253e50-af59-369a-d4fd-0442bd3528b0 at johnhaman.org>
> > Content-Type: text/plain; charset="utf-8"; Format="flowed"
> >
> > I'm curious about the basis for the logistic regression model here. A
> > correct response seems to imply that there is a true categorization
> > (or
> > coarsening) of sounds on the gradient from [s] to [sh]. Is there? Or
> > is the correct classification in the eye of the researcher?
> >
> > To try to answer your actual question, have you thought about modeling
> > the data as
> >
> > glmer(category ~ AQ*gender*stimulus_char + (1 | listener))
> >
> > or some variation thereof? This would treat AQ, gender, and stimulus
> > as fixed effects and supply a random intercept for each listener.
> >
> > -John
> >
> > On 11/10/19 1:15 PM, John Kingston wrote:
> >> I have a data set in which a group of listeners were asked to
> >> categorize a series of sounds that stepped incrementally from an [s]
> >> to a [sh], as in "see" and "she". Members of this series were
> >> followed by one of three vowels, each one spoken by one of four
> >> speakers. Call these the "stimulus" characteristics. Past work
> >> predicts how differences between the vowels and speakers' voices
> >> would influence listeners' choice of [s] or [sh] as the category to
> >> which a particular step in the series belongs, and those predictions
> >> are clearly confirmed by the results.
> >>
> >> In addition to these stimulus characteristics and their predicted
> >> effects, I also have "listener" characteristics, namely, their gender
> >> -- there are 23 women and 24 men -- and their scores on Simon
> >> Baron-Cohen's Autism Spectrum Questionnaire -- it provides a total AQ
> >> score and scores on five subsets of questions for each listener.
> >>
> >> The interest in this study is how a listener's gender and their total
> >> AQ or subset scores influence the effects of stimulus characteristics
> >> on their categorization performance. In a mixed effects logistic
> >> regression model like this, I would ordinarily represent differences
> >> between listeners as a random effect, but here I also want to include
> >> the gender and total and subset AQ scores as fixed effects, in
> >> interactions with the fixed effects that represent the stimulus
> >> characteristics.
> >>
> >> I should add that I have an analogous data set collected from a
> >> different group of listeners, evenly divided between women and men,
> >> in which the stimulus characteristics are the same but the other
> >> listener characteristics are scores from the five subsets of the Big
> >> Five personality questionnaire. As the subsets measure what are
> >> supposed to be independent personality traits, there is no total Big Five
> score.
> >> So my question is more general; namely, how do I model the effects of
> >> these measures of listeners' personality traits while also capturing
> >> uncontrolled differences between listeners?
> >>
> >
> >
> >
> >
> > ------------------------------
> >
> > Subject: Digest Footer
> >
> > _______________________________________________
> > R-sig-mixed-models mailing list
> > R-sig-mixed-models at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
> > ------------------------------
> >
> > End of R-sig-mixed-models Digest, Vol 155, Issue 8
> > **************************************************
> 
> --
> John Kingston
> Professor
> Linguistics Department
> University of Massachusetts
> Integrative Learning Center N434
> 650 N. Pleasant St.
> Amherst, MA 01003
> 1-413-545-6833, fax -2792
> jkingston at linguist.umass.edu
> http://blogs.umass.edu/jkingstn/
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From 113499328 @end|ng |rom um@||@ucc@|e  Wed Nov 13 19:25:30 2019
From: 113499328 @end|ng |rom um@||@ucc@|e (Ronan James Osullivan)
Date: Wed, 13 Nov 2019 18:25:30 +0000
Subject: [R-sig-ME] Massive difference in random effect's posterior mean
 between chains
Message-ID: <CAO1C-jO0RF44b_RHLFe2i_zEJ8c=kG_hbebLaQ_sBvDXpBaycg@mail.gmail.com>

Hi all,

Apologies if this question is trivial or if I'm over-looking something
obvious.

I am trying to investigate the effect of Genetic Type (A or B) and climate
on the lifetime reproductive success (LRS) of a wild-spawning fish species.
I am interacting Genetic Type with seven different climatic variables. I
have included a nested random effects structure to account for
pseudoreplication among years (~Year_of_Spawning), and to account for some
of the fish spawning across multiple years (~Year_ID2). I also interact
Genetic_Type with the relative survival of B compared to A to correct for a
survival bias between the two genetic types (they are sampled at different
points in the spawning season).

The model is specified in MCMCglmm as follows:
Model_a<- MCMCglmm(LRS ~
                   (Genetic_Type-1)*climate1+
                   (Genetic_Type -1)* climate2+
                   (Genetic_Type -1)* climate3+
                   (Genetic_Type -1)* climate4+
                   (Genetic_Type -1)* climate5+
                   (Genetic_Type -1)* climate6+
                   (Genetic_Type -1)* climate7+
                    Genetic_Type *relative_survival,
                 random = ~Year_of_Spawning+ Year_ID2,
                 family = "poisson",
                 data = data1,
                 prior = prior.exp_1,
                 nitt = 110000,
                 burnin = 10000,
                 thin = 100)

The above model was run to illustrate the problem, hence the low number of
iterations.

The parameter expanded prior is as follows:
prior.exp_1<- list(R = list(V = 1, nu = 2),
G = list(G1 = list(V = 1, nu = 0.002, alpha.mu = 0, alpha.V = 1000),
             G2 = list(V = 1, nu = 0.002, alpha.mu = 0, alpha.V = 1000)))

If I run 2 chains of the model, then the results for the fixed effects are
similar, allowing for Monte Carlo error. However, the posterior mean
estimate for the 'Year_of_Spawning' random effect changes massively, with
the posterior mean larger than the upper 95% credible interval:

MODEL 1:
 G-structure:  ~Year_of_Spawning

                                post.mean          l-95% CI     u-95% CI
 eff.samp
Year_of_Spawning      5.49              7.832e-05      15.85         1000

               ~Year_ID2

                               post.mean          l-95% CI       u-95% CI
 eff.samp
Year_ID2                  0.5262              0.000721         0.9471
87.03

 R-structure:  ~units

                             post.mean            l-95% CI       u-95% CI
 eff.samp
units                        0.5792               0.1383            1.082
      87.61

MODEL 2:
G-structure:  ~Year_of_Spawning

                               post.mean         l-95% CI         u-95% CI
 eff.samp
Year_of_Spawning     39.38             9.65e-05            15.52     1000

               ~Year_ID2

                              post.mean         l-95% CI          u-95% CI
  eff.samp
Year_ID2                 0.4724             4.8e-06              0.9168
    81.07

 R-structure:  ~units

                             post.mean         l-95% CI          u-95% CI
  eff.samp
units                        0.6403             0.1838             1.126
      92.06


I imagine that the problem exists in my random effects structure but I am
unsure of where the error lies. Any and all help is massively appreciated.

Cheers,
Ronan


-- 
Ronan O'Sullivan | Ph.D student | School of Biological, Earth and
Environmental Sciences, University College Cork, Ireland |
http://fisheye.ucc.ie/toms-team/

EMPSEB 26 - Chair of Organizing Committee

Irish Ecological Association - Ordinary Committee Member

	[[alternative HTML version deleted]]


From cr|@@|e@@@ndro @end|ng |rom gm@||@com  Wed Nov 13 22:01:44 2019
From: cr|@@|e@@@ndro @end|ng |rom gm@||@com (Cristiano Alessandro)
Date: Wed, 13 Nov 2019 15:01:44 -0600
Subject: [R-sig-ME] inconsistent results in two-way repeated measure
 analysis using mixed models
Message-ID: <CAHhX7Whdsd7A95LbMMVK6qm6+X+d2y12KN4iuaP3ozrQ9=syCw@mail.gmail.com>

Hi all,

I am having issues with the definition of a mixed effect model for a
two-way repeated measure analysis with nested design. The issue is
described in great details at this link:
https://stats.stackexchange.com/questions/435630/inconsistent-results-in-two-way-repeated-measure-analysis-using-mixed-models

Does anybody have any clue of what the problem may be? Thanks in advance.

-- 
*Cristiano Alessandro, PhD*
Postdoctoral Fellow
Physiology Department
Northwestern University

	[[alternative HTML version deleted]]


From m|ch@e|@w||||@m@on @end|ng |rom kc|@@c@uk  Tue Nov 19 11:52:38 2019
From: m|ch@e|@w||||@m@on @end|ng |rom kc|@@c@uk (Williamson, Michael)
Date: Tue, 19 Nov 2019 10:52:38 +0000
Subject: [R-sig-ME] Cook's distance for glmmTMB models
Message-ID: <DB7PR03MB45555EF1E0DB42C7AD7EFF04C24C0@DB7PR03MB4555.eurprd03.prod.outlook.com>

Good Morning,

I've been running a generalise linear mixed model using the glmmTMB package. My data is very large and zero inflated and this packaged worked really well following convergent issues using the traditional lme4 package.

I've been recommended to check for the effect of outliers using Cook's distance, but none of the packages I can find (performance and influence.ME) work with glmmTMB models currently. Is anyone aware of any other methods I might be able to use to check for Cook's distance with glmmTMB objects?

Cheers

Mike



Michael Williamson
London NERC DTP Candidate

Email: michael.williamson at kcl.ac.uk<mailto:michael.williamson at kcl.ac.uk> Phone: +447764836592 Skype: mikejwilliamson Twitter: @mjw_marine

Most recent paper:
Williamson, M. J., Tebbs, E., Dawson, T., Jacoby D. (2019) 'Satellite Remote Sensing in Shark and Ray Ecology, Conservation and Management', Frontiers in Marine Science, 6, 1-23. https://doi.org/10.3389/fmars.2019.00135<https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fdoi.org%2F10.3389%2Ffmars.2019.00135&data=01%7C01%7Cmichael.williamson%40kcl.ac.uk%7Cebe89eb38f9f4638c3af08d6b381355f%7C8370cf1416f34c16b83c724071654356%7C0&sdata=RSgPw0Ar9R1JvA0YDYfJhDOdwUYfy7sh2vZs2t5tO94%3D&reserved=0>



	[[alternative HTML version deleted]]


From wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n|  Wed Nov 20 17:38:26 2019
From: wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n| (Viechtbauer, Wolfgang (SP))
Date: Wed, 20 Nov 2019 16:38:26 +0000
Subject: [R-sig-ME] Cook's distance for glmmTMB models
In-Reply-To: <DB7PR03MB45555EF1E0DB42C7AD7EFF04C24C0@DB7PR03MB4555.eurprd03.prod.outlook.com>
References: <DB7PR03MB45555EF1E0DB42C7AD7EFF04C24C0@DB7PR03MB4555.eurprd03.prod.outlook.com>
Message-ID: <97615d64b6074d768058964146aaeae6@UM-MAIL3213.unimaas.nl>

Dear Mike,

I don't know about packages that will directly work with glmmTMB objects, but computing Cook's distances can be easily done by hand. Let b be the vector with the estimated fixed effects from the model and V(b) the corresponding var-cov matrix. You can extract these with fixef() and vcov() from your model. Now leave out either a single observation or a cluster of observations (e.g., all observations corresponding to an individual) and let b_{-i} denote the estimated fixed effects when fitting the data to this subset of the dataset. Then Cook's distances is simply

D_i = (b - b_{-i})' V(b)^{-1} (b - b_{-i})

Now rinse and repeat for every i, which is easily done in a loop. It might take a while to complete depending on how complex your model is.

Some might compute D_i with V(b_{-i})^{-1} in place of V(b)^{-1}. Can be done easily at the same time, so you could do both and compare.

Best,
Wolfgang

-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Williamson, Michael via R-sig-mixed-models
Sent: Tuesday, 19 November, 2019 11:53
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Cook's distance for glmmTMB models

Good Morning,

I've been running a generalise linear mixed model using the glmmTMB package. My data is very large and zero inflated and this packaged worked really well following convergent issues using the traditional lme4 package.

I've been recommended to check for the effect of outliers using Cook's distance, but none of the packages I can find (performance and influence.ME) work with glmmTMB models currently. Is anyone aware of any other methods I might be able to use to check for Cook's distance with glmmTMB objects?

Cheers

Mike


From ntuzov @end|ng |rom ntuzov@com  Fri Nov 22 23:45:44 2019
From: ntuzov @end|ng |rom ntuzov@com (Nik Tuzov)
Date: Fri, 22 Nov 2019 22:45:44 +0000 (UTC)
Subject: [R-sig-ME] Finding the best package for a mixed Poisson model
References: <914700208.2770145.1574462744024.ref@mail.yahoo.com>
Message-ID: <914700208.2770145.1574462744024@mail.yahoo.com>

 
Hello:

Couldyou help me get oriented among various packages to fit a mixedPoisson model. The goal is to find a relatively fast method that cantake at least two random factors, possibly with interaction, e.g.:

Y~ fixed part + A + B + A*B

Ihave looked at SAS GLIMMIX, lme4::glmer, glmmPQL, glmmTMB, andGLMMadaptive. I have stayed away from simulation/MCMC based methodsfor speed reasons. My questions are:

1)Are there any more packages that are consistent with my objective?

2)GLIMMIX (with default METHOD = RSPL option) and glmmPQL refer to thesame two papers: Wofinger, O?Connell, 1993 and Breslow, Clayton,1993. Does this mean that glmmPQL was meant to reproduce the defaultGLIMMIX? If yes, are they really consistent?

3)This reference:

https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#fitting-models-with-overdispersion

claimsthat previously lme4 had a functionality similar to glmmPQL but thenit was removed altogether because it was ?deemed unreliable?.That implies that the default estimation method in GLIMMIX is veryunreliable (see 2)). Is it really that bad? If yes, why didn?t SASpick a different default (or maybe they did it in some newer PROC)?

4)Presently glmer uses Laplace or Gauss-Hermite quadrature, the latteronly if there is one random term in the model. How consistent is itwith the corresponding SAS options METHOD = LAPLACE and METHOD=QUAD ?

5)GLMMadaptive can use the quadrature with more than one random term:

https://stats.stackexchange.com/questions/403147/an-r-package-for-glmm-estimation-with-two-random-effects

Thedocumentation says that it?s based on the paper of Pinheiro &Bates, 1995, then why is it not available in glmer which is supportedby Bates? Is that because the GLMMadaptive results are unreliable?




Thanksin advance,

NikTuzov


	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Sat Nov 23 01:34:21 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 22 Nov 2019 19:34:21 -0500
Subject: [R-sig-ME] Finding the best package for a mixed Poisson model
In-Reply-To: <914700208.2770145.1574462744024@mail.yahoo.com>
References: <914700208.2770145.1574462744024.ref@mail.yahoo.com>
 <914700208.2770145.1574462744024@mail.yahoo.com>
Message-ID: <CABghstRVVihVki1Kw305e9LK1z6Jf_fJDyqPszBdf=G2+rMbxw@mail.gmail.com>

On Fri, Nov 22, 2019 at 5:46 PM Nik Tuzov <ntuzov at ntuzov.com> wrote:
>
>
> Hello:
>
> Couldyou help me get oriented among various packages to fit a mixedPoisson model. The goal is to find a relatively fast method that cantake at least two random factors, possibly with interaction, e.g.:
>
> Y~ fixed part + A + B + A*B
>
> Ihave looked at SAS GLIMMIX, lme4::glmer, glmmPQL, glmmTMB, andGLMMadaptive. I have stayed away from simulation/MCMC based methodsfor speed reasons. My questions are:
>
> 1)Are there any more packages that are consistent with my objective?

 technically glmmPQL is a function within the MASS package.
  If you're going to use SAS I might recommend PROC MIXED over GLIMMIX
(see below).

>
> 2)GLIMMIX (with default METHOD = RSPL option) and glmmPQL refer to thesame two papers: Wofinger, O?Connell, 1993 and Breslow, Clayton,1993. Does this mean that glmmPQL was meant to reproduce the defaultGLIMMIX? If yes, are they really consistent?

  I don't know if they're exactly the same, but they're implementing
similar methods (I don't know all the options within GLIMMIX ...)

>
> 3)This reference:
>
> https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#fitting-models-with-overdispersion
>
> claimsthat previously lme4 had a functionality similar to glmmPQL but thenit was removed altogether because it was ?deemed unreliable?.That implies that the default estimation method in GLIMMIX is veryunreliable (see 2)). Is it really that bad? If yes, why didn?t SASpick a different default (or maybe they did it in some newer PROC)?

  This is a bit of a long story.
  (1) PQL is indeed a worse approximation in some limits (e.g. Poisson
samples with a small mean *and* small number of samples per group)
[e.g. see the Breslow "Whither PQL?" paper].
  (2) The developers noticed some weird results from PQL when
implemented in lme4, but these probably had less to do with PQL itself
than with the ways in which it interacted with the way that GLMMs are
otherwise implemented in lme4.  Because of #1, it was deemed less
important.

>
> 4)Presently glmer uses Laplace or Gauss-Hermite quadrature, the latteronly if there is one random term in the model. How consistent is itwith the corresponding SAS options METHOD = LAPLACE and METHOD=QUAD ?

   I didn't realize that GLIMMIX  had LAPLACE and QUAD methods, but
yes, those sound similar to nAGQ=1 (default) and nAGQ>1 options in
lme4.  (I don't know whether GLIMMIX does *adaptive* Gauss-Hermite
quadrature, which is important ...)
>
> 5)GLMMadaptive can use the quadrature with more than one random term:
>
> https://stats.stackexchange.com/questions/403147/an-r-package-for-glmm-estimation-with-two-random-effects
>
> Thedocumentation says that it?s based on the paper of Pinheiro &Bates, 1995, then why is it not available in glmer which is supportedby Bates? Is that because the GLMMadaptive results are unreliable?

   Because the glmer developers never got around to implementing it.
While being able to do AGQ on arbitrarily many random effects is
certainly convenient, there's a relatively narrow set of problems for
which AGQ on multiple REs is both useful (i.e. Laplace isn't good
enough) *and* computationally feasible (the computational burden of
AGQ increases rapidly with dimensionality/number of rEs).

  My advice: try a few of these methods and see if the answers differ
much, then choose the most convenient tool that seems adequate.  Most
of the R packages have fairly similar interfaces, so it shouldn't be
too hard to try a variety of them.

> Thanksin advance,
>
> NikTuzov
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From o||verhooker @end|ng |rom pr@t@t|@t|c@@com  Sat Dec  7 17:21:07 2019
From: o||verhooker @end|ng |rom pr@t@t|@t|c@@com (Oliver Hooker)
Date: Sat, 7 Dec 2019 16:21:07 +0000
Subject: [R-sig-ME] COURSE - R 4 ALL (Andrew Beckerman & Dylan Childs)
 (R4LL01) FREE ACCOMMODATION AVAILABLE
Message-ID: <CAEsSYzyYAzjn-vO_fqX+veOhay9-jMOwktD5H6gUPba05KyCyA@mail.gmail.com>

R 4 ALL (Andrew Beckerman & Dylan Childs) (R4LL01) FREE ACCOMMODATION AVAILABLE

https://www.prstatistics.com/course/r-4-all-andrew-beckerman-dylan-childs-r4ll01/

This course will be delivered by Dr Andrew Beckerman and Dr Dylan
Childs, authors of the best selling book ?Getting Started with R, An
Introduction for Biologists? from the 20th-24th January in Glasgow
City Centre.

FREE ACCOMMODATION is available for people working in academia and for
non-profit organisations.

PR Statistics has partnered with R4ALL (www.r4all.org) to offer an
introductory course to R, RStudio and statistics for Biologists. Based
on their best-selling book, ?Getting Started with R, An Introduction
for Biologists?, this course provides training in the R statistical
and programming language for data management, visualisation, and
analysis. The R4All team, with more than 20 years experience
delivering this course, will boost you up the initial learning curve,
streamline your data management and analysis workflows, and give you
scalable solutions. You will develop and take away robust and
repeatable workflows for visualisation and statistical analyses,
ranging from t-tests and ANOVA to generalised linear models and mixed
effects models.

For more details or to request an invoice please email
oliverhooker at prstatistics.com or use the link to book via our website.


-- 
Oliver Hooker PhD.
PR statistics

2019 publications;

A way forward with eco evo devo: an extended theory of resource
polymorphism with postglacial fishes as model systems. Biological
Reviews (2019).

prstatistics.com
facebook.com/prstatistics/
twitter.com/PRstatistics
groups.google.com/d/forum/pr-statistics-post-course-forum
prstatistics.com/organiser/oliver-hooker/

53 Morrison Street
Glasgow
G5 8LB
+44 (0) 7966500340


From q@@hoe@yb @end|ng |rom gm@||@com  Sat Dec  7 19:22:19 2019
From: q@@hoe@yb @end|ng |rom gm@||@com (Shoeayb Qasemi)
Date: Sat, 7 Dec 2019 21:52:19 +0330
Subject: [R-sig-ME] dummy variables in hlm
Message-ID: <CADRwXOJJyz76iTP_pY_ZLQDF4oZ+EXBYY_qMB31vVmA2=-UQ3g@mail.gmail.com>

 Dear Prof. Bob,

I have run an HLM model that contains an independent categorical variable
(5 categories) at level 2. Four dummy variables entered into the model to
represent the categorical variable. Since the dummy variables all test the
null hypothesis of the categorical variable, do I need to adjust P-values
to control the type-I error rate?

Best,
Shoeayb

	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sun Dec 15 02:20:25 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sun, 15 Dec 2019 14:20:25 +1300
Subject: [R-sig-ME] Is there a way to deal with errors such as this?
Message-ID: <5d8a95d7-1310-cec0-8397-054a470dc7e2@auckland.ac.nz>


By "this" I mean as demonstrated in the following code.  The file 
testData.txt is attached.

X <- dget("testData.txt")
library(lme4)
fit <- glmer(cbind(Dead,Alive) ~ (0+Trt)/Dose + (Dose | Rep),
              data=X,family=binomial(link="probit"))

The foregoing falls over with the (rather complex) error message:

> Error in pwrssUpdate(pp, resp, tol = tolPwrss, GQmat = GHrule(0L), compDev = compDev,  : 
>   (maxstephalfit) PIRLS step-halvings failed to reduce deviance in pwrssUpdate

I note that mixed_model() from GLMMadaptive seems to be able to deal 
with these data and this model:

library(GLMMadaptive)
fit <- mixed_model(fixed=cbind(Dead,Alive) ~ (0+Trt)/Dose,
                    random=~Dose | Rep,
                    data=X,family=binomial(link="probit"))

The foregoing runs without complaint.

I am applying the glmer() model in the context of doing some fairly 
elaborate simulations (in which "X" gets randomly generated) and the 
error causes the simulations to crash unpleasantly.  So I would *like* a 
magic incantation that I can apply in an automated way to prevent the
error from occurring.

I can of course wrap function calls up in try() and if there is an error
generate a new data set and go again.  However I'm a little apprehensive
that this might bias the results of the simulations in some way.

I could also switch to using mixed_model(), but would prefer to stick 
with the devil I know (i.e. glmer()) for the sake of consistency with 
other work that I have done.  (And who knows?  Maybe in the course of 
the simulations mixed_model() might fall over too, from time to time.)

I'd appreciate any avuncular (or materteral) advice that anyone might be 
inclined to offer.

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: testData.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20191215/13ee55d5/attachment.txt>

From b@ch|@w01 @end|ng |rom out|ook@com  Sun Dec 15 02:49:45 2019
From: b@ch|@w01 @end|ng |rom out|ook@com (Jonathan Judge)
Date: Sun, 15 Dec 2019 01:49:45 +0000
Subject: [R-sig-ME] Is there a way to deal with errors such as this?
In-Reply-To: <5d8a95d7-1310-cec0-8397-054a470dc7e2@auckland.ac.nz>
References: <5d8a95d7-1310-cec0-8397-054a470dc7e2@auckland.ac.nz>
Message-ID: <DM6PR06MB50516D82269405674B61ACA6AF560@DM6PR06MB5051.namprd06.prod.outlook.com>

Rolf:

Sadly, that error has always been the kiss of death for me no matter what I tried. As parameterized, the model probably just won?t optimize in lme4. If you want to stick with pseudo-frequentist inference, you could try glmmTMB, which is developed by some of the same folks (well, one in particular) and it may work using the same notation you are used to. But that error message usually means you need to try a different package. 

Jonathan 

Sent from my iPhone

> On Dec 14, 2019, at 7:21 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
> ?
> By "this" I mean as demonstrated in the following code.  The file testData.txt is attached.
> 
> X <- dget("testData.txt")
> library(lme4)
> fit <- glmer(cbind(Dead,Alive) ~ (0+Trt)/Dose + (Dose | Rep),
>             data=X,family=binomial(link="probit"))
> 
> The foregoing falls over with the (rather complex) error message:
> 
>> Error in pwrssUpdate(pp, resp, tol = tolPwrss, GQmat = GHrule(0L), compDev = compDev,  :   (maxstephalfit) PIRLS step-halvings failed to reduce deviance in pwrssUpdate
> 
> I note that mixed_model() from GLMMadaptive seems to be able to deal with these data and this model:
> 
> library(GLMMadaptive)
> fit <- mixed_model(fixed=cbind(Dead,Alive) ~ (0+Trt)/Dose,
>                   random=~Dose | Rep,
>                   data=X,family=binomial(link="probit"))
> 
> The foregoing runs without complaint.
> 
> I am applying the glmer() model in the context of doing some fairly elaborate simulations (in which "X" gets randomly generated) and the error causes the simulations to crash unpleasantly.  So I would *like* a magic incantation that I can apply in an automated way to prevent the
> error from occurring.
> 
> I can of course wrap function calls up in try() and if there is an error
> generate a new data set and go again.  However I'm a little apprehensive
> that this might bias the results of the simulations in some way.
> 
> I could also switch to using mixed_model(), but would prefer to stick with the devil I know (i.e. glmer()) for the sake of consistency with other work that I have done.  (And who knows?  Maybe in the course of the simulations mixed_model() might fall over too, from time to time.)
> 
> I'd appreciate any avuncular (or materteral) advice that anyone might be inclined to offer.
> 
> cheers,
> 
> Rolf
> 
> -- 
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> <testData.txt>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://eur04.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7C%7C014e497b7e884f35d78708d780fd0a94%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637119696600482811&amp;sdata=m%2Binqw1ft8rZ1w37Q7McwqOXJ4ws1%2BtcstsRZKts8Lc%3D&amp;reserved=0

From bbo|ker @end|ng |rom gm@||@com  Sun Dec 15 03:11:49 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sat, 14 Dec 2019 21:11:49 -0500
Subject: [R-sig-ME] Is there a way to deal with errors such as this?
In-Reply-To: <DM6PR06MB50516D82269405674B61ACA6AF560@DM6PR06MB5051.namprd06.prod.outlook.com>
References: <5d8a95d7-1310-cec0-8397-054a470dc7e2@auckland.ac.nz>
 <DM6PR06MB50516D82269405674B61ACA6AF560@DM6PR06MB5051.namprd06.prod.outlook.com>
Message-ID: <CABghstTZ6aCW3xCV0s0aV0v7mMR-cRyfd3WBs0O+aaVHg9NpMw@mail.gmail.com>

  I would sadly agree with this assessment as well.  It would be good
to collect a set of models that fail in this way and use them to
debug/figure out what the problem is: the PIRLS loop is implemented
entirely in C++, which makes it relatively painful to debug. (It might
also be possible to make some progress by using the "pureR"
implementation that Steve Walker wrote a few years ago ...)

 One little clue is that (as I vaguely remembered/suspected) is that
the proximal problem is that iterations that result in NaN are not
dealt with well. Next step: figuring out why the NaNs are generated in
the first place ...

*** pwrssUpdate step 1
pdev=182574; delu_min: -158.148; delu_max: 310.47; delb_min: -7.05005;
delb_max: 60.6557

pwrssUpdate: Entering step halving loop
step-halving iteration 0:  pdev=45331.6; delu_min: -79.2949; delu_max:
155.422; delb_min: -3.50962; delb_max: 30.2776
step-halving iteration 1:  pdev=11437.5; delu_min: -39.8683; delu_max:
77.8977; delb_min: -1.73941; delb_max: 15.0885
*** pwrssUpdate step 2
pdev=nan; delu_min: nan; delu_max: nan; delb_min: nan; delb_max: nan

pwrssUpdate: Entering step halving loop
step-halving iteration 0:  pdev=nan; delu_min: nan; delu_max: nan;
delb_min: nan; delb_max: nan
step-halving iteration 1:  pdev=nan; delu_min: nan; delu_max: nan;
delb_min: nan; delb_max: nan
step-halving iteration 2:  pdev=nan; delu_min: nan; delu_max: nan;
delb_min: nan; delb_max: nan
step-halving iteration 3:  pdev=nan; delu_min: nan; delu_max: nan;
delb_min: nan; delb_max: nan
step-halving iteration 4:  pdev=nan; delu_min: nan; delu_max: nan;
delb_min: nan; delb_max: nan
step-halving iteration 5:  pdev=nan; delu_min: nan; delu_max: nan;
delb_min: nan; delb_max: nan
step-halving iteration 6:  pdev=nan; delu_min: nan; delu_max: nan;
delb_min: nan; delb_max: nan
step-halving iteration 7:  pdev=nan; delu_min: nan; delu_max: nan;
delb_min: nan; delb_max: nan
step-halving iteration 8:  pdev=nan; delu_min: nan; delu_max: nan;
delb_min: nan; delb_max: nan
step-halving iteration 9:  pdev=nan; delu_min: nan; delu_max: nan;
delb_min: nan; delb_max: nan
Error in pwrssUpdate(pp, resp, tol = tolPwrss, GQmat = GHrule(0L),
compDev = compDev,  :
  (maxstephalfit) PIRLS step-halvings failed to reduce deviance in pwrssUpdate

On Sat, Dec 14, 2019 at 8:50 PM Jonathan Judge <bachlaw01 at outlook.com> wrote:
>
> Rolf:
>
> Sadly, that error has always been the kiss of death for me no matter what I tried. As parameterized, the model probably just won?t optimize in lme4. If you want to stick with pseudo-frequentist inference, you could try glmmTMB, which is developed by some of the same folks (well, one in particular) and it may work using the same notation you are used to. But that error message usually means you need to try a different package.
>
> Jonathan
>
> Sent from my iPhone
>
> > On Dec 14, 2019, at 7:21 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> >
> > ?
> > By "this" I mean as demonstrated in the following code.  The file testData.txt is attached.
> >
> > X <- dget("testData.txt")
> > library(lme4)
> > fit <- glmer(cbind(Dead,Alive) ~ (0+Trt)/Dose + (Dose | Rep),
> >             data=X,family=binomial(link="probit"))
> >
> > The foregoing falls over with the (rather complex) error message:
> >
> >> Error in pwrssUpdate(pp, resp, tol = tolPwrss, GQmat = GHrule(0L), compDev = compDev,  :   (maxstephalfit) PIRLS step-halvings failed to reduce deviance in pwrssUpdate
> >
> > I note that mixed_model() from GLMMadaptive seems to be able to deal with these data and this model:
> >
> > library(GLMMadaptive)
> > fit <- mixed_model(fixed=cbind(Dead,Alive) ~ (0+Trt)/Dose,
> >                   random=~Dose | Rep,
> >                   data=X,family=binomial(link="probit"))
> >
> > The foregoing runs without complaint.
> >
> > I am applying the glmer() model in the context of doing some fairly elaborate simulations (in which "X" gets randomly generated) and the error causes the simulations to crash unpleasantly.  So I would *like* a magic incantation that I can apply in an automated way to prevent the
> > error from occurring.
> >
> > I can of course wrap function calls up in try() and if there is an error
> > generate a new data set and go again.  However I'm a little apprehensive
> > that this might bias the results of the simulations in some way.
> >
> > I could also switch to using mixed_model(), but would prefer to stick with the devil I know (i.e. glmer()) for the sake of consistency with other work that I have done.  (And who knows?  Maybe in the course of the simulations mixed_model() might fall over too, from time to time.)
> >
> > I'd appreciate any avuncular (or materteral) advice that anyone might be inclined to offer.
> >
> > cheers,
> >
> > Rolf
> >
> > --
> > Honorary Research Fellow
> > Department of Statistics
> > University of Auckland
> > Phone: +64-9-373-7599 ext. 88276
> > <testData.txt>
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://eur04.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7C%7C014e497b7e884f35d78708d780fd0a94%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637119696600482811&amp;sdata=m%2Binqw1ft8rZ1w37Q7McwqOXJ4ws1%2BtcstsRZKts8Lc%3D&amp;reserved=0
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbo|ker @end|ng |rom gm@||@com  Sun Dec 15 03:12:11 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sat, 14 Dec 2019 21:12:11 -0500
Subject: [R-sig-ME] Is there a way to deal with errors such as this?
In-Reply-To: <CABghstTZ6aCW3xCV0s0aV0v7mMR-cRyfd3WBs0O+aaVHg9NpMw@mail.gmail.com>
References: <5d8a95d7-1310-cec0-8397-054a470dc7e2@auckland.ac.nz>
 <DM6PR06MB50516D82269405674B61ACA6AF560@DM6PR06MB5051.namprd06.prod.outlook.com>
 <CABghstTZ6aCW3xCV0s0aV0v7mMR-cRyfd3WBs0O+aaVHg9NpMw@mail.gmail.com>
Message-ID: <CABghstT23=qhOhCrm0=WjDJHztSE9Ed2WeinCR-RFfvah+=Hng@mail.gmail.com>

PS that output was obtained by setting verbose=1000 when running glmer ...

On Sat, Dec 14, 2019 at 9:11 PM Ben Bolker <bbolker at gmail.com> wrote:
>
>   I would sadly agree with this assessment as well.  It would be good
> to collect a set of models that fail in this way and use them to
> debug/figure out what the problem is: the PIRLS loop is implemented
> entirely in C++, which makes it relatively painful to debug. (It might
> also be possible to make some progress by using the "pureR"
> implementation that Steve Walker wrote a few years ago ...)
>
>  One little clue is that (as I vaguely remembered/suspected) is that
> the proximal problem is that iterations that result in NaN are not
> dealt with well. Next step: figuring out why the NaNs are generated in
> the first place ...
>
> *** pwrssUpdate step 1
> pdev=182574; delu_min: -158.148; delu_max: 310.47; delb_min: -7.05005;
> delb_max: 60.6557
>
> pwrssUpdate: Entering step halving loop
> step-halving iteration 0:  pdev=45331.6; delu_min: -79.2949; delu_max:
> 155.422; delb_min: -3.50962; delb_max: 30.2776
> step-halving iteration 1:  pdev=11437.5; delu_min: -39.8683; delu_max:
> 77.8977; delb_min: -1.73941; delb_max: 15.0885
> *** pwrssUpdate step 2
> pdev=nan; delu_min: nan; delu_max: nan; delb_min: nan; delb_max: nan
>
> pwrssUpdate: Entering step halving loop
> step-halving iteration 0:  pdev=nan; delu_min: nan; delu_max: nan;
> delb_min: nan; delb_max: nan
> step-halving iteration 1:  pdev=nan; delu_min: nan; delu_max: nan;
> delb_min: nan; delb_max: nan
> step-halving iteration 2:  pdev=nan; delu_min: nan; delu_max: nan;
> delb_min: nan; delb_max: nan
> step-halving iteration 3:  pdev=nan; delu_min: nan; delu_max: nan;
> delb_min: nan; delb_max: nan
> step-halving iteration 4:  pdev=nan; delu_min: nan; delu_max: nan;
> delb_min: nan; delb_max: nan
> step-halving iteration 5:  pdev=nan; delu_min: nan; delu_max: nan;
> delb_min: nan; delb_max: nan
> step-halving iteration 6:  pdev=nan; delu_min: nan; delu_max: nan;
> delb_min: nan; delb_max: nan
> step-halving iteration 7:  pdev=nan; delu_min: nan; delu_max: nan;
> delb_min: nan; delb_max: nan
> step-halving iteration 8:  pdev=nan; delu_min: nan; delu_max: nan;
> delb_min: nan; delb_max: nan
> step-halving iteration 9:  pdev=nan; delu_min: nan; delu_max: nan;
> delb_min: nan; delb_max: nan
> Error in pwrssUpdate(pp, resp, tol = tolPwrss, GQmat = GHrule(0L),
> compDev = compDev,  :
>   (maxstephalfit) PIRLS step-halvings failed to reduce deviance in pwrssUpdate
>
> On Sat, Dec 14, 2019 at 8:50 PM Jonathan Judge <bachlaw01 at outlook.com> wrote:
> >
> > Rolf:
> >
> > Sadly, that error has always been the kiss of death for me no matter what I tried. As parameterized, the model probably just won?t optimize in lme4. If you want to stick with pseudo-frequentist inference, you could try glmmTMB, which is developed by some of the same folks (well, one in particular) and it may work using the same notation you are used to. But that error message usually means you need to try a different package.
> >
> > Jonathan
> >
> > Sent from my iPhone
> >
> > > On Dec 14, 2019, at 7:21 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> > >
> > > ?
> > > By "this" I mean as demonstrated in the following code.  The file testData.txt is attached.
> > >
> > > X <- dget("testData.txt")
> > > library(lme4)
> > > fit <- glmer(cbind(Dead,Alive) ~ (0+Trt)/Dose + (Dose | Rep),
> > >             data=X,family=binomial(link="probit"))
> > >
> > > The foregoing falls over with the (rather complex) error message:
> > >
> > >> Error in pwrssUpdate(pp, resp, tol = tolPwrss, GQmat = GHrule(0L), compDev = compDev,  :   (maxstephalfit) PIRLS step-halvings failed to reduce deviance in pwrssUpdate
> > >
> > > I note that mixed_model() from GLMMadaptive seems to be able to deal with these data and this model:
> > >
> > > library(GLMMadaptive)
> > > fit <- mixed_model(fixed=cbind(Dead,Alive) ~ (0+Trt)/Dose,
> > >                   random=~Dose | Rep,
> > >                   data=X,family=binomial(link="probit"))
> > >
> > > The foregoing runs without complaint.
> > >
> > > I am applying the glmer() model in the context of doing some fairly elaborate simulations (in which "X" gets randomly generated) and the error causes the simulations to crash unpleasantly.  So I would *like* a magic incantation that I can apply in an automated way to prevent the
> > > error from occurring.
> > >
> > > I can of course wrap function calls up in try() and if there is an error
> > > generate a new data set and go again.  However I'm a little apprehensive
> > > that this might bias the results of the simulations in some way.
> > >
> > > I could also switch to using mixed_model(), but would prefer to stick with the devil I know (i.e. glmer()) for the sake of consistency with other work that I have done.  (And who knows?  Maybe in the course of the simulations mixed_model() might fall over too, from time to time.)
> > >
> > > I'd appreciate any avuncular (or materteral) advice that anyone might be inclined to offer.
> > >
> > > cheers,
> > >
> > > Rolf
> > >
> > > --
> > > Honorary Research Fellow
> > > Department of Statistics
> > > University of Auckland
> > > Phone: +64-9-373-7599 ext. 88276
> > > <testData.txt>
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://eur04.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7C%7C014e497b7e884f35d78708d780fd0a94%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637119696600482811&amp;sdata=m%2Binqw1ft8rZ1w37Q7McwqOXJ4ws1%2BtcstsRZKts8Lc%3D&amp;reserved=0
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sun Dec 15 03:47:45 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sun, 15 Dec 2019 15:47:45 +1300
Subject: [R-sig-ME] Is there a way to deal with errors such as this?
In-Reply-To: <CABghstT23=qhOhCrm0=WjDJHztSE9Ed2WeinCR-RFfvah+=Hng@mail.gmail.com>
References: <5d8a95d7-1310-cec0-8397-054a470dc7e2@auckland.ac.nz>
 <DM6PR06MB50516D82269405674B61ACA6AF560@DM6PR06MB5051.namprd06.prod.outlook.com>
 <CABghstTZ6aCW3xCV0s0aV0v7mMR-cRyfd3WBs0O+aaVHg9NpMw@mail.gmail.com>
 <CABghstT23=qhOhCrm0=WjDJHztSE9Ed2WeinCR-RFfvah+=Hng@mail.gmail.com>
Message-ID: <9d2a50e5-c033-2946-1e81-d4059b7b2ca1@auckland.ac.nz>


Thanks to Jonathan Judge and Ben Bolker for their replies.  It appears 
that the short answer to my question is "No."

That being so, I will go with the strategy of wrapping the calls in 
try() and simulating new data if the error occurs.  If this risks 
biasing the simulation results, well, at least I have a good excuse to 
tell the referees! :-)

Perhaps later I will re-run the simulations using mixed_model() from
GLMMadaptive and compare the results.

Thanks again.

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From d@|uedecke @end|ng |rom uke@de  Sun Dec 15 11:20:56 2019
From: d@|uedecke @end|ng |rom uke@de (=?utf-8?Q?Daniel_L=C3=BCdecke?=)
Date: Sun, 15 Dec 2019 11:20:56 +0100
Subject: [R-sig-ME] Is there a way to deal with errors such as this?
In-Reply-To: <5d8a95d7-1310-cec0-8397-054a470dc7e2@auckland.ac.nz>
References: <5d8a95d7-1310-cec0-8397-054a470dc7e2@auckland.ac.nz>
Message-ID: <000401d5b331$56d13be0$0473b3a0$@uke.de>

The model seems to fit w/o error when you use "glmmTMB". Unlike glmmADAPTIVE, which uses a more time consuming adaptive Gaussian quadrature rule, glmmTMB might be faster to run the models (even faster than glmer(), probably).

 

library(glmmTMB)

fit <- glmmTMB(

  cbind(Dead, Alive) ~ (0 + Trt) / Dose + (Dose | Rep),

  data = dat,

  family = binomial(link = "probit")

)

 

parameters::model_parameters(fit)

#> Parameter             | Coefficient |   SE |         95% CI |     z |  df |      p

#> ----------------------------------------------------------------------------------

#> Trt16hour10deg        |       -0.74 | 0.33 | [-1.38, -0.10] | -2.26 | 109 | 0.024 

#> Trt16hour20deg        |        0.13 | 0.33 | [-0.52,  0.78] |  0.40 | 109 | 0.691 

#> Trt16hour5deg         |       -0.86 | 0.32 | [-1.48, -0.24] | -2.71 | 109 | 0.007 

#> Trt8hour10deg         |       -0.12 | 0.37 | [-0.84,  0.60] | -0.32 | 109 | 0.749 

#> Trt8hour20deg         |       -0.87 | 0.31 | [-1.49, -0.26] | -2.79 | 109 | 0.005 

#> Trt8hour5deg          |       -0.77 | 0.31 | [-1.38, -0.17] | -2.50 | 109 | 0.012 

#> Trt16hour10deg : Dose |        0.16 | 0.01 | [ 0.14,  0.19] | 13.50 | 109 | < .001

#> Trt16hour20deg : Dose |        0.23 | 0.02 | [ 0.18,  0.28] |  9.35 | 109 | < .001

#> Trt16hour5deg : Dose  |        0.08 | 0.01 | [ 0.07,  0.09] | 13.42 | 109 | < .001

#> Trt8hour10deg : Dose  |        0.08 | 0.01 | [ 0.07,  0.10] | 10.84 | 109 | < .001

#> Trt8hour20deg : Dose  |        0.17 | 0.01 | [ 0.15,  0.19] | 16.59 | 109 | < .001

#> Trt8hour5deg : Dose   |        0.05 | 0.00 | [ 0.04,  0.06] | 14.52 | 109 | < .001

 

Best

Daniel

 

-----Urspr?ngliche Nachricht-----
Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> Im Auftrag von Rolf Turner
Gesendet: Sonntag, 15. Dezember 2019 02:20
An: r-sig-mixed-models at r-project.org
Betreff: [R-sig-ME] Is there a way to deal with errors such as this?

 

 

By "this" I mean as demonstrated in the following code.  The file 

testData.txt is attached.

 

X <- dget("testData.txt")

library(lme4)

fit <- glmer(cbind(Dead,Alive) ~ (0+Trt)/Dose + (Dose | Rep),

              data=X,family=binomial(link="probit"))

 

The foregoing falls over with the (rather complex) error message:

 

> Error in pwrssUpdate(pp, resp, tol = tolPwrss, GQmat = GHrule(0L), compDev = compDev,  : 

>   (maxstephalfit) PIRLS step-halvings failed to reduce deviance in pwrssUpdate

 

I note that mixed_model() from GLMMadaptive seems to be able to deal 

with these data and this model:

 

library(GLMMadaptive)

fit <- mixed_model(fixed=cbind(Dead,Alive) ~ (0+Trt)/Dose,

                    random=~Dose | Rep,

                    data=X,family=binomial(link="probit"))

 

The foregoing runs without complaint.

 

I am applying the glmer() model in the context of doing some fairly 

elaborate simulations (in which "X" gets randomly generated) and the 

error causes the simulations to crash unpleasantly.  So I would *like* a 

magic incantation that I can apply in an automated way to prevent the

error from occurring.

 

I can of course wrap function calls up in try() and if there is an error

generate a new data set and go again.  However I'm a little apprehensive

that this might bias the results of the simulations in some way.

 

I could also switch to using mixed_model(), but would prefer to stick 

with the devil I know (i.e. glmer()) for the sake of consistency with 

other work that I have done.  (And who knows?  Maybe in the course of 

the simulations mixed_model() might fall over too, from time to time.)

 

I'd appreciate any avuncular (or materteral) advice that anyone might be 

inclined to offer.

 

cheers,

 

Rolf

 

-- 

Honorary Research Fellow

Department of Statistics

University of Auckland

Phone: +64-9-373-7599 ext. 88276

--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sun Dec 15 21:45:34 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Mon, 16 Dec 2019 09:45:34 +1300
Subject: [R-sig-ME] Is there a way to deal with errors such as this?
In-Reply-To: <000401d5b331$56d13be0$0473b3a0$@uke.de>
References: <5d8a95d7-1310-cec0-8397-054a470dc7e2@auckland.ac.nz>
 <000401d5b331$56d13be0$0473b3a0$@uke.de>
Message-ID: <c5289090-f17c-c6f9-76f2-bc78e011fc78@auckland.ac.nz>


On 15/12/19 11:20 pm, Daniel L?decke wrote:

> The model seems to fit w/o error when you use "glmmTMB". Unlike 
> glmmADAPTIVE, which uses a more time consuming adaptive Gaussian 
> quadrature rule, glmmTMB might be faster to run the models (even faster 
> than glmer(), probably).

<SNIP>

Thanks for this advice.  For some reason I had it my head that 
GLMMadaptive worked better than glmmTMB.  I don't know why I got that 
idea.  I will do some experimentation and timing assessments later on.
But for the moment I'm sticking with glmer() and the strategy of 
discarding the simulated data set and generating a new one if glmer() 
throws an error.

Thanks again.

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From d@r|zopou|o@ @end|ng |rom er@@mu@mc@n|  Sun Dec 15 22:08:52 2019
From: d@r|zopou|o@ @end|ng |rom er@@mu@mc@n| (D. Rizopoulos)
Date: Sun, 15 Dec 2019 21:08:52 +0000
Subject: [R-sig-ME] Is there a way to deal with errors such as this?
In-Reply-To: <c5289090-f17c-c6f9-76f2-bc78e011fc78@auckland.ac.nz>
References: <5d8a95d7-1310-cec0-8397-054a470dc7e2@auckland.ac.nz>
 <000401d5b331$56d13be0$0473b3a0$@uke.de>,
 <c5289090-f17c-c6f9-76f2-bc78e011fc78@auckland.ac.nz>
Message-ID: <AM6PR0402MB333313B9252D5B1FD9827949E8560@AM6PR0402MB3333.eurprd04.prod.outlook.com>

In the datasets for which glmer() fails you could try fitting the model with GLMMadaptive or glmmTMB. The model you?re fitting is always the same, the optimization and numerical integration algorithms change in the different packages.

Moreover, if the main aim of the simulation is to assess some properties of the model and not of the optimization algorithm, you could help the optimization procedure by supplying as starting values for the model parameters the true parameters values from which you simulate the data.

Best,
Dimitris

?-
Dimitris Rizopoulos
Professor of Biostatistics
Erasmus University Medical Center
The Netherlands

________________________________
???: ? ??????? R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> ?? ?????? ??? ?????? Rolf Turner <r.turner at auckland.ac.nz>
????????: ???????, ?????????? 15, 2019 21:45
????: Daniel L?decke
????.: r-sig-mixed-models at r-project.org
????: Re: [R-sig-ME] Is there a way to deal with errors such as this?


On 15/12/19 11:20 pm, Daniel L?decke wrote:

> The model seems to fit w/o error when you use "glmmTMB". Unlike
> glmmADAPTIVE, which uses a more time consuming adaptive Gaussian
> quadrature rule, glmmTMB might be faster to run the models (even faster
> than glmer(), probably).

<SNIP>

Thanks for this advice. For some reason I had it my head that
GLMMadaptive worked better than glmmTMB. I don't know why I got that
idea. I will do some experimentation and timing assessments later on.
But for the moment I'm sticking with glmer() and the strategy of
discarding the simulated data set and generating a new one if glmer()
throws an error.

Thanks again.

cheers,

Rolf

--
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7Cb50fcaf7013c475560e108d7819fc860%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C637120395587161755&amp;sdata=kBWvFPzbLuOdLVnIwTL7hTMeb9zsFt6vxauVgk39PQs%3D&amp;reserved=0

	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Mon Dec 16 00:08:06 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Mon, 16 Dec 2019 12:08:06 +1300
Subject: [R-sig-ME] Is there a way to deal with errors such as this?
In-Reply-To: <AM6PR0402MB333313B9252D5B1FD9827949E8560@AM6PR0402MB3333.eurprd04.prod.outlook.com>
References: <5d8a95d7-1310-cec0-8397-054a470dc7e2@auckland.ac.nz>
 <000401d5b331$56d13be0$0473b3a0$@uke.de>
 <c5289090-f17c-c6f9-76f2-bc78e011fc78@auckland.ac.nz>
 <AM6PR0402MB333313B9252D5B1FD9827949E8560@AM6PR0402MB3333.eurprd04.prod.outlook.com>
Message-ID: <1cb03000-c6b7-a226-9d84-8826eb09852d@auckland.ac.nz>

On 16/12/19 10:08 am, D. Rizopoulos wrote:

<SNIP>

> Moreover, if the main aim of the simulation is to assess some properties 
> of the model and not of the optimization algorithm, you could help the 
> optimization procedure by supplying as starting values for the model 
> parameters the true parameters values from which you simulate the data.

That is a very appealing idea, but I'm afraid that I find the help for 
glmer() to be utterly opaque in terms of the "start" argument.  May I 
impose upon you for some help to get me, uh, started? ( :-) )

Explicitly, suppose that I have a data frame "protoX", and I fit a model:

protoFit <- glmer(cbind(Dead,Alive) ~ (0+Trt)/Dose + (Dose | Rep),
              data=protoX,family=binomial(link="probit"))

Suppose that I then simulate data from protoFit:

X <- protoX
X[,c("Dead","Alive") <- simulate(protoFit)[,1]

The "true" values of the parameters in respect of fitting a model to X, 
will be the fitted parameters contained in protoFit.  How do I specify 
these as starting values in a call to glmer()?

I would do something like:

fit <- glmer(cbind(Dead,Alive) ~ (0+Trt)/Dose + (Dose | Rep),
              data=X,family=binomial(link="probit"),start=???)

What do I use for "???" ?  The help seems to indicate that it should be 
a list with components "fixef" and "theta".  I would conjecture that I'd 
get the "fixef" component as fixef(protoFit).  However it is totally 
mysterious to me how I would get "theta" (or even what "theta" *is*).

Can you (or someone) point me in the right direction?  (An *example* of 
the use of "start" in the help file would have been nice. :-( )

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From c@c@voeten @end|ng |rom hum@|e|denun|v@n|  Mon Dec 16 13:49:56 2019
From: c@c@voeten @end|ng |rom hum@|e|denun|v@n| (Voeten, C.C.)
Date: Mon, 16 Dec 2019 12:49:56 +0000
Subject: [R-sig-ME] Is there a way to deal with errors such as this?
In-Reply-To: <1cb03000-c6b7-a226-9d84-8826eb09852d@auckland.ac.nz>
References: <5d8a95d7-1310-cec0-8397-054a470dc7e2@auckland.ac.nz>
 <000401d5b331$56d13be0$0473b3a0$@uke.de>
 <c5289090-f17c-c6f9-76f2-bc78e011fc78@auckland.ac.nz>
 <AM6PR0402MB333313B9252D5B1FD9827949E8560@AM6PR0402MB3333.eurprd04.prod.outlook.com>
 <1cb03000-c6b7-a226-9d84-8826eb09852d@auckland.ac.nz>
Message-ID: <D14049CE02C4F54D95360EEC06CE45C50FB4891A@SPMXM08.VUW.leidenuniv.nl>

Hi Rolf,

'theta' is the vector of random-effect parameters, obtained by getME(model,'theta'). I'm sure someone more knowledgeable than I can tell you their exact definition - I thought they are the entries of the lower Cholesky factor of the random-effects design matrix scaled by the model's residual error, but I may have gotten a few things mixed up here. 'fixef' is indeed just fixef(model).

HTH,
Cesko

-----Oorspronkelijk bericht-----
Van: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> Namens Rolf Turner
Verzonden: maandag 16 december 2019 00:08
Aan: D. Rizopoulos <d.rizopoulos at erasmusmc.nl>
CC: r-sig-mixed-models at r-project.org
Onderwerp: Re: [R-sig-ME] Is there a way to deal with errors such as this?

On 16/12/19 10:08 am, D. Rizopoulos wrote:

<SNIP>

> Moreover, if the main aim of the simulation is to assess some 
> properties of the model and not of the optimization algorithm, you 
> could help the optimization procedure by supplying as starting values 
> for the model parameters the true parameters values from which you simulate the data.

That is a very appealing idea, but I'm afraid that I find the help for
glmer() to be utterly opaque in terms of the "start" argument.  May I impose upon you for some help to get me, uh, started? ( :-) )

Explicitly, suppose that I have a data frame "protoX", and I fit a model:

protoFit <- glmer(cbind(Dead,Alive) ~ (0+Trt)/Dose + (Dose | Rep),
              data=protoX,family=binomial(link="probit"))

Suppose that I then simulate data from protoFit:

X <- protoX
X[,c("Dead","Alive") <- simulate(protoFit)[,1]

The "true" values of the parameters in respect of fitting a model to X, will be the fitted parameters contained in protoFit.  How do I specify these as starting values in a call to glmer()?

I would do something like:

fit <- glmer(cbind(Dead,Alive) ~ (0+Trt)/Dose + (Dose | Rep),
              data=X,family=binomial(link="probit"),start=???)

What do I use for "???" ?  The help seems to indicate that it should be a list with components "fixef" and "theta".  I would conjecture that I'd get the "fixef" component as fixef(protoFit).  However it is totally mysterious to me how I would get "theta" (or even what "theta" *is*).

Can you (or someone) point me in the right direction?  (An *example* of the use of "start" in the help file would have been nice. :-( )

cheers,

Rolf

--
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From r@turner @end|ng |rom @uck|@nd@@c@nz  Tue Dec 17 04:40:44 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Tue, 17 Dec 2019 16:40:44 +1300
Subject: [R-sig-ME] Is there a way to deal with errors such as this?
In-Reply-To: <D14049CE02C4F54D95360EEC06CE45C50FB4891A@SPMXM08.VUW.leidenuniv.nl>
References: <5d8a95d7-1310-cec0-8397-054a470dc7e2@auckland.ac.nz>
 <000401d5b331$56d13be0$0473b3a0$@uke.de>
 <c5289090-f17c-c6f9-76f2-bc78e011fc78@auckland.ac.nz>
 <AM6PR0402MB333313B9252D5B1FD9827949E8560@AM6PR0402MB3333.eurprd04.prod.outlook.com>
 <1cb03000-c6b7-a226-9d84-8826eb09852d@auckland.ac.nz>
 <D14049CE02C4F54D95360EEC06CE45C50FB4891A@SPMXM08.VUW.leidenuniv.nl>
Message-ID: <7742a7a6-672c-16be-18ae-13b44a168542@auckland.ac.nz>



On 17/12/19 1:49 am, Voeten, C.C. wrote:

> Hi Rolf,
> 
> 'theta' is the vector of random-effect parameters, obtained by
> getME(model,'theta'). I'm sure someone more knowledgeable than I can
> tell you their exact definition - I thought they are the entries of
> the lower Cholesky factor of the random-effects design matrix scaled
> by the model's residual error, but I may have gotten a few things
> mixed up here. 'fixef' is indeed just fixef(model).

That's great.  Thanks hugely.  The "getME(model,'theta')" bit was what I 
really needed to know (and no clue how to find).

Thanks again.

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From g@@d|o @end|ng |rom po@t@bgu@@c@||  Wed Dec 18 12:07:26 2019
From: g@@d|o @end|ng |rom po@t@bgu@@c@|| (Mario Garrido)
Date: Wed, 18 Dec 2019 12:07:26 +0100
Subject: [R-sig-ME] AIC and other IT indexes criteria for for backward,
 forward and stepwise regression
Message-ID: <CAHzBVpKzOD5Jw9payNpA-9R05jYw-GQvo8MS_6fXzd6aOUioQA@mail.gmail.com>

Dear users,
Im currently exploring on the use of AIC and other I-T indexes criteria for
backward, forward and stepwise regression.
Usually, when applying IT indexes for Multimodal Inference, we choose a set
of 'good models' depending on different criteria, but mainly, all models
with delta AIC<2, and then we averaged the estimates between the set of
models or make conclusions based on the set of models, no need to average.
However, if Im not wrong, the goal of backward etc is to get to one 'best'
final model. I understand the use of AIC in this framework but, is there
any criteria to select the best model in this case? Do I simply have to
choose the model with the lowest AIC no matter whether there is another
model whose delta is less than 2? Does it depend on a personal criteria?
For example, if my 'maximal' or saturated model has the lowest AIC and the
model dropping one variable has a delta of 0.5, which model to choose?
I was looking on the web and I have found no answer to this. So, any
literature recommendation or advice will be welcome.
Thanks

-- 
Mario Garrido Escudero, PhD
Dr. Hadas Hawlena Lab
Mitrani Department of Desert Ecology
Jacob Blaustein Institutes for Desert Research
Ben-Gurion University of the Negev
Midreshet Ben-Gurion 84990 ISRAEL

gaiarrido at gmail.com; gaadio at post.bgu.ac.il
phone: (+972) 08-659-6854

	[[alternative HTML version deleted]]


From gu|||@ume@|mon@@2 @end|ng |rom gm@||@com  Wed Dec 18 13:48:44 2019
From: gu|||@ume@|mon@@2 @end|ng |rom gm@||@com (Guillaume Adeux)
Date: Wed, 18 Dec 2019 13:48:44 +0100
Subject: [R-sig-ME] mixed lognormal hurdle model with multiple grouping
 factors
Message-ID: <CAENiVe83vHUUv6i87oEo=ZzeyD4KXstCpx7p=dSwEfWZrtTAsg@mail.gmail.com>

Hi everyone,

I am looking for a package which can handle "hurdle.lognormal" distribution
family and multiple grouping factors.

GLMMadaptive seemed as the way to go but unfortunately, to the best of my
knowledge, it does not handle multiple grouping factors (random effects).

You may ask why? I am analyzing plant diversity and one of the treatments
led to plots which were dominated by one species. Hence, certain diversity
indices are estimated as zero in these plots, and produces a mass at zero.
All other values are positive and continuous.

Anyone have an idea of a package/function which can handle this? Or any
alternative approach?

In lmer syntax, the model is the following:

mod=lmer(diversity~block+syst+(1|plot)+(1|year)+(1|plot:year),data=density,REML=F)

Thank you for your time and help.

Sincerely,

Guillaume ADEUX

	[[alternative HTML version deleted]]


From c@c@voeten @end|ng |rom hum@|e|denun|v@n|  Wed Dec 18 14:45:19 2019
From: c@c@voeten @end|ng |rom hum@|e|denun|v@n| (Cesko Voeten)
Date: Wed, 18 Dec 2019 14:45:19 +0100
Subject: [R-sig-ME] mixed lognormal hurdle model with multiple grouping
 factors
In-Reply-To: <CAENiVe83vHUUv6i87oEo=ZzeyD4KXstCpx7p=dSwEfWZrtTAsg@mail.gmail.com>
References: <CAENiVe83vHUUv6i87oEo=ZzeyD4KXstCpx7p=dSwEfWZrtTAsg@mail.gmail.com>
Message-ID: <3b68fdf6-31d5-f27b-b3a8-200cd0b6a632@hum.leidenuniv.nl>

Hi Guillaume,

If you're not afraid to go Bayesian, brms can do it. Alternatively, you may be able to use glmmTMB and treat the hurdle part as zero inflation, but this is conceptually not the same thing as a hurdle model so you would need to judge whether that would make sense at all for your application.

HTH,
Cesko

Op 18-12-2019 om 13:48 schreef Guillaume Adeux:
> Hi everyone,
> 
> I am looking for a package which can handle "hurdle.lognormal" distribution
> family and multiple grouping factors.
> 
> GLMMadaptive seemed as the way to go but unfortunately, to the best of my
> knowledge, it does not handle multiple grouping factors (random effects).
> 
> You may ask why? I am analyzing plant diversity and one of the treatments
> led to plots which were dominated by one species. Hence, certain diversity
> indices are estimated as zero in these plots, and produces a mass at zero.
> All other values are positive and continuous.
> 
> Anyone have an idea of a package/function which can handle this? Or any
> alternative approach?
> 
> In lmer syntax, the model is the following:
> 
> mod=lmer(diversity~block+syst+(1|plot)+(1|year)+(1|plot:year),data=density,REML=F)
> 
> Thank you for your time and help.
> 
> Sincerely,
> 
> Guillaume ADEUX
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From mo|||eebrook@ @end|ng |rom gm@||@com  Wed Dec 18 15:05:35 2019
From: mo|||eebrook@ @end|ng |rom gm@||@com (Mollie Brooks)
Date: Wed, 18 Dec 2019 15:05:35 +0100
Subject: [R-sig-ME] mixed lognormal hurdle model with multiple grouping
 factors
In-Reply-To: <3b68fdf6-31d5-f27b-b3a8-200cd0b6a632@hum.leidenuniv.nl>
References: <CAENiVe83vHUUv6i87oEo=ZzeyD4KXstCpx7p=dSwEfWZrtTAsg@mail.gmail.com>
 <3b68fdf6-31d5-f27b-b3a8-200cd0b6a632@hum.leidenuniv.nl>
Message-ID: <28255CBD-2A77-4E1B-A9A8-1FEC88CD10A9@gmail.com>

Hi Guillaume,

I don?t think the hurdle lognormal can be fit in a single function call to glmmTMB since the model for the non-zero response requires log-transforming the response. Other types of hurdle models could be fit in glmmTMB using the zero-inflation model.

I don?t think you gain much information in hurdle models by modeling the two parts (zeros and non-zeros) in one function call. The only potential benefit to fitting a hurdle in a single function call is that you get likelihood and AIC for the entire data set, but I don?t know if those are produced by brms.

You could just fit a binomial model for the zero-non-zero process (i.e. monoculture) like
mod_binom=lmer((diversity>0)~block+syst+(1|plot)+(1|year)+(1|plot:year), data=density, family=binomial)

and then fit a model to the log of the positive data
mod_gaus=lmer(log(diversity)~block+syst+(1|plot)+(1|year)+(1|plot:year), data=subset(density, diversity>0))

Or, given that the outcome is non-negative and continuous, it might make sense to try a Tweedie distribution, but I?m not sure I?ve seen this applied to diversity indices in the literature. Has anyone else seen this done?
mod_twe = glmmTMB(diversity~block+syst+(1|plot)+(1|year)+(1|plot:year), data=density, family=tweedie)

Cheers,
Mollie

> On 18Dec 2019, at 14:45, Cesko Voeten <c.c.voeten at hum.leidenuniv.nl> wrote:
> 
> Hi Guillaume,
> 
> If you're not afraid to go Bayesian, brms can do it. Alternatively, you may be able to use glmmTMB and treat the hurdle part as zero inflation, but this is conceptually not the same thing as a hurdle model so you would need to judge whether that would make sense at all for your application.
> 
> HTH,
> Cesko
> 
> Op 18-12-2019 om 13:48 schreef Guillaume Adeux:
>> Hi everyone,
>> I am looking for a package which can handle "hurdle.lognormal" distribution
>> family and multiple grouping factors.
>> GLMMadaptive seemed as the way to go but unfortunately, to the best of my
>> knowledge, it does not handle multiple grouping factors (random effects).
>> You may ask why? I am analyzing plant diversity and one of the treatments
>> led to plots which were dominated by one species. Hence, certain diversity
>> indices are estimated as zero in these plots, and produces a mass at zero.
>> All other values are positive and continuous.
>> Anyone have an idea of a package/function which can handle this? Or any
>> alternative approach?
>> In lmer syntax, the model is the following:
>> mod=lmer(diversity~block+syst+(1|plot)+(1|year)+(1|plot:year),data=density,REML=F)
>> Thank you for your time and help.
>> Sincerely,
>> Guillaume ADEUX
>> 	[[alternative HTML version deleted]]
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbo|ker @end|ng |rom gm@||@com  Wed Dec 18 21:44:03 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Wed, 18 Dec 2019 15:44:03 -0500
Subject: [R-sig-ME] AIC and other IT indexes criteria for for backward,
 forward and stepwise regression
In-Reply-To: <CAHzBVpKzOD5Jw9payNpA-9R05jYw-GQvo8MS_6fXzd6aOUioQA@mail.gmail.com>
References: <CAHzBVpKzOD5Jw9payNpA-9R05jYw-GQvo8MS_6fXzd6aOUioQA@mail.gmail.com>
Message-ID: <1bbdabe4-4a1e-612e-34fb-bafde0a00649@gmail.com>


  This is a reasonable question, but it isn't at all specific to mixed
models (which is the topic of this mailing list).  You could try
CrossValidated (https://stats.stackexchange.com).

  I'm sure opinions differ a lot, and answers will almost certainly
depend on your goals and context, but *if* I were going to do model
selection (which I think is very often a bad idea!) I would simply pick
the model with the minimum AIC, which will (asymptotically) have the
smallest expected Kullback-Leibler distance.

On 2019-12-18 6:07 a.m., Mario Garrido wrote:
> Dear users,
> Im currently exploring on the use of AIC and other I-T indexes criteria for
> backward, forward and stepwise regression.
> Usually, when applying IT indexes for Multimodal Inference, we choose a set
> of 'good models' depending on different criteria, but mainly, all models
> with delta AIC<2, and then we averaged the estimates between the set of
> models or make conclusions based on the set of models, no need to average.
> However, if Im not wrong, the goal of backward etc is to get to one 'best'
> final model. I understand the use of AIC in this framework but, is there
> any criteria to select the best model in this case? Do I simply have to
> choose the model with the lowest AIC no matter whether there is another
> model whose delta is less than 2? Does it depend on a personal criteria?
> For example, if my 'maximal' or saturated model has the lowest AIC and the
> model dropping one variable has a delta of 0.5, which model to choose?
> I was looking on the web and I have found no answer to this. So, any
> literature recommendation or advice will be welcome.
> Thanks
>


From ger@|ttee @end|ng |rom gm@||@com  Thu Dec 19 01:48:32 2019
From: ger@|ttee @end|ng |rom gm@||@com (Szymek Drobniak)
Date: Thu, 19 Dec 2019 11:48:32 +1100
Subject: [R-sig-ME] AIC and other IT indexes criteria for for backward,
 forward and stepwise regression
In-Reply-To: <mailman.17970.1149.1576701888.1419.r-sig-mixed-models@r-project.org>
References: <mailman.17970.1149.1576701888.1419.r-sig-mixed-models@r-project.org>
Message-ID: <69a0badd-1110-4738-bc66-81bb11173210@Spark>

Hi Mario, firstly - you should always think carefully if model selection is exactly what you want. Secondly - if you have multiple models performing similarly (with deltaAICc <= 2) you can average them (there are several methods, you can e.g. have a look at the MuMIn package) and/or summarize importance of different predictors based on the support they receive in different models.

Cheers,
Szymek

Dr Szymon Drobniak

Institute of Environmental Sciences
Jagiellonian University, Krak?w, Poland

School of Biological, Environmental and Earth Sciences
University of New South Wales, Sydney, Australia

Google Scholar profile
szymekdrobniak.wordpress.com
szdrobniak.pl
> Date: Wed, 18 Dec 2019 12:07:26 +0100
> From: Mario Garrido <gaadio at post.bgu.ac.il>
> To: "r-sig-mixed-models at r-project.org"
> <r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] AIC and other IT indexes criteria for for
> backward, forward and stepwise regression
> Message-ID:
> <CAHzBVpKzOD5Jw9payNpA-9R05jYw-GQvo8MS_6fXzd6aOUioQA at mail.gmail.com>
> Content-Type: text/plain; charset="utf-8"
>
> Dear users,
> Im currently exploring on the use of AIC and other I-T indexes criteria for
> backward, forward and stepwise regression.
> Usually, when applying IT indexes for Multimodal Inference, we choose a set
> of 'good models' depending on different criteria, but mainly, all models
> with delta AIC<2, and then we averaged the estimates between the set of
> models or make conclusions based on the set of models, no need to average.
> However, if Im not wrong, the goal of backward etc is to get to one 'best'
> final model. I understand the use of AIC in this framework but, is there
> any criteria to select the best model in this case? Do I simply have to
> choose the model with the lowest AIC no matter whether there is another
> model whose delta is less than 2? Does it depend on a personal criteria?
> For example, if my 'maximal' or saturated model has the lowest AIC and the
> model dropping one variable has a delta of 0.5, which model to choose?
> I was looking on the web and I have found no answer to this. So, any
> literature recommendation or advice will be welcome.
> Thanks
>
> --
> Mario Garrido Escudero, PhD
> Dr. Hadas Hawlena Lab
> Mitrani Department of Desert Ecology
> Jacob Blaustein Institutes for Desert Research
> Ben-Gurion University of the Negev
> Midreshet Ben-Gurion 84990 ISRAEL
>
> gaiarrido at gmail.com; gaadio at post.bgu.ac.il
> phone: (+972) 08-659-6854
>
> [[alternative HTML version deleted]]

	[[alternative HTML version deleted]]


From d@|uedecke @end|ng |rom uke@de  Thu Dec 19 08:02:08 2019
From: d@|uedecke @end|ng |rom uke@de (=?iso-8859-1?Q?Daniel_L=FCdecke?=)
Date: Thu, 19 Dec 2019 08:02:08 +0100
Subject: [R-sig-ME] AIC and other IT indexes criteria for for backward,
 forward and stepwise regression
In-Reply-To: <CAHzBVpKzOD5Jw9payNpA-9R05jYw-GQvo8MS_6fXzd6aOUioQA@mail.gmail.com>
References: <CAHzBVpKzOD5Jw9payNpA-9R05jYw-GQvo8MS_6fXzd6aOUioQA@mail.gmail.com>
Message-ID: <000b01d5b63a$3b0b4390$b121cab0$@uke.de>

I would second what Ben Bolker said, that model selection only based on some
fit indices should be done with care, and most often, theoretical
contemplation about your model / design is a more useful guide in selecting
predictors and models.

That said, you also might want to look at the "performance" package
(https://easystats.github.io/performance). There is a function,
"compare_performance()", which "ranks" your models when you use the argument
"rank = TRUE":
https://easystats.github.io/performance/reference/model_performance.html
The function looks at different fit indices (including AIC, but also R2 or
Bayes factors) that are shared by all models, and normalizes and averaged
those values to create a "ranking". As you may already guess from my
remarks, this is a rather exploratory or experimental method, which is
probably not better than just looking at the AIC, but maybe it's worth a
try.

The "see" package is our visualization tool, and I personally like plots
when exploring data or models. So, you can also create a "spiderweb" plot of
model comparisons:
https://easystats.github.io/see/articles/performance.html#compare-model-perf
ormances
(I think this function is currently only available in the GitHub version of
"see").

Maybe that gives you some inspiration...

Best
Daniel

-----Urspr?ngliche Nachricht-----
Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> Im
Auftrag von Mario Garrido
Gesendet: Mittwoch, 18. Dezember 2019 12:07
An: r-sig-mixed-models at r-project.org
Betreff: [R-sig-ME] AIC and other IT indexes criteria for for backward,
forward and stepwise regression

Dear users,
Im currently exploring on the use of AIC and other I-T indexes criteria for
backward, forward and stepwise regression.
Usually, when applying IT indexes for Multimodal Inference, we choose a set
of 'good models' depending on different criteria, but mainly, all models
with delta AIC<2, and then we averaged the estimates between the set of
models or make conclusions based on the set of models, no need to average.
However, if Im not wrong, the goal of backward etc is to get to one 'best'
final model. I understand the use of AIC in this framework but, is there
any criteria to select the best model in this case? Do I simply have to
choose the model with the lowest AIC no matter whether there is another
model whose delta is less than 2? Does it depend on a personal criteria?
For example, if my 'maximal' or saturated model has the lowest AIC and the
model dropping one variable has a delta of 0.5, which model to choose?
I was looking on the web and I have found no answer to this. So, any
literature recommendation or advice will be welcome.
Thanks

-- 
Mario Garrido Escudero, PhD
Dr. Hadas Hawlena Lab
Mitrani Department of Desert Ecology
Jacob Blaustein Institutes for Desert Research
Ben-Gurion University of the Negev
Midreshet Ben-Gurion 84990 ISRAEL

gaiarrido at gmail.com; gaadio at post.bgu.ac.il
phone: (+972) 08-659-6854

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING


From d@r|zopou|o@ @end|ng |rom er@@mu@mc@n|  Fri Dec 20 08:58:59 2019
From: d@r|zopou|o@ @end|ng |rom er@@mu@mc@n| (D. Rizopoulos)
Date: Fri, 20 Dec 2019 07:58:59 +0000
Subject: [R-sig-ME] mixed lognormal hurdle model with multiple grouping
 factors
In-Reply-To: <28255CBD-2A77-4E1B-A9A8-1FEC88CD10A9@gmail.com>
References: <CAENiVe83vHUUv6i87oEo=ZzeyD4KXstCpx7p=dSwEfWZrtTAsg@mail.gmail.com>
 <3b68fdf6-31d5-f27b-b3a8-200cd0b6a632@hum.leidenuniv.nl>,
 <28255CBD-2A77-4E1B-A9A8-1FEC88CD10A9@gmail.com>
Message-ID: <AM6PR0402MB3333D1F0EEBE20FAE1A0EEE5E82D0@AM6PR0402MB3333.eurprd04.prod.outlook.com>

For a hurdle model for repeated measurements data, the dichotomous outcome I(diversity > 0) is also a repeated measurements outcome. Hence, in the logistic regression model for this dichotomous outcome you will need to include random effects to account for the correlations. And it is logical to assume that the random effects from this logistic regression model will be correlated with the random effects of the linear mixed model for only the positive responses.

In this case the likelihood of the two parts does not split in two functionally independent parts that can be separately maximized. If this is indeed the case, then fitting the two parts separately may cause bias and loss of efficiency.

Best,
Dimitris

??
Dimitris Rizopoulos
Professor of Biostatistics
Erasmus University Medical Center
The Netherlands

________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Mollie Brooks <mollieebrooks at gmail.com>
Sent: Wednesday, December 18, 2019 3:08 PM
To: Help Mixed Models; Guillaume Adeux
Subject: Re: [R-sig-ME] mixed lognormal hurdle model with multiple grouping factors

Hi Guillaume,

I don?t think the hurdle lognormal can be fit in a single function call to glmmTMB since the model for the non-zero response requires log-transforming the response. Other types of hurdle models could be fit in glmmTMB using the zero-inflation model.

I don?t think you gain much information in hurdle models by modeling the two parts (zeros and non-zeros) in one function call. The only potential benefit to fitting a hurdle in a single function call is that you get likelihood and AIC for the entire data set, but I don?t know if those are produced by brms.

You could just fit a binomial model for the zero-non-zero process (i.e. monoculture) like
mod_binom=lmer((diversity>0)~block+syst+(1|plot)+(1|year)+(1|plot:year), data=density, family=binomial)

and then fit a model to the log of the positive data
mod_gaus=lmer(log(diversity)~block+syst+(1|plot)+(1|year)+(1|plot:year), data=subset(density, diversity>0))

Or, given that the outcome is non-negative and continuous, it might make sense to try a Tweedie distribution, but I?m not sure I?ve seen this applied to diversity indices in the literature. Has anyone else seen this done?
mod_twe = glmmTMB(diversity~block+syst+(1|plot)+(1|year)+(1|plot:year), data=density, family=tweedie)

Cheers,
Mollie

> On 18Dec 2019, at 14:45, Cesko Voeten <c.c.voeten at hum.leidenuniv.nl> wrote:
>
> Hi Guillaume,
>
> If you're not afraid to go Bayesian, brms can do it. Alternatively, you may be able to use glmmTMB and treat the hurdle part as zero inflation, but this is conceptually not the same thing as a hurdle model so you would need to judge whether that would make sense at all for your application.
>
> HTH,
> Cesko
>
> Op 18-12-2019 om 13:48 schreef Guillaume Adeux:
>> Hi everyone,
>> I am looking for a package which can handle "hurdle.lognormal" distribution
>> family and multiple grouping factors.
>> GLMMadaptive seemed as the way to go but unfortunately, to the best of my
>> knowledge, it does not handle multiple grouping factors (random effects).
>> You may ask why? I am analyzing plant diversity and one of the treatments
>> led to plots which were dominated by one species. Hence, certain diversity
>> indices are estimated as zero in these plots, and produces a mass at zero.
>> All other values are positive and continuous.
>> Anyone have an idea of a package/function which can handle this? Or any
>> alternative approach?
>> In lmer syntax, the model is the following:
>> mod=lmer(diversity~block+syst+(1|plot)+(1|year)+(1|plot:year),data=density,REML=F)
>> Thank you for your time and help.
>> Sincerely,
>> Guillaume ADEUX
>> [[alternative HTML version deleted]]
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C0f8f22d15f244f0190f208d783c3ca4b%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C637122749245106064&amp;sdata=XWAMTSylM6j81Lf%2BLb8qikDEho3QIo8l%2Bh%2BnxSpwjHM%3D&amp;reserved=0
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C0f8f22d15f244f0190f208d783c3ca4b%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C637122749245106064&amp;sdata=XWAMTSylM6j81Lf%2BLb8qikDEho3QIo8l%2Bh%2BnxSpwjHM%3D&amp;reserved=0

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C0f8f22d15f244f0190f208d783c3ca4b%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C637122749245106064&amp;sdata=XWAMTSylM6j81Lf%2BLb8qikDEho3QIo8l%2Bh%2BnxSpwjHM%3D&amp;reserved=0

	[[alternative HTML version deleted]]


From g@@d|o @end|ng |rom po@t@bgu@@c@||  Fri Dec 20 09:20:02 2019
From: g@@d|o @end|ng |rom po@t@bgu@@c@|| (Mario Garrido)
Date: Fri, 20 Dec 2019 09:20:02 +0100
Subject: [R-sig-ME] AIC and other IT indexes criteria for for backward,
 forward and stepwise regression
In-Reply-To: <1bbdabe4-4a1e-612e-34fb-bafde0a00649@gmail.com>
References: <CAHzBVpKzOD5Jw9payNpA-9R05jYw-GQvo8MS_6fXzd6aOUioQA@mail.gmail.com>
 <1bbdabe4-4a1e-612e-34fb-bafde0a00649@gmail.com>
Message-ID: <CAHzBVpLM=auHcMco=4BvT0er7rdz5+gYbjS1RHgeVZf4zBaqsQ@mail.gmail.com>

Dear Ben and Daniel,
thanks for your advice and recommendations and sorry if this is not the
proper forum for that. Following the advice, I will move my question to
cross validated.

Bests!

El mi?., 18 dic. 2019 a las 21:45, Ben Bolker (<bbolker at gmail.com>)
escribi?:

>
>   This is a reasonable question, but it isn't at all specific to mixed
> models (which is the topic of this mailing list).  You could try
> CrossValidated (https://stats.stackexchange.com).
>
>   I'm sure opinions differ a lot, and answers will almost certainly
> depend on your goals and context, but *if* I were going to do model
> selection (which I think is very often a bad idea!) I would simply pick
> the model with the minimum AIC, which will (asymptotically) have the
> smallest expected Kullback-Leibler distance.
>
> On 2019-12-18 6:07 a.m., Mario Garrido wrote:
> > Dear users,
> > Im currently exploring on the use of AIC and other I-T indexes criteria
> for
> > backward, forward and stepwise regression.
> > Usually, when applying IT indexes for Multimodal Inference, we choose a
> set
> > of 'good models' depending on different criteria, but mainly, all models
> > with delta AIC<2, and then we averaged the estimates between the set of
> > models or make conclusions based on the set of models, no need to
> average.
> > However, if Im not wrong, the goal of backward etc is to get to one
> 'best'
> > final model. I understand the use of AIC in this framework but, is there
> > any criteria to select the best model in this case? Do I simply have to
> > choose the model with the lowest AIC no matter whether there is another
> > model whose delta is less than 2? Does it depend on a personal criteria?
> > For example, if my 'maximal' or saturated model has the lowest AIC and
> the
> > model dropping one variable has a delta of 0.5, which model to choose?
> > I was looking on the web and I have found no answer to this. So, any
> > literature recommendation or advice will be welcome.
> > Thanks
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
Mario Garrido Escudero, PhD
Dr. Hadas Hawlena Lab
Mitrani Department of Desert Ecology
Jacob Blaustein Institutes for Desert Research
Ben-Gurion University of the Negev
Midreshet Ben-Gurion 84990 ISRAEL

gaiarrido at gmail.com; gaadio at post.bgu.ac.il
phone: (+972) 08-659-6854

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Fri Dec 20 15:11:31 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 20 Dec 2019 09:11:31 -0500
Subject: [R-sig-ME] mixed lognormal hurdle model with multiple grouping
 factors
In-Reply-To: <AM6PR0402MB3333D1F0EEBE20FAE1A0EEE5E82D0@AM6PR0402MB3333.eurprd04.prod.outlook.com>
References: <CAENiVe83vHUUv6i87oEo=ZzeyD4KXstCpx7p=dSwEfWZrtTAsg@mail.gmail.com>
 <3b68fdf6-31d5-f27b-b3a8-200cd0b6a632@hum.leidenuniv.nl>
 <28255CBD-2A77-4E1B-A9A8-1FEC88CD10A9@gmail.com>
 <AM6PR0402MB3333D1F0EEBE20FAE1A0EEE5E82D0@AM6PR0402MB3333.eurprd04.prod.outlook.com>
Message-ID: <0f932de6-9977-4d38-b7f8-907d716ebb15@gmail.com>


  Good point.
  This might be manageable in MCMCglmm or brms (or JAGS) ...

On 2019-12-20 2:58 a.m., D. Rizopoulos wrote:
> For a hurdle model for repeated measurements data, the dichotomous outcome I(diversity > 0) is also a repeated measurements outcome. Hence, in the logistic regression model for this dichotomous outcome you will need to include random effects to account for the correlations. And it is logical to assume that the random effects from this logistic regression model will be correlated with the random effects of the linear mixed model for only the positive responses.
> 
> In this case the likelihood of the two parts does not split in two functionally independent parts that can be separately maximized. If this is indeed the case, then fitting the two parts separately may cause bias and loss of efficiency.
> 
> Best,
> Dimitris
> 
> ??
> Dimitris Rizopoulos
> Professor of Biostatistics
> Erasmus University Medical Center
> The Netherlands
> 
> ________________________________
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Mollie Brooks <mollieebrooks at gmail.com>
> Sent: Wednesday, December 18, 2019 3:08 PM
> To: Help Mixed Models; Guillaume Adeux
> Subject: Re: [R-sig-ME] mixed lognormal hurdle model with multiple grouping factors
> 
> Hi Guillaume,
> 
> I don?t think the hurdle lognormal can be fit in a single function call to glmmTMB since the model for the non-zero response requires log-transforming the response. Other types of hurdle models could be fit in glmmTMB using the zero-inflation model.
> 
> I don?t think you gain much information in hurdle models by modeling the two parts (zeros and non-zeros) in one function call. The only potential benefit to fitting a hurdle in a single function call is that you get likelihood and AIC for the entire data set, but I don?t know if those are produced by brms.
> 
> You could just fit a binomial model for the zero-non-zero process (i.e. monoculture) like
> mod_binom=lmer((diversity>0)~block+syst+(1|plot)+(1|year)+(1|plot:year), data=density, family=binomial)
> 
> and then fit a model to the log of the positive data
> mod_gaus=lmer(log(diversity)~block+syst+(1|plot)+(1|year)+(1|plot:year), data=subset(density, diversity>0))
> 
> Or, given that the outcome is non-negative and continuous, it might make sense to try a Tweedie distribution, but I?m not sure I?ve seen this applied to diversity indices in the literature. Has anyone else seen this done?
> mod_twe = glmmTMB(diversity~block+syst+(1|plot)+(1|year)+(1|plot:year), data=density, family=tweedie)
> 
> Cheers,
> Mollie
> 
>> On 18Dec 2019, at 14:45, Cesko Voeten <c.c.voeten at hum.leidenuniv.nl> wrote:
>>
>> Hi Guillaume,
>>
>> If you're not afraid to go Bayesian, brms can do it. Alternatively, you may be able to use glmmTMB and treat the hurdle part as zero inflation, but this is conceptually not the same thing as a hurdle model so you would need to judge whether that would make sense at all for your application.
>>
>> HTH,
>> Cesko
>>
>> Op 18-12-2019 om 13:48 schreef Guillaume Adeux:
>>> Hi everyone,
>>> I am looking for a package which can handle "hurdle.lognormal" distribution
>>> family and multiple grouping factors.
>>> GLMMadaptive seemed as the way to go but unfortunately, to the best of my
>>> knowledge, it does not handle multiple grouping factors (random effects).
>>> You may ask why? I am analyzing plant diversity and one of the treatments
>>> led to plots which were dominated by one species. Hence, certain diversity
>>> indices are estimated as zero in these plots, and produces a mass at zero.
>>> All other values are positive and continuous.
>>> Anyone have an idea of a package/function which can handle this? Or any
>>> alternative approach?
>>> In lmer syntax, the model is the following:
>>> mod=lmer(diversity~block+syst+(1|plot)+(1|year)+(1|plot:year),data=density,REML=F)
>>> Thank you for your time and help.
>>> Sincerely,
>>> Guillaume ADEUX
>>> [[alternative HTML version deleted]]
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C0f8f22d15f244f0190f208d783c3ca4b%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C637122749245106064&amp;sdata=XWAMTSylM6j81Lf%2BLb8qikDEho3QIo8l%2Bh%2BnxSpwjHM%3D&amp;reserved=0
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C0f8f22d15f244f0190f208d783c3ca4b%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C637122749245106064&amp;sdata=XWAMTSylM6j81Lf%2BLb8qikDEho3QIo8l%2Bh%2BnxSpwjHM%3D&amp;reserved=0
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C0f8f22d15f244f0190f208d783c3ca4b%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C637122749245106064&amp;sdata=XWAMTSylM6j81Lf%2BLb8qikDEho3QIo8l%2Bh%2BnxSpwjHM%3D&amp;reserved=0
> 
> 	[[alternative HTML version deleted]]
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From gu|||@ume@|mon@@2 @end|ng |rom gm@||@com  Fri Dec 20 15:31:07 2019
From: gu|||@ume@|mon@@2 @end|ng |rom gm@||@com (Guillaume Adeux)
Date: Fri, 20 Dec 2019 15:31:07 +0100
Subject: [R-sig-ME] mixed lognormal hurdle model with multiple grouping
 factors
In-Reply-To: <0f932de6-9977-4d38-b7f8-907d716ebb15@gmail.com>
References: <CAENiVe83vHUUv6i87oEo=ZzeyD4KXstCpx7p=dSwEfWZrtTAsg@mail.gmail.com>
 <3b68fdf6-31d5-f27b-b3a8-200cd0b6a632@hum.leidenuniv.nl>
 <28255CBD-2A77-4E1B-A9A8-1FEC88CD10A9@gmail.com>
 <AM6PR0402MB3333D1F0EEBE20FAE1A0EEE5E82D0@AM6PR0402MB3333.eurprd04.prod.outlook.com>
 <0f932de6-9977-4d38-b7f8-907d716ebb15@gmail.com>
Message-ID: <CAENiVe9F8zWzXbRWmRWBi7Tjb=hMkYxVFdDLyr4XXDQu+M+BUQ@mail.gmail.com>

Yes, for now, the most seducing solution has been the following (with the
brms package):

fit=brm(bf(H_q~block+syst+(1|plot)+(1|year)+(1|plot:year),hu~block+syst+(1|plot)+(1|year)+(1|plot:year)),data=density,family=hurdle_lognormal(),control
= list(adapt_delta = 0.999))

 Family: hurdle_lognormal
  Links: mu = identity; sigma = identity; hu = logit
Formula: H_q ~ block + syst + (1 | plot) + (1 | year) + (1 | plot:year)
         hu ~ block + syst + (1 | plot) + (1 | year) + (1 | plot:year)
   Data: density (Number of observations: 480)
Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup samples = 4000

Group-Level Effects:
~plot (Number of levels: 10)
                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sd(Intercept)        0.12      0.11     0.01     0.41 1.00      852      912
sd(hu_Intercept)     1.21      1.01     0.05     3.86 1.01      637     1011

~plot:year (Number of levels: 60)
                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sd(Intercept)        0.13      0.06     0.01     0.23 1.00      737      546
sd(hu_Intercept)     2.10      0.46     1.34     3.15 1.00     1427     2435

~year (Number of levels: 6)
                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sd(Intercept)        0.06      0.07     0.00     0.21 1.00     1497     1843
sd(hu_Intercept)     0.83      0.71     0.03     2.55 1.01      935     1469

Population-Level Effects:
             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept       -0.23      0.07    -0.38    -0.08 1.00     2159     1513
hu_Intercept    -1.04      0.66    -2.26     0.43 1.00     1832     2061
block1          -0.06      0.06    -0.17     0.07 1.00     2394     1933
syst1           -0.32      0.17    -0.64     0.03 1.00     1930     1487
syst2           -0.11      0.12    -0.35     0.13 1.00     2023     1617
syst3            0.18      0.11    -0.06     0.41 1.00     1724     1267
syst4            0.08      0.12    -0.16     0.32 1.00     2222     1691
hu_block1        0.36      0.60    -0.81     1.63 1.00     1658     1684
hu_syst1         4.19      1.34     1.61     6.91 1.00     1236     1233
hu_syst2        -0.09      1.17    -2.40     2.38 1.00     1266     1419
hu_syst3        -1.98      1.30    -4.59     0.54 1.01     1183     1235
hu_syst4        -0.52      1.23    -2.95     1.88 1.00     1170     1108

Family Specific Parameters:
      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sigma     0.48      0.02     0.44     0.52 1.00     2632     3025

Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample
is a crude measure of effective sample size, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).


I am currently struggling to obtain "syst" means averaged over blocks (i.e.
what would be done traditionally with emmeans(fit,~syst)) and to compare
them pairwise.

As of now, I am only capable of retrieving a mean for each combination of
"syst" and "block" :

newdata =
expand.grid(syst=levels(density$syst),block=levels(density$block))
means=fitted(fit,newdata,re_formula=NA,summary=TRUE)
colnames(means)=c("fit","se","lwr","upr")
df_plot=cbind(newdata,means)

I am sure this must be simple, particularly with the hypothesis() function
but I am not sure how to include the "zero-non zero part" (i.e. hu_...).

If anyone can foward some information on this, I would be eternally
grateful (or even more should I say).

Sincerely,

Guillaume ADEUX



Le ven. 20 d?c. 2019 ? 15:12, Ben Bolker <bbolker at gmail.com> a ?crit :

>
>   Good point.
>   This might be manageable in MCMCglmm or brms (or JAGS) ...
>
> On 2019-12-20 2:58 a.m., D. Rizopoulos wrote:
> > For a hurdle model for repeated measurements data, the dichotomous
> outcome I(diversity > 0) is also a repeated measurements outcome. Hence, in
> the logistic regression model for this dichotomous outcome you will need to
> include random effects to account for the correlations. And it is logical
> to assume that the random effects from this logistic regression model will
> be correlated with the random effects of the linear mixed model for only
> the positive responses.
> >
> > In this case the likelihood of the two parts does not split in two
> functionally independent parts that can be separately maximized. If this is
> indeed the case, then fitting the two parts separately may cause bias and
> loss of efficiency.
> >
> > Best,
> > Dimitris
> >
> > ??
> > Dimitris Rizopoulos
> > Professor of Biostatistics
> > Erasmus University Medical Center
> > The Netherlands
> >
> > ________________________________
> > From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on
> behalf of Mollie Brooks <mollieebrooks at gmail.com>
> > Sent: Wednesday, December 18, 2019 3:08 PM
> > To: Help Mixed Models; Guillaume Adeux
> > Subject: Re: [R-sig-ME] mixed lognormal hurdle model with multiple
> grouping factors
> >
> > Hi Guillaume,
> >
> > I don?t think the hurdle lognormal can be fit in a single function call
> to glmmTMB since the model for the non-zero response requires
> log-transforming the response. Other types of hurdle models could be fit in
> glmmTMB using the zero-inflation model.
> >
> > I don?t think you gain much information in hurdle models by modeling the
> two parts (zeros and non-zeros) in one function call. The only potential
> benefit to fitting a hurdle in a single function call is that you get
> likelihood and AIC for the entire data set, but I don?t know if those are
> produced by brms.
> >
> > You could just fit a binomial model for the zero-non-zero process (i.e.
> monoculture) like
> > mod_binom=lmer((diversity>0)~block+syst+(1|plot)+(1|year)+(1|plot:year),
> data=density, family=binomial)
> >
> > and then fit a model to the log of the positive data
> > mod_gaus=lmer(log(diversity)~block+syst+(1|plot)+(1|year)+(1|plot:year),
> data=subset(density, diversity>0))
> >
> > Or, given that the outcome is non-negative and continuous, it might make
> sense to try a Tweedie distribution, but I?m not sure I?ve seen this
> applied to diversity indices in the literature. Has anyone else seen this
> done?
> > mod_twe = glmmTMB(diversity~block+syst+(1|plot)+(1|year)+(1|plot:year),
> data=density, family=tweedie)
> >
> > Cheers,
> > Mollie
> >
> >> On 18Dec 2019, at 14:45, Cesko Voeten <c.c.voeten at hum.leidenuniv.nl>
> wrote:
> >>
> >> Hi Guillaume,
> >>
> >> If you're not afraid to go Bayesian, brms can do it. Alternatively, you
> may be able to use glmmTMB and treat the hurdle part as zero inflation, but
> this is conceptually not the same thing as a hurdle model so you would need
> to judge whether that would make sense at all for your application.
> >>
> >> HTH,
> >> Cesko
> >>
> >> Op 18-12-2019 om 13:48 schreef Guillaume Adeux:
> >>> Hi everyone,
> >>> I am looking for a package which can handle "hurdle.lognormal"
> distribution
> >>> family and multiple grouping factors.
> >>> GLMMadaptive seemed as the way to go but unfortunately, to the best of
> my
> >>> knowledge, it does not handle multiple grouping factors (random
> effects).
> >>> You may ask why? I am analyzing plant diversity and one of the
> treatments
> >>> led to plots which were dominated by one species. Hence, certain
> diversity
> >>> indices are estimated as zero in these plots, and produces a mass at
> zero.
> >>> All other values are positive and continuous.
> >>> Anyone have an idea of a package/function which can handle this? Or any
> >>> alternative approach?
> >>> In lmer syntax, the model is the following:
> >>>
> mod=lmer(diversity~block+syst+(1|plot)+(1|year)+(1|plot:year),data=density,REML=F)
> >>> Thank you for your time and help.
> >>> Sincerely,
> >>> Guillaume ADEUX
> >>> [[alternative HTML version deleted]]
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>>
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C0f8f22d15f244f0190f208d783c3ca4b%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C637122749245106064&amp;sdata=XWAMTSylM6j81Lf%2BLb8qikDEho3QIo8l%2Bh%2BnxSpwjHM%3D&amp;reserved=0
> >>>
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >>
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C0f8f22d15f244f0190f208d783c3ca4b%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C637122749245106064&amp;sdata=XWAMTSylM6j81Lf%2BLb8qikDEho3QIo8l%2Bh%2BnxSpwjHM%3D&amp;reserved=0
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> >
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C0f8f22d15f244f0190f208d783c3ca4b%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C637122749245106064&amp;sdata=XWAMTSylM6j81Lf%2BLb8qikDEho3QIo8l%2Bh%2BnxSpwjHM%3D&amp;reserved=0
> >
> >       [[alternative HTML version deleted]]
> >
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From ph||||p@@|d@y @end|ng |rom mp|@n|  Mon Dec 23 13:47:28 2019
From: ph||||p@@|d@y @end|ng |rom mp|@n| (Phillip Alday)
Date: Mon, 23 Dec 2019 13:47:28 +0100
Subject: [R-sig-ME] 
 Question regarding random factor accounting for scores
 scaled by grade
In-Reply-To: <E9302445-7461-47D4-B223-B4D25172C154@UCSD.edu>
References: <E9302445-7461-47D4-B223-B4D25172C154@UCSD.edu>
Message-ID: <eec2a723-bb7a-ef41-069d-b08213ef69b8@mpi.nl>

Hi,

I wouldn't treat grade as a blocking/grouping variable here, because it 
doing so doesn't reflect the systematic differences between grades. 
Grades aren't just random offsets from some ideal mean value and you 
don't want to make statements about some abstract set of grades for 
which you've only observed a few concrete realizations. Instead, you 
want to make statements about the grades you've observed and which show 
a systematic structure. On the numerical end of things, six levels is 
right on the lower edge of what you need to be able to estimate random 
effects.

When moving grades into the fixed effects, you then have a choice. You 
can treat grade as a numerical, linear effect, but I suspect linearity 
is a rather strong assumption here. You could also try using a smoother 
or a polynomial fit. What you could do instead is treat grade as a 
categorical fixed effect. Using sequential difference coding (e.g. with 
MASS::contr.sdif), you would even get the individual estimates for each 
step increase in grade level.

It sounds like the SBAC score is scaled by grade level, i.e. that the 
raw score is converted to an abstract scale that is a statement relative 
to a given grade level. If this is the case, then the statements your 
model makes will be statements about change relative to the grade level 
and not about absolute changes in test score, even without having grade 
as a predictor in the model. I would still keep grade in the model, 
however, because it gives you some indication about whether students are 
able to improve beyond the scaling inherent in SBAC. For example, do 
students who start off behind relative to their current grade level fall 
further behind with each grade advancement or are they able to catch up?

I see you have school as a fixed effect. Unless you have a very small 
number of schools or only interested in making statements about the 
particular schools you observed, I would consider treating schools as a 
blocking variable.

Best,
Phillip

On 23/10/19 6:33 am, Ades, James wrote:
> Hi all:
> 
> I?m looking at SBAC standardized test scores (math in one model and English in the other) for middle schoolers (as the dependent variable) and then executive function task scores and demographic factors as explanatory variables.
> 
> So in a simple model looking at the relationship between a stroop task and the SBAC math variable I?d have the model:
> 
> model <- lmer(math.score ~ School + Ethnicity + Language.Fluency*attendance + Parent.Ed.Lvl +SpEd + t4.minus + eff.rt.stroop + (t4.minus|pid) + (1|grade) + (1|Teacher), data = ace, na.action = 'na.exclude', control = lmerControl(optimizer = "nloptwrap", calc.derivs = FALSE), REML = FALSE)
> 
> where t4.minus is the time in between timepoints (there were four, and they varied from participant to participant), pid is the participant, and eff.rt.stroop is the efficiency stroop score.
> 
> Since there are four timepoints over two years, there are ultimately six grades: 3rd graders who then become 4th graders,  fifth graders who then become sixth graders, and seventh graders who then become eighth graders.
> 
> My question is whether this random factor of grade would not only account for natural variance between grades (with the random intercept) but would also, in a principled and valid way, account for the fact that SBAC score falls on a continuous scale (between 2000-3000) that increases with each grade, such that an equivalent score of 2381 in 3rd grade would be 2411 in 4th grade. Explained (better?) here: http://www.smarterbalanced.org/assessments/scores/.
> 
> Thanks much,
> 
> James
> 
> 
> Have uploaded 10 rows here: https://drive.google.com/open?id=17FJjeln3Ipg0-uq0wQL9tWkJRnHTqdt6
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From ph||||p@@|d@y @end|ng |rom mp|@n|  Mon Dec 23 14:24:03 2019
From: ph||||p@@|d@y @end|ng |rom mp|@n| (Phillip Alday)
Date: Mon, 23 Dec 2019 14:24:03 +0100
Subject: [R-sig-ME] dummy variables in hlm
In-Reply-To: <CADRwXOJJyz76iTP_pY_ZLQDF4oZ+EXBYY_qMB31vVmA2=-UQ3g@mail.gmail.com>
References: <CADRwXOJJyz76iTP_pY_ZLQDF4oZ+EXBYY_qMB31vVmA2=-UQ3g@mail.gmail.com>
Message-ID: <c9edb606-9e52-2bd9-dab7-c181ed0fe0d0@mpi.nl>

This is a question which applies equally well to classical / non 
hierarchical models, so you can also use resources for those. That said, 
I'll answer here anyway.

The answer is "maybe", for a few reasons.

First, we often don't need to / bother worrying about multiple 
comparisons within a single regression model (Gelman, Hill and Yajima 
2012; 
http://www.stat.columbia.edu/~gelman/research/published/multiple2f.pdf). 
That said, for large models, especially those with lots of interactions, 
multiple comparisons issues can become a problem, see e.g. this blog 
post 
https://deevybee.blogspot.com/2013/06/interpreting-unexpected-significant.html 
, which is presented with ANOVA, but which holds for multiple regression.

Speaking of ANOVA ... the dummy variables don't all test the null 
hypothesis of the categorical variable per se, but instead test the null 
hypothesis for a single contrast derived from that categorical variable. 
If you want an omnibus test for your categorical variable, then you need 
to do something like ANOVA / analysis of deviance or a likelihood-ratio 
test. Since these yield a single test across all levels of the 
categorical variable, they don't have the multiple comparisons problem.

In all cases, note that your choice of contrast coding has a big impact 
on the hypotheses that you're testing and whether or not things 
car::Anova() yield meaningful results.

Phillip

PS: I would recommend avoiding the Level 1 / Level 2 terminology. For 
many R packages, you don't need a strict nesting of levels and so the 
Level # terminology doesn't make much sense. I also generally find it 
quite confusing. Instead, try talking about fixed/population-level 
effects and random effects / variance components.

On 7/12/19 7:22 pm, Shoeayb Qasemi wrote:
>   Dear Prof. Bob,
> 
> I have run an HLM model that contains an independent categorical variable
> (5 categories) at level 2. Four dummy variables entered into the model to
> represent the categorical variable. Since the dummy variables all test the
> null hypothesis of the categorical variable, do I need to adjust P-values
> to control the type-I error rate?
> 
> Best,
> Shoeayb
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From ph||||p@@|d@y @end|ng |rom mp|@n|  Mon Dec 23 15:20:16 2019
From: ph||||p@@|d@y @end|ng |rom mp|@n| (Phillip Alday)
Date: Mon, 23 Dec 2019 15:20:16 +0100
Subject: [R-sig-ME] Is there a way to deal with errors such as this?
In-Reply-To: <7742a7a6-672c-16be-18ae-13b44a168542@auckland.ac.nz>
References: <5d8a95d7-1310-cec0-8397-054a470dc7e2@auckland.ac.nz>
 <000401d5b331$56d13be0$0473b3a0$@uke.de>
 <c5289090-f17c-c6f9-76f2-bc78e011fc78@auckland.ac.nz>
 <AM6PR0402MB333313B9252D5B1FD9827949E8560@AM6PR0402MB3333.eurprd04.prod.outlook.com>
 <1cb03000-c6b7-a226-9d84-8826eb09852d@auckland.ac.nz>
 <D14049CE02C4F54D95360EEC06CE45C50FB4891A@SPMXM08.VUW.leidenuniv.nl>
 <7742a7a6-672c-16be-18ae-13b44a168542@auckland.ac.nz>
Message-ID: <e02a5620-c912-a544-a749-943f54a6d37c@mpi.nl>

For completeness, you can also get use getME(model, "beta") to get the 
fixed effects estimates as a simple, unnamed vector. :)

On 17/12/19 4:40 am, Rolf Turner wrote:
> 
> 
> On 17/12/19 1:49 am, Voeten, C.C. wrote:
> 
>> Hi Rolf,
>>
>> 'theta' is the vector of random-effect parameters, obtained by
>> getME(model,'theta'). I'm sure someone more knowledgeable than I can
>> tell you their exact definition - I thought they are the entries of
>> the lower Cholesky factor of the random-effects design matrix scaled
>> by the model's residual error, but I may have gotten a few things
>> mixed up here. 'fixef' is indeed just fixef(model).
> 
> That's great.? Thanks hugely.? The "getME(model,'theta')" bit was what I 
> really needed to know (and no clue how to find).
> 
> Thanks again.
> 
> cheers,
> 
> Rolf
>


From 18754808835 @end|ng |rom 163@com  Fri Dec 20 15:37:34 2019
From: 18754808835 @end|ng |rom 163@com (=?GBK?B?us7I58PO?=)
Date: Fri, 20 Dec 2019 22:37:34 +0800 (CST)
Subject: [R-sig-ME] A consultation about lmer
Message-ID: <11cee80.1101f.16f23be0872.Coremail.18754808835@163.com>

 I have some confusion about the use of lmer. As I learned the data should  be normal distributed when use liner mixed model. I tested the exmple  data (Reaction$sleepstudy) by using shapiro.test. The result shows that  it was not normal distributed.  So I have some confusion about the requirment of data distribution in function lmer and glmmer.
	[[alternative HTML version deleted]]


From |mw@ng @end|ng |rom gm@||@com  Mon Dec 23 19:11:58 2019
From: |mw@ng @end|ng |rom gm@||@com (Liming Wang)
Date: Mon, 23 Dec 2019 10:11:58 -0800
Subject: [R-sig-ME] mixed lognormal hurdle model with multiple grouping
 factors
In-Reply-To: <CAENiVe9F8zWzXbRWmRWBi7Tjb=hMkYxVFdDLyr4XXDQu+M+BUQ@mail.gmail.com>
References: <CAENiVe83vHUUv6i87oEo=ZzeyD4KXstCpx7p=dSwEfWZrtTAsg@mail.gmail.com>
 <3b68fdf6-31d5-f27b-b3a8-200cd0b6a632@hum.leidenuniv.nl>
 <28255CBD-2A77-4E1B-A9A8-1FEC88CD10A9@gmail.com>
 <AM6PR0402MB3333D1F0EEBE20FAE1A0EEE5E82D0@AM6PR0402MB3333.eurprd04.prod.outlook.com>
 <0f932de6-9977-4d38-b7f8-907d716ebb15@gmail.com>
 <CAENiVe9F8zWzXbRWmRWBi7Tjb=hMkYxVFdDLyr4XXDQu+M+BUQ@mail.gmail.com>
Message-ID: <CAOFWXwy+dOF+BcEpEYCNPHAjgSvJ65B7xqbU=Kxo0SHraEzqXw@mail.gmail.com>

Hi Guillaume,

The mixed_model in the GLMMadaptive package supports Two-Part Mixed Effects
Model for Semi-Continuous Data (
https://drizopoulos.github.io/GLMMadaptive/articles/ZeroInflated_and_TwoPart_Models.html#zero-inflated-negative-binomial-mixed-effects-model).
It doesn't seem to support mixed effect for the zero outcome component
though. Another downside is that, since it is written in pure R, it is much
slower than glmmTMB (for similar models).

Liming

On Fri, Dec 20, 2019 at 6:31 AM Guillaume Adeux <guillaumesimon.a2 at gmail.com>
wrote:

> Yes, for now, the most seducing solution has been the following (with the
> brms package):
>
>
> fit=brm(bf(H_q~block+syst+(1|plot)+(1|year)+(1|plot:year),hu~block+syst+(1|plot)+(1|year)+(1|plot:year)),data=density,family=hurdle_lognormal(),control
> = list(adapt_delta = 0.999))
>
>  Family: hurdle_lognormal
>   Links: mu = identity; sigma = identity; hu = logit
> Formula: H_q ~ block + syst + (1 | plot) + (1 | year) + (1 | plot:year)
>          hu ~ block + syst + (1 | plot) + (1 | year) + (1 | plot:year)
>    Data: density (Number of observations: 480)
> Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
>          total post-warmup samples = 4000
>
> Group-Level Effects:
> ~plot (Number of levels: 10)
>                  Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
> Tail_ESS
> sd(Intercept)        0.12      0.11     0.01     0.41 1.00      852
> 912
> sd(hu_Intercept)     1.21      1.01     0.05     3.86 1.01      637
>  1011
>
> ~plot:year (Number of levels: 60)
>                  Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
> Tail_ESS
> sd(Intercept)        0.13      0.06     0.01     0.23 1.00      737
> 546
> sd(hu_Intercept)     2.10      0.46     1.34     3.15 1.00     1427
>  2435
>
> ~year (Number of levels: 6)
>                  Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
> Tail_ESS
> sd(Intercept)        0.06      0.07     0.00     0.21 1.00     1497
>  1843
> sd(hu_Intercept)     0.83      0.71     0.03     2.55 1.01      935
>  1469
>
> Population-Level Effects:
>              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
> Intercept       -0.23      0.07    -0.38    -0.08 1.00     2159     1513
> hu_Intercept    -1.04      0.66    -2.26     0.43 1.00     1832     2061
> block1          -0.06      0.06    -0.17     0.07 1.00     2394     1933
> syst1           -0.32      0.17    -0.64     0.03 1.00     1930     1487
> syst2           -0.11      0.12    -0.35     0.13 1.00     2023     1617
> syst3            0.18      0.11    -0.06     0.41 1.00     1724     1267
> syst4            0.08      0.12    -0.16     0.32 1.00     2222     1691
> hu_block1        0.36      0.60    -0.81     1.63 1.00     1658     1684
> hu_syst1         4.19      1.34     1.61     6.91 1.00     1236     1233
> hu_syst2        -0.09      1.17    -2.40     2.38 1.00     1266     1419
> hu_syst3        -1.98      1.30    -4.59     0.54 1.01     1183     1235
> hu_syst4        -0.52      1.23    -2.95     1.88 1.00     1170     1108
>
> Family Specific Parameters:
>       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
> sigma     0.48      0.02     0.44     0.52 1.00     2632     3025
>
> Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample
> is a crude measure of effective sample size, and Rhat is the potential
> scale reduction factor on split chains (at convergence, Rhat = 1).
>
>
> I am currently struggling to obtain "syst" means averaged over blocks (i.e.
> what would be done traditionally with emmeans(fit,~syst)) and to compare
> them pairwise.
>
> As of now, I am only capable of retrieving a mean for each combination of
> "syst" and "block" :
>
> newdata =
> expand.grid(syst=levels(density$syst),block=levels(density$block))
> means=fitted(fit,newdata,re_formula=NA,summary=TRUE)
> colnames(means)=c("fit","se","lwr","upr")
> df_plot=cbind(newdata,means)
>
> I am sure this must be simple, particularly with the hypothesis() function
> but I am not sure how to include the "zero-non zero part" (i.e. hu_...).
>
> If anyone can foward some information on this, I would be eternally
> grateful (or even more should I say).
>
> Sincerely,
>
> Guillaume ADEUX
>
>
>
> Le ven. 20 d?c. 2019 ? 15:12, Ben Bolker <bbolker at gmail.com> a ?crit :
>
> >
> >   Good point.
> >   This might be manageable in MCMCglmm or brms (or JAGS) ...
> >
> > On 2019-12-20 2:58 a.m., D. Rizopoulos wrote:
> > > For a hurdle model for repeated measurements data, the dichotomous
> > outcome I(diversity > 0) is also a repeated measurements outcome. Hence,
> in
> > the logistic regression model for this dichotomous outcome you will need
> to
> > include random effects to account for the correlations. And it is logical
> > to assume that the random effects from this logistic regression model
> will
> > be correlated with the random effects of the linear mixed model for only
> > the positive responses.
> > >
> > > In this case the likelihood of the two parts does not split in two
> > functionally independent parts that can be separately maximized. If this
> is
> > indeed the case, then fitting the two parts separately may cause bias and
> > loss of efficiency.
> > >
> > > Best,
> > > Dimitris
> > >
> > > ??
> > > Dimitris Rizopoulos
> > > Professor of Biostatistics
> > > Erasmus University Medical Center
> > > The Netherlands
> > >
> > > ________________________________
> > > From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on
> > behalf of Mollie Brooks <mollieebrooks at gmail.com>
> > > Sent: Wednesday, December 18, 2019 3:08 PM
> > > To: Help Mixed Models; Guillaume Adeux
> > > Subject: Re: [R-sig-ME] mixed lognormal hurdle model with multiple
> > grouping factors
> > >
> > > Hi Guillaume,
> > >
> > > I don?t think the hurdle lognormal can be fit in a single function call
> > to glmmTMB since the model for the non-zero response requires
> > log-transforming the response. Other types of hurdle models could be fit
> in
> > glmmTMB using the zero-inflation model.
> > >
> > > I don?t think you gain much information in hurdle models by modeling
> the
> > two parts (zeros and non-zeros) in one function call. The only potential
> > benefit to fitting a hurdle in a single function call is that you get
> > likelihood and AIC for the entire data set, but I don?t know if those are
> > produced by brms.
> > >
> > > You could just fit a binomial model for the zero-non-zero process (i.e.
> > monoculture) like
> > >
> mod_binom=lmer((diversity>0)~block+syst+(1|plot)+(1|year)+(1|plot:year),
> > data=density, family=binomial)
> > >
> > > and then fit a model to the log of the positive data
> > >
> mod_gaus=lmer(log(diversity)~block+syst+(1|plot)+(1|year)+(1|plot:year),
> > data=subset(density, diversity>0))
> > >
> > > Or, given that the outcome is non-negative and continuous, it might
> make
> > sense to try a Tweedie distribution, but I?m not sure I?ve seen this
> > applied to diversity indices in the literature. Has anyone else seen this
> > done?
> > > mod_twe = glmmTMB(diversity~block+syst+(1|plot)+(1|year)+(1|plot:year),
> > data=density, family=tweedie)
> > >
> > > Cheers,
> > > Mollie
> > >
> > >> On 18Dec 2019, at 14:45, Cesko Voeten <c.c.voeten at hum.leidenuniv.nl>
> > wrote:
> > >>
> > >> Hi Guillaume,
> > >>
> > >> If you're not afraid to go Bayesian, brms can do it. Alternatively,
> you
> > may be able to use glmmTMB and treat the hurdle part as zero inflation,
> but
> > this is conceptually not the same thing as a hurdle model so you would
> need
> > to judge whether that would make sense at all for your application.
> > >>
> > >> HTH,
> > >> Cesko
> > >>
> > >> Op 18-12-2019 om 13:48 schreef Guillaume Adeux:
> > >>> Hi everyone,
> > >>> I am looking for a package which can handle "hurdle.lognormal"
> > distribution
> > >>> family and multiple grouping factors.
> > >>> GLMMadaptive seemed as the way to go but unfortunately, to the best
> of
> > my
> > >>> knowledge, it does not handle multiple grouping factors (random
> > effects).
> > >>> You may ask why? I am analyzing plant diversity and one of the
> > treatments
> > >>> led to plots which were dominated by one species. Hence, certain
> > diversity
> > >>> indices are estimated as zero in these plots, and produces a mass at
> > zero.
> > >>> All other values are positive and continuous.
> > >>> Anyone have an idea of a package/function which can handle this? Or
> any
> > >>> alternative approach?
> > >>> In lmer syntax, the model is the following:
> > >>>
> >
> mod=lmer(diversity~block+syst+(1|plot)+(1|year)+(1|plot:year),data=density,REML=F)
> > >>> Thank you for your time and help.
> > >>> Sincerely,
> > >>> Guillaume ADEUX
> > >>> [[alternative HTML version deleted]]
> > >>> _______________________________________________
> > >>> R-sig-mixed-models at r-project.org mailing list
> > >>>
> >
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C0f8f22d15f244f0190f208d783c3ca4b%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C637122749245106064&amp;sdata=XWAMTSylM6j81Lf%2BLb8qikDEho3QIo8l%2Bh%2BnxSpwjHM%3D&amp;reserved=0
> > >>>
> > >>
> > >> _______________________________________________
> > >> R-sig-mixed-models at r-project.org mailing list
> > >>
> >
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C0f8f22d15f244f0190f208d783c3ca4b%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C637122749245106064&amp;sdata=XWAMTSylM6j81Lf%2BLb8qikDEho3QIo8l%2Bh%2BnxSpwjHM%3D&amp;reserved=0
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > >
> >
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C0f8f22d15f244f0190f208d783c3ca4b%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C637122749245106064&amp;sdata=XWAMTSylM6j81Lf%2BLb8qikDEho3QIo8l%2Bh%2BnxSpwjHM%3D&amp;reserved=0
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From d@r|zopou|o@ @end|ng |rom er@@mu@mc@n|  Mon Dec 23 19:47:47 2019
From: d@r|zopou|o@ @end|ng |rom er@@mu@mc@n| (D. Rizopoulos)
Date: Mon, 23 Dec 2019 18:47:47 +0000
Subject: [R-sig-ME] mixed lognormal hurdle model with multiple grouping
 factors
In-Reply-To: <CAOFWXwy+dOF+BcEpEYCNPHAjgSvJ65B7xqbU=Kxo0SHraEzqXw@mail.gmail.com>
References: <CAENiVe83vHUUv6i87oEo=ZzeyD4KXstCpx7p=dSwEfWZrtTAsg@mail.gmail.com>
 <3b68fdf6-31d5-f27b-b3a8-200cd0b6a632@hum.leidenuniv.nl>
 <28255CBD-2A77-4E1B-A9A8-1FEC88CD10A9@gmail.com>
 <AM6PR0402MB3333D1F0EEBE20FAE1A0EEE5E82D0@AM6PR0402MB3333.eurprd04.prod.outlook.com>
 <0f932de6-9977-4d38-b7f8-907d716ebb15@gmail.com>
 <CAENiVe9F8zWzXbRWmRWBi7Tjb=hMkYxVFdDLyr4XXDQu+M+BUQ@mail.gmail.com>,
 <CAOFWXwy+dOF+BcEpEYCNPHAjgSvJ65B7xqbU=Kxo0SHraEzqXw@mail.gmail.com>
Message-ID: <AM6PR0402MB3333F79554424B1C2A230DC8E82E0@AM6PR0402MB3333.eurprd04.prod.outlook.com>

GLMMadaptive does support random effects for the zero part model.

The reason why GLMMadaptive is slower is because it implements the adaptive Gaussian quadrature for approximating the log-likelihood. This approximation is in general considered more accurate (but slower) than the Laplace approximation implemented in glmmTMB.

Best,
Dimitris

?-
Dimitris Rizopoulos
Professor of Biostatistics
Erasmus University Medical Center
The Netherlands

________________________________
???: ? ??????? R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> ?? ?????? ??? ?????? Liming Wang <lmwang at gmail.com>
????????: ???????, ?????????? 23, 2019 19:12
????: Guillaume Adeux
????.: R-mixed models mailing list
????: Re: [R-sig-ME] mixed lognormal hurdle model with multiple grouping factors

Hi Guillaume,

The mixed_model in the GLMMadaptive package supports Two-Part Mixed Effects
Model for Semi-Continuous Data (
https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fdrizopoulos.github.io%2FGLMMadaptive%2Farticles%2FZeroInflated_and_TwoPart_Models.html%23zero-inflated-negative-binomial-mixed-effects-model&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C94c75233c5084fb99c6908d787d3adf4%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637127215536371685&amp;sdata=cDReHBDB%2FLuHfeM06tARqolihNCpVErMgCcMpyr6BYc%3D&amp;reserved=0).
It doesn't seem to support mixed effect for the zero outcome component
though. Another downside is that, since it is written in pure R, it is much
slower than glmmTMB (for similar models).

Liming

On Fri, Dec 20, 2019 at 6:31 AM Guillaume Adeux <guillaumesimon.a2 at gmail.com>
wrote:

> Yes, for now, the most seducing solution has been the following (with the
> brms package):
>
>
> fit=brm(bf(H_q~block+syst+(1|plot)+(1|year)+(1|plot:year),hu~block+syst+(1|plot)+(1|year)+(1|plot:year)),data=density,family=hurdle_lognormal(),control
> = list(adapt_delta = 0.999))
>
> Family: hurdle_lognormal
> Links: mu = identity; sigma = identity; hu = logit
> Formula: H_q ~ block + syst + (1 | plot) + (1 | year) + (1 | plot:year)
> hu ~ block + syst + (1 | plot) + (1 | year) + (1 | plot:year)
> Data: density (Number of observations: 480)
> Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
> total post-warmup samples = 4000
>
> Group-Level Effects:
> ~plot (Number of levels: 10)
> Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
> Tail_ESS
> sd(Intercept) 0.12 0.11 0.01 0.41 1.00 852
> 912
> sd(hu_Intercept) 1.21 1.01 0.05 3.86 1.01 637
> 1011
>
> ~plot:year (Number of levels: 60)
> Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
> Tail_ESS
> sd(Intercept) 0.13 0.06 0.01 0.23 1.00 737
> 546
> sd(hu_Intercept) 2.10 0.46 1.34 3.15 1.00 1427
> 2435
>
> ~year (Number of levels: 6)
> Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
> Tail_ESS
> sd(Intercept) 0.06 0.07 0.00 0.21 1.00 1497
> 1843
> sd(hu_Intercept) 0.83 0.71 0.03 2.55 1.01 935
> 1469
>
> Population-Level Effects:
> Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
> Intercept -0.23 0.07 -0.38 -0.08 1.00 2159 1513
> hu_Intercept -1.04 0.66 -2.26 0.43 1.00 1832 2061
> block1 -0.06 0.06 -0.17 0.07 1.00 2394 1933
> syst1 -0.32 0.17 -0.64 0.03 1.00 1930 1487
> syst2 -0.11 0.12 -0.35 0.13 1.00 2023 1617
> syst3 0.18 0.11 -0.06 0.41 1.00 1724 1267
> syst4 0.08 0.12 -0.16 0.32 1.00 2222 1691
> hu_block1 0.36 0.60 -0.81 1.63 1.00 1658 1684
> hu_syst1 4.19 1.34 1.61 6.91 1.00 1236 1233
> hu_syst2 -0.09 1.17 -2.40 2.38 1.00 1266 1419
> hu_syst3 -1.98 1.30 -4.59 0.54 1.01 1183 1235
> hu_syst4 -0.52 1.23 -2.95 1.88 1.00 1170 1108
>
> Family Specific Parameters:
> Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
> sigma 0.48 0.02 0.44 0.52 1.00 2632 3025
>
> Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample
> is a crude measure of effective sample size, and Rhat is the potential
> scale reduction factor on split chains (at convergence, Rhat = 1).
>
>
> I am currently struggling to obtain "syst" means averaged over blocks (i.e.
> what would be done traditionally with emmeans(fit,~syst)) and to compare
> them pairwise.
>
> As of now, I am only capable of retrieving a mean for each combination of
> "syst" and "block" :
>
> newdata =
> expand.grid(syst=levels(density$syst),block=levels(density$block))
> means=fitted(fit,newdata,re_formula=NA,summary=TRUE)
> colnames(means)=c("fit","se","lwr","upr")
> df_plot=cbind(newdata,means)
>
> I am sure this must be simple, particularly with the hypothesis() function
> but I am not sure how to include the "zero-non zero part" (i.e. hu_...).
>
> If anyone can foward some information on this, I would be eternally
> grateful (or even more should I say).
>
> Sincerely,
>
> Guillaume ADEUX
>
>
>
> Le ven. 20 d?c. 2019 ? 15:12, Ben Bolker <bbolker at gmail.com> a ?crit :
>
> >
> > Good point.
> > This might be manageable in MCMCglmm or brms (or JAGS) ...
> >
> > On 2019-12-20 2:58 a.m., D. Rizopoulos wrote:
> > > For a hurdle model for repeated measurements data, the dichotomous
> > outcome I(diversity > 0) is also a repeated measurements outcome. Hence,
> in
> > the logistic regression model for this dichotomous outcome you will need
> to
> > include random effects to account for the correlations. And it is logical
> > to assume that the random effects from this logistic regression model
> will
> > be correlated with the random effects of the linear mixed model for only
> > the positive responses.
> > >
> > > In this case the likelihood of the two parts does not split in two
> > functionally independent parts that can be separately maximized. If this
> is
> > indeed the case, then fitting the two parts separately may cause bias and
> > loss of efficiency.
> > >
> > > Best,
> > > Dimitris
> > >
> > > ??
> > > Dimitris Rizopoulos
> > > Professor of Biostatistics
> > > Erasmus University Medical Center
> > > The Netherlands
> > >
> > > ________________________________
> > > From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on
> > behalf of Mollie Brooks <mollieebrooks at gmail.com>
> > > Sent: Wednesday, December 18, 2019 3:08 PM
> > > To: Help Mixed Models; Guillaume Adeux
> > > Subject: Re: [R-sig-ME] mixed lognormal hurdle model with multiple
> > grouping factors
> > >
> > > Hi Guillaume,
> > >
> > > I don?t think the hurdle lognormal can be fit in a single function call
> > to glmmTMB since the model for the non-zero response requires
> > log-transforming the response. Other types of hurdle models could be fit
> in
> > glmmTMB using the zero-inflation model.
> > >
> > > I don?t think you gain much information in hurdle models by modeling
> the
> > two parts (zeros and non-zeros) in one function call. The only potential
> > benefit to fitting a hurdle in a single function call is that you get
> > likelihood and AIC for the entire data set, but I don?t know if those are
> > produced by brms.
> > >
> > > You could just fit a binomial model for the zero-non-zero process (i.e.
> > monoculture) like
> > >
> mod_binom=lmer((diversity>0)~block+syst+(1|plot)+(1|year)+(1|plot:year),
> > data=density, family=binomial)
> > >
> > > and then fit a model to the log of the positive data
> > >
> mod_gaus=lmer(log(diversity)~block+syst+(1|plot)+(1|year)+(1|plot:year),
> > data=subset(density, diversity>0))
> > >
> > > Or, given that the outcome is non-negative and continuous, it might
> make
> > sense to try a Tweedie distribution, but I?m not sure I?ve seen this
> > applied to diversity indices in the literature. Has anyone else seen this
> > done?
> > > mod_twe = glmmTMB(diversity~block+syst+(1|plot)+(1|year)+(1|plot:year),
> > data=density, family=tweedie)
> > >
> > > Cheers,
> > > Mollie
> > >
> > >> On 18Dec 2019, at 14:45, Cesko Voeten <c.c.voeten at hum.leidenuniv.nl>
> > wrote:
> > >>
> > >> Hi Guillaume,
> > >>
> > >> If you're not afraid to go Bayesian, brms can do it. Alternatively,
> you
> > may be able to use glmmTMB and treat the hurdle part as zero inflation,
> but
> > this is conceptually not the same thing as a hurdle model so you would
> need
> > to judge whether that would make sense at all for your application.
> > >>
> > >> HTH,
> > >> Cesko
> > >>
> > >> Op 18-12-2019 om 13:48 schreef Guillaume Adeux:
> > >>> Hi everyone,
> > >>> I am looking for a package which can handle "hurdle.lognormal"
> > distribution
> > >>> family and multiple grouping factors.
> > >>> GLMMadaptive seemed as the way to go but unfortunately, to the best
> of
> > my
> > >>> knowledge, it does not handle multiple grouping factors (random
> > effects).
> > >>> You may ask why? I am analyzing plant diversity and one of the
> > treatments
> > >>> led to plots which were dominated by one species. Hence, certain
> > diversity
> > >>> indices are estimated as zero in these plots, and produces a mass at
> > zero.
> > >>> All other values are positive and continuous.
> > >>> Anyone have an idea of a package/function which can handle this? Or
> any
> > >>> alternative approach?
> > >>> In lmer syntax, the model is the following:
> > >>>
> >
> mod=lmer(diversity~block+syst+(1|plot)+(1|year)+(1|plot:year),data=density,REML=F)
> > >>> Thank you for your time and help.
> > >>> Sincerely,
> > >>> Guillaume ADEUX
> > >>> [[alternative HTML version deleted]]
> > >>> _______________________________________________
> > >>> R-sig-mixed-models at r-project.org mailing list
> > >>>
> >
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C94c75233c5084fb99c6908d787d3adf4%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637127215536371685&amp;sdata=PL6VOZ8Q9M5DQa8xp%2FrKKe%2FqXO%2BzE5sfMP%2FvxZr2jHE%3D&amp;reserved=0
> > >>>
> > >>
> > >> _______________________________________________
> > >> R-sig-mixed-models at r-project.org mailing list
> > >>
> >
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C94c75233c5084fb99c6908d787d3adf4%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637127215536371685&amp;sdata=PL6VOZ8Q9M5DQa8xp%2FrKKe%2FqXO%2BzE5sfMP%2FvxZr2jHE%3D&amp;reserved=0
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > >
> >
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C94c75233c5084fb99c6908d787d3adf4%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637127215536381676&amp;sdata=YRc7r3Ni5P345YiPoEuNhmhmte20pMrIb3ojmkmY6qA%3D&amp;reserved=0
> > >
> > > [[alternative HTML version deleted]]
> > >
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C94c75233c5084fb99c6908d787d3adf4%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637127215536381676&amp;sdata=YRc7r3Ni5P345YiPoEuNhmhmte20pMrIb3ojmkmY6qA%3D&amp;reserved=0
> > >
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C94c75233c5084fb99c6908d787d3adf4%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637127215536381676&amp;sdata=YRc7r3Ni5P345YiPoEuNhmhmte20pMrIb3ojmkmY6qA%3D&amp;reserved=0
> >
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C94c75233c5084fb99c6908d787d3adf4%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637127215536381676&amp;sdata=YRc7r3Ni5P345YiPoEuNhmhmte20pMrIb3ojmkmY6qA%3D&amp;reserved=0
>

[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C94c75233c5084fb99c6908d787d3adf4%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637127215536381676&amp;sdata=YRc7r3Ni5P345YiPoEuNhmhmte20pMrIb3ojmkmY6qA%3D&amp;reserved=0

	[[alternative HTML version deleted]]


From |mw@ng @end|ng |rom gm@||@com  Mon Dec 23 20:05:30 2019
From: |mw@ng @end|ng |rom gm@||@com (Liming Wang)
Date: Mon, 23 Dec 2019 11:05:30 -0800
Subject: [R-sig-ME] mixed lognormal hurdle model with multiple grouping
 factors
In-Reply-To: <AM6PR0402MB3333F79554424B1C2A230DC8E82E0@AM6PR0402MB3333.eurprd04.prod.outlook.com>
References: <CAENiVe83vHUUv6i87oEo=ZzeyD4KXstCpx7p=dSwEfWZrtTAsg@mail.gmail.com>
 <3b68fdf6-31d5-f27b-b3a8-200cd0b6a632@hum.leidenuniv.nl>
 <28255CBD-2A77-4E1B-A9A8-1FEC88CD10A9@gmail.com>
 <AM6PR0402MB3333D1F0EEBE20FAE1A0EEE5E82D0@AM6PR0402MB3333.eurprd04.prod.outlook.com>
 <0f932de6-9977-4d38-b7f8-907d716ebb15@gmail.com>
 <CAENiVe9F8zWzXbRWmRWBi7Tjb=hMkYxVFdDLyr4XXDQu+M+BUQ@mail.gmail.com>
 <CAOFWXwy+dOF+BcEpEYCNPHAjgSvJ65B7xqbU=Kxo0SHraEzqXw@mail.gmail.com>
 <AM6PR0402MB3333F79554424B1C2A230DC8E82E0@AM6PR0402MB3333.eurprd04.prod.outlook.com>
Message-ID: <CAOFWXwztxRU8ZLurjC1KwNxJcR14edz2jyUc-08Xj=PpNNdqRw@mail.gmail.com>

Dimitris,

Thanks for the correction and clarification! I apparently didn't note
that Guillaume has ruled out GLMMAdaptive and I didn't recognize that you
are the author of GLMMAdaptive.

Best,

Liming

On Mon, Dec 23, 2019 at 10:47 AM D. Rizopoulos <d.rizopoulos at erasmusmc.nl>
wrote:

> GLMMadaptive does support random effects for the zero part model.
>
> The reason why GLMMadaptive is slower is because it implements the
> adaptive Gaussian quadrature for approximating the log-likelihood. This
> approximation is in general considered more accurate (but slower) than the
> Laplace approximation implemented in glmmTMB.
>
> Best,
> Dimitris
>
> ?-
> Dimitris Rizopoulos
> Professor of Biostatistics
> Erasmus University Medical Center
> The Netherlands
>
> ------------------------------
> *???:* ? ??????? R-sig-mixed-models <
> r-sig-mixed-models-bounces at r-project.org> ?? ?????? ??? ?????? Liming
> Wang <lmwang at gmail.com>
> *????????:* ???????, ?????????? 23, 2019 19:12
> *????:* Guillaume Adeux
> *????.:* R-mixed models mailing list
> *????:* Re: [R-sig-ME] mixed lognormal hurdle model with multiple
> grouping factors
>
> Hi Guillaume,
>
> The mixed_model in the GLMMadaptive package supports Two-Part Mixed
> Effects
> Model for Semi-Continuous Data (
>
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fdrizopoulos.github.io%2FGLMMadaptive%2Farticles%2FZeroInflated_and_TwoPart_Models.html%23zero-inflated-negative-binomial-mixed-effects-model&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C94c75233c5084fb99c6908d787d3adf4%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637127215536371685&amp;sdata=cDReHBDB%2FLuHfeM06tARqolihNCpVErMgCcMpyr6BYc%3D&amp;reserved=0).
>
> It doesn't seem to support mixed effect for the zero outcome component
> though. Another downside is that, since it is written in pure R, it is
> much
> slower than glmmTMB (for similar models).
>
> Liming
>
> On Fri, Dec 20, 2019 at 6:31 AM Guillaume Adeux <
> guillaumesimon.a2 at gmail.com>
> wrote:
>
> > Yes, for now, the most seducing solution has been the following (with
> the
> > brms package):
> >
> >
> >
> fit=brm(bf(H_q~block+syst+(1|plot)+(1|year)+(1|plot:year),hu~block+syst+(1|plot)+(1|year)+(1|plot:year)),data=density,family=hurdle_lognormal(),control
>
> > = list(adapt_delta = 0.999))
> >
> > Family: hurdle_lognormal
> > Links: mu = identity; sigma = identity; hu = logit
> > Formula: H_q ~ block + syst + (1 | plot) + (1 | year) + (1 | plot:year)
> > hu ~ block + syst + (1 | plot) + (1 | year) + (1 | plot:year)
> > Data: density (Number of observations: 480)
> > Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
> > total post-warmup samples = 4000
> >
> > Group-Level Effects:
> > ~plot (Number of levels: 10)
> > Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
> > Tail_ESS
> > sd(Intercept) 0.12 0.11 0.01 0.41 1.00 852
> > 912
> > sd(hu_Intercept) 1.21 1.01 0.05 3.86 1.01 637
> > 1011
> >
> > ~plot:year (Number of levels: 60)
> > Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
> > Tail_ESS
> > sd(Intercept) 0.13 0.06 0.01 0.23 1.00 737
> > 546
> > sd(hu_Intercept) 2.10 0.46 1.34 3.15 1.00 1427
> > 2435
> >
> > ~year (Number of levels: 6)
> > Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
> > Tail_ESS
> > sd(Intercept) 0.06 0.07 0.00 0.21 1.00 1497
> > 1843
> > sd(hu_Intercept) 0.83 0.71 0.03 2.55 1.01 935
> > 1469
> >
> > Population-Level Effects:
> > Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
> > Intercept -0.23 0.07 -0.38 -0.08 1.00 2159 1513
> > hu_Intercept -1.04 0.66 -2.26 0.43 1.00 1832 2061
> > block1 -0.06 0.06 -0.17 0.07 1.00 2394 1933
> > syst1 -0.32 0.17 -0.64 0.03 1.00 1930 1487
> > syst2 -0.11 0.12 -0.35 0.13 1.00 2023 1617
> > syst3 0.18 0.11 -0.06 0.41 1.00 1724 1267
> > syst4 0.08 0.12 -0.16 0.32 1.00 2222 1691
> > hu_block1 0.36 0.60 -0.81 1.63 1.00 1658 1684
> > hu_syst1 4.19 1.34 1.61 6.91 1.00 1236 1233
> > hu_syst2 -0.09 1.17 -2.40 2.38 1.00 1266 1419
> > hu_syst3 -1.98 1.30 -4.59 0.54 1.01 1183 1235
> > hu_syst4 -0.52 1.23 -2.95 1.88 1.00 1170 1108
> >
> > Family Specific Parameters:
> > Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
> > sigma 0.48 0.02 0.44 0.52 1.00 2632 3025
> >
> > Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample
> > is a crude measure of effective sample size, and Rhat is the potential
> > scale reduction factor on split chains (at convergence, Rhat = 1).
> >
> >
> > I am currently struggling to obtain "syst" means averaged over blocks
> (i.e.
> > what would be done traditionally with emmeans(fit,~syst)) and to compare
> > them pairwise.
> >
> > As of now, I am only capable of retrieving a mean for each combination
> of
> > "syst" and "block" :
> >
> > newdata =
> > expand.grid(syst=levels(density$syst),block=levels(density$block))
> > means=fitted(fit,newdata,re_formula=NA,summary=TRUE)
> > colnames(means)=c("fit","se","lwr","upr")
> > df_plot=cbind(newdata,means)
> >
> > I am sure this must be simple, particularly with the hypothesis()
> function
> > but I am not sure how to include the "zero-non zero part" (i.e. hu_...).
> >
> > If anyone can foward some information on this, I would be eternally
> > grateful (or even more should I say).
> >
> > Sincerely,
> >
> > Guillaume ADEUX
> >
> >
> >
> > Le ven. 20 d?c. 2019 ? 15:12, Ben Bolker <bbolker at gmail.com> a ?crit :
> >
> > >
> > > Good point.
> > > This might be manageable in MCMCglmm or brms (or JAGS) ...
> > >
> > > On 2019-12-20 2:58 a.m., D. Rizopoulos wrote:
> > > > For a hurdle model for repeated measurements data, the dichotomous
> > > outcome I(diversity > 0) is also a repeated measurements outcome.
> Hence,
> > in
> > > the logistic regression model for this dichotomous outcome you will
> need
> > to
> > > include random effects to account for the correlations. And it is
> logical
> > > to assume that the random effects from this logistic regression model
> > will
> > > be correlated with the random effects of the linear mixed model for
> only
> > > the positive responses.
> > > >
> > > > In this case the likelihood of the two parts does not split in two
> > > functionally independent parts that can be separately maximized. If
> this
> > is
> > > indeed the case, then fitting the two parts separately may cause bias
> and
> > > loss of efficiency.
> > > >
> > > > Best,
> > > > Dimitris
> > > >
> > > > ??
> > > > Dimitris Rizopoulos
> > > > Professor of Biostatistics
> > > > Erasmus University Medical Center
> > > > The Netherlands
> > > >
> > > > ________________________________
> > > > From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org>
> on
> > > behalf of Mollie Brooks <mollieebrooks at gmail.com>
> > > > Sent: Wednesday, December 18, 2019 3:08 PM
> > > > To: Help Mixed Models; Guillaume Adeux
> > > > Subject: Re: [R-sig-ME] mixed lognormal hurdle model with multiple
> > > grouping factors
> > > >
> > > > Hi Guillaume,
> > > >
> > > > I don?t think the hurdle lognormal can be fit in a single function
> call
> > > to glmmTMB since the model for the non-zero response requires
> > > log-transforming the response. Other types of hurdle models could be
> fit
> > in
> > > glmmTMB using the zero-inflation model.
> > > >
> > > > I don?t think you gain much information in hurdle models by modeling
> > the
> > > two parts (zeros and non-zeros) in one function call. The only
> potential
> > > benefit to fitting a hurdle in a single function call is that you get
> > > likelihood and AIC for the entire data set, but I don?t know if those
> are
> > > produced by brms.
> > > >
> > > > You could just fit a binomial model for the zero-non-zero process
> (i.e.
> > > monoculture) like
> > > >
> > mod_binom=lmer((diversity>0)~block+syst+(1|plot)+(1|year)+(1|plot:year),
> > > data=density, family=binomial)
> > > >
> > > > and then fit a model to the log of the positive data
> > > >
> > mod_gaus=lmer(log(diversity)~block+syst+(1|plot)+(1|year)+(1|plot:year),
> > > data=subset(density, diversity>0))
> > > >
> > > > Or, given that the outcome is non-negative and continuous, it might
> > make
> > > sense to try a Tweedie distribution, but I?m not sure I?ve seen this
> > > applied to diversity indices in the literature. Has anyone else seen
> this
> > > done?
> > > > mod_twe =
> glmmTMB(diversity~block+syst+(1|plot)+(1|year)+(1|plot:year),
> > > data=density, family=tweedie)
> > > >
> > > > Cheers,
> > > > Mollie
> > > >
> > > >> On 18Dec 2019, at 14:45, Cesko Voeten <c.c.voeten at hum.leidenuniv.nl>
>
> > > wrote:
> > > >>
> > > >> Hi Guillaume,
> > > >>
> > > >> If you're not afraid to go Bayesian, brms can do it. Alternatively,
> > you
> > > may be able to use glmmTMB and treat the hurdle part as zero
> inflation,
> > but
> > > this is conceptually not the same thing as a hurdle model so you would
> > need
> > > to judge whether that would make sense at all for your application.
> > > >>
> > > >> HTH,
> > > >> Cesko
> > > >>
> > > >> Op 18-12-2019 om 13:48 schreef Guillaume Adeux:
> > > >>> Hi everyone,
> > > >>> I am looking for a package which can handle "hurdle.lognormal"
> > > distribution
> > > >>> family and multiple grouping factors.
> > > >>> GLMMadaptive seemed as the way to go but unfortunately, to the
> best
> > of
> > > my
> > > >>> knowledge, it does not handle multiple grouping factors (random
> > > effects).
> > > >>> You may ask why? I am analyzing plant diversity and one of the
> > > treatments
> > > >>> led to plots which were dominated by one species. Hence, certain
> > > diversity
> > > >>> indices are estimated as zero in these plots, and produces a mass
> at
> > > zero.
> > > >>> All other values are positive and continuous.
> > > >>> Anyone have an idea of a package/function which can handle this?
> Or
> > any
> > > >>> alternative approach?
> > > >>> In lmer syntax, the model is the following:
> > > >>>
> > >
> >
> mod=lmer(diversity~block+syst+(1|plot)+(1|year)+(1|plot:year),data=density,REML=F)
>
> > > >>> Thank you for your time and help.
> > > >>> Sincerely,
> > > >>> Guillaume ADEUX
> > > >>> [[alternative HTML version deleted]]
> > > >>> _______________________________________________
> > > >>> R-sig-mixed-models at r-project.org mailing list
> > > >>>
> > >
> >
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C94c75233c5084fb99c6908d787d3adf4%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637127215536371685&amp;sdata=PL6VOZ8Q9M5DQa8xp%2FrKKe%2FqXO%2BzE5sfMP%2FvxZr2jHE%3D&amp;reserved=0
> > > >>>
> > > >>
> > > >> _______________________________________________
> > > >> R-sig-mixed-models at r-project.org mailing list
> > > >>
> > >
> >
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C94c75233c5084fb99c6908d787d3adf4%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637127215536371685&amp;sdata=PL6VOZ8Q9M5DQa8xp%2FrKKe%2FqXO%2BzE5sfMP%2FvxZr2jHE%3D&amp;reserved=0
> > > >
> > > > _______________________________________________
> > > > R-sig-mixed-models at r-project.org mailing list
> > > >
> > >
> >
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C94c75233c5084fb99c6908d787d3adf4%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637127215536381676&amp;sdata=YRc7r3Ni5P345YiPoEuNhmhmte20pMrIb3ojmkmY6qA%3D&amp;reserved=0
> > > >
> > > > [[alternative HTML version deleted]]
> > > >
> > > >
> > > > _______________________________________________
> > > > R-sig-mixed-models at r-project.org mailing list
> > > >
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C94c75233c5084fb99c6908d787d3adf4%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637127215536381676&amp;sdata=YRc7r3Ni5P345YiPoEuNhmhmte20pMrIb3ojmkmY6qA%3D&amp;reserved=0
> > > >
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > >
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C94c75233c5084fb99c6908d787d3adf4%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637127215536381676&amp;sdata=YRc7r3Ni5P345YiPoEuNhmhmte20pMrIb3ojmkmY6qA%3D&amp;reserved=0
> > >
> >
> > [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> >
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C94c75233c5084fb99c6908d787d3adf4%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637127215536381676&amp;sdata=YRc7r3Ni5P345YiPoEuNhmhmte20pMrIb3ojmkmY6qA%3D&amp;reserved=0
> >
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
>
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C94c75233c5084fb99c6908d787d3adf4%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637127215536381676&amp;sdata=YRc7r3Ni5P345YiPoEuNhmhmte20pMrIb3ojmkmY6qA%3D&amp;reserved=0
>

	[[alternative HTML version deleted]]


From d|u|op@ucd @end|ng |rom gm@||@com  Mon Dec 23 20:58:20 2019
From: d|u|op@ucd @end|ng |rom gm@||@com (Daniel Fulop)
Date: Mon, 23 Dec 2019 11:58:20 -0800
Subject: [R-sig-ME] mixed lognormal hurdle model with multiple grouping
 factors
In-Reply-To: <CAOFWXwztxRU8ZLurjC1KwNxJcR14edz2jyUc-08Xj=PpNNdqRw@mail.gmail.com>
References: <CAENiVe83vHUUv6i87oEo=ZzeyD4KXstCpx7p=dSwEfWZrtTAsg@mail.gmail.com>
 <3b68fdf6-31d5-f27b-b3a8-200cd0b6a632@hum.leidenuniv.nl>
 <28255CBD-2A77-4E1B-A9A8-1FEC88CD10A9@gmail.com>
 <AM6PR0402MB3333D1F0EEBE20FAE1A0EEE5E82D0@AM6PR0402MB3333.eurprd04.prod.outlook.com>
 <0f932de6-9977-4d38-b7f8-907d716ebb15@gmail.com>
 <CAENiVe9F8zWzXbRWmRWBi7Tjb=hMkYxVFdDLyr4XXDQu+M+BUQ@mail.gmail.com>
 <CAOFWXwy+dOF+BcEpEYCNPHAjgSvJ65B7xqbU=Kxo0SHraEzqXw@mail.gmail.com>
 <AM6PR0402MB3333F79554424B1C2A230DC8E82E0@AM6PR0402MB3333.eurprd04.prod.outlook.com>
 <CAOFWXwztxRU8ZLurjC1KwNxJcR14edz2jyUc-08Xj=PpNNdqRw@mail.gmail.com>
Message-ID: <CAAs0riJzxjqmwqvOCJwOMoJ+TCT6Wib6TQ+Fi1s4z9+wm6tU7A@mail.gmail.com>

Another (Tweedie) option is using the cpglmm() function in the cplm
package.

On Mon, Dec 23, 2019 at 11:06 AM Liming Wang <lmwang at gmail.com> wrote:

> Dimitris,
>
> Thanks for the correction and clarification! I apparently didn't note
> that Guillaume has ruled out GLMMAdaptive and I didn't recognize that you
> are the author of GLMMAdaptive.
>
> Best,
>
> Liming
>
> On Mon, Dec 23, 2019 at 10:47 AM D. Rizopoulos <d.rizopoulos at erasmusmc.nl>
> wrote:
>
> > GLMMadaptive does support random effects for the zero part model.
> >
> > The reason why GLMMadaptive is slower is because it implements the
> > adaptive Gaussian quadrature for approximating the log-likelihood. This
> > approximation is in general considered more accurate (but slower) than
> the
> > Laplace approximation implemented in glmmTMB.
> >
> > Best,
> > Dimitris
> >
> > ?-
> > Dimitris Rizopoulos
> > Professor of Biostatistics
> > Erasmus University Medical Center
> > The Netherlands
> >
> > ------------------------------
> > *???:* ? ??????? R-sig-mixed-models <
> > r-sig-mixed-models-bounces at r-project.org> ?? ?????? ??? ?????? Liming
> > Wang <lmwang at gmail.com>
> > *????????:* ???????, ?????????? 23, 2019 19:12
> > *????:* Guillaume Adeux
> > *????.:* R-mixed models mailing list
> > *????:* Re: [R-sig-ME] mixed lognormal hurdle model with multiple
> > grouping factors
> >
> > Hi Guillaume,
> >
> > The mixed_model in the GLMMadaptive package supports Two-Part Mixed
> > Effects
> > Model for Semi-Continuous Data (
> >
> >
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fdrizopoulos.github.io%2FGLMMadaptive%2Farticles%2FZeroInflated_and_TwoPart_Models.html%23zero-inflated-negative-binomial-mixed-effects-model&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C94c75233c5084fb99c6908d787d3adf4%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637127215536371685&amp;sdata=cDReHBDB%2FLuHfeM06tARqolihNCpVErMgCcMpyr6BYc%3D&amp;reserved=0
> ).
> >
> > It doesn't seem to support mixed effect for the zero outcome component
> > though. Another downside is that, since it is written in pure R, it is
> > much
> > slower than glmmTMB (for similar models).
> >
> > Liming
> >
> > On Fri, Dec 20, 2019 at 6:31 AM Guillaume Adeux <
> > guillaumesimon.a2 at gmail.com>
> > wrote:
> >
> > > Yes, for now, the most seducing solution has been the following (with
> > the
> > > brms package):
> > >
> > >
> > >
> >
> fit=brm(bf(H_q~block+syst+(1|plot)+(1|year)+(1|plot:year),hu~block+syst+(1|plot)+(1|year)+(1|plot:year)),data=density,family=hurdle_lognormal(),control
> >
> > > = list(adapt_delta = 0.999))
> > >
> > > Family: hurdle_lognormal
> > > Links: mu = identity; sigma = identity; hu = logit
> > > Formula: H_q ~ block + syst + (1 | plot) + (1 | year) + (1 | plot:year)
> > > hu ~ block + syst + (1 | plot) + (1 | year) + (1 | plot:year)
> > > Data: density (Number of observations: 480)
> > > Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
> > > total post-warmup samples = 4000
> > >
> > > Group-Level Effects:
> > > ~plot (Number of levels: 10)
> > > Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
> > > Tail_ESS
> > > sd(Intercept) 0.12 0.11 0.01 0.41 1.00 852
> > > 912
> > > sd(hu_Intercept) 1.21 1.01 0.05 3.86 1.01 637
> > > 1011
> > >
> > > ~plot:year (Number of levels: 60)
> > > Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
> > > Tail_ESS
> > > sd(Intercept) 0.13 0.06 0.01 0.23 1.00 737
> > > 546
> > > sd(hu_Intercept) 2.10 0.46 1.34 3.15 1.00 1427
> > > 2435
> > >
> > > ~year (Number of levels: 6)
> > > Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
> > > Tail_ESS
> > > sd(Intercept) 0.06 0.07 0.00 0.21 1.00 1497
> > > 1843
> > > sd(hu_Intercept) 0.83 0.71 0.03 2.55 1.01 935
> > > 1469
> > >
> > > Population-Level Effects:
> > > Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
> > > Intercept -0.23 0.07 -0.38 -0.08 1.00 2159 1513
> > > hu_Intercept -1.04 0.66 -2.26 0.43 1.00 1832 2061
> > > block1 -0.06 0.06 -0.17 0.07 1.00 2394 1933
> > > syst1 -0.32 0.17 -0.64 0.03 1.00 1930 1487
> > > syst2 -0.11 0.12 -0.35 0.13 1.00 2023 1617
> > > syst3 0.18 0.11 -0.06 0.41 1.00 1724 1267
> > > syst4 0.08 0.12 -0.16 0.32 1.00 2222 1691
> > > hu_block1 0.36 0.60 -0.81 1.63 1.00 1658 1684
> > > hu_syst1 4.19 1.34 1.61 6.91 1.00 1236 1233
> > > hu_syst2 -0.09 1.17 -2.40 2.38 1.00 1266 1419
> > > hu_syst3 -1.98 1.30 -4.59 0.54 1.01 1183 1235
> > > hu_syst4 -0.52 1.23 -2.95 1.88 1.00 1170 1108
> > >
> > > Family Specific Parameters:
> > > Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
> > > sigma 0.48 0.02 0.44 0.52 1.00 2632 3025
> > >
> > > Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample
> > > is a crude measure of effective sample size, and Rhat is the potential
> > > scale reduction factor on split chains (at convergence, Rhat = 1).
> > >
> > >
> > > I am currently struggling to obtain "syst" means averaged over blocks
> > (i.e.
> > > what would be done traditionally with emmeans(fit,~syst)) and to
> compare
> > > them pairwise.
> > >
> > > As of now, I am only capable of retrieving a mean for each combination
> > of
> > > "syst" and "block" :
> > >
> > > newdata =
> > > expand.grid(syst=levels(density$syst),block=levels(density$block))
> > > means=fitted(fit,newdata,re_formula=NA,summary=TRUE)
> > > colnames(means)=c("fit","se","lwr","upr")
> > > df_plot=cbind(newdata,means)
> > >
> > > I am sure this must be simple, particularly with the hypothesis()
> > function
> > > but I am not sure how to include the "zero-non zero part" (i.e.
> hu_...).
> > >
> > > If anyone can foward some information on this, I would be eternally
> > > grateful (or even more should I say).
> > >
> > > Sincerely,
> > >
> > > Guillaume ADEUX
> > >
> > >
> > >
> > > Le ven. 20 d?c. 2019 ? 15:12, Ben Bolker <bbolker at gmail.com> a ?crit :
> > >
> > > >
> > > > Good point.
> > > > This might be manageable in MCMCglmm or brms (or JAGS) ...
> > > >
> > > > On 2019-12-20 2:58 a.m., D. Rizopoulos wrote:
> > > > > For a hurdle model for repeated measurements data, the dichotomous
> > > > outcome I(diversity > 0) is also a repeated measurements outcome.
> > Hence,
> > > in
> > > > the logistic regression model for this dichotomous outcome you will
> > need
> > > to
> > > > include random effects to account for the correlations. And it is
> > logical
> > > > to assume that the random effects from this logistic regression model
> > > will
> > > > be correlated with the random effects of the linear mixed model for
> > only
> > > > the positive responses.
> > > > >
> > > > > In this case the likelihood of the two parts does not split in two
> > > > functionally independent parts that can be separately maximized. If
> > this
> > > is
> > > > indeed the case, then fitting the two parts separately may cause bias
> > and
> > > > loss of efficiency.
> > > > >
> > > > > Best,
> > > > > Dimitris
> > > > >
> > > > > ??
> > > > > Dimitris Rizopoulos
> > > > > Professor of Biostatistics
> > > > > Erasmus University Medical Center
> > > > > The Netherlands
> > > > >
> > > > > ________________________________
> > > > > From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org
> >
> > on
> > > > behalf of Mollie Brooks <mollieebrooks at gmail.com>
> > > > > Sent: Wednesday, December 18, 2019 3:08 PM
> > > > > To: Help Mixed Models; Guillaume Adeux
> > > > > Subject: Re: [R-sig-ME] mixed lognormal hurdle model with multiple
> > > > grouping factors
> > > > >
> > > > > Hi Guillaume,
> > > > >
> > > > > I don?t think the hurdle lognormal can be fit in a single function
> > call
> > > > to glmmTMB since the model for the non-zero response requires
> > > > log-transforming the response. Other types of hurdle models could be
> > fit
> > > in
> > > > glmmTMB using the zero-inflation model.
> > > > >
> > > > > I don?t think you gain much information in hurdle models by
> modeling
> > > the
> > > > two parts (zeros and non-zeros) in one function call. The only
> > potential
> > > > benefit to fitting a hurdle in a single function call is that you get
> > > > likelihood and AIC for the entire data set, but I don?t know if those
> > are
> > > > produced by brms.
> > > > >
> > > > > You could just fit a binomial model for the zero-non-zero process
> > (i.e.
> > > > monoculture) like
> > > > >
> > >
> mod_binom=lmer((diversity>0)~block+syst+(1|plot)+(1|year)+(1|plot:year),
> > > > data=density, family=binomial)
> > > > >
> > > > > and then fit a model to the log of the positive data
> > > > >
> > >
> mod_gaus=lmer(log(diversity)~block+syst+(1|plot)+(1|year)+(1|plot:year),
> > > > data=subset(density, diversity>0))
> > > > >
> > > > > Or, given that the outcome is non-negative and continuous, it might
> > > make
> > > > sense to try a Tweedie distribution, but I?m not sure I?ve seen this
> > > > applied to diversity indices in the literature. Has anyone else seen
> > this
> > > > done?
> > > > > mod_twe =
> > glmmTMB(diversity~block+syst+(1|plot)+(1|year)+(1|plot:year),
> > > > data=density, family=tweedie)
> > > > >
> > > > > Cheers,
> > > > > Mollie
> > > > >
> > > > >> On 18Dec 2019, at 14:45, Cesko Voeten <
> c.c.voeten at hum.leidenuniv.nl>
> >
> > > > wrote:
> > > > >>
> > > > >> Hi Guillaume,
> > > > >>
> > > > >> If you're not afraid to go Bayesian, brms can do it.
> Alternatively,
> > > you
> > > > may be able to use glmmTMB and treat the hurdle part as zero
> > inflation,
> > > but
> > > > this is conceptually not the same thing as a hurdle model so you
> would
> > > need
> > > > to judge whether that would make sense at all for your application.
> > > > >>
> > > > >> HTH,
> > > > >> Cesko
> > > > >>
> > > > >> Op 18-12-2019 om 13:48 schreef Guillaume Adeux:
> > > > >>> Hi everyone,
> > > > >>> I am looking for a package which can handle "hurdle.lognormal"
> > > > distribution
> > > > >>> family and multiple grouping factors.
> > > > >>> GLMMadaptive seemed as the way to go but unfortunately, to the
> > best
> > > of
> > > > my
> > > > >>> knowledge, it does not handle multiple grouping factors (random
> > > > effects).
> > > > >>> You may ask why? I am analyzing plant diversity and one of the
> > > > treatments
> > > > >>> led to plots which were dominated by one species. Hence, certain
> > > > diversity
> > > > >>> indices are estimated as zero in these plots, and produces a mass
> > at
> > > > zero.
> > > > >>> All other values are positive and continuous.
> > > > >>> Anyone have an idea of a package/function which can handle this?
> > Or
> > > any
> > > > >>> alternative approach?
> > > > >>> In lmer syntax, the model is the following:
> > > > >>>
> > > >
> > >
> >
> mod=lmer(diversity~block+syst+(1|plot)+(1|year)+(1|plot:year),data=density,REML=F)
> >
> > > > >>> Thank you for your time and help.
> > > > >>> Sincerely,
> > > > >>> Guillaume ADEUX
> > > > >>> [[alternative HTML version deleted]]
> > > > >>> _______________________________________________
> > > > >>> R-sig-mixed-models at r-project.org mailing list
> > > > >>>
> > > >
> > >
> >
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C94c75233c5084fb99c6908d787d3adf4%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637127215536371685&amp;sdata=PL6VOZ8Q9M5DQa8xp%2FrKKe%2FqXO%2BzE5sfMP%2FvxZr2jHE%3D&amp;reserved=0
> > > > >>>
> > > > >>
> > > > >> _______________________________________________
> > > > >> R-sig-mixed-models at r-project.org mailing list
> > > > >>
> > > >
> > >
> >
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C94c75233c5084fb99c6908d787d3adf4%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637127215536371685&amp;sdata=PL6VOZ8Q9M5DQa8xp%2FrKKe%2FqXO%2BzE5sfMP%2FvxZr2jHE%3D&amp;reserved=0
> > > > >
> > > > > _______________________________________________
> > > > > R-sig-mixed-models at r-project.org mailing list
> > > > >
> > > >
> > >
> >
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C94c75233c5084fb99c6908d787d3adf4%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637127215536381676&amp;sdata=YRc7r3Ni5P345YiPoEuNhmhmte20pMrIb3ojmkmY6qA%3D&amp;reserved=0
> > > > >
> > > > > [[alternative HTML version deleted]]
> > > > >
> > > > >
> > > > > _______________________________________________
> > > > > R-sig-mixed-models at r-project.org mailing list
> > > > >
> >
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C94c75233c5084fb99c6908d787d3adf4%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637127215536381676&amp;sdata=YRc7r3Ni5P345YiPoEuNhmhmte20pMrIb3ojmkmY6qA%3D&amp;reserved=0
> > > > >
> > > >
> > > > _______________________________________________
> > > > R-sig-mixed-models at r-project.org mailing list
> > > >
> >
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C94c75233c5084fb99c6908d787d3adf4%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637127215536381676&amp;sdata=YRc7r3Ni5P345YiPoEuNhmhmte20pMrIb3ojmkmY6qA%3D&amp;reserved=0
> > > >
> > >
> > > [[alternative HTML version deleted]]
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > >
> >
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C94c75233c5084fb99c6908d787d3adf4%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637127215536381676&amp;sdata=YRc7r3Ni5P345YiPoEuNhmhmte20pMrIb3ojmkmY6qA%3D&amp;reserved=0
> > >
> >
> > [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> >
> >
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C94c75233c5084fb99c6908d787d3adf4%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637127215536381676&amp;sdata=YRc7r3Ni5P345YiPoEuNhmhmte20pMrIb3ojmkmY6qA%3D&amp;reserved=0
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
-- 
--
Daniel Fulop, Ph.D.
Postdoctoral Scholar
Dept. Plant Biology, UC Davis
Maloof Lab, Rm. 2220
Life Sciences Addition, One Shields Ave.
Davis, CA 95616

510-253-7462
dfulop at ucdavis.edu

	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Mon Dec 23 22:07:21 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Tue, 24 Dec 2019 10:07:21 +1300
Subject: [R-sig-ME] Is there a way to deal with errors such as this?
In-Reply-To: <e02a5620-c912-a544-a749-943f54a6d37c@mpi.nl>
References: <5d8a95d7-1310-cec0-8397-054a470dc7e2@auckland.ac.nz>
 <000401d5b331$56d13be0$0473b3a0$@uke.de>
 <c5289090-f17c-c6f9-76f2-bc78e011fc78@auckland.ac.nz>
 <AM6PR0402MB333313B9252D5B1FD9827949E8560@AM6PR0402MB3333.eurprd04.prod.outlook.com>
 <1cb03000-c6b7-a226-9d84-8826eb09852d@auckland.ac.nz>
 <D14049CE02C4F54D95360EEC06CE45C50FB4891A@SPMXM08.VUW.leidenuniv.nl>
 <7742a7a6-672c-16be-18ae-13b44a168542@auckland.ac.nz>
 <e02a5620-c912-a544-a749-943f54a6d37c@mpi.nl>
Message-ID: <08f8cfac-3546-400f-47ca-4c43babe27c1@auckland.ac.nz>


On 24/12/19 3:20 am, Phillip Alday wrote:

> For completeness, you can also get use getME(model, "beta") to get the 
> fixed effects estimates as a simple, unnamed vector. :)

Thank you.  That is useful to know.

cheers,

Rolf

P. S. Someday I must try to teach the world how to write help 
files/software documentation!!! :-)

R. T.


-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From bbo|ker @end|ng |rom gm@||@com  Tue Dec 24 01:25:55 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 23 Dec 2019 19:25:55 -0500
Subject: [R-sig-ME] Is there a way to deal with errors such as this?
In-Reply-To: <08f8cfac-3546-400f-47ca-4c43babe27c1@auckland.ac.nz>
References: <5d8a95d7-1310-cec0-8397-054a470dc7e2@auckland.ac.nz>
 <000401d5b331$56d13be0$0473b3a0$@uke.de>
 <c5289090-f17c-c6f9-76f2-bc78e011fc78@auckland.ac.nz>
 <AM6PR0402MB333313B9252D5B1FD9827949E8560@AM6PR0402MB3333.eurprd04.prod.outlook.com>
 <1cb03000-c6b7-a226-9d84-8826eb09852d@auckland.ac.nz>
 <D14049CE02C4F54D95360EEC06CE45C50FB4891A@SPMXM08.VUW.leidenuniv.nl>
 <7742a7a6-672c-16be-18ae-13b44a168542@auckland.ac.nz>
 <e02a5620-c912-a544-a749-943f54a6d37c@mpi.nl>
 <08f8cfac-3546-400f-47ca-4c43babe27c1@auckland.ac.nz>
Message-ID: <2f0b1849-5770-af52-4a3c-28a9c83f1604@gmail.com>


    Comments welcome at https://github.com/lme4/lme4/issues/552

  In the grand tradition of R documentation, none of the existing
package documentation is actually *incorrect* (that I know of ...) but
some is very sketchy.

On 2019-12-23 4:07 p.m., Rolf Turner wrote:
> 
> On 24/12/19 3:20 am, Phillip Alday wrote:
> 
>> For completeness, you can also get use getME(model, "beta") to get the
>> fixed effects estimates as a simple, unnamed vector. :)
> 
> Thank you.? That is useful to know.
> 
> cheers,
> 
> Rolf
> 
> P. S. Someday I must try to teach the world how to write help
> files/software documentation!!! :-)
> 
> R. T.
> 
>


From gu|||@ume@|mon@@2 @end|ng |rom gm@||@com  Tue Dec 24 10:53:21 2019
From: gu|||@ume@|mon@@2 @end|ng |rom gm@||@com (Guillaume Adeux)
Date: Tue, 24 Dec 2019 10:53:21 +0100
Subject: [R-sig-ME] mixed lognormal hurdle model with multiple grouping
 factors
In-Reply-To: <CAAs0riJzxjqmwqvOCJwOMoJ+TCT6Wib6TQ+Fi1s4z9+wm6tU7A@mail.gmail.com>
References: <CAENiVe83vHUUv6i87oEo=ZzeyD4KXstCpx7p=dSwEfWZrtTAsg@mail.gmail.com>
 <3b68fdf6-31d5-f27b-b3a8-200cd0b6a632@hum.leidenuniv.nl>
 <28255CBD-2A77-4E1B-A9A8-1FEC88CD10A9@gmail.com>
 <AM6PR0402MB3333D1F0EEBE20FAE1A0EEE5E82D0@AM6PR0402MB3333.eurprd04.prod.outlook.com>
 <0f932de6-9977-4d38-b7f8-907d716ebb15@gmail.com>
 <CAENiVe9F8zWzXbRWmRWBi7Tjb=hMkYxVFdDLyr4XXDQu+M+BUQ@mail.gmail.com>
 <CAOFWXwy+dOF+BcEpEYCNPHAjgSvJ65B7xqbU=Kxo0SHraEzqXw@mail.gmail.com>
 <AM6PR0402MB3333F79554424B1C2A230DC8E82E0@AM6PR0402MB3333.eurprd04.prod.outlook.com>
 <CAOFWXwztxRU8ZLurjC1KwNxJcR14edz2jyUc-08Xj=PpNNdqRw@mail.gmail.com>
 <CAAs0riJzxjqmwqvOCJwOMoJ+TCT6Wib6TQ+Fi1s4z9+wm6tU7A@mail.gmail.com>
Message-ID: <CAENiVe8Zr8MEB6aa9t7XTZN227ym+s5HsAfZmJDZcCUCeDj+=Q@mail.gmail.com>

Thank you all for continuing to provide valuable information.

Indeed, I ruled out glmmadaptive because it does not handle crossed random
effects (such a pity in my case, as it is the only downside).

My dataset is not massive (480 observations), so computation time is not a
problem.

As I specified earlier, i successfully fitted this model with brms:

fit=brm(bf(H_q~block+syst+(1|plot)+(1|year)+(1|plot:year),hu~block+syst+(1|plot)+(1|year)+(1|plot:year)),data=density,family=hurdle_lognormal(),control
= list(adapt_delta = 0.999))

but this bayesian framework is completely new to me and am having a hard
time finding equivalents to (i) test of main effects and (ii) comparison of
treatments means.

Any further advice is welcome. Thanks again for your help.

GA2

Le lun. 23 d?c. 2019 ? 20:58, Daniel Fulop <dfulop.ucd at gmail.com> a ?crit :

> Another (Tweedie) option is using the cpglmm() function in the cplm
> package.
>
> On Mon, Dec 23, 2019 at 11:06 AM Liming Wang <lmwang at gmail.com> wrote:
>
> > Dimitris,
> >
> > Thanks for the correction and clarification! I apparently didn't note
> > that Guillaume has ruled out GLMMAdaptive and I didn't recognize that you
> > are the author of GLMMAdaptive.
> >
> > Best,
> >
> > Liming
> >
> > On Mon, Dec 23, 2019 at 10:47 AM D. Rizopoulos <
> d.rizopoulos at erasmusmc.nl>
> > wrote:
> >
> > > GLMMadaptive does support random effects for the zero part model.
> > >
> > > The reason why GLMMadaptive is slower is because it implements the
> > > adaptive Gaussian quadrature for approximating the log-likelihood. This
> > > approximation is in general considered more accurate (but slower) than
> > the
> > > Laplace approximation implemented in glmmTMB.
> > >
> > > Best,
> > > Dimitris
> > >
> > > ?-
> > > Dimitris Rizopoulos
> > > Professor of Biostatistics
> > > Erasmus University Medical Center
> > > The Netherlands
> > >
> > > ------------------------------
> > > *???:* ? ??????? R-sig-mixed-models <
> > > r-sig-mixed-models-bounces at r-project.org> ?? ?????? ??? ?????? Liming
> > > Wang <lmwang at gmail.com>
> > > *????????:* ???????, ?????????? 23, 2019 19:12
> > > *????:* Guillaume Adeux
> > > *????.:* R-mixed models mailing list
> > > *????:* Re: [R-sig-ME] mixed lognormal hurdle model with multiple
> > > grouping factors
> > >
> > > Hi Guillaume,
> > >
> > > The mixed_model in the GLMMadaptive package supports Two-Part Mixed
> > > Effects
> > > Model for Semi-Continuous Data (
> > >
> > >
> >
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fdrizopoulos.github.io%2FGLMMadaptive%2Farticles%2FZeroInflated_and_TwoPart_Models.html%23zero-inflated-negative-binomial-mixed-effects-model&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C94c75233c5084fb99c6908d787d3adf4%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637127215536371685&amp;sdata=cDReHBDB%2FLuHfeM06tARqolihNCpVErMgCcMpyr6BYc%3D&amp;reserved=0
> > ).
> > >
> > > It doesn't seem to support mixed effect for the zero outcome component
> > > though. Another downside is that, since it is written in pure R, it is
> > > much
> > > slower than glmmTMB (for similar models).
> > >
> > > Liming
> > >
> > > On Fri, Dec 20, 2019 at 6:31 AM Guillaume Adeux <
> > > guillaumesimon.a2 at gmail.com>
> > > wrote:
> > >
> > > > Yes, for now, the most seducing solution has been the following (with
> > > the
> > > > brms package):
> > > >
> > > >
> > > >
> > >
> >
> fit=brm(bf(H_q~block+syst+(1|plot)+(1|year)+(1|plot:year),hu~block+syst+(1|plot)+(1|year)+(1|plot:year)),data=density,family=hurdle_lognormal(),control
> > >
> > > > = list(adapt_delta = 0.999))
> > > >
> > > > Family: hurdle_lognormal
> > > > Links: mu = identity; sigma = identity; hu = logit
> > > > Formula: H_q ~ block + syst + (1 | plot) + (1 | year) + (1 |
> plot:year)
> > > > hu ~ block + syst + (1 | plot) + (1 | year) + (1 | plot:year)
> > > > Data: density (Number of observations: 480)
> > > > Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
> > > > total post-warmup samples = 4000
> > > >
> > > > Group-Level Effects:
> > > > ~plot (Number of levels: 10)
> > > > Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
> > > > Tail_ESS
> > > > sd(Intercept) 0.12 0.11 0.01 0.41 1.00 852
> > > > 912
> > > > sd(hu_Intercept) 1.21 1.01 0.05 3.86 1.01 637
> > > > 1011
> > > >
> > > > ~plot:year (Number of levels: 60)
> > > > Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
> > > > Tail_ESS
> > > > sd(Intercept) 0.13 0.06 0.01 0.23 1.00 737
> > > > 546
> > > > sd(hu_Intercept) 2.10 0.46 1.34 3.15 1.00 1427
> > > > 2435
> > > >
> > > > ~year (Number of levels: 6)
> > > > Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
> > > > Tail_ESS
> > > > sd(Intercept) 0.06 0.07 0.00 0.21 1.00 1497
> > > > 1843
> > > > sd(hu_Intercept) 0.83 0.71 0.03 2.55 1.01 935
> > > > 1469
> > > >
> > > > Population-Level Effects:
> > > > Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
> > > > Intercept -0.23 0.07 -0.38 -0.08 1.00 2159 1513
> > > > hu_Intercept -1.04 0.66 -2.26 0.43 1.00 1832 2061
> > > > block1 -0.06 0.06 -0.17 0.07 1.00 2394 1933
> > > > syst1 -0.32 0.17 -0.64 0.03 1.00 1930 1487
> > > > syst2 -0.11 0.12 -0.35 0.13 1.00 2023 1617
> > > > syst3 0.18 0.11 -0.06 0.41 1.00 1724 1267
> > > > syst4 0.08 0.12 -0.16 0.32 1.00 2222 1691
> > > > hu_block1 0.36 0.60 -0.81 1.63 1.00 1658 1684
> > > > hu_syst1 4.19 1.34 1.61 6.91 1.00 1236 1233
> > > > hu_syst2 -0.09 1.17 -2.40 2.38 1.00 1266 1419
> > > > hu_syst3 -1.98 1.30 -4.59 0.54 1.01 1183 1235
> > > > hu_syst4 -0.52 1.23 -2.95 1.88 1.00 1170 1108
> > > >
> > > > Family Specific Parameters:
> > > > Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
> > > > sigma 0.48 0.02 0.44 0.52 1.00 2632 3025
> > > >
> > > > Samples were drawn using sampling(NUTS). For each parameter,
> Eff.Sample
> > > > is a crude measure of effective sample size, and Rhat is the
> potential
> > > > scale reduction factor on split chains (at convergence, Rhat = 1).
> > > >
> > > >
> > > > I am currently struggling to obtain "syst" means averaged over blocks
> > > (i.e.
> > > > what would be done traditionally with emmeans(fit,~syst)) and to
> > compare
> > > > them pairwise.
> > > >
> > > > As of now, I am only capable of retrieving a mean for each
> combination
> > > of
> > > > "syst" and "block" :
> > > >
> > > > newdata =
> > > > expand.grid(syst=levels(density$syst),block=levels(density$block))
> > > > means=fitted(fit,newdata,re_formula=NA,summary=TRUE)
> > > > colnames(means)=c("fit","se","lwr","upr")
> > > > df_plot=cbind(newdata,means)
> > > >
> > > > I am sure this must be simple, particularly with the hypothesis()
> > > function
> > > > but I am not sure how to include the "zero-non zero part" (i.e.
> > hu_...).
> > > >
> > > > If anyone can foward some information on this, I would be eternally
> > > > grateful (or even more should I say).
> > > >
> > > > Sincerely,
> > > >
> > > > Guillaume ADEUX
> > > >
> > > >
> > > >
> > > > Le ven. 20 d?c. 2019 ? 15:12, Ben Bolker <bbolker at gmail.com> a
> ?crit :
> > > >
> > > > >
> > > > > Good point.
> > > > > This might be manageable in MCMCglmm or brms (or JAGS) ...
> > > > >
> > > > > On 2019-12-20 2:58 a.m., D. Rizopoulos wrote:
> > > > > > For a hurdle model for repeated measurements data, the
> dichotomous
> > > > > outcome I(diversity > 0) is also a repeated measurements outcome.
> > > Hence,
> > > > in
> > > > > the logistic regression model for this dichotomous outcome you will
> > > need
> > > > to
> > > > > include random effects to account for the correlations. And it is
> > > logical
> > > > > to assume that the random effects from this logistic regression
> model
> > > > will
> > > > > be correlated with the random effects of the linear mixed model for
> > > only
> > > > > the positive responses.
> > > > > >
> > > > > > In this case the likelihood of the two parts does not split in
> two
> > > > > functionally independent parts that can be separately maximized. If
> > > this
> > > > is
> > > > > indeed the case, then fitting the two parts separately may cause
> bias
> > > and
> > > > > loss of efficiency.
> > > > > >
> > > > > > Best,
> > > > > > Dimitris
> > > > > >
> > > > > > ??
> > > > > > Dimitris Rizopoulos
> > > > > > Professor of Biostatistics
> > > > > > Erasmus University Medical Center
> > > > > > The Netherlands
> > > > > >
> > > > > > ________________________________
> > > > > > From: R-sig-mixed-models <
> r-sig-mixed-models-bounces at r-project.org
> > >
> > > on
> > > > > behalf of Mollie Brooks <mollieebrooks at gmail.com>
> > > > > > Sent: Wednesday, December 18, 2019 3:08 PM
> > > > > > To: Help Mixed Models; Guillaume Adeux
> > > > > > Subject: Re: [R-sig-ME] mixed lognormal hurdle model with
> multiple
> > > > > grouping factors
> > > > > >
> > > > > > Hi Guillaume,
> > > > > >
> > > > > > I don?t think the hurdle lognormal can be fit in a single
> function
> > > call
> > > > > to glmmTMB since the model for the non-zero response requires
> > > > > log-transforming the response. Other types of hurdle models could
> be
> > > fit
> > > > in
> > > > > glmmTMB using the zero-inflation model.
> > > > > >
> > > > > > I don?t think you gain much information in hurdle models by
> > modeling
> > > > the
> > > > > two parts (zeros and non-zeros) in one function call. The only
> > > potential
> > > > > benefit to fitting a hurdle in a single function call is that you
> get
> > > > > likelihood and AIC for the entire data set, but I don?t know if
> those
> > > are
> > > > > produced by brms.
> > > > > >
> > > > > > You could just fit a binomial model for the zero-non-zero process
> > > (i.e.
> > > > > monoculture) like
> > > > > >
> > > >
> > mod_binom=lmer((diversity>0)~block+syst+(1|plot)+(1|year)+(1|plot:year),
> > > > > data=density, family=binomial)
> > > > > >
> > > > > > and then fit a model to the log of the positive data
> > > > > >
> > > >
> > mod_gaus=lmer(log(diversity)~block+syst+(1|plot)+(1|year)+(1|plot:year),
> > > > > data=subset(density, diversity>0))
> > > > > >
> > > > > > Or, given that the outcome is non-negative and continuous, it
> might
> > > > make
> > > > > sense to try a Tweedie distribution, but I?m not sure I?ve seen
> this
> > > > > applied to diversity indices in the literature. Has anyone else
> seen
> > > this
> > > > > done?
> > > > > > mod_twe =
> > > glmmTMB(diversity~block+syst+(1|plot)+(1|year)+(1|plot:year),
> > > > > data=density, family=tweedie)
> > > > > >
> > > > > > Cheers,
> > > > > > Mollie
> > > > > >
> > > > > >> On 18Dec 2019, at 14:45, Cesko Voeten <
> > c.c.voeten at hum.leidenuniv.nl>
> > >
> > > > > wrote:
> > > > > >>
> > > > > >> Hi Guillaume,
> > > > > >>
> > > > > >> If you're not afraid to go Bayesian, brms can do it.
> > Alternatively,
> > > > you
> > > > > may be able to use glmmTMB and treat the hurdle part as zero
> > > inflation,
> > > > but
> > > > > this is conceptually not the same thing as a hurdle model so you
> > would
> > > > need
> > > > > to judge whether that would make sense at all for your application.
> > > > > >>
> > > > > >> HTH,
> > > > > >> Cesko
> > > > > >>
> > > > > >> Op 18-12-2019 om 13:48 schreef Guillaume Adeux:
> > > > > >>> Hi everyone,
> > > > > >>> I am looking for a package which can handle "hurdle.lognormal"
> > > > > distribution
> > > > > >>> family and multiple grouping factors.
> > > > > >>> GLMMadaptive seemed as the way to go but unfortunately, to the
> > > best
> > > > of
> > > > > my
> > > > > >>> knowledge, it does not handle multiple grouping factors (random
> > > > > effects).
> > > > > >>> You may ask why? I am analyzing plant diversity and one of the
> > > > > treatments
> > > > > >>> led to plots which were dominated by one species. Hence,
> certain
> > > > > diversity
> > > > > >>> indices are estimated as zero in these plots, and produces a
> mass
> > > at
> > > > > zero.
> > > > > >>> All other values are positive and continuous.
> > > > > >>> Anyone have an idea of a package/function which can handle
> this?
> > > Or
> > > > any
> > > > > >>> alternative approach?
> > > > > >>> In lmer syntax, the model is the following:
> > > > > >>>
> > > > >
> > > >
> > >
> >
> mod=lmer(diversity~block+syst+(1|plot)+(1|year)+(1|plot:year),data=density,REML=F)
> > >
> > > > > >>> Thank you for your time and help.
> > > > > >>> Sincerely,
> > > > > >>> Guillaume ADEUX
> > > > > >>> [[alternative HTML version deleted]]
> > > > > >>> _______________________________________________
> > > > > >>> R-sig-mixed-models at r-project.org mailing list
> > > > > >>>
> > > > >
> > > >
> > >
> >
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C94c75233c5084fb99c6908d787d3adf4%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637127215536371685&amp;sdata=PL6VOZ8Q9M5DQa8xp%2FrKKe%2FqXO%2BzE5sfMP%2FvxZr2jHE%3D&amp;reserved=0
> > > > > >>>
> > > > > >>
> > > > > >> _______________________________________________
> > > > > >> R-sig-mixed-models at r-project.org mailing list
> > > > > >>
> > > > >
> > > >
> > >
> >
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C94c75233c5084fb99c6908d787d3adf4%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637127215536371685&amp;sdata=PL6VOZ8Q9M5DQa8xp%2FrKKe%2FqXO%2BzE5sfMP%2FvxZr2jHE%3D&amp;reserved=0
> > > > > >
> > > > > > _______________________________________________
> > > > > > R-sig-mixed-models at r-project.org mailing list
> > > > > >
> > > > >
> > > >
> > >
> >
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C94c75233c5084fb99c6908d787d3adf4%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637127215536381676&amp;sdata=YRc7r3Ni5P345YiPoEuNhmhmte20pMrIb3ojmkmY6qA%3D&amp;reserved=0
> > > > > >
> > > > > > [[alternative HTML version deleted]]
> > > > > >
> > > > > >
> > > > > > _______________________________________________
> > > > > > R-sig-mixed-models at r-project.org mailing list
> > > > > >
> > >
> >
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C94c75233c5084fb99c6908d787d3adf4%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637127215536381676&amp;sdata=YRc7r3Ni5P345YiPoEuNhmhmte20pMrIb3ojmkmY6qA%3D&amp;reserved=0
> > > > > >
> > > > >
> > > > > _______________________________________________
> > > > > R-sig-mixed-models at r-project.org mailing list
> > > > >
> > >
> >
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C94c75233c5084fb99c6908d787d3adf4%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637127215536381676&amp;sdata=YRc7r3Ni5P345YiPoEuNhmhmte20pMrIb3ojmkmY6qA%3D&amp;reserved=0
> > > > >
> > > >
> > > > [[alternative HTML version deleted]]
> > > >
> > > > _______________________________________________
> > > > R-sig-mixed-models at r-project.org mailing list
> > > >
> > >
> >
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C94c75233c5084fb99c6908d787d3adf4%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637127215536381676&amp;sdata=YRc7r3Ni5P345YiPoEuNhmhmte20pMrIb3ojmkmY6qA%3D&amp;reserved=0
> > > >
> > >
> > > [[alternative HTML version deleted]]
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > >
> > >
> >
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C94c75233c5084fb99c6908d787d3adf4%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637127215536381676&amp;sdata=YRc7r3Ni5P345YiPoEuNhmhmte20pMrIb3ojmkmY6qA%3D&amp;reserved=0
> > >
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> --
> --
> Daniel Fulop, Ph.D.
> Postdoctoral Scholar
> Dept. Plant Biology, UC Davis
> Maloof Lab, Rm. 2220
> Life Sciences Addition, One Shields Ave.
> Davis, CA 95616
>
> 510-253-7462
> dfulop at ucdavis.edu
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Tue Dec 24 11:24:47 2019
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Tue, 24 Dec 2019 11:24:47 +0100
Subject: [R-sig-ME] A consultation about lmer
In-Reply-To: <11cee80.1101f.16f23be0872.Coremail.18754808835@163.com>
References: <11cee80.1101f.16f23be0872.Coremail.18754808835@163.com>
Message-ID: <CAJuCY5ydpc4JOsVgL8kkc7JpAUY0Q0=xqQSUAaD-BEqJ7ViKZA@mail.gmail.com>

Dear anonymous,

The assumption of normality is on the residuals, not on the observations.
The assumption holds reasonably for the sleepstudy, except for a few
outliers.

library(lme4)
fm1 <- lmer(Reaction ~ Days + (Days | Subject), sleepstudy)
qqnorm(residuals(fm1))

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op ma 23 dec. 2019 om 17:36 schreef ??? <18754808835 at 163.com>:

>  I have some confusion about the use of lmer. As I learned the data
> should  be normal distributed when use liner mixed model. I tested the
> exmple  data (Reaction$sleepstudy) by using shapiro.test. The result shows
> that  it was not normal distributed.  So I have some confusion about the
> requirment of data distribution in function lmer and glmmer.
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From g@ngchen @end|ng |rom m@||@n|h@gov  Tue Dec 24 11:53:43 2019
From: g@ngchen @end|ng |rom m@||@n|h@gov (Chen, Gang (NIH/NIMH) [E])
Date: Tue, 24 Dec 2019 10:53:43 +0000
Subject: [R-sig-ME] mixed lognormal hurdle model with multiple grouping
 factors
In-Reply-To: <CAENiVe8Zr8MEB6aa9t7XTZN227ym+s5HsAfZmJDZcCUCeDj+=Q@mail.gmail.com>
References: <CAENiVe83vHUUv6i87oEo=ZzeyD4KXstCpx7p=dSwEfWZrtTAsg@mail.gmail.com>
 <3b68fdf6-31d5-f27b-b3a8-200cd0b6a632@hum.leidenuniv.nl>
 <28255CBD-2A77-4E1B-A9A8-1FEC88CD10A9@gmail.com>
 <AM6PR0402MB3333D1F0EEBE20FAE1A0EEE5E82D0@AM6PR0402MB3333.eurprd04.prod.outlook.com>
 <0f932de6-9977-4d38-b7f8-907d716ebb15@gmail.com>
 <CAENiVe9F8zWzXbRWmRWBi7Tjb=hMkYxVFdDLyr4XXDQu+M+BUQ@mail.gmail.com>
 <CAOFWXwy+dOF+BcEpEYCNPHAjgSvJ65B7xqbU=Kxo0SHraEzqXw@mail.gmail.com>
 <AM6PR0402MB3333F79554424B1C2A230DC8E82E0@AM6PR0402MB3333.eurprd04.prod.outlook.com>
 <CAOFWXwztxRU8ZLurjC1KwNxJcR14edz2jyUc-08Xj=PpNNdqRw@mail.gmail.com>
 <CAAs0riJzxjqmwqvOCJwOMoJ+TCT6Wib6TQ+Fi1s4z9+wm6tU7A@mail.gmail.com>
 <CAENiVe8Zr8MEB6aa9t7XTZN227ym+s5HsAfZmJDZcCUCeDj+=Q@mail.gmail.com>
Message-ID: <CAE06E0F-FCC7-469A-B4EC-82EE71C7C16D@nih.gov>

Guillaume,

To make statistical inferences for each particular effect with the Bayesian approach, first you need to directly draw the posterior samples from the output of brm():

ps <- fixef(fit, summary = FALSE)

Based on the reference (or base) level of each factor, assemble the posterior samples for each effect of interest with the above output. Then, you can get various statistical measures (mean, mode, median, standard error, quantile intervals, etc.) from those posterior samples.

The population-level effects you previously obtained from summary(fit) can basically be retrieved from

fixef(fit, summary = TRUE)

Gang
-- 
Gang Chen, Ph. D.
SSCC/DIRP/NIMH
National Institutes of Health
Bethesda, MD 20892-1148
U.S.A.

?On 12/24/19, 4:54 AM, "Guillaume Adeux" <guillaumesimon.a2 at gmail.com> wrote:

    Thank you all for continuing to provide valuable information.
    
    Indeed, I ruled out glmmadaptive because it does not handle crossed random
    effects (such a pity in my case, as it is the only downside).
    
    My dataset is not massive (480 observations), so computation time is not a
    problem.
    
    As I specified earlier, i successfully fitted this model with brms:
    
    fit=brm(bf(H_q~block+syst+(1|plot)+(1|year)+(1|plot:year),hu~block+syst+(1|plot)+(1|year)+(1|plot:year)),data=density,family=hurdle_lognormal(),control
    = list(adapt_delta = 0.999))
    
    but this bayesian framework is completely new to me and am having a hard
    time finding equivalents to (i) test of main effects and (ii) comparison of
    treatments means.
    
    Any further advice is welcome. Thanks again for your help.
    
    GA2
    
    Le lun. 23 d?c. 2019 ? 20:58, Daniel Fulop <dfulop.ucd at gmail.com> a ?crit :
    
    > Another (Tweedie) option is using the cpglmm() function in the cplm
    > package.
    >
    > On Mon, Dec 23, 2019 at 11:06 AM Liming Wang <lmwang at gmail.com> wrote:
    >
    > > Dimitris,
    > >
    > > Thanks for the correction and clarification! I apparently didn't note
    > > that Guillaume has ruled out GLMMAdaptive and I didn't recognize that you
    > > are the author of GLMMAdaptive.
    > >
    > > Best,
    > >
    > > Liming
    > >
    > > On Mon, Dec 23, 2019 at 10:47 AM D. Rizopoulos <
    > d.rizopoulos at erasmusmc.nl>
    > > wrote:
    > >
    > > > GLMMadaptive does support random effects for the zero part model.
    > > >
    > > > The reason why GLMMadaptive is slower is because it implements the
    > > > adaptive Gaussian quadrature for approximating the log-likelihood. This
    > > > approximation is in general considered more accurate (but slower) than
    > > the
    > > > Laplace approximation implemented in glmmTMB.
    > > >
    > > > Best,
    > > > Dimitris
    > > >
    > > > ?-
    > > > Dimitris Rizopoulos
    > > > Professor of Biostatistics
    > > > Erasmus University Medical Center
    > > > The Netherlands
    > > >
    > > > ------------------------------
    > > > *???:* ? ??????? R-sig-mixed-models <
    > > > r-sig-mixed-models-bounces at r-project.org> ?? ?????? ??? ?????? Liming
    > > > Wang <lmwang at gmail.com>
    > > > *????????:* ???????, ?????????? 23, 2019 19:12
    > > > *????:* Guillaume Adeux
    > > > *????.:* R-mixed models mailing list
    > > > *????:* Re: [R-sig-ME] mixed lognormal hurdle model with multiple
    > > > grouping factors
    > > >
    > > > Hi Guillaume,
    > > >
    > > > The mixed_model in the GLMMadaptive package supports Two-Part Mixed
    > > > Effects
    > > > Model for Semi-Continuous Data (
    > > >
    > > >
    > >
    > https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fdrizopoulos.github.io%2FGLMMadaptive%2Farticles%2FZeroInflated_and_TwoPart_Models.html%23zero-inflated-negative-binomial-mixed-effects-model&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C94c75233c5084fb99c6908d787d3adf4%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637127215536371685&amp;sdata=cDReHBDB%2FLuHfeM06tARqolihNCpVErMgCcMpyr6BYc%3D&amp;reserved=0
    > > ).
    > > >
    > > > It doesn't seem to support mixed effect for the zero outcome component
    > > > though. Another downside is that, since it is written in pure R, it is
    > > > much
    > > > slower than glmmTMB (for similar models).
    > > >
    > > > Liming
    > > >
    > > > On Fri, Dec 20, 2019 at 6:31 AM Guillaume Adeux <
    > > > guillaumesimon.a2 at gmail.com>
    > > > wrote:
    > > >
    > > > > Yes, for now, the most seducing solution has been the following (with
    > > > the
    > > > > brms package):
    > > > >
    > > > >
    > > > >
    > > >
    > >
    > fit=brm(bf(H_q~block+syst+(1|plot)+(1|year)+(1|plot:year),hu~block+syst+(1|plot)+(1|year)+(1|plot:year)),data=density,family=hurdle_lognormal(),control
    > > >
    > > > > = list(adapt_delta = 0.999))
    > > > >
    > > > > Family: hurdle_lognormal
    > > > > Links: mu = identity; sigma = identity; hu = logit
    > > > > Formula: H_q ~ block + syst + (1 | plot) + (1 | year) + (1 |
    > plot:year)
    > > > > hu ~ block + syst + (1 | plot) + (1 | year) + (1 | plot:year)
    > > > > Data: density (Number of observations: 480)
    > > > > Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
    > > > > total post-warmup samples = 4000
    > > > >
    > > > > Group-Level Effects:
    > > > > ~plot (Number of levels: 10)
    > > > > Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
    > > > > Tail_ESS
    > > > > sd(Intercept) 0.12 0.11 0.01 0.41 1.00 852
    > > > > 912
    > > > > sd(hu_Intercept) 1.21 1.01 0.05 3.86 1.01 637
    > > > > 1011
    > > > >
    > > > > ~plot:year (Number of levels: 60)
    > > > > Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
    > > > > Tail_ESS
    > > > > sd(Intercept) 0.13 0.06 0.01 0.23 1.00 737
    > > > > 546
    > > > > sd(hu_Intercept) 2.10 0.46 1.34 3.15 1.00 1427
    > > > > 2435
    > > > >
    > > > > ~year (Number of levels: 6)
    > > > > Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
    > > > > Tail_ESS
    > > > > sd(Intercept) 0.06 0.07 0.00 0.21 1.00 1497
    > > > > 1843
    > > > > sd(hu_Intercept) 0.83 0.71 0.03 2.55 1.01 935
    > > > > 1469
    > > > >
    > > > > Population-Level Effects:
    > > > > Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
    > > > > Intercept -0.23 0.07 -0.38 -0.08 1.00 2159 1513
    > > > > hu_Intercept -1.04 0.66 -2.26 0.43 1.00 1832 2061
    > > > > block1 -0.06 0.06 -0.17 0.07 1.00 2394 1933
    > > > > syst1 -0.32 0.17 -0.64 0.03 1.00 1930 1487
    > > > > syst2 -0.11 0.12 -0.35 0.13 1.00 2023 1617
    > > > > syst3 0.18 0.11 -0.06 0.41 1.00 1724 1267
    > > > > syst4 0.08 0.12 -0.16 0.32 1.00 2222 1691
    > > > > hu_block1 0.36 0.60 -0.81 1.63 1.00 1658 1684
    > > > > hu_syst1 4.19 1.34 1.61 6.91 1.00 1236 1233
    > > > > hu_syst2 -0.09 1.17 -2.40 2.38 1.00 1266 1419
    > > > > hu_syst3 -1.98 1.30 -4.59 0.54 1.01 1183 1235
    > > > > hu_syst4 -0.52 1.23 -2.95 1.88 1.00 1170 1108
    > > > >
    > > > > Family Specific Parameters:
    > > > > Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
    > > > > sigma 0.48 0.02 0.44 0.52 1.00 2632 3025
    > > > >
    > > > > Samples were drawn using sampling(NUTS). For each parameter,
    > Eff.Sample
    > > > > is a crude measure of effective sample size, and Rhat is the
    > potential
    > > > > scale reduction factor on split chains (at convergence, Rhat = 1).
    > > > >
    > > > >
    > > > > I am currently struggling to obtain "syst" means averaged over blocks
    > > > (i.e.
    > > > > what would be done traditionally with emmeans(fit,~syst)) and to
    > > compare
    > > > > them pairwise.
    > > > >
    > > > > As of now, I am only capable of retrieving a mean for each
    > combination
    > > > of
    > > > > "syst" and "block" :
    > > > >
    > > > > newdata =
    > > > > expand.grid(syst=levels(density$syst),block=levels(density$block))
    > > > > means=fitted(fit,newdata,re_formula=NA,summary=TRUE)
    > > > > colnames(means)=c("fit","se","lwr","upr")
    > > > > df_plot=cbind(newdata,means)
    > > > >
    > > > > I am sure this must be simple, particularly with the hypothesis()
    > > > function
    > > > > but I am not sure how to include the "zero-non zero part" (i.e.
    > > hu_...).
    > > > >
    > > > > If anyone can foward some information on this, I would be eternally
    > > > > grateful (or even more should I say).
    > > > >
    > > > > Sincerely,
    > > > >
    > > > > Guillaume ADEUX
    > > > >
    > > > >
    > > > >
    > > > > Le ven. 20 d?c. 2019 ? 15:12, Ben Bolker <bbolker at gmail.com> a
    > ?crit :
    > > > >
    > > > > >
    > > > > > Good point.
    > > > > > This might be manageable in MCMCglmm or brms (or JAGS) ...
    > > > > >
    > > > > > On 2019-12-20 2:58 a.m., D. Rizopoulos wrote:
    > > > > > > For a hurdle model for repeated measurements data, the
    > dichotomous
    > > > > > outcome I(diversity > 0) is also a repeated measurements outcome.
    > > > Hence,
    > > > > in
    > > > > > the logistic regression model for this dichotomous outcome you will
    > > > need
    > > > > to
    > > > > > include random effects to account for the correlations. And it is
    > > > logical
    > > > > > to assume that the random effects from this logistic regression
    > model
    > > > > will
    > > > > > be correlated with the random effects of the linear mixed model for
    > > > only
    > > > > > the positive responses.
    > > > > > >
    > > > > > > In this case the likelihood of the two parts does not split in
    > two
    > > > > > functionally independent parts that can be separately maximized. If
    > > > this
    > > > > is
    > > > > > indeed the case, then fitting the two parts separately may cause
    > bias
    > > > and
    > > > > > loss of efficiency.
    > > > > > >
    > > > > > > Best,
    > > > > > > Dimitris
    > > > > > >
    > > > > > > ??
    > > > > > > Dimitris Rizopoulos
    > > > > > > Professor of Biostatistics
    > > > > > > Erasmus University Medical Center
    > > > > > > The Netherlands
    > > > > > >
    > > > > > > ________________________________
    > > > > > > From: R-sig-mixed-models <
    > r-sig-mixed-models-bounces at r-project.org
    > > >
    > > > on
    > > > > > behalf of Mollie Brooks <mollieebrooks at gmail.com>
    > > > > > > Sent: Wednesday, December 18, 2019 3:08 PM
    > > > > > > To: Help Mixed Models; Guillaume Adeux
    > > > > > > Subject: Re: [R-sig-ME] mixed lognormal hurdle model with
    > multiple
    > > > > > grouping factors
    > > > > > >
    > > > > > > Hi Guillaume,
    > > > > > >
    > > > > > > I don?t think the hurdle lognormal can be fit in a single
    > function
    > > > call
    > > > > > to glmmTMB since the model for the non-zero response requires
    > > > > > log-transforming the response. Other types of hurdle models could
    > be
    > > > fit
    > > > > in
    > > > > > glmmTMB using the zero-inflation model.
    > > > > > >
    > > > > > > I don?t think you gain much information in hurdle models by
    > > modeling
    > > > > the
    > > > > > two parts (zeros and non-zeros) in one function call. The only
    > > > potential
    > > > > > benefit to fitting a hurdle in a single function call is that you
    > get
    > > > > > likelihood and AIC for the entire data set, but I don?t know if
    > those
    > > > are
    > > > > > produced by brms.
    > > > > > >
    > > > > > > You could just fit a binomial model for the zero-non-zero process
    > > > (i.e.
    > > > > > monoculture) like
    > > > > > >
    > > > >
    > > mod_binom=lmer((diversity>0)~block+syst+(1|plot)+(1|year)+(1|plot:year),
    > > > > > data=density, family=binomial)
    > > > > > >
    > > > > > > and then fit a model to the log of the positive data
    > > > > > >
    > > > >
    > > mod_gaus=lmer(log(diversity)~block+syst+(1|plot)+(1|year)+(1|plot:year),
    > > > > > data=subset(density, diversity>0))
    > > > > > >
    > > > > > > Or, given that the outcome is non-negative and continuous, it
    > might
    > > > > make
    > > > > > sense to try a Tweedie distribution, but I?m not sure I?ve seen
    > this
    > > > > > applied to diversity indices in the literature. Has anyone else
    > seen
    > > > this
    > > > > > done?
    > > > > > > mod_twe =
    > > > glmmTMB(diversity~block+syst+(1|plot)+(1|year)+(1|plot:year),
    > > > > > data=density, family=tweedie)
    > > > > > >
    > > > > > > Cheers,
    > > > > > > Mollie
    > > > > > >
    > > > > > >> On 18Dec 2019, at 14:45, Cesko Voeten <
    > > c.c.voeten at hum.leidenuniv.nl>
    > > >
    > > > > > wrote:
    > > > > > >>
    > > > > > >> Hi Guillaume,
    > > > > > >>
    > > > > > >> If you're not afraid to go Bayesian, brms can do it.
    > > Alternatively,
    > > > > you
    > > > > > may be able to use glmmTMB and treat the hurdle part as zero
    > > > inflation,
    > > > > but
    > > > > > this is conceptually not the same thing as a hurdle model so you
    > > would
    > > > > need
    > > > > > to judge whether that would make sense at all for your application.
    > > > > > >>
    > > > > > >> HTH,
    > > > > > >> Cesko
    > > > > > >>
    > > > > > >> Op 18-12-2019 om 13:48 schreef Guillaume Adeux:
    > > > > > >>> Hi everyone,
    > > > > > >>> I am looking for a package which can handle "hurdle.lognormal"
    > > > > > distribution
    > > > > > >>> family and multiple grouping factors.
    > > > > > >>> GLMMadaptive seemed as the way to go but unfortunately, to the
    > > > best
    > > > > of
    > > > > > my
    > > > > > >>> knowledge, it does not handle multiple grouping factors (random
    > > > > > effects).
    > > > > > >>> You may ask why? I am analyzing plant diversity and one of the
    > > > > > treatments
    > > > > > >>> led to plots which were dominated by one species. Hence,
    > certain
    > > > > > diversity
    > > > > > >>> indices are estimated as zero in these plots, and produces a
    > mass
    > > > at
    > > > > > zero.
    > > > > > >>> All other values are positive and continuous.
    > > > > > >>> Anyone have an idea of a package/function which can handle
    > this?
    > > > Or
    > > > > any
    > > > > > >>> alternative approach?
    > > > > > >>> In lmer syntax, the model is the following:
    > > > > > >>>
    > > > > >
    > > > >
    > > >
    > >
    > mod=lmer(diversity~block+syst+(1|plot)+(1|year)+(1|plot:year),data=density,REML=F)
    > > >
    > > > > > >>> Thank you for your time and help.
    > > > > > >>> Sincerely,
    > > > > > >>> Guillaume ADEUX
    > > > > > >>> [[alternative HTML version deleted]]
    > > > > > >>> _______________________________________________
    > > > > > >>> R-sig-mixed-models at r-project.org mailing list
    > > > > > >>>
    > > > > >
    > > > >
    > > >
    > >
    > https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C94c75233c5084fb99c6908d787d3adf4%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637127215536371685&amp;sdata=PL6VOZ8Q9M5DQa8xp%2FrKKe%2FqXO%2BzE5sfMP%2FvxZr2jHE%3D&amp;reserved=0
    > > > > > >>>
    > > > > > >>
    > > > > > >> _______________________________________________
    > > > > > >> R-sig-mixed-models at r-project.org mailing list
    > > > > > >>
    > > > > >
    > > > >
    > > >
    > >
    > https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C94c75233c5084fb99c6908d787d3adf4%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637127215536371685&amp;sdata=PL6VOZ8Q9M5DQa8xp%2FrKKe%2FqXO%2BzE5sfMP%2FvxZr2jHE%3D&amp;reserved=0
    > > > > > >
    > > > > > > _______________________________________________
    > > > > > > R-sig-mixed-models at r-project.org mailing list
    > > > > > >
    > > > > >
    > > > >
    > > >
    > >
    > https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C94c75233c5084fb99c6908d787d3adf4%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637127215536381676&amp;sdata=YRc7r3Ni5P345YiPoEuNhmhmte20pMrIb3ojmkmY6qA%3D&amp;reserved=0
    > > > > > >
    > > > > > > [[alternative HTML version deleted]]
    > > > > > >
    > > > > > >
    > > > > > > _______________________________________________
    > > > > > > R-sig-mixed-models at r-project.org mailing list
    > > > > > >
    > > >
    > >
    > https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C94c75233c5084fb99c6908d787d3adf4%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637127215536381676&amp;sdata=YRc7r3Ni5P345YiPoEuNhmhmte20pMrIb3ojmkmY6qA%3D&amp;reserved=0
    > > > > > >
    > > > > >
    > > > > > _______________________________________________
    > > > > > R-sig-mixed-models at r-project.org mailing list
    > > > > >
    > > >
    > >
    > https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C94c75233c5084fb99c6908d787d3adf4%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637127215536381676&amp;sdata=YRc7r3Ni5P345YiPoEuNhmhmte20pMrIb3ojmkmY6qA%3D&amp;reserved=0
    > > > > >
    > > > >
    > > > > [[alternative HTML version deleted]]
    > > > >
    > > > > _______________________________________________
    > > > > R-sig-mixed-models at r-project.org mailing list
    > > > >
    > > >
    > >
    > https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C94c75233c5084fb99c6908d787d3adf4%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637127215536381676&amp;sdata=YRc7r3Ni5P345YiPoEuNhmhmte20pMrIb3ojmkmY6qA%3D&amp;reserved=0
    > > > >
    > > >
    > > > [[alternative HTML version deleted]]
    > > >
    > > > _______________________________________________
    > > > R-sig-mixed-models at r-project.org mailing list
    > > >
    > > >
    > >
    > https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C94c75233c5084fb99c6908d787d3adf4%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637127215536381676&amp;sdata=YRc7r3Ni5P345YiPoEuNhmhmte20pMrIb3ojmkmY6qA%3D&amp;reserved=0
    > > >
    > >
    > >         [[alternative HTML version deleted]]
    > >
    > > _______________________________________________
    > > R-sig-mixed-models at r-project.org mailing list
    > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
    > >
    > --
    > --
    > Daniel Fulop, Ph.D.
    > Postdoctoral Scholar
    > Dept. Plant Biology, UC Davis
    > Maloof Lab, Rm. 2220
    > Life Sciences Addition, One Shields Ave.
    > Davis, CA 95616
    >
    > 510-253-7462
    > dfulop at ucdavis.edu
    >
    >         [[alternative HTML version deleted]]
    >
    > _______________________________________________
    > R-sig-mixed-models at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
    >
    
    	[[alternative HTML version deleted]]
    
    _______________________________________________
    R-sig-mixed-models at r-project.org mailing list
    https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
    


From john@m@|ndon@|d @end|ng |rom @nu@edu@@u  Wed Dec 25 02:16:10 2019
From: john@m@|ndon@|d @end|ng |rom @nu@edu@@u (John Maindonald)
Date: Wed, 25 Dec 2019 01:16:10 +0000
Subject: [R-sig-ME] A consultation about lmer -- normality assumptions
In-Reply-To: <CAJuCY5ydpc4JOsVgL8kkc7JpAUY0Q0=xqQSUAaD-BEqJ7ViKZA@mail.gmail.com>
References: <11cee80.1101f.16f23be0872.Coremail.18754808835@163.com>
 <CAJuCY5ydpc4JOsVgL8kkc7JpAUY0Q0=xqQSUAaD-BEqJ7ViKZA@mail.gmail.com>
Message-ID: <A76FAB53-B219-47A4-853F-9AC102DA4B9A@anu.edu.au>

It is also assumed that the random effects are normally distributed.  Depending
on the relative magnitude of the variance components, and on the relative
contributions to the variance of the statistic that is of interest.  Where there are
a small number of random effects (alias BLUPs), normality can be a much more
serious matter for them than for the residuals, because there is less opportunity
for the Central Limit Theorem to kick in.

Unbalance in the data can make it quite a bit harder to check the relevant set(s)
of random effects for normality.  One may need to resort  to simulation.

John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>


On 24/12/2019, at 23:24, Thierry Onkelinx via R-sig-mixed-models <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>> wrote:

Dear anonymous,

The assumption of normality is on the residuals, not on the observations.
The assumption holds reasonably for the sleepstudy, except for a few
outliers.

library(lme4)
fm1 <- lmer(Reaction ~ Days + (Days | Subject), sleepstudy)
qqnorm(residuals(fm1))

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op ma 23 dec. 2019 om 17:36 schreef ??? <18754808835 at 163.com>:

I have some confusion about the use of lmer. As I learned the data
should  be normal distributed when use liner mixed model. I tested the
exmple  data (Reaction$sleepstudy) by using shapiro.test. The result shows
that  it was not normal distributed.  So I have some confusion about the
requirment of data distribution in function lmer and glmmer.
       [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From john@m@|ndon@|d @end|ng |rom @nu@edu@@u  Thu Dec 26 19:23:12 2019
From: john@m@|ndon@|d @end|ng |rom @nu@edu@@u (John Maindonald)
Date: Thu, 26 Dec 2019 18:23:12 +0000
Subject: [R-sig-ME] A consultation about lmer -- normality assumptions
In-Reply-To: <A76FAB53-B219-47A4-853F-9AC102DA4B9A@anu.edu.au>
References: <11cee80.1101f.16f23be0872.Coremail.18754808835@163.com>
 <CAJuCY5ydpc4JOsVgL8kkc7JpAUY0Q0=xqQSUAaD-BEqJ7ViKZA@mail.gmail.com>
 <A76FAB53-B219-47A4-853F-9AC102DA4B9A@anu.edu.au>
Message-ID: <8A3247A6-E770-4749-A664-9D382C442A81@anu.edu.au>

Re checking normality, note that lattice::qqmath() has methods both for plotting residuals
and for plotting random effects.

library(lme4)                            ## for lmer(), sleepstudy
library(lattice)                         ## for dotplot()
ss.lmer <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
qqmath(ss.lmer)                                         ## Normal probability plot of residuals
qqmath(ranef(ss.lmer, condVar=TRUE))    ## Random effects with 1 SD limits, axes are reversed
qqmath(ranef(ss.lmer, condVar=FALSE))   ## Random effects with 1 SD limits, axes as usual

See ?qqmath.merMod and ?qqmath.ranef.mer for details.

NB also the discussion at:

https://stackoverflow.com/questions/13847936/plot-random-effects-from-lmer-lme4-package-using-qqmath-or-dotplot-how-to-mak?r=SearchResults&s=1|132.5021<https://stackoverflow.com/questions/13847936/plot-random-effects-from-lmer-lme4-package-using-qqmath-or-dotplot-how-to-mak?r=SearchResults&s=1%7C132.5021>

The key question has still to be addressed: Are departures from normality likely to be of sufficient
consequence to matter for purposes of the use that will be made of the analysis?  Checks for
normality may be just the first, relatively easy, step!

John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>

On 25/12/2019, at 14:16, John Maindonald <john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>> wrote:

It is also assumed that the random effects are normally distributed.  Depending
on the relative magnitude of the variance components, and on the relative
contributions to the variance of the statistic that is of interest [, this may or may
not be the greater reason for concern].  Where there are
a small number of random effects (alias BLUPs), normality can be a much more
serious matter for them than for the residuals, because there is less opportunity
for the Central Limit Theorem to kick in.

Unbalance in the data can make it quite a bit harder to check the relevant set(s)
of random effects for normality.  One may need to resort  to simulation.

John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au><mailto:john.maindonald at anu.edu.au>


On 24/12/2019, at 23:24, Thierry Onkelinx via R-sig-mixed-models <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org><mailto:r-sig-mixed-models at r-project.org>> wrote:

Dear anonymous,

The assumption of normality is on the residuals, not on the observations.
The assumption holds reasonably for the sleepstudy, except for a few
outliers.

library(lme4)
fm1 <- lmer(Reaction ~ Days + (Days | Subject), sleepstudy)
qqnorm(residuals(fm1))

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be><mailto:thierry.onkelinx at inbo.be>
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be<http://www.inbo.be>

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op ma 23 dec. 2019 om 17:36 schreef ??? <18754808835 at 163.com<mailto:18754808835 at 163.com>>:

I have some confusion about the use of lmer. As I learned the data
should  be normal distributed when use liner mixed model. I tested the
exmple  data (Reaction$sleepstudy) by using shapiro.test. The result shows
that  it was not normal distributed.  So I have some confusion about the
requirment of data distribution in function lmer and glmmer.
      [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


