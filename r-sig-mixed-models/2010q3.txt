From hypergeometric at mensakorea.org  Thu Jul  1 08:31:19 2010
From: hypergeometric at mensakorea.org (Kyuho Jin)
Date: Thu, 1 Jul 2010 15:31:19 +0900
Subject: [R-sig-ME] MCMCglmm with a fairly large sample size
Message-ID: <AANLkTikJTNMwE3Lpd2271GFdp_mbctWW8OnR7SkM9GiN@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100701/44e0ecd4/attachment.pl>

From edeline at biologie.ens.fr  Thu Jul  1 14:40:20 2010
From: edeline at biologie.ens.fr (Eric Edeline)
Date: Thu, 01 Jul 2010 14:40:20 +0200
Subject: [R-sig-ME] Model selection with gamm
Message-ID: <4C2C8CB4.5000309@biologie.ens.fr>

Dear list,

I am doing model selection with gamm (Gamma GAM with AR1 autocorrelation 
calling to glmmPQL) but do not really know how to proceed. I have no 
random effect in my model. Would anybody have some tips?

Thanks!

Eric Edeline
Assistant Professor
UMR 7618 BIOEMCO
Ecole Normale Sup?rieure
46 rue d'Ulm
75230 Paris cedex 05
France

Tel: +33 (0)1 44 32 38 84
Fax: +33 (0)1 44 32 38 85

http://www.biologie.ens.fr/bioemco/biodiversite/edeline.html



From Jeffrey.Evans at dartmouth.edu  Thu Jul  1 18:03:52 2010
From: Jeffrey.Evans at dartmouth.edu (Jeffrey Evans)
Date: Thu, 1 Jul 2010 12:03:52 -0400
Subject: [R-sig-ME] different aic and LL in glmer(lme4) and glimmix(SAS)?
Message-ID: <AE3EE86B200D463A9CD2A99C04201D22@Animal>

Hello All,
 
I have read several posts related to this previously, but haven't found any
resolution yet. When running the same GLMM in glmer and in SAS PROC GLIMMIX,
both programs return comparable parameter estimates, but wildly different
likelihoods and AIC values.

In SAS I specify use of the Laplace approximation. In R, I believe this is
the default (no?).

What's the difference, and [how] can I reproduce the SAS -2ll in glmer?

Thanks,
Jeff
 
\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/
> R_GLMM = glmer(cbind(SdlFinal, SdlMax-SdlFinal) ~ lnsdlmaxd*lnadultssdld +
 (1|ID),data=sdlPCAdat,family="binomial")
> R_GLMM
Generalized linear mixed model fit by the Laplace approximation 
Formula: cbind(SdlFinal, SdlMax - SdlFinal) ~ lnsdlmaxd * lnadultssdld +
(1 | ID) 
   Data: sdlPCAdat 
  AIC  BIC logLik deviance
 1150 1165   -570     1140        <------------------ this line!!
Random effects:
 Groups Name        Variance Std.Dev.
 ID     (Intercept) 1.2491   1.1176  
Number of obs: 144, groups: ID, 48
 
Fixed effects:
                       Estimate Std. Error z value Pr(>|z|)    
(Intercept)             4.56964    0.43148  10.591  < 2e-16 ***
lnsdlmaxd              -0.65936    0.05686 -11.595  < 2e-16 ***
lnadultssdld           -0.64534    0.15861  -4.069 4.73e-05 ***
lnsdlmaxd:lnadultssdld  0.07393    0.02166   3.414  0.00064 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
 
Correlation of Fixed Effects:
            (Intr) lnsdlm lndlts
lnsdlmaxd   -0.923              
lnadltssdld -0.461  0.479       
lnsdlmxd:ln  0.482 -0.508 -0.994

 
 \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/
title 'SAS GLMM';
proc glimmix data=sdlPCAdat ic=pq noitprint method=laplace;
class site id;
model sdlfinal/sdlmax = lnsdlmaxd|lnadultssdld/ solution dist=binomial;
random ID /;
covtest glm/wald;
run;

//////////////////////////////////////////////////////////////////////

                      SAS GLMM      19:36 Wednesday, June 30, 2010 88

                   The GLIMMIX Procedure

            Data Set           WORK.SDLPCADAT
            Response Variable (Events)  SdlFinal
            Response Variable (Trials)  SdlMax
            Response Distribution     Binomial
            Link Function         Logit
            Variance Function       Default
            Variance Matrix        Not blocked
            Estimation Technique     Maximum Likelihood
            Likelihood Approximation   Laplace
            Degrees of Freedom Method   Containment



                  Optimization Information

             Optimization Technique    Dual Quasi-Newton
             Parameters in Optimization  5
             Lower Boundaries       1
             Upper Boundaries       0
             Fixed Effects         Not Profiled
             Starting From         GLM estimates

             Convergence criterion (GCONV=1E-8) satisfied.

                     Fit Statistics

               -2 Log Likelihood        1653.90  <------------------ this
line!!
               AIC (smaller is better)  1663.90
               AICC (smaller is better) 1664.33
               BIC (smaller is better)  1673.25
               CAIC (smaller is better) 1678.25
               HQIC (smaller is better) 1667.43


              Fit Statistics for Conditional Distribution

              -2 log L(SdlFinal | r. effects)   1436.44
              Pearson Chi-Square          908.07
              Pearson Chi-Square / DF        6.31


                 Covariance Parameter Estimates

            Cov         Standard     Z
            Parm  Estimate    Error   Value   Pr > Z

            ID    1.2491   0.2746   4.55   <.0001


                 Solutions for Fixed Effects

                              Standard
     Effect         Estimate    Error    DF  t Value  Pr > |t|

     Intercept           4.5696   0.4333    47    10.55  <.0001
     lnsdlmaxd          -0.6594   0.05717   93   -11.53  <.0001
     lnadultssdld       -0.6453   0.1593    93   -4.05   0.0001
     lnsdlmaxd*lnadultssd0.07394  0.02174   93    3.40   0.0010



From andyfugard at gmail.com  Thu Jul  1 18:15:54 2010
From: andyfugard at gmail.com (Andy Fugard)
Date: Thu, 1 Jul 2010 18:15:54 +0200
Subject: [R-sig-ME] different aic and LL in glmer(lme4) and glimmix(SAS)?
In-Reply-To: <AE3EE86B200D463A9CD2A99C04201D22@Animal>
References: <AE3EE86B200D463A9CD2A99C04201D22@Animal>
Message-ID: <AANLkTinPz4Now_QLJwhHEwGjD50ShtinzoVZ7ZbTqLtA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100701/0443bad1/attachment.pl>

From bates at stat.wisc.edu  Thu Jul  1 18:24:17 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 1 Jul 2010 11:24:17 -0500
Subject: [R-sig-ME] different aic and LL in glmer(lme4) and glimmix(SAS)?
In-Reply-To: <AE3EE86B200D463A9CD2A99C04201D22@Animal>
References: <AE3EE86B200D463A9CD2A99C04201D22@Animal>
Message-ID: <AANLkTikF0nrxn6QGxDRFhMZHunfrtxruhC1a3G6r5KEA@mail.gmail.com>

On Thu, Jul 1, 2010 at 11:03 AM, Jeffrey Evans
<Jeffrey.Evans at dartmouth.edu> wrote:
> Hello All,

> I have read several posts related to this previously, but haven't found any
> resolution yet. When running the same GLMM in glmer and in SAS PROC GLIMMIX,
> both programs return comparable parameter estimates, but wildly different
> likelihoods and AIC values.

> In SAS I specify use of the Laplace approximation. In R, I believe this is
> the default (no?).

> What's the difference, and [how] can I reproduce the SAS -2ll in glmer?

The difference is probably due to the way that the deviance is defined
for the binomial family in R.  A glm family object is a list of
functions and expressions.  One of the functions, called "dev.resids"
has arguments y, mu and weights.  You can specify the response for a
binomial family as the 0/1 responses or as a matrix with two columns
as you did here.  When you use the two column specification the
response y is transformed to the fraction of successes and the number
of cases is incorporated in the weights.  It turns out that this is
all the information necessary for obtaining the mle's of the
parameters but it does not give the same deviance as you would get by
listing the 0/1 responses.

I'll write an example using the cbpp data from the lme4 package.
> Thanks,
> Jeff
>
> \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/
>> R_GLMM = glmer(cbind(SdlFinal, SdlMax-SdlFinal) ~ lnsdlmaxd*lnadultssdld +
> ?(1|ID),data=sdlPCAdat,family="binomial")
>> R_GLMM
> Generalized linear mixed model fit by the Laplace approximation
> Formula: cbind(SdlFinal, SdlMax - SdlFinal) ~ lnsdlmaxd * lnadultssdld +
> (1 | ID)
> ? Data: sdlPCAdat
> ?AIC ?BIC logLik deviance
> ?1150 1165 ? -570 ? ? 1140 ? ? ? ?<------------------ this line!!
> Random effects:
> ?Groups Name ? ? ? ?Variance Std.Dev.
> ?ID ? ? (Intercept) 1.2491 ? 1.1176
> Number of obs: 144, groups: ID, 48
>
> Fixed effects:
> ? ? ? ? ? ? ? ? ? ? ? Estimate Std. Error z value Pr(>|z|)
> (Intercept) ? ? ? ? ? ? 4.56964 ? ?0.43148 ?10.591 ?< 2e-16 ***
> lnsdlmaxd ? ? ? ? ? ? ?-0.65936 ? ?0.05686 -11.595 ?< 2e-16 ***
> lnadultssdld ? ? ? ? ? -0.64534 ? ?0.15861 ?-4.069 4.73e-05 ***
> lnsdlmaxd:lnadultssdld ?0.07393 ? ?0.02166 ? 3.414 ?0.00064 ***
> ---
> Signif. codes: ?0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
> Correlation of Fixed Effects:
> ? ? ? ? ? ?(Intr) lnsdlm lndlts
> lnsdlmaxd ? -0.923
> lnadltssdld -0.461 ?0.479
> lnsdlmxd:ln ?0.482 -0.508 -0.994
>
>
> ?\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/
> title 'SAS GLMM';
> proc glimmix data=sdlPCAdat ic=pq noitprint method=laplace;
> class site id;
> model sdlfinal/sdlmax = lnsdlmaxd|lnadultssdld/ solution dist=binomial;
> random ID /;
> covtest glm/wald;
> run;
>
> //////////////////////////////////////////////////////////////////////
>
> ? ? ? ? ? ? ? ? ? ? ?SAS GLMM ? ? ?19:36 Wednesday, June 30, 2010 88
>
> ? ? ? ? ? ? ? ? ? The GLIMMIX Procedure
>
> ? ? ? ? ? ?Data Set ? ? ? ? ? WORK.SDLPCADAT
> ? ? ? ? ? ?Response Variable (Events) ?SdlFinal
> ? ? ? ? ? ?Response Variable (Trials) ?SdlMax
> ? ? ? ? ? ?Response Distribution ? ? Binomial
> ? ? ? ? ? ?Link Function ? ? ? ? Logit
> ? ? ? ? ? ?Variance Function ? ? ? Default
> ? ? ? ? ? ?Variance Matrix ? ? ? ?Not blocked
> ? ? ? ? ? ?Estimation Technique ? ? Maximum Likelihood
> ? ? ? ? ? ?Likelihood Approximation ? Laplace
> ? ? ? ? ? ?Degrees of Freedom Method ? Containment
>
>
>
> ? ? ? ? ? ? ? ? ?Optimization Information
>
> ? ? ? ? ? ? Optimization Technique ? ?Dual Quasi-Newton
> ? ? ? ? ? ? Parameters in Optimization ?5
> ? ? ? ? ? ? Lower Boundaries ? ? ? 1
> ? ? ? ? ? ? Upper Boundaries ? ? ? 0
> ? ? ? ? ? ? Fixed Effects ? ? ? ? Not Profiled
> ? ? ? ? ? ? Starting From ? ? ? ? GLM estimates
>
> ? ? ? ? ? ? Convergence criterion (GCONV=1E-8) satisfied.
>
> ? ? ? ? ? ? ? ? ? ? Fit Statistics
>
> ? ? ? ? ? ? ? -2 Log Likelihood ? ? ? ?1653.90 ?<------------------ this
> line!!
> ? ? ? ? ? ? ? AIC (smaller is better) ?1663.90
> ? ? ? ? ? ? ? AICC (smaller is better) 1664.33
> ? ? ? ? ? ? ? BIC (smaller is better) ?1673.25
> ? ? ? ? ? ? ? CAIC (smaller is better) 1678.25
> ? ? ? ? ? ? ? HQIC (smaller is better) 1667.43
>
>
> ? ? ? ? ? ? ?Fit Statistics for Conditional Distribution
>
> ? ? ? ? ? ? ?-2 log L(SdlFinal | r. effects) ? 1436.44
> ? ? ? ? ? ? ?Pearson Chi-Square ? ? ? ? ?908.07
> ? ? ? ? ? ? ?Pearson Chi-Square / DF ? ? ? ?6.31
>
>
> ? ? ? ? ? ? ? ? Covariance Parameter Estimates
>
> ? ? ? ? ? ?Cov ? ? ? ? Standard ? ? Z
> ? ? ? ? ? ?Parm ?Estimate ? ?Error ? Value ? Pr > Z
>
> ? ? ? ? ? ?ID ? ?1.2491 ? 0.2746 ? 4.55 ? <.0001
>
>
> ? ? ? ? ? ? ? ? Solutions for Fixed Effects
>
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Standard
> ? ? Effect ? ? ? ? Estimate ? ?Error ? ?DF ?t Value ?Pr > |t|
>
> ? ? Intercept ? ? ? ? ? 4.5696 ? 0.4333 ? ?47 ? ?10.55 ?<.0001
> ? ? lnsdlmaxd ? ? ? ? ?-0.6594 ? 0.05717 ? 93 ? -11.53 ?<.0001
> ? ? lnadultssdld ? ? ? -0.6453 ? 0.1593 ? ?93 ? -4.05 ? 0.0001
> ? ? lnsdlmaxd*lnadultssd0.07394 ?0.02174 ? 93 ? ?3.40 ? 0.0010
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From Jeffrey.Evans at dartmouth.edu  Thu Jul  1 18:26:32 2010
From: Jeffrey.Evans at dartmouth.edu (Jeffrey Evans)
Date: Thu, 1 Jul 2010 12:26:32 -0400
Subject: [R-sig-ME] different aic and LL in glmer(lme4) and glimmix(SAS)?
In-Reply-To: <AANLkTinPz4Now_QLJwhHEwGjD50ShtinzoVZ7ZbTqLtA@mail.gmail.com>
References: <AE3EE86B200D463A9CD2A99C04201D22@Animal>
	<AANLkTinPz4Now_QLJwhHEwGjD50ShtinzoVZ7ZbTqLtA@mail.gmail.com>
Message-ID: <4413C904170446FEA305BA04DFB30F82@Animal>

Good question.
 
They are similar
 
Compare models with nested fixed effects structures
Full model = lnsdlmaxd + lnadultssdld + lnsdlmaxd:lnadultssdld
Reduced model = lnsdlmaxd + lnadultssdld

AIC		R		SAS
Full		1150		1663.9
Reduced	1159		1673.4
-------------------------------
deltaAIC	9		9.5


________________________________

From: almost at gmail.com [mailto:almost at gmail.com] On Behalf Of Andy Fugard
Sent: Thursday, July 01, 2010 12:16 PM
To: Jeffrey Evans
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] different aic and LL in glmer(lme4) and
glimmix(SAS)?


Hi Jeff, 

Can't answer the question, but out of interest, what happens when you
compare nested models in R and SAS, e.g., models with and without the
lnsdlmaxd:lnadultssdld interaction?  Would be interesting to see the
log-likehood ratio (and maybe /change/ in AIC and BIC between the models).

Cheers,

Andy


On Thu, Jul 1, 2010 at 18:03, Jeffrey Evans <Jeffrey.Evans at dartmouth.edu>
wrote:


	Hello All,
	
	I have read several posts related to this previously, but haven't
found any
	resolution yet. When running the same GLMM in glmer and in SAS PROC
GLIMMIX,
	both programs return comparable parameter estimates, but wildly
different
	likelihoods and AIC values.
	
	In SAS I specify use of the Laplace approximation. In R, I believe
this is
	the default (no?).
	
	What's the difference, and [how] can I reproduce the SAS -2ll in
glmer?
	
	Thanks,
	Jeff
	
	\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/
	> R_GLMM = glmer(cbind(SdlFinal, SdlMax-SdlFinal) ~
lnsdlmaxd*lnadultssdld +
	 (1|ID),data=sdlPCAdat,family="binomial")
	> R_GLMM
	Generalized linear mixed model fit by the Laplace approximation
	Formula: cbind(SdlFinal, SdlMax - SdlFinal) ~ lnsdlmaxd *
lnadultssdld +
	(1 | ID)
	  Data: sdlPCAdat
	 AIC  BIC logLik deviance
	 1150 1165   -570     1140        <------------------ this line!!
	Random effects:
	 Groups Name        Variance Std.Dev.
	 ID     (Intercept) 1.2491   1.1176
	Number of obs: 144, groups: ID, 48
	
	Fixed effects:
	                      Estimate Std. Error z value Pr(>|z|)
	(Intercept)             4.56964    0.43148  10.591  < 2e-16 ***
	lnsdlmaxd              -0.65936    0.05686 -11.595  < 2e-16 ***
	lnadultssdld           -0.64534    0.15861  -4.069 4.73e-05 ***
	lnsdlmaxd:lnadultssdld  0.07393    0.02166   3.414  0.00064 ***
	---
	Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
	
	Correlation of Fixed Effects:
	           (Intr) lnsdlm lndlts
	lnsdlmaxd   -0.923
	lnadltssdld -0.461  0.479
	lnsdlmxd:ln  0.482 -0.508 -0.994
	
	
	 \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/
	title 'SAS GLMM';
	proc glimmix data=sdlPCAdat ic=pq noitprint method=laplace;
	class site id;
	model sdlfinal/sdlmax = lnsdlmaxd|lnadultssdld/ solution
dist=binomial;
	random ID /;
	covtest glm/wald;
	run;
	
	
//////////////////////////////////////////////////////////////////////
	
	                     SAS GLMM      19:36 Wednesday, June 30, 2010 88
	
	                  The GLIMMIX Procedure
	
	           Data Set           WORK.SDLPCADAT
	           Response Variable (Events)  SdlFinal
	           Response Variable (Trials)  SdlMax
	           Response Distribution     Binomial
	           Link Function         Logit
	           Variance Function       Default
	           Variance Matrix        Not blocked
	           Estimation Technique     Maximum Likelihood
	           Likelihood Approximation   Laplace
	           Degrees of Freedom Method   Containment
	
	
	
	                 Optimization Information
	
	            Optimization Technique    Dual Quasi-Newton
	            Parameters in Optimization  5
	            Lower Boundaries       1
	            Upper Boundaries       0
	            Fixed Effects         Not Profiled
	            Starting From         GLM estimates
	
	            Convergence criterion (GCONV=1E-8) satisfied.
	
	                    Fit Statistics
	
	              -2 Log Likelihood        1653.90  <------------------
this
	line!!
	              AIC (smaller is better)  1663.90
	              AICC (smaller is better) 1664.33
	              BIC (smaller is better)  1673.25
	              CAIC (smaller is better) 1678.25
	              HQIC (smaller is better) 1667.43
	
	
	             Fit Statistics for Conditional Distribution
	
	             -2 log L(SdlFinal | r. effects)   1436.44
	             Pearson Chi-Square          908.07
	             Pearson Chi-Square / DF        6.31
	
	
	                Covariance Parameter Estimates
	
	           Cov         Standard     Z
	           Parm  Estimate    Error   Value   Pr > Z
	
	           ID    1.2491   0.2746   4.55   <.0001
	
	
	                Solutions for Fixed Effects
	
	                             Standard
	    Effect         Estimate    Error    DF  t Value  Pr > |t|
	
	    Intercept           4.5696   0.4333    47    10.55  <.0001
	    lnsdlmaxd          -0.6594   0.05717   93   -11.53  <.0001
	    lnadultssdld       -0.6453   0.1593    93   -4.05   0.0001
	    lnsdlmaxd*lnadultssd0.07394  0.02174   93    3.40   0.0010
	
	_______________________________________________
	R-sig-mixed-models at r-project.org mailing list
	https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From Jeffrey.Evans at dartmouth.edu  Thu Jul  1 18:35:57 2010
From: Jeffrey.Evans at dartmouth.edu (Jeffrey Evans)
Date: Thu, 1 Jul 2010 12:35:57 -0400
Subject: [R-sig-ME] different aic and LL in glmer(lme4) and glimmix(SAS)?
In-Reply-To: <AANLkTikF0nrxn6QGxDRFhMZHunfrtxruhC1a3G6r5KEA@mail.gmail.com>
References: <AE3EE86B200D463A9CD2A99C04201D22@Animal>
	<AANLkTikF0nrxn6QGxDRFhMZHunfrtxruhC1a3G6r5KEA@mail.gmail.com>
Message-ID: <0425A639C6224D23A0D926D8D61ECF34@Animal>

I see. Thank you for the clarification.  


I did just try lme4 on a[n expanded] binary version of the same data, but
the numbers are still not coming out the same as in SAS.

No matter. The deltaAIC values are the same, so I am content that they are
doing similar things.

Cheers,
Jeff


-----Original Message-----
From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf Of Douglas
Bates
Sent: Thursday, July 01, 2010 12:24 PM
To: Jeffrey Evans
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] different aic and LL in glmer(lme4) and
glimmix(SAS)?

On Thu, Jul 1, 2010 at 11:03 AM, Jeffrey Evans <Jeffrey.Evans at dartmouth.edu>
wrote:
> Hello All,

> I have read several posts related to this previously, but haven't 
> found any resolution yet. When running the same GLMM in glmer and in 
> SAS PROC GLIMMIX, both programs return comparable parameter estimates, 
> but wildly different likelihoods and AIC values.

> In SAS I specify use of the Laplace approximation. In R, I believe 
> this is the default (no?).

> What's the difference, and [how] can I reproduce the SAS -2ll in glmer?

The difference is probably due to the way that the deviance is defined for
the binomial family in R.  A glm family object is a list of functions and
expressions.  One of the functions, called "dev.resids"
has arguments y, mu and weights.  You can specify the response for a
binomial family as the 0/1 responses or as a matrix with two columns as you
did here.  When you use the two column specification the response y is
transformed to the fraction of successes and the number of cases is
incorporated in the weights.  It turns out that this is all the information
necessary for obtaining the mle's of the parameters but it does not give the
same deviance as you would get by listing the 0/1 responses.

I'll write an example using the cbpp data from the lme4 package.
> Thanks,
> Jeff
>
> \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/
>> R_GLMM = glmer(cbind(SdlFinal, SdlMax-SdlFinal) ~ 
>> lnsdlmaxd*lnadultssdld +
> ?(1|ID),data=sdlPCAdat,family="binomial")
>> R_GLMM
> Generalized linear mixed model fit by the Laplace approximation
> Formula: cbind(SdlFinal, SdlMax - SdlFinal) ~ lnsdlmaxd * lnadultssdld 
> +
> (1 | ID)
> ? Data: sdlPCAdat
> ?AIC ?BIC logLik deviance
> ?1150 1165 ? -570 ? ? 1140 ? ? ? ?<------------------ this line!!
> Random effects:
> ?Groups Name ? ? ? ?Variance Std.Dev.
> ?ID ? ? (Intercept) 1.2491 ? 1.1176
> Number of obs: 144, groups: ID, 48
>
> Fixed effects:
> ? ? ? ? ? ? ? ? ? ? ? Estimate Std. Error z value Pr(>|z|)
> (Intercept) ? ? ? ? ? ? 4.56964 ? ?0.43148 ?10.591 ?< 2e-16 *** 
> lnsdlmaxd ? ? ? ? ? ? ?-0.65936 ? ?0.05686 -11.595 ?< 2e-16 *** 
> lnadultssdld ? ? ? ? ? -0.64534 ? ?0.15861 ?-4.069 4.73e-05 *** 
> lnsdlmaxd:lnadultssdld ?0.07393 ? ?0.02166 ? 3.414 ?0.00064 ***
> ---
> Signif. codes: ?0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
> Correlation of Fixed Effects:
> ? ? ? ? ? ?(Intr) lnsdlm lndlts
> lnsdlmaxd ? -0.923
> lnadltssdld -0.461 ?0.479
> lnsdlmxd:ln ?0.482 -0.508 -0.994
>
>
> ?\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/
> title 'SAS GLMM';
> proc glimmix data=sdlPCAdat ic=pq noitprint method=laplace; class site 
> id; model sdlfinal/sdlmax = lnsdlmaxd|lnadultssdld/ solution 
> dist=binomial; random ID /; covtest glm/wald; run;
>
> //////////////////////////////////////////////////////////////////////
>
> ? ? ? ? ? ? ? ? ? ? ?SAS GLMM ? ? ?19:36 Wednesday, June 30, 2010 88
>
> ? ? ? ? ? ? ? ? ? The GLIMMIX Procedure
>
> ? ? ? ? ? ?Data Set ? ? ? ? ? WORK.SDLPCADAT
> ? ? ? ? ? ?Response Variable (Events) ?SdlFinal
> ? ? ? ? ? ?Response Variable (Trials) ?SdlMax
> ? ? ? ? ? ?Response Distribution ? ? Binomial
> ? ? ? ? ? ?Link Function ? ? ? ? Logit
> ? ? ? ? ? ?Variance Function ? ? ? Default
> ? ? ? ? ? ?Variance Matrix ? ? ? ?Not blocked
> ? ? ? ? ? ?Estimation Technique ? ? Maximum Likelihood
> ? ? ? ? ? ?Likelihood Approximation ? Laplace
> ? ? ? ? ? ?Degrees of Freedom Method ? Containment
>
>
>
> ? ? ? ? ? ? ? ? ?Optimization Information
>
> ? ? ? ? ? ? Optimization Technique ? ?Dual Quasi-Newton
> ? ? ? ? ? ? Parameters in Optimization ?5
> ? ? ? ? ? ? Lower Boundaries ? ? ? 1
> ? ? ? ? ? ? Upper Boundaries ? ? ? 0
> ? ? ? ? ? ? Fixed Effects ? ? ? ? Not Profiled
> ? ? ? ? ? ? Starting From ? ? ? ? GLM estimates
>
> ? ? ? ? ? ? Convergence criterion (GCONV=1E-8) satisfied.
>
> ? ? ? ? ? ? ? ? ? ? Fit Statistics
>
> ? ? ? ? ? ? ? -2 Log Likelihood ? ? ? ?1653.90 ?<------------------ 
> this line!!
> ? ? ? ? ? ? ? AIC (smaller is better) ?1663.90
> ? ? ? ? ? ? ? AICC (smaller is better) 1664.33
> ? ? ? ? ? ? ? BIC (smaller is better) ?1673.25
> ? ? ? ? ? ? ? CAIC (smaller is better) 1678.25
> ? ? ? ? ? ? ? HQIC (smaller is better) 1667.43
>
>
> ? ? ? ? ? ? ?Fit Statistics for Conditional Distribution
>
> ? ? ? ? ? ? ?-2 log L(SdlFinal | r. effects) ? 1436.44
> ? ? ? ? ? ? ?Pearson Chi-Square ? ? ? ? ?908.07
> ? ? ? ? ? ? ?Pearson Chi-Square / DF ? ? ? ?6.31
>
>
> ? ? ? ? ? ? ? ? Covariance Parameter Estimates
>
> ? ? ? ? ? ?Cov ? ? ? ? Standard ? ? Z
> ? ? ? ? ? ?Parm ?Estimate ? ?Error ? Value ? Pr > Z
>
> ? ? ? ? ? ?ID ? ?1.2491 ? 0.2746 ? 4.55 ? <.0001
>
>
> ? ? ? ? ? ? ? ? Solutions for Fixed Effects
>
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Standard
> ? ? Effect ? ? ? ? Estimate ? ?Error ? ?DF ?t Value ?Pr > |t|
>
> ? ? Intercept ? ? ? ? ? 4.5696 ? 0.4333 ? ?47 ? ?10.55 ?<.0001
> ? ? lnsdlmaxd ? ? ? ? ?-0.6594 ? 0.05717 ? 93 ? -11.53 ?<.0001
> ? ? lnadultssdld ? ? ? -0.6453 ? 0.1593 ? ?93 ? -4.05 ? 0.0001
> ? ? lnsdlmaxd*lnadultssd0.07394 ?0.02174 ? 93 ? ?3.40 ? 0.0010
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From adik at ilovebacon.org  Thu Jul  1 18:38:46 2010
From: adik at ilovebacon.org (Adam D. I. Kramer)
Date: Thu, 1 Jul 2010 09:38:46 -0700 (PDT)
Subject: [R-sig-ME] different aic and LL in glmer(lme4) and glimmix(SAS)?
In-Reply-To: <4413C904170446FEA305BA04DFB30F82@Animal>
References: <AE3EE86B200D463A9CD2A99C04201D22@Animal>
	<AANLkTinPz4Now_QLJwhHEwGjD50ShtinzoVZ7ZbTqLtA@mail.gmail.com>
	<4413C904170446FEA305BA04DFB30F82@Animal>
Message-ID: <alpine.DEB.2.00.1007010938270.8163@parser.ilovebacon.org>

Also...R is giving you a model with LESS deviance. So, it's doing a better
job...why would you want to reproduce SAS? :)

--Adam


On Thu, 1 Jul 2010, Jeffrey Evans wrote:

> Good question.
>
> They are similar
>
> Compare models with nested fixed effects structures
> Full model = lnsdlmaxd + lnadultssdld + lnsdlmaxd:lnadultssdld
> Reduced model = lnsdlmaxd + lnadultssdld
>
> AIC		R		SAS
> Full		1150		1663.9
> Reduced	1159		1673.4
> -------------------------------
> deltaAIC	9		9.5
>
>
> ________________________________
>
> From: almost at gmail.com [mailto:almost at gmail.com] On Behalf Of Andy Fugard
> Sent: Thursday, July 01, 2010 12:16 PM
> To: Jeffrey Evans
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] different aic and LL in glmer(lme4) and
> glimmix(SAS)?
>
>
> Hi Jeff,
>
> Can't answer the question, but out of interest, what happens when you
> compare nested models in R and SAS, e.g., models with and without the
> lnsdlmaxd:lnadultssdld interaction?  Would be interesting to see the
> log-likehood ratio (and maybe /change/ in AIC and BIC between the models).
>
> Cheers,
>
> Andy
>
>
> On Thu, Jul 1, 2010 at 18:03, Jeffrey Evans <Jeffrey.Evans at dartmouth.edu>
> wrote:
>
>
> 	Hello All,
>
> 	I have read several posts related to this previously, but haven't
> found any
> 	resolution yet. When running the same GLMM in glmer and in SAS PROC
> GLIMMIX,
> 	both programs return comparable parameter estimates, but wildly
> different
> 	likelihoods and AIC values.
>
> 	In SAS I specify use of the Laplace approximation. In R, I believe
> this is
> 	the default (no?).
>
> 	What's the difference, and [how] can I reproduce the SAS -2ll in
> glmer?
>
> 	Thanks,
> 	Jeff
>
> 	\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/
> 	> R_GLMM = glmer(cbind(SdlFinal, SdlMax-SdlFinal) ~
> lnsdlmaxd*lnadultssdld +
> 	 (1|ID),data=sdlPCAdat,family="binomial")
> 	> R_GLMM
> 	Generalized linear mixed model fit by the Laplace approximation
> 	Formula: cbind(SdlFinal, SdlMax - SdlFinal) ~ lnsdlmaxd *
> lnadultssdld +
> 	(1 | ID)
> 	  Data: sdlPCAdat
> 	 AIC  BIC logLik deviance
> 	 1150 1165   -570     1140        <------------------ this line!!
> 	Random effects:
> 	 Groups Name        Variance Std.Dev.
> 	 ID     (Intercept) 1.2491   1.1176
> 	Number of obs: 144, groups: ID, 48
>
> 	Fixed effects:
> 	                      Estimate Std. Error z value Pr(>|z|)
> 	(Intercept)             4.56964    0.43148  10.591  < 2e-16 ***
> 	lnsdlmaxd              -0.65936    0.05686 -11.595  < 2e-16 ***
> 	lnadultssdld           -0.64534    0.15861  -4.069 4.73e-05 ***
> 	lnsdlmaxd:lnadultssdld  0.07393    0.02166   3.414  0.00064 ***
> 	---
> 	Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
> 	Correlation of Fixed Effects:
> 	           (Intr) lnsdlm lndlts
> 	lnsdlmaxd   -0.923
> 	lnadltssdld -0.461  0.479
> 	lnsdlmxd:ln  0.482 -0.508 -0.994
>
>
> 	 \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/
> 	title 'SAS GLMM';
> 	proc glimmix data=sdlPCAdat ic=pq noitprint method=laplace;
> 	class site id;
> 	model sdlfinal/sdlmax = lnsdlmaxd|lnadultssdld/ solution
> dist=binomial;
> 	random ID /;
> 	covtest glm/wald;
> 	run;
>
>
> //////////////////////////////////////////////////////////////////////
>
> 	                     SAS GLMM      19:36 Wednesday, June 30, 2010 88
>
> 	                  The GLIMMIX Procedure
>
> 	           Data Set           WORK.SDLPCADAT
> 	           Response Variable (Events)  SdlFinal
> 	           Response Variable (Trials)  SdlMax
> 	           Response Distribution     Binomial
> 	           Link Function         Logit
> 	           Variance Function       Default
> 	           Variance Matrix        Not blocked
> 	           Estimation Technique     Maximum Likelihood
> 	           Likelihood Approximation   Laplace
> 	           Degrees of Freedom Method   Containment
>
>
>
> 	                 Optimization Information
>
> 	            Optimization Technique    Dual Quasi-Newton
> 	            Parameters in Optimization  5
> 	            Lower Boundaries       1
> 	            Upper Boundaries       0
> 	            Fixed Effects         Not Profiled
> 	            Starting From         GLM estimates
>
> 	            Convergence criterion (GCONV=1E-8) satisfied.
>
> 	                    Fit Statistics
>
> 	              -2 Log Likelihood        1653.90  <------------------
> this
> 	line!!
> 	              AIC (smaller is better)  1663.90
> 	              AICC (smaller is better) 1664.33
> 	              BIC (smaller is better)  1673.25
> 	              CAIC (smaller is better) 1678.25
> 	              HQIC (smaller is better) 1667.43
>
>
> 	             Fit Statistics for Conditional Distribution
>
> 	             -2 log L(SdlFinal | r. effects)   1436.44
> 	             Pearson Chi-Square          908.07
> 	             Pearson Chi-Square / DF        6.31
>
>
> 	                Covariance Parameter Estimates
>
> 	           Cov         Standard     Z
> 	           Parm  Estimate    Error   Value   Pr > Z
>
> 	           ID    1.2491   0.2746   4.55   <.0001
>
>
> 	                Solutions for Fixed Effects
>
> 	                             Standard
> 	    Effect         Estimate    Error    DF  t Value  Pr > |t|
>
> 	    Intercept           4.5696   0.4333    47    10.55  <.0001
> 	    lnsdlmaxd          -0.6594   0.05717   93   -11.53  <.0001
> 	    lnadultssdld       -0.6453   0.1593    93   -4.05   0.0001
> 	    lnsdlmaxd*lnadultssd0.07394  0.02174   93    3.40   0.0010
>
> 	_______________________________________________
> 	R-sig-mixed-models at r-project.org mailing list
> 	https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From andyfugard at gmail.com  Thu Jul  1 18:50:27 2010
From: andyfugard at gmail.com (Andy Fugard)
Date: Thu, 1 Jul 2010 18:50:27 +0200
Subject: [R-sig-ME] different aic and LL in glmer(lme4) and glimmix(SAS)?
In-Reply-To: <4413C904170446FEA305BA04DFB30F82@Animal>
References: <AE3EE86B200D463A9CD2A99C04201D22@Animal>
	<AANLkTinPz4Now_QLJwhHEwGjD50ShtinzoVZ7ZbTqLtA@mail.gmail.com>
	<4413C904170446FEA305BA04DFB30F82@Animal>
Message-ID: <AANLkTikfFFEfj7g-gUAHHbz-mF8zDeyGxHcTcBV3LPhG@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100701/15de19c9/attachment.pl>

From bates at stat.wisc.edu  Thu Jul  1 20:16:13 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 1 Jul 2010 13:16:13 -0500
Subject: [R-sig-ME] different aic and LL in glmer(lme4) and glimmix(SAS)?
In-Reply-To: <AANLkTikF0nrxn6QGxDRFhMZHunfrtxruhC1a3G6r5KEA@mail.gmail.com>
References: <AE3EE86B200D463A9CD2A99C04201D22@Animal>
	<AANLkTikF0nrxn6QGxDRFhMZHunfrtxruhC1a3G6r5KEA@mail.gmail.com>
Message-ID: <AANLkTil98JCzoE3X9LLecru7FJv7RF6V10RYMW5aqAD0@mail.gmail.com>

On Thu, Jul 1, 2010 at 11:24 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
> On Thu, Jul 1, 2010 at 11:03 AM, Jeffrey Evans
> <Jeffrey.Evans at dartmouth.edu> wrote:
>> Hello All,
>
>> I have read several posts related to this previously, but haven't found any
>> resolution yet. When running the same GLMM in glmer and in SAS PROC GLIMMIX,
>> both programs return comparable parameter estimates, but wildly different
>> likelihoods and AIC values.
>
>> In SAS I specify use of the Laplace approximation. In R, I believe this is
>> the default (no?).
>
>> What's the difference, and [how] can I reproduce the SAS -2ll in glmer?
>
> The difference is probably due to the way that the deviance is defined
> for the binomial family in R. ?A glm family object is a list of
> functions and expressions. ?One of the functions, called "dev.resids"
> has arguments y, mu and weights. ?You can specify the response for a
> binomial family as the 0/1 responses or as a matrix with two columns
> as you did here. ?When you use the two column specification the
> response y is transformed to the fraction of successes and the number
> of cases is incorporated in the weights. ?It turns out that this is
> all the information necessary for obtaining the mle's of the
> parameters but it does not give the same deviance as you would get by
> listing the 0/1 responses.
>
> I'll write an example using the cbpp data from the lme4 package.

I enclose the example I promised.
>> Thanks,
>> Jeff
>>
>> \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/
>>> R_GLMM = glmer(cbind(SdlFinal, SdlMax-SdlFinal) ~ lnsdlmaxd*lnadultssdld +
>> ?(1|ID),data=sdlPCAdat,family="binomial")
>>> R_GLMM
>> Generalized linear mixed model fit by the Laplace approximation
>> Formula: cbind(SdlFinal, SdlMax - SdlFinal) ~ lnsdlmaxd * lnadultssdld +
>> (1 | ID)
>> ? Data: sdlPCAdat
>> ?AIC ?BIC logLik deviance
>> ?1150 1165 ? -570 ? ? 1140 ? ? ? ?<------------------ this line!!
>> Random effects:
>> ?Groups Name ? ? ? ?Variance Std.Dev.
>> ?ID ? ? (Intercept) 1.2491 ? 1.1176
>> Number of obs: 144, groups: ID, 48
>>
>> Fixed effects:
>> ? ? ? ? ? ? ? ? ? ? ? Estimate Std. Error z value Pr(>|z|)
>> (Intercept) ? ? ? ? ? ? 4.56964 ? ?0.43148 ?10.591 ?< 2e-16 ***
>> lnsdlmaxd ? ? ? ? ? ? ?-0.65936 ? ?0.05686 -11.595 ?< 2e-16 ***
>> lnadultssdld ? ? ? ? ? -0.64534 ? ?0.15861 ?-4.069 4.73e-05 ***
>> lnsdlmaxd:lnadultssdld ?0.07393 ? ?0.02166 ? 3.414 ?0.00064 ***
>> ---
>> Signif. codes: ?0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>
>> Correlation of Fixed Effects:
>> ? ? ? ? ? ?(Intr) lnsdlm lndlts
>> lnsdlmaxd ? -0.923
>> lnadltssdld -0.461 ?0.479
>> lnsdlmxd:ln ?0.482 -0.508 -0.994
>>
>>
>> ?\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/
>> title 'SAS GLMM';
>> proc glimmix data=sdlPCAdat ic=pq noitprint method=laplace;
>> class site id;
>> model sdlfinal/sdlmax = lnsdlmaxd|lnadultssdld/ solution dist=binomial;
>> random ID /;
>> covtest glm/wald;
>> run;
>>
>> //////////////////////////////////////////////////////////////////////
>>
>> ? ? ? ? ? ? ? ? ? ? ?SAS GLMM ? ? ?19:36 Wednesday, June 30, 2010 88
>>
>> ? ? ? ? ? ? ? ? ? The GLIMMIX Procedure
>>
>> ? ? ? ? ? ?Data Set ? ? ? ? ? WORK.SDLPCADAT
>> ? ? ? ? ? ?Response Variable (Events) ?SdlFinal
>> ? ? ? ? ? ?Response Variable (Trials) ?SdlMax
>> ? ? ? ? ? ?Response Distribution ? ? Binomial
>> ? ? ? ? ? ?Link Function ? ? ? ? Logit
>> ? ? ? ? ? ?Variance Function ? ? ? Default
>> ? ? ? ? ? ?Variance Matrix ? ? ? ?Not blocked
>> ? ? ? ? ? ?Estimation Technique ? ? Maximum Likelihood
>> ? ? ? ? ? ?Likelihood Approximation ? Laplace
>> ? ? ? ? ? ?Degrees of Freedom Method ? Containment
>>
>>
>>
>> ? ? ? ? ? ? ? ? ?Optimization Information
>>
>> ? ? ? ? ? ? Optimization Technique ? ?Dual Quasi-Newton
>> ? ? ? ? ? ? Parameters in Optimization ?5
>> ? ? ? ? ? ? Lower Boundaries ? ? ? 1
>> ? ? ? ? ? ? Upper Boundaries ? ? ? 0
>> ? ? ? ? ? ? Fixed Effects ? ? ? ? Not Profiled
>> ? ? ? ? ? ? Starting From ? ? ? ? GLM estimates
>>
>> ? ? ? ? ? ? Convergence criterion (GCONV=1E-8) satisfied.
>>
>> ? ? ? ? ? ? ? ? ? ? Fit Statistics
>>
>> ? ? ? ? ? ? ? -2 Log Likelihood ? ? ? ?1653.90 ?<------------------ this
>> line!!
>> ? ? ? ? ? ? ? AIC (smaller is better) ?1663.90
>> ? ? ? ? ? ? ? AICC (smaller is better) 1664.33
>> ? ? ? ? ? ? ? BIC (smaller is better) ?1673.25
>> ? ? ? ? ? ? ? CAIC (smaller is better) 1678.25
>> ? ? ? ? ? ? ? HQIC (smaller is better) 1667.43
>>
>>
>> ? ? ? ? ? ? ?Fit Statistics for Conditional Distribution
>>
>> ? ? ? ? ? ? ?-2 log L(SdlFinal | r. effects) ? 1436.44
>> ? ? ? ? ? ? ?Pearson Chi-Square ? ? ? ? ?908.07
>> ? ? ? ? ? ? ?Pearson Chi-Square / DF ? ? ? ?6.31
>>
>>
>> ? ? ? ? ? ? ? ? Covariance Parameter Estimates
>>
>> ? ? ? ? ? ?Cov ? ? ? ? Standard ? ? Z
>> ? ? ? ? ? ?Parm ?Estimate ? ?Error ? Value ? Pr > Z
>>
>> ? ? ? ? ? ?ID ? ?1.2491 ? 0.2746 ? 4.55 ? <.0001
>>
>>
>> ? ? ? ? ? ? ? ? Solutions for Fixed Effects
>>
>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Standard
>> ? ? Effect ? ? ? ? Estimate ? ?Error ? ?DF ?t Value ?Pr > |t|
>>
>> ? ? Intercept ? ? ? ? ? 4.5696 ? 0.4333 ? ?47 ? ?10.55 ?<.0001
>> ? ? lnsdlmaxd ? ? ? ? ?-0.6594 ? 0.05717 ? 93 ? -11.53 ?<.0001
>> ? ? lnadultssdld ? ? ? -0.6453 ? 0.1593 ? ?93 ? -4.05 ? 0.0001
>> ? ? lnsdlmaxd*lnadultssd0.07394 ?0.02174 ? 93 ? ?3.40 ? 0.0010
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
-------------- next part --------------

R version 2.11.1 (2010-05-31)
Copyright (C) 2010 The R Foundation for Statistical Computing
ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> library(lme4a)
Loading required package: Matrix
Loading required package: lattice

Attaching package: 'Matrix'

The following object(s) are masked from 'package:base':

    det

Loading required package: minqa
Loading required package: Rcpp

Attaching package: 'lme4a'

The following object(s) are masked from 'package:stats':

    AIC

> 
> ##' <description>
> ##' Expand the data frame for the matrix form of the binomial response
> ##' to the vector form of the response. 
> ##' <details>
> ##' In the formula for the glm and glmer functions with family =
> ##' binomial the response can be specified as a matrix with two
> ##' columns, corresponding to numbers of successes and failures.  The
> ##' parameter estimates for the model will be the same as those from
> ##' the vector response but the deviance itself is a different value.
> ##'
> ##' This function expands the model frame for the matrix response to
> ##' the equivalent frame for the vector response, replacing the
> ##' response matrix with a vector called y. of 1's and 0's
> ##' @title Expand binomial matrix response frame
> ##' @param fr model frame from a glm or glmer fitted model with
> ##' family=binomial and the matrix response specification.
> ##' @return expanded model frame with the response matrix replaced by
> ##' a vector of 1's and 0's.
> ##' @author Douglas Bates
> expandsu <- function(fr) {
+     stopifnot(is(fr, "data.frame"),
+               is(mm <- fr[[1]], "matrix"),
+               ncol(mm) == 2,
+               is.numeric(mm),
+               all(mm >= 0))
+     nr <- nrow(mm)
+     within(fr[, -1][rep.int(seq_len(nr), rowSums(mm)), ],
+            y. <- rep.int(rep.int(c(1,0), nr), as.vector(t(mm))))
+ }
> 
> str(cbpp)
'data.frame':	56 obs. of  4 variables:
 $ herd     : Factor w/ 15 levels "1","2","3","4",..: 1 1 1 1 2 2 2 3 3 3 ...
 $ incidence: num  2 3 4 0 3 1 1 8 2 0 ...
 $ size     : num  14 12 9 5 22 18 21 22 16 16 ...
 $ period   : Factor w/ 4 levels "1","2","3","4": 1 2 3 4 1 2 3 1 2 3 ...
> (fm1 <- glmer(cbind(incidence, size - incidence) ~ 0 + period +
+               (1|herd), cbpp, binomial, verbose=1L))
npt = 3 , n =  1 
rhobeg =  0.2 , rhoend =  2e-07 
   0.020:   4:      100.209;0.600000 
  0.0020:   7:      100.154;0.649390 
 0.00020:  10:      100.152;0.641932 
 2.0e-05:  12:      100.152;0.641823 
 2.0e-06:  13:      100.152;0.641823 
 2.0e-07:  15:      100.152;0.641815 
At return
 18:     100.15189: 0.641815
npt = 11 , n =  5 
rhobeg =  0.5840305 , rhoend =  5.840305e-07 
   0.058:  11:      100.152;0.641815 -1.36047 -2.33665 -2.47155 -2.92015 
  0.0058:  18:      100.108;0.653041 -1.38121 -2.38874 -2.52675 -2.97967 
 0.00058:  31:      100.095;0.642982 -1.39633 -2.38831 -2.52555 -2.97656 
 5.8e-05:  48:      100.095;0.642327 -1.39893 -2.39134 -2.52748 -2.97945 
 5.8e-06:  57:      100.095;0.642392 -1.39894 -2.39126 -2.52758 -2.97924 
 5.8e-07:  66:      100.095;0.642393 -1.39894 -2.39125 -2.52758 -2.97924 
At return
 78:     100.09497: 0.642392 -1.39894 -2.39125 -2.52758 -2.97924
Generalized linear mixed model fit by maximum likelihood ['merMod']
 Family: binomial 
Formula: cbind(incidence, size - incidence) ~ 0 + period + (1 | herd) 
   Data: cbpp 
     AIC      BIC   logLik deviance 
110.0950 120.2217 -50.0475 100.0950 

Random effects:
 Groups Name        Variance Std.Dev.
 herd   (Intercept) 0.4127   0.6424  
Number of obs: 56, groups: herd, 15

Fixed effects:
        Estimate Std. Error z value
period1  -1.3989     0.2279  -6.138
period2  -2.3912     0.3103  -7.705
period3  -2.5276     0.3308  -7.641
period4  -2.9792     0.4327  -6.885

Correlation of Fixed Effects:
        perid1 perid2 perid3
period2 0.389               
period3 0.365  0.289        
period4 0.280  0.220  0.205 
> str(cbpp1 <- expandsu(model.frame(fm1)))
'data.frame':	842 obs. of  3 variables:
 $ period: Factor w/ 4 levels "1","2","3","4": 1 1 1 1 1 1 1 1 1 1 ...
 $ herd  : Factor w/ 15 levels "1","2","3","4",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ y.    : num  1 1 0 0 0 0 0 0 0 0 ...
> (fm1a <- glmer(y. ~ 0 + period + (1|herd), cbpp1, binomial,
+                verbose=1L))
npt = 3 , n =  1 
rhobeg =  0.2 , rhoend =  2e-07 
   0.020:   4:      555.118;0.600000 
  0.0020:   7:      555.062;0.649390 
 0.00020:  10:      555.060;0.641932 
 2.0e-05:  12:      555.060;0.641823 
 2.0e-06:  13:      555.060;0.641823 
 2.0e-07:  15:      555.060;0.641815 
At return
 17:     555.05991: 0.641815
npt = 11 , n =  5 
rhobeg =  0.5840305 , rhoend =  5.840305e-07 
   0.058:  11:      555.060;0.641815 -1.36047 -2.33665 -2.47155 -2.92015 
  0.0058:  18:      555.016;0.653041 -1.38121 -2.38874 -2.52675 -2.97967 
 0.00058:  31:      555.003;0.642982 -1.39633 -2.38831 -2.52555 -2.97656 
 5.8e-05:  48:      555.003;0.642327 -1.39893 -2.39134 -2.52748 -2.97945 
 5.8e-06:  57:      555.003;0.642392 -1.39894 -2.39126 -2.52758 -2.97924 
 5.8e-07:  66:      555.003;0.642393 -1.39894 -2.39125 -2.52758 -2.97924 
At return
 76:     555.00300: 0.642392 -1.39894 -2.39125 -2.52758 -2.97924
Generalized linear mixed model fit by maximum likelihood ['merMod']
 Family: binomial 
Formula: y. ~ 0 + period + (1 | herd) 
   Data: cbpp1 
      AIC       BIC    logLik  deviance 
 565.0030  588.6819 -277.5015  555.0030 

Random effects:
 Groups Name        Variance Std.Dev.
 herd   (Intercept) 0.4127   0.6424  
Number of obs: 842, groups: herd, 15

Fixed effects:
        Estimate Std. Error z value
period1  -1.3989     0.2279  -6.138
period2  -2.3912     0.3103  -7.705
period3  -2.5276     0.3308  -7.641
period4  -2.9792     0.4327  -6.885

Correlation of Fixed Effects:
        perid1 perid2 perid3
period2 0.389               
period3 0.365  0.289        
period4 0.280  0.220  0.205 
> 
> 
> proc.time()
   user  system elapsed 
  6.140   0.130   6.405 

From hadley at rice.edu  Thu Jul  1 21:54:36 2010
From: hadley at rice.edu (Hadley Wickham)
Date: Thu, 1 Jul 2010 14:54:36 -0500
Subject: [R-sig-ME] different aic and LL in glmer(lme4) and glimmix(SAS)?
In-Reply-To: <AANLkTikF0nrxn6QGxDRFhMZHunfrtxruhC1a3G6r5KEA@mail.gmail.com>
References: <AE3EE86B200D463A9CD2A99C04201D22@Animal>
	<AANLkTikF0nrxn6QGxDRFhMZHunfrtxruhC1a3G6r5KEA@mail.gmail.com>
Message-ID: <AANLkTinqkCnEaEDr8xa2N1TkFfgpuNUiuKhsd4h-_HOj@mail.gmail.com>

> The difference is probably due to the way that the deviance is defined
> for the binomial family in R. ?A glm family object is a list of
> functions and expressions. ?One of the functions, called "dev.resids"
> has arguments y, mu and weights. ?You can specify the response for a
> binomial family as the 0/1 responses or as a matrix with two columns
> as you did here. ?When you use the two column specification the
> response y is transformed to the fraction of successes and the number
> of cases is incorporated in the weights. ?It turns out that this is
> all the information necessary for obtaining the mle's of the
> parameters but it does not give the same deviance as you would get by
> listing the 0/1 responses.

Isn't it also possible the difference is because (e.g.) lme4 drops
constants out of the likelihood and SAS doesn't?

Hadley


-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/



From bates at stat.wisc.edu  Thu Jul  1 22:56:50 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 1 Jul 2010 15:56:50 -0500
Subject: [R-sig-ME] different aic and LL in glmer(lme4) and glimmix(SAS)?
In-Reply-To: <AANLkTinqkCnEaEDr8xa2N1TkFfgpuNUiuKhsd4h-_HOj@mail.gmail.com>
References: <AE3EE86B200D463A9CD2A99C04201D22@Animal>
	<AANLkTikF0nrxn6QGxDRFhMZHunfrtxruhC1a3G6r5KEA@mail.gmail.com>
	<AANLkTinqkCnEaEDr8xa2N1TkFfgpuNUiuKhsd4h-_HOj@mail.gmail.com>
Message-ID: <AANLkTimBYGLN7fkjV8FOdm4gPYO25ArfPUUB2e3dv8f-@mail.gmail.com>

On Thu, Jul 1, 2010 at 2:54 PM, Hadley Wickham <hadley at rice.edu> wrote:
>> The difference is probably due to the way that the deviance is defined
>> for the binomial family in R. ?A glm family object is a list of
>> functions and expressions. ?One of the functions, called "dev.resids"
>> has arguments y, mu and weights. ?You can specify the response for a
>> binomial family as the 0/1 responses or as a matrix with two columns
>> as you did here. ?When you use the two column specification the
>> response y is transformed to the fraction of successes and the number
>> of cases is incorporated in the weights. ?It turns out that this is
>> all the information necessary for obtaining the mle's of the
>> parameters but it does not give the same deviance as you would get by
>> listing the 0/1 responses.
>
> Isn't it also possible the difference is because (e.g.) lme4 drops
> constants out of the likelihood and SAS doesn't?

Certainly a possibility.  I sometimes amaze myself with how sloppy I
can be in derivations. :-)



From j.hadfield at ed.ac.uk  Fri Jul  2 11:36:53 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 2 Jul 2010 10:36:53 +0100
Subject: [R-sig-ME] MCMCglmm with a fairly large sample size
In-Reply-To: <AANLkTikJTNMwE3Lpd2271GFdp_mbctWW8OnR7SkM9GiN@mail.gmail.com>
References: <AANLkTikJTNMwE3Lpd2271GFdp_mbctWW8OnR7SkM9GiN@mail.gmail.com>
Message-ID: <94A7843F-A773-41EF-BF5E-3FF930A457E4@ed.ac.uk>

Hi Kevin,

If you are not getting convergence after such a long time I would be  
more inclined to try and identify why this might be the case rather  
than sampling subsets of the data. Under some situations for some  
distributions (multinomial and ZIPs particularly) MCMCglmm may not mix  
well and there is very little the user can do except wait. In general  
I have not found ordinal responses to be a problem unless there are  
structural problems (e.g. all levels of the response are associated  
with a single level of a fixed predictor) or variances are trapped at  
zero. These problems can sometimes be solved by either  
reparameterising the model, placing a stronger prior on coefficients  
associated with structural problems or using parameter expansion. If  
the lack of convergence/mixing occurs when you add certain fixed/ 
random effects it may help a diagnosis.

Cheers,

Jarrod


On 1 Jul 2010, at 07:31, Kyuho Jin wrote:

> Hi folks,
>
> I am relatively new to the MCMC approach, but trying to estimate a  
> two-level
> ordinal probit model via MCMCglmm.
>
> My ordinal model is basically simple, but includes many fixed effects
> variables: 2 independent variables and 32 control variables  
> including 14
> year dummies. In addition, it allows for four random effects that are
> independent each other. Consequently, I believe my model structure is
> represented as follows:
>
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> ======================================================================
>> prior <- list(R=list(V=1,nu=0.002, fix=1), G=list(G1=list(V=1,
> nu=0.002),G2=list(V=1, nu=0.002),G3=list(V=1, nu=0.002),G4=list(V=1,
> nu=0.002)))
>> model <-  MCMCglmm(ordinal DV ~ 34 fixed effects variables, random  
>> = ~4
> independent random effects, family="ordinal", options ...)
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> = 
> ======================================================================
>
> Having said that, the problem now I am experiencing is that  
> convergence is
> not achieved even after a relatively large number of iterations like  
> 300,000
> (it ran 7 days to complete). Almost every convergence diagnostic  
> indicates
> that convergence is not achieved even after such a long run. [FYI, my
> computer system is equipped with intel core i7 920 (overclocked to  
> 3.8Ghz)
> CPU and 12Gb DDR3 RAM; OS is Ubuntu 10.04 LTS (64bit).]
>
> Because I am far behind the schedule, I tried running the model by  
> drawing a
> 10% random sample, following the suggestion of Gelman (2007:418).
> Fortunately, convergence is achieved after 500,000 iterations,  
> according to
> all convergence diagnostics. The parameter estimates were quite  
> reasonable
> and exactly what I expected. But my question is "is it okay to  
> report these
> parameter estimates that were generated from a 10% random sample?" In
> classical regression approach, a random sampling makes the analysis  
> merely a
> conservative one because standard errors are negatively associated  
> with
> sample size. But I am not sure if this also applies to MCMC  
> approach. If
> not, what else should I do? Should I just wait till convergence is  
> achieved?
>
> Any help/advice would be greatly appreciated.
>
> Best,
> Kevin
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From j.hadfield at ed.ac.uk  Fri Jul  2 11:37:12 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 2 Jul 2010 10:37:12 +0100
Subject: [R-sig-ME] MCMCglmm help- information about 'units' term
In-Reply-To: <01DF6CEB00684620BE0A2602BB967A5A@ibmroompc>
References: <01DF6CEB00684620BE0A2602BB967A5A@ibmroompc>
Message-ID: <10318822-AFED-4205-91F1-C66CB3B31EFF@ed.ac.uk>

Dear Karen,

I think the model is specified correctly. The units term is the  
variance of observation-level random effects, or a residual variance  
if you like. MCMCglmm always fits this term because a) I think over- 
dispersed models should be the default and b) the algorithm is  
designed so that the mixing properties of the chain are a function of  
the residual variance. This poses a problem for ordinal, binary and  
single-outcome multinomial responses because observation-level  
heterogeneity cannot be estimated from the data. Given this, I suggest  
that the residual (units) variance is fixed at some value. The default  
in most (all?) other packages is to fix the residual variance at zero,  
but MCMCglmm will not mix under this assumption.  In fact the mixing  
properties improve as the units variance is increased (see van Dyck  
and Meng's The art of data augmentation) although at some point  
underflow/overflow problems start to occur. For this reason I suggest  
fixing the residual variance to one in such models, as you have done.   
The interpretation of the parameters are identical to those under a  
probit model without a residual variance although the inverse link is  
now pnorm(x, 0, sqrt(2)) rather than  pnorm(x, 0, sqrt(1)).

Very small values for the ID variance seem to have some support.  The  
mixing of the ID variance can be poor when the value is close to zero  
(it can get stuck at zero).  For reasons very similar to those above  
(again see van Dyck and Meng's paper) mixing can be improved by adding  
a redundant non-identified parameter. Parameter expansion can be  
specified in MCMCglmm through the prior. For example, you may find  
that a change from

prior=list(R=list(V=1, fix=1), G=list(G1=list(V=1, nu=0)))

to

prior=list(R=list(V=1, fix=1), G=list(G1=list(V=1, nu=1, alpha.mu=0,  
alpha.V=100)))

hardly changes the posterior distribution but the autocorrelation in  
the chain is vastly improved. Most of this is documented in the  
CourseNotes and I recommend Gelman's paper "Prior distributions for  
variance parameters in hierarchical models" in Bayesian Analysis for a  
good introduction into these prior distributions.

Cheers,

Jarrod

On 30 Jun 2010, at 12:12, Karen Lamb wrote:

> Hi all,
>
> I have been working with mixed effects models for a couple of years  
> but I am relatively new to MCMCglmm() and MCMC techniques in general  
> so I hope someone may be able to shed some light on an issue I have.
>
> I am currently trying to fit a 3 level ordinal multinomial mixed  
> model. To begin, I fitted a very simplistic model to try out the  
> approach with only an intercept term and the random effect of ID  
> using the following code:
>
> prior=list(R=list(V=1, fix=1), G=list(G1=list(V=1, nu=0)))
>
> m1<-MCMCglmm(newbmi~1, random=~ID, family="ordinal", data=data1,  
> prior=prior)
>
>
>
>> From assessment of  autocorr(m1$Sol)it appears that convergence is  
>> ok.
>
>
>
> The issue I have concerns the random effects.  If I assess anything  
> involving m1$VCV l obtain really strange results. For example,
>
>
>
>> HPDinterval(m1$VCV[, "ID"]/(m1$VCV[,"ID"]+m1$VCV[,"units"]))
>            lower     upper
> var1 1.269593e-11 0.1352029
> attr(,"Probability")
> [1] 0.95
>
>
>> cor(m1$VCV)
>      ID units
> ID     1    NA
> units NA     1
> Warning message:
> In cor(m1$VCV) : the standard deviation is zero
>
>
>> diag(autocorr(m1$VCV)[2,,])
>           ID         units
> -0.0006257816           NaN
>
>
> Can anyone explain what this output means? My ID effect is tiny and  
> I am not sure that it is necessary to have the random effect in the  
> model after all. However, I intend to fit ID level explanatory  
> variables in the model so wish to retain this random effect. I just  
> don't understand what the problem is with the units term. Am I  
> specifying the model incorrectly?
>
>
>
> Any help/suggestions would be greatly appreciated!
>
>
>
> Cheers,
> Karen
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From adik at ilovebacon.org  Sun Jul  4 22:11:00 2010
From: adik at ilovebacon.org (Adam D. I. Kramer)
Date: Sun, 4 Jul 2010 13:11:00 -0700 (PDT)
Subject: [R-sig-ME] lmer verbose output and random effects tables confusion
Message-ID: <alpine.DEB.2.00.1007041202490.8163@parser.ilovebacon.org>

Hello,

 	For my own edification, could someone explain the relationship
between the output of "verbose-mode" model fitting in lmer and the lmer
object output?  I had been led to believe that the last line of the verbose
output would be the random effects table (and then for nonlinear models, the
fixed effects would follow), but when I fit this (rather complicated) model:

lmer(formula = rating ~ rvalue + m:option.1000 + m:option2 + m + (1 +
rvalue + m:option.1000 + m:option2 + m | studyID),
data=cc2[as.logical(cc2$chosen),], verbose=TRUE, control=list(maxIter=10000,
maxFN=10000))

...I get this output:

(...8895 rows of output...)
8896:     1231.8223:  3.75608 0.0485706 0.381782  0.00000 0.141926  0.00000
0.0226706 -0.0359946 -0.192479  6.02644  5.82712 -10.4730 -6.48680 -30.9794
47.8011 -2.39961  9.36467  108.544  10.9610 -94.6165 -51.5401  124.184
-41.8534 -48.6679  42.8230  2.19496 -1.26584  16.5468

...and this random effects table:

Random effects:
  Groups   Name           Variance   Std.Dev.  Corr
  studyID  (Intercept)    6.5123e+00  2.551915
           rvalue         9.5263e-03  0.097603 -0.941
           ml             1.3536e+00  1.163462 -0.422  0.100
           mh:option.1000 2.4708e+02 15.718900  0.978 -0.887 -0.461
           ml:option.1000 8.2346e+02 28.696035  0.518 -0.489 -0.407  0.352
           mh:option2     8.9316e+02 29.885807 -0.894  0.845  0.269 -0.955
           ml:option2     1.3245e+03 36.393087 -0.455  0.461  0.303 -0.275
  Residual                4.6160e-01  0.679410

...they do not correspond. Or do they? What might I be missing here? (I note
that the deviance is reported correctly). Some of the numbers are close, but
others are way off (for example, the zeroes in the verbose output show no
corresponding zeroes here). What's up? How should I read this verbose
output? Fixed effects follow, but also do not correspond:

Fixed effects:
               Estimate Std. Error t value
(Intercept) 18.4601702  0.6169761  29.920
rating       0.4912713  0.0956698   5.135
ml          -8.6768828  0.3568779 -24.313
mh:option    0.1097410  0.0371654   2.953
ml:option    0.0899163  0.0245243   3.666
mh:option2  -0.0012794  0.0004101  -3.120
ml:option2  -0.0010715  0.0002906  -3.688

Correlation of Fixed Effects:
            (Intr) rating ml     mh:ptn ml:ptn mh:pt2
rating     -0.934
ml         -0.521  0.340
mh:option  -0.207  0.022  0.337
ml:option  -0.003  0.023 -0.530 -0.007
mh:option2  0.096  0.075 -0.258 -0.924  0.017
ml:option2 -0.098  0.090  0.459  0.092 -0.882 -0.024

...I note also that this is important for the user level because testing shows
that when the user provides start values (via start=...), the verbose output
starts out with the start values verbatim.

Thanks,
Adam



From lucianolasala at yahoo.com.ar  Mon Jul  5 02:34:01 2010
From: lucianolasala at yahoo.com.ar (Luciano La Sala)
Date: Sun, 4 Jul 2010 21:34:01 -0300
Subject: [R-sig-ME] GLMM & lack of linearity on the logit
Message-ID: <8584AF990FE149A6985E65D62DE145EE@Negro1>

Dear R-people, 

I have just received from reviewers of a manuscript some harsh comments on
the statistical procedures. I'm studying risk factors of mortality at the
nest level among Olrog's Gull nest mates, which is why I used mixed models
with random intercepts (Nest ID). The outcome of interest if "Death"
(yes/no) and one of my explanatory variables is "Egg Volume" (continuous).
Since violation of linearity on the logit was evident I created 4 categories
using the quartiles of the distribution and modeled them as dummies.     

However, one reviewer stated: "It is unclear why you used volume of eggs as
a factor (i.e. categorized variable) in the analyses. Incorporating this
predictor as a continuous variable, as was originally measured, would make
analysis more informative. You stated that you made so "to relax the
linearity assumption". GLMM are sufficiently robust to accept a continuous
variable into a categorized model that, with the correct link function and
the variable transformation, would support well the linearity assumption." 

That said, I wonder if (1) categorization is such a bad thing on the one
hand, and (2) lack of linearity on the logit scale can be handled well by
GLMM.

In my case, adding quadratic and cubic terms after assessment of the shape
of the x-y relationship did not improve the fit, so I decided to use dummies
and thus relax the linearity assumption. 

Thank you very much in advance. 

Luciano



From s.blomberg1 at uq.edu.au  Mon Jul  5 02:45:39 2010
From: s.blomberg1 at uq.edu.au (Simon Blomberg)
Date: Mon, 05 Jul 2010 10:45:39 +1000
Subject: [R-sig-ME] GLMM & lack of linearity on the logit
In-Reply-To: <8584AF990FE149A6985E65D62DE145EE@Negro1>
References: <8584AF990FE149A6985E65D62DE145EE@Negro1>
Message-ID: <4C312B33.9040300@uq.edu.au>

Hi Luciano,

In general, categorization or "binning" is a bad thing to do. You are 
throwing away information in the process, and the size and number of 
bins must be subjective at some level. If there is important 
nonlinearity in egg volume, you could consider a Generalized Additive 
Mixed Model (GAMM) with a smoothing term for egg volume. I recommend 
package mgcv.

Cheers,

Simon.

On 05/07/10 10:34, Luciano La Sala wrote:
> Dear R-people,
>
> I have just received from reviewers of a manuscript some harsh comments on
> the statistical procedures. I'm studying risk factors of mortality at the
> nest level among Olrog's Gull nest mates, which is why I used mixed models
> with random intercepts (Nest ID). The outcome of interest if "Death"
> (yes/no) and one of my explanatory variables is "Egg Volume" (continuous).
> Since violation of linearity on the logit was evident I created 4 categories
> using the quartiles of the distribution and modeled them as dummies.
>
> However, one reviewer stated: "It is unclear why you used volume of eggs as
> a factor (i.e. categorized variable) in the analyses. Incorporating this
> predictor as a continuous variable, as was originally measured, would make
> analysis more informative. You stated that you made so "to relax the
> linearity assumption". GLMM are sufficiently robust to accept a continuous
> variable into a categorized model that, with the correct link function and
> the variable transformation, would support well the linearity assumption."
>
> That said, I wonder if (1) categorization is such a bad thing on the one
> hand, and (2) lack of linearity on the logit scale can be handled well by
> GLMM.
>
> In my case, adding quadratic and cubic terms after assessment of the shape
> of the x-y relationship did not improve the fit, so I decided to use dummies
> and thus relax the linearity assumption.
>
> Thank you very much in advance.
>
> Luciano
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>    

-- 
Simon Blomberg, BSc (Hons), PhD, MAppStat.
Lecturer and Consultant Statistician
School of Biological Sciences
The University of Queensland
St. Lucia Queensland 4072
Australia
T: +61 7 3365 2506
email: S.Blomberg1_at_uq.edu.au
http://www.uq.edu.au/~uqsblomb/

Policies:
1.  I will NOT analyse your data for you.
2.  Your deadline is your problem

Statistics is the grammar of science - Karl Pearson.



From adik at ilovebacon.org  Mon Jul  5 02:57:54 2010
From: adik at ilovebacon.org (Adam D. I. Kramer)
Date: Sun, 4 Jul 2010 17:57:54 -0700 (PDT)
Subject: [R-sig-ME] GLMM & lack of linearity on the logit
In-Reply-To: <8584AF990FE149A6985E65D62DE145EE@Negro1>
References: <8584AF990FE149A6985E65D62DE145EE@Negro1>
Message-ID: <alpine.DEB.2.00.1007041748030.8163@parser.ilovebacon.org>

<puts on stats instructor hat>

When you categorize a continuous variable, you are making an untested
theoretical claim that there are only two kinds of nests: Those of high
volume and those of low volume, and that it does not matter what the volume
is beyond knowing that it is "high" or "low." In psychology, this is rarely
true.

For more than two levels of a factor, the same logic holds: Why do those
levels differ from each other in a manner that makes the continuous
underlying distribution irrelevant?  If your cutoffs are at 2, 4, and 6,
then why would you insist _a priori_ that 3.9999 is wholly different from
4.0001 while being exactly the same as 2.000?

If you have such a reason, you should make this reason clear and apparent in
the methods section of your paper and let the reviewer pick on that. :)

</hat>

In terms of lack of linearity, you can probably just transform your
continuous data into a more-linear continuous distribution.  But if
quadratic and cubic functions don't help, it may just be that it is only the
linear component of your nonlinear variable is predictive of death...but
others may disagree with me on this point.

--Adam

On Sun, 4 Jul 2010, Luciano La Sala wrote:

> Dear R-people,
>
> I have just received from reviewers of a manuscript some harsh comments on
> the statistical procedures. I'm studying risk factors of mortality at the
> nest level among Olrog's Gull nest mates, which is why I used mixed models
> with random intercepts (Nest ID). The outcome of interest if "Death"
> (yes/no) and one of my explanatory variables is "Egg Volume" (continuous).
> Since violation of linearity on the logit was evident I created 4 categories
> using the quartiles of the distribution and modeled them as dummies.
>
> However, one reviewer stated: "It is unclear why you used volume of eggs as
> a factor (i.e. categorized variable) in the analyses. Incorporating this
> predictor as a continuous variable, as was originally measured, would make
> analysis more informative. You stated that you made so "to relax the
> linearity assumption". GLMM are sufficiently robust to accept a continuous
> variable into a categorized model that, with the correct link function and
> the variable transformation, would support well the linearity assumption."
>
> That said, I wonder if (1) categorization is such a bad thing on the one
> hand, and (2) lack of linearity on the logit scale can be handled well by
> GLMM.
>
> In my case, adding quadratic and cubic terms after assessment of the shape
> of the x-y relationship did not improve the fit, so I decided to use dummies
> and thus relax the linearity assumption.
>
> Thank you very much in advance.
>
> Luciano
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From baron at psych.upenn.edu  Mon Jul  5 03:45:20 2010
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Sun, 4 Jul 2010 21:45:20 -0400
Subject: [R-sig-ME] GLMM & lack of linearity on the logit
In-Reply-To: <alpine.DEB.2.00.1007041748030.8163@parser.ilovebacon.org>
References: <8584AF990FE149A6985E65D62DE145EE@Negro1>
	<alpine.DEB.2.00.1007041748030.8163@parser.ilovebacon.org>
Message-ID: <20100705014520.GA5908@psych.upenn.edu>

Another issue is that, when many people create several categories, the
categories are often treated as factors (i.e., names, not numbers).
We don't know in this case.  But that causes two problems.

First, we are looking for any difference between bins, not just a
monotonic effect.  We can get a significant result because (say) the
middle bin is higher than the rest, but that could really be part of
the null hypothesis, not what we are looking for.

Second, the hypothesis test is much broader: any difference at all,
not just a monotonic effect with higher numbers in the predictor
associated with higher numbers in the dependent variable.  Because it
is broader, the test loses power and can fail to detect a real
difference that would be detected even by falsely assuming that the
linear model fits.  (And often the deviation from linearity can be
corrected by transforming variables, as noted by others, so it is just
a matter of scaling.)

On 07/04/10 17:57, Adam D. I. Kramer wrote:
> <puts on stats instructor hat>
> 
> When you categorize a continuous variable, you are making an untested
> theoretical claim that there are only two kinds of nests: Those of high
> volume and those of low volume, and that it does not matter what the volume
> is beyond knowing that it is "high" or "low." In psychology, this is rarely
> true.

An interesting real example is here:

http://journal.sjdm.org/10/10202/jdm10202.html
or http://journal.sjdm.org/10/10202/jdm10202.pdf

A previously published paper found a result based on a split, but the
effect went away with almost any other split, or with a linear model.

> For more than two levels of a factor, the same logic holds: Why do those
> levels differ from each other in a manner that makes the continuous
> underlying distribution irrelevant?  If your cutoffs are at 2, 4, and 6,
> then why would you insist _a priori_ that 3.9999 is wholly different from
> 4.0001 while being exactly the same as 2.000?
> 
> If you have such a reason, you should make this reason clear and apparent in
> the methods section of your paper and let the reviewer pick on that. :)

Jon
-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron
Editor: Judgment and Decision Making (http://journal.sjdm.org)



From etiennelaliberte at gmail.com  Mon Jul  5 11:04:31 2010
From: etiennelaliberte at gmail.com (Etienne =?ISO-8859-1?Q?Lalibert=E9?=)
Date: Mon, 05 Jul 2010 21:04:31 +1200
Subject: [R-sig-ME] p-values in lme vs gamm
Message-ID: <1278320671.2231.49.camel@globetrotter>

With gamm from the mgcv package, I'm struggling to understand the
difference between summary(mymodel$gam) and summary(mymodel$lme).

In particular, can someone enlighten me as to why some of the p-values
differ with the following two calls? Without smoothers, I thought gamm
would simply give the same results as lme().

library(mgcv)
data(oats)
lme.mod <- lme(Y ~ N + V, random = list(B = ~1 , V = ~1), data = oats,
method = "REML")
gamm.mod <- gamm(Y ~ N + V, random = list(B = ~1 , V = ~1), data = oats,
method = "REML")
summary(lme.mod)
summary(gamm.mod$gam)
# note different p-values for VMarvellous and VVictory

Thanks

Etienne



From Christoph.Scherber at agr.uni-goettingen.de  Mon Jul  5 11:41:18 2010
From: Christoph.Scherber at agr.uni-goettingen.de (Christoph Scherber)
Date: Mon, 05 Jul 2010 11:41:18 +0200
Subject: [R-sig-ME] p-values in lme vs gamm
In-Reply-To: <1278320671.2231.49.camel@globetrotter>
References: <1278320671.2231.49.camel@globetrotter>
Message-ID: <4C31A8BE.3030006@agr.uni-goettingen.de>

Dear Etienne,

You should only compare the estimates and SE?s (and P values) from corresponding lme models:

summary(lme.mod)
summary(gamm.mod$lme)

These give exactly identical results.

Looking at the gam model without explicitly specifying a smoothing function s() does not make too much sense.

Best wishes
Christoph





Etienne Lalibert? wrote:

> With gamm from the mgcv package, I'm struggling to understand the
> difference between summary(mymodel$gam) and summary(mymodel$lme).
> 
> In particular, can someone enlighten me as to why some of the p-values
> differ with the following two calls? Without smoothers, I thought gamm
> would simply give the same results as lme().
> 
> library(mgcv)
> data(oats)
> lme.mod <- lme(Y ~ N + V, random = list(B = ~1 , V = ~1), data = oats,
> method = "REML")
> gamm.mod <- gamm(Y ~ N + V, random = list(B = ~1 , V = ~1), data = oats,
> method = "REML")
> summary(lme.mod)
> summary(gamm.mod$gam)
> # note different p-values for VMarvellous and VVictory
> 
> Thanks
> 
> Etienne
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> .
> 



From k.lamb at sphsu.mrc.ac.uk  Mon Jul  5 13:24:02 2010
From: k.lamb at sphsu.mrc.ac.uk (Karen Lamb)
Date: Mon, 5 Jul 2010 12:24:02 +0100
Subject: [R-sig-ME] MCMCglmm help- information about 'units' term
References: <01DF6CEB00684620BE0A2602BB967A5A@ibmroompc>
	<10318822-AFED-4205-91F1-C66CB3B31EFF@ed.ac.uk>
Message-ID: <A41318B62C5E4CCD90DCDA431F5D087F@ibmroompc>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100705/9a3e76b9/attachment.pl>

From Fabian.Scheipl at stat.uni-muenchen.de  Mon Jul  5 15:18:08 2010
From: Fabian.Scheipl at stat.uni-muenchen.de (Fabian Scheipl)
Date: Mon, 5 Jul 2010 15:18:08 +0200
Subject: [R-sig-ME]  GLMM & lack of linearity on the logit
Message-ID: <AANLkTim1tUg3TcH67ujBrEfXhQbdWE8T93DE2HE99hUt@mail.gmail.com>

Simon Blomberg:
> If there is important nonlinearity in egg volume, you could
> consider a Generalized Additive Mixed Model (GAMM) with a smoothing
> term for egg volume. I recommend package mgcv.

I second that, and I would add that you really can't lose by including
a smooth term for important continuous variables as long as you have a
decent number of observations: if the relationship is indeed linear,
the smooth term will be estimated to be (close to) linear as well and
you can then proceed to simplify your model.

In terms of software to fit this, also have a look at my package amer
(http://cran.r-project.org/web/packages/amer/index.html),
which avoids the PQL-approximation used in mgcv and instead relies on
lme4's Laplace integration to fit generalized additive mixed models.



From bates at stat.wisc.edu  Mon Jul  5 17:19:09 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 5 Jul 2010 10:19:09 -0500
Subject: [R-sig-ME] lmer verbose output and random effects tables
	confusion
In-Reply-To: <alpine.DEB.2.00.1007041202490.8163@parser.ilovebacon.org>
References: <alpine.DEB.2.00.1007041202490.8163@parser.ilovebacon.org>
Message-ID: <AANLkTilRfDM-7tqGGVbzgMUBNVz0BCxBdhyZeUNibFoW@mail.gmail.com>

On Sun, Jul 4, 2010 at 3:11 PM, Adam D. I. Kramer <adik at ilovebacon.org> wrote:
> Hello,
>
> ? ? ? ?For my own edification, could someone explain the relationship
> between the output of "verbose-mode" model fitting in lmer and the lmer
> object output? ?I had been led to believe that the last line of the verbose
> output would be the random effects table (and then for nonlinear models, the
> fixed effects would follow), but when I fit this (rather complicated) model:
>
> lmer(formula = rating ~ rvalue + m:option.1000 + m:option2 + m + (1 +
> rvalue + m:option.1000 + m:option2 + m | studyID),
> data=cc2[as.logical(cc2$chosen),], verbose=TRUE, control=list(maxIter=10000,
> maxFN=10000))
>
> ...I get this output:
>
> (...8895 rows of output...)
> 8896: ? ? 1231.8223: ?3.75608 0.0485706 0.381782 ?0.00000 0.141926 ?0.00000
> 0.0226706 -0.0359946 -0.192479 ?6.02644 ?5.82712 -10.4730 -6.48680 -30.9794
> 47.8011 -2.39961 ?9.36467 ?108.544 ?10.9610 -94.6165 -51.5401 ?124.184
> -41.8534 -48.6679 ?42.8230 ?2.19496 -1.26584 ?16.5468
>
> ...and this random effects table:
>
> Random effects:
> ?Groups ? Name ? ? ? ? ? Variance ? Std.Dev. ?Corr
> ?studyID ?(Intercept) ? ?6.5123e+00 ?2.551915
> ? ? ? ? ?rvalue ? ? ? ? 9.5263e-03 ?0.097603 -0.941
> ? ? ? ? ?ml ? ? ? ? ? ? 1.3536e+00 ?1.163462 -0.422 ?0.100
> ? ? ? ? ?mh:option.1000 2.4708e+02 15.718900 ?0.978 -0.887 -0.461
> ? ? ? ? ?ml:option.1000 8.2346e+02 28.696035 ?0.518 -0.489 -0.407 ?0.352
> ? ? ? ? ?mh:option2 ? ? 8.9316e+02 29.885807 -0.894 ?0.845 ?0.269 -0.955
> ? ? ? ? ?ml:option2 ? ? 1.3245e+03 36.393087 -0.455 ?0.461 ?0.303 -0.275
> ?Residual ? ? ? ? ? ? ? ?4.6160e-01 ?0.679410
>
> ...they do not correspond. Or do they? What might I be missing here? (I note
> that the deviance is reported correctly). Some of the numbers are close, but
> others are way off (for example, the zeroes in the verbose output show no
> corresponding zeroes here). What's up? How should I read this verbose
> output? Fixed effects follow, but also do not correspond:
>
> Fixed effects:
> ? ? ? ? ? ? ?Estimate Std. Error t value
> (Intercept) 18.4601702 ?0.6169761 ?29.920
> rating ? ? ? 0.4912713 ?0.0956698 ? 5.135
> ml ? ? ? ? ?-8.6768828 ?0.3568779 -24.313
> mh:option ? ?0.1097410 ?0.0371654 ? 2.953
> ml:option ? ?0.0899163 ?0.0245243 ? 3.666
> mh:option2 ?-0.0012794 ?0.0004101 ?-3.120
> ml:option2 ?-0.0010715 ?0.0002906 ?-3.688
>
> Correlation of Fixed Effects:
> ? ? ? ? ? (Intr) rating ml ? ? mh:ptn ml:ptn mh:pt2
> rating ? ? -0.934
> ml ? ? ? ? -0.521 ?0.340
> mh:option ?-0.207 ?0.022 ?0.337
> ml:option ?-0.003 ?0.023 -0.530 -0.007
> mh:option2 ?0.096 ?0.075 -0.258 -0.924 ?0.017
> ml:option2 -0.098 ?0.090 ?0.459 ?0.092 -0.882 -0.024
>
> ...I note also that this is important for the user level because testing
> shows
> that when the user provides start values (via start=...), the verbose output
> starts out with the start values verbatim.

Which version of the lme4 package?

In all versions the parameters over which the optimization in lmer
takes place are those that determine the relative covariance factor
for the random effects.  I usually write these as theta.
In the case of a scalar random effects term the theta parameter
corresponds to the ratio of the standard deviation of the random
effect to the standard deviation of the residual noise term.  For a
vector-valued random effects the mapping from a collection of theta
parameters to the relative covariance factor depends on the version of
the lme4 package.  I think this version is still using the ST
formulation, in which case those 0's in the parameter vector at
convergence indicate convergence to a singular variance-covariance
matrix.



From Christoph.Scherber at agr.uni-goettingen.de  Tue Jul  6 09:28:00 2010
From: Christoph.Scherber at agr.uni-goettingen.de (Christoph Scherber)
Date: Tue, 06 Jul 2010 09:28:00 +0200
Subject: [R-sig-ME] p-values in lme vs gamm
In-Reply-To: <1278366184.27358.80.camel@globetrotter>
References: <1278320671.2231.49.camel@globetrotter>	
	<4C31A707.90802@agr.uni-goettingen.de>
	<1278366184.27358.80.camel@globetrotter>
Message-ID: <4C32DB00.20805@agr.uni-goettingen.de>

Dear Etienne,

Given that the SE?s and the t values associated with the parameter estimates are identical in the lme and gamm.mod$gam fits, it seems that there are
differences in the calculation of the degrees of freedom. That is, the P values are calculated from the t distributions at different degrees of freedom.

Maybe some inspection of the GAMM source could might help.

All the best,
Christoph




Etienne Lalibert? wrote:

> Thanks Christophe.
> 
> I'm aware it's useless to use gamm() when no smoothers are specified,
> but I still struggle to understand what exactly is the difference
> between summary(gamm.mod$gam) and summary(gamm.mod$lme).
> 
> Cheers
> 
> Etienne
> 
> Le lundi 05 juillet 2010 ? 11:33 +0200, Christoph Scherber a ?crit :
>> Dear Etienne,
>>
>> You should only compare the estimates and SE?s (and P values) from corresponding lme models:
>>
>> summary(lme.mod)
>> summary(gamm.mod$lme)
> 
>> These give exactly identical results.
>>
>> Looking at the gam model without explicitly specifying a smoothing function s() does not make too much sense.
>>
>> Best wishes
>> Christoph
>>
>>
>>
>>
>>
>> Etienne Lalibert? wrote:
>>
>>> With gamm from the mgcv package, I'm struggling to understand the
>>> difference between summary(mymodel$gam) and summary(mymodel$lme).
>>>
>>> In particular, can someone enlighten me as to why some of the p-values
>>> differ with the following two calls? Without smoothers, I thought gamm
>>> would simply give the same results as lme().
>>>
>>> library(mgcv)
>>> data(oats)
>>> lme.mod <- lme(Y ~ N + V, random = list(B = ~1 , V = ~1), data = oats,
>>> method = "REML")
>>> gamm.mod <- gamm(Y ~ N + V, random = list(B = ~1 , V = ~1), data = oats,
>>> method = "REML")
>>> summary(lme.mod)
>>> summary(gamm.mod$gam)
>>> # note different p-values for VMarvellous and VVictory
>>>
>>> Thanks
>>>
>>> Etienne
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>> .
>>>
>>
> 
> 



From j.hadfield at ed.ac.uk  Tue Jul  6 12:22:24 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 6 Jul 2010 11:22:24 +0100
Subject: [R-sig-ME] MCMCglmm help- information about 'units' term
In-Reply-To: <A41318B62C5E4CCD90DCDA431F5D087F@ibmroompc>
References: <01DF6CEB00684620BE0A2602BB967A5A@ibmroompc>
	<10318822-AFED-4205-91F1-C66CB3B31EFF@ed.ac.uk>
	<A41318B62C5E4CCD90DCDA431F5D087F@ibmroompc>
Message-ID: <65C024E4-8A00-4B8A-A9C4-0D472A08FFA5@ed.ac.uk>

Dear Karen,

Imagine a latent variable (l) that conforms to the  standard linear  
model.

l = Xb+Zu+e

The probabilities of falling into each of the three categories are:


pnorm(-l)

pnorm(cp-l)-pnorm(-l)

1-pnorm(cp-l)

where cp is the cut-point.  If you have just an intercept, and you  
fixed the residual variance to 1 this gives:

pnorm(-Intercept, sd=sqrt(2))  = 0.589807

pnorm(cp-Intercept, sd=sqrt(2))-pnorm(-Intercept, sd=sqrt(2)) =  
0.2968132

1-pnorm(cp-Intercept, sd=sqrt(2)) = 0.1133798

where sd=sqrt(2) rather than sd=1 because we're marginalising the  
residuals. The numbers should correspond to the frequency of the  
categories in your data.

Cheers,

Jarrod






On 5 Jul 2010, at 12:24, Karen Lamb wrote:

> Thanks very much for your assistance in this matter. I have  
> persevered with the modelling but am now having problems  
> interpreting the output for the fixed effects from the modelling.
>
> I have a three category model (0=low, 1=medium, 2=high)  which I  
> have been treating as ordinal. I have only previously worked with  
> nominal multinomial models and am used to fitting a different  
> intercept estimate for each comparison. I had assumed when I was  
> fitting the model that I would obtain an intercept for the model  
> comparison of medium to low and one for the comparison of high to  
> low. Do I need to add in some further model specification in my code  
> to obtain this or am I simply misunderstanding the model fitting for  
> an ordinal response? As it is currently specified, I only obtain one  
> estimated intercept parameter and I do not know how to interpret  
> this. The results are:
>
> > posterior.mode(m1$Sol)
> cutpoint.traitnewbmi.1            (Intercept)
>              1.3883328             -0.3210951
>
> In addition, I have a number of explanatory variables I would like  
> to include in the multinomial model and am trying to figure out the  
> best approach to use when deciding which of these variables should  
> be retained in the model. Is it best to examine DIC in the model  
> comparison or is there some other way of testing the significance of  
> the predictor? Is there any particular measure of the goodness of  
> fit of the model that is routinely adopted? I have been asked to  
> provide some measure of the proportion of variance in the data  
> explained by the fixed effects included in the model and do not know  
> if this type of thing is possible with glms. I understand that there  
> are some suggested R-square type measures for linear mixed models  
> but am not aware of anything similar for a multinomial.
>
> Once again, any suggestions would be greatly appreciated.
>
> Cheers,
> Karen
>
>
>
> ----- Original Message -----
> From: Jarrod Hadfield
> To: Karen Lamb
> Cc: r-sig-mixed-models at r-project.org
> Sent: Friday, July 02, 2010 10:37 AM
> Subject: Re: [R-sig-ME] MCMCglmm help- information about 'units' term
>
> Dear Karen,
>
> I think the model is specified correctly. The units term is the
> variance of observation-level random effects, or a residual variance
> if you like. MCMCglmm always fits this term because a) I think over-
> dispersed models should be the default and b) the algorithm is
> designed so that the mixing properties of the chain are a function of
> the residual variance. This poses a problem for ordinal, binary and
> single-outcome multinomial responses because observation-level
> heterogeneity cannot be estimated from the data. Given this, I suggest
> that the residual (units) variance is fixed at some value. The default
> in most (all?) other packages is to fix the residual variance at zero,
> but MCMCglmm will not mix under this assumption.  In fact the mixing
> properties improve as the units variance is increased (see van Dyck
> and Meng's The art of data augmentation) although at some point
> underflow/overflow problems start to occur. For this reason I suggest
> fixing the residual variance to one in such models, as you have done.
> The interpretation of the parameters are identical to those under a
> probit model without a residual variance although the inverse link is
> now pnorm(x, 0, sqrt(2)) rather than  pnorm(x, 0, sqrt(1)).
>
> Very small values for the ID variance seem to have some support.  The
> mixing of the ID variance can be poor when the value is close to zero
> (it can get stuck at zero).  For reasons very similar to those above
> (again see van Dyck and Meng's paper) mixing can be improved by adding
> a redundant non-identified parameter. Parameter expansion can be
> specified in MCMCglmm through the prior. For example, you may find
> that a change from
>
> prior=list(R=list(V=1, fix=1), G=list(G1=list(V=1, nu=0)))
>
> to
>
> prior=list(R=list(V=1, fix=1), G=list(G1=list(V=1, nu=1, alpha.mu=0,
> alpha.V=100)))
>
> hardly changes the posterior distribution but the autocorrelation in
> the chain is vastly improved. Most of this is documented in the
> CourseNotes and I recommend Gelman's paper "Prior distributions for
> variance parameters in hierarchical models" in Bayesian Analysis for a
> good introduction into these prior distributions.
>
> Cheers,
>
> Jarrod
>
> On 30 Jun 2010, at 12:12, Karen Lamb wrote:
>
> > Hi all,
> >
> > I have been working with mixed effects models for a couple of years
> > but I am relatively new to MCMCglmm() and MCMC techniques in general
> > so I hope someone may be able to shed some light on an issue I have.
> >
> > I am currently trying to fit a 3 level ordinal multinomial mixed
> > model. To begin, I fitted a very simplistic model to try out the
> > approach with only an intercept term and the random effect of ID
> > using the following code:
> >
> > prior=list(R=list(V=1, fix=1), G=list(G1=list(V=1, nu=0)))
> >
> > m1<-MCMCglmm(newbmi~1, random=~ID, family="ordinal", data=data1,
> > prior=prior)
> >
> >
> >
> >> From assessment of  autocorr(m1$Sol)it appears that convergence is
> >> ok.
> >
> >
> >
> > The issue I have concerns the random effects.  If I assess anything
> > involving m1$VCV l obtain really strange results. For example,
> >
> >
> >
> >> HPDinterval(m1$VCV[, "ID"]/(m1$VCV[,"ID"]+m1$VCV[,"units"]))
> >            lower     upper
> > var1 1.269593e-11 0.1352029
> > attr(,"Probability")
> > [1] 0.95
> >
> >
> >> cor(m1$VCV)
> >      ID units
> > ID     1    NA
> > units NA     1
> > Warning message:
> > In cor(m1$VCV) : the standard deviation is zero
> >
> >
> >> diag(autocorr(m1$VCV)[2,,])
> >           ID         units
> > -0.0006257816           NaN
> >
> >
> > Can anyone explain what this output means? My ID effect is tiny and
> > I am not sure that it is necessary to have the random effect in the
> > model after all. However, I intend to fit ID level explanatory
> > variables in the model so wish to retain this random effect. I just
> > don't understand what the problem is with the units term. Am I
> > specifying the model incorrectly?
> >
> >
> >
> > Any help/suggestions would be greatly appreciated!
> >
> >
> >
> > Cheers,
> > Karen
> >
> >
> >
> > [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100706/27527ecf/attachment.pl>

From arrayprofile at yahoo.com  Wed Jul  7 02:33:12 2010
From: arrayprofile at yahoo.com (array chip)
Date: Tue, 6 Jul 2010 17:33:12 -0700 (PDT)
Subject: [R-sig-ME] implicit nesting
In-Reply-To: <AANLkTilRfDM-7tqGGVbzgMUBNVz0BCxBdhyZeUNibFoW@mail.gmail.com>
References: <alpine.DEB.2.00.1007041202490.8163@parser.ilovebacon.org>
	<AANLkTilRfDM-7tqGGVbzgMUBNVz0BCxBdhyZeUNibFoW@mail.gmail.com>
Message-ID: <357273.76509.qm@web56305.mail.re3.yahoo.com>

Dear Dr. Bates,

I am learning lmer() from lme4 package. I came across your article "Fitting linear mixed models in R" in R News (vol5, May 2005). I have 2 questions:

1. one is about the implicit nesting in the section "Specifying levels" where you gave an example dataset "Pixel" from MEMSS package. You said "If we wish to fit a model with random effects for "side within dog" we must first create a dog/side factor as 
      > Pixel$DS <- wirth(Pixel, Dog:Side)[drop=TRUE]
". 
I still don't quite understand why we have to create a new factor variable like the above. What is wrong if we simply specify a model like this (it runs and produces results):
  > fm <- lmer(pixel~day + (day|Side) + (day|Dog), Pixel)


2. the 2nd question is about the example you gave in the section "Nested and non-nested grouping factors" where you considered the dataset "star" from mlmRev package. In this example, the model specification is:
   > fm4 <- lmer(math ~ gr + sx + eth + cltype + (yrs | id) + (yrs | sch), star)

In this model, you didn't include "yrs" as a fixed effect. The how should we explain the random slope? When "yrs" is included as a fixed effect in the model, we can explain random slope as a random slope around a fixed common slope. But if "yrs" is not included as a fixed effect, does that mean the random slope is around a common fixed slope of 0?

Actually, I tried to add "yrs" as a fixed effect:
   > fm4 <- lmer(math ~ gr + sx + eth + cltype + yrs + (yrs | id) + (yrs | sch), star)
But I got an error message "Error in mer_finalize(ans) : Downdated X'X is not positive definite, 13.", why is that?

Thank you very much!

John








----- Original Message ----
From: Douglas Bates <bates at stat.wisc.edu>
To: adik at ilovebacon.org
Cc: r-sig-mixed-models at r-project.org
Sent: Mon, July 5, 2010 8:19:09 AM
Subject: Re: [R-sig-ME] lmer verbose output and random effects tables confusion

On Sun, Jul 4, 2010 at 3:11 PM, Adam D. I. Kramer <adik at ilovebacon.org> wrote:
> Hello,
>
>        For my own edification, could someone explain the relationship
> between the output of "verbose-mode" model fitting in lmer and the lmer
> object output?  I had been led to believe that the last line of the verbose
> output would be the random effects table (and then for nonlinear models, the
> fixed effects would follow), but when I fit this (rather complicated) model:
>
> lmer(formula = rating ~ rvalue + m:option.1000 + m:option2 + m + (1 +
> rvalue + m:option.1000 + m:option2 + m | studyID),
> data=cc2[as.logical(cc2$chosen),], verbose=TRUE, control=list(maxIter=10000,
> maxFN=10000))
>
> ...I get this output:
>
> (...8895 rows of output...)
> 8896:     1231.8223:  3.75608 0.0485706 0.381782  0.00000 0.141926  0.00000
> 0.0226706 -0.0359946 -0.192479  6.02644  5.82712 -10.4730 -6.48680 -30.9794
> 47.8011 -2.39961  9.36467  108.544  10.9610 -94.6165 -51.5401  124.184
> -41.8534 -48.6679  42.8230  2.19496 -1.26584  16.5468
>
> ...and this random effects table:
>
> Random effects:
>  Groups   Name           Variance   Std.Dev.  Corr
>  studyID  (Intercept)    6.5123e+00  2.551915
>          rvalue         9.5263e-03  0.097603 -0.941
>          ml             1.3536e+00  1.163462 -0.422  0.100
>          mh:option.1000 2.4708e+02 15.718900  0.978 -0.887 -0.461
>          ml:option.1000 8.2346e+02 28.696035  0.518 -0.489 -0.407  0.352
>          mh:option2     8.9316e+02 29.885807 -0.894  0.845  0.269 -0.955
>          ml:option2     1.3245e+03 36.393087 -0.455  0.461  0.303 -0.275
>  Residual                4.6160e-01  0.679410
>
> ...they do not correspond. Or do they? What might I be missing here? (I note
> that the deviance is reported correctly). Some of the numbers are close, but
> others are way off (for example, the zeroes in the verbose output show no
> corresponding zeroes here). What's up? How should I read this verbose
> output? Fixed effects follow, but also do not correspond:
>
> Fixed effects:
>              Estimate Std. Error t value
> (Intercept) 18.4601702  0.6169761  29.920
> rating       0.4912713  0.0956698   5.135
> ml          -8.6768828  0.3568779 -24.313
> mh:option    0.1097410  0.0371654   2.953
> ml:option    0.0899163  0.0245243   3.666
> mh:option2  -0.0012794  0.0004101  -3.120
> ml:option2  -0.0010715  0.0002906  -3.688
>
> Correlation of Fixed Effects:
>           (Intr) rating ml     mh:ptn ml:ptn mh:pt2
> rating     -0.934
> ml         -0.521  0.340
> mh:option  -0.207  0.022  0.337
> ml:option  -0.003  0.023 -0.530 -0.007
> mh:option2  0.096  0.075 -0.258 -0.924  0.017
> ml:option2 -0.098  0.090  0.459  0.092 -0.882 -0.024
>
> ...I note also that this is important for the user level because testing
> shows
> that when the user provides start values (via start=...), the verbose output
> starts out with the start values verbatim.

Which version of the lme4 package?

In all versions the parameters over which the optimization in lmer
takes place are those that determine the relative covariance factor
for the random effects.  I usually write these as theta.
In the case of a scalar random effects term the theta parameter
corresponds to the ratio of the standard deviation of the random
effect to the standard deviation of the residual noise term.  For a
vector-valued random effects the mapping from a collection of theta
parameters to the relative covariance factor depends on the version of
the lme4 package.  I think this version is still using the ST
formulation, in which case those 0's in the parameter vector at
convergence indicate convergence to a singular variance-covariance
matrix.

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From elizabeth.crone at cfc.umt.edu  Wed Jul  7 07:14:47 2010
From: elizabeth.crone at cfc.umt.edu (Elizabeth Crone)
Date: Tue, 6 Jul 2010 23:14:47 -0600
Subject: [R-sig-ME] postdoc positions
Message-ID: <FDE3381E3E2B9945BDA9105DBBE2D608030535171BF5@pangaea.cfc.umt.edu>

Hello...

I have been enjoying following the discussions on this listserv.  I hope this posting is not inappropriate...

I have funding to hire two postdocs for separate projects, both of which involve applications of mixed models to ecological questions.  For information, see: http://harvardforest.fas.harvard.edu/siteinfo/employment.html 

Thanks!
Elizabeth Crone
elizabeth.crone at cfc.umt.edu


From bates at stat.wisc.edu  Wed Jul  7 17:03:38 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 7 Jul 2010 10:03:38 -0500
Subject: [R-sig-ME] implicit nesting
In-Reply-To: <357273.76509.qm@web56305.mail.re3.yahoo.com>
References: <alpine.DEB.2.00.1007041202490.8163@parser.ilovebacon.org>
	<AANLkTilRfDM-7tqGGVbzgMUBNVz0BCxBdhyZeUNibFoW@mail.gmail.com>
	<357273.76509.qm@web56305.mail.re3.yahoo.com>
Message-ID: <AANLkTikVR67rJRfXQ9pJD1ay6Id8s4Ue8J6nIvSX75d6@mail.gmail.com>

On Tue, Jul 6, 2010 at 7:33 PM, array chip <arrayprofile at yahoo.com> wrote:
> Dear Dr. Bates,

> I am learning lmer() from lme4 package. I came across your article "Fitting linear mixed models in R" in R News (vol5, May 2005). I have 2 questions:

> 1. one is about the implicit nesting in the section "Specifying levels" where you gave an example dataset "Pixel" from MEMSS package. You said "If we wish to fit a model with random effects for "side within dog" we must first create a dog/side factor as
> ? ? ?> Pixel$DS <- wirth(Pixel, Dog:Side)[drop=TRUE]
> ".
> I still don't quite understand why we have to create a new factor variable like the above. What is wrong if we simply specify a model like this (it runs and produces results):
> ?> fm <- lmer(pixel~day + (day|Side) + (day|Dog), Pixel)

Because Side has only two levels, "L" and "R", and you want to define
random effects separately for each side of each dog.

> 2. the 2nd question is about the example you gave in the section "Nested and non-nested grouping factors" where you considered the dataset "star" from mlmRev package. In this example, the model specification is:
> ? > fm4 <- lmer(math ~ gr + sx + eth + cltype + (yrs | id) + (yrs | sch), star)

When modeling the results of annual test scores like these, "year" and
"grade" are usually confounded or close to being confounded within
each student.  For defining per-student random effects we prefer to
use yr because the year should always change from one result to the
next but when a student has been retained the grade doesn't change.

> In this model, you didn't include "yrs" as a fixed effect. The how should we explain the random slope? When "yrs" is included as a fixed effect in the model, we can explain random slope as a random slope around a fixed common slope. But if "yrs" is not included as a fixed effect, does that mean the random slope is around a common fixed slope of 0?

> Actually, I tried to add "yrs" as a fixed effect:
> ? > fm4 <- lmer(math ~ gr + sx + eth + cltype + yrs + (yrs | id) + (yrs | sch), star)
> But I got an error message "Error in mer_finalize(ans) : Downdated X'X is not positive definite, 13.", why is that?

When means that you have linearly dependent columns in the
fixed-effects model matrix.

> Thank you very much!
>
> John



From Mike.Lawrence at dal.ca  Wed Jul  7 17:57:21 2010
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Wed, 7 Jul 2010 12:57:21 -0300
Subject: [R-sig-ME] Using mixed-effects modelling to estimate between- and
	within-Ss variance in an effect
Message-ID: <AANLkTimR0VBlv7jMP_mHMj_W-kkzZs8ZOV8iugm2JXSo@mail.gmail.com>

Hi folks,

In psychology, we're often interested not only in effects, but also
their variability. This is mostly from a pragmatic perspective, where
we want to know how much time to devote to measuring a certain
phenomenon in order to reliably obtain an expected effect.
Historically, variability has been quantified with a single measure of
"reliability" (typically obtained by correlating subsets of
measurements). More recently, it has been suggested that such single
measures confound two sources of variability that are of potentially
independent interest: between-Ss variability of the effect, and
within-Ss variability of the effect. That is, we typically compute
effects based on many observations per Ss, so variability of the
effect is theoretically computable within each Ss.

Prior to my exposure to mixed-effects modelling, I used bootstrap
resampling to estimate the between- and within-Ss variabilities of the
effect, but now that I have dipped my toes into mixed-effects
modelling, I suspect that these values might be already estimated
automatically as part of the mixed-effects modelling procedures. Is
this the case, and if so, how could I obtain these estimates from,
say, the output from lmer?

Mike

-- 
Mike Lawrence
Graduate Student
Department of Psychology
Dalhousie University

Looking to arrange a meeting? Check my public calendar:
http://tr.im/mikes_public_calendar

~ Certainty is folly... I think. ~



From bates at stat.wisc.edu  Wed Jul  7 18:09:18 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 7 Jul 2010 11:09:18 -0500
Subject: [R-sig-ME] Using mixed-effects modelling to estimate between-
	and within-Ss variance in an effect
In-Reply-To: <AANLkTimR0VBlv7jMP_mHMj_W-kkzZs8ZOV8iugm2JXSo@mail.gmail.com>
References: <AANLkTimR0VBlv7jMP_mHMj_W-kkzZs8ZOV8iugm2JXSo@mail.gmail.com>
Message-ID: <AANLkTim6n95WMborsnCzKY8cUX-Tp9jhT-dLGE3FUe8R@mail.gmail.com>

A quick question of clarification, does the notation Ss stand for
"subject-stimulus"?

Perhaps you could follow up with a few sentences giving a bit more
background on the type of experiments that you have in mind.

On Wed, Jul 7, 2010 at 10:57 AM, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
> Hi folks,
>
> In psychology, we're often interested not only in effects, but also
> their variability. This is mostly from a pragmatic perspective, where
> we want to know how much time to devote to measuring a certain
> phenomenon in order to reliably obtain an expected effect.
> Historically, variability has been quantified with a single measure of
> "reliability" (typically obtained by correlating subsets of
> measurements). More recently, it has been suggested that such single
> measures confound two sources of variability that are of potentially
> independent interest: between-Ss variability of the effect, and
> within-Ss variability of the effect. That is, we typically compute
> effects based on many observations per Ss, so variability of the
> effect is theoretically computable within each Ss.
>
> Prior to my exposure to mixed-effects modelling, I used bootstrap
> resampling to estimate the between- and within-Ss variabilities of the
> effect, but now that I have dipped my toes into mixed-effects
> modelling, I suspect that these values might be already estimated
> automatically as part of the mixed-effects modelling procedures. Is
> this the case, and if so, how could I obtain these estimates from,
> say, the output from lmer?
>
> Mike
>
> --
> Mike Lawrence
> Graduate Student
> Department of Psychology
> Dalhousie University
>
> Looking to arrange a meeting? Check my public calendar:
> http://tr.im/mikes_public_calendar
>
> ~ Certainty is folly... I think. ~
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From Mike.Lawrence at dal.ca  Wed Jul  7 18:46:00 2010
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Wed, 7 Jul 2010 13:46:00 -0300
Subject: [R-sig-ME] Using mixed-effects modelling to estimate between-
	and within-Ss variance in an effect
In-Reply-To: <AANLkTim6n95WMborsnCzKY8cUX-Tp9jhT-dLGE3FUe8R@mail.gmail.com>
References: <AANLkTimR0VBlv7jMP_mHMj_W-kkzZs8ZOV8iugm2JXSo@mail.gmail.com> 
	<AANLkTim6n95WMborsnCzKY8cUX-Tp9jhT-dLGE3FUe8R@mail.gmail.com>
Message-ID: <AANLkTil2meBWVtpk4AN_bYpXp4nnImP4q1_yRsj60q_e@mail.gmail.com>

Sorry, "Ss" is an old Psych term for "Subjects", the repeated measures unit.

An example can be found in the ANT data set from the "ez" package. In
that data set is the trial-by-trial record of a (fake) experiment
involving 20 Ss (identified by column sid) who are performing a target
identification task. Response time (RT) and accuracy are measured
performance variables. There are two dependent variables (DVs) of
interest: cue (4 levels) and flanker (3 levels). The DVs are
factorially combined within each Ss, and each cell of the 4x3
combination table is repeated 12 times (randomly distributed through
time, which is indexed by the block and trial columns). Ss are
additionally divided into two groups, treatment and control.

In a study like this, I would typically set the "Center Cue" and
"Congruent Flanker" as the first levels of the cue and flanker
factors, respectively, which allows me to do a mixed effects model:

acc_fit = lmer(
    formula = acc ~ group*cue*flank + (1|sid)
    , family = 'binomial'
    , data = ANT
)

One question might be whether the "Center cue versus no cue" effect
has a different between-Ss variance than the "Center cue versus
spatial cue" effect. Or maybe we might be interested in whether those
effects have different within-Ss variance. Or possibly we might be
interested in comparing the between-Ss variance in the "Congruent
Flanker versus Incongruent Flanker" effect between the 2 groups of Ss
(or, similarly comparing the within-Ss variance of those effects
between the groups).

I guess this description suggests that I'm not only interested in
estimating between- and within-Ss variance, but also comparing such
estimates, which raises the question of how such comparison might be
reasonably achieved...

Mike

On Wed, Jul 7, 2010 at 1:09 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
> A quick question of clarification, does the notation Ss stand for
> "subject-stimulus"?
>
> Perhaps you could follow up with a few sentences giving a bit more
> background on the type of experiments that you have in mind.
>
> On Wed, Jul 7, 2010 at 10:57 AM, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
>> Hi folks,
>>
>> In psychology, we're often interested not only in effects, but also
>> their variability. This is mostly from a pragmatic perspective, where
>> we want to know how much time to devote to measuring a certain
>> phenomenon in order to reliably obtain an expected effect.
>> Historically, variability has been quantified with a single measure of
>> "reliability" (typically obtained by correlating subsets of
>> measurements). More recently, it has been suggested that such single
>> measures confound two sources of variability that are of potentially
>> independent interest: between-Ss variability of the effect, and
>> within-Ss variability of the effect. That is, we typically compute
>> effects based on many observations per Ss, so variability of the
>> effect is theoretically computable within each Ss.
>>
>> Prior to my exposure to mixed-effects modelling, I used bootstrap
>> resampling to estimate the between- and within-Ss variabilities of the
>> effect, but now that I have dipped my toes into mixed-effects
>> modelling, I suspect that these values might be already estimated
>> automatically as part of the mixed-effects modelling procedures. Is
>> this the case, and if so, how could I obtain these estimates from,
>> say, the output from lmer?
>>
>> Mike
>>
>> --
>> Mike Lawrence
>> Graduate Student
>> Department of Psychology
>> Dalhousie University
>>
>> Looking to arrange a meeting? Check my public calendar:
>> http://tr.im/mikes_public_calendar
>>
>> ~ Certainty is folly... I think. ~
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Mike Lawrence
Graduate Student
Department of Psychology
Dalhousie University

Looking to arrange a meeting? Check my public calendar:
http://tr.im/mikes_public_calendar

~ Certainty is folly... I think. ~



From cewright at uci.edu  Wed Jul  7 19:39:24 2010
From: cewright at uci.edu (Charles E. (Ted) Wright)
Date: Wed, 7 Jul 2010 10:39:24 -0700 (Pacific Daylight Time)
Subject: [R-sig-ME] Using mixed-effects modelling to estimate between-
 and within-Ss variance in an effect
In-Reply-To: <AANLkTil2meBWVtpk4AN_bYpXp4nnImP4q1_yRsj60q_e@mail.gmail.com>
References: <AANLkTimR0VBlv7jMP_mHMj_W-kkzZs8ZOV8iugm2JXSo@mail.gmail.com>
	<AANLkTim6n95WMborsnCzKY8cUX-Tp9jhT-dLGE3FUe8R@mail.gmail.com>
	<AANLkTil2meBWVtpk4AN_bYpXp4nnImP4q1_yRsj60q_e@mail.gmail.com>
Message-ID: <alpine.WNT.2.00.1007071037000.4560@pcwright>

Mike,

I am just kibbitzing this thread since I, liek you, am trying to understand 
better how I can use LMMs in psychological applications. However, in this 
message what you label as dependent variables are, I believe, independent 
variables. Wouldn't the two DVs would be RT and accuracy?

Ted Wright

On Wed, 7 Jul 2010, Mike Lawrence wrote:

> Sorry, "Ss" is an old Psych term for "Subjects", the repeated measures unit.
>
> An example can be found in the ANT data set from the "ez" package. In
> that data set is the trial-by-trial record of a (fake) experiment
> involving 20 Ss (identified by column sid) who are performing a target
> identification task. Response time (RT) and accuracy are measured
> performance variables. There are two dependent variables (DVs) of
> interest: cue (4 levels) and flanker (3 levels). The DVs are
> factorially combined within each Ss, and each cell of the 4x3
> combination table is repeated 12 times (randomly distributed through
> time, which is indexed by the block and trial columns). Ss are
> additionally divided into two groups, treatment and control.
>
> In a study like this, I would typically set the "Center Cue" and
> "Congruent Flanker" as the first levels of the cue and flanker
> factors, respectively, which allows me to do a mixed effects model:
>
> acc_fit = lmer(
>    formula = acc ~ group*cue*flank + (1|sid)
>    , family = 'binomial'
>    , data = ANT
> )
>
> One question might be whether the "Center cue versus no cue" effect
> has a different between-Ss variance than the "Center cue versus
> spatial cue" effect. Or maybe we might be interested in whether those
> effects have different within-Ss variance. Or possibly we might be
> interested in comparing the between-Ss variance in the "Congruent
> Flanker versus Incongruent Flanker" effect between the 2 groups of Ss
> (or, similarly comparing the within-Ss variance of those effects
> between the groups).
>
> I guess this description suggests that I'm not only interested in
> estimating between- and within-Ss variance, but also comparing such
> estimates, which raises the question of how such comparison might be
> reasonably achieved...
>
> Mike
>
> On Wed, Jul 7, 2010 at 1:09 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
>> A quick question of clarification, does the notation Ss stand for
>> "subject-stimulus"?
>>
>> Perhaps you could follow up with a few sentences giving a bit more
>> background on the type of experiments that you have in mind.
>>
>> On Wed, Jul 7, 2010 at 10:57 AM, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
>>> Hi folks,
>>>
>>> In psychology, we're often interested not only in effects, but also
>>> their variability. This is mostly from a pragmatic perspective, where
>>> we want to know how much time to devote to measuring a certain
>>> phenomenon in order to reliably obtain an expected effect.
>>> Historically, variability has been quantified with a single measure of
>>> "reliability" (typically obtained by correlating subsets of
>>> measurements). More recently, it has been suggested that such single
>>> measures confound two sources of variability that are of potentially
>>> independent interest: between-Ss variability of the effect, and
>>> within-Ss variability of the effect. That is, we typically compute
>>> effects based on many observations per Ss, so variability of the
>>> effect is theoretically computable within each Ss.
>>>
>>> Prior to my exposure to mixed-effects modelling, I used bootstrap
>>> resampling to estimate the between- and within-Ss variabilities of the
>>> effect, but now that I have dipped my toes into mixed-effects
>>> modelling, I suspect that these values might be already estimated
>>> automatically as part of the mixed-effects modelling procedures. Is
>>> this the case, and if so, how could I obtain these estimates from,
>>> say, the output from lmer?
>>>
>>> Mike
>>>
>>> --
>>> Mike Lawrence
>>> Graduate Student
>>> Department of Psychology
>>> Dalhousie University
>>>
>>> Looking to arrange a meeting? Check my public calendar:
>>> http://tr.im/mikes_public_calendar
>>>
>>> ~ Certainty is folly... I think. ~
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> -- 
> Mike Lawrence
> Graduate Student
> Department of Psychology
> Dalhousie University
>
> Looking to arrange a meeting? Check my public calendar:
> http://tr.im/mikes_public_calendar
>
> ~ Certainty is folly... I think. ~
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



From Mike.Lawrence at dal.ca  Wed Jul  7 20:11:04 2010
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Wed, 7 Jul 2010 15:11:04 -0300
Subject: [R-sig-ME] Using mixed-effects modelling to estimate between-
	and within-Ss variance in an effect
In-Reply-To: <alpine.WNT.2.00.1007071037000.4560@pcwright>
References: <AANLkTimR0VBlv7jMP_mHMj_W-kkzZs8ZOV8iugm2JXSo@mail.gmail.com> 
	<AANLkTim6n95WMborsnCzKY8cUX-Tp9jhT-dLGE3FUe8R@mail.gmail.com> 
	<AANLkTil2meBWVtpk4AN_bYpXp4nnImP4q1_yRsj60q_e@mail.gmail.com> 
	<alpine.WNT.2.00.1007071037000.4560@pcwright>
Message-ID: <AANLkTinWsJbKNeE4i41vuzCKeRvOKEZKZH6LwYfmX7kQ@mail.gmail.com>

Oops! Sorry, I was brought up to think about "predictor variables" and
"response variables", and while I often try to use the more
conventional "IV/DV" terminology, I often get them confused (the
reason why my original training obviated these terms I gather).

Indeed, group, cue and flanker are IVs (predictor variables). RT &
accuracy are DVs (response variables).

Sorry for the confusion!

On Wed, Jul 7, 2010 at 2:39 PM, Charles E. (Ted) Wright
<cewright at uci.edu> wrote:
> Mike,
>
> I am just kibbitzing this thread since I, liek you, am trying to understand
> better how I can use LMMs in psychological applications. However, in this
> message what you label as dependent variables are, I believe, independent
> variables. Wouldn't the two DVs would be RT and accuracy?
>
> Ted Wright
>
> On Wed, 7 Jul 2010, Mike Lawrence wrote:
>
>> Sorry, "Ss" is an old Psych term for "Subjects", the repeated measures
>> unit.
>>
>> An example can be found in the ANT data set from the "ez" package. In
>> that data set is the trial-by-trial record of a (fake) experiment
>> involving 20 Ss (identified by column sid) who are performing a target
>> identification task. Response time (RT) and accuracy are measured
>> performance variables. There are two dependent variables (DVs) of
>> interest: cue (4 levels) and flanker (3 levels). The DVs are
>> factorially combined within each Ss, and each cell of the 4x3
>> combination table is repeated 12 times (randomly distributed through
>> time, which is indexed by the block and trial columns). Ss are
>> additionally divided into two groups, treatment and control.
>>
>> In a study like this, I would typically set the "Center Cue" and
>> "Congruent Flanker" as the first levels of the cue and flanker
>> factors, respectively, which allows me to do a mixed effects model:
>>
>> acc_fit = lmer(
>> ? formula = acc ~ group*cue*flank + (1|sid)
>> ? , family = 'binomial'
>> ? , data = ANT
>> )
>>
>> One question might be whether the "Center cue versus no cue" effect
>> has a different between-Ss variance than the "Center cue versus
>> spatial cue" effect. Or maybe we might be interested in whether those
>> effects have different within-Ss variance. Or possibly we might be
>> interested in comparing the between-Ss variance in the "Congruent
>> Flanker versus Incongruent Flanker" effect between the 2 groups of Ss
>> (or, similarly comparing the within-Ss variance of those effects
>> between the groups).
>>
>> I guess this description suggests that I'm not only interested in
>> estimating between- and within-Ss variance, but also comparing such
>> estimates, which raises the question of how such comparison might be
>> reasonably achieved...
>>
>> Mike
>>
>> On Wed, Jul 7, 2010 at 1:09 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
>>>
>>> A quick question of clarification, does the notation Ss stand for
>>> "subject-stimulus"?
>>>
>>> Perhaps you could follow up with a few sentences giving a bit more
>>> background on the type of experiments that you have in mind.
>>>
>>> On Wed, Jul 7, 2010 at 10:57 AM, Mike Lawrence <Mike.Lawrence at dal.ca>
>>> wrote:
>>>>
>>>> Hi folks,
>>>>
>>>> In psychology, we're often interested not only in effects, but also
>>>> their variability. This is mostly from a pragmatic perspective, where
>>>> we want to know how much time to devote to measuring a certain
>>>> phenomenon in order to reliably obtain an expected effect.
>>>> Historically, variability has been quantified with a single measure of
>>>> "reliability" (typically obtained by correlating subsets of
>>>> measurements). More recently, it has been suggested that such single
>>>> measures confound two sources of variability that are of potentially
>>>> independent interest: between-Ss variability of the effect, and
>>>> within-Ss variability of the effect. That is, we typically compute
>>>> effects based on many observations per Ss, so variability of the
>>>> effect is theoretically computable within each Ss.
>>>>
>>>> Prior to my exposure to mixed-effects modelling, I used bootstrap
>>>> resampling to estimate the between- and within-Ss variabilities of the
>>>> effect, but now that I have dipped my toes into mixed-effects
>>>> modelling, I suspect that these values might be already estimated
>>>> automatically as part of the mixed-effects modelling procedures. Is
>>>> this the case, and if so, how could I obtain these estimates from,
>>>> say, the output from lmer?
>>>>
>>>> Mike
>>>>
>>>> --
>>>> Mike Lawrence
>>>> Graduate Student
>>>> Department of Psychology
>>>> Dalhousie University
>>>>
>>>> Looking to arrange a meeting? Check my public calendar:
>>>> http://tr.im/mikes_public_calendar
>>>>
>>>> ~ Certainty is folly... I think. ~
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>>
>> --
>> Mike Lawrence
>> Graduate Student
>> Department of Psychology
>> Dalhousie University
>>
>> Looking to arrange a meeting? Check my public calendar:
>> http://tr.im/mikes_public_calendar
>>
>> ~ Certainty is folly... I think. ~
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Mike Lawrence
Graduate Student
Department of Psychology
Dalhousie University

Looking to arrange a meeting? Check my public calendar:
http://tr.im/mikes_public_calendar

~ Certainty is folly... I think. ~



From Mike.Lawrence at dal.ca  Wed Jul  7 20:51:51 2010
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Wed, 7 Jul 2010 15:51:51 -0300
Subject: [R-sig-ME] Using mixed-effects modelling to estimate between-
	and within-Ss variance in an effect
In-Reply-To: <AANLkTin9KIn68I7nz-8As_lyrQscMeBwYKYeu1RFOX9u@mail.gmail.com>
References: <AANLkTimR0VBlv7jMP_mHMj_W-kkzZs8ZOV8iugm2JXSo@mail.gmail.com> 
	<AANLkTim6n95WMborsnCzKY8cUX-Tp9jhT-dLGE3FUe8R@mail.gmail.com> 
	<AANLkTil2meBWVtpk4AN_bYpXp4nnImP4q1_yRsj60q_e@mail.gmail.com> 
	<AANLkTin9KIn68I7nz-8As_lyrQscMeBwYKYeu1RFOX9u@mail.gmail.com>
Message-ID: <AANLkTin2nFJYYrLXlTAw7pdSNs2RqX0UICQN_1RxoFAM@mail.gmail.com>

To illustrate the measures I'm seeking, here's how I'd obtain them
normally (code alternatively downloadable at http://drop.io/qumwtvp):

library(ez)
data(ANT)

#simplify the data to a 2x2x2 for demonstration purposes
ANT = ANT[
	ANT$cue %in% c('No Cue','Center Cue')
	& ANT$flanker %in% c('Congruent Flanker','Incongruent Flanker')
	& ANT$group %in% c('Control','Treatment')
	,
]

#use bootstrap resampling to generate distributions of effects from
which the within- and between-Ss variance will be estimated
bootstrap_iterations = 10 #obviously for publication, use a much larger number!
boot = ldply(
	.data = 1:bootstrap_iterations
	, .fun = function(x){
		resampled_ANT = ddply(
			.data = ANT
			, .variables = .(sid,group,cue,flanker)
			, .fun = function(x){
				to_return = x[ sample( 1:nrow(x) , nrow(x) , replace=T ) , ]
				return(to_return)
			}
		)
		resampled_ANT_scores = ddply(
			.data = resampled_ANT
			, .variables = .(sid,group)
			, .fun = function(x){
				cue_eff = mean(x$acc[x$cue=='No Cue']) - mean(x$acc[x$cue=='Center Cue'])
				flank_eff = mean(x$acc[x$flanker=='Incongruent Flanker']) -
mean(x$acc[x$flanker=='Congruent Flanker'])
				to_return = data.frame(
					eff = c('cue','flank')
					, value = c(cue_eff,flank_eff)
				)
				return(to_return)
			}
		)
		resampled_ANT_scores$iteration = x
		return(resampled_ANT_scores)
	}
	, .progress = 'text'
)

within_variance = ddply(
	.data = boot
	, .variables = .(sid,group,eff)
	, .fun = function(x){
		to_return = data.frame(
			value = var(x$value)
		)
		return(to_return)
	}
)

within_variance_stats = ddply(
	.data = within_variance
	, .variables = .(group,eff)
	, .fun = function(x){
		to_return = data.frame(
			Mean = mean(x$value)
			, SD = sd(x$value)
		)
		return(to_return)
	}
)
print(within_variance_stats)


between_variance_per_iteration = ddply(
	.data = boot
	, .variables = .(iteration,group,eff)
	, .fun = function(x){
		to_return = data.frame(
			value = var(x$value)
		)
		return(to_return)
	}
)
between_variance_stats = ddply(
	.data = between_variance_per_iteration
	, .variables = .(group,eff)
	, .fun = function(x){
		to_return = data.frame(
			Mean = mean(x$value)
			, SD = sd(x$value)
		)
		return(to_return)
	}
)
print(between_variance_stats)



From gangchen6 at gmail.com  Wed Jul  7 23:06:00 2010
From: gangchen6 at gmail.com (Gang Chen)
Date: Wed, 7 Jul 2010 17:06:00 -0400
Subject: [R-sig-ME] Extracting variances from a mer object
Message-ID: <AANLkTinTBwkgmxa69yytvl9jrPI2RVQxMPOnTq-iFO7z@mail.gmail.com>

This is a simple question. When fitting a model with lmer, how can I
extract all the variances from the output object? For example, with
the following analysis, I just want to extract the column of Variance
under the Random effects table - those 3 variance numbers: 0.63756 for
Subj, 23.03698 for Scan, and 199.50496 for Residual. VarCorr(fm) only
gives me the first two. I couldn't find any slots for this purpose
from str(fm) either.

> (fm<-lmer(Rep~(1|Subj)+(1|Scan), data=Model))
Linear mixed model fit by REML
Formula: Rep ~ (1 | Subj) + (1 | Scan)
   Data: Model
   AIC   BIC logLik deviance REMLdev
 166.4 170.3 -79.18    163.2   158.4
Random effects:
 Groups   Name        Variance  Std.Dev.
 Subj     (Intercept)   0.63756  0.79847
 Scan     (Intercept)  23.03698  4.79969
 Residual             199.50496 14.12462
Number of obs: 20, groups: Subj, 10; Scan, 2

Fixed effects:
            Estimate Std. Error t value
(Intercept)   27.603      4.642   5.946

Thanks,
Gang



From bates at stat.wisc.edu  Wed Jul  7 23:13:50 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 7 Jul 2010 16:13:50 -0500
Subject: [R-sig-ME] Extracting variances from a mer object
In-Reply-To: <AANLkTinTBwkgmxa69yytvl9jrPI2RVQxMPOnTq-iFO7z@mail.gmail.com>
References: <AANLkTinTBwkgmxa69yytvl9jrPI2RVQxMPOnTq-iFO7z@mail.gmail.com>
Message-ID: <AANLkTilfizPJsceXVHuTAS4NW5CV_TIq-zeN0y2YJNMA@mail.gmail.com>

On Wed, Jul 7, 2010 at 4:06 PM, Gang Chen <gangchen6 at gmail.com> wrote:
> This is a simple question. When fitting a model with lmer, how can I
> extract all the variances from the output object? For example, with
> the following analysis, I just want to extract the column of Variance
> under the Random effects table - those 3 variance numbers: 0.63756 for
> Subj, 23.03698 for Scan, and 199.50496 for Residual. VarCorr(fm) only
> gives me the first two. I couldn't find any slots for this purpose
> from str(fm) either.

?VarCorr

>> (fm<-lmer(Rep~(1|Subj)+(1|Scan), data=Model))
> Linear mixed model fit by REML
> Formula: Rep ~ (1 | Subj) + (1 | Scan)
> ? Data: Model
> ? AIC ? BIC logLik deviance REMLdev
> ?166.4 170.3 -79.18 ? ?163.2 ? 158.4
> Random effects:
> ?Groups ? Name ? ? ? ?Variance ?Std.Dev.
> ?Subj ? ? (Intercept) ? 0.63756 ?0.79847
> ?Scan ? ? (Intercept) ?23.03698 ?4.79969
> ?Residual ? ? ? ? ? ? 199.50496 14.12462
> Number of obs: 20, groups: Subj, 10; Scan, 2
>
> Fixed effects:
> ? ? ? ? ? ?Estimate Std. Error t value
> (Intercept) ? 27.603 ? ? ?4.642 ? 5.946
>
> Thanks,
> Gang
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Wed Jul  7 23:16:27 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 7 Jul 2010 16:16:27 -0500
Subject: [R-sig-ME] Extracting variances from a mer object
In-Reply-To: <AANLkTilfizPJsceXVHuTAS4NW5CV_TIq-zeN0y2YJNMA@mail.gmail.com>
References: <AANLkTinTBwkgmxa69yytvl9jrPI2RVQxMPOnTq-iFO7z@mail.gmail.com>
	<AANLkTilfizPJsceXVHuTAS4NW5CV_TIq-zeN0y2YJNMA@mail.gmail.com>
Message-ID: <AANLkTimYlRlerfotM1i_OSSGGyRLFvngMNVvlqseKRDZ@mail.gmail.com>

On Wed, Jul 7, 2010 at 4:13 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
> On Wed, Jul 7, 2010 at 4:06 PM, Gang Chen <gangchen6 at gmail.com> wrote:
>> This is a simple question. When fitting a model with lmer, how can I
>> extract all the variances from the output object? For example, with
>> the following analysis, I just want to extract the column of Variance
>> under the Random effects table - those 3 variance numbers: 0.63756 for
>> Subj, 23.03698 for Scan, and 199.50496 for Residual. VarCorr(fm) only
>> gives me the first two. I couldn't find any slots for this purpose
>> from str(fm) either.
>
> ?VarCorr

Sorry, I answered too quickly.  You had checked the result of VarCorr.
 The residual variance is square of the "sc" attribute.

> fm1 <- lmer(Yield ~ 1 + (1|Batch), Dyestuff)
> str(VarCorr(fm1))
List of 1
 $ Batch: num [1, 1] 1764
  ..- attr(*, "dimnames")=List of 2
  .. ..$ : chr "(Intercept)"
  .. ..$ : chr "(Intercept)"
  ..- attr(*, "stddev")= Named num 42
  .. ..- attr(*, "names")= chr "(Intercept)"
  ..- attr(*, "correlation")= num [1, 1] 1
  .. ..- attr(*, "dimnames")=List of 2
  .. .. ..$ : chr "(Intercept)"
  .. .. ..$ : chr "(Intercept)"
 - attr(*, "sc")= num 49.5
> fm1
Linear mixed model fit by REML
Formula: Yield ~ 1 + (1 | Batch)
   Data: Dyestuff
   AIC   BIC logLik deviance REMLdev
 325.7 329.9 -159.8    327.4   319.7
Random effects:
 Groups   Name        Variance Std.Dev.
 Batch    (Intercept) 1764.0   42.001
 Residual             2451.3   49.510
Number of obs: 30, groups: Batch, 6

Fixed effects:
            Estimate Std. Error t value
(Intercept)  1527.50      19.38   78.81


>>> (fm<-lmer(Rep~(1|Subj)+(1|Scan), data=Model))
>> Linear mixed model fit by REML
>> Formula: Rep ~ (1 | Subj) + (1 | Scan)
>> ? Data: Model
>> ? AIC ? BIC logLik deviance REMLdev
>> ?166.4 170.3 -79.18 ? ?163.2 ? 158.4
>> Random effects:
>> ?Groups ? Name ? ? ? ?Variance ?Std.Dev.
>> ?Subj ? ? (Intercept) ? 0.63756 ?0.79847
>> ?Scan ? ? (Intercept) ?23.03698 ?4.79969
>> ?Residual ? ? ? ? ? ? 199.50496 14.12462
>> Number of obs: 20, groups: Subj, 10; Scan, 2
>>
>> Fixed effects:
>> ? ? ? ? ? ?Estimate Std. Error t value
>> (Intercept) ? 27.603 ? ? ?4.642 ? 5.946
>>
>> Thanks,
>> Gang
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>



From gangchen6 at gmail.com  Wed Jul  7 23:18:54 2010
From: gangchen6 at gmail.com (Gang Chen)
Date: Wed, 7 Jul 2010 17:18:54 -0400
Subject: [R-sig-ME] Extracting variances from a mer object
In-Reply-To: <AANLkTimYlRlerfotM1i_OSSGGyRLFvngMNVvlqseKRDZ@mail.gmail.com>
References: <AANLkTinTBwkgmxa69yytvl9jrPI2RVQxMPOnTq-iFO7z@mail.gmail.com>
	<AANLkTilfizPJsceXVHuTAS4NW5CV_TIq-zeN0y2YJNMA@mail.gmail.com>
	<AANLkTimYlRlerfotM1i_OSSGGyRLFvngMNVvlqseKRDZ@mail.gmail.com>
Message-ID: <AANLkTilCJJRHnopwVQkNIP9IHrvcbDleE9V6A6CjZy1h@mail.gmail.com>

Thanks a lot for the quick help! I really appreciate it...

Gang

On Wed, Jul 7, 2010 at 5:16 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
> On Wed, Jul 7, 2010 at 4:13 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
>> On Wed, Jul 7, 2010 at 4:06 PM, Gang Chen <gangchen6 at gmail.com> wrote:
>>> This is a simple question. When fitting a model with lmer, how can I
>>> extract all the variances from the output object? For example, with
>>> the following analysis, I just want to extract the column of Variance
>>> under the Random effects table - those 3 variance numbers: 0.63756 for
>>> Subj, 23.03698 for Scan, and 199.50496 for Residual. VarCorr(fm) only
>>> gives me the first two. I couldn't find any slots for this purpose
>>> from str(fm) either.
>>
>> ?VarCorr
>
> Sorry, I answered too quickly. ?You had checked the result of VarCorr.
> ?The residual variance is square of the "sc" attribute.
>
>> fm1 <- lmer(Yield ~ 1 + (1|Batch), Dyestuff)
>> str(VarCorr(fm1))
> List of 1
> ?$ Batch: num [1, 1] 1764
> ?..- attr(*, "dimnames")=List of 2
> ?.. ..$ : chr "(Intercept)"
> ?.. ..$ : chr "(Intercept)"
> ?..- attr(*, "stddev")= Named num 42
> ?.. ..- attr(*, "names")= chr "(Intercept)"
> ?..- attr(*, "correlation")= num [1, 1] 1
> ?.. ..- attr(*, "dimnames")=List of 2
> ?.. .. ..$ : chr "(Intercept)"
> ?.. .. ..$ : chr "(Intercept)"
> ?- attr(*, "sc")= num 49.5
>> fm1
> Linear mixed model fit by REML
> Formula: Yield ~ 1 + (1 | Batch)
> ? Data: Dyestuff
> ? AIC ? BIC logLik deviance REMLdev
> ?325.7 329.9 -159.8 ? ?327.4 ? 319.7
> Random effects:
> ?Groups ? Name ? ? ? ?Variance Std.Dev.
> ?Batch ? ?(Intercept) 1764.0 ? 42.001
> ?Residual ? ? ? ? ? ? 2451.3 ? 49.510
> Number of obs: 30, groups: Batch, 6
>
> Fixed effects:
> ? ? ? ? ? ?Estimate Std. Error t value
> (Intercept) ?1527.50 ? ? ?19.38 ? 78.81
>
>
>>>> (fm<-lmer(Rep~(1|Subj)+(1|Scan), data=Model))
>>> Linear mixed model fit by REML
>>> Formula: Rep ~ (1 | Subj) + (1 | Scan)
>>> ? Data: Model
>>> ? AIC ? BIC logLik deviance REMLdev
>>> ?166.4 170.3 -79.18 ? ?163.2 ? 158.4
>>> Random effects:
>>> ?Groups ? Name ? ? ? ?Variance ?Std.Dev.
>>> ?Subj ? ? (Intercept) ? 0.63756 ?0.79847
>>> ?Scan ? ? (Intercept) ?23.03698 ?4.79969
>>> ?Residual ? ? ? ? ? ? 199.50496 14.12462
>>> Number of obs: 20, groups: Subj, 10; Scan, 2
>>>
>>> Fixed effects:
>>> ? ? ? ? ? ?Estimate Std. Error t value
>>> (Intercept) ? 27.603 ? ? ?4.642 ? 5.946
>>>
>>> Thanks,
>>> Gang
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>



-- 
Existence is elsewhere.
? Andr? Breton, ?The Surrealist Manifesto?



From aleman at fordham.edu  Thu Jul  8 04:14:03 2010
From: aleman at fordham.edu (JOSE A ALEMAN)
Date: 07-Jul-2010 22:14:03 EDT
Subject: [R-sig-ME] question about linear mixed models
Message-ID: <OFC9044B44.1F4C415E-ON8525775A.000C2F2B@fordham.edu>


Dear list users,

I have perhaps what may seem like a very simple question, given that I'm
new to R. I have been trying to fit a linear mixed effects model to a TSCS
dataset where I want to include random intercepts for country and year. I
have noticed that I get slightly different results depending on what
package I use (lme4 and nmle). I think this may have to do with the syntax
for specifying the random effects formula with nmle. With lme4, I type
something like this:

mixed.model <- lmer (y ~ x1+x2+x3 + (1 | nation) + (1 | year), data=data)

and R returns the following output for the random effects:

Random effects:
 Groups   Name          Variance   Std.Dev.
 year          (Intercept)   0.00            0.00
 nation      (Intercept)   9.40            3.07
 Residual                      2.42             1.56

With nmle, however, the formula would have to look something like this:

mixed.effects <- lme (y ~ x1+x2+x3, data=data,
      random=~1|nation+1|year, method="REML")

The results, however, are different, and this leads me to suspect that I'm
not specifying the random effects formula correctly since R returns the
following formula:

Random effects:
 Formula: ~1 | nation + 1 | year
 Structure: General positive-definite, Log-Cholesky parametrization
                                           StdDev     Corr
(Intercept)                          0.9003       (Intr)
1 | nation + 1TRUE             0.9649       -0.918
Residual                             2.0908


Why is this the case? Or am I missing something important?

Thank you,
Jose A. Aleman, Ph.D.
http://faculty.fordham.edu/aleman



From cotter.rs at gmail.com  Thu Jul  8 09:44:13 2010
From: cotter.rs at gmail.com (R.S. Cotter)
Date: Thu, 8 Jul 2010 09:44:13 +0200
Subject: [R-sig-ME] lme constrasts for interaction effects group*time and
	group it self
Message-ID: <AANLkTimptMynt4ALU5iRhXF54BDlk-2wVlK8x04hfabF@mail.gmail.com>

Hello,

I have a question regarding lme ().

First little bit background, the question is stated below.

I want to test the effect of Time on response Y, and whether this effect
differs between Group (A, B, C)

Package: lme(nlme)

Test1<-lme(Y ~ Group*Time,random=~1|ID)

To test for differences between groups reagding the effect of time:

options( contrasts = c("contr.treatment", "contr.poly"))
anova(Test1, L = c("GroupA:Time"=1,"GroupC:Time"=-1))

Let us say that the interaction "Group*Time" is significant and that Group B
and C are significant steeper than A. To illustrate I've made a figure with
different slopes (calculated from lme () parameter estimates) for the effect
of Time on the response Y for the different Groups (A, B, C).

My question:

I'm mainly interested to test for test the effect of Time on response Y, and
whether this effect differs between Group (A, B, C). And that worked well by
using "options( contrasts = c("contr.treatment", "contr.poly"))".
*However, from
the figure (attached), the slope C is far below A and B, is it possible to
test this?*
**
Regards Cotter

From andydolman at gmail.com  Thu Jul  8 09:56:20 2010
From: andydolman at gmail.com (Andrew Dolman)
Date: Thu, 8 Jul 2010 09:56:20 +0200
Subject: [R-sig-ME] question about linear mixed models
In-Reply-To: <OFC9044B44.1F4C415E-ON8525775A.000C2F2B@fordham.edu>
References: <OFC9044B44.1F4C415E-ON8525775A.000C2F2B@fordham.edu>
Message-ID: <AANLkTikOmU23JPVhXRA-bN9cEZT3xEJwSqvCkGgIhaTU@mail.gmail.com>

Hello Jose,

lme4 can handle crossed and nested random effects whereas nlme can
only do nested random effects.

What you've specified here:

> mixed.model <- lmer (y ~ x1+x2+x3 + (1 | nation) + (1 | year), data=data)

has crossed random effects.

> and R returns the following output for the random effects:
>
> Random effects:
> ?Groups ? Name ? ? ? ? ?Variance ? Std.Dev.
> ?year ? ? ? ? ?(Intercept) ? 0.00 ? ? ? ? ? ?0.00
> ?nation ? ? ?(Intercept) ? 9.40 ? ? ? ? ? ?3.07
> ?Residual ? ? ? ? ? ? ? ? ? ? ?2.42 ? ? ? ? ? ? 1.56

and you seem to have zero variance associated with the random effect
"year". This may be a problem with the way you've coded your data
which is why it's helpful if you post a sample of your data, or dummy
data, with your question.

do > head(mydataframe)
the output from str (mydataframe) is useful too because we can see how
many levels of each factor you have


If you want a nested model in lme4 you should specify it as  + (1 |
nation/year) OR +(1|nation) + (1|nation:year)


I'm not sure what the model is that you specified in nlme but it can't
be the same as the one for lme4 because nlme cannot do crossed random
effects

> mixed.effects <- lme (y ~ x1+x2+x3, data=data,
> ? ? ?random=~1|nation+1|year, method="REML")


Andy.



From kw.stat at gmail.com  Thu Jul  8 13:56:00 2010
From: kw.stat at gmail.com (Kevin Wright)
Date: Thu, 8 Jul 2010 06:56:00 -0500
Subject: [R-sig-ME] question about linear mixed models
In-Reply-To: <AANLkTikOmU23JPVhXRA-bN9cEZT3xEJwSqvCkGgIhaTU@mail.gmail.com>
References: <OFC9044B44.1F4C415E-ON8525775A.000C2F2B@fordham.edu>
	<AANLkTikOmU23JPVhXRA-bN9cEZT3xEJwSqvCkGgIhaTU@mail.gmail.com>
Message-ID: <AANLkTilJnZgcfHuzvJtywmdFAhYRWde6n9mtG53fRhyg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100708/3b763049/attachment.pl>

From bates at stat.wisc.edu  Thu Jul  8 14:59:18 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 8 Jul 2010 07:59:18 -0500
Subject: [R-sig-ME] question about linear mixed models
In-Reply-To: <AANLkTilJnZgcfHuzvJtywmdFAhYRWde6n9mtG53fRhyg@mail.gmail.com>
References: <OFC9044B44.1F4C415E-ON8525775A.000C2F2B@fordham.edu>
	<AANLkTikOmU23JPVhXRA-bN9cEZT3xEJwSqvCkGgIhaTU@mail.gmail.com>
	<AANLkTilJnZgcfHuzvJtywmdFAhYRWde6n9mtG53fRhyg@mail.gmail.com>
Message-ID: <AANLkTikJP46AzV02wH_6vb6qSyt82GxL0Zn6MqRdX0mT@mail.gmail.com>

On Thu, Jul 8, 2010 at 6:56 AM, Kevin Wright <kw.stat at gmail.com> wrote:
>> lme4 can handle crossed and nested random effects whereas nlme can
>> only do nested random effects.
>>
> Actually, nlme *can* do crossed random effects.
>
> In the book by Pinheiro and Bates, see the Cell Culture
> Bioassay example starting on pg 163 for a demonstration
> of fitting crossed random effects using pdIdent and pdBlocked objects.

Yes, but that is a horrible kludge and would not be suitable for cases
with more than a few levels for each of the grouping factors.

It is much better to use lme4 when fitting models with crossed random effects.



From bates at stat.wisc.edu  Thu Jul  8 15:01:02 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 8 Jul 2010 08:01:02 -0500
Subject: [R-sig-ME] lme constrasts for interaction effects group*time
	and group it self
In-Reply-To: <AANLkTimptMynt4ALU5iRhXF54BDlk-2wVlK8x04hfabF@mail.gmail.com>
References: <AANLkTimptMynt4ALU5iRhXF54BDlk-2wVlK8x04hfabF@mail.gmail.com>
Message-ID: <AANLkTimfJsvGxaq7WcLsd03PmHYGdAukyWeIbaWPg3lA@mail.gmail.com>

On Thu, Jul 8, 2010 at 2:44 AM, R.S. Cotter <cotter.rs at gmail.com> wrote:
> Hello,
>
> I have a question regarding lme ().
>
> First little bit background, the question is stated below.
>
> I want to test the effect of Time on response Y, and whether this effect
> differs between Group (A, B, C)
>
> Package: lme(nlme)
>
> Test1<-lme(Y ~ Group*Time,random=~1|ID)
>
> To test for differences between groups reagding the effect of time:
>
> options( contrasts = c("contr.treatment", "contr.poly"))
> anova(Test1, L = c("GroupA:Time"=1,"GroupC:Time"=-1))
>
> Let us say that the interaction "Group*Time" is significant and that Group B
> and C are significant steeper than A. To illustrate I've made a figure with
> different slopes (calculated from lme () parameter estimates) for the effect
> of Time on the response Y for the different Groups (A, B, C).
>
> My question:
>
> I'm mainly interested to test for test the effect of Time on response Y, and
> whether this effect differs between Group (A, B, C). And that worked well by
> using "options( contrasts = c("contr.treatment", "contr.poly"))".
> *However, from
> the figure (attached), the slope C is far below A and B, is it possible to
> test this?*
> **

The figure wasn't enclosed with my copy at least.



From aleman at fordham.edu  Thu Jul  8 17:53:37 2010
From: aleman at fordham.edu (JOSE A ALEMAN)
Date: 08-Jul-2010 11:53:37 EDT
Subject: [R-sig-ME] question about linear mixed models
In-Reply-To: <AANLkTikOmU23JPVhXRA-bN9cEZT3xEJwSqvCkGgIhaTU@mail.gmail.com>
Message-ID: <OFA8455424.45441A18-ON8525775A.0056E0ED@fordham.edu>

Dear Andrew, Douglas and Kevin,

Thank you for you quick and helpful responses. Andrew, this is what the
first six lines of the dataframe look like

    country    nation year gini_gross gini_net miwseppp miwsenc compens
1 Australia Australia 1960      39.19    28.48       NA      NA   10045
2 Australia Australia 1961      39.26    28.43       NA      NA   10378
3 Australia Australia 1962      39.22    28.64       NA      NA   11148
4 Australia Australia 1963      39.03    28.29       NA      NA   12026
5 Australia Australia 1964      38.83    28.20     3405    2622   13145
6 Australia Australia 1965      38.45    27.71     3655    2814   14397

There are 18 countries (or nations) and 40 years (1960 to 2000). It seems a
little bit strange that the variance for year is 0.

Jose



                                                                           
             Andrew Dolman                                                 
             <andydolman at gmail                                             
             .com>                                                      To 
                                       JOSE A ALEMAN <aleman at fordham.edu>  
             07/08/2010 03:56                                           cc 
             AM                        r-sig-mixed-models at r-project.org    
                                                                   Subject 
                                       Re: [R-sig-ME] question about       
                                       linear mixed models                 
                                                                           
                                                                           
                                                                           
                                                                           
                                                                           
                                                                           




Hello Jose,

lme4 can handle crossed and nested random effects whereas nlme can
only do nested random effects.

What you've specified here:

> mixed.model <- lmer (y ~ x1+x2+x3 + (1 | nation) + (1 | year), data=data)

has crossed random effects.

> and R returns the following output for the random effects:
>
> Random effects:
> ?Groups ? Name ? ? ? ? ?Variance ? Std.Dev.
> ?year ? ? ? ? ?(Intercept) ? 0.00 ? ? ? ? ? ?0.00
> ?nation ? ? ?(Intercept) ? 9.40 ? ? ? ? ? ?3.07
> ?Residual ? ? ? ? ? ? ? ? ? ? ?2.42 ? ? ? ? ? ? 1.56

and you seem to have zero variance associated with the random effect
"year". This may be a problem with the way you've coded your data
which is why it's helpful if you post a sample of your data, or dummy
data, with your question.

do > head(mydataframe)
the output from str (mydataframe) is useful too because we can see how
many levels of each factor you have


If you want a nested model in lme4 you should specify it as  + (1 |
nation/year) OR +(1|nation) + (1|nation:year)


I'm not sure what the model is that you specified in nlme but it can't
be the same as the one for lme4 because nlme cannot do crossed random
effects

> mixed.effects <- lme (y ~ x1+x2+x3, data=data,
> ? ? ?random=~1|nation+1|year, method="REML")


Andy.



From aleman at fordham.edu  Thu Jul  8 18:12:49 2010
From: aleman at fordham.edu (JOSE A ALEMAN)
Date: 08-Jul-2010 12:12:49 EDT
Subject: [R-sig-ME] question about linear mixed models
In-Reply-To: <AANLkTikOmU23JPVhXRA-bN9cEZT3xEJwSqvCkGgIhaTU@mail.gmail.com>
Message-ID: <OFCF35CDA4.86576792-ON8525775A.00581870@fordham.edu>


Ok, so now I'm slightly confused, because I tried (1 |nation/year) and nmle
returned the exact same results that lme4 returns when you use the syntax
(1 | nation) + (1 | year). I thought was I was trying to estimate was cross
random effects, not nested random effects. To be more precise, the model I
want to estimate looks like this:

                  (Embedded image moved to file: pic08452.jpg),


where the terms (Embedded image moved to file: pic12342.jpg) and (Embedded
image moved to file: pic08045.jpg) are varying-intercept parameters for
units and time.

Yet the output is identical...

Thanks,

Jose


                                                                           
             Andrew Dolman                                                 
             <andydolman at gmail                                             
             .com>                                                      To 
                                       JOSE A ALEMAN <aleman at fordham.edu>  
             07/08/2010 03:56                                           cc 
             AM                        r-sig-mixed-models at r-project.org    
                                                                   Subject 
                                       Re: [R-sig-ME] question about       
                                       linear mixed models                 
                                                                           
                                                                           
                                                                           
                                                                           
                                                                           
                                                                           




Hello Jose,

lme4 can handle crossed and nested random effects whereas nlme can
only do nested random effects.

What you've specified here:

> mixed.model <- lmer (y ~ x1+x2+x3 + (1 | nation) + (1 | year), data=data)

has crossed random effects.

> and R returns the following output for the random effects:
>
> Random effects:
> ?Groups ? Name ? ? ? ? ?Variance ? Std.Dev.
> ?year ? ? ? ? ?(Intercept) ? 0.00 ? ? ? ? ? ?0.00
> ?nation ? ? ?(Intercept) ? 9.40 ? ? ? ? ? ?3.07
> ?Residual ? ? ? ? ? ? ? ? ? ? ?2.42 ? ? ? ? ? ? 1.56

and you seem to have zero variance associated with the random effect
"year". This may be a problem with the way you've coded your data
which is why it's helpful if you post a sample of your data, or dummy
data, with your question.

do > head(mydataframe)
the output from str (mydataframe) is useful too because we can see how
many levels of each factor you have


If you want a nested model in lme4 you should specify it as  + (1 |
nation/year) OR +(1|nation) + (1|nation:year)


I'm not sure what the model is that you specified in nlme but it can't
be the same as the one for lme4 because nlme cannot do crossed random
effects

> mixed.effects <- lme (y ~ x1+x2+x3, data=data,
> ? ? ?random=~1|nation+1|year, method="REML")


Andy.

From andydolman at gmail.com  Thu Jul  8 18:32:52 2010
From: andydolman at gmail.com (Andrew Dolman)
Date: Thu, 8 Jul 2010 18:32:52 +0200
Subject: [R-sig-ME] question about linear mixed models
In-Reply-To: <OFCF35CDA4.86576792-ON8525775A.00581870@fordham.edu>
References: <AANLkTikOmU23JPVhXRA-bN9cEZT3xEJwSqvCkGgIhaTU@mail.gmail.com>
	<OFCF35CDA4.86576792-ON8525775A.00581870@fordham.edu>
Message-ID: <AANLkTikI7t288lN5MKfO_C1dQ4Wve7bcSC5AurjFns5k@mail.gmail.com>

That's odd. What does str(data) give you?


andydolman at gmail.com



On 8 July 2010 18:12, JOSE A ALEMAN <aleman at fordham.edu> wrote:
>
> Ok, so now I'm slightly confused, because I tried (1 |nation/year) and nmle
> returned the exact same results that lme4 returns when you use the syntax
> (1 | nation) + (1 | year). I thought was I was trying to estimate was cross
> random effects, not nested random effects. To be more precise, the model I
> want to estimate looks like this:
>
> ? ? ? ? ? ? ? ? ?(Embedded image moved to file: pic23743.jpg),
>
>
> where the terms (Embedded image moved to file: pic03517.jpg) and (Embedded
> image moved to file: pic15204.jpg) are varying-intercept parameters for
> units and time.
>
> Yet the output is identical...
>
> Thanks,
>
> Jose
>
>
>
> ? ? ? ? ? ? Andrew Dolman
> ? ? ? ? ? ? <andydolman at gmail
> ? ? ? ? ? ? .com> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?To
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? JOSE A ALEMAN <aleman at fordham.edu>
> ? ? ? ? ? ? 07/08/2010 03:56 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? cc
> ? ? ? ? ? ? AM ? ? ? ? ? ? ? ? ? ? ? ?r-sig-mixed-models at r-project.org
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Subject
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Re: [R-sig-ME] question about
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? linear mixed models
>
>
>
>
>
>
>
>
>
>
> Hello Jose,
>
> lme4 can handle crossed and nested random effects whereas nlme can
> only do nested random effects.
>
> What you've specified here:
>
>> mixed.model <- lmer (y ~ x1+x2+x3 + (1 | nation) + (1 | year), data=data)
>
> has crossed random effects.
>
>> and R returns the following output for the random effects:
>>
>> Random effects:
>> ?Groups ? Name ? ? ? ? ?Variance ? Std.Dev.
>> ?year ? ? ? ? ?(Intercept) ? 0.00 ? ? ? ? ? ?0.00
>> ?nation ? ? ?(Intercept) ? 9.40 ? ? ? ? ? ?3.07
>> ?Residual ? ? ? ? ? ? ? ? ? ? ?2.42 ? ? ? ? ? ? 1.56
>
> and you seem to have zero variance associated with the random effect
> "year". This may be a problem with the way you've coded your data
> which is why it's helpful if you post a sample of your data, or dummy
> data, with your question.
>
> do > head(mydataframe)
> the output from str (mydataframe) is useful too because we can see how
> many levels of each factor you have
>
>
> If you want a nested model in lme4 you should specify it as ?+ (1 |
> nation/year) OR +(1|nation) + (1|nation:year)
>
>
> I'm not sure what the model is that you specified in nlme but it can't
> be the same as the one for lme4 because nlme cannot do crossed random
> effects
>
>> mixed.effects <- lme (y ~ x1+x2+x3, data=data,
>> ? ? ?random=~1|nation+1|year, method="REML")
>
>
> Andy.
>



From aleman at fordham.edu  Thu Jul  8 19:34:04 2010
From: aleman at fordham.edu (JOSE A ALEMAN)
Date: 08-Jul-2010 13:34:04 EDT
Subject: [R-sig-ME] question about linear mixed models
In-Reply-To: <AANLkTikI7t288lN5MKfO_C1dQ4Wve7bcSC5AurjFns5k@mail.gmail.com>
Message-ID: <OF9E89A003.45F0B6D8-ON8525775A.006065DC@fordham.edu>

str(data) returns the following output:

 $ country                   : chr  "Australia" "Australia" "Australia"
"Australia" ...
 $ nation                    : Factor w/ 18 levels
"Australia","Austria",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ year                      : num  1960 1961 1962 1963 1964 ...

I have two other dependent variables though, and the results differ between
nmle and lme4.




                                                                           
             Andrew Dolman                                                 
             <andydolman at gmail                                             
             .com>                                                      To 
                                       JOSE A ALEMAN <aleman at fordham.edu>  
             07/08/2010 12:32                                           cc 
             PM                        r-sig-mixed-models at r-project.org    
                                                                   Subject 
                                       Re: [R-sig-ME] question about       
                                       linear mixed models                 
                                                                           
                                                                           
                                                                           
                                                                           
                                                                           
                                                                           




That's odd. What does str(data) give you?


andydolman at gmail.com



On 8 July 2010 18:12, JOSE A ALEMAN <aleman at fordham.edu> wrote:
>
> Ok, so now I'm slightly confused, because I tried (1 |nation/year) and
nmle
> returned the exact same results that lme4 returns when you use the syntax
> (1 | nation) + (1 | year). I thought was I was trying to estimate was
cross
> random effects, not nested random effects. To be more precise, the model
I
> want to estimate looks like this:
>
> ? ? ? ? ? ? ? ? ?(Embedded image moved to file: pic23743.jpg),
>
>
> where the terms (Embedded image moved to file: pic03517.jpg) and
(Embedded
> image moved to file: pic15204.jpg) are varying-intercept parameters for
> units and time.
>
> Yet the output is identical...
>
> Thanks,
>
> Jose
>
>
>
> ? ? ? ? ? ? Andrew Dolman
> ? ? ? ? ? ? <andydolman at gmail
> ? ? ? ? ? ? .com> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?To
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? JOSE A ALEMAN <aleman at fordham.edu>
> ? ? ? ? ? ? 07/08/2010 03:56 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? cc
> ? ? ? ? ? ? AM ? ? ? ? ? ? ? ? ? ? ? ?r-sig-mixed-models at r-project.org
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Subject
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Re: [R-sig-ME] question about
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? linear mixed models
>
>
>
>
>
>
>
>
>
>
> Hello Jose,
>
> lme4 can handle crossed and nested random effects whereas nlme can
> only do nested random effects.
>
> What you've specified here:
>
>> mixed.model <- lmer (y ~ x1+x2+x3 + (1 | nation) + (1 | year),
data=data)
>
> has crossed random effects.
>
>> and R returns the following output for the random effects:
>>
>> Random effects:
>> ?Groups ? Name ? ? ? ? ?Variance ? Std.Dev.
>> ?year ? ? ? ? ?(Intercept) ? 0.00 ? ? ? ? ? ?0.00
>> ?nation ? ? ?(Intercept) ? 9.40 ? ? ? ? ? ?3.07
>> ?Residual ? ? ? ? ? ? ? ? ? ? ?2.42 ? ? ? ? ? ? 1.56
>
> and you seem to have zero variance associated with the random effect
> "year". This may be a problem with the way you've coded your data
> which is why it's helpful if you post a sample of your data, or dummy
> data, with your question.
>
> do > head(mydataframe)
> the output from str (mydataframe) is useful too because we can see how
> many levels of each factor you have
>
>
> If you want a nested model in lme4 you should specify it as ?+ (1 |
> nation/year) OR +(1|nation) + (1|nation:year)
>
>
> I'm not sure what the model is that you specified in nlme but it can't
> be the same as the one for lme4 because nlme cannot do crossed random
> effects
>
>> mixed.effects <- lme (y ~ x1+x2+x3, data=data,
>> ? ? ?random=~1|nation+1|year, method="REML")
>
>
> Andy.
>



From bates at stat.wisc.edu  Thu Jul  8 19:46:12 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 8 Jul 2010 12:46:12 -0500
Subject: [R-sig-ME] question about linear mixed models
In-Reply-To: <OF9E89A003.45F0B6D8-ON8525775A.006065DC@fordham.edu>
References: <AANLkTikI7t288lN5MKfO_C1dQ4Wve7bcSC5AurjFns5k@mail.gmail.com>
	<OF9E89A003.45F0B6D8-ON8525775A.006065DC@fordham.edu>
Message-ID: <AANLkTim-6C4L115AksPOvWX8A_LoOGOeEGc2fKiMU1Wa@mail.gmail.com>

On Thu, Jul 8, 2010 at 12:34 PM, JOSE A ALEMAN <aleman at fordham.edu> wrote:
> str(data) returns the following output:
>
> ?$ country ? ? ? ? ? ? ? ? ? : chr ?"Australia" "Australia" "Australia"
> "Australia" ...
> ?$ nation ? ? ? ? ? ? ? ? ? ?: Factor w/ 18 levels
> "Australia","Austria",..: 1 1 1 1 1 1 1 1 1 1 ...
> ?$ year ? ? ? ? ? ? ? ? ? ? ?: num ?1960 1961 1962 1963 1964 ...

year should be a factor if you want to fit models with terms like
(1|nation) + (1|year).  In lmer it will be coerced to a factor when
used on the right hand side of a random-effects term but not
necessarily in the model formulations in the nlme package.

> I have two other dependent variables though, and the results differ between
> nmle and lme4.
>
>
>
>
>
> ? ? ? ? ? ? Andrew Dolman
> ? ? ? ? ? ? <andydolman at gmail
> ? ? ? ? ? ? .com> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?To
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? JOSE A ALEMAN <aleman at fordham.edu>
> ? ? ? ? ? ? 07/08/2010 12:32 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? cc
> ? ? ? ? ? ? PM ? ? ? ? ? ? ? ? ? ? ? ?r-sig-mixed-models at r-project.org
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Subject
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Re: [R-sig-ME] question about
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? linear mixed models
>
>
>
>
>
>
>
>
>
>
> That's odd. What does str(data) give you?
>
>
> andydolman at gmail.com
>
>
>
> On 8 July 2010 18:12, JOSE A ALEMAN <aleman at fordham.edu> wrote:
>>
>> Ok, so now I'm slightly confused, because I tried (1 |nation/year) and
> nmle
>> returned the exact same results that lme4 returns when you use the syntax
>> (1 | nation) + (1 | year). I thought was I was trying to estimate was
> cross
>> random effects, not nested random effects. To be more precise, the model
> I
>> want to estimate looks like this:
>>
>> ? ? ? ? ? ? ? ? ?(Embedded image moved to file: pic23743.jpg),
>>
>>
>> where the terms (Embedded image moved to file: pic03517.jpg) and
> (Embedded
>> image moved to file: pic15204.jpg) are varying-intercept parameters for
>> units and time.
>>
>> Yet the output is identical...
>>
>> Thanks,
>>
>> Jose
>>
>>
>>
>> ? ? ? ? ? ? Andrew Dolman
>> ? ? ? ? ? ? <andydolman at gmail
>> ? ? ? ? ? ? .com> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?To
>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? JOSE A ALEMAN <aleman at fordham.edu>
>> ? ? ? ? ? ? 07/08/2010 03:56 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? cc
>> ? ? ? ? ? ? AM ? ? ? ? ? ? ? ? ? ? ? ?r-sig-mixed-models at r-project.org
>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Subject
>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Re: [R-sig-ME] question about
>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? linear mixed models
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> Hello Jose,
>>
>> lme4 can handle crossed and nested random effects whereas nlme can
>> only do nested random effects.
>>
>> What you've specified here:
>>
>>> mixed.model <- lmer (y ~ x1+x2+x3 + (1 | nation) + (1 | year),
> data=data)
>>
>> has crossed random effects.
>>
>>> and R returns the following output for the random effects:
>>>
>>> Random effects:
>>> ?Groups ? Name ? ? ? ? ?Variance ? Std.Dev.
>>> ?year ? ? ? ? ?(Intercept) ? 0.00 ? ? ? ? ? ?0.00
>>> ?nation ? ? ?(Intercept) ? 9.40 ? ? ? ? ? ?3.07
>>> ?Residual ? ? ? ? ? ? ? ? ? ? ?2.42 ? ? ? ? ? ? 1.56
>>
>> and you seem to have zero variance associated with the random effect
>> "year". This may be a problem with the way you've coded your data
>> which is why it's helpful if you post a sample of your data, or dummy
>> data, with your question.
>>
>> do > head(mydataframe)
>> the output from str (mydataframe) is useful too because we can see how
>> many levels of each factor you have
>>
>>
>> If you want a nested model in lme4 you should specify it as ?+ (1 |
>> nation/year) OR +(1|nation) + (1|nation:year)
>>
>>
>> I'm not sure what the model is that you specified in nlme but it can't
>> be the same as the one for lme4 because nlme cannot do crossed random
>> effects
>>
>>> mixed.effects <- lme (y ~ x1+x2+x3, data=data,
>>> ? ? ?random=~1|nation+1|year, method="REML")
>>
>>
>> Andy.
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From gavin.simpson at ucl.ac.uk  Fri Jul  9 12:51:29 2010
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Fri, 09 Jul 2010 11:51:29 +0100
Subject: [R-sig-ME] GLMM & lack of linearity on the logit
In-Reply-To: <4C312B33.9040300@uq.edu.au>
References: <8584AF990FE149A6985E65D62DE145EE@Negro1>
	<4C312B33.9040300@uq.edu.au>
Message-ID: <1278672689.9459.23.camel@localhost>

On Mon, 2010-07-05 at 10:45 +1000, Simon Blomberg wrote:
> Hi Luciano,
> 
> In general, categorization or "binning" is a bad thing to do. You are 
> throwing away information in the process, and the size and number of 
> bins must be subjective at some level. If there is important 
> nonlinearity in egg volume, you could consider a Generalized Additive 
> Mixed Model (GAMM) with a smoothing term for egg volume. I recommend 
> package mgcv.

If you use mgcv to fit the GAMM you are using MASS::glmmPQL -> lme,
which will use PQL for the fitting. There are two packages on CRAN that
use lme4 as the underlying fitting code whilst allowing smooth functions
of covariates as per a GAM; amer and gamm4. The latter is by Simon Wood
(author of mgcv) though Fabian's amer package was the first to use the
trick of fitting via lmer. Neither are as full-featured as mgcv::gamm
and the types of smooths allowed is restricted, but amer and gamm4
should be more numerically robust than gamm.

G

> 
> Cheers,
> 
> Simon.
> 
> On 05/07/10 10:34, Luciano La Sala wrote:
> > Dear R-people,
> >
> > I have just received from reviewers of a manuscript some harsh comments on
> > the statistical procedures. I'm studying risk factors of mortality at the
> > nest level among Olrog's Gull nest mates, which is why I used mixed models
> > with random intercepts (Nest ID). The outcome of interest if "Death"
> > (yes/no) and one of my explanatory variables is "Egg Volume" (continuous).
> > Since violation of linearity on the logit was evident I created 4 categories
> > using the quartiles of the distribution and modeled them as dummies.
> >
> > However, one reviewer stated: "It is unclear why you used volume of eggs as
> > a factor (i.e. categorized variable) in the analyses. Incorporating this
> > predictor as a continuous variable, as was originally measured, would make
> > analysis more informative. You stated that you made so "to relax the
> > linearity assumption". GLMM are sufficiently robust to accept a continuous
> > variable into a categorized model that, with the correct link function and
> > the variable transformation, would support well the linearity assumption."
> >
> > That said, I wonder if (1) categorization is such a bad thing on the one
> > hand, and (2) lack of linearity on the logit scale can be handled well by
> > GLMM.
> >
> > In my case, adding quadratic and cubic terms after assessment of the shape
> > of the x-y relationship did not improve the fit, so I decided to use dummies
> > and thus relax the linearity assumption.
> >
> > Thank you very much in advance.
> >
> > Luciano
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >    
> 

-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Dr. Gavin Simpson             [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From specialmary2009 at yahoo.ca  Fri Jul  9 18:28:54 2010
From: specialmary2009 at yahoo.ca (Special Mary)
Date: Fri, 9 Jul 2010 09:28:54 -0700 (PDT)
Subject: [R-sig-ME] A question about crossed random effect model in lmer
Message-ID: <467708.95339.qm@web110413.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100709/17ae6b02/attachment.pl>

From bates at stat.wisc.edu  Fri Jul  9 18:37:54 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 9 Jul 2010 11:37:54 -0500
Subject: [R-sig-ME] A question about crossed random effect model in lmer
In-Reply-To: <467708.95339.qm@web110413.mail.gq1.yahoo.com>
References: <467708.95339.qm@web110413.mail.gq1.yahoo.com>
Message-ID: <AANLkTikfHw32fk1D-66AhlgKpj6xc8Q4B8ebYsrlZszH@mail.gmail.com>

On Fri, Jul 9, 2010 at 11:28 AM, Special Mary <specialmary2009 at yahoo.ca> wrote:
> Hi, I am new to the R programme. I wonder if you can help me with Variance Component analysis. In my data, I have 4 variables: managers? performance (outcome), managers, exercise (interpersonal, decision-making...), and assessment methods (only two: Method A versus Method B). Each manager completes ALL exercises, and each time the exercise is assessed in both Method A and Method B. I want to examine how much of the variance of the outcome can be contributed to managers, exercise, method, and all their interactions (all 2-way and 3-way).

It would help to know the number of levels in each of these factors.
You mention that there are only two assessment methods, in which case
I would not recommend using random effects for assessment.  Estimating
a variance component from only two levels is difficult. ?It is best to
use fixed-effects parameters in such cases.

> I do not believe that managers, exercise, and assessment methods are CROSSED with each other.

I'm not sure why you say that.  Perhaps you didn't intend the "not"
near the beginning of the sentence. You emphasize that each manager
completes all exercises and each exercise is assessed with both
methods.  To me that means that the factors are crossed.

> Assume that managers, exercise, and assessment methods are all regarded as random factors, I do not know how to specify this model in R. Can someone please help me with this? I know how to set it up when the random effects do NOT interact with each other:

> Model1 <- lmer (performance ~ (1|managers) + (1|exercise) + (1|method), data = mtmm)

> However, when it involves interactions among the random effects, then I have no idea how to do it. In addition, I want to assume no correlation/covariance among the three random effects (i.e., variance component structure).

The general way to incorporate an interaction of two random-effects
terms is like

lmer(performance ~ (1|managers) + (1|exercise) + (1|managers:exercise), ...)

but you will need to be careful of the number of levels for each of
those terms.  It is likely that some of the variance component
estimates will be zero because the available data cannot support a
model of too great a complexity.

> Only performance is a continuous variable.
>
> Thanks so much!
> Chester
> PhD Candidate
> Dept of Psychology
> Univ of Western Ontario
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



From rebecca.ross at plants.ox.ac.uk  Mon Jul 12 11:31:50 2010
From: rebecca.ross at plants.ox.ac.uk (Rebecca Ross)
Date: Mon, 12 Jul 2010 10:31:50 +0100
Subject: [R-sig-ME] HPDinterval MCMCglmm and using transformed variables in
	MCMCglmm
Message-ID: <756B64E07365AF43BE945A734A85E44544616944B9@EXMBX03.ad.oak.ox.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100712/19a43750/attachment.pl>

From j.hadfield at ed.ac.uk  Mon Jul 12 12:30:33 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 12 Jul 2010 11:30:33 +0100
Subject: [R-sig-ME] HPDinterval MCMCglmm and using transformed variables
	in MCMCglmm
In-Reply-To: <756B64E07365AF43BE945A734A85E44544616944B9@EXMBX03.ad.oak.ox.ac.uk>
References: <756B64E07365AF43BE945A734A85E44544616944B9@EXMBX03.ad.oak.ox.ac.uk>
Message-ID: <7B51E145-7423-4547-91CE-C7EBBEBB402A@ed.ac.uk>

Dear Rebecca,

You probably need to load MCMCglmm (library(MCMCglmm)) or at least  
load coda. At the moment the response needs to be logged externally:

my.data$ylog<-log(my.data$y)

but the next version will "fix" this.

Cheers,

Jarrod


On 12 Jul 2010, at 10:31, Rebecca Ross wrote:

> Dear ME users,
>
> Apologies if this is a naive question, I am new to using MCMC glmm.  
> I have been working through the tutorial, using some of my own data,  
> and I thought I had followed the steps correctly. The model I have  
> been fitting is:
>
> AMstem3<-MCMCglmm(log(stem)~Dist_fr_A,random=~Block 
> +animal,pedigree=Ped,data=SapRO,prior=prior1.3,
> family="gaussian")
> Briefly, I want to see how the Distance variable (continuous)  
> affects stem weight, which I have log transformed as the raw data is  
> heteroscedastic. Block is field block, and I am fitting the animal  
> random effect to take into account different relatedness between  
> individuals (I'm not at the moment trying to estimate Va).
>
> When I tried this model last night, I could get the 95% CIs using  
> this function
> HPDinterval(AMstem3$Sol[,"Dist_fr_A"])
> HPDinterval(AMstem3$VCV)
>
> When I tried this morning, I get the following error message
> Error in function (classes, fdef, mtable)  :
>  unable to find an inherited method for function "HPDinterval", for  
> signature "mcmc"
> Can anyone explain what  has gone wrong? I've tried changing the  
> terms in the model, but that doesn't help, so I think I must have  
> changed something in R elsewhere? Or else missing something  
> completely obvious.
>
> Question 2: I dont think MCMCglmm is actually logging my stem  
> variable because the fixed effect parameter estimate from the model  
> above (AMstem3) are about a factor of 10 out from the fixed effect  
> estimate from
> a similar model, fit in lme4, without the animal effect and very  
> similar to the same model using the raw stem weight (see below). Do  
> I need to specify the log transform differently?
>
> AMstem3c Dist_fr_A  posterior mode: -0.004236659
> versus:
> stem5a<-lme(log(stem)~Dist_fr_A,random=~1| 
> Block,data=SapRO,na.action=na.omit)
> Fixed effect Estimate: Dist_fr_A   -0.0004442 (SE=0.00006136)
> and:
> stem5b<-lme(stem~Dist_fr_A,random=~1| 
> Block,data=SapRO,na.action=na.omit)
> Fixed effect Estimate: Dist_fr_A   -0.004342 (SE=0.0006714)
>
> Thank you very much for your help,
>
> Rebecca Ross
> DPhil Candidate,
> University of Oxford.
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From rebecca.ross at plants.ox.ac.uk  Mon Jul 12 13:13:40 2010
From: rebecca.ross at plants.ox.ac.uk (Rebecca Ross)
Date: Mon, 12 Jul 2010 12:13:40 +0100
Subject: [R-sig-ME] HPDinterval MCMCglmm and using transformed variables
 in MCMCglmm
In-Reply-To: <7B51E145-7423-4547-91CE-C7EBBEBB402A@ed.ac.uk>
References: <756B64E07365AF43BE945A734A85E44544616944B9@EXMBX03.ad.oak.ox.ac.uk>,
	<7B51E145-7423-4547-91CE-C7EBBEBB402A@ed.ac.uk>
Message-ID: <756B64E07365AF43BE945A734A85E44544616944BA@EXMBX03.ad.oak.ox.ac.uk>

Hi Jarrod,

Thank you for the quick reply.

I tried that one already and it hasnt made a difference (also I haven't closed down R since it worked last night). 

I guess...close R down and start again?!

Re logs - presumably I(x^2) is also not recognised (I had a go but the x2 term did not appear in the Sol output)?

Cheers,

Rebecca



________________________________________
From: Jarrod Hadfield [j.hadfield at ed.ac.uk]
Sent: Monday, July 12, 2010 11:30 AM
To: Rebecca Ross
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] HPDinterval MCMCglmm and using transformed variables in MCMCglmm

Dear Rebecca,

You probably need to load MCMCglmm (library(MCMCglmm)) or at least
load coda. At the moment the response needs to be logged externally:

my.data$ylog<-log(my.data$y)

but the next version will "fix" this.

Cheers,

Jarrod


On 12 Jul 2010, at 10:31, Rebecca Ross wrote:

> Dear ME users,
>
> Apologies if this is a naive question, I am new to using MCMC glmm.
> I have been working through the tutorial, using some of my own data,
> and I thought I had followed the steps correctly. The model I have
> been fitting is:
>
> AMstem3<-MCMCglmm(log(stem)~Dist_fr_A,random=~Block
> +animal,pedigree=Ped,data=SapRO,prior=prior1.3,
> family="gaussian")
> Briefly, I want to see how the Distance variable (continuous)
> affects stem weight, which I have log transformed as the raw data is
> heteroscedastic. Block is field block, and I am fitting the animal
> random effect to take into account different relatedness between
> individuals (I'm not at the moment trying to estimate Va).
>
> When I tried this model last night, I could get the 95% CIs using
> this function
> HPDinterval(AMstem3$Sol[,"Dist_fr_A"])
> HPDinterval(AMstem3$VCV)
>
> When I tried this morning, I get the following error message
> Error in function (classes, fdef, mtable)  :
>  unable to find an inherited method for function "HPDinterval", for
> signature "mcmc"
> Can anyone explain what  has gone wrong? I've tried changing the
> terms in the model, but that doesn't help, so I think I must have
> changed something in R elsewhere? Or else missing something
> completely obvious.
>
> Question 2: I dont think MCMCglmm is actually logging my stem
> variable because the fixed effect parameter estimate from the model
> above (AMstem3) are about a factor of 10 out from the fixed effect
> estimate from
> a similar model, fit in lme4, without the animal effect and very
> similar to the same model using the raw stem weight (see below). Do
> I need to specify the log transform differently?
>
> AMstem3c Dist_fr_A  posterior mode: -0.004236659
> versus:
> stem5a<-lme(log(stem)~Dist_fr_A,random=~1|
> Block,data=SapRO,na.action=na.omit)
> Fixed effect Estimate: Dist_fr_A   -0.0004442 (SE=0.00006136)
> and:
> stem5b<-lme(stem~Dist_fr_A,random=~1|
> Block,data=SapRO,na.action=na.omit)
> Fixed effect Estimate: Dist_fr_A   -0.004342 (SE=0.0006714)
>
> Thank you very much for your help,
>
> Rebecca Ross
> DPhil Candidate,
> University of Oxford.
>
>
>
>
>       [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


--
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From j.hadfield at ed.ac.uk  Mon Jul 12 13:23:33 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 12 Jul 2010 12:23:33 +0100
Subject: [R-sig-ME] HPDinterval MCMCglmm and using transformed variables
	in MCMCglmm
In-Reply-To: <756B64E07365AF43BE945A734A85E44544616944BA@EXMBX03.ad.oak.ox.ac.uk>
References: <756B64E07365AF43BE945A734A85E44544616944B9@EXMBX03.ad.oak.ox.ac.uk>,
	<7B51E145-7423-4547-91CE-C7EBBEBB402A@ed.ac.uk>
	<756B64E07365AF43BE945A734A85E44544616944BA@EXMBX03.ad.oak.ox.ac.uk>
Message-ID: <1AE76051-BEA2-46FC-8B8B-0D335FADAF7F@ed.ac.uk>

Hi,

Have you loaded lme4? This masks HPDinterval from coda. Try:

coda::HPDinterval(AMstem3$Sol[,"Dist_fr_A"])

At the moment only transformations (eg I(x^2)) only work left of the ~.

Cheers,

Jarrod


On 12 Jul 2010, at 12:13, Rebecca Ross wrote:

> Hi Jarrod,
>
> Thank you for the quick reply.
>
> I tried that one already and it hasnt made a difference (also I  
> haven't closed down R since it worked last night).
>
> I guess...close R down and start again?!
>
> Re logs - presumably I(x^2) is also not recognised (I had a go but  
> the x2 term did not appear in the Sol output)?
>
> Cheers,
>
> Rebecca
>
>
>
> ________________________________________
> From: Jarrod Hadfield [j.hadfield at ed.ac.uk]
> Sent: Monday, July 12, 2010 11:30 AM
> To: Rebecca Ross
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] HPDinterval MCMCglmm and using transformed  
> variables in MCMCglmm
>
> Dear Rebecca,
>
> You probably need to load MCMCglmm (library(MCMCglmm)) or at least
> load coda. At the moment the response needs to be logged externally:
>
> my.data$ylog<-log(my.data$y)
>
> but the next version will "fix" this.
>
> Cheers,
>
> Jarrod
>
>
> On 12 Jul 2010, at 10:31, Rebecca Ross wrote:
>
>> Dear ME users,
>>
>> Apologies if this is a naive question, I am new to using MCMC glmm.
>> I have been working through the tutorial, using some of my own data,
>> and I thought I had followed the steps correctly. The model I have
>> been fitting is:
>>
>> AMstem3<-MCMCglmm(log(stem)~Dist_fr_A,random=~Block
>> +animal,pedigree=Ped,data=SapRO,prior=prior1.3,
>> family="gaussian")
>> Briefly, I want to see how the Distance variable (continuous)
>> affects stem weight, which I have log transformed as the raw data is
>> heteroscedastic. Block is field block, and I am fitting the animal
>> random effect to take into account different relatedness between
>> individuals (I'm not at the moment trying to estimate Va).
>>
>> When I tried this model last night, I could get the 95% CIs using
>> this function
>> HPDinterval(AMstem3$Sol[,"Dist_fr_A"])
>> HPDinterval(AMstem3$VCV)
>>
>> When I tried this morning, I get the following error message
>> Error in function (classes, fdef, mtable)  :
>> unable to find an inherited method for function "HPDinterval", for
>> signature "mcmc"
>> Can anyone explain what  has gone wrong? I've tried changing the
>> terms in the model, but that doesn't help, so I think I must have
>> changed something in R elsewhere? Or else missing something
>> completely obvious.
>>
>> Question 2: I dont think MCMCglmm is actually logging my stem
>> variable because the fixed effect parameter estimate from the model
>> above (AMstem3) are about a factor of 10 out from the fixed effect
>> estimate from
>> a similar model, fit in lme4, without the animal effect and very
>> similar to the same model using the raw stem weight (see below). Do
>> I need to specify the log transform differently?
>>
>> AMstem3c Dist_fr_A  posterior mode: -0.004236659
>> versus:
>> stem5a<-lme(log(stem)~Dist_fr_A,random=~1|
>> Block,data=SapRO,na.action=na.omit)
>> Fixed effect Estimate: Dist_fr_A   -0.0004442 (SE=0.00006136)
>> and:
>> stem5b<-lme(stem~Dist_fr_A,random=~1|
>> Block,data=SapRO,na.action=na.omit)
>> Fixed effect Estimate: Dist_fr_A   -0.004342 (SE=0.0006714)
>>
>> Thank you very much for your help,
>>
>> Rebecca Ross
>> DPhil Candidate,
>> University of Oxford.
>>
>>
>>
>>
>>      [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From m.fairbrother at bristol.ac.uk  Mon Jul 12 18:00:23 2010
From: m.fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Mon, 12 Jul 2010 17:00:23 +0100
Subject: [R-sig-ME] spatial correlation structures in multilevel models?
In-Reply-To: <mailman.5.1278756002.27661.r-sig-mixed-models@r-project.org>
References: <mailman.5.1278756002.27661.r-sig-mixed-models@r-project.org>
Message-ID: <9945D065-DFFF-4C54-AF70-C5C29A9B0267@bristol.ac.uk>

Dear all,

I'm interested in fitting a three-level model where the 1st level units are individuals, and the 2nd and 3rd levels are (nested) geographical units, whose locations (centroids) are known. (The precise location of each individual is not known--just the unit to which he/she belongs.) I'd like to exploit the fact that the locations are known, since people in neighbouring/nearby units should be more similar than people in units that are distant from each other. To be specific, I'd like a given unit's random intercept to be adjusted according to the data from nearby/neighbouring units--especially for instances where I have few observations for a unit but lots of observations for neighbouring units.

My understanding is that lme4 and MCMCglmm cannot do this, in the sense that they cannot specify spatial correlation structures. Using these packages, at most, some characteristic of a unit's location (e.g., latitude, distance from X point) and/or some (weighted) characteristic of a unit's neighbour(s) could be included as a fixed effect.

However, as I understand it, nlme can do this, using the "correlation" argument (e.g., "correlation = corExp(form = ~ ...").

Is this correct? Will nlme adjust the random intercepts in such a way? And would it be a problem that it's the higher-level units, not the lowest-level units, for which I know the locations?

If I'm being over-ambitious/demanding here, no worries at all--I'm just curious whether this is possible. I don't have the data yet.

Many thanks,
Malcolm


Dr Malcolm Fairbrother
Lecturer
School of Geographical Sciences
University of Bristol



From nikko at hailmail.net  Mon Jul 12 18:05:31 2010
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: Mon, 12 Jul 2010 09:05:31 -0700
Subject: [R-sig-ME] HPDinterval MCMCglmm and using transformed variables in
 MCMCglmm (Rebecca Ross)
In-Reply-To: <mailman.3.1278928802.10324.r-sig-mixed-models@r-project.org>
References: <mailman.3.1278928802.10324.r-sig-mixed-models@r-project.org>
Message-ID: <1278950731.23899.1384473123@webmail.messagingengine.com>


Hi Rebecca,
Just a thought, when you "logged back in" did you reload all the
libraries?
try 
library(MCMCglmm)
HPDinterval(AMstem3$VCV)

Nicholas

> Date: Mon, 12 Jul 2010 10:31:50 +0100
> From: Rebecca Ross <rebecca.ross at plants.ox.ac.uk>
> To: "r-sig-mixed-models at r-project.org"
> 	<r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] HPDinterval MCMCglmm and using transformed
> 	variables in	MCMCglmm
> Message-ID:
> 	<756B64E07365AF43BE945A734A85E44544616944B9 at EXMBX03.ad.oak.ox.ac.uk>
> Content-Type: text/plain
> 
> Dear ME users,
> 
> Apologies if this is a naive question, I am new to using MCMC glmm. I
> have been working through the tutorial, using some of my own data, and I
> thought I had followed the steps correctly. The model I have been fitting
> is:
> 
> AMstem3<-MCMCglmm(log(stem)~Dist_fr_A,random=~Block+animal,pedigree=Ped,data=SapRO,prior=prior1.3,
> family="gaussian")
> Briefly, I want to see how the Distance variable (continuous) affects
> stem weight, which I have log transformed as the raw data is
> heteroscedastic. Block is field block, and I am fitting the animal random
> effect to take into account different relatedness between individuals
> (I'm not at the moment trying to estimate Va).
> 
> When I tried this model last night, I could get the 95% CIs using this
> function
> HPDinterval(AMstem3$Sol[,"Dist_fr_A"])
> HPDinterval(AMstem3$VCV)
> 
> When I tried this morning, I get the following error message
> Error in function (classes, fdef, mtable)  :
>   unable to find an inherited method for function "HPDinterval", for
>   signature "mcmc"
> Can anyone explain what  has gone wrong? I've tried changing the terms in
> the model, but that doesn't help, so I think I must have changed
> something in R elsewhere? Or else missing something completely obvious.
> 
> Question 2: I dont think MCMCglmm is actually logging my stem variable
> because the fixed effect parameter estimate from the model above
> (AMstem3) are about a factor of 10 out from the fixed effect estimate
> from
> a similar model, fit in lme4, without the animal effect and very similar
> to the same model using the raw stem weight (see below). Do I need to
> specify the log transform differently?
> 
> AMstem3c Dist_fr_A  posterior mode: -0.004236659
> versus:
> stem5a<-lme(log(stem)~Dist_fr_A,random=~1|Block,data=SapRO,na.action=na.omit)
> Fixed effect Estimate: Dist_fr_A   -0.0004442 (SE=0.00006136)
> and:
> stem5b<-lme(stem~Dist_fr_A,random=~1|Block,data=SapRO,na.action=na.omit)
> Fixed effect Estimate: Dist_fr_A   -0.004342 (SE=0.0006714)
> 
> Thank you very much for your help,
> 
> Rebecca Ross
> DPhil Candidate,
> University of Oxford.
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ------------------------------
> 
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> End of R-sig-mixed-models Digest, Vol 43, Issue 14
> **************************************************
>



From arrayprofile at yahoo.com  Mon Jul 12 19:26:54 2010
From: arrayprofile at yahoo.com (array chip)
Date: Mon, 12 Jul 2010 10:26:54 -0700 (PDT)
Subject: [R-sig-ME] nested or non-nested grouping factors
Message-ID: <691057.93744.qm@web56305.mail.re3.yahoo.com>

Dear Dr. Bates,

I have some confusions about how to identify nested or non-nested groups 
factors, and how to fit them in lmer().

In the vignette "Linear mixed model implementation in lme4", you used "Oats" 
data from nlme package as an example for nested grouping factors where "plot" 
grouping factor is nested within the "block" grouping factor, because "A given 
plot occurs in one and only one block". But "plot" factor is actually coded by 
"variety" factor, which I can say that "every variety occurs in every block" 
which seems to mean that "variety" and "block" are crossed. So how in the end 
should I distinguish between nested and crossed grouping factors? Any simple 
rules?

For nested factors (say factor A is nested within factor B), I understand I can 
specify the random effector as (1|B/A). Can I still specify as (1|A)+(1|B)? then 
what's the explanation of these 2 terms?

For non-nested factors, is (1|A)+(1|B) the only way to specify random effects? 
Can I also specify (1|A)+(1|B)+(1|A:B)? So the explanation is  random effects of 
A, B and interaction?

Thank you very much!

John



From Sam_Smith at me.com  Mon Jul 12 20:02:03 2010
From: Sam_Smith at me.com (Sam)
Date: Mon, 12 Jul 2010 19:02:03 +0100
Subject: [R-sig-ME] HPDinterval - Model simplification
References: <7F4C1876-765A-411B-9E39-3A62BB8F4B81@me.com>
Message-ID: <4F947600-D4F8-4DB5-A256-7949EDB23900@me.com>


Dear List,

I am experimenting using mcmcGLMM and have a question -

I am sorry i am not very statistically minded! 

So i have run a model 

MCMCglmm(group~1+ 2 + 3+ 4+ 5 + 6 + 7 + 8 + 9, random=~ a+a:b, family="ordinal", prior=prior, data=group)

1. Group has 5 levels and what i am trying to do is ask - if you are in group 1 (for instance) which factors are most significant (1,2,3,4,5 etc)

2. I then want to reverse this and ask  - if an individual has factors 3,6,7 ( for instance) can i predict what group this individual should be placed in?

Previously i have used minimum adequate models to do this. Reading through the class notes i see i should use HPDinterval(model1$Sol) however i am unsure how to interpret the results to arrive at the most significant factors for each group and simplify the model.

				lower			upper
cutpoint.group.1	0.58967173		0.85945043
cutpoint.group.2	2.31790921		2.68058107
cutpoint.group.3	3.43902338		3.84798758
cutpoint.group.4	3.91302678		4.341789
(Intercept)		0.56616994		3.61939211
a				-0.06867026		0.27986037
b				-0.14199142		0.28397164
c				-0.49411144		0.03729451
d				-0.50516484		0.08844333
e				-0.04864767		0.32516733
f				-0.12977632		0.64986726
g				-0.25288964		0.45337262
h				-0.20219456		0.26453859
i				-0.71870788		-0.16569956
attr(,"Probability")	
[1] 0.95		

Thanks and sorry for my lack of statistical knowledge!

Sam



From Sam_Smith at me.com  Mon Jul 12 19:35:44 2010
From: Sam_Smith at me.com (Sam)
Date: Mon, 12 Jul 2010 18:35:44 +0100
Subject: [R-sig-ME] HPDinterval Help
Message-ID: <7F4C1876-765A-411B-9E39-3A62BB8F4B81@me.com>

Dear List,

I am experimenting using mcmcGLMM and have a question -

I am sorry i am not very statistically minded! 

So i have run a model 

MCMCglmm(group~1+ 2 + 3+ 4+ 5 + 6 + 7 + 8 + 9, random=~ a+a:b, family="ordinal", prior=prior, data=group)

1. Group has 5 levels and what i am trying to do is ask - if you are in group 1 (for instance) which factors are most significant (1,2,3,4,5 etc)

2. I then want to reverse this and ask  - if an individual has factors 3,6,7 can i predict what group this individual should be placed in?

Previously i have used minimum adequate models to do this. Reading through your class notes i see i should use HPDinterval(model1$Sol) however i am unsure how to interpret the results to arrive at the most significant factors for each group?

				lower			upper
cutpoint.group.1	0.58967173		0.85945043
cutpoint.group.2	2.31790921		2.68058107
cutpoint.group.3	3.43902338		3.84798758
cutpoint.group.4	3.91302678		4.341789
(Intercept)		0.56616994		3.61939211
a				-0.06867026		0.27986037
b				-0.14199142		0.28397164
c				-0.49411144		0.03729451
d				-0.50516484		0.08844333
e				-0.04864767		0.32516733
f				-0.12977632		0.64986726
g				-0.25288964		0.45337262
h				-0.20219456		0.26453859
i				-0.71870788		-0.16569956
attr(,"Probability")	
[1] 0.95		

Thanks and sorry for my lack of statistical knowledge!

Sam



From pierces1 at msu.edu  Mon Jul 12 20:19:28 2010
From: pierces1 at msu.edu (Steven J. Pierce)
Date: Mon, 12 Jul 2010 14:19:28 -0400
Subject: [R-sig-ME] spatial correlation structures in multilevel models?
In-Reply-To: <9945D065-DFFF-4C54-AF70-C5C29A9B0267@bristol.ac.uk>
References: <mailman.5.1278756002.27661.r-sig-mixed-models@r-project.org>
	<9945D065-DFFF-4C54-AF70-C5C29A9B0267@bristol.ac.uk>
Message-ID: <005b01cb21ee$c4657e70$4d307b50$@msu.edu>

You might also try doing that model with WinBUGS. There are packages that
will help you move the data out to WinBUGS from R and then bring the results
back into R for post processing. 

Steven J. Pierce, Ph.D. 
Associate Director 
Center for Statistical Training & Consulting (CSTAT) 
Michigan State University 
E-mail: pierces1 at msu.edu 
Web: http://www.cstat.msu.edu 

-----Original Message-----
From: Malcolm Fairbrother [mailto:m.fairbrother at bristol.ac.uk] 
Sent: Monday, July 12, 2010 12:00 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] spatial correlation structures in multilevel models?

Dear all,

I'm interested in fitting a three-level model where the 1st level units are
individuals, and the 2nd and 3rd levels are (nested) geographical units,
whose locations (centroids) are known. (The precise location of each
individual is not known--just the unit to which he/she belongs.) I'd like to
exploit the fact that the locations are known, since people in
neighbouring/nearby units should be more similar than people in units that
are distant from each other. To be specific, I'd like a given unit's random
intercept to be adjusted according to the data from nearby/neighbouring
units--especially for instances where I have few observations for a unit but
lots of observations for neighbouring units.

My understanding is that lme4 and MCMCglmm cannot do this, in the sense that
they cannot specify spatial correlation structures. Using these packages, at
most, some characteristic of a unit's location (e.g., latitude, distance
from X point) and/or some (weighted) characteristic of a unit's neighbour(s)
could be included as a fixed effect.

However, as I understand it, nlme can do this, using the "correlation"
argument (e.g., "correlation = corExp(form = ~ ...").

Is this correct? Will nlme adjust the random intercepts in such a way? And
would it be a problem that it's the higher-level units, not the lowest-level
units, for which I know the locations?

If I'm being over-ambitious/demanding here, no worries at all--I'm just
curious whether this is possible. I don't have the data yet.

Many thanks,
Malcolm


Dr Malcolm Fairbrother
Lecturer
School of Geographical Sciences
University of Bristol



From mlarkin at rsmas.miami.edu  Tue Jul 13 05:06:03 2010
From: mlarkin at rsmas.miami.edu (Michael Larkin)
Date: Mon, 12 Jul 2010 23:06:03 -0400
Subject: [R-sig-ME] can't get model to converge
Message-ID: <000001cb2238$542cdb90$fc8692b0$@miami.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100712/55d4d22d/attachment.pl>

From A.Robinson at ms.unimelb.edu.au  Tue Jul 13 06:11:12 2010
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Tue, 13 Jul 2010 14:11:12 +1000
Subject: [R-sig-ME] can't get model to converge
In-Reply-To: <000001cb2238$542cdb90$fc8692b0$@miami.edu>
References: <000001cb2238$542cdb90$fc8692b0$@miami.edu>
Message-ID: <20100713041112.GC7507@ms.unimelb.edu.au>

Hi Michael,

a few thoughts ...

0) how many fish do you have?  And, how many measurements per fish?

1) are you sure that you need all three parameters to be random?
   Judicious use of nlslist and some graphics might provide insight as
   to whether any of them can be simply fixed effects.  Doing so will
   greatly simplify the model, See Section 8.1.3 of P&B.

2) I've fit models that have required more than 5000 iterations to
   converge.  Try increasing the iterations to 10000.

3) Just as a side-note, I find your code hard to read.  I know that
   the choice between '=' and '<-' is a matter of taste, but please
   make more use of spaces!

I hope that this helps,

Andrew

On Mon, Jul 12, 2010 at 11:06:03PM -0400, Michael Larkin wrote:
> I know my convergence problem is not a new one to this email list.  I looked
> at old post and I still can't figure out my problem.  This is why I am
> sending this email.  
> 
>  
> 
> Here is my situation:  
> 
>  
> 
> I have back-calculated fish growth using otoliths (ear bones).  In a
> nutshell you can back calculate the length of the fish at each age by
> measuring the distance from the core of the otolith to each annuli and the
> edge of the otolith.  Since the data is longitudinal, autocorrelated, and
> unbalanced the best way to generate a growth curve is using a non-linear
> mixed effect model (Vigliola and Meekan 2009).  
> 
>  
> 
> I have three columns of data: fish identification number (id), length at age
> (L), and incremental age (Age).  
> 
>  
> 
> Here is my code:  
> 
> #first I create my growth model which is the von Bertalanffy growth model
> (LVB)
> 
> >LVB=function(x,t0,Lmax,K){                                               
> 
> >y=Lmax*(1-exp(-K*(x-t0)))
> 
> 
> >y
> 
> >}
> 
>  
> 
> #I define the groups for the mixed effect model.  
> 
> >datagr=groupedData(L~Age|id,data=back)
> 
>  
> 
> #The next step fits a von Bertalanffy growth model by non-linear mixed
> effect model.  
> 
> >LVB.nlme=nlme(L~LVB(Age,t0,Lmax,K), data=datagr, 
> 
> >fixed=list(t0~1,Lmax~1,K~1),         #The model is estimating global values
> for all three parameters. 
> 
> >random=t0+Lmax+K~1,                  #The model is estimating values for
> each parameter for 
> 
> each individual fish.  This is the random effect part of the model.  
> 
> >start=list(fixed=c(t0=-1, Lmax=700, K=0.2)))         #list creates a list
> of the arguments, fixed means 1 single fixed effect, c means create a data
> vector.  
> 
>  
> 
> I keep getting the error of "Maximum number of iterations".  I have tried
> different starting values and still have no luck.  I even tried 
> 
> increasing the number of iterations to 1,000 using nlmeControl.  
> 
>  
> 
> Any advice on how to get my model to converge would be greatly appreciated.
> 
> 
>  
> 
> Mike 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Andrew Robinson  
Program Manager, ACERA 
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia               (prefer email)
http://www.ms.unimelb.edu.au/~andrewpr              Fax: +61-3-8344-4599
http://www.acera.unimelb.edu.au/



From s.blomberg1 at uq.edu.au  Tue Jul 13 06:49:28 2010
From: s.blomberg1 at uq.edu.au (Simon Blomberg)
Date: Tue, 13 Jul 2010 14:49:28 +1000
Subject: [R-sig-ME] can't get model to converge
In-Reply-To: <20100713041112.GC7507@ms.unimelb.edu.au>
References: <000001cb2238$542cdb90$fc8692b0$@miami.edu>
	<20100713041112.GC7507@ms.unimelb.edu.au>
Message-ID: <4C3BF058.3090502@uq.edu.au>

I've had problems with this model and otolith data.  There were too few 
measurements per fish, and most of the measurements were at the 
beginning of the growth curve, hence estimating the asymptote was 
difficult. Ultimately, we ditched the vonBert model and simply fitted a 
linear model, so we could only look at growth in a very coarse way, but 
this was enough to detect treatment differences.

Cheers,

Simon.

On 13/07/10 14:11, Andrew Robinson wrote:
> Hi Michael,
>
> a few thoughts ...
>
> 0) how many fish do you have?  And, how many measurements per fish?
>
> 1) are you sure that you need all three parameters to be random?
>     Judicious use of nlslist and some graphics might provide insight as
>     to whether any of them can be simply fixed effects.  Doing so will
>     greatly simplify the model, See Section 8.1.3 of P&B.
>
> 2) I've fit models that have required more than 5000 iterations to
>     converge.  Try increasing the iterations to 10000.
>
> 3) Just as a side-note, I find your code hard to read.  I know that
>     the choice between '=' and '<-' is a matter of taste, but please
>     make more use of spaces!
>
> I hope that this helps,
>
> Andrew
>
> On Mon, Jul 12, 2010 at 11:06:03PM -0400, Michael Larkin wrote:
>    
>> I know my convergence problem is not a new one to this email list.  I looked
>> at old post and I still can't figure out my problem.  This is why I am
>> sending this email.
>>
>>
>>
>> Here is my situation:
>>
>>
>>
>> I have back-calculated fish growth using otoliths (ear bones).  In a
>> nutshell you can back calculate the length of the fish at each age by
>> measuring the distance from the core of the otolith to each annuli and the
>> edge of the otolith.  Since the data is longitudinal, autocorrelated, and
>> unbalanced the best way to generate a growth curve is using a non-linear
>> mixed effect model (Vigliola and Meekan 2009).
>>
>>
>>
>> I have three columns of data: fish identification number (id), length at age
>> (L), and incremental age (Age).
>>
>>
>>
>> Here is my code:
>>
>> #first I create my growth model which is the von Bertalanffy growth model
>> (LVB)
>>
>>      
>>> LVB=function(x,t0,Lmax,K){
>>>        
>>      
>>> y=Lmax*(1-exp(-K*(x-t0)))
>>>        
>>
>>      
>>> y
>>>        
>>      
>>> }
>>>        
>>
>>
>> #I define the groups for the mixed effect model.
>>
>>      
>>> datagr=groupedData(L~Age|id,data=back)
>>>        
>>
>>
>> #The next step fits a von Bertalanffy growth model by non-linear mixed
>> effect model.
>>
>>      
>>> LVB.nlme=nlme(L~LVB(Age,t0,Lmax,K), data=datagr,
>>>        
>>      
>>> fixed=list(t0~1,Lmax~1,K~1),         #The model is estimating global values
>>>        
>> for all three parameters.
>>
>>      
>>> random=t0+Lmax+K~1,                  #The model is estimating values for
>>>        
>> each parameter for
>>
>> each individual fish.  This is the random effect part of the model.
>>
>>      
>>> start=list(fixed=c(t0=-1, Lmax=700, K=0.2)))         #list creates a list
>>>        
>> of the arguments, fixed means 1 single fixed effect, c means create a data
>> vector.
>>
>>
>>
>> I keep getting the error of "Maximum number of iterations".  I have tried
>> different starting values and still have no luck.  I even tried
>>
>> increasing the number of iterations to 1,000 using nlmeControl.
>>
>>
>>
>> Any advice on how to get my model to converge would be greatly appreciated.
>>
>>
>>
>>
>> Mike
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>      
>    

-- 
Simon Blomberg, BSc (Hons), PhD, MAppStat.
Lecturer and Consultant Statistician
School of Biological Sciences
The University of Queensland
St. Lucia Queensland 4072
Australia
T: +61 7 3365 2506
email: S.Blomberg1_at_uq.edu.au
http://www.uq.edu.au/~uqsblomb/

Policies:
1.  I will NOT analyse your data for you.
2.  Your deadline is your problem

Statistics is the grammar of science - Karl Pearson.



From rroa at azti.es  Tue Jul 13 08:15:43 2010
From: rroa at azti.es (=?iso-8859-1?Q?Rub=E9n_Roa?=)
Date: Tue, 13 Jul 2010 08:15:43 +0200
Subject: [R-sig-ME] can't get model to converge
References: <000001cb2238$542cdb90$fc8692b0$@miami.edu>
Message-ID: <5CD78996B8F8844D963C875D3159B94A016906C1@dsrcorreo>


> -----Mensaje original-----
> De: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] En nombre 
> de Michael Larkin
> Enviado el: martes, 13 de julio de 2010 5:06
> Para: r-sig-mixed-models at r-project.org
> Asunto: [R-sig-ME] can't get model to converge
> 
> I know my convergence problem is not a new one to this email 
> list.  I looked at old post and I still can't figure out my 
> problem.  This is why I am sending this email.  
> 
> Here is my situation:  
> 
> I have back-calculated fish growth using otoliths (ear 
> bones).  In a nutshell you can back calculate the length of 
> the fish at each age by measuring the distance from the core 
> of the otolith to each annuli and the edge of the otolith.  
> Since the data is longitudinal, autocorrelated, and 
> unbalanced the best way to generate a growth curve is using a 
> non-linear mixed effect model (Vigliola and Meekan 2009).  
> 
> I have three columns of data: fish identification number 
> (id), length at age (L), and incremental age (Age).  
> 
> Here is my code:  
> 
> #first I create my growth model which is the von Bertalanffy 
> growth model
> (LVB)
> 
> >LVB=function(x,t0,Lmax,K){                                   
> >y=Lmax*(1-exp(-K*(x-t0)))
> >y
> >}
> #I define the groups for the mixed effect model.  
> >datagr=groupedData(L~Age|id,data=back)
> #The next step fits a von Bertalanffy growth model by 
> non-linear mixed effect model.  
> >LVB.nlme=nlme(L~LVB(Age,t0,Lmax,K), data=datagr,
> >fixed=list(t0~1,Lmax~1,K~1),         #The model is 
> estimating global values
> for all three parameters. 
> >random=t0+Lmax+K~1,                  #The model is 
> estimating values for
> each parameter for 
> each individual fish.  This is the random effect part of the model.  
> >start=list(fixed=c(t0=-1, Lmax=700, K=0.2)))         #list 
> creates a list
> of the arguments, fixed means 1 single fixed effect, c means 
> create a data vector.  
> 
> I keep getting the error of "Maximum number of iterations".  
> I have tried different starting values and still have no 
> luck.  I even tried 
> 
> increasing the number of iterations to 1,000 using nlmeControl.  
> 
> Any advice on how to get my model to converge would be 
> greatly appreciated.
> 
> Mike 

Michael,

I think you can tell with some certainty the initial length of your fish, the length at birth.
They all are born pretty small and the variance of this length at birth is very small anayway (at least from a human perspective). If you can fix that value, call it l_0, then a re-parameterised version of your model is

L_t = L_infinity(1-(1-l_0/l_infinity)*exp(-K*t)))

where the t0 parameter (a negative age, doesn't make much sense) is gone and got replaced by the length at birth, l_0, which pressumably you can fix.

In addition to that reduction in the number of parameters, I'd try setting a higher number of iterations to something like 10000.

HTH

____________________________________________________________________________________ 

Dr. Rub?n Roa-Ureta
AZTI - Tecnalia / Marine Research Unit
Txatxarramendi Ugartea z/g
48395 Sukarrieta (Bizkaia)
SPAIN



From F.DUYME at arvalisinstitutduvegetal.fr  Tue Jul 13 10:49:19 2010
From: F.DUYME at arvalisinstitutduvegetal.fr (DUYME Florent)
Date: Tue, 13 Jul 2010 10:49:19 +0200
Subject: [R-sig-ME] Fvalue
Message-ID: <674BC74273529E40A236CE2FB772DE093539D2DB97@srv-exch-bgn.arvalis-fr.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100713/9f7fb253/attachment.pl>

From vlagani at ics.forth.gr  Tue Jul 13 12:19:59 2010
From: vlagani at ics.forth.gr (vlagani at ics.forth.gr)
Date: Tue, 13 Jul 2010 13:19:59 +0300
Subject: [R-sig-ME] testing linear combinations of fixed effects coefficients
Message-ID: <20100713131959.16299ki7ctwxte5w@webmail.ics.forth.gr>

Dear List,

I am interested in assessing the significance of a linear combination  
of fixed effects coefficients in my linear mixed model. In the nlme  
package this can be performed with the anova function and the "L"  
option (see the code snipet below); however, it seems to me that the  
anova function in lm4 does not allow a similar computation.

Reading some previous posts on the list (e.g.  
http://www.mail-archive.com/r-help at r-project.org/msg03028.html), I  
understood that I can *probably* use the variance covariance matrix  
returned by vcov in order to assess the confidence intervals of the  
linear combination I am interested in.
However, I would like to avoid a so complex solution, since it seems  
that there are a lot of "technical" difficulties, e.g. the matrix  
returned by vcov is only an estimation of the real variance covariance  
matrix.

As a possible alternative, I guess that I might use the empirical  
distributions provided by the MCMCglmm function in order to calculate  
the empirical distribution of any combination of model parameters...  
but I am not sure about this.

Thanks in advance for any answer!

Greets,

Vincenzo

############CODE################

library(nlme)

# the following model has four fixed effects coefficients: Intercept, age,
# SexFemale and age:SexFemale. I want to test if the linear combination
# age + age:SexFemale is significant (this test  is probably not meaningful
# in the contest of this model, but it is only for explanation purposes)
model  <-  lme(distance ~ age * Sex, data = Orthodont, random = ~ 1)

#summing the second (age) and fourth (age:SexFemale) coefficients
myL = c(0,1,0,1)

#testing the significance of the linear combination
anova(model, L = myL);



From chesterkam at gmail.com  Tue Jul 13 19:22:37 2010
From: chesterkam at gmail.com (Chester Kam)
Date: Tue, 13 Jul 2010 13:22:37 -0400
Subject: [R-sig-ME] HELP: Got error message in R lme4!
Message-ID: <AANLkTikifYoOslZiYiXz-UwDw7_Po2o7yD9oVNSCWwYW@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100713/521f8d1c/attachment.pl>

From arrayprofile at yahoo.com  Tue Jul 13 20:50:38 2010
From: arrayprofile at yahoo.com (array chip)
Date: Tue, 13 Jul 2010 11:50:38 -0700 (PDT)
Subject: [R-sig-ME] env() error message
Message-ID: <704222.67637.qm@web56307.mail.re3.yahoo.com>

I am following examples of the lme4 draft book. 

> fm1 <- lmer(Yield ~ 1 + (1|Batch), Dyestuff)
> env(fm1ML)$Lambda
Error: could not find function "env"

what went wrong here? Maybe env() function is from some special package that I 
didn't attach?

Thanks

John

> sessionInfo()
R version 2.10.1 (2009-12-14) 
i386-pc-mingw32 

locale:
[1] LC_COLLATE=English_United States.1252 
[2] LC_CTYPE=English_United States.1252   
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C                          
[5] LC_TIME=English_United States.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] nlme_3.1-96        lme4_0.999375-33   Matrix_0.999375-39 lattice_0.18-3    

loaded via a namespace (and not attached):
[1] grid_2.10.1  tools_2.10.1



From bates at stat.wisc.edu  Tue Jul 13 21:01:20 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 13 Jul 2010 14:01:20 -0500
Subject: [R-sig-ME] env() error message
In-Reply-To: <704222.67637.qm@web56307.mail.re3.yahoo.com>
References: <704222.67637.qm@web56307.mail.re3.yahoo.com>
Message-ID: <AANLkTinooaAS5GOvA2hTmKxZIWFfm19-vWAlzqR8hMyR@mail.gmail.com>

On Tue, Jul 13, 2010 at 1:50 PM, array chip <arrayprofile at yahoo.com> wrote:
> I am following examples of the lme4 draft book.
>
>> fm1 <- lmer(Yield ~ 1 + (1|Batch), Dyestuff)
>> env(fm1ML)$Lambda
> Error: could not find function "env"
>
> what went wrong here? Maybe env() function is from some special package that I
> didn't attach?

The env function was in an unreleased version of the lme4 package and
has now been retired.

I am preparing for a tutorial at the useR!2010 conference next week
and will have the versions of lme4 and the book chapters and the
slides coordinated by then.


>
> Thanks
>
> John
>
>> sessionInfo()
> R version 2.10.1 (2009-12-14)
> i386-pc-mingw32
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>
> other attached packages:
> [1] nlme_3.1-96 ? ? ? ?lme4_0.999375-33 ? Matrix_0.999375-39 lattice_0.18-3
>
> loaded via a namespace (and not attached):
> [1] grid_2.10.1 ?tools_2.10.1
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From arrayprofile at yahoo.com  Tue Jul 13 22:20:48 2010
From: arrayprofile at yahoo.com (array chip)
Date: Tue, 13 Jul 2010 13:20:48 -0700 (PDT)
Subject: [R-sig-ME] env() error message
In-Reply-To: <AANLkTinooaAS5GOvA2hTmKxZIWFfm19-vWAlzqR8hMyR@mail.gmail.com>
References: <704222.67637.qm@web56307.mail.re3.yahoo.com>
	<AANLkTinooaAS5GOvA2hTmKxZIWFfm19-vWAlzqR8hMyR@mail.gmail.com>
Message-ID: <283441.58056.qm@web56305.mail.re3.yahoo.com>

Thank you Dr. Bates. I also got error message when using profile(), was that due 
to the same reason? Thanks.

> profile(fm1ML)

Error in UseMethod("profile") : 
  no applicable method for 'profile' applied to an object of class "mer"

John





----- Original Message ----
From: Douglas Bates <bates at stat.wisc.edu>
To: array chip <arrayprofile at yahoo.com>
Cc: r-sig-mixed-models at r-project.org
Sent: Tue, July 13, 2010 12:01:20 PM
Subject: Re: [R-sig-ME] env() error message

On Tue, Jul 13, 2010 at 1:50 PM, array chip <arrayprofile at yahoo.com> wrote:
> I am following examples of the lme4 draft book.
>
>> fm1 <- lmer(Yield ~ 1 + (1|Batch), Dyestuff)
>> env(fm1ML)$Lambda
> Error: could not find function "env"
>
> what went wrong here? Maybe env() function is from some special package that I
> didn't attach?

The env function was in an unreleased version of the lme4 package and
has now been retired.

I am preparing for a tutorial at the useR!2010 conference next week
and will have the versions of lme4 and the book chapters and the
slides coordinated by then.


>
> Thanks
>
> John
>
>> sessionInfo()
> R version 2.10.1 (2009-12-14)
> i386-pc-mingw32
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] nlme_3.1-96        lme4_0.999375-33   Matrix_0.999375-39 lattice_0.18-3
>
> loaded via a namespace (and not attached):
> [1] grid_2.10.1  tools_2.10.1
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From s90225007 at yahoo.com.tw  Tue Jul 13 23:20:09 2010
From: s90225007 at yahoo.com.tw (Nai-Wei Chen)
Date: Wed, 14 Jul 2010 05:20:09 +0800 (CST)
Subject: [R-sig-ME] A problem about the package "lme4" in R-2.11.1
Message-ID: <539761.79975.qm@web73408.mail.tp2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100714/3bf95c97/attachment.pl>

From andydolman at gmail.com  Wed Jul 14 10:29:58 2010
From: andydolman at gmail.com (Andrew Dolman)
Date: Wed, 14 Jul 2010 10:29:58 +0200
Subject: [R-sig-ME] HELP: Got error message in R lme4!
In-Reply-To: <AANLkTikifYoOslZiYiXz-UwDw7_Po2o7yD9oVNSCWwYW@mail.gmail.com>
References: <AANLkTikifYoOslZiYiXz-UwDw7_Po2o7yD9oVNSCWwYW@mail.gmail.com>
Message-ID: <AANLkTimHd8b9ewL8bwz4FMavOc8xswBYu_DIQrpXJA6t@mail.gmail.com>

Hi Chester,

When I get that error message it is usually fixed by making sure that
the random variables are stored as factors. e.g. as.factor(id)

lmer() normally coerces things to factors when they are on the right
hand side of | but sometimes this seems to be broken.

Andy.

andydolman at gmail.com



On 13 July 2010 19:22, Chester Kam <chesterkam at gmail.com> wrote:
> Dear all,
>
>
>
> Hi, a few days ago I have posted a message to my problem. Thank you very
> much for your help! Now I wonder if any of you can help me with my linear
> mixed model with R because I got an error message in R. I tried to
> google the solution, but to no avail. To recall, I am trying to predict
> manager's performance with one fixed effect and two random effects. The
> fixed effect is scoring method (only 2 different methods), and the random
> effects are the type of exercise (interpersonal, in-baskets... together 9
> different exercises) and the managers in the study (46 managers, this
> variable is named id in the datafile).
>
>
>
> Therefore, all 46 managers engage in all 9 exercises. Each of the exercises
> was assessed two ways.
>
>
>
> I do not have problems when I examine the main effect of the variables
> (performance ~ method + (1|id) + (1|exercise). However, I start to encounter
> problems when I examine the interactions between these three variables. I
> wonder if you have any clues why it is the case.
>
>
>
> *When I just try to examine the main effects (without interactions), the
> result is fine:*
>
> * *
>
> *> Model1 <- lmer(performance ~ method + (1|id) + (1|exercise), data=mtmm)*
>
> *> summary (Model1)*
>
> Linear mixed model fit by REML
>
> Formula: performance ~ method + (1 | id) + (1 | exercise)
>
> Data: mtmm
>
> AIC BIC logLik deviance REMLdev
>
> 1617 1641 -803.6 1599 1607
>
> Random effects:
>
> Groups Name Variance Std.Dev.
>
> id (Intercept) 0.113182 0.33642
>
> exercise (Intercept) 0.020629 0.14363
>
> Residual 0.358530 0.59877
>
> Number of obs: 827, groups: id, 46; exercise, 9
>
> Fixed effects:
>
> Estimate Std. Error t value
>
> (Intercept) 3.57527 0.07497 47.69
>
> method 0.13553 0.04164 3.25
>
> Correlation of Fixed Effects:
>
> (Intr)
>
> method -0.278
>
>
>
> *Problems occurs, however, when I specify intearctions. For example:*
>
> * *
>
> *(BETWEEN TWO RANDOM EFFECTS)***
>
> *> Model1 <- lmer(performance ~ method + (1|id) + (1|exercise) +
> (1|id:exercise), data=mtmm)*
>
> Error: length(f1) == length(f2) is not TRUE
>
> In addition: Warning messages:
>
> 1: In id:exercise :
>
> numerical expression has 827 elements: only the first used
>
> 2: In id:exercise :
>
> numerical expression has 827 elements: only the first used
>
>
>
> *(BETWEEN ONE FIXED EFFECT AND ONE RANDOM EFFECT)*
>
> *> Model1 <- lmer(performance ~ method + (1|id) + (1|exercise) +
> (1|method:exercise), mtmm)*
>
> Error: length(f1) == length(f2) is not TRUE
>
> In addition: Warning messages:
>
> 1: In method:exercise :
>
> numerical expression has 827 elements: only the first used
>
> 2: In method:exercise :
>
> numerical expression has 827 elements: only the first used
>
> * *
>
> *The descriptive statistics of the data is as follow:*
>
> *> summary(mtmm)*
>
> id exercise method performance
>
> 40,873 : 18 Min. :1.000 Min. :0.0000 Min. :1.000
>
> 40,888 : 18 1st Qu.:3.000 1st Qu.:0.0000 1st Qu.:3.200
>
> 40,894 : 18 Median :5.000 Median :1.0000 Median :3.670
>
> 40,897 : 18 Mean :4.996 Mean :0.5006 Mean :3.643
>
> 40,903 : 18 3rd Qu.:7.000 3rd Qu.:1.0000 3rd Qu.:4.200
>
> 40,915 : 18 Max. :9.000 Max. :1.0000 Max. :5.000
>
> (Other):719
>
> * *
>
> *A sample data is as follow:*
>
> id
>
> exercise
>
> method
>
> performance
>
> 40873
>
> 1
>
> 0
>
> 3.2
>
> 40873
>
> 1
>
> 1
>
> 3
>
> 40873
>
> 2
>
> 0
>
> 3.2
>
> 40873
>
> 2
>
> 1
>
> 3.8
>
> 40873
>
> 3
>
> 0
>
> 4.8
>
> 40873
>
> 3
>
> 1
>
> 4
>
> 40873
>
> 4
>
> 0
>
> 2.2
>
> 40873
>
> 4
>
> 1
>
> 3.2
>
> 40873
>
> 5
>
> 0
>
> 4.73
>
> 40873
>
> 5
>
> 1
>
> 4.73
>
> 40873
>
> 6
>
> 0
>
> 4.4
>
> 40873
>
> 6
>
> 1
>
> 3
>
> 40873
>
> 7
>
> 0
>
> 3.57
>
> 40873
>
> 7
>
> 1
>
> 3.92
>
> 40873
>
> 8
>
> 0
>
> 3.8
>
> 40873
>
> 8
>
> 1
>
> 3.8
>
> 40873
>
> 9
>
> 0
>
> 4.27
>
> 40873
>
> 9
>
> 1
>
> 3.96
>
> 40888
>
> 1
>
> 0
>
> 2.4
>
> 40888
>
> 1
>
> 1
>
> 3
>
> 40888
>
> 2
>
> 0
>
> 3.6
>
> 40888
>
> 2
>
> 1
>
> 2.4
>
> 40888
>
> 3
>
> 0
>
> 3.4
>
> 40888
>
> 3
>
> 1
>
> 3
>
> 40888
>
> 4
>
> 0
>
> 3.8
>
> 40888
>
> 4
>
> 1
>
> 3.4
>
> 40888
>
> 5
>
> 0
>
> 2.87
>
> 40888
>
> 5
>
> 1
>
> 3.13
>
> 40888
>
> 6
>
> 0
>
> 3.4
>
> 40888
>
> 6
>
> 1
>
> 3.8
>
> 40888
>
> 7
>
> 0
>
> 4.75
>
> 40888
>
> 7
>
> 1
>
> 4.58
>
> 40888
>
> 8
>
> 0
>
> 3.1
>
> 40888
>
> 8
>
> 1
>
> 4.2
>
> 40888
>
> 9
>
> 0
>
> 3.79
>
> 40888
>
> 9
>
> 1
>
> 2.48
>
> ?*So I wonder what is wrong in my setup. Or, I need a supercomputer, with
> plenty of processing power, in order to assess my data?*
>
> * *
>
> *In addition, I wonder if there is a difference between (1|exercise:method)
> and (1|method:exercise), or between (1|exercise:id) and (1|id:exercise)?*
>
> * *
>
> *Thanks so much for help me again! I appreciate it a lot!*
>
> * *
>
> *Chester*
>
> *PhD Candidate*
>
> *University of Western Ontario*
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From agalecki at umich.edu  Wed Jul 14 16:53:00 2010
From: agalecki at umich.edu (Andrzej Galecki)
Date: Wed, 14 Jul 2010 10:53:00 -0400
Subject: [R-sig-ME] Eqn. (5.22)
Message-ID: <4C3DCF4C.6040301@umich.edu>

Dear Mixed List:

I am trying to follow eqn (5.22) in Chapter 5 of  "lme4: Mixed-effects 
modeling with R" book by Douglas Bates
and cross-check the results from a linear mixed effects model  fit.

Specifically, in the code below I extract pieces of information from 
object "fm2" and compute
expressions on the left and right hand side of (5.22). For some reason 
left side is (slightly) different from right hand side.
What am I doing wrong? Same with object "fm2a".

Thank you

Andrzej Galecki


# http://lme4.r-forge.r-project.org/book/Ch5.pdf
# Eqn. (5.22) on p.89

library(lme4)
# sessionInfo()    # see postscript later in this email

fm2 <- lmer(Reaction ~ Days + (1|Subject) + (0+Days|Subject), sleepstudy)
# fm2a <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy) 

fm <- fm2

###### Right hand side of (5.20)
Zt <- slot(fm,"Zt")      # Z transposed
# image(Zt)
STs  <- expand(fm)       # Expand ST slot

#summary(STs)

P    <- STs$P  # permutation matrix P

S    <- STs$S  # Diagonal scale matrix S
# summary(S)
T    <- STs$T  # Unit lower-triangular matrix T
#summary(T)     # All off-diagonal equal to 0      

Lmbda <- T %*% S     #  Formula w/out number on p.84      
U <- t(Zt) %*% Lmbda
U1 <-   (t(U) %*% U + Diagonal(ncol(U)))
U1P <- P %*% U1 %*% t(P)
#image(U1P)

######  Left hand side of (5.20)
Ls  <- slot(fm,"L") 
#image(Ls)
L  <- as(Ls, "sparseMatrix")
LtL <- tcrossprod(L)

# Compare left and right hand sides of (5.20)

max(abs(LtL -U1P ))    # LtL not equal to U1P
# [1] 0.003046723

LtL[1:2,1:2]                 # Block extracted
#2 x 2 sparse Matrix of class "dsCMatrix"
#                     
# [1,] 10.60194 10.32746
# [2,] 10.32746 16.63319

        
U1P[1:2,1:2]             # Block
# 2 x 2 sparse Matrix of class "dgCMatrix"
                     
# [1,] 10.60194 10.32846
# [2,] 10.32846 16.63624



PS.

######## sessionInfo ######  

 > sessionInfo()
R version 2.10.1 (2009-12-14)
i386-pc-mingw32

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252  
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C                         
[5] LC_TIME=English_United States.1252   

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base    

other attached packages:
[1] lme4_0.999375-32   Matrix_0.999375-33 lattice_0.17-26  

loaded via a namespace (and not attached):
[1] grid_2.10.1 nlme_3.1-96



From agalecki at umich.edu  Wed Jul 14 17:05:11 2010
From: agalecki at umich.edu (Andrzej Galecki)
Date: Wed, 14 Jul 2010 11:05:11 -0400
Subject: [R-sig-ME] Eqn. (5.22). Resent
Message-ID: <4C3DD227.5060307@umich.edu>


Unfortunately, two lines of my code were merged  together. They are 
separated in this email.

Andrzej Galecki


# http://lme4.r-forge.r-project.org/book/Ch5.pdf
# Eqn. (5.22) on p.89

library(lme4)
# sessionInfo()    # see postscript later in this email

fm2 <- lmer(Reaction ~ Days + (1|Subject) + (0+Days|Subject), sleepstudy)
# fm2a <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
fm <- fm2

###### Right hand side of (5.20)
Zt <- slot(fm,"Zt")      # Z transposed
# image(Zt)
STs  <- expand(fm)       # Expand ST slot

#summary(STs)

P    <- STs$P  # permutation matrix P

S    <- STs$S  # Diagonal scale matrix S
# summary(S)
T    <- STs$T  # Unit lower-triangular matrix T
#summary(T)     # All off-diagonal equal to 0     
Lmbda <- T %*% S     #  Formula w/out number on p.84     

U <- t(Zt) %*% Lmbda       # This line was  lumped  with previous one
U1 <-   (t(U) %*% U + Diagonal(ncol(U)))
U1P <- P %*% U1 %*% t(P)
#image(U1P)

######  Left hand side of (5.20)
Ls  <- slot(fm,"L") #image(Ls)
L  <- as(Ls, "sparseMatrix")
LtL <- tcrossprod(L)

# Compare left and right hand sides of (5.20)

max(abs(LtL -U1P ))    # LtL not equal to U1P
# [1] 0.003046723

LtL[1:2,1:2]                 # Block extracted
#2 x 2 sparse Matrix of class "dsCMatrix"
#                     # [1,] 10.60194 10.32746
# [2,] 10.32746 16.63319

       U1P[1:2,1:2]             # Block
# 2 x 2 sparse Matrix of class "dgCMatrix"
                    # [1,] 10.60194 10.32846
# [2,] 10.32846 16.63624



From rdanner at vt.edu  Wed Jul 14 17:10:39 2010
From: rdanner at vt.edu (Raymond Danner)
Date: Wed, 14 Jul 2010 11:10:39 -0400
Subject: [R-sig-ME] Function to create candidate model list
Message-ID: <C8634BAF.1984%rdanner@vt.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100714/5e2186fb/attachment.pl>

From andyfugard at gmail.com  Wed Jul 14 18:00:44 2010
From: andyfugard at gmail.com (Andy Fugard)
Date: Wed, 14 Jul 2010 18:00:44 +0200
Subject: [R-sig-ME] Function to create candidate model list
In-Reply-To: <C8634BAF.1984%rdanner@vt.edu>
References: <C8634BAF.1984%rdanner@vt.edu>
Message-ID: <AANLkTin-dVsfRkLDg_HZ3KObjKErlLMTMh87LjrGDdZX@mail.gmail.com>

There's one here:

    http://www.andyfugard.info/TypeII_Lmer.R

which might give you some clues for how to write what you really want.
 (See examples at end.)  It does a sort of iterated "drop1" - only on
the fixed effects.  It doesn't touch the random effects at all, which
means you'll end up with nonsense if you have a random slope, e.g.,
models of these forms will be compared.

   ?y ~ 1 + x + (x|id)
?   y ~ 1 ? ? + (x|id)

Here's example output:

lmer.typeII(r2 ~ (Anger * Gender * btype * situ) + (1|id) + (1|item),
 family = binomial, data = VerbAgg)

                            AIC    BIC Chisq Chi Df Pr(>Chisq)
 Anger                    -9.52  -2.58 11.52      1       0.00
 Gender                   -0.78   6.15  2.78      1       0.10
 btype                   -27.88 -14.01 31.88      2       0.00
 situ                    -15.20  -8.27 17.20      1       0.00
 Anger:Gender              2.00   8.93  0.00      1       0.98
 Anger:btype               2.03  15.90  1.97      2       0.37
 Anger:situ               -0.63   6.30  2.63      1       0.10
 Gender:btype            -14.83  -0.96 18.83      2       0.00
 Gender:situ               1.48   8.42  0.52      1       0.47
 btype:situ                2.75  16.61  1.25      2       0.53
 Anger:Gender:btype        0.87  14.74  3.13      2       0.21
 Anger:Gender:situ        -0.09   6.85  2.09      1       0.15
 Anger:btype:situ          3.32  17.19  0.68      2       0.71
 Gender:btype:situ         3.33  17.20  0.67      2       0.71
 Anger:Gender:btype:situ   3.57  17.44  0.43      2       0.81

For instance the row for Anger is the result of comparing these two models:

 r2 ~ Anger + Gender + btype + situ + (1 | id) + (1 | item)
 r2 ~         Gender + btype + situ + (1 | id) + (1 | item)

(the AIC and BIC columns are differences; Chisq is the log-likelihood
ratio.)

The row for Anger:Gender is the result of comparing:

 r2 ~ Anger + Gender + btype + situ + (1 | id) + (1 | item) +
     Anger:Gender + Anger:btype + Anger:situ + Gender:btype +
     Gender:situ + btype:situ
 r2 ~ Anger + Gender + btype + situ + (1 | id) + (1 | item) +
                  + Anger:btype + Anger:situ + Gender:btype +
     Gender:situ + btype:situ

Cheers,

Andy


On Wed, Jul 14, 2010 at 17:10, Raymond Danner <rdanner at vt.edu> wrote:
>
> Dear R users,
>
> Could anyone recommend a function that creates a list of all possible
> candidate mixed models (type lmer) from specified fixed and random
> variables? ?So that you know where I? going--I would then like to rank
> these models with AIC and calculate model averages with the AICcmodavg
> package.
>
> Thanks in advance,
> Ray
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Wed Jul 14 19:52:04 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 14 Jul 2010 12:52:04 -0500
Subject: [R-sig-ME] env() error message
In-Reply-To: <283441.58056.qm@web56305.mail.re3.yahoo.com>
References: <704222.67637.qm@web56307.mail.re3.yahoo.com>
	<AANLkTinooaAS5GOvA2hTmKxZIWFfm19-vWAlzqR8hMyR@mail.gmail.com>
	<283441.58056.qm@web56305.mail.re3.yahoo.com>
Message-ID: <AANLkTik_YWuO71WeyGYCnOV2VsQhf2bTDr1_nGys54Uf@mail.gmail.com>

On Tue, Jul 13, 2010 at 3:20 PM, array chip <arrayprofile at yahoo.com> wrote:
> Thank you Dr. Bates. I also got error message when using profile(), was that due
> to the same reason? Thanks.

Yes.

>> profile(fm1ML)
>
> Error in UseMethod("profile") :
> ?no applicable method for 'profile' applied to an object of class "mer"
>
> John
>
>
>
>
>
> ----- Original Message ----
> From: Douglas Bates <bates at stat.wisc.edu>
> To: array chip <arrayprofile at yahoo.com>
> Cc: r-sig-mixed-models at r-project.org
> Sent: Tue, July 13, 2010 12:01:20 PM
> Subject: Re: [R-sig-ME] env() error message
>
> On Tue, Jul 13, 2010 at 1:50 PM, array chip <arrayprofile at yahoo.com> wrote:
>> I am following examples of the lme4 draft book.
>>
>>> fm1 <- lmer(Yield ~ 1 + (1|Batch), Dyestuff)
>>> env(fm1ML)$Lambda
>> Error: could not find function "env"
>>
>> what went wrong here? Maybe env() function is from some special package that I
>> didn't attach?
>
> The env function was in an unreleased version of the lme4 package and
> has now been retired.
>
> I am preparing for a tutorial at the useR!2010 conference next week
> and will have the versions of lme4 and the book chapters and the
> slides coordinated by then.
>
>
>>
>> Thanks
>>
>> John
>>
>>> sessionInfo()
>> R version 2.10.1 (2009-12-14)
>> i386-pc-mingw32
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252
>> [2] LC_CTYPE=English_United States.1252
>> [3] LC_MONETARY=English_United States.1252
>> [4] LC_NUMERIC=C
>> [5] LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>
>> other attached packages:
>> [1] nlme_3.1-96 ? ? ? ?lme4_0.999375-33 ? Matrix_0.999375-39 lattice_0.18-3
>>
>> loaded via a namespace (and not attached):
>> [1] grid_2.10.1 ?tools_2.10.1
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
>
>
>



From rdanner at vt.edu  Wed Jul 14 22:48:22 2010
From: rdanner at vt.edu (Raymond Danner)
Date: Wed, 14 Jul 2010 16:48:22 -0400
Subject: [R-sig-ME] Function to create candidate model list
In-Reply-To: <AANLkTin-dVsfRkLDg_HZ3KObjKErlLMTMh87LjrGDdZX@mail.gmail.com>
Message-ID: <C8639AD6.199A%rdanner@vt.edu>

Thanks Andy,

I'll look into it!

Ray


On 7/14/10 12:00 PM, "Andy Fugard" <andyfugard at gmail.com> wrote:

> There's one here:
> 
>     http://www.andyfugard.info/TypeII_Lmer.R
> 
> which might give you some clues for how to write what you really want.
>  (See examples at end.)  It does a sort of iterated "drop1" - only on
> the fixed effects.  It doesn't touch the random effects at all, which
> means you'll end up with nonsense if you have a random slope, e.g.,
> models of these forms will be compared.
> 
>    ?y ~ 1 + x + (x|id)
> ?   y ~ 1 ? ? + (x|id)
> 
> Here's example output:
> 
> lmer.typeII(r2 ~ (Anger * Gender * btype * situ) + (1|id) + (1|item),
>  family = binomial, data = VerbAgg)
> 
>                             AIC    BIC Chisq Chi Df Pr(>Chisq)
>  Anger                    -9.52  -2.58 11.52      1       0.00
>  Gender                   -0.78   6.15  2.78      1       0.10
>  btype                   -27.88 -14.01 31.88      2       0.00
>  situ                    -15.20  -8.27 17.20      1       0.00
>  Anger:Gender              2.00   8.93  0.00      1       0.98
>  Anger:btype               2.03  15.90  1.97      2       0.37
>  Anger:situ               -0.63   6.30  2.63      1       0.10
>  Gender:btype            -14.83  -0.96 18.83      2       0.00
>  Gender:situ               1.48   8.42  0.52      1       0.47
>  btype:situ                2.75  16.61  1.25      2       0.53
>  Anger:Gender:btype        0.87  14.74  3.13      2       0.21
>  Anger:Gender:situ        -0.09   6.85  2.09      1       0.15
>  Anger:btype:situ          3.32  17.19  0.68      2       0.71
>  Gender:btype:situ         3.33  17.20  0.67      2       0.71
>  Anger:Gender:btype:situ   3.57  17.44  0.43      2       0.81
> 
> For instance the row for Anger is the result of comparing these two models:
> 
>  r2 ~ Anger + Gender + btype + situ + (1 | id) + (1 | item)
>  r2 ~         Gender + btype + situ + (1 | id) + (1 | item)
> 
> (the AIC and BIC columns are differences; Chisq is the log-likelihood
> ratio.)
> 
> The row for Anger:Gender is the result of comparing:
> 
>  r2 ~ Anger + Gender + btype + situ + (1 | id) + (1 | item) +
>      Anger:Gender + Anger:btype + Anger:situ + Gender:btype +
>      Gender:situ + btype:situ
>  r2 ~ Anger + Gender + btype + situ + (1 | id) + (1 | item) +
>                   + Anger:btype + Anger:situ + Gender:btype +
>      Gender:situ + btype:situ
> 
> Cheers,
> 
> Andy
> 
> 
> On Wed, Jul 14, 2010 at 17:10, Raymond Danner <rdanner at vt.edu> wrote:
>> 
>> Dear R users,
>> 
>> Could anyone recommend a function that creates a list of all possible
>> candidate mixed models (type lmer) from specified fixed and random
>> variables? ?So that you know where I? going--I would then like to rank
>> these models with AIC and calculate model averages with the AICcmodavg
>> package.
>> 
>> Thanks in advance,
>> Ray
>> 
>> ? ? ? ?[[alternative HTML version deleted]]
>> 
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>



From lucianolasala at yahoo.com.ar  Wed Jul 14 23:19:38 2010
From: lucianolasala at yahoo.com.ar (Luciano La Sala)
Date: Wed, 14 Jul 2010 18:19:38 -0300
Subject: [R-sig-ME] Plot a "mer" object
Message-ID: <B1F9F468BDE24EE1B24889EE8C7AAA63@Negro1>

Hello, 

I fitted a glmm on a small dataset using lme4. Data consist of dependent
variable "Egg_Volume" (continuous) and independent variables "Hatching
Order" (3 factors: first, second, third), "Year" (2 factors: 2006, 2007) and
their interaction (Hatching_Order*Year). Nest IDs were included as random
intercepts. 

Model output: 

> model.2 <- lmer(EggVolume~HatchOrder*Year+(1|NestID),REML=FALSE)

Linear mixed model fit by maximum likelihood 
Formula: EggVolume ~ HatchOrder * Year + (1 | NestID) 
   AIC   BIC logLik deviance REMLdev
 745.4 768.4 -364.7    729.4   720.4

Random effects:
 Groups   Name        Variance Std.Dev.
 NestID   (Intercept) 25.272   5.0271  
 Residual              5.930   2.4352  
Number of obs: 130, groups: NestID, 55

Fixed effects:
                          Estimate Std. Error t value
(Intercept)                79.6515     1.1092   71.81
HatchOrderSecond           -0.5676     0.7714   -0.74
HatchOrderThird            -4.7545     0.8817   -5.39
Year2007                    3.6288     1.5408    2.36
HatchOrderSecond:Year2007  -2.8466     1.0600   -2.69
HatchOrderThird:Year2007   -2.8900     1.1946   -2.42

Correlation of Fixed Effects:
            (Intr) HtchOS HtchOT Yr2007 HOS:Y2
HtchOrdrScn -0.267                            
HtchOrdrThr -0.221  0.367                     
Year2007    -0.720  0.192  0.159              
HtcOS:Y2007  0.195 -0.728 -0.267 -0.294       
HtcOT:Y2007  0.163 -0.271 -0.738 -0.297  0.404

I've been trying to come to grips with the function "plotLMER.fnc" from
"languageR" package to plot my results, but so far I have not succeeded. 

>From the relevant documentation
(http://bm2.genes.nig.ac.jp/RGM2/R_current/library/languageR/man/plotLMER.fn
c.html) there are some arguments which I am not sure how to specify
(indicated with "???" below).  

plotLMER.fnc(mixto.4a, xlabel = NA, xlabs = "Year", ylabel = "Egg Volume",
ylimit = NA, fun = NA, pred = NA, n = ????, intr = ????, "end", mcmcMat =
NA, lockYlim = TRUE, addlines = TRUE, withList = FALSE, cexsize = 0.5)

Could someone help me out with this? If there is a better and simpler way of
plotting this kind of models, I'd like to know it. I am quite new to R and
its language. 

Thanks in advance! 

LFLS



From s-lukic at northwestern.edu  Thu Jul 15 18:01:13 2010
From: s-lukic at northwestern.edu (Sladjana)
Date: Thu, 15 Jul 2010 16:01:13 +0000 (UTC)
Subject: [R-sig-ME] Failure to load lme4 on Mac
References: <C8207D43.4236%mcmahons@si.edu> <4BFB0AE0.3090803@zeno.co.nz>
Message-ID: <loom.20100715T175631-148@post.gmane.org>

Hi,

I am having the same problem with loading lme4 on Mac. 
Can someone guid me through this, I would really appreciate?
This is the error message I have been getting:
* installing *source* package ?lme4? ...
** libs
*** arch - i386
sh: make: command not found
ERROR: compilation failed for package ?lme4?
* removing ?/Library/Frameworks/R.framework/Versions/2.11/Resources/library/lme4?

The downloaded packages are in
	?/private/var/folders/5i/5ineVodYG08abdx7gchSaE+++TI/-Tmp-
/Rtmp4Czfel/downloaded_packages?

Thank you
Sladjana



From desja004 at umn.edu  Thu Jul 15 18:58:12 2010
From: desja004 at umn.edu (Christopher Desjardins)
Date: Thu, 15 Jul 2010 11:58:12 -0500
Subject: [R-sig-ME] Failure to load lme4 on Mac
In-Reply-To: <loom.20100715T175631-148@post.gmane.org>
References: <C8207D43.4236%mcmahons@si.edu> <4BFB0AE0.3090803@zeno.co.nz>
	<loom.20100715T175631-148@post.gmane.org>
Message-ID: <AANLkTim4iUokYQZvcL99rhTQkHqIQ5wuESMAGCPu7qGe@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100715/a971d96d/attachment.pl>

From danielezrajohnson at gmail.com  Thu Jul 15 19:31:16 2010
From: danielezrajohnson at gmail.com (Daniel Ezra Johnson)
Date: Thu, 15 Jul 2010 13:31:16 -0400
Subject: [R-sig-ME] Failure to load lme4 on Mac
In-Reply-To: <AANLkTim4iUokYQZvcL99rhTQkHqIQ5wuESMAGCPu7qGe@mail.gmail.com>
References: <C8207D43.4236%mcmahons@si.edu> <4BFB0AE0.3090803@zeno.co.nz>
	<loom.20100715T175631-148@post.gmane.org>
	<AANLkTim4iUokYQZvcL99rhTQkHqIQ5wuESMAGCPu7qGe@mail.gmail.com>
Message-ID: <AANLkTil72csO0XA3-ZghXw62RUp9gMr-Df1Kx8Bi_Iq2@mail.gmail.com>

I would appreciate it if the lme4 developers could state whether they
plan to ensure that a Mac binary be available at any point in the
future (as it does not seem like the problem is going to fix itself).
As we see, it is not trivial to compile the package from source on the
Mac OS.

Thanks,
Dan

On Thu, Jul 15, 2010 at 12:58 PM, Christopher Desjardins
<desja004 at umn.edu> wrote:
> Did you see this from Daniel Myall ...
>
> .................
> Hi Sean,
>
> On your Macbook do you have xcode installed? The error "sh: make: command
> not found" indicates that this is not the case.
>
> The best place to get the latest xcode is http://connect.apple.com/ (The
> main Apple site sends you back and forward between two pages for the xcode
> download).
> ................
>
> You need to install Xcode as you don't have the 'make' command.
> http://developer.apple.com/technologies/tools/xcode.html. Unfortunately
> Xcode is about 1 GB in size.
>
> Or you could wait for a binary build of lme4 for Mac.
> Chris
>
>
>
>
> On Thu, Jul 15, 2010 at 11:01 AM, Sladjana <s-lukic at northwestern.edu> wrote:
>
>> Hi,
>>
>> I am having the same problem with loading lme4 on Mac.
>> Can someone guid me through this, I would really appreciate?
>> This is the error message I have been getting:
>> * installing *source* package ?lme4? ...
>> ** libs
>> *** arch - i386
>> sh: make: command not found
>> ERROR: compilation failed for package ?lme4?
>> * removing
>> ?/Library/Frameworks/R.framework/Versions/2.11/Resources/library/lme4?
>>
>> The downloaded packages are in
>> ? ? ? ? ?/private/var/folders/5i/5ineVodYG08abdx7gchSaE+++TI/-Tmp-
>> /Rtmp4Czfel/downloaded_packages?
>>
>> Thank you
>> Sladjana
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



From cm744 at st-andrews.ac.uk  Thu Jul 15 20:50:35 2010
From: cm744 at st-andrews.ac.uk (Chris Mcowen)
Date: Thu, 15 Jul 2010 19:50:35 +0100
Subject: [R-sig-ME] Interpreting interaction terms
Message-ID: <8D2EEBB1-697B-4023-9399-5C1AFD6DF323@st-andrews.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100715/3750f431/attachment.pl>

From bates at stat.wisc.edu  Thu Jul 15 22:54:34 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 15 Jul 2010 15:54:34 -0500
Subject: [R-sig-ME] Failure to load lme4 on Mac
In-Reply-To: <AANLkTil72csO0XA3-ZghXw62RUp9gMr-Df1Kx8Bi_Iq2@mail.gmail.com>
References: <C8207D43.4236%mcmahons@si.edu> <4BFB0AE0.3090803@zeno.co.nz>
	<loom.20100715T175631-148@post.gmane.org>
	<AANLkTim4iUokYQZvcL99rhTQkHqIQ5wuESMAGCPu7qGe@mail.gmail.com>
	<AANLkTil72csO0XA3-ZghXw62RUp9gMr-Df1Kx8Bi_Iq2@mail.gmail.com>
Message-ID: <AANLkTik15uc4QqaIxcwkhAd4HjpzCQ60MuKqiFDJyJnS@mail.gmail.com>

On Thu, Jul 15, 2010 at 12:31 PM, Daniel Ezra Johnson
<danielezrajohnson at gmail.com> wrote:
> I would appreciate it if the lme4 developers could state whether they
> plan to ensure that a Mac binary be available at any point in the
> future (as it does not seem like the problem is going to fix itself).
> As we see, it is not trivial to compile the package from source on the
> Mac OS.

Neither Martin nor I use Mac OS and we can't reproduce the problem on
other operating systems so we are kind of stuck.

Apparently it is a matter of one of the tests failing but without
access to a system that exhibits the failure I wouldn't know where to
start debugging.  Is some kind person using Mac OS were to download
and test the package and provide some details about the nature of the
failure we might be able to get started.

>
> Thanks,
> Dan
>
> On Thu, Jul 15, 2010 at 12:58 PM, Christopher Desjardins
> <desja004 at umn.edu> wrote:
>> Did you see this from Daniel Myall ...
>>
>> .................
>> Hi Sean,
>>
>> On your Macbook do you have xcode installed? The error "sh: make: command
>> not found" indicates that this is not the case.
>>
>> The best place to get the latest xcode is http://connect.apple.com/ (The
>> main Apple site sends you back and forward between two pages for the xcode
>> download).
>> ................
>>
>> You need to install Xcode as you don't have the 'make' command.
>> http://developer.apple.com/technologies/tools/xcode.html. Unfortunately
>> Xcode is about 1 GB in size.
>>
>> Or you could wait for a binary build of lme4 for Mac.
>> Chris
>>
>>
>>
>>
>> On Thu, Jul 15, 2010 at 11:01 AM, Sladjana <s-lukic at northwestern.edu> wrote:
>>
>>> Hi,
>>>
>>> I am having the same problem with loading lme4 on Mac.
>>> Can someone guid me through this, I would really appreciate?
>>> This is the error message I have been getting:
>>> * installing *source* package ?lme4? ...
>>> ** libs
>>> *** arch - i386
>>> sh: make: command not found
>>> ERROR: compilation failed for package ?lme4?
>>> * removing
>>> ?/Library/Frameworks/R.framework/Versions/2.11/Resources/library/lme4?
>>>
>>> The downloaded packages are in
>>> ? ? ? ? ?/private/var/folders/5i/5ineVodYG08abdx7gchSaE+++TI/-Tmp-
>>> /Rtmp4Czfel/downloaded_packages?
>>>
>>> Thank you
>>> Sladjana
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> ? ? ? ?[[alternative HTML version deleted]]
>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From r.turner at auckland.ac.nz  Thu Jul 15 23:09:06 2010
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 16 Jul 2010 09:09:06 +1200
Subject: [R-sig-ME] Interpreting interaction terms
In-Reply-To: <8D2EEBB1-697B-4023-9399-5C1AFD6DF323@st-andrews.ac.uk>
References: <8D2EEBB1-697B-4023-9399-5C1AFD6DF323@st-andrews.ac.uk>
Message-ID: <86268766-6EE3-483F-95BB-C5E2084194F2@auckland.ac.nz>


In situations like this it helps to think about *simple* examples.  You can do this
just in terms of ordinary garden-variety fixed effects only anova; no need to get
into mixed models and lmer, etc.

Suppose that you have a 2 x 2 design with cell means

	2 3
	3 2

If you were to fit a linear model with no interaction to a y-vector exactly equal to the cell means
(no noise at all) you would find that the A and B effect estimates were exactly 0 (since the row
means and column means are all equal to the grand mean).  However there ***is*** of course interaction
here, the values of the (alpha beta)_ij being +/- 0.5.

If you fit a model *with* interaction you get an error sum of squares equal to 0 and get a non-zero
interaction sum of squares.  The ``main effect'' sums of squares will still of course be 0.

So how can we concoct an example where the main effects appear to be 0 when an additive model is fitted,
but all effects (main and interaction) appear *not* to be 0 when a model with interaction is fitted?

Perturb the basic example a little bit so that the row and column means are not *exactly* equal to
the grand mean, but are close enough so that they will show up as being ``non-significant'' when
their sums of squares are compared with the interaction sum of squares (which becomes the error
sum of squares when you fit an additive model).

When you fit a model with interaction, the error sum of squares gets reduced since the interaction
sum of squares is no longer absorbed into it, and the ``little differences'' between the row and
column means and the grand mean show up as significant.

To do a numerical example in R, replicate the design twice and add a tiny bit of noise so that the
error sum of squares for the model with interaction is not exactly zero (which makes anova() complain
a bit):

mu <- rep(c(2.1,3.2,3,2.1),2)
a  <- rep(factor(c(1,1,2,2)),2)
b  <- rep(factor(c(1,2,1,2)),2)
set.seed(42)
y  <- mu + rnorm(8,0,0.0001)

anova(lm(y ~ a + b)) # Neither a nor b significant.
anova(lm(y ~ a * b)) # All effects significant.

Notice that ``significance'' --- or meaning --- of main effects when there is interaction
in the model is of dubious import.  A significant main effect when there is interaction can be
interpreted as saying that there are differences between the levels of this effect when these
levels are *averaged* over the levels of the *other* factor.  In other words there are differences
between the row means, or column means, in the cell means model. There are those who will fulminate
vehemently about the folly of giving *any* consideration at all to such an interpretation.  And
indeed it is not likely to be of much interest in any practical application.

HTH.

	cheers,

		Rolf Turner



On 16/07/2010, at 6:50 AM, Chris Mcowen wrote:

> Dear List -
> 
> I am fitting some models and have a question regarding the interpretation.
> 
> When i fit the model with no interaction term   only one significant term - pollen dispersal - is significant
> 
> However when i introduce an interaction term ( based on a priori knowledge) not only do the interaction terms become significant ( A*B) but also the terms A + B become significant on there own. Furthermore, new factors become slightly significant.
> 
> Please see below for models ( sorry for formatting).
> 
> My question is, how do i interpret this? Is factor A or B significant on their own? Furthermore, what about the factor that appears significant when the interaction term is added?
> 
> Thanks for your help
> 
> Chris
> 
> 
> NO INTERACTION TERMS
> 
> Starting model - model31 <- lmer(netf~1+(1|order/family) + endosperm + geophyte + breedingsystem + woodyness + seasonality + geophyte + fruit + pollendispersal, family=binomial)
> 
> MAM -  (by removing the factor with the highest pvalue) - model31 <- lmer(netf~1+(1|order/family) + pollendispersal, family=binomial)
> 
> Generalized linear mixed model fit by the Laplace approximation 
> Formula: netf ~ 1 + (1 | order/family) + pollendispersal 
>  AIC  BIC logLik deviance
> 1245 1266 -618.6     1237
> Random effects:
> Groups       Name        Variance Std.Dev.
> family:order (Intercept) 5.3978   2.3233  
> order        (Intercept) 0.0000   0.0000  
> Number of obs: 1242, groups: family:order, 43; order, 9
> 
> Fixed effects:
>                Estimate Std. Error z value Pr(>|z|)  
> (Intercept)       0.9065     0.9071   0.999   0.3177  
> pollendispersal  -1.7225     0.6782  -2.540   0.0111 *
> 
> INTERACTION TERM INCLUDED
> 
> Starting model - model32 <- lmer(netf~1+(1|order/family) + endosperm + geophyte + breedingsystem* woodyness + seasonality + geophyte + fruit + pollendispersal, family=binomial)
> 
> MAM- model33 <- lmer(netf~1+(1|order/family) + breedingsystem*fruit + seasonality + fruit + pollendispersal, family=binomial)
> Generalized linear mixed model fit by the Laplace approximation 
> Formula: netf ~ 1 + (1 | order/family) + breedingsystem * fruit + seasonality +      fruit + pollendispersal 
>  AIC  BIC logLik deviance
> 1246 1287 -614.8     1230
> Random effects:
> Groups       Name        Variance   Std.Dev.  
> family:order (Intercept) 4.8431e+00 2.2007e+00
> order        (Intercept) 4.2899e-11 6.5497e-06
> Number of obs: 1242, groups: family:order, 43; order, 9
> 
> Fixed effects:
>                     Estimate Std. Error z value Pr(>|z|)  
> (Intercept)            2.9283     2.0712   1.414   0.1574  
> breedingsystem        -1.4739     0.7695  -1.915   0.0554 .
> fruit                 -2.4174     1.1130  -2.172   0.0299 *
> seasonality            0.7199     0.4367   1.648   0.0993 .
> pollendispersal       -1.6574     0.6686  -2.479   0.0132 *
> breedingsystem:fruit   1.0401     0.5029   2.068   0.0386 *
> 
> 
> Chris Mcowen
> PhD Student
> 
> Room 15
> Sir Harold Mitchell Building
> University of St Andrews
> St Andrews
> Fife
> KY16 9TH
> UK
> Phone 01334 463381 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

######################################################################
Attention: 
This e-mail message is privileged and confidential. If you are not the 
intended recipient please delete the message and notify the sender. 
Any views or opinions presented are solely those of the author.

This e-mail has been scanned and cleared by MailMarshal 
www.marshalsoftware.com
######################################################################



From john.maindonald at anu.edu.au  Thu Jul 15 23:53:38 2010
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Fri, 16 Jul 2010 07:53:38 +1000
Subject: [R-sig-ME] Failure to load lme4 on Mac
In-Reply-To: <AANLkTik15uc4QqaIxcwkhAd4HjpzCQ60MuKqiFDJyJnS@mail.gmail.com>
References: <C8207D43.4236%mcmahons@si.edu> <4BFB0AE0.3090803@zeno.co.nz>
	<loom.20100715T175631-148@post.gmane.org>
	<AANLkTim4iUokYQZvcL99rhTQkHqIQ5wuESMAGCPu7qGe@mail.gmail.com>
	<AANLkTil72csO0XA3-ZghXw62RUp9gMr-Df1Kx8Bi_Iq2@mail.gmail.com>
	<AANLkTik15uc4QqaIxcwkhAd4HjpzCQ60MuKqiFDJyJnS@mail.gmail.com>
Message-ID: <08AD950F-C3DB-4E23-868B-0EFD94833014@anu.edu.au>

This is odd. Around June 27, I installed version lme4_0.999375-34
from R-forge, using:

install.packages("lme4", repos="http://R-Forge.R-project.org")

I checked a moment ago, and this still works:

> install.packages("lme4", repos="http://R-Forge.R-project.org")
trying URL 'http://R-Forge.R-project.org/bin/macosx/leopard/contrib/2.11/lme4_0.999375-34.tgz'
Content type 'application/x-gzip' length 1281413 bytes (1.2 Mb)
opened URL
==================================================
downloaded 1.2 Mb

I have been happily using it.  

I do however have another Mac that I am keeping for my sister,
and on which I have installed R-2.11.1.  When I try the same command
there, I get: 

"
Warning: unable to access index for repository index http://R-Forge.R-project.org/bin/macosx/leopard/contrib/2.11
Warning message:
In getDependencies(pkgs, available, lib) :
  package 'lme4' is not available.
"

This other R installation is not as fully configured as my main R machine.

For what it is worth (nothing that I can see), here are the two sessionInfo's

Main Machine:
> sessionInfo()
R version 2.11.1 (2010-05-31) 
x86_64-apple-darwin9.8.0 

locale:
[1] C

attached base packages:
[1] stats     graphics  grDevices datasets  utils     methods   base     

loaded via a namespace (and not attached):
[1] Matrix_0.999375-41 grid_2.11.1        lattice_0.18-8     lme4_0.999375-34  
[5] nlme_3.1-96        stats4_2.11.1     
Warning message:
'DESCRIPTION' file has 'Encoding' field and re-encoding is not possible 

Other machine:
> sessionInfo()
R version 2.11.1 (2010-05-31) 
x86_64-apple-darwin9.8.0 

locale:
[1] en_AU.UTF-8/en_AU.UTF-8/C/C/en_AU.UTF-8/en_AU.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods  
[7] base     

loaded via a namespace (and not attached):
[1] tools_2.11.1


John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 16/07/2010, at 6:54 AM, Douglas Bates wrote:

> On Thu, Jul 15, 2010 at 12:31 PM, Daniel Ezra Johnson
> <danielezrajohnson at gmail.com> wrote:
>> I would appreciate it if the lme4 developers could state whether they
>> plan to ensure that a Mac binary be available at any point in the
>> future (as it does not seem like the problem is going to fix itself).
>> As we see, it is not trivial to compile the package from source on the
>> Mac OS.
> 
> Neither Martin nor I use Mac OS and we can't reproduce the problem on
> other operating systems so we are kind of stuck.
> 
> Apparently it is a matter of one of the tests failing but without
> access to a system that exhibits the failure I wouldn't know where to
> start debugging.  Is some kind person using Mac OS were to download
> and test the package and provide some details about the nature of the
> failure we might be able to get started.
> 
>> 
>> Thanks,
>> Dan
>> 
>> On Thu, Jul 15, 2010 at 12:58 PM, Christopher Desjardins
>> <desja004 at umn.edu> wrote:
>>> Did you see this from Daniel Myall ...
>>> 
>>> .................
>>> Hi Sean,
>>> 
>>> On your Macbook do you have xcode installed? The error "sh: make: command
>>> not found" indicates that this is not the case.
>>> 
>>> The best place to get the latest xcode is http://connect.apple.com/ (The
>>> main Apple site sends you back and forward between two pages for the xcode
>>> download).
>>> ................
>>> 
>>> You need to install Xcode as you don't have the 'make' command.
>>> http://developer.apple.com/technologies/tools/xcode.html. Unfortunately
>>> Xcode is about 1 GB in size.
>>> 
>>> Or you could wait for a binary build of lme4 for Mac.
>>> Chris
>>> 
>>> 
>>> 
>>> 
>>> On Thu, Jul 15, 2010 at 11:01 AM, Sladjana <s-lukic at northwestern.edu> wrote:
>>> 
>>>> Hi,
>>>> 
>>>> I am having the same problem with loading lme4 on Mac.
>>>> Can someone guid me through this, I would really appreciate?
>>>> This is the error message I have been getting:
>>>> * installing *source* package ?lme4? ...
>>>> ** libs
>>>> *** arch - i386
>>>> sh: make: command not found
>>>> ERROR: compilation failed for package ?lme4?
>>>> * removing
>>>> ?/Library/Frameworks/R.framework/Versions/2.11/Resources/library/lme4?
>>>> 
>>>> The downloaded packages are in
>>>>        ?/private/var/folders/5i/5ineVodYG08abdx7gchSaE+++TI/-Tmp-
>>>> /Rtmp4Czfel/downloaded_packages?
>>>> 
>>>> Thank you
>>>> Sladjana
>>>> 
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>> 
>>> 
>>>       [[alternative HTML version deleted]]
>>> 
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
>>> 
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bates at stat.wisc.edu  Fri Jul 16 00:13:45 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 15 Jul 2010 17:13:45 -0500
Subject: [R-sig-ME] Failure to load lme4 on Mac
In-Reply-To: <08AD950F-C3DB-4E23-868B-0EFD94833014@anu.edu.au>
References: <C8207D43.4236%mcmahons@si.edu> <4BFB0AE0.3090803@zeno.co.nz>
	<loom.20100715T175631-148@post.gmane.org>
	<AANLkTim4iUokYQZvcL99rhTQkHqIQ5wuESMAGCPu7qGe@mail.gmail.com>
	<AANLkTil72csO0XA3-ZghXw62RUp9gMr-Df1Kx8Bi_Iq2@mail.gmail.com>
	<AANLkTik15uc4QqaIxcwkhAd4HjpzCQ60MuKqiFDJyJnS@mail.gmail.com>
	<08AD950F-C3DB-4E23-868B-0EFD94833014@anu.edu.au>
Message-ID: <AANLkTil7OZ91zRrGf3licxyYQTdgO7QFfLr5CJoyqPc5@mail.gmail.com>

On Thu, Jul 15, 2010 at 4:53 PM, John Maindonald
<john.maindonald at anu.edu.au> wrote:
> This is odd. Around June 27, I installed version lme4_0.999375-34
> from R-forge, using:
>
> install.packages("lme4", repos="http://R-Forge.R-project.org")

I believe it was the absence of an Mac OS X binary package on CRAN,
not on R-forge, that others were commenting on.  If you check on the
main CRAN site

http://cran.r-project.org/web/packages/lme4/

(or on the equivalent page from your local mirror) you will see that
the source and Windows packages are available but not the Mac OS X
package as it reports errors in one of the package tests.

The place where the error is reported is curious because two models
are being compared and they differ only in whether the implicit
intercept or an explicit intercept is used in the formula.  So once
the model matrices and internal representations have been established,
the models should be identical yet somehow they are producing
discernibly different answers.  It is always possible that there is
something happening much earlier in the tests that corrupted memory
but without access to a system displaying the error I am a bit of a
loss as to how we can proceed.

Perhaps Martin or I can sit down with someone who has a Mac laptop
with the necessary build tools at useR!2010 next week and see if we
can find out what is going on.

The report of the test failure is at
http://www.r-project.org/nosvn/R.check/r-release-macosx-ix86/lme4-00check.html

Interestingly Marc Otto was able to build and test the experimental
version, lme4a, on Mac OS X today and it has the same test but did not
trip up on it.

> I checked a moment ago, and this still works:
>
>> install.packages("lme4", repos="http://R-Forge.R-project.org")
> trying URL 'http://R-Forge.R-project.org/bin/macosx/leopard/contrib/2.11/lme4_0.999375-34.tgz'
> Content type 'application/x-gzip' length 1281413 bytes (1.2 Mb)
> opened URL
> ==================================================
> downloaded 1.2 Mb
>
> I have been happily using it.
>
> I do however have another Mac that I am keeping for my sister,
> and on which I have installed R-2.11.1. ?When I try the same command
> there, I get:
>
> "
> Warning: unable to access index for repository index http://R-Forge.R-project.org/bin/macosx/leopard/contrib/2.11
> Warning message:
> In getDependencies(pkgs, available, lib) :
> ?package 'lme4' is not available.
> "
>
> This other R installation is not as fully configured as my main R machine.
>
> For what it is worth (nothing that I can see), here are the two sessionInfo's
>
> Main Machine:
>> sessionInfo()
> R version 2.11.1 (2010-05-31)
> x86_64-apple-darwin9.8.0
>
> locale:
> [1] C
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices datasets ?utils ? ? methods ? base
>
> loaded via a namespace (and not attached):
> [1] Matrix_0.999375-41 grid_2.11.1 ? ? ? ?lattice_0.18-8 ? ? lme4_0.999375-34
> [5] nlme_3.1-96 ? ? ? ?stats4_2.11.1
> Warning message:
> 'DESCRIPTION' file has 'Encoding' field and re-encoding is not possible
>
> Other machine:
>> sessionInfo()
> R version 2.11.1 (2010-05-31)
> x86_64-apple-darwin9.8.0
>
> locale:
> [1] en_AU.UTF-8/en_AU.UTF-8/C/C/en_AU.UTF-8/en_AU.UTF-8
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods
> [7] base
>
> loaded via a namespace (and not attached):
> [1] tools_2.11.1
>
>
> John Maindonald ? ? ? ? ? ? email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473 ? ?fax ?: +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> http://www.maths.anu.edu.au/~johnm
>
> On 16/07/2010, at 6:54 AM, Douglas Bates wrote:
>
>> On Thu, Jul 15, 2010 at 12:31 PM, Daniel Ezra Johnson
>> <danielezrajohnson at gmail.com> wrote:
>>> I would appreciate it if the lme4 developers could state whether they
>>> plan to ensure that a Mac binary be available at any point in the
>>> future (as it does not seem like the problem is going to fix itself).
>>> As we see, it is not trivial to compile the package from source on the
>>> Mac OS.
>>
>> Neither Martin nor I use Mac OS and we can't reproduce the problem on
>> other operating systems so we are kind of stuck.
>>
>> Apparently it is a matter of one of the tests failing but without
>> access to a system that exhibits the failure I wouldn't know where to
>> start debugging. ?Is some kind person using Mac OS were to download
>> and test the package and provide some details about the nature of the
>> failure we might be able to get started.
>>
>>>
>>> Thanks,
>>> Dan
>>>
>>> On Thu, Jul 15, 2010 at 12:58 PM, Christopher Desjardins
>>> <desja004 at umn.edu> wrote:
>>>> Did you see this from Daniel Myall ...
>>>>
>>>> .................
>>>> Hi Sean,
>>>>
>>>> On your Macbook do you have xcode installed? The error "sh: make: command
>>>> not found" indicates that this is not the case.
>>>>
>>>> The best place to get the latest xcode is http://connect.apple.com/ (The
>>>> main Apple site sends you back and forward between two pages for the xcode
>>>> download).
>>>> ................
>>>>
>>>> You need to install Xcode as you don't have the 'make' command.
>>>> http://developer.apple.com/technologies/tools/xcode.html. Unfortunately
>>>> Xcode is about 1 GB in size.
>>>>
>>>> Or you could wait for a binary build of lme4 for Mac.
>>>> Chris
>>>>
>>>>
>>>>
>>>>
>>>> On Thu, Jul 15, 2010 at 11:01 AM, Sladjana <s-lukic at northwestern.edu> wrote:
>>>>
>>>>> Hi,
>>>>>
>>>>> I am having the same problem with loading lme4 on Mac.
>>>>> Can someone guid me through this, I would really appreciate?
>>>>> This is the error message I have been getting:
>>>>> * installing *source* package ?lme4? ...
>>>>> ** libs
>>>>> *** arch - i386
>>>>> sh: make: command not found
>>>>> ERROR: compilation failed for package ?lme4?
>>>>> * removing
>>>>> ?/Library/Frameworks/R.framework/Versions/2.11/Resources/library/lme4?
>>>>>
>>>>> The downloaded packages are in
>>>>> ? ? ? ??/private/var/folders/5i/5ineVodYG08abdx7gchSaE+++TI/-Tmp-
>>>>> /Rtmp4Czfel/downloaded_packages?
>>>>>
>>>>> Thank you
>>>>> Sladjana
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>
>>>> ? ? ? [[alternative HTML version deleted]]
>>>>
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>>
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



From daniel.lists at zeno.co.nz  Fri Jul 16 01:47:13 2010
From: daniel.lists at zeno.co.nz (Daniel Myall)
Date: Fri, 16 Jul 2010 11:47:13 +1200
Subject: [R-sig-ME] Failure to load lme4 on Mac
In-Reply-To: <AANLkTil7OZ91zRrGf3licxyYQTdgO7QFfLr5CJoyqPc5@mail.gmail.com>
References: <C8207D43.4236%mcmahons@si.edu> <4BFB0AE0.3090803@zeno.co.nz>
	<loom.20100715T175631-148@post.gmane.org>
	<AANLkTim4iUokYQZvcL99rhTQkHqIQ5wuESMAGCPu7qGe@mail.gmail.com>
	<AANLkTil72csO0XA3-ZghXw62RUp9gMr-Df1Kx8Bi_Iq2@mail.gmail.com>
	<AANLkTik15uc4QqaIxcwkhAd4HjpzCQ60MuKqiFDJyJnS@mail.gmail.com>
	<08AD950F-C3DB-4E23-868B-0EFD94833014@anu.edu.au>
	<AANLkTil7OZ91zRrGf3licxyYQTdgO7QFfLr5CJoyqPc5@mail.gmail.com>
Message-ID: <4C3F9E01.9050804@zeno.co.nz>

I've attempted to reproduce the error seen on the CRAN on several Mac OS 
X machines and haven't been able to. I'm able to build the CRAN lme4 
version and the svn versions of lme4 and lme4a without issues.

There is obviously an interaction with lme4 and the version of xcode 
installed on the CRAN Mac OS build machine that is resulting in the test 
failure. Is there a page that details the setup of the Mac OS X CRAN 
build machine?

I'm happy to determine what is going on and attempt to resolve this (it 
will mean I don't have to custom compile lme4 for users all the time).

Daniel


On 16/07/10 10:13 AM, Douglas Bates wrote:
>>> Neither Martin nor I use Mac OS and we can't reproduce the problem on
>>> other operating systems so we are kind of stuck.
>>>
>>> Apparently it is a matter of one of the tests failing but without
>>> access to a system that exhibits the failure I wouldn't know where to
>>> start debugging.  Is some kind person using Mac OS were to download
>>> and test the package and provide some details about the nature of the
>>> failure we might be able to get started.
>>>



From bates at stat.wisc.edu  Fri Jul 16 01:54:18 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 15 Jul 2010 18:54:18 -0500
Subject: [R-sig-ME] Failure to load lme4 on Mac
In-Reply-To: <4C3F9E01.9050804@zeno.co.nz>
References: <C8207D43.4236%mcmahons@si.edu> <4BFB0AE0.3090803@zeno.co.nz>
	<loom.20100715T175631-148@post.gmane.org>
	<AANLkTim4iUokYQZvcL99rhTQkHqIQ5wuESMAGCPu7qGe@mail.gmail.com>
	<AANLkTil72csO0XA3-ZghXw62RUp9gMr-Df1Kx8Bi_Iq2@mail.gmail.com>
	<AANLkTik15uc4QqaIxcwkhAd4HjpzCQ60MuKqiFDJyJnS@mail.gmail.com>
	<08AD950F-C3DB-4E23-868B-0EFD94833014@anu.edu.au>
	<AANLkTil7OZ91zRrGf3licxyYQTdgO7QFfLr5CJoyqPc5@mail.gmail.com>
	<4C3F9E01.9050804@zeno.co.nz>
Message-ID: <AANLkTimy0SevCeJ87YhFis_fQg-S1ixMwaZF2Bk2K-Jq@mail.gmail.com>

On Thu, Jul 15, 2010 at 6:47 PM, Daniel Myall <daniel.lists at zeno.co.nz> wrote:
> I've attempted to reproduce the error seen on the CRAN on several Mac OS X
> machines and haven't been able to. I'm able to build the CRAN lme4 version
> and the svn versions of lme4 and lme4a without issues.

> There is obviously an interaction with lme4 and the version of xcode
> installed on the CRAN Mac OS build machine that is resulting in the test
> failure. Is there a page that details the setup of the Mac OS X CRAN build
> machine?

> I'm happy to determine what is going on and attempt to resolve this (it will
> mean I don't have to custom compile lme4 for users all the time).

Thank you Daniel.   Simon Urbanek is the person who coordinates the
Mac OS X builds so it might be best if you could share your
experiences on successful building with him and perhaps determine why
the CRAN builds are encountering the error.  I think it unlikely that
it would be due to an out-of-date Xcode compiler set as usually Simon
is one of the people working with the most recent tools.

I believe that Simon, who I have cc'd on this response, may be on
vacation or otherwise away from his email this week.  I suggest that
you pursue the issue with him off-list when he is available again.

>
> Daniel
>
>
> On 16/07/10 10:13 AM, Douglas Bates wrote:
>>>>
>>>> Neither Martin nor I use Mac OS and we can't reproduce the problem on
>>>> other operating systems so we are kind of stuck.
>>>>
>>>> Apparently it is a matter of one of the tests failing but without
>>>> access to a system that exhibits the failure I wouldn't know where to
>>>> start debugging. ?Is some kind person using Mac OS were to download
>>>> and test the package and provide some details about the nature of the
>>>> failure we might be able to get started.
>>>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From m.fairbrother at bristol.ac.uk  Fri Jul 16 10:34:41 2010
From: m.fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Fri, 16 Jul 2010 10:34:41 +0200
Subject: [R-sig-ME] spatial correlation structures in multilevel models?
In-Reply-To: <005b01cb21ee$c4657e70$4d307b50$@msu.edu>
References: <mailman.5.1278756002.27661.r-sig-mixed-models@r-project.org>
	<9945D065-DFFF-4C54-AF70-C5C29A9B0267@bristol.ac.uk>
	<005b01cb21ee$c4657e70$4d307b50$@msu.edu>
Message-ID: <84DB2959-66D8-4311-9A76-1398B48DD915@bristol.ac.uk>

Thanks to both Ben Bolker and Steven Pierce for responses to this question--their general consensus seems to be that WinBUGS would be an option, but lme4 and nlme won't work.

I also subsequently discovered that MLwiN can fit multilevel models taking into account the location of the higher-level units. It can do that because it can fit "multiple membership" multilevel models (e.g., where a given student is nested within more than one school for a single observation period, and the memberships are weighted in some way which sums to 1). The trick for spatial multilevel models is to treat each lower-level unit as a member of both the higher-level unit in which it is located (first, standard random effect), and of all of its weighted neighbouring units (second random effect).

- Malcolm


Dr Malcolm Fairbrother
Lecturer
School of Geographical Sciences
University of Bristol



On 12 Jul 2010, at 20:19, Steven J. Pierce wrote:

> You might also try doing that model with WinBUGS. There are packages that
> will help you move the data out to WinBUGS from R and then bring the results
> back into R for post processing. 
> 
> Steven J. Pierce, Ph.D. 
> Associate Director 
> Center for Statistical Training & Consulting (CSTAT) 
> Michigan State University 
> E-mail: pierces1 at msu.edu 
> Web: http://www.cstat.msu.edu 
> 
> -----Original Message-----
> From: Malcolm Fairbrother [mailto:m.fairbrother at bristol.ac.uk] 
> Sent: Monday, July 12, 2010 12:00 PM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] spatial correlation structures in multilevel models?
> 
> Dear all,
> 
> I'm interested in fitting a three-level model where the 1st level units are
> individuals, and the 2nd and 3rd levels are (nested) geographical units,
> whose locations (centroids) are known. (The precise location of each
> individual is not known--just the unit to which he/she belongs.) I'd like to
> exploit the fact that the locations are known, since people in
> neighbouring/nearby units should be more similar than people in units that
> are distant from each other. To be specific, I'd like a given unit's random
> intercept to be adjusted according to the data from nearby/neighbouring
> units--especially for instances where I have few observations for a unit but
> lots of observations for neighbouring units.
> 
> My understanding is that lme4 and MCMCglmm cannot do this, in the sense that
> they cannot specify spatial correlation structures. Using these packages, at
> most, some characteristic of a unit's location (e.g., latitude, distance
> from X point) and/or some (weighted) characteristic of a unit's neighbour(s)
> could be included as a fixed effect.
> 
> However, as I understand it, nlme can do this, using the "correlation"
> argument (e.g., "correlation = corExp(form = ~ ...").
> 
> Is this correct? Will nlme adjust the random intercepts in such a way? And
> would it be a problem that it's the higher-level units, not the lowest-level
> units, for which I know the locations?
> 
> If I'm being over-ambitious/demanding here, no worries at all--I'm just
> curious whether this is possible. I don't have the data yet.
> 
> Many thanks,
> Malcolm
> 
> 
> Dr Malcolm Fairbrother
> Lecturer
> School of Geographical Sciences
> University of Bristol
> 
> 
> 



From jan.hanspach at ufz.de  Fri Jul 16 11:14:52 2010
From: jan.hanspach at ufz.de (Jan Hanspach)
Date: Fri, 16 Jul 2010 11:14:52 +0200
Subject: [R-sig-ME] spatial correlation structures in multilevel models?
In-Reply-To: <84DB2959-66D8-4311-9A76-1398B48DD915@bristol.ac.uk>
References: <mailman.5.1278756002.27661.r-sig-mixed-models@r-project.org>
	<9945D065-DFFF-4C54-AF70-C5C29A9B0267@bristol.ac.uk>
	<005b01cb21ee$c4657e70$4d307b50$@msu.edu>
	<84DB2959-66D8-4311-9A76-1398B48DD915@bristol.ac.uk>
Message-ID: <4C40230C.8030005@ufz.de>

Hi Malcolm,
I just missed the argument why defining a correlation structure in nlme 
would not be an option? Could you expand on this?
Thanks
Jan

Malcolm Fairbrother schrieb:
> Thanks to both Ben Bolker and Steven Pierce for responses to this question--their general consensus seems to be that WinBUGS would be an option, but lme4 and nlme won't work.
>
> I also subsequently discovered that MLwiN can fit multilevel models taking into account the location of the higher-level units. It can do that because it can fit "multiple membership" multilevel models (e.g., where a given student is nested within more than one school for a single observation period, and the memberships are weighted in some way which sums to 1). The trick for spatial multilevel models is to treat each lower-level unit as a member of both the higher-level unit in which it is located (first, standard random effect), and of all of its weighted neighbouring units (second random effect).
>
> - Malcolm
>
>
> Dr Malcolm Fairbrother
> Lecturer
> School of Geographical Sciences
> University of Bristol
>
>
>
> On 12 Jul 2010, at 20:19, Steven J. Pierce wrote:
>
>   
>> You might also try doing that model with WinBUGS. There are packages that
>> will help you move the data out to WinBUGS from R and then bring the results
>> back into R for post processing. 
>>
>> Steven J. Pierce, Ph.D. 
>> Associate Director 
>> Center for Statistical Training & Consulting (CSTAT) 
>> Michigan State University 
>> E-mail: pierces1 at msu.edu 
>> Web: http://www.cstat.msu.edu 
>>
>> -----Original Message-----
>> From: Malcolm Fairbrother [mailto:m.fairbrother at bristol.ac.uk] 
>> Sent: Monday, July 12, 2010 12:00 PM
>> To: r-sig-mixed-models at r-project.org
>> Subject: [R-sig-ME] spatial correlation structures in multilevel models?
>>
>> Dear all,
>>
>> I'm interested in fitting a three-level model where the 1st level units are
>> individuals, and the 2nd and 3rd levels are (nested) geographical units,
>> whose locations (centroids) are known. (The precise location of each
>> individual is not known--just the unit to which he/she belongs.) I'd like to
>> exploit the fact that the locations are known, since people in
>> neighbouring/nearby units should be more similar than people in units that
>> are distant from each other. To be specific, I'd like a given unit's random
>> intercept to be adjusted according to the data from nearby/neighbouring
>> units--especially for instances where I have few observations for a unit but
>> lots of observations for neighbouring units.
>>
>> My understanding is that lme4 and MCMCglmm cannot do this, in the sense that
>> they cannot specify spatial correlation structures. Using these packages, at
>> most, some characteristic of a unit's location (e.g., latitude, distance
>> from X point) and/or some (weighted) characteristic of a unit's neighbour(s)
>> could be included as a fixed effect.
>>
>> However, as I understand it, nlme can do this, using the "correlation"
>> argument (e.g., "correlation = corExp(form = ~ ...").
>>
>> Is this correct? Will nlme adjust the random intercepts in such a way? And
>> would it be a problem that it's the higher-level units, not the lowest-level
>> units, for which I know the locations?
>>
>> If I'm being over-ambitious/demanding here, no worries at all--I'm just
>> curious whether this is possible. I don't have the data yet.
>>
>> Many thanks,
>> Malcolm
>>
>>
>> Dr Malcolm Fairbrother
>> Lecturer
>> School of Geographical Sciences
>> University of Bristol
>>
>>
>>
>>     
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From simon.urbanek at r-project.org  Fri Jul 16 14:48:31 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 16 Jul 2010 08:48:31 -0400
Subject: [R-sig-ME] Failure to load lme4 on Mac
In-Reply-To: <AANLkTimy0SevCeJ87YhFis_fQg-S1ixMwaZF2Bk2K-Jq@mail.gmail.com>
References: <C8207D43.4236%mcmahons@si.edu> <4BFB0AE0.3090803@zeno.co.nz>
	<loom.20100715T175631-148@post.gmane.org>
	<AANLkTim4iUokYQZvcL99rhTQkHqIQ5wuESMAGCPu7qGe@mail.gmail.com>
	<AANLkTil72csO0XA3-ZghXw62RUp9gMr-Df1Kx8Bi_Iq2@mail.gmail.com>
	<AANLkTik15uc4QqaIxcwkhAd4HjpzCQ60MuKqiFDJyJnS@mail.gmail.com>
	<08AD950F-C3DB-4E23-868B-0EFD94833014@anu.edu.au>
	<AANLkTil7OZ91zRrGf3licxyYQTdgO7QFfLr5CJoyqPc5@mail.gmail.com>
	<4C3F9E01.9050804@zeno.co.nz>
	<AANLkTimy0SevCeJ87YhFis_fQg-S1ixMwaZF2Bk2K-Jq@mail.gmail.com>
Message-ID: <E1F79CC7-DB81-4916-B847-10C6C02DF2A8@r-project.org>


On Jul 15, 2010, at 7:54 PM, Douglas Bates wrote:

> On Thu, Jul 15, 2010 at 6:47 PM, Daniel Myall <daniel.lists at zeno.co.nz> wrote:
>> I've attempted to reproduce the error seen on the CRAN on several Mac OS X
>> machines and haven't been able to. I'm able to build the CRAN lme4 version
>> and the svn versions of lme4 and lme4a without issues.
> 
>> There is obviously an interaction with lme4 and the version of xcode
>> installed on the CRAN Mac OS build machine that is resulting in the test
>> failure. Is there a page that details the setup of the Mac OS X CRAN build
>> machine?
> 
>> I'm happy to determine what is going on and attempt to resolve this (it will
>> mean I don't have to custom compile lme4 for users all the time).
> 
> Thank you Daniel.   Simon Urbanek is the person who coordinates the
> Mac OS X builds so it might be best if you could share your
> experiences on successful building with him and perhaps determine why
> the CRAN builds are encountering the error.  I think it unlikely that
> it would be due to an out-of-date Xcode compiler set as usually Simon
> is one of the people working with the most recent tools.
> 

The CRAN machine is Mac OS X 10.5.8 with Xcode 3.1.4 (using gcc-4.2) which is indeed the latest Xcode version for Leopard. If you have any hints as of why lme4 may be failing they are highly appreciated.

Thanks,
Simon



> I believe that Simon, who I have cc'd on this response, may be on
> vacation or otherwise away from his email this week.  I suggest that
> you pursue the issue with him off-list when he is available again.
> 
>> 
>> Daniel
>> 
>> 
>> On 16/07/10 10:13 AM, Douglas Bates wrote:
>>>>> 
>>>>> Neither Martin nor I use Mac OS and we can't reproduce the problem on
>>>>> other operating systems so we are kind of stuck.
>>>>> 
>>>>> Apparently it is a matter of one of the tests failing but without
>>>>> access to a system that exhibits the failure I wouldn't know where to
>>>>> start debugging.  Is some kind person using Mac OS were to download
>>>>> and test the package and provide some details about the nature of the
>>>>> failure we might be able to get started.
>>>>> 
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> 



From tim.carnus at gmail.com  Thu Jul 15 19:58:44 2010
From: tim.carnus at gmail.com (Tim Carnus)
Date: Thu, 15 Jul 2010 18:58:44 +0100
Subject: [R-sig-ME] Failure to load lme4 on Mac
In-Reply-To: <AANLkTil72csO0XA3-ZghXw62RUp9gMr-Df1Kx8Bi_Iq2@mail.gmail.com>
References: <C8207D43.4236%mcmahons@si.edu> <4BFB0AE0.3090803@zeno.co.nz>
	<loom.20100715T175631-148@post.gmane.org>
	<AANLkTim4iUokYQZvcL99rhTQkHqIQ5wuESMAGCPu7qGe@mail.gmail.com>
	<AANLkTil72csO0XA3-ZghXw62RUp9gMr-Df1Kx8Bi_Iq2@mail.gmail.com>
Message-ID: <1279216724.16677.17.camel@tim-laptop>

Hi,

Just to note that I have had no issues compiling lme4 from source on
three separate macs (imac and emac running tiger and power book running
snow leopard). I did have to install xcode on all 3.

Best regards,

Tim

On Thu, 2010-07-15 at 13:31 -0400, Daniel Ezra Johnson wrote:
> I would appreciate it if the lme4 developers could state whether they
> plan to ensure that a Mac binary be available at any point in the
> future (as it does not seem like the problem is going to fix itself).
> As we see, it is not trivial to compile the package from source on the
> Mac OS.
> 
> Thanks,
> Dan
> 
> On Thu, Jul 15, 2010 at 12:58 PM, Christopher Desjardins
> <desja004 at umn.edu> wrote:
> > Did you see this from Daniel Myall ...
> >
> > .................
> > Hi Sean,
> >
> > On your Macbook do you have xcode installed? The error "sh: make: command
> > not found" indicates that this is not the case.
> >
> > The best place to get the latest xcode is http://connect.apple.com/ (The
> > main Apple site sends you back and forward between two pages for the xcode
> > download).
> > ................
> >
> > You need to install Xcode as you don't have the 'make' command.
> > http://developer.apple.com/technologies/tools/xcode.html. Unfortunately
> > Xcode is about 1 GB in size.
> >
> > Or you could wait for a binary build of lme4 for Mac.
> > Chris
> >
> >
> >
> >
> > On Thu, Jul 15, 2010 at 11:01 AM, Sladjana <s-lukic at northwestern.edu> wrote:
> >
> >> Hi,
> >>
> >> I am having the same problem with loading lme4 on Mac.
> >> Can someone guid me through this, I would really appreciate?
> >> This is the error message I have been getting:
> >> * installing *source* package ?lme4? ...
> >> ** libs
> >> *** arch - i386
> >> sh: make: command not found
> >> ERROR: compilation failed for package ?lme4?
> >> * removing
> >> ?/Library/Frameworks/R.framework/Versions/2.11/Resources/library/lme4?
> >>
> >> The downloaded packages are in
> >>         ?/private/var/folders/5i/5ineVodYG08abdx7gchSaE+++TI/-Tmp-
> >> /Rtmp4Czfel/downloaded_packages?
> >>
> >> Thank you
> >> Sladjana
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
> >        [[alternative HTML version deleted]]
> >
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From ken.knoblauch at inserm.fr  Fri Jul 16 15:51:23 2010
From: ken.knoblauch at inserm.fr (Ken Knoblauch)
Date: Fri, 16 Jul 2010 13:51:23 +0000 (UTC)
Subject: [R-sig-ME] Failure to load lme4 on Mac
References: <C8207D43.4236%mcmahons@si.edu> <4BFB0AE0.3090803@zeno.co.nz>
	<loom.20100715T175631-148@post.gmane.org>
	<AANLkTim4iUokYQZvcL99rhTQkHqIQ5wuESMAGCPu7qGe@mail.gmail.com>
	<AANLkTil72csO0XA3-ZghXw62RUp9gMr-Df1Kx8Bi_Iq2@mail.gmail.com>
	<AANLkTik15uc4QqaIxcwkhAd4HjpzCQ60MuKqiFDJyJnS@mail.gmail.com>
	<08AD950F-C3DB-4E23-868B-0EFD94833014@anu.edu.au>
	<AANLkTil7OZ91zRrGf3licxyYQTdgO7QFfLr5CJoyqPc5@mail.gmail.com>
	<4C3F9E01.9050804@zeno.co.nz>
	<AANLkTimy0SevCeJ87YhFis_fQg-S1ixMwaZF2Bk2K-Jq@mail.gmail.com>
	<E1F79CC7-DB81-4916-B847-10C6C02DF2A8@r-project.org>
Message-ID: <loom.20100716T153900-860@post.gmane.org>

Simon Urbanek <simon.urbanek at ...> writes: 
> On Jul 15, 2010, at 7:54 PM, Douglas Bates wrote:
> 
> > On Thu, Jul 15, 2010 at 6:47 PM, Daniel Myall
> <daniel.lists at ...> wrote:
> >> I've attempted to reproduce the error seen on the CRAN on several 
Mac OS X
> >> machines and haven't been able to. I'm able to build the CRAN 
lme4 version
> >> and the svn versions of lme4 and lme4a without issues.
> > 
> >> There is obviously an interaction with lme4 and the version of 
xcode
> >> installed on the CRAN Mac OS build machine that is resulting in the 
test
> >> failure. Is there a page that details the setup of the Mac OS X CRAN 
build
> >> machine?
> > 
> >> I'm happy to determine what is going on and attempt to resolve this 
(it will
> >> mean I don't have to custom compile lme4 for users all the time).
> > 
> > Thank you Daniel.   Simon Urbanek is the person who coordinates the
> > Mac OS X builds so it might be best if you could share your
> > experiences on successful building with him and perhaps determine 
why
> > the CRAN builds are encountering the error.  I think it unlikely that
> > it would be due to an out-of-date Xcode compiler set as usually 
Simon
> > is one of the people working with the most recent tools.
> > 
> 
> The CRAN machine is Mac OS X 10.5.8 with Xcode 3.1.4 (using 
gcc-4.2) 
which is 
indeed the latest 
Xcode version
> for Leopard. If you have any hints as of why lme4 may be failing they 
are 
highly appreciated.
> 
> Thanks,
> Simon
> 
> > I believe that Simon, who I have cc'd on this response, may be on
> > vacation or otherwise away from his email this week.  I suggest that
> > you pursue the issue with him off-list when he is available again.
> > 
> >> 
> >> Daniel
> >> 
> >> 
> >> On 16/07/10 10:13 AM, Douglas Bates wrote:
> >>>>> 
> >>>>> Neither Martin nor I use Mac OS and we can't reproduce the 
problem on
> >>>>> other operating systems so we are kind of stuck.
> >>>>> 
> >>>>> Apparently it is a matter of one of the tests failing but without
> >>>>> access to a system that exhibits the failure I wouldn't know 
where to
> >>>>> start debugging.  Is some kind person using Mac OS were to 
download
> >>>>> and test the package and provide some details about the 
nature of the
> >>>>> failure we might be able to get started.
> >>>>> 
Just having updated Xcode to 3.1.4 and fixed the versions of gcc, etc. so
that I'm able to install latest version of Rcpp and lme4a without any 
problems,
I'll take a bite, but maybe I'm just repeating what you have already seen.
I can install lme4 from source from Rforge with no problem.
Just for starters here is my sessionInfo
R version 2.11.1 Patched (2010-07-15 r52539) 
i386-apple-darwin9.8.0 

locale:
[1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods  
[7] base     

other attached packages:
[1] lme4_0.999375-34   Matrix_0.999375-41 lattice_0.18-8    

loaded via a namespace (and not attached):
[1] grid_2.11.1   nlme_3.1-96   stats4_2.11.1

I dowloaded lme4_0.999375-34.tar.gz from CRAN and ran
R CMD check on it and came up with
* checking tests ...
  Running ?extras.R?
  Running ?lmer-1.R?
 ERROR
Running the tests in 'tests/lmer-1.R' failed.
Last 13 lines of output:
  +                  x3=rnorm(20,1))
  > m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
  > m1 <- lmer(y ~ x1 + x2|ff  , data = D)
  > m2 <- lmer(y ~ x1 + (x2|ff), data = D)
  > m3 <- lmer(y ~ (x2|ff) + x1, data = D)
  > stopifnot(identical(ranef(m0), ranef(m1)),
  +     identical(ranef(m2), ranef(m3)),
  +    inherits(tryCatch(lmer(y ~ x2|ff + x1, data = D), error = function(e)e),
  +                    "error"))
  Error: identical(ranef(m0), ranef(m1)) is not TRUE
  In addition: Warning message:
  In Ops.factor(ff, x1) : + not meaningful for factors
  Execution halted
which I think is the reported problem.

I went into the file lmer-1.R which seems to be where this is
coming from and sourced the lines indicated above and get

> D <-  data.frame(y= rnorm(20,10), ff = gl(4,5),
+                  x1=rnorm(20,3), x2=rnorm(20,7),
+                  x3=rnorm(20,1))
> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
> m1 <- lmer(y ~ x1 + x2|ff  , data = D)
> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
> stopifnot(identical(ranef(m0), ranef(m1)),
+           identical(ranef(m2), ranef(m3)),
+           inherits(tryCatch(lmer(y ~ x2|ff + x1, data = D), error = 
function(e)e),
+                    "error"))
Error: identical(ranef(m2), ranef(m3)) is not TRUE
In addition: Warning message:
In Ops.factor(ff, x1) : + not meaningful for factors
> identical(ranef(m0), ranef(m1))
[1] TRUE
> identical(ranef(m2), ranef(m3))
[1] FALSE

so it happens in an R session as well.
Checking the ranef's
> ranef(m2)
$ff
  (Intercept)          x2
1  -1.4142222  0.15618464
2   0.4787662 -0.05287424
3   0.3193410 -0.03526755
4   1.7224362 -0.19022335

> ranef(m3)
$ff
  (Intercept)          x2
1  -1.4141930  0.15618142
2   0.4787944 -0.05287736
3   0.3193632 -0.03527000
4   1.7224652 -0.19022656

They do indeed differ.  I'm on a 32 bit machine, could this be
a 32/64 bit difference or something at the level of BLAS/ATLAS level?
That's out of my league.  If I have time, I'll try it on a 64 bit Mac, but I'm
not likely to get back to that before about the beginning of August.


Hope that this is useful.

Ken

-- 
Ken Knoblauch
Inserm U846
Stem-cell and Brain Research Institute
Department of Integrative Neurosciences
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.sbri.fr/members/kenneth-knoblauch.html



From rebecca.ross at plants.ox.ac.uk  Fri Jul 16 16:02:56 2010
From: rebecca.ross at plants.ox.ac.uk (Rebecca Ross)
Date: Fri, 16 Jul 2010 15:02:56 +0100
Subject: [R-sig-ME] Raw and orthogonal polynomials differences in results
Message-ID: <756B64E07365AF43BE945A734A85E44544616944F5@EXMBX03.ad.oak.ox.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100716/2283af0a/attachment.pl>

From maechler at stat.math.ethz.ch  Fri Jul 16 18:05:39 2010
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 16 Jul 2010 18:05:39 +0200
Subject: [R-sig-ME] Failure to load lme4 on Mac
In-Reply-To: <loom.20100716T153900-860@post.gmane.org>
References: <C8207D43.4236%mcmahons@si.edu> <4BFB0AE0.3090803@zeno.co.nz>
	<loom.20100715T175631-148@post.gmane.org>
	<AANLkTim4iUokYQZvcL99rhTQkHqIQ5wuESMAGCPu7qGe@mail.gmail.com>
	<AANLkTil72csO0XA3-ZghXw62RUp9gMr-Df1Kx8Bi_Iq2@mail.gmail.com>
	<AANLkTik15uc4QqaIxcwkhAd4HjpzCQ60MuKqiFDJyJnS@mail.gmail.com>
	<08AD950F-C3DB-4E23-868B-0EFD94833014@anu.edu.au>
	<AANLkTil7OZ91zRrGf3licxyYQTdgO7QFfLr5CJoyqPc5@mail.gmail.com>
	<4C3F9E01.9050804@zeno.co.nz>
	<AANLkTimy0SevCeJ87YhFis_fQg-S1ixMwaZF2Bk2K-Jq@mail.gmail.com>
	<E1F79CC7-DB81-4916-B847-10C6C02DF2A8@r-project.org>
	<loom.20100716T153900-860@post.gmane.org>
Message-ID: <19520.33619.18880.815822@lynne.math.ethz.ch>

>>>>> "KK" == Ken Knoblauch <ken.knoblauch at inserm.fr>
>>>>>     on Fri, 16 Jul 2010 13:51:23 +0000 (UTC) writes:

   [...........]

    >> The CRAN machine is Mac OS X 10.5.8 with Xcode 3.1.4
    >> (using gcc-4.2) which is indeed the latest Xcode version
    >> for Leopard. If you have any hints as of why lme4 may be
    >> failing they are highly appreciated.

    >> Thanks,
    >> Simon

    [.......................]

    KK> Just having updated Xcode to 3.1.4 and fixed the versions of gcc, etc. so
    KK> that I'm able to install latest version of Rcpp and lme4a without any 
    KK> problems,
    KK> I'll take a bite, but maybe I'm just repeating what you have already seen.
    KK> I can install lme4 from source from Rforge with no problem.
    KK> Just for starters here is my sessionInfo
    KK> R version 2.11.1 Patched (2010-07-15 r52539) 
    KK> i386-apple-darwin9.8.0 

    KK> locale:
    KK> [1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8

    KK> attached base packages:
    KK> [1] stats     graphics  grDevices utils     datasets  methods  
    KK> [7] base     

    KK> other attached packages:
    KK> [1] lme4_0.999375-34   Matrix_0.999375-41 lattice_0.18-8    

    KK> loaded via a namespace (and not attached):
    KK> [1] grid_2.11.1   nlme_3.1-96   stats4_2.11.1

    KK> I dowloaded lme4_0.999375-34.tar.gz from CRAN and ran
    KK> R CMD check on it and came up with
    KK> * checking tests ...
    KK> Running ?extras.R?
    KK> Running ?lmer-1.R?
    KK> ERROR
    KK> Running the tests in 'tests/lmer-1.R' failed.
    KK> Last 13 lines of output:
    KK> +                  x3=rnorm(20,1))
    >> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
    >> m1 <- lmer(y ~ x1 + x2|ff  , data = D)
    >> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
    >> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
    >> stopifnot(identical(ranef(m0), ranef(m1)),
    KK> +     identical(ranef(m2), ranef(m3)),
    KK> +    inherits(tryCatch(lmer(y ~ x2|ff + x1, data = D), error = function(e)e),
    KK> +                    "error"))
    KK> Error: identical(ranef(m0), ranef(m1)) is not TRUE
    KK> In addition: Warning message:
    KK> In Ops.factor(ff, x1) : + not meaningful for factors
    KK> Execution halted
    KK> which I think is the reported problem.

Yes, one of the typical two ones.

The other one that Mac useRs, e.g.,  Kent Holsinger, in a private
communication, have also encountered, is the even simpler case
{earlier in lmer-1.R, so this means it did not trigger for
*you*}:

y <- (1:20)*pi
x <- (1:20)^2
group <- gl(2,10)

stopifnot(require(lme4))
sessionInfo()

M2. <- lmer (y ~ 1 + x + (1 + x | group))
M2  <- lmer (y ~     x + (    x | group))

## should be identical (and is .. well, not on all versions on Mac OSX):
identical(ranef(M2), ranef(M2.))
## not  TRUE on some  Mac : OSX : R  combinations


How can the linear algebra computations that start from
identical numbers give different results *sometimes* on Mac OSX?
Could it be that it uses some Mac specific BLAS/LAPACK
optimizations which only happen *sometimes* ?

    KK> I went into the file lmer-1.R which seems to be where this is
    KK> coming from

[correct]

    KK> and sourced the lines indicated above and get

    >> D <-  data.frame(y= rnorm(20,10), ff = gl(4,5),
    KK> +                  x1=rnorm(20,3), x2=rnorm(20,7),
    KK> +                  x3=rnorm(20,1))
    >> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
    >> m1 <- lmer(y ~ x1 + x2|ff  , data = D)
    >> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
    >> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
    >> stopifnot(identical(ranef(m0), ranef(m1)),
    KK> +           identical(ranef(m2), ranef(m3)),
    KK> +           inherits(tryCatch(lmer(y ~ x2|ff + x1, data = D), error = 
    KK> function(e)e),
    KK> +                    "error"))
    KK> Error: identical(ranef(m2), ranef(m3)) is not TRUE
    KK> In addition: Warning message:
    KK> In Ops.factor(ff, x1) : + not meaningful for factors
    >> identical(ranef(m0), ranef(m1))
    KK> [1] TRUE

    >> identical(ranef(m2), ranef(m3))
    KK> [1] FALSE

    KK> so it happens in an R session as well.

yes. 
So, 
 m2 <- lmer(y ~ x1 + (x2|ff), data = D)
 m3 <- lmer(y ~ (x2|ff) + x1, data = D)

give differing results? How come?
It seems as curious as the above simpler case,
as really the initial starting matrices must be identical,
unless the mac CPU does some things slightly differently
depending on the exact machine configuration ???

To me that could mean that even two identical R statements
could give very slightly differing results, depending on the
exact circumstance in which they are called {and of course I'm
not talking about things that depend on options() or global
variables or different search(), ...}

??

    KK> Checking the ranef's
    >> ranef(m2)
    KK> $ff
    KK> (Intercept)          x2
    KK> 1  -1.4142222  0.15618464
    KK> 2   0.4787662 -0.05287424
    KK> 3   0.3193410 -0.03526755
    KK> 4   1.7224362 -0.19022335

    >> ranef(m3)
    KK> $ff
    KK> (Intercept)          x2
    KK> 1  -1.4141930  0.15618142
    KK> 2   0.4787944 -0.05287736
    KK> 3   0.3193632 -0.03527000
    KK> 4   1.7224652 -0.19022656

    KK> They do indeed differ.  I'm on a 32 bit machine, could this be
    KK> a 32/64 bit difference or something at the level of BLAS/ATLAS level?
    KK> That's out of my league.  If I have time, I'll try it on a 64 bit Mac, but I'm
    KK> not likely to get back to that before about the beginning of August.


    KK> Hope that this is useful.

    KK> Ken

    KK> -- 
    KK> Ken Knoblauch
    KK> Inserm U846
    KK> Stem-cell and Brain Research Institute
    KK> Department of Integrative Neurosciences
    KK> 18 avenue du Doyen L?pine
    KK> 69500 Bron
    KK> France
    KK> tel: +33 (0)4 72 91 34 77
    KK> fax: +33 (0)4 72 91 34 61
    KK> portable: +33 (0)6 84 10 64 10
    KK> http://www.sbri.fr/members/kenneth-knoblauch.html

    KK> _______________________________________________
    KK> R-sig-mixed-models at r-project.org mailing list
    KK> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From smckinney at bccrc.ca  Fri Jul 16 21:04:09 2010
From: smckinney at bccrc.ca (Steven McKinney)
Date: Fri, 16 Jul 2010 12:04:09 -0700
Subject: [R-sig-ME] Raw and orthogonal polynomials differences in results
In-Reply-To: <21911_1279288991_1279288991_756B64E07365AF43BE945A734A85E44544616944F5@EXMBX03.ad.oak.ox.ac.uk>
References: <21911_1279288991_1279288991_756B64E07365AF43BE945A734A85E44544616944F5@EXMBX03.ad.oak.ox.ac.uk>
Message-ID: <DCE81E14EB74504B971DAD4D2DB0356B06160D8545@crcmail4.BCCRC.CA>

Hi Rebecca

The high correlation between the linear and
quadratic terms in the raw polynomial
form (-0.993) is a warning sign that
raw polynomial fits to this data will be
numerically challenging (due to numerical
precision issues involved in inverting 
matrices with nearly linearly-dependent
columns etc.).

In such situations orthogonal polynomial
fits are essential.  (Notice the lack of correlation
of the orthogonal polynomial regressors - all
close to zero.)  Really, orthogonal polynomial
fits are always the best approach.  When
"raw" polynomial predictor variables show
low correlation, the model may be easier to
interpret or explain in some circumstances, but the 
polynomial fit should always be checked to confirm that
there are no numerical stability issues involved
with the model fit estimates. 

The polynomial fit is indeed the one to interpret,
and it shows no evidence of a quadratic component.
You report that no quadratic component appears
in plots of the data, so that concurs with the
(numerically more stable) orthogonal polynomial
fit results.

Mean-centred variables often perform better
in "raw" polynomial fits, so if you form a new 
variable

F2dat$Av_alt_m <- F2dat$Av_alt - mean(F2dat$Av_alt, na.rm = TRUE)
then a fit of 

total_RO ~ Av_alt_m + I(Av_alt_m^2) + (1 | Block) + (1 | fam:Type)

may show lower correlation between the linear and quadratic
predictors.

The orthogonal polynomial fit is the safest fit with
which to statistically assess the functional form of 
the association of the response with the predictor.
Other basis spline fits and smoothers are also useful.

Steven McKinney, Ph.D.

Statistician
Molecular Oncology and Breast Cancer Program
British Columbia Cancer Research Centre

email: smckinney +at+ bccrc +dot+ ca

tel: 604-675-8000 x7561

BCCRC
Molecular Oncology
675 West 10th Ave, Floor 4
Vancouver B.C.
V5Z 1L3
Canada



> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-
> models-bounces at r-project.org] On Behalf Of Rebecca Ross
> Sent: July-16-10 7:03 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Raw and orthogonal polynomials differences in
> results
> 
> Dear List,
> 
> I apologise if this has been covered before, but I haven't been able to
> find an exact answer to my question and I am hoping someone can help or
> advise. I am fitting an lmer model and would like to know if there is
> evidence for curvature or not in the regression, and if there is
> curvature, to plot the predictions and see what it looks like. I had
> been using orthogonal polynomials (poly default), but I have realised
> that I get vastly different results, in terms of significance,
> depending on whether I use orthogonals or raw. I have the impression
> from reading about this that orthogonal ones are better for my case (ie
> model selection, but not to extract the equation), but I am not sure if
> that is correct, and if it means I can follow the orthogonal or the raw
> result. Model formula and model summaries are below for raw and
> orthogonal polynomals. The data 'looks' like there should be a linear
> but not quadratic effect.
> Thank you in advance,
> 
> Rebecca Ross,
> Dphil Candidate,
> Oxford University
> 
> > summary(avalt2POLY)
> Linear mixed model fit by REML
> Formula: total_RO ~ poly(Av_alt, 2) + (1 | Block) + (1 | fam:Type)
>    Data: F2dat
>   AIC  BIC logLik deviance REMLdev
>  2557 2580  -1273     2562    2545
> Random effects:
>  Groups   Name        Variance Std.Dev.
>  fam:Type (Intercept)  28.621   5.3499
>  Block    (Intercept)  14.759   3.8417
>  Residual             111.788  10.5730
> Number of obs: 329, groups: fam:Type, 194; Block, 5 Fixed effects:
>                  Estimate Std. Error t value
> (Intercept)        23.281      1.856  12.541
> poly(Av_alt, 2)1  -82.333     12.776  -6.444
> poly(Av_alt, 2)2   -3.875     12.781  -0.303
> Correlation of Fixed Effects:
>             (Intr) p(A_,2)1
> ply(Av_,2)1  0.000
> ply(Av_,2)2  0.000 -0.002
> > summary(avalt2RAW)
> Linear mixed model fit by REML
> Formula: total_RO ~ Av_alt + I(Av_alt^2) + (1 | Block) + (1 | fam:Type)
>    Data: F2dat
>   AIC  BIC logLik deviance REMLdev
>  2605 2627  -1296     2562    2593
> Random effects:
>  Groups   Name        Variance Std.Dev.
>  fam:Type (Intercept)  28.621   5.3499
>  Block    (Intercept)  14.759   3.8417
>  Residual             111.788  10.5730
> Number of obs: 329, groups: fam:Type, 194; Block, 5 Fixed effects:
>               Estimate Std. Error t value
> (Intercept)  3.709e+01  1.024e+01   3.623
> Av_alt      -6.827e-03  1.444e-02  -0.473
> I(Av_alt^2) -1.479e-06  4.877e-06  -0.303 Correlation of Fixed Effects:
>             (Intr) Av_alt
> Av_alt      -0.974
> I(Av_alt^2)  0.950 -0.993
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From schad at izw-berlin.de  Fri Jul 16 20:53:01 2010
From: schad at izw-berlin.de (Schad, Julia)
Date: Fri, 16 Jul 2010 20:53:01 +0200
Subject: [R-sig-ME] missing p-value when using lmer-function of the lme4
	package by overdispersed count data
Message-ID: <BDFDBC3063FF10438EA523A9AC56F1A30136F5BB@izw-mail-1.izw-berlin.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100716/9f3388ae/attachment.pl>

From daniel.lists at zeno.co.nz  Sat Jul 17 00:05:21 2010
From: daniel.lists at zeno.co.nz (Daniel Myall)
Date: Sat, 17 Jul 2010 10:05:21 +1200
Subject: [R-sig-ME] Failure to load lme4 on Mac
In-Reply-To: <E1F79CC7-DB81-4916-B847-10C6C02DF2A8@r-project.org>
References: <C8207D43.4236%mcmahons@si.edu> <4BFB0AE0.3090803@zeno.co.nz>
	<loom.20100715T175631-148@post.gmane.org>
	<AANLkTim4iUokYQZvcL99rhTQkHqIQ5wuESMAGCPu7qGe@mail.gmail.com>
	<AANLkTil72csO0XA3-ZghXw62RUp9gMr-Df1Kx8Bi_Iq2@mail.gmail.com>
	<AANLkTik15uc4QqaIxcwkhAd4HjpzCQ60MuKqiFDJyJnS@mail.gmail.com>
	<08AD950F-C3DB-4E23-868B-0EFD94833014@anu.edu.au>
	<AANLkTil7OZ91zRrGf3licxyYQTdgO7QFfLr5CJoyqPc5@mail.gmail.com>
	<4C3F9E01.9050804@zeno.co.nz>
	<AANLkTimy0SevCeJ87YhFis_fQg-S1ixMwaZF2Bk2K-Jq@mail.gmail.com>
	<E1F79CC7-DB81-4916-B847-10C6C02DF2A8@r-project.org>
Message-ID: <4C40D7A1.8030608@zeno.co.nz>

Hi Simon,

The machine I'm primarily testing on has Mac OS X 10.6.4 with Xcode 
3.2.2 (using gcc-4.2.1). The log from R CMD check is included below. I 
don't have any Leopard installs around anymore, although I am setting up 
a virtual machine with Mac OS X 10.5.8 and Xcode 3.1.4 to hopefully 
reproduce the bug.

If there is a bug in Mac OS X 10.5.8 or Xcode 3.1.4 resulting in the two 
errors in the tests that have so far been seen,  I am curious as to why 
it is only being exhibited with lme4. Once the VM has installed I'll 
play around with compile-time optimisations of lme4 to see if they are 
exposing the bug.

* using log directory '/Users/daniel/working/R-packages/lme4.Rcheck'
* using R version 2.11.1 (2010-05-31)
* using session charset: UTF-8
* checking for file 'lme4/DESCRIPTION' ... OK
* this is package 'lme4' version '0.999375-34'
* checking package name space information ... OK
* checking package dependencies ... OK
* checking if this is a source package ... OK
* checking for executable files ... OK
* checking whether package 'lme4' can be installed ... OK
* checking package directory ... OK
* checking for portable file names ... OK
* checking for sufficient/correct file permissions ... OK
* checking DESCRIPTION meta-information ... OK
* checking top-level files ... OK
* checking index information ... OK
* checking package subdirectories ... OK
* checking R files for non-ASCII characters ... OK
* checking R files for syntax errors ... OK
* checking whether the package can be loaded ... OK
* checking whether the package can be loaded with stated dependencies ... OK
* checking whether the package can be unloaded cleanly ... OK
* checking whether the name space can be loaded with stated dependencies 
... OK
* checking whether the name space can be unloaded cleanly ... OK
* checking for unstated dependencies in R code ... OK
* checking S3 generic/method consistency ... OK
* checking replacement functions ... OK
* checking foreign function calls ... OK
* checking R code for possible problems ... OK
* checking Rd files ... OK
* checking Rd metadata ... OK
* checking Rd cross-references ... OK
* checking for missing documentation entries ... OK
* checking for code/documentation mismatches ... OK
* checking Rd \usage sections ... OK
* checking Rd contents ... OK
* checking data for non-ASCII characters ... OK
* checking line endings in C/C++/Fortran sources/headers ... OK
* checking line endings in Makefiles ... OK
* checking for portable compilation flags in Makevars ... OK
* checking for portable use of $BLAS_LIBS ... OK
* checking examples ... OK
* checking tests ... OK
* checking package vignettes in 'inst/doc' ... OK
* checking PDF version of manual ... OK




On 17/07/10 12:48 AM, Simon Urbanek wrote:
> The CRAN machine is Mac OS X 10.5.8 with Xcode 3.1.4 (using gcc-4.2) which is indeed the latest Xcode version for Leopard. If you have any hints as of why lme4 may be failing they are highly appreciated.
>
> Thanks,
> Simon
>
>



From daniel.lists at zeno.co.nz  Sat Jul 17 03:30:34 2010
From: daniel.lists at zeno.co.nz (Daniel Myall)
Date: Sat, 17 Jul 2010 13:30:34 +1200
Subject: [R-sig-ME] Failure to load lme4 on Mac
In-Reply-To: <76CE89BD-5FC2-4F6D-BEB2-43AC75207F17@r-project.org>
References: <C8207D43.4236%mcmahons@si.edu> <4BFB0AE0.3090803@zeno.co.nz>
	<loom.20100715T175631-148@post.gmane.org>
	<AANLkTim4iUokYQZvcL99rhTQkHqIQ5wuESMAGCPu7qGe@mail.gmail.com>
	<AANLkTil72csO0XA3-ZghXw62RUp9gMr-Df1Kx8Bi_Iq2@mail.gmail.com>
	<AANLkTik15uc4QqaIxcwkhAd4HjpzCQ60MuKqiFDJyJnS@mail.gmail.com>
	<08AD950F-C3DB-4E23-868B-0EFD94833014@anu.edu.au>
	<AANLkTil7OZ91zRrGf3licxyYQTdgO7QFfLr5CJoyqPc5@mail.gmail.com>
	<4C3F9E01.9050804@zeno.co.nz>
	<AANLkTimy0SevCeJ87YhFis_fQg-S1ixMwaZF2Bk2K-Jq@mail.gmail.com>
	<E1F79CC7-DB81-4916-B847-10C6C02DF2A8@r-project.org>
	<4C40D7A1.8030608@zeno.co.nz>
	<76CE89BD-5FC2-4F6D-BEB2-43AC75207F17@r-project.org>
Message-ID: <4C4107BA.1040407@zeno.co.nz>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100717/59525b45/attachment.pl>

From ken.knoblauch at inserm.fr  Sat Jul 17 07:07:06 2010
From: ken.knoblauch at inserm.fr (Ken Knoblauch)
Date: Sat, 17 Jul 2010 07:07:06 +0200
Subject: [R-sig-ME] Failure to load lme4 on Mac
In-Reply-To: <19520.33619.18880.815822@lynne.math.ethz.ch>
References: <C8207D43.4236%mcmahons@si.edu> <4BFB0AE0.3090803@zeno.co.nz>
	<loom.20100715T175631-148@post.gmane.org>
	<AANLkTim4iUokYQZvcL99rhTQkHqIQ5wuESMAGCPu7qGe@mail.gmail.com>
	<AANLkTil72csO0XA3-ZghXw62RUp9gMr-Df1Kx8Bi_Iq2@mail.gmail.com>
	<AANLkTik15uc4QqaIxcwkhAd4HjpzCQ60MuKqiFDJyJnS@mail.gmail.com>
	<08AD950F-C3DB-4E23-868B-0EFD94833014@anu.edu.au>
	<AANLkTil7OZ91zRrGf3licxyYQTdgO7QFfLr5CJoyqPc5@mail.gmail.com>
	<4C3F9E01.9050804@zeno.co.nz>
	<AANLkTimy0SevCeJ87YhFis_fQg-S1ixMwaZF2Bk2K-Jq@mail.gmail.com>
	<E1F79CC7-DB81-4916-B847-10C6C02DF2A8@r-project.org>
	<loom.20100716T153900-860@post.gmane.org>
	<19520.33619.18880.815822@lynne.math.ethz.ch>
Message-ID: <20100717070706.70fg8lchcskskgo0@imp.inserm.fr>

Thanks, Martin.  I'm wondering if this could be more
widespread, whether it explains an anomaly that cropped
up a few weeks ago when a colleague and I were running the
same code using mgcv, on the same data, me, on my (32 bit) Mac, same
as below and she (her?) under (64 bit) linux.  We were getting
slight differences in p-values (and perhaps elsewhere) in
several digits to the right of the decimal point.  (She
was in Grenoble and I was in Lyon, just for precision).
No unit tests involved so unless we had been comparing
outputs, any differences would have been insidiously unnoticed.

A short term solution to get a Mac binary up until the
underlying source of this anomaly is brought to light
might be to make these unit tests conditional on not
being a Mac, but you might find that (understandably) less than righteous
in that it is letting people generate results with potentially
small errors (as far as we know at this point) leaking in
without any protection.

best,

Ken

Quoting Martin Maechler <maechler at stat.math.ethz.ch>:

>>>>>> "KK" == Ken Knoblauch <ken.knoblauch at inserm.fr>
>>>>>>     on Fri, 16 Jul 2010 13:51:23 +0000 (UTC) writes:
>
>    [...........]
>
>     >> The CRAN machine is Mac OS X 10.5.8 with Xcode 3.1.4
>     >> (using gcc-4.2) which is indeed the latest Xcode version
>     >> for Leopard. If you have any hints as of why lme4 may be
>     >> failing they are highly appreciated.
>
>     >> Thanks,
>     >> Simon
>
>     [.......................]
>
>     KK> Just having updated Xcode to 3.1.4 and fixed the versions of  
>  gcc, etc. so
>     KK> that I'm able to install latest version of Rcpp and lme4a without any
>     KK> problems,
>     KK> I'll take a bite, but maybe I'm just repeating what you have  
>  already seen.
>     KK> I can install lme4 from source from Rforge with no problem.
>     KK> Just for starters here is my sessionInfo
>     KK> R version 2.11.1 Patched (2010-07-15 r52539)
>     KK> i386-apple-darwin9.8.0
>
>     KK> locale:
>     KK> [1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
>
>     KK> attached base packages:
>     KK> [1] stats     graphics  grDevices utils     datasets  methods
>     KK> [7] base
>
>     KK> other attached packages:
>     KK> [1] lme4_0.999375-34   Matrix_0.999375-41 lattice_0.18-8
>
>     KK> loaded via a namespace (and not attached):
>     KK> [1] grid_2.11.1   nlme_3.1-96   stats4_2.11.1
>
>     KK> I dowloaded lme4_0.999375-34.tar.gz from CRAN and ran
>     KK> R CMD check on it and came up with
>     KK> * checking tests ...
>     KK> Running ?extras.R?
>     KK> Running ?lmer-1.R?
>     KK> ERROR
>     KK> Running the tests in 'tests/lmer-1.R' failed.
>     KK> Last 13 lines of output:
>     KK> +                  x3=rnorm(20,1))
>     >> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>     >> m1 <- lmer(y ~ x1 + x2|ff  , data = D)
>     >> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>     >> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>     >> stopifnot(identical(ranef(m0), ranef(m1)),
>     KK> +     identical(ranef(m2), ranef(m3)),
>     KK> +    inherits(tryCatch(lmer(y ~ x2|ff + x1, data = D), error  
>  = function(e)e),
>     KK> +                    "error"))
>     KK> Error: identical(ranef(m0), ranef(m1)) is not TRUE
>     KK> In addition: Warning message:
>     KK> In Ops.factor(ff, x1) : + not meaningful for factors
>     KK> Execution halted
>     KK> which I think is the reported problem.
>
> Yes, one of the typical two ones.
>
> The other one that Mac useRs, e.g.,  Kent Holsinger, in a private
> communication, have also encountered, is the even simpler case
> {earlier in lmer-1.R, so this means it did not trigger for
> *you*}:
>
> y <- (1:20)*pi
> x <- (1:20)^2
> group <- gl(2,10)
>
> stopifnot(require(lme4))
> sessionInfo()
>
> M2. <- lmer (y ~ 1 + x + (1 + x | group))
> M2  <- lmer (y ~     x + (    x | group))
>
> ## should be identical (and is .. well, not on all versions on Mac OSX):
> identical(ranef(M2), ranef(M2.))
> ## not  TRUE on some  Mac : OSX : R  combinations
>
>
> How can the linear algebra computations that start from
> identical numbers give different results *sometimes* on Mac OSX?
> Could it be that it uses some Mac specific BLAS/LAPACK
> optimizations which only happen *sometimes* ?
>
>     KK> I went into the file lmer-1.R which seems to be where this is
>     KK> coming from
>
> [correct]
>
>     KK> and sourced the lines indicated above and get
>
>     >> D <-  data.frame(y= rnorm(20,10), ff = gl(4,5),
>     KK> +                  x1=rnorm(20,3), x2=rnorm(20,7),
>     KK> +                  x3=rnorm(20,1))
>     >> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>     >> m1 <- lmer(y ~ x1 + x2|ff  , data = D)
>     >> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>     >> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>     >> stopifnot(identical(ranef(m0), ranef(m1)),
>     KK> +           identical(ranef(m2), ranef(m3)),
>     KK> +           inherits(tryCatch(lmer(y ~ x2|ff + x1, data = D), error =
>     KK> function(e)e),
>     KK> +                    "error"))
>     KK> Error: identical(ranef(m2), ranef(m3)) is not TRUE
>     KK> In addition: Warning message:
>     KK> In Ops.factor(ff, x1) : + not meaningful for factors
>     >> identical(ranef(m0), ranef(m1))
>     KK> [1] TRUE
>
>     >> identical(ranef(m2), ranef(m3))
>     KK> [1] FALSE
>
>     KK> so it happens in an R session as well.
>
> yes.
> So,
>  m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>  m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>
> give differing results? How come?
> It seems as curious as the above simpler case,
> as really the initial starting matrices must be identical,
> unless the mac CPU does some things slightly differently
> depending on the exact machine configuration ???
>
> To me that could mean that even two identical R statements
> could give very slightly differing results, depending on the
> exact circumstance in which they are called {and of course I'm
> not talking about things that depend on options() or global
> variables or different search(), ...}
>
> ??
>
>     KK> Checking the ranef's
>     >> ranef(m2)
>     KK> $ff
>     KK> (Intercept)          x2
>     KK> 1  -1.4142222  0.15618464
>     KK> 2   0.4787662 -0.05287424
>     KK> 3   0.3193410 -0.03526755
>     KK> 4   1.7224362 -0.19022335
>
>     >> ranef(m3)
>     KK> $ff
>     KK> (Intercept)          x2
>     KK> 1  -1.4141930  0.15618142
>     KK> 2   0.4787944 -0.05287736
>     KK> 3   0.3193632 -0.03527000
>     KK> 4   1.7224652 -0.19022656
>
>     KK> They do indeed differ.  I'm on a 32 bit machine, could this be
>     KK> a 32/64 bit difference or something at the level of BLAS/ATLAS level?
>     KK> That's out of my league.  If I have time, I'll try it on a   
> 64 bit Mac, but I'm
>     KK> not likely to get back to that before about the beginning of August.
>
>
>     KK> Hope that this is useful.
>
>     KK> Ken
>
>     KK> --
>     KK> Ken Knoblauch
>     KK> Inserm U846
>     KK> Stem-cell and Brain Research Institute
>     KK> Department of Integrative Neurosciences
>     KK> 18 avenue du Doyen L?pine
>     KK> 69500 Bron
>     KK> France
>     KK> tel: +33 (0)4 72 91 34 77
>     KK> fax: +33 (0)4 72 91 34 61
>     KK> portable: +33 (0)6 84 10 64 10
>     KK> http://www.sbri.fr/members/kenneth-knoblauch.html
>
>     KK> _______________________________________________
>     KK> R-sig-mixed-models at r-project.org mailing list
>     KK> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Ken Knoblauch
Inserm U846
Stem-cell and Brain Research Institute
Department of Integrative Neurosciences
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.sbri.fr/members/kenneth-knoblauch.html



From ken.knoblauch at inserm.fr  Sat Jul 17 07:30:34 2010
From: ken.knoblauch at inserm.fr (Ken Knoblauch)
Date: Sat, 17 Jul 2010 07:30:34 +0200
Subject: [R-sig-ME] Failure to load lme4 on Mac
In-Reply-To: <19520.33619.18880.815822@lynne.math.ethz.ch>
References: <C8207D43.4236%mcmahons@si.edu> <4BFB0AE0.3090803@zeno.co.nz>
	<loom.20100715T175631-148@post.gmane.org>
	<AANLkTim4iUokYQZvcL99rhTQkHqIQ5wuESMAGCPu7qGe@mail.gmail.com>
	<AANLkTil72csO0XA3-ZghXw62RUp9gMr-Df1Kx8Bi_Iq2@mail.gmail.com>
	<AANLkTik15uc4QqaIxcwkhAd4HjpzCQ60MuKqiFDJyJnS@mail.gmail.com>
	<08AD950F-C3DB-4E23-868B-0EFD94833014@anu.edu.au>
	<AANLkTil7OZ91zRrGf3licxyYQTdgO7QFfLr5CJoyqPc5@mail.gmail.com>
	<4C3F9E01.9050804@zeno.co.nz>
	<AANLkTimy0SevCeJ87YhFis_fQg-S1ixMwaZF2Bk2K-Jq@mail.gmail.com>
	<E1F79CC7-DB81-4916-B847-10C6C02DF2A8@r-project.org>
	<loom.20100716T153900-860@post.gmane.org>
	<19520.33619.18880.815822@lynne.math.ethz.ch>
Message-ID: <20100717073034.586halmzkgowwcs8@imp.inserm.fr>

Here is one more thing that I tried, that goes along with
the hypothesis of interference from some previous initialization.
I first ran the lmer-1.R file up to the offending section and
got one result then cleared the workspace and did a gc()
and then ran just the offending section of code and got
a different result:


... Previous section of file run ...

> ## Wrong formula gave a seg.fault at times:
> D <-  data.frame(y= rnorm(20,10), ff = gl(4,5),
+                  x1=rnorm(20,3), x2=rnorm(20,7),
+                  x3=rnorm(20,1))
> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
> m1 <- lmer(y ~ x1 + x2|ff  , data = D)
> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
> stopifnot(identical(ranef(m0), ranef(m1)),
+           identical(ranef(m2), ranef(m3)),
+           inherits(tryCatch(lmer(y ~ x2|ff + x1, data = D), error =  
function(e)e),
+                    "error"))
Error: identical(ranef(m0), ranef(m1)) is not TRUE
In addition: Warning message:
In Ops.factor(ff, x1) : + not meaningful for factors

... then just the next section

> rm(list = ls(all = TRUE))
> gc()
          used (Mb) gc trigger (Mb) max used (Mb)
Ncells 906841 24.3    1476915 39.5  1368491 36.6
Vcells 315369  2.5     905753  7.0   827749  6.4
> D <-  data.frame(y= rnorm(20,10), ff = gl(4,5),
+                  x1=rnorm(20,3), x2=rnorm(20,7),
+                  x3=rnorm(20,1))
> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
> m1 <- lmer(y ~ x1 + x2|ff  , data = D)
> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
> stopifnot(identical(ranef(m0), ranef(m1)),
+           identical(ranef(m2), ranef(m3)),
+           inherits(tryCatch(lmer(y ~ x2|ff + x1, data = D), error =  
function(e)e),
+                    "error"))
Error: identical(ranef(m2), ranef(m3)) is not TRUE
In addition: Warning message:
In Ops.factor(ff, x1) : + not meaningful for factors

Curious.

Ken


Quoting Martin Maechler <maechler at stat.math.ethz.ch>:

>>>>>> "KK" == Ken Knoblauch <ken.knoblauch at inserm.fr>
>>>>>>     on Fri, 16 Jul 2010 13:51:23 +0000 (UTC) writes:
>
>    [...........]
>
>     >> The CRAN machine is Mac OS X 10.5.8 with Xcode 3.1.4
>     >> (using gcc-4.2) which is indeed the latest Xcode version
>     >> for Leopard. If you have any hints as of why lme4 may be
>     >> failing they are highly appreciated.
>
>     >> Thanks,
>     >> Simon
>
>     [.......................]
>
>     KK> Just having updated Xcode to 3.1.4 and fixed the versions of  
>  gcc, etc. so
>     KK> that I'm able to install latest version of Rcpp and lme4a without any
>     KK> problems,
>     KK> I'll take a bite, but maybe I'm just repeating what you have  
>  already seen.
>     KK> I can install lme4 from source from Rforge with no problem.
>     KK> Just for starters here is my sessionInfo
>     KK> R version 2.11.1 Patched (2010-07-15 r52539)
>     KK> i386-apple-darwin9.8.0
>
>     KK> locale:
>     KK> [1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
>
>     KK> attached base packages:
>     KK> [1] stats     graphics  grDevices utils     datasets  methods
>     KK> [7] base
>
>     KK> other attached packages:
>     KK> [1] lme4_0.999375-34   Matrix_0.999375-41 lattice_0.18-8
>
>     KK> loaded via a namespace (and not attached):
>     KK> [1] grid_2.11.1   nlme_3.1-96   stats4_2.11.1
>
>     KK> I dowloaded lme4_0.999375-34.tar.gz from CRAN and ran
>     KK> R CMD check on it and came up with
>     KK> * checking tests ...
>     KK> Running ?extras.R?
>     KK> Running ?lmer-1.R?
>     KK> ERROR
>     KK> Running the tests in 'tests/lmer-1.R' failed.
>     KK> Last 13 lines of output:
>     KK> +                  x3=rnorm(20,1))
>     >> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>     >> m1 <- lmer(y ~ x1 + x2|ff  , data = D)
>     >> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>     >> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>     >> stopifnot(identical(ranef(m0), ranef(m1)),
>     KK> +     identical(ranef(m2), ranef(m3)),
>     KK> +    inherits(tryCatch(lmer(y ~ x2|ff + x1, data = D), error  
>  = function(e)e),
>     KK> +                    "error"))
>     KK> Error: identical(ranef(m0), ranef(m1)) is not TRUE
>     KK> In addition: Warning message:
>     KK> In Ops.factor(ff, x1) : + not meaningful for factors
>     KK> Execution halted
>     KK> which I think is the reported problem.
>
> Yes, one of the typical two ones.
>
> The other one that Mac useRs, e.g.,  Kent Holsinger, in a private
> communication, have also encountered, is the even simpler case
> {earlier in lmer-1.R, so this means it did not trigger for
> *you*}:
>
> y <- (1:20)*pi
> x <- (1:20)^2
> group <- gl(2,10)
>
> stopifnot(require(lme4))
> sessionInfo()
>
> M2. <- lmer (y ~ 1 + x + (1 + x | group))
> M2  <- lmer (y ~     x + (    x | group))
>
> ## should be identical (and is .. well, not on all versions on Mac OSX):
> identical(ranef(M2), ranef(M2.))
> ## not  TRUE on some  Mac : OSX : R  combinations
>
>
> How can the linear algebra computations that start from
> identical numbers give different results *sometimes* on Mac OSX?
> Could it be that it uses some Mac specific BLAS/LAPACK
> optimizations which only happen *sometimes* ?
>
>     KK> I went into the file lmer-1.R which seems to be where this is
>     KK> coming from
>
> [correct]
>
>     KK> and sourced the lines indicated above and get
>
>     >> D <-  data.frame(y= rnorm(20,10), ff = gl(4,5),
>     KK> +                  x1=rnorm(20,3), x2=rnorm(20,7),
>     KK> +                  x3=rnorm(20,1))
>     >> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>     >> m1 <- lmer(y ~ x1 + x2|ff  , data = D)
>     >> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>     >> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>     >> stopifnot(identical(ranef(m0), ranef(m1)),
>     KK> +           identical(ranef(m2), ranef(m3)),
>     KK> +           inherits(tryCatch(lmer(y ~ x2|ff + x1, data = D), error =
>     KK> function(e)e),
>     KK> +                    "error"))
>     KK> Error: identical(ranef(m2), ranef(m3)) is not TRUE
>     KK> In addition: Warning message:
>     KK> In Ops.factor(ff, x1) : + not meaningful for factors
>     >> identical(ranef(m0), ranef(m1))
>     KK> [1] TRUE
>
>     >> identical(ranef(m2), ranef(m3))
>     KK> [1] FALSE
>
>     KK> so it happens in an R session as well.
>
> yes.
> So,
>  m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>  m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>
> give differing results? How come?
> It seems as curious as the above simpler case,
> as really the initial starting matrices must be identical,
> unless the mac CPU does some things slightly differently
> depending on the exact machine configuration ???
>
> To me that could mean that even two identical R statements
> could give very slightly differing results, depending on the
> exact circumstance in which they are called {and of course I'm
> not talking about things that depend on options() or global
> variables or different search(), ...}
>
> ??
>
>     KK> Checking the ranef's
>     >> ranef(m2)
>     KK> $ff
>     KK> (Intercept)          x2
>     KK> 1  -1.4142222  0.15618464
>     KK> 2   0.4787662 -0.05287424
>     KK> 3   0.3193410 -0.03526755
>     KK> 4   1.7224362 -0.19022335
>
>     >> ranef(m3)
>     KK> $ff
>     KK> (Intercept)          x2
>     KK> 1  -1.4141930  0.15618142
>     KK> 2   0.4787944 -0.05287736
>     KK> 3   0.3193632 -0.03527000
>     KK> 4   1.7224652 -0.19022656
>
>     KK> They do indeed differ.  I'm on a 32 bit machine, could this be
>     KK> a 32/64 bit difference or something at the level of BLAS/ATLAS level?
>     KK> That's out of my league.  If I have time, I'll try it on a   
> 64 bit Mac, but I'm
>     KK> not likely to get back to that before about the beginning of August.
>
>
>     KK> Hope that this is useful.
>
>     KK> Ken
>
>     KK> --
>     KK> Ken Knoblauch
>     KK> Inserm U846
>     KK> Stem-cell and Brain Research Institute
>     KK> Department of Integrative Neurosciences
>     KK> 18 avenue du Doyen L?pine
>     KK> 69500 Bron
>     KK> France
>     KK> tel: +33 (0)4 72 91 34 77
>     KK> fax: +33 (0)4 72 91 34 61
>     KK> portable: +33 (0)6 84 10 64 10
>     KK> http://www.sbri.fr/members/kenneth-knoblauch.html
>
>     KK> _______________________________________________
>     KK> R-sig-mixed-models at r-project.org mailing list
>     KK> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Ken Knoblauch
Inserm U846
Stem-cell and Brain Research Institute
Department of Integrative Neurosciences
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.sbri.fr/members/kenneth-knoblauch.html



From john.maindonald at anu.edu.au  Sat Jul 17 07:51:06 2010
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Sat, 17 Jul 2010 15:51:06 +1000
Subject: [R-sig-ME] Failure to load lme4 on Mac
In-Reply-To: <20100717070706.70fg8lchcskskgo0@imp.inserm.fr>
References: <C8207D43.4236%mcmahons@si.edu> <4BFB0AE0.3090803@zeno.co.nz>
	<loom.20100715T175631-148@post.gmane.org>
	<AANLkTim4iUokYQZvcL99rhTQkHqIQ5wuESMAGCPu7qGe@mail.gmail.com>
	<AANLkTil72csO0XA3-ZghXw62RUp9gMr-Df1Kx8Bi_Iq2@mail.gmail.com>
	<AANLkTik15uc4QqaIxcwkhAd4HjpzCQ60MuKqiFDJyJnS@mail.gmail.com>
	<08AD950F-C3DB-4E23-868B-0EFD94833014@anu.edu.au>
	<AANLkTil7OZ91zRrGf3licxyYQTdgO7QFfLr5CJoyqPc5@mail.gmail.com>
	<4C3F9E01.9050804@zeno.co.nz>
	<AANLkTimy0SevCeJ87YhFis_fQg-S1ixMwaZF2Bk2K-Jq@mail.gmail.com>
	<E1F79CC7-DB81-4916-B847-10C6C02DF2A8@r-project.org>
	<loom.20100716T153900-860@post.gmane.org>
	<19520.33619.18880.815822@lynne.math.ethz.ch>
	<20100717070706.70fg8lchcskskgo0@imp.inserm.fr>
Message-ID: <7E3C1A13-65AE-4E6F-9EB6-1EEB2B1677C0@anu.edu.au>

In principle, maybe a Snow Leopard version might be posted
as an alternative, if someone can provide one.  But I take it
that the issue is now a bit wider than tests that fail on Leopard
vs passing on Snow Leopard?

This is I guess an issue for R-devel, but I will float it here first.
It would surely be handy to have a command, maybe status()
would do, so that one could type
> status("lme4")
and receive back details of available binary versions of lme4
on CRAN or on R-forge, or on another relevant site.  One might
want to insist on a recent version of R, or on the most recent
version.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 17/07/2010, at 3:07 PM, Ken Knoblauch wrote:

> Thanks, Martin.  I'm wondering if this could be more
> widespread, whether it explains an anomaly that cropped
> up a few weeks ago when a colleague and I were running the
> same code using mgcv, on the same data, me, on my (32 bit) Mac, same
> as below and she (her?) under (64 bit) linux.  We were getting
> slight differences in p-values (and perhaps elsewhere) in
> several digits to the right of the decimal point.  (She
> was in Grenoble and I was in Lyon, just for precision).
> No unit tests involved so unless we had been comparing
> outputs, any differences would have been insidiously unnoticed.
> 
> A short term solution to get a Mac binary up until the
> underlying source of this anomaly is brought to light
> might be to make these unit tests conditional on not
> being a Mac, but you might find that (understandably) less than righteous
> in that it is letting people generate results with potentially
> small errors (as far as we know at this point) leaking in
> without any protection.
> 
> best,
> 
> Ken
> 
> Quoting Martin Maechler <maechler at stat.math.ethz.ch>:
> 
>>>>>>> "KK" == Ken Knoblauch <ken.knoblauch at inserm.fr>
>>>>>>>   on Fri, 16 Jul 2010 13:51:23 +0000 (UTC) writes:
>> 
>>  [...........]
>> 
>>>> The CRAN machine is Mac OS X 10.5.8 with Xcode 3.1.4
>>>> (using gcc-4.2) which is indeed the latest Xcode version
>>>> for Leopard. If you have any hints as of why lme4 may be
>>>> failing they are highly appreciated.
>> 
>>>> Thanks,
>>>> Simon
>> 
>>   [.......................]
>> 
>>   KK> Just having updated Xcode to 3.1.4 and fixed the versions of  gcc, etc. so
>>   KK> that I'm able to install latest version of Rcpp and lme4a without any
>>   KK> problems,
>>   KK> I'll take a bite, but maybe I'm just repeating what you have  already seen.
>>   KK> I can install lme4 from source from Rforge with no problem.
>>   KK> Just for starters here is my sessionInfo
>>   KK> R version 2.11.1 Patched (2010-07-15 r52539)
>>   KK> i386-apple-darwin9.8.0
>> 
>>   KK> locale:
>>   KK> [1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
>> 
>>   KK> attached base packages:
>>   KK> [1] stats     graphics  grDevices utils     datasets  methods
>>   KK> [7] base
>> 
>>   KK> other attached packages:
>>   KK> [1] lme4_0.999375-34   Matrix_0.999375-41 lattice_0.18-8
>> 
>>   KK> loaded via a namespace (and not attached):
>>   KK> [1] grid_2.11.1   nlme_3.1-96   stats4_2.11.1
>> 
>>   KK> I dowloaded lme4_0.999375-34.tar.gz from CRAN and ran
>>   KK> R CMD check on it and came up with
>>   KK> * checking tests ...
>>   KK> Running ?extras.R?
>>   KK> Running ?lmer-1.R?
>>   KK> ERROR
>>   KK> Running the tests in 'tests/lmer-1.R' failed.
>>   KK> Last 13 lines of output:
>>   KK> +                  x3=rnorm(20,1))
>>>> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>>>> m1 <- lmer(y ~ x1 + x2|ff  , data = D)
>>>> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>>>> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>>>> stopifnot(identical(ranef(m0), ranef(m1)),
>>   KK> +     identical(ranef(m2), ranef(m3)),
>>   KK> +    inherits(tryCatch(lmer(y ~ x2|ff + x1, data = D), error  = function(e)e),
>>   KK> +                    "error"))
>>   KK> Error: identical(ranef(m0), ranef(m1)) is not TRUE
>>   KK> In addition: Warning message:
>>   KK> In Ops.factor(ff, x1) : + not meaningful for factors
>>   KK> Execution halted
>>   KK> which I think is the reported problem.
>> 
>> Yes, one of the typical two ones.
>> 
>> The other one that Mac useRs, e.g.,  Kent Holsinger, in a private
>> communication, have also encountered, is the even simpler case
>> {earlier in lmer-1.R, so this means it did not trigger for
>> *you*}:
>> 
>> y <- (1:20)*pi
>> x <- (1:20)^2
>> group <- gl(2,10)
>> 
>> stopifnot(require(lme4))
>> sessionInfo()
>> 
>> M2. <- lmer (y ~ 1 + x + (1 + x | group))
>> M2  <- lmer (y ~     x + (    x | group))
>> 
>> ## should be identical (and is .. well, not on all versions on Mac OSX):
>> identical(ranef(M2), ranef(M2.))
>> ## not  TRUE on some  Mac : OSX : R  combinations
>> 
>> 
>> How can the linear algebra computations that start from
>> identical numbers give different results *sometimes* on Mac OSX?
>> Could it be that it uses some Mac specific BLAS/LAPACK
>> optimizations which only happen *sometimes* ?
>> 
>>   KK> I went into the file lmer-1.R which seems to be where this is
>>   KK> coming from
>> 
>> [correct]
>> 
>>   KK> and sourced the lines indicated above and get
>> 
>>>> D <-  data.frame(y= rnorm(20,10), ff = gl(4,5),
>>   KK> +                  x1=rnorm(20,3), x2=rnorm(20,7),
>>   KK> +                  x3=rnorm(20,1))
>>>> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>>>> m1 <- lmer(y ~ x1 + x2|ff  , data = D)
>>>> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>>>> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>>>> stopifnot(identical(ranef(m0), ranef(m1)),
>>   KK> +           identical(ranef(m2), ranef(m3)),
>>   KK> +           inherits(tryCatch(lmer(y ~ x2|ff + x1, data = D), error =
>>   KK> function(e)e),
>>   KK> +                    "error"))
>>   KK> Error: identical(ranef(m2), ranef(m3)) is not TRUE
>>   KK> In addition: Warning message:
>>   KK> In Ops.factor(ff, x1) : + not meaningful for factors
>>>> identical(ranef(m0), ranef(m1))
>>   KK> [1] TRUE
>> 
>>>> identical(ranef(m2), ranef(m3))
>>   KK> [1] FALSE
>> 
>>   KK> so it happens in an R session as well.
>> 
>> yes.
>> So,
>> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>> 
>> give differing results? How come?
>> It seems as curious as the above simpler case,
>> as really the initial starting matrices must be identical,
>> unless the mac CPU does some things slightly differently
>> depending on the exact machine configuration ???
>> 
>> To me that could mean that even two identical R statements
>> could give very slightly differing results, depending on the
>> exact circumstance in which they are called {and of course I'm
>> not talking about things that depend on options() or global
>> variables or different search(), ...}
>> 
>> ??
>> 
>>   KK> Checking the ranef's
>>>> ranef(m2)
>>   KK> $ff
>>   KK> (Intercept)          x2
>>   KK> 1  -1.4142222  0.15618464
>>   KK> 2   0.4787662 -0.05287424
>>   KK> 3   0.3193410 -0.03526755
>>   KK> 4   1.7224362 -0.19022335
>> 
>>>> ranef(m3)
>>   KK> $ff
>>   KK> (Intercept)          x2
>>   KK> 1  -1.4141930  0.15618142
>>   KK> 2   0.4787944 -0.05287736
>>   KK> 3   0.3193632 -0.03527000
>>   KK> 4   1.7224652 -0.19022656
>> 
>>   KK> They do indeed differ.  I'm on a 32 bit machine, could this be
>>   KK> a 32/64 bit difference or something at the level of BLAS/ATLAS level?
>>   KK> That's out of my league.  If I have time, I'll try it on a  64 bit Mac, but I'm
>>   KK> not likely to get back to that before about the beginning of August.
>> 
>> 
>>   KK> Hope that this is useful.
>> 
>>   KK> Ken
>> 
>>   KK> --
>>   KK> Ken Knoblauch
>>   KK> Inserm U846
>>   KK> Stem-cell and Brain Research Institute
>>   KK> Department of Integrative Neurosciences
>>   KK> 18 avenue du Doyen L?pine
>>   KK> 69500 Bron
>>   KK> France
>>   KK> tel: +33 (0)4 72 91 34 77
>>   KK> fax: +33 (0)4 72 91 34 61
>>   KK> portable: +33 (0)6 84 10 64 10
>>   KK> http://www.sbri.fr/members/kenneth-knoblauch.html
>> 
>>   KK> _______________________________________________
>>   KK> R-sig-mixed-models at r-project.org mailing list
>>   KK> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> 
> 
> -- 
> Ken Knoblauch
> Inserm U846
> Stem-cell and Brain Research Institute
> Department of Integrative Neurosciences
> 18 avenue du Doyen L?pine
> 69500 Bron
> France
> tel: +33 (0)4 72 91 34 77
> fax: +33 (0)4 72 91 34 61
> portable: +33 (0)6 84 10 64 10
> http://www.sbri.fr/members/kenneth-knoblauch.html
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From daniel.lists at zeno.co.nz  Sat Jul 17 10:50:06 2010
From: daniel.lists at zeno.co.nz (Daniel Myall)
Date: Sat, 17 Jul 2010 20:50:06 +1200
Subject: [R-sig-ME] Failure to load lme4 on Mac
In-Reply-To: <7E3C1A13-65AE-4E6F-9EB6-1EEB2B1677C0@anu.edu.au>
References: <C8207D43.4236%mcmahons@si.edu>
	<4BFB0AE0.3090803@zeno.co.nz>	<loom.20100715T175631-148@post.gmane.org>	<AANLkTim4iUokYQZvcL99rhTQkHqIQ5wuESMAGCPu7qGe@mail.gmail.com>	<AANLkTil72csO0XA3-ZghXw62RUp9gMr-Df1Kx8Bi_Iq2@mail.gmail.com>	<AANLkTik15uc4QqaIxcwkhAd4HjpzCQ60MuKqiFDJyJnS@mail.gmail.com>	<08AD950F-C3DB-4E23-868B-0EFD94833014@anu.edu.au>	<AANLkTil7OZ91zRrGf3licxyYQTdgO7QFfLr5CJoyqPc5@mail.gmail.com>	<4C3F9E01.9050804@zeno.co.nz>	<AANLkTimy0SevCeJ87YhFis_fQg-S1ixMwaZF2Bk2K-Jq@mail.gmail.com>	<E1F79CC7-DB81-4916-B847-10C6C02DF2A8@r-project.org>	<loom.20100716T153900-860@post.gmane.org>	<19520.33619.18880.815822@lynne.math.ethz.ch>	<20100717070706.70fg8lchcskskgo0@imp.inserm.fr>
	<7E3C1A13-65AE-4E6F-9EB6-1EEB2B1677C0@anu.edu.au>
Message-ID: <4C416EBE.4080204@zeno.co.nz>

I've done some further testing (R 2.11.1) and the issue is not limited 
to Leopard.

Using the test:

library(lme4)
y <- (1:20)*pi
x <- (1:20)^2
group <- gl(2,10)
for (i in 1:10) {
   M1 <- lmer (y ~     x + (    x | group))
   M2 <- lmer (y ~     x + (    x | group))
   print(identical(M1,M2))
}

For CRAN lme4 and Matrix:

32 bit on Leopard: R CMD check fails; different results (on most runs)
32 bit on Snow Leopard: R CMD check passes; different results (on some 
runs).
64 bit on Snow Leopard: R CMD check passes; identical results

For SVN version of Matrix with CRAN lme4:

32 bit on Snow Leopard: different results (on all runs).
64 bit on Snow Leopard: different results (on all runs)

For SVN version of Matrix with SVN lme4a:

32 bit on Snow Leopard: different results (on all runs).
64 bit on Snow Leopard: identical results

I couldn't reproduce on Linux 32/64bit. Is it time to jump into valgrind 
to try and find the cause?

Cheers,
Daniel



On 17/07/10 5:51 PM, John Maindonald wrote:
> In principle, maybe a Snow Leopard version might be posted
> as an alternative, if someone can provide one.  But I take it
> that the issue is now a bit wider than tests that fail on Leopard
> vs passing on Snow Leopard?
>



From simon.urbanek at r-project.org  Sat Jul 17 02:14:57 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 16 Jul 2010 20:14:57 -0400
Subject: [R-sig-ME] Failure to load lme4 on Mac
In-Reply-To: <4C40D7A1.8030608@zeno.co.nz>
References: <C8207D43.4236%mcmahons@si.edu> <4BFB0AE0.3090803@zeno.co.nz>
	<loom.20100715T175631-148@post.gmane.org>
	<AANLkTim4iUokYQZvcL99rhTQkHqIQ5wuESMAGCPu7qGe@mail.gmail.com>
	<AANLkTil72csO0XA3-ZghXw62RUp9gMr-Df1Kx8Bi_Iq2@mail.gmail.com>
	<AANLkTik15uc4QqaIxcwkhAd4HjpzCQ60MuKqiFDJyJnS@mail.gmail.com>
	<08AD950F-C3DB-4E23-868B-0EFD94833014@anu.edu.au>
	<AANLkTil7OZ91zRrGf3licxyYQTdgO7QFfLr5CJoyqPc5@mail.gmail.com>
	<4C3F9E01.9050804@zeno.co.nz>
	<AANLkTimy0SevCeJ87YhFis_fQg-S1ixMwaZF2Bk2K-Jq@mail.gmail.com>
	<E1F79CC7-DB81-4916-B847-10C6C02DF2A8@r-project.org>
	<4C40D7A1.8030608@zeno.co.nz>
Message-ID: <76CE89BD-5FC2-4F6D-BEB2-43AC75207F17@r-project.org>

Daniel,

On Jul 16, 2010, at 6:05 PM, Daniel Myall wrote:

> Hi Simon,
> 
> The machine I'm primarily testing on has Mac OS X 10.6.4 with Xcode 3.2.2 (using gcc-4.2.1).

Yes, that setup works, but SL binaries are incompatible with Leopard so that doesn't help.


> The log from R CMD check is included below. I don't have any Leopard installs around anymore, although I am setting up a virtual machine with Mac OS X 10.5.8 and Xcode 3.1.4 to hopefully reproduce the bug.
> 

Can you tell me what are you using for that? I could use that myself :). I'm not aware of any VM so far that can run OS X 10.5.8 client as guest OS...


> If there is a bug in Mac OS X 10.5.8 or Xcode 3.1.4 resulting in the two errors in the tests that have so far been seen,  I am curious as to why it is only being exhibited with lme4. Once the VM has installed I'll play around with compile-time optimisations of lme4 to see if they are exposing the bug.
> 

It's not clear that the bug is on OS X or Xcode - it may or may not - from experience the issue is quite often a real bug but it can be masked other things such as memory layout, optimizations etc. I strongly suspect that in the current case since the result depends on the preceding code so it may be something like an uninitialized variable or so. We had both before, but lme4 is the only one failing in the current setup... 

Cheers,
Simon



> * using log directory '/Users/daniel/working/R-packages/lme4.Rcheck'
> * using R version 2.11.1 (2010-05-31)
> * using session charset: UTF-8
> * checking for file 'lme4/DESCRIPTION' ... OK
> * this is package 'lme4' version '0.999375-34'
> * checking package name space information ... OK
> * checking package dependencies ... OK
> * checking if this is a source package ... OK
> * checking for executable files ... OK
> * checking whether package 'lme4' can be installed ... OK
> * checking package directory ... OK
> * checking for portable file names ... OK
> * checking for sufficient/correct file permissions ... OK
> * checking DESCRIPTION meta-information ... OK
> * checking top-level files ... OK
> * checking index information ... OK
> * checking package subdirectories ... OK
> * checking R files for non-ASCII characters ... OK
> * checking R files for syntax errors ... OK
> * checking whether the package can be loaded ... OK
> * checking whether the package can be loaded with stated dependencies ... OK
> * checking whether the package can be unloaded cleanly ... OK
> * checking whether the name space can be loaded with stated dependencies ... OK
> * checking whether the name space can be unloaded cleanly ... OK
> * checking for unstated dependencies in R code ... OK
> * checking S3 generic/method consistency ... OK
> * checking replacement functions ... OK
> * checking foreign function calls ... OK
> * checking R code for possible problems ... OK
> * checking Rd files ... OK
> * checking Rd metadata ... OK
> * checking Rd cross-references ... OK
> * checking for missing documentation entries ... OK
> * checking for code/documentation mismatches ... OK
> * checking Rd \usage sections ... OK
> * checking Rd contents ... OK
> * checking data for non-ASCII characters ... OK
> * checking line endings in C/C++/Fortran sources/headers ... OK
> * checking line endings in Makefiles ... OK
> * checking for portable compilation flags in Makevars ... OK
> * checking for portable use of $BLAS_LIBS ... OK
> * checking examples ... OK
> * checking tests ... OK
> * checking package vignettes in 'inst/doc' ... OK
> * checking PDF version of manual ... OK
> 
> 
> 
> 
> On 17/07/10 12:48 AM, Simon Urbanek wrote:
>> The CRAN machine is Mac OS X 10.5.8 with Xcode 3.1.4 (using gcc-4.2) which is indeed the latest Xcode version for Leopard. If you have any hints as of why lme4 may be failing they are highly appreciated.
>> 
>> Thanks,
>> Simon
>> 
>>   
> 
> 



From simon.urbanek at r-project.org  Sat Jul 17 03:51:10 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 16 Jul 2010 21:51:10 -0400
Subject: [R-sig-ME] Failure to load lme4 on Mac
In-Reply-To: <4C4107BA.1040407@zeno.co.nz>
References: <C8207D43.4236%mcmahons@si.edu> <4BFB0AE0.3090803@zeno.co.nz>
	<loom.20100715T175631-148@post.gmane.org>
	<AANLkTim4iUokYQZvcL99rhTQkHqIQ5wuESMAGCPu7qGe@mail.gmail.com>
	<AANLkTil72csO0XA3-ZghXw62RUp9gMr-Df1Kx8Bi_Iq2@mail.gmail.com>
	<AANLkTik15uc4QqaIxcwkhAd4HjpzCQ60MuKqiFDJyJnS@mail.gmail.com>
	<08AD950F-C3DB-4E23-868B-0EFD94833014@anu.edu.au>
	<AANLkTil7OZ91zRrGf3licxyYQTdgO7QFfLr5CJoyqPc5@mail.gmail.com>
	<4C3F9E01.9050804@zeno.co.nz>
	<AANLkTimy0SevCeJ87YhFis_fQg-S1ixMwaZF2Bk2K-Jq@mail.gmail.com>
	<E1F79CC7-DB81-4916-B847-10C6C02DF2A8@r-project.org>
	<4C40D7A1.8030608@zeno.co.nz>
	<76CE89BD-5FC2-4F6D-BEB2-43AC75207F17@r-project.org>
	<4C4107BA.1040407@zeno.co.nz>
Message-ID: <624F986E-9F0D-4D6E-80E0-4DFB3F8B6240@r-project.org>


On Jul 16, 2010, at 9:30 PM, Daniel Myall wrote:

> Hi Simon,
> 
>> 
>> Can you tell me what are you using for that? I could use that myself :). I'm not aware of any VM so far that can run OS X 10.5.8 client as guest OS...
>>   
>> 
> 
> Virtualbox [http://www.virtualbox.org/] can run OS X 10.5.8 as a guest OS (only legal on Apple hardware, etc, ....).
> 

I'm using VB but according to docs only the server version is supported, not the normal one... (I didn't actually try it but their docs say specifically that it doesn't work).

>>> If there is a bug in Mac OS X 10.5.8 or Xcode 3.1.4 resulting in the two errors in the tests that have so far been seen,  I am curious as to why it is only being exhibited with lme4. Once the VM has installed I'll play around with compile-time optimisations of lme4 to see if they are exposing the bug.
>>> 
>>>     
>>> 
>> 
>> It's not clear that the bug is on OS X or Xcode - it may or may not - from experience the issue is quite often a real bug but it can be masked other things such as memory layout, optimizations etc. I strongly suspect that in the current case since the result depends on the preceding code so it may be something like an uninitialized variable or so. We had both before, but lme4 is the only one failing in the current setup... 
>>   
>> 
> 
> Thanks (looks like it will be fun to debug!).
> 

Unfortunately :/ I had a quick look but that was not enough - I still need to find some time to dig deeper ... 

Cheers,
Simon



From maechler at stat.math.ethz.ch  Sat Jul 17 15:12:14 2010
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 17 Jul 2010 15:12:14 +0200
Subject: [R-sig-ME] Failure to load lme4 on Mac
In-Reply-To: <20100717073034.586halmzkgowwcs8@imp.inserm.fr>
References: <C8207D43.4236%mcmahons@si.edu> <4BFB0AE0.3090803@zeno.co.nz>
	<loom.20100715T175631-148@post.gmane.org>
	<AANLkTim4iUokYQZvcL99rhTQkHqIQ5wuESMAGCPu7qGe@mail.gmail.com>
	<AANLkTil72csO0XA3-ZghXw62RUp9gMr-Df1Kx8Bi_Iq2@mail.gmail.com>
	<AANLkTik15uc4QqaIxcwkhAd4HjpzCQ60MuKqiFDJyJnS@mail.gmail.com>
	<08AD950F-C3DB-4E23-868B-0EFD94833014@anu.edu.au>
	<AANLkTil7OZ91zRrGf3licxyYQTdgO7QFfLr5CJoyqPc5@mail.gmail.com>
	<4C3F9E01.9050804@zeno.co.nz>
	<AANLkTimy0SevCeJ87YhFis_fQg-S1ixMwaZF2Bk2K-Jq@mail.gmail.com>
	<E1F79CC7-DB81-4916-B847-10C6C02DF2A8@r-project.org>
	<loom.20100716T153900-860@post.gmane.org>
	<19520.33619.18880.815822@lynne.math.ethz.ch>
	<20100717073034.586halmzkgowwcs8@imp.inserm.fr>
Message-ID: <AANLkTilFCDW2kU5PvC5sa1S_kk9r4YyCGisBFCxLaUzZ@mail.gmail.com>

On Sat, Jul 17, 2010 at 07:30, Ken Knoblauch <ken.knoblauch at inserm.fr> wrote:
> Here is one more thing that I tried, that goes along with
> the hypothesis of interference from some previous initialization.
> I first ran the lmer-1.R file up to the offending section and
> got one result then cleared the workspace and did a gc()
> and then ran just the offending section of code and got
> a different result:
>
>
> ... Previous section of file run ...
>
>> ## Wrong formula gave a seg.fault at times:
>> D <- ?data.frame(y= rnorm(20,10), ff = gl(4,5),
>
> + ? ? ? ? ? ? ? ? ?x1=rnorm(20,3), x2=rnorm(20,7),
> + ? ? ? ? ? ? ? ? ?x3=rnorm(20,1))
>>
>> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>> m1 <- lmer(y ~ x1 + x2|ff ?, data = D)
>> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>> stopifnot(identical(ranef(m0), ranef(m1)),
>
> + ? ? ? ? ? identical(ranef(m2), ranef(m3)),
> + ? ? ? ? ? inherits(tryCatch(lmer(y ~ x2|ff + x1, data = D), error =
> function(e)e),
> + ? ? ? ? ? ? ? ? ? ?"error"))
> Error: identical(ranef(m0), ranef(m1)) is not TRUE
> In addition: Warning message:
> In Ops.factor(ff, x1) : + not meaningful for factors
>
> ... then just the next section
>
>> rm(list = ls(all = TRUE))
>> gc()
>
> ? ? ? ? used (Mb) gc trigger (Mb) max used (Mb)
> Ncells 906841 24.3 ? ?1476915 39.5 ?1368491 36.6
> Vcells 315369 ?2.5 ? ? 905753 ?7.0 ? 827749 ?6.4
>>
>> D <- ?data.frame(y= rnorm(20,10), ff = gl(4,5),
>
> + ? ? ? ? ? ? ? ? ?x1=rnorm(20,3), x2=rnorm(20,7),
> + ? ? ? ? ? ? ? ? ?x3=rnorm(20,1))
>>
>> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>> m1 <- lmer(y ~ x1 + x2|ff ?, data = D)
>> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>> stopifnot(identical(ranef(m0), ranef(m1)),
>
> + ? ? ? ? ? identical(ranef(m2), ranef(m3)),
> + ? ? ? ? ? inherits(tryCatch(lmer(y ~ x2|ff + x1, data = D), error =
> function(e)e),
> + ? ? ? ? ? ? ? ? ? ?"error"))
> Error: identical(ranef(m2), ranef(m3)) is not TRUE
> In addition: Warning message:
> In Ops.factor(ff, x1) : + not meaningful for factors
>
> Curious.

Well this one is using *different* data  'D' ,
as there's no  set.seed() before its creation..

But in general, may be using the other example (that comes earlier,
and I re-posted here),
it would be very interesting, if you could get it to fail or not to
fail "just depending on the state of your machine / R" (e.g. still in
the same R session)...

>
> Ken



From aleman at fordham.edu  Sat Jul 17 16:52:22 2010
From: aleman at fordham.edu (JOSE A ALEMAN)
Date: 17-Jul-2010 10:52:22 EDT
Subject: [R-sig-ME] question about random coefficients model (RCM)
Message-ID: <OF1D5BAA4A.B4CF105B-ON85257763.00510C35@fordham.edu>


Dear list users,

I have a question about how to estimate the RCM described by Western (1998)
in his article "Causal Heterogeneity in Comparative Research: A Bayesian
Hierarchical Modeling Approach". While I know how to estimate this model in
R via restricted maximum likelihood, I am at a loss as to how to interpret
the results. The random coefficients are supposed to be different for each
country, yet R provides  a standard regression-like output with a single
coefficient for the variable with the random slope. How would I go about
extracting the country specific information?

Thanks.

Jose A. Aleman
http://faculty.fordham.edu/aleman



From bates at stat.wisc.edu  Sat Jul 17 17:30:27 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat, 17 Jul 2010 10:30:27 -0500
Subject: [R-sig-ME] question about random coefficients model (RCM)
In-Reply-To: <OF1D5BAA4A.B4CF105B-ON85257763.00510C35@fordham.edu>
References: <OF1D5BAA4A.B4CF105B-ON85257763.00510C35@fordham.edu>
Message-ID: <AANLkTikk--k4g1GkY0E-hiNaZnPs_aC8qLW9Tcq0dUPm@mail.gmail.com>

On Sat, Jul 17, 2010 at 9:52 AM, JOSE A ALEMAN <aleman at fordham.edu> wrote:
>
> Dear list users,
>
> I have a question about how to estimate the RCM described by Western (1998)
> in his article "Causal Heterogeneity in Comparative Research: A Bayesian
> Hierarchical Modeling Approach". While I know how to estimate this model in
> R via restricted maximum likelihood, I am at a loss as to how to interpret
> the results. The random coefficients are supposed to be different for each
> country, yet R provides ?a standard regression-like output with a single
> coefficient for the variable with the random slope. How would I go about
> extracting the country specific information?

Can you be more specific about how you fit the model?  Just saying "in
R" is too general.

If you fit the model with lmer from the lme4 package then you may want
to look at the output from the ranef() and coef() extractors.



From ken.knoblauch at inserm.fr  Sat Jul 17 19:38:35 2010
From: ken.knoblauch at inserm.fr (Ken Knoblauch)
Date: Sat, 17 Jul 2010 19:38:35 +0200
Subject: [R-sig-ME] Failure to load lme4 on Mac
In-Reply-To: <19520.33619.18880.815822@lynne.math.ethz.ch>
References: <C8207D43.4236%mcmahons@si.edu> <4BFB0AE0.3090803@zeno.co.nz>
	<loom.20100715T175631-148@post.gmane.org>
	<AANLkTim4iUokYQZvcL99rhTQkHqIQ5wuESMAGCPu7qGe@mail.gmail.com>
	<AANLkTil72csO0XA3-ZghXw62RUp9gMr-Df1Kx8Bi_Iq2@mail.gmail.com>
	<AANLkTik15uc4QqaIxcwkhAd4HjpzCQ60MuKqiFDJyJnS@mail.gmail.com>
	<08AD950F-C3DB-4E23-868B-0EFD94833014@anu.edu.au>
	<AANLkTil7OZ91zRrGf3licxyYQTdgO7QFfLr5CJoyqPc5@mail.gmail.com>
	<4C3F9E01.9050804@zeno.co.nz>
	<AANLkTimy0SevCeJ87YhFis_fQg-S1ixMwaZF2Bk2K-Jq@mail.gmail.com>
	<E1F79CC7-DB81-4916-B847-10C6C02DF2A8@r-project.org>
	<loom.20100716T153900-860@post.gmane.org>
	<19520.33619.18880.815822@lynne.math.ethz.ch>
Message-ID: <20100717193835.panheknc0g088cw4@imp.inserm.fr>

Martin, et al.

Your simple example does trigger on a fresh session if I load lme4 with
library()


R version 2.11.1 Patched (2010-07-15 r52539)
Copyright (C) 2010 The R Foundation for Statistical Computing
ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

   Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[R.app GUI 1.35 (5601) i386-apple-darwin9.8.0]

> library(lme4)
Loading required package: Matrix
Loading required package: lattice

Attaching package: 'Matrix'

The following object(s) are masked from 'package:base':

     det


Attaching package: 'lme4'

The following object(s) are masked from 'package:stats':

     AIC

> y <- (1:20)*pi
> x <- (1:20)^2
> group <- gl(2,10)
>
> stopifnot(require(lme4))
> sessionInfo()
R version 2.11.1 Patched (2010-07-15 r52539)
i386-apple-darwin9.8.0

locale:
[1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods
[7] base

other attached packages:
[1] lme4_0.999375-34   Matrix_0.999375-41 lattice_0.18-8

loaded via a namespace (and not attached):
[1] grid_2.11.1   nlme_3.1-96   stats4_2.11.1
>
> M2. <- lmer (y ~ 1 + x + (1 + x | group))
> M2  <- lmer (y ~     x + (    x | group))
>
> ## should be identical (and is .. well, not on all versions on Mac OSX):
> identical(ranef(M2), ranef(M2.))
[1] FALSE

but not require()


R version 2.11.1 Patched (2010-07-15 r52539)
Copyright (C) 2010 The R Foundation for Statistical Computing
ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

   Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[R.app GUI 1.35 (5601) i386-apple-darwin9.8.0]

> require(lme4)
Loading required package: lme4
Loading required package: Matrix
Loading required package: lattice

Attaching package: 'Matrix'

The following object(s) are masked from 'package:base':

     det


Attaching package: 'lme4'

The following object(s) are masked from 'package:stats':

     AIC

> y <- (1:20)*pi
> x <- (1:20)^2
> group <- gl(2,10)
>
> stopifnot(require(lme4))
> sessionInfo()
R version 2.11.1 Patched (2010-07-15 r52539)
i386-apple-darwin9.8.0

locale:
[1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods
[7] base

other attached packages:
[1] lme4_0.999375-34   Matrix_0.999375-41 lattice_0.18-8

loaded via a namespace (and not attached):
[1] grid_2.11.1   nlme_3.1-96   stats4_2.11.1
>
> M2. <- lmer (y ~ 1 + x + (1 + x | group))
> M2  <- lmer (y ~     x + (    x | group))
>
> ## should be identical (and is .. well, not on all versions on Mac OSX):
> identical(ranef(M2), ranef(M2.))
[1] TRUE

how do library() and require() differ with respect to loading
packages????

Ken


Quoting Martin Maechler <maechler at stat.math.ethz.ch>:

>>>>>> "KK" == Ken Knoblauch <ken.knoblauch at inserm.fr>
>>>>>>     on Fri, 16 Jul 2010 13:51:23 +0000 (UTC) writes:
>
>    [...........]
>
>     >> The CRAN machine is Mac OS X 10.5.8 with Xcode 3.1.4
>     >> (using gcc-4.2) which is indeed the latest Xcode version
>     >> for Leopard. If you have any hints as of why lme4 may be
>     >> failing they are highly appreciated.
>
>     >> Thanks,
>     >> Simon
>
>     [.......................]
>
>     KK> Just having updated Xcode to 3.1.4 and fixed the versions of  
>  gcc, etc. so
>     KK> that I'm able to install latest version of Rcpp and lme4a without any
>     KK> problems,
>     KK> I'll take a bite, but maybe I'm just repeating what you have  
>  already seen.
>     KK> I can install lme4 from source from Rforge with no problem.
>     KK> Just for starters here is my sessionInfo
>     KK> R version 2.11.1 Patched (2010-07-15 r52539)
>     KK> i386-apple-darwin9.8.0
>
>     KK> locale:
>     KK> [1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
>
>     KK> attached base packages:
>     KK> [1] stats     graphics  grDevices utils     datasets  methods
>     KK> [7] base
>
>     KK> other attached packages:
>     KK> [1] lme4_0.999375-34   Matrix_0.999375-41 lattice_0.18-8
>
>     KK> loaded via a namespace (and not attached):
>     KK> [1] grid_2.11.1   nlme_3.1-96   stats4_2.11.1
>
>     KK> I dowloaded lme4_0.999375-34.tar.gz from CRAN and ran
>     KK> R CMD check on it and came up with
>     KK> * checking tests ...
>     KK> Running ?extras.R?
>     KK> Running ?lmer-1.R?
>     KK> ERROR
>     KK> Running the tests in 'tests/lmer-1.R' failed.
>     KK> Last 13 lines of output:
>     KK> +                  x3=rnorm(20,1))
>     >> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>     >> m1 <- lmer(y ~ x1 + x2|ff  , data = D)
>     >> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>     >> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>     >> stopifnot(identical(ranef(m0), ranef(m1)),
>     KK> +     identical(ranef(m2), ranef(m3)),
>     KK> +    inherits(tryCatch(lmer(y ~ x2|ff + x1, data = D), error  
>  = function(e)e),
>     KK> +                    "error"))
>     KK> Error: identical(ranef(m0), ranef(m1)) is not TRUE
>     KK> In addition: Warning message:
>     KK> In Ops.factor(ff, x1) : + not meaningful for factors
>     KK> Execution halted
>     KK> which I think is the reported problem.
>
> Yes, one of the typical two ones.
>
> The other one that Mac useRs, e.g.,  Kent Holsinger, in a private
> communication, have also encountered, is the even simpler case
> {earlier in lmer-1.R, so this means it did not trigger for
> *you*}:
>
> y <- (1:20)*pi
> x <- (1:20)^2
> group <- gl(2,10)
>
> stopifnot(require(lme4))
> sessionInfo()
>
> M2. <- lmer (y ~ 1 + x + (1 + x | group))
> M2  <- lmer (y ~     x + (    x | group))
>
> ## should be identical (and is .. well, not on all versions on Mac OSX):
> identical(ranef(M2), ranef(M2.))
> ## not  TRUE on some  Mac : OSX : R  combinations
>
>
> How can the linear algebra computations that start from
> identical numbers give different results *sometimes* on Mac OSX?
> Could it be that it uses some Mac specific BLAS/LAPACK
> optimizations which only happen *sometimes* ?
>
>     KK> I went into the file lmer-1.R which seems to be where this is
>     KK> coming from
>
> [correct]
>
>     KK> and sourced the lines indicated above and get
>
>     >> D <-  data.frame(y= rnorm(20,10), ff = gl(4,5),
>     KK> +                  x1=rnorm(20,3), x2=rnorm(20,7),
>     KK> +                  x3=rnorm(20,1))
>     >> m0 <- lmer(y ~ (x1 + x2)|ff, data = D)
>     >> m1 <- lmer(y ~ x1 + x2|ff  , data = D)
>     >> m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>     >> m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>     >> stopifnot(identical(ranef(m0), ranef(m1)),
>     KK> +           identical(ranef(m2), ranef(m3)),
>     KK> +           inherits(tryCatch(lmer(y ~ x2|ff + x1, data = D), error =
>     KK> function(e)e),
>     KK> +                    "error"))
>     KK> Error: identical(ranef(m2), ranef(m3)) is not TRUE
>     KK> In addition: Warning message:
>     KK> In Ops.factor(ff, x1) : + not meaningful for factors
>     >> identical(ranef(m0), ranef(m1))
>     KK> [1] TRUE
>
>     >> identical(ranef(m2), ranef(m3))
>     KK> [1] FALSE
>
>     KK> so it happens in an R session as well.
>
> yes.
> So,
>  m2 <- lmer(y ~ x1 + (x2|ff), data = D)
>  m3 <- lmer(y ~ (x2|ff) + x1, data = D)
>
> give differing results? How come?
> It seems as curious as the above simpler case,
> as really the initial starting matrices must be identical,
> unless the mac CPU does some things slightly differently
> depending on the exact machine configuration ???
>
> To me that could mean that even two identical R statements
> could give very slightly differing results, depending on the
> exact circumstance in which they are called {and of course I'm
> not talking about things that depend on options() or global
> variables or different search(), ...}
>
> ??
>
>     KK> Checking the ranef's
>     >> ranef(m2)
>     KK> $ff
>     KK> (Intercept)          x2
>     KK> 1  -1.4142222  0.15618464
>     KK> 2   0.4787662 -0.05287424
>     KK> 3   0.3193410 -0.03526755
>     KK> 4   1.7224362 -0.19022335
>
>     >> ranef(m3)
>     KK> $ff
>     KK> (Intercept)          x2
>     KK> 1  -1.4141930  0.15618142
>     KK> 2   0.4787944 -0.05287736
>     KK> 3   0.3193632 -0.03527000
>     KK> 4   1.7224652 -0.19022656
>
>     KK> They do indeed differ.  I'm on a 32 bit machine, could this be
>     KK> a 32/64 bit difference or something at the level of BLAS/ATLAS level?
>     KK> That's out of my league.  If I have time, I'll try it on a   
> 64 bit Mac, but I'm
>     KK> not likely to get back to that before about the beginning of August.
>
>
>     KK> Hope that this is useful.
>
>     KK> Ken
>
>     KK> --
>     KK> Ken Knoblauch
>     KK> Inserm U846
>     KK> Stem-cell and Brain Research Institute
>     KK> Department of Integrative Neurosciences
>     KK> 18 avenue du Doyen L?pine
>     KK> 69500 Bron
>     KK> France
>     KK> tel: +33 (0)4 72 91 34 77
>     KK> fax: +33 (0)4 72 91 34 61
>     KK> portable: +33 (0)6 84 10 64 10
>     KK> http://www.sbri.fr/members/kenneth-knoblauch.html
>
>     KK> _______________________________________________
>     KK> R-sig-mixed-models at r-project.org mailing list
>     KK> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Ken Knoblauch
Inserm U846
Stem-cell and Brain Research Institute
Department of Integrative Neurosciences
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.sbri.fr/members/kenneth-knoblauch.html



From daniel.lists at zeno.co.nz  Sat Jul 17 23:50:55 2010
From: daniel.lists at zeno.co.nz (Daniel Myall)
Date: Sun, 18 Jul 2010 09:50:55 +1200
Subject: [R-sig-ME] bug in identical()? [Was: Failure to load lme4 on
 Mac]
In-Reply-To: <270A5F5A-081B-4310-B269-4795713260BA@r-project.org>
References: <C8207D43.4236%mcmahons@si.edu>
	<4BFB0AE0.3090803@zeno.co.nz>	<loom.20100715T175631-148@post.gmane.org>	<AANLkTim4iUokYQZvcL99rhTQkHqIQ5wuESMAGCPu7qGe@mail.gmail.com>	<AANLkTil72csO0XA3-ZghXw62RUp9gMr-Df1Kx8Bi_Iq2@mail.gmail.com>	<AANLkTik15uc4QqaIxcwkhAd4HjpzCQ60MuKqiFDJyJnS@mail.gmail.com>	<08AD950F-C3DB-4E23-868B-0EFD94833014@anu.edu.au>	<AANLkTil7OZ91zRrGf3licxyYQTdgO7QFfLr5CJoyqPc5@mail.gmail.com>	<4C3F9E01.9050804@zeno.co.nz>	<AANLkTimy0SevCeJ87YhFis_fQg-S1ixMwaZF2Bk2K-Jq@mail.gmail.com>	<E1F79CC7-DB81-4916-B847-10C6C02DF2A8@r-project.org>	<loom.20100716T153900-860@post.gmane.org>	<19520.33619.18880.815822@lynne.math.ethz.ch>	<20100717070706.70fg8lchcskskgo0@imp.inserm.fr>
	<7E3C1A13-65AE-4E6F-9EB6-1EEB2B1677C0@anu.edu.au>
	<4C416EBE.4080204@zeno.co.nz>
	<D32F4A20-8620-4C43-A316-33CD816ACCF9@r-project.org>
	<270A5F5A-081B-4310-B269-4795713260BA@r-project.org>
Message-ID: <4C4225BF.10501@zeno.co.nz>

Hi Simon,

Unfortunately I don't think is the full story (there are actual small 
differences in the fits).

To match the lme4 tests the example should actually be:

library(lme4)
y<- (1:20)*pi
x<- (1:20)^2
group<- gl(2,10)
for (i in 1:10) {
M1<- lmer (y ~     x + (    x | group))
M2<- lmer (y ~     x + (    x | group))
print(identical(ranef(M1),ranef(M2)))
print(ranef(M1)$group-ranef(M2)$group)
}

Which gives me (the number of TRUE/FALSE and the order change on each run, even if restarting R):

[1] FALSE
     (Intercept)             x
1  6.613450e-06 -6.898626e-08
2 -6.613462e-06  6.898637e-08
[1] TRUE
   (Intercept) x
1           0 0
2           0 0
[1] FALSE
     (Intercept)             x
1 -6.613450e-06  6.898626e-08
2  6.613462e-06 -6.898637e-08
[1] FALSE
     (Intercept)             x
1  6.613450e-06 -6.898626e-08
2 -6.613462e-06  6.898637e-08
[1] TRUE
   (Intercept) x
1           0 0
2           0 0
[1] FALSE
     (Intercept)             x
1 -6.613450e-06  6.898626e-08
2  6.613462e-06 -6.898637e-08
[1] FALSE
     (Intercept)             x
1 -6.613450e-06  6.898626e-08
2  6.613462e-06 -6.898637e-08
[1] FALSE
     (Intercept)             x
1 -6.613450e-06  6.898626e-08
2  6.613462e-06 -6.898637e-08
[1] TRUE
   (Intercept) x
1           0 0
2           0 0
[1] TRUE
   (Intercept) x
1           0 0
2           0 0


Although only small differences, I assume lme4 should be deterministic?

Cheers,
Daniel




On 18/07/10 8:23 AM, Simon Urbanek wrote:
> Ok, I think I found the issue. I'm not sure why this varies by platform but the mismatch is due to the @env slot. Two environments are only identical if it is *the* same environment (i.e. the same pointer). However, M1 and M2 have different environments. The content of those environments is identical, but that is irrelevant as it's not the same pointer. Hence identical(M1, M2) fails (and serialize comparison succeeds as it cares only about the content).
>
> So the short story is don't use identical() to compare the models (unless you remove @env first). The long story raises the question whether identical() should really return FALSE for environments like
>    
>> identical(new.env(),new.env())
>>      
> [1] FALSE
> I can see arguments both ways but for the purposes of comparing values there should be an option that the above is TRUE.
>
> To be honest I don't see why this has not shown up on other platforms as that is a global issue... (I hope this is the full story - I didn't try all the combinations to see if setting @env to the same environment will appease identical() for all the models)
>
> Cheers,
> Simon
>
>
> On Jul 17, 2010, at 3:49 PM, Simon Urbanek wrote:
>
>    
>> Daniel,
>>
>> thanks for the test case. I did run it in valgrind but nothing showed up, however ...
>>
>> I'm starting to have a suspicion that this has something to do with identical() - look at this:
>>
>>      
>>> identical(M1,M2)
>>>        
>> [1] FALSE
>>      
>>> all(serialize(M1,NULL)==serialize(M2,NULL))
>>>        
>> [1] TRUE
>>      
>>> identical(unserialize(serialize(M1,NULL)),unserialize(serialize(M2,NULL)))
>>>        
>> [1] FALSE
>>      
>>> identical(unserialize(serialize(M1,NULL)),unserialize(serialize(M1,NULL)))
>>>        
>> [1] FALSE
>>
>> So I think this may be a bug in identical() mainly because of the last one. I'll need to take identical() apart to see where it fails ... I'm CCing this to R-devel as the current issue seems more like an R issue so more eyes can have a look ...
>>
>> Cheers,
>> Simon
>>
>>
>> [FWIW this is tested in today's R-devel (with valgrind level 2) on x86_64 OS X 10.6.4 with lme4 from CRAN and Matrix form R-devel Recommended]
>>
>>
>> On Jul 17, 2010, at 4:50 AM, Daniel Myall wrote:
>>
>>      
>>> I've done some further testing (R 2.11.1) and the issue is not limited to Leopard.
>>>
>>> Using the test:
>>>
>>> library(lme4)
>>> y<- (1:20)*pi
>>> x<- (1:20)^2
>>> group<- gl(2,10)
>>> for (i in 1:10) {
>>> M1<- lmer (y ~     x + (    x | group))
>>> M2<- lmer (y ~     x + (    x | group))
>>> print(identical(M1,M2))
>>> }
>>>
>>> For CRAN lme4 and Matrix:
>>>
>>> 32 bit on Leopard: R CMD check fails; different results (on most runs)
>>> 32 bit on Snow Leopard: R CMD check passes; different results (on some runs).
>>> 64 bit on Snow Leopard: R CMD check passes; identical results
>>>
>>> For SVN version of Matrix with CRAN lme4:
>>>
>>> 32 bit on Snow Leopard: different results (on all runs).
>>> 64 bit on Snow Leopard: different results (on all runs)
>>>
>>> For SVN version of Matrix with SVN lme4a:
>>>
>>> 32 bit on Snow Leopard: different results (on all runs).
>>> 64 bit on Snow Leopard: identical results
>>>
>>> I couldn't reproduce on Linux 32/64bit. Is it time to jump into valgrind to try and find the cause?
>>>
>>> Cheers,
>>> Daniel
>>>
>>>
>>>
>>> On 17/07/10 5:51 PM, John Maindonald wrote:
>>>        
>>>> In principle, maybe a Snow Leopard version might be posted
>>>> as an alternative, if someone can provide one.  But I take it
>>>> that the issue is now a bit wider than tests that fail on Leopard
>>>> vs passing on Snow Leopard?
>>>>
>>>>          
>>>
>>>        
>>      
>



From m.fairbrother at bristol.ac.uk  Sun Jul 18 00:20:12 2010
From: m.fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Sun, 18 Jul 2010 00:20:12 +0200
Subject: [R-sig-ME] spatial correlation structures in multilevel models?
In-Reply-To: <4C40230C.8030005@ufz.de>
References: <mailman.5.1278756002.27661.r-sig-mixed-models@r-project.org>
	<9945D065-DFFF-4C54-AF70-C5C29A9B0267@bristol.ac.uk>
	<005b01cb21ee$c4657e70$4d307b50$@msu.edu>
	<84DB2959-66D8-4311-9A76-1398B48DD915@bristol.ac.uk>
	<4C40230C.8030005@ufz.de>
Message-ID: <D0DECDC0-246B-4469-B820-C4B898345824@bristol.ac.uk>

Hi Jan,

My understanding (and someone else can correct me if I'm wrong) is that nlme *can* take into account a *lowest*-level unit's location--even if some of those units occupy the same precise location, as long as any two units located in the same place are members of *different* higher-level units. In my case, all the lower-level units belonging to a given higher-level unit share the same location.

I'm not sure *why* nlme has these particular capacities and limits, but that's what I understand them to be.

Cheers,
Malcolm

Dr Malcolm Fairbrother
Lecturer
School of Geographical Sciences
University of Bristol



On 16 Jul 2010, at 11:14, Jan Hanspach wrote:

> Hi Malcolm,
> I just missed the argument why defining a correlation structure in nlme would not be an option? Could you expand on this?
> Thanks
> Jan
> 
> Malcolm Fairbrother schrieb:
>> Thanks to both Ben Bolker and Steven Pierce for responses to this question--their general consensus seems to be that WinBUGS would be an option, but lme4 and nlme won't work.
>> 
>> I also subsequently discovered that MLwiN can fit multilevel models taking into account the location of the higher-level units. It can do that because it can fit "multiple membership" multilevel models (e.g., where a given student is nested within more than one school for a single observation period, and the memberships are weighted in some way which sums to 1). The trick for spatial multilevel models is to treat each lower-level unit as a member of both the higher-level unit in which it is located (first, standard random effect), and of all of its weighted neighbouring units (second random effect).
>> 
>> - Malcolm
>> 
>> 
>> Dr Malcolm Fairbrother
>> Lecturer
>> School of Geographical Sciences
>> University of Bristol
>> 
>> 
>> 
>> On 12 Jul 2010, at 20:19, Steven J. Pierce wrote:
>> 
>>  
>>> You might also try doing that model with WinBUGS. There are packages that
>>> will help you move the data out to WinBUGS from R and then bring the results
>>> back into R for post processing. 
>>> Steven J. Pierce, Ph.D. Associate Director Center for Statistical Training & Consulting (CSTAT) Michigan State University E-mail: pierces1 at msu.edu Web: http://www.cstat.msu.edu 
>>> -----Original Message-----
>>> From: Malcolm Fairbrother [mailto:m.fairbrother at bristol.ac.uk] Sent: Monday, July 12, 2010 12:00 PM
>>> To: r-sig-mixed-models at r-project.org
>>> Subject: [R-sig-ME] spatial correlation structures in multilevel models?
>>> 
>>> Dear all,
>>> 
>>> I'm interested in fitting a three-level model where the 1st level units are
>>> individuals, and the 2nd and 3rd levels are (nested) geographical units,
>>> whose locations (centroids) are known. (The precise location of each
>>> individual is not known--just the unit to which he/she belongs.) I'd like to
>>> exploit the fact that the locations are known, since people in
>>> neighbouring/nearby units should be more similar than people in units that
>>> are distant from each other. To be specific, I'd like a given unit's random
>>> intercept to be adjusted according to the data from nearby/neighbouring
>>> units--especially for instances where I have few observations for a unit but
>>> lots of observations for neighbouring units.
>>> 
>>> My understanding is that lme4 and MCMCglmm cannot do this, in the sense that
>>> they cannot specify spatial correlation structures. Using these packages, at
>>> most, some characteristic of a unit's location (e.g., latitude, distance
>>> from X point) and/or some (weighted) characteristic of a unit's neighbour(s)
>>> could be included as a fixed effect.
>>> 
>>> However, as I understand it, nlme can do this, using the "correlation"
>>> argument (e.g., "correlation = corExp(form = ~ ...").
>>> 
>>> Is this correct? Will nlme adjust the random intercepts in such a way? And
>>> would it be a problem that it's the higher-level units, not the lowest-level
>>> units, for which I know the locations?
>>> 
>>> If I'm being over-ambitious/demanding here, no worries at all--I'm just
>>> curious whether this is possible. I don't have the data yet.
>>> 
>>> Many thanks,
>>> Malcolm
>>> 
>>> 
>>> Dr Malcolm Fairbrother
>>> Lecturer
>>> School of Geographical Sciences
>>> University of Bristol
>>> 
>>> 
>>> 
>>>    
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>  
> 



From simon.urbanek at r-project.org  Sat Jul 17 21:49:08 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sat, 17 Jul 2010 15:49:08 -0400
Subject: [R-sig-ME] bug in identical()? [Was: Failure to load lme4 on Mac]
In-Reply-To: <4C416EBE.4080204@zeno.co.nz>
References: <C8207D43.4236%mcmahons@si.edu>
	<4BFB0AE0.3090803@zeno.co.nz>	<loom.20100715T175631-148@post.gmane.org>	<AANLkTim4iUokYQZvcL99rhTQkHqIQ5wuESMAGCPu7qGe@mail.gmail.com>	<AANLkTil72csO0XA3-ZghXw62RUp9gMr-Df1Kx8Bi_Iq2@mail.gmail.com>	<AANLkTik15uc4QqaIxcwkhAd4HjpzCQ60MuKqiFDJyJnS@mail.gmail.com>	<08AD950F-C3DB-4E23-868B-0EFD94833014@anu.edu.au>	<AANLkTil7OZ91zRrGf3licxyYQTdgO7QFfLr5CJoyqPc5@mail.gmail.com>	<4C3F9E01.9050804@zeno.co.nz>	<AANLkTimy0SevCeJ87YhFis_fQg-S1ixMwaZF2Bk2K-Jq@mail.gmail.com>	<E1F79CC7-DB81-4916-B847-10C6C02DF2A8@r-project.org>	<loom.20100716T153900-860@post.gmane.org>	<19520.33619.18880.815822@lynne.math.ethz.ch>	<20100717070706.70fg8lchcskskgo0@imp.inserm.fr>
	<7E3C1A13-65AE-4E6F-9EB6-1EEB2B1677C0@anu.edu.au>
	<4C416EBE.4080204@zeno.co.nz>
Message-ID: <D32F4A20-8620-4C43-A316-33CD816ACCF9@r-project.org>

Daniel,

thanks for the test case. I did run it in valgrind but nothing showed up, however ... 

I'm starting to have a suspicion that this has something to do with identical() - look at this:

> identical(M1,M2)
[1] FALSE
> all(serialize(M1,NULL)==serialize(M2,NULL))
[1] TRUE
> identical(unserialize(serialize(M1,NULL)),unserialize(serialize(M2,NULL)))
[1] FALSE
> identical(unserialize(serialize(M1,NULL)),unserialize(serialize(M1,NULL)))
[1] FALSE

So I think this may be a bug in identical() mainly because of the last one. I'll need to take identical() apart to see where it fails ... I'm CCing this to R-devel as the current issue seems more like an R issue so more eyes can have a look ...

Cheers,
Simon


[FWIW this is tested in today's R-devel (with valgrind level 2) on x86_64 OS X 10.6.4 with lme4 from CRAN and Matrix form R-devel Recommended]


On Jul 17, 2010, at 4:50 AM, Daniel Myall wrote:

> I've done some further testing (R 2.11.1) and the issue is not limited to Leopard.
> 
> Using the test:
> 
> library(lme4)
> y <- (1:20)*pi
> x <- (1:20)^2
> group <- gl(2,10)
> for (i in 1:10) {
>  M1 <- lmer (y ~     x + (    x | group))
>  M2 <- lmer (y ~     x + (    x | group))
>  print(identical(M1,M2))
> }
> 
> For CRAN lme4 and Matrix:
> 
> 32 bit on Leopard: R CMD check fails; different results (on most runs)
> 32 bit on Snow Leopard: R CMD check passes; different results (on some runs).
> 64 bit on Snow Leopard: R CMD check passes; identical results
> 
> For SVN version of Matrix with CRAN lme4:
> 
> 32 bit on Snow Leopard: different results (on all runs).
> 64 bit on Snow Leopard: different results (on all runs)
> 
> For SVN version of Matrix with SVN lme4a:
> 
> 32 bit on Snow Leopard: different results (on all runs).
> 64 bit on Snow Leopard: identical results
> 
> I couldn't reproduce on Linux 32/64bit. Is it time to jump into valgrind to try and find the cause?
> 
> Cheers,
> Daniel
> 
> 
> 
> On 17/07/10 5:51 PM, John Maindonald wrote:
>> In principle, maybe a Snow Leopard version might be posted
>> as an alternative, if someone can provide one.  But I take it
>> that the issue is now a bit wider than tests that fail on Leopard
>> vs passing on Snow Leopard?
>>   
> 
> 



From simon.urbanek at r-project.org  Sat Jul 17 22:23:24 2010
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sat, 17 Jul 2010 16:23:24 -0400
Subject: [R-sig-ME] bug in identical()? [Was: Failure to load lme4 on
	Mac]
In-Reply-To: <D32F4A20-8620-4C43-A316-33CD816ACCF9@r-project.org>
References: <C8207D43.4236%mcmahons@si.edu>
	<4BFB0AE0.3090803@zeno.co.nz>	<loom.20100715T175631-148@post.gmane.org>	<AANLkTim4iUokYQZvcL99rhTQkHqIQ5wuESMAGCPu7qGe@mail.gmail.com>	<AANLkTil72csO0XA3-ZghXw62RUp9gMr-Df1Kx8Bi_Iq2@mail.gmail.com>	<AANLkTik15uc4QqaIxcwkhAd4HjpzCQ60MuKqiFDJyJnS@mail.gmail.com>	<08AD950F-C3DB-4E23-868B-0EFD94833014@anu.edu.au>	<AANLkTil7OZ91zRrGf3licxyYQTdgO7QFfLr5CJoyqPc5@mail.gmail.com>	<4C3F9E01.9050804@zeno.co.nz>	<AANLkTimy0SevCeJ87YhFis_fQg-S1ixMwaZF2Bk2K-Jq@mail.gmail.com>	<E1F79CC7-DB81-4916-B847-10C6C02DF2A8@r-project.org>	<loom.20100716T153900-860@post.gmane.org>	<19520.33619.18880.815822@lynne.math.ethz.ch>	<20100717070706.70fg8lchcskskgo0@imp.inserm.fr>
	<7E3C1A13-65AE-4E6F-9EB6-1EEB2B1677C0@anu.edu.au>
	<4C416EBE.4080204@zeno.co.nz>
	<D32F4A20-8620-4C43-A316-33CD816ACCF9@r-project.org>
Message-ID: <270A5F5A-081B-4310-B269-4795713260BA@r-project.org>

Ok, I think I found the issue. I'm not sure why this varies by platform but the mismatch is due to the @env slot. Two environments are only identical if it is *the* same environment (i.e. the same pointer). However, M1 and M2 have different environments. The content of those environments is identical, but that is irrelevant as it's not the same pointer. Hence identical(M1, M2) fails (and serialize comparison succeeds as it cares only about the content).

So the short story is don't use identical() to compare the models (unless you remove @env first). The long story raises the question whether identical() should really return FALSE for environments like
> identical(new.env(),new.env())
[1] FALSE
I can see arguments both ways but for the purposes of comparing values there should be an option that the above is TRUE.

To be honest I don't see why this has not shown up on other platforms as that is a global issue... (I hope this is the full story - I didn't try all the combinations to see if setting @env to the same environment will appease identical() for all the models)

Cheers,
Simon


On Jul 17, 2010, at 3:49 PM, Simon Urbanek wrote:

> Daniel,
> 
> thanks for the test case. I did run it in valgrind but nothing showed up, however ... 
> 
> I'm starting to have a suspicion that this has something to do with identical() - look at this:
> 
>> identical(M1,M2)
> [1] FALSE
>> all(serialize(M1,NULL)==serialize(M2,NULL))
> [1] TRUE
>> identical(unserialize(serialize(M1,NULL)),unserialize(serialize(M2,NULL)))
> [1] FALSE
>> identical(unserialize(serialize(M1,NULL)),unserialize(serialize(M1,NULL)))
> [1] FALSE
> 
> So I think this may be a bug in identical() mainly because of the last one. I'll need to take identical() apart to see where it fails ... I'm CCing this to R-devel as the current issue seems more like an R issue so more eyes can have a look ...
> 
> Cheers,
> Simon
> 
> 
> [FWIW this is tested in today's R-devel (with valgrind level 2) on x86_64 OS X 10.6.4 with lme4 from CRAN and Matrix form R-devel Recommended]
> 
> 
> On Jul 17, 2010, at 4:50 AM, Daniel Myall wrote:
> 
>> I've done some further testing (R 2.11.1) and the issue is not limited to Leopard.
>> 
>> Using the test:
>> 
>> library(lme4)
>> y <- (1:20)*pi
>> x <- (1:20)^2
>> group <- gl(2,10)
>> for (i in 1:10) {
>> M1 <- lmer (y ~     x + (    x | group))
>> M2 <- lmer (y ~     x + (    x | group))
>> print(identical(M1,M2))
>> }
>> 
>> For CRAN lme4 and Matrix:
>> 
>> 32 bit on Leopard: R CMD check fails; different results (on most runs)
>> 32 bit on Snow Leopard: R CMD check passes; different results (on some runs).
>> 64 bit on Snow Leopard: R CMD check passes; identical results
>> 
>> For SVN version of Matrix with CRAN lme4:
>> 
>> 32 bit on Snow Leopard: different results (on all runs).
>> 64 bit on Snow Leopard: different results (on all runs)
>> 
>> For SVN version of Matrix with SVN lme4a:
>> 
>> 32 bit on Snow Leopard: different results (on all runs).
>> 64 bit on Snow Leopard: identical results
>> 
>> I couldn't reproduce on Linux 32/64bit. Is it time to jump into valgrind to try and find the cause?
>> 
>> Cheers,
>> Daniel
>> 
>> 
>> 
>> On 17/07/10 5:51 PM, John Maindonald wrote:
>>> In principle, maybe a Snow Leopard version might be posted
>>> as an alternative, if someone can provide one.  But I take it
>>> that the issue is now a bit wider than tests that fail on Leopard
>>> vs passing on Snow Leopard?
>>> 
>> 
>> 
> 



From daniel.lists at zeno.co.nz  Sun Jul 18 11:35:37 2010
From: daniel.lists at zeno.co.nz (Daniel Myall)
Date: Sun, 18 Jul 2010 21:35:37 +1200
Subject: [R-sig-ME] bug in identical()? [Was: Failure to load lme4 on
 Mac]
In-Reply-To: <4C4225BF.10501@zeno.co.nz>
References: <C8207D43.4236%mcmahons@si.edu>	<4BFB0AE0.3090803@zeno.co.nz>	<loom.20100715T175631-148@post.gmane.org>	<AANLkTim4iUokYQZvcL99rhTQkHqIQ5wuESMAGCPu7qGe@mail.gmail.com>	<AANLkTil72csO0XA3-ZghXw62RUp9gMr-Df1Kx8Bi_Iq2@mail.gmail.com>	<AANLkTik15uc4QqaIxcwkhAd4HjpzCQ60MuKqiFDJyJnS@mail.gmail.com>	<08AD950F-C3DB-4E23-868B-0EFD94833014@anu.edu.au>	<AANLkTil7OZ91zRrGf3licxyYQTdgO7QFfLr5CJoyqPc5@mail.gmail.com>	<4C3F9E01.9050804@zeno.co.nz>	<AANLkTimy0SevCeJ87YhFis_fQg-S1ixMwaZF2Bk2K-Jq@mail.gmail.com>	<E1F79CC7-DB81-4916-B847-10C6C02DF2A8@r-project.org>	<loom.20100716T153900-860@post.gmane.org>	<19520.33619.18880.815822@lynne.math.ethz.ch>	<20100717070706.70fg8lchcskskgo0@imp.inserm.fr>	<7E3C1A13-65AE-4E6F-9EB6-1EEB2B1677C0@anu.edu.au>	<4C416EBE.4080204@zeno.co.nz>	<D32F4A20-8620-4C43-A316-33CD816ACCF9@r-project.org>	<270A5F5A-081B-4310-B269-4795713260BA@r-project.org>
	<4C4225BF.10501@zeno.co.nz>
Message-ID: <4C42CAE9.5070609@zeno.co.nz>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100718/3cec6b19/attachment.pl>

From reinhold.kliegl at gmail.com  Sun Jul 18 12:28:55 2010
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Sun, 18 Jul 2010 12:28:55 +0200
Subject: [R-sig-ME] bug in identical()? [Was: Failure to load lme4 on
	Mac]
In-Reply-To: <4C42CAE9.5070609@zeno.co.nz>
References: <C8207D43.4236%mcmahons@si.edu> <4BFB0AE0.3090803@zeno.co.nz>
	<loom.20100715T175631-148@post.gmane.org>
	<AANLkTim4iUokYQZvcL99rhTQkHqIQ5wuESMAGCPu7qGe@mail.gmail.com>
	<AANLkTil72csO0XA3-ZghXw62RUp9gMr-Df1Kx8Bi_Iq2@mail.gmail.com>
	<AANLkTik15uc4QqaIxcwkhAd4HjpzCQ60MuKqiFDJyJnS@mail.gmail.com>
	<08AD950F-C3DB-4E23-868B-0EFD94833014@anu.edu.au>
	<AANLkTil7OZ91zRrGf3licxyYQTdgO7QFfLr5CJoyqPc5@mail.gmail.com>
	<4C3F9E01.9050804@zeno.co.nz>
	<AANLkTimy0SevCeJ87YhFis_fQg-S1ixMwaZF2Bk2K-Jq@mail.gmail.com>
	<E1F79CC7-DB81-4916-B847-10C6C02DF2A8@r-project.org>
	<loom.20100716T153900-860@post.gmane.org>
	<19520.33619.18880.815822@lynne.math.ethz.ch>
	<20100717070706.70fg8lchcskskgo0@imp.inserm.fr>
	<7E3C1A13-65AE-4E6F-9EB6-1EEB2B1677C0@anu.edu.au>
	<4C416EBE.4080204@zeno.co.nz>
	<D32F4A20-8620-4C43-A316-33CD816ACCF9@r-project.org>
	<270A5F5A-081B-4310-B269-4795713260BA@r-project.org>
	<4C4225BF.10501@zeno.co.nz> <4C42CAE9.5070609@zeno.co.nz>
Message-ID: <AANLkTimd-q7PBYfAMuyTKKXk1Rh6TEQK6SP6cvgdyol4@mail.gmail.com>

First of all, I really appreciate these efforts.

Changing to R BLAS did not do the trick for me on Mac OS X (10.5.8).
Here is the protocol.

###
Last login: Sun Jul 18 12:04:10 on ttys000
Reinhold:~ kliegl$ bash

~ > cd /Library/Frameworks/R.framework/Resources/lib
/Library/Frameworks/R.framework/Resources/lib > ls
i386                    libRblas.vecLib.dylib   libreadline.5.2.dylib
libR.dylib              libRlapack.dylib        libreadline.dylib
libRblas.0.dylib        libgcc_s.1.dylib        ppc
libRblas.dylib          libgfortran.2.dylib     x86_64

/Library/Frameworks/R.framework/Resources/lib > ln -sf
libRblas.0.dylib libRblas.dylib
/Library/Frameworks/R.framework/Resources/lib > R

R version 2.11.1 Patched (2010-07-16 r52550)
Copyright (C) 2010 The R Foundation for Statistical Computing
ISBN 3-900051-07-0

< clipped>

> library(lme4)

<clipped>

> y <- (1:6)*pi # 3.14
> x <- (1:6)^2
> group <- gl(2,3)
> for (i in 1:10) {
+ M1 <- lmer (y ~     x + (x | group))
+ M2 <- lmer (y ~     x + (x | group))
+ print(identical(ranef(M1),ranef(M2)))
+ print(identical(coef(M1),coef(M2)))
+  }
[1] TRUE
[1] TRUE
[1] TRUE
[1] TRUE
[1] FALSE
[1] FALSE
[1] TRUE
[1] TRUE
[1] FALSE
[1] FALSE
[1] FALSE
[1] FALSE
[1] TRUE
[1] TRUE
[1] FALSE
[1] FALSE
[1] TRUE
[1] TRUE
[1] TRUE
[1] TRUE

> sessionInfo()
R version 2.11.1 Patched (2010-07-16 r52550)
i386-apple-darwin9.8.0

locale:
[1] de_DE/de_DE/C/C/de_DE/de_DE

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_0.999375-34   Matrix_0.999375-41 lattice_0.18-8

loaded via a namespace (and not attached):
[1] grid_2.11.1   nlme_3.1-96   stats4_2.11.1
>
#####

Did I do something wrong in getting the correct library? Is there a
command to check whether R BLAS is used?

Using require(lme4) instead of library(lme4) did not make a difference either.

Many thanks again,
Reinhold Kliegl


On Sun, Jul 18, 2010 at 11:35 AM, Daniel Myall <daniel.lists at zeno.co.nz> wrote:
> Hi Simon,
>
> The Apple vecLib BLAS appears to be the cause of the strangeness (at
> least on my machine).
>
> Following:
> http://cran.r-project.org/bin/macosx/RMacOSX-FAQ.html#Which-BLAS-is-used-and-how-can-it-be-changed_003f
>
>
> I changed to the R BLAS and everything now works as it should (i.e., for
> certain source data, lme4 now gives the same solution on multiple runs
> instead of randomly giving one of two different "solutions" on each
> run). The FAQ does note in relation to vecLib BLAS " Although fast, it
> is not under our control and may possibly deliver inaccurate results."
> which appears to be true, at least with lme4.
>
> What BLAS does the CRAN build machine use? If it does use the vecLib
> BLAS is there a case for changing to R BLAS (maybe only when
> building/checking lme4)?
>
> Cheers,
> Daniel
>
> On 18/07/10 9:50 AM, Daniel Myall wrote:
>> Hi Simon,
>>
>> Unfortunately I don't think is the full story (there are actual small
>> differences in the fits).
>>
>> To match the lme4 tests the example should actually be:
>>
>> library(lme4)
>> y<- (1:20)*pi
>> x<- (1:20)^2
>> group<- gl(2,10)
>> for (i in 1:10) {
>> M1<- lmer (y ~ ? ? x + ( ? ?x | group))
>> M2<- lmer (y ~ ? ? x + ( ? ?x | group))
>> print(identical(ranef(M1),ranef(M2)))
>> print(ranef(M1)$group-ranef(M2)$group)
>> }
>>
>> Which gives me (the number of TRUE/FALSE and the order change on each
>> run, even if restarting R):
>>
>> [1] FALSE
>> ? ? (Intercept) ? ? ? ? ? ? x
>> 1 ?6.613450e-06 -6.898626e-08
>> 2 -6.613462e-06 ?6.898637e-08
>> [1] TRUE
>> ? (Intercept) x
>> 1 ? ? ? ? ? 0 0
>> 2 ? ? ? ? ? 0 0
>> [1] FALSE
>> ? ? (Intercept) ? ? ? ? ? ? x
>> 1 -6.613450e-06 ?6.898626e-08
>> 2 ?6.613462e-06 -6.898637e-08
>> [1] FALSE
>> ? ? (Intercept) ? ? ? ? ? ? x
>> 1 ?6.613450e-06 -6.898626e-08
>> 2 -6.613462e-06 ?6.898637e-08
>> [1] TRUE
>> ? (Intercept) x
>> 1 ? ? ? ? ? 0 0
>> 2 ? ? ? ? ? 0 0
>> [1] FALSE
>> ? ? (Intercept) ? ? ? ? ? ? x
>> 1 -6.613450e-06 ?6.898626e-08
>> 2 ?6.613462e-06 -6.898637e-08
>> [1] FALSE
>> ? ? (Intercept) ? ? ? ? ? ? x
>> 1 -6.613450e-06 ?6.898626e-08
>> 2 ?6.613462e-06 -6.898637e-08
>> [1] FALSE
>> ? ? (Intercept) ? ? ? ? ? ? x
>> 1 -6.613450e-06 ?6.898626e-08
>> 2 ?6.613462e-06 -6.898637e-08
>> [1] TRUE
>> ? (Intercept) x
>> 1 ? ? ? ? ? 0 0
>> 2 ? ? ? ? ? 0 0
>> [1] TRUE
>> ? (Intercept) x
>> 1 ? ? ? ? ? 0 0
>> 2 ? ? ? ? ? 0 0
>>
>>
>> Although only small differences, I assume lme4 should be deterministic?
>>
>> Cheers,
>> Daniel
>>
>>
>>
>>
>> On 18/07/10 8:23 AM, Simon Urbanek wrote:
>>> Ok, I think I found the issue. I'm not sure why this varies by
>>> platform but the mismatch is due to the @env slot. Two environments
>>> are only identical if it is *the* same environment (i.e. the same
>>> pointer). However, M1 and M2 have different environments. The content
>>> of those environments is identical, but that is irrelevant as it's
>>> not the same pointer. Hence identical(M1, M2) fails (and serialize
>>> comparison succeeds as it cares only about the content).
>>>
>>> So the short story is don't use identical() to compare the models
>>> (unless you remove @env first). The long story raises the question
>>> whether identical() should really return FALSE for environments like
>>>> identical(new.env(),new.env())
>>> [1] FALSE
>>> I can see arguments both ways but for the purposes of comparing
>>> values there should be an option that the above is TRUE.
>>>
>>> To be honest I don't see why this has not shown up on other platforms
>>> as that is a global issue... (I hope this is the full story - I
>>> didn't try all the combinations to see if setting @env to the same
>>> environment will appease identical() for all the models)
>>>
>>> Cheers,
>>> Simon
>>>
>>>
>>> On Jul 17, 2010, at 3:49 PM, Simon Urbanek wrote:
>>>
>>>> Daniel,
>>>>
>>>> thanks for the test case. I did run it in valgrind but nothing
>>>> showed up, however ...
>>>>
>>>> I'm starting to have a suspicion that this has something to do with
>>>> identical() - look at this:
>>>>
>>>>> identical(M1,M2)
>>>> [1] FALSE
>>>>> all(serialize(M1,NULL)==serialize(M2,NULL))
>>>> [1] TRUE
>>>>> identical(unserialize(serialize(M1,NULL)),unserialize(serialize(M2,NULL)))
>>>>>
>>>> [1] FALSE
>>>>> identical(unserialize(serialize(M1,NULL)),unserialize(serialize(M1,NULL)))
>>>>>
>>>> [1] FALSE
>>>>
>>>> So I think this may be a bug in identical() mainly because of the
>>>> last one. I'll need to take identical() apart to see where it fails
>>>> ... I'm CCing this to R-devel as the current issue seems more like
>>>> an R issue so more eyes can have a look ...
>>>>
>>>> Cheers,
>>>> Simon
>>>>
>>>>
>>>> [FWIW this is tested in today's R-devel (with valgrind level 2) on
>>>> x86_64 OS X 10.6.4 with lme4 from CRAN and Matrix form R-devel
>>>> Recommended]
>>>>
>>>>
>>>> On Jul 17, 2010, at 4:50 AM, Daniel Myall wrote:
>>>>
>>>>> I've done some further testing (R 2.11.1) and the issue is not
>>>>> limited to Leopard.
>>>>>
>>>>> Using the test:
>>>>>
>>>>> library(lme4)
>>>>> y<- (1:20)*pi
>>>>> x<- (1:20)^2
>>>>> group<- gl(2,10)
>>>>> for (i in 1:10) {
>>>>> M1<- lmer (y ~ ? ? x + ( ? ?x | group))
>>>>> M2<- lmer (y ~ ? ? x + ( ? ?x | group))
>>>>> print(identical(M1,M2))
>>>>> }
>>>>>
>>>>> For CRAN lme4 and Matrix:
>>>>>
>>>>> 32 bit on Leopard: R CMD check fails; different results (on most runs)
>>>>> 32 bit on Snow Leopard: R CMD check passes; different results (on
>>>>> some runs).
>>>>> 64 bit on Snow Leopard: R CMD check passes; identical results
>>>>>
>>>>> For SVN version of Matrix with CRAN lme4:
>>>>>
>>>>> 32 bit on Snow Leopard: different results (on all runs).
>>>>> 64 bit on Snow Leopard: different results (on all runs)
>>>>>
>>>>> For SVN version of Matrix with SVN lme4a:
>>>>>
>>>>> 32 bit on Snow Leopard: different results (on all runs).
>>>>> 64 bit on Snow Leopard: identical results
>>>>>
>>>>> I couldn't reproduce on Linux 32/64bit. Is it time to jump into
>>>>> valgrind to try and find the cause?
>>>>>
>>>>> Cheers,
>>>>> Daniel
>>>>>
>>>>>
>>>>>
>>>>> On 17/07/10 5:51 PM, John Maindonald wrote:
>>>>>> In principle, maybe a Snow Leopard version might be posted
>>>>>> as an alternative, if someone can provide one. ?But I take it
>>>>>> that the issue is now a bit wider than tests that fail on Leopard
>>>>>> vs passing on Snow Leopard?
>>>>>>
>>>>>
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From reinhold.kliegl at gmail.com  Sun Jul 18 13:20:23 2010
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Sun, 18 Jul 2010 13:20:23 +0200
Subject: [R-sig-ME] bug in identical()? [Was: Failure to load lme4 on
	Mac]
In-Reply-To: <AANLkTimd-q7PBYfAMuyTKKXk1Rh6TEQK6SP6cvgdyol4@mail.gmail.com>
References: <C8207D43.4236%mcmahons@si.edu> <4BFB0AE0.3090803@zeno.co.nz>
	<loom.20100715T175631-148@post.gmane.org>
	<AANLkTim4iUokYQZvcL99rhTQkHqIQ5wuESMAGCPu7qGe@mail.gmail.com>
	<AANLkTil72csO0XA3-ZghXw62RUp9gMr-Df1Kx8Bi_Iq2@mail.gmail.com>
	<AANLkTik15uc4QqaIxcwkhAd4HjpzCQ60MuKqiFDJyJnS@mail.gmail.com>
	<08AD950F-C3DB-4E23-868B-0EFD94833014@anu.edu.au>
	<AANLkTil7OZ91zRrGf3licxyYQTdgO7QFfLr5CJoyqPc5@mail.gmail.com>
	<4C3F9E01.9050804@zeno.co.nz>
	<AANLkTimy0SevCeJ87YhFis_fQg-S1ixMwaZF2Bk2K-Jq@mail.gmail.com>
	<E1F79CC7-DB81-4916-B847-10C6C02DF2A8@r-project.org>
	<loom.20100716T153900-860@post.gmane.org>
	<19520.33619.18880.815822@lynne.math.ethz.ch>
	<20100717070706.70fg8lchcskskgo0@imp.inserm.fr>
	<7E3C1A13-65AE-4E6F-9EB6-1EEB2B1677C0@anu.edu.au>
	<4C416EBE.4080204@zeno.co.nz>
	<D32F4A20-8620-4C43-A316-33CD816ACCF9@r-project.org>
	<270A5F5A-081B-4310-B269-4795713260BA@r-project.org>
	<4C4225BF.10501@zeno.co.nz> <4C42CAE9.5070609@zeno.co.nz>
	<AANLkTimd-q7PBYfAMuyTKKXk1Rh6TEQK6SP6cvgdyol4@mail.gmail.com>
Message-ID: <AANLkTimxEaE-GoeIeIMKgKbrEQQLb-I3DfaHkw9sy8xE@mail.gmail.com>

Actually, what makes a difference on my machine for this test example
is switching to
`R --arch x86_64'

After this switch linking either R BLAS and vecLIB BLAS checked out
fine--at least for 100 tests of the example.
( I think ...).

Reinhold Kliegl

On Sun, Jul 18, 2010 at 12:28 PM, Reinhold Kliegl
<reinhold.kliegl at gmail.com> wrote:
> First of all, I really appreciate these efforts.
>
> Changing to R BLAS did not do the trick for me on Mac OS X (10.5.8).
> Here is the protocol.
>
> ###
> Last login: Sun Jul 18 12:04:10 on ttys000
> Reinhold:~ kliegl$ bash
>
> ~ > cd /Library/Frameworks/R.framework/Resources/lib
> /Library/Frameworks/R.framework/Resources/lib > ls
> i386 ? ? ? ? ? ? ? ? ? ?libRblas.vecLib.dylib ? libreadline.5.2.dylib
> libR.dylib ? ? ? ? ? ? ?libRlapack.dylib ? ? ? ?libreadline.dylib
> libRblas.0.dylib ? ? ? ?libgcc_s.1.dylib ? ? ? ?ppc
> libRblas.dylib ? ? ? ? ?libgfortran.2.dylib ? ? x86_64
>
> /Library/Frameworks/R.framework/Resources/lib > ln -sf
> libRblas.0.dylib libRblas.dylib
> /Library/Frameworks/R.framework/Resources/lib > R
>
> R version 2.11.1 Patched (2010-07-16 r52550)
> Copyright (C) 2010 The R Foundation for Statistical Computing
> ISBN 3-900051-07-0
>
> < clipped>
>
>> library(lme4)
>
> <clipped>
>
>> y <- (1:6)*pi # 3.14
>> x <- (1:6)^2
>> group <- gl(2,3)
>> for (i in 1:10) {
> + M1 <- lmer (y ~ ? ? x + (x | group))
> + M2 <- lmer (y ~ ? ? x + (x | group))
> + print(identical(ranef(M1),ranef(M2)))
> + print(identical(coef(M1),coef(M2)))
> + ?}
> [1] TRUE
> [1] TRUE
> [1] TRUE
> [1] TRUE
> [1] FALSE
> [1] FALSE
> [1] TRUE
> [1] TRUE
> [1] FALSE
> [1] FALSE
> [1] FALSE
> [1] FALSE
> [1] TRUE
> [1] TRUE
> [1] FALSE
> [1] FALSE
> [1] TRUE
> [1] TRUE
> [1] TRUE
> [1] TRUE
>
>> sessionInfo()
> R version 2.11.1 Patched (2010-07-16 r52550)
> i386-apple-darwin9.8.0
>
> locale:
> [1] de_DE/de_DE/C/C/de_DE/de_DE
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>
> other attached packages:
> [1] lme4_0.999375-34 ? Matrix_0.999375-41 lattice_0.18-8
>
> loaded via a namespace (and not attached):
> [1] grid_2.11.1 ? nlme_3.1-96 ? stats4_2.11.1
>>
> #####
>
> Did I do something wrong in getting the correct library? Is there a
> command to check whether R BLAS is used?
>
> Using require(lme4) instead of library(lme4) did not make a difference either.
>
> Many thanks again,
> Reinhold Kliegl
>
>
> On Sun, Jul 18, 2010 at 11:35 AM, Daniel Myall <daniel.lists at zeno.co.nz> wrote:
>> Hi Simon,
>>
>> The Apple vecLib BLAS appears to be the cause of the strangeness (at
>> least on my machine).
>>
>> Following:
>> http://cran.r-project.org/bin/macosx/RMacOSX-FAQ.html#Which-BLAS-is-used-and-how-can-it-be-changed_003f
>>
>>
>> I changed to the R BLAS and everything now works as it should (i.e., for
>> certain source data, lme4 now gives the same solution on multiple runs
>> instead of randomly giving one of two different "solutions" on each
>> run). The FAQ does note in relation to vecLib BLAS " Although fast, it
>> is not under our control and may possibly deliver inaccurate results."
>> which appears to be true, at least with lme4.
>>
>> What BLAS does the CRAN build machine use? If it does use the vecLib
>> BLAS is there a case for changing to R BLAS (maybe only when
>> building/checking lme4)?
>>
>> Cheers,
>> Daniel
>>
>> On 18/07/10 9:50 AM, Daniel Myall wrote:
>>> Hi Simon,
>>>
>>> Unfortunately I don't think is the full story (there are actual small
>>> differences in the fits).
>>>
>>> To match the lme4 tests the example should actually be:
>>>
>>> library(lme4)
>>> y<- (1:20)*pi
>>> x<- (1:20)^2
>>> group<- gl(2,10)
>>> for (i in 1:10) {
>>> M1<- lmer (y ~ ? ? x + ( ? ?x | group))
>>> M2<- lmer (y ~ ? ? x + ( ? ?x | group))
>>> print(identical(ranef(M1),ranef(M2)))
>>> print(ranef(M1)$group-ranef(M2)$group)
>>> }
>>>
>>> Which gives me (the number of TRUE/FALSE and the order change on each
>>> run, even if restarting R):
>>>
>>> [1] FALSE
>>> ? ? (Intercept) ? ? ? ? ? ? x
>>> 1 ?6.613450e-06 -6.898626e-08
>>> 2 -6.613462e-06 ?6.898637e-08
>>> [1] TRUE
>>> ? (Intercept) x
>>> 1 ? ? ? ? ? 0 0
>>> 2 ? ? ? ? ? 0 0
>>> [1] FALSE
>>> ? ? (Intercept) ? ? ? ? ? ? x
>>> 1 -6.613450e-06 ?6.898626e-08
>>> 2 ?6.613462e-06 -6.898637e-08
>>> [1] FALSE
>>> ? ? (Intercept) ? ? ? ? ? ? x
>>> 1 ?6.613450e-06 -6.898626e-08
>>> 2 -6.613462e-06 ?6.898637e-08
>>> [1] TRUE
>>> ? (Intercept) x
>>> 1 ? ? ? ? ? 0 0
>>> 2 ? ? ? ? ? 0 0
>>> [1] FALSE
>>> ? ? (Intercept) ? ? ? ? ? ? x
>>> 1 -6.613450e-06 ?6.898626e-08
>>> 2 ?6.613462e-06 -6.898637e-08
>>> [1] FALSE
>>> ? ? (Intercept) ? ? ? ? ? ? x
>>> 1 -6.613450e-06 ?6.898626e-08
>>> 2 ?6.613462e-06 -6.898637e-08
>>> [1] FALSE
>>> ? ? (Intercept) ? ? ? ? ? ? x
>>> 1 -6.613450e-06 ?6.898626e-08
>>> 2 ?6.613462e-06 -6.898637e-08
>>> [1] TRUE
>>> ? (Intercept) x
>>> 1 ? ? ? ? ? 0 0
>>> 2 ? ? ? ? ? 0 0
>>> [1] TRUE
>>> ? (Intercept) x
>>> 1 ? ? ? ? ? 0 0
>>> 2 ? ? ? ? ? 0 0
>>>
>>>
>>> Although only small differences, I assume lme4 should be deterministic?
>>>
>>> Cheers,
>>> Daniel
>>>
>>>
>>>
>>>
>>> On 18/07/10 8:23 AM, Simon Urbanek wrote:
>>>> Ok, I think I found the issue. I'm not sure why this varies by
>>>> platform but the mismatch is due to the @env slot. Two environments
>>>> are only identical if it is *the* same environment (i.e. the same
>>>> pointer). However, M1 and M2 have different environments. The content
>>>> of those environments is identical, but that is irrelevant as it's
>>>> not the same pointer. Hence identical(M1, M2) fails (and serialize
>>>> comparison succeeds as it cares only about the content).
>>>>
>>>> So the short story is don't use identical() to compare the models
>>>> (unless you remove @env first). The long story raises the question
>>>> whether identical() should really return FALSE for environments like
>>>>> identical(new.env(),new.env())
>>>> [1] FALSE
>>>> I can see arguments both ways but for the purposes of comparing
>>>> values there should be an option that the above is TRUE.
>>>>
>>>> To be honest I don't see why this has not shown up on other platforms
>>>> as that is a global issue... (I hope this is the full story - I
>>>> didn't try all the combinations to see if setting @env to the same
>>>> environment will appease identical() for all the models)
>>>>
>>>> Cheers,
>>>> Simon
>>>>
>>>>
>>>> On Jul 17, 2010, at 3:49 PM, Simon Urbanek wrote:
>>>>
>>>>> Daniel,
>>>>>
>>>>> thanks for the test case. I did run it in valgrind but nothing
>>>>> showed up, however ...
>>>>>
>>>>> I'm starting to have a suspicion that this has something to do with
>>>>> identical() - look at this:
>>>>>
>>>>>> identical(M1,M2)
>>>>> [1] FALSE
>>>>>> all(serialize(M1,NULL)==serialize(M2,NULL))
>>>>> [1] TRUE
>>>>>> identical(unserialize(serialize(M1,NULL)),unserialize(serialize(M2,NULL)))
>>>>>>
>>>>> [1] FALSE
>>>>>> identical(unserialize(serialize(M1,NULL)),unserialize(serialize(M1,NULL)))
>>>>>>
>>>>> [1] FALSE
>>>>>
>>>>> So I think this may be a bug in identical() mainly because of the
>>>>> last one. I'll need to take identical() apart to see where it fails
>>>>> ... I'm CCing this to R-devel as the current issue seems more like
>>>>> an R issue so more eyes can have a look ...
>>>>>
>>>>> Cheers,
>>>>> Simon
>>>>>
>>>>>
>>>>> [FWIW this is tested in today's R-devel (with valgrind level 2) on
>>>>> x86_64 OS X 10.6.4 with lme4 from CRAN and Matrix form R-devel
>>>>> Recommended]
>>>>>
>>>>>
>>>>> On Jul 17, 2010, at 4:50 AM, Daniel Myall wrote:
>>>>>
>>>>>> I've done some further testing (R 2.11.1) and the issue is not
>>>>>> limited to Leopard.
>>>>>>
>>>>>> Using the test:
>>>>>>
>>>>>> library(lme4)
>>>>>> y<- (1:20)*pi
>>>>>> x<- (1:20)^2
>>>>>> group<- gl(2,10)
>>>>>> for (i in 1:10) {
>>>>>> M1<- lmer (y ~ ? ? x + ( ? ?x | group))
>>>>>> M2<- lmer (y ~ ? ? x + ( ? ?x | group))
>>>>>> print(identical(M1,M2))
>>>>>> }
>>>>>>
>>>>>> For CRAN lme4 and Matrix:
>>>>>>
>>>>>> 32 bit on Leopard: R CMD check fails; different results (on most runs)
>>>>>> 32 bit on Snow Leopard: R CMD check passes; different results (on
>>>>>> some runs).
>>>>>> 64 bit on Snow Leopard: R CMD check passes; identical results
>>>>>>
>>>>>> For SVN version of Matrix with CRAN lme4:
>>>>>>
>>>>>> 32 bit on Snow Leopard: different results (on all runs).
>>>>>> 64 bit on Snow Leopard: different results (on all runs)
>>>>>>
>>>>>> For SVN version of Matrix with SVN lme4a:
>>>>>>
>>>>>> 32 bit on Snow Leopard: different results (on all runs).
>>>>>> 64 bit on Snow Leopard: identical results
>>>>>>
>>>>>> I couldn't reproduce on Linux 32/64bit. Is it time to jump into
>>>>>> valgrind to try and find the cause?
>>>>>>
>>>>>> Cheers,
>>>>>> Daniel
>>>>>>
>>>>>>
>>>>>>
>>>>>> On 17/07/10 5:51 PM, John Maindonald wrote:
>>>>>>> In principle, maybe a Snow Leopard version might be posted
>>>>>>> as an alternative, if someone can provide one. ?But I take it
>>>>>>> that the issue is now a bit wider than tests that fail on Leopard
>>>>>>> vs passing on Snow Leopard?
>>>>>>>
>>>>>>
>>>>
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>> ? ? ? ?[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>



From etiennelaliberte at gmail.com  Mon Jul 19 01:34:11 2010
From: etiennelaliberte at gmail.com (Etienne =?ISO-8859-1?Q?Lalibert=E9?=)
Date: Mon, 19 Jul 2010 11:34:11 +1200
Subject: [R-sig-ME] lme with varIdent in a split-plot design
Message-ID: <1279496051.2158.14.camel@globetrotter>

I'm using lme() to analyse soil pH data from a simple, balanced,
minimally replicated agricultural split-plot experiment with 2 block
(replicates), each with five whole plots (corresponding to 5 fertilizer
levels). Within each of the 10 whole plots are 3 subplots corresponding
to 3 grazing intensity treatments, for a total of 30 subplots.

There was evidence for heterogeneity when I plotted residuals against
fertilizer levels, so I tried using varIdent(form = ~1 | fert). However,
I get this error message:

Error in MEestimate(lmeSt, grps) : 
  Singularity in backsolve at level 0, block 1

Can someone please explain me what this error means?

To make my example reproducible, I'm attaching the R code (with the real
data and design):

# get pH dataset
pH <- c(5.0, 4.9, 4.8, 5.0, 4.9, 4.9, 5.5, 5.5, 5.6, 5.2, 5.0, 5.2, 4.9,
4.9, 5.0, 5.1, 5.2, 5.0, 4.9, 5.1, 4.9, 5.1, 5.0, 5.2, 5.6, 5.4, 5.2,
4.6, 4.7, 4.8)
block <- gl(2, 15)
fert <- factor(c(500, 500, 500, 250, 250, 250, 0, 0, 0, 50, 50, 50, 100,
100, 100, 500, 500, 500, 100, 100, 100, 50, 50, 50, 0, 0, 0, 250, 250,
250 ))
graz <- factor(c("mod", "lax", "hard", "lax", "mod", "hard", "hard",
"mod", "lax", "lax", "mod", "hard", "hard", "mod", "lax", "lax", "mod",
"hard", "lax", "hard", "mod", "lax", "mod", "hard", "mod", "lax",
"hard", "lax", "mod", "hard"))
pHdata <- data.frame(pH, block, fert, graz)

# run model
library(nlme)
mod1 <- lme(pH ~ fert * graz, random = ~ 1 | block / fert, data =
pHdata)
anova(mod1)

# get residuals and fitted values
mod1.res <- residuals(mod1)
mod1.fit <- fitted(mod1)

# check residuals against fitted
plot(mod1.res ~ mod1.fit)

# check residuals against fert
plot(mod1.res ~ fert) # heterogeneity

# update model with different variances for fert
mod2 <- update(mod1, weights = varIdent(form = ~ 1 | fert) ) # returns
error message I don't understand

# try something else: remove interaction and use different variances for
fert
mod3 <- update(mod1, .~. - fert:graz, weights = varIdent(form = ~ 1 |
fert) ) # this works



Many thanks

Etienne



From lborger at uoguelph.ca  Mon Jul 19 07:28:40 2010
From: lborger at uoguelph.ca (Luca Borger)
Date: Mon, 19 Jul 2010 01:28:40 -0400
Subject: [R-sig-ME] lme with varIdent in a split-plot design
References: <1279496051.2158.14.camel@globetrotter>
Message-ID: <57715DE57B12475AB0CC6026DB7669BB@lborger>

Hello,

> Error in MEestimate(lmeSt, grps) :
>  Singularity in backsolve at level 0, block 1
>
> Can someone please explain me what this error means?


This message usually comes when the fixed effects parts of the model ("level 
0") is too complicated, given the data. In fact, as you say, your dataset is 
"minimally replicated" and the message disappears when you take the 
interaction out. You can 'force' an estimate by slightly changing the 
variance structure (if this is adequate to do so, I'm not entirely sure):

mod1b <- update(mod1, weights = varPower(form = ~ as.numeric(fert)))
mod1c <- update(mod1, weights = varPower())

However, given your data, the variance structure does not appear to be 
supported, and neither is the effect of grazing:

mod3b <- update(mod1, .~. - fert:graz)
mod4 <- update(mod3b, .~. - graz)
mod5 <- update(mod4, .~. - fert)


> AIC(mod1,mod1b,mod1c,mod3,mod3b,mod4,mod5)
      df        AIC
mod1  18  25.365540
mod1b 19  26.318237
mod1c 19  27.022812
mod3  14   8.683218
mod3b 10   2.501522
mod4   8  -9.972859
mod5   4 -10.700400
>


HTH and probably others can provide better suggestions.


Cheers,

Luca




----- Original Message ----- 
From: "Etienne Lalibert?" <etiennelaliberte at gmail.com>
To: "r-sig-mixed-models" <r-sig-mixed-models at r-project.org>
Sent: Sunday, July 18, 2010 7:34 PM
Subject: [R-sig-ME] lme with varIdent in a split-plot design


> I'm using lme() to analyse soil pH data from a simple, balanced,
> minimally replicated agricultural split-plot experiment with 2 block
> (replicates), each with five whole plots (corresponding to 5 fertilizer
> levels). Within each of the 10 whole plots are 3 subplots corresponding
> to 3 grazing intensity treatments, for a total of 30 subplots.
>
> There was evidence for heterogeneity when I plotted residuals against
> fertilizer levels, so I tried using varIdent(form = ~1 | fert). However,
> I get this error message:
>
> Error in MEestimate(lmeSt, grps) :
>  Singularity in backsolve at level 0, block 1
>
> Can someone please explain me what this error means?
>
> To make my example reproducible, I'm attaching the R code (with the real
> data and design):
>
> # get pH dataset
> pH <- c(5.0, 4.9, 4.8, 5.0, 4.9, 4.9, 5.5, 5.5, 5.6, 5.2, 5.0, 5.2, 4.9,
> 4.9, 5.0, 5.1, 5.2, 5.0, 4.9, 5.1, 4.9, 5.1, 5.0, 5.2, 5.6, 5.4, 5.2,
> 4.6, 4.7, 4.8)
> block <- gl(2, 15)
> fert <- factor(c(500, 500, 500, 250, 250, 250, 0, 0, 0, 50, 50, 50, 100,
> 100, 100, 500, 500, 500, 100, 100, 100, 50, 50, 50, 0, 0, 0, 250, 250,
> 250 ))
> graz <- factor(c("mod", "lax", "hard", "lax", "mod", "hard", "hard",
> "mod", "lax", "lax", "mod", "hard", "hard", "mod", "lax", "lax", "mod",
> "hard", "lax", "hard", "mod", "lax", "mod", "hard", "mod", "lax",
> "hard", "lax", "mod", "hard"))
> pHdata <- data.frame(pH, block, fert, graz)
>
> # run model
> library(nlme)
> mod1 <- lme(pH ~ fert * graz, random = ~ 1 | block / fert, data =
> pHdata)
> anova(mod1)
>
> # get residuals and fitted values
> mod1.res <- residuals(mod1)
> mod1.fit <- fitted(mod1)
>
> # check residuals against fitted
> plot(mod1.res ~ mod1.fit)
>
> # check residuals against fert
> plot(mod1.res ~ fert) # heterogeneity
>
> # update model with different variances for fert
> mod2 <- update(mod1, weights = varIdent(form = ~ 1 | fert) ) # returns
> error message I don't understand
>
> # try something else: remove interaction and use different variances for
> fert
> mod3 <- update(mod1, .~. - fert:graz, weights = varIdent(form = ~ 1 |
> fert) ) # this works
>
>
>
> Many thanks
>
> Etienne
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From etiennelaliberte at gmail.com  Mon Jul 19 09:50:13 2010
From: etiennelaliberte at gmail.com (Etienne =?ISO-8859-1?Q?Lalibert=E9?=)
Date: Mon, 19 Jul 2010 19:50:13 +1200
Subject: [R-sig-ME] lme with varIdent in a split-plot design
In-Reply-To: <57715DE57B12475AB0CC6026DB7669BB@lborger>
References: <1279496051.2158.14.camel@globetrotter>
	<57715DE57B12475AB0CC6026DB7669BB@lborger>
Message-ID: <1279525813.2158.25.camel@globetrotter>

Thanks Luca. Yes, you're right that in that case the model is overly
complicated as only "fert" is important.

What puzzled me (and still does) is that I had used varIdent(form = ~ 1
| fert) before with other response variables from this same experimental
design and using all fixed terms (i.e. fert * graz), without problems.

Thanks for your help.

Etienne

Le lundi 19 juillet 2010 ? 01:28 -0400, Luca Borger a ?crit :
> Hello,
> 
> > Error in MEestimate(lmeSt, grps) :
> >  Singularity in backsolve at level 0, block 1
> >
> > Can someone please explain me what this error means?
> 
> 
> This message usually comes when the fixed effects parts of the model ("level 
> 0") is too complicated, given the data. In fact, as you say, your dataset is 
> "minimally replicated" and the message disappears when you take the 
> interaction out. You can 'force' an estimate by slightly changing the 
> variance structure (if this is adequate to do so, I'm not entirely sure):
> 
> mod1b <- update(mod1, weights = varPower(form = ~ as.numeric(fert)))
> mod1c <- update(mod1, weights = varPower())
> 
> However, given your data, the variance structure does not appear to be 
> supported, and neither is the effect of grazing:
> 
> mod3b <- update(mod1, .~. - fert:graz)
> mod4 <- update(mod3b, .~. - graz)
> mod5 <- update(mod4, .~. - fert)
> 
> 
> > AIC(mod1,mod1b,mod1c,mod3,mod3b,mod4,mod5)
>       df        AIC
> mod1  18  25.365540
> mod1b 19  26.318237
> mod1c 19  27.022812
> mod3  14   8.683218
> mod3b 10   2.501522
> mod4   8  -9.972859
> mod5   4 -10.700400
> >
> 
> 
> HTH and probably others can provide better suggestions.
> 
> 
> Cheers,
> 
> Luca
> 
> 
> 
> 
> ----- Original Message ----- 
> From: "Etienne Lalibert?" <etiennelaliberte at gmail.com>
> To: "r-sig-mixed-models" <r-sig-mixed-models at r-project.org>
> Sent: Sunday, July 18, 2010 7:34 PM
> Subject: [R-sig-ME] lme with varIdent in a split-plot design
> 
> 
> > I'm using lme() to analyse soil pH data from a simple, balanced,
> > minimally replicated agricultural split-plot experiment with 2 block
> > (replicates), each with five whole plots (corresponding to 5 fertilizer
> > levels). Within each of the 10 whole plots are 3 subplots corresponding
> > to 3 grazing intensity treatments, for a total of 30 subplots.
> >
> > There was evidence for heterogeneity when I plotted residuals against
> > fertilizer levels, so I tried using varIdent(form = ~1 | fert). However,
> > I get this error message:
> >
> > Error in MEestimate(lmeSt, grps) :
> >  Singularity in backsolve at level 0, block 1
> >
> > Can someone please explain me what this error means?
> >
> > To make my example reproducible, I'm attaching the R code (with the real
> > data and design):
> >
> > # get pH dataset
> > pH <- c(5.0, 4.9, 4.8, 5.0, 4.9, 4.9, 5.5, 5.5, 5.6, 5.2, 5.0, 5.2, 4.9,
> > 4.9, 5.0, 5.1, 5.2, 5.0, 4.9, 5.1, 4.9, 5.1, 5.0, 5.2, 5.6, 5.4, 5.2,
> > 4.6, 4.7, 4.8)
> > block <- gl(2, 15)
> > fert <- factor(c(500, 500, 500, 250, 250, 250, 0, 0, 0, 50, 50, 50, 100,
> > 100, 100, 500, 500, 500, 100, 100, 100, 50, 50, 50, 0, 0, 0, 250, 250,
> > 250 ))
> > graz <- factor(c("mod", "lax", "hard", "lax", "mod", "hard", "hard",
> > "mod", "lax", "lax", "mod", "hard", "hard", "mod", "lax", "lax", "mod",
> > "hard", "lax", "hard", "mod", "lax", "mod", "hard", "mod", "lax",
> > "hard", "lax", "mod", "hard"))
> > pHdata <- data.frame(pH, block, fert, graz)
> >
> > # run model
> > library(nlme)
> > mod1 <- lme(pH ~ fert * graz, random = ~ 1 | block / fert, data =
> > pHdata)
> > anova(mod1)
> >
> > # get residuals and fitted values
> > mod1.res <- residuals(mod1)
> > mod1.fit <- fitted(mod1)
> >
> > # check residuals against fitted
> > plot(mod1.res ~ mod1.fit)
> >
> > # check residuals against fert
> > plot(mod1.res ~ fert) # heterogeneity
> >
> > # update model with different variances for fert
> > mod2 <- update(mod1, weights = varIdent(form = ~ 1 | fert) ) # returns
> > error message I don't understand
> >
> > # try something else: remove interaction and use different variances for
> > fert
> > mod3 <- update(mod1, .~. - fert:graz, weights = varIdent(form = ~ 1 |
> > fert) ) # this works
> >
> >
> >
> > Many thanks
> >
> > Etienne
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > 
> 


-- 
Etienne Lalibert?
================================
School of Forestry
University of Canterbury
Private Bag 4800
Christchurch 8140, New Zealand
Phone: +64 3 366 7001 ext. 8365
Fax: +64 3 364 2124
www.elaliberte.info



From john.maindonald at anu.edu.au  Mon Jul 19 10:27:37 2010
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Mon, 19 Jul 2010 18:27:37 +1000
Subject: [R-sig-ME] Effective sample size
Message-ID: <CE0EDA99-6432-4338-96D9-A33FA56D280D@anu.edu.au>

Does anyone know of an implementation of the Effective Sample Size
methodology that is described in 
<<<
The Effective Sample Size and an Alternative Small-Sample Degrees-of-Freedom Method
by: Christel Faes, Geert Molenberghs, Marc Aerts, Geert Verbeke, Michael G. Kenward
The American Statistician, Vol. 63, No. 4. (2009), pp. 389-399.
>>> ?

The key requirement, as I understand the paper, is to calculate a variance for the predicted
value, for each observation.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm



From jochen.laubrock at gmail.com  Mon Jul 19 17:44:27 2010
From: jochen.laubrock at gmail.com (jochen laubrock)
Date: Mon, 19 Jul 2010 17:44:27 +0200
Subject: [R-sig-ME] bug in identical()? [Was: Failure to load lme4 on
	Mac]
In-Reply-To: <AANLkTimxEaE-GoeIeIMKgKbrEQQLb-I3DfaHkw9sy8xE@mail.gmail.com>
References: <C8207D43.4236%mcmahons@si.edu> <4BFB0AE0.3090803@zeno.co.nz>
	<loom.20100715T175631-148@post.gmane.org>
	<AANLkTim4iUokYQZvcL99rhTQkHqIQ5wuESMAGCPu7qGe@mail.gmail.com>
	<AANLkTil72csO0XA3-ZghXw62RUp9gMr-Df1Kx8Bi_Iq2@mail.gmail.com>
	<AANLkTik15uc4QqaIxcwkhAd4HjpzCQ60MuKqiFDJyJnS@mail.gmail.com>
	<08AD950F-C3DB-4E23-868B-0EFD94833014@anu.edu.au>
	<AANLkTil7OZ91zRrGf3licxyYQTdgO7QFfLr5CJoyqPc5@mail.gmail.com>
	<4C3F9E01.9050804@zeno.co.nz>
	<AANLkTimy0SevCeJ87YhFis_fQg-S1ixMwaZF2Bk2K-Jq@mail.gmail.com>
	<E1F79CC7-DB81-4916-B847-10C6C02DF2A8@r-project.org>
	<loom.20100716T153900-860@post.gmane.org>
	<19520.33619.18880.815822@lynne.math.ethz.ch>
	<20100717070706.70fg8lchcskskgo0@imp.inserm.fr>
	<7E3C1A13-65AE-4E6F-9EB6-1EEB2B1677C0@anu.edu.au>
	<4C416EBE.4080204@zeno.co.nz>
	<D32F4A20-8620-4C43-A316-33CD816ACCF9@r-project.org>
	<270A5F5A-081B-4310-B269-4795713260BA@r-project.org>
	<4C4225BF.10501@zeno.co.nz> <4C42CAE9.5070609@zeno.co.nz>
	<AANLkTimd-q7PBYfAMuyTKKXk1Rh6TEQK6SP6cvgdyol4@mail.gmail.com>
	<AANLkTimxEaE-GoeIeIMKgKbrEQQLb-I3DfaHkw9sy8xE@mail.gmail.com>
Message-ID: <1081604C-1746-4620-935B-A72AC5AE53DD@gmail.com>

Hi,

talking about deterministic behavior, what puzzles me even more is why a call to identical sometimes seems to the eliminate the (small) numerical differences between coefficients, and why this depends on the order in which identical and coef/ranef are called. See example (and lengthy output, will probably differ each time called) below. 

In TEST1 and TEST2, the difference is always zero although identical often returns FALSE. TEST3, which should do exactly the same as TEST2 up to the second call of identical often produces a difference larger than zero, as does TEST4, in which identical is called after the computation of the difference in coefficients. This does not seem to depend on the order in which TEST1 to TEST4 are performed (not shown).

Well, at least identical never returns TRUE when the difference is not in zero?

This is running in 32-bit mode on Mac OS X, R -arch=i386; no worries if run in 64-bit mode.


cheers, jochen


# script 
library(lme4)
y <- (1:20)*pi
x <- (1:20)^2
group<- gl(2,10)


ntestsPerRun <- 10
cat("\n--------TEST1--------\n")
for (i in 1:ntestsPerRun) {
	cat(paste("--", "run", i, "--\n"))
	M1 <- lmer (y ~     x + (x | group))
	M2 <- lmer (y ~     x + (x | group))
	print(identical(ranef(M1),ranef(M2)))
	print(identical(coef(M1),coef(M2)))
	print(ranef(M1)$group - ranef(M1)$group)
	print(coef(M1)$group - coef(M1)$group)
}

cat("\n--------TEST2--------\n")
for (i in 1:ntestsPerRun) {
	cat(paste("--", "run", i, "--\n"))
	M1 <- lmer (y ~     x + (x | group))
	M2 <- lmer (y ~     x + (x | group))
	print(identical(ranef(M1),ranef(M2)))
	print(ranef(M1)$group - ranef(M1)$group)
	print(identical(coef(M1),coef(M2)))
	print(coef(M1)$group - coef(M1)$group)
}

cat("\n--------TEST3--------\n")
for (i in 1:ntestsPerRun) {
	cat(paste("--", "run", i, "--\n"))
	M1<- lmer (y ~     x + (    x | group))
	M2<- lmer (y ~     x + (    x | group))
	print(identical(ranef(M1),ranef(M2)))
	print(ranef(M1)$group-ranef(M2)$group)
}

cat("\n--------TEST4--------\n")
for (i in 1:ntestsPerRun) {
	cat(paste("--", "run", i, "--\n"))
	M1 <- lmer (y ~     x + (x | group))
	M2 <- lmer (y ~     x + (x | group))
	print(ranef(M1)$group - ranef(M2)$group)
	print(coef(M1)$group - coef(M2)$group)
	print(identical(ranef(M1),ranef(M2)))
	print(identical(coef(M1),ranef(M2)))
}
# output


--------TEST1--------
-- run 1 --
[1] TRUE
[1] TRUE
  (Intercept) x
1           0 0
2           0 0
  (Intercept) x
1           0 0
2           0 0
-- run 2 --
[1] TRUE
[1] TRUE
  (Intercept) x
1           0 0
2           0 0
  (Intercept) x
1           0 0
2           0 0
-- run 3 --
[1] TRUE
[1] TRUE
  (Intercept) x
1           0 0
2           0 0
  (Intercept) x
1           0 0
2           0 0
-- run 4 --
[1] TRUE
[1] TRUE
  (Intercept) x
1           0 0
2           0 0
  (Intercept) x
1           0 0
2           0 0
-- run 5 --
[1] TRUE
[1] TRUE
  (Intercept) x
1           0 0
2           0 0
  (Intercept) x
1           0 0
2           0 0
-- run 6 --
[1] TRUE
[1] TRUE
  (Intercept) x
1           0 0
2           0 0
  (Intercept) x
1           0 0
2           0 0
-- run 7 --
[1] TRUE
[1] TRUE
  (Intercept) x
1           0 0
2           0 0
  (Intercept) x
1           0 0
2           0 0
-- run 8 --
[1] TRUE
[1] TRUE
  (Intercept) x
1           0 0
2           0 0
  (Intercept) x
1           0 0
2           0 0
-- run 9 --
[1] TRUE
[1] TRUE
  (Intercept) x
1           0 0
2           0 0
  (Intercept) x
1           0 0
2           0 0
-- run 10 --
[1] FALSE
[1] FALSE
  (Intercept) x
1           0 0
2           0 0
  (Intercept) x
1           0 0
2           0 0

--------TEST2--------
-- run 1 --
[1] TRUE
  (Intercept) x
1           0 0
2           0 0
[1] TRUE
  (Intercept) x
1           0 0
2           0 0
-- run 2 --
[1] TRUE
  (Intercept) x
1           0 0
2           0 0
[1] TRUE
  (Intercept) x
1           0 0
2           0 0
-- run 3 --
[1] TRUE
  (Intercept) x
1           0 0
2           0 0
[1] TRUE
  (Intercept) x
1           0 0
2           0 0
-- run 4 --
[1] FALSE
  (Intercept) x
1           0 0
2           0 0
[1] FALSE
  (Intercept) x
1           0 0
2           0 0
-- run 5 --
[1] FALSE
  (Intercept) x
1           0 0
2           0 0
[1] FALSE
  (Intercept) x
1           0 0
2           0 0
-- run 6 --
[1] FALSE
  (Intercept) x
1           0 0
2           0 0
[1] FALSE
  (Intercept) x
1           0 0
2           0 0
-- run 7 --
[1] TRUE
  (Intercept) x
1           0 0
2           0 0
[1] TRUE
  (Intercept) x
1           0 0
2           0 0
-- run 8 --
[1] FALSE
  (Intercept) x
1           0 0
2           0 0
[1] FALSE
  (Intercept) x
1           0 0
2           0 0
-- run 9 --
[1] FALSE
  (Intercept) x
1           0 0
2           0 0
[1] FALSE
  (Intercept) x
1           0 0
2           0 0
-- run 10 --
[1] FALSE
  (Intercept) x
1           0 0
2           0 0
[1] FALSE
  (Intercept) x
1           0 0
2           0 0

--------TEST3--------
-- run 1 --
[1] TRUE
  (Intercept) x
1           0 0
2           0 0
-- run 2 --
[1] FALSE
    (Intercept)             x
1  6.613450e-06 -6.898626e-08
2 -6.613462e-06  6.898637e-08
-- run 3 --
[1] FALSE
    (Intercept)             x
1  6.613450e-06 -6.898626e-08
2 -6.613462e-06  6.898637e-08
-- run 4 --
[1] FALSE
    (Intercept)             x
1  6.613450e-06 -6.898626e-08
2 -6.613462e-06  6.898637e-08
-- run 5 --
[1] TRUE
  (Intercept) x
1           0 0
2           0 0
-- run 6 --
[1] TRUE
  (Intercept) x
1           0 0
2           0 0
-- run 7 --
[1] TRUE
  (Intercept) x
1           0 0
2           0 0
-- run 8 --
[1] FALSE
    (Intercept)             x
1  6.613450e-06 -6.898626e-08
2 -6.613462e-06  6.898637e-08
-- run 9 --
[1] FALSE
    (Intercept)             x
1  6.613450e-06 -6.898626e-08
2 -6.613462e-06  6.898637e-08
-- run 10 --
[1] FALSE
    (Intercept)             x
1  6.613450e-06 -6.898626e-08
2 -6.613462e-06  6.898637e-08

--------TEST4--------
-- run 1 --
    (Intercept)             x
1 -6.613450e-06  6.898626e-08
2  6.613462e-06 -6.898637e-08
   (Intercept)             x
1 3.719195e-06 -4.640498e-08
2 1.694611e-05 -1.843776e-07
[1] FALSE
[1] FALSE
-- run 2 --
    (Intercept)             x
1 -6.613450e-06  6.898626e-08
2  6.613462e-06 -6.898637e-08
   (Intercept)             x
1 3.719195e-06 -4.640498e-08
2 1.694611e-05 -1.843776e-07
[1] FALSE
[1] FALSE
-- run 3 --
    (Intercept)             x
1 -6.613450e-06  6.898626e-08
2  6.613462e-06 -6.898637e-08
   (Intercept)             x
1 3.719195e-06 -4.640498e-08
2 1.694611e-05 -1.843776e-07
[1] FALSE
[1] FALSE
-- run 4 --
    (Intercept)             x
1 -6.613450e-06  6.898626e-08
2  6.613462e-06 -6.898637e-08
   (Intercept)             x
1 3.719195e-06 -4.640498e-08
2 1.694611e-05 -1.843776e-07
[1] FALSE
[1] FALSE
-- run 5 --
  (Intercept) x
1           0 0
2           0 0
  (Intercept) x
1           0 0
2           0 0
[1] TRUE
[1] FALSE
-- run 6 --
  (Intercept) x
1           0 0
2           0 0
  (Intercept) x
1           0 0
2           0 0
[1] TRUE
[1] FALSE
-- run 7 --
    (Intercept)             x
1 -6.613450e-06  6.898626e-08
2  6.613462e-06 -6.898637e-08
   (Intercept)             x
1 3.719195e-06 -4.640498e-08
2 1.694611e-05 -1.843776e-07
[1] FALSE
[1] FALSE
-- run 8 --
  (Intercept) x
1           0 0
2           0 0
  (Intercept) x
1           0 0
2           0 0
[1] TRUE
[1] FALSE
-- run 9 --
    (Intercept)             x
1 -6.613450e-06  6.898626e-08
2  6.613462e-06 -6.898637e-08
   (Intercept)             x
1 3.719195e-06 -4.640498e-08
2 1.694611e-05 -1.843776e-07
[1] FALSE
[1] FALSE
-- run 10 --
  (Intercept) x
1           0 0
2           0 0
  (Intercept) x
1           0 0
2           0 0
[1] TRUE
[1] FALSE


> sessionInfo()

R version 2.11.1 Patched (2010-06-14 r52281) 
i386-apple-darwin9.8.0 

locale:
[1] de_DE.UTF-8/de_DE.UTF-8/C/C/de_DE.UTF-8/de_DE.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] lme4_0.999375-33   Matrix_0.999375-40 lattice_0.18-8    

loaded via a namespace (and not attached):
[1] grid_2.11.1  nlme_3.1-96  tools_2.11.1




On Jul 18, 2010, at 13:20 , Reinhold Kliegl wrote:

> Actually, what makes a difference on my machine for this test example
> is switching to
> `R --arch x86_64'
> 
> After this switch linking either R BLAS and vecLIB BLAS checked out
> fine--at least for 100 tests of the example.
> ( I think ...).
> 
> Reinhold Kliegl
> 
> On Sun, Jul 18, 2010 at 12:28 PM, Reinhold Kliegl
> <reinhold.kliegl at gmail.com> wrote:
>> First of all, I really appreciate these efforts.
>> 
>> Changing to R BLAS did not do the trick for me on Mac OS X (10.5.8).
>> Here is the protocol.
>> 
>> ###
>> Last login: Sun Jul 18 12:04:10 on ttys000
>> Reinhold:~ kliegl$ bash
>> 
>> ~ > cd /Library/Frameworks/R.framework/Resources/lib
>> /Library/Frameworks/R.framework/Resources/lib > ls
>> i386                    libRblas.vecLib.dylib   libreadline.5.2.dylib
>> libR.dylib              libRlapack.dylib        libreadline.dylib
>> libRblas.0.dylib        libgcc_s.1.dylib        ppc
>> libRblas.dylib          libgfortran.2.dylib     x86_64
>> 
>> /Library/Frameworks/R.framework/Resources/lib > ln -sf
>> libRblas.0.dylib libRblas.dylib
>> /Library/Frameworks/R.framework/Resources/lib > R
>> 
>> R version 2.11.1 Patched (2010-07-16 r52550)
>> Copyright (C) 2010 The R Foundation for Statistical Computing
>> ISBN 3-900051-07-0
>> 
>> < clipped>
>> 
>>> library(lme4)
>> 
>> <clipped>
>> 
>>> y <- (1:6)*pi # 3.14
>>> x <- (1:6)^2
>>> group <- gl(2,3)
>>> for (i in 1:10) {
>> + M1 <- lmer (y ~     x + (x | group))
>> + M2 <- lmer (y ~     x + (x | group))
>> + print(identical(ranef(M1),ranef(M2)))
>> + print(identical(coef(M1),coef(M2)))
>> +  }
>> [1] TRUE
>> [1] TRUE
>> [1] TRUE
>> [1] TRUE
>> [1] FALSE
>> [1] FALSE
>> [1] TRUE
>> [1] TRUE
>> [1] FALSE
>> [1] FALSE
>> [1] FALSE
>> [1] FALSE
>> [1] TRUE
>> [1] TRUE
>> [1] FALSE
>> [1] FALSE
>> [1] TRUE
>> [1] TRUE
>> [1] TRUE
>> [1] TRUE
>> 
>>> sessionInfo()
>> R version 2.11.1 Patched (2010-07-16 r52550)
>> i386-apple-darwin9.8.0
>> 
>> locale:
>> [1] de_DE/de_DE/C/C/de_DE/de_DE
>> 
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>> 
>> other attached packages:
>> [1] lme4_0.999375-34   Matrix_0.999375-41 lattice_0.18-8
>> 
>> loaded via a namespace (and not attached):
>> [1] grid_2.11.1   nlme_3.1-96   stats4_2.11.1
>>> 
>> #####
>> 
>> Did I do something wrong in getting the correct library? Is there a
>> command to check whether R BLAS is used?
>> 
>> Using require(lme4) instead of library(lme4) did not make a difference either.
>> 
>> Many thanks again,
>> Reinhold Kliegl
>> 
>> 
>> On Sun, Jul 18, 2010 at 11:35 AM, Daniel Myall <daniel.lists at zeno.co.nz> wrote:
>>> Hi Simon,
>>> 
>>> The Apple vecLib BLAS appears to be the cause of the strangeness (at
>>> least on my machine).
>>> 
>>> Following:
>>> http://cran.r-project.org/bin/macosx/RMacOSX-FAQ.html#Which-BLAS-is-used-and-how-can-it-be-changed_003f
>>> 
>>> 
>>> I changed to the R BLAS and everything now works as it should (i.e., for
>>> certain source data, lme4 now gives the same solution on multiple runs
>>> instead of randomly giving one of two different "solutions" on each
>>> run). The FAQ does note in relation to vecLib BLAS " Although fast, it
>>> is not under our control and may possibly deliver inaccurate results."
>>> which appears to be true, at least with lme4.
>>> 
>>> What BLAS does the CRAN build machine use? If it does use the vecLib
>>> BLAS is there a case for changing to R BLAS (maybe only when
>>> building/checking lme4)?
>>> 
>>> Cheers,
>>> Daniel
>>> 
>>> On 18/07/10 9:50 AM, Daniel Myall wrote:
>>>> Hi Simon,
>>>> 
>>>> Unfortunately I don't think is the full story (there are actual small
>>>> differences in the fits).
>>>> 
>>>> To match the lme4 tests the example should actually be:
>>>> 
>>>> library(lme4)
>>>> y<- (1:20)*pi
>>>> x<- (1:20)^2
>>>> group<- gl(2,10)
>>>> for (i in 1:10) {
>>>> M1<- lmer (y ~     x + (    x | group))
>>>> M2<- lmer (y ~     x + (    x | group))
>>>> print(identical(ranef(M1),ranef(M2)))
>>>> print(ranef(M1)$group-ranef(M2)$group)
>>>> }
>>>> 
>>>> Which gives me (the number of TRUE/FALSE and the order change on each
>>>> run, even if restarting R):
>>>> 
>>>> [1] FALSE
>>>>     (Intercept)             x
>>>> 1  6.613450e-06 -6.898626e-08
>>>> 2 -6.613462e-06  6.898637e-08
>>>> [1] TRUE
>>>>   (Intercept) x
>>>> 1           0 0
>>>> 2           0 0
>>>> [1] FALSE
>>>>     (Intercept)             x
>>>> 1 -6.613450e-06  6.898626e-08
>>>> 2  6.613462e-06 -6.898637e-08
>>>> [1] FALSE
>>>>     (Intercept)             x
>>>> 1  6.613450e-06 -6.898626e-08
>>>> 2 -6.613462e-06  6.898637e-08
>>>> [1] TRUE
>>>>   (Intercept) x
>>>> 1           0 0
>>>> 2           0 0
>>>> [1] FALSE
>>>>     (Intercept)             x
>>>> 1 -6.613450e-06  6.898626e-08
>>>> 2  6.613462e-06 -6.898637e-08
>>>> [1] FALSE
>>>>     (Intercept)             x
>>>> 1 -6.613450e-06  6.898626e-08
>>>> 2  6.613462e-06 -6.898637e-08
>>>> [1] FALSE
>>>>     (Intercept)             x
>>>> 1 -6.613450e-06  6.898626e-08
>>>> 2  6.613462e-06 -6.898637e-08
>>>> [1] TRUE
>>>>   (Intercept) x
>>>> 1           0 0
>>>> 2           0 0
>>>> [1] TRUE
>>>>   (Intercept) x
>>>> 1           0 0
>>>> 2           0 0
>>>> 
>>>> 
>>>> Although only small differences, I assume lme4 should be deterministic?
>>>> 
>>>> Cheers,
>>>> Daniel
>>>> 
>>>> 
>>>> 
>>>> 
>>>> On 18/07/10 8:23 AM, Simon Urbanek wrote:
>>>>> Ok, I think I found the issue. I'm not sure why this varies by
>>>>> platform but the mismatch is due to the @env slot. Two environments
>>>>> are only identical if it is *the* same environment (i.e. the same
>>>>> pointer). However, M1 and M2 have different environments. The content
>>>>> of those environments is identical, but that is irrelevant as it's
>>>>> not the same pointer. Hence identical(M1, M2) fails (and serialize
>>>>> comparison succeeds as it cares only about the content).
>>>>> 
>>>>> So the short story is don't use identical() to compare the models
>>>>> (unless you remove @env first). The long story raises the question
>>>>> whether identical() should really return FALSE for environments like
>>>>>> identical(new.env(),new.env())
>>>>> [1] FALSE
>>>>> I can see arguments both ways but for the purposes of comparing
>>>>> values there should be an option that the above is TRUE.
>>>>> 
>>>>> To be honest I don't see why this has not shown up on other platforms
>>>>> as that is a global issue... (I hope this is the full story - I
>>>>> didn't try all the combinations to see if setting @env to the same
>>>>> environment will appease identical() for all the models)
>>>>> 
>>>>> Cheers,
>>>>> Simon
>>>>> 
>>>>> 
>>>>> On Jul 17, 2010, at 3:49 PM, Simon Urbanek wrote:
>>>>> 
>>>>>> Daniel,
>>>>>> 
>>>>>> thanks for the test case. I did run it in valgrind but nothing
>>>>>> showed up, however ...
>>>>>> 
>>>>>> I'm starting to have a suspicion that this has something to do with
>>>>>> identical() - look at this:
>>>>>> 
>>>>>>> identical(M1,M2)
>>>>>> [1] FALSE
>>>>>>> all(serialize(M1,NULL)==serialize(M2,NULL))
>>>>>> [1] TRUE
>>>>>>> identical(unserialize(serialize(M1,NULL)),unserialize(serialize(M2,NULL)))
>>>>>>> 
>>>>>> [1] FALSE
>>>>>>> identical(unserialize(serialize(M1,NULL)),unserialize(serialize(M1,NULL)))
>>>>>>> 
>>>>>> [1] FALSE
>>>>>> 
>>>>>> So I think this may be a bug in identical() mainly because of the
>>>>>> last one. I'll need to take identical() apart to see where it fails
>>>>>> ... I'm CCing this to R-devel as the current issue seems more like
>>>>>> an R issue so more eyes can have a look ...
>>>>>> 
>>>>>> Cheers,
>>>>>> Simon
>>>>>> 
>>>>>> 
>>>>>> [FWIW this is tested in today's R-devel (with valgrind level 2) on
>>>>>> x86_64 OS X 10.6.4 with lme4 from CRAN and Matrix form R-devel
>>>>>> Recommended]
>>>>>> 
>>>>>> 
>>>>>> On Jul 17, 2010, at 4:50 AM, Daniel Myall wrote:
>>>>>> 
>>>>>>> I've done some further testing (R 2.11.1) and the issue is not
>>>>>>> limited to Leopard.
>>>>>>> 
>>>>>>> Using the test:
>>>>>>> 
>>>>>>> library(lme4)
>>>>>>> y<- (1:20)*pi
>>>>>>> x<- (1:20)^2
>>>>>>> group<- gl(2,10)
>>>>>>> for (i in 1:10) {
>>>>>>> M1<- lmer (y ~     x + (    x | group))
>>>>>>> M2<- lmer (y ~     x + (    x | group))
>>>>>>> print(identical(M1,M2))
>>>>>>> }
>>>>>>> 
>>>>>>> For CRAN lme4 and Matrix:
>>>>>>> 
>>>>>>> 32 bit on Leopard: R CMD check fails; different results (on most runs)
>>>>>>> 32 bit on Snow Leopard: R CMD check passes; different results (on
>>>>>>> some runs).
>>>>>>> 64 bit on Snow Leopard: R CMD check passes; identical results
>>>>>>> 
>>>>>>> For SVN version of Matrix with CRAN lme4:
>>>>>>> 
>>>>>>> 32 bit on Snow Leopard: different results (on all runs).
>>>>>>> 64 bit on Snow Leopard: different results (on all runs)
>>>>>>> 
>>>>>>> For SVN version of Matrix with SVN lme4a:
>>>>>>> 
>>>>>>> 32 bit on Snow Leopard: different results (on all runs).
>>>>>>> 64 bit on Snow Leopard: identical results
>>>>>>> 
>>>>>>> I couldn't reproduce on Linux 32/64bit. Is it time to jump into
>>>>>>> valgrind to try and find the cause?
>>>>>>> 
>>>>>>> Cheers,
>>>>>>> Daniel
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> On 17/07/10 5:51 PM, John Maindonald wrote:
>>>>>>>> In principle, maybe a Snow Leopard version might be posted
>>>>>>>> as an alternative, if someone can provide one.  But I take it
>>>>>>>> that the issue is now a bit wider than tests that fail on Leopard
>>>>>>>> vs passing on Snow Leopard?
>>>>>>>> 
>>>>>>> 
>>>>> 
>>>> 
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
>> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From catferr at libero.it  Mon Jul 19 18:47:47 2010
From: catferr at libero.it (catferr at libero.it)
Date: Mon, 19 Jul 2010 18:47:47 +0200 (CEST)
Subject: [R-sig-ME] model selection with mcmc
Message-ID: <10466355.243571279558067999.JavaMail.defaultUser@defaultHost>

Dear all
  I am trying to run some models on behavioral data by using lme4 and 
mcmcsamp. I am new with this approach and  I have a question I would like to 
ask you: once I select the best random structure, what is the best way (or more 
advisable at this stage) to do a model selection from a full model (e.g. 
including all potential important variables as fixed effects) to the best 
model? I was wondering if it would be better to use the AIC criterium or to run 
the mcmcsamp on the full model. in case I use the mcmcsamp on the full model 
which is the correct way to proceed? I will check for further reference on this 
topics but if you have some suggestion it would be very appreciated.

thanks a lot
Caterina Ferrari
UQAM



From dodogomez at yahoo.fr  Mon Jul 19 22:27:20 2010
From: dodogomez at yahoo.fr (doris gomez)
Date: Mon, 19 Jul 2010 20:27:20 +0000 (GMT)
Subject: [R-sig-ME] p-values with lmer
Message-ID: <777458.38736.qm@web27506.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100719/de5a1e99/attachment.pl>

From daniel.lists at zeno.co.nz  Mon Jul 19 23:16:48 2010
From: daniel.lists at zeno.co.nz (Daniel Myall)
Date: Tue, 20 Jul 2010 09:16:48 +1200
Subject: [R-sig-ME] non-deterministic behaviour of lme4 on Mac OS X R
 32bit [Was: Failure to load lme4 on Mac]
In-Reply-To: <1081604C-1746-4620-935B-A72AC5AE53DD@gmail.com>
References: <C8207D43.4236%mcmahons@si.edu>
	<AANLkTil72csO0XA3-ZghXw62RUp9gMr-Df1Kx8Bi_Iq2@mail.gmail.com>
	<AANLkTik15uc4QqaIxcwkhAd4HjpzCQ60MuKqiFDJyJnS@mail.gmail.com>
	<08AD950F-C3DB-4E23-868B-0EFD94833014@anu.edu.au>
	<AANLkTil7OZ91zRrGf3licxyYQTdgO7QFfLr5CJoyqPc5@mail.gmail.com>
	<4C3F9E01.9050804@zeno.co.nz>
	<AANLkTimy0SevCeJ87YhFis_fQg-S1ixMwaZF2Bk2K-Jq@mail.gmail.com>
	<E1F79CC7-DB81-4916-B847-10C6C02DF2A8@r-project.org>
	<loom.20100716T153900-860@post.gmane.org>
	<19520.33619.18880.815822@lynne.math.ethz.ch>
	<20100717070706.70fg8lchcskskgo0@imp.inserm.fr>
	<7E3C1A13-65AE-4E6F-9EB6-1EEB2B1677C0@anu.edu.au>
	<4C416EBE.4080204@zeno.co.nz>
	<D32F4A20-8620-4C43-A316-33CD816ACCF9@r-project.org>
	<270A5F5A-081B-4310-B269-4795713260BA@r-project.org>
	<4C4225BF.10501@zeno.co.nz> <4C42CAE9.5070609@zeno.co.nz>
	<AANLkTimd-q7PBYfAMuyTKKXk1Rh6TEQK6SP6cvgdyol4@mail.gmail.com>
	<AANLkTimxEaE-GoeIeIMKgKbrEQQLb-I3DfaHkw9sy8xE@mail.gmail.com>
	<1081604C-1746-4620-935B-A72AC5AE53DD@gmail.com>
Message-ID: <4C44C0C0.5050505@zeno.co.nz>

Hi Jochen,

Thanks for the extended example.  Another example below is showing that 
the differences in fits aren't always small, and actually correspond to 
different number of iterations (in this case 53 versus 41 on R 32 bit, R 
64 bit fit also shown) with slight differences observable on the first 
iteration in the verbose output.

My main concern was that this issue may have influenced several fits of 
real data that I have done lately with lme4 on Mac OS X R 32 bit. 
However,  in comparison to these slightly-pathological examples, I don't 
observe this non-deterministic behaviour with real data.

(Mac OS X 10.6.4, R 2.11.1, using vecLib BLAS - problem disappears with 
R BLAS on 10.6.4 but not with R BLAS on 10.5.8).

Daniel


library(lme4)
set.seed(555)
D <-  data.frame(y= rnorm(20,10), ff = gl(4,5), x1=rnorm(20,3), 
x2=rnorm(20,7))

# Run several times on Mac OS X with R 32 bit to observe two different 
fits. Fine on R 64 bit.
lmer(y ~ (x1 + x2)|ff, data = D,control=list(msVerbose=TRUE))


 > lmer(y ~ (x1 + x2)|ff, data = D,control=list(msVerbose=TRUE))
##SOLUTION 1 - R 32 bit
Linear mixed model fit by REML
Formula: y ~ (x1 + x2) | ff
    Data: D
    AIC   BIC logLik deviance REMLdev
  66.97 74.94 -25.48     50.1   50.97
Random effects:
  Groups   Name        Variance Std.Dev. Corr
  ff       (Intercept) 6.795131 2.60675
           x1          0.225402 0.47477  -0.812
           x2          0.029834 0.17272  -0.906  0.488
  Residual             0.539207 0.73431
Number of obs: 20, groups: ff, 4

Fixed effects:
             Estimate Std. Error t value
(Intercept)   9.9852     0.2616   38.16

##SOLUTION 2 - R 32 bit
 > lmer(y ~ (x1 + x2)|ff, data = D,control=list(msVerbose=TRUE))
Linear mixed model fit by REML
Formula: y ~ (x1 + x2) | ff
    Data: D
    AIC   BIC logLik deviance REMLdev
  67.07 75.04 -25.54    49.89   51.07
Random effects:
  Groups   Name        Variance  Std.Dev. Corr
  ff       (Intercept) 0.5087343 0.713256
           x1          0.2099050 0.458154 -1.000
           x2          0.0015519 0.039395  1.000 -1.000
  Residual             0.6031291 0.776614
Number of obs: 20, groups: ff, 4

Fixed effects:
             Estimate Std. Error t value
(Intercept)   9.8047     0.2239   43.79

##SOLUTION - R 64 bit
Linear mixed model fit by REML
Formula: y ~ (x1 + x2) | ff
    Data: D
    AIC   BIC logLik deviance REMLdev
  67.07 75.04 -25.54    49.89   51.07
Random effects:
  Groups   Name        Variance  Std.Dev. Corr
  ff       (Intercept) 0.5087061 0.71324
           x1          0.2099093 0.45816  -1.000
           x2          0.0015523 0.03940   1.000 -1.000
  Residual             0.6031284 0.77661
Number of obs: 20, groups: ff, 4

Fixed effects:
             Estimate Std. Error t value
(Intercept)   9.8047     0.2239   43.79




##SOLUTION 1 R 32 bit verbose output
   0:     54.397032: 0.730297 0.237125 0.101177  0.00000  0.00000  0.00000
   1:     53.424891: 0.694582 0.208795  0.00000 -0.0845121 -0.225232 
-0.0647230
   2:     52.309724: 0.525523 0.173934  0.00000 -0.0956795 -0.0435683 
-0.245102
   3:     51.796132: 0.531816 0.275691 2.50806e-09 -0.0723777 -0.0177521 
-0.193844
   4:     51.510783: 0.501953 0.339499 0.0185560 -0.102619 -0.0999522 
-0.229227
   5:     51.340266: 0.495931 0.417092  0.00000 -0.108591 -0.0380971 
-0.270879
   6:     51.314044: 0.495003 0.441668  0.00000 -0.119973 -0.0710709 
-0.245133
   7:     51.279576: 0.495433 0.439788  0.00000 -0.121056 -0.0677952 
-0.267080
   8:     51.266170: 0.494992 0.453146  0.00000 -0.137109 -0.0606157 
-0.264009
   9:     51.261334: 0.497575 0.462626 0.00215758 -0.143005 -0.0579236 
-0.273609
  10:     51.257651: 0.500835 0.470608  0.00000 -0.149210 -0.0580369 
-0.264854
  11:     51.247426: 0.512961 0.479519  0.00000 -0.171565 -0.0572242 
-0.271917
  12:     51.243462: 0.514494 0.482739 7.97212e-12 -0.172317 -0.0470170 
-0.273164
  13:     51.242221: 0.517730 0.489447 1.14978e-09 -0.179539 -0.0492034 
-0.270588
  14:     51.238508: 0.522108 0.489827 0.00134272 -0.188105 -0.0461837 
-0.274515
  15:     51.236056: 0.526621 0.491497  0.00000 -0.196288 -0.0424196 
-0.271936
  16:     51.197261: 0.682790 0.501074  0.00000 -0.489111 0.0294043 
-0.264454
  17:     51.189778: 0.787526 0.487157  0.00000 -0.480229 0.0535125 
-0.268740
  18:     51.185330: 0.690942 0.426891  0.00000 -0.320089 -0.0126689 
-0.262818
  19:     51.129963: 0.860167 0.405773  0.00000 -0.525289 0.0349497 
-0.249824
  20:     51.108450: 0.858513 0.399743  0.00000 -0.441274 0.0241085 
-0.249921
  21:     51.085509: 0.960111 0.361481  0.00000 -0.465470 0.0255299 
-0.241661
  22:     51.076072:  1.02659 0.333386  0.00000 -0.462479 0.0181507 
-0.236373
  23:     51.075348:  1.03803 0.329761 0.00171915 -0.459560 0.0180648 
-0.235031
  24:     51.074205:  1.04897 0.324847  0.00000 -0.458212 0.0173642 
-0.234406
  25:     51.073789:  1.06032 0.320322  0.00000 -0.456404 0.0155610 
-0.233229
  26:     51.073094:  1.07187 0.315634 0.000162410 -0.455188 0.0154937 
-0.232546
  27:     51.072409:  1.10979 0.300717 0.000274572 -0.451556 0.0131734 
-0.229526
  28:     51.072379:  1.11039 0.300508 2.31012e-05 -0.449857 0.0128583 
-0.229280
  29:     51.072368:  1.11129 0.300351  0.00000 -0.451022 0.0133420 
-0.228826
  30:     51.072355:  1.11173 0.300610 1.04130e-05 -0.449943 0.0130218 
-0.228551
  31:     51.072344:  1.11328 0.301363 5.89851e-06 -0.448036 0.0125698 
-0.228082
  32:     51.072337:  1.11511 0.302273 5.99925e-06 -0.446401 0.0122070 
-0.227862
  33:     51.072309:  1.12266 0.306077 5.60258e-06 -0.440161 0.0108298 
-0.227340
  34:     51.072241:  1.15331 0.321328 4.37217e-06 -0.415740 0.00543811 
-0.225849
  35:     51.072028:  1.18520 0.332126  0.00000 -0.395151 0.000770566 
-0.225396
  36:     51.071488:  1.31516 0.374814  0.00000 -0.316139 -0.0169819 
-0.225801
  37:     51.068467:  1.45961 0.395095  0.00000 -0.254872 -0.0315079 
-0.231321
  38:     51.066090:  1.48207 0.389322  0.00000 -0.256881 -0.0303985 
-0.235516
  39:     51.062974:  1.57032 0.408708 8.11318e-05 -0.229093 -0.0348309 
-0.240098
  40:     51.057825:  1.66297 0.416006 0.000186021 -0.211495 -0.0397993 
-0.242146
  41:     51.038652:  2.03831 0.430554 0.000524841 -0.187182 -0.0497647 
-0.245336
  42:     51.030401:  2.16630 0.435868 0.000426435 -0.172095 -0.0514469 
-0.247531
  43:     51.024146:  2.22436 0.432647 0.000255846 -0.182843 -0.0474585 
-0.247490
  44:     51.005388:  2.84789 0.426666  0.00000 -0.150432 -0.0571510 
-0.253099
  45:     50.995550:  3.24173 0.389308  0.00000 -0.151364 -0.0610219 
-0.249748
  46:     50.977018:  3.15752 0.389444  0.00000 -0.157012 -0.0565075 
-0.257137
  47:     50.973292:  3.28034 0.387458  0.00000 -0.150868 -0.0583208 
-0.260005
  48:     50.971023:  3.40321 0.381883  0.00000 -0.148687 -0.0593800 
-0.261335
  49:     50.969882:  3.54757 0.376528  0.00000 -0.147883 -0.0601091 
-0.263958
  50:     50.969844:  3.55395 0.376877  0.00000 -0.147903 -0.0600074 
-0.264721
  51:     50.969841:  3.54867 0.377061  0.00000 -0.148001 -0.0599892 
-0.264719
  52:     50.969841:  3.54994 0.376990  0.00000 -0.147962 -0.0600032 
-0.264723
  53:     50.969841:  3.54994 0.376985 9.92829e-09 -0.147966 -0.0600016 
-0.264720

##SOLUTION 2 R 32 bit verbose output
   0:     54.397032: 0.730297 0.237125 0.101177  0.00000  0.00000  0.00000
   1:     53.424876: 0.694582 0.208795  0.00000 -0.0845112 -0.225231 
-0.0647248
   2:     52.309714: 0.525524 0.173936  0.00000 -0.0956772 -0.0435674 
-0.245105
   3:     51.796133: 0.531818 0.275692  0.00000 -0.0723750 -0.0177522 
-0.193847
   4:     51.510778: 0.501954 0.339501 0.0185563 -0.102616 -0.0999511 
-0.229228
   5:     51.340266: 0.495933 0.417093  0.00000 -0.108587 -0.0380969 
-0.270878
   6:     51.314066: 0.495004 0.441675  0.00000 -0.119974 -0.0710830 
-0.245129
   7:     51.279573: 0.495434 0.439793  0.00000 -0.121055 -0.0678019 
-0.267079
   8:     51.266170: 0.494987 0.453150  0.00000 -0.137106 -0.0606079 
-0.264006
   9:     51.261310: 0.497595 0.462675 0.00218985 -0.143053 -0.0579286 
-0.273610
  10:     51.257629: 0.500873 0.470682  0.00000 -0.149297 -0.0580353 
-0.264852
  11:     51.247359: 0.513031 0.479574  0.00000 -0.171743 -0.0571635 
-0.271925
  12:     51.243406: 0.514565 0.482778 1.08518e-09 -0.172496 -0.0469748 
-0.273173
  13:     51.243392: 0.517517 0.489117  0.00000 -0.179386 -0.0500068 
-0.269610
  14:     51.240453: 0.518420 0.488706 0.000131212 -0.180792 -0.0482817 
-0.274468
  15:     51.237928: 0.523090 0.491233 0.000456325 -0.188991 -0.0439936 
-0.272385
  16:     51.190208: 0.621321 0.496717  0.00000 -0.391327 0.00657277 
-0.266122
  17:     51.167675: 0.675696 0.492156  0.00000 -0.454025 0.0277453 
-0.267639
  18:     51.135392: 0.842086 0.420798  0.00000 -0.575192 0.0601573 
-0.259493
  19:     51.116745: 0.836737 0.395554 1.10233e-09 -0.563068 0.0497940 
-0.267516
  20:     51.093702: 0.891244 0.324336  0.00000 -0.559277 0.0469394 
-0.258530
  21:     51.088675: 0.891291 0.324441 3.90944e-12 -0.560389 0.0429698 
-0.256607
  22:     51.087235: 0.893191 0.320990 0.000470701 -0.559711 0.0442643 
-0.254926
  23:     51.078996: 0.936686 0.263380 0.00268585 -0.567754 0.0411852 
-0.250071
  24:     51.072813: 0.975622 0.204411  0.00000 -0.565440 0.0387248 
-0.239708
  25:     51.072273: 0.985859 0.187342  0.00000 -0.570844 0.0390460 
-0.237792
  26:     51.071812: 0.989314 0.167512  0.00000 -0.573474 0.0389454 
-0.233659
  27:     51.071496: 0.983768 0.151969  0.00000 -0.581341 0.0409441 
-0.229549
  28:     51.071256: 0.972827 0.137479  0.00000 -0.590418 0.0429409 
-0.226161
  29:     51.070957: 0.947293 0.108716  0.00000 -0.612238 0.0482764 
-0.219427
  30:     51.070952: 0.927248 0.0855910 0.000952352 -0.628362 0.0522636 
-0.214125
  31:     51.070821: 0.916369 0.0748359 0.000262673 -0.636437 0.0544307 
-0.211681
  32:     51.070780: 0.909515 0.0610305 6.27899e-05 -0.644316 0.0562519 
-0.208965
  33:     51.070734: 0.924013 0.0656458  0.00000 -0.635847 0.0541799 
-0.210599
  34:     51.070620: 0.920001 0.0492322  0.00000 -0.639701 0.0548962 
-0.207517
  35:     51.070588: 0.916679  0.00000  0.00000 -0.644959 0.0554623 
-0.198822
  36:     51.070430: 0.923618  0.00000  0.00000 -0.637526 0.0535969 
-0.199476
  37:     51.070401: 0.916820 0.00470934 6.27813e-05 -0.643440 0.0555798 
-0.199608
  38:     51.070397: 0.918316 0.00160787 9.36880e-06 -0.642337 0.0552253 
-0.199194
  39:     51.070397: 0.918458 0.000122311 2.95739e-06 -0.642295 
0.0552150 -0.198938
  40:     51.070397: 0.918418 3.27547e-05 9.93605e-08 -0.642341 
0.0552323 -0.198916
  41:     51.070397: 0.918418 3.27547e-05 9.93605e-08 -0.642341 
0.0552323 -0.198916

## SOLUTION R 64 bit verbose output
   0:     54.397032: 0.730297 0.237125 0.101177  0.00000  0.00000  0.00000
   1:     53.424870: 0.694584 0.208795  0.00000 -0.0845130 -0.225230 
-0.0647244
   2:     52.309727: 0.525529 0.173935  0.00000 -0.0956826 -0.0435657 
-0.245105
   3:     51.796134: 0.531823 0.275692  0.00000 -0.0723803 -0.0177510 
-0.193847
   4:     51.450927: 0.500902 0.342360  0.00000 -0.102403 -0.0972944 
-0.233869
   5:     51.371013: 0.481020 0.438866 0.0243591 -0.123910 -0.0480737 
-0.266176
   6:     51.277917: 0.481373 0.442344  0.00000 -0.129746 -0.0638011 
-0.269659
   7:     51.271522: 0.481853 0.448398  0.00000 -0.130622 -0.0622441 
-0.263198
   8:     51.267093: 0.482735 0.454038  0.00000 -0.132903 -0.0607989 
-0.269674
   9:     51.260552: 0.485842 0.469711  0.00000 -0.136772 -0.0539558 
-0.266486
  10:     51.253821: 0.491137 0.477787  0.00000 -0.148551 -0.0495027 
-0.275170
  11:     51.247634: 0.496346 0.480217  0.00000 -0.165182 -0.0515957 
-0.271526
  12:     51.206567: 0.595026 0.516835  0.00000 -0.331950 -0.00372166 
-0.270981
  13:     51.193179: 0.619994 0.514666  0.00000 -0.366758 0.00374120 
-0.276707
  14:     51.181583: 0.645429 0.494263  0.00000 -0.389967 0.0206792 
-0.270429
  15:     51.165924: 0.672599 0.486667 0.000763299 -0.423409 0.0201332 
-0.266818
  16:     51.149622: 0.766528 0.462641 0.00204744 -0.527999 0.0511090 
-0.259707
  17:     51.095452: 0.840507 0.344529 0.00241554 -0.567718 0.0502609 
-0.241032
  18:     51.090315: 0.858861 0.304546  0.00000 -0.553297 0.0476001 
-0.238051
  19:     51.077540: 0.899093 0.277922  0.00000 -0.555000 0.0405539 
-0.234436
  20:     51.074770: 0.940670 0.253043 0.00144442 -0.560290 0.0400183 
-0.230554
  21:     51.072690: 0.979609 0.226943  0.00000 -0.550970 0.0351800 
-0.227689
  22:     51.072236:  1.00996 0.213705  0.00000 -0.539170 0.0326290 
-0.225695
  23:     51.071959:  1.00403 0.213148  0.00000 -0.546726 0.0343060 
-0.225637
  24:     51.071943:  1.00239 0.212546  0.00000 -0.545324 0.0336297 
-0.225716
  25:     51.071926:  1.00223 0.211238  0.00000 -0.546573 0.0340303 
-0.225548
  26:     51.071884: 0.999479 0.205777  0.00000 -0.551286 0.0352392 
-0.225004
  27:     51.071748: 0.986381 0.185445  0.00000 -0.568493 0.0393525 
-0.223204
  28:     51.071738: 0.940895 0.119931  0.00000 -0.622375 0.0519225 
-0.217755
  29:     51.071431: 0.945604 0.146434  0.00000 -0.604402 0.0480598 
-0.220346
  30:     51.071239: 0.934417 0.127923  0.00000 -0.616544 0.0506460 
-0.218960
  31:     51.071110: 0.925195 0.111673  0.00000 -0.626599 0.0527393 
-0.217760
  32:     51.070996: 0.918666 0.0929372  0.00000 -0.634293 0.0539966 
-0.216502
  33:     51.070890: 0.924688 0.0907819  0.00000 -0.628645 0.0521726 
-0.216661
  34:     51.070801: 0.918347 0.0775752  0.00000 -0.633475 0.0531133 
-0.216173
  35:     51.070673: 0.917184 0.0611515  0.00000 -0.636366 0.0536126 
-0.215674
  36:     51.070514: 0.914608 0.0308008  0.00000 -0.643298 0.0552587 
-0.214750
  37:     51.070469: 0.920407 0.0253583  0.00000 -0.639986 0.0549125 
-0.215139
  38:     51.070416: 0.919351 0.0170298  0.00000 -0.641940 0.0552652 
-0.214860
  39:     51.070408: 0.918746 0.00749333 1.81821e-05 -0.643165 0.0554947 
-0.214674
  40:     51.070402: 0.918715 0.00987454  0.00000 -0.642126 0.0551905 
-0.214811
  41:     51.070399: 0.918283 0.00617101  0.00000 -0.642457 0.0552644 
-0.214784
  42:     51.070397: 0.918260 0.000523215  0.00000 -0.642508 0.0552671 
-0.214764
  43:     51.070397: 0.918309 0.000283276  0.00000 -0.642415 0.0552520 
-0.214779
  44:     51.070397: 0.918393 1.04493e-05  0.00000 -0.642366 0.0552410 
-0.214780
  45:     51.070397: 0.918393 1.04493e-05  0.00000 -0.642366 0.0552410 
-0.214780





On 20/07/10 3:44 AM, jochen laubrock wrote:
> Hi,
>
> talking about deterministic behavior, what puzzles me even more is why a call to identical sometimes seems to the eliminate the (small) numerical differences between coefficients, and why this depends on the order in which identical and coef/ranef are called. See example (and lengthy output, will probably differ each time called) below.
>
> In TEST1 and TEST2, the difference is always zero although identical often returns FALSE. TEST3, which should do exactly the same as TEST2 up to the second call of identical often produces a difference larger than zero, as does TEST4, in which identical is called after the computation of the difference in coefficients. This does not seem to depend on the order in which TEST1 to TEST4 are performed (not shown).
>
> Well, at least identical never returns TRUE when the difference is not in zero?
>
> This is running in 32-bit mode on Mac OS X, R -arch=i386; no worries if run in 64-bit mode.
>
>
> cheers, jochen
>
>
> # script
> library(lme4)
> y<- (1:20)*pi
> x<- (1:20)^2
> group<- gl(2,10)
>
>
> ntestsPerRun<- 10
> cat("\n--------TEST1--------\n")
> for (i in 1:ntestsPerRun) {
> 	cat(paste("--", "run", i, "--\n"))
> 	M1<- lmer (y ~     x + (x | group))
> 	M2<- lmer (y ~     x + (x | group))
> 	print(identical(ranef(M1),ranef(M2)))
> 	print(identical(coef(M1),coef(M2)))
> 	print(ranef(M1)$group - ranef(M1)$group)
> 	print(coef(M1)$group - coef(M1)$group)
> }
>
> cat("\n--------TEST2--------\n")
> for (i in 1:ntestsPerRun) {
> 	cat(paste("--", "run", i, "--\n"))
> 	M1<- lmer (y ~     x + (x | group))
> 	M2<- lmer (y ~     x + (x | group))
> 	print(identical(ranef(M1),ranef(M2)))
> 	print(ranef(M1)$group - ranef(M1)$group)
> 	print(identical(coef(M1),coef(M2)))
> 	print(coef(M1)$group - coef(M1)$group)
> }
>
> cat("\n--------TEST3--------\n")
> for (i in 1:ntestsPerRun) {
> 	cat(paste("--", "run", i, "--\n"))
> 	M1<- lmer (y ~     x + (    x | group))
> 	M2<- lmer (y ~     x + (    x | group))
> 	print(identical(ranef(M1),ranef(M2)))
> 	print(ranef(M1)$group-ranef(M2)$group)
> }
>
> cat("\n--------TEST4--------\n")
> for (i in 1:ntestsPerRun) {
> 	cat(paste("--", "run", i, "--\n"))
> 	M1<- lmer (y ~     x + (x | group))
> 	M2<- lmer (y ~     x + (x | group))
> 	print(ranef(M1)$group - ranef(M2)$group)
> 	print(coef(M1)$group - coef(M2)$group)
> 	print(identical(ranef(M1),ranef(M2)))
> 	print(identical(coef(M1),ranef(M2)))
> }
> # output
>
>
> --------TEST1--------
> -- run 1 --
> [1] TRUE
> [1] TRUE
>    (Intercept) x
> 1           0 0
> 2           0 0
>    (Intercept) x
> 1           0 0
> 2           0 0
> -- run 2 --
> [1] TRUE
> [1] TRUE
>    (Intercept) x
> 1           0 0
> 2           0 0
>    (Intercept) x
> 1           0 0
> 2           0 0
> -- run 3 --
> [1] TRUE
> [1] TRUE
>    (Intercept) x
> 1           0 0
> 2           0 0
>    (Intercept) x
> 1           0 0
> 2           0 0
> -- run 4 --
> [1] TRUE
> [1] TRUE
>    (Intercept) x
> 1           0 0
> 2           0 0
>    (Intercept) x
> 1           0 0
> 2           0 0
> -- run 5 --
> [1] TRUE
> [1] TRUE
>    (Intercept) x
> 1           0 0
> 2           0 0
>    (Intercept) x
> 1           0 0
> 2           0 0
> -- run 6 --
> [1] TRUE
> [1] TRUE
>    (Intercept) x
> 1           0 0
> 2           0 0
>    (Intercept) x
> 1           0 0
> 2           0 0
> -- run 7 --
> [1] TRUE
> [1] TRUE
>    (Intercept) x
> 1           0 0
> 2           0 0
>    (Intercept) x
> 1           0 0
> 2           0 0
> -- run 8 --
> [1] TRUE
> [1] TRUE
>    (Intercept) x
> 1           0 0
> 2           0 0
>    (Intercept) x
> 1           0 0
> 2           0 0
> -- run 9 --
> [1] TRUE
> [1] TRUE
>    (Intercept) x
> 1           0 0
> 2           0 0
>    (Intercept) x
> 1           0 0
> 2           0 0
> -- run 10 --
> [1] FALSE
> [1] FALSE
>    (Intercept) x
> 1           0 0
> 2           0 0
>    (Intercept) x
> 1           0 0
> 2           0 0
>
> --------TEST2--------
> -- run 1 --
> [1] TRUE
>    (Intercept) x
> 1           0 0
> 2           0 0
> [1] TRUE
>    (Intercept) x
> 1           0 0
> 2           0 0
> -- run 2 --
> [1] TRUE
>    (Intercept) x
> 1           0 0
> 2           0 0
> [1] TRUE
>    (Intercept) x
> 1           0 0
> 2           0 0
> -- run 3 --
> [1] TRUE
>    (Intercept) x
> 1           0 0
> 2           0 0
> [1] TRUE
>    (Intercept) x
> 1           0 0
> 2           0 0
> -- run 4 --
> [1] FALSE
>    (Intercept) x
> 1           0 0
> 2           0 0
> [1] FALSE
>    (Intercept) x
> 1           0 0
> 2           0 0
> -- run 5 --
> [1] FALSE
>    (Intercept) x
> 1           0 0
> 2           0 0
> [1] FALSE
>    (Intercept) x
> 1           0 0
> 2           0 0
> -- run 6 --
> [1] FALSE
>    (Intercept) x
> 1           0 0
> 2           0 0
> [1] FALSE
>    (Intercept) x
> 1           0 0
> 2           0 0
> -- run 7 --
> [1] TRUE
>    (Intercept) x
> 1           0 0
> 2           0 0
> [1] TRUE
>    (Intercept) x
> 1           0 0
> 2           0 0
> -- run 8 --
> [1] FALSE
>    (Intercept) x
> 1           0 0
> 2           0 0
> [1] FALSE
>    (Intercept) x
> 1           0 0
> 2           0 0
> -- run 9 --
> [1] FALSE
>    (Intercept) x
> 1           0 0
> 2           0 0
> [1] FALSE
>    (Intercept) x
> 1           0 0
> 2           0 0
> -- run 10 --
> [1] FALSE
>    (Intercept) x
> 1           0 0
> 2           0 0
> [1] FALSE
>    (Intercept) x
> 1           0 0
> 2           0 0
>
> --------TEST3--------
> -- run 1 --
> [1] TRUE
>    (Intercept) x
> 1           0 0
> 2           0 0
> -- run 2 --
> [1] FALSE
>      (Intercept)             x
> 1  6.613450e-06 -6.898626e-08
> 2 -6.613462e-06  6.898637e-08
> -- run 3 --
> [1] FALSE
>      (Intercept)             x
> 1  6.613450e-06 -6.898626e-08
> 2 -6.613462e-06  6.898637e-08
> -- run 4 --
> [1] FALSE
>      (Intercept)             x
> 1  6.613450e-06 -6.898626e-08
> 2 -6.613462e-06  6.898637e-08
> -- run 5 --
> [1] TRUE
>    (Intercept) x
> 1           0 0
> 2           0 0
> -- run 6 --
> [1] TRUE
>    (Intercept) x
> 1           0 0
> 2           0 0
> -- run 7 --
> [1] TRUE
>    (Intercept) x
> 1           0 0
> 2           0 0
> -- run 8 --
> [1] FALSE
>      (Intercept)             x
> 1  6.613450e-06 -6.898626e-08
> 2 -6.613462e-06  6.898637e-08
> -- run 9 --
> [1] FALSE
>      (Intercept)             x
> 1  6.613450e-06 -6.898626e-08
> 2 -6.613462e-06  6.898637e-08
> -- run 10 --
> [1] FALSE
>      (Intercept)             x
> 1  6.613450e-06 -6.898626e-08
> 2 -6.613462e-06  6.898637e-08
>
> --------TEST4--------
> -- run 1 --
>      (Intercept)             x
> 1 -6.613450e-06  6.898626e-08
> 2  6.613462e-06 -6.898637e-08
>     (Intercept)             x
> 1 3.719195e-06 -4.640498e-08
> 2 1.694611e-05 -1.843776e-07
> [1] FALSE
> [1] FALSE
> -- run 2 --
>      (Intercept)             x
> 1 -6.613450e-06  6.898626e-08
> 2  6.613462e-06 -6.898637e-08
>     (Intercept)             x
> 1 3.719195e-06 -4.640498e-08
> 2 1.694611e-05 -1.843776e-07
> [1] FALSE
> [1] FALSE
> -- run 3 --
>      (Intercept)             x
> 1 -6.613450e-06  6.898626e-08
> 2  6.613462e-06 -6.898637e-08
>     (Intercept)             x
> 1 3.719195e-06 -4.640498e-08
> 2 1.694611e-05 -1.843776e-07
> [1] FALSE
> [1] FALSE
> -- run 4 --
>      (Intercept)             x
> 1 -6.613450e-06  6.898626e-08
> 2  6.613462e-06 -6.898637e-08
>     (Intercept)             x
> 1 3.719195e-06 -4.640498e-08
> 2 1.694611e-05 -1.843776e-07
> [1] FALSE
> [1] FALSE
> -- run 5 --
>    (Intercept) x
> 1           0 0
> 2           0 0
>    (Intercept) x
> 1           0 0
> 2           0 0
> [1] TRUE
> [1] FALSE
> -- run 6 --
>    (Intercept) x
> 1           0 0
> 2           0 0
>    (Intercept) x
> 1           0 0
> 2           0 0
> [1] TRUE
> [1] FALSE
> -- run 7 --
>      (Intercept)             x
> 1 -6.613450e-06  6.898626e-08
> 2  6.613462e-06 -6.898637e-08
>     (Intercept)             x
> 1 3.719195e-06 -4.640498e-08
> 2 1.694611e-05 -1.843776e-07
> [1] FALSE
> [1] FALSE
> -- run 8 --
>    (Intercept) x
> 1           0 0
> 2           0 0
>    (Intercept) x
> 1           0 0
> 2           0 0
> [1] TRUE
> [1] FALSE
> -- run 9 --
>      (Intercept)             x
> 1 -6.613450e-06  6.898626e-08
> 2  6.613462e-06 -6.898637e-08
>     (Intercept)             x
> 1 3.719195e-06 -4.640498e-08
> 2 1.694611e-05 -1.843776e-07
> [1] FALSE
> [1] FALSE
> -- run 10 --
>    (Intercept) x
> 1           0 0
> 2           0 0
>    (Intercept) x
> 1           0 0
> 2           0 0
> [1] TRUE
> [1] FALSE
>
>
>    
>> sessionInfo()
>>      
> R version 2.11.1 Patched (2010-06-14 r52281)
> i386-apple-darwin9.8.0
>
> locale:
> [1] de_DE.UTF-8/de_DE.UTF-8/C/C/de_DE.UTF-8/de_DE.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] lme4_0.999375-33   Matrix_0.999375-40 lattice_0.18-8
>
> loaded via a namespace (and not attached):
> [1] grid_2.11.1  nlme_3.1-96  tools_2.11.1
>
>
>
>
> On Jul 18, 2010, at 13:20 , Reinhold Kliegl wrote:
>
>    
>> Actually, what makes a difference on my machine for this test example
>> is switching to
>> `R --arch x86_64'
>>
>> After this switch linking either R BLAS and vecLIB BLAS checked out
>> fine--at least for 100 tests of the example.
>> ( I think ...).
>>
>> Reinhold Kliegl
>>
>> On Sun, Jul 18, 2010 at 12:28 PM, Reinhold Kliegl
>> <reinhold.kliegl at gmail.com>  wrote:
>>      
>>> First of all, I really appreciate these efforts.
>>>
>>> Changing to R BLAS did not do the trick for me on Mac OS X (10.5.8).
>>> Here is the protocol.
>>>
>>> ###
>>> Last login: Sun Jul 18 12:04:10 on ttys000
>>> Reinhold:~ kliegl$ bash
>>>
>>> ~>  cd /Library/Frameworks/R.framework/Resources/lib
>>> /Library/Frameworks/R.framework/Resources/lib>  ls
>>> i386                    libRblas.vecLib.dylib   libreadline.5.2.dylib
>>> libR.dylib              libRlapack.dylib        libreadline.dylib
>>> libRblas.0.dylib        libgcc_s.1.dylib        ppc
>>> libRblas.dylib          libgfortran.2.dylib     x86_64
>>>
>>> /Library/Frameworks/R.framework/Resources/lib>  ln -sf
>>> libRblas.0.dylib libRblas.dylib
>>> /Library/Frameworks/R.framework/Resources/lib>  R
>>>
>>> R version 2.11.1 Patched (2010-07-16 r52550)
>>> Copyright (C) 2010 The R Foundation for Statistical Computing
>>> ISBN 3-900051-07-0
>>>
>>> <  clipped>
>>>
>>>        
>>>> library(lme4)
>>>>          
>>> <clipped>
>>>
>>>        
>>>> y<- (1:6)*pi # 3.14
>>>> x<- (1:6)^2
>>>> group<- gl(2,3)
>>>> for (i in 1:10) {
>>>>          
>>> + M1<- lmer (y ~     x + (x | group))
>>> + M2<- lmer (y ~     x + (x | group))
>>> + print(identical(ranef(M1),ranef(M2)))
>>> + print(identical(coef(M1),coef(M2)))
>>> +  }
>>> [1] TRUE
>>> [1] TRUE
>>> [1] TRUE
>>> [1] TRUE
>>> [1] FALSE
>>> [1] FALSE
>>> [1] TRUE
>>> [1] TRUE
>>> [1] FALSE
>>> [1] FALSE
>>> [1] FALSE
>>> [1] FALSE
>>> [1] TRUE
>>> [1] TRUE
>>> [1] FALSE
>>> [1] FALSE
>>> [1] TRUE
>>> [1] TRUE
>>> [1] TRUE
>>> [1] TRUE
>>>
>>>        
>>>> sessionInfo()
>>>>          
>>> R version 2.11.1 Patched (2010-07-16 r52550)
>>> i386-apple-darwin9.8.0
>>>
>>> locale:
>>> [1] de_DE/de_DE/C/C/de_DE/de_DE
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> other attached packages:
>>> [1] lme4_0.999375-34   Matrix_0.999375-41 lattice_0.18-8
>>>
>>> loaded via a namespace (and not attached):
>>> [1] grid_2.11.1   nlme_3.1-96   stats4_2.11.1
>>>        
>>>>          
>>> #####
>>>
>>> Did I do something wrong in getting the correct library? Is there a
>>> command to check whether R BLAS is used?
>>>
>>> Using require(lme4) instead of library(lme4) did not make a difference either.
>>>
>>> Many thanks again,
>>> Reinhold Kliegl
>>>
>>>
>>> On Sun, Jul 18, 2010 at 11:35 AM, Daniel Myall<daniel.lists at zeno.co.nz>  wrote:
>>>        
>>>> Hi Simon,
>>>>
>>>> The Apple vecLib BLAS appears to be the cause of the strangeness (at
>>>> least on my machine).
>>>>
>>>> Following:
>>>> http://cran.r-project.org/bin/macosx/RMacOSX-FAQ.html#Which-BLAS-is-used-and-how-can-it-be-changed_003f
>>>>
>>>>
>>>> I changed to the R BLAS and everything now works as it should (i.e., for
>>>> certain source data, lme4 now gives the same solution on multiple runs
>>>> instead of randomly giving one of two different "solutions" on each
>>>> run). The FAQ does note in relation to vecLib BLAS " Although fast, it
>>>> is not under our control and may possibly deliver inaccurate results."
>>>> which appears to be true, at least with lme4.
>>>>
>>>> What BLAS does the CRAN build machine use? If it does use the vecLib
>>>> BLAS is there a case for changing to R BLAS (maybe only when
>>>> building/checking lme4)?
>>>>
>>>> Cheers,
>>>> Daniel
>>>>
>>>> On 18/07/10 9:50 AM, Daniel Myall wrote:
>>>>          
>>>>> Hi Simon,
>>>>>
>>>>> Unfortunately I don't think is the full story (there are actual small
>>>>> differences in the fits).
>>>>>
>>>>> To match the lme4 tests the example should actually be:
>>>>>
>>>>> library(lme4)
>>>>> y<- (1:20)*pi
>>>>> x<- (1:20)^2
>>>>> group<- gl(2,10)
>>>>> for (i in 1:10) {
>>>>> M1<- lmer (y ~     x + (    x | group))
>>>>> M2<- lmer (y ~     x + (    x | group))
>>>>> print(identical(ranef(M1),ranef(M2)))
>>>>> print(ranef(M1)$group-ranef(M2)$group)
>>>>> }
>>>>>
>>>>> Which gives me (the number of TRUE/FALSE and the order change on each
>>>>> run, even if restarting R):
>>>>>
>>>>> [1] FALSE
>>>>>      (Intercept)             x
>>>>> 1  6.613450e-06 -6.898626e-08
>>>>> 2 -6.613462e-06  6.898637e-08
>>>>> [1] TRUE
>>>>>    (Intercept) x
>>>>> 1           0 0
>>>>> 2           0 0
>>>>> [1] FALSE
>>>>>      (Intercept)             x
>>>>> 1 -6.613450e-06  6.898626e-08
>>>>> 2  6.613462e-06 -6.898637e-08
>>>>> [1] FALSE
>>>>>      (Intercept)             x
>>>>> 1  6.613450e-06 -6.898626e-08
>>>>> 2 -6.613462e-06  6.898637e-08
>>>>> [1] TRUE
>>>>>    (Intercept) x
>>>>> 1           0 0
>>>>> 2           0 0
>>>>> [1] FALSE
>>>>>      (Intercept)             x
>>>>> 1 -6.613450e-06  6.898626e-08
>>>>> 2  6.613462e-06 -6.898637e-08
>>>>> [1] FALSE
>>>>>      (Intercept)             x
>>>>> 1 -6.613450e-06  6.898626e-08
>>>>> 2  6.613462e-06 -6.898637e-08
>>>>> [1] FALSE
>>>>>      (Intercept)             x
>>>>> 1 -6.613450e-06  6.898626e-08
>>>>> 2  6.613462e-06 -6.898637e-08
>>>>> [1] TRUE
>>>>>    (Intercept) x
>>>>> 1           0 0
>>>>> 2           0 0
>>>>> [1] TRUE
>>>>>    (Intercept) x
>>>>> 1           0 0
>>>>> 2           0 0
>>>>>
>>>>>
>>>>> Although only small differences, I assume lme4 should be deterministic?
>>>>>
>>>>> Cheers,
>>>>> Daniel
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> On 18/07/10 8:23 AM, Simon Urbanek wrote:
>>>>>            
>>>>>> Ok, I think I found the issue. I'm not sure why this varies by
>>>>>> platform but the mismatch is due to the @env slot. Two environments
>>>>>> are only identical if it is *the* same environment (i.e. the same
>>>>>> pointer). However, M1 and M2 have different environments. The content
>>>>>> of those environments is identical, but that is irrelevant as it's
>>>>>> not the same pointer. Hence identical(M1, M2) fails (and serialize
>>>>>> comparison succeeds as it cares only about the content).
>>>>>>
>>>>>> So the short story is don't use identical() to compare the models
>>>>>> (unless you remove @env first). The long story raises the question
>>>>>> whether identical() should really return FALSE for environments like
>>>>>>              
>>>>>>> identical(new.env(),new.env())
>>>>>>>                
>>>>>> [1] FALSE
>>>>>> I can see arguments both ways but for the purposes of comparing
>>>>>> values there should be an option that the above is TRUE.
>>>>>>
>>>>>> To be honest I don't see why this has not shown up on other platforms
>>>>>> as that is a global issue... (I hope this is the full story - I
>>>>>> didn't try all the combinations to see if setting @env to the same
>>>>>> environment will appease identical() for all the models)
>>>>>>
>>>>>> Cheers,
>>>>>> Simon
>>>>>>
>>>>>>
>>>>>> On Jul 17, 2010, at 3:49 PM, Simon Urbanek wrote:
>>>>>>
>>>>>>              
>>>>>>> Daniel,
>>>>>>>
>>>>>>> thanks for the test case. I did run it in valgrind but nothing
>>>>>>> showed up, however ...
>>>>>>>
>>>>>>> I'm starting to have a suspicion that this has something to do with
>>>>>>> identical() - look at this:
>>>>>>>
>>>>>>>                
>>>>>>>> identical(M1,M2)
>>>>>>>>                  
>>>>>>> [1] FALSE
>>>>>>>                
>>>>>>>> all(serialize(M1,NULL)==serialize(M2,NULL))
>>>>>>>>                  
>>>>>>> [1] TRUE
>>>>>>>                
>>>>>>>> identical(unserialize(serialize(M1,NULL)),unserialize(serialize(M2,NULL)))
>>>>>>>>
>>>>>>>>                  
>>>>>>> [1] FALSE
>>>>>>>                
>>>>>>>> identical(unserialize(serialize(M1,NULL)),unserialize(serialize(M1,NULL)))
>>>>>>>>
>>>>>>>>                  
>>>>>>> [1] FALSE
>>>>>>>
>>>>>>> So I think this may be a bug in identical() mainly because of the
>>>>>>> last one. I'll need to take identical() apart to see where it fails
>>>>>>> ... I'm CCing this to R-devel as the current issue seems more like
>>>>>>> an R issue so more eyes can have a look ...
>>>>>>>
>>>>>>> Cheers,
>>>>>>> Simon
>>>>>>>
>>>>>>>
>>>>>>> [FWIW this is tested in today's R-devel (with valgrind level 2) on
>>>>>>> x86_64 OS X 10.6.4 with lme4 from CRAN and Matrix form R-devel
>>>>>>> Recommended]
>>>>>>>
>>>>>>>
>>>>>>> On Jul 17, 2010, at 4:50 AM, Daniel Myall wrote:
>>>>>>>
>>>>>>>                
>>>>>>>> I've done some further testing (R 2.11.1) and the issue is not
>>>>>>>> limited to Leopard.
>>>>>>>>
>>>>>>>> Using the test:
>>>>>>>>
>>>>>>>> library(lme4)
>>>>>>>> y<- (1:20)*pi
>>>>>>>> x<- (1:20)^2
>>>>>>>> group<- gl(2,10)
>>>>>>>> for (i in 1:10) {
>>>>>>>> M1<- lmer (y ~     x + (    x | group))
>>>>>>>> M2<- lmer (y ~     x + (    x | group))
>>>>>>>> print(identical(M1,M2))
>>>>>>>> }
>>>>>>>>
>>>>>>>> For CRAN lme4 and Matrix:
>>>>>>>>
>>>>>>>> 32 bit on Leopard: R CMD check fails; different results (on most runs)
>>>>>>>> 32 bit on Snow Leopard: R CMD check passes; different results (on
>>>>>>>> some runs).
>>>>>>>> 64 bit on Snow Leopard: R CMD check passes; identical results
>>>>>>>>
>>>>>>>> For SVN version of Matrix with CRAN lme4:
>>>>>>>>
>>>>>>>> 32 bit on Snow Leopard: different results (on all runs).
>>>>>>>> 64 bit on Snow Leopard: different results (on all runs)
>>>>>>>>
>>>>>>>> For SVN version of Matrix with SVN lme4a:
>>>>>>>>
>>>>>>>> 32 bit on Snow Leopard: different results (on all runs).
>>>>>>>> 64 bit on Snow Leopard: identical results
>>>>>>>>
>>>>>>>> I couldn't reproduce on Linux 32/64bit. Is it time to jump into
>>>>>>>> valgrind to try and find the cause?
>>>>>>>>
>>>>>>>> Cheers,
>>>>>>>> Daniel
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> On 17/07/10 5:51 PM, John Maindonald wrote:
>>>>>>>>                  
>>>>>>>>> In principle, maybe a Snow Leopard version might be posted
>>>>>>>>> as an alternative, if someone can provide one.  But I take it
>>>>>>>>> that the issue is now a bit wider than tests that fail on Leopard
>>>>>>>>> vs passing on Snow Leopard?
>>>>>>>>>
>>>>>>>>>                    
>>>>>>>>                  
>>>>>>              
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>            
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>>          
>>>        
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>      
>



From Christoph.Scherber at agr.uni-goettingen.de  Mon Jul 19 23:32:49 2010
From: Christoph.Scherber at agr.uni-goettingen.de (Christoph Scherber)
Date: Mon, 19 Jul 2010 23:32:49 +0200
Subject: [R-sig-ME] p-values with lmer
In-Reply-To: <777458.38736.qm@web27506.mail.ukl.yahoo.com>
References: <777458.38736.qm@web27506.mail.ukl.yahoo.com>
Message-ID: <6fb6c2ea25c10d3189855b76ece0cb71.squirrel@mailbox.gwdg.de>

Dear Doris,

I assume you performed a likelihood ratio test on the two models?

The model containing X1 has the lower AIC, so it is actually pointless to
perform a likelihood ratio test on that model and a model containing both
X1 and X2.

Rather, to assess the significanced of X1, you should compare the model to
a null model (containing the intercept only).

The algorithm is like this:

- Write down your minimal adequate model
- Write down the corresponding null model
- Perform likelihood ratio tests, starting with the null model and adding
terms one at a time until you arrive at the minimal adequate model.

Example:

- minimal adequate model contains X1+X2+X3
- Null model is ~1
- Now do LRT?s with:

~1
~1+X1
~1+X1+X2
~1+X1+X2+X3

And be sure to use;
(1) QAIC in case of overdispersion
(2) AICc in case of small sample sizes

All the best
Christoph









> Dear lmer users,
>
> I compute several models with lmer (poisson distribution, correction for
> overdispersion).
>
> I run several models with the same random effect and different structures
> for
> fixed effect (a full model and different models with only some of the
> factors of
> the full model).
>
> I select the model with the minimal AIC. In fact, two models are within 2
> AIC
> units:
> - a model (with lowest AIC) with one factor, X1.
> - another model (at 0.8 of the first) with two factors, X1 and X2.
>
> Looking at the p-values, X1 is significant in both models while X2 is not
> significant, despite the low AIC associated to the model. How to interpret
> the
> apparent contradiction between the non-significant p-value and the low
> AIC?
>
>
>>From an old message on the list, I can see that p-values  are not good.
> But the bayesian approach mcmcsample does not run either with lmer.
>
> How to get the p-values associated with the fixed effects?
> Thank you for your help
> Doris Gomez
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From F.DUYME at arvalisinstitutduvegetal.fr  Tue Jul 20 09:18:09 2010
From: F.DUYME at arvalisinstitutduvegetal.fr (DUYME Florent)
Date: Tue, 20 Jul 2010 09:18:09 +0200
Subject: [R-sig-ME] with lmer : Erreur dans names(argNew)[1] <-
	names(formals(new))[[1]]
Message-ID: <674BC74273529E40A236CE2FB772DE093539D2E4B0@srv-exch-bgn.arvalis-fr.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100720/d4d1caf1/attachment.pl>

From Timothy_Handley at nps.gov  Wed Jul 21 16:43:29 2010
From: Timothy_Handley at nps.gov (Timothy_Handley at nps.gov)
Date: Wed, 21 Jul 2010 07:43:29 -0700
Subject: [R-sig-ME] non-positive definite matrix
Message-ID: <OF12EBB512.3B89F739-ON88257767.004F4640-88257767.0050E2D0@nps.gov>


Hello,

I'm trying to use lmer to fit a linear mixed effects model to some data.
Unfortunately, lmer fails, saying "Error in mer_finalize(ans) : Downdated
X'X is not positive definite." While this may be a problem with my setup,
I've looked over it several times, so I think this is more likely a result
of my data. A quick search of the internet suggests that sometimes, the
random errors in real data are such that the resulting matrices are
mathematically unacceptable.

My one thought is that I might be able to avoid this problem by using a
function which fits a model via iteration/optimization. Based on a very
rough understanding of lmer, from Bates's book, my impression is that
*linear* mixed models are fit via some matrix method (akin to vanilla
least-squares regression), while generalized mixed models are fit via
optimization (similar to glm). If this is true, then if I could  get glmer
to fit my lmm via optimization, then perhaps I could fit this model to my
data without needing to tweak the data.

I would greatly appreciate any thoughts or advice any of you might have on
this problem. Thanks,

Tim Handley
Fire Effects Monitor
Santa Monica Mountains National Recreation Area
401 W. Hillcrest Dr.
Thousand Oaks, CA 91360
805-370-2300 x2412



From datkins at u.washington.edu  Wed Jul 21 18:32:20 2010
From: datkins at u.washington.edu (David Atkins)
Date: Wed, 21 Jul 2010 09:32:20 -0700
Subject: [R-sig-ME] non-positive definite matrix
In-Reply-To: <OF12EBB512.3B89F739-ON88257767.004F4640-88257767.0050E2D0@nps.gov>
References: <OF12EBB512.3B89F739-ON88257767.004F4640-88257767.0050E2D0@nps.gov>
Message-ID: <4C472114.3070303@u.washington.edu>


Hi Tim--

All methods in the lme4 package (i.e., lmer, glmer, nlmer) use iterative 
optimization routines.  You can see the iterations if you set "verbose = 
TRUE".  It is true that linear mixed models are easier to fit, but it is 
still an iterative fitting procedure.

I have received the error you mention several times, which always (I 
believe) stemmed from one of two sources:

1. There was redundancy in the fixed-effects.

2. I was trying to fit a very complicated model to not so much data.

As a proposed "solution" for either 1 or 2 above, I'd suggest starting 
with a very simple model and work up slowly.  Ideally, you could 
diagnose quickly where the error occurs -- that is, is there some 
predictor or random-effect that seems to trigger the error when it 
enters the model.

If those don't seem helpful or not relevant, then more info about your 
data, your model, and ideally a reproducible example will get you a lot 
more helpful responses.

[Hope your staying cool in Thousand Oaks...]

cheers, Dave

Tim wrote:

Hello,

I'm trying to use lmer to fit a linear mixed effects model to some data.
Unfortunately, lmer fails, saying "Error in mer_finalize(ans) : Downdated
X'X is not positive definite." While this may be a problem with my setup,
I've looked over it several times, so I think this is more likely a result
of my data. A quick search of the internet suggests that sometimes, the
random errors in real data are such that the resulting matrices are
mathematically unacceptable.

My one thought is that I might be able to avoid this problem by using a
function which fits a model via iteration/optimization. Based on a very
rough understanding of lmer, from Bates's book, my impression is that
*linear* mixed models are fit via some matrix method (akin to vanilla
least-squares regression), while generalized mixed models are fit via
optimization (similar to glm). If this is true, then if I could  get glmer
to fit my lmm via optimization, then perhaps I could fit this model to my
data without needing to tweak the data.

I would greatly appreciate any thoughts or advice any of you might have on
this problem. Thanks,

Tim Handley
Fire Effects Monitor
Santa Monica Mountains National Recreation Area
401 W. Hillcrest Dr.
Thousand Oaks, CA 91360
805-370-2300 x2412



-- 
Dave Atkins, PhD
Research Associate Professor
Department of Psychiatry and Behavioral Science
University of Washington
datkins at u.washington.edu

Center for the Study of Health and Risk Behaviors (CSHRB)		
1100 NE 45th Street, Suite 300 	
Seattle, WA  98105 	
206-616-3879 	
http://depts.washington.edu/cshrb/
(Mon-Wed)	

Center for Healthcare Improvement, for Addictions, Mental Illness,
   Medically Vulnerable Populations (CHAMMP)
325 9th Avenue, 2HH-15
Box 359911
Seattle, WA 98104
http://www.chammp.org
(Thurs)



From igorblan at gmail.com  Wed Jul 21 18:23:20 2010
From: igorblan at gmail.com (Igor Blanco)
Date: Wed, 21 Jul 2010 18:23:20 +0200
Subject: [R-sig-ME] Binary variables used with lme model
Message-ID: <AANLkTilsUTvCVBaY-dXWFI4Dc7GyYcpD34KWECk-XCoW@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100721/0bea2cb1/attachment.pl>

From pauljohn32 at gmail.com  Thu Jul 22 05:34:38 2010
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Wed, 21 Jul 2010 22:34:38 -0500
Subject: [R-sig-ME] data cloning. have you seen this?
Message-ID: <AANLkTik7O5GRgrEYlx2w20ycP9cg7u631SPqoSiSR0RP@mail.gmail.com>

Hey, everybody:

Have you seen these papers that use "data cloning" for
hierarchical/mixed models? I'm pasting in 2 bibtex cites.  The claims
are so fantastic that I can't hardly believe them.   One can obtain ML
estimates and information matrix from an ensemble of  MCMC estimates
derived from clones of a data set.  I don't know how that is different
from averaging a lot of MCMC chains together, it sure seems like it.

I don't have an axe to grind here.  I'm asking you, the smartest folks
I know ( :) ), what you think?

(I found this by accident. The rjags package turned up with a reverse
depends on the package "dclone" and I was curious to know what dclone
is for. The man pages in dclone point at the first Lele et al article
below. )

I don't know how this addresses the problem that estimates of variance
estimates of the variance components can't be normally distributed,
even asymptotically, because they have that boundary at 0.   It seems
as though they assume that away, in the same way that many other
frequentists do.

I also wonder about the small-medium sized sample performance of this
kind of ML approximation versus a genuine Bayesian approach.

@article{lele_data_2007,
        title = {Data cloning: easy maximum likelihood estimation for
complex ecological models using Bayesian Markov chain Monte Carlo
methods},
        volume = {10},
        issn = {1461-0248},
        shorttitle = {Data cloning},
        url = {http://www.ncbi.nlm.nih.gov/pubmed/17542934},
        doi = {10.1111/j.1461-0248.2007.01047.x},
        abstract = {We introduce a new statistical computing method,
called data cloning, to calculate maximum likelihood estimates and
their standard errors for complex ecological models. Although the
method uses the Bayesian framework and exploits the computational
simplicity of the Markov chain Monte Carlo {(MCMC)} algorithms, it
provides valid frequentist inferences such as the maximum likelihood
estimates and their standard errors. The inferences are completely
invariant to the choice of the prior distributions and therefore avoid
the inherent subjectivity of the Bayesian approach. The data cloning
method is easily implemented using standard {MCMC} software. Data
cloning is particularly useful for analysing ecological situations in
which hierarchical statistical models, such as state-space models and
mixed effects models, are appropriate. We illustrate the method by
fitting two nonlinear population dynamics models to data in the
presence of process and observation noise.},
        number = {7},
        journal = {Ecology Letters},
        author = {Subhash R Lele and Brian Dennis and Frithjof Lutscher},
        month = jul,
        year = {2007},
        note = {{PMID:} 17542934},
        keywords = {Bayes Theorem, Computational Biology, Computer
Simulation, Ecology, Ecosystem, Likelihood Functions, Markov Chains,
Models, Biological, {MONTE} Carlo method, Population Dynamics},
        pages = {551--563}
},


@article{ponciano_hierarchical_2009,
        title = {Hierarchical models in ecology: confidence intervals,
hypothesis testing, and model selection using data cloning},
        volume = {90},
        issn = {0012-9658},
        shorttitle = {Hierarchical models in ecology},
        url = {http://www.esajournals.org/doi/abs/10.1890/08-0967.1},
        doi = {10.1890/08-0967.1},
        number = {2},
        journal = {Ecology},
        author = {Jos? Miguel Ponciano and Mark L. Taper and Brian
Dennis and Subhash R. Lele},
        year = {2009},
        pages = {356--362}
},





-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas



From davidD at qimr.edu.au  Thu Jul 22 07:36:48 2010
From: davidD at qimr.edu.au (David Duffy)
Date: Thu, 22 Jul 2010 15:36:48 +1000 (EST)
Subject: [R-sig-ME] data cloning. have you seen this?
In-Reply-To: <AANLkTik7O5GRgrEYlx2w20ycP9cg7u631SPqoSiSR0RP@mail.gmail.com>
References: <AANLkTik7O5GRgrEYlx2w20ycP9cg7u631SPqoSiSR0RP@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.1007221512470.9735@orpheus.qimr.edu.au>

On Wed, 21 Jul 2010, Paul Johnson wrote:

> Hey, everybody:
>
> Have you seen these papers that use "data cloning" for
> hierarchical/mixed models?

As I understand the first paper, at least, they are "just" using MCMC to 
fit ML frequentist models, wuth WinBUGS being used because it is 
convenient.  I have been using data cloning for MCMC GLMM a while, and it 
does seem to improve the point estimates for the fixed effects regression 
coefficients and variance components.  I came upon it as a natural thing 
to do with a poorly mixing model on a smaller example dataset, and it was 
subsequently pointed out to me to be used in the machine learning 
literature as well.  I also decided that it was not used by WinBUGs 
because their algorithms were better formulated, and didn't need this 
crutch ;) -- it does slow things down.

Thanks for the references!

David Duffy.

PS If you are interested, I will post an example of its effects on random
effects variances for a GLMM.


-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From goulven.salic at edf.fr  Thu Jul 22 11:00:51 2010
From: goulven.salic at edf.fr (Goulven SALIC)
Date: Thu, 22 Jul 2010 11:00:51 +0200
Subject: [R-sig-ME] Piecewise linear regression using lme()
Message-ID: <OF320AC167.15A265FF-ONC1257768.003173CA-C1257768.003184B0@notes.edfgdf.fr>

Hi everyone,

I'm trying to fit a of piecewise regression model on a time series. The 
idea is to divide the series into segments and then to apply linear 
regression models on each segment but in a "global way" and considering 
heteroskedasticity between the segments. For example, I build a time 
series y with 3 segments:

segment1=1:20+rnorm(20,0,2)
segment2=20-2*1:30+rnorm(30,0,5)
segment3=-40+0.5*1:15+rnorm(15,0,1)

group=c(rep(1,20),rep(2,30),rep(3,15))
y=c(segment1,segment2,segment3)

Data=data.frame(y,t=1:65,group=as.factor(group))

the model I'd like to fit is:

y_t= 
(beta_01+beta_11*t+error_1)*(group==1)+(beta_02+beta_12*t+error_2)*(group==2)+(beta_03+beta_13*t+error_3)*(group==3)

It looks like a mixed effects model were the fixed effect are the 
piecewise linear regression parts (beta_0i+beta_1i*t) and the random 
effects are the variance components error_i.

The problem is that I can't find the way the write this model correctly 
using the lme() function of the package nlme. I can't remove the global 
intercept and the global variance component. Here's what I tried:

#1 Using a prior piecewise linear regression

lm.list=lmList(y~t|group,Data)

model.lme=lme(lm.list,weights=varIdent(form=~1|group))

#2 Trying to estimate the whole model directly and considering the 
different lines as random effects

model.lme=lme(y~1,random=~t|group,data=Data)

but the intercept remains...

I read a lot of R-help messages before posting this one (my first!) and 
I'm not getting any closer. It looks like no one tried to estimate the 
exact same model. I'll be very grateful if someone could help me on this.

Thanks

Goulven 
-------------- next part --------------



Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont ?tablis ? l'intention exclusive des destinataires et les informations qui y figurent sont strictement confidentielles. Toute utilisation de ce Message non conforme ? sa destination, toute diffusion ou toute publication totale ou partielle, est interdite sauf autorisation expresse.

Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace sur quelque support que ce soit. Nous vous remercions ?galement d'en avertir imm?diatement l'exp?diteur par retour du message.

Il est impossible de garantir que les communications par messagerie ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute erreur ou virus.
____________________________________________________

This message and any attachments (the 'Message') are intended solely for the addressees. The information contained in this Message is confidential. Any use of information contained in this Message not in accord with its purpose, any dissemination or disclosure, either whole or partial, is prohibited except formal approval.

If you are not the addressee, you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return message.

E-mail communication cannot be guaranteed to be timely secure, error or virus-free.

From kevin.thorpe at utoronto.ca  Thu Jul 22 21:15:50 2010
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Thu, 22 Jul 2010 15:15:50 -0400
Subject: [R-sig-ME] Question About Cluster RCT analysis
Message-ID: <4C4898E6.1070508@utoronto.ca>

Hello.

I'm in the process of analyzing a cluster RCT with a continuous outcome
and am comparing some methods to help aid my understanding.  I have
compared the results from t.test.cluster in Hmisc to results using lmer
in lme4 and geese in geepack.  My main question concerns the effect size
(follows the output from all three analyses).  Here is the output from 
t.test.cluster.

> with(fim, t.test.cluster(FIM_TotalScore,Hospital_Code,Group))
                                    Control    Intervention
N                                   882        921
Clusters                            10         10
Mean                                98.00680   99.79045
SS among clusters within groups     36569.40   47721.81
SS within clusters within groups    411844.6   445172.7
MS among clusters within groups     4682.845
d.f.                                18
MS within clusters within groups    480.6603
d.f.                                1783
Na                                  82.28852
Intracluster correlation            0.09603894
Variance Correction Factor          12.63857   12.17243
Variance of effect                  13.24026
Variance without cluster adjustment 1.066856
Design Effect                       12.41054
Effect (Difference in Means)        1.783642
S.E. of Effect                      3.638716
0.95 Confidence limits              -5.348111   8.915396
Z Statistic                         0.4901845
2-sided P Value                     0.6240033

Now, lmer.

> lmer(FIM_TotalScore~Group+(1|Hospital_Code),data=fim)
Linear mixed model fit by REML
Formula: FIM_TotalScore ~ Group + (1 | Hospital_Code)
   Data: fim
   AIC   BIC logLik deviance REMLdev
16292 16314  -8142    16291   16284
Random effects:
Groups        Name        Variance Std.Dev.
Hospital_Code (Intercept)  46.279   6.8029
Residual                  480.657  21.9239
Number of obs: 1803, groups: Hospital_Code, 20

Fixed effects:
                  Estimate Std. Error t value
(Intercept)        98.7553     2.3091   42.77
GroupIntervention   0.5398     3.2653    0.17

Correlation of Fixed Effects:
            (Intr)
GrpIntrvntn -0.707
> 46.279/(46.279+480.657)  # icc

Finally, geese.

> 
summary(geese(FIM_TotalScore~Group,id=Hospital_Code,data=fim,corstr="exchangeable"))

Call:
geese(formula = FIM_TotalScore ~ Group, id = Hospital_Code, data = fim,
    corstr = "exchangeable")

Mean Model:
Mean Link:                 identity
Variance to Mean Relation: gaussian

Coefficients:
                    estimate   san.se         wald         p
(Intercept)       98.7547493 2.052763 2.314399e+03 0.0000000
GroupIntervention  0.5472461 3.195752 2.932373e-02 0.8640337

Scale Model:
Scale Link:                identity

Estimated Scale Parameters:
            estimate   san.se     wald p
(Intercept) 522.4746 50.14271 108.5712 0

Correlation Model:
Correlation Structure:     exchangeable
Correlation Link:          identity

Estimated Correlation Parameters:
       estimate     san.se     wald           p
alpha 0.0828722 0.02078484 15.89734 6.68725e-05

Returned Error Value:    0
Number of clusters:   20   Maximum cluster size: 223

As you can see, the effect size in t.test.cluser is 1.783642 which is
the difference in the means, which makes sense to me.  I would have
expected the estimate of the fixed group effect in lmer and geese to be
similar to this, which they are not, although they are similar to each
other.  lmer = 0.5398 and geese = 0.5472461.  The intercepts in both
cases are very close to the control group mean.  The icc estimates are
close, lmer = 0.0878266 (based on the random effect variances),
geese = 0.0828722 (the correlation in the exchangeable structure),
t.test.cluster = 0.09603894.

My contrasts are not weird.

> options("contrasts")
$contrasts
        unordered           ordered
"contr.treatment"      "contr.poly"

> contrasts(fim$Group)
             Intervention
Control                 0
Intervention            1

I'm probably being dense today, but can you offer any explanation for
the difference even if that involves exposing my denseness?

 > sessionInfo()
R version 2.10.1 Patched (2009-12-29 r50852)
i686-pc-linux-gnu

locale:
  [1] LC_CTYPE=en_US       LC_NUMERIC=C         LC_TIME=en_US
  [4] LC_COLLATE=C         LC_MONETARY=C        LC_MESSAGES=en_US
  [7] LC_PAPER=en_US       LC_NAME=C            LC_ADDRESS=C
[10] LC_TELEPHONE=C       LC_MEASUREMENT=en_US LC_IDENTIFICATION=C

attached base packages:
[1] splines   stats     graphics  grDevices utils     datasets  methods
[8] base

other attached packages:
[1] geepack_1.0-17     doBy_4.0.5         lme4_0.999375-33 
Matrix_0.999375-38
[5] lattice_0.18-3     Hmisc_3.7-0        survival_2.35-8

loaded via a namespace (and not attached):
[1] cluster_1.12.3 grid_2.10.1    nlme_3.1-96    tools_2.10.1


Kevin

-- 
Kevin E. Thorpe
Biostatistician/Trialist, Knowledge Translation Program
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016



From reinhold.kliegl at gmail.com  Thu Jul 22 22:08:09 2010
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Thu, 22 Jul 2010 22:08:09 +0200
Subject: [R-sig-ME] Question About Cluster RCT analysis
In-Reply-To: <4C4898E6.1070508@utoronto.ca>
References: <4C4898E6.1070508@utoronto.ca>
Message-ID: <AANLkTilUXVEZBlPK1j0OSjylfH82BuoPQfSfw1JKIe3a@mail.gmail.com>

This is a really surprising result, but then I do not know anything
about t.test.cluster(). Anyway, I would recommend to artifiically
balance the clusters (either by randomly deleting or even simply
re-assigning cases) or by removing some outlier clusters completely.
Do lmer and geese reproduce the treatment effect for such data?

Reinhold Kliegl

On Thu, Jul 22, 2010 at 9:15 PM, Kevin E. Thorpe
<kevin.thorpe at utoronto.ca> wrote:
> Hello.
>
> I'm in the process of analyzing a cluster RCT with a continuous outcome
> and am comparing some methods to help aid my understanding. ?I have
> compared the results from t.test.cluster in Hmisc to results using lmer
> in lme4 and geese in geepack. ?My main question concerns the effect size
> (follows the output from all three analyses). ?Here is the output from
> t.test.cluster.
>
>> with(fim, t.test.cluster(FIM_TotalScore,Hospital_Code,Group))
>
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Control ? ?Intervention
> N ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 882 ? ? ? ?921
> Clusters ? ? ? ? ? ? ? ? ? ? ? ? ? ?10 ? ? ? ? 10
> Mean ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?98.00680 ? 99.79045
> SS among clusters within groups ? ? 36569.40 ? 47721.81
> SS within clusters within groups ? ?411844.6 ? 445172.7
> MS among clusters within groups ? ? 4682.845
> d.f. ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?18
> MS within clusters within groups ? ?480.6603
> d.f. ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?1783
> Na ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?82.28852
> Intracluster correlation ? ? ? ? ? ?0.09603894
> Variance Correction Factor ? ? ? ? ?12.63857 ? 12.17243
> Variance of effect ? ? ? ? ? ? ? ? ?13.24026
> Variance without cluster adjustment 1.066856
> Design Effect ? ? ? ? ? ? ? ? ? ? ? 12.41054
> Effect (Difference in Means) ? ? ? ?1.783642
> S.E. of Effect ? ? ? ? ? ? ? ? ? ? ?3.638716
> 0.95 Confidence limits ? ? ? ? ? ? ?-5.348111 ? 8.915396
> Z Statistic ? ? ? ? ? ? ? ? ? ? ? ? 0.4901845
> 2-sided P Value ? ? ? ? ? ? ? ? ? ? 0.6240033
>
> Now, lmer.
>
>> lmer(FIM_TotalScore~Group+(1|Hospital_Code),data=fim)
>
> Linear mixed model fit by REML
> Formula: FIM_TotalScore ~ Group + (1 | Hospital_Code)
> ?Data: fim
> ?AIC ? BIC logLik deviance REMLdev
> 16292 16314 ?-8142 ? ?16291 ? 16284
> Random effects:
> Groups ? ? ? ?Name ? ? ? ?Variance Std.Dev.
> Hospital_Code (Intercept) ?46.279 ? 6.8029
> Residual ? ? ? ? ? ? ? ? ?480.657 ?21.9239
> Number of obs: 1803, groups: Hospital_Code, 20
>
> Fixed effects:
> ? ? ? ? ? ? ? ? Estimate Std. Error t value
> (Intercept) ? ? ? ?98.7553 ? ? 2.3091 ? 42.77
> GroupIntervention ? 0.5398 ? ? 3.2653 ? ?0.17
>
> Correlation of Fixed Effects:
> ? ? ? ? ? (Intr)
> GrpIntrvntn -0.707
>>
>> 46.279/(46.279+480.657) ?# icc
>
> Finally, geese.
>
>>
> summary(geese(FIM_TotalScore~Group,id=Hospital_Code,data=fim,corstr="exchangeable"))
>
> Call:
> geese(formula = FIM_TotalScore ~ Group, id = Hospital_Code, data = fim,
> ? corstr = "exchangeable")
>
> Mean Model:
> Mean Link: ? ? ? ? ? ? ? ? identity
> Variance to Mean Relation: gaussian
>
> Coefficients:
> ? ? ? ? ? ? ? ? ? estimate ? san.se ? ? ? ? wald ? ? ? ? p
> (Intercept) ? ? ? 98.7547493 2.052763 2.314399e+03 0.0000000
> GroupIntervention ?0.5472461 3.195752 2.932373e-02 0.8640337
>
> Scale Model:
> Scale Link: ? ? ? ? ? ? ? ?identity
>
> Estimated Scale Parameters:
> ? ? ? ? ? estimate ? san.se ? ? wald p
> (Intercept) 522.4746 50.14271 108.5712 0
>
> Correlation Model:
> Correlation Structure: ? ? exchangeable
> Correlation Link: ? ? ? ? ?identity
>
> Estimated Correlation Parameters:
> ? ? ?estimate ? ? san.se ? ? wald ? ? ? ? ? p
> alpha 0.0828722 0.02078484 15.89734 6.68725e-05
>
> Returned Error Value: ? ?0
> Number of clusters: ? 20 ? Maximum cluster size: 223
>
> As you can see, the effect size in t.test.cluser is 1.783642 which is
> the difference in the means, which makes sense to me. ?I would have
> expected the estimate of the fixed group effect in lmer and geese to be
> similar to this, which they are not, although they are similar to each
> other. ?lmer = 0.5398 and geese = 0.5472461. ?The intercepts in both
> cases are very close to the control group mean. ?The icc estimates are
> close, lmer = 0.0878266 (based on the random effect variances),
> geese = 0.0828722 (the correlation in the exchangeable structure),
> t.test.cluster = 0.09603894.
>
> My contrasts are not weird.
>
>> options("contrasts")
>
> $contrasts
> ? ? ? unordered ? ? ? ? ? ordered
> "contr.treatment" ? ? ?"contr.poly"
>
>> contrasts(fim$Group)
>
> ? ? ? ? ? ?Intervention
> Control ? ? ? ? ? ? ? ? 0
> Intervention ? ? ? ? ? ?1
>
> I'm probably being dense today, but can you offer any explanation for
> the difference even if that involves exposing my denseness?
>
>> sessionInfo()
> R version 2.10.1 Patched (2009-12-29 r50852)
> i686-pc-linux-gnu
>
> locale:
> ?[1] LC_CTYPE=en_US ? ? ? LC_NUMERIC=C ? ? ? ? LC_TIME=en_US
> ?[4] LC_COLLATE=C ? ? ? ? LC_MONETARY=C ? ? ? ?LC_MESSAGES=en_US
> ?[7] LC_PAPER=en_US ? ? ? LC_NAME=C ? ? ? ? ? ?LC_ADDRESS=C
> [10] LC_TELEPHONE=C ? ? ? LC_MEASUREMENT=en_US LC_IDENTIFICATION=C
>
> attached base packages:
> [1] splines ? stats ? ? graphics ?grDevices utils ? ? datasets ?methods
> [8] base
>
> other attached packages:
> [1] geepack_1.0-17 ? ? doBy_4.0.5 ? ? ? ? lme4_0.999375-33
> Matrix_0.999375-38
> [5] lattice_0.18-3 ? ? Hmisc_3.7-0 ? ? ? ?survival_2.35-8
>
> loaded via a namespace (and not attached):
> [1] cluster_1.12.3 grid_2.10.1 ? ?nlme_3.1-96 ? ?tools_2.10.1
>
>
> Kevin
>
> --
> Kevin E. Thorpe
> Biostatistician/Trialist, Knowledge Translation Program
> Assistant Professor, Dalla Lana School of Public Health
> University of Toronto
> email: kevin.thorpe at utoronto.ca ?Tel: 416.864.5776 ?Fax: 416.864.3016
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From shigesong at gmail.com  Fri Jul 23 03:36:35 2010
From: shigesong at gmail.com (Shige Song)
Date: Fri, 23 Jul 2010 09:36:35 +0800
Subject: [R-sig-ME] Random slope with npmlreg
Message-ID: <AANLkTikCpuxLw1iWJufeAmxU1WOOKbBGrzUETzUoxRGj@mail.gmail.com>

Dear All,

I am trying to estimate a mixed effect model with random slope with
npmlreg. To make my question clear, I use the sample data set that was
used in the vignettes (as part of the package "nlme").

-----------------------------------------------------------------------------------------------------------------------------------------
> vc2 <- allvc(height ~ age, random=~age|Subject, data=Oxboys, random.distribution="np", k=3)
1 ..2 ..3 ..4 ..5 ..6 ..7 ..8 ..9 ..10 .. EM algorithm met convergence
criteria at iteration # 10 Disparity trend plotted.
EM Trajectories plotted.

> summary(vc2)

Call: allvc(formula = height ~ age, random = ~age | Subject, data =
Oxboys, k = 3, random.distribution = "np")

Coefficients:

            Estimate Std. Error    t value
age         7.919030  0.4065465  19.478782
MASS1     138.588240  0.2827517 490.141113
MASS2     149.249701  0.1921859 776.590184
MASS3     158.909797  0.2627202 604.863195

MASS1:age -2.350977 0.5966915 -3.940021 MASS2:age -1.701525 0.5034540 -3.379703

Mixture proportions:

    MASS1 MASS2 MASS3
0.2313332 0.5007243 0.2679425

Component distribution - MLE of sigma:	   3.586
Random effect distribution - standard deviation:	   7.161265

-2 log L:	    1315     Convergence at iteration  10
-----------------------------------------------------------------------------------------------------------------------------------------

My question is: how do I interpret the random slope coefficients
"age", "MASS1:age", and "MASS2:age"? Does it mean that the effect of
age is 7.919030 in the third component, -2.350977 in the first
component, and -1.701525 in the second, or something else?

Many thanks.

Best,
Shige



From kevin.thorpe at utoronto.ca  Fri Jul 23 15:24:59 2010
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Fri, 23 Jul 2010 09:24:59 -0400
Subject: [R-sig-ME] lme4a versus lme4b
Message-ID: <4C49982B.5070901@utoronto.ca>

Hello.

I decided to update my lme4a installation to play with it on my present
analysis and noticed an lme4b package at r-forge.

Apologies if I missed an announcement, but is lme4 development now
in beta stage with lme4b being the beta version?  Is it the preferred
development package to use now?

Kevin

-- 
Kevin E. Thorpe
Biostatistician/Trialist, Knowledge Translation Program
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016



From bates at stat.wisc.edu  Fri Jul 23 18:10:46 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 23 Jul 2010 11:10:46 -0500
Subject: [R-sig-ME] lme4a versus lme4b
In-Reply-To: <4C49982B.5070901@utoronto.ca>
References: <4C49982B.5070901@utoronto.ca>
Message-ID: <AANLkTi=BC-XpPhOjRZno215QWuMXTfc+2oj0QPMgY=z=@mail.gmail.com>

On Fri, Jul 23, 2010 at 8:24 AM, Kevin E. Thorpe
<kevin.thorpe at utoronto.ca> wrote:
> Hello.
>
> I decided to update my lme4a installation to play with it on my present
> analysis and noticed an lme4b package at r-forge.
>
> Apologies if I missed an announcement, but is lme4 development now
> in beta stage with lme4b being the beta version? ?Is it the preferred
> development package to use now?

No.  What is in lme4b is an interim version that will never see the
light of day.  We kept it around for purposes of cross-checking
results but others should not be concerned about it.

I am currently at the useR!2010 conference where Uwe Ligges spoke this
morning on some of the challenges involved in maintaining CRAN,
especially the Windows binaries in his case.  The changes to lme4 in
lme4a, in particular the use of Rcpp constructions and classes in the
compiled code are somewhat problematic.  Dependence on Rcpp seems to
be associated with unexplained failures in some of the installation
and checking.  As a result it may take a bit longer than hoped to get
lme4a on CRAN.
>
> Kevin
>
> --
> Kevin E. Thorpe
> Biostatistician/Trialist, Knowledge Translation Program
> Assistant Professor, Dalla Lana School of Public Health
> University of Toronto
> email: kevin.thorpe at utoronto.ca ?Tel: 416.864.5776 ?Fax: 416.864.3016
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From Thierry.ONKELINX at inbo.be  Mon Jul 26 10:31:52 2010
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 26 Jul 2010 10:31:52 +0200
Subject: [R-sig-ME] Binary variables used with lme model
In-Reply-To: <AANLkTilsUTvCVBaY-dXWFI4Dc7GyYcpD34KWECk-XCoW@mail.gmail.com>
References: <AANLkTilsUTvCVBaY-dXWFI4Dc7GyYcpD34KWECk-XCoW@mail.gmail.com>
Message-ID: <3DB16098F738284D8DBEB2FC3699163821E24A@inboexch.inbo.be>

Hi Igor,

If your response is binary, you must treat it as binary. Lme only works
with continuous data. Use glmer() from the lme4 package instead.

HTH,

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey
  

> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Igor Blanco
> Verzonden: woensdag 21 juli 2010 18:23
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] Binary variables used with lme model
> 
> Hi there,
> 
> I am trying to analyze some data using the lme package.
> My data contains continuous variables but there is one 
> specific variable called Newmarker that can only take 2 
> values (number 1 or number 2).
> I am interested in using this as a "flag" when I apply a lme 
> model I have used the as.factor trying to remark this fact 
> but an error message appears stating: attempt to set rownames 
> on object with no dimensions.
> 
> Here is the code I have used:
> 
> *Dataset <-   read.table("Data2.txt", header=TRUE, sep="", 
> na.strings="NA",
> dec=".", strip.white=TRUE)
> 
> Dataset$Newmarker <- as.factor(Dataset$Newmarker)
> 
> lme.1 <- lme(Newmarker ~ Age, data=Dataset,  random= ~1|ID)
> 
> summary(lme.1)*
> 
> If I don't use the as.factor I have no problems but the 
> results don't reflect the fact of my "binary" variable Newmarker..
> 
> Can anybody help me please?
> 
> Thanking you in advance,
> 
> Much appreciated,
> 
> Igor Blanco
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

Druk dit bericht a.u.b. niet onnodig af.
Please do not print this message unnecessarily.

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From gangchen6 at gmail.com  Mon Jul 26 21:31:02 2010
From: gangchen6 at gmail.com (Gang Chen)
Date: Mon, 26 Jul 2010 15:31:02 -0400
Subject: [R-sig-ME] Updating fit with lmer()
Message-ID: <AANLkTimiDy9tG_Np0o6C1twvn-b9wq+PxHN1LoPBpfNR@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100726/64e723a1/attachment.pl>

From R.Donders at ebh.umcn.nl  Tue Jul 27 16:00:39 2010
From: R.Donders at ebh.umcn.nl (R.Donders at ebh.umcn.nl)
Date: Tue, 27 Jul 2010 16:00:39 +0200
Subject: [R-sig-ME] problem fitting a mixed model due to between subject
	variation
Message-ID: <42892AAA8DC00D47BF9169507F3D0CB614A990@UMCEXBE04.umcn.nl>

Dear all,

I have a problem with an mixed analysis. All though residual plots and a
fixed analysis suggest that (at least) 
a random intercept should be incorporated in the model, I keep getting a
zero variance (or almost zero variance) for the random intercept, 
I guess because of the huge between subject differences. The data and
some commands for visualizing and analyzing 
the data are given below. These are performed using package nlme, but I
found identical results for packages lme4 and lmm, 
and also for SAS, SPSS and MlWin.
I could use the fixed analysis, but I rather would like not to do that,
since that implies that the number of parameters 
increases with the number of subjects. I could center all predictor
scores around the subject means, but that would 
(almost) be the same so I also would not want to do that. Does anybody
have a suggestion how to proceed?

Best regards
Rogier

_______________________________________________________

Rogier Donders, PhD, Biostatistician
Department of Epidemiology, Biostatistics and HTA, EBH 133
Radboud University Nijmegen Medical Centre
P.O. Box 9101
6500 HB Nijmegen
The Netherlands
_______________________________________________________


strangedat <- 
structure(list(subject = structure(c(1L, 1L, 1L, 2L, 2L, 2L, 
2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 
5L, 5L, 6L, 6L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 7L, 7L, 8L, 8L, 
8L, 8L, 8L, 8L, 9L, 9L, 9L, 10L, 10L, 10L, 10L, 10L, 11L, 11L, 
11L, 11L, 11L, 11L, 12L, 12L, 12L, 12L, 13L, 13L, 13L, 13L, 14L, 
14L, 14L, 14L, 14L, 14L, 15L, 15L, 15L, 15L, 15L, 15L, 16L, 16L, 
16L, 16L, 16L, 16L, 17L, 17L, 17L, 17L, 17L, 17L, 18L, 18L, 18L, 
19L, 19L, 19L, 19L, 19L, 19L, 20L, 20L, 20L, 20L, 20L, 20L, 21L, 
21L, 21L, 21L, 22L, 22L, 22L, 22L, 22L, 22L, 23L, 23L, 23L, 23L, 
23L, 24L, 24L, 24L, 24L, 24L, 24L, 25L, 25L, 25L, 25L, 25L, 25L, 
26L, 26L, 26L, 27L, 27L, 27L, 27L, 27L, 27L, 28L, 28L, 28L, 28L, 
28L, 28L, 29L, 29L, 29L, 29L, 29L, 30L, 30L, 30L, 30L, 30L, 30L, 
31L, 31L, 31L, 31L, 32L, 32L, 32L, 32L, 32L, 32L, 33L, 33L, 33L, 
33L, 33L, 33L, 34L, 34L, 34L, 34L, 34L, 34L, 35L, 35L, 35L, 35L, 
35L, 35L, 36L, 36L, 36L, 36L, 36L, 37L, 37L, 37L, 37L, 37L, 37L, 
38L, 38L, 38L, 38L, 38L, 38L, 39L, 39L, 39L, 39L, 39L, 40L, 40L, 
40L, 40L, 40L, 41L, 41L, 41L, 41L, 41L, 42L, 42L, 42L, 42L, 43L, 
43L, 43L, 43L, 43L, 43L, 44L, 44L, 44L, 44L, 44L, 44L, 45L, 45L, 
45L, 45L, 45L, 45L, 46L, 46L, 46L, 46L, 47L, 47L, 47L, 47L, 47L, 
47L, 48L, 48L, 48L, 48L, 48L, 48L, 49L, 49L, 49L, 50L, 50L, 50L, 
50L, 50L, 51L, 51L, 51L, 51L, 51L, 51L, 52L, 52L, 52L, 52L, 52L, 
52L, 53L, 53L, 53L, 53L, 53L, 53L, 54L, 54L, 54L, 54L, 54L, 54L, 
55L, 55L, 55L, 56L, 56L, 56L, 56L, 56L, 56L, 57L, 57L, 57L, 57L, 
57L, 58L, 58L, 58L, 58L, 58L, 58L, 59L, 59L, 59L, 59L, 60L, 60L, 
60L, 60L, 60L, 60L, 61L, 61L, 61L, 61L, 62L, 62L, 62L, 62L, 62L, 
62L, 63L, 63L, 63L, 63L, 63L, 64L, 64L, 64L, 64L, 64L, 65L, 65L, 
65L, 65L, 65L, 65L, 66L, 66L, 66L, 66L, 66L, 66L, 67L, 67L, 67L, 
67L, 67L, 67L, 68L, 68L, 68L, 68L, 69L, 69L, 69L, 69L, 69L, 69L, 
70L, 70L, 70L, 70L, 70L, 70L, 71L, 71L, 71L, 71L, 71L, 72L, 72L, 
72L, 72L, 72L, 73L, 73L, 73L, 73L, 73L, 73L, 74L, 74L, 74L, 74L, 
74L, 75L, 75L, 75L, 76L, 76L, 76L, 76L, 76L, 76L, 77L, 77L, 77L, 
77L, 77L, 77L, 78L, 78L, 78L, 78L, 78L, 79L, 79L, 79L, 80L, 80L, 
80L), .Label = c("5002", "5004", "5005", "5008", "5009", "5010", 
"5012", "5013", "5014", "5016", "5019", "5022", "5023", "5025", 
"5026", "5027", "5028", "5030", "5031", "5032", "5033", "5034", 
"5035", "5038", "5041", "5042", "5044", "5045", "5046", "5051", 
"5052", "5053", "5056", "5060", "5061", "5062", "5064", "5066", 
"5067", "5069", "5072", "5073", "5075", "5077", "5078", "5079", 
"5080", "5081", "5084", "5087", "5089", "5090", "5092", "5093", 
"5095", "5096", "5097", "5098", "5100", "5102", "5103", "5104", 
"5105", "5107", "5108", "5109", "5110", "5111", "5112", "5114", 
"5117", "5118", "5119", "5120", "5121", "5122", "5123", "5124", 
"5126", "5128"), class = "factor"), outcome = c(1.04380405217311, 
2.08193842187842, 2.94391252482419, 2.10046890887191, 2.11142458753289, 
2.05284085988266, 1.59736533119983, 2.12226153886276, 2.31451366385932, 
3.85418200573830, 3.54961738678043, 3.56189799235315, 3.67630067190708, 
3.40319538432483, 3.46291944029015, 3.17680304844629, 2.99322914333587, 
3.18387021566939, 2.96578839718092, 2.85819285953193, 2.91831112658541, 
1.81482474215905, 2.00955541421567, 2.00955541421567, 2.51365606307399, 
2.59076704048748, 2.10413415427021, 1.95302761682418, 2.40423874672055, 
1.72276659774110, 1.72455071953461, 1.74221902366792, 1.49514876603197, 
1.70837786028900, 2.12226153886276, 1.49514876603197, 4.65965837127216, 
3.98210861299483, 3.62886402170395, 4.39321382406445, 3.52164353473802, 
3.05400118167797, 2.81899509505394, 3.39618483983861, 3.37861088298936, 
3.26575941076705, 3.36970671457078, 3.19335286763712, 3.14544454678232, 
3.2557861788883, 6.43268282492196, 5.34843997595125, 4.18128649235591, 
4.19283150893675, 4.86236727742715, 3.1776370768516, 1.22671229129543, 
2.40423874672055, 1.74221902366792, 1.34807314829969, 6.64395898965631, 
6.65780563324742, 6.42285727722606, 7.00471863698859, 3.71503441159079, 
3.97724879034585, 4.41170678877529, 4.06302587896467, 3.93123722435195, 
3.80176161117061, 4.20886301566469, 4.22566517954946, 4.04847512856365, 
3.86094021519883, 3.95393240850536, 3.95393240850536, 1.41827740697294, 
1.48839958405704, 1.10525683138678, 1.10525683138678, 1.30562645805244, 
1.02961941718116, 4.5913754749659, 4.54063166485052, 4.60936139060656, 
4.51688527112052, 4.34211568336104, 4.24175831411093, 3.08694315360738, 
3.13375357145137, 2.96681826338935, 2.50552593699074, 2.74855214441154, 
2.67000213346468, 2.65112705370259, 2.59823533509500, 3.30468648128131, 
1.31103187661934, 1.08856195281461, 1.20597080698861, 1.32972400963150, 
1.38629436111989, 1.42310833424261, 0.451075619360217,
0.871293365943419, 
0.215111379616945, 0.570979546585738, 5.70501504805875,
5.48910300175412, 
5.60326207855065, 5.23409879422139, 5.85878993020344, 5.47629617390785, 
2.79177841663292, 3.35898553285285, 2.40423874672055, 2.66792241001143, 
2.52492832413749, 3.3579418729912, 3.29212628660779, 2.84024737071360, 
2.94391252482419, 3.04974686186023, 2.65675690671466, 1.86717610851281, 
2.06812778177956, 1.55180879959746, 2.06812778177956, 1.88858365386359, 
1.84371920815877, 2.76443053453832, 3.1302631665116, 3.21124679770371, 
2.39789527279837, 3.3098128198603, 3.95393240850536, 3.84481425573470, 
3.10234200861225, 1.70110510095992, 2.00417905717929, 2.13416644136908, 
2.52011290552262, 2.35991015961332, 2.38508631450579, 2.38508631450579, 
4.9928107091837, 6.24999454709245, 5.49100171037754, 5.33262217024003, 
5.29796730528374, 3.20599319903719, 3.04974686186023, 3.66073714816766, 
2.41054223449914, 3.65169666298622, 3.1540172525197, 4.19283150893675, 
4.1292289640756, 4.52482743330555, 3.02042488614436, 3.0996417369445, 
2.93279247378012, 2.77757626375082, 2.68239045432163, 2.92316158071916, 
2.21920348405499, 1.56861591791385, 0.970778917158225, 1.23256026117785,

0.65232518603969, 1.26129787094521, 1.17557332980424, 2.27109442590267, 
2.1701959049483, 2.45272775142377, 2.65675690671466, 3.47165584531072, 
2.32630161961136, 1.07840958135059, 0.708035793053696, 1.23256026117785,

1.07840958135059, 1.11185751541813, 1.14422279992016, 1.34286480319255, 
1.94448055624572, 0.802001585472027, 0.802001585472027, 2.2321626286975,

0.887891257352457, 0.476234178996372, 0.157003748809665,
0.476234178996372, 
0, 1.43983512804792, 0.887891257352457, 0.802001585472027,
0.598836501088704, 
0.598836501088704, 0.887891257352457, 1.11185751541813,
2.06812778177956, 
2.59972232421658, 2.30657711426358, 2.1770218700187, 2.23964529322017, 
2.13771044980381, 0.598836501088704, 3.04594998971461,
0.476234178996372, 
1.62727783056243, 0.708035793053696, 1.04380405217311,
0.970778917158225, 
1.23256026117785, 1.14422279992016, 0.157003748809665,
0.476234178996372, 
0.598836501088704, 0, 3.73862154600875, 3.55363230470591,
3.3456846717319, 
3.1302631665116, 2.88088243187505, 3.76838355522654, 1.81482474215905, 
1.04380405217311, 1.82937633279936, 0.536493370514568,
0.476234178996372, 
1.71739505393919, 2.21156569460688, 2.03339760317843, 2.27109442590267, 
2.10413415427021, 3.09467222140889, 2.07065303564676, 5.20499520931666, 
4.0095126267054, 3.56359963768718, 4.83055123224249, 0, 0,
0.246860077931526, 
0, 0.157003748809665, 0.708035793053696, 2.70604819843154,
2.71204222237175, 
2.6440448711263, 2.76443053453832, 2.99822915375258, 3.02042488614436, 
1.80828877117927, 1.62924053973028, 2.77508560243837, 0.476234178996372,

0.476234178996372, 1.04380405217311, 1.17557332980424,
0.756121979721334, 
2.7868613815265, 2.91560622907471, 2.79239134953596, 2.7239235502585, 
2.39607543608138, 2.7239235502585, 1.98375629154543, 2.37861977927004, 
2.21156569460688, 2.35327820730956, 2.10413415427021, 2.10413415427021, 
0.598836501088704, 0.157003748809665, 0, 0.157003748809665, 0, 
0.157003748809665, 0.329303747142600, 0.802001585472027,
0.476234178996372, 
0.598836501088704, 0.476234178996372, 0.405465108108164,
4.17392562489244, 
4.18113369229449, 4.12632760807515, 0.708035793053696, 1.07840958135059,

0.887891257352457, 1.56861591791385, 0.802001585472027,
0.157003748809665, 
1.62924053973028, 1.56234630490025, 1.52605630349505, 1.73695123273306, 
1.62924053973028, 3.55019193434004, 4.19750265432473, 4.36995405343961, 
4.22171115814254, 4.32307249183021, 4.00787849107167, 2.71800053195538, 
2.44408465526775, 2.41233595695316, 2.28949985344539, 1.11185751541813, 
1.31640823365572, 1.34286480319255, 0.708035793053696,
0.405465108108164, 
1.81482474215905, 2.70604819843154, 2.98517675961447, 3.80488312987024, 
3.07083974604080, 1.69193913394584, 2.12942147398486, 1.80828877117927, 
2.19499988231411, 1.88555334851442, 2.47148362945586, 4.41012806478476, 
3.10458667846607, 2.25654115449264, 2.52492832413749, 2.08939187253300, 
2.56878813376870, 1.70837786028900, 1.5953389880546, 1.62924053973028, 
2.71336936257981, 3.41969196429832, 3.4626060097908, 1.17865499634165, 
3.70105503004407, 3.90499839049118, 3.65325227647079, 3.24102862950933, 
3.27487801498349, 1.62924053973028, 1.72276659774110, 1.48839958405704, 
1.89911798754855, 1.25561603747777, 1.5953389880546, 1.72276659774110, 
1.17865499634165, 1.32441895740180, 1.00795792039998, 0.157003748809665,

0.329303747142600, 1.26129787094521, 0, 2.33891702224144,
1.69193913394584, 
1.27815220250019, 1.12492959698548, 1.66203036255327, 1.66203036255327, 
2.20386912005489, 1.56234630490025, 0.90825856017689, 1.91102289005487, 
1.88555334851442, 1.44926916028128, 3.17805383034795, 2.89037175789616, 
2.99573227355399, 3.43398720448515, 3.13549421592915, 4.60517018598809, 
4.91998092582813, 4.47733681447821, 4.39444915467244, 4.65396035015752, 
2.56494935746154, 2.19722457733622, 2.56494935746154, 2.30258509299405, 
2.39789527279837, 1.6094379124341, 2.89037175789616, 2.77258872223978, 
2.77258872223978, 2.63905732961526, 2.83321334405622, 1.94591014905531, 
3.73766961828337, 1.94591014905531, 4.02535169073515, 3.78418963391826, 
2.07944154167984, 3.87120101090789, 4.04305126783455, 3.76120011569356, 
2.07944154167984, 1.94591014905531, 3.52636052461616, 3.87120101090789, 
3.46573590279973, 3.17805383034795, 1.6094379124341, 1.6094379124341, 
1.38629436111989, 1.38629436111989, 0, 4.82398437914107,
4.00642368084963, 
4.9608145991123, 1.17865499634165, 1.98237982883670, 1.36863942588117
), pred = c(1.28923264827676, 1.04380405217311, 2.08193842187842, 
2.287471455184, 2.10046890887191, 2.11142458753289, 2.05284085988266, 
1.59736533119983, 2.12226153886276, 3.96100362764977, 3.85418200573830, 
3.54961738678043, 3.56189799235315, 3.67630067190708, 3.40319538432483, 
3.16547504814109, 3.17680304844629, 2.99322914333587, 3.18387021566939, 
2.96578839718092, 2.85819285953193, 1.71739505393919, 1.81482474215905, 
2.00955541421567, 2.80940269536250, 2.51365606307399, 2.59076704048748, 
2.10413415427021, 1.95302761682418, 2.40423874672055, 1.83736998048011, 
1.72455071953461, 1.74221902366792, 1.49514876603197, 1.70837786028900, 
2.12226153886276, 4.05421677113132, 4.65965837127216, 3.98210861299483, 
3.62886402170395, 4.39321382406445, 3.52164353473802, 2.88088243187505, 
2.81899509505394, 3.39618483983861, 3.38167471517329, 3.26575941076705, 
3.36970671457078, 3.19335286763712, 3.14544454678232, 4.62045280951925, 
6.43268282492196, 5.34843997595125, 4.18128649235591, 4.19283150893675, 
4.86236727742715, 1.31103187661934, 1.22671229129543, 2.40423874672055, 
1.74221902366792, 6.17213891469703, 6.64395898965631, 6.65780563324742, 
6.42285727722606, 5.26806432337702, 3.71503441159079, 3.97724879034585, 
4.41170678877529, 4.06302587896467, 3.93123722435195, 4.35014889577586, 
4.20886301566469, 4.22566517954946, 4.04847512856365, 3.86094021519883, 
3.95393240850536, 1.17865499634165, 1.41827740697294, 1.48839958405704, 
1.10525683138678, 1.10525683138678, 1.30562645805244, 4.51502663613513, 
4.5913754749659, 4.54063166485052, 4.60936139060656, 4.51688527112052, 
4.34211568336104, 2.83497649467460, 3.08694315360738, 3.13375357145137, 
2.82137888640921, 2.50552593699074, 2.74855214441154, 2.67000213346468, 
2.65112705370259, 2.59823533509500, 2.0906287310704, 1.31103187661934, 
1.08856195281461, 1.20597080698861, 1.32972400963150, 1.38629436111989, 
0.871293365943419, 0.451075619360217, 0.871293365943419,
0.215111379616945, 
6.44489408173266, 5.70501504805875, 5.48910300175412, 5.60326207855065, 
5.23409879422139, 5.85878993020344, 2.85070650150373, 2.79177841663292, 
3.35898553285285, 2.40423874672055, 2.66792241001143, 3.14931136148229, 
3.3579418729912, 3.29212628660779, 2.84024737071360, 2.94391252482419, 
3.04974686186023, 2.07819075977818, 1.86717610851281, 2.06812778177956, 
1.55180879959746, 2.06812778177956, 1.88858365386359, 3.86157146193205, 
2.76443053453832, 3.1302631665116, 5.06474461974329, 2.39789527279837, 
3.3098128198603, 3.95393240850536, 3.84481425573470, 3.10234200861225, 
2.02814824729229, 2.00417905717929, 2.13416644136908, 2.52011290552262, 
2.35991015961332, 2.38508631450579, 5.57135523413609, 4.9928107091837, 
6.24999454709245, 5.49100171037754, 5.33262217024003, 2.90853906185161, 
3.20599319903719, 3.04974686186023, 3.66073714816766, 2.41054223449914, 
3.65169666298622, 5.04838056033851, 4.19283150893675, 4.1292289640756, 
4.52482743330555, 2.67000213346468, 3.0996417369445, 2.93279247378012, 
2.77757626375082, 2.68239045432163, 2.92316158071916, 1.56861591791385, 
1.56861591791385, 0.970778917158225, 1.23256026117785, 0.65232518603969,

1.26129787094521, 1.99605993274078, 2.27109442590267, 2.1701959049483, 
2.45272775142377, 2.65675690671466, 3.47165584531072, 1.39128190263093, 
1.07840958135059, 0.708035793053696, 1.23256026117785, 1.07840958135059,

1.11185751541813, 0, 1.34286480319255, 1.94448055624572,
0.802001585472027, 
0.802001585472027, 1.39128190263093, 0.887891257352457,
0.476234178996372, 
0.157003748809665, 0.476234178996372, 0, 1.07840958135059,
0.887891257352457, 
0.802001585472027, 0.598836501088704, 0.598836501088704,
0.887891257352457, 
2.70203212877665, 2.06812778177956, 2.59972232421658, 2.30657711426358, 
2.1770218700187, 0.932164081030445, 2.13771044980381, 0.598836501088704,

3.04594998971461, 0.476234178996372, 0.887891257352457,
0.708035793053696, 
1.04380405217311, 0.970778917158225, 1.23256026117785, 0.65232518603969,

0.157003748809665, 0.476234178996372, 0.598836501088704,
4.11577984294217, 
3.73862154600875, 3.55363230470591, 3.3456846717319, 3.1302631665116, 
2.88088243187505, 1.04380405217311, 1.81482474215905, 1.04380405217311, 
1.82937633279936, 0.536493370514568, 0.476234178996372,
2.25129179860650, 
2.21156569460688, 2.03339760317843, 2.27109442590267, 2.10413415427021, 
3.09467222140889, 6.0498277904049, 5.20499520931666, 4.0095126267054, 
3.56359963768718, 0.476234178996372, 0, 0, 0.246860077931526, 
0, 0.157003748809665, 2.46044317760963, 2.70604819843154,
2.71204222237175, 
2.6440448711263, 2.76443053453832, 2.99822915375258, 2.53131302260216, 
1.80828877117927, 1.62924053973028, 0, 0.476234178996372,
0.476234178996372, 
1.04380405217311, 1.17557332980424, 3.08694315360738, 2.7868613815265, 
2.91560622907471, 2.79239134953596, 2.7239235502585, 2.39607543608138, 
1.97129938306013, 1.98375629154543, 2.37861977927004, 2.21156569460688, 
2.35327820730956, 2.10413415427021, 1.56861591791385, 0.598836501088704,

0.157003748809665, 0, 0.157003748809665, 0, 1.52822785700856, 
0.329303747142600, 0.802001585472027, 0.476234178996372,
0.598836501088704, 
0.476234178996372, 4.25632167829882, 4.17392562489244, 4.18113369229449,

0.598836501088704, 0.708035793053696, 1.07840958135059,
0.887891257352457, 
1.56861591791385, 0.802001585472027, 1.52605630349505, 1.62924053973028,

1.56234630490025, 1.52605630349505, 1.73695123273306, 3.70868208141012, 
3.55019193434004, 4.19750265432473, 4.36995405343961, 4.22171115814254, 
4.32307249183021, 2.68784749378469, 2.71800053195538, 2.44408465526775, 
2.41233595695316, 1.98375629154543, 1.11185751541813, 1.31640823365572, 
1.34286480319255, 0.708035793053696, 0.405465108108164,
2.67552700939665, 
2.70604819843154, 2.98517675961447, 3.80488312987024, 2.04769284336526, 
1.69193913394584, 2.12942147398486, 1.80828877117927, 2.19499988231411, 
1.88555334851442, 2.73436750941958, 4.41012806478476, 3.10458667846607, 
2.25654115449264, 2.52492832413749, 2.55022611590864, 2.56878813376870, 
1.70837786028900, 1.5953389880546, 1.62924053973028, 3.35550242240003, 
3.41969196429832, 3.4626060097908, 1.17865499634165, 3.70105503004407, 
3.90499839049118, 2.10900034392138, 3.24102862950933, 3.27487801498349, 
1.62924053973028, 1.72276659774110, 1.48839958405704, 1.72276659774110, 
1.25561603747777, 1.5953389880546, 1.72276659774110, 1.17865499634165, 
1.32441895740180, 0.0487901641694320, 0.157003748809665,
0.329303747142600, 
1.26129787094521, 2.29857707159651, 2.33891702224144, 1.69193913394584, 
1.27815220250019, 1.12492959698548, 1.66203036255327, 1.78002421300963, 
2.20386912005489, 1.56234630490025, 0.90825856017689, 1.91102289005487, 
1.88555334851442, 3.49650756146648, 3.17805383034795, 2.89037175789616, 
2.99573227355399, 3.43398720448515, 4.07753744390572, 4.60517018598809, 
4.91998092582813, 4.47733681447821, 4.39444915467244, 2.07944154167984, 
2.56494935746154, 2.19722457733622, 2.56494935746154, 2.30258509299405, 
2.39789527279837, 2.94443897916644, 2.89037175789616, 2.77258872223978, 
2.77258872223978, 2.63905732961526, 2.07944154167984, 1.94591014905531, 
3.73766961828337, 3.66356164612965, 4.02535169073515, 3.78418963391826, 
2.07944154167984, 3.87120101090789, 4.04305126783455, 1.94591014905531, 
2.07944154167984, 1.94591014905531, 3.52636052461616, 3.87120101090789, 
3.46573590279973, 1.79175946922805, 1.6094379124341, 1.6094379124341, 
1.38629436111989, 1.38629436111989, 4.24305188238329, 4.82398437914107, 
4.00642368084963, 1.30019166206648, 1.17865499634165, 1.98237982883670
)), .Names = c("subject", "outcome", "pred"), row.names = c(2L, 
3L, 4L, 9L, 10L, 11L, 12L, 13L, 14L, 16L, 17L, 18L, 19L, 20L, 
21L, 23L, 24L, 25L, 26L, 27L, 28L, 33L, 34L, 35L, 37L, 38L, 39L, 
40L, 41L, 42L, 44L, 45L, 46L, 47L, 48L, 49L, 51L, 52L, 53L, 54L, 
55L, 56L, 58L, 59L, 60L, 66L, 67L, 68L, 69L, 70L, 72L, 73L, 74L, 
75L, 76L, 77L, 81L, 82L, 83L, 84L, 88L, 89L, 90L, 91L, 93L, 94L, 
95L, 96L, 97L, 98L, 100L, 101L, 102L, 103L, 104L, 105L, 107L, 
108L, 109L, 110L, 111L, 112L, 114L, 115L, 116L, 117L, 118L, 119L, 
121L, 122L, 123L, 128L, 129L, 130L, 131L, 132L, 133L, 135L, 136L, 
137L, 138L, 139L, 140L, 142L, 143L, 144L, 145L, 149L, 150L, 151L, 
152L, 153L, 154L, 156L, 157L, 158L, 159L, 160L, 163L, 164L, 165L, 
166L, 167L, 168L, 170L, 171L, 172L, 173L, 174L, 175L, 177L, 178L, 
179L, 184L, 185L, 186L, 187L, 188L, 189L, 191L, 192L, 193L, 194L, 
195L, 196L, 198L, 199L, 200L, 201L, 202L, 205L, 206L, 207L, 208L, 
209L, 210L, 212L, 213L, 214L, 215L, 219L, 220L, 221L, 222L, 223L, 
224L, 226L, 227L, 228L, 229L, 230L, 231L, 233L, 234L, 235L, 236L, 
237L, 238L, 240L, 241L, 242L, 243L, 244L, 245L, 247L, 248L, 249L, 
250L, 251L, 254L, 255L, 256L, 257L, 258L, 259L, 261L, 262L, 263L, 
264L, 265L, 266L, 268L, 269L, 270L, 271L, 272L, 275L, 276L, 277L, 
278L, 279L, 282L, 283L, 284L, 285L, 286L, 291L, 292L, 293L, 294L, 
296L, 297L, 298L, 299L, 300L, 301L, 303L, 304L, 305L, 306L, 307L, 
308L, 310L, 311L, 312L, 313L, 314L, 315L, 319L, 320L, 321L, 322L, 
324L, 325L, 326L, 327L, 328L, 329L, 331L, 332L, 333L, 334L, 335L, 
336L, 338L, 339L, 340L, 345L, 346L, 347L, 348L, 349L, 352L, 353L, 
354L, 355L, 356L, 357L, 359L, 360L, 361L, 362L, 363L, 364L, 366L, 
367L, 368L, 369L, 370L, 371L, 373L, 374L, 375L, 376L, 377L, 378L, 
382L, 383L, 384L, 387L, 388L, 389L, 390L, 391L, 392L, 394L, 395L, 
396L, 397L, 398L, 401L, 402L, 403L, 404L, 405L, 406L, 410L, 411L, 
412L, 413L, 415L, 416L, 417L, 418L, 419L, 420L, 422L, 423L, 424L, 
425L, 429L, 430L, 431L, 432L, 433L, 434L, 436L, 437L, 438L, 439L, 
440L, 444L, 445L, 446L, 447L, 448L, 450L, 451L, 452L, 453L, 454L, 
455L, 457L, 458L, 459L, 460L, 461L, 462L, 464L, 465L, 466L, 467L, 
468L, 469L, 471L, 472L, 473L, 474L, 478L, 479L, 480L, 481L, 482L, 
483L, 485L, 486L, 487L, 488L, 489L, 490L, 492L, 493L, 494L, 495L, 
496L, 499L, 500L, 501L, 502L, 503L, 506L, 507L, 508L, 509L, 510L, 
511L, 514L, 515L, 516L, 517L, 518L, 522L, 523L, 524L, 527L, 528L, 
529L, 530L, 531L, 532L, 534L, 535L, 536L, 537L, 538L, 539L, 541L, 
542L, 543L, 544L, 545L, 548L, 549L, 550L, 555L, 556L, 557L), class =
"data.frame")

require(nlme)
require(lattice)

xyplot(outcome ~ pred, data = strangedat, type = c('p','r'))

# Note a clear positive relation over subjects

xyplot(outcome ~ pred|subject, data = strangedat, type = c('p','r'))

# Note that within subjects there does not appear to be a relation

# fixed effect models confirm this
fixedmod1 <- lm(outcome ~ pred, data = strangedat)
summary(fixedmod1)

fixedmod2 <- lm(outcome ~ pred + subject, data = strangedat)
summary(fixedmod2)
# Note that the effect for pred has now disappeared 


anova(fixedmod1, fixedmod2)
# and the model with the individual intercepts fits better

randommod <- lme(outcome ~ pred, data = strangedat, random = ~
1|subject)
summary(randommod)
# but almost no variation for the random intercept

plot(randommod,resid(.) ~ pred|subject, type = c('p','r'))
# however it is clear that the residuals do NOT behave correctly


Het UMC St Radboud staat geregistreerd bij de Kamer van Koophandel in het handelsregister onder nummer 41055629.
The Radboud University Nijmegen Medical Centre is listed in the Commercial Register of the Chamber of Commerce under file number 41055629.



From c.ryan.king at gmail.com  Tue Jul 27 19:43:17 2010
From: c.ryan.king at gmail.com (Ryan King)
Date: Tue, 27 Jul 2010 12:43:17 -0500
Subject: [R-sig-ME] compiling CHOLMOD c code
Message-ID: <AANLkTim2TvC3TL8CdXr47ShRycyMt4SukXP3HCoaFV6J@mail.gmail.com>

Hello list,
Like most mixed model implementations, my little project tries to use
CHOLMOD for the underlying calculation.  I haven't had to use raw c
libraries before.  Unfortunately, I need/want access to some CHOLMOD
functions not used by Matrix or lme4.   My procedure was to make all
the UF sparse suite packages into archives
make in each of the following:
UFconfig/
CHOLMOD/Lib/
AMD/Lib/
CAMD/Lib/
CCOLAMD/Lib/
CHOLMOD/Lib/
COLAMD/Lib/
metis-4.0/Lib/

then move the archives to my working directory and link the results all together
R CMD SHLIB  *.a mylikec.c ../sparsesuite/metis-4.0/Lib/*.o -o
bigsmush.so -llapack -lblas

However, the result won't load

> dyn.load("bigsmush.so")
Error in dyn.load("bigsmush.so") :
  unable to load shared library 'bigsmush.so':
  bigsmush.so: undefined symbol: camd_malloc


Grep says that camd_malloc is declared
CAMD/Include/camd.h:329:EXTERN void *(*camd_malloc) (size_t) ;		    /*
pointer to malloc */

and defined in both
CAMD/Source/camd_global.c:51:void *(*camd_malloc) (size_t) = malloc ;
CHOLMOD/Partition/cholmod_camd.c:185:    camd_malloc = Common->malloc_memory ;


as long as I don't compile with the -DNMALLOC option, which I don't
think that I did.  Any help as to what I need to to?

Thanks,
Ryan King
Dept Health Studies,
University of Chicago



From etiennelaliberte at gmail.com  Wed Jul 28 00:31:36 2010
From: etiennelaliberte at gmail.com (Etienne =?ISO-8859-1?Q?Lalibert=E9?=)
Date: Wed, 28 Jul 2010 10:31:36 +1200
Subject: [R-sig-ME] lme for split-plot
Message-ID: <1280269896.14651.295.camel@globetrotter>

I'm analyzing experimental data from a split-plot design, with two
blocks, each block containing five whole plots, and each whole plot
containing three subplots.

The multilevel structure of the design dictates the following random
structure (in the case of a random intercept model):

lme(...., random = ~ 1 | block / wholeplot, ...)

However, if, for a given model, the random effects end up being
incredibly small, e.g.

Random effects:
 Formula: ~1 | block
         (Intercept)
StdDev: 4.639022e-06

 Formula: ~1 | wholeplot %in% block
         (Intercept)  Residual
StdDev: 2.256742e-09 0.1911715

Is it still better to leave them in the model, or should I exclude them
and use gls() instead?

Many thanks,

Etienne



From A.Robinson at ms.unimelb.edu.au  Wed Jul 28 00:40:49 2010
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Wed, 28 Jul 2010 08:40:49 +1000
Subject: [R-sig-ME] lme for split-plot
In-Reply-To: <1280269896.14651.295.camel@globetrotter>
References: <1280269896.14651.295.camel@globetrotter>
Message-ID: <369CD765-4E33-4F91-ACF8-A44586BDA893@ms.unimelb.edu.au>

I think that you should leave them in the model. They reflect the experimental design, and their inclusion will help your fixed effects estimates and inference do the same!

I hope that this helps,

Andrew

---

Andrew Robinson. 
Program Manager, ACERA
Senior Lecturer, Applied Statistics
The University of Melbourne. 

On 28/07/2010, at 8:31 AM, Etienne Lalibert? <etiennelaliberte at gmail.com> wrote:

> I'm analyzing experimental data from a split-plot design, with two
> blocks, each block containing five whole plots, and each whole plot
> containing three subplots.
> 
> The multilevel structure of the design dictates the following random
> structure (in the case of a random intercept model):
> 
> lme(...., random = ~ 1 | block / wholeplot, ...)
> 
> However, if, for a given model, the random effects end up being
> incredibly small, e.g.
> 
> Random effects:
> Formula: ~1 | block
>         (Intercept)
> StdDev: 4.639022e-06
> 
> Formula: ~1 | wholeplot %in% block
>         (Intercept)  Residual
> StdDev: 2.256742e-09 0.1911715
> 
> Is it still better to leave them in the model, or should I exclude them
> and use gls() instead?
> 
> Many thanks,
> 
> Etienne
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From davidD at qimr.edu.au  Wed Jul 28 01:04:26 2010
From: davidD at qimr.edu.au (David Duffy)
Date: Wed, 28 Jul 2010 09:04:26 +1000 (EST)
Subject: [R-sig-ME] problem fitting a mixed model due to between
	subjectvariation
In-Reply-To: <42892AAA8DC00D47BF9169507F3D0CB614A990@UMCEXBE04.umcn.nl>
References: <42892AAA8DC00D47BF9169507F3D0CB614A990@UMCEXBE04.umcn.nl>
Message-ID: <Pine.LNX.4.64.1007280835410.32000@orpheus.qimr.edu.au>

On Tue, 27 Jul 2010, R.Donders at ebh.umcn.nl wrote:

> Dear all,
>
> I have a problem with an mixed analysis. All though residual plots and a
> fixed analysis suggest that (at least)
> a random intercept should be incorporated in the model, I keep getting a
> zero variance (or almost zero variance) for the random intercept,
> I guess because of the huge between subject differences.
>
> summary(m2)

The random slopes model looks like:

> summary(m2)
Linear mixed model fit by REML
Formula: outcome ~ pred + (pred | subject)
    Data: strangedat
    AIC   BIC logLik deviance REMLdev
  781.4 805.6 -384.7      759   769.4
Random effects:
  Groups   Name        Variance Std.Dev. Corr
  subject  (Intercept) 0.095927 0.30972
           pred        0.015808 0.12573  -1.000
  Residual             0.340696 0.58369
Number of obs: 417, groups: subject, 80

Fixed effects:
             Estimate Std. Error t value
(Intercept)  0.31775    0.07503   4.235
pred         0.85699    0.02806  30.537

Correlation of Fixed Effects:
      (Intr)
pred -0.901

The random intercepts model gave:
  AIC   BIC logLik deviance REMLdev
  783 799.2 -387.5      764     775

It looks to me that the largest clusters tend to run horizontally wrt 
pred, that is across the strong between-clusters line of identity.

with(strangedat, plot(outcome ~ pred, col=as.integer(subject)))
z1 <- by(strangedat, strangedat$subject, mean)
z2 <- matrix(unlist(z1),nc=3,byrow=T)
z3 <- as.data.frame(z2[,-1])
names(z3) <- c("outcome","pred")
points(outcome ~ pred, data=z3, pch=15)

t1 <-  table(strangedat$subject)
sss <- split(strangedat, strangedat$subject)
library(locfit)
for(s in rownames(t1)[t1==6]) lines(locfit(outcome ~ pred, alpha=3, 
data=sss[[s]]))

This wasn't your homework, was it? ;)

Cheers, David Duffy.
-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From Christoph.Scherber at agr.uni-goettingen.de  Wed Jul 28 01:43:00 2010
From: Christoph.Scherber at agr.uni-goettingen.de (Christoph Scherber)
Date: Wed, 28 Jul 2010 01:43:00 +0200
Subject: [R-sig-ME] Fitting crossed random effects in lme (not lmer)
Message-ID: <ae2bcb7b994593979edf4f82412049d7.squirrel@mailbox.gwdg.de>

Dear all,

Let?s assume I have an lme model with the following random effects structure:

random=~1|block/plot

Now, further treatments are applied at the next smallest level, but they
are on the same hierarchy. In lmer notation, this could be parameterized
as

...+(1|block/plot/treatment.type1)+(1|block/plot/treatment.type2)

How could I specify the same structure in lme?

I know that I would need to use one of the pdClasses(), but I don?t
understand how to set this up correctly. I tried of course the Pinheiro &
Bates book, but maybe someone can give me a hint. That would be excellent!

All the best and many thanks for any help,
Christoph



From R.Donders at ebh.umcn.nl  Wed Jul 28 10:24:45 2010
From: R.Donders at ebh.umcn.nl (R.Donders at ebh.umcn.nl)
Date: Wed, 28 Jul 2010 10:24:45 +0200
Subject: [R-sig-ME] problem fitting a mixed model due to between
	subjectvariation
In-Reply-To: <Pine.LNX.4.64.1007280835410.32000@orpheus.qimr.edu.au>
References: <42892AAA8DC00D47BF9169507F3D0CB614A990@UMCEXBE04.umcn.nl>
	<Pine.LNX.4.64.1007280835410.32000@orpheus.qimr.edu.au>
Message-ID: <42892AAA8DC00D47BF9169507F3D0CB614A995@UMCEXBE04.umcn.nl>

Dear David,


Thanks for the reply. I wish it were homework... These are not my own
data and the people who provided me with the data gave me a choice:
either I could use their data but then it should be impossible to trace
back to any content matter, or I should generate data and then I could
explain where the data came from. I chose the first option...

I also looked at the random slopes model, but since it gave a
correlation of -1 I first tried to solve the simpler case.

Indeed from a graphical inspection (not as nice as yours) I also
concluded that there really should not be any effect of pred for
individual subjects. I thought that conclusion was even valid for
clusters of all sizes. But for the people who provided me with the data,
this is only a starting model; they want to look at the effect of
additional covariates, so a conclusion like 'there is no effect of pred'
is not enough.

Restricting the analysis to the large clusters only, things do not seem
to become simpler. Following your example:
# t1 <-  table(strangedat$subject)
strangedatlargeclust <- strangedat[strangedat$subject %in%
rownames(t1)[t1 == 6],]
strangedatlargeclust$subject <- factor(strangedatlargeclust$subject) #
dropping unused levels (still don't know how to do that in one step)

# using nlme as in my previous post:

lmemodlargeclust <- lme(outcome ~ pred, data = strangedatlargeclust,
random = ~pred|subject)
summary(lmemodlargeclust)

# or using lme4
# in that case use:
# detach('package:nlme')
# require(lme4)

lmemodlargeclust <- lmer(outcome ~ pred + (pred|subject), data =
strangedatlargeclust)
summary(lmemodlargeclust)

For lme4 I obtain:

Linear mixed model fit by REML 
Formula: outcome ~ pred + (pred | subject) 
   Data: strangedatlargeclust 
   AIC   BIC logLik deviance REMLdev
 486.4 508.2 -237.2      464   474.4
Random effects:
 Groups   Name        Variance Std.Dev. Corr  
 subject  (Intercept) 0.0000   0.00000        
          pred        0.0000   0.00000    NaN 
 Residual             0.3168   0.56285        
Number of obs: 276, groups: subject, 46

Fixed effects:
            Estimate Std. Error t value
(Intercept)  0.21668    0.07068    3.07
pred         0.88911    0.02550   34.87


(For nlme things appear to be not that gross, but I guess that is only
appearance:
Linear mixed-effects model fit by REML
 Data: strangedatlargeclust 
       AIC      BIC    logLik
  486.4296 508.1084 -237.2148

Random effects:
 Formula: ~pred | subject
 Structure: General positive-definite, Log-Cholesky parametrization
            StdDev       Corr  
(Intercept) 1.423596e-05 (Intr)
pred        4.608392e-07 0     
Residual    5.628509e-01       

Fixed effects: outcome ~ pred 
                Value  Std.Error  DF  t-value p-value
(Intercept) 0.2166817 0.07067610 229  3.06584  0.0024
pred        0.8891061 0.02549993 229 34.86700  0.0000
 Correlation: 
     (Intr)
pred -0.878

Standardized Within-Group Residuals:
        Min          Q1         Med          Q3         Max 
-4.12521685 -0.48108890  0.01259325  0.46206772  4.32871991 

Number of Observations: 276
Number of Groups: 46)

Since I would hope that using a mixed model would provide me with a
conditional model (in contrast to a marginal model), I would really want
a regression weight of pred that is near 0...

Best regards,
Rogier


-----Oorspronkelijk bericht-----
Van: David Duffy [mailto:davidD at qimr.edu.au] 
Verzonden: woensdag 28 juli 2010 1:04
Aan: Donders, Rogier
CC: r-sig-mixed-models at r-project.org
Onderwerp: Re: [R-sig-ME] problem fitting a mixed model due to between
subjectvariation

On Tue, 27 Jul 2010, R.Donders at ebh.umcn.nl wrote:

> Dear all,
>
> I have a problem with an mixed analysis. All though residual plots and
a
> fixed analysis suggest that (at least)
> a random intercept should be incorporated in the model, I keep getting
a
> zero variance (or almost zero variance) for the random intercept,
> I guess because of the huge between subject differences.
>
> summary(m2)

The random slopes model looks like:

> summary(m2)
Linear mixed model fit by REML
Formula: outcome ~ pred + (pred | subject)
    Data: strangedat
    AIC   BIC logLik deviance REMLdev
  781.4 805.6 -384.7      759   769.4
Random effects:
  Groups   Name        Variance Std.Dev. Corr
  subject  (Intercept) 0.095927 0.30972
           pred        0.015808 0.12573  -1.000
  Residual             0.340696 0.58369
Number of obs: 417, groups: subject, 80

Fixed effects:
             Estimate Std. Error t value
(Intercept)  0.31775    0.07503   4.235
pred         0.85699    0.02806  30.537

Correlation of Fixed Effects:
      (Intr)
pred -0.901

The random intercepts model gave:
  AIC   BIC logLik deviance REMLdev
  783 799.2 -387.5      764     775

It looks to me that the largest clusters tend to run horizontally wrt 
pred, that is across the strong between-clusters line of identity.

with(strangedat, plot(outcome ~ pred, col=as.integer(subject)))
z1 <- by(strangedat, strangedat$subject, mean)
z2 <- matrix(unlist(z1),nc=3,byrow=T)
z3 <- as.data.frame(z2[,-1])
names(z3) <- c("outcome","pred")
points(outcome ~ pred, data=z3, pch=15)

t1 <-  table(strangedat$subject)
sss <- split(strangedat, strangedat$subject)
library(locfit)
for(s in rownames(t1)[t1==6]) lines(locfit(outcome ~ pred, alpha=3, 
data=sss[[s]]))

This wasn't your homework, was it? ;)

Cheers, David Duffy.
-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



Het UMC St Radboud staat geregistreerd bij de Kamer van Koophandel in het handelsregister onder nummer 41055629.
The Radboud University Nijmegen Medical Centre is listed in the Commercial Register of the Chamber of Commerce under file number 41055629.



From betinig at uoguelph.ca  Wed Jul 28 17:50:26 2010
From: betinig at uoguelph.ca (Gustavo Betini)
Date: Wed, 28 Jul 2010 11:50:26 -0400
Subject: [R-sig-ME] Error in UseMethod("ranef")
Message-ID: <4C5051C2.7050102@uoguelph.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100728/17df3ce5/attachment.pl>

From Tanja.Srebotnjak at ecologic-institute.us  Mon Jul 26 21:15:16 2010
From: Tanja.Srebotnjak at ecologic-institute.us (Tanja Srebotnjak)
Date: Mon, 26 Jul 2010 12:15:16 -0700
Subject: [R-sig-ME] variance-covariance structure of random effects in glmer
Message-ID: <AANLkTin_LxDtJws+-tkkhC_tAzD4UYoTSca=u78cvwWg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100726/859d7e4d/attachment.pl>

From tylerdeanrudolph at gmail.com  Tue Jul 27 00:49:22 2010
From: tylerdeanrudolph at gmail.com (Tyler Dean Rudolph)
Date: Mon, 26 Jul 2010 18:49:22 -0400
Subject: [R-sig-ME] ramps::corStruct formats: compatible in nlme?
Message-ID: <AANLkTinFFfHsQAbi3F_jmjmH4LCZU+RZdU1GE1TWqRoD@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100726/8125a112/attachment.pl>

From drewdogy at uw.edu  Wed Jul 28 14:34:03 2010
From: drewdogy at uw.edu (Andrew Kosydar)
Date: Wed, 28 Jul 2010 08:34:03 -0400
Subject: [R-sig-ME] p-values with lmer
In-Reply-To: <6fb6c2ea25c10d3189855b76ece0cb71.squirrel@mailbox.gwdg.de>
References: <777458.38736.qm@web27506.mail.ukl.yahoo.com>
	<6fb6c2ea25c10d3189855b76ece0cb71.squirrel@mailbox.gwdg.de>
Message-ID: <AANLkTinB7oYkC5guwAYS4s0CqngmRT45vu7-OWx6PECa@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100728/6c3d53c7/attachment.pl>

From lborger at uoguelph.ca  Wed Jul 28 21:00:00 2010
From: lborger at uoguelph.ca (Luca Borger)
Date: Wed, 28 Jul 2010 15:00:00 -0400
Subject: [R-sig-ME] Error in UseMethod("ranef")
References: <4C5051C2.7050102@uoguelph.ca>
Message-ID: <4A01E93768BC420D95EF28FA80AAA8C5@lborger>

Hello,

are you using updated versions for lme4, Matrix, R? It works on my machine 
(Windows, see below):

(gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
+               family = binomial, data = cbpp))

> ranef(gm1)
$herd
   (Intercept)
1   0.59002543
2  -0.29889417
3   0.40626540
4   0.03928257
5  -0.19001102
6  -0.40026000
7   0.88940374
8   0.59937372
9  -0.23764977
10 -0.54092635
11 -0.08462816
12 -0.06481190
13 -0.68991231
14  0.97071999
15 -0.53046901

>


> fm3 <- lmer(diameter ~ (1|plate) + (1|sample), Penicillin)
> ranef(fm3)
$plate
  (Intercept)
a  0.80454705
b  0.80454705
c  0.18167191
d  0.33739070
e  0.02595313
f -0.44120322
g -1.37551593
h  0.80454705
i -0.75264079
j -0.75264079
k  0.96026583
l  0.49310948
m  1.42742219
n  0.49310948
o  0.96026583
p  0.02595313
q -0.28548444
r -0.28548444
s -1.37551593
t  0.96026583
u -0.90835957
v -0.28548444
w -0.59692201
x -1.21979714

$sample
  (Intercept)
A  2.18724529
B -1.01056270
C  1.93806545
D -0.09690327
E -0.01384332
F -3.00400144

>


> sessionInfo()
R version 2.11.1 (2010-05-31)
i386-pc-mingw32

locale:
[1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United 
Kingdom.1252    LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C
[5] LC_TIME=English_United Kingdom.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_0.999375-34   Matrix_0.999375-42 lattice_0.18-8

loaded via a namespace (and not attached):
[1] grid_2.11.1   nlme_3.1-96   stats4_2.11.1 tools_2.11.1
>


HTH

Cheers,

Luca


----- Original Message ----- 
From: "Gustavo Betini" <betinig at uoguelph.ca>
To: <r-sig-mixed-models at r-project.org>
Sent: Wednesday, July 28, 2010 11:50 AM
Subject: [R-sig-ME] Error in UseMethod("ranef")


> Hi, all,
>
> yesterday I ran a GLMM with the glmer function from the lme4 package,
> and extracted the modes of the random effects using ranef(model). This
> morning I tried to do the same and got the following error:
>
> Error in UseMethod("ranef") :
>   no applicable method for 'ranef' applied to an object of class "mer"
>
> I tried the example from the R documentation,
>
> fm3 <- lmer(diameter ~ (1|plate) + (1|sample), Penicillin)
> ranef(fm1)
>
> and got the same error. It seems that I am missing something. Any clue?
>
> Thanks,
>
> Gustavo S. Betini
>
>
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From betinig at uoguelph.ca  Wed Jul 28 21:33:20 2010
From: betinig at uoguelph.ca (Gustavo Betini)
Date: Wed, 28 Jul 2010 15:33:20 -0400
Subject: [R-sig-ME] Error in UseMethod("ranef")
In-Reply-To: <4A01E93768BC420D95EF28FA80AAA8C5@lborger>
References: <4C5051C2.7050102@uoguelph.ca>
	<4A01E93768BC420D95EF28FA80AAA8C5@lborger>
Message-ID: <4C508600.5050609@uoguelph.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100728/7ac8a3d4/attachment.pl>

From raptorbio at hotmail.com  Wed Jul 28 23:04:55 2010
From: raptorbio at hotmail.com (Adam Smith)
Date: Wed, 28 Jul 2010 17:04:55 -0400
Subject: [R-sig-ME] Difficulty with GLMM specification in lme4
Message-ID: <BAY127-W12F59BE6BA9126D63419D2A1A80@phx.gbl>


Hello list,

I think I've exhausted my (limited) knowledge of GLMMs in attempting to analyze a for a subset of my research.? I've been immersed in the R-help archives and recent publications for the past two weeks, and I've finally decided to solicit help from this distinguished list.? This is my first post, and I've read the appropriate posting materials, but I hope you'll forgive should I stray from those recommendations at any point.

First, some background...

The objective: Examine the fixed effect of treatment (binary) and geography (binary) on the consumption of fruits by avian frugivores over 14 count periods.? Specifically, I'd like to generate odds of consumption for each count period, and determine whether the odds vary between treatments or geographic locations (either as a consistent main effect or via an interaction with count period).? I'm most concerned with marginal effects (which I know GLMM is not giving me), but GEE model selection strike me as even less fun...and the results from similar GEE and GLMM models on similar datasets have given me comparable qualitative results.

The design:? 17 plots, each comprising two subplots.? Treatment levels (e.g., control or treatment) were assigned randomly to the subplots within a plot.? 

The response:? On each subplot, I monitored the fate (consumed or not) of fruits during 14 count periods.? The number of fruits initially present and monitored on a given subplot varied (min = 71, max = 461, total = 7572). 

At present, I am modeling consumption (yes or no) as a function of each count period (this very general time specification is likely to be appropriate), the treatment effect, and the geographic location of the plots (north vs. south).? In the dataset "fruit", each individual fruit (id) has up to 14 records, depending on when or if it was consumed.? For the 7572 individuals, this results in 59779 records:? 

> str(fruit)
'data.frame':?? 59779 obs. of? 6 variables:
?$ id??????? : Factor w/ 7572 levels "1","2","3","4",..: 1 2 3 4 5 6 7 8 9 10 ...
?$ plot?? ?? : Factor w/ 17 levels "N-10","N-2","N-3",..: 1 1 1 1 1 1 1 1 1 1 ...
?$ trt?????? : Factor w/ 2 levels "0","1": 1 1 1 1 1 1 1 1 1 1 ...
?$ geog????? : Factor w/ 2 levels "0","1": 2 2 2 2 2 2 2 2 2 2 ...
?$ count???? : Factor w/ 14 levels "1","2","3","4",..: 1 1 1 1 1 1 1 1 1 1 ...
?$ cons????? : int? 1 1 0 0 0 0 0 0 0 0 ...
?$ available : int? 260 260 260 260 260 260 260 260 260 260 ...

Is this dataset format unnecessary?? Can I not simply sum events in each count period in each subplot, such that my response variable takes the form of cbind(cons, available - cons), or does this violate the binomial assumption that events are independent?

The answer to these questions would seem to dictate the appropriate specification of the random effects.? If I leave the dataset as is, I'm not sure what specification of the random effects is most appropriate. Are there not three random effects that need to be modeled?? I recall that when Judith Singer and John Willett (Applied Longitudinal Data Analysis, 2003) set up data like this, they ignore the apparent repeated measure on individuals...

The most relevant glmer model that I have tried using the original data format is: 

m_orig <- glmer(cons ~ count + geog + trt + count:geog + count:trt? + (1 | plot) + (1 | plot/trt) + (1 | id), data=fruit, family=binomial)

As I said, this model, and those dropping the (1 | id) term, churn for hours; I've yet to see it converge (or do anything).

The alternative dataset actually converges quickly.? For example, after creating a new dataset that sums consumption events (num_cons) within each count time period (not shown):

m_alt <- glmer(cbind(num_cons, available-num_cons) ~ count + geog + trt + count:geog + count:trt? + (1 | plot) + (1 | plot/trt), data=fruit_alt, family=binomial)

Which specification is more appropriate?? Am I way off base with this?? Since I'm interested in marginal effects, perhaps my objectives would be better addressed with the GEE approach?

Any assistance is greatly appreciated.

Best,

Adam Smith
Ph.D. Candidate, Avian Ecology
Dept. Natural Resources Science
University of Rhode Island
 		 	   		  
_________________________________________________________________
The New Busy is not the too busy. Combine all your e-mail accounts with Hotmail.

ID28326::T:WLMTAGL:ON:WL:en-US:WM_HMP:042010_4


From cvonende at niu.edu  Thu Jul 29 01:00:32 2010
From: cvonende at niu.edu (Carl Von Ende)
Date: Wed, 28 Jul 2010 18:00:32 -0500
Subject: [R-sig-ME] Difficulty with GLMM specification in lme4 (Adam Smith)
In-Reply-To: <mailman.5198.1280354851.4244.r-sig-mixed-models@r-project.org>
References: <mailman.5198.1280354851.4244.r-sig-mixed-models@r-project.org>
Message-ID: <4C5070410200005F000BC82D@wpo.cso.niu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100728/1e412bc3/attachment.pl>

From davidD at qimr.edu.au  Thu Jul 29 01:47:02 2010
From: davidD at qimr.edu.au (David Duffy)
Date: Thu, 29 Jul 2010 09:47:02 +1000 (EST)
Subject: [R-sig-ME] problem fitting a mixed model due to between
	subjectvariation
In-Reply-To: <42892AAA8DC00D47BF9169507F3D0CB614A995@UMCEXBE04.umcn.nl>
References: <42892AAA8DC00D47BF9169507F3D0CB614A990@UMCEXBE04.umcn.nl>
	<Pine.LNX.4.64.1007280835410.32000@orpheus.qimr.edu.au>
	<42892AAA8DC00D47BF9169507F3D0CB614A995@UMCEXBE04.umcn.nl>
Message-ID: <Pine.LNX.4.64.1007281843550.21837@orpheus.qimr.edu.au>

On Wed, 28 Jul 2010, R.Donders at ebh.umcn.nl wrote:

> ... These are not my own
> data and the people who provided me with the data gave me a choice:
> either I could use their data but then it should be impossible to trace
> back to any content matter [...]

Hmph.  So, should one expect autoregressive or order effects within each 
subject across values of pred?

>
> Indeed from a graphical inspection (not as nice as yours) I also
> concluded that there really should not be any effect of pred for
> individual subjects. I thought that conclusion was even valid for
> clusters of all sizes.

Yes.  I did this so there would be enough within-cluster data to 
look at nonlinear effects.  Specifically whether the curviness of loess 
fits was systematic.  I was thinking of the textbook examples of a 
completely deterministic relationship with zero linear correlation.

> dropping unused levels (still don't know how to do that in one step)

[drop=T]

Just 2c, David.


| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From raptorbio at hotmail.com  Thu Jul 29 04:24:57 2010
From: raptorbio at hotmail.com (Adam Smith)
Date: Thu, 29 Jul 2010 02:24:57 +0000 (UTC)
Subject: [R-sig-ME] Difficulty with GLMM specification in lme4 (Adam
	Smith)
References: <mailman.5198.1280354851.4244.r-sig-mixed-models@r-project.org>
	<4C5070410200005F000BC82D@wpo.cso.niu.edu>
Message-ID: <loom.20100729T034307-462@post.gmane.org>

Carl Von Ende <cvonende at ...> writes:

> 
> Hi Adam,
> 
> I have several questions/clarifications and some comments about your
> design: 

I am happy to clarify.

>(1) Isn't geography confounded with treatment? 

Geography is a characteristic at the plot level.  There are 9 northern plots
and 8 southern plots.  Within each plot, both levels of the treatment effect
occur.  I suppose if you stopped there, it would resemble a randomized complete
block or a split-plot design, with plot as the blocking factor. 

>(2) Subplot is
> your experimental unit for each treatment level.  Are there different
> kinds of fruits available in a subplot for each count period, or are
> they all the same kind? If the former, were all kinds always available?
> Your statement that there are 14 records for each individual fruit seems
> to suggest you are referring to repeated observations on the same fruit
> type/kind?   If only one fruit type, the number of fruits eaten or
> remaining in each subplot for each count period is your basic response
> variable; but there would actually be a cross-classified response,if
> there was more than one fruit type in each subplot (i.e. eat/not eat X
> fruit type).  

I monitored only a single type of fruit.  And, yes, the same fruits were
monitored during each of the 14 count periods to determine whether consumption
had occurred.  My concern with using the number of fruits eaten in a given count
period (relative to the number available) as the response variable is that the
consumption events may not be independent.  For example, a single bird may
consume several (or many) fruits in succession.  For what it's worth, when I
model the full (individual level) dataset using a GEE with an exchangeable
correlation structure within subplots, the working correlation is very small  
(< 0.03), perhaps suggesting that the binomial assumption of independent events
is not grossly violated.  I'm not sure if I'm interpreting this exactly
correctly though...

(3) since the same plots & subplots were monitored
> repeatedly, it certainly seems to be a repeated measures design.  In the
> Big R book, Crawley collapses time for a binary response repeated
> measures design, but it seems to be that he is assuming independence of
> repeated observations by doing that (p. 604).  

I noticed the Crawley example, but that involves a recurring event response
(i.e., a patient can test positive multiple times).  For the fruit, it's once
bitten, gone... (obviously), so I'm not sure the example is directly comparable.
And I'm not sure he's assuming independence, but rather taking a repeated
response and converting it into a single, integrated response such that each
subject contributes only a single, weighted, observation to the model.  

> 
> Carl von Ende



From Thierry.ONKELINX at inbo.be  Thu Jul 29 16:55:39 2010
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 29 Jul 2010 16:55:39 +0200
Subject: [R-sig-ME] [R] Residuals of mixed effects model
In-Reply-To: <20100729140727.317130@gmx.net>
References: <20100729140727.317130@gmx.net>
Message-ID: <3DB16098F738284D8DBEB2FC3699163821E6F7@inboexch.inbo.be>

Dear Will,

residuals() should take both the fixed and random effects into account.
Can you give us a reproducible example if you get something different?

Use residuals(model, type = "normalized") if you also want to account
for the correlation structure.

What do you want to do with the residuals? Model them? In that case I
would suggest that you model the response variable directly. Note that
the parameter estimates of the random effects and the correlation
structure can (will) change if you add variables to the model.

Best regards,

Thierry

PS Use the mixed models list for this kind of questions about mixed
models.

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey
  

> -----Oorspronkelijk bericht-----
> Van: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] Namens will.eagle at gmx.net
> Verzonden: donderdag 29 juli 2010 16:07
> Aan: r-help at r-project.org
> Onderwerp: [R] Residuals of mixed effects model
> 
> Dear all,
> 
> how do I get the residuals from a lme() output objects which 
> are adjusted for fixed AND (!) random effects?
> 
> I tried residuals(), but it seems they just give me the 
> residuals adjusted for the fixed effects of the regression model.
> 
> The model I use is:
> lme.out <- lme(data=MyDataInLongFormat,fixed= outcome~1, 
> random= ~ 1|individual, correlation=corSymm(form = ~time|individual))
> 
> Actually, I use only the intercept in the fixed part of the 
> predictor, and I want to get residuals which are adjusted for 
> the fixed part (intercept) and the random effect, ie to get 
> rid of the correlatedness of individual measures across time. 
> This way I want to get data where I can treat the measures 
> per time point as independent groups. Makes sense?
> 
> Thanks in advance,
> 
> Will
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

Druk dit bericht a.u.b. niet onnodig af.
Please do not print this message unnecessarily.

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From cvonende at niu.edu  Thu Jul 29 22:41:58 2010
From: cvonende at niu.edu (Carl Von Ende)
Date: Thu, 29 Jul 2010 15:41:58 -0500
Subject: [R-sig-ME] Difficulty with GLMM specification in lme4 - [Adam Smith]
In-Reply-To: <mailman.5228.1280370617.4244.r-sig-mixed-models@r-project.org>
References: <mailman.5228.1280370617.4244.r-sig-mixed-models@r-project.org>
Message-ID: <4C51A1460200005F000BCA26@wpo.cso.niu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100729/f5edaf95/attachment.pl>

From praguewatermelon at gmail.com  Fri Jul 30 01:49:27 2010
From: praguewatermelon at gmail.com (Xiao He)
Date: Thu, 29 Jul 2010 16:49:27 -0700
Subject: [R-sig-ME] Is it possible to compare an experimental group to a
	control group in lmer() ?
Message-ID: <AANLkTim-1jo2RmOAHPjhrksdPR28NnkSNpw4XiuLsvg7@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100729/eae71ec0/attachment.pl>

From praguewatermelon at gmail.com  Fri Jul 30 02:57:35 2010
From: praguewatermelon at gmail.com (Xiao He)
Date: Thu, 29 Jul 2010 17:57:35 -0700
Subject: [R-sig-ME] What to do when a subset of binomial data has only
	positive outcomes
Message-ID: <AANLkTi=zskcerd9fuELVQZ833mYPRkCddYpRUdVvQq7-@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100729/4f537c7a/attachment.pl>

From rebecca.ross at plants.ox.ac.uk  Fri Jul 30 12:03:41 2010
From: rebecca.ross at plants.ox.ac.uk (Rebecca Ross)
Date: Fri, 30 Jul 2010 11:03:41 +0100
Subject: [R-sig-ME] Incomplete repeated measures
Message-ID: <756B64E07365AF43BE945A734A85E4454461694562@EXMBX03.ad.oak.ox.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100730/9ee8db18/attachment.pl>

From Chris.Brien at unisa.edu.au  Fri Jul 30 07:32:58 2010
From: Chris.Brien at unisa.edu.au (Chris Brien)
Date: Fri, 30 Jul 2010 15:02:58 +0930
Subject: [R-sig-ME] Negative estimates of variance component
Message-ID: <EC96E350A5D6444B82CBD8DA338F017528BF1757@ITUPC-EX1MBOX.UniNet.unisa.edu.au>

Dear mixed modellers,

I have a data set that gives me an estimate of 0 for one of the variance components. I wanted to allow for the estimate of the component to be negative. My search of the documentation led me to believe that this is not possible. Am I right, or did I miss something?

Cheers, 

Chris Brien
-----
University of South Australia
ADELAIDE? 5001? South Australia
WEB page:? <http://people.unisa.edu.au/Chris.Brien> 



From bates at stat.wisc.edu  Fri Jul 30 15:50:33 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 30 Jul 2010 09:50:33 -0400
Subject: [R-sig-ME] Negative estimates of variance component
In-Reply-To: <EC96E350A5D6444B82CBD8DA338F017528BF1757@ITUPC-EX1MBOX.UniNet.unisa.edu.au>
References: <EC96E350A5D6444B82CBD8DA338F017528BF1757@ITUPC-EX1MBOX.UniNet.unisa.edu.au>
Message-ID: <AANLkTikp7M60EBmfAmXbvX5rMduJES-Nb-kna3fvwU-W@mail.gmail.com>

On 7/30/10, Chris Brien <Chris.Brien at unisa.edu.au> wrote:
> Dear mixed modellers,
>
> I have a data set that gives me an estimate of 0 for one of the variance
> components. I wanted to allow for the estimate of the component to be
> negative. My search of the documentation led me to believe that this is not
> possible. Am I right, or did I miss something?

You are correct.  The lme4 and nlme packages do not allow for negative
estimates of variance.



From bbolker at gmail.com  Fri Jul 30 15:54:06 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 30 Jul 2010 09:54:06 -0400
Subject: [R-sig-ME] Negative estimates of variance component
In-Reply-To: <EC96E350A5D6444B82CBD8DA338F017528BF1757@ITUPC-EX1MBOX.UniNet.unisa.edu.au>
References: <EC96E350A5D6444B82CBD8DA338F017528BF1757@ITUPC-EX1MBOX.UniNet.unisa.edu.au>
Message-ID: <AANLkTinCu2TznFnm2jHqBRe7hqYYV1bagdY+sybirngO@mail.gmail.com>

  Pardon my asking, but why? For consistency with older (arguably less
correct) method-of-moments estimates that could give negative
estimates?

On Fri, Jul 30, 2010 at 1:32 AM, Chris Brien <Chris.Brien at unisa.edu.au> wrote:
> Dear mixed modellers,
>
> I have a data set that gives me an estimate of 0 for one of the variance components. I wanted to allow for the estimate of the component to be negative. My search of the documentation led me to believe that this is not possible. Am I right, or did I miss something?
>
> Cheers,
>
> Chris Brien
> -----
> University of South Australia
> ADELAIDE? 5001? South Australia
> WEB page:? <http://people.unisa.edu.au/Chris.Brien>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Fri Jul 30 15:59:23 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 30 Jul 2010 09:59:23 -0400
Subject: [R-sig-ME] Negative estimates of variance component
In-Reply-To: <AANLkTinCu2TznFnm2jHqBRe7hqYYV1bagdY+sybirngO@mail.gmail.com>
References: <EC96E350A5D6444B82CBD8DA338F017528BF1757@ITUPC-EX1MBOX.UniNet.unisa.edu.au>
	<AANLkTinCu2TznFnm2jHqBRe7hqYYV1bagdY+sybirngO@mail.gmail.com>
Message-ID: <AANLkTikDhDumHtzkJW79uo+6CR-qpfmbPmAdguwiDZ=d@mail.gmail.com>

When I first read your question I thought you were asking why lme4 and
nlme don't allow negative variance estimates and I was going to trot
out that old mathematical impossibility argument.  Then I realized
that you were asking why one would want a negative estimate of the
variance.

On 7/30/10, Ben Bolker <bbolker at gmail.com> wrote:
>   Pardon my asking, but why? For consistency with older (arguably less
> correct) method-of-moments estimates that could give negative
> estimates?
>
> On Fri, Jul 30, 2010 at 1:32 AM, Chris Brien <Chris.Brien at unisa.edu.au>
> wrote:
>> Dear mixed modellers,
>>
>> I have a data set that gives me an estimate of 0 for one of the variance
>> components. I wanted to allow for the estimate of the component to be
>> negative. My search of the documentation led me to believe that this is
>> not possible. Am I right, or did I miss something?
>>
>> Cheers,
>>
>> Chris Brien
>> -----
>> University of South Australia
>> ADELAIDE? 5001? South Australia
>> WEB page:? <http://people.unisa.edu.au/Chris.Brien>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From cm744 at st-andrews.ac.uk  Fri Jul 30 16:09:33 2010
From: cm744 at st-andrews.ac.uk (Chris Mcowen)
Date: Fri, 30 Jul 2010 15:09:33 +0100
Subject: [R-sig-ME] ROC Curve GLMM
Message-ID: <7737AFEE-115B-4101-8CD2-04D02E862CCA@st-andrews.ac.uk>

Dear List,

I am wanting to test how good my model derived from my training data is at predicting my test data. To do this i have been advised to calculate the receiver operating characteristic (ROC) curve.

I cant find a function to do this with a glmm - is there one? 

And second, would you recommend this approach, or is there a better, alternative?

Thanks

Chris


From Timothy_Handley at nps.gov  Fri Jul 30 16:28:28 2010
From: Timothy_Handley at nps.gov (Timothy_Handley at nps.gov)
Date: Fri, 30 Jul 2010 07:28:28 -0700
Subject: [R-sig-ME] What to do when a subset of binomial data has only
	positive outcomes
Message-ID: <OFAACC9BC8.01B76E7F-ON88257770.004D99D8-88257770.004F82C1@nps.gov>


I had this problem with glm. My solution was to create a likelihood
function, and use the optim or optimize function to find an appropriate
confidence interval. More specifically, I found the likelihood of the data
for the best-estimate parameters, then found the range of parameters for
which a likelihood-ratio-test (best-estimate params vs. current params) had
a p-value>.025. The range is then the 95% confidence interval for those
parameters. This is essentially replicating the functionality of glm by
hand, as it seemed unable to deal with data which is all positive or all
negative.

While I understand how to do this with glm, I don't understand enough about
fixed effects models to do the same for lmer. If you were willing to treat
everything as a fixed effect and switch to glm, then you could e-mail me,
and I could offer some more specific advice on how to do this.

If anyone else has a better solution, I'd be very interested to hear it.

Tim Handley
Fire Effects Monitor
Santa Monica Mountains National Recreation Area
401 W. Hillcrest Dr.
Thousand Oaks, CA 91360
805-370-2300 x2412

Date: Thu, 29 Jul 2010 17:57:35 -0700
From: Xiao He <praguewatermelon at gmail.com>
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] What to do when a subset of binomial data has only
             positive outcomes
Message-ID:
             <AANLkTi=zskcerd9fuELVQZ833mYPRkCddYpRUdVvQq7- at mail.gmail.com>
Content-Type: text/plain

Dear R users and experts,

I tried to fit a model as shown below:

data.lmer<-lmer(word1~compoundType*nativelanguage + (1|subject) + (1|word),
data=data, family="binomial").

the factor 'compoundType' has three levels: blue, green, red.
the factor nativelanguage has two levels: english, other

I obtained the following results:
************************************************
Fixed effects:
                              Estimate Std. Error z value Pr(>|z|)
(Intercept)                    -1.0190     0.5777  -1.764   0.0778 .
nativelanguageother            -0.6862     0.4075  -1.684   0.0922 .
typegreen                      19.7882   728.0627   0.027   0.9783
typered                         3.6985     0.8359   4.425 9.65e-06 ***
nativelanguageother:typegreen -16.1915   728.0624  -0.022   0.9823
nativelanguageother:typered    -2.8106     0.5639  -4.984 6.23e-07 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
************************************************

As you can see, the standard errors and estimates for "typegreen" as well
as
"nativelanguageother:typegreen" are enormous. I examined my data and
realized that the responses obtained for the level "green" of compoundType
were all positive. But the responses of "green" were clearly significantly
different from the base level "blue" as green was 100% positive responses,
whereas blue had only 30% of positive responses.

I wonder if there is any way to conduct statistical analyses to show that
green is significantly different from blue (and potentially red) because
obviously I can't just say they are different :)...

Thank you in advance for your help!



Best,

Xiao He
Graduate student
Department of Linguistics
University of Southern California

From aleman at fordham.edu  Fri Jul 30 18:52:45 2010
From: aleman at fordham.edu (JOSE A ALEMAN)
Date: 30-Jul-2010 12:52:45 EDT
Subject: [R-sig-ME] question about random coefficients model (RCM)
In-Reply-To: <AANLkTikk--k4g1GkY0E-hiNaZnPs_aC8qLW9Tcq0dUPm@mail.gmail.com>
Message-ID: <OF740B4713.340C0D06-ON85257770.0058ED9A@fordham.edu>

The model I'm using is of the form:

RCM <- lmer (data.gini_net ~ data.neocorporatism_std +
data.firm_level_coop_std + data.cog + data.gov_employ_std +
      data.netden_std + data.trade_openness_std +
data.capital_liberalization_std + data.lagged_unemploy_std +
      data.deindustrialization_std + data.pop_over_65_percent_std +
(data.nation|data.neocorporatism_std), data=new.data)

but when I try to use the extractor coef(), I get the following error
message:

> coef(RCM)
Error in coef(RCM) : unable to align random and fixed effects



                                                                           
             Douglas Bates                                                 
             <bates at stat.wisc.                                             
             edu>                                                       To 
             Sent by:                  JOSE A ALEMAN <aleman at fordham.edu>  
             dmbates at gmail.com                                          cc 
                                       r-sig-mixed-models at r-project.org    
                                                                   Subject 
             07/17/2010 11:30          Re: [R-sig-ME] question about       
             AM                        random coefficients model (RCM)     
                                                                           
                                                                           
                                                                           
                                                                           
                                                                           
                                                                           




On Sat, Jul 17, 2010 at 9:52 AM, JOSE A ALEMAN <aleman at fordham.edu> wrote:
>
> Dear list users,
>
> I have a question about how to estimate the RCM described by Western
(1998)
> in his article "Causal Heterogeneity in Comparative Research: A Bayesian
> Hierarchical Modeling Approach". While I know how to estimate this model
in
> R via restricted maximum likelihood, I am at a loss as to how to
interpret
> the results. The random coefficients are supposed to be different for
each
> country, yet R provides ?a standard regression-like output with a single
> coefficient for the variable with the random slope. How would I go about
> extracting the country specific information?

Can you be more specific about how you fit the model?  Just saying "in
R" is too general.

If you fit the model with lmer from the lme4 package then you may want
to look at the output from the ranef() and coef() extractors.



From bbolker at gmail.com  Fri Jul 30 20:01:52 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 30 Jul 2010 14:01:52 -0400
Subject: [R-sig-ME] Negative estimates of variance component
In-Reply-To: <4C53002E.7090404@unil.ch>
References: <EC96E350A5D6444B82CBD8DA338F017528BF1757@ITUPC-EX1MBOX.UniNet.unisa.edu.au>
	<AANLkTinCu2TznFnm2jHqBRe7hqYYV1bagdY+sybirngO@mail.gmail.com>
	<4C53002E.7090404@unil.ch>
Message-ID: <AANLkTik+DfZSCB1RR4z0e6ca9Z=V=f9Rg5QQ67VZevOB@mail.gmail.com>

  I claim that this is in the category of "consistency with older
method-of-moments estimates" ... I know that population geneticists
still like to think in terms of variance components, but wouldn't one
ideally want to deal with the negative correlation built into the
system by estimating it more or less directly (i.e. via a structured
variance-covariance model that has nonnegative variances but could
have negative covariances) rather than by estimating a negative
variance component?

  Ben Bolker (not a population geneticist so possibly missing the point)

On Fri, Jul 30, 2010 at 12:39 PM, Jerome Goudet <jerome.goudet at unil.ch> wrote:
> Hi all,
>
> Here is an example: genes are nested in individuals, themselves nested in
> populations.? If individuals avoid mating with relatives, then the variance
> component of allele frequencies among individuals within population is
> expected to take negative values, as 2 genes taken from 2 different
> individuals are more similar than two genes taken from the same individual.
> See Weir & Cockerham (1984) Evolution for instance.
>
>
>
>
> Ben Bolker wrote:
>
>   Pardon my asking, but why? For consistency with older (arguably less
> correct) method-of-moments estimates that could give negative
> estimates?
>
> On Fri, Jul 30, 2010 at 1:32 AM, Chris Brien <Chris.Brien at unisa.edu.au>
> wrote:
>
>
> Dear mixed modellers,
>
> I have a data set that gives me an estimate of 0 for one of the variance
> components. I wanted to allow for the estimate of the component to be
> negative. My search of the documentation led me to believe that this is not
> possible. Am I right, or did I miss something?
>
> Cheers,
>
> Chris Brien
> -----
> University of South Australia
> ADELAIDE? 5001? South Australia
> WEB page:? <http://people.unisa.edu.au/Chris.Brien>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
> --
> J?r?me Goudet
> Dept. Ecology & Evolution
> UNIL-Sorge, CH-1015 Lausanne
>
> mail:jerome.goudet at unil.ch
> Tel:+41 (0)21 692 4242
> Fax:+41 (0)21 692 4265



From andydolman at gmail.com  Fri Jul 30 21:45:45 2010
From: andydolman at gmail.com (Andrew Dolman)
Date: Fri, 30 Jul 2010 21:45:45 +0200
Subject: [R-sig-ME] question about random coefficients model (RCM)
In-Reply-To: <OF740B4713.340C0D06-ON85257770.0058ED9A@fordham.edu>
References: <AANLkTikk--k4g1GkY0E-hiNaZnPs_aC8qLW9Tcq0dUPm@mail.gmail.com>
	<OF740B4713.340C0D06-ON85257770.0058ED9A@fordham.edu>
Message-ID: <AANLkTim5wdsQVChL5z4CwZknGBFUn8tu==jyZhrEKpJN@mail.gmail.com>

Hi Jose

data.nation is not present in the the fixed effects specification of
your model, so coef() won't work, but ranef() should. Your model
assumes that there is no overall relationship between data.gini_net
and data.nation and yet allows for a relationship within the
sub-groups defined by data.neocorporatism_std, with a slope that
varies randomly between groups but is zero overall. That's probably
not what you want.

I also notice that data.neocorporatism seems to have been standardised
somehow, which would be odd for a categorical variable used to group
things.



andydolman at gmail.com



On 30 July 2010 18:52, JOSE A ALEMAN <aleman at fordham.edu> wrote:
> The model I'm using is of the form:
>
> RCM <- lmer (data.gini_net ~ data.neocorporatism_std +
> data.firm_level_coop_std + data.cog + data.gov_employ_std +
> ? ? ?data.netden_std + data.trade_openness_std +
> data.capital_liberalization_std + data.lagged_unemploy_std +
> ? ? ?data.deindustrialization_std + data.pop_over_65_percent_std +
> (data.nation|data.neocorporatism_std), data=new.data)
>
> but when I try to use the extractor coef(), I get the following error
> message:
>
>> coef(RCM)
> Error in coef(RCM) : unable to align random and fixed effects
>
>
>
>
> ? ? ? ? ? ? Douglas Bates
> ? ? ? ? ? ? <bates at stat.wisc.
> ? ? ? ? ? ? edu> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? To
> ? ? ? ? ? ? Sent by: ? ? ? ? ? ? ? ? ?JOSE A ALEMAN <aleman at fordham.edu>
> ? ? ? ? ? ? dmbates at gmail.com ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?cc
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? r-sig-mixed-models at r-project.org
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Subject
> ? ? ? ? ? ? 07/17/2010 11:30 ? ? ? ? ?Re: [R-sig-ME] question about
> ? ? ? ? ? ? AM ? ? ? ? ? ? ? ? ? ? ? ?random coefficients model (RCM)
>
>
>
>
>
>
>
>
>
>
> On Sat, Jul 17, 2010 at 9:52 AM, JOSE A ALEMAN <aleman at fordham.edu> wrote:
>>
>> Dear list users,
>>
>> I have a question about how to estimate the RCM described by Western
> (1998)
>> in his article "Causal Heterogeneity in Comparative Research: A Bayesian
>> Hierarchical Modeling Approach". While I know how to estimate this model
> in
>> R via restricted maximum likelihood, I am at a loss as to how to
> interpret
>> the results. The random coefficients are supposed to be different for
> each
>> country, yet R provides ?a standard regression-like output with a single
>> coefficient for the variable with the random slope. How would I go about
>> extracting the country specific information?
>
> Can you be more specific about how you fit the model? ?Just saying "in
> R" is too general.
>
> If you fit the model with lmer from the lme4 package then you may want
> to look at the output from the ranef() and coef() extractors.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bbolker at gmail.com  Fri Jul 30 22:26:49 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 30 Jul 2010 16:26:49 -0400
Subject: [R-sig-ME] What to do when a subset of binomial data has only
	positive outcomes
In-Reply-To: <OFAACC9BC8.01B76E7F-ON88257770.004D99D8-88257770.004F82C1@nps.gov>
References: <OFAACC9BC8.01B76E7F-ON88257770.004D99D8-88257770.004F82C1@nps.gov>
Message-ID: <AANLkTimpQ33tDNQZqpP_pS7b2RvmSHB-VCA=K2BwUtzr@mail.gmail.com>

  The bleeding-edge version of lme4, lme4a, has some profiling
capabilities that might (?) be useful. A Bayesian approach (which you
would probably have to roll yourself; glmmBUGS exists but did not seem
flexible enough to deal with crossed random effects the last time I
looked) would also be useful for stabilizing this kind of estimation
problem (i.e., assigning a prior would allow the posterior probability
density to be not quite completely concentrated at prob=0 or prob=1
...)  For inspiration you might also try looking in the GLM literature
under the keyword 'complete separation'.

On Fri, Jul 30, 2010 at 10:28 AM,  <Timothy_Handley at nps.gov> wrote:
>
> I had this problem with glm. My solution was to create a likelihood
> function, and use the optim or optimize function to find an appropriate
> confidence interval. More specifically, I found the likelihood of the data
> for the best-estimate parameters, then found the range of parameters for
> which a likelihood-ratio-test (best-estimate params vs. current params) had
> a p-value>.025. The range is then the 95% confidence interval for those
> parameters. This is essentially replicating the functionality of glm by
> hand, as it seemed unable to deal with data which is all positive or all
> negative.
>
> While I understand how to do this with glm, I don't understand enough about
> fixed effects models to do the same for lmer. If you were willing to treat
> everything as a fixed effect and switch to glm, then you could e-mail me,
> and I could offer some more specific advice on how to do this.
>
> If anyone else has a better solution, I'd be very interested to hear it.
>
> Tim Handley
> Fire Effects Monitor
> Santa Monica Mountains National Recreation Area
> 401 W. Hillcrest Dr.
> Thousand Oaks, CA 91360
> 805-370-2300 x2412
>
> Date: Thu, 29 Jul 2010 17:57:35 -0700
> From: Xiao He <praguewatermelon at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] What to do when a subset of binomial data has only
> ? ? ? ? ? ? positive outcomes
> Message-ID:
> ? ? ? ? ? ? <AANLkTi=zskcerd9fuELVQZ833mYPRkCddYpRUdVvQq7- at mail.gmail.com>
> Content-Type: text/plain
>
> Dear R users and experts,
>
> I tried to fit a model as shown below:
>
> data.lmer<-lmer(word1~compoundType*nativelanguage + (1|subject) + (1|word),
> data=data, family="binomial").
>
> the factor 'compoundType' has three levels: blue, green, red.
> the factor nativelanguage has two levels: english, other
>
> I obtained the following results:
> ************************************************
> Fixed effects:
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
> (Intercept) ? ? ? ? ? ? ? ? ? ?-1.0190 ? ? 0.5777 ?-1.764 ? 0.0778 .
> nativelanguageother ? ? ? ? ? ?-0.6862 ? ? 0.4075 ?-1.684 ? 0.0922 .
> typegreen ? ? ? ? ? ? ? ? ? ? ?19.7882 ? 728.0627 ? 0.027 ? 0.9783
> typered ? ? ? ? ? ? ? ? ? ? ? ? 3.6985 ? ? 0.8359 ? 4.425 9.65e-06 ***
> nativelanguageother:typegreen -16.1915 ? 728.0624 ?-0.022 ? 0.9823
> nativelanguageother:typered ? ?-2.8106 ? ? 0.5639 ?-4.984 6.23e-07 ***
> ---
> Signif. codes: ?0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> ************************************************
>
> As you can see, the standard errors and estimates for "typegreen" as well
> as
> "nativelanguageother:typegreen" are enormous. I examined my data and
> realized that the responses obtained for the level "green" of compoundType
> were all positive. But the responses of "green" were clearly significantly
> different from the base level "blue" as green was 100% positive responses,
> whereas blue had only 30% of positive responses.
>
> I wonder if there is any way to conduct statistical analyses to show that
> green is significantly different from blue (and potentially red) because
> obviously I can't just say they are different :)...
>
> Thank you in advance for your help!
>
>
>
> Best,
>
> Xiao He
> Graduate student
> Department of Linguistics
> University of Southern California
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From aleman at fordham.edu  Fri Jul 30 22:48:33 2010
From: aleman at fordham.edu (JOSE A ALEMAN)
Date: 30-Jul-2010 16:48:33 EDT
Subject: [R-sig-ME] question about random coefficients model (RCM)
In-Reply-To: <AANLkTim5wdsQVChL5z4CwZknGBFUn8tu==jyZhrEKpJN@mail.gmail.com>
Message-ID: <OF4E9738AC.B8F4A4AE-ON85257770.00710104@fordham.edu>

Hi Andy,

You're right, ranef() does actually work. Actually, data.neocorporatism is
pretty much a time-invariant institutional variable. What I want is to
estimate a random intercepts random slopes model where the effects of other
time varying variables enter the model through the institutional variable
"data.neocorporatism". The effects for neocorporatism, in other words,
should be different depending on the country, that is, there shouldn't be a
single coefficient for this variable but 18 different coefficients for the
18 different countries. If that's the case, then "data.neocorporatism"
should not be in the fixed effects equation.

I indeed tried the model having removed this variable, but the result after
typing coef() was the same. Actually, ranef() gave me what I believe are
the random intercepts for each country, but I still need to figure out a
way to get the coefficients.

I'm probably doing something wrong, but I am basically trying to fit a
model similar to Western's (1998) described in my original message below.

Thank you,

Jose


                                                                           
             Andrew Dolman                                                 
             <andydolman at gmail                                             
             .com>                                                      To 
                                       JOSE A ALEMAN <aleman at fordham.edu>  
             07/30/2010 03:45                                           cc 
             PM                        Douglas Bates                       
                                       <bates at stat.wisc.edu>,              
                                       dmbates at gmail.com,                  
                                       r-sig-mixed-models at r-project.org    
                                                                   Subject 
                                       Re: [R-sig-ME] question about       
                                       random coefficients model (RCM)     
                                                                           
                                                                           
                                                                           
                                                                           
                                                                           
                                                                           




Hi Jose

data.nation is not present in the the fixed effects specification of
your model, so coef() won't work, but ranef() should. Your model
assumes that there is no overall relationship between data.gini_net
and data.nation and yet allows for a relationship within the
sub-groups defined by data.neocorporatism_std, with a slope that
varies randomly between groups but is zero overall. That's probably
not what you want.

I also notice that data.neocorporatism seems to have been standardised
somehow, which would be odd for a categorical variable used to group
things.



andydolman at gmail.com



On 30 July 2010 18:52, JOSE A ALEMAN <aleman at fordham.edu> wrote:
> The model I'm using is of the form:
>
> RCM <- lmer (data.gini_net ~ data.neocorporatism_std +
> data.firm_level_coop_std + data.cog + data.gov_employ_std +
> ? ? ?data.netden_std + data.trade_openness_std +
> data.capital_liberalization_std + data.lagged_unemploy_std +
> ? ? ?data.deindustrialization_std + data.pop_over_65_percent_std +
> (data.nation|data.neocorporatism_std), data=new.data)
>
> but when I try to use the extractor coef(), I get the following error
> message:
>
>> coef(RCM)
> Error in coef(RCM) : unable to align random and fixed effects
>
>
>
>
> ? ? ? ? ? ? Douglas Bates
> ? ? ? ? ? ? <bates at stat.wisc.
> ? ? ? ? ? ? edu> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? To
> ? ? ? ? ? ? Sent by: ? ? ? ? ? ? ? ? ?JOSE A ALEMAN <aleman at fordham.edu>
> ? ? ? ? ? ? dmbates at gmail.com ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?cc
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? r-sig-mixed-models at r-project.org
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Subject
> ? ? ? ? ? ? 07/17/2010 11:30 ? ? ? ? ?Re: [R-sig-ME] question about
> ? ? ? ? ? ? AM ? ? ? ? ? ? ? ? ? ? ? ?random coefficients model (RCM)
>
>
>
>
>
>
>
>
>
>
> On Sat, Jul 17, 2010 at 9:52 AM, JOSE A ALEMAN <aleman at fordham.edu>
wrote:
>>
>> Dear list users,
>>
>> I have a question about how to estimate the RCM described by Western
> (1998)
>> in his article "Causal Heterogeneity in Comparative Research: A Bayesian
>> Hierarchical Modeling Approach". While I know how to estimate this model
> in
>> R via restricted maximum likelihood, I am at a loss as to how to
> interpret
>> the results. The random coefficients are supposed to be different for
> each
>> country, yet R provides ?a standard regression-like output with a single
>> coefficient for the variable with the random slope. How would I go about
>> extracting the country specific information?
>
> Can you be more specific about how you fit the model? ?Just saying "in
> R" is too general.
>
> If you fit the model with lmer from the lme4 package then you may want
> to look at the output from the ranef() and coef() extractors.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From lucianolasala at yahoo.com.ar  Sat Jul 31 00:01:02 2010
From: lucianolasala at yahoo.com.ar (Luciano La Sala)
Date: Fri, 30 Jul 2010 19:01:02 -0300
Subject: [R-sig-ME] Plot a "mer" object
Message-ID: <9F6C251E0C38456D8C9FEDE9F761C6CA@Negro1>

Hello all,  

Sorry to re-post, but I got no response from the list and I am still
struggling with this. 
 
I fitted a glmm on a small dataset using lme4. Data consist of dependent
variable "Egg_Volume" (continuous) and independent variables "Hatching
Order" (3 factors: first, second, third), "Year" (2 factors: 2006, 2007) and
their interaction (Hatching_Order*Year). Nest IDs were included as random
intercepts. 

Model output: 

> model.2 <- lmer(EggVolume~HatchOrder*Year+(1|NestID),REML=FALSE)

Linear mixed model fit by maximum likelihood 
Formula: EggVolume ~ HatchOrder * Year + (1 | NestID) 
   AIC   BIC logLik deviance REMLdev
 745.4 768.4 -364.7    729.4   720.4

Random effects:
 Groups   Name        Variance Std.Dev.
 NestID   (Intercept) 25.272   5.0271  
 Residual              5.930   2.4352  
Number of obs: 130, groups: NestID, 55

Fixed effects:
                          Estimate Std. Error t value
(Intercept)                79.6515     1.1092   71.81
HatchOrderSecond           -0.5676     0.7714   -0.74
HatchOrderThird            -4.7545     0.8817   -5.39
Year2007                    3.6288     1.5408    2.36
HatchOrderSecond:Year2007  -2.8466     1.0600   -2.69
HatchOrderThird:Year2007   -2.8900     1.1946   -2.42

Correlation of Fixed Effects:
            (Intr) HtchOS HtchOT Yr2007 HOS:Y2
HtchOrdrScn -0.267                            
HtchOrdrThr -0.221  0.367                     
Year2007    -0.720  0.192  0.159              
HtcOS:Y2007  0.195 -0.728 -0.267 -0.294       
HtcOT:Y2007  0.163 -0.271 -0.738 -0.297  0.404

I've been trying to come to grips with the function "plotLMER.fnc" from
"languageR" package to plot my results, but so far I have not succeeded. 

>From the relevant documentation
(http://bm2.genes.nig.ac.jp/RGM2/R_current/library/languageR/man/plotLMER.fn
c.html) there are some arguments which I am not sure how to specify
(indicated with "???" below).  

plotLMER.fnc(mixto.4a, xlabel = NA, xlabs = "Year", ylabel = "Egg Volume",
ylimit = NA, fun = NA, pred = NA, n = ????, intr = ????, "end", mcmcMat =
NA, lockYlim = TRUE, addlines = TRUE, withList = FALSE, cexsize = 0.5)

Could someone help me out with this? If there is a better and simpler way of
plotting this kind of models, I'd like to know it. I am quite new to R and
its language. 

I'd be thrilled if there were a better, more straightforward way of plotting
my results (considering the RE and interaction term). 

Thanks in advance! 

LFLS



From Mike.Lawrence at dal.ca  Sat Jul 31 06:10:43 2010
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Sat, 31 Jul 2010 01:10:43 -0300
Subject: [R-sig-ME] gamm4 model formulation clarification
Message-ID: <AANLkTims1fHToCt7RyRN1jdVhNbXZuUzM5SWRXq2+Y2T@mail.gmail.com>

Hi folks,

I have some data that form a 2x2x15 design, where the 15 level
variable is a discrete sampling of a ratio variable with clear
non-linearities (see bottom for a dput() of the means). I came across
gamm4 tonight and it looks like it will help tackle this data, but I'm
not sure how to tell it to let the smooth of the 15 level variable
vary as a function of BOTH of the other predictor variables. As a
hack, I created a dummy 4 level variable that represented the
combination of the 2x2 level variables, but I'm not positive that this
was the right thing to do. Any feedback would be greatly appreciated.
Here's how I had things set up:

> str(ab)
'data.frame':	49668 obs. of  5 variables:
 $ id       : Factor w/ 20 levels "5","6","7","8",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ design   : Factor w/ 2 levels "CD","NCD": 1 1 1 1 1 1 1 1 1 1 ...
 $ ddB      : Factor w/ 2 levels "0ddB","+ddB": 1 1 1 1 1 1 1 1 1 1 ...
 $ soa      : num  300 300 300 300 300 300 300 300 300 300 ...
 $ rt       : num  441 373 440 290 221 ...
 $ g        : Factor w/ 4 levels "+ddB CD","+ddB NCD",..: 3 3 3 3 3 3
3 3 3 3 ...

#id is the random effect (human participants)
#design and ddB are 2-level fixed effects
#soa is a 15 level fixed effect
#rt is the data to predict (there are dozens of observations for each
combination of the random and fixed effects)

#fit using dummy variable "g" to get different soa smooths per
combination of ddB and design
fit = gamm4(
	data = ab
	, formula = rrt ~ ddB*design+s(soa,by=g)
	, random = ~ (1|id)
	, family = 'gaussian'
)


#here's dput() ouput of the 2x2x15 means, revealing that soa is
clearly non-linear
> dput(means)
structure(list(ddB = structure(c(1L, 2L, 1L, 2L, 1L, 2L, 1L,
2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
2L, 1L, 2L, 1L, 2L), .Label = c("0ddB", "+ddB"), class = "factor"),
    design = structure(c(1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L,
    1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L,
    1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L,
    2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L,
    2L, 2L, 1L, 1L, 2L, 2L), .Label = c("CD", "NCD"), class = "factor"),
    soa = c(-175, -175, -175, -175, -125, -125, -125, -125, -75,
    -75, -75, -75, -25, -25, -25, -25, 25, 25, 25, 25, 75, 75,
    75, 75, 125, 125, 125, 125, 175, 175, 175, 175, 250, 250,
    250, 250, 350, 350, 350, 350, 450, 450, 450, 450, 550, 550,
    550, 550, 700, 700, 700, 700, 900, 900, 900, 900, 1100, 1100,
    1100, 1100), rt = structure(c(444.93273739708, 441.513208123373,
    471.546335977687, 472.283526755609, 444.056771928409, 442.461563636396,
    472.166623352385, 474.462330421383, 445.513188139913, 444.966221088285,
    475.669898472348, 461.315736508479, 442.982086750377, 435.355068015326,
    458.89264807265, 455.638816561315, 434.340063293089, 415.709247937572,
    450.359216604288, 438.114012378908, 420.982354512772, 404.811090521404,
    442.721222728774, 430.421981079446, 406.373845346035, 393.411137886923,
    439.687373941982, 427.611295261772, 398.185439780545, 384.007719475387,
    429.451304040456, 431.531830923294, 390.486982286177, 380.880066145206,
    431.287499227013, 435.926925139256, 382.937376664574, 382.020452210116,
    439.606939778423, 441.751714989440, 384.546631449636, 385.477927260379,
    440.7286749068, 442.790235121405, 387.589278670798, 386.68589658312,
    440.384534575679, 440.376618739428, 392.649929780933, 392.496542853778,
    442.673509587221, 446.148838198613, 401.042352162140, 394.475542684099,
    441.072702415870, 440.157897723193, 406.059905100442, 398.292572833949,
    443.899793077701, 445.715779415161), .Dim = c(60L, 1L), .Dimnames = list(
        NULL, NULL))), .Names = c("ddB", "design", "soa", "rt"
), row.names = c(NA, 60L), class = "data.frame")

#visualise the means
library(ggplot2)
ggplot(
	data = means
	, mapping = aes(
		x = soa
		, y = rt
		, colour = design
		, linetype = ddB
	)
)+
geom_line()+
geom_point(shape=21,fill='white')

-- 
Mike Lawrence
Graduate Student
Department of Psychology
Dalhousie University

Looking to arrange a meeting? Check my public calendar:
http://tr.im/mikes_public_calendar

~ Certainty is folly... I think. ~



From nuala.brady at ucd.ie  Sat Jul 31 13:41:29 2010
From: nuala.brady at ucd.ie (nuala brady)
Date: Sat, 31 Jul 2010 12:41:29 +0100
Subject: [R-sig-ME] help in coding random effects in lmer
Message-ID: <73409e642cb2.4c5419f9@ucd.ie>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100731/d1bb3eb8/attachment.pl>

From j.hadfield at ed.ac.uk  Sat Jul 31 15:22:19 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sat, 31 Jul 2010 14:22:19 +0100
Subject: [R-sig-ME] What to do when a subset of binomial data has
	only	positive outcomes
In-Reply-To: <AANLkTimpQ33tDNQZqpP_pS7b2RvmSHB-VCA=K2BwUtzr@mail.gmail.com>
References: <OFAACC9BC8.01B76E7F-ON88257770.004D99D8-88257770.004F82C1@nps.gov>
	<AANLkTimpQ33tDNQZqpP_pS7b2RvmSHB-VCA=K2BwUtzr@mail.gmail.com>
Message-ID: <20100731142219.dsk04v6o00w8gw8g@www.staffmail.ed.ac.uk>

You may want to take a look at A WEAKLY INFORMATIVE DEFAULT PRIOR  
DISTRIBUTION FOR LOGISTIC AND OTHER REGRESSION MODELS Gelman et. al.  
2008 The annals of applied statistics 2 pp1360-1383 which you will  
need to implement in BUGS or JAGS. However, an easier route may be to  
to use normal priors on the coefficients and use MCMCglmm. In many  
cases I think this prior specification has good properties. For example:

dat<-data.frame(y = gl(2,50, labels=c(0,1)), tr = gl(2,50)) # data  
with complete separation

# standard glm #

summary(glm(y~tr-1, family="binomial", data=dat))  # SE's and p-values  
suffer from the Hauck-Donner effect

# Bayesian glm - logit link #

prior1<-list(R=list(V=1, fix=1), B=list(V=diag(2)*(pi^2/3+1), mu=rep(0,2)))

# residual variance is not identifiable in the likelihood for binary  
data so fixed at 1
# give the coefficients independent prior distribution with mean zero  
and variance pi^2/3 (variance of the logistic distribution) + 1 (the  
residual variance)

m1<-MCMCglmm(y~tr-1, family="categorical", data=dat, prior=prior1,slice=T)

# use family categorical: link is logit (plogis)

c2 <- (16 * sqrt(3)/(15 * pi))^2

HPDinterval(plogis(m1$Sol[,1]/sqrt(1+c2)))
HPDinterval(plogis(m1$Sol[,2]/sqrt(1+c2)))

# get credible intervals for probability of success for both levels of  
tr after marginalising the residuals

# Bayesian glm - probit link #

prior2<-list(R=list(V=1, fix=1), B=list(V=diag(2)*2, mu=rep(0,2)))

# again residual variance is not identifiable in the likelihood for  
binary data so fixed at 1
# give the coefficients independent prior distribution with mean zero  
and variance 1 (the variance of the unit normal) + 1 (the residual  
variance)

m2<-MCMCglmm(y~tr-1, family="ordinal", data=dat, prior=prior2, slice=T)

# use family ordinal: link is probit (pnorm)

c2 <- 1

HPDinterval(pnorm(m2$Sol[,1]/sqrt(1+c2)))
HPDinterval(pnorm(m2$Sol[,2]/sqrt(1+c2)))

# get credible intervals for probability of success for both levels of  
tr after marginalising the residuals.

You will probably need more iterations that the default when complete  
separation exists.

Cheers,

Jarrod


Quoting Ben Bolker <bbolker at gmail.com>:

>   The bleeding-edge version of lme4, lme4a, has some profiling
> capabilities that might (?) be useful. A Bayesian approach (which you
> would probably have to roll yourself; glmmBUGS exists but did not seem
> flexible enough to deal with crossed random effects the last time I
> looked) would also be useful for stabilizing this kind of estimation
> problem (i.e., assigning a prior would allow the posterior probability
> density to be not quite completely concentrated at prob=0 or prob=1
> ...)  For inspiration you might also try looking in the GLM literature
> under the keyword 'complete separation'.
>
> On Fri, Jul 30, 2010 at 10:28 AM,  <Timothy_Handley at nps.gov> wrote:
>>
>> I had this problem with glm. My solution was to create a likelihood
>> function, and use the optim or optimize function to find an appropriate
>> confidence interval. More specifically, I found the likelihood of the data
>> for the best-estimate parameters, then found the range of parameters for
>> which a likelihood-ratio-test (best-estimate params vs. current params) had
>> a p-value>.025. The range is then the 95% confidence interval for those
>> parameters. This is essentially replicating the functionality of glm by
>> hand, as it seemed unable to deal with data which is all positive or all
>> negative.
>>
>> While I understand how to do this with glm, I don't understand enough about
>> fixed effects models to do the same for lmer. If you were willing to treat
>> everything as a fixed effect and switch to glm, then you could e-mail me,
>> and I could offer some more specific advice on how to do this.
>>
>> If anyone else has a better solution, I'd be very interested to hear it.
>>
>> Tim Handley
>> Fire Effects Monitor
>> Santa Monica Mountains National Recreation Area
>> 401 W. Hillcrest Dr.
>> Thousand Oaks, CA 91360
>> 805-370-2300 x2412
>>
>> Date: Thu, 29 Jul 2010 17:57:35 -0700
>> From: Xiao He <praguewatermelon at gmail.com>
>> To: r-sig-mixed-models at r-project.org
>> Subject: [R-sig-ME] What to do when a subset of binomial data has only
>> ? ? ? ? ? ? positive outcomes
>> Message-ID:
>> ? ? ? ? ? ? <AANLkTi=zskcerd9fuELVQZ833mYPRkCddYpRUdVvQq7- at mail.gmail.com>
>> Content-Type: text/plain
>>
>> Dear R users and experts,
>>
>> I tried to fit a model as shown below:
>>
>> data.lmer<-lmer(word1~compoundType*nativelanguage + (1|subject) + (1|word),
>> data=data, family="binomial").
>>
>> the factor 'compoundType' has three levels: blue, green, red.
>> the factor nativelanguage has two levels: english, other
>>
>> I obtained the following results:
>> ************************************************
>> Fixed effects:
>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
>> (Intercept) ? ? ? ? ? ? ? ? ? ?-1.0190 ? ? 0.5777 ?-1.764 ? 0.0778 .
>> nativelanguageother ? ? ? ? ? ?-0.6862 ? ? 0.4075 ?-1.684 ? 0.0922 .
>> typegreen ? ? ? ? ? ? ? ? ? ? ?19.7882 ? 728.0627 ? 0.027 ? 0.9783
>> typered ? ? ? ? ? ? ? ? ? ? ? ? 3.6985 ? ? 0.8359 ? 4.425 9.65e-06 ***
>> nativelanguageother:typegreen -16.1915 ? 728.0624 ?-0.022 ? 0.9823
>> nativelanguageother:typered ? ?-2.8106 ? ? 0.5639 ?-4.984 6.23e-07 ***
>> ---
>> Signif. codes: ?0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> ************************************************
>>
>> As you can see, the standard errors and estimates for "typegreen" as well
>> as
>> "nativelanguageother:typegreen" are enormous. I examined my data and
>> realized that the responses obtained for the level "green" of compoundType
>> were all positive. But the responses of "green" were clearly significantly
>> different from the base level "blue" as green was 100% positive responses,
>> whereas blue had only 30% of positive responses.
>>
>> I wonder if there is any way to conduct statistical analyses to show that
>> green is significantly different from blue (and potentially red) because
>> obviously I can't just say they are different :)...
>>
>> Thank you in advance for your help!
>>
>>
>>
>> Best,
>>
>> Xiao He
>> Graduate student
>> Department of Linguistics
>> University of Southern California
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From reinhold.kliegl at gmail.com  Sat Jul 31 23:30:24 2010
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Sat, 31 Jul 2010 23:30:24 +0200
Subject: [R-sig-ME] gamm4 model formulation clarification
In-Reply-To: <AANLkTims1fHToCt7RyRN1jdVhNbXZuUzM5SWRXq2+Y2T@mail.gmail.com>
References: <AANLkTims1fHToCt7RyRN1jdVhNbXZuUzM5SWRXq2+Y2T@mail.gmail.com>
Message-ID: <AANLkTinRyvm=qj=Pooz1QOJMN-a7bJoQMjJa_Bxn4qLD@mail.gmail.com>

Perhaps assign contrasts to g. For example,
# ... ... contrast estimates
cmat <- matrix(c(  -1/2, -1/2, +1/2, +1/2,   # Main effect 1
                              -1/2, +1/2, -1/2, +1/2,   # Main effect 2
                              +1/2, -1/2, -1/2, +1/2),  4,  3,    # Interaction
                               dimnames=list(c("A1", "A2", "A3", "A4"),
                                c(".34-12", ".24-13", ".14-23")))

constrasts(g) <- cmat
 fit = gamm4(
     ?data = ab
      , formula = rrt ~ g+s(soa,by=g)
    ?, random = ~ (1|id)
    ?, family = 'gaussian'
   )

Reinhold Kliegl

On Sat, Jul 31, 2010 at 6:10 AM, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
> Hi folks,
>
> I have some data that form a 2x2x15 design, where the 15 level
> variable is a discrete sampling of a ratio variable with clear
> non-linearities (see bottom for a dput() of the means). I came across
> gamm4 tonight and it looks like it will help tackle this data, but I'm
> not sure how to tell it to let the smooth of the 15 level variable
> vary as a function of BOTH of the other predictor variables. As a
> hack, I created a dummy 4 level variable that represented the
> combination of the 2x2 level variables, but I'm not positive that this
> was the right thing to do. Any feedback would be greatly appreciated.
> Here's how I had things set up:
>
>> str(ab)
> 'data.frame': ? 49668 obs. of ?5 variables:
> ?$ id ? ? ? : Factor w/ 20 levels "5","6","7","8",..: 1 1 1 1 1 1 1 1 1 1 ...
> ?$ design ? : Factor w/ 2 levels "CD","NCD": 1 1 1 1 1 1 1 1 1 1 ...
> ?$ ddB ? ? ?: Factor w/ 2 levels "0ddB","+ddB": 1 1 1 1 1 1 1 1 1 1 ...
> ?$ soa ? ? ?: num ?300 300 300 300 300 300 300 300 300 300 ...
> ?$ rt ? ? ? : num ?441 373 440 290 221 ...
> ?$ g ? ? ? ?: Factor w/ 4 levels "+ddB CD","+ddB NCD",..: 3 3 3 3 3 3
> 3 3 3 3 ...
>
> #id is the random effect (human participants)
> #design and ddB are 2-level fixed effects
> #soa is a 15 level fixed effect
> #rt is the data to predict (there are dozens of observations for each
> combination of the random and fixed effects)
>
> #fit using dummy variable "g" to get different soa smooths per
> combination of ddB and design
> fit = gamm4(
> ? ? ? ?data = ab
> ? ? ? ?, formula = rrt ~ ddB*design+s(soa,by=g)
> ? ? ? ?, random = ~ (1|id)
> ? ? ? ?, family = 'gaussian'
> )
>
>
> #here's dput() ouput of the 2x2x15 means, revealing that soa is
> clearly non-linear
>> dput(means)
> structure(list(ddB = structure(c(1L, 2L, 1L, 2L, 1L, 2L, 1L,
> 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
> 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
> 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
> 2L, 1L, 2L, 1L, 2L), .Label = c("0ddB", "+ddB"), class = "factor"),
> ? ?design = structure(c(1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L,
> ? ?1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L,
> ? ?1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L,
> ? ?2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L,
> ? ?2L, 2L, 1L, 1L, 2L, 2L), .Label = c("CD", "NCD"), class = "factor"),
> ? ?soa = c(-175, -175, -175, -175, -125, -125, -125, -125, -75,
> ? ?-75, -75, -75, -25, -25, -25, -25, 25, 25, 25, 25, 75, 75,
> ? ?75, 75, 125, 125, 125, 125, 175, 175, 175, 175, 250, 250,
> ? ?250, 250, 350, 350, 350, 350, 450, 450, 450, 450, 550, 550,
> ? ?550, 550, 700, 700, 700, 700, 900, 900, 900, 900, 1100, 1100,
> ? ?1100, 1100), rt = structure(c(444.93273739708, 441.513208123373,
> ? ?471.546335977687, 472.283526755609, 444.056771928409, 442.461563636396,
> ? ?472.166623352385, 474.462330421383, 445.513188139913, 444.966221088285,
> ? ?475.669898472348, 461.315736508479, 442.982086750377, 435.355068015326,
> ? ?458.89264807265, 455.638816561315, 434.340063293089, 415.709247937572,
> ? ?450.359216604288, 438.114012378908, 420.982354512772, 404.811090521404,
> ? ?442.721222728774, 430.421981079446, 406.373845346035, 393.411137886923,
> ? ?439.687373941982, 427.611295261772, 398.185439780545, 384.007719475387,
> ? ?429.451304040456, 431.531830923294, 390.486982286177, 380.880066145206,
> ? ?431.287499227013, 435.926925139256, 382.937376664574, 382.020452210116,
> ? ?439.606939778423, 441.751714989440, 384.546631449636, 385.477927260379,
> ? ?440.7286749068, 442.790235121405, 387.589278670798, 386.68589658312,
> ? ?440.384534575679, 440.376618739428, 392.649929780933, 392.496542853778,
> ? ?442.673509587221, 446.148838198613, 401.042352162140, 394.475542684099,
> ? ?441.072702415870, 440.157897723193, 406.059905100442, 398.292572833949,
> ? ?443.899793077701, 445.715779415161), .Dim = c(60L, 1L), .Dimnames = list(
> ? ? ? ?NULL, NULL))), .Names = c("ddB", "design", "soa", "rt"
> ), row.names = c(NA, 60L), class = "data.frame")
>
> #visualise the means
> library(ggplot2)
> ggplot(
> ? ? ? ?data = means
> ? ? ? ?, mapping = aes(
> ? ? ? ? ? ? ? ?x = soa
> ? ? ? ? ? ? ? ?, y = rt
> ? ? ? ? ? ? ? ?, colour = design
> ? ? ? ? ? ? ? ?, linetype = ddB
> ? ? ? ?)
> )+
> geom_line()+
> geom_point(shape=21,fill='white')
>
> --
> Mike Lawrence
> Graduate Student
> Department of Psychology
> Dalhousie University
>
> Looking to arrange a meeting? Check my public calendar:
> http://tr.im/mikes_public_calendar
>
> ~ Certainty is folly... I think. ~
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From reinhold.kliegl at gmail.com  Sat Jul 31 23:47:20 2010
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Sat, 31 Jul 2010 23:47:20 +0200
Subject: [R-sig-ME] gamm4 model formulation clarification
In-Reply-To: <AANLkTinRyvm=qj=Pooz1QOJMN-a7bJoQMjJa_Bxn4qLD@mail.gmail.com>
References: <AANLkTims1fHToCt7RyRN1jdVhNbXZuUzM5SWRXq2+Y2T@mail.gmail.com>
	<AANLkTinRyvm=qj=Pooz1QOJMN-a7bJoQMjJa_Bxn4qLD@mail.gmail.com>
Message-ID: <AANLkTimBL-zOQueKayB6Gf-_H3nvHZdE+3UOqOW+CTQE@mail.gmail.com>

Sorry, the following line should be:
constrasts(ab$g) <- cmat

On Sat, Jul 31, 2010 at 11:30 PM, Reinhold Kliegl
<reinhold.kliegl at gmail.com> wrote:
> Perhaps assign contrasts to g. For example,
> # ... ... contrast estimates
> cmat <- matrix(c( ?-1/2, -1/2, +1/2, +1/2, ? # Main effect 1
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?-1/2, +1/2, -1/2, +1/2, ? # Main effect 2
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?+1/2, -1/2, -1/2, +1/2), ?4, ?3, ? ?# Interaction
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? dimnames=list(c("A1", "A2", "A3", "A4"),
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?c(".34-12", ".24-13", ".14-23")))
>
> constrasts(g) <- cmat
> ?fit = gamm4(
> ? ? ?data = ab
> ? ? ?, formula = rrt ~ g+s(soa,by=g)
> ? ??, random = ~ (1|id)
> ? ??, family = 'gaussian'
> ? )
>
> Reinhold Kliegl
>
> On Sat, Jul 31, 2010 at 6:10 AM, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
>> Hi folks,
>>
>> I have some data that form a 2x2x15 design, where the 15 level
>> variable is a discrete sampling of a ratio variable with clear
>> non-linearities (see bottom for a dput() of the means). I came across
>> gamm4 tonight and it looks like it will help tackle this data, but I'm
>> not sure how to tell it to let the smooth of the 15 level variable
>> vary as a function of BOTH of the other predictor variables. As a
>> hack, I created a dummy 4 level variable that represented the
>> combination of the 2x2 level variables, but I'm not positive that this
>> was the right thing to do. Any feedback would be greatly appreciated.
>> Here's how I had things set up:
>>
>>> str(ab)
>> 'data.frame': ? 49668 obs. of ?5 variables:
>> ?$ id ? ? ? : Factor w/ 20 levels "5","6","7","8",..: 1 1 1 1 1 1 1 1 1 1 ...
>> ?$ design ? : Factor w/ 2 levels "CD","NCD": 1 1 1 1 1 1 1 1 1 1 ...
>> ?$ ddB ? ? ?: Factor w/ 2 levels "0ddB","+ddB": 1 1 1 1 1 1 1 1 1 1 ...
>> ?$ soa ? ? ?: num ?300 300 300 300 300 300 300 300 300 300 ...
>> ?$ rt ? ? ? : num ?441 373 440 290 221 ...
>> ?$ g ? ? ? ?: Factor w/ 4 levels "+ddB CD","+ddB NCD",..: 3 3 3 3 3 3
>> 3 3 3 3 ...
>>
>> #id is the random effect (human participants)
>> #design and ddB are 2-level fixed effects
>> #soa is a 15 level fixed effect
>> #rt is the data to predict (there are dozens of observations for each
>> combination of the random and fixed effects)
>>
>> #fit using dummy variable "g" to get different soa smooths per
>> combination of ddB and design
>> fit = gamm4(
>> ? ? ? ?data = ab
>> ? ? ? ?, formula = rrt ~ ddB*design+s(soa,by=g)
>> ? ? ? ?, random = ~ (1|id)
>> ? ? ? ?, family = 'gaussian'
>> )
>>
>>
>> #here's dput() ouput of the 2x2x15 means, revealing that soa is
>> clearly non-linear
>>> dput(means)
>> structure(list(ddB = structure(c(1L, 2L, 1L, 2L, 1L, 2L, 1L,
>> 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>> 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>> 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>> 2L, 1L, 2L, 1L, 2L), .Label = c("0ddB", "+ddB"), class = "factor"),
>> ? ?design = structure(c(1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L,
>> ? ?1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L,
>> ? ?1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L,
>> ? ?2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L,
>> ? ?2L, 2L, 1L, 1L, 2L, 2L), .Label = c("CD", "NCD"), class = "factor"),
>> ? ?soa = c(-175, -175, -175, -175, -125, -125, -125, -125, -75,
>> ? ?-75, -75, -75, -25, -25, -25, -25, 25, 25, 25, 25, 75, 75,
>> ? ?75, 75, 125, 125, 125, 125, 175, 175, 175, 175, 250, 250,
>> ? ?250, 250, 350, 350, 350, 350, 450, 450, 450, 450, 550, 550,
>> ? ?550, 550, 700, 700, 700, 700, 900, 900, 900, 900, 1100, 1100,
>> ? ?1100, 1100), rt = structure(c(444.93273739708, 441.513208123373,
>> ? ?471.546335977687, 472.283526755609, 444.056771928409, 442.461563636396,
>> ? ?472.166623352385, 474.462330421383, 445.513188139913, 444.966221088285,
>> ? ?475.669898472348, 461.315736508479, 442.982086750377, 435.355068015326,
>> ? ?458.89264807265, 455.638816561315, 434.340063293089, 415.709247937572,
>> ? ?450.359216604288, 438.114012378908, 420.982354512772, 404.811090521404,
>> ? ?442.721222728774, 430.421981079446, 406.373845346035, 393.411137886923,
>> ? ?439.687373941982, 427.611295261772, 398.185439780545, 384.007719475387,
>> ? ?429.451304040456, 431.531830923294, 390.486982286177, 380.880066145206,
>> ? ?431.287499227013, 435.926925139256, 382.937376664574, 382.020452210116,
>> ? ?439.606939778423, 441.751714989440, 384.546631449636, 385.477927260379,
>> ? ?440.7286749068, 442.790235121405, 387.589278670798, 386.68589658312,
>> ? ?440.384534575679, 440.376618739428, 392.649929780933, 392.496542853778,
>> ? ?442.673509587221, 446.148838198613, 401.042352162140, 394.475542684099,
>> ? ?441.072702415870, 440.157897723193, 406.059905100442, 398.292572833949,
>> ? ?443.899793077701, 445.715779415161), .Dim = c(60L, 1L), .Dimnames = list(
>> ? ? ? ?NULL, NULL))), .Names = c("ddB", "design", "soa", "rt"
>> ), row.names = c(NA, 60L), class = "data.frame")
>>
>> #visualise the means
>> library(ggplot2)
>> ggplot(
>> ? ? ? ?data = means
>> ? ? ? ?, mapping = aes(
>> ? ? ? ? ? ? ? ?x = soa
>> ? ? ? ? ? ? ? ?, y = rt
>> ? ? ? ? ? ? ? ?, colour = design
>> ? ? ? ? ? ? ? ?, linetype = ddB
>> ? ? ? ?)
>> )+
>> geom_line()+
>> geom_point(shape=21,fill='white')
>>
>> --
>> Mike Lawrence
>> Graduate Student
>> Department of Psychology
>> Dalhousie University
>>
>> Looking to arrange a meeting? Check my public calendar:
>> http://tr.im/mikes_public_calendar
>>
>> ~ Certainty is folly... I think. ~
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>



From Mike.Lawrence at dal.ca  Sun Aug  1 02:42:14 2010
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Sat, 31 Jul 2010 21:42:14 -0300
Subject: [R-sig-ME] gamm4 model formulation clarification
In-Reply-To: <AANLkTimBL-zOQueKayB6Gf-_H3nvHZdE+3UOqOW+CTQE@mail.gmail.com>
References: <AANLkTims1fHToCt7RyRN1jdVhNbXZuUzM5SWRXq2+Y2T@mail.gmail.com> 
	<AANLkTinRyvm=qj=Pooz1QOJMN-a7bJoQMjJa_Bxn4qLD@mail.gmail.com> 
	<AANLkTimBL-zOQueKayB6Gf-_H3nvHZdE+3UOqOW+CTQE@mail.gmail.com>
Message-ID: <AANLkTi=ZzfJKsNZyG_3jmx6DdSJ+Eb97qx9VF1qw8FoH@mail.gmail.com>

Thanks, though I'm not clear on how assigning contrasts to g then
adding it as a fixed effect is different from the original
specification, where the smooth is told to vary by g but g isn't in
the fixed effects; instead I had ddB*design in the fixed effects,
which I thought would be equivalent to having g and the contrasts you
suggested. However, it seems that I get different results between the
two approaches (see below). Any ideas why? I presume I'm missing
something!

Also, I'm just now thinking that neither approach really gets at what
I want to test; what I want to test whether the model is improved by
(1) letting the smooth vary as a function of design, (2) letting the
smooth vary as a function of ddB, and (3) letting the smooth vary as a
function of both design & ddB. That is, is there a design*soa
interaction, a ddB*soa interaction and/or a design*ddB*soa
interaction? In the case of support for any of these interactions, I'd
also be interested in pinpointing the timeframe over which the
interactions take place.

Thoughts?

#here is the "ddB*design+s(soa,by=g)" versus "g+s(soa,by=g)" fits and
output, showing that they're not identical:

>fit1 = gamm4(
>	data = ab
>	, formula = rt ~ ddB*design+s(soa,by=g)
>	, random = ~ (1|id)
>)
>
> print(fit1$mer,corr=F)
Linear mixed model fit by REML
     AIC     BIC logLik deviance REMLdev
 -564383 -564261 282205  -564567 -564411
Random effects:
 Groups   Name              Variance   Std.Dev.
 id       (Intercept)       6.9251e-08 0.00026316
 Xr.4     s(soa):g0ddB NCD 6.1200e-05 0.00782305
 Xr.3     s(soa):g0ddB CD  1.3823e-03 0.03717992
 Xr.2     s(soa):g+ddB NCD 2.4589e-04 0.01568096
 Xr.1     s(soa):g+ddB CD  2.0301e-03 0.04505718
 Residual                   2.0814e-07 0.00045623
Number of obs: 45013, groups: id, 20; Xr.4, 8; Xr.3, 8; Xr.2, 8; Xr.1, 8

Fixed effects:
                        Estimate Std. Error t value
X(Intercept)           2.455e-03  5.896e-05   41.63
XddB+ddB               5.104e-05  5.232e-06    9.76
XdesignNCD            -2.665e-04  7.066e-06  -37.72
XddB+ddB:designNCD    -4.450e-05  1.007e-05   -4.42
Xs(soa):g+ddB CDFx1  -1.592e-04  5.178e-05   -3.07
Xs(soa):g+ddB NCDFx1  1.099e-04  6.717e-05    1.64
Xs(soa):g0ddB CDFx1   9.027e-06  4.942e-05    0.18
Xs(soa):g0ddB NCDFx1  3.618e-05  4.430e-05    0.82
>
>
> summary(fit1$gam)

Family: gaussian
Link function: identity

Formula:
rrt ~ ddB * design + s(soa, by = g)

Parametric coefficients:
                    Estimate Std. Error t value Pr(>|t|)
(Intercept)        2.455e-03  3.706e-06 662.327  < 2e-16 ***
ddB+ddB            5.104e-05  5.230e-06   9.760  < 2e-16 ***
designNCD         -2.665e-04  7.260e-06 -36.710  < 2e-16 ***
ddB+ddB:designNCD -4.450e-05  1.005e-05  -4.428 9.55e-06 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Approximate significance of smooth terms:
                    edf Ref.df       F  p-value
s(soa):g+ddB CD  8.042  8.042 205.327  < 2e-16 ***
s(soa):g+ddB NCD 5.419  5.419   4.375 0.000361 ***
s(soa):g0ddB CD  7.795  7.795 213.477  < 2e-16 ***
s(soa):g0ddB NCD 3.977  3.977   4.461 0.001358 **
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

R-sq.(adj) =  0.0964lmer.REML score = -5.6441e+05  Scale est. =
2.0814e-07  n = 45013

>fit2 = gamm4(
>	data = ab
>	, formula = rt ~ g+s(soa,by=g)
>	, random = ~ (1|id)
>)
>
> print(fit2$mer,corr=F)
Linear mixed model fit by REML
     AIC     BIC logLik deviance REMLdev
 -564381 -564259 282205  -564567 -564409
Random effects:
 Groups   Name              Variance   Std.Dev.
 id       (Intercept)       6.9252e-08 0.00026316
 Xr.4     s(Ssoa):g0ddB NCD 6.1196e-05 0.00782278
 Xr.3     s(Ssoa):g0ddB CD  1.3824e-03 0.03718002
 Xr.2     s(Ssoa):g+ddB NCD 2.4589e-04 0.01568093
 Xr.1     s(Ssoa):g+ddB CD  2.0302e-03 0.04505719
 Residual                   2.0814e-07 0.00045623
Number of obs: 45013, groups: id, 20; Xr.4, 8; Xr.3, 8; Xr.2, 8; Xr.1, 8

Fixed effects:
                        Estimate Std. Error t value
X(Intercept)           2.336e-03  5.890e-05   39.66
Xg.34-12              -2.879e-05  5.035e-06   -5.72
Xg.24-13              -2.887e-04  5.032e-06  -57.38
Xg.14-23               2.225e-05  5.035e-06    4.42
Xs(soa):g+ddB CDFx1  -1.592e-04  5.178e-05   -3.07
Xs(soa):g+ddB NCDFx1  1.099e-04  6.717e-05    1.64
Xs(soa):g0ddB CDFx1   9.027e-06  4.942e-05    0.18
Xs(soa):g0ddB NCDFx1  3.618e-05  4.430e-05    0.82
>
>
> summary(fit2$gam)

Family: gaussian
Link function: identity

Formula:
rrt ~ g + s(soa, by = g)

Parametric coefficients:
              Estimate Std. Error t value Pr(>|t|)
(Intercept)  2.336e-03  2.637e-06 885.684  < 2e-16 ***
g.34-12     -2.879e-05  5.025e-06  -5.728 1.02e-08 ***
g.24-13     -2.887e-04  5.275e-06 -54.741  < 2e-16 ***
g.14-23      2.225e-05  5.025e-06   4.428 9.55e-06 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Approximate significance of smooth terms:
                    edf Ref.df       F  p-value
s(soa):g+ddB CD  8.042  8.042 205.328  < 2e-16 ***
s(soa):g+ddB NCD 5.419  5.419   4.375 0.000361 ***
s(soa):g0ddB CD  7.795  7.795 213.477  < 2e-16 ***
s(soa):g0ddB NCD 3.977  3.977   4.462 0.001357 **
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

R-sq.(adj) =  0.0964lmer.REML score = -5.6441e+05  Scale est. =
2.0814e-07  n = 45013



On Sat, Jul 31, 2010 at 6:47 PM, Reinhold Kliegl
<reinhold.kliegl at gmail.com> wrote:
> Sorry, the following line should be:
> constrasts(ab$g) <- cmat
>
> On Sat, Jul 31, 2010 at 11:30 PM, Reinhold Kliegl
> <reinhold.kliegl at gmail.com> wrote:
>> Perhaps assign contrasts to g. For example,
>> # ... ... contrast estimates
>> cmat <- matrix(c( ?-1/2, -1/2, +1/2, +1/2, ? # Main effect 1
>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?-1/2, +1/2, -1/2, +1/2, ? # Main effect 2
>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?+1/2, -1/2, -1/2, +1/2), ?4, ?3, ? ?# Interaction
>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? dimnames=list(c("A1", "A2", "A3", "A4"),
>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?c(".34-12", ".24-13", ".14-23")))
>>
>> constrasts(g) <- cmat
>> ?fit = gamm4(
>> ? ? ?data = ab
>> ? ? ?, formula = rrt ~ g+s(soa,by=g)
>> ? ??, random = ~ (1|id)
>> ? ??, family = 'gaussian'
>> ? )
>>
>> Reinhold Kliegl
>>
>> On Sat, Jul 31, 2010 at 6:10 AM, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
>>> Hi folks,
>>>
>>> I have some data that form a 2x2x15 design, where the 15 level
>>> variable is a discrete sampling of a ratio variable with clear
>>> non-linearities (see bottom for a dput() of the means). I came across
>>> gamm4 tonight and it looks like it will help tackle this data, but I'm
>>> not sure how to tell it to let the smooth of the 15 level variable
>>> vary as a function of BOTH of the other predictor variables. As a
>>> hack, I created a dummy 4 level variable that represented the
>>> combination of the 2x2 level variables, but I'm not positive that this
>>> was the right thing to do. Any feedback would be greatly appreciated.
>>> Here's how I had things set up:
>>>
>>>> str(ab)
>>> 'data.frame': ? 49668 obs. of ?5 variables:
>>> ?$ id ? ? ? : Factor w/ 20 levels "5","6","7","8",..: 1 1 1 1 1 1 1 1 1 1 ...
>>> ?$ design ? : Factor w/ 2 levels "CD","NCD": 1 1 1 1 1 1 1 1 1 1 ...
>>> ?$ ddB ? ? ?: Factor w/ 2 levels "0ddB","+ddB": 1 1 1 1 1 1 1 1 1 1 ...
>>> ?$ soa ? ? ?: num ?300 300 300 300 300 300 300 300 300 300 ...
>>> ?$ rt ? ? ? : num ?441 373 440 290 221 ...
>>> ?$ g ? ? ? ?: Factor w/ 4 levels "+ddB CD","+ddB NCD",..: 3 3 3 3 3 3
>>> 3 3 3 3 ...
>>>
>>> #id is the random effect (human participants)
>>> #design and ddB are 2-level fixed effects
>>> #soa is a 15 level fixed effect
>>> #rt is the data to predict (there are dozens of observations for each
>>> combination of the random and fixed effects)
>>>
>>> #fit using dummy variable "g" to get different soa smooths per
>>> combination of ddB and design
>>> fit = gamm4(
>>> ? ? ? ?data = ab
>>> ? ? ? ?, formula = rrt ~ ddB*design+s(soa,by=g)
>>> ? ? ? ?, random = ~ (1|id)
>>> ? ? ? ?, family = 'gaussian'
>>> )
>>>
>>>
>>> #here's dput() ouput of the 2x2x15 means, revealing that soa is
>>> clearly non-linear
>>>> dput(means)
>>> structure(list(ddB = structure(c(1L, 2L, 1L, 2L, 1L, 2L, 1L,
>>> 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>>> 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>>> 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>>> 2L, 1L, 2L, 1L, 2L), .Label = c("0ddB", "+ddB"), class = "factor"),
>>> ? ?design = structure(c(1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L,
>>> ? ?1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L,
>>> ? ?1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L,
>>> ? ?2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L,
>>> ? ?2L, 2L, 1L, 1L, 2L, 2L), .Label = c("CD", "NCD"), class = "factor"),
>>> ? ?soa = c(-175, -175, -175, -175, -125, -125, -125, -125, -75,
>>> ? ?-75, -75, -75, -25, -25, -25, -25, 25, 25, 25, 25, 75, 75,
>>> ? ?75, 75, 125, 125, 125, 125, 175, 175, 175, 175, 250, 250,
>>> ? ?250, 250, 350, 350, 350, 350, 450, 450, 450, 450, 550, 550,
>>> ? ?550, 550, 700, 700, 700, 700, 900, 900, 900, 900, 1100, 1100,
>>> ? ?1100, 1100), rt = structure(c(444.93273739708, 441.513208123373,
>>> ? ?471.546335977687, 472.283526755609, 444.056771928409, 442.461563636396,
>>> ? ?472.166623352385, 474.462330421383, 445.513188139913, 444.966221088285,
>>> ? ?475.669898472348, 461.315736508479, 442.982086750377, 435.355068015326,
>>> ? ?458.89264807265, 455.638816561315, 434.340063293089, 415.709247937572,
>>> ? ?450.359216604288, 438.114012378908, 420.982354512772, 404.811090521404,
>>> ? ?442.721222728774, 430.421981079446, 406.373845346035, 393.411137886923,
>>> ? ?439.687373941982, 427.611295261772, 398.185439780545, 384.007719475387,
>>> ? ?429.451304040456, 431.531830923294, 390.486982286177, 380.880066145206,
>>> ? ?431.287499227013, 435.926925139256, 382.937376664574, 382.020452210116,
>>> ? ?439.606939778423, 441.751714989440, 384.546631449636, 385.477927260379,
>>> ? ?440.7286749068, 442.790235121405, 387.589278670798, 386.68589658312,
>>> ? ?440.384534575679, 440.376618739428, 392.649929780933, 392.496542853778,
>>> ? ?442.673509587221, 446.148838198613, 401.042352162140, 394.475542684099,
>>> ? ?441.072702415870, 440.157897723193, 406.059905100442, 398.292572833949,
>>> ? ?443.899793077701, 445.715779415161), .Dim = c(60L, 1L), .Dimnames = list(
>>> ? ? ? ?NULL, NULL))), .Names = c("ddB", "design", "soa", "rt"
>>> ), row.names = c(NA, 60L), class = "data.frame")
>>>
>>> #visualise the means
>>> library(ggplot2)
>>> ggplot(
>>> ? ? ? ?data = means
>>> ? ? ? ?, mapping = aes(
>>> ? ? ? ? ? ? ? ?x = soa
>>> ? ? ? ? ? ? ? ?, y = rt
>>> ? ? ? ? ? ? ? ?, colour = design
>>> ? ? ? ? ? ? ? ?, linetype = ddB
>>> ? ? ? ?)
>>> )+
>>> geom_line()+
>>> geom_point(shape=21,fill='white')
>>>
>>> --
>>> Mike Lawrence
>>> Graduate Student
>>> Department of Psychology
>>> Dalhousie University
>>>
>>> Looking to arrange a meeting? Check my public calendar:
>>> http://tr.im/mikes_public_calendar
>>>
>>> ~ Certainty is folly... I think. ~
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Mike Lawrence
Graduate Student
Department of Psychology
Dalhousie University

Looking to arrange a meeting? Check my public calendar:
http://tr.im/mikes_public_calendar

~ Certainty is folly... I think. ~



From Mike.Lawrence at dal.ca  Sun Aug  1 03:07:57 2010
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Sat, 31 Jul 2010 22:07:57 -0300
Subject: [R-sig-ME] help in coding random effects in lmer
In-Reply-To: <73409e642cb2.4c5419f9@ucd.ie>
References: <73409e642cb2.4c5419f9@ucd.ie>
Message-ID: <AANLkTimnNxreGuVWEWMuqRJhyuAuKrXtz6PhL6HH41w0@mail.gmail.com>

I'm still learning mixed effects modelling myself, but one thing pops
out at me: In your formulae, you have the variable "meanRT"; I presume
this reflects the fact that you aggregated your data to means within
conditions prior to submitting it to lmer? If so, you have done
yourself a disservice; lmer can analyze the raw, trial-by-trial data
and you'll find that you can achieve higher power by providing it will
all the data. Now, a problem arises whereby RT data are  typically
positively skewed and violate the normality assumption; I feel there
is still a gap in the literature on how to deal with this (because
there are plenty of examples where this skew has been found to be
affected by experimental manipulations differentially from central
tendency), but a reciprocal transform at least seems to do well at
normalizing the residuals (Kliegl, Masson & Richter, 2009, compare
various transforms).

So, where "a" is your trial-by-trial data, I suggest you try:
a$rrt = 1/a$rt
fit1 = lmer(
    formula = rrt ~ (angle+laterality+condition:laterality)+(1|subject)
    , data = a
)

and let us know if you still get wonky results.

As a side note, l *think* that the difference between the two models
you posted was that the second permitted the effects to vary Ss-by-Ss,
which may be plausible but I assume costs power. As I understand it,
unless you are really interested in individual differences in the
effect (eg. for correlations, etc), it's better to avoid letting
effects vary Ss-by-Ss. (Again, I'm still getting to grips with mixed
effects modelling, so I may be entirely incorrect on these points!).

On Sat, Jul 31, 2010 at 8:41 AM, nuala brady <nuala.brady at ucd.ie> wrote:
> Dear lmer?people & Dr Bates
>
> ?I ?am a cognitive psychologist who needs to leave the ?world of ANOVA?and move to lmer. I am looking for advice on coding ?random effects in lmer.
>
> ??My experiment is: 30 subjects judge the laterality?of a hand (i.e.. say whether it is a left or right hand) presented onscreen?which varies in its
> ?(A) Laterality?(2 levels, right/left) and
> ?(B) Orientation (8 levels, 0 to 315 degs?in steps of 45 degs) while holding their own hands in one of 3 postures
> ?(C) Postures (3 levels, coded as both, minusRight?& minusLeft).
>
> ?The dependent variable is reaction time (RT).
>
> ?Laterality, Orientation & Posture are fixed effects (all ?coded as categorical variables), the random effects come from the ?subjects i.e.,
> ?all 30 subjects respond in all possible combinations of the ?experimental variables and we need to generalise from them to the ?population ...
>
> ?My expectation (based on theory & previous studies) is that there will be a sig. main effect of angle, of laterality?& possibly a condition by laterality?interaction;
> ?and graphing shows this.
>
> ?The traditional way to analyse such data ?in psychology, where we typically look at all main effects & possible ?interactions as a first pass,? is via a repeated measures
> ?(or within-subjects) ANOVA?and the ?code in R is
>
> ?aov(RT~Laterality*Angle*Posture+Error(subject/(Laterality*Angle*Posture)),data=RTdata)
>
> ?moving to lmer, simplifying the model to just look at effects I am interested in, and specifying the random effects as shown in many examples online as follows:
>
> ?model2a<-lmer(meanRT~(angle+laterality+condition:laterality)+(1|subject),data=RTdata)
>
> ?I receive the output shown below as OUTPUT 1. Looking at the table of fixed effects I note that the Std. Err. within a specific explanatory variable (e.g, Angle) is constant across all levels of that variable. Obviously I am on the wrong track as this is not an assumption I want to? make. One of the reasons I am moving from ANOVA?to lmer?is because variance is not constant across the levels of some factors (both angle & laterality) as seen from graph, by running levene's?test etc
>
> ?Rerunning as:
> ?model2<-lmer(meanRT~(angle+laterality+condition:laterality)+(angle|subject)+(laterality|subject)+(condition:laterality|subject),data=RTdata)
>
> ?(...and?quite honestly, I am generalizing here from how one might specify error in aov....)
>
> ?I receive the output shown below as OUTPUT 2. Scrolling?down to the fixed effects, the Std., Errs are looking a lot better to me, BUT I am unsure whether I am using the
> ?syntax?correctly
>
>
> ?can anyone advise?? I ?appreciate this may be a very basic question, but I have not found many ?examples in my reading except for nested designs (which do not apply here, as least in my understanding of 'nested designs' ), and crossed random effects (which seem more complex than I need, having more than 1 source of random effects)
>
> ?thanks in advance, - Nuala
>
> ?ps - in case the description of the experiment is not clear, I copy data for s1 (aine) at the very end of the email - this pattern will repeat for s2 to s30
>
> ?OUTPUT 1: summary(model2a)
> ?Linear mixed model fit by REML
> ?Formula: meanRT ~ (angle + laterality + condition:laterality) + (1 | subject)
> ??? Data: data
> ??? AIC?? BIC logLik deviance REMLdev
> ??20620 20699 -10295??? 20700?? 20590
> ?Random effects:
> ??Groups?? Name??????? Variance Std.Dev.
> ??subject? (Intercept) 124335?? 352.61
> ??Residual????????????? 94809?? 307.91
> ?Number of obs: 1440, groups: subject, 30
>
> ?Fixed effects:
> ???????????????????????????????????? Estimate Std. Error t value
> ?(Intercept)????????????????????????? 1218.82????? 70.70? 17.240
> ?angle45??????????????????????????????? 13.49????? 32.46?? 0.416
> ?angle90?????????????????????????????? 217.20????? 32.46?? 6.692
> ?angle135????????????????????????????? 499.11????? 32.46? 15.378
> ?angle180????????????????????????????? 961.80????? 32.46? 29.633
> ?angle225????????????????????????????? 471.60????? 32.46? 14.530
> ?angle270????????????????????????????? 228.82????? 32.46?? 7.050
> ?angle315?????????????????????????????? 62.12????? 32.46?? 1.914
> ?lateralityright????????????????????? -122.60????? 28.11? -4.362
> ?lateralityleft:conditionminusLeft????? 14.23????? 28.11?? 0.506
> ?lateralityright:conditionminusLeft??? -27.28????? 28.11? -0.971
> ?lateralityleft:conditionminusRight??? -33.77????? 28.11? -1.201
> ?lateralityright:conditionminusRight??? 35.94????? 28.11?? 1.279
>
>
> ?OUTPUT 2: summary(model2)
> ? Linear mixed model fit by REML
> ?Formula: meanRT ~ (angle + laterality + condition:laterality) + (angle | subject) + (laterality | subject) + (condition:laterality |subject)
> ??? Data: data
> ??? AIC?? BIC logLik deviance REMLdev
> ??19918 20345? -9878??? 19867?? 19756
> ?Random effects:
> ??Groups?? Name??????????????????????????????? Variance?? Std.Dev.?? Corr
> ??subject? (Intercept)???????????????????????? 3.5601e+04 188.681267
> ?????????? angle45???????????????????????????? 3.5488e+01?? 5.957191? 1.000
> ?????????? angle90???????????????????????????? 1.9515e+04 139.697353? 1.000
> ?????????? angle135??????????????????????????? 7.8349e+04 279.909544? 0.704
> ?????????? angle180??????????????????????????? 3.3373e+05 577.689525? 0.390
> ?????????? angle225??????????????????????????? 7.1096e+04 266.638569? 0.462
> ?????????? angle270??????????????????????????? 1.7412e+04 131.954987? 0.695
> ?????????? angle315??????????????????????????? 7.1155e+03? 84.353226? 0.759
> ??subject? (Intercept)???????????????????????? 2.5444e-04?? 0.015951
> ?????????? lateralityright???????????????????? 5.2171e-05?? 0.007223 -1.000
> ??subject? (Intercept)???????????????????????? 1.4016e+04 118.388702
> ?????????? conditionboth:lateralityleft??????? 1.2554e+04 112.046691? 0.327
> ?????????? conditionminusLeft:lateralityleft?? 3.0653e+04 175.080964? 0.257
> ?????????? conditionminusRight:lateralityleft? 1.6837e+04 129.758438 -0.019
> ?????????? conditionboth:lateralityright?????? 1.0627e+04 103.089657 -0.340
> ?????????? conditionminusLeft:lateralityright? 9.6021e+03? 97.990531 -0.822
> ?????????? conditionminusRight:lateralityright 1.0345e+04 101.711720 -0.453
> ??Residual???????????????????????????????????? 4.2251e+04 205.549629
>
>
>
> ?? 1.000
> ?? 0.704? 0.704
> ?? 0.390? 0.390? 0.847
> ?? 0.462? 0.462? 0.837? 0.889
> ?? 0.695? 0.695? 0.711? 0.609? 0.867
> ?? 0.759? 0.759? 0.324 -0.042? 0.021? 0.317
>
>
>
>
> ?? 0.424
> ?? 0.196? 0.569
> ?? 0.428 -0.431 -0.555
> ??-0.112 -0.364 -0.475? 0.730
> ??-0.451 -0.211? 0.622 -0.400 -0.094
>
> ?Number of obs: 1440, groups: subject, 30
>
> ?Fixed effects:
> ???????????????????????????????????? Estimate Std. Error t value
> ?(Intercept)????????????????????????? 1218.82????? 52.37? 23.273
> ?angle45??????????????????????????????? 13.49????? 21.69?? 0.622
> ?angle90?????????????????????????????? 217.20????? 33.47?? 6.490
> ?angle135????????????????????????????? 499.11????? 55.51?? 8.992
> ?angle180????????????????????????????? 961.80???? 107.67?? 8.933
> ?angle225????????????????????????????? 471.60????? 53.29?? 8.850
> ?angle270????????????????????????????? 228.82????? 32.40?? 7.062
> ?angle315?????????????????????????????? 62.12????? 26.58?? 2.337
> ?lateralityright????????????????????? -122.60????? 28.20? -4.348
> ?lateralityleft:conditionminusLeft????? 14.23????? 35.18?? 0.404
> ?lateralityright:conditionminusLeft??? -27.28????? 23.13? -1.180
> ?lateralityleft:conditionminusRight??? -33.77????? 33.79? -0.999
> ?lateralityright:conditionminusRight??? 35.94????? 36.48?? 0.985
>
>
> ?Example data for 1 subject
> ?data[1:48,1:5] - RT is actially mean RT of 18 trails
> ??? subject laterality? posture angle??? RT
> ?1???? aine?????? left?????? both???? 0? 844.8000
> ?2???? aine?????? left?????? both??? 45? 796.4706
> ?3???? aine?????? left?????? both??? 90 1007.5722
> ?4???? aine?????? left?????? both?? 135 1214.7556
> ?5???? aine?????? left?????? both?? 180 1249.9625
> ?6???? aine?????? left?????? both?? 225 1305.0500
> ?7???? aine?????? left?????? both?? 270 1043.8000
> ?8???? aine?????? left?????? both?? 315? 814.6833
> ?9???? aine?????? left? minusLeft???? 0? 817.3778
> ?10??? aine?????? left? minusLeft??? 45? 951.0588
> ?11??? aine?????? left? minusLeft??? 90 1044.5706
> ?12??? aine?????? left? minusLeft?? 135 1345.5625
> ?13??? aine?????? left? minusLeft?? 180 1482.8333
> ?14??? aine?????? left? minusLeft?? 225 1331.3588
> ?15??? aine?????? left? minusLeft?? 270? 985.1000
> ?16??? aine?????? left? minusLeft?? 315? 995.2563
> ?17??? aine?????? left minusRight???? 0? 986.8556
> ?18??? aine?????? left minusRight??? 45? 903.2176
> ?19??? aine?????? left minusRight??? 90? 947.8059
> ?20??? aine?????? left minusRight?? 135 1453.8750
> ?21??? aine?????? left minusRight?? 180 1698.8278
> ?22??? aine?????? left minusRight?? 225 1337.1200
> ?23??? aine?????? left minusRight?? 270 1109.2467
> ?24??? aine?????? left minusRight?? 315? 929.0412
> ?25??? aine????? right?????? both???? 0? 913.5944
> ?26??? aine????? right?????? both??? 45? 930.5056
> ?27??? aine????? right?????? both??? 90 1093.9167
> ?28??? aine????? right?????? both?? 135 1275.9647
> ?29??? aine????? right?????? both?? 180 1489.1750
> ?30??? aine????? right?????? both?? 225 1188.1333
> ?31??? aine????? right?????? both?? 270 1054.7778
> ?32??? aine????? right?????? both?? 315? 904.8722
> ?33??? aine????? right? minusLeft???? 0? 888.9375
> ?34??? aine????? right? minusLeft??? 45? 915.0706
> ?35??? aine????? right? minusLeft??? 90 1060.3167
> ?36??? aine????? right? minusLeft?? 135 1240.0867
> ?37??? aine????? right? minusLeft?? 180 1772.4611
> ?38??? aine????? right? minusLeft?? 225 1168.5625
> ?39??? aine????? right? minusLeft?? 270 1093.1889
> ?40??? aine????? right? minusLeft?? 315? 842.2667
> ?41??? aine????? right minusRight???? 0? 971.3944
> ?42??? aine????? right minusRight??? 45? 974.3333
> ?43??? aine????? right minusRight??? 90 1064.9833
> ?44??? aine????? right minusRight?? 135 1389.0059
> ?45??? aine????? right minusRight?? 180 1575.9000
> ?46??? aine????? right minusRight?? 225 1322.6444
> ?47??? aine????? right minusRight?? 270 1053.7389
> ?48??? aine????? right minusRight?? 315 1077.0529
>
>
> ?Nuala Brady
> ?School of Psychology
> ?University College Dublin
> ?Belfield, D4
> ?IRELAND
>
> ?+353 (0)1 716 8247
> ?nuala.brady at ucd.ie
>
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
Mike Lawrence
Graduate Student
Department of Psychology
Dalhousie University

Looking to arrange a meeting? Check my public calendar:
http://tr.im/mikes_public_calendar

~ Certainty is folly... I think. ~



From mr.xiaohe at gmail.com  Sun Aug  1 03:53:02 2010
From: mr.xiaohe at gmail.com (Xiao He)
Date: Sun, 1 Aug 2010 01:53:02 +0000
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 43, Issue 48
In-Reply-To: <mailman.5951.1280611833.4244.r-sig-mixed-models@r-project.org>
References: <mailman.5951.1280611833.4244.r-sig-mixed-models@r-project.org>
Message-ID: <AANLkTintJSqz5BhX4CaGXiVS1+noM32m9tiqOiD8KS=T@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100801/90254765/attachment.pl>

From praguewatermelon at gmail.com  Sun Aug  1 03:54:29 2010
From: praguewatermelon at gmail.com (Xiao He)
Date: Sun, 1 Aug 2010 01:54:29 +0000
Subject: [R-sig-ME] What to do when a subset of binomial data has only
	positive outcomes
Message-ID: <AANLkTi==w9vP1ZRPM02+bexkPsUyTSO6oYFSigQ5Gock@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100801/01ee58ac/attachment.pl>

From praguewatermelon at gmail.com  Sun Aug  1 04:18:57 2010
From: praguewatermelon at gmail.com (Xiao He)
Date: Sun, 1 Aug 2010 02:18:57 +0000
Subject: [R-sig-ME] What to do when a subset of binomial data has only
	positive outcomes
Message-ID: <AANLkTikkjhrn5dmLBi+=iytme9RaJAcEGEAJ0Ka=yuH=@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100801/bbc70f81/attachment.pl>

From reinhold.kliegl at gmail.com  Sun Aug  1 08:48:27 2010
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Sun, 1 Aug 2010 08:48:27 +0200
Subject: [R-sig-ME] gamm4 model formulation clarification
In-Reply-To: <AANLkTi=ZzfJKsNZyG_3jmx6DdSJ+Eb97qx9VF1qw8FoH@mail.gmail.com>
References: <AANLkTims1fHToCt7RyRN1jdVhNbXZuUzM5SWRXq2+Y2T@mail.gmail.com>
	<AANLkTinRyvm=qj=Pooz1QOJMN-a7bJoQMjJa_Bxn4qLD@mail.gmail.com>
	<AANLkTimBL-zOQueKayB6Gf-_H3nvHZdE+3UOqOW+CTQE@mail.gmail.com>
	<AANLkTi=ZzfJKsNZyG_3jmx6DdSJ+Eb97qx9VF1qw8FoH@mail.gmail.com>
Message-ID: <AANLkTi=yw_YpDn7Ueig8VrM4oW9bjF+U59G-KBZ5xu-T@mail.gmail.com>

On the difference between the two specifications: Perhaps you have
treatment contrasts for design and soa. Then the fixed effect
coefficients will not estimate the main effect and the interaction.
You would need to specify  "contrasts(design) <- contr.sum(2)/2, etc."
for them if you specify the contrast matrix as a I suggested (which
returns estimates of the difference between levels, not as a
difference from the grand mean as the default).

Reinhold Kliegl

On Sun, Aug 1, 2010 at 2:42 AM, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
> Thanks, though I'm not clear on how assigning contrasts to g then
> adding it as a fixed effect is different from the original
> specification, where the smooth is told to vary by g but g isn't in
> the fixed effects; instead I had ddB*design in the fixed effects,
> which I thought would be equivalent to having g and the contrasts you
> suggested. However, it seems that I get different results between the
> two approaches (see below). Any ideas why? I presume I'm missing
> something!
>
> Also, I'm just now thinking that neither approach really gets at what
> I want to test; what I want to test whether the model is improved by
> (1) letting the smooth vary as a function of design, (2) letting the
> smooth vary as a function of ddB, and (3) letting the smooth vary as a
> function of both design & ddB. That is, is there a design*soa
> interaction, a ddB*soa interaction and/or a design*ddB*soa
> interaction? In the case of support for any of these interactions, I'd
> also be interested in pinpointing the timeframe over which the
> interactions take place.
>
> Thoughts?
>
> #here is the "ddB*design+s(soa,by=g)" versus "g+s(soa,by=g)" fits and
> output, showing that they're not identical:
>
>>fit1 = gamm4(
>> ? ? ? data = ab
>> ? ? ? , formula = rt ~ ddB*design+s(soa,by=g)
>> ? ? ? , random = ~ (1|id)
>>)
>>
>> print(fit1$mer,corr=F)
> Linear mixed model fit by REML
> ? ? AIC ? ? BIC logLik deviance REMLdev
> ?-564383 -564261 282205 ?-564567 -564411
> Random effects:
> ?Groups ? Name ? ? ? ? ? ? ?Variance ? Std.Dev.
> ?id ? ? ? (Intercept) ? ? ? 6.9251e-08 0.00026316
> ?Xr.4 ? ? s(soa):g0ddB NCD 6.1200e-05 0.00782305
> ?Xr.3 ? ? s(soa):g0ddB CD ?1.3823e-03 0.03717992
> ?Xr.2 ? ? s(soa):g+ddB NCD 2.4589e-04 0.01568096
> ?Xr.1 ? ? s(soa):g+ddB CD ?2.0301e-03 0.04505718
> ?Residual ? ? ? ? ? ? ? ? ? 2.0814e-07 0.00045623
> Number of obs: 45013, groups: id, 20; Xr.4, 8; Xr.3, 8; Xr.2, 8; Xr.1, 8
>
> Fixed effects:
> ? ? ? ? ? ? ? ? ? ? ? ?Estimate Std. Error t value
> X(Intercept) ? ? ? ? ? 2.455e-03 ?5.896e-05 ? 41.63
> XddB+ddB ? ? ? ? ? ? ? 5.104e-05 ?5.232e-06 ? ?9.76
> XdesignNCD ? ? ? ? ? ?-2.665e-04 ?7.066e-06 ?-37.72
> XddB+ddB:designNCD ? ?-4.450e-05 ?1.007e-05 ? -4.42
> Xs(soa):g+ddB CDFx1 ?-1.592e-04 ?5.178e-05 ? -3.07
> Xs(soa):g+ddB NCDFx1 ?1.099e-04 ?6.717e-05 ? ?1.64
> Xs(soa):g0ddB CDFx1 ? 9.027e-06 ?4.942e-05 ? ?0.18
> Xs(soa):g0ddB NCDFx1 ?3.618e-05 ?4.430e-05 ? ?0.82
>>
>>
>> summary(fit1$gam)
>
> Family: gaussian
> Link function: identity
>
> Formula:
> rrt ~ ddB * design + s(soa, by = g)
>
> Parametric coefficients:
> ? ? ? ? ? ? ? ? ? ?Estimate Std. Error t value Pr(>|t|)
> (Intercept) ? ? ? ?2.455e-03 ?3.706e-06 662.327 ?< 2e-16 ***
> ddB+ddB ? ? ? ? ? ?5.104e-05 ?5.230e-06 ? 9.760 ?< 2e-16 ***
> designNCD ? ? ? ? -2.665e-04 ?7.260e-06 -36.710 ?< 2e-16 ***
> ddB+ddB:designNCD -4.450e-05 ?1.005e-05 ?-4.428 9.55e-06 ***
> ---
> Signif. codes: ?0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Approximate significance of smooth terms:
> ? ? ? ? ? ? ? ? ? ?edf Ref.df ? ? ? F ?p-value
> s(soa):g+ddB CD ?8.042 ?8.042 205.327 ?< 2e-16 ***
> s(soa):g+ddB NCD 5.419 ?5.419 ? 4.375 0.000361 ***
> s(soa):g0ddB CD ?7.795 ?7.795 213.477 ?< 2e-16 ***
> s(soa):g0ddB NCD 3.977 ?3.977 ? 4.461 0.001358 **
> ---
> Signif. codes: ?0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> R-sq.(adj) = ?0.0964lmer.REML score = -5.6441e+05 ?Scale est. =
> 2.0814e-07 ?n = 45013
>
>>fit2 = gamm4(
>> ? ? ? data = ab
>> ? ? ? , formula = rt ~ g+s(soa,by=g)
>> ? ? ? , random = ~ (1|id)
>>)
>>
>> print(fit2$mer,corr=F)
> Linear mixed model fit by REML
> ? ? AIC ? ? BIC logLik deviance REMLdev
> ?-564381 -564259 282205 ?-564567 -564409
> Random effects:
> ?Groups ? Name ? ? ? ? ? ? ?Variance ? Std.Dev.
> ?id ? ? ? (Intercept) ? ? ? 6.9252e-08 0.00026316
> ?Xr.4 ? ? s(Ssoa):g0ddB NCD 6.1196e-05 0.00782278
> ?Xr.3 ? ? s(Ssoa):g0ddB CD ?1.3824e-03 0.03718002
> ?Xr.2 ? ? s(Ssoa):g+ddB NCD 2.4589e-04 0.01568093
> ?Xr.1 ? ? s(Ssoa):g+ddB CD ?2.0302e-03 0.04505719
> ?Residual ? ? ? ? ? ? ? ? ? 2.0814e-07 0.00045623
> Number of obs: 45013, groups: id, 20; Xr.4, 8; Xr.3, 8; Xr.2, 8; Xr.1, 8
>
> Fixed effects:
> ? ? ? ? ? ? ? ? ? ? ? ?Estimate Std. Error t value
> X(Intercept) ? ? ? ? ? 2.336e-03 ?5.890e-05 ? 39.66
> Xg.34-12 ? ? ? ? ? ? ?-2.879e-05 ?5.035e-06 ? -5.72
> Xg.24-13 ? ? ? ? ? ? ?-2.887e-04 ?5.032e-06 ?-57.38
> Xg.14-23 ? ? ? ? ? ? ? 2.225e-05 ?5.035e-06 ? ?4.42
> Xs(soa):g+ddB CDFx1 ?-1.592e-04 ?5.178e-05 ? -3.07
> Xs(soa):g+ddB NCDFx1 ?1.099e-04 ?6.717e-05 ? ?1.64
> Xs(soa):g0ddB CDFx1 ? 9.027e-06 ?4.942e-05 ? ?0.18
> Xs(soa):g0ddB NCDFx1 ?3.618e-05 ?4.430e-05 ? ?0.82
>>
>>
>> summary(fit2$gam)
>
> Family: gaussian
> Link function: identity
>
> Formula:
> rrt ~ g + s(soa, by = g)
>
> Parametric coefficients:
> ? ? ? ? ? ? ?Estimate Std. Error t value Pr(>|t|)
> (Intercept) ?2.336e-03 ?2.637e-06 885.684 ?< 2e-16 ***
> g.34-12 ? ? -2.879e-05 ?5.025e-06 ?-5.728 1.02e-08 ***
> g.24-13 ? ? -2.887e-04 ?5.275e-06 -54.741 ?< 2e-16 ***
> g.14-23 ? ? ?2.225e-05 ?5.025e-06 ? 4.428 9.55e-06 ***
> ---
> Signif. codes: ?0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Approximate significance of smooth terms:
> ? ? ? ? ? ? ? ? ? ?edf Ref.df ? ? ? F ?p-value
> s(soa):g+ddB CD ?8.042 ?8.042 205.328 ?< 2e-16 ***
> s(soa):g+ddB NCD 5.419 ?5.419 ? 4.375 0.000361 ***
> s(soa):g0ddB CD ?7.795 ?7.795 213.477 ?< 2e-16 ***
> s(soa):g0ddB NCD 3.977 ?3.977 ? 4.462 0.001357 **
> ---
> Signif. codes: ?0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> R-sq.(adj) = ?0.0964lmer.REML score = -5.6441e+05 ?Scale est. =
> 2.0814e-07 ?n = 45013
>
>
>
> On Sat, Jul 31, 2010 at 6:47 PM, Reinhold Kliegl
> <reinhold.kliegl at gmail.com> wrote:
>> Sorry, the following line should be:
>> constrasts(ab$g) <- cmat
>>
>> On Sat, Jul 31, 2010 at 11:30 PM, Reinhold Kliegl
>> <reinhold.kliegl at gmail.com> wrote:
>>> Perhaps assign contrasts to g. For example,
>>> # ... ... contrast estimates
>>> cmat <- matrix(c( ?-1/2, -1/2, +1/2, +1/2, ? # Main effect 1
>>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?-1/2, +1/2, -1/2, +1/2, ? # Main effect 2
>>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?+1/2, -1/2, -1/2, +1/2), ?4, ?3, ? ?# Interaction
>>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? dimnames=list(c("A1", "A2", "A3", "A4"),
>>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?c(".34-12", ".24-13", ".14-23")))
>>>
>>> constrasts(g) <- cmat
>>> ?fit = gamm4(
>>> ? ? ?data = ab
>>> ? ? ?, formula = rrt ~ g+s(soa,by=g)
>>> ? ??, random = ~ (1|id)
>>> ? ??, family = 'gaussian'
>>> ? )
>>>
>>> Reinhold Kliegl
>>>
>>> On Sat, Jul 31, 2010 at 6:10 AM, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
>>>> Hi folks,
>>>>
>>>> I have some data that form a 2x2x15 design, where the 15 level
>>>> variable is a discrete sampling of a ratio variable with clear
>>>> non-linearities (see bottom for a dput() of the means). I came across
>>>> gamm4 tonight and it looks like it will help tackle this data, but I'm
>>>> not sure how to tell it to let the smooth of the 15 level variable
>>>> vary as a function of BOTH of the other predictor variables. As a
>>>> hack, I created a dummy 4 level variable that represented the
>>>> combination of the 2x2 level variables, but I'm not positive that this
>>>> was the right thing to do. Any feedback would be greatly appreciated.
>>>> Here's how I had things set up:
>>>>
>>>>> str(ab)
>>>> 'data.frame': ? 49668 obs. of ?5 variables:
>>>> ?$ id ? ? ? : Factor w/ 20 levels "5","6","7","8",..: 1 1 1 1 1 1 1 1 1 1 ...
>>>> ?$ design ? : Factor w/ 2 levels "CD","NCD": 1 1 1 1 1 1 1 1 1 1 ...
>>>> ?$ ddB ? ? ?: Factor w/ 2 levels "0ddB","+ddB": 1 1 1 1 1 1 1 1 1 1 ...
>>>> ?$ soa ? ? ?: num ?300 300 300 300 300 300 300 300 300 300 ...
>>>> ?$ rt ? ? ? : num ?441 373 440 290 221 ...
>>>> ?$ g ? ? ? ?: Factor w/ 4 levels "+ddB CD","+ddB NCD",..: 3 3 3 3 3 3
>>>> 3 3 3 3 ...
>>>>
>>>> #id is the random effect (human participants)
>>>> #design and ddB are 2-level fixed effects
>>>> #soa is a 15 level fixed effect
>>>> #rt is the data to predict (there are dozens of observations for each
>>>> combination of the random and fixed effects)
>>>>
>>>> #fit using dummy variable "g" to get different soa smooths per
>>>> combination of ddB and design
>>>> fit = gamm4(
>>>> ? ? ? ?data = ab
>>>> ? ? ? ?, formula = rrt ~ ddB*design+s(soa,by=g)
>>>> ? ? ? ?, random = ~ (1|id)
>>>> ? ? ? ?, family = 'gaussian'
>>>> )
>>>>
>>>>
>>>> #here's dput() ouput of the 2x2x15 means, revealing that soa is
>>>> clearly non-linear
>>>>> dput(means)
>>>> structure(list(ddB = structure(c(1L, 2L, 1L, 2L, 1L, 2L, 1L,
>>>> 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>>>> 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>>>> 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>>>> 2L, 1L, 2L, 1L, 2L), .Label = c("0ddB", "+ddB"), class = "factor"),
>>>> ? ?design = structure(c(1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L,
>>>> ? ?1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L,
>>>> ? ?1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L,
>>>> ? ?2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L,
>>>> ? ?2L, 2L, 1L, 1L, 2L, 2L), .Label = c("CD", "NCD"), class = "factor"),
>>>> ? ?soa = c(-175, -175, -175, -175, -125, -125, -125, -125, -75,
>>>> ? ?-75, -75, -75, -25, -25, -25, -25, 25, 25, 25, 25, 75, 75,
>>>> ? ?75, 75, 125, 125, 125, 125, 175, 175, 175, 175, 250, 250,
>>>> ? ?250, 250, 350, 350, 350, 350, 450, 450, 450, 450, 550, 550,
>>>> ? ?550, 550, 700, 700, 700, 700, 900, 900, 900, 900, 1100, 1100,
>>>> ? ?1100, 1100), rt = structure(c(444.93273739708, 441.513208123373,
>>>> ? ?471.546335977687, 472.283526755609, 444.056771928409, 442.461563636396,
>>>> ? ?472.166623352385, 474.462330421383, 445.513188139913, 444.966221088285,
>>>> ? ?475.669898472348, 461.315736508479, 442.982086750377, 435.355068015326,
>>>> ? ?458.89264807265, 455.638816561315, 434.340063293089, 415.709247937572,
>>>> ? ?450.359216604288, 438.114012378908, 420.982354512772, 404.811090521404,
>>>> ? ?442.721222728774, 430.421981079446, 406.373845346035, 393.411137886923,
>>>> ? ?439.687373941982, 427.611295261772, 398.185439780545, 384.007719475387,
>>>> ? ?429.451304040456, 431.531830923294, 390.486982286177, 380.880066145206,
>>>> ? ?431.287499227013, 435.926925139256, 382.937376664574, 382.020452210116,
>>>> ? ?439.606939778423, 441.751714989440, 384.546631449636, 385.477927260379,
>>>> ? ?440.7286749068, 442.790235121405, 387.589278670798, 386.68589658312,
>>>> ? ?440.384534575679, 440.376618739428, 392.649929780933, 392.496542853778,
>>>> ? ?442.673509587221, 446.148838198613, 401.042352162140, 394.475542684099,
>>>> ? ?441.072702415870, 440.157897723193, 406.059905100442, 398.292572833949,
>>>> ? ?443.899793077701, 445.715779415161), .Dim = c(60L, 1L), .Dimnames = list(
>>>> ? ? ? ?NULL, NULL))), .Names = c("ddB", "design", "soa", "rt"
>>>> ), row.names = c(NA, 60L), class = "data.frame")
>>>>
>>>> #visualise the means
>>>> library(ggplot2)
>>>> ggplot(
>>>> ? ? ? ?data = means
>>>> ? ? ? ?, mapping = aes(
>>>> ? ? ? ? ? ? ? ?x = soa
>>>> ? ? ? ? ? ? ? ?, y = rt
>>>> ? ? ? ? ? ? ? ?, colour = design
>>>> ? ? ? ? ? ? ? ?, linetype = ddB
>>>> ? ? ? ?)
>>>> )+
>>>> geom_line()+
>>>> geom_point(shape=21,fill='white')
>>>>
>>>> --
>>>> Mike Lawrence
>>>> Graduate Student
>>>> Department of Psychology
>>>> Dalhousie University
>>>>
>>>> Looking to arrange a meeting? Check my public calendar:
>>>> http://tr.im/mikes_public_calendar
>>>>
>>>> ~ Certainty is folly... I think. ~
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
> Mike Lawrence
> Graduate Student
> Department of Psychology
> Dalhousie University
>
> Looking to arrange a meeting? Check my public calendar:
> http://tr.im/mikes_public_calendar
>
> ~ Certainty is folly... I think. ~
>



From j.hadfield at ed.ac.uk  Sun Aug  1 10:53:01 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sun, 01 Aug 2010 09:53:01 +0100
Subject: [R-sig-ME] What to do when a subset of binomial data has
	only	positive outcomes
In-Reply-To: <AANLkTikkjhrn5dmLBi+=iytme9RaJAcEGEAJ0Ka=yuH=@mail.gmail.com>
References: <AANLkTikkjhrn5dmLBi+=iytme9RaJAcEGEAJ0Ka=yuH=@mail.gmail.com>
Message-ID: <20100801095301.u4yqjkv2kg4cgc4o@www.staffmail.ed.ac.uk>

Hi,

You can fit (crossed) random effects in MCMCglmm using the random  
argument (random=~subject+word for your model).  A good prior for  
complete separation with random effects is a little more involved  
though, and I'm not completely sure what is the best approach. In the  
example I sent before the only random effects were the residuals which  
had known variance (1). Having a flatish prior on the probability  
scale after marginalising the residuals was quite easy as it just  
involved adding 1 to pi^2/3 (for the logit link) or adding 1 to 1  
(probit link). With additional random effects you may want to have a  
prior that is also flat after marginalisation. This would involve  
replacing 1 with the sum of all variance components. Of course you  
don't know this a priori (you're trying to estimate it) which creates  
a problem. However, you can probably make a sensible guess and see how  
sensitive you're conclusions would be to alternative prior  
specifications.

Cheers,

Jarrod


Quoting Xiao He <praguewatermelon at gmail.com>:

> Hi Jarrod,
>
> Thanks for the suggestion. But as I wrote in my previous reply, one issue
> with the several alternative models that I've found or that have been
> suggested to me is that they don't take random effects, and I have to
> include these effects due to the nature of my experiment. It would be great
> if you knew any alternative methods that could take random effects.
>
> I found an alternative solution that relies on likelihood-ratio test, in
> this link: http://www.mail-archive.com/r-lang at ling.ucsd.edu/msg00115.html .
> Based on the proposed solution, since compoundType has 3 levels, a new
> predictor "compoundType1" will be created by combining the offending level
> "green" (the one with no variance) with another level, as shown below:.
>
> e.g. >compound$compoundType1<-ifelse(compound$compoundType == "green,"
> "greenANDred", ifelse(
> ompound$compoundType == "red," "greenANDred", "blue")).
>
> This will result in two factors: blue, greenANDred
>
> Then, I will run the following model comparison:
> ***************************************************
>> native.lmer = lmer (word1 ~ compoundType + (1 | subject) + (1|word), data
> = compound, family = "binomial",REML=F)
>> native2.lmer = lmer (word1 ~ compoundType1 + (1 | subject) + (1|word),
> data = compound, family = "binomial",REML=F)
>
>
>> anova(deacc.lmer,deacc.lmer1)
>
> ****************************************************
>
> But I don't really know the underlying logic of this method, so I don't know
> how to explain the results obtained from this kind of method. What does it
> mean if I obtained significant difference between the two models? What does
> it mean if no significance was detected?
>
> An explanation of this method would be much appreciated! Thanks!
>
> _____________________________________
> Message: 2
> Date: Sat, 31 Jul 2010 14:22:19 +0100
> From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
> To: Ben Bolker <bbolker at gmail.com>
> Cc: Timothy_Handley at nps.gov, r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] What to do when a subset of binomial data has
>        only    positive outcomes
> Message-ID: <20100731142219.dsk04v6o00w8gw8g at www.staffmail.ed.ac.uk>
> Content-Type: text/plain;       charset=UTF-8;  DelSp="Yes";
>  format="flowed"
>
> You may want to take a look at A WEAKLY INFORMATIVE DEFAULT PRIOR
> DISTRIBUTION FOR LOGISTIC AND OTHER REGRESSION MODELS Gelman et. al.
> 2008 The annals of applied statistics 2 pp1360-1383 which you will
> need to implement in BUGS or JAGS. However, an easier route may be to
> to use normal priors on the coefficients and use MCMCglmm. In many
> cases I think this prior specification has good properties. For example:
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From nuala.brady at ucd.ie  Sun Aug  1 11:01:15 2010
From: nuala.brady at ucd.ie (nuala brady)
Date: Sun, 01 Aug 2010 10:01:15 +0100
Subject: [R-sig-ME] help in coding random effects in lmer
In-Reply-To: <AANLkTimnNxreGuVWEWMuqRJhyuAuKrXtz6PhL6HH41w0@mail.gmail.com>
References: <73409e642cb2.4c5419f9@ucd.ie>
	<AANLkTimnNxreGuVWEWMuqRJhyuAuKrXtz6PhL6HH41w0@mail.gmail.com>
Message-ID: <73d0b42c7061.4c5545eb@ucd.ie>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100801/09678c60/attachment.pl>

From Mike.Lawrence at dal.ca  Sun Aug  1 15:23:26 2010
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Sun, 1 Aug 2010 10:23:26 -0300
Subject: [R-sig-ME] help in coding random effects in lmer
In-Reply-To: <AANLkTimnNxreGuVWEWMuqRJhyuAuKrXtz6PhL6HH41w0@mail.gmail.com>
References: <73409e642cb2.4c5419f9@ucd.ie>
	<AANLkTimnNxreGuVWEWMuqRJhyuAuKrXtz6PhL6HH41w0@mail.gmail.com>
Message-ID: <AANLkTinZ9MbLvpFo8rfQ8smSuS=WrXSPqMVhhGW_We3H@mail.gmail.com>

Oh, another benefit of including trial-by-trial data is that you can
increase the signal-to-noise ratio for the effects of interest by
covarying out temporal/sequential effects that typically are of less
interest; for example, response hand, time since last response (if
targets are temporally uncertain), etc. You can also quantify things
are are indeed of interest but that may not have been possible to
measure in traditional anova: I like to add block-number and
trial-number-within-block to look at  the effects of practice and
fatigue, respectively (you could even let block/trial interact with
the other effects of interest to see if/how those effects are affected
by practice & fatigue). Lately I've been exploring adding the previous
trial's RT as a covariate; if you ever look at the correlation between
current and previous trial RT, it's typically quite large and likely
driven by things like vigilance cycles that may not be of interest. On
this theme, a colleague mentioned an alternative approach he's seen
folks adopt whereby you first do a PCA that includes several trials
back of RTs, then include the first component as a covariate in the
mixed model; I'm still not sure what this achieves over-and-above the
more straightforward case of simply using the previous trial's RT, but
it certainly sounds sexy :Op

Mike

On Sat, Jul 31, 2010 at 10:07 PM, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
> I'm still learning mixed effects modelling myself, but one thing pops
> out at me: In your formulae, you have the variable "meanRT"; I presume
> this reflects the fact that you aggregated your data to means within
> conditions prior to submitting it to lmer? If so, you have done
> yourself a disservice; lmer can analyze the raw, trial-by-trial data
> and you'll find that you can achieve higher power by providing it will
> all the data. Now, a problem arises whereby RT data are ?typically
> positively skewed and violate the normality assumption; I feel there
> is still a gap in the literature on how to deal with this (because
> there are plenty of examples where this skew has been found to be
> affected by experimental manipulations differentially from central
> tendency), but a reciprocal transform at least seems to do well at
> normalizing the residuals (Kliegl, Masson & Richter, 2009, compare
> various transforms).
>
> So, where "a" is your trial-by-trial data, I suggest you try:
> a$rrt = 1/a$rt
> fit1 = lmer(
> ? ?formula = rrt ~ (angle+laterality+condition:laterality)+(1|subject)
> ? ?, data = a
> )
>
> and let us know if you still get wonky results.
>
> As a side note, l *think* that the difference between the two models
> you posted was that the second permitted the effects to vary Ss-by-Ss,
> which may be plausible but I assume costs power. As I understand it,
> unless you are really interested in individual differences in the
> effect (eg. for correlations, etc), it's better to avoid letting
> effects vary Ss-by-Ss. (Again, I'm still getting to grips with mixed
> effects modelling, so I may be entirely incorrect on these points!).
>
> On Sat, Jul 31, 2010 at 8:41 AM, nuala brady <nuala.brady at ucd.ie> wrote:
>> Dear lmer?people & Dr Bates
>>
>> ?I ?am a cognitive psychologist who needs to leave the ?world of ANOVA?and move to lmer. I am looking for advice on coding ?random effects in lmer.
>>
>> ??My experiment is: 30 subjects judge the laterality?of a hand (i.e.. say whether it is a left or right hand) presented onscreen?which varies in its
>> ?(A) Laterality?(2 levels, right/left) and
>> ?(B) Orientation (8 levels, 0 to 315 degs?in steps of 45 degs) while holding their own hands in one of 3 postures
>> ?(C) Postures (3 levels, coded as both, minusRight?& minusLeft).
>>
>> ?The dependent variable is reaction time (RT).
>>
>> ?Laterality, Orientation & Posture are fixed effects (all ?coded as categorical variables), the random effects come from the ?subjects i.e.,
>> ?all 30 subjects respond in all possible combinations of the ?experimental variables and we need to generalise from them to the ?population ...
>>
>> ?My expectation (based on theory & previous studies) is that there will be a sig. main effect of angle, of laterality?& possibly a condition by laterality?interaction;
>> ?and graphing shows this.
>>
>> ?The traditional way to analyse such data ?in psychology, where we typically look at all main effects & possible ?interactions as a first pass,? is via a repeated measures
>> ?(or within-subjects) ANOVA?and the ?code in R is
>>
>> ?aov(RT~Laterality*Angle*Posture+Error(subject/(Laterality*Angle*Posture)),data=RTdata)
>>
>> ?moving to lmer, simplifying the model to just look at effects I am interested in, and specifying the random effects as shown in many examples online as follows:
>>
>> ?model2a<-lmer(meanRT~(angle+laterality+condition:laterality)+(1|subject),data=RTdata)
>>
>> ?I receive the output shown below as OUTPUT 1. Looking at the table of fixed effects I note that the Std. Err. within a specific explanatory variable (e.g, Angle) is constant across all levels of that variable. Obviously I am on the wrong track as this is not an assumption I want to? make. One of the reasons I am moving from ANOVA?to lmer?is because variance is not constant across the levels of some factors (both angle & laterality) as seen from graph, by running levene's?test etc
>>
>> ?Rerunning as:
>> ?model2<-lmer(meanRT~(angle+laterality+condition:laterality)+(angle|subject)+(laterality|subject)+(condition:laterality|subject),data=RTdata)
>>
>> ?(...and?quite honestly, I am generalizing here from how one might specify error in aov....)
>>
>> ?I receive the output shown below as OUTPUT 2. Scrolling?down to the fixed effects, the Std., Errs are looking a lot better to me, BUT I am unsure whether I am using the
>> ?syntax?correctly
>>
>>
>> ?can anyone advise?? I ?appreciate this may be a very basic question, but I have not found many ?examples in my reading except for nested designs (which do not apply here, as least in my understanding of 'nested designs' ), and crossed random effects (which seem more complex than I need, having more than 1 source of random effects)
>>
>> ?thanks in advance, - Nuala
>>
>> ?ps - in case the description of the experiment is not clear, I copy data for s1 (aine) at the very end of the email - this pattern will repeat for s2 to s30
>>
>> ?OUTPUT 1: summary(model2a)
>> ?Linear mixed model fit by REML
>> ?Formula: meanRT ~ (angle + laterality + condition:laterality) + (1 | subject)
>> ??? Data: data
>> ??? AIC?? BIC logLik deviance REMLdev
>> ??20620 20699 -10295??? 20700?? 20590
>> ?Random effects:
>> ??Groups?? Name??????? Variance Std.Dev.
>> ??subject? (Intercept) 124335?? 352.61
>> ??Residual????????????? 94809?? 307.91
>> ?Number of obs: 1440, groups: subject, 30
>>
>> ?Fixed effects:
>> ???????????????????????????????????? Estimate Std. Error t value
>> ?(Intercept)????????????????????????? 1218.82????? 70.70? 17.240
>> ?angle45??????????????????????????????? 13.49????? 32.46?? 0.416
>> ?angle90?????????????????????????????? 217.20????? 32.46?? 6.692
>> ?angle135????????????????????????????? 499.11????? 32.46? 15.378
>> ?angle180????????????????????????????? 961.80????? 32.46? 29.633
>> ?angle225????????????????????????????? 471.60????? 32.46? 14.530
>> ?angle270????????????????????????????? 228.82????? 32.46?? 7.050
>> ?angle315?????????????????????????????? 62.12????? 32.46?? 1.914
>> ?lateralityright????????????????????? -122.60????? 28.11? -4.362
>> ?lateralityleft:conditionminusLeft????? 14.23????? 28.11?? 0.506
>> ?lateralityright:conditionminusLeft??? -27.28????? 28.11? -0.971
>> ?lateralityleft:conditionminusRight??? -33.77????? 28.11? -1.201
>> ?lateralityright:conditionminusRight??? 35.94????? 28.11?? 1.279
>>
>>
>> ?OUTPUT 2: summary(model2)
>> ? Linear mixed model fit by REML
>> ?Formula: meanRT ~ (angle + laterality + condition:laterality) + (angle | subject) + (laterality | subject) + (condition:laterality |subject)
>> ??? Data: data
>> ??? AIC?? BIC logLik deviance REMLdev
>> ??19918 20345? -9878??? 19867?? 19756
>> ?Random effects:
>> ??Groups?? Name??????????????????????????????? Variance?? Std.Dev.?? Corr
>> ??subject? (Intercept)???????????????????????? 3.5601e+04 188.681267
>> ?????????? angle45???????????????????????????? 3.5488e+01?? 5.957191? 1.000
>> ?????????? angle90???????????????????????????? 1.9515e+04 139.697353? 1.000
>> ?????????? angle135??????????????????????????? 7.8349e+04 279.909544? 0.704
>> ?????????? angle180??????????????????????????? 3.3373e+05 577.689525? 0.390
>> ?????????? angle225??????????????????????????? 7.1096e+04 266.638569? 0.462
>> ?????????? angle270??????????????????????????? 1.7412e+04 131.954987? 0.695
>> ?????????? angle315??????????????????????????? 7.1155e+03? 84.353226? 0.759
>> ??subject? (Intercept)???????????????????????? 2.5444e-04?? 0.015951
>> ?????????? lateralityright???????????????????? 5.2171e-05?? 0.007223 -1.000
>> ??subject? (Intercept)???????????????????????? 1.4016e+04 118.388702
>> ?????????? conditionboth:lateralityleft??????? 1.2554e+04 112.046691? 0.327
>> ?????????? conditionminusLeft:lateralityleft?? 3.0653e+04 175.080964? 0.257
>> ?????????? conditionminusRight:lateralityleft? 1.6837e+04 129.758438 -0.019
>> ?????????? conditionboth:lateralityright?????? 1.0627e+04 103.089657 -0.340
>> ?????????? conditionminusLeft:lateralityright? 9.6021e+03? 97.990531 -0.822
>> ?????????? conditionminusRight:lateralityright 1.0345e+04 101.711720 -0.453
>> ??Residual???????????????????????????????????? 4.2251e+04 205.549629
>>
>>
>>
>> ?? 1.000
>> ?? 0.704? 0.704
>> ?? 0.390? 0.390? 0.847
>> ?? 0.462? 0.462? 0.837? 0.889
>> ?? 0.695? 0.695? 0.711? 0.609? 0.867
>> ?? 0.759? 0.759? 0.324 -0.042? 0.021? 0.317
>>
>>
>>
>>
>> ?? 0.424
>> ?? 0.196? 0.569
>> ?? 0.428 -0.431 -0.555
>> ??-0.112 -0.364 -0.475? 0.730
>> ??-0.451 -0.211? 0.622 -0.400 -0.094
>>
>> ?Number of obs: 1440, groups: subject, 30
>>
>> ?Fixed effects:
>> ???????????????????????????????????? Estimate Std. Error t value
>> ?(Intercept)????????????????????????? 1218.82????? 52.37? 23.273
>> ?angle45??????????????????????????????? 13.49????? 21.69?? 0.622
>> ?angle90?????????????????????????????? 217.20????? 33.47?? 6.490
>> ?angle135????????????????????????????? 499.11????? 55.51?? 8.992
>> ?angle180????????????????????????????? 961.80???? 107.67?? 8.933
>> ?angle225????????????????????????????? 471.60????? 53.29?? 8.850
>> ?angle270????????????????????????????? 228.82????? 32.40?? 7.062
>> ?angle315?????????????????????????????? 62.12????? 26.58?? 2.337
>> ?lateralityright????????????????????? -122.60????? 28.20? -4.348
>> ?lateralityleft:conditionminusLeft????? 14.23????? 35.18?? 0.404
>> ?lateralityright:conditionminusLeft??? -27.28????? 23.13? -1.180
>> ?lateralityleft:conditionminusRight??? -33.77????? 33.79? -0.999
>> ?lateralityright:conditionminusRight??? 35.94????? 36.48?? 0.985
>>
>>
>> ?Example data for 1 subject
>> ?data[1:48,1:5] - RT is actially mean RT of 18 trails
>> ??? subject laterality? posture angle??? RT
>> ?1???? aine?????? left?????? both???? 0? 844.8000
>> ?2???? aine?????? left?????? both??? 45? 796.4706
>> ?3???? aine?????? left?????? both??? 90 1007.5722
>> ?4???? aine?????? left?????? both?? 135 1214.7556
>> ?5???? aine?????? left?????? both?? 180 1249.9625
>> ?6???? aine?????? left?????? both?? 225 1305.0500
>> ?7???? aine?????? left?????? both?? 270 1043.8000
>> ?8???? aine?????? left?????? both?? 315? 814.6833
>> ?9???? aine?????? left? minusLeft???? 0? 817.3778
>> ?10??? aine?????? left? minusLeft??? 45? 951.0588
>> ?11??? aine?????? left? minusLeft??? 90 1044.5706
>> ?12??? aine?????? left? minusLeft?? 135 1345.5625
>> ?13??? aine?????? left? minusLeft?? 180 1482.8333
>> ?14??? aine?????? left? minusLeft?? 225 1331.3588
>> ?15??? aine?????? left? minusLeft?? 270? 985.1000
>> ?16??? aine?????? left? minusLeft?? 315? 995.2563
>> ?17??? aine?????? left minusRight???? 0? 986.8556
>> ?18??? aine?????? left minusRight??? 45? 903.2176
>> ?19??? aine?????? left minusRight??? 90? 947.8059
>> ?20??? aine?????? left minusRight?? 135 1453.8750
>> ?21??? aine?????? left minusRight?? 180 1698.8278
>> ?22??? aine?????? left minusRight?? 225 1337.1200
>> ?23??? aine?????? left minusRight?? 270 1109.2467
>> ?24??? aine?????? left minusRight?? 315? 929.0412
>> ?25??? aine????? right?????? both???? 0? 913.5944
>> ?26??? aine????? right?????? both??? 45? 930.5056
>> ?27??? aine????? right?????? both??? 90 1093.9167
>> ?28??? aine????? right?????? both?? 135 1275.9647
>> ?29??? aine????? right?????? both?? 180 1489.1750
>> ?30??? aine????? right?????? both?? 225 1188.1333
>> ?31??? aine????? right?????? both?? 270 1054.7778
>> ?32??? aine????? right?????? both?? 315? 904.8722
>> ?33??? aine????? right? minusLeft???? 0? 888.9375
>> ?34??? aine????? right? minusLeft??? 45? 915.0706
>> ?35??? aine????? right? minusLeft??? 90 1060.3167
>> ?36??? aine????? right? minusLeft?? 135 1240.0867
>> ?37??? aine????? right? minusLeft?? 180 1772.4611
>> ?38??? aine????? right? minusLeft?? 225 1168.5625
>> ?39??? aine????? right? minusLeft?? 270 1093.1889
>> ?40??? aine????? right? minusLeft?? 315? 842.2667
>> ?41??? aine????? right minusRight???? 0? 971.3944
>> ?42??? aine????? right minusRight??? 45? 974.3333
>> ?43??? aine????? right minusRight??? 90 1064.9833
>> ?44??? aine????? right minusRight?? 135 1389.0059
>> ?45??? aine????? right minusRight?? 180 1575.9000
>> ?46??? aine????? right minusRight?? 225 1322.6444
>> ?47??? aine????? right minusRight?? 270 1053.7389
>> ?48??? aine????? right minusRight?? 315 1077.0529
>>
>>
>> ?Nuala Brady
>> ?School of Psychology
>> ?University College Dublin
>> ?Belfield, D4
>> ?IRELAND
>>
>> ?+353 (0)1 716 8247
>> ?nuala.brady at ucd.ie
>>
>>
>>
>> ? ? ? ?[[alternative HTML version deleted]]
>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
>
>
> --
> Mike Lawrence
> Graduate Student
> Department of Psychology
> Dalhousie University
>
> Looking to arrange a meeting? Check my public calendar:
> http://tr.im/mikes_public_calendar
>
> ~ Certainty is folly... I think. ~
>



-- 
Mike Lawrence
Graduate Student
Department of Psychology
Dalhousie University

Looking to arrange a meeting? Check my public calendar:
http://tr.im/mikes_public_calendar

~ Certainty is folly... I think. ~



From cm744 at st-andrews.ac.uk  Sun Aug  1 16:57:16 2010
From: cm744 at st-andrews.ac.uk (Chris Mcowen)
Date: Sun, 1 Aug 2010 15:57:16 +0100
Subject: [R-sig-ME] Overdispersion lme4 binomial
Message-ID: <7AE367D9-B6BB-4D27-9B7B-834B1F35E282@st-andrews.ac.uk>

Dear List,

I am wanting to test for overdispersion in my model and am unsure how for my specific case.

I have 2 random factors, 7 fixed factors that have multiple levels and are categorical and then i have a binary response (True or False).

model1 <- lmer(threattf~1+(1|order/family) + geophyte + seasonality + pollendispersal + breedingsystem*fruit + habit + lifeform + woodyness, family=binomial)

I would be very grateful if somebody could point me in the right direction for testing for overdispersion under such scenarios?

Please see part of the output below -

Thanks for any help, and if more data is required feel free to ask.

Chris

Generalized linear mixed model fit by the Laplace approximation 
Formula: threattf ~ 1 + (1 | order/family) + geophyte + seasonality +      pollendispersal + breedingsystem * fruit + habit + lifeform +      woodyness 
  AIC  BIC logLik deviance
 1562 1649 -764.2     1528
Random effects:
 Groups       Name        Variance Std.Dev.
 family:order (Intercept) 0.26932  0.51896 
 order        (Intercept) 0.00000  0.00000 
Number of obs: 1242, groups: family:order, 43; order, 9

Fixed effects:
                       Estimate Std. Error z value Pr(>|z|)   
(Intercept)            -0.10413    0.98004  -0.106  0.91538 


From j.hadfield at ed.ac.uk  Sun Aug  1 17:11:06 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sun, 01 Aug 2010 16:11:06 +0100
Subject: [R-sig-ME] Overdispersion lme4 binomial
In-Reply-To: <7AE367D9-B6BB-4D27-9B7B-834B1F35E282@st-andrews.ac.uk>
References: <7AE367D9-B6BB-4D27-9B7B-834B1F35E282@st-andrews.ac.uk>
Message-ID: <20100801161106.5bwfd2pz284gow48@www.staffmail.ed.ac.uk>

Dear Chris,

Over-dispersion does not occur with a binary response variable so you  
don't need to test for it.

This does not mean that between-datum heterogeneity in the probability  
of success is absent, only that it cannot be observed. For example,  
take 1000 random draws from a binomial distribution with constant  
probability (0.5):

table(rbinom(1000, 1, 0.5))

and compare the frequency of outcomes with a 1000 draws from 1000  
binomial distributions with different probabilities of success (but  
with mean = 0.5)

table(rbinom(1000, 1, runif(1000)))

The data look the same, and so the between-datum heterogeneity  
(residual variance if you like) although it may exist cannot be  
estimated from the data.

Cheers,

Jarrod


Quoting Chris Mcowen <cm744 at st-andrews.ac.uk>:

> Dear List,
>
> I am wanting to test for overdispersion in my model and am unsure   
> how for my specific case.
>
> I have 2 random factors, 7 fixed factors that have multiple levels   
> and are categorical and then i have a binary response (True or False).
>
> model1 <- lmer(threattf~1+(1|order/family) + geophyte + seasonality   
> + pollendispersal + breedingsystem*fruit + habit + lifeform +   
> woodyness, family=binomial)
>
> I would be very grateful if somebody could point me in the right   
> direction for testing for overdispersion under such scenarios?
>
> Please see part of the output below -
>
> Thanks for any help, and if more data is required feel free to ask.
>
> Chris
>
> Generalized linear mixed model fit by the Laplace approximation
> Formula: threattf ~ 1 + (1 | order/family) + geophyte + seasonality   
> +      pollendispersal + breedingsystem * fruit + habit + lifeform +  
>       woodyness
>   AIC  BIC logLik deviance
>  1562 1649 -764.2     1528
> Random effects:
>  Groups       Name        Variance Std.Dev.
>  family:order (Intercept) 0.26932  0.51896
>  order        (Intercept) 0.00000  0.00000
> Number of obs: 1242, groups: family:order, 43; order, 9
>
> Fixed effects:
>                        Estimate Std. Error z value Pr(>|z|)
> (Intercept)            -0.10413    0.98004  -0.106  0.91538
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From cm744 at st-andrews.ac.uk  Sun Aug  1 17:36:58 2010
From: cm744 at st-andrews.ac.uk (Chris Mcowen)
Date: Sun, 1 Aug 2010 16:36:58 +0100
Subject: [R-sig-ME] RE Overdispersion lme4 binomial
References: <F6C1E6E0-28E9-4C96-BF49-B2A15AFB034E@st-andrews.ac.uk>
Message-ID: <ACA84BE8-E65A-4FF3-AEEA-C75AB6A803D6@st-andrews.ac.uk>

Hi Jarrord,

Thanks very much for this - i am relatively new to modelling! I am trying to check the goodness of fit of my model before i use it as a predictive model.

I plotted the residuals(see attached) and they looked odd, so i was a little unsure why and thought i would run through a few possibilities. Using a binary response variable what post model checks are appropriate?

Thanks

> plot(resid(model1))

Chris

On 1 Aug 2010, at 16:11, Jarrod Hadfield wrote:

Dear Chris,

Over-dispersion does not occur with a binary response variable so you don't need to test for it.

This does not mean that between-datum heterogeneity in the probability of success is absent, only that it cannot be observed. For example, take 1000 random draws from a binomial distribution with constant probability (0.5):

table(rbinom(1000, 1, 0.5))

and compare the frequency of outcomes with a 1000 draws from 1000 binomial distributions with different probabilities of success (but with mean = 0.5)

table(rbinom(1000, 1, runif(1000)))

The data look the same, and so the between-datum heterogeneity (residual variance if you like) although it may exist cannot be estimated from the data.

Cheers,

Jarrod


Quoting Chris Mcowen <cm744 at st-andrews.ac.uk>:

> Dear List,
> 
> I am wanting to test for overdispersion in my model and am unsure  how for my specific case.
> 
> I have 2 random factors, 7 fixed factors that have multiple levels  and are categorical and then i have a binary response (True or False).
> 
> model1 <- lmer(threattf~1+(1|order/family) + geophyte + seasonality  + pollendispersal + breedingsystem*fruit + habit + lifeform +  woodyness, family=binomial)
> 
> I would be very grateful if somebody could point me in the right  direction for testing for overdispersion under such scenarios?
> 
> Please see part of the output below -
> 
> Thanks for any help, and if more data is required feel free to ask.
> 
> Chris
> 
> Generalized linear mixed model fit by the Laplace approximation
> Formula: threattf ~ 1 + (1 | order/family) + geophyte + seasonality  +      pollendispersal + breedingsystem * fruit + habit + lifeform +       woodyness
> AIC  BIC logLik deviance
> 1562 1649 -764.2     1528
> Random effects:
> Groups       Name        Variance Std.Dev.
> family:order (Intercept) 0.26932  0.51896
> order        (Intercept) 0.00000  0.00000
> Number of obs: 1242, groups: family:order, 43; order, 9
> 
> Fixed effects:
>                      Estimate Std. Error z value Pr(>|z|)
> (Intercept)            -0.10413    0.98004  -0.106  0.91538
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From cm744 at st-andrews.ac.uk  Sun Aug  1 17:40:31 2010
From: cm744 at st-andrews.ac.uk (Chris Mcowen)
Date: Sun, 1 Aug 2010 16:40:31 +0100
Subject: [R-sig-ME] RE Overdispersion lme4 binomial
In-Reply-To: <ACA84BE8-E65A-4FF3-AEEA-C75AB6A803D6@st-andrews.ac.uk>
References: <F6C1E6E0-28E9-4C96-BF49-B2A15AFB034E@st-andrews.ac.uk>
	<ACA84BE8-E65A-4FF3-AEEA-C75AB6A803D6@st-andrews.ac.uk>
Message-ID: <4C932A8A-5E96-4628-AE69-0793B754B8D0@st-andrews.ac.uk>

Sorry for some reason the residual plot did not attach -

-------------- next part --------------

On 1 Aug 2010, at 16:36, Chris Mcowen wrote:

Hi Jarrord,

Thanks very much for this - i am relatively new to modelling! I am trying to check the goodness of fit of my model before i use it as a predictive model.

I plotted the residuals(see attached) and they looked odd, so i was a little unsure why and thought i would run through a few possibilities. Using a binary response variable what post model checks are appropriate?

Thanks

> plot(resid(model1))

Chris

On 1 Aug 2010, at 16:11, Jarrod Hadfield wrote:

Dear Chris,

Over-dispersion does not occur with a binary response variable so you don't need to test for it.

This does not mean that between-datum heterogeneity in the probability of success is absent, only that it cannot be observed. For example, take 1000 random draws from a binomial distribution with constant probability (0.5):

table(rbinom(1000, 1, 0.5))

and compare the frequency of outcomes with a 1000 draws from 1000 binomial distributions with different probabilities of success (but with mean = 0.5)

table(rbinom(1000, 1, runif(1000)))

The data look the same, and so the between-datum heterogeneity (residual variance if you like) although it may exist cannot be estimated from the data.

Cheers,

Jarrod


Quoting Chris Mcowen <cm744 at st-andrews.ac.uk>:

> Dear List,
> 
> I am wanting to test for overdispersion in my model and am unsure  how for my specific case.
> 
> I have 2 random factors, 7 fixed factors that have multiple levels  and are categorical and then i have a binary response (True or False).
> 
> model1 <- lmer(threattf~1+(1|order/family) + geophyte + seasonality  + pollendispersal + breedingsystem*fruit + habit + lifeform +  woodyness, family=binomial)
> 
> I would be very grateful if somebody could point me in the right  direction for testing for overdispersion under such scenarios?
> 
> Please see part of the output below -
> 
> Thanks for any help, and if more data is required feel free to ask.
> 
> Chris
> 
> Generalized linear mixed model fit by the Laplace approximation
> Formula: threattf ~ 1 + (1 | order/family) + geophyte + seasonality  +      pollendispersal + breedingsystem * fruit + habit + lifeform +       woodyness
> AIC  BIC logLik deviance
> 1562 1649 -764.2     1528
> Random effects:
> Groups       Name        Variance Std.Dev.
> family:order (Intercept) 0.26932  0.51896
> order        (Intercept) 0.00000  0.00000
> Number of obs: 1242, groups: family:order, 43; order, 9
> 
> Fixed effects:
>                     Estimate Std. Error z value Pr(>|z|)
> (Intercept)            -0.10413    0.98004  -0.106  0.91538
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From rafael.laboissiere at inserm.fr  Mon Aug  2 00:27:55 2010
From: rafael.laboissiere at inserm.fr (Rafael Laboissiere)
Date: Mon, 2 Aug 2010 00:27:55 +0200
Subject: [R-sig-ME] Interpretation of lmer's sigma for binomial data
Message-ID: <20100801222755.GG22370@pc049-u864.lyon.inserm.fr>

Dear colleagues,

First of all, I apologize if this is not the appropriate forum for my
question.

I am trying to understand the meaning of the sigma slot in the
summary.mer class of the lme4 package (version 0.999375-34).  From what I
read in this mailing list's archive and elsewhere, sigma gives an
indication of under- or over-dispersed data.

So, I ran the following code:

    # Generate 20 repetitions of binary responses for size of 40
    # and a theoretical probability of 0.5
    repetitions <- 20
    size <- 40
    set.seed (1)
    success <- rbinom (repetitions, size, 0.5)
    
    # Compute the failure rate
    failure <- size - success

    # Add a dummy random effect variable, otherwise lmer barks
    block <- c (rep ("A", 10), rep ("B", 10))
    
    # Fit a binomial model using the actual counts
    library (lme4)
    m.binom <- lmer (cbind (success, failure) ~ 1 + (1 | block), family = binomial)

    # Fit a quasibinomial model using the proportions
    m.quasi <- lmer (success / (success + failure) ~ 1 + (1 | block), family = quasibinomial)

As expected, the value of summary(m.binom)@sigma is 1.  Since the data is
generated with rbinom and no under- or over-dispersion has been
explicitly introduced in it, I would expect that sigma for m.quasi is
also close to 1.  However, I see:

    > summary(m.quasi)@sigma
    [1] 0.07716662

I am sure I am terribly failing to understand something here.  What is
it?

Thanks in advance for your help.

Best regards,

Rafael Laboissiere



From r.turner at auckland.ac.nz  Mon Aug  2 00:38:15 2010
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 2 Aug 2010 10:38:15 +1200
Subject: [R-sig-ME] Interpretation of lmer's sigma for binomial data
In-Reply-To: <20100801222755.GG22370@pc049-u864.lyon.inserm.fr>
References: <20100801222755.GG22370@pc049-u864.lyon.inserm.fr>
Message-ID: <55B8CED5-EDD8-4D3E-B8E8-8B3A1B129236@auckland.ac.nz>


I would like to second the request for enlightenment on this issue.
In particular, how does this fit with the recent posting from Jarrod
Hadfield:

> Over-dispersion does not occur with a binary response variable so you  
> don't need to test for it.
> 
> This does not mean that between-datum heterogeneity in the probability  
> of success is absent, only that it cannot be observed. For example,  
> take 1000 random draws from a binomial distribution with constant  
> probability (0.5):
> 
> table(rbinom(1000, 1, 0.5))
> 
> and compare the frequency of outcomes with a 1000 draws from 1000  
> binomial distributions with different probabilities of success (but  
> with mean = 0.5)
> 
> table(rbinom(1000, 1, runif(1000)))
> 
> The data look the same, and so the between-datum heterogeneity  
> (residual variance if you like) although it may exist cannot be  
> estimated from the data.


Hadfield's posting makes perfectly good sense to me.  I have done
simulation experiments similar to that which he suggested, and have
found what he said I would find.  Also I did some simple theoretical
manipulations which further confirmed his assertions.

So what is the quasibinomial family ***doing***, then?

	cheers,

		Rolf Turner

On 2/08/2010, at 10:27 AM, Rafael Laboissiere wrote:

> Dear colleagues,
> 
> First of all, I apologize if this is not the appropriate forum for my
> question.
> 
> I am trying to understand the meaning of the sigma slot in the
> summary.mer class of the lme4 package (version 0.999375-34).  From what I
> read in this mailing list's archive and elsewhere, sigma gives an
> indication of under- or over-dispersed data.
> 
> So, I ran the following code:
> 
>    # Generate 20 repetitions of binary responses for size of 40
>    # and a theoretical probability of 0.5
>    repetitions <- 20
>    size <- 40
>    set.seed (1)
>    success <- rbinom (repetitions, size, 0.5)
> 
>    # Compute the failure rate
>    failure <- size - success
> 
>    # Add a dummy random effect variable, otherwise lmer barks
>    block <- c (rep ("A", 10), rep ("B", 10))
> 
>    # Fit a binomial model using the actual counts
>    library (lme4)
>    m.binom <- lmer (cbind (success, failure) ~ 1 + (1 | block), family = binomial)
> 
>    # Fit a quasibinomial model using the proportions
>    m.quasi <- lmer (success / (success + failure) ~ 1 + (1 | block), family = quasibinomial)
> 
> As expected, the value of summary(m.binom)@sigma is 1.  Since the data is
> generated with rbinom and no under- or over-dispersion has been
> explicitly introduced in it, I would expect that sigma for m.quasi is
> also close to 1.  However, I see:
> 
>> summary(m.quasi)@sigma
>    [1] 0.07716662
> 
> I am sure I am terribly failing to understand something here.  What is
> it?
> 
> Thanks in advance for your help.
> 
> Best regards,
> 
> Rafael Laboissiere
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

######################################################################
Attention: 
This e-mail message is privileged and confidential. If you are not the 
intended recipient please delete the message and notify the sender. 
Any views or opinions presented are solely those of the author.

This e-mail has been scanned and cleared by MailMarshal 
www.marshalsoftware.com
######################################################################



From davidD at qimr.edu.au  Mon Aug  2 01:44:20 2010
From: davidD at qimr.edu.au (David Duffy)
Date: Mon, 2 Aug 2010 09:44:20 +1000 (EST)
Subject: [R-sig-ME] Interpretation of lmer's sigma for binomial data
In-Reply-To: <55B8CED5-EDD8-4D3E-B8E8-8B3A1B129236@auckland.ac.nz>
References: <20100801222755.GG22370@pc049-u864.lyon.inserm.fr>
	<55B8CED5-EDD8-4D3E-B8E8-8B3A1B129236@auckland.ac.nz>
Message-ID: <Pine.LNX.4.64.1008020931320.8586@orpheus.qimr.edu.au>

On Mon, 2 Aug 2010, Rolf Turner wrote:

>
> I would like to second the request for enlightenment on this issue.
> In particular, how does this fit with the recent posting from Jarrod
> Hadfield:
>
>> Over-dispersion does not occur with a binary response variable so you
>> don't need to test for it.

> So what is the quasibinomial family ***doing***, then?

The only trouble with this differentiation of Bernoulli data from 
Binomial data is that we usually fit both types of data using the same 
model.  Which is say, dispersion problems are seen once you are 
trying to model the effects of a covariate, which is implicitly present 
for the binomial setup.

Cheers, David Duffy.
-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From Chris.Brien at unisa.edu.au  Fri Jul 30 23:38:43 2010
From: Chris.Brien at unisa.edu.au (Chris Brien)
Date: Sat, 31 Jul 2010 07:08:43 +0930
Subject: [R-sig-ME] Negative estimates of variance component
In-Reply-To: <AANLkTik+DfZSCB1RR4z0e6ca9Z=V=f9Rg5QQ67VZevOB@mail.gmail.com>
References: <EC96E350A5D6444B82CBD8DA338F017528BF1757@ITUPC-EX1MBOX.UniNet.unisa.edu.au>
	<AANLkTinCu2TznFnm2jHqBRe7hqYYV1bagdY+sybirngO@mail.gmail.com>
	<4C53002E.7090404@unil.ch>
	<AANLkTik+DfZSCB1RR4z0e6ca9Z=V=f9Rg5QQ67VZevOB@mail.gmail.com>
Message-ID: <EC96E350A5D6444B82CBD8DA338F017528BF1A94@ITUPC-EX1MBOX.UniNet.unisa.edu.au>

Dear all,

Doug, thanks for the information that negative estimates are not possible with lme4 and nlme.

As for the questions from others about why would you want to do it, there are a number of reasons.

Of course, variance components must be positive. However, one reason, given by Littel et al in  SAS for Mixed Models, to allow negative estimates is that it controls Type I error better and in certain circumstance may give better power. This is essentially related to the issue of pooling non-significant error terms. In SAS MIXED there is an option to allow negative estimates. 

Another reason is that variance components might be interpreted as components of excess variation or even excess covariance. Then negative values indicate less covariance between than within groups, as Jerome explained. However, as suggested in the "Heywood case" scenario, reasons for negative estimates need to be investigated to make sure that it really is negative covariance. As for fitting using structured covariance matrices as suggested by Ben, this is a nice way to go about it but requires that the software has this capability. Lme4 does not have it and nlme is not good at fitting crossed factors - a gotcha' situation.

A third reason is that in order to approximate a randomization analysis, one needs to allow for negative estimates. I reiterate that here I am thinking of variance components as surrogates for components of excess covariance.

So, I do not agree that it is in the category of "consistency with older method-of-moments estimates". The issue is more that there is no coherent way to specify the types of models of which I am thinking in current software packages.

Cheers,

  Chris


-----Original Message-----
From: Ben Bolker [mailto:bbolker at gmail.com] 
Sent: Friday, 30 July 2010 7:02 PM
To: jerome.goudet at unil.ch
Cc: Chris Brien; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Negative estimates of variance component

  I claim that this is in the category of "consistency with older
method-of-moments estimates" ... I know that population geneticists
still like to think in terms of variance components, but wouldn't one
ideally want to deal with the negative correlation built into the
system by estimating it more or less directly (i.e. via a structured
variance-covariance model that has nonnegative variances but could
have negative covariances) rather than by estimating a negative
variance component?

  Ben Bolker (not a population geneticist so possibly missing the point)

On Fri, Jul 30, 2010 at 12:39 PM, Jerome Goudet <jerome.goudet at unil.ch> wrote:
> Hi all,
>
> Here is an example: genes are nested in individuals, themselves nested in
> populations.? If individuals avoid mating with relatives, then the variance
> component of allele frequencies among individuals within population is
> expected to take negative values, as 2 genes taken from 2 different
> individuals are more similar than two genes taken from the same individual.
> See Weir & Cockerham (1984) Evolution for instance.
>
>
>
>
> Ben Bolker wrote:
>
>   Pardon my asking, but why? For consistency with older (arguably less
> correct) method-of-moments estimates that could give negative
> estimates?
>
> On Fri, Jul 30, 2010 at 1:32 AM, Chris Brien <Chris.Brien at unisa.edu.au>
> wrote:
>
>
> Dear mixed modellers,
>
> I have a data set that gives me an estimate of 0 for one of the variance
> components. I wanted to allow for the estimate of the component to be
> negative. My search of the documentation led me to believe that this is not
> possible. Am I right, or did I miss something?
>
> Cheers,
>
> Chris Brien
> -----
> University of South Australia
> ADELAIDE? 5001? South Australia
> WEB page:? <http://people.unisa.edu.au/Chris.Brien>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
> --
> J?r?me Goudet
> Dept. Ecology & Evolution
> UNIL-Sorge, CH-1015 Lausanne
>
> mail:jerome.goudet at unil.ch
> Tel:+41 (0)21 692 4242
> Fax:+41 (0)21 692 4265



From cm744 at st-andrews.ac.uk  Sun Aug  1 17:31:56 2010
From: cm744 at st-andrews.ac.uk (Chris Mcowen)
Date: Sun, 1 Aug 2010 16:31:56 +0100
Subject: [R-sig-ME] Overdispersion lme4 binomial
In-Reply-To: <20100801161106.5bwfd2pz284gow48@www.staffmail.ed.ac.uk>
References: <7AE367D9-B6BB-4D27-9B7B-834B1F35E282@st-andrews.ac.uk>
	<20100801161106.5bwfd2pz284gow48@www.staffmail.ed.ac.uk>
Message-ID: <F6C1E6E0-28E9-4C96-BF49-B2A15AFB034E@st-andrews.ac.uk>

Hi Jarrord,

Thanks very much for this - i am relatively new to modelling! I am trying to check the goodness of fit of my model before i use it as a predictive model.

I plotted the residuals(see attached) and they looked odd, so i was a little unsure why and thought i would run through a few possibilities. Using a binary response variable what post model checks are appropriate?

Thanks

> plot(resid(model1))

Chris
-------------- next part --------------
A non-text attachment was scrubbed...
Name: residuals.pdf
Type: application/pdf
Size: 189359 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100801/65f2cf40/attachment.pdf>
-------------- next part --------------

On 1 Aug 2010, at 16:11, Jarrod Hadfield wrote:

Dear Chris,

Over-dispersion does not occur with a binary response variable so you don't need to test for it.

This does not mean that between-datum heterogeneity in the probability of success is absent, only that it cannot be observed. For example, take 1000 random draws from a binomial distribution with constant probability (0.5):

table(rbinom(1000, 1, 0.5))

and compare the frequency of outcomes with a 1000 draws from 1000 binomial distributions with different probabilities of success (but with mean = 0.5)

table(rbinom(1000, 1, runif(1000)))

The data look the same, and so the between-datum heterogeneity (residual variance if you like) although it may exist cannot be estimated from the data.

Cheers,

Jarrod


Quoting Chris Mcowen <cm744 at st-andrews.ac.uk>:

> Dear List,
> 
> I am wanting to test for overdispersion in my model and am unsure  how for my specific case.
> 
> I have 2 random factors, 7 fixed factors that have multiple levels  and are categorical and then i have a binary response (True or False).
> 
> model1 <- lmer(threattf~1+(1|order/family) + geophyte + seasonality  + pollendispersal + breedingsystem*fruit + habit + lifeform +  woodyness, family=binomial)
> 
> I would be very grateful if somebody could point me in the right  direction for testing for overdispersion under such scenarios?
> 
> Please see part of the output below -
> 
> Thanks for any help, and if more data is required feel free to ask.
> 
> Chris
> 
> Generalized linear mixed model fit by the Laplace approximation
> Formula: threattf ~ 1 + (1 | order/family) + geophyte + seasonality  +      pollendispersal + breedingsystem * fruit + habit + lifeform +       woodyness
>  AIC  BIC logLik deviance
> 1562 1649 -764.2     1528
> Random effects:
> Groups       Name        Variance Std.Dev.
> family:order (Intercept) 0.26932  0.51896
> order        (Intercept) 0.00000  0.00000
> Number of obs: 1242, groups: family:order, 43; order, 9
> 
> Fixed effects:
>                       Estimate Std. Error z value Pr(>|z|)
> (Intercept)            -0.10413    0.98004  -0.106  0.91538
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From john.maindonald at anu.edu.au  Mon Aug  2 06:18:12 2010
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Mon, 2 Aug 2010 14:18:12 +1000
Subject: [R-sig-ME] Negative estimates of variance component
In-Reply-To: <EC96E350A5D6444B82CBD8DA338F017528BF1A94@ITUPC-EX1MBOX.UniNet.unisa.edu.au>
References: <EC96E350A5D6444B82CBD8DA338F017528BF1757@ITUPC-EX1MBOX.UniNet.unisa.edu.au>
	<AANLkTinCu2TznFnm2jHqBRe7hqYYV1bagdY+sybirngO@mail.gmail.com>
	<4C53002E.7090404@unil.ch>
	<AANLkTik+DfZSCB1RR4z0e6ca9Z=V=f9Rg5QQ67VZevOB@mail.gmail.com>
	<EC96E350A5D6444B82CBD8DA338F017528BF1A94@ITUPC-EX1MBOX.UniNet.unisa.edu.au>
Message-ID: <A7606BE4-9F4A-4E43-95A0-4C419E011C9F@anu.edu.au>

The negative estimates are really then parameters in the 
variance-covariance matrix.  (There is no escaping from 
the requirement that this matrix, however parameterised, 
should be positive definite.)  If a parameter is negative to 
an extent that excludes statistical error, it cannot then be 
interpreted as a variances, but provides an indication 
that the variance-covariance structure has been wrongly 
formulated.  This can be useful diagnostic information.

In results from a block design, it might for example result
from choosing plots in a manner that increases rather than 
decreases heterogeneity between plots.  For example, 
blocks may be chosen so that plots are at increasing 
distances from a river bank.  I have from time to time 
encountered scientists who though that a choice of this 
type (maximising heterogeneity) was the right thing to do.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 31/07/2010, at 7:38 AM, Chris Brien wrote:

> Dear all,
> 
> Doug, thanks for the information that negative estimates are not possible with lme4 and nlme.
> 
> As for the questions from others about why would you want to do it, there are a number of reasons.
> 
> Of course, variance components must be positive. However, one reason, given by Littel et al in  SAS for Mixed Models, to allow negative estimates is that it controls Type I error better and in certain circumstance may give better power. This is essentially related to the issue of pooling non-significant error terms. In SAS MIXED there is an option to allow negative estimates. 
> 
> Another reason is that variance components might be interpreted as components of excess variation or even excess covariance. Then negative values indicate less covariance between than within groups, as Jerome explained. However, as suggested in the "Heywood case" scenario, reasons for negative estimates need to be investigated to make sure that it really is negative covariance. As for fitting using structured covariance matrices as suggested by Ben, this is a nice way to go about it but requires that the software has this capability. Lme4 does not have it and nlme is not good at fitting crossed factors - a gotcha' situation.
> 
> A third reason is that in order to approximate a randomization analysis, one needs to allow for negative estimates. I reiterate that here I am thinking of variance components as surrogates for components of excess covariance.
> 
> So, I do not agree that it is in the category of "consistency with older method-of-moments estimates". The issue is more that there is no coherent way to specify the types of models of which I am thinking in current software packages.
> 
> Cheers,
> 
>  Chris
> 
> 
> -----Original Message-----
> From: Ben Bolker [mailto:bbolker at gmail.com] 
> Sent: Friday, 30 July 2010 7:02 PM
> To: jerome.goudet at unil.ch
> Cc: Chris Brien; r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Negative estimates of variance component
> 
>  I claim that this is in the category of "consistency with older
> method-of-moments estimates" ... I know that population geneticists
> still like to think in terms of variance components, but wouldn't one
> ideally want to deal with the negative correlation built into the
> system by estimating it more or less directly (i.e. via a structured
> variance-covariance model that has nonnegative variances but could
> have negative covariances) rather than by estimating a negative
> variance component?
> 
>  Ben Bolker (not a population geneticist so possibly missing the point)
> 
> On Fri, Jul 30, 2010 at 12:39 PM, Jerome Goudet <jerome.goudet at unil.ch> wrote:
>> Hi all,
>> 
>> Here is an example: genes are nested in individuals, themselves nested in
>> populations.  If individuals avoid mating with relatives, then the variance
>> component of allele frequencies among individuals within population is
>> expected to take negative values, as 2 genes taken from 2 different
>> individuals are more similar than two genes taken from the same individual.
>> See Weir & Cockerham (1984) Evolution for instance.
>> 
>> 
>> 
>> 
>> Ben Bolker wrote:
>> 
>>  Pardon my asking, but why? For consistency with older (arguably less
>> correct) method-of-moments estimates that could give negative
>> estimates?
>> 
>> On Fri, Jul 30, 2010 at 1:32 AM, Chris Brien <Chris.Brien at unisa.edu.au>
>> wrote:
>> 
>> 
>> Dear mixed modellers,
>> 
>> I have a data set that gives me an estimate of 0 for one of the variance
>> components. I wanted to allow for the estimate of the component to be
>> negative. My search of the documentation led me to believe that this is not
>> possible. Am I right, or did I miss something?
>> 
>> Cheers,
>> 
>> Chris Brien
>> -----
>> University of South Australia
>> ADELAIDE  5001  South Australia
>> WEB page:  <http://people.unisa.edu.au/Chris.Brien>
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
>> 
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
>> 
>> 
>> --
>> J?r?me Goudet
>> Dept. Ecology & Evolution
>> UNIL-Sorge, CH-1015 Lausanne
>> 
>> mail:jerome.goudet at unil.ch
>> Tel:+41 (0)21 692 4242
>> Fax:+41 (0)21 692 4265
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From will.eagle at gmx.net  Mon Aug  2 11:55:46 2010
From: will.eagle at gmx.net (will.eagle at gmx.net)
Date: Mon, 02 Aug 2010 11:55:46 +0200
Subject: [R-sig-ME] Residuals of mixed effects model
Message-ID: <20100802095546.272430@gmx.net>

Dear all,

I would like to apply a statistical test which is only available for indepedent samples to a data set with dependent samples based on a repeated measures design with 3 time points.

To adjust for correlatedness my idea was to convert the data into long format and use a linear mixed effects model with individuals as a random effect and an unstructured covariance matrix, to calculate the residuals. 

lme.out <- lme(data=MyDataInLongFormat,fixed= outcome~1, 
random= ~ 1|individual, correlation=corSymm(form = ~time|individual))

My expectaction was that residuals(lme.out, type = "normalized") should give me residuals which show only minor correlations (|r|<0.05) across time points (assuming the covariance structure fits the data), which should be suitable as an input for a test for independent samples.

Unfortunately, the original variable and residuals behave like that, which is the opposite of what I expected e.g.:
Original values: r(t1,t2) = 0.33
Residual values: r(t1,t2) = 0.73

Is my approach correct? Am using the right functions and options?

Thanks for your help in advance,

Will

PS: Sorry for cross-posting this question again after I misplaced it to the R-help mailing list: http://r.789695.n4.nabble.com/Residuals-of-mixed-effects-model-td2306516.html



From sol.heber at pg.canterbury.ac.nz  Mon Aug  2 07:18:44 2010
From: sol.heber at pg.canterbury.ac.nz (Sol Heber)
Date: Mon, 02 Aug 2010 17:18:44 +1200
Subject: [R-sig-ME] In mer_finalize(ans) : gr cannot be computed at initial
	par (65)
Message-ID: <3D675FA33045664383713F4D3A8ED82AB647@ucexchange6.canterbury.ac.nz>

Dear R List ?

I am trying to use a GLMM to analyse data on breeding success from crossing experiments between inbred lines of fruit flies but am having problems. 

My response variable is a proportion (proportion of eggs that hatched into adults), I have two fixed factors (one of them, ?cross?, has 4 levels: inbred, 1st or 2nd generation hybrid, and outbred, while the other fixed factor, ?line?, has 3 levels: the initial two lines of fruit flies used for the experiments and the resulting hybrid line), and two random terms ? female and male origin (to control for the fact that eggs of the same pair are not independent). 

My experimental design therefore looks something like this (resulting in missing cells in some of the combinations, e.g. there would be no data for the interaction inbred*AB, because in the inbred category there is no mix of the two lines):

Cross				Lines		
Inbred		AA				BB		
Hybrid F1	A1A2		AB		B1B2
Hybrid F2	A1A2		AB		B1B2
Outbred	        AA				BB

I have been using the following commands: 

> data<-read.table(file="data.txt",header=TRUE)
> attach(data)
> names(data)
 [1] "cross"     "line"      "forigin"   "morigin"  
 [6] "eggs" 	  "adults" 

> library(lme4)

> y<-cbind(adults,(eggs-adults))

> model1<-lmer(y~cross*line+(1|forigin)+(1|morigin),family=binomial)

But I get the error message: In mer_finalize(ans) : gr cannot be computed at initial par (65)

I suppose that I receive this error message because the experimental design is unbalanced, because as soon as I take out the interaction between the explanatory variables, R seems to be able to run the model. But it is precisely the interaction between ?cross? and ?line? that I am interested in.

So I have tried a different approach, by coding the origin of each individual fly: instead of using ?cross? and ?line? I have tried using maternal grandmother, maternal grandfather, paternal grandmother and paternal grandfather, which combines both the information of ?cross? and ?line? and should avoid the problem of the unbalanced design.

Again, after attaching the data I have been using the following commands:

> names(data)
 [1] "mat_granm"  "mat_granf" "pat_granm"  "pat_granf"  "forigin"  "morigin"  "eggs"  "adults"   

> y<-cbind(adults,eggs-adults)

> model1<-lmer(y~mat_granm*mat_granf*pat_granm*pat_granf+(1|forigin)+(1|morigin),family=binomial)

This again doesn?t work, but instead of getting an error message, R hangs itself up every time I attempt the analysis (I left it over night to see if it would just take that long, but the program doesn?t react).

Any help would be greatly appreciated, and I would also be happy to make the data available for this purpose.

Sol



This email may be confidential and subject to legal privilege, it may
not reflect the views of the University of Canterbury, and it is not
guaranteed to be virus free. If you are not an intended recipient,
please notify the sender immediately and erase all copies of the message
and any attachments.

Please refer to http://www.canterbury.ac.nz/emaildisclaimer for more
information.



From marie-agnes.coutellec at rennes.inra.fr  Mon Aug  2 14:29:47 2010
From: marie-agnes.coutellec at rennes.inra.fr (Marie-Agnes)
Date: Mon, 02 Aug 2010 14:29:47 +0200
Subject: [R-sig-ME] lme4 and cholmod warning
Message-ID: <4C56BA3B.5010708@rennes.inra.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100802/8d66c51f/attachment.pl>

From peterfrancis at me.com  Mon Aug  2 18:51:09 2010
From: peterfrancis at me.com (Peter Francis)
Date: Mon, 02 Aug 2010 17:51:09 +0100
Subject: [R-sig-ME] Multi-level qualitative (fixed-effects) factors
Message-ID: <45E1FDC6-EB9D-41C1-9105-7FF1DA820280@me.com>

Dear List,

For the analysis of my GLMM i am using AIC values rather than stepwise regression to simplify it. I have developed some candidate models and am running through them now. I know a priori that  there are some important interactions and i  have also removed all the factors i consider unimportant.

I have many multi level factors i.e habit - aquatic, terrestrial, epiphyte etc

I ran the model with habit as a factor 

> model111 <-lmer(threatornot~1+(1|a/b) + habit, family=binomial)

> Generalized linear mixed model fit by the Laplace approximation 
> Formula: threatornot ~ 1 + (1 | order/family) + habit 
>   AIC  BIC logLik deviance
>  1406 1436 -696.9     1394
> Random effects:
>  Groups       Name        Variance   Std.Dev.  
>  family:order (Intercept) 6.9892e-01 8.3602e-01
>  order        (Intercept) 4.2292e-14 2.0565e-07
> Number of obs: 1116, groups: family:order, 43; order, 9
> 
> Fixed effects:
>             Estimate Std. Error z value Pr(>|z|)   
> (Intercept) -0.04803    0.19174  -0.250  0.80219   
> habit2       1.10627    0.41607   2.659  0.00784 **
> habit3       0.92578    0.78141   1.185  0.23611   
> habit4       0.14383    0.38477   0.374  0.70856
   
---
Which had a AIC of 1406

I then re-ran the model with only aquatic and got a lower AIC value - which i guess is to be expected as aquatic is highly significant and aquatic species are more prone to threat ( my response).


> > model112 <-lmer(threatornot~1+(1|a/b) + aquatic, family=binomial)
> > model112
> Generalized linear mixed model fit by the Laplace approximation 
> Formula: threatornot ~ 1 + (1 | order/family) + aquatic 
>   AIC  BIC logLik deviance
>  1395 1415 -693.4     1387
> Random effects:
>  Groups       Name        Variance Std.Dev.
>  family:order (Intercept) 0.60007  0.77464 
>  order        (Intercept) 0.00000  0.00000 
> Number of obs: 1116, groups: family:order, 43; order, 9
> 
> Fixed effects:
>             Estimate Std. Error z value Pr(>|z|)    
> (Intercept)   0.1572     0.1827   0.860 0.389613    
> aquatic      -0.6683     0.1737  -3.847 0.000119 ***

My question is  - when i developed the candidate models i thought using multilevel factors would be OK and i would be able to tease out the individual levels. If i split the factors into levels from the beginning then i am left with a huge amount of candidate models? This would not be a problem in stepwise regression as i could just remove the habit with the least significant P Value.

If i remove habits i "feel" are unimportant from the beginning i feel i would be limiting the model too much.

I hope this makes sense!

Has anyone else had this problem or can see a work around?

Thanks

Peter



From Mike.Lawrence at dal.ca  Mon Aug  2 19:44:24 2010
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Mon, 2 Aug 2010 14:44:24 -0300
Subject: [R-sig-ME] gamm4 model formulation clarification
In-Reply-To: <AANLkTi=ZzfJKsNZyG_3jmx6DdSJ+Eb97qx9VF1qw8FoH@mail.gmail.com>
References: <AANLkTims1fHToCt7RyRN1jdVhNbXZuUzM5SWRXq2+Y2T@mail.gmail.com> 
	<AANLkTinRyvm=qj=Pooz1QOJMN-a7bJoQMjJa_Bxn4qLD@mail.gmail.com> 
	<AANLkTimBL-zOQueKayB6Gf-_H3nvHZdE+3UOqOW+CTQE@mail.gmail.com> 
	<AANLkTi=ZzfJKsNZyG_3jmx6DdSJ+Eb97qx9VF1qw8FoH@mail.gmail.com>
Message-ID: <AANLkTi=N9tz-CcNbzkWWivnD0Yit=ipznSWoe+Mx_3gB@mail.gmail.com>

On Sat, Jul 31, 2010 at 9:42 PM, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
> Also, I'm just now thinking that neither approach really gets at what
> I want to test; what I want to test whether the model is improved by
> (1) letting the smooth vary as a function of design, (2) letting the
> smooth vary as a function of ddB, and (3) letting the smooth vary as a
> function of both design & ddB. That is, is there a design*soa
> interaction, a ddB*soa interaction and/or a design*ddB*soa
> interaction? In the case of support for any of these interactions, I'd
> also be interested in pinpointing the timeframe over which the
> interactions take place.

After playing a bit, I wonder if anyone has any input on the following
"solution" I'm currently working with. First, a change in variable
names to simplify things: A & B are both 2-level factor variables, C
is a continuous numeric variable that needs smoothing, D is the
dependent variable, and E is the random effect (in my case, human
participants in an experiment).

To assess the A*C interaction:

1) turn B into a numeric centered on zero (-1,1):
my_data$B2 = as.numeric(my_data$B2)-1.5

2) fit a gamm, including the A*B2 interaction and smoothing C
independently per level of A:
AC_fit = gamm4(
    formula = D ~ A*B2 + s(C,by=A)
    , random = ~ (1|E)
    , data = my_data
)

3) Obtain predictions & 95% CI from the model for the 2 levels of A
across the range of C
AC_pred = expand.grid(
    A = factor(levels(my_data$A),levels=levels(my_data$A))
    , B2 = 0
    , C = seq(min(my_data$C),max(my_data$X),length.out=1e3)
)
from_predict = predict(AC_fit,newdata=AC_pred,se.fit=T)
AC_pred$D = from_predict$fit
AC_pred$se = from_predict$se.fit
AC_pred$lo_95ci = AC_pred$D - AC_pred$se*1.96
AC_pred$hi_95ci = AC_pred$D + AC_pred$se*1.96

4) You could plot the "pred" data now, plotting D as a function of C
and split by levels of A, but this will include the main effects of
both A and C, obscuring visualization of the interaction.

5) Compute the A*C interaction by computing the difference between the
levels of A at each value of C:
AC_effect = ddply(
    .data = AC_pred
    , .variables = .(C)
    , .fun = function(x){
        to_return = data.frame(
            A_effect = x$D[x$A==levels(x$A)[1]] - x$D[x$A==levels(x$A)[2]]
            , lo_95ci = min(
                x$hi_95ci[x$A==levels(x$A)[1]] - x$lo_95ci[x$A==levels(x$A)[2]]
                , x$lo_95ci[x$A==levels(x$A)[1]] -
x$hi_95ci[x$A==levels(x$A)[2]]
            )
            , hi_95ci = max(
                x$hi_95ci[x$A==levels(x$A)[1]] - x$lo_95ci[x$A==levels(x$A)[2]]
                , x$lo_95ci[x$A==levels(x$A)[1]] -
x$hi_95ci[x$A==levels(x$A)[2]]
            )
        )
        return(to_return)
    }
)

6) Now you can visualize the A*C interaction; any area where the CI
ribbon does not include zero may be considered a region where there is
a significant A*C interaction.
ggplot(data=AC_effect)+
layer(
    geom='hline'
    , yintercept = 0
    , linetype = 2
)+
layer(
    geom = 'ribbon'
    , mapping = aes(
        x = C
        , ymin = lo_95ci
        , ymax = hi_95ci
    )
    , alpha = .5
)+
layer(
    geom = 'line'
    , mapping = aes(
        x = C
        , y = A_effect
    )
)


Similar steps can be applied to the inspection of a B*C interaction.

The A*B*C interaction would be assessed by:

1) create dummy variable, F, representing the A*B combinations:
my_data$F = factor(paste(my_data$A,my_data$B))

2) fit a gam that smooths C in each combination of A*B:
ABC_fit = gamm4(
    formula = D ~ A*B + s(C,by=F)
    , random = ~ (1|E)
    , data = my_data
)

3) obtain the prediction & CI for D in each combination of A*B and
across the range of C:
ABC_pred = expand.grid(
    A = factor(levels(my_data$A),levels=levels(my_data$A))
    , B = factor(levels(my_data$B),levels=levels(my_data$B))
    , C = seq(min(my_data$C),max(my_data$X),length.out=1e3)
)
ABC_pred = factor(paste(ABC_pred$A,ABC_pred$B),levels=levels(my_data$F))
from_predict = predict(ABC_fit,newdata=ABC_pred,se.fit=T)
ABC_pred$D = from_predict$fit
ABC_pred$se = from_predict$se.fit
ABC_pred$lo_95ci = ABC_pred$D - ABC_pred$se*1.96
ABC_pred$hi_95ci = ABC_pred$D + ABC_pred$se*1.96

4) Similar to step 5 above, compute the difference between levels of A
at each value of C *and* each level of B.

5) Using the differences computed in step 4, now compute the
difference between levels of B at each value of C.

6) Now we have another single function and confidence ribbon that can
be plotted; any region where the ribbon excludes zero may be
considered a region with a significant A*B*C interaction.


Does anyone have any thoughts on the validity of this approach? Also,
this is clearly only applicable to the cases where A and B have only 2
levels each, so any thoughts on an alternative more generalizable
approach would be appreciated.

Mike

-- 
Mike Lawrence
Graduate Student
Department of Psychology
Dalhousie University

Looking to arrange a meeting? Check my public calendar:
http://tr.im/mikes_public_calendar

~ Certainty is folly... I think. ~



From davidD at qimr.edu.au  Tue Aug  3 00:45:42 2010
From: davidD at qimr.edu.au (David Duffy)
Date: Tue, 3 Aug 2010 08:45:42 +1000 (EST)
Subject: [R-sig-ME] lme4 and cholmod warning
In-Reply-To: <4C56BA3B.5010708@rennes.inra.fr>
References: <4C56BA3B.5010708@rennes.inra.fr>
Message-ID: <Pine.LNX.4.64.1008030842360.4225@orpheus.qimr.edu.au>

On Mon, 2 Aug 2010, Marie-Agnes wrote:

> Dears,
>
> I encoutered the following message, when using lme4 :
>
> Warning messages:
> 1: In mer_finalize(ans) :
>  Cholmod warning 'not positive definite' at
> file:../Cholesky/t_cholmod_rowfac.c, line 432
> 2: In mer_finalize(ans) :
>  Cholmod warning 'not positive definite' at
> file:../Cholesky/t_cholmod_rowfac.c, line 432
> 3: In mer_finalize(ans) : singular convergence (7)
>
>
> I saw the same kind of message on your mailing list, but then I could
> not follow up the reply.
>
> My model was:
> > ga1p<-glmer(A1P~T131006+typop*mr+(1|pop/fam), family= poisson)
>
> The dataset is unbalanced:  there are 16 "pop", with a varying number of
> "fam" within pop. In one population, there is only one family.
> The problem is related to T131006 (when omitted, glmer works). When I
> replace this covariate by another one, I have the same message, except
> in one particular case.

Is T131006 continuous or categorical?  If the latter, what do 
table(T131006) and table(pop,T131006) look like?

Cheers, David Duffy
-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From davidD at qimr.edu.au  Tue Aug  3 01:16:43 2010
From: davidD at qimr.edu.au (David Duffy)
Date: Tue, 3 Aug 2010 09:16:43 +1000 (EST)
Subject: [R-sig-ME] Multi-level qualitative (fixed-effects) factors
In-Reply-To: <45E1FDC6-EB9D-41C1-9105-7FF1DA820280@me.com>
References: <45E1FDC6-EB9D-41C1-9105-7FF1DA820280@me.com>
Message-ID: <Pine.LNX.4.64.1008030909450.4225@orpheus.qimr.edu.au>

On Mon, 2 Aug 2010, Peter Francis wrote:

> I have many multi level factors i.e habit - aquatic, terrestrial, epiphyte etc
>
> I ran the model with habit as a factor
>
>> model111 <-lmer(threatornot~1+(1|a/b) + habit, family=binomial)
>
>> Generalized linear mixed model fit by the Laplace approximation
>> Formula: threatornot ~ 1 + (1 | order/family) + habit
>>   AIC  BIC logLik deviance
>>  1406 1436 -696.9     1394
>> Random effects:
>>  Groups       Name        Variance   Std.Dev.
>>  family:order (Intercept) 6.9892e-01 8.3602e-01
>>  order        (Intercept) 4.2292e-14 2.0565e-07
>> Number of obs: 1116, groups: family:order, 43; order, 9
>>
>> Fixed effects:
>>             Estimate Std. Error z value Pr(>|z|)
>> (Intercept) -0.04803    0.19174  -0.250  0.80219
>> habit2       1.10627    0.41607   2.659  0.00784 **
>> habit3       0.92578    0.78141   1.185  0.23611
>> habit4       0.14383    0.38477   0.374  0.70856
>
> ---
> Which had a AIC of 1406
>
> I then re-ran the model with only aquatic and got a lower AIC value - 
> which i guess is to be expected as aquatic is highly significant and 
> aquatic species are more prone to threat ( my response).
>
>
>>> model112 <-lmer(threatornot~1+(1|a/b) + aquatic, family=binomial)
>>> model112
>> Generalized linear mixed model fit by the Laplace approximation
>> Formula: threatornot ~ 1 + (1 | order/family) + aquatic
>>   AIC  BIC logLik deviance
>>  1395 1415 -693.4     1387
>> Random effects:
>>  Groups       Name        Variance Std.Dev.
>>  family:order (Intercept) 0.60007  0.77464
>>  order        (Intercept) 0.00000  0.00000
>> Number of obs: 1116, groups: family:order, 43; order, 9
>>
>> Fixed effects:
>>             Estimate Std. Error z value Pr(>|z|)
>> (Intercept)   0.1572     0.1827   0.860 0.389613
>> aquatic      -0.6683     0.1737  -3.847 0.000119 ***
>
> My question is - when i developed the candidate models i thought using 
> multilevel factors would be OK and i would be able to tease out the 
> individual levels. If i split the factors into levels from the beginning 
> then i am left with a huge amount of candidate models? This would not be 
> a problem in stepwise regression as i could just remove the habit with 
> the least significant P Value.
>
> If i remove habits i "feel" are unimportant from the beginning i feel i 
> would be limiting the model too much.
>
> I hope this makes sense!

I don't understand at all, I'm afraid.  Is aquatic the same as habit=2, or 
something?  If so, there is something funny about the model fits.

If family and order are "nuisance" variables, then a stepwise 
approach is quite reasonable (if you are someone who thinks stepwise 
regression is reasonable, of course ;)).

Just 2c, David Duffy.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From bbolker at gmail.com  Tue Aug  3 04:09:07 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 3 Aug 2010 02:09:07 +0000 (UTC)
Subject: [R-sig-ME] Negative estimates of variance component
References: <EC96E350A5D6444B82CBD8DA338F017528BF1757@ITUPC-EX1MBOX.UniNet.unisa.edu.au>
	<AANLkTinCu2TznFnm2jHqBRe7hqYYV1bagdY+sybirngO@mail.gmail.com>
	<4C53002E.7090404@unil.ch>
	<AANLkTik+DfZSCB1RR4z0e6ca9Z=V=f9Rg5QQ67VZevOB@mail.gmail.com>
	<EC96E350A5D6444B82CBD8DA338F017528BF1A94@ITUPC-EX1MBOX.UniNet.unisa.edu.au>
	<A7606BE4-9F4A-4E43-95A0-4C419E011C9F@anu.edu.au>
Message-ID: <loom.20100803T040842-836@post.gmane.org>

John Maindonald <john.maindonald at ...> writes:

> 
> The negative estimates are really then parameters in the 
> variance-covariance matrix.  (There is no escaping from 
> the requirement that this matrix, however parameterised, 
> should be positive definite.)  If a parameter is negative to 
> an extent that excludes statistical error, it cannot then be 
> interpreted as a variances, but provides an indication 
> that the variance-covariance structure has been wrongly 
> formulated.  This can be useful diagnostic information.
> 
> > So, I do not agree that it is in the category of 
> "consistency with older method-of-moments estimates". The
> issue is more that there is no coherent way to specify the types 
> of models of which I am thinking in current
> software packages.
> 

  I would probably see if MCMCglmm can do this.
  It does allow the specification of "R-side" correlation
structures, and I think it allows crossed random effects.



From chris.brien at iinet.net.au  Tue Aug  3 08:10:29 2010
From: chris.brien at iinet.net.au (chris.brien at iinet.net.au)
Date: Tue, 03 Aug 2010 14:10:29 +0800
Subject: [R-sig-ME] FW:  Negative estimates of variance component
Message-ID: <1292.1280815829@iinet.net.au>



Hi Jerome,

The example that John gave is a nice one. There are others in references that
discuss negative estimates. Two older references are:

Nelder, J. A. (1954). "The interpretation of negative components of variance."
Biometrika 41(3/4): 544-548.
Nelder, J. A. (1977). "A reformulation of linear models (with discussion)."
Journal of the Royal Statistical Society, Series A 140(1): 48-77.

There is also a lot of discussion of negative estimates in Searle, S. R., G.
Casella, and C.E. McCulloch. (1992). Variance components. New York, And Wiley.

and some in Littell, R. C., G. A. Milliken, et al. (2006). SAS for Mixed Models.
Cary, N.C., SAS Press.

As for implementation in lme4, that is outside what I know. However, the usual
way used in other packages is to allow negative estimates of negative components
as a surrogate for components of excess covariance, but, as John has pointed out,
with the overall covariance matrix remaining positive definite.

Cheers,

Chris

PS Apologies for multiple messages caused by mail client problems

>From:
>Jerome Goudet [mailto:jerome.goudet at unil.ch] 
>
>Sent: Monday, 2 August 2010 12:44 PM
>
>To: John Maindonald
>
>Cc: Chris Brien; Ben Bolker; r-sig-mixed-models at r-project.org
>
>Subject: Re: [R-sig-ME] Negative estimates of variance component
>
>
>
>
>
>?
>
>I'd be delighted to learn more about this, and how it could
>be implemented in lme4. Any lead that I could follow?? Cheers, Jerome
>
>
>
>
>
>John Maindonald wrote: 
>
>The negative estimates are really then parameters in the variance-covariance
matrix.? (There is no escaping from the requirement that this matrix, however
parameterised, should be positive definite.)? If a parameter is negative to an
extent that excludes statistical error, it cannot then be interpreted as a
variances, but provides an indication that the variance-covariance structure has
been wrongly formulated.? This can be useful diagnostic information.?In results
from a block design, it might for example resultfrom choosing plots in a manner
that increases rather than decreases heterogeneity between plots.? For example,
blocks may be chosen so that plots are at increasing distances from a river
bank.? I have from time to time encountered scientists who though that a choice
of this type (maximising heterogeneity) was the right thing to do.?John
Maindonald???????????? email: john.maindonald at anu.edu.auphone : +61 2
(6125)3473??? fax? : +61 2(6125)5549Centre for Mathematics & Its Applications,
Room 1194,John Dedman Mathematical Sciences Building (Building 27)Australian
National University, Canberra ACT 0200.http://www.maths.anu.edu.au/~johnm?On
31/07/2010, at 7:38 AM, Chris Brien wrote:?? 
>
>Dear all,?Doug, thanks for the information that negative estimates are not
possible with lme4 and nlme.?As for the questions from others about why would you
want to do it, there are a number of reasons.?Of course, variance components must
be positive. However, one reason, given by Littel et al in? SAS for Mixed Models,
to allow negative estimates is that it controls Type I error better and in
certain circumstance may give better power. This is essentially related to the
issue of pooling non-significant error terms. In SAS MIXED there is an option to
allow negative estimates. ?Another reason is that variance components might be
interpreted as components of excess variation or even excess covariance. Then
negative values indicate less covariance between than within groups, as Jerome
explained. However, as suggested in the "Heywood case" scenario, reasons for
negative estimates need to be investigated to make sure that it really is
negative covariance. As for fitting using structured covariance matrices as
suggested by Ben, this is a nice way to go about it but requires that the
software has this capability. Lme4 does not have it and nlme is not good at
fitting crossed factors - a gotcha' situation.?A third reason is that in order to
approximate a randomization analysis, one needs to allow for negative estimates.
I reiterate that here I am thinking of variance components as surrogates for
components of excess covariance.?So, I do not agree that it is in the category of
"consistency with older method-of-moments estimates". The issue is more that
there is no coherent way to specify the types of models of which I am thinking in
current software packages.?Cheers,? Chris??-----Original Message-----From: Ben
Bolker [mailto:bbolker at gmail.com] Sent: Friday, 30 July 2010 7:02 PMTo:
jerome.goudet at unil.chCc: Chris Brien; r-sig-mixed-models at r-project.orgSubject:
Re: [R-sig-ME] Negative estimates of variance component? I claim that this is in
the category of "consistency with oldermethod-of-moments estimates" ... I know
that population geneticistsstill like to think in terms of variance components,
but wouldn't oneideally want to deal with the negative correlation built into
thesystem by estimating it more or less directly (i.e. via a
structuredvariance-covariance model that has nonnegative variances but couldhave
negative covariances) rather than by estimating a negativevariance component??
Ben Bolker (not a population geneticist so possibly missing the point)?On Fri,
Jul 30, 2010 at 12:39 PM, Jerome Goudet <jerome.goudet at unil.ch> wrote:??? 
>
>Hi all,?Here is an example: genes are nested in individuals, themselves nested
inpopulations.? If individuals avoid mating with relatives, then the
variancecomponent of allele frequencies among individuals within population
isexpected to take negative values, as 2 genes taken from 2 differentindividuals
are more similar than two genes taken from the same individual.See Weir &
Cockerham (1984) Evolution for instance.????Ben Bolker wrote:? Pardon my asking,
but why? For consistency with older (arguably lesscorrect) method-of-moments
estimates that could give negativeestimates??On Fri, Jul 30, 2010 at 1:32 AM,
Chris Brien <Chris.Brien at unisa.edu.au>wrote:??Dear mixed modellers,?I have a data
set that gives me an estimate of 0 for one of the variancecomponents. I wanted to
allow for the estimate of the component to benegative. My search of the
documentation led me to believe that this is notpossible. Am I right, or did I
miss something??Cheers,?Chris Brien-----University of South AustraliaADELAIDE?
5001? South AustraliaWEB page:?
<http://people.unisa.edu.au/Chris.Brien>?_______________________________________________R-sig-mixed-models at r-project.org
mailing
listhttps://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models???_______________________________________________R-sig-mixed-models at r-project.org
mailing listhttps://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models???--J?r?me
GoudetDept. Ecology & EvolutionUNIL-Sorge, CH-1015
Lausanne?mail:jerome.goudet at unil.chTel:+41 (0)21 692 4242Fax:+41 (0)21 692 4265????? 
>
>_______________________________________________R-sig-mixed-models at r-project.org
mailing listhttps://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models??? 
>
>??? 
>
>
>
>
>
>
>
>-- J?r?me GoudetDept. Ecology & EvolutionUNIL-Sorge, CH-1015
Lausanne?mail:jerome.goudet at unil.chTel:+41 (0)21 692 4242Fax:+41 (0)21 692 4265
>
>
>
>



From peterfrancis at me.com  Tue Aug  3 08:48:41 2010
From: peterfrancis at me.com (Peter Francis)
Date: Tue, 03 Aug 2010 07:48:41 +0100
Subject: [R-sig-ME] Multi-level qualitative (fixed-effects) factors
In-Reply-To: <Pine.LNX.4.64.1008030909450.4225@orpheus.qimr.edu.au>
References: <45E1FDC6-EB9D-41C1-9105-7FF1DA820280@me.com>
	<Pine.LNX.4.64.1008030909450.4225@orpheus.qimr.edu.au>
Message-ID: <0EFB90B1-6CDA-4807-9640-292B21B224FA@me.com>

Hi David and Ben, thanks for your help - 

I was worried this would make little sense!

I have set out my candidate models

A+B+C+D
B+C+D
A+C+D
etc etc

And am running through them in lmer. Factor A for instance is Habit, which takes 3 forms - aquatic, terrestrial or epiphyte. 

When i run the model with A as a factor i get the breakdown of the individual levels habitat 1, habitat 2 and habitat 3 and a corresponding AIC score. However if i just run it with habitat 3 - aquatic - i get a lower AIC score, therefore the model fits the data better?

I am unsure how to, without splitting my factors into their constituent levels at the beginning - A1+A2+A3 + B1 + B2 etc, arrive at the model with the lowest AIC?

Thanks

Peter

On 3 Aug 2010, at 00:16, David Duffy wrote:

On Mon, 2 Aug 2010, Peter Francis wrote:

> I have many multi level factors i.e habit - aquatic, terrestrial, epiphyte etc
> 
> I ran the model with habit as a factor
> 
>> model111 <-lmer(threatornot~1+(1|a/b) + habit, family=binomial)
> 
>> Generalized linear mixed model fit by the Laplace approximation
>> Formula: threatornot ~ 1 + (1 | order/family) + habit
>>  AIC  BIC logLik deviance
>> 1406 1436 -696.9     1394
>> Random effects:
>> Groups       Name        Variance   Std.Dev.
>> family:order (Intercept) 6.9892e-01 8.3602e-01
>> order        (Intercept) 4.2292e-14 2.0565e-07
>> Number of obs: 1116, groups: family:order, 43; order, 9
>> 
>> Fixed effects:
>>            Estimate Std. Error z value Pr(>|z|)
>> (Intercept) -0.04803    0.19174  -0.250  0.80219
>> habit2       1.10627    0.41607   2.659  0.00784 **
>> habit3       0.92578    0.78141   1.185  0.23611
>> habit4       0.14383    0.38477   0.374  0.70856
> 
> ---
> Which had a AIC of 1406
> 
> I then re-ran the model with only aquatic and got a lower AIC value - which i guess is to be expected as aquatic is highly significant and aquatic species are more prone to threat ( my response).
> 
> 
>>> model112 <-lmer(threatornot~1+(1|a/b) + aquatic, family=binomial)
>>> model112
>> Generalized linear mixed model fit by the Laplace approximation
>> Formula: threatornot ~ 1 + (1 | order/family) + aquatic
>>  AIC  BIC logLik deviance
>> 1395 1415 -693.4     1387
>> Random effects:
>> Groups       Name        Variance Std.Dev.
>> family:order (Intercept) 0.60007  0.77464
>> order        (Intercept) 0.00000  0.00000
>> Number of obs: 1116, groups: family:order, 43; order, 9
>> 
>> Fixed effects:
>>            Estimate Std. Error z value Pr(>|z|)
>> (Intercept)   0.1572     0.1827   0.860 0.389613
>> aquatic      -0.6683     0.1737  -3.847 0.000119 ***
> 
> My question is - when i developed the candidate models i thought using multilevel factors would be OK and i would be able to tease out the individual levels. If i split the factors into levels from the beginning then i am left with a huge amount of candidate models? This would not be a problem in stepwise regression as i could just remove the habit with the least significant P Value.
> 
> If i remove habits i "feel" are unimportant from the beginning i feel i would be limiting the model too much.
> 
> I hope this makes sense!

I don't understand at all, I'm afraid.  Is aquatic the same as habit=2, or something?  If so, there is something funny about the model fits.

If family and order are "nuisance" variables, then a stepwise approach is quite reasonable (if you are someone who thinks stepwise regression is reasonable, of course ;)).

Just 2c, David Duffy.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From andydolman at gmail.com  Tue Aug  3 09:50:32 2010
From: andydolman at gmail.com (Andrew Dolman)
Date: Tue, 3 Aug 2010 09:50:32 +0200
Subject: [R-sig-ME] Multi-level qualitative (fixed-effects) factors
In-Reply-To: <0EFB90B1-6CDA-4807-9640-292B21B224FA@me.com>
References: <45E1FDC6-EB9D-41C1-9105-7FF1DA820280@me.com>
	<Pine.LNX.4.64.1008030909450.4225@orpheus.qimr.edu.au>
	<0EFB90B1-6CDA-4807-9640-292B21B224FA@me.com>
Message-ID: <AANLkTimq6Vo37hUS_dYnk9ofJUHeqU8EM+tewE+YF_jA@mail.gmail.com>

I don't get it. How can you fit the model with just 1 of three levels
of factor "habitat" and have the same number of observations as when
you run the model with all three? (It must have at least 2 levels to
fit anyway) Also, in the first example you have 4 levels of habitat.

Are they different levels of habitat resolution? e.g.

Aquatic - non aquatic
Aquatic - Terrestrial - Epiphytic
Aquatic - Terrestrial - Epiphytic - Up elephant's noses


Please read the posting guide and include proper examples of what you
are doing and what the data look like.


andydolman at gmail.com



On 3 August 2010 08:48, Peter Francis <peterfrancis at me.com> wrote:
> Hi David and Ben, thanks for your help -
>
> I was worried this would make little sense!
>
> I have set out my candidate models
>
> A+B+C+D
> B+C+D
> A+C+D
> etc etc
>
> And am running through them in lmer. Factor A for instance is Habit, which takes 3 forms - aquatic, terrestrial or epiphyte.
>
> When i run the model with A as a factor i get the breakdown of the individual levels habitat 1, habitat 2 and habitat 3 and a corresponding AIC score. However if i just run it with habitat 3 - aquatic - i get a lower AIC score, therefore the model fits the data better?
>
> I am unsure how to, without splitting my factors into their constituent levels at the beginning - A1+A2+A3 + B1 + B2 etc, arrive at the model with the lowest AIC?
>
> Thanks
>
> Peter
>
> On 3 Aug 2010, at 00:16, David Duffy wrote:
>
> On Mon, 2 Aug 2010, Peter Francis wrote:
>
>> I have many multi level factors i.e habit - aquatic, terrestrial, epiphyte etc
>>
>> I ran the model with habit as a factor
>>
>>> model111 <-lmer(threatornot~1+(1|a/b) + habit, family=binomial)
>>
>>> Generalized linear mixed model fit by the Laplace approximation
>>> Formula: threatornot ~ 1 + (1 | order/family) + habit
>>> ?AIC ?BIC logLik deviance
>>> 1406 1436 -696.9 ? ? 1394
>>> Random effects:
>>> Groups ? ? ? Name ? ? ? ?Variance ? Std.Dev.
>>> family:order (Intercept) 6.9892e-01 8.3602e-01
>>> order ? ? ? ?(Intercept) 4.2292e-14 2.0565e-07
>>> Number of obs: 1116, groups: family:order, 43; order, 9
>>>
>>> Fixed effects:
>>> ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
>>> (Intercept) -0.04803 ? ?0.19174 ?-0.250 ?0.80219
>>> habit2 ? ? ? 1.10627 ? ?0.41607 ? 2.659 ?0.00784 **
>>> habit3 ? ? ? 0.92578 ? ?0.78141 ? 1.185 ?0.23611
>>> habit4 ? ? ? 0.14383 ? ?0.38477 ? 0.374 ?0.70856
>>
>> ---
>> Which had a AIC of 1406
>>
>> I then re-ran the model with only aquatic and got a lower AIC value - which i guess is to be expected as aquatic is highly significant and aquatic species are more prone to threat ( my response).
>>
>>
>>>> model112 <-lmer(threatornot~1+(1|a/b) + aquatic, family=binomial)
>>>> model112
>>> Generalized linear mixed model fit by the Laplace approximation
>>> Formula: threatornot ~ 1 + (1 | order/family) + aquatic
>>> ?AIC ?BIC logLik deviance
>>> 1395 1415 -693.4 ? ? 1387
>>> Random effects:
>>> Groups ? ? ? Name ? ? ? ?Variance Std.Dev.
>>> family:order (Intercept) 0.60007 ?0.77464
>>> order ? ? ? ?(Intercept) 0.00000 ?0.00000
>>> Number of obs: 1116, groups: family:order, 43; order, 9
>>>
>>> Fixed effects:
>>> ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
>>> (Intercept) ? 0.1572 ? ? 0.1827 ? 0.860 0.389613
>>> aquatic ? ? ?-0.6683 ? ? 0.1737 ?-3.847 0.000119 ***
>>
>> My question is - when i developed the candidate models i thought using multilevel factors would be OK and i would be able to tease out the individual levels. If i split the factors into levels from the beginning then i am left with a huge amount of candidate models? This would not be a problem in stepwise regression as i could just remove the habit with the least significant P Value.
>>
>> If i remove habits i "feel" are unimportant from the beginning i feel i would be limiting the model too much.
>>
>> I hope this makes sense!
>
> I don't understand at all, I'm afraid. ?Is aquatic the same as habit=2, or something? ?If so, there is something funny about the model fits.
>
> If family and order are "nuisance" variables, then a stepwise approach is quite reasonable (if you are someone who thinks stepwise regression is reasonable, of course ;)).
>
> Just 2c, David Duffy.
>
> --
> | David Duffy (MBBS PhD) ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ,-_|\
> | email: davidD at qimr.edu.au ?ph: INT+61+7+3362-0217 fax: -0101 ?/ ? ? *
> | Epidemiology Unit, Queensland Institute of Medical Research ? \_,-._/
> | 300 Herston Rd, Brisbane, Queensland 4029, Australia ?GPG 4D0B994A v
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From peterfrancis at me.com  Tue Aug  3 10:53:20 2010
From: peterfrancis at me.com (Peter Francis)
Date: Tue, 03 Aug 2010 09:53:20 +0100
Subject: [R-sig-ME]  Multi-level qualitative (fixed-effects) factors
References: <59FC717C-0510-4E58-A4FE-4790322A0234@me.com>
Message-ID: <6B10024D-0AE7-4429-81BD-D77B22D13025@me.com>

Sorry to everyone,

I guess i should rephrase this completely as i think i am not getting across what i want to ( my fault, i apologise for the spam!).

I am trying to discover which traits correlate with threatened or not (binary response- i do have different levele of threat but am unsure how to model continuos response variables in GLMM - quasi poisson?)

I shall work through a quick example and would appreciate it if you could tell me if my conclusions are justified.

Lets just say for ease i am have two models -  i can send str(traits) etc if required - 

> model1 <-lmer(threatornot~1+(1|a/b) + habit, family=binomial)
> 
> Generalized linear mixed model fit by the Laplace approximation 
> Formula: threatornot ~ 1 + (1 | a/b) + habit 
>  AIC  BIC logLik deviance
> 1406 1436 -696.9     1394
> Random effects:
> Groups       Name        Variance   Std.Dev.  
> family:order (Intercept) 6.9892e-01 8.3602e-01
> order        (Intercept) 4.2292e-14 2.0565e-07
> Number of obs: 1116, groups: family:order, 43; order, 9
> 
> Fixed effects:
>            Estimate Std. Error z value Pr(>|z|)   
> (Intercept) -0.04803    0.19174  -0.250  0.80219   
> habit2       1.10627    0.41607   2.659  0.00784 **
> habit3       0.92578    0.78141   1.185  0.23611   
> habit4       0.14383    0.38477   0.374  0.70856   
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 


This shows that with habit the model has a AIC value of 1406 and habit2 has the significant effect on the threat status of a species?

Now model 2
> model2 <-lmer(threatornot~1+(1|a/b) + habit + breedingsystem, family=binomial)
> Generalized linear mixed model fit by the Laplace approximation 
> Formula: threatornot ~ 1 + (1 | a/b) + habit + breedingsystem 
>  AIC  BIC logLik deviance
> 1408 1449 -696.2     1392
> Random effects:
> Groups       Name        Variance Std.Dev.
> family:order (Intercept) 0.67836  0.82363 
> order        (Intercept) 0.00000  0.00000 
> Number of obs: 1116, groups: family:order, 43; order, 9
> 
> Fixed effects:
>                Estimate Std. Error z value Pr(>|z|)   
> (Intercept)      0.17398    0.39138   0.444  0.65665   
> habit2           1.15687    0.41943   2.758  0.00581 **
> habit3           0.92017    0.78158   1.177  0.23907   
> habit4          -0.01673    0.43150  -0.039  0.96907   
> breedingsystem2 -0.18615    0.37849  -0.492  0.62285   
> breedingsystem3 -0.42513    0.40652  -1.046  0.29567   
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 


This shows that adding breeding system to the model doesn't fit the data any better (the AIC is higher), therefore breedingsystem has no significant effect on the threat status of a species

Under this simple example i can conclude that the habit of a species is significant in determining how threatened the species is and in particular species from habit2 are more threatened than those not from habit2.

Are these inferences justified or am i missing something?

Thanks




On 3 Aug 2010, at 08:50, Andrew Dolman wrote:

I don't get it. How can you fit the model with just 1 of three levels
of factor "habitat" and have the same number of observations as when
you run the model with all three? (It must have at least 2 levels to
fit anyway) Also, in the first example you have 4 levels of habitat.

Are they different levels of habitat resolution? e.g.

Aquatic - non aquatic
Aquatic - Terrestrial - Epiphytic
Aquatic - Terrestrial - Epiphytic - Up elephant's noses


Please read the posting guide and include proper examples of what you
are doing and what the data look like.


andydolman at gmail.com



On 3 August 2010 08:48, Peter Francis <peterfrancis at me.com> wrote:
> Hi David and Ben, thanks for your help -
> 
> I was worried this would make little sense!
> 
> I have set out my candidate models
> 
> A+B+C+D
> B+C+D
> A+C+D
> etc etc
> 
> And am running through them in lmer. Factor A for instance is Habit, which takes 3 forms - aquatic, terrestrial or epiphyte.
> 
> When i run the model with A as a factor i get the breakdown of the individual levels habitat 1, habitat 2 and habitat 3 and a corresponding AIC score. However if i just run it with habitat 3 - aquatic - i get a lower AIC score, therefore the model fits the data better?
> 
> I am unsure how to, without splitting my factors into their constituent levels at the beginning - A1+A2+A3 + B1 + B2 etc, arrive at the model with the lowest AIC?
> 
> Thanks
> 
> Peter
> 
> On 3 Aug 2010, at 00:16, David Duffy wrote:
> 
> On Mon, 2 Aug 2010, Peter Francis wrote:
> 
>> I have many multi level factors i.e habit - aquatic, terrestrial, epiphyte etc
>> 
>> I ran the model with habit as a factor
>> 
>>> model111 <-lmer(threatornot~1+(1|a/b) + habit, family=binomial)
>> 
>>> Generalized linear mixed model fit by the Laplace approximation
>>> Formula: threatornot ~ 1 + (1 | order/family) + habit
>>> AIC  BIC logLik deviance
>>> 1406 1436 -696.9     1394
>>> Random effects:
>>> Groups       Name        Variance   Std.Dev.
>>> family:order (Intercept) 6.9892e-01 8.3602e-01
>>> order        (Intercept) 4.2292e-14 2.0565e-07
>>> Number of obs: 1116, groups: family:order, 43; order, 9
>>> 
>>> Fixed effects:
>>>           Estimate Std. Error z value Pr(>|z|)
>>> (Intercept) -0.04803    0.19174  -0.250  0.80219
>>> habit2       1.10627    0.41607   2.659  0.00784 **
>>> habit3       0.92578    0.78141   1.185  0.23611
>>> habit4       0.14383    0.38477   0.374  0.70856
>> 
>> ---
>> Which had a AIC of 1406
>> 
>> I then re-ran the model with only aquatic and got a lower AIC value - which i guess is to be expected as aquatic is highly significant and aquatic species are more prone to threat ( my response).
>> 
>> 
>>>> model112 <-lmer(threatornot~1+(1|a/b) + aquatic, family=binomial)
>>>> model112
>>> Generalized linear mixed model fit by the Laplace approximation
>>> Formula: threatornot ~ 1 + (1 | order/family) + aquatic
>>> AIC  BIC logLik deviance
>>> 1395 1415 -693.4     1387
>>> Random effects:
>>> Groups       Name        Variance Std.Dev.
>>> family:order (Intercept) 0.60007  0.77464
>>> order        (Intercept) 0.00000  0.00000
>>> Number of obs: 1116, groups: family:order, 43; order, 9
>>> 
>>> Fixed effects:
>>>           Estimate Std. Error z value Pr(>|z|)
>>> (Intercept)   0.1572     0.1827   0.860 0.389613
>>> aquatic      -0.6683     0.1737  -3.847 0.000119 ***
>> 
>> My question is - when i developed the candidate models i thought using multilevel factors would be OK and i would be able to tease out the individual levels. If i split the factors into levels from the beginning then i am left with a huge amount of candidate models? This would not be a problem in stepwise regression as i could just remove the habit with the least significant P Value.
>> 
>> If i remove habits i "feel" are unimportant from the beginning i feel i would be limiting the model too much.
>> 
>> I hope this makes sense!
> 
> I don't understand at all, I'm afraid.  Is aquatic the same as habit=2, or something?  If so, there is something funny about the model fits.
> 
> If family and order are "nuisance" variables, then a stepwise approach is quite reasonable (if you are someone who thinks stepwise regression is reasonable, of course ;)).
> 
> Just 2c, David Duffy.
> 
> --
> | David Duffy (MBBS PhD)                                         ,-_|\
> | email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
> | Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
> | 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 



From Thierry.ONKELINX at inbo.be  Tue Aug  3 11:18:10 2010
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 3 Aug 2010 11:18:10 +0200
Subject: [R-sig-ME] Multi-level qualitative (fixed-effects) factors
In-Reply-To: <6B10024D-0AE7-4429-81BD-D77B22D13025@me.com>
References: <59FC717C-0510-4E58-A4FE-4790322A0234@me.com>
	<6B10024D-0AE7-4429-81BD-D77B22D13025@me.com>
Message-ID: <3DB16098F738284D8DBEB2FC3699163821EA97@inboexch.inbo.be>

Dear Peter,

Your inference in not correct. The significance you get from habitat2 is
only the comparison between habitat2 and the reference level
(habitat1?). You can conclude that only habitat2 is significantly
different from habitat1 and habitat 3 vs 1 and habitat 4 vs 1 is not
significant. You cannot compare 2 vs 3, 2 vs 4 and 3 vs 4. That would
require multiple comparisons (cfr Tukey).

Best regards,

Thierry


------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey
  

> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Peter Francis
> Verzonden: dinsdag 3 augustus 2010 10:53
> Aan: R-mixed models mailing list
> Onderwerp: [R-sig-ME] Multi-level qualitative (fixed-effects) factors
> 
> Sorry to everyone,
> 
> I guess i should rephrase this completely as i think i am not 
> getting across what i want to ( my fault, i apologise for the spam!).
> 
> I am trying to discover which traits correlate with
> threatened or not (binary response- i do have different 
> levele of threat but am unsure how to model continuos 
> response variables in GLMM - quasi poisson?)
> 
> I shall work through a quick example and would appreciate it 
> if you could tell me if my conclusions are justified.
> 
> Lets just say for ease i am have two models -  i can send 
> str(traits) etc if required - 
> 
> > model1 <-lmer(threatornot~1+(1|a/b) + habit, family=binomial)
> > 
> > Generalized linear mixed model fit by the Laplace approximation
> > Formula: threatornot ~ 1 + (1 | a/b) + habit  AIC  BIC 
> logLik deviance
> > 1406 1436 -696.9     1394
> > Random effects:
> > Groups       Name        Variance   Std.Dev.  
> > family:order (Intercept) 6.9892e-01 8.3602e-01
> > order        (Intercept) 4.2292e-14 2.0565e-07
> > Number of obs: 1116, groups: family:order, 43; order, 9
> > 
> > Fixed effects:
> >            Estimate Std. Error z value Pr(>|z|)   
> > (Intercept) -0.04803    0.19174  -0.250  0.80219   
> > habit2       1.10627    0.41607   2.659  0.00784 **
> > habit3       0.92578    0.78141   1.185  0.23611   
> > habit4       0.14383    0.38477   0.374  0.70856   
> > ---
> > Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> 
> 
> This shows that with habit the model has a AIC value of 1406 
> and habit2 has the significant effect on the threat status of 
> a species?
> 
> Now model 2
> > model2 <-lmer(threatornot~1+(1|a/b) + habit + 
> breedingsystem, family=binomial)
> > Generalized linear mixed model fit by the Laplace approximation 
> > Formula: threatornot ~ 1 + (1 | a/b) + habit + breedingsystem 
> >  AIC  BIC logLik deviance
> > 1408 1449 -696.2     1392
> > Random effects:
> > Groups       Name        Variance Std.Dev.
> > family:order (Intercept) 0.67836  0.82363 
> > order        (Intercept) 0.00000  0.00000
> > Number of obs: 1116, groups: family:order, 43; order, 9
> > 
> > Fixed effects:
> >                Estimate Std. Error z value Pr(>|z|)   
> > (Intercept)      0.17398    0.39138   0.444  0.65665   
> > habit2           1.15687    0.41943   2.758  0.00581 **
> > habit3           0.92017    0.78158   1.177  0.23907   
> > habit4          -0.01673    0.43150  -0.039  0.96907   
> > breedingsystem2 -0.18615    0.37849  -0.492  0.62285   
> > breedingsystem3 -0.42513    0.40652  -1.046  0.29567   
> > ---
> > Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
> 
> 
> This shows that adding breeding system to the model doesn't 
> fit the data any better (the AIC is higher), therefore 
> breedingsystem has no significant effect on the threat status 
> of a species
> 
> Under this simple example i can conclude that the habit of a 
> species is significant in determining how threatened the 
> species is and in particular species from habit2 are more 
> threatened than those not from habit2.
> 
> Are these inferences justified or am i missing something?
> 
> Thanks
> 
> 
> 
> 
> On 3 Aug 2010, at 08:50, Andrew Dolman wrote:
> 
> I don't get it. How can you fit the model with just 1 of three levels
> of factor "habitat" and have the same number of observations as when
> you run the model with all three? (It must have at least 2 levels to
> fit anyway) Also, in the first example you have 4 levels of habitat.
> 
> Are they different levels of habitat resolution? e.g.
> 
> Aquatic - non aquatic
> Aquatic - Terrestrial - Epiphytic
> Aquatic - Terrestrial - Epiphytic - Up elephant's noses
> 
> 
> Please read the posting guide and include proper examples of what you
> are doing and what the data look like.
> 
> 
> andydolman at gmail.com
> 
> 
> 
> On 3 August 2010 08:48, Peter Francis <peterfrancis at me.com> wrote:
> > Hi David and Ben, thanks for your help -
> > 
> > I was worried this would make little sense!
> > 
> > I have set out my candidate models
> > 
> > A+B+C+D
> > B+C+D
> > A+C+D
> > etc etc
> > 
> > And am running through them in lmer. Factor A for instance 
> is Habit, which takes 3 forms - aquatic, terrestrial or epiphyte.
> > 
> > When i run the model with A as a factor i get the breakdown 
> of the individual levels habitat 1, habitat 2 and habitat 3 
> and a corresponding AIC score. However if i just run it with 
> habitat 3 - aquatic - i get a lower AIC score, therefore the 
> model fits the data better?
> > 
> > I am unsure how to, without splitting my factors into their 
> constituent levels at the beginning - A1+A2+A3 + B1 + B2 etc, 
> arrive at the model with the lowest AIC?
> > 
> > Thanks
> > 
> > Peter
> > 
> > On 3 Aug 2010, at 00:16, David Duffy wrote:
> > 
> > On Mon, 2 Aug 2010, Peter Francis wrote:
> > 
> >> I have many multi level factors i.e habit - aquatic, 
> terrestrial, epiphyte etc
> >> 
> >> I ran the model with habit as a factor
> >> 
> >>> model111 <-lmer(threatornot~1+(1|a/b) + habit, family=binomial)
> >> 
> >>> Generalized linear mixed model fit by the Laplace approximation
> >>> Formula: threatornot ~ 1 + (1 | order/family) + habit
> >>> AIC  BIC logLik deviance
> >>> 1406 1436 -696.9     1394
> >>> Random effects:
> >>> Groups       Name        Variance   Std.Dev.
> >>> family:order (Intercept) 6.9892e-01 8.3602e-01
> >>> order        (Intercept) 4.2292e-14 2.0565e-07
> >>> Number of obs: 1116, groups: family:order, 43; order, 9
> >>> 
> >>> Fixed effects:
> >>>           Estimate Std. Error z value Pr(>|z|)
> >>> (Intercept) -0.04803    0.19174  -0.250  0.80219
> >>> habit2       1.10627    0.41607   2.659  0.00784 **
> >>> habit3       0.92578    0.78141   1.185  0.23611
> >>> habit4       0.14383    0.38477   0.374  0.70856
> >> 
> >> ---
> >> Which had a AIC of 1406
> >> 
> >> I then re-ran the model with only aquatic and got a lower 
> AIC value - which i guess is to be expected as aquatic is 
> highly significant and aquatic species are more prone to 
> threat ( my response).
> >> 
> >> 
> >>>> model112 <-lmer(threatornot~1+(1|a/b) + aquatic, family=binomial)
> >>>> model112
> >>> Generalized linear mixed model fit by the Laplace approximation
> >>> Formula: threatornot ~ 1 + (1 | order/family) + aquatic
> >>> AIC  BIC logLik deviance
> >>> 1395 1415 -693.4     1387
> >>> Random effects:
> >>> Groups       Name        Variance Std.Dev.
> >>> family:order (Intercept) 0.60007  0.77464
> >>> order        (Intercept) 0.00000  0.00000
> >>> Number of obs: 1116, groups: family:order, 43; order, 9
> >>> 
> >>> Fixed effects:
> >>>           Estimate Std. Error z value Pr(>|z|)
> >>> (Intercept)   0.1572     0.1827   0.860 0.389613
> >>> aquatic      -0.6683     0.1737  -3.847 0.000119 ***
> >> 
> >> My question is - when i developed the candidate models i 
> thought using multilevel factors would be OK and i would be 
> able to tease out the individual levels. If i split the 
> factors into levels from the beginning then i am left with a 
> huge amount of candidate models? This would not be a problem 
> in stepwise regression as i could just remove the habit with 
> the least significant P Value.
> >> 
> >> If i remove habits i "feel" are unimportant from the 
> beginning i feel i would be limiting the model too much.
> >> 
> >> I hope this makes sense!
> > 
> > I don't understand at all, I'm afraid.  Is aquatic the same 
> as habit=2, or something?  If so, there is something funny 
> about the model fits.
> > 
> > If family and order are "nuisance" variables, then a 
> stepwise approach is quite reasonable (if you are someone who 
> thinks stepwise regression is reasonable, of course ;)).
> > 
> > Just 2c, David Duffy.
> > 
> > --
> > | David Duffy (MBBS PhD)                                   
>      ,-_|\
> > | email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: 
> -0101  /     *
> > | Epidemiology Unit, Queensland Institute of Medical
> Research   \_,-._/
> > | 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 
> 4D0B994A v
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

Druk dit bericht a.u.b. niet onnodig af.
Please do not print this message unnecessarily.

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From Thierry.ONKELINX at inbo.be  Tue Aug  3 12:19:22 2010
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 3 Aug 2010 12:19:22 +0200
Subject: [R-sig-ME] Multi-level qualitative (fixed-effects) factors
In-Reply-To: <51A15AB0-8BB1-49C4-8815-D92DF84CA518@me.com>
References: <59FC717C-0510-4E58-A4FE-4790322A0234@me.com>
	<6B10024D-0AE7-4429-81BD-D77B22D13025@me.com>
	<3DB16098F738284D8DBEB2FC3699163821EA97@inboexch.inbo.be>
	<51A15AB0-8BB1-49C4-8815-D92DF84CA518@me.com>
Message-ID: <3DB16098F738284D8DBEB2FC3699163821EABD@inboexch.inbo.be>

Dear Peter,

You could use glht() from the multcomp package to do a Tukey test or
test several prespecified hypotheses on your model. 

I don't known is fitting a complex model in order to find a 'profile'
for treatened species is such a good idea. The model will return the
probability of a species being threatened depending on the fixed and
random effects. So how would you separate threatened species from
non-threatened species based on the model?

You might want to do some reading upto the difference between GEE and
GLMM. The first provides marginal ('population') estimates. In your case
it is what is happening in the average family. The latter gives
estimates conditional on the random effects. So that is what is
happening after you that the effect that a specific family into account.
I'm not sure which of the two is the most appropriate for your question.

Best regards,

Thierry

PS Please keep the mailing list in cc when replying.

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey
  

> -----Oorspronkelijk bericht-----
> Van: Peter Francis [mailto:peterfrancis at me.com] 
> Verzonden: dinsdag 3 augustus 2010 11:27
> Aan: ONKELINX, Thierry
> Onderwerp: Re: [R-sig-ME] Multi-level qualitative 
> (fixed-effects) factors
> 
> Dear Thierry,
> 
> I thought that maybe the case! Thank you very much.
> 
> I am relatively new too this field, can a Tukey test be 
> implemented in R and at what point should i do it? Is there a 
> sample workflow?
> 
> i want to be able conclude for example that - species from 
> habitat 1 are more threatened than those from habitat 2 etc. 
> I have multiple factors with multiple levels so by the end i 
> would like a profile of what a threatened species "looks" 
> like compared to a non threatened.
> 
> I am sorry for the questions and appreciate any advice given.
> 
> Peter
> On 3 Aug 2010, at 10:18, ONKELINX, Thierry wrote:
> 
> Dear Peter,
> 
> Your inference in not correct. The significance you get from 
> habitat2 is only the comparison between habitat2 and the 
> reference level (habitat1?). You can conclude that only
> habitat2 is significantly different from habitat1 and habitat 
> 3 vs 1 and habitat 4 vs 1 is not significant. You cannot 
> compare 2 vs 3, 2 vs 4 and 3 vs 4. That would require 
> multiple comparisons (cfr Tukey).
> 
> Best regards,
> 
> Thierry
> 
> 
> --------------------------------------------------------------
> ----------
> ----
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek
> team Biometrie & Kwaliteitszorg
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium
> 
> Research Institute for Nature and Forest team Biometrics & 
> Quality Assurance Gaverstraat 4 9500 Geraardsbergen Belgium
> 
> tel. + 32 54/436 185
> Thierry.Onkelinx at inbo.be
> www.inbo.be
> 
> To call in the statistician after the experiment is done may 
> be no more than asking him to perform a post-mortem
> examination: he may be able to say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
> 
> The plural of anecdote is not data.
> ~ Roger Brinner
> 
> The combination of some data and an aching desire for an 
> answer does not ensure that a reasonable answer can be 
> extracted from a given body of data.
> ~ John Tukey
> 
> 
> > -----Oorspronkelijk bericht-----
> > Van: r-sig-mixed-models-bounces at r-project.org
> > [mailto:r-sig-mixed-models-bounces at r-project.org] Namens 
> Peter Francis
> > Verzonden: dinsdag 3 augustus 2010 10:53
> > Aan: R-mixed models mailing list
> > Onderwerp: [R-sig-ME] Multi-level qualitative 
> (fixed-effects) factors
> > 
> > Sorry to everyone,
> > 
> > I guess i should rephrase this completely as i think i am 
> not getting 
> > across what i want to ( my fault, i apologise for the spam!).
> > 
> > I am trying to discover which traits correlate with 
> threatened or not 
> > (binary response- i do have different levele of threat but 
> am unsure 
> > how to model continuos response variables in GLMM - quasi poisson?)
> > 
> > I shall work through a quick example and would appreciate it if you 
> > could tell me if my conclusions are justified.
> > 
> > Lets just say for ease i am have two models -  i can send
> > str(traits) etc if required -
> > 
> >> model1 <-lmer(threatornot~1+(1|a/b) + habit, family=binomial)
> >> 
> >> Generalized linear mixed model fit by the Laplace approximation
> >> Formula: threatornot ~ 1 + (1 | a/b) + habit  AIC  BIC
> > logLik deviance
> >> 1406 1436 -696.9     1394
> >> Random effects:
> >> Groups       Name        Variance   Std.Dev.  
> >> family:order (Intercept) 6.9892e-01 8.3602e-01
> >> order        (Intercept) 4.2292e-14 2.0565e-07
> >> Number of obs: 1116, groups: family:order, 43; order, 9
> >> 
> >> Fixed effects:
> >>           Estimate Std. Error z value Pr(>|z|)   
> >> (Intercept) -0.04803    0.19174  -0.250  0.80219   
> >> habit2       1.10627    0.41607   2.659  0.00784 **
> >> habit3       0.92578    0.78141   1.185  0.23611   
> >> habit4       0.14383    0.38477   0.374  0.70856   
> >> ---
> >> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> > 
> > 
> > This shows that with habit the model has a AIC value of 1406 and 
> > habit2 has the significant effect on the threat status of a species?
> > 
> > Now model 2
> >> model2 <-lmer(threatornot~1+(1|a/b) + habit +
> > breedingsystem, family=binomial)
> >> Generalized linear mixed model fit by the Laplace approximation
> >> Formula: threatornot ~ 1 + (1 | a/b) + habit + breedingsystem AIC  
> >> BIC logLik deviance
> >> 1408 1449 -696.2     1392
> >> Random effects:
> >> Groups       Name        Variance Std.Dev.
> >> family:order (Intercept) 0.67836  0.82363 
> >> order        (Intercept) 0.00000  0.00000
> >> Number of obs: 1116, groups: family:order, 43; order, 9
> >> 
> >> Fixed effects:
> >>               Estimate Std. Error z value Pr(>|z|)   
> >> (Intercept)      0.17398    0.39138   0.444  0.65665   
> >> habit2           1.15687    0.41943   2.758  0.00581 **
> >> habit3           0.92017    0.78158   1.177  0.23907   
> >> habit4          -0.01673    0.43150  -0.039  0.96907   
> >> breedingsystem2 -0.18615    0.37849  -0.492  0.62285   
> >> breedingsystem3 -0.42513    0.40652  -1.046  0.29567   
> >> ---
> >> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> > 
> > 
> > This shows that adding breeding system to the model doesn't fit the 
> > data any better (the AIC is higher), therefore 
> breedingsystem has no 
> > significant effect on the threat status of a species
> > 
> > Under this simple example i can conclude that the habit of 
> a species 
> > is significant in determining how threatened the species is and in 
> > particular species from habit2 are more threatened than 
> those not from 
> > habit2.
> > 
> > Are these inferences justified or am i missing something?
> > 
> > Thanks
> > 
> > 
> > 
> > 
> > On 3 Aug 2010, at 08:50, Andrew Dolman wrote:
> > 
> > I don't get it. How can you fit the model with just 1 of 
> three levels 
> > of factor "habitat" and have the same number of
> observations as when 
> > you run the model with all three? (It must have at least 2 
> levels to 
> > fit anyway) Also, in the first example you have 4 levels of habitat.
> > 
> > Are they different levels of habitat resolution? e.g.
> > 
> > Aquatic - non aquatic
> > Aquatic - Terrestrial - Epiphytic
> > Aquatic - Terrestrial - Epiphytic - Up elephant's noses
> > 
> > 
> > Please read the posting guide and include proper examples 
> of what you 
> > are doing and what the data look like.
> > 
> > 
> > andydolman at gmail.com
> > 
> > 
> > 
> > On 3 August 2010 08:48, Peter Francis <peterfrancis at me.com> wrote:
> >> Hi David and Ben, thanks for your help -
> >> 
> >> I was worried this would make little sense!
> >> 
> >> I have set out my candidate models
> >> 
> >> A+B+C+D
> >> B+C+D
> >> A+C+D
> >> etc etc
> >> 
> >> And am running through them in lmer. Factor A for instance
> > is Habit, which takes 3 forms - aquatic, terrestrial or epiphyte.
> >> 
> >> When i run the model with A as a factor i get the breakdown
> > of the individual levels habitat 1, habitat 2 and habitat 3 and a 
> > corresponding AIC score. However if i just run it with habitat 3 - 
> > aquatic - i get a lower AIC score, therefore the model fits 
> the data 
> > better?
> >> 
> >> I am unsure how to, without splitting my factors into their
> > constituent levels at the beginning - A1+A2+A3 + B1 + B2 
> etc, arrive 
> > at the model with the lowest AIC?
> >> 
> >> Thanks
> >> 
> >> Peter
> >> 
> >> On 3 Aug 2010, at 00:16, David Duffy wrote:
> >> 
> >> On Mon, 2 Aug 2010, Peter Francis wrote:
> >> 
> >>> I have many multi level factors i.e habit - aquatic,
> > terrestrial, epiphyte etc
> >>> 
> >>> I ran the model with habit as a factor
> >>> 
> >>>> model111 <-lmer(threatornot~1+(1|a/b) + habit, family=binomial)
> >>> 
> >>>> Generalized linear mixed model fit by the Laplace approximation
> >>>> Formula: threatornot ~ 1 + (1 | order/family) + habit AIC  BIC 
> >>>> logLik deviance
> >>>> 1406 1436 -696.9     1394
> >>>> Random effects:
> >>>> Groups       Name        Variance   Std.Dev.
> >>>> family:order (Intercept) 6.9892e-01 8.3602e-01
> >>>> order        (Intercept) 4.2292e-14 2.0565e-07
> >>>> Number of obs: 1116, groups: family:order, 43; order, 9
> >>>> 
> >>>> Fixed effects:
> >>>>          Estimate Std. Error z value Pr(>|z|)
> >>>> (Intercept) -0.04803    0.19174  -0.250  0.80219
> >>>> habit2       1.10627    0.41607   2.659  0.00784 **
> >>>> habit3       0.92578    0.78141   1.185  0.23611
> >>>> habit4       0.14383    0.38477   0.374  0.70856
> >>> 
> >>> ---
> >>> Which had a AIC of 1406
> >>> 
> >>> I then re-ran the model with only aquatic and got a lower
> > AIC value - which i guess is to be expected as aquatic is highly 
> > significant and aquatic species are more prone to threat ( my 
> > response).
> >>> 
> >>> 
> >>>>> model112 <-lmer(threatornot~1+(1|a/b) + aquatic, 
> family=binomial)
> >>>>> model112
> >>>> Generalized linear mixed model fit by the Laplace approximation
> >>>> Formula: threatornot ~ 1 + (1 | order/family) + aquatic AIC  BIC 
> >>>> logLik deviance
> >>>> 1395 1415 -693.4     1387
> >>>> Random effects:
> >>>> Groups       Name        Variance Std.Dev.
> >>>> family:order (Intercept) 0.60007  0.77464
> >>>> order        (Intercept) 0.00000  0.00000
> >>>> Number of obs: 1116, groups: family:order, 43; order, 9
> >>>> 
> >>>> Fixed effects:
> >>>>          Estimate Std. Error z value Pr(>|z|)
> >>>> (Intercept)   0.1572     0.1827   0.860 0.389613
> >>>> aquatic      -0.6683     0.1737  -3.847 0.000119 ***
> >>> 
> >>> My question is - when i developed the candidate models i
> > thought using multilevel factors would be OK and i would be able to 
> > tease out the individual levels. If i split the factors into levels 
> > from the beginning then i am left with a huge amount of candidate 
> > models? This would not be a problem in stepwise regression 
> as i could 
> > just remove the habit with the least significant P Value.
> >>> 
> >>> If i remove habits i "feel" are unimportant from the
> > beginning i feel i would be limiting the model too much.
> >>> 
> >>> I hope this makes sense!
> >> 
> >> I don't understand at all, I'm afraid.  Is aquatic the same
> > as habit=2, or something?  If so, there is something funny 
> about the 
> > model fits.
> >> 
> >> If family and order are "nuisance" variables, then a
> > stepwise approach is quite reasonable (if you are someone 
> who thinks 
> > stepwise regression is reasonable, of course ;)).
> >> 
> >> Just 2c, David Duffy.
> >> 
> >> --
> >> | David Duffy (MBBS PhD)                                  
> >     ,-_|\
> >> | email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: 
> > -0101  /     *
> >> | Epidemiology Unit, Queensland Institute of Medical
> > Research   \_,-._/
> >> | 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG
> > 4D0B994A v
> >> 
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list 
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> 
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > 
> 
> Druk dit bericht a.u.b. niet onnodig af.
> Please do not print this message unnecessarily.
> 
> Dit bericht en eventuele bijlagen geven enkel de visie van de 
> schrijver weer en binden het INBO onder geen enkel beding, 
> zolang dit bericht niet bevestigd is door een geldig
> ondertekend document. The views expressed in  this message 
> and any annex are purely those of the writer and may not be 
> regarded as stating an official position of INBO, as long as 
> the message is not confirmed by a duly signed document.
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 

Druk dit bericht a.u.b. niet onnodig af.
Please do not print this message unnecessarily.

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From peterfrancis at me.com  Tue Aug  3 12:28:20 2010
From: peterfrancis at me.com (Peter Francis)
Date: Tue, 03 Aug 2010 11:28:20 +0100
Subject: [R-sig-ME] Multi-level qualitative (fixed-effects) factors
In-Reply-To: <3DB16098F738284D8DBEB2FC3699163821EABD@inboexch.inbo.be>
References: <59FC717C-0510-4E58-A4FE-4790322A0234@me.com>
	<6B10024D-0AE7-4429-81BD-D77B22D13025@me.com>
	<3DB16098F738284D8DBEB2FC3699163821EA97@inboexch.inbo.be>
	<51A15AB0-8BB1-49C4-8815-D92DF84CA518@me.com>
	<3DB16098F738284D8DBEB2FC3699163821EABD@inboexch.inbo.be>
Message-ID: <807B785E-EE27-4F42-962E-504373E2A629@me.com>

Thanks for this,

I need a random effect, to control for the phylogenetic relationships of the species, they are part of a hierarchical structure. Thats i why i went down the glmm line.

> So how would you separate threatened species from
> non-threatened species based on the model?

I was under the impression that if i modelled threat or not - against traits, the significant traits would relate to those species that are threatened?

The challenge from here is using the "best"  model generated by my training data to test the effectiveness of the model on my test data. I.E how can the model be used in a predictive sense - is it this you feel would be difficult?

Thanks

Peter 
On 3 Aug 2010, at 11:19, ONKELINX, Thierry wrote:

Dear Peter,

You could use glht() from the multcomp package to do a Tukey test or
test several prespecified hypotheses on your model. 

I don't known is fitting a complex model in order to find a 'profile'
for treatened species is such a good idea. The model will return the
probability of a species being threatened depending on the fixed and
random effects. So how would you separate threatened species from
non-threatened species based on the model?

You might want to do some reading upto the difference between GEE and
GLMM. The first provides marginal ('population') estimates. In your case
it is what is happening in the average family. The latter gives
estimates conditional on the random effects. So that is what is
happening after you that the effect that a specific family into account.
I'm not sure which of the two is the most appropriate for your question.

Best regards,

Thierry

PS Please keep the mailing list in cc when replying.

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey


> -----Oorspronkelijk bericht-----
> Van: Peter Francis [mailto:peterfrancis at me.com] 
> Verzonden: dinsdag 3 augustus 2010 11:27
> Aan: ONKELINX, Thierry
> Onderwerp: Re: [R-sig-ME] Multi-level qualitative 
> (fixed-effects) factors
> 
> Dear Thierry,
> 
> I thought that maybe the case! Thank you very much.
> 
> I am relatively new too this field, can a Tukey test be 
> implemented in R and at what point should i do it? Is there a 
> sample workflow?
> 
> i want to be able conclude for example that - species from 
> habitat 1 are more threatened than those from habitat 2 etc. 
> I have multiple factors with multiple levels so by the end i 
> would like a profile of what a threatened species "looks" 
> like compared to a non threatened.
> 
> I am sorry for the questions and appreciate any advice given.
> 
> Peter
> On 3 Aug 2010, at 10:18, ONKELINX, Thierry wrote:
> 
> Dear Peter,
> 
> Your inference in not correct. The significance you get from 
> habitat2 is only the comparison between habitat2 and the 
> reference level (habitat1?). You can conclude that only 
> habitat2 is significantly different from habitat1 and habitat 
> 3 vs 1 and habitat 4 vs 1 is not significant. You cannot 
> compare 2 vs 3, 2 vs 4 and 3 vs 4. That would require 
> multiple comparisons (cfr Tukey).
> 
> Best regards,
> 
> Thierry
> 
> 
> --------------------------------------------------------------
> ----------
> ----
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek
> team Biometrie & Kwaliteitszorg
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium
> 
> Research Institute for Nature and Forest team Biometrics & 
> Quality Assurance Gaverstraat 4 9500 Geraardsbergen Belgium
> 
> tel. + 32 54/436 185
> Thierry.Onkelinx at inbo.be
> www.inbo.be
> 
> To call in the statistician after the experiment is done may 
> be no more than asking him to perform a post-mortem 
> examination: he may be able to say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
> 
> The plural of anecdote is not data.
> ~ Roger Brinner
> 
> The combination of some data and an aching desire for an 
> answer does not ensure that a reasonable answer can be 
> extracted from a given body of data.
> ~ John Tukey
> 
> 
>> -----Oorspronkelijk bericht-----
>> Van: r-sig-mixed-models-bounces at r-project.org
>> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens 
> Peter Francis
>> Verzonden: dinsdag 3 augustus 2010 10:53
>> Aan: R-mixed models mailing list
>> Onderwerp: [R-sig-ME] Multi-level qualitative 
> (fixed-effects) factors
>> 
>> Sorry to everyone,
>> 
>> I guess i should rephrase this completely as i think i am 
> not getting 
>> across what i want to ( my fault, i apologise for the spam!).
>> 
>> I am trying to discover which traits correlate with 
> threatened or not 
>> (binary response- i do have different levele of threat but 
> am unsure 
>> how to model continuos response variables in GLMM - quasi poisson?)
>> 
>> I shall work through a quick example and would appreciate it if you 
>> could tell me if my conclusions are justified.
>> 
>> Lets just say for ease i am have two models -  i can send
>> str(traits) etc if required -
>> 
>>> model1 <-lmer(threatornot~1+(1|a/b) + habit, family=binomial)
>>> 
>>> Generalized linear mixed model fit by the Laplace approximation
>>> Formula: threatornot ~ 1 + (1 | a/b) + habit  AIC  BIC
>> logLik deviance
>>> 1406 1436 -696.9     1394
>>> Random effects:
>>> Groups       Name        Variance   Std.Dev.  
>>> family:order (Intercept) 6.9892e-01 8.3602e-01
>>> order        (Intercept) 4.2292e-14 2.0565e-07
>>> Number of obs: 1116, groups: family:order, 43; order, 9
>>> 
>>> Fixed effects:
>>>          Estimate Std. Error z value Pr(>|z|)   
>>> (Intercept) -0.04803    0.19174  -0.250  0.80219   
>>> habit2       1.10627    0.41607   2.659  0.00784 **
>>> habit3       0.92578    0.78141   1.185  0.23611   
>>> habit4       0.14383    0.38477   0.374  0.70856   
>>> ---
>>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>> 
>> 
>> This shows that with habit the model has a AIC value of 1406 and 
>> habit2 has the significant effect on the threat status of a species?
>> 
>> Now model 2
>>> model2 <-lmer(threatornot~1+(1|a/b) + habit +
>> breedingsystem, family=binomial)
>>> Generalized linear mixed model fit by the Laplace approximation
>>> Formula: threatornot ~ 1 + (1 | a/b) + habit + breedingsystem AIC  
>>> BIC logLik deviance
>>> 1408 1449 -696.2     1392
>>> Random effects:
>>> Groups       Name        Variance Std.Dev.
>>> family:order (Intercept) 0.67836  0.82363 
>>> order        (Intercept) 0.00000  0.00000
>>> Number of obs: 1116, groups: family:order, 43; order, 9
>>> 
>>> Fixed effects:
>>>              Estimate Std. Error z value Pr(>|z|)   
>>> (Intercept)      0.17398    0.39138   0.444  0.65665   
>>> habit2           1.15687    0.41943   2.758  0.00581 **
>>> habit3           0.92017    0.78158   1.177  0.23907   
>>> habit4          -0.01673    0.43150  -0.039  0.96907   
>>> breedingsystem2 -0.18615    0.37849  -0.492  0.62285   
>>> breedingsystem3 -0.42513    0.40652  -1.046  0.29567   
>>> ---
>>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>> 
>> 
>> This shows that adding breeding system to the model doesn't fit the 
>> data any better (the AIC is higher), therefore 
> breedingsystem has no 
>> significant effect on the threat status of a species
>> 
>> Under this simple example i can conclude that the habit of 
> a species 
>> is significant in determining how threatened the species is and in 
>> particular species from habit2 are more threatened than 
> those not from 
>> habit2.
>> 
>> Are these inferences justified or am i missing something?
>> 
>> Thanks
>> 
>> 
>> 
>> 
>> On 3 Aug 2010, at 08:50, Andrew Dolman wrote:
>> 
>> I don't get it. How can you fit the model with just 1 of 
> three levels 
>> of factor "habitat" and have the same number of 
> observations as when 
>> you run the model with all three? (It must have at least 2 
> levels to 
>> fit anyway) Also, in the first example you have 4 levels of habitat.
>> 
>> Are they different levels of habitat resolution? e.g.
>> 
>> Aquatic - non aquatic
>> Aquatic - Terrestrial - Epiphytic
>> Aquatic - Terrestrial - Epiphytic - Up elephant's noses
>> 
>> 
>> Please read the posting guide and include proper examples 
> of what you 
>> are doing and what the data look like.
>> 
>> 
>> andydolman at gmail.com
>> 
>> 
>> 
>> On 3 August 2010 08:48, Peter Francis <peterfrancis at me.com> wrote:
>>> Hi David and Ben, thanks for your help -
>>> 
>>> I was worried this would make little sense!
>>> 
>>> I have set out my candidate models
>>> 
>>> A+B+C+D
>>> B+C+D
>>> A+C+D
>>> etc etc
>>> 
>>> And am running through them in lmer. Factor A for instance
>> is Habit, which takes 3 forms - aquatic, terrestrial or epiphyte.
>>> 
>>> When i run the model with A as a factor i get the breakdown
>> of the individual levels habitat 1, habitat 2 and habitat 3 and a 
>> corresponding AIC score. However if i just run it with habitat 3 - 
>> aquatic - i get a lower AIC score, therefore the model fits 
> the data 
>> better?
>>> 
>>> I am unsure how to, without splitting my factors into their
>> constituent levels at the beginning - A1+A2+A3 + B1 + B2 
> etc, arrive 
>> at the model with the lowest AIC?
>>> 
>>> Thanks
>>> 
>>> Peter
>>> 
>>> On 3 Aug 2010, at 00:16, David Duffy wrote:
>>> 
>>> On Mon, 2 Aug 2010, Peter Francis wrote:
>>> 
>>>> I have many multi level factors i.e habit - aquatic,
>> terrestrial, epiphyte etc
>>>> 
>>>> I ran the model with habit as a factor
>>>> 
>>>>> model111 <-lmer(threatornot~1+(1|a/b) + habit, family=binomial)
>>>> 
>>>>> Generalized linear mixed model fit by the Laplace approximation
>>>>> Formula: threatornot ~ 1 + (1 | order/family) + habit AIC  BIC 
>>>>> logLik deviance
>>>>> 1406 1436 -696.9     1394
>>>>> Random effects:
>>>>> Groups       Name        Variance   Std.Dev.
>>>>> family:order (Intercept) 6.9892e-01 8.3602e-01
>>>>> order        (Intercept) 4.2292e-14 2.0565e-07
>>>>> Number of obs: 1116, groups: family:order, 43; order, 9
>>>>> 
>>>>> Fixed effects:
>>>>>         Estimate Std. Error z value Pr(>|z|)
>>>>> (Intercept) -0.04803    0.19174  -0.250  0.80219
>>>>> habit2       1.10627    0.41607   2.659  0.00784 **
>>>>> habit3       0.92578    0.78141   1.185  0.23611
>>>>> habit4       0.14383    0.38477   0.374  0.70856
>>>> 
>>>> ---
>>>> Which had a AIC of 1406
>>>> 
>>>> I then re-ran the model with only aquatic and got a lower
>> AIC value - which i guess is to be expected as aquatic is highly 
>> significant and aquatic species are more prone to threat ( my 
>> response).
>>>> 
>>>> 
>>>>>> model112 <-lmer(threatornot~1+(1|a/b) + aquatic, 
> family=binomial)
>>>>>> model112
>>>>> Generalized linear mixed model fit by the Laplace approximation
>>>>> Formula: threatornot ~ 1 + (1 | order/family) + aquatic AIC  BIC 
>>>>> logLik deviance
>>>>> 1395 1415 -693.4     1387
>>>>> Random effects:
>>>>> Groups       Name        Variance Std.Dev.
>>>>> family:order (Intercept) 0.60007  0.77464
>>>>> order        (Intercept) 0.00000  0.00000
>>>>> Number of obs: 1116, groups: family:order, 43; order, 9
>>>>> 
>>>>> Fixed effects:
>>>>>         Estimate Std. Error z value Pr(>|z|)
>>>>> (Intercept)   0.1572     0.1827   0.860 0.389613
>>>>> aquatic      -0.6683     0.1737  -3.847 0.000119 ***
>>>> 
>>>> My question is - when i developed the candidate models i
>> thought using multilevel factors would be OK and i would be able to 
>> tease out the individual levels. If i split the factors into levels 
>> from the beginning then i am left with a huge amount of candidate 
>> models? This would not be a problem in stepwise regression 
> as i could 
>> just remove the habit with the least significant P Value.
>>>> 
>>>> If i remove habits i "feel" are unimportant from the
>> beginning i feel i would be limiting the model too much.
>>>> 
>>>> I hope this makes sense!
>>> 
>>> I don't understand at all, I'm afraid.  Is aquatic the same
>> as habit=2, or something?  If so, there is something funny 
> about the 
>> model fits.
>>> 
>>> If family and order are "nuisance" variables, then a
>> stepwise approach is quite reasonable (if you are someone 
> who thinks 
>> stepwise regression is reasonable, of course ;)).
>>> 
>>> Just 2c, David Duffy.
>>> 
>>> --
>>> | David Duffy (MBBS PhD)                                   
>>    ,-_|\
>>> | email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: 
>> -0101  /     *
>>> | Epidemiology Unit, Queensland Institute of Medical
>> Research   \_,-._/
>>> | 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG
>> 4D0B994A v
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list 
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> Druk dit bericht a.u.b. niet onnodig af.
> Please do not print this message unnecessarily.
> 
> Dit bericht en eventuele bijlagen geven enkel de visie van de 
> schrijver weer en binden het INBO onder geen enkel beding, 
> zolang dit bericht niet bevestigd is door een geldig 
> ondertekend document. The views expressed in  this message 
> and any annex are purely those of the writer and may not be 
> regarded as stating an official position of INBO, as long as 
> the message is not confirmed by a duly signed document.
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 

Druk dit bericht a.u.b. niet onnodig af.
Please do not print this message unnecessarily.

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From Mike.Lawrence at dal.ca  Tue Aug  3 14:45:04 2010
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Tue, 3 Aug 2010 09:45:04 -0300
Subject: [R-sig-ME] gamm4 model formulation clarification
In-Reply-To: <AANLkTi=N9tz-CcNbzkWWivnD0Yit=ipznSWoe+Mx_3gB@mail.gmail.com>
References: <AANLkTims1fHToCt7RyRN1jdVhNbXZuUzM5SWRXq2+Y2T@mail.gmail.com> 
	<AANLkTinRyvm=qj=Pooz1QOJMN-a7bJoQMjJa_Bxn4qLD@mail.gmail.com> 
	<AANLkTimBL-zOQueKayB6Gf-_H3nvHZdE+3UOqOW+CTQE@mail.gmail.com> 
	<AANLkTi=ZzfJKsNZyG_3jmx6DdSJ+Eb97qx9VF1qw8FoH@mail.gmail.com> 
	<AANLkTi=N9tz-CcNbzkWWivnD0Yit=ipznSWoe+Mx_3gB@mail.gmail.com>
Message-ID: <AANLkTi=qQ1R8xb3urCk7L9LWKR8BLKu7ea_XD3s4=yWL@mail.gmail.com>

Oops. It seems that my logic in computing the CI for the difference
scores in the "solution" I posted was seriously flawed (see:
http://stats.stackexchange.com/questions/1169/ci-for-a-difference-based-on-independent-cis).
So, predict.gam(..., se.fit=T) produces predicted values and and SEs
for those values; any suggestions on how to compute the proper CI for
a difference between such predicted values given the SEs?

On Mon, Aug 2, 2010 at 2:44 PM, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
> On Sat, Jul 31, 2010 at 9:42 PM, Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
>> Also, I'm just now thinking that neither approach really gets at what
>> I want to test; what I want to test whether the model is improved by
>> (1) letting the smooth vary as a function of design, (2) letting the
>> smooth vary as a function of ddB, and (3) letting the smooth vary as a
>> function of both design & ddB. That is, is there a design*soa
>> interaction, a ddB*soa interaction and/or a design*ddB*soa
>> interaction? In the case of support for any of these interactions, I'd
>> also be interested in pinpointing the timeframe over which the
>> interactions take place.
>
> After playing a bit, I wonder if anyone has any input on the following
> "solution" I'm currently working with. First, a change in variable
> names to simplify things: A & B are both 2-level factor variables, C
> is a continuous numeric variable that needs smoothing, D is the
> dependent variable, and E is the random effect (in my case, human
> participants in an experiment).
>
> To assess the A*C interaction:
>
> 1) turn B into a numeric centered on zero (-1,1):
> my_data$B2 = as.numeric(my_data$B2)-1.5
>
> 2) fit a gamm, including the A*B2 interaction and smoothing C
> independently per level of A:
> AC_fit = gamm4(
> ? ?formula = D ~ A*B2 + s(C,by=A)
> ? ?, random = ~ (1|E)
> ? ?, data = my_data
> )
>
> 3) Obtain predictions & 95% CI from the model for the 2 levels of A
> across the range of C
> AC_pred = expand.grid(
> ? ?A = factor(levels(my_data$A),levels=levels(my_data$A))
> ? ?, B2 = 0
> ? ?, C = seq(min(my_data$C),max(my_data$X),length.out=1e3)
> )
> from_predict = predict(AC_fit,newdata=AC_pred,se.fit=T)
> AC_pred$D = from_predict$fit
> AC_pred$se = from_predict$se.fit
> AC_pred$lo_95ci = AC_pred$D - AC_pred$se*1.96
> AC_pred$hi_95ci = AC_pred$D + AC_pred$se*1.96
>
> 4) You could plot the "pred" data now, plotting D as a function of C
> and split by levels of A, but this will include the main effects of
> both A and C, obscuring visualization of the interaction.
>
> 5) Compute the A*C interaction by computing the difference between the
> levels of A at each value of C:
> AC_effect = ddply(
> ? ?.data = AC_pred
> ? ?, .variables = .(C)
> ? ?, .fun = function(x){
> ? ? ? ?to_return = data.frame(
> ? ? ? ? ? ?A_effect = x$D[x$A==levels(x$A)[1]] - x$D[x$A==levels(x$A)[2]]
> ? ? ? ? ? ?, lo_95ci = min(
> ? ? ? ? ? ? ? ?x$hi_95ci[x$A==levels(x$A)[1]] - x$lo_95ci[x$A==levels(x$A)[2]]
> ? ? ? ? ? ? ? ?, x$lo_95ci[x$A==levels(x$A)[1]] -
> x$hi_95ci[x$A==levels(x$A)[2]]
> ? ? ? ? ? ?)
> ? ? ? ? ? ?, hi_95ci = max(
> ? ? ? ? ? ? ? ?x$hi_95ci[x$A==levels(x$A)[1]] - x$lo_95ci[x$A==levels(x$A)[2]]
> ? ? ? ? ? ? ? ?, x$lo_95ci[x$A==levels(x$A)[1]] -
> x$hi_95ci[x$A==levels(x$A)[2]]
> ? ? ? ? ? ?)
> ? ? ? ?)
> ? ? ? ?return(to_return)
> ? ?}
> )
>
> 6) Now you can visualize the A*C interaction; any area where the CI
> ribbon does not include zero may be considered a region where there is
> a significant A*C interaction.
> ggplot(data=AC_effect)+
> layer(
> ? ?geom='hline'
> ? ?, yintercept = 0
> ? ?, linetype = 2
> )+
> layer(
> ? ?geom = 'ribbon'
> ? ?, mapping = aes(
> ? ? ? ?x = C
> ? ? ? ?, ymin = lo_95ci
> ? ? ? ?, ymax = hi_95ci
> ? ?)
> ? ?, alpha = .5
> )+
> layer(
> ? ?geom = 'line'
> ? ?, mapping = aes(
> ? ? ? ?x = C
> ? ? ? ?, y = A_effect
> ? ?)
> )
>
>
> Similar steps can be applied to the inspection of a B*C interaction.
>
> The A*B*C interaction would be assessed by:
>
> 1) create dummy variable, F, representing the A*B combinations:
> my_data$F = factor(paste(my_data$A,my_data$B))
>
> 2) fit a gam that smooths C in each combination of A*B:
> ABC_fit = gamm4(
> ? ?formula = D ~ A*B + s(C,by=F)
> ? ?, random = ~ (1|E)
> ? ?, data = my_data
> )
>
> 3) obtain the prediction & CI for D in each combination of A*B and
> across the range of C:
> ABC_pred = expand.grid(
> ? ?A = factor(levels(my_data$A),levels=levels(my_data$A))
> ? ?, B = factor(levels(my_data$B),levels=levels(my_data$B))
> ? ?, C = seq(min(my_data$C),max(my_data$X),length.out=1e3)
> )
> ABC_pred = factor(paste(ABC_pred$A,ABC_pred$B),levels=levels(my_data$F))
> from_predict = predict(ABC_fit,newdata=ABC_pred,se.fit=T)
> ABC_pred$D = from_predict$fit
> ABC_pred$se = from_predict$se.fit
> ABC_pred$lo_95ci = ABC_pred$D - ABC_pred$se*1.96
> ABC_pred$hi_95ci = ABC_pred$D + ABC_pred$se*1.96
>
> 4) Similar to step 5 above, compute the difference between levels of A
> at each value of C *and* each level of B.
>
> 5) Using the differences computed in step 4, now compute the
> difference between levels of B at each value of C.
>
> 6) Now we have another single function and confidence ribbon that can
> be plotted; any region where the ribbon excludes zero may be
> considered a region with a significant A*B*C interaction.
>
>
> Does anyone have any thoughts on the validity of this approach? Also,
> this is clearly only applicable to the cases where A and B have only 2
> levels each, so any thoughts on an alternative more generalizable
> approach would be appreciated.
>
> Mike
>
> --
> Mike Lawrence
> Graduate Student
> Department of Psychology
> Dalhousie University
>
> Looking to arrange a meeting? Check my public calendar:
> http://tr.im/mikes_public_calendar
>
> ~ Certainty is folly... I think. ~
>



-- 
Mike Lawrence
Graduate Student
Department of Psychology
Dalhousie University

Looking to arrange a meeting? Check my public calendar:
http://tr.im/mikes_public_calendar

~ Certainty is folly... I think. ~



From Sam_Smith at me.com  Tue Aug  3 15:34:02 2010
From: Sam_Smith at me.com (Sam)
Date: Tue, 03 Aug 2010 14:34:02 +0100
Subject: [R-sig-ME] factor / intiger
Message-ID: <46954B32-E577-4167-A795-0F0F0B4ADF2E@me.com>

Dear List

I have a excel spread sheet with 5 columns that contain categorical data. I have recoded them to numbers 

A	B 	C
0	0	0
1	1	1
2	2	2
3	3
4
5

etc

When i read it into R and do str(dataframe) i get -

 $ A       : int  1 1 1 1 1 1 1 1 1 1 ...
 $ B    : int  1 1 1 1 1 1 1 1 1 1 ...
 $ C       : int  0 0 0 0 0 0 0 0 0 0 ...
 $ D    : int  0 0 0 0 0 0 0 0 0 0 ...
 $ E : int  0 0 0 0 0 0 0 0 0 0 ...

I then realised they should probably be factors instead of integers so used as.factor to convert them -

A <- as.factor(A)

Now when i run the GLMM the AIC values are different from when they were integers, i have 2 questions

1. Should i not have converted the categories to numbers in the excel spreadsheet before import.

2. Why are the AIC values different when i use as.factor as opposed to keeping them as integers, and which approach is recommended?

Thanks

Sam



From danielezrajohnson at gmail.com  Tue Aug  3 15:40:02 2010
From: danielezrajohnson at gmail.com (Daniel Ezra Johnson)
Date: Tue, 3 Aug 2010 09:40:02 -0400
Subject: [R-sig-ME] factor / intiger
In-Reply-To: <46954B32-E577-4167-A795-0F0F0B4ADF2E@me.com>
References: <46954B32-E577-4167-A795-0F0F0B4ADF2E@me.com>
Message-ID: <AANLkTimVB+xx9Arf4fWeqPDJ8zCjBi3G4_Ep51P0VBV9@mail.gmail.com>

Dear Sam,

When the factor levels are numbers, you have to do:

> A <- as.factor(as.character(A))

Regarding your other question, it's an entirely different model, if
you treat the predictors as linear/numeric or as factors. You should
choose based on what the predictor(s) is/are, probably not working
backwards from the AIC.

Dan

On Tue, Aug 3, 2010 at 9:34 AM, Sam <Sam_Smith at me.com> wrote:
> Dear List
>
> I have a excel spread sheet with 5 columns that contain categorical data. I have recoded them to numbers
>
> A ? ? ? B ? ? ? C
> 0 ? ? ? 0 ? ? ? 0
> 1 ? ? ? 1 ? ? ? 1
> 2 ? ? ? 2 ? ? ? 2
> 3 ? ? ? 3
> 4
> 5
>
> etc
>
> When i read it into R and do str(dataframe) i get -
>
> ?$ A ? ? ? : int ?1 1 1 1 1 1 1 1 1 1 ...
> ?$ B ? ?: int ?1 1 1 1 1 1 1 1 1 1 ...
> ?$ C ? ? ? : int ?0 0 0 0 0 0 0 0 0 0 ...
> ?$ D ? ?: int ?0 0 0 0 0 0 0 0 0 0 ...
> ?$ E : int ?0 0 0 0 0 0 0 0 0 0 ...
>
> I then realised they should probably be factors instead of integers so used as.factor to convert them -
>
> A <- as.factor(A)
>
> Now when i run the GLMM the AIC values are different from when they were integers, i have 2 questions
>
> 1. Should i not have converted the categories to numbers in the excel spreadsheet before import.
>
> 2. Why are the AIC values different when i use as.factor as opposed to keeping them as integers, and which approach is recommended?
>
> Thanks
>
> Sam
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From Sam_Smith at me.com  Tue Aug  3 15:43:52 2010
From: Sam_Smith at me.com (Sam)
Date: Tue, 03 Aug 2010 14:43:52 +0100
Subject: [R-sig-ME] factor / intiger
In-Reply-To: <AANLkTimVB+xx9Arf4fWeqPDJ8zCjBi3G4_Ep51P0VBV9@mail.gmail.com>
References: <46954B32-E577-4167-A795-0F0F0B4ADF2E@me.com>
	<AANLkTimVB+xx9Arf4fWeqPDJ8zCjBi3G4_Ep51P0VBV9@mail.gmail.com>
Message-ID: <714B27E2-6458-4FBC-A15B-7F263EFBD1C6@me.com>

Dear Dan,

Thanks for this, 

I was not working back from the AIC i was just unsure why they are different - in what way are they a different model?

If i have categorical predictors i should code them as factors in GLMM - correct?

Thanks

Sam
On 3 Aug 2010, at 14:40, Daniel Ezra Johnson wrote:

Dear Sam,

When the factor levels are numbers, you have to do:

> A <- as.factor(as.character(A))

Regarding your other question, it's an entirely different model, if
you treat the predictors as linear/numeric or as factors. You should
choose based on what the predictor(s) is/are, probably not working
backwards from the AIC.

Dan

On Tue, Aug 3, 2010 at 9:34 AM, Sam <Sam_Smith at me.com> wrote:
> Dear List
> 
> I have a excel spread sheet with 5 columns that contain categorical data. I have recoded them to numbers
> 
> A       B       C
> 0       0       0
> 1       1       1
> 2       2       2
> 3       3
> 4
> 5
> 
> etc
> 
> When i read it into R and do str(dataframe) i get -
> 
>  $ A       : int  1 1 1 1 1 1 1 1 1 1 ...
>  $ B    : int  1 1 1 1 1 1 1 1 1 1 ...
>  $ C       : int  0 0 0 0 0 0 0 0 0 0 ...
>  $ D    : int  0 0 0 0 0 0 0 0 0 0 ...
>  $ E : int  0 0 0 0 0 0 0 0 0 0 ...
> 
> I then realised they should probably be factors instead of integers so used as.factor to convert them -
> 
> A <- as.factor(A)
> 
> Now when i run the GLMM the AIC values are different from when they were integers, i have 2 questions
> 
> 1. Should i not have converted the categories to numbers in the excel spreadsheet before import.
> 
> 2. Why are the AIC values different when i use as.factor as opposed to keeping them as integers, and which approach is recommended?
> 
> Thanks
> 
> Sam
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From danielezrajohnson at gmail.com  Tue Aug  3 15:50:35 2010
From: danielezrajohnson at gmail.com (Daniel Ezra Johnson)
Date: Tue, 3 Aug 2010 09:50:35 -0400
Subject: [R-sig-ME] factor / intiger
In-Reply-To: <714B27E2-6458-4FBC-A15B-7F263EFBD1C6@me.com>
References: <46954B32-E577-4167-A795-0F0F0B4ADF2E@me.com>
	<AANLkTimVB+xx9Arf4fWeqPDJ8zCjBi3G4_Ep51P0VBV9@mail.gmail.com>
	<714B27E2-6458-4FBC-A15B-7F263EFBD1C6@me.com>
Message-ID: <AANLkTinwtAwxHA1Mjsc4LRJ1WDg8o85Xnzp5Fs8XwWzt@mail.gmail.com>

If a predictor is numeric/integer then it will usually be assigned one
parameter in the model (corresponding to a slope, change in
response/change in predictor).

If the predictor is a factor with k levels then there will usually be
(k-1) parameters for that predictor in the model.

In practice I think your model is going to fit better with the
predictors as factors but - see above - be much more complex, and the
AIC is one way of assessing that tradeoff.

Without knowing what the integers represent I can't really say which
approach is better. If you think there is a linear relationship
between the predictor(s) and the (log-odds of the) response, then you
may well be justified (perhaps others will disagree) in running the
predictors as numeric even though they happen to take only integer
values...

Dan

On Tue, Aug 3, 2010 at 9:43 AM, Sam <Sam_Smith at me.com> wrote:
> Dear Dan,
>
> Thanks for this,
>
> I was not working back from the AIC i was just unsure why they are different - in what way are they a different model?
>
> If i have categorical predictors i should code them as factors in GLMM - correct?
>
> Thanks
>
> Sam
> On 3 Aug 2010, at 14:40, Daniel Ezra Johnson wrote:
>
> Dear Sam,
>
> When the factor levels are numbers, you have to do:
>
>> A <- as.factor(as.character(A))
>
> Regarding your other question, it's an entirely different model, if
> you treat the predictors as linear/numeric or as factors. You should
> choose based on what the predictor(s) is/are, probably not working
> backwards from the AIC.
>
> Dan
>
> On Tue, Aug 3, 2010 at 9:34 AM, Sam <Sam_Smith at me.com> wrote:
>> Dear List
>>
>> I have a excel spread sheet with 5 columns that contain categorical data. I have recoded them to numbers
>>
>> A ? ? ? B ? ? ? C
>> 0 ? ? ? 0 ? ? ? 0
>> 1 ? ? ? 1 ? ? ? 1
>> 2 ? ? ? 2 ? ? ? 2
>> 3 ? ? ? 3
>> 4
>> 5
>>
>> etc
>>
>> When i read it into R and do str(dataframe) i get -
>>
>> ?$ A ? ? ? : int ?1 1 1 1 1 1 1 1 1 1 ...
>> ?$ B ? ?: int ?1 1 1 1 1 1 1 1 1 1 ...
>> ?$ C ? ? ? : int ?0 0 0 0 0 0 0 0 0 0 ...
>> ?$ D ? ?: int ?0 0 0 0 0 0 0 0 0 0 ...
>> ?$ E : int ?0 0 0 0 0 0 0 0 0 0 ...
>>
>> I then realised they should probably be factors instead of integers so used as.factor to convert them -
>>
>> A <- as.factor(A)
>>
>> Now when i run the GLMM the AIC values are different from when they were integers, i have 2 questions
>>
>> 1. Should i not have converted the categories to numbers in the excel spreadsheet before import.
>>
>> 2. Why are the AIC values different when i use as.factor as opposed to keeping them as integers, and which approach is recommended?
>>
>> Thanks
>>
>> Sam
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



From bbolker at gmail.com  Tue Aug  3 15:52:38 2010
From: bbolker at gmail.com (bbolker at gmail.com)
Date: Tue, 03 Aug 2010 13:52:38 +0000
Subject: [R-sig-ME] factor / intiger
In-Reply-To: <714B27E2-6458-4FBC-A15B-7F263EFBD1C6@me.com>
Message-ID: <0016e6d284ea4de678048ceba151@google.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100803/c99e819e/attachment.pl>

From bates at stat.wisc.edu  Tue Aug  3 17:44:39 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 3 Aug 2010 11:44:39 -0400
Subject: [R-sig-ME] Effective sample size
In-Reply-To: <CE0EDA99-6432-4338-96D9-A33FA56D280D@anu.edu.au>
References: <CE0EDA99-6432-4338-96D9-A33FA56D280D@anu.edu.au>
Message-ID: <AANLkTi=ggnU8ayz8nvd3AjKmONp=KvG-Vja2KpPZ3RXg@mail.gmail.com>

On Mon, Jul 19, 2010 at 4:27 AM, John Maindonald
<john.maindonald at anu.edu.au> wrote:
> Does anyone know of an implementation of the Effective Sample Size
> methodology that is described in
> <<<
> The Effective Sample Size and an Alternative Small-Sample Degrees-of-Freedom Method
> by: Christel Faes, Geert Molenberghs, Marc Aerts, Geert Verbeke, Michael G. Kenward
> The American Statistician, Vol. 63, No. 4. (2009), pp. 389-399.
>>>> ?
>
> The key requirement, as I understand the paper, is to calculate a variance for the predicted
> value, for each observation.

Sorry to come back to this question after so long John (I was at the
useR!2010 conference followed by vacation) but I think that the trick
is first to define the variance for the predicted value.  I haven't
read the paper myself and probably should not speculate on how the
methods are being formulated but I do note that often there is an
preconception that it should be possible to incorporate the
variability from the random effects or from their conditional means
along with the variability of the estimators of the fixed-effects
parameters into some kind of variance for the predicted values.  It is
not clear to me how this would be done if one reverts to the
definition of the probability model, which is the only way I know of
keeping the theory straight.  As you may know I tend to think of the
fixed-effects as entering into the definition of the conditional
distribution of the response, given the random effects, and the
variance-component parameters as being part of the definition of the
unconditional distribution of the random effects.  To me it is rather
tricky to decide how all the "sources of variability" could be
incorporated into the variance of a predicted value.



From bates at stat.wisc.edu  Tue Aug  3 17:51:40 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 3 Aug 2010 11:51:40 -0400
Subject: [R-sig-ME] with lmer : Erreur dans names(argNew)[1] <-
	names(formals(new))[[1]]
In-Reply-To: <674BC74273529E40A236CE2FB772DE093539D2E4B0@srv-exch-bgn.arvalis-fr.com>
References: <Acsn27Sw/HuUINCkS6ee1dPqP+/Q7A==>
	<674BC74273529E40A236CE2FB772DE093539D2E4B0@srv-exch-bgn.arvalis-fr.com>
Message-ID: <AANLkTinjsoFM6A4yKwaeX90PCRxuK1XPbgSY4WEsaz5H@mail.gmail.com>

Without a reproducible example it is difficult to determine why the
problem may be manifesting itself.  I would note that you are using
the car package and there may be an interaction between having car
loaded and some of the methods in lme4.  However, without a
reproducible example and some information on exactly what versions of
which packages are attached (i.e. the output from sessionInfo()) this
is just speculation.


On Tue, Jul 20, 2010 at 3:18 AM, DUYME Florent
<F.DUYME at arvalisinstitutduvegetal.fr> wrote:
> Hi
>
>
>
> While running lmer after lm, I get ?this error message :
>
>
>
> Erreur dans names(argNew)[1] <- names(formals(new))[[1]] :
>
> ?l'argument de remplacement est de longueur nulle
>
>
>
> I don't understand why it appears. I re-start R, and then lmer works.
>
>
>
> I suppose the previous work has an influence on lmer; why ?
>
>
>
>
>
> My previous work:
>
> op<-options(contrasts=c("contr.sum", "contr.treatment"))
>
> resu1<-lm(Y ~ fact1 + bloc_c*bloc_l, data=DF)
>
> Anova(resu1, type="III") ?# library car
>
> summary(resu1)
>
> options(op)
>
>
>
>
>
> sessionInfo()
>
> R version 2.10.0 (2009-10-26)
>
> i386-pc-mingw32
>
>
>
> locale:
>
> [1] LC_COLLATE=French_France.1252 ?LC_CTYPE=French_France.1252 ? ?LC_MONETARY=French_France.1252 LC_NUMERIC=C
>
> [5] LC_TIME=French_France.1252
>
>
>
> attached base packages:
>
> [1] grDevices datasets ?splines ? graphics ?stats ? ? tcltk ? ? utils ? ? methods ? base
>
>
>
> other attached packages:
>
> ?[1] lme4_0.999375-33 ? Matrix_0.999375-41 car_1.2-16 ? ? ? ? multcomp_1.1-7 ? ? mvtnorm_0.9-9 ? ? ?lattice_0.18-3 ? ? gdata_2.8.0 ? ? ? ?RODBC_1.3-1
>
> ?[9] svSocket_0.9-48 ? ?TinnR_1.0.3 ? ? ? ?R2HTML_2.0.0 ? ? ? Hmisc_3.8-0 ? ? ? ?survival_2.35-7
>
>
>
> loaded via a namespace (and not attached):
>
> [1] cluster_1.13.1 grid_2.10.0 ? ?gtools_2.6.2 ? nlme_3.1-96 ? ?svMisc_0.9-57 ?tools_2.10.0
>
>
>
>
>
>
>
> thanks for your advices
>
>
>
> florent
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From betinig at uoguelph.ca  Tue Aug  3 18:48:17 2010
From: betinig at uoguelph.ca (Gustavo Betini)
Date: Tue, 03 Aug 2010 12:48:17 -0400
Subject: [R-sig-ME] Correlation of random effects
Message-ID: <4C584851.9060308@uoguelph.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100803/43c12ade/attachment.pl>

From bates at stat.wisc.edu  Tue Aug  3 19:44:16 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 3 Aug 2010 13:44:16 -0400
Subject: [R-sig-ME] Fitting crossed random effects in lme (not lmer)
In-Reply-To: <ae2bcb7b994593979edf4f82412049d7.squirrel@mailbox.gwdg.de>
References: <ae2bcb7b994593979edf4f82412049d7.squirrel@mailbox.gwdg.de>
Message-ID: <AANLkTimepkv4t4CKo5MRdvG0G+L9KfPo3546UTXb9XjH@mail.gmail.com>

Sorry for the late reply.  As I indicated in another message, I was at
useR!2010 then on vacation.

On Tue, Jul 27, 2010 at 7:43 PM, Christoph Scherber
<Christoph.Scherber at agr.uni-goettingen.de> wrote:
> Dear all,
>
> Let?s assume I have an lme model with the following random effects structure:
>
> random=~1|block/plot
>
> Now, further treatments are applied at the next smallest level, but they
> are on the same hierarchy. In lmer notation, this could be parameterized
> as
>
> ...+(1|block/plot/treatment.type1)+(1|block/plot/treatment.type2)
>

I'm not entirely sure that would be successful.  The expansion of the
/ in the grouping factor in lme4 doesn't do a full symbolic analysis
of the terms.  Instead it is more of a macro expansion.  I think that
would probably end up with multiple random-effects terms of the form
1|block and 1|block:plot and a model for which unique parameter
estimates are not defined.

> How could I specify the same structure in lme?

It would not be easy to do that.  In fact, I'm not even sure it is
possible.  I think my advice would be to stay with simpler model
specifications.  You would need a huge amount of data to be able to
estimate parameters in such a model successfully.

> I know that I would need to use one of the pdClasses(), but I don?t
> understand how to set this up correctly. I tried of course the Pinheiro &
> Bates book, but maybe someone can give me a hint. That would be excellent!
>
> All the best and many thanks for any help,
> Christoph
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Tue Aug  3 20:25:19 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 3 Aug 2010 14:25:19 -0400
Subject: [R-sig-ME] Updating fit with lmer()
In-Reply-To: <AANLkTimiDy9tG_Np0o6C1twvn-b9wq+PxHN1LoPBpfNR@mail.gmail.com>
References: <AANLkTimiDy9tG_Np0o6C1twvn-b9wq+PxHN1LoPBpfNR@mail.gmail.com>
Message-ID: <AANLkTikQxEpPV5W76PYHBvExb+VFN5AjhjQ8YfF7kpg9@mail.gmail.com>

On Mon, Jul 26, 2010 at 3:31 PM, Gang Chen <gangchen6 at gmail.com> wrote:
> Suppose I run a linear mixed-effects model such as
>
> (fm <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
>
> and I want to update the fitting with a new response data (e.g.,
> newReaction) with everything else the same as the original model. Dr. Bates
> suggested the following on Sept. 5, 2007 to save runtime:
>
>> After fitting the model to the first simulated response, producing the
> object 'fm', ?the only operations needed to update the model are
>>
>> fm at y <- newy
>> Xy <- cbind(fm at X, fm at y)
>> fm at ZtXy <- fm at Zt %*% Xy
>> fm at XytXy <- crossprod(Xy)
>> lme4:::mer_finalize(fm, verbose)
>
> However, I could not find slots fm at ZtXy and fm at XytXy any more in lme4 nor
> lme4a. Have these two slots been changed to different names?

Indeed, things have changed since then.

> Or essentially the above steps have been wrapped into refit() in lme4?

Yes.



From bates at stat.wisc.edu  Tue Aug  3 20:40:26 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 3 Aug 2010 14:40:26 -0400
Subject: [R-sig-ME] compiling CHOLMOD c code
In-Reply-To: <AANLkTim2TvC3TL8CdXr47ShRycyMt4SukXP3HCoaFV6J@mail.gmail.com>
References: <AANLkTim2TvC3TL8CdXr47ShRycyMt4SukXP3HCoaFV6J@mail.gmail.com>
Message-ID: <AANLkTinYbgSR-rDLM7ydktUXBoq5=54w6LWo=Z84fdJR@mail.gmail.com>

On Tue, Jul 27, 2010 at 1:43 PM, Ryan King <c.ryan.king at gmail.com> wrote:
> Hello list,
> Like most mixed model implementations, my little project tries to use
> CHOLMOD for the underlying calculation. ?I haven't had to use raw c
> libraries before. ?Unfortunately, I need/want access to some CHOLMOD
> functions not used by Matrix or lme4. ? My procedure was to make all
> the UF sparse suite packages into archives
> make in each of the following:
> UFconfig/
> CHOLMOD/Lib/
> AMD/Lib/
> CAMD/Lib/
> CCOLAMD/Lib/
> CHOLMOD/Lib/
> COLAMD/Lib/
> metis-4.0/Lib/
>
> then move the archives to my working directory and link the results all together
> R CMD SHLIB ?*.a mylikec.c ../sparsesuite/metis-4.0/Lib/*.o -o
> bigsmush.so -llapack -lblas
>
> However, the result won't load
>
>> dyn.load("bigsmush.so")
> Error in dyn.load("bigsmush.so") :
> ?unable to load shared library 'bigsmush.so':
> ?bigsmush.so: undefined symbol: camd_malloc
>
>
> Grep says that camd_malloc is declared
> CAMD/Include/camd.h:329:EXTERN void *(*camd_malloc) (size_t) ; ? ? ? ? ? ? ?/*
> pointer to malloc */
>
> and defined in both
> CAMD/Source/camd_global.c:51:void *(*camd_malloc) (size_t) = malloc ;

My guess is that this source file is very much like the
AMD/Source/amd_global.c file and the purpose of all these defines is
to accommodate incorporating these sources into Matlab.

> CHOLMOD/Partition/cholmod_camd.c:185: ? ?camd_malloc = Common->malloc_memory ;
>
>
> as long as I don't compile with the -DNMALLOC option, which I don't
> think that I did. ?Any help as to what I need to to?

Not really.  It is quite complicated trying to get all the CHOLMOD
pieces working with each other, which is one reason that Martin and I
decided to avoid the partitioning algorithms based on Metis.  (Also,
the last time we checked Metis is not available under an open source
license, which means we couldn't use it even if we could work out all
the linkage details.)

Generally the order in which you list object files for the linker is
important.  Linkers may have changed since I last looked at the
details but in the past they only did one pass over the object files
so if the reference to a particular symbol occurred after the
definition of the symbol it was not incorporated in the result.

The way that we did things in Matrix is to create archive (.a files)
from the CHOLMOD packages and then list those files in the link step.
Most versions of the ar program that creates archives put a symbol
table in the archive so that the order in which the files occur is
irrelevant.



From davidD at qimr.edu.au  Wed Aug  4 08:23:58 2010
From: davidD at qimr.edu.au (David Duffy)
Date: Wed, 4 Aug 2010 16:23:58 +1000 (EST)
Subject: [R-sig-ME] Correlation of random effects
In-Reply-To: <4C584851.9060308@uoguelph.ca>
References: <4C584851.9060308@uoguelph.ca>
Message-ID: <Pine.LNX.4.64.1008041609310.21053@orpheus.qimr.edu.au>

On Tue, 3 Aug 2010, Gustavo Betini wrote:

> m1<-lmer(pc1 ~ year + datejc + stage + rept + age + tarsusc + mtempc +
> windsc + rhc + (1|id), data=ndf, REML=0)
> m2<-lmer(pc1 ~ year + datejc + stage + rept + age + tarsusc + mtempc +
> windsc + rhc + (1+mtempc|id), data=ndf, REML=0)
>
> In order to compare these two models I would use a LRT test:
>
> anova(m1,m2)
>
> However, LRT test is not recommended when Corr is near the extremes
> (+1,-1). So, how I compare the fit of two models in lme4 when the
> correlation between two random effects are near the extremes?
>

You can always look at the likelihood ratio, the question is 
whether it follows a simple chi-square distribution under the null or not.
If the LR is large enough, then it probably won't matter 
anyway. You can obtain percentiles by an appropriate simulation 
based on your data setup, especially since m1 only has id as a random 
effect.  I don't think the RLRsim package can be used here, but its author 
may clarify on that.

Cheers, David Duffy.
-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From davidD at qimr.edu.au  Wed Aug  4 08:54:52 2010
From: davidD at qimr.edu.au (David Duffy)
Date: Wed, 4 Aug 2010 16:54:52 +1000 (EST)
Subject: [R-sig-ME] gamm4 model formulation clarification
In-Reply-To: <AANLkTi=qQ1R8xb3urCk7L9LWKR8BLKu7ea_XD3s4=yWL@mail.gmail.com>
References: <AANLkTims1fHToCt7RyRN1jdVhNbXZuUzM5SWRXq2+Y2T@mail.gmail.com>
	<AANLkTinRyvm=qj=Pooz1QOJMN-a7bJoQMjJa_Bxn4qLD@mail.gmail.com>
	<AANLkTimBL-zOQueKayB6Gf-_H3nvHZdE+3UOqOW+CTQE@mail.gmail.com>
	<AANLkTi=ZzfJKsNZyG_3jmx6DdSJ+Eb97qx9VF1qw8FoH@mail.gmail.com>
	<AANLkTi=N9tz-CcNbzkWWivnD0Yit=ipznSWoe+Mx_3gB@mail.gmail.com>
	<AANLkTi=qQ1R8xb3urCk7L9LWKR8BLKu7ea_XD3s4=yWL@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.1008041642060.21053@orpheus.qimr.edu.au>

On Tue, 3 Aug 2010, Mike Lawrence wrote:

> Oops. It seems that my logic in computing the CI for the difference
> scores in the "solution" I posted was seriously flawed (see:
> http://stats.stackexchange.com/questions/1169/ci-for-a-difference-based-on-independent-cis).
> So, predict.gam(..., se.fit=T) produces predicted values and and SEs
> for those values; any suggestions on how to compute the proper CI for
> a difference between such predicted values given the SEs?

I know very little about this, but I thought the smoothing procedure in 
mgcv etc tests the rank of the GCV problem, where your hypothesis is 
something like "rank of smooth of interaction = 1".  Then the AIC can be 
plotted for different fixed values of ranks/dfs.

Cheers, David Duffy.
-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From F.DUYME at arvalisinstitutduvegetal.fr  Wed Aug  4 09:34:45 2010
From: F.DUYME at arvalisinstitutduvegetal.fr (DUYME Florent)
Date: Wed, 4 Aug 2010 09:34:45 +0200
Subject: [R-sig-ME] RE : with lmer : Erreur dans names(argNew)[1] <-
 names(formals(new))[[1]]
In-Reply-To: <AANLkTinjsoFM6A4yKwaeX90PCRxuK1XPbgSY4WEsaz5H@mail.gmail.com>
Message-ID: <674BC74273529E40A236CE2FB772DE093539ECF4B8@srv-exch-bgn.arvalis-fr.com>

Here are data, script and sessionInfo()
Florent

R version 2.10.0 (2009-10-26)
i386-pc-mingw32

locale:
[1] LC_COLLATE=French_France.1252  LC_CTYPE=French_France.1252    LC_MONETARY=French_France.1252 LC_NUMERIC=C
[5] LC_TIME=French_France.1252

attached base packages:
[1] grDevices datasets  splines   graphics  stats     tcltk     utils     methods   base

other attached packages:
 [1] lme4_0.999375-33   Matrix_0.999375-41 lattice_0.18-3     car_2.0-2          nnet_7.3-1         MASS_7.3-4         svSocket_0.9-48    TinnR_1.0.3
 [9] R2HTML_2.0.0       Hmisc_3.8-0        survival_2.35-7

loaded via a namespace (and not attached):
[1] cluster_1.13.1 grid_2.10.0    nlme_3.1-96    svMisc_0.9-57  tools_2.10.0



-----Message d'origine-----
De : dmbates at gmail.com [mailto:dmbates at gmail.com] De la part de Douglas Bates
Envoy? : mardi 3 ao?t 2010 17:52
? : DUYME Florent
Cc : r-sig-mixed-models at r-project.org
Objet : Re: [R-sig-ME] with lmer : Erreur dans names(argNew)[1] <- names(formals(new))[[1]]

Without a reproducible example it is difficult to determine why the
problem may be manifesting itself.  I would note that you are using
the car package and there may be an interaction between having car
loaded and some of the methods in lme4.  However, without a
reproducible example and some information on exactly what versions of
which packages are attached (i.e. the output from sessionInfo()) this
is just speculation.


On Tue, Jul 20, 2010 at 3:18 AM, DUYME Florent
<F.DUYME at arvalisinstitutduvegetal.fr> wrote:
> Hi
>
>
>
> While running lmer after lm, I get  this error message :
>
>
>
> Erreur dans names(argNew)[1] <- names(formals(new))[[1]] :
>
>  l'argument de remplacement est de longueur nulle
>
>
>
> I don't understand why it appears. I re-start R, and then lmer works.
>
>
>
> I suppose the previous work has an influence on lmer; why ?
>
>
>
>
>
> My previous work:
>
> op<-options(contrasts=c("contr.sum", "contr.treatment"))
>
> resu1<-lm(Y ~ fact1 + bloc_c*bloc_l, data=DF)
>
> Anova(resu1, type="III")  # library car
>
> summary(resu1)
>
> options(op)
>
>
>
>
>
> sessionInfo()
>
> R version 2.10.0 (2009-10-26)
>
> i386-pc-mingw32
>
>
>
> locale:
>
> [1] LC_COLLATE=French_France.1252  LC_CTYPE=French_France.1252    LC_MONETARY=French_France.1252 LC_NUMERIC=C
>
> [5] LC_TIME=French_France.1252
>
>
>
> attached base packages:
>
> [1] grDevices datasets  splines   graphics  stats     tcltk     utils     methods   base
>
>
>
> other attached packages:
>
>  [1] lme4_0.999375-33   Matrix_0.999375-41 car_1.2-16         multcomp_1.1-7     mvtnorm_0.9-9      lattice_0.18-3     gdata_2.8.0        RODBC_1.3-1
>
>  [9] svSocket_0.9-48    TinnR_1.0.3        R2HTML_2.0.0       Hmisc_3.8-0        survival_2.35-7
>
>
>
> loaded via a namespace (and not attached):
>
> [1] cluster_1.13.1 grid_2.10.0    gtools_2.6.2   nlme_3.1-96    svMisc_0.9-57  tools_2.10.0
>
>
>
>
>
>
>
> thanks for your advices
>
>
>
> florent
>
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: data_D_Bates.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100804/9a6b0fd6/attachment.txt>

From another83 at me.com  Wed Aug  4 10:54:15 2010
From: another83 at me.com (John Haart)
Date: Wed, 04 Aug 2010 09:54:15 +0100
Subject: [R-sig-ME] Binary response ordering
Message-ID: <5113B82C-DBE8-4A1B-8872-7FA6174EAC39@me.com>

Dear List,

I have a quick question regarding the setup of my data for analysis with a glmm.  I hope this is the appropriate list, i apologise if it is not.

I have a response variable, TRUE or FALSE. I have coded this as 0 = False and 1 = TRUE in excel.

I have 3 categorical factors with C,D and E

I then read in the data frame and run the model as follows-

lmer(trueorfalse~1+(1|A/B) + C + D+ E ,family=binomial)

And this is the output

Generalized linear mixed model fit by the Laplace approximation 
Formula: threatornot ~ 1 + (1 | A/B) + C + D+  E ,family=binomial)
  AIC  BIC logLik deviance
 1410 1450 -696.8     1394
Random effects:
 Groups       Name        Variance   Std.Dev.  
 family:order (Intercept) 6.7869e-01 8.2382e-01
 order        (Intercept) 7.8204e-11 8.8433e-06
Number of obs: 1116, groups: A:B, 43; B, 9

Fixed effects:
            Estimate Std. Error z value Pr(>|z|)  
(Intercept)  0.11281    0.42232   0.267   0.7894  
C1   -0.02414    0.19964  -0.121   0.9038  
D2  -0.16482    0.38602  -0.427   0.6694  
E2       0.95381    0.54316   1.756   0.0791 .
E3      0.75733    0.87275   0.868   0.3855  
E4       0.03044    0.47328   0.064   0.9487  

What i am unsure about is the inference, if a term is significant does this relate to TRUE or FALSE?

I.E E2 has a p value of 0.079, does this 0.079 relate to the probability of it resulting in a true or false response? Does it matter how i code the input i.e FALSE = 1, TRUE =2 for instance?

Maybe i am reading the output wrong?

Thanks

John



From Thierry.ONKELINX at inbo.be  Wed Aug  4 11:05:32 2010
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 4 Aug 2010 11:05:32 +0200
Subject: [R-sig-ME] Binary response ordering
In-Reply-To: <5113B82C-DBE8-4A1B-8872-7FA6174EAC39@me.com>
References: <5113B82C-DBE8-4A1B-8872-7FA6174EAC39@me.com>
Message-ID: <3DB16098F738284D8DBEB2FC3699163821EBEA@inboexch.inbo.be>

Is this homework? The data and the analysis look very similar to the one
is this post
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q3/004203.html

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey
  

> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens John Haart
> Verzonden: woensdag 4 augustus 2010 10:54
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] Binary response ordering
> 
> Dear List,
> 
> I have a quick question regarding the setup of my data for 
> analysis with a glmm.  I hope this is the appropriate list, i 
> apologise if it is not.
> 
> I have a response variable, TRUE or FALSE. I have coded this 
> as 0 = False and 1 = TRUE in excel.
> 
> I have 3 categorical factors with C,D and E
> 
> I then read in the data frame and run the model as follows-
> 
> lmer(trueorfalse~1+(1|A/B) + C + D+ E ,family=binomial)
> 
> And this is the output
> 
> Generalized linear mixed model fit by the Laplace approximation
> Formula: threatornot ~ 1 + (1 | A/B) + C + D+  E ,family=binomial)
>   AIC  BIC logLik deviance
>  1410 1450 -696.8     1394
> Random effects:
>  Groups       Name        Variance   Std.Dev.  
>  family:order (Intercept) 6.7869e-01 8.2382e-01
>  order        (Intercept) 7.8204e-11 8.8433e-06
> Number of obs: 1116, groups: A:B, 43; B, 9
> 
> Fixed effects:
>             Estimate Std. Error z value Pr(>|z|)  
> (Intercept)  0.11281    0.42232   0.267   0.7894  
> C1   -0.02414    0.19964  -0.121   0.9038 
> D2  -0.16482    0.38602  -0.427   0.6694  
> E2       0.95381    0.54316   1.756   0.0791 .
> E3      0.75733    0.87275   0.868   0.3855  
> E4       0.03044    0.47328   0.064   0.9487  
> 
> What i am unsure about is the inference, if a term is 
> significant does this relate to TRUE or FALSE?
> 
> I.E E2 has a p value of 0.079, does this 0.079 relate to the 
> probability of it resulting in a true or false response? Does 
> it matter how i code the input i.e FALSE = 1, TRUE =2 for instance?
> 
> Maybe i am reading the output wrong?
> 
> Thanks
> 
> John
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

Druk dit bericht a.u.b. niet onnodig af.
Please do not print this message unnecessarily.

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From another83 at me.com  Wed Aug  4 11:14:28 2010
From: another83 at me.com (John Haart)
Date: Wed, 04 Aug 2010 10:14:28 +0100
Subject: [R-sig-ME] Binary response ordering
In-Reply-To: <3DB16098F738284D8DBEB2FC3699163821EBEA@inboexch.inbo.be>
References: <5113B82C-DBE8-4A1B-8872-7FA6174EAC39@me.com>
	<3DB16098F738284D8DBEB2FC3699163821EBEA@inboexch.inbo.be>
Message-ID: <3A6F0716-4A01-45FB-8E91-825AE2E07893@me.com>

No its not homework,

Its a group undergrad project, is this not the appropriate forum?

Thanks


On 4 Aug 2010, at 10:05, ONKELINX, Thierry wrote:

Is this homework? The data and the analysis look very similar to the one
is this post
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q3/004203.html

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey


> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens John Haart
> Verzonden: woensdag 4 augustus 2010 10:54
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] Binary response ordering
> 
> Dear List,
> 
> I have a quick question regarding the setup of my data for 
> analysis with a glmm.  I hope this is the appropriate list, i 
> apologise if it is not.
> 
> I have a response variable, TRUE or FALSE. I have coded this 
> as 0 = False and 1 = TRUE in excel.
> 
> I have 3 categorical factors with C,D and E
> 
> I then read in the data frame and run the model as follows-
> 
> lmer(trueorfalse~1+(1|A/B) + C + D+ E ,family=binomial)
> 
> And this is the output
> 
> Generalized linear mixed model fit by the Laplace approximation
> Formula: threatornot ~ 1 + (1 | A/B) + C + D+  E ,family=binomial)
>  AIC  BIC logLik deviance
> 1410 1450 -696.8     1394
> Random effects:
> Groups       Name        Variance   Std.Dev.  
> family:order (Intercept) 6.7869e-01 8.2382e-01
> order        (Intercept) 7.8204e-11 8.8433e-06
> Number of obs: 1116, groups: A:B, 43; B, 9
> 
> Fixed effects:
>            Estimate Std. Error z value Pr(>|z|)  
> (Intercept)  0.11281    0.42232   0.267   0.7894  
> C1   -0.02414    0.19964  -0.121   0.9038 
> D2  -0.16482    0.38602  -0.427   0.6694  
> E2       0.95381    0.54316   1.756   0.0791 .
> E3      0.75733    0.87275   0.868   0.3855  
> E4       0.03044    0.47328   0.064   0.9487  
> 
> What i am unsure about is the inference, if a term is 
> significant does this relate to TRUE or FALSE?
> 
> I.E E2 has a p value of 0.079, does this 0.079 relate to the 
> probability of it resulting in a true or false response? Does 
> it matter how i code the input i.e FALSE = 1, TRUE =2 for instance?
> 
> Maybe i am reading the output wrong?
> 
> Thanks
> 
> John
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

Druk dit bericht a.u.b. niet onnodig af.
Please do not print this message unnecessarily.

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From etiennelaliberte at gmail.com  Wed Aug  4 12:12:15 2010
From: etiennelaliberte at gmail.com (Etienne =?ISO-8859-1?Q?Lalibert=E9?=)
Date: Wed, 04 Aug 2010 22:12:15 +1200
Subject: [R-sig-ME] Edward's 2008 R^2 for lme?
Message-ID: <1280916735.2157.58.camel@globetrotter>

Without wanting to start a heated debate on the pitfalls associated with
a "R^2-like" statistic for linear mixed models, I would simply like to
know if someone happens to have implemented Edward's 2008 approach in R
for lme(), and if so, if that person would be willing to kindly share
some code.

Edwards, L. J., K. E. Muller, R. D. Wolfinger, B. F. Qaqish, and O.
Schabenberger. 2008. An R2 statistic for fixed effects in the linear
mixed model. Statistics in Medicine 27:6137-6157.

Thanks,

Etienne



From bates at stat.wisc.edu  Wed Aug  4 14:05:37 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 4 Aug 2010 08:05:37 -0400
Subject: [R-sig-ME] Correlation of random effects
In-Reply-To: <Pine.LNX.4.64.1008041609310.21053@orpheus.qimr.edu.au>
References: <4C584851.9060308@uoguelph.ca>
	<Pine.LNX.4.64.1008041609310.21053@orpheus.qimr.edu.au>
Message-ID: <AANLkTi=3gOcfkk7dFGTHjVFZGf3Sehq8vAHUtoztS3Mx@mail.gmail.com>

On Wed, Aug 4, 2010 at 2:23 AM, David Duffy <davidD at qimr.edu.au> wrote:
> On Tue, 3 Aug 2010, Gustavo Betini wrote:
>
>> m1<-lmer(pc1 ~ year + datejc + stage + rept + age + tarsusc + mtempc +
>> windsc + rhc + (1|id), data=ndf, REML=0)
>> m2<-lmer(pc1 ~ year + datejc + stage + rept + age + tarsusc + mtempc +
>> windsc + rhc + (1+mtempc|id), data=ndf, REML=0)
>>
>> In order to compare these two models I would use a LRT test:
>>
>> anova(m1,m2)
>>
>> However, LRT test is not recommended when Corr is near the extremes
>> (+1,-1). So, how I compare the fit of two models in lme4 when the
>> correlation between two random effects are near the extremes?
>>
>
> You can always look at the likelihood ratio, the question is whether it
> follows a simple chi-square distribution under the null or not.
> If the LR is large enough, then it probably won't matter anyway. You can
> obtain percentiles by an appropriate simulation based on your data setup,
> especially since m1 only has id as a random effect. ?I don't think the
> RLRsim package can be used here, but its author may clarify on that.

I agree with David that you can always look at the likelihood ratio
and if its value is very large then whether or not the chi-square
approximation to the change in the deviance is accurate you will still
have strong evidence that the random effects correlation is
non-negligible.

However, I think you are comparing the wrong models.  You should
compare m2 to the same model but with random effects of the form

(1|id) + (0+mtempc|id)

if you want to isolate the correlation parameter.



From bates at stat.wisc.edu  Wed Aug  4 14:55:36 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 4 Aug 2010 08:55:36 -0400
Subject: [R-sig-ME] RE : with lmer : Erreur dans names(argNew)[1] <-
	names(formals(new))[[1]]
In-Reply-To: <674BC74273529E40A236CE2FB772DE093539ECF4B8@srv-exch-bgn.arvalis-fr.com>
References: <AANLkTinjsoFM6A4yKwaeX90PCRxuK1XPbgSY4WEsaz5H@mail.gmail.com>
	<674BC74273529E40A236CE2FB772DE093539ECF4B8@srv-exch-bgn.arvalis-fr.com>
Message-ID: <AANLkTi=vm=JpXZ9bMyhxjsPfcOkgh+++njignViwky4U@mail.gmail.com>

The problem is subtle and traces back to your calling the new data
frame "new" thereby overriding the function new in the methods
package.   The right hand side of that assignment in the function
Matrix::fac2sparse should be changed to
names(formals(methods::new))[1] and we will make the change in the
next release of the Matrix package.  Until then you can run the script
if you change the name new to newDF

2010/8/4 DUYME Florent <F.DUYME at arvalisinstitutduvegetal.fr>:
> Here are data, script and sessionInfo()
> Florent
>
> R version 2.10.0 (2009-10-26)
> i386-pc-mingw32
>
> locale:
> [1] LC_COLLATE=French_France.1252 ?LC_CTYPE=French_France.1252 ? ?LC_MONETARY=French_France.1252 LC_NUMERIC=C
> [5] LC_TIME=French_France.1252
>
> attached base packages:
> [1] grDevices datasets ?splines ? graphics ?stats ? ? tcltk ? ? utils ? ? methods ? base
>
> other attached packages:
> ?[1] lme4_0.999375-33 ? Matrix_0.999375-41 lattice_0.18-3 ? ? car_2.0-2 ? ? ? ? ?nnet_7.3-1 ? ? ? ? MASS_7.3-4 ? ? ? ? svSocket_0.9-48 ? ?TinnR_1.0.3
> ?[9] R2HTML_2.0.0 ? ? ? Hmisc_3.8-0 ? ? ? ?survival_2.35-7
>
> loaded via a namespace (and not attached):
> [1] cluster_1.13.1 grid_2.10.0 ? ?nlme_3.1-96 ? ?svMisc_0.9-57 ?tools_2.10.0
>
>
>
> -----Message d'origine-----
> De : dmbates at gmail.com [mailto:dmbates at gmail.com] De la part de Douglas Bates
> Envoy? : mardi 3 ao?t 2010 17:52
> ? : DUYME Florent
> Cc : r-sig-mixed-models at r-project.org
> Objet : Re: [R-sig-ME] with lmer : Erreur dans names(argNew)[1] <- names(formals(new))[[1]]
>
> Without a reproducible example it is difficult to determine why the
> problem may be manifesting itself. ?I would note that you are using
> the car package and there may be an interaction between having car
> loaded and some of the methods in lme4. ?However, without a
> reproducible example and some information on exactly what versions of
> which packages are attached (i.e. the output from sessionInfo()) this
> is just speculation.
>
>
> On Tue, Jul 20, 2010 at 3:18 AM, DUYME Florent
> <F.DUYME at arvalisinstitutduvegetal.fr> wrote:
>> Hi
>>
>>
>>
>> While running lmer after lm, I get ?this error message :
>>
>>
>>
>> Erreur dans names(argNew)[1] <- names(formals(new))[[1]] :
>>
>> ?l'argument de remplacement est de longueur nulle
>>
>>
>>
>> I don't understand why it appears. I re-start R, and then lmer works.
>>
>>
>>
>> I suppose the previous work has an influence on lmer; why ?
>>
>>
>>
>>
>>
>> My previous work:
>>
>> op<-options(contrasts=c("contr.sum", "contr.treatment"))
>>
>> resu1<-lm(Y ~ fact1 + bloc_c*bloc_l, data=DF)
>>
>> Anova(resu1, type="III") ?# library car
>>
>> summary(resu1)
>>
>> options(op)
>>
>>
>>
>>
>>
>> sessionInfo()
>>
>> R version 2.10.0 (2009-10-26)
>>
>> i386-pc-mingw32
>>
>>
>>
>> locale:
>>
>> [1] LC_COLLATE=French_France.1252 ?LC_CTYPE=French_France.1252 ? ?LC_MONETARY=French_France.1252 LC_NUMERIC=C
>>
>> [5] LC_TIME=French_France.1252
>>
>>
>>
>> attached base packages:
>>
>> [1] grDevices datasets ?splines ? graphics ?stats ? ? tcltk ? ? utils ? ? methods ? base
>>
>>
>>
>> other attached packages:
>>
>> ?[1] lme4_0.999375-33 ? Matrix_0.999375-41 car_1.2-16 ? ? ? ? multcomp_1.1-7 ? ? mvtnorm_0.9-9 ? ? ?lattice_0.18-3 ? ? gdata_2.8.0 ? ? ? ?RODBC_1.3-1
>>
>> ?[9] svSocket_0.9-48 ? ?TinnR_1.0.3 ? ? ? ?R2HTML_2.0.0 ? ? ? Hmisc_3.8-0 ? ? ? ?survival_2.35-7
>>
>>
>>
>> loaded via a namespace (and not attached):
>>
>> [1] cluster_1.13.1 grid_2.10.0 ? ?gtools_2.6.2 ? nlme_3.1-96 ? ?svMisc_0.9-57 ?tools_2.10.0
>>
>>
>>
>>
>>
>>
>>
>> thanks for your advices
>>
>>
>>
>> florent
>>
>>
>> ? ? ? ?[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

From bobhuang09 at gmail.com  Wed Aug  4 15:06:34 2010
From: bobhuang09 at gmail.com (Bob Huang)
Date: Wed, 4 Aug 2010 21:06:34 +0800
Subject: [R-sig-ME] specify the correlation structure
Message-ID: <AANLkTimF5gADmmqoE5FaA=rbpspu+RJPVeUAgCbuV4yc@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100804/50ea3336/attachment.pl>

From betinig at uoguelph.ca  Wed Aug  4 15:11:53 2010
From: betinig at uoguelph.ca (Gustavo Betini)
Date: Wed, 04 Aug 2010 09:11:53 -0400
Subject: [R-sig-ME] Correlation of random effects
In-Reply-To: <AANLkTi=3gOcfkk7dFGTHjVFZGf3Sehq8vAHUtoztS3Mx@mail.gmail.com>
References: <4C584851.9060308@uoguelph.ca>	<Pine.LNX.4.64.1008041609310.21053@orpheus.qimr.edu.au>
	<AANLkTi=3gOcfkk7dFGTHjVFZGf3Sehq8vAHUtoztS3Mx@mail.gmail.com>
Message-ID: <4C596719.6090805@uoguelph.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100804/865f77c8/attachment.pl>

From bates at stat.wisc.edu  Wed Aug  4 15:15:15 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 4 Aug 2010 09:15:15 -0400
Subject: [R-sig-ME] Binary response ordering
In-Reply-To: <5113B82C-DBE8-4A1B-8872-7FA6174EAC39@me.com>
References: <5113B82C-DBE8-4A1B-8872-7FA6174EAC39@me.com>
Message-ID: <AANLkTimHPors_t2YkB3QAO1vzGiARZO2e59gwhwwWku3@mail.gmail.com>

On Wed, Aug 4, 2010 at 4:54 AM, John Haart <another83 at me.com> wrote:
> Dear List,
>
> I have a quick question regarding the setup of my data for analysis with a glmm. ?I hope this is the appropriate list, i apologise if it is not.
>
> I have a response variable, TRUE or FALSE. I have coded this as 0 = False and 1 = TRUE in excel.
>
> I have 3 categorical factors with C,D and E
>
> I then read in the data frame and run the model as follows-
>
> lmer(trueorfalse~1+(1|A/B) + C + D+ E ,family=binomial)
>
> And this is the output
>
> Generalized linear mixed model fit by the Laplace approximation
> Formula: threatornot ~ 1 + (1 | A/B) + C + D+ ?E ,family=binomial)
> ?AIC ?BIC logLik deviance
> ?1410 1450 -696.8 ? ? 1394
> Random effects:
> ?Groups ? ? ? Name ? ? ? ?Variance ? Std.Dev.
> ?family:order (Intercept) 6.7869e-01 8.2382e-01
> ?order ? ? ? ?(Intercept) 7.8204e-11 8.8433e-06
> Number of obs: 1116, groups: A:B, 43; B, 9

Apparently you altered the output at some point because the factors
that were named A and B ended up as order and family in the random
effects description.

> Fixed effects:
> ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
> (Intercept) ?0.11281 ? ?0.42232 ? 0.267 ? 0.7894
> C1 ? -0.02414 ? ?0.19964 ?-0.121 ? 0.9038
> D2 ?-0.16482 ? ?0.38602 ?-0.427 ? 0.6694
> E2 ? ? ? 0.95381 ? ?0.54316 ? 1.756 ? 0.0791 .
> E3 ? ? ?0.75733 ? ?0.87275 ? 0.868 ? 0.3855
> E4 ? ? ? 0.03044 ? ?0.47328 ? 0.064 ? 0.9487
>
> What i am unsure about is the inference, if a term is significant does this relate to TRUE or FALSE?

In this case it would be related to the probability of a TRUE response
but, as this is simply 1 - P(FALSE) then the only change if you
reversed the order would be to change the signs of the coefficients.
The simple way to verify this is to fit

glm(threatornot ~ 1)

and check the value of the coefficient.  It should be
log(pHat/(1-pHat)) where pHat is the proportion of TRUE responses.

> I.E E2 has a p value of 0.079, does this 0.079 relate to the probability of it resulting in a true or false response? Does it matter how i code the input i.e FALSE = 1, TRUE =2 for instance?

If there are two levels in the response then the model is fit
according to the probability of the second versus the first.  You can
disambiguate the process if you convert the response to a factor with
the levels specified explicitly.

The bigger issue is that you shouldn't pay too much attention to a
particular coefficient related to the levels of a factor like E
because the coefficients are defined with respect to the contrasts in
effect at the time the model was fit.  Without knowing the contrasts
being used and without prior knowledge that a particular contrast was
important, those coefficients are not important by themselves.  It is
the cumulative effect of the variability amongst the levels of the
factor that is important.

> Maybe i am reading the output wrong?
>
> Thanks
>
> John
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From another83 at me.com  Wed Aug  4 15:30:05 2010
From: another83 at me.com (John Haart)
Date: Wed, 04 Aug 2010 14:30:05 +0100
Subject: [R-sig-ME] Binary response ordering
In-Reply-To: <AANLkTimHPors_t2YkB3QAO1vzGiARZO2e59gwhwwWku3@mail.gmail.com>
References: <5113B82C-DBE8-4A1B-8872-7FA6174EAC39@me.com>
	<AANLkTimHPors_t2YkB3QAO1vzGiARZO2e59gwhwwWku3@mail.gmail.com>
Message-ID: <8FC9DF9E-92C6-49C3-85AC-0B0610439018@me.com>

Dear Douglas,

Thanks very much for this,


> You can
> disambiguate the process if you convert the response to a factor with
> the levels specified explicitly.

I am a little unsure what this means?

My response is TRUE or FALSE. However there are different levels of TRUE / FALSE. At this point i have not discriminated between them, as i am unsure how, my thought was to convert them to a continuous factor and use this as a response? Instead of having a multi level categorical response which i don't think is possible in lmer? 

Whilst on the subject of P-Values, 

I am using AIC model selection rather than P-value based stepwise regression as i feel it is more robust (Burnham & Anderson, 2002). However there seems to be a huge difference in my results.

The factors with the highest p-values , and therefore retained in the MAM, when i did an explanatory stepwise regression, do not appear in the model with the lowest AIC value - do the two approaches generally not match?

Thanks

 

 
On 4 Aug 2010, at 14:15, Douglas Bates wrote:

On Wed, Aug 4, 2010 at 4:54 AM, John Haart <another83 at me.com> wrote:
> Dear List,
> 
> I have a quick question regarding the setup of my data for analysis with a glmm.  I hope this is the appropriate list, i apologise if it is not.
> 
> I have a response variable, TRUE or FALSE. I have coded this as 0 = False and 1 = TRUE in excel.
> 
> I have 3 categorical factors with C,D and E
> 
> I then read in the data frame and run the model as follows-
> 
> lmer(trueorfalse~1+(1|A/B) + C + D+ E ,family=binomial)
> 
> And this is the output
> 
> Generalized linear mixed model fit by the Laplace approximation
> Formula: threatornot ~ 1 + (1 | A/B) + C + D+  E ,family=binomial)
>  AIC  BIC logLik deviance
>  1410 1450 -696.8     1394
> Random effects:
>  Groups       Name        Variance   Std.Dev.
>  family:order (Intercept) 6.7869e-01 8.2382e-01
>  order        (Intercept) 7.8204e-11 8.8433e-06
> Number of obs: 1116, groups: A:B, 43; B, 9

Apparently you altered the output at some point because the factors
that were named A and B ended up as order and family in the random
effects description.

> Fixed effects:
>            Estimate Std. Error z value Pr(>|z|)
> (Intercept)  0.11281    0.42232   0.267   0.7894
> C1   -0.02414    0.19964  -0.121   0.9038
> D2  -0.16482    0.38602  -0.427   0.6694
> E2       0.95381    0.54316   1.756   0.0791 .
> E3      0.75733    0.87275   0.868   0.3855
> E4       0.03044    0.47328   0.064   0.9487
> 
> What i am unsure about is the inference, if a term is significant does this relate to TRUE or FALSE?

In this case it would be related to the probability of a TRUE response
but, as this is simply 1 - P(FALSE) then the only change if you
reversed the order would be to change the signs of the coefficients.
The simple way to verify this is to fit

glm(threatornot ~ 1)

and check the value of the coefficient.  It should be
log(pHat/(1-pHat)) where pHat is the proportion of TRUE responses.

> I.E E2 has a p value of 0.079, does this 0.079 relate to the probability of it resulting in a true or false response? Does it matter how i code the input i.e FALSE = 1, TRUE =2 for instance?

If there are two levels in the response then the model is fit
according to the probability of the second versus the first.  You can
disambiguate the process if you convert the response to a factor with
the levels specified explicitly.

The bigger issue is that you shouldn't pay too much attention to a
particular coefficient related to the levels of a factor like E
because the coefficients are defined with respect to the contrasts in
effect at the time the model was fit.  Without knowing the contrasts
being used and without prior knowledge that a particular contrast was
important, those coefficients are not important by themselves.  It is
the cumulative effect of the variability amongst the levels of the
factor that is important.

> Maybe i am reading the output wrong?
> 
> Thanks
> 
> John
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bates at stat.wisc.edu  Wed Aug  4 15:44:24 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 4 Aug 2010 09:44:24 -0400
Subject: [R-sig-ME] Binary response ordering
In-Reply-To: <8FC9DF9E-92C6-49C3-85AC-0B0610439018@me.com>
References: <5113B82C-DBE8-4A1B-8872-7FA6174EAC39@me.com>
	<AANLkTimHPors_t2YkB3QAO1vzGiARZO2e59gwhwwWku3@mail.gmail.com>
	<8FC9DF9E-92C6-49C3-85AC-0B0610439018@me.com>
Message-ID: <AANLkTimdDpAqhfNA4h0YFK25ROG=LOu6hDUNYYMY=1Gu@mail.gmail.com>

On Wed, Aug 4, 2010 at 9:30 AM, John Haart <another83 at me.com> wrote:
> Dear Douglas,
>
> Thanks very much for this,
>
>
>> You can
>> disambiguate the process if you convert the response to a factor with
>> the levels specified explicitly.
>
> I am a little unsure what this means?

I just meant that when you create a factor from a numeric variable you
can either accept the default ordering of the factor levels, which is
lexicographic (if all the numeric values are small integers this
corresponds to numeric ordering but as soon as you get numbers like 10
you have to be careful because 10 sorts before 2 in lexicographic
ordering) or you can impose an ordering.

A glm or glmer model fit for family = binomial with the response a
factor with two levels uses the 2nd level as "success" and the first
level as "failure".

> My response is TRUE or FALSE. However there are different levels of TRUE / FALSE. At this point i have not discriminated between them, as i am unsure how, my thought was to convert them to a continuous factor and use this as a response? Instead of having a multi level categorical response which i don't think is possible in lmer?
>
> Whilst on the subject of P-Values,
>
> I am using AIC model selection rather than P-value based stepwise regression as i feel it is more robust (Burnham & Anderson, 2002). However there seems to be a huge difference in my results.

I'll leave it to others to comment on p-values, AIC, etc.
> The factors with the highest p-values , and therefore retained in the MAM, when i did an explanatory stepwise regression, do not appear in the model with the lowest AIC value - do the two approaches generally not match?
>
> Thanks
>
>
>
>
> On 4 Aug 2010, at 14:15, Douglas Bates wrote:
>
> On Wed, Aug 4, 2010 at 4:54 AM, John Haart <another83 at me.com> wrote:
>> Dear List,
>>
>> I have a quick question regarding the setup of my data for analysis with a glmm. ?I hope this is the appropriate list, i apologise if it is not.
>>
>> I have a response variable, TRUE or FALSE. I have coded this as 0 = False and 1 = TRUE in excel.
>>
>> I have 3 categorical factors with C,D and E
>>
>> I then read in the data frame and run the model as follows-
>>
>> lmer(trueorfalse~1+(1|A/B) + C + D+ E ,family=binomial)
>>
>> And this is the output
>>
>> Generalized linear mixed model fit by the Laplace approximation
>> Formula: threatornot ~ 1 + (1 | A/B) + C + D+ ?E ,family=binomial)
>> ?AIC ?BIC logLik deviance
>> ?1410 1450 -696.8 ? ? 1394
>> Random effects:
>> ?Groups ? ? ? Name ? ? ? ?Variance ? Std.Dev.
>> ?family:order (Intercept) 6.7869e-01 8.2382e-01
>> ?order ? ? ? ?(Intercept) 7.8204e-11 8.8433e-06
>> Number of obs: 1116, groups: A:B, 43; B, 9
>
> Apparently you altered the output at some point because the factors
> that were named A and B ended up as order and family in the random
> effects description.
>
>> Fixed effects:
>> ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
>> (Intercept) ?0.11281 ? ?0.42232 ? 0.267 ? 0.7894
>> C1 ? -0.02414 ? ?0.19964 ?-0.121 ? 0.9038
>> D2 ?-0.16482 ? ?0.38602 ?-0.427 ? 0.6694
>> E2 ? ? ? 0.95381 ? ?0.54316 ? 1.756 ? 0.0791 .
>> E3 ? ? ?0.75733 ? ?0.87275 ? 0.868 ? 0.3855
>> E4 ? ? ? 0.03044 ? ?0.47328 ? 0.064 ? 0.9487
>>
>> What i am unsure about is the inference, if a term is significant does this relate to TRUE or FALSE?
>
> In this case it would be related to the probability of a TRUE response
> but, as this is simply 1 - P(FALSE) then the only change if you
> reversed the order would be to change the signs of the coefficients.
> The simple way to verify this is to fit
>
> glm(threatornot ~ 1)
>
> and check the value of the coefficient. ?It should be
> log(pHat/(1-pHat)) where pHat is the proportion of TRUE responses.
>
>> I.E E2 has a p value of 0.079, does this 0.079 relate to the probability of it resulting in a true or false response? Does it matter how i code the input i.e FALSE = 1, TRUE =2 for instance?
>
> If there are two levels in the response then the model is fit
> according to the probability of the second versus the first. ?You can
> disambiguate the process if you convert the response to a factor with
> the levels specified explicitly.
>
> The bigger issue is that you shouldn't pay too much attention to a
> particular coefficient related to the levels of a factor like E
> because the coefficients are defined with respect to the contrasts in
> effect at the time the model was fit. ?Without knowing the contrasts
> being used and without prior knowledge that a particular contrast was
> important, those coefficients are not important by themselves. ?It is
> the cumulative effect of the variability amongst the levels of the
> factor that is important.
>
>> Maybe i am reading the output wrong?
>>
>> Thanks
>>
>> John
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



From bates at stat.wisc.edu  Wed Aug  4 20:55:13 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 4 Aug 2010 13:55:13 -0500
Subject: [R-sig-ME] lme for split-plot
In-Reply-To: <1280269896.14651.295.camel@globetrotter>
References: <1280269896.14651.295.camel@globetrotter>
Message-ID: <AANLkTi=QodELHisa9YN2TcdmsS+syjd38g+yr8_Lw15A@mail.gmail.com>

2010/7/27 Etienne Lalibert? <etiennelaliberte at gmail.com>:
> I'm analyzing experimental data from a split-plot design, with two
> blocks, each block containing five whole plots, and each whole plot
> containing three subplots.
>
> The multilevel structure of the design dictates the following random
> structure (in the case of a random intercept model):
>
> lme(...., random = ~ 1 | block / wholeplot, ...)
>
> However, if, for a given model, the random effects end up being
> incredibly small, e.g.
>
> Random effects:
> ?Formula: ~1 | block
> ? ? ? ? (Intercept)
> StdDev: 4.639022e-06
>
> ?Formula: ~1 | wholeplot %in% block
> ? ? ? ? (Intercept) ?Residual
> StdDev: 2.256742e-09 0.1911715
>
> Is it still better to leave them in the model, or should I exclude them
> and use gls() instead?

Because of the way that the estimation algorithm in the lme function
worked, you would never get zero for the estimated standard deviation
of the random effects.  These values could be regarded as "effectively
zero" relative to the residual variability.  You could check by
fitting the equivalent model using lmer from the lme4 package, which
does allow for variance component estimates to be zero.



From bates at stat.wisc.edu  Wed Aug  4 21:01:10 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 4 Aug 2010 14:01:10 -0500
Subject: [R-sig-ME] variance-covariance structure of random effects in
	glmer
In-Reply-To: <AANLkTin_LxDtJws+-tkkhC_tAzD4UYoTSca=u78cvwWg@mail.gmail.com>
References: <AANLkTin_LxDtJws+-tkkhC_tAzD4UYoTSca=u78cvwWg@mail.gmail.com>
Message-ID: <AANLkTimeC=o29bicO8pG3p7KHOw-4pR6Ed0mXNFnzYOm@mail.gmail.com>

On Mon, Jul 26, 2010 at 2:15 PM, Tanja Srebotnjak
<Tanja.Srebotnjak at ecologic-institute.us> wrote:
> Hello list members,

> I know I should study the documentation of lme4 but I think you might be
> able to answer my question in a blink: what is the default
> variance-covariance structure used in glmer in a logistic model with logit
> link and family binomial? And can it be changed?

I think you will need to refine your question a bit.  Are you asking
about the variance-covariance structure of the random effects, in
which case it depends on the random-effects terms in the model, or
about the variance-covariance of the conditional distribution of the
response, given the random effects and the values of the parameters.

Generally I would assume you are asking about the first possibility
but, as that doesn't depend on the family or the link, I'm not sure.

> Many thanks in advance!
> Tanja
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From touchtonj at gmail.com  Thu Aug  5 15:37:24 2010
From: touchtonj at gmail.com (touchtonj)
Date: Thu, 5 Aug 2010 15:37:24 +0200
Subject: [R-sig-ME] checking for overdispersion in lmer?
Message-ID: <10D639E2-2783-479D-A37A-D4E6938F070E@gmail.com>

Hello,

How can I check for overdispersion in a lmer with proportion data? There is no residual deviance output like in a glm

thanks ~ janeene


From bates at stat.wisc.edu  Thu Aug  5 17:19:15 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 5 Aug 2010 10:19:15 -0500
Subject: [R-sig-ME] In mer_finalize(ans) : gr cannot be computed at
	initial par (65)
In-Reply-To: <3D675FA33045664383713F4D3A8ED82AB647@ucexchange6.canterbury.ac.nz>
References: <3D675FA33045664383713F4D3A8ED82AB647@ucexchange6.canterbury.ac.nz>
Message-ID: <AANLkTinBjiRpgPX2yNZtfcV68Nk3WsXGFY780JpNpEF4@mail.gmail.com>

On Mon, Aug 2, 2010 at 12:18 AM, Sol Heber
<sol.heber at pg.canterbury.ac.nz> wrote:
> Dear R List ?
>
> I am trying to use a GLMM to analyse data on breeding success from crossing experiments between inbred lines of fruit flies but am having problems.
>
> My response variable is a proportion (proportion of eggs that hatched into adults), I have two fixed factors (one of them, ?cross?, has 4 levels: inbred, 1st or 2nd generation hybrid, and outbred, while the other fixed factor, ?line?, has 3 levels: the initial two lines of fruit flies used for the experiments and the resulting hybrid line), and two random terms ? female and male origin (to control for the fact that eggs of the same pair are not independent).
>
> My experimental design therefore looks something like this (resulting in missing cells in some of the combinations, e.g. there would be no data for the interaction inbred*AB, because in the inbred category there is no mix of the two lines):
>
> Cross ? ? ? ? ? ? ? ? ? ? ? ? ? Lines
> Inbred ? ? ? ? ?AA ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?BB
> Hybrid F1 ? ? ? A1A2 ? ? ? ? ? ?AB ? ? ? ? ? ? ?B1B2
> Hybrid F2 ? ? ? A1A2 ? ? ? ? ? ?AB ? ? ? ? ? ? ?B1B2
> Outbred ? ? ? ? AA ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?BB
>
> I have been using the following commands:
>
>> data<-read.table(file="data.txt",header=TRUE)
>> attach(data)
>> names(data)
> ?[1] "cross" ? ? "line" ? ? ?"forigin" ? "morigin"
> ?[6] "eggs" ? ? ? "adults"
>
>> library(lme4)
>
>> y<-cbind(adults,(eggs-adults))
>
>> model1<-lmer(y~cross*line+(1|forigin)+(1|morigin),family=binomial)
>
> But I get the error message: In mer_finalize(ans) : gr cannot be computed at initial par (65)

> I suppose that I receive this error message because the experimental design is unbalanced, because as soon as I take out the interaction between the explanatory variables, R seems to be able to run the model. But it is precisely the interaction between ?cross? and ?line? that I am interested in.

It appears that you have the classic situation of a two-way layout
with missing cells.  This is an example of a situation where the
symbolic analysis performed by model.matrix does not detect rank
deficiency in the result.

The model with the term cross * line is equivalent to fitting a "cell
means" model which includes the interaction term cross:line but not
the main effects terms cross and line.  However, the model matrix for
cross:line will be constructed properly because it will drop the
unused levels (i.e. the missing cells) in the interaction factor.

So, try to fit with cross:line instead of cross*line.

> So I have tried a different approach, by coding the origin of each individual fly: instead of using ?cross? and ?line? I have tried using maternal grandmother, maternal grandfather, paternal grandmother and paternal grandfather, which combines both the information of ?cross? and ?line? and should avoid the problem of the unbalanced design.
>
> Again, after attaching the data I have been using the following commands:
>
>> names(data)
> ?[1] "mat_granm" ?"mat_granf" "pat_granm" ?"pat_granf" ?"forigin" ?"morigin" ?"eggs" ?"adults"
>
>> y<-cbind(adults,eggs-adults)
>
>> model1<-lmer(y~mat_granm*mat_granf*pat_granm*pat_granf+(1|forigin)+(1|morigin),family=binomial)
>
> This again doesn?t work, but instead of getting an error message, R hangs itself up every time I attempt the analysis (I left it over night to see if it would just take that long, but the program doesn?t react).
>
> Any help would be greatly appreciated, and I would also be happy to make the data available for this purpose.
>
> Sol
>
>
>
> This email may be confidential and subject to legal privilege, it may
> not reflect the views of the University of Canterbury, and it is not
> guaranteed to be virus free. If you are not an intended recipient,
> please notify the sender immediately and erase all copies of the message
> and any attachments.
>
> Please refer to http://www.canterbury.ac.nz/emaildisclaimer for more
> information.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From marianne.promberger at kcl.ac.uk  Thu Aug  5 19:00:30 2010
From: marianne.promberger at kcl.ac.uk (Marianne Promberger)
Date: Thu, 5 Aug 2010 18:00:30 +0100
Subject: [R-sig-ME] lmer() for conjoint analysis? (interpreting coefficients)
Message-ID: <20100805170030.GB2660@evelyn>

Dear list,

I have data from a discrete choice experiment (conjoint analysis). I'm
using lmer(... family=binomial) to analyse the data. I'm posting here
in case there is something I overlooked that makes this analysis
inappropriate. I also have two specific questions.

Our experiment aims to assess subjects' relative preferences between
standard medication and three different alternatives for smoking
cessation, compared to increases in treatment effectiveness.

My main specific questions are:

- Is my interpretation (below) of the coeffcients of the fixed effects
  correct? (I did read Douglas Bates' answer to this post yesterday,
  https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q3/004232.html
  but I am not sure whether I am making that mistake of paying too
  much attention to a particular coefficient)

- How worried need I be about high correlation of fixed effects in my
  second model?

Here's the setup of the study:

Each of 98 subjects made 9 choices, choosing one alternative each
time from pairs of two.

We had prior evidence that subjects would prefer the standard
treatment to any of the alternatives, at equal effectiveness. Hence,
to reduce number of pairs to present to each subject, one option in
each pair was always standard medication at lowest level of
effectiveness (10 out of 100), and the other option was one of the
three alternatives, at equal or better effectiveness: 10 out of 100,
20 out of 100, 40 out of 100. 

str(long)
'data.frame':	882 obs. of  5 variables:
 $ subject      : Factor w/ 98 levels "subject 001",..: 1 2 3 4 5 6 7 8 9 10 ...
 $ alternative  : Factor w/ 3 levels "alt1","alt2",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ effectiveness: Factor w/ 3 levels "10","20","40": 1 1 1 1 1 1 1 1 1 1 ...
 $ choice       : Factor w/ 2 levels "0","1": 1 2 2 1 1 1 1 2 1 2 ...


I fit this model: (model 1)
lmer(choice ~ 0 + alternative + effectiveness + (1|subject), family = binomial, data = long)

                Estimate Std. Error z value Pr(>|z|)    
alternativealt1   -0.363      0.446   -0.81     0.42    
alternativealt2   -0.679      0.448   -1.51     0.13    
alternativealt3    2.422      0.459    5.28  1.3e-07 ***
effectiveness20    2.543      0.321    7.93  2.3e-15 ***
effectiveness40    3.846      0.376   10.22  < 2e-16 ***

The output makes sense and matches the story from a simple barplot
showing percentage choosing standard vs alternative at each level of
effectiveness. (attached - bars are unequal height because I have set
intransitive preferences within an alternative to NA)

Of interest in conjoint analysis are the relative preferences, or
"part-worth utilities", and to my understanding I can get these by
comparing coefficients, e.g. increasing effectiveness from 10 to 40
(3.846) is about 1.5 times as important as increasing effectiveness
from 20 to 40 (revealed in choice behaviour in that more subjects
choose the alternative). Alternatives 1 and 2 are not significant
because standard and alternative get chosen about equally often, but
they can be compared in that alternative 3 is preferred to medication,
and that preference is, e.g., 2.42/.67= 3.6 times stronger than the
slight preference of medication over alternative 2. 

(Ideally, I will do bootstrapping to get empirical confidence
intervals around these coefficients and hence the ratios)

We also asked each subject once about their perceptions of
responsibility for smoking, and had a hypothesis that high perceptions
would lead to rejection of the alternative treatment.

 $ respcause    : int  4 5 6 6 5 5 6 5 4 5 ...

I include the term like this: (OR, do I need (1+respcause|subject)?

model 2:
lmer(choice ~ 0 + alternative + effectiveness + respcause + (1|subject), family = binomial, data = long)

alternativealt1    2.881      1.511    1.91  0.05655 .  
alternativealt2    2.572      1.514    1.70  0.08926 .  
alternativealt3    5.671      1.529    3.71  0.00021 ***
effectiveness20    2.550      0.322    7.92  2.3e-15 ***
effectiveness40    3.856      0.377   10.22  < 2e-16 ***
respcause         -0.753      0.335   -2.25  0.02470 *  

The effect of "respcause" is in the predicted direction (less likely
to choose alternative). Can I compare the coefficient of this effect,
which is at the subject level, to the other coefficients?

The ratios of some coefficients are roughly the same as in model 1,
e.g. between effectiveness20 and effectiveness40, but they change
quite dramatically, e.g., when comparing effectiveness at 40 to
alternative 3. 

Does this mean it is inappropriate to interpret the coefficients in
this way? Or is the appropriate interpretation that knowing how a
subject attributes responsibility (respcause) explains some of their
choice behaviour, and when this knowledge is taken into account, the
relative importance of the other factors changes? The latter
interpretation would make sense in our experiment, as we would have
the hypothesis that the assignment of responsibility makes subjects
prefer standard medication to these specific alternatives, but that
the influence of effectiveness operates on a different level, i.e. the
variance that gets picked up by respcause was previously picked up by
the alternatives, but changing effectiveness adds 'independent'
variance.

Is this making sense?

Maybe related is the correlation of the fixed effects for model 2,
which is very high for the alternatives and respcause, respectively --
I guess if this were a different type of study I'd have to worry that
the model is overparametrized, but in this case this is part of the
message -- or do I have to worry about this after all?

Correlation of Fixed Effects:
            altrn1 altrn2 altrn3 effc20 effc40
alterntvlt2  0.982                            
alterntvlt3  0.971  0.970                     
effctvnss20 -0.051 -0.058  0.014              
effctvnss40 -0.039 -0.047  0.040  0.559       
respcause   -0.956 -0.956 -0.955 -0.048 -0.059


I hope I'm not totally off. 

Thanks

Marianne











-- 
Marianne Promberger PhD, King's College London
http://promberger.info
R version 2.11.1 (2010-05-31)
Ubuntu 9.10
-------------- next part --------------
A non-text attachment was scrubbed...
Name: choose.png
Type: image/png
Size: 6636 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100805/ca95987b/attachment.png>

From john.maindonald at anu.edu.au  Fri Aug  6 00:31:09 2010
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Fri, 6 Aug 2010 08:31:09 +1000
Subject: [R-sig-ME] checking for overdispersion in lmer?
In-Reply-To: <10D639E2-2783-479D-A37A-D4E6938F070E@gmail.com>
References: <10D639E2-2783-479D-A37A-D4E6938F070E@gmail.com>
Message-ID: <A43C9B08-8098-470F-B153-DA9077F71622@anu.edu.au>

The totals (input as weights if you are fitting proportions) need
to be supplied, with family=binomial.  You need to model the
extra variance, with observation level random effects.  If you
need an example, some of can supply one.  I gave an example
for overdispersed Poisson in a Dec 12 message last year.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 05/08/2010, at 11:37 PM, touchtonj wrote:

> Hello,
> 
> How can I check for overdispersion in a lmer with proportion data? There is no residual deviance output like in a glm
> 
> thanks ~ janeene
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From andyfugard at gmail.com  Fri Aug  6 13:41:27 2010
From: andyfugard at gmail.com (Andy Fugard)
Date: Fri, 6 Aug 2010 13:41:27 +0200
Subject: [R-sig-ME] lmer() for conjoint analysis? (interpreting
	coefficients)
In-Reply-To: <20100805170030.GB2660@evelyn>
References: <20100805170030.GB2660@evelyn>
Message-ID: <AANLkTinvcnqc13hFK9GWB2OPam+O9pjcFU84GJ5HyExx@mail.gmail.com>

Dear Marianne,


On Thu, Aug 5, 2010 at 19:00, Marianne Promberger
<marianne.promberger at kcl.ac.uk> wrote:

>
> Each of 98 subjects made 9 choices, choosing one alternative each
> time from pairs of two.

Is this coded so that the model is predicting probability of choosing
the a priori determined best option for all 9 comparisons?

>
> We had prior evidence that subjects would prefer the standard
> treatment to any of the alternatives, at equal effectiveness. Hence,
> to reduce number of pairs to present to each subject, one option in
> each pair was always standard medication at lowest level of
> effectiveness (10 out of 100), and the other option was one of the
> three alternatives, at equal or better effectiveness: 10 out of 100,
> 20 out of 100, 40 out of 100.
>
> str(long)
> 'data.frame': ? 882 obs. of ?5 variables:
> ?$ subject ? ? ?: Factor w/ 98 levels "subject 001",..: 1 2 3 4 5 6 7 8 9 10 ...
> ?$ alternative ?: Factor w/ 3 levels "alt1","alt2",..: 1 1 1 1 1 1 1 1 1 1 ...
> ?$ effectiveness: Factor w/ 3 levels "10","20","40": 1 1 1 1 1 1 1 1 1 1 ...
> ?$ choice ? ? ? : Factor w/ 2 levels "0","1": 1 2 2 1 1 1 1 2 1 2 ...

(Just a thought: I find it easier to interpret logistic fits if I
encode the dependent variable values to be numerical 0s and 1s, rather
than a factor.)

>
> I fit this model: (model 1)
> lmer(choice ~ 0 + alternative + effectiveness + (1|subject), family = binomial, data = long)
>
> ? ? ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
> alternativealt1 ? -0.363 ? ? ?0.446 ? -0.81 ? ? 0.42
> alternativealt2 ? -0.679 ? ? ?0.448 ? -1.51 ? ? 0.13
> alternativealt3 ? ?2.422 ? ? ?0.459 ? ?5.28 ?1.3e-07 ***

Is one of these the standard medication, then?

Also why did you get rid of the intercept?  Might make sense to push
the standard medication into the intercept, then you can see if
participants always prefer it over the others (i.e., the others will
have negative coefficients).

> effectiveness20 ? ?2.543 ? ? ?0.321 ? ?7.93 ?2.3e-15 ***
> effectiveness40 ? ?3.846 ? ? ?0.376 ? 10.22 ?< 2e-16 ***

Okay, so these three are comparisons with effectiveness20, which is coded as 0.

>
> Of interest in conjoint analysis are the relative preferences, or
> "part-worth utilities", and to my understanding I can get these by
> comparing coefficients, e.g. increasing effectiveness from 10 to 40
> (3.846) is about 1.5 times as important as increasing effectiveness
> from 20 to 40 (revealed in choice behaviour in that more subjects
> choose the alternative). Alternatives 1 and 2 are not significant
> because standard and alternative get chosen about equally often, but
> they can be compared in that alternative 3 is preferred to medication,
> and that preference is, e.g., 2.42/.67= 3.6 times stronger than the
> slight preference of medication over alternative 2.

Have you tried getting the mean predictions from the model, feeding
them through invlogit?  Can be helpful to see what's going on
within-subject between conditions.

Also you could use relevel to code the variables to make the
comparisons you want.  Or use one of the multiple comparisons
packages, sometimes discussed on this list.

>
> We also asked each subject once about their perceptions of
> responsibility for smoking, and had a hypothesis that high perceptions
> would lead to rejection of the alternative treatment.
>
> ?$ respcause ? ?: int ?4 5 6 6 5 5 6 5 4 5 ...

This sounds like a hypothesized interaction between respcause and alternative.

M1 = lmer(choice ~ 1 + alternative + effectiveness + respcause +
(1|subject), family = binomial, data = long)

M2 = lmer(choice ~ 1 + alternative + effectiveness + respcause +
alternative:respcause + (1|subject), family = binomial, data = long)

anova(M1,M2)

Just some thoughts.  Maybe I've partially understood what you're doing!

Cheers,

Andy



From david.schoeman at gmail.com  Fri Aug  6 14:17:31 2010
From: david.schoeman at gmail.com (Dave Schoeman)
Date: Fri, 6 Aug 2010 13:17:31 +0100
Subject: [R-sig-ME] Multiple before-after control-impact analysis
Message-ID: <75069CDA-59D7-4A76-BA83-FE89F7044145@gmail.com>

I'd like to pick up a thread posted by Nikolaos Lampadariou in 2008. I am trying to analyse the MBACI design of Keough & Quinn (Legislative vs. practical protection of an 
intertidal shoreline in southeastern Australia. Ecol. Appl. 2000. 10: 871-881). The design is simple: samples were taken at 8 Sites, of which 2 were "protected" and 6 were not; protection ended some time into the study; samples were taken annually at each site for three years prior to the end of protection and for 5 years afterwards. The response variable is a single value for each year-site combination. This leaves us with the fixed factors BA (two levels: before or after), H (two levels: protected or not) and Year (nested within BA). The random factor Site has 8 levels and is nested within H. Keough and Quinn use a repeated-measures ANOVA to fit the following terms: H, BA, H*BA, Site(H), Year(BA), Site(H)*BA and Year(BA)*H. Because there is no replication at the highest level interaction, this is left out of the model.

Nikolaos kindly provided code to simulate the resulting data:
	site<-c(rep(c("A1","A2", "RR1", "RR2", "WT1", "WT2", "WT3", "WT4"),8))
	H<-c(rep(c("exp", "exp", "prot", "pro", "exp", "exp", "exp", "exp"), 8))
	year<-c(rep(1989,8), rep(1990,8), rep(1991,8), rep(1993,8), rep(1994,8), rep(1995,8), rep(1996,8), rep(1997,8))
	BA<-c(rep("bef",24), rep("after",40))
	abund<-runif(64, min=0, max=10)
	harvest<-data.frame(abund, BA, H, site, year)

He suggested fitting the model using lmer something like this:
	harvest.lmer<-lmer(abund~H*BA+BA/year+BA/year:H+H/site:BA+(1|H/site), harvest)

When I run this model, I get the dreaded "Error in mer_finalize(ans) : Downdated X'X is not positive definite, 12." error. Following recent advice on this thread, I tried dropping terms one at a time, and found that the problem lies with the H/site:BA term; omitting this allows the model to run without problem.

My questions are:
1 - Does the specified model look correct according to the experimental design described (or could the model specification causing the error)?
2 - Would I be justified in simply omitting the offending term?

Any comments appreciated.

- Dave


From marianne.promberger at kcl.ac.uk  Fri Aug  6 15:33:06 2010
From: marianne.promberger at kcl.ac.uk (Marianne Promberger)
Date: Fri, 6 Aug 2010 14:33:06 +0100
Subject: [R-sig-ME] lmer() for conjoint analysis? (interpreting
 coefficients)
In-Reply-To: <AANLkTinvcnqc13hFK9GWB2OPam+O9pjcFU84GJ5HyExx@mail.gmail.com>
References: <20100805170030.GB2660@evelyn>
	<AANLkTinvcnqc13hFK9GWB2OPam+O9pjcFU84GJ5HyExx@mail.gmail.com>
Message-ID: <20100806133306.GA2901@evelyn>

Dear Andy,

Many thanks for the quick reply. Sorry if I was unclear, a few
clarifications below:

Andy Fugard <andyfugard at gmail.com> 06-Aug-10 12:41:
> On Thu, Aug 5, 2010 at 19:00, Marianne Promberger
> <marianne.promberger at kcl.ac.uk> wrote:
> >
> > Each of 98 subjects made 9 choices, choosing one alternative each
> > time from pairs of two.
> 
> Is this coded so that the model is predicting probability of choosing
> the a priori determined best option for all 9 comparisons?

Not entirely sure what you mean, but it is coded so "1" = "subject
chooses the alternative" (which in each case was either alt1 or alt2
or alt3; "0" = "subject chooses standard med". One clarification is
that the alternatives are all non-medical (behavioral), i.e., they are
mores similar to each other than any is to standard med.

> > We had prior evidence that subjects would prefer the standard
> > treatment to any of the alternatives, at equal effectiveness. Hence,
> > to reduce number of pairs to present to each subject, one option in
> > each pair was always standard medication at lowest level of
> > effectiveness (10 out of 100), and the other option was one of the
> > three alternatives, at equal or better effectiveness: 10 out of 100,
> > 20 out of 100, 40 out of 100.
> >
> > str(long)
> > 'data.frame': ? 882 obs. of ?5 variables:
> > ?$ subject ? ? ?: Factor w/ 98 levels "subject 001",..: 1 2 3 4 5 6 7 8 9 10 ...
> > ?$ alternative ?: Factor w/ 3 levels "alt1","alt2",..: 1 1 1 1 1 1 1 1 1 1 ...
> > ?$ effectiveness: Factor w/ 3 levels "10","20","40": 1 1 1 1 1 1 1 1 1 1 ...
> > ?$ choice ? ? ? : Factor w/ 2 levels "0","1": 1 2 2 1 1 1 1 2 1 2 ...
> 
> (Just a thought: I find it easier to interpret logistic fits if I
> encode the dependent variable values to be numerical 0s and 1s, rather
> than a factor.)

Thanks, makes sense. I've done this now but so far for the lmer() no difference in output.

> > I fit this model: (model 1)
> > lmer(choice ~ 0 + alternative + effectiveness + (1|subject), family = binomial, data = long)
> >
> > ? ? ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
> > alternativealt1 ? -0.363 ? ? ?0.446 ? -0.81 ? ? 0.42
> > alternativealt2 ? -0.679 ? ? ?0.448 ? -1.51 ? ? 0.13
> > alternativealt3 ? ?2.422 ? ? ?0.459 ? ?5.28 ?1.3e-07 ***
> 
> Is one of these the standard medication, then?

No. Standard med is not explicitly coded, as it  is always the
"backdrop" (always the constant option). 

Exhaustive list of choices each subject saw:

med (helps 10%) vs alt1 (helps 10%)
med (helps 10%) vs alt1 (helps 20%)
med (helps 10%) vs alt1 (helps 40%)

med (helps 10%) vs alt2 (helps 10%)
med (helps 10%) vs alt2 (helps 20%)
med (helps 10%) vs alt2 (helps 40%)

med (helps 10%) vs alt3 (helps 10%)
med (helps 10%) vs alt3 (helps 20%)
med (helps 10%) vs alt3 (helps 40%)

> Also why did you get rid of the intercept?  Might make sense to push
> the standard medication into the intercept, then you can see if
> participants always prefer it over the others (i.e., the others will
> have negative coefficients).

This is why I set it to have no intercept -- because I find it
confusing when one of the three alternatives is in the intercept, if
that makes sense. Coefficients for the alternatives are meaningful as
compared to the (implicit, constant) "standard med" option. Negative
coefficients should mean standard med is preferred, positive
coefficients should mean alternative is preferred (since it is coded
as 1). This matches the result visible in the barplot (bars represent
which alternative was shown, but the choice was always between that
type of alternative and standard med, and colors in the barplot
correspond to that).

> > effectiveness20 ? ?2.543 ? ? ?0.321 ? ?7.93 ?2.3e-15 ***
> > effectiveness40 ? ?3.846 ? ? ?0.376 ? 10.22 ?< 2e-16 ***
> 
> Okay, so these three are comparisons with effectiveness20, which is coded as 0.

Yes.

> > Of interest in conjoint analysis are the relative preferences, or
> > "part-worth utilities", and to my understanding I can get these by
> > comparing coefficients, e.g. increasing effectiveness from 10 to 40
> > (3.846) is about 1.5 times as important as increasing effectiveness
> > from 20 to 40 (revealed in choice behaviour in that more subjects
> > choose the alternative). Alternatives 1 and 2 are not significant
> > because standard and alternative get chosen about equally often, but
> > they can be compared in that alternative 3 is preferred to medication,
> > and that preference is, e.g., 2.42/.67= 3.6 times stronger than the
> > slight preference of medication over alternative 2.
> 
> Have you tried getting the mean predictions from the model, feeding
> them through invlogit?  Can be helpful to see what's going on
> within-subject between conditions.

No. I didn't know about invlogit, thanks. 

> Also you could use relevel to code the variables to make the
> comparisons you want.  Or use one of the multiple comparisons
> packages, sometimes discussed on this list.

Ok, I'll look into that, too. 

I'm still interested in whether I can directly compare the
coefficients in the model. I like this because it is straightforward,
and there is previous literature in the field where this is aimed at
in terms of publication using this method with a "random effects
probit" (of unspecified statistical package provenance).(*)

I guess I'm just not sure whether lmer() is sufficiently different for
this interpretation not to be warranted, and/or whether the
interpretation will not work for coefficients of variables sitting at
different levels, as it were (type of alternative and effectiveness
are at the level of each choice, respcause at the level of subject).

> > We also asked each subject once about their perceptions of
> > responsibility for smoking, and had a hypothesis that high perceptions
> > would lead to rejection of the alternative treatment.
> >
> > ?$ respcause ? ?: int ?4 5 6 6 5 5 6 5 4 5 ...
> 
> This sounds like a hypothesized interaction between respcause and alternative.

No. I hope this is clearer now, as it refers to subjects choosing any
of the three alternative (i.e., proportion picking "1") given their
rating for respcause -- regardless of which is the type of alternative.

But I have compared my model 1 and model 2 using anova() and the model
including the main effect of respcause comes out better.

I am currently trying to generate plots that show the effect of
respcause, by giving a different barplot for subjects answering at
each level of the latter and collapsing once across level, of
effectiveness and once across type of alternative.

Thanks

Marianne


(*)
Ryan, M. and Farrar, S. (2000). Using conjoint analysis to elicit
preferences for health care. BMJ, 320(7248):1530-1533.

Ratcliffe, J., Bekker, H. L., Dolan, P., and Edlin,
R. (2009). Examining the attitudes and preferences of health care
decision-makers in relation to access, equity and cost-effectiveness:
A discrete choice experiment. Health Policy, 90(1):45-57.


-- 
Marianne Promberger PhD, King's College London
http://promberger.info
R version 2.11.1 (2010-05-31)
Ubuntu 9.10



From mcbilton at hotmail.com  Fri Aug  6 16:39:13 2010
From: mcbilton at hotmail.com (Mark Bilton)
Date: Fri, 6 Aug 2010 14:39:13 +0000 (UTC)
Subject: [R-sig-ME] Generalised Linear Mixed Model with Moving Average
Message-ID: <loom.20100806T150506-86@post.gmane.org>

Dear all potential friends,

I am having a few problems with a glmer I am trying to create in R.
Some of the them are the normal basic problems (defining random factors
correctly) and some are a bit complicated (ie including a moving average). I
have done a lot of reading and I've been going round in circles and I'm just not
sure about some things. So, any help will be greatly appreciated.

Firstly I will define my dataset and objectives:

My data to be modelled is the abundance of a plant species in a fixed quadrat
(and for the purposes of this post, just 1 species).
I have a spatial hierachical design. At a site, I have 15 'plots', each plot
contains 5 'quadrats'.

I have a 'treatment' of 3 climates (control, +water, -water), and so for the 15
plots 5 of them were assigned to each treatment (therefore 5 is my 'real'
replication per treatment).

The data for each species was also recorded for 8 'years'.
The first year no treatment was applied to any plots.

My objective is to find if there is a change in species abundance across time
(slope) for the different climate treatments.

Firstly, I will only talk about the full model (and not the comparisons for full
significance testing).

Year is a continuous variable.
Plot, Treatment, and Quadrat are factors.

The model I have then is:

Model1<-glmer(Species~Year*Treatment+(1|Plot), REML = FALSE, family=poisson,
na.action = na.omit)

You will notice that I am looking at log-likelihood to compare my models. That I
am modelling with a poisson link function. And that my data contains some NA's
which are omitted in the analysis.

QUESTION 1:
I do not include 'Quadrat' as a random variable (as stated in Crawley R book for
the lowest level of the hierarchy). However, I am not sure if this is correct,
as I do get slightly different results when included or not. So, for the spatial
nesting should I use ((1|Plot/Quadrat) ??

QUESTION 2:
Do I need to include 'Year' in the random variables as well ?
I have tried  (1|Plot) + (Year|Plot) (doesn't converge) and just (Year|Plot)
(doesn't converge) and (as.factor(Year)|Plot) (doesn't converge). The lack of
converging may be due to a large amount of zero's in my dataset, but not sure if
this is the case or not.

QUESTION 3:
I could include a covariate for the level of the species in the first year.
Although, I am not sure this is necessary as I am really interested in slope (ie
the interaction between Year and Treatment), and a covariate should not alter
this. Do you agree with my statement, or do you think I should include it ? If I
do include it, is this a fixed or random variable. My feeling was random, but a
colleague disagreed.

QUESTION 4:
I also want to test some moving average models using this framework. Is it
possible to do this with glmer ?? I tried coding a simple function myself for
different lag distances, but the averages then are not integers, which the
poisson link function does not like. Any suggestions as to how I could run this,
either within glmer, lmer, or something like the 'arima' function ?? (although I
struggle to set up a time series dataset (ts) with the nested data). For
example, I tried just using (log(Species+1)) for the data, but for the original
model, I lose my significant differences between slopes.

Finally then
QUESTION 5:
Using the full model I can use the default contrasts (contr.treatment) to look
for significance between the slopes. Although clearly I should further
investigate whether these aspects of the model should be included in the final
model (e.g. look at model with the same slope, same intercept etc). The default
contrasts are good for what I want, but I also want to see if I can have a
single slope or intercept for 2 of the treatments, and different for the other
one. Contrasts have always confused me, and my logical thought was
[2,-1,-1];[-1,2,-1];[-1,-1,2] but this doesn't seem to do what I thought it
would. This is not quite as important as the other aspects, but if you do have
any advice, it would be gratefully received.

I know there are a number of questions here. But I hope the details are fairly
clear. Any help you can offer on just one question would be great.

Thank you for your time
Mark



From bbolker at gmail.com  Fri Aug  6 22:36:45 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 6 Aug 2010 20:36:45 +0000 (UTC)
Subject: [R-sig-ME] Plot a &quot;mer&quot; object
References: <9F6C251E0C38456D8C9FEDE9F761C6CA@Negro1>
Message-ID: <loom.20100806T223346-181@post.gmane.org>

Luciano La Sala <lucianolasala at ...> writes:

> I fitted a glmm on a small dataset using lme4. Data consist of dependent
> variable "Egg_Volume" (continuous) and independent variables "Hatching
> Order" (3 factors: first, second, third), "Year" (2 factors: 2006, 2007) and
> their interaction (Hatching_Order*Year). Nest IDs were included as random
> intercepts. 

[snip]

> I've been trying to come to grips with the function "plotLMER.fnc" from
> "languageR" package to plot my results, but so far I have not succeeded. 

> >From the relevant documentation
> (http://bm2.genes.nig.ac.jp/RGM2/R_current/library/languageR/man/plotLMER.fn
> c.html) there are some arguments which I am not sure how to specify
> (indicated with "???" below).  
> 
> plotLMER.fnc(mixto.4a, xlabel = NA, xlabs = "Year", ylabel = "Egg Volume",
> ylimit = NA, fun = NA, pred = NA, n = ????, intr = ????, "end", mcmcMat =
> NA, lockYlim = TRUE, addlines = TRUE, withList = FALSE, cexsize = 0.5)

  When in doubt, why not try leaving these arguments at their
default values (n=100 and intr=NA)?  Then, if you like the results,
you're done ...

  (Gmane wants me to add more before it will let me post -- I don't
want to quote any less than is here.)



From daniel.lists at zeno.co.nz  Sat Aug  7 00:26:13 2010
From: daniel.lists at zeno.co.nz (Daniel Myall)
Date: Sat, 07 Aug 2010 10:26:13 +1200
Subject: [R-sig-ME] Update: Easiest way to install lme4 on Mac OS X
Message-ID: <4C5C8C05.4090703@zeno.co.nz>

Hi,

I've had several off-list emails inquiring about installing lme4 on Mac 
OS X and the progress in determining the cause of the non-deterministic 
behaviour. Hence, a quick update:


Easiest way of installing lme4:

The package is available from R-forge as package checks are not run for 
Mac OS X on R-forge (hence the non-deterministic behaviour under Mac 
isn't flagged). However, I would only run lme4 under R 64 bit on Mac 
(where no issues have been observed).

Download and install gfortran from 
http://cran.r-project.org/bin/macosx/tools/ (available as a dmg which 
installs the required libraries for the builds from R-forge into 
/usr/local/)

In R run: install.packages(c("Matrix","lme4"), 
repos="http://R-Forge.R-project.org")


Summary of clues to what may be the cause of non-deterministic results 
of identical calls:

* I've only observed it with slightly-pathological cases and not with 
real experimental data (there will of course be real experimental data 
where the bug is exposed).
* Has only been observed in 32 bit R and not 64 bit R.
* Occurs with both vecLib and R BLAS on 10.5.8 but only with vecLib BLAS 
on 10.6.4.
* Occurs with all versions of lme4/Matrix in the past two years when run 
on R 2.11.1.
* lme4a has a slightly different behaviour in that, instead of only two 
potential results, every run has a different result.


When I have some more time I'll dig deeper into debugging each run to 
try to figure out exactly where the non-deterministic behaviour is 
creeping in. I want to get this resolved so that the package appears on 
CRAN again.

Cheers,
Daniel



From bbolker at gmail.com  Sat Aug  7 04:48:33 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 7 Aug 2010 02:48:33 +0000 (UTC)
Subject: [R-sig-ME] Generalised Linear Mixed Model with Moving Average
References: <loom.20100806T150506-86@post.gmane.org>
Message-ID: <loom.20100807T041524-901@post.gmane.org>

Mark Bilton <mcbilton at ...> writes:

> I am having a few problems with a glmer I am trying to create in R.

 [snip]
 
> My data to be modelled is the abundance of a plant species in a fixed quadrat
> (and for the purposes of this post, just 1 species).
> I have a spatial hierachical design. At a site, I have 15 'plots', each plot
> contains 5 'quadrats'.

  A single site, or multiple sites?
 
> I have a 'treatment' of 3 climates (control, +water, -water), and
> so for the 15
> plots 5 of them were assigned to each treatment (therefore 5 is my 'real'
> replication per treatment).
> 
> The data for each species was also recorded for 8 'years'.
> The first year no treatment was applied to any plots.
> 
> My objective is to find if there is a change in species abundance across time
> (slope) for the different climate treatments.
> 
> Firstly, I will only talk about the full model 
> (and not the comparisons for full
> significance testing).
> 
> Year is a continuous variable.
> Plot, Treatment, and Quadrat are factors.

  Do you really need to keep quadrats separate?  If you take the
mean of quadrats to get a single value for each plot, are your
data adequately/approximately normally distributed?  This would let
you do a LMM instead of a GLMM, which would simplify your life.
In fact, then you might not need a LMM at all.

> 
> The model I have then is:
> 
> Model1<-glmer(Species~Year*Treatment+(1|Plot), REML = FALSE, family=poisson,
> na.action = na.omit)

  REML=FALSE is redundant/ignored in glmer, as explained in a recent
thread on this list.

> QUESTION 1:
> I do not include 'Quadrat' as a random variable 
> (as stated in Crawley R book for
> the lowest level of the hierarchy). However, I am not sure if this is correct,
> as I do get slightly different results when included or not. 
> So, for the spatial
> nesting should I use ((1|Plot/Quadrat) ??

  If you include quadrat, then you are essentially allowing for
extra-Poisson variation in the samples, or equivalently using
a lognormal-Poisson rather than a Poisson distribution.  If your
model is feasible and there is a non-negligible amount of variability
estimated at the among-quadrat/within-plot level, you probably
do want to retain quadrat as a random variable (or lump and hope
for normality, see above).

> QUESTION 2:
> Do I need to include 'Year' in the random variables as well ?
> I have tried  (1|Plot) + (Year|Plot) (doesn't converge) and just (Year|Plot)
> (doesn't converge) and (as.factor(Year)|Plot) (doesn't converge). The lack of
> converging may be due to a large amount of zero's in my dataset, 
> but not sure if
> this is the case or not.

  If you include (Year|Plot), you are allowing for
the possibility that there is random variation in slopes (as well
as intercepts) across plots.  as.factor(Year)|Plot allows for random
(not necessarily linear) year-to-year variation that varies across plots.

(1|Plot) and (Year|Plot) should be the same, because the latter includes
an implicit intercept term.
> 
> QUESTION 3:
> I could include a covariate for the level of the species in the first year.
> Although, I am not sure this is necessary as I am really interested 
> in slope (ie
> the interaction between Year and Treatment), and a covariate should not alter
> this. Do you agree with my statement, or do you think I should include it ?
> If I do include it, is this a fixed or random variable. 
> My feeling was random, but a
> colleague disagreed.

  It's certainly not impossible that there could be a relationship
between overall level and slope. Have you tried looking at the data?
Fixed makes more sense to me.
 
> QUESTION 4:
> I also want to test some moving average models using this framework. Is it
> possible to do this with glmer ?? I tried coding a simple function myself for
> different lag distances, but the averages then are not integers, which the
> poisson link function does not like.

  glmer does not allow so-called 'R-side' correlation structures;
nor does lmer.  You can do this in lme, and possibly handle a GLMM
with such correlation structures in glmmPQL (in the MASS package),
but glmmPQL has some disadvantages.

  I would suggest you look at the residuals from an otherwise
full model to see if there is any hint of temporal autocorrelation ...
this is a pretty small/short data set for detecting temporal autocorrelation.
> 

  I'm going to let someone else have question 5.



From d.schoeman at ulster.ac.uk  Sat Aug  7 07:38:06 2010
From: d.schoeman at ulster.ac.uk (Dave Schoeman)
Date: Sat, 7 Aug 2010 06:38:06 +0100
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 44, Issue 19
In-Reply-To: <mailman.7390.1281127028.4244.r-sig-mixed-models@r-project.org>
References: <mailman.7390.1281127028.4244.r-sig-mixed-models@r-project.org>
Message-ID: <E1D4019E-BA85-4401-935E-05231C035C89@ulster.ac.uk>

Sorry, all, there is a typo in the code submitted below. The SECOND line of code should read:

	H<-c(rep(c("exp", "exp", "pro", "pro", "exp", "exp", "exp", "exp"), 8))

i.e., the first code for protection should be "pro" like the rest, rather than "prot".

Very sorry about that.

- Dave


> Message: 2
> Date: Fri, 6 Aug 2010 13:17:31 +0100
> From: Dave Schoeman <david.schoeman at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Multiple before-after control-impact analysis
> Message-ID: <75069CDA-59D7-4A76-BA83-FE89F7044145 at gmail.com>
> Content-Type: text/plain; charset=us-ascii
> 
> I'd like to pick up a thread posted by Nikolaos Lampadariou in 2008. I am trying to analyse the MBACI design of Keough & Quinn (Legislative vs. practical protection of an 
> intertidal shoreline in southeastern Australia. Ecol. Appl. 2000. 10: 871-881). The design is simple: samples were taken at 8 Sites, of which 2 were "protected" and 6 were not; protection ended some time into the study; samples were taken annually at each site for three years prior to the end of protection and for 5 years afterwards. The response variable is a single value for each year-site combination. This leaves us with the fixed factors BA (two levels: before or after), H (two levels: protected or not) and Year (nested within BA). The random factor Site has 8 levels and is nested within H. Keough and Quinn use a repeated-measures ANOVA to fit the following terms: H, BA, H*BA, Site(H), Year(BA), Site(H)*BA and Year(BA)*H. Because there is no replication at the highest level interaction, this is left out of the model.
> 
> Nikolaos kindly provided code to simulate the resulting data:
> 	site<-c(rep(c("A1","A2", "RR1", "RR2", "WT1", "WT2", "WT3", "WT4"),8))
> 	H<-c(rep(c("exp", "exp", "prot", "pro", "exp", "exp", "exp", "exp"), 8))
> 	year<-c(rep(1989,8), rep(1990,8), rep(1991,8), rep(1993,8), rep(1994,8), rep(1995,8), rep(1996,8), rep(1997,8))
> 	BA<-c(rep("bef",24), rep("after",40))
> 	abund<-runif(64, min=0, max=10)
> 	harvest<-data.frame(abund, BA, H, site, year)
> 
> He suggested fitting the model using lmer something like this:
> 	harvest.lmer<-lmer(abund~H*BA+BA/year+BA/year:H+H/site:BA+(1|H/site), harvest)
> 
> When I run this model, I get the dreaded "Error in mer_finalize(ans) : Downdated X'X is not positive definite, 12." error. Following recent advice on this thread, I tried dropping terms one at a time, and found that the problem lies with the H/site:BA term; omitting this allows the model to run without problem.
> 
> My questions are:
> 1 - Does the specified model look correct according to the experimental design described (or could the model specification causing the error)?
> 2 - Would I be justified in simply omitting the offending term?
> 
> Any comments appreciated.
> 
> - Dave
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> End of R-sig-mixed-models Digest, Vol 44, Issue 19
> **************************************************
> 



From reinhold.kliegl at gmail.com  Sat Aug  7 13:58:36 2010
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Sat, 7 Aug 2010 13:58:36 +0200
Subject: [R-sig-ME] Update: Easiest way to install lme4 on Mac OS X
In-Reply-To: <4C5C8C05.4090703@zeno.co.nz>
References: <4C5C8C05.4090703@zeno.co.nz>
Message-ID: <AANLkTik-h1pZ44YG4j1dbRmY_VozLD-8r9z2CuqBcp0j@mail.gmail.com>

As to point one:
> * I've only observed it with slightly-pathological cases and not with real
> experimental data (there will of course be real experimental data where the
> bug is exposed)
I have observed it for experimental data (non pathological, I hope).
The effect was one decimal point in the t-value (1.9 vs. 2.0). (Not
that I do care too much about 0.1-differences in t-values, but I know
that some do.). Anyway, 32-bit R for MacOS X should be "out", in my
opinion. Could one change the default installation to 64-bit?

Reinhold Kliegl.

On Sat, Aug 7, 2010 at 12:26 AM, Daniel Myall <daniel.lists at zeno.co.nz> wrote:
> Hi,
>
> I've had several off-list emails inquiring about installing lme4 on Mac OS X
> and the progress in determining the cause of the non-deterministic
> behaviour. Hence, a quick update:
>
>
> Easiest way of installing lme4:
>
> The package is available from R-forge as package checks are not run for Mac
> OS X on R-forge (hence the non-deterministic behaviour under Mac isn't
> flagged). However, I would only run lme4 under R 64 bit on Mac (where no
> issues have been observed).
>
> Download and install gfortran from
> http://cran.r-project.org/bin/macosx/tools/ (available as a dmg which
> installs the required libraries for the builds from R-forge into
> /usr/local/)
>
> In R run: install.packages(c("Matrix","lme4"),
> repos="http://R-Forge.R-project.org")
>
>
> Summary of clues to what may be the cause of non-deterministic results of
> identical calls:
>
> * I've only observed it with slightly-pathological cases and not with real
> experimental data (there will of course be real experimental data where the
> bug is exposed).
> * Has only been observed in 32 bit R and not 64 bit R.
> * Occurs with both vecLib and R BLAS on 10.5.8 but only with vecLib BLAS on
> 10.6.4.
> * Occurs with all versions of lme4/Matrix in the past two years when run on
> R 2.11.1.
> * lme4a has a slightly different behaviour in that, instead of only two
> potential results, every run has a different result.
>
>
> When I have some more time I'll dig deeper into debugging each run to try to
> figure out exactly where the non-deterministic behaviour is creeping in. I
> want to get this resolved so that the package appears on CRAN again.
>
> Cheers,
> Daniel
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From amelie.lescroel at univ-rennes1.fr  Mon Aug  9 14:27:55 2010
From: amelie.lescroel at univ-rennes1.fr (Amelie Lescroel)
Date: Mon, 9 Aug 2010 14:27:55 +0200
Subject: [R-sig-ME] Clarification needed about the terminology used when
	talking about mixed models
Message-ID: <25CEA3FCB11E4C49B56D41AD368545C2@Gentoo>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100809/e8f17424/attachment.pl>

From amelie.lescroel at univ-rennes1.fr  Mon Aug  9 15:11:12 2010
From: amelie.lescroel at univ-rennes1.fr (Amelie Lescroel)
Date: Mon, 9 Aug 2010 15:11:12 +0200
Subject: [R-sig-ME] Clarification needed about the terminology used when
	talking about mixed models
In-Reply-To: <4C5FFA75.1000708@uoguelph.ca>
References: <4C5FFA75.1000708@uoguelph.ca>
Message-ID: <98E7B860B3F748EF88C2725A63102185@Gentoo>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100809/bfde91ac/attachment.pl>

From amelie.lescroel at univ-rennes1.fr  Mon Aug  9 15:18:22 2010
From: amelie.lescroel at univ-rennes1.fr (Amelie Lescroel)
Date: Mon, 9 Aug 2010 15:18:22 +0200
Subject: [R-sig-ME] Clarification needed about the terminology used
	whentalking about mixed models
In-Reply-To: <4CF2646FA7AADD49A08570779F45B78D01BCF83A@SVMAIL6.domain.siouxvalley.local>
References: <25CEA3FCB11E4C49B56D41AD368545C2@Gentoo>
	<4CF2646FA7AADD49A08570779F45B78D01BCF83A@SVMAIL6.domain.siouxvalley.local>
Message-ID: <A8BE6BF5ACD7426184FF4A1EF249759E@Gentoo>

Thanks a lot Paul. Thus I should be able to fit a random regression model
using lmer. You'll probably hear from me at that time!

-----Original Message-----
From: Thompson,Paul [mailto:Paul.Thompson at sanfordhealth.org] 
Sent: Monday, August 09, 2010 3:08 PM
To: Amelie Lescroel; r-sig-mixed-models at r-project.org
Subject: RE: [R-sig-ME] Clarification needed about the terminology used
whentalking about mixed models


I can start.

1) Mixed models are models which include fixed and random effects.  Mixed
models can be used to estimate and test multi-level models, and random
regression models are among those.  Random regression models are a form of
mixed model, in which each unit at Level 1 has an individualized regression
equation estimated.  The regression often includes a slope (individual rate
of change) and intercept (individually tailored y-intercept).

2) I have no idea what an animal model is, unless you mean one of those
little dinosaur toys :-).

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org on behalf of Amelie Lescroel
Sent: Mon 8/9/2010 7:27 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Clarification needed about the terminology used
whentalking about mixed models
 
Hello,

 

Could someone give me a clear definition of what a "random regression model"
is and what are the differences between a mixed model, a random regression
model and an animal model? I'm beginning to be lost among the multiple
designations. 

 

Thanks,

 

Amelie

 

 

 


	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-----------------------------------------------------------------------
Confidentiality Notice: This e-mail message, including a...{{dropped:7}}



From Paul.Thompson at sanfordhealth.org  Mon Aug  9 15:08:18 2010
From: Paul.Thompson at sanfordhealth.org (Thompson,Paul)
Date: Mon, 9 Aug 2010 08:08:18 -0500
Subject: [R-sig-ME] Clarification needed about the terminology used
	whentalking about mixed models
References: <25CEA3FCB11E4C49B56D41AD368545C2@Gentoo>
Message-ID: <4CF2646FA7AADD49A08570779F45B78D01BCF83A@SVMAIL6.domain.siouxvalley.local>


I can start.

1) Mixed models are models which include fixed and random effects.  Mixed models can be used to estimate and test multi-level models, and random regression models are among those.  Random regression models are a form of mixed model, in which each unit at Level 1 has an individualized regression equation estimated.  The regression often includes a slope (individual rate of change) and intercept (individually tailored y-intercept).

2) I have no idea what an animal model is, unless you mean one of those little dinosaur toys :-).

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org on behalf of Amelie Lescroel
Sent: Mon 8/9/2010 7:27 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Clarification needed about the terminology used whentalking about mixed models
 
Hello,

 

Could someone give me a clear definition of what a "random regression model"
is and what are the differences between a mixed model, a random regression
model and an animal model? I'm beginning to be lost among the multiple
designations. 

 

Thanks,

 

Amelie

 

 

 


	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-----------------------------------------------------------------------
Confidentiality Notice: This e-mail message, including any attachments,
is for the sole use of the intended recipient(s) and may contain
privileged and confidential information.  Any unauthorized review, use,
disclosure or distribution is prohibited.  If you are not the intended
recipient, please contact the sender by reply e-mail and destroy
all copies of the original message.




From paolo.innocenti at ebc.uu.se  Mon Aug  9 18:17:49 2010
From: paolo.innocenti at ebc.uu.se (Paolo Innocenti)
Date: Mon, 09 Aug 2010 18:17:49 +0200
Subject: [R-sig-ME] Clarification needed about the terminology
 used	whentalking about mixed models
In-Reply-To: <4CF2646FA7AADD49A08570779F45B78D01BCF83A@SVMAIL6.domain.siouxvalley.local>
References: <25CEA3FCB11E4C49B56D41AD368545C2@Gentoo>
	<4CF2646FA7AADD49A08570779F45B78D01BCF83A@SVMAIL6.domain.siouxvalley.local>
Message-ID: <4C602A2D.3030302@ebc.uu.se>

An animal model is a mixed model in which you use a "pedigree" to 
estimate your variance components, instead of defined levels within a 
factor. This pedigree provides information about the relationships among 
your observations. I have no idea about how it works, but Jarrod 
Hadfield provides this reference when talking about animal models in his 
MCMCglmm package (in which you can fit animal models):

C. R. Henderson. Simple method for computing inverse of a numerator 
relationship matrix used in prediction of breeding values. Biometrics, 
32(1):69?83,
1976.

Someone should correct me if what I said is wrong =).
Best,
paolo


Thompson,Paul wrote:
> I can start.
> 
> 1) Mixed models are models which include fixed and random effects.  Mixed models can be used to estimate and test multi-level models, and random regression models are among those.  Random regression models are a form of mixed model, in which each unit at Level 1 has an individualized regression equation estimated.  The regression often includes a slope (individual rate of change) and intercept (individually tailored y-intercept).
> 
> 2) I have no idea what an animal model is, unless you mean one of those little dinosaur toys :-).
> 
> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org on behalf of Amelie Lescroel
> Sent: Mon 8/9/2010 7:27 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Clarification needed about the terminology used whentalking about mixed models
>  
> Hello,
> 
>  
> 
> Could someone give me a clear definition of what a "random regression model"
> is and what are the differences between a mixed model, a random regression
> model and an animal model? I'm beginning to be lost among the multiple
> designations. 
> 
>  
> 
> Thanks,
> 
>  
> 
> Amelie
> 
>  
> 
>  
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> -----------------------------------------------------------------------
> Confidentiality Notice: This e-mail message, including any attachments,
> is for the sole use of the intended recipient(s) and may contain
> privileged and confidential information.  Any unauthorized review, use,
> disclosure or distribution is prohibited.  If you are not the intended
> recipient, please contact the sender by reply e-mail and destroy
> all copies of the original message.
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bobhuang09 at gmail.com  Mon Aug  9 19:06:27 2010
From: bobhuang09 at gmail.com (Bob Huang)
Date: Tue, 10 Aug 2010 01:06:27 +0800
Subject: [R-sig-ME] Specifying correlation structure of random effects in
	lme()
Message-ID: <AANLkTin8d4QV=bCSP6pss+1keof2n_5FAZb4uLKvMdi6@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100810/76119766/attachment.pl>

From another83 at me.com  Tue Aug 10 15:07:35 2010
From: another83 at me.com (John Haart)
Date: Tue, 10 Aug 2010 14:07:35 +0100
Subject: [R-sig-ME] Predict response variable Lmer
Message-ID: <C5FBAB41-8E4F-4EDB-8BC2-13F419DD598D@me.com>

Dear List,

I have arrived at my most parsimonious set of models (AIC & BIC) using lmer, however i am unsure how i go from this to predicting the response variable when i only have the fixed effects.

I.e 

Best model = 

H~ a+b+d+f 

Where H is a binary response variable

How do i predict if H will be true or false if i have a,b,c,d,e,f etc?

My aim is to take the fixed effects and predict if the response will be true or false.


Thanks very much

John



From j.hadfield at ed.ac.uk  Tue Aug 10 22:16:12 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 10 Aug 2010 21:16:12 +0100
Subject: [R-sig-ME] MCMCglmm 2.05 update
Message-ID: <20100810211612.e6fmuizdc8kok0o0@www.staffmail.ed.ac.uk>

Hi,

I've released a new version of MCMCglmm with the following:

BUG FIXES

I) Sparse design matrices with certain types of contrast were  
sometimes incorrect (e.g sum contrasts when only a two-level factor  
was fitted in the fixed term)

II)  Latent variables for censored Gaussian data were sometimes  
updated incorrectly

IMPORTANT CHANGES

I) with idh structures the prior for each diagonal element was  
equivalent to the marginal distribution of the variance under a  
standard inverse-Wishart distribution. This seemed to confuse many so  
now the prior specification for the ith variance is simply a  
univariate inverse-Wishart with V*=V[i,i] and nu*=nu

ADDED FUNCTIONALITY

I) summary function which includes the dreaded P-value (although I  
wouldn't really call it that)

II) hurdle Poisson ("hupoisson") zero-truncated Poisson ("ztpoisson")  
and zero-altered Poisson ("zapoisson" )distributions can now be fitted  
- these models have much better mixing properties than  zero-inflated  
Poisson models ("zipoisson") and they are discussed a little in the  
CourseNotes

III) predict function with confidence and prediction intervals on the  
data and link scale.  This is not yet implemented for all  
distributions and should be treated with care.

IV) response-feedback models  - developmental only

Thanks to everyone who sent bug reports and offered advice,  it is  
very much appreciated.

Cheers,

Jarrod



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From arrayprofile at yahoo.com  Wed Aug 11 00:11:59 2010
From: arrayprofile at yahoo.com (array chip)
Date: Tue, 10 Aug 2010 15:11:59 -0700 (PDT)
Subject: [R-sig-ME] longitudinal with 2 time points
Message-ID: <439946.26259.qm@web56301.mail.re3.yahoo.com>

Hi, I am wondering if it is still meaningful to run a mixed model if a 
longitudinal dataset has only 2 time points (baseline and week 4)? Would it be 
more appropriate to simply take the difference between the 2 time points and run 
ANOVA (ANCOVA) on the difference? what about still running mixed model on the 
difference of the 2 time points, but adding baseline measurement as a random 
factor?

Thanks for sharing your thoughts.

John



From arrayprofile at yahoo.com  Wed Aug 11 00:21:28 2010
From: arrayprofile at yahoo.com (array chip)
Date: Tue, 10 Aug 2010 15:21:28 -0700 (PDT)
Subject: [R-sig-ME] env() error message
In-Reply-To: <AANLkTinooaAS5GOvA2hTmKxZIWFfm19-vWAlzqR8hMyR@mail.gmail.com>
References: <704222.67637.qm@web56307.mail.re3.yahoo.com>
	<AANLkTinooaAS5GOvA2hTmKxZIWFfm19-vWAlzqR8hMyR@mail.gmail.com>
Message-ID: <284002.6925.qm@web56302.mail.re3.yahoo.com>

Dear Dr. Bates,

I am wondering if you are able to update the book chapters for lme4 package. The 
current version of the book has been a tremendous help to me learning mixed 
model in R except some of the functions used in the book doesn't work anymore.

Thank you for your excellent work.

John



----- Original Message ----
From: Douglas Bates <bates at stat.wisc.edu>
To: array chip <arrayprofile at yahoo.com>
Cc: r-sig-mixed-models at r-project.org
Sent: Tue, July 13, 2010 12:01:20 PM
Subject: Re: [R-sig-ME] env() error message

On Tue, Jul 13, 2010 at 1:50 PM, array chip <arrayprofile at yahoo.com> wrote:
> I am following examples of the lme4 draft book.
>
>> fm1 <- lmer(Yield ~ 1 + (1|Batch), Dyestuff)
>> env(fm1ML)$Lambda
> Error: could not find function "env"
>
> what went wrong here? Maybe env() function is from some special package that I
> didn't attach?

The env function was in an unreleased version of the lme4 package and
has now been retired.

I am preparing for a tutorial at the useR!2010 conference next week
and will have the versions of lme4 and the book chapters and the
slides coordinated by then.


>
> Thanks
>
> John
>
>> sessionInfo()
> R version 2.10.1 (2009-12-14)
> i386-pc-mingw32
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] nlme_3.1-96        lme4_0.999375-33   Matrix_0.999375-39 lattice_0.18-3
>
> loaded via a namespace (and not attached):
> [1] grid_2.10.1  tools_2.10.1
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From john.maindonald at anu.edu.au  Wed Aug 11 09:04:01 2010
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Wed, 11 Aug 2010 17:04:01 +1000
Subject: [R-sig-ME] longitudinal with 2 time points
In-Reply-To: <439946.26259.qm@web56301.mail.re3.yahoo.com>
References: <439946.26259.qm@web56301.mail.re3.yahoo.com>
Message-ID: <B80EFDF8-B705-4EBA-A80E-9A4354F08353@anu.edu.au>

All these are possibilities, except maybe making baseline measurement
a random factor.  This would make sense only if data divide into groups,
and you want the baseline effect to vary randomly from group to group.  
That may limit your ability to estimate parameters that are of interest.
In most circumstances that I am familiar with, it makes better sense to 
treat baseline effect as fixed.

John.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 11/08/2010, at 8:11 AM, array chip wrote:

> Hi, I am wondering if it is still meaningful to run a mixed model if a 
> longitudinal dataset has only 2 time points (baseline and week 4)? Would it be 
> more appropriate to simply take the difference between the 2 time points and run 
> ANOVA (ANCOVA) on the difference? what about still running mixed model on the 
> difference of the 2 time points, but adding baseline measurement as a random 
> factor?
> 
> Thanks for sharing your thoughts.
> 
> John
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From cewright at uci.edu  Wed Aug 11 14:34:21 2010
From: cewright at uci.edu (Charles E. (Ted) Wright)
Date: Wed, 11 Aug 2010 05:34:21 -0700 (Pacific Daylight Time)
Subject: [R-sig-ME] longitudinal with 2 time points
In-Reply-To: <B80EFDF8-B705-4EBA-A80E-9A4354F08353@anu.edu.au>
References: <439946.26259.qm@web56301.mail.re3.yahoo.com>
	<B80EFDF8-B705-4EBA-A80E-9A4354F08353@anu.edu.au>
Message-ID: <alpine.WNT.2.00.1008110532370.640@TED2>

Keep in mind that running an ANOVA on the difference is not the same thing 
as using the baseline data as a covariate in an ANOVA on the Week 4 data. 
Essentially the ANOVA on the differences is like the ANCOVA with the slope 
constrained to be 1.

Ted Wright

On Wed, 11 Aug 2010, John Maindonald wrote:

> All these are possibilities, except maybe making baseline measurement
> a random factor.  This would make sense only if data divide into groups,
> and you want the baseline effect to vary randomly from group to group.
> That may limit your ability to estimate parameters that are of interest.
> In most circumstances that I am familiar with, it makes better sense to
> treat baseline effect as fixed.
>
> John.
>
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> http://www.maths.anu.edu.au/~johnm
>
> On 11/08/2010, at 8:11 AM, array chip wrote:
>
>> Hi, I am wondering if it is still meaningful to run a mixed model if a
>> longitudinal dataset has only 2 time points (baseline and week 4)? Would it be
>> more appropriate to simply take the difference between the 2 time points and run
>> ANOVA (ANCOVA) on the difference? what about still running mixed model on the
>> difference of the 2 time points, but adding baseline measurement as a random
>> factor?
>>
>> Thanks for sharing your thoughts.
>>
>> John
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



From marc_schwartz at me.com  Wed Aug 11 15:20:13 2010
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 11 Aug 2010 08:20:13 -0500
Subject: [R-sig-ME] longitudinal with 2 time points
In-Reply-To: <alpine.WNT.2.00.1008110532370.640@TED2>
References: <439946.26259.qm@web56301.mail.re3.yahoo.com>
	<B80EFDF8-B705-4EBA-A80E-9A4354F08353@anu.edu.au>
	<alpine.WNT.2.00.1008110532370.640@TED2>
Message-ID: <8D383357-99BA-4447-A93B-0D8FC7AF7279@me.com>

Hi,

I'll throw in a reference that covers some of these issues:

Statistics Notes
Analysing controlled trials with baseline and follow up measurements
Vickers and Altman
BMJ. 2001 November 10; 323(7321): 1123?1124.
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1121605/


The basic model specification would of course be:

  lm(4Wks ~ Baseline + Group)

You will also want to test for an interaction between the baseline score and your grouping factor, in case the observed group (eg. treatment) effect is dependent upon the value of the baseline measurement. In this case, unlike in the above paper, you of course end up with crossing fitted regression lines, rather than parallel lines.

HTH,

Marc Schwartz


On Aug 11, 2010, at 7:34 AM, Charles E. (Ted) Wright wrote:

> Keep in mind that running an ANOVA on the difference is not the same thing as using the baseline data as a covariate in an ANOVA on the Week 4 data. Essentially the ANOVA on the differences is like the ANCOVA with the slope constrained to be 1.
> 
> Ted Wright
> 
> On Wed, 11 Aug 2010, John Maindonald wrote:
> 
>> All these are possibilities, except maybe making baseline measurement
>> a random factor.  This would make sense only if data divide into groups,
>> and you want the baseline effect to vary randomly from group to group.
>> That may limit your ability to estimate parameters that are of interest.
>> In most circumstances that I am familiar with, it makes better sense to
>> treat baseline effect as fixed.
>> 
>> John.
>> 
>> On 11/08/2010, at 8:11 AM, array chip wrote:
>> 
>>> Hi, I am wondering if it is still meaningful to run a mixed model if a
>>> longitudinal dataset has only 2 time points (baseline and week 4)? Would it be
>>> more appropriate to simply take the difference between the 2 time points and run
>>> ANOVA (ANCOVA) on the difference? what about still running mixed model on the
>>> difference of the 2 time points, but adding baseline measurement as a random
>>> factor?
>>> 
>>> Thanks for sharing your thoughts.
>>> 
>>> John



From bbolker at gmail.com  Wed Aug 11 16:31:56 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 11 Aug 2010 10:31:56 -0400
Subject: [R-sig-ME] [R-sig-eco] LRT tests in lmer
In-Reply-To: <849679F9-600B-4642-825F-2187EF4FA04A@gmail.com>
References: <C3EE1ECE-FD66-4EA4-9471-B55FCFB5400D@qmul.ac.uk>
	<39F64CBD-4157-4BD1-ABB2-8DC4A9FED8D4@gmail.com>
	<4C62AFC9.1040409@gmail.com>
	<849679F9-600B-4642-825F-2187EF4FA04A@gmail.com>
Message-ID: <4C62B45C.7050301@gmail.com>

On 10-08-11 10:21 AM, Chris Mcowen wrote:
> Dear Ben/Rob.
>
>    
>> As far as I can tell, the standard advice is simply to look at the predictions of the model, compare them with the data, and try to spot any systematic patterns in the residuals.
>>      
>
> I have plotted the residuals of my model - https://files.me.com/chrismcowen/v586vx
>
> I have been made aware that  that lmer uses the random effects in its  prediction ( Jarrord Hadfield). And this is reflected in the residual plot with the the long lines of equal residuals all belonging  to the same family - i.e 200 - 600 is the orchid family and 650-100 is the grass family.
>
> So is there a work around with a glmm?
>
>
>
> Thanks
>
> Chris
>
>    

    If you want to do population-level predictions from a GLMM (i.e. 
setting all random effects to zero), the basic recipe is to (1) 
construct a model (design) matrix for the desired sets of predictor 
variables (if you want to the predict the observed data rather than some 
other set, you can just extract the model matrix from the fitted 
object); (2) multiply it by the vector of fixed effect coefficients; (3) 
transform it back to the scale of the observations with the inverse link 
function.  There's an example on p. 6 of 
http://glmm.wdfiles.com/local--files/examples/Owls.pdf ...



From cm744 at st-andrews.ac.uk  Wed Aug 11 16:47:03 2010
From: cm744 at st-andrews.ac.uk (Chris Mcowen)
Date: Wed, 11 Aug 2010 15:47:03 +0100
Subject: [R-sig-ME] Fwd:  [R-sig-eco] LRT tests in lmer
References: <06C77127-37C1-4FB3-8ADC-A3AFCE4F26DF@gmail.com>
Message-ID: <1F754FDE-BBA2-497A-AE6A-704BBE20D748@st-andrews.ac.uk>


Thats great thanks,

But will this work where you have a binary response variable or will the residuals clump around 1 and 0?

Chris
On 11 Aug 2010, at 15:31, Ben Bolker wrote:

On 10-08-11 10:21 AM, Chris Mcowen wrote:
> Dear Ben/Rob.
> 
> 
>> As far as I can tell, the standard advice is simply to look at the predictions of the model, compare them with the data, and try to spot any systematic patterns in the residuals.
>> 
> 
> I have plotted the residuals of my model - https://files.me.com/chrismcowen/v586vx
> 
> I have been made aware that  that lmer uses the random effects in its  prediction ( Jarrord Hadfield). And this is reflected in the residual plot with the the long lines of equal residuals all belonging  to the same family - i.e 200 - 600 is the orchid family and 650-100 is the grass family.
> 
> So is there a work around with a glmm?
> 
> 
> 
> Thanks
> 
> Chris
> 
> 

 If you want to do population-level predictions from a GLMM (i.e. setting all random effects to zero), the basic recipe is to (1) construct a model (design) matrix for the desired sets of predictor variables (if you want to the predict the observed data rather than some other set, you can just extract the model matrix from the fitted object); (2) multiply it by the vector of fixed effect coefficients; (3) transform it back to the scale of the observations with the inverse link function.  There's an example on p. 6 of http://glmm.wdfiles.com/local--files/examples/Owls.pdf ...

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From j.hadfield at ed.ac.uk  Wed Aug 11 16:59:07 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 11 Aug 2010 15:59:07 +0100
Subject: [R-sig-ME] [R-sig-eco] LRT tests in lmer
In-Reply-To: <4C62B45C.7050301@gmail.com>
References: <C3EE1ECE-FD66-4EA4-9471-B55FCFB5400D@qmul.ac.uk>
	<39F64CBD-4157-4BD1-ABB2-8DC4A9FED8D4@gmail.com>
	<4C62AFC9.1040409@gmail.com>
	<849679F9-600B-4642-825F-2187EF4FA04A@gmail.com>
	<4C62B45C.7050301@gmail.com>
Message-ID: <F09164A2-69DA-45CF-AC6D-0814C8E657EE@ed.ac.uk>

Hi,

In general I don't think transforming the fixed effect predictions by  
the inverse link  function works if you want to get the predicted  
expectation.  In this case you have to take into account the magnitude  
of the variance components.  The new predict function in MCMCglmm will  
do this for a MCMCglmm fit. By default the predictions will be on the  
data scale and all random effects marginalised, but you can also get  
predictions that include the random effects if you save their  
posterior distribution (i.e pr=TRUE)

Cheers,

Jarrod




On 11 Aug 2010, at 15:31, Ben Bolker wrote:

> On 10-08-11 10:21 AM, Chris Mcowen wrote:
>> Dear Ben/Rob.
>>
>>
>>> As far as I can tell, the standard advice is simply to look at the  
>>> predictions of the model, compare them with the data, and try to  
>>> spot any systematic patterns in the residuals.
>>>
>>
>> I have plotted the residuals of my model - https://files.me.com/chrismcowen/v586vx
>>
>> I have been made aware that  that lmer uses the random effects in  
>> its  prediction ( Jarrord Hadfield). And this is reflected in the  
>> residual plot with the the long lines of equal residuals all  
>> belonging  to the same family - i.e 200 - 600 is the orchid family  
>> and 650-100 is the grass family.
>>
>> So is there a work around with a glmm?
>>
>>
>>
>> Thanks
>>
>> Chris
>>
>>
>
>   If you want to do population-level predictions from a GLMM (i.e.  
> setting all random effects to zero), the basic recipe is to (1)  
> construct a model (design) matrix for the desired sets of predictor  
> variables (if you want to the predict the observed data rather than  
> some other set, you can just extract the model matrix from the  
> fitted object); (2) multiply it by the vector of fixed effect  
> coefficients; (3) transform it back to the scale of the observations  
> with the inverse link function.  There's an example on p. 6 of http://glmm.wdfiles.com/local--files/examples/Owls.pdf 
>  ...
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From c.hardner at uq.edu.au  Wed Aug 11 14:27:53 2010
From: c.hardner at uq.edu.au (Craig Hardner)
Date: Wed, 11 Aug 2010 22:27:53 +1000
Subject: [R-sig-ME] D relationship matrix
Message-ID: <506E385513570F4FA5E3F84C96486802034E1911@UQEXMB3.soe.uq.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100811/8861a168/attachment.pl>

From chrismcowen at gmail.com  Wed Aug 11 16:41:59 2010
From: chrismcowen at gmail.com (Chris Mcowen)
Date: Wed, 11 Aug 2010 15:41:59 +0100
Subject: [R-sig-ME] [R-sig-eco] LRT tests in lmer
In-Reply-To: <4C62B45C.7050301@gmail.com>
References: <C3EE1ECE-FD66-4EA4-9471-B55FCFB5400D@qmul.ac.uk>
	<39F64CBD-4157-4BD1-ABB2-8DC4A9FED8D4@gmail.com>
	<4C62AFC9.1040409@gmail.com>
	<849679F9-600B-4642-825F-2187EF4FA04A@gmail.com>
	<4C62B45C.7050301@gmail.com>
Message-ID: <06C77127-37C1-4FB3-8ADC-A3AFCE4F26DF@gmail.com>

Thats great thanks,

But will this work where you have a binary response variable or will the residuals clump around 1 and 0?

Chris
On 11 Aug 2010, at 15:31, Ben Bolker wrote:

On 10-08-11 10:21 AM, Chris Mcowen wrote:
> Dear Ben/Rob.
> 
>   
>> As far as I can tell, the standard advice is simply to look at the predictions of the model, compare them with the data, and try to spot any systematic patterns in the residuals.
>>     
> 
> I have plotted the residuals of my model - https://files.me.com/chrismcowen/v586vx
> 
> I have been made aware that  that lmer uses the random effects in its  prediction ( Jarrord Hadfield). And this is reflected in the residual plot with the the long lines of equal residuals all belonging  to the same family - i.e 200 - 600 is the orchid family and 650-100 is the grass family.
> 
> So is there a work around with a glmm?
> 
> 
> 
> Thanks
> 
> Chris
> 
>   

  If you want to do population-level predictions from a GLMM (i.e. setting all random effects to zero), the basic recipe is to (1) construct a model (design) matrix for the desired sets of predictor variables (if you want to the predict the observed data rather than some other set, you can just extract the model matrix from the fitted object); (2) multiply it by the vector of fixed effect coefficients; (3) transform it back to the scale of the observations with the inverse link function.  There's an example on p. 6 of http://glmm.wdfiles.com/local--files/examples/Owls.pdf ...

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From j.hadfield at ed.ac.uk  Wed Aug 11 17:37:02 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 11 Aug 2010 16:37:02 +0100
Subject: [R-sig-ME] [R-sig-eco] LRT tests in lmer
In-Reply-To: <06C77127-37C1-4FB3-8ADC-A3AFCE4F26DF@gmail.com>
References: <C3EE1ECE-FD66-4EA4-9471-B55FCFB5400D@qmul.ac.uk>
	<39F64CBD-4157-4BD1-ABB2-8DC4A9FED8D4@gmail.com>
	<4C62AFC9.1040409@gmail.com>
	<849679F9-600B-4642-825F-2187EF4FA04A@gmail.com>
	<4C62B45C.7050301@gmail.com>
	<06C77127-37C1-4FB3-8ADC-A3AFCE4F26DF@gmail.com>
Message-ID: <B35928C5-C703-49FE-989A-3DB98377352C@ed.ac.uk>

Hi Chris,

It is hard to say as it will depend on the fixed effects. In addition  
its not clear whether such a situation is diagnostic of a problem.   
Imagine you just have an intercept which is estimated to be exactly  
zero. The residuals on the data scale will be either 0.5 or -0.5, but  
this does not imply the model is wrong.

Cheers,

Jarrod

On 11 Aug 2010, at 15:41, Chris Mcowen wrote:

> Thats great thanks,
>
> But will this work where you have a binary response variable or will  
> the residuals clump around 1 and 0?
>
> Chris
> On 11 Aug 2010, at 15:31, Ben Bolker wrote:
>
> On 10-08-11 10:21 AM, Chris Mcowen wrote:
>> Dear Ben/Rob.
>>
>>
>>> As far as I can tell, the standard advice is simply to look at the  
>>> predictions of the model, compare them with the data, and try to  
>>> spot any systematic patterns in the residuals.
>>>
>>
>> I have plotted the residuals of my model - https://files.me.com/chrismcowen/v586vx
>>
>> I have been made aware that  that lmer uses the random effects in  
>> its  prediction ( Jarrord Hadfield). And this is reflected in the  
>> residual plot with the the long lines of equal residuals all  
>> belonging  to the same family - i.e 200 - 600 is the orchid family  
>> and 650-100 is the grass family.
>>
>> So is there a work around with a glmm?
>>
>>
>>
>> Thanks
>>
>> Chris
>>
>>
>
>  If you want to do population-level predictions from a GLMM (i.e.  
> setting all random effects to zero), the basic recipe is to (1)  
> construct a model (design) matrix for the desired sets of predictor  
> variables (if you want to the predict the observed data rather than  
> some other set, you can just extract the model matrix from the  
> fitted object); (2) multiply it by the vector of fixed effect  
> coefficients; (3) transform it back to the scale of the observations  
> with the inverse link function.  There's an example on p. 6 of http://glmm.wdfiles.com/local--files/examples/Owls.pdf 
>  ...
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From j.hadfield at ed.ac.uk  Wed Aug 11 17:37:55 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 11 Aug 2010 16:37:55 +0100
Subject: [R-sig-ME] D relationship matrix
In-Reply-To: <506E385513570F4FA5E3F84C96486802034E1911@UQEXMB3.soe.uq.edu.au>
References: <506E385513570F4FA5E3F84C96486802034E1911@UQEXMB3.soe.uq.edu.au>
Message-ID: <6FF569AD-56D0-40D6-AE07-BF3BBD4D33A1@ed.ac.uk>

Hi,

Is D for dominance?

Cheers,

Jarrod


On 11 Aug 2010, at 13:27, Craig Hardner wrote:

> Hi Folks
>
>
> just wonderinf if any one has some code to write the D realtionship  
> matrix (or inverse) for an outbreed population with no inbreeding  
> that I could use?
>
> Thanks for your help
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From cm744 at st-andrews.ac.uk  Wed Aug 11 18:08:07 2010
From: cm744 at st-andrews.ac.uk (Chris Mcowen)
Date: Wed, 11 Aug 2010 17:08:07 +0100
Subject: [R-sig-ME] [R-sig-eco] LRT tests in lmer
In-Reply-To: <B35928C5-C703-49FE-989A-3DB98377352C@ed.ac.uk>
References: <C3EE1ECE-FD66-4EA4-9471-B55FCFB5400D@qmul.ac.uk>
	<39F64CBD-4157-4BD1-ABB2-8DC4A9FED8D4@gmail.com>
	<4C62AFC9.1040409@gmail.com>
	<849679F9-600B-4642-825F-2187EF4FA04A@gmail.com>
	<4C62B45C.7050301@gmail.com>
	<06C77127-37C1-4FB3-8ADC-A3AFCE4F26DF@gmail.com>
	<B35928C5-C703-49FE-989A-3DB98377352C@ed.ac.uk>
Message-ID: <EF9C9CB3-7E8C-4932-932A-51D237FD1312@st-andrews.ac.uk>

Hi Jarrord,

I have tried using MCMCglmm, however the posterior distributions of the majority of the fixed factors straddle 0, which i have read is a problem, likely with the priors.

HPDintervals - https://files.me.com/chrismcowen/wqq1lu

prior=list(R=list(V=1, fix=1), G=list(G1=list(V=1, nu=0), G2=list(V=1, nu=0)))

So i am unsure how to interpret the results, as to ascertain the importance of each factor.

Unfortunately i don't know enough about baysian statistics or R to alter my model so the interpretations become clearer.

An example

                              			lower      		upper
(Intercept)             			-3.510792767 	2.40740650
STOStorage organ        	-0.299408836 	0.23073133
BSUnisexual flower      	-0.131660436 	0.54887912
BSUnisexual plant       	 0.003566637 	0.81742862
PDBiotic                			 0.054625970 	0.72436838
PDMammalia              		-2.139720264 	1.39753939



On 11 Aug 2010, at 16:37, Jarrod Hadfield wrote:

Hi Chris,

It is hard to say as it will depend on the fixed effects. In addition its not clear whether such a situation is diagnostic of a problem.  Imagine you just have an intercept which is estimated to be exactly zero. The residuals on the data scale will be either 0.5 or -0.5, but this does not imply the model is wrong.

Cheers,

Jarrod

On 11 Aug 2010, at 15:41, Chris Mcowen wrote:

> Thats great thanks,
> 
> But will this work where you have a binary response variable or will the residuals clump around 1 and 0?
> 
> Chris
> On 11 Aug 2010, at 15:31, Ben Bolker wrote:
> 
> On 10-08-11 10:21 AM, Chris Mcowen wrote:
>> Dear Ben/Rob.
>> 
>> 
>>> As far as I can tell, the standard advice is simply to look at the predictions of the model, compare them with the data, and try to spot any systematic patterns in the residuals.
>>> 
>> 
>> I have plotted the residuals of my model - https://files.me.com/chrismcowen/v586vx
>> 
>> I have been made aware that  that lmer uses the random effects in its  prediction ( Jarrord Hadfield). And this is reflected in the residual plot with the the long lines of equal residuals all belonging  to the same family - i.e 200 - 600 is the orchid family and 650-100 is the grass family.
>> 
>> So is there a work around with a glmm?
>> 
>> 
>> 
>> Thanks
>> 
>> Chris
>> 
>> 
> 
> If you want to do population-level predictions from a GLMM (i.e. setting all random effects to zero), the basic recipe is to (1) construct a model (design) matrix for the desired sets of predictor variables (if you want to the predict the observed data rather than some other set, you can just extract the model matrix from the fitted object); (2) multiply it by the vector of fixed effect coefficients; (3) transform it back to the scale of the observations with the inverse link function.  There's an example on p. 6 of http://glmm.wdfiles.com/local--files/examples/Owls.pdf ...
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From j.hadfield at ed.ac.uk  Wed Aug 11 18:15:24 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 11 Aug 2010 17:15:24 +0100
Subject: [R-sig-ME] [R-sig-eco] LRT tests in lmer
In-Reply-To: <EF9C9CB3-7E8C-4932-932A-51D237FD1312@st-andrews.ac.uk>
References: <C3EE1ECE-FD66-4EA4-9471-B55FCFB5400D@qmul.ac.uk>
	<39F64CBD-4157-4BD1-ABB2-8DC4A9FED8D4@gmail.com>
	<4C62AFC9.1040409@gmail.com>
	<849679F9-600B-4642-825F-2187EF4FA04A@gmail.com>
	<4C62B45C.7050301@gmail.com>
	<06C77127-37C1-4FB3-8ADC-A3AFCE4F26DF@gmail.com>
	<B35928C5-C703-49FE-989A-3DB98377352C@ed.ac.uk>
	<EF9C9CB3-7E8C-4932-932A-51D237FD1312@st-andrews.ac.uk>
Message-ID: <DADD3609-6ECC-4271-9A23-D785B45C3D89@ed.ac.uk>

Hi,

Could you give summary(model) with the new version (2.05) - it will be  
easier to see what is going on?

Jarrod
On 11 Aug 2010, at 17:08, Chris Mcowen wrote:

> Hi Jarrord,
>
> I have tried using MCMCglmm, however the posterior distributions of  
> the majority of the fixed factors straddle 0, which i have read is a  
> problem, likely with the priors.
>
> HPDintervals - https://files.me.com/chrismcowen/wqq1lu
>
> prior=list(R=list(V=1, fix=1), G=list(G1=list(V=1, nu=0),  
> G2=list(V=1, nu=0)))
>
> So i am unsure how to interpret the results, as to ascertain the  
> importance of each factor.
>
> Unfortunately i don't know enough about baysian statistics or R to  
> alter my model so the interpretations become clearer.
>
> An example
>
>                              			lower      		upper
> (Intercept)             			-3.510792767 	2.40740650
> STOStorage organ        	-0.299408836 	0.23073133
> BSUnisexual flower      	-0.131660436 	0.54887912
> BSUnisexual plant       	 0.003566637 	0.81742862
> PDBiotic                			 0.054625970 	0.72436838
> PDMammalia              		-2.139720264 	1.39753939
>
>
>
> On 11 Aug 2010, at 16:37, Jarrod Hadfield wrote:
>
> Hi Chris,
>
> It is hard to say as it will depend on the fixed effects. In  
> addition its not clear whether such a situation is diagnostic of a  
> problem.  Imagine you just have an intercept which is estimated to  
> be exactly zero. The residuals on the data scale will be either 0.5  
> or -0.5, but this does not imply the model is wrong.
>
> Cheers,
>
> Jarrod
>
> On 11 Aug 2010, at 15:41, Chris Mcowen wrote:
>
>> Thats great thanks,
>>
>> But will this work where you have a binary response variable or  
>> will the residuals clump around 1 and 0?
>>
>> Chris
>> On 11 Aug 2010, at 15:31, Ben Bolker wrote:
>>
>> On 10-08-11 10:21 AM, Chris Mcowen wrote:
>>> Dear Ben/Rob.
>>>
>>>
>>>> As far as I can tell, the standard advice is simply to look at  
>>>> the predictions of the model, compare them with the data, and try  
>>>> to spot any systematic patterns in the residuals.
>>>>
>>>
>>> I have plotted the residuals of my model - https://files.me.com/chrismcowen/v586vx
>>>
>>> I have been made aware that  that lmer uses the random effects in  
>>> its  prediction ( Jarrord Hadfield). And this is reflected in the  
>>> residual plot with the the long lines of equal residuals all  
>>> belonging  to the same family - i.e 200 - 600 is the orchid family  
>>> and 650-100 is the grass family.
>>>
>>> So is there a work around with a glmm?
>>>
>>>
>>>
>>> Thanks
>>>
>>> Chris
>>>
>>>
>>
>> If you want to do population-level predictions from a GLMM (i.e.  
>> setting all random effects to zero), the basic recipe is to (1)  
>> construct a model (design) matrix for the desired sets of predictor  
>> variables (if you want to the predict the observed data rather than  
>> some other set, you can just extract the model matrix from the  
>> fitted object); (2) multiply it by the vector of fixed effect  
>> coefficients; (3) transform it back to the scale of the  
>> observations with the inverse link function.  There's an example on  
>> p. 6 of http://glmm.wdfiles.com/local--files/examples/Owls.pdf ...
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From cm744 at st-andrews.ac.uk  Wed Aug 11 18:20:08 2010
From: cm744 at st-andrews.ac.uk (Chris Mcowen)
Date: Wed, 11 Aug 2010 17:20:08 +0100
Subject: [R-sig-ME] [R-sig-eco] LRT tests in lmer
In-Reply-To: <DADD3609-6ECC-4271-9A23-D785B45C3D89@ed.ac.uk>
References: <C3EE1ECE-FD66-4EA4-9471-B55FCFB5400D@qmul.ac.uk>
	<39F64CBD-4157-4BD1-ABB2-8DC4A9FED8D4@gmail.com>
	<4C62AFC9.1040409@gmail.com>
	<849679F9-600B-4642-825F-2187EF4FA04A@gmail.com>
	<4C62B45C.7050301@gmail.com>
	<06C77127-37C1-4FB3-8ADC-A3AFCE4F26DF@gmail.com>
	<B35928C5-C703-49FE-989A-3DB98377352C@ed.ac.uk>
	<EF9C9CB3-7E8C-4932-932A-51D237FD1312@st-andrews.ac.uk>
	<DADD3609-6ECC-4271-9A23-D785B45C3D89@ed.ac.uk>
Message-ID: <5B256B07-4DCC-4A2F-BF98-A212B9D12831@st-andrews.ac.uk>

Sorry about the formatting, 

i was not going to use P values for model selection, rather the DIC value

 Iterations = 12991
 Thinning interval  = 3001
 Sample size  = 1000 

 DIC: 3171.501 

 G-structure:  ~order

      post.mean  l-95% CI u-95% CI eff.samp
order      7720 4.023e-13  0.09208     1000

               ~fam:fam

        post.mean  l-95% CI u-95% CI eff.samp
fam:fam   4092456 2.376e-12  0.02938     1000

 R-structure:  ~units

      post.mean l-95% CI u-95% CI eff.samp
units         1        1        1        0

 Location effects: IUCN ~ STO + BS + PD + FR + END + WO + RG + SEA + ALT + BIO + SE + FS 

                         			post.mean   l-95% CI   u-95% 		CI eff.samp pMCMC   
(Intercept)              		39.065870  -3.510793   2.407406   1000.0 		0.776   
STOStorage organ        	 -0.004916  -0.299409   0.230731    757.2		 0.946   
BSUnisexual flower       	 0.211852  -0.131660   0.548879    708.0 		0.212   
BSUnisexual plant         	0.370895   0.003567   0.817429    770.3 		0.070 . 
PDBiotic                  		0.381261   0.054626   0.724368    774.4 		0.040 * 
PDMammalia               		26.364377  -2.139720   1.397539   1000		.0 0.724   
FRNon_fleshy_fruit       	-0.208198  -0.536699   0.083012    964.2 		0.202   
ENDNon_endospermous   0.503829   0.200868   0.822120    591.7 		0.004 **
WOWoody                  		-0.203632  -0.565069   0.139240    857.5 		0.272   
RGTwo+                   		-0.052508  -0.250675   0.163811    831.8 		0.588   
SEAHapaxanthic           	-1.344993  -4.504625   1.848373    890.4 		0.406   
SEAHapaxanthic          	  0.223060  -1.590483   2.012970    785.9 		0.800   
SEAPerennial             		-0.097971  -0.460607   0.304681    849.9 		0.580   
SEAPleonanthic       	       -0.069756  -0.813837   0.704066    969.4 		0.872   
ALTHigh                 		 -0.129331  -0.483238   0.200436   1000.0 		0.472   
ALTLow                  		 -0.171467  -0.514753   0.121200    842.9 		0.316   
ALTMid                   		 0.068307  -0.227978   0.379701    814.9 		0.660   
BIOBoreal                 		1.785916  -1.222387   4.769563    860.2 		0.254   
BIOMediterranean-type     2.105530  -0.888236   4.786029    817.9 		0.156   
BIOSubantarctic           	2.214561  -0.888921   5.239470    841.3 		0.190   
BIOSubarctic            		  2.441894  -0.667793   5.677992    849.5 		0.142   
BIOSubtropical/Tropical     2.336425  -0.660675   4.899198    928.3 		0.124   
BIOTemperate             		 2.315834  -0.761101   4.826330    809.2 		0.132   
SEFew-Several           		146.220538  -0.620787   3.933475   1000.0 		0.172   
SENumerous              	  	0.206148  -0.117869   0.572987    734.9 		0.236   
SESeveral                 		0.626675  -0.236956   1.456895    881.7 		0.134   
SESingle                		  0.399690   0.030041   0.779923    709.8 		0.032 * 
FSZygomorphic            	 0.032334  -0.215194   0.265597    355.7 		0.814   
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 

 Cutpoints: 
                     post.mean l-95% CI u-95% CI eff.samp
cutpoint.traitIUCN.1    0.6593   0.5211    0.793    48.46
cutpoint.traitIUCN.2    2.4694   2.2952    2.663    41.37
cutpoint.traitIUCN.3    3.6258   3.4220    3.827    38.02
cutpoint.traitIUCN.4    4.1156   3.9166    4.341    52.46
On 11 Aug 2010, at 17:15, Jarrod Hadfield wrote:

Hi,

Could you give summary(model) with the new version (2.05) - it will be easier to see what is going on?

Jarrod
On 11 Aug 2010, at 17:08, Chris Mcowen wrote:

> Hi Jarrord,
> 
> I have tried using MCMCglmm, however the posterior distributions of the majority of the fixed factors straddle 0, which i have read is a problem, likely with the priors.
> 
> HPDintervals - https://files.me.com/chrismcowen/wqq1lu
> 
> prior=list(R=list(V=1, fix=1), G=list(G1=list(V=1, nu=0), G2=list(V=1, nu=0)))
> 
> So i am unsure how to interpret the results, as to ascertain the importance of each factor.
> 
> Unfortunately i don't know enough about baysian statistics or R to alter my model so the interpretations become clearer.
> 
> An example
> 
>                             			lower      		upper
> (Intercept)             			-3.510792767 	2.40740650
> STOStorage organ        	-0.299408836 	0.23073133
> BSUnisexual flower      	-0.131660436 	0.54887912
> BSUnisexual plant       	 0.003566637 	0.81742862
> PDBiotic                			 0.054625970 	0.72436838
> PDMammalia              		-2.139720264 	1.39753939
> 
> 
> 
> On 11 Aug 2010, at 16:37, Jarrod Hadfield wrote:
> 
> Hi Chris,
> 
> It is hard to say as it will depend on the fixed effects. In addition its not clear whether such a situation is diagnostic of a problem.  Imagine you just have an intercept which is estimated to be exactly zero. The residuals on the data scale will be either 0.5 or -0.5, but this does not imply the model is wrong.
> 
> Cheers,
> 
> Jarrod
> 
> On 11 Aug 2010, at 15:41, Chris Mcowen wrote:
> 
>> Thats great thanks,
>> 
>> But will this work where you have a binary response variable or will the residuals clump around 1 and 0?
>> 
>> Chris
>> On 11 Aug 2010, at 15:31, Ben Bolker wrote:
>> 
>> On 10-08-11 10:21 AM, Chris Mcowen wrote:
>>> Dear Ben/Rob.
>>> 
>>> 
>>>> As far as I can tell, the standard advice is simply to look at the predictions of the model, compare them with the data, and try to spot any systematic patterns in the residuals.
>>>> 
>>> 
>>> I have plotted the residuals of my model - https://files.me.com/chrismcowen/v586vx
>>> 
>>> I have been made aware that  that lmer uses the random effects in its  prediction ( Jarrord Hadfield). And this is reflected in the residual plot with the the long lines of equal residuals all belonging  to the same family - i.e 200 - 600 is the orchid family and 650-100 is the grass family.
>>> 
>>> So is there a work around with a glmm?
>>> 
>>> 
>>> 
>>> Thanks
>>> 
>>> Chris
>>> 
>>> 
>> 
>> If you want to do population-level predictions from a GLMM (i.e. setting all random effects to zero), the basic recipe is to (1) construct a model (design) matrix for the desired sets of predictor variables (if you want to the predict the observed data rather than some other set, you can just extract the model matrix from the fitted object); (2) multiply it by the vector of fixed effect coefficients; (3) transform it back to the scale of the observations with the inverse link function.  There's an example on p. 6 of http://glmm.wdfiles.com/local--files/examples/Owls.pdf ...
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> 
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From j.hadfield at ed.ac.uk  Wed Aug 11 18:34:29 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 11 Aug 2010 17:34:29 +0100
Subject: [R-sig-ME] [R-sig-eco] LRT tests in lmer
In-Reply-To: <5B256B07-4DCC-4A2F-BF98-A212B9D12831@st-andrews.ac.uk>
References: <C3EE1ECE-FD66-4EA4-9471-B55FCFB5400D@qmul.ac.uk>
	<39F64CBD-4157-4BD1-ABB2-8DC4A9FED8D4@gmail.com>
	<4C62AFC9.1040409@gmail.com>
	<849679F9-600B-4642-825F-2187EF4FA04A@gmail.com>
	<4C62B45C.7050301@gmail.com>
	<06C77127-37C1-4FB3-8ADC-A3AFCE4F26DF@gmail.com>
	<B35928C5-C703-49FE-989A-3DB98377352C@ed.ac.uk>
	<EF9C9CB3-7E8C-4932-932A-51D237FD1312@st-andrews.ac.uk>
	<DADD3609-6ECC-4271-9A23-D785B45C3D89@ed.ac.uk>
	<5B256B07-4DCC-4A2F-BF98-A212B9D12831@st-andrews.ac.uk>
Message-ID: <77C85FB4-2A18-49CD-AE31-E39668E9E133@ed.ac.uk>

Hi Chris,


The model syntax looks reasonable but there seems to be some large  
posterior means (outside of the 95% credible range). I bet plot(model 
$VCV) looks pretty horrible too. You need to  consider using proper  
priors in this instance because the chain is getting stuck at zero for  
long periods of time and generating numerical problems. I tend to use  
parameter expanded priors more and more as they improve mixing and  
seem to be only weakly informative. For example: G1=list(V=1, nu=1,  
alpha.mu=0, alpha.V=1000) ....  There is also the possibility that you  
have complete separation as you have a lot of fixed effects and many  
levels in the ordinal response - are all 5's for example associated  
with a single fixed factor, or something like this?

Jarrod



On 11 Aug 2010, at 17:20, Chris Mcowen wrote:

> Sorry about the formatting,
>
> i was not going to use P values for model selection, rather the DIC  
> value
>
> Iterations = 12991
> Thinning interval  = 3001
> Sample size  = 1000
>
> DIC: 3171.501
>
> G-structure:  ~order
>
>      post.mean  l-95% CI u-95% CI eff.samp
> order      7720 4.023e-13  0.09208     1000
>
>               ~fam:fam
>
>        post.mean  l-95% CI u-95% CI eff.samp
> fam:fam   4092456 2.376e-12  0.02938     1000
>
> R-structure:  ~units
>
>      post.mean l-95% CI u-95% CI eff.samp
> units         1        1        1        0
>
> Location effects: IUCN ~ STO + BS + PD + FR + END + WO + RG + SEA +  
> ALT + BIO + SE + FS
>
>                         			post.mean   l-95% CI   u-95% 		CI  
> eff.samp pMCMC
> (Intercept)              		39.065870  -3.510793   2.407406   1000.0  
> 		0.776
> STOStorage organ        	 -0.004916  -0.299409   0.230731    757.2		  
> 0.946
> BSUnisexual flower       	 0.211852  -0.131660   0.548879    708.0 		 
> 0.212
> BSUnisexual plant         	0.370895   0.003567   0.817429    770.3 		 
> 0.070 .
> PDBiotic                  		0.381261   0.054626   0.724368    774.4  
> 		0.040 *
> PDMammalia               		26.364377  -2.139720   1.397539   1000		. 
> 0 0.724
> FRNon_fleshy_fruit       	-0.208198  -0.536699   0.083012    964.2 		 
> 0.202
> ENDNon_endospermous   0.503829   0.200868   0.822120    591.7 		 
> 0.004 **
> WOWoody                  		-0.203632  -0.565069   0.139240    857.5  
> 		0.272
> RGTwo+                   		-0.052508  -0.250675   0.163811    831.8  
> 		0.588
> SEAHapaxanthic           	-1.344993  -4.504625   1.848373    890.4 		 
> 0.406
> SEAHapaxanthic          	  0.223060  -1.590483   2.012970    785.9 		 
> 0.800
> SEAPerennial             		-0.097971  -0.460607   0.304681    849.9  
> 		0.580
> SEAPleonanthic       	       -0.069756  -0.813837   0.704066     
> 969.4 		0.872
> ALTHigh                 		 -0.129331  -0.483238   0.200436   1000.0  
> 		0.472
> ALTLow                  		 -0.171467  -0.514753   0.121200    842.9  
> 		0.316
> ALTMid                   		 0.068307  -0.227978   0.379701    814.9  
> 		0.660
> BIOBoreal                 		1.785916  -1.222387   4.769563    860.2  
> 		0.254
> BIOMediterranean-type     2.105530  -0.888236   4.786029    817.9 		 
> 0.156
> BIOSubantarctic           	2.214561  -0.888921   5.239470    841.3 		 
> 0.190
> BIOSubarctic            		  2.441894  -0.667793   5.677992    849.5  
> 		0.142
> BIOSubtropical/Tropical     2.336425  -0.660675   4.899198    928.3  
> 		0.124
> BIOTemperate             		 2.315834  -0.761101   4.826330    809.2  
> 		0.132
> SEFew-Several           		146.220538  -0.620787   3.933475   1000.0  
> 		0.172
> SENumerous              	  	0.206148  -0.117869   0.572987    734.9  
> 		0.236
> SESeveral                 		0.626675  -0.236956   1.456895    881.7  
> 		0.134
> SESingle                		  0.399690   0.030041   0.779923    709.8  
> 		0.032 *
> FSZygomorphic            	 0.032334  -0.215194   0.265597    355.7 		 
> 0.814
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Cutpoints:
>                     post.mean l-95% CI u-95% CI eff.samp
> cutpoint.traitIUCN.1    0.6593   0.5211    0.793    48.46
> cutpoint.traitIUCN.2    2.4694   2.2952    2.663    41.37
> cutpoint.traitIUCN.3    3.6258   3.4220    3.827    38.02
> cutpoint.traitIUCN.4    4.1156   3.9166    4.341    52.46
> On 11 Aug 2010, at 17:15, Jarrod Hadfield wrote:
>
> Hi,
>
> Could you give summary(model) with the new version (2.05) - it will  
> be easier to see what is going on?
>
> Jarrod
> On 11 Aug 2010, at 17:08, Chris Mcowen wrote:
>
>> Hi Jarrord,
>>
>> I have tried using MCMCglmm, however the posterior distributions of  
>> the majority of the fixed factors straddle 0, which i have read is  
>> a problem, likely with the priors.
>>
>> HPDintervals - https://files.me.com/chrismcowen/wqq1lu
>>
>> prior=list(R=list(V=1, fix=1), G=list(G1=list(V=1, nu=0),  
>> G2=list(V=1, nu=0)))
>>
>> So i am unsure how to interpret the results, as to ascertain the  
>> importance of each factor.
>>
>> Unfortunately i don't know enough about baysian statistics or R to  
>> alter my model so the interpretations become clearer.
>>
>> An example
>>
>>                            			lower      		upper
>> (Intercept)             			-3.510792767 	2.40740650
>> STOStorage organ        	-0.299408836 	0.23073133
>> BSUnisexual flower      	-0.131660436 	0.54887912
>> BSUnisexual plant       	 0.003566637 	0.81742862
>> PDBiotic                			 0.054625970 	0.72436838
>> PDMammalia              		-2.139720264 	1.39753939
>>
>>
>>
>> On 11 Aug 2010, at 16:37, Jarrod Hadfield wrote:
>>
>> Hi Chris,
>>
>> It is hard to say as it will depend on the fixed effects. In  
>> addition its not clear whether such a situation is diagnostic of a  
>> problem.  Imagine you just have an intercept which is estimated to  
>> be exactly zero. The residuals on the data scale will be either 0.5  
>> or -0.5, but this does not imply the model is wrong.
>>
>> Cheers,
>>
>> Jarrod
>>
>> On 11 Aug 2010, at 15:41, Chris Mcowen wrote:
>>
>>> Thats great thanks,
>>>
>>> But will this work where you have a binary response variable or  
>>> will the residuals clump around 1 and 0?
>>>
>>> Chris
>>> On 11 Aug 2010, at 15:31, Ben Bolker wrote:
>>>
>>> On 10-08-11 10:21 AM, Chris Mcowen wrote:
>>>> Dear Ben/Rob.
>>>>
>>>>
>>>>> As far as I can tell, the standard advice is simply to look at  
>>>>> the predictions of the model, compare them with the data, and  
>>>>> try to spot any systematic patterns in the residuals.
>>>>>
>>>>
>>>> I have plotted the residuals of my model - https://files.me.com/chrismcowen/v586vx
>>>>
>>>> I have been made aware that  that lmer uses the random effects in  
>>>> its  prediction ( Jarrord Hadfield). And this is reflected in the  
>>>> residual plot with the the long lines of equal residuals all  
>>>> belonging  to the same family - i.e 200 - 600 is the orchid  
>>>> family and 650-100 is the grass family.
>>>>
>>>> So is there a work around with a glmm?
>>>>
>>>>
>>>>
>>>> Thanks
>>>>
>>>> Chris
>>>>
>>>>
>>>
>>> If you want to do population-level predictions from a GLMM (i.e.  
>>> setting all random effects to zero), the basic recipe is to (1)  
>>> construct a model (design) matrix for the desired sets of  
>>> predictor variables (if you want to the predict the observed data  
>>> rather than some other set, you can just extract the model matrix  
>>> from the fitted object); (2) multiply it by the vector of fixed  
>>> effect coefficients; (3) transform it back to the scale of the  
>>> observations with the inverse link function.  There's an example  
>>> on p. 6 of http://glmm.wdfiles.com/local--files/examples/ 
>>> Owls.pdf ...
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>> -- 
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
>
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From cm744 at st-andrews.ac.uk  Wed Aug 11 18:44:57 2010
From: cm744 at st-andrews.ac.uk (Chris Mcowen)
Date: Wed, 11 Aug 2010 17:44:57 +0100
Subject: [R-sig-ME] [R-sig-eco] LRT tests in lmer
In-Reply-To: <77C85FB4-2A18-49CD-AE31-E39668E9E133@ed.ac.uk>
References: <C3EE1ECE-FD66-4EA4-9471-B55FCFB5400D@qmul.ac.uk>
	<39F64CBD-4157-4BD1-ABB2-8DC4A9FED8D4@gmail.com>
	<4C62AFC9.1040409@gmail.com>
	<849679F9-600B-4642-825F-2187EF4FA04A@gmail.com>
	<4C62B45C.7050301@gmail.com>
	<06C77127-37C1-4FB3-8ADC-A3AFCE4F26DF@gmail.com>
	<B35928C5-C703-49FE-989A-3DB98377352C@ed.ac.uk>
	<EF9C9CB3-7E8C-4932-932A-51D237FD1312@st-andrews.ac.uk>
	<DADD3609-6ECC-4271-9A23-D785B45C3D89@ed.ac.uk>
	<5B256B07-4DCC-4A2F-BF98-A212B9D12831@st-andrews.ac.uk>
	<77C85FB4-2A18-49CD-AE31-E39668E9E133@ed.ac.uk>
Message-ID: <80A2B683-F9A8-4EC0-B142-02AA0C76CFC2@st-andrews.ac.uk>

Hi 

> are all 5's for example associated with a single fixed factor, or something like this?

The ordinal response are categorical - different levels of threat, however they can be successfully used as a continuous response ( Purvis, Mace etc) they are not associated with any of the fixed factors, i am trying to use the fixed factors (life history traits) to predict the ordinal response. 

I shall have a play with the priors as 
> G1=list(V=1, nu=1, alpha.mu=0, alpha.V=1000)

Has improved things, but not greatly

Thanks

Chris

Intercept)              -0.23325 -2.89744  2.83429    793.1 0.884  
STOStorage organ         -0.04486 -0.28088  0.23706   1306.4 0.722  
BSUnisexual flower        0.21329 -0.11396  0.52257    861.1 0.206  
BSUnisexual plant         0.33547 -0.04818  0.75086    806.5 0.122  
PDBiotic                  0.28292 -0.13199  0.63020    599.1 0.184  
PDMammalia               -0.46017 -2.15330  1.44028    862.8 0.640  
FRNon_fleshy_fruit       -0.22784 -0.54680  0.10850    764.5 0.192  
ENDNon_endospermous       0.44173  0.10830  0.74418    747.8 0.016 *
WOWoody                  -0.22039 -0.59506  0.11227    631.0 0.252  
RGTwo+                   -0.04816 -0.24944  0.15221    816.4 0.666  
SEAHapaxanthic           -1.53904 -4.55702  1.67797    688.6 0.330  
SEAHapaxanthic            0.18037 -1.72087  2.27258    796.5 0.800  
SEAPerennial             -0.07601 -0.44810  0.33258    926.0 0.712  
SEAPleonanthic           -0.14699 -1.14695  0.81452    723.9 0.748  
ALTHigh                  -0.13191 -0.46780  0.22911    725.0 0.452  
ALTLow                   -0.17699 -0.51173  0.10969    772.8 0.292  
ALTMid                    0.06855 -0.21312  0.41342    882.1 0.684  
BIOBoreal                 1.74800 -1.18782  4.72759    782.0 0.242  
BIOMediterranean-type     2.08074 -0.62533  5.05527    780.1 0.140  
BIOSubantarctic           2.17686 -1.13669  5.24883    806.7 0.180  
BIOSubarctic              2.39551 -0.91077  5.41454    839.1 0.138  
BIOSubtropical/Tropical   2.31132 -0.36795  5.24304    791.5 0.110  
BIOTemperate              2.29529 -0.41744  5.18185    795.5 0.104  
SEFew-Several             1.86331 -0.57544  4.01647    732.1 0.106  
SENumerous                0.20823 -0.14937  0.57547    851.4 0.226  
SESeveral                 0.66868 -0.13298  1.45685    894.6 0.102  
SESingle                  0.42408  0.07265  0.80295    872.5 0.022 *
FSZygomorphic             0.01505 -0.22554  0.27481    760.5 0.908

On 11 Aug 2010, at 17:34, Jarrod Hadfield wrote:

Hi Chris,


The model syntax looks reasonable but there seems to be some large posterior means (outside of the 95% credible range). I bet plot(model$VCV) looks pretty horrible too. You need to  consider using proper priors in this instance because the chain is getting stuck at zero for long periods of time and generating numerical problems. I tend to use parameter expanded priors more and more as they improve mixing and seem to be only weakly informative. For example: G1=list(V=1, nu=1, alpha.mu=0, alpha.V=1000) ....  There is also the possibility that you have complete separation as you have a lot of fixed effects and many levels in the ordinal response - are all 5's for example associated with a single fixed factor, or something like this?

Jarrod



On 11 Aug 2010, at 17:20, Chris Mcowen wrote:

> Sorry about the formatting,
> 
> i was not going to use P values for model selection, rather the DIC value
> 
> Iterations = 12991
> Thinning interval  = 3001
> Sample size  = 1000
> 
> DIC: 3171.501
> 
> G-structure:  ~order
> 
>    post.mean  l-95% CI u-95% CI eff.samp
> order      7720 4.023e-13  0.09208     1000
> 
>             ~fam:fam
> 
>      post.mean  l-95% CI u-95% CI eff.samp
> fam:fam   4092456 2.376e-12  0.02938     1000
> 
> R-structure:  ~units
> 
>    post.mean l-95% CI u-95% CI eff.samp
> units         1        1        1        0
> 
> Location effects: IUCN ~ STO + BS + PD + FR + END + WO + RG + SEA + ALT + BIO + SE + FS
> 
>                       			post.mean   l-95% CI   u-95% 		CI eff.samp pMCMC
> (Intercept)              		39.065870  -3.510793   2.407406   1000.0 		0.776
> STOStorage organ        	 -0.004916  -0.299409   0.230731    757.2		 0.946
> BSUnisexual flower       	 0.211852  -0.131660   0.548879    708.0 		0.212
> BSUnisexual plant         	0.370895   0.003567   0.817429    770.3 		0.070 .
> PDBiotic                  		0.381261   0.054626   0.724368    774.4 		0.040 *
> PDMammalia               		26.364377  -2.139720   1.397539   1000		.0 0.724
> FRNon_fleshy_fruit       	-0.208198  -0.536699   0.083012    964.2 		0.202
> ENDNon_endospermous   0.503829   0.200868   0.822120    591.7 		0.004 **
> WOWoody                  		-0.203632  -0.565069   0.139240    857.5 		0.272
> RGTwo+                   		-0.052508  -0.250675   0.163811    831.8 		0.588
> SEAHapaxanthic           	-1.344993  -4.504625   1.848373    890.4 		0.406
> SEAHapaxanthic          	  0.223060  -1.590483   2.012970    785.9 		0.800
> SEAPerennial             		-0.097971  -0.460607   0.304681    849.9 		0.580
> SEAPleonanthic       	       -0.069756  -0.813837   0.704066    969.4 		0.872
> ALTHigh                 		 -0.129331  -0.483238   0.200436   1000.0 		0.472
> ALTLow                  		 -0.171467  -0.514753   0.121200    842.9 		0.316
> ALTMid                   		 0.068307  -0.227978   0.379701    814.9 		0.660
> BIOBoreal                 		1.785916  -1.222387   4.769563    860.2 		0.254
> BIOMediterranean-type     2.105530  -0.888236   4.786029    817.9 		0.156
> BIOSubantarctic           	2.214561  -0.888921   5.239470    841.3 		0.190
> BIOSubarctic            		  2.441894  -0.667793   5.677992    849.5 		0.142
> BIOSubtropical/Tropical     2.336425  -0.660675   4.899198    928.3 		0.124
> BIOTemperate             		 2.315834  -0.761101   4.826330    809.2 		0.132
> SEFew-Several           		146.220538  -0.620787   3.933475   1000.0 		0.172
> SENumerous              	  	0.206148  -0.117869   0.572987    734.9 		0.236
> SESeveral                 		0.626675  -0.236956   1.456895    881.7 		0.134
> SESingle                		  0.399690   0.030041   0.779923    709.8 		0.032 *
> FSZygomorphic            	 0.032334  -0.215194   0.265597    355.7 		0.814
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Cutpoints:
>                   post.mean l-95% CI u-95% CI eff.samp
> cutpoint.traitIUCN.1    0.6593   0.5211    0.793    48.46
> cutpoint.traitIUCN.2    2.4694   2.2952    2.663    41.37
> cutpoint.traitIUCN.3    3.6258   3.4220    3.827    38.02
> cutpoint.traitIUCN.4    4.1156   3.9166    4.341    52.46
> On 11 Aug 2010, at 17:15, Jarrod Hadfield wrote:
> 
> Hi,
> 
> Could you give summary(model) with the new version (2.05) - it will be easier to see what is going on?
> 
> Jarrod
> On 11 Aug 2010, at 17:08, Chris Mcowen wrote:
> 
>> Hi Jarrord,
>> 
>> I have tried using MCMCglmm, however the posterior distributions of the majority of the fixed factors straddle 0, which i have read is a problem, likely with the priors.
>> 
>> HPDintervals - https://files.me.com/chrismcowen/wqq1lu
>> 
>> prior=list(R=list(V=1, fix=1), G=list(G1=list(V=1, nu=0), G2=list(V=1, nu=0)))
>> 
>> So i am unsure how to interpret the results, as to ascertain the importance of each factor.
>> 
>> Unfortunately i don't know enough about baysian statistics or R to alter my model so the interpretations become clearer.
>> 
>> An example
>> 
>>                          			lower      		upper
>> (Intercept)             			-3.510792767 	2.40740650
>> STOStorage organ        	-0.299408836 	0.23073133
>> BSUnisexual flower      	-0.131660436 	0.54887912
>> BSUnisexual plant       	 0.003566637 	0.81742862
>> PDBiotic                			 0.054625970 	0.72436838
>> PDMammalia              		-2.139720264 	1.39753939
>> 
>> 
>> 
>> On 11 Aug 2010, at 16:37, Jarrod Hadfield wrote:
>> 
>> Hi Chris,
>> 
>> It is hard to say as it will depend on the fixed effects. In addition its not clear whether such a situation is diagnostic of a problem.  Imagine you just have an intercept which is estimated to be exactly zero. The residuals on the data scale will be either 0.5 or -0.5, but this does not imply the model is wrong.
>> 
>> Cheers,
>> 
>> Jarrod
>> 
>> On 11 Aug 2010, at 15:41, Chris Mcowen wrote:
>> 
>>> Thats great thanks,
>>> 
>>> But will this work where you have a binary response variable or will the residuals clump around 1 and 0?
>>> 
>>> Chris
>>> On 11 Aug 2010, at 15:31, Ben Bolker wrote:
>>> 
>>> On 10-08-11 10:21 AM, Chris Mcowen wrote:
>>>> Dear Ben/Rob.
>>>> 
>>>> 
>>>>> As far as I can tell, the standard advice is simply to look at the predictions of the model, compare them with the data, and try to spot any systematic patterns in the residuals.
>>>>> 
>>>> 
>>>> I have plotted the residuals of my model - https://files.me.com/chrismcowen/v586vx
>>>> 
>>>> I have been made aware that  that lmer uses the random effects in its  prediction ( Jarrord Hadfield). And this is reflected in the residual plot with the the long lines of equal residuals all belonging  to the same family - i.e 200 - 600 is the orchid family and 650-100 is the grass family.
>>>> 
>>>> So is there a work around with a glmm?
>>>> 
>>>> 
>>>> 
>>>> Thanks
>>>> 
>>>> Chris
>>>> 
>>>> 
>>> 
>>> If you want to do population-level predictions from a GLMM (i.e. setting all random effects to zero), the basic recipe is to (1) construct a model (design) matrix for the desired sets of predictor variables (if you want to the predict the observed data rather than some other set, you can just extract the model matrix from the fitted object); (2) multiply it by the vector of fixed effect coefficients; (3) transform it back to the scale of the observations with the inverse link function.  There's an example on p. 6 of http://glmm.wdfiles.com/local--files/examples/Owls.pdf ...
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
>> 
>> 
>> -- 
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
>> 
> 
> 
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From kevin.thorpe at utoronto.ca  Wed Aug 11 20:13:22 2010
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Wed, 11 Aug 2010 14:13:22 -0400
Subject: [R-sig-ME] Why am I getting a Variance of 0 for my random effect
Message-ID: <4C62E842.5040403@utoronto.ca>

Hello.

I'm getting a variance of 0 on a random effect and I don't know why.
I suspect I've not set the model up correctly.  My transcript is below
with my own comments sprinkled in for time to time.

A little bit about the data (which I will provide off-list if 
requested).  We have nurses managing an aspect of patient care
according to different algorithms.  Interest focuses on of the
algorithms result in different outcomes.  I have restricted this
to only nurses who did each algorithm twice (in case my problem
was being caused by some nurses doing only one algorithm, possibly
only one time).

I figured that since I have multiple observations per nurse, I
should treat nurse as a random effect, but maybe I confused myself
again.


R version 2.11.1 Patched (2010-07-21 r52598)
Copyright (C) 2010 The R Foundation for Statistical Computing
ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

   Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

 > library(lattice)
 > library(lme4)

 > str(data1)
'data.frame':   72 obs. of  3 variables:
  $ RN        : int  1 1 2 3 7 7 9 9 15 15 ...
  $ Assignment: Factor w/ 2 levels "E","N": 1 1 1 1 1 1 1 1 1 1 ...
  $ AUChr     : num  12.26 7.23 9.26 4.04 10.31 ...
 > tmp1 <- 
with(data1,aggregate(AUChr,list(RN=RN,Assigment=Assignment),mean))
 > names(tmp1)[3] <- "Mean"
 >
 > tmp2 <- 
with(data1,aggregate(AUChr,list(RN=RN,Assignment=Assignment),var))
 > names(tmp2)[3] <- "Variance"
 >
 > meanvar <- merge(tmp1,tmp2)

The point of this is to show that the means are not all the same,
nor are the variances.

 > meanvar
    RN Assignment   Mean  Variance
1   1          E  9.745  12.65045
2   1          N  7.185   1.36125
3  15          E 10.605  15.07005
4  15          N 10.385   4.41045
5  16          E  8.175   0.00845
6  16          N  8.420   1.03680
7   2          E  7.300   7.68320
8   2          N  6.950   1.00820
9  21          E  9.670   9.41780
10 21          N 10.535   2.44205
11 22          E  7.720   2.04020
12 22          N  7.930   1.21680
13 24          E  9.555  10.35125
14 24          N  9.330   0.38720
15 25          E  8.240   0.92480
16 25          N  9.485   0.00125
17 27          E  8.635   0.08405
18 27          N  7.745   3.72645
19 28          E  9.635   8.61125
20 28          N  8.315  10.35125
21  3          E  6.005   7.72245
22  3          N 11.435  55.44045
23 31          E  9.590   9.94580
24 31          N 10.570  16.70420
25 35          E  9.055   0.32805
26 35          N  9.925  14.41845
27 36          E  9.040   2.08080
28 36          N  7.395   1.14005
29  5          E  8.430   3.38000
30  5          N 17.385 139.94645
31  6          E  6.930   0.24500
32  6          N  8.330   1.72980
33  7          E 10.650   0.23120
34  7          N  7.375   0.09245
35  9          E  8.885   7.56605
36  9          N  8.405   0.73205

Model with "Assignment" (algorithm).

 > lmer(AUChr~Assignment+(1|RN),data=data1,REML=FALSE)
Linear mixed model fit by maximum likelihood
Formula: AUChr ~ Assignment + (1 | RN)
    Data: data1
    AIC   BIC logLik deviance REMLdev
  365.7 374.8 -178.8    357.7   356.9
Random effects:
  Groups   Name        Variance Std.Dev.
  RN       (Intercept) 0.0000   0.0000
  Residual             8.4152   2.9009
Number of obs: 72, groups: RN, 18

Fixed effects:
             Estimate Std. Error t value
(Intercept)   8.7703     0.4835   18.14
AssignmentN   0.5131     0.6837    0.75

Correlation of Fixed Effects:
             (Intr)
AssignmentN -0.707


Model without the algorithm variable.

 > lmer(AUChr~(1|RN),data=data1,REML=FALSE)
Linear mixed model fit by maximum likelihood
Formula: AUChr ~ (1 | RN)
    Data: data1
    AIC   BIC logLik deviance REMLdev
  364.3 371.1 -179.1    358.3   358.5
Random effects:
  Groups   Name        Variance Std.Dev.
  RN       (Intercept) 0.000    0.0000
  Residual             8.481    2.9122
Number of obs: 72, groups: RN, 18

Fixed effects:
             Estimate Std. Error t value
(Intercept)   9.0268     0.3432    26.3
 >
 > sessionInfo()
R version 2.11.1 Patched (2010-07-21 r52598)
Platform: i686-pc-linux-gnu (32-bit)

locale:
  [1] LC_CTYPE=en_US       LC_NUMERIC=C         LC_TIME=en_US
  [4] LC_COLLATE=C         LC_MONETARY=C        LC_MESSAGES=en_US
  [7] LC_PAPER=en_US       LC_NAME=C            LC_ADDRESS=C
[10] LC_TELEPHONE=C       LC_MEASUREMENT=en_US LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_0.999375-34   Matrix_0.999375-42 lattice_0.18-8

loaded via a namespace (and not attached):
[1] grid_2.11.1   nlme_3.1-96   stats4_2.11.1
 >
 > proc.time()
    user  system elapsed
   3.488   0.056   3.536

-- 
Kevin E. Thorpe
Biostatistician/Trialist, Knowledge Translation Program
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016



From danielezrajohnson at gmail.com  Wed Aug 11 20:16:24 2010
From: danielezrajohnson at gmail.com (Daniel Ezra Johnson)
Date: Wed, 11 Aug 2010 14:16:24 -0400
Subject: [R-sig-ME] Why am I getting a Variance of 0 for my random effect
In-Reply-To: <4C62E842.5040403@utoronto.ca>
References: <4C62E842.5040403@utoronto.ca>
Message-ID: <AANLkTikqfrYEO_Xvyr99BaNgfdKt9urw_5Nvds=dQRSF@mail.gmail.com>

Try data1$RN <- as.factor(data1$RN).

On Wed, Aug 11, 2010 at 2:13 PM, Kevin E. Thorpe
<kevin.thorpe at utoronto.ca> wrote:
> Hello.
>
> I'm getting a variance of 0 on a random effect and I don't know why.
> I suspect I've not set the model up correctly. ?My transcript is below
> with my own comments sprinkled in for time to time.
>
> A little bit about the data (which I will provide off-list if requested).
> ?We have nurses managing an aspect of patient care
> according to different algorithms. ?Interest focuses on of the
> algorithms result in different outcomes. ?I have restricted this
> to only nurses who did each algorithm twice (in case my problem
> was being caused by some nurses doing only one algorithm, possibly
> only one time).
>
> I figured that since I have multiple observations per nurse, I
> should treat nurse as a random effect, but maybe I confused myself
> again.
>
>
> R version 2.11.1 Patched (2010-07-21 r52598)
> Copyright (C) 2010 The R Foundation for Statistical Computing
> ISBN 3-900051-07-0
>
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
>
> ?Natural language support but running in an English locale
>
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
>
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
>
>> library(lattice)
>> library(lme4)
>
>> str(data1)
> 'data.frame': ? 72 obs. of ?3 variables:
> ?$ RN ? ? ? ?: int ?1 1 2 3 7 7 9 9 15 15 ...
> ?$ Assignment: Factor w/ 2 levels "E","N": 1 1 1 1 1 1 1 1 1 1 ...
> ?$ AUChr ? ? : num ?12.26 7.23 9.26 4.04 10.31 ...
>> tmp1 <- with(data1,aggregate(AUChr,list(RN=RN,Assigment=Assignment),mean))
>> names(tmp1)[3] <- "Mean"
>>
>> tmp2 <- with(data1,aggregate(AUChr,list(RN=RN,Assignment=Assignment),var))
>> names(tmp2)[3] <- "Variance"
>>
>> meanvar <- merge(tmp1,tmp2)
>
> The point of this is to show that the means are not all the same,
> nor are the variances.
>
>> meanvar
> ? RN Assignment ? Mean ?Variance
> 1 ? 1 ? ? ? ? ?E ?9.745 ?12.65045
> 2 ? 1 ? ? ? ? ?N ?7.185 ? 1.36125
> 3 ?15 ? ? ? ? ?E 10.605 ?15.07005
> 4 ?15 ? ? ? ? ?N 10.385 ? 4.41045
> 5 ?16 ? ? ? ? ?E ?8.175 ? 0.00845
> 6 ?16 ? ? ? ? ?N ?8.420 ? 1.03680
> 7 ? 2 ? ? ? ? ?E ?7.300 ? 7.68320
> 8 ? 2 ? ? ? ? ?N ?6.950 ? 1.00820
> 9 ?21 ? ? ? ? ?E ?9.670 ? 9.41780
> 10 21 ? ? ? ? ?N 10.535 ? 2.44205
> 11 22 ? ? ? ? ?E ?7.720 ? 2.04020
> 12 22 ? ? ? ? ?N ?7.930 ? 1.21680
> 13 24 ? ? ? ? ?E ?9.555 ?10.35125
> 14 24 ? ? ? ? ?N ?9.330 ? 0.38720
> 15 25 ? ? ? ? ?E ?8.240 ? 0.92480
> 16 25 ? ? ? ? ?N ?9.485 ? 0.00125
> 17 27 ? ? ? ? ?E ?8.635 ? 0.08405
> 18 27 ? ? ? ? ?N ?7.745 ? 3.72645
> 19 28 ? ? ? ? ?E ?9.635 ? 8.61125
> 20 28 ? ? ? ? ?N ?8.315 ?10.35125
> 21 ?3 ? ? ? ? ?E ?6.005 ? 7.72245
> 22 ?3 ? ? ? ? ?N 11.435 ?55.44045
> 23 31 ? ? ? ? ?E ?9.590 ? 9.94580
> 24 31 ? ? ? ? ?N 10.570 ?16.70420
> 25 35 ? ? ? ? ?E ?9.055 ? 0.32805
> 26 35 ? ? ? ? ?N ?9.925 ?14.41845
> 27 36 ? ? ? ? ?E ?9.040 ? 2.08080
> 28 36 ? ? ? ? ?N ?7.395 ? 1.14005
> 29 ?5 ? ? ? ? ?E ?8.430 ? 3.38000
> 30 ?5 ? ? ? ? ?N 17.385 139.94645
> 31 ?6 ? ? ? ? ?E ?6.930 ? 0.24500
> 32 ?6 ? ? ? ? ?N ?8.330 ? 1.72980
> 33 ?7 ? ? ? ? ?E 10.650 ? 0.23120
> 34 ?7 ? ? ? ? ?N ?7.375 ? 0.09245
> 35 ?9 ? ? ? ? ?E ?8.885 ? 7.56605
> 36 ?9 ? ? ? ? ?N ?8.405 ? 0.73205
>
> Model with "Assignment" (algorithm).
>
>> lmer(AUChr~Assignment+(1|RN),data=data1,REML=FALSE)
> Linear mixed model fit by maximum likelihood
> Formula: AUChr ~ Assignment + (1 | RN)
> ? Data: data1
> ? AIC ? BIC logLik deviance REMLdev
> ?365.7 374.8 -178.8 ? ?357.7 ? 356.9
> Random effects:
> ?Groups ? Name ? ? ? ?Variance Std.Dev.
> ?RN ? ? ? (Intercept) 0.0000 ? 0.0000
> ?Residual ? ? ? ? ? ? 8.4152 ? 2.9009
> Number of obs: 72, groups: RN, 18
>
> Fixed effects:
> ? ? ? ? ? ?Estimate Std. Error t value
> (Intercept) ? 8.7703 ? ? 0.4835 ? 18.14
> AssignmentN ? 0.5131 ? ? 0.6837 ? ?0.75
>
> Correlation of Fixed Effects:
> ? ? ? ? ? ?(Intr)
> AssignmentN -0.707
>
>
> Model without the algorithm variable.
>
>> lmer(AUChr~(1|RN),data=data1,REML=FALSE)
> Linear mixed model fit by maximum likelihood
> Formula: AUChr ~ (1 | RN)
> ? Data: data1
> ? AIC ? BIC logLik deviance REMLdev
> ?364.3 371.1 -179.1 ? ?358.3 ? 358.5
> Random effects:
> ?Groups ? Name ? ? ? ?Variance Std.Dev.
> ?RN ? ? ? (Intercept) 0.000 ? ?0.0000
> ?Residual ? ? ? ? ? ? 8.481 ? ?2.9122
> Number of obs: 72, groups: RN, 18
>
> Fixed effects:
> ? ? ? ? ? ?Estimate Std. Error t value
> (Intercept) ? 9.0268 ? ? 0.3432 ? ?26.3
>>
>> sessionInfo()
> R version 2.11.1 Patched (2010-07-21 r52598)
> Platform: i686-pc-linux-gnu (32-bit)
>
> locale:
> ?[1] LC_CTYPE=en_US ? ? ? LC_NUMERIC=C ? ? ? ? LC_TIME=en_US
> ?[4] LC_COLLATE=C ? ? ? ? LC_MONETARY=C ? ? ? ?LC_MESSAGES=en_US
> ?[7] LC_PAPER=en_US ? ? ? LC_NAME=C ? ? ? ? ? ?LC_ADDRESS=C
> [10] LC_TELEPHONE=C ? ? ? LC_MEASUREMENT=en_US LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>
> other attached packages:
> [1] lme4_0.999375-34 ? Matrix_0.999375-42 lattice_0.18-8
>
> loaded via a namespace (and not attached):
> [1] grid_2.11.1 ? nlme_3.1-96 ? stats4_2.11.1
>>
>> proc.time()
> ? user ?system elapsed
> ?3.488 ? 0.056 ? 3.536
>
> --
> Kevin E. Thorpe
> Biostatistician/Trialist, Knowledge Translation Program
> Assistant Professor, Dalla Lana School of Public Health
> University of Toronto
> email: kevin.thorpe at utoronto.ca ?Tel: 416.864.5776 ?Fax: 416.864.3016
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From kevin.thorpe at utoronto.ca  Wed Aug 11 20:24:29 2010
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Wed, 11 Aug 2010 14:24:29 -0400
Subject: [R-sig-ME] Why am I getting a Variance of 0 for my random effect
In-Reply-To: <AANLkTikqfrYEO_Xvyr99BaNgfdKt9urw_5Nvds=dQRSF@mail.gmail.com>
References: <4C62E842.5040403@utoronto.ca>
	<AANLkTikqfrYEO_Xvyr99BaNgfdKt9urw_5Nvds=dQRSF@mail.gmail.com>
Message-ID: <4C62EADD.2000601@utoronto.ca>

On 08/11/2010 02:16 PM, Daniel Ezra Johnson wrote:
> Try data1$RN<- as.factor(data1$RN).

Thanks, but that has no effect.  That is I get the same results.

>
> On Wed, Aug 11, 2010 at 2:13 PM, Kevin E. Thorpe
> <kevin.thorpe at utoronto.ca>  wrote:
>> Hello.
>>
>> I'm getting a variance of 0 on a random effect and I don't know why.
>> I suspect I've not set the model up correctly.  My transcript is below
>> with my own comments sprinkled in for time to time.
>>
>> A little bit about the data (which I will provide off-list if requested).
>>   We have nurses managing an aspect of patient care
>> according to different algorithms.  Interest focuses on of the
>> algorithms result in different outcomes.  I have restricted this
>> to only nurses who did each algorithm twice (in case my problem
>> was being caused by some nurses doing only one algorithm, possibly
>> only one time).
>>
>> I figured that since I have multiple observations per nurse, I
>> should treat nurse as a random effect, but maybe I confused myself
>> again.
>>
>>
>> R version 2.11.1 Patched (2010-07-21 r52598)
>> Copyright (C) 2010 The R Foundation for Statistical Computing
>> ISBN 3-900051-07-0
>>
>> R is free software and comes with ABSOLUTELY NO WARRANTY.
>> You are welcome to redistribute it under certain conditions.
>> Type 'license()' or 'licence()' for distribution details.
>>
>>   Natural language support but running in an English locale
>>
>> R is a collaborative project with many contributors.
>> Type 'contributors()' for more information and
>> 'citation()' on how to cite R or R packages in publications.
>>
>> Type 'demo()' for some demos, 'help()' for on-line help, or
>> 'help.start()' for an HTML browser interface to help.
>> Type 'q()' to quit R.
>>
>>> library(lattice)
>>> library(lme4)
>>
>>> str(data1)
>> 'data.frame':   72 obs. of  3 variables:
>>   $ RN        : int  1 1 2 3 7 7 9 9 15 15 ...
>>   $ Assignment: Factor w/ 2 levels "E","N": 1 1 1 1 1 1 1 1 1 1 ...
>>   $ AUChr     : num  12.26 7.23 9.26 4.04 10.31 ...
>>> tmp1<- with(data1,aggregate(AUChr,list(RN=RN,Assigment=Assignment),mean))
>>> names(tmp1)[3]<- "Mean"
>>>
>>> tmp2<- with(data1,aggregate(AUChr,list(RN=RN,Assignment=Assignment),var))
>>> names(tmp2)[3]<- "Variance"
>>>
>>> meanvar<- merge(tmp1,tmp2)
>>
>> The point of this is to show that the means are not all the same,
>> nor are the variances.
>>
>>> meanvar
>>    RN Assignment   Mean  Variance
>> 1   1          E  9.745  12.65045
>> 2   1          N  7.185   1.36125
>> 3  15          E 10.605  15.07005
>> 4  15          N 10.385   4.41045
>> 5  16          E  8.175   0.00845
>> 6  16          N  8.420   1.03680
>> 7   2          E  7.300   7.68320
>> 8   2          N  6.950   1.00820
>> 9  21          E  9.670   9.41780
>> 10 21          N 10.535   2.44205
>> 11 22          E  7.720   2.04020
>> 12 22          N  7.930   1.21680
>> 13 24          E  9.555  10.35125
>> 14 24          N  9.330   0.38720
>> 15 25          E  8.240   0.92480
>> 16 25          N  9.485   0.00125
>> 17 27          E  8.635   0.08405
>> 18 27          N  7.745   3.72645
>> 19 28          E  9.635   8.61125
>> 20 28          N  8.315  10.35125
>> 21  3          E  6.005   7.72245
>> 22  3          N 11.435  55.44045
>> 23 31          E  9.590   9.94580
>> 24 31          N 10.570  16.70420
>> 25 35          E  9.055   0.32805
>> 26 35          N  9.925  14.41845
>> 27 36          E  9.040   2.08080
>> 28 36          N  7.395   1.14005
>> 29  5          E  8.430   3.38000
>> 30  5          N 17.385 139.94645
>> 31  6          E  6.930   0.24500
>> 32  6          N  8.330   1.72980
>> 33  7          E 10.650   0.23120
>> 34  7          N  7.375   0.09245
>> 35  9          E  8.885   7.56605
>> 36  9          N  8.405   0.73205
>>
>> Model with "Assignment" (algorithm).
>>
>>> lmer(AUChr~Assignment+(1|RN),data=data1,REML=FALSE)
>> Linear mixed model fit by maximum likelihood
>> Formula: AUChr ~ Assignment + (1 | RN)
>>    Data: data1
>>    AIC   BIC logLik deviance REMLdev
>>   365.7 374.8 -178.8    357.7   356.9
>> Random effects:
>>   Groups   Name        Variance Std.Dev.
>>   RN       (Intercept) 0.0000   0.0000
>>   Residual             8.4152   2.9009
>> Number of obs: 72, groups: RN, 18
>>
>> Fixed effects:
>>             Estimate Std. Error t value
>> (Intercept)   8.7703     0.4835   18.14
>> AssignmentN   0.5131     0.6837    0.75
>>
>> Correlation of Fixed Effects:
>>             (Intr)
>> AssignmentN -0.707
>>
>>
>> Model without the algorithm variable.
>>
>>> lmer(AUChr~(1|RN),data=data1,REML=FALSE)
>> Linear mixed model fit by maximum likelihood
>> Formula: AUChr ~ (1 | RN)
>>    Data: data1
>>    AIC   BIC logLik deviance REMLdev
>>   364.3 371.1 -179.1    358.3   358.5
>> Random effects:
>>   Groups   Name        Variance Std.Dev.
>>   RN       (Intercept) 0.000    0.0000
>>   Residual             8.481    2.9122
>> Number of obs: 72, groups: RN, 18
>>
>> Fixed effects:
>>             Estimate Std. Error t value
>> (Intercept)   9.0268     0.3432    26.3
>>>
>>> sessionInfo()
>> R version 2.11.1 Patched (2010-07-21 r52598)
>> Platform: i686-pc-linux-gnu (32-bit)
>>
>> locale:
>>   [1] LC_CTYPE=en_US       LC_NUMERIC=C         LC_TIME=en_US
>>   [4] LC_COLLATE=C         LC_MONETARY=C        LC_MESSAGES=en_US
>>   [7] LC_PAPER=en_US       LC_NAME=C            LC_ADDRESS=C
>> [10] LC_TELEPHONE=C       LC_MEASUREMENT=en_US LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] lme4_0.999375-34   Matrix_0.999375-42 lattice_0.18-8
>>
>> loaded via a namespace (and not attached):
>> [1] grid_2.11.1   nlme_3.1-96   stats4_2.11.1
>>>
>>> proc.time()
>>    user  system elapsed
>>   3.488   0.056   3.536


-- 
Kevin E. Thorpe
Biostatistician/Trialist, Knowledge Translation Program
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016



From bates at stat.wisc.edu  Wed Aug 11 20:25:02 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 11 Aug 2010 13:25:02 -0500
Subject: [R-sig-ME] Why am I getting a Variance of 0 for my random effect
In-Reply-To: <4C62E842.5040403@utoronto.ca>
References: <4C62E842.5040403@utoronto.ca>
Message-ID: <AANLkTikm8uKHc+qL+7mcKbLepHTyrjLQR_S67XPKKL_C@mail.gmail.com>

On Wed, Aug 11, 2010 at 1:13 PM, Kevin E. Thorpe
<kevin.thorpe at utoronto.ca> wrote:
> Hello.

> I'm getting a variance of 0 on a random effect and I don't know why.

It's not a bug - it's a feature.  ML estimates or REML estimates of
variance components can be zero.  This simply indicates that the
variability in the response associated with the factor, RN in your
case, is not sufficient to warrant the additional complexity in the
model.

> I suspect I've not set the model up correctly. ?My transcript is below
> with my own comments sprinkled in for time to time.
>
> A little bit about the data (which I will provide off-list if requested).
> ?We have nurses managing an aspect of patient care
> according to different algorithms. ?Interest focuses on of the
> algorithms result in different outcomes. ?I have restricted this
> to only nurses who did each algorithm twice (in case my problem
> was being caused by some nurses doing only one algorithm, possibly
> only one time).
>
> I figured that since I have multiple observations per nurse, I
> should treat nurse as a random effect, but maybe I confused myself
> again.

You are quite correct that it is appropriate to allow for the
possibility of RN having an effect on the response and that it should
be incorporated as a random effect if it were in the model but the
results indicate that RN does not have sufficient effect on the
response.

>
> R version 2.11.1 Patched (2010-07-21 r52598)
> Copyright (C) 2010 The R Foundation for Statistical Computing
> ISBN 3-900051-07-0
>
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
>
> ?Natural language support but running in an English locale
>
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
>
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
>
>> library(lattice)
>> library(lme4)
>
>> str(data1)
> 'data.frame': ? 72 obs. of ?3 variables:
> ?$ RN ? ? ? ?: int ?1 1 2 3 7 7 9 9 15 15 ...
> ?$ Assignment: Factor w/ 2 levels "E","N": 1 1 1 1 1 1 1 1 1 1 ...
> ?$ AUChr ? ? : num ?12.26 7.23 9.26 4.04 10.31 ...
>> tmp1 <- with(data1,aggregate(AUChr,list(RN=RN,Assigment=Assignment),mean))
>> names(tmp1)[3] <- "Mean"
>>
>> tmp2 <- with(data1,aggregate(AUChr,list(RN=RN,Assignment=Assignment),var))
>> names(tmp2)[3] <- "Variance"
>>
>> meanvar <- merge(tmp1,tmp2)
>
> The point of this is to show that the means are not all the same,
> nor are the variances.
>
>> meanvar
> ? RN Assignment ? Mean ?Variance
> 1 ? 1 ? ? ? ? ?E ?9.745 ?12.65045
> 2 ? 1 ? ? ? ? ?N ?7.185 ? 1.36125
> 3 ?15 ? ? ? ? ?E 10.605 ?15.07005
> 4 ?15 ? ? ? ? ?N 10.385 ? 4.41045
> 5 ?16 ? ? ? ? ?E ?8.175 ? 0.00845
> 6 ?16 ? ? ? ? ?N ?8.420 ? 1.03680
> 7 ? 2 ? ? ? ? ?E ?7.300 ? 7.68320
> 8 ? 2 ? ? ? ? ?N ?6.950 ? 1.00820
> 9 ?21 ? ? ? ? ?E ?9.670 ? 9.41780
> 10 21 ? ? ? ? ?N 10.535 ? 2.44205
> 11 22 ? ? ? ? ?E ?7.720 ? 2.04020
> 12 22 ? ? ? ? ?N ?7.930 ? 1.21680
> 13 24 ? ? ? ? ?E ?9.555 ?10.35125
> 14 24 ? ? ? ? ?N ?9.330 ? 0.38720
> 15 25 ? ? ? ? ?E ?8.240 ? 0.92480
> 16 25 ? ? ? ? ?N ?9.485 ? 0.00125
> 17 27 ? ? ? ? ?E ?8.635 ? 0.08405
> 18 27 ? ? ? ? ?N ?7.745 ? 3.72645
> 19 28 ? ? ? ? ?E ?9.635 ? 8.61125
> 20 28 ? ? ? ? ?N ?8.315 ?10.35125
> 21 ?3 ? ? ? ? ?E ?6.005 ? 7.72245
> 22 ?3 ? ? ? ? ?N 11.435 ?55.44045
> 23 31 ? ? ? ? ?E ?9.590 ? 9.94580
> 24 31 ? ? ? ? ?N 10.570 ?16.70420
> 25 35 ? ? ? ? ?E ?9.055 ? 0.32805
> 26 35 ? ? ? ? ?N ?9.925 ?14.41845
> 27 36 ? ? ? ? ?E ?9.040 ? 2.08080
> 28 36 ? ? ? ? ?N ?7.395 ? 1.14005
> 29 ?5 ? ? ? ? ?E ?8.430 ? 3.38000
> 30 ?5 ? ? ? ? ?N 17.385 139.94645
> 31 ?6 ? ? ? ? ?E ?6.930 ? 0.24500
> 32 ?6 ? ? ? ? ?N ?8.330 ? 1.72980
> 33 ?7 ? ? ? ? ?E 10.650 ? 0.23120
> 34 ?7 ? ? ? ? ?N ?7.375 ? 0.09245
> 35 ?9 ? ? ? ? ?E ?8.885 ? 7.56605
> 36 ?9 ? ? ? ? ?N ?8.405 ? 0.73205
>
> Model with "Assignment" (algorithm).
>
>> lmer(AUChr~Assignment+(1|RN),data=data1,REML=FALSE)
> Linear mixed model fit by maximum likelihood
> Formula: AUChr ~ Assignment + (1 | RN)
> ? Data: data1
> ? AIC ? BIC logLik deviance REMLdev
> ?365.7 374.8 -178.8 ? ?357.7 ? 356.9
> Random effects:
> ?Groups ? Name ? ? ? ?Variance Std.Dev.
> ?RN ? ? ? (Intercept) 0.0000 ? 0.0000
> ?Residual ? ? ? ? ? ? 8.4152 ? 2.9009
> Number of obs: 72, groups: RN, 18
>
> Fixed effects:
> ? ? ? ? ? ?Estimate Std. Error t value
> (Intercept) ? 8.7703 ? ? 0.4835 ? 18.14
> AssignmentN ? 0.5131 ? ? 0.6837 ? ?0.75
>
> Correlation of Fixed Effects:
> ? ? ? ? ? ?(Intr)
> AssignmentN -0.707
>
>
> Model without the algorithm variable.
>
>> lmer(AUChr~(1|RN),data=data1,REML=FALSE)
> Linear mixed model fit by maximum likelihood
> Formula: AUChr ~ (1 | RN)
> ? Data: data1
> ? AIC ? BIC logLik deviance REMLdev
> ?364.3 371.1 -179.1 ? ?358.3 ? 358.5
> Random effects:
> ?Groups ? Name ? ? ? ?Variance Std.Dev.
> ?RN ? ? ? (Intercept) 0.000 ? ?0.0000
> ?Residual ? ? ? ? ? ? 8.481 ? ?2.9122
> Number of obs: 72, groups: RN, 18
>
> Fixed effects:
> ? ? ? ? ? ?Estimate Std. Error t value
> (Intercept) ? 9.0268 ? ? 0.3432 ? ?26.3
>>
>> sessionInfo()
> R version 2.11.1 Patched (2010-07-21 r52598)
> Platform: i686-pc-linux-gnu (32-bit)
>
> locale:
> ?[1] LC_CTYPE=en_US ? ? ? LC_NUMERIC=C ? ? ? ? LC_TIME=en_US
> ?[4] LC_COLLATE=C ? ? ? ? LC_MONETARY=C ? ? ? ?LC_MESSAGES=en_US
> ?[7] LC_PAPER=en_US ? ? ? LC_NAME=C ? ? ? ? ? ?LC_ADDRESS=C
> [10] LC_TELEPHONE=C ? ? ? LC_MEASUREMENT=en_US LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>
> other attached packages:
> [1] lme4_0.999375-34 ? Matrix_0.999375-42 lattice_0.18-8
>
> loaded via a namespace (and not attached):
> [1] grid_2.11.1 ? nlme_3.1-96 ? stats4_2.11.1
>>
>> proc.time()
> ? user ?system elapsed
> ?3.488 ? 0.056 ? 3.536
>
> --
> Kevin E. Thorpe
> Biostatistician/Trialist, Knowledge Translation Program
> Assistant Professor, Dalla Lana School of Public Health
> University of Toronto
> email: kevin.thorpe at utoronto.ca ?Tel: 416.864.5776 ?Fax: 416.864.3016
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Wed Aug 11 20:26:20 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 11 Aug 2010 13:26:20 -0500
Subject: [R-sig-ME] Why am I getting a Variance of 0 for my random effect
In-Reply-To: <AANLkTikqfrYEO_Xvyr99BaNgfdKt9urw_5Nvds=dQRSF@mail.gmail.com>
References: <4C62E842.5040403@utoronto.ca>
	<AANLkTikqfrYEO_Xvyr99BaNgfdKt9urw_5Nvds=dQRSF@mail.gmail.com>
Message-ID: <AANLkTimi6Mt=nwPLk-g7RhutvKpgPxpcpy1hu1y_9tfh@mail.gmail.com>

On Wed, Aug 11, 2010 at 1:16 PM, Daniel Ezra Johnson
<danielezrajohnson at gmail.com> wrote:
> Try data1$RN <- as.factor(data1$RN).

A reasonable suggestion but it wouldn't make a difference.  Note that
lmer is already picking up on there being 18 levels of the RN factor.

> On Wed, Aug 11, 2010 at 2:13 PM, Kevin E. Thorpe
> <kevin.thorpe at utoronto.ca> wrote:
>> Hello.
>>
>> I'm getting a variance of 0 on a random effect and I don't know why.
>> I suspect I've not set the model up correctly. ?My transcript is below
>> with my own comments sprinkled in for time to time.
>>
>> A little bit about the data (which I will provide off-list if requested).
>> ?We have nurses managing an aspect of patient care
>> according to different algorithms. ?Interest focuses on of the
>> algorithms result in different outcomes. ?I have restricted this
>> to only nurses who did each algorithm twice (in case my problem
>> was being caused by some nurses doing only one algorithm, possibly
>> only one time).
>>
>> I figured that since I have multiple observations per nurse, I
>> should treat nurse as a random effect, but maybe I confused myself
>> again.
>>
>>
>> R version 2.11.1 Patched (2010-07-21 r52598)
>> Copyright (C) 2010 The R Foundation for Statistical Computing
>> ISBN 3-900051-07-0
>>
>> R is free software and comes with ABSOLUTELY NO WARRANTY.
>> You are welcome to redistribute it under certain conditions.
>> Type 'license()' or 'licence()' for distribution details.
>>
>> ?Natural language support but running in an English locale
>>
>> R is a collaborative project with many contributors.
>> Type 'contributors()' for more information and
>> 'citation()' on how to cite R or R packages in publications.
>>
>> Type 'demo()' for some demos, 'help()' for on-line help, or
>> 'help.start()' for an HTML browser interface to help.
>> Type 'q()' to quit R.
>>
>>> library(lattice)
>>> library(lme4)
>>
>>> str(data1)
>> 'data.frame': ? 72 obs. of ?3 variables:
>> ?$ RN ? ? ? ?: int ?1 1 2 3 7 7 9 9 15 15 ...
>> ?$ Assignment: Factor w/ 2 levels "E","N": 1 1 1 1 1 1 1 1 1 1 ...
>> ?$ AUChr ? ? : num ?12.26 7.23 9.26 4.04 10.31 ...
>>> tmp1 <- with(data1,aggregate(AUChr,list(RN=RN,Assigment=Assignment),mean))
>>> names(tmp1)[3] <- "Mean"
>>>
>>> tmp2 <- with(data1,aggregate(AUChr,list(RN=RN,Assignment=Assignment),var))
>>> names(tmp2)[3] <- "Variance"
>>>
>>> meanvar <- merge(tmp1,tmp2)
>>
>> The point of this is to show that the means are not all the same,
>> nor are the variances.
>>
>>> meanvar
>> ? RN Assignment ? Mean ?Variance
>> 1 ? 1 ? ? ? ? ?E ?9.745 ?12.65045
>> 2 ? 1 ? ? ? ? ?N ?7.185 ? 1.36125
>> 3 ?15 ? ? ? ? ?E 10.605 ?15.07005
>> 4 ?15 ? ? ? ? ?N 10.385 ? 4.41045
>> 5 ?16 ? ? ? ? ?E ?8.175 ? 0.00845
>> 6 ?16 ? ? ? ? ?N ?8.420 ? 1.03680
>> 7 ? 2 ? ? ? ? ?E ?7.300 ? 7.68320
>> 8 ? 2 ? ? ? ? ?N ?6.950 ? 1.00820
>> 9 ?21 ? ? ? ? ?E ?9.670 ? 9.41780
>> 10 21 ? ? ? ? ?N 10.535 ? 2.44205
>> 11 22 ? ? ? ? ?E ?7.720 ? 2.04020
>> 12 22 ? ? ? ? ?N ?7.930 ? 1.21680
>> 13 24 ? ? ? ? ?E ?9.555 ?10.35125
>> 14 24 ? ? ? ? ?N ?9.330 ? 0.38720
>> 15 25 ? ? ? ? ?E ?8.240 ? 0.92480
>> 16 25 ? ? ? ? ?N ?9.485 ? 0.00125
>> 17 27 ? ? ? ? ?E ?8.635 ? 0.08405
>> 18 27 ? ? ? ? ?N ?7.745 ? 3.72645
>> 19 28 ? ? ? ? ?E ?9.635 ? 8.61125
>> 20 28 ? ? ? ? ?N ?8.315 ?10.35125
>> 21 ?3 ? ? ? ? ?E ?6.005 ? 7.72245
>> 22 ?3 ? ? ? ? ?N 11.435 ?55.44045
>> 23 31 ? ? ? ? ?E ?9.590 ? 9.94580
>> 24 31 ? ? ? ? ?N 10.570 ?16.70420
>> 25 35 ? ? ? ? ?E ?9.055 ? 0.32805
>> 26 35 ? ? ? ? ?N ?9.925 ?14.41845
>> 27 36 ? ? ? ? ?E ?9.040 ? 2.08080
>> 28 36 ? ? ? ? ?N ?7.395 ? 1.14005
>> 29 ?5 ? ? ? ? ?E ?8.430 ? 3.38000
>> 30 ?5 ? ? ? ? ?N 17.385 139.94645
>> 31 ?6 ? ? ? ? ?E ?6.930 ? 0.24500
>> 32 ?6 ? ? ? ? ?N ?8.330 ? 1.72980
>> 33 ?7 ? ? ? ? ?E 10.650 ? 0.23120
>> 34 ?7 ? ? ? ? ?N ?7.375 ? 0.09245
>> 35 ?9 ? ? ? ? ?E ?8.885 ? 7.56605
>> 36 ?9 ? ? ? ? ?N ?8.405 ? 0.73205
>>
>> Model with "Assignment" (algorithm).
>>
>>> lmer(AUChr~Assignment+(1|RN),data=data1,REML=FALSE)
>> Linear mixed model fit by maximum likelihood
>> Formula: AUChr ~ Assignment + (1 | RN)
>> ? Data: data1
>> ? AIC ? BIC logLik deviance REMLdev
>> ?365.7 374.8 -178.8 ? ?357.7 ? 356.9
>> Random effects:
>> ?Groups ? Name ? ? ? ?Variance Std.Dev.
>> ?RN ? ? ? (Intercept) 0.0000 ? 0.0000
>> ?Residual ? ? ? ? ? ? 8.4152 ? 2.9009
>> Number of obs: 72, groups: RN, 18
>>
>> Fixed effects:
>> ? ? ? ? ? ?Estimate Std. Error t value
>> (Intercept) ? 8.7703 ? ? 0.4835 ? 18.14
>> AssignmentN ? 0.5131 ? ? 0.6837 ? ?0.75
>>
>> Correlation of Fixed Effects:
>> ? ? ? ? ? ?(Intr)
>> AssignmentN -0.707
>>
>>
>> Model without the algorithm variable.
>>
>>> lmer(AUChr~(1|RN),data=data1,REML=FALSE)
>> Linear mixed model fit by maximum likelihood
>> Formula: AUChr ~ (1 | RN)
>> ? Data: data1
>> ? AIC ? BIC logLik deviance REMLdev
>> ?364.3 371.1 -179.1 ? ?358.3 ? 358.5
>> Random effects:
>> ?Groups ? Name ? ? ? ?Variance Std.Dev.
>> ?RN ? ? ? (Intercept) 0.000 ? ?0.0000
>> ?Residual ? ? ? ? ? ? 8.481 ? ?2.9122
>> Number of obs: 72, groups: RN, 18
>>
>> Fixed effects:
>> ? ? ? ? ? ?Estimate Std. Error t value
>> (Intercept) ? 9.0268 ? ? 0.3432 ? ?26.3
>>>
>>> sessionInfo()
>> R version 2.11.1 Patched (2010-07-21 r52598)
>> Platform: i686-pc-linux-gnu (32-bit)
>>
>> locale:
>> ?[1] LC_CTYPE=en_US ? ? ? LC_NUMERIC=C ? ? ? ? LC_TIME=en_US
>> ?[4] LC_COLLATE=C ? ? ? ? LC_MONETARY=C ? ? ? ?LC_MESSAGES=en_US
>> ?[7] LC_PAPER=en_US ? ? ? LC_NAME=C ? ? ? ? ? ?LC_ADDRESS=C
>> [10] LC_TELEPHONE=C ? ? ? LC_MEASUREMENT=en_US LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>
>> other attached packages:
>> [1] lme4_0.999375-34 ? Matrix_0.999375-42 lattice_0.18-8
>>
>> loaded via a namespace (and not attached):
>> [1] grid_2.11.1 ? nlme_3.1-96 ? stats4_2.11.1
>>>
>>> proc.time()
>> ? user ?system elapsed
>> ?3.488 ? 0.056 ? 3.536
>>
>> --
>> Kevin E. Thorpe
>> Biostatistician/Trialist, Knowledge Translation Program
>> Assistant Professor, Dalla Lana School of Public Health
>> University of Toronto
>> email: kevin.thorpe at utoronto.ca ?Tel: 416.864.5776 ?Fax: 416.864.3016
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From betinig at uoguelph.ca  Wed Aug 11 20:40:17 2010
From: betinig at uoguelph.ca (Gustavo Betini)
Date: Wed, 11 Aug 2010 14:40:17 -0400
Subject: [R-sig-ME] Why am I getting a Variance of 0 for my random effect
In-Reply-To: <AANLkTikm8uKHc+qL+7mcKbLepHTyrjLQR_S67XPKKL_C@mail.gmail.com>
References: <4C62E842.5040403@utoronto.ca>
	<AANLkTikm8uKHc+qL+7mcKbLepHTyrjLQR_S67XPKKL_C@mail.gmail.com>
Message-ID: <4C62EE91.70805@uoguelph.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100811/7d46b1e6/attachment.pl>

From bates at stat.wisc.edu  Wed Aug 11 21:00:06 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 11 Aug 2010 14:00:06 -0500
Subject: [R-sig-ME] Why am I getting a Variance of 0 for my random effect
In-Reply-To: <4C62EE91.70805@uoguelph.ca>
References: <4C62E842.5040403@utoronto.ca>
	<AANLkTikm8uKHc+qL+7mcKbLepHTyrjLQR_S67XPKKL_C@mail.gmail.com>
	<4C62EE91.70805@uoguelph.ca>
Message-ID: <AANLkTi=7jA4tavG=S-tviTD9yz34kzuT4OEZB3XOaNUN@mail.gmail.com>

On Wed, Aug 11, 2010 at 1:40 PM, Gustavo Betini <betinig at uoguelph.ca> wrote:
>
>> It's not a bug - it's a feature. ?ML estimates or REML estimates of
>> variance components can be zero. ?This simply indicates that the
>> variability in the response associated with the factor, RN in your
>> case, is not sufficient to warrant the additional complexity in the
>> model.
>>
>
> does it mean that the correlation between two random effects can be 1 or
> -1?

Yes.  For example,
> data(Early, package="mlmRev")
> Early <- within(Early, tos <- age-0.5)
> fm12 <- lmer(cog ~ tos+trt:tos+(tos|id), Early, verbose=TRUE)
npt = 7 , n =  3
rhobeg =  0.2 , rhoend =  2e-07
   0.020:  11:      2368.50; 1.09296 -0.173139 0.0953204
  0.0020:  30:      2364.50; 1.48770 -0.374305 0.0138819
 0.00020:  42:      2364.50; 1.48462 -0.372458 0.00762182
 2.0e-05:  58:      2364.50; 1.48417 -0.372319 0.00114305
 2.0e-06:  74:      2364.50; 1.48420 -0.372480  0.00000
 2.0e-07:  80:      2364.50; 1.48420 -0.372481  0.00000
At return
 85:     2364.5016:  1.48420 -0.372481 2.77475e-07
> print(fm12, corr=FALSE)
Linear mixed model fit by REML ['merMod']
Formula: cog ~ tos + trt:tos + (tos | id)
   Data: Early
REML criterion at convergence: 2364.502

Random effects:
 Groups   Name        Variance Std.Dev. Corr
 id       (Intercept) 166.40   12.900
          tos          10.48    3.237   -1.000
 Residual              75.54    8.691
Number of obs: 309, groups: id, 103

Fixed effects:
            Estimate Std. Error t value
(Intercept)  120.783      1.824   66.22
tos          -22.470      1.494  -15.04
tos:trtY       7.646      1.447    5.28


The resulting model no longer fulfills the technical definition of a
linear mixed-effects model.



From kevin.thorpe at utoronto.ca  Wed Aug 11 21:18:31 2010
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Wed, 11 Aug 2010 15:18:31 -0400
Subject: [R-sig-ME] Why am I getting a Variance of 0 for my random effect
In-Reply-To: <AANLkTikm8uKHc+qL+7mcKbLepHTyrjLQR_S67XPKKL_C@mail.gmail.com>
References: <4C62E842.5040403@utoronto.ca>
	<AANLkTikm8uKHc+qL+7mcKbLepHTyrjLQR_S67XPKKL_C@mail.gmail.com>
Message-ID: <4C62F787.6070504@utoronto.ca>

On 08/11/2010 02:25 PM, Douglas Bates wrote:
> On Wed, Aug 11, 2010 at 1:13 PM, Kevin E. Thorpe
> <kevin.thorpe at utoronto.ca>  wrote:
>> Hello.
>
>> I'm getting a variance of 0 on a random effect and I don't know why.
>
> It's not a bug - it's a feature.  ML estimates or REML estimates of
> variance components can be zero.  This simply indicates that the
> variability in the response associated with the factor, RN in your
> case, is not sufficient to warrant the additional complexity in the
> model.
>
>> I suspect I've not set the model up correctly.  My transcript is below
>> with my own comments sprinkled in for time to time.
>>
>> A little bit about the data (which I will provide off-list if requested).
>>   We have nurses managing an aspect of patient care
>> according to different algorithms.  Interest focuses on of the
>> algorithms result in different outcomes.  I have restricted this
>> to only nurses who did each algorithm twice (in case my problem
>> was being caused by some nurses doing only one algorithm, possibly
>> only one time).
>>
>> I figured that since I have multiple observations per nurse, I
>> should treat nurse as a random effect, but maybe I confused myself
>> again.
>
> You are quite correct that it is appropriate to allow for the
> possibility of RN having an effect on the response and that it should
> be incorporated as a random effect if it were in the model but the
> results indicate that RN does not have sufficient effect on the
> response.

Thanks Doug.  Your response is helpful, as always.  If RN does not
contribute a random effect, would it be appropriate to revert to a
standard regression model, or is it best to leave the unimportant
random effect?  In the case of ordinary regression, dropping
variables based on their p-values compromises inference.  Does the
same apply with dropping a random effect with no variance?

Kevin

>
>>
>> R version 2.11.1 Patched (2010-07-21 r52598)
>> Copyright (C) 2010 The R Foundation for Statistical Computing
>> ISBN 3-900051-07-0
>>
>> R is free software and comes with ABSOLUTELY NO WARRANTY.
>> You are welcome to redistribute it under certain conditions.
>> Type 'license()' or 'licence()' for distribution details.
>>
>>   Natural language support but running in an English locale
>>
>> R is a collaborative project with many contributors.
>> Type 'contributors()' for more information and
>> 'citation()' on how to cite R or R packages in publications.
>>
>> Type 'demo()' for some demos, 'help()' for on-line help, or
>> 'help.start()' for an HTML browser interface to help.
>> Type 'q()' to quit R.
>>
>>> library(lattice)
>>> library(lme4)
>>
>>> str(data1)
>> 'data.frame':   72 obs. of  3 variables:
>>   $ RN        : int  1 1 2 3 7 7 9 9 15 15 ...
>>   $ Assignment: Factor w/ 2 levels "E","N": 1 1 1 1 1 1 1 1 1 1 ...
>>   $ AUChr     : num  12.26 7.23 9.26 4.04 10.31 ...
>>> tmp1<- with(data1,aggregate(AUChr,list(RN=RN,Assigment=Assignment),mean))
>>> names(tmp1)[3]<- "Mean"
>>>
>>> tmp2<- with(data1,aggregate(AUChr,list(RN=RN,Assignment=Assignment),var))
>>> names(tmp2)[3]<- "Variance"
>>>
>>> meanvar<- merge(tmp1,tmp2)
>>
>> The point of this is to show that the means are not all the same,
>> nor are the variances.
>>
>>> meanvar
>>    RN Assignment   Mean  Variance
>> 1   1          E  9.745  12.65045
>> 2   1          N  7.185   1.36125
>> 3  15          E 10.605  15.07005
>> 4  15          N 10.385   4.41045
>> 5  16          E  8.175   0.00845
>> 6  16          N  8.420   1.03680
>> 7   2          E  7.300   7.68320
>> 8   2          N  6.950   1.00820
>> 9  21          E  9.670   9.41780
>> 10 21          N 10.535   2.44205
>> 11 22          E  7.720   2.04020
>> 12 22          N  7.930   1.21680
>> 13 24          E  9.555  10.35125
>> 14 24          N  9.330   0.38720
>> 15 25          E  8.240   0.92480
>> 16 25          N  9.485   0.00125
>> 17 27          E  8.635   0.08405
>> 18 27          N  7.745   3.72645
>> 19 28          E  9.635   8.61125
>> 20 28          N  8.315  10.35125
>> 21  3          E  6.005   7.72245
>> 22  3          N 11.435  55.44045
>> 23 31          E  9.590   9.94580
>> 24 31          N 10.570  16.70420
>> 25 35          E  9.055   0.32805
>> 26 35          N  9.925  14.41845
>> 27 36          E  9.040   2.08080
>> 28 36          N  7.395   1.14005
>> 29  5          E  8.430   3.38000
>> 30  5          N 17.385 139.94645
>> 31  6          E  6.930   0.24500
>> 32  6          N  8.330   1.72980
>> 33  7          E 10.650   0.23120
>> 34  7          N  7.375   0.09245
>> 35  9          E  8.885   7.56605
>> 36  9          N  8.405   0.73205
>>
>> Model with "Assignment" (algorithm).
>>
>>> lmer(AUChr~Assignment+(1|RN),data=data1,REML=FALSE)
>> Linear mixed model fit by maximum likelihood
>> Formula: AUChr ~ Assignment + (1 | RN)
>>    Data: data1
>>    AIC   BIC logLik deviance REMLdev
>>   365.7 374.8 -178.8    357.7   356.9
>> Random effects:
>>   Groups   Name        Variance Std.Dev.
>>   RN       (Intercept) 0.0000   0.0000
>>   Residual             8.4152   2.9009
>> Number of obs: 72, groups: RN, 18
>>
>> Fixed effects:
>>             Estimate Std. Error t value
>> (Intercept)   8.7703     0.4835   18.14
>> AssignmentN   0.5131     0.6837    0.75
>>
>> Correlation of Fixed Effects:
>>             (Intr)
>> AssignmentN -0.707
>>
>>
>> Model without the algorithm variable.
>>
>>> lmer(AUChr~(1|RN),data=data1,REML=FALSE)
>> Linear mixed model fit by maximum likelihood
>> Formula: AUChr ~ (1 | RN)
>>    Data: data1
>>    AIC   BIC logLik deviance REMLdev
>>   364.3 371.1 -179.1    358.3   358.5
>> Random effects:
>>   Groups   Name        Variance Std.Dev.
>>   RN       (Intercept) 0.000    0.0000
>>   Residual             8.481    2.9122
>> Number of obs: 72, groups: RN, 18
>>
>> Fixed effects:
>>             Estimate Std. Error t value
>> (Intercept)   9.0268     0.3432    26.3
>>>
>>> sessionInfo()
>> R version 2.11.1 Patched (2010-07-21 r52598)
>> Platform: i686-pc-linux-gnu (32-bit)
>>
>> locale:
>>   [1] LC_CTYPE=en_US       LC_NUMERIC=C         LC_TIME=en_US
>>   [4] LC_COLLATE=C         LC_MONETARY=C        LC_MESSAGES=en_US
>>   [7] LC_PAPER=en_US       LC_NAME=C            LC_ADDRESS=C
>> [10] LC_TELEPHONE=C       LC_MEASUREMENT=en_US LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] lme4_0.999375-34   Matrix_0.999375-42 lattice_0.18-8
>>
>> loaded via a namespace (and not attached):
>> [1] grid_2.11.1   nlme_3.1-96   stats4_2.11.1
>>>
>>> proc.time()
>>    user  system elapsed
>>   3.488   0.056   3.536


-- 
Kevin E. Thorpe
Biostatistician/Trialist, Knowledge Translation Program
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016



From bates at stat.wisc.edu  Wed Aug 11 22:05:06 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 11 Aug 2010 15:05:06 -0500
Subject: [R-sig-ME] Why am I getting a Variance of 0 for my random effect
In-Reply-To: <4C62F787.6070504@utoronto.ca>
References: <4C62E842.5040403@utoronto.ca>
	<AANLkTikm8uKHc+qL+7mcKbLepHTyrjLQR_S67XPKKL_C@mail.gmail.com>
	<4C62F787.6070504@utoronto.ca>
Message-ID: <AANLkTi=GGBC+teF63va9Z=wDhyLNvbRdcnN4PWLQBUz7@mail.gmail.com>

On Wed, Aug 11, 2010 at 2:18 PM, Kevin E. Thorpe
<kevin.thorpe at utoronto.ca> wrote:
> On 08/11/2010 02:25 PM, Douglas Bates wrote:
>>
>> On Wed, Aug 11, 2010 at 1:13 PM, Kevin E. Thorpe
>> <kevin.thorpe at utoronto.ca> ?wrote:
>>>
>>> Hello.
>>
>>> I'm getting a variance of 0 on a random effect and I don't know why.
>>
>> It's not a bug - it's a feature. ?ML estimates or REML estimates of
>> variance components can be zero. ?This simply indicates that the
>> variability in the response associated with the factor, RN in your
>> case, is not sufficient to warrant the additional complexity in the
>> model.
>>
>>> I suspect I've not set the model up correctly. ?My transcript is below
>>> with my own comments sprinkled in for time to time.
>>>
>>> A little bit about the data (which I will provide off-list if requested).
>>> ?We have nurses managing an aspect of patient care
>>> according to different algorithms. ?Interest focuses on of the
>>> algorithms result in different outcomes. ?I have restricted this
>>> to only nurses who did each algorithm twice (in case my problem
>>> was being caused by some nurses doing only one algorithm, possibly
>>> only one time).
>>>
>>> I figured that since I have multiple observations per nurse, I
>>> should treat nurse as a random effect, but maybe I confused myself
>>> again.
>>
>> You are quite correct that it is appropriate to allow for the
>> possibility of RN having an effect on the response and that it should
>> be incorporated as a random effect if it were in the model but the
>> results indicate that RN does not have sufficient effect on the
>> response.
>
> Thanks Doug. ?Your response is helpful, as always. ?If RN does not
> contribute a random effect, would it be appropriate to revert to a
> standard regression model, or is it best to leave the unimportant
> random effect? ?In the case of ordinary regression, dropping
> variables based on their p-values compromises inference. ?Does the
> same apply with dropping a random effect with no variance?

When the random effects variance is zero the model reverts to the
linear regression model in the sense that the two models give the same
predicted values, the same log-likelihood, coefficient estimates for
the fixed effects and standard errors.  That is, there is no need to
continue to represent the model as a linear mixed model if the only
variance component parameter's estimated value is zero.

> Kevin
>
>>
>>>
>>> R version 2.11.1 Patched (2010-07-21 r52598)
>>> Copyright (C) 2010 The R Foundation for Statistical Computing
>>> ISBN 3-900051-07-0
>>>
>>> R is free software and comes with ABSOLUTELY NO WARRANTY.
>>> You are welcome to redistribute it under certain conditions.
>>> Type 'license()' or 'licence()' for distribution details.
>>>
>>> ?Natural language support but running in an English locale
>>>
>>> R is a collaborative project with many contributors.
>>> Type 'contributors()' for more information and
>>> 'citation()' on how to cite R or R packages in publications.
>>>
>>> Type 'demo()' for some demos, 'help()' for on-line help, or
>>> 'help.start()' for an HTML browser interface to help.
>>> Type 'q()' to quit R.
>>>
>>>> library(lattice)
>>>> library(lme4)
>>>
>>>> str(data1)
>>>
>>> 'data.frame': ? 72 obs. of ?3 variables:
>>> ?$ RN ? ? ? ?: int ?1 1 2 3 7 7 9 9 15 15 ...
>>> ?$ Assignment: Factor w/ 2 levels "E","N": 1 1 1 1 1 1 1 1 1 1 ...
>>> ?$ AUChr ? ? : num ?12.26 7.23 9.26 4.04 10.31 ...
>>>>
>>>> tmp1<-
>>>> with(data1,aggregate(AUChr,list(RN=RN,Assigment=Assignment),mean))
>>>> names(tmp1)[3]<- "Mean"
>>>>
>>>> tmp2<-
>>>> with(data1,aggregate(AUChr,list(RN=RN,Assignment=Assignment),var))
>>>> names(tmp2)[3]<- "Variance"
>>>>
>>>> meanvar<- merge(tmp1,tmp2)
>>>
>>> The point of this is to show that the means are not all the same,
>>> nor are the variances.
>>>
>>>> meanvar
>>>
>>> ? RN Assignment ? Mean ?Variance
>>> 1 ? 1 ? ? ? ? ?E ?9.745 ?12.65045
>>> 2 ? 1 ? ? ? ? ?N ?7.185 ? 1.36125
>>> 3 ?15 ? ? ? ? ?E 10.605 ?15.07005
>>> 4 ?15 ? ? ? ? ?N 10.385 ? 4.41045
>>> 5 ?16 ? ? ? ? ?E ?8.175 ? 0.00845
>>> 6 ?16 ? ? ? ? ?N ?8.420 ? 1.03680
>>> 7 ? 2 ? ? ? ? ?E ?7.300 ? 7.68320
>>> 8 ? 2 ? ? ? ? ?N ?6.950 ? 1.00820
>>> 9 ?21 ? ? ? ? ?E ?9.670 ? 9.41780
>>> 10 21 ? ? ? ? ?N 10.535 ? 2.44205
>>> 11 22 ? ? ? ? ?E ?7.720 ? 2.04020
>>> 12 22 ? ? ? ? ?N ?7.930 ? 1.21680
>>> 13 24 ? ? ? ? ?E ?9.555 ?10.35125
>>> 14 24 ? ? ? ? ?N ?9.330 ? 0.38720
>>> 15 25 ? ? ? ? ?E ?8.240 ? 0.92480
>>> 16 25 ? ? ? ? ?N ?9.485 ? 0.00125
>>> 17 27 ? ? ? ? ?E ?8.635 ? 0.08405
>>> 18 27 ? ? ? ? ?N ?7.745 ? 3.72645
>>> 19 28 ? ? ? ? ?E ?9.635 ? 8.61125
>>> 20 28 ? ? ? ? ?N ?8.315 ?10.35125
>>> 21 ?3 ? ? ? ? ?E ?6.005 ? 7.72245
>>> 22 ?3 ? ? ? ? ?N 11.435 ?55.44045
>>> 23 31 ? ? ? ? ?E ?9.590 ? 9.94580
>>> 24 31 ? ? ? ? ?N 10.570 ?16.70420
>>> 25 35 ? ? ? ? ?E ?9.055 ? 0.32805
>>> 26 35 ? ? ? ? ?N ?9.925 ?14.41845
>>> 27 36 ? ? ? ? ?E ?9.040 ? 2.08080
>>> 28 36 ? ? ? ? ?N ?7.395 ? 1.14005
>>> 29 ?5 ? ? ? ? ?E ?8.430 ? 3.38000
>>> 30 ?5 ? ? ? ? ?N 17.385 139.94645
>>> 31 ?6 ? ? ? ? ?E ?6.930 ? 0.24500
>>> 32 ?6 ? ? ? ? ?N ?8.330 ? 1.72980
>>> 33 ?7 ? ? ? ? ?E 10.650 ? 0.23120
>>> 34 ?7 ? ? ? ? ?N ?7.375 ? 0.09245
>>> 35 ?9 ? ? ? ? ?E ?8.885 ? 7.56605
>>> 36 ?9 ? ? ? ? ?N ?8.405 ? 0.73205
>>>
>>> Model with "Assignment" (algorithm).
>>>
>>>> lmer(AUChr~Assignment+(1|RN),data=data1,REML=FALSE)
>>>
>>> Linear mixed model fit by maximum likelihood
>>> Formula: AUChr ~ Assignment + (1 | RN)
>>> ? Data: data1
>>> ? AIC ? BIC logLik deviance REMLdev
>>> ?365.7 374.8 -178.8 ? ?357.7 ? 356.9
>>> Random effects:
>>> ?Groups ? Name ? ? ? ?Variance Std.Dev.
>>> ?RN ? ? ? (Intercept) 0.0000 ? 0.0000
>>> ?Residual ? ? ? ? ? ? 8.4152 ? 2.9009
>>> Number of obs: 72, groups: RN, 18
>>>
>>> Fixed effects:
>>> ? ? ? ? ? ?Estimate Std. Error t value
>>> (Intercept) ? 8.7703 ? ? 0.4835 ? 18.14
>>> AssignmentN ? 0.5131 ? ? 0.6837 ? ?0.75
>>>
>>> Correlation of Fixed Effects:
>>> ? ? ? ? ? ?(Intr)
>>> AssignmentN -0.707
>>>
>>>
>>> Model without the algorithm variable.
>>>
>>>> lmer(AUChr~(1|RN),data=data1,REML=FALSE)
>>>
>>> Linear mixed model fit by maximum likelihood
>>> Formula: AUChr ~ (1 | RN)
>>> ? Data: data1
>>> ? AIC ? BIC logLik deviance REMLdev
>>> ?364.3 371.1 -179.1 ? ?358.3 ? 358.5
>>> Random effects:
>>> ?Groups ? Name ? ? ? ?Variance Std.Dev.
>>> ?RN ? ? ? (Intercept) 0.000 ? ?0.0000
>>> ?Residual ? ? ? ? ? ? 8.481 ? ?2.9122
>>> Number of obs: 72, groups: RN, 18
>>>
>>> Fixed effects:
>>> ? ? ? ? ? ?Estimate Std. Error t value
>>> (Intercept) ? 9.0268 ? ? 0.3432 ? ?26.3
>>>>
>>>> sessionInfo()
>>>
>>> R version 2.11.1 Patched (2010-07-21 r52598)
>>> Platform: i686-pc-linux-gnu (32-bit)
>>>
>>> locale:
>>> ?[1] LC_CTYPE=en_US ? ? ? LC_NUMERIC=C ? ? ? ? LC_TIME=en_US
>>> ?[4] LC_COLLATE=C ? ? ? ? LC_MONETARY=C ? ? ? ?LC_MESSAGES=en_US
>>> ?[7] LC_PAPER=en_US ? ? ? LC_NAME=C ? ? ? ? ? ?LC_ADDRESS=C
>>> [10] LC_TELEPHONE=C ? ? ? LC_MEASUREMENT=en_US LC_IDENTIFICATION=C
>>>
>>> attached base packages:
>>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>>
>>> other attached packages:
>>> [1] lme4_0.999375-34 ? Matrix_0.999375-42 lattice_0.18-8
>>>
>>> loaded via a namespace (and not attached):
>>> [1] grid_2.11.1 ? nlme_3.1-96 ? stats4_2.11.1
>>>>
>>>> proc.time()
>>>
>>> ? user ?system elapsed
>>> ?3.488 ? 0.056 ? 3.536
>
>
> --
> Kevin E. Thorpe
> Biostatistician/Trialist, Knowledge Translation Program
> Assistant Professor, Dalla Lana School of Public Health
> University of Toronto
> email: kevin.thorpe at utoronto.ca ?Tel: 416.864.5776 ?Fax: 416.864.3016
>



From A.Robinson at ms.unimelb.edu.au  Wed Aug 11 22:21:48 2010
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Thu, 12 Aug 2010 06:21:48 +1000
Subject: [R-sig-ME] Why am I getting a Variance of 0 for my random effect
In-Reply-To: <AANLkTi=GGBC+teF63va9Z=wDhyLNvbRdcnN4PWLQBUz7@mail.gmail.com>
References: <4C62E842.5040403@utoronto.ca>
	<AANLkTikm8uKHc+qL+7mcKbLepHTyrjLQR_S67XPKKL_C@mail.gmail.com>
	<4C62F787.6070504@utoronto.ca>
	<AANLkTi=GGBC+teF63va9Z=wDhyLNvbRdcnN4PWLQBUz7@mail.gmail.com>
Message-ID: <20100811202148.GI75947@ms.unimelb.edu.au>

On Wed, Aug 11, 2010 at 03:05:06PM -0500, Douglas Bates wrote:
> > Thanks Doug. ?Your response is helpful, as always. ?If RN does not
> > contribute a random effect, would it be appropriate to revert to a
> > standard regression model, or is it best to leave the unimportant
> > random effect? ?In the case of ordinary regression, dropping
> > variables based on their p-values compromises inference. ?Does the
> > same apply with dropping a random effect with no variance?
> 
> When the random effects variance is zero the model reverts to the
> linear regression model in the sense that the two models give the same
> predicted values, the same log-likelihood, coefficient estimates for
> the fixed effects and standard errors.  That is, there is no need to
> continue to represent the model as a linear mixed model if the only
> variance component parameter's estimated value is zero.

It's worth noting that this behaviour will not always be what you want
to happen.  There are times when you may want the inference and
estimation that arise from a model to reflect the inclusion of random
effects, even if the mode of the density of those effects is zero.

This is true, for example, in design-based inference.  For example,
you may feel strongly that the experimental design (or sample design)
has elements of clustering, and that to fit a model that ignores the
clustering will result in negatively biased estimates of the standard
errors of the fixed effects.

If your inference is model based, then this behaviour should be
perfectly fine.

Best wishes,

Andrew

-- 
Andrew Robinson  
Program Manager, ACERA 
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia               (prefer email)
http://www.ms.unimelb.edu.au/~andrewpr              Fax: +61-3-8344-4599
http://www.acera.unimelb.edu.au/



From john.maindonald at anu.edu.au  Thu Aug 12 01:29:53 2010
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Thu, 12 Aug 2010 09:29:53 +1000
Subject: [R-sig-ME] Why am I getting a Variance of 0 for my random effect
In-Reply-To: <4C62EADD.2000601@utoronto.ca>
References: <4C62E842.5040403@utoronto.ca>
	<AANLkTikqfrYEO_Xvyr99BaNgfdKt9urw_5Nvds=dQRSF@mail.gmail.com>
	<4C62EADD.2000601@utoronto.ca>
Message-ID: <41167339-642E-4F8B-B634-10327A037F6D@anu.edu.au>

Surely you do want to treat nurses as a random effect, by analysing 
summary data at the nurse level, if not in a multi-level model.

The zero variance may (if it really would prefer to be negative) be telling 
you that there is a systematic difference between the two times, for which 
your model needs to account.  Maybe there is a learning effect -- 2nd time 
is systematically different from the first.  Did your model account for such 
an effect?

Or (requires more thought to model), those who do badly the first time
may learn rather more from their experience than those who did
moderately well, doing better than average next time?  It appears that
the data have the information needed to get insight on these questions.

The most insightful approach might well be separate regressions
for 2-1 differences and 2+1 averages.  I'd do those analyses whatever 
else you do.  

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 12/08/2010, at 4:24 AM, Kevin E. Thorpe wrote:

> On 08/11/2010 02:16 PM, Daniel Ezra Johnson wrote:
>> Try data1$RN<- as.factor(data1$RN).
> 
> Thanks, but that has no effect.  That is I get the same results.
> 
>> 
>> On Wed, Aug 11, 2010 at 2:13 PM, Kevin E. Thorpe
>> <kevin.thorpe at utoronto.ca>  wrote:
>>> Hello.
>>> 
>>> I'm getting a variance of 0 on a random effect and I don't know why.
>>> I suspect I've not set the model up correctly.  My transcript is below
>>> with my own comments sprinkled in for time to time.
>>> 
>>> A little bit about the data (which I will provide off-list if requested).
>>>  We have nurses managing an aspect of patient care
>>> according to different algorithms.  Interest focuses on of the
>>> algorithms result in different outcomes.  I have restricted this
>>> to only nurses who did each algorithm twice (in case my problem
>>> was being caused by some nurses doing only one algorithm, possibly
>>> only one time).
>>> 
>>> I figured that since I have multiple observations per nurse, I
>>> should treat nurse as a random effect, but maybe I confused myself
>>> again.
>>> 
>>> 
>>> R version 2.11.1 Patched (2010-07-21 r52598)
>>> Copyright (C) 2010 The R Foundation for Statistical Computing
>>> ISBN 3-900051-07-0
>>> 
>>> R is free software and comes with ABSOLUTELY NO WARRANTY.
>>> You are welcome to redistribute it under certain conditions.
>>> Type 'license()' or 'licence()' for distribution details.
>>> 
>>>  Natural language support but running in an English locale
>>> 
>>> R is a collaborative project with many contributors.
>>> Type 'contributors()' for more information and
>>> 'citation()' on how to cite R or R packages in publications.
>>> 
>>> Type 'demo()' for some demos, 'help()' for on-line help, or
>>> 'help.start()' for an HTML browser interface to help.
>>> Type 'q()' to quit R.
>>> 
>>>> library(lattice)
>>>> library(lme4)
>>> 
>>>> str(data1)
>>> 'data.frame':   72 obs. of  3 variables:
>>>  $ RN        : int  1 1 2 3 7 7 9 9 15 15 ...
>>>  $ Assignment: Factor w/ 2 levels "E","N": 1 1 1 1 1 1 1 1 1 1 ...
>>>  $ AUChr     : num  12.26 7.23 9.26 4.04 10.31 ...
>>>> tmp1<- with(data1,aggregate(AUChr,list(RN=RN,Assigment=Assignment),mean))
>>>> names(tmp1)[3]<- "Mean"
>>>> 
>>>> tmp2<- with(data1,aggregate(AUChr,list(RN=RN,Assignment=Assignment),var))
>>>> names(tmp2)[3]<- "Variance"
>>>> 
>>>> meanvar<- merge(tmp1,tmp2)
>>> 
>>> The point of this is to show that the means are not all the same,
>>> nor are the variances.
>>> 
>>>> meanvar
>>>   RN Assignment   Mean  Variance
>>> 1   1          E  9.745  12.65045
>>> 2   1          N  7.185   1.36125
>>> 3  15          E 10.605  15.07005
>>> 4  15          N 10.385   4.41045
>>> 5  16          E  8.175   0.00845
>>> 6  16          N  8.420   1.03680
>>> 7   2          E  7.300   7.68320
>>> 8   2          N  6.950   1.00820
>>> 9  21          E  9.670   9.41780
>>> 10 21          N 10.535   2.44205
>>> 11 22          E  7.720   2.04020
>>> 12 22          N  7.930   1.21680
>>> 13 24          E  9.555  10.35125
>>> 14 24          N  9.330   0.38720
>>> 15 25          E  8.240   0.92480
>>> 16 25          N  9.485   0.00125
>>> 17 27          E  8.635   0.08405
>>> 18 27          N  7.745   3.72645
>>> 19 28          E  9.635   8.61125
>>> 20 28          N  8.315  10.35125
>>> 21  3          E  6.005   7.72245
>>> 22  3          N 11.435  55.44045
>>> 23 31          E  9.590   9.94580
>>> 24 31          N 10.570  16.70420
>>> 25 35          E  9.055   0.32805
>>> 26 35          N  9.925  14.41845
>>> 27 36          E  9.040   2.08080
>>> 28 36          N  7.395   1.14005
>>> 29  5          E  8.430   3.38000
>>> 30  5          N 17.385 139.94645
>>> 31  6          E  6.930   0.24500
>>> 32  6          N  8.330   1.72980
>>> 33  7          E 10.650   0.23120
>>> 34  7          N  7.375   0.09245
>>> 35  9          E  8.885   7.56605
>>> 36  9          N  8.405   0.73205
>>> 
>>> Model with "Assignment" (algorithm).
>>> 
>>>> lmer(AUChr~Assignment+(1|RN),data=data1,REML=FALSE)
>>> Linear mixed model fit by maximum likelihood
>>> Formula: AUChr ~ Assignment + (1 | RN)
>>>   Data: data1
>>>   AIC   BIC logLik deviance REMLdev
>>>  365.7 374.8 -178.8    357.7   356.9
>>> Random effects:
>>>  Groups   Name        Variance Std.Dev.
>>>  RN       (Intercept) 0.0000   0.0000
>>>  Residual             8.4152   2.9009
>>> Number of obs: 72, groups: RN, 18
>>> 
>>> Fixed effects:
>>>            Estimate Std. Error t value
>>> (Intercept)   8.7703     0.4835   18.14
>>> AssignmentN   0.5131     0.6837    0.75
>>> 
>>> Correlation of Fixed Effects:
>>>            (Intr)
>>> AssignmentN -0.707
>>> 
>>> 
>>> Model without the algorithm variable.
>>> 
>>>> lmer(AUChr~(1|RN),data=data1,REML=FALSE)
>>> Linear mixed model fit by maximum likelihood
>>> Formula: AUChr ~ (1 | RN)
>>>   Data: data1
>>>   AIC   BIC logLik deviance REMLdev
>>>  364.3 371.1 -179.1    358.3   358.5
>>> Random effects:
>>>  Groups   Name        Variance Std.Dev.
>>>  RN       (Intercept) 0.000    0.0000
>>>  Residual             8.481    2.9122
>>> Number of obs: 72, groups: RN, 18
>>> 
>>> Fixed effects:
>>>            Estimate Std. Error t value
>>> (Intercept)   9.0268     0.3432    26.3
>>>> 
>>>> sessionInfo()
>>> R version 2.11.1 Patched (2010-07-21 r52598)
>>> Platform: i686-pc-linux-gnu (32-bit)
>>> 
>>> locale:
>>>  [1] LC_CTYPE=en_US       LC_NUMERIC=C         LC_TIME=en_US
>>>  [4] LC_COLLATE=C         LC_MONETARY=C        LC_MESSAGES=en_US
>>>  [7] LC_PAPER=en_US       LC_NAME=C            LC_ADDRESS=C
>>> [10] LC_TELEPHONE=C       LC_MEASUREMENT=en_US LC_IDENTIFICATION=C
>>> 
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>> 
>>> other attached packages:
>>> [1] lme4_0.999375-34   Matrix_0.999375-42 lattice_0.18-8
>>> 
>>> loaded via a namespace (and not attached):
>>> [1] grid_2.11.1   nlme_3.1-96   stats4_2.11.1
>>>> 
>>>> proc.time()
>>>   user  system elapsed
>>>  3.488   0.056   3.536
> 
> 
> -- 
> Kevin E. Thorpe
> Biostatistician/Trialist, Knowledge Translation Program
> Assistant Professor, Dalla Lana School of Public Health
> University of Toronto
> email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From john.maindonald at anu.edu.au  Thu Aug 12 01:55:33 2010
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Thu, 12 Aug 2010 09:55:33 +1000
Subject: [R-sig-ME] Why am I getting a Variance of 0 for my random effect
In-Reply-To: <17504_1281569527_4C6332F6_17504_61238_1_41167339-642E-4F8B-B634-10327A037F6D@anu.edu.au>
References: <4C62E842.5040403@utoronto.ca>
	<AANLkTikqfrYEO_Xvyr99BaNgfdKt9urw_5Nvds=dQRSF@mail.gmail.com>
	<4C62EADD.2000601@utoronto.ca>
	<17504_1281569527_4C6332F6_17504_61238_1_41167339-642E-4F8B-B634-10327A037F6D@anu.edu.au>
Message-ID: <77F1664A-45D8-471F-B904-9FF3C6CBBE4A@anu.edu.au>

Also, plot time 2 versus time 1, broken down by assignment.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 12/08/2010, at 9:29 AM, John Maindonald wrote:

> Surely you do want to treat nurses as a random effect, by analysing 
> summary data at the nurse level, if not in a multi-level model.
> 
> The zero variance may (if it really would prefer to be negative) be telling 
> you that there is a systematic difference between the two times, for which 
> your model needs to account.  Maybe there is a learning effect -- 2nd time 
> is systematically different from the first.  Did your model account for such 
> an effect?
> 
> Or (requires more thought to model), those who do badly the first time
> may learn rather more from their experience than those who did
> moderately well, doing better than average next time?  It appears that
> the data have the information needed to get insight on these questions.
> 
> The most insightful approach might well be separate regressions
> for 2-1 differences and 2+1 averages.  I'd do those analyses whatever 
> else you do.  
> 
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> http://www.maths.anu.edu.au/~johnm
> 
> On 12/08/2010, at 4:24 AM, Kevin E. Thorpe wrote:
> 
>> On 08/11/2010 02:16 PM, Daniel Ezra Johnson wrote:
>>> Try data1$RN<- as.factor(data1$RN).
>> 
>> Thanks, but that has no effect.  That is I get the same results.
>> 
>>> 
>>> On Wed, Aug 11, 2010 at 2:13 PM, Kevin E. Thorpe
>>> <kevin.thorpe at utoronto.ca>  wrote:
>>>> Hello.
>>>> 
>>>> I'm getting a variance of 0 on a random effect and I don't know why.
>>>> I suspect I've not set the model up correctly.  My transcript is below
>>>> with my own comments sprinkled in for time to time.
>>>> 
>>>> A little bit about the data (which I will provide off-list if requested).
>>>> We have nurses managing an aspect of patient care
>>>> according to different algorithms.  Interest focuses on of the
>>>> algorithms result in different outcomes.  I have restricted this
>>>> to only nurses who did each algorithm twice (in case my problem
>>>> was being caused by some nurses doing only one algorithm, possibly
>>>> only one time).
>>>> 
>>>> I figured that since I have multiple observations per nurse, I
>>>> should treat nurse as a random effect, but maybe I confused myself
>>>> again.
>>>> 
>>>> 
>>>> R version 2.11.1 Patched (2010-07-21 r52598)
>>>> Copyright (C) 2010 The R Foundation for Statistical Computing
>>>> ISBN 3-900051-07-0
>>>> 
>>>> R is free software and comes with ABSOLUTELY NO WARRANTY.
>>>> You are welcome to redistribute it under certain conditions.
>>>> Type 'license()' or 'licence()' for distribution details.
>>>> 
>>>> Natural language support but running in an English locale
>>>> 
>>>> R is a collaborative project with many contributors.
>>>> Type 'contributors()' for more information and
>>>> 'citation()' on how to cite R or R packages in publications.
>>>> 
>>>> Type 'demo()' for some demos, 'help()' for on-line help, or
>>>> 'help.start()' for an HTML browser interface to help.
>>>> Type 'q()' to quit R.
>>>> 
>>>>> library(lattice)
>>>>> library(lme4)
>>>> 
>>>>> str(data1)
>>>> 'data.frame':   72 obs. of  3 variables:
>>>> $ RN        : int  1 1 2 3 7 7 9 9 15 15 ...
>>>> $ Assignment: Factor w/ 2 levels "E","N": 1 1 1 1 1 1 1 1 1 1 ...
>>>> $ AUChr     : num  12.26 7.23 9.26 4.04 10.31 ...
>>>>> tmp1<- with(data1,aggregate(AUChr,list(RN=RN,Assigment=Assignment),mean))
>>>>> names(tmp1)[3]<- "Mean"
>>>>> 
>>>>> tmp2<- with(data1,aggregate(AUChr,list(RN=RN,Assignment=Assignment),var))
>>>>> names(tmp2)[3]<- "Variance"
>>>>> 
>>>>> meanvar<- merge(tmp1,tmp2)
>>>> 
>>>> The point of this is to show that the means are not all the same,
>>>> nor are the variances.
>>>> 
>>>>> meanvar
>>>>  RN Assignment   Mean  Variance
>>>> 1   1          E  9.745  12.65045
>>>> 2   1          N  7.185   1.36125
>>>> 3  15          E 10.605  15.07005
>>>> 4  15          N 10.385   4.41045
>>>> 5  16          E  8.175   0.00845
>>>> 6  16          N  8.420   1.03680
>>>> 7   2          E  7.300   7.68320
>>>> 8   2          N  6.950   1.00820
>>>> 9  21          E  9.670   9.41780
>>>> 10 21          N 10.535   2.44205
>>>> 11 22          E  7.720   2.04020
>>>> 12 22          N  7.930   1.21680
>>>> 13 24          E  9.555  10.35125
>>>> 14 24          N  9.330   0.38720
>>>> 15 25          E  8.240   0.92480
>>>> 16 25          N  9.485   0.00125
>>>> 17 27          E  8.635   0.08405
>>>> 18 27          N  7.745   3.72645
>>>> 19 28          E  9.635   8.61125
>>>> 20 28          N  8.315  10.35125
>>>> 21  3          E  6.005   7.72245
>>>> 22  3          N 11.435  55.44045
>>>> 23 31          E  9.590   9.94580
>>>> 24 31          N 10.570  16.70420
>>>> 25 35          E  9.055   0.32805
>>>> 26 35          N  9.925  14.41845
>>>> 27 36          E  9.040   2.08080
>>>> 28 36          N  7.395   1.14005
>>>> 29  5          E  8.430   3.38000
>>>> 30  5          N 17.385 139.94645
>>>> 31  6          E  6.930   0.24500
>>>> 32  6          N  8.330   1.72980
>>>> 33  7          E 10.650   0.23120
>>>> 34  7          N  7.375   0.09245
>>>> 35  9          E  8.885   7.56605
>>>> 36  9          N  8.405   0.73205
>>>> 
>>>> Model with "Assignment" (algorithm).
>>>> 
>>>>> lmer(AUChr~Assignment+(1|RN),data=data1,REML=FALSE)
>>>> Linear mixed model fit by maximum likelihood
>>>> Formula: AUChr ~ Assignment + (1 | RN)
>>>>  Data: data1
>>>>  AIC   BIC logLik deviance REMLdev
>>>> 365.7 374.8 -178.8    357.7   356.9
>>>> Random effects:
>>>> Groups   Name        Variance Std.Dev.
>>>> RN       (Intercept) 0.0000   0.0000
>>>> Residual             8.4152   2.9009
>>>> Number of obs: 72, groups: RN, 18
>>>> 
>>>> Fixed effects:
>>>>           Estimate Std. Error t value
>>>> (Intercept)   8.7703     0.4835   18.14
>>>> AssignmentN   0.5131     0.6837    0.75
>>>> 
>>>> Correlation of Fixed Effects:
>>>>           (Intr)
>>>> AssignmentN -0.707
>>>> 
>>>> 
>>>> Model without the algorithm variable.
>>>> 
>>>>> lmer(AUChr~(1|RN),data=data1,REML=FALSE)
>>>> Linear mixed model fit by maximum likelihood
>>>> Formula: AUChr ~ (1 | RN)
>>>>  Data: data1
>>>>  AIC   BIC logLik deviance REMLdev
>>>> 364.3 371.1 -179.1    358.3   358.5
>>>> Random effects:
>>>> Groups   Name        Variance Std.Dev.
>>>> RN       (Intercept) 0.000    0.0000
>>>> Residual             8.481    2.9122
>>>> Number of obs: 72, groups: RN, 18
>>>> 
>>>> Fixed effects:
>>>>           Estimate Std. Error t value
>>>> (Intercept)   9.0268     0.3432    26.3
>>>>> 
>>>>> sessionInfo()
>>>> R version 2.11.1 Patched (2010-07-21 r52598)
>>>> Platform: i686-pc-linux-gnu (32-bit)
>>>> 
>>>> locale:
>>>> [1] LC_CTYPE=en_US       LC_NUMERIC=C         LC_TIME=en_US
>>>> [4] LC_COLLATE=C         LC_MONETARY=C        LC_MESSAGES=en_US
>>>> [7] LC_PAPER=en_US       LC_NAME=C            LC_ADDRESS=C
>>>> [10] LC_TELEPHONE=C       LC_MEASUREMENT=en_US LC_IDENTIFICATION=C
>>>> 
>>>> attached base packages:
>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>> 
>>>> other attached packages:
>>>> [1] lme4_0.999375-34   Matrix_0.999375-42 lattice_0.18-8
>>>> 
>>>> loaded via a namespace (and not attached):
>>>> [1] grid_2.11.1   nlme_3.1-96   stats4_2.11.1
>>>>> 
>>>>> proc.time()
>>>>  user  system elapsed
>>>> 3.488   0.056   3.536
>> 
>> 
>> -- 
>> Kevin E. Thorpe
>> Biostatistician/Trialist, Knowledge Translation Program
>> Assistant Professor, Dalla Lana School of Public Health
>> University of Toronto
>> email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From arrayprofile at yahoo.com  Thu Aug 12 07:29:40 2010
From: arrayprofile at yahoo.com (array chip)
Date: Wed, 11 Aug 2010 22:29:40 -0700 (PDT)
Subject: [R-sig-ME] longitudinal with 2 time points
In-Reply-To: <B80EFDF8-B705-4EBA-A80E-9A4354F08353@anu.edu.au>
References: <439946.26259.qm@web56301.mail.re3.yahoo.com>
	<B80EFDF8-B705-4EBA-A80E-9A4354F08353@anu.edu.au>
Message-ID: <153555.93802.qm@web56306.mail.re3.yahoo.com>

Thank you John. I agree making baseline as a random factor is not a good idea. 

The data have treatment groups and age and gender for each subject. The purpose 
of the study is to investigate the treatment effect on the change of the study 
endpoint?(glucose level) between week 4?and baseline. I am thinking of several 
models/methods to analye the data:

1. mixed model with fixed time and random intercept:
lmer(y ~ treatment + gender + age + time + (1|subject)??? where time = 0 or 4

2. mixed model with random intercept and random slope
lmer(y ~ treatment + gender + age + time + (time|subject)

3. mixed?model with random intercept but no fixed time factor:
lmer(y ~ treatment + gender + age + (1|subject)

4. calculate delta.y = difference of y between week 4?& baseline
lm(delta.y ~ treatment + gender + age)

5. same as 4, but add baseline as a factor
lm(delta.y ~ baseline.y + treatment + gender + age)

My thinking on these 5 models are: model 1 and 2 have a limitation that they 
impose a linear relationship of y versus time, which may not be sensible with 2 
time points. Model 3 simply treats baseline and week?4 as repeated measures, not 
imposing linear relationship. Model 4 & 5 are based on the difference between 
baseline and week 4, except that model 5 adds baseline as a covariate. The 
reason of adding baseline as covariate is based on assumption that the extent of 
the change of y between week 4 and baseline depends on the?level of baseline.

Anyone has any suggestions on which one you would use?

Thanks!

John


----- Original Message ----
From: John Maindonald <john.maindonald at anu.edu.au>
To: array chip <arrayprofile at yahoo.com>
Cc: r-sig-mixed-models at r-project.org
Sent: Wed, August 11, 2010 12:04:01 AM
Subject: Re: [R-sig-ME] longitudinal with 2 time points

All these are possibilities, except maybe making baseline measurement
a random factor.? This would make sense only if data divide into groups,
and you want the baseline effect to vary randomly from group to group.? 
That may limit your ability to estimate parameters that are of interest.
In most circumstances that I am familiar with, it makes better sense to 
treat baseline effect as fixed.

John.

John Maindonald? ? ? ? ? ? email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473? ? fax? : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 11/08/2010, at 8:11 AM, array chip wrote:

> Hi, I am wondering if it is still meaningful to run a mixed model if a 
> longitudinal dataset has only 2 time points (baseline and week 4)? Would it be 

> more appropriate to simply take the difference between the 2 time points and 
>run 
>
> ANOVA (ANCOVA) on the difference? what about still running mixed model on the 
> difference of the 2 time points, but adding baseline measurement as a random 
> factor?
> 
> Thanks for sharing your thoughts.
> 
> John
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models






From arrayprofile at yahoo.com  Thu Aug 12 07:33:00 2010
From: arrayprofile at yahoo.com (array chip)
Date: Wed, 11 Aug 2010 22:33:00 -0700 (PDT)
Subject: [R-sig-ME] longitudinal with 2 time points
In-Reply-To: <alpine.WNT.2.00.1008110532370.640@TED2>
References: <439946.26259.qm@web56301.mail.re3.yahoo.com>
	<B80EFDF8-B705-4EBA-A80E-9A4354F08353@anu.edu.au>
	<alpine.WNT.2.00.1008110532370.640@TED2>
Message-ID: <393234.80656.qm@web56307.mail.re3.yahoo.com>

Thank you Ted for pointing this out. See my response to John's reply. What would 
you think of the model 5 where I used ANCOVA on the difference between week 5 & 
baseline and also included baseline as a covariate?

Thanks

John



----- Original Message ----
From: Charles E. (Ted) Wright <cewright at uci.edu>
To: John Maindonald <john.maindonald at anu.edu.au>
Cc: array chip <arrayprofile at yahoo.com>; r-sig-mixed-models at r-project.org
Sent: Wed, August 11, 2010 5:34:21 AM
Subject: Re: [R-sig-ME] longitudinal with 2 time points

Keep in mind that running an ANOVA on the difference is not the same thing 
as using the baseline data as a covariate in an ANOVA on the Week 4 data. 
Essentially the ANOVA on the differences is like the ANCOVA with the slope 
constrained to be 1.

Ted Wright

On Wed, 11 Aug 2010, John Maindonald wrote:

> All these are possibilities, except maybe making baseline measurement
> a random factor.? This would make sense only if data divide into groups,
> and you want the baseline effect to vary randomly from group to group.
> That may limit your ability to estimate parameters that are of interest.
> In most circumstances that I am familiar with, it makes better sense to
> treat baseline effect as fixed.
>
> John.
>
> John Maindonald? ? ? ? ? ? email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473? ? fax? : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> http://www.maths.anu.edu.au/~johnm
>
> On 11/08/2010, at 8:11 AM, array chip wrote:
>
>> Hi, I am wondering if it is still meaningful to run a mixed model if a
>> longitudinal dataset has only 2 time points (baseline and week 4)? Would it 
be
>> more appropriate to simply take the difference between the 2 time points and 
>>run
>> ANOVA (ANCOVA) on the difference? what about still running mixed model on the
>> difference of the 2 time points, but adding baseline measurement as a random
>> factor?
>>
>> Thanks for sharing your thoughts.
>>
>> John
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>







From arrayprofile at yahoo.com  Thu Aug 12 07:39:04 2010
From: arrayprofile at yahoo.com (array chip)
Date: Wed, 11 Aug 2010 22:39:04 -0700 (PDT)
Subject: [R-sig-ME] longitudinal with 2 time points
In-Reply-To: <8D383357-99BA-4447-A93B-0D8FC7AF7279@me.com>
References: <439946.26259.qm@web56301.mail.re3.yahoo.com>
	<B80EFDF8-B705-4EBA-A80E-9A4354F08353@anu.edu.au>
	<alpine.WNT.2.00.1008110532370.640@TED2>
	<8D383357-99BA-4447-A93B-0D8FC7AF7279@me.com>
Message-ID: <323634.22474.qm@web56305.mail.re3.yahoo.com>

Hi Marc,

Thanks for the reference. I will definitely read it. Please see my reponse to 
John's reply. Your model is another model I should add to the 5 models I 
proposed in that email. What's your overall thoughts on these different models?

Thank you for sharing.

John



----- Original Message ----
From: Marc Schwartz <marc_schwartz at me.com>
To: Charles E. (Ted) Wright <cewright at uci.edu>; array chip 
<arrayprofile at yahoo.com>
Cc: John Maindonald <john.maindonald at anu.edu.au>; 
r-sig-mixed-models at r-project.org
Sent: Wed, August 11, 2010 6:20:13 AM
Subject: Re: [R-sig-ME] longitudinal with 2 time points

Hi,

I'll throw in a reference that covers some of these issues:

Statistics Notes
Analysing controlled trials with baseline and follow up measurements
Vickers and Altman
BMJ. 2001 November 10; 323(7321): 1123?1124.
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1121605/


The basic model specification would of course be:

? lm(4Wks ~ Baseline + Group)

You will also want to test for an interaction between the baseline score and 
your grouping factor, in case the observed group (eg. treatment) effect is 
dependent upon the value of the baseline measurement. In this case, unlike in 
the above paper, you of course end up with crossing fitted regression lines, 
rather than parallel lines.

HTH,

Marc Schwartz


On Aug 11, 2010, at 7:34 AM, Charles E. (Ted) Wright wrote:

> Keep in mind that running an ANOVA on the difference is not the same thing as 
>using the baseline data as a covariate in an ANOVA on the Week 4 data. 
>Essentially the ANOVA on the differences is like the ANCOVA with the slope 
>constrained to be 1.
> 
> Ted Wright
> 
> On Wed, 11 Aug 2010, John Maindonald wrote:
> 
>> All these are possibilities, except maybe making baseline measurement
>> a random factor.? This would make sense only if data divide into groups,
>> and you want the baseline effect to vary randomly from group to group.
>> That may limit your ability to estimate parameters that are of interest.
>> In most circumstances that I am familiar with, it makes better sense to
>> treat baseline effect as fixed.
>> 
>> John.
>> 
>> On 11/08/2010, at 8:11 AM, array chip wrote:
>> 
>>> Hi, I am wondering if it is still meaningful to run a mixed model if a
>>> longitudinal dataset has only 2 time points (baseline and week 4)? Would it 
>be
>>> more appropriate to simply take the difference between the 2 time points and 
>>>run
>>> ANOVA (ANCOVA) on the difference? what about still running mixed model on 
the
>>> difference of the 2 time points, but adding baseline measurement as a random
>>> factor?
>>> 
>>> Thanks for sharing your thoughts.
>>> 
>>> John






From paul.metzner at gmail.com  Thu Aug 12 10:44:09 2010
From: paul.metzner at gmail.com (Paul Metzner)
Date: Thu, 12 Aug 2010 10:44:09 +0200
Subject: [R-sig-ME] Contrasts for interactions in lmer
Message-ID: <E76415FE-31A0-464F-8B83-84D78C636CAE@gmail.com>

Dear all.

I am currently analyzing eye-tracking data and am interested in a main effect of condition (COND) plus its interaction with subjects' operation span (PCU) and the direction of a verb bias (1 or 2). The contrasts are:

> contrasts(COND)
>  [,1]
> a   -1
> b    1

and

> contrasts(DIR)
>  [,1]
> 1   -1
> 2    1

PCU is a continuous predictor which I centered by subtracting the mean (the problem does, however, persist when I split the sample into extreme groups and work with a categorial predictor). With the following model, I don't get a correlation between the fixed effects:

> Linear mixed model fit by REML 
> Formula: RRT ~ COND * PCU * DIR + (1 | SUBJECT) + (1 | ITEM) 
>    Data: fm3 
>    AIC   BIC logLik deviance REMLdev
>  46733 46801 -23355    46768   46711
> Random effects:
>  Groups   Name        Variance Std.Dev.
>  SUBJECT  (Intercept)  8918.29  94.437 
>  ITEM     (Intercept)   404.85  20.121 
>  Residual             34881.69 186.766 
> Number of obs: 3503, groups: SUBJECT, 59; ITEM, 59
> 
> Fixed effects:
>                Estimate Std. Error t value
> (Intercept)     122.900     12.963   9.481
> COND1            15.924      3.165   5.031
> PCU             139.411    120.025   1.162
> DIR1             -7.746      4.107  -1.886
> COND1:PCU        48.309     29.850   1.618
> COND1:DIR1       -3.396      3.164  -1.073
> PCU:DIR1        -26.835     29.814  -0.900
> COND1:PCU:DIR1   -8.069     29.838  -0.270
> 
> Correlation of Fixed Effects:
>             (Intr) COND1  PCU    DIR1   COND1:PCU COND1:D PCU:DI
> COND1        0.002                                              
> PCU          0.004 -0.001                                       
> DIR1         0.002 -0.004  0.004                                
> COND1:PCU   -0.001 -0.001  0.003  0.000                         
> COND1:DIR1  -0.001  0.000  0.000  0.007  0.021                  
> PCU:DIR1     0.005  0.000 -0.003  0.000 -0.009    -0.005        
> COND1:PCU:D  0.000  0.021 -0.002 -0.004 -0.009    -0.001   0.011

But, since I'm mainly interested in the interactions and not so much the main effects of PCU and DIR, I changed the model to the following:

> Linear mixed model fit by REML 
> Formula: RRT ~ COND + COND:PCU + COND:DIR + (1 | SUBJECT) + (1 | ITEM) 
>    Data: fm3 
>    AIC   BIC logLik deviance REMLdev
>  46744 46800 -23363    46769   46726
> Random effects:
>  Groups   Name        Variance Std.Dev.
>  SUBJECT  (Intercept)  8911.15  94.399 
>  ITEM     (Intercept)   406.16  20.153 
>  Residual             34869.91 186.735 
> Number of obs: 3503, groups: SUBJECT, 59; ITEM, 59
> 
> Fixed effects:
>             Estimate Std. Error t value
> (Intercept)  122.962     12.959   9.489
> COND1         15.941      3.164   5.039
> CONDa:PCU     91.049    123.553   0.737
> CONDb:PCU    187.055    123.714   1.512
> CONDa:DIR1    -4.340      5.168  -0.840
> CONDb:DIR1   -11.160      5.204  -2.144
> 
> Correlation of Fixed Effects:
>            (Intr) COND1  CONDa:PCU CONDb:PCU CONDa:DIR1
> COND1       0.002                                      
> CONDa:PCU   0.004 -0.001                               
> CONDb:PCU   0.004 -0.001  0.883                        
> CONDa:DIR1  0.002 -0.003  0.006     0.000              
> CONDb:DIR1  0.001 -0.003  0.000     0.006     0.256    

Not I do get a considerable correlation between the interactions. From the output (CONDa:?, CONDb:?), I infer that the model didn't always use helmert coding for condition but applied something else for the interactions. Is that right? When I code COND numerically as -1 and 1, the correlations turn out fine, which supports my conclusion. I would be very grateful for suggestions.

Thanks,
Paul

---
Paul Metzner

Humboldt-Universit?t zu Berlin
Philosophische Fakult?t II
Institut f?r deutsche Sprache und Linguistik

Post: Unter den Linden 6 | 10099 Berlin | Deutschland
Besuch: Dorotheenstra?e 24 | 10117 Berlin | Deutschland

+49-(0)30-2093-9726
paul.metzner at gmail.com
http://amor.rz.hu-berlin.de/~metznerp/



From j.hadfield at ed.ac.uk  Thu Aug 12 10:49:11 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 12 Aug 2010 09:49:11 +0100
Subject: [R-sig-ME] longitudinal with 2 time points
In-Reply-To: <393234.80656.qm@web56307.mail.re3.yahoo.com>
References: <439946.26259.qm@web56301.mail.re3.yahoo.com>
	<B80EFDF8-B705-4EBA-A80E-9A4354F08353@anu.edu.au>
	<alpine.WNT.2.00.1008110532370.640@TED2>
	<393234.80656.qm@web56307.mail.re3.yahoo.com>
Message-ID: <513B6C4A-5CE2-4487-9172-0FAB5C844636@ed.ac.uk>

Hi John,

If there are only two time points per subject I think model 2 should  
throw an error because the residual variance and (time|Subject)  
(co)variances cannot be uniquely estimated. You can get around this  
problem  by moving the (time|Subject) term into the residual term and  
dropping it from the random terms using MCMCglmm or ASReml:

MCMCglmm(y ~ treatment + gender + age + time, rcov=~  
us(as.factor(time)):subject,  ...

This route was also suggested by Ben Bolker and John Maindonald for  
coping with negative variances.


However, when I try:

set.seed(1)
subject<-gl(50,2)
time<-gl(2,1,100)
y<-rnorm(100)
summary(lmer(y~time+(time|subject)))

I get estimates of all terms and so may be they can be uniquely  
estimated (although it would surprise me a lot)?

Jarrod





On 12 Aug 2010, at 06:33, array chip wrote:

> Thank you Ted for pointing this out. See my response to John's  
> reply. What would
> you think of the model 5 where I used ANCOVA on the difference  
> between week 5 &
> baseline and also included baseline as a covariate?
>
> Thanks
>
> John
>
>
>
> ----- Original Message ----
> From: Charles E. (Ted) Wright <cewright at uci.edu>
> To: John Maindonald <john.maindonald at anu.edu.au>
> Cc: array chip <arrayprofile at yahoo.com>; r-sig-mixed-models at r-project.org
> Sent: Wed, August 11, 2010 5:34:21 AM
> Subject: Re: [R-sig-ME] longitudinal with 2 time points
>
> Keep in mind that running an ANOVA on the difference is not the same  
> thing
> as using the baseline data as a covariate in an ANOVA on the Week 4  
> data.
> Essentially the ANOVA on the differences is like the ANCOVA with the  
> slope
> constrained to be 1.
>
> Ted Wright
>
> On Wed, 11 Aug 2010, John Maindonald wrote:
>
>> All these are possibilities, except maybe making baseline measurement
>> a random factor.  This would make sense only if data divide into  
>> groups,
>> and you want the baseline effect to vary randomly from group to  
>> group.
>> That may limit your ability to estimate parameters that are of  
>> interest.
>> In most circumstances that I am familiar with, it makes better  
>> sense to
>> treat baseline effect as fixed.
>>
>> John.
>>
>> John Maindonald            email: john.maindonald at anu.edu.au
>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>> Centre for Mathematics & Its Applications, Room 1194,
>> John Dedman Mathematical Sciences Building (Building 27)
>> Australian National University, Canberra ACT 0200.
>> http://www.maths.anu.edu.au/~johnm
>>
>> On 11/08/2010, at 8:11 AM, array chip wrote:
>>
>>> Hi, I am wondering if it is still meaningful to run a mixed model  
>>> if a
>>> longitudinal dataset has only 2 time points (baseline and week 4)?  
>>> Would it
> be
>>> more appropriate to simply take the difference between the 2 time  
>>> points and
>>> run
>>> ANOVA (ANCOVA) on the difference? what about still running mixed  
>>> model on the
>>> difference of the 2 time points, but adding baseline measurement  
>>> as a random
>>> factor?
>>>
>>> Thanks for sharing your thoughts.
>>>
>>> John
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
>
>
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From j.hadfield at ed.ac.uk  Thu Aug 12 10:59:57 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 12 Aug 2010 09:59:57 +0100
Subject: [R-sig-ME] D relationship matrix
In-Reply-To: <506E385513570F4FA5E3F84C96486802034E1912@UQEXMB3.soe.uq.edu.au>
References: <506E385513570F4FA5E3F84C96486802034E1911@UQEXMB3.soe.uq.edu.au>
	<6FF569AD-56D0-40D6-AE07-BF3BBD4D33A1@ed.ac.uk>
	<506E385513570F4FA5E3F84C96486802034E1912@UQEXMB3.soe.uq.edu.au>
Message-ID: <F07D8167-D0C1-4B3B-9A43-F0D97C7282CF@ed.ac.uk>

Hi Craig,


I'm not aware of anything in R but I believe Ignacy Misztal's fotran  
routines http://nce.ads.uga.edu/~ignacy/newprograms.html or Per Madsen  
and Just Jensen's DMU package http://www.dmu.agrsci.dk/ will calculate  
D and presumably D-1. Hoeschele & van Raden (J. Dairy Science  
74:557-569) provide a recursive algorithm for D-1 in the absence of  
inbreeding and this may not be that hard to implement.

Cheers,

Jarrod
On 12 Aug 2010, at 00:35, Craig Hardner wrote:

> sorry yes
>
> Craig
>
> From: Jarrod Hadfield [mailto:j.hadfield at ed.ac.uk]
> Sent: Thu 12/08/2010 1:37 AM
> To: Craig Hardner
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] D relationship matrix
>
> Hi,
>
> Is D for dominance?
>
> Cheers,
>
> Jarrod
>
>
> On 11 Aug 2010, at 13:27, Craig Hardner wrote:
>
> > Hi Folks
> >
> >
> > just wonderinf if any one has some code to write the D realtionship
> > matrix (or inverse) for an outbreed population with no inbreeding
> > that I could use?
> >
> > Thanks for your help
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100812/3651a0d0/attachment.pl>

From reinhold.kliegl at gmail.com  Thu Aug 12 11:24:58 2010
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Thu, 12 Aug 2010 11:24:58 +0200
Subject: [R-sig-ME] Contrasts for interactions in lmer
In-Reply-To: <E76415FE-31A0-464F-8B83-84D78C636CAE@gmail.com>
References: <E76415FE-31A0-464F-8B83-84D78C636CAE@gmail.com>
Message-ID: <AANLkTikjX5L3t0SJOJSoghEBYRYSB2rF1qRVfYLVzjZ0@mail.gmail.com>

There is a bit of evidence for an interaction of COND and PCU:
>> COND1:PCU ? ? ? ?48.309 ? ? 29.850 ? 1.618
If the t-value were larger it would indicate that slopes for the
regression of RRT on PCU differ between the two condition.

There is no statistical support for the the interaction of DIR and PCU
>> PCU:DIR1 ? ? ? ?-26.835 ? ? 29.814 ?-0.900

Now to some of your questions relating to correlations:
(1) The Fixed Effects correlations are probably not what you are
after. For example, in a perfectly balanced design, these correlations
will be zero.

(2) I suspect what you might be after are effect correlations related
to subjects or items. Assuming cond and verb bias are within-subject
effects, you could get an estimate of the parameter for the covariance
component with the following specification.
RRT ~ COND * PCU * DIR + (1 + COND + DIR  | SUBJECT) + (1 | ITEM)

You should check whether adding these variance components to the model
improves the goodness fo fit, for example with an ANOVA..

(3) You used a sum contrast specification for the two factors (COND
and DIR). This is fine. For two-level factors there is no point in
specifying Helmert contrasts. So it is unclear what you referring to
in this context.

Finally, it is generally a bad idea to specify models with
interactions terms leaving out the factors contributing to the
interactions. If you do so, you need to have very good theoretical
reasons.

Reinhold Kliegl


On Thu, Aug 12, 2010 at 10:44 AM, Paul Metzner <paul.metzner at gmail.com> wrote:
> Dear all.
>
> I am currently analyzing eye-tracking data and am interested in a main effect of condition (COND) plus its interaction with subjects' operation span (PCU) and the direction of a verb bias (1 or 2). The contrasts are:
>
>> contrasts(COND)
>> ?[,1]
>> a ? -1
>> b ? ?1
>
> and
>
>> contrasts(DIR)
>> ?[,1]
>> 1 ? -1
>> 2 ? ?1
>
> PCU is a continuous predictor which I centered by subtracting the mean (the problem does, however, persist when I split the sample into extreme groups and work with a categorial predictor). With the following model, I don't get a correlation between the fixed effects:
>
>> Linear mixed model fit by REML
>> Formula: RRT ~ COND * PCU * DIR + (1 | SUBJECT) + (1 | ITEM)
>> ? ?Data: fm3
>> ? ?AIC ? BIC logLik deviance REMLdev
>> ?46733 46801 -23355 ? ?46768 ? 46711
>> Random effects:
>> ?Groups ? Name ? ? ? ?Variance Std.Dev.
>> ?SUBJECT ?(Intercept) ?8918.29 ?94.437
>> ?ITEM ? ? (Intercept) ? 404.85 ?20.121
>> ?Residual ? ? ? ? ? ? 34881.69 186.766
>> Number of obs: 3503, groups: SUBJECT, 59; ITEM, 59
>>
>> Fixed effects:
>> ? ? ? ? ? ? ? ?Estimate Std. Error t value
>> (Intercept) ? ? 122.900 ? ? 12.963 ? 9.481
>> COND1 ? ? ? ? ? ?15.924 ? ? ?3.165 ? 5.031
>> PCU ? ? ? ? ? ? 139.411 ? ?120.025 ? 1.162
>> DIR1 ? ? ? ? ? ? -7.746 ? ? ?4.107 ?-1.886
>> COND1:PCU ? ? ? ?48.309 ? ? 29.850 ? 1.618
>> COND1:DIR1 ? ? ? -3.396 ? ? ?3.164 ?-1.073
>> PCU:DIR1 ? ? ? ?-26.835 ? ? 29.814 ?-0.900
>> COND1:PCU:DIR1 ? -8.069 ? ? 29.838 ?-0.270
>>
>> Correlation of Fixed Effects:
>> ? ? ? ? ? ? (Intr) COND1 ?PCU ? ?DIR1 ? COND1:PCU COND1:D PCU:DI
>> COND1 ? ? ? ?0.002
>> PCU ? ? ? ? ?0.004 -0.001
>> DIR1 ? ? ? ? 0.002 -0.004 ?0.004
>> COND1:PCU ? -0.001 -0.001 ?0.003 ?0.000
>> COND1:DIR1 ?-0.001 ?0.000 ?0.000 ?0.007 ?0.021
>> PCU:DIR1 ? ? 0.005 ?0.000 -0.003 ?0.000 -0.009 ? ?-0.005
>> COND1:PCU:D ?0.000 ?0.021 -0.002 -0.004 -0.009 ? ?-0.001 ? 0.011
>
> But, since I'm mainly interested in the interactions and not so much the main effects of PCU and DIR, I changed the model to the following:
>
>> Linear mixed model fit by REML
>> Formula: RRT ~ COND + COND:PCU + COND:DIR + (1 | SUBJECT) + (1 | ITEM)
>> ? ?Data: fm3
>> ? ?AIC ? BIC logLik deviance REMLdev
>> ?46744 46800 -23363 ? ?46769 ? 46726
>> Random effects:
>> ?Groups ? Name ? ? ? ?Variance Std.Dev.
>> ?SUBJECT ?(Intercept) ?8911.15 ?94.399
>> ?ITEM ? ? (Intercept) ? 406.16 ?20.153
>> ?Residual ? ? ? ? ? ? 34869.91 186.735
>> Number of obs: 3503, groups: SUBJECT, 59; ITEM, 59
>>
>> Fixed effects:
>> ? ? ? ? ? ? Estimate Std. Error t value
>> (Intercept) ?122.962 ? ? 12.959 ? 9.489
>> COND1 ? ? ? ? 15.941 ? ? ?3.164 ? 5.039
>> CONDa:PCU ? ? 91.049 ? ?123.553 ? 0.737
>> CONDb:PCU ? ?187.055 ? ?123.714 ? 1.512
>> CONDa:DIR1 ? ?-4.340 ? ? ?5.168 ?-0.840
>> CONDb:DIR1 ? -11.160 ? ? ?5.204 ?-2.144
>>
>> Correlation of Fixed Effects:
>> ? ? ? ? ? ?(Intr) COND1 ?CONDa:PCU CONDb:PCU CONDa:DIR1
>> COND1 ? ? ? 0.002
>> CONDa:PCU ? 0.004 -0.001
>> CONDb:PCU ? 0.004 -0.001 ?0.883
>> CONDa:DIR1 ?0.002 -0.003 ?0.006 ? ? 0.000
>> CONDb:DIR1 ?0.001 -0.003 ?0.000 ? ? 0.006 ? ? 0.256
>
> Not I do get a considerable correlation between the interactions. From the output (CONDa:?, CONDb:?), I infer that the model didn't always use helmert coding for condition but applied something else for the interactions. Is that right? When I code COND numerically as -1 and 1, the correlations turn out fine, which supports my conclusion. I would be very grateful for suggestions.
>
> Thanks,
> Paul
>
> ---
> Paul Metzner
>
> Humboldt-Universit?t zu Berlin
> Philosophische Fakult?t II
> Institut f?r deutsche Sprache und Linguistik
>
> Post: Unter den Linden 6 | 10099 Berlin | Deutschland
> Besuch: Dorotheenstra?e 24 | 10117 Berlin | Deutschland
>
> +49-(0)30-2093-9726
> paul.metzner at gmail.com
> http://amor.rz.hu-berlin.de/~metznerp/
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From c.hardner at uq.edu.au  Thu Aug 12 01:35:57 2010
From: c.hardner at uq.edu.au (Craig Hardner)
Date: Thu, 12 Aug 2010 09:35:57 +1000
Subject: [R-sig-ME] D relationship matrix
References: <506E385513570F4FA5E3F84C96486802034E1911@UQEXMB3.soe.uq.edu.au>
	<6FF569AD-56D0-40D6-AE07-BF3BBD4D33A1@ed.ac.uk>
Message-ID: <506E385513570F4FA5E3F84C96486802034E1912@UQEXMB3.soe.uq.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100812/cfa85c54/attachment.pl>

From marc_schwartz at me.com  Thu Aug 12 15:02:29 2010
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 12 Aug 2010 08:02:29 -0500
Subject: [R-sig-ME] longitudinal with 2 time points
In-Reply-To: <323634.22474.qm@web56305.mail.re3.yahoo.com>
References: <439946.26259.qm@web56301.mail.re3.yahoo.com>
	<B80EFDF8-B705-4EBA-A80E-9A4354F08353@anu.edu.au>
	<alpine.WNT.2.00.1008110532370.640@TED2>
	<8D383357-99BA-4447-A93B-0D8FC7AF7279@me.com>
	<323634.22474.qm@web56305.mail.re3.yahoo.com>
Message-ID: <FB025028-0C67-4B59-9757-FC2305C07EA6@me.com>

Hi John,

If you read that article, you will see that your use of delta.y as the dependent variable does not make sense.

Thus, I would re-express your model 5 as:

  lm(wk4.glucose ~ baseline.glucose + treatment + gender + age)

and as noted, check for the interaction between baseline glucose and treatment:

  lm(wk4.glucose ~ baseline.glucose * treatment + gender + age)


You might also want to consider using a spline function on age, presuming that age is hopefully measured as a continuous variable (eg. not ordinal groups).

Since the ANCOVA based approach described in the paper is essentially an OLS linear regression, you can of course include the additional covariates for adjustment. If the interaction term p value is >0.1 (a common threshold), you can remove it and the beta coefficient and its CIs for the treatment factor is your estimated treatment effect relative to your control.

For the presentation of the results, besides the obvious tabular summaries and the scatter/regression lines plot, include a series of plots showing selected baseline values and the treatment versus control predicted follow up values and CIs for the same baseline value in each plot. This visually shows the common estimated treatment effect for each baseline value, which will also tend to reveal regression to the mean. This presentation is especially helpful if the interaction term is retained, which therefore shows how the treatment effect varies and will reverse, over the range of the baseline values. You can select a series of clinically relevant values over the range of the observed baseline values, and/or by default, select a five number plus mean series over the observed baseline values.

I don't see a role for a mixed effects model here, given that this is a pretty straightforward "change from baseline" type design, but there are many here with greater expertise than I. If this was a cross-over design, you have multiple measures of glucose for each patient at each time point, more than two time points, or a multi-center study, then a mixed effects model would make more sense to me.

HTH,

Marc



On Aug 12, 2010, at 12:39 AM, array chip wrote:

> Hi Marc,
> 
> Thanks for the reference. I will definitely read it. Please see my reponse to 
> John's reply. Your model is another model I should add to the 5 models I 
> proposed in that email. What's your overall thoughts on these different models?
> 
> Thank you for sharing.
> 
> John
> 
> 
> 
> ----- Original Message ----
> From: Marc Schwartz <marc_schwartz at me.com>
> To: Charles E. (Ted) Wright <cewright at uci.edu>; array chip 
> <arrayprofile at yahoo.com>
> Cc: John Maindonald <john.maindonald at anu.edu.au>; 
> r-sig-mixed-models at r-project.org
> Sent: Wed, August 11, 2010 6:20:13 AM
> Subject: Re: [R-sig-ME] longitudinal with 2 time points
> 
> Hi,
> 
> I'll throw in a reference that covers some of these issues:
> 
> Statistics Notes
> Analysing controlled trials with baseline and follow up measurements
> Vickers and Altman
> BMJ. 2001 November 10; 323(7321): 1123?1124.
> https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1121605/
> 
> 
> The basic model specification would of course be:
> 
>   lm(4Wks ~ Baseline + Group)
> 
> You will also want to test for an interaction between the baseline score and 
> your grouping factor, in case the observed group (eg. treatment) effect is 
> dependent upon the value of the baseline measurement. In this case, unlike in 
> the above paper, you of course end up with crossing fitted regression lines, 
> rather than parallel lines.
> 
> HTH,
> 
> Marc Schwartz
> 
> 
> On Aug 11, 2010, at 7:34 AM, Charles E. (Ted) Wright wrote:
> 
>> Keep in mind that running an ANOVA on the difference is not the same thing as 
>> using the baseline data as a covariate in an ANOVA on the Week 4 data. 
>> Essentially the ANOVA on the differences is like the ANCOVA with the slope 
>> constrained to be 1.
>> 
>> Ted Wright
>> 
>> On Wed, 11 Aug 2010, John Maindonald wrote:
>> 
>>> All these are possibilities, except maybe making baseline measurement
>>> a random factor.  This would make sense only if data divide into groups,
>>> and you want the baseline effect to vary randomly from group to group.
>>> That may limit your ability to estimate parameters that are of interest.
>>> In most circumstances that I am familiar with, it makes better sense to
>>> treat baseline effect as fixed.
>>> 
>>> John.
>>> 
>>> On 11/08/2010, at 8:11 AM, array chip wrote:
>>> 
>>>> Hi, I am wondering if it is still meaningful to run a mixed model if a
>>>> longitudinal dataset has only 2 time points (baseline and week 4)? Would it 
>> be
>>>> more appropriate to simply take the difference between the 2 time points and 
>>>> run
>>>> ANOVA (ANCOVA) on the difference? what about still running mixed model on 
> the
>>>> difference of the 2 time points, but adding baseline measurement as a random
>>>> factor?
>>>> 
>>>> Thanks for sharing your thoughts.
>>>> 
>>>> John
> 
> 
> 
> 



From spluque at gmail.com  Thu Aug 12 17:42:45 2010
From: spluque at gmail.com (Sebastian P. Luque)
Date: Thu, 12 Aug 2010 10:42:45 -0500
Subject: [R-sig-ME] examples in Applied Longitudinal Analysis
Message-ID: <87sk2jrg5m.fsf@kolob.sebmags.homelinux.org>

Hi,

Now that I'm reading Fitzmaurice et al's book, I recall having seen
their examples using lme4 but cannot trace back what URL this was on.
If someone knows where this is now, I'd appreciate the pointer.  Thanks.

-- 
Seb



From Mike.Lawrence at dal.ca  Thu Aug 12 23:11:23 2010
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Thu, 12 Aug 2010 18:11:23 -0300
Subject: [R-sig-ME] Testing differences in measurement variance
Message-ID: <AANLkTimh-hDS3B+_L-O=QjOCuMdL60yg6hnd_Vd_yfjC@mail.gmail.com>

Hi folks,

Can mixed effects modelling be used to compare the variability of
measurement between treatments? That is, in the conventional ANOVA
world, if I were interested in studying the effect of a treatment
(within or between groups) on the variability of measurement, I would
(1) measure multiple individuals each multiple times, obtain an SD of
measurement per individual, then (2) submit these SD scores as a
dependent variable to an ANOVA. I wonder if this traditional two-stage
process could be replaced with a single mixed effects analysis, which
presumably would permit increased power through things like shrinkage,
accounting for measurement confidence (by taking into account
different numbers of observations within each individual), etc.

If this is possible, how would I structure the lmer() call to achieve
such estimation and comparison of measurement variance?

Mike

-- 
Mike Lawrence
Graduate Student
Department of Psychology
Dalhousie University

Looking to arrange a meeting? Check my public calendar:
http://tr.im/mikes_public_calendar

~ Certainty is folly... I think. ~



From bbolker at gmail.com  Thu Aug 12 23:48:10 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 12 Aug 2010 17:48:10 -0400
Subject: [R-sig-ME] Testing differences in measurement variance
In-Reply-To: <AANLkTimLQt0BPjZ27K-AR1+U-6uUJN603o7rSbBenuNU@mail.gmail.com>
References: <AANLkTimh-hDS3B+_L-O=QjOCuMdL60yg6hnd_Vd_yfjC@mail.gmail.com>
	<4C646471.4040309@gmail.com>
	<AANLkTimLQt0BPjZ27K-AR1+U-6uUJN603o7rSbBenuNU@mail.gmail.com>
Message-ID: <4C646C1A.8000705@gmail.com>


    I wrote fast and was a little bit confused (and hence confusing).  
When you said "variability of measurement" I read it as "measurement 
variability", so I was assuming a model like

Var(group i) = Var(process error) + Var(measurement error, group i)

    I may have the details/syntax wrong, you'll have to check it (of 
course).

     Ben

On 10-08-12 05:44 PM, Mike Lawrence wrote:
> Thanks for the reply, but I'm a little confused; if I'm interested in
> estimating and comparing variances, how is it useful to "assume that
> the underlying variability is the same"?
>
> Mike
>
> On Thu, Aug 12, 2010 at 6:15 PM, Ben Bolker<bbolker at gmail.com>  wrote:
>    
>> On 10-08-12 05:11 PM, Mike Lawrence wrote:
>>      
>>> Hi folks,
>>>
>>> Can mixed effects modelling be used to compare the variability of
>>> measurement between treatments? That is, in the conventional ANOVA
>>> world, if I were interested in studying the effect of a treatment
>>> (within or between groups) on the variability of measurement, I would
>>> (1) measure multiple individuals each multiple times, obtain an SD of
>>> measurement per individual, then (2) submit these SD scores as a
>>> dependent variable to an ANOVA. I wonder if this traditional two-stage
>>> process could be replaced with a single mixed effects analysis, which
>>> presumably would permit increased power through things like shrinkage,
>>> accounting for measurement confidence (by taking into account
>>> different numbers of observations within each individual), etc.
>>>
>>> If this is possible, how would I structure the lmer() call to achieve
>>> such estimation and comparison of measurement variance?
>>>
>>> Mike
>>>
>>>
>>>        
>> If you're willing to assume that the underlying variability is the same, I
>> think you can do this in lme() [not lmer()] by specifying
>> weights=varIdent(~ttt)
>>
>>
>>      
>
>
>



From Mike.Lawrence at dal.ca  Fri Aug 13 00:23:57 2010
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Thu, 12 Aug 2010 19:23:57 -0300
Subject: [R-sig-ME] Testing differences in measurement variance
In-Reply-To: <4C646C1A.8000705@gmail.com>
References: <AANLkTimh-hDS3B+_L-O=QjOCuMdL60yg6hnd_Vd_yfjC@mail.gmail.com>
	<4C646471.4040309@gmail.com>
	<AANLkTimLQt0BPjZ27K-AR1+U-6uUJN603o7rSbBenuNU@mail.gmail.com>
	<4C646C1A.8000705@gmail.com>
Message-ID: <AANLkTinf6F4QkoYs2uz5yqAZWyPVjLwy7SkFKhFGw7av@mail.gmail.com>

On Thu, Aug 12, 2010 at 6:48 PM, Ben Bolker <bbolker at gmail.com> wrote:
> Var(group i) = Var(process error) + Var(measurement error, group i)


Ah, yes, I think the assumption of equal "measurement error" across
groups but unequal "process error" is appropriate for the question I
raised. To be as clear as possible, I've included below an example of
the type of data I'd anticipate encountering. There are two groups of
individuals, both groups have the same measurement error but have
their own unique process error added onto this measurement error.
Individuals within each group will of course not manifest precisely
the group's base variability but vary from the base variability by
some random amount.

set.seed(1)

measurement_error = 1
group_A_base_sd = measurement_error + 1
group_B_base_sd = measurement_error + 2
within_group_sd_of_sds = .1

n_per_group = 10
obs_per_id = 20

temp = data.frame(
	id = 1:(n_per_group*2)
	, group = rep(c('A','B'))
)

#generate example data
library(plyr) #to avoid loops (for coding convenience only)
obs_data = ddply(
	.data = temp
	, .variables = .(id,group)
	, .fun = function(x){
		#generate a unique sd for this individual
		# based on their group's sd plus some
		# within-group variability
		id_sd = ifelse(
			x$group=='A'
			, rnorm(
				1
				, group_A_base_sd
				, within_group_sd_of_sds
			)
			, rnorm(
				1
				, group_B_base_sd
				, within_group_sd_of_sds
			)
		)
		#generate data points with the above generated
		# variability
		to_return = data.frame(
			obs_num = 1:obs_per_id
			, measurement = rnorm(obs_per_id,0,id_sd)
		)
		return(to_return)
	}
)

#first step of an anova-based approach:
# compute SDs within each Ss
obs_sds = ddply(
	.data = obs_data
	, .variables = .(id,group)
	, .fun = function(x){
		to_return = data.frame(
			obs_sd = sd(x$measurement)
		)
	}
)

#second step of an anova-based approach:
# compute the anova on the SDs
summary(
	aov(
		formula = obs_sd~group
		, data = obs_sds
	)
)




-- 
Mike Lawrence
Graduate Student
Department of Psychology
Dalhousie University

Looking to arrange a meeting? Check my public calendar:
http://tr.im/mikes_public_calendar

~ Certainty is folly... I think. ~



From bates at stat.wisc.edu  Fri Aug 13 00:53:22 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 12 Aug 2010 17:53:22 -0500
Subject: [R-sig-ME] examples in Applied Longitudinal Analysis
In-Reply-To: <87sk2jrg5m.fsf@kolob.sebmags.homelinux.org>
References: <87sk2jrg5m.fsf@kolob.sebmags.homelinux.org>
Message-ID: <AANLkTi=EOKoLaL6jGrckgAr2-sbZ6dXvgsMnYDJx3xha@mail.gmail.com>

On Thu, Aug 12, 2010 at 10:42 AM, Sebastian P. Luque <spluque at gmail.com> wrote:
> Hi,

> Now that I'm reading Fitzmaurice et al's book, I recall having seen
> their examples using lme4 but cannot trace back what URL this was on.
> If someone knows where this is now, I'd appreciate the pointer. ?Thanks.

I created a project on R-forge with the intention of building a
package for the data sets from that book but haven't done anything
with it.  I can remove the project to avoid confusion if someone else
has make the data sets available for R.



From arrayprofile at yahoo.com  Fri Aug 13 08:02:55 2010
From: arrayprofile at yahoo.com (array chip)
Date: Thu, 12 Aug 2010 23:02:55 -0700 (PDT)
Subject: [R-sig-ME] longitudinal with 2 time points
In-Reply-To: <FB025028-0C67-4B59-9757-FC2305C07EA6@me.com>
References: <439946.26259.qm@web56301.mail.re3.yahoo.com>
	<B80EFDF8-B705-4EBA-A80E-9A4354F08353@anu.edu.au>
	<alpine.WNT.2.00.1008110532370.640@TED2>
	<8D383357-99BA-4447-A93B-0D8FC7AF7279@me.com>
	<323634.22474.qm@web56305.mail.re3.yahoo.com>
	<FB025028-0C67-4B59-9757-FC2305C07EA6@me.com>
Message-ID: <111355.9211.qm@web56301.mail.re3.yahoo.com>

Marc,

Thanks for sharing your insights. Let's take this?model as an example:

?lm(wk4.glucose ~ baseline.glucose + treatment + gender + age)

Because the investigator is interested in knowing whether the?CHANGE of glucose 
in week 4 from baseline is different between treatment and control, Is it still 
legitimate to ask whether and?HOW can we test this hypothesis? I think the 
coefficient of the?treatment factor is only testing whether the week 4 glucose 
level is different between treatment and control, but not testing whether 
the?CHANGE of week 4 glucose level with respect to baseline is different between 
treatment and control.

Thanks again for your suggestion.

Yi



?


----- Original Message ----
From: Marc Schwartz <marc_schwartz at me.com>
To: array chip <arrayprofile at yahoo.com>
Cc: Charles E. (Ted) Wright <cewright at uci.edu>; John Maindonald 
<john.maindonald at anu.edu.au>; r-sig-mixed-models at r-project.org
Sent: Thu, August 12, 2010 6:02:29 AM
Subject: Re: [R-sig-ME] longitudinal with 2 time points

Hi John,

If you read that article, you will see that your use of delta.y as the dependent 
variable does not make sense.

Thus, I would re-express your model 5 as:

? lm(wk4.glucose ~ baseline.glucose + treatment + gender + age)

and as noted, check for the interaction between baseline glucose and treatment:

? lm(wk4.glucose ~ baseline.glucose * treatment + gender + age)


You might also want to consider using a spline function on age, presuming that 
age is hopefully measured as a continuous variable (eg. not ordinal groups).

Since the ANCOVA based approach described in the paper is essentially an OLS 
linear regression, you can of course include the additional covariates for 
adjustment. If the interaction term p value is >0.1 (a common threshold), you 
can remove it and the beta coefficient and its CIs for the treatment factor is 
your estimated treatment effect relative to your control.

For the presentation of the results, besides the obvious tabular summaries and 
the scatter/regression lines plot, include a series of plots showing selected 
baseline values and the treatment versus control predicted follow up values and 
CIs for the same baseline value in each plot. This visually shows the common 
estimated treatment effect for each baseline value, which will also tend to 
reveal regression to the mean. This presentation is especially helpful if the 
interaction term is retained, which therefore shows how the treatment effect 
varies and will reverse, over the range of the baseline values. You can select a 
series of clinically relevant values over the range of the observed baseline 
values, and/or by default, select a five number plus mean series over the 
observed baseline values.

I don't see a role for a mixed effects model here, given that this is a pretty 
straightforward "change from baseline" type design, but there are many here with 
greater expertise than I. If this was a cross-over design, you have multiple 
measures of glucose for each patient at each time point, more than two time 
points, or a multi-center study, then a mixed effects model would make more 
sense to me.

HTH,

Marc



On Aug 12, 2010, at 12:39 AM, array chip wrote:

> Hi Marc,
> 
> Thanks for the reference. I will definitely read it. Please see my reponse to 
> John's reply. Your model is another model I should add to the 5 models I 
> proposed in that email. What's your overall thoughts on these different 
models?
> 
> Thank you for sharing.
> 
> John
> 
> 
> 
> ----- Original Message ----
> From: Marc Schwartz <marc_schwartz at me.com>
> To: Charles E. (Ted) Wright <cewright at uci.edu>; array chip 
> <arrayprofile at yahoo.com>
> Cc: John Maindonald <john.maindonald at anu.edu.au>; 
> r-sig-mixed-models at r-project.org
> Sent: Wed, August 11, 2010 6:20:13 AM
> Subject: Re: [R-sig-ME] longitudinal with 2 time points
> 
> Hi,
> 
> I'll throw in a reference that covers some of these issues:
> 
> Statistics Notes
> Analysing controlled trials with baseline and follow up measurements
> Vickers and Altman
> BMJ. 2001 November 10; 323(7321): 1123?1124.
> https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1121605/
> 
> 
> The basic model specification would of course be:
> 
>? lm(4Wks ~ Baseline + Group)
> 
> You will also want to test for an interaction between the baseline score and 
> your grouping factor, in case the observed group (eg. treatment) effect is 
> dependent upon the value of the baseline measurement. In this case, unlike in 
> the above paper, you of course end up with crossing fitted regression lines, 
> rather than parallel lines.
> 
> HTH,
> 
> Marc Schwartz
> 
> 
> On Aug 11, 2010, at 7:34 AM, Charles E. (Ted) Wright wrote:
> 
>> Keep in mind that running an ANOVA on the difference is not the same thing as 

>> using the baseline data as a covariate in an ANOVA on the Week 4 data. 
>> Essentially the ANOVA on the differences is like the ANCOVA with the slope 
>> constrained to be 1.
>> 
>> Ted Wright
>> 
>> On Wed, 11 Aug 2010, John Maindonald wrote:
>> 
>>> All these are possibilities, except maybe making baseline measurement
>>> a random factor.? This would make sense only if data divide into groups,
>>> and you want the baseline effect to vary randomly from group to group.
>>> That may limit your ability to estimate parameters that are of interest.
>>> In most circumstances that I am familiar with, it makes better sense to
>>> treat baseline effect as fixed.
>>> 
>>> John.
>>> 
>>> On 11/08/2010, at 8:11 AM, array chip wrote:
>>> 
>>>> Hi, I am wondering if it is still meaningful to run a mixed model if a
>>>> longitudinal dataset has only 2 time points (baseline and week 4)? Would it 

>> be
>>>> more appropriate to simply take the difference between the 2 time points and 
>
>>>> run
>>>> ANOVA (ANCOVA) on the difference? what about still running mixed model on 
> the
>>>> difference of the 2 time points, but adding baseline measurement as a 
random
>>>> factor?
>>>> 
>>>> Thanks for sharing your thoughts.
>>>> 
>>>> John
> 
> 
> 
> 






From cm744 at st-andrews.ac.uk  Fri Aug 13 09:26:37 2010
From: cm744 at st-andrews.ac.uk (Chris Mcowen)
Date: Fri, 13 Aug 2010 08:26:37 +0100
Subject: [R-sig-ME] Worked analysis of owl data
References: <517342A2-7F66-4F17-BE98-4BBB670D2DD8@st-andrews.ac.uk>
Message-ID: <8DF140D0-72A1-48AA-8342-28A1C8DC45A0@st-andrews.ac.uk>

Hi Jarrord/Ben and list

Thanks for this.

I have extended the model to a gaussian error with 5 level response variable (IUCN- 1-5) this is a as discrete variable but is an approximation of an underlying continuous spectrum.

The reason i am worrying about the residuals ( please follow link to a new picture - https://files.me.com/chrismcowen/0v6ys4)

 Is that i want to use the fitted values from the model to predict extinction risk ( the response variable) - that way i could include species that don't have a extinction risk, species that weren't in the original model, but for which i have all the necessary life history data. However i am unsure if this is possible with lmer?

I hope this makes sense, and thank you for your help

Chris


On 12 Aug 2010, at 18:47, Jarrod Hadfield wrote:

Hi Ben/Chris,

I agree and would not be unduly worried about the residuals from a binary model. They always look odd if you are used to looking at residuals from a Guassian model, and I'm not sure whether its possible to diagnose problems using them (except complete separation perhaps).

Cheers,

Jarrod


On 12 Aug 2010, at 16:41, Ben Bolker wrote:

> On Thu, Aug 12, 2010 at 5:24 AM, Chris Mcowen <cm744 at st-andrews.ac.uk> wrote:
>> Hi Ben,
>> 
>> I have been working through the above data set
>> 
>> I have followed the code to NOT account for random effects in my model,  which has worked well - thanks, however as i have a binary response my residual plot shows this
>> 
>> https://files.me.com/chrismcowen/i4jxlw
>> 
>> Is there a way to Plot predictions and confidence intervals with residuals like this?
> 
> Why not?  The recipes in the Owls example should work, I think ...
> with the proviso that (as Jarrod Hadfield said) you have to be very
> careful in defining what response you are predicting the mean _of_ --
> if there are any random effects (other than the intrinsic variability
> of the binary response) that are non-zero, and if you try to calculate
> the mean of the predicted response on the original (rather than the
> link/logit scale), they will affect the prediction of the mean.
> 
> You seem quite concerned about the odd distributions of the
> residuals. It's good to be careful, but as far I have seen so far what
> you are seeing is just the nature of binary residuals.  One way to get
> a handle on what the residuals should look like is to simulate data
> from a situation reasonably similar to (although often a bit simpler
> than) what you think is going on with your data, so that you *know*
> the model is specified correctly, and see what the residuals from the
> fitted model look like in that case.
> 


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From paul.metzner at gmail.com  Fri Aug 13 10:20:41 2010
From: paul.metzner at gmail.com (Paul Metzner)
Date: Fri, 13 Aug 2010 10:20:41 +0200
Subject: [R-sig-ME] Contrasts for interactions in lmer
In-Reply-To: <AANLkTikjX5L3t0SJOJSoghEBYRYSB2rF1qRVfYLVzjZ0@mail.gmail.com>
References: <E76415FE-31A0-464F-8B83-84D78C636CAE@gmail.com>
	<AANLkTikjX5L3t0SJOJSoghEBYRYSB2rF1qRVfYLVzjZ0@mail.gmail.com>
Message-ID: <B2205DE8-25B0-4061-B3D2-47967A4C061F@gmail.com>

Thank you for the quick answer!

> (1) The Fixed Effects correlations are probably not what you are
> after. For example, in a perfectly balanced design, these correlations
> will be zero.

They are not, but like you suggested, I wanted them to be at least close to zero. When I changed the model like mentioned before, I noticed an increase in fixed effects correlations and a curious change in contrast coding (see below), that I couldn't explain.
My main interest are the fixed effects interactions. My hypothesis is that subjects with a higher PCU will be affected more strongly by the condition manipulation. Also, in some studies only one kind of verbs (DIR) has been shown to evoke the effect, hence the desired interaction of COND and DIR. But, because I really don't want individual differences over and above what is explained by PCU, I implemented the random effect term like you suggested and re-included the factors contributing to the interactions. My model now looks like this:

lmer(log(RRT)~COND + PCU + COND:PCU + DIR + COND:DIR + (1+COND+DIR|SUBJECT) + (1|ITEM), data=fm3)

Although including the covariance component did not improve model fit, I decided to leave it in the model for the reasons mentioned above. I did, however, exclude the three-way interaction COND:DIR:PCU.

> (3) You used a sum contrast specification for the two factors (COND
> and DIR). This is fine. For two-level factors there is no point in
> specifying Helmert contrasts. So it is unclear what you referring to
> in this context.

Being a novice to contrast coding, I thought it was the same. Coincidentally, that seems to be the case for two-level factors. Thanks again for the suggestions!

Paul


On 12 Aug 2010, at 11:24, Reinhold Kliegl wrote:

> There is a bit of evidence for an interaction of COND and PCU:
>>> COND1:PCU        48.309     29.850   1.618
> If the t-value were larger it would indicate that slopes for the
> regression of RRT on PCU differ between the two condition.
> 
> There is no statistical support for the the interaction of DIR and PCU
>>> PCU:DIR1        -26.835     29.814  -0.900
> 
> Now to some of your questions relating to correlations:
> (1) The Fixed Effects correlations are probably not what you are
> after. For example, in a perfectly balanced design, these correlations
> will be zero.
> 
> (2) I suspect what you might be after are effect correlations related
> to subjects or items. Assuming cond and verb bias are within-subject
> effects, you could get an estimate of the parameter for the covariance
> component with the following specification.
> RRT ~ COND * PCU * DIR + (1 + COND + DIR  | SUBJECT) + (1 | ITEM)
> 
> You should check whether adding these variance components to the model
> improves the goodness fo fit, for example with an ANOVA..
> 
> (3) You used a sum contrast specification for the two factors (COND
> and DIR). This is fine. For two-level factors there is no point in
> specifying Helmert contrasts. So it is unclear what you referring to
> in this context.
> 
> Finally, it is generally a bad idea to specify models with
> interactions terms leaving out the factors contributing to the
> interactions. If you do so, you need to have very good theoretical
> reasons.
> 
> Reinhold Kliegl
> 
> 
> On Thu, Aug 12, 2010 at 10:44 AM, Paul Metzner <paul.metzner at gmail.com> wrote:
>> Dear all.
>> 
>> I am currently analyzing eye-tracking data and am interested in a main effect of condition (COND) plus its interaction with subjects' operation span (PCU) and the direction of a verb bias (1 or 2). The contrasts are:
>> 
>>> contrasts(COND)
>>>  [,1]
>>> a   -1
>>> b    1
>> 
>> and
>> 
>>> contrasts(DIR)
>>>  [,1]
>>> 1   -1
>>> 2    1
>> 
>> PCU is a continuous predictor which I centered by subtracting the mean (the problem does, however, persist when I split the sample into extreme groups and work with a categorial predictor). With the following model, I don't get a correlation between the fixed effects:
>> 
>>> Linear mixed model fit by REML
>>> Formula: RRT ~ COND * PCU * DIR + (1 | SUBJECT) + (1 | ITEM)
>>>    Data: fm3
>>>    AIC   BIC logLik deviance REMLdev
>>>  46733 46801 -23355    46768   46711
>>> Random effects:
>>>  Groups   Name        Variance Std.Dev.
>>>  SUBJECT  (Intercept)  8918.29  94.437
>>>  ITEM     (Intercept)   404.85  20.121
>>>  Residual             34881.69 186.766
>>> Number of obs: 3503, groups: SUBJECT, 59; ITEM, 59
>>> 
>>> Fixed effects:
>>>                Estimate Std. Error t value
>>> (Intercept)     122.900     12.963   9.481
>>> COND1            15.924      3.165   5.031
>>> PCU             139.411    120.025   1.162
>>> DIR1             -7.746      4.107  -1.886
>>> COND1:PCU        48.309     29.850   1.618
>>> COND1:DIR1       -3.396      3.164  -1.073
>>> PCU:DIR1        -26.835     29.814  -0.900
>>> COND1:PCU:DIR1   -8.069     29.838  -0.270
>>> 
>>> Correlation of Fixed Effects:
>>>             (Intr) COND1  PCU    DIR1   COND1:PCU COND1:D PCU:DI
>>> COND1        0.002
>>> PCU          0.004 -0.001
>>> DIR1         0.002 -0.004  0.004
>>> COND1:PCU   -0.001 -0.001  0.003  0.000
>>> COND1:DIR1  -0.001  0.000  0.000  0.007  0.021
>>> PCU:DIR1     0.005  0.000 -0.003  0.000 -0.009    -0.005
>>> COND1:PCU:D  0.000  0.021 -0.002 -0.004 -0.009    -0.001   0.011
>> 
>> But, since I'm mainly interested in the interactions and not so much the main effects of PCU and DIR, I changed the model to the following:
>> 
>>> Linear mixed model fit by REML
>>> Formula: RRT ~ COND + COND:PCU + COND:DIR + (1 | SUBJECT) + (1 | ITEM)
>>>    Data: fm3
>>>    AIC   BIC logLik deviance REMLdev
>>>  46744 46800 -23363    46769   46726
>>> Random effects:
>>>  Groups   Name        Variance Std.Dev.
>>>  SUBJECT  (Intercept)  8911.15  94.399
>>>  ITEM     (Intercept)   406.16  20.153
>>>  Residual             34869.91 186.735
>>> Number of obs: 3503, groups: SUBJECT, 59; ITEM, 59
>>> 
>>> Fixed effects:
>>>             Estimate Std. Error t value
>>> (Intercept)  122.962     12.959   9.489
>>> COND1         15.941      3.164   5.039
>>> CONDa:PCU     91.049    123.553   0.737
>>> CONDb:PCU    187.055    123.714   1.512
>>> CONDa:DIR1    -4.340      5.168  -0.840
>>> CONDb:DIR1   -11.160      5.204  -2.144
>>> 
>>> Correlation of Fixed Effects:
>>>            (Intr) COND1  CONDa:PCU CONDb:PCU CONDa:DIR1
>>> COND1       0.002
>>> CONDa:PCU   0.004 -0.001
>>> CONDb:PCU   0.004 -0.001  0.883
>>> CONDa:DIR1  0.002 -0.003  0.006     0.000
>>> CONDb:DIR1  0.001 -0.003  0.000     0.006     0.256
>> 
>> Not I do get a considerable correlation between the interactions. From the output (CONDa:?, CONDb:?), I infer that the model didn't always use helmert coding for condition but applied something else for the interactions. Is that right? When I code COND numerically as -1 and 1, the correlations turn out fine, which supports my conclusion. I would be very grateful for suggestions.
>> 
>> Thanks,
>> Paul
>> 
>> ---
>> Paul Metzner
>> 
>> Humboldt-Universit?t zu Berlin
>> Philosophische Fakult?t II
>> Institut f?r deutsche Sprache und Linguistik
>> 
>> Post: Unter den Linden 6 | 10099 Berlin | Deutschland
>> Besuch: Dorotheenstra?e 24 | 10117 Berlin | Deutschland
>> 
>> +49-(0)30-2093-9726
>> paul.metzner at gmail.com
>> http://amor.rz.hu-berlin.de/~metznerp/
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 


---
Paul Metzner

Humboldt-Universit?t zu Berlin
Philosophische Fakult?t II
Institut f?r deutsche Sprache und Linguistik

Post: Unter den Linden 6 | 10099 Berlin | Deutschland
Besuch: Dorotheenstra?e 24 | 10117 Berlin | Deutschland

+49-(0)30-2093-9726
paul.metzner at gmail.com
http://amor.rz.hu-berlin.de/~metznerp/



From reinhold.kliegl at gmail.com  Fri Aug 13 12:25:27 2010
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Fri, 13 Aug 2010 12:25:27 +0200
Subject: [R-sig-ME] Contrasts for interactions in lmer
In-Reply-To: <B2205DE8-25B0-4061-B3D2-47967A4C061F@gmail.com>
References: <E76415FE-31A0-464F-8B83-84D78C636CAE@gmail.com>
	<AANLkTikjX5L3t0SJOJSoghEBYRYSB2rF1qRVfYLVzjZ0@mail.gmail.com>
	<B2205DE8-25B0-4061-B3D2-47967A4C061F@gmail.com>
Message-ID: <AANLkTiknfjhRop29-T_vruhe+U2KFLo+_crtuUfyELjN@mail.gmail.com>

Maybe I responded to quickly ...

First, I guess for a two-level factor a sum contrast can also be
called a Helmert contrast; it is a bit unusual, I think.

Second, the story about the fixed-effect correlations is complicated.
What I wrote for balanced designs returning a zero correlation matrix
of fixed effects assumes also that contrasts for the fixed effects are
orthogonal and that the variance components are specified only for the
intercepts, as you had set up your first model. If you specify a
non-orthogonal set of treatment contrasts, the fixed-effects
correlations will  be 0.5. Thus, these correlations inform about the
correlations of the predictors in the model matrix.
        Moreover, the story changes again  if you estimate values for
parameters representing (co-)-variance components for random effects
in a balanced design, the fixed-effect correlations return values that
(sometimes?) are close to within-subject correlations (i.e.,
correlations unadjusted for shrinkage); maybe for balanced designs
with orthogonal predictors there is actually a specification under
which they are actually identical with them.  This would be cool.

Third, I think the fixed-effect part of the model you give now looks
fine; it is defensible (and sometimes necessary) to exclude
non-significant higher-order interactions.  I still don't think you
need the variance components associated with COND and DIR for subjects
and you may be communicating the wrong thing, but opinions may differ
on this, because non-significance of these components is a thorny
issue.
         In this case, as far as I can see, these correlations are not
really related to the COND x PCU interaction  you are interested in.
Significant effect correlations  can be mapped onto a different kind
of interaction (e.g.,, subjects with a large COND effect may tend to
have a larger DIR effect than subjects with a small COND effect), but
this does not bear on your PCU covariate, at least not directly. (This
could happen independent of a DIR x COND interaction in the
fixed-effect part of the model.)
        I saw that now you use log-transformed DVs and that in my
experience is a good choice for durations collected in eye tracking.
Nevertheless you should check the distribution of model residuals to
back up this decision. Anyway, the log-transformation of RRT may have
lifted the t-value for the PCU  X COND interaction. So I am curious
whether it did or not?

Reinhold Kliegl


On Fri, Aug 13, 2010 at 10:20 AM, Paul Metzner <paul.metzner at gmail.com> wrote:
> Thank you for the quick answer!
>
>> (1) The Fixed Effects correlations are probably not what you are
>> after. For example, in a perfectly balanced design, these correlations
>> will be zero.
>
> They are not, but like you suggested, I wanted them to be at least close to zero. When I changed the model like mentioned before, I noticed an increase in fixed effects correlations and a curious change in contrast coding (see below), that I couldn't explain.
> My main interest are the fixed effects interactions. My hypothesis is that subjects with a higher PCU will be affected more strongly by the condition manipulation. Also, in some studies only one kind of verbs (DIR) has been shown to evoke the effect, hence the desired interaction of COND and DIR. But, because I really don't want individual differences over and above what is explained by PCU, I implemented the random effect term like you suggested and re-included the factors contributing to the interactions. My model now looks like this:
>
> lmer(log(RRT)~COND + PCU + COND:PCU + DIR + COND:DIR + (1+COND+DIR|SUBJECT) + (1|ITEM), data=fm3)
>
> Although including the covariance component did not improve model fit, I decided to leave it in the model for the reasons mentioned above. I did, however, exclude the three-way interaction COND:DIR:PCU.
>
>> (3) You used a sum contrast specification for the two factors (COND
>> and DIR). This is fine. For two-level factors there is no point in
>> specifying Helmert contrasts. So it is unclear what you referring to
>> in this context.
>
> Being a novice to contrast coding, I thought it was the same. Coincidentally, that seems to be the case for two-level factors. Thanks again for the suggestions!
>
> Paul
>
>
> On 12 Aug 2010, at 11:24, Reinhold Kliegl wrote:
>
>> There is a bit of evidence for an interaction of COND and PCU:
>>>> COND1:PCU ? ? ? ?48.309 ? ? 29.850 ? 1.618
>> If the t-value were larger it would indicate that slopes for the
>> regression of RRT on PCU differ between the two condition.
>>
>> There is no statistical support for the the interaction of DIR and PCU
>>>> PCU:DIR1 ? ? ? ?-26.835 ? ? 29.814 ?-0.900
>>
>> Now to some of your questions relating to correlations:
>> (1) The Fixed Effects correlations are probably not what you are
>> after. For example, in a perfectly balanced design, these correlations
>> will be zero.
>>
>> (2) I suspect what you might be after are effect correlations related
>> to subjects or items. Assuming cond and verb bias are within-subject
>> effects, you could get an estimate of the parameter for the covariance
>> component with the following specification.
>> RRT ~ COND * PCU * DIR + (1 + COND + DIR ?| SUBJECT) + (1 | ITEM)
>>
>> You should check whether adding these variance components to the model
>> improves the goodness fo fit, for example with an ANOVA..
>>
>> (3) You used a sum contrast specification for the two factors (COND
>> and DIR). This is fine. For two-level factors there is no point in
>> specifying Helmert contrasts. So it is unclear what you referring to
>> in this context.
>>
>> Finally, it is generally a bad idea to specify models with
>> interactions terms leaving out the factors contributing to the
>> interactions. If you do so, you need to have very good theoretical
>> reasons.
>>
>> Reinhold Kliegl
>>
>>
>> On Thu, Aug 12, 2010 at 10:44 AM, Paul Metzner <paul.metzner at gmail.com> wrote:
>>> Dear all.
>>>
>>> I am currently analyzing eye-tracking data and am interested in a main effect of condition (COND) plus its interaction with subjects' operation span (PCU) and the direction of a verb bias (1 or 2). The contrasts are:
>>>
>>>> contrasts(COND)
>>>> ?[,1]
>>>> a ? -1
>>>> b ? ?1
>>>
>>> and
>>>
>>>> contrasts(DIR)
>>>> ?[,1]
>>>> 1 ? -1
>>>> 2 ? ?1
>>>
>>> PCU is a continuous predictor which I centered by subtracting the mean (the problem does, however, persist when I split the sample into extreme groups and work with a categorial predictor). With the following model, I don't get a correlation between the fixed effects:
>>>
>>>> Linear mixed model fit by REML
>>>> Formula: RRT ~ COND * PCU * DIR + (1 | SUBJECT) + (1 | ITEM)
>>>> ? ?Data: fm3
>>>> ? ?AIC ? BIC logLik deviance REMLdev
>>>> ?46733 46801 -23355 ? ?46768 ? 46711
>>>> Random effects:
>>>> ?Groups ? Name ? ? ? ?Variance Std.Dev.
>>>> ?SUBJECT ?(Intercept) ?8918.29 ?94.437
>>>> ?ITEM ? ? (Intercept) ? 404.85 ?20.121
>>>> ?Residual ? ? ? ? ? ? 34881.69 186.766
>>>> Number of obs: 3503, groups: SUBJECT, 59; ITEM, 59
>>>>
>>>> Fixed effects:
>>>> ? ? ? ? ? ? ? ?Estimate Std. Error t value
>>>> (Intercept) ? ? 122.900 ? ? 12.963 ? 9.481
>>>> COND1 ? ? ? ? ? ?15.924 ? ? ?3.165 ? 5.031
>>>> PCU ? ? ? ? ? ? 139.411 ? ?120.025 ? 1.162
>>>> DIR1 ? ? ? ? ? ? -7.746 ? ? ?4.107 ?-1.886
>>>> COND1:PCU ? ? ? ?48.309 ? ? 29.850 ? 1.618
>>>> COND1:DIR1 ? ? ? -3.396 ? ? ?3.164 ?-1.073
>>>> PCU:DIR1 ? ? ? ?-26.835 ? ? 29.814 ?-0.900
>>>> COND1:PCU:DIR1 ? -8.069 ? ? 29.838 ?-0.270
>>>>
>>>> Correlation of Fixed Effects:
>>>> ? ? ? ? ? ? (Intr) COND1 ?PCU ? ?DIR1 ? COND1:PCU COND1:D PCU:DI
>>>> COND1 ? ? ? ?0.002
>>>> PCU ? ? ? ? ?0.004 -0.001
>>>> DIR1 ? ? ? ? 0.002 -0.004 ?0.004
>>>> COND1:PCU ? -0.001 -0.001 ?0.003 ?0.000
>>>> COND1:DIR1 ?-0.001 ?0.000 ?0.000 ?0.007 ?0.021
>>>> PCU:DIR1 ? ? 0.005 ?0.000 -0.003 ?0.000 -0.009 ? ?-0.005
>>>> COND1:PCU:D ?0.000 ?0.021 -0.002 -0.004 -0.009 ? ?-0.001 ? 0.011
>>>
>>> But, since I'm mainly interested in the interactions and not so much the main effects of PCU and DIR, I changed the model to the following:
>>>
>>>> Linear mixed model fit by REML
>>>> Formula: RRT ~ COND + COND:PCU + COND:DIR + (1 | SUBJECT) + (1 | ITEM)
>>>> ? ?Data: fm3
>>>> ? ?AIC ? BIC logLik deviance REMLdev
>>>> ?46744 46800 -23363 ? ?46769 ? 46726
>>>> Random effects:
>>>> ?Groups ? Name ? ? ? ?Variance Std.Dev.
>>>> ?SUBJECT ?(Intercept) ?8911.15 ?94.399
>>>> ?ITEM ? ? (Intercept) ? 406.16 ?20.153
>>>> ?Residual ? ? ? ? ? ? 34869.91 186.735
>>>> Number of obs: 3503, groups: SUBJECT, 59; ITEM, 59
>>>>
>>>> Fixed effects:
>>>> ? ? ? ? ? ? Estimate Std. Error t value
>>>> (Intercept) ?122.962 ? ? 12.959 ? 9.489
>>>> COND1 ? ? ? ? 15.941 ? ? ?3.164 ? 5.039
>>>> CONDa:PCU ? ? 91.049 ? ?123.553 ? 0.737
>>>> CONDb:PCU ? ?187.055 ? ?123.714 ? 1.512
>>>> CONDa:DIR1 ? ?-4.340 ? ? ?5.168 ?-0.840
>>>> CONDb:DIR1 ? -11.160 ? ? ?5.204 ?-2.144
>>>>
>>>> Correlation of Fixed Effects:
>>>> ? ? ? ? ? ?(Intr) COND1 ?CONDa:PCU CONDb:PCU CONDa:DIR1
>>>> COND1 ? ? ? 0.002
>>>> CONDa:PCU ? 0.004 -0.001
>>>> CONDb:PCU ? 0.004 -0.001 ?0.883
>>>> CONDa:DIR1 ?0.002 -0.003 ?0.006 ? ? 0.000
>>>> CONDb:DIR1 ?0.001 -0.003 ?0.000 ? ? 0.006 ? ? 0.256
>>>
>>> Not I do get a considerable correlation between the interactions. From the output (CONDa:?, CONDb:?), I infer that the model didn't always use helmert coding for condition but applied something else for the interactions. Is that right? When I code COND numerically as -1 and 1, the correlations turn out fine, which supports my conclusion. I would be very grateful for suggestions.
>>>
>>> Thanks,
>>> Paul
>>>
>>> ---
>>> Paul Metzner
>>>
>>> Humboldt-Universit?t zu Berlin
>>> Philosophische Fakult?t II
>>> Institut f?r deutsche Sprache und Linguistik
>>>
>>> Post: Unter den Linden 6 | 10099 Berlin | Deutschland
>>> Besuch: Dorotheenstra?e 24 | 10117 Berlin | Deutschland
>>>
>>> +49-(0)30-2093-9726
>>> paul.metzner at gmail.com
>>> http://amor.rz.hu-berlin.de/~metznerp/
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>
>
> ---
> Paul Metzner
>
> Humboldt-Universit?t zu Berlin
> Philosophische Fakult?t II
> Institut f?r deutsche Sprache und Linguistik
>
> Post: Unter den Linden 6 | 10099 Berlin | Deutschland
> Besuch: Dorotheenstra?e 24 | 10117 Berlin | Deutschland
>
> +49-(0)30-2093-9726
> paul.metzner at gmail.com
> http://amor.rz.hu-berlin.de/~metznerp/
>
>



From paul.metzner at gmail.com  Fri Aug 13 13:15:43 2010
From: paul.metzner at gmail.com (Paul Metzner)
Date: Fri, 13 Aug 2010 13:15:43 +0200
Subject: [R-sig-ME] Contrasts for interactions in lmer
In-Reply-To: <AANLkTiknfjhRop29-T_vruhe+U2KFLo+_crtuUfyELjN@mail.gmail.com>
References: <E76415FE-31A0-464F-8B83-84D78C636CAE@gmail.com>
	<AANLkTikjX5L3t0SJOJSoghEBYRYSB2rF1qRVfYLVzjZ0@mail.gmail.com>
	<B2205DE8-25B0-4061-B3D2-47967A4C061F@gmail.com>
	<AANLkTiknfjhRop29-T_vruhe+U2KFLo+_crtuUfyELjN@mail.gmail.com>
Message-ID: <33E36232-BA52-4301-A168-1C4ED9B93F62@gmail.com>

First, to clear things up, RRT is not reciprocal reading time, but re-reading time (time spent on a region after it was fixated and left).

> I saw that now you use log-transformed DVs and that in my
> experience is a good choice for durations collected in eye tracking.
> Nevertheless you should check the distribution of model residuals to
> back up this decision. Anyway, the log-transformation of RRT may have
> lifted the t-value for the PCU  X COND interaction. So I am curious
> whether it did or not?

I am very unsecure about whether or not i should log-transform. Because most of the duration variables include zeroes and because this is informative, as well, I don't want to exclude them. To still be able to log-transform, I would have to add a constant value and I am uncertain, if that is a valid operation. Plotting fitted values against residuals doesn't look good both when I use raw data and when I log-transform. The distribution of the model residuals look at least ok when zeroes are excluded (and even better with log(RRT)), but that would no longer be the DV that I am interested in. See these plots for illustration: http://amor.rz.hu-berlin.de/~metznerp/Rplot.pdf
However, the log-transformation did indeed lift the t-value for PCU x COND, but only marginally (from 1.492 to 1.581). Generally, the log-transform seems to have little impact on the main effects and interactions (two or three effects disappear without log-transformation).



On 13 Aug 2010, at 12:25, Reinhold Kliegl wrote:

> Maybe I responded to quickly ...
> 
> First, I guess for a two-level factor a sum contrast can also be
> called a Helmert contrast; it is a bit unusual, I think.
> 
> Second, the story about the fixed-effect correlations is complicated.
> What I wrote for balanced designs returning a zero correlation matrix
> of fixed effects assumes also that contrasts for the fixed effects are
> orthogonal and that the variance components are specified only for the
> intercepts, as you had set up your first model. If you specify a
> non-orthogonal set of treatment contrasts, the fixed-effects
> correlations will  be 0.5. Thus, these correlations inform about the
> correlations of the predictors in the model matrix.
>        Moreover, the story changes again  if you estimate values for
> parameters representing (co-)-variance components for random effects
> in a balanced design, the fixed-effect correlations return values that
> (sometimes?) are close to within-subject correlations (i.e.,
> correlations unadjusted for shrinkage); maybe for balanced designs
> with orthogonal predictors there is actually a specification under
> which they are actually identical with them.  This would be cool.
> 
> Third, I think the fixed-effect part of the model you give now looks
> fine; it is defensible (and sometimes necessary) to exclude
> non-significant higher-order interactions.  I still don't think you
> need the variance components associated with COND and DIR for subjects
> and you may be communicating the wrong thing, but opinions may differ
> on this, because non-significance of these components is a thorny
> issue.
>         In this case, as far as I can see, these correlations are not
> really related to the COND x PCU interaction  you are interested in.
> Significant effect correlations  can be mapped onto a different kind
> of interaction (e.g.,, subjects with a large COND effect may tend to
> have a larger DIR effect than subjects with a small COND effect), but
> this does not bear on your PCU covariate, at least not directly. (This
> could happen independent of a DIR x COND interaction in the
> fixed-effect part of the model.)
>        I saw that now you use log-transformed DVs and that in my
> experience is a good choice for durations collected in eye tracking.
> Nevertheless you should check the distribution of model residuals to
> back up this decision. Anyway, the log-transformation of RRT may have
> lifted the t-value for the PCU  X COND interaction. So I am curious
> whether it did or not?
> 
> Reinhold Kliegl
> 
> 
> On Fri, Aug 13, 2010 at 10:20 AM, Paul Metzner <paul.metzner at gmail.com> wrote:
>> Thank you for the quick answer!
>> 
>>> (1) The Fixed Effects correlations are probably not what you are
>>> after. For example, in a perfectly balanced design, these correlations
>>> will be zero.
>> 
>> They are not, but like you suggested, I wanted them to be at least close to zero. When I changed the model like mentioned before, I noticed an increase in fixed effects correlations and a curious change in contrast coding (see below), that I couldn't explain.
>> My main interest are the fixed effects interactions. My hypothesis is that subjects with a higher PCU will be affected more strongly by the condition manipulation. Also, in some studies only one kind of verbs (DIR) has been shown to evoke the effect, hence the desired interaction of COND and DIR. But, because I really don't want individual differences over and above what is explained by PCU, I implemented the random effect term like you suggested and re-included the factors contributing to the interactions. My model now looks like this:
>> 
>> lmer(log(RRT)~COND + PCU + COND:PCU + DIR + COND:DIR + (1+COND+DIR|SUBJECT) + (1|ITEM), data=fm3)
>> 
>> Although including the covariance component did not improve model fit, I decided to leave it in the model for the reasons mentioned above. I did, however, exclude the three-way interaction COND:DIR:PCU.
>> 
>>> (3) You used a sum contrast specification for the two factors (COND
>>> and DIR). This is fine. For two-level factors there is no point in
>>> specifying Helmert contrasts. So it is unclear what you referring to
>>> in this context.
>> 
>> Being a novice to contrast coding, I thought it was the same. Coincidentally, that seems to be the case for two-level factors. Thanks again for the suggestions!
>> 
>> Paul
>> 
>> 
>> On 12 Aug 2010, at 11:24, Reinhold Kliegl wrote:
>> 
>>> There is a bit of evidence for an interaction of COND and PCU:
>>>>> COND1:PCU        48.309     29.850   1.618
>>> If the t-value were larger it would indicate that slopes for the
>>> regression of RRT on PCU differ between the two condition.
>>> 
>>> There is no statistical support for the the interaction of DIR and PCU
>>>>> PCU:DIR1        -26.835     29.814  -0.900
>>> 
>>> Now to some of your questions relating to correlations:
>>> (1) The Fixed Effects correlations are probably not what you are
>>> after. For example, in a perfectly balanced design, these correlations
>>> will be zero.
>>> 
>>> (2) I suspect what you might be after are effect correlations related
>>> to subjects or items. Assuming cond and verb bias are within-subject
>>> effects, you could get an estimate of the parameter for the covariance
>>> component with the following specification.
>>> RRT ~ COND * PCU * DIR + (1 + COND + DIR  | SUBJECT) + (1 | ITEM)
>>> 
>>> You should check whether adding these variance components to the model
>>> improves the goodness fo fit, for example with an ANOVA..
>>> 
>>> (3) You used a sum contrast specification for the two factors (COND
>>> and DIR). This is fine. For two-level factors there is no point in
>>> specifying Helmert contrasts. So it is unclear what you referring to
>>> in this context.
>>> 
>>> Finally, it is generally a bad idea to specify models with
>>> interactions terms leaving out the factors contributing to the
>>> interactions. If you do so, you need to have very good theoretical
>>> reasons.
>>> 
>>> Reinhold Kliegl
>>> 
>>> 
>>> On Thu, Aug 12, 2010 at 10:44 AM, Paul Metzner <paul.metzner at gmail.com> wrote:
>>>> Dear all.
>>>> 
>>>> I am currently analyzing eye-tracking data and am interested in a main effect of condition (COND) plus its interaction with subjects' operation span (PCU) and the direction of a verb bias (1 or 2). The contrasts are:
>>>> 
>>>>> contrasts(COND)
>>>>>  [,1]
>>>>> a   -1
>>>>> b    1
>>>> 
>>>> and
>>>> 
>>>>> contrasts(DIR)
>>>>>  [,1]
>>>>> 1   -1
>>>>> 2    1
>>>> 
>>>> PCU is a continuous predictor which I centered by subtracting the mean (the problem does, however, persist when I split the sample into extreme groups and work with a categorial predictor). With the following model, I don't get a correlation between the fixed effects:
>>>> 
>>>>> Linear mixed model fit by REML
>>>>> Formula: RRT ~ COND * PCU * DIR + (1 | SUBJECT) + (1 | ITEM)
>>>>>    Data: fm3
>>>>>    AIC   BIC logLik deviance REMLdev
>>>>>  46733 46801 -23355    46768   46711
>>>>> Random effects:
>>>>>  Groups   Name        Variance Std.Dev.
>>>>>  SUBJECT  (Intercept)  8918.29  94.437
>>>>>  ITEM     (Intercept)   404.85  20.121
>>>>>  Residual             34881.69 186.766
>>>>> Number of obs: 3503, groups: SUBJECT, 59; ITEM, 59
>>>>> 
>>>>> Fixed effects:
>>>>>                Estimate Std. Error t value
>>>>> (Intercept)     122.900     12.963   9.481
>>>>> COND1            15.924      3.165   5.031
>>>>> PCU             139.411    120.025   1.162
>>>>> DIR1             -7.746      4.107  -1.886
>>>>> COND1:PCU        48.309     29.850   1.618
>>>>> COND1:DIR1       -3.396      3.164  -1.073
>>>>> PCU:DIR1        -26.835     29.814  -0.900
>>>>> COND1:PCU:DIR1   -8.069     29.838  -0.270
>>>>> 
>>>>> Correlation of Fixed Effects:
>>>>>             (Intr) COND1  PCU    DIR1   COND1:PCU COND1:D PCU:DI
>>>>> COND1        0.002
>>>>> PCU          0.004 -0.001
>>>>> DIR1         0.002 -0.004  0.004
>>>>> COND1:PCU   -0.001 -0.001  0.003  0.000
>>>>> COND1:DIR1  -0.001  0.000  0.000  0.007  0.021
>>>>> PCU:DIR1     0.005  0.000 -0.003  0.000 -0.009    -0.005
>>>>> COND1:PCU:D  0.000  0.021 -0.002 -0.004 -0.009    -0.001   0.011
>>>> 
>>>> But, since I'm mainly interested in the interactions and not so much the main effects of PCU and DIR, I changed the model to the following:
>>>> 
>>>>> Linear mixed model fit by REML
>>>>> Formula: RRT ~ COND + COND:PCU + COND:DIR + (1 | SUBJECT) + (1 | ITEM)
>>>>>    Data: fm3
>>>>>    AIC   BIC logLik deviance REMLdev
>>>>>  46744 46800 -23363    46769   46726
>>>>> Random effects:
>>>>>  Groups   Name        Variance Std.Dev.
>>>>>  SUBJECT  (Intercept)  8911.15  94.399
>>>>>  ITEM     (Intercept)   406.16  20.153
>>>>>  Residual             34869.91 186.735
>>>>> Number of obs: 3503, groups: SUBJECT, 59; ITEM, 59
>>>>> 
>>>>> Fixed effects:
>>>>>             Estimate Std. Error t value
>>>>> (Intercept)  122.962     12.959   9.489
>>>>> COND1         15.941      3.164   5.039
>>>>> CONDa:PCU     91.049    123.553   0.737
>>>>> CONDb:PCU    187.055    123.714   1.512
>>>>> CONDa:DIR1    -4.340      5.168  -0.840
>>>>> CONDb:DIR1   -11.160      5.204  -2.144
>>>>> 
>>>>> Correlation of Fixed Effects:
>>>>>            (Intr) COND1  CONDa:PCU CONDb:PCU CONDa:DIR1
>>>>> COND1       0.002
>>>>> CONDa:PCU   0.004 -0.001
>>>>> CONDb:PCU   0.004 -0.001  0.883
>>>>> CONDa:DIR1  0.002 -0.003  0.006     0.000
>>>>> CONDb:DIR1  0.001 -0.003  0.000     0.006     0.256
>>>> 
>>>> Not I do get a considerable correlation between the interactions. From the output (CONDa:?, CONDb:?), I infer that the model didn't always use helmert coding for condition but applied something else for the interactions. Is that right? When I code COND numerically as -1 and 1, the correlations turn out fine, which supports my conclusion. I would be very grateful for suggestions.
>>>> 
>>>> Thanks,
>>>> Paul
>>>> 
>>>> ---
>>>> Paul Metzner
>>>> 
>>>> Humboldt-Universit?t zu Berlin
>>>> Philosophische Fakult?t II
>>>> Institut f?r deutsche Sprache und Linguistik
>>>> 
>>>> Post: Unter den Linden 6 | 10099 Berlin | Deutschland
>>>> Besuch: Dorotheenstra?e 24 | 10117 Berlin | Deutschland
>>>> 
>>>> +49-(0)30-2093-9726
>>>> paul.metzner at gmail.com
>>>> http://amor.rz.hu-berlin.de/~metznerp/
>>>> 
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>> 
>> 
>> 
>> ---
>> Paul Metzner
>> 
>> Humboldt-Universit?t zu Berlin
>> Philosophische Fakult?t II
>> Institut f?r deutsche Sprache und Linguistik
>> 
>> Post: Unter den Linden 6 | 10099 Berlin | Deutschland
>> Besuch: Dorotheenstra?e 24 | 10117 Berlin | Deutschland
>> 
>> +49-(0)30-2093-9726
>> paul.metzner at gmail.com
>> http://amor.rz.hu-berlin.de/~metznerp/
>> 
>> 


---
Paul Metzner
Manfred-von-Richthofen-Str. 13
12101 Berlin
Deutschland

Tel.:  +49-(0)30-6730-9220
Mobil: +49-(0)17-8288-1059

paul.metzner at gmail.com
http://amor.rz.hu-berlin.de/~metznerp/



From reinhold.kliegl at gmail.com  Fri Aug 13 13:57:11 2010
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Fri, 13 Aug 2010 13:57:11 +0200
Subject: [R-sig-ME] Contrasts for interactions in lmer
In-Reply-To: <33E36232-BA52-4301-A168-1C4ED9B93F62@gmail.com>
References: <E76415FE-31A0-464F-8B83-84D78C636CAE@gmail.com>
	<AANLkTikjX5L3t0SJOJSoghEBYRYSB2rF1qRVfYLVzjZ0@mail.gmail.com>
	<B2205DE8-25B0-4061-B3D2-47967A4C061F@gmail.com>
	<AANLkTiknfjhRop29-T_vruhe+U2KFLo+_crtuUfyELjN@mail.gmail.com>
	<33E36232-BA52-4301-A168-1C4ED9B93F62@gmail.com>
Message-ID: <AANLkTind5httvnaoT-m7ka-oEyhzXv7iRhP5eyyZoB+e@mail.gmail.com>

This is not a list about eye-movement analyses, but very briefly I
would very strongly advise against including non-fixated words with a
zero value in any such analysis. There are many applications for
non-negative DVs where incrementing the DV by one to get around zero
before log-transforming them is perfectly ok. Fixation durations
simply belong not to these measures.
       I see two options. One is the one you already tried that is to
restrict the analysis to fixated words (and discuss this appropriately
and document the limits of generalizability of your results). Your
residual plot shows that from a statistical point of view this looks
ok. The fact that the interaction is not significant could well be
related to the reduced statistical power you have after throwing out
the zero-fixation cases, but the interaction may simply not be there,
too.
       Alternatively, you might want to switch to a dichotomous
variable for the critical words (fixated vs. not fixated), which would
require a generalized linear mixed model (fixated ~ . , family =
binomial).  This way you could keep all data in the analysis.

Reinhold Kliegl

On Fri, Aug 13, 2010 at 1:15 PM, Paul Metzner <paul.metzner at gmail.com> wrote:
> First, to clear things up, RRT is not reciprocal reading time, but re-reading time (time spent on a region after it was fixated and left).
>
>> I saw that now you use log-transformed DVs and that in my
>> experience is a good choice for durations collected in eye tracking.
>> Nevertheless you should check the distribution of model residuals to
>> back up this decision. Anyway, the log-transformation of RRT may have
>> lifted the t-value for the PCU ?X COND interaction. So I am curious
>> whether it did or not?
>
> I am very unsecure about whether or not i should log-transform. Because most of the duration variables include zeroes and because this is informative, as well, I don't want to exclude them. To still be able to log-transform, I would have to add a constant value and I am uncertain, if that is a valid operation. Plotting fitted values against residuals doesn't look good both when I use raw data and when I log-transform. The distribution of the model residuals look at least ok when zeroes are excluded (and even better with log(RRT)), but that would no longer be the DV that I am interested in. See these plots for illustration: http://amor.rz.hu-berlin.de/~metznerp/Rplot.pdf
> However, the log-transformation did indeed lift the t-value for PCU x COND, but only marginally (from 1.492 to 1.581). Generally, the log-transform seems to have little impact on the main effects and interactions (two or three effects disappear without log-transformation).
>
>
>
> On 13 Aug 2010, at 12:25, Reinhold Kliegl wrote:
>
>> Maybe I responded to quickly ...
>>
>> First, I guess for a two-level factor a sum contrast can also be
>> called a Helmert contrast; it is a bit unusual, I think.
>>
>> Second, the story about the fixed-effect correlations is complicated.
>> What I wrote for balanced designs returning a zero correlation matrix
>> of fixed effects assumes also that contrasts for the fixed effects are
>> orthogonal and that the variance components are specified only for the
>> intercepts, as you had set up your first model. If you specify a
>> non-orthogonal set of treatment contrasts, the fixed-effects
>> correlations will ?be 0.5. Thus, these correlations inform about the
>> correlations of the predictors in the model matrix.
>> ? ? ? ?Moreover, the story changes again ?if you estimate values for
>> parameters representing (co-)-variance components for random effects
>> in a balanced design, the fixed-effect correlations return values that
>> (sometimes?) are close to within-subject correlations (i.e.,
>> correlations unadjusted for shrinkage); maybe for balanced designs
>> with orthogonal predictors there is actually a specification under
>> which they are actually identical with them. ?This would be cool.
>>
>> Third, I think the fixed-effect part of the model you give now looks
>> fine; it is defensible (and sometimes necessary) to exclude
>> non-significant higher-order interactions. ?I still don't think you
>> need the variance components associated with COND and DIR for subjects
>> and you may be communicating the wrong thing, but opinions may differ
>> on this, because non-significance of these components is a thorny
>> issue.
>> ? ? ? ? In this case, as far as I can see, these correlations are not
>> really related to the COND x PCU interaction ?you are interested in.
>> Significant effect correlations ?can be mapped onto a different kind
>> of interaction (e.g.,, subjects with a large COND effect may tend to
>> have a larger DIR effect than subjects with a small COND effect), but
>> this does not bear on your PCU covariate, at least not directly. (This
>> could happen independent of a DIR x COND interaction in the
>> fixed-effect part of the model.)
>> ? ? ? ?I saw that now you use log-transformed DVs and that in my
>> experience is a good choice for durations collected in eye tracking.
>> Nevertheless you should check the distribution of model residuals to
>> back up this decision. Anyway, the log-transformation of RRT may have
>> lifted the t-value for the PCU ?X COND interaction. So I am curious
>> whether it did or not?
>>
>> Reinhold Kliegl
>>
>>
>> On Fri, Aug 13, 2010 at 10:20 AM, Paul Metzner <paul.metzner at gmail.com> wrote:
>>> Thank you for the quick answer!
>>>
>>>> (1) The Fixed Effects correlations are probably not what you are
>>>> after. For example, in a perfectly balanced design, these correlations
>>>> will be zero.
>>>
>>> They are not, but like you suggested, I wanted them to be at least close to zero. When I changed the model like mentioned before, I noticed an increase in fixed effects correlations and a curious change in contrast coding (see below), that I couldn't explain.
>>> My main interest are the fixed effects interactions. My hypothesis is that subjects with a higher PCU will be affected more strongly by the condition manipulation. Also, in some studies only one kind of verbs (DIR) has been shown to evoke the effect, hence the desired interaction of COND and DIR. But, because I really don't want individual differences over and above what is explained by PCU, I implemented the random effect term like you suggested and re-included the factors contributing to the interactions. My model now looks like this:
>>>
>>> lmer(log(RRT)~COND + PCU + COND:PCU + DIR + COND:DIR + (1+COND+DIR|SUBJECT) + (1|ITEM), data=fm3)
>>>
>>> Although including the covariance component did not improve model fit, I decided to leave it in the model for the reasons mentioned above. I did, however, exclude the three-way interaction COND:DIR:PCU.
>>>
>>>> (3) You used a sum contrast specification for the two factors (COND
>>>> and DIR). This is fine. For two-level factors there is no point in
>>>> specifying Helmert contrasts. So it is unclear what you referring to
>>>> in this context.
>>>
>>> Being a novice to contrast coding, I thought it was the same. Coincidentally, that seems to be the case for two-level factors. Thanks again for the suggestions!
>>>
>>> Paul
>>>
>>>
>>> On 12 Aug 2010, at 11:24, Reinhold Kliegl wrote:
>>>
>>>> There is a bit of evidence for an interaction of COND and PCU:
>>>>>> COND1:PCU ? ? ? ?48.309 ? ? 29.850 ? 1.618
>>>> If the t-value were larger it would indicate that slopes for the
>>>> regression of RRT on PCU differ between the two condition.
>>>>
>>>> There is no statistical support for the the interaction of DIR and PCU
>>>>>> PCU:DIR1 ? ? ? ?-26.835 ? ? 29.814 ?-0.900
>>>>
>>>> Now to some of your questions relating to correlations:
>>>> (1) The Fixed Effects correlations are probably not what you are
>>>> after. For example, in a perfectly balanced design, these correlations
>>>> will be zero.
>>>>
>>>> (2) I suspect what you might be after are effect correlations related
>>>> to subjects or items. Assuming cond and verb bias are within-subject
>>>> effects, you could get an estimate of the parameter for the covariance
>>>> component with the following specification.
>>>> RRT ~ COND * PCU * DIR + (1 + COND + DIR ?| SUBJECT) + (1 | ITEM)
>>>>
>>>> You should check whether adding these variance components to the model
>>>> improves the goodness fo fit, for example with an ANOVA..
>>>>
>>>> (3) You used a sum contrast specification for the two factors (COND
>>>> and DIR). This is fine. For two-level factors there is no point in
>>>> specifying Helmert contrasts. So it is unclear what you referring to
>>>> in this context.
>>>>
>>>> Finally, it is generally a bad idea to specify models with
>>>> interactions terms leaving out the factors contributing to the
>>>> interactions. If you do so, you need to have very good theoretical
>>>> reasons.
>>>>
>>>> Reinhold Kliegl
>>>>
>>>>
>>>> On Thu, Aug 12, 2010 at 10:44 AM, Paul Metzner <paul.metzner at gmail.com> wrote:
>>>>> Dear all.
>>>>>
>>>>> I am currently analyzing eye-tracking data and am interested in a main effect of condition (COND) plus its interaction with subjects' operation span (PCU) and the direction of a verb bias (1 or 2). The contrasts are:
>>>>>
>>>>>> contrasts(COND)
>>>>>> ?[,1]
>>>>>> a ? -1
>>>>>> b ? ?1
>>>>>
>>>>> and
>>>>>
>>>>>> contrasts(DIR)
>>>>>> ?[,1]
>>>>>> 1 ? -1
>>>>>> 2 ? ?1
>>>>>
>>>>> PCU is a continuous predictor which I centered by subtracting the mean (the problem does, however, persist when I split the sample into extreme groups and work with a categorial predictor). With the following model, I don't get a correlation between the fixed effects:
>>>>>
>>>>>> Linear mixed model fit by REML
>>>>>> Formula: RRT ~ COND * PCU * DIR + (1 | SUBJECT) + (1 | ITEM)
>>>>>> ? ?Data: fm3
>>>>>> ? ?AIC ? BIC logLik deviance REMLdev
>>>>>> ?46733 46801 -23355 ? ?46768 ? 46711
>>>>>> Random effects:
>>>>>> ?Groups ? Name ? ? ? ?Variance Std.Dev.
>>>>>> ?SUBJECT ?(Intercept) ?8918.29 ?94.437
>>>>>> ?ITEM ? ? (Intercept) ? 404.85 ?20.121
>>>>>> ?Residual ? ? ? ? ? ? 34881.69 186.766
>>>>>> Number of obs: 3503, groups: SUBJECT, 59; ITEM, 59
>>>>>>
>>>>>> Fixed effects:
>>>>>> ? ? ? ? ? ? ? ?Estimate Std. Error t value
>>>>>> (Intercept) ? ? 122.900 ? ? 12.963 ? 9.481
>>>>>> COND1 ? ? ? ? ? ?15.924 ? ? ?3.165 ? 5.031
>>>>>> PCU ? ? ? ? ? ? 139.411 ? ?120.025 ? 1.162
>>>>>> DIR1 ? ? ? ? ? ? -7.746 ? ? ?4.107 ?-1.886
>>>>>> COND1:PCU ? ? ? ?48.309 ? ? 29.850 ? 1.618
>>>>>> COND1:DIR1 ? ? ? -3.396 ? ? ?3.164 ?-1.073
>>>>>> PCU:DIR1 ? ? ? ?-26.835 ? ? 29.814 ?-0.900
>>>>>> COND1:PCU:DIR1 ? -8.069 ? ? 29.838 ?-0.270
>>>>>>
>>>>>> Correlation of Fixed Effects:
>>>>>> ? ? ? ? ? ? (Intr) COND1 ?PCU ? ?DIR1 ? COND1:PCU COND1:D PCU:DI
>>>>>> COND1 ? ? ? ?0.002
>>>>>> PCU ? ? ? ? ?0.004 -0.001
>>>>>> DIR1 ? ? ? ? 0.002 -0.004 ?0.004
>>>>>> COND1:PCU ? -0.001 -0.001 ?0.003 ?0.000
>>>>>> COND1:DIR1 ?-0.001 ?0.000 ?0.000 ?0.007 ?0.021
>>>>>> PCU:DIR1 ? ? 0.005 ?0.000 -0.003 ?0.000 -0.009 ? ?-0.005
>>>>>> COND1:PCU:D ?0.000 ?0.021 -0.002 -0.004 -0.009 ? ?-0.001 ? 0.011
>>>>>
>>>>> But, since I'm mainly interested in the interactions and not so much the main effects of PCU and DIR, I changed the model to the following:
>>>>>
>>>>>> Linear mixed model fit by REML
>>>>>> Formula: RRT ~ COND + COND:PCU + COND:DIR + (1 | SUBJECT) + (1 | ITEM)
>>>>>> ? ?Data: fm3
>>>>>> ? ?AIC ? BIC logLik deviance REMLdev
>>>>>> ?46744 46800 -23363 ? ?46769 ? 46726
>>>>>> Random effects:
>>>>>> ?Groups ? Name ? ? ? ?Variance Std.Dev.
>>>>>> ?SUBJECT ?(Intercept) ?8911.15 ?94.399
>>>>>> ?ITEM ? ? (Intercept) ? 406.16 ?20.153
>>>>>> ?Residual ? ? ? ? ? ? 34869.91 186.735
>>>>>> Number of obs: 3503, groups: SUBJECT, 59; ITEM, 59
>>>>>>
>>>>>> Fixed effects:
>>>>>> ? ? ? ? ? ? Estimate Std. Error t value
>>>>>> (Intercept) ?122.962 ? ? 12.959 ? 9.489
>>>>>> COND1 ? ? ? ? 15.941 ? ? ?3.164 ? 5.039
>>>>>> CONDa:PCU ? ? 91.049 ? ?123.553 ? 0.737
>>>>>> CONDb:PCU ? ?187.055 ? ?123.714 ? 1.512
>>>>>> CONDa:DIR1 ? ?-4.340 ? ? ?5.168 ?-0.840
>>>>>> CONDb:DIR1 ? -11.160 ? ? ?5.204 ?-2.144
>>>>>>
>>>>>> Correlation of Fixed Effects:
>>>>>> ? ? ? ? ? ?(Intr) COND1 ?CONDa:PCU CONDb:PCU CONDa:DIR1
>>>>>> COND1 ? ? ? 0.002
>>>>>> CONDa:PCU ? 0.004 -0.001
>>>>>> CONDb:PCU ? 0.004 -0.001 ?0.883
>>>>>> CONDa:DIR1 ?0.002 -0.003 ?0.006 ? ? 0.000
>>>>>> CONDb:DIR1 ?0.001 -0.003 ?0.000 ? ? 0.006 ? ? 0.256
>>>>>
>>>>> Not I do get a considerable correlation between the interactions. From the output (CONDa:?, CONDb:?), I infer that the model didn't always use helmert coding for condition but applied something else for the interactions. Is that right? When I code COND numerically as -1 and 1, the correlations turn out fine, which supports my conclusion. I would be very grateful for suggestions.
>>>>>
>>>>> Thanks,
>>>>> Paul
>>>>>
>>>>> ---
>>>>> Paul Metzner
>>>>>
>>>>> Humboldt-Universit?t zu Berlin
>>>>> Philosophische Fakult?t II
>>>>> Institut f?r deutsche Sprache und Linguistik
>>>>>
>>>>> Post: Unter den Linden 6 | 10099 Berlin | Deutschland
>>>>> Besuch: Dorotheenstra?e 24 | 10117 Berlin | Deutschland
>>>>>
>>>>> +49-(0)30-2093-9726
>>>>> paul.metzner at gmail.com
>>>>> http://amor.rz.hu-berlin.de/~metznerp/
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>
>>>
>>> ---
>>> Paul Metzner
>>>
>>> Humboldt-Universit?t zu Berlin
>>> Philosophische Fakult?t II
>>> Institut f?r deutsche Sprache und Linguistik
>>>
>>> Post: Unter den Linden 6 | 10099 Berlin | Deutschland
>>> Besuch: Dorotheenstra?e 24 | 10117 Berlin | Deutschland
>>>
>>> +49-(0)30-2093-9726
>>> paul.metzner at gmail.com
>>> http://amor.rz.hu-berlin.de/~metznerp/
>>>
>>>
>
>
> ---
> Paul Metzner
> Manfred-von-Richthofen-Str. 13
> 12101 Berlin
> Deutschland
>
> Tel.: ?+49-(0)30-6730-9220
> Mobil: +49-(0)17-8288-1059
>
> paul.metzner at gmail.com
> http://amor.rz.hu-berlin.de/~metznerp/
>
>



From laf.nilsson at gmail.com  Fri Aug 13 15:17:31 2010
From: laf.nilsson at gmail.com (Fredrik Nilsson)
Date: Fri, 13 Aug 2010 15:17:31 +0200
Subject: [R-sig-ME] examples in Applied Longitudinal Analysis
In-Reply-To: <87sk2jrg5m.fsf@kolob.sebmags.homelinux.org>
References: <87sk2jrg5m.fsf@kolob.sebmags.homelinux.org>
Message-ID: <AANLkTi=pc+KD6B6zRuGkmHUq0CHwJoab7+QpV_OHTXTG@mail.gmail.com>

Dear Sebastian and Doug,

I don't quite understand, is it the data sets in Applied Longitudinal
Analysis that is wanted? If so, I made a search on "fitzmaurice
applied longitudinal analysis data set" and found some data sets on
http://biosun1.harvard.edu/~fitzmaur/ala/ (the homepage of what I
assume is the "book"). Or is it the syntax of the analyses that you
(Sebastian) wants?

Hope this solves your problem and that the R-forge project on useful
data sets isn't terminated.

Best regards,

Fredrik


2010/8/12 Sebastian P. Luque <spluque at gmail.com>:
> Hi,
>
> Now that I'm reading Fitzmaurice et al's book, I recall having seen
> their examples using lme4 but cannot trace back what URL this was on.
> If someone knows where this is now, I'd appreciate the pointer. ?Thanks.
>
> --
> Seb
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Fri Aug 13 15:23:31 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 13 Aug 2010 08:23:31 -0500
Subject: [R-sig-ME] examples in Applied Longitudinal Analysis
In-Reply-To: <AANLkTi=pc+KD6B6zRuGkmHUq0CHwJoab7+QpV_OHTXTG@mail.gmail.com>
References: <87sk2jrg5m.fsf@kolob.sebmags.homelinux.org>
	<AANLkTi=pc+KD6B6zRuGkmHUq0CHwJoab7+QpV_OHTXTG@mail.gmail.com>
Message-ID: <AANLkTinZQt5wWo7waD1NH4wvzTsNNickqm+mkZiGj7xZ@mail.gmail.com>

On Fri, Aug 13, 2010 at 8:17 AM, Fredrik Nilsson <laf.nilsson at gmail.com> wrote:
> Dear Sebastian and Doug,
>
> I don't quite understand, is it the data sets in Applied Longitudinal
> Analysis that is wanted? If so, I made a search on "fitzmaurice
> applied longitudinal analysis data set" and found some data sets on
> http://biosun1.harvard.edu/~fitzmaur/ala/ (the homepage of what I
> assume is the "book"). Or is it the syntax of the analyses that you
> (Sebastian) wants?

I knew of the site with the data sets and had planned to create an R
package for the data sets but then I ran out of steam.  (I'm better at
starting projects than at finishing them.)  In my message I intended
to say that if anyone else wanted to create an R package of the data
sets and perhaps sample analyses corresponding to those in the book I
would be happy to support them.  To avoid potential confusion, I would
be happy to remove the project that I had started but not finished.

> Hope this solves your problem and that the R-forge project on useful
> data sets isn't terminated.
>
> Best regards,
>
> Fredrik
>
>
> 2010/8/12 Sebastian P. Luque <spluque at gmail.com>:
>> Hi,
>>
>> Now that I'm reading Fitzmaurice et al's book, I recall having seen
>> their examples using lme4 but cannot trace back what URL this was on.
>> If someone knows where this is now, I'd appreciate the pointer. ?Thanks.
>>
>> --
>> Seb
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From spluque at gmail.com  Fri Aug 13 16:11:20 2010
From: spluque at gmail.com (Sebastian P. Luque)
Date: Fri, 13 Aug 2010 09:11:20 -0500
Subject: [R-sig-ME] examples in Applied Longitudinal Analysis
In-Reply-To: <AANLkTinZQt5wWo7waD1NH4wvzTsNNickqm+mkZiGj7xZ@mail.gmail.com>
	(Douglas Bates's message of "Fri, 13 Aug 2010 08:23:31 -0500")
References: <87sk2jrg5m.fsf@kolob.sebmags.homelinux.org>
	<AANLkTi=pc+KD6B6zRuGkmHUq0CHwJoab7+QpV_OHTXTG@mail.gmail.com>
	<AANLkTinZQt5wWo7waD1NH4wvzTsNNickqm+mkZiGj7xZ@mail.gmail.com>
Message-ID: <87pqxmob5j.fsf@kolob.sebmags.homelinux.org>

On Fri, 13 Aug 2010 08:23:31 -0500,
Douglas Bates <bates-GX8I/T4BApV4piUD7e9S/g at public.gmane.org> wrote:

> On Fri, Aug 13, 2010 at 8:17 AM, Fredrik Nilsson <laf.nilsson-Re5JQEeQqe8AvxtiuMwx3w at public.gmane.org> wrote:
>> Dear Sebastian and Doug,

>> I don't quite understand, is it the data sets in Applied Longitudinal
>> Analysis that is wanted? If so, I made a search on "fitzmaurice
>> applied longitudinal analysis data set" and found some data sets on
>> http://biosun1.harvard.edu/~fitzmaur/ala/ (the homepage of what I
>> assume is the "book"). Or is it the syntax of the analyses that you
>> (Sebastian) wants?

> I knew of the site with the data sets and had planned to create an R
> package for the data sets but then I ran out of steam.  (I'm better at
> starting projects than at finishing them.)  In my message I intended
> to say that if anyone else wanted to create an R package of the data
> sets and perhaps sample analyses corresponding to those in the book I
> would be happy to support them.  To avoid potential confusion, I would
> be happy to remove the project that I had started but not finished.

Yes, I was looking for some worked examples using lme4 to learn more
about the syntax in lme4 as I read the book, since I'm more used to
nlme.  I can volunteer to package the data sets first, and later include
some analyses from the book with some help for sure.

AFAICS, there are no files at all in the R-Forge project AppLong.
Should I start this as another R-Forge project/package, perhaps naming
it ALA (to follow the convention at CRAN from this kind of package), or
keep the project Dr. Bates started and develop there?


-- 
Seb



From marc_schwartz at me.com  Fri Aug 13 16:24:59 2010
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 13 Aug 2010 09:24:59 -0500
Subject: [R-sig-ME] longitudinal with 2 time points
In-Reply-To: <111355.9211.qm@web56301.mail.re3.yahoo.com>
References: <439946.26259.qm@web56301.mail.re3.yahoo.com>
	<B80EFDF8-B705-4EBA-A80E-9A4354F08353@anu.edu.au>
	<alpine.WNT.2.00.1008110532370.640@TED2>
	<8D383357-99BA-4447-A93B-0D8FC7AF7279@me.com>
	<323634.22474.qm@web56305.mail.re3.yahoo.com>
	<FB025028-0C67-4B59-9757-FC2305C07EA6@me.com>
	<111355.9211.qm@web56301.mail.re3.yahoo.com>
Message-ID: <5992F7D6-7C3D-4AC2-A8AD-3D9AED2CA3D5@me.com>

John,

That you are asking this question indicates that either you have yet to read the article or that you need to re-read it, as you have not comprehended the content.

The beta coefficient for treatment IS the difference in mean glucose change between baseline and 4 weeks **attributable to treatment**, after adjusting for any baseline differences in glucose between the two groups. That is also presuming that there is no interaction at baseline.

For example, let's say that the beta for treatment is -20. Then, at 4 weeks, given the same baseline glucose level, we would predict that, on average, the treatment group will have a glucose level 20 mg/dl less than the control group. 

In the absence of an interaction, we would estimate the same average treatment difference at 4 weeks of 20 mg/dl whether the baseline glucose was 300 mg/dl or 100 mg/dl. 

However, given regression to the mean, we might reasonably expect the patient with a 300 mg/dl baseline level to have a greater mean reduction at 4 weeks as compared to the patient with a 100 mg/dl baseline level. 

We might also expect a patient with a glucose level at the low end of the baseline range (eg. 50 mg/dl) to experience an average increase in glucose level at 4 weeks, presuming that your inclusion/exclusion criteria permitted patients with below normal glucose levels. But the difference will still be, on average, 20 mg/dl between the two treatment groups.

So the patient with a 300 mg/dl baseline level might have an average reduction to 200 mg/dl at 4 weeks on the control treatment, whereas the same patient on the active treatment would have an average reduction to 180 mg/dl (a difference of -20).

The patient with a 100 mg/dl baseline level might have an average reduction to 90 mg/dl at 4 weeks on the control treatment, whereas the same patient on the active treatment would have an average reduction to 70 mg/dl (again, a difference of -20).

The patient with a 50 mg/dl baseline level might have an average increase to 90 mg/dl at 4 weeks on the control treatment, whereas the same patient on the active treatment would have an average increase to 70 mg/dl (yet again, a difference of -20).

So your conclusion would be that on average, between baseline and 4 weeks, glucose levels were reduced by 20 mg/dl more in the active treatment group relative to control.

This difference is the vertical separation in the two parallel fitted regression lines as shown in the figure in the paper.

So the method is answering exactly the question the investigator is asking.

Marc


On Aug 13, 2010, at 1:02 AM, array chip wrote:

> Marc,
> 
> Thanks for sharing your insights. Let's take this model as an example:
> 
>  lm(wk4.glucose ~ baseline.glucose + treatment + gender + age)
> 
> Because the investigator is interested in knowing whether the CHANGE of glucose 
> in week 4 from baseline is different between treatment and control, Is it still 
> legitimate to ask whether and HOW can we test this hypothesis? I think the 
> coefficient of the treatment factor is only testing whether the week 4 glucose 
> level is different between treatment and control, but not testing whether 
> the CHANGE of week 4 glucose level with respect to baseline is different between 
> treatment and control.
> 
> Thanks again for your suggestion.
> 
> Yi
> 
> 
> 
>  
> 
> 
> ----- Original Message ----
> From: Marc Schwartz <marc_schwartz at me.com>
> To: array chip <arrayprofile at yahoo.com>
> Cc: Charles E. (Ted) Wright <cewright at uci.edu>; John Maindonald 
> <john.maindonald at anu.edu.au>; r-sig-mixed-models at r-project.org
> Sent: Thu, August 12, 2010 6:02:29 AM
> Subject: Re: [R-sig-ME] longitudinal with 2 time points
> 
> Hi John,
> 
> If you read that article, you will see that your use of delta.y as the dependent 
> variable does not make sense.
> 
> Thus, I would re-express your model 5 as:
> 
>   lm(wk4.glucose ~ baseline.glucose + treatment + gender + age)
> 
> and as noted, check for the interaction between baseline glucose and treatment:
> 
>   lm(wk4.glucose ~ baseline.glucose * treatment + gender + age)
> 
> 
> You might also want to consider using a spline function on age, presuming that 
> age is hopefully measured as a continuous variable (eg. not ordinal groups).
> 
> Since the ANCOVA based approach described in the paper is essentially an OLS 
> linear regression, you can of course include the additional covariates for 
> adjustment. If the interaction term p value is >0.1 (a common threshold), you 
> can remove it and the beta coefficient and its CIs for the treatment factor is 
> your estimated treatment effect relative to your control.
> 
> For the presentation of the results, besides the obvious tabular summaries and 
> the scatter/regression lines plot, include a series of plots showing selected 
> baseline values and the treatment versus control predicted follow up values and 
> CIs for the same baseline value in each plot. This visually shows the common 
> estimated treatment effect for each baseline value, which will also tend to 
> reveal regression to the mean. This presentation is especially helpful if the 
> interaction term is retained, which therefore shows how the treatment effect 
> varies and will reverse, over the range of the baseline values. You can select a 
> series of clinically relevant values over the range of the observed baseline 
> values, and/or by default, select a five number plus mean series over the 
> observed baseline values.
> 
> I don't see a role for a mixed effects model here, given that this is a pretty 
> straightforward "change from baseline" type design, but there are many here with 
> greater expertise than I. If this was a cross-over design, you have multiple 
> measures of glucose for each patient at each time point, more than two time 
> points, or a multi-center study, then a mixed effects model would make more 
> sense to me.
> 
> HTH,
> 
> Marc
> 
> 
> 
> On Aug 12, 2010, at 12:39 AM, array chip wrote:
> 
>> Hi Marc,
>> 
>> Thanks for the reference. I will definitely read it. Please see my reponse to 
>> John's reply. Your model is another model I should add to the 5 models I 
>> proposed in that email. What's your overall thoughts on these different 
> models?
>> 
>> Thank you for sharing.
>> 
>> John
>> 
>> 
>> 
>> ----- Original Message ----
>> From: Marc Schwartz <marc_schwartz at me.com>
>> To: Charles E. (Ted) Wright <cewright at uci.edu>; array chip 
>> <arrayprofile at yahoo.com>
>> Cc: John Maindonald <john.maindonald at anu.edu.au>; 
>> r-sig-mixed-models at r-project.org
>> Sent: Wed, August 11, 2010 6:20:13 AM
>> Subject: Re: [R-sig-ME] longitudinal with 2 time points
>> 
>> Hi,
>> 
>> I'll throw in a reference that covers some of these issues:
>> 
>> Statistics Notes
>> Analysing controlled trials with baseline and follow up measurements
>> Vickers and Altman
>> BMJ. 2001 November 10; 323(7321): 1123?1124.
>> https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1121605/
>> 
>> 
>> The basic model specification would of course be:
>> 
>>   lm(4Wks ~ Baseline + Group)
>> 
>> You will also want to test for an interaction between the baseline score and 
>> your grouping factor, in case the observed group (eg. treatment) effect is 
>> dependent upon the value of the baseline measurement. In this case, unlike in 
>> the above paper, you of course end up with crossing fitted regression lines, 
>> rather than parallel lines.
>> 
>> HTH,
>> 
>> Marc Schwartz
>> 
>> 
>> On Aug 11, 2010, at 7:34 AM, Charles E. (Ted) Wright wrote:
>> 
>>> Keep in mind that running an ANOVA on the difference is not the same thing as 
> 
>>> using the baseline data as a covariate in an ANOVA on the Week 4 data. 
>>> Essentially the ANOVA on the differences is like the ANCOVA with the slope 
>>> constrained to be 1.
>>> 
>>> Ted Wright
>>> 
>>> On Wed, 11 Aug 2010, John Maindonald wrote:
>>> 
>>>> All these are possibilities, except maybe making baseline measurement
>>>> a random factor.  This would make sense only if data divide into groups,
>>>> and you want the baseline effect to vary randomly from group to group.
>>>> That may limit your ability to estimate parameters that are of interest.
>>>> In most circumstances that I am familiar with, it makes better sense to
>>>> treat baseline effect as fixed.
>>>> 
>>>> John.
>>>> 
>>>> On 11/08/2010, at 8:11 AM, array chip wrote:
>>>> 
>>>>> Hi, I am wondering if it is still meaningful to run a mixed model if a
>>>>> longitudinal dataset has only 2 time points (baseline and week 4)? Would it 
> 
>>> be
>>>>> more appropriate to simply take the difference between the 2 time points and 
>> 
>>>>> run
>>>>> ANOVA (ANCOVA) on the difference? what about still running mixed model on 
>> the
>>>>> difference of the 2 time points, but adding baseline measurement as a 
> random
>>>>> factor?
>>>>> 
>>>>> Thanks for sharing your thoughts.
>>>>> 
>>>>> John



From bates at stat.wisc.edu  Fri Aug 13 17:03:23 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 13 Aug 2010 10:03:23 -0500
Subject: [R-sig-ME] examples in Applied Longitudinal Analysis
In-Reply-To: <87pqxmob5j.fsf@kolob.sebmags.homelinux.org>
References: <87sk2jrg5m.fsf@kolob.sebmags.homelinux.org>
	<AANLkTi=pc+KD6B6zRuGkmHUq0CHwJoab7+QpV_OHTXTG@mail.gmail.com>
	<AANLkTinZQt5wWo7waD1NH4wvzTsNNickqm+mkZiGj7xZ@mail.gmail.com>
	<87pqxmob5j.fsf@kolob.sebmags.homelinux.org>
Message-ID: <AANLkTi=wPnf8Cx_y9r7-NWohpzBEocgY63owan2kT69h@mail.gmail.com>

On Fri, Aug 13, 2010 at 9:11 AM, Sebastian P. Luque <spluque at gmail.com> wrote:
> On Fri, 13 Aug 2010 08:23:31 -0500,
> Douglas Bates <bates-GX8I/T4BApV4piUD7e9S/g at public.gmane.org> wrote:
>
>> On Fri, Aug 13, 2010 at 8:17 AM, Fredrik Nilsson <laf.nilsson-Re5JQEeQqe8AvxtiuMwx3w at public.gmane.org> wrote:
>>> Dear Sebastian and Doug,
>
>>> I don't quite understand, is it the data sets in Applied Longitudinal
>>> Analysis that is wanted? If so, I made a search on "fitzmaurice
>>> applied longitudinal analysis data set" and found some data sets on
>>> http://biosun1.harvard.edu/~fitzmaur/ala/ (the homepage of what I
>>> assume is the "book"). Or is it the syntax of the analyses that you
>>> (Sebastian) wants?
>
>> I knew of the site with the data sets and had planned to create an R
>> package for the data sets but then I ran out of steam. ?(I'm better at
>> starting projects than at finishing them.) ?In my message I intended
>> to say that if anyone else wanted to create an R package of the data
>> sets and perhaps sample analyses corresponding to those in the book I
>> would be happy to support them. ?To avoid potential confusion, I would
>> be happy to remove the project that I had started but not finished.
>
> Yes, I was looking for some worked examples using lme4 to learn more
> about the syntax in lme4 as I read the book, since I'm more used to
> nlme. ?I can volunteer to package the data sets first, and later include
> some analyses from the book with some help for sure.
>
> AFAICS, there are no files at all in the R-Forge project AppLong.
> Should I start this as another R-Forge project/package, perhaps naming
> it ALA (to follow the convention at CRAN from this kind of package), or
> keep the project Dr. Bates started and develop there?
>

I am happy to have you be added to the AppLong project.  If you have
an R-forge login then please look up the AppLong project and click on
the "request to join" link.



From Greg.Snow at imail.org  Fri Aug 13 19:52:27 2010
From: Greg.Snow at imail.org (Greg Snow)
Date: Fri, 13 Aug 2010 11:52:27 -0600
Subject: [R-sig-ME] Worked analysis of owl data
In-Reply-To: <8DF140D0-72A1-48AA-8342-28A1C8DC45A0@st-andrews.ac.uk>
References: <517342A2-7F66-4F17-BE98-4BBB670D2DD8@st-andrews.ac.uk>
	<8DF140D0-72A1-48AA-8342-28A1C8DC45A0@st-andrews.ac.uk>
Message-ID: <B37C0A15B8FB3C468B5BC7EBC7DA14CC633A8C7B94@LP-EXMBVS10.CO.IHC.COM>

One suggestion for looking at the residual plots is to simulate data that matches your underlying model (and all the assumptions that you want to check with the residual plots are true), then discretize the response into the 5 levels, run the regression and look at the residual plot when the assumptions are true.  Do this a few times, then compare the residual plot from your actual data to see if it looks different.  The vis.test function in the TeachingDemos package can help with the comparisons if you want.

For what you hope to do with this model, a Bayesian approach may work better, you can explicitly model the underlying continuous variable and the rule to convert that to the 5 level variable.  Predicting outcomes or probabilities of outcomes for the next individual (observed species or new species) is then natural for Bayesian models.

Just don't tell my Bayesian friends that I recommend this, I hate it when they get all smug.

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at imail.org
801.408.8111


> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-
> models-bounces at r-project.org] On Behalf Of Chris Mcowen
> Sent: Friday, August 13, 2010 1:27 AM
> To: Ben Bolker; Jarrod Hadfield
> Cc: R-mixed models mailing list
> Subject: Re: [R-sig-ME] Worked analysis of owl data
> 
> Hi Jarrord/Ben and list
> 
> Thanks for this.
> 
> I have extended the model to a gaussian error with 5 level response
> variable (IUCN- 1-5) this is a as discrete variable but is an
> approximation of an underlying continuous spectrum.
> 
> The reason i am worrying about the residuals ( please follow link to a
> new picture - https://files.me.com/chrismcowen/0v6ys4)
> 
>  Is that i want to use the fitted values from the model to predict
> extinction risk ( the response variable) - that way i could include
> species that don't have a extinction risk, species that weren't in the
> original model, but for which i have all the necessary life history
> data. However i am unsure if this is possible with lmer?
> 
> I hope this makes sense, and thank you for your help
> 
> Chris
> 
> 
> On 12 Aug 2010, at 18:47, Jarrod Hadfield wrote:
> 
> Hi Ben/Chris,
> 
> I agree and would not be unduly worried about the residuals from a
> binary model. They always look odd if you are used to looking at
> residuals from a Guassian model, and I'm not sure whether its possible
> to diagnose problems using them (except complete separation perhaps).
> 
> Cheers,
> 
> Jarrod
> 
> 
> On 12 Aug 2010, at 16:41, Ben Bolker wrote:
> 
> > On Thu, Aug 12, 2010 at 5:24 AM, Chris Mcowen <cm744 at st-
> andrews.ac.uk> wrote:
> >> Hi Ben,
> >>
> >> I have been working through the above data set
> >>
> >> I have followed the code to NOT account for random effects in my
> model,  which has worked well - thanks, however as i have a binary
> response my residual plot shows this
> >>
> >> https://files.me.com/chrismcowen/i4jxlw
> >>
> >> Is there a way to Plot predictions and confidence intervals with
> residuals like this?
> >
> > Why not?  The recipes in the Owls example should work, I think ...
> > with the proviso that (as Jarrod Hadfield said) you have to be very
> > careful in defining what response you are predicting the mean _of_ --
> > if there are any random effects (other than the intrinsic variability
> > of the binary response) that are non-zero, and if you try to
> calculate
> > the mean of the predicted response on the original (rather than the
> > link/logit scale), they will affect the prediction of the mean.
> >
> > You seem quite concerned about the odd distributions of the
> > residuals. It's good to be careful, but as far I have seen so far
> what
> > you are seeing is just the nature of binary residuals.  One way to
> get
> > a handle on what the residuals should look like is to simulate data
> > from a situation reasonably similar to (although often a bit simpler
> > than) what you think is going on with your data, so that you *know*
> > the model is specified correctly, and see what the residuals from the
> > fitted model look like in that case.
> >
> 
> 
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From mlarkin at rsmas.miami.edu  Sat Aug 14 04:22:39 2010
From: mlarkin at rsmas.miami.edu (Michael Larkin)
Date: Fri, 13 Aug 2010 22:22:39 -0400
Subject: [R-sig-ME] stuck with maximum likelihood problem
Message-ID: <000001cb3b57$911f1d00$b35d5700$@miami.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100813/00578782/attachment.pl>

From bbolker at gmail.com  Sat Aug 14 19:01:41 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 14 Aug 2010 13:01:41 -0400
Subject: [R-sig-ME] stuck with maximum likelihood problem
In-Reply-To: <000001cb3b57$911f1d00$b35d5700$@miami.edu>
References: <000001cb3b57$911f1d00$b35d5700$@miami.edu>
Message-ID: <AANLkTikxPdu2MRN0bQj+bpJUu5-p3tKbR1d=BqH7tOiy@mail.gmail.com>

> Here is my situation in a simple description:
>
> I have an equation that has one parameter and 3 data variables. ?I need to
> get R to determine the parameter value that maximizes the sum calculated
> from the equation.
>
> I know this is simple problem but my search into functions of R got me
> confused. ?I think I should use the optim function but I also read about the
> trust function. ?I found some very useful examples for the optim function
> but they related to specific distributions (i.e. normal, poisson)
>

  Your question is pretty vague ...

  Suppose you define a function  objfun() that takes the parameter as
its first argument (for simplicity, let's say that it just uses the
values of the
data drawn from the global workspace) so that objfun(p) returns the value
you are trying to maximize.

  Then

  optim(startval,fn=objfun,control=list(fnscale=-1))

  should find the value of the parameter that maximizes the function
(by default optim() does minimization: the fnscale=-1 option makes
it do maximization instead



From maj at waikato.ac.nz  Sun Aug 15 01:32:22 2010
From: maj at waikato.ac.nz (Murray Jorgensen)
Date: Sun, 15 Aug 2010 11:32:22 +1200
Subject: [R-sig-ME] stuck with maximum likelihood problem
In-Reply-To: <000001cb3b57$911f1d00$b35d5700$@miami.edu>
References: <000001cb3b57$911f1d00$b35d5700$@miami.edu>
Message-ID: <4C672786.5030601@waikato.ac.nz>

Have you considered doing the math needed to solve the score equation? 
You will need to solve a single nonlinear equation

        g(theta) = 0

If you cant do this analytically you should be able to transform it to 
the form

        theta = h(theta)

and then iterate on h or h-inverse from a suitable starting value to 
find a fixed point.

Murray Jorgensen

On 14/08/10 2:22 PM, Michael Larkin wrote:
> I know this is a mixed effect model email list and I apologize if I annoy
> anyone.  I figured since I was already a member of this list I could try my
> question here first.  Also, I have received VERY helpful responses from this
> list in the past and I am hoping to repeat this.
>
>
>
> Here is my situation in a simple description:
>
> I have an equation that has one parameter and 3 data variables.  I need to
> get R to determine the parameter value that maximizes the sum calculated
> from the equation.
>
>
>
> I know this is simple problem but my search into functions of R got me
> confused.  I think I should use the optim function but I also read about the
> trust function.  I found some very useful examples for the optim function
> but they related to specific distributions (i.e. normal, poisson)
>
>
>
> Any advice would be greatly appreciated.
>
>
>
> Mike
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz  majorgensen at ihug.co.nz        Fax 7 838 4155
Phone  +64 7 838 4773 wk    Home +64 7 825 0441   Mobile 021 0200 8350



From richard.feldman at mail.mcgill.ca  Sun Aug 15 22:29:08 2010
From: richard.feldman at mail.mcgill.ca (Richard Feldman)
Date: Sun, 15 Aug 2010 16:29:08 -0400
Subject: [R-sig-ME] Selecting random effects in lme4: ML vs. QAICc
Message-ID: <4C684E14.2080204@mail.mcgill.ca>

Hello all,

I am trying to select between two models that differ in their random 
effects. Running a likelihood test gives me a different result than 
using information criteria.

My models:

model.1 <- glmer(Y ~ V1 + V2 + V1:V2 + (V2|SITE), data=Data, family = 
quasipoisson, REML = TRUE)

model.2 <- glmer(Y ~ V1 + V2 + V1:V2 + (1|SITE), data=Data, family = 
quasipoisson, REML = TRUE)

I use quasipoisson because they are highly overdispersed:

lme4:::sigma(model.1)
#5.886659
lme4:::sigma(model.2)
#101.6434

The results of the likelihood test:
(I know that technically one should not use (RE)ML for 
quasi-distributions. However the results are nearly identical whether I 
use quasipoisson or poisson as the family)

anova(model.2, model.1)

#         Df    AIC    BIC   logLik  Chisq Chi Df Pr(>Chisq)
#model.2  9 4648.3 4665.1 -2315.13
#model.1 14  346.8  373.0  -159.39 4311.5      5  < 2.2e-16 ***

Now, I run the same models with a poisson distribution and then adjust 
the AIC by the overdispersion and the number of parameters to obtain 
QAICc. With all these penalties taken into account, model.2 has the 
lowest QAICc. My gut instinct is to go with model.1, however, because 
the overdispersion of model.2 is so high that perhaps it shouldn't even 
be a candidate model. On the other hand, perhaps adjusting the AIC 
really does put the two models on a more level playing field.

Does anyone in the community have any guidance on this matter?

Much appreciated and thanks in advance!

Richard

-- 
Richard Feldman, PhD Candidate
Dept. of Biological Sciences, McGill University
W3/5 Stewart Biology Building
1205 Docteur Penfield
Montreal, QC H3A 1B1
514-212-3466
richard.feldman at mail.mcgill.ca



From bbolker at gmail.com  Sun Aug 15 23:46:06 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 15 Aug 2010 17:46:06 -0400
Subject: [R-sig-ME] Selecting random effects in lme4: ML vs. QAICc
In-Reply-To: <4C684E14.2080204@mail.mcgill.ca>
References: <4C684E14.2080204@mail.mcgill.ca>
Message-ID: <4C68601E.4030609@gmail.com>

  There are a number of issues here, I will comment in-line ...

Richard Feldman wrote:
> I am trying to select between two models that differ in their random
> effects. Running a likelihood test gives me a different result than
> using information criteria.

  In general you shouldn't be applying both methods in the same
analysis, except for pedagogical/self-teaching purposes. The two tests
answer different questions, and trying both leads to the temptation to
cherry-pick.
>
> My models:
>
> model.1 <- glmer(Y ~ V1 + V2 + V1:V2 + (V2|SITE), data=Data, family =
> quasipoisson, REML = TRUE)
>
> model.2 <- glmer(Y ~ V1 + V2 + V1:V2 + (1|SITE), data=Data, family =
> quasipoisson, REML = TRUE)

  Specifying REML=TRUE has no effect in glmer models.  (I don't know
offhand whether you got a warning, arguably you should have.)  Note that
in ?glmer there is no REML argument specified for glmer -- there is no
warning because it gets swallowed by the optional "..." argument.

> I use quasipoisson because they are highly overdispersed:
>
> lme4:::sigma(model.1) #5.886659 lme4:::sigma(model.2) #101.6434
 
  If you are going to fit a quasi-likelihood model then generally you
should find sigma for the most complex model (model 1 in your case) and
then apply the same estimated value of sigma for all models.

> The results of the likelihood test: (I know that technically one
> should not use (RE)ML for quasi-distributions. However the results
> are nearly identical whether I use quasipoisson or poisson as the
> family)

  Clarification: generally one should not use likelihood ratio tests (ML
vs REML is a separate issue) at all on quasi-likelihood fits, although
Venables and Ripley (MASS, p. 210) do suggest using an F test on the
scaled difference in deviance (this is implemented for GLMs with the
'test="F"' option to anova.glm()).  (In contrast, they say in the same
section that one *cannot* use AIC in this case, because one doesn't have
a real likelihood -- presumably they don't agree with the line of
reasoning leading to QAIC.)

   I'm also assuming that your sample size is large enough that the LRT applies (which is often a problem with GLMMs 
if the number of random-effects levels is small)


> anova(model.2, model.1)
>
> #         Df    AIC    BIC   logLik  Chisq Chi Df Pr(>Chisq) #model.2
> 9 4648.3 4665.1 -2315.13 #model.1 14  346.8  373.0  -159.39 4311.5
> 5  < 2.2e-16 ***

  Besides the fact that you shouldn't do this, it's unlikely that
anova() is correcting for overdispersion.
>
> Now, I run the same models with a poisson distribution and then
> adjust the AIC by the overdispersion and the number of parameters to
> obtain QAICc. With all these penalties taken into account, model.2
> has the lowest QAICc. My gut instinct is to go with model.1, however,
> because the overdispersion of model.2 is so high that perhaps it
> shouldn't even be a candidate model. On the other hand, perhaps
> adjusting the AIC really does put the two models on a more level
> playing field.

  How did you calculate overdispersion?  If you're going to do this (and
there are still some questions about whether this works) you should use
sigma^2, not sigma, as your estimate of overdispersion.  If you are
(heaven forbid) following the supplementary material of the Bolker et al
2009 TREE article, please look in the worked examples section of
glmm.wikidot.com for an updated and corrected version.



From drasnarova.alena at gmail.com  Mon Aug 16 11:58:13 2010
From: drasnarova.alena at gmail.com (=?ISO-8859-2?Q?Alena_Dra=B9narov=E1?=)
Date: Mon, 16 Aug 2010 11:58:13 +0200
Subject: [R-sig-ME] Questions about mix models
Message-ID: <AANLkTikz63RfPBi6mi4Qk-aVmuUM1-Tma0KH_AeJedWH@mail.gmail.com>

Dear all,
 I have so complicated data and I am trying to gain correct results from them.

I am interested in factors influencing density and diversity of the
soil seed bank on alluvial meadows. I have nested design of my
experiment: 35 meadows (mead=M1-M35), three transects on each meadow
(trans=T1-T3) and  2 plots on each transect (top=A,B).
I found out  a lot of information (about soil properties, moisure,
litter, biomass, vegetation diversity and management).
At first, I tried to use glmer, but sometimes there was error message:

> a2<-glmer(number~top+depth+HPV+K+VVS+(1|mead/trans/top),data=dat,family=poisson)
Warning messages:
1: In mer_finalize(ans) :
 Cholmod warning 'not positive definite' at
file:../Cholesky/t_cholmod_rowfac.c, line 432
2: In mer_finalize(ans) :
 Cholmod warning 'not positive definite' at
file:../Cholesky/t_cholmod_rowfac.c, line 432
3: In mer_finalize(ans) : false convergence (8)

So, I decided to use MCMCglmm, but I am not sure with fitting the
model. I tried to fitt it by this way (example below is for one
factor):

> prior=list(R=list(V=1, n=0, fix=1), G=list(G1 = list(V =1,n=1),G2=list(V=1,n=1),G3=list(V=1,n=1)))
> m1 <- MCMCglmm(number ~ as.factor(top), random=~mead+mead:trans+mead:trans:top, family = "poisson", data=dat,prior=prior)
I am not sure with define prior and random effect.

I will be very happy, if anybody write me own experiences with these
models and similar data and help me which model is the best to use.

With kind regards
Alena Dra?narov?



From Angelo.Franchini at bristol.ac.uk  Mon Aug 16 12:57:31 2010
From: Angelo.Franchini at bristol.ac.uk (Angelo Franchini)
Date: Mon, 16 Aug 2010 11:57:31 +0100 (BST)
Subject: [R-sig-ME] (no subject)
Message-ID: <53344.81.155.18.201.1281956251.squirrel@webmail.bris.ac.uk>

Hello,

I am trying to use the lme function part of the nlme package to perform a
random-effects meta-analysis at arm level, but I am not sure what is the
proper use that I should make of the weights option for this situation.
(By arm level I mean a meta-analysis that considers separately both
treatment arm and control arm outcomes, and not just the contrast between
them.)

The command that I am using is:
  out <- lme(o~s+t-1, random=~t-1 | s, weights=(~ se.o^2))

with
s as study/trial identifier
t as 0/1 for control/treatment arm
o as observed outcome in control or treatment arm
se.o as standard error of that outcome measure


I have looked through the R archives and forum and generally on the
Internet for clear indications on what to do, but have not found any.
Could anyone please help with that?

Many thanks.

Angelo



From julien.beguin.1 at ulaval.ca  Mon Aug 16 15:26:27 2010
From: julien.beguin.1 at ulaval.ca (Julien Beguin)
Date: Mon, 16 Aug 2010 09:26:27 -0400
Subject: [R-sig-ME] RE :  Questions about mix models
In-Reply-To: <AANLkTikz63RfPBi6mi4Qk-aVmuUM1-Tma0KH_AeJedWH@mail.gmail.com>
References: <AANLkTikz63RfPBi6mi4Qk-aVmuUM1-Tma0KH_AeJedWH@mail.gmail.com>
Message-ID: <B56D7C27B4408243B93FBC46ABECB5A0011A8EE9AA84@EXCH-MBX-F.ulaval.ca>

Alena,

1) Can you join a summary of your data. Is it a balanced design?

2) Not sure to understand how your model assigns the residual error... Have you tried to exclude variable 'top' from the random component: only (1|mead/trans) ? does it improve convergence? and do you get the appropriate number of degree of freedom for your fixed effects (based on your experimental design)? 

Julien Beguin
________________________________________
De : r-sig-mixed-models-bounces at r-project.org [r-sig-mixed-models-bounces at r-project.org] de la part de Alena Dra?narov? [drasnarova.alena at gmail.com]
Date d'envoi : 16 ao?t 2010 05:58
? : r-sig-mixed-models at r-project.org
Objet : [R-sig-ME] Questions about mix models

Dear all,
 I have so complicated data and I am trying to gain correct results from them.

I am interested in factors influencing density and diversity of the
soil seed bank on alluvial meadows. I have nested design of my
experiment: 35 meadows (mead=M1-M35), three transects on each meadow
(trans=T1-T3) and  2 plots on each transect (top=A,B).
I found out  a lot of information (about soil properties, moisure,
litter, biomass, vegetation diversity and management).
At first, I tried to use glmer, but sometimes there was error message:

> a2<-glmer(number~top+depth+HPV+K+VVS+(1|mead/trans/top),data=dat,family=poisson)
Warning messages:
1: In mer_finalize(ans) :
 Cholmod warning 'not positive definite' at
file:../Cholesky/t_cholmod_rowfac.c, line 432
2: In mer_finalize(ans) :
 Cholmod warning 'not positive definite' at
file:../Cholesky/t_cholmod_rowfac.c, line 432
3: In mer_finalize(ans) : false convergence (8)

So, I decided to use MCMCglmm, but I am not sure with fitting the
model. I tried to fitt it by this way (example below is for one
factor):

> prior=list(R=list(V=1, n=0, fix=1), G=list(G1 = list(V =1,n=1),G2=list(V=1,n=1),G3=list(V=1,n=1)))
> m1 <- MCMCglmm(number ~ as.factor(top), random=~mead+mead:trans+mead:trans:top, family = "poisson", data=dat,prior=prior)
I am not sure with define prior and random effect.

I will be very happy, if anybody write me own experiences with these
models and similar data and help me which model is the best to use.

With kind regards
Alena Dra?narov?

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From richard.feldman at mail.mcgill.ca  Mon Aug 16 16:06:07 2010
From: richard.feldman at mail.mcgill.ca (Richard Feldman)
Date: Mon, 16 Aug 2010 10:06:07 -0400
Subject: [R-sig-ME] Selecting random effects in lme4: ML vs. QAICc
In-Reply-To: <4C68601E.4030609@gmail.com>
References: <4C684E14.2080204@mail.mcgill.ca> <4C68601E.4030609@gmail.com>
Message-ID: <4C6945CF.2060704@mail.mcgill.ca>

Thank you very much for your informative response.

I guess I'm confused about how to interpret overdispersion. Using the 
Zuur et al. Owls data that you also present in your worked example, I 
ran the following models, keeping the fixed and random effects just as 
you present it:

glmer, family = gaussian
glmer, family = poisson
glmer, family = quasipoisson
glmmPQL, family = quasipoisson
glmmADMB, family = poisson ##zeroInflation=FALSE
glmmADMB, family = negative binomial ##zeroInflation=FALSE
glmmADMB, family = poisson ##zeroInflation=TRUE
glmmADMB, family = negative binomial ##zeroInflation=TRUE


For all but the quasipoisson glmer, I calculated dispersion following 
your example:

 >rdev<-sum(residuals(model)^2)
 >mdf<-length(fixef(model))
 >rdf<-nrow(Data)-mdf
 >rdev/rdf

For the quasipoisson glmer, I extracted dispersion as:

  >lme4:::sigma(model)^2

The results are as follows:

#                          model dispersion
#1                glmer.gaussian  35.534989
#2                    glmer.pois   5.630751
#3 glmer.quasi -- sigma(model)^2  29.830221
#4                 glmmPQL.quasi   1.076906
#5                 glmmADMB.pois   7.585654
#6               glmmADMB.nbinom   1.085072
#7            glmmADMB.pois.zero   8.255389
#8          glmmADMB.nbinom.zero   1.516587

Am I right to interpret this as saying 1) the sigma(model)^2 method is 
inaccurate and 2) the glmmPQL.quasi and glmmADMB.nbinom are sufficiently 
correcting for the overdispersion? I had thought I had read you advising 
using the quasipoisson model to calculate the overdispersion parameter 
(assuming it did so correctly) needed to adjust AIC for QAIC. It would 
seem the dispersion parameter should come from the Poisson regression. 
More likely I just misread you. Also, is it a concern that the 
dispersion is higher in the zero-inflated models? Does this mean 
zero-inflation is not an issue, at least when wanting to calculate AIC 
values?

Again, thank you for all the help!

Richard


Ben Bolker wrote:
>   There are a number of issues here, I will comment in-line ...
> 
> Richard Feldman wrote:
>> I am trying to select between two models that differ in their random
>> effects. Running a likelihood test gives me a different result than
>> using information criteria.
> 
>   In general you shouldn't be applying both methods in the same
> analysis, except for pedagogical/self-teaching purposes. The two tests
> answer different questions, and trying both leads to the temptation to
> cherry-pick.
>> My models:
>>
>> model.1 <- glmer(Y ~ V1 + V2 + V1:V2 + (V2|SITE), data=Data, family =
>> quasipoisson, REML = TRUE)
>>
>> model.2 <- glmer(Y ~ V1 + V2 + V1:V2 + (1|SITE), data=Data, family =
>> quasipoisson, REML = TRUE)
> 
>   Specifying REML=TRUE has no effect in glmer models.  (I don't know
> offhand whether you got a warning, arguably you should have.)  Note that
> in ?glmer there is no REML argument specified for glmer -- there is no
> warning because it gets swallowed by the optional "..." argument.
> 
>> I use quasipoisson because they are highly overdispersed:
>>
>> lme4:::sigma(model.1) #5.886659 lme4:::sigma(model.2) #101.6434
>  
>   If you are going to fit a quasi-likelihood model then generally you
> should find sigma for the most complex model (model 1 in your case) and
> then apply the same estimated value of sigma for all models.
> 
>> The results of the likelihood test: (I know that technically one
>> should not use (RE)ML for quasi-distributions. However the results
>> are nearly identical whether I use quasipoisson or poisson as the
>> family)
> 
>   Clarification: generally one should not use likelihood ratio tests (ML
> vs REML is a separate issue) at all on quasi-likelihood fits, although
> Venables and Ripley (MASS, p. 210) do suggest using an F test on the
> scaled difference in deviance (this is implemented for GLMs with the
> 'test="F"' option to anova.glm()).  (In contrast, they say in the same
> section that one *cannot* use AIC in this case, because one doesn't have
> a real likelihood -- presumably they don't agree with the line of
> reasoning leading to QAIC.)
> 
>    I'm also assuming that your sample size is large enough that the LRT applies (which is often a problem with GLMMs 
> if the number of random-effects levels is small)
> 
> 
>> anova(model.2, model.1)
>>
>> #         Df    AIC    BIC   logLik  Chisq Chi Df Pr(>Chisq) #model.2
>> 9 4648.3 4665.1 -2315.13 #model.1 14  346.8  373.0  -159.39 4311.5
>> 5  < 2.2e-16 ***
> 
>   Besides the fact that you shouldn't do this, it's unlikely that
> anova() is correcting for overdispersion.
>> Now, I run the same models with a poisson distribution and then
>> adjust the AIC by the overdispersion and the number of parameters to
>> obtain QAICc. With all these penalties taken into account, model.2
>> has the lowest QAICc. My gut instinct is to go with model.1, however,
>> because the overdispersion of model.2 is so high that perhaps it
>> shouldn't even be a candidate model. On the other hand, perhaps
>> adjusting the AIC really does put the two models on a more level
>> playing field.
> 
>   How did you calculate overdispersion?  If you're going to do this (and
> there are still some questions about whether this works) you should use
> sigma^2, not sigma, as your estimate of overdispersion.  If you are
> (heaven forbid) following the supplementary material of the Bolker et al
> 2009 TREE article, please look in the worked examples section of
> glmm.wikidot.com for an updated and corrected version.
> 
>  
> 
>   
> 
>   
> 

-- 
Richard Feldman, PhD Candidate
Dept. of Biological Sciences, McGill University
W3/5 Stewart Biology Building
1205 Docteur Penfield
Montreal, QC H3A 1B1
514-212-3466
richard.feldman at mail.mcgill.ca



From drasnarova.alena at gmail.com  Mon Aug 16 19:38:27 2010
From: drasnarova.alena at gmail.com (=?ISO-8859-2?Q?Alena_Dra=B9narov=E1?=)
Date: Mon, 16 Aug 2010 19:38:27 +0200
Subject: [R-sig-ME] RE :  Questions about mix models
In-Reply-To: <B56D7C27B4408243B93FBC46ABECB5A0011A8EE9AA84@EXCH-MBX-F.ulaval.ca>
References: <AANLkTikz63RfPBi6mi4Qk-aVmuUM1-Tma0KH_AeJedWH@mail.gmail.com>
	<B56D7C27B4408243B93FBC46ABECB5A0011A8EE9AA84@EXCH-MBX-F.ulaval.ca>
Message-ID: <AANLkTi=23AiH9UWpUMRChpc7JDecQoSs0QRWURY-cnsG@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100816/175f3b59/attachment.pl>

From rebecca.ross at plants.ox.ac.uk  Mon Aug 16 21:08:43 2010
From: rebecca.ross at plants.ox.ac.uk (Rebecca Ross)
Date: Mon, 16 Aug 2010 20:08:43 +0100
Subject: [R-sig-ME] Advice on fitting particular treatment contrasts in a
 random effects model
Message-ID: <756B64E07365AF43BE945A734A85E44544616945DE@EXMBX03.ad.oak.ox.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100816/968387b5/attachment.pl>

From lborger at uoguelph.ca  Mon Aug 16 21:49:39 2010
From: lborger at uoguelph.ca (Luca Borger)
Date: Mon, 16 Aug 2010 15:49:39 -0400
Subject: [R-sig-ME] RE :  Questions about mix models
References: <AANLkTikz63RfPBi6mi4Qk-aVmuUM1-Tma0KH_AeJedWH@mail.gmail.com><B56D7C27B4408243B93FBC46ABECB5A0011A8EE9AA84@EXCH-MBX-F.ulaval.ca>
	<AANLkTi=23AiH9UWpUMRChpc7JDecQoSs0QRWURY-cnsG@mail.gmail.com>
Message-ID: <C5CDBC4B3D944DFD8429A2AAEBFC1979@lborger>

Hello,

given that you are interested in investigating the effects of a series of 
predictors (e.g. moisture) on the number of seeds, whilst using random 
effects to account for your sampling design, I would actually suggest to fit 
your model without "top" also as fixed effect. Something like:

glmer(number ~ depth + HPV + K + VVS + 
(1|mead/trans/top),data=dat,family=poisson)

HTH, just my 2 cents.


Cheers,

Luca


----- Original Message ----- 
From: "Alena Drasnarov?" <drasnarova.alena at gmail.com>
To: "Julien Beguin" <julien.beguin.1 at ulaval.ca>
Cc: <r-sig-mixed-models at r-project.org>
Sent: Monday, August 16, 2010 1:38 PM
Subject: Re: [R-sig-ME] RE : Questions about mix models


Julien, thank you for your reaction.
1) Below you can see structura of my data (for 1 meadow)

        mead trans top depth number man litt water pH Ca K Mg P N C  VVS  1
1 A S 605 L 8.6 0 5.28 40.667 8.000 14.292 1.903 0.165 14.068 0.199  1 1 A V
582 L 8.6 0 5.28 40.667 8.000 14.292 1.903 0.165 14.068 0.199  1 1 B S 135 L
10.5 208 4.49 3.629 4.484 2.387 1.889 0.185 10.173 0.096  1 1 B V 153 L 10.5
208 4.49 3.629 4.484 2.387 1.889 0.185 10.173 0.096  1 2 A S 3 L 2.6 182
5.90 114.113 33.967 27.520 1.848 0.167 8.782 0.457  1 2 A V 2 L 2.6 182 5.90
114.113 33.967 27.520 1.848 0.167 8.782 0.457  1 2 B S 18 L 7.7 332 5.48
133.495 9.194 41.580 1.769 0.252 11.612 0.252  1 2 B V 57 L 7.7 332 5.48
133.495 9.194 41.580 1.769 0.252 11.612 0.252  1 3 A S 387 L 5.4 0 5.84
266.500 8.588 51.103 1.777 0.211 18.139 0.232  1 3 A V 462 L 5.4 0 5.84
266.500 8.588 51.103 1.777 0.211 18.139 0.232  1 3 B S 62 L 4.5 5 5.32
227.184 15.444 47.302 1.895 0.337 14.172 0.313  1 3 B V 22 L 4.5 5 5.32
227.184 15.444 47.302 1.895 0.337 14.172 0.313
Only on 2 meadows there are some missing data. But I prefer to use these
plots too.

2)
I did not try my model without top in random part. I can try it, but I think
that the model will lost important information about my design. About deegre
of freedom, I am not sure how to calculate them.

Alena
























































































































































































































































































































































































































Dne 16. srpna 2010 15:26 Julien Beguin <julien.beguin.1 at ulaval.ca>
napsal(a):
> Alena,
>
> 1) Can you join a summary of your data. Is it a balanced design?
>
> 2) Not sure to understand how your model assigns the residual error...
Have you tried to exclude variable 'top' from the random component: only
(1|mead/trans) ? does it improve convergence? and do you get the appropriate
number of degree of freedom for your fixed effects (based on your
experimental design)?
>
> Julien Beguin
> ________________________________________
> De : r-sig-mixed-models-bounces at r-project.org [
r-sig-mixed-models-bounces at r-project.org] de la part de Alena Dra??narov?? [
drasnarova.alena at gmail.com]
> Date d'envoi : 16 ao??t 2010 05:58
> ?? : r-sig-mixed-models at r-project.org
> Objet : [R-sig-ME] Questions about mix models
>
> Dear all,
>  I have so complicated data and I am trying to gain correct results from
them.
>
> I am interested in factors influencing density and diversity of the
> soil seed bank on alluvial meadows. I have nested design of my
> experiment: 35 meadows (mead=M1-M35), three transects on each meadow
> (trans=T1-T3) and  2 plots on each transect (top=A,B).
> I found out  a lot of information (about soil properties, moisure,
> litter, biomass, vegetation diversity and management).
> At first, I tried to use glmer, but sometimes there was error message:
>
>>
a2<-glmer(number~top+depth+HPV+K+VVS+(1|mead/trans/top),data=dat,family=poisson)
> Warning messages:
> 1: In mer_finalize(ans) :
>  Cholmod warning 'not positive definite' at
> file:../Cholesky/t_cholmod_rowfac.c, line 432
> 2: In mer_finalize(ans) :
>  Cholmod warning 'not positive definite' at
> file:../Cholesky/t_cholmod_rowfac.c, line 432
> 3: In mer_finalize(ans) : false convergence (8)
>
> So, I decided to use MCMCglmm, but I am not sure with fitting the
> model. I tried to fitt it by this way (example below is for one
> factor):
>
>> prior=list(R=list(V=1, n=0, fix=1), G=list(G1 = list(V
=1,n=1),G2=list(V=1,n=1),G3=list(V=1,n=1)))
>> m1 <- MCMCglmm(number ~ as.factor(top),
random=~mead+mead:trans+mead:trans:top, family = "poisson",
data=dat,prior=prior)
> I am not sure with define prior and random effect.
>
> I will be very happy, if anybody write me own experiences with these
> models and similar data and help me which model is the best to use.
>
> With kind regards
> Alena Dra??narov??
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

[[alternative HTML version deleted]]




--------------------------------------------------------------------------------


> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From julien.beguin.1 at ulaval.ca  Mon Aug 16 22:15:08 2010
From: julien.beguin.1 at ulaval.ca (Julien Beguin)
Date: Mon, 16 Aug 2010 16:15:08 -0400
Subject: [R-sig-ME] RE : RE :   Questions about mix models
Message-ID: <B56D7C27B4408243B93FBC46ABECB5A0011A8EE9AA8D@EXCH-MBX-F.ulaval.ca>

Alena,

With simulated data and with your model structure, it converged with no apprent problem (see code below). It is difficult with the actual info, however, to see where the problem originates. Can you return the following commands:

1) xtabs(~ mead + trans + top + depth, your_datafile)
2) summary(your_datafile, 35)
3) str(your_datafile)

--------------------------------------------------------------------------------------
require(lme4)
set.seed(1001)
mead <- rep(c(1:35), each = 12)
trans <- rep(c(1:3), each = 4, time = 35)
top <- rep(c("A","B"), each = 2, time = 105)
depth <- rep(c("S","V"), time = 210)
number <- rpois(420, 207)
P <- rnorm(420, 1.7, 0.5)
K <- rnorm(420, 15, 5)
VVS <- runif(420, 0, 1)
datafile <- as.data.frame(cbind(mead, trans, top, depth, number, P, K, VVS))
datafile$number <- as.integer(datafile$number)
datafile$P <- as.numeric(P)
datafile$K <- as.numeric(K)
datafile$VVS <- as.numeric(VVS)
a2<-glmer(number~top + depth + P + K + VVS + (1|mead/trans/top), family=poisson, data=datafile)
summary(a2)
--------------------------------------------------------------------------------------

Julien Beguin

PS: adding your session info might also be a good idea


________________________________________
De : Luca Borger [lborger at uoguelph.ca]
Date d'envoi : 16 ao?t 2010 15:49
? : Alena Drasnarov?; Julien Beguin
Cc : r-sig-mixed-models at r-project.org
Objet : Re: [R-sig-ME] RE :  Questions about mix models

Hello,

given that you are interested in investigating the effects of a series of
predictors (e.g. moisture) on the number of seeds, whilst using random
effects to account for your sampling design, I would actually suggest to fit
your model without "top" also as fixed effect. Something like:

glmer(number ~ depth + HPV + K + VVS +
(1|mead/trans/top),data=dat,family=poisson)

HTH, just my 2 cents.


Cheers,

Luca


----- Original Message -----
From: "Alena Drasnarov?" <drasnarova.alena at gmail.com>
To: "Julien Beguin" <julien.beguin.1 at ulaval.ca>
Cc: <r-sig-mixed-models at r-project.org>
Sent: Monday, August 16, 2010 1:38 PM
Subject: Re: [R-sig-ME] RE : Questions about mix models


Julien, thank you for your reaction.
1) Below you can see structura of my data (for 1 meadow)

        mead trans top depth number man litt water pH Ca K Mg P N C  VVS  1
1 A S 605 L 8.6 0 5.28 40.667 8.000 14.292 1.903 0.165 14.068 0.199  1 1 A V
582 L 8.6 0 5.28 40.667 8.000 14.292 1.903 0.165 14.068 0.199  1 1 B S 135 L
10.5 208 4.49 3.629 4.484 2.387 1.889 0.185 10.173 0.096  1 1 B V 153 L 10.5
208 4.49 3.629 4.484 2.387 1.889 0.185 10.173 0.096  1 2 A S 3 L 2.6 182
5.90 114.113 33.967 27.520 1.848 0.167 8.782 0.457  1 2 A V 2 L 2.6 182 5.90
114.113 33.967 27.520 1.848 0.167 8.782 0.457  1 2 B S 18 L 7.7 332 5.48
133.495 9.194 41.580 1.769 0.252 11.612 0.252  1 2 B V 57 L 7.7 332 5.48
133.495 9.194 41.580 1.769 0.252 11.612 0.252  1 3 A S 387 L 5.4 0 5.84
266.500 8.588 51.103 1.777 0.211 18.139 0.232  1 3 A V 462 L 5.4 0 5.84
266.500 8.588 51.103 1.777 0.211 18.139 0.232  1 3 B S 62 L 4.5 5 5.32
227.184 15.444 47.302 1.895 0.337 14.172 0.313  1 3 B V 22 L 4.5 5 5.32
227.184 15.444 47.302 1.895 0.337 14.172 0.313
Only on 2 meadows there are some missing data. But I prefer to use these
plots too.

2)
I did not try my model without top in random part. I can try it, but I think
that the model will lost important information about my design. About deegre
of freedom, I am not sure how to calculate them.

Alena
























































































































































































































































































































































































































Dne 16. srpna 2010 15:26 Julien Beguin <julien.beguin.1 at ulaval.ca>
napsal(a):
> Alena,
>
> 1) Can you join a summary of your data. Is it a balanced design?
>
> 2) Not sure to understand how your model assigns the residual error...
Have you tried to exclude variable 'top' from the random component: only
(1|mead/trans) ? does it improve convergence? and do you get the appropriate
number of degree of freedom for your fixed effects (based on your
experimental design)?
>
> Julien Beguin
> ________________________________________
> De : r-sig-mixed-models-bounces at r-project.org [
r-sig-mixed-models-bounces at r-project.org] de la part de Alena Dra??narov?? [
drasnarova.alena at gmail.com]
> Date d'envoi : 16 ao??t 2010 05:58
> ?? : r-sig-mixed-models at r-project.org
> Objet : [R-sig-ME] Questions about mix models
>
> Dear all,
>  I have so complicated data and I am trying to gain correct results from
them.
>
> I am interested in factors influencing density and diversity of the
> soil seed bank on alluvial meadows. I have nested design of my
> experiment: 35 meadows (mead=M1-M35), three transects on each meadow
> (trans=T1-T3) and  2 plots on each transect (top=A,B).
> I found out  a lot of information (about soil properties, moisure,
> litter, biomass, vegetation diversity and management).
> At first, I tried to use glmer, but sometimes there was error message:
>
>>
a2<-glmer(number~top+depth+HPV+K+VVS+(1|mead/trans/top),data=dat,family=poisson)
> Warning messages:
> 1: In mer_finalize(ans) :
>  Cholmod warning 'not positive definite' at
> file:../Cholesky/t_cholmod_rowfac.c, line 432
> 2: In mer_finalize(ans) :
>  Cholmod warning 'not positive definite' at
> file:../Cholesky/t_cholmod_rowfac.c, line 432
> 3: In mer_finalize(ans) : false convergence (8)
>
> So, I decided to use MCMCglmm, but I am not sure with fitting the
> model. I tried to fitt it by this way (example below is for one
> factor):
>
>> prior=list(R=list(V=1, n=0, fix=1), G=list(G1 = list(V
=1,n=1),G2=list(V=1,n=1),G3=list(V=1,n=1)))
>> m1 <- MCMCglmm(number ~ as.factor(top),
random=~mead+mead:trans+mead:trans:top, family = "poisson",
data=dat,prior=prior)
> I am not sure with define prior and random effect.
>
> I will be very happy, if anybody write me own experiences with these
> models and similar data and help me which model is the best to use.
>
> With kind regards
> Alena Dra??narov??
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

[[alternative HTML version deleted]]




--------------------------------------------------------------------------------


> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From j.hadfield at ed.ac.uk  Tue Aug 17 11:10:08 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 17 Aug 2010 10:10:08 +0100
Subject: [R-sig-ME] Questions about mix models
In-Reply-To: <AANLkTikz63RfPBi6mi4Qk-aVmuUM1-Tma0KH_AeJedWH@mail.gmail.com>
References: <AANLkTikz63RfPBi6mi4Qk-aVmuUM1-Tma0KH_AeJedWH@mail.gmail.com>
Message-ID: <51A9711B-696F-4826-BDC6-01B3D464B64E@ed.ac.uk>

Dear Alena,

As other's have said, its hard to assess the problem without more  
information. However, with regards to MCMCglmm, the model you  
specified is equivalent to the model you tried to fit in glmer (in  
terms of random effects) but models over-dispersion, which is  
important. However, you have fixed the residual variance to one which  
you should not do - this is only for categorical and ordinal responses.

If glmer is issuing warnings of this sort it often suggests there may  
be some problems with the model and so I would be very careful. If  
there is little replication for the random effects the priors you use  
will be quite informative. There is no perfect prior but I often find  
parameter expanded priors to work well:

prior=list(R=list(V=1, n=0), G=list(G1 = list(V =1,n=1, alpha.mu=0,  
alpha.V=1000),G2=list(V=1,n=1, alpha.mu=0,  
alpha.V=1000),G3=list(V=1,n=1, alpha.mu=0, alpha.V=1000)))

Cheers,

Jarrod


On 16 Aug 2010, at 10:58, Alena Dra?narov? wrote:

> Dear all,
> I have so complicated data and I am trying to gain correct results  
> from them.
>
> I am interested in factors influencing density and diversity of the
> soil seed bank on alluvial meadows. I have nested design of my
> experiment: 35 meadows (mead=M1-M35), three transects on each meadow
> (trans=T1-T3) and  2 plots on each transect (top=A,B).
> I found out  a lot of information (about soil properties, moisure,
> litter, biomass, vegetation diversity and management).
> At first, I tried to use glmer, but sometimes there was error message:
>
>> a2<-glmer(number~top+depth+HPV+K+VVS+(1|mead/trans/ 
>> top),data=dat,family=poisson)
> Warning messages:
> 1: In mer_finalize(ans) :
> Cholmod warning 'not positive definite' at
> file:../Cholesky/t_cholmod_rowfac.c, line 432
> 2: In mer_finalize(ans) :
> Cholmod warning 'not positive definite' at
> file:../Cholesky/t_cholmod_rowfac.c, line 432
> 3: In mer_finalize(ans) : false convergence (8)
>
> So, I decided to use MCMCglmm, but I am not sure with fitting the
> model. I tried to fitt it by this way (example below is for one
> factor):
>
>> prior=list(R=list(V=1, n=0, fix=1), G=list(G1 = list(V  
>> =1,n=1),G2=list(V=1,n=1),G3=list(V=1,n=1)))
>> m1 <- MCMCglmm(number ~ as.factor(top), random=~mead+mead:trans 
>> +mead:trans:top, family = "poisson", data=dat,prior=prior)
> I am not sure with define prior and random effect.
>
> I will be very happy, if anybody write me own experiences with these
> models and similar data and help me which model is the best to use.
>
> With kind regards
> Alena Dra?narov?
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From m.a.m.vande.ven at gmail.com  Tue Aug 17 13:00:47 2010
From: m.a.m.vande.ven at gmail.com (Marco van de Ven)
Date: Tue, 17 Aug 2010 13:00:47 +0200
Subject: [R-sig-ME] Monte Carlo simulations for lmer with binomial link
Message-ID: <AANLkTik1sUH8cjQtEcYvA4hi8do+39ZwqnMUGaKj7hrX@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100817/82e532e6/attachment.pl>

From bbolker at gmail.com  Tue Aug 17 18:25:40 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 17 Aug 2010 12:25:40 -0400
Subject: [R-sig-ME] Monte Carlo simulations for lmer with binomial link
In-Reply-To: <AANLkTik1sUH8cjQtEcYvA4hi8do+39ZwqnMUGaKj7hrX@mail.gmail.com>
References: <AANLkTik1sUH8cjQtEcYvA4hi8do+39ZwqnMUGaKj7hrX@mail.gmail.com>
Message-ID: <4C6AB804.8040206@gmail.com>

Marco van de Ven wrote:
> Hello,
>
> I fitted a linear mixed effects model (lmer) with the binomial link
> function (family = binomial). I tried to obtain pMCMC values for this
> regression model by using pvals.fnc, but this does not work. Similarly,
> mcmcsamp does not seem to work with binomial dependent variables. Are
> there alternative methods for obtaining p-values for these lmer models
> with Monte Carlo (or other) simulations? Many thanks in advance!
>
> Cheers,
>
> Marco van de Ven
> MPI Nijmegen
>   
  Not extremely easily.  See if anything at
<http://glmm.wikidot.com/faq> helps.



From bbolker at gmail.com  Tue Aug 17 18:42:51 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 17 Aug 2010 12:42:51 -0400
Subject: [R-sig-ME] Selecting random effects in lme4: ML vs. QAICc
In-Reply-To: <4C6945CF.2060704@mail.mcgill.ca>
References: <4C684E14.2080204@mail.mcgill.ca> <4C68601E.4030609@gmail.com>
	<4C6945CF.2060704@mail.mcgill.ca>
Message-ID: <4C6ABC0B.1000408@gmail.com>

Richard Feldman wrote:
> Thank you very much for your informative response.
>
> I guess I'm confused about how to interpret overdispersion. Using the
> Zuur et al. Owls data that you also present in your worked example, I
> ran the following models, keeping the fixed and random effects just as
> you present it:
>
> glmer, family = gaussian
> glmer, family = poisson
> glmer, family = quasipoisson
> glmmPQL, family = quasipoisson
> glmmADMB, family = poisson ##zeroInflation=FALSE
> glmmADMB, family = negative binomial ##zeroInflation=FALSE
> glmmADMB, family = poisson ##zeroInflation=TRUE
> glmmADMB, family = negative binomial ##zeroInflation=TRUE
>
>
> For all but the quasipoisson glmer, I calculated dispersion following
> your example:
>
> >rdev<-sum(residuals(model)^2)
> >mdf<-length(fixef(model))
> >rdf<-nrow(Data)-mdf
> >rdev/rdf
>
> For the quasipoisson glmer, I extracted dispersion as:
>
>  >lme4:::sigma(model)^2
>
> The results are as follows:
>
> #                          model dispersion
> #1                glmer.gaussian  35.534989
> #2                    glmer.pois   5.630751
> #3 glmer.quasi -- sigma(model)^2  29.830221
> #4                 glmmPQL.quasi   1.076906
> #5                 glmmADMB.pois   7.585654
> #6               glmmADMB.nbinom   1.085072
> #7            glmmADMB.pois.zero   8.255389
> #8          glmmADMB.nbinom.zero   1.516587
>
> Am I right to interpret this as saying 1) the sigma(model)^2 method is
> inaccurate and 2) the glmmPQL.quasi and glmmADMB.nbinom are
> sufficiently correcting for the overdispersion? I had thought I had
> read you advising using the quasipoisson model to calculate the
> overdispersion parameter (assuming it did so correctly) needed to
> adjust AIC for QAIC. It would seem the dispersion parameter should
> come from the Poisson regression. More likely I just misread you.
> Also, is it a concern that the dispersion is higher in the
> zero-inflated models? Does this mean zero-inflation is not an issue,
> at least when wanting to calculate AIC values?

   (1) Yes. I would agree that we don't quite know what's going on with
quasi- in glmer, and that using other methods is better if possible:
various people have reported odd results, Doug Bates has gone on record
as saying he wouldn't really know how to interpret a quasi-likelihood
GLMM anyway (I think that's a fair summary of his position), and it's
not clear whether the problem is with bugs in a little-tested corner of
the software or fundamental problems with the definitions of the model.
That said, quasi- is also the easiest way forward ...
  (2) glmmPQL.quasi uses penalized quasi-likelihood, so at least it's
consistent in the way it handles the random effects and the individual
variance structures.  PQL is known to be a bit dicey for data with small
numbers (e.g. means < 5) [Breslow 2003], not that that has stopped lots
of people from using it because for a long time it was the only game in
town. (3) The dispersion approx. 1 in the neg binom models does look
reasonable. See Venables and Ripley's section on overdispersion for some
cautions on this approach ... (4) I don't know why the deviance is
coming out slightly higher for the zero-inflated neg binom -- seems odd.
(5) Since you've gone to all this trouble to fit the overdispersed and
zero-inflated likelihood models, your best bet is to try likelihood
ratio tests between nested models (e.g. #8 vs #6 to test for
zero-inflation, #8 vs #7 or #6 vs #5 to test for overdispersion).  The
quasi- and overdispersion calculations are usually done as a way of
avoiding having to the fit the more complex models at all.



From j.hadfield at ed.ac.uk  Tue Aug 17 19:58:16 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 17 Aug 2010 18:58:16 +0100
Subject: [R-sig-ME] Monte Carlo simulations for lmer with binomial link
In-Reply-To: <AANLkTik1sUH8cjQtEcYvA4hi8do+39ZwqnMUGaKj7hrX@mail.gmail.com>
References: <AANLkTik1sUH8cjQtEcYvA4hi8do+39ZwqnMUGaKj7hrX@mail.gmail.com>
Message-ID: <20100817185816.i2ckbeg1hussoc0k@www.staffmail.ed.ac.uk>

Hi Marco,

The newest version of MCMCglmm calculates p-values when you call  
summary. These should be reasonably close to what should be obtained  
under mcmcsamp/pvals.func unless there is a lot of over-dispersion. In  
this case the p-values will be larger  - as they should be.

For testing groups of effects as in anova, I recently recommended to  
someone that they calculate the posterior covariance matrix and pass  
it to Wald.test in the aod package. I am not advocating this, but I  
would be interested in other people's thoughts. If the posterior  
distribution of the effects is close to multivariate normal (its  
multivariate-t for Gaussian models) I can't see a problem, but perhaps  
there are some issues....

Cheers,

Jarrod



Cheers,

Jarrod


Quoting Marco van de Ven <m.a.m.vande.ven at gmail.com>:

> Hello,
>
> I fitted a linear mixed effects model (lmer) with the binomial link
> function (family = binomial). I tried to obtain pMCMC values for this
> regression model by using pvals.fnc, but this does not work. Similarly,
> mcmcsamp does not seem to work with binomial dependent variables. Are
> there alternative methods for obtaining p-values for these lmer models
> with Monte Carlo (or other) simulations? Many thanks in advance!
>
> Cheers,
>
> Marco van de Ven
> MPI Nijmegen
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From amelie.lescroel at univ-rennes1.fr  Tue Aug 17 22:16:06 2010
From: amelie.lescroel at univ-rennes1.fr (Amelie Lescroel)
Date: Tue, 17 Aug 2010 22:16:06 +0200
Subject: [R-sig-ME] Modelling heterogeneity and crossed random effects
Message-ID: <D5B2D6A1441C448FB6F3666CC1D27921@Gentoo>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100817/e514c91c/attachment.pl>

From Matthew.Diebel at cadmusgroup.com  Wed Aug 18 00:19:33 2010
From: Matthew.Diebel at cadmusgroup.com (Matthew Diebel)
Date: Tue, 17 Aug 2010 18:19:33 -0400
Subject: [R-sig-ME] piecewise mixed effects model with know breakpoint
Message-ID: <197E0C924E33A54BB41B2921100AFF251630724284@mail.cadmusgroup.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100817/afdd23fe/attachment.pl>

From desja004 at umn.edu  Wed Aug 18 01:36:32 2010
From: desja004 at umn.edu (Christopher David Desjardins)
Date: Tue, 17 Aug 2010 18:36:32 -0500
Subject: [R-sig-ME] Testing whether I need a random effect?
Message-ID: <4C6B1D00.8060609@umn.edu>

Hi I have the following model:

m.f <- glmer(NumCitations ~ 1 + Program + ProductType + ProductField + 
(1 | ProductDate), family="poisson",data = data)

And I am wondering how I can test whether or not ProductDate needs to be 
included as a random effect or if I could just run a glm() without 
ProductDate?

Below is the output from m.f. As you can see there variance associated 
with ProductDate is non-zero but should it be included? I presume it's 
wrong to compare an AIC of a glmer() object with a glm() object?

Thanks!
Chris

 > m.f
Generalized linear mixed model fit by the Laplace approximation
Formula: NumCitations ~ 1 + Program + ProductType + ProductField + (1 | 
ProductDate)
Data: lija.ns
AIC BIC logLik deviance
2070 2107 -1026 2052
Random effects:
Groups Name Variance Std.Dev.
ProductDate (Intercept) 0.88876 0.94274
Number of obs: 465, groups: ProductDate, 12

Fixed effects:
Estimate Std. Error z value Pr(>|z|)
(Intercept) 0.91594 0.41865 2.188 0.02868 *
ProgramCETP 0.56466 0.16619 3.398 0.00068 ***
ProgramLSC 1.32624 0.09636 13.763 < 2e-16 ***
ProgramMSP-RETA 0.08312 0.24420 0.340 0.73358
ProductTypePublication -2.61985 0.15060 -17.396 < 2e-16 ***
ProductTypeReport -1.85925 0.10888 -17.077 < 2e-16 ***
ProductFieldSTEM education/research -0.07700 0.38272 -0.201 0.84054
ProductFieldSTEM evaluation 0.85661 0.31292 2.737 0.00619 **
---
Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
(Intr) PrCETP PrgLSC PMSP-R PrdcTP PrdcTR PFSTEMe/
ProgramCETP -0.074
ProgramLSC -0.109 0.530
PrgMSP-RETA -0.553 0.135 0.201
PrdctTypPbl -0.048 0.390 0.077 0.081
PrdctTypRpr 0.018 0.494 0.041 0.054 0.601
PrdcFSTEMe/ -0.601 -0.205 -0.170 0.574 -0.235 -0.222
PrdctFSTEMe -0.689 -0.200 -0.134 0.626 -0.139 -0.285 0.862



From bbolker at gmail.com  Wed Aug 18 02:34:12 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 17 Aug 2010 20:34:12 -0400
Subject: [R-sig-ME] Testing whether I need a random effect?
In-Reply-To: <4C6B1D00.8060609@umn.edu>
References: <4C6B1D00.8060609@umn.edu>
Message-ID: <4C6B2A84.7020909@gmail.com>

Christopher David Desjardins wrote:
> Hi I have the following model:
>
> m.f <- glmer(NumCitations ~ 1 + Program + ProductType + ProductField +
> (1 | ProductDate), family="poisson",data = data)
>
> And I am wondering how I can test whether or not ProductDate needs to
> be included as a random effect or if I could just run a glm() without
> ProductDate?
>
  see http://glmm.wikidot.com/faq , "How can I test whether a random
effect is significant?" (there aren't worked examples there -- anyone
want to donate some?)



From jianyun.fred.wu at gmail.com  Wed Aug 18 02:41:42 2010
From: jianyun.fred.wu at gmail.com (Jianyun Wu)
Date: Wed, 18 Aug 2010 10:41:42 +1000
Subject: [R-sig-ME] piecewise mixed effects model with know breakpoint
Message-ID: <AANLkTikmoo3GQKJG4c4p+3t6HXvkQdeLDC=miqxyqmQk@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100818/e5cc8966/attachment.pl>

From davidD at qimr.edu.au  Wed Aug 18 03:44:47 2010
From: davidD at qimr.edu.au (David Duffy)
Date: Wed, 18 Aug 2010 11:44:47 +1000 (EST)
Subject: [R-sig-ME] Testing whether I need a random effect?
In-Reply-To: <4C6B2A84.7020909@gmail.com>
References: <4C6B1D00.8060609@umn.edu> <4C6B2A84.7020909@gmail.com>
Message-ID: <Pine.LNX.4.64.1008181122030.9850@orpheus.qimr.edu.au>

On Tue, 17 Aug 2010, Ben Bolker wrote:

>  see http://glmm.wikidot.com/faq , "How can I test whether a random
> effect is significant?" (there aren't worked examples there -- anyone
> want to donate some?)

One example, but with shortcomings - I think you need random effects for 
visit *and* subject for a Poisson.  If I understand correctly, 
a negative binomial GLMM model incorporates the subject effect in that bit 
of the model.

library(MASS)
library(glmmML)
#
# an advantage of glmmML is that it uses the same constants etc 
# in its likelihood.  But it is only applicable for one random effect 
# (intercept)
#
m1 <- glm(y ~ lbase*trt + lage + V4, data=epil, family=poisson())
m2 <- glmmML(y ~ lbase*trt + lage + V4, cluster=subject, data=epil, family=poisson())

...
Scale parameter in mixing distribution:  0.5011 gaussian
Std. Error:                              0.05693

A Wald test would look impressive.

lrts <- m1$deviance-m2$deviance

This should be distributed 1/2*chisq(df=1)+1/2*chisq(df=0)

Cheers, David Duffy

| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From desja004 at umn.edu  Wed Aug 18 03:45:10 2010
From: desja004 at umn.edu (Christopher David Desjardins)
Date: Tue, 17 Aug 2010 20:45:10 -0500
Subject: [R-sig-ME] Testing whether I need a random effect?
In-Reply-To: <4C6B2A84.7020909@gmail.com>
References: <4C6B1D00.8060609@umn.edu> <4C6B2A84.7020909@gmail.com>
Message-ID: <4C6B3B26.8060205@umn.edu>

On 08/17/2010 07:34 PM, Ben Bolker wrote:
> Christopher David Desjardins wrote:
>    
>> Hi I have the following model:
>>
>> m.f<- glmer(NumCitations ~ 1 + Program + ProductType + ProductField +
>> (1 | ProductDate), family="poisson",data = data)
>>
>> And I am wondering how I can test whether or not ProductDate needs to
>> be included as a random effect or if I could just run a glm() without
>> ProductDate?
>>
>>      
>    see http://glmm.wikidot.com/faq , "How can I test whether a random
> effect is significant?" (there aren't worked examples there -- anyone
> want to donate some?)
>    

Thanks Ben.

The library RLRSim and the function exactRLRT(). However, when I run 
that function I get the following message:

 > exactRLRT(m.f)
Using restricted likelihood evaluated at ML estimators.
  Refit with method="REML" for exact results.
Error in if (rlrt.obs != 0) { : missing value where TRUE/FALSE needed

Does this function not work with the glmer() and the Poisson family?



From m.chaloupka at uq.edu.au  Wed Aug 18 03:51:08 2010
From: m.chaloupka at uq.edu.au (Milani Chaloupka)
Date: Wed, 18 Aug 2010 11:51:08 +1000
Subject: [R-sig-ME] Testing whether I need a random effect?
In-Reply-To: <4C6B2A84.7020909@gmail.com>
References: <4C6B1D00.8060609@umn.edu> <4C6B2A84.7020909@gmail.com>
Message-ID: <FC46EA63-2C1C-43E5-A2C9-37C2E06ED670@uq.edu.au>


Ben

perhaps this is a one approach to test for random effect in the glmm:

1) fit poisson glm instead

2) extract residuals (type = "d")

3) add to dataframe

4) load nlme package

5) fit lme model with residual as the response var, 1 as the explanatory var (like ~1) and the random effect on RHS (like random ~1|trial)

6) fit lm model with residual as the response var and 1 as the explanatory var (no random effect included)

7) LLR test using anova for the lme model vs lm model (AIC and BIC also valid here)

8) viola??


Milani



On 18/08/2010, at 10:34 AM, Ben Bolker wrote:

> Christopher David Desjardins wrote:
>> Hi I have the following model:
>> 
>> m.f <- glmer(NumCitations ~ 1 + Program + ProductType + ProductField +
>> (1 | ProductDate), family="poisson",data = data)
>> 
>> And I am wondering how I can test whether or not ProductDate needs to
>> be included as a random effect or if I could just run a glm() without
>> ProductDate?
>> 
>  see http://glmm.wikidot.com/faq , "How can I test whether a random
> effect is significant?" (there aren't worked examples there -- anyone
> want to donate some?)
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From dieter.anseeuw at katho.be  Wed Aug 18 09:28:37 2010
From: dieter.anseeuw at katho.be (dieter.anseeuw)
Date: Wed, 18 Aug 2010 07:28:37 +0000
Subject: [R-sig-ME] my first random effects logistic regression
Message-ID: <7C79081F82FB544BAF7B847A02F87972019CCC25@KA-EXCHMBX-02.katho.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100818/b537ffc0/attachment.pl>

From bobhuang09 at gmail.com  Wed Aug 18 09:31:44 2010
From: bobhuang09 at gmail.com (Bob Huang)
Date: Wed, 18 Aug 2010 15:31:44 +0800
Subject: [R-sig-ME] Problem in Between Subject Correlation
Message-ID: <AANLkTikR2gA-eq41LzirK0ZJbAvg5LHGXAObNfYrtDzB@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100818/f98d2f3e/attachment.pl>

From luciano.selzer at gmail.com  Wed Aug 18 09:51:40 2010
From: luciano.selzer at gmail.com (Luciano Selzer)
Date: Wed, 18 Aug 2010 04:51:40 -0300
Subject: [R-sig-ME] my first random effects logistic regression
In-Reply-To: <7C79081F82FB544BAF7B847A02F87972019CCC25@KA-EXCHMBX-02.katho.local>
References: <7C79081F82FB544BAF7B847A02F87972019CCC25@KA-EXCHMBX-02.katho.local>
Message-ID: <AANLkTi=0WBLTeA6Rkq8vAAsLqYNkQNH_+mrpbM=PEpKA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100818/a98eed53/attachment.pl>

From amelie.lescroel at univ-rennes1.fr  Wed Aug 18 10:05:38 2010
From: amelie.lescroel at univ-rennes1.fr (Amelie Lescroel)
Date: Wed, 18 Aug 2010 10:05:38 +0200
Subject: [R-sig-ME] Modelling heterogeneity and crossed random effects
In-Reply-To: <D5B2D6A1441C448FB6F3666CC1D27921@Gentoo>
References: <D5B2D6A1441C448FB6F3666CC1D27921@Gentoo>
Message-ID: <F00479A577164EBB8DF1812DEED0E0D8@Gentoo>

Dear all,
I did not receive any answer to my questions below. Not that I consider that
anybody "owes" me an answer but I would really need advices from people more
knowledgeable than I am. Please let me know if I need to reformulate /
shorten my questions or examples or if they are too "na?ve".
Best regards,
Amelie

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Amelie
Lescroel
Sent: Tuesday, August 17, 2010 10:16 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Modelling heterogeneity and crossed random effects

Dear all,

 

I am currently trying to model the behavioural response of individual
seabirds (in terms of foraging efficiency) to the variation in sea ice cover
(SICdr) of their foraging environment. I have 13 years of data, birds are
individually marked and followed, I have several records (= foraging
efficiency data = CPUEr in my code) per individual (IDr) for each year
(YEARr) and individuals are followed across years.

 

I am trying to find the right random effect structure (biologically
meaningful and dealing with problems of independence) and to deal with
heterogeneity of the residual variance at the same time (for all my models,
the variance of the residuals increases with increasing fitted values).
Regarding the random effect structure, would you say that crossed random
effects of the form (1|IDr) + (1|YEARr) would correctly reflect the study
design? Is there any way to model the variance heterogeneity in lmer that
would be analogous to the varIdent or varFixed functions in nlme? So far, I
can model the variance heterogeneity with nlme only and the (hopefully)
appropriate random effect structure with lmer only. Would you have other
suggestions for dealing with this heteroscedasticity?

 

Here are a couple of examples regarding the random effect structure with
some associated questions: 

 

> M1 <- lmer(CPUEr~SEXr+SICdr+(1|IDr))

> summary(M1)

 

Linear mixed model fit by REML

Formula: CPUEr ~ SEXr + SICdr + (1 | IDr) 

   AIC   BIC logLik deviance REMLdev

 270.2 297.6 -130.1    234.5   260.2

Random effects:

 Groups   Name        Variance Std.Dev.

 IDr      (Intercept) 0.010906 0.10443 

 Residual             0.060610 0.24619 

Number of obs: 1759, groups: IDr, 229

 

Fixed effects:

             Estimate Std. Error t value

(Intercept) 0.3070164  0.0155734  19.714

SEXrM       0.0961795  0.0195420   4.922

SICdr       0.0026240  0.0008478   3.095

 

Correlation of Fixed Effects:

      (Intr) SEXrM 

SEXrM -0.612       

SICdr -0.478 -0.006

 

Here, the correlation between 2 observations from the same individual
(irrespective of year) is: 0.010906/(0.010906+0.060610)=0.15

 

> M2 <- lmer(CPUEr~SEXr+SICdr+(1|YEARr))

> summary(M2)

Linear mixed model fit by REML

Formula: CPUEr ~ SEXr + SICdr + (1 | YEARr) 

   AIC   BIC logLik deviance REMLdev

 117.1 144.5 -53.55     84.8   107.1

Random effects:

 Groups   Name        Variance Std.Dev.

 YEARr    (Intercept) 0.020395 0.14281 

 Residual             0.059892 0.24473 

Number of obs: 1759, groups: YEARr, 13

 

Fixed effects:

            Estimate Std. Error t value

(Intercept)  0.36443    0.04367   8.345

SEXrM        0.10819    0.01175   9.207

SICdr       -0.00920    0.00192  -4.793

 

Correlation of Fixed Effects:

      (Intr) SEXrM 

SEXrM -0.134       

SICdr -0.367  0.009

 

Here, the correlation between 2 observations from the same year
(irrespective of the bird) is: 0.020395/(0.020395+0.059892)=0.25 How do I
get the correlation of 2 observations from the same individual within a
year? By modeling CPUEr~SEXr+SICdr+(1|YEARr/IDr)?

 

> M3 <- lmer(CPUEr~SEXr+SICdr+(1|YEARr/IDr))

> summary(M3)

Linear mixed model fit by REML

Formula: CPUEr ~ SEXr + SICdr + (1 | YEARr/IDr) 

   AIC   BIC logLik deviance REMLdev

 51.29 84.12 -19.64    17.21   39.29

Random effects:

 Groups    Name        Variance  Std.Dev.

 IDr:YEARr (Intercept) 0.0097178 0.09858 

 YEARr     (Intercept) 0.0188065 0.13714 

 Residual              0.0500727 0.22377 

Number of obs: 1759, groups: IDr:YEARr, 543; YEARr, 13

 

Fixed effects:

             Estimate Std. Error t value

(Intercept)  0.357318   0.042408   8.426

SEXrM        0.104650   0.014207   7.366

SICdr       -0.008960   0.001855  -4.831

 

Correlation of Fixed Effects:

      (Intr) SEXrM 

SEXrM -0.166       

SICdr -0.365  0.004

 

Then, would the correlation of 2 observations from the same individual
within a year be 0.0097178/(0.0097178+0.0500727)=0.16?

 

My best model (in terms of AIC) so far is the following:

 

> M4 <- lmer(CPUEr~SEXr+SICdr+(SICdr|IDr)+(1|YEARr))

> summary(M4)

Linear mixed model fit by REML

Formula: CPUEr ~ SEXr + SICdr + (SICdr | IDr) + (1 | YEARr) 

   AIC   BIC logLik deviance REMLdev

 12.88 56.66  1.559   -24.55  -3.119

Random effects:

 Groups   Name        Variance   Std.Dev.  Corr   

 IDr      (Intercept) 8.9314e-03 0.0945058        

          SICdr       2.3781e-05 0.0048766 -0.464 

 YEARr    (Intercept) 2.1401e-02 0.1462922        

 Residual             5.0765e-02 0.2253112        

Number of obs: 1759, groups: IDr, 229; YEARr, 13

 

Fixed effects:

             Estimate Std. Error t value

(Intercept)  0.363366   0.045471   7.991

SEXrM        0.100215   0.017188   5.830

SICdr       -0.009910   0.001974  -5.021

 

Correlation of Fixed Effects:

      (Intr) SEXrM 

SEXrM -0.189       

SICdr -0.357  0.010

 

How should I interpret the random effects?

 

I am using the R package version 0.999375-31 of lme4 and R version 2.9.2.

 

Thanks in advance for your help!

 

Cheers,

 

Amelie

 

 

 

 


	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From davidD at qimr.edu.au  Wed Aug 18 10:15:00 2010
From: davidD at qimr.edu.au (David Duffy)
Date: Wed, 18 Aug 2010 18:15:00 +1000 (EST)
Subject: [R-sig-ME] my first random effects logistic regression
In-Reply-To: <7C79081F82FB544BAF7B847A02F87972019CCC25@KA-EXCHMBX-02.katho.local>
References: <7C79081F82FB544BAF7B847A02F87972019CCC25@KA-EXCHMBX-02.katho.local>
Message-ID: <Pine.LNX.4.64.1008181812390.25912@orpheus.qimr.edu.au>

On Wed, 18 Aug 2010, dieter.anseeuw wrote:

> A friend has inspected three randomly chosen farms (random factor 
> 'farm'). At each farm three randomly chosen series of chickens (random 
> factor 'flock' nested within 'farm') were each inspected for the 
> presence of a certain bacteria. The contaminated chickens were counted 
> (response variable 'positives'). The sample sizes per flock are given by 
> the variable 'broilers'. We want to have a look at within-broilers, 
> within-farm and between-farm variability.
>
>> model1<-glmer(positives~1 + (flock|farm), data=broilers.dat, family=binomial(link="logit"), weights=broilers)
>
> Error in eval(expr, envir, enclos) : y values must be 0 <= y <= 1

glmer() would like to know how many tested chickens were negative.

cbind(positives, negatives) ~

Cheers, David Duffy
-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From Thierry.ONKELINX at inbo.be  Wed Aug 18 10:29:48 2010
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 18 Aug 2010 10:29:48 +0200
Subject: [R-sig-ME] Modelling heterogeneity and crossed random effects
In-Reply-To: <F00479A577164EBB8DF1812DEED0E0D8@Gentoo>
References: <D5B2D6A1441C448FB6F3666CC1D27921@Gentoo>
	<F00479A577164EBB8DF1812DEED0E0D8@Gentoo>
Message-ID: <3DB16098F738284D8DBEB2FC36991638296CD0@inboexch.inbo.be>

Dear Amelie,

Do you expect a common effect of year on all individuals that is not captured by your fixed effects? If not, you do not need to add year as a random effect and only  a random effect of individual will do. Hence you could switch back to nlme which has more features in terms of variance and correlation structures.

HTH,

Thierry

----------------------------------------------------------------------------
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
  

> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens 
> Amelie Lescroel
> Verzonden: woensdag 18 augustus 2010 10:06
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: Re: [R-sig-ME] Modelling heterogeneity and crossed 
> random effects
> 
> Dear all,
> I did not receive any answer to my questions below. Not that 
> I consider that anybody "owes" me an answer but I would 
> really need advices from people more knowledgeable than I am. 
> Please let me know if I need to reformulate / shorten my 
> questions or examples or if they are too "na?ve".
> Best regards,
> Amelie
> 
> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf 
> Of Amelie Lescroel
> Sent: Tuesday, August 17, 2010 10:16 PM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Modelling heterogeneity and crossed random effects
> 
> Dear all,
> 
>  
> 
> I am currently trying to model the behavioural response of 
> individual seabirds (in terms of foraging efficiency) to the 
> variation in sea ice cover
> (SICdr) of their foraging environment. I have 13 years of 
> data, birds are individually marked and followed, I have 
> several records (= foraging efficiency data = CPUEr in my 
> code) per individual (IDr) for each year
> (YEARr) and individuals are followed across years.
> 
>  
> 
> I am trying to find the right random effect structure 
> (biologically meaningful and dealing with problems of 
> independence) and to deal with heterogeneity of the residual 
> variance at the same time (for all my models, the variance of 
> the residuals increases with increasing fitted values).
> Regarding the random effect structure, would you say that 
> crossed random effects of the form (1|IDr) + (1|YEARr) would 
> correctly reflect the study design? Is there any way to model 
> the variance heterogeneity in lmer that would be analogous to 
> the varIdent or varFixed functions in nlme? So far, I can 
> model the variance heterogeneity with nlme only and the 
> (hopefully) appropriate random effect structure with lmer
> only. Would you have other suggestions for dealing with this 
> heteroscedasticity?
> 
>  
> 
> Here are a couple of examples regarding the random effect 
> structure with some associated questions: 
> 
>  
> 
> > M1 <- lmer(CPUEr~SEXr+SICdr+(1|IDr))
> 
> > summary(M1)
> 
>  
> 
> Linear mixed model fit by REML
> 
> Formula: CPUEr ~ SEXr + SICdr + (1 | IDr) 
> 
>    AIC   BIC logLik deviance REMLdev
> 
>  270.2 297.6 -130.1    234.5   260.2
> 
> Random effects:
> 
>  Groups   Name        Variance Std.Dev.
> 
>  IDr      (Intercept) 0.010906 0.10443 
> 
>  Residual             0.060610 0.24619
> 
> Number of obs: 1759, groups: IDr, 229
> 
>  
> 
> Fixed effects:
> 
>              Estimate Std. Error t value
> 
> (Intercept) 0.3070164  0.0155734  19.714
> 
> SEXrM       0.0961795  0.0195420   4.922
> 
> SICdr       0.0026240  0.0008478   3.095
> 
>  
> 
> Correlation of Fixed Effects:
> 
>       (Intr) SEXrM 
> 
> SEXrM -0.612       
> 
> SICdr -0.478 -0.006
> 
>  
> 
> Here, the correlation between 2 observations from the same 
> individual (irrespective of year) is: 
> 0.010906/(0.010906+0.060610)=0.15
> 
>  
> 
> > M2 <- lmer(CPUEr~SEXr+SICdr+(1|YEARr))
> 
> > summary(M2)
> 
> Linear mixed model fit by REML
> 
> Formula: CPUEr ~ SEXr + SICdr + (1 | YEARr) 
> 
>    AIC   BIC logLik deviance REMLdev
> 
>  117.1 144.5 -53.55     84.8   107.1
> 
> Random effects:
> 
>  Groups   Name        Variance Std.Dev.
> 
>  YEARr    (Intercept) 0.020395 0.14281 
> 
>  Residual             0.059892 0.24473
> 
> Number of obs: 1759, groups: YEARr, 13
> 
>  
> 
> Fixed effects:
> 
>             Estimate Std. Error t value
> 
> (Intercept)  0.36443    0.04367   8.345
> 
> SEXrM        0.10819    0.01175   9.207
> 
> SICdr       -0.00920    0.00192  -4.793
> 
>  
> 
> Correlation of Fixed Effects:
> 
>       (Intr) SEXrM 
> 
> SEXrM -0.134       
> 
> SICdr -0.367  0.009
> 
>  
> 
> Here, the correlation between 2 observations from the same 
> year (irrespective of the bird) is: 
> 0.020395/(0.020395+0.059892)=0.25 How do I get the 
> correlation of 2 observations from the same individual within 
> a year? By modeling CPUEr~SEXr+SICdr+(1|YEARr/IDr)?
> 
>  
> 
> > M3 <- lmer(CPUEr~SEXr+SICdr+(1|YEARr/IDr))
> 
> > summary(M3)
> 
> Linear mixed model fit by REML
> 
> Formula: CPUEr ~ SEXr + SICdr + (1 | YEARr/IDr) 
> 
>    AIC   BIC logLik deviance REMLdev
> 
>  51.29 84.12 -19.64    17.21   39.29
> 
> Random effects:
> 
>  Groups    Name        Variance  Std.Dev.
> 
>  IDr:YEARr (Intercept) 0.0097178 0.09858 
> 
>  YEARr     (Intercept) 0.0188065 0.13714 
> 
>  Residual              0.0500727 0.22377 
> 
> Number of obs: 1759, groups: IDr:YEARr, 543; YEARr, 13
> 
>  
> 
> Fixed effects:
> 
>              Estimate Std. Error t value
> 
> (Intercept)  0.357318   0.042408   8.426
> 
> SEXrM        0.104650   0.014207   7.366
> 
> SICdr       -0.008960   0.001855  -4.831
> 
>  
> 
> Correlation of Fixed Effects:
> 
>       (Intr) SEXrM 
> 
> SEXrM -0.166       
> 
> SICdr -0.365  0.004
> 
>  
> 
> Then, would the correlation of 2 observations from the same 
> individual within a year be 0.0097178/(0.0097178+0.0500727)=0.16?
> 
>  
> 
> My best model (in terms of AIC) so far is the following:
> 
>  
> 
> > M4 <- lmer(CPUEr~SEXr+SICdr+(SICdr|IDr)+(1|YEARr))
> 
> > summary(M4)
> 
> Linear mixed model fit by REML
> 
> Formula: CPUEr ~ SEXr + SICdr + (SICdr | IDr) + (1 | YEARr) 
> 
>    AIC   BIC logLik deviance REMLdev
> 
>  12.88 56.66  1.559   -24.55  -3.119
> 
> Random effects:
> 
>  Groups   Name        Variance   Std.Dev.  Corr   
> 
>  IDr      (Intercept) 8.9314e-03 0.0945058        
> 
>           SICdr       2.3781e-05 0.0048766 -0.464 
> 
>  YEARr    (Intercept) 2.1401e-02 0.1462922        
> 
>  Residual             5.0765e-02 0.2253112        
> 
> Number of obs: 1759, groups: IDr, 229; YEARr, 13
> 
>  
> 
> Fixed effects:
> 
>              Estimate Std. Error t value
> 
> (Intercept)  0.363366   0.045471   7.991
> 
> SEXrM        0.100215   0.017188   5.830
> 
> SICdr       -0.009910   0.001974  -5.021
> 
>  
> 
> Correlation of Fixed Effects:
> 
>       (Intr) SEXrM 
> 
> SEXrM -0.189       
> 
> SICdr -0.357  0.010
> 
>  
> 
> How should I interpret the random effects?
> 
>  
> 
> I am using the R package version 0.999375-31 of lme4 and R 
> version 2.9.2.
> 
>  
> 
> Thanks in advance for your help!
> 
>  
> 
> Cheers,
> 
>  
> 
> Amelie
> 
>  
> 
>  
> 
>  
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

Druk dit bericht a.u.b. niet onnodig af.
Please do not print this message unnecessarily.

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From amelie.lescroel at univ-rennes1.fr  Wed Aug 18 10:40:54 2010
From: amelie.lescroel at univ-rennes1.fr (Amelie Lescroel)
Date: Wed, 18 Aug 2010 10:40:54 +0200
Subject: [R-sig-ME] Modelling heterogeneity and crossed random effects
In-Reply-To: <3DB16098F738284D8DBEB2FC36991638296CD0@inboexch.inbo.be>
References: <D5B2D6A1441C448FB6F3666CC1D27921@Gentoo>
	<F00479A577164EBB8DF1812DEED0E0D8@Gentoo>
	<3DB16098F738284D8DBEB2FC36991638296CD0@inboexch.inbo.be>
Message-ID: <385EA88808B64818BA90BA92BCA5EEFD@Gentoo>

Dear Thierry,

Thanks a lot for your answer. I was hoping that year as a random effect
would 1) account for the study design (I have several points per individual
for each year and I wanted to quantify the correlation of 2 observations
from the same individual within a year vs. across years) and 2) capture
other year effects that would not be accounted for by my fixed effects. And
indeed, all my models including year as a random effect performed better, in
terms of AIC, than those that did not include year. Otherwise, yes, it would
easier to model the variance in nlme. In either package though, I'm not sure
that I found the right structure model that would correspond to the study
design (longitudinal study with replicated points within years) and I would
welcome any suggestion.

Best,

Amelie

-----Original Message-----
From: ONKELINX, Thierry [mailto:Thierry.ONKELINX at inbo.be] 
Sent: Wednesday, August 18, 2010 10:30 AM
To: Amelie Lescroel; r-sig-mixed-models at r-project.org
Subject: RE: [R-sig-ME] Modelling heterogeneity and crossed random effects

Dear Amelie,

Do you expect a common effect of year on all individuals that is not
captured by your fixed effects? If not, you do not need to add year as a
random effect and only  a random effect of individual will do. Hence you
could switch back to nlme which has more features in terms of variance and
correlation structures.

HTH,

Thierry

----------------------------------------------------------------------------
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than
asking him to perform a post-mortem examination: he may be able to say what
the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
  

> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens 
> Amelie Lescroel
> Verzonden: woensdag 18 augustus 2010 10:06
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: Re: [R-sig-ME] Modelling heterogeneity and crossed 
> random effects
> 
> Dear all,
> I did not receive any answer to my questions below. Not that 
> I consider that anybody "owes" me an answer but I would 
> really need advices from people more knowledgeable than I am. 
> Please let me know if I need to reformulate / shorten my 
> questions or examples or if they are too "na?ve".
> Best regards,
> Amelie
> 
> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf 
> Of Amelie Lescroel
> Sent: Tuesday, August 17, 2010 10:16 PM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Modelling heterogeneity and crossed random effects
> 
> Dear all,
> 
>  
> 
> I am currently trying to model the behavioural response of 
> individual seabirds (in terms of foraging efficiency) to the 
> variation in sea ice cover
> (SICdr) of their foraging environment. I have 13 years of 
> data, birds are individually marked and followed, I have 
> several records (= foraging efficiency data = CPUEr in my 
> code) per individual (IDr) for each year
> (YEARr) and individuals are followed across years.
> 
>  
> 
> I am trying to find the right random effect structure 
> (biologically meaningful and dealing with problems of 
> independence) and to deal with heterogeneity of the residual 
> variance at the same time (for all my models, the variance of 
> the residuals increases with increasing fitted values).
> Regarding the random effect structure, would you say that 
> crossed random effects of the form (1|IDr) + (1|YEARr) would 
> correctly reflect the study design? Is there any way to model 
> the variance heterogeneity in lmer that would be analogous to 
> the varIdent or varFixed functions in nlme? So far, I can 
> model the variance heterogeneity with nlme only and the 
> (hopefully) appropriate random effect structure with lmer 
> only. Would you have other suggestions for dealing with this 
> heteroscedasticity?
> 
>  
> 
> Here are a couple of examples regarding the random effect 
> structure with some associated questions: 
> 
>  
> 
> > M1 <- lmer(CPUEr~SEXr+SICdr+(1|IDr))
> 
> > summary(M1)
> 
>  
> 
> Linear mixed model fit by REML
> 
> Formula: CPUEr ~ SEXr + SICdr + (1 | IDr) 
> 
>    AIC   BIC logLik deviance REMLdev
> 
>  270.2 297.6 -130.1    234.5   260.2
> 
> Random effects:
> 
>  Groups   Name        Variance Std.Dev.
> 
>  IDr      (Intercept) 0.010906 0.10443 
> 
>  Residual             0.060610 0.24619 
> 
> Number of obs: 1759, groups: IDr, 229
> 
>  
> 
> Fixed effects:
> 
>              Estimate Std. Error t value
> 
> (Intercept) 0.3070164  0.0155734  19.714
> 
> SEXrM       0.0961795  0.0195420   4.922
> 
> SICdr       0.0026240  0.0008478   3.095
> 
>  
> 
> Correlation of Fixed Effects:
> 
>       (Intr) SEXrM 
> 
> SEXrM -0.612       
> 
> SICdr -0.478 -0.006
> 
>  
> 
> Here, the correlation between 2 observations from the same 
> individual (irrespective of year) is: 
> 0.010906/(0.010906+0.060610)=0.15
> 
>  
> 
> > M2 <- lmer(CPUEr~SEXr+SICdr+(1|YEARr))
> 
> > summary(M2)
> 
> Linear mixed model fit by REML
> 
> Formula: CPUEr ~ SEXr + SICdr + (1 | YEARr) 
> 
>    AIC   BIC logLik deviance REMLdev
> 
>  117.1 144.5 -53.55     84.8   107.1
> 
> Random effects:
> 
>  Groups   Name        Variance Std.Dev.
> 
>  YEARr    (Intercept) 0.020395 0.14281 
> 
>  Residual             0.059892 0.24473 
> 
> Number of obs: 1759, groups: YEARr, 13
> 
>  
> 
> Fixed effects:
> 
>             Estimate Std. Error t value
> 
> (Intercept)  0.36443    0.04367   8.345
> 
> SEXrM        0.10819    0.01175   9.207
> 
> SICdr       -0.00920    0.00192  -4.793
> 
>  
> 
> Correlation of Fixed Effects:
> 
>       (Intr) SEXrM 
> 
> SEXrM -0.134       
> 
> SICdr -0.367  0.009
> 
>  
> 
> Here, the correlation between 2 observations from the same 
> year (irrespective of the bird) is: 
> 0.020395/(0.020395+0.059892)=0.25 How do I get the 
> correlation of 2 observations from the same individual within 
> a year? By modeling CPUEr~SEXr+SICdr+(1|YEARr/IDr)?
> 
>  
> 
> > M3 <- lmer(CPUEr~SEXr+SICdr+(1|YEARr/IDr))
> 
> > summary(M3)
> 
> Linear mixed model fit by REML
> 
> Formula: CPUEr ~ SEXr + SICdr + (1 | YEARr/IDr) 
> 
>    AIC   BIC logLik deviance REMLdev
> 
>  51.29 84.12 -19.64    17.21   39.29
> 
> Random effects:
> 
>  Groups    Name        Variance  Std.Dev.
> 
>  IDr:YEARr (Intercept) 0.0097178 0.09858 
> 
>  YEARr     (Intercept) 0.0188065 0.13714 
> 
>  Residual              0.0500727 0.22377 
> 
> Number of obs: 1759, groups: IDr:YEARr, 543; YEARr, 13
> 
>  
> 
> Fixed effects:
> 
>              Estimate Std. Error t value
> 
> (Intercept)  0.357318   0.042408   8.426
> 
> SEXrM        0.104650   0.014207   7.366
> 
> SICdr       -0.008960   0.001855  -4.831
> 
>  
> 
> Correlation of Fixed Effects:
> 
>       (Intr) SEXrM 
> 
> SEXrM -0.166       
> 
> SICdr -0.365  0.004
> 
>  
> 
> Then, would the correlation of 2 observations from the same 
> individual within a year be 0.0097178/(0.0097178+0.0500727)=0.16?
> 
>  
> 
> My best model (in terms of AIC) so far is the following:
> 
>  
> 
> > M4 <- lmer(CPUEr~SEXr+SICdr+(SICdr|IDr)+(1|YEARr))
> 
> > summary(M4)
> 
> Linear mixed model fit by REML
> 
> Formula: CPUEr ~ SEXr + SICdr + (SICdr | IDr) + (1 | YEARr) 
> 
>    AIC   BIC logLik deviance REMLdev
> 
>  12.88 56.66  1.559   -24.55  -3.119
> 
> Random effects:
> 
>  Groups   Name        Variance   Std.Dev.  Corr   
> 
>  IDr      (Intercept) 8.9314e-03 0.0945058        
> 
>           SICdr       2.3781e-05 0.0048766 -0.464 
> 
>  YEARr    (Intercept) 2.1401e-02 0.1462922        
> 
>  Residual             5.0765e-02 0.2253112        
> 
> Number of obs: 1759, groups: IDr, 229; YEARr, 13
> 
>  
> 
> Fixed effects:
> 
>              Estimate Std. Error t value
> 
> (Intercept)  0.363366   0.045471   7.991
> 
> SEXrM        0.100215   0.017188   5.830
> 
> SICdr       -0.009910   0.001974  -5.021
> 
>  
> 
> Correlation of Fixed Effects:
> 
>       (Intr) SEXrM 
> 
> SEXrM -0.189       
> 
> SICdr -0.357  0.010
> 
>  
> 
> How should I interpret the random effects?
> 
>  
> 
> I am using the R package version 0.999375-31 of lme4 and R 
> version 2.9.2.
> 
>  
> 
> Thanks in advance for your help!
> 
>  
> 
> Cheers,
> 
>  
> 
> Amelie
> 
>  
> 
>  
> 
>  
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

Druk dit bericht a.u.b. niet onnodig af.
Please do not print this message unnecessarily.

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer

en binden het INBO onder geen enkel beding, zolang dit bericht niet
bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as
stating 
an official position of INBO, as long as the message is not confirmed by a
duly 
signed document.



From Thierry.ONKELINX at inbo.be  Wed Aug 18 10:40:37 2010
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 18 Aug 2010 10:40:37 +0200
Subject: [R-sig-ME] my first random effects logistic regression
In-Reply-To: <7C79081F82FB544BAF7B847A02F87972019CCC25@KA-EXCHMBX-02.katho.local>
References: <7C79081F82FB544BAF7B847A02F87972019CCC25@KA-EXCHMBX-02.katho.local>
Message-ID: <3DB16098F738284D8DBEB2FC36991638296CD7@inboexch.inbo.be>

Dear Dieter,

You allready got the comments needed to get to code working. I would
like to point to a flaw in your random effect specification. The correct
specification for your design would be (1|farm/flock).

However I would model it in this case as (1|farm:flock) becasue you have
only 3 farms. Which is very low, so the variance estimates would not be
very reliable.

HTH,

Thierry
------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey
  

> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens 
> dieter.anseeuw
> Verzonden: woensdag 18 augustus 2010 9:29
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] my first random effects logistic regression
> 
> Hi all,
> 
> 
> 
> I am new to using lme4 and only just discovered the mailing 
> list (I already shortly introduced my problem in the
> epi-mailinglist, sorry for cross-posting, but my questions 
> seem more appropriate for the mixed models discussion group).
> 
> 
> 
> A friend has inspected three randomly chosen farms (random 
> factor 'farm'). At each farm three randomly chosen series of 
> chickens (random factor 'flock' nested within 'farm') were 
> each inspected for the presence of a certain bacteria. The 
> contaminated chickens were counted (response variable 
> 'positives'). The sample sizes per flock are given by the 
> variable 'broilers'. We want to have a look at 
> within-broilers, within-farm and between-farm variability.
> 
> 
> 
> This is the closest I get to analysing her data:
> 
> 
> 
> > 
> broilers.dat<-data.frame(farm=c("FA","FA","FA","FB","FB","FB","FC","FC
> > ","FC"), flock=c("a","b","c","d","e","f","g","h","i"), 
> broilers=c(50, 
> > rep(25,8)), positives=c(7,2,0,7,2,0,0,0,2))
> 
> > library(lme4)
> 
> > model1<-glmer(positives~1 + (flock|farm), data=broilers.dat, 
> > family=binomial(link="logit"), weights=broilers)
> 
> Error in eval(expr, envir, enclos) : y values must be 0 <= y <= 1
> 
> 
> 
> Hence, my code doesn't work. Could anybody help me out where 
> and why I go wrong?
> 
> 
> 
> Many thanks in advance,
> 
> Dieter
> 
> 
> 
> --
> 
> Dr. Ir. Dieter Anseeuw
> 
> Katho Campus Roeselare
> 
> Wilgenstraat 32
> 
> 8800 Roeselare Belgium
> 
> 
> 
> Direct phone: +32 51 23 29 68
> 
> http://www.katho.be/hivb
> 
> http://www.linkedin.com/in/dieteranseeuw
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

Druk dit bericht a.u.b. niet onnodig af.
Please do not print this message unnecessarily.

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From j.hadfield at ed.ac.uk  Wed Aug 18 10:56:36 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 18 Aug 2010 09:56:36 +0100
Subject: [R-sig-ME] my first random effects logistic regression
In-Reply-To: <7C79081F82FB544BAF7B847A02F87972019CCC25@KA-EXCHMBX-02.katho.local>
References: <7C79081F82FB544BAF7B847A02F87972019CCC25@KA-EXCHMBX-02.katho.local>
Message-ID: <8C92C98A-0FEE-4E55-AEC3-EAC85C949DD7@ed.ac.uk>

Hi Dieter,

I was writing this as Thierry posted. My recommendation is similar,  
although you wont be able to fit  farm:flock in glmer because it will  
complain about the number of random effects being equal to the number  
of data. Anyhow....

I'm not sure if I have understood the sampling design correctly, but  
it seems there are 9 flocks over 3 farms, 3 in each farm? If this is  
the case you are going to run into problems with (flock|farm). This  
specification is trying to estimate a 9X9 matrix which is the between  
farm variance for each flock along the diagonals, and the between farm  
covariances between flocks in the off-diagonals.  This is 45  
(co)variance parameters from 9 data points. I think I would try  
something simpler:

model2<-glm(cbind(positives, broilers-positives)~farm,  
data=broilers.dat, family=quasibinomial)

The quasi bit is capturing the flock effects, and the farm effects are  
fitted as fixed. Another way to do it is to expand the binomial  
response into a series of binary data and fit flock as a random effect:


broilers.dat2<-broilers.dat[rep(1:9, broilers.dat$broilers),]
broilers.dat2$positives<- 
(broilers.dat2$positives>=unlist(sapply(broilers.dat$broilers,  
function(x){1:x})))

tapply(broilers.dat2$positives, broilers.dat2$flock, sum) # check its  
OK - it is

model3<-glmer(positives~farm+(1|flock), data=broilers.dat2,  
family=binomial)


you could try farm as well, but with only 3 I would be careful

model4<-glmer(positives~(1|farm)+(1|flock), data=broilers.dat2,  
family=binomial)


This model:

model5<-glmer(positives~(1|flock), data=broilers.dat2, family=binomial)

is equivalent to the one posted by Thierry , but it will run.

Cheers,

Jarrod


On 18 Aug 2010, at 08:28, dieter.anseeuw wrote:

> Hi all,
>
>
>
> I am new to using lme4 and only just discovered the mailing list (I  
> already shortly introduced my problem in the epi-mailinglist, sorry  
> for cross-posting, but my questions seem more appropriate for the  
> mixed models discussion group).
>
>
>
> A friend has inspected three randomly chosen farms (random factor  
> 'farm'). At each farm three randomly chosen series of chickens  
> (random factor 'flock' nested within 'farm') were each inspected for  
> the presence of a certain bacteria. The contaminated chickens were  
> counted (response variable 'positives'). The sample sizes per flock  
> are given by the variable 'broilers'. We want to have a look at  
> within-broilers, within-farm and between-farm variability.
>
>
>
> This is the closest I get to analysing her data:
>
>
>
>> broilers.dat<- 
>> data.frame(farm=c("FA","FA","FA","FB","FB","FB","FC","FC","FC"),  
>> flock=c("a","b","c","d","e","f","g","h","i"), broilers=c(50,  
>> rep(25,8)), positives=c(7,2,0,7,2,0,0,0,2))
>
>> library(lme4)
>
>> model1<-glmer(positives~1 + (flock|farm), data=broilers.dat,  
>> family=binomial(link="logit"), weights=broilers)
>
> Error in eval(expr, envir, enclos) : y values must be 0 <= y <= 1
>
>
>
> Hence, my code doesn't work. Could anybody help me out where and why  
> I go wrong?
>
>
>
> Many thanks in advance,
>
> Dieter
>
>
>
> --
>
> Dr. Ir. Dieter Anseeuw
>
> Katho Campus Roeselare
>
> Wilgenstraat 32
>
> 8800 Roeselare Belgium
>
>
>
> Direct phone: +32 51 23 29 68
>
> http://www.katho.be/hivb
>
> http://www.linkedin.com/in/dieteranseeuw
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From Thierry.ONKELINX at inbo.be  Wed Aug 18 11:17:21 2010
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 18 Aug 2010 11:17:21 +0200
Subject: [R-sig-ME] Modelling heterogeneity and crossed random effects
In-Reply-To: <385EA88808B64818BA90BA92BCA5EEFD@Gentoo>
References: <D5B2D6A1441C448FB6F3666CC1D27921@Gentoo>
	<F00479A577164EBB8DF1812DEED0E0D8@Gentoo>
	<3DB16098F738284D8DBEB2FC36991638296CD0@inboexch.inbo.be>
	<385EA88808B64818BA90BA92BCA5EEFD@Gentoo>
Message-ID: <3DB16098F738284D8DBEB2FC36991638296CF2@inboexch.inbo.be>

Dear Amelie,

In my opinion, a correlation structure (e.g. corAR1(~Year) or corExp(~Year)) will do to represent your design. And it will give you information about the difference in variance in a year and among years.
A second option would be to add year as a random slope per individual. Random = ~ factor(Year) - 1|ID
You could even combine both options.

Note that according to Zuur et al. (2009) is random intercept is equivalent to a compound symmetry correlation structure.

lme(Z ~ ..., random = ~ 1|A) is equivalent to gls(Z ~ ..., correlation = corCompSymm(~A))

HTH,

Thierry

----------------------------------------------------------------------------
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
  

> -----Oorspronkelijk bericht-----
> Van: Amelie Lescroel [mailto:amelie.lescroel at univ-rennes1.fr]
> Verzonden: woensdag 18 augustus 2010 10:41
> Aan: ONKELINX, Thierry; r-sig-mixed-models at r-project.org
> Onderwerp: RE: [R-sig-ME] Modelling heterogeneity and crossed 
> random effects
> 
> Dear Thierry,
> 
> Thanks a lot for your answer. I was hoping that year as a 
> random effect would 1) account for the study design (I have 
> several points per individual for each year and I wanted to 
> quantify the correlation of 2 observations from the same 
> individual within a year vs. across years) and 2) capture 
> other year effects that would not be accounted for by my 
> fixed effects. And indeed, all my models including year as a 
> random effect performed better, in terms of AIC, than those 
> that did not include year. Otherwise, yes, it would easier to 
> model the variance in nlme. In either package though, I'm not 
> sure that I found the right structure model that would 
> correspond to the study design (longitudinal study with
> replicated points within years) and I would welcome any suggestion.
> 
> Best,
> 
> Amelie
> 
> -----Original Message-----
> From: ONKELINX, Thierry [mailto:Thierry.ONKELINX at inbo.be]
> Sent: Wednesday, August 18, 2010 10:30 AM
> To: Amelie Lescroel; r-sig-mixed-models at r-project.org
> Subject: RE: [R-sig-ME] Modelling heterogeneity and crossed 
> random effects
> 
> Dear Amelie,
> 
> Do you expect a common effect of year on all individuals that 
> is not captured by your fixed effects? If not, you do not 
> need to add year as a random effect and only  a random effect 
> of individual will do. Hence you could switch back to nlme 
> which has more features in terms of variance and correlation 
> structures.
> 
> HTH,
> 
> Thierry
> 
> --------------------------------------------------------------
> --------------
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek
> team Biometrie & Kwaliteitszorg
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium
> 
> Research Institute for Nature and Forest team Biometrics & 
> Quality Assurance Gaverstraat 4 9500 Geraardsbergen Belgium
> 
> tel. + 32 54/436 185
> Thierry.Onkelinx at inbo.be
> www.inbo.be
> 
> To call in the statistician after the experiment is done may 
> be no more than asking him to perform a post-mortem
> examination: he may be able to say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
> 
> The plural of anecdote is not data.
> ~ Roger Brinner
> 
> The combination of some data and an aching desire for an 
> answer does not ensure that a reasonable answer can be 
> extracted from a given body of data.
> ~ John Tukey
>   
> 
> > -----Oorspronkelijk bericht-----
> > Van: r-sig-mixed-models-bounces at r-project.org
> > [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Amelie 
> > Lescroel
> > Verzonden: woensdag 18 augustus 2010 10:06
> > Aan: r-sig-mixed-models at r-project.org
> > Onderwerp: Re: [R-sig-ME] Modelling heterogeneity and
> crossed random 
> > effects
> > 
> > Dear all,
> > I did not receive any answer to my questions below. Not that I 
> > consider that anybody "owes" me an answer but I would really need 
> > advices from people more knowledgeable than I am.
> > Please let me know if I need to reformulate / shorten my 
> questions or 
> > examples or if they are too "na?ve".
> > Best regards,
> > Amelie
> > 
> > -----Original Message-----
> > From: r-sig-mixed-models-bounces at r-project.org
> > [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf
> Of Amelie 
> > Lescroel
> > Sent: Tuesday, August 17, 2010 10:16 PM
> > To: r-sig-mixed-models at r-project.org
> > Subject: [R-sig-ME] Modelling heterogeneity and crossed
> random effects
> > 
> > Dear all,
> > 
> >  
> > 
> > I am currently trying to model the behavioural response of 
> individual 
> > seabirds (in terms of foraging efficiency) to the variation 
> in sea ice 
> > cover
> > (SICdr) of their foraging environment. I have 13 years of 
> data, birds 
> > are individually marked and followed, I have several records (= 
> > foraging efficiency data = CPUEr in my
> > code) per individual (IDr) for each year
> > (YEARr) and individuals are followed across years.
> > 
> >  
> > 
> > I am trying to find the right random effect structure (biologically 
> > meaningful and dealing with problems of
> > independence) and to deal with heterogeneity of the
> residual variance 
> > at the same time (for all my models, the variance of the residuals 
> > increases with increasing fitted values).
> > Regarding the random effect structure, would you say that crossed 
> > random effects of the form (1|IDr) + (1|YEARr) would 
> correctly reflect 
> > the study design? Is there any way to model the variance 
> heterogeneity 
> > in lmer that would be analogous to the varIdent or varFixed 
> functions 
> > in nlme? So far, I can model the variance heterogeneity 
> with nlme only 
> > and the
> > (hopefully) appropriate random effect structure with lmer 
> only. Would 
> > you have other suggestions for dealing with this heteroscedasticity?
> > 
> >  
> > 
> > Here are a couple of examples regarding the random effect structure 
> > with some associated questions:
> > 
> >  
> > 
> > > M1 <- lmer(CPUEr~SEXr+SICdr+(1|IDr))
> > 
> > > summary(M1)
> > 
> >  
> > 
> > Linear mixed model fit by REML
> > 
> > Formula: CPUEr ~ SEXr + SICdr + (1 | IDr)
> > 
> >    AIC   BIC logLik deviance REMLdev
> > 
> >  270.2 297.6 -130.1    234.5   260.2
> > 
> > Random effects:
> > 
> >  Groups   Name        Variance Std.Dev.
> > 
> >  IDr      (Intercept) 0.010906 0.10443 
> > 
> >  Residual             0.060610 0.24619 
> > 
> > Number of obs: 1759, groups: IDr, 229
> > 
> >  
> > 
> > Fixed effects:
> > 
> >              Estimate Std. Error t value
> > 
> > (Intercept) 0.3070164  0.0155734  19.714
> > 
> > SEXrM       0.0961795  0.0195420   4.922
> > 
> > SICdr       0.0026240  0.0008478   3.095
> > 
> >  
> > 
> > Correlation of Fixed Effects:
> > 
> >       (Intr) SEXrM
> > 
> > SEXrM -0.612       
> > 
> > SICdr -0.478 -0.006
> > 
> >  
> > 
> > Here, the correlation between 2 observations from the same 
> individual 
> > (irrespective of year) is:
> > 0.010906/(0.010906+0.060610)=0.15
> > 
> >  
> > 
> > > M2 <- lmer(CPUEr~SEXr+SICdr+(1|YEARr))
> > 
> > > summary(M2)
> > 
> > Linear mixed model fit by REML
> > 
> > Formula: CPUEr ~ SEXr + SICdr + (1 | YEARr)
> > 
> >    AIC   BIC logLik deviance REMLdev
> > 
> >  117.1 144.5 -53.55     84.8   107.1
> > 
> > Random effects:
> > 
> >  Groups   Name        Variance Std.Dev.
> > 
> >  YEARr    (Intercept) 0.020395 0.14281 
> > 
> >  Residual             0.059892 0.24473 
> > 
> > Number of obs: 1759, groups: YEARr, 13
> > 
> >  
> > 
> > Fixed effects:
> > 
> >             Estimate Std. Error t value
> > 
> > (Intercept)  0.36443    0.04367   8.345
> > 
> > SEXrM        0.10819    0.01175   9.207
> > 
> > SICdr       -0.00920    0.00192  -4.793
> > 
> >  
> > 
> > Correlation of Fixed Effects:
> > 
> >       (Intr) SEXrM
> > 
> > SEXrM -0.134       
> > 
> > SICdr -0.367  0.009
> > 
> >  
> > 
> > Here, the correlation between 2 observations from the same year 
> > (irrespective of the bird) is:
> > 0.020395/(0.020395+0.059892)=0.25 How do I get the correlation of 2 
> > observations from the same individual within a year? By modeling 
> > CPUEr~SEXr+SICdr+(1|YEARr/IDr)?
> > 
> >  
> > 
> > > M3 <- lmer(CPUEr~SEXr+SICdr+(1|YEARr/IDr))
> > 
> > > summary(M3)
> > 
> > Linear mixed model fit by REML
> > 
> > Formula: CPUEr ~ SEXr + SICdr + (1 | YEARr/IDr)
> > 
> >    AIC   BIC logLik deviance REMLdev
> > 
> >  51.29 84.12 -19.64    17.21   39.29
> > 
> > Random effects:
> > 
> >  Groups    Name        Variance  Std.Dev.
> > 
> >  IDr:YEARr (Intercept) 0.0097178 0.09858
> > 
> >  YEARr     (Intercept) 0.0188065 0.13714 
> > 
> >  Residual              0.0500727 0.22377 
> > 
> > Number of obs: 1759, groups: IDr:YEARr, 543; YEARr, 13
> > 
> >  
> > 
> > Fixed effects:
> > 
> >              Estimate Std. Error t value
> > 
> > (Intercept)  0.357318   0.042408   8.426
> > 
> > SEXrM        0.104650   0.014207   7.366
> > 
> > SICdr       -0.008960   0.001855  -4.831
> > 
> >  
> > 
> > Correlation of Fixed Effects:
> > 
> >       (Intr) SEXrM
> > 
> > SEXrM -0.166       
> > 
> > SICdr -0.365  0.004
> > 
> >  
> > 
> > Then, would the correlation of 2 observations from the same 
> individual 
> > within a year be 0.0097178/(0.0097178+0.0500727)=0.16?
> > 
> >  
> > 
> > My best model (in terms of AIC) so far is the following:
> > 
> >  
> > 
> > > M4 <- lmer(CPUEr~SEXr+SICdr+(SICdr|IDr)+(1|YEARr))
> > 
> > > summary(M4)
> > 
> > Linear mixed model fit by REML
> > 
> > Formula: CPUEr ~ SEXr + SICdr + (SICdr | IDr) + (1 | YEARr)
> > 
> >    AIC   BIC logLik deviance REMLdev
> > 
> >  12.88 56.66  1.559   -24.55  -3.119
> > 
> > Random effects:
> > 
> >  Groups   Name        Variance   Std.Dev.  Corr   
> > 
> >  IDr      (Intercept) 8.9314e-03 0.0945058        
> > 
> >           SICdr       2.3781e-05 0.0048766 -0.464 
> > 
> >  YEARr    (Intercept) 2.1401e-02 0.1462922        
> > 
> >  Residual             5.0765e-02 0.2253112        
> > 
> > Number of obs: 1759, groups: IDr, 229; YEARr, 13
> > 
> >  
> > 
> > Fixed effects:
> > 
> >              Estimate Std. Error t value
> > 
> > (Intercept)  0.363366   0.045471   7.991
> > 
> > SEXrM        0.100215   0.017188   5.830
> > 
> > SICdr       -0.009910   0.001974  -5.021
> > 
> >  
> > 
> > Correlation of Fixed Effects:
> > 
> >       (Intr) SEXrM
> > 
> > SEXrM -0.189       
> > 
> > SICdr -0.357  0.010
> > 
> >  
> > 
> > How should I interpret the random effects?
> > 
> >  
> > 
> > I am using the R package version 0.999375-31 of lme4 and R version 
> > 2.9.2.
> > 
> >  
> > 
> > Thanks in advance for your help!
> > 
> >  
> > 
> > Cheers,
> > 
> >  
> > 
> > Amelie
> > 
> >  
> > 
> >  
> > 
> >  
> > 
> >  
> > 
> > 
> > 	[[alternative HTML version deleted]]
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > 
> 
> Druk dit bericht a.u.b. niet onnodig af.
> Please do not print this message unnecessarily.
> 
> Dit bericht en eventuele bijlagen geven enkel de visie van de 
> schrijver weer
> 
> en binden het INBO onder geen enkel beding, zolang dit 
> bericht niet bevestigd is door een geldig ondertekend
> document. The views expressed in  this message and any annex 
> are purely those of the writer and may not be regarded as 
> stating an official position of INBO, as long as the message 
> is not confirmed by a duly signed document.
> 
> 

Druk dit bericht a.u.b. niet onnodig af.
Please do not print this message unnecessarily.

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From malsburg at gmail.com  Wed Aug 18 11:42:13 2010
From: malsburg at gmail.com (Titus von der Malsburg)
Date: Wed, 18 Aug 2010 11:42:13 +0200
Subject: [R-sig-ME] Modeling polar coordinates
Message-ID: <AANLkTi=tv6oxXfE3k=Um=W7VFcn6Ydo5fQG8Cz89b3t2@mail.gmail.com>

I'd like to fit mixed models for polar coordinates.  Each point
represents the outcome of a trial in an experiment.  Items and
subjects will be crossed random effects.  Fitting a model for the
radius component is business as usual but I don't know how to approach
the azimuth component.  The problem is that 2pi and 0 specify the same
point on a circle and that the difference between 2pi-0.1 and 0.1 is
0.2 rather than ~6.08.  Is there a way to deal with that in lme4?

R-seek didn't yield anything useful, maybe I used bad search terms.
Thanks in advance for any advice!

Best,
  Titus



From maechler at stat.math.ethz.ch  Wed Aug 18 11:49:12 2010
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 18 Aug 2010 11:49:12 +0200
Subject: [R-sig-ME] my first random effects logistic regression
In-Reply-To: <8C92C98A-0FEE-4E55-AEC3-EAC85C949DD7@ed.ac.uk>
References: <7C79081F82FB544BAF7B847A02F87972019CCC25@KA-EXCHMBX-02.katho.local>
	<8C92C98A-0FEE-4E55-AEC3-EAC85C949DD7@ed.ac.uk>
Message-ID: <19563.44184.573252.589673@lynne.math.ethz.ch>

>>>>> "JH" == Jarrod Hadfield <j.hadfield at ed.ac.uk>
>>>>>     on Wed, 18 Aug 2010 09:56:36 +0100 writes:

    JH> Hi Dieter, I was writing this as Thierry posted. My
    JH> recommendation is similar, although you wont be able to
    JH> fit farm:flock in glmer because it will complain about
    JH> the number of random effects being equal to the number
    JH> of data. Anyhow....

That ("you wont be able ...") hasn't been true for a "while",
well at least since lme4 0.999375-34  has been released...

Martin

   [.......................]



From lborger at uoguelph.ca  Wed Aug 18 13:01:05 2010
From: lborger at uoguelph.ca (Luca Borger)
Date: Wed, 18 Aug 2010 07:01:05 -0400
Subject: [R-sig-ME] my first random effects logistic regression
References: <7C79081F82FB544BAF7B847A02F87972019CCC25@KA-EXCHMBX-02.katho.local><8C92C98A-0FEE-4E55-AEC3-EAC85C949DD7@ed.ac.uk>
	<19563.44184.573252.589673@lynne.math.ethz.ch>
Message-ID: <EB403773FC8C48E9A45B6C525A59E385@lborger>

> That ("you wont be able ...") hasn't been true for a "while",
> well at least since lme4 0.999375-34  has been released...

Was going to mention that, too. Hence, glmer happily fits all the models 
that have been proposed and they all give the same, or very similar, 
estimates, even the very complex (given the data) ones:


######## the data
broilers.dat<-
data.frame(farm=c("FA","FA","FA","FB","FB","FB","FC","FC","FC"),
flock=c("a","b","c","d","e","f","g","h","i"), broilers=c(50,
rep(25,8)), positives=c(7,2,0,7,2,0,0,0,2))

## model 1 and 2 are identical because "flock" has got a unique identifier

model1<-glmer(cbind(positives, broilers-positives) ~ 1 + (1|farm:flock), 
data=broilers.dat,
family=binomial(link="logit"))

model2 <-glmer(cbind(positives, broilers-positives) ~ 1 + (1|flock), 
data=broilers.dat,
family=binomial(link="logit"))

### compare model 3 and the quasi-glm suggested by Jarrod

model3 <-glmer(cbind(positives, broilers-positives) ~ farm + (1|flock), 
data=broilers.dat,
family=binomial(link="logit"))

glm3 <-glm(cbind(positives, broilers-positives)~farm,
data=broilers.dat, family=quasibinomial)


# response as binary
broilers.dat2<-broilers.dat[rep(1:9, broilers.dat$broilers),]
broilers.dat2$positives<-
(broilers.dat2$positives>=unlist(sapply(broilers.dat$broilers,
function(x){1:x})))


model4 <-glmer(positives~farm+(1|flock), data=broilers.dat2,
family=binomial)

model5<-glmer(positives~(1|farm)+(1|flock), data=broilers.dat2,
family=binomial)

model6 <-glmer(positives~ farm + (1|farm)+(1|flock), data=broilers.dat2,
family=binomial)




###########################
> print(model1, corr=FALSE)
Generalized linear mixed model fit by the Laplace approximation
Formula: cbind(positives, broilers - positives) ~ 1 + (1 | farm:flock)
   Data: broilers.dat
   AIC   BIC logLik deviance
 24.17 24.56 -10.08    20.17
Random effects:
 Groups     Name        Variance Std.Dev.
 farm:flock (Intercept) 1.4175   1.1906
Number of obs: 9, groups: farm:flock, 9

Fixed effects:
            Estimate Std. Error z value Pr(>|z|)
(Intercept)  -3.0486     0.5061  -6.024 1.70e-09 ***
---

###########################
> print(model2, corr=FALSE)
Generalized linear mixed model fit by the Laplace approximation
Formula: cbind(positives, broilers - positives) ~ 1 + (1 | flock)
   Data: broilers.dat
   AIC   BIC logLik deviance
 24.17 24.56 -10.08    20.17
Random effects:
 Groups Name        Variance Std.Dev.
 flock  (Intercept) 1.4175   1.1906
Number of obs: 9, groups: flock, 9

Fixed effects:
            Estimate Std. Error z value Pr(>|z|)
(Intercept)  -3.0486     0.5061  -6.024 1.70e-09 ***
---

###########################
> print(model5, corr=FALSE)
Generalized linear mixed model fit by the Laplace approximation
Formula: positives ~ (1 | farm) + (1 | flock)
   Data: broilers.dat2
   AIC   BIC logLik deviance
 138.1 148.7 -66.06    132.1
Random effects:
 Groups Name        Variance Std.Dev.
 flock  (Intercept) 1.4175   1.1906
 farm   (Intercept) 0.0000   0.0000
Number of obs: 250, groups: flock, 9; farm, 3

Fixed effects:
            Estimate Std. Error z value Pr(>|z|)
(Intercept)  -3.0487     0.5061  -6.024  1.7e-09 ***
---

###########################
> print(model3, corr=FALSE)
Generalized linear mixed model fit by the Laplace approximation
Formula: cbind(positives, broilers - positives) ~ farm + (1 | flock)
   Data: broilers.dat
   AIC   BIC logLik deviance
 26.25 27.04 -9.124    18.25
Random effects:
 Groups Name        Variance Std.Dev.
 flock  (Intercept) 0.87752  0.93676
Number of obs: 9, groups: flock, 9

Fixed effects:
            Estimate Std. Error z value Pr(>|z|)
(Intercept)  -2.7264     0.6939  -3.929 8.54e-05 ***
farmFB        0.3737     0.9752   0.383    0.702
farmFC       -1.2609     1.1981  -1.052    0.293
---

###########################
> summary(glm3)
Call:
glm(formula = cbind(positives, broilers - positives) ~ farm,
    family = quasibinomial, data = broilers.dat)

Deviance Residuals:
    Min       1Q   Median       3Q      Max
-2.5282  -1.1625  -0.6503   1.1514   2.1536

Coefficients:
            Estimate Std. Error t value Pr(>|t|)
(Intercept)  -2.3136     0.6050  -3.824  0.00872 **
farmFB        0.3212     0.8629   0.372  0.72250
farmFC       -1.2837     1.3806  -0.930  0.38835
---

(Dispersion parameter for quasibinomial family taken to be 2.997898)

    Null deviance: 27.425  on 8  degrees of freedom
Residual deviance: 22.030  on 6  degrees of freedom
AIC: NA
Number of Fisher Scoring iterations: 5

###########################
> print(model4, corr=FALSE)
Generalized linear mixed model fit by the Laplace approximation
Formula: positives ~ farm + (1 | flock)
   Data: broilers.dat2
   AIC   BIC logLik deviance
 138.2 152.3  -65.1    130.2
Random effects:
 Groups Name        Variance Std.Dev.
 flock  (Intercept) 0.87752  0.93676
Number of obs: 250, groups: flock, 9

Fixed effects:
            Estimate Std. Error z value Pr(>|z|)
(Intercept)  -2.7264     0.6939  -3.929 8.54e-05 ***
farmFB        0.3737     0.9752   0.383    0.702
farmFC       -1.2610     1.1981  -1.053    0.293
---

###########################
> print(model6, corr=FALSE)
Generalized linear mixed model fit by the Laplace approximation
Formula: positives ~ farm + (1 | farm) + (1 | flock)
   Data: broilers.dat2
   AIC   BIC logLik deviance
 140.2 157.8  -65.1    130.2
Random effects:
 Groups Name        Variance Std.Dev.
 flock  (Intercept) 0.87752  0.93676
 farm   (Intercept) 0.00000  0.00000
Number of obs: 250, groups: flock, 9; farm, 3

Fixed effects:
            Estimate Std. Error z value Pr(>|z|)
(Intercept)  -2.7263     0.6939  -3.929 8.54e-05 ***
farmFB        0.3737     0.9752   0.383    0.702
farmFC       -1.2611     1.1981  -1.053    0.293
---



############
> sessionInfo()
R version 2.11.1 (2010-05-31)
i386-pc-mingw32

locale:
[1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United 
Kingdom.1252    LC_MONETARY=English_United Kingdom.1252
[4] LC_NUMERIC=C                            LC_TIME=English_United 
Kingdom.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_0.999375-34   Matrix_0.999375-43 lattice_0.18-8

loaded via a namespace (and not attached):
[1] grid_2.11.1   nlme_3.1-96   stats4_2.11.1 tools_2.11.1
>
##########################################################################



Hope this is of any use.


Cheers,

Luca






----- Original Message ----- 
From: "Martin Maechler" <maechler at stat.math.ethz.ch>
To: "Jarrod Hadfield" <j.hadfield at ed.ac.uk>
Cc: <r-sig-mixed-models at r-project.org>
Sent: Wednesday, August 18, 2010 5:49 AM
Subject: Re: [R-sig-ME] my first random effects logistic regression


>>>>>> "JH" == Jarrod Hadfield <j.hadfield at ed.ac.uk>
>>>>>>     on Wed, 18 Aug 2010 09:56:36 +0100 writes:
>
>    JH> Hi Dieter, I was writing this as Thierry posted. My
>    JH> recommendation is similar, although you wont be able to
>    JH> fit farm:flock in glmer because it will complain about
>    JH> the number of random effects being equal to the number
>    JH> of data. Anyhow....
>
> That ("you wont be able ...") hasn't been true for a "while",
> well at least since lme4 0.999375-34  has been released...
>
> Martin
>
>   [.......................]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From mlarkin at rsmas.miami.edu  Wed Aug 18 17:28:12 2010
From: mlarkin at rsmas.miami.edu (Michael Larkin)
Date: Wed, 18 Aug 2010 11:28:12 -0400
Subject: [R-sig-ME] starting values are not correct length?
Message-ID: <000001cb3ee9$f857b230$e9071690$@miami.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100818/c9c3c89d/attachment.pl>

From andydolman at gmail.com  Wed Aug 18 17:36:35 2010
From: andydolman at gmail.com (Andrew Dolman)
Date: Wed, 18 Aug 2010 17:36:35 +0200
Subject: [R-sig-ME] starting values are not correct length?
In-Reply-To: <000001cb3ee9$f857b230$e9071690$@miami.edu>
References: <000001cb3ee9$f857b230$e9071690$@miami.edu>
Message-ID: <AANLkTi=W1xx5fGfXxL1khnZU6wx0bHShqgiK1sYowhjC@mail.gmail.com>

That error means that you've got the wrong number of starting values,
not that the values themselves are wrong. Don't you have 4 parameters
to estimate not 6?



andydolman at gmail.com



On 18 August 2010 17:28, Michael Larkin <mlarkin at rsmas.miami.edu> wrote:
> I am trying to run a non-linear mixed effect model. ?I keep getting the
> error of "starting values for the fixed component are not the correct
> length" ?I tried different sized values for the starting values but keep
> getting the same error message. ?Any advice would be greatly appreciated.
> My code is below.
>
>
>
> LVBbis.nlme=nlme(L~LVB(Age,t0,Lmax,K), data=datagr,
>
> fixed=list(t0~Pop-1,Lmax~Pop-1,K~Pop-1),
>
> random=t0+Lmax+K~1,
>
> start=list(fixed=c(-1.54,-1.54,710,700,0.21,0.21)))
>
>
>
>
>
> Mike
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From luciano.selzer at gmail.com  Wed Aug 18 17:37:23 2010
From: luciano.selzer at gmail.com (Luciano Selzer)
Date: Wed, 18 Aug 2010 12:37:23 -0300
Subject: [R-sig-ME] Modeling polar coordinates
In-Reply-To: <AANLkTi=tv6oxXfE3k=Um=W7VFcn6Ydo5fQG8Cz89b3t2@mail.gmail.com>
References: <AANLkTi=tv6oxXfE3k=Um=W7VFcn6Ydo5fQG8Cz89b3t2@mail.gmail.com>
Message-ID: <AANLkTinfhy13c2QNhBZEiEBY2GMt6ioTg-C12Rmkjr9J@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100818/609280eb/attachment.pl>

From malsburg at gmail.com  Wed Aug 18 18:00:06 2010
From: malsburg at gmail.com (Titus von der Malsburg)
Date: Wed, 18 Aug 2010 18:00:06 +0200
Subject: [R-sig-ME] Modeling polar coordinates
In-Reply-To: <AANLkTinfhy13c2QNhBZEiEBY2GMt6ioTg-C12Rmkjr9J@mail.gmail.com>
References: <AANLkTi=tv6oxXfE3k=Um=W7VFcn6Ydo5fQG8Cz89b3t2@mail.gmail.com>
	<AANLkTinfhy13c2QNhBZEiEBY2GMt6ioTg-C12Rmkjr9J@mail.gmail.com>
Message-ID: <20100818160006.GA26589@gmail.com>

On Wed, Aug 18, 2010 at 12:37:23PM -0300, Luciano Selzer wrote:
> I don't know if there's anything to deal with that builtin in lme4. But
> perhaps you could transform your polar coordinates to cartesian
> coordinates??

Hi Luciano.  Thanks for the suggestion but using cartesian coordinates
is unfortunately not possible.  I have one map for each experimental
item.  Each subject contributes one point to each map.  The maps where
derived using multi-dimensional scaling (MDS) and the solutions of MDS
are invariant to rotation.  This means that x- and y-axis do not mean
the same on those maps.  One goal of modeling the polar coordinates is
to find out how I have to rotate the maps in order to align them.  The
amount I have to rotate the maps would be given by the random
intercept for items.

  Titus



From lborger at uoguelph.ca  Wed Aug 18 18:16:32 2010
From: lborger at uoguelph.ca (Luca Borger)
Date: Wed, 18 Aug 2010 12:16:32 -0400
Subject: [R-sig-ME] Modeling polar coordinates
References: <AANLkTi=tv6oxXfE3k=Um=W7VFcn6Ydo5fQG8Cz89b3t2@mail.gmail.com><AANLkTinfhy13c2QNhBZEiEBY2GMt6ioTg-C12Rmkjr9J@mail.gmail.com>
	<20100818160006.GA26589@gmail.com>
Message-ID: <CEC4DD57CDE04EC18C2DB5460D3AF972@lborger>

Hello,

unless I'm misunderstanding, isn't this one of those cases were you need to 
use circular regression methods? e.g. for an example:

S. Rao Jammalamadaka and Ulric J. Lund (2006) "The effect of wind direction 
on ozone levels - a case study".
Environmental and Ecological Statistics 13(3): 287-298

so to analyse a variable like day of the year you need to multiply it by 
2*pi/365, then you can model it as a combination of sin and cos terms of the 
circualr variable in mixed effects models (please check the details for the 
polar coordinates - I think you can look up the examples where wind 
direction is modeled?).


HTH


Cheers,

Luca



----- Original Message ----- 
From: "Titus von der Malsburg" <malsburg at gmail.com>
To: "Luciano Selzer" <luciano.selzer at gmail.com>
Cc: <r-sig-mixed-models at r-project.org>
Sent: Wednesday, August 18, 2010 12:00 PM
Subject: Re: [R-sig-ME] Modeling polar coordinates


> On Wed, Aug 18, 2010 at 12:37:23PM -0300, Luciano Selzer wrote:
>> I don't know if there's anything to deal with that builtin in lme4. But
>> perhaps you could transform your polar coordinates to cartesian
>> coordinates??
>
> Hi Luciano.  Thanks for the suggestion but using cartesian coordinates
> is unfortunately not possible.  I have one map for each experimental
> item.  Each subject contributes one point to each map.  The maps where
> derived using multi-dimensional scaling (MDS) and the solutions of MDS
> are invariant to rotation.  This means that x- and y-axis do not mean
> the same on those maps.  One goal of modeling the polar coordinates is
> to find out how I have to rotate the maps in order to align them.  The
> amount I have to rotate the maps would be given by the random
> intercept for items.
>
>  Titus
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From andydolman at gmail.com  Wed Aug 18 20:41:05 2010
From: andydolman at gmail.com (Andrew Dolman)
Date: Wed, 18 Aug 2010 20:41:05 +0200
Subject: [R-sig-ME] starting values are not correct length?
In-Reply-To: <000001cb3eec$015f0700$041d1500$@miami.edu>
References: <000001cb3ee9$f857b230$e9071690$@miami.edu>
	<AANLkTi=W1xx5fGfXxL1khnZU6wx0bHShqgiK1sYowhjC@mail.gmail.com>
	<000001cb3eec$015f0700$041d1500$@miami.edu>
Message-ID: <AANLkTikzEaYeDvyWgPS6_QFz62-mM0+JSqh0kwaub62L@mail.gmail.com>

Hi Michael,

You might be right and it's 3 parameters to estimate, or fewer.
Depends on which of those parameters are in the data frame and which
are variables to be estimated in the equation/model LVB.


andydolman at gmail.com



On 18 August 2010 17:42, Michael Larkin <mlarkin at rsmas.miami.edu> wrote:
> Can you help me understand this code? ?How do you get 4 parameters instead of 3? ?I see three parameters: ?Lmax, t0, and K? ?I guess Age is the fourth parameter?
>
> LVBbis.nlme=nlme(L~LVB(Age,t0,Lmax,K), data=datagr,
> fixed=list(t0~Pop-1,Lmax~Pop-1,K~Pop-1),
> random=t0+Lmax+K~1,
> start=list(fixed=c(-1.54,-1.54,710,700,0.21,0.21)))
>
>
>
> -----Original Message-----
> From: Andrew Dolman [mailto:andydolman at gmail.com]
> Sent: Wednesday, August 18, 2010 11:37 AM
> To: Michael Larkin
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] starting values are not correct length?
>
> That error means that you've got the wrong number of starting values,
> not that the values themselves are wrong. Don't you have 4 parameters
> to estimate not 6?
>
>
>
> andydolman at gmail.com
>
>
>
> On 18 August 2010 17:28, Michael Larkin <mlarkin at rsmas.miami.edu> wrote:
>> I am trying to run a non-linear mixed effect model. I keep getting the
>> error of "starting values for the fixed component are not the correct
>> length" I tried different sized values for the starting values but keep
>> getting the same error message. Any advice would be greatly appreciated.
>> My code is below.
>>
>>
>>
>> LVBbis.nlme=nlme(L~LVB(Age,t0,Lmax,K), data=datagr,
>>
>> fixed=list(t0~Pop-1,Lmax~Pop-1,K~Pop-1),
>>
>> random=t0+Lmax+K~1,
>>
>> start=list(fixed=c(-1.54,-1.54,710,700,0.21,0.21)))
>>
>>
>>
>>
>>
>> Mike
>>
>>
>> ? ?[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>



From richard.feldman at mail.mcgill.ca  Thu Aug 19 23:32:14 2010
From: richard.feldman at mail.mcgill.ca (Richard Feldman)
Date: Thu, 19 Aug 2010 17:32:14 -0400
Subject: [R-sig-ME] Crossed effects and model selection
In-Reply-To: <mailman.9528.1282123080.4244.r-sig-mixed-models@r-project.org>
References: <mailman.9528.1282123080.4244.r-sig-mixed-models@r-project.org>
Message-ID: <4C6DA2DE.7090503@mail.mcgill.ca>

Hello all,

I am using AIC to select the best model from a model set. I am confused 
about what models to include when there are cross-level interactions.

Here is the model:

model <- glmer(Y ~ V1 * V2 + (V1|SITE), data=Data), which expands to

model <- glmer(Y ~ V1 + V2 + V1:V2 + (V1|SITE), data=Data)

V1 is a level-1 predictor and V2 is a level-2 (i.e. SITE) level predictor.

I am wondering whether the following model can be used in the set of models:

model.int <- glmer(Y ~ V1:V2 + (V1|SITE), data=Data), which actually tests:

model.int <- glmer(Y ~ V2 + V1:V2 + (V1|SITE), data=Data)


This model implies that the slope of V1 is modeled without an intercept:

The level-1 model is:

Yij = b0j + b1j*V1 + eij

The level-1 intercept and slope at level-2 are then:

B0j = p00 + p01*V2 + r0j

B1j = p10 + p11*V2 + r1j

Substituting the above into the full equation leads to:

Yij = p00 + p01*V2 + r0j + p10*V1 + p11*V1*V2 + r1j*V1 + eij

But since model.int doesn't contain a "main effect" V1, p10 must be zero 
and the slope has a zero intercept:

B1j = 0 + p11*V2 + r1j,

I would interpret this as meaning there is no ?average? effect of V1 on 
the response variable, Y, and that the effect of V1 on Y can only be 
interpreted based on the V2 value of the site. Is the above possible or 
must the slope-model retain its intercept parameter?

Thank you in advance!

Richard


-- 
Richard Feldman, PhD Candidate
Dept. of Biological Sciences, McGill University
W3/5 Stewart Biology Building
1205 Docteur Penfield
Montreal, QC H3A 1B1
514-212-3466
richard.feldman at mail.mcgill.ca



From ned.dochtermann at gmail.com  Fri Aug 20 04:01:41 2010
From: ned.dochtermann at gmail.com (Ned Dochtermann)
Date: Thu, 19 Aug 2010 19:01:41 -0700
Subject: [R-sig-ME] Additive versus multiplicative overdispersion modeling
Message-ID: <AANLkTim+GRgF2qPAAsJ2phav8K==dTom3RUzrK+f2fLo@mail.gmail.com>

First posting to the list, prior to sending this out I've tried
searching the mixed model list, other lists and anything google could
pick up.

I am currently trying to calculate repeatability estimates
(intra-class correlation coefficients) following Nakagawa & Schielzeth
(2010, Biol.Rev. Repeatability for Gaussian and non-Gaussian data: a
practical guide for biologists. online early). The details of my
models shouldn't be important except that I originally fit the models
using binomial error structures and a logit link. Nakagawa and
Schielzeth (henceforth N&S) specify that repeatability estimates
differ based on whether additive or multiplicative overdispersion
modelling is conducted.

N&S define multiplicative as when the dispersion parameter is
estimated but that residual variance is fixed to one. Additive is
defined as having the residual variance estimated and the dispersion
parameter fixed to one. These definitions are based on Browne et al.
(2005, J. Roy. Stat. Soc A, 168:599-613).

Based on my reading of the family objects description it seems that
using the quasibinomial family would correspond to the multiplicative
overdispersion modelling and the binomial family would correspond to
additive overdispersion modelling.

Is this conclusion about multiplicative vs. additive correct or am I
missing something? I do realize that when the dispersion parameter is
estimated as being close to one under a quasibinomial model then the
results should be close to what you'd get with a binomial approach
which makes me think I am missing something (since the multiplicative
model would have the residual variance fixed).

Thank you for any help you can provide.
Ned Dochtermann



--
Ned Dochtermann
Department of Biology
University of Nevada, Reno
--



From davidD at qimr.edu.au  Fri Aug 20 07:00:42 2010
From: davidD at qimr.edu.au (David Duffy)
Date: Fri, 20 Aug 2010 15:00:42 +1000 (EST)
Subject: [R-sig-ME] Additive versus multiplicative overdispersion
	modeling
In-Reply-To: <AANLkTim+GRgF2qPAAsJ2phav8K==dTom3RUzrK+f2fLo@mail.gmail.com>
References: <AANLkTim+GRgF2qPAAsJ2phav8K==dTom3RUzrK+f2fLo@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.1008201439540.15563@orpheus.qimr.edu.au>

On Thu, 19 Aug 2010, Ned Dochtermann wrote:

> I am currently trying to calculate repeatability estimates
> (intra-class correlation coefficients) following Nakagawa & Schielzeth
> (2010, Biol.Rev. Repeatability for Gaussian and non-Gaussian data: a
> practical guide for biologists. online early). The details of my
> models shouldn't be important except that I originally fit the models
> using binomial error structures and a logit link.

> Nakagawa and Schielzeth (henceforth N&S) specify that repeatability 
> estimates differ based on whether additive or multiplicative 
> overdispersion modelling is conducted.
[SNIP]
> These definitions are based on Browne et al.
> (2005, J. Roy. Stat. Soc A, 168:599-613).
>
> Based on my reading of the family objects description it seems that
> using the quasibinomial family would correspond to the multiplicative
> overdispersion modelling and the binomial family would correspond to
> additive overdispersion modelling.

Yes.  Browne et al say they are using the "additive" approach because it 
has a proper likelihood.

If you are interested in repeatability of binary measures, there are lots 
of perfectly good "direct" measures.  The thing about the GLMM variance 
components is that they are up in the latent variable part of the model. 
If you are using a probit-normal, you are getting (essentially) 
tetrachoric correlations, that is, estimating the correlation between the 
"true" continuous measures that are being arbitrarily dichotomized to give 
you your binary outcome.  For biometrical geneticists, this is a regarded 
as a good thing (Yule might disagree ;)), but might not be as useful for, 
say, assessing different clinical tests.  It really does depend on your
actual problem.

Cheers, David Duffy.
-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From ned.dochtermann at gmail.com  Sat Aug 21 00:19:04 2010
From: ned.dochtermann at gmail.com (Ned Dochtermann)
Date: Fri, 20 Aug 2010 15:19:04 -0700
Subject: [R-sig-ME] Additive versus multiplicative overdispersion
	modeling
In-Reply-To: <Pine.LNX.4.64.1008201439540.15563@orpheus.qimr.edu.au>
References: <AANLkTim+GRgF2qPAAsJ2phav8K==dTom3RUzrK+f2fLo@mail.gmail.com>
	<Pine.LNX.4.64.1008201439540.15563@orpheus.qimr.edu.au>
Message-ID: <AANLkTinanseqyrPL0Dyz+omRJV1Fnkn4o22Sogomz249@mail.gmail.com>

Thanks a lot, if that is indeed the case it makes calculating
repeatabilities per N&S quite straightforward for the multiplicative
models (quasibinomial & quasipoisson) since the relevant term to
include in the denominator would just be (summary(model)@sigma)^2
(multiplied by (pi^2)/3 ). Of course I still can't figure out how to
get the needed information from the additive models, i.e. the residual
of the distribution specific variance.


Ned

On Thu, Aug 19, 2010 at 10:00 PM, David Duffy <davidD at qimr.edu.au> wrote:
> On Thu, 19 Aug 2010, Ned Dochtermann wrote:
>
>> I am currently trying to calculate repeatability estimates
>> (intra-class correlation coefficients) following Nakagawa & Schielzeth
>> (2010, Biol.Rev. Repeatability for Gaussian and non-Gaussian data: a
>> practical guide for biologists. online early). The details of my
>> models shouldn't be important except that I originally fit the models
>> using binomial error structures and a logit link.
>
>> Nakagawa and Schielzeth (henceforth N&S) specify that repeatability
>> estimates differ based on whether additive or multiplicative overdispersion
>> modelling is conducted.
>
> [SNIP]
>>
>> These definitions are based on Browne et al.
>> (2005, J. Roy. Stat. Soc A, 168:599-613).
>>
>> Based on my reading of the family objects description it seems that
>> using the quasibinomial family would correspond to the multiplicative
>> overdispersion modelling and the binomial family would correspond to
>> additive overdispersion modelling.
>
> Yes. ?Browne et al say they are using the "additive" approach because it has
> a proper likelihood.
>
> If you are interested in repeatability of binary measures, there are lots of
> perfectly good "direct" measures. ?The thing about the GLMM variance
> components is that they are up in the latent variable part of the model. If
> you are using a probit-normal, you are getting (essentially) tetrachoric
> correlations, that is, estimating the correlation between the "true"
> continuous measures that are being arbitrarily dichotomized to give you your
> binary outcome. ?For biometrical geneticists, this is a regarded as a good
> thing (Yule might disagree ;)), but might not be as useful for, say,
> assessing different clinical tests. ?It really does depend on your
> actual problem.
>
> Cheers, David Duffy.
> --
> | David Duffy (MBBS PhD) ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ,-_|\
> | email: davidD at qimr.edu.au ?ph: INT+61+7+3362-0217 fax: -0101 ?/ ? ? *
> | Epidemiology Unit, Queensland Institute of Medical Research ? \_,-._/
> | 300 Herston Rd, Brisbane, Queensland 4029, Australia ?GPG 4D0B994A v
>



From j.hadfield at ed.ac.uk  Sat Aug 21 09:42:55 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sat, 21 Aug 2010 08:42:55 +0100
Subject: [R-sig-ME] Additive versus multiplicative
	overdispersion	modeling
In-Reply-To: <AANLkTinanseqyrPL0Dyz+omRJV1Fnkn4o22Sogomz249@mail.gmail.com>
References: <AANLkTim+GRgF2qPAAsJ2phav8K==dTom3RUzrK+f2fLo@mail.gmail.com>
	<Pine.LNX.4.64.1008201439540.15563@orpheus.qimr.edu.au>
	<AANLkTinanseqyrPL0Dyz+omRJV1Fnkn4o22Sogomz249@mail.gmail.com>
Message-ID: <20100821084255.mojc9mwpw00wsk80@www.staffmail.ed.ac.uk>

Hi Ned,

You can get the additive residual term of N&S by fitting an  
observation-level random effect (i.e. one effect for each datum). You  
will need the latest version of lme4 for this (not available for Mac).  
If the data are binary you can't estimate the residual, so it is usual  
just to set it to zero.

Cheers,

Jarrod


Quoting Ned Dochtermann <ned.dochtermann at gmail.com>:

> Thanks a lot, if that is indeed the case it makes calculating
> repeatabilities per N&S quite straightforward for the multiplicative
> models (quasibinomial & quasipoisson) since the relevant term to
> include in the denominator would just be (summary(model)@sigma)^2
> (multiplied by (pi^2)/3 ). Of course I still can't figure out how to
> get the needed information from the additive models, i.e. the residual
> of the distribution specific variance.
>
>
> Ned
>
> On Thu, Aug 19, 2010 at 10:00 PM, David Duffy <davidD at qimr.edu.au> wrote:
>> On Thu, 19 Aug 2010, Ned Dochtermann wrote:
>>
>>> I am currently trying to calculate repeatability estimates
>>> (intra-class correlation coefficients) following Nakagawa & Schielzeth
>>> (2010, Biol.Rev. Repeatability for Gaussian and non-Gaussian data: a
>>> practical guide for biologists. online early). The details of my
>>> models shouldn't be important except that I originally fit the models
>>> using binomial error structures and a logit link.
>>
>>> Nakagawa and Schielzeth (henceforth N&S) specify that repeatability
>>> estimates differ based on whether additive or multiplicative overdispersion
>>> modelling is conducted.
>>
>> [SNIP]
>>>
>>> These definitions are based on Browne et al.
>>> (2005, J. Roy. Stat. Soc A, 168:599-613).
>>>
>>> Based on my reading of the family objects description it seems that
>>> using the quasibinomial family would correspond to the multiplicative
>>> overdispersion modelling and the binomial family would correspond to
>>> additive overdispersion modelling.
>>
>> Yes. ?Browne et al say they are using the "additive" approach because it has
>> a proper likelihood.
>>
>> If you are interested in repeatability of binary measures, there are lots of
>> perfectly good "direct" measures. ?The thing about the GLMM variance
>> components is that they are up in the latent variable part of the model. If
>> you are using a probit-normal, you are getting (essentially) tetrachoric
>> correlations, that is, estimating the correlation between the "true"
>> continuous measures that are being arbitrarily dichotomized to give you your
>> binary outcome. ?For biometrical geneticists, this is a regarded as a good
>> thing (Yule might disagree ;)), but might not be as useful for, say,
>> assessing different clinical tests. ?It really does depend on your
>> actual problem.
>>
>> Cheers, David Duffy.
>> --
>> | David Duffy (MBBS PhD) ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ,-_|\
>> | email: davidD at qimr.edu.au ?ph: INT+61+7+3362-0217 fax: -0101 ?/ ? ? *
>> | Epidemiology Unit, Queensland Institute of Medical Research ? \_,-._/
>> | 300 Herston Rd, Brisbane, Queensland 4029, Australia ?GPG 4D0B994A v
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From j.hadfield at ed.ac.uk  Sat Aug 21 10:34:57 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sat, 21 Aug 2010 09:34:57 +0100
Subject: [R-sig-ME] Additive versus multiplicative
	overdispersion	modeling
In-Reply-To: <A8FBFDC5DA531A45B57C4AF622AE1C5AB2CC80B987@MAIL3.registry.otago.ac.nz>
References: <AANLkTim+GRgF2qPAAsJ2phav8K==dTom3RUzrK+f2fLo@mail.gmail.com>
	<Pine.LNX.4.64.1008201439540.15563@orpheus.qimr.edu.au>
	<AANLkTinanseqyrPL0Dyz+omRJV1Fnkn4o22Sogomz249@mail.gmail.com>,
	<20100821084255.mojc9mwpw00wsk80@www.staffmail.ed.ac.uk>
	<A8FBFDC5DA531A45B57C4AF622AE1C5AB2CC80B987@MAIL3.registry.otago.ac.nz>
Message-ID: <20100821093457.c11yltxum8w4ckos@www.staffmail.ed.ac.uk>

Hi Shinichi,

Just tried - this works for me.

Cheers,

Jarrod
Quoting Shinichi Nakagawa <shinichi.nakagawa at otago.ac.nz>:

> Hi, Jarrod
>
> I think you can probably install lme4 on Mac - see the blog and its   
> correspondences (I have not tried myself).
>
> http://www.stat.columbia.edu/~cook/movabletype/archives/2010/08/multilevel_mode_11.html
>
> Thanks for the tip
>
> Best wishes
>
> Shinichi
>
> Shinichi Nakagawa, PhD
> (Lecturer of Behavioural Ecology)
> Department of Zoology
> University of Otago
> 340 Great King Street
> P. O. Box 56
> Dunedin, New Zealand
> Tel:  +64-3-479-5046
> Fax: +64-3-479-7584
> http://www.otago.ac.nz/zoology/staff/academic/nakagawa.html
> ________________________________________
> From: Jarrod Hadfield [j.hadfield at ed.ac.uk]
> Sent: Saturday, 21 August 2010 7:42 p.m.
> To: Ned Dochtermann
> Cc: David Duffy; r-sig-mixed-models at r-project.org; Holger   
> Schielzeth; Shinichi Nakagawa
> Subject: Re: [R-sig-ME] Additive versus multiplicative   
> overdispersion   modeling
>
> Hi Ned,
>
> You can get the additive residual term of N&S by fitting an
> observation-level random effect (i.e. one effect for each datum). You
> will need the latest version of lme4 for this (not available for Mac).
> If the data are binary you can't estimate the residual, so it is usual
> just to set it to zero.
>
> Cheers,
>
> Jarrod
>
>
> Quoting Ned Dochtermann <ned.dochtermann at gmail.com>:
>
>> Thanks a lot, if that is indeed the case it makes calculating
>> repeatabilities per N&S quite straightforward for the multiplicative
>> models (quasibinomial & quasipoisson) since the relevant term to
>> include in the denominator would just be (summary(model)@sigma)^2
>> (multiplied by (pi^2)/3 ). Of course I still can't figure out how to
>> get the needed information from the additive models, i.e. the residual
>> of the distribution specific variance.
>>
>>
>> Ned
>>
>> On Thu, Aug 19, 2010 at 10:00 PM, David Duffy <davidD at qimr.edu.au> wrote:
>>> On Thu, 19 Aug 2010, Ned Dochtermann wrote:
>>>
>>>> I am currently trying to calculate repeatability estimates
>>>> (intra-class correlation coefficients) following Nakagawa & Schielzeth
>>>> (2010, Biol.Rev. Repeatability for Gaussian and non-Gaussian data: a
>>>> practical guide for biologists. online early). The details of my
>>>> models shouldn't be important except that I originally fit the models
>>>> using binomial error structures and a logit link.
>>>
>>>> Nakagawa and Schielzeth (henceforth N&S) specify that repeatability
>>>> estimates differ based on whether additive or multiplicative   
>>>> overdispersion
>>>> modelling is conducted.
>>>
>>> [SNIP]
>>>>
>>>> These definitions are based on Browne et al.
>>>> (2005, J. Roy. Stat. Soc A, 168:599-613).
>>>>
>>>> Based on my reading of the family objects description it seems that
>>>> using the quasibinomial family would correspond to the multiplicative
>>>> overdispersion modelling and the binomial family would correspond to
>>>> additive overdispersion modelling.
>>>
>>> Yes.  Browne et al say they are using the "additive" approach   
>>> because it has
>>> a proper likelihood.
>>>
>>> If you are interested in repeatability of binary measures, there   
>>> are lots of
>>> perfectly good "direct" measures.  The thing about the GLMM variance
>>> components is that they are up in the latent variable part of the model. If
>>> you are using a probit-normal, you are getting (essentially) tetrachoric
>>> correlations, that is, estimating the correlation between the "true"
>>> continuous measures that are being arbitrarily dichotomized to   
>>> give you your
>>> binary outcome.  For biometrical geneticists, this is a regarded as a good
>>> thing (Yule might disagree ;)), but might not be as useful for, say,
>>> assessing different clinical tests.  It really does depend on your
>>> actual problem.
>>>
>>> Cheers, David Duffy.
>>> --
>>> | David Duffy (MBBS PhD)                                         ,-_|\
>>> | email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
>>> | Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
>>> | 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From shinichi.nakagawa at otago.ac.nz  Sat Aug 21 10:17:28 2010
From: shinichi.nakagawa at otago.ac.nz (Shinichi Nakagawa)
Date: Sat, 21 Aug 2010 20:17:28 +1200
Subject: [R-sig-ME] Additive versus multiplicative
	overdispersion	modeling
In-Reply-To: <20100821084255.mojc9mwpw00wsk80@www.staffmail.ed.ac.uk>
References: <AANLkTim+GRgF2qPAAsJ2phav8K==dTom3RUzrK+f2fLo@mail.gmail.com>
	<Pine.LNX.4.64.1008201439540.15563@orpheus.qimr.edu.au>
	<AANLkTinanseqyrPL0Dyz+omRJV1Fnkn4o22Sogomz249@mail.gmail.com>,
	<20100821084255.mojc9mwpw00wsk80@www.staffmail.ed.ac.uk>
Message-ID: <A8FBFDC5DA531A45B57C4AF622AE1C5AB2CC80B987@MAIL3.registry.otago.ac.nz>

Hi, Jarrod

I think you can probably install lme4 on Mac - see the blog and its correspondences (I have not tried myself).

http://www.stat.columbia.edu/~cook/movabletype/archives/2010/08/multilevel_mode_11.html

Thanks for the tip

Best wishes

Shinichi

Shinichi Nakagawa, PhD
(Lecturer of Behavioural Ecology)
Department of Zoology
University of Otago
340 Great King Street
P. O. Box 56
Dunedin, New Zealand
Tel:  +64-3-479-5046
Fax: +64-3-479-7584
http://www.otago.ac.nz/zoology/staff/academic/nakagawa.html
________________________________________
From: Jarrod Hadfield [j.hadfield at ed.ac.uk]
Sent: Saturday, 21 August 2010 7:42 p.m.
To: Ned Dochtermann
Cc: David Duffy; r-sig-mixed-models at r-project.org; Holger Schielzeth; Shinichi Nakagawa
Subject: Re: [R-sig-ME] Additive versus multiplicative overdispersion   modeling

Hi Ned,

You can get the additive residual term of N&S by fitting an
observation-level random effect (i.e. one effect for each datum). You
will need the latest version of lme4 for this (not available for Mac).
If the data are binary you can't estimate the residual, so it is usual
just to set it to zero.

Cheers,

Jarrod


Quoting Ned Dochtermann <ned.dochtermann at gmail.com>:

> Thanks a lot, if that is indeed the case it makes calculating
> repeatabilities per N&S quite straightforward for the multiplicative
> models (quasibinomial & quasipoisson) since the relevant term to
> include in the denominator would just be (summary(model)@sigma)^2
> (multiplied by (pi^2)/3 ). Of course I still can't figure out how to
> get the needed information from the additive models, i.e. the residual
> of the distribution specific variance.
>
>
> Ned
>
> On Thu, Aug 19, 2010 at 10:00 PM, David Duffy <davidD at qimr.edu.au> wrote:
>> On Thu, 19 Aug 2010, Ned Dochtermann wrote:
>>
>>> I am currently trying to calculate repeatability estimates
>>> (intra-class correlation coefficients) following Nakagawa & Schielzeth
>>> (2010, Biol.Rev. Repeatability for Gaussian and non-Gaussian data: a
>>> practical guide for biologists. online early). The details of my
>>> models shouldn't be important except that I originally fit the models
>>> using binomial error structures and a logit link.
>>
>>> Nakagawa and Schielzeth (henceforth N&S) specify that repeatability
>>> estimates differ based on whether additive or multiplicative overdispersion
>>> modelling is conducted.
>>
>> [SNIP]
>>>
>>> These definitions are based on Browne et al.
>>> (2005, J. Roy. Stat. Soc A, 168:599-613).
>>>
>>> Based on my reading of the family objects description it seems that
>>> using the quasibinomial family would correspond to the multiplicative
>>> overdispersion modelling and the binomial family would correspond to
>>> additive overdispersion modelling.
>>
>> Yes.  Browne et al say they are using the "additive" approach because it has
>> a proper likelihood.
>>
>> If you are interested in repeatability of binary measures, there are lots of
>> perfectly good "direct" measures.  The thing about the GLMM variance
>> components is that they are up in the latent variable part of the model. If
>> you are using a probit-normal, you are getting (essentially) tetrachoric
>> correlations, that is, estimating the correlation between the "true"
>> continuous measures that are being arbitrarily dichotomized to give you your
>> binary outcome.  For biometrical geneticists, this is a regarded as a good
>> thing (Yule might disagree ;)), but might not be as useful for, say,
>> assessing different clinical tests.  It really does depend on your
>> actual problem.
>>
>> Cheers, David Duffy.
>> --
>> | David Duffy (MBBS PhD)                                         ,-_|\
>> | email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
>> | Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
>> | 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



--
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From spluque at gmail.com  Sat Aug 21 19:07:56 2010
From: spluque at gmail.com (Sebastian P. Luque)
Date: Sat, 21 Aug 2010 12:07:56 -0500
Subject: [R-sig-ME] alternative interaction representations
Message-ID: <87hbinvqqb.fsf@kolob.sebmags.homelinux.org>

Hi,

## With the CO2 data, suppose we want to build a LME model of 'uptake' with
## 'conc' (continuous) and want to know whether there is a change in slope
## at conc=300, with random slopes for plants

CO2new <- subset(CO2, Type == "Quebec" & Treatment == "nonchilled")
CO2new <- within(CO2new, {
    ## The more intuitive way to set up the interaction is to first define
    ## a factor breaking up the 'conc' predictor
    stage1 <- cut(conc, breaks=c(floor(min(conc)), 300,
                          ceiling(max(conc))),
                  labels=c("pre", "post"), include.lowest=TRUE)
    ## Alternative, direct representation of interaction
    stage2 <- ifelse(conc > 300, conc - 300, 0)
    ## We center conc at 300 for interpreting intercept here
    conc <- conc - 300
})
str(CO2new)
xyplot(uptake ~ conc, data=CO2new, groups=Plant, type="b")

## Consider a model with fixed effects for intercept, conc, and varying
## slopes.  Using the more intuitive representation:

(fm1 <- lmer(uptake ~ conc + conc:stage1 + (conc:stage1 | Plant), data=CO2new))

## And using the direct representation of the interaction

(fm2 <- lmer(uptake ~ conc + stage2 + (conc + stage2 | Plant), data=CO2new))

## In this simple case, it doesn't seem to matter which representation is
## used.  For other models where an interaction with another factor, say
## Type, is needed in the model to indicate 3-way interactions with conc
## then the latter seems to allow for a simpler model (which may impact
## lmer performance) because the interaction would then be modelled as a
## 2-way interaction.
##
## Is this a fair comparison of using direct representations of
## interactions compared to the more natural factor-based representations?
## Overall, is it preferable to use one rather than the other?

Cheers,

-- 
Seb



From reinhold.kliegl at gmail.com  Sun Aug 22 08:47:47 2010
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Sun, 22 Aug 2010 08:47:47 +0200
Subject: [R-sig-ME] alternative interaction representations
In-Reply-To: <87hbinvqqb.fsf@kolob.sebmags.homelinux.org>
References: <87hbinvqqb.fsf@kolob.sebmags.homelinux.org>
Message-ID: <AANLkTinOLnCVFCYL+te8eMD5j=kt+=+X928QSCAPLWm_@mail.gmail.com>

# This representation fits two linear slopes, one below and one after
conc = 300, splicing them at 0:
CO2new$conc1 <- ifelse(CO2new$conc < 300, CO2new$conc - 300, 0)
CO2new$conc2 <- ifelse(CO2new$conc > 300, CO2new$conc - 300, 0)

# Basic LMM
print(LMM <- lmer(uptake ~ conc1 + conc2 + (1 | Plant), data=CO2new), cor=FALSE)
#  ... the linear uptake is significant below 300, no longer
significant after 300
# ... the intercept estimates the upake at conc=300

# To test whether there is significant between-plant variance in
slopes below and above conc:
# Varying-slopes LMM
print(LMM.conc.1 <-   lmer(uptake ~ conc1 + conc2 + (1 | Plant) +
(0+conc1 | Plant), data=CO2new), cor=FALSE)
print(LMM.conc.2 <-   lmer(uptake ~ conc1 + conc2 + (1 | Plant) +
(0+conc2 | Plant), data=CO2new), cor=FALSE)
#print(LMM.conc.1.2 <- lmer(uptake ~ conc1 + conc2 + (1 | Plant) +
(0+conc1 | Plant) + (0+conc2 | Plant), data=CO2new), cor=FALSE)
#print(LMM.conc.12 <-  lmer(uptake ~ conc1 + conc2 + (1 + conc1 +
conc2 | Plant), data=CO2new), cor=FALSE)

anova(LMM, LMM.conc.1)
anova(LMM, LMM.conc.2)
#  Apparently there is not enough information in the data to test the
between-slope variance.

Reinhold Kliegl

On Sat, Aug 21, 2010 at 7:07 PM, Sebastian P. Luque <spluque at gmail.com> wrote:
> Hi,
>
> ## With the CO2 data, suppose we want to build a LME model of 'uptake' with
> ## 'conc' (continuous) and want to know whether there is a change in slope
> ## at conc=300, with random slopes for plants
>
> CO2new <- subset(CO2, Type == "Quebec" & Treatment == "nonchilled")
> CO2new <- within(CO2new, {
> ? ?## The more intuitive way to set up the interaction is to first define
> ? ?## a factor breaking up the 'conc' predictor
> ? ?stage1 <- cut(conc, breaks=c(floor(min(conc)), 300,
> ? ? ? ? ? ? ? ? ? ? ? ? ?ceiling(max(conc))),
> ? ? ? ? ? ? ? ? ?labels=c("pre", "post"), include.lowest=TRUE)
> ? ?## Alternative, direct representation of interaction
> ? ?stage2 <- ifelse(conc > 300, conc - 300, 0)
> ? ?## We center conc at 300 for interpreting intercept here
> ? ?conc <- conc - 300
> })
> str(CO2new)
> xyplot(uptake ~ conc, data=CO2new, groups=Plant, type="b")
>
> ## Consider a model with fixed effects for intercept, conc, and varying
> ## slopes. ?Using the more intuitive representation:
>
> (fm1 <- lmer(uptake ~ conc + conc:stage1 + (conc:stage1 | Plant), data=CO2new))
>
> ## And using the direct representation of the interaction
>
> (fm2 <- lmer(uptake ~ conc + stage2 + (conc + stage2 | Plant), data=CO2new))
>
> ## In this simple case, it doesn't seem to matter which representation is
> ## used. ?For other models where an interaction with another factor, say
> ## Type, is needed in the model to indicate 3-way interactions with conc
> ## then the latter seems to allow for a simpler model (which may impact
> ## lmer performance) because the interaction would then be modelled as a
> ## 2-way interaction.
> ##
> ## Is this a fair comparison of using direct representations of
> ## interactions compared to the more natural factor-based representations?
> ## Overall, is it preferable to use one rather than the other?
>
> Cheers,
>
> --
> Seb
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From spluque at gmail.com  Sun Aug 22 21:39:05 2010
From: spluque at gmail.com (Sebastian P. Luque)
Date: Sun, 22 Aug 2010 14:39:05 -0500
Subject: [R-sig-ME] alternative interaction representations
In-Reply-To: <AANLkTinOLnCVFCYL+te8eMD5j=kt+=+X928QSCAPLWm_@mail.gmail.com>
	(Reinhold Kliegl's message of "Sun, 22 Aug 2010 08:47:47 +0200")
References: <87hbinvqqb.fsf@kolob.sebmags.homelinux.org>
	<AANLkTinOLnCVFCYL+te8eMD5j=kt+=+X928QSCAPLWm_@mail.gmail.com>
Message-ID: <87bp8ue8ti.fsf@kolob.sebmags.homelinux.org>

On Sun, 22 Aug 2010 08:47:47 +0200,
Reinhold Kliegl <reinhold.kliegl-Re5JQEeQqe8AvxtiuMwx3w at public.gmane.org> wrote:

> # This representation fits two linear slopes, one below and one after
> conc = 300, splicing them at 0:
> CO2new$conc1 <- ifelse(CO2new$conc < 300, CO2new$conc - 300, 0)
> CO2new$conc2 <- ifelse(CO2new$conc > 300, CO2new$conc - 300, 0)

> # Basic LMM
> print(LMM <- lmer(uptake ~ conc1 + conc2 + (1 | Plant), data=CO2new), cor=FALSE)
> #  ... the linear uptake is significant below 300, no longer
> significant after 300
> # ... the intercept estimates the upake at conc=300

> # To test whether there is significant between-plant variance in
> slopes below and above conc:
> # Varying-slopes LMM
> print(LMM.conc.1 <-   lmer(uptake ~ conc1 + conc2 + (1 | Plant) +
> (0+conc1 | Plant), data=CO2new), cor=FALSE)
> print(LMM.conc.2 <-   lmer(uptake ~ conc1 + conc2 + (1 | Plant) +
> (0+conc2 | Plant), data=CO2new), cor=FALSE)
> #print(LMM.conc.1.2 <- lmer(uptake ~ conc1 + conc2 + (1 | Plant) +
> (0+conc1 | Plant) + (0+conc2 | Plant), data=CO2new), cor=FALSE)
> #print(LMM.conc.12 <-  lmer(uptake ~ conc1 + conc2 + (1 + conc1 +
> conc2 | Plant), data=CO2new), cor=FALSE)

> anova(LMM, LMM.conc.1)
> anova(LMM, LMM.conc.2)
> #  Apparently there is not enough information in the data to test the
> between-slope variance.

Thanks Reinhold, it seems as if these piecewise linear splines with one
or two knots are easier to fit and interpret than using a factor.

Cheers,

-- 
Seb



From davidD at qimr.edu.au  Mon Aug 23 03:39:05 2010
From: davidD at qimr.edu.au (David Duffy)
Date: Mon, 23 Aug 2010 11:39:05 +1000 (EST)
Subject: [R-sig-ME] Additive versus multiplicative overdispersion
	modeling
In-Reply-To: <AANLkTinanseqyrPL0Dyz+omRJV1Fnkn4o22Sogomz249@mail.gmail.com>
References: <AANLkTim+GRgF2qPAAsJ2phav8K==dTom3RUzrK+f2fLo@mail.gmail.com><Pine.LNX.4.64.1008201439540.15563@orpheus.qimr.edu.au>
	<AANLkTinanseqyrPL0Dyz+omRJV1Fnkn4o22Sogomz249@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.1008231132330.13523@orpheus.qimr.edu.au>

On Fri, 20 Aug 2010, Ned Dochtermann wrote:

> Thanks a lot, if that is indeed the case it makes calculating
> repeatabilities per N&S quite straightforward for the multiplicative
> models (quasibinomial & quasipoisson) since the relevant term to
> include in the denominator would just be (summary(model)@sigma)^2
> (multiplied by (pi^2)/3 ). Of course I still can't figure out how to
> get the needed information from the additive models, i.e. the residual
> of the distribution specific variance.
>

Method "C" in the Browne paper uses: r = V/(V+pi^2/3) for the logistic 
link, and r=V/(V+1) for the probit link (the latter is the tetrachoric r).

Cheers, David Duffy.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From Mike.Lawrence at dal.ca  Mon Aug 23 16:04:19 2010
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Mon, 23 Aug 2010 11:04:19 -0300
Subject: [R-sig-ME] Bootstrapping mixed effects models
Message-ID: <AANLkTi=JKuMsxmYxQEr39+kmMz9HxvfVutJB_C6KoOo2@mail.gmail.com>

Hi folks,

Visual data analysis is very important in my field (cognitive
science), and while I know that you can obtain confidence intervals
for the cells of a fixed-effects design (as described at
http://glmm.wikidot.com/faq ), and confidence intervals for each
effect/interaction via MCMC, these approaches (at least, as I
understand them) fail to completely satisfy me. I can provide further
details details on my (possibly naive) dissatisfaction if necessary,
but for now I would be grateful for feedback on a solution I've come
up with that lets me visualize any level of the data I choose.

The approach I take is to obtain the model predictions for each cell
of the fixed-effects design, then bootstrap distributions of
predictions for each cell. The data I typically encounter have only
one random effect (experiment participant), and many observations
within each participant and cell of the fixed-effects design, so on
each iteration of the bootstrap I resample participants then resample
observations independently within each individual in the new sample of
participants (as recommended by:
http://stats.stackexchange.com/questions/1399/obtaining-and-interpreting-bootstrapped-confidence-intervals-from-hierarchical-da).

This yields distributions of predicted values for each cell of the
fixed-effects design which can be used to generate CIs for each cell,
but also can be used to compute the CI for any effect/interaction. For
example, if I suspect (whether a priori or by looking at the t-values
from the original model) that there's an interaction between the
2-level and 4-level predictors, I can generate 2 useful graphs:
(1) collapse the 3-level predictor to a mean within each iteration and
plot the resulting set of 8 means and associated CIs.
(2) collapse the 3-level predictor to a mean within each iteration
*then* collapse the 2-level predictor to a difference score within
each iteration and plot the resulting set of 4 means and associated
CIs

If I have a numeric predictor in the model, I would obtain predictions
across a set of values across the range of this predictor (eg. seq(
min(nIV) , max(nIV) , length.out = 1e3 ) ).

One thing I like about this approach is that within each predictor I
don't have to specify an intercept level to which the other levels are
compared. Furthermore, where I typically deal with data that is
strongly positively skewed (human response times), I wonder if the
non-parametric-ness of bootstrapping actually improves inference
relative to looking simply at the t-values from the original model or
anova()-based sub-model comparisons, both of which assume gaussian
error as I understand it.

I'd appreciate feedback on the reasonability of this approach.

Cheers,

Mike

-- 
Mike Lawrence
Graduate Student
Department of Psychology
Dalhousie University

Looking to arrange a meeting? Check my public calendar:
http://tr.im/mikes_public_calendar

~ Certainty is folly... I think. ~



From arrayprofile at yahoo.com  Tue Aug 24 10:02:01 2010
From: arrayprofile at yahoo.com (array chip)
Date: Tue, 24 Aug 2010 01:02:01 -0700 (PDT)
Subject: [R-sig-ME] longitudinal with 2 time points
In-Reply-To: <5992F7D6-7C3D-4AC2-A8AD-3D9AED2CA3D5@me.com>
References: <439946.26259.qm@web56301.mail.re3.yahoo.com>
	<B80EFDF8-B705-4EBA-A80E-9A4354F08353@anu.edu.au>
	<alpine.WNT.2.00.1008110532370.640@TED2>
	<8D383357-99BA-4447-A93B-0D8FC7AF7279@me.com>
	<323634.22474.qm@web56305.mail.re3.yahoo.com>
	<FB025028-0C67-4B59-9757-FC2305C07EA6@me.com>
	<111355.9211.qm@web56301.mail.re3.yahoo.com>
	<5992F7D6-7C3D-4AC2-A8AD-3D9AED2CA3D5@me.com>
Message-ID: <515776.45518.qm@web56301.mail.re3.yahoo.com>

Hi Marc,

I have to admit that I didn't get a chance to carefully read the article before 
my previous reply. So I want to wait till now to respond after finally I got a 
chance to read the article. Thanks for?your excellent explanation below. I agree 
that the coefficient for treatment is estimating?the extent of the difference 
between treatment and control?in?the CHANGE of glucose in week 4 from baseline.

Now my dataset becomes a little bt more complicated: each glucose testing was 
done twice (blood was draw from left arm and right arm and tested separately. So 
for each patient, on each time point, there are 2 measurements (from left and 
right arm separately). So I think I should now include factor "arm" as a random 
effect:

lmer(wk4.glucose ~ baseline.glucose + treatment + gender + age+ 
(1|subject/time))

What do you think of this model specification?
?
Adiitionally, since I am using mixed model now, if I code a new variable ?time? 
(either 0 or 4) and new response variable ?y?, how do I specify a mixed model 
with 2 random effects, one with respect to ?time? variable (2 time points per 
subject per arm), the other with respect to ?arm? variable (2 arms per subject 
per time point)?
?
Thanks a lot!
?John




----- Original Message ----
From: Marc Schwartz <marc_schwartz at me.com>
To: array chip <arrayprofile at yahoo.com>
Cc: r-sig-mixed-models at r-project.org
Sent: Fri, August 13, 2010 7:24:59 AM
Subject: Re: [R-sig-ME] longitudinal with 2 time points

John,

That you are asking this question indicates that either you have yet to read the 
article or that you need to re-read it, as you have not comprehended the 
content.

The beta coefficient for treatment IS the difference in mean glucose change 
between baseline and 4 weeks **attributable to treatment**, after adjusting for 
any baseline differences in glucose between the two groups. That is also 
presuming that there is no interaction at baseline.

For example, let's say that the beta for treatment is -20. Then, at 4 weeks, 
given the same baseline glucose level, we would predict that, on average, the 
treatment group will have a glucose level 20 mg/dl less than the control group. 


In the absence of an interaction, we would estimate the same average treatment 
difference at 4 weeks of 20 mg/dl whether the baseline glucose was 300 mg/dl or 
100 mg/dl. 


However, given regression to the mean, we might reasonably expect the patient 
with a 300 mg/dl baseline level to have a greater mean reduction at 4 weeks as 
compared to the patient with a 100 mg/dl baseline level. 


We might also expect a patient with a glucose level at the low end of the 
baseline range (eg. 50 mg/dl) to experience an average increase in glucose level 
at 4 weeks, presuming that your inclusion/exclusion criteria permitted patients 
with below normal glucose levels. But the difference will still be, on average, 
20 mg/dl between the two treatment groups.

So the patient with a 300 mg/dl baseline level might have an average reduction 
to 200 mg/dl at 4 weeks on the control treatment, whereas the same patient on 
the active treatment would have an average reduction to 180 mg/dl (a difference 
of -20).

The patient with a 100 mg/dl baseline level might have an average reduction to 
90 mg/dl at 4 weeks on the control treatment, whereas the same patient on the 
active treatment would have an average reduction to 70 mg/dl (again, a 
difference of -20).

The patient with a 50 mg/dl baseline level might have an average increase to 90 
mg/dl at 4 weeks on the control treatment, whereas the same patient on the 
active treatment would have an average increase to 70 mg/dl (yet again, a 
difference of -20).

So your conclusion would be that on average, between baseline and 4 weeks, 
glucose levels were reduced by 20 mg/dl more in the active treatment group 
relative to control.

This difference is the vertical separation in the two parallel fitted regression 
lines as shown in the figure in the paper.

So the method is answering exactly the question the investigator is asking.

Marc


On Aug 13, 2010, at 1:02 AM, array chip wrote:

> Marc,
> 
> Thanks for sharing your insights. Let's take this model as an example:
> 
>? lm(wk4.glucose ~ baseline.glucose + treatment + gender + age)
> 
> Because the investigator is interested in knowing whether the CHANGE of glucose 
>
> in week 4 from baseline is different between treatment and control, Is it still 
>
> legitimate to ask whether and HOW can we test this hypothesis? I think the 
> coefficient of the treatment factor is only testing whether the week 4 glucose 

> level is different between treatment and control, but not testing whether 
> the CHANGE of week 4 glucose level with respect to baseline is different 
>between 
>
> treatment and control.
> 
> Thanks again for your suggestion.
> 
> Yi
> 
> 
> 
>? 
> 
> 
> ----- Original Message ----
> From: Marc Schwartz <marc_schwartz at me.com>
> To: array chip <arrayprofile at yahoo.com>
> Cc: Charles E. (Ted) Wright <cewright at uci.edu>; John Maindonald 
> <john.maindonald at anu.edu.au>; r-sig-mixed-models at r-project.org
> Sent: Thu, August 12, 2010 6:02:29 AM
> Subject: Re: [R-sig-ME] longitudinal with 2 time points
> 
> Hi John,
> 
> If you read that article, you will see that your use of delta.y as the 
>dependent 
>
> variable does not make sense.
> 
> Thus, I would re-express your model 5 as:
> 
>? lm(wk4.glucose ~ baseline.glucose + treatment + gender + age)
> 
> and as noted, check for the interaction between baseline glucose and 
treatment:
> 
>? lm(wk4.glucose ~ baseline.glucose * treatment + gender + age)
> 
> 
> You might also want to consider using a spline function on age, presuming that 

> age is hopefully measured as a continuous variable (eg. not ordinal groups).
> 
> Since the ANCOVA based approach described in the paper is essentially an OLS 
> linear regression, you can of course include the additional covariates for 
> adjustment. If the interaction term p value is >0.1 (a common threshold), you 
> can remove it and the beta coefficient and its CIs for the treatment factor is 

> your estimated treatment effect relative to your control.
> 
> For the presentation of the results, besides the obvious tabular summaries and 

> the scatter/regression lines plot, include a series of plots showing selected 
> baseline values and the treatment versus control predicted follow up values and 
>
> CIs for the same baseline value in each plot. This visually shows the common 
> estimated treatment effect for each baseline value, which will also tend to 
> reveal regression to the mean. This presentation is especially helpful if the 
> interaction term is retained, which therefore shows how the treatment effect 
> varies and will reverse, over the range of the baseline values. You can select 
>a 
>
> series of clinically relevant values over the range of the observed baseline 
> values, and/or by default, select a five number plus mean series over the 
> observed baseline values.
> 
> I don't see a role for a mixed effects model here, given that this is a pretty 

> straightforward "change from baseline" type design, but there are many here 
>with 
>
> greater expertise than I. If this was a cross-over design, you have multiple 
> measures of glucose for each patient at each time point, more than two time 
> points, or a multi-center study, then a mixed effects model would make more 
> sense to me.
> 
> HTH,
> 
> Marc
> 
> 
> 
> On Aug 12, 2010, at 12:39 AM, array chip wrote:
> 
>> Hi Marc,
>> 
>> Thanks for the reference. I will definitely read it. Please see my reponse to 

>> John's reply. Your model is another model I should add to the 5 models I 
>> proposed in that email. What's your overall thoughts on these different 
> models?
>> 
>> Thank you for sharing.
>> 
>> John
>> 
>> 
>> 
>> ----- Original Message ----
>> From: Marc Schwartz <marc_schwartz at me.com>
>> To: Charles E. (Ted) Wright <cewright at uci.edu>; array chip 
>> <arrayprofile at yahoo.com>
>> Cc: John Maindonald <john.maindonald at anu.edu.au>; 
>> r-sig-mixed-models at r-project.org
>> Sent: Wed, August 11, 2010 6:20:13 AM
>> Subject: Re: [R-sig-ME] longitudinal with 2 time points
>> 
>> Hi,
>> 
>> I'll throw in a reference that covers some of these issues:
>> 
>> Statistics Notes
>> Analysing controlled trials with baseline and follow up measurements
>> Vickers and Altman
>> BMJ. 2001 November 10; 323(7321): 1123?1124.
>> https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1121605/
>> 
>> 
>> The basic model specification would of course be:
>> 
>>? lm(4Wks ~ Baseline + Group)
>> 
>> You will also want to test for an interaction between the baseline score and 
>> your grouping factor, in case the observed group (eg. treatment) effect is 
>> dependent upon the value of the baseline measurement. In this case, unlike in 

>> the above paper, you of course end up with crossing fitted regression lines, 
>> rather than parallel lines.
>> 
>> HTH,
>> 
>> Marc Schwartz
>> 
>> 
>> On Aug 11, 2010, at 7:34 AM, Charles E. (Ted) Wright wrote:
>> 
>>> Keep in mind that running an ANOVA on the difference is not the same thing as 
>
> 
>>> using the baseline data as a covariate in an ANOVA on the Week 4 data. 
>>> Essentially the ANOVA on the differences is like the ANCOVA with the slope 
>>> constrained to be 1.
>>> 
>>> Ted Wright
>>> 
>>> On Wed, 11 Aug 2010, John Maindonald wrote:
>>> 
>>>> All these are possibilities, except maybe making baseline measurement
>>>> a random factor.? This would make sense only if data divide into groups,
>>>> and you want the baseline effect to vary randomly from group to group.
>>>> That may limit your ability to estimate parameters that are of interest.
>>>> In most circumstances that I am familiar with, it makes better sense to
>>>> treat baseline effect as fixed.
>>>> 
>>>> John.
>>>> 
>>>> On 11/08/2010, at 8:11 AM, array chip wrote:
>>>> 
>>>>> Hi, I am wondering if it is still meaningful to run a mixed model if a
>>>>> longitudinal dataset has only 2 time points (baseline and week 4)? Would it 
>
> 
>>> be
>>>>> more appropriate to simply take the difference between the 2 time points and 
>>
>> 
>>>>> run
>>>>> ANOVA (ANCOVA) on the difference? what about still running mixed model on 
>> the
>>>>> difference of the 2 time points, but adding baseline measurement as a 
> random
>>>>> factor?
>>>>> 
>>>>> Thanks for sharing your thoughts.
>>>>> 
>>>>> John






From cotter.rs at gmail.com  Tue Aug 24 13:02:04 2010
From: cotter.rs at gmail.com (R.S. Cotter)
Date: Tue, 24 Aug 2010 13:02:04 +0200
Subject: [R-sig-ME] Testing significance of random effect in lme () and lmer
	()
Message-ID: <AANLkTikYgO+ouy+7bskdGtUkWGW=NL2h8xEADxtCPBAQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100824/e6e504c8/attachment.pl>

From malsburg at gmail.com  Tue Aug 24 17:00:21 2010
From: malsburg at gmail.com (Titus von der Malsburg)
Date: Tue, 24 Aug 2010 17:00:21 +0200
Subject: [R-sig-ME] Modeling polar coordinates
In-Reply-To: <CEC4DD57CDE04EC18C2DB5460D3AF972@lborger>
References: <AANLkTi=tv6oxXfE3k=Um=W7VFcn6Ydo5fQG8Cz89b3t2@mail.gmail.com>
	<AANLkTinfhy13c2QNhBZEiEBY2GMt6ioTg-C12Rmkjr9J@mail.gmail.com>
	<20100818160006.GA26589@gmail.com>
	<CEC4DD57CDE04EC18C2DB5460D3AF972@lborger>
Message-ID: <20100824150021.GB30116@gmail.com>


Luca, thanks for these suggestions.  Your pointers led me to two
packages that provide regression modeling for circular dependent
variables: CircStat and circular.  The latter seems to be the
successor of the former.  Unfortunately, these packages don't solve my
problem as they model a circular variable only as a function of one
circular or linear independent variable.  The paper that you mention
uses CircStat.

Following the references in the documentation I found some papers by
statisticians that discuss possible solutions for the problem.  E.g:

    NI Fisher and AJ Lee, Regression Models for an Angular Response.
    Biometrics, Vol. 48, No. 3 (Sep., 1992), pp. 665-677.

Unfortunately, my knowledge of the theory of generalized linear models
is insufficient to turn the information in those papers into a
solution.  Please forgive me if the following is nonsense: The
proposed solution seems to come down to define an appropriate link
function that maps the linear predictor to the circular dependent
variable.  However, as far as I can see, lmer only allows you to
select among a set of predefined link functions, none of which does
what I want, and I don't see how I can plug in custom link functions.

Your suggestion about using sin and cos combinations sounds
interesting, but your description is a bit too terse for me.  Could
you please elaborate your idea a little bit?  To make sure we're on
the same page: the circular variable is my dependent variable.  The
predictors are linear.

Is this roughly what you propose?:

  # This is the circular variable ranging from 0 to 2*pi:
  x <- rnorm(100, pi, 0.5)

  mer.cos <- lmer(cos(x) ~ 1 + factor + (1|subject), my.data.frame)
  mer.sin <- lmer(sin(x) ~ 1 + factor + (1|subject), my.data.frame)

This is of course modulo some transformation that makes the residuals
being normally distributed.  (Which would that be?)

Many thanks again,

  Titus


On Wed, Aug 18, 2010 at 12:16:32PM -0400, Luca Borger wrote:
> unless I'm misunderstanding, isn't this one of those cases were you
> need to use circular regression methods? e.g. for an example:
> 
> S. Rao Jammalamadaka and Ulric J. Lund (2006) "The effect of wind
> direction on ozone levels - a case study".
> Environmental and Ecological Statistics 13(3): 287-298
> 
> so to analyse a variable like day of the year you need to multiply
> it by 2*pi/365, then you can model it as a combination of sin and
> cos terms of the circualr variable in mixed effects models (please
> check the details for the polar coordinates - I think you can look
> up the examples where wind direction is modeled?).



From marc_schwartz at me.com  Tue Aug 24 20:55:36 2010
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 24 Aug 2010 13:55:36 -0500
Subject: [R-sig-ME] longitudinal with 2 time points
In-Reply-To: <515776.45518.qm@web56301.mail.re3.yahoo.com>
References: <439946.26259.qm@web56301.mail.re3.yahoo.com>
	<B80EFDF8-B705-4EBA-A80E-9A4354F08353@anu.edu.au>
	<alpine.WNT.2.00.1008110532370.640@TED2>
	<8D383357-99BA-4447-A93B-0D8FC7AF7279@me.com>
	<323634.22474.qm@web56305.mail.re3.yahoo.com>
	<FB025028-0C67-4B59-9757-FC2305C07EA6@me.com>
	<111355.9211.qm@web56301.mail.re3.yahoo.com>
	<5992F7D6-7C3D-4AC2-A8AD-3D9AED2CA3D5@me.com>
	<515776.45518.qm@web56301.mail.re3.yahoo.com>
Message-ID: <0E0D98A7-1F25-448E-9652-DCFFB740EE6B@me.com>

Hi John,

Since we have crossed the threshold into mixed models, I am going to provide some comments, but (notably because I have not used lmer, although I attended Doug's class a few years ago at useR), will defer to and solicit comments from the lmer experts on the list.

First, I am not sure, unless we restate the model where Glucose is the response variable and Time is a covariate, that using Time in the random effects term make sense. But I could be wrong.

If we stay with and extend the ANCOVA style approach, then I might envision something like:
  
  lmer(wk4.glucose ~ baseline.glucose + treatment + gender + age + 
       (1 | arm / subject))

where the random effect term expresses the nesting of arm within subject. I am also presuming that you are not interested in arm as a main effect. So we are still concerned with the other main effects as before, but now consider the variation in the multiple measurements of glucose from each arm within each subject.

If you restate the model as I noted above, then perhaps:

  lmer(glucose ~ time + treatment + gender + age + 
       (1 | arm / subject / time))

might make sense. From a review of the archives, it would seem that a multi-level nesting is permitted in lmer formulae random effects terms, so this would reflect the nesting of arm, within subject, within time. The interpretation of this model is of course, going to be different than the ANCOVA based approach above.

Hopefully, this might at least provide a starting point for further discussion and others with greater expertise will chime in.

Regards,

Marc

P.S. Note that I trimmed some of the thread below, to conserve space...

On Aug 24, 2010, at 3:02 AM, array chip wrote:

> Hi Marc,
> 
> I have to admit that I didn't get a chance to carefully read the article before 
> my previous reply. So I want to wait till now to respond after finally I got a 
> chance to read the article. Thanks for your excellent explanation below. I agree 
> that the coefficient for treatment is estimating the extent of the difference 
> between treatment and control in the CHANGE of glucose in week 4 from baseline.
> 
> Now my dataset becomes a little bt more complicated: each glucose testing was 
> done twice (blood was draw from left arm and right arm and tested separately. So 
> for each patient, on each time point, there are 2 measurements (from left and 
> right arm separately). So I think I should now include factor "arm" as a random 
> effect:
> 
> lmer(wk4.glucose ~ baseline.glucose + treatment + gender + age+ 
> (1|subject/time))
> 
> What do you think of this model specification?
>  
> Adiitionally, since I am using mixed model now, if I code a new variable ?time? 
> (either 0 or 4) and new response variable ?y?, how do I specify a mixed model 
> with 2 random effects, one with respect to ?time? variable (2 time points per 
> subject per arm), the other with respect to ?arm? variable (2 arms per subject 
> per time point)?
>  
> Thanks a lot!
>  John
> 
> 
> 
> 
> ----- Original Message ----
> From: Marc Schwartz <marc_schwartz at me.com>
> To: array chip <arrayprofile at yahoo.com>
> Cc: r-sig-mixed-models at r-project.org
> Sent: Fri, August 13, 2010 7:24:59 AM
> Subject: Re: [R-sig-ME] longitudinal with 2 time points
> 
> John,
> 
> That you are asking this question indicates that either you have yet to read the 
> article or that you need to re-read it, as you have not comprehended the 
> content.
> 
> The beta coefficient for treatment IS the difference in mean glucose change 
> between baseline and 4 weeks **attributable to treatment**, after adjusting for 
> any baseline differences in glucose between the two groups. That is also 
> presuming that there is no interaction at baseline.
> 
> For example, let's say that the beta for treatment is -20. Then, at 4 weeks, 
> given the same baseline glucose level, we would predict that, on average, the 
> treatment group will have a glucose level 20 mg/dl less than the control group. 
> 
> 
> In the absence of an interaction, we would estimate the same average treatment 
> difference at 4 weeks of 20 mg/dl whether the baseline glucose was 300 mg/dl or 
> 100 mg/dl. 
> 
> 
> However, given regression to the mean, we might reasonably expect the patient 
> with a 300 mg/dl baseline level to have a greater mean reduction at 4 weeks as 
> compared to the patient with a 100 mg/dl baseline level. 
> 
> 
> We might also expect a patient with a glucose level at the low end of the 
> baseline range (eg. 50 mg/dl) to experience an average increase in glucose level 
> at 4 weeks, presuming that your inclusion/exclusion criteria permitted patients 
> with below normal glucose levels. But the difference will still be, on average, 
> 20 mg/dl between the two treatment groups.
> 
> So the patient with a 300 mg/dl baseline level might have an average reduction 
> to 200 mg/dl at 4 weeks on the control treatment, whereas the same patient on 
> the active treatment would have an average reduction to 180 mg/dl (a difference 
> of -20).
> 
> The patient with a 100 mg/dl baseline level might have an average reduction to 
> 90 mg/dl at 4 weeks on the control treatment, whereas the same patient on the 
> active treatment would have an average reduction to 70 mg/dl (again, a 
> difference of -20).
> 
> The patient with a 50 mg/dl baseline level might have an average increase to 90 
> mg/dl at 4 weeks on the control treatment, whereas the same patient on the 
> active treatment would have an average increase to 70 mg/dl (yet again, a 
> difference of -20).
> 
> So your conclusion would be that on average, between baseline and 4 weeks, 
> glucose levels were reduced by 20 mg/dl more in the active treatment group 
> relative to control.
> 
> This difference is the vertical separation in the two parallel fitted regression 
> lines as shown in the figure in the paper.
> 
> So the method is answering exactly the question the investigator is asking.
> 
> Marc
> 
> 
> On Aug 13, 2010, at 1:02 AM, array chip wrote:
> 
>> Marc,
>> 
>> Thanks for sharing your insights. Let's take this model as an example:
>> 
>>   lm(wk4.glucose ~ baseline.glucose + treatment + gender + age)
>> 
>> Because the investigator is interested in knowing whether the CHANGE of glucose 
>> 
>> in week 4 from baseline is different between treatment and control, Is it still 
>> 
>> legitimate to ask whether and HOW can we test this hypothesis? I think the 
>> coefficient of the treatment factor is only testing whether the week 4 glucose 
> 
>> level is different between treatment and control, but not testing whether 
>> the CHANGE of week 4 glucose level with respect to baseline is different 
>> between 
>> 
>> treatment and control.
>> 
>> Thanks again for your suggestion.
>> 
>> Yi



From arrayprofile at yahoo.com  Tue Aug 24 22:21:56 2010
From: arrayprofile at yahoo.com (array chip)
Date: Tue, 24 Aug 2010 13:21:56 -0700 (PDT)
Subject: [R-sig-ME] longitudinal with 2 time points
In-Reply-To: <0E0D98A7-1F25-448E-9652-DCFFB740EE6B@me.com>
References: <439946.26259.qm@web56301.mail.re3.yahoo.com>
	<B80EFDF8-B705-4EBA-A80E-9A4354F08353@anu.edu.au>
	<alpine.WNT.2.00.1008110532370.640@TED2>
	<8D383357-99BA-4447-A93B-0D8FC7AF7279@me.com>
	<323634.22474.qm@web56305.mail.re3.yahoo.com>
	<FB025028-0C67-4B59-9757-FC2305C07EA6@me.com>
	<111355.9211.qm@web56301.mail.re3.yahoo.com>
	<5992F7D6-7C3D-4AC2-A8AD-3D9AED2CA3D5@me.com>
	<515776.45518.qm@web56301.mail.re3.yahoo.com>
	<0E0D98A7-1F25-448E-9652-DCFFB740EE6B@me.com>
Message-ID: <141201.46127.qm@web56306.mail.re3.yahoo.com>

Hi Marc, thanks for your comments. Yes, I am debating between the 2 models as 
well. 


The first model doesnot have a "time" variable, and there is only 1 level of 
nesting: arm within subject. I think the syntax for nesting is   (1|subject / 
arm) instead of (1|arm/subject).

The 2nd model certainly have a different layout of data with a "time" variable. 
It has 2-level nesting: arm within subject within time, so the syntax should 
(1|time/subject/arm)?

Now I have a little confusion on how to define the nesting here. Can I define it 
as arm within time within subject instead? so the syntax would be 
(1|arm/time/subject)? The reason I am thinking of this way is: each subject was 
measured at 2 time points (0 & 4), at each time point, measured twice at 2 arms 
(left & right).

What is the simplest way to define nesting structure? any principles that we 
should follow? Sometimes I feel I can use different nesting structures as they 
all sound reasonable to me.

Really wish someone can chime in and share their thoughts.

John




----- Original Message ----
From: Marc Schwartz <marc_schwartz at me.com>
To: array chip <arrayprofile at yahoo.com>
Cc: r-sig-mixed-models at r-project.org
Sent: Tue, August 24, 2010 11:55:36 AM
Subject: Re: [R-sig-ME] longitudinal with 2 time points

Hi John,

Since we have crossed the threshold into mixed models, I am going to provide 
some comments, but (notably because I have not used lmer, although I attended 
Doug's class a few years ago at useR), will defer to and solicit comments from 
the lmer experts on the list.

First, I am not sure, unless we restate the model where Glucose is the response 
variable and Time is a covariate, that using Time in the random effects term 
make sense. But I could be wrong.

If we stay with and extend the ANCOVA style approach, then I might envision 
something like:
  
  lmer(wk4.glucose ~ baseline.glucose + treatment + gender + age + 
       (1 | arm / subject))

where the random effect term expresses the nesting of arm within subject. I am 
also presuming that you are not interested in arm as a main effect. So we are 
still concerned with the other main effects as before, but now consider the 
variation in the multiple measurements of glucose from each arm within each 
subject.

If you restate the model as I noted above, then perhaps:

  lmer(glucose ~ time + treatment + gender + age + 
       (1 | arm / subject / time))

might make sense. From a review of the archives, it would seem that a 
multi-level nesting is permitted in lmer formulae random effects terms, so this 
would reflect the nesting of arm, within subject, within time. The 
interpretation of this model is of course, going to be different than the ANCOVA 
based approach above.

Hopefully, this might at least provide a starting point for further discussion 
and others with greater expertise will chime in.

Regards,

Marc

P.S. Note that I trimmed some of the thread below, to conserve space...

On Aug 24, 2010, at 3:02 AM, array chip wrote:

> Hi Marc,
> 
> I have to admit that I didn't get a chance to carefully read the article before 
>
> my previous reply. So I want to wait till now to respond after finally I got a 

> chance to read the article. Thanks for your excellent explanation below. I 
>agree 
>
> that the coefficient for treatment is estimating the extent of the difference 
> between treatment and control in the CHANGE of glucose in week 4 from 
baseline.
> 
> Now my dataset becomes a little bt more complicated: each glucose testing was 
> done twice (blood was draw from left arm and right arm and tested separately. 
>So 
>
> for each patient, on each time point, there are 2 measurements (from left and 
> right arm separately). So I think I should now include factor "arm" as a random 
>
> effect:
> 
> lmer(wk4.glucose ~ baseline.glucose + treatment + gender + age+ 
> (1|subject/time))
> 
> What do you think of this model specification?
>  
> Adiitionally, since I am using mixed model now, if I code a new variable ?time? 
>
> (either 0 or 4) and new response variable ?y?, how do I specify a mixed model 
> with 2 random effects, one with respect to ?time? variable (2 time points per 
> subject per arm), the other with respect to ?arm? variable (2 arms per subject 

> per time point)?
>  
> Thanks a lot!
>  John
> 
> 
> 
> 
> ----- Original Message ----
> From: Marc Schwartz <marc_schwartz at me.com>
> To: array chip <arrayprofile at yahoo.com>
> Cc: r-sig-mixed-models at r-project.org
> Sent: Fri, August 13, 2010 7:24:59 AM
> Subject: Re: [R-sig-ME] longitudinal with 2 time points
> 
> John,
> 
> That you are asking this question indicates that either you have yet to read 
>the 
>
> article or that you need to re-read it, as you have not comprehended the 
> content.
> 
> The beta coefficient for treatment IS the difference in mean glucose change 
> between baseline and 4 weeks **attributable to treatment**, after adjusting for 
>
> any baseline differences in glucose between the two groups. That is also 
> presuming that there is no interaction at baseline.
> 
> For example, let's say that the beta for treatment is -20. Then, at 4 weeks, 
> given the same baseline glucose level, we would predict that, on average, the 
> treatment group will have a glucose level 20 mg/dl less than the control group. 
>
> 
> 
> In the absence of an interaction, we would estimate the same average treatment 

> difference at 4 weeks of 20 mg/dl whether the baseline glucose was 300 mg/dl or 
>
> 100 mg/dl. 
> 
> 
> However, given regression to the mean, we might reasonably expect the patient 
> with a 300 mg/dl baseline level to have a greater mean reduction at 4 weeks as 

> compared to the patient with a 100 mg/dl baseline level. 
> 
> 
> We might also expect a patient with a glucose level at the low end of the 
> baseline range (eg. 50 mg/dl) to experience an average increase in glucose 
>level 
>
> at 4 weeks, presuming that your inclusion/exclusion criteria permitted patients 
>
> with below normal glucose levels. But the difference will still be, on average, 
>
> 20 mg/dl between the two treatment groups.
> 
> So the patient with a 300 mg/dl baseline level might have an average reduction 

> to 200 mg/dl at 4 weeks on the control treatment, whereas the same patient on 
> the active treatment would have an average reduction to 180 mg/dl (a difference 
>
> of -20).
> 
> The patient with a 100 mg/dl baseline level might have an average reduction to 

> 90 mg/dl at 4 weeks on the control treatment, whereas the same patient on the 
> active treatment would have an average reduction to 70 mg/dl (again, a 
> difference of -20).
> 
> The patient with a 50 mg/dl baseline level might have an average increase to 90 
>
> mg/dl at 4 weeks on the control treatment, whereas the same patient on the 
> active treatment would have an average increase to 70 mg/dl (yet again, a 
> difference of -20).
> 
> So your conclusion would be that on average, between baseline and 4 weeks, 
> glucose levels were reduced by 20 mg/dl more in the active treatment group 
> relative to control.
> 
> This difference is the vertical separation in the two parallel fitted 
>regression 
>
> lines as shown in the figure in the paper.
> 
> So the method is answering exactly the question the investigator is asking.
> 
> Marc
> 
> 
> On Aug 13, 2010, at 1:02 AM, array chip wrote:
> 
>> Marc,
>> 
>> Thanks for sharing your insights. Let's take this model as an example:
>> 
>>   lm(wk4.glucose ~ baseline.glucose + treatment + gender + age)
>> 
>> Because the investigator is interested in knowing whether the CHANGE of glucose 
>>
>> 
>> in week 4 from baseline is different between treatment and control, Is it still 
>>
>> 
>> legitimate to ask whether and HOW can we test this hypothesis? I think the 
>> coefficient of the treatment factor is only testing whether the week 4 glucose 
>
> 
>> level is different between treatment and control, but not testing whether 
>> the CHANGE of week 4 glucose level with respect to baseline is different 
>> between 
>> 
>> treatment and control.
>> 
>> Thanks again for your suggestion.
>> 
>> Yi






From richard.feldman at mail.mcgill.ca  Tue Aug 24 23:01:26 2010
From: richard.feldman at mail.mcgill.ca (Richard Feldman)
Date: Tue, 24 Aug 2010 17:01:26 -0400
Subject: [R-sig-ME] Model specification: crossed vs nested factors
Message-ID: <4C743326.6080206@mail.mcgill.ca>

Hello,

I am at my wit's end with regards to specifying my model, perhaps 
because I am confused about nested vs. crossed grouping factors.

My dataset has 16 sites and within each site I applied 3 treatments (A, 
B, C). The sites differ based on elevation. I originally thought I had a 
hierarchical (nested) model and specified the full model as such:

model.n <- glmer(Y ~ Treatment*Elevation + (Treatment|Site), data=Data)

The data also seemed analogous to a longitudinal model where instead of 
subject I have site and instead of time/days I have treatment. I am not 
totally clear on why this analogy breaks down.

After extensive reading, it seems that because each site receives the 
same three treatments, my model is crossed and not nested. Hence the 
specification should be:

model.c <- glmer(Y ~ Treatment*Elevation + (1|Site) + (1|Treatment), 
data=Data)

I have three questions:

1. Is model.c indeed the correct specification given my data?

2. Given model.c, does the treatment by elevation interaction capture 
this cross-scale effect, even though the former is a level-1 predictor 
(varies within site) and the latter a level-2 predictor (varies among 
sites)?

3. The output from model.c gives zero variance for the random effect of 
treatment. I assume this is because there are only three levels. Hence, 
treatment can only be a fixed variable. I have no problem with that. 
What I am confused about is how I can discover how much the 
treatment-response relationship varies among sites. I originally thought 
that (Treatment|Site) made sense because the treatment-response slope 
could vary based on site.

I appreciate all your help in getting me out of this mental quagmire. 
Thank you!

-- 
Richard Feldman, PhD Candidate
Dept. of Biological Sciences, McGill University
W3/5 Stewart Biology Building
1205 Docteur Penfield
Montreal, QC H3A 1B1
514-212-3466
richard.feldman at mail.mcgill.ca



From marc_schwartz at me.com  Tue Aug 24 23:23:43 2010
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 24 Aug 2010 16:23:43 -0500
Subject: [R-sig-ME] longitudinal with 2 time points
In-Reply-To: <141201.46127.qm@web56306.mail.re3.yahoo.com>
References: <439946.26259.qm@web56301.mail.re3.yahoo.com>
	<B80EFDF8-B705-4EBA-A80E-9A4354F08353@anu.edu.au>
	<alpine.WNT.2.00.1008110532370.640@TED2>
	<8D383357-99BA-4447-A93B-0D8FC7AF7279@me.com>
	<323634.22474.qm@web56305.mail.re3.yahoo.com>
	<FB025028-0C67-4B59-9757-FC2305C07EA6@me.com>
	<111355.9211.qm@web56301.mail.re3.yahoo.com>
	<5992F7D6-7C3D-4AC2-A8AD-3D9AED2CA3D5@me.com>
	<515776.45518.qm@web56301.mail.re3.yahoo.com>
	<0E0D98A7-1F25-448E-9652-DCFFB740EE6B@me.com>
	<141201.46127.qm@web56306.mail.re3.yahoo.com>
Message-ID: <D4124AE4-3836-4D4C-9BC8-E1607C1B2A54@me.com>

John,

I'll throw out one more reply, since as I look at what I had below, I was suffering from some transient cerebral flatulence...

For the first model, indeed it should be:

  (1 | Subject / Arm))

For the second model, it should be:

  (Time | Subject / Arm)

So I had the nesting hierarchy reversed and of course Time should not be nested. From further searching, it would seem that in actuality, the preferred expression of the random effects term above for lmer(), would be:

  (Time | Subject : Arm) + (Time | Subject)

The initial expression would be largely equivalent to:

  random = ~Time | Subject / Arm

in lme().

But I'll await clarification from someone who will not risk steering you further astray.

Regards,

Marc


On Aug 24, 2010, at 3:21 PM, array chip wrote:

> Hi Marc, thanks for your comments. Yes, I am debating between the 2 models as 
> well. 
> 
> 
> The first model doesnot have a "time" variable, and there is only 1 level of 
> nesting: arm within subject. I think the syntax for nesting is   (1|subject / 
> arm) instead of (1|arm/subject).
> 
> The 2nd model certainly have a different layout of data with a "time" variable. 
> It has 2-level nesting: arm within subject within time, so the syntax should 
> (1|time/subject/arm)?
> 
> Now I have a little confusion on how to define the nesting here. Can I define it 
> as arm within time within subject instead? so the syntax would be 
> (1|arm/time/subject)? The reason I am thinking of this way is: each subject was 
> measured at 2 time points (0 & 4), at each time point, measured twice at 2 arms 
> (left & right).
> 
> What is the simplest way to define nesting structure? any principles that we 
> should follow? Sometimes I feel I can use different nesting structures as they 
> all sound reasonable to me.
> 
> Really wish someone can chime in and share their thoughts.
> 
> John
> 
> 
> 
> 
> ----- Original Message ----
> From: Marc Schwartz <marc_schwartz at me.com>
> To: array chip <arrayprofile at yahoo.com>
> Cc: r-sig-mixed-models at r-project.org
> Sent: Tue, August 24, 2010 11:55:36 AM
> Subject: Re: [R-sig-ME] longitudinal with 2 time points
> 
> Hi John,
> 
> Since we have crossed the threshold into mixed models, I am going to provide 
> some comments, but (notably because I have not used lmer, although I attended 
> Doug's class a few years ago at useR), will defer to and solicit comments from 
> the lmer experts on the list.
> 
> First, I am not sure, unless we restate the model where Glucose is the response 
> variable and Time is a covariate, that using Time in the random effects term 
> make sense. But I could be wrong.
> 
> If we stay with and extend the ANCOVA style approach, then I might envision 
> something like:
> 
>  lmer(wk4.glucose ~ baseline.glucose + treatment + gender + age + 
>       (1 | arm / subject))
> 
> where the random effect term expresses the nesting of arm within subject. I am 
> also presuming that you are not interested in arm as a main effect. So we are 
> still concerned with the other main effects as before, but now consider the 
> variation in the multiple measurements of glucose from each arm within each 
> subject.
> 
> If you restate the model as I noted above, then perhaps:
> 
>  lmer(glucose ~ time + treatment + gender + age + 
>       (1 | arm / subject / time))
> 
> might make sense. From a review of the archives, it would seem that a 
> multi-level nesting is permitted in lmer formulae random effects terms, so this 
> would reflect the nesting of arm, within subject, within time. The 
> interpretation of this model is of course, going to be different than the ANCOVA 
> based approach above.
> 
> Hopefully, this might at least provide a starting point for further discussion 
> and others with greater expertise will chime in.
> 
> Regards,
> 
> Marc
> 
> P.S. Note that I trimmed some of the thread below, to conserve space...
> 
> On Aug 24, 2010, at 3:02 AM, array chip wrote:
> 
>> Hi Marc,
>> 
>> I have to admit that I didn't get a chance to carefully read the article before 
>> 
>> my previous reply. So I want to wait till now to respond after finally I got a 
> 
>> chance to read the article. Thanks for your excellent explanation below. I 
>> agree 
>> 
>> that the coefficient for treatment is estimating the extent of the difference 
>> between treatment and control in the CHANGE of glucose in week 4 from 
> baseline.
>> 
>> Now my dataset becomes a little bt more complicated: each glucose testing was 
>> done twice (blood was draw from left arm and right arm and tested separately. 
>> So 
>> 
>> for each patient, on each time point, there are 2 measurements (from left and 
>> right arm separately). So I think I should now include factor "arm" as a random 
>> 
>> effect:
>> 
>> lmer(wk4.glucose ~ baseline.glucose + treatment + gender + age+ 
>> (1|subject/time))
>> 
>> What do you think of this model specification?
>> 
>> Adiitionally, since I am using mixed model now, if I code a new variable ?time? 
>> 
>> (either 0 or 4) and new response variable ?y?, how do I specify a mixed model 
>> with 2 random effects, one with respect to ?time? variable (2 time points per 
>> subject per arm), the other with respect to ?arm? variable (2 arms per subject 
> 
>> per time point)?
>> 
>> Thanks a lot!
>> John
>> 
>> 
>> 
>> 
>> ----- Original Message ----
>> From: Marc Schwartz <marc_schwartz at me.com>
>> To: array chip <arrayprofile at yahoo.com>
>> Cc: r-sig-mixed-models at r-project.org
>> Sent: Fri, August 13, 2010 7:24:59 AM
>> Subject: Re: [R-sig-ME] longitudinal with 2 time points
>> 
>> John,
>> 
>> That you are asking this question indicates that either you have yet to read 
>> the 
>> 
>> article or that you need to re-read it, as you have not comprehended the 
>> content.
>> 
>> The beta coefficient for treatment IS the difference in mean glucose change 
>> between baseline and 4 weeks **attributable to treatment**, after adjusting for 
>> 
>> any baseline differences in glucose between the two groups. That is also 
>> presuming that there is no interaction at baseline.
>> 
>> For example, let's say that the beta for treatment is -20. Then, at 4 weeks, 
>> given the same baseline glucose level, we would predict that, on average, the 
>> treatment group will have a glucose level 20 mg/dl less than the control group. 
>> 
>> 
>> 
>> In the absence of an interaction, we would estimate the same average treatment 
> 
>> difference at 4 weeks of 20 mg/dl whether the baseline glucose was 300 mg/dl or 
>> 
>> 100 mg/dl. 
>> 
>> 
>> However, given regression to the mean, we might reasonably expect the patient 
>> with a 300 mg/dl baseline level to have a greater mean reduction at 4 weeks as 
> 
>> compared to the patient with a 100 mg/dl baseline level. 
>> 
>> 
>> We might also expect a patient with a glucose level at the low end of the 
>> baseline range (eg. 50 mg/dl) to experience an average increase in glucose 
>> level 
>> 
>> at 4 weeks, presuming that your inclusion/exclusion criteria permitted patients 
>> 
>> with below normal glucose levels. But the difference will still be, on average, 
>> 
>> 20 mg/dl between the two treatment groups.
>> 
>> So the patient with a 300 mg/dl baseline level might have an average reduction 
> 
>> to 200 mg/dl at 4 weeks on the control treatment, whereas the same patient on 
>> the active treatment would have an average reduction to 180 mg/dl (a difference 
>> 
>> of -20).
>> 
>> The patient with a 100 mg/dl baseline level might have an average reduction to 
> 
>> 90 mg/dl at 4 weeks on the control treatment, whereas the same patient on the 
>> active treatment would have an average reduction to 70 mg/dl (again, a 
>> difference of -20).
>> 
>> The patient with a 50 mg/dl baseline level might have an average increase to 90 
>> 
>> mg/dl at 4 weeks on the control treatment, whereas the same patient on the 
>> active treatment would have an average increase to 70 mg/dl (yet again, a 
>> difference of -20).
>> 
>> So your conclusion would be that on average, between baseline and 4 weeks, 
>> glucose levels were reduced by 20 mg/dl more in the active treatment group 
>> relative to control.
>> 
>> This difference is the vertical separation in the two parallel fitted 
>> regression 
>> 
>> lines as shown in the figure in the paper.
>> 
>> So the method is answering exactly the question the investigator is asking.
>> 
>> Marc
>> 
>> 
>> On Aug 13, 2010, at 1:02 AM, array chip wrote:
>> 
>>> Marc,
>>> 
>>> Thanks for sharing your insights. Let's take this model as an example:
>>> 
>>>  lm(wk4.glucose ~ baseline.glucose + treatment + gender + age)
>>> 
>>> Because the investigator is interested in knowing whether the CHANGE of glucose 
>>> 
>>> 
>>> in week 4 from baseline is different between treatment and control, Is it still 
>>> 
>>> 
>>> legitimate to ask whether and HOW can we test this hypothesis? I think the 
>>> coefficient of the treatment factor is only testing whether the week 4 glucose 
>> 
>> 
>>> level is different between treatment and control, but not testing whether 
>>> the CHANGE of week 4 glucose level with respect to baseline is different 
>>> between 
>>> 
>>> treatment and control.
>>> 
>>> Thanks again for your suggestion.
>>> 
>>> Yi
> 
> 
> 
> 



From djmuser at gmail.com  Tue Aug 24 23:58:06 2010
From: djmuser at gmail.com (Dennis Murphy)
Date: Tue, 24 Aug 2010 14:58:06 -0700
Subject: [R-sig-ME] Model specification: crossed vs nested factors
In-Reply-To: <4C743326.6080206@mail.mcgill.ca>
References: <4C743326.6080206@mail.mcgill.ca>
Message-ID: <AANLkTinF8RdHVSDRZV=vKeTSpRV6mqn+icOz3KDacaSk@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100824/d31e4c30/attachment.pl>

From richard.feldman at mail.mcgill.ca  Wed Aug 25 00:22:46 2010
From: richard.feldman at mail.mcgill.ca (Richard Feldman)
Date: Tue, 24 Aug 2010 18:22:46 -0400
Subject: [R-sig-ME] Model specification: crossed vs nested factors
In-Reply-To: <AANLkTinF8RdHVSDRZV=vKeTSpRV6mqn+icOz3KDacaSk@mail.gmail.com>
References: <4C743326.6080206@mail.mcgill.ca>
	<AANLkTinF8RdHVSDRZV=vKeTSpRV6mqn+icOz3KDacaSk@mail.gmail.com>
Message-ID: <4C744636.60504@mail.mcgill.ca>

Ah, yes, I forgot one key piece of information. The treatments were 
added sequentially in time at the site. In Site #1, treatment A was 
applied, measurements taken, then treatment B was applied, etc. A proper 
control period (4 days) occurred between the application of the 
treatment. This is why I see my design as analogous to a growth model, 
though the treatment does vary in time.

Dennis Murphy wrote:
> Hi:
> 
> No direct answers, but some questions...
> 
> On Tue, Aug 24, 2010 at 2:01 PM, Richard Feldman 
> <richard.feldman at mail.mcgill.ca <mailto:richard.feldman at mail.mcgill.ca>> 
> wrote:
> 
>     Hello,
> 
>     I am at my wit's end with regards to specifying my model, perhaps
>     because I am confused about nested vs. crossed grouping factors.
> 
>     My dataset has 16 sites and within each site I applied 3 treatments
>     (A, B, C). The sites differ based on elevation. I originally thought
>     I had a hierarchical (nested) model and specified the full model as
>     such:
> 
> How did you assign treatments within site? Were they assigned to 
> divisions of a site (e.g., subplots) or were they assigned to the entire 
> site at different times, or ???  This matters in the analysis...a lot.
> 
>  
> 
>     model.n <- glmer(Y ~ Treatment*Elevation + (Treatment|Site), data=Data)
> 
>     The data also seemed analogous to a longitudinal model where instead
>     of subject I have site and instead of time/days I have treatment. I
>     am not totally clear on why this analogy breaks down.
> 
> 
> Longitudinal models involve a time element, usually within 
> subject/primary unit, and constitute repeated measurements on that unit 
> over time with the same treatment conditions and possibly time-varying 
> covariates. How would such a scenario correspond to your design?
>  
> 
> 
>     After extensive reading, it seems that because each site receives
>     the same three treatments, my model is crossed and not nested. Hence
>     the specification should be:
> 
> 
> It's not obvious at this point whether you have crossed or nested 
> effects. It's entirely possible that site could be a blocking factor. Go 
> back to the initial question.
> 
> 
>     model.c <- glmer(Y ~ Treatment*Elevation + (1|Site) + (1|Treatment),
>     data=Data)
> 
>     I have three questions:
> 
>     1. Is model.c indeed the correct specification given my data?
> 
>     2. Given model.c, does the treatment by elevation interaction
>     capture this cross-scale effect, even though the former is a level-1
>     predictor (varies within site) and the latter a level-2 predictor
>     (varies among sites)?
> 
>     3. The output from model.c gives zero variance for the random effect
>     of treatment. I assume this is because there are only three levels.
>     Hence, treatment can only be a fixed variable. I have no problem
>     with that. What I am confused about is how I can discover how much
>     the treatment-response relationship varies among sites. I originally
>     thought that (Treatment|Site) made sense because the
>     treatment-response slope could vary based on site.
> 
> 
> I don't think we have enough information yet to make a determination on 
> any of your questions.
> 
> Hope this helps somewhat,
> Dennis
> 
> 
>     I appreciate all your help in getting me out of this mental
>     quagmire. Thank you!
> 
>     -- 
>     Richard Feldman, PhD Candidate
>     Dept. of Biological Sciences, McGill University
>     W3/5 Stewart Biology Building
>     1205 Docteur Penfield
>     Montreal, QC H3A 1B1
>     514-212-3466
>     richard.feldman at mail.mcgill.ca <mailto:richard.feldman at mail.mcgill.ca>
> 
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 

-- 
Richard Feldman, PhD Candidate
Dept. of Biological Sciences, McGill University
W3/5 Stewart Biology Building
1205 Docteur Penfield
Montreal, QC H3A 1B1
514-212-3466
richard.feldman at mail.mcgill.ca



From davidD at qimr.edu.au  Wed Aug 25 00:26:22 2010
From: davidD at qimr.edu.au (David Duffy)
Date: Wed, 25 Aug 2010 08:26:22 +1000 (EST)
Subject: [R-sig-ME] Testing significance of random effect in lme () and
	lmer()
In-Reply-To: <AANLkTikYgO+ouy+7bskdGtUkWGW=NL2h8xEADxtCPBAQ@mail.gmail.com>
References: <AANLkTikYgO+ouy+7bskdGtUkWGW=NL2h8xEADxtCPBAQ@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.1008250812290.7139@orpheus.qimr.edu.au>

On Tue, 24 Aug 2010, R.S. Cotter wrote:
> Is this the right way to state the results: The random effect ID (likelihood
> ratio test; c2=12.26, d.f.=1, p=0.0005)?
>
> Is this the right way to state the results: The random effect ID (likelihood
> ratio test; p<0.0001)? Or should I also state the value L.Ratio?

Why would you give the value of the likelihood ratio test for lme but not 
lmer?  And the P-value, as mentioned recently here recently (and see Ben 
Bolker's http://glmm.wikidot.com/faq, and Fabian Scheipl's RLRsim package) 
is too conservative, though it won't matter here.

Cheers, David Duffy.
-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From bbolker at gmail.com  Wed Aug 25 00:26:32 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 24 Aug 2010 18:26:32 -0400
Subject: [R-sig-ME] Model specification: crossed vs nested factors
In-Reply-To: <AANLkTinF8RdHVSDRZV=vKeTSpRV6mqn+icOz3KDacaSk@mail.gmail.com>
References: <4C743326.6080206@mail.mcgill.ca>
	<AANLkTinF8RdHVSDRZV=vKeTSpRV6mqn+icOz3KDacaSk@mail.gmail.com>
Message-ID: <4C744718.8060609@gmail.com>

Dennis Murphy wrote:
> Hi:
>
> No direct answers, but some questions...
>
> On Tue, Aug 24, 2010 at 2:01 PM, Richard Feldman <
> richard.feldman at mail.mcgill.ca> wrote:
>
>   
>> Hello,
>>
>> I am at my wit's end with regards to specifying my model, perhaps because I
>> am confused about nested vs. crossed grouping factors.
>>
>> My dataset has 16 sites and within each site I applied 3 treatments (A, B,
>> C). The sites differ based on elevation. I originally thought I had a
>> hierarchical (nested) model and specified the full model as such:
>>
>> How did you assign treatments within site? Were they assigned to divisions
>>     
> of a site (e.g., subplots) or were they assigned to the entire site at
> different times, or ???  This matters in the analysis...a lot.
>   

  Yes. Telling us the total number of observations would help a lot.  Is
it 48, or more?
>
>
>   
>> model.n <- glmer(Y ~ Treatment*Elevation + (Treatment|Site), data=Data)
>>
>> The data also seemed analogous to a longitudinal model where instead of
>> subject I have site and instead of time/days I have treatment. I am not
>> totally clear on why this analogy breaks down.
>>
>>     
>
> Longitudinal models involve a time element, usually within subject/primary
> unit, and constitute repeated measurements on that unit over time with the
> same treatment conditions and possibly time-varying covariates. How would
> such a scenario correspond to your design?
>
>
>   
>> After extensive reading, it seems that because each site receives the same
>> three treatments, my model is crossed and not nested. Hence the
>> specification should be:
>>
>>     
>
> It's not obvious at this point whether you have crossed or nested effects.
> It's entirely possible that site could be a blocking factor. Go back to the
> initial question.
>
>
>   
>> model.c <- glmer(Y ~ Treatment*Elevation + (1|Site) + (1|Treatment),
>> data=Data)
>>
>> I have three questions:
>>
>> 1. Is model.c indeed the correct specification given my data?
>>
>> 2. Given model.c, does the treatment by elevation interaction capture this
>> cross-scale effect, even though the former is a level-1 predictor (varies
>> within site) and the latter a level-2 predictor (varies among sites)?
>>
>> 3. The output from model.c gives zero variance for the random effect of
>> treatment. I assume this is because there are only three levels. Hence,
>> treatment can only be a fixed variable.
  You typically wouldn't want treatment to by a random variable anyway,
would you?  Unless it's not
a typical treatment ...
>>  I have no problem with that. What I
>> am confused about is how I can discover how much the treatment-response
>> relationship varies among sites. I originally thought that (Treatment|Site)
>> made sense because the treatment-response slope could vary based on site.
>>
>>     
  I'm guessing here, but let's suppose that you do indeed have 48 total
observations, of 3 treatments each at 16 sites, each site having its own
elevation value (i.e. regression design), but the treatments at each
site are unreplicated, and share the same 'elevation' value.

     Then I would say that

glmer(Y~Treatment*Elevation + (1|Site), family=..., data=...)

is the appropriate specification.  The fixed effects evaluate whether
there is a trend (linear on the scale of the linear predictor) with
elevation, whether there is a treatment effect, and whether the
elevational trend varies by treatment.  The Site random effect cleans up
any systematic variation among Site that is not accounted for by the
elevational trends.  I was going to say that with this assumed design,
you don't have enough data to estimate Site-by-Treatment interactions
(i.e. treatment has different effects at different sites), because
Treatment is not replicated within sites, but I'm going to waffle a bit
and say that at the very least the Site:Treatment interaction is *hard*
to identify (whether it's exactly, qualitatively, unidentifiable or not)
because of the lack of replication.
   Suppose we leave elevation out for a moment.  Then we are trying to
decide between Y~Treatment+(1|Site) or  Y~Treatment+(Treatment|Site).  I
think that in a classic linear mixed model we would be in trouble with
the latter model, because our error variance would be indistinguishable
from the treatment:site variance
   If I wanted to try to convince myself one way or the other without
actually thinking about it more carefully, I would
set up a simulation with lots of sites and lots of treatments, but with
unreplicated treatments within sites, and see if I
could estimate anything successfully with a sufficiently large data
set.  Alternatively, I would go back and stare at
some classic book (Quinn and Keough is nice for ecologists) and follow
the logic for regular old mixed models, which
applies in this case too even if the algorithms are different.

  I just saw your other e-mail.
  You say "In Site #1, treatment A was applied, measurements taken, then
treatment B was applied, etc.".  Was the order of the treatments
randomly assigned at each site?  If not, the time effect would be
indistinguishable from the treatment effect. If so, I would consider

  glmer(Y~Treatment*Elevation +Time+ (1|Site), family=..., data=...)

  good luck.



From spluque at gmail.com  Tue Aug 24 23:47:25 2010
From: spluque at gmail.com (Sebastian P. Luque)
Date: Tue, 24 Aug 2010 16:47:25 -0500
Subject: [R-sig-ME] alternative interaction representations
References: <87hbinvqqb.fsf@kolob.sebmags.homelinux.org>
	<AANLkTinOLnCVFCYL+te8eMD5j=kt+=+X928QSCAPLWm_@mail.gmail.com>
	<87bp8ue8ti.fsf@kolob.sebmags.homelinux.org>
Message-ID: <8762yz8uw8.fsf@kolob.sebmags.homelinux.org>

On Sun, 22 Aug 2010 14:39:05 -0500,
"Sebastian P. Luque" <spluque-Re5JQEeQqe8AvxtiuMwx3w at public.gmane.org> wrote:

> On Sun, 22 Aug 2010 08:47:47 +0200,
> Reinhold Kliegl <reinhold.kliegl-Re5JQEeQqe8AvxtiuMwx3w-XMD5yJDbdMReXY1tMh2IBg at public.gmane.org> wrote:

> # This representation fits two linear slopes, one below and one after
>> conc = 300, splicing them at 0: CO2new$conc1 <- ifelse(CO2new$conc <
>> 300, CO2new$conc - 300, 0) CO2new$conc2 <- ifelse(CO2new$conc > 300,
>> CO2new$conc - 300, 0)

>> # Basic LMM print(LMM <- lmer(uptake ~ conc1 + conc2 + (1 | Plant),
>> data=CO2new), cor=FALSE) # ... the linear uptake is significant below
>> 300, no longer significant after 300 # ... the intercept estimates
>> the upake at conc=300

>> # To test whether there is significant between-plant variance in
>> slopes below and above conc: # Varying-slopes LMM print(LMM.conc.1 <-
>> lmer(uptake ~ conc1 + conc2 + (1 | Plant) + (0+conc1 | Plant),
>> data=CO2new), cor=FALSE) print(LMM.conc.2 <- lmer(uptake ~ conc1 +
>> conc2 + (1 | Plant) + (0+conc2 | Plant), data=CO2new), cor=FALSE)
>> #print(LMM.conc.1.2 <- lmer(uptake ~ conc1 + conc2 + (1 | Plant) +
>> (0+conc1 | Plant) + (0+conc2 | Plant), data=CO2new), cor=FALSE)
>> #print(LMM.conc.12 <- lmer(uptake ~ conc1 + conc2 + (1 + conc1 +
>> conc2 | Plant), data=CO2new), cor=FALSE)

>> anova(LMM, LMM.conc.1) anova(LMM, LMM.conc.2) # Apparently there is
>> not enough information in the data to test the between-slope
>> variance.

> Thanks Reinhold, it seems as if these piecewise linear splines with
> one or two knots are easier to fit and interpret than using a factor.

Actually I'm having some trouble interpreting the intercept
coefficients, although it may have more to do with piecewise functions
in general, rather than with mixed modelling (so apologies for the
slightly off-topic message).

In a similar case, Fitzmaurice et al.'s say (in Applied Longitudinal
Analysis) that in a model for the mean response Y for a subject i at
time (T) j randomized to 2 groups (G):

B1 + B2*Tij + B3*(Tij-a) + B4*Gi + B5*Tij*Gi + B6*(Tij-a)*Gi

where Yij can be modelled as linear spline with a single knot at 'a'.
The term (Tij-a) is Tij-a when Tij > a and zero otherwise.  The 'B's are
linear coefficients.  Expressing the model in terms of the two lines of
the model for the baseline group:

B1 + B2*Tij                            (Tij <= a)
(B1 - B3) + (B2 + B3)*Tij              (Tij > a)

In the last case (Tij > a), I can't see why the intercept = (B1 - B3).
B3 is a slope, so why is it playing a role (and subtracted from B1) in
the intercept there?

Thanks for any light on this.

-- 
Seb



From davidD at qimr.edu.au  Wed Aug 25 01:31:49 2010
From: davidD at qimr.edu.au (David Duffy)
Date: Wed, 25 Aug 2010 09:31:49 +1000 (EST)
Subject: [R-sig-ME] Modeling polar coordinates
In-Reply-To: <20100824150021.GB30116@gmail.com>
References: <AANLkTi=tv6oxXfE3k=Um=W7VFcn6Ydo5fQG8Cz89b3t2@mail.gmail.com><AANLkTinfhy13c2QNhBZEiEBY2GMt6ioTg-C12Rmkjr9J@mail.gmail.com><20100818160006.GA26589@gmail.com><CEC4DD57CDE04EC18C2DB5460D3AF972@lborger>
	<20100824150021.GB30116@gmail.com>
Message-ID: <Pine.LNX.4.64.1008250900340.7139@orpheus.qimr.edu.au>

On Tue, 24 Aug 2010, Titus von der Malsburg wrote:

> Your [Luca's] suggestion about using sin and cos combinations sounds
> interesting, but your description is a bit too terse for me.
>
>  mer.cos <- lmer(cos(x) ~ 1 + factor + (1|subject), my.data.frame)
>  mer.sin <- lmer(sin(x) ~ 1 + factor + (1|subject), my.data.frame)
>
> This is of course modulo some transformation that makes the residuals
> being normally distributed.  (Which would that be?)

I can't see it being that simple. AFAICT (Song, Correlated Data Analysis), 
the Fisher and Lee model uses a tan(z/2) link function for the mean, *and* 
1/2 sec^2(z/2) for the dispersion.  You might be able to directly maximize 
the wrapped normal likelihood (from the circular package) for your model.

Just 2c, David Duffy.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From djmuser at gmail.com  Wed Aug 25 13:47:21 2010
From: djmuser at gmail.com (Dennis Murphy)
Date: Wed, 25 Aug 2010 04:47:21 -0700
Subject: [R-sig-ME] [R] lmer() causes segfault
In-Reply-To: <807CC055-0A65-4531-88A5-91F05A095005@sozpsy.uzh.ch>
References: <807CC055-0A65-4531-88A5-91F05A095005@sozpsy.uzh.ch>
Message-ID: <AANLkTinnk2LquPp1xvJEDN1rBDhk93NQ8LW5KnR1C_vS@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100825/05ea48f6/attachment.pl>

From Kay.Cichini at uibk.ac.at  Wed Aug 25 18:53:11 2010
From: Kay.Cichini at uibk.ac.at (Kay Cecil Cichini)
Date: Wed, 25 Aug 2010 18:53:11 +0200
Subject: [R-sig-ME] GLMM, LRTs and post-hocs
Message-ID: <20100825185311.60473zjxxacndpq8@web-mail.uibk.ac.at>

hello everyone,

i did a GLMM with two fixed crossed (2 levels each) and one random  
factor. modelselection by LRTs gives no significance for the one fixed  
factor i'm mainly interested in, neither for the interaction with the  
second factor. however when i do post-hoc tests on the first factor  
within each level of the second i get significant effects at one of  
the two levels of the second factor, saying factor one is significant  
but only within level X of the factor two.

now i'm clueless how to proceed with this result, because LRTs tell me  
to dismiss the factor of interest but by pos-hocs i know in fact the  
one factor has an effect, however restricted on one level of the  
second factor...

any comments on this would be greatly appreciated,
kay



From ned.dochtermann at gmail.com  Wed Aug 25 20:50:15 2010
From: ned.dochtermann at gmail.com (Ned Dochtermann)
Date: Wed, 25 Aug 2010 11:50:15 -0700
Subject: [R-sig-ME] Additive versus multiplicative overdispersion
	modeling
In-Reply-To: <Pine.LNX.4.64.1008231132330.13523@orpheus.qimr.edu.au>
References: <AANLkTim+GRgF2qPAAsJ2phav8K==dTom3RUzrK+f2fLo@mail.gmail.com><Pine.LNX.4.64.1008201439540.15563@orpheus.qimr.edu.au>
	<AANLkTinanseqyrPL0Dyz+omRJV1Fnkn4o22Sogomz249@mail.gmail.com>
	<Pine.LNX.4.64.1008231132330.13523@orpheus.qimr.edu.au>
Message-ID: <4c7565e9.173e8e0a.7eda.2ce5@mx.google.com>

David,

To somewhat wrap things up; as I guess would be expected, I get the same
repeatability estimate from a quasibinomial model using V/(V+sigma^2*pi^2/3)
as with V/(V+pi^2/3) from a binomial model.

Thanks again for your and everyone else's help!
Ned

--
Ned Dochtermann
Department of Biology
University of Nevada, Reno

ned.dochtermann at gmail.com
http://wolfweb.unr.edu/homepage/mpeacock/Dochter/
--



-----Original Message-----
From: David Duffy [mailto:davidD at qimr.edu.au] 
Sent: Sunday, August 22, 2010 6:39 PM
To: Ned Dochtermann
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Additive versus multiplicative overdispersion
modeling

On Fri, 20 Aug 2010, Ned Dochtermann wrote:

> Thanks a lot, if that is indeed the case it makes calculating
> repeatabilities per N&S quite straightforward for the multiplicative
> models (quasibinomial & quasipoisson) since the relevant term to
> include in the denominator would just be (summary(model)@sigma)^2
> (multiplied by (pi^2)/3 ). Of course I still can't figure out how to
> get the needed information from the additive models, i.e. the residual
> of the distribution specific variance.
>

Method "C" in the Browne paper uses: r = V/(V+pi^2/3) for the logistic 
link, and r=V/(V+1) for the probit link (the latter is the tetrachoric r).

Cheers, David Duffy.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From john.maindonald at anu.edu.au  Thu Aug 26 02:22:00 2010
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Thu, 26 Aug 2010 10:22:00 +1000
Subject: [R-sig-ME] GLMM, LRTs and post-hocs
In-Reply-To: <20100825185311.60473zjxxacndpq8@web-mail.uibk.ac.at>
References: <20100825185311.60473zjxxacndpq8@web-mail.uibk.ac.at>
Message-ID: <2A1A26A3-1C96-4081-98DA-20252C9B8D84@anu.edu.au>

1) The LRT is a more reliable guide than what I assume are the modified
Wald statistics that you are using for the post-hoc comparisons.  The
Wald statistics involve approximations that can play havoc with the
distributional assumptions that are commonly use.
2) Even if both tests are pretty much beyond reproach, as in some 
normal theory contexts, different testing procedures may give different 
answers. The LRT is an overall test, automatically taking a/c of multiplicity.  
If you believe in adjustments for multiplicity, or (a better reason, I consider) 
think that such an adjustment accords with the aims of the project, you 
might go with the LRT.

-----------------------------------------------------------------------------------------------

Now for what may seem something of a hobby-horse.  I wish we could 
move away from this heavy reliance on p-values.  Often, it will do much 
better justice to the data to say:

a) These (. . . .) are the effects stand out clearly, pretty much irrespective 
of the twists and turns of the way that the results might be interpreted . . .

b) Next note effects that are borderline . . .  Remember that there can be
model uncertainty as well as the statistical uncertainty that a particular
form of analysis identifies.  With GLMMs that have a fixed scale factor, 
there is the issue of whether observation level random effects are
required to adequately account for the variation.  If there are such
effects, then unless they are very small and/or there are many 
observations, think carefully before taking too much notice of p-values 
that may be given for the Wald statistics.

c) Whichever way one shakes it, remaining effect estimates are 
consistent with statistical variation.

This way of presenting results would, often, give a clearer and
more honest account of the data and of model uncertainty.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 26/08/2010, at 2:53 AM, Kay Cecil Cichini wrote:

> hello everyone,
> 
> i did a GLMM with two fixed crossed (2 levels each) and one random factor. modelselection by LRTs gives no significance for the one fixed factor i'm mainly interested in, neither for the interaction with the second factor. however when i do post-hoc tests on the first factor within each level of the second i get significant effects at one of the two levels of the second factor, saying factor one is significant but only within level X of the factor two.
> 
> now i'm clueless how to proceed with this result, because LRTs tell me to dismiss the factor of interest but by pos-hocs i know in fact the one factor has an effect, however restricted on one level of the second factor...
> 
> any comments on this would be greatly appreciated,
> kay
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From a.j.close at newcastle.ac.uk  Thu Aug 26 16:59:21 2010
From: a.j.close at newcastle.ac.uk (Andrew Close)
Date: Thu, 26 Aug 2010 15:59:21 +0100
Subject: [R-sig-ME] Multiple covariates in SSbiexp model and an error message
Message-ID: <6EC8ACEECB03A94F91EFB55F0FA3630E90664CBB22@EXSAN03.campus.ncl.ac.uk>

Dear all,

I wanted to experiment with the SSbiexp model but include multiple covariates. To this end I have been following the presented in P&B for the CO2 uptake model

I was presented with the error message:

### Error in eval(expr, envir, enclos) : object 'temp1' not found ###

The following code illustrates my modelling process:
I attached a new column to the Indometh data from randomly generated numbers to represent temperature.
library(nlme)
temp<-rnorm(66, mean = 3, sd = 0.5)
temp<-data.frame(temp)
temp
Indometh1<-cbind(Indometh, temp)

I converted the temperature values to the same order of magnitude using the following line of code.
> Indometh1$temp1 <- 10^-(Indometh1$temp)

converted the data to a grouped object and began the model fitting process:
> Indometh1<-groupedData(conc ~ time + temp1 | Subject, data = Indometh1)

> fm1Indom.lis <- nlsList(conc ~ SSbiexp(time + temp, A1, lrc1, A2, lrc2), data = Indometh1)

> fm1Indom.nlme <- nlme(fm1Indom.lis, random = pdDiag(A1 + lrc1 + A2 + lrc2~1))

> summary(fm1Indom.nlme)

Nonlinear mixed-effects model fit by maximum likelihood
  Model: conc ~ SSbiexp(time + H, A1, lrc1, A2, lrc2)
 Data: Indometh1.g
        AIC       BIC   logLik
  -91.35715 -71.65026 54.67858
Random effects:
 Formula: list(A1 ~ 1, lrc1 ~ 1, A2 ~ 1, lrc2 ~ 1)
 Level: Subject
 Structure: Diagonal
               A1      lrc1        A2         lrc2  Residual
StdDev: 0.5640351 0.1556456 0.1122092 9.439076e-06 0.0815653
Fixed effects: list(A1 ~ 1, lrc1 ~ 1, A2 ~ 1, lrc2 ~ 1)
          Value Std.Error DF   t-value p-value
A1    2.8328430 0.2613774 57 10.838132   0e+00
lrc1  0.7731807 0.1095290 57  7.059140   0e+00
A2    0.4625497 0.1132419 57  4.084615   1e-04
lrc2 -1.3422416 0.2309100 57 -5.812833   0e+00
 Correlation:
     A1     lrc1   A2
lrc1  0.057
A2   -0.102  0.634
lrc2 -0.140  0.581  0.834
Standardized Within-Group Residuals:
       Min         Q1        Med         Q3        Max
-3.1672960 -0.3592548 -0.1301288  0.3445645  2.9932219
Number of Observations: 66
Number of Groups: 6

##
Using the estimates from the above model I tried to generate new starting values for the fixed effects. My aim to see how the decay may vary according to time and the newly generated "temp1" variable.

> fm2Indom.nlme <- update(fm1Indom.nlme, fixed = list(A1~time+temp, lrc1~1 + A2~time+temp + lrc2~1),
+ start=c(2.8328430, 0, 0, 0.7731807, 0, 0.4625497, 0, 0, -1.3422416, 0))

I was presented with the the error message:

### Error in eval(expr, envir, enclos) : object 'temp1' not found ###

Can anyone clarify if it possible to generate biexp models with multiple covariates and if so what is it that I am doing wrong?

Thank you for your patience.

Best wishes

Andrew Close
<mailto:a.j.close at ncl.ac.uk>



From Jesus.Frias at dit.ie  Thu Aug 26 18:08:44 2010
From: Jesus.Frias at dit.ie (Jesus Frias)
Date: Thu, 26 Aug 2010 17:08:44 +0100 (BST)
Subject: [R-sig-ME] Multiple covariates in SSbiexp model and an error
	message
Message-ID: <3836642.1282838924312.JavaMail.Jesus.Frias@dit.ie>

Hi Andrew,

I think you just needed a little change. I've changed slightly your 
code to show you a plotting method in nlsList and nlme that allows to 
inspect graphically the covariates (is really nice, at least for me). 
You should be able to use the coef() or ranef() to extract the random 
effects and test for covariate dependence before you build your final 
model (two-stage). This is the main reason why I love the suite of 
nlList, gnls and nlme in R.

I've modified the call to update so that it includes one dependence of 
A1 with the temperature, but it is easily extended to include others. 
It works in my computer, but send me an email it it doesn't in yours.


library(nlme)
temp<-rnorm(66, mean = 3, sd = 0.5)
temp<-data.frame(temp)
temp
Indometh1<-cbind(Indometh, temp)

Indometh1$temp1 <- 10^-(Indometh1$temp)

Indometh1<-groupedData(conc ~ time + temp1 | Subject, data = Indometh1)

fm1Indom.lis <- nlsList(conc ~ SSbiexp(time, A1, lrc1, A2, lrc2), data 
= Indometh1)

plot(coef(fm1Indom.lis,augFrame=T),A1~temp)
plot(coef(fm1Indom.lis,augFrame=T),A2~temp)


fm1Indom.nlme <- nlme(fm1Indom.lis, random = pdDiag(A1 + lrc1 + A2 + 
lrc2~1))
summary(fm1Indom.nlme)
plot(ranef(fm1Indom.nlme,augFrame=T),A1~temp)
plot(ranef(fm1Indom.nlme,augFrame=T),A2~temp)


fm2Indom.nlme <- update(fm1Indom.nlme,
                        fixed = list(A1~temp,
                          lrc1~1,
                          A2~1,
                          lrc2~1),
                        start=c(2.8328430, 0,0.7731807, 0.4625497, 
-1.3422416))


regards,

Jesus


Andrew Close wrote:


>Dear all,
>
>I wanted to experiment with the SSbiexp model but include multiple 
covariates. To this end I have been following the presented in P&B for 
the CO2 uptake model
>
>I was presented with the error message:
>
>### Error in eval(expr, envir, enclos) : object 'temp1' not found ###
>
>The following code illustrates my modelling process:
>I attached a new column to the Indometh data from randomly generated 
numbers to represent temperature.
>library(nlme)
>temp<-rnorm(66, mean = 3, sd = 0.5)
>temp<-data.frame(temp)
>temp
>Indometh1<-cbind(Indometh, temp)
>
>I converted the temperature values to the same order of magnitude using 
the following line of code.
>> Indometh1$temp1 <- 10^-(Indometh1$temp)
>
>converted the data to a grouped object and began the model fitting 
process:
>> Indometh1<-groupedData(conc ~ time + temp1 | Subject, data = Indometh1)
>
>> fm1Indom.lis <- nlsList(conc ~ SSbiexp(time + temp, A1, lrc1, A2, 
lrc2), data = Indometh1)
>
>> fm1Indom.nlme <- nlme(fm1Indom.lis, random = pdDiag(A1 + lrc1 + A2 + 
lrc2~1))
>
>> summary(fm1Indom.nlme)
>
>Nonlinear mixed-effects model fit by maximum likelihood
>  Model: conc ~ SSbiexp(time + H, A1, lrc1, A2, lrc2)
> Data: Indometh1.g
>        AIC       BIC   logLik
>  -91.35715 -71.65026 54.67858
>Random effects:
> Formula: list(A1 ~ 1, lrc1 ~ 1, A2 ~ 1, lrc2 ~ 1)
> Level: Subject
> Structure: Diagonal
>               A1      lrc1        A2         lrc2  Residual
>StdDev: 0.5640351 0.1556456 0.1122092 9.439076e-06 0.0815653
>Fixed effects: list(A1 ~ 1, lrc1 ~ 1, A2 ~ 1, lrc2 ~ 1)
>          Value Std.Error DF   t-value p-value
>A1    2.8328430 0.2613774 57 10.838132   0e+00
>lrc1  0.7731807 0.1095290 57  7.059140   0e+00
>A2    0.4625497 0.1132419 57  4.084615   1e-04
>lrc2 -1.3422416 0.2309100 57 -5.812833   0e+00
> Correlation:
>     A1     lrc1   A2
>lrc1  0.057
>A2   -0.102  0.634
>lrc2 -0.140  0.581  0.834
>Standardized Within-Group Residuals:
>       Min         Q1        Med         Q3        Max
>-3.1672960 -0.3592548 -0.1301288  0.3445645  2.9932219
>Number of Observations: 66
>Number of Groups: 6
>
>##
>Using the estimates from the above model I tried to generate new 
starting values for the fixed effects. My aim to see how the decay may 
vary according to time and the newly generated "temp1" variable.
>
>> fm2Indom.nlme <- update(fm1Indom.nlme, fixed = list(A1~time+temp, 
lrc1~1 + A2~time+temp + lrc2~1),
>+ start=c(2.8328430, 0, 0, 0.7731807, 0, 0.4625497, 0, 0, -1.3422416, 
0))
>
>I was presented with the the error message:
>
>### Error in eval(expr, envir, enclos) : object 'temp1' not found ###
>
>Can anyone clarify if it possible to generate biexp models with 
multiple covariates and if so what is it that I am doing wrong?
>
>Thank you for your patience.
>
>Best wishes
>
>Andrew Close
><mailto:a.j.close at ncl.ac.uk>
>
>_______________________________________________
>R-sig-mixed-models at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

--------------------------------------------------
Jes??s Mar??a Fr??as Celayeta
Head of the Dept of Food Science 
School of Food Sci. and Env. Health 
DIT 
t + 353 1 402 4459 
f + 353 1 402 4495
http://fseh.dit.ie/o4/StaffListing/JesusFrias.html

This message has been scanned for content and viruses by the DIT Information Services E-Mail Scanning Service, and is believed to be clean. http://www.dit.ie



From felixbach72 at gmx.de  Thu Aug 26 18:17:29 2010
From: felixbach72 at gmx.de (Felix Bach)
Date: Thu, 26 Aug 2010 18:17:29 +0200
Subject: [R-sig-ME] Fwd: failure notice
Message-ID: <20100826161729.299480@gmx.net>

-
Hello,

I am new to this group and hope that my question is not too simple. however, I checked previous messages and could not find an answer to my question. 
Iwould like to obtian the credibility interval for the intraclass correlation for a random efffects model. For example

(fm1 <- lmer(Reaction ~ Days + (1|Subject), sleepstudy))

Linear mixed model fit by REML 
Formula: Reaction ~ Days + (1 | Subject) 
   Data: sleepstudy 
Random effects:
 Groups   Name        Variance Std.Dev.
 Subject  (Intercept) 1378.18  37.124  
 Residual              960.46  30.991  

--> ICC= 1378/(1378+960)

set.seed(101); samp0 <- mcmcsamp(fm1, n = 1000)


str(samp0)

Formal class 'merMCMC' [package "lme4"] with 9 slots
  ..@ Gp      : int [1:2] 0 18
  ..@ ST      : num [1, 1:1000] 1.198 1.104 0.941 0.805 0.874 ...
  ..@ call    : language lmer(formula = Reaction ~ Days + (1 | Subject), data = sleepstudy)
  ..@ deviance: num [1:1000] 1794 1794 1794 1795 1798 ...
  ..@ dims    : Named int [1:18] 1 180 2 18 1 1 0 1 2 5 ...
  .. ..- attr(*, "names")= chr [1:18] "nt" "n" "p" "q" ...
  ..@ fixef   : num [1:2, 1:1000] 251.4 10.5 256.8 10.1 263.1 ...
  .. ..- attr(*, "dimnames")=List of 2
  .. .. ..$ : chr [1:2] "(Intercept)" "Days"
  .. .. ..$ : NULL
  ..@ nc      : int 1
  ..@ ranef   : num[1:18, 0 ] 
  ..@ sigma   : num [1, 1:1000] 31 30 31.9 30.9 31.1 ...

I can get the residual variance (@sigma) but not the subject variance.

Any suggestions would be highly appreciated. Many thanks
Felix
-- 
GMX DSL SOMMER-SPECIAL: Surf & Phone Flat 16.000 f??r nur 19,99 ??/mtl.!*

-- 
GMX DSL SOMMER-SPECIAL: Surf & Phone Flat 16.000 f?r nur 19,99 ?/mtl.!*



From S.elMesslaki at student.TUDelft.NL  Thu Aug 26 22:29:19 2010
From: S.elMesslaki at student.TUDelft.NL (Sabira el Messlaki)
Date: Thu, 26 Aug 2010 22:29:19 +0200
Subject: [R-sig-ME] R console not responding after defining variable as
	factor
References: <mailman.0.1282853534.6203.r-sig-mixed-models@r-project.org>
Message-ID: <3154E0B9605B3140AFAD0A3A97DA29CF832426@SRV603.tudelft.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100826/74eab335/attachment.pl>

From bates at stat.wisc.edu  Fri Aug 27 00:26:39 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 26 Aug 2010 17:26:39 -0500
Subject: [R-sig-ME] R console not responding after defining variable as
	factor
In-Reply-To: <3154E0B9605B3140AFAD0A3A97DA29CF832426@SRV603.tudelft.net>
References: <mailman.0.1282853534.6203.r-sig-mixed-models@r-project.org>
	<3154E0B9605B3140AFAD0A3A97DA29CF832426@SRV603.tudelft.net>
Message-ID: <AANLkTinVWBfcpSjncPCUA24xHAOyoaqym1vofDsdgAcY@mail.gmail.com>

On Thu, Aug 26, 2010 at 3:29 PM, Sabira el Messlaki
<S.elMesslaki at student.tudelft.nl> wrote:
> Dear list members,

> I have a problem running the lme model. The problem is caused by the random factor TransJaarCod. TransJaarCod is a factor with 12 levels. If I run the underneath model without defining TransJaarCod (R recognize it by default as interval) ?as a factor the model works fine, but when I define TransJaarCod as a factor the R console turns not responding. I thought it was because of a lack of memory on my notebook but I tried the same on my desktop and the same happens there.

> model3.7.fit <- lme(y ~ x1+LnBankt500+Perceelkwaliteit+LnNS_Afstand+PGebouwd+Bouwjaar_cat4+LnBanIndDistr500+LeegstandJaar_L2, random = ~TransJaarCod|GebID,data, method = "REML")

It's not that the console has frozen - it's that the R process is
going to be very, very busy for a long time (and possibly run out of
memory space).  When you include a random effect specification with a
continuous covariate you need to estimate 3 variance components - 2
variances and a covariance.  When you have a factor with 12 levels you
need to estimate 12 variances and 66 covariances.  That will take a
very long time, if it could be done at all.

You should reconsider the form of your model.

> Can someone please help me out.
>
>
>> str(data)
> 'data.frame': ? 695 obs. of ?35 variables:
> ?$ nr ? ? ? ? ? ? ? ? ? ? ?: int ?59 72 74 89 129 130 145 146 157 168 ...
> ?$ GebID ? ? ? ? ? ? ? ? ? : Factor w/ 165 levels "AFC-01","ALA-01",..: 16 20 21 23 32 32 36 36 38 41 ...
> ?$ TransJaarCod ? ? ? ? ? ?: int ?1 1 1 1 1 1 1 1 1 1 ...
> ?$ L_3L750 ? ? ? ? ? ? ? ? : int ?2100 500 0 2000 42100 42100 41250 41250 10910 42100 ...
> ?$ LnRHuurM2 ? ? ? ? ? ? ? : num ?4.72 5.27 5.17 5.21 5.07 ...
> ?$ LnReis_opaf_m ? ? ? ? ? : num ?0.945 1.446 0.236 1.187 0.896 ...
> ?$ LnNS_Afstand ? ? ? ? ? ?: num ?6.46 7.28 6.89 7.24 6.6 ...
> ?$ LnIC_afstand ? ? ? ? ? ?: num ?7.98 7.28 6.89 7.46 6.6 ...
> ?$ LnBankt500 ? ? ? ? ? ? ?: num ?5.54 6.93 7.68 6.71 8.46 ...
> ?$ LnBanIndDistr500 ? ? ? ?: int ?152 218 566 114 1776 1776 1175 1175 327 3607 ...
> ?$ LnVoorzDagel500 ? ? ? ? : num ?2.77 3 0 1.95 1.1 ...
> ?$ PGebouwd ? ? ? ? ? ? ? ?: int ?0 0 0 0 0 0 0 0 0 0 ...
> ?$ Bouwjaar_cat4 ? ? ? ? ? : int ?1 1 3 2 3 3 3 3 3 3 ...
> ?$ LogoBedrijf ? ? ? ? ? ? : int ?0 0 0 1 1 1 0 0 0 1 ...
> ?$ Perceelkwaliteit ? ? ? ?: int ?0 1 1 1 1 1 0 0 0 1 ...
> ?$ KwaliteitStraatmeubilair: int ?0 0 0 0 0 0 0 0 0 0 ...
> ?$ X_Coord ? ? ? ? ? ? ? ? : int ?117591 119543 123932 120624 125236 125236 124636 124636 122515 124799 ...
> ?$ Y_Coord ? ? ? ? ? ? ? ? : int ?486259 482125 482698 482028 479864 479864 480391 480391 486650 479899 ...
> ?$ LeegstandJaar_L2 ? ? ? ?: num ?9.78 9.78 9.78 9.78 9.78 ...
> ?[list output truncated]
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From dieter.menne at menne-biomed.de  Fri Aug 27 14:35:38 2010
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Fri, 27 Aug 2010 14:35:38 +0200
Subject: [R-sig-ME] Windows Binary lme4a from R-forge
Message-ID: <000001cb45e4$5ae57bc0$10b07340$@menne@menne-biomed.de>

I tried to download the Windows binary of lme4a today, but it is missing in

http://r-forge.r-project.org/bin/windows/contrib/2.11/


The lme4b version which "should never see the light of day" according to
Douglas Bates, is available. So is this version the born eventually, and
does it supersede lme4a?

Dieter



From bbolker at gmail.com  Fri Aug 27 14:41:05 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 27 Aug 2010 08:41:05 -0400
Subject: [R-sig-ME] Windows Binary lme4a from R-forge
In-Reply-To: <000001cb45e4$5ae57bc0$10b07340$@menne@menne-biomed.de>
References: <000001cb45e4$5ae57bc0$10b07340$@menne@menne-biomed.de>
Message-ID: <4C77B261.6010204@gmail.com>


  I think the current build of lme4a is just broken (maybe due to an
Rcpp version mismatch???)

  See

https://r-forge.r-project.org/R/?group_id=60&log=build_win32&pkg=lme4a&flavor=patched

Dieter Menne wrote:
> I tried to download the Windows binary of lme4a today, but it is missing in
>
> http://r-forge.r-project.org/bin/windows/contrib/2.11/
>
>
> The lme4b version which "should never see the light of day" according to
> Douglas Bates, is available. So is this version the born eventually, and
> does it supersede lme4a?
>
> Dieter
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Fri Aug 27 16:53:12 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 27 Aug 2010 09:53:12 -0500
Subject: [R-sig-ME] Windows Binary lme4a from R-forge
In-Reply-To: <4C77B261.6010204@gmail.com>
References: <4C77B261.6010204@gmail.com>
Message-ID: <AANLkTiknwgLpFoAmmbyUuhGxLC3uCJafrGXJxmYc-FLB@mail.gmail.com>

On Fri, Aug 27, 2010 at 7:41 AM, Ben Bolker <bbolker at gmail.com> wrote:

> ?I think the current build of lme4a is just broken (maybe due to an
> Rcpp version mismatch???)

> ?See
>
> https://r-forge.r-project.org/R/?group_id=60&log=build_win32&pkg=lme4a&flavor=patched

Ben is correct that it is a version mismatch with packages on which
lme4a depends, although it happens to be the MatrixModels package
rather than Rcpp.  There is a cascade of dependencies because the new
version of MatrixModels depends on an as-yet-unreleased version of
Matrix.

Sorry for the blockage.  Martin and I will coordinate releases,
probably this weekend.  It happens that both of us are very busy
preparing courses that we are or will be teaching.  I have a heavy
teaching load this semester and am trying to get materials prepared
ahead of time.

I have compiled packages of the lme4a from July available at
http://lme4.r-forge.r-project.org/slides/2010-07-20-Gaithersburg/pkg/

> Dieter Menne wrote:
>> I tried to download the Windows binary of lme4a today, but it is missing in
>>
>> http://r-forge.r-project.org/bin/windows/contrib/2.11/
>>
>>
>> The lme4b version which "should never see the light of day" according to
>> Douglas Bates, is available. So is this version the born eventually, and
>> does it supersede lme4a?
>>
>> Dieter
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From d.schoeman at ulster.ac.uk  Fri Aug 27 18:12:28 2010
From: d.schoeman at ulster.ac.uk (Dave Schoeman)
Date: Fri, 27 Aug 2010 17:12:28 +0100
Subject: [R-sig-ME] Help with coding an intervention analysis with lmer()
Message-ID: <46B05E88-BDEA-4578-AB8F-8E40815B3B1E@ulster.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100827/885ee310/attachment.pl>

From djmuser at gmail.com  Fri Aug 27 20:50:24 2010
From: djmuser at gmail.com (Dennis Murphy)
Date: Fri, 27 Aug 2010 11:50:24 -0700
Subject: [R-sig-ME] Help with coding an intervention analysis with lmer()
In-Reply-To: <46B05E88-BDEA-4578-AB8F-8E40815B3B1E@ulster.ac.uk>
References: <46B05E88-BDEA-4578-AB8F-8E40815B3B1E@ulster.ac.uk>
Message-ID: <AANLkTikeQZzagK4LqKdhW3SbXUJSx8nefpvB_VB2d_mj@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100827/5dd850be/attachment.pl>

From d.schoeman at ulster.ac.uk  Sat Aug 28 08:58:07 2010
From: d.schoeman at ulster.ac.uk (Dave Schoeman)
Date: Sat, 28 Aug 2010 07:58:07 +0100
Subject: [R-sig-ME] Help with coding an intervention analysis with lmer()
In-Reply-To: <AANLkTikeQZzagK4LqKdhW3SbXUJSx8nefpvB_VB2d_mj@mail.gmail.com>
References: <46B05E88-BDEA-4578-AB8F-8E40815B3B1E@ulster.ac.uk>
	<AANLkTikeQZzagK4LqKdhW3SbXUJSx8nefpvB_VB2d_mj@mail.gmail.com>
Message-ID: <04BB37A5-8461-4BF5-9678-96FB7A0898A3@ulster.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100828/d082650d/attachment.pl>

From Sam_Smith at me.com  Sat Aug 28 17:31:49 2010
From: Sam_Smith at me.com (Sam)
Date: Sat, 28 Aug 2010 16:31:49 +0100
Subject: [R-sig-ME] Bootstrapping
Message-ID: <0E9D2CF9-16D3-4270-8DBD-7B4965D017E1@me.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100828/df0ae1aa/attachment.pl>

From izahn at psych.rochester.edu  Sat Aug 28 18:00:16 2010
From: izahn at psych.rochester.edu (Ista Zahn)
Date: Sat, 28 Aug 2010 12:00:16 -0400
Subject: [R-sig-ME] Help with coding an intervention analysis with lmer()
In-Reply-To: <04BB37A5-8461-4BF5-9678-96FB7A0898A3@ulster.ac.uk>
References: <46B05E88-BDEA-4578-AB8F-8E40815B3B1E@ulster.ac.uk>
	<AANLkTikeQZzagK4LqKdhW3SbXUJSx8nefpvB_VB2d_mj@mail.gmail.com>
	<04BB37A5-8461-4BF5-9678-96FB7A0898A3@ulster.ac.uk>
Message-ID: <AANLkTim4rk1+25_xd-szKHnF+mzv2m=zp-MKK+3-2W3R@mail.gmail.com>

Hi all,
I hesitate to weigh in on this, because I still consider myself a
newbie with lme4. But I really think you're on the wrong track here,
and I trust that someone will correct me if I'm wrong.



On Sat, Aug 28, 2010 at 2:58 AM, Dave Schoeman <d.schoeman at ulster.ac.uk> wrote:
>
> Hi, many thanks for the thoughts; it is extremely useful to have outside input.

> <snip>

> ?is also why I believe that the model term of interest is the Group x BA interaction.

I think this part is reasonable.

>
> I defined the random effect of (1| Group/Subject) purely on the basis of the experimental design: Subject is nested in Group (if you agree with the logic above).

I think this is where you go off the rails. Nesting refers to
_grouping variables_, not to fixed effects. If I'm understanding
correctly, group is not a grouping variable, it is a fixed effect with
2 repeatable levels: control and experimental.

 In this case, and generally with my real data, the estimated variance
for Group is very small (zero here), so could probably be eliminated,
reducing the random term to (1|Subject). This would make sense,
anyway, if lmer() automatically accounts for nesting (uniquely-coded
Subjects).
>
> The term BA/Year:Group is unclear, I agree. What it means is that I want to add an interaction term on a nested factor: Year (within BA) x Group. Similarly Group/Subject:BA is the interaction of Subject (within Group) x BA. Finally, there SHOULD be a term for Year (within BA) x Subject (within Group), but these data are unreplicated at this level, so this term is not estimable in conventional anova (so it is omitted to contribute to the residual variance). I understand that these interactions are difficult to read, and I tried to resolve this by isolating the nested terms in brackets, but this seems to make no difference to R.

I don't think this is right. I don't think you need to specify nesting
this way, especially in the fixed-effects part of the model. The way I
see it, you have only one grouping factor, and that is Subject.

If we go back to your original model specification, you had

mod <- lmer(Attack ~ Group*BA + BA/Year + BA/Year:Group +
Group/Subject:BA + (1|Group/Subject), data = dat, family = poisson)

in my view that is gobbledygook. You have Group as a fixed effect
predictor, but also as a grouping factor, and I don't think that makes
any sense. I also don't think that those nesting statements in the
fixed-effects specification make any sense, but it's possible I'm the
one who doesn't understand lmer syntax... Anyway, I would do something
like

Subject <- c(rep(c(1:20), 8))
Group <- c(rep(c(rep("C", 10), rep("E", 10)), 8))
BA <- c(rep("Bef", 80), rep("After", 80))
Year <- c(rep(1990, 20), rep(1991, 20), rep(1992, 20), rep(1993, 20),
rep(1994, 20), rep(1995, 20), rep(1996, 20), rep(1997, 20))

Attack <- c(rpois(10, lambda = 10), rpois(10, lambda = 12), rpois(10,
lambda = 10), rpois(10, lambda = 12), rpois(10, lambda = 10),
rpois(10, lambda = 12), rpois(10, lambda = 10), rpois(10, lambda =
12), rpois(10, lambda = 15), rpois(10, lambda = 3), rpois(10, lambda =
15), rpois(10, lambda = 3), rpois(10, lambda = 15), rpois(10, lambda =
3), rpois(10, lambda = 15), rpois(10, lambda = 3))

dat <- data.frame(Attack, Subject, Group, BA, Year)
dat$Subject <- factor(dat$Subject)
dat$Year <- dat$Year - 1994
dat$BA <- relevel(dat$BA, ref="Bef")


library(lme4)

mod <- lmer(Attack ~ Group*Year + Group*BA + (1|Subject), data=dat,
family=poisson)

This tests whether the difference in Attack before and after differs
by Group, and whether the trajectory of Attack over time (Year)
differs by Group. Note that year is numeric and re-centered at 1994
(the year the intervention started).

Hope this was helpful. And please, those of you who know more than I
do, please jump in and correct me if I've given bad advice here...

Ista
>
> As for whether this design has standard approaches, the answer is YES. I reframed this example as a biomed trial partially because I think it is easier to contextualise it like that and partially because I can't believe that this design doesn't crop up regularly in the biomed context. But in reality (and in my case), this is a design that is often used in ecology (particularly impact assessment), where it is known as a multiple before-after, impact-control (MBACI) design. The model I am trying to specify is identical to one fit in the reference paper by Keough & Quinn (Legislative vs. practical protection of an intertidal shoreline in southeastern Australia. Ecol. Appl. 2000. 10: 871-881), which in terms of the variables above would be (written in basic ANOVA terminology):
> Attack ~ Group + BA + BA x Group + Year (within BA) + Subject (within Group) + Year (within BA) x Group + Subject (within Group) x BA
> I'd like to use lmer() first because it fits repeated-measures data better than ANOVA, second because it deals with missing data (which I have in my real data), and third because my data comprise small counts (cetacean mortalities by year), so I need the freedom to fit the response as a Poisson (or rather quasipoisson) variable.
>
> This ecological framing also partially explains the a priori designation of Subjects (in reality Sites) to Group: it is difficult to come up with Control sites that are very similar to Impact Sites, so by defining Group from the start, you can compare trajectories through time, rather than means (hence, also, my interest in the Group x BA interaction).
>
>
>
>
>
> On 27 Aug 2010, at 19:50, Dennis Murphy wrote:
>
> > Hi:
> >
> > On Fri, Aug 27, 2010 at 9:12 AM, Dave Schoeman <d.schoeman at ulster.ac.uk> wrote:
> > I tried this in a slightly different context and got no response, so I thought I'd try and frame the analysis slightly differently. The design is quite simple, but the analysis is proving difficult. Say I have 20 individual Subjects prone to mild anxiety attacks, half of which are assigned to a Control group and half to an Experimental group. I monitor these patients for 8 consecutive years, counting the number of anxiety attacks each year. After the initial 4 years, I provide members of the Control group a placebo and members of the Experimental group a supposed effective treatment. The hypothesis is that the supposed effective treatment has no effect in reality.
> >
> > As I see it, I have several fixed effects, all of which are factors: Group (Control or Experiment); BA (Before "treatment" or After "treatment"); and Year (nested within BA). There is a single random effect: Subject (nested within Group).
> >
> > Data can be simulated as follows (I have coded the attack rate Before slightly higher in the Experiment than the Control Group, with the attack rate increasing slightly after dosing in the Control group, but decreasing substantially in the Experiment group):
> > ? ? ? ?Subject <- c(rep(c(1:20), 8))
> > ? ? ? ?Group <- c(rep(c(rep("C", 10), rep("E", 10)), 8))
> > ? ? ? ?BA <- c(rep("Bef", 80), rep("After", 80))
> > ? ? ? ?Year <- c(rep(1990, 20), rep(1991, 20), rep(1992, 20), rep(1993, 20), rep(1994, 20), rep(1995, 20), rep(1996, 20), rep(1997, 20))
> > ? ? ? ?Attack <- c(rep(c(rpois(10, lambda = 10), rpois(10, lambda = 12)), 4), rep(c(rpois(10, lambda = 12), rpois(10, lambda = 3)), 4))
> > ? ? ? ?dat <- data.frame(Attack, Subject, Group, BA, Year)
> > ? ? ? ?dat$Subject <- as.factor(dat$Subject)
> > ? ? ? ?dat$Year <- as.factor(dat$Year)
> > The model seems like it should be:
> > ? ? ? ?mod <- lmer(Attack ~ Group*BA + BA/Year + BA/Year:Group + Group/Subject:BA + (1|Group/Subject), data = dat, family = poisson)
> >
> > Group is assigned at the time of the intervention; everything before it is baseline data. I could see comparisons between before/after trends at the subject level that would depend on Group assignment, but the Group * BA interaction is a bit of a problem, since no treatment is assigned in the 'Before' phase. The (1 | Group/Subject) term makes some sense (random intercepts), but you need something to generate and compare random slopes before and after treatment by Group and Subject. I'm not quite sure how that would be done; I'm concerned with maintaining the quantitative values of Year but estimating the slopes and intercepts by before/after treatment assignment. There must be a standard way to do this with biomedical data, but I don't have a lot of experience in that area. Hopefully, others will have better ideas.
> >
> > I don't see how Group is nested within BA (BA/Year:Group), especially when your first term is Group * BA, which suggests they are crossed. Group is not even assigned temporally until the After phase of BA, so it's clearly not nested within the levels of BA. It is more accurate to say that it is at best partially crossed, but even that is debatable - the groups are split in the After phase. You can't have it both ways - either two terms are crossed or they are nested...or in this case, perhaps somewhere in between. This is the part you need to unravel properly. Conceptually, I can see why you think Year should be nested within BA, but Year is a quantitative variable rather than a factor, and your aim should be to predict random intercepts and slopes among subjects, and compare mean differences between the control and experimental groups, before and after the treatments were applied.
> >
> > This type of problem must occur in biostatistics at least occasionally. How is this traditionally handled when you have longitudinal data by subject, where part of it is baseline (pre-treatment) and part of it is post-treatment? ?(BA * Year | Group/Subject) ??
> >
> >
> > BUT, this gives an error: "Error in mer_finalize(ans) : Downdated X'X is not positive definite, 1."
> >
> > This partially explains why:
> >
> > library(ggplot2)
> > g <- ggplot(dat, aes(x = Year, y = Attack, groups = Subject))
> > g + geom_line()
> > g + geom_line() + facet_grid(Group ~ BA, scales = 'free')
> >
> > You have no within-subject variablility within before/after phases and several subjects overlap in at least one of the phases.
> >
> > To avoid this error, I have to drop all of the interaction terms involving nesting. HOWEVER, if I code Year as a continuous covariate, I need only drop the term Group/Subject:BA. This suggests that interaction terms comprising only factors are not easily fit using this unreplicated design...
> >
> > I believe you have hit the nail on the head....rather than unreplicated, I would say incompletely crossed [BA * Group], because there is replication in the BA and Group factors.
> >
> > My questions are these:
> > 1 - Does my initial model look correct (and do I need to specify the nesting - other threads suggest that this might not be necessary if nested variables have unique codes)?
> > 2 - Why is it that the ?factor-by-factor interactions won't work (I'm an lmer() novice, so it might be very obvious to some...)?
> > 3 - Would I be more or less correct to simply ignore the Group/Subject:BA interaction and proceed with model development from there?
> >
> > Any comments appreciated.
> >
> > - Dave
> >
> >
> > I don't think I've helped resolve the form of model you need, but it seems that certain aspects of your design have to be massaged. Hopefully others can weigh in on the problem...
> >
> > Regards,
> > Dennis
> >
> >
> > _________
> > Dr Dave Schoeman
> > Lecturer in Marine Science
> > School of Environmental Sciences
> > University of Ulster
> > Cromore Road
> > Coleraine
> > BT52 1SA
> > Northern Ireland
> >
> > Phone: +44 (0)28 701 24076
> > Mobile: +44 (0)75 49 526 743
> > Fax: +44 (0)28 701 24491
> >
> > Treat data with care; under duress they will tell you anything you want to hear...
> >
> >
> > ? ? ? ?[[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



--
Ista Zahn
Graduate student
University of Rochester
Department of Clinical and Social Psychology
http://yourpsyche.org



From harring at umd.edu  Sun Aug 29 01:35:42 2010
From: harring at umd.edu (Jeffrey Harring)
Date: Sat, 28 Aug 2010 19:35:42 -0400
Subject: [R-sig-ME] nlme question...
Message-ID: <4C799D4E.8030809@umd.edu>

I would like to fit a nonlinear model with "nlme."

The model is a nonlinear growth model with five time points: y = X*b + 
e, where design matrix X is defined as

X= |  1   0  |
   |  1   1  |
   |  1   k  |
   |  1  2k  |
   |  1  3k  |

and parameter vector b = (b0, b1). And where "k" is a parameter to be 
estimated. Of course I also want to estimate the intercept (b0), slope 
(b1). Error variances (e) with 5 free parameters and random effects 
covariance matrix  (2x2: for b0 and b1).

I am not certain how to get the design matrix in the code so that the 
"nlme" procedure will be able to
estimate parameter "k" as well as the intercept and slope.

I have tried the following:

meanfunc <- function(x,b0,b1,k){
meangrad <- array(0,c(length(x),2),list(NULL,c("b0","b1")))

for(i in 1:length(x)){
    if(x[i]==0){
     err[i] <- b0 + b1*x[i]
       meangrad[i,"b0"] <- 1
       meangrad[i,"b1"] <- x[i]}
    if(x[i]==1){
     err[i] <- b0 + b1*x[i]
       meangrad[i,"b0"] <- 1
       meangrad[i,"b1"] <- x[i]}
    if(x[i]==2){
     err[i] <- b0 + b1*(x[i]-1)*k
     meangrad[i,"b0"] <- 1
       meangrad[i,"b1"] <- (x[i]-1)*k}
    if(x[i]==3){
       err[i] <- b0 + b1*2*(x[i]-1)*k
     meangrad[i,"b0"] <- 1
       meangrad[i,"b1"] <- (x[i]-1)*k}
    if(x[i]==4){
       err[i] <- b0 + b1*3*(x[i]-1)*k
     meangrad[i,"b0"] <- 1
       meangrad[i,"b1"] <- (x[i]-1)*k}
}
#  compute analytical derivatives
   attr(err,"gradient") <- meangrad
   err
}

data.mlfit <- nlme(y ~ meanfunc(x,b0,b1,k),
   fixed=list(b0 ~ 1, b1 ~ 1, k ~ 1),
   random=list(b0 ~ 1, b1 ~ 1),
   groups = ~subj,
   data=nd,
   start=list(fixed=c(300,50,1)),
   method="ML",verbose=T)

I get the following error message:

Error in meangrad[i, "b1"] <- (x[i] - 1) * k :
  number of items to replace is not a multiple of replacement length
In addition: Warning messages:
1: In err[i] <- b0 + b1 * x[i] :
  number of items to replace is not a multiple of replacement length
2: In err[i] <- b0 + b1 * x[i] :
  number of items to replace is not a multiple of replacement length
3: In err[i] <- b0 + b1 * (x[i] - 1) * k :
  number of items to replace is not a multiple of replacement length

Any suggestions or insights would be greatly appreciated.

Thank you,
Jeff

-- 
**********************************************************
Jeffrey R. Harring, Assistant Professor
Department of Measurement, Statistics & Evaluation (EDMS)
1230 Benjamin Building
University of Maryland
College Park, MD 20742-1115

Phone: 	301.405.3630
Fax: 	301.314.9245
Email: 	harring at umd.edu
Web:  	http://www.education.umd.edu/EDMS/fac/Harring/webpage.html



From A.Robinson at ms.unimelb.edu.au  Sun Aug 29 01:54:07 2010
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Sun, 29 Aug 2010 09:54:07 +1000
Subject: [R-sig-ME] nlme question...
In-Reply-To: <4C799D4E.8030809@umd.edu>
References: <4C799D4E.8030809@umd.edu>
Message-ID: <20100828235407.GA1470@ms.unimelb.edu.au>

Hi Jeffrey,  

in the first instance, I think that the problem is that "if" is not
vectorised.  Try ifelse() instead.

Cheers

Andrew

On Sat, Aug 28, 2010 at 07:35:42PM -0400, Jeffrey Harring wrote:
> I would like to fit a nonlinear model with "nlme."
> 
> The model is a nonlinear growth model with five time points: y = X*b + 
> e, where design matrix X is defined as
> 
> X= |  1   0  |
>   |  1   1  |
>   |  1   k  |
>   |  1  2k  |
>   |  1  3k  |
> 
> and parameter vector b = (b0, b1). And where "k" is a parameter to be 
> estimated. Of course I also want to estimate the intercept (b0), slope 
> (b1). Error variances (e) with 5 free parameters and random effects 
> covariance matrix  (2x2: for b0 and b1).
> 
> I am not certain how to get the design matrix in the code so that the 
> "nlme" procedure will be able to
> estimate parameter "k" as well as the intercept and slope.
> 
> I have tried the following:
> 
> meanfunc <- function(x,b0,b1,k){
> meangrad <- array(0,c(length(x),2),list(NULL,c("b0","b1")))
> 
> for(i in 1:length(x)){
>    if(x[i]==0){
>     err[i] <- b0 + b1*x[i]
>       meangrad[i,"b0"] <- 1
>       meangrad[i,"b1"] <- x[i]}
>    if(x[i]==1){
>     err[i] <- b0 + b1*x[i]
>       meangrad[i,"b0"] <- 1
>       meangrad[i,"b1"] <- x[i]}
>    if(x[i]==2){
>     err[i] <- b0 + b1*(x[i]-1)*k
>     meangrad[i,"b0"] <- 1
>       meangrad[i,"b1"] <- (x[i]-1)*k}
>    if(x[i]==3){
>       err[i] <- b0 + b1*2*(x[i]-1)*k
>     meangrad[i,"b0"] <- 1
>       meangrad[i,"b1"] <- (x[i]-1)*k}
>    if(x[i]==4){
>       err[i] <- b0 + b1*3*(x[i]-1)*k
>     meangrad[i,"b0"] <- 1
>       meangrad[i,"b1"] <- (x[i]-1)*k}
> }
> #  compute analytical derivatives
>   attr(err,"gradient") <- meangrad
>   err
> }
> 
> data.mlfit <- nlme(y ~ meanfunc(x,b0,b1,k),
>   fixed=list(b0 ~ 1, b1 ~ 1, k ~ 1),
>   random=list(b0 ~ 1, b1 ~ 1),
>   groups = ~subj,
>   data=nd,
>   start=list(fixed=c(300,50,1)),
>   method="ML",verbose=T)
> 
> I get the following error message:
> 
> Error in meangrad[i, "b1"] <- (x[i] - 1) * k :
>  number of items to replace is not a multiple of replacement length
> In addition: Warning messages:
> 1: In err[i] <- b0 + b1 * x[i] :
>  number of items to replace is not a multiple of replacement length
> 2: In err[i] <- b0 + b1 * x[i] :
>  number of items to replace is not a multiple of replacement length
> 3: In err[i] <- b0 + b1 * (x[i] - 1) * k :
>  number of items to replace is not a multiple of replacement length
> 
> Any suggestions or insights would be greatly appreciated.
> 
> Thank you,
> Jeff
> 
> -- 
> **********************************************************
> Jeffrey R. Harring, Assistant Professor
> Department of Measurement, Statistics & Evaluation (EDMS)
> 1230 Benjamin Building
> University of Maryland
> College Park, MD 20742-1115
> 
> Phone: 	301.405.3630
> Fax: 	301.314.9245
> Email: 	harring at umd.edu
> Web:  	http://www.education.umd.edu/EDMS/fac/Harring/webpage.html
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Andrew Robinson  
Program Manager, ACERA 
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia               (prefer email)
http://www.ms.unimelb.edu.au/~andrewpr              Fax: +61-3-8344-4599
http://www.acera.unimelb.edu.au/



From d.schoeman at ulster.ac.uk  Sun Aug 29 12:03:07 2010
From: d.schoeman at ulster.ac.uk (Dave Schoeman)
Date: Sun, 29 Aug 2010 11:03:07 +0100
Subject: [R-sig-ME] Help with coding an intervention analysis with lmer()
In-Reply-To: <AANLkTim4rk1+25_xd-szKHnF+mzv2m=zp-MKK+3-2W3R@mail.gmail.com>
References: <46B05E88-BDEA-4578-AB8F-8E40815B3B1E@ulster.ac.uk>
	<AANLkTikeQZzagK4LqKdhW3SbXUJSx8nefpvB_VB2d_mj@mail.gmail.com>
	<04BB37A5-8461-4BF5-9678-96FB7A0898A3@ulster.ac.uk>
	<AANLkTim4rk1+25_xd-szKHnF+mzv2m=zp-MKK+3-2W3R@mail.gmail.com>
Message-ID: <F8DF5C9C-45F6-4D41-A3C8-68BAA78D3D4E@ulster.ac.uk>

Many thanks for the input! This is very interesting.

On 28 Aug 2010, at 17:00, Ista Zahn wrote:

> Hi all,
> I hesitate to weigh in on this, because I still consider myself a
> newbie with lme4. But I really think you're on the wrong track here,
> and I trust that someone will correct me if I'm wrong.
> 
> 
> 
> On Sat, Aug 28, 2010 at 2:58 AM, Dave Schoeman <d.schoeman at ulster.ac.uk> wrote:
>> 
>> Hi, many thanks for the thoughts; it is extremely useful to have outside input.
> 
>> <snip>

<snip>

>> I defined the random effect of (1| Group/Subject) purely on the basis of the experimental design: Subject is nested in Group (if you agree with the logic above).
> 
> I think this is where you go off the rails. Nesting refers to
> _grouping variables_, not to fixed effects. If I'm understanding
> correctly, group is not a grouping variable, it is a fixed effect with
> 2 repeatable levels: control and experimental.

OK, I think this is a fundamental question. In my understanding, nesting arises when levels of one factor (here Subject) are present in only one level of another factor (here Group). In other words, Subjects 1-10 occur only in the Control Group, and Subjects 11-20 occur only in the Experiment Group. If each Subject occurred in each Group, Subject and Group would be crossed. The same goes for BA and Year: Years 1990-1993 are Before and Years 1994-1997 are After, so again Year is nested within BA. If this nesting is correct, then should I not try to estimate the effects of each? And if I should, the question is HOW? I agree with you that my model specification looks like gobbledygook, but it is just an attempt to model all components of variance.

<snip>

>> The term BA/Year:Group is unclear, I agree. What it means is that I want to add an interaction term on a nested factor: Year (within BA) x Group. Similarly Group/Subject:BA is the interaction of Subject (within Group) x BA. Finally, there SHOULD be a term for Year (within BA) x Subject (within Group), but these data are unreplicated at this level, so this term is not estimable in conventional anova (so it is omitted to contribute to the residual variance). I understand that these interactions are difficult to read, and I tried to resolve this by isolating the nested terms in brackets, but this seems to make no difference to R.
> 
> I don't think this is right. I don't think you need to specify nesting
> this way, especially in the fixed-effects part of the model. The way I
> see it, you have only one grouping factor, and that is Subject.
> 
> If we go back to your original model specification, you had
> 
> mod <- lmer(Attack ~ Group*BA + BA/Year + BA/Year:Group +
> Group/Subject:BA + (1|Group/Subject), data = dat, family = poisson)
> 
> in my view that is gobbledygook. You have Group as a fixed effect
> predictor, but also as a grouping factor, and I don't think that makes
> any sense. I also don't think that those nesting statements in the
> fixed-effects specification make any sense, but it's possible I'm the
> one who doesn't understand lmer syntax... Anyway, I would do something
> like
> 
> Subject <- c(rep(c(1:20), 8))
> Group <- c(rep(c(rep("C", 10), rep("E", 10)), 8))
> BA <- c(rep("Bef", 80), rep("After", 80))
> Year <- c(rep(1990, 20), rep(1991, 20), rep(1992, 20), rep(1993, 20),
> rep(1994, 20), rep(1995, 20), rep(1996, 20), rep(1997, 20))
> 
> Attack <- c(rpois(10, lambda = 10), rpois(10, lambda = 12), rpois(10,
> lambda = 10), rpois(10, lambda = 12), rpois(10, lambda = 10),
> rpois(10, lambda = 12), rpois(10, lambda = 10), rpois(10, lambda =
> 12), rpois(10, lambda = 15), rpois(10, lambda = 3), rpois(10, lambda =
> 15), rpois(10, lambda = 3), rpois(10, lambda = 15), rpois(10, lambda =
> 3), rpois(10, lambda = 15), rpois(10, lambda = 3))
> 
> dat <- data.frame(Attack, Subject, Group, BA, Year)
> dat$Subject <- factor(dat$Subject)
> dat$Year <- dat$Year - 1994
> dat$BA <- relevel(dat$BA, ref="Bef")
> 
> 
> library(lme4)
> 
> mod <- lmer(Attack ~ Group*Year + Group*BA + (1|Subject), data=dat,
> family=poisson)
> 
> This tests whether the difference in Attack before and after differs
> by Group, and whether the trajectory of Attack over time (Year)
> differs by Group. Note that year is numeric and re-centered at 1994
> (the year the intervention started).

Yes, I agree that your model tests the hypotheses I'm interested in, and the model-building process ends up in the same place, irrespective if whether you start with my model or yours (both with the simulated data provided, or with the real data). BUT, should the model not start by including all terms?

> Hope this was helpful. And please, those of you who know more than I
> do, please jump in and correct me if I've given bad advice here...

Yes, very helpful, indeed. Thanks. And thanks, also, to Dennis who wrote earlier.

I do think that it would be useful, though, to get further input on the nesting concepts here and how to specify them using the fixed and random effects...

- Dave

> 
> Ista



>> On 27 Aug 2010, at 19:50, Dennis Murphy wrote:
>> 
>>> Hi:
>>> 
>>> On Fri, Aug 27, 2010 at 9:12 AM, Dave Schoeman <d.schoeman at ulster.ac.uk> wrote:
>>> I tried this in a slightly different context and got no response, so I thought I'd try and frame the analysis slightly differently. The design is quite simple, but the analysis is proving difficult. Say I have 20 individual Subjects prone to mild anxiety attacks, half of which are assigned to a Control group and half to an Experimental group. I monitor these patients for 8 consecutive years, counting the number of anxiety attacks each year. After the initial 4 years, I provide members of the Control group a placebo and members of the Experimental group a supposed effective treatment. The hypothesis is that the supposed effective treatment has no effect in reality.
>>> 
>>> As I see it, I have several fixed effects, all of which are factors: Group (Control or Experiment); BA (Before "treatment" or After "treatment"); and Year (nested within BA). There is a single random effect: Subject (nested within Group).
>>> 
>>> Data can be simulated as follows (I have coded the attack rate Before slightly higher in the Experiment than the Control Group, with the attack rate increasing slightly after dosing in the Control group, but decreasing substantially in the Experiment group):
>>>        Subject <- c(rep(c(1:20), 8))
>>>        Group <- c(rep(c(rep("C", 10), rep("E", 10)), 8))
>>>        BA <- c(rep("Bef", 80), rep("After", 80))
>>>        Year <- c(rep(1990, 20), rep(1991, 20), rep(1992, 20), rep(1993, 20), rep(1994, 20), rep(1995, 20), rep(1996, 20), rep(1997, 20))
>>>        Attack <- c(rep(c(rpois(10, lambda = 10), rpois(10, lambda = 12)), 4), rep(c(rpois(10, lambda = 12), rpois(10, lambda = 3)), 4))
>>>        dat <- data.frame(Attack, Subject, Group, BA, Year)
>>>        dat$Subject <- as.factor(dat$Subject)
>>>        dat$Year <- as.factor(dat$Year)
>>> The model seems like it should be:
>>>        mod <- lmer(Attack ~ Group*BA + BA/Year + BA/Year:Group + Group/Subject:BA + (1|Group/Subject), data = dat, family = poisson)
>>> 
>>> Group is assigned at the time of the intervention; everything before it is baseline data. I could see comparisons between before/after trends at the subject level that would depend on Group assignment, but the Group * BA interaction is a bit of a problem, since no treatment is assigned in the 'Before' phase. The (1 | Group/Subject) term makes some sense (random intercepts), but you need something to generate and compare random slopes before and after treatment by Group and Subject. I'm not quite sure how that would be done; I'm concerned with maintaining the quantitative values of Year but estimating the slopes and intercepts by before/after treatment assignment. There must be a standard way to do this with biomedical data, but I don't have a lot of experience in that area. Hopefully, others will have better ideas.
>>> 
>>> I don't see how Group is nested within BA (BA/Year:Group), especially when your first term is Group * BA, which suggests they are crossed. Group is not even assigned temporally until the After phase of BA, so it's clearly not nested within the levels of BA. It is more accurate to say that it is at best partially crossed, but even that is debatable - the groups are split in the After phase. You can't have it both ways - either two terms are crossed or they are nested...or in this case, perhaps somewhere in between. This is the part you need to unravel properly. Conceptually, I can see why you think Year should be nested within BA, but Year is a quantitative variable rather than a factor, and your aim should be to predict random intercepts and slopes among subjects, and compare mean differences between the control and experimental groups, before and after the treatments were applied.
>>> 
>>> This type of problem must occur in biostatistics at least occasionally. How is this traditionally handled when you have longitudinal data by subject, where part of it is baseline (pre-treatment) and part of it is post-treatment?  (BA * Year | Group/Subject) ??
>>> 
>>> 
>>> BUT, this gives an error: "Error in mer_finalize(ans) : Downdated X'X is not positive definite, 1."
>>> 
>>> This partially explains why:
>>> 
>>> library(ggplot2)
>>> g <- ggplot(dat, aes(x = Year, y = Attack, groups = Subject))
>>> g + geom_line()
>>> g + geom_line() + facet_grid(Group ~ BA, scales = 'free')
>>> 
>>> You have no within-subject variablility within before/after phases and several subjects overlap in at least one of the phases.
>>> 
>>> To avoid this error, I have to drop all of the interaction terms involving nesting. HOWEVER, if I code Year as a continuous covariate, I need only drop the term Group/Subject:BA. This suggests that interaction terms comprising only factors are not easily fit using this unreplicated design...
>>> 
>>> I believe you have hit the nail on the head....rather than unreplicated, I would say incompletely crossed [BA * Group], because there is replication in the BA and Group factors.
>>> 
>>> My questions are these:
>>> 1 - Does my initial model look correct (and do I need to specify the nesting - other threads suggest that this might not be necessary if nested variables have unique codes)?
>>> 2 - Why is it that the  factor-by-factor interactions won't work (I'm an lmer() novice, so it might be very obvious to some...)?
>>> 3 - Would I be more or less correct to simply ignore the Group/Subject:BA interaction and proceed with model development from there?
>>> 
>>> Any comments appreciated.
>>> 
>>> - Dave
>>> 
>>> 
>>> I don't think I've helped resolve the form of model you need, but it seems that certain aspects of your design have to be massaged. Hopefully others can weigh in on the problem...
>>> 
>>> Regards,
>>> Dennis
>>> 
>>> 
>>> _________
>>> Dr Dave Schoeman
>>> Lecturer in Marine Science
>>> School of Environmental Sciences
>>> University of Ulster
>>> Cromore Road
>>> Coleraine
>>> BT52 1SA
>>> Northern Ireland
>>> 
>>> Phone: +44 (0)28 701 24076
>>> Mobile: +44 (0)75 49 526 743
>>> Fax: +44 (0)28 701 24491
>>> 
>>> Treat data with care; under duress they will tell you anything you want to hear...
>>> 
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
>> 
>> 
>>        [[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 
> --
> Ista Zahn
> Graduate student
> University of Rochester
> Department of Clinical and Social Psychology
> http://yourpsyche.org
> 



From mensurationist at gmail.com  Sun Aug 29 12:26:28 2010
From: mensurationist at gmail.com (Andrew Robinson)
Date: Sun, 29 Aug 2010 20:26:28 +1000
Subject: [R-sig-ME] Help with coding an intervention analysis with lmer()
In-Reply-To: <F8DF5C9C-45F6-4D41-A3C8-68BAA78D3D4E@ulster.ac.uk>
References: <46B05E88-BDEA-4578-AB8F-8E40815B3B1E@ulster.ac.uk>
	<AANLkTikeQZzagK4LqKdhW3SbXUJSx8nefpvB_VB2d_mj@mail.gmail.com>
	<04BB37A5-8461-4BF5-9678-96FB7A0898A3@ulster.ac.uk>
	<AANLkTim4rk1+25_xd-szKHnF+mzv2m=zp-MKK+3-2W3R@mail.gmail.com>
	<F8DF5C9C-45F6-4D41-A3C8-68BAA78D3D4E@ulster.ac.uk>
Message-ID: <16348AAB-709A-444F-988C-F1162C8A73DB@ms.unimelb.edu.au>


>> 
>> If we go back to your original model specification, you had
>> 
>> mod <- lmer(Attack ~ Group*BA + BA/Year + BA/Year:Group +
>> Group/Subject:BA + (1|Group/Subject), data = dat, family = poisson)
>> 
>> in my view that is gobbledygook. You have Group as a fixed effect
>> predictor, but also as a grouping factor, and I don't think that makes
>> any sense.

Just as a general point, there is a case when fixed effect predictor can also appear as a grouping effect: in split-plot designs. Indeed, this occurs in one of the examples in Pinheiro & Bates (2000).  It is a bit unclear in coding, and it would be cleaner if the coder were to create separate factors for the fixed and the random effects, even if they are the same. The algorithms allow the shortcut, though.    

Cheers

Andrew


>>  



From bates at stat.wisc.edu  Sun Aug 29 20:48:12 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sun, 29 Aug 2010 13:48:12 -0500
Subject: [R-sig-ME] Help with coding an intervention analysis with lmer()
In-Reply-To: <16348AAB-709A-444F-988C-F1162C8A73DB@ms.unimelb.edu.au>
References: <46B05E88-BDEA-4578-AB8F-8E40815B3B1E@ulster.ac.uk>
	<AANLkTikeQZzagK4LqKdhW3SbXUJSx8nefpvB_VB2d_mj@mail.gmail.com>
	<04BB37A5-8461-4BF5-9678-96FB7A0898A3@ulster.ac.uk>
	<AANLkTim4rk1+25_xd-szKHnF+mzv2m=zp-MKK+3-2W3R@mail.gmail.com>
	<F8DF5C9C-45F6-4D41-A3C8-68BAA78D3D4E@ulster.ac.uk>
	<16348AAB-709A-444F-988C-F1162C8A73DB@ms.unimelb.edu.au>
Message-ID: <AANLkTinprng88CDUPryptPLMbbmfVr0oVztg+F=Jz81q@mail.gmail.com>

On Sun, Aug 29, 2010 at 5:26 AM, Andrew Robinson
<mensurationist at gmail.com> wrote:
>
>>>
>>> If we go back to your original model specification, you had
>>>
>>> mod <- lmer(Attack ~ Group*BA + BA/Year + BA/Year:Group +
>>> Group/Subject:BA + (1|Group/Subject), data = dat, family = poisson)
>>>
>>> in my view that is gobbledygook. You have Group as a fixed effect
>>> predictor, but also as a grouping factor, and I don't think that makes
>>> any sense.
>
> Just as a general point, there is a case when fixed effect predictor can also appear as a grouping effect: in split-plot designs. Indeed, this occurs in one of the examples in Pinheiro & Bates (2000). ?It is a bit unclear in coding, and it would be cleaner if the coder were to create separate factors for the fixed and the random effects, even if they are the same. The algorithms allow the shortcut, though.

There is such an example but it doesn't apply in this case.  Even
though the whole plot factor was being used as a grouping factor for
the random effects it was used in the form of an interaction with the
blocking factor.  In other words, if F1, F2, etc are fixed-effects
factors and B1, B2, etc. are environmental factors (such as location)
then a formula of

Y ~ F1 + (1|B1/F1)

which expands to

Y ~ F1 + (1|B1) + (1|B1:F1)

is sensible but a term of the form (1|F1) is not.

>
> Cheers
>
> Andrew
>
>
>>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From albrem04 at student.uwa.edu.au  Mon Aug 30 05:14:12 2010
From: albrem04 at student.uwa.edu.au (Matthew Albrecht)
Date: Mon, 30 Aug 2010 11:14:12 +0800
Subject: [R-sig-ME] Setting correlation to 0 for factored random effects
Message-ID: <4C7B2204.9040908@student.uwa.edu.au>

  Dear list,
How do you (can you) set the correlation among factored random effects 
to zero?

#For example:
     set.seed(69)
     sid <- factor(rep((1:10), 4))
     fac <- factor(rep(c("a","b","c","d"),each=10))
     dv <- c(rnorm(10, sd=1), rnorm(10, sd=2), rnorm(10, sd=3), 
rnorm(10, sd=4))
     df1 <- data.frame(sid, fac, dv)

     fm1 <- lmer(dv~fac+(1+fac|sid), data=df1)
     fm2 <- lmer(dv~fac+(0+fac|sid), data=df1)

#The method for setting the correlation to zero for the relationship 
between a continuous variable and the intercept is as far as I can tell 
not doing what I want it to. However, I think I can do it by creating 
new factors as below:

     df1$faca <- ifelse(df1$fac=="a", 1, 0)
     df1$facb <- ifelse(df1$fac=="b", 1, 0)
     df1$facc <- ifelse(df1$fac=="c", 1, 0)
     df1$facd<-ifelse(df1$fac=="d", 1, 0)

     
fm3<-lmer(dv~fac+(0+faca|sid)+(0+facb|sid)+(0+facc|sid)+(0+facd|sid), 
data=df1)

#Is this giving me what I want? (It seems to be). And is there another 
way for when I have more complex models?

Thanks,
Matt Albrecht



From harring at umd.edu  Mon Aug 30 19:47:46 2010
From: harring at umd.edu (Jeffrey Harring)
Date: Mon, 30 Aug 2010 13:47:46 -0400
Subject: [R-sig-ME] nlme question...
Message-ID: <4C7BEEC2.3040401@umd.edu>

  Hi all,

Can the algorithm in nlme handle a nonlinear function that is written as 
a design matrix and linear coefficients like the following

The model is a nonlinear growth model with five time points: y = X*b +
e, where design matrix X is defined as

X= |  1   0  |
    |  1   1  |
    |  1   k  |
    |  1  2k  |
    |  1  3k  |

and parameter vector b = (b0, b1). And where "k" is a parameter to be
estimated. Of course I also want to estimate the intercept (b0), slope
(b1). Error variances (e) with 5 free parameters and random effects
covariance matrix  (2x2: for b0 and b1).

If anyone has concrete suggestions I would love to hear from you.

Thanks for your consideration,
Jeff




-- 
**********************************************************
Jeffrey R. Harring, Assistant Professor
Department of Measurement, Statistics&  Evaluation (EDMS)
1230 Benjamin Building
University of Maryland
College Park, MD 20742-1115

Phone: 	301.405.3630
Fax: 	301.314.9245
Email: 	harring at umd.edu
Web:  	http://www.education.umd.edu/EDMS/fac/Harring/webpage.html



From HDoran at air.org  Mon Aug 30 20:31:43 2010
From: HDoran at air.org (Doran, Harold)
Date: Mon, 30 Aug 2010 14:31:43 -0400
Subject: [R-sig-ME] nlme question...
In-Reply-To: <4C7BEEC2.3040401@umd.edu>
References: <4C7BEEC2.3040401@umd.edu>
Message-ID: <C0772C7568B5374481D2F8A880E9BBDF059CB062E3@DC1EX07CMS.air.org>

This is confusing. First, how is your model non-linear? It looks like it is linear in the parameters. A design matrix is known and parameters are estimated. So, is k known or is it part of the parameters to be estimated. 

Moreover, can you use lmer and not lme since nlme is not supported much anymore

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Jeffrey Harring
Sent: Monday, August 30, 2010 1:48 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] nlme question...

  Hi all,

Can the algorithm in nlme handle a nonlinear function that is written as 
a design matrix and linear coefficients like the following

The model is a nonlinear growth model with five time points: y = X*b +
e, where design matrix X is defined as

X= |  1   0  |
    |  1   1  |
    |  1   k  |
    |  1  2k  |
    |  1  3k  |

and parameter vector b = (b0, b1). And where "k" is a parameter to be
estimated. Of course I also want to estimate the intercept (b0), slope
(b1). Error variances (e) with 5 free parameters and random effects
covariance matrix  (2x2: for b0 and b1).

If anyone has concrete suggestions I would love to hear from you.

Thanks for your consideration,
Jeff




-- 
**********************************************************
Jeffrey R. Harring, Assistant Professor
Department of Measurement, Statistics&  Evaluation (EDMS)
1230 Benjamin Building
University of Maryland
College Park, MD 20742-1115

Phone: 	301.405.3630
Fax: 	301.314.9245
Email: 	harring at umd.edu
Web:  	http://www.education.umd.edu/EDMS/fac/Harring/webpage.html

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From HDoran at air.org  Mon Aug 30 21:32:05 2010
From: HDoran at air.org (Doran, Harold)
Date: Mon, 30 Aug 2010 15:32:05 -0400
Subject: [R-sig-ME] nlme question...
In-Reply-To: <4C7C050F.7030800@umd.edu>
References: <4C7BEEC2.3040401@umd.edu>
	<C0772C7568B5374481D2F8A880E9BBDF059CB062E3@DC1EX07CMS.air.org>
	<4C7C050F.7030800@umd.edu>
Message-ID: <C0772C7568B5374481D2F8A880E9BBDF059CB06316@DC1EX07CMS.air.org>

Jeff

I still think something is wrong here, but maybe it is just me and someone else might see it differently. First off, your model notation is y = XB + e which is not a mixed model. Second, if k is a parameter, then it cannot be in your *known* model matrix. Your model matrix has two columns and your parameter vector has two unknowns (b0 and b1).

If your model matrix were (or something like it), I can see how you would estimate b0 and b1 as you would estimate those from the observed data. But, upon what data is k estimated?

 X= |  1   0  |
      |  1   1  |
      |  1  2  |
      |  1  3  |

If I am understanding your problem correctly (and it seems I may not be), your design matrix has two columns of known values, but your parameter vector has 3 unknowns. So, how can this be?

Also, are you hoping to estimate a mixed model or a least squares model?

-----Original Message-----
From: Jeffrey Harring [mailto:harring at umd.edu] 
Sent: Monday, August 30, 2010 3:23 PM
To: Doran, Harold
Subject: Re: [R-sig-ME] nlme question...

  Harold,

Thanks for responding. Yes, k in the design matrix is a parameter to be 
estimated. If you think lmer is a viable option for this type of problem 
I will certainly look into it.

Jeff

On 8/30/2010 2:31 PM, Doran, Harold wrote:
> This is confusing. First, how is your model non-linear? It looks like it is linear in the parameters. A design matrix is known and parameters are estimated. So, is k known or is it part of the parameters to be estimated.
>
> Moreover, can you use lmer and not lme since nlme is not supported much anymore
>
> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Jeffrey Harring
> Sent: Monday, August 30, 2010 1:48 PM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] nlme question...
>
>    Hi all,
>
> Can the algorithm in nlme handle a nonlinear function that is written as
> a design matrix and linear coefficients like the following
>
> The model is a nonlinear growth model with five time points: y = X*b +
> e, where design matrix X is defined as
>
> X= |  1   0  |
>      |  1   1  |
>      |  1   k  |
>      |  1  2k  |
>      |  1  3k  |
>
> and parameter vector b = (b0, b1). And where "k" is a parameter to be
> estimated. Of course I also want to estimate the intercept (b0), slope
> (b1). Error variances (e) with 5 free parameters and random effects
> covariance matrix  (2x2: for b0 and b1).
>
> If anyone has concrete suggestions I would love to hear from you.
>
> Thanks for your consideration,
> Jeff
>
>
>
>

-- 
**********************************************************
Jeffrey R. Harring, Assistant Professor
Department of Measurement, Statistics&  Evaluation (EDMS)
1230 Benjamin Building
University of Maryland
College Park, MD 20742-1115

Phone: 	301.405.3630
Fax: 	301.314.9245
Email: 	harring at umd.edu
Web:  	http://www.education.umd.edu/EDMS/fac/Harring/webpage.html



From maj at waikato.ac.nz  Mon Aug 30 21:58:36 2010
From: maj at waikato.ac.nz (Murray Jorgensen)
Date: Tue, 31 Aug 2010 07:58:36 +1200
Subject: [R-sig-ME] nlme question...
In-Reply-To: <4C7BEEC2.3040401@umd.edu>
References: <4C7BEEC2.3040401@umd.edu>
Message-ID: <4C7C0D6C.4060807@waikato.ac.nz>

Maybe you could tell us more about the data and why you wish to 
associate error components with b0 and b1 parameters? It just looks like 
a perfectly ordinary nonlinear model that might be fitted using the 
Gauss-Newton or partially linear methods using nls().

Murray Jorgensen

Jeffrey Harring wrote:
>  Hi all,
> 
> Can the algorithm in nlme handle a nonlinear function that is written as 
> a design matrix and linear coefficients like the following
> 
> The model is a nonlinear growth model with five time points: y = X*b +
> e, where design matrix X is defined as
> 
> X= |  1   0  |
>    |  1   1  |
>    |  1   k  |
>    |  1  2k  |
>    |  1  3k  |
> 
> and parameter vector b = (b0, b1). And where "k" is a parameter to be
> estimated. Of course I also want to estimate the intercept (b0), slope
> (b1). Error variances (e) with 5 free parameters and random effects
> covariance matrix  (2x2: for b0 and b1).
> 
> If anyone has concrete suggestions I would love to hear from you.
> 
> Thanks for your consideration,
> Jeff
> 
> 
> 
> 


-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz    majorgensen at ihug.co.nz      Fax 7 838 4155
Phone  +64 7 838 4773 wk    Home +64 7 825 0441   Mobile 021 0200 8350



From datkins at u.washington.edu  Mon Aug 30 22:37:29 2010
From: datkins at u.washington.edu (David Atkins)
Date: Mon, 30 Aug 2010 13:37:29 -0700
Subject: [R-sig-ME] rare binary outcome, MCMCglmm,
	and priors (related to separation)
Message-ID: <4C7C1689.3030101@u.washington.edu>


Some colleagues have collected data from 184 females in dating 
relationships.  Data were collected daily using PDAs; the outcome is a 
binary indicator of whether any physical aggression occurred (intimate 
partner violence, or IPV).

They are interested in 3 covariates:

-- alcohol use: yes/no
-- anger: rated on 1-5 scale
-- verbal aggression: sum of handful of items, with 0-15 scale

Their hypothesis is that the interaction of all 3 covariates will lead 
to the highest likelihood of IPV.  As you might expect, the outcome is 
very rare with 51 instances of IPV out of 8,269 days of data, and 158 
women (out of 184) reported no instances of IPV.

Question 1: Given that a GLMM will assume a normal distribution for the 
person-specific baserate in IPV, is this data even appropriate for GLMM 
or should they be looking elsewhere (perhaps GEE)?

That said, for some (unknown) proportion of individuals, there probably 
would be instances of IPV if the data collection period were longer. 
Thus, perhaps there is some basis for assuming a distribution across 
people, even if the observed data for some individuals are all zeroes.

To present some of the data (and I can check to see if it would be okay 
to make the data available), I dichotomized both anger and verbal 
aggression ("prov.cut" below):

   ang.cut prov.cut alc.cut ipv.yes ipv.no
1       0        0       0       0     3918
2       0        0       1       0        1
3       1        0       0       5     2381
4       1        0       1       1      292
5       1        1       0      36     1471
6       1        1       1       9      257

Thus, the instances of IPV are more likely when there is anger and 
verbal aggression; alcohol is a little less clear.  (And, if the 
association of anger and verbal aggression with IPV seems tautological, 
there has been debate about different forms of IPV, where some research 
has pointed to "cold" aggression.)

Not surprisingly, analyses using either glmer() or MCMCglmm() show signs 
of partial separation, with some whopping odds-ratios and 95% CI 
spanning a couple orders of magnitude.

I have read a bit about the problems of separation in logistic 
regression and know that Gelman et al suggest Bayesian priors as one 
"solution".  Moreover, I see in Jarrod Hadfield's course notes that his 
multinomial example has a "structural" zero that he addresses via priors 
on pp. 96-97, though I confess I don't quite follow exactly what he has 
done (and why).

If I just let MCMCglmm cook on a regression with all 2-way interactions 
for a long while:

prior = list(R = list(V = 1, fix = 1),
			B = list(mu = c(rep(0,7)), V = diag(7)),
			G = list(G1 = list(V = 1, nu = 0.002)))
lr.mcmc <- MCMCglmm(ipv ~ (alc.cut + angc + log(provc + 0.03))^2, data = 
ipv.df,
					family = "categorical", verbose = TRUE,
					prior = prior,
					nitt = 2000000, burnin = 1000000, thin = 1000,
					random =  ~ person)

The answers are less extreme than what I get with glmer, perhaps 
suggesting this is wandering toward the "correct" solution, though there 
are also plenty of indicators that we aren't there yet:

 > summary(lr.mcmc)

  Iterations = 1999001
  Thinning interval  = 1000001
  Sample size  = 1000

  DIC: 379.972

  G-structure:  ~person

        post.mean l-95% CI u-95% CI eff.samp
person     2.287   0.6775    4.206    194.0

  R-structure:  ~units

       post.mean l-95% CI u-95% CI eff.samp
units         1        1        1        0

  Location effects: ipv ~ (alc.cut + angc + log(provc + 0.03))^2

                           post.mean l-95% CI u-95% CI eff.samp  pMCMC
(Intercept)                -2.58724 -3.49492 -1.65250   245.20 <0.001 ***
alc.cut                     0.49512 -0.75268  1.99397  1000.00  0.464
angc                        0.02664 -0.34227  0.41365   283.90  0.880
log(provc + 0.03)           1.36626  0.98743  1.70863    28.69 <0.001 ***
alc.cut:angc               -0.16519 -0.79299  0.41949   683.56  0.590
alc.cut:log(provc + 0.03)  -0.02631 -0.53118  0.55065   157.34  0.898
angc:log(provc + 0.03)     -0.26132 -0.40141 -0.10407    74.98  0.004 **
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

I haven't run multiple chains yet, but the effective sample sizes and 
trace plots already suggest we ain't there yet.  My specific question is 
whether there would be an alternative prior specification for the 
fixed-effects that would be more appropriate?

I would appreciate any and all thoughts here, including if this just 
doesn't seem like an appropriate data/question for GLMMs.

sessionInfo below.

cheers, Dave

 > sessionInfo()
R version 2.11.1 (2010-05-31)
i386-apple-darwin9.8.0

locale:
[1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats4    splines   stats     graphics  grDevices utils     datasets
[8] methods   base

other attached packages:
  [1] MCMCglmm_2.06      corpcor_1.5.7      ape_2.5-3
  [4] coda_0.13-5        Matrix_0.999375-44 lattice_0.19-10
  [7] tensorA_0.35       Hmisc_3.8-2        modeltools_0.2-16
[10] mvtnorm_0.9-92     survival_2.36-1

loaded via a namespace (and not attached):
  [1] cluster_1.13.1   coin_1.0-16      colorspace_1.0-1 gee_4.13-15
  [5] grid_2.11.1      lme4_0.999375-35 nlme_3.1-96      party_0.9-9998
  [9] rpart_3.1-46     tools_2.11.1

-- 
Dave Atkins, PhD
Research Associate Professor
Department of Psychiatry and Behavioral Science
University of Washington
datkins at u.washington.edu

Center for the Study of Health and Risk Behaviors (CSHRB)		
1100 NE 45th Street, Suite 300 	
Seattle, WA  98105 	
206-616-3879 	
http://depts.washington.edu/cshrb/
(Mon-Wed)	

Center for Healthcare Improvement, for Addictions, Mental Illness,
   Medically Vulnerable Populations (CHAMMP)
325 9th Avenue, 2HH-15
Box 359911
Seattle, WA 98104
http://www.chammp.org
(Thurs)



From Paul.Thompson at sanfordhealth.org  Mon Aug 30 22:02:26 2010
From: Paul.Thompson at sanfordhealth.org (Thompson,Paul)
Date: Mon, 30 Aug 2010 15:02:26 -0500
Subject: [R-sig-ME] nlme question...
In-Reply-To: <4C7C0D6C.4060807@waikato.ac.nz>
References: <4C7BEEC2.3040401@umd.edu> <4C7C0D6C.4060807@waikato.ac.nz>
Message-ID: <4CF2646FA7AADD49A08570779F45B78D01A63462@SVMAIL6.domain.siouxvalley.local>

The model looks odd, very odd.  Are you sure that you mean "k 2K 3K"?
Don't you mean "k, k^2, k^3"?  If you really mean "k 2k 3k", you have
total collinierity.  In addition, if this is an individual growth curve
with 5 parameters, do you have 6+ obs per person?


Paul A. Thompson, Ph.D.

   

Additional contact numbers:
Cell: 618-974-0473
Fax: 605-312-6071



-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Murray
Jorgensen
Sent: Monday, August 30, 2010 2:59 PM
To: Jeffrey Harring
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] nlme question...

Maybe you could tell us more about the data and why you wish to 
associate error components with b0 and b1 parameters? It just looks like

a perfectly ordinary nonlinear model that might be fitted using the 
Gauss-Newton or partially linear methods using nls().

Murray Jorgensen

Jeffrey Harring wrote:
>  Hi all,
> 
> Can the algorithm in nlme handle a nonlinear function that is written
as 
> a design matrix and linear coefficients like the following
> 
> The model is a nonlinear growth model with five time points: y = X*b +
> e, where design matrix X is defined as
> 
> X= |  1   0  |
>    |  1   1  |
>    |  1   k  |
>    |  1  2k  |
>    |  1  3k  |
> 
> and parameter vector b = (b0, b1). And where "k" is a parameter to be
> estimated. Of course I also want to estimate the intercept (b0), slope
> (b1). Error variances (e) with 5 free parameters and random effects
> covariance matrix  (2x2: for b0 and b1).
> 
> If anyone has concrete suggestions I would love to hear from you.
> 
> Thanks for your consideration,
> Jeff
> 
> 
> 
> 


-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz    majorgensen at ihug.co.nz      Fax 7 838 4155
Phone  +64 7 838 4773 wk    Home +64 7 825 0441   Mobile 021 0200 8350

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-----------------------------------------------------------------------
Confidentiality Notice: This e-mail message, including any attachments,
is for the sole use of the intended recipient(s) and may contain
privileged and confidential information.  Any unauthorized review, use,
disclosure or distribution is prohibited.  If you are not the intended
recipient, please contact the sender by reply e-mail and destroy
all copies of the original message.




From davidD at qimr.edu.au  Mon Aug 30 23:58:23 2010
From: davidD at qimr.edu.au (David Duffy)
Date: Tue, 31 Aug 2010 07:58:23 +1000 (EST)
Subject: [R-sig-ME] rare binary outcome, MCMCglmm,
	and priors (related to separation)
In-Reply-To: <4C7C1689.3030101@u.washington.edu>
References: <4C7C1689.3030101@u.washington.edu>
Message-ID: <Pine.LNX.4.64.1008310748590.11085@orpheus.qimr.edu.au>

On Mon, 30 Aug 2010, David Atkins wrote:

>
> Some colleagues have collected data from 184 females in dating relationships. 
> Data were collected daily using PDAs; the outcome is a binary indicator of 
> whether any physical aggression occurred (intimate partner violence, or IPV).
>
> They are interested in 3 covariates:
>
> -- alcohol use: yes/no
> -- anger: rated on 1-5 scale
> -- verbal aggression: sum of handful of items, with 0-15 scale
>
> Their hypothesis is that the interaction of all 3 covariates will lead to the 
> highest likelihood of IPV.  As you might expect, the outcome is very rare 
> with 51 instances of IPV out of 8,269 days of data, and 158 women (out of 
> 184) reported no instances of IPV.
>
> I have read a bit about the problems of separation in logistic regression and 
> know that Gelman et al suggest Bayesian priors as one "solution".  Moreover, 
> I see in Jarrod Hadfield's course notes that his multinomial example has a 
> "structural" zero that he addresses via priors on pp. 96-97, though I confess 
> I don't quite follow exactly what he has done (and why).
>

Hi. why are you using a mixed model here: dispersion, or are there 
multiple reports per individual?  Another approach for separated/sparse 
data implemented in R is the penalized likelihood approach in the brlr, 
logistf, brglm (and Design) packages:

brglm(formula = cbind(ipv.yes, ipv.no) ~ (ang.cut + prov.cut +
     alc.cut)^2, family = binomial(), data = ipv)

Coefficients: (1 not defined because of singularities)
                  Estimate Std. Error z value Pr(>|z|)
(Intercept)       -8.9666     1.4145  -6.339 2.31e-10 ***
ang.cut            2.8959     1.4775   1.960  0.05000 .
prov.cut           2.3740     0.4587   5.175 2.27e-07 ***
alc.cut            7.8680     2.7082   2.905  0.00367 **
ang.cut:prov.cut       NA         NA      NA       NA
ang.cut:alc.cut   -7.0703     2.8616  -2.471  0.01348 *
prov.cut:alc.cut  -0.4007     0.9962  -0.402  0.68747

Model 1: cbind(ipv.yes, ipv.no) ~ (ang.cut + prov.cut + alc.cut)
Model 2: cbind(ipv.yes, ipv.no) ~ (ang.cut + prov.cut + alc.cut)^2
   Resid. Df Resid. Dev Df Deviance P(>|Chi|)
1         2     1.0875
2         0     1.8387  2 -0.75117

Cheers, David Duffy.
-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From datkins at u.washington.edu  Tue Aug 31 00:07:58 2010
From: datkins at u.washington.edu (David Atkins)
Date: Mon, 30 Aug 2010 15:07:58 -0700
Subject: [R-sig-ME] rare binary outcome, MCMCglmm,
 and priors (related to separation)
In-Reply-To: <Pine.LNX.4.64.1008310748590.11085@orpheus.qimr.edu.au>
References: <4C7C1689.3030101@u.washington.edu>
	<Pine.LNX.4.64.1008310748590.11085@orpheus.qimr.edu.au>
Message-ID: <4C7C2BBE.9070302@u.washington.edu>


On 8/30/10 2:58 PM, David Duffy wrote:
[snip]

>
> Hi. why are you using a mixed model here: dispersion, or are there
> multiple reports per individual?

Ack; seems like there is always something that I miss in a post - apologies!

Yes, this was a daily diary study with data collected over 60 days per 
individual (with some variability in compliance).  Thus, this is why I 
was thinking of glmer/MCMCglmm.

cheers, Dave

Another approach for separated/sparse
> data implemented in R is the penalized likelihood approach in the brlr,
> logistf, brglm (and Design) packages:
>
> brglm(formula = cbind(ipv.yes, ipv.no) ~ (ang.cut + prov.cut +
> alc.cut)^2, family = binomial(), data = ipv)
>
> Coefficients: (1 not defined because of singularities)
> Estimate Std. Error z value Pr(>|z|)
> (Intercept) -8.9666 1.4145 -6.339 2.31e-10 ***
> ang.cut 2.8959 1.4775 1.960 0.05000 .
> prov.cut 2.3740 0.4587 5.175 2.27e-07 ***
> alc.cut 7.8680 2.7082 2.905 0.00367 **
> ang.cut:prov.cut NA NA NA NA
> ang.cut:alc.cut -7.0703 2.8616 -2.471 0.01348 *
> prov.cut:alc.cut -0.4007 0.9962 -0.402 0.68747
>
> Model 1: cbind(ipv.yes, ipv.no) ~ (ang.cut + prov.cut + alc.cut)
> Model 2: cbind(ipv.yes, ipv.no) ~ (ang.cut + prov.cut + alc.cut)^2
> Resid. Df Resid. Dev Df Deviance P(>|Chi|)
> 1 2 1.0875
> 2 0 1.8387 2 -0.75117
>
> Cheers, David Duffy.



From djmuser at gmail.com  Tue Aug 31 02:00:30 2010
From: djmuser at gmail.com (Dennis Murphy)
Date: Mon, 30 Aug 2010 17:00:30 -0700
Subject: [R-sig-ME] rare binary outcome, MCMCglmm,
	and priors (related to separation)
In-Reply-To: <4C7C1689.3030101@u.washington.edu>
References: <4C7C1689.3030101@u.washington.edu>
Message-ID: <AANLkTi=-ZboaH3yJCXnS9-4myh1hSUME+ZVam6NfVSNw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100830/2be53ee7/attachment.pl>

From j.hadfield at ed.ac.uk  Tue Aug 31 11:43:27 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 31 Aug 2010 10:43:27 +0100
Subject: [R-sig-ME] rare binary outcome, MCMCglmm,
	and priors (related to separation)
In-Reply-To: <4C7C1689.3030101@u.washington.edu>
References: <4C7C1689.3030101@u.washington.edu>
Message-ID: <644BB360-FC12-49FC-97C0-19D7C7BE0C37@ed.ac.uk>

Hi Dave,

With respect to the prior specification for the fixed effects, you may  
want to make the variance larger.  Perhaps something like:

prior$B$V = diag(7)*(3+pi^2/3)

The motivation behind this is to choose a prior for b, for which  
plogis(Xb+Zu+e) would be close to a uniform after marginalising the  
random effects u and e.  pi^2/3 is the variance of the logistic  
distribution (the cdf of which is the inverse logit function) and  3  
is the variance of Zu+e assuming Z is an identity matrix (1 for the  
residual variance + ~2 for the person variance). You can see it is  
pretty close for an intercept.

priorB<-rnorm(1000, 0, sqrt(3+pi^2/3))
priorMB<-1:1000
for(i in 1:1000){
priorMB[i]<-mean(plogis(priorB[i]+rnorm(1000,0,sqrt(3))))
}
hist(priorMB)

This example works for a model with a single intercept, and when  
fitting a categorical predictor I usually remove the intercept (-1) so  
that the distribution is approximately uniform for all levels of the  
predictor. For continuous covariates and interactions it will be a bit  
more involved and you should probably read  Gelman et. al. 2008 Annals  
of Applied Statistics 1360-1383.

Using a prior with a variance of one will shrink the estimates to less  
extreme values and may explain some of the differences between models.  
However, if anything this new prior is likely to make the  mixing  
worse rather than better. Two options that may speed up mixing are  
using slice=TRUE in the call to MCMCglmm. This will use slice sampling  
to update the latent variables rather then MH updates. You could also  
use parameter expanded priors for G, but from your output it does not  
look like the variance is hitting zero so it is unlikely to improve  
things.

Cheers,

Jarrod





On 30 Aug 2010, at 21:37, David Atkins wrote:

>
> Some colleagues have collected data from 184 females in dating  
> relationships.  Data were collected daily using PDAs; the outcome is  
> a binary indicator of whether any physical aggression occurred  
> (intimate partner violence, or IPV).
>
> They are interested in 3 covariates:
>
> -- alcohol use: yes/no
> -- anger: rated on 1-5 scale
> -- verbal aggression: sum of handful of items, with 0-15 scale
>
> Their hypothesis is that the interaction of all 3 covariates will  
> lead to the highest likelihood of IPV.  As you might expect, the  
> outcome is very rare with 51 instances of IPV out of 8,269 days of  
> data, and 158 women (out of 184) reported no instances of IPV.
>
> Question 1: Given that a GLMM will assume a normal distribution for  
> the person-specific baserate in IPV, is this data even appropriate  
> for GLMM or should they be looking elsewhere (perhaps GEE)?
>
> That said, for some (unknown) proportion of individuals, there  
> probably would be instances of IPV if the data collection period  
> were longer. Thus, perhaps there is some basis for assuming a  
> distribution across people, even if the observed data for some  
> individuals are all zeroes.
>
> To present some of the data (and I can check to see if it would be  
> okay to make the data available), I dichotomized both anger and  
> verbal aggression ("prov.cut" below):
>
>  ang.cut prov.cut alc.cut ipv.yes ipv.no
> 1       0        0       0       0     3918
> 2       0        0       1       0        1
> 3       1        0       0       5     2381
> 4       1        0       1       1      292
> 5       1        1       0      36     1471
> 6       1        1       1       9      257
>
> Thus, the instances of IPV are more likely when there is anger and  
> verbal aggression; alcohol is a little less clear.  (And, if the  
> association of anger and verbal aggression with IPV seems  
> tautological, there has been debate about different forms of IPV,  
> where some research has pointed to "cold" aggression.)
>
> Not surprisingly, analyses using either glmer() or MCMCglmm() show  
> signs of partial separation, with some whopping odds-ratios and 95%  
> CI spanning a couple orders of magnitude.
>
> I have read a bit about the problems of separation in logistic  
> regression and know that Gelman et al suggest Bayesian priors as one  
> "solution".  Moreover, I see in Jarrod Hadfield's course notes that  
> his multinomial example has a "structural" zero that he addresses  
> via priors on pp. 96-97, though I confess I don't quite follow  
> exactly what he has done (and why).
>
> If I just let MCMCglmm cook on a regression with all 2-way  
> interactions for a long while:
>
> prior = list(R = list(V = 1, fix = 1),
> 			B = list(mu = c(rep(0,7)), V = diag(7)),
> 			G = list(G1 = list(V = 1, nu = 0.002)))
> lr.mcmc <- MCMCglmm(ipv ~ (alc.cut + angc + log(provc + 0.03))^2,  
> data = ipv.df,
> 					family = "categorical", verbose = TRUE,
> 					prior = prior,
> 					nitt = 2000000, burnin = 1000000, thin = 1000,
> 					random =  ~ person)
>
> The answers are less extreme than what I get with glmer, perhaps  
> suggesting this is wandering toward the "correct" solution, though  
> there are also plenty of indicators that we aren't there yet:
>
> > summary(lr.mcmc)
>
> Iterations = 1999001
> Thinning interval  = 1000001
> Sample size  = 1000
>
> DIC: 379.972
>
> G-structure:  ~person
>
>       post.mean l-95% CI u-95% CI eff.samp
> person     2.287   0.6775    4.206    194.0
>
> R-structure:  ~units
>
>      post.mean l-95% CI u-95% CI eff.samp
> units         1        1        1        0
>
> Location effects: ipv ~ (alc.cut + angc + log(provc + 0.03))^2
>
>                          post.mean l-95% CI u-95% CI eff.samp  pMCMC
> (Intercept)                -2.58724 -3.49492 -1.65250   245.20  
> <0.001 ***
> alc.cut                     0.49512 -0.75268  1.99397  1000.00  0.464
> angc                        0.02664 -0.34227  0.41365   283.90  0.880
> log(provc + 0.03)           1.36626  0.98743  1.70863    28.69  
> <0.001 ***
> alc.cut:angc               -0.16519 -0.79299  0.41949   683.56  0.590
> alc.cut:log(provc + 0.03)  -0.02631 -0.53118  0.55065   157.34  0.898
> angc:log(provc + 0.03)     -0.26132 -0.40141 -0.10407    74.98   
> 0.004 **
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> I haven't run multiple chains yet, but the effective sample sizes  
> and trace plots already suggest we ain't there yet.  My specific  
> question is whether there would be an alternative prior  
> specification for the fixed-effects that would be more appropriate?
>
> I would appreciate any and all thoughts here, including if this just  
> doesn't seem like an appropriate data/question for GLMMs.
>
> sessionInfo below.
>
> cheers, Dave
>
> > sessionInfo()
> R version 2.11.1 (2010-05-31)
> i386-apple-darwin9.8.0
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats4    splines   stats     graphics  grDevices utils      
> datasets
> [8] methods   base
>
> other attached packages:
> [1] MCMCglmm_2.06      corpcor_1.5.7      ape_2.5-3
> [4] coda_0.13-5        Matrix_0.999375-44 lattice_0.19-10
> [7] tensorA_0.35       Hmisc_3.8-2        modeltools_0.2-16
> [10] mvtnorm_0.9-92     survival_2.36-1
>
> loaded via a namespace (and not attached):
> [1] cluster_1.13.1   coin_1.0-16      colorspace_1.0-1 gee_4.13-15
> [5] grid_2.11.1      lme4_0.999375-35 nlme_3.1-96      party_0.9-9998
> [9] rpart_3.1-46     tools_2.11.1
>
> -- 
> Dave Atkins, PhD
> Research Associate Professor
> Department of Psychiatry and Behavioral Science
> University of Washington
> datkins at u.washington.edu
>
> Center for the Study of Health and Risk Behaviors (CSHRB)		
> 1100 NE 45th Street, Suite 300 	
> Seattle, WA  98105 	
> 206-616-3879 	
> http://depts.washington.edu/cshrb/
> (Mon-Wed)	
>
> Center for Healthcare Improvement, for Addictions, Mental Illness,
>  Medically Vulnerable Populations (CHAMMP)
> 325 9th Avenue, 2HH-15
> Box 359911
> Seattle, WA 98104
> http://www.chammp.org
> (Thurs)
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From selling83 at me.com  Tue Aug 31 16:18:04 2010
From: selling83 at me.com (selling83 at me.com)
Date: Tue, 31 Aug 2010 15:18:04 +0100
Subject: [R-sig-ME] ROC plots and predictions with glmm?
Message-ID: <85614903-5C4A-45AA-B1F7-A81417268A22@me.com>

Dear List,

I am new to GLMM's and am trying to understand if a workflow i have used previously with GLM's will transfer to lmer.

I have a binary response variable - TRUE / FALSE and a series of 6 categorical factors with one interaction, and two random variables which account for phylogenetic structure.

I have run the model -

model1 <-  lmer(response~1+(1|ord/fam) + a*b + c + d +e + f, family=binomial) which works fine.

Now i want to use the model to predict responses and am looking to validate the model with cross validation.

Using GLM my approach was 


	get predicted values using predict()

	construct a ROC plot with ROCR or Epi.

	cross validate with cv.glm

	construct another ROC plot with cross validation lines to get a idea of variation etc.


I am thinking this is a common thing to do and people must want to do it with GLMM's? however with no predict function i don't know how this is possible?

Based on AIC criteria, the model that explains the data "best" for glm was also the best when using glmm, however i am unsure if this can justify using a glm and ignoring the random variables, even though i know they are important?

Any help would be greatly appreciated.

George



From datkins at u.washington.edu  Tue Aug 31 20:42:14 2010
From: datkins at u.washington.edu (David Atkins)
Date: Tue, 31 Aug 2010 11:42:14 -0700
Subject: [R-sig-ME] rare binary outcome, MCMCglmm,
 and priors (related to separation)
In-Reply-To: <644BB360-FC12-49FC-97C0-19D7C7BE0C37@ed.ac.uk>
References: <4C7C1689.3030101@u.washington.edu>
	<644BB360-FC12-49FC-97C0-19D7C7BE0C37@ed.ac.uk>
Message-ID: <4C7D4D06.2050507@u.washington.edu>


Jarrod--

Per usual, thanks for the input; I've got the Gelman et al. (2008) 
article and have some models running.  I'll update with what I find.

cheers, Dave

Dave Atkins, PhD
Research Associate Professor
Department of Psychiatry and Behavioral Science
University of Washington
datkins at u.washington.edu

Center for the Study of Health and Risk Behaviors (CSHRB)		
1100 NE 45th Street, Suite 300 	
Seattle, WA  98105 	
206-616-3879 	
http://depts.washington.edu/cshrb/
(Mon-Wed)	

Center for Healthcare Improvement, for Addictions, Mental Illness,
   Medically Vulnerable Populations (CHAMMP)
325 9th Avenue, 2HH-15
Box 359911
Seattle, WA 98104
http://www.chammp.org
(Thurs)

On 8/31/10 2:43 AM, Jarrod Hadfield wrote:
> Hi Dave,
>
> With respect to the prior specification for the fixed effects, you may
> want to make the variance larger. Perhaps something like:
>
> prior$B$V = diag(7)*(3+pi^2/3)
>
> The motivation behind this is to choose a prior for b, for which
> plogis(Xb+Zu+e) would be close to a uniform after marginalising the
> random effects u and e. pi^2/3 is the variance of the logistic
> distribution (the cdf of which is the inverse logit function) and 3 is
> the variance of Zu+e assuming Z is an identity matrix (1 for the
> residual variance + ~2 for the person variance). You can see it is
> pretty close for an intercept.
>
> priorB<-rnorm(1000, 0, sqrt(3+pi^2/3))
> priorMB<-1:1000
> for(i in 1:1000){
> priorMB[i]<-mean(plogis(priorB[i]+rnorm(1000,0,sqrt(3))))
> }
> hist(priorMB)
>
> This example works for a model with a single intercept, and when fitting
> a categorical predictor I usually remove the intercept (-1) so that the
> distribution is approximately uniform for all levels of the predictor.
> For continuous covariates and interactions it will be a bit more
> involved and you should probably read Gelman et. al. 2008 Annals of
> Applied Statistics 1360-1383.
>
> Using a prior with a variance of one will shrink the estimates to less
> extreme values and may explain some of the differences between models.
> However, if anything this new prior is likely to make the mixing worse
> rather than better. Two options that may speed up mixing are using
> slice=TRUE in the call to MCMCglmm. This will use slice sampling to
> update the latent variables rather then MH updates. You could also use
> parameter expanded priors for G, but from your output it does not look
> like the variance is hitting zero so it is unlikely to improve things.
>
> Cheers,
>
> Jarrod
>
>
>
>
>
> On 30 Aug 2010, at 21:37, David Atkins wrote:
>
>>
>> Some colleagues have collected data from 184 females in dating
>> relationships. Data were collected daily using PDAs; the outcome is a
>> binary indicator of whether any physical aggression occurred (intimate
>> partner violence, or IPV).
>>
>> They are interested in 3 covariates:
>>
>> -- alcohol use: yes/no
>> -- anger: rated on 1-5 scale
>> -- verbal aggression: sum of handful of items, with 0-15 scale
>>
>> Their hypothesis is that the interaction of all 3 covariates will lead
>> to the highest likelihood of IPV. As you might expect, the outcome is
>> very rare with 51 instances of IPV out of 8,269 days of data, and 158
>> women (out of 184) reported no instances of IPV.
>>
>> Question 1: Given that a GLMM will assume a normal distribution for
>> the person-specific baserate in IPV, is this data even appropriate for
>> GLMM or should they be looking elsewhere (perhaps GEE)?
>>
>> That said, for some (unknown) proportion of individuals, there
>> probably would be instances of IPV if the data collection period were
>> longer. Thus, perhaps there is some basis for assuming a distribution
>> across people, even if the observed data for some individuals are all
>> zeroes.
>>
>> To present some of the data (and I can check to see if it would be
>> okay to make the data available), I dichotomized both anger and verbal
>> aggression ("prov.cut" below):
>>
>> ang.cut prov.cut alc.cut ipv.yes ipv.no
>> 1 0 0 0 0 3918
>> 2 0 0 1 0 1
>> 3 1 0 0 5 2381
>> 4 1 0 1 1 292
>> 5 1 1 0 36 1471
>> 6 1 1 1 9 257
>>
>> Thus, the instances of IPV are more likely when there is anger and
>> verbal aggression; alcohol is a little less clear. (And, if the
>> association of anger and verbal aggression with IPV seems
>> tautological, there has been debate about different forms of IPV,
>> where some research has pointed to "cold" aggression.)
>>
>> Not surprisingly, analyses using either glmer() or MCMCglmm() show
>> signs of partial separation, with some whopping odds-ratios and 95% CI
>> spanning a couple orders of magnitude.
>>
>> I have read a bit about the problems of separation in logistic
>> regression and know that Gelman et al suggest Bayesian priors as one
>> "solution". Moreover, I see in Jarrod Hadfield's course notes that his
>> multinomial example has a "structural" zero that he addresses via
>> priors on pp. 96-97, though I confess I don't quite follow exactly
>> what he has done (and why).
>>
>> If I just let MCMCglmm cook on a regression with all 2-way
>> interactions for a long while:
>>
>> prior = list(R = list(V = 1, fix = 1),
>> B = list(mu = c(rep(0,7)), V = diag(7)),
>> G = list(G1 = list(V = 1, nu = 0.002)))
>> lr.mcmc <- MCMCglmm(ipv ~ (alc.cut + angc + log(provc + 0.03))^2, data
>> = ipv.df,
>> family = "categorical", verbose = TRUE,
>> prior = prior,
>> nitt = 2000000, burnin = 1000000, thin = 1000,
>> random = ~ person)
>>
>> The answers are less extreme than what I get with glmer, perhaps
>> suggesting this is wandering toward the "correct" solution, though
>> there are also plenty of indicators that we aren't there yet:
>>
>> > summary(lr.mcmc)
>>
>> Iterations = 1999001
>> Thinning interval = 1000001
>> Sample size = 1000
>>
>> DIC: 379.972
>>
>> G-structure: ~person
>>
>> post.mean l-95% CI u-95% CI eff.samp
>> person 2.287 0.6775 4.206 194.0
>>
>> R-structure: ~units
>>
>> post.mean l-95% CI u-95% CI eff.samp
>> units 1 1 1 0
>>
>> Location effects: ipv ~ (alc.cut + angc + log(provc + 0.03))^2
>>
>> post.mean l-95% CI u-95% CI eff.samp pMCMC
>> (Intercept) -2.58724 -3.49492 -1.65250 245.20 <0.001 ***
>> alc.cut 0.49512 -0.75268 1.99397 1000.00 0.464
>> angc 0.02664 -0.34227 0.41365 283.90 0.880
>> log(provc + 0.03) 1.36626 0.98743 1.70863 28.69 <0.001 ***
>> alc.cut:angc -0.16519 -0.79299 0.41949 683.56 0.590
>> alc.cut:log(provc + 0.03) -0.02631 -0.53118 0.55065 157.34 0.898
>> angc:log(provc + 0.03) -0.26132 -0.40141 -0.10407 74.98 0.004 **
>> ---
>> Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>> I haven't run multiple chains yet, but the effective sample sizes and
>> trace plots already suggest we ain't there yet. My specific question
>> is whether there would be an alternative prior specification for the
>> fixed-effects that would be more appropriate?
>>
>> I would appreciate any and all thoughts here, including if this just
>> doesn't seem like an appropriate data/question for GLMMs.
>>
>> sessionInfo below.
>>
>> cheers, Dave
>>
>> > sessionInfo()
>> R version 2.11.1 (2010-05-31)
>> i386-apple-darwin9.8.0
>>
>> locale:
>> [1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
>>
>> attached base packages:
>> [1] stats4 splines stats graphics grDevices utils datasets
>> [8] methods base
>>
>> other attached packages:
>> [1] MCMCglmm_2.06 corpcor_1.5.7 ape_2.5-3
>> [4] coda_0.13-5 Matrix_0.999375-44 lattice_0.19-10
>> [7] tensorA_0.35 Hmisc_3.8-2 modeltools_0.2-16
>> [10] mvtnorm_0.9-92 survival_2.36-1
>>
>> loaded via a namespace (and not attached):
>> [1] cluster_1.13.1 coin_1.0-16 colorspace_1.0-1 gee_4.13-15
>> [5] grid_2.11.1 lme4_0.999375-35 nlme_3.1-96 party_0.9-9998
>> [9] rpart_3.1-46 tools_2.11.1
>>
>> --
>> Dave Atkins, PhD
>> Research Associate Professor
>> Department of Psychiatry and Behavioral Science
>> University of Washington
>> datkins at u.washington.edu
>>
>> Center for the Study of Health and Risk Behaviors (CSHRB)
>> 1100 NE 45th Street, Suite 300
>> Seattle, WA 98105
>> 206-616-3879
>> http://depts.washington.edu/cshrb/
>> (Mon-Wed)
>>
>> Center for Healthcare Improvement, for Addictions, Mental Illness,
>> Medically Vulnerable Populations (CHAMMP)
>> 325 9th Avenue, 2HH-15
>> Box 359911
>> Seattle, WA 98104
>> http://www.chammp.org
>> (Thurs)
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>



From mikl at mikl.dk  Thu Sep  2 14:21:24 2010
From: mikl at mikl.dk (Mikkel Meyer Andersen)
Date: Thu, 2 Sep 2010 14:21:24 +0200
Subject: [R-sig-ME] [R] nlme formula from model specification
In-Reply-To: <3DB16098F738284D8DBEB2FC369916382FE12B@inboexch.inbo.be>
References: <AANLkTi=o=jM02Zm4Vq1dNoUP8ZePZyeG0SrPu34jjMbm@mail.gmail.com>
	<3DB16098F738284D8DBEB2FC369916382FE12B@inboexch.inbo.be>
Message-ID: <AANLkTiniOqwLz-7XmRpxsrQT8QmAbeja8Xoyp87CL9-y@mail.gmail.com>

Dear Thierry,

Thanks for the quick answer. I'm moving this to r-sig-mixed-models
(but also posting on r-help to notify).

I reserved "Mixed-effects models in S and S-PLUS" by Pinheiro and
Bates, New York : Springer, 2000. Do you know any other good
references?

Cheers, Mikkel.

2010/9/2 ONKELINX, Thierry <Thierry.ONKELINX at inbo.be>:
> Dear Mikkel,
>
> You need to do some reading on terminology.
>
> In your model the fixed effects are channel 1, 2 and 3. samplenumber is
> a random effect and the error term is an error term
>
> The model you described has the notation below. You do not need to
> create the grouped data structure.
>
> lme(channel0 ~ pos + samplenumber + channel1 + channel2 + channel3,
> ? random = ~ 1 | samplenumber,
> ? correlation = corAR1(value = 0.5, form = ~ pos | samplenumber),
> ? data = channel.matrix)
>
> HTH,
>
> Thierry
>
> PS There is a dedicated mailing list for mixed models:
> R-sig-mixed-models
>
> ------------------------------------------------------------------------
> ----
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek
> team Biometrie & Kwaliteitszorg
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium
>
> Research Institute for Nature and Forest
> team Biometrics & Quality Assurance
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium
>
> tel. + 32 54/436 185
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to
> say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of
> data.
> ~ John Tukey
>
>
>> -----Oorspronkelijk bericht-----
>> Van: r-help-bounces at r-project.org
>> [mailto:r-help-bounces at r-project.org] Namens Mikkel Meyer Andersen
>> Verzonden: donderdag 2 september 2010 13:30
>> Aan: r-help at r-project.org
>> Onderwerp: [R] nlme formula from model specification
>>
>> Dear R-community,
>>
>> I'm analysing some noise using the nlme-package. I'm writing
>> in order to get my usage of lme verified.
>>
>> In practise, a number of samples have been processed by a
>> machine measuring the same signal at four different channels.
>> I want to model the noise. I have taken the noise (the signal
>> is from position 1 to 3500, and after that there is only noise).
>>
>> My data looks like this:
>> channel.matrix:
>> ? ? ? pos channel0 channel1 channel2 channel3 samplenumber
>> ? ?1 3501 ? ? ? ?8 ? ? ? ?3 ? ? ? 12 ? ? ? ?1 ? ? ? ? ? ?1
>> ? ?2 3502 ? ? ? ?3 ? ? ? ?7 ? ? ? ?0 ? ? ? 14 ? ? ? ? ? ?1
>> ? ?3 3503 ? ? ? ?9 ? ? ? ?1 ? ? ? 13 ? ? ? ?3 ? ? ? ? ? ?1
>> ? ?4 3504 ? ? ? ?3 ? ? ? ?7 ? ? ? ?3 ? ? ? 14 ? ? ? ? ? ?1
>> ? ?5 3505 ? ? ? ?6 ? ? ? ?5 ? ? ? ?4 ? ? ? ?5 ? ? ? ? ? ?1
>> ? ?6 3506 ? ? ? ?7 ? ? ? ?0 ? ? ? 16 ? ? ? ?0 ? ? ? ? ? ?1
>> ...
>> ?495 3995 ? ? ? ?5 ? ? ? ?2 ? ? ? ?9 ? ? ? ?9 ? ? ? ? ? ?1
>> ?496 3996 ? ? ? ?2 ? ? ? ?4 ? ? ? ?6 ? ? ? 10 ? ? ? ? ? ?1
>> ?497 3997 ? ? ? ?3 ? ? ? ?2 ? ? ? ?7 ? ? ? ?7 ? ? ? ? ? ?1
>> ?498 3998 ? ? ? ?2 ? ? ? ?4 ? ? ? ?3 ? ? ? ?9 ? ? ? ? ? ?1
>> ?499 3999 ? ? ? ?3 ? ? ? ?1 ? ? ? ?6 ? ? ? 11 ? ? ? ? ? ?1
>> ?500 4000 ? ? ? ?0 ? ? ? ?3 ? ? ? ?6 ? ? ? ?7 ? ? ? ? ? ?1
>> 2301 3501 ? ? ? ?1 ? ? ? ?4 ? ? ? ?3 ? ? ? ?9 ? ? ? ? ? ?2
>> 2302 3502 ? ? ? ?3 ? ? ? ?3 ? ? ? ?4 ? ? ? 13 ? ? ? ? ? ?2
>> 2303 3503 ? ? ? ?4 ? ? ? ?1 ? ? ? ?8 ? ? ? ?5 ? ? ? ? ? ?2
>> 2304 3504 ? ? ? ?3 ? ? ? ?1 ? ? ? 10 ? ? ? ?2 ? ? ? ? ? ?2
>> 2305 3505 ? ? ? ?2 ? ? ? ?3 ? ? ? ?5 ? ? ? ?8 ? ? ? ? ? ?2
>> 2306 3506 ? ? ? ?0 ? ? ? ?5 ? ? ? ?8 ? ? ? ?2 ? ? ? ? ? ?2
>> ...
>>
>> The model is
>> channel0 ~ alpha_i + eps_{i, j} + channel1 + channel2 +
>> channel3 where i is sample number, j is position, and:
>> ? alpha_i: ? ? ? ? ? ? ? ? fixed effect for each samplenumber
>> ? eps_{i, j}: ? ? ? ? ? ? ?random effect, here with correlation
>> structure as AR(1)
>> ? channel1, ..., channel3: fixed effect for each channel not
>> depending on
>> ? ? ? ? ? ? ? ? ? ? ? ? ? ?samplenumber nor position
>>
>> (And then afterwards I would model channel1 ~ ... + channel2
>> + channel3 etc.)
>>
>> I then use this function call:
>> channel.matrix.grouped <- groupedData(channel0 ~ pos | samplenumber,
>> ? data = channel.matrix)
>>
>> fit <- lme(channel0 ~ pos + samplenumber + channel1 +
>> channel2 + channel3,
>> ? random = ~ pos | samplenumber,
>> ? correlation = corAR1(value = 0.5, form = ~ pos | samplenumber),
>> ? data = channel.matrix.grouped)
>>
>> Is that the right way to express the model in (n)lme-notation?
>>
>> Cheers, Mikkel.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> Druk dit bericht a.u.b. niet onnodig af.
> Please do not print this message unnecessarily.
>
> Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer
> en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
> door een geldig ondertekend document. The views expressed in ?this message
> and any annex are purely those of the writer and may not be regarded as stating
> an official position of INBO, as long as the message is not confirmed by a duly
> signed document.
>



From Thierry.ONKELINX at inbo.be  Thu Sep  2 17:04:34 2010
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 2 Sep 2010 17:04:34 +0200
Subject: [R-sig-ME] [R] nlme formula from model specification
In-Reply-To: <AANLkTiniOqwLz-7XmRpxsrQT8QmAbeja8Xoyp87CL9-y@mail.gmail.com>
References: <AANLkTi=o=jM02Zm4Vq1dNoUP8ZePZyeG0SrPu34jjMbm@mail.gmail.com>
	<3DB16098F738284D8DBEB2FC369916382FE12B@inboexch.inbo.be>
	<AANLkTiniOqwLz-7XmRpxsrQT8QmAbeja8Xoyp87CL9-y@mail.gmail.com>
Message-ID: <3DB16098F738284D8DBEB2FC369916382FE1CD@inboexch.inbo.be>

Dear Mikkel,

I really liked Zuur et al (2009). It requires less mathematical skills to read than Pinheiro and Bates.

@BOOK{ZuurMixedModels,
  title = {Mixed Effects Models and Extensions in Ecology with R},
  publisher = {Springer New York},
  year = {2009},
  author = {Zuur, Alain F. and Ieno, Elena N. and Walker, Neil J. and Saveliev,
	Anatoly A. and Smith, Graham M.},
  doi = {10.1007/978-0-387-87458-6},
  owner = {thierry_onkelinx},
  timestamp = {2009.11.30}
}

Best regards,

Thierry

----------------------------------------------------------------------------
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
  

> -----Oorspronkelijk bericht-----
> Van: Mikkel Meyer Andersen [mailto:mikl at mikl.dk] 
> Verzonden: donderdag 2 september 2010 14:21
> Aan: ONKELINX, Thierry
> CC: r-help at r-project.org; r-sig-mixed-models at r-project.org
> Onderwerp: Re: [R] nlme formula from model specification
> 
> Dear Thierry,
> 
> Thanks for the quick answer. I'm moving this to 
> r-sig-mixed-models (but also posting on r-help to notify).
> 
> I reserved "Mixed-effects models in S and S-PLUS" by Pinheiro 
> and Bates, New York : Springer, 2000. Do you know any other 
> good references?
> 
> Cheers, Mikkel.
> 
> 2010/9/2 ONKELINX, Thierry <Thierry.ONKELINX at inbo.be>:
> > Dear Mikkel,
> >
> > You need to do some reading on terminology.
> >
> > In your model the fixed effects are channel 1, 2 and 3. 
> samplenumber 
> > is a random effect and the error term is an error term
> >
> > The model you described has the notation below. You do not need to 
> > create the grouped data structure.
> >
> > lme(channel0 ~ pos + samplenumber + channel1 + channel2 + channel3,
> > ? random = ~ 1 | samplenumber,
> > ? correlation = corAR1(value = 0.5, form = ~ pos | samplenumber),
> > ? data = channel.matrix)
> >
> > HTH,
> >
> > Thierry
> >
> > PS There is a dedicated mailing list for mixed models:
> > R-sig-mixed-models
> >
> > 
> ----------------------------------------------------------------------
> > --
> > ----
> > ir. Thierry Onkelinx
> > Instituut voor natuur- en bosonderzoek team Biometrie & 
> Kwaliteitszorg 
> > Gaverstraat 4 9500 Geraardsbergen Belgium
> >
> > Research Institute for Nature and Forest team Biometrics & Quality 
> > Assurance Gaverstraat 4 9500 Geraardsbergen Belgium
> >
> > tel. + 32 54/436 185
> > Thierry.Onkelinx at inbo.be
> > www.inbo.be
> >
> > To call in the statistician after the experiment is done may be no 
> > more than asking him to perform a post-mortem examination: 
> he may be 
> > able to say what the experiment died of.
> > ~ Sir Ronald Aylmer Fisher
> >
> > The plural of anecdote is not data.
> > ~ Roger Brinner
> >
> > The combination of some data and an aching desire for an 
> answer does 
> > not ensure that a reasonable answer can be extracted from a 
> given body 
> > of data.
> > ~ John Tukey
> >
> >
> >> -----Oorspronkelijk bericht-----
> >> Van: r-help-bounces at r-project.org
> >> [mailto:r-help-bounces at r-project.org] Namens Mikkel Meyer Andersen
> >> Verzonden: donderdag 2 september 2010 13:30
> >> Aan: r-help at r-project.org
> >> Onderwerp: [R] nlme formula from model specification
> >>
> >> Dear R-community,
> >>
> >> I'm analysing some noise using the nlme-package. I'm 
> writing in order 
> >> to get my usage of lme verified.
> >>
> >> In practise, a number of samples have been processed by a machine 
> >> measuring the same signal at four different channels.
> >> I want to model the noise. I have taken the noise (the 
> signal is from 
> >> position 1 to 3500, and after that there is only noise).
> >>
> >> My data looks like this:
> >> channel.matrix:
> >> ? ? ? pos channel0 channel1 channel2 channel3 samplenumber
> >> ? ?1 3501 ? ? ? ?8 ? ? ? ?3 ? ? ? 12 ? ? ? ?1 ? ? ? ? ? ?1
> >> ? ?2 3502 ? ? ? ?3 ? ? ? ?7 ? ? ? ?0 ? ? ? 14 ? ? ? ? ? ?1
> >> ? ?3 3503 ? ? ? ?9 ? ? ? ?1 ? ? ? 13 ? ? ? ?3 ? ? ? ? ? ?1
> >> ? ?4 3504 ? ? ? ?3 ? ? ? ?7 ? ? ? ?3 ? ? ? 14 ? ? ? ? ? ?1
> >> ? ?5 3505 ? ? ? ?6 ? ? ? ?5 ? ? ? ?4 ? ? ? ?5 ? ? ? ? ? ?1
> >> ? ?6 3506 ? ? ? ?7 ? ? ? ?0 ? ? ? 16 ? ? ? ?0 ? ? ? ? ? ?1 ...
> >> ?495 3995 ? ? ? ?5 ? ? ? ?2 ? ? ? ?9 ? ? ? ?9 ? ? ? ? ? ?1
> >> ?496 3996 ? ? ? ?2 ? ? ? ?4 ? ? ? ?6 ? ? ? 10 ? ? ? ? ? ?1
> >> ?497 3997 ? ? ? ?3 ? ? ? ?2 ? ? ? ?7 ? ? ? ?7 ? ? ? ? ? ?1
> >> ?498 3998 ? ? ? ?2 ? ? ? ?4 ? ? ? ?3 ? ? ? ?9 ? ? ? ? ? ?1
> >> ?499 3999 ? ? ? ?3 ? ? ? ?1 ? ? ? ?6 ? ? ? 11 ? ? ? ? ? ?1
> >> ?500 4000 ? ? ? ?0 ? ? ? ?3 ? ? ? ?6 ? ? ? ?7 ? ? ? ? ? ?1
> >> 2301 3501 ? ? ? ?1 ? ? ? ?4 ? ? ? ?3 ? ? ? ?9 ? ? ? ? ? ?2
> >> 2302 3502 ? ? ? ?3 ? ? ? ?3 ? ? ? ?4 ? ? ? 13 ? ? ? ? ? ?2
> >> 2303 3503 ? ? ? ?4 ? ? ? ?1 ? ? ? ?8 ? ? ? ?5 ? ? ? ? ? ?2
> >> 2304 3504 ? ? ? ?3 ? ? ? ?1 ? ? ? 10 ? ? ? ?2 ? ? ? ? ? ?2
> >> 2305 3505 ? ? ? ?2 ? ? ? ?3 ? ? ? ?5 ? ? ? ?8 ? ? ? ? ? ?2
> >> 2306 3506 ? ? ? ?0 ? ? ? ?5 ? ? ? ?8 ? ? ? ?2 ? ? ? ? ? ?2 ...
> >>
> >> The model is
> >> channel0 ~ alpha_i + eps_{i, j} + channel1 + channel2 +
> >> channel3 where i is sample number, j is position, and:
> >> ? alpha_i: ? ? ? ? ? ? ? ? fixed effect for each samplenumber
> >> ? eps_{i, j}: ? ? ? ? ? ? ?random effect, here with correlation 
> >> structure as AR(1)
> >> ? channel1, ..., channel3: fixed effect for each channel not 
> >> depending on
> >> ? ? ? ? ? ? ? ? ? ? ? ? ? ?samplenumber nor position
> >>
> >> (And then afterwards I would model channel1 ~ ... + channel2
> >> + channel3 etc.)
> >>
> >> I then use this function call:
> >> channel.matrix.grouped <- groupedData(channel0 ~ pos |
> samplenumber,
> >> ? data = channel.matrix)
> >>
> >> fit <- lme(channel0 ~ pos + samplenumber + channel1 +
> >> channel2 + channel3,
> >> ? random = ~ pos | samplenumber,
> >> ? correlation = corAR1(value = 0.5, form = ~ pos | samplenumber),
> >> ? data = channel.matrix.grouped)
> >>
> >> Is that the right way to express the model in (n)lme-notation?
> >>
> >> Cheers, Mikkel.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> > Druk dit bericht a.u.b. niet onnodig af.
> > Please do not print this message unnecessarily.
> >
> > Dit bericht en eventuele bijlagen geven enkel de visie van de 
> > schrijver weer en binden het INBO onder geen enkel beding, 
> zolang dit 
> > bericht niet bevestigd is door een geldig ondertekend document. The 
> > views expressed in ?this message and any annex are purely 
> those of the 
> > writer and may not be regarded as stating an official position of 
> > INBO, as long as the message is not confirmed by a duly 
> signed document.
> >
> 

Druk dit bericht a.u.b. niet onnodig af.
Please do not print this message unnecessarily.

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From arrayprofile at yahoo.com  Fri Sep  3 09:26:24 2010
From: arrayprofile at yahoo.com (array chip)
Date: Fri, 3 Sep 2010 00:26:24 -0700 (PDT)
Subject: [R-sig-ME] longitudinal study with baseline
Message-ID: <189325.62646.qm@web56302.mail.re3.yahoo.com>

Hi all,

I asked some questions on how to analyze?longitudinal study with only 2 time 
points (baseline and a follow-up) previously. I appreciate?many useful comments 
from some members, especially Dennis Murphy?who refered the following paper 
addressing specifically this type of study with only 2 time points: 
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1121605/

Basically, with only 2 time points (baseline and one follow-up), ANCOVA with 
follow-up as dependent variable and baseline as covariate should be used:

follow-up?= a + b*baseline + treatment

Now I have a regular longitudinal study with 6 time points, 7 treatments 
(vehicle, A, B, C, D, F, G), measuring a response variable "y". The dataset is 
attached. I have some questions, and appreciate any suggestions on how to 
analyze the dataset.

dat<-read.table("dat.txt",sep='\t',header=T,row.names=NULL)
library(MASS)
dat$trt<-relevel(dat$trt,'vehicle')

xyplot(y~time, groups=trt, data=dat, 
ylim=c(3,10),col=c(1:6,8),lwd=2,type=c('g','a'),xlab='Days',ylab="response",
?key = list(lines=list(col=c(1:6,8),lty=1,lwd=2),
????????????????? text = list(lab = levels(dat$trt)),
????????????????? columns = 3, title = "Treatment"))

So as you can see that there is some curvature between glucose level and time, 
so a quadratic fit might be needed. 


dat$time2<-dat$time*dat$time

A straight fit like below seems reasonable:

fit<-lmer(y~trt*time+trt*time2+(time|id),dat)

Checking on random effects, it appears that variance component for random slope 
is very small, so?a simpler model with?random intercept only may be sufficient:

fit<-lmer(y~trt*time+trt*time2+(1|id),dat)

Now, I want to incorporate baseline?response into the model in order to account 
for any baseline imbalance. I need to generate a new variable "baseline" based 
on glucose levels at time=0:

dat<-merge(dat, dat[dat$time==0,c('id','y')], by.x='id',by.y='id',all.x=T)
colnames(dat)[c(4,6)]<-c('y','baseline')

so the new fit adding baseline into the mixed model is:

fit<-lmer(y~baseline+trt*time+trt*time2+(1|id),dat)

Now my question is 1). Is the above model a reasonable thing to do? 2) when 
baseline is included as a covariate, should I remove the data points at baseline 
from the dataset? I am kind of unsure if it's reasonable to use the baseline 
both as a covariate and as part of the dependent variable values.

Next thing I want to do with this dataset is to do multiple comparisons between 
each treatment (A, B, C, D, F, G) vs. vehicle at a given time point, say time=56 
(the last time points) after adjusting the baseline imbalance. This seems to be 
done using Dunnet test. When I say "after adjusting baseline imbalance", I mean 
the comparisons?should be?done based on the difference between time=56 and 
time=0 (baseline). How can we test this? Will glht() in multcomp work for a lmer 
fit? If yes, how can I specify the syntax?

Finally, with the above model, is there anyway to estimate the difference (and 
the standard error) between time=56 and time=0 (baseline) for each treatment 
groups?

Thank you fall or your attention.

John


      
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: dat.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100903/700fb364/attachment.txt>

From arrayprofile at yahoo.com  Fri Sep  3 18:30:50 2010
From: arrayprofile at yahoo.com (array chip)
Date: Fri, 3 Sep 2010 09:30:50 -0700 (PDT)
Subject: [R-sig-ME] longitudinal study with baseline
In-Reply-To: <189325.62646.qm@web56302.mail.re3.yahoo.com>
References: <189325.62646.qm@web56302.mail.re3.yahoo.com>
Message-ID: <300050.42040.qm@web56302.mail.re3.yahoo.com>

Hi all, I just realized that actually it is Marc Schwartz who referred the 
baseline handling paper to me. I am sorry for the error. Both Marc and Dennis 
have been tremendous help in my previous discussion. I would appreciate very 
much if anyone can share their thoughts on this one. Also realized the data file 
"dat.txt" should have the column titled "glucose" as "y" instead to use my code 
below.

Thanks you all.

John



----- Original Message ----
From: array chip <arrayprofile at yahoo.com>
To: r-sig-mixed-models at r-project.org
Sent: Fri, September 3, 2010 12:26:24 AM
Subject: [R-sig-ME] longitudinal study with baseline

Hi all,

I asked some questions on how to analyze longitudinal study with only 2 time 
points (baseline and a follow-up) previously. I appreciate many useful comments 
from some members, especially Dennis Murphy who refered the following paper 
addressing specifically this type of study with only 2 time points: 
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1121605/

Basically, with only 2 time points (baseline and one follow-up), ANCOVA with 
follow-up as dependent variable and baseline as covariate should be used:

follow-up = a + b*baseline + treatment

Now I have a regular longitudinal study with 6 time points, 7 treatments 
(vehicle, A, B, C, D, F, G), measuring a response variable "y". The dataset is 
attached. I have some questions, and appreciate any suggestions on how to 
analyze the dataset.

dat<-read.table("dat.txt",sep='\t',header=T,row.names=NULL)
library(MASS)
dat$trt<-relevel(dat$trt,'vehicle')

xyplot(y~time, groups=trt, data=dat, 
ylim=c(3,10),col=c(1:6,8),lwd=2,type=c('g','a'),xlab='Days',ylab="response",
 key = list(lines=list(col=c(1:6,8),lty=1,lwd=2),
                  text = list(lab = levels(dat$trt)),
                  columns = 3, title = "Treatment"))

So as you can see that there is some curvature between glucose level and time, 
so a quadratic fit might be needed. 


dat$time2<-dat$time*dat$time

A straight fit like below seems reasonable:

fit<-lmer(y~trt*time+trt*time2+(time|id),dat)

Checking on random effects, it appears that variance component for random slope 
is very small, so a simpler model with random intercept only may be sufficient:

fit<-lmer(y~trt*time+trt*time2+(1|id),dat)

Now, I want to incorporate baseline response into the model in order to account 
for any baseline imbalance. I need to generate a new variable "baseline" based 
on glucose levels at time=0:

dat<-merge(dat, dat[dat$time==0,c('id','y')], by.x='id',by.y='id',all.x=T)
colnames(dat)[c(4,6)]<-c('y','baseline')

so the new fit adding baseline into the mixed model is:

fit<-lmer(y~baseline+trt*time+trt*time2+(1|id),dat)

Now my question is 1). Is the above model a reasonable thing to do? 2) when 
baseline is included as a covariate, should I remove the data points at baseline 

from the dataset? I am kind of unsure if it's reasonable to use the baseline 
both as a covariate and as part of the dependent variable values.

Next thing I want to do with this dataset is to do multiple comparisons between 
each treatment (A, B, C, D, F, G) vs. vehicle at a given time point, say time=56 

(the last time points) after adjusting the baseline imbalance. This seems to be 
done using Dunnet test. When I say "after adjusting baseline imbalance", I mean 
the comparisons should be done based on the difference between time=56 and 
time=0 (baseline). How can we test this? Will glht() in multcomp work for a lmer 

fit? If yes, how can I specify the syntax?

Finally, with the above model, is there anyway to estimate the difference (and 
the standard error) between time=56 and time=0 (baseline) for each treatment 
groups?

Thank you fall or your attention.

John



From ned.dochtermann at gmail.com  Sat Sep  4 00:44:40 2010
From: ned.dochtermann at gmail.com (Ned Dochtermann)
Date: Fri, 3 Sep 2010 15:44:40 -0700
Subject: [R-sig-ME] MCMCglmm: Within- versus between-individual covariances
In-Reply-To: <mailman.2714.1283498808.4229.r-sig-mixed-models@r-project.org>
References: <mailman.2714.1283498808.4229.r-sig-mixed-models@r-project.org>
Message-ID: <4c817a5b.014a640a.77fb.78d4@mx.google.com>

I tried to find an answer to this problem but either failed to select the
proper search terms or this topic hasn't been discussed. I apologize if the
former. I've also consulted the "class notes" for MCMCglmm but that hasn't
clarified the issue for me.

I am currently working on the analysis of some repeated measures behavioural
data and am attempting to estimate variances and covariances among
behaviours. Specifically we're looking to estimate the between-individual
(co)variance matrix and I was using a multi-response model and the Poisson
family in MCMCglmm to do so.

I had thought that the posterior modes for the (co)variance matrix (i.e.
posterior.modes(model$VCV)) was producing this on the latent scale, with the
".ID" terms being the between individual (co)variances and the ".unit" terms
being the within/residual indvidual (co)variances. This conclusion was based
on Jarrod Hadfield's appendix to the recent animal model paper published in
the Journal of Animal Ecology (2009). In the appendix discussing MCMCglmm
for repeated measures, repeatability is calculated using the .ID variance as
the between individual component and the .unit variance as the within
individual component.

The problem I've encountered is that due to the experimental design certain
aspects of the within individual covariance matrix should not be
estimatable, but estimates are nonetheless reported. This is, of course, due
to my misspecification of the model. 

To use an example provided by a colleague, consider a situation where three
distinct behaviours are measured and we're interested in their covariance.
Due to aspects of the experimental manipulation all the behaviours cannot be
measured on the same days. Thus the data might look something like:

ID	Day	Behav1	Behav2	Behav3
1	1	4		NA		10
1	2	3		NA		15
1	3	NA		5		NA
1	4	NA		4		NA
2	1	2		NA		12
2	2	1		NA		18
2	3	NA		4		NA
2	4	NA		3		NA
...		
N	1	6		NA		8
N	2	5		NA		6
N	3	NA		8		NA
N	4	NA		7		NA
[[note, I know these fictitious data aren't necessarily Poisson distributed
but the actual data are]]

In this case between individual variances and covariances can be calculated
among all three behaviours and within individual covariances should be
calculated between Behav1 and Behav3 but not for Behav2 with either 1 or 3
due to separation.

In attempting the initial analyses I specified the random statement using an
unstructured matrix:
>random=~us(trait):ID
(I'm pretty sure that's what I want and what produces the between individual
covariance matrix)

I also kept the residual covariance matrix as the default unstructured:
>rcov=~us(trait):units

However, if the within-individual/residual covariances really shouldn't be
calculated between Behav2 and the other two responses, rcov should actually
look something like:

v.B1		0		cov.B1*3
0		v.B2		0
cov.B1*3	0		v.B3

For this example "~us" is thus estimating two extra parameters that
shouldn't be estimated (for the actual dataset these elements have
credibility intervals overlapping 0).

Clearly idh wouldn't be appropriate for this either but none of the options
listed in Table 3.1 of the Class Notes for MCMCglmm seem correct. It also
doesn't look like I can specify the matrix structure directly (which is how
my colleague dealt with this concern using ASreml and which I know SAS
allows for regular mixed models).

Is there any advice on how best to deal with this issue? I'm at a loss.

Thanks a lot,
Ned Dochtermann


--
Ned Dochtermann
Department of Biology
University of Nevada, Reno

ned.dochtermann at gmail.com
http://wolfweb.unr.edu/homepage/mpeacock/Dochter/
--



From j.hadfield at ed.ac.uk  Sun Sep  5 18:53:08 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sun, 05 Sep 2010 17:53:08 +0100
Subject: [R-sig-ME] MCMCglmm: Within- versus
	between-individual	covariances
In-Reply-To: <4c817a5b.014a640a.77fb.78d4@mx.google.com>
References: <mailman.2714.1283498808.4229.r-sig-mixed-models@r-project.org>
	<4c817a5b.014a640a.77fb.78d4@mx.google.com>
Message-ID: <20100905175308.kmfn04hqg48g8gss@www.staffmail.ed.ac.uk>

Hi Ned,

Currently it is not possible to specify covariance matrices with  
arbitrary covariances set to zero. If you can reorder the terms so  
that the covariance matrix has a block structure (eg swap trait 2 and  
3 in your example) then you can fit this is in the random terms.  
However, the residual term can only be specified by a single term so  
this is not possible. You can still run the model with a us structure  
of course, but as you are aware the posterior distribution for the  
non-identified covariances will simply be the prior distribution.

Cheers,

Jarrod

Quoting Ned Dochtermann <ned.dochtermann at gmail.com>:

> I tried to find an answer to this problem but either failed to select the
> proper search terms or this topic hasn't been discussed. I apologize if the
> former. I've also consulted the "class notes" for MCMCglmm but that hasn't
> clarified the issue for me.
>
> I am currently working on the analysis of some repeated measures behavioural
> data and am attempting to estimate variances and covariances among
> behaviours. Specifically we're looking to estimate the between-individual
> (co)variance matrix and I was using a multi-response model and the Poisson
> family in MCMCglmm to do so.
>
> I had thought that the posterior modes for the (co)variance matrix (i.e.
> posterior.modes(model$VCV)) was producing this on the latent scale, with the
> ".ID" terms being the between individual (co)variances and the ".unit" terms
> being the within/residual indvidual (co)variances. This conclusion was based
> on Jarrod Hadfield's appendix to the recent animal model paper published in
> the Journal of Animal Ecology (2009). In the appendix discussing MCMCglmm
> for repeated measures, repeatability is calculated using the .ID variance as
> the between individual component and the .unit variance as the within
> individual component.
>
> The problem I've encountered is that due to the experimental design certain
> aspects of the within individual covariance matrix should not be
> estimatable, but estimates are nonetheless reported. This is, of course, due
> to my misspecification of the model.
>
> To use an example provided by a colleague, consider a situation where three
> distinct behaviours are measured and we're interested in their covariance.
> Due to aspects of the experimental manipulation all the behaviours cannot be
> measured on the same days. Thus the data might look something like:
>
> ID	Day	Behav1	Behav2	Behav3
> 1	1	4		NA		10
> 1	2	3		NA		15
> 1	3	NA		5		NA
> 1	4	NA		4		NA
> 2	1	2		NA		12
> 2	2	1		NA		18
> 2	3	NA		4		NA
> 2	4	NA		3		NA
> ...
> N	1	6		NA		8
> N	2	5		NA		6
> N	3	NA		8		NA
> N	4	NA		7		NA
> [[note, I know these fictitious data aren't necessarily Poisson distributed
> but the actual data are]]
>
> In this case between individual variances and covariances can be calculated
> among all three behaviours and within individual covariances should be
> calculated between Behav1 and Behav3 but not for Behav2 with either 1 or 3
> due to separation.
>
> In attempting the initial analyses I specified the random statement using an
> unstructured matrix:
>> random=~us(trait):ID
> (I'm pretty sure that's what I want and what produces the between individual
> covariance matrix)
>
> I also kept the residual covariance matrix as the default unstructured:
>> rcov=~us(trait):units
>
> However, if the within-individual/residual covariances really shouldn't be
> calculated between Behav2 and the other two responses, rcov should actually
> look something like:
>
> v.B1		0		cov.B1*3
> 0		v.B2		0
> cov.B1*3	0		v.B3
>
> For this example "~us" is thus estimating two extra parameters that
> shouldn't be estimated (for the actual dataset these elements have
> credibility intervals overlapping 0).
>
> Clearly idh wouldn't be appropriate for this either but none of the options
> listed in Table 3.1 of the Class Notes for MCMCglmm seem correct. It also
> doesn't look like I can specify the matrix structure directly (which is how
> my colleague dealt with this concern using ASreml and which I know SAS
> allows for regular mixed models).
>
> Is there any advice on how best to deal with this issue? I'm at a loss.
>
> Thanks a lot,
> Ned Dochtermann
>
>
> --
> Ned Dochtermann
> Department of Biology
> University of Nevada, Reno
>
> ned.dochtermann at gmail.com
> http://wolfweb.unr.edu/homepage/mpeacock/Dochter/
> --
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From Mike.Lawrence at dal.ca  Mon Sep  6 02:02:38 2010
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Sun, 5 Sep 2010 21:02:38 -0300
Subject: [R-sig-ME] submitted for list review: ezBuildME()
Message-ID: <AANLkTi=QGVWc087Kkbv_Pg=SO1jKfpN8=tm80DgDxO5e@mail.gmail.com>

Hi folks,

Hot on the heels of my release of ez v2.0 last week, I have version
2.1 nearly ready to go. Amongst minor bug fixes, I'm toying with
adding a function to automate the process of building up a mixed
effects model for very simple designs: one random effect (participants
in an experiment) and any number of factorized fixed effects. I
imagine this being used in factorial experiments where people have a
priori interest in all main effects and interactions between the fixed
effects, so this automates the process of building and comparing all
pertinent models.

As a neophyte to mixed effects modelling, I thought I'd check with the
list that the function's operation makes sense
statistically/philosophically. The code & documentation are
downloadable here (you'll need to load the plyr and lme4 packages to
use it):

http://rfecs.me/wp-content/uploads/2010/09/ezBuildME.zip

And here's a brief description of the operation:

This function is used to compute sequential comparisons of nested
mixed effects models, testing each possible effect against a model
that contains all effects at levels of interaction lower than that
effect. For example:

- a test of a main effect of a predictor compares a model containing
the main effect of the predictor plus the random effect (specified by
\code{wid}) against a model containing simply the random effect. eg:
    dv ~ v1 + (1|wid)
        versus
    dv ~ (1|wid)

- a test of a 2-way interaction compares a model containing the 2-way
interaction plus the main effects of all predictors plus the random
effect against a model with just the main effects and the random
effect. eg:
    dv ~ v1:v2 + v1 + v2 + v3 + (1|wid)
        versus
    dv ~ v1 + v2 + v3 + (1|wid)

- a test of a 3-way interaction compares a model containing the 3-way
interaction plus all 2-way interactions plus all main effects plus the
random effect against a model with all 2-way effects, all main
effects, and the random effect. eg:
    dv ~ v1:v2:v3 + v1:v2 + v1:v3 + v2:v3 + v1 + v2 + v3 + (1|wid)
        versus
    dv ~  v1:v2 + v1:v3 + v2:v3 + v1 + v2 + v3 + (1|wid)

- etc.

Thoughts?


--
Mike Lawrence
Graduate Student
Department of Psychology
Dalhousie University

Looking to arrange a meeting? Check my public calendar:
http://tr.im/mikes_public_calendar

~ Certainty is folly... I think. ~



From hadley at rice.edu  Mon Sep  6 02:58:58 2010
From: hadley at rice.edu (Hadley Wickham)
Date: Sun, 5 Sep 2010 19:58:58 -0500
Subject: [R-sig-ME] submitted for list review: ezBuildME()
In-Reply-To: <AANLkTi=QGVWc087Kkbv_Pg=SO1jKfpN8=tm80DgDxO5e@mail.gmail.com>
References: <AANLkTi=QGVWc087Kkbv_Pg=SO1jKfpN8=tm80DgDxO5e@mail.gmail.com>
Message-ID: <AANLkTi=4ZGX0r5-EcWqbZ+P8k3fKe0YPV3_LbXm5fKxK@mail.gmail.com>

> - a test of a 2-way interaction compares a model containing the 2-way
> interaction plus the main effects of all predictors plus the random
> effect against a model with just the main effects and the random
> effect. eg:
> ? ?dv ~ v1:v2 + v1 + v2 + v3 + (1|wid)
> ? ? ? ?versus
> ? ?dv ~ v1 + v2 + v3 + (1|wid)
>
> - a test of a 3-way interaction compares a model containing the 3-way
> interaction plus all 2-way interactions plus all main effects plus the
> random effect against a model with all 2-way effects, all main
> effects, and the random effect. eg:
> ? ?dv ~ v1:v2:v3 + v1:v2 + v1:v3 + v2:v3 + v1 + v2 + v3 + (1|wid)
> ? ? ? ?versus
> ? ?dv ~ ?v1:v2 + v1:v3 + v2:v3 + v1 + v2 + v3 + (1|wid)

It's a small point, but this comparison is easier to understand if expressed as:

dv ~ (v1 + v2 + v3) ^ 3 + (1 | wid)
vs
dv ~ (v1 + v2 + v3) ^ 2 + (1 | wid)

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/



From ken.knoblauch at inserm.fr  Mon Sep  6 11:25:51 2010
From: ken.knoblauch at inserm.fr (Ken Knoblauch)
Date: Mon, 06 Sep 2010 11:25:51 +0200
Subject: [R-sig-ME] scope for LHS of formula in lmList
Message-ID: <20100906112551.57nf9s7zwgcogcs4@imp.inserm.fr>

Hi,

I have a data frame

  str(Context)
'data.frame':	120 obs. of  4 variables:
  $ Obs     : Factor w/ 6 levels "A","B","C","D",..: 1 1 1 1 1 1 1 1 1 1 ...
  $ TargCntr: num  0 0.002 0.004 0.006 0.008 0 0.002 0.004 0.006 0.008 ...
  $ NumYes  : int  0 0 5 18 23 24 22 22 22 24 ...
  $ NumNo   : int  24 24 19 6 1 0 2 2 2 0 ...

and find that if I run lmList as follows, I get an error message
in which names from the data frame are not found if enclosed in
a cbind for the LHS of formula (for a binomial family)

lmList(cbind(NumYes, NumNo) ~ TargCntr | Obs,
	data = Context, family = binomial)
Error in cbind(NumYes, NumNo) : object 'NumYes' not found
...

but it works fine if I either define a 2 column matrix in my
workspace or add one to the data frame.

resp <- with(Context, cbind(NumYes, NumNo))

lmList(resp ~ TargCntr | Obs, Context, binomial)

Call: lmList(formula = resp ~ TargCntr | Obs, data = Context, family =  
binomial)
Coefficients:
   (Intercept) TargCntr
A  -0.8574118 369.1977
B  -0.8048122 425.1355
  ...

or

Context <- within(Context, Resp <- cbind(NumYes, NumNo))

lmList(Resp ~ TargCntr | Obs, Context, binomial)

Call: lmList(formula = Resp ~ TargCntr | Obs, data = Context, family =  
binomial)
Coefficients:
   (Intercept) TargCntr
A  -0.8574118 369.1977
B  -0.8048122 425.1355
  ...

So, there is an easy workaround.  I've mostly been working
with binary responses lately, so hadn't noticed this behavior
earlier.

sessionInfo()
R version 2.11.1 Patched (2010-08-30 r52847)
Platform: i386-apple-darwin9.8.0/i386 (32-bit)

locale:
[1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods
[7] base

other attached packages:
[1] lme4_0.999375-35   Matrix_0.999375-44 lattice_0.19-11

loaded via a namespace (and not attached):
[1] grid_2.11.1   MASS_7.3-7    nlme_3.1-96   stats4_2.11.1
[5] tools_2.11.1

Thank you.

best,

Ken

-- 
Ken Knoblauch
Inserm U846
Stem-cell and Brain Research Institute
Department of Integrative Neurosciences
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.sbri.fr/members/kenneth-knoblauch.html



From ken.knoblauch at inserm.fr  Mon Sep  6 12:46:35 2010
From: ken.knoblauch at inserm.fr (Ken Knoblauch)
Date: Mon, 6 Sep 2010 10:46:35 +0000 (UTC)
Subject: [R-sig-ME] scope for LHS of formula in lmList
References: <20100906112551.57nf9s7zwgcogcs4@imp.inserm.fr>
Message-ID: <loom.20100906T124329-293@post.gmane.org>

Ken Knoblauch <ken.knoblauch at ...> writes:
> I have a data frame
>   str(Context)
> 'data.frame':	120 obs. of  4 variables:
>   $ Obs     : Factor w/ 6 levels "A","B","C","D",..: 1 1 1
>   $ TargCntr: num  0 0.002 0.004 0.006 0.008 0 0.
>   $ NumYes  : int  0 0 5 18 23 24 22 22 22 24 ...
>   $ NumNo   : int  24 24 19 6 1 0 2 2 2 0 ...
> and find that if I run lmList as follows, I get an error message
> in which names from the data frame are not found if enclosed in
> a cbind for the LHS of formula (for a binomial family)
> lmList(cbind(NumYes, NumNo) ~ TargCntr | Obs,
> 	data = Context, family = binomial)
> Error in cbind(NumYes, NumNo) : object 'NumYes' not found
> ...
> but it works fine if I either define a 2 column matrix in my
> workspace or add one to the data frame.
> resp <- with(Context, cbind(NumYes, NumNo))
> lmList(resp ~ TargCntr | Obs, Context, binomial)
> Call: lmList(formula = resp ~ TargCntr | Obs, data = Context, family =  
> binomial)
> Coefficients:
>    (Intercept) TargCntr
> A  -0.8574118 369.1977
> B  -0.8048122 425.1355
>   ...
> 
<snip>
> 
> sessionInfo()
> R version 2.11.1 Patched (2010-08-30 r52847)
> Platform: i386-apple-darwin9.8.0/i386 (32-bit)
> 
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods
> [7] base
> 
> other attached packages:
> [1] lme4_0.999375-35   Matrix_0.999375-44 lattice_0.19-11
> 
> loaded via a namespace (and not attached):
> [1] grid_2.11.1   MASS_7.3-7    nlme_3.1-96   stats4_2.11.1
> [5] tools_2.11.1
> 
Just a quick followup to my own message.  It isn't
specific to the LHS of the formula but seems to
affect variables that are isolated within a 
function call whether on the left or right hand
side, e.g., 


lmList(resp ~ I(1000 * TargCntr) | Obs, Context, binomial)
Error in unique(c("AsIs", oldClass(x))) : object 'TargCntr' not found
...

Thanks, 

Ken



From reinhold.kliegl at gmail.com  Mon Sep  6 15:05:54 2010
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Mon, 6 Sep 2010 15:05:54 +0200
Subject: [R-sig-ME] submitted for list review: ezBuildME()
In-Reply-To: <AANLkTi=4ZGX0r5-EcWqbZ+P8k3fKe0YPV3_LbXm5fKxK@mail.gmail.com>
References: <AANLkTi=QGVWc087Kkbv_Pg=SO1jKfpN8=tm80DgDxO5e@mail.gmail.com>
	<AANLkTi=4ZGX0r5-EcWqbZ+P8k3fKe0YPV3_LbXm5fKxK@mail.gmail.com>
Message-ID: <AANLkTi=RKn_xgNG64JXO=4==ZFOr+UvFsA1KYWc-=vDE@mail.gmail.com>

Three comments (which you probably already considered anyway, but it
was not clear from the post):

(1) In general, I would recommend to implement the sequence
drop1()-like, that is start with the full model and check whether
dropping the highest-order interaction significantly reduces the GOF,
and so on. (Of course, in perfectly balanced design it does not
matter, but we rarely have the data in this shape.) I was not sure
whether you want to advocate it as a way to arrive at a minimal model.
If so, then the drop1() approach makes sure that you do not
accidentally delete low-order interactions before you test the
high-order one.

(2) Do you plan some branching for separate tests of main effects or
of interactions of the same order rather than an omnibus test for
removing all main effects or 2-factor or 3-factor interactions? Often,
we expect only one of the the interactions to be significant. In other
words, suppose you have factors A, B, and C. Do you plan to test the
joint effect of A:B, A:C, and B:C or do you perform the tests for each
of the three interactions separately?

(3) There are quite a few side conditions for whether or not the LRT
statistics are conservative or anti-conservative (e.g., Pinheiro &
Bates, 2000). So probably there should be a big "Use at or your own
risk!" message displayed up front. (In my experience, data from
typical psychological experiments with RT as DV are usually fine in
this respect--or at least I have not seen evidence to the contrary.)

Reinhold Kliegl

PS: Many psychologists will love you for this LRT script as a
substitute for their favorite omnibus ANOVA F-test. Fortunately, they
still will have to think about planned comparisons to make sense of
the coefficients for factors.



From ned.dochtermann at gmail.com  Tue Sep  7 17:05:05 2010
From: ned.dochtermann at gmail.com (Ned Dochtermann)
Date: Tue, 7 Sep 2010 08:05:05 -0700
Subject: [R-sig-ME] MCMCglmm: Within- versus between-individual
	covariances
In-Reply-To: <20100905175308.kmfn04hqg48g8gss@www.staffmail.ed.ac.uk>
References: <mailman.2714.1283498808.4229.r-sig-mixed-models@r-project.org>
	<4c817a5b.014a640a.77fb.78d4@mx.google.com>
	<20100905175308.kmfn04hqg48g8gss@www.staffmail.ed.ac.uk>
Message-ID: <4c8654a4.5429e70a.58cd.ffffc07f@mx.google.com>

Jarrod,
Thank you very much for getting back to me so promptly. I am curious about
your suggestion of modelling this within the random component of the model.
Assuming the same data structure as before but adding a fourth trait
measured at the same time as "2" below, would I then add a column
"test.block" with A's for 1&3 and B's for 2&4 and add the MCMCglmm
equivalent of "+ (1|test.block)"? Sorry, I realize this is a pretty basic
question but most of my mixed model experience has been restricted to
fitting random intercepts to individuals along with the occasional intercept
& slope model for individuals.

The whole issue of priors, their implications, and their proper
specification is something I'm still working through. In the priors for R
the covariances for the non-identified parameters were indeed 0 so it seems
like that may be the most straightforward way to deal with it in this case. 

Thanks a lot for your time.
Ned






-----Original Message-----
From: Jarrod Hadfield [mailto:j.hadfield at ed.ac.uk] 
Sent: Sunday, September 05, 2010 9:53 AM
To: Ned Dochtermann
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] MCMCglmm: Within- versus between-individual
covariances

Hi Ned,

Currently it is not possible to specify covariance matrices with  
arbitrary covariances set to zero. If you can reorder the terms so  
that the covariance matrix has a block structure (eg swap trait 2 and  
3 in your example) then you can fit this is in the random terms.  
However, the residual term can only be specified by a single term so  
this is not possible. You can still run the model with a us structure  
of course, but as you are aware the posterior distribution for the  
non-identified covariances will simply be the prior distribution.

Cheers,

Jarrod

Quoting Ned Dochtermann <ned.dochtermann at gmail.com>:

> I tried to find an answer to this problem but either failed to select the
> proper search terms or this topic hasn't been discussed. I apologize if
the
> former. I've also consulted the "class notes" for MCMCglmm but that hasn't
> clarified the issue for me.
>
> I am currently working on the analysis of some repeated measures
behavioural
> data and am attempting to estimate variances and covariances among
> behaviours. Specifically we're looking to estimate the between-individual
> (co)variance matrix and I was using a multi-response model and the Poisson
> family in MCMCglmm to do so.
>
> I had thought that the posterior modes for the (co)variance matrix (i.e.
> posterior.modes(model$VCV)) was producing this on the latent scale, with
the
> ".ID" terms being the between individual (co)variances and the ".unit"
terms
> being the within/residual indvidual (co)variances. This conclusion was
based
> on Jarrod Hadfield's appendix to the recent animal model paper published
in
> the Journal of Animal Ecology (2009). In the appendix discussing MCMCglmm
> for repeated measures, repeatability is calculated using the .ID variance
as
> the between individual component and the .unit variance as the within
> individual component.
>
> The problem I've encountered is that due to the experimental design
certain
> aspects of the within individual covariance matrix should not be
> estimatable, but estimates are nonetheless reported. This is, of course,
due
> to my misspecification of the model.
>
> To use an example provided by a colleague, consider a situation where
three
> distinct behaviours are measured and we're interested in their covariance.
> Due to aspects of the experimental manipulation all the behaviours cannot
be
> measured on the same days. Thus the data might look something like:
>
> ID	Day	Behav1	Behav2	Behav3
> 1	1	4		NA		10
> 1	2	3		NA		15
> 1	3	NA		5		NA
> 1	4	NA		4		NA
> 2	1	2		NA		12
> 2	2	1		NA		18
> 2	3	NA		4		NA
> 2	4	NA		3		NA
> ...
> N	1	6		NA		8
> N	2	5		NA		6
> N	3	NA		8		NA
> N	4	NA		7		NA
> [[note, I know these fictitious data aren't necessarily Poisson
distributed
> but the actual data are]]
>
> In this case between individual variances and covariances can be
calculated
> among all three behaviours and within individual covariances should be
> calculated between Behav1 and Behav3 but not for Behav2 with either 1 or 3
> due to separation.
>
> In attempting the initial analyses I specified the random statement using
an
> unstructured matrix:
>> random=~us(trait):ID
> (I'm pretty sure that's what I want and what produces the between
individual
> covariance matrix)
>
> I also kept the residual covariance matrix as the default unstructured:
>> rcov=~us(trait):units
>
> However, if the within-individual/residual covariances really shouldn't be
> calculated between Behav2 and the other two responses, rcov should
actually
> look something like:
>
> v.B1		0		cov.B1*3
> 0		v.B2		0
> cov.B1*3	0		v.B3
>
> For this example "~us" is thus estimating two extra parameters that
> shouldn't be estimated (for the actual dataset these elements have
> credibility intervals overlapping 0).
>
> Clearly idh wouldn't be appropriate for this either but none of the
options
> listed in Table 3.1 of the Class Notes for MCMCglmm seem correct. It also
> doesn't look like I can specify the matrix structure directly (which is
how
> my colleague dealt with this concern using ASreml and which I know SAS
> allows for regular mixed models).
>
> Is there any advice on how best to deal with this issue? I'm at a loss.
>
> Thanks a lot,
> Ned Dochtermann
>
>
> --
> Ned Dochtermann
> Department of Biology
> University of Nevada, Reno
>
> ned.dochtermann at gmail.com
> http://wolfweb.unr.edu/homepage/mpeacock/Dochter/
> --
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From mhighfield106 at googlemail.com  Tue Sep  7 17:28:23 2010
From: mhighfield106 at googlemail.com (martin highfield)
Date: Tue, 7 Sep 2010 16:28:23 +0100
Subject: [R-sig-ME] Two compartment model PK model using nlme
Message-ID: <AANLkTinz0fH7sP5WDN3P9CWNeO-8n5915pqrYiyF4k5a@mail.gmail.com>

Dear list members,

Can anyone point me in the right direction for implementing a two
?compartment exponential model with instantaneous input and
first-order elimination kinetics using the nlme package. I have been
asked (informally)  to replicate some pharmacokinetic data analysis
which was previously analysed using the NONMEM program but have little
experience with these types of models (how do I get myself into these
situations?) I know there is a function that implements a one
compartment open model (phenoModel) but am unable to find a function
specific to two compartment exponential with instantaneous input and
first order elimination. Would the SSbiexp function be equivalent or
would I have to construct a function myself?

The data comes from 33 subjects although the number of observations
per subjectis quite sparse and with some non consecutive observations
within a subject.

table(table(subset(dataf.stack, !is.na(dataf.stack$Concentration))$Subject))

 2  3  4  5  6  7
 4  5  5  8 10  1

Many thanks (and I hope I havent asked too many daft questions)
Best
Martin




sessionInfo()
R version 2.11.0 (2010-04-22)
i386-pc-mingw32

locale:
[1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United
Kingdom.1252    LC_MONETARY=English_United Kingdom.1252
[4] LC_NUMERIC=C                            LC_TIME=English_United
Kingdom.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] reshape_0.8.3  plyr_0.1.9     lattice_0.18-8 nlme_3.1-96

loaded via a namespace (and not attached):
[1] grid_2.11.0  tools_2.11.0



From Jesus.Frias at DIT.IE  Tue Sep  7 18:21:18 2010
From: Jesus.Frias at DIT.IE (Jesus Frias)
Date: Tue, 7 Sep 2010 17:21:18 +0100
Subject: [R-sig-ME] Two compartment model PK model using nlme
In-Reply-To: <AANLkTinz0fH7sP5WDN3P9CWNeO-8n5915pqrYiyF4k5a@mail.gmail.com>
References: <AANLkTinz0fH7sP5WDN3P9CWNeO-8n5915pqrYiyF4k5a@mail.gmail.com>
Message-ID: <011e01cb4ea8$b3ce11d0$1b6a3570$@Frias@DIT.IE>

Hi Martin,

The nlmeODE library has a few examples of simulations of a two compartmental
model. See

library(nlmeODE)
help(PKPDmodels)

It works with nlme and I think that this is what you will need.

The SSbiexp is the general solution those systems of ODEs and could serve
you as well, although you would have to make some work to make sense of your
parameters.

There is a whole taskview in pharmacokinetics in the CRAN repositories and
it points to the PK and PKfit, which have functions for those kind of
models, but I am not sure if they can be plugged to nlme.

Regards,

Jesus
 

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of martin
highfield
Sent: 07 September 2010 16:28
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Two compartment model PK model using nlme

Dear list members,

Can anyone point me in the right direction for implementing a two
-compartment exponential model with instantaneous input and
first-order elimination kinetics using the nlme package. I have been
asked (informally)  to replicate some pharmacokinetic data analysis
which was previously analysed using the NONMEM program but have little
experience with these types of models (how do I get myself into these
situations?) I know there is a function that implements a one
compartment open model (phenoModel) but am unable to find a function
specific to two compartment exponential with instantaneous input and
first order elimination. Would the SSbiexp function be equivalent or
would I have to construct a function myself?

The data comes from 33 subjects although the number of observations
per subjectis quite sparse and with some non consecutive observations
within a subject.

table(table(subset(dataf.stack, !is.na(dataf.stack$Concentration))$Subject))

 2  3  4  5  6  7
 4  5  5  8 10  1

Many thanks (and I hope I havent asked too many daft questions)
Best
Martin




sessionInfo()
R version 2.11.0 (2010-04-22)
i386-pc-mingw32

locale:
[1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United
Kingdom.1252    LC_MONETARY=English_United Kingdom.1252
[4] LC_NUMERIC=C                            LC_TIME=English_United
Kingdom.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] reshape_0.8.3  plyr_0.1.9     lattice_0.18-8 nlme_3.1-96

loaded via a namespace (and not attached):
[1] grid_2.11.0  tools_2.11.0

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


This message has been scanned for content and viruses by the DIT Information Services E-Mail Scanning Service, and is believed to be clean. http://www.dit.ie



From arrayprofile at yahoo.com  Tue Sep  7 19:05:51 2010
From: arrayprofile at yahoo.com (array chip)
Date: Tue, 7 Sep 2010 10:05:51 -0700 (PDT)
Subject: [R-sig-ME] some questions about longitudinal study with baseline
Message-ID: <52781.88281.qm@web56308.mail.re3.yahoo.com>

Hi all,

I asked this before the holiday, didn't get any response. So would like to 
resend the message, hope to get any fresh attention. Since this is not purely 
lme technical question, so I also cc-ed R general mailing list, hope to get some 
suggestions from there as well. 


I asked some questions on how to analyze longitudinal study with only 2 time 
points (baseline and a follow-up) previously. I appreciate many useful comments 
from some members, especially Dennis Murphy and Marc Schwartz who refered the 
following paper addressing specifically this type of study with only 2 time 
points: 

https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1121605/

Basically, with only 2 time points (baseline and one follow-up), ANCOVA with 
follow-up as dependent variable and baseline as covariate should be used:

follow-up = a + b*baseline + treatment

Now I have a regular longitudinal study with 6 time points, 7 treatments 
(vehicle, A, B, C, D, F, G), measuring a response variable "y". The dataset is 
attached. I have some questions, and appreciate any suggestions on how to 
analyze the dataset.

dat<-read.table("dat.txt",sep='\t',header=T,row.names=NULL)
library(MASS)
dat$trt<-relevel(dat$trt,'vehicle')

xyplot(y~time, groups=trt, data=dat, 
ylim=c(3,10),col=c(1:6,8),lwd=2,type=c('g','a'),xlab='Days',ylab="response",
 key = list(lines=list(col=c(1:6,8),lty=1,lwd=2),
                  text = list(lab = levels(dat$trt)),
                  columns = 3, title = "Treatment"))

So as you can see that there is some curvature between glucose level and time, 
so a quadratic fit might be needed. 



dat$time2<-dat$time*dat$time

A straight fit like below seems reasonable:

fit<-lmer(y~trt*time+trt*time2+(time|id),dat)

Checking on random effects, it appears that variance component for random slope 
is very small, so a simpler model with random intercept only may be sufficient:

fit<-lmer(y~trt*time+trt*time2+(1|id),dat)

Now, I want to incorporate baseline response into the model in order to account 
for any baseline imbalance. I need to generate a new variable "baseline" based 
on glucose levels at time=0:

dat<-merge(dat, dat[dat$time==0,c('id','y')], by.x='id',by.y='id',all.x=T)
colnames(dat)[c(4,6)]<-c('y','baseline')

so the new fit adding baseline into the mixed model is:

fit<-lmer(y~baseline+trt*time+trt*time2+(1|id),dat)

Now my question is 1). Is the above model a reasonable thing to do? 2) when 
baseline is included as a covariate, should I remove the data points at baseline 
from the dataset? I am kind of unsure if it's reasonable to use the baseline 
both as a covariate and as part of the dependent variable values.

Next thing I want to do with this dataset is to do multiple comparisons between 
each treatment (A, B, C, D, F, G) vs. vehicle at a given time point, say time=56 
(the last time points) after adjusting the baseline imbalance. This seems to be 
done using Dunnet test. When I say "after adjusting baseline imbalance", I mean 
the comparisons should be done based on the difference between time=56 and 
time=0 (baseline), i.e. is there any difference in the change from baseline for 
treatment A (or B, C, D, F, G) vs. vehicle?. How can we test this? Will glht() 
in multcomp work for a lmer fit? If yes, how can I specify the syntax?

Finally, with the above model, how to estimate the difference (and the standard 
error) between time=56 and time=0 (baseline) for each treatment groups?

Thank you all for your attention.

John


      
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: dat.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100907/156ddd31/attachment.txt>

From rebecca.sardell at abdn.ac.uk  Wed Sep  8 16:19:31 2010
From: rebecca.sardell at abdn.ac.uk (Sardell, Rebecca)
Date: Wed, 8 Sep 2010 15:19:31 +0100
Subject: [R-sig-ME] nested random effect specification in MCMCglmm
Message-ID: <CE2B0D953EC6A34B94D24D145133356D99C027821B@VMAILB.uoa.abdn.ac.uk>

Hi,

I'm using MCMCglmm to run some binary and Poisson models and I'd just like to check whether I'm specifying a nested random effect correctly.

I have 773 data points, each one corresponding to a chick in a nest. I want to test for differences between half-siblings so I'm using three random effects: natal year, nest and pairID.  There are 17 natal years so year was included as a blocking factor.  There are 245 nests each with a unique number, and 177 different parent pairs, each with a unique number.  Some parent pairs have >1 nest so nest is nested within pairID.

My understanding is that in lmer (1|pairID/nest) is equivalent to (1|pairID) + (1|pairID:nest) which is equivalent to (1|pairID) + (1|nest) as long as each level of nest has a unique value, which it does. Using my dataset in a binary model I get the same results for each of the above in lmer so that's fine.

I'm just wondering whether this is the same when specifying nested random effects in MCMCglmm? I'm guessing it's not as specifying random ~ pairID + nest compared to random ~ pairID + pairID:nest in the model below gives me different significance levels for one of my main effects.  Comparing these results with the binary model in lmer suggests that I should probably be using ~ pairID + pairID:nest when using MCMCglmm but I'm not completely sure. Is this correct or should I be able to use either??

priorX1 = list(R = list(V = 1, n = 0, fix = 1), G = list(G1 = list(V = 1, n = 0.002), G2 = list(V = 1, n = 0.002)))
modelX1 <- MCMCglmm(y ~ C + D + C:D, random = ~ natalyr + pairID + pairID:nest, family = "categorical", data =early, prior = priorX1, burnin = 3000, nitt = 1003000, thin=1000)


Thanks,


Rebecca Sardell
PhD Student
Institute of Biological & Environmental Sciences
University of Aberdeen
Zoology Building
Tillydrone Avenue
Aberdeen
AB24 2TZ
Scotland



The University of Aberdeen is a charity registered in Scotland, No SC013683.



From f.harrell at vanderbilt.edu  Wed Sep  8 00:30:38 2010
From: f.harrell at vanderbilt.edu (Frank Harrell)
Date: Tue, 7 Sep 2010 17:30:38 -0500 (CDT)
Subject: [R-sig-ME] [R] some questions about longitudinal study with
	baseline
In-Reply-To: <52781.88281.qm@web56308.mail.re3.yahoo.com>
References: <52781.88281.qm@web56308.mail.re3.yahoo.com>
Message-ID: <alpine.DEB.2.00.1009071730020.13934@biostat145>

Baseline should appear only as a baseline and should be removed from 
the set of longitudinal responses.  This is often done with a merge( ) 
operation.

Frank

Frank E Harrell Jr   Professor and Chairman        School of Medicine
                      Department of Biostatistics   Vanderbilt University

On Tue, 7 Sep 2010, array chip wrote:

> Hi all,
>
> I asked this before the holiday, didn't get any response. So would like to
> resend the message, hope to get any fresh attention. Since this is not purely
> lme technical question, so I also cc-ed R general mailing list, hope to get some
> suggestions from there as well.
>
>
> I asked some questions on how to analyze longitudinal study with only 2 time
> points (baseline and a follow-up) previously. I appreciate many useful comments
> from some members, especially Dennis Murphy and Marc Schwartz who refered the
> following paper addressing specifically this type of study with only 2 time
> points:
>
> https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1121605/
>
> Basically, with only 2 time points (baseline and one follow-up), ANCOVA with
> follow-up as dependent variable and baseline as covariate should be used:
>
> follow-up = a + b*baseline + treatment
>
> Now I have a regular longitudinal study with 6 time points, 7 treatments
> (vehicle, A, B, C, D, F, G), measuring a response variable "y". The dataset is
> attached. I have some questions, and appreciate any suggestions on how to
> analyze the dataset.
>
> dat<-read.table("dat.txt",sep='\t',header=T,row.names=NULL)
> library(MASS)
> dat$trt<-relevel(dat$trt,'vehicle')
>
> xyplot(y~time, groups=trt, data=dat,
> ylim=c(3,10),col=c(1:6,8),lwd=2,type=c('g','a'),xlab='Days',ylab="response",
> key = list(lines=list(col=c(1:6,8),lty=1,lwd=2),
>                  text = list(lab = levels(dat$trt)),
>                  columns = 3, title = "Treatment"))
>
> So as you can see that there is some curvature between glucose level and time,
> so a quadratic fit might be needed.
>
>
>
> dat$time2<-dat$time*dat$time
>
> A straight fit like below seems reasonable:
>
> fit<-lmer(y~trt*time+trt*time2+(time|id),dat)
>
> Checking on random effects, it appears that variance component for random slope
> is very small, so a simpler model with random intercept only may be sufficient:
>
> fit<-lmer(y~trt*time+trt*time2+(1|id),dat)
>
> Now, I want to incorporate baseline response into the model in order to account
> for any baseline imbalance. I need to generate a new variable "baseline" based
> on glucose levels at time=0:
>
> dat<-merge(dat, dat[dat$time==0,c('id','y')], by.x='id',by.y='id',all.x=T)
> colnames(dat)[c(4,6)]<-c('y','baseline')
>
> so the new fit adding baseline into the mixed model is:
>
> fit<-lmer(y~baseline+trt*time+trt*time2+(1|id),dat)
>
> Now my question is 1). Is the above model a reasonable thing to do? 2) when
> baseline is included as a covariate, should I remove the data points at baseline
> from the dataset? I am kind of unsure if it's reasonable to use the baseline
> both as a covariate and as part of the dependent variable values.
>
> Next thing I want to do with this dataset is to do multiple comparisons between
> each treatment (A, B, C, D, F, G) vs. vehicle at a given time point, say time=56
> (the last time points) after adjusting the baseline imbalance. This seems to be
> done using Dunnet test. When I say "after adjusting baseline imbalance", I mean
> the comparisons should be done based on the difference between time=56 and
> time=0 (baseline), i.e. is there any difference in the change from baseline for
> treatment A (or B, C, D, F, G) vs. vehicle?. How can we test this? Will glht()
> in multcomp work for a lmer fit? If yes, how can I specify the syntax?
>
> Finally, with the above model, how to estimate the difference (and the standard
> error) between time=56 and time=0 (baseline) for each treatment groups?
>
> Thank you all for your attention.
>
> John
>
>
>



From ned.dochtermann at gmail.com  Thu Sep  9 00:00:33 2010
From: ned.dochtermann at gmail.com (Ned Dochtermann)
Date: Wed, 8 Sep 2010 15:00:33 -0700
Subject: [R-sig-ME] rare binary outcome, MCMCglmm, and priors
In-Reply-To: <mailman.5.1283335202.17246.r-sig-mixed-models@r-project.org>
References: <mailman.5.1283335202.17246.r-sig-mixed-models@r-project.org>
Message-ID: <4c880783.1eeb640a.721d.19a4@mx.google.com>

Hi Dave,
I was wondering if you happened to have finished these analyses and whether
the greater variance in the priors "worked". I coincidentally have a paper
in review (well, waiting on the AE recommendation actually-which I typically
assume means impending rejection!) which I now realize likely had a similar
problem to what you encountered. Like you I had some ridiculously large
odds-ratios and I only came across the Gelman et al. (2008, Annals) paper
after submission. I doubt the reanalysis would change the inferences but I'd
prefer to have the analysis done correctly.

Thanks a lot,
Ned

--
Ned Dochtermann
Department of Biology
University of Nevada, Reno

ned.dochtermann at gmail.com
http://wolfweb.unr.edu/homepage/mpeacock/Dochter/
--



Message: 2
Date: Tue, 31 Aug 2010 11:42:14 -0700
From: David Atkins <datkins at u.washington.edu>
To: Jarrod Hadfield <j.hadfield at ed.ac.uk>
Cc: "r-sig-mixed-models at r-project.org"
	<r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] rare binary outcome, MCMCglmm, and priors
	(related to separation)
Message-ID: <4C7D4D06.2050507 at u.washington.edu>
Content-Type: text/plain; charset=windows-1252; format=flowed


Jarrod--

Per usual, thanks for the input; I've got the Gelman et al. (2008) 
article and have some models running.  I'll update with what I find.

cheers, Dave

Dave Atkins, PhD
Research Associate Professor
Department of Psychiatry and Behavioral Science
University of Washington
datkins at u.washington.edu

Center for the Study of Health and Risk Behaviors (CSHRB)		
1100 NE 45th Street, Suite 300 	
Seattle, WA  98105 	
206-616-3879 	
http://depts.washington.edu/cshrb/
(Mon-Wed)	

Center for Healthcare Improvement, for Addictions, Mental Illness,
   Medically Vulnerable Populations (CHAMMP)
325 9th Avenue, 2HH-15
Box 359911
Seattle, WA 98104
http://www.chammp.org
(Thurs)

On 8/31/10 2:43 AM, Jarrod Hadfield wrote:
> Hi Dave,
>
> With respect to the prior specification for the fixed effects, you may
> want to make the variance larger. Perhaps something like:
>
> prior$B$V = diag(7)*(3+pi^2/3)
>
> The motivation behind this is to choose a prior for b, for which
> plogis(Xb+Zu+e) would be close to a uniform after marginalising the
> random effects u and e. pi^2/3 is the variance of the logistic
> distribution (the cdf of which is the inverse logit function) and 3 is
> the variance of Zu+e assuming Z is an identity matrix (1 for the
> residual variance + ~2 for the person variance). You can see it is
> pretty close for an intercept.
>
> priorB<-rnorm(1000, 0, sqrt(3+pi^2/3))
> priorMB<-1:1000
> for(i in 1:1000){
> priorMB[i]<-mean(plogis(priorB[i]+rnorm(1000,0,sqrt(3))))
> }
> hist(priorMB)
>
> This example works for a model with a single intercept, and when fitting
> a categorical predictor I usually remove the intercept (-1) so that the
> distribution is approximately uniform for all levels of the predictor.
> For continuous covariates and interactions it will be a bit more
> involved and you should probably read Gelman et. al. 2008 Annals of
> Applied Statistics 1360-1383.
>
> Using a prior with a variance of one will shrink the estimates to less
> extreme values and may explain some of the differences between models.
> However, if anything this new prior is likely to make the mixing worse
> rather than better. Two options that may speed up mixing are using
> slice=TRUE in the call to MCMCglmm. This will use slice sampling to
> update the latent variables rather then MH updates. You could also use
> parameter expanded priors for G, but from your output it does not look
> like the variance is hitting zero so it is unlikely to improve things.
>
> Cheers,
>
> Jarrod
>
>
>
>
>
> On 30 Aug 2010, at 21:37, David Atkins wrote:
>
>>
>> Some colleagues have collected data from 184 females in dating
>> relationships. Data were collected daily using PDAs; the outcome is a
>> binary indicator of whether any physical aggression occurred (intimate
>> partner violence, or IPV).
>>
>> They are interested in 3 covariates:
>>
>> -- alcohol use: yes/no
>> -- anger: rated on 1-5 scale
>> -- verbal aggression: sum of handful of items, with 0-15 scale
>>
>> Their hypothesis is that the interaction of all 3 covariates will lead
>> to the highest likelihood of IPV. As you might expect, the outcome is
>> very rare with 51 instances of IPV out of 8,269 days of data, and 158
>> women (out of 184) reported no instances of IPV.
>>
>> Question 1: Given that a GLMM will assume a normal distribution for
>> the person-specific baserate in IPV, is this data even appropriate for
>> GLMM or should they be looking elsewhere (perhaps GEE)?
>>
>> That said, for some (unknown) proportion of individuals, there
>> probably would be instances of IPV if the data collection period were
>> longer. Thus, perhaps there is some basis for assuming a distribution
>> across people, even if the observed data for some individuals are all
>> zeroes.
>>
>> To present some of the data (and I can check to see if it would be
>> okay to make the data available), I dichotomized both anger and verbal
>> aggression ("prov.cut" below):
>>
>> ang.cut prov.cut alc.cut ipv.yes ipv.no
>> 1 0 0 0 0 3918
>> 2 0 0 1 0 1
>> 3 1 0 0 5 2381
>> 4 1 0 1 1 292
>> 5 1 1 0 36 1471
>> 6 1 1 1 9 257
>>
>> Thus, the instances of IPV are more likely when there is anger and
>> verbal aggression; alcohol is a little less clear. (And, if the
>> association of anger and verbal aggression with IPV seems
>> tautological, there has been debate about different forms of IPV,
>> where some research has pointed to "cold" aggression.)
>>
>> Not surprisingly, analyses using either glmer() or MCMCglmm() show
>> signs of partial separation, with some whopping odds-ratios and 95% CI
>> spanning a couple orders of magnitude.
>>
>> I have read a bit about the problems of separation in logistic
>> regression and know that Gelman et al suggest Bayesian priors as one
>> "solution". Moreover, I see in Jarrod Hadfield's course notes that his
>> multinomial example has a "structural" zero that he addresses via
>> priors on pp. 96-97, though I confess I don't quite follow exactly
>> what he has done (and why).
>>
>> If I just let MCMCglmm cook on a regression with all 2-way
>> interactions for a long while:
>>
>> prior = list(R = list(V = 1, fix = 1),
>> B = list(mu = c(rep(0,7)), V = diag(7)),
>> G = list(G1 = list(V = 1, nu = 0.002)))
>> lr.mcmc <- MCMCglmm(ipv ~ (alc.cut + angc + log(provc + 0.03))^2, data
>> = ipv.df,
>> family = "categorical", verbose = TRUE,
>> prior = prior,
>> nitt = 2000000, burnin = 1000000, thin = 1000,
>> random = ~ person)
>>
>> The answers are less extreme than what I get with glmer, perhaps
>> suggesting this is wandering toward the "correct" solution, though
>> there are also plenty of indicators that we aren't there yet:
>>
>> > summary(lr.mcmc)
>>
>> Iterations = 1999001
>> Thinning interval = 1000001
>> Sample size = 1000
>>
>> DIC: 379.972
>>
>> G-structure: ~person
>>
>> post.mean l-95% CI u-95% CI eff.samp
>> person 2.287 0.6775 4.206 194.0
>>
>> R-structure: ~units
>>
>> post.mean l-95% CI u-95% CI eff.samp
>> units 1 1 1 0
>>
>> Location effects: ipv ~ (alc.cut + angc + log(provc + 0.03))^2
>>
>> post.mean l-95% CI u-95% CI eff.samp pMCMC
>> (Intercept) -2.58724 -3.49492 -1.65250 245.20 <0.001 ***
>> alc.cut 0.49512 -0.75268 1.99397 1000.00 0.464
>> angc 0.02664 -0.34227 0.41365 283.90 0.880
>> log(provc + 0.03) 1.36626 0.98743 1.70863 28.69 <0.001 ***
>> alc.cut:angc -0.16519 -0.79299 0.41949 683.56 0.590
>> alc.cut:log(provc + 0.03) -0.02631 -0.53118 0.55065 157.34 0.898
>> angc:log(provc + 0.03) -0.26132 -0.40141 -0.10407 74.98 0.004 **
>> ---
>> Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>> I haven't run multiple chains yet, but the effective sample sizes and
>> trace plots already suggest we ain't there yet. My specific question
>> is whether there would be an alternative prior specification for the
>> fixed-effects that would be more appropriate?
>>
>> I would appreciate any and all thoughts here, including if this just
>> doesn't seem like an appropriate data/question for GLMMs.
>>
>> sessionInfo below.
>>
>> cheers, Dave
>>
>> > sessionInfo()
>> R version 2.11.1 (2010-05-31)
>> i386-apple-darwin9.8.0
>>
>> locale:
>> [1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
>>
>> attached base packages:
>> [1] stats4 splines stats graphics grDevices utils datasets
>> [8] methods base
>>
>> other attached packages:
>> [1] MCMCglmm_2.06 corpcor_1.5.7 ape_2.5-3
>> [4] coda_0.13-5 Matrix_0.999375-44 lattice_0.19-10
>> [7] tensorA_0.35 Hmisc_3.8-2 modeltools_0.2-16
>> [10] mvtnorm_0.9-92 survival_2.36-1
>>
>> loaded via a namespace (and not attached):
>> [1] cluster_1.13.1 coin_1.0-16 colorspace_1.0-1 gee_4.13-15
>> [5] grid_2.11.1 lme4_0.999375-35 nlme_3.1-96 party_0.9-9998
>> [9] rpart_3.1-46 tools_2.11.1
>>
>> --
>> Dave Atkins, PhD
>> Research Associate Professor
>> Department of Psychiatry and Behavioral Science
>> University of Washington
>> datkins at u.washington.edu
>>
>> Center for the Study of Health and Risk Behaviors (CSHRB)
>> 1100 NE 45th Street, Suite 300
>> Seattle, WA 98105
>> 206-616-3879
>> http://depts.washington.edu/cshrb/
>> (Mon-Wed)
>>
>> Center for Healthcare Improvement, for Addictions, Mental Illness,
>> Medically Vulnerable Populations (CHAMMP)
>> 325 9th Avenue, 2HH-15
>> Box 359911
>> Seattle, WA 98104
>> http://www.chammp.org
>> (Thurs)
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>



------------------------------

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


End of R-sig-mixed-models Digest, Vol 45, Issue 1



From datkins at u.washington.edu  Thu Sep  9 19:11:07 2010
From: datkins at u.washington.edu (David Atkins)
Date: Thu, 09 Sep 2010 10:11:07 -0700
Subject: [R-sig-ME] rare binary outcome, MCMCglmm, and priors
In-Reply-To: <4c880783.1eeb640a.721d.19a4@mx.google.com>
References: <mailman.5.1283335202.17246.r-sig-mixed-models@r-project.org>
	<4c880783.1eeb640a.721d.19a4@mx.google.com>
Message-ID: <4C89152B.5000703@u.washington.edu>


On 9/8/10 3:00 PM, Ned Dochtermann wrote:
> Hi Dave,
> I was wondering if you happened to have finished these analyses and whether
> the greater variance in the priors "worked". I coincidentally have a paper
> in review (well, waiting on the AE recommendation actually-which I typically
> assume means impending rejection!) which I now realize likely had a similar
> problem to what you encountered. Like you I had some ridiculously large
> odds-ratios and I only came across the Gelman et al. (2008, Annals) paper
> after submission. I doubt the reanalysis would change the inferences but I'd
> prefer to have the analysis done correctly.

Hi Ned--

Yes, and apologies for not getting back to the list earlier.

The quick response is yes, using MCMCglmm with tighter priors for the 
fixed-effects (relative to the defaults) helped with extreme 
coefficients and odds-ratios (output below).

Here's my summary (and Jarrod, please feel free to edit as appropriate..):

-- The default fixed-effects priors in MCMCglmm are MVN with mean vector 
of zero and variance I*1e+10, which is huge and not placing any 
functional constraints on the fixed-effects.

-- Following Jarrod's suggestion, I used the following prior:

prior2.1.1 = list(R = list(V = 1, fix = 1),
			B = list(mu = c(rep(0,9)), V = diag(9)*(4.3+pi^2/3)),
			G = list(G1 = list(V = 1, nu = 0.002, alpha.mu = 0, alpha.V = 1000)))

where the key difference is the variance of the fixed-effects prior B, 
which will provide some constraint on the fixed-effects, though if we 
actually look at this variance vs. the observed coefficients, I still 
feel comfortable that this is not "dominating" the data.

-- Jarrod also referred to the Gelman et al. article, which is 
definitely worthwhile reading related to separation and Bayesian priors. 
  However, Gelman et al. suggest a t prior and in a backchannel exchange 
with Jarrod he suggested that: 1) his earlier suggestion was in the same 
"spirit" as the Gelman approach, but that 2) actually implementing t 
priors in MCMCglmm would be non-trivial.  Jarrod did have the following 
suggestion, which I didn't explore but I pass along here in case someone 
wants to explore:

"One possibility (and I may be wrong so I wouldn't waste too much time 
following it up) is to fit the fixed effects as random effects with 
common variance. You can do this  by passing ~idv(fixed formula) to the 
random part of the model. Lets say the prior for the fixed effects in 
your current model has null mean vector and covariance matrix  I*v.  In 
the model suggested above you can fix the variance associated with the 
idv term to v, and this would be identical to treating them as fixed 
with prior I*v as in the first model. Now, if you don't fix the variance 
associated with the idv term, but give it an inverse-Wishart prior, this 
will induce a t-prior on the effects. It should be possible to choose a 
prior for  the variance associated with the idv term which results in a 
posterior distribution that conforms to the t-distribution suggested by 
Gelman. [snip] My gut feeling however is that it could be made to work, 
but I'm not sure whether you would get a very different answer."

A few other reflections:

-- Using slice = TRUE *definitely* helped convergence in this case.

-- I did end up using the parameter expansion (alpha.mu, alpha.V) for 
the random-effect, though it was less clear whether this had notable 
influence.

Below are outputs from MCMCglmm (nitt = 500000, burnin = 250000, thin = 
250) which multiple chains and diagnostics suggest are reasonable 
(though definitely still autocorrelation for some parameters), as well 
as comparable output from glmer.  Key differences are size of 
random-effect variance and the smaller (and more reasonable) 
coefficients from the MCMCglmm run.

At the end of the day, I think the underlying machinery of MCMCglmm was 
quite helpful, though the data still are very rare, and so we need to be 
cautious in interpretation, etc.

Hope that helps.

cheers, Dave

 > summary(lr.mcmc1f)

  Iterations = 499751
  Thinning interval  = 250001
  Sample size  = 1000

  DIC: 346.7383

  G-structure:  ~person

        post.mean l-95% CI u-95% CI eff.samp
person     3.704    1.228     6.35    81.95

  R-structure:  ~units

       post.mean l-95% CI u-95% CI eff.samp
units         1        1        1        0

  Location effects: ipv ~ ang5.c + alc.c * ang.c * prov.c

                    post.mean l-95% CI u-95% CI eff.samp  pMCMC
(Intercept)         -8.58321 -9.60202 -7.57860    46.07 <0.001 ***
ang5.c               1.60969  0.18604  3.10334   674.87  0.032 *
alc.c                1.83108 -0.07322  3.63476   541.45  0.072 .
ang.c                1.63127  0.66607  2.62645   232.09  0.002 **
prov.c               2.08320  1.43703  2.64396   313.69 <0.001 ***
alc.c:ang.c         -2.69393 -5.37519 -0.06124  1000.00  0.036 *
alc.c:prov.c        -0.73255 -2.22607  0.79766   743.17  0.348
ang.c:prov.c        -0.68224 -1.19169 -0.11578   229.32  0.008 **
alc.c:ang.c:prov.c   1.68279  0.03122  3.56480  1175.32  0.044 *
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1


 > print(glmer.comp, cor = FALSE)
Generalized linear mixed model fit by the Laplace approximation
Formula: ipv ~ ang5.c + alc.c * ang.c * prov.c + (1 | person)
    Data: ipv.df
    AIC   BIC logLik deviance
  387.9 458.1 -183.9    367.9
Random effects:
  Groups Name        Variance Std.Dev.
  person (Intercept) 6.6537   2.5795
Number of obs: 8320, groups: person, 183

Fixed effects:
                    Estimate Std. Error z value Pr(>|z|)
(Intercept)         -8.8112     0.6133 -14.366  < 2e-16 ***
ang5.c               1.7139     0.7781   2.203  0.02761 *
alc.c                3.3495     1.2264   2.731  0.00631 **
ang.c                1.5704     0.6068   2.588  0.00966 **
prov.c               2.0618     0.3630   5.680 1.35e-08 ***
alc.c:ang.c         -4.8751     1.9567  -2.492  0.01272 *
alc.c:prov.c        -1.3401     0.9584  -1.398  0.16204
ang.c:prov.c        -0.7178     0.2997  -2.395  0.01661 *
alc.c:ang.c:prov.c   2.6829     1.1900   2.255  0.02416 *
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1


 > sessionInfo()
R version 2.11.1 (2010-05-31)
i386-apple-darwin9.8.0

locale:
[1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats4    splines   stats     graphics  grDevices utils     datasets 
  methods
[9] base

other attached packages:
  [1] MCMCglmm_2.06      corpcor_1.5.7      ape_2.5-3 
coda_0.13-5
  [5] tensorA_0.35       lme4_0.999375-35   Matrix_0.999375-44 
lattice_0.19-11
  [9] modeltools_0.2-16  mvtnorm_0.9-93     survival_2.36-1

loaded via a namespace (and not attached):
[1] coin_1.0-16      colorspace_1.0-1 gee_4.13-15      grid_2.11.1 
nlme_3.1-96
[6] party_0.9-9998   rpart_3.1-46     tools_2.11.1


>
> Thanks a lot,
> Ned
>
> --
> Ned Dochtermann
> Department of Biology
> University of Nevada, Reno
>
> ned.dochtermann at gmail.com
> http://wolfweb.unr.edu/homepage/mpeacock/Dochter/
> --



From j.hadfield at ed.ac.uk  Thu Sep  9 20:48:42 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 09 Sep 2010 19:48:42 +0100
Subject: [R-sig-ME] nested random effect specification in MCMCglmm
In-Reply-To: <CE2B0D953EC6A34B94D24D145133356D99C027821B@VMAILB.uoa.abdn.ac.uk>
References: <CE2B0D953EC6A34B94D24D145133356D99C027821B@VMAILB.uoa.abdn.ac.uk>
Message-ID: <20100909194842.6qtert2v4w4so880@www.staffmail.ed.ac.uk>

Hi Rebecca,

If every nest has a unique identifier then MCMCglmm should give the  
same answer (up to Monte Carlo error) for random ~ pairID + nest and  
random ~ pairID + pairID:nest, so a difference is worrying. Can the  
difference for the significance be explained by Monte Carlo error?  
Perhaps you could post the summaries from the two models?

Cheers,

Jarrod


Quoting "Sardell, Rebecca" <rebecca.sardell at abdn.ac.uk>:

> Hi,
>
> I'm using MCMCglmm to run some binary and Poisson models and I'd   
> just like to check whether I'm specifying a nested random effect   
> correctly.
>
> I have 773 data points, each one corresponding to a chick in a nest.  
>  I want to test for differences between half-siblings so I'm using   
> three random effects: natal year, nest and pairID.  There are 17   
> natal years so year was included as a blocking factor.  There are   
> 245 nests each with a unique number, and 177 different parent pairs,  
>  each with a unique number.  Some parent pairs have >1 nest so nest   
> is nested within pairID.
>
> My understanding is that in lmer (1|pairID/nest) is equivalent to   
> (1|pairID) + (1|pairID:nest) which is equivalent to (1|pairID) +   
> (1|nest) as long as each level of nest has a unique value, which it   
> does. Using my dataset in a binary model I get the same results for   
> each of the above in lmer so that's fine.
>
> I'm just wondering whether this is the same when specifying nested   
> random effects in MCMCglmm? I'm guessing it's not as specifying   
> random ~ pairID + nest compared to random ~ pairID + pairID:nest in   
> the model below gives me different significance levels for one of my  
>  main effects.  Comparing these results with the binary model in  
> lmer  suggests that I should probably be using ~ pairID +  
> pairID:nest when  using MCMCglmm but I'm not completely sure. Is  
> this correct or  should I be able to use either??
>
> priorX1 = list(R = list(V = 1, n = 0, fix = 1), G = list(G1 = list(V  
>  = 1, n = 0.002), G2 = list(V = 1, n = 0.002)))
> modelX1 <- MCMCglmm(y ~ C + D + C:D, random = ~ natalyr + pairID +   
> pairID:nest, family = "categorical", data =early, prior = priorX1,   
> burnin = 3000, nitt = 1003000, thin=1000)
>
>
> Thanks,
>
>
> Rebecca Sardell
> PhD Student
> Institute of Biological & Environmental Sciences
> University of Aberdeen
> Zoology Building
> Tillydrone Avenue
> Aberdeen
> AB24 2TZ
> Scotland
>
>
>
> The University of Aberdeen is a charity registered in Scotland, No SC013683.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From r.millar at auckland.ac.nz  Fri Sep 10 00:03:47 2010
From: r.millar at auckland.ac.nz (Russell Millar)
Date: Fri, 10 Sep 2010 10:03:47 +1200
Subject: [R-sig-ME] Quadrature appears to incorrectly calculate deviance in
 binomial GLMM
Message-ID: <4C8959C3.1080506@auckland.ac.nz>

Dear All,

I'm fitting to some historical grouped binomial data. There are 16 
binomial obs arranged in 8 blocks of 2 (trmt and control). I know what 
the model deviance calculated via the Laplace approx and quadrature 
should be since I've fitted the model using SAS PROC GLIMMIX, ADMB and 
via simulated likelihood (Millar 2004, ANZJS). However, lmer is only 
giving the correct deviance under the Laplace approximation.  Also, the 
deviance calculated by lmer using quadrature depends on the choice of 
quadrature points???

By the way, I'm not directly interested in the deviance. The calculated 
value of 35.8 on 13 dof would suggest lack of fit, which is nonsense. 
I've done a parametric bootstrap and this observed deviance is typical. 
I'm really interested in the accuracy of the calculated log-likelihood.

Thanks for any help,

Russell Millar
Dept of Stats
U. Akld


#Binomial data in 8 blocks of 2
clinic=rep(1:8,rep(2,8))
trmt=as.factor(rep(c("Drug","Control"),8))
y=c(11,10,16,22,14,7,2,1,6,0,1,0,1,1,4,6) #Successes
n=c(36,37,20,32,19,19,16,17,17,12,11,10,5,9,6,7) #Number of trials

#log-likelihood of saturated model
sum(log(dbinom(y,n,y/n)))
#[1] -19.19493

#Using 3 forms of alternative software, it has been calculated that
#the true log-likelihood (with consts) of this model is -37.0313
#or -37.1006 if calculated using the Laplace approximation.
#These correspond to deviances of
#2*(-19.19493+37.0313)=35.67274 (exact)
#2*(-19.19493+37.1006)=35.81134 (from Laplace approx)


library(lme4)
#Laplace approximation
deviance( lmer(y/n~trmt+(1|clinic),family="binomial",weight=n) )
#[1] 35.81135 #Looks good

#Quadrature with 2 quadrature points
deviance( lmer(y/n~trmt+(1|clinic),family="binomial",weight=n,nAGQ=2) )
#[1] 38.90244 #???

#Quadrature with 3 quadrature points
deviance( lmer(y/n~trmt+(1|clinic),family="binomial",weight=n,nAGQ=3) )
#[1] 38.90244 #At least this is the same as above

#Quadrature with 9 quadrature points
deviance( lmer(y/n~trmt+(1|clinic),family="binomial",weight=n,nAGQ=9) )
#[1] 39.05139 #Losing numerical accuracy perhaps?

#Quadrature with lots of quadrature points
deviance( lmer(y/n~trmt+(1|clinic),family="binomial",weight=n,nAGQ=99) )
#[1] 31.59593 #Yikes!



From nextsunday at gmail.com  Fri Sep 10 12:15:25 2010
From: nextsunday at gmail.com (=?UTF-8?B?6rO97ZWc67mI?=)
Date: Fri, 10 Sep 2010 19:15:25 +0900
Subject: [R-sig-ME] How can I apply the truncated Poisson Generalized Mixed
	Model?
Message-ID: <AANLkTinRHeegKWvi7vqpLQiri6F2w4-xqDHGM-5gx4tw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100910/a4237fd0/attachment.pl>

From bbolker at gmail.com  Fri Sep 10 16:07:40 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 10 Sep 2010 10:07:40 -0400
Subject: [R-sig-ME] Quadrature appears to incorrectly calculate deviance
 in binomial GLMM
In-Reply-To: <4C8959C3.1080506@auckland.ac.nz>
References: <4C8959C3.1080506@auckland.ac.nz>
Message-ID: <4C8A3BAC.9080005@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100910/73d30142/attachment.pl>

From arrayprofile at yahoo.com  Fri Sep 10 19:23:28 2010
From: arrayprofile at yahoo.com (array chip)
Date: Fri, 10 Sep 2010 10:23:28 -0700 (PDT)
Subject: [R-sig-ME] lme4a package loading error
In-Reply-To: <1284138015.2345.20.camel@desktop.localdomain>
References: <4C88E931.6030400@icr.ac.uk>
	<E18FDA5C64FC5645A25B2B52EB8CC9CE0393DA22A7@EXCHMCA.tirol.local>
	<4C896716020000CB000740F3@medicine.umaryland.edu>
	<AANLkTinii9iAQffTuioy1UD-ZrtCR=_UH41B13h100nE@mail.gmail.com>
	<4C897083020000CB000740FF@medicine.umaryland.edu>
	<1284109537.2409.2.camel@desktop.localdomain>
	<302000.40845.qm@web56308.mail.re3.yahoo.com>
	<1284138015.2345.20.camel@desktop.localdomain>
Message-ID: <190156.65925.qm@web56301.mail.re3.yahoo.com>

Thanks for reminding this. So I found lme4a package from Doug's UserR!2010 
presentation folder: 
http://lme4.r-forge.r-project.org/slides/2010-07-20-Gaithersburg/pkg/

However, after installation, I got the following error message when trying to 
load the library:

library(Matrix)
> library(Rcpp)
> library(minqa)
> library(lme4a)
Error : classes "modelMatrix", "denseModelMatrix", "sparseModelMatrix", 
"ddenseModelMatrix", "dsparseModelMatrix", "predModule", "dPredModule", 
"sPredModule", "respModule", "glmRespMod", "nlsRespMod" are not exported by 
'namespace:Matrix'
Error: package/namespace load failed for 'lme4a'

Here is my sessionInfo()
> sessionInfo()
R version 2.11.1 (2010-05-31) 
i386-pc-mingw32 

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252   

[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C                          

[5] LC_TIME=English_United States.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] minqa_1.1.9        Rcpp_0.8.6         Matrix_0.999375-43 lattice_0.18-8    

loaded via a namespace (and not attached):
[1] grid_2.11.1    nlme_3.1-96    splines_2.11.1 stats4_2.11.1  tools_2.11.1  

Any suggestions would be appreciated.

John





----- Original Message ----
From: Gavin Simpson <gavin.simpson at ucl.ac.uk>
To: array chip <arrayprofile at yahoo.com>
Cc: John Sorkin <jsorkin at grecc.umaryland.edu>; r-help at r-project.org; Bert Gunter 
<gunter.berton at gene.com>
Sent: Fri, September 10, 2010 10:00:15 AM
Subject: Re: [R] lmer fixed effects, SE, t . . . and p

On Fri, 2010-09-10 at 09:51 -0700, array chip wrote:
> But as far as I know, profile() seems to be de-activated in the lme4 package.

It is beta software. The lme4a version of the lme4 "package" might have
had profile re-enabled, IIRC. 

G

> ----- Original Message ----
> From: Gavin Simpson <gavin.simpson at ucl.ac.uk>
> To: John Sorkin <jsorkin at grecc.umaryland.edu>
> Cc: r-help at r-project.org; Bert Gunter <gunter.berton at gene.com>
> Sent: Fri, September 10, 2010 2:05:37 AM
> Subject: Re: [R] lmer fixed effects, SE, t . . . and p
> 
> On Thu, 2010-09-09 at 23:40 -0400, John Sorkin wrote:
> > Bert,
> > I appreciate you comments, and I have read Doug Bates writing about p
> > values in mixed effects regression. It is precisely because I read
> > Doug's material that I asked "how are we to interpret the estimates"
> > rather than "how can we compute a p value". My question is a simple
> > question whose answer is undoubtedly complex, but one that needs an
> > answer. Without p values, or confidence intervals, I am not certain
> > what to make of the results of my analysis. Does my analysis suggest,
> > or does it not suggest that there is a relation between time and y? If
> > I can't answer this question after running the analysis, I don't have
> > any more information than I did before I ran the analysis, and a fair
> > question would be why did I run the analysis? I am asking for help not
> > in calculation a p value or a CI, but rather to know what I can and
> > can't say about the results of the analysis. If this basic question
> > can not be answered, I am at a loss to interpret my results. 
> > Thank you,
> > John
> 
> Doug talks quite a lot about profiling lmer fits using 'profile
> deviance' to investigate variability in fixed effects. For example, see
> section 1.5 in the draft of chapter 1 of Doug's book on mixed models:
> 
> http://lme4.r-forge.r-project.org/book/
> 
> HTH
> 
> G
> 
> > John David Sorkin M.D., Ph.D.
> > Chief, Biostatistics and Informatics
> > University of Maryland School of Medicine Division of Gerontology
> > Baltimore VA Medical Center
> > 10 North Greene Street
> > GRECC (BT/18/GR)
> > Baltimore, MD 21201-1524
> > (Phone) 410-605-7119
> > (Fax) 410-605-7913 (Please call phone number above prior to faxing)>>> Bert 
> >Gunter <gunter.berton at gene.com> 9/9/2010 11:21 PM >>>
> > John:
> > 
> > Search on this issue in the list archives. Doug Bates has addressed it
> > at length. Basically, he does not calculate CI's or p-values because
> > he does not know how to reliably do so.
> > 
> > However, the key remark in your query was:
> > 
> > > (2) lmer does not give p values or confidence intervals for the fixed 
> >effects. How we are to interpret the estimates given that no p value or CI is 

> >given for the estimates?
> > 
> > Think about it. A statistical analysis -- ANY statistical analysis --
> > treats the data in isolation: it is not informed by physics,
> > thermodynamics, biology,  other similar data, prior experience, or,
> > indeed, any part of the body of relevant scientific knowledge. Do you
> > really think that any such analysis, especially when predicated upon
> > often tenuous or even (necessarily) unverifiable assumptions and
> > simplifications should be considered authoritative? Classical
> > statistical inference is just another piece of the puzzle, and not
> > even particularly useful when, as if typically the case, hypotheses
> > are formulated AFTER seeing the data (this invalidates the probability
> > calculations -- hypotheses must be formulated before seeing the data
> > to be meaningfully assessed). Leo Breiman called this statistics'
> > "quiet scandal" something like 20 years ago, and he was no dummy.
> > 
> > It is comforting, perhaps, but illusory to believe that statistical
> > inference can be relied on to give sound, objective scientific
> > results. True, without such a framework, science seems rather
> > subjective, perhaps closer to religion and arbitrary cultural
> > archetypes than we care to admit. But see Thomas Kuhn and Paul
> > Feuerabend for why this is neither surprising nor necessarily a bad
> > thing.
> > 
> > Cheers,
> > Bert Gunter
> > 
> > 
> > 
> > 
> > On Thu, Sep 9, 2010 at 8:00 PM, John Sorkin <jsorkin at grecc.umaryland.edu> 
> >wrote:
> > > windows Vista
> > > R 2.10.1
> > >
> > >
> > > (1) How can I get the complete table of for the fixed effects from lmer. As 
>
> >can be seen from the example below, fixef(fit2) only give the estimates and 
>not 
>
> >the SE or t value
> > >
> > >> fit3<- lmer(y~time + (1|Subject) + (time|Subject),data=data.frame(data))
> > >> summary(fit3)
> > > Linear mixed model fit by REML
> > > Formula: y ~ time + (1 | Subject) + (time | Subject)
> > >   Data: data.frame(data)
> > >    AIC    BIC logLik deviance REMLdev
> > >  -126.2 -116.4   70.1   -152.5  -140.2
> > > Random effects:
> > >  Groups   Name        Variance   Std.Dev.   Corr
> > >  Subject  (Intercept) 2.9311e+01 5.41396385
> > >  Subject  (Intercept) 0.0000e+00 0.00000000
> > >          time        0.0000e+00 0.00000000   NaN
> > >  Residual             8.1591e-07 0.00090328
> > > Number of obs: 30, groups: Subject, 10
> > >
> > > Fixed effects:
> > >             Estimate Std. Error t value
> > > (Intercept) 14.998216   1.712046       9
> > > time        -0.999779   0.000202   -4950
> > >
> > > Correlation of Fixed Effects:
> > >     (Intr)
> > > time -0.001
> > >> fixef(fit3)
> > > (Intercept)        time
> > >  14.9982158  -0.9997793
> > >
> > > (2) lmer does not give p values or confidence intervals for the fixed 
> >effects. How we are to interpret the estimates given that no p value or CI is 

> >given for the estimates?
> > >
> > >
> > >
> > >
> > > John David Sorkin M.D., Ph.D.
> > > Chief, Biostatistics and Informatics
> > > University of Maryland School of Medicine Division of Gerontology
> > > Baltimore VA Medical Center
> > > 10 North Greene Street
> > > GRECC (BT/18/GR)
> > > Baltimore, MD 21201-1524
> > > (Phone) 410-605-7119
> > > (Fax) 410-605-7913 (Please call phone number above prior to faxing)
> > >
> > > Confidentiality Statement:
> > > This email message, including any attachments, is for ...{{dropped:25}}
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 

-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Dr. Gavin Simpson             [t] +44 (0)20 7679 0522
ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From bbolker at gmail.com  Fri Sep 10 22:24:16 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 10 Sep 2010 16:24:16 -0400
Subject: [R-sig-ME] [R] specify the covariance matrix for random effect
In-Reply-To: <5B31EB0C79EAE246A4F1F30667D812CD028CA1600A@sphmail.sph.ualberta.ca>
References: <5B31EB0C79EAE246A4F1F30667D812CD028CA1600A@sphmail.sph.ualberta.ca>
Message-ID: <4C8A93F0.10809@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100910/51eb2d2e/attachment.pl>

From jsorkin at grecc.umaryland.edu  Fri Sep 10 23:22:54 2010
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Fri, 10 Sep 2010 17:22:54 -0400
Subject: [R-sig-ME] gee p values
Message-ID: <4C8A696E020000CB0007421A@medicine.umaryland.edu>

I am sending this Email to r-sig-mixed-models at r-project.org having previously sent it to r-help and it was suggested that I follow up on this listserver. 
windows Vista
R 2.10.1

Is it possible to get p values from gee? Summary(geemodel) does not appear to produce p values (see code at end of this Email message)

I received the following response from Peng:
There are two z-scores reported in the summary: Naive z and Robust z.

pvalue=2*min(pnorm(z-score), 1-pnorm(z-score))   # two-sided test

I replied to Peng as follows:
> Peng,
> If the answer were as simple as you suggest, I would expect that gee would
automatically produce the p
> values. Since gee does not produce the values, I fear that the computation may
be more complex, or perhaps
> computing p values from gee may be controversial. Do you know which, if either
of my speculations is true?
> Thank you,
> John

Ben Bolker responded: 
  May be worth following up on r-sig-mixed-models .  My guess would be
that if you're willing to treat your data set as 'large' (e.g. your
guess is that the 'residual degrees of freedom', whatever that may
mean, are > 40 ), then you could go ahead and use the naive translation
from Z-score to p-value; otherwise it probably devolves to the
usual 'effective residual degrees of freedom for complex multilevel/
smoothing models' can of worms.













> fit4<- gee(y~time, id=Subject, data=data.frame(data))
Beginning Cgee S-function, @(#) geeformula.q 4.13 98/01/27
running glm to get initial regression estimate
(Intercept)        time 
  1.1215614   0.8504413 
> summary(fit4)

 GEE:  GENERALIZED LINEAR MODELS FOR DEPENDENT DATA
 gee S-function, version 4.13 modified 98/01/27 (1998) 

Model:
 Link:                      Identity 
 Variance to Mean Relation: Gaussian 
 Correlation Structure:     Independent 

Call:
gee(formula = y ~ time, id = Subject, data = data.frame(data))

Summary of Residuals:
          Min            1Q        Median            3Q           Max 
-2.5224390768 -1.4384989365 -0.0006304408  1.4385426203  2.5229173416 


Coefficients:
             Estimate Naive S.E.  Naive z Robust S.E.  Robust z
(Intercept) 1.1215614  0.8023886 1.397778  0.31918831  3.513792
time        0.8504413  0.0993967 8.556031  0.03851821 22.078938

Estimated Scale Parameter:  2.642821
Number of Iterations:  1

Working Correlation
     [,1] [,2] [,3]
[1,]    1    0    0
[2,]    0    1    0
[3,]    0    0    1



John David Sorkin M.D., Ph.D.
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)

Confidentiality Statement:
This email message, including any attachments, is for th...{{dropped:6}}



From jsorkin at grecc.umaryland.edu  Fri Sep 10 23:29:37 2010
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Fri, 10 Sep 2010 17:29:37 -0400
Subject: [R-sig-ME] lme, groupedData, random intercept and slope
Message-ID: <4C8A6B01020000CB0007421E@medicine.umaryland.edu>

I previously sent this to r-help. It has been suggested to me that I sent this to the r-sig-mixed-models mailing lisst:

Windows Vista
R 2.10.1

Does the following use of groupedData and lme produce an analysis with both random intercept and slope, or only random slope?


zz<-groupedData(y~time |  Subject,data=data.frame(data),
              labels = list( x = "Time",
                y = "y" ),
              units = list( x = "(yr)", y = "(mm)")
)
plot(zz)

fit10<-lme(zz)
summary(fit10)

Linear mixed-effects model fit by REML
 Data: zz 
        AIC       BIC  logLik
  -123.1942 -115.2010 67.5971

Random effects:
 Formula: ~time | Subject
 Structure: General positive-definite
            StdDev       Corr  
(Intercept) 6.054897e+00 (Intr)
time        4.160662e-05 1     
Residual    9.775954e-04       

Fixed effects: y ~ time 
                Value Std.Error DF   t-value p-value
(Intercept) 15.000217  1.914727 19     7.834       0
time        -1.000051  0.000219 19 -4566.598       0
 Correlation: 
     (Intr)
time 0.059 

Standardized Within-Group Residuals:
        Min          Q1         Med          Q3         Max 
-1.73706837 -0.36289558  0.06892484  0.59777067  1.69095476 

Number of Observations: 30
Number of Groups: 10 


John David Sorkin M.D., Ph.D.
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)

Confidentiality Statement:
This email message, including any attachments, is for th...{{dropped:6}}



From kevin.thorpe at utoronto.ca  Sat Sep 11 00:26:10 2010
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Fri, 10 Sep 2010 18:26:10 -0400
Subject: [R-sig-ME] gee p values
In-Reply-To: <4C8A696E020000CB0007421A@medicine.umaryland.edu>
References: <4C8A696E020000CB0007421A@medicine.umaryland.edu>
Message-ID: <4C8AB082.2010906@utoronto.ca>

On 09/10/2010 05:22 PM, John Sorkin wrote:
> I am sending this Email to r-sig-mixed-models at r-project.org having previously sent it to r-help and it was suggested that I follow up on this listserver.
> windows Vista
> R 2.10.1
>
> Is it possible to get p values from gee? Summary(geemodel) does not appear to produce p values (see code at end of this Email message)
>
> I received the following response from Peng:
> There are two z-scores reported in the summary: Naive z and Robust z.
>
> pvalue=2*min(pnorm(z-score), 1-pnorm(z-score))   # two-sided test
>
> I replied to Peng as follows:
>> Peng,
>> If the answer were as simple as you suggest, I would expect that gee would
> automatically produce the p
>> values. Since gee does not produce the values, I fear that the computation may
> be more complex, or perhaps
>> computing p values from gee may be controversial. Do you know which, if either
> of my speculations is true?
>> Thank you,
>> John

FWIW, I usually use the geepack package for GEE.  It does provide p-values.

>
> Ben Bolker responded:
>    May be worth following up on r-sig-mixed-models .  My guess would be
> that if you're willing to treat your data set as 'large' (e.g. your
> guess is that the 'residual degrees of freedom', whatever that may
> mean, are>  40 ), then you could go ahead and use the naive translation
> from Z-score to p-value; otherwise it probably devolves to the
> usual 'effective residual degrees of freedom for complex multilevel/
> smoothing models' can of worms.
>
>
>
>
>
>
>
>
>
>
>
>
>
>> fit4<- gee(y~time, id=Subject, data=data.frame(data))
> Beginning Cgee S-function, @(#) geeformula.q 4.13 98/01/27
> running glm to get initial regression estimate
> (Intercept)        time
>    1.1215614   0.8504413
>> summary(fit4)
>
>   GEE:  GENERALIZED LINEAR MODELS FOR DEPENDENT DATA
>   gee S-function, version 4.13 modified 98/01/27 (1998)
>
> Model:
>   Link:                      Identity
>   Variance to Mean Relation: Gaussian
>   Correlation Structure:     Independent
>
> Call:
> gee(formula = y ~ time, id = Subject, data = data.frame(data))
>
> Summary of Residuals:
>            Min            1Q        Median            3Q           Max
> -2.5224390768 -1.4384989365 -0.0006304408  1.4385426203  2.5229173416
>
>
> Coefficients:
>               Estimate Naive S.E.  Naive z Robust S.E.  Robust z
> (Intercept) 1.1215614  0.8023886 1.397778  0.31918831  3.513792
> time        0.8504413  0.0993967 8.556031  0.03851821 22.078938
>
> Estimated Scale Parameter:  2.642821
> Number of Iterations:  1
>
> Working Correlation
>       [,1] [,2] [,3]
> [1,]    1    0    0
> [2,]    0    1    0
> [3,]    0    0    1
>
>
>
> John David Sorkin M.D., Ph.D.
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:15}}



From datkins at u.washington.edu  Sat Sep 11 00:24:34 2010
From: datkins at u.washington.edu (David Atkins)
Date: Fri, 10 Sep 2010 15:24:34 -0700
Subject: [R-sig-ME] lme, groupedData, random intercept and slope
In-Reply-To: <4C8A6B01020000CB0007421E@medicine.umaryland.edu>
References: <4C8A6B01020000CB0007421E@medicine.umaryland.edu>
Message-ID: <4C8AB022.9050609@u.washington.edu>


John--

Focusing on the random-effects output (snipped from your post):

Random effects:
  Formula: ~time | Subject
  Structure: General positive-definite
             StdDev       Corr
(Intercept) 6.054897e+00 (Intr)
time        4.160662e-05 1
Residual    9.775954e-04

That is reporting random intercept, random slope (for time), and 
residual error (and that the correlation between intercepts and slopes 
is 1, which usually isn't a good sign...).

Note that those are all on the SD scale (sqrt of variance terms).

If you don't have a copy of Pinheiro and Bates (2000) and plan to use 
nlme, I would strongly suggest tracking one down.

Hope that helps.

cheers, Dave

-- 
Dave Atkins, PhD
Research Associate Professor
Department of Psychiatry and Behavioral Science
University of Washington
datkins at u.washington.edu

Center for the Study of Health and Risk Behaviors (CSHRB)		
1100 NE 45th Street, Suite 300 	
Seattle, WA  98105 	
206-616-3879 	
http://depts.washington.edu/cshrb/
(Mon-Wed)	

Center for Healthcare Improvement, for Addictions, Mental Illness,
   Medically Vulnerable Populations (CHAMMP)
325 9th Avenue, 2HH-15
Box 359911
Seattle, WA 98104
http://www.chammp.org
(Thurs)



From A.Robinson at ms.unimelb.edu.au  Sat Sep 11 01:00:56 2010
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Sat, 11 Sep 2010 09:00:56 +1000
Subject: [R-sig-ME] lme, groupedData, random intercept and slope
In-Reply-To: <4C8AB022.9050609@u.washington.edu>
References: <4C8A6B01020000CB0007421E@medicine.umaryland.edu>
	<4C8AB022.9050609@u.washington.edu>
Message-ID: <20100910230056.GE54737@ms.unimelb.edu.au>

Hi Dave,

on the topic of correlation between random slopes and intercepts, it's
not necessarily bad news.  It may (probably does) indicate that the
data are remote from the origin.  Under those circumstances, an
adjustment to the slope, for example, leads inevitably to adjustment
in the intercept.  

Best wishes

Andrew

On Fri, Sep 10, 2010 at 03:24:34PM -0700, David Atkins wrote:
> 
> John--
> 
> Focusing on the random-effects output (snipped from your post):
> 
> Random effects:
>  Formula: ~time | Subject
>  Structure: General positive-definite
>             StdDev       Corr
> (Intercept) 6.054897e+00 (Intr)
> time        4.160662e-05 1
> Residual    9.775954e-04
> 
> That is reporting random intercept, random slope (for time), and 
> residual error (and that the correlation between intercepts and slopes 
> is 1, which usually isn't a good sign...).
> 
> Note that those are all on the SD scale (sqrt of variance terms).
> 
> If you don't have a copy of Pinheiro and Bates (2000) and plan to use 
> nlme, I would strongly suggest tracking one down.
> 
> Hope that helps.
> 
> cheers, Dave
> 
> -- 
> Dave Atkins, PhD
> Research Associate Professor
> Department of Psychiatry and Behavioral Science
> University of Washington
> datkins at u.washington.edu
> 
> Center for the Study of Health and Risk Behaviors (CSHRB)		
> 1100 NE 45th Street, Suite 300 	
> Seattle, WA  98105 	
> 206-616-3879 	
> http://depts.washington.edu/cshrb/
> (Mon-Wed)	
> 
> Center for Healthcare Improvement, for Addictions, Mental Illness,
>   Medically Vulnerable Populations (CHAMMP)
> 325 9th Avenue, 2HH-15
> Box 359911
> Seattle, WA 98104
> http://www.chammp.org
> (Thurs)
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Andrew Robinson  
Program Manager, ACERA 
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia               (prefer email)
http://www.ms.unimelb.edu.au/~andrewpr              Fax: +61-3-8344-4599
http://www.acera.unimelb.edu.au/



From datkins at u.washington.edu  Sat Sep 11 01:07:23 2010
From: datkins at u.washington.edu (David Atkins)
Date: Fri, 10 Sep 2010 16:07:23 -0700
Subject: [R-sig-ME] lme, groupedData, random intercept and slope
In-Reply-To: <20100910230056.GE54737@ms.unimelb.edu.au>
References: <4C8A6B01020000CB0007421E@medicine.umaryland.edu>
	<4C8AB022.9050609@u.washington.edu>
	<20100910230056.GE54737@ms.unimelb.edu.au>
Message-ID: <4C8ABA2B.40506@u.washington.edu>


On 9/10/10 4:00 PM, Andrew Robinson wrote:
> Hi Dave,
>
> on the topic of correlation between random slopes and intercepts, it's
> not necessarily bad news.  It may (probably does) indicate that the
> data are remote from the origin.  Under those circumstances, an
> adjustment to the slope, for example, leads inevitably to adjustment
> in the intercept.

Fair enough, though in looking at the original post (most of which I had 
snipped out), the data have 10 groups and 30 observations.  Thus, in 
this particular case, I'm inclined to think it's over-parameterized.

More generally, 9 times out of 10 with my own data, a correlation of 1 
in the random-effects means I'm over-fitting.  Though as you note, it's 
certainly worth wondering whether there is an extreme correlation 
induced by radically different scale.

[Almost sort of vaguely remember an example of this early on in P&B...]

cheers, Dave

>
> Best wishes
>
> Andrew
>
> On Fri, Sep 10, 2010 at 03:24:34PM -0700, David Atkins wrote:
>>
>> John--
>>
>> Focusing on the random-effects output (snipped from your post):
>>
>> Random effects:
>>   Formula: ~time | Subject
>>   Structure: General positive-definite
>>              StdDev       Corr
>> (Intercept) 6.054897e+00 (Intr)
>> time        4.160662e-05 1
>> Residual    9.775954e-04
>>
>> That is reporting random intercept, random slope (for time), and
>> residual error (and that the correlation between intercepts and slopes
>> is 1, which usually isn't a good sign...).
>>
>> Note that those are all on the SD scale (sqrt of variance terms).
>>
>> If you don't have a copy of Pinheiro and Bates (2000) and plan to use
>> nlme, I would strongly suggest tracking one down.
>>
>> Hope that helps.
>>
>> cheers, Dave
>>
>> --
>> Dave Atkins, PhD
>> Research Associate Professor
>> Department of Psychiatry and Behavioral Science
>> University of Washington
>> datkins at u.washington.edu
>>
>> Center for the Study of Health and Risk Behaviors (CSHRB)		
>> 1100 NE 45th Street, Suite 300 	
>> Seattle, WA  98105 	
>> 206-616-3879 	
>> http://depts.washington.edu/cshrb/
>> (Mon-Wed)	
>>
>> Center for Healthcare Improvement, for Addictions, Mental Illness,
>>    Medically Vulnerable Populations (CHAMMP)
>> 325 9th Avenue, 2HH-15
>> Box 359911
>> Seattle, WA 98104
>> http://www.chammp.org
>> (Thurs)
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From arrayprofile at yahoo.com  Sat Sep 11 08:51:38 2010
From: arrayprofile at yahoo.com (array chip)
Date: Fri, 10 Sep 2010 23:51:38 -0700 (PDT)
Subject: [R-sig-ME] lme4a package loading error
In-Reply-To: <1284140776.2345.28.camel@desktop.localdomain>
References: <4C88E931.6030400@icr.ac.uk>
	<E18FDA5C64FC5645A25B2B52EB8CC9CE0393DA22A7@EXCHMCA.tirol.local>
	<4C896716020000CB000740F3@medicine.umaryland.edu>
	<AANLkTinii9iAQffTuioy1UD-ZrtCR=_UH41B13h100nE@mail.gmail.com>
	<4C897083020000CB000740FF@medicine.umaryland.edu>
	<1284109537.2409.2.camel@desktop.localdomain>
	<302000.40845.qm@web56308.mail.re3.yahoo.com>
	<1284138015.2345.20.camel@desktop.localdomain>
	<190156.65925.qm@web56301.mail.re3.yahoo.com>
	<1284140776.2345.28.camel@desktop.localdomain>
Message-ID: <170086.93539.qm@web56308.mail.re3.yahoo.com>

Thank you for pointing ou R-forge. I tried link from R-forge for lme4a, it 
doesn't work at the time I tried (Returned "PAGE NOT FOUND".

However, the link for lme4b worked, and I installed lme4b package which can be 
loaded successfully. lme4b has lmer1() instead of lmer().

However, when trying to run lmer1(), it will tell you this?warning message:

Warning message:
model.Matrix() has been moved from package 'Matrix' to the new package
'MatrixModels' which is now loaded (if installed).
? Its use from package 'Matrix' is deprecated.
Do use it from 'MatrixModels' instead. 

I think this?may be?why I got error message when I try to load lme4a, which may 
have not been updated to look for MatrixModels package instead of Matrix 
package.

The reason I posted to both R and R-mixed-models mailing list is that it seems 
that this question?is more suitable?to R-mixed-models, but response there is 
pretty slow,......

Thanks,

John


?


----- Original Message ----
From: Gavin Simpson <gavin.simpson at ucl.ac.uk>
To: array chip <arrayprofile at yahoo.com>
Cc: John Sorkin <jsorkin at grecc.umaryland.edu>; r-help at r-project.org; Bert Gunter 
<gunter.berton at gene.com>
Sent: Fri, September 10, 2010 10:46:16 AM
Subject: Re: lme4a package loading error

On Fri, 2010-09-10 at 10:23 -0700, array chip wrote:
> Thanks for reminding this. So I found lme4a package from Doug's UserR!2010 
> presentation folder: 
> http://lme4.r-forge.r-project.org/slides/2010-07-20-Gaithersburg/pkg/

What is wrong with the one on the packages tab of the lme4 project page:

https://r-forge.r-project.org/R/?group_id=60

?

You might need to make sure you have the latest Matrix as well to run
lme4a. Update Matrix via update.packages() or install the latest version
from r-forge and see if that helps.

Also, try not to cross-post to multiple lists. Stick with one, or move
the thread onto the new list.

HTH

G

> However, after installation, I got the following error message when trying to 
> load the library:
> 
> library(Matrix)
> > library(Rcpp)
> > library(minqa)
> > library(lme4a)
> Error : classes "modelMatrix", "denseModelMatrix", "sparseModelMatrix", 
> "ddenseModelMatrix", "dsparseModelMatrix", "predModule", "dPredModule", 
> "sPredModule", "respModule", "glmRespMod", "nlsRespMod" are not exported by 
> 'namespace:Matrix'
> Error: package/namespace load failed for 'lme4a'
> 
> Here is my sessionInfo()
> > sessionInfo()
> R version 2.11.1 (2010-05-31) 
> i386-pc-mingw32 
> 
> locale:
> [1] LC_COLLATE=English_United States.1252? LC_CTYPE=English_United States.1252? 
>
> 
> [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C? ? ? ? ? ? ? ? ? ? ? ? 
>? 
>
> 
> [5] LC_TIME=English_United States.1252? ? 
> 
> attached base packages:
> [1] stats? ? graphics? grDevices utils? ? datasets? methods? base? ? 
> 
> other attached packages:
> [1] minqa_1.1.9? ? ? ? Rcpp_0.8.6? ? ? ? Matrix_0.999375-43 lattice_0.18-8? ? 
> 
> loaded via a namespace (and not attached):
> [1] grid_2.11.1? ? nlme_3.1-96? ? splines_2.11.1 stats4_2.11.1? tools_2.11.1? 
> 
> Any suggestions would be appreciated.
> 
> John
> 
> 
> 
> 
> 
> ----- Original Message ----
> From: Gavin Simpson <gavin.simpson at ucl.ac.uk>
> To: array chip <arrayprofile at yahoo.com>
> Cc: John Sorkin <jsorkin at grecc.umaryland.edu>; r-help at r-project.org; Bert 
>Gunter 
>
> <gunter.berton at gene.com>
> Sent: Fri, September 10, 2010 10:00:15 AM
> Subject: Re: [R] lmer fixed effects, SE, t . . . and p
> 
> On Fri, 2010-09-10 at 09:51 -0700, array chip wrote:
> > But as far as I know, profile() seems to be de-activated in the lme4 
package.
> 
> It is beta software. The lme4a version of the lme4 "package" might have
> had profile re-enabled, IIRC. 
> 
> G
> 
> > ----- Original Message ----
> > From: Gavin Simpson <gavin.simpson at ucl.ac.uk>
> > To: John Sorkin <jsorkin at grecc.umaryland.edu>
> > Cc: r-help at r-project.org; Bert Gunter <gunter.berton at gene.com>
> > Sent: Fri, September 10, 2010 2:05:37 AM
> > Subject: Re: [R] lmer fixed effects, SE, t . . . and p
> > 
> > On Thu, 2010-09-09 at 23:40 -0400, John Sorkin wrote:
> > > Bert,
> > > I appreciate you comments, and I have read Doug Bates writing about p
> > > values in mixed effects regression. It is precisely because I read
> > > Doug's material that I asked "how are we to interpret the estimates"
> > > rather than "how can we compute a p value". My question is a simple
> > > question whose answer is undoubtedly complex, but one that needs an
> > > answer. Without p values, or confidence intervals, I am not certain
> > > what to make of the results of my analysis. Does my analysis suggest,
> > > or does it not suggest that there is a relation between time and y? If
> > > I can't answer this question after running the analysis, I don't have
> > > any more information than I did before I ran the analysis, and a fair
> > > question would be why did I run the analysis? I am asking for help not
> > > in calculation a p value or a CI, but rather to know what I can and
> > > can't say about the results of the analysis. If this basic question
> > > can not be answered, I am at a loss to interpret my results. 
> > > Thank you,
> > > John
> > 
> > Doug talks quite a lot about profiling lmer fits using 'profile
> > deviance' to investigate variability in fixed effects. For example, see
> > section 1.5 in the draft of chapter 1 of Doug's book on mixed models:
> > 
> > http://lme4.r-forge.r-project.org/book/
> > 
> > HTH
> > 
> > G
> > 
> > > John David Sorkin M.D., Ph.D.
> > > Chief, Biostatistics and Informatics
> > > University of Maryland School of Medicine Division of Gerontology
> > > Baltimore VA Medical Center
> > > 10 North Greene Street
> > > GRECC (BT/18/GR)
> > > Baltimore, MD 21201-1524
> > > (Phone) 410-605-7119
> > > (Fax) 410-605-7913 (Please call phone number above prior to faxing)>>> Bert 
>
> > >Gunter <gunter.berton at gene.com> 9/9/2010 11:21 PM >>>
> > > John:
> > > 
> > > Search on this issue in the list archives. Doug Bates has addressed it
> > > at length. Basically, he does not calculate CI's or p-values because
> > > he does not know how to reliably do so.
> > > 
> > > However, the key remark in your query was:
> > > 
> > > > (2) lmer does not give p values or confidence intervals for the fixed 
> > >effects. How we are to interpret the estimates given that no p value or CI 
>is 
>
> 
> > >given for the estimates?
> > > 
> > > Think about it. A statistical analysis -- ANY statistical analysis --
> > > treats the data in isolation: it is not informed by physics,
> > > thermodynamics, biology,? other similar data, prior experience, or,
> > > indeed, any part of the body of relevant scientific knowledge. Do you
> > > really think that any such analysis, especially when predicated upon
> > > often tenuous or even (necessarily) unverifiable assumptions and
> > > simplifications should be considered authoritative? Classical
> > > statistical inference is just another piece of the puzzle, and not
> > > even particularly useful when, as if typically the case, hypotheses
> > > are formulated AFTER seeing the data (this invalidates the probability
> > > calculations -- hypotheses must be formulated before seeing the data
> > > to be meaningfully assessed). Leo Breiman called this statistics'
> > > "quiet scandal" something like 20 years ago, and he was no dummy.
> > > 
> > > It is comforting, perhaps, but illusory to believe that statistical
> > > inference can be relied on to give sound, objective scientific
> > > results. True, without such a framework, science seems rather
> > > subjective, perhaps closer to religion and arbitrary cultural
> > > archetypes than we care to admit. But see Thomas Kuhn and Paul
> > > Feuerabend for why this is neither surprising nor necessarily a bad
> > > thing.
> > > 
> > > Cheers,
> > > Bert Gunter
> > > 
> > > 
> > > 
> > > 
> > > On Thu, Sep 9, 2010 at 8:00 PM, John Sorkin <jsorkin at grecc.umaryland.edu> 
> > >wrote:
> > > > windows Vista
> > > > R 2.10.1
> > > >
> > > >
> > > > (1) How can I get the complete table of for the fixed effects from lmer. 
>As 
>
> >
> > >can be seen from the example below, fixef(fit2) only give the estimates and 

> >not 
> >
> > >the SE or t value
> > > >
> > > >> fit3<- lmer(y~time + (1|Subject) + 
(time|Subject),data=data.frame(data))
> > > >> summary(fit3)
> > > > Linear mixed model fit by REML
> > > > Formula: y ~ time + (1 | Subject) + (time | Subject)
> > > >? Data: data.frame(data)
> > > >? ? AIC? ? BIC logLik deviance REMLdev
> > > >? -126.2 -116.4? 70.1? -152.5? -140.2
> > > > Random effects:
> > > >? Groups? Name? ? ? ? Variance? Std.Dev.? Corr
> > > >? Subject? (Intercept) 2.9311e+01 5.41396385
> > > >? Subject? (Intercept) 0.0000e+00 0.00000000
> > > >? ? ? ? ? time? ? ? ? 0.0000e+00 0.00000000? NaN
> > > >? Residual? ? ? ? ? ? 8.1591e-07 0.00090328
> > > > Number of obs: 30, groups: Subject, 10
> > > >
> > > > Fixed effects:
> > > >? ? ? ? ? ? Estimate Std. Error t value
> > > > (Intercept) 14.998216? 1.712046? ? ? 9
> > > > time? ? ? ? -0.999779? 0.000202? -4950
> > > >
> > > > Correlation of Fixed Effects:
> > > >? ? (Intr)
> > > > time -0.001
> > > >> fixef(fit3)
> > > > (Intercept)? ? ? ? time
> > > >? 14.9982158? -0.9997793
> > > >
> > > > (2) lmer does not give p values or confidence intervals for the fixed 
> > >effects. How we are to interpret the estimates given that no p value or CI 
>is 
>
> 
> > >given for the estimates?
> > > >
> > > >
> > > >
> > > >
> > > > John David Sorkin M.D., Ph.D.
> > > > Chief, Biostatistics and Informatics
> > > > University of Maryland School of Medicine Division of Gerontology
> > > > Baltimore VA Medical Center
> > > > 10 North Greene Street
> > > > GRECC (BT/18/GR)
> > > > Baltimore, MD 21201-1524
> > > > (Phone) 410-605-7119
> > > > (Fax) 410-605-7913 (Please call phone number above prior to faxing)
> > > >
> > > > Confidentiality Statement:
> > > > This email message, including any attachments, is for ...{{dropped:25}}
> > > 
> > > ______________________________________________
> > > R-help at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide 
>http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > 
> 
> -- 
> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> Dr. Gavin Simpson? ? ? ? ? ? [t] +44 (0)20 7679 0522
> ECRC, UCL Geography,? ? ? ? ? [f] +44 (0)20 7679 0565
> Pearson Building,? ? ? ? ? ? [e] gavin.simpsonATNOSPAMucl.ac.uk
> Gower Street, London? ? ? ? ? [w] http://www.ucl.ac.uk/~ucfagls/
> UK. WC1E 6BT.? ? ? ? ? ? ? ? [w] http://www.freshwaters.org.uk
> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> 
> 
>? ? ? 
> 

-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Dr. Gavin Simpson? ? ? ? ? ? [t] +44 (0)20 7679 0522
ECRC, UCL Geography,? ? ? ? ? [f] +44 (0)20 7679 0565
Pearson Building,? ? ? ? ? ? [e] gavin.simpsonATNOSPAMucl.ac.uk
Gower Street, London? ? ? ? ? [w] http://www.ucl.ac.uk/~ucfagls/
UK. WC1E 6BT.? ? ? ? ? ? ? ? [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%






From weiyu at ualberta.ca  Sat Sep 11 03:07:33 2010
From: weiyu at ualberta.ca (Qiu, Weiyu)
Date: Fri, 10 Sep 2010 19:07:33 -0600
Subject: [R-sig-ME] [R] specify the covariance matrix for random effect
In-Reply-To: <4C8A93F0.10809@gmail.com>
References: <5B31EB0C79EAE246A4F1F30667D812CD028CA1600A@sphmail.sph.ualberta.ca>
	<4C8A93F0.10809@gmail.com>
Message-ID: <5B31EB0C79EAE246A4F1F30667D812CD028CA160CA@sphmail.sph.ualberta.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100910/11588652/attachment.pl>

From haroldozoo at hotmail.com  Sun Sep 12 20:39:47 2010
From: haroldozoo at hotmail.com (Haroldo Neves)
Date: Sun, 12 Sep 2010 15:39:47 -0300
Subject: [R-sig-ME] Hat matrix (lme4)
Message-ID: <SNT133-ds23681C428ACEF12D79528C6760@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100912/24478d83/attachment.pl>

From dmeliza at gmail.com  Tue Sep 14 19:59:12 2010
From: dmeliza at gmail.com (daniel meliza)
Date: Tue, 14 Sep 2010 12:59:12 -0500
Subject: [R-sig-ME] inferences from conditional modes?
Message-ID: <AANLkTin=Vt=jS8D07fihrpAwnDSqPtV8aG+eG1FUgyDg@mail.gmail.com>

Dear mixed-effect modellers,

I have been using a Poisson GLMM to model neuronal response rates in
response to various auditory stimuli.  The data are collected in
trials during which several stimuli are presented; the dependent
variable is the number of action potentials emitted by the neuron
during each stimulus.  The stimuli are chosen from a large library of
sounds, and there is a stimulus-level factor related to the animal's
familiarity with the stimulus.

I'm interested in making two inferences from this data.  One is the
variance in the responses to different stimuli, which is related to
the selectivity of the neuron, and two is the effect of familiarity.
The model I am using looks something like this (see end for runnable
code):

model <- glmer(count ~ fam + (1|stim) + (1|trial), family=poisson)

This gives me inference #2 just fine, but as for #1 I would really
like to know the variance in responses without taking familiarity into
account.  My options seem to be the following, but I'm uncertain which
is most appropriate.

1) Fit a second model that lacks the 'fam' fixed effect for inference
#1.  This seems like double-dipping to me.

2) Add the fixed effect back to the conditional modes for 'stim' and
calculate SD.  However, the SD of the conditional modes is not the
same as the SD for the random effect reported by lmer, and I am not
sure how to correct it.

3) Infer the effects of familiarity from the conditional modes,
presumably by calculating the mean for each group and pooling the
conditional variances.  However, I am aware that the CMs are not
independent samples, so I am back in the same boat as #1.

I appreciate any help anyone can give, as well as all the help I've
received from reading this list.

Regards,

Dan Meliza


#################CODE#####################

require(lme4)

unit <- read.csv('http://meliza.org/files/st321_cell_1_7_2.csv')
unit$fam <- relevel(unit$fam,'unf')

# inference for variance in responses to stims
(fm1 <- glmer(count ~ offset(log(period/1000)) + (1|stim) + (1|trial),
unit, family=poisson))

# inference for familiarity
(fm2 <- glmer(count ~ offset(log(period/1000)) + fam + (1|stim) +
(1|trial), unit, family=poisson))


---------------------------
C Daniel Meliza
Department of Organismal Biology and Anatomy
University of Chicago



From jsorkin at grecc.umaryland.edu  Wed Sep 15 03:05:08 2010
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Tue, 14 Sep 2010 21:05:08 -0400
Subject: [R-sig-ME] Incorrect slope, 0.99 vs. correct slope -0.99,
	due to false	 convergence
Message-ID: <4C8FE384020000CB0007470F@medicine.umaryland.edu>

Windows XP
R 2.10.0

I am running a random effects model (random intercept) on a data set in which each subject has a negative slope (run script below and see graph). When I analyze the data using lme (see end of the script) I get a positive slope (0.99 estimate for time) when the true slope should be close to -1.0. As has been noted before this is because my data are somewhat pathological (the correlation of the intercept and time is -0.889). I believe the incorrect slope is due to false convergence. Is there some way I can specify starting values to the iterative procedure used in lme so as to avoid the false convergence and obtain the correct slope?
Thanks,
John




library(nlme)

########################
# Create data          #
########################
nsub <- 40
data<-matrix(nrow=3*nsub,ncol=3)
dimnames(data)<-list(NULL,c("Subject","time","y"))

# Define time
time<-rep((1:3)/1,nsub)
data[,"time"]<-time

# Define subject
Subject<-rep((1:nsub),3)
data[,"Subject"]<-sort(Subject)

# Define time value
# Add a bit of noise to time values so we can use random intercept and random time
data[,"time"]<-data[,"Subject"]+data[,"time"]+rnorm(3*nsub,0,0.001)

# Define y value
data[,"y"]<-data[,"Subject"]+rep((3:1)/1,nsub) +rnorm(3*nsub,0,0.001)
data

# Plot the data
plot(data[,"time"],data[,"y"],xlab="Time",ylab="y")
title("Each subject has a negative slope")

# Regression of y on x ignoring the fact that the data come from 10 different subjects.
fit0 <- lm(y~time,data=data.frame(data))
summary(fit0)

# Compute subject specific regressions.
for (i in 1:nsub){
fit0 <-  lm(y~time, data=data.frame(data[data[,"Subject"]==i,c("time","y")]))
abline(fit0) # Add sub. specific regression lines to plot.
coefs[i,] <- coef(fit0)
}


######################################################################
######################################################################
# This is lme give a slope (time) of 0.99. The true slope should be  #
# approx. -1.0.                                                      #
######################################################################
fit12c<-lme(y ~ time, random= ~ 1      | Subject, data=data.frame(data))
summary(fit12c)


John David Sorkin M.D., Ph.D.
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)

Confidentiality Statement:
This email message, including any attachments, is for th...{{dropped:6}}



From lborger at uoguelph.ca  Wed Sep 15 04:44:35 2010
From: lborger at uoguelph.ca (Luca Borger)
Date: Tue, 14 Sep 2010 22:44:35 -0400
Subject: [R-sig-ME] Incorrect slope, 0.99 vs. correct slope -0.99,
	due to false	 convergence
References: <4C8FE384020000CB0007470F@medicine.umaryland.edu>
Message-ID: <E616C34EEC804A8BB788E38CC278FA6E@lborger>

Hello,

it appears this is also because you got only three records for each subject. 
If you increase it to just 10, you get a slope exactly -1.0 (and no false 
convergence warning):


so, first using 3 records per subject, but lmer instead of lme:

fit12c <-lmer(y ~ time + (1| Subject), data=data.frame(data))
> fit12c
Linear mixed model fit by REML
Formula: y ~ time + (1 | Subject)
   Data: data.frame(data)
   AIC   BIC logLik deviance REMLdev
 474.5 485.6 -233.2    457.7   466.5
Random effects:
 Groups   Name        Variance Std.Dev.
 Subject  (Intercept) 0.0000   0.0000
 Residual             2.6985   1.6427
Number of obs: 120, groups: Subject, 40

Fixed effects:
            Estimate Std. Error t value
(Intercept)  0.22396    0.32787    0.68
time         0.99004    0.01296   76.40

Correlation of Fixed Effects:
     (Intr)
time -0.889
>

# now, 10 records per subject
#######################################
########################
# Create data          #
########################
nsub <- 40
data<-matrix(nrow=10*nsub,ncol=3)
dimnames(data)<-list(NULL,c("Subject","time","y"))

# Define time
time<-rep((1:10)/1,nsub)
data[,"time"]<-time

# Define subject
Subject<-rep((1:nsub),10)
data[,"Subject"]<-sort(Subject)

# Define time value
# Add a bit of noise to time values so we can use random intercept and 
random time
data[,"time"]<-data[,"Subject"]+data[,"time"]+rnorm(10*nsub,0,0.001)

# Define y value
data[,"y"]<-data[,"Subject"]+rep((10:1)/1,nsub) +rnorm(10*nsub,0,0.001)
data



fit12c <-lmer(y ~ time + (1| Subject), data=data.frame(data))

> fit12c
Linear mixed model fit by REML
Formula: y ~ time + (1 | Subject)
   Data: data.frame(data)
   AIC   BIC logLik deviance REMLdev
 -3190 -3174   1599    -3213   -3198
Random effects:
 Groups   Name        Variance   Std.Dev.
 Subject  (Intercept) 4.9738e+02 22.3020258
 Residual             2.2170e-06  0.0014889
Number of obs: 400, groups: Subject, 40

Fixed effects:
              Estimate Std. Error t value
(Intercept)  5.200e+01  3.526e+00      15
time        -1.000e+00  2.592e-05  -38580

Correlation of Fixed Effects:
     (Intr)
time 0.000
>


fit12d <-lmer(y ~ time + (1+time| Subject), data=data.frame(data))    # 
gives a false convergence warning

> fit12d
Linear mixed model fit by REML
Formula: y ~ time + (1 + time | Subject)
   Data: data.frame(data)
   AIC   BIC logLik deviance REMLdev
 -2567 -2543   1290    -2579   -2579
Random effects:
 Groups   Name        Variance   Std.Dev.   Corr
 Subject  (Intercept) 1.8228e+02 13.5010870
          time        2.6926e-01  0.5189022 0.009
 Residual             2.4337e-06  0.0015600
Number of obs: 400, groups: Subject, 40

Fixed effects:
            Estimate Std. Error t value
(Intercept) 51.99921    2.13471   24.36
time        -0.99997    0.08205  -12.19

Correlation of Fixed Effects:
     (Intr)
time 0.009
>



fit12f <-lmer(y ~ time + (0+time| Subject), data=data.frame(data))    # no 
false convergence warning, but slope estimate is not exactly -1.00 anymore

> fit12f
Linear mixed model fit by REML
Formula: y ~ time + (0 + time | Subject)
   Data: data.frame(data)
  AIC  BIC logLik deviance REMLdev
 2301 2317  -1146     2292    2293
Random effects:
 Groups   Name Variance Std.Dev.
 Subject  time  0.69206 0.8319
 Residual      10.02260 3.1658
Number of obs: 400, groups: Subject, 40

Fixed effects:
            Estimate Std. Error t value
(Intercept)  27.8111     0.9359  29.716
time         -0.3955     0.1393  -2.838

Correlation of Fixed Effects:
     (Intr)
time -0.324
>



fit12g <-lmer(y ~ time + (1| Subject) + (0+time| Subject), 
data=data.frame(data))    # false convergence warning, but slope exactly -1

> fit12g
Linear mixed model fit by REML
Formula: y ~ time + (1 | Subject) + (0 + time | Subject)
   Data: data.frame(data)
   AIC   BIC logLik deviance REMLdev
 -3189 -3169   1600    -3214   -3199
Random effects:
 Groups   Name        Variance   Std.Dev.
 Subject  (Intercept) 5.2392e+02 2.2889e+01
 Subject  time        6.0692e-09 7.7905e-05
 Residual             2.1488e-06 1.4659e-03
Number of obs: 400, groups: Subject, 40

Fixed effects:
              Estimate Std. Error t value
(Intercept)  5.200e+01  3.619e+00      14
time        -1.000e+00  2.834e-05  -35291

Correlation of Fixed Effects:
     (Intr)
time 0.000
>

#############################################




Just my 2 cents, in case this is of any help.




Cheers,

Luca


---------------------------
Luca B?rger, PhD
Postdoctoral Research Fellow
Department of Integrative Biology
University of Guelph
Guelph, Ontario, Canada N1G 2W1

office +1 519 824 4120 ext. 52975
lab     +1 519 824 4120 ext. 53594
fax:     +1 519 767 1656

email: lborger at uoguelph.ca
www.researcherid.com/rid/C-6003-2008
http://uoguelph.academia.edu/LucaBorger
--------------------------------------------------------------------





----- Original Message ----- 
From: "John Sorkin" <jsorkin at grecc.umaryland.edu>
To: <r-sig-mixed-models at r-project.org>
Sent: Tuesday, September 14, 2010 9:05 PM
Subject: [R-sig-ME] Incorrect slope, 0.99 vs. correct slope -0.99,due to 
false convergence


> Windows XP
> R 2.10.0
>
> I am running a random effects model (random intercept) on a data set in 
> which each subject has a negative slope (run script below and see graph). 
> When I analyze the data using lme (see end of the script) I get a positive 
> slope (0.99 estimate for time) when the true slope should be close 
> to -1.0. As has been noted before this is because my data are somewhat 
> pathological (the correlation of the intercept and time is -0.889). I 
> believe the incorrect slope is due to false convergence. Is there some way 
> I can specify starting values to the iterative procedure used in lme so as 
> to avoid the false convergence and obtain the correct slope?
> Thanks,
> John
>
>
>
>
> library(nlme)
>
> ########################
> # Create data          #
> ########################
> nsub <- 40
> data<-matrix(nrow=3*nsub,ncol=3)
> dimnames(data)<-list(NULL,c("Subject","time","y"))
>
> # Define time
> time<-rep((1:3)/1,nsub)
> data[,"time"]<-time
>
> # Define subject
> Subject<-rep((1:nsub),3)
> data[,"Subject"]<-sort(Subject)
>
> # Define time value
> # Add a bit of noise to time values so we can use random intercept and 
> random time
> data[,"time"]<-data[,"Subject"]+data[,"time"]+rnorm(3*nsub,0,0.001)
>
> # Define y value
> data[,"y"]<-data[,"Subject"]+rep((3:1)/1,nsub) +rnorm(3*nsub,0,0.001)
> data
>
> # Plot the data
> plot(data[,"time"],data[,"y"],xlab="Time",ylab="y")
> title("Each subject has a negative slope")
>
> # Regression of y on x ignoring the fact that the data come from 10 
> different subjects.
> fit0 <- lm(y~time,data=data.frame(data))
> summary(fit0)
>
> # Compute subject specific regressions.
> for (i in 1:nsub){
> fit0 <-  lm(y~time, 
> data=data.frame(data[data[,"Subject"]==i,c("time","y")]))
> abline(fit0) # Add sub. specific regression lines to plot.
> coefs[i,] <- coef(fit0)
> }
>
>
> ######################################################################
> ######################################################################
> # This is lme give a slope (time) of 0.99. The true slope should be  #
> # approx. -1.0.                                                      #
> ######################################################################
> fit12c<-lme(y ~ time, random= ~ 1      | Subject, data=data.frame(data))
> summary(fit12c)
>
>
> John David Sorkin M.D., Ph.D.
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
> Confidentiality Statement:
> This email message, including any attachments, is for th...{{dropped:6}}
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From jsorkin at grecc.umaryland.edu  Wed Sep 15 13:03:46 2010
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Wed, 15 Sep 2010 07:03:46 -0400
Subject: [R-sig-ME] Incorrect slope, 0.99 vs. correct slope	 -0.99,
	due to false	 convergence
In-Reply-To: <E616C34EEC804A8BB788E38CC278FA6E@lborger>
References: <4C8FE384020000CB0007470F@medicine.umaryland.edu>
	<E616C34EEC804A8BB788E38CC278FA6E@lborger>
Message-ID: <4C906FCF.91DF.00CB.1@grecc.umaryland.edu>

Luca,
First my thanks for your thoughts.
You are correct that increasing the number of measurements each subject
has from three to ten eliminates the false convergence. While your
solution works, it changes the problem and does not answer my original
question. I have only three observations  per subject, and I would like
to know if it is possible to modify the initial parameters used in the
iterative solution used by lme so that the false convergence does not
occur. The essence of my problem is, I believe, that the variance of the
intercepts is much larger than the residual variance leading to bad
initial parameter estimates and false convergence. I believe that if I
can modify the starting parameters I can get true convergence.
Thank you,
John

John Sorkin M.D., Ph.D.
Chief, Biostatistics and Informatics
Baltimore VA Medical Center GRECC,
University of Maryland School of Medicine Claude D. Pepper OAIC,
University of Maryland Clinical Nutrition Research Unit, and
Baltimore VA Center Stroke of Excellence

University of Maryland School of Medicine
Division of Gerontology
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524

(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)
jsorkin at grecc.umaryland.edu

>>> "Luca Borger" <lborger at uoguelph.ca> 9/14/2010 10:44 PM >>>
Hello,

it appears this is also because you got only three records for each
subject. 
If you increase it to just 10, you get a slope exactly -1.0 (and no
false 
convergence warning):


so, first using 3 records per subject, but lmer instead of lme:

fit12c <-lmer(y ~ time + (1| Subject), data=data.frame(data))
> fit12c
Linear mixed model fit by REML
Formula: y ~ time + (1 | Subject)
   Data: data.frame(data)
   AIC   BIC logLik deviance REMLdev
 474.5 485.6 -233.2    457.7   466.5
Random effects:
 Groups   Name        Variance Std.Dev.
 Subject  (Intercept) 0.0000   0.0000
 Residual             2.6985   1.6427
Number of obs: 120, groups: Subject, 40

Fixed effects:
            Estimate Std. Error t value
(Intercept)  0.22396    0.32787    0.68
time         0.99004    0.01296   76.40

Correlation of Fixed Effects:
     (Intr)
time -0.889
>

# now, 10 records per subject
#######################################
########################
# Create data          #
########################
nsub <- 40
data<-matrix(nrow=10*nsub,ncol=3)
dimnames(data)<-list(NULL,c("Subject","time","y"))

# Define time
time<-rep((1:10)/1,nsub)
data[,"time"]<-time

# Define subject
Subject<-rep((1:nsub),10)
data[,"Subject"]<-sort(Subject)

# Define time value
# Add a bit of noise to time values so we can use random intercept and

random time
data[,"time"]<-data[,"Subject"]+data[,"time"]+rnorm(10*nsub,0,0.001)

# Define y value
data[,"y"]<-data[,"Subject"]+rep((10:1)/1,nsub)
+rnorm(10*nsub,0,0.001)
data



fit12c <-lmer(y ~ time + (1| Subject), data=data.frame(data))

> fit12c
Linear mixed model fit by REML
Formula: y ~ time + (1 | Subject)
   Data: data.frame(data)
   AIC   BIC logLik deviance REMLdev
 -3190 -3174   1599    -3213   -3198
Random effects:
 Groups   Name        Variance   Std.Dev.
 Subject  (Intercept) 4.9738e+02 22.3020258
 Residual             2.2170e-06  0.0014889
Number of obs: 400, groups: Subject, 40

Fixed effects:
              Estimate Std. Error t value
(Intercept)  5.200e+01  3.526e+00      15
time        -1.000e+00  2.592e-05  -38580

Correlation of Fixed Effects:
     (Intr)
time 0.000
>


fit12d <-lmer(y ~ time + (1+time| Subject), data=data.frame(data))    #

gives a false convergence warning

> fit12d
Linear mixed model fit by REML
Formula: y ~ time + (1 + time | Subject)
   Data: data.frame(data)
   AIC   BIC logLik deviance REMLdev
 -2567 -2543   1290    -2579   -2579
Random effects:
 Groups   Name        Variance   Std.Dev.   Corr
 Subject  (Intercept) 1.8228e+02 13.5010870
          time        2.6926e-01  0.5189022 0.009
 Residual             2.4337e-06  0.0015600
Number of obs: 400, groups: Subject, 40

Fixed effects:
            Estimate Std. Error t value
(Intercept) 51.99921    2.13471   24.36
time        -0.99997    0.08205  -12.19

Correlation of Fixed Effects:
     (Intr)
time 0.009
>



fit12f <-lmer(y ~ time + (0+time| Subject), data=data.frame(data))    #
no 
false convergence warning, but slope estimate is not exactly -1.00
anymore

> fit12f
Linear mixed model fit by REML
Formula: y ~ time + (0 + time | Subject)
   Data: data.frame(data)
  AIC  BIC logLik deviance REMLdev
 2301 2317  -1146     2292    2293
Random effects:
 Groups   Name Variance Std.Dev.
 Subject  time  0.69206 0.8319
 Residual      10.02260 3.1658
Number of obs: 400, groups: Subject, 40

Fixed effects:
            Estimate Std. Error t value
(Intercept)  27.8111     0.9359  29.716
time         -0.3955     0.1393  -2.838

Correlation of Fixed Effects:
     (Intr)
time -0.324
>



fit12g <-lmer(y ~ time + (1| Subject) + (0+time| Subject), 
data=data.frame(data))    # false convergence warning, but slope
exactly -1

> fit12g
Linear mixed model fit by REML
Formula: y ~ time + (1 | Subject) + (0 + time | Subject)
   Data: data.frame(data)
   AIC   BIC logLik deviance REMLdev
 -3189 -3169   1600    -3214   -3199
Random effects:
 Groups   Name        Variance   Std.Dev.
 Subject  (Intercept) 5.2392e+02 2.2889e+01
 Subject  time        6.0692e-09 7.7905e-05
 Residual             2.1488e-06 1.4659e-03
Number of obs: 400, groups: Subject, 40

Fixed effects:
              Estimate Std. Error t value
(Intercept)  5.200e+01  3.619e+00      14
time        -1.000e+00  2.834e-05  -35291

Correlation of Fixed Effects:
     (Intr)
time 0.000
>

#############################################




Just my 2 cents, in case this is of any help.




Cheers,

Luca


---------------------------
Luca B?rger, PhD
Postdoctoral Research Fellow
Department of Integrative Biology
University of Guelph
Guelph, Ontario, Canada N1G 2W1

office +1 519 824 4120 ext. 52975
lab     +1 519 824 4120 ext. 53594
fax:     +1 519 767 1656

email: lborger at uoguelph.ca 
www.researcherid.com/rid/C-6003-2008 
http://uoguelph.academia.edu/LucaBorger 
--------------------------------------------------------------------





----- Original Message ----- 
From: "John Sorkin" <jsorkin at grecc.umaryland.edu>
To: <r-sig-mixed-models at r-project.org>
Sent: Tuesday, September 14, 2010 9:05 PM
Subject: [R-sig-ME] Incorrect slope, 0.99 vs. correct slope -0.99,due
to 
false convergence


> Windows XP
> R 2.10.0
>
> I am running a random effects model (random intercept) on a data set
in 
> which each subject has a negative slope (run script below and see
graph). 
> When I analyze the data using lme (see end of the script) I get a
positive 
> slope (0.99 estimate for time) when the true slope should be close 
> to -1.0. As has been noted before this is because my data are
somewhat 
> pathological (the correlation of the intercept and time is -0.889). I

> believe the incorrect slope is due to false convergence. Is there
some way 
> I can specify starting values to the iterative procedure used in lme
so as 
> to avoid the false convergence and obtain the correct slope?
> Thanks,
> John
>
>
>
>
> library(nlme)
>
> ########################
> # Create data          #
> ########################
> nsub <- 40
> data<-matrix(nrow=3*nsub,ncol=3)
> dimnames(data)<-list(NULL,c("Subject","time","y"))
>
> # Define time
> time<-rep((1:3)/1,nsub)
> data[,"time"]<-time
>
> # Define subject
> Subject<-rep((1:nsub),3)
> data[,"Subject"]<-sort(Subject)
>
> # Define time value
> # Add a bit of noise to time values so we can use random intercept
and 
> random time
> data[,"time"]<-data[,"Subject"]+data[,"time"]+rnorm(3*nsub,0,0.001)
>
> # Define y value
> data[,"y"]<-data[,"Subject"]+rep((3:1)/1,nsub)
+rnorm(3*nsub,0,0.001)
> data
>
> # Plot the data
> plot(data[,"time"],data[,"y"],xlab="Time",ylab="y")
> title("Each subject has a negative slope")
>
> # Regression of y on x ignoring the fact that the data come from 10 
> different subjects.
> fit0 <- lm(y~time,data=data.frame(data))
> summary(fit0)
>
> # Compute subject specific regressions.
> for (i in 1:nsub){
> fit0 <-  lm(y~time, 
> data=data.frame(data[data[,"Subject"]==i,c("time","y")]))
> abline(fit0) # Add sub. specific regression lines to plot.
> coefs[i,] <- coef(fit0)
> }
>
>
>
######################################################################
>
######################################################################
> # This is lme give a slope (time) of 0.99. The true slope should be 
#
> # approx. -1.0.                                                     
#
>
######################################################################
> fit12c<-lme(y ~ time, random= ~ 1      | Subject,
data=data.frame(data))
> summary(fit12c)
>
>
> John David Sorkin M.D., Ph.D.
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
> Confidentiality Statement:
> This email message, including any attachments, is for\...{{dropped:16}}



From lborger at uoguelph.ca  Wed Sep 15 13:31:16 2010
From: lborger at uoguelph.ca (Luca Borger)
Date: Wed, 15 Sep 2010 07:31:16 -0400
Subject: [R-sig-ME] Incorrect slope, 0.99 vs. correct slope -0.99,
	due to false	 convergence
References: <4C8FE384020000CB0007470F@medicine.umaryland.edu>
	<E616C34EEC804A8BB788E38CC278FA6E@lborger>
	<4C906FCF.91DF.00CB.1@grecc.umaryland.edu>
Message-ID: <BCA5B271E77F4E0CA56ACE2CE68DC52D@lborger>

Hello,

I forgot the starting values question ;-)


How about (but please check this is actually appropriate):

## no starting values
fit12b<-lmer(y ~ time + (1| Subject),
data=data.frame(data),verbose = TRUE)

  0:     514.30292: 0.942809
  1:     466.47314:  0.00000
  2:     466.47314:  0.00000

> summary(fit12b)
Linear mixed model fit by REML
Formula: y ~ time + (1 | Subject)
   Data: data.frame(data)
   AIC   BIC logLik deviance REMLdev
 474.5 485.6 -233.2    457.6   466.5
Random effects:
 Groups   Name        Variance Std.Dev.
 Subject  (Intercept) 0.0000   0.0000
 Residual             2.6983   1.6427
Number of obs: 120, groups: Subject, 40

Fixed effects:
            Estimate Std. Error t value
(Intercept)  0.22386    0.32786    0.68
time         0.99005    0.01296   76.40

Correlation of Fixed Effects:
     (Intr)
time -0.889
>



#### with starting value
 fit12c<-lmer(y ~ time + (1|Subject), start = (50),
data=data.frame(data), verbose = TRUE)

  0:     378.91223:  50.0000
  1:     369.93186:  53.0381
  2:     303.05576:  81.8034
  3:     221.14500:  138.040
  4:     146.49123:  221.786
  5:     69.694894:  360.911
  6:    -5.9883317:  583.179
  7:    -81.547428:  942.393
  8:    -156.62461:  1522.07
  9:    -229.86189:  2445.53
 10:    -298.29322:  3868.55
 11:    -359.72808:  6047.84
 12:    -404.16415:  8866.56
 13:    -431.83889:  12188.6
 14:    -443.87889:  14943.8
 15:    -453.39962:  23592.1
 16:    -453.41087:  23528.7
 17:    -453.49005:  22563.6
 18:    -453.49030:  22592.6
 19:    -453.49032:       22591.
 20:    -453.49032:       22591.
 21:    -453.49032:       22591.

> summary(fit12c)
Linear mixed model fit by REML
Formula: y ~ time + (1 | Subject)
   Data: data.frame(data)
    AIC    BIC logLik deviance REMLdev
 -445.5 -434.3  226.7   -465.3  -453.5
Random effects:
 Groups   Name        Variance   Std.Dev.
 Subject  (Intercept) 5.4560e+02 23.3581476
 Residual             1.0691e-06  0.0010340
Number of obs: 120, groups: Subject, 40

Fixed effects:
              Estimate Std. Error t value
(Intercept) 45.0002761  3.6932472      12
time        -1.0000095  0.0001156   -8651

Correlation of Fixed Effects:
     (Intr)
time -0.001
>


HTH


Cheers,

Luca

----- Original Message ----- 
From: "John Sorkin" <jsorkin at grecc.umaryland.edu>
To: <r-sig-mixed-models at r-project.org>; "Luca Borger" <lborger at uoguelph.ca>
Sent: Wednesday, September 15, 2010 7:03 AM
Subject: Re: [R-sig-ME] Incorrect slope, 0.99 vs. correct slope -0.99,due to 
false convergence


> Luca,
> First my thanks for your thoughts.
> You are correct that increasing the number of measurements each subject
> has from three to ten eliminates the false convergence. While your
> solution works, it changes the problem and does not answer my original
> question. I have only three observations  per subject, and I would like
> to know if it is possible to modify the initial parameters used in the
> iterative solution used by lme so that the false convergence does not
> occur. The essence of my problem is, I believe, that the variance of the
> intercepts is much larger than the residual variance leading to bad
> initial parameter estimates and false convergence. I believe that if I
> can modify the starting parameters I can get true convergence.
> Thank you,
> John
>
> John Sorkin M.D., Ph.D.
> Chief, Biostatistics and Informatics
> Baltimore VA Medical Center GRECC,
> University of Maryland School of Medicine Claude D. Pepper OAIC,
> University of Maryland Clinical Nutrition Research Unit, and
> Baltimore VA Center Stroke of Excellence
>
> University of Maryland School of Medicine
> Division of Gerontology
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
>
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
> jsorkin at grecc.umaryland.edu
>
>>>> "Luca Borger" <lborger at uoguelph.ca> 9/14/2010 10:44 PM >>>
> Hello,
>
> it appears this is also because you got only three records for each
> subject.
> If you increase it to just 10, you get a slope exactly -1.0 (and no
> false
> convergence warning):
>
>
> so, first using 3 records per subject, but lmer instead of lme:
>
> fit12c <-lmer(y ~ time + (1| Subject), data=data.frame(data))
>> fit12c
> Linear mixed model fit by REML
> Formula: y ~ time + (1 | Subject)
>   Data: data.frame(data)
>   AIC   BIC logLik deviance REMLdev
> 474.5 485.6 -233.2    457.7   466.5
> Random effects:
> Groups   Name        Variance Std.Dev.
> Subject  (Intercept) 0.0000   0.0000
> Residual             2.6985   1.6427
> Number of obs: 120, groups: Subject, 40
>
> Fixed effects:
>            Estimate Std. Error t value
> (Intercept)  0.22396    0.32787    0.68
> time         0.99004    0.01296   76.40
>
> Correlation of Fixed Effects:
>     (Intr)
> time -0.889
>>
>
> # now, 10 records per subject
> #######################################
> ########################
> # Create data          #
> ########################
> nsub <- 40
> data<-matrix(nrow=10*nsub,ncol=3)
> dimnames(data)<-list(NULL,c("Subject","time","y"))
>
> # Define time
> time<-rep((1:10)/1,nsub)
> data[,"time"]<-time
>
> # Define subject
> Subject<-rep((1:nsub),10)
> data[,"Subject"]<-sort(Subject)
>
> # Define time value
> # Add a bit of noise to time values so we can use random intercept and
>
> random time
> data[,"time"]<-data[,"Subject"]+data[,"time"]+rnorm(10*nsub,0,0.001)
>
> # Define y value
> data[,"y"]<-data[,"Subject"]+rep((10:1)/1,nsub)
> +rnorm(10*nsub,0,0.001)
> data
>
>
>
> fit12c <-lmer(y ~ time + (1| Subject), data=data.frame(data))
>
>> fit12c
> Linear mixed model fit by REML
> Formula: y ~ time + (1 | Subject)
>   Data: data.frame(data)
>   AIC   BIC logLik deviance REMLdev
> -3190 -3174   1599    -3213   -3198
> Random effects:
> Groups   Name        Variance   Std.Dev.
> Subject  (Intercept) 4.9738e+02 22.3020258
> Residual             2.2170e-06  0.0014889
> Number of obs: 400, groups: Subject, 40
>
> Fixed effects:
>              Estimate Std. Error t value
> (Intercept)  5.200e+01  3.526e+00      15
> time        -1.000e+00  2.592e-05  -38580
>
> Correlation of Fixed Effects:
>     (Intr)
> time 0.000
>>
>
>
> fit12d <-lmer(y ~ time + (1+time| Subject), data=data.frame(data))    #
>
> gives a false convergence warning
>
>> fit12d
> Linear mixed model fit by REML
> Formula: y ~ time + (1 + time | Subject)
>   Data: data.frame(data)
>   AIC   BIC logLik deviance REMLdev
> -2567 -2543   1290    -2579   -2579
> Random effects:
> Groups   Name        Variance   Std.Dev.   Corr
> Subject  (Intercept) 1.8228e+02 13.5010870
>          time        2.6926e-01  0.5189022 0.009
> Residual             2.4337e-06  0.0015600
> Number of obs: 400, groups: Subject, 40
>
> Fixed effects:
>            Estimate Std. Error t value
> (Intercept) 51.99921    2.13471   24.36
> time        -0.99997    0.08205  -12.19
>
> Correlation of Fixed Effects:
>     (Intr)
> time 0.009
>>
>
>
>
> fit12f <-lmer(y ~ time + (0+time| Subject), data=data.frame(data))    #
> no
> false convergence warning, but slope estimate is not exactly -1.00
> anymore
>
>> fit12f
> Linear mixed model fit by REML
> Formula: y ~ time + (0 + time | Subject)
>   Data: data.frame(data)
>  AIC  BIC logLik deviance REMLdev
> 2301 2317  -1146     2292    2293
> Random effects:
> Groups   Name Variance Std.Dev.
> Subject  time  0.69206 0.8319
> Residual      10.02260 3.1658
> Number of obs: 400, groups: Subject, 40
>
> Fixed effects:
>            Estimate Std. Error t value
> (Intercept)  27.8111     0.9359  29.716
> time         -0.3955     0.1393  -2.838
>
> Correlation of Fixed Effects:
>     (Intr)
> time -0.324
>>
>
>
>
> fit12g <-lmer(y ~ time + (1| Subject) + (0+time| Subject),
> data=data.frame(data))    # false convergence warning, but slope
> exactly -1
>
>> fit12g
> Linear mixed model fit by REML
> Formula: y ~ time + (1 | Subject) + (0 + time | Subject)
>   Data: data.frame(data)
>   AIC   BIC logLik deviance REMLdev
> -3189 -3169   1600    -3214   -3199
> Random effects:
> Groups   Name        Variance   Std.Dev.
> Subject  (Intercept) 5.2392e+02 2.2889e+01
> Subject  time        6.0692e-09 7.7905e-05
> Residual             2.1488e-06 1.4659e-03
> Number of obs: 400, groups: Subject, 40
>
> Fixed effects:
>              Estimate Std. Error t value
> (Intercept)  5.200e+01  3.619e+00      14
> time        -1.000e+00  2.834e-05  -35291
>
> Correlation of Fixed Effects:
>     (Intr)
> time 0.000
>>
>
> #############################################
>
>
>
>
> Just my 2 cents, in case this is of any help.
>
>
>
>
> Cheers,
>
> Luca
>
>
> ---------------------------
> Luca B?rger, PhD
> Postdoctoral Research Fellow
> Department of Integrative Biology
> University of Guelph
> Guelph, Ontario, Canada N1G 2W1
>
> office +1 519 824 4120 ext. 52975
> lab     +1 519 824 4120 ext. 53594
> fax:     +1 519 767 1656
>
> email: lborger at uoguelph.ca
> www.researcherid.com/rid/C-6003-2008
> http://uoguelph.academia.edu/LucaBorger
> --------------------------------------------------------------------
>
>
>
>
>
> ----- Original Message ----- 
> From: "John Sorkin" <jsorkin at grecc.umaryland.edu>
> To: <r-sig-mixed-models at r-project.org>
> Sent: Tuesday, September 14, 2010 9:05 PM
> Subject: [R-sig-ME] Incorrect slope, 0.99 vs. correct slope -0.99,due
> to
> false convergence
>
>
>> Windows XP
>> R 2.10.0
>>
>> I am running a random effects model (random intercept) on a data set
> in
>> which each subject has a negative slope (run script below and see
> graph).
>> When I analyze the data using lme (see end of the script) I get a
> positive
>> slope (0.99 estimate for time) when the true slope should be close
>> to -1.0. As has been noted before this is because my data are
> somewhat
>> pathological (the correlation of the intercept and time is -0.889). I
>
>> believe the incorrect slope is due to false convergence. Is there
> some way
>> I can specify starting values to the iterative procedure used in lme
> so as
>> to avoid the false convergence and obtain the correct slope?
>> Thanks,
>> John
>>
>>
>>
>>
>> library(nlme)
>>
>> ########################
>> # Create data          #
>> ########################
>> nsub <- 40
>> data<-matrix(nrow=3*nsub,ncol=3)
>> dimnames(data)<-list(NULL,c("Subject","time","y"))
>>
>> # Define time
>> time<-rep((1:3)/1,nsub)
>> data[,"time"]<-time
>>
>> # Define subject
>> Subject<-rep((1:nsub),3)
>> data[,"Subject"]<-sort(Subject)
>>
>> # Define time value
>> # Add a bit of noise to time values so we can use random intercept
> and
>> random time
>> data[,"time"]<-data[,"Subject"]+data[,"time"]+rnorm(3*nsub,0,0.001)
>>
>> # Define y value
>> data[,"y"]<-data[,"Subject"]+rep((3:1)/1,nsub)
> +rnorm(3*nsub,0,0.001)
>> data
>>
>> # Plot the data
>> plot(data[,"time"],data[,"y"],xlab="Time",ylab="y")
>> title("Each subject has a negative slope")
>>
>> # Regression of y on x ignoring the fact that the data come from 10
>> different subjects.
>> fit0 <- lm(y~time,data=data.frame(data))
>> summary(fit0)
>>
>> # Compute subject specific regressions.
>> for (i in 1:nsub){
>> fit0 <-  lm(y~time,
>> data=data.frame(data[data[,"Subject"]==i,c("time","y")]))
>> abline(fit0) # Add sub. specific regression lines to plot.
>> coefs[i,] <- coef(fit0)
>> }
>>
>>
>>
> ######################################################################
>>
> ######################################################################
>> # This is lme give a slope (time) of 0.99. The true slope should be
> #
>> # approx. -1.0.
> #
>>
> ######################################################################
>> fit12c<-lme(y ~ time, random= ~ 1      | Subject,
> data=data.frame(data))
>> summary(fit12c)
>>
>>
>> John David Sorkin M.D., Ph.D.
>> Chief, Biostatistics and Informatics
>> University of Maryland School of Medicine Division of Gerontology
>> Baltimore VA Medical Center
>> 10 North Greene Street
>> GRECC (BT/18/GR)
>> Baltimore, MD 21201-1524
>> (Phone) 410-605-7119
>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>>
>> Confidentiality Statement:
>> This email message, including any attachments, is for
> th...{{dropped:6}}
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:7}}



From julie.morand-ferron at zoo.ox.ac.uk  Wed Sep 15 16:49:25 2010
From: julie.morand-ferron at zoo.ox.ac.uk (Julie Morand-Ferron)
Date: Wed, 15 Sep 2010 15:49:25 +0100
Subject: [R-sig-ME] FW: random slopes with lme4
Message-ID: <2D25462751476A4DBD9396FC3163296924686E5D33@EXMBX06.ad.oak.ox.ac.uk>

Dear all,
I would like to share this reply from Dr Bolker with members of the list:

I wrote: 
I cannot find a confirmation that the logic of the procedure one would use to test the significance of random slopes with linear mixed-models in package nlme (i.e. comparing 2 identical models differing only in the random slope component with anova(model1,model2)) is also correct for glmm in lme4?

Dr Bolker:
  Yes, the logic of comparison should be the same in both cases.  The
usual caveats apply: (1) the likelihood ratio test
is asymptotic (analogous to assuming infinite 'denominator degrees of
freedom' in an F test); (2) likelihood ratio test
comparisons where the null hypothesis is at the boundary of the feasible
set (in this case NH = (variance of 'centcond' response
across individuals equals 0)) are conservative (increased type II error)
by approximately a factor of 2.  See <http://glmm.wikidot.com/faq> ...



Julie Morand-Ferron

Postdoctoral researcher
Edward Grey Institute
Department of Zoology
Oxford University
South Parks Road
Oxford, OX1 3PS

Tel: 01865 281999
Fax: 01865 271168


From arrayprofile at yahoo.com  Fri Sep 17 20:39:17 2010
From: arrayprofile at yahoo.com (array chip)
Date: Fri, 17 Sep 2010 11:39:17 -0700 (PDT)
Subject: [R-sig-ME] lmer() vs. lme() gave different variance component
	estimates
Message-ID: <851867.90179.qm@web56305.mail.re3.yahoo.com>

Hi, I have a dataset of animals receiving some eye treatments. There are 8 
treatments, each animal's right and left eye was measured with some scores 
(ranging from 0 to 7) 4 times after treatment. So there are nesting groups eyes 
within animal. Dataset attached

> dat<-read.table("dat.txt",sep='\t',header=T,row.names=1)
> dat$id<-factor(dat$id)
> str(dat)
'data.frame':   640 obs. of  5 variables:
 $ score: int  0 2 0 7 4 7 0 2 0 7 ...
 $ id   : Factor w/ 80 levels "1","3","6","10",..: 7 48 66 54 18 26 38 52 39 63 
...
 $ rep  : int  1 1 1 1 1 1 1 1 1 1 ...
 $ eye  : Factor w/ 2 levels "L","R": 2 2 2 2 2 2 2 2 2 2 ...
 $ trt  : Factor w/ 8 levels "A","B","C","Control",..: 1 1 1 1 1 1 1 1 1 1 ...

I fit a mixed model using both lmer() from lme4 package and lme() from nlme 
package:

> lmer(score~trt+(1|id/eye),dat)

Linear mixed model fit by REML 
Formula: score ~ trt + (1 | id/eye) 
   Data: dat 
   AIC   BIC logLik deviance REMLdev
 446.7 495.8 -212.4    430.9   424.7
Random effects:
 Groups   Name        Variance   Std.Dev.      
 eye:id   (Intercept) 6.9208e+00 2.630742315798
 id       (Intercept) 1.4471e-16 0.000000012030
 Residual             1.8750e-02 0.136930641909
Number of obs: 640, groups: eye:id, 160; id, 80

> summary(lme(score~trt, random=(~1|id/eye), dat))

Linear mixed-effects model fit by REML
 Data: dat 
       AIC      BIC    logLik
  425.1569 474.0947 -201.5785

Random effects:
 Formula: ~1 | id
        (Intercept)
StdDev:    1.873576

 Formula: ~1 | eye %in% id
        (Intercept)  Residual
StdDev:    1.896126 0.1369306

As you can see, the variance components estimates of random effects are quite 
different between the 2 model fits. From the data, I know that the variance 
component for "id" can't be near 0, which is what lmer() fit produced, so I 
think the lme() fit is correct while lmer() fit is off. This can also be seen 
from AIC, BIC etc. lme() fit has better values than lmer() fit. 


I guess this might be due to lmer() didn't converge very well, is there anyway 
to adjust to make lmer() converge better to get similar results as lme()?

Thanks

John


      
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: dat.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100917/4662c616/attachment.txt>

From reinhold.kliegl at gmail.com  Fri Sep 17 21:14:13 2010
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Fri, 17 Sep 2010 21:14:13 +0200
Subject: [R-sig-ME] lmer() vs. lme() gave different variance component
	estimates
In-Reply-To: <851867.90179.qm@web56305.mail.re3.yahoo.com>
References: <851867.90179.qm@web56305.mail.re3.yahoo.com>
Message-ID: <AANLkTikcWBPYYpqJmi=5mbYZ3zty2vd8wUX95uP1-G3d@mail.gmail.com>

Not on my computer. Perhaps you could provide sessionInfo()?

> lmer(score~trt+(1|id/eye), dat)
Linear mixed model fit by REML
Formula: score ~ trt + (1 | id/eye)
   Data: dat
   AIC   BIC logLik deviance REMLdev
 425.2 474.2 -201.6    412.7   403.2
Random effects:
 Groups   Name        Variance Std.Dev.
 eye:id   (Intercept) 3.59532  1.89613
 id       (Intercept) 3.51024  1.87356
 Residual             0.01875  0.13693
Number of obs: 640, groups: eye:id, 160; id, 80

> sessionInfo()
R version 2.11.1 Patched (2010-07-16 r52550)
x86_64-apple-darwin9.8.0

locale:
[1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_0.999375-34   Matrix_0.999375-43 lattice_0.18-8

loaded via a namespace (and not attached):
[1] grid_2.11.1   nlme_3.1-96   stats4_2.11.1 tools_2.11.1

Reinhold Kliegl


On Fri, Sep 17, 2010 at 8:39 PM, array chip <arrayprofile at yahoo.com> wrote:
> Hi, I have a dataset of animals receiving some eye treatments. There are 8
> treatments, each animal's right and left eye was measured with some scores
> (ranging from 0 to 7) 4 times after treatment. So there are nesting groups eyes
> within animal. Dataset attached
>
>> dat<-read.table("dat.txt",sep='\t',header=T,row.names=1)
>> dat$id<-factor(dat$id)
>> str(dat)
> 'data.frame': ? 640 obs. of ?5 variables:
> ?$ score: int ?0 2 0 7 4 7 0 2 0 7 ...
> ?$ id ? : Factor w/ 80 levels "1","3","6","10",..: 7 48 66 54 18 26 38 52 39 63
> ...
> ?$ rep ?: int ?1 1 1 1 1 1 1 1 1 1 ...
> ?$ eye ?: Factor w/ 2 levels "L","R": 2 2 2 2 2 2 2 2 2 2 ...
> ?$ trt ?: Factor w/ 8 levels "A","B","C","Control",..: 1 1 1 1 1 1 1 1 1 1 ...
>
> I fit a mixed model using both lmer() from lme4 package and lme() from nlme
> package:
>
>> lmer(score~trt+(1|id/eye),dat)
>
> Linear mixed model fit by REML
> Formula: score ~ trt + (1 | id/eye)
> ? Data: dat
> ? AIC ? BIC logLik deviance REMLdev
> ?446.7 495.8 -212.4 ? ?430.9 ? 424.7
> Random effects:
> ?Groups ? Name ? ? ? ?Variance ? Std.Dev.
> ?eye:id ? (Intercept) 6.9208e+00 2.630742315798
> ?id ? ? ? (Intercept) 1.4471e-16 0.000000012030
> ?Residual ? ? ? ? ? ? 1.8750e-02 0.136930641909
> Number of obs: 640, groups: eye:id, 160; id, 80
>
>> summary(lme(score~trt, random=(~1|id/eye), dat))
>
> Linear mixed-effects model fit by REML
> ?Data: dat
> ? ? ? AIC ? ? ?BIC ? ?logLik
> ?425.1569 474.0947 -201.5785
>
> Random effects:
> ?Formula: ~1 | id
> ? ? ? ?(Intercept)
> StdDev: ? ?1.873576
>
> ?Formula: ~1 | eye %in% id
> ? ? ? ?(Intercept) ?Residual
> StdDev: ? ?1.896126 0.1369306
>
> As you can see, the variance components estimates of random effects are quite
> different between the 2 model fits. From the data, I know that the variance
> component for "id" can't be near 0, which is what lmer() fit produced, so I
> think the lme() fit is correct while lmer() fit is off. This can also be seen
> from AIC, BIC etc. lme() fit has better values than lmer() fit.
>
>
> I guess this might be due to lmer() didn't converge very well, is there anyway
> to adjust to make lmer() converge better to get similar results as lme()?
>
> Thanks
>
> John
>
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



From dmsilv at gmail.com  Fri Sep 17 21:20:12 2010
From: dmsilv at gmail.com (Daniel)
Date: Fri, 17 Sep 2010 16:20:12 -0300
Subject: [R-sig-ME] lmer() vs. lme() gave different variance component
	estimates
In-Reply-To: <851867.90179.qm@web56305.mail.re3.yahoo.com>
References: <851867.90179.qm@web56305.mail.re3.yahoo.com>
Message-ID: <AANLkTin+u1KTJ2-td1o3nLdLdSo1Rx3BVGaQHzogT7M7@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100917/f845a89e/attachment.pl>

From arrayprofile at yahoo.com  Fri Sep 17 21:33:38 2010
From: arrayprofile at yahoo.com (array chip)
Date: Fri, 17 Sep 2010 12:33:38 -0700 (PDT)
Subject: [R-sig-ME] lmer() vs. lme() gave different variance component
	estimates
In-Reply-To: <AANLkTikcWBPYYpqJmi=5mbYZ3zty2vd8wUX95uP1-G3d@mail.gmail.com>
References: <851867.90179.qm@web56305.mail.re3.yahoo.com>
	<AANLkTikcWBPYYpqJmi=5mbYZ3zty2vd8wUX95uP1-G3d@mail.gmail.com>
Message-ID: <889816.11434.qm@web56307.mail.re3.yahoo.com>

Hi, Reinhold and Daniel,

I just re-installed lme4 package, still got different results than yours.

Here is my sessionInfo():

R version 2.11.1 (2010-05-31) 
i386-pc-mingw32 

locale:
[1] LC_COLLATE=English_United States.1252 
[2] LC_CTYPE=English_United States.1252   
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C                          
[5] LC_TIME=English_United States.1252    

attached base packages:
[1] stats     graphics  grDevices datasets  utils     methods   base     

other attached packages:
[1] lme4_0.999375-35   Matrix_0.999375-43 lattice_0.18-8    

loaded via a namespace (and not attached):
[1] grid_2.11.1   nlme_3.1-96   stats4_2.11.1

John









----- Original Message ----
From: Reinhold Kliegl <reinhold.kliegl at gmail.com>
To: array chip <arrayprofile at yahoo.com>
Cc: r-sig-mixed-models at r-project.org
Sent: Fri, September 17, 2010 12:14:13 PM
Subject: Re: [R-sig-ME] lmer() vs. lme() gave different variance component 
estimates

Not on my computer. Perhaps you could provide sessionInfo()?

> lmer(score~trt+(1|id/eye), dat)
Linear mixed model fit by REML
Formula: score ~ trt + (1 | id/eye)
   Data: dat
   AIC   BIC logLik deviance REMLdev
425.2 474.2 -201.6    412.7   403.2
Random effects:
Groups   Name        Variance Std.Dev.
eye:id   (Intercept) 3.59532  1.89613
id       (Intercept) 3.51024  1.87356
Residual             0.01875  0.13693
Number of obs: 640, groups: eye:id, 160; id, 80

> sessionInfo()
R version 2.11.1 Patched (2010-07-16 r52550)
x86_64-apple-darwin9.8.0

locale:
[1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_0.999375-34   Matrix_0.999375-43 lattice_0.18-8

loaded via a namespace (and not attached):
[1] grid_2.11.1   nlme_3.1-96   stats4_2.11.1 tools_2.11.1

Reinhold Kliegl


On Fri, Sep 17, 2010 at 8:39 PM, array chip <arrayprofile at yahoo.com> wrote:
> Hi, I have a dataset of animals receiving some eye treatments. There are 8
> treatments, each animal's right and left eye was measured with some scores
> (ranging from 0 to 7) 4 times after treatment. So there are nesting groups 
eyes
> within animal. Dataset attached
>
>> dat<-read.table("dat.txt",sep='\t',header=T,row.names=1)
>> dat$id<-factor(dat$id)
>> str(dat)
> 'data.frame':   640 obs. of  5 variables:
>  $ score: int  0 2 0 7 4 7 0 2 0 7 ...
>  $ id   : Factor w/ 80 levels "1","3","6","10",..: 7 48 66 54 18 26 38 52 39 
63
> ...
>  $ rep  : int  1 1 1 1 1 1 1 1 1 1 ...
>  $ eye  : Factor w/ 2 levels "L","R": 2 2 2 2 2 2 2 2 2 2 ...
>  $ trt  : Factor w/ 8 levels "A","B","C","Control",..: 1 1 1 1 1 1 1 1 1 1 ...
>
> I fit a mixed model using both lmer() from lme4 package and lme() from nlme
> package:
>
>> lmer(score~trt+(1|id/eye),dat)
>
> Linear mixed model fit by REML
> Formula: score ~ trt + (1 | id/eye)
>   Data: dat
>   AIC   BIC logLik deviance REMLdev
>  446.7 495.8 -212.4    430.9   424.7
> Random effects:
>  Groups   Name        Variance   Std.Dev.
>  eye:id   (Intercept) 6.9208e+00 2.630742315798
>  id       (Intercept) 1.4471e-16 0.000000012030
>  Residual             1.8750e-02 0.136930641909
> Number of obs: 640, groups: eye:id, 160; id, 80
>
>> summary(lme(score~trt, random=(~1|id/eye), dat))
>
> Linear mixed-effects model fit by REML
>  Data: dat
>       AIC      BIC    logLik
>  425.1569 474.0947 -201.5785
>
> Random effects:
>  Formula: ~1 | id
>        (Intercept)
> StdDev:    1.873576
>
>  Formula: ~1 | eye %in% id
>        (Intercept)  Residual
> StdDev:    1.896126 0.1369306
>
> As you can see, the variance components estimates of random effects are quite
> different between the 2 model fits. From the data, I know that the variance
> component for "id" can't be near 0, which is what lmer() fit produced, so I
> think the lme() fit is correct while lmer() fit is off. This can also be seen
> from AIC, BIC etc. lme() fit has better values than lmer() fit.
>
>
> I guess this might be due to lmer() didn't converge very well, is there anyway
> to adjust to make lmer() converge better to get similar results as lme()?
>
> Thanks
>
> John
>
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



From dmsilv at gmail.com  Fri Sep 17 21:57:59 2010
From: dmsilv at gmail.com (Daniel)
Date: Fri, 17 Sep 2010 16:57:59 -0300
Subject: [R-sig-ME] lmer() vs. lme() gave different variance component
	estimates
In-Reply-To: <889816.11434.qm@web56307.mail.re3.yahoo.com>
References: <851867.90179.qm@web56305.mail.re3.yahoo.com>
	<AANLkTikcWBPYYpqJmi=5mbYZ3zty2vd8wUX95uP1-G3d@mail.gmail.com>
	<889816.11434.qm@web56307.mail.re3.yahoo.com>
Message-ID: <AANLkTimQF2AdGjeSiBxec5sdz1=2Y8fWz2p52d-pNV90@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100917/c6623ba6/attachment.pl>

From A.Robinson at ms.unimelb.edu.au  Sat Sep 18 22:34:09 2010
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Sun, 19 Sep 2010 06:34:09 +1000
Subject: [R-sig-ME] lmer() vs. lme() gave different variance component
	estimates
In-Reply-To: <AANLkTimQF2AdGjeSiBxec5sdz1=2Y8fWz2p52d-pNV90@mail.gmail.com>
References: <851867.90179.qm@web56305.mail.re3.yahoo.com>
	<AANLkTikcWBPYYpqJmi=5mbYZ3zty2vd8wUX95uP1-G3d@mail.gmail.com>
	<889816.11434.qm@web56307.mail.re3.yahoo.com>
	<AANLkTimQF2AdGjeSiBxec5sdz1=2Y8fWz2p52d-pNV90@mail.gmail.com>
Message-ID: <20100918203409.GE9274@ms.unimelb.edu.au>

So far the results split on platform lines: John's is pc, Daniel's and
Reinhold's are Mac.

I get the Mac result on FreeBSD.

> lmer(score~trt+(1|id/eye),dat)
Linear mixed model fit by REML 
Formula: score ~ trt + (1 | id/eye) 
   Data: dat 
   AIC   BIC logLik deviance REMLdev
 425.2 474.2 -201.6    412.7   403.2
Random effects:
 Groups   Name        Variance Std.Dev.
 eye:id   (Intercept) 3.59531  1.89613 
 id       (Intercept) 3.51025  1.87357 
 Residual             0.01875  0.13693 
Number of obs: 640, groups: eye:id, 160; id, 80

Fixed effects:
            Estimate Std. Error t value
(Intercept)   2.5500     0.7287   3.499
trtB          0.9875     1.0305   0.958
trtC          0.8625     1.0305   0.837
trtControl    1.1500     1.0305   1.116
trtD          2.4125     1.0305   2.341
trtE          1.4375     1.0305   1.395
trtF          2.1750     1.0305   2.111
trtG         -2.5500     1.0305  -2.474

Correlation of Fixed Effects:
           (Intr) trtB   trtC   trtCnt trtD   trtE   trtF  
trtB       -0.707                                          
trtC       -0.707  0.500                                   
trtControl -0.707  0.500  0.500                            
trtD       -0.707  0.500  0.500  0.500                     
trtE       -0.707  0.500  0.500  0.500  0.500              
trtF       -0.707  0.500  0.500  0.500  0.500  0.500       
trtG       -0.707  0.500  0.500  0.500  0.500  0.500  0.500
> sessionInfo()
R version 2.11.1 (2010-05-31) 
x86_64-unknown-freebsd8.0 

locale:
[1] C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base
  

other attached packages:
[1] lme4_0.999375-35   Matrix_0.999375-43 lattice_0.19-11   

loaded via a namespace (and not attached):
[1] grid_2.11.1   nlme_3.1-96   stats4_2.11.1



Cheers

Andrew


On Fri, Sep 17, 2010 at 04:57:59PM -0300, Daniel wrote:
> I really don't know what is going wrong.
> 
>  sessionInfo()
> R version 2.11.1 (2010-05-31)
> x86_64-apple-darwin9.8.0
> 
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] lme4_0.999375-35   Matrix_0.999375-43 lattice_0.18-8
> 
> loaded via a namespace (and not attached):
> [1] grid_2.11.1   nlme_3.1-96   stats4_2.11.1
> 
> 
> On Fri, Sep 17, 2010 at 4:33 PM, array chip <arrayprofile at yahoo.com> wrote:
> 
> > Hi, Reinhold and Daniel,
> >
> > I just re-installed lme4 package, still got different results than yours.
> >
> > Here is my sessionInfo():
> >
> > R version 2.11.1 (2010-05-31)
> > i386-pc-mingw32
> >
> > locale:
> > [1] LC_COLLATE=English_United States.1252
> > [2] LC_CTYPE=English_United States.1252
> > [3] LC_MONETARY=English_United States.1252
> > [4] LC_NUMERIC=C
> > [5] LC_TIME=English_United States.1252
> >
> > attached base packages:
> > [1] stats     graphics  grDevices datasets  utils     methods   base
> >
> > other attached packages:
> > [1] lme4_0.999375-35   Matrix_0.999375-43 lattice_0.18-8
> >
> > loaded via a namespace (and not attached):
> > [1] grid_2.11.1   nlme_3.1-96   stats4_2.11.1
> >
> > John
> >
> >
> >
> >
> >
> >
> >
> >
> >
> > ----- Original Message ----
> > From: Reinhold Kliegl <reinhold.kliegl at gmail.com>
> > To: array chip <arrayprofile at yahoo.com>
> > Cc: r-sig-mixed-models at r-project.org
> > Sent: Fri, September 17, 2010 12:14:13 PM
> > Subject: Re: [R-sig-ME] lmer() vs. lme() gave different variance component
> > estimates
> >
> > Not on my computer. Perhaps you could provide sessionInfo()?
> >
> > > lmer(score~trt+(1|id/eye), dat)
> > Linear mixed model fit by REML
> > Formula: score ~ trt + (1 | id/eye)
> >   Data: dat
> >   AIC   BIC logLik deviance REMLdev
> > 425.2 474.2 -201.6    412.7   403.2
> > Random effects:
> > Groups   Name        Variance Std.Dev.
> > eye:id   (Intercept) 3.59532  1.89613
> > id       (Intercept) 3.51024  1.87356
> > Residual             0.01875  0.13693
> > Number of obs: 640, groups: eye:id, 160; id, 80
> >
> > > sessionInfo()
> > R version 2.11.1 Patched (2010-07-16 r52550)
> > x86_64-apple-darwin9.8.0
> >
> > locale:
> > [1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >
> > other attached packages:
> > [1] lme4_0.999375-34   Matrix_0.999375-43 lattice_0.18-8
> >
> > loaded via a namespace (and not attached):
> > [1] grid_2.11.1   nlme_3.1-96   stats4_2.11.1 tools_2.11.1
> >
> > Reinhold Kliegl
> >
> >
> > On Fri, Sep 17, 2010 at 8:39 PM, array chip <arrayprofile at yahoo.com>
> > wrote:
> > > Hi, I have a dataset of animals receiving some eye treatments. There are
> > 8
> > > treatments, each animal's right and left eye was measured with some
> > scores
> > > (ranging from 0 to 7) 4 times after treatment. So there are nesting
> > groups
> > eyes
> > > within animal. Dataset attached
> > >
> > >> dat<-read.table("dat.txt",sep='\t',header=T,row.names=1)
> > >> dat$id<-factor(dat$id)
> > >> str(dat)
> > > 'data.frame':   640 obs. of  5 variables:
> > >  $ score: int  0 2 0 7 4 7 0 2 0 7 ...
> > >  $ id   : Factor w/ 80 levels "1","3","6","10",..: 7 48 66 54 18 26 38 52
> > 39
> > 63
> > > ...
> > >  $ rep  : int  1 1 1 1 1 1 1 1 1 1 ...
> > >  $ eye  : Factor w/ 2 levels "L","R": 2 2 2 2 2 2 2 2 2 2 ...
> > >  $ trt  : Factor w/ 8 levels "A","B","C","Control",..: 1 1 1 1 1 1 1 1 1
> > 1 ...
> > >
> > > I fit a mixed model using both lmer() from lme4 package and lme() from
> > nlme
> > > package:
> > >
> > >> lmer(score~trt+(1|id/eye),dat)
> > >
> > > Linear mixed model fit by REML
> > > Formula: score ~ trt + (1 | id/eye)
> > >   Data: dat
> > >   AIC   BIC logLik deviance REMLdev
> > >  446.7 495.8 -212.4    430.9   424.7
> > > Random effects:
> > >  Groups   Name        Variance   Std.Dev.
> > >  eye:id   (Intercept) 6.9208e+00 2.630742315798
> > >  id       (Intercept) 1.4471e-16 0.000000012030
> > >  Residual             1.8750e-02 0.136930641909
> > > Number of obs: 640, groups: eye:id, 160; id, 80
> > >
> > >> summary(lme(score~trt, random=(~1|id/eye), dat))
> > >
> > > Linear mixed-effects model fit by REML
> > >  Data: dat
> > >       AIC      BIC    logLik
> > >  425.1569 474.0947 -201.5785
> > >
> > > Random effects:
> > >  Formula: ~1 | id
> > >        (Intercept)
> > > StdDev:    1.873576
> > >
> > >  Formula: ~1 | eye %in% id
> > >        (Intercept)  Residual
> > > StdDev:    1.896126 0.1369306
> > >
> > > As you can see, the variance components estimates of random effects are
> > quite
> > > different between the 2 model fits. From the data, I know that the
> > variance
> > > component for "id" can't be near 0, which is what lmer() fit produced, so
> > I
> > > think the lme() fit is correct while lmer() fit is off. This can also be
> > seen
> > > from AIC, BIC etc. lme() fit has better values than lmer() fit.
> > >
> > >
> > > I guess this might be due to lmer() didn't converge very well, is there
> > anyway
> > > to adjust to make lmer() converge better to get similar results as lme()?
> > >
> > > Thanks
> > >
> > > John
> > >
> > >
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >
> > >
> >
> >
> >
> >
> >
> >
> 
> 
> -- 
> Daniel Marcelino
> Skype: dmsilv
> http://bit.ly/pol4vc
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Andrew Robinson  
Program Manager, ACERA 
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia               (prefer email)
http://www.ms.unimelb.edu.au/~andrewpr              Fax: +61-3-8344-4599
http://www.acera.unimelb.edu.au/



From arrayprofile at yahoo.com  Fri Sep 17 22:50:30 2010
From: arrayprofile at yahoo.com (array chip)
Date: Fri, 17 Sep 2010 13:50:30 -0700 (PDT)
Subject: [R-sig-ME] [R] lmer() vs. lme() gave different variance
	component estimates
In-Reply-To: <4C93CA07.6020708@gmail.com>
References: <127299.36449.qm@web56301.mail.re3.yahoo.com>
	<4C93CA07.6020708@gmail.com>
Message-ID: <979833.56316.qm@web56303.mail.re3.yahoo.com>



Thank you Peter. Actually 3 people from mixed model mailing list tried my code 
using lmer(). They got the same results as what I got from lme4(). So they 
couldn't replicate my lmer() results:

Random effects:
Groups   Name        Variance Std.Dev.
eye:id   (Intercept) 3.59531  1.89613 
id       (Intercept) 3.51025  1.87357 
Residual             0.01875  0.13693 
Number of obs: 640, groups: eye:id, 160; id, 80

The only difference they can think of is they are using Mac and FreeBSD while 
mine is PC. I can't imagine this can be the reason. I re-install lme4 package, 
but still got weird results with lmer().

Per your suggestion, here is the results for aov()

summary(aov(score~trt+Error(id/eye), data=dat))

Error: id
          Df Sum Sq Mean Sq F value    Pr(>F)    
trt        7 1353.6 193.378   4.552 0.0002991 ***
Residuals 72 3058.7  42.482                      
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 

Error: id:eye
          Df Sum Sq Mean Sq F value Pr(>F)
Residuals 80   1152    14.4               

Error: Within
           Df Sum Sq Mean Sq F value Pr(>F)
Residuals 480      9 0.01875

As can be seen, thr within subject variance estimate (0.01875) is the same 
between aov, lmer and lme. But I am not sure how to relate results between aov 
and lmer/lme for the other 2 variance components (id and eye%in%id).

Thanks

John






----- Original Message ----
From: Peter Dalgaard <pdalgd at gmail.com>
To: array chip <arrayprofile at yahoo.com>
Cc: r-help at r-project.org
Sent: Fri, September 17, 2010 1:05:27 PM
Subject: Re: [R] lmer() vs. lme() gave different variance component estimates

On 09/17/2010 09:14 PM, array chip wrote:
> Hi, I asked this on mixed model mailing list, but that list is not very active, 
>
> so I'd like to try the general R mailing list. Sorry if anyone receives the 
> double post.
> 
> 
> Hi, I have a dataset of animals receiving some eye treatments. There are 8 
> 
> treatments, each animal's right and left eye was measured with some scores 
> (ranging from 0 to 7) 4 times after treatment. So there are nesting groups eyes 
>
> within animal. Dataset attached
> 
>> dat<-read.table("dat.txt",sep='\t',header=T,row.names=1)
>> dat$id<-factor(dat$id)
>> str(dat)
> 'data.frame':   640 obs. of  5 variables:
> $ score: int  0 2 0 7 4 7 0 2 0 7 ...
> $ id   : Factor w/ 80 levels "1","3","6","10",..: 7 48 66 54 18 26 38 52 39 63 

> ...
> $ rep  : int  1 1 1 1 1 1 1 1 1 1 ...
> $ eye  : Factor w/ 2 levels "L","R": 2 2 2 2 2 2 2 2 2 2 ...
> $ trt  : Factor w/ 8 levels "A","B","C","Control",..: 1 1 1 1 1 1 1 1 1 1 ...
> 
> I fit a mixed model using both lmer() from lme4 package and lme() from nlme 
> package:
> 
>> lmer(score~trt+(1|id/eye),dat)
> 
> Linear mixed model fit by REML 
> Formula: score ~ trt + (1 | id/eye) 
>    Data: dat 
>    AIC   BIC logLik deviance REMLdev
> 446.7 495.8 -212.4    430.9   424.7
> Random effects:
> Groups   Name        Variance   Std.Dev.      
> eye:id   (Intercept) 6.9208e+00 2.630742315798
> id       (Intercept) 1.4471e-16 0.000000012030
> Residual             1.8750e-02 0.136930641909
> Number of obs: 640, groups: eye:id, 160; id, 80
> 
>> summary(lme(score~trt, random=(~1|id/eye), dat))
> 
> Linear mixed-effects model fit by REML
> Data: dat 
>        AIC      BIC    logLik
>   425.1569 474.0947 -201.5785
> 
> Random effects:
> Formula: ~1 | id
>         (Intercept)
> StdDev:    1.873576
> 
> Formula: ~1 | eye %in% id
>         (Intercept)  Residual
> StdDev:    1.896126 0.1369306
> 
> As you can see, the variance components estimates of random effects are quite 
> different between the 2 model fits. From the data, I know that the variance 
> component for "id" can't be near 0, which is what lmer() fit produced, so I 
> think the lme() fit is correct while lmer() fit is off. This can also be seen 
> from AIC, BIC etc. lme() fit has better values than lmer() fit. 
> 
> 
> I guess this might be due to lmer() didn't converge very well, is there anyway 

> to adjust to make lmer() converge better to get similar results as lme()?

That's your guess... I'd be more careful about jumping to conclusions.
If this is a balanced data set, perhaps you could supply the result of

summary(aov(score~trt+Error(id/eye), data=dat))

The correct estimates should be computable from the ANOVA table.


-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com







From izahn at psych.rochester.edu  Fri Sep 17 22:56:08 2010
From: izahn at psych.rochester.edu (Ista Zahn)
Date: Fri, 17 Sep 2010 16:56:08 -0400
Subject: [R-sig-ME] lmer() vs. lme() gave different variance component
	estimates
In-Reply-To: <20100918203409.GE9274@ms.unimelb.edu.au>
References: <851867.90179.qm@web56305.mail.re3.yahoo.com>
	<AANLkTikcWBPYYpqJmi=5mbYZ3zty2vd8wUX95uP1-G3d@mail.gmail.com>
	<889816.11434.qm@web56307.mail.re3.yahoo.com>
	<AANLkTimQF2AdGjeSiBxec5sdz1=2Y8fWz2p52d-pNV90@mail.gmail.com>
	<20100918203409.GE9274@ms.unimelb.edu.au>
Message-ID: <AANLkTinHxyzf87vgYB0BnntfdRBbxNG=7p+XcYntoXwb@mail.gmail.com>

I get the "PC" results on arch linux:

>  lmer(score~trt+(1|id/eye),dat)
Linear mixed model fit by REML
Formula: score ~ trt + (1 | id/eye)
   Data: dat
   AIC   BIC logLik deviance REMLdev
 446.7 495.8 -212.4    430.9   424.7
Random effects:
 Groups   Name        Variance   Std.Dev.
 eye:id   (Intercept) 6.9208e+00 2.6307e+00
 id       (Intercept) 3.0516e-17 5.5241e-09
 Residual             1.8750e-02 1.3693e-01
Number of obs: 640, groups: eye:id, 160; id, 80

Fixed effects:
            Estimate Std. Error t value
(Intercept)   2.5500     0.5885   4.333
trtB          0.9875     0.8322   1.187
trtC          0.8625     0.8322   1.036
trtControl    1.1500     0.8322   1.382
trtD          2.4125     0.8322   2.899
trtE          1.4375     0.8322   1.727
trtF          2.1750     0.8322   2.614
trtG         -2.5500     0.8322  -3.064

> sessionInfo()
R version 2.11.1 (2010-05-31)
i686-pc-linux-gnu

locale:
 [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C
 [3] LC_TIME=en_US.utf8        LC_COLLATE=en_US.utf8
 [5] LC_MONETARY=C             LC_MESSAGES=en_US.utf8
 [7] LC_PAPER=en_US.utf8       LC_NAME=C
 [9] LC_ADDRESS=C              LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_0.999375-35   Matrix_0.999375-44 lattice_0.19-11

loaded via a namespace (and not attached):
[1] grid_2.11.1   nlme_3.1-96   stats4_2.11.1

-Ista

On Sat, Sep 18, 2010 at 4:34 PM, Andrew Robinson
<A.Robinson at ms.unimelb.edu.au> wrote:
> So far the results split on platform lines: John's is pc, Daniel's and
> Reinhold's are Mac.
>
> I get the Mac result on FreeBSD.
>
>> lmer(score~trt+(1|id/eye),dat)
> Linear mixed model fit by REML
> Formula: score ~ trt + (1 | id/eye)
> ? Data: dat
> ? AIC ? BIC logLik deviance REMLdev
> ?425.2 474.2 -201.6 ? ?412.7 ? 403.2
> Random effects:
> ?Groups ? Name ? ? ? ?Variance Std.Dev.
> ?eye:id ? (Intercept) 3.59531 ?1.89613
> ?id ? ? ? (Intercept) 3.51025 ?1.87357
> ?Residual ? ? ? ? ? ? 0.01875 ?0.13693
> Number of obs: 640, groups: eye:id, 160; id, 80
>
> Fixed effects:
> ? ? ? ? ? ?Estimate Std. Error t value
> (Intercept) ? 2.5500 ? ? 0.7287 ? 3.499
> trtB ? ? ? ? ?0.9875 ? ? 1.0305 ? 0.958
> trtC ? ? ? ? ?0.8625 ? ? 1.0305 ? 0.837
> trtControl ? ?1.1500 ? ? 1.0305 ? 1.116
> trtD ? ? ? ? ?2.4125 ? ? 1.0305 ? 2.341
> trtE ? ? ? ? ?1.4375 ? ? 1.0305 ? 1.395
> trtF ? ? ? ? ?2.1750 ? ? 1.0305 ? 2.111
> trtG ? ? ? ? -2.5500 ? ? 1.0305 ?-2.474
>
> Correlation of Fixed Effects:
> ? ? ? ? ? (Intr) trtB ? trtC ? trtCnt trtD ? trtE ? trtF
> trtB ? ? ? -0.707
> trtC ? ? ? -0.707 ?0.500
> trtControl -0.707 ?0.500 ?0.500
> trtD ? ? ? -0.707 ?0.500 ?0.500 ?0.500
> trtE ? ? ? -0.707 ?0.500 ?0.500 ?0.500 ?0.500
> trtF ? ? ? -0.707 ?0.500 ?0.500 ?0.500 ?0.500 ?0.500
> trtG ? ? ? -0.707 ?0.500 ?0.500 ?0.500 ?0.500 ?0.500 ?0.500
>> sessionInfo()
> R version 2.11.1 (2010-05-31)
> x86_64-unknown-freebsd8.0
>
> locale:
> [1] C
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>
>
> other attached packages:
> [1] lme4_0.999375-35 ? Matrix_0.999375-43 lattice_0.19-11
>
> loaded via a namespace (and not attached):
> [1] grid_2.11.1 ? nlme_3.1-96 ? stats4_2.11.1
>
>
>
> Cheers
>
> Andrew
>
>
> On Fri, Sep 17, 2010 at 04:57:59PM -0300, Daniel wrote:
>> I really don't know what is going wrong.
>>
>> ?sessionInfo()
>> R version 2.11.1 (2010-05-31)
>> x86_64-apple-darwin9.8.0
>>
>> locale:
>> [1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
>>
>> attached base packages:
>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>
>> other attached packages:
>> [1] lme4_0.999375-35 ? Matrix_0.999375-43 lattice_0.18-8
>>
>> loaded via a namespace (and not attached):
>> [1] grid_2.11.1 ? nlme_3.1-96 ? stats4_2.11.1
>>
>>
>> On Fri, Sep 17, 2010 at 4:33 PM, array chip <arrayprofile at yahoo.com> wrote:
>>
>> > Hi, Reinhold and Daniel,
>> >
>> > I just re-installed lme4 package, still got different results than yours.
>> >
>> > Here is my sessionInfo():
>> >
>> > R version 2.11.1 (2010-05-31)
>> > i386-pc-mingw32
>> >
>> > locale:
>> > [1] LC_COLLATE=English_United States.1252
>> > [2] LC_CTYPE=English_United States.1252
>> > [3] LC_MONETARY=English_United States.1252
>> > [4] LC_NUMERIC=C
>> > [5] LC_TIME=English_United States.1252
>> >
>> > attached base packages:
>> > [1] stats ? ? graphics ?grDevices datasets ?utils ? ? methods ? base
>> >
>> > other attached packages:
>> > [1] lme4_0.999375-35 ? Matrix_0.999375-43 lattice_0.18-8
>> >
>> > loaded via a namespace (and not attached):
>> > [1] grid_2.11.1 ? nlme_3.1-96 ? stats4_2.11.1
>> >
>> > John
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> > ----- Original Message ----
>> > From: Reinhold Kliegl <reinhold.kliegl at gmail.com>
>> > To: array chip <arrayprofile at yahoo.com>
>> > Cc: r-sig-mixed-models at r-project.org
>> > Sent: Fri, September 17, 2010 12:14:13 PM
>> > Subject: Re: [R-sig-ME] lmer() vs. lme() gave different variance component
>> > estimates
>> >
>> > Not on my computer. Perhaps you could provide sessionInfo()?
>> >
>> > > lmer(score~trt+(1|id/eye), dat)
>> > Linear mixed model fit by REML
>> > Formula: score ~ trt + (1 | id/eye)
>> > ? Data: dat
>> > ? AIC ? BIC logLik deviance REMLdev
>> > 425.2 474.2 -201.6 ? ?412.7 ? 403.2
>> > Random effects:
>> > Groups ? Name ? ? ? ?Variance Std.Dev.
>> > eye:id ? (Intercept) 3.59532 ?1.89613
>> > id ? ? ? (Intercept) 3.51024 ?1.87356
>> > Residual ? ? ? ? ? ? 0.01875 ?0.13693
>> > Number of obs: 640, groups: eye:id, 160; id, 80
>> >
>> > > sessionInfo()
>> > R version 2.11.1 Patched (2010-07-16 r52550)
>> > x86_64-apple-darwin9.8.0
>> >
>> > locale:
>> > [1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
>> >
>> > attached base packages:
>> > [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>> >
>> > other attached packages:
>> > [1] lme4_0.999375-34 ? Matrix_0.999375-43 lattice_0.18-8
>> >
>> > loaded via a namespace (and not attached):
>> > [1] grid_2.11.1 ? nlme_3.1-96 ? stats4_2.11.1 tools_2.11.1
>> >
>> > Reinhold Kliegl
>> >
>> >
>> > On Fri, Sep 17, 2010 at 8:39 PM, array chip <arrayprofile at yahoo.com>
>> > wrote:
>> > > Hi, I have a dataset of animals receiving some eye treatments. There are
>> > 8
>> > > treatments, each animal's right and left eye was measured with some
>> > scores
>> > > (ranging from 0 to 7) 4 times after treatment. So there are nesting
>> > groups
>> > eyes
>> > > within animal. Dataset attached
>> > >
>> > >> dat<-read.table("dat.txt",sep='\t',header=T,row.names=1)
>> > >> dat$id<-factor(dat$id)
>> > >> str(dat)
>> > > 'data.frame': ? 640 obs. of ?5 variables:
>> > > ?$ score: int ?0 2 0 7 4 7 0 2 0 7 ...
>> > > ?$ id ? : Factor w/ 80 levels "1","3","6","10",..: 7 48 66 54 18 26 38 52
>> > 39
>> > 63
>> > > ...
>> > > ?$ rep ?: int ?1 1 1 1 1 1 1 1 1 1 ...
>> > > ?$ eye ?: Factor w/ 2 levels "L","R": 2 2 2 2 2 2 2 2 2 2 ...
>> > > ?$ trt ?: Factor w/ 8 levels "A","B","C","Control",..: 1 1 1 1 1 1 1 1 1
>> > 1 ...
>> > >
>> > > I fit a mixed model using both lmer() from lme4 package and lme() from
>> > nlme
>> > > package:
>> > >
>> > >> lmer(score~trt+(1|id/eye),dat)
>> > >
>> > > Linear mixed model fit by REML
>> > > Formula: score ~ trt + (1 | id/eye)
>> > > ? Data: dat
>> > > ? AIC ? BIC logLik deviance REMLdev
>> > > ?446.7 495.8 -212.4 ? ?430.9 ? 424.7
>> > > Random effects:
>> > > ?Groups ? Name ? ? ? ?Variance ? Std.Dev.
>> > > ?eye:id ? (Intercept) 6.9208e+00 2.630742315798
>> > > ?id ? ? ? (Intercept) 1.4471e-16 0.000000012030
>> > > ?Residual ? ? ? ? ? ? 1.8750e-02 0.136930641909
>> > > Number of obs: 640, groups: eye:id, 160; id, 80
>> > >
>> > >> summary(lme(score~trt, random=(~1|id/eye), dat))
>> > >
>> > > Linear mixed-effects model fit by REML
>> > > ?Data: dat
>> > > ? ? ? AIC ? ? ?BIC ? ?logLik
>> > > ?425.1569 474.0947 -201.5785
>> > >
>> > > Random effects:
>> > > ?Formula: ~1 | id
>> > > ? ? ? ?(Intercept)
>> > > StdDev: ? ?1.873576
>> > >
>> > > ?Formula: ~1 | eye %in% id
>> > > ? ? ? ?(Intercept) ?Residual
>> > > StdDev: ? ?1.896126 0.1369306
>> > >
>> > > As you can see, the variance components estimates of random effects are
>> > quite
>> > > different between the 2 model fits. From the data, I know that the
>> > variance
>> > > component for "id" can't be near 0, which is what lmer() fit produced, so
>> > I
>> > > think the lme() fit is correct while lmer() fit is off. This can also be
>> > seen
>> > > from AIC, BIC etc. lme() fit has better values than lmer() fit.
>> > >
>> > >
>> > > I guess this might be due to lmer() didn't converge very well, is there
>> > anyway
>> > > to adjust to make lmer() converge better to get similar results as lme()?
>> > >
>> > > Thanks
>> > >
>> > > John
>> > >
>> > >
>> > >
>> > > _______________________________________________
>> > > R-sig-mixed-models at r-project.org mailing list
>> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> > >
>> > >
>> >
>> >
>> >
>> >
>> >
>> >
>>
>>
>> --
>> Daniel Marcelino
>> Skype: dmsilv
>> http://bit.ly/pol4vc
>>
>> ? ? ? [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> --
> Andrew Robinson
> Program Manager, ACERA
> Department of Mathematics and Statistics ? ? ? ? ? ?Tel: +61-3-8344-6410
> University of Melbourne, VIC 3010 Australia ? ? ? ? ? ? ? (prefer email)
> http://www.ms.unimelb.edu.au/~andrewpr ? ? ? ? ? ? ?Fax: +61-3-8344-4599
> http://www.acera.unimelb.edu.au/
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Ista Zahn
Graduate student
University of Rochester
Department of Clinical and Social Psychology
http://yourpsyche.org



From kw.stat at gmail.com  Fri Sep 17 23:17:55 2010
From: kw.stat at gmail.com (Kevin Wright)
Date: Fri, 17 Sep 2010 16:17:55 -0500
Subject: [R-sig-ME] [R] lmer() vs. lme() gave different variance
	component estimates
In-Reply-To: <979833.56316.qm@web56303.mail.re3.yahoo.com>
References: <127299.36449.qm@web56301.mail.re3.yahoo.com>
	<4C93CA07.6020708@gmail.com>
	<979833.56316.qm@web56303.mail.re3.yahoo.com>
Message-ID: <AANLkTi=APdNPCqGSAZf99mEq4jLGVi8Sq1x4a+=ZO6NT@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100917/451782cc/attachment.pl>

From lborger at uoguelph.ca  Fri Sep 17 23:20:01 2010
From: lborger at uoguelph.ca (Luca Borger)
Date: Fri, 17 Sep 2010 17:20:01 -0400
Subject: [R-sig-ME] lmer() vs. lme() gave different variance
	componentestimates
References: <851867.90179.qm@web56305.mail.re3.yahoo.com><AANLkTikcWBPYYpqJmi=5mbYZ3zty2vd8wUX95uP1-G3d@mail.gmail.com><889816.11434.qm@web56307.mail.re3.yahoo.com><AANLkTimQF2AdGjeSiBxec5sdz1=2Y8fWz2p52d-pNV90@mail.gmail.com><20100918203409.GE9274@ms.unimelb.edu.au>
	<AANLkTinHxyzf87vgYB0BnntfdRBbxNG=7p+XcYntoXwb@mail.gmail.com>
Message-ID: <7483716CD7F1477A9D327EECA9F6E8F1@lborger>

I can confirm the "PC" results on a PC ;-)

> lmer(score~trt+(1|id/eye),dat)
Linear mixed model fit by REML
Formula: score ~ trt + (1 | id/eye)
   Data: dat
   AIC   BIC logLik deviance REMLdev
 446.7 495.8 -212.4    430.9   424.7
Random effects:
 Groups   Name        Variance   Std.Dev.
 eye:id   (Intercept) 6.9208e+00 2.6307e+00
 id       (Intercept) 1.4471e-16 1.2030e-08
 Residual             1.8750e-02 1.3693e-01
Number of obs: 640, groups: eye:id, 160; id, 80


# on Windows XP
> sessionInfo()
R version 2.11.1 (2010-05-31)
i386-pc-mingw32

locale:
[1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United 
Kingdom.1252    LC_MONETARY=English_United Kingdom.1252
[4] LC_NUMERIC=C                            LC_TIME=English_United 
Kingdom.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_0.999375-35   Matrix_0.999375-44 lattice_0.19-11

loaded via a namespace (and not attached):
[1] grid_2.11.1   nlme_3.1-96   stats4_2.11.1 tools_2.11.1
>



Cheers,

Luca



----- Original Message ----- 
From: "Ista Zahn" <izahn at psych.rochester.edu>
To: "Andrew Robinson" <A.Robinson at ms.unimelb.edu.au>
Cc: <r-sig-mixed-models at r-project.org>
Sent: Friday, September 17, 2010 4:56 PM
Subject: Re: [R-sig-ME] lmer() vs. lme() gave different variance 
componentestimates


I get the "PC" results on arch linux:

>  lmer(score~trt+(1|id/eye),dat)
Linear mixed model fit by REML
Formula: score ~ trt + (1 | id/eye)
   Data: dat
   AIC   BIC logLik deviance REMLdev
 446.7 495.8 -212.4    430.9   424.7
Random effects:
 Groups   Name        Variance   Std.Dev.
 eye:id   (Intercept) 6.9208e+00 2.6307e+00
 id       (Intercept) 3.0516e-17 5.5241e-09
 Residual             1.8750e-02 1.3693e-01
Number of obs: 640, groups: eye:id, 160; id, 80

Fixed effects:
            Estimate Std. Error t value
(Intercept)   2.5500     0.5885   4.333
trtB          0.9875     0.8322   1.187
trtC          0.8625     0.8322   1.036
trtControl    1.1500     0.8322   1.382
trtD          2.4125     0.8322   2.899
trtE          1.4375     0.8322   1.727
trtF          2.1750     0.8322   2.614
trtG         -2.5500     0.8322  -3.064

> sessionInfo()
R version 2.11.1 (2010-05-31)
i686-pc-linux-gnu

locale:
 [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C
 [3] LC_TIME=en_US.utf8        LC_COLLATE=en_US.utf8
 [5] LC_MONETARY=C             LC_MESSAGES=en_US.utf8
 [7] LC_PAPER=en_US.utf8       LC_NAME=C
 [9] LC_ADDRESS=C              LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_0.999375-35   Matrix_0.999375-44 lattice_0.19-11

loaded via a namespace (and not attached):
[1] grid_2.11.1   nlme_3.1-96   stats4_2.11.1

-Ista

On Sat, Sep 18, 2010 at 4:34 PM, Andrew Robinson
<A.Robinson at ms.unimelb.edu.au> wrote:
> So far the results split on platform lines: John's is pc, Daniel's and
> Reinhold's are Mac.
>
> I get the Mac result on FreeBSD.
>
>> lmer(score~trt+(1|id/eye),dat)
> Linear mixed model fit by REML
> Formula: score ~ trt + (1 | id/eye)
> Data: dat
> AIC BIC logLik deviance REMLdev
> 425.2 474.2 -201.6 412.7 403.2
> Random effects:
> Groups Name Variance Std.Dev.
> eye:id (Intercept) 3.59531 1.89613
> id (Intercept) 3.51025 1.87357
> Residual 0.01875 0.13693
> Number of obs: 640, groups: eye:id, 160; id, 80
>
> Fixed effects:
> Estimate Std. Error t value
> (Intercept) 2.5500 0.7287 3.499
> trtB 0.9875 1.0305 0.958
> trtC 0.8625 1.0305 0.837
> trtControl 1.1500 1.0305 1.116
> trtD 2.4125 1.0305 2.341
> trtE 1.4375 1.0305 1.395
> trtF 2.1750 1.0305 2.111
> trtG -2.5500 1.0305 -2.474
>
> Correlation of Fixed Effects:
> (Intr) trtB trtC trtCnt trtD trtE trtF
> trtB -0.707
> trtC -0.707 0.500
> trtControl -0.707 0.500 0.500
> trtD -0.707 0.500 0.500 0.500
> trtE -0.707 0.500 0.500 0.500 0.500
> trtF -0.707 0.500 0.500 0.500 0.500 0.500
> trtG -0.707 0.500 0.500 0.500 0.500 0.500 0.500
>> sessionInfo()
> R version 2.11.1 (2010-05-31)
> x86_64-unknown-freebsd8.0
>
> locale:
> [1] C
>
> attached base packages:
> [1] stats graphics grDevices utils datasets methods base
>
>
> other attached packages:
> [1] lme4_0.999375-35 Matrix_0.999375-43 lattice_0.19-11
>
> loaded via a namespace (and not attached):
> [1] grid_2.11.1 nlme_3.1-96 stats4_2.11.1
>
>
>
> Cheers
>
> Andrew
>
>
> On Fri, Sep 17, 2010 at 04:57:59PM -0300, Daniel wrote:
>> I really don't know what is going wrong.
>>
>> sessionInfo()
>> R version 2.11.1 (2010-05-31)
>> x86_64-apple-darwin9.8.0
>>
>> locale:
>> [1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
>>
>> attached base packages:
>> [1] stats graphics grDevices utils datasets methods base
>>
>> other attached packages:
>> [1] lme4_0.999375-35 Matrix_0.999375-43 lattice_0.18-8
>>
>> loaded via a namespace (and not attached):
>> [1] grid_2.11.1 nlme_3.1-96 stats4_2.11.1
>>
>>
>> On Fri, Sep 17, 2010 at 4:33 PM, array chip <arrayprofile at yahoo.com> 
>> wrote:
>>
>> > Hi, Reinhold and Daniel,
>> >
>> > I just re-installed lme4 package, still got different results than 
>> > yours.
>> >
>> > Here is my sessionInfo():
>> >
>> > R version 2.11.1 (2010-05-31)
>> > i386-pc-mingw32
>> >
>> > locale:
>> > [1] LC_COLLATE=English_United States.1252
>> > [2] LC_CTYPE=English_United States.1252
>> > [3] LC_MONETARY=English_United States.1252
>> > [4] LC_NUMERIC=C
>> > [5] LC_TIME=English_United States.1252
>> >
>> > attached base packages:
>> > [1] stats graphics grDevices datasets utils methods base
>> >
>> > other attached packages:
>> > [1] lme4_0.999375-35 Matrix_0.999375-43 lattice_0.18-8
>> >
>> > loaded via a namespace (and not attached):
>> > [1] grid_2.11.1 nlme_3.1-96 stats4_2.11.1
>> >
>> > John
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> > ----- Original Message ----
>> > From: Reinhold Kliegl <reinhold.kliegl at gmail.com>
>> > To: array chip <arrayprofile at yahoo.com>
>> > Cc: r-sig-mixed-models at r-project.org
>> > Sent: Fri, September 17, 2010 12:14:13 PM
>> > Subject: Re: [R-sig-ME] lmer() vs. lme() gave different variance 
>> > component
>> > estimates
>> >
>> > Not on my computer. Perhaps you could provide sessionInfo()?
>> >
>> > > lmer(score~trt+(1|id/eye), dat)
>> > Linear mixed model fit by REML
>> > Formula: score ~ trt + (1 | id/eye)
>> > Data: dat
>> > AIC BIC logLik deviance REMLdev
>> > 425.2 474.2 -201.6 412.7 403.2
>> > Random effects:
>> > Groups Name Variance Std.Dev.
>> > eye:id (Intercept) 3.59532 1.89613
>> > id (Intercept) 3.51024 1.87356
>> > Residual 0.01875 0.13693
>> > Number of obs: 640, groups: eye:id, 160; id, 80
>> >
>> > > sessionInfo()
>> > R version 2.11.1 Patched (2010-07-16 r52550)
>> > x86_64-apple-darwin9.8.0
>> >
>> > locale:
>> > [1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
>> >
>> > attached base packages:
>> > [1] stats graphics grDevices utils datasets methods base
>> >
>> > other attached packages:
>> > [1] lme4_0.999375-34 Matrix_0.999375-43 lattice_0.18-8
>> >
>> > loaded via a namespace (and not attached):
>> > [1] grid_2.11.1 nlme_3.1-96 stats4_2.11.1 tools_2.11.1
>> >
>> > Reinhold Kliegl
>> >
>> >
>> > On Fri, Sep 17, 2010 at 8:39 PM, array chip <arrayprofile at yahoo.com>
>> > wrote:
>> > > Hi, I have a dataset of animals receiving some eye treatments. There 
>> > > are
>> > 8
>> > > treatments, each animal's right and left eye was measured with some
>> > scores
>> > > (ranging from 0 to 7) 4 times after treatment. So there are nesting
>> > groups
>> > eyes
>> > > within animal. Dataset attached
>> > >
>> > >> dat<-read.table("dat.txt",sep='\t',header=T,row.names=1)
>> > >> dat$id<-factor(dat$id)
>> > >> str(dat)
>> > > 'data.frame': 640 obs. of 5 variables:
>> > > $ score: int 0 2 0 7 4 7 0 2 0 7 ...
>> > > $ id : Factor w/ 80 levels "1","3","6","10",..: 7 48 66 54 18 26 38 
>> > > 52
>> > 39
>> > 63
>> > > ...
>> > > $ rep : int 1 1 1 1 1 1 1 1 1 1 ...
>> > > $ eye : Factor w/ 2 levels "L","R": 2 2 2 2 2 2 2 2 2 2 ...
>> > > $ trt : Factor w/ 8 levels "A","B","C","Control",..: 1 1 1 1 1 1 1 1 
>> > > 1
>> > 1 ...
>> > >
>> > > I fit a mixed model using both lmer() from lme4 package and lme() 
>> > > from
>> > nlme
>> > > package:
>> > >
>> > >> lmer(score~trt+(1|id/eye),dat)
>> > >
>> > > Linear mixed model fit by REML
>> > > Formula: score ~ trt + (1 | id/eye)
>> > > Data: dat
>> > > AIC BIC logLik deviance REMLdev
>> > > 446.7 495.8 -212.4 430.9 424.7
>> > > Random effects:
>> > > Groups Name Variance Std.Dev.
>> > > eye:id (Intercept) 6.9208e+00 2.630742315798
>> > > id (Intercept) 1.4471e-16 0.000000012030
>> > > Residual 1.8750e-02 0.136930641909
>> > > Number of obs: 640, groups: eye:id, 160; id, 80
>> > >
>> > >> summary(lme(score~trt, random=(~1|id/eye), dat))
>> > >
>> > > Linear mixed-effects model fit by REML
>> > > Data: dat
>> > > AIC BIC logLik
>> > > 425.1569 474.0947 -201.5785
>> > >
>> > > Random effects:
>> > > Formula: ~1 | id
>> > > (Intercept)
>> > > StdDev: 1.873576
>> > >
>> > > Formula: ~1 | eye %in% id
>> > > (Intercept) Residual
>> > > StdDev: 1.896126 0.1369306
>> > >
>> > > As you can see, the variance components estimates of random effects 
>> > > are
>> > quite
>> > > different between the 2 model fits. From the data, I know that the
>> > variance
>> > > component for "id" can't be near 0, which is what lmer() fit 
>> > > produced, so
>> > I
>> > > think the lme() fit is correct while lmer() fit is off. This can also 
>> > > be
>> > seen
>> > > from AIC, BIC etc. lme() fit has better values than lmer() fit.
>> > >
>> > >
>> > > I guess this might be due to lmer() didn't converge very well, is 
>> > > there
>> > anyway
>> > > to adjust to make lmer() converge better to get similar results as 
>> > > lme()?
>> > >
>> > > Thanks
>> > >
>> > > John
>> > >
>> > >
>> > >
>> > > _______________________________________________
>> > > R-sig-mixed-models at r-project.org mailing list
>> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> > >
>> > >
>> >
>> >
>> >
>> >
>> >
>> >
>>
>>
>> --
>> Daniel Marcelino
>> Skype: dmsilv
>> http://bit.ly/pol4vc
>>
>> [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> --
> Andrew Robinson
> Program Manager, ACERA
> Department of Mathematics and Statistics Tel: +61-3-8344-6410
> University of Melbourne, VIC 3010 Australia (prefer email)
> http://www.ms.unimelb.edu.au/~andrewpr Fax: +61-3-8344-4599
> http://www.acera.unimelb.edu.au/
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Ista Zahn
Graduate student
University of Rochester
Department of Clinical and Social Psychology
http://yourpsyche.org

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From pdalgd at gmail.com  Sat Sep 18 10:35:45 2010
From: pdalgd at gmail.com (Peter Dalgaard)
Date: Sat, 18 Sep 2010 10:35:45 +0200
Subject: [R-sig-ME] [R] lmer() vs. lme() gave different variance
	component estimates
In-Reply-To: <979833.56316.qm@web56303.mail.re3.yahoo.com>
References: <127299.36449.qm@web56301.mail.re3.yahoo.com>
	<4C93CA07.6020708@gmail.com>
	<979833.56316.qm@web56303.mail.re3.yahoo.com>
Message-ID: <4C9479E1.70303@gmail.com>

On 09/17/2010 10:50 PM, array chip wrote:
> 
> 
> Thank you Peter. Actually 3 people from mixed model mailing list tried my code 
> using lmer(). They got the same results as what I got from lme4(). So they 
> couldn't replicate my lmer() results:
> 
> Random effects:
> Groups   Name        Variance Std.Dev.
> eye:id   (Intercept) 3.59531  1.89613 
> id       (Intercept) 3.51025  1.87357 
> Residual             0.01875  0.13693 
> Number of obs: 640, groups: eye:id, 160; id, 80
> 
> The only difference they can think of is they are using Mac and FreeBSD while 
> mine is PC. I can't imagine this can be the reason. I re-install lme4 package, 
> but still got weird results with lmer().
> 
> Per your suggestion, here is the results for aov()
> 
> summary(aov(score~trt+Error(id/eye), data=dat))
> 
> Error: id
>           Df Sum Sq Mean Sq F value    Pr(>F)    
> trt        7 1353.6 193.378   4.552 0.0002991 ***
> Residuals 72 3058.7  42.482                      
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 
> 
> Error: id:eye
>           Df Sum Sq Mean Sq F value Pr(>F)
> Residuals 80   1152    14.4               
> 
> Error: Within
>            Df Sum Sq Mean Sq F value Pr(>F)
> Residuals 480      9 0.01875
> 
> As can be seen, thr within subject variance estimate (0.01875) is the same 
> between aov, lmer and lme. But I am not sure how to relate results between aov 
> and lmer/lme for the other 2 variance components (id and eye%in%id).
> 

For a nested design, the relation is quite straightforward: The residual
MS are the variances of sample means scaled to be comparable with the
residuals (so that in the absense of random components, all
MS are equal to within the F-ratio variability). So to get the id:eye
variance component, subtract the Within MS from the id:eye MS and divide
by the number of replicates (4 in this case since you have 640
observations on 160 eyes) (14.4 - 0.01875)/4 = 3.59, and similarly, the
id variance is the MS for id minus that for id:eye scaled by 8:
(42.482-14.4)/8 = 3.51.

I.e. it is reproducing the lmer results above, but of course not those
from your original post.

(Notice, by the way, that if you are only interested in the treatment
effect, you might as well have computed the average of all 8
measurements on each animal and computed a 1-way ANOVA).

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com



From j.hadfield at ed.ac.uk  Sat Sep 18 11:24:05 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sat, 18 Sep 2010 10:24:05 +0100
Subject: [R-sig-ME] lmer() vs. lme() gave different variance
	component	estimates
In-Reply-To: <20100918203409.GE9274@ms.unimelb.edu.au>
References: <851867.90179.qm@web56305.mail.re3.yahoo.com>
	<AANLkTikcWBPYYpqJmi=5mbYZ3zty2vd8wUX95uP1-G3d@mail.gmail.com>
	<889816.11434.qm@web56307.mail.re3.yahoo.com>
	<AANLkTimQF2AdGjeSiBxec5sdz1=2Y8fWz2p52d-pNV90@mail.gmail.com>
	<20100918203409.GE9274@ms.unimelb.edu.au>
Message-ID: <20100918102405.f8ef1dodxwckg0o4@www.staffmail.ed.ac.uk>

Fedora Core 13 seems fine:

Linear mixed model fit by REML
Formula: score ~ trt + (1 | id/eye)
    Data: dat
    AIC   BIC logLik deviance REMLdev
  425.2 474.2 -201.6    412.7   403.2
Random effects:
  Groups   Name        Variance Std.Dev.
  eye:id   (Intercept) 3.59532  1.89613
  id       (Intercept) 3.51024  1.87356
  Residual             0.01875  0.13693
Number of obs: 640, groups: eye:id, 160; id, 80

Fixed effects:
             Estimate Std. Error t value
(Intercept)   2.5500     0.7287   3.499
trtB          0.9875     1.0305   0.958
trtC          0.8625     1.0305   0.837
trtControl    1.1500     1.0305   1.116
trtD          2.4125     1.0305   2.341
trtE          1.4375     1.0305   1.395
trtF          2.1750     1.0305   2.111
trtG         -2.5500     1.0305  -2.474

Correlation of Fixed Effects:
            (Intr) trtB   trtC   trtCnt trtD   trtE   trtF
trtB       -0.707
trtC       -0.707  0.500
trtControl -0.707  0.500  0.500
trtD       -0.707  0.500  0.500  0.500
trtE       -0.707  0.500  0.500  0.500  0.500
trtF       -0.707  0.500  0.500  0.500  0.500  0.500
trtG       -0.707  0.500  0.500  0.500  0.500  0.500  0.500
>
> sessionInfo()
R version 2.11.1 (2010-05-31)
x86_64-redhat-linux-gnu

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
  [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8
  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_0.999375-34   Matrix_0.999375-43 lattice_0.18-8

loaded via a namespace (and not attached):
[1] grid_2.11.1   nlme_3.1-96   stats4_2.11.1



Quoting Andrew Robinson <A.Robinson at ms.unimelb.edu.au>:

> So far the results split on platform lines: John's is pc, Daniel's and
> Reinhold's are Mac.
>
> I get the Mac result on FreeBSD.
>
>> lmer(score~trt+(1|id/eye),dat)
> Linear mixed model fit by REML
> Formula: score ~ trt + (1 | id/eye)
>    Data: dat
>    AIC   BIC logLik deviance REMLdev
>  425.2 474.2 -201.6    412.7   403.2
> Random effects:
>  Groups   Name        Variance Std.Dev.
>  eye:id   (Intercept) 3.59531  1.89613
>  id       (Intercept) 3.51025  1.87357
>  Residual             0.01875  0.13693
> Number of obs: 640, groups: eye:id, 160; id, 80
>
> Fixed effects:
>             Estimate Std. Error t value
> (Intercept)   2.5500     0.7287   3.499
> trtB          0.9875     1.0305   0.958
> trtC          0.8625     1.0305   0.837
> trtControl    1.1500     1.0305   1.116
> trtD          2.4125     1.0305   2.341
> trtE          1.4375     1.0305   1.395
> trtF          2.1750     1.0305   2.111
> trtG         -2.5500     1.0305  -2.474
>
> Correlation of Fixed Effects:
>            (Intr) trtB   trtC   trtCnt trtD   trtE   trtF
> trtB       -0.707
> trtC       -0.707  0.500
> trtControl -0.707  0.500  0.500
> trtD       -0.707  0.500  0.500  0.500
> trtE       -0.707  0.500  0.500  0.500  0.500
> trtF       -0.707  0.500  0.500  0.500  0.500  0.500
> trtG       -0.707  0.500  0.500  0.500  0.500  0.500  0.500
>> sessionInfo()
> R version 2.11.1 (2010-05-31)
> x86_64-unknown-freebsd8.0
>
> locale:
> [1] C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
>
> other attached packages:
> [1] lme4_0.999375-35   Matrix_0.999375-43 lattice_0.19-11
>
> loaded via a namespace (and not attached):
> [1] grid_2.11.1   nlme_3.1-96   stats4_2.11.1
>
>
>
> Cheers
>
> Andrew
>
>
> On Fri, Sep 17, 2010 at 04:57:59PM -0300, Daniel wrote:
>> I really don't know what is going wrong.
>>
>>  sessionInfo()
>> R version 2.11.1 (2010-05-31)
>> x86_64-apple-darwin9.8.0
>>
>> locale:
>> [1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] lme4_0.999375-35   Matrix_0.999375-43 lattice_0.18-8
>>
>> loaded via a namespace (and not attached):
>> [1] grid_2.11.1   nlme_3.1-96   stats4_2.11.1
>>
>>
>> On Fri, Sep 17, 2010 at 4:33 PM, array chip <arrayprofile at yahoo.com> wrote:
>>
>> > Hi, Reinhold and Daniel,
>> >
>> > I just re-installed lme4 package, still got different results than yours.
>> >
>> > Here is my sessionInfo():
>> >
>> > R version 2.11.1 (2010-05-31)
>> > i386-pc-mingw32
>> >
>> > locale:
>> > [1] LC_COLLATE=English_United States.1252
>> > [2] LC_CTYPE=English_United States.1252
>> > [3] LC_MONETARY=English_United States.1252
>> > [4] LC_NUMERIC=C
>> > [5] LC_TIME=English_United States.1252
>> >
>> > attached base packages:
>> > [1] stats     graphics  grDevices datasets  utils     methods   base
>> >
>> > other attached packages:
>> > [1] lme4_0.999375-35   Matrix_0.999375-43 lattice_0.18-8
>> >
>> > loaded via a namespace (and not attached):
>> > [1] grid_2.11.1   nlme_3.1-96   stats4_2.11.1
>> >
>> > John
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> > ----- Original Message ----
>> > From: Reinhold Kliegl <reinhold.kliegl at gmail.com>
>> > To: array chip <arrayprofile at yahoo.com>
>> > Cc: r-sig-mixed-models at r-project.org
>> > Sent: Fri, September 17, 2010 12:14:13 PM
>> > Subject: Re: [R-sig-ME] lmer() vs. lme() gave different variance component
>> > estimates
>> >
>> > Not on my computer. Perhaps you could provide sessionInfo()?
>> >
>> > > lmer(score~trt+(1|id/eye), dat)
>> > Linear mixed model fit by REML
>> > Formula: score ~ trt + (1 | id/eye)
>> >   Data: dat
>> >   AIC   BIC logLik deviance REMLdev
>> > 425.2 474.2 -201.6    412.7   403.2
>> > Random effects:
>> > Groups   Name        Variance Std.Dev.
>> > eye:id   (Intercept) 3.59532  1.89613
>> > id       (Intercept) 3.51024  1.87356
>> > Residual             0.01875  0.13693
>> > Number of obs: 640, groups: eye:id, 160; id, 80
>> >
>> > > sessionInfo()
>> > R version 2.11.1 Patched (2010-07-16 r52550)
>> > x86_64-apple-darwin9.8.0
>> >
>> > locale:
>> > [1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
>> >
>> > attached base packages:
>> > [1] stats     graphics  grDevices utils     datasets  methods   base
>> >
>> > other attached packages:
>> > [1] lme4_0.999375-34   Matrix_0.999375-43 lattice_0.18-8
>> >
>> > loaded via a namespace (and not attached):
>> > [1] grid_2.11.1   nlme_3.1-96   stats4_2.11.1 tools_2.11.1
>> >
>> > Reinhold Kliegl
>> >
>> >
>> > On Fri, Sep 17, 2010 at 8:39 PM, array chip <arrayprofile at yahoo.com>
>> > wrote:
>> > > Hi, I have a dataset of animals receiving some eye treatments. There are
>> > 8
>> > > treatments, each animal's right and left eye was measured with some
>> > scores
>> > > (ranging from 0 to 7) 4 times after treatment. So there are nesting
>> > groups
>> > eyes
>> > > within animal. Dataset attached
>> > >
>> > >> dat<-read.table("dat.txt",sep='\t',header=T,row.names=1)
>> > >> dat$id<-factor(dat$id)
>> > >> str(dat)
>> > > 'data.frame':   640 obs. of  5 variables:
>> > >  $ score: int  0 2 0 7 4 7 0 2 0 7 ...
>> > >  $ id   : Factor w/ 80 levels "1","3","6","10",..: 7 48 66 54   
>> 18 26 38 52
>> > 39
>> > 63
>> > > ...
>> > >  $ rep  : int  1 1 1 1 1 1 1 1 1 1 ...
>> > >  $ eye  : Factor w/ 2 levels "L","R": 2 2 2 2 2 2 2 2 2 2 ...
>> > >  $ trt  : Factor w/ 8 levels "A","B","C","Control",..: 1 1 1 1 1 1 1 1 1
>> > 1 ...
>> > >
>> > > I fit a mixed model using both lmer() from lme4 package and lme() from
>> > nlme
>> > > package:
>> > >
>> > >> lmer(score~trt+(1|id/eye),dat)
>> > >
>> > > Linear mixed model fit by REML
>> > > Formula: score ~ trt + (1 | id/eye)
>> > >   Data: dat
>> > >   AIC   BIC logLik deviance REMLdev
>> > >  446.7 495.8 -212.4    430.9   424.7
>> > > Random effects:
>> > >  Groups   Name        Variance   Std.Dev.
>> > >  eye:id   (Intercept) 6.9208e+00 2.630742315798
>> > >  id       (Intercept) 1.4471e-16 0.000000012030
>> > >  Residual             1.8750e-02 0.136930641909
>> > > Number of obs: 640, groups: eye:id, 160; id, 80
>> > >
>> > >> summary(lme(score~trt, random=(~1|id/eye), dat))
>> > >
>> > > Linear mixed-effects model fit by REML
>> > >  Data: dat
>> > >       AIC      BIC    logLik
>> > >  425.1569 474.0947 -201.5785
>> > >
>> > > Random effects:
>> > >  Formula: ~1 | id
>> > >        (Intercept)
>> > > StdDev:    1.873576
>> > >
>> > >  Formula: ~1 | eye %in% id
>> > >        (Intercept)  Residual
>> > > StdDev:    1.896126 0.1369306
>> > >
>> > > As you can see, the variance components estimates of random effects are
>> > quite
>> > > different between the 2 model fits. From the data, I know that the
>> > variance
>> > > component for "id" can't be near 0, which is what lmer() fit   
>> produced, so
>> > I
>> > > think the lme() fit is correct while lmer() fit is off. This can also be
>> > seen
>> > > from AIC, BIC etc. lme() fit has better values than lmer() fit.
>> > >
>> > >
>> > > I guess this might be due to lmer() didn't converge very well, is there
>> > anyway
>> > > to adjust to make lmer() converge better to get similar results  
>>  as lme()?
>> > >
>> > > Thanks
>> > >
>> > > John
>> > >
>> > >
>> > >
>> > > _______________________________________________
>> > > R-sig-mixed-models at r-project.org mailing list
>> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> > >
>> > >
>> >
>> >
>> >
>> >
>> >
>> >
>>
>>
>> --
>> Daniel Marcelino
>> Skype: dmsilv
>> http://bit.ly/pol4vc
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> --
> Andrew Robinson
> Program Manager, ACERA
> Department of Mathematics and Statistics            Tel: +61-3-8344-6410
> University of Melbourne, VIC 3010 Australia               (prefer email)
> http://www.ms.unimelb.edu.au/~andrewpr              Fax: +61-3-8344-4599
> http://www.acera.unimelb.edu.au/
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From pdalgd at gmail.com  Sat Sep 18 11:58:37 2010
From: pdalgd at gmail.com (Peter Dalgaard)
Date: Sat, 18 Sep 2010 11:58:37 +0200
Subject: [R-sig-ME] lmer() vs. lme() gave different variance component
 estimates
In-Reply-To: <20100918102405.f8ef1dodxwckg0o4@www.staffmail.ed.ac.uk>
References: <851867.90179.qm@web56305.mail.re3.yahoo.com>	<AANLkTikcWBPYYpqJmi=5mbYZ3zty2vd8wUX95uP1-G3d@mail.gmail.com>	<889816.11434.qm@web56307.mail.re3.yahoo.com>	<AANLkTimQF2AdGjeSiBxec5sdz1=2Y8fWz2p52d-pNV90@mail.gmail.com>	<20100918203409.GE9274@ms.unimelb.edu.au>
	<20100918102405.f8ef1dodxwckg0o4@www.staffmail.ed.ac.uk>
Message-ID: <4C948D4D.9080602@gmail.com>

On 09/18/2010 11:24 AM, Jarrod Hadfield wrote:
> Fedora Core 13 seems fine:
> 
> Linear mixed model fit by REML
> Formula: score ~ trt + (1 | id/eye)
>     Data: dat
>     AIC   BIC logLik deviance REMLdev
>   425.2 474.2 -201.6    412.7   403.2
> Random effects:
>   Groups   Name        Variance Std.Dev.
>   eye:id   (Intercept) 3.59532  1.89613
>   id       (Intercept) 3.51024  1.87356
>   Residual             0.01875  0.13693
> Number of obs: 640, groups: eye:id, 160; id, 80

Not in 32bit:

> lmer(score~trt+(1|id/eye),dat)
Linear mixed model fit by REML
Formula: score ~ trt + (1 | id/eye)
   Data: dat
   AIC   BIC logLik deviance REMLdev
 446.7 495.8 -212.4    430.9   424.7
Random effects:
 Groups   Name        Variance   Std.Dev.
 eye:id   (Intercept) 6.9208e+00 2.6307e+00
 id       (Intercept) 4.0996e-12 2.0248e-06
 Residual             1.8750e-02 1.3693e-01
Number of obs: 640, groups: eye:id, 160; id, 80

Diddling the start values can change the result, though. Could you all try

(a) setting verbose=T
(b) try start=list(matrix(10),matrix(10))
(c) same thing, but with .81 and .57


In the (c) case, I get

> l <- lmer(score~trt+(1|id/eye),dat,
start=list(matrix(.81),matrix(.57)), verbose=T)
  0:     2226.5319: 0.810000 0.570000
  1:     1304.7507:  2.42844  1.75398
  2:     776.66839:  6.30805  0.00000
  3:     657.56008:  7.73875  0.00000
  4:     514.89378:  10.7783  0.00000
  5:     460.61371:  13.2310  0.00000
  6:     434.88972:  15.6779 1.52026e-08
  7:     426.68822:  17.5387 6.57868e-08
  8:     424.89428:  18.6843 1.41900e-07
  9:     424.71823:  19.1258 2.47916e-07
 10:     424.71356:  19.2075 3.75766e-07
 11:     424.71354:  19.2122 5.37851e-07
 12:     424.71354:  19.2122 7.55161e-07

which suggests an algorithm error where the parameters are getting stuck
on the boundary. These values match the automatically generated starting
values only to two digits, so I'm somewhat baffled that you apparently
get something completely different in 64 bits!

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com



From j.hadfield at ed.ac.uk  Sat Sep 18 12:09:04 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sat, 18 Sep 2010 11:09:04 +0100
Subject: [R-sig-ME] lmer() vs. lme() gave different variance
	component	estimates
In-Reply-To: <4C948D4D.9080602@gmail.com>
References: <851867.90179.qm@web56305.mail.re3.yahoo.com>
	<AANLkTikcWBPYYpqJmi=5mbYZ3zty2vd8wUX95uP1-G3d@mail.gmail.com>
	<889816.11434.qm@web56307.mail.re3.yahoo.com>
	<AANLkTimQF2AdGjeSiBxec5sdz1=2Y8fWz2p52d-pNV90@mail.gmail.com>
	<20100918203409.GE9274@ms.unimelb.edu.au>
	<20100918102405.f8ef1dodxwckg0o4@www.staffmail.ed.ac.uk>
	<4C948D4D.9080602@gmail.com>
Message-ID: <20100918110904.2a7vt65qko84k4og@www.staffmail.ed.ac.uk>

Both converge to the same answer on Fedora and Mac (Mac sessionInfo() below)

lmer(score~trt+(1|id/eye),dat, verbose=T, start=list(matrix(10),matrix(10)))
  0:     429.50725:  10.0000  10.0000
   1:     406.76151:  12.7962  11.2523
   2:     403.69482:  13.3016  12.8538
   3:     403.18712:  13.6918  13.5236
   4:     403.15738:  13.8230  13.6823
   5:     403.15696:  13.8432  13.6895
   6:     403.15694:  13.8467  13.6854
   7:     403.15694:  13.8475  13.6827
   8:     403.15694:  13.8474  13.6826

lmer(score~trt+(1|id/eye),dat, verbose=T, start=list(matrix(.81),matrix(.57)))

  1:     1304.7519:  2.42844  1.75398
   2:     776.66857:  6.30805  0.00000
   3:     657.56008:  7.73875  0.00000
   4:     514.89384:  10.7783 0.000123881
   5:     460.61372:  13.2310 0.00140974
   6:     434.88979:  15.6779 0.00908817
   7:     426.68762:  17.5388 0.0316599
   8:     424.89288:  18.6843 0.0743135
   9:     424.71437:  19.1269 0.132248
  10:     424.70495:  19.2146 0.203365
  11:     424.68492:  19.3175 0.420732
  12:     424.52038:  19.7021  1.39710
  13:     424.12511:  20.4042  3.37502
  14:     422.97192:  20.4400  4.91187
  15:     417.56194:  17.5366  5.92339
  16:     406.81181:  13.4830  17.5342
  17:     405.45194:  15.7947  12.4361
  18:     404.19817:  15.0352  12.5415
  19:     403.37771:  13.5806  13.0273
  20:     403.37260:  13.7001  14.5562
  21:     403.16170:  13.8571  13.8057
  22:     403.15707:  13.8372  13.6724
  23:     403.15694:  13.8483  13.6821
  24:     403.15694:  13.8473  13.6827
  25:     403.15694:  13.8474  13.6826

sessionInfo()
R version 2.10.1 (2009-12-14)
i386-apple-darwin9.8.0

locale:
[1] en_GB.UTF-8/en_GB.UTF-8/C/C/en_GB.UTF-8/en_GB.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_0.999375-35   Matrix_0.999375-43 lattice_0.18-3

loaded via a namespace (and not attached):
[1] grid_2.10.1   nlme_3.1-96   stats4_2.10.1




Quoting Peter Dalgaard <pdalgd at gmail.com>:

> On 09/18/2010 11:24 AM, Jarrod Hadfield wrote:
>> Fedora Core 13 seems fine:
>>
>> Linear mixed model fit by REML
>> Formula: score ~ trt + (1 | id/eye)
>>     Data: dat
>>     AIC   BIC logLik deviance REMLdev
>>   425.2 474.2 -201.6    412.7   403.2
>> Random effects:
>>   Groups   Name        Variance Std.Dev.
>>   eye:id   (Intercept) 3.59532  1.89613
>>   id       (Intercept) 3.51024  1.87356
>>   Residual             0.01875  0.13693
>> Number of obs: 640, groups: eye:id, 160; id, 80
>
> Not in 32bit:
>
>> lmer(score~trt+(1|id/eye),dat)
> Linear mixed model fit by REML
> Formula: score ~ trt + (1 | id/eye)
>    Data: dat
>    AIC   BIC logLik deviance REMLdev
>  446.7 495.8 -212.4    430.9   424.7
> Random effects:
>  Groups   Name        Variance   Std.Dev.
>  eye:id   (Intercept) 6.9208e+00 2.6307e+00
>  id       (Intercept) 4.0996e-12 2.0248e-06
>  Residual             1.8750e-02 1.3693e-01
> Number of obs: 640, groups: eye:id, 160; id, 80
>
> Diddling the start values can change the result, though. Could you all try
>
> (a) setting verbose=T
> (b) try start=list(matrix(10),matrix(10))
> (c) same thing, but with .81 and .57
>
>
> In the (c) case, I get
>
>> l <- lmer(score~trt+(1|id/eye),dat,
> start=list(matrix(.81),matrix(.57)), verbose=T)
>   0:     2226.5319: 0.810000 0.570000
>   1:     1304.7507:  2.42844  1.75398
>   2:     776.66839:  6.30805  0.00000
>   3:     657.56008:  7.73875  0.00000
>   4:     514.89378:  10.7783  0.00000
>   5:     460.61371:  13.2310  0.00000
>   6:     434.88972:  15.6779 1.52026e-08
>   7:     426.68822:  17.5387 6.57868e-08
>   8:     424.89428:  18.6843 1.41900e-07
>   9:     424.71823:  19.1258 2.47916e-07
>  10:     424.71356:  19.2075 3.75766e-07
>  11:     424.71354:  19.2122 5.37851e-07
>  12:     424.71354:  19.2122 7.55161e-07
>
> which suggests an algorithm error where the parameters are getting stuck
> on the boundary. These values match the automatically generated starting
> values only to two digits, so I'm somewhat baffled that you apparently
> get something completely different in 64 bits!
>
> --
> Peter Dalgaard
> Center for Statistics, Copenhagen Business School
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From johan.h.jackson at gmail.com  Sat Sep 18 02:43:48 2010
From: johan.h.jackson at gmail.com (Johan Jackson)
Date: Fri, 17 Sep 2010 18:43:48 -0600
Subject: [R-sig-ME] modeling variance heterogeneity in lme4
Message-ID: <AANLkTi=tougcGg2wPJnR-_7RfHoyHEw+vmQKwDeWZayO@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100917/4b0fd91b/attachment.pl>

From johan.h.jackson at gmail.com  Sat Sep 18 02:48:43 2010
From: johan.h.jackson at gmail.com (Johan Jackson)
Date: Fri, 17 Sep 2010 18:48:43 -0600
Subject: [R-sig-ME] modeling variance heterogeneity in lme4
In-Reply-To: <AANLkTi=tougcGg2wPJnR-_7RfHoyHEw+vmQKwDeWZayO@mail.gmail.com>
References: <AANLkTi=tougcGg2wPJnR-_7RfHoyHEw+vmQKwDeWZayO@mail.gmail.com>
Message-ID: <AANLkTimJmpU01Y=YAc5jATDc6feredRCR8TyQs4oa+wu@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100917/25909099/attachment.pl>

From lborger at uoguelph.ca  Sat Sep 18 23:17:24 2010
From: lborger at uoguelph.ca (Luca Borger)
Date: Sat, 18 Sep 2010 17:17:24 -0400
Subject: [R-sig-ME] lmer() vs. lme() gave different variance component
	estimates
References: <851867.90179.qm@web56305.mail.re3.yahoo.com>	<AANLkTikcWBPYYpqJmi=5mbYZ3zty2vd8wUX95uP1-G3d@mail.gmail.com>	<889816.11434.qm@web56307.mail.re3.yahoo.com>	<AANLkTimQF2AdGjeSiBxec5sdz1=2Y8fWz2p52d-pNV90@mail.gmail.com>	<20100918203409.GE9274@ms.unimelb.edu.au><20100918102405.f8ef1dodxwckg0o4@www.staffmail.ed.ac.uk>
	<4C948D4D.9080602@gmail.com>
Message-ID: <1E694BE6BF7340129DB6C0606F97E1D1@lborger>

> Diddling the start values can change the result, though. Could you all try
>
> (a) setting verbose=T
> (b) try start=list(matrix(10),matrix(10))
> (c) same thing, but with .81 and .57



# In case this is of any use, I get (Win-XP, 32-bit, sessionInfo() at the 
end):

> mod_a <- lmer(score ~ trt+(1|id/eye), dat, verbose=T)
  0:     2219.2409: 0.816497 0.577350
  1:     1300.6006:  2.44030  1.76298
  2:     774.29059:  6.33180  0.00000
  3:     655.91611:  7.76290  0.00000
  4:     514.09907:  10.8045  0.00000
  5:     460.23606:  13.2559  0.00000
  6:     434.74990:  15.6993  0.00000
  7:     426.65081:  17.5537  0.00000
  8:     424.88919:  18.6916 1.16103e-08
  9:     424.71803:  19.1277 2.38735e-08
 10:     424.71356:  19.2077 4.23682e-08
 11:     424.71354:  19.2122 6.29032e-08
 12:     424.71354:  19.2122 8.78525e-08
>

> mod_a
Linear mixed model fit by REML
Formula: score ~ trt + (1 | id/eye)
   Data: dat
   AIC   BIC logLik deviance REMLdev
 446.7 495.8 -212.4    430.9   424.7
Random effects:
 Groups   Name        Variance   Std.Dev.
 eye:id   (Intercept) 6.9208e+00 2.6307e+00
 id       (Intercept) 1.4471e-16 1.2030e-08
 Residual             1.8750e-02 1.3693e-01
Number of obs: 640, groups: eye:id, 160; id, 80


> mod_b <- lmer(score ~ trt+(1|id/eye), dat, 
> start=list(matrix(10),matrix(10)), verbose=T)
  0:     429.50725:  10.0000  10.0000
  1:     406.77628:  12.7928  11.2494
  2:     403.69604:  13.2997  12.8550
  3:     403.18732:  13.6909  13.5238
  4:     403.15739:  13.8229  13.6825
  5:     403.15696:  13.8431  13.6896
  6:     403.15694:  13.8467  13.6854
  7:     403.15694:  13.8475  13.6828
  8:     403.15694:  13.8474  13.6826
Warning message:
In is.na(x) : is.na() applied to non-(list or vector) of type 'NULL'
>

> mod_b
Linear mixed model fit by REML
Formula: score ~ trt + (1 | id/eye)
   Data: dat
   AIC   BIC logLik deviance REMLdev
 425.2 474.2 -201.6    412.7   403.2
Random effects:
 Groups   Name Variance Std.Dev.
 eye:id        3.59532  1.89613
 id            3.51024  1.87356
 Residual      0.01875  0.13693
Number of obs: 640, groups: eye:id, 160; id, 80


> mod_c <- lmer(score ~ trt+(1|id/eye), dat, 
> start=list(matrix(.81),matrix(.57)), verbose=T)
  0:     2226.5319: 0.810000 0.570000
  1:     1304.7507:  2.42844  1.75398
  2:     776.66839:  6.30805  0.00000
  3:     657.56009:  7.73875  0.00000
  4:     514.89375:  10.7783  0.00000
  5:     460.61370:  13.2310 5.55866e-08
  6:     434.88975:  15.6779 3.94635e-07
  7:     426.68823:  17.5387 1.39786e-06
  8:     424.89427:  18.6843 3.27134e-06
  9:     424.71823:  19.1258 5.82021e-06
 10:     424.71356:  19.2075 8.90695e-06
 11:     424.71354:  19.2122 1.28100e-05
 12:     424.71354:  19.2122 1.80876e-05
Warning message:
In is.na(x) : is.na() applied to non-(list or vector) of type 'NULL'
>


> mod_c
Linear mixed model fit by REML
Formula: score ~ trt + (1 | id/eye)
   Data: dat
   AIC   BIC logLik deviance REMLdev
 446.7 495.8 -212.4    430.9   424.7
Random effects:
 Groups   Name Variance   Std.Dev.
 eye:id        6.9208e+00 2.6307e+00
 id            6.1342e-12 2.4767e-06
 Residual      1.8750e-02 1.3693e-01
Number of obs: 640, groups: eye:id, 160; id, 80


> sessionInfo()
R version 2.11.1 (2010-05-31)
i386-pc-mingw32

locale:
[1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United 
Kingdom.1252    LC_MONETARY=English_United Kingdom.1252
[4] LC_NUMERIC=C                            LC_TIME=English_United 
Kingdom.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_0.999375-35   Matrix_0.999375-44 lattice_0.19-11

loaded via a namespace (and not attached):
[1] grid_2.11.1   nlme_3.1-96   stats4_2.11.1 tools_2.11.1
>


HTH

Cheers,

Luca



----- Original Message ----- 
From: "Peter Dalgaard" <pdalgd at gmail.com>
To: "Jarrod Hadfield" <j.hadfield at ed.ac.uk>
Cc: <r-sig-mixed-models at r-project.org>
Sent: Saturday, September 18, 2010 5:58 AM
Subject: Re: [R-sig-ME] lmer() vs. lme() gave different variance component 
estimates


> On 09/18/2010 11:24 AM, Jarrod Hadfield wrote:
>> Fedora Core 13 seems fine:
>>
>> Linear mixed model fit by REML
>> Formula: score ~ trt + (1 | id/eye)
>>     Data: dat
>>     AIC   BIC logLik deviance REMLdev
>>   425.2 474.2 -201.6    412.7   403.2
>> Random effects:
>>   Groups   Name        Variance Std.Dev.
>>   eye:id   (Intercept) 3.59532  1.89613
>>   id       (Intercept) 3.51024  1.87356
>>   Residual             0.01875  0.13693
>> Number of obs: 640, groups: eye:id, 160; id, 80
>
> Not in 32bit:
>
>> lmer(score~trt+(1|id/eye),dat)
> Linear mixed model fit by REML
> Formula: score ~ trt + (1 | id/eye)
>   Data: dat
>   AIC   BIC logLik deviance REMLdev
> 446.7 495.8 -212.4    430.9   424.7
> Random effects:
> Groups   Name        Variance   Std.Dev.
> eye:id   (Intercept) 6.9208e+00 2.6307e+00
> id       (Intercept) 4.0996e-12 2.0248e-06
> Residual             1.8750e-02 1.3693e-01
> Number of obs: 640, groups: eye:id, 160; id, 80
>
> Diddling the start values can change the result, though. Could you all try
>
> (a) setting verbose=T
> (b) try start=list(matrix(10),matrix(10))
> (c) same thing, but with .81 and .57
>
>
> In the (c) case, I get
>
>> l <- lmer(score~trt+(1|id/eye),dat,
> start=list(matrix(.81),matrix(.57)), verbose=T)
>  0:     2226.5319: 0.810000 0.570000
>  1:     1304.7507:  2.42844  1.75398
>  2:     776.66839:  6.30805  0.00000
>  3:     657.56008:  7.73875  0.00000
>  4:     514.89378:  10.7783  0.00000
>  5:     460.61371:  13.2310  0.00000
>  6:     434.88972:  15.6779 1.52026e-08
>  7:     426.68822:  17.5387 6.57868e-08
>  8:     424.89428:  18.6843 1.41900e-07
>  9:     424.71823:  19.1258 2.47916e-07
> 10:     424.71356:  19.2075 3.75766e-07
> 11:     424.71354:  19.2122 5.37851e-07
> 12:     424.71354:  19.2122 7.55161e-07
>
> which suggests an algorithm error where the parameters are getting stuck
> on the boundary. These values match the automatically generated starting
> values only to two digits, so I'm somewhat baffled that you apparently
> get something completely different in 64 bits!
>
> -- 
> Peter Dalgaard
> Center for Statistics, Copenhagen Business School
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From farmerb at gmail.com  Mon Sep 20 03:49:58 2010
From: farmerb at gmail.com (Bob Farmer)
Date: Sun, 19 Sep 2010 22:49:58 -0300
Subject: [R-sig-ME] MCMCglmm for binomial models?
Message-ID: <AANLkTinF=k-SaD6wmYd3TsHp8-7hdAqYfQOU203rt6Wk@mail.gmail.com>

Hi all, I've spent some time evaluating MCMCglmm as a faster
alternative to WinBUGS and lmer (+/- mcmcsamp) for my modeling, and I
wonder if anyone (esp. Dr. Hadfield) could comment on using this
package for binomial models.  Consider the following test code:

############  first, a Gaussian model
library(MCMCglmm); library(lme4)
data(PlodiaPO)
mc2<-MCMCglmm(PO~plate, random=~FSfamily, data=PlodiaPO, verbose=FALSE)
gm2<-lmer(PO ~ 1 + plate + (1|FSfamily), data = PlodiaPO)
summary(mc2)
summary(gm2)@coefs

where, as an index of MCMCglmm's ability to perform like lmer, the
fixed-effects coefficients are quite similar.
On the other hand, in this case:

#################now binomial from a reference dataset
gm3 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
              family = binomial, data = cbpp)
mc3<-MCMCglmm(cbind(incidence, size - incidence) ~ period,
  random = ~ herd,
  family = "multinomial2",
  data = cbpp, verbose = FALSE,
  nitt = 50E3
)
summary(gm3)@coefs
summary(mc3)

(with extra iterations for insurance), the results are far more
variable, and generally not consistent with glmer()'s output.
Assuming that glmer()'s output is okay (and maybe this is a big
assumption?  it *is* the example listed in the helpfile), does this
mean that MCMCglmm doesn't perform well in these sorts of models
without lots of attention?  I've spent some time playing with prior
specifications, but I find the documentation in this department is a
bit weak (G =list(G1)?  what's G1?  what's "n"?), and so I'm not
comfortable spending too much time when I already am at the leading
edge of "knowing what it is I'm doing".

Any help is much appreciated!
Thanks.
--Bob Farmer
Dalhousie University



From davidD at qimr.edu.au  Mon Sep 20 06:51:52 2010
From: davidD at qimr.edu.au (David Duffy)
Date: Mon, 20 Sep 2010 14:51:52 +1000 (EST)
Subject: [R-sig-ME] MCMCglmm for binomial models?
In-Reply-To: <AANLkTinF=k-SaD6wmYd3TsHp8-7hdAqYfQOU203rt6Wk@mail.gmail.com>
References: <AANLkTinF=k-SaD6wmYd3TsHp8-7hdAqYfQOU203rt6Wk@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.1009201445240.3626@orpheus.qimr.edu.au>

On Sun, 19 Sep 2010, Bob Farmer wrote:

>  nitt = 50E3
>
> (with extra iterations for insurance), the results are far more
> variable, and generally not consistent with glmer()'s output.

You need to look at the effective sample size for each parameter (eff.samp 
in the summary output) -- 50000 reduces to only 10-80 independent 
observations for this example as I ran it, so there is still a largish 
Monte Carlo error.

> Assuming that glmer()'s output is okay (and maybe this is a big
> assumption?

Not for this simple problem.

Cheers, David Duffy.



From pdalgd at gmail.com  Mon Sep 20 08:35:05 2010
From: pdalgd at gmail.com (Peter Dalgaard)
Date: Mon, 20 Sep 2010 08:35:05 +0200
Subject: [R-sig-ME] lmer() vs. lme() gave different variance component
 estimates
In-Reply-To: <20100918110904.2a7vt65qko84k4og@www.staffmail.ed.ac.uk>
References: <851867.90179.qm@web56305.mail.re3.yahoo.com>	<AANLkTikcWBPYYpqJmi=5mbYZ3zty2vd8wUX95uP1-G3d@mail.gmail.com>	<889816.11434.qm@web56307.mail.re3.yahoo.com>	<AANLkTimQF2AdGjeSiBxec5sdz1=2Y8fWz2p52d-pNV90@mail.gmail.com>	<20100918203409.GE9274@ms.unimelb.edu.au>	<20100918102405.f8ef1dodxwckg0o4@www.staffmail.ed.ac.uk>	<4C948D4D.9080602@gmail.com>
	<20100918110904.2a7vt65qko84k4og@www.staffmail.ed.ac.uk>
Message-ID: <4C970099.7000701@gmail.com>

On 09/18/2010 12:09 PM, Jarrod Hadfield wrote:
> Both converge to the same answer on Fedora and Mac (Mac sessionInfo() below)
[snip]
> lmer(score~trt+(1|id/eye),dat, verbose=T, start=list(matrix(.81),matrix(.57)))
> 
>   1:     1304.7519:  2.42844  1.75398
>    2:     776.66857:  6.30805  0.00000
>    3:     657.56008:  7.73875  0.00000
>    4:     514.89384:  10.7783 0.000123881
>    5:     460.61372:  13.2310 0.00140974
>    6:     434.88979:  15.6779 0.00908817
>    7:     426.68762:  17.5388 0.0316599
>    8:     424.89288:  18.6843 0.0743135
>    9:     424.71437:  19.1269 0.132248
>   10:     424.70495:  19.2146 0.203365
>   11:     424.68492:  19.3175 0.420732
[snip]
>>> l <- lmer(score~trt+(1|id/eye),dat,
>> start=list(matrix(.81),matrix(.57)), verbose=T)
>>   0:     2226.5319: 0.810000 0.570000
>>   1:     1304.7507:  2.42844  1.75398
>>   2:     776.66839:  6.30805  0.00000
>>   3:     657.56008:  7.73875  0.00000
>>   4:     514.89378:  10.7783  0.00000
>>   5:     460.61371:  13.2310  0.00000
>>   6:     434.88972:  15.6779 1.52026e-08
>>   7:     426.68822:  17.5387 6.57868e-08
>>   8:     424.89428:  18.6843 1.41900e-07
>>   9:     424.71823:  19.1258 2.47916e-07
>>  10:     424.71356:  19.2075 3.75766e-07
>>  11:     424.71354:  19.2122 5.37851e-07
>>  12:     424.71354:  19.2122 7.55161e-07

This would appear to be the crux. Notice how in both cases the 2nd
parameter gets thrown to (near-) zero, but on the 64-bit machine, it
manages to claw  itself back, in 32 bits it is struggling as well, but
not fast enough so that convergence is declared prematurely.

I'm not quite up to speed on the current implementation of lmer, but I
guess that it is still using the log-Cholesky representation, and I
suspect that the above is displaying a general weakness of
log-parametrizations: By introducing singularities at the boundary of
the parameter space it turns an otherwise perfectly well-behaved
likelihood into one with extensive very flat regions.

In this case, the REML likelihood can be explicitly written as a product
of three  chi-square terms with a linear parametrization of their scale
parameters, profiled over one of the parameters, and with an explicit
formula for the maximum to boot. Someone with a large piece of paper and
sufficient time on their hand should be able to map the situation out in
extensive detail.

(I'm also continually fascinated by the fact that so large differences
come up between 32-bit and 64-bit platforms and I can't quite escape
from the suspicion that somewhere in our code, we have an unintended
platform dependence. However, I don't think that is the main point here.)



-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com



From farmerb at gmail.com  Mon Sep 20 14:17:44 2010
From: farmerb at gmail.com (Bob Farmer)
Date: Mon, 20 Sep 2010 09:17:44 -0300
Subject: [R-sig-ME] MCMCglmm for binomial models?
In-Reply-To: <Pine.LNX.4.64.1009201445240.3626@orpheus.qimr.edu.au>
References: <AANLkTinF=k-SaD6wmYd3TsHp8-7hdAqYfQOU203rt6Wk@mail.gmail.com>
	<Pine.LNX.4.64.1009201445240.3626@orpheus.qimr.edu.au>
Message-ID: <AANLkTik9FcrgbFSk2Bs9_nMFNTmSDPLSKJu+Jvxg9fLg@mail.gmail.com>

Thanks for the reply.  Unfortunately, I'm not sure that that's the
whole story.  Upping the iterations to achieve an effective sample
size of 1000 (output pasted below) still leads to some differences
between the two models (total runtime on a quad-core Windows box is
under 2 minutes, in case you want to try).  In fact, running it a
second time shooting for an n.eff of 2000 (thin = 325) leads to even
more divergent estimates (e.g. mean.int == -72.96).  Again, assuming
that the glmer() output in this case is a `gold standard', maybe
there's another puzzle piece missing?

Thanks again.
--Bob


#################now binomial from a reference dataset
gm3 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
              family = binomial, data = cbpp)
mc3<-MCMCglmm(cbind(incidence, size - incidence) ~ period,
  random = ~ herd,
  family = "multinomial2",
  data = cbpp, verbose = FALSE,
  nitt = 750E3, thin = 650, burnin = 100E3
)
summary(gm3)@coefs
summary(mc3)

Leads to:

> summary(gm3)@coefs
              Estimate Std. Error   z value     Pr(>|z|)
(Intercept) -1.3985351  0.2278906 -6.136871 8.416284e-10
period2     -0.9923347  0.3053852 -3.249452 1.156274e-03
period3     -1.1286754  0.3260491 -3.461673 5.368286e-04
period4     -1.5803739  0.4288037 -3.685542 2.282169e-04

Versus:

> summary(mc3)

 Iterations = 749351
 Thinning interval  = 100001
 Sample size  = 1000
....
            post.mean l-95% CI u-95% CI eff.samp pMCMC
(Intercept)   -1.6102  -2.2092  -0.8357     1000 0.002 **
period2       -1.2476  -2.2146  -0.1284     1000 0.020 *
period3       -1.3743  -2.3387  -0.2746     1000 0.008 **
period4       -1.9677  -3.2814  -0.8065     1000 0.008 **
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1



From armstrong.whit at gmail.com  Mon Sep 20 14:50:26 2010
From: armstrong.whit at gmail.com (Whit Armstrong)
Date: Mon, 20 Sep 2010 08:50:26 -0400
Subject: [R-sig-ME] MCMCglmm for binomial models?
In-Reply-To: <AANLkTik9FcrgbFSk2Bs9_nMFNTmSDPLSKJu+Jvxg9fLg@mail.gmail.com>
References: <AANLkTinF=k-SaD6wmYd3TsHp8-7hdAqYfQOU203rt6Wk@mail.gmail.com>
	<Pine.LNX.4.64.1009201445240.3626@orpheus.qimr.edu.au>
	<AANLkTik9FcrgbFSk2Bs9_nMFNTmSDPLSKJu+Jvxg9fLg@mail.gmail.com>
Message-ID: <AANLkTi=e51Mn9EKKQ0nzXGRfczNxWARMQMV0WqOVvwmC@mail.gmail.com>

Bob,

Do you mind posting the winbugs code for your model?  I am curious to
see how pymc performs.  Additionally, I have a pure c++ MCMC package.
Which I would like to try too.

A link to some sample data would be useful as well.

-Whit


On Mon, Sep 20, 2010 at 8:17 AM, Bob Farmer <farmerb at gmail.com> wrote:
> Thanks for the reply. ?Unfortunately, I'm not sure that that's the
> whole story. ?Upping the iterations to achieve an effective sample
> size of 1000 (output pasted below) still leads to some differences
> between the two models (total runtime on a quad-core Windows box is
> under 2 minutes, in case you want to try). ?In fact, running it a
> second time shooting for an n.eff of 2000 (thin = 325) leads to even
> more divergent estimates (e.g. mean.int == -72.96). ?Again, assuming
> that the glmer() output in this case is a `gold standard', maybe
> there's another puzzle piece missing?
>
> Thanks again.
> --Bob
>
>
> #################now binomial from a reference dataset
> gm3 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
> ? ? ? ? ? ? ?family = binomial, data = cbpp)
> mc3<-MCMCglmm(cbind(incidence, size - incidence) ~ period,
> ?random = ~ herd,
> ?family = "multinomial2",
> ?data = cbpp, verbose = FALSE,
> ?nitt = 750E3, thin = 650, burnin = 100E3
> )
> summary(gm3)@coefs
> summary(mc3)
>
> Leads to:
>
>> summary(gm3)@coefs
> ? ? ? ? ? ? ?Estimate Std. Error ? z value ? ? Pr(>|z|)
> (Intercept) -1.3985351 ?0.2278906 -6.136871 8.416284e-10
> period2 ? ? -0.9923347 ?0.3053852 -3.249452 1.156274e-03
> period3 ? ? -1.1286754 ?0.3260491 -3.461673 5.368286e-04
> period4 ? ? -1.5803739 ?0.4288037 -3.685542 2.282169e-04
>
> Versus:
>
>> summary(mc3)
>
> ?Iterations = 749351
> ?Thinning interval ?= 100001
> ?Sample size ?= 1000
> ....
> ? ? ? ? ? ?post.mean l-95% CI u-95% CI eff.samp pMCMC
> (Intercept) ? -1.6102 ?-2.2092 ?-0.8357 ? ? 1000 0.002 **
> period2 ? ? ? -1.2476 ?-2.2146 ?-0.1284 ? ? 1000 0.020 *
> period3 ? ? ? -1.3743 ?-2.3387 ?-0.2746 ? ? 1000 0.008 **
> period4 ? ? ? -1.9677 ?-3.2814 ?-0.8065 ? ? 1000 0.008 **
> ---
> Signif. codes: ?0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From Thierry.ONKELINX at inbo.be  Mon Sep 20 16:43:19 2010
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 20 Sep 2010 16:43:19 +0200
Subject: [R-sig-ME] MCMCglmm for binomial models?
In-Reply-To: <AANLkTik9FcrgbFSk2Bs9_nMFNTmSDPLSKJu+Jvxg9fLg@mail.gmail.com>
References: <AANLkTinF=k-SaD6wmYd3TsHp8-7hdAqYfQOU203rt6Wk@mail.gmail.com><Pine.LNX.4.64.1009201445240.3626@orpheus.qimr.edu.au>
	<AANLkTik9FcrgbFSk2Bs9_nMFNTmSDPLSKJu+Jvxg9fLg@mail.gmail.com>
Message-ID: <3DB16098F738284D8DBEB2FC3699163837C274@inboexch.inbo.be>

Dear Bob,

Notice that MCMCglmm always estimates 'units' to take overdispersion
into account. So the glmer model and the MCMCglmm model are not the
same.

Furthermore, you did not specify the priors. I'm not sure if the default
work well for all types of models.

HTH,

Thierry


------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey
  

> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Bob Farmer
> Verzonden: maandag 20 september 2010 14:18
> Aan: David Duffy; r-sig-mixed-models at r-project.org
> Onderwerp: Re: [R-sig-ME] MCMCglmm for binomial models?
> 
> Thanks for the reply.  Unfortunately, I'm not sure that 
> that's the whole story.  Upping the iterations to achieve an 
> effective sample size of 1000 (output pasted below) still 
> leads to some differences between the two models (total 
> runtime on a quad-core Windows box is under 2 minutes, in 
> case you want to try).  In fact, running it a second time 
> shooting for an n.eff of 2000 (thin = 325) leads to even more 
> divergent estimates (e.g. mean.int == -72.96).  Again, 
> assuming that the glmer() output in this case is a `gold 
> standard', maybe there's another puzzle piece missing?
> 
> Thanks again.
> --Bob
> 
> 
> #################now binomial from a reference dataset
> gm3 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
>               family = binomial, data = cbpp) 
> mc3<-MCMCglmm(cbind(incidence, size - incidence) ~ period,
>   random = ~ herd,
>   family = "multinomial2",
>   data = cbpp, verbose = FALSE,
>   nitt = 750E3, thin = 650, burnin = 100E3
> )
> summary(gm3)@coefs
> summary(mc3)
> 
> Leads to:
> 
> > summary(gm3)@coefs
>               Estimate Std. Error   z value     Pr(>|z|)
> (Intercept) -1.3985351  0.2278906 -6.136871 8.416284e-10
> period2     -0.9923347  0.3053852 -3.249452 1.156274e-03
> period3     -1.1286754  0.3260491 -3.461673 5.368286e-04
> period4     -1.5803739  0.4288037 -3.685542 2.282169e-04
> 
> Versus:
> 
> > summary(mc3)
> 
>  Iterations = 749351
>  Thinning interval  = 100001
>  Sample size  = 1000
> ....
>             post.mean l-95% CI u-95% CI eff.samp pMCMC
> (Intercept)   -1.6102  -2.2092  -0.8357     1000 0.002 **
> period2       -1.2476  -2.2146  -0.1284     1000 0.020 *
> period3       -1.3743  -2.3387  -0.2746     1000 0.008 **
> period4       -1.9677  -3.2814  -0.8065     1000 0.008 **
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

Druk dit bericht a.u.b. niet onnodig af.
Please do not print this message unnecessarily.

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From j.hadfield at ed.ac.uk  Mon Sep 20 19:03:28 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 20 Sep 2010 18:03:28 +0100
Subject: [R-sig-ME] MCMCglmm for binomial models?
In-Reply-To: <3DB16098F738284D8DBEB2FC3699163837C274@inboexch.inbo.be>
References: <AANLkTinF=k-SaD6wmYd3TsHp8-7hdAqYfQOU203rt6Wk@mail.gmail.com><Pine.LNX.4.64.1009201445240.3626@orpheus.qimr.edu.au>
	<AANLkTik9FcrgbFSk2Bs9_nMFNTmSDPLSKJu+Jvxg9fLg@mail.gmail.com>
	<3DB16098F738284D8DBEB2FC3699163837C274@inboexch.inbo.be>
Message-ID: <20100920180328.m345nbowgc48g0g4@www.staffmail.ed.ac.uk>

Dear Bob,

As Thierry points out the main difference is that MCMCglmm  
automatically fits a "residual" variance and in this case (in most  
cases!) the data are over-dispersed. I am sure glmer gives the right  
answer for the model it is trying to fit, but I would say the model is  
wrong. For example, if you fit an observation level random effect in  
glmer you will find that the herd variance is more than an order of  
magnitude smaller than what it was:

cbpp$id<-as.factor(1:dim(cbpp)[1])

gm3b <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd)+(1|id),
              family = binomial, data = cbpp)

summary(gm3b)

Generalized linear mixed model fit by the Laplace approximation
Formula: cbind(incidence, size - incidence) ~ period + (1 | herd) + (1  
|      id)
    Data: cbpp
    AIC   BIC logLik deviance
  102.7 114.8 -45.34    90.68
Random effects:
  Groups Name        Variance Std.Dev.
  id     (Intercept) 0.794023 0.89108
  herd   (Intercept) 0.033835 0.18394
Number of obs: 56, groups: id, 56; herd, 15

Fixed effects:
             Estimate Std. Error z value Pr(>|z|)
(Intercept)  -1.5003     0.2888  -5.196 2.04e-07 ***
period2      -1.2265     0.4735  -2.591  0.00958 **
period3      -1.3288     0.4884  -2.721  0.00651 **
period4      -1.8663     0.5906  -3.160  0.00158 **
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
         (Intr) perid2 perid3
period2 -0.594
period3 -0.576  0.353
period4 -0.476  0.292  0.282

With respect to the prior - MCMCglmm can hit (and does with this  
problem occasionally) numerical problems with near-singular covariance  
matrices when priors aren't used.  Here are some priors that may be of  
use:

  prior1=list(R=list(V=1, nu=0.002), G=list(G1=list(V=1, nu=0.002)))

This fits an inverse-Wishart prior for both the units (residual)  
variance (the R element) and an inverse-Wishart for the herd variance  
(the first and only element of G). If you fitted >1 random term G  
would be a list with an additional element (you could call it G2 or  
anything you like). This prior is equivalent to an inverse gamma prior  
with shape=scale=0.001, which used to be used a lot in WinBUGS. It is  
now known to have poor properties when a variance is close to zero and  
so an alternative recommendation is to use parameter expanded priors.  
Parameter expansion was originally developed for computational reasons  
but it turns out that it induces scaled non-central F priors for the  
variance components. These can have nicer properties (see section 8 of  
the CourseNotes or the Gelman reference). As an example:

   prior2=list(R=list(V=1, nu=0.002), G=list(G1=list(V=1, nu=1,  
alpha.mu=0, alpha.V=100)))

For both priors the results are broadly similar and give answers close  
to glmer:

mc3b<-MCMCglmm(cbind(incidence, size - incidence) ~ period,
  random = ~ herd,
  family = "multinomial2",
  data = cbpp, verbose = FALSE,
  nitt = 50E3,
prior=prior1)

mc3c<-MCMCglmm(cbind(incidence, size - incidence) ~ period,
  random = ~ herd,
  family = "multinomial2",
  data = cbpp, verbose = FALSE,
  nitt = 50E3,
prior=prior2)

The posteriors for the variances are skewed making the comparison  
between the posterior mean (i.e. as shown in summary(mc3b)) and the  
REML mode difficult. However, a plot shows the correspondence nicely:

plot(cbind(mc3b$VCV), pch=19, cex=0.2)
points(cbind(mc3c$VCV), pch=19, cex=0.2, col="green")
points(0.033835, 0.794023, col="red", pch=19)

Cheers,

Jarrod


Quoting "ONKELINX, Thierry" <Thierry.ONKELINX at inbo.be>:

> Dear Bob,
>
> Notice that MCMCglmm always estimates 'units' to take overdispersion
> into account. So the glmer model and the MCMCglmm model are not the
> same.
>
> Furthermore, you did not specify the priors. I'm not sure if the default
> work well for all types of models.
>
> HTH,
>
> Thierry
>
>
> ------------------------------------------------------------------------
> ----
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek
> team Biometrie & Kwaliteitszorg
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium
>
> Research Institute for Nature and Forest
> team Biometrics & Quality Assurance
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium
>
> tel. + 32 54/436 185
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to
> say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of
> data.
> ~ John Tukey
>
>
>> -----Oorspronkelijk bericht-----
>> Van: r-sig-mixed-models-bounces at r-project.org
>> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Bob Farmer
>> Verzonden: maandag 20 september 2010 14:18
>> Aan: David Duffy; r-sig-mixed-models at r-project.org
>> Onderwerp: Re: [R-sig-ME] MCMCglmm for binomial models?
>>
>> Thanks for the reply.  Unfortunately, I'm not sure that
>> that's the whole story.  Upping the iterations to achieve an
>> effective sample size of 1000 (output pasted below) still
>> leads to some differences between the two models (total
>> runtime on a quad-core Windows box is under 2 minutes, in
>> case you want to try).  In fact, running it a second time
>> shooting for an n.eff of 2000 (thin = 325) leads to even more
>> divergent estimates (e.g. mean.int == -72.96).  Again,
>> assuming that the glmer() output in this case is a `gold
>> standard', maybe there's another puzzle piece missing?
>>
>> Thanks again.
>> --Bob
>>
>>
>> #################now binomial from a reference dataset
>> gm3 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
>>               family = binomial, data = cbpp)
>> mc3<-MCMCglmm(cbind(incidence, size - incidence) ~ period,
>>   random = ~ herd,
>>   family = "multinomial2",
>>   data = cbpp, verbose = FALSE,
>>   nitt = 750E3, thin = 650, burnin = 100E3
>> )
>> summary(gm3)@coefs
>> summary(mc3)
>>
>> Leads to:
>>
>> > summary(gm3)@coefs
>>               Estimate Std. Error   z value     Pr(>|z|)
>> (Intercept) -1.3985351  0.2278906 -6.136871 8.416284e-10
>> period2     -0.9923347  0.3053852 -3.249452 1.156274e-03
>> period3     -1.1286754  0.3260491 -3.461673 5.368286e-04
>> period4     -1.5803739  0.4288037 -3.685542 2.282169e-04
>>
>> Versus:
>>
>> > summary(mc3)
>>
>>  Iterations = 749351
>>  Thinning interval  = 100001
>>  Sample size  = 1000
>> ....
>>             post.mean l-95% CI u-95% CI eff.samp pMCMC
>> (Intercept)   -1.6102  -2.2092  -0.8357     1000 0.002 **
>> period2       -1.2476  -2.2146  -0.1284     1000 0.020 *
>> period3       -1.3743  -2.3387  -0.2746     1000 0.008 **
>> period4       -1.9677  -3.2814  -0.8065     1000 0.008 **
>> ---
>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> Druk dit bericht a.u.b. niet onnodig af.
> Please do not print this message unnecessarily.
>
> Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer
> en binden het INBO onder geen enkel beding, zolang dit bericht niet   
> bevestigd is
> door een geldig ondertekend document. The views expressed in  this message
> and any annex are purely those of the writer and may not be regarded  
>  as stating
> an official position of INBO, as long as the message is not   
> confirmed by a duly
> signed document.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From arrayprofile at yahoo.com  Mon Sep 20 20:09:58 2010
From: arrayprofile at yahoo.com (array chip)
Date: Mon, 20 Sep 2010 11:09:58 -0700 (PDT)
Subject: [R-sig-ME] [R] lmer() vs. lme() gave different variance
	component estimates
In-Reply-To: <4C9479E1.70303@gmail.com>
References: <127299.36449.qm@web56301.mail.re3.yahoo.com>
	<4C93CA07.6020708@gmail.com>
	<979833.56316.qm@web56303.mail.re3.yahoo.com>
	<4C9479E1.70303@gmail.com>
Message-ID: <681770.33787.qm@web56305.mail.re3.yahoo.com>

Thank you Peter for your explanation of relationship between aov and lme. It 
makes perfect sense. 


When you said "you might have computed the average of all 8
measurements on each animal and computed a 1-way ANOVA" for treatment effect, 
would this be the case for balanced design, or it is also true for unbalanced 
data?

Another question is if 1-way ANOVA is equivalent to mixed model for testing 
treatment effect, what would be reason why mixed model is used? Just to estimate 
the variance components? If the interest is not in the estimation of variance 
components, then there is no need to run mixed models to test treatment effects?

And my last question is I am glad to find that glht() from multcomp package 
works well with a lmer() fit for multiple comparisons. Given Professor Bates's 
view that denominator degree's of freedom is not well defined in mixed models, 
are the results from glht() reasonable/meaningful? If not, will the suggested 
1-way ANOVA used together with glht() give us correct post-hoc multiple 
comparsion results?

Thank you very much!

John





----- Original Message ----
From: Peter Dalgaard <pdalgd at gmail.com>
To: array chip <arrayprofile at yahoo.com>
Cc: r-help at r-project.org; r-sig-mixed-models at r-project.org
Sent: Sat, September 18, 2010 1:35:45 AM
Subject: Re: [R] lmer() vs. lme() gave different variance component estimates


For a nested design, the relation is quite straightforward: The residual
MS are the variances of sample means scaled to be comparable with the
residuals (so that in the absense of random components, all
MS are equal to within the F-ratio variability). So to get the id:eye
variance component, subtract the Within MS from the id:eye MS and divide
by the number of replicates (4 in this case since you have 640
observations on 160 eyes) (14.4 - 0.01875)/4 = 3.59, and similarly, the
id variance is the MS for id minus that for id:eye scaled by 8:
(42.482-14.4)/8 = 3.51.

I.e. it is reproducing the lmer results above, but of course not those
from your original post.

(Notice, by the way, that if you are only interested in the treatment
effect, you might as well have computed the average of all 8
measurements on each animal and computed a 1-way ANOVA).

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com



From bbolker at gmail.com  Mon Sep 20 20:27:39 2010
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 20 Sep 2010 14:27:39 -0400
Subject: [R-sig-ME] [R] lmer() vs. lme() gave different variance
 component estimates
In-Reply-To: <681770.33787.qm@web56305.mail.re3.yahoo.com>
References: <127299.36449.qm@web56301.mail.re3.yahoo.com>	<4C93CA07.6020708@gmail.com>	<979833.56316.qm@web56303.mail.re3.yahoo.com>	<4C9479E1.70303@gmail.com>
	<681770.33787.qm@web56305.mail.re3.yahoo.com>
Message-ID: <4C97A79B.8040508@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100920/c6968a95/attachment.pl>

From pdalgd at gmail.com  Mon Sep 20 21:28:43 2010
From: pdalgd at gmail.com (Peter Dalgaard)
Date: Mon, 20 Sep 2010 21:28:43 +0200
Subject: [R-sig-ME] [R] lmer() vs. lme() gave different variance
	component estimates
In-Reply-To: <681770.33787.qm@web56305.mail.re3.yahoo.com>
References: <127299.36449.qm@web56301.mail.re3.yahoo.com>
	<4C93CA07.6020708@gmail.com>
	<979833.56316.qm@web56303.mail.re3.yahoo.com>
	<4C9479E1.70303@gmail.com>
	<681770.33787.qm@web56305.mail.re3.yahoo.com>
Message-ID: <4C97B5EB.6010102@gmail.com>

On 09/20/2010 08:09 PM, array chip wrote:
> Thank you Peter for your explanation of relationship between aov and lme. It 
> makes perfect sense. 
> 
> 
> When you said "you might have computed the average of all 8
> measurements on each animal and computed a 1-way ANOVA" for treatment effect, 
> would this be the case for balanced design, or it is also true for unbalanced 
> data?

It is only exactly true for a balanced design, although it can be a
practical expedient in nearly-balanced cases, especially if there is a
clearly dominant animal variation. In strongly unbalanced data, you get
reduced efficiency because animals with less data should be downweighted
(not proportionally if there is substantial between-animal variation,
though). And of course the whole thing relies on the fact that you have
individuals nested in treatment (no animals had multiple treatments)

> 
> Another question is if 1-way ANOVA is equivalent to mixed model for testing 
> treatment effect, what would be reason why mixed model is used? Just to estimate 
> the variance components? If the interest is not in the estimation of variance 
> components, then there is no need to run mixed models to test treatment effects?

Not too far off the mark. In more complex cases, there is the advantage
that the mixed model helps figure out a sensible analysis for you.

 
> And my last question is I am glad to find that glht() from multcomp package 
> works well with a lmer() fit for multiple comparisons. Given Professor Bates's 
> view that denominator degree's of freedom is not well defined in mixed models, 
> are the results from glht() reasonable/meaningful? If not, will the suggested 
> 1-way ANOVA used together with glht() give us correct post-hoc multiple 
> comparsion results?

I think Doug's view is that DFs are not _reliably_estimated_ with any of
the current procedures. In the balanced cases, they are very well
defined (well, give or take the issues with "negative variances"), and I
would expect glht() to give meaningful results. Do check the residuals
for at least approximate normality, though.


> 
> Thank you very much!
> 
> John
> 
> 
> 
> 
> 
> ----- Original Message ----
> From: Peter Dalgaard <pdalgd at gmail.com>
> To: array chip <arrayprofile at yahoo.com>
> Cc: r-help at r-project.org; r-sig-mixed-models at r-project.org
> Sent: Sat, September 18, 2010 1:35:45 AM
> Subject: Re: [R] lmer() vs. lme() gave different variance component estimates
> 
> 
> For a nested design, the relation is quite straightforward: The residual
> MS are the variances of sample means scaled to be comparable with the
> residuals (so that in the absense of random components, all
> MS are equal to within the F-ratio variability). So to get the id:eye
> variance component, subtract the Within MS from the id:eye MS and divide
> by the number of replicates (4 in this case since you have 640
> observations on 160 eyes) (14.4 - 0.01875)/4 = 3.59, and similarly, the
> id variance is the MS for id minus that for id:eye scaled by 8:
> (42.482-14.4)/8 = 3.51.
> 
> I.e. it is reproducing the lmer results above, but of course not those
> from your original post.
> 
> (Notice, by the way, that if you are only interested in the treatment
> effect, you might as well have computed the average of all 8
> measurements on each animal and computed a 1-way ANOVA).
> 


-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com



From farmerb at gmail.com  Mon Sep 20 21:53:42 2010
From: farmerb at gmail.com (Bob Farmer)
Date: Mon, 20 Sep 2010 16:53:42 -0300
Subject: [R-sig-ME] MCMCglmm for binomial models?
In-Reply-To: <AANLkTinMsh-j3vxZPm9Z8+D5N7_m7YJPGsVsUanULL1b@mail.gmail.com>
References: <AANLkTinF=k-SaD6wmYd3TsHp8-7hdAqYfQOU203rt6Wk@mail.gmail.com>
	<Pine.LNX.4.64.1009201445240.3626@orpheus.qimr.edu.au>
	<AANLkTik9FcrgbFSk2Bs9_nMFNTmSDPLSKJu+Jvxg9fLg@mail.gmail.com>
	<3DB16098F738284D8DBEB2FC3699163837C274@inboexch.inbo.be>
	<20100920180328.m345nbowgc48g0g4@www.staffmail.ed.ac.uk>
	<AANLkTinMsh-j3vxZPm9Z8+D5N7_m7YJPGsVsUanULL1b@mail.gmail.com>
Message-ID: <AANLkTim78YtCgODibMGoxRMySGh4RSVEbq9jteJ0dAK7@mail.gmail.com>

seems I replied to Dr. Hadfield without adding the mailing list!
Sorry about that.  See below.
-------------------

Thank you very much, Drs. Hadfield and Onkelinx, for your comments.
I've refit the glmer() model with a quasibinomial link, but it was my
understanding that overdispersion changes the estimated error ranges
of the parameters, and not the values of the parameters themselves
(Gelman and Hill, "Data Analysis Using Regression and
Multilevel/Hierarchical Models 2007, p 115); this is borne out by a
comparison of the equivalent glmer() fits with the data here. ?So I
don't see how accounting for overdispersion could change the parameter
estimates, just the inferences arising from them.

I've refit the MCMCglmm model using the priors supplied, and while I
don't see a fantastic alignment with glmer()'s parameter values, there
is good congruence with the bugs() (package "arm") equivalent (at
least, as I've coded it (below), albeit with low n.eff values, and
almost-adequate convergence statistics (Rhat <= 1.1 in most
cases)...). ?On the whole, this third hat in the ring suggests to me
that the fits of all 3 model approaches must all be reasonably close
to what the data can say. ?So many thanks again for the help --
although I welcome further thoughts.

My only lingering request for Dr. Hadfield is a more systematic
explanation of the priors arguments in the MCMCglmm helpfile -- even
in Chapter 8 of the course notes, the list structure and parameter
values seem to be assumed knowledge, rather than provided as an
exhaustive list of options, along with descriptions of each option
(e.g. alpha.V -- what is it explicitly?). ?Presently, I can't derived
these priors myself, because I don't know their context well enough to
make informed choices -- but I would prefer a bit more up-front
context to use these existing prior sets with confidence.
Nonetheless, MCMCglmm seems like a wonderful addition to the set of
free modeling tools available!

--Bob

Code:

#################now binomial from a reference dataset
rm(list=ls())
library(MCMCglmm); library(lme4)
####lmer version
(gm3 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
? ? ? ? ? ? ?family = quasibinomial, data = cbpp))

####MCMCglmm version
#priors in email from Jarrod Hadfield
?prior2=list(R=list(V=1, nu=0.002), G=list(G1=list(V=1, nu=1,
alpha.mu=0, alpha.V=100)))
st<-Sys.time()
mc3<-MCMCglmm(cbind(incidence, size - incidence) ~ period,
?random = ~ herd,
?family = "multinomial2",
?data = cbpp, verbose = FALSE,
?nitt = 750E3, thin = 650, burnin = 100E3,
?prior = prior2
)
runt<-Sys.time() - st
runt
summary(gm3)@coefs
summary(mc3)

####now a WinBUGS equivalent
library(arm)
n<-nrow(cbpp)
n.herd<-length(unique(cbpp$herd))
model.data<-list(
?"incidence" = cbpp$incidence,
?"size" = cbpp$size,
?"period2" = as.numeric(model.matrix(~cbpp$period - 1)[,2]),
?"period3" = as.numeric(model.matrix(~cbpp$period - 1)[,3]),
?"period4" = as.numeric(model.matrix(~cbpp$period - 1)[,4]),
?"herd" = as.numeric(cbpp$herd),
?"n" = n,
?"n.herd" = n.herd
)
model.inits<-function(){
?list(
? ?B.0 = rnorm(1),
? ?B.period2 = rnorm(1),
? ?B.period3 = rnorm(1),
? ?B.period4 = rnorm(1),
? ?b.herd = rnorm(15),
? ?overdisp = rnorm(56),
? ?sigma.overdisp = runif(1),
? ?sigma.b.herd = runif(1)
?)
}
params<-c("B.0", "B.period2", "B.period3", "B.period4",
"sigma.overdisp", "sigma.b.herd")
model<-function(){
?for(i in 1:n){
? ?incidence[i] ~ dbin(phi2[i], size[i])
? ?logit(phi[i]) <- B.0 + B.period2*period2[i] + B.period3*period3[i]
+ B.period4*period4[i] +
? ? ?b.herd[herd[i]] + overdisp[i]
? ?phi2[i] <- max(0.00001, min(phi[i], 0.9999999))
? ?overdisp[i] ~ dnorm(0,tau.overdisp)
?}
?B.0 ~ dnorm(0,0.001)
?B.period2 ~ dnorm(0, 0.001)
?B.period3 ~ dnorm(0, 0.001)
?B.period4 ~ dnorm(0, 0.001)
?tau.overdisp <- pow(sigma.overdisp, -2)
?sigma.overdisp ~ dunif(0, 1000)
?for(j in 1:n.herd){
? ?b.herd[j] ~ dnorm(0, tau.b.herd)
?}
?tau.b.herd <- pow(sigma.b.herd, -2)
?sigma.b.herd ~ dunif(0, 100)
}
write.model(model, con="mcmcTest.bug")
starT<-Sys.time()
bug3<-bugs(model.data, model.inits, params, "mcmcTest.bug",
?n.iter = 500E3, debug = FALSE)
runt<-Sys.time() - starT
runt

summary(gm3)@coefs
summary(mc3)
bug3$summary[which(rownames(bug3$summary) %in% params), c("mean",
"sd", "2.5%", "97.5%", "Rhat", "n.eff")]



From j.hadfield at ed.ac.uk  Mon Sep 20 22:07:52 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 20 Sep 2010 21:07:52 +0100
Subject: [R-sig-ME] MCMCglmm for binomial models?
In-Reply-To: <AANLkTim78YtCgODibMGoxRMySGh4RSVEbq9jteJ0dAK7@mail.gmail.com>
References: <AANLkTinF=k-SaD6wmYd3TsHp8-7hdAqYfQOU203rt6Wk@mail.gmail.com>
	<Pine.LNX.4.64.1009201445240.3626@orpheus.qimr.edu.au>
	<AANLkTik9FcrgbFSk2Bs9_nMFNTmSDPLSKJu+Jvxg9fLg@mail.gmail.com>
	<3DB16098F738284D8DBEB2FC3699163837C274@inboexch.inbo.be>
	<20100920180328.m345nbowgc48g0g4@www.staffmail.ed.ac.uk>
	<AANLkTinMsh-j3vxZPm9Z8+D5N7_m7YJPGsVsUanULL1b@mail.gmail.com>
	<AANLkTim78YtCgODibMGoxRMySGh4RSVEbq9jteJ0dAK7@mail.gmail.com>
Message-ID: <20100920210752.hwicclv8jk0g004g@www.staffmail.ed.ac.uk>

Hi Bob,

Quoting Bob Farmer <farmerb at gmail.com>:

> seems I replied to Dr. Hadfield without adding the mailing list!
> Sorry about that.  See below.
> -------------------
>
> Thank you very much, Drs. Hadfield and Onkelinx, for your comments.
> I've refit the glmer() model with a quasibinomial link, but it was my
> understanding that overdispersion changes the estimated error ranges
> of the parameters, and not the values of the parameters themselves
> (Gelman and Hill, "Data Analysis Using Regression and
> Multilevel/Hierarchical Models 2007, p 115); this is borne out by a
> comparison of the equivalent glmer() fits with the data here. ?So I
> don't see how accounting for overdispersion could change the parameter
> estimates, just the inferences arising from them.

There are two ways of handling over-dispersion. If you use a  
multiplicative model the fixed effect estimates should stay the same  
and the standard error should increase (if the data are  
over-dispersed). I am not sure what the state of play is with  glmer's  
quasi models but with my version at least, it does not look right. The  
alternative is to fit an additive model by fitting a level for each  
observation, which is what I did in the last post. You should not  
expect the fixed effect coefficients to remain the same with additive  
models unless they are zero.

>
> I've refit the MCMCglmm model using the priors supplied, and while I
> don't see a fantastic alignment with glmer()'s parameter values, there
> is good congruence with the bugs() (package "arm") equivalent (at
> least, as I've coded it (below), albeit with low n.eff values, and
> almost-adequate convergence statistics (Rhat <= 1.1 in most
> cases)...). ?On the whole, this third hat in the ring suggests to me
> that the fits of all 3 model approaches must all be reasonably close
> to what the data can say. ?So many thanks again for the help --
> although I welcome further thoughts.

Could you post the output from

bug3$summary[which(rownames(bug3$summary) %in% params), c("mean",
"sd", "2.5%", "97.5%", "Rhat", "n.eff")]

I'm on a Mac so I can't run this (unless things have changed?)


>
> My only lingering request for Dr. Hadfield is a more systematic
> explanation of the priors arguments in the MCMCglmm helpfile -- even
> in Chapter 8 of the course notes, the list structure and parameter
> values seem to be assumed knowledge, rather than provided as an
> exhaustive list of options, along with descriptions of each option
> (e.g. alpha.V -- what is it explicitly?). ?Presently, I can't derived
> these priors myself, because I don't know their context well enough to
> make informed choices -- but I would prefer a bit more up-front
> context to use these existing prior sets with confidence.
> Nonetheless, MCMCglmm seems like a wonderful addition to the set of
> free modeling tools available!

Further info can be found in section's 1.3, 1.5, 2.7, 3.6 of the  
CourseNotes and Gelman's  2006 Bayesian Analysis 1(3) 515-533 is a  
good reference for parameter expanded priors, at least for single  
variance components. If I get more time I will make the notes more  
complete and indexed!

Cheers,

Jarrod


>
> --Bob
>
> Code:
>
> #################now binomial from a reference dataset
> rm(list=ls())
> library(MCMCglmm); library(lme4)
> ####lmer version
> (gm3 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
> ? ? ? ? ? ? ?family = quasibinomial, data = cbpp))
>
> ####MCMCglmm version
> #priors in email from Jarrod Hadfield
> ?prior2=list(R=list(V=1, nu=0.002), G=list(G1=list(V=1, nu=1,
> alpha.mu=0, alpha.V=100)))
> st<-Sys.time()
> mc3<-MCMCglmm(cbind(incidence, size - incidence) ~ period,
> ?random = ~ herd,
> ?family = "multinomial2",
> ?data = cbpp, verbose = FALSE,
> ?nitt = 750E3, thin = 650, burnin = 100E3,
> ?prior = prior2
> )
> runt<-Sys.time() - st
> runt
> summary(gm3)@coefs
> summary(mc3)
>
> ####now a WinBUGS equivalent
> library(arm)
> n<-nrow(cbpp)
> n.herd<-length(unique(cbpp$herd))
> model.data<-list(
> ?"incidence" = cbpp$incidence,
> ?"size" = cbpp$size,
> ?"period2" = as.numeric(model.matrix(~cbpp$period - 1)[,2]),
> ?"period3" = as.numeric(model.matrix(~cbpp$period - 1)[,3]),
> ?"period4" = as.numeric(model.matrix(~cbpp$period - 1)[,4]),
> ?"herd" = as.numeric(cbpp$herd),
> ?"n" = n,
> ?"n.herd" = n.herd
> )
> model.inits<-function(){
> ?list(
> ? ?B.0 = rnorm(1),
> ? ?B.period2 = rnorm(1),
> ? ?B.period3 = rnorm(1),
> ? ?B.period4 = rnorm(1),
> ? ?b.herd = rnorm(15),
> ? ?overdisp = rnorm(56),
> ? ?sigma.overdisp = runif(1),
> ? ?sigma.b.herd = runif(1)
> ?)
> }
> params<-c("B.0", "B.period2", "B.period3", "B.period4",
> "sigma.overdisp", "sigma.b.herd")
> model<-function(){
> ?for(i in 1:n){
> ? ?incidence[i] ~ dbin(phi2[i], size[i])
> ? ?logit(phi[i]) <- B.0 + B.period2*period2[i] + B.period3*period3[i]
> + B.period4*period4[i] +
> ? ? ?b.herd[herd[i]] + overdisp[i]
> ? ?phi2[i] <- max(0.00001, min(phi[i], 0.9999999))
> ? ?overdisp[i] ~ dnorm(0,tau.overdisp)
> ?}
> ?B.0 ~ dnorm(0,0.001)
> ?B.period2 ~ dnorm(0, 0.001)
> ?B.period3 ~ dnorm(0, 0.001)
> ?B.period4 ~ dnorm(0, 0.001)
> ?tau.overdisp <- pow(sigma.overdisp, -2)
> ?sigma.overdisp ~ dunif(0, 1000)
> ?for(j in 1:n.herd){
> ? ?b.herd[j] ~ dnorm(0, tau.b.herd)
> ?}
> ?tau.b.herd <- pow(sigma.b.herd, -2)
> ?sigma.b.herd ~ dunif(0, 100)
> }
> write.model(model, con="mcmcTest.bug")
> starT<-Sys.time()
> bug3<-bugs(model.data, model.inits, params, "mcmcTest.bug",
> ?n.iter = 500E3, debug = FALSE)
> runt<-Sys.time() - starT
> runt
>
> summary(gm3)@coefs
> summary(mc3)
> bug3$summary[which(rownames(bug3$summary) %in% params), c("mean",
> "sd", "2.5%", "97.5%", "Rhat", "n.eff")]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From farmerb at gmail.com  Mon Sep 20 23:47:44 2010
From: farmerb at gmail.com (Bob Farmer)
Date: Mon, 20 Sep 2010 18:47:44 -0300
Subject: [R-sig-ME] MCMCglmm for binomial models?
In-Reply-To: <20100920210752.hwicclv8jk0g004g@www.staffmail.ed.ac.uk>
References: <AANLkTinF=k-SaD6wmYd3TsHp8-7hdAqYfQOU203rt6Wk@mail.gmail.com>
	<Pine.LNX.4.64.1009201445240.3626@orpheus.qimr.edu.au>
	<AANLkTik9FcrgbFSk2Bs9_nMFNTmSDPLSKJu+Jvxg9fLg@mail.gmail.com>
	<3DB16098F738284D8DBEB2FC3699163837C274@inboexch.inbo.be>
	<20100920180328.m345nbowgc48g0g4@www.staffmail.ed.ac.uk>
	<AANLkTinMsh-j3vxZPm9Z8+D5N7_m7YJPGsVsUanULL1b@mail.gmail.com>
	<AANLkTim78YtCgODibMGoxRMySGh4RSVEbq9jteJ0dAK7@mail.gmail.com>
	<20100920210752.hwicclv8jk0g004g@www.staffmail.ed.ac.uk>
Message-ID: <AANLkTink18fg5qY=qpW8nayiewo-6DaizBf+RTK_0aP2@mail.gmail.com>

Thanks for the further detail.  I wasn't familiar with these two
methods of overdispersion; I think I only understood them in the
WinBUGS sense, which, I believe, is additive (e.g. overdisp[i] as a
parameter).  I'll have to explore the family() helpfiles a bit more.

Below is a summary of the model outputs from the three methods
described earlier.  Note that here, I bumped the WinBUGS iterations to
750E3 to reduce the Rhats a bit further.
I also use an adaptation of the bugsParallel function to make my
WinBUGS runs 3x faster (time for this run:  5.8 minutes); I can
provide details if anybody else would like to use this function (and
some other bugs summary functions I've written).
Hope this is useful or interesting -- I appreciate this discussion!

--Bob

**glmer**
> summary(gm3)@coefs
              Estimate Std. Error   t value
(Intercept) -1.3985351 0.01698321 -82.34810
period2     -0.9923347 0.02275838 -43.60304
period3     -1.1286754 0.02429833 -46.45075
period4     -1.5803739 0.03195596 -49.45474

**MCMCglmm**
> summary(mc3)
 Iterations = 749351
 Thinning interval  = 100001
 Sample size  = 1000
 DIC: 539.7889
 G-structure:  ~herd
     post.mean  l-95% CI u-95% CI eff.samp
herd    0.2894 1.309e-06    1.035     1000
 R-structure:  ~units
      post.mean l-95% CI u-95% CI eff.samp
units      0.93 0.003825     1.98     1000
 Location effects: cbind(incidence, size - incidence) ~ period
            post.mean l-95% CI u-95% CI eff.samp  pMCMC
(Intercept)   -1.5263  -2.2221  -0.9602   1000.0 <0.001 ***
period2       -1.2407  -2.2072  -0.2449    947.2  0.012 *
period3       -1.3574  -2.4534  -0.3472   1000.0  0.012 *
period4       -1.9126  -3.2662  -0.8298   1136.0  0.002 **

**WinBUGS**
> bug3$summary[which(rownames(bug3$summary) %in% params), c("mean", "sd", "2.5%", "97.5%", "Rhat", "n.eff")]
                     mean        sd        2.5%      97.5%     Rhat n.eff
B.0            -1.6070301 0.3556674 -2.33980000 -0.9947425 1.039548    69
B.period2      -1.2761798 0.4895902 -2.14292500 -0.2391200 1.018612   210
B.period3      -1.5100405 0.6337780 -2.63680000 -0.2266425 1.123427    22
B.period4      -2.0678331 0.6539004 -3.31892500 -0.8586700 1.018622   270
sigma.overdisp  1.1975969 0.3147531  0.69358404  1.8740000 1.045062    55
sigma.b.herd    0.5120043 0.3825848  0.01658429  1.3659249 1.542432     7
(note that I can provide a link to parameter histograms, if you want
more detail)

--Bob



From cm744 at st-andrews.ac.uk  Tue Sep 21 11:58:47 2010
From: cm744 at st-andrews.ac.uk (Chris Mcowen)
Date: Tue, 21 Sep 2010 10:58:47 +0100
Subject: [R-sig-ME] Predict in glmer using method from Owl data ( Ben Bolker)
Message-ID: <B8C8AA5E-8FE0-4598-9690-9D802726679C@st-andrews.ac.uk>

Dear List and Ben,

I am having some trouble replicating the method used by Ben for getting predicted values from glmer. 

I had heard that as long as the model is selected taking into account the random effects then it should be fine to use a lm and the predict function to get the predicted values. I have done this and the model performs OK with binomial data C value - 0.77 and Bieber score - 0.199. However when i try and do this for a ordinal response then the model performs badly in predicting. I am wondering if this is because it makes no account for random effects so i have decided to revisit mixed models.

> > g1
> Generalized linear mixed model fit by the Laplace approximation 
> Formula: THREAT ~ 1 + (1 | order/fam) + BS * FR + HAB + SEA + PD + WO +      ALT + REG + BIO + LIF 

Where i am trying to predict if a species is threatened or not based on a series of life history traits. I have a list of species where i know their life history but not threat level.


I am using the method Ben used in his example to get the predicted values , however i am having trouble. The output contains a large number of outputs (7000+), where as my data frame only has 993, i feel the problem may arise from setting up the data frame (see below) the output makes no sense in relation to my data for example only 6 species are Arctic where as the data frame has loads?

> >  pframe0 <- with(traits,expand.grid(BS=levels(BS),FR=levels(FR),WO=levels(WO),PD=levels(PD),HAB=levels(HAB),SEA=levels(SEA),ALT=levels(ALT),BIO=levels(BIO),REG=levels(REG),LIF=levels(LIF)))


> pframe0

>                      BS         FR        WO      PD          HAB       SEA  ALT                  BIO      REG     LIF
> 1       Bisexual_flower     Fleshy Non_woody Abiotic     Epiphyte    Annual  All               Arctic      One  Bamboo
> 2     Unisexual_flowers     Fleshy Non_woody Abiotic     Epiphyte    Annual  All               Arctic      One  Bamboo
> 3       Unisexual_plant     Fleshy Non_woody Abiotic     Epiphyte    Annual  All               Arctic      One  Bamboo
> 4       Bisexual_flower Non_fleshy Non_woody Abiotic     Epiphyte    Annual  All               Arctic      One  Bamboo
> 5     Unisexual_flowers Non_fleshy Non_woody Abiotic     Epiphyte    Annual  All               Arctic      One  Bamboo
> 6       Unisexual_plant Non_fleshy Non_woody Abiotic     Epiphyte    Annual  All               Arctic      One  Bamboo
> 7       Bisexual_flower     Fleshy     Woody Abiotic     Epiphyte    Annual  All               Arctic      One  Bamboo
> 8     Unisexual_flowers     Fleshy     Woody Abiotic     Epiphyte    Annual  All               Arctic      One  Bamboo
> 9       Unisexual_plant     Fleshy     Woody Abiotic     Epiphyte    Annual  All               Arctic      One  Bamboo
> 10      Bisexual_flower Non_fleshy     Woody Abiotic     Epiphyte    Annual  All               Arctic      One  Bamboo
> 11    Unisexual_flowers Non_fleshy     Woody Abiotic     Epiphyte    Annual  All               Arctic      One  Bamboo
> 12      Unisexual_plant Non_fleshy     Woody Abiotic     Epiphyte    Annual  All               Arctic      One  Bamboo
> 13      Bisexual_flower     Fleshy Non_woody  Biotic     Epiphyte    Annual  All               Arctic      One  Bamboo
> 14    Unisexual_flowers     Fleshy Non_woody  Biotic     Epiphyte    Annual  All               Arctic      One  Bamboo
> 15      Unisexual_plant     Fleshy Non_woody  Biotic     Epiphyte    Annual  All               Arctic      One  Bamboo
> 16      Bisexual_flower Non_fleshy Non_woody  Biotic     Epiphyte    Annual  All               Arctic      One  Bamboo
> 17    Unisexual_flowers Non_fleshy Non_woody  Biotic     Epiphyte    Annual  All               Arctic      One  Bamboo
> 18      Unisexual_plant Non_fleshy Non_woody  Biotic     Epiphyte    Annual  All               Arctic      One  Bamboo
> 19      Bisexual_flower     Fleshy     Woody  Biotic     Epiphyte    Annual  All               Arctic      One  Bamboo
> 20    Unisexual_flowers     Fleshy     Woody  Biotic     Epiphyte    Annual  All               Arctic      One  Bamboo

I then tried to attach the fixed effects predictions, i got values but as there are a huge number of enterys in the data frame i am unsure what they correspond to (see below)

> pframe1 <- data.frame(pframe0,eta=mm%*%fixef(g1))

I am sorry if this is hard to follow, i can supply more data or clarify further if required

Chris


From luciano.selzer at gmail.com  Tue Sep 21 14:20:51 2010
From: luciano.selzer at gmail.com (Luciano Selzer)
Date: Tue, 21 Sep 2010 09:20:51 -0300
Subject: [R-sig-ME] Predict in glmer using method from Owl data ( Ben
	Bolker)
In-Reply-To: <B8C8AA5E-8FE0-4598-9690-9D802726679C@st-andrews.ac.uk>
References: <B8C8AA5E-8FE0-4598-9690-9D802726679C@st-andrews.ac.uk>
Message-ID: <AANLkTim1H7xqo3MmvVswCjzSydyTbsfEH2-cy9-39xMc@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100921/595d73ab/attachment.pl>

From luciano.selzer at gmail.com  Tue Sep 21 14:24:26 2010
From: luciano.selzer at gmail.com (Luciano Selzer)
Date: Tue, 21 Sep 2010 09:24:26 -0300
Subject: [R-sig-ME] Fwd: Predict in glmer using method from Owl data ( Ben
	Bolker)
In-Reply-To: <AANLkTim1H7xqo3MmvVswCjzSydyTbsfEH2-cy9-39xMc@mail.gmail.com>
References: <B8C8AA5E-8FE0-4598-9690-9D802726679C@st-andrews.ac.uk>
	<AANLkTim1H7xqo3MmvVswCjzSydyTbsfEH2-cy9-39xMc@mail.gmail.com>
Message-ID: <AANLkTim4FmV1Rrv5sMozmFDJfwTwvjkA11Sfd0R0h0hT@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100921/f06c8d81/attachment.pl>

From armstrong.whit at gmail.com  Tue Sep 21 21:41:06 2010
From: armstrong.whit at gmail.com (Whit Armstrong)
Date: Tue, 21 Sep 2010 15:41:06 -0400
Subject: [R-sig-ME] MCMCglmm for binomial models?
In-Reply-To: <AANLkTink18fg5qY=qpW8nayiewo-6DaizBf+RTK_0aP2@mail.gmail.com>
References: <AANLkTinF=k-SaD6wmYd3TsHp8-7hdAqYfQOU203rt6Wk@mail.gmail.com>
	<Pine.LNX.4.64.1009201445240.3626@orpheus.qimr.edu.au>
	<AANLkTik9FcrgbFSk2Bs9_nMFNTmSDPLSKJu+Jvxg9fLg@mail.gmail.com>
	<3DB16098F738284D8DBEB2FC3699163837C274@inboexch.inbo.be>
	<20100920180328.m345nbowgc48g0g4@www.staffmail.ed.ac.uk>
	<AANLkTinMsh-j3vxZPm9Z8+D5N7_m7YJPGsVsUanULL1b@mail.gmail.com>
	<AANLkTim78YtCgODibMGoxRMySGh4RSVEbq9jteJ0dAK7@mail.gmail.com>
	<20100920210752.hwicclv8jk0g004g@www.staffmail.ed.ac.uk>
	<AANLkTink18fg5qY=qpW8nayiewo-6DaizBf+RTK_0aP2@mail.gmail.com>
Message-ID: <AANLkTingMJ+PdjyeAU6mNBMr_9L41WGD9oFU5U72MjdD@mail.gmail.com>

Bob,

Just wanted to post the results from my project.  It is still very
much alpha quality software, but the speed is good.  Your sample model
runs in 22secs on my workstation.  I ran the model in JAGS earlier but
it took ages (20min or so).

These are my results which are closer to the MCMCglmm run than the
WinBUGS run.  Eventually, I'll try to make it easy to run these models
directly from R.

The full code for this model is posted in-line below.  However, the
guts are just two functions which just separate the winbugs model into
separate "update" and "logp" functions:

  void update() {
    phi.value = b0.value + b_period2.value*period2 +
b_period3.value*period3 + b_period4.value*period4 +
sum(permutation_matrix*b_herd.value,1) + overdisp.value;
    phi.value = 1/(1+exp(-phi.value));
    sigma_overdisp.value = 1/sqrt(tau_overdisp.value);
    sigma_b_herd.value = 1/sqrt(tau_b_herd.value);
  }
  double logp() const {
    return b0.logp() + b_period2.logp() + b_period3.logp() +
b_period4.logp() + tau_overdisp.logp() + tau_b_herd.logp() +
b_herd.logp(0, tau_b_herd.value) +
      overdisp.logp(0,tau_overdisp.value) + likelihood.logp(size,phi.value);
  }

The speed of the model could probably be improved by consolidating all
the b's into a vector.  I'll try that later on.  Code for this model,
and some other examples will go up on github sometime in the near
future.

I've also cc'd Chris Fonnesbeck, since he may want to chime in on the
pymc front.  I haven't had time to code up an equivalent pymc model,
but it should be very easy to do.

Feedback welcome.

-Whit


results:
warmstrong at krypton:~/dvl/c++/CppBugs/test$ time ./a.out
samples: 17999
b0: -1.52515
b_period2: -1.21971
b_period3: -1.32685
b_period4: -1.88475
tau_overdisp: 1.59118
tau_b_herd: 25.9476
sigma_overdisp: 0.886191
sigma_b_herd: 0.258111
b_herd:
   0.1623
  -0.0524
   0.0852
   0.0080
  -0.0506
  -0.0953
   0.1859
   0.0835
  -0.0690
  -0.0897
   0.0096
  -0.0183
  -0.1496
   0.1133
  -0.1061


real	0m21.930s
user	0m21.920s
sys	0m0.000s
warmstrong at krypton:~/dvl/c++/CppBugs/test$


model code:
class HerdModel: public MCModel {
  const ivec incidence;
  const ivec size;
  const ivec herd;
  const vec period2;
  const vec period3;
  const vec period4;
  int N, N_herd;
  mat permutation_matrix;

public:
  NormalStatic<double> b0;
  NormalStatic<double> b_period2;
  NormalStatic<double> b_period3;
  NormalStatic<double> b_period4;
  UniformStatic<double> tau_overdisp;
  UniformStatic<double> tau_b_herd;
  Deterministic<double> sigma_overdisp;
  Deterministic<double> sigma_b_herd;
  Normal<vec> b_herd;
  Normal<vec> overdisp;
  Deterministic<vec> phi;
  Binomial<ivec> likelihood;


  HerdModel(const ivec& incidence_,const ivec& size_,const ivec& herd_,
            const vec& period2_,const vec& period3_,const vec&
period4_, int N_, int N_herd_):
    incidence(incidence_),size(size_),herd(herd_),
    period2(period2_),period3(period3_),period4(period4_),
    N(N_),N_herd(N_herd_),permutation_matrix(N,N_herd),
    b0(0,0,0.001),b_period2(0,0,0.001),b_period3(0,0,0.001),b_period4(0,0,0.001),
    tau_overdisp(1,0,1000),tau_b_herd(1,0,100),
    sigma_overdisp(1),sigma_b_herd(1),
    b_herd(randn<vec>(N_herd_)),overdisp(randn<vec>(N)),
    phi(randu<vec>(N)),
    likelihood(incidence_,true)
  {
    permutation_matrix.fill(0.0);
    for(uint i = 0; i < herd.n_elem; i++) {
      permutation_matrix(i,herd[i]) = 1.0;
    }
    add(b0);
    add(b_period2);
    add(b_period3);
    add(b_period4);
    add(tau_overdisp);
    add(tau_b_herd);
    add(sigma_overdisp);
    add(sigma_b_herd);
    add(b_herd);
    add(overdisp);
    add(phi);
    add(likelihood);
  }

  void update() {
    phi.value = b0.value + b_period2.value*period2 +
b_period3.value*period3 + b_period4.value*period4 +
sum(permutation_matrix*b_herd.value,1) + overdisp.value;
    phi.value = 1/(1+exp(-phi.value));
    sigma_overdisp.value = 1/sqrt(tau_overdisp.value);
    sigma_b_herd.value = 1/sqrt(tau_b_herd.value);
  }
  double logp() const {
    return b0.logp() + b_period2.logp() + b_period3.logp() +
b_period4.logp() + tau_overdisp.logp() + tau_b_herd.logp() +
b_herd.logp(0, tau_b_herd.value) +
      overdisp.logp(0,tau_overdisp.value) + likelihood.logp(size,phi.value);
  }
};



On Mon, Sep 20, 2010 at 5:47 PM, Bob Farmer <farmerb at gmail.com> wrote:
> Thanks for the further detail. ?I wasn't familiar with these two
> methods of overdispersion; I think I only understood them in the
> WinBUGS sense, which, I believe, is additive (e.g. overdisp[i] as a
> parameter). ?I'll have to explore the family() helpfiles a bit more.
>
> Below is a summary of the model outputs from the three methods
> described earlier. ?Note that here, I bumped the WinBUGS iterations to
> 750E3 to reduce the Rhats a bit further.
> I also use an adaptation of the bugsParallel function to make my
> WinBUGS runs 3x faster (time for this run: ?5.8 minutes); I can
> provide details if anybody else would like to use this function (and
> some other bugs summary functions I've written).
> Hope this is useful or interesting -- I appreciate this discussion!
>
> --Bob
>
> **glmer**
>> summary(gm3)@coefs
> ? ? ? ? ? ? ?Estimate Std. Error ? t value
> (Intercept) -1.3985351 0.01698321 -82.34810
> period2 ? ? -0.9923347 0.02275838 -43.60304
> period3 ? ? -1.1286754 0.02429833 -46.45075
> period4 ? ? -1.5803739 0.03195596 -49.45474
>
> **MCMCglmm**
>> summary(mc3)
> ?Iterations = 749351
> ?Thinning interval ?= 100001
> ?Sample size ?= 1000
> ?DIC: 539.7889
> ?G-structure: ?~herd
> ? ? post.mean ?l-95% CI u-95% CI eff.samp
> herd ? ?0.2894 1.309e-06 ? ?1.035 ? ? 1000
> ?R-structure: ?~units
> ? ? ?post.mean l-95% CI u-95% CI eff.samp
> units ? ? ?0.93 0.003825 ? ? 1.98 ? ? 1000
> ?Location effects: cbind(incidence, size - incidence) ~ period
> ? ? ? ? ? ?post.mean l-95% CI u-95% CI eff.samp ?pMCMC
> (Intercept) ? -1.5263 ?-2.2221 ?-0.9602 ? 1000.0 <0.001 ***
> period2 ? ? ? -1.2407 ?-2.2072 ?-0.2449 ? ?947.2 ?0.012 *
> period3 ? ? ? -1.3574 ?-2.4534 ?-0.3472 ? 1000.0 ?0.012 *
> period4 ? ? ? -1.9126 ?-3.2662 ?-0.8298 ? 1136.0 ?0.002 **
>
> **WinBUGS**
>> bug3$summary[which(rownames(bug3$summary) %in% params), c("mean", "sd", "2.5%", "97.5%", "Rhat", "n.eff")]
> ? ? ? ? ? ? ? ? ? ? mean ? ? ? ?sd ? ? ? ?2.5% ? ? ?97.5% ? ? Rhat n.eff
> B.0 ? ? ? ? ? ?-1.6070301 0.3556674 -2.33980000 -0.9947425 1.039548 ? ?69
> B.period2 ? ? ?-1.2761798 0.4895902 -2.14292500 -0.2391200 1.018612 ? 210
> B.period3 ? ? ?-1.5100405 0.6337780 -2.63680000 -0.2266425 1.123427 ? ?22
> B.period4 ? ? ?-2.0678331 0.6539004 -3.31892500 -0.8586700 1.018622 ? 270
> sigma.overdisp ?1.1975969 0.3147531 ?0.69358404 ?1.8740000 1.045062 ? ?55
> sigma.b.herd ? ?0.5120043 0.3825848 ?0.01658429 ?1.3659249 1.542432 ? ? 7
> (note that I can provide a link to parameter histograms, if you want
> more detail)
>
> --Bob
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From armstrong.whit at gmail.com  Tue Sep 21 22:26:57 2010
From: armstrong.whit at gmail.com (Whit Armstrong)
Date: Tue, 21 Sep 2010 16:26:57 -0400
Subject: [R-sig-ME] MCMCglmm for binomial models?
In-Reply-To: <AANLkTingMJ+PdjyeAU6mNBMr_9L41WGD9oFU5U72MjdD@mail.gmail.com>
References: <AANLkTinF=k-SaD6wmYd3TsHp8-7hdAqYfQOU203rt6Wk@mail.gmail.com>
	<Pine.LNX.4.64.1009201445240.3626@orpheus.qimr.edu.au>
	<AANLkTik9FcrgbFSk2Bs9_nMFNTmSDPLSKJu+Jvxg9fLg@mail.gmail.com>
	<3DB16098F738284D8DBEB2FC3699163837C274@inboexch.inbo.be>
	<20100920180328.m345nbowgc48g0g4@www.staffmail.ed.ac.uk>
	<AANLkTinMsh-j3vxZPm9Z8+D5N7_m7YJPGsVsUanULL1b@mail.gmail.com>
	<AANLkTim78YtCgODibMGoxRMySGh4RSVEbq9jteJ0dAK7@mail.gmail.com>
	<20100920210752.hwicclv8jk0g004g@www.staffmail.ed.ac.uk>
	<AANLkTink18fg5qY=qpW8nayiewo-6DaizBf+RTK_0aP2@mail.gmail.com>
	<AANLkTingMJ+PdjyeAU6mNBMr_9L41WGD9oFU5U72MjdD@mail.gmail.com>
Message-ID: <AANLkTik8Z6ksVMq=bdCmK0Wx2ip8cajTgOCVyeDVeudN@mail.gmail.com>

so much for intuition.  consolidating the b's doesn't make any
material speed difference, but it does simplify the model code a bit.

btw, this run and the previous post were using 1e6 interations, 1e5
burn-in, and 50 thin: m.sample(1e6,1e5,50).

-Whit


warmstrong at krypton:~/dvl/c++/CppBugs/test$ g++ -I.. -Wall -O2
herd.fast.cpp -llapack
warmstrong at krypton:~/dvl/c++/CppBugs/test$ time ./a.out
samples: 17999
b:
  -1.5077
  -1.2344
  -1.3518
  -1.8819

tau_overdisp: 1.54806
tau_b_herd: 22.059
sigma_overdisp: 0.878115
sigma_b_herd: 0.245386
b_herd:
   0.1464
  -0.0475
   0.0739
   0.0070
  -0.0353
  -0.0866
   0.1661
   0.0658
  -0.0585
  -0.0904
   0.0052
  -0.0138
  -0.1324
   0.0947
  -0.0902


real	0m21.905s
user	0m21.880s
sys	0m0.020s
warmstrong at krypton:~/dvl/c++/CppBugs/test$


updated code:
class HerdModel: public MCModel {
  const ivec incidence;
  const ivec size;
  const ivec herd;
  const mat fixed;
  int N, N_herd;
  mat permutation_matrix;

public:
  NormalStatic<vec> b;
  UniformStatic<double> tau_overdisp;
  UniformStatic<double> tau_b_herd;
  Deterministic<double> sigma_overdisp;
  Deterministic<double> sigma_b_herd;
  Normal<vec> b_herd;
  Normal<vec> overdisp;
  Deterministic<vec> phi;
  Binomial<ivec> likelihood;


  HerdModel(const ivec& incidence_,const ivec& size_,const ivec&
herd_,const mat& fixed_,int N_, int N_herd_):
    incidence(incidence_),size(size_),herd(herd_),
    fixed(fixed_),N(N_),N_herd(N_herd_),permutation_matrix(N,N_herd),
    b(randn<vec>(4),0,0.001),tau_overdisp(1,0,1000),tau_b_herd(1,0,100),
    sigma_overdisp(1),sigma_b_herd(1),
    b_herd(randn<vec>(N_herd_)),overdisp(randn<vec>(N)),
    phi(randu<vec>(N)),
    likelihood(incidence_,true)
  {
    permutation_matrix.fill(0.0);
    for(uint i = 0; i < herd.n_elem; i++) {
      permutation_matrix(i,herd[i]) = 1.0;
    }
    add(b);
    add(tau_overdisp);
    add(tau_b_herd);
    add(sigma_overdisp);
    add(sigma_b_herd);
    add(b_herd);
    add(overdisp);
    add(phi);
    add(likelihood);
  }

  void update() {
    phi.value = fixed*b.value + sum(permutation_matrix*b_herd.value,1)
+ overdisp.value;
    phi.value = 1/(1+exp(-phi.value));
    sigma_overdisp.value = 1/sqrt(tau_overdisp.value);
    sigma_b_herd.value = 1/sqrt(tau_b_herd.value);
  }
  double logp() const {
    return b.logp() + tau_overdisp.logp() + tau_b_herd.logp() +
b_herd.logp(0, tau_b_herd.value) +
      overdisp.logp(0,tau_overdisp.value) + likelihood.logp(size,phi.value);
  }
};



On Tue, Sep 21, 2010 at 3:41 PM, Whit Armstrong
<armstrong.whit at gmail.com> wrote:
> Bob,
>
> Just wanted to post the results from my project. ?It is still very
> much alpha quality software, but the speed is good. ?Your sample model
> runs in 22secs on my workstation. ?I ran the model in JAGS earlier but
> it took ages (20min or so).
>
> These are my results which are closer to the MCMCglmm run than the
> WinBUGS run. ?Eventually, I'll try to make it easy to run these models
> directly from R.
>
> The full code for this model is posted in-line below. ?However, the
> guts are just two functions which just separate the winbugs model into
> separate "update" and "logp" functions:
>
> ?void update() {
> ? ?phi.value = b0.value + b_period2.value*period2 +
> b_period3.value*period3 + b_period4.value*period4 +
> sum(permutation_matrix*b_herd.value,1) + overdisp.value;
> ? ?phi.value = 1/(1+exp(-phi.value));
> ? ?sigma_overdisp.value = 1/sqrt(tau_overdisp.value);
> ? ?sigma_b_herd.value = 1/sqrt(tau_b_herd.value);
> ?}
> ?double logp() const {
> ? ?return b0.logp() + b_period2.logp() + b_period3.logp() +
> b_period4.logp() + tau_overdisp.logp() + tau_b_herd.logp() +
> b_herd.logp(0, tau_b_herd.value) +
> ? ? ?overdisp.logp(0,tau_overdisp.value) + likelihood.logp(size,phi.value);
> ?}
>
> The speed of the model could probably be improved by consolidating all
> the b's into a vector. ?I'll try that later on. ?Code for this model,
> and some other examples will go up on github sometime in the near
> future.
>
> I've also cc'd Chris Fonnesbeck, since he may want to chime in on the
> pymc front. ?I haven't had time to code up an equivalent pymc model,
> but it should be very easy to do.
>
> Feedback welcome.
>
> -Whit
>
>
> results:
> warmstrong at krypton:~/dvl/c++/CppBugs/test$ time ./a.out
> samples: 17999
> b0: -1.52515
> b_period2: -1.21971
> b_period3: -1.32685
> b_period4: -1.88475
> tau_overdisp: 1.59118
> tau_b_herd: 25.9476
> sigma_overdisp: 0.886191
> sigma_b_herd: 0.258111
> b_herd:
> ? 0.1623
> ?-0.0524
> ? 0.0852
> ? 0.0080
> ?-0.0506
> ?-0.0953
> ? 0.1859
> ? 0.0835
> ?-0.0690
> ?-0.0897
> ? 0.0096
> ?-0.0183
> ?-0.1496
> ? 0.1133
> ?-0.1061
>
>
> real ? ?0m21.930s
> user ? ?0m21.920s
> sys ? ? 0m0.000s
> warmstrong at krypton:~/dvl/c++/CppBugs/test$
>
>
> model code:
> class HerdModel: public MCModel {
> ?const ivec incidence;
> ?const ivec size;
> ?const ivec herd;
> ?const vec period2;
> ?const vec period3;
> ?const vec period4;
> ?int N, N_herd;
> ?mat permutation_matrix;
>
> public:
> ?NormalStatic<double> b0;
> ?NormalStatic<double> b_period2;
> ?NormalStatic<double> b_period3;
> ?NormalStatic<double> b_period4;
> ?UniformStatic<double> tau_overdisp;
> ?UniformStatic<double> tau_b_herd;
> ?Deterministic<double> sigma_overdisp;
> ?Deterministic<double> sigma_b_herd;
> ?Normal<vec> b_herd;
> ?Normal<vec> overdisp;
> ?Deterministic<vec> phi;
> ?Binomial<ivec> likelihood;
>
>
> ?HerdModel(const ivec& incidence_,const ivec& size_,const ivec& herd_,
> ? ? ? ? ? ?const vec& period2_,const vec& period3_,const vec&
> period4_, int N_, int N_herd_):
> ? ?incidence(incidence_),size(size_),herd(herd_),
> ? ?period2(period2_),period3(period3_),period4(period4_),
> ? ?N(N_),N_herd(N_herd_),permutation_matrix(N,N_herd),
> ? ?b0(0,0,0.001),b_period2(0,0,0.001),b_period3(0,0,0.001),b_period4(0,0,0.001),
> ? ?tau_overdisp(1,0,1000),tau_b_herd(1,0,100),
> ? ?sigma_overdisp(1),sigma_b_herd(1),
> ? ?b_herd(randn<vec>(N_herd_)),overdisp(randn<vec>(N)),
> ? ?phi(randu<vec>(N)),
> ? ?likelihood(incidence_,true)
> ?{
> ? ?permutation_matrix.fill(0.0);
> ? ?for(uint i = 0; i < herd.n_elem; i++) {
> ? ? ?permutation_matrix(i,herd[i]) = 1.0;
> ? ?}
> ? ?add(b0);
> ? ?add(b_period2);
> ? ?add(b_period3);
> ? ?add(b_period4);
> ? ?add(tau_overdisp);
> ? ?add(tau_b_herd);
> ? ?add(sigma_overdisp);
> ? ?add(sigma_b_herd);
> ? ?add(b_herd);
> ? ?add(overdisp);
> ? ?add(phi);
> ? ?add(likelihood);
> ?}
>
> ?void update() {
> ? ?phi.value = b0.value + b_period2.value*period2 +
> b_period3.value*period3 + b_period4.value*period4 +
> sum(permutation_matrix*b_herd.value,1) + overdisp.value;
> ? ?phi.value = 1/(1+exp(-phi.value));
> ? ?sigma_overdisp.value = 1/sqrt(tau_overdisp.value);
> ? ?sigma_b_herd.value = 1/sqrt(tau_b_herd.value);
> ?}
> ?double logp() const {
> ? ?return b0.logp() + b_period2.logp() + b_period3.logp() +
> b_period4.logp() + tau_overdisp.logp() + tau_b_herd.logp() +
> b_herd.logp(0, tau_b_herd.value) +
> ? ? ?overdisp.logp(0,tau_overdisp.value) + likelihood.logp(size,phi.value);
> ?}
> };
>
>
>
> On Mon, Sep 20, 2010 at 5:47 PM, Bob Farmer <farmerb at gmail.com> wrote:
>> Thanks for the further detail. ?I wasn't familiar with these two
>> methods of overdispersion; I think I only understood them in the
>> WinBUGS sense, which, I believe, is additive (e.g. overdisp[i] as a
>> parameter). ?I'll have to explore the family() helpfiles a bit more.
>>
>> Below is a summary of the model outputs from the three methods
>> described earlier. ?Note that here, I bumped the WinBUGS iterations to
>> 750E3 to reduce the Rhats a bit further.
>> I also use an adaptation of the bugsParallel function to make my
>> WinBUGS runs 3x faster (time for this run: ?5.8 minutes); I can
>> provide details if anybody else would like to use this function (and
>> some other bugs summary functions I've written).
>> Hope this is useful or interesting -- I appreciate this discussion!
>>
>> --Bob
>>
>> **glmer**
>>> summary(gm3)@coefs
>> ? ? ? ? ? ? ?Estimate Std. Error ? t value
>> (Intercept) -1.3985351 0.01698321 -82.34810
>> period2 ? ? -0.9923347 0.02275838 -43.60304
>> period3 ? ? -1.1286754 0.02429833 -46.45075
>> period4 ? ? -1.5803739 0.03195596 -49.45474
>>
>> **MCMCglmm**
>>> summary(mc3)
>> ?Iterations = 749351
>> ?Thinning interval ?= 100001
>> ?Sample size ?= 1000
>> ?DIC: 539.7889
>> ?G-structure: ?~herd
>> ? ? post.mean ?l-95% CI u-95% CI eff.samp
>> herd ? ?0.2894 1.309e-06 ? ?1.035 ? ? 1000
>> ?R-structure: ?~units
>> ? ? ?post.mean l-95% CI u-95% CI eff.samp
>> units ? ? ?0.93 0.003825 ? ? 1.98 ? ? 1000
>> ?Location effects: cbind(incidence, size - incidence) ~ period
>> ? ? ? ? ? ?post.mean l-95% CI u-95% CI eff.samp ?pMCMC
>> (Intercept) ? -1.5263 ?-2.2221 ?-0.9602 ? 1000.0 <0.001 ***
>> period2 ? ? ? -1.2407 ?-2.2072 ?-0.2449 ? ?947.2 ?0.012 *
>> period3 ? ? ? -1.3574 ?-2.4534 ?-0.3472 ? 1000.0 ?0.012 *
>> period4 ? ? ? -1.9126 ?-3.2662 ?-0.8298 ? 1136.0 ?0.002 **
>>
>> **WinBUGS**
>>> bug3$summary[which(rownames(bug3$summary) %in% params), c("mean", "sd", "2.5%", "97.5%", "Rhat", "n.eff")]
>> ? ? ? ? ? ? ? ? ? ? mean ? ? ? ?sd ? ? ? ?2.5% ? ? ?97.5% ? ? Rhat n.eff
>> B.0 ? ? ? ? ? ?-1.6070301 0.3556674 -2.33980000 -0.9947425 1.039548 ? ?69
>> B.period2 ? ? ?-1.2761798 0.4895902 -2.14292500 -0.2391200 1.018612 ? 210
>> B.period3 ? ? ?-1.5100405 0.6337780 -2.63680000 -0.2266425 1.123427 ? ?22
>> B.period4 ? ? ?-2.0678331 0.6539004 -3.31892500 -0.8586700 1.018622 ? 270
>> sigma.overdisp ?1.1975969 0.3147531 ?0.69358404 ?1.8740000 1.045062 ? ?55
>> sigma.b.herd ? ?0.5120043 0.3825848 ?0.01658429 ?1.3659249 1.542432 ? ? 7
>> (note that I can provide a link to parameter histograms, if you want
>> more detail)
>>
>> --Bob
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>



From myaseen208 at gmail.com  Sat Sep 25 08:01:36 2010
From: myaseen208 at gmail.com (Muhammad Yaseen)
Date: Fri, 24 Sep 2010 23:01:36 -0700
Subject: [R-sig-ME] Standard Errors of Differences and TukeyHSD in Split
	Plot Desing
Message-ID: <AANLkTimKgEv9D_Rtco+ggAyvSLet_NiV__jZGaNm0Z0+@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100924/132e6315/attachment.pl>

From mspinola10 at gmail.com  Sun Sep 26 13:24:37 2010
From: mspinola10 at gmail.com (=?ISO-8859-1?Q?Manuel_Sp=EDnola?=)
Date: Sun, 26 Sep 2010 05:24:37 -0600
Subject: [R-sig-ME] Dealing with heteroscedasticity in repeated measure
	models
Message-ID: <4C9F2D75.6070601@gmail.com>

  Dear list members,

I am fitting a repeated measure model using lme.
I have 4 measurements of a rate (variable called ipa) measured each year 
(variable called tempo, which was centered) on 48 counties (all the 
counties from a province, variable called localidad).
I am considering county like a random factor.
My models are:

model1 = lme(ipa ~ tempo, data=ipa, random = ~1 | localidad) # random 
intercept

model2 = lme(ipa ~ tempo, random = ~1 | tempo/localidad, data=ipa) # 
random intercept and slope

model3 = lme(ipa ~ tempo, random = ~1 | localidad, data=ipa, 
correlation=corAR1(form=~ tempo))

I have heteroscedasticity.
Is my last model dealing with heteroscedasticity?
Thank you very much in advance.
Best,

Manuel

-- 
Manuel Sp?nola, Ph.D.
Instituto Internacional en Conservaci?n y Manejo de Vida Silvestre
Universidad Nacional
Apartado 1350-3000
Heredia
COSTA RICA
mspinola at una.ac.cr
mspinola10 at gmail.com
Tel?fono: (506) 2277-3598
Fax: (506) 2237-7036



From djmuser at gmail.com  Sun Sep 26 13:52:49 2010
From: djmuser at gmail.com (Dennis Murphy)
Date: Sun, 26 Sep 2010 04:52:49 -0700
Subject: [R-sig-ME] Dealing with heteroscedasticity in repeated measure
	models
In-Reply-To: <4C9F2D75.6070601@gmail.com>
References: <4C9F2D75.6070601@gmail.com>
Message-ID: <AANLkTinD_6Zbd9JoaVAwgJkGGd9eQBbX+3BW+4q9gsFn@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100926/6fa018fe/attachment.pl>

From andydolman at gmail.com  Sun Sep 26 13:58:32 2010
From: andydolman at gmail.com (Andrew Dolman)
Date: Sun, 26 Sep 2010 13:58:32 +0200
Subject: [R-sig-ME] Dealing with heteroscedasticity in repeated measure
	models
In-Reply-To: <4C9F2D75.6070601@gmail.com>
References: <4C9F2D75.6070601@gmail.com>
Message-ID: <AANLkTin8zge-rzBRA_A=5PHHYqVgCf1=3uKO_5XeToGq@mail.gmail.com>

Hi Manuel,

First of all a quick correction to your basic model specifications.

First model is correct:
model1 = lme(ipa ~ tempo, data=ipa, random = ~1 | localidad) # random intercept

Second model is wrong
model2 = lme(ipa ~ tempo, random = ~1 | tempo/localidad, data=ipa) #
random intercept and slope

should be
model2 = lme(ipa ~ tempo, random = ~tempo|localidad, data=ipa) #
random intercept and slope

Your 3rd model fits an autoregressive model for temporally correlated
data. Whether this deals with heteroscedasticity depends on the type
of heteroscedasticity .

model3 = lme(ipa ~ tempo, random = ~1 | localidad, data=ipa,
correlation=corAR1(form=~ tempo))



andydolman at gmail.com



On 26 September 2010 13:24, Manuel Sp?nola <mspinola10 at gmail.com> wrote:
> ?Dear list members,
>
> I am fitting a repeated measure model using lme.
> I have 4 measurements of a rate (variable called ipa) measured each year
> (variable called tempo, which was centered) on 48 counties (all the counties
> from a province, variable called localidad).
> I am considering county like a random factor.
> My models are:
>
> model1 = lme(ipa ~ tempo, data=ipa, random = ~1 | localidad) # random
> intercept
>
> model2 = lme(ipa ~ tempo, random = ~1 | tempo/localidad, data=ipa) # random
> intercept and slope
>
> model3 = lme(ipa ~ tempo, random = ~1 | localidad, data=ipa,
> correlation=corAR1(form=~ tempo))
>
> I have heteroscedasticity.
> Is my last model dealing with heteroscedasticity?
> Thank you very much in advance.
> Best,
>
> Manuel
>
> --
> Manuel Sp?nola, Ph.D.
> Instituto Internacional en Conservaci?n y Manejo de Vida Silvestre
> Universidad Nacional
> Apartado 1350-3000
> Heredia
> COSTA RICA
> mspinola at una.ac.cr
> mspinola10 at gmail.com
> Tel?fono: (506) 2277-3598
> Fax: (506) 2237-7036
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From andydolman at gmail.com  Sun Sep 26 14:51:22 2010
From: andydolman at gmail.com (Andrew Dolman)
Date: Sun, 26 Sep 2010 14:51:22 +0200
Subject: [R-sig-ME] Dealing with heteroscedasticity in repeated measure
	models
In-Reply-To: <4C9F3AD5.2070009@gmail.com>
References: <4C9F2D75.6070601@gmail.com>
	<AANLkTin8zge-rzBRA_A=5PHHYqVgCf1=3uKO_5XeToGq@mail.gmail.com>
	<4C9F3AD5.2070009@gmail.com>
Message-ID: <AANLkTi=BfxZyE6uR3nz7h=5Ai8phRDdR3TXzCZdAwj8L@mail.gmail.com>

> I found an increase of variance when increasing time, is that a
> heteroscedasticity problem?

Yes, but it could be due to several things. For example, does your
dependent variable, ipa, increase with time? For many measurements the
variance increases with the mean so if the mean increases with time so
will the variance. To deal with this you would need to look at using
either a transformation, e.g. log, or using a generalized linear model
with an appropriate error distributions, e.g. poisson. It could also
be that you have divergent time series due to autocorrelation, in
which case your third model might be appropriate.

I'm having to guess because you haven't given enough information about
the data you are modeling. Ideally this would include a sample of the
data or dummy data that reproduces the problem.


> I fitted the model in the way you suggested me but I got an error (lack of
> convergence). ?Is there any way to get around this problem?

This is fairly likely because you only have 4 data points per
localidad. You may have more luck using lmer from the lme4 package.


Andy.



>> modelo2 = lme(ipa ~ tempo, random = ~ tempo | localidad, data=ipa) #
>> intercepto y pendiente diferentes para cada localidad
> Error en lme.formula(ipa ~ tempo, random = ~tempo | localidad, data = ipa) :
> ?nlminb problem, convergence error code = 1
> ?message = iteration limit reached without convergence (9)
>
>
>
> On 26/09/2010 05:58 a.m., Andrew Dolman wrote:
>>
>> Hi Manuel,
>>
>> First of all a quick correction to your basic model specifications.
>>
>> First model is correct:
>> model1 = lme(ipa ~ tempo, data=ipa, random = ~1 | localidad) # random
>> intercept
>>
>> Second model is wrong
>> model2 = lme(ipa ~ tempo, random = ~1 | tempo/localidad, data=ipa) #
>> random intercept and slope
>>
>> should be
>> model2 = lme(ipa ~ tempo, random = ~tempo|localidad, data=ipa) #
>> random intercept and slope
>>
>> Your 3rd model fits an autoregressive model for temporally correlated
>> data. Whether this deals with heteroscedasticity depends on the type
>> of heteroscedasticity .
>>
>> model3 = lme(ipa ~ tempo, random = ~1 | localidad, data=ipa,
>> correlation=corAR1(form=~ tempo))
>>
>>
>>
>> andydolman at gmail.com
>>
>>
>>
>> On 26 September 2010 13:24, Manuel Sp?nola<mspinola10 at gmail.com> ?wrote:
>>>
>>> ?Dear list members,
>>>
>>> I am fitting a repeated measure model using lme.
>>> I have 4 measurements of a rate (variable called ipa) measured each year
>>> (variable called tempo, which was centered) on 48 counties (all the
>>> counties
>>> from a province, variable called localidad).
>>> I am considering county like a random factor.
>>> My models are:
>>>
>>> model1 = lme(ipa ~ tempo, data=ipa, random = ~1 | localidad) # random
>>> intercept
>>>
>>> model2 = lme(ipa ~ tempo, random = ~1 | tempo/localidad, data=ipa) #
>>> random
>>> intercept and slope
>>>
>>> model3 = lme(ipa ~ tempo, random = ~1 | localidad, data=ipa,
>>> correlation=corAR1(form=~ tempo))
>>>
>>> I have heteroscedasticity.
>>> Is my last model dealing with heteroscedasticity?
>>> Thank you very much in advance.
>>> Best,
>>>
>>> Manuel
>>>
>>> --
>>> Manuel Sp?nola, Ph.D.
>>> Instituto Internacional en Conservaci?n y Manejo de Vida Silvestre
>>> Universidad Nacional
>>> Apartado 1350-3000
>>> Heredia
>>> COSTA RICA
>>> mspinola at una.ac.cr
>>> mspinola10 at gmail.com
>>> Tel?fono: (506) 2277-3598
>>> Fax: (506) 2237-7036
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>
>
> --
> Manuel Sp?nola, Ph.D.
> Instituto Internacional en Conservaci?n y Manejo de Vida Silvestre
> Universidad Nacional
> Apartado 1350-3000
> Heredia
> COSTA RICA
> mspinola at una.ac.cr
> mspinola10 at gmail.com
> Tel?fono: (506) 2277-3598
> Fax: (506) 2237-7036
>
>



From andydolman at gmail.com  Sun Sep 26 16:14:45 2010
From: andydolman at gmail.com (Andrew Dolman)
Date: Sun, 26 Sep 2010 16:14:45 +0200
Subject: [R-sig-ME] Dealing with heteroscedasticity in repeated measure
	models
In-Reply-To: <4C9F469B.6090403@gmail.com>
References: <4C9F2D75.6070601@gmail.com>
	<AANLkTin8zge-rzBRA_A=5PHHYqVgCf1=3uKO_5XeToGq@mail.gmail.com>
	<4C9F3AD5.2070009@gmail.com>
	<AANLkTi=BfxZyE6uR3nz7h=5Ai8phRDdR3TXzCZdAwj8L@mail.gmail.com>
	<4C9F469B.6090403@gmail.com>
Message-ID: <AANLkTikSCaroGLCPqLfZ0fmwrj0EnVi_fZ=g7+aWjXFT@mail.gmail.com>

Hi Manuel,

Your first problem to overcome is that your response data are not from
a normal (gaussian) distribution. Far from it.

See this:

ipaDat <- read.table("ipaloc.txt", header=T, sep="\t")

library(lattice)
histogram(~ipa|tiempo, data=ipaDat)

Using an appropriate transformation or error distribution will likely
solve the heteroscedasticity too.


The quick and dirty method would be to do a log transformation of your
response variable. You have some zero values so you would have to
either exclude some data or apply a kludge like adding 1 to all values
(or perhaps 1/2 the minimum non-zero value).


How is ipa calculated? You say it is an incidence. Did you start with
a raw count?


It's better if you reply to the list rather than entering private
email chats with respondents.


andydolman at gmail.com







2010/9/26 Manuel Sp?nola <mspinola10 at gmail.com>:
> ?Thank you very much Andy.
>
> I am attaching the data. ?"tempo" in my model is "tiempo" centered.
>
> I am trying to see is ipa shows a declining trend for the 4 years period.
> ?Ipa refer to incidence of malaria in these counties (localidades).
> May be I need to see the difference in IPA between year 1 and 4 and model
> that?
> IPA usually decrease in time, for several counties.
> I tried lmer, but I found that lmer do not have the capability to deal with
> covariance structures and that lme has much more options, for example the
> function "intervals" to get the CI.
>
> If I use a poisson, should I get the count and an offset variable (the way
> that the incidence rate was calculated), right?
>
> Best,
>
> Manuel
>
>
> On 26/09/2010 06:51 a.m., Andrew Dolman wrote:
>>>
>>> I found an increase of variance when increasing time, is that a
>>> heteroscedasticity problem?
>>
>> Yes, but it could be due to several things. For example, does your
>> dependent variable, ipa, increase with time? For many measurements the
>> variance increases with the mean so if the mean increases with time so
>> will the variance. To deal with this you would need to look at using
>> either a transformation, e.g. log, or using a generalized linear model
>> with an appropriate error distributions, e.g. poisson. It could also
>> be that you have divergent time series due to autocorrelation, in
>> which case your third model might be appropriate.
>>
>> I'm having to guess because you haven't given enough information about
>> the data you are modeling. Ideally this would include a sample of the
>> data or dummy data that reproduces the problem.
>>
>>
>>> I fitted the model in the way you suggested me but I got an error (lack
>>> of
>>> convergence). ?Is there any way to get around this problem?
>>
>> This is fairly likely because you only have 4 data points per
>> localidad. You may have more luck using lmer from the lme4 package.
>>
>>
>> Andy.
>>
>>
>>
>>>> modelo2 = lme(ipa ~ tempo, random = ~ tempo | localidad, data=ipa) #
>>>> intercepto y pendiente diferentes para cada localidad
>>>
>>> Error en lme.formula(ipa ~ tempo, random = ~tempo | localidad, data =
>>> ipa) :
>>> ?nlminb problem, convergence error code = 1
>>> ?message = iteration limit reached without convergence (9)
>>>
>>>
>>>
>>> On 26/09/2010 05:58 a.m., Andrew Dolman wrote:
>>>>
>>>> Hi Manuel,
>>>>
>>>> First of all a quick correction to your basic model specifications.
>>>>
>>>> First model is correct:
>>>> model1 = lme(ipa ~ tempo, data=ipa, random = ~1 | localidad) # random
>>>> intercept
>>>>
>>>> Second model is wrong
>>>> model2 = lme(ipa ~ tempo, random = ~1 | tempo/localidad, data=ipa) #
>>>> random intercept and slope
>>>>
>>>> should be
>>>> model2 = lme(ipa ~ tempo, random = ~tempo|localidad, data=ipa) #
>>>> random intercept and slope
>>>>
>>>> Your 3rd model fits an autoregressive model for temporally correlated
>>>> data. Whether this deals with heteroscedasticity depends on the type
>>>> of heteroscedasticity .
>>>>
>>>> model3 = lme(ipa ~ tempo, random = ~1 | localidad, data=ipa,
>>>> correlation=corAR1(form=~ tempo))
>>>>
>>>>
>>>>
>>>> andydolman at gmail.com
>>>>
>>>>
>>>>
>>>> On 26 September 2010 13:24, Manuel Sp?nola<mspinola10 at gmail.com>
>>>> ?wrote:
>>>>>
>>>>> ?Dear list members,
>>>>>
>>>>> I am fitting a repeated measure model using lme.
>>>>> I have 4 measurements of a rate (variable called ipa) measured each
>>>>> year
>>>>> (variable called tempo, which was centered) on 48 counties (all the
>>>>> counties
>>>>> from a province, variable called localidad).
>>>>> I am considering county like a random factor.
>>>>> My models are:
>>>>>
>>>>> model1 = lme(ipa ~ tempo, data=ipa, random = ~1 | localidad) # random
>>>>> intercept
>>>>>
>>>>> model2 = lme(ipa ~ tempo, random = ~1 | tempo/localidad, data=ipa) #
>>>>> random
>>>>> intercept and slope
>>>>>
>>>>> model3 = lme(ipa ~ tempo, random = ~1 | localidad, data=ipa,
>>>>> correlation=corAR1(form=~ tempo))
>>>>>
>>>>> I have heteroscedasticity.
>>>>> Is my last model dealing with heteroscedasticity?
>>>>> Thank you very much in advance.
>>>>> Best,
>>>>>
>>>>> Manuel
>>>>>
>>>>> --
>>>>> Manuel Sp?nola, Ph.D.
>>>>> Instituto Internacional en Conservaci?n y Manejo de Vida Silvestre
>>>>> Universidad Nacional
>>>>> Apartado 1350-3000
>>>>> Heredia
>>>>> COSTA RICA
>>>>> mspinola at una.ac.cr
>>>>> mspinola10 at gmail.com
>>>>> Tel?fono: (506) 2277-3598
>>>>> Fax: (506) 2237-7036
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>
>>> --
>>> Manuel Sp?nola, Ph.D.
>>> Instituto Internacional en Conservaci?n y Manejo de Vida Silvestre
>>> Universidad Nacional
>>> Apartado 1350-3000
>>> Heredia
>>> COSTA RICA
>>> mspinola at una.ac.cr
>>> mspinola10 at gmail.com
>>> Tel?fono: (506) 2277-3598
>>> Fax: (506) 2237-7036
>>>
>>>
>
>
> --
> Manuel Sp?nola, Ph.D.
> Instituto Internacional en Conservaci?n y Manejo de Vida Silvestre
> Universidad Nacional
> Apartado 1350-3000
> Heredia
> COSTA RICA
> mspinola at una.ac.cr
> mspinola10 at gmail.com
> Tel?fono: (506) 2277-3598
> Fax: (506) 2237-7036
>
>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: ipaloc.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100926/380ec7cc/attachment.txt>

From m.fairbrother at bristol.ac.uk  Sun Sep 26 21:18:24 2010
From: m.fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Sun, 26 Sep 2010 20:18:24 +0100
Subject: [R-sig-ME] multilevel time series?
In-Reply-To: <mailman.593.1285510498.4267.r-sig-mixed-models@r-project.org>
References: <mailman.593.1285510498.4267.r-sig-mixed-models@r-project.org>
Message-ID: <ACE5A2B9-475C-4038-ADFA-F76934B0E6FC@bristol.ac.uk>

Dear all,

In macro-social science, it's become fairly conventional to analyse repeated cross-sectional survey data using three-level models. Individual survey espondents (level-1) are nested in state-years (level-2), which are in turn nested within states (level-3). One big pay-off is the ability to examine how time-constant or time-varying state-level variables affect level-1 outcomes.

A co-author and I recently had a reviewer question whether this approach is adequate, however. He/she suggested that this approach could generate very misleading results, if the data are nonstationary. (We just included a linear time effect in our models.) So I'm thinking about how to proceed (and I'm not particularly knowledgeable about time series analysis). Any advice would be much appreciated. We used lme4 to fit the models in our paper, and we have several tens of thousands of respondents nested in 48 states, each observed about 15 or 16 times over about a 30-year period.

(1) Is the reviewer's query? Is he/she right to question this approach?

(2) How might we test for nonstationarity? The reviewer mentioned differencing the outcome variable, but in a multilevel context I'm not sure how to do that... Perhaps we could calculate an *aggregate* value for every state-year, and check the aggregated data for autocorrelation? My understanding is that autocorrelation across multiple lags is a strong indicator of nonstationarity (while, conversely, the absence of multiple-lag autocorrelation is almost a guarantee of stationarity). I believe this can be done with nlme, as a two-level model, with state-years nested within states.

(3) However, that approach would seem to throw away a lot of level-1 information (about individual respondents), and I'm not sure about the implications for any significance tests. An alternative approach would seem to be "multilevel time series", where autocorrelation at the *group* rather than individual/first level is specifically allowed for in the model. However, I can't find any references to R packages (or other software) that allow for the specification of, for example, AR1 processes at anything other than level-1 in multilevel models.

In short, I'd be curious to hear what people think... (especially if anyone out there happens to be a whiz at both multilevel and time series analysis). I hope I've been clear about the problem, but I'm happy to elaborate. Thanks in advance for any help.

Cheers,
Malcolm


Dr Malcolm Fairbrother
Lecturer
School of Geographical Sciences
University of Bristol



From Thierry.ONKELINX at inbo.be  Mon Sep 27 10:34:33 2010
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 27 Sep 2010 10:34:33 +0200
Subject: [R-sig-ME] multilevel time series?
In-Reply-To: <ACE5A2B9-475C-4038-ADFA-F76934B0E6FC@bristol.ac.uk>
References: <mailman.593.1285510498.4267.r-sig-mixed-models@r-project.org>
	<ACE5A2B9-475C-4038-ADFA-F76934B0E6FC@bristol.ac.uk>
Message-ID: <3DB16098F738284D8DBEB2FC369916383B3B4B@inboexch.inbo.be>

Dear Malcolm,

Your design requires IMHO crossed random effects instead of nested
random effects. Individual is clearly crossed with year. Each individual
can be surveyed in more that one year and vice versa. If they were
nested, all data from a specific individual would come from only one
specific year. The same goes for state and year, they are rather crossed
than nested.

Fitting year as a crossed random effect will take nonstationarity along
time into account. The size of variance of this random effect will
indicate how strong this nonstationarity is.

HTH,

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey
  

> -----Oorspronkelijk bericht-----
> Van: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens 
> Malcolm Fairbrother
> Verzonden: zondag 26 september 2010 21:18
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] multilevel time series?
> 
> Dear all,
> 
> In macro-social science, it's become fairly conventional to 
> analyse repeated cross-sectional survey data using 
> three-level models. Individual survey espondents (level-1)
> are nested in state-years (level-2), which are in turn nested 
> within states (level-3). One big pay-off is the ability to 
> examine how time-constant or time-varying state-level 
> variables affect level-1 outcomes.
> 
> A co-author and I recently had a reviewer question whether 
> this approach is adequate, however. He/she suggested that 
> this approach could generate very misleading results, if the 
> data are nonstationary. (We just included a linear time 
> effect in our models.) So I'm thinking about how to proceed 
> (and I'm not particularly knowledgeable about time series 
> analysis). Any advice would be much appreciated. We used lme4 
> to fit the models in our paper, and we have several tens of 
> thousands of respondents nested in 48 states, each observed 
> about 15 or 16 times over about a 30-year period.
> 
> (1) Is the reviewer's query? Is he/she right to question this 
> approach?
> 
> (2) How might we test for nonstationarity? The reviewer 
> mentioned differencing the outcome variable, but in a
> multilevel context I'm not sure how to do that... Perhaps we 
> could calculate an *aggregate* value for every state-year, 
> and check the aggregated data for autocorrelation? My
> understanding is that autocorrelation across multiple lags is 
> a strong indicator of nonstationarity (while, conversely, the 
> absence of multiple-lag autocorrelation is almost a guarantee 
> of stationarity). I believe this can be done with nlme, as a 
> two-level model, with state-years nested within states.
> 
> (3) However, that approach would seem to throw away a lot of 
> level-1 information (about individual respondents), and I'm 
> not sure about the implications for any significance tests. 
> An alternative approach would seem to be "multilevel time 
> series", where autocorrelation at the *group* rather than 
> individual/first level is specifically allowed for in the 
> model. However, I can't find any references to R packages (or 
> other software) that allow for the specification of, for 
> example, AR1 processes at anything other than level-1 in 
> multilevel models.
> 
> In short, I'd be curious to hear what people think... 
> (especially if anyone out there happens to be a whiz at both 
> multilevel and time series analysis). I hope I've been clear 
> about the problem, but I'm happy to elaborate. Thanks in 
> advance for any help.
> 
> Cheers,
> Malcolm
> 
> 
> Dr Malcolm Fairbrother
> Lecturer
> School of Geographical Sciences
> University of Bristol
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

Druk dit bericht a.u.b. niet onnodig af.
Please do not print this message unnecessarily.

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From miller at psy2.psych.tu-dresden.de  Mon Sep 27 15:54:11 2010
From: miller at psy2.psych.tu-dresden.de (Robert Miller)
Date: Mon, 27 Sep 2010 15:54:11 +0200
Subject: [R-sig-ME] Logistic and nonlinear mixed models: Accounting for
 guessing probability
In-Reply-To: <C8C669BD.24A1%miller@biopsych.tu-dresden.de>
Message-ID: <C8C66EA3.24A6%miller@biopsych.tu-dresden.de>

Hello everyone,

Recently i tried to predict the discrimination probability of a chemosignal
by its concentration and an experimental manipulation factor (term:
concentration*x + test*b + concentration*test*c + d) with nested factor
"manipulation" within "participants". For statistical analysis i needed to
incorporate a fixed guessing probability into my model (similiar to a 3-PL
IRT model) resulting in the following equation:

P(correct) = 0.33 + 0.67*(exp(term)/(1 + exp(term)))

As i found no way to do so via the glmer()-function of the lme4-package, i
tried to use nlmer() but unfortunately even the simplest analysis with just
the concentration factor and intercept resulted in cryptic error messages.

Syntax:
library(lme4)
rawdata <- read.csv2("http://dl.dropbox.com/u/7147679/AND_data.csv")

mod1 <- glmer(Correct ~ log(Concentrat) * Test + (Test|Code), family =
binomial, data=rawdata) #works fine but is inappropriate
mod2 <- nlmer(Correct ~ .33 + .67*(exp(log(Concentrat)*a+d))
/(1+exp(log(Concentrat)*a+d)) ~ (Test|Code), start = c(a = 0.1, d = -3),
data = rawdata) #doesnt work
mod3 <- nlmer(Correct ~ .33 + .67*(exp(log(Concentrat)*a + Test*b +
log(Concentrat)*Test*c + d))/(1+exp( log(Concentrat)*a + Test*b +
log(Concentrat)*Test*c + d)) ~ (Test|Code), start = c(a = 0.115,b = -0.05,
c= 0.065, d= -3), data = rawdata) #doesnt work either

Even without specifying random effects nls() doesnt work, but brute force
ML-parameter estimation on the aggregated data produces reasonable results.

Right now I'm quite desperate and would appreciate any help.
Thank you
Robert Miller



From ken.knoblauch at inserm.fr  Mon Sep 27 17:50:41 2010
From: ken.knoblauch at inserm.fr (Ken Knoblauch)
Date: Mon, 27 Sep 2010 15:50:41 +0000 (UTC)
Subject: [R-sig-ME] Logistic and nonlinear mixed models: Accounting for
	guessing probability
References: <C8C669BD.24A1%miller@biopsych.tu-dresden.de>
	<C8C66EA3.24A6%miller@biopsych.tu-dresden.de>
Message-ID: <loom.20100927T174510-467@post.gmane.org>

Robert Miller <miller at ...> writes:
> Recently i tried to predict the discrimination probability of a chemosignal
> by its concentration and an experimental manipulation factor (term:
> concentration*x + test*b + concentration*test*c + d) with nested factor
> "manipulation" within "participants". For statistical analysis i needed to
> incorporate a fixed guessing probability into my model (similiar to a 3-PL
> IRT model) resulting in the following equation:
> P(correct) = 0.33 + 0.67*(exp(term)/(1 + exp(term)))
> As i found no way to do so via the glmer()-function of the lme4-package, i
> tried to use nlmer() but unfortunately even the simplest analysis with just
> the concentration factor and intercept resulted in cryptic error messages.
> Syntax:
> library(lme4)
> rawdata <- read.csv2("http://dl.dropbox.com/u/7147679/AND_data.csv")
> 
> mod1 <- glmer(Correct ~ log(Concentrat) * Test + (Test|Code), family =
> binomial, data=rawdata) #works fine but is inappropriate
> Thank you
> Robert Miller

My understanding is that you cannot do this with glmer
out of the box, as the link functions are built in at the
level of the C code.  You would have to modify that
and reinstall it.

An alternative that you might consider, is to use 
the glmmPQL function from the MASS package and
the mafc.logit link from my package psyphy.

I think that your model would be something like this
(untried):

library(MASS)
library(psyphy)

glmmPQL(Correct ~ log(Concentrat) * Test, 
    family = binomial(mafc.logit(3)), 
    data = rawdata, random = list(Code = ~ Test))

but someone can (will hopefully) correct me if I've
gotten it wrong.

Ken

-- 
Ken Knoblauch
Inserm U846
Stem-cell and Brain Research Institute
Department of Integrative Neurosciences
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.sbri.fr/members/kenneth-knoblauch.html



From Manuel.A.Morales at williams.edu  Mon Sep 27 18:25:24 2010
From: Manuel.A.Morales at williams.edu (Manuel Morales)
Date: Mon, 27 Sep 2010 12:25:24 -0400
Subject: [R-sig-ME] Logistic and nonlinear mixed models: Accounting for
 guessing probability
In-Reply-To: <C8C66EA3.24A6%miller@biopsych.tu-dresden.de>
References: <C8C66EA3.24A6%miller@biopsych.tu-dresden.de>
Message-ID: <1285604724.17358.4.camel@localhost.localdomain>

I found this link doing a search for your error message on Google:
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2007q4/000408.html

Following the recipe:
grModel <- function(x,y,a,b,c,d) .33 + .67*(exp(log(x)*a+y*b+log(x)*y*c
+ d))/
  (1+exp( log(x)*a + y*b +log(x)*y*c + d))

grModg <- deriv(body(grModel), namevec = c("a","b","c","d"),
function.arg=grModel)

mod3 <- nlmer(Correct~grModg(Concentrat,Test,a,b,c,d)~(Test|Code),
              start = c(a = 0.115, b=-0.1, c=0.65, d=-3),
              data = rawdata)
Which appears to work.

My messages haven't been posted to R, so you may want to post again with
this solution if it works for you.

Best,

Manuel

On Mon, 2010-09-27 at 15:54 +0200, Robert Miller wrote:
> Hello everyone,
> 
> Recently i tried to predict the discrimination probability of a chemosignal
> by its concentration and an experimental manipulation factor (term:
> concentration*x + test*b + concentration*test*c + d) with nested factor
> "manipulation" within "participants". For statistical analysis i needed to
> incorporate a fixed guessing probability into my model (similiar to a 3-PL
> IRT model) resulting in the following equation:
> 
> P(correct) = 0.33 + 0.67*(exp(term)/(1 + exp(term)))
> 
> As i found no way to do so via the glmer()-function of the lme4-package, i
> tried to use nlmer() but unfortunately even the simplest analysis with just
> the concentration factor and intercept resulted in cryptic error messages.
> 
> Syntax:
> library(lme4)
> rawdata <- read.csv2("http://dl.dropbox.com/u/7147679/AND_data.csv")
> 
> mod1 <- glmer(Correct ~ log(Concentrat) * Test + (Test|Code), family =
> binomial, data=rawdata) #works fine but is inappropriate
> mod2 <- nlmer(Correct ~ .33 + .67*(exp(log(Concentrat)*a+d))
> /(1+exp(log(Concentrat)*a+d)) ~ (Test|Code), start = c(a = 0.1, d = -3),
> data = rawdata) #doesnt work
> mod3 <- nlmer(Correct ~ .33 + .67*(exp(log(Concentrat)*a + Test*b +
> log(Concentrat)*Test*c + d))/(1+exp( log(Concentrat)*a + Test*b +
> log(Concentrat)*Test*c + d)) ~ (Test|Code), start = c(a = 0.115,b = -0.05,
> c= 0.065, d= -3), data = rawdata) #doesnt work either
> 
> Even without specifying random effects nls() doesnt work, but brute force
> ML-parameter estimation on the aggregated data produces reasonable results.
> 
> Right now I'm quite desperate and would appreciate any help.
> Thank you
> Robert Miller
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
http://mutualism.williams.edu



From silvie.com88 at gmail.com  Tue Sep 28 08:07:42 2010
From: silvie.com88 at gmail.com (Silvia Bauty Hidayana)
Date: Tue, 28 Sep 2010 13:07:42 +0700
Subject: [R-sig-ME] asking about panel data
Message-ID: <AANLkTi=E4Rz7qwGs=nJU-6NWTOGBAot24mOU+uXDem5O@mail.gmail.com>

Hello Sir,,my name is Silvi from Indonesia. I want to ask you about R
squared of random effect model of panel data with maximum likelihood
estimation.  I have used the package nlme to find MLE for random
effects model of panel data. But, I don?t find the R squared. How can
I get the value of R square of my models? This is my data.
Yti is percentage of poverty
X1 is gross regional domestic product per capita without the oil and gas
X2 is gross regional domestic product sector agricultural per labour
X3 is gross regional domestic product sector industri per labour
X4 is gross regional domestic product sector service per labour
t is year, i is cross section.

From farmerb at gmail.com  Tue Sep 28 14:46:24 2010
From: farmerb at gmail.com (Bob Farmer)
Date: Tue, 28 Sep 2010 09:46:24 -0300
Subject: [R-sig-ME] Overdispersion in Bernoulli models
Message-ID: <AANLkTi=vCpUMbN6T-6+=5gde==AEfAeLxA45FtyyvzPc@mail.gmail.com>

Hi again.
I've been working with a Bernoulli dependent variable and modeling its
values as a mixed model using glmer().  My understanding is that it's
not possible to model overdispersion in a Bernoulli dataset (for
instance, see Gelman and Hill 2007, p302, or
http://finzi.psych.upenn.edu/R/Rhelp02a/archive/91242.html ), however
I can find some suggestions that while it's technically not possible
to do this, estimating some analog of this parameter may nonetheless
improve model fit (see Skrondal and Rabe-Hesketh 2007, and a paragraph
in Venables and Ripley 2002, p297-8 (table 10.4, the "bacteria"
data)), even if that parameter doesn't actually represent
"overdispersion" per se.  I don't really understand how this is
possible for Bernoulli datasets -- I think the mechanics of this
process are well beyond me -- so I'd have to take it on faith that
it's working properly, and that makes me uncomfortable.

What I find interesting is that in the following self-contained
example, glmer() happily models with a quasibinomial family and gives
tighter SEs about the fixed effects compared to binomial(), but
glmmPQL (and incidentally, a glm() without the arbitrary grouping
factor) doesn't (or maybe it does? -- it has broader SEs, but also a
residual SD term).  In general, my suspicion is that something's amiss
-- I'm somehow "abusing" the glmer -- and I'm better just sticking
with the binomial family for Bernoulli datasets.  Any thoughts?

Thanks very much.
--Bob Farmer
Dalhousie University, Halifax NS

rm(list=ls())
table(bacteria$y) #Bernoulli dependent
m1<-glm(y ~ trt * week, data = bacteria, family=binomial)
#above example from ?bacteria
m2<-update(m1, family=quasibinomial)
summary(m1)
summary(m2)  #standard errors are similar enough

#use ID as a grouping factor
library(lme4)
m1.mix<-glmer(y ~ trt * week + (1 | ID), data = bacteria,family=binomial)
m2.mix<-update(m1.mix, family=quasibinomial)
summary(m1.mix)
summary(m2.mix)  #vastly different standard errors, plus residual
sigma (the overdisp?)

library(MASS)
m1.mix.PQL<-glmmPQL(y ~ trt * week, random = ~ 1 | ID, data = bacteria,
  family=binomial)
m2.mix.PQL<-update(m1.mix.PQL, family=quasibinomial)
summary(m1.mix.PQL) #also with residual sigma, but m1-style SEs
summary(m2.mix.PQL)

Note:  As far as I can tell, in these non-BUGS-based models, this is
multiplicative overdispersion (which estimates an overdispersion
parameter based on how the model deviance differs from its expected
value (which is distributed as a chi-square when overdispersion == 1)
and then scales down the standard deviation of fixed-effects
parameters accordingly.  My question does not concern the alternative
of adding a sigma[i] parameter to the main model formula directly.



From arives at wisc.edu  Tue Sep 28 15:17:19 2010
From: arives at wisc.edu (Anthony R Ives)
Date: Tue, 28 Sep 2010 08:17:19 -0500
Subject: [R-sig-ME] Overdispersion in Bernoulli models
In-Reply-To: <AANLkTi=vCpUMbN6T-6+=5gde==AEfAeLxA45FtyyvzPc@mail.gmail.com>
References: <AANLkTi=vCpUMbN6T-6+=5gde==AEfAeLxA45FtyyvzPc@mail.gmail.com>
Message-ID: <F8B71C5D-6792-4DBA-A1D1-956A38474EB9@wisc.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100928/e5d50982/attachment.pl>

From mlarkin at rsmas.miami.edu  Tue Sep 28 20:23:31 2010
From: mlarkin at rsmas.miami.edu (Michael Larkin)
Date: Tue, 28 Sep 2010 14:23:31 -0400
Subject: [R-sig-ME] bootstrapping question
Message-ID: <000601cb5f3a$40ef0820$c2cd1860$@miami.edu>

I need to bootstrap my data in R.  I am trying to run the program boot in R but am not having any luck.  I am assuming there must be a library that I first need to download before it will run?  Any advice would be greatly appreciated.  

Mike



From Stephan.Kolassa at gmx.de  Tue Sep 28 20:44:49 2010
From: Stephan.Kolassa at gmx.de (Stephan Kolassa)
Date: Tue, 28 Sep 2010 20:44:49 +0200
Subject: [R-sig-ME] bootstrapping question
In-Reply-To: <000601cb5f3a$40ef0820$c2cd1860$@miami.edu>
References: <000601cb5f3a$40ef0820$c2cd1860$@miami.edu>
Message-ID: <4CA237A1.9060102@gmx.de>

Hi Mike,

try

library(boot)
?boot

HTH,
Stephan


Am 28.09.2010 20:23, schrieb Michael Larkin:
> I need to bootstrap my data in R.  I am trying to run the program boot in R but am not having any luck.  I am assuming there must be a library that I first need to download before it will run?  Any advice would be greatly appreciated.
>
> Mike
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From mlarkin at rsmas.miami.edu  Tue Sep 28 21:14:29 2010
From: mlarkin at rsmas.miami.edu (Michael Larkin)
Date: Tue, 28 Sep 2010 15:14:29 -0400
Subject: [R-sig-ME] bootstrapping question
In-Reply-To: <4CA237A1.9060102@gmx.de>
References: <000601cb5f3a$40ef0820$c2cd1860$@miami.edu>
	<4CA237A1.9060102@gmx.de>
Message-ID: <000001cb5f41$5fba29e0$1f2e7da0$@miami.edu>

I tried that however when I run the boot program after installing the
library I keep getting the error message of: 

ERROR:  'R' is missing

Mike

-----Original Message-----
From: Stephan Kolassa [mailto:Stephan.Kolassa at gmx.de] 
Sent: Tuesday, September 28, 2010 2:45 PM
To: Michael Larkin
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] bootstrapping question

Hi Mike,

try

library(boot)
?boot

HTH,
Stephan


Am 28.09.2010 20:23, schrieb Michael Larkin:
> I need to bootstrap my data in R.  I am trying to run the program boot in
R but am not having any luck.  I am assuming there must be a library that I
first need to download before it will run?  Any advice would be greatly
appreciated.
>
> Mike
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From mlarkin at rsmas.miami.edu  Tue Sep 28 21:27:38 2010
From: mlarkin at rsmas.miami.edu (Michael Larkin)
Date: Tue, 28 Sep 2010 15:27:38 -0400
Subject: [R-sig-ME] bootstrapping
Message-ID: <000301cb5f43$36178630$a2469290$@miami.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100928/37e97b89/attachment.pl>

From NordlDJ at dshs.wa.gov  Tue Sep 28 21:29:06 2010
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Tue, 28 Sep 2010 12:29:06 -0700
Subject: [R-sig-ME] bootstrapping question
In-Reply-To: <000001cb5f41$5fba29e0$1f2e7da0$@miami.edu>
References: <000601cb5f3a$40ef0820$c2cd1860$@miami.edu>
	<4CA237A1.9060102@gmx.de> <000001cb5f41$5fba29e0$1f2e7da0$@miami.edu>
Message-ID: <941871A13165C2418EC144ACB212BDB001A283A3@dshsmxoly1504g.dshs.wa.lcl>

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-
> models-bounces at r-project.org] On Behalf Of Michael Larkin
> Sent: Tuesday, September 28, 2010 12:14 PM
> To: 'Stephan Kolassa'
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] bootstrapping question
> 
> I tried that however when I run the boot program after installing the
> library I keep getting the error message of:
> 
> ERROR:  'R' is missing
> 
> Mike
> 
Mike,

So, I think you will need to show us the code that you used to "run the boot program" before anyone can help you out.  It is often helpful to create a self-contained example (create a small data set and provide program code) so that others can play along.

Dan 

Daniel J. Nordlund
Washington State Department of Social and Health Services
Planning, Performance, and Accountability
Research and Data Analysis Division
Olympia, WA 98504-5204



From mensurationist at gmail.com  Tue Sep 28 21:51:50 2010
From: mensurationist at gmail.com (Andrew Robinson)
Date: Wed, 29 Sep 2010 05:51:50 +1000
Subject: [R-sig-ME] bootstrapping question
In-Reply-To: <000001cb5f41$5fba29e0$1f2e7da0$@miami.edu>
References: <000601cb5f3a$40ef0820$c2cd1860$@miami.edu>
	<4CA237A1.9060102@gmx.de>
	<000001cb5f41$5fba29e0$1f2e7da0$@miami.edu>
Message-ID: <AANLkTinySZZixAfCdpQqVyM=XempKuZeyy7y176_g_M_@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100929/e7e6a536/attachment.pl>

From ned.dochtermann at gmail.com  Wed Sep 29 00:18:23 2010
From: ned.dochtermann at gmail.com (Ned Dochtermann)
Date: Tue, 28 Sep 2010 15:18:23 -0700
Subject: [R-sig-ME] asking about panel data
Message-ID: <4ca269b3.2245e50a.692c.3e2a@mx.google.com>

Silvi,

There's not going to be a typical r^2 calculated for mixed models just as
part of the output. Instead you have to use one of the extensions to
likelihood models. What I've done, and hopefully someone will correct me if
there is a better approach, has been to calculate r^2 based on Nagelkerke's
1991 formulation:

Nagelkerke, N. J. D. 1991. A note on a general definition of the coefficient
of determination. Biometrika 78:691-692.

Using nlme you would calculate r^2 as:
1-exp((-2/n)*(main.model$logLik-null.model$logLik))

Where the two models (obviously) correspond to your main model and a null.
"n" is the sample size.

You'll have to decide what the appropriate structure for your null model is;
that is, should you include the random terms or not-it is going to depend on
your question. It is also important to specify in your code for the initial
models that you want to use ML estimation rather than REML estimation. If
you choose to not include the random terms, use gls{nlme} to get the null
likelihood not "lm":
http://glmm.wikidot.com/random-effects-testing

There's a comment on Ben Bolker's site (the wiki link above) saying it isn't
necessarily a good idea to calculate r^2 but no expansion is given and so it
isn't clear whether that's mainly in reference to generalized models-which
aren't fit by likelihood.

You may also find it useful to search the archives of this listserv as I
would be surprised if this topic hasn't come up before.

Good luck!
Ned



--
Ned Dochtermann
Department of Biology
University of Nevada, Reno

ned.dochtermann at gmail.com
http://wolfweb.unr.edu/homepage/mpeacock/Dochter/
--

Hello Sir,,my name is Silvi from Indonesia. I want to ask you about R
squared of random effect model of panel data with maximum likelihood
estimation.  I have used the package nlme to find MLE for random
effects model of panel data. But, I don't find the R squared. How can
I get the value of R square of my models? This is my data.
Yti is percentage of poverty
X1 is gross regional domestic product per capita without the oil and gas
X2 is gross regional domestic product sector agricultural per labour
X3 is gross regional domestic product sector industri per labour
X4 is gross regional domestic product sector service per labour
t is year, i is cross section.



From S.elMesslaki at student.TUDelft.NL  Wed Sep 29 15:21:34 2010
From: S.elMesslaki at student.TUDelft.NL (Sabira el Messlaki)
Date: Wed, 29 Sep 2010 15:21:34 +0200
Subject: [R-sig-ME] corclasses
References: <mailman.7.1285754402.2217.r-sig-mixed-models@r-project.org>
Message-ID: <3154E0B9605B3140AFAD0A3A97DA29CF83244C@SRV603.tudelft.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100929/72ab3a60/attachment.pl>

From S.elMesslaki at student.TUDelft.NL  Wed Sep 29 15:25:56 2010
From: S.elMesslaki at student.TUDelft.NL (Sabira el Messlaki)
Date: Wed, 29 Sep 2010 15:25:56 +0200
Subject: [R-sig-ME] corclasses
Message-ID: <3154E0B9605B3140AFAD0A3A97DA29CF83244E@SRV603.tudelft.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100929/c0621b33/attachment.pl>

From nikko at hailmail.net  Wed Sep 29 19:47:35 2010
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: Wed, 29 Sep 2010 10:47:35 -0700
Subject: [R-sig-ME] Help with nested doubly repeated measures
In-Reply-To: <mailman.7.1285754402.2217.r-sig-mixed-models@r-project.org>
References: <mailman.7.1285754402.2217.r-sig-mixed-models@r-project.org>
Message-ID: <1285782455.8777.1397521877@webmail.messagingengine.com>

Hi Folks,
I have an experiment with about 80 mice. Mice were randomized to
treatment and control arms. The experiment consisted of 3 balance beams,
Wide, Medium and Narrow. The mice were each given 3 trials on each
balance beam (no not in random order). So the beam should get
sequentially harder as it gets narrower. The responses were the latency,
the time to cross the beam and the number of footslips as they crossed
the beam. So I have beam nested in mouse and trial nested in beam. I
tried the following model:

lmer(latency.s.~ Treatment + BeamSize +
(1|ID./BeamSize/TrialNo),data=dat,na.action=na.omit)
Error: length(f1) == length(f2) is not TRUE
In addition: Warning messages:
1: In TrialNo:(BeamSize:ID.) :
  numerical expression has 827 elements: only the first used
2: In TrialNo:(BeamSize:ID.) :
  numerical expression has 827 elements: only the first use

But I am not sure that this is the "right" way to specify this model.
Ideally 
There are two questions. 1) Is the overall marginal latency lower in the
treated animals, and 2) is the Beam size Slope 
for treated animals shallower than for untreated animals. I have looked
at Park and Lee (2002) Statistics in Medicine 23:143-164, who give SAS
code for a similar model. However, I am not very good at translating SAS
to lme/lme4.

Once I have this figured out, is it possible to jointly model foot slips
and latency?

Thanks for any input.

Nicholas Lewin-Koh
Senior Statistical Scientist
Genentech



From djmuser at gmail.com  Wed Sep 29 20:46:00 2010
From: djmuser at gmail.com (Dennis Murphy)
Date: Wed, 29 Sep 2010 11:46:00 -0700
Subject: [R-sig-ME] Help with nested doubly repeated measures
In-Reply-To: <1285782455.8777.1397521877@webmail.messagingengine.com>
References: <mailman.7.1285754402.2217.r-sig-mixed-models@r-project.org>
	<1285782455.8777.1397521877@webmail.messagingengine.com>
Message-ID: <AANLkTimOpNgZ6QhgOyMG3sCZv+ARVY8_pFoZVjHEv=2g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100929/278f27f4/attachment.pl>

From camargo.ufpr at gmail.com  Wed Sep 29 20:46:20 2010
From: camargo.ufpr at gmail.com (=?ISO-8859-1?Q?Maur=EDcio_Camargo?=)
Date: Wed, 29 Sep 2010 15:46:20 -0300
Subject: [R-sig-ME] New package GAD (General ANOVA Design)
Message-ID: <AANLkTi=xyJAoYZQOUD7b73Me68Y5rYk+B+=AWDu=2QTg@mail.gmail.com>

Hi, everyone.

GAD package analyses complex ANOVA models with any combination of
orthogonal/nested and fixed/random factors, as described by Underwood
(1997). There are two restrictions: (i) data must be balanced; (ii)
fixed nested factors are not allowed. Homogeneity of variances is
checked using Cochran's C test and "a posteriori" comparisons of means
are done using Student-Newman-Keuls (SNK) procedure.

Best,

Maur?cio G. Camargo



From nikko at hailmail.net  Wed Sep 29 22:21:42 2010
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: Wed, 29 Sep 2010 13:21:42 -0700
Subject: [R-sig-ME] Help with nested doubly repeated measures
In-Reply-To: <AANLkTimOpNgZ6QhgOyMG3sCZv+ARVY8_pFoZVjHEv=2g@mail.gmail.com>
References: <mailman.7.1285754402.2217.r-sig-mixed-models@r-project.org><1285782455.8777.1397521877@webmail.messagingengine.com>
	<AANLkTimOpNgZ6QhgOyMG3sCZv+ARVY8_pFoZVjHEv=2g@mail.gmail.com>
Message-ID: <1285791702.8657.1397560365@webmail.messagingengine.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100929/cc84cd7f/attachment.pl>

From Mike.Lawrence at dal.ca  Wed Sep 29 22:36:35 2010
From: Mike.Lawrence at dal.ca (Mike Lawrence)
Date: Wed, 29 Sep 2010 17:36:35 -0300
Subject: [R-sig-ME] Help with nested doubly repeated measures
In-Reply-To: <1285791702.8657.1397560365@webmail.messagingengine.com>
References: <mailman.7.1285754402.2217.r-sig-mixed-models@r-project.org>
	<1285782455.8777.1397521877@webmail.messagingengine.com>
	<AANLkTimOpNgZ6QhgOyMG3sCZv+ARVY8_pFoZVjHEv=2g@mail.gmail.com>
	<1285791702.8657.1397560365@webmail.messagingengine.com>
Message-ID: <AANLkTimSd7mujqKcfTj_qTe07OPXavCF3kzdL-VMqVzX@mail.gmail.com>

No need to average across trials, best to leave trials in so that the
model take into account that variance and possibly improve power. You
might even add trial number as a variable in the model if you think
there might be consistent changes across trials, though I'm not sure
if it's better to include it as a numeric variable or a factor; the
latter might be better if you expect non-linearity of the effect of
trial.

fit = lmer(
    formula = latency.s.~ Treatment*BeamSize*Trial +
        (1|ID)
    , data = dat
    , na.action = na.omit
)

Since you're dealing with latencies, you should check that the
residuals are normal and if not, consider transforming latency with a
reciprocal or log.

Regarding combining your latency measure with foot slips, this sounds
similar to the problem of integrating speed and accuracy data from
experiments on human response time. In both domains you might
reasonably expect speed and accuracy to potentially trade-off; if
speed goes up but accuracy goes down between two conditions, a
speed-accuracy trade-off (SAT) has occurred. In some circumstances,
SATs are far less interesting than true changes in performance that
manifest when either only one variable changes or both variables
change in the same direction. Unfortunately, there is no solid answer
on how to appropriately combine speed and accuracy measures, so it's
probably best to model them separately and compare the outcomes to
look for SATs.



On Wed, Sep 29, 2010 at 5:21 PM, Nicholas Lewin-Koh <nikko at hailmail.net> wrote:
> I was thinking of it more like a split-plot, where each mouse
> gets a treatment (whole plot),
> and within each mouse ?there is a set of treatments, beams and
> the trials
> are the replicates. So yes I can see that the beams are fixed,
> and all
> mice are tested on the same beams ie crossed. Each mouse gets
> three
> trials on each beam, 9 trials altogether. I could average the
> trials on each beam
> by mouse, which would make the model easier to fit. So that would
> be
>
> lmer(latency.s.~ Treatment*BeamSize +
> (1|ID),data=dat,na.action=na.omit)
>
> But I would still like to understand how to fit the full model in
> R. My data is structured
> as follows:
> ?dat[1:10,]
> ? ? ? ? ? newID ? ? falls ? ? ?footslips Sex ?GT Treatment
> ID. BB.age
> 1 ?2596-1802.L.1 ? ? 0 ? ? ? ? 0 M ? ? pos ? ? ? ? V ?2596-1802
> 17.1
> 2 ?2596-1802.L.2 ? ? 0 ? ? ? ? 0 M ? ? pos ? ? ? ? V ?2596-1802
> 17.1
> 3 ?2596-1802.L.3 ? ? 0 ? ? ? ? 1 M ? ? pos ? ? ? ? V ?2596-1802
> 17.1
> 4 ?2596-1802.M.1 ? ? 0 ? ? ? ? 1 M ? ? pos ? ? ? ?V ?2596-1802
> 17.1
> 5 ?2596-1802.M.2 ? ? 0 ? ? ? ? 2 M ? ? pos ? ? ? ?V ?2596-1802
> 17.1
> 6 ?2596-1802.M.3 ? ? 0 ? ? ? ?13 M ? ? pos ? ? ? V ?2596-1802
> 17.1
> 7 ?2596-1802.S.1 ? ? 0 ? ? ? ?15 M ? ? pos ? ? ? ?V ?2596-1802
> 17.1
> 8 ?2596-1802.S.2 ? ? 0 ? ? ? ? 7 M ? ? pos ? ? ? ? V ?2596-1802
> 17.1
> 9 ?2596-1802.S.3 ? ? 0 ? ? ? ? 5 M ? ? pos ? ? ? ? V ?2596-1802
> 17.1
> 10 2596-1804.L.1 ? ? 0 ? ? ? ? 0 F ? ? pos ? ? ? ? T ?2596-1804
> 17.4
> ? traverses.beam BeamSize latency.s. TrialNo
> 1 ? ? ? ? on toes ? ? ? ?L ? ? ? ? ? ? ? ? 11.40 ? ? ? 1
> 2 ? ? ? ? on toes ? ? ? ?L ? ? ? ? ? ? ? ? 17.31 ? ? ? 2
> 3 ? ? ? ? on toes ? ? ? ?L ? ? ? ? ? ? ? ? 21.87 ? ? ? 3
> 4 ? ? ? ? on toes ? ? ? ?M ? ? ? ? ? ? ? ?37.81 ? ? ? 1
> 5 ? ? ? ? on toes ? ? ? ?M ? ? ? ? ? ? ? ?21.84 ? ? ? 2
> 6 ? ? ? ? on toes ? ? ? ?M ? ? ? ? ? ? ? ?25.96 ? ? ? 3
> 7 ? ? ? ? on toes ? ? ? ?S ? ? ? ? ? ? ? ? 40.03 ? ? ? 1
> 8 ? ? ? ? on toes ? ? ? ?S ? ? ? ? ? ? ? ? 68.72 ? ? ? 2
> 9 ? ? ? ? on toes ? ? ? ?S ? ? ? ? ? ? ? ? 61.18 ? ? ? 3
> 10 ? ? ? ? ? ? ? ? ? ? ? ? ? ? L ? ? ? ? ? ? ? ?26.03 ? ? ? 1
>
> Nicholas
> On Wed, 29 Sep 2010 11:46 -0700, "Dennis Murphy"
> <djmuser at gmail.com> wrote:
>
> ?Hi:
>
> On Wed, Sep 29, 2010 at 10:47 AM, Nicholas Lewin-Koh
> <[1]nikko at hailmail.net> wrote:
>
> ?Hi Folks,
> ?I have an experiment with about 80 mice. Mice were randomized
> ?to
> ?treatment and control arms. The experiment consisted of 3
> ?balance beams,
> ?Wide, Medium and Narrow. The mice were each given 3 trials on
> ?each
> ?balance beam (no not in random order). So the beam should get
> ?sequentially harder as it gets narrower. The responses were
> ?the latency,
> ?the time to cross the beam and the number of footslips as they
> ?crossed
> ?the beam. So I have beam nested in mouse and trial nested in
> ?beam. I
> ?tried the following model:
>
> The only way beam is nested within mouse is if different sets of
> beams
> were used for different mice. If all mice used the same set of
> beams, then
> mice and beams are crossed factors. Recall that factor B is
> nested within
> factor A if each level of B is associated with exactly one level
> of A.
> Conversely, A and B are (completely) crossed if each level of A
> occurs
> in combination with each level of B.
> As far as the trials go, each mouse gets three trials, so if
> trial were to be
> nested within anything, it would have to be the mouse. The key
> question
> is what is the experimental unit - the mouse or the beam?
> Now that I think about it, each trial uses a different beam, so
> beam and
> trial are confounded, no? If that's the case, the model gets much
> simpler...
> HTH,
> Dennis
>
> ?lmer(latency.s.~ Treatment + BeamSize +
> ?(1|ID./BeamSize/TrialNo),data=dat,na.action=na.omit)
> ?Error: length(f1) == length(f2) is not TRUE
> ?In addition: Warning messages:
> ?1: In TrialNo:(BeamSize:ID.) :
> ? numerical expression has 827 elements: only the first used
> ?2: In TrialNo:(BeamSize:ID.) :
> ? numerical expression has 827 elements: only the first use
> ?But I am not sure that this is the "right" way to specify this
> ?model.
> ?Ideally
> ?There are two questions. 1) Is the overall marginal latency
> ?lower in the
> ?treated animals, and 2) is the Beam size Slope
> ?for treated animals shallower than for untreated animals. I
> ?have looked
> ?at Park and Lee (2002) Statistics in Medicine 23:143-164, who
> ?give SAS
> ?code for a similar model. However, I am not very good at
> ?translating SAS
> ?to lme/lme4.
> ?Once I have this figured out, is it possible to jointly model
> ?foot slips
> ?and latency?
> ?Thanks for any input.
> ?Nicholas Lewin-Koh
> ?Senior Statistical Scientist
> ?Genentech
> ?_______________________________________________
> ?[2]R-sig-mixed-models at r-project.org mailing list
> ?[3]https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> References
>
> 1. mailto:nikko at hailmail.net
> 2. mailto:R-sig-mixed-models at r-project.org
> 3. https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From djmuser at gmail.com  Wed Sep 29 23:46:47 2010
From: djmuser at gmail.com (Dennis Murphy)
Date: Wed, 29 Sep 2010 14:46:47 -0700
Subject: [R-sig-ME] Help with nested doubly repeated measures
In-Reply-To: <1285791702.8657.1397560365@webmail.messagingengine.com>
References: <mailman.7.1285754402.2217.r-sig-mixed-models@r-project.org>
	<1285782455.8777.1397521877@webmail.messagingengine.com>
	<AANLkTimOpNgZ6QhgOyMG3sCZv+ARVY8_pFoZVjHEv=2g@mail.gmail.com>
	<1285791702.8657.1397560365@webmail.messagingengine.com>
Message-ID: <AANLkTimkiUiAm7qnLm6wQtU0NBnQes7cRGFx4UqN+2+g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100929/cf21b117/attachment.pl>

From ndjido at gmail.com  Thu Sep 30 10:03:18 2010
From: ndjido at gmail.com (Ndjido Ardo BAR)
Date: Thu, 30 Sep 2010 08:03:18 +0000
Subject: [R-sig-ME] heritability standard error
Message-ID: <AANLkTinH1oAN6ju846fzNEoxKsc-z9f50LbqCOy3mba-@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20100930/ade61361/attachment.pl>

From j.hadfield at ed.ac.uk  Thu Sep 30 10:29:54 2010
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 30 Sep 2010 09:29:54 +0100
Subject: [R-sig-ME] heritability standard error
In-Reply-To: <AANLkTinH1oAN6ju846fzNEoxKsc-z9f50LbqCOy3mba-@mail.gmail.com>
References: <AANLkTinH1oAN6ju846fzNEoxKsc-z9f50LbqCOy3mba-@mail.gmail.com>
Message-ID: <20100930092954.hu5nyum7twkkc8c4@www.staffmail.ed.ac.uk>

Hi,

If the response is Gaussian:

sd(m1$VCV[,"animal"]/rowSums(m1$VCV))

where m1 is the model. However, I would call it the posterior standard  
deviation rather than a standard error.

Cheers,

Jarrod


Quoting Ndjido Ardo BAR <ndjido at gmail.com>:

> Hi Folks!
> Does someone knows how to calculate heritability standard error from an
> animal model obtained using MCMCglmm?
> Ardo.
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From peterfrancis at me.com  Thu Sep 30 13:44:59 2010
From: peterfrancis at me.com (Peter Francis)
Date: Thu, 30 Sep 2010 12:44:59 +0100
Subject: [R-sig-ME] model simplification with lme4, brier etc with lrm
Message-ID: <08854FCA-E79F-45C1-B908-894D63F37944@me.com>

Dear List,

I have arrived at the most likely model using the  AIC value, AIC weights, etc etc as model selection, the model has  5 fixed variables and two random effects.

I am wanting to use this model in a predictive sense, i understand lmer does not have a predict() function and from reading the literature i understand why. 

So my approach was to use the "most likely" model selected with lmer and run it as a linear model with lrm( package design) and leave out the random effects ( which are significant).

>From here i validated the model with the AUC, Brier score etc and used the predict function.

However my r2 values, brier score etc were not very good and i was wondering if this is because i left out the random effects? And if it is is there a work around?

Thanks

Peter



From bates at stat.wisc.edu  Thu Sep 30 21:56:21 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 30 Sep 2010 14:56:21 -0500
Subject: [R-sig-ME] multilevel time series?
In-Reply-To: <3DB16098F738284D8DBEB2FC369916383B3B4B@inboexch.inbo.be>
References: <mailman.593.1285510498.4267.r-sig-mixed-models@r-project.org>
	<ACE5A2B9-475C-4038-ADFA-F76934B0E6FC@bristol.ac.uk>
	<3DB16098F738284D8DBEB2FC369916383B3B4B@inboexch.inbo.be>
Message-ID: <AANLkTimjt1DU3c8=Hs-SuWZc4CuQz4rTaCtSq_5LMCz+@mail.gmail.com>

On Mon, Sep 27, 2010 at 3:34 AM, ONKELINX, Thierry
<Thierry.ONKELINX at inbo.be> wrote:
> Dear Malcolm,

> Your design requires IMHO crossed random effects instead of nested
> random effects. Individual is clearly crossed with year. Each individual
> can be surveyed in more that one year and vice versa. If they were
> nested, all data from a specific individual would come from only one
> specific year. The same goes for state and year, they are rather crossed
> than nested.

Malcolm's original description mentions modeling a linear trend in
time, which would make sense to me.  Even taking into account the fact
that a person can move from one state to another (hence you don't have
strict nesting of the person and state factors) such data can still be
analyzed using lme4.  Before doing so I would want to plot response
versus time for several individuals, just to see if a linear trend
looks adequate.  Having 15 to 20 different time points per subject
would allow you to model more than a linear trend within subject.

Sometimes people will approach such a case using time series methods,
even though the series are rather short.  Simple relationships like an
AR1 (first-order autoregressive) model generate marginal covariance
patterns that are very similar to that generated by a model with
per-subject random effects for the intercept and the slope with
respect to time.  This is why I don't usually combine these terms.  It
is hard to separate out the effect of each.

Your suggestion is somewhat different.  It is more like a panel data
type of model and could definitely be appropriate if the effect of a
particular year was more-or-less common across subjects.  This type of
model is applied to data like the quarterly profits of several
companies.  Macro-economic forces can (and did) have industry-wide
effects on the Q1 results in 2009 so it makes sense to regard each
time period as distinct.

If, on the other hand, you had time trends within individuals but not
synchronized across time periods then I would set up a model for the
within-subject time trends and try to incorporate random effects in
that model, as Malcolm seems to indicate they have done.

> Fitting year as a crossed random effect will take nonstationarity along
> time into account. The size of variance of this random effect will
> indicate how strong this nonstationarity is.
>> -----Oorspronkelijk bericht-----
>> Van: r-sig-mixed-models-bounces at r-project.org
>> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens
>> Malcolm Fairbrother
>> Verzonden: zondag 26 september 2010 21:18
>> Aan: r-sig-mixed-models at r-project.org
>> Onderwerp: [R-sig-ME] multilevel time series?
>>
>> Dear all,
>>
>> In macro-social science, it's become fairly conventional to
>> analyse repeated cross-sectional survey data using
>> three-level models. Individual survey espondents (level-1)
>> are nested in state-years (level-2), which are in turn nested
>> within states (level-3). One big pay-off is the ability to
>> examine how time-constant or time-varying state-level
>> variables affect level-1 outcomes.
>>
>> A co-author and I recently had a reviewer question whether
>> this approach is adequate, however. He/she suggested that
>> this approach could generate very misleading results, if the
>> data are nonstationary. (We just included a linear time
>> effect in our models.) So I'm thinking about how to proceed
>> (and I'm not particularly knowledgeable about time series
>> analysis). Any advice would be much appreciated. We used lme4
>> to fit the models in our paper, and we have several tens of
>> thousands of respondents nested in 48 states, each observed
>> about 15 or 16 times over about a 30-year period.
>>
>> (1) Is the reviewer's query? Is he/she right to question this
>> approach?
>>
>> (2) How might we test for nonstationarity? The reviewer
>> mentioned differencing the outcome variable, but in a
>> multilevel context I'm not sure how to do that... Perhaps we
>> could calculate an *aggregate* value for every state-year,
>> and check the aggregated data for autocorrelation? My
>> understanding is that autocorrelation across multiple lags is
>> a strong indicator of nonstationarity (while, conversely, the
>> absence of multiple-lag autocorrelation is almost a guarantee
>> of stationarity). I believe this can be done with nlme, as a
>> two-level model, with state-years nested within states.
>>
>> (3) However, that approach would seem to throw away a lot of
>> level-1 information (about individual respondents), and I'm
>> not sure about the implications for any significance tests.
>> An alternative approach would seem to be "multilevel time
>> series", where autocorrelation at the *group* rather than
>> individual/first level is specifically allowed for in the
>> model. However, I can't find any references to R packages (or
>> other software) that allow for the specification of, for
>> example, AR1 processes at anything other than level-1 in
>> multilevel models.
>>
>> In short, I'd be curious to hear what people think...
>> (especially if anyone out there happens to be a whiz at both
>> multilevel and time series analysis). I hope I've been clear
>> about the problem, but I'm happy to elaborate. Thanks in
>> advance for any help.
>>
>> Cheers,
>> Malcolm
>>
>>
>> Dr Malcolm Fairbrother
>> Lecturer
>> School of Geographical Sciences
>> University of Bristol
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> Druk dit bericht a.u.b. niet onnodig af.
> Please do not print this message unnecessarily.
>
> Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer
> en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
> door een geldig ondertekend document. The views expressed in ?this message
> and any annex are purely those of the writer and may not be regarded as stating
> an official position of INBO, as long as the message is not confirmed by a duly
> signed document.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Thu Sep 30 22:29:32 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 30 Sep 2010 15:29:32 -0500
Subject: [R-sig-ME] Logistic and nonlinear mixed models: Accounting for
 guessing probability
In-Reply-To: <1285604724.17358.4.camel@localhost.localdomain>
References: <C8C66EA3.24A6%miller@biopsych.tu-dresden.de>
	<1285604724.17358.4.camel@localhost.localdomain>
Message-ID: <AANLkTimc2hR1Br247tCAGeNnvWXcSb_hjBK7s90nmzW5@mail.gmail.com>

Unfortunately an nlmer model is not appropriate for a binary response,
because it doesn't appropriately weight the residuals.

Incorporating a non-zero guessing parameter requires a generalized
nonlinear mixed model if you need to estimate the guessing parameter.
The long term plan is to allow such a model.  This is the reason that
Martin and I worked on factoring out the internal code dealing with
different kinds of models for the expected response.  Nonlinear models
affect these in one way and generalized linear models in another so
you need to chain these effects.

For the particular case that Robert is considering, in which the
guessing parameter is fixed at 0.33 I think it may be possible to use
the mafc.logit link from the psyphy package with lme4a, the
development version of lme4.  I am currently installing the necessary
packages to see if I can make it work.  My thanks to Robert for making
the data available so we can test it.

On Mon, Sep 27, 2010 at 11:25 AM, Manuel Morales
<Manuel.A.Morales at williams.edu> wrote:
> I found this link doing a search for your error message on Google:
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2007q4/000408.html
>
> Following the recipe:
> grModel <- function(x,y,a,b,c,d) .33 + .67*(exp(log(x)*a+y*b+log(x)*y*c
> + d))/
> ?(1+exp( log(x)*a + y*b +log(x)*y*c + d))
>
> grModg <- deriv(body(grModel), namevec = c("a","b","c","d"),
> function.arg=grModel)
>
> mod3 <- nlmer(Correct~grModg(Concentrat,Test,a,b,c,d)~(Test|Code),
> ? ? ? ? ? ? ?start = c(a = 0.115, b=-0.1, c=0.65, d=-3),
> ? ? ? ? ? ? ?data = rawdata)
> Which appears to work.
>
> My messages haven't been posted to R, so you may want to post again with
> this solution if it works for you.
>
> Best,
>
> Manuel
>
> On Mon, 2010-09-27 at 15:54 +0200, Robert Miller wrote:
>> Hello everyone,
>>
>> Recently i tried to predict the discrimination probability of a chemosignal
>> by its concentration and an experimental manipulation factor (term:
>> concentration*x + test*b + concentration*test*c + d) with nested factor
>> "manipulation" within "participants". For statistical analysis i needed to
>> incorporate a fixed guessing probability into my model (similiar to a 3-PL
>> IRT model) resulting in the following equation:
>>
>> P(correct) = 0.33 + 0.67*(exp(term)/(1 + exp(term)))
>>
>> As i found no way to do so via the glmer()-function of the lme4-package, i
>> tried to use nlmer() but unfortunately even the simplest analysis with just
>> the concentration factor and intercept resulted in cryptic error messages.
>>
>> Syntax:
>> library(lme4)
>> rawdata <- read.csv2("http://dl.dropbox.com/u/7147679/AND_data.csv")
>>
>> mod1 <- glmer(Correct ~ log(Concentrat) * Test + (Test|Code), family =
>> binomial, data=rawdata) #works fine but is inappropriate
>> mod2 <- nlmer(Correct ~ .33 + .67*(exp(log(Concentrat)*a+d))
>> /(1+exp(log(Concentrat)*a+d)) ~ (Test|Code), start = c(a = 0.1, d = -3),
>> data = rawdata) #doesnt work
>> mod3 <- nlmer(Correct ~ .33 + .67*(exp(log(Concentrat)*a + Test*b +
>> log(Concentrat)*Test*c + d))/(1+exp( log(Concentrat)*a + Test*b +
>> log(Concentrat)*Test*c + d)) ~ (Test|Code), start = c(a = 0.115,b = -0.05,
>> c= 0.065, d= -3), data = rawdata) #doesnt work either
>>
>> Even without specifying random effects nls() doesnt work, but brute force
>> ML-parameter estimation on the aggregated data produces reasonable results.
>>
>> Right now I'm quite desperate and would appreciate any help.
>> Thank you
>> Robert Miller
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> --
> http://mutualism.williams.edu
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Thu Sep 30 22:42:39 2010
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 30 Sep 2010 15:42:39 -0500
Subject: [R-sig-ME] Logistic and nonlinear mixed models: Accounting for
 guessing probability
In-Reply-To: <AANLkTimc2hR1Br247tCAGeNnvWXcSb_hjBK7s90nmzW5@mail.gmail.com>
References: <C8C66EA3.24A6%miller@biopsych.tu-dresden.de>
	<1285604724.17358.4.camel@localhost.localdomain>
	<AANLkTimc2hR1Br247tCAGeNnvWXcSb_hjBK7s90nmzW5@mail.gmail.com>
Message-ID: <AANLkTi=kXkb-kah9KRhA31=tBcwaNiMWMkVpDTYG4=mp@mail.gmail.com>

On Thu, Sep 30, 2010 at 3:29 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
> Unfortunately an nlmer model is not appropriate for a binary response,
> because it doesn't appropriately weight the residuals.
>
> Incorporating a non-zero guessing parameter requires a generalized
> nonlinear mixed model if you need to estimate the guessing parameter.
> The long term plan is to allow such a model. ?This is the reason that
> Martin and I worked on factoring out the internal code dealing with
> different kinds of models for the expected response. ?Nonlinear models
> affect these in one way and generalized linear models in another so
> you need to chain these effects.
>
> For the particular case that Robert is considering, in which the
> guessing parameter is fixed at 0.33 I think it may be possible to use
> the mafc.logit link from the psyphy package with lme4a, the
> development version of lme4. ?I am currently installing the necessary
> packages to see if I can make it work. ?My thanks to Robert for making
> the data available so we can test it.

It wasn't as easy as I had hoped it would be.  I'm getting an error
when evaluating the linkfun (and, presumably, will get such an error
for all the other functions in the family).  It probably has to do
with the environment in which the function is evaluated in that it
can't see the value of 'm'.

I'm not sure if I will be able to fix it in a reasonable amount of
time (I should be grading assignments from one of my classes right
now).

Actually the whole design of the glm families should be reconsidered
but we'll save that for another time.

> On Mon, Sep 27, 2010 at 11:25 AM, Manuel Morales
> <Manuel.A.Morales at williams.edu> wrote:
>> I found this link doing a search for your error message on Google:
>> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2007q4/000408.html
>>
>> Following the recipe:
>> grModel <- function(x,y,a,b,c,d) .33 + .67*(exp(log(x)*a+y*b+log(x)*y*c
>> + d))/
>> ?(1+exp( log(x)*a + y*b +log(x)*y*c + d))
>>
>> grModg <- deriv(body(grModel), namevec = c("a","b","c","d"),
>> function.arg=grModel)
>>
>> mod3 <- nlmer(Correct~grModg(Concentrat,Test,a,b,c,d)~(Test|Code),
>> ? ? ? ? ? ? ?start = c(a = 0.115, b=-0.1, c=0.65, d=-3),
>> ? ? ? ? ? ? ?data = rawdata)
>> Which appears to work.
>>
>> My messages haven't been posted to R, so you may want to post again with
>> this solution if it works for you.
>>
>> Best,
>>
>> Manuel
>>
>> On Mon, 2010-09-27 at 15:54 +0200, Robert Miller wrote:
>>> Hello everyone,
>>>
>>> Recently i tried to predict the discrimination probability of a chemosignal
>>> by its concentration and an experimental manipulation factor (term:
>>> concentration*x + test*b + concentration*test*c + d) with nested factor
>>> "manipulation" within "participants". For statistical analysis i needed to
>>> incorporate a fixed guessing probability into my model (similiar to a 3-PL
>>> IRT model) resulting in the following equation:
>>>
>>> P(correct) = 0.33 + 0.67*(exp(term)/(1 + exp(term)))
>>>
>>> As i found no way to do so via the glmer()-function of the lme4-package, i
>>> tried to use nlmer() but unfortunately even the simplest analysis with just
>>> the concentration factor and intercept resulted in cryptic error messages.
>>>
>>> Syntax:
>>> library(lme4)
>>> rawdata <- read.csv2("http://dl.dropbox.com/u/7147679/AND_data.csv")
>>>
>>> mod1 <- glmer(Correct ~ log(Concentrat) * Test + (Test|Code), family =
>>> binomial, data=rawdata) #works fine but is inappropriate
>>> mod2 <- nlmer(Correct ~ .33 + .67*(exp(log(Concentrat)*a+d))
>>> /(1+exp(log(Concentrat)*a+d)) ~ (Test|Code), start = c(a = 0.1, d = -3),
>>> data = rawdata) #doesnt work
>>> mod3 <- nlmer(Correct ~ .33 + .67*(exp(log(Concentrat)*a + Test*b +
>>> log(Concentrat)*Test*c + d))/(1+exp( log(Concentrat)*a + Test*b +
>>> log(Concentrat)*Test*c + d)) ~ (Test|Code), start = c(a = 0.115,b = -0.05,
>>> c= 0.065, d= -3), data = rawdata) #doesnt work either
>>>
>>> Even without specifying random effects nls() doesnt work, but brute force
>>> ML-parameter estimation on the aggregated data produces reasonable results.
>>>
>>> Right now I'm quite desperate and would appreciate any help.
>>> Thank you
>>> Robert Miller
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> --
>> http://mutualism.williams.edu
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>



