From mo|||eebrook@ @end|ng |rom gm@||@com  Tue Apr  2 13:20:06 2024
From: mo|||eebrook@ @end|ng |rom gm@||@com (Mollie Brooks)
Date: Tue, 2 Apr 2024 13:20:06 +0200
Subject: [R-sig-ME] RTMB course at International Statistical Ecology
 Conference - Sunday, 14 July
Message-ID: <BB6E9162-C866-4791-875A-4ADB095C6E1C@gmail.com>

Dear R-sig-mixed list,

I would like your help letting people know about a course being offered in person at ISEC in Swansea, Wales on the 14th of July. The workshop fee is 50 GBP. Registration and more information is here https://statisticalecology.org/?page_id=58


RTMB: Automatic differentiation in R

Date: Sunday 14 July

Length: Full day

Instructors: Anders Nielsen (DTU ? Danish Technical University, Denmark); Ben Bolker (University of McMaster, Canada)

Overview: This workshop will introduce participants to RTMB. RTMB is the latest iteration of TMB (Template Model Builder), a widely used tool for flexible statistical modeling. RTMB?s novel feature is that models are specified in plain R code (rather than C++ code or another special modelling language). Once the model is specified, it evaluates function values and derivatives as efficiently as if the model were written in C++. Calculations in RTMB are supported by automatic differentiation, sparse matrices, delta-method calculations, and efficient Laplace approximation, which makes RTMB ideal for maximum likelihood inference in small and large models with and without random effects. Models specified in RTMB can also sampled with MCMC by linking them to Stan. In the course, examples and exercises will span non-linear regression, generalized linear models, random effects, state-space, and spatio-temporal models with flexible spatial mesh structure (as known from INLA).

cheers,
Mollie

From m|n@j@h@ng|r|984 @end|ng |rom gm@||@com  Sun Apr  7 13:53:27 2024
From: m|n@j@h@ng|r|984 @end|ng |rom gm@||@com (mina jahan)
Date: Sun, 7 Apr 2024 15:23:27 +0330
Subject: [R-sig-ME] Package lme4
Message-ID: <CAJt0zy-7Jc5TjR6kPGnPgGqEmEHhO7uswnDorxzKbsb3+s+eHQ@mail.gmail.com>

Hi,

I want to run linear mixed-effects models for analysis of the attached data
file but I was exposed with under error:


*Error in initializePtr() : function 'cholmod_factor_ldetA' not provided by
package 'Matrix'*

I attached the R code and data file.

How can I solve this error? Please guide me.


Best regards,

Mina Jahangiri

Ph.D. student of Biostatistics

From bbo|ker @end|ng |rom gm@||@com  Sun Apr  7 16:05:04 2024
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sun, 7 Apr 2024 10:05:04 -0400
Subject: [R-sig-ME] Package lme4
In-Reply-To: <CAJt0zy-7Jc5TjR6kPGnPgGqEmEHhO7uswnDorxzKbsb3+s+eHQ@mail.gmail.com>
References: <CAJt0zy-7Jc5TjR6kPGnPgGqEmEHhO7uswnDorxzKbsb3+s+eHQ@mail.gmail.com>
Message-ID: <b3915f59-7469-4dc5-ab7c-b65dc6f7d200@gmail.com>

   Did you google the error message ... ??

   The top hit for me is ...

https://stackoverflow.com/questions/77481539/error-in-initializeptr-function-cholmod-factor-ldeta-not-provided-by-pack

   The short answer is that you should update packages, making sure that 
the version of lme4 has been compiled with the same version of Matrix 
that you have installed on your system.

   If you are installing from a repository that has binaries that are 
up-to-date, just making sure you have the latest versions of Matrix and 
lme4 should be sufficient.  Otherwise follow the instructions at 
https://stackoverflow.com/a/77532685/190277

   Ben Bolker

On 2024-04-07 7:53 a.m., mina jahan wrote:
> Hi,
> 
> I want to run linear mixed-effects models for analysis of the attached data
> file but I was exposed with under error:
> 
> 
> *Error in initializePtr() : function 'cholmod_factor_ldetA' not provided by
> package 'Matrix'*
> 
> I attached the R code and data file.
> 
> How can I solve this error? Please guide me.
> 
> 
> Best regards,
> 
> Mina Jahangiri
> 
> Ph.D. student of Biostatistics
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From Ro@@@Boy|@n @end|ng |rom uc@|@edu  Thu Apr 11 03:04:54 2024
From: Ro@@@Boy|@n @end|ng |rom uc@|@edu (Boylan, Ross)
Date: Thu, 11 Apr 2024 01:04:54 +0000
Subject: [R-sig-ME] error: 'Index' is not a member...
Message-ID: <BY3PR05MB81164764A517E0082DC277B987052@BY3PR05MB8116.namprd05.prod.outlook.com>

When trying to build lme4 from source (git master) I get a bunch of compiler errors, which seem to result from

lme4CholmodDecomposition.h:58:39: error: 'Index' is not a member of 'lme4::lme4CholmodDecomposition<Eigen::SparseMatrix<double, 0, int> >::Base' {aka 'Eigen::CholmodDecomposition
<Eigen::SparseMatrix<double, 0, int>, 1>'}
      58 |             eigen_assert((Base::Index)(factor()->n) == other.rows());
         |                          ~~~~~~~~~~~~~^~~~~~~~~~~~~

Discussion of somewhat similar problems focuses on changes to Matrix, specifically at 1.6-2.  But I'm using 1.6-5 with a fresh install of R 4.3.3 and recreation of the libraries for that version (i.e., I didn't copy any stuff from the old libraries).

Any ideas?

Really, my interest is in following some of the R code in the debugger, and this only arose on the way to that goal.

Environment
Windows Server 2019 v1809
R 4.3.3 running inside VS Code, with the R extension.
Using devtools::load_all()
System has RTools4.3 installed (though not recently refreshed), RStudio 2023.12.1 Build 402, Visual Studio 2019, and Cygwin.  I believe the first is the source of the build tools used, but I mention the others because it's possible they are being used or are interfering.

Fuller Transcript:
> load_all()
i Loading lme4
i Re-compiling lme4 (debug build)
-- R CMD INSTALL --------------------------------------------------------------------------------------------------------------------------------------------------------------------
-  installing *source* package 'lme4' ... (456ms)
   ** using staged installation
   ** libs
   using C++ compiler: 'G__~1.EXE (GCC) 12.3.0'
   g++ -std=gnu++17  -I"C:/PROGRA~1/R/R-43~1.3/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE -I'C:/Program Files/R/R-4.3.3/library/Rcpp/include' -I'C:/Program Files/R/R-4.3.
3/library/RcppEigen/include' -I'C:/Program Files/R/R-4.3.3/library/Matrix/include'   -I"C:/rtools43/x86_64-w64-mingw32.static.posix/include"     -O2 -Wall -gdwarf-2 -mfpmath=sse -ms
se2 -mstackrealign  -UNDEBUG -Wall -pedantic -g -O0 -fdiagnostics-color=always -c external.cpp -o external.o
   g++ -std=gnu++17  -I"C:/PROGRA~1/R/R-43~1.3/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE -I'C:/Program Files/R/R-4.3.3/library/Rcpp/include' -I'C:/Program Files/R/R-4.3.
3/library/RcppEigen/include' -I'C:/Program Files/R/R-4.3.3/library/Matrix/include'   -I"C:/rtools43/x86_64-w64-mingw32.static.posix/include"     -O2 -Wall -gdwarf-2 -mfpmath=sse -ms
se2 -mstackrealign  -UNDEBUG -Wall -pedantic -g -O0 -fdiagnostics-color=always -c glmFamily.cpp -o glmFamily.o
   g++ -std=gnu++17  -I"C:/PROGRA~1/R/R-43~1.3/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE -I'C:/Program Files/R/R-4.3.3/library/Rcpp/include' -I'C:/Program Files/R/R-4.3.
3/library/RcppEigen/include' -I'C:/Program Files/R/R-4.3.3/library/Matrix/include'   -I"C:/rtools43/x86_64-w64-mingw32.static.posix/include"     -O2 -Wall -gdwarf-2 -mfpmath=sse -ms
se2 -mstackrealign  -UNDEBUG -Wall -pedantic -g -O0 -fdiagnostics-color=always -c mcmcsamp.cpp -o mcmcsamp.o
   g++ -std=gnu++17  -I"C:/PROGRA~1/R/R-43~1.3/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE -I'C:/Program Files/R/R-4.3.3/library/Rcpp/include' -I'C:/Program Files/R/R-4.3.
3/library/RcppEigen/include' -I'C:/Program Files/R/R-4.3.3/library/Matrix/include'   -I"C:/rtools43/x86_64-w64-mingw32.static.posix/include"     -O2 -Wall -gdwarf-2 -mfpmath=sse -ms
se2 -mstackrealign  -UNDEBUG -Wall -pedantic -g -O0 -fdiagnostics-color=always -c optimizer.cpp -o optimizer.o
   g++ -std=gnu++17  -I"C:/PROGRA~1/R/R-43~1.3/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE -I'C:/Program Files/R/R-4.3.3/library/Rcpp/include' -I'C:/Program Files/R/R-4.3.
3/library/RcppEigen/include' -I'C:/Program Files/R/R-4.3.3/library/Matrix/include'   -I"C:/rtools43/x86_64-w64-mingw32.static.posix/include"     -O2 -Wall -gdwarf-2 -mfpmath=sse -ms
se2 -mstackrealign  -UNDEBUG -Wall -pedantic -g -O0 -fdiagnostics-color=always -c predModule.cpp -o predModule.o
   In file included from c:\rtools43\x86_64-w64-mingw32.static.posix\lib\gcc\x86_64-w64-mingw32.static.posix\12.3.0\include\c++\cassert:44,
                    from C:/Program Files/R/R-4.3.3/library/RcppEigen/include/Eigen/Core:84,
                    from C:/Program Files/R/R-4.3.3/library/RcppEigen/include/Eigen/Dense:1,
                    from C:/Program Files/R/R-4.3.3/library/RcppEigen/include/RcppEigenForward.h:28,
                    from C:/Program Files/R/R-4.3.3/library/RcppEigen/include/RcppEigen.h:25,
                    from predModule.h:12,
                    from predModule.cpp:8:
   lme4CholmodDecomposition.h: In instantiation of 'void lme4::lme4CholmodDecomposition<_MatrixType, _UpLo>::solveInPlace(const Eigen::MatrixBase<OtherDerived>&, int) const [with Ot
herDerived = Eigen::Matrix<double, -1, -1>; _MatrixType = Eigen::SparseMatrix<double, 0, int>; int _UpLo = 1]':
   predModule.cpp:123:37:   required from here
   lme4CholmodDecomposition.h:58:39: error: 'Index' is not a member of 'lme4::lme4CholmodDecomposition<Eigen::SparseMatrix<double, 0, int> >::Base' {aka 'Eigen::CholmodDecomposition
<Eigen::SparseMatrix<double, 0, int>, 1>'}
      58 |             eigen_assert((Base::Index)(factor()->n) == other.rows());
         |                          ~~~~~~~~~~~~~^~~~~~~~~~~~~
   C:/Program Files/R/R-4.3.3/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:1037:25: note: in expansion of macro 'eigen_plain_assert'
    1037 | #define eigen_assert(x) eigen_plain_assert(x)
         |                         ^~~~~~~~~~~~~~~~~~
         ^~~~~~~~~~~~

# That exact pair of errors, at the same lines, repeats ~5 times

   make: *** [C:/PROGRA~1/R/R-43~1.3/etc/x64/Makeconf:272: predModule.o] Error 1
   ERROR: compilation failed for package 'lme4'
-  removing 'C:/Users/rdboylan/AppData/Local/Temp/3/RtmpmQrCjG/devtools_install_4fac7c5146bb/lme4'
Error in `(function (command = NULL, args = character(), error_on_status = TRUE, ...`:
! System command 'Rcmd.exe' failed
---
Exit status: 1

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Thu Apr 11 17:27:38 2024
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 11 Apr 2024 11:27:38 -0400
Subject: [R-sig-ME] error: 'Index' is not a member...
In-Reply-To: <BY3PR05MB81164764A517E0082DC277B987052@BY3PR05MB8116.namprd05.prod.outlook.com>
References: <BY3PR05MB81164764A517E0082DC277B987052@BY3PR05MB8116.namprd05.prod.outlook.com>
Message-ID: <b06f4d6c-d63c-4be5-8b5e-021e17763e0e@gmail.com>


   Hmm.

   Just to rule out some things, do you get the same problems if you 
install via R CMD INSTALL <lme4 tarball> from a terminal/command shell?

   (This might be more appropriate for the lme4 issues list.)

   Do you want to look at the R code in the devel version specifically? 
It's not clear to me that you need to install from source in order to 
debug()/trace through R code -- maybe I'm missing something?

   Ben Bolker

On 2024-04-10 9:04 p.m., Boylan, Ross via R-sig-mixed-models wrote:
> When trying to build lme4 from source (git master) I get a bunch of compiler errors, which seem to result from
> 
> lme4CholmodDecomposition.h:58:39: error: 'Index' is not a member of 'lme4::lme4CholmodDecomposition<Eigen::SparseMatrix<double, 0, int> >::Base' {aka 'Eigen::CholmodDecomposition
> <Eigen::SparseMatrix<double, 0, int>, 1>'}
>        58 |             eigen_assert((Base::Index)(factor()->n) == other.rows());
>           |                          ~~~~~~~~~~~~~^~~~~~~~~~~~~
> 
> Discussion of somewhat similar problems focuses on changes to Matrix, specifically at 1.6-2.  But I'm using 1.6-5 with a fresh install of R 4.3.3 and recreation of the libraries for that version (i.e., I didn't copy any stuff from the old libraries).
> 
> Any ideas?
> 
> Really, my interest is in following some of the R code in the debugger, and this only arose on the way to that goal.
> 
> Environment
> Windows Server 2019 v1809
> R 4.3.3 running inside VS Code, with the R extension.
> Using devtools::load_all()
> System has RTools4.3 installed (though not recently refreshed), RStudio 2023.12.1 Build 402, Visual Studio 2019, and Cygwin.  I believe the first is the source of the build tools used, but I mention the others because it's possible they are being used or are interfering.
> 
> Fuller Transcript:
>> load_all()
> i Loading lme4
> i Re-compiling lme4 (debug build)
> -- R CMD INSTALL --------------------------------------------------------------------------------------------------------------------------------------------------------------------
> -  installing *source* package 'lme4' ... (456ms)
>     ** using staged installation
>     ** libs
>     using C++ compiler: 'G__~1.EXE (GCC) 12.3.0'
>     g++ -std=gnu++17  -I"C:/PROGRA~1/R/R-43~1.3/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE -I'C:/Program Files/R/R-4.3.3/library/Rcpp/include' -I'C:/Program Files/R/R-4.3.
> 3/library/RcppEigen/include' -I'C:/Program Files/R/R-4.3.3/library/Matrix/include'   -I"C:/rtools43/x86_64-w64-mingw32.static.posix/include"     -O2 -Wall -gdwarf-2 -mfpmath=sse -ms
> se2 -mstackrealign  -UNDEBUG -Wall -pedantic -g -O0 -fdiagnostics-color=always -c external.cpp -o external.o
>     g++ -std=gnu++17  -I"C:/PROGRA~1/R/R-43~1.3/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE -I'C:/Program Files/R/R-4.3.3/library/Rcpp/include' -I'C:/Program Files/R/R-4.3.
> 3/library/RcppEigen/include' -I'C:/Program Files/R/R-4.3.3/library/Matrix/include'   -I"C:/rtools43/x86_64-w64-mingw32.static.posix/include"     -O2 -Wall -gdwarf-2 -mfpmath=sse -ms
> se2 -mstackrealign  -UNDEBUG -Wall -pedantic -g -O0 -fdiagnostics-color=always -c glmFamily.cpp -o glmFamily.o
>     g++ -std=gnu++17  -I"C:/PROGRA~1/R/R-43~1.3/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE -I'C:/Program Files/R/R-4.3.3/library/Rcpp/include' -I'C:/Program Files/R/R-4.3.
> 3/library/RcppEigen/include' -I'C:/Program Files/R/R-4.3.3/library/Matrix/include'   -I"C:/rtools43/x86_64-w64-mingw32.static.posix/include"     -O2 -Wall -gdwarf-2 -mfpmath=sse -ms
> se2 -mstackrealign  -UNDEBUG -Wall -pedantic -g -O0 -fdiagnostics-color=always -c mcmcsamp.cpp -o mcmcsamp.o
>     g++ -std=gnu++17  -I"C:/PROGRA~1/R/R-43~1.3/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE -I'C:/Program Files/R/R-4.3.3/library/Rcpp/include' -I'C:/Program Files/R/R-4.3.
> 3/library/RcppEigen/include' -I'C:/Program Files/R/R-4.3.3/library/Matrix/include'   -I"C:/rtools43/x86_64-w64-mingw32.static.posix/include"     -O2 -Wall -gdwarf-2 -mfpmath=sse -ms
> se2 -mstackrealign  -UNDEBUG -Wall -pedantic -g -O0 -fdiagnostics-color=always -c optimizer.cpp -o optimizer.o
>     g++ -std=gnu++17  -I"C:/PROGRA~1/R/R-43~1.3/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE -I'C:/Program Files/R/R-4.3.3/library/Rcpp/include' -I'C:/Program Files/R/R-4.3.
> 3/library/RcppEigen/include' -I'C:/Program Files/R/R-4.3.3/library/Matrix/include'   -I"C:/rtools43/x86_64-w64-mingw32.static.posix/include"     -O2 -Wall -gdwarf-2 -mfpmath=sse -ms
> se2 -mstackrealign  -UNDEBUG -Wall -pedantic -g -O0 -fdiagnostics-color=always -c predModule.cpp -o predModule.o
>     In file included from c:\rtools43\x86_64-w64-mingw32.static.posix\lib\gcc\x86_64-w64-mingw32.static.posix\12.3.0\include\c++\cassert:44,
>                      from C:/Program Files/R/R-4.3.3/library/RcppEigen/include/Eigen/Core:84,
>                      from C:/Program Files/R/R-4.3.3/library/RcppEigen/include/Eigen/Dense:1,
>                      from C:/Program Files/R/R-4.3.3/library/RcppEigen/include/RcppEigenForward.h:28,
>                      from C:/Program Files/R/R-4.3.3/library/RcppEigen/include/RcppEigen.h:25,
>                      from predModule.h:12,
>                      from predModule.cpp:8:
>     lme4CholmodDecomposition.h: In instantiation of 'void lme4::lme4CholmodDecomposition<_MatrixType, _UpLo>::solveInPlace(const Eigen::MatrixBase<OtherDerived>&, int) const [with Ot
> herDerived = Eigen::Matrix<double, -1, -1>; _MatrixType = Eigen::SparseMatrix<double, 0, int>; int _UpLo = 1]':
>     predModule.cpp:123:37:   required from here
>     lme4CholmodDecomposition.h:58:39: error: 'Index' is not a member of 'lme4::lme4CholmodDecomposition<Eigen::SparseMatrix<double, 0, int> >::Base' {aka 'Eigen::CholmodDecomposition
> <Eigen::SparseMatrix<double, 0, int>, 1>'}
>        58 |             eigen_assert((Base::Index)(factor()->n) == other.rows());
>           |                          ~~~~~~~~~~~~~^~~~~~~~~~~~~
>     C:/Program Files/R/R-4.3.3/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:1037:25: note: in expansion of macro 'eigen_plain_assert'
>      1037 | #define eigen_assert(x) eigen_plain_assert(x)
>           |                         ^~~~~~~~~~~~~~~~~~
>           ^~~~~~~~~~~~
> 
> # That exact pair of errors, at the same lines, repeats ~5 times
> 
>     make: *** [C:/PROGRA~1/R/R-43~1.3/etc/x64/Makeconf:272: predModule.o] Error 1
>     ERROR: compilation failed for package 'lme4'
> -  removing 'C:/Users/rdboylan/AppData/Local/Temp/3/RtmpmQrCjG/devtools_install_4fac7c5146bb/lme4'
> Error in `(function (command = NULL, args = character(), error_on_status = TRUE, ...`:
> ! System command 'Rcmd.exe' failed
> ---
> Exit status: 1
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From Ro@@@Boy|@n @end|ng |rom uc@|@edu  Fri Apr 12 01:55:45 2024
From: Ro@@@Boy|@n @end|ng |rom uc@|@edu (Boylan, Ross)
Date: Thu, 11 Apr 2024 23:55:45 +0000
Subject: [R-sig-ME] error: 'Index' is not a member...
In-Reply-To: <b06f4d6c-d63c-4be5-8b5e-021e17763e0e@gmail.com>
References: <BY3PR05MB81164764A517E0082DC277B987052@BY3PR05MB8116.namprd05.prod.outlook.com>
 <b06f4d6c-d63c-4be5-8b5e-021e17763e0e@gmail.com>
Message-ID: <BY3PR05MB8116A4C303926A0B16B78F9D87052@BY3PR05MB8116.namprd05.prod.outlook.com>

Ben Bolker wrote
  > Just to rule out some things, do you get the same problems if you install via R CMD INSTALL <lme4 tarball> from a terminal/command shell?

R CMD INSTALL seems to work fine; transcript below.  However, I have installed the lme4 binary in between my first try 
and this attempt, and my original method also seems fine.
Back in the environment of my original problem and repeating, i.e., executing load_all(), does not give an error or appear to do much.
The only output is "Loading required package: Matrix".

Another oddity with the second try is that even though I specified an alternate library to install to, it seems to have picked up
precisely where it failed before.  There's no mention of the first files built.  For my "tarball" I just used the existing source directory, 
and it does have the binaries from previous attempts.  So I guess make just continued.

  > (This might be more appropriate for the lme4 issues list.)

I was going by the README.md, under Where to get help.

 > Do you want to look at the R code in the devel version specifically? 
 > It's not clear to me that you need to install from source in order to debug()/trace through R code -- maybe I'm missing something?
No, I'm happy to look at release code.   It's more likely I'm missing something.  I wanted to be able to set breakpoints and follow through
 with the code, and figured that wouldn't work too well with just a binary package install.  I think even from that I could get at least some
decompiled code, but I was hoping  for more.

Transcript
=========

The total compilation from R CMD in the terminal is
PS C:\Users\rdboylan\Documents> & $R CMD INSTALL -l tossme lme4
* installing *source* package 'lme4' ...
** using staged installation
** libs
using C++ compiler: 'G__~1.EXE (GCC) 12.3.0'
g++ -std=gnu++17  -I"C:/PROGRA~1/R/R-43~1.3/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE -I'C:/Program Files/R/R-4.3.3/library/Rcpp/include' -I'C:/Program Files/R/R-4.3.3/library/RcppEigen/include' -I'C:/Program Files/R/R-4.3.3/library/Matrix/include'   -I"C:/rtools43/x86_64-w64-mingw32.static.posix/include"     -O2 -Wall  -mfpmath=sse -msse2 -mstackrealign  -c predModule.cpp -o predModule.o
g++ -std=gnu++17  -I"C:/PROGRA~1/R/R-43~1.3/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE -I'C:/Program Files/R/R-4.3.3/library/Rcpp/include' -I'C:/Program Files/R/R-4.3.3/library/RcppEigen/include' -I'C:/Program Files/R/R-4.3.3/library/Matrix/include'   -I"C:/rtools43/x86_64-w64-mingw32.static.posix/include"     -O2 -Wall  -mfpmath=sse -msse2 -mstackrealign  -c respModule.cpp -o respModule.o
g++ -std=gnu++17 -shared -s -static-libgcc -o lme4.dll tmp.def external.o glmFamily.o mcmcsamp.o optimizer.o predModule.o respModule.o -LC:/rtools43/x86_64-w64-mingw32.static.posix/lib/x64 -LC:/rtools43/x86_64-w64-mingw32.static.posix/lib -LC:/PROGRA~1/R/R-43~1.3/bin/x64 -lR
installing to C:/Users/rdboylan/Documents/tossme/00LOCK-lme4/00new/lme4/libs/x64
 


From @r|n|dh|@j@y@kum@r @end|ng |rom @tonybrook@edu  Sat May  4 22:08:48 2024
From: @r|n|dh|@j@y@kum@r @end|ng |rom @tonybrook@edu (Srinidhi Jayakumar)
Date: Sat, 4 May 2024 16:08:48 -0400
Subject: [R-sig-ME] Errorin lmer for time varying predictor.
Message-ID: <CAMvZaurgva9jGa2UM4F_aiPaPPmQrwjKzeJpV_xMMmvmrifGJw@mail.gmail.com>

Hi,

I am running a multilevel growth curve model to examine predictors of
social anhedonia (SA) trajectory through ages 12, 15 and 18. SA is a
continuous numeric variable. The age variable (Index1) has been coded as 0
for age  12, 1 for age 15 and 2 for age 18. I am currently using a time
varying predictor, stress (LSI), which was measured at ages 12, 15 and 18,
to examine whether trajectory/variation in LSI predicts difference in SA
trajectory. LSI is a continuous numeric variable. The data has been
converted to long format with SA in 1 column, LSI in the other, ID in
another and age in another column. I used the code below to run my model
using lmer. However, I get the following error. Please let me know how I
can solve this error. Please note that I have 50% missing data in SA at age
12, which I am handling using the REML method.
modelLSI_maineff_RE <- lmer(SA ~ Index1* LSI+ (1 + Index1+LSI |ID),
                            data = LSIDATA, control = lmerControl(optimizer
="bobyqa"), REML=TRUE)
summary(modelLSI_maineff_RE)

Error: number of observations (=1080) <= number of random effects
(=1479) for term (1 + Index1 + LSI | ID); the random-effects
parameters and the residual variance (or scale parameter) are probably
unidentifiable


 I did test the within-person variance for the LSI variable and
the within-person variance is significant from the Greenhouse-Geisser,
Hyunh-Feidt tests.

Also, for some reason, the model runs if I specify the random effects as
either of these 2 models. However, I want to know whether variation in LSI
predicts variation in SA trajectory between and within people. Hence, I
need both age and LSI in the random effects.
  modelLSI1 <- lmer(SA ~ Index1* LSI+ (1 + Index1 |ID),
                            data = LSIDATA, control = lmerControl(optimizer
="bobyqa"), REML=TRUE)
*OR*
  modelLSI2 <- lmer(SA ~ Index1* LSI+ (1 +LSI |ID),
                            data = LSIDATA, control = lmerControl(optimizer
="bobyqa"), REML=TRUE)

Please let me know how I can solve my error and examine the random effect
of LSI.

Thank you,
Srinidhi

	[[alternative HTML version deleted]]


From @r|n|dh|@j@y@kum@r @end|ng |rom @tonybrook@edu  Mon May  6 01:58:35 2024
From: @r|n|dh|@j@y@kum@r @end|ng |rom @tonybrook@edu (Srinidhi Jayakumar)
Date: Sun, 5 May 2024 19:58:35 -0400
Subject: [R-sig-ME] lmer error: number of observations <= number of random
 effects
Message-ID: <CAMvZauqY=naWQtSgfp+JtX73vB5+Sm3pO=iv6P6ujNGQHcg5WQ@mail.gmail.com>

I am running a multilevel growth curve model to examine predictors of
social anhedonia (SA) trajectory through ages 12, 15 and 18. SA is a
continuous numeric variable. The age variable (Index1) has been coded as 0
for age 12, 1 for age 15 and 2 for age 18. I am currently using a time
varying predictor, stress (LSI), which was measured at ages 12, 15 and 18,
to examine whether trajectory/variation in LSI predicts difference in SA
trajectory. LSI is a continuous numeric variable and was grand-mean
centered before using in the models. The data has been converted to long
format with SA in 1 column, LSI in the other, ID in another, and age in
another column. I used the code below to run my model using lmer. However,
I get the following error. Please let me know how I can solve this error.
Please note that I have 50% missing data in SA at age 12.
modelLSI_maineff_RE <- lmer(SA ~ Index1* LSI+ (1 + Index1+LSI |ID), data =
LSIDATA, control = lmerControl(optimizer ="bobyqa"), REML=TRUE)
summary(modelLSI_maineff_RE)
Error: number of observations (=1080) <= number of random effects (=1479)
for term (1 + Index1 + LSI | ID); the random-effects parameters and the
residual variance (or scale parameter) are probably unidentifiable

I did test the within-person variance for the LSI variable and the
within-person variance is significant from the Greenhouse-Geisser,
Hyunh-Feidt tests.

I also tried control = lmerControl(check.nobs.vs.nRE = "ignore") which gave
me the following output. modelLSI_maineff_RE <- lmer(SA ~ Index1* LSI+ (1 +
Index1+LSI |ID), data = LSIDATA, control = lmerControl(check.nobs.vs.nRE =
"ignore", optimizer ="bobyqa", check.conv.singular = .makeCC(action =
"ignore", tol = 1e-4)), REML=TRUE)

summary(modelLSI_maineff_RE)
Linear mixed model fit by REML. t-tests use Satterthwaite's method
['lmerModLmerTest']
Formula: SA ~ Index1 * LSI + (1 + Index1 + LSI | ID)
Data: LSIDATA
Control: lmerControl(check.nobs.vs.nRE = "ignore", optimizer = "bobyqa",
check.conv.singular = .makeCC(action = "ignore", tol = 1e-04))

REML criterion at convergence: 7299.6

Scaled residuals:
Min 1Q Median 3Q Max
-2.7289 -0.4832 -0.1449 0.3604 4.5715

Random effects:
Groups Name Variance Std.Dev. Corr
ID (Intercept) 30.2919 5.5038
Index1 2.4765 1.5737 -0.15
LSI 0.1669 0.4085 -0.23 0.70
Residual 24.1793 4.9172
Number of obs: 1080, groups: ID, 493

Fixed effects:
Estimate Std. Error df t value Pr(>|t|)
(Intercept) 24.68016 0.39722 313.43436 62.133 < 2e-16 ***
Index1 0.98495 0.23626 362.75018 4.169 3.83e-05 ***
LSI -0.05197 0.06226 273.85575 -0.835 0.4046
Index1:LSI 0.09797 0.04506 426.01185 2.174 0.0302 *
Signif. codes: 0 ?? 0.001 ?? 0.01 ?? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
(Intr) Index1 LSI
Index1 -0.645
LSI -0.032 0.057
Index1:LSI 0.015 0.037 -0.695

I am a little vary of the output still as the error states that I have
equal observations as the number of random effects (i.e., 3 observations
per ID and 3 random effects). Hence, I am wondering whether I can simplify
the model as either of the below models and choose the one with the
best-fit statistics:

 modelLSI2 <- lmer(SA ~ Index1* LSI+ (1 |ID)+ (Index1+LSI -1|ID),data =
LSIDATA, control = lmerControl(optimizer ="bobyqa"), REML=TRUE) *OR*

modelLSI3 <- lmer(SA ~ Index1* LSI+ (1+LSI |ID),data = LSIDATA, control =
lmerControl(optimizer ="bobyqa"), REML=TRUE) [image: example of dataset]
<https://i.sstatic.net/JcRKS2C9.png>

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Mon May  6 08:45:57 2024
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Mon, 6 May 2024 08:45:57 +0200
Subject: [R-sig-ME] 
 lmer error: number of observations <= number of random effects
In-Reply-To: <CAMvZauqY=naWQtSgfp+JtX73vB5+Sm3pO=iv6P6ujNGQHcg5WQ@mail.gmail.com>
References: <CAMvZauqY=naWQtSgfp+JtX73vB5+Sm3pO=iv6P6ujNGQHcg5WQ@mail.gmail.com>
Message-ID: <CAJuCY5ysmodQ=Jt8UGSuimNyz66WS9MAxdxWv4fttrM6O1Tw5A@mail.gmail.com>

Dear Srinidhi,

You are trying to fit 1 random intercept and 2 random slopes per
individual, while you have at most 3 observations per individual. You
simply don't have enough data to fit the random slopes. Reduce the random
part to (1|ID).

Best regards,

Thierry

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
*Postadres:* Koning Albert II-laan 15 bus 186, 1210 Brussel
*Poststukken die naar dit adres worden gestuurd, worden ingescand en
digitaal aan de geadresseerde bezorgd. Zo kan de Vlaamse overheid haar
dossiers volledig digitaal behandelen. Poststukken met de vermelding
?vertrouwelijk? worden niet ingescand, maar ongeopend aan de geadresseerde
bezorgd.*
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op ma 6 mei 2024 om 01:59 schreef Srinidhi Jayakumar via R-sig-mixed-models
<r-sig-mixed-models at r-project.org>:

> I am running a multilevel growth curve model to examine predictors of
> social anhedonia (SA) trajectory through ages 12, 15 and 18. SA is a
> continuous numeric variable. The age variable (Index1) has been coded as 0
> for age 12, 1 for age 15 and 2 for age 18. I am currently using a time
> varying predictor, stress (LSI), which was measured at ages 12, 15 and 18,
> to examine whether trajectory/variation in LSI predicts difference in SA
> trajectory. LSI is a continuous numeric variable and was grand-mean
> centered before using in the models. The data has been converted to long
> format with SA in 1 column, LSI in the other, ID in another, and age in
> another column. I used the code below to run my model using lmer. However,
> I get the following error. Please let me know how I can solve this error.
> Please note that I have 50% missing data in SA at age 12.
> modelLSI_maineff_RE <- lmer(SA ~ Index1* LSI+ (1 + Index1+LSI |ID), data =
> LSIDATA, control = lmerControl(optimizer ="bobyqa"), REML=TRUE)
> summary(modelLSI_maineff_RE)
> Error: number of observations (=1080) <= number of random effects (=1479)
> for term (1 + Index1 + LSI | ID); the random-effects parameters and the
> residual variance (or scale parameter) are probably unidentifiable
>
> I did test the within-person variance for the LSI variable and the
> within-person variance is significant from the Greenhouse-Geisser,
> Hyunh-Feidt tests.
>
> I also tried control = lmerControl(check.nobs.vs.nRE = "ignore") which gave
> me the following output. modelLSI_maineff_RE <- lmer(SA ~ Index1* LSI+ (1 +
> Index1+LSI |ID), data = LSIDATA, control = lmerControl(check.nobs.vs.nRE =
> "ignore", optimizer ="bobyqa", check.conv.singular = .makeCC(action =
> "ignore", tol = 1e-4)), REML=TRUE)
>
> summary(modelLSI_maineff_RE)
> Linear mixed model fit by REML. t-tests use Satterthwaite's method
> ['lmerModLmerTest']
> Formula: SA ~ Index1 * LSI + (1 + Index1 + LSI | ID)
> Data: LSIDATA
> Control: lmerControl(check.nobs.vs.nRE = "ignore", optimizer = "bobyqa",
> check.conv.singular = .makeCC(action = "ignore", tol = 1e-04))
>
> REML criterion at convergence: 7299.6
>
> Scaled residuals:
> Min 1Q Median 3Q Max
> -2.7289 -0.4832 -0.1449 0.3604 4.5715
>
> Random effects:
> Groups Name Variance Std.Dev. Corr
> ID (Intercept) 30.2919 5.5038
> Index1 2.4765 1.5737 -0.15
> LSI 0.1669 0.4085 -0.23 0.70
> Residual 24.1793 4.9172
> Number of obs: 1080, groups: ID, 493
>
> Fixed effects:
> Estimate Std. Error df t value Pr(>|t|)
> (Intercept) 24.68016 0.39722 313.43436 62.133 < 2e-16 ***
> Index1 0.98495 0.23626 362.75018 4.169 3.83e-05 ***
> LSI -0.05197 0.06226 273.85575 -0.835 0.4046
> Index1:LSI 0.09797 0.04506 426.01185 2.174 0.0302 *
> Signif. codes: 0 ?? 0.001 ?? 0.01 ?? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
> (Intr) Index1 LSI
> Index1 -0.645
> LSI -0.032 0.057
> Index1:LSI 0.015 0.037 -0.695
>
> I am a little vary of the output still as the error states that I have
> equal observations as the number of random effects (i.e., 3 observations
> per ID and 3 random effects). Hence, I am wondering whether I can simplify
> the model as either of the below models and choose the one with the
> best-fit statistics:
>
>  modelLSI2 <- lmer(SA ~ Index1* LSI+ (1 |ID)+ (Index1+LSI -1|ID),data =
> LSIDATA, control = lmerControl(optimizer ="bobyqa"), REML=TRUE) *OR*
>
> modelLSI3 <- lmer(SA ~ Index1* LSI+ (1+LSI |ID),data = LSIDATA, control =
> lmerControl(optimizer ="bobyqa"), REML=TRUE) [image: example of dataset]
> <https://i.sstatic.net/JcRKS2C9.png>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From tr@@h|@ket @end|ng |rom gm@||@com  Mon May  6 09:11:15 2024
From: tr@@h|@ket @end|ng |rom gm@||@com (TT FF)
Date: Mon, 6 May 2024 08:11:15 +0100
Subject: [R-sig-ME] 
 lmer error: number of observations <= number of random effects
In-Reply-To: <CAJuCY5ysmodQ=Jt8UGSuimNyz66WS9MAxdxWv4fttrM6O1Tw5A@mail.gmail.com>
References: <CAMvZauqY=naWQtSgfp+JtX73vB5+Sm3pO=iv6P6ujNGQHcg5WQ@mail.gmail.com>
 <CAJuCY5ysmodQ=Jt8UGSuimNyz66WS9MAxdxWv4fttrM6O1Tw5A@mail.gmail.com>
Message-ID: <CF887C5A-1262-4EEE-BA5D-D28899A84A50@gmail.com>

See if this paper may help If it helps reducing the model when you have few observations. the (1|ID) may increase the type 1 error.
https://journals.sagepub.com/doi/10.1177/25152459231214454 <https://journals.sagepub.com/doi/10.1177/25152459231214454>

Best

> On 6 May 2024, at 07:45, Thierry Onkelinx via R-sig-mixed-models <r-sig-mixed-models at r-project.org> wrote:
> 
> Dear Srinidhi,
> 
> You are trying to fit 1 random intercept and 2 random slopes per
> individual, while you have at most 3 observations per individual. You
> simply don't have enough data to fit the random slopes. Reduce the random
> part to (1|ID).
> 
> Best regards,
> 
> Thierry
> 
> ir. Thierry Onkelinx
> Statisticus / Statistician
> 
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> *Postadres:* Koning Albert II-laan 15 bus 186, 1210 Brussel
> *Poststukken die naar dit adres worden gestuurd, worden ingescand en
> digitaal aan de geadresseerde bezorgd. Zo kan de Vlaamse overheid haar
> dossiers volledig digitaal behandelen. Poststukken met de vermelding
> ?vertrouwelijk? worden niet ingescand, maar ongeopend aan de geadresseerde
> bezorgd.*
> www.inbo.be
> 
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
> 
> <https://www.inbo.be>
> 
> 
> Op ma 6 mei 2024 om 01:59 schreef Srinidhi Jayakumar via R-sig-mixed-models
> <r-sig-mixed-models at r-project.org>:
> 
>> I am running a multilevel growth curve model to examine predictors of
>> social anhedonia (SA) trajectory through ages 12, 15 and 18. SA is a
>> continuous numeric variable. The age variable (Index1) has been coded as 0
>> for age 12, 1 for age 15 and 2 for age 18. I am currently using a time
>> varying predictor, stress (LSI), which was measured at ages 12, 15 and 18,
>> to examine whether trajectory/variation in LSI predicts difference in SA
>> trajectory. LSI is a continuous numeric variable and was grand-mean
>> centered before using in the models. The data has been converted to long
>> format with SA in 1 column, LSI in the other, ID in another, and age in
>> another column. I used the code below to run my model using lmer. However,
>> I get the following error. Please let me know how I can solve this error.
>> Please note that I have 50% missing data in SA at age 12.
>> modelLSI_maineff_RE <- lmer(SA ~ Index1* LSI+ (1 + Index1+LSI |ID), data =
>> LSIDATA, control = lmerControl(optimizer ="bobyqa"), REML=TRUE)
>> summary(modelLSI_maineff_RE)
>> Error: number of observations (=1080) <= number of random effects (=1479)
>> for term (1 + Index1 + LSI | ID); the random-effects parameters and the
>> residual variance (or scale parameter) are probably unidentifiable
>> 
>> I did test the within-person variance for the LSI variable and the
>> within-person variance is significant from the Greenhouse-Geisser,
>> Hyunh-Feidt tests.
>> 
>> I also tried control = lmerControl(check.nobs.vs.nRE = "ignore") which gave
>> me the following output. modelLSI_maineff_RE <- lmer(SA ~ Index1* LSI+ (1 +
>> Index1+LSI |ID), data = LSIDATA, control = lmerControl(check.nobs.vs.nRE =
>> "ignore", optimizer ="bobyqa", check.conv.singular = .makeCC(action =
>> "ignore", tol = 1e-4)), REML=TRUE)
>> 
>> summary(modelLSI_maineff_RE)
>> Linear mixed model fit by REML. t-tests use Satterthwaite's method
>> ['lmerModLmerTest']
>> Formula: SA ~ Index1 * LSI + (1 + Index1 + LSI | ID)
>> Data: LSIDATA
>> Control: lmerControl(check.nobs.vs.nRE = "ignore", optimizer = "bobyqa",
>> check.conv.singular = .makeCC(action = "ignore", tol = 1e-04))
>> 
>> REML criterion at convergence: 7299.6
>> 
>> Scaled residuals:
>> Min 1Q Median 3Q Max
>> -2.7289 -0.4832 -0.1449 0.3604 4.5715
>> 
>> Random effects:
>> Groups Name Variance Std.Dev. Corr
>> ID (Intercept) 30.2919 5.5038
>> Index1 2.4765 1.5737 -0.15
>> LSI 0.1669 0.4085 -0.23 0.70
>> Residual 24.1793 4.9172
>> Number of obs: 1080, groups: ID, 493
>> 
>> Fixed effects:
>> Estimate Std. Error df t value Pr(>|t|)
>> (Intercept) 24.68016 0.39722 313.43436 62.133 < 2e-16 ***
>> Index1 0.98495 0.23626 362.75018 4.169 3.83e-05 ***
>> LSI -0.05197 0.06226 273.85575 -0.835 0.4046
>> Index1:LSI 0.09797 0.04506 426.01185 2.174 0.0302 *
>> Signif. codes: 0 ?? 0.001 ?? 0.01 ?? 0.05 ?.? 0.1 ? ? 1
>> 
>> Correlation of Fixed Effects:
>> (Intr) Index1 LSI
>> Index1 -0.645
>> LSI -0.032 0.057
>> Index1:LSI 0.015 0.037 -0.695
>> 
>> I am a little vary of the output still as the error states that I have
>> equal observations as the number of random effects (i.e., 3 observations
>> per ID and 3 random effects). Hence, I am wondering whether I can simplify
>> the model as either of the below models and choose the one with the
>> best-fit statistics:
>> 
>> modelLSI2 <- lmer(SA ~ Index1* LSI+ (1 |ID)+ (Index1+LSI -1|ID),data =
>> LSIDATA, control = lmerControl(optimizer ="bobyqa"), REML=TRUE) *OR*
>> 
>> modelLSI3 <- lmer(SA ~ Index1* LSI+ (1+LSI |ID),data = LSIDATA, control =
>> lmerControl(optimizer ="bobyqa"), REML=TRUE) [image: example of dataset]
>> <https://i.sstatic.net/JcRKS2C9.png>
>> 
>>        [[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From @r|n|dh|@j@y@kum@r @end|ng |rom @tonybrook@edu  Mon May  6 15:53:30 2024
From: @r|n|dh|@j@y@kum@r @end|ng |rom @tonybrook@edu (Srinidhi Jayakumar)
Date: Mon, 6 May 2024 09:53:30 -0400
Subject: [R-sig-ME] 
 lmer error: number of observations <= number of random effects
In-Reply-To: <CF887C5A-1262-4EEE-BA5D-D28899A84A50@gmail.com>
References: <CAMvZauqY=naWQtSgfp+JtX73vB5+Sm3pO=iv6P6ujNGQHcg5WQ@mail.gmail.com>
 <CAJuCY5ysmodQ=Jt8UGSuimNyz66WS9MAxdxWv4fttrM6O1Tw5A@mail.gmail.com>
 <CF887C5A-1262-4EEE-BA5D-D28899A84A50@gmail.com>
Message-ID: <CAMvZauoywbby6FWwKQcdbH10rRREEh6iSgYnQwaR=WMcAuhPjQ@mail.gmail.com>

Thank you very  much for your responses!

What if I reduce the model to
 modelLSI3 <- lmer(SA ~ Index1* LSI+ (1+LSI |ID),data = LSIDATA, control =
lmerControl(optimizer ="bobyqa"), REML=TRUE).
This would allow me to see the random effects of LSI and I can drop the
random effect of age (Index1) since I can see that in the unconditional
model [model0 <- lmer(SA ~ Index1+ (1+Index1|ID),data = LSIDATA, control =
lmerControl(optimizer ="bobyqa"), REML=TRUE)]. Would the modelLSI3 also
have a type 1 error?

Thank you,
Srinidhi




On Mon, 6 May 2024, 03:11 TT FF, <trashfaket at gmail.com> wrote:

> See if this paper may help If it helps reducing the model when you have
> few observations. the (1|ID) may increase the type 1 error.
> https://journals.sagepub.com/doi/10.1177/25152459231214454
>
> Best
>
> On 6 May 2024, at 07:45, Thierry Onkelinx via R-sig-mixed-models <
> r-sig-mixed-models at r-project.org> wrote:
>
> Dear Srinidhi,
>
> You are trying to fit 1 random intercept and 2 random slopes per
> individual, while you have at most 3 observations per individual. You
> simply don't have enough data to fit the random slopes. Reduce the random
> part to (1|ID).
>
> Best regards,
>
> Thierry
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> *Postadres:* Koning Albert II-laan 15 bus 186, 1210 Brussel
> *Poststukken die naar dit adres worden gestuurd, worden ingescand en
> digitaal aan de geadresseerde bezorgd. Zo kan de Vlaamse overheid haar
> dossiers volledig digitaal behandelen. Poststukken met de vermelding
> ?vertrouwelijk? worden niet ingescand, maar ongeopend aan de geadresseerde
> bezorgd.*
> www.inbo.be
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be>
>
>
> Op ma 6 mei 2024 om 01:59 schreef Srinidhi Jayakumar via R-sig-mixed-models
> <r-sig-mixed-models at r-project.org>:
>
> I am running a multilevel growth curve model to examine predictors of
> social anhedonia (SA) trajectory through ages 12, 15 and 18. SA is a
> continuous numeric variable. The age variable (Index1) has been coded as 0
> for age 12, 1 for age 15 and 2 for age 18. I am currently using a time
> varying predictor, stress (LSI), which was measured at ages 12, 15 and 18,
> to examine whether trajectory/variation in LSI predicts difference in SA
> trajectory. LSI is a continuous numeric variable and was grand-mean
> centered before using in the models. The data has been converted to long
> format with SA in 1 column, LSI in the other, ID in another, and age in
> another column. I used the code below to run my model using lmer. However,
> I get the following error. Please let me know how I can solve this error.
> Please note that I have 50% missing data in SA at age 12.
> modelLSI_maineff_RE <- lmer(SA ~ Index1* LSI+ (1 + Index1+LSI |ID), data =
> LSIDATA, control = lmerControl(optimizer ="bobyqa"), REML=TRUE)
> summary(modelLSI_maineff_RE)
> Error: number of observations (=1080) <= number of random effects (=1479)
> for term (1 + Index1 + LSI | ID); the random-effects parameters and the
> residual variance (or scale parameter) are probably unidentifiable
>
> I did test the within-person variance for the LSI variable and the
> within-person variance is significant from the Greenhouse-Geisser,
> Hyunh-Feidt tests.
>
> I also tried control = lmerControl(check.nobs.vs.nRE = "ignore") which gave
> me the following output. modelLSI_maineff_RE <- lmer(SA ~ Index1* LSI+ (1 +
> Index1+LSI |ID), data = LSIDATA, control = lmerControl(check.nobs.vs.nRE =
> "ignore", optimizer ="bobyqa", check.conv.singular = .makeCC(action =
> "ignore", tol = 1e-4)), REML=TRUE)
>
> summary(modelLSI_maineff_RE)
> Linear mixed model fit by REML. t-tests use Satterthwaite's method
> ['lmerModLmerTest']
> Formula: SA ~ Index1 * LSI + (1 + Index1 + LSI | ID)
> Data: LSIDATA
> Control: lmerControl(check.nobs.vs.nRE = "ignore", optimizer = "bobyqa",
> check.conv.singular = .makeCC(action = "ignore", tol = 1e-04))
>
> REML criterion at convergence: 7299.6
>
> Scaled residuals:
> Min 1Q Median 3Q Max
> -2.7289 -0.4832 -0.1449 0.3604 4.5715
>
> Random effects:
> Groups Name Variance Std.Dev. Corr
> ID (Intercept) 30.2919 5.5038
> Index1 2.4765 1.5737 -0.15
> LSI 0.1669 0.4085 -0.23 0.70
> Residual 24.1793 4.9172
> Number of obs: 1080, groups: ID, 493
>
> Fixed effects:
> Estimate Std. Error df t value Pr(>|t|)
> (Intercept) 24.68016 0.39722 313.43436 62.133 < 2e-16 ***
> Index1 0.98495 0.23626 362.75018 4.169 3.83e-05 ***
> LSI -0.05197 0.06226 273.85575 -0.835 0.4046
> Index1:LSI 0.09797 0.04506 426.01185 2.174 0.0302 *
> Signif. codes: 0 ?? 0.001 ?? 0.01 ?? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
> (Intr) Index1 LSI
> Index1 -0.645
> LSI -0.032 0.057
> Index1:LSI 0.015 0.037 -0.695
>
> I am a little vary of the output still as the error states that I have
> equal observations as the number of random effects (i.e., 3 observations
> per ID and 3 random effects). Hence, I am wondering whether I can simplify
> the model as either of the below models and choose the one with the
> best-fit statistics:
>
> modelLSI2 <- lmer(SA ~ Index1* LSI+ (1 |ID)+ (Index1+LSI -1|ID),data =
> LSIDATA, control = lmerControl(optimizer ="bobyqa"), REML=TRUE) *OR*
>
> modelLSI3 <- lmer(SA ~ Index1* LSI+ (1+LSI |ID),data = LSIDATA, control =
> lmerControl(optimizer ="bobyqa"), REML=TRUE) [image: example of dataset]
> <https://i.sstatic.net/JcRKS2C9.png>
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>

	[[alternative HTML version deleted]]


From m@rc_@chw@rtz @end|ng |rom me@com  Mon May  6 17:33:11 2024
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Mon, 06 May 2024 11:33:11 -0400
Subject: [R-sig-ME] 
 lmer error: number of observations <= number of random effects
In-Reply-To: <CAMvZauoywbby6FWwKQcdbH10rRREEh6iSgYnQwaR=WMcAuhPjQ@mail.gmail.com>
References: <CAMvZauqY=naWQtSgfp+JtX73vB5+Sm3pO=iv6P6ujNGQHcg5WQ@mail.gmail.com>
 <CAJuCY5ysmodQ=Jt8UGSuimNyz66WS9MAxdxWv4fttrM6O1Tw5A@mail.gmail.com>
 <CF887C5A-1262-4EEE-BA5D-D28899A84A50@gmail.com>
 <CAMvZauoywbby6FWwKQcdbH10rRREEh6iSgYnQwaR=WMcAuhPjQ@mail.gmail.com>
Message-ID: <1A9DDD0E-250B-427A-AB43-C79505AC4247@me.com>

Hi All,

As an FYI, there is no need for this thread to be cross-posted to three different lists: R-help, R-sig-mixed-models and R-devel.

I am removing R-Help and R-Devel from this reply and only replying to the authors and R-sig-mixed-models, which is the appropriate list for this thread.

For any future e-mails to this thread, please only reply to the author(s) and to R-sig-mixed-models, removing the other two lists.

Thank you,

Marc Schwartz
R-Devel Co-Admin


?-----Original Message-----
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org <mailto:r-sig-mixed-models-bounces at r-project.org>> on behalf of Srinidhi Jayakumar via R-sig-mixed-models <r-sig-mixed-models at r-project.org <mailto:r-sig-mixed-models at r-project.org>>
Reply-To: Srinidhi Jayakumar <srinidhi.jayakumar at stonybrook.edu <mailto:srinidhi.jayakumar at stonybrook.edu>>
Date: Monday, May 6, 2024 at 9:54 AM
To: TT FF <trashfaket at gmail.com <mailto:trashfaket at gmail.com>>
Cc: <r-help at r-project.org <mailto:r-help at r-project.org>>, <r-sig-mixed-models at r-project.org <mailto:r-sig-mixed-models at r-project.org>>, <r-devel at r-project.org <mailto:r-devel at r-project.org>>
Subject: Re: [R-sig-ME] lmer error: number of observations <= number of random effects


Thank you very much for your responses!


What if I reduce the model to
modelLSI3 <- lmer(SA ~ Index1* LSI+ (1+LSI |ID),data = LSIDATA, control =
lmerControl(optimizer ="bobyqa"), REML=TRUE).
This would allow me to see the random effects of LSI and I can drop the
random effect of age (Index1) since I can see that in the unconditional
model [model0 <- lmer(SA ~ Index1+ (1+Index1|ID),data = LSIDATA, control =
lmerControl(optimizer ="bobyqa"), REML=TRUE)]. Would the modelLSI3 also
have a type 1 error?


Thank you,
Srinidhi








On Mon, 6 May 2024, 03:11 TT FF, <trashfaket at gmail.com <mailto:trashfaket at gmail.com>> wrote:


> See if this paper may help If it helps reducing the model when you have
> few observations. the (1|ID) may increase the type 1 error.
> https://journals.sagepub.com/doi/10.1177/25152459231214454 <https://journals.sagepub.com/doi/10.1177/25152459231214454>
>
> Best
>
> On 6 May 2024, at 07:45, Thierry Onkelinx via R-sig-mixed-models <
> r-sig-mixed-models at r-project.org <mailto:r-sig-mixed-models at r-project.org>> wrote:
>
> Dear Srinidhi,
>
> You are trying to fit 1 random intercept and 2 random slopes per
> individual, while you have at most 3 observations per individual. You
> simply don't have enough data to fit the random slopes. Reduce the random
> part to (1|ID).
>
> Best regards,
>
> Thierry
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>
> Havenlaan 88 bus 73, 1000 Brussel
> *Postadres:* Koning Albert II-laan 15 bus 186, 1210 Brussel
> *Poststukken die naar dit adres worden gestuurd, worden ingescand en
> digitaal aan de geadresseerde bezorgd. Zo kan de Vlaamse overheid haar
> dossiers volledig digitaal behandelen. Poststukken met de vermelding
> ?vertrouwelijk? worden niet ingescand, maar ongeopend aan de geadresseerde
> bezorgd.*
> www.inbo.be
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be> <https://www.inbo.be&gt;>
>
>
> Op ma 6 mei 2024 om 01:59 schreef Srinidhi Jayakumar via R-sig-mixed-models
> <r-sig-mixed-models at r-project.org <mailto:r-sig-mixed-models at r-project.org>>:
>
> I am running a multilevel growth curve model to examine predictors of
> social anhedonia (SA) trajectory through ages 12, 15 and 18. SA is a
> continuous numeric variable. The age variable (Index1) has been coded as 0
> for age 12, 1 for age 15 and 2 for age 18. I am currently using a time
> varying predictor, stress (LSI), which was measured at ages 12, 15 and 18,
> to examine whether trajectory/variation in LSI predicts difference in SA
> trajectory. LSI is a continuous numeric variable and was grand-mean
> centered before using in the models. The data has been converted to long
> format with SA in 1 column, LSI in the other, ID in another, and age in
> another column. I used the code below to run my model using lmer. However,
> I get the following error. Please let me know how I can solve this error.
> Please note that I have 50% missing data in SA at age 12.
> modelLSI_maineff_RE <- lmer(SA ~ Index1* LSI+ (1 + Index1+LSI |ID), data =
> LSIDATA, control = lmerControl(optimizer ="bobyqa"), REML=TRUE)
> summary(modelLSI_maineff_RE)
> Error: number of observations (=1080) <= number of random effects (=1479)
> for term (1 + Index1 + LSI | ID); the random-effects parameters and the
> residual variance (or scale parameter) are probably unidentifiable
>
> I did test the within-person variance for the LSI variable and the
> within-person variance is significant from the Greenhouse-Geisser,
> Hyunh-Feidt tests.
>
> I also tried control = lmerControl(check.nobs.vs.nRE = "ignore") which gave
> me the following output. modelLSI_maineff_RE <- lmer(SA ~ Index1* LSI+ (1 +
> Index1+LSI |ID), data = LSIDATA, control = lmerControl(check.nobs.vs.nRE =
> "ignore", optimizer ="bobyqa", check.conv.singular = .makeCC(action =
> "ignore", tol = 1e-4)), REML=TRUE)
>
> summary(modelLSI_maineff_RE)
> Linear mixed model fit by REML. t-tests use Satterthwaite's method
> ['lmerModLmerTest']
> Formula: SA ~ Index1 * LSI + (1 + Index1 + LSI | ID)
> Data: LSIDATA
> Control: lmerControl(check.nobs.vs.nRE = "ignore", optimizer = "bobyqa",
> check.conv.singular = .makeCC(action = "ignore", tol = 1e-04))
>
> REML criterion at convergence: 7299.6
>
> Scaled residuals:
> Min 1Q Median 3Q Max
> -2.7289 -0.4832 -0.1449 0.3604 4.5715
>
> Random effects:
> Groups Name Variance Std.Dev. Corr
> ID (Intercept) 30.2919 5.5038
> Index1 2.4765 1.5737 -0.15
> LSI 0.1669 0.4085 -0.23 0.70
> Residual 24.1793 4.9172
> Number of obs: 1080, groups: ID, 493
>
> Fixed effects:
> Estimate Std. Error df t value Pr(>|t|)
> (Intercept) 24.68016 0.39722 313.43436 62.133 < 2e-16 ***
> Index1 0.98495 0.23626 362.75018 4.169 3.83e-05 ***
> LSI -0.05197 0.06226 273.85575 -0.835 0.4046
> Index1:LSI 0.09797 0.04506 426.01185 2.174 0.0302 *
> Signif. codes: 0 ?? 0.001 ?? 0.01 ?? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
> (Intr) Index1 LSI
> Index1 -0.645
> LSI -0.032 0.057
> Index1:LSI 0.015 0.037 -0.695
>
> I am a little vary of the output still as the error states that I have
> equal observations as the number of random effects (i.e., 3 observations
> per ID and 3 random effects). Hence, I am wondering whether I can simplify
> the model as either of the below models and choose the one with the
> best-fit statistics:
>
> modelLSI2 <- lmer(SA ~ Index1* LSI+ (1 |ID)+ (Index1+LSI -1|ID),data =
> LSIDATA, control = lmerControl(optimizer ="bobyqa"), REML=TRUE) *OR*
>
> modelLSI3 <- lmer(SA ~ Index1* LSI+ (1+LSI |ID),data = LSIDATA, control =
> lmerControl(optimizer ="bobyqa"), REML=TRUE) [image: example of dataset]
> <https://i.sstatic.net/JcRKS2C9.png> <https://i.sstatic.net/JcRKS2C9.png&gt;>
>


From tr@@h|@ket @end|ng |rom gm@||@com  Mon May  6 18:59:03 2024
From: tr@@h|@ket @end|ng |rom gm@||@com (TT FF)
Date: Mon, 6 May 2024 17:59:03 +0100
Subject: [R-sig-ME] 
 lmer error: number of observations <= number of random effects
In-Reply-To: <1A9DDD0E-250B-427A-AB43-C79505AC4247@me.com>
References: <CAMvZauqY=naWQtSgfp+JtX73vB5+Sm3pO=iv6P6ujNGQHcg5WQ@mail.gmail.com>
 <CAJuCY5ysmodQ=Jt8UGSuimNyz66WS9MAxdxWv4fttrM6O1Tw5A@mail.gmail.com>
 <CF887C5A-1262-4EEE-BA5D-D28899A84A50@gmail.com>
 <CAMvZauoywbby6FWwKQcdbH10rRREEh6iSgYnQwaR=WMcAuhPjQ@mail.gmail.com>
 <1A9DDD0E-250B-427A-AB43-C79505AC4247@me.com>
Message-ID: <BA1E1CBC-EC4D-4424-A610-98D04F4D0CB6@gmail.com>

if I understood the design correctly.

Index is a wihtin subject factor (the same participant tested at 3 different ages), while LSI is instead a numerical predictor.

If the above is correct, 
AND
If you assume the LSI will affect similarly across ages, then I would try the following:
mdl<-lmer(SA ~ Index1*LSI+ (1+LSI | ID)+(1 | ID:Index1),data = LSIDATA, control 
lmerControl(optimizer ="bobyqa"), REML=TRUE)]. 
car::Anova(mdl, type 3, test F)

If you assume the LSI will affect differently across ages, then I would try the following:
mdl<-lmer(SA ~ Index1*LSI+ (1 | ID)+(1 +LSI | ID:Index1),data = LSIDATA, control 
lmerControl(optimizer ="bobyqa"), REML=TRUE)]. 
car::Anova(mdl, type 3, test F)


However, 
if Index1 is a between subjects factor (i.e, each ID has one age only). Then, I would keep Index1 as numerical predictor (given that is also equally spaced) and run
mdl<-lmer(SA ~ Index1*LSI+ (1 +Index1:LSI | ID)),data = LSIDATA, control 
lmerControl(optimizer ="bobyqa"), REML=TRUE)]. 
car::Anova(mdl, type 3, test F)

The latter is based on (https://doi.org/10.3389/fpsyg.2013.00328 <https://doi.org/10.3389/fpsyg.2013.00328>) that suggests to keep the highest interaction. 

if you want to keep the age as between subjects factor (i.e, not a numerical predictor), then I would run
mdl<-lmer(SA ~ Index1*LSI+ (1+LSI | ID)),data = LSIDATA, control 
lmerControl(optimizer ="bobyqa"), REML=TRUE)]. 
car::Anova(mdl, type 3, test F)

But I would not make model comparisions by altering the random effect strcuture to see if LSI and Index has a different contribution. I would achieve that goal with a single model and by keeping them always in the fixed part of the LMM.


I hope this makes sense.

Best

> On 6 May 2024, at 16:33, Marc Schwartz <marc_schwartz at me.com> wrote:
> 
> Hi All,
> 
> As an FYI, there is no need for this thread to be cross-posted to three different lists: R-help, R-sig-mixed-models and R-devel.
> 
> I am removing R-Help and R-Devel from this reply and only replying to the authors and R-sig-mixed-models, which is the appropriate list for this thread.
> 
> For any future e-mails to this thread, please only reply to the author(s) and to R-sig-mixed-models, removing the other two lists.
> 
> Thank you,
> 
> Marc Schwartz
> R-Devel Co-Admin
> 
> 
> ?-----Original Message-----
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org <mailto:r-sig-mixed-models-bounces at r-project.org>> on behalf of Srinidhi Jayakumar via R-sig-mixed-models <r-sig-mixed-models at r-project.org <mailto:r-sig-mixed-models at r-project.org>>
> Reply-To: Srinidhi Jayakumar <srinidhi.jayakumar at stonybrook.edu <mailto:srinidhi.jayakumar at stonybrook.edu>>
> Date: Monday, May 6, 2024 at 9:54 AM
> To: TT FF <trashfaket at gmail.com <mailto:trashfaket at gmail.com>>
> Cc: <r-help at r-project.org <mailto:r-help at r-project.org>>, <r-sig-mixed-models at r-project.org <mailto:r-sig-mixed-models at r-project.org>>, <r-devel at r-project.org <mailto:r-devel at r-project.org>>
> Subject: Re: [R-sig-ME] lmer error: number of observations <= number of random effects
> 
> 
> Thank you very much for your responses!
> 
> 
> What if I reduce the model to
> modelLSI3 <- lmer(SA ~ Index1* LSI+ (1+LSI |ID),data = LSIDATA, control =
> lmerControl(optimizer ="bobyqa"), REML=TRUE).
> This would allow me to see the random effects of LSI and I can drop the
> random effect of age (Index1) since I can see that in the unconditional
> model [model0 <- lmer(SA ~ Index1+ (1+Index1|ID),data = LSIDATA, control =
> lmerControl(optimizer ="bobyqa"), REML=TRUE)]. Would the modelLSI3 also
> have a type 1 error?
> 
> 
> Thank you,
> Srinidhi
> 
> 
> 
> 
> 
> 
> 
> 
> On Mon, 6 May 2024, 03:11 TT FF, <trashfaket at gmail.com <mailto:trashfaket at gmail.com>> wrote:
> 
> 
>> See if this paper may help If it helps reducing the model when you have
>> few observations. the (1|ID) may increase the type 1 error.
>> https://journals.sagepub.com/doi/10.1177/25152459231214454 <https://journals.sagepub.com/doi/10.1177/25152459231214454>
>> 
>> Best
>> 
>> On 6 May 2024, at 07:45, Thierry Onkelinx via R-sig-mixed-models <
>> r-sig-mixed-models at r-project.org <mailto:r-sig-mixed-models at r-project.org>> wrote:
>> 
>> Dear Srinidhi,
>> 
>> You are trying to fit 1 random intercept and 2 random slopes per
>> individual, while you have at most 3 observations per individual. You
>> simply don't have enough data to fit the random slopes. Reduce the random
>> part to (1|ID).
>> 
>> Best regards,
>> 
>> Thierry
>> 
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>> 
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
>> FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>
>> Havenlaan 88 bus 73, 1000 Brussel
>> *Postadres:* Koning Albert II-laan 15 bus 186, 1210 Brussel
>> *Poststukken die naar dit adres worden gestuurd, worden ingescand en
>> digitaal aan de geadresseerde bezorgd. Zo kan de Vlaamse overheid haar
>> dossiers volledig digitaal behandelen. Poststukken met de vermelding
>> ?vertrouwelijk? worden niet ingescand, maar ongeopend aan de geadresseerde
>> bezorgd.*
>> www.inbo.be
>> 
>> 
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>> 
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> 
>> <https://www.inbo.be> <https://www.inbo.be&gt;>
>> 
>> 
>> Op ma 6 mei 2024 om 01:59 schreef Srinidhi Jayakumar via R-sig-mixed-models
>> <r-sig-mixed-models at r-project.org <mailto:r-sig-mixed-models at r-project.org>>:
>> 
>> I am running a multilevel growth curve model to examine predictors of
>> social anhedonia (SA) trajectory through ages 12, 15 and 18. SA is a
>> continuous numeric variable. The age variable (Index1) has been coded as 0
>> for age 12, 1 for age 15 and 2 for age 18. I am currently using a time
>> varying predictor, stress (LSI), which was measured at ages 12, 15 and 18,
>> to examine whether trajectory/variation in LSI predicts difference in SA
>> trajectory. LSI is a continuous numeric variable and was grand-mean
>> centered before using in the models. The data has been converted to long
>> format with SA in 1 column, LSI in the other, ID in another, and age in
>> another column. I used the code below to run my model using lmer. However,
>> I get the following error. Please let me know how I can solve this error.
>> Please note that I have 50% missing data in SA at age 12.
>> modelLSI_maineff_RE <- lmer(SA ~ Index1* LSI+ (1 + Index1+LSI |ID), data =
>> LSIDATA, control = lmerControl(optimizer ="bobyqa"), REML=TRUE)
>> summary(modelLSI_maineff_RE)
>> Error: number of observations (=1080) <= number of random effects (=1479)
>> for term (1 + Index1 + LSI | ID); the random-effects parameters and the
>> residual variance (or scale parameter) are probably unidentifiable
>> 
>> I did test the within-person variance for the LSI variable and the
>> within-person variance is significant from the Greenhouse-Geisser,
>> Hyunh-Feidt tests.
>> 
>> I also tried control = lmerControl(check.nobs.vs.nRE = "ignore") which gave
>> me the following output. modelLSI_maineff_RE <- lmer(SA ~ Index1* LSI+ (1 +
>> Index1+LSI |ID), data = LSIDATA, control = lmerControl(check.nobs.vs.nRE =
>> "ignore", optimizer ="bobyqa", check.conv.singular = .makeCC(action =
>> "ignore", tol = 1e-4)), REML=TRUE)
>> 
>> summary(modelLSI_maineff_RE)
>> Linear mixed model fit by REML. t-tests use Satterthwaite's method
>> ['lmerModLmerTest']
>> Formula: SA ~ Index1 * LSI + (1 + Index1 + LSI | ID)
>> Data: LSIDATA
>> Control: lmerControl(check.nobs.vs.nRE = "ignore", optimizer = "bobyqa",
>> check.conv.singular = .makeCC(action = "ignore", tol = 1e-04))
>> 
>> REML criterion at convergence: 7299.6
>> 
>> Scaled residuals:
>> Min 1Q Median 3Q Max
>> -2.7289 -0.4832 -0.1449 0.3604 4.5715
>> 
>> Random effects:
>> Groups Name Variance Std.Dev. Corr
>> ID (Intercept) 30.2919 5.5038
>> Index1 2.4765 1.5737 -0.15
>> LSI 0.1669 0.4085 -0.23 0.70
>> Residual 24.1793 4.9172
>> Number of obs: 1080, groups: ID, 493
>> 
>> Fixed effects:
>> Estimate Std. Error df t value Pr(>|t|)
>> (Intercept) 24.68016 0.39722 313.43436 62.133 < 2e-16 ***
>> Index1 0.98495 0.23626 362.75018 4.169 3.83e-05 ***
>> LSI -0.05197 0.06226 273.85575 -0.835 0.4046
>> Index1:LSI 0.09797 0.04506 426.01185 2.174 0.0302 *
>> Signif. codes: 0 ?? 0.001 ?? 0.01 ?? 0.05 ?.? 0.1 ? ? 1
>> 
>> Correlation of Fixed Effects:
>> (Intr) Index1 LSI
>> Index1 -0.645
>> LSI -0.032 0.057
>> Index1:LSI 0.015 0.037 -0.695
>> 
>> I am a little vary of the output still as the error states that I have
>> equal observations as the number of random effects (i.e., 3 observations
>> per ID and 3 random effects). Hence, I am wondering whether I can simplify
>> the model as either of the below models and choose the one with the
>> best-fit statistics:
>> 
>> modelLSI2 <- lmer(SA ~ Index1* LSI+ (1 |ID)+ (Index1+LSI -1|ID),data =
>> LSIDATA, control = lmerControl(optimizer ="bobyqa"), REML=TRUE) *OR*
>> 
>> modelLSI3 <- lmer(SA ~ Index1* LSI+ (1+LSI |ID),data = LSIDATA, control =
>> lmerControl(optimizer ="bobyqa"), REML=TRUE) [image: example of dataset]
>> <https://i.sstatic.net/JcRKS2C9.png> <https://i.sstatic.net/JcRKS2C9.png&gt;>
>> 
> 
> 
> 


	[[alternative HTML version deleted]]


From @r|n|dh|@j@y@kum@r @end|ng |rom @tonybrook@edu  Mon May  6 19:46:39 2024
From: @r|n|dh|@j@y@kum@r @end|ng |rom @tonybrook@edu (Srinidhi Jayakumar)
Date: Mon, 6 May 2024 13:46:39 -0400
Subject: [R-sig-ME] 
 lmer error: number of observations <= number of random effects
In-Reply-To: <BA1E1CBC-EC4D-4424-A610-98D04F4D0CB6@gmail.com>
References: <CAMvZauqY=naWQtSgfp+JtX73vB5+Sm3pO=iv6P6ujNGQHcg5WQ@mail.gmail.com>
 <CAJuCY5ysmodQ=Jt8UGSuimNyz66WS9MAxdxWv4fttrM6O1Tw5A@mail.gmail.com>
 <CF887C5A-1262-4EEE-BA5D-D28899A84A50@gmail.com>
 <CAMvZauoywbby6FWwKQcdbH10rRREEh6iSgYnQwaR=WMcAuhPjQ@mail.gmail.com>
 <1A9DDD0E-250B-427A-AB43-C79505AC4247@me.com>
 <BA1E1CBC-EC4D-4424-A610-98D04F4D0CB6@gmail.com>
Message-ID: <CAMvZauqz_vALDQxEXhc2SiOScKnKqgB=mx1H1q9eEqLG1Du51w@mail.gmail.com>

Hi,

Thank you very much for your response. Index1 is the time point variable.
So, we collected social anhedonia, and LSI at time points of age 12, 15,
and 18. So for every participant the time point variable (Index1) was coded
as 0 (for the 1st time point, i.e., age 12), 1  (for the 2nd time point,
i.e., age 15), and 2 (for the 3rd time point, i.e., age 18). So Index1 in
the fixed  effects would mean the average trajectory of SA, and Index1 as a
random effect would mean the variation in trajectories of SA. So it would
be a within subjects factor. I am looking into whether trajectory of social
anhedonia over these time points would differ depending on the LSI values
at the time points. I am assuming that LSI at each time point would affect
SA at each time point differently (e.g, 1 unit increase in LSI at time
point 0 would be associated with a 1 unit increase in SA at time point 0
but a 0.5 unit increase in SA at time point 1, if that makes sense).
I believe in this case, you are suggesting that I try
mdl<-lmer(SA ~ Index1*LSI+ (1 | ID)+(1 +LSI | ID:Index1),data = LSIDATA,
control = lmerControl(optimizer ="bobyqa"), REML=TRUE)].
Could you please let me know what would be the difference between the above
model vs when I nest the inviduals with time, i.e.,
mdl<-lmer(SA ~ Index1*LSI+ (1 | ID)+(1 +LSI | Index1/ID),data = LSIDATA,
control = lmerControl(optimizer ="bobyqa"), REML=TRUE)]. I am thinking in
this case, it would be that for each person, over time, we are examining
the variation in LSI and how that affects variation in SA. Whereas, in the
model you had suggested, it would be that between IDs, over time, we  are
examining the variation in LSI and how that affects variation in SA
correct? So the model you had suggested wouldn't tell me about variation in
LSI and its effects on variation in SA per person over time is that correct?
Thank you in advance for your sincere help!


Thank you,
Srinidhi


On Mon, May 6, 2024 at 12:59?PM TT FF <trashfaket at gmail.com> wrote:

> if I understood the design correctly.
>
> Index is a wihtin subject factor (the same participant tested at 3
> different ages), while LSI is instead a numerical predictor.
>
> If the above is correct,
> AND
> If you assume the LSI will affect similarly across ages, then I would try
> the following:
> mdl<-lmer(SA ~ Index1*LSI+ (1+LSI | ID)+(1 | ID:Index1),data = LSIDATA,
> control
> lmerControl(optimizer ="bobyqa"), REML=TRUE)].
> car::Anova(mdl, type 3, test F)
>
> If you assume the LSI will affect differently across ages, then I would
> try the following:
> mdl<-lmer(SA ~ Index1*LSI+ (1 | ID)+(1 +LSI | ID:Index1),data = LSIDATA,
> control
> lmerControl(optimizer ="bobyqa"), REML=TRUE)].
> car::Anova(mdl, type 3, test F)
>
>
> However,
> if Index1 is a between subjects factor (i.e, each ID has one age only).
> Then, I would keep Index1 as numerical predictor (given that is also
> equally spaced) and run
> mdl<-lmer(SA ~ Index1*LSI+ (1 +Index1:LSI | ID)),data = LSIDATA, control
> lmerControl(optimizer ="bobyqa"), REML=TRUE)].
> car::Anova(mdl, type 3, test F)
>
> The latter is based on (https://doi.org/10.3389/fpsyg.2013.00328) that
> suggests to keep the highest interaction.
>
> if you want to keep the age as between subjects factor (i.e, not a
> numerical predictor), then I would run
> mdl<-lmer(SA ~ Index1*LSI+ (1+LSI | ID)),data = LSIDATA, control
> lmerControl(optimizer ="bobyqa"), REML=TRUE)].
> car::Anova(mdl, type 3, test F)
>
> But I would not make model comparisions by altering the random effect
> strcuture to see if LSI and Index has a different contribution. I would
> achieve that goal with a single model and by keeping them always in the
> fixed part of the LMM.
>
>
> I hope this makes sense.
>
> Best
>
> On 6 May 2024, at 16:33, Marc Schwartz <marc_schwartz at me.com> wrote:
>
> Hi All,
>
> As an FYI, there is no need for this thread to be cross-posted to three
> different lists: R-help, R-sig-mixed-models and R-devel.
>
> I am removing R-Help and R-Devel from this reply and only replying to the
> authors and R-sig-mixed-models, which is the appropriate list for this
> thread.
>
> For any future e-mails to this thread, please only reply to the author(s)
> and to R-sig-mixed-models, removing the other two lists.
>
> Thank you,
>
> Marc Schwartz
> R-Devel Co-Admin
>
>
> ?-----Original Message-----
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org <
> mailto:r-sig-mixed-models-bounces at r-project.org
> <r-sig-mixed-models-bounces at r-project.org>>> on behalf of Srinidhi
> Jayakumar via R-sig-mixed-models <r-sig-mixed-models at r-project.org <
> mailto:r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
> >>
> Reply-To: Srinidhi Jayakumar <srinidhi.jayakumar at stonybrook.edu <
> mailto:srinidhi.jayakumar at stonybrook.edu
> <srinidhi.jayakumar at stonybrook.edu>>>
> Date: Monday, May 6, 2024 at 9:54 AM
> To: TT FF <trashfaket at gmail.com <mailto:trashfaket at gmail.com
> <trashfaket at gmail.com>>>
> Cc: <r-help at r-project.org <mailto:r-help at r-project.org
> <r-help at r-project.org>>>, <r-sig-mixed-models at r-project.org <
> mailto:r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>>>,
> <r-devel at r-project.org <mailto:r-devel at r-project.org
> <r-devel at r-project.org>>>
> Subject: Re: [R-sig-ME] lmer error: number of observations <= number of
> random effects
>
>
> Thank you very much for your responses!
>
>
> What if I reduce the model to
> modelLSI3 <- lmer(SA ~ Index1* LSI+ (1+LSI |ID),data = LSIDATA, control =
> lmerControl(optimizer ="bobyqa"), REML=TRUE).
> This would allow me to see the random effects of LSI and I can drop the
> random effect of age (Index1) since I can see that in the unconditional
> model [model0 <- lmer(SA ~ Index1+ (1+Index1|ID),data = LSIDATA, control =
> lmerControl(optimizer ="bobyqa"), REML=TRUE)]. Would the modelLSI3 also
> have a type 1 error?
>
>
> Thank you,
> Srinidhi
>
>
>
>
>
>
>
>
> On Mon, 6 May 2024, 03:11 TT FF, <trashfaket at gmail.com <
> mailto:trashfaket at gmail.com <trashfaket at gmail.com>>> wrote:
>
>
> See if this paper may help If it helps reducing the model when you have
> few observations. the (1|ID) may increase the type 1 error.
> https://journals.sagepub.com/doi/10.1177/25152459231214454 <
> https://journals.sagepub.com/doi/10.1177/25152459231214454>
>
> Best
>
> On 6 May 2024, at 07:45, Thierry Onkelinx via R-sig-mixed-models <
> r-sig-mixed-models at r-project.org <mailto:r-sig-mixed-models at r-project.org
> <r-sig-mixed-models at r-project.org>>> wrote:
>
> Dear Srinidhi,
>
> You are trying to fit 1 random intercept and 2 random slopes per
> individual, while you have at most 3 observations per individual. You
> simply don't have enough data to fit the random slopes. Reduce the random
> part to (1|ID).
>
> Best regards,
>
> Thierry
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be
> <thierry.onkelinx at inbo.be>>
> Havenlaan 88 bus 73, 1000 Brussel
> *Postadres:* Koning Albert II-laan 15 bus 186, 1210 Brussel
> *Poststukken die naar dit adres worden gestuurd, worden ingescand en
> digitaal aan de geadresseerde bezorgd. Zo kan de Vlaamse overheid haar
> dossiers volledig digitaal behandelen. Poststukken met de vermelding
> ?vertrouwelijk? worden niet ingescand, maar ongeopend aan de geadresseerde
> bezorgd.*
> www.inbo.be
>
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be> <https://www.inbo.be&gt;>
>
>
> Op ma 6 mei 2024 om 01:59 schreef Srinidhi Jayakumar via R-sig-mixed-models
> <r-sig-mixed-models at r-project.org <mailto:r-sig-mixed-models at r-project.org
> >>:
>
> I am running a multilevel growth curve model to examine predictors of
> social anhedonia (SA) trajectory through ages 12, 15 and 18. SA is a
> continuous numeric variable. The age variable (Index1) has been coded as 0
> for age 12, 1 for age 15 and 2 for age 18. I am currently using a time
> varying predictor, stress (LSI), which was measured at ages 12, 15 and 18,
> to examine whether trajectory/variation in LSI predicts difference in SA
> trajectory. LSI is a continuous numeric variable and was grand-mean
> centered before using in the models. The data has been converted to long
> format with SA in 1 column, LSI in the other, ID in another, and age in
> another column. I used the code below to run my model using lmer. However,
> I get the following error. Please let me know how I can solve this error.
> Please note that I have 50% missing data in SA at age 12.
> modelLSI_maineff_RE <- lmer(SA ~ Index1* LSI+ (1 + Index1+LSI |ID), data =
> LSIDATA, control = lmerControl(optimizer ="bobyqa"), REML=TRUE)
> summary(modelLSI_maineff_RE)
> Error: number of observations (=1080) <= number of random effects (=1479)
> for term (1 + Index1 + LSI | ID); the random-effects parameters and the
> residual variance (or scale parameter) are probably unidentifiable
>
> I did test the within-person variance for the LSI variable and the
> within-person variance is significant from the Greenhouse-Geisser,
> Hyunh-Feidt tests.
>
> I also tried control = lmerControl(check.nobs.vs.nRE = "ignore") which gave
> me the following output. modelLSI_maineff_RE <- lmer(SA ~ Index1* LSI+ (1 +
> Index1+LSI |ID), data = LSIDATA, control = lmerControl(check.nobs.vs.nRE =
> "ignore", optimizer ="bobyqa", check.conv.singular = .makeCC(action =
> "ignore", tol = 1e-4)), REML=TRUE)
>
> summary(modelLSI_maineff_RE)
> Linear mixed model fit by REML. t-tests use Satterthwaite's method
> ['lmerModLmerTest']
> Formula: SA ~ Index1 * LSI + (1 + Index1 + LSI | ID)
> Data: LSIDATA
> Control: lmerControl(check.nobs.vs.nRE = "ignore", optimizer = "bobyqa",
> check.conv.singular = .makeCC(action = "ignore", tol = 1e-04))
>
> REML criterion at convergence: 7299.6
>
> Scaled residuals:
> Min 1Q Median 3Q Max
> -2.7289 -0.4832 -0.1449 0.3604 4.5715
>
> Random effects:
> Groups Name Variance Std.Dev. Corr
> ID (Intercept) 30.2919 5.5038
> Index1 2.4765 1.5737 -0.15
> LSI 0.1669 0.4085 -0.23 0.70
> Residual 24.1793 4.9172
> Number of obs: 1080, groups: ID, 493
>
> Fixed effects:
> Estimate Std. Error df t value Pr(>|t|)
> (Intercept) 24.68016 0.39722 313.43436 62.133 < 2e-16 ***
> Index1 0.98495 0.23626 362.75018 4.169 3.83e-05 ***
> LSI -0.05197 0.06226 273.85575 -0.835 0.4046
> Index1:LSI 0.09797 0.04506 426.01185 2.174 0.0302 *
> Signif. codes: 0 ?? 0.001 ?? 0.01 ?? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
> (Intr) Index1 LSI
> Index1 -0.645
> LSI -0.032 0.057
> Index1:LSI 0.015 0.037 -0.695
>
> I am a little vary of the output still as the error states that I have
> equal observations as the number of random effects (i.e., 3 observations
> per ID and 3 random effects). Hence, I am wondering whether I can simplify
> the model as either of the below models and choose the one with the
> best-fit statistics:
>
> modelLSI2 <- lmer(SA ~ Index1* LSI+ (1 |ID)+ (Index1+LSI -1|ID),data =
> LSIDATA, control = lmerControl(optimizer ="bobyqa"), REML=TRUE) *OR*
>
> modelLSI3 <- lmer(SA ~ Index1* LSI+ (1+LSI |ID),data = LSIDATA, control =
> lmerControl(optimizer ="bobyqa"), REML=TRUE) [image: example of dataset]
> <https://i.sstatic.net/JcRKS2C9.png> <
> https://i.sstatic.net/JcRKS2C9.png&gt;>
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From tr@@h|@ket @end|ng |rom gm@||@com  Mon May  6 20:18:06 2024
From: tr@@h|@ket @end|ng |rom gm@||@com (TT FF)
Date: Mon, 6 May 2024 19:18:06 +0100
Subject: [R-sig-ME] 
 lmer error: number of observations <= number of random effects
In-Reply-To: <CAMvZauqz_vALDQxEXhc2SiOScKnKqgB=mx1H1q9eEqLG1Du51w@mail.gmail.com>
References: <CAMvZauqY=naWQtSgfp+JtX73vB5+Sm3pO=iv6P6ujNGQHcg5WQ@mail.gmail.com>
 <CAJuCY5ysmodQ=Jt8UGSuimNyz66WS9MAxdxWv4fttrM6O1Tw5A@mail.gmail.com>
 <CF887C5A-1262-4EEE-BA5D-D28899A84A50@gmail.com>
 <CAMvZauoywbby6FWwKQcdbH10rRREEh6iSgYnQwaR=WMcAuhPjQ@mail.gmail.com>
 <1A9DDD0E-250B-427A-AB43-C79505AC4247@me.com>
 <BA1E1CBC-EC4D-4424-A610-98D04F4D0CB6@gmail.com>
 <CAMvZauqz_vALDQxEXhc2SiOScKnKqgB=mx1H1q9eEqLG1Du51w@mail.gmail.com>
Message-ID: <7BB7E026-CE48-42AD-9EC0-1A43D740FFE5@gmail.com>

yes, based on what you said, I would use:
> mdl<-lmer(SA ~ Index1*LSI+ (1 | ID)+(1 +LSI | ID:Index1)

About the different syntax. Based on (https://stats.stackexchange.com/questions/228800/crossed-vs-nested-random-effects-how-do-they-differ-and-how-are-they-specified <https://stats.stackexchange.com/questions/228800/crossed-vs-nested-random-effects-how-do-they-differ-and-how-are-they-specified>) the correct syntax would be:
> mdl<-lmer(SA ~ Index1*LSI+ (1 | ID)+(1 +LSI |ID/Index1) 
not
> mdl<-lmer(SA ~ Index1*LSI+ (1 | ID)+(1 +LSI | Index1/ID)

However, while the syntax
> (1 |ID/Index1) 
would be equivalent to 
> (1 |ID) + (1 | ID:Index1)

I am not sure where the LSI random slope would go
> (1+LSI |ID) + (1+LSI| ID:Index1)
or in just one of the two RE parts.

Hence, to answer that question more digging is necessary (also to answer the last part of your question)?sorry?
However, the first model based on (https://journals.sagepub.com/doi/10.1177/25152459231214454 <https://journals.sagepub.com/doi/10.1177/25152459231214454>) is what I would do OR I would also try to use afex that allows to remove correlations using ?||?.
https://cran.r-project.org/web/packages/afex/vignettes/introduction-mixed-models.pdf <https://cran.r-project.org/web/packages/afex/vignettes/introduction-mixed-models.pdf>

https://cran.r-project.org/web/packages/afex/vignettes/afex_mixed_example.html <https://cran.r-project.org/web/packages/afex/vignettes/afex_mixed_example.html>

I hope this helps

Best

> On 6 May 2024, at 18:46, Srinidhi Jayakumar <srinidhi.jayakumar at stonybrook.edu> wrote:
> 
> Hi,
> 
> Thank you very much for your response. Index1 is the time point variable. So, we collected social anhedonia, and LSI at time points of age 12, 15, and 18. So for every participant the time point variable (Index1) was coded as 0 (for the 1st time point, i.e., age 12), 1  (for the 2nd time point, i.e., age 15), and 2 (for the 3rd time point, i.e., age 18). So Index1 in the fixed  effects would mean the average trajectory of SA, and Index1 as a random effect would mean the variation in trajectories of SA. So it would be a within subjects factor. I am looking into whether trajectory of social anhedonia over these time points would differ depending on the LSI values at the time points. I am assuming that LSI at each time point would affect SA at each time point differently (e.g, 1 unit increase in LSI at time point 0 would be associated with a 1 unit increase in SA at time point 0 but a 0.5 unit increase in SA at time point 1, if that makes sense). 
> I believe in this case, you are suggesting that I try
> mdl<-lmer(SA ~ Index1*LSI+ (1 | ID)+(1 +LSI | ID:Index1),data = LSIDATA, control = lmerControl(optimizer ="bobyqa"), REML=TRUE)]. 
> Could you please let me know what would be the difference between the above model vs when I nest the inviduals with time, i.e., 
> mdl<-lmer(SA ~ Index1*LSI+ (1 | ID)+(1 +LSI | Index1/ID),data = LSIDATA, control = lmerControl(optimizer ="bobyqa"), REML=TRUE)]. I am thinking in this case, it would be that for each person, over time, we are examining the variation in LSI and how that affects variation in SA. Whereas, in the model you had suggested, it would be that between IDs, over time, we  are examining the variation in LSI and how that affects variation in SA correct? So the model you had suggested wouldn't tell me about variation in LSI and its effects on variation in SA per person over time is that correct?
> Thank you in advance for your sincere help!  
> 
> 
> Thank you,
> Srinidhi
> 
> 
> On Mon, May 6, 2024 at 12:59?PM TT FF <trashfaket at gmail.com <mailto:trashfaket at gmail.com>> wrote:
> if I understood the design correctly.
> 
> Index is a wihtin subject factor (the same participant tested at 3 different ages), while LSI is instead a numerical predictor.
> 
> If the above is correct, 
> AND
> If you assume the LSI will affect similarly across ages, then I would try the following:
> mdl<-lmer(SA ~ Index1*LSI+ (1+LSI | ID)+(1 | ID:Index1),data = LSIDATA, control 
> lmerControl(optimizer ="bobyqa"), REML=TRUE)]. 
> car::Anova(mdl, type 3, test F)
> 
> If you assume the LSI will affect differently across ages, then I would try the following:
> mdl<-lmer(SA ~ Index1*LSI+ (1 | ID)+(1 +LSI | ID:Index1),data = LSIDATA, control 
> lmerControl(optimizer ="bobyqa"), REML=TRUE)]. 
> car::Anova(mdl, type 3, test F)
> 
> 
> However, 
> if Index1 is a between subjects factor (i.e, each ID has one age only). Then, I would keep Index1 as numerical predictor (given that is also equally spaced) and run
> mdl<-lmer(SA ~ Index1*LSI+ (1 +Index1:LSI | ID)),data = LSIDATA, control 
> lmerControl(optimizer ="bobyqa"), REML=TRUE)]. 
> car::Anova(mdl, type 3, test F)
> 
> The latter is based on (https://doi.org/10.3389/fpsyg.2013.00328 <https://doi.org/10.3389/fpsyg.2013.00328>) that suggests to keep the highest interaction. 
> 
> if you want to keep the age as between subjects factor (i.e, not a numerical predictor), then I would run
> mdl<-lmer(SA ~ Index1*LSI+ (1+LSI | ID)),data = LSIDATA, control 
> lmerControl(optimizer ="bobyqa"), REML=TRUE)]. 
> car::Anova(mdl, type 3, test F)
> 
> But I would not make model comparisions by altering the random effect strcuture to see if LSI and Index has a different contribution. I would achieve that goal with a single model and by keeping them always in the fixed part of the LMM.
> 
> 
> I hope this makes sense.
> 
> Best
> 
>> On 6 May 2024, at 16:33, Marc Schwartz <marc_schwartz at me.com <mailto:marc_schwartz at me.com>> wrote:
>> 
>> Hi All,
>> 
>> As an FYI, there is no need for this thread to be cross-posted to three different lists: R-help, R-sig-mixed-models and R-devel.
>> 
>> I am removing R-Help and R-Devel from this reply and only replying to the authors and R-sig-mixed-models, which is the appropriate list for this thread.
>> 
>> For any future e-mails to this thread, please only reply to the author(s) and to R-sig-mixed-models, removing the other two lists.
>> 
>> Thank you,
>> 
>> Marc Schwartz
>> R-Devel Co-Admin
>> 
>> 
>> ?-----Original Message-----
>> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org <mailto:r-sig-mixed-models-bounces at r-project.org> <mailto:r-sig-mixed-models-bounces at r-project.org <mailto:r-sig-mixed-models-bounces at r-project.org>>> on behalf of Srinidhi Jayakumar via R-sig-mixed-models <r-sig-mixed-models at r-project.org <mailto:r-sig-mixed-models at r-project.org> <mailto:r-sig-mixed-models at r-project.org <mailto:r-sig-mixed-models at r-project.org>>>
>> Reply-To: Srinidhi Jayakumar <srinidhi.jayakumar at stonybrook.edu <mailto:srinidhi.jayakumar at stonybrook.edu> <mailto:srinidhi.jayakumar at stonybrook.edu <mailto:srinidhi.jayakumar at stonybrook.edu>>>
>> Date: Monday, May 6, 2024 at 9:54 AM
>> To: TT FF <trashfaket at gmail.com <mailto:trashfaket at gmail.com> <mailto:trashfaket at gmail.com <mailto:trashfaket at gmail.com>>>
>> Cc: <r-help at r-project.org <mailto:r-help at r-project.org> <mailto:r-help at r-project.org <mailto:r-help at r-project.org>>>, <r-sig-mixed-models at r-project.org <mailto:r-sig-mixed-models at r-project.org> <mailto:r-sig-mixed-models at r-project.org <mailto:r-sig-mixed-models at r-project.org>>>, <r-devel at r-project.org <mailto:r-devel at r-project.org> <mailto:r-devel at r-project.org <mailto:r-devel at r-project.org>>>
>> Subject: Re: [R-sig-ME] lmer error: number of observations <= number of random effects
>> 
>> 
>> Thank you very much for your responses!
>> 
>> 
>> What if I reduce the model to
>> modelLSI3 <- lmer(SA ~ Index1* LSI+ (1+LSI |ID),data = LSIDATA, control =
>> lmerControl(optimizer ="bobyqa"), REML=TRUE).
>> This would allow me to see the random effects of LSI and I can drop the
>> random effect of age (Index1) since I can see that in the unconditional
>> model [model0 <- lmer(SA ~ Index1+ (1+Index1|ID),data = LSIDATA, control =
>> lmerControl(optimizer ="bobyqa"), REML=TRUE)]. Would the modelLSI3 also
>> have a type 1 error?
>> 
>> 
>> Thank you,
>> Srinidhi
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> On Mon, 6 May 2024, 03:11 TT FF, <trashfaket at gmail.com <mailto:trashfaket at gmail.com> <mailto:trashfaket at gmail.com <mailto:trashfaket at gmail.com>>> wrote:
>> 
>> 
>>> See if this paper may help If it helps reducing the model when you have
>>> few observations. the (1|ID) may increase the type 1 error.
>>> https://journals.sagepub.com/doi/10.1177/25152459231214454 <https://journals.sagepub.com/doi/10.1177/25152459231214454> <https://journals.sagepub.com/doi/10.1177/25152459231214454 <https://journals.sagepub.com/doi/10.1177/25152459231214454>>
>>> 
>>> Best
>>> 
>>> On 6 May 2024, at 07:45, Thierry Onkelinx via R-sig-mixed-models <
>>> r-sig-mixed-models at r-project.org <mailto:r-sig-mixed-models at r-project.org> <mailto:r-sig-mixed-models at r-project.org <mailto:r-sig-mixed-models at r-project.org>>> wrote:
>>> 
>>> Dear Srinidhi,
>>> 
>>> You are trying to fit 1 random intercept and 2 random slopes per
>>> individual, while you have at most 3 observations per individual. You
>>> simply don't have enough data to fit the random slopes. Reduce the random
>>> part to (1|ID).
>>> 
>>> Best regards,
>>> 
>>> Thierry
>>> 
>>> ir. Thierry Onkelinx
>>> Statisticus / Statistician
>>> 
>>> Vlaamse Overheid / Government of Flanders
>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
>>> FOREST
>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>>> thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be> <mailto:thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>>
>>> Havenlaan 88 bus 73, 1000 Brussel
>>> *Postadres:* Koning Albert II-laan 15 bus 186, 1210 Brussel
>>> *Poststukken die naar dit adres worden gestuurd, worden ingescand en
>>> digitaal aan de geadresseerde bezorgd. Zo kan de Vlaamse overheid haar
>>> dossiers volledig digitaal behandelen. Poststukken met de vermelding
>>> ?vertrouwelijk? worden niet ingescand, maar ongeopend aan de geadresseerde
>>> bezorgd.*
>>> www.inbo.be <http://www.inbo.be/>
>>> 
>>> 
>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to say
>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of data.
>>> ~ John Tukey
>>> 
>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>> 
>>> <https://www.inbo.be <https://www.inbo.be/>> <https://www.inbo.be <https://www.inbo.be/>&gt;>
>>> 
>>> 
>>> Op ma 6 mei 2024 om 01:59 schreef Srinidhi Jayakumar via R-sig-mixed-models
>>> <r-sig-mixed-models at r-project.org <mailto:r-sig-mixed-models at r-project.org> <mailto:r-sig-mixed-models at r-project.org <mailto:r-sig-mixed-models at r-project.org>>>:
>>> 
>>> I am running a multilevel growth curve model to examine predictors of
>>> social anhedonia (SA) trajectory through ages 12, 15 and 18. SA is a
>>> continuous numeric variable. The age variable (Index1) has been coded as 0
>>> for age 12, 1 for age 15 and 2 for age 18. I am currently using a time
>>> varying predictor, stress (LSI), which was measured at ages 12, 15 and 18,
>>> to examine whether trajectory/variation in LSI predicts difference in SA
>>> trajectory. LSI is a continuous numeric variable and was grand-mean
>>> centered before using in the models. The data has been converted to long
>>> format with SA in 1 column, LSI in the other, ID in another, and age in
>>> another column. I used the code below to run my model using lmer. However,
>>> I get the following error. Please let me know how I can solve this error.
>>> Please note that I have 50% missing data in SA at age 12.
>>> modelLSI_maineff_RE <- lmer(SA ~ Index1* LSI+ (1 + Index1+LSI |ID), data =
>>> LSIDATA, control = lmerControl(optimizer ="bobyqa"), REML=TRUE)
>>> summary(modelLSI_maineff_RE)
>>> Error: number of observations (=1080) <= number of random effects (=1479)
>>> for term (1 + Index1 + LSI | ID); the random-effects parameters and the
>>> residual variance (or scale parameter) are probably unidentifiable
>>> 
>>> I did test the within-person variance for the LSI variable and the
>>> within-person variance is significant from the Greenhouse-Geisser,
>>> Hyunh-Feidt tests.
>>> 
>>> I also tried control = lmerControl(check.nobs.vs.nRE = "ignore") which gave
>>> me the following output. modelLSI_maineff_RE <- lmer(SA ~ Index1* LSI+ (1 +
>>> Index1+LSI |ID), data = LSIDATA, control = lmerControl(check.nobs.vs.nRE =
>>> "ignore", optimizer ="bobyqa", check.conv.singular = .makeCC(action =
>>> "ignore", tol = 1e-4)), REML=TRUE)
>>> 
>>> summary(modelLSI_maineff_RE)
>>> Linear mixed model fit by REML. t-tests use Satterthwaite's method
>>> ['lmerModLmerTest']
>>> Formula: SA ~ Index1 * LSI + (1 + Index1 + LSI | ID)
>>> Data: LSIDATA
>>> Control: lmerControl(check.nobs.vs.nRE = "ignore", optimizer = "bobyqa",
>>> check.conv.singular = .makeCC(action = "ignore", tol = 1e-04))
>>> 
>>> REML criterion at convergence: 7299.6
>>> 
>>> Scaled residuals:
>>> Min 1Q Median 3Q Max
>>> -2.7289 -0.4832 -0.1449 0.3604 4.5715
>>> 
>>> Random effects:
>>> Groups Name Variance Std.Dev. Corr
>>> ID (Intercept) 30.2919 5.5038
>>> Index1 2.4765 1.5737 -0.15
>>> LSI 0.1669 0.4085 -0.23 0.70
>>> Residual 24.1793 4.9172
>>> Number of obs: 1080, groups: ID, 493
>>> 
>>> Fixed effects:
>>> Estimate Std. Error df t value Pr(>|t|)
>>> (Intercept) 24.68016 0.39722 313.43436 62.133 < 2e-16 ***
>>> Index1 0.98495 0.23626 362.75018 4.169 3.83e-05 ***
>>> LSI -0.05197 0.06226 273.85575 -0.835 0.4046
>>> Index1:LSI 0.09797 0.04506 426.01185 2.174 0.0302 *
>>> Signif. codes: 0 ?? 0.001 ?? 0.01 ?? 0.05 ?.? 0.1 ? ? 1
>>> 
>>> Correlation of Fixed Effects:
>>> (Intr) Index1 LSI
>>> Index1 -0.645
>>> LSI -0.032 0.057
>>> Index1:LSI 0.015 0.037 -0.695
>>> 
>>> I am a little vary of the output still as the error states that I have
>>> equal observations as the number of random effects (i.e., 3 observations
>>> per ID and 3 random effects). Hence, I am wondering whether I can simplify
>>> the model as either of the below models and choose the one with the
>>> best-fit statistics:
>>> 
>>> modelLSI2 <- lmer(SA ~ Index1* LSI+ (1 |ID)+ (Index1+LSI -1|ID),data =
>>> LSIDATA, control = lmerControl(optimizer ="bobyqa"), REML=TRUE) *OR*
>>> 
>>> modelLSI3 <- lmer(SA ~ Index1* LSI+ (1+LSI |ID),data = LSIDATA, control =
>>> lmerControl(optimizer ="bobyqa"), REML=TRUE) [image: example of dataset]
>>> <https://i.sstatic.net/JcRKS2C9.png <https://i.sstatic.net/JcRKS2C9.png>> <https://i.sstatic.net/JcRKS2C9.png&gt <https://i.sstatic.net/JcRKS2C9.png&gt>;>
>>> 
>> 
>> 
>> 
> 


	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Tue May  7 19:23:48 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 7 May 2024 10:23:48 -0700
Subject: [R-sig-ME] [R] lmer error: number of observations <= number of
 random effects
In-Reply-To: <CAMvZauoywbby6FWwKQcdbH10rRREEh6iSgYnQwaR=WMcAuhPjQ@mail.gmail.com>
References: <CAMvZauqY=naWQtSgfp+JtX73vB5+Sm3pO=iv6P6ujNGQHcg5WQ@mail.gmail.com>
 <CAJuCY5ysmodQ=Jt8UGSuimNyz66WS9MAxdxWv4fttrM6O1Tw5A@mail.gmail.com>
 <CF887C5A-1262-4EEE-BA5D-D28899A84A50@gmail.com>
 <CAMvZauoywbby6FWwKQcdbH10rRREEh6iSgYnQwaR=WMcAuhPjQ@mail.gmail.com>
Message-ID: <CAGxFJbS4pDkj-q2Ooe-2uiHY77=5rVRcB+6WzJUiT+K2Xrr2Sg@mail.gmail.com>

I think you should seek out a local statistician with whom to consult if at
all possible, as the details of your research goals and the nature of the
data you have to meet those goals matter and cannot be effectively
discussed in a remote forum like this. That is, to be blunt, you seem to be
risk of producing junk. Just my opinion, which you are of course free to
ignore. Certainly, no response needed, and I will not say anything further.

Cheers,
Bert

On Tue, May 7, 2024 at 9:12?AM Srinidhi Jayakumar via R-help <
r-help at r-project.org> wrote:

> Thank you very  much for your responses!
>
> What if I reduce the model to
>  modelLSI3 <- lmer(SA ~ Index1* LSI+ (1+LSI |ID),data = LSIDATA, control =
> lmerControl(optimizer ="bobyqa"), REML=TRUE).
> This would allow me to see the random effects of LSI and I can drop the
> random effect of age (Index1) since I can see that in the unconditional
> model [model0 <- lmer(SA ~ Index1+ (1+Index1|ID),data = LSIDATA, control =
> lmerControl(optimizer ="bobyqa"), REML=TRUE)]. Would the modelLSI3 also
> have a type 1 error?
>
> Thank you,
> Srinidhi
>
>
>
>
> On Mon, 6 May 2024, 03:11 TT FF, <trashfaket at gmail.com> wrote:
>
> > See if this paper may help If it helps reducing the model when you have
> > few observations. the (1|ID) may increase the type 1 error.
> > https://journals.sagepub.com/doi/10.1177/25152459231214454
> >
> > Best
> >
> > On 6 May 2024, at 07:45, Thierry Onkelinx via R-sig-mixed-models <
> > r-sig-mixed-models at r-project.org> wrote:
> >
> > Dear Srinidhi,
> >
> > You are trying to fit 1 random intercept and 2 random slopes per
> > individual, while you have at most 3 observations per individual. You
> > simply don't have enough data to fit the random slopes. Reduce the random
> > part to (1|ID).
> >
> > Best regards,
> >
> > Thierry
> >
> > ir. Thierry Onkelinx
> > Statisticus / Statistician
> >
> > Vlaamse Overheid / Government of Flanders
> > INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> AND
> > FOREST
> > Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> > thierry.onkelinx at inbo.be
> > Havenlaan 88 bus 73, 1000 Brussel
> > *Postadres:* Koning Albert II-laan 15 bus 186, 1210 Brussel
> > *Poststukken die naar dit adres worden gestuurd, worden ingescand en
> > digitaal aan de geadresseerde bezorgd. Zo kan de Vlaamse overheid haar
> > dossiers volledig digitaal behandelen. Poststukken met de vermelding
> > ?vertrouwelijk? worden niet ingescand, maar ongeopend aan de
> geadresseerde
> > bezorgd.*
> > www.inbo.be
> >
> >
> >
> ///////////////////////////////////////////////////////////////////////////////////////////
> > To call in the statistician after the experiment is done may be no more
> > than asking him to perform a post-mortem examination: he may be able to
> say
> > what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > The plural of anecdote is not data. ~ Roger Brinner
> > The combination of some data and an aching desire for an answer does not
> > ensure that a reasonable answer can be extracted from a given body of
> data.
> > ~ John Tukey
> >
> >
> ///////////////////////////////////////////////////////////////////////////////////////////
> >
> > <https://www.inbo.be>
> >
> >
> > Op ma 6 mei 2024 om 01:59 schreef Srinidhi Jayakumar via
> R-sig-mixed-models
> > <r-sig-mixed-models at r-project.org>:
> >
> > I am running a multilevel growth curve model to examine predictors of
> > social anhedonia (SA) trajectory through ages 12, 15 and 18. SA is a
> > continuous numeric variable. The age variable (Index1) has been coded as
> 0
> > for age 12, 1 for age 15 and 2 for age 18. I am currently using a time
> > varying predictor, stress (LSI), which was measured at ages 12, 15 and
> 18,
> > to examine whether trajectory/variation in LSI predicts difference in SA
> > trajectory. LSI is a continuous numeric variable and was grand-mean
> > centered before using in the models. The data has been converted to long
> > format with SA in 1 column, LSI in the other, ID in another, and age in
> > another column. I used the code below to run my model using lmer.
> However,
> > I get the following error. Please let me know how I can solve this error.
> > Please note that I have 50% missing data in SA at age 12.
> > modelLSI_maineff_RE <- lmer(SA ~ Index1* LSI+ (1 + Index1+LSI |ID), data
> =
> > LSIDATA, control = lmerControl(optimizer ="bobyqa"), REML=TRUE)
> > summary(modelLSI_maineff_RE)
> > Error: number of observations (=1080) <= number of random effects (=1479)
> > for term (1 + Index1 + LSI | ID); the random-effects parameters and the
> > residual variance (or scale parameter) are probably unidentifiable
> >
> > I did test the within-person variance for the LSI variable and the
> > within-person variance is significant from the Greenhouse-Geisser,
> > Hyunh-Feidt tests.
> >
> > I also tried control = lmerControl(check.nobs.vs.nRE = "ignore") which
> gave
> > me the following output. modelLSI_maineff_RE <- lmer(SA ~ Index1* LSI+
> (1 +
> > Index1+LSI |ID), data = LSIDATA, control = lmerControl(check.nobs.vs.nRE
> =
> > "ignore", optimizer ="bobyqa", check.conv.singular = .makeCC(action =
> > "ignore", tol = 1e-4)), REML=TRUE)
> >
> > summary(modelLSI_maineff_RE)
> > Linear mixed model fit by REML. t-tests use Satterthwaite's method
> > ['lmerModLmerTest']
> > Formula: SA ~ Index1 * LSI + (1 + Index1 + LSI | ID)
> > Data: LSIDATA
> > Control: lmerControl(check.nobs.vs.nRE = "ignore", optimizer = "bobyqa",
> > check.conv.singular = .makeCC(action = "ignore", tol = 1e-04))
> >
> > REML criterion at convergence: 7299.6
> >
> > Scaled residuals:
> > Min 1Q Median 3Q Max
> > -2.7289 -0.4832 -0.1449 0.3604 4.5715
> >
> > Random effects:
> > Groups Name Variance Std.Dev. Corr
> > ID (Intercept) 30.2919 5.5038
> > Index1 2.4765 1.5737 -0.15
> > LSI 0.1669 0.4085 -0.23 0.70
> > Residual 24.1793 4.9172
> > Number of obs: 1080, groups: ID, 493
> >
> > Fixed effects:
> > Estimate Std. Error df t value Pr(>|t|)
> > (Intercept) 24.68016 0.39722 313.43436 62.133 < 2e-16 ***
> > Index1 0.98495 0.23626 362.75018 4.169 3.83e-05 ***
> > LSI -0.05197 0.06226 273.85575 -0.835 0.4046
> > Index1:LSI 0.09797 0.04506 426.01185 2.174 0.0302 *
> > Signif. codes: 0 ?? 0.001 ?? 0.01 ?? 0.05 ?.? 0.1 ? ? 1
> >
> > Correlation of Fixed Effects:
> > (Intr) Index1 LSI
> > Index1 -0.645
> > LSI -0.032 0.057
> > Index1:LSI 0.015 0.037 -0.695
> >
> > I am a little vary of the output still as the error states that I have
> > equal observations as the number of random effects (i.e., 3 observations
> > per ID and 3 random effects). Hence, I am wondering whether I can
> simplify
> > the model as either of the below models and choose the one with the
> > best-fit statistics:
> >
> > modelLSI2 <- lmer(SA ~ Index1* LSI+ (1 |ID)+ (Index1+LSI -1|ID),data =
> > LSIDATA, control = lmerControl(optimizer ="bobyqa"), REML=TRUE) *OR*
> >
> > modelLSI3 <- lmer(SA ~ Index1* LSI+ (1+LSI |ID),data = LSIDATA, control =
> > lmerControl(optimizer ="bobyqa"), REML=TRUE) [image: example of dataset]
> > <https://i.sstatic.net/JcRKS2C9.png>
> >
> >        [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
> > [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @o|ntu@|e|k@@ @end|ng |rom he|@|nk|@||  Wed May  8 10:51:12 2024
From: @o|ntu@|e|k@@ @end|ng |rom he|@|nk|@|| (Leikas, Sointu S)
Date: Wed, 8 May 2024 08:51:12 +0000
Subject: [R-sig-ME] Number of random effects estimated with different lmer
 specifications
Message-ID: <AS2PR07MB914747C26F05DD83765E32A9E1E52@AS2PR07MB9147.eurprd07.prod.outlook.com>

Hello!

I'm confused about the error the lmer function sometimes gives, "Error: number of observations (=n) <= number of random effects (=n) for term (x| id); the random-effects parameters and the residual variance (or scale parameter) are probably unidentifiable"
Regarding this error, I'm confused about how the "number of random effects" is defined. My na?ve understanding was that if you have, say, 10 clusters, then a random intercept model estimates 10 random effects (i.e., a random intercept for all clusters). If you have one random intercept and one random slope, the model would estimate 10+10+1=21 random effects (random intercept and slope for all participants plus the correlation between them). With 2 random intercepts and 2 slopes it would be 10+10+10+10+2 (or 3, depending on the exact random effects syntax)=42 (or 43).

However, experimenting a little showed me that the correlations between random effects do not seem to be included into the number of random effects, so I'll forget them for now.

My main puzzlement comes from this: I generated a simple dataset of 10 clusters ("id") and 3 observations per cluster ("time"), as well as a level 1 predictor ("x") and ran the following models:


mod1<-lmer(y ~ x + time + (time|id) + (x|id), data=d)

This model converges (though the correlations between random effects are 1 and -1, which is probably just due to my sloppy data generation process) with no errors or warnings.

Then I ran this model:


mod2<-lmer(y ~ x + time + (time + x |id), data=d)



This model won't converge and I get the error:

Error: number of observations (=30) <= number of random effects (=30) for term (time + x | id); the random-effects parameters and the residual variance (or scale parameter) are probably unidentifiable

********************
I thought that the first model would estimate 40 random effects (two intercepts and two slopes for each of the 10 clusters), and the second model would estimate 30 (1 intercept and 2 slopes for each cluster). This seems to be correct regarding the second model, but why is the first model seemingly estimating less random effects (less than 40, and apparently also less than 30)?

I do apologize if this is very basic; I don't have math or proper stats background, just applied stats. I did read the manual, and several online discussions regarding this error before posting. I didn't find the answer in the manual (this may well be due to my own incompetence), and the online discussions (e.g. https://stats.stackexchange.com/questions/193678/number-of-random-effects-is-not-correct-in-lmer-model) seem to support my initial intuition, which however is clearly wrong. What am I missing?

Thank you in advance if someone can help!

-Sointu

*********************
My code for the above:

set.seed(12345)
id1<-c(1:10)
id<-rep(id1, each=3)
t<-c(1:3)
time<-rep(t, times=10)
x<-rnorm(30, 3,1)
err<-rnorm(10,0,1)
err2<-rep(err, each=3)
y<-3+0.2*x+0.3*time+rnorm(30)+err2
d<-data.frame(id, time, x, y)
mod1<-lmer(y ~ x + time + (time|id) + (x|id),data=d)
summary(mod1)
mod2<-lmer(y ~ x + time + (time + x|id),data=d)




	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Wed May  8 11:02:09 2024
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Wed, 8 May 2024 11:02:09 +0200
Subject: [R-sig-ME] 
 Number of random effects estimated with different lmer
 specifications
In-Reply-To: <AS2PR07MB914747C26F05DD83765E32A9E1E52@AS2PR07MB9147.eurprd07.prod.outlook.com>
References: <AS2PR07MB914747C26F05DD83765E32A9E1E52@AS2PR07MB9147.eurprd07.prod.outlook.com>
Message-ID: <CAJuCY5wJqp9nh18g5Wvcu4mPWOTd9EEPBX208wrFif781i5c4w@mail.gmail.com>

Dear Sointu,

You only need to count the number of parameters contributing to the linear
predictor. Hence not the parameters of the variance-covariance matrix.
1 random intercept + 2 random slopes = 3 parameters per ID
Times 10 ID yields 30 parameters
Your mod1 actually requires 2 times (1 random intercept + 1 random slope)
times 10 ID = 40 random effect parameters. IMHO lme4 should warn for this
too.
ranef(mod1)$id

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
*Postadres:* Koning Albert II-laan 15 bus 186, 1210 Brussel
*Poststukken die naar dit adres worden gestuurd, worden ingescand en
digitaal aan de geadresseerde bezorgd. Zo kan de Vlaamse overheid haar
dossiers volledig digitaal behandelen. Poststukken met de vermelding
?vertrouwelijk? worden niet ingescand, maar ongeopend aan de geadresseerde
bezorgd.*
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op wo 8 mei 2024 om 10:51 schreef Leikas, Sointu S <
sointu.leikas at helsinki.fi>:

> Hello!
>
> I'm confused about the error the lmer function sometimes gives, "Error:
> number of observations (=n) <= number of random effects (=n) for term (x|
> id); the random-effects parameters and the residual variance (or scale
> parameter) are probably unidentifiable"
> Regarding this error, I'm confused about how the "number of random
> effects" is defined. My na?ve understanding was that if you have, say, 10
> clusters, then a random intercept model estimates 10 random effects (i.e.,
> a random intercept for all clusters). If you have one random intercept and
> one random slope, the model would estimate 10+10+1=21 random effects
> (random intercept and slope for all participants plus the correlation
> between them). With 2 random intercepts and 2 slopes it would be
> 10+10+10+10+2 (or 3, depending on the exact random effects syntax)=42 (or
> 43).
>
> However, experimenting a little showed me that the correlations between
> random effects do not seem to be included into the number of random
> effects, so I'll forget them for now.
>
> My main puzzlement comes from this: I generated a simple dataset of 10
> clusters ("id") and 3 observations per cluster ("time"), as well as a level
> 1 predictor ("x") and ran the following models:
>
>
> mod1<-lmer(y ~ x + time + (time|id) + (x|id), data=d)
>
> This model converges (though the correlations between random effects are 1
> and -1, which is probably just due to my sloppy data generation process)
> with no errors or warnings.
>
> Then I ran this model:
>
>
> mod2<-lmer(y ~ x + time + (time + x |id), data=d)
>
>
>
> This model won't converge and I get the error:
>
> Error: number of observations (=30) <= number of random effects (=30) for
> term (time + x | id); the random-effects parameters and the residual
> variance (or scale parameter) are probably unidentifiable
>
> ********************
> I thought that the first model would estimate 40 random effects (two
> intercepts and two slopes for each of the 10 clusters), and the second
> model would estimate 30 (1 intercept and 2 slopes for each cluster). This
> seems to be correct regarding the second model, but why is the first model
> seemingly estimating less random effects (less than 40, and apparently also
> less than 30)?
>
> I do apologize if this is very basic; I don't have math or proper stats
> background, just applied stats. I did read the manual, and several online
> discussions regarding this error before posting. I didn't find the answer
> in the manual (this may well be due to my own incompetence), and the online
> discussions (e.g.
> https://stats.stackexchange.com/questions/193678/number-of-random-effects-is-not-correct-in-lmer-model)
> seem to support my initial intuition, which however is clearly wrong. What
> am I missing?
>
> Thank you in advance if someone can help!
>
> -Sointu
>
> *********************
> My code for the above:
>
> set.seed(12345)
> id1<-c(1:10)
> id<-rep(id1, each=3)
> t<-c(1:3)
> time<-rep(t, times=10)
> x<-rnorm(30, 3,1)
> err<-rnorm(10,0,1)
> err2<-rep(err, each=3)
> y<-3+0.2*x+0.3*time+rnorm(30)+err2
> d<-data.frame(id, time, x, y)
> mod1<-lmer(y ~ x + time + (time|id) + (x|id),data=d)
> summary(mod1)
> mod2<-lmer(y ~ x + time + (time + x|id),data=d)
>
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From @o|ntu@|e|k@@ @end|ng |rom he|@|nk|@||  Wed May  8 11:12:01 2024
From: @o|ntu@|e|k@@ @end|ng |rom he|@|nk|@|| (Leikas, Sointu S)
Date: Wed, 8 May 2024 09:12:01 +0000
Subject: [R-sig-ME] 
 Number of random effects estimated with different lmer
 specifications
In-Reply-To: <CAJuCY5wJqp9nh18g5Wvcu4mPWOTd9EEPBX208wrFif781i5c4w@mail.gmail.com>
References: <AS2PR07MB914747C26F05DD83765E32A9E1E52@AS2PR07MB9147.eurprd07.prod.outlook.com>
 <CAJuCY5wJqp9nh18g5Wvcu4mPWOTd9EEPBX208wrFif781i5c4w@mail.gmail.com>
Message-ID: <AS2PR07MB914702176C1236BD89658D36E1E52@AS2PR07MB9147.eurprd07.prod.outlook.com>

Dear Thierry,

thank you very much for the quick and helpful reply! I thought there had to be 40 but I trusted too much the error message/lack of it :) This really clarified things for me!

all the best,
Sointu

From: Thierry Onkelinx <thierry.onkelinx at inbo.be>
Sent: keskiviikko 8. toukokuuta 2024 12.02
To: Leikas, Sointu S <sointu.leikas at helsinki.fi>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Number of random effects estimated with different lmer specifications

Dear Sointu,

You only need to count the number of parameters contributing to the linear predictor. Hence not the parameters of the variance-covariance matrix.
1 random intercept + 2 random slopes = 3 parameters per ID
Times 10 ID yields 30 parameters
Your mod1 actually requires 2 times (1 random intercept + 1 random slope) times 10 ID = 40 random effect parameters. IMHO lme4 should warn for this too.
ranef(mod1)$id

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>
Havenlaan 88 bus 73, 1000 Brussel
Postadres: Koning Albert II-laan 15 bus 186, 1210 Brussel
Poststukken die naar dit adres worden gestuurd, worden ingescand en digitaal aan de geadresseerde bezorgd. Zo kan de Vlaamse overheid haar dossiers volledig digitaal behandelen. Poststukken met de vermelding ?vertrouwelijk? worden niet ingescand, maar ongeopend aan de geadresseerde bezorgd.
www.inbo.be<http://www.inbo.be>
///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

[https://inbo-website-prd-532750756126.s3-eu-west-1.amazonaws.com/inbologoleeuw_nl.png]<https://www.inbo.be/>


Op wo 8 mei 2024 om 10:51 schreef Leikas, Sointu S <sointu.leikas at helsinki.fi<mailto:sointu.leikas at helsinki.fi>>:
Hello!

I'm confused about the error the lmer function sometimes gives, "Error: number of observations (=n) <= number of random effects (=n) for term (x| id); the random-effects parameters and the residual variance (or scale parameter) are probably unidentifiable"
Regarding this error, I'm confused about how the "number of random effects" is defined. My na?ve understanding was that if you have, say, 10 clusters, then a random intercept model estimates 10 random effects (i.e., a random intercept for all clusters). If you have one random intercept and one random slope, the model would estimate 10+10+1=21 random effects (random intercept and slope for all participants plus the correlation between them). With 2 random intercepts and 2 slopes it would be 10+10+10+10+2 (or 3, depending on the exact random effects syntax)=42 (or 43).

However, experimenting a little showed me that the correlations between random effects do not seem to be included into the number of random effects, so I'll forget them for now.

My main puzzlement comes from this: I generated a simple dataset of 10 clusters ("id") and 3 observations per cluster ("time"), as well as a level 1 predictor ("x") and ran the following models:


mod1<-lmer(y ~ x + time + (time|id) + (x|id), data=d)

This model converges (though the correlations between random effects are 1 and -1, which is probably just due to my sloppy data generation process) with no errors or warnings.

Then I ran this model:


mod2<-lmer(y ~ x + time + (time + x |id), data=d)



This model won't converge and I get the error:

Error: number of observations (=30) <= number of random effects (=30) for term (time + x | id); the random-effects parameters and the residual variance (or scale parameter) are probably unidentifiable

********************
I thought that the first model would estimate 40 random effects (two intercepts and two slopes for each of the 10 clusters), and the second model would estimate 30 (1 intercept and 2 slopes for each cluster). This seems to be correct regarding the second model, but why is the first model seemingly estimating less random effects (less than 40, and apparently also less than 30)?

I do apologize if this is very basic; I don't have math or proper stats background, just applied stats. I did read the manual, and several online discussions regarding this error before posting. I didn't find the answer in the manual (this may well be due to my own incompetence), and the online discussions (e.g. https://stats.stackexchange.com/questions/193678/number-of-random-effects-is-not-correct-in-lmer-model) seem to support my initial intuition, which however is clearly wrong. What am I missing?

Thank you in advance if someone can help!

-Sointu

*********************
My code for the above:

set.seed(12345)
id1<-c(1:10)
id<-rep(id1, each=3)
t<-c(1:3)
time<-rep(t, times=10)
x<-rnorm(30, 3,1)
err<-rnorm(10,0,1)
err2<-rep(err, each=3)
y<-3+0.2*x+0.3*time+rnorm(30)+err2
d<-data.frame(id, time, x, y)
mod1<-lmer(y ~ x + time + (time|id) + (x|id),data=d)
summary(mod1)
mod2<-lmer(y ~ x + time + (time + x|id),data=d)




        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Fri May 10 02:07:57 2024
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 9 May 2024 20:07:57 -0400
Subject: [R-sig-ME] Discussion of convergence warnings in lme4
Message-ID: <a7941188-ec91-4a98-80e4-e3bb0f948082@gmail.com>

   Because I am a glutton for punishment, and because I value the input 
of this community, I invite constructive discussion on the value (or 
lack thereof) of convergence warnings in lme4 here:

https://github.com/lme4/lme4/issues/783''

   cheers
    Ben Bolker


From Ro@@@Boy|@n @end|ng |rom uc@|@edu  Fri Jun 14 07:05:23 2024
From: Ro@@@Boy|@n @end|ng |rom uc@|@edu (Boylan, Ross)
Date: Fri, 14 Jun 2024 05:05:23 +0000
Subject: [R-sig-ME] modifying the simulation in lme4
Message-ID: <BY3PR05MB8116D538DF21FB5FB5C8E41B87C22@BY3PR05MB8116.namprd05.prod.outlook.com>

I want to do simulations using GLMM's from lme4, but not exactly what the current simulate() offers.
In particular I want to generate cluster random effects that are limited to various subsets of the real line.  So in effect the simulation takes some extra arguments.

Does anyone have any thoughts about the best way to approach this?

At the moment, it looks to me as if the simplest route is to copy the code (from predict.R, I think) and modify it, placing the result in my package.  This wouldn't track future changes in the lme4 code and generally violates Don't Repeat Yourself, but it doesn't seem there are good alternatives.  The parts I'm interested in changing are sections of the current code, including functions defined inside the main function, as well as functions internal to lme4.  These do not seem amenable to the monkey-patching methods I've read about in R, which generally involve inserting extra namespaces.  Since the functions are in the package namespace (or even have function scope), I can't intercept them.

The current simulate(), or, more accurately, the .simulateFun() it calls, does a large amount of bookkeeping getting everything in suitable form, and I would like to use that.

My cases of interest only have random intercepts, which of course means some of the code that deals with more complicated random effects is not necessary, at least initially.

Thanks.
Ross Boylan


	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Sat Jun 15 21:31:26 2024
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sat, 15 Jun 2024 15:31:26 -0400
Subject: [R-sig-ME] modifying the simulation in lme4
In-Reply-To: <BY3PR05MB8116D538DF21FB5FB5C8E41B87C22@BY3PR05MB8116.namprd05.prod.outlook.com>
References: <BY3PR05MB8116D538DF21FB5FB5C8E41B87C22@BY3PR05MB8116.namprd05.prod.outlook.com>
Message-ID: <a4f9f071-b2ec-420a-9c67-e2bc2820d898@gmail.com>

   Depending on how quickly you want to put this into production (e.g. 
whether you would be willing to depend on a development version of 
lme4), I wonder if it would be possible to refactor/modularize 
.simulateFun() to allow hooks, or to return the components you need ... 
maybe open an issue on the lme4 issues list with more details?

On 2024-06-14 1:05 a.m., Boylan, Ross via R-sig-mixed-models wrote:
> I want to do simulations using GLMM's from lme4, but not exactly what the current simulate() offers.
> In particular I want to generate cluster random effects that are limited to various subsets of the real line.  So in effect the simulation takes some extra arguments.
> 
> Does anyone have any thoughts about the best way to approach this?
> 
> At the moment, it looks to me as if the simplest route is to copy the code (from predict.R, I think) and modify it, placing the result in my package.  This wouldn't track future changes in the lme4 code and generally violates Don't Repeat Yourself, but it doesn't seem there are good alternatives.  The parts I'm interested in changing are sections of the current code, including functions defined inside the main function, as well as functions internal to lme4.  These do not seem amenable to the monkey-patching methods I've read about in R, which generally involve inserting extra namespaces.  Since the functions are in the package namespace (or even have function scope), I can't intercept them.
> 
> The current simulate(), or, more accurately, the .simulateFun() it calls, does a large amount of bookkeeping getting everything in suitable form, and I would like to use that.
> 
> My cases of interest only have random intercepts, which of course means some of the code that deals with more complicated random effects is not necessary, at least initially.
> 
> Thanks.
> Ross Boylan
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From j@h@d||e|d @end|ng |rom ed@@c@uk  Mon Jun 17 15:05:52 2024
From: j@h@d||e|d @end|ng |rom ed@@c@uk (Jarrod Hadfield)
Date: Mon, 17 Jun 2024 13:05:52 +0000
Subject: [R-sig-ME] Fixed effects in nlmer
Message-ID: <72A72B5E-250F-414F-A991-BD3BE79A465F@ed.ac.uk>

Hi,

I would like to use nlmer to fit logistic growth curves to data where a number of replicate growth series are available for several clonal lines. Fitting the random effect structure is straightforward:

fm1 <- lme4:::nlmer(y ~ SSlogis(x, Asym, xmid, scal) ~  (Asym+xmid+scal | line) + (Asym+xmid+scal | rep), ?.)

allowing all 3 growth parameters to vary across lines and across replicates within lines.  However, I?ve had no success adding fixed effects to the model formula, and the examples on the help page do not have fixed effect predictors. For example, if lines could be divided into two groups (A and B) how would I allow Asym to differ between these two groups?

Thanks for any help,

Jarrod








The University of Edinburgh is a charitable body, registered in Scotland, with registration number SC005336. Is e buidheann carthannais a th? ann an Oilthigh Dh?n ?ideann, cl?raichte an Alba, ?ireamh cl?raidh SC005336.

From mtonc|c @end|ng |rom ||r|@un|r|@hr  Mon Jun 17 15:17:45 2024
From: mtonc|c @end|ng |rom ||r|@un|r|@hr (marKo)
Date: Mon, 17 Jun 2024 15:17:45 +0200
Subject: [R-sig-ME] Fixed effects in nlmer
In-Reply-To: <72A72B5E-250F-414F-A991-BD3BE79A465F@ed.ac.uk>
References: <72A72B5E-250F-414F-A991-BD3BE79A465F@ed.ac.uk>
Message-ID: <cf90593c-b64a-4fc9-ab67-120c887fe4cd@ffri.uniri.hr>

Hi.

How about adding it via an interaction effect?
Something like: y ~ SSlogis(x, Asym, Asym:lines_cathegorical, xmid, scal)
The rest should be more or less the same.

Hope that it make sense.


Cheers,

Marko


  On 17. 06. 2024. 15:05, Jarrod Hadfield wrote:
> Hi,
> 
> I would like to use nlmer to fit logistic growth curves to data where a number of replicate growth series are available for several clonal lines. Fitting the random effect structure is straightforward:
> 
> fm1 <- lme4:::nlmer(y ~ SSlogis(x, Asym, xmid, scal) ~  (Asym+xmid+scal | line) + (Asym+xmid+scal | rep), ?.)
> 
> allowing all 3 growth parameters to vary across lines and across replicates within lines.  However, I?ve had no success adding fixed effects to the model formula, and the examples on the help page do not have fixed effect predictors. For example, if lines could be divided into two groups (A and B) how would I allow Asym to differ between these two groups?
> 
> Thanks for any help,
> 
> Jarrod
> 
> 
> 
> 
> 
> 
> 
> 
> The University of Edinburgh is a charitable body, registered in Scotland, with registration number SC005336. Is e buidheann carthannais a th? ann an Oilthigh Dh?n ?ideann, cl?raichte an Alba, ?ireamh cl?raidh SC005336.
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbo|ker @end|ng |rom gm@||@com  Mon Jun 17 15:32:24 2024
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 17 Jun 2024 09:32:24 -0400
Subject: [R-sig-ME] Fixed effects in nlmer
In-Reply-To: <cf90593c-b64a-4fc9-ab67-120c887fe4cd@ffri.uniri.hr>
References: <72A72B5E-250F-414F-A991-BD3BE79A465F@ed.ac.uk>
 <cf90593c-b64a-4fc9-ab67-120c887fe4cd@ffri.uniri.hr>
Message-ID: <77c1d451-985e-419a-81e6-455c44b49078@gmail.com>

    Nice idea, but I don't see how that would work.  The terms in a 
nonlinear mixed model aren't automatically expanded using linear model 
formulas ...

On 2024-06-17 9:17 a.m., marKo via R-sig-mixed-models wrote:
> Hi.
> 
> How about adding it via an interaction effect?
> Something like: y ~ SSlogis(x, Asym, Asym:lines_cathegorical, xmid, scal)
> The rest should be more or less the same.
> 
> Hope that it make sense.
> 
> 
> Cheers,
> 
> Marko
> 
> 
>  ?On 17. 06. 2024. 15:05, Jarrod Hadfield wrote:
>> Hi,
>>
>> I would like to use nlmer to fit logistic growth curves to data where 
>> a number of replicate growth series are available for several clonal 
>> lines. Fitting the random effect structure is straightforward:
>>
>> fm1 <- lme4:::nlmer(y ~ SSlogis(x, Asym, xmid, scal) ~  
>> (Asym+xmid+scal | line) + (Asym+xmid+scal | rep), ?.)
>>
>> allowing all 3 growth parameters to vary across lines and across 
>> replicates within lines.? However, I?ve had no success adding fixed 
>> effects to the model formula, and the examples on the help page do not 
>> have fixed effect predictors. For example, if lines could be divided 
>> into two groups (A and B) how would I allow Asym to differ between 
>> these two groups?
>>
>> Thanks for any help,
>>
>> Jarrod
>>
>>
>>
>>
>>
>>
>>
>>
>> The University of Edinburgh is a charitable body, registered in 
>> Scotland, with registration number SC005336. Is e buidheann 
>> carthannais a th? ann an Oilthigh Dh?n ?ideann, cl?raichte an Alba, 
>> ?ireamh cl?raidh SC005336.
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics
 > E-mail is sent at my convenience; I don't expect replies outside of 
working hours.


From gh@m|rz@gh@der| @end|ng |rom uok@@c@|r  Mon Jun 17 16:01:25 2024
From: gh@m|rz@gh@der| @end|ng |rom uok@@c@|r (Ghader Mirzaghaderi)
Date: Mon, 17 Jun 2024 14:01:25 +0000
Subject: [R-sig-ME] Paired ttest using lme4
Message-ID: <2094dcb0fef24f318e7b77049bc8bcd0@uok.ac.ir>



Dear Ben,

I appreciate your letting me know how the paired t-test is done using lmer function.

using the following code, the p-value from lmer is different from the paired t.test.

Many thanks

Best regards,

Ghader


tt <- read.table(text = "
g y
1 2.39
1 2.59
1 2.44
2 4.34
2 2.89
2 3.77
", header = T)
t.test(tt$y ~ tt$g, var.equal = F, paired = T)


tt2 <- read.table(text = "
id  g y
a1 a 2.39
a2 a 2.59
a3 a 2.44
a1 b 4.34
a2 b 2.89
a3 b 3.77
", header = T)
library(lme4)
library(emmeans)
anova(lmerTest::lmer(y ~ g + (1 | id), data = tt2))



	[[alternative HTML version deleted]]


From j@h@d||e|d @end|ng |rom ed@@c@uk  Mon Jun 17 16:15:32 2024
From: j@h@d||e|d @end|ng |rom ed@@c@uk (Jarrod Hadfield)
Date: Mon, 17 Jun 2024 14:15:32 +0000
Subject: [R-sig-ME] Paired ttest using lme4
In-Reply-To: <2094dcb0fef24f318e7b77049bc8bcd0@uok.ac.ir>
References: <2094dcb0fef24f318e7b77049bc8bcd0@uok.ac.ir>
Message-ID: <A6561A41-E32A-4F07-9C1C-CDFF943EFB74@ed.ac.uk>

Hi Ghader,

a) tt is not set up in the correct way for a pair t-test.
b) the mixed model assumes the variances are equal, but the call to t.test specifies them to be different.

t.test(tt2[1:3,3], tt2[4:6,3], var.equal=TRUE)

is identical to lmer.

Cheers,

Jarrod



On 17 Jun 2024, at 16:01, Ghader Mirzaghaderi via R-sig-mixed-models <r-sig-mixed-models at r-project.org> wrote:

var.equal = F

The University of Edinburgh is a charitable body, registered in Scotland, with registration number SC005336. Is e buidheann carthannais a th' ann an Oilthigh Dh?n ?ideann, cl?raichte an Alba, ?ireamh cl?raidh SC005336.

	[[alternative HTML version deleted]]


From mtonc|c @end|ng |rom ||r|@un|r|@hr  Tue Jun 18 15:03:27 2024
From: mtonc|c @end|ng |rom ||r|@un|r|@hr (marKo)
Date: Tue, 18 Jun 2024 15:03:27 +0200
Subject: [R-sig-ME] Fixed effects in nlmer
In-Reply-To: <77c1d451-985e-419a-81e6-455c44b49078@gmail.com>
References: <72A72B5E-250F-414F-A991-BD3BE79A465F@ed.ac.uk>
 <cf90593c-b64a-4fc9-ab67-120c887fe4cd@ffri.uniri.hr>
 <77c1d451-985e-419a-81e6-455c44b49078@gmail.com>
Message-ID: <cc7be015-c323-4659-b460-e78aa459cdf0@ffri.uniri.hr>

Hi Ben and group,

Is this a computational problem? How to solve it?
Do you have (on hand) some resources (links) to explain why? Used to see 
interaction used quite a bit in logistic models (not mixed models 
though, not recall any).

Thanks, and sorry for my ignorance.


Cheers,

Marko

On 17. 06. 2024. 15:32, Ben Bolker wrote:
>  ?? Nice idea, but I don't see how that would work.? The terms in a 
> nonlinear mixed model aren't automatically expanded using linear model 
> formulas ...
> 
> On 2024-06-17 9:17 a.m., marKo via R-sig-mixed-models wrote:
>> Hi.
>>
>> How about adding it via an interaction effect?
>> Something like: y ~ SSlogis(x, Asym, Asym:lines_cathegorical, xmid, scal)
>> The rest should be more or less the same.
>>
>> Hope that it make sense.
>>
>>
>> Cheers,
>>
>> Marko
>>
>>
>> ??On 17. 06. 2024. 15:05, Jarrod Hadfield wrote:
>>> Hi,
>>>
>>> I would like to use nlmer to fit logistic growth curves to data where 
>>> a number of replicate growth series are available for several clonal 
>>> lines. Fitting the random effect structure is straightforward:
>>>
>>> fm1 <- lme4:::nlmer(y ~ SSlogis(x, Asym, xmid, scal) ~ 
>>> (Asym+xmid+scal | line) + (Asym+xmid+scal | rep), ?.)
>>>
>>> allowing all 3 growth parameters to vary across lines and across 
>>> replicates within lines.? However, I?ve had no success adding fixed 
>>> effects to the model formula, and the examples on the help page do 
>>> not have fixed effect predictors. For example, if lines could be 
>>> divided into two groups (A and B) how would I allow Asym to differ 
>>> between these two groups?
>>>
>>> Thanks for any help,
>>>
>>> Jarrod
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> The University of Edinburgh is a charitable body, registered in 
>>> Scotland, with registration number SC005336. Is e buidheann 
>>> carthannais a th? ann an Oilthigh Dh?n ?ideann, cl?raichte an Alba, 
>>> ?ireamh cl?raidh SC005336.
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From ru@@e||-|enth @end|ng |rom u|ow@@edu  Tue Jun 18 17:16:55 2024
From: ru@@e||-|enth @end|ng |rom u|ow@@edu (Lenth, Russell V)
Date: Tue, 18 Jun 2024 15:16:55 +0000
Subject: [R-sig-ME] Paired ttest using lme4
In-Reply-To: <mailman.20311.3.1718704801.33228.r-sig-mixed-models@r-project.org>
References: <mailman.20311.3.1718704801.33228.r-sig-mixed-models@r-project.org>
Message-ID: <DM6PR04MB44741531D26F9FA4F7F947D3F1CE2@DM6PR04MB4474.namprd04.prod.outlook.com>

Ghader,

An odd thing about this solution is that the emmeans package is loaded, but not used. Assuming (I hope so) that you care to see the estimated means and then test the difference, I suggest:

    mod <- lmerTest::lmer(y ~ g + (1 | id), data = tt2)

    ( emm <- emmeans(mod, "g") )      # obtain the estimated means

    pairs(emm)                                      # compare them

For this example, this does NOT yield the same P value as the anova test, and that is because the anova test is clearly wrong! (It shows that there are 4 d.f., but there are only 3 subjects so there should be 2 d.f. as you will obtain using the code above.)

After testing, I found that the error is due to a singularity issue in fitting the model. That issue is due to the fact that the 'id' effect is estimated as zero, hence we are not really estimating a subject effect, and hence we in a sense don't really have a paired t test. If you include real subject variations in the data, e.g., 

    tt2$y = tt2$y + rep(c(3,-2,-1), 2)

and repeat the procedure, there will be no singularity issues in fitting the model and the anova and emmeans results will agree on 2 d.f.
--
Russ Lenth
U of Iowa

-----Original Message-----

Date: Mon, 17 Jun 2024 14:01:25 +0000
From: Ghader Mirzaghaderi <gh.mirzaghaderi at uok.ac.ir>
To: "r-sig-mixed-models at r-project.org"
	<r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] Paired ttest using lme4
Message-ID: <2094dcb0fef24f318e7b77049bc8bcd0 at uok.ac.ir>
Content-Type: text/plain; charset="utf-8"



Dear Ben,

I appreciate your letting me know how the paired t-test is done using lmer function.

using the following code, the p-value from lmer is different from the paired t.test.

Many thanks

Best regards,

Ghader


tt <- read.table(text = "
g y
1 2.39
1 2.59
1 2.44
2 4.34
2 2.89
2 3.77
", header = T)
t.test(tt$y ~ tt$g, var.equal = F, paired = T)


tt2 <- read.table(text = "
id  g y
a1 a 2.39
a2 a 2.59
a3 a 2.44
a1 b 4.34
a2 b 2.89
a3 b 3.77
", header = T)
library(lme4)
library(emmeans)
anova(lmerTest::lmer(y ~ g + (1 | id), data = tt2))


From c@r|o@@mb@rboz@ @end|ng |rom gm@||@com  Tue Jun 18 11:59:28 2024
From: c@r|o@@mb@rboz@ @end|ng |rom gm@||@com (Carlos Barboza)
Date: Tue, 18 Jun 2024 06:59:28 -0300
Subject: [R-sig-ME] Comparing mixed models
In-Reply-To: <CAGAvxRn2AB=ZhkQWtKYLFg9pRj9mT=D5t=7RpM-aJuoj+q3=Xw@mail.gmail.com>
References: <CAGAvxRn2AB=ZhkQWtKYLFg9pRj9mT=D5t=7RpM-aJuoj+q3=Xw@mail.gmail.com>
Message-ID: <CAGAvxRkBNViFfPg-9n3CDvD2esY8YTYWo_FajzN+2OSzbrj6Zg@mail.gmail.com>

Dear all,
why Anova type III function gives different results if I change the names
of a categorical factor? I suspect that is because contrast type but it's
something strange get different results using the same data.
thank you

Em s?b., 7 de mai. de 2016 ?s 12:26, Carlos Barboza <
carlosambarboza at gmail.com> escreveu:

> Dear Dr. Ben Bolker
>
> My name is Carlos Barboza and I am a Marine Biologist from the Rio de
> Janeiro University, Brazil. First it's a pleasure to again have the
> opportunity to send you a message.The reason for it is a simple doubt:
> Can I compare AIC from:
>
> 1. glmmADMB: Density ~ 1 + 1|Site
>
> 2. glmmADMB: Density ~ Sector + 1|Site + Cage
>
> Note that they have different random and fixed structures. I know that
> this is not the best choice to model selection but, I think that the AIC
> values can be compared.
>
> thank you very much for your attention
>
>
>   is Cage a random effect?  Are you intentionally leaving out the
> intercept in the second case (it will be included anyway unless you
> use -1)?  In any case, I don't see any obvious reason you can't
> compare AIC values; see
>
> https://rawgit.com/bbolker/mixedmodels-misc/master/glmmFAQ.html#can-i-use-aic-for-mixed-models-how-do-i-count-the-number-of-degrees-of-freedom-for-a-random-effect
>
>   Follow-ups to r-sig-mixed-models at r-project.org, please ...
>
> sorry, yes, cage was included only to examplify a different random
> structure in the second case...it should be coded (1|Site) + (1|Cage)
> yes, I know that the intercept will be included in the second model
>
> it's an example of comparing AIC values from mixed models with different
> fixed and random structures:
>
> 1. Density ~ 1 + 1|Site
>
> 2. Density ~ Sector + 1|Site + 1|Cage
>
> comparing AIC...I beleive that both values can be compared
>
> again, thank you very much for your very fast message
>
>
>
>

-- 
Universidade Federal do Rio de Janeiro (UFRJ)
Instituto de Biodiversidade e Sustentabilidade - NUPEM
Caixa Postal 119331, CEP 27910-970
Maca?, RJ, Brazil
https://www.macae.ufrj.br/nupem/
http://lattes.cnpq.br/3629226944950076
https://scholar.google.com.br/citations?user=p-PRvd4AAAAJ&hl=pt-BR
https://www.researchgate.net/profile/Carlos_Barboza3

	[[alternative HTML version deleted]]


From c@r|o@@mb@rboz@ @end|ng |rom gm@||@com  Tue Jun 18 11:59:57 2024
From: c@r|o@@mb@rboz@ @end|ng |rom gm@||@com (Carlos Barboza)
Date: Tue, 18 Jun 2024 06:59:57 -0300
Subject: [R-sig-ME] Comparing mixed models
In-Reply-To: <CAGAvxRkBNViFfPg-9n3CDvD2esY8YTYWo_FajzN+2OSzbrj6Zg@mail.gmail.com>
References: <CAGAvxRn2AB=ZhkQWtKYLFg9pRj9mT=D5t=7RpM-aJuoj+q3=Xw@mail.gmail.com>
 <CAGAvxRkBNViFfPg-9n3CDvD2esY8YTYWo_FajzN+2OSzbrj6Zg@mail.gmail.com>
Message-ID: <CAGAvxR=nWu+O4ohNAZXwAJv=r7noH8dY1DY7Ba3a22fw_Gj4Jw@mail.gmail.com>

sorry, Anova type III function form car package in R

Em ter., 18 de jun. de 2024 ?s 06:59, Carlos Barboza <
carlosambarboza at gmail.com> escreveu:

> Dear all,
> why Anova type III function gives different results if I change the names
> of a categorical factor? I suspect that is because contrast type but it's
> something strange get different results using the same data.
> thank you
>
> Em s?b., 7 de mai. de 2016 ?s 12:26, Carlos Barboza <
> carlosambarboza at gmail.com> escreveu:
>
>> Dear Dr. Ben Bolker
>>
>> My name is Carlos Barboza and I am a Marine Biologist from the Rio de
>> Janeiro University, Brazil. First it's a pleasure to again have the
>> opportunity to send you a message.The reason for it is a simple doubt:
>> Can I compare AIC from:
>>
>> 1. glmmADMB: Density ~ 1 + 1|Site
>>
>> 2. glmmADMB: Density ~ Sector + 1|Site + Cage
>>
>> Note that they have different random and fixed structures. I know that
>> this is not the best choice to model selection but, I think that the AIC
>> values can be compared.
>>
>> thank you very much for your attention
>>
>>
>>   is Cage a random effect?  Are you intentionally leaving out the
>> intercept in the second case (it will be included anyway unless you
>> use -1)?  In any case, I don't see any obvious reason you can't
>> compare AIC values; see
>>
>> https://rawgit.com/bbolker/mixedmodels-misc/master/glmmFAQ.html#can-i-use-aic-for-mixed-models-how-do-i-count-the-number-of-degrees-of-freedom-for-a-random-effect
>>
>>   Follow-ups to r-sig-mixed-models at r-project.org, please ...
>>
>> sorry, yes, cage was included only to examplify a different random
>> structure in the second case...it should be coded (1|Site) + (1|Cage)
>> yes, I know that the intercept will be included in the second model
>>
>> it's an example of comparing AIC values from mixed models with different
>> fixed and random structures:
>>
>> 1. Density ~ 1 + 1|Site
>>
>> 2. Density ~ Sector + 1|Site + 1|Cage
>>
>> comparing AIC...I beleive that both values can be compared
>>
>> again, thank you very much for your very fast message
>>
>>
>>
>>
>
> --
> Universidade Federal do Rio de Janeiro (UFRJ)
> Instituto de Biodiversidade e Sustentabilidade - NUPEM
> Caixa Postal 119331, CEP 27910-970
> Maca?, RJ, Brazil
> https://www.macae.ufrj.br/nupem/
> http://lattes.cnpq.br/3629226944950076
> https://scholar.google.com.br/citations?user=p-PRvd4AAAAJ&hl=pt-BR
> https://www.researchgate.net/profile/Carlos_Barboza3
>


-- 
Universidade Federal do Rio de Janeiro (UFRJ)
Instituto de Biodiversidade e Sustentabilidade - NUPEM
Caixa Postal 119331, CEP 27910-970
Maca?, RJ, Brazil
https://www.macae.ufrj.br/nupem/
http://lattes.cnpq.br/3629226944950076
https://scholar.google.com.br/citations?user=p-PRvd4AAAAJ&hl=pt-BR
https://www.researchgate.net/profile/Carlos_Barboza3

	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Wed Jun 19 15:14:55 2024
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Wed, 19 Jun 2024 09:14:55 -0400
Subject: [R-sig-ME] Comparing mixed models
In-Reply-To: <CAGAvxR=nWu+O4ohNAZXwAJv=r7noH8dY1DY7Ba3a22fw_Gj4Jw@mail.gmail.com>
References: <CAGAvxRn2AB=ZhkQWtKYLFg9pRj9mT=D5t=7RpM-aJuoj+q3=Xw@mail.gmail.com>
 <CAGAvxRkBNViFfPg-9n3CDvD2esY8YTYWo_FajzN+2OSzbrj6Zg@mail.gmail.com>
 <CAGAvxR=nWu+O4ohNAZXwAJv=r7noH8dY1DY7Ba3a22fw_Gj4Jw@mail.gmail.com>
Message-ID: <8c92a556-09cf-4372-bfc8-e8d294eed43a@mcmaster.ca>

Dear Carlos,

 From ?Anova:

"Warning

Be careful of type-III tests: For a traditional multifactor ANOVA model 
with interactions, for example, these tests will normally only be 
sensible when using contrasts that, for different terms, are orthogonal 
in the row-basis of the model, such as those produced by contr.sum, 
contr.poly, or contr.helmert, but not by the default contr.treatment. In 
a model that contains factors, numeric covariates, and interactions, 
main-effect tests for factors will be for differences over the origin. 
In contrast (pun intended), type-II tests are invariant with respect to 
(full-rank) contrast coding. If you don't understand this issue, then 
you probably shouldn't use Anova for type-III tests."

I hope this helps,
  John

-- 
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://www.john-fox.ca/
--
On 2024-06-18 5:59 a.m., Carlos Barboza wrote:
> [You don't often get email from carlosambarboza at gmail.com. Learn why this is important at https://aka.ms/LearnAboutSenderIdentification ]
> 
> Caution: External email.
> 
> 
> sorry, Anova type III function form car package in R
> 
> Em ter., 18 de jun. de 2024 ?s 06:59, Carlos Barboza <
> carlosambarboza at gmail.com> escreveu:
> 
>> Dear all,
>> why Anova type III function gives different results if I change the names
>> of a categorical factor? I suspect that is because contrast type but it's
>> something strange get different results using the same data.
>> thank you
>>
>> Em s?b., 7 de mai. de 2016 ?s 12:26, Carlos Barboza <
>> carlosambarboza at gmail.com> escreveu:
>>
>>> Dear Dr. Ben Bolker
>>>
>>> My name is Carlos Barboza and I am a Marine Biologist from the Rio de
>>> Janeiro University, Brazil. First it's a pleasure to again have the
>>> opportunity to send you a message.The reason for it is a simple doubt:
>>> Can I compare AIC from:
>>>
>>> 1. glmmADMB: Density ~ 1 + 1|Site
>>>
>>> 2. glmmADMB: Density ~ Sector + 1|Site + Cage
>>>
>>> Note that they have different random and fixed structures. I know that
>>> this is not the best choice to model selection but, I think that the AIC
>>> values can be compared.
>>>
>>> thank you very much for your attention
>>>
>>>
>>>    is Cage a random effect?  Are you intentionally leaving out the
>>> intercept in the second case (it will be included anyway unless you
>>> use -1)?  In any case, I don't see any obvious reason you can't
>>> compare AIC values; see
>>>
>>> https://rawgit.com/bbolker/mixedmodels-misc/master/glmmFAQ.html#can-i-use-aic-for-mixed-models-how-do-i-count-the-number-of-degrees-of-freedom-for-a-random-effect
>>>
>>>    Follow-ups to r-sig-mixed-models at r-project.org, please ...
>>>
>>> sorry, yes, cage was included only to examplify a different random
>>> structure in the second case...it should be coded (1|Site) + (1|Cage)
>>> yes, I know that the intercept will be included in the second model
>>>
>>> it's an example of comparing AIC values from mixed models with different
>>> fixed and random structures:
>>>
>>> 1. Density ~ 1 + 1|Site
>>>
>>> 2. Density ~ Sector + 1|Site + 1|Cage
>>>
>>> comparing AIC...I beleive that both values can be compared
>>>
>>> again, thank you very much for your very fast message
>>>
>>>
>>>
>>>
>>
>> --
>> Universidade Federal do Rio de Janeiro (UFRJ)
>> Instituto de Biodiversidade e Sustentabilidade - NUPEM
>> Caixa Postal 119331, CEP 27910-970
>> Maca?, RJ, Brazil
>> https://www.macae.ufrj.br/nupem/
>> http://lattes.cnpq.br/3629226944950076
>> https://scholar.google.com.br/citations?user=p-PRvd4AAAAJ&hl=pt-BR
>> https://www.researchgate.net/profile/Carlos_Barboza3
>>
> 
> 
> --
> Universidade Federal do Rio de Janeiro (UFRJ)
> Instituto de Biodiversidade e Sustentabilidade - NUPEM
> Caixa Postal 119331, CEP 27910-970
> Maca?, RJ, Brazil
> https://www.macae.ufrj.br/nupem/
> http://lattes.cnpq.br/3629226944950076
> https://scholar.google.com.br/citations?user=p-PRvd4AAAAJ&hl=pt-BR
> https://www.researchgate.net/profile/Carlos_Barboza3
> 
>          [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From c@r|o@@mb@rboz@ @end|ng |rom gm@||@com  Wed Jun 19 17:13:01 2024
From: c@r|o@@mb@rboz@ @end|ng |rom gm@||@com (Carlos Barboza)
Date: Wed, 19 Jun 2024 12:13:01 -0300
Subject: [R-sig-ME] Comparing mixed models
In-Reply-To: <8c92a556-09cf-4372-bfc8-e8d294eed43a@mcmaster.ca>
References: <CAGAvxRn2AB=ZhkQWtKYLFg9pRj9mT=D5t=7RpM-aJuoj+q3=Xw@mail.gmail.com>
 <CAGAvxRkBNViFfPg-9n3CDvD2esY8YTYWo_FajzN+2OSzbrj6Zg@mail.gmail.com>
 <CAGAvxR=nWu+O4ohNAZXwAJv=r7noH8dY1DY7Ba3a22fw_Gj4Jw@mail.gmail.com>
 <8c92a556-09cf-4372-bfc8-e8d294eed43a@mcmaster.ca>
Message-ID: <CAGAvxR=7Rrq=Fc1EejZj00E9fkCCzmLmrNEty8jq=6ACnr1=oQ@mail.gmail.com>

Thank you Jonh for you answer
I indeed used contr.sum, contr.poly before to model definition
after that I get the same results using any names for the same factors
but, what do you exactly mean when testing for factors for differences over
the origin?
best regards
Carlos


Em qua., 19 de jun. de 2024 ?s 10:14, John Fox <jfox at mcmaster.ca> escreveu:

> Dear Carlos,
>
>  From ?Anova:
>
> "Warning
>
> Be careful of type-III tests: For a traditional multifactor ANOVA model
> with interactions, for example, these tests will normally only be
> sensible when using contrasts that, for different terms, are orthogonal
> in the row-basis of the model, such as those produced by contr.sum,
> contr.poly, or contr.helmert, but not by the default contr.treatment. In
> a model that contains factors, numeric covariates, and interactions,
> main-effect tests for factors will be for differences over the origin.
> In contrast (pun intended), type-II tests are invariant with respect to
> (full-rank) contrast coding. If you don't understand this issue, then
> you probably shouldn't use Anova for type-III tests."
>
> I hope this helps,
>   John
>
> --
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> web: https://www.john-fox.ca/
> --
> On 2024-06-18 5:59 a.m., Carlos Barboza wrote:
> > [You don't often get email from carlosambarboza at gmail.com. Learn why
> this is important at https://aka.ms/LearnAboutSenderIdentification ]
> >
> > Caution: External email.
> >
> >
> > sorry, Anova type III function form car package in R
> >
> > Em ter., 18 de jun. de 2024 ?s 06:59, Carlos Barboza <
> > carlosambarboza at gmail.com> escreveu:
> >
> >> Dear all,
> >> why Anova type III function gives different results if I change the
> names
> >> of a categorical factor? I suspect that is because contrast type but
> it's
> >> something strange get different results using the same data.
> >> thank you
> >>
> >> Em s?b., 7 de mai. de 2016 ?s 12:26, Carlos Barboza <
> >> carlosambarboza at gmail.com> escreveu:
> >>
> >>> Dear Dr. Ben Bolker
> >>>
> >>> My name is Carlos Barboza and I am a Marine Biologist from the Rio de
> >>> Janeiro University, Brazil. First it's a pleasure to again have the
> >>> opportunity to send you a message.The reason for it is a simple doubt:
> >>> Can I compare AIC from:
> >>>
> >>> 1. glmmADMB: Density ~ 1 + 1|Site
> >>>
> >>> 2. glmmADMB: Density ~ Sector + 1|Site + Cage
> >>>
> >>> Note that they have different random and fixed structures. I know that
> >>> this is not the best choice to model selection but, I think that the
> AIC
> >>> values can be compared.
> >>>
> >>> thank you very much for your attention
> >>>
> >>>
> >>>    is Cage a random effect?  Are you intentionally leaving out the
> >>> intercept in the second case (it will be included anyway unless you
> >>> use -1)?  In any case, I don't see any obvious reason you can't
> >>> compare AIC values; see
> >>>
> >>>
> https://rawgit.com/bbolker/mixedmodels-misc/master/glmmFAQ.html#can-i-use-aic-for-mixed-models-how-do-i-count-the-number-of-degrees-of-freedom-for-a-random-effect
> >>>
> >>>    Follow-ups to r-sig-mixed-models at r-project.org, please ...
> >>>
> >>> sorry, yes, cage was included only to examplify a different random
> >>> structure in the second case...it should be coded (1|Site) + (1|Cage)
> >>> yes, I know that the intercept will be included in the second model
> >>>
> >>> it's an example of comparing AIC values from mixed models with
> different
> >>> fixed and random structures:
> >>>
> >>> 1. Density ~ 1 + 1|Site
> >>>
> >>> 2. Density ~ Sector + 1|Site + 1|Cage
> >>>
> >>> comparing AIC...I beleive that both values can be compared
> >>>
> >>> again, thank you very much for your very fast message
> >>>
> >>>
> >>>
> >>>
> >>
> >> --
> >> Universidade Federal do Rio de Janeiro (UFRJ)
> >> Instituto de Biodiversidade e Sustentabilidade - NUPEM
> >> Caixa Postal 119331, CEP 27910-970
> >> Maca?, RJ, Brazil
> >> https://www.macae.ufrj.br/nupem/
> >> http://lattes.cnpq.br/3629226944950076
> >> https://scholar.google.com.br/citations?user=p-PRvd4AAAAJ&hl=pt-BR
> >> https://www.researchgate.net/profile/Carlos_Barboza3
> >>
> >
> >
> > --
> > Universidade Federal do Rio de Janeiro (UFRJ)
> > Instituto de Biodiversidade e Sustentabilidade - NUPEM
> > Caixa Postal 119331, CEP 27910-970
> > Maca?, RJ, Brazil
> > https://www.macae.ufrj.br/nupem/
> > http://lattes.cnpq.br/3629226944950076
> > https://scholar.google.com.br/citations?user=p-PRvd4AAAAJ&hl=pt-BR
> > https://www.researchgate.net/profile/Carlos_Barboza3
> >
> >          [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

-- 
Universidade Federal do Rio de Janeiro (UFRJ)
Instituto de Biodiversidade e Sustentabilidade - NUPEM
Caixa Postal 119331, CEP 27910-970
Maca?, RJ, Brazil
https://www.macae.ufrj.br/nupem/
http://lattes.cnpq.br/3629226944950076
https://scholar.google.com.br/citations?user=p-PRvd4AAAAJ&hl=pt-BR
https://www.researchgate.net/profile/Carlos_Barboza3

	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Wed Jun 19 17:20:07 2024
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Wed, 19 Jun 2024 11:20:07 -0400
Subject: [R-sig-ME] Comparing mixed models
In-Reply-To: <CAGAvxR=7Rrq=Fc1EejZj00E9fkCCzmLmrNEty8jq=6ACnr1=oQ@mail.gmail.com>
References: <CAGAvxRn2AB=ZhkQWtKYLFg9pRj9mT=D5t=7RpM-aJuoj+q3=Xw@mail.gmail.com>
 <CAGAvxRkBNViFfPg-9n3CDvD2esY8YTYWo_FajzN+2OSzbrj6Zg@mail.gmail.com>
 <CAGAvxR=nWu+O4ohNAZXwAJv=r7noH8dY1DY7Ba3a22fw_Gj4Jw@mail.gmail.com>
 <8c92a556-09cf-4372-bfc8-e8d294eed43a@mcmaster.ca>
 <CAGAvxR=7Rrq=Fc1EejZj00E9fkCCzmLmrNEty8jq=6ACnr1=oQ@mail.gmail.com>
Message-ID: <b5911c4e-8d5b-4896-8150-1566588f85a9@mcmaster.ca>

Dear Carlos,

On 2024-06-19 11:13 a.m., Carlos Barboza wrote:
> 	
> You don't often get email from carlosambarboza at gmail.com. Learn why this 
> is important <https://aka.ms/LearnAboutSenderIdentification>
> 	
> 
> 	
> Caution: External email.
> 
> 
> Thank you Jonh for you answer
> I indeed used contr.sum, contr.poly before to model definition
> after that I get the same results using any names for the same factors
> but,?what do you exactly mean when testing for factors for differences 
> over the origin?

The context here is models with both numeric and factor predictors. 
Consider a model of the form y ~ x*f, where x is numeric and f is a 
factor. A type-III test for the "main effect" of f tests for differences 
among factor levels where x = 0 (the origin).

More generally, the issues concerning "types" of tests in models with 
linear predictors are sufficiently complicated that discussing them in a 
help file or by email is likely to prove unsatisfactory. See the first 
two references in ?Anova for more details.

I hope this helps,
  John

> best regards
> Carlos
> 
> 
> Em qua., 19 de jun. de 2024 ?s 10:14, John Fox <jfox at mcmaster.ca 
> <mailto:jfox at mcmaster.ca>> escreveu:
> 
>     Dear Carlos,
> 
>      ?From ?Anova:
> 
>     "Warning
> 
>     Be careful of type-III tests: For a traditional multifactor ANOVA model
>     with interactions, for example, these tests will normally only be
>     sensible when using contrasts that, for different terms, are orthogonal
>     in the row-basis of the model, such as those produced by contr.sum,
>     contr.poly, or contr.helmert, but not by the default
>     contr.treatment. In
>     a model that contains factors, numeric covariates, and interactions,
>     main-effect tests for factors will be for differences over the origin.
>     In contrast (pun intended), type-II tests are invariant with respect to
>     (full-rank) contrast coding. If you don't understand this issue, then
>     you probably shouldn't use Anova for type-III tests."
> 
>     I hope this helps,
>      ? John
> 
>     -- 
>     John Fox, Professor Emeritus
>     McMaster University
>     Hamilton, Ontario, Canada
>     web: https://www.john-fox.ca/ <https://www.john-fox.ca/>
>     --
>     On 2024-06-18 5:59 a.m., Carlos Barboza wrote:
>      > [You don't often get email from carlosambarboza at gmail.com
>     <mailto:carlosambarboza at gmail.com>. Learn why this is important at
>     https://aka.ms/LearnAboutSenderIdentification
>     <https://aka.ms/LearnAboutSenderIdentification> ]
>      >
>      > Caution: External email.
>      >
>      >
>      > sorry, Anova type III function form car package in R
>      >
>      > Em ter., 18 de jun. de 2024 ?s 06:59, Carlos Barboza <
>      > carlosambarboza at gmail.com <mailto:carlosambarboza at gmail.com>>
>     escreveu:
>      >
>      >> Dear all,
>      >> why Anova type III function gives different results if I change
>     the names
>      >> of a categorical factor? I suspect that is because contrast type
>     but it's
>      >> something strange get different results using the same data.
>      >> thank you
>      >>
>      >> Em s?b., 7 de mai. de 2016 ?s 12:26, Carlos Barboza <
>      >> carlosambarboza at gmail.com <mailto:carlosambarboza at gmail.com>>
>     escreveu:
>      >>
>      >>> Dear Dr. Ben Bolker
>      >>>
>      >>> My name is Carlos Barboza and I am a Marine Biologist from the
>     Rio de
>      >>> Janeiro University, Brazil. First it's a pleasure to again have the
>      >>> opportunity to send you a message.The reason for it is a simple
>     doubt:
>      >>> Can I compare AIC from:
>      >>>
>      >>> 1. glmmADMB: Density ~ 1 + 1|Site
>      >>>
>      >>> 2. glmmADMB: Density ~ Sector + 1|Site + Cage
>      >>>
>      >>> Note that they have different random and fixed structures. I
>     know that
>      >>> this is not the best choice to model selection but, I think
>     that the AIC
>      >>> values can be compared.
>      >>>
>      >>> thank you very much for your attention
>      >>>
>      >>>
>      >>>? ? is Cage a random effect?? Are you intentionally leaving out the
>      >>> intercept in the second case (it will be included anyway unless you
>      >>> use -1)?? In any case, I don't see any obvious reason you can't
>      >>> compare AIC values; see
>      >>>
>      >>>
>     https://rawgit.com/bbolker/mixedmodels-misc/master/glmmFAQ.html#can-i-use-aic-for-mixed-models-how-do-i-count-the-number-of-degrees-of-freedom-for-a-random-effect <https://rawgit.com/bbolker/mixedmodels-misc/master/glmmFAQ.html#can-i-use-aic-for-mixed-models-how-do-i-count-the-number-of-degrees-of-freedom-for-a-random-effect>
>      >>>
>      >>>? ? Follow-ups to r-sig-mixed-models at r-project.org
>     <mailto:r-sig-mixed-models at r-project.org>, please ...
>      >>>
>      >>> sorry, yes, cage was included only to examplify a different random
>      >>> structure in the second case...it should be coded (1|Site) +
>     (1|Cage)
>      >>> yes, I know that the intercept will be included in the second model
>      >>>
>      >>> it's an example of comparing AIC values from mixed models with
>     different
>      >>> fixed and random structures:
>      >>>
>      >>> 1. Density ~ 1 + 1|Site
>      >>>
>      >>> 2. Density ~ Sector + 1|Site + 1|Cage
>      >>>
>      >>> comparing AIC...I beleive that both values can be compared
>      >>>
>      >>> again, thank you very much for your very fast message
>      >>>
>      >>>
>      >>>
>      >>>
>      >>
>      >> --
>      >> Universidade Federal do Rio de Janeiro (UFRJ)
>      >> Instituto de Biodiversidade e Sustentabilidade - NUPEM
>      >> Caixa Postal 119331, CEP 27910-970
>      >> Maca?, RJ, Brazil
>      >> https://www.macae.ufrj.br/nupem/ <https://www.macae.ufrj.br/nupem/>
>      >> http://lattes.cnpq.br/3629226944950076
>     <http://lattes.cnpq.br/3629226944950076>
>      >>
>     https://scholar.google.com.br/citations?user=p-PRvd4AAAAJ&hl=pt-BR
>     <https://scholar.google.com.br/citations?user=p-PRvd4AAAAJ&hl=pt-BR>
>      >> https://www.researchgate.net/profile/Carlos_Barboza3
>     <https://www.researchgate.net/profile/Carlos_Barboza3>
>      >>
>      >
>      >
>      > --
>      > Universidade Federal do Rio de Janeiro (UFRJ)
>      > Instituto de Biodiversidade e Sustentabilidade - NUPEM
>      > Caixa Postal 119331, CEP 27910-970
>      > Maca?, RJ, Brazil
>      > https://www.macae.ufrj.br/nupem/ <https://www.macae.ufrj.br/nupem/>
>      > http://lattes.cnpq.br/3629226944950076
>     <http://lattes.cnpq.br/3629226944950076>
>      >
>     https://scholar.google.com.br/citations?user=p-PRvd4AAAAJ&hl=pt-BR
>     <https://scholar.google.com.br/citations?user=p-PRvd4AAAAJ&hl=pt-BR>
>      > https://www.researchgate.net/profile/Carlos_Barboza3
>     <https://www.researchgate.net/profile/Carlos_Barboza3>
>      >
>      >? ? ? ? ? [[alternative HTML version deleted]]
>      >
>      > _______________________________________________
>      > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> 
> 
> 
> -- 
> Universidade Federal do Rio de Janeiro (UFRJ)
> Instituto de Biodiversidade e Sustentabilidade - NUPEM
> Caixa Postal 119331, CEP 27910-970
> Maca?, RJ, Brazil
> https://www.macae.ufrj.br/nupem/ <https://www.macae.ufrj.br/nupem/>
> http://lattes.cnpq.br/3629226944950076 
> <http://lattes.cnpq.br/3629226944950076>
> https://scholar.google.com.br/citations?user=p-PRvd4AAAAJ&hl=pt-BR 
> <https://scholar.google.com.br/citations?user=p-PRvd4AAAAJ&hl=pt-BR>
> https://www.researchgate.net/profile/Carlos_Barboza3 
> <https://www.researchgate.net/profile/Carlos_Barboza3>


From c@r|o@@mb@rboz@ @end|ng |rom gm@||@com  Wed Jun 19 17:42:34 2024
From: c@r|o@@mb@rboz@ @end|ng |rom gm@||@com (Carlos Barboza)
Date: Wed, 19 Jun 2024 12:42:34 -0300
Subject: [R-sig-ME] Comparing mixed models
In-Reply-To: <b5911c4e-8d5b-4896-8150-1566588f85a9@mcmaster.ca>
References: <CAGAvxRn2AB=ZhkQWtKYLFg9pRj9mT=D5t=7RpM-aJuoj+q3=Xw@mail.gmail.com>
 <CAGAvxRkBNViFfPg-9n3CDvD2esY8YTYWo_FajzN+2OSzbrj6Zg@mail.gmail.com>
 <CAGAvxR=nWu+O4ohNAZXwAJv=r7noH8dY1DY7Ba3a22fw_Gj4Jw@mail.gmail.com>
 <8c92a556-09cf-4372-bfc8-e8d294eed43a@mcmaster.ca>
 <CAGAvxR=7Rrq=Fc1EejZj00E9fkCCzmLmrNEty8jq=6ACnr1=oQ@mail.gmail.com>
 <b5911c4e-8d5b-4896-8150-1566588f85a9@mcmaster.ca>
Message-ID: <CAGAvxRkdjWr7Hd5N-dY7Y0PvoNjb5EhadTO67iK0XfT1hp5p3Q@mail.gmail.com>

Thank you,
yes I know that, it's the same interpretation when using the summary
function when we have f*x
thank you
Carlos

Em qua., 19 de jun. de 2024 ?s 12:20, John Fox <jfox at mcmaster.ca> escreveu:

> Dear Carlos,
>
> On 2024-06-19 11:13 a.m., Carlos Barboza wrote:
> >
> > You don't often get email from carlosambarboza at gmail.com. Learn why
> this
> > is important <https://aka.ms/LearnAboutSenderIdentification>
> >
> >
> >
> > Caution: External email.
> >
> >
> > Thank you Jonh for you answer
> > I indeed used contr.sum, contr.poly before to model definition
> > after that I get the same results using any names for the same factors
> > but, what do you exactly mean when testing for factors for differences
> > over the origin?
>
> The context here is models with both numeric and factor predictors.
> Consider a model of the form y ~ x*f, where x is numeric and f is a
> factor. A type-III test for the "main effect" of f tests for differences
> among factor levels where x = 0 (the origin).
>
> More generally, the issues concerning "types" of tests in models with
> linear predictors are sufficiently complicated that discussing them in a
> help file or by email is likely to prove unsatisfactory. See the first
> two references in ?Anova for more details.
>
> I hope this helps,
>   John
>
> > best regards
> > Carlos
> >
> >
> > Em qua., 19 de jun. de 2024 ?s 10:14, John Fox <jfox at mcmaster.ca
> > <mailto:jfox at mcmaster.ca>> escreveu:
> >
> >     Dear Carlos,
> >
> >       From ?Anova:
> >
> >     "Warning
> >
> >     Be careful of type-III tests: For a traditional multifactor ANOVA
> model
> >     with interactions, for example, these tests will normally only be
> >     sensible when using contrasts that, for different terms, are
> orthogonal
> >     in the row-basis of the model, such as those produced by contr.sum,
> >     contr.poly, or contr.helmert, but not by the default
> >     contr.treatment. In
> >     a model that contains factors, numeric covariates, and interactions,
> >     main-effect tests for factors will be for differences over the
> origin.
> >     In contrast (pun intended), type-II tests are invariant with respect
> to
> >     (full-rank) contrast coding. If you don't understand this issue, then
> >     you probably shouldn't use Anova for type-III tests."
> >
> >     I hope this helps,
> >        John
> >
> >     --
> >     John Fox, Professor Emeritus
> >     McMaster University
> >     Hamilton, Ontario, Canada
> >     web: https://www.john-fox.ca/ <https://www.john-fox.ca/>
> >     --
> >     On 2024-06-18 5:59 a.m., Carlos Barboza wrote:
> >      > [You don't often get email from carlosambarboza at gmail.com
> >     <mailto:carlosambarboza at gmail.com>. Learn why this is important at
> >     https://aka.ms/LearnAboutSenderIdentification
> >     <https://aka.ms/LearnAboutSenderIdentification> ]
> >      >
> >      > Caution: External email.
> >      >
> >      >
> >      > sorry, Anova type III function form car package in R
> >      >
> >      > Em ter., 18 de jun. de 2024 ?s 06:59, Carlos Barboza <
> >      > carlosambarboza at gmail.com <mailto:carlosambarboza at gmail.com>>
> >     escreveu:
> >      >
> >      >> Dear all,
> >      >> why Anova type III function gives different results if I change
> >     the names
> >      >> of a categorical factor? I suspect that is because contrast type
> >     but it's
> >      >> something strange get different results using the same data.
> >      >> thank you
> >      >>
> >      >> Em s?b., 7 de mai. de 2016 ?s 12:26, Carlos Barboza <
> >      >> carlosambarboza at gmail.com <mailto:carlosambarboza at gmail.com>>
> >     escreveu:
> >      >>
> >      >>> Dear Dr. Ben Bolker
> >      >>>
> >      >>> My name is Carlos Barboza and I am a Marine Biologist from the
> >     Rio de
> >      >>> Janeiro University, Brazil. First it's a pleasure to again have
> the
> >      >>> opportunity to send you a message.The reason for it is a simple
> >     doubt:
> >      >>> Can I compare AIC from:
> >      >>>
> >      >>> 1. glmmADMB: Density ~ 1 + 1|Site
> >      >>>
> >      >>> 2. glmmADMB: Density ~ Sector + 1|Site + Cage
> >      >>>
> >      >>> Note that they have different random and fixed structures. I
> >     know that
> >      >>> this is not the best choice to model selection but, I think
> >     that the AIC
> >      >>> values can be compared.
> >      >>>
> >      >>> thank you very much for your attention
> >      >>>
> >      >>>
> >      >>>    is Cage a random effect?  Are you intentionally leaving out
> the
> >      >>> intercept in the second case (it will be included anyway unless
> you
> >      >>> use -1)?  In any case, I don't see any obvious reason you can't
> >      >>> compare AIC values; see
> >      >>>
> >      >>>
> >
> https://rawgit.com/bbolker/mixedmodels-misc/master/glmmFAQ.html#can-i-use-aic-for-mixed-models-how-do-i-count-the-number-of-degrees-of-freedom-for-a-random-effect
> <
> https://rawgit.com/bbolker/mixedmodels-misc/master/glmmFAQ.html#can-i-use-aic-for-mixed-models-how-do-i-count-the-number-of-degrees-of-freedom-for-a-random-effect
> >
> >      >>>
> >      >>>    Follow-ups to r-sig-mixed-models at r-project.org
> >     <mailto:r-sig-mixed-models at r-project.org>, please ...
> >      >>>
> >      >>> sorry, yes, cage was included only to examplify a different
> random
> >      >>> structure in the second case...it should be coded (1|Site) +
> >     (1|Cage)
> >      >>> yes, I know that the intercept will be included in the second
> model
> >      >>>
> >      >>> it's an example of comparing AIC values from mixed models with
> >     different
> >      >>> fixed and random structures:
> >      >>>
> >      >>> 1. Density ~ 1 + 1|Site
> >      >>>
> >      >>> 2. Density ~ Sector + 1|Site + 1|Cage
> >      >>>
> >      >>> comparing AIC...I beleive that both values can be compared
> >      >>>
> >      >>> again, thank you very much for your very fast message
> >      >>>
> >      >>>
> >      >>>
> >      >>>
> >      >>
> >      >> --
> >      >> Universidade Federal do Rio de Janeiro (UFRJ)
> >      >> Instituto de Biodiversidade e Sustentabilidade - NUPEM
> >      >> Caixa Postal 119331, CEP 27910-970
> >      >> Maca?, RJ, Brazil
> >      >> https://www.macae.ufrj.br/nupem/ <
> https://www.macae.ufrj.br/nupem/>
> >      >> http://lattes.cnpq.br/3629226944950076
> >     <http://lattes.cnpq.br/3629226944950076>
> >      >>
> >     https://scholar.google.com.br/citations?user=p-PRvd4AAAAJ&hl=pt-BR
> >     <https://scholar.google.com.br/citations?user=p-PRvd4AAAAJ&hl=pt-BR>
> >      >> https://www.researchgate.net/profile/Carlos_Barboza3
> >     <https://www.researchgate.net/profile/Carlos_Barboza3>
> >      >>
> >      >
> >      >
> >      > --
> >      > Universidade Federal do Rio de Janeiro (UFRJ)
> >      > Instituto de Biodiversidade e Sustentabilidade - NUPEM
> >      > Caixa Postal 119331, CEP 27910-970
> >      > Maca?, RJ, Brazil
> >      > https://www.macae.ufrj.br/nupem/ <
> https://www.macae.ufrj.br/nupem/>
> >      > http://lattes.cnpq.br/3629226944950076
> >     <http://lattes.cnpq.br/3629226944950076>
> >      >
> >     https://scholar.google.com.br/citations?user=p-PRvd4AAAAJ&hl=pt-BR
> >     <https://scholar.google.com.br/citations?user=p-PRvd4AAAAJ&hl=pt-BR>
> >      > https://www.researchgate.net/profile/Carlos_Barboza3
> >     <https://www.researchgate.net/profile/Carlos_Barboza3>
> >      >
> >      >          [[alternative HTML version deleted]]
> >      >
> >      > _______________________________________________
> >      > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >
> >
> >
> > --
> > Universidade Federal do Rio de Janeiro (UFRJ)
> > Instituto de Biodiversidade e Sustentabilidade - NUPEM
> > Caixa Postal 119331, CEP 27910-970
> > Maca?, RJ, Brazil
> > https://www.macae.ufrj.br/nupem/ <https://www.macae.ufrj.br/nupem/>
> > http://lattes.cnpq.br/3629226944950076
> > <http://lattes.cnpq.br/3629226944950076>
> > https://scholar.google.com.br/citations?user=p-PRvd4AAAAJ&hl=pt-BR
> > <https://scholar.google.com.br/citations?user=p-PRvd4AAAAJ&hl=pt-BR>
> > https://www.researchgate.net/profile/Carlos_Barboza3
> > <https://www.researchgate.net/profile/Carlos_Barboza3>
>
>

-- 
Universidade Federal do Rio de Janeiro (UFRJ)
Instituto de Biodiversidade e Sustentabilidade - NUPEM
Caixa Postal 119331, CEP 27910-970
Maca?, RJ, Brazil
https://www.macae.ufrj.br/nupem/
http://lattes.cnpq.br/3629226944950076
https://scholar.google.com.br/citations?user=p-PRvd4AAAAJ&hl=pt-BR
https://www.researchgate.net/profile/Carlos_Barboza3

	[[alternative HTML version deleted]]


From |z@gu|rre@@|e @end|ng |rom gm@||@com  Mon Jun 24 21:21:06 2024
From: |z@gu|rre@@|e @end|ng |rom gm@||@com (Alejandro Izaguirre)
Date: Mon, 24 Jun 2024 16:21:06 -0300
Subject: [R-sig-ME] lme4 package
Message-ID: <CAOuedHONcy-Pas=ZbJFjoLfE8by7FtGqPH4ujxXmvJr+FBZBRA@mail.gmail.com>

My name is Alejandro Izaguirre, I am an economist specialized in spatial
data analysis. I use linear mixed  models for estimating poverty maps.
I have a question about the *lme4* package, specifically about lmer. I
usually work with informative sampling designs and I would like to know if
the command *"weights"* in *lmer* stands for sampling weights. There are
discussions on the internet about this, and I would like to ask you for
some clarifications.

Thank you very much.

regards,

Alejandro Izaguirre

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Wed Jun 26 15:21:55 2024
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Wed, 26 Jun 2024 09:21:55 -0400
Subject: [R-sig-ME] lme4 package
In-Reply-To: <CAOuedHONcy-Pas=ZbJFjoLfE8by7FtGqPH4ujxXmvJr+FBZBRA@mail.gmail.com>
References: <CAOuedHONcy-Pas=ZbJFjoLfE8by7FtGqPH4ujxXmvJr+FBZBRA@mail.gmail.com>
Message-ID: <a3fd698a-a292-45a4-ba4e-45127002f6ec@gmail.com>

    lmer does *not* implement sampling weights. You may want to look at 
the svylme <https://CRAN.R-project.org/package=svylme> package (see the 
README at https://cran.r-project.org/web/packages/svylme/readme/README.html)

    cheers
    Ben Bolker


On 2024-06-24 3:21 p.m., Alejandro Izaguirre wrote:
> My name is Alejandro Izaguirre, I am an economist specialized in spatial
> data analysis. I use linear mixed  models for estimating poverty maps.
> I have a question about the *lme4* package, specifically about lmer. I
> usually work with informative sampling designs and I would like to know if
> the command *"weights"* in *lmer* stands for sampling weights. There are
> discussions on the internet about this, and I would like to ask you for
> some clarifications.
> 
> Thank you very much.
> 
> regards,
> 
> Alejandro Izaguirre
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics
 > E-mail is sent at my convenience; I don't expect replies outside of 
working hours.


From bbo|ker @end|ng |rom gm@||@com  Wed Jun 26 15:58:36 2024
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Wed, 26 Jun 2024 09:58:36 -0400
Subject: [R-sig-ME] lme4 package
In-Reply-To: <a3fd698a-a292-45a4-ba4e-45127002f6ec@gmail.com>
References: <CAOuedHONcy-Pas=ZbJFjoLfE8by7FtGqPH4ujxXmvJr+FBZBRA@mail.gmail.com>
 <a3fd698a-a292-45a4-ba4e-45127002f6ec@gmail.com>
Message-ID: <33d1fc8e-defd-409d-9bee-beafe225cbbd@gmail.com>

   I've been reminded that I forgot about the WeMix package 
<https://CRAN.R-project.org/package=WeMix>, which supports some models 
that svylme doesn't ...

   Ben Bolker

On 2024-06-26 9:21 a.m., Ben Bolker wrote:
>  ?? lmer does *not* implement sampling weights. You may want to look at 
> the svylme <https://CRAN.R-project.org/package=svylme> package (see the 
> README at 
> https://cran.r-project.org/web/packages/svylme/readme/README.html)
> 
>  ?? cheers
>  ?? Ben Bolker
> 
> 
> On 2024-06-24 3:21 p.m., Alejandro Izaguirre wrote:
>> My name is Alejandro Izaguirre, I am an economist specialized in spatial
>> data analysis. I use linear mixed? models for estimating poverty maps.
>> I have a question about the *lme4* package, specifically about lmer. I
>> usually work with informative sampling designs and I would like to 
>> know if
>> the command *"weights"* in *lmer* stands for sampling weights. There are
>> discussions on the internet about this, and I would like to ask you for
>> some clarifications.
>>
>> Thank you very much.
>>
>> regards,
>>
>> Alejandro Izaguirre
>>
>> ????[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics
 > E-mail is sent at my convenience; I don't expect replies outside of 
working hours.


From o||verhooker @end|ng |rom pr@t@t|@t|c@@com  Thu Jun 27 16:14:00 2024
From: o||verhooker @end|ng |rom pr@t@t|@t|c@@com (Oliver Hooker)
Date: Thu, 27 Jun 2024 15:14:00 +0100
Subject: [R-sig-ME] =?utf-8?q?IN_PERSON_COURSE_=E2=80=93_Hierarchical_mod?=
	=?utf-8?q?elling_in_ecology_=28HMIE01=29_=28Universit=C3=A9_de_She?=
	=?utf-8?q?rbrooke=2C_Canada=29?=
Message-ID: <CAEsSYzydPm3iajAHdK0agFQbVOES5q4JvN1eUS1E4rpFj4tw2g@mail.gmail.com>

IN PERSON COURSE ? Hierarchical modelling in ecology (HMIE01) (Universit?
de Sherbrooke, Canada)

https://www.prstats.org/course/hierarchical-modelling-in-ecology-hmie01/

Where - Longueuil Campus <https://tinyurl.com/y5pntkxc> of Universit? de
Sherbrooke

When - Monday 11th - Frtiday 15th November

Please feel free to share!


COURSE OVERVIEW - More than ever in biology and ecology we need statistical
modelling tools that go beyond the basic linear or generalized linear
models. The next evolution in statistical modelling are hierarchical
models, also known as mixed models. Hierarchical models are complex tools
that have the potential to bring your research to the next level. However,
to understand hierarchical models properly, in this course we will briefly
discuss probability theory, the frequentists and Bayesian paradigms and
(generalized) linear models before studying hierarchical models. The
discussions on hierarchical models will first focus on simple hierarchical
models and as we advance in the course, we will study the basis of
constrained hierarchical models (i.e. in space or time) and multivariate
hierarchical models. The course will be a mixed of theory and practice. To
implement the models we will discuss in the course, we will be using the
Stan programming language, a flexible programming infrastructure designed
to construct any hierarchical models from the simplest to the most complex
ones. Stan is a programming language that is typically used through a
higher-level programming language such as R, python or Julia. In this
respect, although all our examples and practical exercises will be carried
out using R, any language that can interface with Stan can be used.

By the end of the course, participants should have:

   - Learned statistical theory to better construct, apply and interpret
   different statistical models applied to biology and ecology.
   - Become familiar with primary research in statistical modelling in
   biology and ecology.
   - Gained experience in working collaboratively on issues related to the
   development and application of statistical methods.

Please email oliverhooker at prstatistics.com with any questions.

-- 
Best wishes,

Oliver

Oliver Hooker PhD.
PR stats

	[[alternative HTML version deleted]]


From k|m@pe@rce @end|ng |rom newc@@t|e@@c@uk  Thu Jun 27 16:41:21 2024
From: k|m@pe@rce @end|ng |rom newc@@t|e@@c@uk (Kim Pearce)
Date: Thu, 27 Jun 2024 14:41:21 +0000
Subject: [R-sig-ME] lmer function in R for linear mixed models : syntax -
 your views
Message-ID: <LO0P302MB0211374074A81DC62C1EF380D7D72@LO0P302MB0211.GBRP302.PROD.OUTLOOK.COM>

Hello everyone,

I am a senior statistician working in Newcastle University, UK.  My question relates to the generation of a (hypothetical) linear mixed model using R's lmer function within the lme4 package.

I wonder if anyone has any views on the following?

Hypothetically, say we had a response (Y) from N subjects which was recorded at baseline and at each of 6 subsequent years.? "Time" (values 0,1,2,3,4,5,6) is recorded for each subject. "Medication dose" (continuous) is recorded for each subject at each of the time points.? Each subject's baseline severity group is also recorded.

In this hypothetical situation, time (level 1) would be nested within patient (level 2).? At each time point, medication dose and associated response would be recorded for each patient (and each patient belongs to a specific baseline severity group which, of course, would be constant for each patient).? I am hypothesising that the effect of medication (i.e. dose) on response could vary as a function of patient and the change in response over time could vary across people too.? In my example, I am thinking about a model that could possibly include random intercepts, fixed and random slopes for time and fixed and random slopes for medication (i.e. dose) plus q-1 fixed slopes for the q category baseline severity group.

In my model, the response (Y) takes a continuous form and I am taking "time" (time) and "medication dose" (meddose) as continuous - additionally, baseline severity group (basesevgroupf) is declared as a factor i.e. categorical.

Would the following syntax be correct?

Modely <- lmer(Y ~ time + meddose + basesevgroupf + (time + meddose | subject), data=datafile)

Or equivalently:

Modely <- lmer(Y ~ time + meddose + basesevgroupf + (1+ time + meddose | subject), data=datafile)

(Additionally, as I understand it, the above pieces of syntax would create a model with correlated random intercepts and slopes)

I ask this question as examples I have seen utilising R usually focus on the situation when the linear mixed model either contains (i) just random intercepts or (ii) random intercepts and random slopes for one predictor (whereas, in my hypothetical example, the model contains random intercepts and random slopes for two predictors).

Many thanks, in advance, for your views.
Best wishes,
Kim

Dr Kim Pearce PhD, CStat, Fellow HEA
Newcastle University 


From bbo|ker @end|ng |rom gm@||@com  Thu Jun 27 18:11:32 2024
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 27 Jun 2024 12:11:32 -0400
Subject: [R-sig-ME] 
 lmer function in R for linear mixed models : syntax - your views
In-Reply-To: <LO0P302MB0211374074A81DC62C1EF380D7D72@LO0P302MB0211.GBRP302.PROD.OUTLOOK.COM>
References: <LO0P302MB0211374074A81DC62C1EF380D7D72@LO0P302MB0211.GBRP302.PROD.OUTLOOK.COM>
Message-ID: <bc7ad418-edce-48c1-b334-28d291771662@gmail.com>

   This seems fine.  You would end up with a 3x3 covariance matrix 
(variation in intercept, slope with respect to time, and effect of dose 
across subjects, and 3 covariances).

   A bit more complicated, but e.g. Moritz et al (2023) fit models where 
the random effects include the intercept plus random slopes for *four* 
continuous covariates ...

   I might consider the possibility of a time-by-meddose interaction, 
both in the fixed effects and random effects (i.e. (1 + time + meddose + 
time:meddose | subject) or equivalently (1 + time*meddose | subject ), 
although that would expand your covariance matrix to 4x4 ...

   cheers
    Ben Bolker


Moritz, Max A., Enric Batllori, and Benjamin M. Bolker. 2023. ?The Role 
of Fire in Terrestrial Vertebrate Richness Patterns.? Ecology Letters 26 
(4): 563?74. https://doi.org/10.1111/ele.14177.


On 2024-06-27 10:41 a.m., Kim Pearce via R-sig-mixed-models wrote:
> Hello everyone,
> 
> I am a senior statistician working in Newcastle University, UK.  My question relates to the generation of a (hypothetical) linear mixed model using R's lmer function within the lme4 package.
> 
> I wonder if anyone has any views on the following?
> 
> Hypothetically, say we had a response (Y) from N subjects which was recorded at baseline and at each of 6 subsequent years.? "Time" (values 0,1,2,3,4,5,6) is recorded for each subject. "Medication dose" (continuous) is recorded for each subject at each of the time points.? Each subject's baseline severity group is also recorded.
> 
> In this hypothetical situation, time (level 1) would be nested within patient (level 2).? At each time point, medication dose and associated response would be recorded for each patient (and each patient belongs to a specific baseline severity group which, of course, would be constant for each patient).? I am hypothesising that the effect of medication (i.e. dose) on response could vary as a function of patient and the change in response over time could vary across people too.? In my example, I am thinking about a model that could possibly include random intercepts, fixed and random slopes for time and fixed and random slopes for medication (i.e. dose) plus q-1 fixed slopes for the q category baseline severity group.
> 
> In my model, the response (Y) takes a continuous form and I am taking "time" (time) and "medication dose" (meddose) as continuous - additionally, baseline severity group (basesevgroupf) is declared as a factor i.e. categorical.
> 
> Would the following syntax be correct?
> 
> Modely <- lmer(Y ~ time + meddose + basesevgroupf + (time + meddose | subject), data=datafile)
> 
> Or equivalently:
> 
> Modely <- lmer(Y ~ time + meddose + basesevgroupf + (1+ time + meddose | subject), data=datafile)
> 
> (Additionally, as I understand it, the above pieces of syntax would create a model with correlated random intercepts and slopes)
> 
> I ask this question as examples I have seen utilising R usually focus on the situation when the linear mixed model either contains (i) just random intercepts or (ii) random intercepts and random slopes for one predictor (whereas, in my hypothetical example, the model contains random intercepts and random slopes for two predictors).
> 
> Many thanks, in advance, for your views.
> Best wishes,
> Kim
> 
> Dr Kim Pearce PhD, CStat, Fellow HEA
> Newcastle University
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From Ro@@@Boy|@n @end|ng |rom uc@|@edu  Sat Jun 29 05:03:15 2024
From: Ro@@@Boy|@n @end|ng |rom uc@|@edu (Boylan, Ross)
Date: Sat, 29 Jun 2024 03:03:15 +0000
Subject: [R-sig-ME] errors building lme4 from source: Indexis not a member
 of 'lme4::lme4CholmodDecomposition...
Message-ID: <BY3PR05MB81164AF3A4D3880AF094213B87D12@BY3PR05MB8116.namprd05.prod.outlook.com>

While trying to build lme4 from source with current master (SHA a7239d63) on MS-Windows I get the errors shown at the bottom of this message; the first one is
----------------------------------------------
lme4CholmodDecomposition.h: In instantiation of 'lme4::lme4CholmodDecomposition<_MatrixType, _UpLo>::solveInPlaceonst Eigen::MatrixBase<OtherDerived>&, int) const [with OtherDerived = Eigen::Matrix<double, -1, -1>; _MatrixType = Eigen::SparseMatrix<double, 0, int>; int _UpLo = 1]
predModule.cpp:127:37: required from here
lme4CholmodDecomposition.h:59:39:error: Indexis not a member of 'lme4::lme4CholmodDecomposition<Eigen::SparseMatrix<double, 0, int> >::Base{aka 'Eigen::CholmodDecomposition<Eigen::SparseMatrix<double, 0, int>, 1>
   59 |             eigen_assert((Base::Index)(factor()->n)ther.rows());
      |                          ~~~~~~~~~~~~~^~~~~~~~~~~~~
------------------------------------------------
which looks as if I may have some version mismatch, but I'm not sure exactly where the culprit is or what to do about it.  Any ideas?
This particular build was triggered while requesting a run of the test suite in RStudio, but I got roughly the same when doing a straight build in RStudio.

This is the development version of lme4, but the rest of my system, including the dependencies, is back in vanilla R 4.4.0.  And I have lme4 1.1-35.4 installed from binary.

Further version info:
> Sys.info()
       sysname        release        version       nodename        machine          login 
     "Windows"   "Server x64"  "build 17763"     "xxx"       "x86-64"     "me" 
          user effective_user 
    "me"     "me" 
> R.version
               _                                
platform       x86_64-w64-mingw32               
arch           x86_64                           
os             mingw32                          
crt            ucrt                             
system         x86_64, mingw32                  
status                                          
major          4                                
minor          4.0                              
year           2024                             
month          04                               
day            24                               
svn rev        86474                            
language       R                                
version.string R version 4.4.0 (2024-04-24 ucrt)
nickname       Puppy Cup

RStudio 2024.04.2+764 "Chocolate Cosmos" Release (e4392fc9ddc21961fd1d0efd47484b43f07a4177, 2024-06-05) for windows
Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) RStudio/2024.04.2+764 Chrome/120.0.6099.291 Electron/28.3.1 Safari/537.36, Quarto 1.4.555 (C:/Program Files/RStudio/resources/app/bin/quarto/bin/quarto.exe)

R  packages:
Rcpp 1.0.12
RcppEigen 0.3.4.0.0
Matrix 1.7-0   # in particular, past 1.6-2, source of somewhat similar problems
Because those were all binary installs, I wondered if I was simply missing some headers.  But the errors don't look like "can't find file".

RTools44 installed.


Finally, here's part of the log of the failure:
---------------------------------------------------------------------
==> devtools::test()

i Testing lme4
Error in `(function (command = NULL, args = character(), error_on_status = TRUE, ...`:
! System command 'Rcmd.exe' failed
---
Exit status: 1
Stdout & stderr:
* installing *source* package 'lme4' ...
** using staged installation
** libs
using C++ compiler: 'G__~1.EXE (GCC) 13.2.0'
g++ -std=gnu++17  -I"C:/PROGRA~1/R/R-44~1.0/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE -I'C:/Program Files/R/R-4.4.0/library/Rcpp/include' -I'C:/Program Files/R/R-4.4.0/library/RcppEigen/include' -I'C:/Program Files/R/R-4.4.0/library/Matrix/include'   -I"C:/Programs/rtools44/x86_64-w64-mingw32.static.posix/include"     -O2 -Wall -gdwarf-2 -mfpmath=sse -msse2 -mstackrealign  -UNDEBUG -Wall -pedantic -g -O0 -fdiagnostics-color=always -c external.cpp -o external.o
g++ -std=gnu++17  -I"C:/PROGRA~1/R/R-44~1.0/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE -I'C:/Program Files/R/R-4.4.0/library/Rcpp/include' -I'C:/Program Files/R/R-4.4.0/library/RcppEigen/include' -I'C:/Program Files/R/R-4.4.0/library/Matrix/include'   -I"C:/Programs/rtools44/x86_64-w64-mingw32.static.posix/include"     -O2 -Wall -gdwarf-2 -mfpmath=sse -msse2 -mstackrealign  -UNDEBUG -Wall -pedantic -g -O0 -fdiagnostics-color=always -c glmFamily.cpp -o glmFamily.o
g++ -std=gnu++17  -I"C:/PROGRA~1/R/R-44~1.0/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE -I'C:/Program Files/R/R-4.4.0/library/Rcpp/include' -I'C:/Program Files/R/R-4.4.0/library/RcppEigen/include' -I'C:/Program Files/R/R-4.4.0/library/Matrix/include'   -I"C:/Programs/rtools44/x86_64-w64-mingw32.static.posix/include"     -O2 -Wall -gdwarf-2 -mfpmath=sse -msse2 -mstackrealign  -UNDEBUG -Wall -pedantic -g -O0 -fdiagnostics-color=always -c mcmcsamp.cpp -o mcmcsamp.o
g++ -std=gnu++17  -I"C:/PROGRA~1/R/R-44~1.0/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE -I'C:/Program Files/R/R-4.4.0/library/Rcpp/include' -I'C:/Program Files/R/R-4.4.0/library/RcppEigen/include' -I'C:/Program Files/R/R-4.4.0/library/Matrix/include'   -I"C:/Programs/rtools44/x86_64-w64-mingw32.static.posix/include"     -O2 -Wall -gdwarf-2 -mfpmath=sse -msse2 -mstackrealign  -UNDEBUG -Wall -pedantic -g -O0 -fdiagnostics-color=always -c optimizer.cpp -o optimizer.o
g++ -std=gnu++17  -I"C:/PROGRA~1/R/R-44~1.0/include" -DNDEBUG -I. -DNDEBUG -DEIGEN_DONT_VECTORIZE -I'C:/Program Files/R/R-4.4.0/library/Rcpp/include' -I'C:/Program Files/R/R-4.4.0/library/RcppEigen/include' -I'C:/Program Files/R/R-4.4.0/library/Matrix/include'   -I"C:/Programs/rtools44/x86_64-w64-mingw32.static.posix/include"     -O2 -Wall -gdwarf-2 -mfpmath=sse -msse2 -mstackrealign  -UNDEBUG -Wall -pedantic -g -O0 -fdiagnostics-color=always -c predModule.cpp -o predModule.o
In file included from C:/Programs/rtools44/x86_64-w64-mingw32.static.posix/lib/gcc/x86_64-w64-mingw32.static.posix/13.2.0/include/c++/cassert:44
                 from C:/Program Files/R/R-4.4.0/library/RcppEigen/include/Eigen/Core:84
                 from C:/Program Files/R/R-4.4.0/library/RcppEigen/include/Eigen/Dense:1
                 from C:/Program Files/R/R-4.4.0/library/RcppEigen/include/RcppEigenForward.h:28
                 from C:/Program Files/R/R-4.4.0/library/RcppEigen/include/RcppEigen.h:25
                 from predModule.h:12
                 from predModule.cpp:8
lme4CholmodDecomposition.h: In instantiation of 'lme4::lme4CholmodDecomposition<_MatrixType, _UpLo>::solveInPlaceonst Eigen::MatrixBase<OtherDerived>&, int) const [with OtherDerived = Eigen::Matrix<double, -1, -1>; _MatrixType = Eigen::SparseMatrix<double, 0, int>; int _UpLo = 1]
predModule.cpp:127:37: required from here
lme4CholmodDecomposition.h:59:39:error: Indexis not a member of 'lme4::lme4CholmodDecomposition<Eigen::SparseMatrix<double, 0, int> >::Base{aka 'Eigen::CholmodDecomposition<Eigen::SparseMatrix<double, 0, int>, 1>
   59 |             eigen_assert((Base::Index)(factor()->n)ther.rows());
      |                          ~~~~~~~~~~~~~^~~~~~~~~~~~~
C:/Program Files/R/R-4.4.0/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:1037:25:note:  expansion of macro 'eigen_plain_assert
 1037 | #define eigen_assert(x) eigen_plain_assert
      |                         ^~~~~~~~~~~~~~~~~~
lme4CholmodDecomposition.h:59:13:note:  expansion of macro 'eigen_assert
   59 |             eigen_asserte::Index)(factor()->n) == other.rows());
      |             ^~~~~~~~~~~~
lme4CholmodDecomposition.h: In instantiation of 'lme4::lme4CholmodDecomposition<_MatrixType, _UpLo>::solveInPlaceonst Eigen::MatrixBase<OtherDerived>&, int) const [with OtherDerived = Eigen::Map<Eigen::Matrix<double, -1, 1> >; _MatrixType = Eigen::SparseMatrix<double, 0, int>; int _UpLo = 1]
predModule.cpp:191:25: required from here
lme4CholmodDecomposition.h:59:39:error: Indexis not a member of 'lme4::lme4CholmodDecomposition<Eigen::SparseMatrix<double, 0, int> >::Base{aka 'Eigen::CholmodDecomposition<Eigen::SparseMatrix<double, 0, int>, 1>
   59 |             eigen_assert((Base::Index)(factor()->n)ther.rows());
      |                          ~~~~~~~~~~~~~^~~~~~~~~~~~~
C:/Program Files/R/R-4.4.0/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:1037:25:note:  expansion of macro 'eigen_plain_assert
### and more, ending
C:/Program Files/R/R-4.4.0/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:1037:25:note:  expansion of macro 'eigen_plain_assert
 1037 | #define eigen_assert(x) eigen_plain_assert
      |                         ^~~~~~~~~~~~~~~~~~
lme4CholmodDecomposition.h:59:13:note:  expansion of macro 'eigen_assert
   59 |             eigen_asserte::Index)(factor()->n) == other.rows());
      |             ^~~~~~~~~~~~
make: *** [C:/PROGRA~1/R/R-44~1.0/etc/x64/Makeconf:296: predModule.o] Error 1
ERROR: compilation failed for package 'lme4'
---------------------------------------------------------------------------------------------------------

Thanks!
Ross

P.S. I have made some changes, but none of them involve the C code.
And "check" in RStudio passes.  Which is a bit weird; I thought building the package was part of the check.  I guess it's "build" as in "create the source package".


