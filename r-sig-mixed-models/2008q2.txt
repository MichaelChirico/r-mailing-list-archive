From cotter.rs at gmail.com  Tue Apr  1 12:17:41 2008
From: cotter.rs at gmail.com (R.S. Cotter)
Date: Tue, 1 Apr 2008 12:17:41 +0200
Subject: [R-sig-ME] Coefficient of determination (R^2) when using lme()
Message-ID: <742479270804010317j6edf2417n7d85754c08fa959e@mail.gmail.com>

Dear mixed models users,

I have recently started using R, and I have learned to use lme ().

Is it possible to interpret coefficient of determination (R^2) when
using lme ()?


Best Regards

R.S. Cotter



From HStevens at muohio.edu  Tue Apr  1 12:37:21 2008
From: HStevens at muohio.edu (MHH Stevens)
Date: Tue, 1 Apr 2008 06:37:21 -0400
Subject: [R-sig-ME] Coefficient of determination (R^2) when using lme()
In-Reply-To: <742479270804010317j6edf2417n7d85754c08fa959e@mail.gmail.com>
References: <742479270804010317j6edf2417n7d85754c08fa959e@mail.gmail.com>
Message-ID: <859570CB-7AAC-4443-BF16-2C50B3BCAAC3@muohio.edu>

Hi R.S.,
This quantity is not clearly defined for mixed models --- should it  
include that which is "explained" by the random effects? What would  
it mean to "explain" a response with a variance? In any event, try  
searching R-help lists for Coefficient of determination AND lme.
Cheers,
Hank
On Apr 1, 2008, at 6:17 AM, R.S. Cotter wrote:
> Dear mixed models users,
>
> I have recently started using R, and I have learned to use lme ().
>
> Is it possible to interpret coefficient of determination (R^2) when
> using lme ()?
>
>
> Best Regards
>
> R.S. Cotter
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

Dr. Hank Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/~stevenmh/
http://www.cas.muohio.edu/ecology
http://www.muohio.edu/botany/

"If the stars should appear one night in a thousand years, how would men
believe and adore." -Ralph Waldo Emerson, writer and philosopher  
(1803-1882)



From cotter.rs at gmail.com  Tue Apr  1 12:54:23 2008
From: cotter.rs at gmail.com (R.S. Cotter)
Date: Tue, 1 Apr 2008 12:54:23 +0200
Subject: [R-sig-ME] Basic question about interpretation of lme () result.
Message-ID: <742479270804010354i66c3984ga8f96d7dbf5b2e5b@mail.gmail.com>

DeaR mixed effect model users

I'm need some advice regarding interpretation of the lme () result. My
question is possible too basic, but I hope someone could help me with
advices (it may be valuable for other lme() new beginners).

Respons: Speed
Fixed effects: Fuel, CarMod (1,2&3), Driver (Old or Young), and Fuel*CarMod.
Random effects: Place

Questions regarding my model, se below:

1. Is it right to interpret that CarMod2 is significant different from CarMod1?
2. Is it right to interpret that the effect of Fuel is different in
CarMod2 compared to CarMod1?
3. Is there a guideline for reporting lme() result? I'm uncertain
whether to report this result as a table with only the estimates from
the lme () or a table with only the anova (mod1)?


> mod1 <- lme(Speed ~ Fuel + Car + Driver + Fuel*Car, random=~1|Place,data=test)
> summary(mod1)
Linear mixed-effects model fit by REML
 Data: test
       AIC      BIC    logLik
  261.2013 275.6996 -121.6007

Random effects:
 Formula: ~1 | Place
            (Intercept)         Residual
StdDev: 0.0003238738   5.013858

Fixed effects: Speed ~ Fuel + Car + Driver + Fuel * Car
                       Value        Std.Error     DF   t-value       p-value
(Intercept)        -29.33479  12.743084   30   -2.302017   0.0285
Fuel                10.04684    1.408789    30    7.131542   0.0000
CarMod2         46.55593    14.192029   7     3.280428   0.0135
CarMod3          1.65157     18.247158   7     0.090511   0.9304
DriverYoung     26.65219    1.688643    30   15.783202  0.0000
Fuel:CarMod2  -5.53264     1.624159    30   -3.406464   0.0019
Fuel:CarMod3  -0.18452      2.010470   30   -0.091779   0.9275

Number of Observations: 44
Number of Groups: 10
> anova(mod1)
               numDF   denDF    F-value     p-value
(Intercept)     1        30        8487.520  <.0001
Fuel             1        30         340.661   <.0001
Car              2         7            6.283     0.0274
Driver           1        30         235.860    <.0001
Fuel:Car       2        30           8.655      0.0011

Best regards R.S. Cotter



From HStevens at muohio.edu  Tue Apr  1 13:06:30 2008
From: HStevens at muohio.edu (MHH Stevens)
Date: Tue, 1 Apr 2008 07:06:30 -0400
Subject: [R-sig-ME] Basic question about interpretation of lme () result.
In-Reply-To: <742479270804010354i66c3984ga8f96d7dbf5b2e5b@mail.gmail.com>
References: <742479270804010354i66c3984ga8f96d7dbf5b2e5b@mail.gmail.com>
Message-ID: <66054F93-4B9A-4DF9-9C7E-024E5559F865@muohio.edu>

Hi RS,
The coefficients below need to be interpreted appropriately, and  
these (presumeably treatment contrasts or dummy coding) do not  
necessarily correspond directly to ANOVA type factor tests. I suggest  
consulting one of the R books listed on the R project web site under  
"Documentation/Books."
Cheers,
Hank
On Apr 1, 2008, at 6:54 AM, R.S. Cotter wrote:
> DeaR mixed effect model users
>
> I'm need some advice regarding interpretation of the lme () result. My
> question is possible too basic, but I hope someone could help me with
> advices (it may be valuable for other lme() new beginners).
>
> Respons: Speed
> Fixed effects: Fuel, CarMod (1,2&3), Driver (Old or Young), and  
> Fuel*CarMod.
> Random effects: Place
>
> Questions regarding my model, se below:
>
> 1. Is it right to interpret that CarMod2 is significant different  
> from CarMod1?
> 2. Is it right to interpret that the effect of Fuel is different in
> CarMod2 compared to CarMod1?
> 3. Is there a guideline for reporting lme() result? I'm uncertain
> whether to report this result as a table with only the estimates from
> the lme () or a table with only the anova (mod1)?
>
>
>> mod1 <- lme(Speed ~ Fuel + Car + Driver + Fuel*Car, random=~1| 
>> Place,data=test)
>> summary(mod1)
> Linear mixed-effects model fit by REML
>  Data: test
>        AIC      BIC    logLik
>   261.2013 275.6996 -121.6007
>
> Random effects:
>  Formula: ~1 | Place
>             (Intercept)         Residual
> StdDev: 0.0003238738   5.013858
>
> Fixed effects: Speed ~ Fuel + Car + Driver + Fuel * Car
>                        Value        Std.Error     DF   t- 
> value       p-value
> (Intercept)        -29.33479  12.743084   30   -2.302017   0.0285
> Fuel                10.04684    1.408789    30    7.131542   0.0000
> CarMod2         46.55593    14.192029   7     3.280428   0.0135
> CarMod3          1.65157     18.247158   7     0.090511   0.9304
> DriverYoung     26.65219    1.688643    30   15.783202  0.0000
> Fuel:CarMod2  -5.53264     1.624159    30   -3.406464   0.0019
> Fuel:CarMod3  -0.18452      2.010470   30   -0.091779   0.9275
>
> Number of Observations: 44
> Number of Groups: 10
>> anova(mod1)
>                numDF   denDF    F-value     p-value
> (Intercept)     1        30        8487.520  <.0001
> Fuel             1        30         340.661   <.0001
> Car              2         7            6.283     0.0274
> Driver           1        30         235.860    <.0001
> Fuel:Car       2        30           8.655      0.0011
>
> Best regards R.S. Cotter
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

Dr. Hank Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/~stevenmh/
http://www.cas.muohio.edu/ecology
http://www.muohio.edu/botany/

"If the stars should appear one night in a thousand years, how would men
believe and adore." -Ralph Waldo Emerson, writer and philosopher  
(1803-1882)



From vmuggeo at dssm.unipa.it  Tue Apr  1 13:54:47 2008
From: vmuggeo at dssm.unipa.it (vito muggeo)
Date: Tue, 01 Apr 2008 13:54:47 +0200
Subject: [R-sig-ME] Coefficient of determination (R^2) when using lme()
In-Reply-To: <742479270804010317j6edf2417n7d85754c08fa959e@mail.gmail.com>
References: <742479270804010317j6edf2417n7d85754c08fa959e@mail.gmail.com>
Message-ID: <47F22287.1060603@dssm.unipa.it>

Dear R.S. Cotter,
I think that interpretation of R2 is not straightforward and it is area 
of research.. Have a look to

Xu. Measuring explained variation in linear mixed effects models 
Statist. Med. 2003; 22:3527?3541 (DOI: 10.1002/sim.1572)

Orelien, J.G., Edwards, L.J., Fixed-effect variable selection in linear 
mixed models using R2 statistics Comput. Statist.
Data Anal. (2007), doi: 10.1016/j.csda.2007.06.006

Hope this helps you,

vito



R.S. Cotter ha scritto:
> Dear mixed models users,
> 
> I have recently started using R, and I have learned to use lme ().
> 
> Is it possible to interpret coefficient of determination (R^2) when
> using lme ()?
> 
> 
> Best Regards
> 
> R.S. Cotter
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 

-- 
====================================
Vito M.R. Muggeo
Dip.to Sc Statist e Matem `Vianelli'
Universit? di Palermo
viale delle Scienze, edificio 13
90128 Palermo - ITALY
tel: 091 6626240
fax: 091 485726/485612



From jebyrnes at ucdavis.edu  Tue Apr  1 16:40:16 2008
From: jebyrnes at ucdavis.edu (Jarrett Byrnes)
Date: Tue, 1 Apr 2008 07:40:16 -0700
Subject: [R-sig-ME] Coefficient of determination (R^2) when using lme()
In-Reply-To: <859570CB-7AAC-4443-BF16-2C50B3BCAAC3@muohio.edu>
References: <742479270804010317j6edf2417n7d85754c08fa959e@mail.gmail.com>
	<859570CB-7AAC-4443-BF16-2C50B3BCAAC3@muohio.edu>
Message-ID: <D78960DE-E2C3-4C48-86FB-E0DD1CE5F0D1@ucdavis.edu>

This came up with a reviewer when I was using glms as well. I've  
become fond of using the R^2 of the correlation between the fitted and  
observed values.  It's easily interpretable by a general audience.

r2.corr.lmer<-function(lmer.object){
         summary(lm(attr(lmer.object, "y") ~ fitted (lmer.object))) 
$r.squared}


On Apr 1, 2008, at 3:37 AM, MHH Stevens wrote:

> Hi R.S.,
> This quantity is not clearly defined for mixed models --- should it
> include that which is "explained" by the random effects? What would
> it mean to "explain" a response with a variance? In any event, try
> searching R-help lists for Coefficient of determination AND lme.
> Cheers,
> Hank
> On Apr 1, 2008, at 6:17 AM, R.S. Cotter wrote:
>> Dear mixed models users,
>>
>> I have recently started using R, and I have learned to use lme ().
>>
>> Is it possible to interpret coefficient of determination (R^2) when
>> using lme ()?
>>
>>
>> Best Regards
>>
>> R.S. Cotter
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> Dr. Hank Stevens, Assistant Professor
> 338 Pearson Hall
> Botany Department
> Miami University
> Oxford, OH 45056
>
> Office: (513) 529-4206
> Lab: (513) 529-4262
> FAX: (513) 529-4243
> http://www.cas.muohio.edu/~stevenmh/
> http://www.cas.muohio.edu/ecology
> http://www.muohio.edu/botany/
>
> "If the stars should appear one night in a thousand years, how would  
> men
> believe and adore." -Ralph Waldo Emerson, writer and philosopher
> (1803-1882)
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bates at stat.wisc.edu  Tue Apr  1 18:10:00 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 1 Apr 2008 11:10:00 -0500
Subject: [R-sig-ME] Coefficient of determination (R^2) when using lme()
In-Reply-To: <D78960DE-E2C3-4C48-86FB-E0DD1CE5F0D1@ucdavis.edu>
References: <742479270804010317j6edf2417n7d85754c08fa959e@mail.gmail.com>
	<859570CB-7AAC-4443-BF16-2C50B3BCAAC3@muohio.edu>
	<D78960DE-E2C3-4C48-86FB-E0DD1CE5F0D1@ucdavis.edu>
Message-ID: <40e66e0b0804010910t4f9eb382j63211e33dd681bd8@mail.gmail.com>

That's going to break in the next version of R (due out later this month).

Use

 lmer.object at y

not

 attr(lmer.object, "y")

Slots in S4 classed objects were initially implemented as attributes
but they are not attributes.

In general, if you want to determine the structure of an object, use
the str() function.  It's even better to use the appropriate extractor
functions as the value of the extractor function should be consistent
across versions of the package but the structure of the object changes
between versions.  The appropriate extractor in this case is

model.response(lmer.object)


On Tue, Apr 1, 2008 at 9:40 AM, Jarrett Byrnes <jebyrnes at ucdavis.edu> wrote:
> This came up with a reviewer when I was using glms as well. I've
>  become fond of using the R^2 of the correlation between the fitted and
>  observed values.  It's easily interpretable by a general audience.
>
>  r2.corr.lmer<-function(lmer.object){
>          summary(lm(attr(lmer.object, "y") ~ fitted (lmer.object)))
>  $r.squared}
>
>
>
>
>  On Apr 1, 2008, at 3:37 AM, MHH Stevens wrote:
>
>  > Hi R.S.,
>  > This quantity is not clearly defined for mixed models --- should it
>  > include that which is "explained" by the random effects? What would
>  > it mean to "explain" a response with a variance? In any event, try
>  > searching R-help lists for Coefficient of determination AND lme.
>  > Cheers,
>  > Hank
>  > On Apr 1, 2008, at 6:17 AM, R.S. Cotter wrote:
>  >> Dear mixed models users,
>  >>
>  >> I have recently started using R, and I have learned to use lme ().
>  >>
>  >> Is it possible to interpret coefficient of determination (R^2) when
>  >> using lme ()?
>  >>
>  >>
>  >> Best Regards
>  >>
>  >> R.S. Cotter
>  >>
>  >> _______________________________________________
>  >> R-sig-mixed-models at r-project.org mailing list
>  >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>  >
>  > Dr. Hank Stevens, Assistant Professor
>  > 338 Pearson Hall
>  > Botany Department
>  > Miami University
>  > Oxford, OH 45056
>  >
>  > Office: (513) 529-4206
>  > Lab: (513) 529-4262
>  > FAX: (513) 529-4243
>  > http://www.cas.muohio.edu/~stevenmh/
>  > http://www.cas.muohio.edu/ecology
>  > http://www.muohio.edu/botany/
>  >
>  > "If the stars should appear one night in a thousand years, how would
>  > men
>  > believe and adore." -Ralph Waldo Emerson, writer and philosopher
>  > (1803-1882)
>  >
>  > _______________________________________________
>  > R-sig-mixed-models at r-project.org mailing list
>  > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>  _______________________________________________
>  R-sig-mixed-models at r-project.org mailing list
>  https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From llopez at oikos.unam.mx  Tue Apr  1 19:02:56 2008
From: llopez at oikos.unam.mx (Leonel Arturo Lopez Toledo)
Date: Tue, 1 Apr 2008 11:02:56 -0600
Subject: [R-sig-ME] how to know if random factors are significant?
Message-ID: <20080401165818.M50176@oikos.unam.mx>

Dear all:
I?m new to mixed models and I?m trying to understand the output from ?lme? in the nlme 
package. I hope my question is not too basic for that list-mail. Really sorry if that 
is the case.
Especially I have problems to interpret the random effect output. I have only one 
random factor which is ?Site?. I know the ?Variance and Stdev? indicate variation by 
the random factor, but are they indicating any significance? Is there any way to 
obtain a p-value for the random effects? And in case is not significant, how can I 
remove it from the model? With ?update (model,~.-)?? 

The variance in first case (see below) is very low and in the second example is more 
considerable, but should I consider in the model or do I remove it?

Thank you very much for your help in advance.

EXAMPLE 1
Linear mixed-effects model fit by maximum likelihood
 Data: NULL 
       AIC      BIC    logLik
  277.8272 287.3283 -132.9136

Random effects:
 Formula: ~1 | Sitio
         (Intercept) Residual
StdDev: 0.0005098433 9.709515

EXAMPLE 2
Generalized linear mixed model fit using Laplace 
Formula: y ~Canopy*Area + (1 | Sitio) 
   Data: tod 
 Family: binomial(logit link)
   AIC   BIC logLik deviance
 50.93 54.49 -21.46    42.93

Random effects:
 Groups Name        Variance Std.Dev.
 Sitio  (Intercept) 0.25738  0.50733 
number of obs: 18, groups: Sitio, 6


Leonel Lopez
Centro de Investigaciones en Ecosistemas-UNAM
MEXICO




-- 
Este mensaje ha sido analizado por MailScanner
en busca de virus y otros contenidos peligrosos,
y se considera que est? limpio.
For all your IT requirements visit: http://www.transtec.co.uk



From rune.haubo at gmail.com  Tue Apr  1 19:00:42 2008
From: rune.haubo at gmail.com (Rune Haubo)
Date: Tue, 1 Apr 2008 19:00:42 +0200
Subject: [R-sig-ME] how to know if random factors are significant?
In-Reply-To: <20080401165818.M50176@oikos.unam.mx>
References: <20080401165818.M50176@oikos.unam.mx>
Message-ID: <4949c7e60804011000l3c10f4d6h5d08d3b68c94f08e@mail.gmail.com>

On 01/04/2008, Leonel Arturo Lopez Toledo <llopez at oikos.unam.mx> wrote:
> Dear all:
>  I'm new to mixed models and I'm trying to understand the output from "lme" in the nlme
>  package. I hope my question is not too basic for that list-mail. Really sorry if that
>  is the case.
No need to be sorry. It seems though, that you are also using lmer.

>  Especially I have problems to interpret the random effect output. I have only one
>  random factor which is "Site". I know the "Variance and Stdev" indicate variation by
>  the random factor, but are they indicating any significance? Is there any way to
>  obtain a p-value for the random effects? And in case is not significant, how can I
>  remove it from the model? With "update (model,~.-)"?

In the case of lme, there is no indication of the significance of the
variance parameters in the standard output. To test the variance
component you fit another model excluding that parameter, which i
guess is why you come to think of update(). It is however not possible
to fit a model with lme, that does not contain any random effects,
hence you have to fit a linear model by lm (or gls in package nlme in
case other non-standard stuff is at stake) and make the likelihood
ratio test with anova( fm.lme, fm.lm). Note that order of the
arguments to anova matters in this case (cf ?anova.lme). To obtain a
p-value, you need to compare with some distribution and a chi-square
with one df is the default output. Often however a mixture of 0 and 1
df's are more appropriate, hence a more correct p-value is half the
one, the software reports. You can check these distributions by the
simulate function in the nlme package. When you have more than one
random effect in you model, update works just fine. You should consult
the book: Mixed-Effects Models in S and S-plus by Pinheiro and Bates
for further details.

>
>  The variance in first case (see below) is very low and in the second example is more
>  considerable, but should I consider in the model or do I remove it?

The variance parameter in the first model indeed seems rather small
compared to residual variation. The latter model is incomparable to
the former model, since it is a binomial(logit) GLMM. The obvious
thing to do would be to compare the deviance of this model, with the
corresponding GLM (I am however unsure of how the constant terms in
the likelihood are handled by glm and lmer in this case, so comparison
is perhaps not simple) without the variance component, but then again,
the interpretation of the fixed effect parameters change, so other
issues should also have a say in choosing an appropriate model.

Best
Rune

>
>  Thank you very much for your help in advance.
>
>  EXAMPLE 1
>  Linear mixed-effects model fit by maximum likelihood
>   Data: NULL
>        AIC      BIC    logLik
>   277.8272 287.3283 -132.9136
>
>  Random effects:
>   Formula: ~1 | Sitio
>          (Intercept) Residual
>  StdDev: 0.0005098433 9.709515
>
>  EXAMPLE 2
>  Generalized linear mixed model fit using Laplace
>  Formula: y ~Canopy*Area + (1 | Sitio)
>    Data: tod
>   Family: binomial(logit link)
>    AIC   BIC logLik deviance
>   50.93 54.49 -21.46    42.93
>
>  Random effects:
>   Groups Name        Variance Std.Dev.
>   Sitio  (Intercept) 0.25738  0.50733
>  number of obs: 18, groups: Sitio, 6
>
>
>  Leonel Lopez
>  Centro de Investigaciones en Ecosistemas-UNAM
>  MEXICO
>
>
>
>
>  --
>  Este mensaje ha sido analizado por MailScanner
>  en busca de virus y otros contenidos peligrosos,
>  y se considera que est? limpio.
>  For all your IT requirements visit: http://www.transtec.co.uk
>
>  _______________________________________________
>  R-sig-mixed-models at r-project.org mailing list
>  https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From sundar.dorai-raj at pdf.com  Tue Apr  1 19:50:16 2008
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Tue, 01 Apr 2008 10:50:16 -0700
Subject: [R-sig-ME] lme4::mcmcsamp + coda::HPDinterval
Message-ID: <47F275D8.2090603@pdf.com>

Hi, lmer+coda Users,

(reproducible code at end)

I have a question regarding confidence intervals on the random effects. 
The data I'm working with is a highly unbalanced, nested design with two 
random effects (say, A/B), where the B variance is expected to be larger 
than A variance. I need to compute confidence bounds on the standard 
deviations of each effect (A and A:B). To do this, I use lme4::mcmcsamp 
with coda::HPDinterval. As in,

f <- lmer(...)
m <- mcmcsamp(f, n = 1000)
(s <- sqrt(exp(HPDinterval(m))))

However, one of the point estimates falls below the lower bound of the 
confidence interval. My guess is that this is due to the correlation 
between A and A:B (due to imbalance? relative magnitude of A vs. A:B?) 
leading to an unstable model fit. Are the point estimates completely 
untrustworthy? In this case, should I simply remove the offending random 
effect and refit? Is there a reference that describes situations such as 
these (point estimates outside the C.I.)?

Also, this may be an example where the nlme:::intervals.lme function 
produces intervals that are nonsensical (at least to me) if you change 
sd.A below to, say, 0.5.

Thanks,

--sundar

<code>
set.seed(2)
## simulate data
A <- factor(rep(1:10, each = 4))
n <- length(A)
B <- factor(rep(1:2, 20))
sd.A <- 5
sd.B <- 10
sd.e <- 0.5
rA <- rnorm(nlevels(A), 0, sd.A)
rB <- rnorm(nlevels(A:B), 0, sd.B)
e <- rnorm(n, 0, sd.e)
y <- 0.5 + rA[A] + rB[A:B] + e
## create unbalance
out <- seq(length(y)) %in% sample(length(y), 20)

## fit model
library(lme4)
library(coda)
f <- lmer2(y ~ (1 | A) + (1 | A:B), subset = !out)
m <- mcmcsamp(f, 1000)
v <- VarCorr(f)
s.lmer <- cbind(sqrt(exp(HPDinterval(m[, -1]))),
                 est. = c(attr(v, "sc"), sqrt(sapply(v, as.matrix))),
                 true = c(sd.e, sd.B, sd.A))
s.lmer <- s.lmer[, c("lower", "est.", "upper", "true")]
rownames(s.lmer) <- c("sigma", "A:B", "A")
print(zapsmall(s.lmer), digits = 4)
</code>



From bates at stat.wisc.edu  Tue Apr  1 22:04:14 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 1 Apr 2008 15:04:14 -0500
Subject: [R-sig-ME] Fwd:  lme4::mcmcsamp + coda::HPDinterval
In-Reply-To: <40e66e0b0804011140n2580dc8age75c048c9666ae@mail.gmail.com>
References: <47F275D8.2090603@pdf.com>
	<40e66e0b0804011140n2580dc8age75c048c9666ae@mail.gmail.com>
Message-ID: <40e66e0b0804011304r3dead851r43fc63075bb99e3f@mail.gmail.com>

I replied to Sundar including code and a plot then found that the plot
was too large for the mailing list software.  I have left the plot at
http://www.stat.wisc.edu/~bates/Sundar.pdf or you can run the code to
produce your own copy of the plot.


---------- Forwarded message ----------
From: Douglas Bates <bates at stat.wisc.edu>
Date: Tue, Apr 1, 2008 at 1:40 PM
Subject: Re: [R-sig-ME] lme4::mcmcsamp + coda::HPDinterval
To: Sundar Dorai-Raj <sundar.dorai-raj at pdf.com>
Cc: r-sig-mixed-models at r-project.org


May I suggest that you repeat the experiment in the development
 version of the lme4 package?  In that version the HPDinterval function
 has been moved to lme4 and it is no longer necessary to attach the
 coda package.

 I think it is easier to see what is happening when you use that
 version of the package because you can use the xyplot method to
 examine the evolution of the sampler.  I enclose a modified version of
 your code.  Running this version produces the enclosed plot.  You will
 see that the (relative) standard deviation of A (labelled 'ST2') gets
 stuck near zero.  This is a known problem with MCMC sampling of
 variance components.  The prior distribution corresponds to a "locally
 constant" uninformative prior on log(sigma_A).  As long as the
 likelihood at sigma = zero is sufficiently small to prevent the MCMC
 sampler getting near there the sampler proceeds happily.  However, if
 the likelihood is not sufficiently small then the MCMC sampler may
 wander into the "sigma near zero" region where the posterior density
 of log(sigma) is essentially flat and it gets stuck there.  The recent
 paper by Gelman et al. (JCGS, 2008) provides a suggestion of avoiding
 this problem by overparameterizing the model for the MCMC sampler but
 I haven't yet implemented.





 On Tue, Apr 1, 2008 at 12:50 PM, Sundar Dorai-Raj
 <sundar.dorai-raj at pdf.com> wrote:
 > Hi, lmer+coda Users,
 >
 >  (reproducible code at end)
 >
 >  I have a question regarding confidence intervals on the random effects.
 >  The data I'm working with is a highly unbalanced, nested design with two
 >  random effects (say, A/B), where the B variance is expected to be larger
 >  than A variance. I need to compute confidence bounds on the standard
 >  deviations of each effect (A and A:B). To do this, I use lme4::mcmcsamp
 >  with coda::HPDinterval. As in,
 >
 >  f <- lmer(...)
 >  m <- mcmcsamp(f, n = 1000)
 >  (s <- sqrt(exp(HPDinterval(m))))
 >
 >  However, one of the point estimates falls below the lower bound of the
 >  confidence interval. My guess is that this is due to the correlation
 >  between A and A:B (due to imbalance? relative magnitude of A vs. A:B?)
 >  leading to an unstable model fit. Are the point estimates completely
 >  untrustworthy? In this case, should I simply remove the offending random
 >  effect and refit? Is there a reference that describes situations such as
 >  these (point estimates outside the C.I.)?
 >
 >  Also, this may be an example where the nlme:::intervals.lme function
 >  produces intervals that are nonsensical (at least to me) if you change
 >  sd.A below to, say, 0.5.
 >
 >  Thanks,
 >
 >  --sundar
 >
 >  <code>
 >  set.seed(2)
 >  ## simulate data
 >  A <- factor(rep(1:10, each = 4))
 >  n <- length(A)
 >  B <- factor(rep(1:2, 20))
 >  sd.A <- 5
 >  sd.B <- 10
 >  sd.e <- 0.5
 >  rA <- rnorm(nlevels(A), 0, sd.A)
 >  rB <- rnorm(nlevels(A:B), 0, sd.B)
 >  e <- rnorm(n, 0, sd.e)
 >  y <- 0.5 + rA[A] + rB[A:B] + e
 >  ## create unbalance
 >  out <- seq(length(y)) %in% sample(length(y), 20)
 >
 >  ## fit model
 >  library(lme4)
 >  library(coda)
 >  f <- lmer2(y ~ (1 | A) + (1 | A:B), subset = !out)
 >  m <- mcmcsamp(f, 1000)
 >  v <- VarCorr(f)
 >  s.lmer <- cbind(sqrt(exp(HPDinterval(m[, -1]))),
 >                  est. = c(attr(v, "sc"), sqrt(sapply(v, as.matrix))),
 >                  true = c(sd.e, sd.B, sd.A))
 >  s.lmer <- s.lmer[, c("lower", "est.", "upper", "true")]
 >  rownames(s.lmer) <- c("sigma", "A:B", "A")
 >  print(zapsmall(s.lmer), digits = 4)
 >  </code>
 >
 >  _______________________________________________
 >  R-sig-mixed-models at r-project.org mailing list
 >  https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
 >

From sundar.dorai-raj at pdf.com  Tue Apr  1 22:22:17 2008
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Tue, 01 Apr 2008 13:22:17 -0700
Subject: [R-sig-ME] lme4::mcmcsamp + coda::HPDinterval
In-Reply-To: <40e66e0b0804011140n2580dc8age75c048c9666ae@mail.gmail.com>
References: <47F275D8.2090603@pdf.com>
	<40e66e0b0804011140n2580dc8age75c048c9666ae@mail.gmail.com>
Message-ID: <47F29979.1050509@pdf.com>

Hi, Prof. Bates,

Douglas Bates said the following on 4/1/2008 11:40 AM:
 > This is a known problem with MCMC sampling of
 > variance components.

So, does this mean the confidence interval is in question, and not the 
point estimate? Would Wald intervals not be appropriate either? Or 
profile likelihood intervals? (I know neither are available in lme4 but 
I think could hack it if necessary.)

I've updated the lme4 package have started testing it. Thanks also for 
the Gelman reference. I've requested a copy and will take a look.

Thanks,

--sundar

Douglas Bates said the following on 4/1/2008 11:40 AM:
> May I suggest that you repeat the experiment in the development
> version of the lme4 package?  In that version the HPDinterval function
> has been moved to lme4 and it is no longer necessary to attach the
> coda package.
> 
> I think it is easier to see what is happening when you use that
> version of the package because you can use the xyplot method to
> examine the evolution of the sampler.  I enclose a modified version of
> your code.  Running this version produces the enclosed plot.  You will
> see that the (relative) standard deviation of A (labelled 'ST2') gets
> stuck near zero.  This is a known problem with MCMC sampling of
> variance components.  The prior distribution corresponds to a "locally
> constant" uninformative prior on log(sigma_A).  As long as the
> likelihood at sigma = zero is sufficiently small to prevent the MCMC
> sampler getting near there the sampler proceeds happily.  However, if
> the likelihood is not sufficiently small then the MCMC sampler may
> wander into the "sigma near zero" region where the posterior density
> of log(sigma) is essentially flat and it gets stuck there.  The recent
> paper by Gelman et al. (JCGS, 2008) provides a suggestion of avoiding
> this problem by overparameterizing the model for the MCMC sampler but
> I haven't yet implemented.
> 
> 
> 
> On Tue, Apr 1, 2008 at 12:50 PM, Sundar Dorai-Raj
> <sundar.dorai-raj at pdf.com> wrote:
>> Hi, lmer+coda Users,
>>
>>  (reproducible code at end)
>>
>>  I have a question regarding confidence intervals on the random effects.
>>  The data I'm working with is a highly unbalanced, nested design with two
>>  random effects (say, A/B), where the B variance is expected to be larger
>>  than A variance. I need to compute confidence bounds on the standard
>>  deviations of each effect (A and A:B). To do this, I use lme4::mcmcsamp
>>  with coda::HPDinterval. As in,
>>
>>  f <- lmer(...)
>>  m <- mcmcsamp(f, n = 1000)
>>  (s <- sqrt(exp(HPDinterval(m))))
>>
>>  However, one of the point estimates falls below the lower bound of the
>>  confidence interval. My guess is that this is due to the correlation
>>  between A and A:B (due to imbalance? relative magnitude of A vs. A:B?)
>>  leading to an unstable model fit. Are the point estimates completely
>>  untrustworthy? In this case, should I simply remove the offending random
>>  effect and refit? Is there a reference that describes situations such as
>>  these (point estimates outside the C.I.)?
>>
>>  Also, this may be an example where the nlme:::intervals.lme function
>>  produces intervals that are nonsensical (at least to me) if you change
>>  sd.A below to, say, 0.5.
>>
>>  Thanks,
>>
>>  --sundar
>>
>>  <code>
>>  set.seed(2)
>>  ## simulate data
>>  A <- factor(rep(1:10, each = 4))
>>  n <- length(A)
>>  B <- factor(rep(1:2, 20))
>>  sd.A <- 5
>>  sd.B <- 10
>>  sd.e <- 0.5
>>  rA <- rnorm(nlevels(A), 0, sd.A)
>>  rB <- rnorm(nlevels(A:B), 0, sd.B)
>>  e <- rnorm(n, 0, sd.e)
>>  y <- 0.5 + rA[A] + rB[A:B] + e
>>  ## create unbalance
>>  out <- seq(length(y)) %in% sample(length(y), 20)
>>
>>  ## fit model
>>  library(lme4)
>>  library(coda)
>>  f <- lmer2(y ~ (1 | A) + (1 | A:B), subset = !out)
>>  m <- mcmcsamp(f, 1000)
>>  v <- VarCorr(f)
>>  s.lmer <- cbind(sqrt(exp(HPDinterval(m[, -1]))),
>>                  est. = c(attr(v, "sc"), sqrt(sapply(v, as.matrix))),
>>                  true = c(sd.e, sd.B, sd.A))
>>  s.lmer <- s.lmer[, c("lower", "est.", "upper", "true")]
>>  rownames(s.lmer) <- c("sigma", "A:B", "A")
>>  print(zapsmall(s.lmer), digits = 4)
>>  </code>
>>
>>  _______________________________________________
>>  R-sig-mixed-models at r-project.org mailing list
>>  https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>



From kyler at mail.smu.edu  Tue Apr  1 22:21:28 2008
From: kyler at mail.smu.edu (Roberts, Kyle)
Date: Tue, 1 Apr 2008 15:21:28 -0500
Subject: [R-sig-ME] Coefficient of determination (R^2) when using lme()
In-Reply-To: <47F22287.1060603@dssm.unipa.it>
References: <742479270804010317j6edf2417n7d85754c08fa959e@mail.gmail.com>
	<47F22287.1060603@dssm.unipa.it>
Message-ID: <6FBE93B66C50154D9F1E55B674AFCC9DA45476@s31xe7.systems.smu.edu>

My $0.02.

Gelman also has an excellent article, but he uses Bayes to estimate explained variance, so it may not be as straightforward as other methods.

[2006] Bayesian measures of explained variance and pooling in multilevel (hierarchical) models. Technometrics, 48(2), 241--251. (Andrew Gelman and Iain Pardoe)

I personally am not a fan of simply correlating the fitted values with the raw scores. The problem, as I see it, is that you ran the multilevel model because you wanted to honor the nesting structure (for any number of reasons). I see doing this almost like when people run ANOVAs as a post hoc for a MANOVA. If your analysis is multilevel, then produce a statistic for understanding explained variance that is also multilevel. By the way, I have come full circle on this. I used to think that we needed a single metric to tell us about explained variance in a model (see http://www.hlm-online.com/papers/). Now, I'm not so sure.

One other problem is that unlike the OLS counterpart, in multilevel analysis you can actually ADD variance to your model through the addition of covariates/predictors. This is often a sign of model misspecification, but it can also occur when the model is correctly specified (and no, group mean centering won't always fix this problem). If you do a search on the multilevel listserv, you can see this discussed in length in multiple threads. You can also see a discussion of this in Snijders & Bosker (1999, p. 99-109)

Hope this helps,
Kyle

********************************************************
Dr. J. Kyle Roberts
Department of Literacy, Language and Learning
School of Education and Human Development
Southern Methodist University
P.O. Box 750381
Dallas, TX  75275
214-768-4494
http://www.hlm-online.com/
********************************************************

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of vito muggeo
Sent: Tuesday, April 01, 2008 6:55 AM
To: cotterrs at gmail.com
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Coefficient of determination (R^2) when using lme()

Dear R.S. Cotter,
I think that interpretation of R2 is not straightforward and it is area 
of research.. Have a look to

Xu. Measuring explained variation in linear mixed effects models 
Statist. Med. 2003; 22:3527-3541 (DOI: 10.1002/sim.1572)

Orelien, J.G., Edwards, L.J., Fixed-effect variable selection in linear 
mixed models using R2 statistics Comput. Statist.
Data Anal. (2007), doi: 10.1016/j.csda.2007.06.006

Hope this helps you,

vito



R.S. Cotter ha scritto:
> Dear mixed models users,
> 
> I have recently started using R, and I have learned to use lme ().
> 
> Is it possible to interpret coefficient of determination (R^2) when
> using lme ()?
> 
> 
> Best Regards
> 
> R.S. Cotter
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 

-- 
====================================
Vito M.R. Muggeo
Dip.to Sc Statist e Matem `Vianelli'
Universit? di Palermo
viale delle Scienze, edificio 13
90128 Palermo - ITALY
tel: 091 6626240
fax: 091 485726/485612

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From john.maindonald at anu.edu.au  Wed Apr  2 00:09:47 2008
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Wed, 2 Apr 2008 09:09:47 +1100
Subject: [R-sig-ME] Coefficient of determination (R^2) when using lme()
In-Reply-To: <47F22287.1060603@dssm.unipa.it>
References: <742479270804010317j6edf2417n7d85754c08fa959e@mail.gmail.com>
	<47F22287.1060603@dssm.unipa.it>
Message-ID: <C06B50B6-1EE6-419D-89BE-9FAABEB8D57A@anu.edu.au>

The question should be: "What is one trying to estimate?"
Or "What is one trying to measure?"  Until that is settled,
no amount of research will go anywhere useful.  Once it
is settled, an answer may be quickly forthcoming.

R^2 ought not to be treated as a quantity that has a magic
that is independent of meaningfulness.  Often, it has no
meaningfulness that is relevant to the intended use of the
regression results.  If used at all adjusted R^2 is preferable
to R^2.

R^2 is a design measure, estimating how effectively
the data are designed to extract a regression signal.
Change the design (e.g., in a linear regression by
doubling the range of values of the explanatory variable),
and one changes (in this case, very substantially
increases) the expected value of R^2.

It can also be used as a rather crude way to compare two
models for the one set of data, i.e., with the same 'design'.
But be careful, replacing y by log(y) can increase R^2
and give a model that fits less well, or vice versa.
Consider why that might be!

What aspect of the 'design' that underpins your multilevel
model do you wish to characterize?

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


On 1 Apr 2008, at 10:54 PM, vito muggeo wrote:

> Dear R.S. Cotter,
> I think that interpretation of R2 is not straightforward and it is  
> area
> of research.. Have a look to
>
> Xu. Measuring explained variation in linear mixed effects models
> Statist. Med. 2003; 22:3527?3541 (DOI: 10.1002/sim.1572)
>
> Orelien, J.G., Edwards, L.J., Fixed-effect variable selection in  
> linear
> mixed models using R2 statistics Comput. Statist.
> Data Anal. (2007), doi: 10.1016/j.csda.2007.06.006
>
> Hope this helps you,
>
> vito
>
>
>
> R.S. Cotter ha scritto:
>> Dear mixed models users,
>>
>> I have recently started using R, and I have learned to use lme ().
>>
>> Is it possible to interpret coefficient of determination (R^2) when
>> using lme ()?
>>
>>
>> Best Regards
>>
>> R.S. Cotter
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
> -- 
> ====================================
> Vito M.R. Muggeo
> Dip.to Sc Statist e Matem `Vianelli'
> Universit? di Palermo
> viale delle Scienze, edificio 13
> 90128 Palermo - ITALY
> tel: 091 6626240
> fax: 091 485726/485612
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bates at stat.wisc.edu  Wed Apr  2 00:58:55 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 1 Apr 2008 17:58:55 -0500
Subject: [R-sig-ME] lme4::mcmcsamp + coda::HPDinterval
In-Reply-To: <47F29979.1050509@pdf.com>
References: <47F275D8.2090603@pdf.com>
	<40e66e0b0804011140n2580dc8age75c048c9666ae@mail.gmail.com>
	<47F29979.1050509@pdf.com>
Message-ID: <40e66e0b0804011558m3ec444dfr699d5dd0f052fbb3@mail.gmail.com>

On Tue, Apr 1, 2008 at 3:22 PM, Sundar Dorai-Raj
<sundar.dorai-raj at pdf.com> wrote:
> Hi, Prof. Bates,
>
>  Douglas Bates said the following on 4/1/2008 11:40 AM:
>
>  > This is a known problem with MCMC sampling of
>   > variance components.
>
>  So, does this mean the confidence interval is in question, and not the
>  point estimate?

I think I would characterize it as a problem with the mixing of the
Markov chain.  Another way of looking at it is that it is caused by an
improper posterior distribution for the parameter that is getting
stuck.  Frequently we use an improper prior distribution because the
likelihood will dominate the prior and we end up with a proper
posterior distribution (or close enough to being proper that we don't
encounter problems).  However, if the likelihood flattens out so that
it doesn't dominate the prior and it does this in a place where it is
not much, much smaller than the likelihood at the estimate, then we
have an improper posterior and a non-negligible probability of ending
up on the flat patch.  That's when we get problems.

> Would Wald intervals not be appropriate either? Or
>  profile likelihood intervals? (I know neither are available in lme4 but
>  I think could hack it if necessary.)

That's probably the best approach, although things may get touchy at
the boundary of the parameter space.  I must leave for a meeting now
but tomorrow morning I should be able to draft some code to show how
one would evaluate the profiled likelihood.  Basically you do the
following

# Set the value of the ST parameters (the two relative standard
deviations for this model)
# This also updates the scaled model matrix A.
.Call("mer_ST_setPars", fm, pars, PACKAGE = "lme4")
# Update the sparse Cholesky factor
.Call("mer_update_L", fm, PACKAGE = "lme4")
# Update the other parts of the Cholesky factor
.Call("mer_update_RX", fm, PACKAGE = "lme4")
# extract the deviance or REML deviance
dev  <- fm at deviance["ML"]  # or "REML"

If you want to get sophisticated you can profile one of the ST
parameters with respect to the other.

>  I've updated the lme4 package have started testing it. Thanks also for
>  the Gelman reference. I've requested a copy and will take a look.
>
>  Thanks,
>
>  --sundar
>
>  Douglas Bates said the following on 4/1/2008 11:40 AM:
>
>
> > May I suggest that you repeat the experiment in the development
>  > version of the lme4 package?  In that version the HPDinterval function
>  > has been moved to lme4 and it is no longer necessary to attach the
>  > coda package.
>  >
>  > I think it is easier to see what is happening when you use that
>  > version of the package because you can use the xyplot method to
>  > examine the evolution of the sampler.  I enclose a modified version of
>  > your code.  Running this version produces the enclosed plot.  You will
>  > see that the (relative) standard deviation of A (labelled 'ST2') gets
>  > stuck near zero.  This is a known problem with MCMC sampling of
>  > variance components.  The prior distribution corresponds to a "locally
>  > constant" uninformative prior on log(sigma_A).  As long as the
>  > likelihood at sigma = zero is sufficiently small to prevent the MCMC
>  > sampler getting near there the sampler proceeds happily.  However, if
>  > the likelihood is not sufficiently small then the MCMC sampler may
>  > wander into the "sigma near zero" region where the posterior density
>  > of log(sigma) is essentially flat and it gets stuck there.  The recent
>  > paper by Gelman et al. (JCGS, 2008) provides a suggestion of avoiding
>  > this problem by overparameterizing the model for the MCMC sampler but
>  > I haven't yet implemented.
>  >
>  >
>  >
>  > On Tue, Apr 1, 2008 at 12:50 PM, Sundar Dorai-Raj
>  > <sundar.dorai-raj at pdf.com> wrote:
>  >> Hi, lmer+coda Users,
>  >>
>  >>  (reproducible code at end)
>  >>
>  >>  I have a question regarding confidence intervals on the random effects.
>  >>  The data I'm working with is a highly unbalanced, nested design with two
>  >>  random effects (say, A/B), where the B variance is expected to be larger
>  >>  than A variance. I need to compute confidence bounds on the standard
>  >>  deviations of each effect (A and A:B). To do this, I use lme4::mcmcsamp
>  >>  with coda::HPDinterval. As in,
>  >>
>  >>  f <- lmer(...)
>  >>  m <- mcmcsamp(f, n = 1000)
>  >>  (s <- sqrt(exp(HPDinterval(m))))
>  >>
>  >>  However, one of the point estimates falls below the lower bound of the
>  >>  confidence interval. My guess is that this is due to the correlation
>  >>  between A and A:B (due to imbalance? relative magnitude of A vs. A:B?)
>  >>  leading to an unstable model fit. Are the point estimates completely
>  >>  untrustworthy? In this case, should I simply remove the offending random
>  >>  effect and refit? Is there a reference that describes situations such as
>  >>  these (point estimates outside the C.I.)?
>  >>
>  >>  Also, this may be an example where the nlme:::intervals.lme function
>  >>  produces intervals that are nonsensical (at least to me) if you change
>  >>  sd.A below to, say, 0.5.
>  >>
>  >>  Thanks,
>  >>
>  >>  --sundar
>  >>
>  >>  <code>
>  >>  set.seed(2)
>  >>  ## simulate data
>  >>  A <- factor(rep(1:10, each = 4))
>  >>  n <- length(A)
>  >>  B <- factor(rep(1:2, 20))
>  >>  sd.A <- 5
>  >>  sd.B <- 10
>  >>  sd.e <- 0.5
>  >>  rA <- rnorm(nlevels(A), 0, sd.A)
>  >>  rB <- rnorm(nlevels(A:B), 0, sd.B)
>  >>  e <- rnorm(n, 0, sd.e)
>  >>  y <- 0.5 + rA[A] + rB[A:B] + e
>  >>  ## create unbalance
>  >>  out <- seq(length(y)) %in% sample(length(y), 20)
>  >>
>  >>  ## fit model
>  >>  library(lme4)
>  >>  library(coda)
>  >>  f <- lmer2(y ~ (1 | A) + (1 | A:B), subset = !out)
>  >>  m <- mcmcsamp(f, 1000)
>  >>  v <- VarCorr(f)
>  >>  s.lmer <- cbind(sqrt(exp(HPDinterval(m[, -1]))),
>  >>                  est. = c(attr(v, "sc"), sqrt(sapply(v, as.matrix))),
>  >>                  true = c(sd.e, sd.B, sd.A))
>  >>  s.lmer <- s.lmer[, c("lower", "est.", "upper", "true")]
>  >>  rownames(s.lmer) <- c("sigma", "A:B", "A")
>  >>  print(zapsmall(s.lmer), digits = 4)
>  >>  </code>
>  >>
>  >>  _______________________________________________
>  >>  R-sig-mixed-models at r-project.org mailing list
>  >>  https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>  >>
>  >
>



From john.maindonald at anu.edu.au  Wed Apr  2 04:19:39 2008
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Wed, 2 Apr 2008 13:19:39 +1100
Subject: [R-sig-ME] how to know if random factors are significant?
In-Reply-To: <20080401165818.M50176@oikos.unam.mx>
References: <20080401165818.M50176@oikos.unam.mx>
Message-ID: <BB14B19D-8F1A-4528-B86C-61C42738B6F3@anu.edu.au>

There was a related question from Mariana Martinez a day or two ago.   
Before removing a random term that background knowledge or past  
experience with similar data suggests is likely, check what difference  
it makes to the p-values for the fixed  effects that are of interest.   
If it makes a substantial difference, caution demands that it be left  
it in.

To pretty much repeat my earlier comment:
If you omit the component then you have to contemplate the alternatives:
1) the component really was present but undetectable
2) the component was not present, or so small that it could be  
ignored, and the inference from the model that omits it is valid.

If (1) has a modest probability, and it matters whether you go with  
(1) or (2), going with (2) leads to a very insecure inference. The p- 
value that comes out of the analysis is unreasonably optimistic; it is  
wrong and misleading.

If you do anyway want a Bayesian credible interval, which you can  
treat pretty much as a confidence interval, for the random component,  
check Douglas Bates' message of a few hours ago, the first of two  
messages with the subject "lme4::mcmcsamp + coda::HPDinterval", re the  
use of the function HPDInterval().

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


On 2 Apr 2008, at 4:02 AM, Leonel Arturo Lopez Toledo wrote:

> Dear all:
> I?m new to mixed models and I?m trying to understand the output from  
> ?lme? in the nlme
> package. I hope my question is not too basic for that list-mail.  
> Really sorry if that
> is the case.
> Especially I have problems to interpret the random effect output. I  
> have only one
> random factor which is ?Site?. I know the ?Variance and Stdev?  
> indicate variation by
> the random factor, but are they indicating any significance? Is  
> there any way to
> obtain a p-value for the random effects? And in case is not  
> significant, how can I
> remove it from the model? With ?update (model,~.-)??
>
> The variance in first case (see below) is very low and in the second  
> example is more
> considerable, but should I consider in the model or do I remove it?
>
> Thank you very much for your help in advance.
>
> EXAMPLE 1
> Linear mixed-effects model fit by maximum likelihood
> Data: NULL
>       AIC      BIC    logLik
>  277.8272 287.3283 -132.9136
>
> Random effects:
> Formula: ~1 | Sitio
>         (Intercept) Residual
> StdDev: 0.0005098433 9.709515
>
> EXAMPLE 2
> Generalized linear mixed model fit using Laplace
> Formula: y ~Canopy*Area + (1 | Sitio)
>   Data: tod
> Family: binomial(logit link)
>   AIC   BIC logLik deviance
> 50.93 54.49 -21.46    42.93
>
> Random effects:
> Groups Name        Variance Std.Dev.
> Sitio  (Intercept) 0.25738  0.50733
> number of obs: 18, groups: Sitio, 6
>
>
> Leonel Lopez
> Centro de Investigaciones en Ecosistemas-UNAM
> MEXICO
>
>
>
>
> -- 
> Este mensaje ha sido analizado por MailScanner
> en busca de virus y otros contenidos peligrosos,
> y se considera que est? limpio.
> For all your IT requirements visit: http://www.transtec.co.uk
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From kushler at oakland.edu  Wed Apr  2 05:46:57 2008
From: kushler at oakland.edu (Robert Kushler)
Date: Tue, 01 Apr 2008 23:46:57 -0400
Subject: [R-sig-ME] how to know if random factors are significant?
In-Reply-To: <BB14B19D-8F1A-4528-B86C-61C42738B6F3@anu.edu.au>
References: <20080401165818.M50176@oikos.unam.mx>
	<BB14B19D-8F1A-4528-B86C-61C42738B6F3@anu.edu.au>
Message-ID: <47F301B1.60302@oakland.edu>


Wait a minute ... what p-values?  Have you informed Doug that the
degrees of freedom police have resolved the issue?

:-)    Rob Kushler

(Sorry, couldn't resist.)


John Maindonald wrote:
> There was a related question from Mariana Martinez a day or two ago.   
> Before removing a random term that background knowledge or past  
> experience with similar data suggests is likely, check what difference  
> it makes to the p-values for the fixed  effects that are of interest.   
> If it makes a substantial difference, caution demands that it be left  
> it in.
> 
> To pretty much repeat my earlier comment:
> If you omit the component then you have to contemplate the alternatives:
> 1) the component really was present but undetectable
> 2) the component was not present, or so small that it could be  
> ignored, and the inference from the model that omits it is valid.
> 
> If (1) has a modest probability, and it matters whether you go with  
> (1) or (2), going with (2) leads to a very insecure inference. The p- 
> value that comes out of the analysis is unreasonably optimistic; it is  
> wrong and misleading.
> 
> If you do anyway want a Bayesian credible interval, which you can  
> treat pretty much as a confidence interval, for the random component,  
> check Douglas Bates' message of a few hours ago, the first of two  
> messages with the subject "lme4::mcmcsamp + coda::HPDinterval", re the  
> use of the function HPDInterval().
> 
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> 
> 
> On 2 Apr 2008, at 4:02 AM, Leonel Arturo Lopez Toledo wrote:
> 
>> Dear all:
>> I?m new to mixed models and I?m trying to understand the output from  
>> ?lme? in the nlme
>> package. I hope my question is not too basic for that list-mail.  
>> Really sorry if that
>> is the case.
>> Especially I have problems to interpret the random effect output. I  
>> have only one
>> random factor which is ?Site?. I know the ?Variance and Stdev?  
>> indicate variation by
>> the random factor, but are they indicating any significance? Is  
>> there any way to
>> obtain a p-value for the random effects? And in case is not  
>> significant, how can I
>> remove it from the model? With ?update (model,~.-)??
>>
>> The variance in first case (see below) is very low and in the second  
>> example is more
>> considerable, but should I consider in the model or do I remove it?
>>
>> Thank you very much for your help in advance.
>>
>> EXAMPLE 1
>> Linear mixed-effects model fit by maximum likelihood
>> Data: NULL
>>       AIC      BIC    logLik
>>  277.8272 287.3283 -132.9136
>>
>> Random effects:
>> Formula: ~1 | Sitio
>>         (Intercept) Residual
>> StdDev: 0.0005098433 9.709515
>>
>> EXAMPLE 2
>> Generalized linear mixed model fit using Laplace
>> Formula: y ~Canopy*Area + (1 | Sitio)
>>   Data: tod
>> Family: binomial(logit link)
>>   AIC   BIC logLik deviance
>> 50.93 54.49 -21.46    42.93
>>
>> Random effects:
>> Groups Name        Variance Std.Dev.
>> Sitio  (Intercept) 0.25738  0.50733
>> number of obs: 18, groups: Sitio, 6
>>
>>
>> Leonel Lopez
>> Centro de Investigaciones en Ecosistemas-UNAM
>> MEXICO
>>
>>
>>
>>
>> -- 
>> Este mensaje ha sido analizado por MailScanner
>> en busca de virus y otros contenidos peligrosos,
>> y se considera que est? limpio.
>> For all your IT requirements visit: http://www.transtec.co.uk
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From John.Maindonald at anu.edu.au  Wed Apr  2 08:21:52 2008
From: John.Maindonald at anu.edu.au (John Maindonald)
Date: Wed, 2 Apr 2008 17:21:52 +1100
Subject: [R-sig-ME] how to know if random factors are significant?
In-Reply-To: <47F301B1.60302@oakland.edu>
References: <20080401165818.M50176@oikos.unam.mx>
	<BB14B19D-8F1A-4528-B86C-61C42738B6F3@anu.edu.au>
	<47F301B1.60302@oakland.edu>
Message-ID: <5AA37B8F-9B6B-4CE3-BE18-7F6002875DC5@anu.edu.au>

Sure, I should have said:
"p-values (once one has worked out how to calculate them)"

Where was it said that degrees of freedom would necessarily help,  
especially for a generalized linear mixed model?
:-) John.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


On 2 Apr 2008, at 2:46 PM, Robert Kushler wrote:

>
> Wait a minute ... what p-values?  Have you informed Doug that the
> degrees of freedom police have resolved the issue?
>
> :-)    Rob Kushler
>
> (Sorry, couldn't resist.)
>
>
> John Maindonald wrote:
>> There was a related question from Mariana Martinez a day or two  
>> ago.   Before removing a random term that background knowledge or  
>> past  experience with similar data suggests is likely, check what  
>> difference  it makes to the p-values for the fixed  effects that  
>> are of interest.   If it makes a substantial difference, caution  
>> demands that it be left  it in.
>> To pretty much repeat my earlier comment:
>> If you omit the component then you have to contemplate the  
>> alternatives:
>> 1) the component really was present but undetectable
>> 2) the component was not present, or so small that it could be   
>> ignored, and the inference from the model that omits it is valid.
>> If (1) has a modest probability, and it matters whether you go  
>> with  (1) or (2), going with (2) leads to a very insecure  
>> inference. The p- value that comes out of the analysis is  
>> unreasonably optimistic; it is  wrong and misleading.
>> If you do anyway want a Bayesian credible interval, which you can   
>> treat pretty much as a confidence interval, for the random  
>> component,  check Douglas Bates' message of a few hours ago, the  
>> first of two  messages with the subject "lme4::mcmcsamp +  
>> coda::HPDinterval", re the  use of the function HPDInterval().
>> John Maindonald             email: john.maindonald at anu.edu.au
>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>> Centre for Mathematics & Its Applications, Room 1194,
>> John Dedman Mathematical Sciences Building (Building 27)
>> Australian National University, Canberra ACT 0200.
>> On 2 Apr 2008, at 4:02 AM, Leonel Arturo Lopez Toledo wrote:
>>> Dear all:
>>> I?m new to mixed models and I?m trying to understand the output  
>>> from  ?lme? in the nlme
>>> package. I hope my question is not too basic for that list-mail.   
>>> Really sorry if that
>>> is the case.
>>> Especially I have problems to interpret the random effect output.  
>>> I  have only one
>>> random factor which is ?Site?. I know the ?Variance and Stdev?   
>>> indicate variation by
>>> the random factor, but are they indicating any significance? Is   
>>> there any way to
>>> obtain a p-value for the random effects? And in case is not   
>>> significant, how can I
>>> remove it from the model? With ?update (model,~.-)??
>>>
>>> The variance in first case (see below) is very low and in the  
>>> second  example is more
>>> considerable, but should I consider in the model or do I remove it?
>>>
>>> Thank you very much for your help in advance.
>>>
>>> EXAMPLE 1
>>> Linear mixed-effects model fit by maximum likelihood
>>> Data: NULL
>>>     AIC      BIC    logLik
>>> 277.8272 287.3283 -132.9136
>>>
>>> Random effects:
>>> Formula: ~1 | Sitio
>>>       (Intercept) Residual
>>> StdDev: 0.0005098433 9.709515
>>>
>>> EXAMPLE 2
>>> Generalized linear mixed model fit using Laplace
>>> Formula: y ~Canopy*Area + (1 | Sitio)
>>> Data: tod
>>> Family: binomial(logit link)
>>> AIC   BIC logLik deviance
>>> 50.93 54.49 -21.46    42.93
>>>
>>> Random effects:
>>> Groups Name        Variance Std.Dev.
>>> Sitio  (Intercept) 0.25738  0.50733
>>> number of obs: 18, groups: Sitio, 6
>>>
>>>
>>> Leonel Lopez
>>> Centro de Investigaciones en Ecosistemas-UNAM
>>> MEXICO
>>>
>>>
>>>
>>>
>>> -- 
>>> Este mensaje ha sido analizado por MailScanner
>>> en busca de virus y otros contenidos peligrosos,
>>> y se considera que est? limpio.
>>> For all your IT requirements visit: http://www.transtec.co.uk
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From rune.haubo at gmail.com  Wed Apr  2 09:35:59 2008
From: rune.haubo at gmail.com (Rune Haubo)
Date: Wed, 2 Apr 2008 09:35:59 +0200
Subject: [R-sig-ME] how to know if random factors are significant?
In-Reply-To: <BB14B19D-8F1A-4528-B86C-61C42738B6F3@anu.edu.au>
References: <20080401165818.M50176@oikos.unam.mx>
	<BB14B19D-8F1A-4528-B86C-61C42738B6F3@anu.edu.au>
Message-ID: <4949c7e60804020035g2934b01fx500ee31f8a1b1664@mail.gmail.com>

On 02/04/2008, John Maindonald <john.maindonald at anu.edu.au> wrote:
> There was a related question from Mariana Martinez a day or two ago.
>  Before removing a random term that background knowledge or past
>  experience with similar data suggests is likely, check what difference
>  it makes to the p-values for the fixed  effects that are of interest.
>  If it makes a substantial difference, caution demands that it be left
>  it in.
>
>  To pretty much repeat my earlier comment:
>  If you omit the component then you have to contemplate the alternatives:
>  1) the component really was present but undetectable
>  2) the component was not present, or so small that it could be
>  ignored, and the inference from the model that omits it is valid.
>
>  If (1) has a modest probability, and it matters whether you go with
>  (1) or (2), going with (2) leads to a very insecure inference. The p-
>  value that comes out of the analysis is unreasonably optimistic; it is
>  wrong and misleading.

I think this is a question of strategy. Leonel did put emphasis on the
random effect, and he might just be interested in the size and
significance of the random effect rather than the fixed effects.
Estimating and testing the random effect seems reasonable to me in
this case, although confidence intervals, as you mention below also
provides good inference.

It is always possible to discuss how much non-data information to
include in an analysis and I believe the answer depends very much on
the purpose of the research. If the research question regards the size
and "existence" of the variance of 'Site', then he might conclude that
it is so small compared to other effects in the model/data, that it
has no place in the model.

I think the question regarding "existence" of some effect can be
misleading in many cases, because one can always claim that any effect
is really there, and had we observed enough data, we would be able to
estimate the effect reliably. Leaving too many variables in the model
on which there is too little information also results in bias in
parameter estimates, so it is a trade off. We often speak of
appropriate models, but the appropriateness depends on the purpose -
do we seek inference for a specific (set of) parameter(s), the system
as a whole or do we want to use it for prediction?

/Rune
>
>  If you do anyway want a Bayesian credible interval, which you can
>  treat pretty much as a confidence interval, for the random component,
>  check Douglas Bates' message of a few hours ago, the first of two
>  messages with the subject "lme4::mcmcsamp + coda::HPDinterval", re the
>  use of the function HPDInterval().
>
>
>  John Maindonald             email: john.maindonald at anu.edu.au
>  phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>  Centre for Mathematics & Its Applications, Room 1194,
>  John Dedman Mathematical Sciences Building (Building 27)
>  Australian National University, Canberra ACT 0200.
>
>
>
>  On 2 Apr 2008, at 4:02 AM, Leonel Arturo Lopez Toledo wrote:
>
>  > Dear all:
>  > I'm new to mixed models and I'm trying to understand the output from
>  > "lme" in the nlme
>  > package. I hope my question is not too basic for that list-mail.
>  > Really sorry if that
>  > is the case.
>  > Especially I have problems to interpret the random effect output. I
>  > have only one
>  > random factor which is "Site". I know the "Variance and Stdev"
>  > indicate variation by
>  > the random factor, but are they indicating any significance? Is
>  > there any way to
>  > obtain a p-value for the random effects? And in case is not
>  > significant, how can I
>  > remove it from the model? With "update (model,~.-)"?
>  >
>  > The variance in first case (see below) is very low and in the second
>  > example is more
>  > considerable, but should I consider in the model or do I remove it?
>  >
>  > Thank you very much for your help in advance.
>  >
>  > EXAMPLE 1
>  > Linear mixed-effects model fit by maximum likelihood
>  > Data: NULL
>  >       AIC      BIC    logLik
>  >  277.8272 287.3283 -132.9136
>  >
>  > Random effects:
>  > Formula: ~1 | Sitio
>  >         (Intercept) Residual
>  > StdDev: 0.0005098433 9.709515
>  >
>  > EXAMPLE 2
>  > Generalized linear mixed model fit using Laplace
>  > Formula: y ~Canopy*Area + (1 | Sitio)
>  >   Data: tod
>  > Family: binomial(logit link)
>  >   AIC   BIC logLik deviance
>  > 50.93 54.49 -21.46    42.93
>  >
>  > Random effects:
>  > Groups Name        Variance Std.Dev.
>  > Sitio  (Intercept) 0.25738  0.50733
>  > number of obs: 18, groups: Sitio, 6
>  >
>  >
>  > Leonel Lopez
>  > Centro de Investigaciones en Ecosistemas-UNAM
>  > MEXICO
>  >
>  >
>  >
>  >
>  > --
>  > Este mensaje ha sido analizado por MailScanner
>  > en busca de virus y otros contenidos peligrosos,
>  > y se considera que est? limpio.
>  > For all your IT requirements visit: http://www.transtec.co.uk
>  >
>  > _______________________________________________
>  > R-sig-mixed-models at r-project.org mailing list
>  > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>  _______________________________________________
>  R-sig-mixed-models at r-project.org mailing list
>  https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From llopez at oikos.unam.mx  Wed Apr  2 12:39:09 2008
From: llopez at oikos.unam.mx (Leonel Arturo Lopez Toledo)
Date: Wed, 2 Apr 2008 04:39:09 -0600
Subject: [R-sig-ME] how to know if random factors are significant?
In-Reply-To: <4949c7e60804020035g2934b01fx500ee31f8a1b1664@mail.gmail.com>
References: <20080401165818.M50176@oikos.unam.mx>
	<BB14B19D-8F1A-4528-B86C-61C42738B6F3@anu.edu.au>
	<4949c7e60804020035g2934b01fx500ee31f8a1b1664@mail.gmail.com>
Message-ID: <20080402103622.M550@oikos.unam.mx>

Dear all:
Thank you very much all for your comments. I?m trying everything you said and checked 
previous messages from Marianne, John and Douglas Bates. I found that removing the 
random factor reduced the p-values for fixed effects (as John mentioned) and this new 
model has not better significant power indicated by the likelihood ration test. 
So, even with a low Variance the random factor must be used in a mix model effects.

Thank you very much for your help. I'm understanding and learning so much with the "R-
help lists".

Leo



-- 
Este mensaje ha sido analizado por MailScanner
en busca de virus y otros contenidos peligrosos,
y se considera que est? limpio.
For all your IT requirements visit: http://www.transtec.co.uk



From HStevens at muohio.edu  Wed Apr  2 12:27:13 2008
From: HStevens at muohio.edu (MHH Stevens)
Date: Wed, 2 Apr 2008 06:27:13 -0400
Subject: [R-sig-ME] how to know if random factors are significant?
In-Reply-To: <4949c7e60804020035g2934b01fx500ee31f8a1b1664@mail.gmail.com>
References: <20080401165818.M50176@oikos.unam.mx>
	<BB14B19D-8F1A-4528-B86C-61C42738B6F3@anu.edu.au>
	<4949c7e60804020035g2934b01fx500ee31f8a1b1664@mail.gmail.com>
Message-ID: <A19A77C8-01AD-4454-9797-8202A5AADB9A@muohio.edu>


On Apr 2, 2008, at 3:35 AM, Rune Haubo wrote:
> On 02/04/2008, John Maindonald <john.maindonald at anu.edu.au> wrote:
>> There was a related question from Mariana Martinez a day or two ago.
>>  Before removing a random term that background knowledge or past
>>  experience with similar data suggests is likely, check what  
>> difference
>>  it makes to the p-values for the fixed  effects that are of  
>> interest.
>>  If it makes a substantial difference, caution demands that it be  
>> left
>>  it in.
>>
>>  To pretty much repeat my earlier comment:
>>  If you omit the component then you have to contemplate the  
>> alternatives:
>>  1) the component really was present but undetectable
>>  2) the component was not present, or so small that it could be
>>  ignored, and the inference from the model that omits it is valid.
>>
>>  If (1) has a modest probability, and it matters whether you go with
>>  (1) or (2), going with (2) leads to a very insecure inference.  
>> The p-
>>  value that comes out of the analysis is unreasonably optimistic;  
>> it is
>>  wrong and misleading.
Can "caution" ever cause us to select the more "optimistic" model? If  
we assume that the absence of the random effect reduces the p-value  
of the fixed effect, we might ponder the situation in which there is  
a meaningful risk associated with with ignoring type II error (that  
we erroneously accept the null hypothesis). Imagine field testing the  
effects of a pesticide on non-target organisms --- does (2) result in  
a "minimum" p-value, or is the p-value, as John said, wrong and  
misleading?

More generally, if a random effect has the real potential to exist  
(has a "modest probability"), but we don't see evidence for it in our  
particular data set, does it exist for us? (i.e. "If a tree  
falls ..." or worse, Heisenberg's proposition, Is the cat dead if we  
don't look?). I have typically acted as though it does not exist if I  
do not have evidence for it in MY data. However, when it does make a  
significant difference, I do lose sleep over it.

-Hank
>
> I think this is a question of strategy. Leonel did put emphasis on the
> random effect, and he might just be interested in the size and
> significance of the random effect rather than the fixed effects.
> Estimating and testing the random effect seems reasonable to me in
> this case, although confidence intervals, as you mention below also
> provides good inference.
>
> It is always possible to discuss how much non-data information to
> include in an analysis and I believe the answer depends very much on
> the purpose of the research. If the research question regards the size
> and "existence" of the variance of 'Site', then he might conclude that
> it is so small compared to other effects in the model/data, that it
> has no place in the model.
>
> I think the question regarding "existence" of some effect can be
> misleading in many cases, because one can always claim that any effect
> is really there, and had we observed enough data, we would be able to
> estimate the effect reliably. Leaving too many variables in the model
> on which there is too little information also results in bias in
> parameter estimates, so it is a trade off. We often speak of
> appropriate models, but the appropriateness depends on the purpose -
> do we seek inference for a specific (set of) parameter(s), the system
> as a whole or do we want to use it for prediction?
>
> /Rune
>>
>>  If you do anyway want a Bayesian credible interval, which you can
>>  treat pretty much as a confidence interval, for the random  
>> component,
>>  check Douglas Bates' message of a few hours ago, the first of two
>>  messages with the subject "lme4::mcmcsamp + coda::HPDinterval",  
>> re the
>>  use of the function HPDInterval().
>>
>>
>>  John Maindonald             email: john.maindonald at anu.edu.au
>>  phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>>  Centre for Mathematics & Its Applications, Room 1194,
>>  John Dedman Mathematical Sciences Building (Building 27)
>>  Australian National University, Canberra ACT 0200.
>>
>>
>>
>>  On 2 Apr 2008, at 4:02 AM, Leonel Arturo Lopez Toledo wrote:
>>
>>> Dear all:
>>> I'm new to mixed models and I'm trying to understand the output from
>>> "lme" in the nlme
>>> package. I hope my question is not too basic for that list-mail.
>>> Really sorry if that
>>> is the case.
>>> Especially I have problems to interpret the random effect output. I
>>> have only one
>>> random factor which is "Site". I know the "Variance and Stdev"
>>> indicate variation by
>>> the random factor, but are they indicating any significance? Is
>>> there any way to
>>> obtain a p-value for the random effects? And in case is not
>>> significant, how can I
>>> remove it from the model? With "update (model,~.-)"?
>>>
>>> The variance in first case (see below) is very low and in the second
>>> example is more
>>> considerable, but should I consider in the model or do I remove it?
>>>
>>> Thank you very much for your help in advance.
>>>
>>> EXAMPLE 1
>>> Linear mixed-effects model fit by maximum likelihood
>>> Data: NULL
>>>       AIC      BIC    logLik
>>>  277.8272 287.3283 -132.9136
>>>
>>> Random effects:
>>> Formula: ~1 | Sitio
>>>         (Intercept) Residual
>>> StdDev: 0.0005098433 9.709515
>>>
>>> EXAMPLE 2
>>> Generalized linear mixed model fit using Laplace
>>> Formula: y ~Canopy*Area + (1 | Sitio)
>>>   Data: tod
>>> Family: binomial(logit link)
>>>   AIC   BIC logLik deviance
>>> 50.93 54.49 -21.46    42.93
>>>
>>> Random effects:
>>> Groups Name        Variance Std.Dev.
>>> Sitio  (Intercept) 0.25738  0.50733
>>> number of obs: 18, groups: Sitio, 6
>>>
>>>
>>> Leonel Lopez
>>> Centro de Investigaciones en Ecosistemas-UNAM
>>> MEXICO
>>>
>>>
>>>
>>>
>>> --
>>> Este mensaje ha sido analizado por MailScanner
>>> en busca de virus y otros contenidos peligrosos,
>>> y se considera que est? limpio.
>>> For all your IT requirements visit: http://www.transtec.co.uk
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>  _______________________________________________
>>  R-sig-mixed-models at r-project.org mailing list
>>  https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

Dr. Hank Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/~stevenmh/
http://www.cas.muohio.edu/ecology
http://www.muohio.edu/botany/

"If the stars should appear one night in a thousand years, how would men
believe and adore." -Ralph Waldo Emerson, writer and philosopher  
(1803-1882)



From John.Maindonald at anu.edu.au  Wed Apr  2 12:53:05 2008
From: John.Maindonald at anu.edu.au (John Maindonald)
Date: Wed, 2 Apr 2008 21:53:05 +1100
Subject: [R-sig-ME] how to know if random factors are significant?
In-Reply-To: <4949c7e60804020035g2934b01fx500ee31f8a1b1664@mail.gmail.com>
References: <20080401165818.M50176@oikos.unam.mx>
	<BB14B19D-8F1A-4528-B86C-61C42738B6F3@anu.edu.au>
	<4949c7e60804020035g2934b01fx500ee31f8a1b1664@mail.gmail.com>
Message-ID: <A3865D67-C543-44D8-88CB-FDCD7A77B8B6@anu.edu.au>

Just one further comment.  When removing nonsignificant random  
components  makes scant difference for the inferences that are of  
interest, I'd go along with a case for removing them.  The same may  
even apply to components that are significant but of small consequence  
relative to components within which they are nested.  I have in mind  
models with a relatively complicated hierarchical structure.  Or it  
may be possible, with advantages for ease of interpretation, to  
replace a crossed random effects model with a hierarchical model.

A model where there are just two plausible random components, such as  
Site in addition to 'Residual', is a very different case.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


On 2 Apr 2008, at 6:35 PM, Rune Haubo wrote:

> On 02/04/2008, John Maindonald <john.maindonald at anu.edu.au> wrote:
>> There was a related question from Mariana Martinez a day or two ago.
>> Before removing a random term that background knowledge or past
>> experience with similar data suggests is likely, check what  
>> difference
>> it makes to the p-values for the fixed  effects that are of interest.
>> If it makes a substantial difference, caution demands that it be left
>> it in.
>>
>> To pretty much repeat my earlier comment:
>> If you omit the component then you have to contemplate the  
>> alternatives:
>> 1) the component really was present but undetectable
>> 2) the component was not present, or so small that it could be
>> ignored, and the inference from the model that omits it is valid.
>>
>> If (1) has a modest probability, and it matters whether you go with
>> (1) or (2), going with (2) leads to a very insecure inference. The p-
>> value that comes out of the analysis is unreasonably optimistic; it  
>> is
>> wrong and misleading.
>
> I think this is a question of strategy. Leonel did put emphasis on the
> random effect, and he might just be interested in the size and
> significance of the random effect rather than the fixed effects.
> Estimating and testing the random effect seems reasonable to me in
> this case, although confidence intervals, as you mention below also
> provides good inference.
>
> It is always possible to discuss how much non-data information to
> include in an analysis and I believe the answer depends very much on
> the purpose of the research. If the research question regards the size
> and "existence" of the variance of 'Site', then he might conclude that
> it is so small compared to other effects in the model/data, that it
> has no place in the model.
>
> I think the question regarding "existence" of some effect can be
> misleading in many cases, because one can always claim that any effect
> is really there, and had we observed enough data, we would be able to
> estimate the effect reliably. Leaving too many variables in the model
> on which there is too little information also results in bias in
> parameter estimates, so it is a trade off. We often speak of
> appropriate models, but the appropriateness depends on the purpose -
> do we seek inference for a specific (set of) parameter(s), the system
> as a whole or do we want to use it for prediction?
>
> /Rune
>>
>> If you do anyway want a Bayesian credible interval, which you can
>> treat pretty much as a confidence interval, for the random component,
>> check Douglas Bates' message of a few hours ago, the first of two
>> messages with the subject "lme4::mcmcsamp + coda::HPDinterval", re  
>> the
>> use of the function HPDInterval().
>>
>>
>> John Maindonald             email: john.maindonald at anu.edu.au
>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>> Centre for Mathematics & Its Applications, Room 1194,
>> John Dedman Mathematical Sciences Building (Building 27)
>> Australian National University, Canberra ACT 0200.
>>
>>
>>
>> On 2 Apr 2008, at 4:02 AM, Leonel Arturo Lopez Toledo wrote:
>>
>>> Dear all:
>>> I'm new to mixed models and I'm trying to understand the output from
>>> "lme" in the nlme
>>> package. I hope my question is not too basic for that list-mail.
>>> Really sorry if that
>>> is the case.
>>> Especially I have problems to interpret the random effect output. I
>>> have only one
>>> random factor which is "Site". I know the "Variance and Stdev"
>>> indicate variation by
>>> the random factor, but are they indicating any significance? Is
>>> there any way to
>>> obtain a p-value for the random effects? And in case is not
>>> significant, how can I
>>> remove it from the model? With "update (model,~.-)"?
>>>
>>> The variance in first case (see below) is very low and in the second
>>> example is more
>>> considerable, but should I consider in the model or do I remove it?
>>>
>>> Thank you very much for your help in advance.
>>>
>>> EXAMPLE 1
>>> Linear mixed-effects model fit by maximum likelihood
>>> Data: NULL
>>>     AIC      BIC    logLik
>>> 277.8272 287.3283 -132.9136
>>>
>>> Random effects:
>>> Formula: ~1 | Sitio
>>>       (Intercept) Residual
>>> StdDev: 0.0005098433 9.709515
>>>
>>> EXAMPLE 2
>>> Generalized linear mixed model fit using Laplace
>>> Formula: y ~Canopy*Area + (1 | Sitio)
>>> Data: tod
>>> Family: binomial(logit link)
>>> AIC   BIC logLik deviance
>>> 50.93 54.49 -21.46    42.93
>>>
>>> Random effects:
>>> Groups Name        Variance Std.Dev.
>>> Sitio  (Intercept) 0.25738  0.50733
>>> number of obs: 18, groups: Sitio, 6
>>>
>>>
>>> Leonel Lopez
>>> Centro de Investigaciones en Ecosistemas-UNAM
>>> MEXICO
>>>
>>>
>>>
>>>
>>> --
>>> Este mensaje ha sido analizado por MailScanner
>>> en busca de virus y otros contenidos peligrosos,
>>> y se considera que est? limpio.
>>> For all your IT requirements visit: http://www.transtec.co.uk
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>



From Fabian.Scheipl at stat.uni-muenchen.de  Wed Apr  2 09:32:01 2008
From: Fabian.Scheipl at stat.uni-muenchen.de (Fabian Scheipl)
Date: Wed, 2 Apr 2008 09:32:01 +0200
Subject: [R-sig-ME] how to know if random factors are significant?
Message-ID: <4836bc6a0804020032q2662f086m4301e62f8021aa07@mail.gmail.com>

>To obtain a
>p-value, you need to compare with some distribution and a chi-square
>with one df is the default output. Often however a mixture of 0 and 1
>df's are more appropriate, hence a more correct p-value is half the
>one, the software reports.

For linear mixed models with uncorrelated random effects, our package
RLRsim offers a rapid algorithm to determine the exact finite sample
distribution of the restricted likelihood ratio for testing whether
the variance of a random effect is zero.
Using the ChiSquare(1) or a 50:50  mixture of ChiSquare(1) and 0 will
almost always lead to very conservative tests. For a detailed
comparison of various approaches to test for zero variance in linear
mixed models have a look at:

 F.Scheipl, S.Greven, H.K?chenhoff (2008): Size and power of tests for
a zero random effect variance or polynomial regression in additive and
linear mixed models.
 Computational Statistics & Data Analysis, 52(7):3283-3299
(http://dx.doi.org/10.1016/j.csda.2007.10.022).



From fajardo.alex at gmail.com  Wed Apr  2 16:17:50 2008
From: fajardo.alex at gmail.com (Alex Fajardo)
Date: Wed, 2 Apr 2008 07:17:50 -0700
Subject: [R-sig-ME] random factor and error messages in the model fitting
Message-ID: <f69dbed20804020717q772724cfoddded38188850a20@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080402/3a9a89f7/attachment.pl>

From HStevens at MUOhio.edu  Wed Apr  2 19:02:56 2008
From: HStevens at MUOhio.edu (Hank Stevens)
Date: Wed, 2 Apr 2008 13:02:56 -0400
Subject: [R-sig-ME] random factor and error messages in the model fitting
In-Reply-To: <f69dbed20804020717q772724cfoddded38188850a20@mail.gmail.com>
References: <f69dbed20804020717q772724cfoddded38188850a20@mail.gmail.com>
Message-ID: <FE28EB62-8092-4134-B2D6-024147EB94C2@MUOhio.edu>

Hi Alex,
On Apr 2, 2008, at 10:17 AM, Alex Fajardo wrote:

> Dear r-sig-mixed-models webmail list members,
>
> I am new in the mixed-effects models world and I am learning from  
> Faraway's
> and Pinheiro & Bates' books and also from this list.
> I have 3, very straightforward, questions, but first a brief summary  
> of my
> analysis objectives. I am trying to analyze my data with mixed effects
> models where the fixed factor is represented by altitudinal  
> transects (4
> transects, where T4 is treeline, and T1, T2 and T3 are below  
> treeline). In
> each altitudinal transect I collected tissue samples from different
> age-class trees (a categorical variable with 4 levels, I, II, III,  
> and IV);
> all this with the main objective to compare specific leaf area -SLA-  
> of the
> treeline trees with lower elevation transects, and take into account  
> the
> age-class of the tree being considered. The data set is very  
> unbalanced and
> reading similar papers I concluded that age-class should be  
> considered a
> random factor nested in transects.
>
> *Question 1*: am I correct by considering age-class a random factor  
> nested
> within transect? If so, what should be the way to code the model?
> My suggestion is:
>> sla.termas = lmer(SLA ~ 1 + Transect + (1|Transect:Age),
> data=Treeline[Site=="TermasChillan",], na.action=na.omit) or
>> sla.termas = lmer(SLA ~ 1 + Transect + (Transect|Age),
> data=Treeline[Site=="TermasChillan",], na.action=na.omit), but I am  
> not
> sure.
I would assume that Age is NOT nested; if it is, you are saying that  
the effect of age could depend entirely on which transect you look at.  
Rather, I assume different ages simply have different responses, i.e.,  
(1|Age).

However, I would think that a fixed effect model is just as useful.
lm( SLA ~ Transect + Age + Age:Transect)

I am not sure why these altitudes or age class are considered a random  
draw from a large number of such classes that you know little about.  
They seem entirely repeated, and usefully so.

My two cents,
Hank
>
>
>
> In my learning process I followed examples given in Faraway's book  
> and just
> for learning purposes I computed my model in the way he does  
> (considering
> both factors random) and got, for some, variables the following  
> warning
> message:
>
>> sla.termas = lmer(SLA ~ 1 + (1|Transect) + (1|Transect:Age),
> data=Treeline[Site=="TermasChillan",], na.action=na.omit)
> *Warning message: In .local(x, ..., value) :
>  Estimated variance-covariance for factor 'Age' is singular*
>
> This is not good when I try to test the significance of the  
> variation among
> ages by ANOVA, since I get a Pr(>Chisq)=1; something must be wrong.  
> This
> situation happens with some variables and not with all of them:  
> strange?
>
> *Question 2*: any idea why this happens? What am I doing wrong?
>
> When I do get the model run (no such a warning message and just for  
> some
> other variables) and compare this model with a reduced version  
> (without the
> nested random factor, e.g., age-class) I run anova and get a p- 
> value. As
> suggested by Faraway I should also go for a p-value computing LRT  
> 1000 times
> (less conservative cf. Faraway) and most of the time I get the  
> following
> message:
>
>> lrstat = numeric(1000)
>> for(i in 1:1000){
> + rSLA = unlist(simulate(sla.termas2))
> + nmod =
> lmer(rSLA~1+(1| 
> Transect),data=Treeline[Site=="TermasChillan",],na.action=na.omit)
> + amod =
> lmer(rSLA~1+(1|Transect)+(1| 
> Transect:Age),data=Treeline[Site=="TermasChillan",],na.action=na.omit)
> + lrstat[i] = 2*(logLik(amod)-logLik(nmod))
> + }
> *Error in model.frame.default(data = Treeline[Site ==  
> "TermasChillan",  :
>  variable lengths differ (found for 'Transect')*
>
> *Question 3*: any idea why this happens? What am I doing wrong? I  
> made an
> artificial balanced data set to see whether the unbalanced situation  
> was the
> responsible for this message but it was not.
>
> I am new in the mixed-effects models world but I want to learn; your
> comments and advice will be greatly appreciated. Cheers,
>
>
>
> --
> Alex Fajardo, PhD
> Investigador Asociado
> Centro de Investigaci?n en Ecosistemas de la Patagonia
> Bilbao 449. Coyhaique, CHILE
> Telefonos: 56-67-244503; (56) 8-4506354
> Fax: 56-67-244501
> alex.fajardo at ciep.cl
>
>        [[alternative HTML version deleted]]
>
> <ATT00001.txt>



Dr. Hank Stevens, Associate Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/~stevenmh/
http://www.cas.muohio.edu/ecology
http://www.muohio.edu/botany/

"If the stars should appear one night in a thousand years, how would men
believe and adore." -Ralph Waldo Emerson, writer and philosopher  
(1803-1882)



From bates at stat.wisc.edu  Wed Apr  2 19:51:40 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 2 Apr 2008 12:51:40 -0500
Subject: [R-sig-ME] lme4::mcmcsamp + coda::HPDinterval
In-Reply-To: <47F39ABD.2030602@pdf.com>
References: <47F275D8.2090603@pdf.com>
	<40e66e0b0804011140n2580dc8age75c048c9666ae@mail.gmail.com>
	<47F29979.1050509@pdf.com>
	<40e66e0b0804011558m3ec444dfr699d5dd0f052fbb3@mail.gmail.com>
	<47F39ABD.2030602@pdf.com>
Message-ID: <40e66e0b0804021051q10966221lc8e9a1e16542d284@mail.gmail.com>

I just checked in files to update the lme4 package on R-forge to
version 0.999375-12, adding a hidden function devmat.  The function is
hidden because I am still considering the form of the arguments and
the response.  At present it takes a fitted linear mixed model and a
matrix of values for the ST parameters.  As shown in the enclosed
example this allows for evaluation on a grid of parameter values
through the expand.grid function.  It returns a data frame with
columns of the parameters and

ML - the profiled deviance
REML - the profiled REML deviance
ldL2 - logarithm of the square of the determinant of the q by q
Cholesky factor L
ldRX2 - logarithm of the square of the determinant of the p by p
Cholesky factor RX
sigmaML - conditional ML estimate of sigma
sigmaREML - conditional REML estimate of sigma
pwrss - penalized, weighted residual sum of squares (= usqr + wrss)
disc - discrepancy (= wrss for linear mixed models but not for GLMMs)
usqr - squared length of the orthogonal random effects u at their
conditional mode
wrss - weighted residual sum of squares

All these components are calculated during the evaluation of the
profiled deviance so I included everything in case researchers want to
examine other functions of these quantities.  It just occurred to me
that I could also include the conditional estimates of the fixed
effects, perhaps as an option.

I reran the example your simulated example evaluating the REML
deviance on a grid of values of ST1 = sigma[A:B]/sigma and ST2 =
sigma[A]/sigma, equally spaced on the logarithm scale.  The prior used
in mcmcsamp is locally uniform on the logarithm scale.  The resulting
contour plot (enclosed) shows what I mean by "the flat spot".  The
deviance is insensitive to the value of log(ST2) below zero.  When the
MCMC sampler hits that region it gets stuck there.


On Wed, Apr 2, 2008 at 9:39 AM, Sundar Dorai-Raj
<sundar.dorai-raj at pdf.com> wrote:
> Hi, Prof. Bates,
>
>  Douglas Bates said the following on 4/1/2008 3:58 PM:
>
>  > I must leave for a meeting now
>  > but tomorrow morning I should be able to draft some code to show how
>  > one would evaluate the profiled likelihood.
>
>  That would be great!
>
>  Thanks,
>
>  --sundar
>
>  Douglas Bates said the following on 4/1/2008 3:58 PM:
>
>
>
> > On Tue, Apr 1, 2008 at 3:22 PM, Sundar Dorai-Raj
> > <sundar.dorai-raj at pdf.com> wrote:
> >
> > > Hi, Prof. Bates,
> > >
> > >  Douglas Bates said the following on 4/1/2008 11:40 AM:
> > >
> > >  > This is a known problem with MCMC sampling of
> > >  > variance components.
> > >
> > >  So, does this mean the confidence interval is in question, and not the
> > >  point estimate?
> > >
> >
> > I think I would characterize it as a problem with the mixing of the
> > Markov chain.  Another way of looking at it is that it is caused by an
> > improper posterior distribution for the parameter that is getting
> > stuck.  Frequently we use an improper prior distribution because the
> > likelihood will dominate the prior and we end up with a proper
> > posterior distribution (or close enough to being proper that we don't
> > encounter problems).  However, if the likelihood flattens out so that
> > it doesn't dominate the prior and it does this in a place where it is
> > not much, much smaller than the likelihood at the estimate, then we
> > have an improper posterior and a non-negligible probability of ending
> > up on the flat patch.  That's when we get problems.
> >
> >
> > > Would Wald intervals not be appropriate either? Or
> > >  profile likelihood intervals? (I know neither are available in lme4 but
> > >  I think could hack it if necessary.)
> > >
> >
> > That's probably the best approach, although things may get touchy at
> > the boundary of the parameter space.  I must leave for a meeting now
> > but tomorrow morning I should be able to draft some code to show how
> > one would evaluate the profiled likelihood.  Basically you do the
> > following
> >
> > # Set the value of the ST parameters (the two relative standard
> > deviations for this model)
> > # This also updates the scaled model matrix A.
> > .Call("mer_ST_setPars", fm, pars, PACKAGE = "lme4")
> > # Update the sparse Cholesky factor
> > .Call("mer_update_L", fm, PACKAGE = "lme4")
> > # Update the other parts of the Cholesky factor
> > .Call("mer_update_RX", fm, PACKAGE = "lme4")
> > # extract the deviance or REML deviance
> > dev  <- fm at deviance["ML"]  # or "REML"
> >
> > If you want to get sophisticated you can profile one of the ST
> > parameters with respect to the other.
> >
> >
> > >  I've updated the lme4 package have started testing it. Thanks also for
> > >  the Gelman reference. I've requested a copy and will take a look.
> > >
> > >  Thanks,
> > >
> > >  --sundar
> > >
> > >  Douglas Bates said the following on 4/1/2008 11:40 AM:
> > >
> > >
> > >
> > > > May I suggest that you repeat the experiment in the development
> > > >
> > >  > version of the lme4 package?  In that version the HPDinterval
> function
> > >  > has been moved to lme4 and it is no longer necessary to attach the
> > >  > coda package.
> > >  >
> > >  > I think it is easier to see what is happening when you use that
> > >  > version of the package because you can use the xyplot method to
> > >  > examine the evolution of the sampler.  I enclose a modified version
> of
> > >  > your code.  Running this version produces the enclosed plot.  You
> will
> > >  > see that the (relative) standard deviation of A (labelled 'ST2') gets
> > >  > stuck near zero.  This is a known problem with MCMC sampling of
> > >  > variance components.  The prior distribution corresponds to a
> "locally
> > >  > constant" uninformative prior on log(sigma_A).  As long as the
> > >  > likelihood at sigma = zero is sufficiently small to prevent the MCMC
> > >  > sampler getting near there the sampler proceeds happily.  However, if
> > >  > the likelihood is not sufficiently small then the MCMC sampler may
> > >  > wander into the "sigma near zero" region where the posterior density
> > >  > of log(sigma) is essentially flat and it gets stuck there.  The
> recent
> > >  > paper by Gelman et al. (JCGS, 2008) provides a suggestion of avoiding
> > >  > this problem by overparameterizing the model for the MCMC sampler but
> > >  > I haven't yet implemented.
> > >  >
> > >  >
> > >  >
> > >  > On Tue, Apr 1, 2008 at 12:50 PM, Sundar Dorai-Raj
> > >  > <sundar.dorai-raj at pdf.com> wrote:
> > >  >> Hi, lmer+coda Users,
> > >  >>
> > >  >>  (reproducible code at end)
> > >  >>
> > >  >>  I have a question regarding confidence intervals on the random
> effects.
> > >  >>  The data I'm working with is a highly unbalanced, nested design
> with two
> > >  >>  random effects (say, A/B), where the B variance is expected to be
> larger
> > >  >>  than A variance. I need to compute confidence bounds on the
> standard
> > >  >>  deviations of each effect (A and A:B). To do this, I use
> lme4::mcmcsamp
> > >  >>  with coda::HPDinterval. As in,
> > >  >>
> > >  >>  f <- lmer(...)
> > >  >>  m <- mcmcsamp(f, n = 1000)
> > >  >>  (s <- sqrt(exp(HPDinterval(m))))
> > >  >>
> > >  >>  However, one of the point estimates falls below the lower bound of
> the
> > >  >>  confidence interval. My guess is that this is due to the
> correlation
> > >  >>  between A and A:B (due to imbalance? relative magnitude of A vs.
> A:B?)
> > >  >>  leading to an unstable model fit. Are the point estimates
> completely
> > >  >>  untrustworthy? In this case, should I simply remove the offending
> random
> > >  >>  effect and refit? Is there a reference that describes situations
> such as
> > >  >>  these (point estimates outside the C.I.)?
> > >  >>
> > >  >>  Also, this may be an example where the nlme:::intervals.lme
> function
> > >  >>  produces intervals that are nonsensical (at least to me) if you
> change
> > >  >>  sd.A below to, say, 0.5.
> > >  >>
> > >  >>  Thanks,
> > >  >>
> > >  >>  --sundar
> > >  >>
> > >  >>  <code>
> > >  >>  set.seed(2)
> > >  >>  ## simulate data
> > >  >>  A <- factor(rep(1:10, each = 4))
> > >  >>  n <- length(A)
> > >  >>  B <- factor(rep(1:2, 20))
> > >  >>  sd.A <- 5
> > >  >>  sd.B <- 10
> > >  >>  sd.e <- 0.5
> > >  >>  rA <- rnorm(nlevels(A), 0, sd.A)
> > >  >>  rB <- rnorm(nlevels(A:B), 0, sd.B)
> > >  >>  e <- rnorm(n, 0, sd.e)
> > >  >>  y <- 0.5 + rA[A] + rB[A:B] + e
> > >  >>  ## create unbalance
> > >  >>  out <- seq(length(y)) %in% sample(length(y), 20)
> > >  >>
> > >  >>  ## fit model
> > >  >>  library(lme4)
> > >  >>  library(coda)
> > >  >>  f <- lmer2(y ~ (1 | A) + (1 | A:B), subset = !out)
> > >  >>  m <- mcmcsamp(f, 1000)
> > >  >>  v <- VarCorr(f)
> > >  >>  s.lmer <- cbind(sqrt(exp(HPDinterval(m[, -1]))),
> > >  >>                  est. = c(attr(v, "sc"), sqrt(sapply(v,
> as.matrix))),
> > >  >>                  true = c(sd.e, sd.B, sd.A))
> > >  >>  s.lmer <- s.lmer[, c("lower", "est.", "upper", "true")]
> > >  >>  rownames(s.lmer) <- c("sigma", "A:B", "A")
> > >  >>  print(zapsmall(s.lmer), digits = 4)
> > >  >>  </code>
> > >  >>
> > >  >>  _______________________________________________
> > >  >>  R-sig-mixed-models at r-project.org mailing list
> > >  >>  https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >  >>
> > >  >
> > >
> > >
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplots.pdf
Type: application/pdf
Size: 22017 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080402/a0a2447e/attachment.pdf>

From Praghavan at bear.com  Wed Apr  2 23:06:17 2008
From: Praghavan at bear.com (Raghavan, Partha (Exchange))
Date: Wed, 2 Apr 2008 17:06:17 -0400
Subject: [R-sig-ME] Help installing Package lme4
Message-ID: <A9078D032B956846BDE68FD207D2757C0FF87CD3@whexchmb09.bsna.bsroot.bear.com>

I am having trouble installing the lme4 package.

It looks likes the install is having trouble locating a header, Matrix.h


 

I just installed the Matrix package successfully 

 

Do I need to set any CPPFLAGS var etc?

 

 

This is all on a 64 bit LINUX box

 

[pbfastprepay1 /a/praghava/out/R/lib/R/library 1128] R CMD INSTALL
lme4_0.99875-9.tar.gz
<

* Installing to library '/a/praghava/out/R/lib/R/library/'

* Installing *source* package 'lme4' ...

** libs

gcc -std=gnu99 -I/usr/local/public/R-2.6.1_LINUX_VS9/lib64/R/include
-I/usr/local/public/R-2.6.1_LINUX_VS9/lib64/R/include
-I/usr/local/include    -fpic  -g -O2 -c glmer.c -o glmer.o

In file included from lmer.h:4,

                 from glmer.h:4,

                 from glmer.c:1:

lme4_utils.h:12:20: Matrix.h: No such file or directory

In file included from lmer.h:4,

                 from glmer.h:4,

                 from glmer.c:1:

lme4_utils.h:40: error: parse error before "c"

lme4_utils.h:40: warning: type defaults to `int' in declaration of `c'

lme4_utils.h:40: warning: data definition has no type or storage class

lme4_utils.h:192: error: parse error before "cholmod_factor"

lme4_utils.h:217: error: parse error before "cholmod_factor"

glmer.c: In function `b_quadratic':

glmer.c:59: warning: implicit declaration of function `M_dpoMatrix_chol'

glmer.c:59: warning: passing arg 1 of `R_do_slot' makes pointer from
integer without a cast

glmer.c: At top level:

glmer.c:180: error: parse error before "cholmod_factor"

glmer.c: In function `internal_Gaussian_deviance':

glmer.c:185: error: `CHM_SP' undeclared (first use in this function)

glmer.c:185: error: (Each undeclared identifier is reported only once

glmer.c:185: error: for each function it appears in.)

glmer.c:185: error: parse error before "Lm"

glmer.c:186: error: `CHM_FR' undeclared (first use in this function)

glmer.c:188: error: `q' undeclared (first use in this function)

glmer.c:188: error: `p' undeclared (first use in this function)

glmer.c:189: error: `CHM_DN' undeclared (first use in this function)

glmer.c:189: error: parse error before "Ltb"

glmer.c:193: error: subscripted value is neither array nor pointer

glmer.c:193: error: `betahat' undeclared (first use in this function)

glmer.c:194: error: `b' undeclared (first use in this function)

glmer.c:194: error: `bhat' undeclared (first use in this function)

glmer.c:195: error: `Lcp' undeclared (first use in this function)

glmer.c:195: warning: implicit declaration of function
`M_cholmod_copy_factor'

glmer.c:195: error: `L' undeclared (first use in this function)

glmer.c:196: error: `Lm' undeclared (first use in this function)

glmer.c:196: warning: implicit declaration of function
`M_cholmod_factor_to_sparse'

glmer.c:196: warning: implicit declaration of function
`M_cholmod_free_factor'

glmer.c:197: warning: implicit declaration of function
`M_cholmod_sdmult'

glmer.c:197: error: `Ltb' undeclared (first use in this function)

glmer.c:200: warning: implicit declaration of function
`M_cholmod_free_sparse'

glmer.c:200: warning: implicit declaration of function
`M_cholmod_free_dense'

glmer.c:201: error: `RZX' undeclared (first use in this function)

glmer.c:204: error: `RXX' undeclared (first use in this function)

glmer.c: In function `internal_bhat':

glmer.c:396: error: `CHM_FR' undeclared (first use in this function)

glmer.c:396: error: parse error before "L"

glmer.c:403: error: `L' undeclared (first use in this function)

glmer.c: In function `glmer_MCMCsamp':

glmer.c:657: error: `CHM_FR' undeclared (first use in this function)

glmer.c:657: error: parse error before "L"

glmer.c:680: error: `L' undeclared (first use in this function)

make: *** [glmer.o] Error 1

ERROR: compilation failed for package 'lme4'

** Removing '/n/fast-fast/praghava/out/R/lib/R/library/lme4'

 

/************** GCC VERSION  *****************/

 

[pbfastprepay1 /a/praghava/out/R/lib/R/library 1129] gcc -v

Reading specs from /usr/lib64/gcc-lib/x86_64-suse-linux/3.3.3/specs

Configured with: ../configure --enable-threads=posix --prefix=/usr
--with-local-prefix=/usr/local --infodir=/usr/share/info
--mandir=/usr/share/man --enable-languages=c,c++,f77,objc,java,ada
--disable-checking --libdir=/usr/lib64 --enable-libgcj
--with-gxx-include-dir=/usr/include/g++ --with-slibdir=/lib64
--with-system-zlib --enable-shared --enable-__cxa_atexit
x86_64-suse-linux

Thread model: posix

gcc version 3.3.3 (SuSE Linux)

 

/************ LINUX VERSION *****************/

 

[pbfastprepay1 /a/praghava/out/R/lib/R/library 1130]uname -a 

Linux pbfastprepay1 2.6.5-7.244-smp #1 SMP Mon Dec 12 18:32:25 UTC 2005
x86_64 x86_64 x86_64 GNU/Linux

 

Partha Raghavan

F.A.S.T.

Bear Stearns & Co. Inc.

383 Madison Avenue 

New York, NY 10179 

 

Ph. 212 272 3454 

Fax 212 272 7310

 

-------------- next part --------------


***********************************************************************
Bear Stearns is not responsible for any recommendation, ...{{dropped:8}}


From Praghavan at bear.com  Wed Apr  2 23:32:10 2008
From: Praghavan at bear.com (Raghavan, Partha (Exchange))
Date: Wed, 2 Apr 2008 17:32:10 -0400
Subject: [R-sig-ME] FW: Help installing Package lme4
Message-ID: <A9078D032B956846BDE68FD207D2757C0FF87CD4@whexchmb09.bsna.bsroot.bear.com>

Please ignore my earlier posting. 

I managed to successfully install the package after specifying the same
-l <target lib dir> for both Matrix & lme4 

 

Partha 

 

  _____  

From: Raghavan, Partha (Exchange) 
Sent: Wednesday, April 02, 2008 5:06 PM
To: r-sig-mixed-models at r-project.org
Subject: Help installing Package lme4

 

I am having trouble installing the lme4 package.

It looks likes the install is having trouble locating a header, Matrix.h


 

I just installed the Matrix package successfully 

 

Do I need to set any CPPFLAGS var etc?

 

 

This is all on a 64 bit LINUX box

 

[pbfastprepay1 /a/praghava/out/R/lib/R/library 1128] R CMD INSTALL
lme4_0.99875-9.tar.gz
<

* Installing to library '/a/praghava/out/R/lib/R/library/'

* Installing *source* package 'lme4' ...

** libs

gcc -std=gnu99 -I/usr/local/public/R-2.6.1_LINUX_VS9/lib64/R/include
-I/usr/local/public/R-2.6.1_LINUX_VS9/lib64/R/include
-I/usr/local/include    -fpic  -g -O2 -c glmer.c -o glmer.o

In file included from lmer.h:4,

                 from glmer.h:4,

                 from glmer.c:1:

lme4_utils.h:12:20: Matrix.h: No such file or directory

In file included from lmer.h:4,

                 from glmer.h:4,

                 from glmer.c:1:

lme4_utils.h:40: error: parse error before "c"

lme4_utils.h:40: warning: type defaults to `int' in declaration of `c'

lme4_utils.h:40: warning: data definition has no type or storage class

lme4_utils.h:192: error: parse error before "cholmod_factor"

lme4_utils.h:217: error: parse error before "cholmod_factor"

glmer.c: In function `b_quadratic':

glmer.c:59: warning: implicit declaration of function `M_dpoMatrix_chol'

glmer.c:59: warning: passing arg 1 of `R_do_slot' makes pointer from
integer without a cast

glmer.c: At top level:

glmer.c:180: error: parse error before "cholmod_factor"

glmer.c: In function `internal_Gaussian_deviance':

glmer.c:185: error: `CHM_SP' undeclared (first use in this function)

glmer.c:185: error: (Each undeclared identifier is reported only once

glmer.c:185: error: for each function it appears in.)

glmer.c:185: error: parse error before "Lm"

glmer.c:186: error: `CHM_FR' undeclared (first use in this function)

glmer.c:188: error: `q' undeclared (first use in this function)

glmer.c:188: error: `p' undeclared (first use in this function)

glmer.c:189: error: `CHM_DN' undeclared (first use in this function)

glmer.c:189: error: parse error before "Ltb"

glmer.c:193: error: subscripted value is neither array nor pointer

glmer.c:193: error: `betahat' undeclared (first use in this function)

glmer.c:194: error: `b' undeclared (first use in this function)

glmer.c:194: error: `bhat' undeclared (first use in this function)

glmer.c:195: error: `Lcp' undeclared (first use in this function)

glmer.c:195: warning: implicit declaration of function
`M_cholmod_copy_factor'

glmer.c:195: error: `L' undeclared (first use in this function)

glmer.c:196: error: `Lm' undeclared (first use in this function)

glmer.c:196: warning: implicit declaration of function
`M_cholmod_factor_to_sparse'

glmer.c:196: warning: implicit declaration of function
`M_cholmod_free_factor'

glmer.c:197: warning: implicit declaration of function
`M_cholmod_sdmult'

glmer.c:197: error: `Ltb' undeclared (first use in this function)

glmer.c:200: warning: implicit declaration of function
`M_cholmod_free_sparse'

glmer.c:200: warning: implicit declaration of function
`M_cholmod_free_dense'

glmer.c:201: error: `RZX' undeclared (first use in this function)

glmer.c:204: error: `RXX' undeclared (first use in this function)

glmer.c: In function `internal_bhat':

glmer.c:396: error: `CHM_FR' undeclared (first use in this function)

glmer.c:396: error: parse error before "L"

glmer.c:403: error: `L' undeclared (first use in this function)

glmer.c: In function `glmer_MCMCsamp':

glmer.c:657: error: `CHM_FR' undeclared (first use in this function)

glmer.c:657: error: parse error before "L"

glmer.c:680: error: `L' undeclared (first use in this function)

make: *** [glmer.o] Error 1

ERROR: compilation failed for package 'lme4'

** Removing '/n/fast-fast/praghava/out/R/lib/R/library/lme4'

 

/************** GCC VERSION  *****************/

 

[pbfastprepay1 /a/praghava/out/R/lib/R/library 1129] gcc -v

Reading specs from /usr/lib64/gcc-lib/x86_64-suse-linux/3.3.3/specs

Configured with: ../configure --enable-threads=posix --prefix=/usr
--with-local-prefix=/usr/local --infodir=/usr/share/info
--mandir=/usr/share/man --enable-languages=c,c++,f77,objc,java,ada
--disable-checking --libdir=/usr/lib64 --enable-libgcj
--with-gxx-include-dir=/usr/include/g++ --with-slibdir=/lib64
--with-system-zlib --enable-shared --enable-__cxa_atexit
x86_64-suse-linux

Thread model: posix

gcc version 3.3.3 (SuSE Linux)

 

/************ LINUX VERSION *****************/

 

[pbfastprepay1 /a/praghava/out/R/lib/R/library 1130]uname -a 

Linux pbfastprepay1 2.6.5-7.244-smp #1 SMP Mon Dec 12 18:32:25 UTC 2005
x86_64 x86_64 x86_64 GNU/Linux

 

Partha Raghavan

F.A.S.T.

Bear Stearns & Co. Inc.

383 Madison Avenue 

New York, NY 10179 

 

Ph. 212 272 3454 

Fax 212 272 7310

 

-------------- next part --------------


***********************************************************************
Bear Stearns is not responsible for any recommendation, ...{{dropped:8}}


From bates at stat.wisc.edu  Thu Apr  3 00:02:00 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 2 Apr 2008 17:02:00 -0500
Subject: [R-sig-ME] FW: Help installing Package lme4
In-Reply-To: <A9078D032B956846BDE68FD207D2757C0FF87CD4@whexchmb09.bsna.bsroot.bear.com>
References: <A9078D032B956846BDE68FD207D2757C0FF87CD4@whexchmb09.bsna.bsroot.bear.com>
Message-ID: <40e66e0b0804021502k24a8002cofff5cc9a496fad90@mail.gmail.com>

You need to have the Matrix package installed before you can install
the lme4 package.  The missing header files are found in the installed
Matrix package.

If you have the Matrix package installed then the R CMD INSTALL script
should find the directory with those headers and put it on the include
path for the compilations.

On Wed, Apr 2, 2008 at 4:32 PM, Raghavan, Partha (Exchange)
<Praghavan at bear.com> wrote:
> Please ignore my earlier posting.
>
>  I managed to successfully install the package after specifying the same
>  -l <target lib dir> for both Matrix & lme4
>
>
>
>  Partha
>
>
>
>   _____
>
>  From: Raghavan, Partha (Exchange)
>  Sent: Wednesday, April 02, 2008 5:06 PM
>  To: r-sig-mixed-models at r-project.org
>  Subject: Help installing Package lme4
>
>
>
>
>
>  I am having trouble installing the lme4 package.
>
>  It looks likes the install is having trouble locating a header, Matrix.h
>
>
>
>
>  I just installed the Matrix package successfully
>
>
>
>  Do I need to set any CPPFLAGS var etc?
>
>
>
>
>
>  This is all on a 64 bit LINUX box
>
>
>
>  [pbfastprepay1 /a/praghava/out/R/lib/R/library 1128] R CMD INSTALL
>  lme4_0.99875-9.tar.gz
>  <
>
>  * Installing to library '/a/praghava/out/R/lib/R/library/'
>
>  * Installing *source* package 'lme4' ...
>
>  ** libs
>
>  gcc -std=gnu99 -I/usr/local/public/R-2.6.1_LINUX_VS9/lib64/R/include
>  -I/usr/local/public/R-2.6.1_LINUX_VS9/lib64/R/include
>  -I/usr/local/include    -fpic  -g -O2 -c glmer.c -o glmer.o
>
>  In file included from lmer.h:4,
>
>                  from glmer.h:4,
>
>                  from glmer.c:1:
>
>  lme4_utils.h:12:20: Matrix.h: No such file or directory
>
>  In file included from lmer.h:4,
>
>                  from glmer.h:4,
>
>                  from glmer.c:1:
>
>  lme4_utils.h:40: error: parse error before "c"
>
>  lme4_utils.h:40: warning: type defaults to `int' in declaration of `c'
>
>  lme4_utils.h:40: warning: data definition has no type or storage class
>
>  lme4_utils.h:192: error: parse error before "cholmod_factor"
>
>  lme4_utils.h:217: error: parse error before "cholmod_factor"
>
>  glmer.c: In function `b_quadratic':
>
>  glmer.c:59: warning: implicit declaration of function `M_dpoMatrix_chol'
>
>  glmer.c:59: warning: passing arg 1 of `R_do_slot' makes pointer from
>  integer without a cast
>
>  glmer.c: At top level:
>
>  glmer.c:180: error: parse error before "cholmod_factor"
>
>  glmer.c: In function `internal_Gaussian_deviance':
>
>  glmer.c:185: error: `CHM_SP' undeclared (first use in this function)
>
>  glmer.c:185: error: (Each undeclared identifier is reported only once
>
>  glmer.c:185: error: for each function it appears in.)
>
>  glmer.c:185: error: parse error before "Lm"
>
>  glmer.c:186: error: `CHM_FR' undeclared (first use in this function)
>
>  glmer.c:188: error: `q' undeclared (first use in this function)
>
>  glmer.c:188: error: `p' undeclared (first use in this function)
>
>  glmer.c:189: error: `CHM_DN' undeclared (first use in this function)
>
>  glmer.c:189: error: parse error before "Ltb"
>
>  glmer.c:193: error: subscripted value is neither array nor pointer
>
>  glmer.c:193: error: `betahat' undeclared (first use in this function)
>
>  glmer.c:194: error: `b' undeclared (first use in this function)
>
>  glmer.c:194: error: `bhat' undeclared (first use in this function)
>
>  glmer.c:195: error: `Lcp' undeclared (first use in this function)
>
>  glmer.c:195: warning: implicit declaration of function
>  `M_cholmod_copy_factor'
>
>  glmer.c:195: error: `L' undeclared (first use in this function)
>
>  glmer.c:196: error: `Lm' undeclared (first use in this function)
>
>  glmer.c:196: warning: implicit declaration of function
>  `M_cholmod_factor_to_sparse'
>
>  glmer.c:196: warning: implicit declaration of function
>  `M_cholmod_free_factor'
>
>  glmer.c:197: warning: implicit declaration of function
>  `M_cholmod_sdmult'
>
>  glmer.c:197: error: `Ltb' undeclared (first use in this function)
>
>  glmer.c:200: warning: implicit declaration of function
>  `M_cholmod_free_sparse'
>
>  glmer.c:200: warning: implicit declaration of function
>  `M_cholmod_free_dense'
>
>  glmer.c:201: error: `RZX' undeclared (first use in this function)
>
>  glmer.c:204: error: `RXX' undeclared (first use in this function)
>
>  glmer.c: In function `internal_bhat':
>
>  glmer.c:396: error: `CHM_FR' undeclared (first use in this function)
>
>  glmer.c:396: error: parse error before "L"
>
>  glmer.c:403: error: `L' undeclared (first use in this function)
>
>  glmer.c: In function `glmer_MCMCsamp':
>
>  glmer.c:657: error: `CHM_FR' undeclared (first use in this function)
>
>  glmer.c:657: error: parse error before "L"
>
>  glmer.c:680: error: `L' undeclared (first use in this function)
>
>  make: *** [glmer.o] Error 1
>
>  ERROR: compilation failed for package 'lme4'
>
>  ** Removing '/n/fast-fast/praghava/out/R/lib/R/library/lme4'
>
>
>
>  /************** GCC VERSION  *****************/
>
>
>
>  [pbfastprepay1 /a/praghava/out/R/lib/R/library 1129] gcc -v
>
>  Reading specs from /usr/lib64/gcc-lib/x86_64-suse-linux/3.3.3/specs
>
>  Configured with: ../configure --enable-threads=posix --prefix=/usr
>  --with-local-prefix=/usr/local --infodir=/usr/share/info
>  --mandir=/usr/share/man --enable-languages=c,c++,f77,objc,java,ada
>  --disable-checking --libdir=/usr/lib64 --enable-libgcj
>  --with-gxx-include-dir=/usr/include/g++ --with-slibdir=/lib64
>  --with-system-zlib --enable-shared --enable-__cxa_atexit
>  x86_64-suse-linux
>
>  Thread model: posix
>
>  gcc version 3.3.3 (SuSE Linux)
>
>
>
>  /************ LINUX VERSION *****************/
>
>
>
>  [pbfastprepay1 /a/praghava/out/R/lib/R/library 1130]uname -a
>
>  Linux pbfastprepay1 2.6.5-7.244-smp #1 SMP Mon Dec 12 18:32:25 UTC 2005
>  x86_64 x86_64 x86_64 GNU/Linux
>
>
>
>  Partha Raghavan
>
>  F.A.S.T.
>
>  Bear Stearns & Co. Inc.
>
>  383 Madison Avenue
>
>  New York, NY 10179
>
>
>
>  Ph. 212 272 3454
>
>  Fax 212 272 7310
>
>
>
>
>
>
>  ***********************************************************************
>  Bear Stearns is not responsible for any recommendation, ...{{dropped:8}}
>
>
> _______________________________________________
>  R-sig-mixed-models at r-project.org mailing list
>  https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



From bates at stat.wisc.edu  Thu Apr  3 00:27:00 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 2 Apr 2008 17:27:00 -0500
Subject: [R-sig-ME] lme4::mcmcsamp + coda::HPDinterval
In-Reply-To: <40e66e0b0804021051q10966221lc8e9a1e16542d284@mail.gmail.com>
References: <47F275D8.2090603@pdf.com>
	<40e66e0b0804011140n2580dc8age75c048c9666ae@mail.gmail.com>
	<47F29979.1050509@pdf.com>
	<40e66e0b0804011558m3ec444dfr699d5dd0f052fbb3@mail.gmail.com>
	<47F39ABD.2030602@pdf.com>
	<40e66e0b0804021051q10966221lc8e9a1e16542d284@mail.gmail.com>
Message-ID: <40e66e0b0804021527w11b39f0vca0052173ef8a95f@mail.gmail.com>

I enclose another plot from a simulation that may show why I refer to
"the flat spot".  In this case I simulate a simple model with one
fixed effect and with random effects for a single grouping factor.  I
am simulating from the null model where the variance of the random
effect is zero.  The first two simulations produce an estimated
variance of zero - i.e. they converge on the boundary of the parameter
space.  The third model converges to a non-zero estimate.  The
profiled REML deviance, as a function of the logarithm of the relative
standard deviation has only a shallow dip for the optimum and becomes
flat for large negative values of the logarithm.  If the MCMC sampler
gets onto that plateau it has a hard time getting off again.



From bates at stat.wisc.edu  Thu Apr  3 00:28:08 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 2 Apr 2008 17:28:08 -0500
Subject: [R-sig-ME] lme4::mcmcsamp + coda::HPDinterval
In-Reply-To: <40e66e0b0804021527w11b39f0vca0052173ef8a95f@mail.gmail.com>
References: <47F275D8.2090603@pdf.com>
	<40e66e0b0804011140n2580dc8age75c048c9666ae@mail.gmail.com>
	<47F29979.1050509@pdf.com>
	<40e66e0b0804011558m3ec444dfr699d5dd0f052fbb3@mail.gmail.com>
	<47F39ABD.2030602@pdf.com>
	<40e66e0b0804021051q10966221lc8e9a1e16542d284@mail.gmail.com>
	<40e66e0b0804021527w11b39f0vca0052173ef8a95f@mail.gmail.com>
Message-ID: <40e66e0b0804021528y896ab5fkdf690d99b99e1646@mail.gmail.com>

Files attached this time.

On Wed, Apr 2, 2008 at 5:27 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
> I enclose another plot from a simulation that may show why I refer to
>  "the flat spot".  In this case I simulate a simple model with one
>  fixed effect and with random effects for a single grouping factor.  I
>  am simulating from the null model where the variance of the random
>  effect is zero.  The first two simulations produce an estimated
>  variance of zero - i.e. they converge on the boundary of the parameter
>  space.  The third model converges to a non-zero estimate.  The
>  profiled REML deviance, as a function of the logarithm of the relative
>  standard deviation has only a shallow dip for the optimum and becomes
>  flat for large negative values of the logarithm.  If the MCMC sampler
>  gets onto that plateau it has a hard time getting off again.
>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplots.pdf
Type: application/pdf
Size: 6320 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080402/66038fb4/attachment.pdf>

From john.maindonald at anu.edu.au  Thu Apr  3 01:22:33 2008
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Thu, 3 Apr 2008 10:22:33 +1100
Subject: [R-sig-ME] random factor and error messages in the model fitting
In-Reply-To: <FE28EB62-8092-4134-B2D6-024147EB94C2@MUOhio.edu>
References: <f69dbed20804020717q772724cfoddded38188850a20@mail.gmail.com>
	<FE28EB62-8092-4134-B2D6-024147EB94C2@MUOhio.edu>
Message-ID: <1DB8BC83-5099-445B-9F7B-A32E81B1F293@anu.edu.au>

I'd expect that you want to generalize to a difference choice of  
transects within each altitude and age-class.  Were there multiple  
transects for each altitude and age-class combination?  If not, the  
factor Transect is trying to do two things at once -- account for the  
fixed effect of altitude, and account for the random effect of transect.

Two analyses are possible with the data that you seem to have:

A)  lm( SLA ~ Transect + Age + Age:Transect)

The inferences generalize to a different choice of tissue samples  
within those same Age and Transect combinations.  When a prediction is  
made, you have to say which Age and Transect combination you have in  
mind, and inferences apply to the particular Transects that were taken.


B)

lmer(SLA ~ Age + Transect + (1|Transect:Age),
          data=Treeline[Site=="TermasChillan",], na.action=na.omit)

This treats variation between Age:Transect combinations as the  
relevant measure of error, hoping that this will be mach the same as  
the error that you'd get from different transects within Altitude:Age  
combinations.  If there is an Altitude:Age interaction, it may over- 
estimate the error.

[If you do happen to have multiple transects for each Age:Transect  
combination, you'd want something like:

lmer(SLA ~ Age*Altitude+ (1|transect/Age),
          data=Treeline[Site=="TermasChillan",], na.action=na.omit)

(the error term needs to identify individual transect*Age  
combinations) ]


NB also, you might want to try a non-linear term in Age in the fixed  
part of the model.


John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


On 3 Apr 2008, at 4:02 AM, Hank Stevens wrote:

> Hi Alex,
> On Apr 2, 2008, at 10:17 AM, Alex Fajardo wrote:
>
>> Dear r-sig-mixed-models webmail list members,
>>
>> I am new in the mixed-effects models world and I am learning from
>> Faraway's
>> and Pinheiro & Bates' books and also from this list.
>> I have 3, very straightforward, questions, but first a brief summary
>> of my
>> analysis objectives. I am trying to analyze my data with mixed  
>> effects
>> models where the fixed factor is represented by altitudinal
>> transects (4
>> transects, where T4 is treeline, and T1, T2 and T3 are below
>> treeline). In
>> each altitudinal transect I collected tissue samples from different
>> age-class trees (a categorical variable with 4 levels, I, II, III,
>> and IV);
>> all this with the main objective to compare specific leaf area -SLA-
>> of the
>> treeline trees with lower elevation transects, and take into account
>> the
>> age-class of the tree being considered. The data set is very
>> unbalanced and
>> reading similar papers I concluded that age-class should be
>> considered a
>> random factor nested in transects.
>>
>> *Question 1*: am I correct by considering age-class a random factor
>> nested
>> within transect? If so, what should be the way to code the model?
>> My suggestion is:
>>> sla.termas = lmer(SLA ~ 1 + Transect + (1|Transect:Age),
>> data=Treeline[Site=="TermasChillan",], na.action=na.omit) or
>>> sla.termas = lmer(SLA ~ 1 + Transect + (Transect|Age),
>> data=Treeline[Site=="TermasChillan",], na.action=na.omit), but I am
>> not
>> sure.
> I would assume that Age is NOT nested; if it is, you are saying that
> the effect of age could depend entirely on which transect you look at.
> Rather, I assume different ages simply have different responses, i.e.,
> (1|Age).
>
> However, I would think that a fixed effect model is just as useful.
> lm( SLA ~ Transect + Age + Age:Transect)
>
> I am not sure why these altitudes or age class are considered a random
> draw from a large number of such classes that you know little about.
> They seem entirely repeated, and usefully so.
>
> My two cents,
> Hank
>>
>>
>>
>> In my learning process I followed examples given in Faraway's book
>> and just
>> for learning purposes I computed my model in the way he does
>> (considering
>> both factors random) and got, for some, variables the following
>> warning
>> message:
>>
>>> sla.termas = lmer(SLA ~ 1 + (1|Transect) + (1|Transect:Age),
>> data=Treeline[Site=="TermasChillan",], na.action=na.omit)
>> *Warning message: In .local(x, ..., value) :
>> Estimated variance-covariance for factor 'Age' is singular*
>>
>> This is not good when I try to test the significance of the
>> variation among
>> ages by ANOVA, since I get a Pr(>Chisq)=1; something must be wrong.
>> This
>> situation happens with some variables and not with all of them:
>> strange?
>>
>> *Question 2*: any idea why this happens? What am I doing wrong?
>>
>> When I do get the model run (no such a warning message and just for
>> some
>> other variables) and compare this model with a reduced version
>> (without the
>> nested random factor, e.g., age-class) I run anova and get a p-
>> value. As
>> suggested by Faraway I should also go for a p-value computing LRT
>> 1000 times
>> (less conservative cf. Faraway) and most of the time I get the
>> following
>> message:
>>
>>> lrstat = numeric(1000)
>>> for(i in 1:1000){
>> + rSLA = unlist(simulate(sla.termas2))
>> + nmod =
>> lmer(rSLA~1+(1|
>> Transect),data=Treeline[Site=="TermasChillan",],na.action=na.omit)
>> + amod =
>> lmer(rSLA~1+(1|Transect)+(1|
>> Transect:Age 
>> ),data=Treeline[Site=="TermasChillan",],na.action=na.omit)
>> + lrstat[i] = 2*(logLik(amod)-logLik(nmod))
>> + }
>> *Error in model.frame.default(data = Treeline[Site ==
>> "TermasChillan",  :
>> variable lengths differ (found for 'Transect')*
>>
>> *Question 3*: any idea why this happens? What am I doing wrong? I
>> made an
>> artificial balanced data set to see whether the unbalanced situation
>> was the
>> responsible for this message but it was not.
>>
>> I am new in the mixed-effects models world but I want to learn; your
>> comments and advice will be greatly appreciated. Cheers,
>>
>>
>>
>> --
>> Alex Fajardo, PhD
>> Investigador Asociado
>> Centro de Investigaci?n en Ecosistemas de la Patagonia
>> Bilbao 449. Coyhaique, CHILE
>> Telefonos: 56-67-244503; (56) 8-4506354
>> Fax: 56-67-244501
>> alex.fajardo at ciep.cl
>>
>>      [[alternative HTML version deleted]]
>>
>> <ATT00001.txt>
>
>
>
> Dr. Hank Stevens, Associate Professor
> 338 Pearson Hall
> Botany Department
> Miami University
> Oxford, OH 45056
>
> Office: (513) 529-4206
> Lab: (513) 529-4262
> FAX: (513) 529-4243
> http://www.cas.muohio.edu/~stevenmh/
> http://www.cas.muohio.edu/ecology
> http://www.muohio.edu/botany/
>
> "If the stars should appear one night in a thousand years, how would  
> men
> believe and adore." -Ralph Waldo Emerson, writer and philosopher
> (1803-1882)
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From sundar.dorai-raj at pdf.com  Thu Apr  3 02:20:44 2008
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Wed, 02 Apr 2008 17:20:44 -0700
Subject: [R-sig-ME] lme4::mcmcsamp + coda::HPDinterval
In-Reply-To: <40e66e0b0804021528y896ab5fkdf690d99b99e1646@mail.gmail.com>
References: <47F275D8.2090603@pdf.com>	<40e66e0b0804011140n2580dc8age75c048c9666ae@mail.gmail.com>	<47F29979.1050509@pdf.com>	<40e66e0b0804011558m3ec444dfr699d5dd0f052fbb3@mail.gmail.com>	<47F39ABD.2030602@pdf.com>	<40e66e0b0804021051q10966221lc8e9a1e16542d284@mail.gmail.com>	<40e66e0b0804021527w11b39f0vca0052173ef8a95f@mail.gmail.com>
	<40e66e0b0804021528y896ab5fkdf690d99b99e1646@mail.gmail.com>
Message-ID: <47F422DC.3020009@pdf.com>

Thanks so much. I'm working on a profile function with your suggestions. 
I'll post it back when I'm done.

Thanks,

--sundar

Douglas Bates said the following on 4/2/2008 3:28 PM:
> Files attached this time.
> 
> On Wed, Apr 2, 2008 at 5:27 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
>> I enclose another plot from a simulation that may show why I refer to
>>  "the flat spot".  In this case I simulate a simple model with one
>>  fixed effect and with random effects for a single grouping factor.  I
>>  am simulating from the null model where the variance of the random
>>  effect is zero.  The first two simulations produce an estimated
>>  variance of zero - i.e. they converge on the boundary of the parameter
>>  space.  The third model converges to a non-zero estimate.  The
>>  profiled REML deviance, as a function of the logarithm of the relative
>>  standard deviation has only a shallow dip for the optimum and becomes
>>  flat for large negative values of the logarithm.  If the MCMC sampler
>>  gets onto that plateau it has a hard time getting off again.
>>
>>
>> ------------------------------------------------------------------------
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From John.Maindonald at anu.edu.au  Thu Apr  3 04:40:55 2008
From: John.Maindonald at anu.edu.au (John Maindonald)
Date: Thu, 3 Apr 2008 13:40:55 +1100
Subject: [R-sig-ME] how to know if random factors are significant?
In-Reply-To: <A19A77C8-01AD-4454-9797-8202A5AADB9A@muohio.edu>
References: <20080401165818.M50176@oikos.unam.mx>
	<BB14B19D-8F1A-4528-B86C-61C42738B6F3@anu.edu.au>
	<4949c7e60804020035g2934b01fx500ee31f8a1b1664@mail.gmail.com>
	<A19A77C8-01AD-4454-9797-8202A5AADB9A@muohio.edu>
Message-ID: <8AC2A6A3-4E90-43B8-B4F3-AFD2720511FF@anu.edu.au>

An analogy with the Copenhagen interpretation (not by any means the  
only interpretation on offer) of quantum mechanics seems to me  
strained.  In that arena, there's a lot to be said for the "Shut up  
and calculate" view that is favored by at least some physicists, not  
advice I'd want to give to mixed level modelers!  Rather, the issue  
here has to do with a too cavalier use of Occam's razor, when Fisher's  
"Make your hypotheses complex" is more pertinent.

Debate over the use of results from twin studies to partition effects  
on measured IQ into environmental and genetic components illustrates  
the point.  The variance components are relevant only in the  
populations of parents who adopted one or other twin.  More to the  
present point, the Flynn effect by which there've been huge IQ  
increases between one generation and the next requires the invocation  
of some mixture of environmental and genetic effects that are outside  
the ken of both the twin studies data and the models used to analyze  
that data.  In biology, do not expect anything to be simple.  As I  
understand it, there've been a variety of attempts to explain the  
Flynn effect, but no clear consensus.

The analyst ought to worry about implications of the with/without  
disputed random effect for power (or effective sample size, or ...) as  
well as for the p-value or CI limits.  The analyst who omits the  
disputed random effect has to worry both that the p-value might be  
unreasonably optimistic and the power curve unreasonably optimistic.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


On 2 Apr 2008, at 9:27 PM, MHH Stevens wrote:

>
> On Apr 2, 2008, at 3:35 AM, Rune Haubo wrote:
>> On 02/04/2008, John Maindonald <john.maindonald at anu.edu.au> wrote:
>>> There was a related question from Mariana Martinez a day or two ago.
>>> Before removing a random term that background knowledge or past
>>> experience with similar data suggests is likely, check what  
>>> difference
>>> it makes to the p-values for the fixed  effects that are of  
>>> interest.
>>> If it makes a substantial difference, caution demands that it be  
>>> left
>>> it in.
>>>
>>> To pretty much repeat my earlier comment:
>>> If you omit the component then you have to contemplate the  
>>> alternatives:
>>> 1) the component really was present but undetectable
>>> 2) the component was not present, or so small that it could be
>>> ignored, and the inference from the model that omits it is valid.
>>>
>>> If (1) has a modest probability, and it matters whether you go with
>>> (1) or (2), going with (2) leads to a very insecure inference. The  
>>> p-
>>> value that comes out of the analysis is unreasonably optimistic;  
>>> it is
>>> wrong and misleading.
> Can "caution" ever cause us to select the more "optimistic" model?  
> If we assume that the absence of the random effect reduces the p- 
> value of the fixed effect, we might ponder the situation in which  
> there is a meaningful risk associated with with ignoring type II  
> error (that we erroneously accept the null hypothesis). Imagine  
> field testing the effects of a pesticide on non-target organisms ---  
> does (2) result in a "minimum" p-value, or is the p-value, as John  
> said, wrong and misleading?
>
> More generally, if a random effect has the real potential to exist  
> (has a "modest probability"), but we don't see evidence for it in  
> our particular data set, does it exist for us? (i.e. "If a tree  
> falls ..." or worse, Heisenberg's proposition, Is the cat dead if we  
> don't look?). I have typically acted as though it does not exist if  
> I do not have evidence for it in MY data. However, when it does make  
> a significant difference, I do lose sleep over it.
>
> -Hank
>>
>> I think this is a question of strategy. Leonel did put emphasis on  
>> the
>> random effect, and he might just be interested in the size and
>> significance of the random effect rather than the fixed effects.
>> Estimating and testing the random effect seems reasonable to me in
>> this case, although confidence intervals, as you mention below also
>> provides good inference.
>>
>> It is always possible to discuss how much non-data information to
>> include in an analysis and I believe the answer depends very much on
>> the purpose of the research. If the research question regards the  
>> size
>> and "existence" of the variance of 'Site', then he might conclude  
>> that
>> it is so small compared to other effects in the model/data, that it
>> has no place in the model.
>>
>> I think the question regarding "existence" of some effect can be
>> misleading in many cases, because one can always claim that any  
>> effect
>> is really there, and had we observed enough data, we would be able to
>> estimate the effect reliably. Leaving too many variables in the model
>> on which there is too little information also results in bias in
>> parameter estimates, so it is a trade off. We often speak of
>> appropriate models, but the appropriateness depends on the purpose -
>> do we seek inference for a specific (set of) parameter(s), the system
>> as a whole or do we want to use it for prediction?
>>
>> /Rune
>>>
>>> If you do anyway want a Bayesian credible interval, which you can
>>> treat pretty much as a confidence interval, for the random  
>>> component,
>>> check Douglas Bates' message of a few hours ago, the first of two
>>> messages with the subject "lme4::mcmcsamp + coda::HPDinterval", re  
>>> the
>>> use of the function HPDInterval().
>>>
>>>
>>> John Maindonald             email: john.maindonald at anu.edu.au
>>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>>> Centre for Mathematics & Its Applications, Room 1194,
>>> John Dedman Mathematical Sciences Building (Building 27)
>>> Australian National University, Canberra ACT 0200.
>>>
>>>
>>>
>>> On 2 Apr 2008, at 4:02 AM, Leonel Arturo Lopez Toledo wrote:
>>>
>>>> Dear all:
>>>> I'm new to mixed models and I'm trying to understand the output  
>>>> from
>>>> "lme" in the nlme
>>>> package. I hope my question is not too basic for that list-mail.
>>>> Really sorry if that
>>>> is the case.
>>>> Especially I have problems to interpret the random effect output. I
>>>> have only one
>>>> random factor which is "Site". I know the "Variance and Stdev"
>>>> indicate variation by
>>>> the random factor, but are they indicating any significance? Is
>>>> there any way to
>>>> obtain a p-value for the random effects? And in case is not
>>>> significant, how can I
>>>> remove it from the model? With "update (model,~.-)"?
>>>>
>>>> The variance in first case (see below) is very low and in the  
>>>> second
>>>> example is more
>>>> considerable, but should I consider in the model or do I remove it?
>>>>
>>>> Thank you very much for your help in advance.
>>>>
>>>> EXAMPLE 1
>>>> Linear mixed-effects model fit by maximum likelihood
>>>> Data: NULL
>>>>      AIC      BIC    logLik
>>>> 277.8272 287.3283 -132.9136
>>>>
>>>> Random effects:
>>>> Formula: ~1 | Sitio
>>>>        (Intercept) Residual
>>>> StdDev: 0.0005098433 9.709515
>>>>
>>>> EXAMPLE 2
>>>> Generalized linear mixed model fit using Laplace
>>>> Formula: y ~Canopy*Area + (1 | Sitio)
>>>>  Data: tod
>>>> Family: binomial(logit link)
>>>>  AIC   BIC logLik deviance
>>>> 50.93 54.49 -21.46    42.93
>>>>
>>>> Random effects:
>>>> Groups Name        Variance Std.Dev.
>>>> Sitio  (Intercept) 0.25738  0.50733
>>>> number of obs: 18, groups: Sitio, 6
>>>>
>>>>
>>>> Leonel Lopez
>>>> Centro de Investigaciones en Ecosistemas-UNAM
>>>> MEXICO
>>>>
>>>>
>>>>
>>>>
>>>> --
>>>> Este mensaje ha sido analizado por MailScanner
>>>> en busca de virus y otros contenidos peligrosos,
>>>> y se considera que est? limpio.
>>>> For all your IT requirements visit: http://www.transtec.co.uk
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> Dr. Hank Stevens, Assistant Professor
> 338 Pearson Hall
> Botany Department
> Miami University
> Oxford, OH 45056
>
> Office: (513) 529-4206
> Lab: (513) 529-4262
> FAX: (513) 529-4243
> http://www.cas.muohio.edu/~stevenmh/
> http://www.cas.muohio.edu/ecology
> http://www.muohio.edu/botany/
>
> "If the stars should appear one night in a thousand years, how would  
> men
> believe and adore." -Ralph Waldo Emerson, writer and philosopher  
> (1803-1882)
>
>
>
>
>
>



From David.Duffy at qimr.edu.au  Thu Apr  3 06:27:16 2008
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Thu, 3 Apr 2008 14:27:16 +1000 (EST)
Subject: [R-sig-ME] how to know if random factors are significant?
In-Reply-To: <8AC2A6A3-4E90-43B8-B4F3-AFD2720511FF@anu.edu.au>
References: <20080401165818.M50176@oikos.unam.mx><BB14B19D-8F1A-4528-B86C-61C42738B6F3@anu.edu.au><4949c7e60804020035g2934b01fx500ee31f8a1b1664@mail.gmail.com><A19A77C8-01AD-4454-9797-8202A5AADB9A@muohio.edu>
	<8AC2A6A3-4E90-43B8-B4F3-AFD2720511FF@anu.edu.au>
Message-ID: <Pine.LNX.4.64.0804031302130.17108@orpheus.qimr.edu.au>

On Thu, 3 Apr 2008, John Maindonald wrote:

> Debate over the use of results from twin studies to partition effects
> on measured IQ into environmental and genetic components illustrates
> the point.  The variance components are relevant only in the
> populations of parents who adopted one or other twin.  More to the
> present point, the Flynn effect by which there've been huge IQ
> increases between one generation and the next requires the invocation
> of some mixture of environmental and genetic effects that are outside
> the ken of both the twin studies data and the models used to analyze
> that data.  In biology, do not expect anything to be simple.  As I
> understand it, there've been a variety of attempts to explain the
> Flynn effect, but no clear consensus.
>

Well, this discussion is straying more into the topic of whether the study 
of individual differences is useful.  Even though the mechanism of cohort 
effects on IQ measures is unknown, a suitable observational design can 
still look at variances within generations and covariances between 
generations for various types of relative pair.  A just as difficult human 
phenotype is adult height, where all these same issues are acting (strong 
secular trends, very strong familial resemblance).

> The analyst ought to worry about implications of the with/without
> disputed random effect for power (or effective sample size, or ...) as
> well as for the p-value or CI limits.  The analyst who omits the
> disputed random effect has to worry both that the p-value might be
> unreasonably optimistic and the power curve unreasonably optimistic.
>

This same bugbear is brought up all the time where a particular fixed 
effect/covariate is "not statistically significant" in the present study, 
even though it is known to have effects in other studies.  It is generally 
recommended to include that covariate in one's models. I have never been 
particularly impressed by the examples (eg Breslow and Day) that purport 
to demonstrate problems with just dropping it out -- but it is one place 
where a Bayesian framework deals sensibly with the prior scientific 
information.

Cheers, David Duffy.
-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From kjbeath at kagi.com  Thu Apr  3 06:40:59 2008
From: kjbeath at kagi.com (Ken Beath)
Date: Thu, 3 Apr 2008 15:40:59 +1100
Subject: [R-sig-ME] how to know if random factors are significant?
In-Reply-To: <A19A77C8-01AD-4454-9797-8202A5AADB9A@muohio.edu>
References: <20080401165818.M50176@oikos.unam.mx>
	<BB14B19D-8F1A-4528-B86C-61C42738B6F3@anu.edu.au>
	<4949c7e60804020035g2934b01fx500ee31f8a1b1664@mail.gmail.com>
	<A19A77C8-01AD-4454-9797-8202A5AADB9A@muohio.edu>
Message-ID: <56F7EF10-935B-4E22-B7D6-6E93AD954CF5@kagi.com>


On 02/04/2008, at 9:27 PM, MHH Stevens wrote:

>
> On Apr 2, 2008, at 3:35 AM, Rune Haubo wrote:
>> On 02/04/2008, John Maindonald <john.maindonald at anu.edu.au> wrote:
>>> There was a related question from Mariana Martinez a day or two ago.
>>> Before removing a random term that background knowledge or past
>>> experience with similar data suggests is likely, check what
>>> difference
>>> it makes to the p-values for the fixed  effects that are of
>>> interest.
>>> If it makes a substantial difference, caution demands that it be
>>> left
>>> it in.
>>>
>>> To pretty much repeat my earlier comment:
>>> If you omit the component then you have to contemplate the
>>> alternatives:
>>> 1) the component really was present but undetectable
>>> 2) the component was not present, or so small that it could be
>>> ignored, and the inference from the model that omits it is valid.
>>>
>>> If (1) has a modest probability, and it matters whether you go with
>>> (1) or (2), going with (2) leads to a very insecure inference.
>>> The p-
>>> value that comes out of the analysis is unreasonably optimistic;
>>> it is
>>> wrong and misleading.
> Can "caution" ever cause us to select the more "optimistic" model? If
> we assume that the absence of the random effect reduces the p-value
> of the fixed effect, we might ponder the situation in which there is
> a meaningful risk associated with with ignoring type II error (that
> we erroneously accept the null hypothesis). Imagine field testing the
> effects of a pesticide on non-target organisms --- does (2) result in
> a "minimum" p-value, or is the p-value, as John said, wrong and
> misleading?
>
> More generally, if a random effect has the real potential to exist
> (has a "modest probability"), but we don't see evidence for it in our
> particular data set, does it exist for us? (i.e. "If a tree
> falls ..." or worse, Heisenberg's proposition, Is the cat dead if we
> don't look?). I have typically acted as though it does not exist if I
> do not have evidence for it in MY data. However, when it does make a
> significant difference, I do lose sleep over it.
>

Incorrectly ignoring a random effect will have the effect of either  
increasing or decreasing the significance level of fixed effects. With  
the common configuration where a covariate is constant across a  
cluster the effect of ignoring the covariate is to increase  
significance. Provided it doesn't produce numerical problems including  
a non-existent random effect probably isn't going to make a lot of  
difference to the p-values.

One worry I have with checking for the existence of a random effect is  
that I may have low power to detect the effect, so I don't find it,  
but it may still be sufficient to inflate the type I error for a  
covariate, maybe excessively so. For this reason it seems essential to  
include a random effect where a fixed effect may operate in the same  
way. If there are possible random effects that aren't related to  
covariates, it is probably reasonable to exclude them if they don't  
seem significant.

As an example, if I had repeated measurements on a subject over time  
with a linear relationship, then I might have both a random effect for  
constant and slope. Assume treatments applied to different subjects.  
Now if my model is that treatments only affect the mean response and I  
find that a random effect for slope doesn't improve the model, then  
excluding it may improve the fit of the covariates without causing  
other problems. However if I model the effect of treatment  on the  
slope then I should have both random effects in the model (the random  
effect for constant is needed because of the slope random effect) even  
if the slope random effect doesn't seem necessary, in case there  
really is a random effect for slope.

Ken

> -Hank
>>
>> I think this is a question of strategy. Leonel did put emphasis on  
>> the
>> random effect, and he might just be interested in the size and
>> significance of the random effect rather than the fixed effects.
>> Estimating and testing the random effect seems reasonable to me in
>> this case, although confidence intervals, as you mention below also
>> provides good inference.
>>
>> It is always possible to discuss how much non-data information to
>> include in an analysis and I believe the answer depends very much on
>> the purpose of the research. If the research question regards the  
>> size
>> and "existence" of the variance of 'Site', then he might conclude  
>> that
>> it is so small compared to other effects in the model/data, that it
>> has no place in the model.
>>
>> I think the question regarding "existence" of some effect can be
>> misleading in many cases, because one can always claim that any  
>> effect
>> is really there, and had we observed enough data, we would be able to
>> estimate the effect reliably. Leaving too many variables in the model
>> on which there is too little information also results in bias in
>> parameter estimates, so it is a trade off. We often speak of
>> appropriate models, but the appropriateness depends on the purpose -
>> do we seek inference for a specific (set of) parameter(s), the system
>> as a whole or do we want to use it for prediction?
>>
>> /Rune
>>>
>>> If you do anyway want a Bayesian credible interval, which you can
>>> treat pretty much as a confidence interval, for the random
>>> component,
>>> check Douglas Bates' message of a few hours ago, the first of two
>>> messages with the subject "lme4::mcmcsamp + coda::HPDinterval",
>>> re the
>>> use of the function HPDInterval().
>>>
>>>
>>> John Maindonald             email: john.maindonald at anu.edu.au
>>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>>> Centre for Mathematics & Its Applications, Room 1194,
>>> John Dedman Mathematical Sciences Building (Building 27)
>>> Australian National University, Canberra ACT 0200.
>>>
>>>
>>>
>>> On 2 Apr 2008, at 4:02 AM, Leonel Arturo Lopez Toledo wrote:
>>>
>>>> Dear all:
>>>> I'm new to mixed models and I'm trying to understand the output  
>>>> from
>>>> "lme" in the nlme
>>>> package. I hope my question is not too basic for that list-mail.
>>>> Really sorry if that
>>>> is the case.
>>>> Especially I have problems to interpret the random effect output. I
>>>> have only one
>>>> random factor which is "Site". I know the "Variance and Stdev"
>>>> indicate variation by
>>>> the random factor, but are they indicating any significance? Is
>>>> there any way to
>>>> obtain a p-value for the random effects? And in case is not
>>>> significant, how can I
>>>> remove it from the model? With "update (model,~.-)"?
>>>>
>>>> The variance in first case (see below) is very low and in the  
>>>> second
>>>> example is more
>>>> considerable, but should I consider in the model or do I remove it?
>>>>
>>>> Thank you very much for your help in advance.
>>>>
>>>> EXAMPLE 1
>>>> Linear mixed-effects model fit by maximum likelihood
>>>> Data: NULL
>>>>      AIC      BIC    logLik
>>>> 277.8272 287.3283 -132.9136
>>>>
>>>> Random effects:
>>>> Formula: ~1 | Sitio
>>>>        (Intercept) Residual
>>>> StdDev: 0.0005098433 9.709515
>>>>
>>>> EXAMPLE 2
>>>> Generalized linear mixed model fit using Laplace
>>>> Formula: y ~Canopy*Area + (1 | Sitio)
>>>>  Data: tod
>>>> Family: binomial(logit link)
>>>>  AIC   BIC logLik deviance
>>>> 50.93 54.49 -21.46    42.93
>>>>
>>>> Random effects:
>>>> Groups Name        Variance Std.Dev.
>>>> Sitio  (Intercept) 0.25738  0.50733
>>>> number of obs: 18, groups: Sitio, 6
>>>>
>>>>
>>>> Leonel Lopez
>>>> Centro de Investigaciones en Ecosistemas-UNAM
>>>> MEXICO
>>>>
>>>>
>>>>
>>>>
>>>> --
>>>> Este mensaje ha sido analizado por MailScanner
>>>> en busca de virus y otros contenidos peligrosos,
>>>> y se considera que est? limpio.
>>>> For all your IT requirements visit: http://www.transtec.co.uk
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> Dr. Hank Stevens, Assistant Professor
> 338 Pearson Hall
> Botany Department
> Miami University
> Oxford, OH 45056
>
> Office: (513) 529-4206
> Lab: (513) 529-4262
> FAX: (513) 529-4243
> http://www.cas.muohio.edu/~stevenmh/
> http://www.cas.muohio.edu/ecology
> http://www.muohio.edu/botany/
>
> "If the stars should appear one night in a thousand years, how would  
> men
> believe and adore." -Ralph Waldo Emerson, writer and philosopher
> (1803-1882)
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From claudie.desroches at usherbrooke.ca  Thu Apr  3 15:32:43 2008
From: claudie.desroches at usherbrooke.ca (Claudie Desroches)
Date: Thu, 3 Apr 2008 09:32:43 -0400
Subject: [R-sig-ME] help for lemr
Message-ID: <000001c8958f$336491b0$6c1ad284@Claudie>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080403/d217bc15/attachment.pl>

From bates at stat.wisc.edu  Thu Apr  3 16:13:37 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 3 Apr 2008 09:13:37 -0500
Subject: [R-sig-ME] help for lemr
In-Reply-To: <000001c8958f$336491b0$6c1ad284@Claudie>
References: <000001c8958f$336491b0$6c1ad284@Claudie>
Message-ID: <40e66e0b0804030713o6fdc9959w46d2447039675ad4@mail.gmail.com>

Could you tell us which version of the lme4 package you are using, please?  Use

sessionInfo()

to get that information.  If you haven't already done so it may be
worthwhile trying the development version obtainable by

install.packages("lme4", repos = "http://r-forge.r-project.org/")


On Thu, Apr 3, 2008 at 8:32 AM, Claudie Desroches
<claudie.desroches at usherbrooke.ca> wrote:
> To whom who can help me!
>
>
>
>  I want to run an lmer with a Poisson distribution because it is abundance
>  data (discrete data)named "ind_total".
>
>  I have a nested structure which is "observations" within "localisation"
>  within "site"
>
>  The lme function would be: y~x1+x2+x3+random=1|site/localisation, data)
>
>
>
>  Actually, with lmer function I tried :
>  model_2_lmer<-lmer(ind_total~1+(1|site:localisation)+(1|site),data=donnees,m
>  ethod="Laplace",family=poisson(link = "log"),na.action=na.omit)
>
>  And a warning message appears saying:
>
>
>
>  Error in lmerFactorList(formula, mf, fltype) :
>
>   number of levels in grouping factor(s) 'site' is too large
>
>  Warning messages:
>
>  1: In site:localisation :
>
>   l'expression num?rique a 1278 ?l?ments : seul le premier est utilis?
>  (numerical expression has 1278 elements : only first is used)
>
>  2: In site:localisation :
>
>   l'expression num?rique a 1278 ?l?ments : seul le premier est utilis?
>  (numerical expression has 1278 elements : only first is used)
>
>
>
>  So I tried
>
>  model_3_lmer<-lmer(ind_total~1+(1|localisation)+(1|site),data=donnees,method
>  ="Laplace",family=poisson(link = "log"),na.action=na.omit)
>
>  and it seems to work:
>
>  Generalized linear mixed model fit using Laplace
>
>  Formula: ind_total ~ 1 + (1 | localisation) + (1 | site)
>
>    Data: donnees
>
>   Family: poisson(log link)
>
>   AIC  BIC logLik deviance
>
>   1032 1048 -513.1     1026
>
>  Random effects:
>
>   Groups       Name        Variance   Std.Dev.
>
>   site         (Intercept) 2.0538e-01 4.5319e-01
>
>   localisation (Intercept) 5.0000e-10 2.2361e-05
>
>  number of obs: 1278, groups: site, 40; localisation, 2
>
>
>
>  Estimated scale (compare to  1 )  0.7704331
>
>
>
>  Fixed effects:
>
>             Estimate Std. Error z value Pr(>|z|)
>
>  (Intercept)  0.15660    0.07645   2.048   0.0405 *
>
>
>
>  Is my nested structure written right?
>
>
>
>  Then I tried to include all my covariates and a warning message appears
>  again:
>
>  model_4lmer<-lmer(ind_total~as.factor(annee)+temp+as.factor(pluie)+foret_tot
>  +superf_reelle+foret_tot*superf_reelle+as.factor(localisation)+as.factor(pic
>  )+axe_1+axe_2+as.factor(traitement)+as.factor(annee)*as.factor(traitement)+(
>  1|localisation)+(1|site),data=donnees,method="Laplace",family=poisson(link =
>  "log"),na.action=na.omit)
>
>  > summary(model_4lmer)
>
>  Erreur dans asMethod(object) : matrix is not symmetric [1,2]
>
>
>
>  I looked at my matrix and everything is ok? the only thing is I have 3 NAs
>  in my response variable but I specified "na.action=na.omit"?What am I doing
>  wrong!?!
>
>  Thank you
>
>  Claudie Desroches
>
>  ------------
>
>  Claudie Desroches
>  ?tudiante au 2e cycle
>  Chaire de recherche du Canada en ?cologie spatiale et en ?cologie du paysage
>  Universit? de Sherbrooke: D?partement de Biologie
>  1-819-821-8000 poste 63468
>  HYPERLINK
>  "mailto:claudie.desroches at usherbrooke.ca"claudie.desroches at usherbrooke.ca
>
>
>
>
>
>  Checked by AVG.
>
>  10:48
>
>
>         [[alternative HTML version deleted]]
>
>
> _______________________________________________
>  R-sig-mixed-models at r-project.org mailing list
>  https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



From a.beckerman at sheffield.ac.uk  Thu Apr  3 16:43:55 2008
From: a.beckerman at sheffield.ac.uk (Andrew Beckerman)
Date: Thu, 3 Apr 2008 15:43:55 +0100
Subject: [R-sig-ME] logLik df in lme vs. lmer
Message-ID: <2CFF26DD-D449-474C-9938-C834A4EBB270@sheffield.ac.uk>

Dear all -

R 2.6.2, lme4 version 0.99875-9, OSX.

We have noticed that lme and lmer produce different estimates of the  
number of paramters in the estimation of the logLik.  While these are   
different, the logLik is not (good), but ensuing calculations of AIC  
can be.

According to some textbooks (i.e. Burnham and Anderson), the number of  
paramters is calcuated as the intercept + betas+ random effects levels  
(?) + a term for the residual variance.  In the example below  
(sleepstudy from lmer), that calculation results in df=5, as indicated  
in lmer but not in lme.

library(lme4)

wrk<-sleepstudy # data from lmer package

fm.lmer <- lmer(Reaction ~ Days + (Days|Subject), wrk,method="ML")
logLik(fm.lmer) # df = 5
fm.lmer
AIC(logLik(fm.lmer))

detach(package:lme4)

library(nlme)

fm.lme <- lme(Reaction ~ Days,random=~Days|Subject, wrk,method="ML")
summary(fm.lme)
logLik(fm.lme) # df=6
AIC(logLik(fm.lme))

However, we have also seen lmer appear to "underestimate" and lme get  
it right -

# continuing from above

wrk2<-Orthodont # data from nlme package
fm.lme2 <- lme(distance ~ age + Sex, data = wrk2, random = ~  
1,method="ML")
fm.lme2
logLik(fm.lme2) # df=5 (correct?)

detach(package:nlme)

library(lme4)

fm.lmer2 <- lmer(distance ~ age + Sex+(1|Subject), data = wrk2,  
method="ML")
fm.lmer2
logLik(fm.lmer2) # df=4 (now underestimated?)

Does anyone know what is going on?  Obviously, we can just specify the  
df in AIC calculations by hand, but AIC() uses the df from logLik (),  
which seems to vary.

I've noticed this question here as well.

http://tolstoy.newcastle.edu.au/R/e4/help/08/02/3988.html

Cheers
andrew


---------------------------------------------------------------------------------
Dr. Andrew Beckerman
Department of Animal and Plant Sciences, University of Sheffield,
Alfred Denny Building, Western Bank, Sheffield S10 2TN, UK
ph +44 (0)114 222 0026; fx +44 (0)114 222 0002
http://www.beckslab.staff.shef.ac.uk/



From a.beckerman at sheffield.ac.uk  Thu Apr  3 18:10:09 2008
From: a.beckerman at sheffield.ac.uk (Andrew Beckerman)
Date: Thu, 3 Apr 2008 17:10:09 +0100
Subject: [R-sig-ME] logLik df in lme vs. lmer
In-Reply-To: <8C28BAD5-9321-4155-9477-2C8089858329@muohio.edu>
References: <2CFF26DD-D449-474C-9938-C834A4EBB270@sheffield.ac.uk>
	<8C28BAD5-9321-4155-9477-2C8089858329@muohio.edu>
Message-ID: <06FCC6B3-3293-40F9-9BE4-CD7B9876414F@sheffield.ac.uk>

Dear all -

Given Hank's comment below, I want to emphasize that I am not aiming  
to get into the rather enjoyable df debate...i.e. "how" or even  
whether to calculate df....

Lets assume that we are going to use the df = intercept + betas+  
random effects levels(?) + a term for the residual variance.

I was curious as to whether there was a concious decision made between  
lme and lmer, and if so, whether there is something to the "variable"  
difference between them as indicated by the code for the two datasets  
in the original posting.

A

---------------------------------------------------------------------------------
Dr. Andrew Beckerman
Department of Animal and Plant Sciences, University of Sheffield,
Alfred Denny Building, Western Bank, Sheffield S10 2TN, UK
ph +44 (0)114 222 0026; fx +44 (0)114 222 0002
http://www.beckslab.staff.shef.ac.uk/
----------------------------------------------------------------------------------


On 3 Apr 2008, at 15:57, MHH Stevens wrote:
> Hi Andrew,
> Welcome to the hornets' nest.
> Hank
> On Apr 3, 2008, at 10:43 AM, Andrew Beckerman wrote:
>> Dear all -
>>
>> R 2.6.2, lme4 version 0.99875-9, OSX.
>>
>> We have noticed that lme and lmer produce different estimates of the
>> number of paramters in the estimation of the logLik.  While these are
>> different, the logLik is not (good), but ensuing calculations of AIC
>> can be.
>>
>> According to some textbooks (i.e. Burnham and Anderson), the number  
>> of
>> paramters is calcuated as the intercept + betas+ random effects  
>> levels
>> (?) + a term for the residual variance.  In the example below
>> (sleepstudy from lmer), that calculation results in df=5, as  
>> indicated
>> in lmer but not in lme.
>>
>> library(lme4)
>>
>> wrk<-sleepstudy # data from lmer package
>>
>> fm.lmer <- lmer(Reaction ~ Days + (Days|Subject), wrk,method="ML")
>> logLik(fm.lmer) # df = 5
>> fm.lmer
>> AIC(logLik(fm.lmer))
>>
>> detach(package:lme4)
>>
>> library(nlme)
>>
>> fm.lme <- lme(Reaction ~ Days,random=~Days|Subject, wrk,method="ML")
>> summary(fm.lme)
>> logLik(fm.lme) # df=6
>> AIC(logLik(fm.lme))
>>
>> However, we have also seen lmer appear to "underestimate" and lme get
>> it right -
>>
>> # continuing from above
>>
>> wrk2<-Orthodont # data from nlme package
>> fm.lme2 <- lme(distance ~ age + Sex, data = wrk2, random = ~
>> 1,method="ML")
>> fm.lme2
>> logLik(fm.lme2) # df=5 (correct?)
>>
>> detach(package:nlme)
>>
>> library(lme4)
>>
>> fm.lmer2 <- lmer(distance ~ age + Sex+(1|Subject), data = wrk2,
>> method="ML")
>> fm.lmer2
>> logLik(fm.lmer2) # df=4 (now underestimated?)
>>
>> Does anyone know what is going on?  Obviously, we can just specify  
>> the
>> df in AIC calculations by hand, but AIC() uses the df from logLik (),
>> which seems to vary.
>>
>> I've noticed this question here as well.
>>
>> http://tolstoy.newcastle.edu.au/R/e4/help/08/02/3988.html
>>
>> Cheers
>> andrew
>>
>>
>> ---------------------------------------------------------------------------------
>> Dr. Andrew Beckerman
>> Department of Animal and Plant Sciences, University of Sheffield,
>> Alfred Denny Building, Western Bank, Sheffield S10 2TN, UK
>> ph +44 (0)114 222 0026; fx +44 (0)114 222 0002
>> http://www.beckslab.staff.shef.ac.uk/
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> Dr. Hank Stevens, Assistant Professor
> 338 Pearson Hall
> Botany Department
> Miami University
> Oxford, OH 45056
>
> Office: (513) 529-4206
> Lab: (513) 529-4262
> FAX: (513) 529-4243
> http://www.cas.muohio.edu/~stevenmh/
> http://www.cas.muohio.edu/ecology
> http://www.muohio.edu/botany/
>
> "If the stars should appear one night in a thousand years, how would  
> men
> believe and adore." -Ralph Waldo Emerson, writer and philosopher  
> (1803-1882)
>
>
>
>
>
>



From maechler at stat.math.ethz.ch  Thu Apr  3 18:16:11 2008
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 3 Apr 2008 18:16:11 +0200
Subject: [R-sig-ME] logLik df in lme vs. lmer
In-Reply-To: <2CFF26DD-D449-474C-9938-C834A4EBB270@sheffield.ac.uk>
References: <2CFF26DD-D449-474C-9938-C834A4EBB270@sheffield.ac.uk>
Message-ID: <18421.715.677380.802279@stat.math.ethz.ch>

>>>>> "AB" == Andrew Beckerman <a.beckerman at sheffield.ac.uk>
>>>>>     on Thu, 3 Apr 2008 15:43:55 +0100 writes:

    AB> Dear all -
    AB> R 2.6.2, lme4 version 0.99875-9, OSX.

If you use any recent R-forge version of 'lme4'
you will see that the degrees of freedoms 
are 6 and 5  (instead of 5 and 4) for your two examples.

You can get the R-forge version by

install.packages("lme4",repos="http://R-Forge.R-project.org")
library(lme4)

If you want to have it in a different than default library
(because you would want the "old" CRAN-lme4 by default),
you'd need something like

myLib <- "......./my_library"
##        ^^^^^^^^^^^^^^^^^^  a place where you have WRITE permission
dir.create(myLib)
install.packages("lme4",repos="http://R-Forge.R-project.org",
		 lib = myLib)
library(lme4, lib = myLib)


Martin




    AB> We have noticed that lme and lmer produce different estimates of the  
    AB> number of paramters in the estimation of the logLik.  While these are   
    AB> different, the logLik is not (good), but ensuing calculations of AIC  
    AB> can be.

    AB> According to some textbooks (i.e. Burnham and Anderson), the number of  
    AB> paramters is calcuated as the intercept + betas+ random effects levels  
    AB> (?) + a term for the residual variance.  In the example below  
    AB> (sleepstudy from lmer), that calculation results in df=5, as indicated  
    AB> in lmer but not in lme.

    AB> library(lme4)

    AB> wrk<-sleepstudy # data from lmer package

    AB> fm.lmer <- lmer(Reaction ~ Days + (Days|Subject), wrk,method="ML")
    AB> logLik(fm.lmer) # df = 5
    AB> fm.lmer
    AB> AIC(logLik(fm.lmer))

    AB> detach(package:lme4)

    AB> library(nlme)

    AB> fm.lme <- lme(Reaction ~ Days,random=~Days|Subject, wrk,method="ML")
    AB> summary(fm.lme)
    AB> logLik(fm.lme) # df=6
    AB> AIC(logLik(fm.lme))

    AB> However, we have also seen lmer appear to "underestimate" and lme get  
    AB> it right -

    AB> # continuing from above

    AB> wrk2<-Orthodont # data from nlme package
    AB> fm.lme2 <- lme(distance ~ age + Sex, data = wrk2, random = ~  
    AB> 1,method="ML")
    AB> fm.lme2
    AB> logLik(fm.lme2) # df=5 (correct?)

    AB> detach(package:nlme)

    AB> library(lme4)

    AB> fm.lmer2 <- lmer(distance ~ age + Sex+(1|Subject), data = wrk2,  
    AB> method="ML")
    AB> fm.lmer2
    AB> logLik(fm.lmer2) # df=4 (now underestimated?)

    AB> Does anyone know what is going on?  Obviously, we can just specify the  
    AB> df in AIC calculations by hand, but AIC() uses the df from logLik (),  
    AB> which seems to vary.

    AB> I've noticed this question here as well.

    AB> http://tolstoy.newcastle.edu.au/R/e4/help/08/02/3988.html

    AB> Cheers
    AB> andrew


    AB> ---------------------------------------------------------------------------------
    AB> Dr. Andrew Beckerman
    AB> Department of Animal and Plant Sciences, University of Sheffield,
    AB> Alfred Denny Building, Western Bank, Sheffield S10 2TN, UK
    AB> ph +44 (0)114 222 0026; fx +44 (0)114 222 0002
    AB> http://www.beckslab.staff.shef.ac.uk/

    AB> _______________________________________________
    AB> R-sig-mixed-models at r-project.org mailing list
    AB> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From spluque at gmail.com  Thu Apr  3 22:45:33 2008
From: spluque at gmail.com (Sebastian P. Luque)
Date: Thu, 03 Apr 2008 15:45:33 -0500
Subject: [R-sig-ME] random effects specification
Message-ID: <87abkak6qa.fsf@patagonia.sebmags.homelinux.org>

Hi,

In the past I've used lme to fit simple mixed models to longitudinal
data (growth), but now I'm trying to learn lmer and its different syntax
to fit a more complex model.  I have a structure with subjects (id,
random factor) exposed to 4 different treatments and a continuous
response variable is measured (n).  The subjects come from 2 different
communities, so it's a nested design very much like the Oats data in the
nlme package.  The interest is in the fixed effects of community and
treatment, and their interaction, so I thought this could be modelled in
lmer with this call:

lmer(n ~ treatment + community + (1 | id/treatment), mydata)

but got this error:

Error in lmerFactorList(formula, mf, fltype) : 
  number of levels in grouping factor(s) ?treatment:id? is too large


Am I using the right formula here?  Thanks.


-- 
Seb



From bates at stat.wisc.edu  Fri Apr  4 00:32:40 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 3 Apr 2008 17:32:40 -0500
Subject: [R-sig-ME] random effects specification
In-Reply-To: <87abkak6qa.fsf@patagonia.sebmags.homelinux.org>
References: <87abkak6qa.fsf@patagonia.sebmags.homelinux.org>
Message-ID: <40e66e0b0804031532q12880b01mcba6173fc3e32c10@mail.gmail.com>

On Thu, Apr 3, 2008 at 3:45 PM, Sebastian P. Luque <spluque at gmail.com> wrote:
> Hi,

>  In the past I've used lme to fit simple mixed models to longitudinal
>  data (growth), but now I'm trying to learn lmer and its different syntax
>  to fit a more complex model.  I have a structure with subjects (id,
>  random factor) exposed to 4 different treatments and a continuous
>  response variable is measured (n).  The subjects come from 2 different
>  communities, so it's a nested design very much like the Oats data in the
>  nlme package.  The interest is in the fixed effects of community and
>  treatment, and their interaction, so I thought this could be modelled in
>  lmer with this call:

>  lmer(n ~ treatment + community + (1 | id/treatment), mydata)

>  but got this error:

>  Error in lmerFactorList(formula, mf, fltype) :
>   number of levels in grouping factor(s) 'treatment:id' is too large

>  Am I using the right formula here?  Thanks.

It seems that the observations are indexed by subject and treatment so
the number of levels in the factor treatment:id equals the number of
observations.  You can't estimate a variance for such a term and also
estimate a residual variance.

I would start with

n ~ treatment * community +(1|id)



From spluque at gmail.com  Fri Apr  4 01:32:23 2008
From: spluque at gmail.com (Sebastian P. Luque)
Date: Thu, 03 Apr 2008 18:32:23 -0500
Subject: [R-sig-ME] random effects specification
References: <87abkak6qa.fsf@patagonia.sebmags.homelinux.org>
	<40e66e0b0804031532q12880b01mcba6173fc3e32c10@mail.gmail.com>
Message-ID: <878wzuzf94.fsf@patagonia.sebmags.homelinux.org>

On Thu, 3 Apr 2008 17:32:40 -0500,
"Douglas Bates" <bates at stat.wisc.edu> wrote:

[...]

> It seems that the observations are indexed by subject and treatment so
> the number of levels in the factor treatment:id equals the number of
> observations.  You can't estimate a variance for such a term and also
> estimate a residual variance.

> I would start with

> n ~ treatment * community +(1|id)

Yes, the observations are indexed by subject and treatment in the sense
that id levels are the same within treatments of the same community, but
are different among communities.  This is a subset of the data:

---<---------------cut here---------------start-------------->---
id  community treatment     n
 1          A         1 13.93
 2          A         1 14.42
 3          A         1 13.56
 1          A         2 14.61
 2          A         2 14.74
 3          A         2 15.59
 1          A         3 13.95
 2          A         3 15.21
 3          A         3 14.51
 1          A         4 13.61
 2          A         4 14.99
 3          A         4 15.13
 4          B         1 14.79
 5          B         1 13.41
 6          B         1 14.71
 4          B         2 14.69
 5          B         2 13.46
 6          B         2 14.28
 4          B         3 14.30
 5          B         3 13.18
 6          B         3 13.58
 4          B         4 14.54
 5          B         4 13.25
 6          B         4 14.09
---<---------------cut here---------------end---------------->---

Of course, there are many more individuals, but the levels of id differ
among communities, and are the same among treatments.  lmer did converge
rapidly with your suggested formula though:

---<---------------cut here---------------start-------------->---
Linear mixed-effects model fit by REML 
Formula: n ~ treatment * community + (1 | id) 
   Data: isotope.m.ph 
 AIC BIC logLik MLdeviance REMLdeviance
 450 481   -216        410          432
Random effects:
 Groups   Name        Variance Std.Dev.
 id       (Intercept) 0.193    0.439   
 Residual             0.232    0.481   
number of obs: 240, groups: id, 61

Fixed effects:
                               Estimate Std. Error t value
(Intercept)                     14.9748     0.1170   128.0
treatment2                       0.0884     0.1222     0.7
treatment3                      -0.2829     0.1222    -2.3
treatment4                       0.3568     0.1222     2.9
communitysanikiluaq             -0.5749     0.1678    -3.4
treatment2:communitysanikiluaq  -0.2471     0.1763    -1.4
treatment3:communitysanikiluaq  -0.7479     0.1763    -4.2
treatment4:communitysanikiluaq  -0.6169     0.1763    -3.5

Correlation of Fixed Effects:
            (Intr) trtmn2 trtmn3 trtmn4 cmmnty trtm2: trtm3:
treatment2  -0.522                                          
treatment3  -0.522  0.500                                   
treatment4  -0.522  0.500  0.500                            
cmmntysnklq -0.697  0.364  0.364  0.364                     
trtmnt2:cmm  0.362 -0.693 -0.347 -0.347 -0.524              
trtmnt3:cmm  0.362 -0.347 -0.693 -0.347 -0.524  0.503       
trtmnt4:cmm  0.362 -0.347 -0.347 -0.693 -0.524  0.503  0.503
---<---------------cut here---------------end---------------->---


However, I don't understand how (1 | id) accounts for treatment being
nested within community.  Maybe it's time for me to re-read some more
examples from "Mixed-effects models in S and S-plus".  Thanks.


Cheers,

-- 
Seb



From bates at stat.wisc.edu  Fri Apr  4 14:17:36 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 4 Apr 2008 07:17:36 -0500
Subject: [R-sig-ME] random effects specification
In-Reply-To: <878wzuzf94.fsf@patagonia.sebmags.homelinux.org>
References: <87abkak6qa.fsf@patagonia.sebmags.homelinux.org>
	<40e66e0b0804031532q12880b01mcba6173fc3e32c10@mail.gmail.com>
	<878wzuzf94.fsf@patagonia.sebmags.homelinux.org>
Message-ID: <40e66e0b0804040517w3602b3dch6e6d5c7d53f33eb@mail.gmail.com>

On Thu, Apr 3, 2008 at 6:32 PM, Sebastian P. Luque <spluque at gmail.com> wrote:
> On Thu, 3 Apr 2008 17:32:40 -0500,
>  "Douglas Bates" <bates at stat.wisc.edu> wrote:
>
>  [...]
>
>
>  > It seems that the observations are indexed by subject and treatment so
>  > the number of levels in the factor treatment:id equals the number of
>  > observations.  You can't estimate a variance for such a term and also
>  > estimate a residual variance.
>
>  > I would start with
>
>  > n ~ treatment * community +(1|id)
>
>  Yes, the observations are indexed by subject and treatment in the sense
>  that id levels are the same within treatments of the same community, but
>  are different among communities.  This is a subset of the data:
>
>  ---<---------------cut here---------------start-------------->---
>  id  community treatment     n
>   1          A         1 13.93
>   2          A         1 14.42
>   3          A         1 13.56
>   1          A         2 14.61
>   2          A         2 14.74
>   3          A         2 15.59
>   1          A         3 13.95
>   2          A         3 15.21
>   3          A         3 14.51
>   1          A         4 13.61
>   2          A         4 14.99
>   3          A         4 15.13
>   4          B         1 14.79
>   5          B         1 13.41
>   6          B         1 14.71
>   4          B         2 14.69
>   5          B         2 13.46
>   6          B         2 14.28
>   4          B         3 14.30
>   5          B         3 13.18
>   6          B         3 13.58
>   4          B         4 14.54
>   5          B         4 13.25
>   6          B         4 14.09
>  ---<---------------cut here---------------end---------------->---
>
>  Of course, there are many more individuals, but the levels of id differ
>  among communities, and are the same among treatments.  lmer did converge
>  rapidly with your suggested formula though:
>
>  ---<---------------cut here---------------start-------------->---
>  Linear mixed-effects model fit by REML
>  Formula: n ~ treatment * community + (1 | id)
>    Data: isotope.m.ph
>   AIC BIC logLik MLdeviance REMLdeviance
>   450 481   -216        410          432
>  Random effects:
>   Groups   Name        Variance Std.Dev.
>   id       (Intercept) 0.193    0.439
>   Residual             0.232    0.481
>  number of obs: 240, groups: id, 61
>
>  Fixed effects:
>                                Estimate Std. Error t value
>  (Intercept)                     14.9748     0.1170   128.0
>  treatment2                       0.0884     0.1222     0.7
>  treatment3                      -0.2829     0.1222    -2.3
>  treatment4                       0.3568     0.1222     2.9
>  communitysanikiluaq             -0.5749     0.1678    -3.4
>  treatment2:communitysanikiluaq  -0.2471     0.1763    -1.4
>  treatment3:communitysanikiluaq  -0.7479     0.1763    -4.2
>  treatment4:communitysanikiluaq  -0.6169     0.1763    -3.5
>
>  Correlation of Fixed Effects:
>             (Intr) trtmn2 trtmn3 trtmn4 cmmnty trtm2: trtm3:
>  treatment2  -0.522
>  treatment3  -0.522  0.500
>  treatment4  -0.522  0.500  0.500
>  cmmntysnklq -0.697  0.364  0.364  0.364
>  trtmnt2:cmm  0.362 -0.693 -0.347 -0.347 -0.524
>  trtmnt3:cmm  0.362 -0.347 -0.693 -0.347 -0.524  0.503
>  trtmnt4:cmm  0.362 -0.347 -0.347 -0.693 -0.524  0.503  0.503
>  ---<---------------cut here---------------end---------------->---
>
>
>  However, I don't understand how (1 | id) accounts for treatment being
>  nested within community.  Maybe it's time for me to re-read some more
>  examples from "Mixed-effects models in S and S-plus".  Thanks.

I'm not sure that I understand what you mean by "treatment being
nested within community".  Does this mean that there are really 8
different treatments because treatment 1 in community A is different
from treatment 1 in community B?  If so, then it would make sense to
me to simply create a new factor that is the interaction of treatment
and community.

Perhaps I am approaching the community factor incorrectly.  In your
data there are two communities so, even if it would be reasonable to
model community effects as random effects, that would be difficult.
With only two levels I think it is best modeled as a fixed effect,
which would mean that questions about treatment and community are
related to the fixed effects.



From jesse.whittington2 at gmail.com  Fri Apr  4 14:56:08 2008
From: jesse.whittington2 at gmail.com (Jesse Whittington)
Date: Fri, 4 Apr 2008 06:56:08 -0600
Subject: [R-sig-ME] random effects specification
In-Reply-To: <40e66e0b0804040517w3602b3dch6e6d5c7d53f33eb@mail.gmail.com>
References: <87abkak6qa.fsf@patagonia.sebmags.homelinux.org>
	<40e66e0b0804031532q12880b01mcba6173fc3e32c10@mail.gmail.com>
	<878wzuzf94.fsf@patagonia.sebmags.homelinux.org>
	<40e66e0b0804040517w3602b3dch6e6d5c7d53f33eb@mail.gmail.com>
Message-ID: <3f86a31e0804040556l26e64de7o620ed8a7e178f4ad@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080404/c6c4ab3a/attachment.pl>

From spluque at gmail.com  Fri Apr  4 15:05:10 2008
From: spluque at gmail.com (Sebastian P. Luque)
Date: Fri, 04 Apr 2008 08:05:10 -0500
Subject: [R-sig-ME] random effects specification
References: <87abkak6qa.fsf@patagonia.sebmags.homelinux.org>
	<40e66e0b0804031532q12880b01mcba6173fc3e32c10@mail.gmail.com>
	<878wzuzf94.fsf@patagonia.sebmags.homelinux.org>
	<40e66e0b0804040517w3602b3dch6e6d5c7d53f33eb@mail.gmail.com>
Message-ID: <87ve2xydmh.fsf@patagonia.sebmags.homelinux.org>

On Fri, 4 Apr 2008 07:17:36 -0500,
"Douglas Bates" <bates at stat.wisc.edu> wrote:

[...]

> I'm not sure that I understand what you mean by "treatment being
> nested within community".  Does this mean that there are really 8
> different treatments because treatment 1 in community A is different
> from treatment 1 in community B?  If so, then it would make sense to
> me to simply create a new factor that is the interaction of treatment
> and community.

I was not employing the term "nested" properly.  The number of levels
for both community and treatment are 2 and 4, respectively, just as in
the example.  The same 4 treatments were used in both communties, so in
fact, treatment is crossed with community, not nested.  However,
subjects are nested within communities because each subject belongs to
one community only, yet received all 4 treatments.  Sorry for this
confusion.


> Perhaps I am approaching the community factor incorrectly.  In your
> data there are two communities so, even if it would be reasonable to
> model community effects as random effects, that would be difficult.
> With only two levels I think it is best modeled as a fixed effect,
> which would mean that questions about treatment and community are
> related to the fixed effects.

Could you please show a formula for the case where each individual is
seen at both communities (community and treatment still being fixed)?
This would help me understand the syntax better.

Thank you so much for your help.


-- 
Seb



From bates at stat.wisc.edu  Fri Apr  4 15:33:55 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 4 Apr 2008 08:33:55 -0500
Subject: [R-sig-ME] Fwd: same old question - lme4 and p-values
In-Reply-To: <40e66e0b0804040554m41e63d58l3a5825924696cf78@mail.gmail.com>
References: <28642179.2370001207304657364.JavaMail.nabble@isper.nabble.com>
	<40e66e0b0804040554m41e63d58l3a5825924696cf78@mail.gmail.com>
Message-ID: <40e66e0b0804040633k619803fayfd2e9b9b07b88b77@mail.gmail.com>

---------- Forwarded message ----------
From: Douglas Bates <bates at stat.wisc.edu>
Date: Fri, Apr 4, 2008 at 7:54 AM
Subject: Re: same old question - lme4 and p-values
To: andreas.nord at zooekol.lu.se



On Fri, Apr 4, 2008 at 5:24 AM,  <andreas.nord at zooekol.lu.se> wrote:
 > Dear Prof. Bates,

 >  I've recently switched to using R for my analyses, and I find the
lme4 package to be extremely helpful. I have read your explanation
(posted on the mailing list) of why you choose not to display
p-values. Unfortunately, most of the journals I publish in require
that I include p-values, which is why I have to find a way of
calculating them from the lmer output. However, not being a trained
statistician I have some difficulties following your recommendations
given in the explanatory text. In other words, after having fitted my
model, I am not at all sure on what to do in order to obtain p-values
(or similar).

 >  I am sorry to have to bother you with a question I know you have
already answered many times, but perhaps you would be so kind as to
give me some hints on how to proceed.

 I understand your situation.  Statisticians have created the "every
 question of scientific interest must be answered by a p-value" monster
 and now it turns on us.  Nevertheless I am reluctant to give advice on
 p-values in lme4 because apparently I don't know how to do it
 correctly.

 May I send a copy of this reply to the
 R-SIG-Mixed-Models at r-project.org mailing list? ("SIG" == "Special
 Interest Group")? (I ask your permission to send the copy because I am
 quoting your original question.)   Some who subscribe to that mailing
 list may have the courage to wade into this swamp and offer their
 advice.



From ngbyju at gmail.com  Fri Apr  4 16:15:23 2008
From: ngbyju at gmail.com (Byju Govindan)
Date: Fri, 4 Apr 2008 10:15:23 -0400
Subject: [R-sig-ME] Fwd: Repeated measures_ Poisson modeling ?
In-Reply-To: <3c15314c0804040705y7a0c0dfardddc9d30a0918fa9@mail.gmail.com>
References: <3c15314c0804010706p4f6eb9c2i81e9683e46e0ff69@mail.gmail.com>
	<40e66e0b0804010723vcbde53fy5d29b911ffc91165@mail.gmail.com>
	<3c15314c0804040705y7a0c0dfardddc9d30a0918fa9@mail.gmail.com>
Message-ID: <3c15314c0804040715k8bc0c5ck8d6e08aed9de4efc@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080404/f887e263/attachment.pl>

From bates at stat.wisc.edu  Fri Apr  4 16:19:40 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 4 Apr 2008 09:19:40 -0500
Subject: [R-sig-ME] Fwd: R - specify estimated residual variance
In-Reply-To: <40e66e0b0804040538h5013ed7ds28742e23ca0c9062@mail.gmail.com>
References: <47F61B06.4090508@kuleuven-kortrijk.be>
	<40e66e0b0804040538h5013ed7ds28742e23ca0c9062@mail.gmail.com>
Message-ID: <40e66e0b0804040719i50b9d546k19eb483c403cd436@mail.gmail.com>

---------- Forwarded message ----------
From: Douglas Bates <bates at stat.wisc.edu>
Date: Fri, Apr 4, 2008 at 7:38 AM
Subject: Re: R - specify estimated residual variance
To: Kelly Wauters <Kelly.wauters at kuleuven-kortrijk.be>


On Fri, Apr 4, 2008 at 7:11 AM, Kelly Wauters
 <Kelly.wauters at kuleuven-kortrijk.be> wrote:
 > Dear Prof. dr. Bates,

 >  I want to use lmer to fit a glmm with a dichotomous dependent variable
 >  (family binomial - link logit). The scores on the lowest level follow a
 >  binomial distribution. This indicates that the variance of the lowest
 >  level is defined by the estimated residual variance multiplied by
 >  pi(1-pi). This means that the estimated residual variance has to be
 >  equal to 1. In SAS you can do this by means of the code

 >  proc glimmix data= dichotoom noclprint noitprint asycov ;
 >  class school id item;
 >  PARMS 0.34 1/HOLD=2;
 >  model scores=/ dist=binomial solution;
 >  random intercept/ subject=id;
 >  random _residual_;
 >  run;

 >  How can I translate the code into R code?

 > > dichloso$school<-as.factor(dichloso$school)
 > > dichloso$id<-as.factor(dichloso$id)
 > > dichloso$item<-as.factor(dichloso$item)

 Transforming those variables to factors is a good practice but not
 strictly necessary to fit the model shown below.


 > > model <- lmer(scores~1+(1|id), dichotoom,
family=binomial(link="logit"),...)

 >  I don't know how I can translate the code PARMS 0.34 1/HOLD=2; into R

>  code. Can you help me on this?

 I'm afraid I can't help you on this because I don't know what the SAS
 code does.  I don't use SAS myself.

 It is possible that there is no need to specify this parameter in R as
 having a constant value.  My guess, but this is just a guess, is that
 the distinction between holding that parameter constant at 1 and
 allowing it to vary is equivalent to using the binomial family or the
 quasibinomial family in lmer.

 May I send a copy of this reply to the
 R-SIG-Mixed-Models at r-project.org mailing list? ("SIG" == "Special
 Interest Group")? (I ask your permission to send the copy because I am
 quoting your original question.)   Some who subscribe to that mailing
 list may have experience with SAS PROC GLIMMIX and be able to describe
 the equivalent code for lmer.



From vlp1 at CDC.GOV  Fri Apr  4 16:39:48 2008
From: vlp1 at CDC.GOV (Parsons, Van L. (CDC/CCHIS/NCHS))
Date: Fri, 4 Apr 2008 10:39:48 -0400
Subject: [R-sig-ME] weights in lmer
In-Reply-To: <CB6AFE613082DD4FB037471AE7A1EDAF1A43E9@LTA3VS013.ees.hhs.gov>
References: <CB6AFE613082DD4FB037471AE7A1EDAF1A43E7@LTA3VS013.ees.hhs.gov>
	<CB6AFE613082DD4FB037471AE7A1EDAF1A43E9@LTA3VS013.ees.hhs.gov>
Message-ID: <CB6AFE613082DD4FB037471AE7A1EDAFC46E56@LTA3VS013.ees.hhs.gov>

 
Prof Bates,
  There is a problem with the "weights" option in lmer.
 I checked a run with lme4_0.999375-12 for a model

lmer(    Reaction ~ (1|Subject) , data=sleepstudy     )
Vs a weight=1 model 

   wt1 = rep(1, 180 )    
 lmer(    Reaction ~ (1|Subject) , data=sleepstudy ,weight= wt1    )  
 
and observed different random and fixed effects.
The old version lme4_0.99875-9 was OK.

This issue has come up in a previous thread, and I 
wondering on the status of a correction. 

Thanks,

Van

 



From HStevens at MUOhio.edu  Fri Apr  4 17:48:31 2008
From: HStevens at MUOhio.edu (Hank Stevens)
Date: Fri, 4 Apr 2008 11:48:31 -0400
Subject: [R-sig-ME] Fwd: same old question - lme4 and p-values
In-Reply-To: <40e66e0b0804040633k619803fayfd2e9b9b07b88b77@mail.gmail.com>
References: <28642179.2370001207304657364.JavaMail.nabble@isper.nabble.com>
	<40e66e0b0804040554m41e63d58l3a5825924696cf78@mail.gmail.com>
	<40e66e0b0804040633k619803fayfd2e9b9b07b88b77@mail.gmail.com>
Message-ID: <2A882A0D-B7AC-43CB-970C-F009D334DA3D@MUOhio.edu>

Google:
p-values lmer wiki

On Apr 4, 2008, at 9:33 AM, Douglas Bates wrote:

> ---------- Forwarded message ----------
> From: Douglas Bates <bates at stat.wisc.edu>
> Date: Fri, Apr 4, 2008 at 7:54 AM
> Subject: Re: same old question - lme4 and p-values
> To: andreas.nord at zooekol.lu.se
>
>
>
> On Fri, Apr 4, 2008 at 5:24 AM,  <andreas.nord at zooekol.lu.se> wrote:
>> Dear Prof. Bates,
>
>> I've recently switched to using R for my analyses, and I find the
> lme4 package to be extremely helpful. I have read your explanation
> (posted on the mailing list) of why you choose not to display
> p-values. Unfortunately, most of the journals I publish in require
> that I include p-values, which is why I have to find a way of
> calculating them from the lmer output. However, not being a trained
> statistician I have some difficulties following your recommendations
> given in the explanatory text. In other words, after having fitted my
> model, I am not at all sure on what to do in order to obtain p-values
> (or similar).
>
>> I am sorry to have to bother you with a question I know you have
> already answered many times, but perhaps you would be so kind as to
> give me some hints on how to proceed.
>
> I understand your situation.  Statisticians have created the "every
> question of scientific interest must be answered by a p-value" monster
> and now it turns on us.  Nevertheless I am reluctant to give advice on
> p-values in lme4 because apparently I don't know how to do it
> correctly.
>
> May I send a copy of this reply to the
> R-SIG-Mixed-Models at r-project.org mailing list? ("SIG" == "Special
> Interest Group")? (I ask your permission to send the copy because I am
> quoting your original question.)   Some who subscribe to that mailing
> list may have the courage to wade into this swamp and offer their
> advice.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



Dr. Hank Stevens, Associate Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/~stevenmh/
http://www.cas.muohio.edu/ecology
http://www.muohio.edu/botany/

"If the stars should appear one night in a thousand years, how would men
believe and adore." -Ralph Waldo Emerson, writer and philosopher  
(1803-1882)



From reinhold.kliegl at gmail.com  Sat Apr  5 12:10:51 2008
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Sat, 5 Apr 2008 12:10:51 +0200
Subject: [R-sig-ME] Fwd: same old question - lme4 and p-values
In-Reply-To: <2A882A0D-B7AC-43CB-970C-F009D334DA3D@MUOhio.edu>
References: <28642179.2370001207304657364.JavaMail.nabble@isper.nabble.com>
	<40e66e0b0804040554m41e63d58l3a5825924696cf78@mail.gmail.com>
	<40e66e0b0804040633k619803fayfd2e9b9b07b88b77@mail.gmail.com>
	<2A882A0D-B7AC-43CB-970C-F009D334DA3D@MUOhio.edu>
Message-ID: <aefe4d0a0804050310q1bd57ec6n8abf01a0e6e248d@mail.gmail.com>

Here is a section that worked in Kliegl, Risse, & Laubrock (2007, J
Exp Psychol:Human Perception and Performance, 33, 1250-1251).

"Analysis
     Inferential statistics are based on a linear mixed-effects model
(lme) specifying participants and items as crossed random effects.
This analysis takes into account differences between participants and
differences between items in a single sweep and has been shown to
suffer substantially less loss of statistical power in unbalanced
designs than traditional ANOVAs over participants (F1) and items (F2;
see Baayen, in press, Pinheiro & Bates, 2000; Quen? & van den Bergh,
2004, for simulations).
    We used the lmer program (lme4 package; Bates & Sarkar, 2006) in
the R system for statistical computing (R Development Core Team, 2006)
and report regression coefficients (b; absolute effect size in ms),
standard errors (SE), and p-values for an upper-bound n of denominator
degrees of freedom computed as n of observations minus n of fixed
effects. As these p-values are potentially anti-conservative, we
generated confidence intervals from the posterior distribution of
parameter estimates with Markov Chain Monte Carlo methods, using the
mcmcsamp program in the lme4 package with default specifications
(e.g., n=1000 samples; locally uniform priors for fixed effects;
locally non-informative priors for random effects). Both procedures
yielded the same results.
    Finally, we also computed post-hoc power statistics for the
preview and lexical status main effects and for the interaction effect
on first fixation durations (with effect sizes similar to those
reported earlier, e.g., Kliegl, 2007), and using lme estimates of
between-participant, between-item, and residual variances (Gelman &
Hill, in press). For the observed proportion of random loss of items,
power estimates based on 1000 simulations each were around .85 for
word n and n+2 and .59 for word n+1 (due to the higher skipping
rate)."  (page 1251)

Power statistics were included in response to a reviewer request. I am
not much in favor of post-hoc power statistics; but note that here
they are restricted to the use of estimates of random effects. For
reviewers, we also included traditional F1- and F2-ANOVA tables; they
are not part of the article. In other articles, it has also been
acceptable to report coefficients, their standard errors, and their
ratio, and to say that coefficients larger than 2 SE are interpreted
as significant (e.g., Kliegl, 2007, J Exp Psychol: General, 136,
530-537), that is, it is possible to leave out p-values completely.

Corrections and improvements of the above sentences are highly welcome
for future articles. In perspective, I think the p-value problem will
simply go away.

Best
Reinhold

PS: Would it be useful to have a site where peer-reviewed articles
using lme4 for statistical inference are listed and, possibly,
retrievable versions are provided?

On Fri, Apr 4, 2008 at 5:48 PM, Hank Stevens <HStevens at muohio.edu> wrote:
> Google:
>  p-values lmer wiki
>
>
>
>  On Apr 4, 2008, at 9:33 AM, Douglas Bates wrote:
>
>  > ---------- Forwarded message ----------
>  > From: Douglas Bates <bates at stat.wisc.edu>
>  > Date: Fri, Apr 4, 2008 at 7:54 AM
>  > Subject: Re: same old question - lme4 and p-values
>  > To: andreas.nord at zooekol.lu.se
>  >
>  >
>  >
>  > On Fri, Apr 4, 2008 at 5:24 AM,  <andreas.nord at zooekol.lu.se> wrote:
>  >> Dear Prof. Bates,
>  >
>  >> I've recently switched to using R for my analyses, and I find the
>  > lme4 package to be extremely helpful. I have read your explanation
>  > (posted on the mailing list) of why you choose not to display
>  > p-values. Unfortunately, most of the journals I publish in require
>  > that I include p-values, which is why I have to find a way of
>  > calculating them from the lmer output. However, not being a trained
>  > statistician I have some difficulties following your recommendations
>  > given in the explanatory text. In other words, after having fitted my
>  > model, I am not at all sure on what to do in order to obtain p-values
>  > (or similar).
>  >
>  >> I am sorry to have to bother you with a question I know you have
>  > already answered many times, but perhaps you would be so kind as to
>  > give me some hints on how to proceed.
>  >
>  > I understand your situation.  Statisticians have created the "every
>  > question of scientific interest must be answered by a p-value" monster
>  > and now it turns on us.  Nevertheless I am reluctant to give advice on
>  > p-values in lme4 because apparently I don't know how to do it
>  > correctly.
>  >
>  > May I send a copy of this reply to the
>  > R-SIG-Mixed-Models at r-project.org mailing list? ("SIG" == "Special
>  > Interest Group")? (I ask your permission to send the copy because I am
>  > quoting your original question.)   Some who subscribe to that mailing
>  > list may have the courage to wade into this swamp and offer their
>  > advice.
>  >
>  > _______________________________________________
>  > R-sig-mixed-models at r-project.org mailing list
>  > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
>  Dr. Hank Stevens, Associate Professor
>  338 Pearson Hall
>  Botany Department
>  Miami University
>  Oxford, OH 45056
>
>  Office: (513) 529-4206
>  Lab: (513) 529-4262
>  FAX: (513) 529-4243
>  http://www.cas.muohio.edu/~stevenmh/
>  http://www.cas.muohio.edu/ecology
>  http://www.muohio.edu/botany/
>
>  "If the stars should appear one night in a thousand years, how would men
>  believe and adore." -Ralph Waldo Emerson, writer and philosopher
>  (1803-1882)
>
>
>
>  _______________________________________________
>  R-sig-mixed-models at r-project.org mailing list
>  https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From baron at psych.upenn.edu  Sat Apr  5 13:21:19 2008
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Sat, 5 Apr 2008 07:21:19 -0400
Subject: [R-sig-ME] Fwd: same old question - lme4 and p-values
In-Reply-To: <aefe4d0a0804050310q1bd57ec6n8abf01a0e6e248d@mail.gmail.com>
References: <28642179.2370001207304657364.JavaMail.nabble@isper.nabble.com>
	<40e66e0b0804040554m41e63d58l3a5825924696cf78@mail.gmail.com>
	<40e66e0b0804040633k619803fayfd2e9b9b07b88b77@mail.gmail.com>
	<2A882A0D-B7AC-43CB-970C-F009D334DA3D@MUOhio.edu>
	<aefe4d0a0804050310q1bd57ec6n8abf01a0e6e248d@mail.gmail.com>
Message-ID: <20080405112119.GA22390@psych.upenn.edu>

On 04/05/08 12:10, Reinhold Kliegl wrote:
> Here is a section that worked in Kliegl, Risse, & Laubrock (2007, J
> Exp Psychol:Human Perception and Performance, 33, 1250-1251).

This is extremely helpful.

> In perspective, I think the p-value problem will
> simply go away.

I'm not sure what you mean here.  If you mean to replace them with
confidence intervals, I have no problem with that.  But, as a journal
editor, I am afraid that I will continue to insist on some sort of
evidence that effects are real.  This can be done in many ways.  But
too many authors submit articles in which the claimed effects can
result from random variation, either in subjects ("participants*") or
items, and they don't correctly reject such alternative explanations
of a difference in means.

I have noticed a kind of split among those who comment on this issue.
On the one side are those who are familiar with fields such as
epidemiology or economics (excluding experimental economics), where
the claim is often made that "the null hypothesis is always false
anyway, so why bother rejecting it?"  These are the ones interested in
effect sizes, variance accounted for, etc.  They are correct for this
kind of research, but there are other kinds of research.

On the other side, are those from (e.g.) experimental psychology,
where the name of the game is to design experiments that are so well
controlled that the null hypothesis will be true if the effect of
interest is absent.  As a member of this group, when I read people
from the first group, I find it very discouraging.  It is almost as if
they are saying that what I work so hard to try to do is impossible.

To get a little specific, although I found Gelman and Hill's book very
helpful on many points (and it does not deny the existence of people
like me), it is written largely for members of the first group.  By
contrast, Baayen's book is written for people like me, as is the
Baayen, Davidson, and Bates article, "Mixed effects modeling with
crossed random effects for subjects and items."

I'm afraid we do need significance tests, or confidence intervals, or
something.

Jon

* On "participants" vs. "subjects" see:
http://www.psychologicalscience.org/observer/getArticle.cfm?id=1549

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron
Editor: Judgment and Decision Making (http://journal.sjdm.org)



From reinhold.kliegl at gmail.com  Sat Apr  5 13:52:42 2008
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Sat, 5 Apr 2008 13:52:42 +0200
Subject: [R-sig-ME] Fwd: same old question - lme4 and p-values
In-Reply-To: <20080405112119.GA22390@psych.upenn.edu>
References: <28642179.2370001207304657364.JavaMail.nabble@isper.nabble.com>
	<40e66e0b0804040554m41e63d58l3a5825924696cf78@mail.gmail.com>
	<40e66e0b0804040633k619803fayfd2e9b9b07b88b77@mail.gmail.com>
	<2A882A0D-B7AC-43CB-970C-F009D334DA3D@MUOhio.edu>
	<aefe4d0a0804050310q1bd57ec6n8abf01a0e6e248d@mail.gmail.com>
	<20080405112119.GA22390@psych.upenn.edu>
Message-ID: <aefe4d0a0804050452m1ccf00a7g82e60f592b3c6a1c@mail.gmail.com>

 "If you mean to replace them with confidence intervals, I have no
problem with that."

That's what I mean or, perhaps, credibility intervals. Of course, I do
not want to do away with statistics but, in perspective, hope for an
increase in sophisticated application.

Reinhold

On Sat, Apr 5, 2008 at 1:21 PM, Jonathan Baron <baron at psych.upenn.edu> wrote:
> On 04/05/08 12:10, Reinhold Kliegl wrote:
>  > Here is a section that worked in Kliegl, Risse, & Laubrock (2007, J
>  > Exp Psychol:Human Perception and Performance, 33, 1250-1251).
>
>  This is extremely helpful.
>
>
>  > In perspective, I think the p-value problem will
>  > simply go away.
>
>  I'm not sure what you mean here.  If you mean to replace them with
>  confidence intervals, I have no problem with that.  But, as a journal
>  editor, I am afraid that I will continue to insist on some sort of
>  evidence that effects are real.  This can be done in many ways.  But
>  too many authors submit articles in which the claimed effects can
>  result from random variation, either in subjects ("participants*") or
>  items, and they don't correctly reject such alternative explanations
>  of a difference in means.
>
>  I have noticed a kind of split among those who comment on this issue.
>  On the one side are those who are familiar with fields such as
>  epidemiology or economics (excluding experimental economics), where
>  the claim is often made that "the null hypothesis is always false
>  anyway, so why bother rejecting it?"  These are the ones interested in
>  effect sizes, variance accounted for, etc.  They are correct for this
>  kind of research, but there are other kinds of research.
>
>  On the other side, are those from (e.g.) experimental psychology,
>  where the name of the game is to design experiments that are so well
>  controlled that the null hypothesis will be true if the effect of
>  interest is absent.  As a member of this group, when I read people
>  from the first group, I find it very discouraging.  It is almost as if
>  they are saying that what I work so hard to try to do is impossible.
>
>  To get a little specific, although I found Gelman and Hill's book very
>  helpful on many points (and it does not deny the existence of people
>  like me), it is written largely for members of the first group.  By
>  contrast, Baayen's book is written for people like me, as is the
>  Baayen, Davidson, and Bates article, "Mixed effects modeling with
>  crossed random effects for subjects and items."
>
>  I'm afraid we do need significance tests, or confidence intervals, or
>  something.
>
>  Jon
>
>  * On "participants" vs. "subjects" see:
>  http://www.psychologicalscience.org/observer/getArticle.cfm?id=1549
>
>  --
>  Jonathan Baron, Professor of Psychology, University of Pennsylvania
>  Home page: http://www.sas.upenn.edu/~baron
>  Editor: Judgment and Decision Making (http://journal.sjdm.org)
>



From maechler at stat.math.ethz.ch  Sat Apr  5 15:13:02 2008
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 5 Apr 2008 15:13:02 +0200
Subject: [R-sig-ME] Fwd: same old question - lme4 and p-values
In-Reply-To: <20080405112119.GA22390@psych.upenn.edu>
References: <28642179.2370001207304657364.JavaMail.nabble@isper.nabble.com>
	<40e66e0b0804040554m41e63d58l3a5825924696cf78@mail.gmail.com>
	<40e66e0b0804040633k619803fayfd2e9b9b07b88b77@mail.gmail.com>
	<2A882A0D-B7AC-43CB-970C-F009D334DA3D@MUOhio.edu>
	<aefe4d0a0804050310q1bd57ec6n8abf01a0e6e248d@mail.gmail.com>
	<20080405112119.GA22390@psych.upenn.edu>
Message-ID: <18423.31454.209907.1456@cmath-5.math.ethz.ch>

>>>>> "Jon" == Jonathan Baron <baron at psych.upenn.edu>
>>>>>     on Sat, 5 Apr 2008 07:21:19 -0400 writes:

    Jon> On 04/05/08 12:10, Reinhold Kliegl wrote:

[...]

    >> In perspective, I think the p-value problem will simply
    >> go away.

    Jon> I'm not sure what you mean here.  If you mean to
    Jon> replace them with confidence intervals, I have no
    Jon> problem with that.  But, as a journal editor, I am
    Jon> afraid that I will continue to insist on some sort of
    Jon> evidence that effects are real.  This can be done in
    Jon> many ways.  But too many authors submit articles in
    Jon> which the claimed effects can result from random
    Jon> variation, either in subjects ("participants*") or
    Jon> items, and they don't correctly reject such alternative
    Jon> explanations of a difference in means.

    Jon> I have noticed a kind of split among those who comment
    Jon> on this issue.  On the one side are those who are
    Jon> familiar with fields such as epidemiology or economics
    Jon> (excluding experimental economics), where the claim is
    Jon> often made that "the null hypothesis is always false
    Jon> anyway, so why bother rejecting it?"  These are the
    Jon> ones interested in effect sizes, variance accounted
    Jon> for, etc.  They are correct for this kind of research,
    Jon> but there are other kinds of research.

    Jon> On the other side, are those from (e.g.) experimental
    Jon> psychology, where the name of the game is to design
    Jon> experiments that are so well controlled that the null
    Jon> hypothesis will be true if the effect of interest is
    Jon> absent.  As a member of this group, when I read people
    Jon> from the first group, I find it very discouraging.  It
    Jon> is almost as if they are saying that what I work so
    Jon> hard to try to do is impossible.

    Jon> To get a little specific, although I found Gelman and
    Jon> Hill's book very helpful on many points (and it does
    Jon> not deny the existence of people like me), it is
    Jon> written largely for members of the first group.  By
    Jon> contrast, Baayen's book is written for people like me,
    Jon> as is the Baayen, Davidson, and Bates article, "Mixed
    Jon> effects modeling with crossed random effects for
    Jon> subjects and items."

    Jon> I'm afraid we do need significance tests, or confidence
    Jon> intervals, or something.

I agree even though I'm very deeply inside the camp of statisticians
who know that all models are wrong but some are useful, and
hence I do not "believe" any P-values (or exact confidence /
credibility intervals).

For those who need ``something like a P-value'' I've heard
yesterday Lorenz Gygax (also subscriber here) proposing
to report the "credibility of 0", possibly "2-sided", as a
pseudo-P value;, i.e. basically that would be
2 * k/n, for an MCMC sample b_1,b_2, ..., b_n 
k := {min k'; b_k' > 0}.
The reasoning would be the following:
Use the 1-to-1 correspondence between confidence intervals and
testing pretending that the credibility intervals are confidence
intervals, and consequently you just need to look at which
confidence level 0 will be at the exact border of the
credibility interval.

Yesterday after the talk, I found that a good idea.
Just now, it seems a bit doubtful, since under the null
hypothesis, I don't think such a pseudo P-value would be uniform
in [0,1].

Martin


    Jon> * On "participants" vs. "subjects" see:
    Jon> http://www.psychologicalscience.org/observer/getArticle.cfm?id=1549

    Jon> -- Jonathan Baron, Professor of Psychology, University
    Jon> of Pennsylvania Home page:
    Jon> http://www.sas.upenn.edu/~baron Editor: Judgment and
    Jon> Decision Making (http://journal.sjdm.org)

    Jon> _______________________________________________
    Jon> R-sig-mixed-models at r-project.org mailing list
    Jon> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From a.fugard at ed.ac.uk  Sat Apr  5 17:19:55 2008
From: a.fugard at ed.ac.uk (Andy Fugard)
Date: Sat, 05 Apr 2008 16:19:55 +0100
Subject: [R-sig-ME] Fwd: same old question - lme4 and p-values
In-Reply-To: <2A882A0D-B7AC-43CB-970C-F009D334DA3D@MUOhio.edu>
References: <28642179.2370001207304657364.JavaMail.nabble@isper.nabble.com>	<40e66e0b0804040554m41e63d58l3a5825924696cf78@mail.gmail.com>	<40e66e0b0804040633k619803fayfd2e9b9b07b88b77@mail.gmail.com>
	<2A882A0D-B7AC-43CB-970C-F009D334DA3D@MUOhio.edu>
Message-ID: <47F7989B.9010904@ed.ac.uk>

I made (more) sense of mixed effects models when I went back to standard 
regression and ANOVAs with the philosophy: Everything is a Comparison.

So for instance noting different ways of getting the magical numbers 
that result from doing regression:

---8<--------------------------------------------------------------------

 > m.0 = lm(Fertility ~ 1, data = swiss)
 > m.full = lm(Fertility ~ ., data = swiss)
 > summary(m.full)

...

Residual standard error: 7.17 on 41 degrees of freedom
Multiple R-squared: 0.707,      Adjusted R-squared: 0.671
F-statistic: 19.8 on 5 and 41 DF,  p-value: 5.59e-10
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

 > anova(m.0,m.full)
Analysis of Variance Table

Model 1: Fertility ~ 1
Model 2: Fertility ~ Agriculture + Examination + Education + Catholic +
     Infant.Mortality
   Res.Df  RSS Df Sum of Sq    F  Pr(>F)
1     46 7178
2     41 2105  5      5073 19.8 5.6e-10 ***
       ^^       ^           ^^^^^^^^^^^^
----------------------------------------------------------------->8------

Noting what happens when you compare nested models (incidentally, a 
confusing term when used the context of "multilevel" models):

---8<--------------------------------------------------------------------

 > m.full = lm(Fertility ~ . , data = swiss)
 > summary(m.full)

...

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)
(Intercept)       66.9152    10.7060    6.25  1.9e-07 ***
Agriculture       -0.1721     0.0703   -2.45   0.0187 *
Examination       -0.2580     0.2539   -1.02   0.3155
Education         -0.8709     0.1830   -4.76  2.4e-05 ***
Catholic           0.1041     0.0353    2.95   0.0052 **
Infant.Mortality   1.0770     0.3817    2.82   0.0073 **
                                                ^^^^^^
...

 >
 > m1 = update(full.model, ~. -Infant.Mortality)
 > anova(m.full,m1)
Analysis of Variance Table

Model 1: Fertility ~ Agriculture + Examination + Education + Catholic +
     Infant.Mortality
Model 2: Fertility ~ Agriculture + Examination + Education + Catholic
   Res.Df  RSS Df Sum of Sq    F Pr(>F)
1     41 2105
2     42 2514 -1      -409 7.96 0.0073 **
                                 ^^^^^^

----------------------------------------------------------------->8------

Playing around with this sort of thing made it a lot easier to 
understand why statisticians get annoyed (e.g., 
<http://www.stats.ox.ac.uk/pub/MASS3/Exegeses.pdf> for a good example) 
with us non-statisticians.

On a more practical note, the languageR package has an especially useful 
pvals.fnc function for when you really do need a test of whether a slope 
is significantly different to zero, e.g. when you've got a load of 
categorical predictors and want to see where the difference is.

Hope that wasn't too far off topic.

Cheers,

Andy



Hank Stevens wrote:
> Google:
> p-values lmer wiki
> 
> On Apr 4, 2008, at 9:33 AM, Douglas Bates wrote:
> 
>> ---------- Forwarded message ----------
>> From: Douglas Bates <bates at stat.wisc.edu>
>> Date: Fri, Apr 4, 2008 at 7:54 AM
>> Subject: Re: same old question - lme4 and p-values
>> To: andreas.nord at zooekol.lu.se
>>
>>
>>
>> On Fri, Apr 4, 2008 at 5:24 AM,  <andreas.nord at zooekol.lu.se> wrote:
>>> Dear Prof. Bates,
>>> I've recently switched to using R for my analyses, and I find the
>> lme4 package to be extremely helpful. I have read your explanation
>> (posted on the mailing list) of why you choose not to display
>> p-values. Unfortunately, most of the journals I publish in require
>> that I include p-values, which is why I have to find a way of
>> calculating them from the lmer output. However, not being a trained
>> statistician I have some difficulties following your recommendations
>> given in the explanatory text. In other words, after having fitted my
>> model, I am not at all sure on what to do in order to obtain p-values
>> (or similar).
>>
>>> I am sorry to have to bother you with a question I know you have
>> already answered many times, but perhaps you would be so kind as to
>> give me some hints on how to proceed.
>>
>> I understand your situation.  Statisticians have created the "every
>> question of scientific interest must be answered by a p-value" monster
>> and now it turns on us.  Nevertheless I am reluctant to give advice on
>> p-values in lme4 because apparently I don't know how to do it
>> correctly.
>>
>> May I send a copy of this reply to the
>> R-SIG-Mixed-Models at r-project.org mailing list? ("SIG" == "Special
>> Interest Group")? (I ask your permission to send the copy because I am
>> quoting your original question.)   Some who subscribe to that mailing
>> list may have the courage to wade into this swamp and offer their
>> advice.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 
> Dr. Hank Stevens, Associate Professor
> 338 Pearson Hall
> Botany Department
> Miami University
> Oxford, OH 45056
> 
> Office: (513) 529-4206
> Lab: (513) 529-4262
> FAX: (513) 529-4243
> http://www.cas.muohio.edu/~stevenmh/
> http://www.cas.muohio.edu/ecology
> http://www.muohio.edu/botany/
> 
> "If the stars should appear one night in a thousand years, how would men
> believe and adore." -Ralph Waldo Emerson, writer and philosopher  
> (1803-1882)
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 


-- 
Andy Fugard, Postgraduate Research Student
Psychology (Room F3), The University of Edinburgh,
   7 George Square, Edinburgh EH8 9JZ, UK
Mobile: +44 (0)78 123 87190   http://www.possibly.me.uk

The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From kushler at oakland.edu  Sat Apr  5 17:21:36 2008
From: kushler at oakland.edu (Robert Kushler)
Date: Sat, 05 Apr 2008 11:21:36 -0400
Subject: [R-sig-ME] Fwd: same old question - lme4 and p-values
In-Reply-To: <18423.31454.209907.1456@cmath-5.math.ethz.ch>
References: <28642179.2370001207304657364.JavaMail.nabble@isper.nabble.com>	<40e66e0b0804040554m41e63d58l3a5825924696cf78@mail.gmail.com>	<40e66e0b0804040633k619803fayfd2e9b9b07b88b77@mail.gmail.com>	<2A882A0D-B7AC-43CB-970C-F009D334DA3D@MUOhio.edu>	<aefe4d0a0804050310q1bd57ec6n8abf01a0e6e248d@mail.gmail.com>	<20080405112119.GA22390@psych.upenn.edu>
	<18423.31454.209907.1456@cmath-5.math.ethz.ch>
Message-ID: <47F79900.1000108@oakland.edu>


For a one-sided situation, the posterior probability that
the parameter is on the wrong side of zero makes a lot of
sense.  (Ironically, the classic mistake of interpreting
a p-value as a probability statement about the parameter
is correct here!)

The two-sided case seems more challenging.  The posterior
probability content of an "indifference zone" around zero
can be computed, but it's easy to play games by carefully
picking the width of the zone.  A graph of the probability
against the width of the zone could be a useful exploratory
tool, but would take up a lot of space if used in reporting
results.

Regards,   Rob Kushler



Martin Maechler wrote:
>>>>>> "Jon" == Jonathan Baron <baron at psych.upenn.edu>
>>>>>>     on Sat, 5 Apr 2008 07:21:19 -0400 writes:
> 
>     Jon> On 04/05/08 12:10, Reinhold Kliegl wrote:
> 
> [...]
> 
>     >> In perspective, I think the p-value problem will simply
>     >> go away.
> 
>     Jon> I'm not sure what you mean here.  If you mean to
>     Jon> replace them with confidence intervals, I have no
>     Jon> problem with that.  But, as a journal editor, I am
>     Jon> afraid that I will continue to insist on some sort of
>     Jon> evidence that effects are real.  This can be done in
>     Jon> many ways.  But too many authors submit articles in
>     Jon> which the claimed effects can result from random
>     Jon> variation, either in subjects ("participants*") or
>     Jon> items, and they don't correctly reject such alternative
>     Jon> explanations of a difference in means.
> 
>     Jon> I have noticed a kind of split among those who comment
>     Jon> on this issue.  On the one side are those who are
>     Jon> familiar with fields such as epidemiology or economics
>     Jon> (excluding experimental economics), where the claim is
>     Jon> often made that "the null hypothesis is always false
>     Jon> anyway, so why bother rejecting it?"  These are the
>     Jon> ones interested in effect sizes, variance accounted
>     Jon> for, etc.  They are correct for this kind of research,
>     Jon> but there are other kinds of research.
> 
>     Jon> On the other side, are those from (e.g.) experimental
>     Jon> psychology, where the name of the game is to design
>     Jon> experiments that are so well controlled that the null
>     Jon> hypothesis will be true if the effect of interest is
>     Jon> absent.  As a member of this group, when I read people
>     Jon> from the first group, I find it very discouraging.  It
>     Jon> is almost as if they are saying that what I work so
>     Jon> hard to try to do is impossible.
> 
>     Jon> To get a little specific, although I found Gelman and
>     Jon> Hill's book very helpful on many points (and it does
>     Jon> not deny the existence of people like me), it is
>     Jon> written largely for members of the first group.  By
>     Jon> contrast, Baayen's book is written for people like me,
>     Jon> as is the Baayen, Davidson, and Bates article, "Mixed
>     Jon> effects modeling with crossed random effects for
>     Jon> subjects and items."
> 
>     Jon> I'm afraid we do need significance tests, or confidence
>     Jon> intervals, or something.
> 
> I agree even though I'm very deeply inside the camp of statisticians
> who know that all models are wrong but some are useful, and
> hence I do not "believe" any P-values (or exact confidence /
> credibility intervals).
> 
> For those who need ``something like a P-value'' I've heard
> yesterday Lorenz Gygax (also subscriber here) proposing
> to report the "credibility of 0", possibly "2-sided", as a
> pseudo-P value;, i.e. basically that would be
> 2 * k/n, for an MCMC sample b_1,b_2, ..., b_n 
> k := {min k'; b_k' > 0}.
> The reasoning would be the following:
> Use the 1-to-1 correspondence between confidence intervals and
> testing pretending that the credibility intervals are confidence
> intervals, and consequently you just need to look at which
> confidence level 0 will be at the exact border of the
> credibility interval.
> 
> Yesterday after the talk, I found that a good idea.
> Just now, it seems a bit doubtful, since under the null
> hypothesis, I don't think such a pseudo P-value would be uniform
> in [0,1].
> 
> Martin
> 
> 
>     Jon> * On "participants" vs. "subjects" see:
>     Jon> http://www.psychologicalscience.org/observer/getArticle.cfm?id=1549
> 
>     Jon> -- Jonathan Baron, Professor of Psychology, University
>     Jon> of Pennsylvania Home page:
>     Jon> http://www.sas.upenn.edu/~baron Editor: Judgment and
>     Jon> Decision Making (http://journal.sjdm.org)
> 
>     Jon> _______________________________________________
>     Jon> R-sig-mixed-models at r-project.org mailing list
>     Jon> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From kushler at oakland.edu  Sat Apr  5 17:50:18 2008
From: kushler at oakland.edu (Robert Kushler)
Date: Sat, 05 Apr 2008 11:50:18 -0400
Subject: [R-sig-ME] Fwd: same old question - lme4 and p-values
In-Reply-To: <47F7989B.9010904@ed.ac.uk>
References: <28642179.2370001207304657364.JavaMail.nabble@isper.nabble.com>	<40e66e0b0804040554m41e63d58l3a5825924696cf78@mail.gmail.com>	<40e66e0b0804040633k619803fayfd2e9b9b07b88b77@mail.gmail.com>	<2A882A0D-B7AC-43CB-970C-F009D334DA3D@MUOhio.edu>
	<47F7989B.9010904@ed.ac.uk>
Message-ID: <47F79FBA.4040006@oakland.edu>


Unfortunately, the latest changes to lme4 seem to have broken languageR.
Many of the plotting functions are now built in to lme4, but the p-value
obsessed among us would love to have the other functions in languageR
back in action.

Harold, any plans for an update?  Will Doug let you do it?  :-)

Rob Kushler


Andy Fugard wrote:
> I made (more) sense of mixed effects models when I went back to standard 
> regression and ANOVAs with the philosophy: Everything is a Comparison.
> 
> So for instance noting different ways of getting the magical numbers 
> that result from doing regression:
> 
> ---8<--------------------------------------------------------------------
> 
>  > m.0 = lm(Fertility ~ 1, data = swiss)
>  > m.full = lm(Fertility ~ ., data = swiss)
>  > summary(m.full)
> 
> ...
> 
> Residual standard error: 7.17 on 41 degrees of freedom
> Multiple R-squared: 0.707,      Adjusted R-squared: 0.671
> F-statistic: 19.8 on 5 and 41 DF,  p-value: 5.59e-10
>               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
> 
>  > anova(m.0,m.full)
> Analysis of Variance Table
> 
> Model 1: Fertility ~ 1
> Model 2: Fertility ~ Agriculture + Examination + Education + Catholic +
>      Infant.Mortality
>    Res.Df  RSS Df Sum of Sq    F  Pr(>F)
> 1     46 7178
> 2     41 2105  5      5073 19.8 5.6e-10 ***
>        ^^       ^           ^^^^^^^^^^^^
> ----------------------------------------------------------------->8------
> 
> Noting what happens when you compare nested models (incidentally, a 
> confusing term when used the context of "multilevel" models):
> 
> ---8<--------------------------------------------------------------------
> 
>  > m.full = lm(Fertility ~ . , data = swiss)
>  > summary(m.full)
> 
> ...
> 
> Coefficients:
>                   Estimate Std. Error t value Pr(>|t|)
> (Intercept)       66.9152    10.7060    6.25  1.9e-07 ***
> Agriculture       -0.1721     0.0703   -2.45   0.0187 *
> Examination       -0.2580     0.2539   -1.02   0.3155
> Education         -0.8709     0.1830   -4.76  2.4e-05 ***
> Catholic           0.1041     0.0353    2.95   0.0052 **
> Infant.Mortality   1.0770     0.3817    2.82   0.0073 **
>                                                 ^^^^^^
> ...
> 
>  >
>  > m1 = update(full.model, ~. -Infant.Mortality)
>  > anova(m.full,m1)
> Analysis of Variance Table
> 
> Model 1: Fertility ~ Agriculture + Examination + Education + Catholic +
>      Infant.Mortality
> Model 2: Fertility ~ Agriculture + Examination + Education + Catholic
>    Res.Df  RSS Df Sum of Sq    F Pr(>F)
> 1     41 2105
> 2     42 2514 -1      -409 7.96 0.0073 **
>                                  ^^^^^^
> 
> ----------------------------------------------------------------->8------
> 
> Playing around with this sort of thing made it a lot easier to 
> understand why statisticians get annoyed (e.g., 
> <http://www.stats.ox.ac.uk/pub/MASS3/Exegeses.pdf> for a good example) 
> with us non-statisticians.
> 
> On a more practical note, the languageR package has an especially useful 
> pvals.fnc function for when you really do need a test of whether a slope 
> is significantly different to zero, e.g. when you've got a load of 
> categorical predictors and want to see where the difference is.
> 
> Hope that wasn't too far off topic.
> 
> Cheers,
> 
> Andy
> 
> 
> 
> Hank Stevens wrote:
>> Google:
>> p-values lmer wiki
>>
>> On Apr 4, 2008, at 9:33 AM, Douglas Bates wrote:
>>
>>> ---------- Forwarded message ----------
>>> From: Douglas Bates <bates at stat.wisc.edu>
>>> Date: Fri, Apr 4, 2008 at 7:54 AM
>>> Subject: Re: same old question - lme4 and p-values
>>> To: andreas.nord at zooekol.lu.se
>>>
>>>
>>>
>>> On Fri, Apr 4, 2008 at 5:24 AM,  <andreas.nord at zooekol.lu.se> wrote:
>>>> Dear Prof. Bates,
>>>> I've recently switched to using R for my analyses, and I find the
>>> lme4 package to be extremely helpful. I have read your explanation
>>> (posted on the mailing list) of why you choose not to display
>>> p-values. Unfortunately, most of the journals I publish in require
>>> that I include p-values, which is why I have to find a way of
>>> calculating them from the lmer output. However, not being a trained
>>> statistician I have some difficulties following your recommendations
>>> given in the explanatory text. In other words, after having fitted my
>>> model, I am not at all sure on what to do in order to obtain p-values
>>> (or similar).
>>>
>>>> I am sorry to have to bother you with a question I know you have
>>> already answered many times, but perhaps you would be so kind as to
>>> give me some hints on how to proceed.
>>>
>>> I understand your situation.  Statisticians have created the "every
>>> question of scientific interest must be answered by a p-value" monster
>>> and now it turns on us.  Nevertheless I am reluctant to give advice on
>>> p-values in lme4 because apparently I don't know how to do it
>>> correctly.
>>>
>>> May I send a copy of this reply to the
>>> R-SIG-Mixed-Models at r-project.org mailing list? ("SIG" == "Special
>>> Interest Group")? (I ask your permission to send the copy because I am
>>> quoting your original question.)   Some who subscribe to that mailing
>>> list may have the courage to wade into this swamp and offer their
>>> advice.
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>> Dr. Hank Stevens, Associate Professor
>> 338 Pearson Hall
>> Botany Department
>> Miami University
>> Oxford, OH 45056
>>
>> Office: (513) 529-4206
>> Lab: (513) 529-4262
>> FAX: (513) 529-4243
>> http://www.cas.muohio.edu/~stevenmh/
>> http://www.cas.muohio.edu/ecology
>> http://www.muohio.edu/botany/
>>
>> "If the stars should appear one night in a thousand years, how would men
>> believe and adore." -Ralph Waldo Emerson, writer and philosopher  
>> (1803-1882)
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
>



From vasishth.shravan at gmail.com  Sat Apr  5 18:52:14 2008
From: vasishth.shravan at gmail.com (S Vasishth)
Date: Sat, 5 Apr 2008 18:52:14 +0200
Subject: [R-sig-ME] Fwd: same old question - lme4 and p-values
Message-ID: <fafe4cec0804050952u7c46b4c2haeb3eccd1da8e0bb@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080405/be62cf54/attachment.pl>

From vasishth.shravan at gmail.com  Sat Apr  5 21:12:50 2008
From: vasishth.shravan at gmail.com (S Vasishth)
Date: Sat, 5 Apr 2008 21:12:50 +0200
Subject: [R-sig-ME] Fwd: same old question - lme4 and p-values
In-Reply-To: <fafe4cec0804050952u7c46b4c2haeb3eccd1da8e0bb@mail.gmail.com>
References: <fafe4cec0804050952u7c46b4c2haeb3eccd1da8e0bb@mail.gmail.com>
Message-ID: <fafe4cec0804051212o76c410dfn7de547fab6c4d803@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080405/474a8972/attachment.pl>

From A.Robinson at ms.unimelb.edu.au  Sat Apr  5 22:40:48 2008
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Sun, 6 Apr 2008 06:40:48 +1000
Subject: [R-sig-ME] Fwd: same old question - lme4 and p-values
In-Reply-To: <18423.31454.209907.1456@cmath-5.math.ethz.ch>
References: <28642179.2370001207304657364.JavaMail.nabble@isper.nabble.com>
	<40e66e0b0804040554m41e63d58l3a5825924696cf78@mail.gmail.com>
	<40e66e0b0804040633k619803fayfd2e9b9b07b88b77@mail.gmail.com>
	<2A882A0D-B7AC-43CB-970C-F009D334DA3D@MUOhio.edu>
	<aefe4d0a0804050310q1bd57ec6n8abf01a0e6e248d@mail.gmail.com>
	<20080405112119.GA22390@psych.upenn.edu>
	<18423.31454.209907.1456@cmath-5.math.ethz.ch>
Message-ID: <20080405204048.GA1257@ms.unimelb.edu.au>

On Sat, Apr 05, 2008 at 03:13:02PM +0200, Martin Maechler wrote:
> >>>>> "Jon" == Jonathan Baron <baron at psych.upenn.edu>
> >>>>>     on Sat, 5 Apr 2008 07:21:19 -0400 writes:
> 
>     Jon> On 04/05/08 12:10, Reinhold Kliegl wrote:
> 
> [...]
> 
>     >> In perspective, I think the p-value problem will simply
>     >> go away.
>
> [...]
> 
>     Jon> I'm afraid we do need significance tests, or confidence
>     Jon> intervals, or something.
> 
> I agree even though I'm very deeply inside the camp of statisticians
> who know that all models are wrong but some are useful, and
> hence I do not "believe" any P-values (or exact confidence /
> credibility intervals).
> 
> For those who need ``something like a P-value'' I've heard
> yesterday Lorenz Gygax (also subscriber here) proposing
> to report the "credibility of 0", possibly "2-sided", as a
> pseudo-P value;, i.e. basically that would be
> 2 * k/n, for an MCMC sample b_1,b_2, ..., b_n 
> k := {min k'; b_k' > 0}.
> The reasoning would be the following:
> Use the 1-to-1 correspondence between confidence intervals and
> testing pretending that the credibility intervals are confidence
> intervals, and consequently you just need to look at which
> confidence level 0 will be at the exact border of the
> credibility interval.
> 
> Yesterday after the talk, I found that a good idea.
> Just now, it seems a bit doubtful, since under the null
> hypothesis, I don't think such a pseudo P-value would be uniform
> in [0,1].

Is that because the credible intervals are not confidence intervals,
or for some other reason?  

Andrew
 
> Martin

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From john.maindonald at anu.edu.au  Sun Apr  6 03:37:16 2008
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Sun, 6 Apr 2008 11:37:16 +1000
Subject: [R-sig-ME] Fwd: same old question - lme4 and p-values
In-Reply-To: <18423.31454.209907.1456@cmath-5.math.ethz.ch>
References: <28642179.2370001207304657364.JavaMail.nabble@isper.nabble.com>
	<40e66e0b0804040554m41e63d58l3a5825924696cf78@mail.gmail.com>
	<40e66e0b0804040633k619803fayfd2e9b9b07b88b77@mail.gmail.com>
	<2A882A0D-B7AC-43CB-970C-F009D334DA3D@MUOhio.edu>
	<aefe4d0a0804050310q1bd57ec6n8abf01a0e6e248d@mail.gmail.com>
	<20080405112119.GA22390@psych.upenn.edu>
	<18423.31454.209907.1456@cmath-5.math.ethz.ch>
Message-ID: <33C9BCEB-6C3A-4CD4-8FE4-E4CEE240A2F5@anu.edu.au>

I agree with Lorenz Gygax.  I'll come back to p-values below.

Confidence intervals (CIs) make, for me, a lot more sense than
p-values. The reality, though, is that users will interpret CIs as
some kind of probability statement.  For all practical purposes,
a CI is just the Bayesian credible interval that one gets with
some suitable "non-informative prior".  Why not then be specific
about the prior, and go with the Bayesian credible interval?
(There is an issue whether such a prior can always be found.
Am right in judging this no practical consequence?)

There are cases where the prior is informative in a sense that
breaks the nexus between the CI and a realistic Bayesian
credible interval.  A similar issue arises for a p-value; the
probability of the evidence given innocence (or freedom from
some rare disease)  (this is H0) is dramatically different from
the probability of innocence given the evidence, and it may
be a difference between 1/100000 and 1/2.  Where the
Bayesian credible interval and the CI are dramatically different,
a p-value or CI can only mislead.  In the way that p-values are
commonly taught, it may take considerable strength of will to
avoid confusion between P(A | H0) and (P(H0 | A)!

For intervals for variances, the prior can matter a lot, if a
smallish number of independent pieces of information is used
to  estimate the variance and/or those pieces of information
have widely varying weights.  I guess that emphasizes how
insecure inference about variances can be.  It is much worse
than the common forms of CI indicate.

If one is to take abs(t) > 2 as indicating significance, this is
under iid Normal assumptions a p-value of 0.1 for 5df, and 0.18
for 2 degrees of freedom.  One has to ask members of the
relevant scientific community whether they are comfortable
with that, given also that those p-values are likely to be more
than otherwise suspect because of the small number of
degrees of freedom.  Or are we discussing experiments where
we always have at least 10 degrees of freedom?  If not, and
there is an insistence on making claims of "significance",
maybe we want abs(t) > 2.5 or abs(t) > 3.

I do not see any cogent reason to be concerned that the
distribution of the Bayesian p-value may, under H0, be far
from uniform on (0,1).  This, if it is an issue, is an especial issue
for intervals for variances.

Why not then, for models fitted using lmer, a Bayesian HPD
interval, given that Douglas has made it so easy to calculate
these? This seems to me more than otherwise pertinent if the
emphasis is on effect size.

None of these various measures is more than a very crude
summary of what has been achieved.  Maybe plots of posterior
density estimates might be given for key parameters, ideally
with some indication of sensitivity to the prior (this would need
more than mcmcsamp()).  In any case, publish the data, so that
the sceptical reader can make his/her own checks, and/or use
it in the design of future experiments, and/or so that it can be
used as a teaching resource.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


On 6 Apr 2008, at 12:13 AM, Martin Maechler wrote:

>>>>>> "Jon" == Jonathan Baron <baron at psych.upenn.edu>
>>>>>>   on Sat, 5 Apr 2008 07:21:19 -0400 writes:
>
>   Jon> On 04/05/08 12:10, Reinhold Kliegl wrote:
>
> [...]
>
>>> In perspective, I think the p-value problem will simply
>>> go away.
>
>   Jon> I'm not sure what you mean here.  If you mean to
>   Jon> replace them with confidence intervals, I have no
>   Jon> problem with that.  But, as a journal editor, I am
>   Jon> afraid that I will continue to insist on some sort of
>   Jon> evidence that effects are real.  This can be done in
>   Jon> many ways.  But too many authors submit articles in
>   Jon> which the claimed effects can result from random
>   Jon> variation, either in subjects ("participants*") or
>   Jon> items, and they don't correctly reject such alternative
>   Jon> explanations of a difference in means.
>
>   Jon> I have noticed a kind of split among those who comment
>   Jon> on this issue.  On the one side are those who are
>   Jon> familiar with fields such as epidemiology or economics
>   Jon> (excluding experimental economics), where the claim is
>   Jon> often made that "the null hypothesis is always false
>   Jon> anyway, so why bother rejecting it?"  These are the
>   Jon> ones interested in effect sizes, variance accounted
>   Jon> for, etc.  They are correct for this kind of research,
>   Jon> but there are other kinds of research.
>
>   Jon> On the other side, are those from (e.g.) experimental
>   Jon> psychology, where the name of the game is to design
>   Jon> experiments that are so well controlled that the null
>   Jon> hypothesis will be true if the effect of interest is
>   Jon> absent.  As a member of this group, when I read people
>   Jon> from the first group, I find it very discouraging.  It
>   Jon> is almost as if they are saying that what I work so
>   Jon> hard to try to do is impossible.
>
>   Jon> To get a little specific, although I found Gelman and
>   Jon> Hill's book very helpful on many points (and it does
>   Jon> not deny the existence of people like me), it is
>   Jon> written largely for members of the first group.  By
>   Jon> contrast, Baayen's book is written for people like me,
>   Jon> as is the Baayen, Davidson, and Bates article, "Mixed
>   Jon> effects modeling with crossed random effects for
>   Jon> subjects and items."
>
>   Jon> I'm afraid we do need significance tests, or confidence
>   Jon> intervals, or something.
>
> I agree even though I'm very deeply inside the camp of statisticians
> who know that all models are wrong but some are useful, and
> hence I do not "believe" any P-values (or exact confidence /
> credibility intervals).
>
> For those who need ``something like a P-value'' I've heard
> yesterday Lorenz Gygax (also subscriber here) proposing
> to report the "credibility of 0", possibly "2-sided", as a
> pseudo-P value;, i.e. basically that would be
> 2 * k/n, for an MCMC sample b_1,b_2, ..., b_n
> k := {min k'; b_k' > 0}.
> The reasoning would be the following:
> Use the 1-to-1 correspondence between confidence intervals and
> testing pretending that the credibility intervals are confidence
> intervals, and consequently you just need to look at which
> confidence level 0 will be at the exact border of the
> credibility interval.
>
> Yesterday after the talk, I found that a good idea.
> Just now, it seems a bit doubtful, since under the null
> hypothesis, I don't think such a pseudo P-value would be uniform
> in [0,1].
>
> Martin
>
>
>   Jon> * On "participants" vs. "subjects" see:
>   Jon> http://www.psychologicalscience.org/observer/getArticle.cfm?id=1549
>
>   Jon> -- Jonathan Baron, Professor of Psychology, University
>   Jon> of Pennsylvania Home page:
>   Jon> http://www.sas.upenn.edu/~baron Editor: Judgment and
>   Jon> Decision Making (http://journal.sjdm.org)
>
>   Jon> _______________________________________________
>   Jon> R-sig-mixed-models at r-project.org mailing list
>   Jon> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From kjbeath at kagi.com  Sun Apr  6 05:14:18 2008
From: kjbeath at kagi.com (Ken Beath)
Date: Sun, 6 Apr 2008 13:14:18 +1000
Subject: [R-sig-ME] random effects specification
In-Reply-To: <87ve2xydmh.fsf@patagonia.sebmags.homelinux.org>
References: <87abkak6qa.fsf@patagonia.sebmags.homelinux.org>
	<40e66e0b0804031532q12880b01mcba6173fc3e32c10@mail.gmail.com>
	<878wzuzf94.fsf@patagonia.sebmags.homelinux.org>
	<40e66e0b0804040517w3602b3dch6e6d5c7d53f33eb@mail.gmail.com>
	<87ve2xydmh.fsf@patagonia.sebmags.homelinux.org>
Message-ID: <75A3A990-0E70-4BDB-A44D-2BA011ADEA8C@kagi.com>

On 05/04/2008, at 12:05 AM, Sebastian P. Luque wrote:
> On Fri, 4 Apr 2008 07:17:36 -0500,
> "Douglas Bates" <bates at stat.wisc.edu> wrote:
>
> [...]
>
>> I'm not sure that I understand what you mean by "treatment being
>> nested within community".  Does this mean that there are really 8
>> different treatments because treatment 1 in community A is different
>> from treatment 1 in community B?  If so, then it would make sense to
>> me to simply create a new factor that is the interaction of treatment
>> and community.
>
> I was not employing the term "nested" properly.  The number of levels
> for both community and treatment are 2 and 4, respectively, just as in
> the example.  The same 4 treatments were used in both communties, so  
> in
> fact, treatment is crossed with community, not nested.  However,
> subjects are nested within communities because each subject belongs to
> one community only, yet received all 4 treatments.  Sorry for this
> confusion.
>

Once they are considered fixed effects, concepts of crossing and  
nesting are irrelevant. They are simply covariates. So a model of the  
form n ~ treatment + community +(1|id) or if the treatment effect is  
allowed to vary between communities n ~ treatment *community +(1|id)  
is appropriate. The main problem is your subject id are not unique.  
You will need to define a new id. The easiest way is to add a  
different large number to id depending on community.


>
>> Perhaps I am approaching the community factor incorrectly.  In your
>> data there are two communities so, even if it would be reasonable to
>> model community effects as random effects, that would be difficult.
>> With only two levels I think it is best modeled as a fixed effect,
>> which would mean that questions about treatment and community are
>> related to the fixed effects.
>
> Could you please show a formula for the case where each individual is
> seen at both communities (community and treatment still being fixed)?
> This would help me understand the syntax better.
>

Same model as previous, provided a subject only receives a treatment  
once. If a subject receives the same treatment more than once then  
there needs to be a random effect that models the correlation between  
repeated measurements of the same treatment, so the model is  
y~treatment+community+(1|id/treatment) One problem that may have  
occurred in your original attempts is that id and treatment need to be  
factors.

Ken

> Thank you so much for your help.
>
>
> -- 
> Seb
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From marshj02 at student.uwa.edu.au  Sun Apr  6 12:18:14 2008
From: marshj02 at student.uwa.edu.au (Julie Marsh)
Date: Sun, 06 Apr 2008 18:18:14 +0800
Subject: [R-sig-ME] Modelling growth data: time polynomials as random effects
Message-ID: <20080406181814.y388axpydb4k40c4@webmail-5.ucs.uwa.edu.au>


Dear LMER Experts,

I am trying to model some growth data based on multiple ultrasound  
measurements taken across the time course (in days) of each pregnancy.  
The vast majority of subjects have 4+ measurements.  Everything seems  
good up to:

> model.ac1 <- lmer(y.ac ~ TIME + I(TIME^2) + I(TIME^3) +  
> (TIME|STUDYNO), data=s.workdat, method="ML", na.action=na.omit)

> summary(model.ac1)
Linear mixed-effects model fit by maximum likelihood
Formula: y.ac ~ TIME + I(TIME^2) + I(TIME^3) + (TIME | STUDYNO)
    Data: s.workdat
    AIC   BIC logLik MLdeviance REMLdeviance
  -5051 -5004   2532      -5065        -4978
Random effects:
  Groups   Name        Variance   Std.Dev.  Corr
  STUDYNO  (Intercept) 6.3577e-02 0.2521444
           TIME        1.7435e-06 0.0013204 -0.828
  Residual             1.3597e-02 0.1166055
number of obs: 6066, groups: STUDYNO, 1289

Fixed effects:
               Estimate Std. Error t value
(Intercept)  1.309e+00  1.313e-01   9.970
TIME         5.825e-02  2.160e-03  26.963
I(TIME^2)   -1.113e-04  1.144e-05  -9.723
I(TIME^3)    7.197e-08  1.957e-08   3.678

Correlation of Fixed Effects:
           (Intr) TIME   I(TIME^2
TIME      -0.996
I(TIME^2)  0.988 -0.997
I(TIME^3) -0.976  0.991 -0.998


However as the slope consists of the polynomial combination (TIME +  
TIME^2 + TIME^3) intuitively it would seem correct to include these  
polynomial terms as  random effects. However, everything goes  
pair-shaped when I try:

> test.ac3 <- lmer(y.ac ~ TIME + I(TIME^2) + I(TIME^3) +  
> (TIME+I(TIME^2)+I(TIME^3)|STUDYNO), data=s.workdat, method="ML",  
> na.action=na.omit)

Warning messages:
1: In .local(x, ..., value) :
   Estimated variance-covariance for factor ?STUDYNO? is singular

2: In .local(x, ..., value) :
   nlminb returned message false convergence (8)


I am assuming that this is due to the strong correlations between the  
polynomials of TIME. I also performed this analysis on the subset of  
subjects with 5 or greater ultrasound measurements (in desperation!  
n=1024) and obtained the same error message.

My dilemma is explaining why TIME has both a fixed and random  
component, whereas TIME^2 and TIME^3 only have a fixed component.  I  
suspect I am missing something fundamental !!!

I have also had some fun fitting different AR structures but decided  
to strip back the model to the basic correlation structure for this  
question. Any help would be very much appreciated.


kindest regards,  julie marsh

PhD Student
Centre for Genetic Epidemiology
University of Western Autsralia
email: marshj02 at student.uwa.edu.au



From reinhold.kliegl at gmail.com  Sun Apr  6 12:51:24 2008
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Sun, 6 Apr 2008 12:51:24 +0200
Subject: [R-sig-ME] Modelling growth data: time polynomials as random
	effects
In-Reply-To: <20080406181814.y388axpydb4k40c4@webmail-5.ucs.uwa.edu.au>
References: <20080406181814.y388axpydb4k40c4@webmail-5.ucs.uwa.edu.au>
Message-ID: <aefe4d0a0804060351t56b79841g23547769d1bb68b2@mail.gmail.com>

You may want to center "TIME" prior to running lmer. Probably, it
probably better to use "poly(TIME, 3)".

For example, it works here:
> (fm1 <- lmer(Reaction ~ poly(Days,2) + (poly(Days,2)|Subject), sleepstudy))
Linear mixed model fit by REML
Formula: Reaction ~ poly(Days, 2) + (poly(Days, 2) | Subject)
   Data: sleepstudy
  AIC  BIC logLik deviance REMLdev
 1733 1765 -856.4     1738    1713
Random effects:
 Groups   Name           Variance Std.Dev. Corr
          (Intercept)     1422.41  37.715
          poly(Days, 2)1 54543.55 233.546   0.732
          poly(Days, 2)2 20260.08 142.338  -0.140 -0.025
 Residual                  518.16  22.763
Number of obs: 180, groups: Subject, 18

Fixed effects:
               Estimate Std. Error t value
(Intercept)      298.51       9.05   32.98
poly(Days, 2)1   403.36      59.57    6.77
poly(Days, 2)2    32.86      40.54    0.81

Correlation of Fixed Effects:
            (Intr) p(D,2)1
ply(Dys,2)1  0.665
ply(Dys,2)2 -0.114 -0.019

On a practical side, it could also be that there simple is too little
variance between subjects for higher-order TIME effects.

Reinhold

On Sun, Apr 6, 2008 at 12:18 PM, Julie Marsh
<marshj02 at student.uwa.edu.au> wrote:
>
>  Dear LMER Experts,
>
>  I am trying to model some growth data based on multiple ultrasound
>  measurements taken across the time course (in days) of each pregnancy.
>  The vast majority of subjects have 4+ measurements.  Everything seems
>  good up to:
>
>  > model.ac1 <- lmer(y.ac ~ TIME + I(TIME^2) + I(TIME^3) +
>  > (TIME|STUDYNO), data=s.workdat, method="ML", na.action=na.omit)
>
>  > summary(model.ac1)
>  Linear mixed-effects model fit by maximum likelihood
>  Formula: y.ac ~ TIME + I(TIME^2) + I(TIME^3) + (TIME | STUDYNO)
>     Data: s.workdat
>     AIC   BIC logLik MLdeviance REMLdeviance
>   -5051 -5004   2532      -5065        -4978
>  Random effects:
>   Groups   Name        Variance   Std.Dev.  Corr
>   STUDYNO  (Intercept) 6.3577e-02 0.2521444
>            TIME        1.7435e-06 0.0013204 -0.828
>   Residual             1.3597e-02 0.1166055
>  number of obs: 6066, groups: STUDYNO, 1289
>
>  Fixed effects:
>                Estimate Std. Error t value
>  (Intercept)  1.309e+00  1.313e-01   9.970
>  TIME         5.825e-02  2.160e-03  26.963
>  I(TIME^2)   -1.113e-04  1.144e-05  -9.723
>  I(TIME^3)    7.197e-08  1.957e-08   3.678
>
>  Correlation of Fixed Effects:
>            (Intr) TIME   I(TIME^2
>  TIME      -0.996
>  I(TIME^2)  0.988 -0.997
>  I(TIME^3) -0.976  0.991 -0.998
>
>
>  However as the slope consists of the polynomial combination (TIME +
>  TIME^2 + TIME^3) intuitively it would seem correct to include these
>  polynomial terms as  random effects. However, everything goes
>  pair-shaped when I try:
>
>  > test.ac3 <- lmer(y.ac ~ TIME + I(TIME^2) + I(TIME^3) +
>  > (TIME+I(TIME^2)+I(TIME^3)|STUDYNO), data=s.workdat, method="ML",
>  > na.action=na.omit)
>
>  Warning messages:
>  1: In .local(x, ..., value) :
>    Estimated variance-covariance for factor 'STUDYNO' is singular
>
>  2: In .local(x, ..., value) :
>    nlminb returned message false convergence (8)
>
>
>  I am assuming that this is due to the strong correlations between the
>  polynomials of TIME. I also performed this analysis on the subset of
>  subjects with 5 or greater ultrasound measurements (in desperation!
>  n=1024) and obtained the same error message.
>
>  My dilemma is explaining why TIME has both a fixed and random
>  component, whereas TIME^2 and TIME^3 only have a fixed component.  I
>  suspect I am missing something fundamental !!!
>
>  I have also had some fun fitting different AR structures but decided
>  to strip back the model to the basic correlation structure for this
>  question. Any help would be very much appreciated.
>
>
>  kindest regards,  julie marsh
>
>  PhD Student
>  Centre for Genetic Epidemiology
>  University of Western Autsralia
>  email: marshj02 at student.uwa.edu.au
>
>  _______________________________________________
>  R-sig-mixed-models at r-project.org mailing list
>  https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Sun Apr  6 17:04:34 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sun, 6 Apr 2008 10:04:34 -0500
Subject: [R-sig-ME] random effects specification
In-Reply-To: <75A3A990-0E70-4BDB-A44D-2BA011ADEA8C@kagi.com>
References: <87abkak6qa.fsf@patagonia.sebmags.homelinux.org>
	<40e66e0b0804031532q12880b01mcba6173fc3e32c10@mail.gmail.com>
	<878wzuzf94.fsf@patagonia.sebmags.homelinux.org>
	<40e66e0b0804040517w3602b3dch6e6d5c7d53f33eb@mail.gmail.com>
	<87ve2xydmh.fsf@patagonia.sebmags.homelinux.org>
	<75A3A990-0E70-4BDB-A44D-2BA011ADEA8C@kagi.com>
Message-ID: <40e66e0b0804060804g494f8f59i5307444fc581227d@mail.gmail.com>

On Sat, Apr 5, 2008 at 10:14 PM, Ken Beath <kjbeath at kagi.com> wrote:
> On 05/04/2008, at 12:05 AM, Sebastian P. Luque wrote:
>  > On Fri, 4 Apr 2008 07:17:36 -0500,
>  > "Douglas Bates" <bates at stat.wisc.edu> wrote:
>  >
>  > [...]
>  >
>  >> I'm not sure that I understand what you mean by "treatment being
>  >> nested within community".  Does this mean that there are really 8
>  >> different treatments because treatment 1 in community A is different
>  >> from treatment 1 in community B?  If so, then it would make sense to
>  >> me to simply create a new factor that is the interaction of treatment
>  >> and community.
>  >
>  > I was not employing the term "nested" properly.  The number of levels
>  > for both community and treatment are 2 and 4, respectively, just as in
>  > the example.  The same 4 treatments were used in both communties, so
>  > in
>  > fact, treatment is crossed with community, not nested.  However,
>  > subjects are nested within communities because each subject belongs to
>  > one community only, yet received all 4 treatments.  Sorry for this
>  > confusion.
>  >
>
>  Once they are considered fixed effects, concepts of crossing and
>  nesting are irrelevant. They are simply covariates. So a model of the
>  form n ~ treatment + community +(1|id) or if the treatment effect is
>  allowed to vary between communities n ~ treatment *community +(1|id)
>  is appropriate. The main problem is your subject id are not unique.
>  You will need to define a new id.

I agree with everything up to here.

> The easiest way is to add a
>  different large number to id depending on community.

That approach contradicts your later advice to represent a factor
variable as a factor in R.  If id is a factor (as it should be) you
can't add  a large number to it.

The specification (1|treatment:id) generates unique id's.

To me the convention that different experimental units should be given
the same level of 'id' is just another nonsensical aspect of the
traditional approaches to random-effects models using observed and
expected mean squares, for which it makes sense to index the
observations by group and by unit within group.

If we could manage to unlearn old habits and just give each subject a
unique id at the start it would make life easier.

>
>
>  >
>  >> Perhaps I am approaching the community factor incorrectly.  In your
>  >> data there are two communities so, even if it would be reasonable to
>  >> model community effects as random effects, that would be difficult.
>  >> With only two levels I think it is best modeled as a fixed effect,
>  >> which would mean that questions about treatment and community are
>  >> related to the fixed effects.
>  >
>  > Could you please show a formula for the case where each individual is
>  > seen at both communities (community and treatment still being fixed)?
>  > This would help me understand the syntax better.
>  >
>
>  Same model as previous, provided a subject only receives a treatment
>  once. If a subject receives the same treatment more than once then
>  there needs to be a random effect that models the correlation between
>  repeated measurements of the same treatment, so the model is
>  y~treatment+community+(1|id/treatment) One problem that may have
>  occurred in your original attempts is that id and treatment need to be
>  factors.

Yes, that is one way of expressing an interaction between a random
effect for id and a fixed effect for treatment.

It expands to two random effects terms (1|id) + (1|id:treatment).  The
first is the effect for person and the second is the effect of
different individuals having different responses to the levels of
treatment.

A more general model (and consequently more difficult to estimate on
occasion) has possible correlations of the random effects for
different levels of treatment within individual.  The term is written
(treatment|id).



From bates at stat.wisc.edu  Sun Apr  6 17:15:09 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sun, 6 Apr 2008 10:15:09 -0500
Subject: [R-sig-ME] Fwd: same old question - lme4 and p-values
In-Reply-To: <aefe4d0a0804050310q1bd57ec6n8abf01a0e6e248d@mail.gmail.com>
References: <28642179.2370001207304657364.JavaMail.nabble@isper.nabble.com>
	<40e66e0b0804040554m41e63d58l3a5825924696cf78@mail.gmail.com>
	<40e66e0b0804040633k619803fayfd2e9b9b07b88b77@mail.gmail.com>
	<2A882A0D-B7AC-43CB-970C-F009D334DA3D@MUOhio.edu>
	<aefe4d0a0804050310q1bd57ec6n8abf01a0e6e248d@mail.gmail.com>
Message-ID: <40e66e0b0804060815k121807aap9d31f233a506c341@mail.gmail.com>

On Sat, Apr 5, 2008 at 5:10 AM, Reinhold Kliegl
<reinhold.kliegl at gmail.com> wrote:
> Here is a section that worked in Kliegl, Risse, & Laubrock (2007, J
>  Exp Psychol:Human Perception and Performance, 33, 1250-1251).
>
>  "Analysis
>      Inferential statistics are based on a linear mixed-effects model
>  (lme) specifying participants and items as crossed random effects.
>  This analysis takes into account differences between participants and
>  differences between items in a single sweep and has been shown to
>  suffer substantially less loss of statistical power in unbalanced
>  designs than traditional ANOVAs over participants (F1) and items (F2;
>  see Baayen, in press, Pinheiro & Bates, 2000; Quen? & van den Bergh,
>  2004, for simulations).
>     We used the lmer program (lme4 package; Bates & Sarkar, 2006) in
>  the R system for statistical computing (R Development Core Team, 2006)
>  and report regression coefficients (b; absolute effect size in ms),
>  standard errors (SE), and p-values for an upper-bound n of denominator
>  degrees of freedom computed as n of observations minus n of fixed
>  effects. As these p-values are potentially anti-conservative, we
>  generated confidence intervals from the posterior distribution of
>  parameter estimates with Markov Chain Monte Carlo methods, using the
>  mcmcsamp program in the lme4 package with default specifications
>  (e.g., n=1000 samples; locally uniform priors for fixed effects;
>  locally non-informative priors for random effects). Both procedures
>  yielded the same results.
>     Finally, we also computed post-hoc power statistics for the
>  preview and lexical status main effects and for the interaction effect
>  on first fixation durations (with effect sizes similar to those
>  reported earlier, e.g., Kliegl, 2007), and using lme estimates of
>  between-participant, between-item, and residual variances (Gelman &
>  Hill, in press). For the observed proportion of random loss of items,
>  power estimates based on 1000 simulations each were around .85 for
>  word n and n+2 and .59 for word n+1 (due to the higher skipping
>  rate)."  (page 1251)
>
>  Power statistics were included in response to a reviewer request. I am
>  not much in favor of post-hoc power statistics; but note that here
>  they are restricted to the use of estimates of random effects. For
>  reviewers, we also included traditional F1- and F2-ANOVA tables; they
>  are not part of the article. In other articles, it has also been
>  acceptable to report coefficients, their standard errors, and their
>  ratio, and to say that coefficients larger than 2 SE are interpreted
>  as significant (e.g., Kliegl, 2007, J Exp Psychol: General, 136,
>  530-537), that is, it is possible to leave out p-values completely.
>
>  Corrections and improvements of the above sentences are highly welcome
>  for future articles. In perspective, I think the p-value problem will
>  simply go away.
>
>  Best
>  Reinhold
>
>  PS: Would it be useful to have a site where peer-reviewed articles
>  using lme4 for statistical inference are listed and, possibly,
>  retrievable versions are provided?

Thanks for the suggestion, Reinhold.  I would be delighted to provide
a page on http://lme4.r-forge.r-project.org/ to list such references.

May I ask for a volunteer to maintain such a listing?  I am rather
overextended at present trying to get lme4_1.0-0 out and writing a
book about what it does.  All that is required is to obtain a R-forge
login, decide how to organize the pages and then update the pages as
new references are submitted.



From marshj02 at student.uwa.edu.au  Sun Apr  6 17:26:18 2008
From: marshj02 at student.uwa.edu.au (Julie Marsh)
Date: Sun, 06 Apr 2008 23:26:18 +0800
Subject: [R-sig-ME] Modelling growth data: time polynomials as
	random	effects
In-Reply-To: <aefe4d0a0804060351t56b79841g23547769d1bb68b2@mail.gmail.com>
References: <20080406181814.y388axpydb4k40c4@webmail-5.ucs.uwa.edu.au>
	<aefe4d0a0804060351t56b79841g23547769d1bb68b2@mail.gmail.com>
Message-ID: <20080406232618.32qx4lvzjf8k48ks@webmail-2.ucs.uwa.edu.au>

Dear Prof Kliegl,

Many thanks for your excellent comments.  I centered the TIME data and  
managed to squeeze in poly(I(TIME-100),2) as a random effect. (The  
majority of the ultrasounds occur after Day 100).  However including  
poly(I(TIME-100),3) in the model produced the familiar error message:

> ac.model3 <- lmer(y.ac ~ poly(I(TIME-100),3) +  
> (poly(I(TIME-100),3)|STUDYNO), data=s.workdat, method="ML",  
> na.action=na.omit)

Warning message:
In .local(x, ..., value) : nlminb returned message false convergence (8)

I suspect that you are correct in suggesting that there may be too  
little variation between subjects for any higher order effects.  The  
within subject variation is far greater (across time) than the  
variability between subjects (at each time point).

Thanks again for all your help.

kindest regards,  julie.



Quoting Reinhold Kliegl <reinhold.kliegl at gmail.com>:

> You may want to center "TIME" prior to running lmer. Probably, it
> probably better to use "poly(TIME, 3)".
>
> For example, it works here:
>> (fm1 <- lmer(Reaction ~ poly(Days,2) + (poly(Days,2)|Subject), sleepstudy))
> Linear mixed model fit by REML
> Formula: Reaction ~ poly(Days, 2) + (poly(Days, 2) | Subject)
>    Data: sleepstudy
>   AIC  BIC logLik deviance REMLdev
>  1733 1765 -856.4     1738    1713
> Random effects:
>  Groups   Name           Variance Std.Dev. Corr
>           (Intercept)     1422.41  37.715
>           poly(Days, 2)1 54543.55 233.546   0.732
>           poly(Days, 2)2 20260.08 142.338  -0.140 -0.025
>  Residual                  518.16  22.763
> Number of obs: 180, groups: Subject, 18
>
> Fixed effects:
>                Estimate Std. Error t value
> (Intercept)      298.51       9.05   32.98
> poly(Days, 2)1   403.36      59.57    6.77
> poly(Days, 2)2    32.86      40.54    0.81
>
> Correlation of Fixed Effects:
>             (Intr) p(D,2)1
> ply(Dys,2)1  0.665
> ply(Dys,2)2 -0.114 -0.019
>
> On a practical side, it could also be that there simple is too little
> variance between subjects for higher-order TIME effects.
>
> Reinhold
>
> On Sun, Apr 6, 2008 at 12:18 PM, Julie Marsh
> <marshj02 at student.uwa.edu.au> wrote:
>>
>>  Dear LMER Experts,
>>
>>  I am trying to model some growth data based on multiple ultrasound
>>  measurements taken across the time course (in days) of each pregnancy.
>>  The vast majority of subjects have 4+ measurements.  Everything seems
>>  good up to:
>>
>>  > model.ac1 <- lmer(y.ac ~ TIME + I(TIME^2) + I(TIME^3) +
>>  > (TIME|STUDYNO), data=s.workdat, method="ML", na.action=na.omit)
>>
>>  > summary(model.ac1)
>>  Linear mixed-effects model fit by maximum likelihood
>>  Formula: y.ac ~ TIME + I(TIME^2) + I(TIME^3) + (TIME | STUDYNO)
>>     Data: s.workdat
>>     AIC   BIC logLik MLdeviance REMLdeviance
>>   -5051 -5004   2532      -5065        -4978
>>  Random effects:
>>   Groups   Name        Variance   Std.Dev.  Corr
>>   STUDYNO  (Intercept) 6.3577e-02 0.2521444
>>            TIME        1.7435e-06 0.0013204 -0.828
>>   Residual             1.3597e-02 0.1166055
>>  number of obs: 6066, groups: STUDYNO, 1289
>>
>>  Fixed effects:
>>                Estimate Std. Error t value
>>  (Intercept)  1.309e+00  1.313e-01   9.970
>>  TIME         5.825e-02  2.160e-03  26.963
>>  I(TIME^2)   -1.113e-04  1.144e-05  -9.723
>>  I(TIME^3)    7.197e-08  1.957e-08   3.678
>>
>>  Correlation of Fixed Effects:
>>            (Intr) TIME   I(TIME^2
>>  TIME      -0.996
>>  I(TIME^2)  0.988 -0.997
>>  I(TIME^3) -0.976  0.991 -0.998
>>
>>
>>  However as the slope consists of the polynomial combination (TIME +
>>  TIME^2 + TIME^3) intuitively it would seem correct to include these
>>  polynomial terms as  random effects. However, everything goes
>>  pair-shaped when I try:
>>
>>  > test.ac3 <- lmer(y.ac ~ TIME + I(TIME^2) + I(TIME^3) +
>>  > (TIME+I(TIME^2)+I(TIME^3)|STUDYNO), data=s.workdat, method="ML",
>>  > na.action=na.omit)
>>
>>  Warning messages:
>>  1: In .local(x, ..., value) :
>>    Estimated variance-covariance for factor 'STUDYNO' is singular
>>
>>  2: In .local(x, ..., value) :
>>    nlminb returned message false convergence (8)
>>
>>
>>  I am assuming that this is due to the strong correlations between the
>>  polynomials of TIME. I also performed this analysis on the subset of
>>  subjects with 5 or greater ultrasound measurements (in desperation!
>>  n=1024) and obtained the same error message.
>>
>>  My dilemma is explaining why TIME has both a fixed and random
>>  component, whereas TIME^2 and TIME^3 only have a fixed component.  I
>>  suspect I am missing something fundamental !!!
>>
>>  I have also had some fun fitting different AR structures but decided
>>  to strip back the model to the basic correlation structure for this
>>  question. Any help would be very much appreciated.
>>
>>
>>  kindest regards,  julie marsh
>>
>>  PhD Student
>>  Centre for Genetic Epidemiology
>>  University of Western Autsralia
>>  email: marshj02 at student.uwa.edu.au
>>
>>  _______________________________________________
>>  R-sig-mixed-models at r-project.org mailing list
>>  https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>



From bates at stat.wisc.edu  Sun Apr  6 17:34:53 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sun, 6 Apr 2008 10:34:53 -0500
Subject: [R-sig-ME] Modelling growth data: time polynomials as random
	effects
In-Reply-To: <aefe4d0a0804060351t56b79841g23547769d1bb68b2@mail.gmail.com>
References: <20080406181814.y388axpydb4k40c4@webmail-5.ucs.uwa.edu.au>
	<aefe4d0a0804060351t56b79841g23547769d1bb68b2@mail.gmail.com>
Message-ID: <40e66e0b0804060834p30ee48ag89780f21c40c9c7a@mail.gmail.com>

On Sun, Apr 6, 2008 at 5:51 AM, Reinhold Kliegl
<reinhold.kliegl at gmail.com> wrote:
> You may want to center "TIME" prior to running lmer. Probably, it
>  probably better to use "poly(TIME, 3)".
>
>  For example, it works here:
>  > (fm1 <- lmer(Reaction ~ poly(Days,2) + (poly(Days,2)|Subject), sleepstudy))
>  Linear mixed model fit by REML
>  Formula: Reaction ~ poly(Days, 2) + (poly(Days, 2) | Subject)
>    Data: sleepstudy
>   AIC  BIC logLik deviance REMLdev
>   1733 1765 -856.4     1738    1713
>
> Random effects:
>   Groups   Name           Variance Std.Dev. Corr
>           (Intercept)     1422.41  37.715
>           poly(Days, 2)1 54543.55 233.546   0.732
>           poly(Days, 2)2 20260.08 142.338  -0.140 -0.025
>   Residual                  518.16  22.763
>  Number of obs: 180, groups: Subject, 18
>
>
>  Fixed effects:
>                Estimate Std. Error t value
>  (Intercept)      298.51       9.05   32.98
>  poly(Days, 2)1   403.36      59.57    6.77
>  poly(Days, 2)2    32.86      40.54    0.81
>
>  Correlation of Fixed Effects:
>             (Intr) p(D,2)1
>  ply(Dys,2)1  0.665
>  ply(Dys,2)2 -0.114 -0.019
>
>  On a practical side, it could also be that there simple is too little
>  variance between subjects for higher-order TIME effects.

I agree.  The Pixel data analyzed in "Mixed-effects Models in S and
S-PLUS" (and available in the MEMSS package) is such an example.  The
overal shape of the density versus time curve is quadratic but the
variation between dogs can only be modeled up to the linear term and
the variation in side within dog as an additive shift only.

>  On Sun, Apr 6, 2008 at 12:18 PM, Julie Marsh
>  <marshj02 at student.uwa.edu.au> wrote:
>  >
>  >  Dear LMER Experts,
>  >
>  >  I am trying to model some growth data based on multiple ultrasound
>  >  measurements taken across the time course (in days) of each pregnancy.
>  >  The vast majority of subjects have 4+ measurements.  Everything seems
>  >  good up to:
>  >
>  >  > model.ac1 <- lmer(y.ac ~ TIME + I(TIME^2) + I(TIME^3) +
>  >  > (TIME|STUDYNO), data=s.workdat, method="ML", na.action=na.omit)
>  >
>  >  > summary(model.ac1)
>  >  Linear mixed-effects model fit by maximum likelihood
>  >  Formula: y.ac ~ TIME + I(TIME^2) + I(TIME^3) + (TIME | STUDYNO)
>  >     Data: s.workdat
>  >     AIC   BIC logLik MLdeviance REMLdeviance
>  >   -5051 -5004   2532      -5065        -4978
>  >  Random effects:
>  >   Groups   Name        Variance   Std.Dev.  Corr
>  >   STUDYNO  (Intercept) 6.3577e-02 0.2521444
>  >            TIME        1.7435e-06 0.0013204 -0.828
>  >   Residual             1.3597e-02 0.1166055
>  >  number of obs: 6066, groups: STUDYNO, 1289
>  >
>  >  Fixed effects:
>  >                Estimate Std. Error t value
>  >  (Intercept)  1.309e+00  1.313e-01   9.970
>  >  TIME         5.825e-02  2.160e-03  26.963
>  >  I(TIME^2)   -1.113e-04  1.144e-05  -9.723
>  >  I(TIME^3)    7.197e-08  1.957e-08   3.678
>  >
>  >  Correlation of Fixed Effects:
>  >            (Intr) TIME   I(TIME^2
>  >  TIME      -0.996
>  >  I(TIME^2)  0.988 -0.997
>  >  I(TIME^3) -0.976  0.991 -0.998
>  >
>  >
>  >  However as the slope consists of the polynomial combination (TIME +
>  >  TIME^2 + TIME^3) intuitively it would seem correct to include these
>  >  polynomial terms as  random effects. However, everything goes
>  >  pair-shaped when I try:
>  >
>  >  > test.ac3 <- lmer(y.ac ~ TIME + I(TIME^2) + I(TIME^3) +
>  >  > (TIME+I(TIME^2)+I(TIME^3)|STUDYNO), data=s.workdat, method="ML",
>  >  > na.action=na.omit)
>  >
>  >  Warning messages:
>  >  1: In .local(x, ..., value) :
>  >    Estimated variance-covariance for factor 'STUDYNO' is singular
>  >
>  >  2: In .local(x, ..., value) :
>  >    nlminb returned message false convergence (8)
>  >
>  >
>  >  I am assuming that this is due to the strong correlations between the
>  >  polynomials of TIME. I also performed this analysis on the subset of
>  >  subjects with 5 or greater ultrasound measurements (in desperation!
>  >  n=1024) and obtained the same error message.
>  >
>  >  My dilemma is explaining why TIME has both a fixed and random
>  >  component, whereas TIME^2 and TIME^3 only have a fixed component.  I
>  >  suspect I am missing something fundamental !!!
>  >
>  >  I have also had some fun fitting different AR structures but decided
>  >  to strip back the model to the basic correlation structure for this
>  >  question. Any help would be very much appreciated.
>  >
>  >
>  >  kindest regards,  julie marsh
>  >
>  >  PhD Student
>  >  Centre for Genetic Epidemiology
>  >  University of Western Autsralia
>  >  email: marshj02 at student.uwa.edu.au
>  >
>  >  _______________________________________________
>  >  R-sig-mixed-models at r-project.org mailing list
>  >  https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>  >
>
>  _______________________________________________
>  R-sig-mixed-models at r-project.org mailing list
>  https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From A.Robinson at ms.unimelb.edu.au  Sun Apr  6 23:02:19 2008
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Mon, 7 Apr 2008 07:02:19 +1000
Subject: [R-sig-ME] Fwd: same old question - lme4 and p-values
In-Reply-To: <40e66e0b0804060815k121807aap9d31f233a506c341@mail.gmail.com>
References: <28642179.2370001207304657364.JavaMail.nabble@isper.nabble.com>
	<40e66e0b0804040554m41e63d58l3a5825924696cf78@mail.gmail.com>
	<40e66e0b0804040633k619803fayfd2e9b9b07b88b77@mail.gmail.com>
	<2A882A0D-B7AC-43CB-970C-F009D334DA3D@MUOhio.edu>
	<aefe4d0a0804050310q1bd57ec6n8abf01a0e6e248d@mail.gmail.com>
	<40e66e0b0804060815k121807aap9d31f233a506c341@mail.gmail.com>
Message-ID: <20080406210219.GD1341@ms.unimelb.edu.au>

On Sun, Apr 06, 2008 at 10:15:09AM -0500, Douglas Bates wrote:
> On Sat, Apr 5, 2008 at 5:10 AM, Reinhold Kliegl
> <reinhold.kliegl at gmail.com> wrote:
> > Here is a section that worked in Kliegl, Risse, & Laubrock (2007, J
> >  Exp Psychol:Human Perception and Performance, 33, 1250-1251).
> >
> >  "Analysis
> >      Inferential statistics are based on a linear mixed-effects model
> >  (lme) specifying participants and items as crossed random effects.
> >  This analysis takes into account differences between participants and
> >  differences between items in a single sweep and has been shown to
> >  suffer substantially less loss of statistical power in unbalanced
> >  designs than traditional ANOVAs over participants (F1) and items (F2;
> >  see Baayen, in press, Pinheiro & Bates, 2000; Quen? & van den Bergh,
> >  2004, for simulations).
> >     We used the lmer program (lme4 package; Bates & Sarkar, 2006) in
> >  the R system for statistical computing (R Development Core Team, 2006)
> >  and report regression coefficients (b; absolute effect size in ms),
> >  standard errors (SE), and p-values for an upper-bound n of denominator
> >  degrees of freedom computed as n of observations minus n of fixed
> >  effects. As these p-values are potentially anti-conservative, we
> >  generated confidence intervals from the posterior distribution of
> >  parameter estimates with Markov Chain Monte Carlo methods, using the
> >  mcmcsamp program in the lme4 package with default specifications
> >  (e.g., n=1000 samples; locally uniform priors for fixed effects;
> >  locally non-informative priors for random effects). Both procedures
> >  yielded the same results.
> >     Finally, we also computed post-hoc power statistics for the
> >  preview and lexical status main effects and for the interaction effect
> >  on first fixation durations (with effect sizes similar to those
> >  reported earlier, e.g., Kliegl, 2007), and using lme estimates of
> >  between-participant, between-item, and residual variances (Gelman &
> >  Hill, in press). For the observed proportion of random loss of items,
> >  power estimates based on 1000 simulations each were around .85 for
> >  word n and n+2 and .59 for word n+1 (due to the higher skipping
> >  rate)."  (page 1251)
> >
> >  Power statistics were included in response to a reviewer request. I am
> >  not much in favor of post-hoc power statistics; but note that here
> >  they are restricted to the use of estimates of random effects. For
> >  reviewers, we also included traditional F1- and F2-ANOVA tables; they
> >  are not part of the article. In other articles, it has also been
> >  acceptable to report coefficients, their standard errors, and their
> >  ratio, and to say that coefficients larger than 2 SE are interpreted
> >  as significant (e.g., Kliegl, 2007, J Exp Psychol: General, 136,
> >  530-537), that is, it is possible to leave out p-values completely.
> >
> >  Corrections and improvements of the above sentences are highly welcome
> >  for future articles. In perspective, I think the p-value problem will
> >  simply go away.
> >
> >  Best
> >  Reinhold
> >
> >  PS: Would it be useful to have a site where peer-reviewed articles
> >  using lme4 for statistical inference are listed and, possibly,
> >  retrievable versions are provided?
> 
> Thanks for the suggestion, Reinhold.  I would be delighted to provide
> a page on http://lme4.r-forge.r-project.org/ to list such references.
> 
> May I ask for a volunteer to maintain such a listing?  I am rather
> overextended at present trying to get lme4_1.0-0 out and writing a
> book about what it does.  All that is required is to obtain a R-forge
> login, decide how to organize the pages and then update the pages as
> new references are submitted.

I'm happy to do that, Doug.  I've registered.

Andrew

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From bates at stat.wisc.edu  Sun Apr  6 23:38:49 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sun, 6 Apr 2008 16:38:49 -0500
Subject: [R-sig-ME] Fwd: same old question - lme4 and p-values
In-Reply-To: <20080406210219.GD1341@ms.unimelb.edu.au>
References: <28642179.2370001207304657364.JavaMail.nabble@isper.nabble.com>
	<40e66e0b0804040554m41e63d58l3a5825924696cf78@mail.gmail.com>
	<40e66e0b0804040633k619803fayfd2e9b9b07b88b77@mail.gmail.com>
	<2A882A0D-B7AC-43CB-970C-F009D334DA3D@MUOhio.edu>
	<aefe4d0a0804050310q1bd57ec6n8abf01a0e6e248d@mail.gmail.com>
	<40e66e0b0804060815k121807aap9d31f233a506c341@mail.gmail.com>
	<20080406210219.GD1341@ms.unimelb.edu.au>
Message-ID: <40e66e0b0804061438l6bafc1daoc8fe496ed017b6ac@mail.gmail.com>

On Sun, Apr 6, 2008 at 4:02 PM, Andrew Robinson
<A.Robinson at ms.unimelb.edu.au> wrote:
> On Sun, Apr 06, 2008 at 10:15:09AM -0500, Douglas Bates wrote:
>  > On Sat, Apr 5, 2008 at 5:10 AM, Reinhold Kliegl
>  > <reinhold.kliegl at gmail.com> wrote:
>  > > Here is a section that worked in Kliegl, Risse, & Laubrock (2007, J
>  > >  Exp Psychol:Human Perception and Performance, 33, 1250-1251).
>  > >
>  > >  "Analysis
>  > >      Inferential statistics are based on a linear mixed-effects model
>  > >  (lme) specifying participants and items as crossed random effects.
>  > >  This analysis takes into account differences between participants and
>  > >  differences between items in a single sweep and has been shown to
>  > >  suffer substantially less loss of statistical power in unbalanced
>  > >  designs than traditional ANOVAs over participants (F1) and items (F2;
>  > >  see Baayen, in press, Pinheiro & Bates, 2000; Quen? & van den Bergh,
>
>
> > >  2004, for simulations).
>  > >     We used the lmer program (lme4 package; Bates & Sarkar, 2006) in
>  > >  the R system for statistical computing (R Development Core Team, 2006)
>  > >  and report regression coefficients (b; absolute effect size in ms),
>  > >  standard errors (SE), and p-values for an upper-bound n of denominator
>  > >  degrees of freedom computed as n of observations minus n of fixed
>  > >  effects. As these p-values are potentially anti-conservative, we
>  > >  generated confidence intervals from the posterior distribution of
>  > >  parameter estimates with Markov Chain Monte Carlo methods, using the
>  > >  mcmcsamp program in the lme4 package with default specifications
>  > >  (e.g., n=1000 samples; locally uniform priors for fixed effects;
>  > >  locally non-informative priors for random effects). Both procedures
>  > >  yielded the same results.
>  > >     Finally, we also computed post-hoc power statistics for the
>  > >  preview and lexical status main effects and for the interaction effect
>  > >  on first fixation durations (with effect sizes similar to those
>  > >  reported earlier, e.g., Kliegl, 2007), and using lme estimates of
>  > >  between-participant, between-item, and residual variances (Gelman &
>  > >  Hill, in press). For the observed proportion of random loss of items,
>  > >  power estimates based on 1000 simulations each were around .85 for
>  > >  word n and n+2 and .59 for word n+1 (due to the higher skipping
>  > >  rate)."  (page 1251)
>  > >
>  > >  Power statistics were included in response to a reviewer request. I am
>  > >  not much in favor of post-hoc power statistics; but note that here
>  > >  they are restricted to the use of estimates of random effects. For
>  > >  reviewers, we also included traditional F1- and F2-ANOVA tables; they
>  > >  are not part of the article. In other articles, it has also been
>  > >  acceptable to report coefficients, their standard errors, and their
>  > >  ratio, and to say that coefficients larger than 2 SE are interpreted
>  > >  as significant (e.g., Kliegl, 2007, J Exp Psychol: General, 136,
>  > >  530-537), that is, it is possible to leave out p-values completely.
>  > >
>  > >  Corrections and improvements of the above sentences are highly welcome
>  > >  for future articles. In perspective, I think the p-value problem will
>  > >  simply go away.
>  > >
>  > >  Best
>  > >  Reinhold
>  > >
>  > >  PS: Would it be useful to have a site where peer-reviewed articles
>  > >  using lme4 for statistical inference are listed and, possibly,
>  > >  retrievable versions are provided?
>  >
>  > Thanks for the suggestion, Reinhold.  I would be delighted to provide
>  > a page on http://lme4.r-forge.r-project.org/ to list such references.
>  >
>  > May I ask for a volunteer to maintain such a listing?  I am rather
>  > overextended at present trying to get lme4_1.0-0 out and writing a
>  > book about what it does.  All that is required is to obtain a R-forge
>  > login, decide how to organize the pages and then update the pages as
>  > new references are submitted.
>
>  I'm happy to do that, Doug.  I've registered.

Thanks for the offer, Andrew.  Shravan Vasishth has already kindly
taken on the job.



From nikko at hailmail.net  Mon Apr  7 02:18:30 2008
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: Sun, 06 Apr 2008 20:18:30 -0400
Subject: [R-sig-ME] same old question - lme4 and p-values
In-Reply-To: <mailman.4526.1207445853.4224.r-sig-mixed-models@r-project.org>
References: <mailman.4526.1207445853.4224.r-sig-mixed-models@r-project.org>
Message-ID: <1207527510.5563.1246390525@webmail.messagingengine.com>

Hi,
I feel compelled to ad my 2c here. I am strongly against
the reporting of p-values for several reasons. There are the slew
of theoretical arguments about p-values, the most compelling is which is
the
correct null distribution, and that p-values are a very measure of
statistical 
evidence, if they measure evidence at all. p-values only measure the
null versus
alternative, and are not a measure of evidence of one model over another
that
can be ranked over a set of alternate models. See Royall 1997, or Taper
and Lele 2004.

These arguments aside, in the world where I work, early development
pharmaceuticals, many scientists and
managers would have the p-values make decisions for them. This is very
dangerous, as the
experiment to experiment variation is usually much higher than the
within experiment variation.
Even more important, it is not clear to me that many of the processes we
look
at converge to a stable distribution. I think that the responsibility of
the scientist 
in a publication is to show the variability of the data, explain the
sources of 
variation and how they were controlled, the relevant effect sizes and
the ASSUMPTIONS
made in the model. In either the epidemiological or the experimental
paradigms
consensus will only come with demonstrated repeatability. A publication
should
generate scientific discussion about the mechanisms and trends being
reported. I am
not sure that p-values generate the right discussion.

Didn't mean to rant.

Nicholas

Statistical Evidence: A Likelihood Paradigm. R. Royall, Chapman & Hall,
London, 1997

MARK L. TAPER AND SUBHASH R. LELE, eds. The Nature of Scientific
Evidence: Statistical, Philosophical, 
and Empirical Considerations. Chicago and London: University of Chicago
Press, 2004.



From kjbeath at kagi.com  Mon Apr  7 08:10:17 2008
From: kjbeath at kagi.com (Ken Beath)
Date: Mon, 7 Apr 2008 16:10:17 +1000
Subject: [R-sig-ME] random effects specification
In-Reply-To: <40e66e0b0804060804g494f8f59i5307444fc581227d@mail.gmail.com>
References: <87abkak6qa.fsf@patagonia.sebmags.homelinux.org>
	<40e66e0b0804031532q12880b01mcba6173fc3e32c10@mail.gmail.com>
	<878wzuzf94.fsf@patagonia.sebmags.homelinux.org>
	<40e66e0b0804040517w3602b3dch6e6d5c7d53f33eb@mail.gmail.com>
	<87ve2xydmh.fsf@patagonia.sebmags.homelinux.org>
	<75A3A990-0E70-4BDB-A44D-2BA011ADEA8C@kagi.com>
	<40e66e0b0804060804g494f8f59i5307444fc581227d@mail.gmail.com>
Message-ID: <3D4A6791-2368-412E-A62E-BD10EFD5DA91@kagi.com>

On 07/04/2008, at 1:04 AM, Douglas Bates wrote:
> On Sat, Apr 5, 2008 at 10:14 PM, Ken Beath <kjbeath at kagi.com> wrote:
>> On 05/04/2008, at 12:05 AM, Sebastian P. Luque wrote:
>>> On Fri, 4 Apr 2008 07:17:36 -0500,
>>> "Douglas Bates" <bates at stat.wisc.edu> wrote:
>>>
>>> [...]
>>>
>>>> I'm not sure that I understand what you mean by "treatment being
>>>> nested within community".  Does this mean that there are really 8
>>>> different treatments because treatment 1 in community A is  
>>>> different
>>>> from treatment 1 in community B?  If so, then it would make sense  
>>>> to
>>>> me to simply create a new factor that is the interaction of  
>>>> treatment
>>>> and community.
>>>
>>> I was not employing the term "nested" properly.  The number of  
>>> levels
>>> for both community and treatment are 2 and 4, respectively, just  
>>> as in
>>> the example.  The same 4 treatments were used in both communties, so
>>> in
>>> fact, treatment is crossed with community, not nested.  However,
>>> subjects are nested within communities because each subject  
>>> belongs to
>>> one community only, yet received all 4 treatments.  Sorry for this
>>> confusion.
>>>
>>
>> Once they are considered fixed effects, concepts of crossing and
>> nesting are irrelevant. They are simply covariates. So a model of the
>> form n ~ treatment + community +(1|id) or if the treatment effect is
>> allowed to vary between communities n ~ treatment *community +(1|id)
>> is appropriate. The main problem is your subject id are not unique.
>> You will need to define a new id.
>
> I agree with everything up to here.
>
>> The easiest way is to add a
>> different large number to id depending on community.
>
> That approach contradicts your later advice to represent a factor
> variable as a factor in R.  If id is a factor (as it should be) you
> can't add  a large number to it.
>

I was thinking of this in terms of the original data, and should have  
mentioned that a conversion may be required in R, as described in  
help(factor).

> The specification (1|treatment:id) generates unique id's.
>
> To me the convention that different experimental units should be given
> the same level of 'id' is just another nonsensical aspect of the
> traditional approaches to random-effects models using observed and
> expected mean squares, for which it makes sense to index the
> observations by group and by unit within group.
>
> If we could manage to unlearn old habits and just give each subject a
> unique id at the start it would make life easier.
>
>>
>>
>>>
>>>> Perhaps I am approaching the community factor incorrectly.  In your
>>>> data there are two communities so, even if it would be reasonable  
>>>> to
>>>> model community effects as random effects, that would be difficult.
>>>> With only two levels I think it is best modeled as a fixed effect,
>>>> which would mean that questions about treatment and community are
>>>> related to the fixed effects.
>>>
>>> Could you please show a formula for the case where each individual  
>>> is
>>> seen at both communities (community and treatment still being  
>>> fixed)?
>>> This would help me understand the syntax better.
>>>
>>
>> Same model as previous, provided a subject only receives a treatment
>> once. If a subject receives the same treatment more than once then
>> there needs to be a random effect that models the correlation between
>> repeated measurements of the same treatment, so the model is
>> y~treatment+community+(1|id/treatment) One problem that may have
>> occurred in your original attempts is that id and treatment need to  
>> be
>> factors.
>
> Yes, that is one way of expressing an interaction between a random
> effect for id and a fixed effect for treatment.
>
> It expands to two random effects terms (1|id) + (1|id:treatment).  The
> first is the effect for person and the second is the effect of
> different individuals having different responses to the levels of
> treatment.
>
> A more general model (and consequently more difficult to estimate on
> occasion) has possible correlations of the random effects for
> different levels of treatment within individual.  The term is written
> (treatment|id).
>


This does give problems fitting although I get sensible results.



The need for id to be a factor is not consistent but depends on the  
model (this is using the version of lme4 on CRAN). In the following  
simulation (for the model with subjects treated in both communities)   
id as a numeric works for (1|id) but needs to be a factor for (1|id/ 
treatment).


library(lme4)

nsubjects <- 100

id <- rep(1:nsubjects,each=8)
treatment <- rep(1:4,times=nsubjects*2)
community <- rep(1:2,each=4,times=nsubjects)

thedata <- data.frame(id,treatment,community)

subject <- data.frame(id=1:nsubjects,subject=rnorm(nsubjects))

thedata <- merge(thedata,subject)

treatment <- data.frame(id=rep(1:nsubjects, 
4),treatment=rep(1:4,each=nsubjects),subtreat=rnorm(4*nsubjects))

thedata <- merge(thedata,treatment)

thedata$y <- thedata$subject+thedata$subtreat+thedata$community+thedata 
$treatment+rnorm(8*nsubjects)/10

thedata$treatment <- factor(thedata$treatment)
thedata$community <- factor(thedata$community)

# ignoring  treatment within subject correlations
lmer0 <- lmer(y~treatment+community+(1|id),data=thedata)

print(lmer0)

thedata$id <- factor(thedata$id)

lmer1 <- lmer(y~treatment+community+(1|id/treatment),data=thedata)

print(lmer1)


Ken



From John.Maindonald at anu.edu.au  Mon Apr  7 12:47:17 2008
From: John.Maindonald at anu.edu.au (John Maindonald)
Date: Mon, 7 Apr 2008 20:47:17 +1000
Subject: [R-sig-ME] Fwd: same old question - lme4 and p-values
In-Reply-To: <58FA8AD3-6C19-4830-8427-EF4946AFEA9C@Revolution-Computing.Com>
References: <28642179.2370001207304657364.JavaMail.nabble@isper.nabble.com>
	<40e66e0b0804040554m41e63d58l3a5825924696cf78@mail.gmail.com>
	<40e66e0b0804040633k619803fayfd2e9b9b07b88b77@mail.gmail.com>
	<2A882A0D-B7AC-43CB-970C-F009D334DA3D@MUOhio.edu>
	<aefe4d0a0804050310q1bd57ec6n8abf01a0e6e248d@mail.gmail.com>
	<20080405112119.GA22390@psych.upenn.edu>
	<18423.31454.209907.1456@cmath-5.math.ethz.ch>
	<33C9BCEB-6C3A-4CD4-8FE4-E4CEE240A2F5@anu.edu.au>
	<58FA8AD3-6C19-4830-8427-EF4946AFEA9C@Revolution-Computing.Com>
Message-ID: <BDE434F6-B2C0-40A9-BAE8-824E4A6B7268@anu.edu.au>

Real CIs?
~~~~~~~
Most application area people, and indeed many statisticians,
treat confidence intervals (i'd prefer to call them coverage
intervals, but that argument may be lost) as probability
statements about the parameter.  The interpretaion
that is strictly correct does not make a lot of sense, in my
view, relative to what application area people want.

Now in fact classical intervals have (if not exact, then close
enough for all practical purposes) a Bayesian interpretation.
This interpretation has the advantage of making explicit the
assumptions that will support the interpretation of confidence
intervals as probability statements about the parameter.

While this is not the rationale for CIs that is advertised in
those texts that are careful in what they say about CIs,
I am suggesting that it is a more enlightening rationale.
Whether or not one then has a different entity seems to
me slightly academic.

I am arguing, then, that the intervals provided by
mcmcsamp() are preferable to CIs. One knows what the
prior was that led to them.  I do not see why editors who
insist on p-values should not to be entirely happy with them.
They can be sold as a superior kind of CI,  and p-values
that are derived by the same route are a superior kind of
p-value!

Note also; whether they are really Bayesian is a moot point.
The prior is chosen primarily for ease of calculation, and it
may be better to think of the MCMC calculation as a
mechanism for calculating an interval that in intention is not
much different from a classical CI.  Douglas, is this heresy?

The demands of journals
~~~~~~~~~~~~~~~~~~~
At the end of the day, there may sometimes have to be
concessions to editorial rigidity.  But let's at least try for
more accommodating approaches, noting that we can
often easily do what was not possible even a decade
ago.  No-one is talking about forcing anything on
anyone, as I read the discussion.

With respect to effect estimates and SEs, surely these
are CIs, maybe 68% CIs, in different dress.  They may
be preferable to CIs if effects are commonly much larger
than the relevant SE, say at least 4 times as large.

A better way?
~~~~~~~~~~
I am not committed to defending p-values or CIs, or
Bayesian rough equivalents.  There's not, though, going
to be much movement until there is broad agreement on
good alternatives (or, more likely, on a smorgasbord of
good alternatives) in the statistical community, and those
alternatives are implemented in readily accessible software.

Douglas's mcmcsamp() has advanced the state of the art
for multi-level models, offering an approach that had not
previously been readily available.  It is anyone's guess
where it, and statistics and graphs that it makes readily
possible, will in the course of time fit among styles of
presentation that application area people find helpful.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


On 7 Apr 2008, at 12:05 PM, David Henderson wrote:

> Hi John:
>
>> For all practical purposes, a CI is just the Bayesian credible  
>> interval that one gets with some suitable "non-informative prior".   
>> Why not then be specific about the prior, and go with the Bayesian  
>> credible interval?  (There is an issue whether such a prior can  
>> always be found.  Am right in judging this no practical consequence?)
>
>
> What?  Could you explain this a little more?  There is nothing  
> Bayesian about a classical (i.e. not Bayesian credible set or  
> highest posterior density, or whatever terminology you prefer) CI.   
> The interpretation is completely different, and the assumptions used  
> in deriving the interval are also different.  Even though the  
> interval created when using a noninformative prior is similar to a  
> classical CI, they are not the same entity.
>
> Now, while i agree with the arguments about p-values and their  
> validity, there is one aspect missing from this discussion.  When  
> creating a general use package like lme4, we are trying to create  
> software that enables statisticians and researchers to perform the  
> statistical analyses they need and interpret the results in ways  
> that HELP them get published.  While I admire Doug for "drawing a  
> line in the sand" in regard to the use of p-values in published  
> research, this is counter to HELPING the researcher publish their  
> results.  There has to be a better way to further your point in the  
> community than FORCING your point upon them.  Education of the next  
> generation of researchers and journal editors is admittedly slow,  
> but a much more community friendly way of getting your point used in  
> practice.
>
> Just my $0.02...
>
> Dave H
> --
> David Henderson, Ph.D.
> Director of Community
> REvolution Computing
> 1100 Dexter Avenue North, Suite 250
> 206-577-4778 x3203
> DNADave at Revolution-Computing.Com
> http://www.revolution-computing.com
>



From dnadave at revolution-computing.com  Mon Apr  7 04:05:45 2008
From: dnadave at revolution-computing.com (David Henderson)
Date: Sun, 6 Apr 2008 19:05:45 -0700
Subject: [R-sig-ME] Fwd: same old question - lme4 and p-values
In-Reply-To: <33C9BCEB-6C3A-4CD4-8FE4-E4CEE240A2F5@anu.edu.au>
References: <28642179.2370001207304657364.JavaMail.nabble@isper.nabble.com>
	<40e66e0b0804040554m41e63d58l3a5825924696cf78@mail.gmail.com>
	<40e66e0b0804040633k619803fayfd2e9b9b07b88b77@mail.gmail.com>
	<2A882A0D-B7AC-43CB-970C-F009D334DA3D@MUOhio.edu>
	<aefe4d0a0804050310q1bd57ec6n8abf01a0e6e248d@mail.gmail.com>
	<20080405112119.GA22390@psych.upenn.edu>
	<18423.31454.209907.1456@cmath-5.math.ethz.ch>
	<33C9BCEB-6C3A-4CD4-8FE4-E4CEE240A2F5@anu.edu.au>
Message-ID: <58FA8AD3-6C19-4830-8427-EF4946AFEA9C@Revolution-Computing.Com>

Hi John:

> For all practical purposes, a CI is just the Bayesian credible  
> interval that one gets with some suitable "non-informative prior".   
> Why not then be specific about the prior, and go with the Bayesian  
> credible interval?  (There is an issue whether such a prior can  
> always be found.  Am right in judging this no practical consequence?)


What?  Could you explain this a little more?  There is nothing  
Bayesian about a classical (i.e. not Bayesian credible set or highest  
posterior density, or whatever terminology you prefer) CI.  The  
interpretation is completely different, and the assumptions used in  
deriving the interval are also different.  Even though the interval  
created when using a noninformative prior is similar to a classical  
CI, they are not the same entity.

Now, while i agree with the arguments about p-values and their  
validity, there is one aspect missing from this discussion.  When  
creating a general use package like lme4, we are trying to create  
software that enables statisticians and researchers to perform the  
statistical analyses they need and interpret the results in ways that  
HELP them get published.  While I admire Doug for "drawing a line in  
the sand" in regard to the use of p-values in published research, this  
is counter to HELPING the researcher publish their results.  There has  
to be a better way to further your point in the community than FORCING  
your point upon them.  Education of the next generation of researchers  
and journal editors is admittedly slow, but a much more community  
friendly way of getting your point used in practice.

Just my $0.02...

Dave H
--
David Henderson, Ph.D.
Director of Community
REvolution Computing
1100 Dexter Avenue North, Suite 250
206-577-4778 x3203
DNADave at Revolution-Computing.Com
http://www.revolution-computing.com



From bates at stat.wisc.edu  Mon Apr  7 15:13:33 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 7 Apr 2008 08:13:33 -0500
Subject: [R-sig-ME] Fwd: same old question - lme4 and p-values
In-Reply-To: <58FA8AD3-6C19-4830-8427-EF4946AFEA9C@Revolution-Computing.Com>
References: <28642179.2370001207304657364.JavaMail.nabble@isper.nabble.com>
	<40e66e0b0804040554m41e63d58l3a5825924696cf78@mail.gmail.com>
	<40e66e0b0804040633k619803fayfd2e9b9b07b88b77@mail.gmail.com>
	<2A882A0D-B7AC-43CB-970C-F009D334DA3D@MUOhio.edu>
	<aefe4d0a0804050310q1bd57ec6n8abf01a0e6e248d@mail.gmail.com>
	<20080405112119.GA22390@psych.upenn.edu>
	<18423.31454.209907.1456@cmath-5.math.ethz.ch>
	<33C9BCEB-6C3A-4CD4-8FE4-E4CEE240A2F5@anu.edu.au>
	<58FA8AD3-6C19-4830-8427-EF4946AFEA9C@Revolution-Computing.Com>
Message-ID: <40e66e0b0804070613q65a2cbbao2976d8a48e9964cb@mail.gmail.com>

On Sun, Apr 6, 2008 at 9:05 PM, David Henderson
<dnadave at revolution-computing.com> wrote:
> Hi John:

>  > For all practical purposes, a CI is just the Bayesian credible
>  > interval that one gets with some suitable "non-informative prior".
>  > Why not then be specific about the prior, and go with the Bayesian
>  > credible interval?  (There is an issue whether such a prior can
>  > always be found.  Am right in judging this no practical consequence?)

>  What?  Could you explain this a little more?  There is nothing
>  Bayesian about a classical (i.e. not Bayesian credible set or highest
>  posterior density, or whatever terminology you prefer) CI.  The
>  interpretation is completely different, and the assumptions used in
>  deriving the interval are also different.  Even though the interval
>  created when using a noninformative prior is similar to a classical
>  CI, they are not the same entity.

>  Now, while i agree with the arguments about p-values and their
>  validity, there is one aspect missing from this discussion.  When
>  creating a general use package like lme4, we are trying to create
>  software that enables statisticians and researchers to perform the
>  statistical analyses they need and interpret the results in ways that
>  HELP them get published.  While I admire Doug for "drawing a line in
>  the sand" in regard to the use of p-values in published research, this
>  is counter to HELPING the researcher publish their results.  There has
>  to be a better way to further your point in the community than FORCING
>  your point upon them.  Education of the next generation of researchers
>  and journal editors is admittedly slow, but a much more community
>  friendly way of getting your point used in practice.

Perhaps I should clarify.  The summary of a fitted lmer model does not
provide p-values because I don't know how to calculate them in an
acceptable way, not because I am philosophically opposed to them.  The
estimates and the approximate standard errors can be readily
calculated as can their ratio.  The problem is determining the
appropriate reference distribution for that ratio from which to
calculate a p-value.  In fixed-effects models (under the "usual"
assumptions) that ratio is distributed as a T with a certain number of
degrees of freedom.  For mixed models it is not clear exactly what
distribution it has - except in certain cases of completely balanced
data sets (i.e. the sort of data sets that occur in text books).  At
one time I used a T distribution and an upper bound on the degrees of
freedom but I was persuaded that providing p-values that could be
strongly "anti-conservative" is worse than not providing any.

That decision not to provide p-values is particularly inconvenient to
many users who are not especially interested in statistical niceties
but do need to satisfy editors or referees who want to see p-values.
I know that is a real problem.  My earlier comment about having
created a monster that now turns on us, which touched off this line of
discussion, was more about the fact that we try to take complex
analyses and reduce the conclusions from them to a single number, the
p-value. We can provide considerable information about the models that
are fit to the experimenter's data but without p-values the
experimenter may be unable to publish the results.

The approach that I feel is most likely to be successful in
summarizing these models is first to obtain the REML or ML estimates
of the parameters then to run a Markov chain Monte Carlo sampler to
assess the variability in the parameters (or, if you prefer, the
variability in the parameter estimators).  (Note: I am not advocating
using MCMC to obtain the estimates, I suggest MCMC for assessing the
variability.)

The current version of the mcmcsamp function suffers from the
practical problem that it gets stuck at near-zero values of variance
components.  There are some approaches to dealing with that.  Over the
weekend I thought that I had a devastatingly simple way of dealing
with such cases until I reflected on it a bit more and realized that
it would require a division by zero.  Other than that, it was a good
idea.

The practical problem with the mcmcsamp function at present is th

>  Just my $0.02...
>
>  Dave H
>  --
>  David Henderson, Ph.D.
>  Director of Community
>  REvolution Computing
>  1100 Dexter Avenue North, Suite 250
>  206-577-4778 x3203
>  DNADave at Revolution-Computing.Com
>  http://www.revolution-computing.com
>
>
>
>  _______________________________________________
>  R-sig-mixed-models at r-project.org mailing list
>  https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From Andreas.Nord at zooekol.lu.se  Mon Apr  7 15:16:33 2008
From: Andreas.Nord at zooekol.lu.se (Andreas Nord)
Date: Mon, 07 Apr 2008 15:16:33 +0200
Subject: [R-sig-ME] Fwd: same old question - lme4 and p-values
Message-ID: <5618be562d58.562d585618be@net.lu.se>

Thank you all on the mailing list for much appreciated and valuable advice. I will explore my different options to see how it works out!

Once again, thank you!

Andreas 

=============================
Andreas Nord 
Department of Animal Ecology
Lund university
Ecology building
SE-223 62 Lund
Sweden
 
Phone: +46462223177
Cell: +46704953262
Fax: +46462224716 
E-mail: Andreas.Nord at zooekol.lu.se

----- Original Message -----
From: Douglas Bates <bates at stat.wisc.edu>
Date: Sunday, April 6, 2008 5:15 pm
Subject: Re: [R-sig-ME] Fwd: same old question - lme4 and p-values

> On Sat, Apr 5, 2008 at 5:10 AM, Reinhold Kliegl
> <reinhold.kliegl at gmail.com> wrote:
> > Here is a section that worked in Kliegl, Risse, & Laubrock 
> (2007, J
> >  Exp Psychol:Human Perception and Performance, 33, 1250-1251).
> >
> >  "Analysis
> >      Inferential statistics are based on a linear mixed-effects 
> model>  (lme) specifying participants and items as crossed random 
> effects.>  This analysis takes into account differences between 
> participants and
> >  differences between items in a single sweep and has been shown to
> >  suffer substantially less loss of statistical power in unbalanced
> >  designs than traditional ANOVAs over participants (F1) and 
> items (F2;
> >  see Baayen, in press, Pinheiro & Bates, 2000; Quen? & van den 
> Bergh,>  2004, for simulations).
> >     We used the lmer program (lme4 package; Bates & Sarkar, 
> 2006) in
> >  the R system for statistical computing (R Development Core 
> Team, 2006)
> >  and report regression coefficients (b; absolute effect size in ms),
> >  standard errors (SE), and p-values for an upper-bound n of 
> denominator>  degrees of freedom computed as n of observations 
> minus n of fixed
> >  effects. As these p-values are potentially anti-conservative, we
> >  generated confidence intervals from the posterior distribution of
> >  parameter estimates with Markov Chain Monte Carlo methods, 
> using the
> >  mcmcsamp program in the lme4 package with default specifications
> >  (e.g., n=1000 samples; locally uniform priors for fixed effects;
> >  locally non-informative priors for random effects). Both procedures
> >  yielded the same results.
> >     Finally, we also computed post-hoc power statistics for the
> >  preview and lexical status main effects and for the interaction 
> effect>  on first fixation durations (with effect sizes similar to 
> those>  reported earlier, e.g., Kliegl, 2007), and using lme 
> estimates of
> >  between-participant, between-item, and residual variances 
> (Gelman &
> >  Hill, in press). For the observed proportion of random loss of 
> items,>  power estimates based on 1000 simulations each were 
> around .85 for
> >  word n and n+2 and .59 for word n+1 (due to the higher skipping
> >  rate)."  (page 1251)
> >
> >  Power statistics were included in response to a reviewer 
> request. I am
> >  not much in favor of post-hoc power statistics; but note that here
> >  they are restricted to the use of estimates of random effects. For
> >  reviewers, we also included traditional F1- and F2-ANOVA 
> tables; they
> >  are not part of the article. In other articles, it has also been
> >  acceptable to report coefficients, their standard errors, and their
> >  ratio, and to say that coefficients larger than 2 SE are 
> interpreted>  as significant (e.g., Kliegl, 2007, J Exp Psychol: 
> General, 136,
> >  530-537), that is, it is possible to leave out p-values completely.
> >
> >  Corrections and improvements of the above sentences are highly 
> welcome>  for future articles. In perspective, I think the p-value 
> problem will
> >  simply go away.
> >
> >  Best
> >  Reinhold
> >
> >  PS: Would it be useful to have a site where peer-reviewed articles
> >  using lme4 for statistical inference are listed and, possibly,
> >  retrievable versions are provided?
> 
> Thanks for the suggestion, Reinhold.  I would be delighted to provide
> a page on http://lme4.r-forge.r-project.org/ to list such references.
> 
> May I ask for a volunteer to maintain such a listing?  I am rather
> overextended at present trying to get lme4_1.0-0 out and writing a
> book about what it does.  All that is required is to obtain a R-forge
> login, decide how to organize the pages and then update the pages as
> new references are submitted.
>



From spluque at gmail.com  Mon Apr  7 15:49:10 2008
From: spluque at gmail.com (Sebastian P. Luque)
Date: Mon, 07 Apr 2008 08:49:10 -0500
Subject: [R-sig-ME] random effects specification
References: <87abkak6qa.fsf@patagonia.sebmags.homelinux.org>
	<40e66e0b0804031532q12880b01mcba6173fc3e32c10@mail.gmail.com>
	<878wzuzf94.fsf@patagonia.sebmags.homelinux.org>
	<40e66e0b0804040517w3602b3dch6e6d5c7d53f33eb@mail.gmail.com>
	<87ve2xydmh.fsf@patagonia.sebmags.homelinux.org>
	<75A3A990-0E70-4BDB-A44D-2BA011ADEA8C@kagi.com>
	<40e66e0b0804060804g494f8f59i5307444fc581227d@mail.gmail.com>
	<3D4A6791-2368-412E-A62E-BD10EFD5DA91@kagi.com>
Message-ID: <87prt1ojvt.fsf@patagonia.sebmags.homelinux.org>

Hi,

Fortunately, I have learnt to use unique factor levels for subjects,
only as a lucky accident though, but am glad it's a good convention to
use in mixed models.

Thanks everyone for your useful feedback, this has been very instructive!


Cheers,

-- 
Seb



From bates at stat.wisc.edu  Mon Apr  7 18:29:50 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 7 Apr 2008 11:29:50 -0500
Subject: [R-sig-ME] Simulating linear mixed models - the Venables approach
Message-ID: <40e66e0b0804070929q250f3805qaf128754c6b5f89d@mail.gmail.com>

In case you missed it on the R-help list, I urge readers of this list
to consider the understated elegance of the code Bill Venables posted
for simulating data from a simple random effects model.

> set.seed(7658943)
>
> fph <- 0.4
> Sigh <- sqrt(0.0002)
> Sigi <- sqrt(0.04)
>
> reH <- rnorm(90, fph, Sigh)  ## hospid effects
> dta <- within(expand.grid(hospid = 1:90, empid = 1:80),
           fpi1 <- reH[hospid] + rnorm(7200, fph, Sigi))

One is reminded of John Keats

 'Beauty is truth, truth beauty,?that is all	
 Ye know on earth, and all ye need to know.'



From kubovy at virginia.edu  Mon Apr  7 19:34:05 2008
From: kubovy at virginia.edu (Michael Kubovy)
Date: Mon, 7 Apr 2008 13:34:05 -0400
Subject: [R-sig-ME] lmer syntax
Message-ID: <7A6681AD-8293-40FC-BCAB-FA8CFC9B6D50@virginia.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080407/09a79033/attachment.pl>

From bates at stat.wisc.edu  Mon Apr  7 19:59:51 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 7 Apr 2008 12:59:51 -0500
Subject: [R-sig-ME] lmer syntax
In-Reply-To: <7A6681AD-8293-40FC-BCAB-FA8CFC9B6D50@virginia.edu>
References: <7A6681AD-8293-40FC-BCAB-FA8CFC9B6D50@virginia.edu>
Message-ID: <40e66e0b0804071059p10cc9380x18c76dc44c005215@mail.gmail.com>

On Mon, Apr 7, 2008 at 12:34 PM, Michael Kubovy <kubovy at virginia.edu> wrote:
> Dear lme4 folk,

> The lmer help page gives two examples:
>  (fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
> (fm2 <- lmer(Reaction ~ Days + (1|Subject) + (0+Days|Subject), sleepstudy))
> How is the following different, in principle, from the above? Is it that the
> above treats (Intercept) and Days as orthogonal, whereas the latter checks
> to see if they are? What would be appropriate if the correlation between
> Days and Intercept (here 0.067, apparently) were large?
> (fm3 <- lmer(Reaction ~ Days + (1 + Days | Subject), sleepstudy))

Model fm3 is equivalent to model fm1.  In the linear model formula
language used in the S language, the intercept term is implicit so the
random-effects term (Days|Subject) is equivalent to (1+Days|Subject).
Some authors, notably Gelman and Hill in their 2007 book, prefer to
use the second form so that the presence of the intercept is explicit.
 I can see the point of that.

Every random effect is associated with one and only one random-effects
term in the model formula and with one and only one level of the
grouping factor for that random-effects term.  The general rules for
determining the variance-covariance of the random effects (as fit in
lmer) are:

 - random effects associated with different terms are independent
 - random effects associated with the same term but with different
levels of the grouping factor are independent
 - within a term the random effects may be partitioned according to
the levels of the grouping factor.  The variance-covariance matrix of
the vector of random effects associated with each of these levels of
the grouping factor is a constant, symmetric, positive semidefinite
matrix.  It has no additional constraints other than being symmetric
and positive semidefinite.  (In SAS-speak this is called an
"unstructured" variance-covariance matrix but the mathematician in me
refuses to accept the concept of an unstructured, symmetic, positive
semidefinite matrix.)

(Note that when I refer to "levels" in the above description I am
referring to the S-language concept of the levels of a factor, not
levels of random effects in the sense of multilevel models.)

In practice the difference between the two models is that fm2 is a
restricted form of fm1/fm3 in which the correlation of the random
effects has been set to zero.

> ?????
> Random effects:
> Groups Name Variance Std.Dev. Corr
> Subject (Intercept) 610.8 24.72
>  Days 35.1 5.92 0.067
> Residual 655.1 25.59
>
>
>
> _____________________________
> Professor Michael Kubovy
> University of Virginia
> Department of Psychology
> USPS:     P.O.Box 400400    Charlottesville, VA 22904-4400
> Parcels:    Room 102        Gilmer Hall
>         McCormick Road    Charlottesville, VA 22903
> Office:    B011    +1-434-982-4729
> Lab:        B019    +1-434-982-4751
> Fax:        +1-434-982-4766
> WWW:    http://www.people.virginia.edu/~mk9y/
>
>



From s.blomberg1 at uq.edu.au  Tue Apr  8 01:36:45 2008
From: s.blomberg1 at uq.edu.au (Simon Blomberg)
Date: Tue, 08 Apr 2008 09:36:45 +1000
Subject: [R-sig-ME] Fwd: same old question - lme4 and p-values
In-Reply-To: <58FA8AD3-6C19-4830-8427-EF4946AFEA9C@Revolution-Computing.Com>
References: <28642179.2370001207304657364.JavaMail.nabble@isper.nabble.com>
	<40e66e0b0804040554m41e63d58l3a5825924696cf78@mail.gmail.com>
	<40e66e0b0804040633k619803fayfd2e9b9b07b88b77@mail.gmail.com>
	<2A882A0D-B7AC-43CB-970C-F009D334DA3D@MUOhio.edu>
	<aefe4d0a0804050310q1bd57ec6n8abf01a0e6e248d@mail.gmail.com>
	<20080405112119.GA22390@psych.upenn.edu>
	<18423.31454.209907.1456@cmath-5.math.ethz.ch>
	<33C9BCEB-6C3A-4CD4-8FE4-E4CEE240A2F5@anu.edu.au>
	<58FA8AD3-6C19-4830-8427-EF4946AFEA9C@Revolution-Computing.Com>
Message-ID: <1207611405.23040.3.camel@sib-sblomber01d.sib.uq.edu.au>

On Sun, 2008-04-06 at 19:05 -0700, David Henderson wrote:
> Hi John:
> 
> > For all practical purposes, a CI is just the Bayesian credible  
> > interval that one gets with some suitable "non-informative prior".   
> > Why not then be specific about the prior, and go with the Bayesian  
> > credible interval?  (There is an issue whether such a prior can  
> > always be found.  Am right in judging this no practical consequence?)
> 
> 
> What?  Could you explain this a little more?  There is nothing  
> Bayesian about a classical (i.e. not Bayesian credible set or highest  
> posterior density, or whatever terminology you prefer) CI.  The  
> interpretation is completely different, and the assumptions used in  
> deriving the interval are also different.  Even though the interval  
> created when using a noninformative prior is similar to a classical  
> CI, they are not the same entity.
> 
> Now, while i agree with the arguments about p-values and their  
> validity, there is one aspect missing from this discussion.  When  
> creating a general use package like lme4, we are trying to create  
> software that enables statisticians and researchers to perform the  
> statistical analyses they need and interpret the results in ways that  
> HELP them get published. 

Well, that's only one reason for R's existence.

>  While I admire Doug for "drawing a line in  
> the sand" in regard to the use of p-values in published research, this  
> is counter to HELPING the researcher publish their results. 
>  There has  
> to be a better way to further your point in the community than FORCING  
> your point upon them.  Education of the next generation of researchers  
> and journal editors is admittedly slow, but a much more community  
> friendly way of getting your point used in practice.

?
If you don't like Doug's software, don't use it! Or since the code is
open source, hack it so it does what YOU want. Nobody is forcing
anything on you.

> 
> Just my $0.02...

Mine too. :-)

> 
> Dave H
> --
> David Henderson, Ph.D.
> Director of Community
> REvolution Computing
> 1100 Dexter Avenue North, Suite 250
> 206-577-4778 x3203
> DNADave at Revolution-Computing.Com
> http://www.revolution-computing.com
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
-- 
Simon Blomberg, BSc (Hons), PhD, MAppStat. 
Lecturer and Consultant Statistician 
Faculty of Biological and Chemical Sciences 
The University of Queensland 
St. Lucia Queensland 4072 
Australia
Room 320 Goddard Building (8)
T: +61 7 3365 2506
http://www.uq.edu.au/~uqsblomb
email: S.Blomberg1_at_uq.edu.au

Policies:
1.  I will NOT analyse your data for you.
2.  Your deadline is your problem.

The combination of some data and an aching desire for 
an answer does not ensure that a reasonable answer can 
be extracted from a given body of data. - John Tukey.



From s.blomberg1 at uq.edu.au  Tue Apr  8 01:46:02 2008
From: s.blomberg1 at uq.edu.au (Simon Blomberg)
Date: Tue, 08 Apr 2008 09:46:02 +1000
Subject: [R-sig-ME] Fwd: same old question - lme4 and p-values
In-Reply-To: <BDE434F6-B2C0-40A9-BAE8-824E4A6B7268@anu.edu.au>
References: <28642179.2370001207304657364.JavaMail.nabble@isper.nabble.com>
	<40e66e0b0804040554m41e63d58l3a5825924696cf78@mail.gmail.com>
	<40e66e0b0804040633k619803fayfd2e9b9b07b88b77@mail.gmail.com>
	<2A882A0D-B7AC-43CB-970C-F009D334DA3D@MUOhio.edu>
	<aefe4d0a0804050310q1bd57ec6n8abf01a0e6e248d@mail.gmail.com>
	<20080405112119.GA22390@psych.upenn.edu>
	<18423.31454.209907.1456@cmath-5.math.ethz.ch>
	<33C9BCEB-6C3A-4CD4-8FE4-E4CEE240A2F5@anu.edu.au>
	<58FA8AD3-6C19-4830-8427-EF4946AFEA9C@Revolution-Computing.Com>
	<BDE434F6-B2C0-40A9-BAE8-824E4A6B7268@anu.edu.au>
Message-ID: <1207611962.23040.9.camel@sib-sblomber01d.sib.uq.edu.au>

On Mon, 2008-04-07 at 20:47 +1000, John Maindonald wrote:
[ snip ]
> 
> Douglas's mcmcsamp() has advanced the state of the art
> for multi-level models, offering an approach that had not
> previously been readily available.  It is anyone's guess
> where it, and statistics and graphs that it makes readily
> possible, will in the course of time fit among styles of
> presentation that application area people find helpful.

Well, it's been possible to easily implement multi-level models in BUGS
using MCMC for a long time. Would you agree that BUGS is readily
available? :-) Doug has made it more convenient for R users, but I'm not
sure it has necessarily advanced the state of the art. Maybe brought R
up to speed (but ahead of other software which tends to start with the
letter S).

Simon.

> 
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> 
> 
> On 7 Apr 2008, at 12:05 PM, David Henderson wrote:
> 
> > Hi John:
> >
> >> For all practical purposes, a CI is just the Bayesian credible  
> >> interval that one gets with some suitable "non-informative prior".   
> >> Why not then be specific about the prior, and go with the Bayesian  
> >> credible interval?  (There is an issue whether such a prior can  
> >> always be found.  Am right in judging this no practical consequence?)
> >
> >
> > What?  Could you explain this a little more?  There is nothing  
> > Bayesian about a classical (i.e. not Bayesian credible set or  
> > highest posterior density, or whatever terminology you prefer) CI.   
> > The interpretation is completely different, and the assumptions used  
> > in deriving the interval are also different.  Even though the  
> > interval created when using a noninformative prior is similar to a  
> > classical CI, they are not the same entity.
> >
> > Now, while i agree with the arguments about p-values and their  
> > validity, there is one aspect missing from this discussion.  When  
> > creating a general use package like lme4, we are trying to create  
> > software that enables statisticians and researchers to perform the  
> > statistical analyses they need and interpret the results in ways  
> > that HELP them get published.  While I admire Doug for "drawing a  
> > line in the sand" in regard to the use of p-values in published  
> > research, this is counter to HELPING the researcher publish their  
> > results.  There has to be a better way to further your point in the  
> > community than FORCING your point upon them.  Education of the next  
> > generation of researchers and journal editors is admittedly slow,  
> > but a much more community friendly way of getting your point used in  
> > practice.
> >
> > Just my $0.02...
> >
> > Dave H
> > --
> > David Henderson, Ph.D.
> > Director of Community
> > REvolution Computing
> > 1100 Dexter Avenue North, Suite 250
> > 206-577-4778 x3203
> > DNADave at Revolution-Computing.Com
> > http://www.revolution-computing.com
> >
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
-- 
Simon Blomberg, BSc (Hons), PhD, MAppStat. 
Lecturer and Consultant Statistician 
Faculty of Biological and Chemical Sciences 
The University of Queensland 
St. Lucia Queensland 4072 
Australia
Room 320 Goddard Building (8)
T: +61 7 3365 2506
http://www.uq.edu.au/~uqsblomb
email: S.Blomberg1_at_uq.edu.au

Policies:
1.  I will NOT analyse your data for you.
2.  Your deadline is your problem.

The combination of some data and an aching desire for 
an answer does not ensure that a reasonable answer can 
be extracted from a given body of data. - John Tukey.



From John.Maindonald at anu.edu.au  Tue Apr  8 02:25:13 2008
From: John.Maindonald at anu.edu.au (John Maindonald)
Date: Tue, 8 Apr 2008 10:25:13 +1000
Subject: [R-sig-ME] Fwd: same old question - lme4 and p-values
In-Reply-To: <1207611962.23040.9.camel@sib-sblomber01d.sib.uq.edu.au>
References: <28642179.2370001207304657364.JavaMail.nabble@isper.nabble.com>
	<40e66e0b0804040554m41e63d58l3a5825924696cf78@mail.gmail.com>
	<40e66e0b0804040633k619803fayfd2e9b9b07b88b77@mail.gmail.com>
	<2A882A0D-B7AC-43CB-970C-F009D334DA3D@MUOhio.edu>
	<aefe4d0a0804050310q1bd57ec6n8abf01a0e6e248d@mail.gmail.com>
	<20080405112119.GA22390@psych.upenn.edu>
	<18423.31454.209907.1456@cmath-5.math.ethz.ch>
	<33C9BCEB-6C3A-4CD4-8FE4-E4CEE240A2F5@anu.edu.au>
	<58FA8AD3-6C19-4830-8427-EF4946AFEA9C@Revolution-Computing.Com>
	<BDE434F6-B2C0-40A9-BAE8-824E4A6B7268@anu.edu.au>
	<1207611962.23040.9.camel@sib-sblomber01d.sib.uq.edu.au>
Message-ID: <16B9D71F-3074-466C-96CB-FCF611B79C6E@anu.edu.au>

Well, I may have been a bit carried away!

BUGS is though a bit different, surely. Estimation is done from
the beginning in a Bayesian framework.  It had not occurred to
me. till mcmcsamp() came along, that one could do use classical
estimates, and then graft an MCMC calculation on the end to
get posterior density estimates.  Purists may think this hybrid
approach not quite kosher. I'd expect that it would be problematic
if a highly informative prior was used in the MCMC calculation
(is that correct?).

Note however that a prior is chosen that makes the calculation
relatively straightforward.

I presume this hybrid approach is a lot less expensive,
computationally, than Bayesian MCMC estimation of parameters
as well as posterior densities?

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


On 8 Apr 2008, at 9:46 AM, Simon Blomberg wrote:

> On Mon, 2008-04-07 at 20:47 +1000, John Maindonald wrote:
> [ snip ]
>>
>> Douglas's mcmcsamp() has advanced the state of the art
>> for multi-level models, offering an approach that had not
>> previously been readily available.  It is anyone's guess
>> where it, and statistics and graphs that it makes readily
>> possible, will in the course of time fit among styles of
>> presentation that application area people find helpful.
>
> Well, it's been possible to easily implement multi-level models in  
> BUGS
> using MCMC for a long time. Would you agree that BUGS is readily
> available? :-) Doug has made it more convenient for R users, but I'm  
> not
> sure it has necessarily advanced the state of the art. Maybe brought R
> up to speed (but ahead of other software which tends to start with the
> letter S).
>
> Simon.
>
>>
>> John Maindonald             email: john.maindonald at anu.edu.au
>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>> Centre for Mathematics & Its Applications, Room 1194,
>> John Dedman Mathematical Sciences Building (Building 27)
>> Australian National University, Canberra ACT 0200.
>>
>>
>> On 7 Apr 2008, at 12:05 PM, David Henderson wrote:
>>
>>> Hi John:
>>>
>>>> For all practical purposes, a CI is just the Bayesian credible
>>>> interval that one gets with some suitable "non-informative prior".
>>>> Why not then be specific about the prior, and go with the Bayesian
>>>> credible interval?  (There is an issue whether such a prior can
>>>> always be found.  Am right in judging this no practical  
>>>> consequence?)
>>>
>>>
>>> What?  Could you explain this a little more?  There is nothing
>>> Bayesian about a classical (i.e. not Bayesian credible set or
>>> highest posterior density, or whatever terminology you prefer) CI.
>>> The interpretation is completely different, and the assumptions used
>>> in deriving the interval are also different.  Even though the
>>> interval created when using a noninformative prior is similar to a
>>> classical CI, they are not the same entity.
>>>
>>> Now, while i agree with the arguments about p-values and their
>>> validity, there is one aspect missing from this discussion.  When
>>> creating a general use package like lme4, we are trying to create
>>> software that enables statisticians and researchers to perform the
>>> statistical analyses they need and interpret the results in ways
>>> that HELP them get published.  While I admire Doug for "drawing a
>>> line in the sand" in regard to the use of p-values in published
>>> research, this is counter to HELPING the researcher publish their
>>> results.  There has to be a better way to further your point in the
>>> community than FORCING your point upon them.  Education of the next
>>> generation of researchers and journal editors is admittedly slow,
>>> but a much more community friendly way of getting your point used in
>>> practice.
>>>
>>> Just my $0.02...
>>>
>>> Dave H
>>> --
>>> David Henderson, Ph.D.
>>> Director of Community
>>> REvolution Computing
>>> 1100 Dexter Avenue North, Suite 250
>>> 206-577-4778 x3203
>>> DNADave at Revolution-Computing.Com
>>> http://www.revolution-computing.com
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> -- 
> Simon Blomberg, BSc (Hons), PhD, MAppStat.
> Lecturer and Consultant Statistician
> Faculty of Biological and Chemical Sciences
> The University of Queensland
> St. Lucia Queensland 4072
> Australia
> Room 320 Goddard Building (8)
> T: +61 7 3365 2506
> http://www.uq.edu.au/~uqsblomb
> email: S.Blomberg1_at_uq.edu.au
>
> Policies:
> 1.  I will NOT analyse your data for you.
> 2.  Your deadline is your problem.
>
> The combination of some data and an aching desire for
> an answer does not ensure that a reasonable answer can
> be extracted from a given body of data. - John Tukey.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From jebyrnes at ucdavis.edu  Tue Apr  8 02:45:22 2008
From: jebyrnes at ucdavis.edu (Jarrett Byrnes)
Date: Mon, 7 Apr 2008 17:45:22 -0700
Subject: [R-sig-ME] Fwd: same old question - lme4 and p-values
In-Reply-To: <1207611962.23040.9.camel@sib-sblomber01d.sib.uq.edu.au>
References: <28642179.2370001207304657364.JavaMail.nabble@isper.nabble.com>
	<40e66e0b0804040554m41e63d58l3a5825924696cf78@mail.gmail.com>
	<40e66e0b0804040633k619803fayfd2e9b9b07b88b77@mail.gmail.com>
	<2A882A0D-B7AC-43CB-970C-F009D334DA3D@MUOhio.edu>
	<aefe4d0a0804050310q1bd57ec6n8abf01a0e6e248d@mail.gmail.com>
	<20080405112119.GA22390@psych.upenn.edu>
	<18423.31454.209907.1456@cmath-5.math.ethz.ch>
	<33C9BCEB-6C3A-4CD4-8FE4-E4CEE240A2F5@anu.edu.au>
	<58FA8AD3-6C19-4830-8427-EF4946AFEA9C@Revolution-Computing.Com>
	<BDE434F6-B2C0-40A9-BAE8-824E4A6B7268@anu.edu.au>
	<1207611962.23040.9.camel@sib-sblomber01d.sib.uq.edu.au>
Message-ID: <6A693E8E-B4C3-4C75-8913-6A9C711034D3@ucdavis.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080407/757a8931/attachment.pl>

From s.blomberg1 at uq.edu.au  Tue Apr  8 03:01:52 2008
From: s.blomberg1 at uq.edu.au (Simon Blomberg)
Date: Tue, 08 Apr 2008 11:01:52 +1000
Subject: [R-sig-ME] Fwd: same old question - lme4 and p-values
In-Reply-To: <6A693E8E-B4C3-4C75-8913-6A9C711034D3@ucdavis.edu>
References: <28642179.2370001207304657364.JavaMail.nabble@isper.nabble.com>
	<40e66e0b0804040554m41e63d58l3a5825924696cf78@mail.gmail.com>
	<40e66e0b0804040633k619803fayfd2e9b9b07b88b77@mail.gmail.com>
	<2A882A0D-B7AC-43CB-970C-F009D334DA3D@MUOhio.edu>
	<aefe4d0a0804050310q1bd57ec6n8abf01a0e6e248d@mail.gmail.com>
	<20080405112119.GA22390@psych.upenn.edu>
	<18423.31454.209907.1456@cmath-5.math.ethz.ch>
	<33C9BCEB-6C3A-4CD4-8FE4-E4CEE240A2F5@anu.edu.au>
	<58FA8AD3-6C19-4830-8427-EF4946AFEA9C@Revolution-Computing.Com>
	<BDE434F6-B2C0-40A9-BAE8-824E4A6B7268@anu.edu.au>
	<1207611962.23040.9.camel@sib-sblomber01d.sib.uq.edu.au>
	<6A693E8E-B4C3-4C75-8913-6A9C711034D3@ucdavis.edu>
Message-ID: <1207616512.26305.3.camel@sib-sblomber01d.sib.uq.edu.au>

On Mon, 2008-04-07 at 17:45 -0700, Jarrett Byrnes wrote:
> On Apr 7, 2008, at 4:46 PM, Simon Blomberg wrote:
> 
> > On Mon, 2008-04-07 at 20:47 +1000, John Maindonald wrote:
> > [ snip ]
> >>
> >> Douglas's mcmcsamp() has advanced the state of the art
> >> for multi-level models, offering an approach that had not
> >> previously been readily available.  It is anyone's guess
> >> where it, and statistics and graphs that it makes readily
> >> possible, will in the course of time fit among styles of
> >> presentation that application area people find helpful.
> >
> > Well, it's been possible to easily implement multi-level models in  
> > BUGS
> > using MCMC for a long time. Would you agree that BUGS is readily
> > available? :-) Doug has made it more convenient for R users, but I'm  
> > not
> > sure it has necessarily advanced the state of the art. Maybe brought R
> > up to speed (but ahead of other software which tends to start with the
> > letter S).
> >
> > Simon.
> >
> 
> 
> But BUGS, JAGS, and their ilk require quite a bit of additional  
> coding. 

And R doesn't? Maybe you use Rcmdr? :-) Also users can specify models in
BUGS using DAGs, if coding is too scary an option.

>  This may not be ideal for a wide variety of users.  This is  
> not to mention the problems of prior specification, etc.  What would  
> be ideal (perhaps for lme4 1.1!) would be a model compiler that would  
> run using rbugs, rjags, or another package such as follows for a  
> random block effect:
> 
> my.model<-lmer(Response ~ Treatment + (1 | Block), data=my.data)
> 
> my.mcmc<-bugsMCMC(my.model)
> 
> Perhaps one could even specify priors and the like, if they wished.   
> One could also use this with R2WinBugs and other great packages that  
> are cropping up out there for Bayesian inference.
> 
> This would also take care of the large additional burden of coding in  
> BUGS, but, does also opens the door wide for mis-use of Bayes.  It's  
> also kind of a pie-in-the-sky, but I can dream.
> 
> -Jarrett
> 
> ----------------------------------------
> Jarrett Byrnes
> Population Biology Graduate Group, UC Davis
> Bodega Marine Lab
> 707-875-1969
> http://www-eve.ucdavis.edu/stachowicz/byrnes.shtml
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
-- 
Simon Blomberg, BSc (Hons), PhD, MAppStat. 
Lecturer and Consultant Statistician 
Faculty of Biological and Chemical Sciences 
The University of Queensland 
St. Lucia Queensland 4072 
Australia
Room 320 Goddard Building (8)
T: +61 7 3365 2506
http://www.uq.edu.au/~uqsblomb
email: S.Blomberg1_at_uq.edu.au

Policies:
1.  I will NOT analyse your data for you.
2.  Your deadline is your problem.

The combination of some data and an aching desire for 
an answer does not ensure that a reasonable answer can 
be extracted from a given body of data. - John Tukey.



From s.blomberg1 at uq.edu.au  Tue Apr  8 03:13:30 2008
From: s.blomberg1 at uq.edu.au (Simon Blomberg)
Date: Tue, 08 Apr 2008 11:13:30 +1000
Subject: [R-sig-ME] Fwd: same old question - lme4 and p-values
In-Reply-To: <16B9D71F-3074-466C-96CB-FCF611B79C6E@anu.edu.au>
References: <28642179.2370001207304657364.JavaMail.nabble@isper.nabble.com>
	<40e66e0b0804040554m41e63d58l3a5825924696cf78@mail.gmail.com>
	<40e66e0b0804040633k619803fayfd2e9b9b07b88b77@mail.gmail.com>
	<2A882A0D-B7AC-43CB-970C-F009D334DA3D@MUOhio.edu>
	<aefe4d0a0804050310q1bd57ec6n8abf01a0e6e248d@mail.gmail.com>
	<20080405112119.GA22390@psych.upenn.edu>
	<18423.31454.209907.1456@cmath-5.math.ethz.ch>
	<33C9BCEB-6C3A-4CD4-8FE4-E4CEE240A2F5@anu.edu.au>
	<58FA8AD3-6C19-4830-8427-EF4946AFEA9C@Revolution-Computing.Com>
	<BDE434F6-B2C0-40A9-BAE8-824E4A6B7268@anu.edu.au>
	<1207611962.23040.9.camel@sib-sblomber01d.sib.uq.edu.au>
	<16B9D71F-3074-466C-96CB-FCF611B79C6E@anu.edu.au>
Message-ID: <1207617210.26305.15.camel@sib-sblomber01d.sib.uq.edu.au>

On Tue, 2008-04-08 at 10:25 +1000, John Maindonald wrote:
> Well, I may have been a bit carried away!
> 
> BUGS is though a bit different, surely. Estimation is done from
> the beginning in a Bayesian framework.  It had not occurred to
> me. till mcmcsamp() came along, that one could do use classical
> estimates, and then graft an MCMC calculation on the end to
> get posterior density estimates.  Purists may think this hybrid
> approach not quite kosher.

MCMC is just a technique that can be used to solve integrals by
simulation. There is nothing intrinsically Bayesian about it. It's just
that complicated integrals necessarily crop up in Bayesian problems. I
think that you are right in that mcmcsamp would upset purists. Why
prefer ML or REML parameter estimates, but then derive a Bayesian
posterior density? But if you get a posterior density, you can get the
posterior mean, median or mode from that, and use that as your estimate
if you want to be more Bayesian.

>  I'd expect that it would be problematic
> if a highly informative prior was used in the MCMC calculation
> (is that correct?).

Only problematic for frequentists and likelihoodists. :-)

> 
> Note however that a prior is chosen that makes the calculation
> relatively straightforward.
> 
> I presume this hybrid approach is a lot less expensive,
> computationally, than Bayesian MCMC estimation of parameters
> as well as posterior densities?
> 
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> 
> 
> On 8 Apr 2008, at 9:46 AM, Simon Blomberg wrote:
> 
> > On Mon, 2008-04-07 at 20:47 +1000, John Maindonald wrote:
> > [ snip ]
> >>
> >> Douglas's mcmcsamp() has advanced the state of the art
> >> for multi-level models, offering an approach that had not
> >> previously been readily available.  It is anyone's guess
> >> where it, and statistics and graphs that it makes readily
> >> possible, will in the course of time fit among styles of
> >> presentation that application area people find helpful.
> >
> > Well, it's been possible to easily implement multi-level models in  
> > BUGS
> > using MCMC for a long time. Would you agree that BUGS is readily
> > available? :-) Doug has made it more convenient for R users, but I'm  
> > not
> > sure it has necessarily advanced the state of the art. Maybe brought R
> > up to speed (but ahead of other software which tends to start with the
> > letter S).
> >
> > Simon.
> >
> >>
> >> John Maindonald             email: john.maindonald at anu.edu.au
> >> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> >> Centre for Mathematics & Its Applications, Room 1194,
> >> John Dedman Mathematical Sciences Building (Building 27)
> >> Australian National University, Canberra ACT 0200.
> >>
> >>
> >> On 7 Apr 2008, at 12:05 PM, David Henderson wrote:
> >>
> >>> Hi John:
> >>>
> >>>> For all practical purposes, a CI is just the Bayesian credible
> >>>> interval that one gets with some suitable "non-informative prior".
> >>>> Why not then be specific about the prior, and go with the Bayesian
> >>>> credible interval?  (There is an issue whether such a prior can
> >>>> always be found.  Am right in judging this no practical  
> >>>> consequence?)
> >>>
> >>>
> >>> What?  Could you explain this a little more?  There is nothing
> >>> Bayesian about a classical (i.e. not Bayesian credible set or
> >>> highest posterior density, or whatever terminology you prefer) CI.
> >>> The interpretation is completely different, and the assumptions used
> >>> in deriving the interval are also different.  Even though the
> >>> interval created when using a noninformative prior is similar to a
> >>> classical CI, they are not the same entity.
> >>>
> >>> Now, while i agree with the arguments about p-values and their
> >>> validity, there is one aspect missing from this discussion.  When
> >>> creating a general use package like lme4, we are trying to create
> >>> software that enables statisticians and researchers to perform the
> >>> statistical analyses they need and interpret the results in ways
> >>> that HELP them get published.  While I admire Doug for "drawing a
> >>> line in the sand" in regard to the use of p-values in published
> >>> research, this is counter to HELPING the researcher publish their
> >>> results.  There has to be a better way to further your point in the
> >>> community than FORCING your point upon them.  Education of the next
> >>> generation of researchers and journal editors is admittedly slow,
> >>> but a much more community friendly way of getting your point used in
> >>> practice.
> >>>
> >>> Just my $0.02...
> >>>
> >>> Dave H
> >>> --
> >>> David Henderson, Ph.D.
> >>> Director of Community
> >>> REvolution Computing
> >>> 1100 Dexter Avenue North, Suite 250
> >>> 206-577-4778 x3203
> >>> DNADave at Revolution-Computing.Com
> >>> http://www.revolution-computing.com
> >>>
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > -- 
> > Simon Blomberg, BSc (Hons), PhD, MAppStat.
> > Lecturer and Consultant Statistician
> > Faculty of Biological and Chemical Sciences
> > The University of Queensland
> > St. Lucia Queensland 4072
> > Australia
> > Room 320 Goddard Building (8)
> > T: +61 7 3365 2506
> > http://www.uq.edu.au/~uqsblomb
> > email: S.Blomberg1_at_uq.edu.au
> >
> > Policies:
> > 1.  I will NOT analyse your data for you.
> > 2.  Your deadline is your problem.
> >
> > The combination of some data and an aching desire for
> > an answer does not ensure that a reasonable answer can
> > be extracted from a given body of data. - John Tukey.
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
-- 
Simon Blomberg, BSc (Hons), PhD, MAppStat. 
Lecturer and Consultant Statistician 
Faculty of Biological and Chemical Sciences 
The University of Queensland 
St. Lucia Queensland 4072 
Australia
Room 320 Goddard Building (8)
T: +61 7 3365 2506
http://www.uq.edu.au/~uqsblomb
email: S.Blomberg1_at_uq.edu.au

Policies:
1.  I will NOT analyse your data for you.
2.  Your deadline is your problem.

The combination of some data and an aching desire for 
an answer does not ensure that a reasonable answer can 
be extracted from a given body of data. - John Tukey.



From dnadavenator at gmail.com  Tue Apr  8 04:18:08 2008
From: dnadavenator at gmail.com (David Henderson)
Date: Mon, 7 Apr 2008 19:18:08 -0700
Subject: [R-sig-ME] Fwd: same old question - lme4 and p-values
In-Reply-To: <40e66e0b0804070613q65a2cbbao2976d8a48e9964cb@mail.gmail.com>
References: <28642179.2370001207304657364.JavaMail.nabble@isper.nabble.com>
	<40e66e0b0804040554m41e63d58l3a5825924696cf78@mail.gmail.com>
	<40e66e0b0804040633k619803fayfd2e9b9b07b88b77@mail.gmail.com>
	<2A882A0D-B7AC-43CB-970C-F009D334DA3D@MUOhio.edu>
	<aefe4d0a0804050310q1bd57ec6n8abf01a0e6e248d@mail.gmail.com>
	<20080405112119.GA22390@psych.upenn.edu>
	<18423.31454.209907.1456@cmath-5.math.ethz.ch>
	<33C9BCEB-6C3A-4CD4-8FE4-E4CEE240A2F5@anu.edu.au>
	<58FA8AD3-6C19-4830-8427-EF4946AFEA9C@Revolution-Computing.Com>
	<40e66e0b0804070613q65a2cbbao2976d8a48e9964cb@mail.gmail.com>
Message-ID: <F1DA7F8D-9722-4D38-A064-56A1111C1367@GMail.Com>

Hi Doug:

> Perhaps I should clarify.  The summary of a fitted lmer model does not
> provide p-values because I don't know how to calculate them in an
> acceptable way, not because I am philosophically opposed to them.  The
> estimates and the approximate standard errors can be readily
> calculated as can their ratio.  The problem is determining the
> appropriate reference distribution for that ratio from which to
> calculate a p-value.  In fixed-effects models (under the "usual"
> assumptions) that ratio is distributed as a T with a certain number of
> degrees of freedom.  For mixed models it is not clear exactly what
> distribution it has - except in certain cases of completely balanced
> data sets (i.e. the sort of data sets that occur in text books).  At
> one time I used a T distribution and an upper bound on the degrees of
> freedom but I was persuaded that providing p-values that could be
> strongly "anti-conservative" is worse than not providing any.

Now I understand the situation better and am in agreement that this is  
clearly the right solution at this point.

> The approach that I feel is most likely to be successful in
> summarizing these models is first to obtain the REML or ML estimates
> of the parameters then to run a Markov chain Monte Carlo sampler to
> assess the variability in the parameters (or, if you prefer, the
> variability in the parameter estimators).  (Note: I am not advocating
> using MCMC to obtain the estimates, I suggest MCMC for assessing the
> variability.)

I'm a little confused as to what is the Monte Carlo part of this  
scenario?  If you perform REML or ML, theoretically it should always  
converge to the REML/ML estimates (unless you have a flat or  
multimodal likelihood which each produce other problems).  I  
understand you are fixing the parameter estimates of something at the  
REML/ML estimates, but what is the random component?

Of course, I could always stop being lazy and just look at the  
source... ;^)

> The current version of the mcmcsamp function suffers from the
> practical problem that it gets stuck at near-zero values of variance
> components.  There are some approaches to dealing with that.  Over the
> weekend I thought that I had a devastatingly simple way of dealing
> with such cases until I reflected on it a bit more and realized that
> it would require a division by zero.  Other than that, it was a good
> idea.

At least the variance estimates were not negative... ;^)

Thanks!!

Dave H
--
David Henderson, Ph.D.
Director of Community
REvolution Computing
1100 Dexter Avenue North, Suite 250
206-577-4778 x3203
DNADave at Revolution-Computing.Com
http://www.revolution-computing.com



From lamprianou at yahoo.com  Tue Apr  8 07:46:46 2008
From: lamprianou at yahoo.com (Iasonas Lamprianou)
Date: Mon, 7 Apr 2008 22:46:46 -0700 (PDT)
Subject: [R-sig-ME] Introductory texts
Message-ID: <139589.17374.qm@web54105.mail.re2.yahoo.com>

Dear all,
there is a very large silent majority which struggles to follow your sophisticated thoughts and discussions. We need a definite answer to the old question: those of us that are very comfortable with the multiple  linear regression but know very few things about mixed-effects models, need introductory texts with EXAMPLES but not many maths to help us RUN mixed effects models,  INTERPRET their results and TEST their fit. Is it possible that any one of you out there who plans to write (or is currently writing) a book on running mixed models in R may uses some of us as pilot-testers of their text, so that we gain some early info until we manage to buy it? In any case, we could even help anyone with such aspirations by providing our own examples, datasets etc from several different disciplines, so that the book will attract people from various disciplines and has an increased audience. 

Just a few ideas
 
Dr. Iasonas Lamprianou
Department of Education
The University of Manchester
Oxford Road, Manchester M13 9PL, UK
Tel. 0044 161 275 3485
iasonas.lamprianou at manchester.ac.uk


----- Original Message ----
From: "r-sig-mixed-models-request at r-project.org" <r-sig-mixed-models-request at r-project.org>
To: r-sig-mixed-models at r-project.org
Sent: Tuesday, 8 April, 2008 3:25:37 AM
Subject: R-sig-mixed-models Digest, Vol 16, Issue 21

Send R-sig-mixed-models mailing list submissions to
    r-sig-mixed-models at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
    https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
or, via email, send a message with subject or body 'help' to
    r-sig-mixed-models-request at r-project.org

You can reach the person managing the list at
    r-sig-mixed-models-owner at r-project.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-mixed-models digest..."


Today's Topics:

  1. Simulating linear mixed models - the Venables approach
      (Douglas Bates)
  2. lmer syntax (Michael Kubovy)
  3. Re: lmer syntax (Douglas Bates)
  4. Re: Fwd: same old question - lme4 and p-values (Simon Blomberg)
  5. Re: Fwd: same old question - lme4 and p-values (Simon Blomberg)
  6. Re: Fwd: same old question - lme4 and p-values (John Maindonald)


----------------------------------------------------------------------

Message: 1
Date: Mon, 7 Apr 2008 11:29:50 -0500
From: "Douglas Bates" <bates at stat.wisc.edu>
Subject: [R-sig-ME] Simulating linear mixed models - the Venables
    approach
To: "R Mixed Models" <r-sig-mixed-models at r-project.org>
Message-ID:
    <40e66e0b0804070929q250f3805qaf128754c6b5f89d at mail.gmail.com>
Content-Type: text/plain; charset=WINDOWS-1252

In case you missed it on the R-help list, I urge readers of this list
to consider the understated elegance of the code Bill Venables posted
for simulating data from a simple random effects model.

> set.seed(7658943)
>
> fph <- 0.4
> Sigh <- sqrt(0.0002)
> Sigi <- sqrt(0.04)
>
> reH <- rnorm(90, fph, Sigh)  ## hospid effects
> dta <- within(expand.grid(hospid = 1:90, empid = 1:80),
          fpi1 <- reH[hospid] + rnorm(7200, fph, Sigi))

One is reminded of John Keats

'Beauty is truth, truth beauty,?that is all    
Ye know on earth, and all ye need to know.'



------------------------------

Message: 2
Date: Mon, 7 Apr 2008 13:34:05 -0400
From: Michael Kubovy <kubovy at virginia.edu>
Subject: [R-sig-ME] lmer syntax
To: R Mixed Models <r-sig-mixed-models at r-project.org>
Message-ID: <7A6681AD-8293-40FC-BCAB-FA8CFC9B6D50 at virginia.edu>
Content-Type: text/plain

Dear lme4 folk,

The lmer help page gives two examples:
(fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
(fm2 <- lmer(Reaction ~ Days + (1|Subject) + (0+Days|Subject),  
sleepstudy))
How is the following different, in principle, from the above? Is it  
that the above treats (Intercept) and Days as orthogonal, whereas the  
latter checks to see if they are? What would be appropriate if the  
correlation between Days and Intercept (here 0.067, apparently) were  
large?
(fm3 <- lmer(Reaction ~ Days + (1 + Days | Subject), sleepstudy))
?????
Random effects:
Groups Name Variance Std.Dev. Corr
Subject (Intercept) 610.8 24.72
    Days 35.1 5.92 0.067
Residual 655.1 25.59
_____________________________
Professor Michael Kubovy
University of Virginia
Department of Psychology
USPS:    P.O.Box 400400    Charlottesville, VA 22904-4400
Parcels:    Room 102        Gilmer Hall
        McCormick Road    Charlottesville, VA 22903
Office:    B011    +1-434-982-4729
Lab:        B019    +1-434-982-4751
Fax:        +1-434-982-4766
WWW:    http://www.people.virginia.edu/~mk9y/



    [[alternative HTML version deleted]]



------------------------------

Message: 3
Date: Mon, 7 Apr 2008 12:59:51 -0500
From: "Douglas Bates" <bates at stat.wisc.edu>
Subject: Re: [R-sig-ME] lmer syntax
To: "Michael Kubovy" <kubovy at virginia.edu>
Cc: R Mixed Models <r-sig-mixed-models at r-project.org>
Message-ID:
    <40e66e0b0804071059p10cc9380x18c76dc44c005215 at mail.gmail.com>
Content-Type: text/plain; charset=WINDOWS-1252

On Mon, Apr 7, 2008 at 12:34 PM, Michael Kubovy <kubovy at virginia.edu> wrote:
> Dear lme4 folk,

> The lmer help page gives two examples:
>  (fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
> (fm2 <- lmer(Reaction ~ Days + (1|Subject) + (0+Days|Subject), sleepstudy))
> How is the following different, in principle, from the above? Is it that the
> above treats (Intercept) and Days as orthogonal, whereas the latter checks
> to see if they are? What would be appropriate if the correlation between
> Days and Intercept (here 0.067, apparently) were large?
> (fm3 <- lmer(Reaction ~ Days + (1 + Days | Subject), sleepstudy))

Model fm3 is equivalent to model fm1.  In the linear model formula
language used in the S language, the intercept term is implicit so the
random-effects term (Days|Subject) is equivalent to (1+Days|Subject).
Some authors, notably Gelman and Hill in their 2007 book, prefer to
use the second form so that the presence of the intercept is explicit.
I can see the point of that.

Every random effect is associated with one and only one random-effects
term in the model formula and with one and only one level of the
grouping factor for that random-effects term.  The general rules for
determining the variance-covariance of the random effects (as fit in
lmer) are:

- random effects associated with different terms are independent
- random effects associated with the same term but with different
levels of the grouping factor are independent
- within a term the random effects may be partitioned according to
the levels of the grouping factor.  The variance-covariance matrix of
the vector of random effects associated with each of these levels of
the grouping factor is a constant, symmetric, positive semidefinite
matrix.  It has no additional constraints other than being symmetric
and positive semidefinite.  (In SAS-speak this is called an
"unstructured" variance-covariance matrix but the mathematician in me
refuses to accept the concept of an unstructured, symmetic, positive
semidefinite matrix.)

(Note that when I refer to "levels" in the above description I am
referring to the S-language concept of the levels of a factor, not
levels of random effects in the sense of multilevel models.)

In practice the difference between the two models is that fm2 is a
restricted form of fm1/fm3 in which the correlation of the random
effects has been set to zero.

> ?????
> Random effects:
> Groups Name Variance Std.Dev. Corr
> Subject (Intercept) 610.8 24.72
>  Days 35.1 5.92 0.067
> Residual 655.1 25.59
>
>
>
> _____________________________
> Professor Michael Kubovy
> University of Virginia
> Department of Psychology
> USPS:    P.O.Box 400400    Charlottesville, VA 22904-4400
> Parcels:    Room 102        Gilmer Hall
>        McCormick Road    Charlottesville, VA 22903
> Office:    B011    +1-434-982-4729
> Lab:        B019    +1-434-982-4751
> Fax:        +1-434-982-4766
> WWW:    http://www.people.virginia.edu/~mk9y/
>
>



------------------------------

Message: 4
Date: Tue, 08 Apr 2008 09:36:45 +1000
From: Simon Blomberg <s.blomberg1 at uq.edu.au>
Subject: Re: [R-sig-ME] Fwd: same old question - lme4 and p-values
To: David Henderson <dnadave at revolution-computing.com>
Cc: R Mixed Models <r-sig-mixed-models at r-project.org>,    Martin Maechler
    <maechler at stat.math.ethz.ch>
Message-ID: <1207611405.23040.3.camel at sib-sblomber01d.sib.uq.edu.au>
Content-Type: text/plain; charset=utf-8

On Sun, 2008-04-06 at 19:05 -0700, David Henderson wrote:
> Hi John:
> 
> > For all practical purposes, a CI is just the Bayesian credible  
> > interval that one gets with some suitable "non-informative prior".  
> > Why not then be specific about the prior, and go with the Bayesian  
> > credible interval?  (There is an issue whether such a prior can  
> > always be found.  Am right in judging this no practical consequence?)
> 
> 
> What?  Could you explain this a little more?  There is nothing  
> Bayesian about a classical (i.e. not Bayesian credible set or highest  
> posterior density, or whatever terminology you prefer) CI.  The  
> interpretation is completely different, and the assumptions used in  
> deriving the interval are also different.  Even though the interval  
> created when using a noninformative prior is similar to a classical  
> CI, they are not the same entity.
> 
> Now, while i agree with the arguments about p-values and their  
> validity, there is one aspect missing from this discussion.  When  
> creating a general use package like lme4, we are trying to create  
> software that enables statisticians and researchers to perform the  
> statistical analyses they need and interpret the results in ways that  
> HELP them get published. 

Well, that's only one reason for R's existence.

>  While I admire Doug for "drawing a line in  
> the sand" in regard to the use of p-values in published research, this  
> is counter to HELPING the researcher publish their results. 
>  There has  
> to be a better way to further your point in the community than FORCING  
> your point upon them.  Education of the next generation of researchers  
> and journal editors is admittedly slow, but a much more community  
> friendly way of getting your point used in practice.

?
If you don't like Doug's software, don't use it! Or since the code is
open source, hack it so it does what YOU want. Nobody is forcing
anything on you.

> 
> Just my $0.02...

Mine too. :-)

> 
> Dave H
> --
> David Henderson, Ph.D.
> Director of Community
> REvolution Computing
> 1100 Dexter Avenue North, Suite 250
> 206-577-4778 x3203
> DNADave at Revolution-Computing.Com
> http://www.revolution-computing.com
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
-- 
Simon Blomberg, BSc (Hons), PhD, MAppStat. 
Lecturer and Consultant Statistician 
Faculty of Biological and Chemical Sciences 
The University of Queensland 
St. Lucia Queensland 4072 
Australia
Room 320 Goddard Building (8)
T: +61 7 3365 2506
http://www.uq.edu.au/~uqsblomb
email: S.Blomberg1_at_uq.edu.au

Policies:
1.  I will NOT analyse your data for you.
2.  Your deadline is your problem.

The combination of some data and an aching desire for 
an answer does not ensure that a reasonable answer can 
be extracted from a given body of data. - John Tukey.



------------------------------

Message: 5
Date: Tue, 08 Apr 2008 09:46:02 +1000
From: Simon Blomberg <s.blomberg1 at uq.edu.au>
Subject: Re: [R-sig-ME] Fwd: same old question - lme4 and p-values
To: John Maindonald <John.Maindonald at anu.edu.au>
Cc: R Mixed Models <r-sig-mixed-models at r-project.org>,    David Henderson
    <dnadave at revolution-computing.com>,    Martin Maechler
    <maechler at stat.math.ethz.ch>
Message-ID: <1207611962.23040.9.camel at sib-sblomber01d.sib.uq.edu.au>
Content-Type: text/plain

On Mon, 2008-04-07 at 20:47 +1000, John Maindonald wrote:
[ snip ]
> 
> Douglas's mcmcsamp() has advanced the state of the art
> for multi-level models, offering an approach that had not
> previously been readily available.  It is anyone's guess
> where it, and statistics and graphs that it makes readily
> possible, will in the course of time fit among styles of
> presentation that application area people find helpful.

Well, it's been possible to easily implement multi-level models in BUGS
using MCMC for a long time. Would you agree that BUGS is readily
available? :-) Doug has made it more convenient for R users, but I'm not
sure it has necessarily advanced the state of the art. Maybe brought R
up to speed (but ahead of other software which tends to start with the
letter S).

Simon.

> 
> John Maindonald            email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> 
> 
> On 7 Apr 2008, at 12:05 PM, David Henderson wrote:
> 
> > Hi John:
> >
> >> For all practical purposes, a CI is just the Bayesian credible  
> >> interval that one gets with some suitable "non-informative prior".  
> >> Why not then be specific about the prior, and go with the Bayesian  
> >> credible interval?  (There is an issue whether such a prior can  
> >> always be found.  Am right in judging this no practical consequence?)
> >
> >
> > What?  Could you explain this a little more?  There is nothing  
> > Bayesian about a classical (i.e. not Bayesian credible set or  
> > highest posterior density, or whatever terminology you prefer) CI.  
> > The interpretation is completely different, and the assumptions used  
> > in deriving the interval are also different.  Even though the  
> > interval created when using a noninformative prior is similar to a  
> > classical CI, they are not the same entity.
> >
> > Now, while i agree with the arguments about p-values and their  
> > validity, there is one aspect missing from this discussion.  When  
> > creating a general use package like lme4, we are trying to create  
> > software that enables statisticians and researchers to perform the  
> > statistical analyses they need and interpret the results in ways  
> > that HELP them get published.  While I admire Doug for "drawing a  
> > line in the sand" in regard to the use of p-values in published  
> > research, this is counter to HELPING the researcher publish their  
> > results.  There has to be a better way to further your point in the  
> > community than FORCING your point upon them.  Education of the next  
> > generation of researchers and journal editors is admittedly slow,  
> > but a much more community friendly way of getting your point used in  
> > practice.
> >
> > Just my $0.02...
> >
> > Dave H
> > --
> > David Henderson, Ph.D.
> > Director of Community
> > REvolution Computing
> > 1100 Dexter Avenue North, Suite 250
> > 206-577-4778 x3203
> > DNADave at Revolution-Computing.Com
> > http://www.revolution-computing.com
> >
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
-- 
Simon Blomberg, BSc (Hons), PhD, MAppStat. 
Lecturer and Consultant Statistician 
Faculty of Biological and Chemical Sciences 
The University of Queensland 
St. Lucia Queensland 4072 
Australia
Room 320 Goddard Building (8)
T: +61 7 3365 2506
http://www.uq.edu.au/~uqsblomb
email: S.Blomberg1_at_uq.edu.au

Policies:
1.  I will NOT analyse your data for you.
2.  Your deadline is your problem.

The combination of some data and an aching desire for 
an answer does not ensure that a reasonable answer can 
be extracted from a given body of data. - John Tukey.



------------------------------

Message: 6
Date: Tue, 8 Apr 2008 10:25:13 +1000
From: John Maindonald <John.Maindonald at anu.edu.au>
Subject: Re: [R-sig-ME] Fwd: same old question - lme4 and p-values
To: Simon Blomberg <s.blomberg1 at uq.edu.au>
Cc: R Mixed Models <r-sig-mixed-models at r-project.org>,    David Henderson
    <dnadave at revolution-computing.com>,    Martin Maechler
    <maechler at stat.math.ethz.ch>
Message-ID: <16B9D71F-3074-466C-96CB-FCF611B79C6E at anu.edu.au>
Content-Type: text/plain; charset=US-ASCII; format=flowed; delsp=yes

Well, I may have been a bit carried away!

BUGS is though a bit different, surely. Estimation is done from
the beginning in a Bayesian framework.  It had not occurred to
me. till mcmcsamp() came along, that one could do use classical
estimates, and then graft an MCMC calculation on the end to
get posterior density estimates.  Purists may think this hybrid
approach not quite kosher. I'd expect that it would be problematic
if a highly informative prior was used in the MCMC calculation
(is that correct?).

Note however that a prior is chosen that makes the calculation
relatively straightforward.

I presume this hybrid approach is a lot less expensive,
computationally, than Bayesian MCMC estimation of parameters
as well as posterior densities?

John Maindonald            email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


On 8 Apr 2008, at 9:46 AM, Simon Blomberg wrote:

> On Mon, 2008-04-07 at 20:47 +1000, John Maindonald wrote:
> [ snip ]
>>
>> Douglas's mcmcsamp() has advanced the state of the art
>> for multi-level models, offering an approach that had not
>> previously been readily available.  It is anyone's guess
>> where it, and statistics and graphs that it makes readily
>> possible, will in the course of time fit among styles of
>> presentation that application area people find helpful.
>
> Well, it's been possible to easily implement multi-level models in  
> BUGS
> using MCMC for a long time. Would you agree that BUGS is readily
> available? :-) Doug has made it more convenient for R users, but I'm  
> not
> sure it has necessarily advanced the state of the art. Maybe brought R
> up to speed (but ahead of other software which tends to start with the
> letter S).
>
> Simon.
>
>>
>> John Maindonald            email: john.maindonald at anu.edu.au
>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>> Centre for Mathematics & Its Applications, Room 1194,
>> John Dedman Mathematical Sciences Building (Building 27)
>> Australian National University, Canberra ACT 0200.
>>
>>
>> On 7 Apr 2008, at 12:05 PM, David Henderson wrote:
>>
>>> Hi John:
>>>
>>>> For all practical purposes, a CI is just the Bayesian credible
>>>> interval that one gets with some suitable "non-informative prior".
>>>> Why not then be specific about the prior, and go with the Bayesian
>>>> credible interval?  (There is an issue whether such a prior can
>>>> always be found.  Am right in judging this no practical  
>>>> consequence?)
>>>
>>>
>>> What?  Could you explain this a little more?  There is nothing
>>> Bayesian about a classical (i.e. not Bayesian credible set or
>>> highest posterior density, or whatever terminology you prefer) CI.
>>> The interpretation is completely different, and the assumptions used
>>> in deriving the interval are also different.  Even though the
>>> interval created when using a noninformative prior is similar to a
>>> classical CI, they are not the same entity.
>>>
>>> Now, while i agree with the arguments about p-values and their
>>> validity, there is one aspect missing from this discussion.  When
>>> creating a general use package like lme4, we are trying to create
>>> software that enables statisticians and researchers to perform the
>>> statistical analyses they need and interpret the results in ways
>>> that HELP them get published.  While I admire Doug for "drawing a
>>> line in the sand" in regard to the use of p-values in published
>>> research, this is counter to HELPING the researcher publish their
>>> results.  There has to be a better way to further your point in the
>>> community than FORCING your point upon them.  Education of the next
>>> generation of researchers and journal editors is admittedly slow,
>>> but a much more community friendly way of getting your point used in
>>> practice.
>>>
>>> Just my $0.02...
>>>
>>> Dave H
>>> --
>>> David Henderson, Ph.D.
>>> Director of Community
>>> REvolution Computing
>>> 1100 Dexter Avenue North, Suite 250
>>> 206-577-4778 x3203
>>> DNADave at Revolution-Computing.Com
>>> http://www.revolution-computing.com
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> -- 
> Simon Blomberg, BSc (Hons), PhD, MAppStat.
> Lecturer and Consultant Statistician
> Faculty of Biological and Chemical Sciences
> The University of Queensland
> St. Lucia Queensland 4072
> Australia
> Room 320 Goddard Building (8)
> T: +61 7 3365 2506
> http://www.uq.edu.au/~uqsblomb
> email: S.Blomberg1_at_uq.edu.au
>
> Policies:
> 1.  I will NOT analyse your data for you.
> 2.  Your deadline is your problem.
>
> The combination of some data and an aching desire for
> an answer does not ensure that a reasonable answer can
> be extracted from a given body of data. - John Tukey.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



------------------------------

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


End of R-sig-mixed-models Digest, Vol 16, Issue 21
**************************************************


      ___________________________________________________________ 
Yahoo! For Good helps you make a difference  

http://uk.promotions.yahoo.com/forgood/



From lorenz.gygax at art.admin.ch  Tue Apr  8 08:54:36 2008
From: lorenz.gygax at art.admin.ch (lorenz.gygax at art.admin.ch)
Date: Tue, 8 Apr 2008 08:54:36 +0200
Subject: [R-sig-ME] Fwd: same old question - lme4 and p-values
Message-ID: <145C63777EF3ED41A5A99035845F7DD9D316E9@EVD-C8001.bk.evdad.admin.ch>

This is very nice, indeed:
to come back from a day out of office and finding one's own problem thoroughly discussed. The thread was a rewarding read.

Thank you, Martin, for bringing up my idea and stating it so succinctly. And many thanks to all the other contributors in the discussion. nlme, lme4 and this list help a lot again and again in getting results published reasonably (in respect to the statistical methods used and the presentation of results).

Lorenz
- 
Lorenz Gygax
Centre for proper housing of ruminants and pigs
Agroscope Reckenholz-T?nikon Research Station ART
T?nikon, CH-8356 Ettenhausen / Switzerland



From njbisaac at googlemail.com  Tue Apr  8 17:39:08 2008
From: njbisaac at googlemail.com (Nick Isaac)
Date: Tue, 8 Apr 2008 16:39:08 +0100
Subject: [R-sig-ME] Random or Fixed effects appropriate?
Message-ID: <a072ed700804080839r5e51d834n509e67ef6400f533@mail.gmail.com>

I would be grateful for some advice to help me fit the right model.
Specifically, I can't work out whether it's more appropriate to get
the answer I need from a random slopes model or by adding a fixed
interaction term.

My dataset has one continuous normally-distributed fixed effect and
four random effects that are nested (in fact, it is a taxonomy). For
simplicity, I've removed the variable names, so the dataset has the
following structure:

y ~ x | A/B/C/D

My hypothesis is that the relationship between x and y varies at
different levels of the taxonomy, but I have no a priori expectation
of which level would be most appropriate (i.e one or more of A, B, C
or D). The structure is very unbalanced, so I fit a series of mixed
models:

lmer( y ~ x + (1|A) + (1|B) + (1|C) + (1|D) )
lmer( y ~ x + (1|A) + (1|B) + (1|C) + (x|D) )
....
lmer( y ~ x + (x|A) + (x|B) + (x|C) + (x|D) )

and compared them using AIC. So far so good, I thought.

As the research has progressed, I have become interested in the actual
values of the slope between x and y at each level of the random
effects. So I extracted them:

coef( lmer( y ~ x + (1|A) + (1|B) + (x|C) + (1|D) ) )

I can plot these out and compare them with other attributes of random
effect C. But I'm treating the random effects as if they were
parameters, which feels like cheating. I've no idea if there is a
precedent for this: a quick look at the R-SIG-ME archive reveals that
folks do use coef(), but the context is rather different.

So I've also tried adding x:C as an interaction term in a fixed effect model:

lmer( y ~ x + (1|A) + (1|B) + (1|C) + (1|D) + C + x:C) #error:
Downdated X'X is not positive definite, 82
lmer( y ~ x + (1|A) + (1|B) + (1|C) + (1|D) + x:C) #gives sensible results

Parameter values for x:C are very close to the random effects. Some
extreme values have small samples and correspondingly large standard
errors. This is one reason why I like using the random effects:
shrinkage effectively gives them equal weight. But is this reasonable
or egregious?

I think this question reflects some flaw in my understanding, for
which I apologise. Any insights would be gratefully received.

Best wishes, Nick



From spluque at gmail.com  Tue Apr  8 18:22:30 2008
From: spluque at gmail.com (Sebastian P. Luque)
Date: Tue, 08 Apr 2008 11:22:30 -0500
Subject: [R-sig-ME] random effects specification
References: <87abkak6qa.fsf@patagonia.sebmags.homelinux.org>
	<40e66e0b0804031532q12880b01mcba6173fc3e32c10@mail.gmail.com>
	<878wzuzf94.fsf@patagonia.sebmags.homelinux.org>
	<40e66e0b0804040517w3602b3dch6e6d5c7d53f33eb@mail.gmail.com>
	<87ve2xydmh.fsf@patagonia.sebmags.homelinux.org>
	<75A3A990-0E70-4BDB-A44D-2BA011ADEA8C@kagi.com>
	<40e66e0b0804060804g494f8f59i5307444fc581227d@mail.gmail.com>
	<3D4A6791-2368-412E-A62E-BD10EFD5DA91@kagi.com>
	<87prt1ojvt.fsf@patagonia.sebmags.homelinux.org>
Message-ID: <87ve2s5nax.fsf@patagonia.sebmags.homelinux.org>

Hi,

I think I'm misunderstanding something because I expected a different
result below (building up a reproducible example).

---<---------------cut here---------------start-------------->---
## Simulating data
library(lattice)
library(lme4)
set.seed(1000)
rCom <- rnorm(2, mean=5, sd=0.5)
rTr <- rep(rCom / 1.1, 2)
nbase <- rnorm(240, 10, 0.1)
dta <- within(expand.grid(community=LETTERS[1:2], treatment=letters[1:4],
                          id=factor(1:30)), {
                              n <- rCom[as.numeric(community)] +
                                  rTr[as.numeric(treatment)] + nbase
                          })
dta <- dta[order(dta$community, dta$treatment), ]
## Simulate an interaction
dta$n[dta$community == "A"] <- rev(dta$n[dta$community == "A"])
## Have a look
xyplot(n ~ treatment | community, data=dta, groups=id,
       type="b", pch=19, cex=0.3)

## We fit LME with community and treatment fixed effects, their
## interactions, and use random effects for subject.
n.lmer1 <- lmer(n ~ community * treatment + (1 | id), dta)
## Remove the interaction, for comparison.
n.lmer2 <- lmer(n ~ community + treatment + (1 | id), dta)
## Compare these models.
anova(n.lmer1, n.lmer2)                 # interaction term needed

## So let's test the treatment effect at each community separately.
n.lmerA <- lmer(n ~ treatment + (1 | id), dta,
                subset=community == "A")
## Here I expected some terms to be significantly different
## from zero, but that's not the case:
summary(n.lmerA)
---<---------------cut here---------------end---------------->---

Looking at the data, there seems to be an obvious treatment effect, yet
this doesn't show in the lmer summary.  What am I misunderstanding here?
Thanks.


Cheers,

-- 
Seb



From bates at stat.wisc.edu  Tue Apr  8 18:53:04 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 8 Apr 2008 11:53:04 -0500
Subject: [R-sig-ME] Fwd: same old question - lme4 and p-values
In-Reply-To: <F1DA7F8D-9722-4D38-A064-56A1111C1367@GMail.Com>
References: <28642179.2370001207304657364.JavaMail.nabble@isper.nabble.com>
	<40e66e0b0804040633k619803fayfd2e9b9b07b88b77@mail.gmail.com>
	<2A882A0D-B7AC-43CB-970C-F009D334DA3D@MUOhio.edu>
	<aefe4d0a0804050310q1bd57ec6n8abf01a0e6e248d@mail.gmail.com>
	<20080405112119.GA22390@psych.upenn.edu>
	<18423.31454.209907.1456@cmath-5.math.ethz.ch>
	<33C9BCEB-6C3A-4CD4-8FE4-E4CEE240A2F5@anu.edu.au>
	<58FA8AD3-6C19-4830-8427-EF4946AFEA9C@Revolution-Computing.Com>
	<40e66e0b0804070613q65a2cbbao2976d8a48e9964cb@mail.gmail.com>
	<F1DA7F8D-9722-4D38-A064-56A1111C1367@GMail.Com>
Message-ID: <40e66e0b0804080953n2300d3a1hae1bdec633bb7dc4@mail.gmail.com>

On Mon, Apr 7, 2008 at 9:18 PM, David Henderson <dnadavenator at gmail.com> wrote:
> Hi Doug:

> > Perhaps I should clarify.  The summary of a fitted lmer model does not
> > provide p-values because I don't know how to calculate them in an
> > acceptable way, not because I am philosophically opposed to them.  The
> > estimates and the approximate standard errors can be readily
> > calculated as can their ratio.  The problem is determining the
> > appropriate reference distribution for that ratio from which to
> > calculate a p-value.  In fixed-effects models (under the "usual"
> > assumptions) that ratio is distributed as a T with a certain number of
> > degrees of freedom.  For mixed models it is not clear exactly what
> > distribution it has - except in certain cases of completely balanced
> > data sets (i.e. the sort of data sets that occur in text books).  At
> > one time I used a T distribution and an upper bound on the degrees of
> > freedom but I was persuaded that providing p-values that could be
> > strongly "anti-conservative" is worse than not providing any.

>  Now I understand the situation better and am in agreement that this is
> clearly the right solution at this point.

> > The approach that I feel is most likely to be successful in
> > summarizing these models is first to obtain the REML or ML estimates
> > of the parameters then to run a Markov chain Monte Carlo sampler to
> > assess the variability in the parameters (or, if you prefer, the
> > variability in the parameter estimators).  (Note: I am not advocating
> > using MCMC to obtain the estimates, I suggest MCMC for assessing the
> > variability.)

>  I'm a little confused as to what is the Monte Carlo part of this scenario?
> If you perform REML or ML, theoretically it should always converge to the
> REML/ML estimates (unless you have a flat or multimodal likelihood which
> each produce other problems).  I understand you are fixing the parameter
> estimates of something at the REML/ML estimates, but what is the random
> component?

Although the MCMC chain starts at the REML/ML estimates its iterations
are of the form

 - given the current residuals, sample a new value of $\sigma$ using a
random value from a $\chi^2$ distribution
 - given the current values of $\sigma$ and the variance-covariance of
the random effects, sample new values of the fixed-effects and the
random effects (in the Bayesian formulation both the fixed-effects
parameters and the random effects are regarded as random variables).
For a locally uniform prior on the fixed-effects this stage can be
reduced to sampling from a multivariate normal distribution.
 - given the current values of $\sigma$, the fixed effects, the
variance-covariance of the random effects and the random-effects
themselves sample from the distribution of the variance-covariance
parameters.
 - repeat the above three steps n times

It is the third step that gets tricky.  The "simple" approach is to
condition only on the values of the random effects and use a Wishart
distribution.  The problem with feedback is in steps 2 and 3.  If in
step 3 you happen to get a very small value of a variance component
then the next set of random effects sampled in step 2 will be small in
magnitude, resulting in the next sample of the variance component in
step 3 being very small, resulting in ...

I enclose a script to illustrate this effect using a model fit to data
from an experiment described in the classic book "Statistical Methods
in Research and Production" edited by O.L.Davies.  The "Yield"
variable is the amount of dyestuff in five different analyses of
samples from each of six different batches.  The REML estimates for a
simple random effects model reproduce the estimates of the variance
components shown in the book (there were at least 4 editions of the
book, the first in 1947, and all contain this example).  If you run
this script yourself and look at the plot of the samples from the
Bayesian posterior distribution of the 3 parameters versus the
iteration number for the MCMC sample, you will see the places where
the value of ST1, which is the standard deviation for batches divided
by the standard deviation for analyses within batch, gets stuck at
zero.  Those places also coincide with unusually large values of sigma
and attenuated variability of the distribution of the mean parameter.

(I don't enclose the plots because even the PDF files are very large
when you are plotting 10000 samples)

>  Of course, I could always stop being lazy and just look at the source...
> ;^)
>
>
>
> > The current version of the mcmcsamp function suffers from the
> > practical problem that it gets stuck at near-zero values of variance
> > components.  There are some approaches to dealing with that.  Over the
> > weekend I thought that I had a devastatingly simple way of dealing
> > with such cases until I reflected on it a bit more and realized that
> > it would require a division by zero.  Other than that, it was a good
> > idea.
> >
>
>  At least the variance estimates were not negative... ;^)
>
>  Thanks!!
>
>
>
>  Dave H
>  --
>  David Henderson, Ph.D.
>  Director of Community
>  REvolution Computing
>  1100 Dexter Avenue North, Suite 250
>  206-577-4778 x3203
>  DNADave at Revolution-Computing.Com
>  http://www.revolution-computing.com
>
>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Davies_R.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080408/7b69f7a7/attachment.txt>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Davies_Rout.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080408/7b69f7a7/attachment-0001.txt>

From reinhold.kliegl at gmail.com  Tue Apr  8 19:10:16 2008
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Tue, 8 Apr 2008 19:10:16 +0200
Subject: [R-sig-ME] Random or Fixed effects appropriate?
In-Reply-To: <a072ed700804080839r5e51d834n509e67ef6400f533@mail.gmail.com>
References: <a072ed700804080839r5e51d834n509e67ef6400f533@mail.gmail.com>
Message-ID: <aefe4d0a0804081010s11cfa43t40997786bd75d9a5@mail.gmail.com>

>  My dataset has one continuous normally-distributed fixed effect and
>  four random effects that are nested (in fact, it is a taxonomy). For
>  simplicity, I've removed the variable names, so the dataset has the
>  following structure:
>
>  y ~ x | A/B/C/D
It would be good to know how many units/levels you have for each of
your four random effects. Those with fewer than, say, five, are good
candidates for being specified as fixed effects. Think how many
observations you need to get a stable estimate of a variance!

>  lmer( y ~ x + (1|A) + (1|B) + (1|C) + (1|D) + C + x:C) #error:
>  Downdated X'X is not positive definite, 82
You cannot include C both as a random and a fixed effect

>  lmer( y ~ x + (1|A) + (1|B) + (1|C) + (1|D) + x:C) #gives sensible results
If this gives sensible results, I suspect you have very few levels of
C, say, 2 or 3?
In this case, definitely specify C and x and their interaction as
fixed effects, e.g.:
lmer( y ~ x*C + (1|A) + (1|B)  + (1|D)

The following may not apply to your case, but it might: Sometimes
people think that a nested/taxonomic design implies a random effect
structure (e.g., schools, classes, students). This is not true. If you
have only a few units for each factor, you are better off to specify
it as a fixed-effects rather than a random-effects taxonomy. (Of
course, you lose generalizability, but if you want this you should
make sure you have sample that provides a basis for it.) The
interpretation of conditional modes (formerly knowns as BLUPs, that is
"predictions") is a tricky business, especially with few units per
levels.

Reinhold



From reinhold.kliegl at gmail.com  Tue Apr  8 19:31:08 2008
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Tue, 8 Apr 2008 19:31:08 +0200
Subject: [R-sig-ME] random effects specification
In-Reply-To: <87ve2s5nax.fsf@patagonia.sebmags.homelinux.org>
References: <87abkak6qa.fsf@patagonia.sebmags.homelinux.org>
	<40e66e0b0804031532q12880b01mcba6173fc3e32c10@mail.gmail.com>
	<878wzuzf94.fsf@patagonia.sebmags.homelinux.org>
	<40e66e0b0804040517w3602b3dch6e6d5c7d53f33eb@mail.gmail.com>
	<87ve2xydmh.fsf@patagonia.sebmags.homelinux.org>
	<75A3A990-0E70-4BDB-A44D-2BA011ADEA8C@kagi.com>
	<40e66e0b0804060804g494f8f59i5307444fc581227d@mail.gmail.com>
	<3D4A6791-2368-412E-A62E-BD10EFD5DA91@kagi.com>
	<87prt1ojvt.fsf@patagonia.sebmags.homelinux.org>
	<87ve2s5nax.fsf@patagonia.sebmags.homelinux.org>
Message-ID: <aefe4d0a0804081031v28ebeac3t9d849213c4b1e954@mail.gmail.com>

Looking at your data, the lmer tells you very nicely the pattern of
means shown in your plot:

> (n.lmerA)
Linear mixed model fit by REML
Formula: n ~ treatment + (1 | id)
   Data: dta
 Subset: community == "A"
    AIC    BIC logLik deviance REMLdev
 -181.7 -164.9  96.83   -218.5  -193.7
Random effects:
 Groups   Name        Variance   Std.Dev.
          (Intercept) 5.5211e-13 7.4304e-07
 Residual             9.8079e-03 9.9035e-02
Number of obs: 120, groups: id, 30

Fixed effects:
            Estimate Std. Error t value
(Intercept) 18.78058    0.01808  1038.7
treatmentb   0.33300    0.02557    13.0
treatmentc   0.01150    0.02557     0.4
treatmentd   0.32939    0.02557    12.9

Treatment b is significanlty higher, c is at the same level, and d is
again significantly higher than treatment a. (With t-values of 13 we
may say that even without HPD intervals.)

The same is true for community B, except that here treatment b and d
are significantly lower than a and that what the estimates tell you.
If you learn how to combine estimates, you can derive the pattern of
means directly from your first analyses.

Reinhold


On Tue, Apr 8, 2008 at 6:22 PM, Sebastian P. Luque <spluque at gmail.com> wrote:
> Hi,
>
>  I think I'm misunderstanding something because I expected a different
>  result below (building up a reproducible example).
>
>  ---<---------------cut here---------------start-------------->---
>  ## Simulating data
>  library(lattice)
>  library(lme4)
>  set.seed(1000)
>  rCom <- rnorm(2, mean=5, sd=0.5)
>  rTr <- rep(rCom / 1.1, 2)
>  nbase <- rnorm(240, 10, 0.1)
>  dta <- within(expand.grid(community=LETTERS[1:2], treatment=letters[1:4],
>                           id=factor(1:30)), {
>                               n <- rCom[as.numeric(community)] +
>                                   rTr[as.numeric(treatment)] + nbase
>                           })
>  dta <- dta[order(dta$community, dta$treatment), ]
>  ## Simulate an interaction
>  dta$n[dta$community == "A"] <- rev(dta$n[dta$community == "A"])
>  ## Have a look
>  xyplot(n ~ treatment | community, data=dta, groups=id,
>        type="b", pch=19, cex=0.3)
>
>  ## We fit LME with community and treatment fixed effects, their
>  ## interactions, and use random effects for subject.
>  n.lmer1 <- lmer(n ~ community * treatment + (1 | id), dta)
>  ## Remove the interaction, for comparison.
>  n.lmer2 <- lmer(n ~ community + treatment + (1 | id), dta)
>  ## Compare these models.
>  anova(n.lmer1, n.lmer2)                 # interaction term needed
>
>  ## So let's test the treatment effect at each community separately.
>  n.lmerA <- lmer(n ~ treatment + (1 | id), dta,
>                 subset=community == "A")
>  ## Here I expected some terms to be significantly different
>  ## from zero, but that's not the case:
>  summary(n.lmerA)
>  ---<---------------cut here---------------end---------------->---
>
>  Looking at the data, there seems to be an obvious treatment effect, yet
>  this doesn't show in the lmer summary.  What am I misunderstanding here?
>  Thanks.
>
>
>
>
>  Cheers,
>
>  --
>  Seb
>
>  _______________________________________________
>  R-sig-mixed-models at r-project.org mailing list
>  https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From spluque at gmail.com  Tue Apr  8 20:13:17 2008
From: spluque at gmail.com (Sebastian P. Luque)
Date: Tue, 08 Apr 2008 13:13:17 -0500
Subject: [R-sig-ME] random effects specification
References: <87abkak6qa.fsf@patagonia.sebmags.homelinux.org>
	<40e66e0b0804031532q12880b01mcba6173fc3e32c10@mail.gmail.com>
	<878wzuzf94.fsf@patagonia.sebmags.homelinux.org>
	<40e66e0b0804040517w3602b3dch6e6d5c7d53f33eb@mail.gmail.com>
	<87ve2xydmh.fsf@patagonia.sebmags.homelinux.org>
	<75A3A990-0E70-4BDB-A44D-2BA011ADEA8C@kagi.com>
	<40e66e0b0804060804g494f8f59i5307444fc581227d@mail.gmail.com>
	<3D4A6791-2368-412E-A62E-BD10EFD5DA91@kagi.com>
	<87prt1ojvt.fsf@patagonia.sebmags.homelinux.org>
	<87ve2s5nax.fsf@patagonia.sebmags.homelinux.org>
	<aefe4d0a0804081031v28ebeac3t9d849213c4b1e954@mail.gmail.com>
Message-ID: <87iqys5i6a.fsf@patagonia.sebmags.homelinux.org>

On Tue, 8 Apr 2008 19:31:08 +0200,
"Reinhold Kliegl" <reinhold.kliegl at gmail.com> wrote:

[...]

> Treatment b is significanlty higher, c is at the same level, and d is
> again significantly higher than treatment a. (With t-values of 13 we
> may say that even without HPD intervals.)

Of course, what was I thinking!  Thanks.


> The same is true for community B, except that here treatment b and d
> are significantly lower than a and that what the estimates tell you.
> If you learn how to combine estimates, you can derive the pattern of
> means directly from your first analyses.

You mean using approaches as those used in estimable() from the gmodels
package?  If so, is that equivalent to doing a separate analysis for
each level of community with mixed models?  I think it isn't for fixed
effects only models.


Cheers,

-- 
Seb



From reinhold.kliegl at gmail.com  Tue Apr  8 21:47:04 2008
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Tue, 8 Apr 2008 21:47:04 +0200
Subject: [R-sig-ME] random effects specification
In-Reply-To: <87iqys5i6a.fsf@patagonia.sebmags.homelinux.org>
References: <87abkak6qa.fsf@patagonia.sebmags.homelinux.org>
	<40e66e0b0804040517w3602b3dch6e6d5c7d53f33eb@mail.gmail.com>
	<87ve2xydmh.fsf@patagonia.sebmags.homelinux.org>
	<75A3A990-0E70-4BDB-A44D-2BA011ADEA8C@kagi.com>
	<40e66e0b0804060804g494f8f59i5307444fc581227d@mail.gmail.com>
	<3D4A6791-2368-412E-A62E-BD10EFD5DA91@kagi.com>
	<87prt1ojvt.fsf@patagonia.sebmags.homelinux.org>
	<87ve2s5nax.fsf@patagonia.sebmags.homelinux.org>
	<aefe4d0a0804081031v28ebeac3t9d849213c4b1e954@mail.gmail.com>
	<87iqys5i6a.fsf@patagonia.sebmags.homelinux.org>
Message-ID: <aefe4d0a0804081247x1bdcaaa2u9661b8ebfbfde9d4@mail.gmail.com>

On Tue, Apr 8, 2008 at 8:13 PM, Sebastian P. Luque <spluque at gmail.com> wrote:
> On Tue, 8 Apr 2008 19:31:08 +0200,
>  "Reinhold Kliegl" <reinhold.kliegl at gmail.com> wrote:
>
>  [...]

>  > If you learn how to combine estimates, you can derive the pattern of
>  > means directly from your first analyses.
>
>  You mean using approaches as those used in estimable() from the gmodels
>  package?  If so, is that equivalent to doing a separate analysis for
>  each level of community with mixed models?  I think it isn't for fixed
>  effects only models.
>

> tapply(dta$n, list(dta$treatment, dta$community), mean)
          A            B
a 18.78058 18.74912
b 19.11358 18.38756
c 18.79208 18.73067
d 19.10998 18.40533

> (n.lmer1)
...
Fixed effects:
                      Estimate Std. Error t value
(Intercept)           18.78058    0.01784  1052.7
communityB            -0.03146    0.02523    -1.2
treatmentb             0.33300    0.02523    13.2
treatmentc             0.01150    0.02523     0.5
treatmentd             0.32939    0.02523    13.1
communityB:treatmentb -0.69456    0.03568   -19.5
communityB:treatmentc -0.02995    0.03568    -0.8
communityB:treatmentd -0.67318    0.03568   -18.9

You can reconstruct the table of means from the coefficients:
                      A                                                   B
a :  intercept                               intercept + communityB
b:   intercept + treatmentb          intercept + treatmentb +
communityB + communityB:treatmentb
c:   intercept + treatmentc          intercept + treatmentc +
communityB + communityB:treatmentc
d:   intercept + treatmentd          intercept + treatmentd +
communityB + communityB:treatmentd

This is a consequence of the default treatment contrasts associated
with factors as attributes.
> contrasts(dta$treatment)
  b c d
a 0 0 0
b 1 0 0
c 0 1 0
d 0 0 1

> contrasts(dta$community)
  B
A 0
B 1

You can change the default, that is specify your own contrasts as
factor attributes most flexibly via C (see ?C). lmer uses the factor
attribute (like, e.g.,  lm and other programs) and provides test
statistics for each of the contrasts (and their products).

Best
Reinhold



From spluque at gmail.com  Tue Apr  8 22:35:15 2008
From: spluque at gmail.com (Sebastian P. Luque)
Date: Tue, 08 Apr 2008 15:35:15 -0500
Subject: [R-sig-ME] random effects specification
References: <87abkak6qa.fsf@patagonia.sebmags.homelinux.org>
	<40e66e0b0804040517w3602b3dch6e6d5c7d53f33eb@mail.gmail.com>
	<87ve2xydmh.fsf@patagonia.sebmags.homelinux.org>
	<75A3A990-0E70-4BDB-A44D-2BA011ADEA8C@kagi.com>
	<40e66e0b0804060804g494f8f59i5307444fc581227d@mail.gmail.com>
	<3D4A6791-2368-412E-A62E-BD10EFD5DA91@kagi.com>
	<87prt1ojvt.fsf@patagonia.sebmags.homelinux.org>
	<87ve2s5nax.fsf@patagonia.sebmags.homelinux.org>
	<aefe4d0a0804081031v28ebeac3t9d849213c4b1e954@mail.gmail.com>
	<87iqys5i6a.fsf@patagonia.sebmags.homelinux.org>
	<aefe4d0a0804081247x1bdcaaa2u9661b8ebfbfde9d4@mail.gmail.com>
Message-ID: <873apw5blo.fsf@patagonia.sebmags.homelinux.org>

[sorry for the line wrap mangling]

On Tue, 8 Apr 2008 21:47:04 +0200,
"Reinhold Kliegl" <reinhold.kliegl at gmail.com> wrote:

[...]

> You can reconstruct the table of means from the coefficients: A B a :
> intercept intercept + communityB b: intercept + treatmentb intercept +
> treatmentb + communityB + communityB:treatmentb c: intercept +
> treatmentc intercept + treatmentc + communityB + communityB:treatmentc
> d: intercept + treatmentd intercept + treatmentd + communityB +
> communityB:treatmentd

Yes, but IIUC, this is not necessarily equivalent to fitting separate
models with subsets of the terms/levels.  Correct me if I'm wrong, but I
think the estimates will differ when the design is unbalanced (e.g. some
subjects not receiving all treatments) because a straight calculation
from the full model assumes the coefficients have equal weight.  For
this example data, the design is balanced, so this might not be a
problem.

Thanks,
-- 
Seb



From A.Robinson at ms.unimelb.edu.au  Tue Apr  8 22:56:05 2008
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Wed, 9 Apr 2008 06:56:05 +1000
Subject: [R-sig-ME] Random or Fixed effects appropriate?
In-Reply-To: <aefe4d0a0804081010s11cfa43t40997786bd75d9a5@mail.gmail.com>
References: <a072ed700804080839r5e51d834n509e67ef6400f533@mail.gmail.com>
	<aefe4d0a0804081010s11cfa43t40997786bd75d9a5@mail.gmail.com>
Message-ID: <20080408205605.GA1239@ms.unimelb.edu.au>

On Tue, Apr 08, 2008 at 07:10:16PM +0200, Reinhold Kliegl wrote:
> >  My dataset has one continuous normally-distributed fixed effect and
> >  four random effects that are nested (in fact, it is a taxonomy). For
> >  simplicity, I've removed the variable names, so the dataset has the
> >  following structure:
> >
> >  y ~ x | A/B/C/D
> It would be good to know how many units/levels you have for each of
> your four random effects. Those with fewer than, say, five, are good
> candidates for being specified as fixed effects. Think how many
> observations you need to get a stable estimate of a variance!
> 
> >  lmer( y ~ x + (1|A) + (1|B) + (1|C) + (1|D) + C + x:C) #error:
> >  Downdated X'X is not positive definite, 82
> You cannot include C both as a random and a fixed effect


I do not believe that this is generally true.  See, for example,

> require(lme4)
> (fm1 <- lmer(Reaction ~ Days + Subject + (Days|Subject),  sleepstudy))

Therefore I am uncertain as to how you can draw this conclusion
without more information about the design (which the poster really
should have provided).


> >  lmer( y ~ x + (1|A) + (1|B) + (1|C) + (1|D) + x:C) #gives sensible results
> If this gives sensible results, I suspect you have very few levels of
> C, say, 2 or 3?
> In this case, definitely specify C and x and their interaction as
> fixed effects, e.g.:
> lmer( y ~ x*C + (1|A) + (1|B)  + (1|D)
> 
> The following may not apply to your case, but it might: Sometimes
> people think that a nested/taxonomic design implies a random effect
> structure (e.g., schools, classes, students). This is not true. If you
> have only a few units for each factor, you are better off to specify
> it as a fixed-effects rather than a random-effects taxonomy. (Of
> course, you lose generalizability, but if you want this you should
> make sure you have sample that provides a basis for it.) 

I can see the sense behind this position but sometimes a few units are
all that is available, and including them in a model as fixed effects
muddies the statistical waters, especially if they are the kinds of
effects that a model user will be unlikely to naturally condition upon.  

I do agree that if there are problems with model fitting and/or
interpretation when the design is rigorously followed, then a more
flexible approach can and should be adopted, and appropriate
allowances must be made.

> The interpretation of conditional modes (formerly knowns as BLUPs,
> that is "predictions") is a tricky business, especially with few
> units per levels.

Sorry, I think I've missed something.  In what sense are the
conditional modes formerly known as BLUPs?

Andrew

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From reinhold.kliegl at gmail.com  Tue Apr  8 23:37:30 2008
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Tue, 8 Apr 2008 23:37:30 +0200
Subject: [R-sig-ME] Random or Fixed effects appropriate?
In-Reply-To: <20080408205605.GA1239@ms.unimelb.edu.au>
References: <a072ed700804080839r5e51d834n509e67ef6400f533@mail.gmail.com>
	<aefe4d0a0804081010s11cfa43t40997786bd75d9a5@mail.gmail.com>
	<20080408205605.GA1239@ms.unimelb.edu.au>
Message-ID: <aefe4d0a0804081437k7da862a5sa5fab66c84b17d0@mail.gmail.com>

Hi Andrew,

>  > >  lmer( y ~ x + (1|A) + (1|B) + (1|C) + (1|D) + C + x:C) #error:
>  > >  Downdated X'X is not positive definite, 82
>  > You cannot include C both as a random and a fixed effect
>
>
>  I do not believe that this is generally true.  See, for example,
>
>  > require(lme4)
>  > (fm1 <- lmer(Reaction ~ Days + Subject + (Days|Subject),  sleepstudy))
>
>  Therefore I am uncertain as to how you can draw this conclusion
>  without more information about the design (which the poster really
>  should have provided).
I stand corrected. I thought this would force the between-subject
variance to zero. So what does the (substantially reduced)
between-subjects variance estimated in this model refer to? I noticed
that the residual variance stayed the same.

>  >
>  > The following may not apply to your case, but it might: Sometimes
>  > people think that a nested/taxonomic design implies a random effect
>  > structure (e.g., schools, classes, students). This is not true. If you
>  > have only a few units for each factor, you are better off to specify
>  > it as a fixed-effects rather than a random-effects taxonomy. (Of
>  > course, you lose generalizability, but if you want this you should
>  > make sure you have sample that provides a basis for it.)
>
>  I can see the sense behind this position but sometimes a few units are
>  all that is available, and including them in a model as fixed effects
>  muddies the statistical waters, especially if they are the kinds of
>  effects that a model user will be unlikely to naturally condition upon.

If you have only a few units, how can this muddy the statistical waters?

>
>  I do agree that if there are problems with model fitting and/or
>  interpretation when the design is rigorously followed, then a more
>  flexible approach can and should be adopted, and appropriate
>  allowances must be made.
>
>
>  > The interpretation of conditional modes (formerly knowns as BLUPs,
>  > that is "predictions") is a tricky business, especially with few
>  > units per levels.
>
>  Sorry, I think I've missed something.  In what sense are the
>  conditional modes formerly known as BLUPs?

From: "Douglas Bates" <bates at stat.wisc.edu>
Date: September 27, 2007 5:00:41 PM GMT+02:00
The BLUPs of the random effects (actually as Alan James described
the situation, "For a nonlinear model these are just like the BLUPs
(Best Linear Unbiased Predictors) except that they are not linear, and
they're not unbiased, and there is no clear sense in which they are
"best" but, other than that, ...") are not guaranteed to have an
observed variance-covariance matrix that corresponds to the estimate
of the variance-covariance matrix of the random effects.

	From: 	  bates at stat.wisc.edu
	Subject: 	Re: [R-sig-ME] [R] coef se in lme
	Date: 	October 17, 2007 10:04:47 PM GMT+02:00
Lately I have taken to referring to the "estimates" of the random
effects, what are sometimes called the BLUPs or Best Linear Unbiased
Predictors, as the "conditional modes" of the random effects.  That
is, they are the values that maximize the density of the random
effects given the observed data and the values of the model
parameters.  For a linear mixed model the conditional distribution of
the random effects is multivariate normal so the conditional modes are
also the conditional means.

Thanks,
Best
Reinhold



From bates at stat.wisc.edu  Tue Apr  8 23:58:04 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 8 Apr 2008 16:58:04 -0500
Subject: [R-sig-ME] lmer bug / feature
In-Reply-To: <47FBDAEF.4040803@oakland.edu>
References: <47FBDAEF.4040803@oakland.edu>
Message-ID: <40e66e0b0804081458q584c5c5g6210358f9b660af7@mail.gmail.com>

On 4/8/08, Robert Kushler <kushler at oakland.edu> wrote:

>  Well, I left you alone for *two* days.

>  1) The "Groups" labels in the Random effects section of the lmer
>    output have vanished in rel -12 (but I think this relates
>    to the structural changes introduced in rel -11).

That is indeed a bug.  Thanks for reminding me.  I will fix that.

>  2) The "interaction" variance is listed first for models
>    of the form  "Y ~ (1 | A) + (1 | B) + (1 | A:B)".

>    Similarly, the "inner" variance appears first in nested
>    models like

>       "Y ~ (1 | A/B)"  or  "Y ~ (1 | A) + (1 | A:B)" (implicit nesting)
>    or
>       "Y ~ (1 | A) + (1 | B)" (explicit nesting).

>    It would seem more "user friendly" to list the terms in the
>    order they appear in the model formula.  (This will be less
>    of a problem if issue #1 is resolved.)

John Maindonald has also pointed out that the ordering of the terms in
the VarCorr display is counter-intuitive.

The ordering of the terms is not arbitrary - they are ordered by
decreasing numbers of levels in the grouping factor.  At least that
was the intention.  Versions before -11 had a bug in the code and the
terms were not being reordered when they should have been.  I fixed
that bug but, in the process, introduced bug #1.

This ordering is chosen to facilitate the selection of a fill-reducing
permutation for the sparse Cholesky decomposition and I would be
reluctant to change that part of the code.  For big data sets and
models with multiple random effects terms a good fill-reducing
permutation is the key to saving both time and memory when fitting the
model.

I'm not sure how much work would be involved in reordering the terms
for display.

I'll fix the first bug.  Patches for the second infelicity (this
really is an infelicity, not a bug) would be gladly accepted.  The
relevant function is the hidden function formatVC in lme4/R/lmer.R.
The first argument is a list and the fix may be as simple as reversing
the order of the elements of that list before operating on it.  This
would create an ordering by increasing numbers of levels, not
necessarily the ordering of the terms in the original formula.  You
would need to work a bit harder to get that.

I have taken the liberty of cc:'ing this reply to the R-SIG-Mixed-Models list.



From reinhold.kliegl at gmail.com  Wed Apr  9 00:00:49 2008
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Wed, 9 Apr 2008 00:00:49 +0200
Subject: [R-sig-ME] random effects specification
In-Reply-To: <873apw5blo.fsf@patagonia.sebmags.homelinux.org>
References: <87abkak6qa.fsf@patagonia.sebmags.homelinux.org>
	<75A3A990-0E70-4BDB-A44D-2BA011ADEA8C@kagi.com>
	<40e66e0b0804060804g494f8f59i5307444fc581227d@mail.gmail.com>
	<3D4A6791-2368-412E-A62E-BD10EFD5DA91@kagi.com>
	<87prt1ojvt.fsf@patagonia.sebmags.homelinux.org>
	<87ve2s5nax.fsf@patagonia.sebmags.homelinux.org>
	<aefe4d0a0804081031v28ebeac3t9d849213c4b1e954@mail.gmail.com>
	<87iqys5i6a.fsf@patagonia.sebmags.homelinux.org>
	<aefe4d0a0804081247x1bdcaaa2u9661b8ebfbfde9d4@mail.gmail.com>
	<873apw5blo.fsf@patagonia.sebmags.homelinux.org>
Message-ID: <aefe4d0a0804081500r665d5a23gf337da3fc49aac36@mail.gmail.com>

>
>  Yes, but IIUC, this is not necessarily equivalent to fitting separate
>  models with subsets of the terms/levels.
That is correct, but what is the issue? In general, I think it is best
to stay with one model. This gives you more precise estimates, because
you have more observations and fewer model parameters, for example,
you estimate only one residual variance. (Of course, there are also
situations where it is best to run separate analyses for different
parts of the data, for reasons of ease of communication, reviewer
requests, etc.).

> Correct me if I'm wrong, but I
>  think the estimates will differ when the design is unbalanced (e.g. some
>  subjects not receiving all treatments) because a straight calculation
>  from the full model assumes the coefficients have equal weight.
This is correct. Note, however, that for unbalanced designs the model
estimates correct for differences in reliability (e.g., due to
differences in the number of observations). So, for prediction, the
estimates may be better than the observed means.

Reinhold



From bates at stat.wisc.edu  Wed Apr  9 00:40:46 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 8 Apr 2008 17:40:46 -0500
Subject: [R-sig-ME] lme4, version 0.999375-13 uploaded to R-forge
Message-ID: <40e66e0b0804081540l3962ff4dv753f158aefcbe334@mail.gmail.com>

I have uploaded to R-forge the files for release 0.999375-13 of the
lme4 package.  This version restores the names of the components in
the VarCorr object and adds the Dyestuff data from Davies and
Goldsmith (1972) - actually I think it goes back to the first edition
of that book from 1947 - and more options for the hidden function
devmat.  You can now request a matrix of values whose rows are the
deviance slot (the default) or the fixef slot or the ranef slot or the
u slot.



From bates at stat.wisc.edu  Wed Apr  9 00:49:46 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 8 Apr 2008 17:49:46 -0500
Subject: [R-sig-ME] Random or Fixed effects appropriate?
In-Reply-To: <aefe4d0a0804081437k7da862a5sa5fab66c84b17d0@mail.gmail.com>
References: <a072ed700804080839r5e51d834n509e67ef6400f533@mail.gmail.com>
	<aefe4d0a0804081010s11cfa43t40997786bd75d9a5@mail.gmail.com>
	<20080408205605.GA1239@ms.unimelb.edu.au>
	<aefe4d0a0804081437k7da862a5sa5fab66c84b17d0@mail.gmail.com>
Message-ID: <40e66e0b0804081549v331faa18i1cda6b9ccbf7de36@mail.gmail.com>

On 4/8/08, Reinhold Kliegl <reinhold.kliegl at gmail.com> wrote:
> Hi Andrew,
>
>
>  >  > >  lmer( y ~ x + (1|A) + (1|B) + (1|C) + (1|D) + C + x:C) #error:
>  >  > >  Downdated X'X is not positive definite, 82
>  >  > You cannot include C both as a random and a fixed effect
>  >
>  >
>  >  I do not believe that this is generally true.  See, for example,
>  >
>  >  > require(lme4)
>  >  > (fm1 <- lmer(Reaction ~ Days + Subject + (Days|Subject),  sleepstudy))
>  >
>  >  Therefore I am uncertain as to how you can draw this conclusion
>  >  without more information about the design (which the poster really
>  >  should have provided).
>
> I stand corrected. I thought this would force the between-subject
>  variance to zero. So what does the (substantially reduced)
>  between-subjects variance estimated in this model refer to? I noticed
>  that the residual variance stayed the same.

I would regard that result as a numerical accident rather than a
matter of design.  I don't think the same factor A should be present
in both the fixed effects and as a random effect of the form (1|A).
The same factor can be involved in the fixed effects and the random
effects as, for example, the factor Machine in the Machines  data (in
the MEMSS package) for models of the form

lmer(score ~ Machine + (1|Worker/Machine), Machines)

In those cases the role of Machine is different in the fixed effects
and in the random effects.

(Sorry Andrew but I think you are wrong on this one.  As always I am
willing to be convinced otherwise.)
>  >  > The following may not apply to your case, but it might: Sometimes
>  >  > people think that a nested/taxonomic design implies a random effect
>  >  > structure (e.g., schools, classes, students). This is not true. If you
>  >  > have only a few units for each factor, you are better off to specify
>  >  > it as a fixed-effects rather than a random-effects taxonomy. (Of
>  >  > course, you lose generalizability, but if you want this you should
>  >  > make sure you have sample that provides a basis for it.)
>  >
>  >  I can see the sense behind this position but sometimes a few units are
>  >  all that is available, and including them in a model as fixed effects
>  >  muddies the statistical waters, especially if they are the kinds of
>  >  effects that a model user will be unlikely to naturally condition upon.
>
>
> If you have only a few units, how can this muddy the statistical waters?
>
>
>  >
>  >  I do agree that if there are problems with model fitting and/or
>  >  interpretation when the design is rigorously followed, then a more
>  >  flexible approach can and should be adopted, and appropriate
>  >  allowances must be made.
>  >
>  >
>  >  > The interpretation of conditional modes (formerly knowns as BLUPs,
>  >  > that is "predictions") is a tricky business, especially with few
>  >  > units per levels.
>  >
>  >  Sorry, I think I've missed something.  In what sense are the
>  >  conditional modes formerly known as BLUPs?
>
>
> From: "Douglas Bates" <bates at stat.wisc.edu>
>  Date: September 27, 2007 5:00:41 PM GMT+02:00
>  The BLUPs of the random effects (actually as Alan James described
>  the situation, "For a nonlinear model these are just like the BLUPs
>  (Best Linear Unbiased Predictors) except that they are not linear, and
>  they're not unbiased, and there is no clear sense in which they are
>  "best" but, other than that, ...") are not guaranteed to have an
>  observed variance-covariance matrix that corresponds to the estimate
>  of the variance-covariance matrix of the random effects.
>
>         From:     bates at stat.wisc.edu
>         Subject:        Re: [R-sig-ME] [R] coef se in lme
>         Date:   October 17, 2007 10:04:47 PM GMT+02:00
>  Lately I have taken to referring to the "estimates" of the random
>  effects, what are sometimes called the BLUPs or Best Linear Unbiased
>  Predictors, as the "conditional modes" of the random effects.  That
>  is, they are the values that maximize the density of the random
>  effects given the observed data and the values of the model
>  parameters.  For a linear mixed model the conditional distribution of
>  the random effects is multivariate normal so the conditional modes are
>  also the conditional means.
>
>  Thanks,
>  Best
>
> Reinhold
>
>
>  _______________________________________________
>  R-sig-mixed-models at r-project.org mailing list
>  https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From A.Robinson at ms.unimelb.edu.au  Wed Apr  9 02:16:31 2008
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Wed, 9 Apr 2008 10:16:31 +1000
Subject: [R-sig-ME] Random or Fixed effects appropriate?
In-Reply-To: <40e66e0b0804081549v331faa18i1cda6b9ccbf7de36@mail.gmail.com>
References: <a072ed700804080839r5e51d834n509e67ef6400f533@mail.gmail.com>
	<aefe4d0a0804081010s11cfa43t40997786bd75d9a5@mail.gmail.com>
	<20080408205605.GA1239@ms.unimelb.edu.au>
	<aefe4d0a0804081437k7da862a5sa5fab66c84b17d0@mail.gmail.com>
	<40e66e0b0804081549v331faa18i1cda6b9ccbf7de36@mail.gmail.com>
Message-ID: <20080409001631.GB8775@ms.unimelb.edu.au>

Hi Reinhold and Doug,

On Tue, Apr 08, 2008 at 05:49:46PM -0500, Douglas Bates wrote:
> On 4/8/08, Reinhold Kliegl <reinhold.kliegl at gmail.com> wrote:
> > Hi Andrew,
> >
> >
> >  >  > >  lmer( y ~ x + (1|A) + (1|B) + (1|C) + (1|D) + C + x:C) #error:
> >  >  > >  Downdated X'X is not positive definite, 82
> >  >  > You cannot include C both as a random and a fixed effect
> >  >
> >  >
> >  >  I do not believe that this is generally true.  See, for example,
> >  >
> >  >  > require(lme4)
> >  >  > (fm1 <- lmer(Reaction ~ Days + Subject + (Days|Subject),  sleepstudy))
> >  >
> >  >  Therefore I am uncertain as to how you can draw this conclusion
> >  >  without more information about the design (which the poster really
> >  >  should have provided).
> >
> > I stand corrected. I thought this would force the between-subject
> >  variance to zero. So what does the (substantially reduced)
> >  between-subjects variance estimated in this model refer to? I noticed
> >  that the residual variance stayed the same.
> 
> I would regard that result as a numerical accident rather than a
> matter of design.  I don't think the same factor A should be present
> in both the fixed effects and as a random effect of the form (1|A).
> The same factor can be involved in the fixed effects and the random
> effects as, for example, the factor Machine in the Machines  data (in
> the MEMSS package) for models of the form
> 
> lmer(score ~ Machine + (1|Worker/Machine), Machines)
> 
> In those cases the role of Machine is different in the fixed effects
> and in the random effects.
> 
> (Sorry Andrew but I think you are wrong on this one.  As always I am
> willing to be convinced otherwise.)

It is the latter case that I was thinking of, where an effect plays a
different role in the fixed and in the random effects, but nonetheless
does appear in both.  I was also thinking of split-plot designs.
So I think that I was tripped up by a poorly-chosen counter-example!

Warm wishes

Andrew


> >  >  > The following may not apply to your case, but it might: Sometimes
> >  >  > people think that a nested/taxonomic design implies a random effect
> >  >  > structure (e.g., schools, classes, students). This is not true. If you
> >  >  > have only a few units for each factor, you are better off to specify
> >  >  > it as a fixed-effects rather than a random-effects taxonomy. (Of
> >  >  > course, you lose generalizability, but if you want this you should
> >  >  > make sure you have sample that provides a basis for it.)
> >  >
> >  >  I can see the sense behind this position but sometimes a few units are
> >  >  all that is available, and including them in a model as fixed effects
> >  >  muddies the statistical waters, especially if they are the kinds of
> >  >  effects that a model user will be unlikely to naturally condition upon.
> >
> >
> > If you have only a few units, how can this muddy the statistical waters?
> >
> >
> >  >
> >  >  I do agree that if there are problems with model fitting and/or
> >  >  interpretation when the design is rigorously followed, then a more
> >  >  flexible approach can and should be adopted, and appropriate
> >  >  allowances must be made.
> >  >
> >  >
> >  >  > The interpretation of conditional modes (formerly knowns as BLUPs,
> >  >  > that is "predictions") is a tricky business, especially with few
> >  >  > units per levels.
> >  >
> >  >  Sorry, I think I've missed something.  In what sense are the
> >  >  conditional modes formerly known as BLUPs?
> >
> >
> > From: "Douglas Bates" <bates at stat.wisc.edu>
> >  Date: September 27, 2007 5:00:41 PM GMT+02:00
> >  The BLUPs of the random effects (actually as Alan James described
> >  the situation, "For a nonlinear model these are just like the BLUPs
> >  (Best Linear Unbiased Predictors) except that they are not linear, and
> >  they're not unbiased, and there is no clear sense in which they are
> >  "best" but, other than that, ...") are not guaranteed to have an
> >  observed variance-covariance matrix that corresponds to the estimate
> >  of the variance-covariance matrix of the random effects.
> >
> >         From:     bates at stat.wisc.edu
> >         Subject:        Re: [R-sig-ME] [R] coef se in lme
> >         Date:   October 17, 2007 10:04:47 PM GMT+02:00
> >  Lately I have taken to referring to the "estimates" of the random
> >  effects, what are sometimes called the BLUPs or Best Linear Unbiased
> >  Predictors, as the "conditional modes" of the random effects.  That
> >  is, they are the values that maximize the density of the random
> >  effects given the observed data and the values of the model
> >  parameters.  For a linear mixed model the conditional distribution of
> >  the random effects is multivariate normal so the conditional modes are
> >  also the conditional means.
> >
> >  Thanks,
> >  Best
> >
> > Reinhold
> >
> >
> >  _______________________________________________
> >  R-sig-mixed-models at r-project.org mailing list
> >  https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From A.Robinson at ms.unimelb.edu.au  Wed Apr  9 02:37:38 2008
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Wed, 9 Apr 2008 10:37:38 +1000
Subject: [R-sig-ME] Random or Fixed effects appropriate?
In-Reply-To: <aefe4d0a0804081437k7da862a5sa5fab66c84b17d0@mail.gmail.com>
References: <a072ed700804080839r5e51d834n509e67ef6400f533@mail.gmail.com>
	<aefe4d0a0804081010s11cfa43t40997786bd75d9a5@mail.gmail.com>
	<20080408205605.GA1239@ms.unimelb.edu.au>
	<aefe4d0a0804081437k7da862a5sa5fab66c84b17d0@mail.gmail.com>
Message-ID: <20080409003738.GC8775@ms.unimelb.edu.au>

Hi Reinhold,

On Tue, Apr 08, 2008 at 11:37:30PM +0200, Reinhold Kliegl wrote:
> Hi Andrew,
> 
> >  > >  lmer( y ~ x + (1|A) + (1|B) + (1|C) + (1|D) + C + x:C) #error:
> >  > >  Downdated X'X is not positive definite, 82
> >  > You cannot include C both as a random and a fixed effect
> >
> >
> >  I do not believe that this is generally true.  See, for example,
> >
> >  > require(lme4)
> >  > (fm1 <- lmer(Reaction ~ Days + Subject + (Days|Subject),  sleepstudy))
> >
> >  Therefore I am uncertain as to how you can draw this conclusion
> >  without more information about the design (which the poster really
> >  should have provided).
> I stand corrected. I thought this would force the between-subject
> variance to zero. So what does the (substantially reduced)
> between-subjects variance estimated in this model refer to? I noticed
> that the residual variance stayed the same.

[see earlier reply to you and Doug]
 
> >  >
> >  > The following may not apply to your case, but it might: Sometimes
> >  > people think that a nested/taxonomic design implies a random effect
> >  > structure (e.g., schools, classes, students). This is not true. If you
> >  > have only a few units for each factor, you are better off to specify
> >  > it as a fixed-effects rather than a random-effects taxonomy. (Of
> >  > course, you lose generalizability, but if you want this you should
> >  > make sure you have sample that provides a basis for it.)
> >
> >  I can see the sense behind this position but sometimes a few units are
> >  all that is available, and including them in a model as fixed effects
> >  muddies the statistical waters, especially if they are the kinds of
> >  effects that a model user will be unlikely to naturally condition upon.
> 
> If you have only a few units, how can this muddy the statistical waters?

Sorry, that is not great phrasing on my part.  I guess I should say
that I think that it could unnecessarily complicate the presentation
of the results.  For example, one may have a few-unit variable that is
suggested by the design and required for the assumptions.  Including
that variable as a fixed effect means that it has to be conditioned
on.  Including it as a random effect means that it can be averaged
across.  The latter can make a more straightforward story.  Of course,
it depends on the modelling goal.

> >
> >  I do agree that if there are problems with model fitting and/or
> >  interpretation when the design is rigorously followed, then a more
> >  flexible approach can and should be adopted, and appropriate
> >  allowances must be made.
> >
> >
> >  > The interpretation of conditional modes (formerly knowns as BLUPs,
> >  > that is "predictions") is a tricky business, especially with few
> >  > units per levels.
> >
> >  Sorry, I think I've missed something.  In what sense are the
> >  conditional modes formerly known as BLUPs?
> 
> From: "Douglas Bates" <bates at stat.wisc.edu>
> Date: September 27, 2007 5:00:41 PM GMT+02:00
> The BLUPs of the random effects (actually as Alan James described
> the situation, "For a nonlinear model these are just like the BLUPs
> (Best Linear Unbiased Predictors) except that they are not linear, and
> they're not unbiased, and there is no clear sense in which they are
> "best" but, other than that, ...") are not guaranteed to have an
> observed variance-covariance matrix that corresponds to the estimate
> of the variance-covariance matrix of the random effects.
> 
> 	From: 	  bates at stat.wisc.edu
> 	Subject: 	Re: [R-sig-ME] [R] coef se in lme
> 	Date: 	October 17, 2007 10:04:47 PM GMT+02:00
> Lately I have taken to referring to the "estimates" of the random
> effects, what are sometimes called the BLUPs or Best Linear Unbiased
> Predictors, as the "conditional modes" of the random effects.  That
> is, they are the values that maximize the density of the random
> effects given the observed data and the values of the model
> parameters.  For a linear mixed model the conditional distribution of
> the random effects is multivariate normal so the conditional modes are
> also the conditional means.

Ok, I see where you are coming from.  But I think that this means that
Doug is estimating the random effects by the conditional modes, which
for certain models are the same as the BLUPS.  I think that Doug
prefers "conditional modes" over BLUPS because he is now deploying his
algorithms for models in which BLUPS are no longer necessarily
sensible or available.  

I suppose that whilst I'm channelling Doug I should say something
about p-values, to get full value for my psychic dollar ;).  "P-values
are reported in lme4 but only those who really understand their
meaning can see them."

Doug, if I'm mis-channelling you, please correct me again.

Best wishes,

Andrew

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From njbisaac at googlemail.com  Wed Apr  9 11:21:53 2008
From: njbisaac at googlemail.com (Nick Isaac)
Date: Wed, 9 Apr 2008 10:21:53 +0100
Subject: [R-sig-ME] Random or Fixed effects appropriate?
In-Reply-To: <20080408205605.GA1239@ms.unimelb.edu.au>
References: <a072ed700804080839r5e51d834n509e67ef6400f533@mail.gmail.com>
	<aefe4d0a0804081010s11cfa43t40997786bd75d9a5@mail.gmail.com>
	<20080408205605.GA1239@ms.unimelb.edu.au>
Message-ID: <a072ed700804090221h3c4a6259pc3c69dd9a30d515c@mail.gmail.com>

Dear all,

Thanks for the comments and apologies for not providing more
information. I (mis)judged it would be better to discuss the issue
abstractly. There should be enough levels to estimate the variance of
C and at least one other random effect:

Number of obs: 1242, groups: D, 269; C, 64; B, 8; A, 3

My interpretation of comments by all three respondents is as follows:
1) extracting the random effects/BLUPs/conditional modes is reasonable
in general
2) a taxonomy might be considered fixed or random, depending on the
question and the number of units/levels
3) In my case, it would be better to use the conditional modes for x|C
than to fit x*C as an interaction term.

Best wishes, Nick


On 08/04/2008, Andrew Robinson <A.Robinson at ms.unimelb.edu.au> wrote:
> On Tue, Apr 08, 2008 at 07:10:16PM +0200, Reinhold Kliegl wrote:
>  > >  My dataset has one continuous normally-distributed fixed effect and
>  > >  four random effects that are nested (in fact, it is a taxonomy). For
>  > >  simplicity, I've removed the variable names, so the dataset has the
>  > >  following structure:
>  > >
>  > >  y ~ x | A/B/C/D
>  > It would be good to know how many units/levels you have for each of
>  > your four random effects. Those with fewer than, say, five, are good
>  > candidates for being specified as fixed effects. Think how many
>  > observations you need to get a stable estimate of a variance!
>  >
>  > >  lmer( y ~ x + (1|A) + (1|B) + (1|C) + (1|D) + C + x:C) #error:
>  > >  Downdated X'X is not positive definite, 82
>  > You cannot include C both as a random and a fixed effect
>
>
>
> I do not believe that this is generally true.  See, for example,
>
>  > require(lme4)
>  > (fm1 <- lmer(Reaction ~ Days + Subject + (Days|Subject),  sleepstudy))
>
>  Therefore I am uncertain as to how you can draw this conclusion
>  without more information about the design (which the poster really
>  should have provided).
>
>
>
>  > >  lmer( y ~ x + (1|A) + (1|B) + (1|C) + (1|D) + x:C) #gives sensible results
>  > If this gives sensible results, I suspect you have very few levels of
>  > C, say, 2 or 3?
>  > In this case, definitely specify C and x and their interaction as
>  > fixed effects, e.g.:
>  > lmer( y ~ x*C + (1|A) + (1|B)  + (1|D)
>  >
>  > The following may not apply to your case, but it might: Sometimes
>  > people think that a nested/taxonomic design implies a random effect
>  > structure (e.g., schools, classes, students). This is not true. If you
>  > have only a few units for each factor, you are better off to specify
>  > it as a fixed-effects rather than a random-effects taxonomy. (Of
>  > course, you lose generalizability, but if you want this you should
>  > make sure you have sample that provides a basis for it.)
>
>
> I can see the sense behind this position but sometimes a few units are
>  all that is available, and including them in a model as fixed effects
>  muddies the statistical waters, especially if they are the kinds of
>  effects that a model user will be unlikely to naturally condition upon.
>
>  I do agree that if there are problems with model fitting and/or
>  interpretation when the design is rigorously followed, then a more
>  flexible approach can and should be adopted, and appropriate
>  allowances must be made.
>
>
>  > The interpretation of conditional modes (formerly knowns as BLUPs,
>  > that is "predictions") is a tricky business, especially with few
>  > units per levels.
>
>
> Sorry, I think I've missed something.  In what sense are the
>  conditional modes formerly known as BLUPs?
>
>  Andrew
>
>
>  --
>  Andrew Robinson
>  Department of Mathematics and Statistics            Tel: +61-3-8344-6410
>  University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
>  http://www.ms.unimelb.edu.au/~andrewpr
>  http://blogs.mbs.edu/fishing-in-the-bay/
>



From mmatejus at googlemail.com  Wed Apr  9 12:29:52 2008
From: mmatejus at googlemail.com (Martin Matejus)
Date: Wed, 9 Apr 2008 11:29:52 +0100
Subject: [R-sig-ME] advice on grouping structure - many levels but few
	individuals per level
Message-ID: <e160952d0804090329r3916b60t6ebd2279c21ccade@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080409/d17417ad/attachment.pl>

From bates at stat.wisc.edu  Wed Apr  9 15:47:27 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 9 Apr 2008 08:47:27 -0500
Subject: [R-sig-ME] advice on grouping structure - many levels but few
	individuals per level
In-Reply-To: <e160952d0804090329r3916b60t6ebd2279c21ccade@mail.gmail.com>
References: <e160952d0804090329r3916b60t6ebd2279c21ccade@mail.gmail.com>
Message-ID: <40e66e0b0804090647v2347d7advc68a575f3833bbed@mail.gmail.com>

On Wed, Apr 9, 2008 at 5:29 AM, Martin Matejus <mmatejus at googlemail.com> wrote:
> Dear lmer's

>  I was hoping to get a little advice about specifying a grouping structure
>  with many levels but few (sometimes one) individual per level. I have had a
>  look through the posting archives but could not find a similar question.
>  Many apologies in advance if I have missed any.

>  The context of the question is as follows:

>  I would like to model fitness of juvenile birds (a simple weight based
>  metric) with a number of explanatory variables including; when they were
>  layed (as a Julian day - egglayed), number of nestlings in nest (nestlings)
>  and whether they are male or female (sex). Each bird obviously originates
>  from a nest with some birds originating from the same nest (siblings). As
>  there is the potential for the fitness of siblings to be similar (either due
>  to genetic or environmental effects) I would like to include nest as a
>  random effect to reflect this potential grouping structure. For example

>  model <- lmer(fitness ~ egglayed + nestlings + sex +(1|nest))

>  I have many nests (175) but about half of them contain only 1 individual.

>  My question is: does it make sense to include nest as a random effect given
>  that many nests only contain one individual? I know this probably reflects a
>  rather deep misunderstanding regarding mixed effects models on my part but I
>  would have thought that it would be impossible to estimate a within nest
>  variance with only one individual and therefore make my between nest
>  variance estimates meaningless.

That's not a problem as long as you recognize that you will get almost
no new information from the groups that have only one observation. In
other words you will get almost the same parameter estimates from the
complete data set as you would get from the data after elimination
those nests with only one individual.  If you wrote out all of the
error terms for each observation you would see that for those nests
with only one observation you have two confounded error terms.

I have seen this effect when fitting models to the 'star' data set in
the mlmRev package.  Because these are longitudinal data, groups are
indexed by individuals (students, in this case)  and the number of
observations per group is the number of times the student takes a
test.  Many students have only one observation.  For most models you
can remove those students or keep them in without affecting the
parameter estimates noticeably.

>  Many, many thanks for your advice in advance.
>  Best wishes
>  Martin
>
>         [[alternative HTML version deleted]]
>
>  _______________________________________________
>  R-sig-mixed-models at r-project.org mailing list
>  https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From reinhold.kliegl at gmail.com  Wed Apr  9 17:45:54 2008
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Wed, 9 Apr 2008 17:45:54 +0200
Subject: [R-sig-ME] Random or Fixed effects appropriate?
In-Reply-To: <a072ed700804090221h3c4a6259pc3c69dd9a30d515c@mail.gmail.com>
References: <a072ed700804080839r5e51d834n509e67ef6400f533@mail.gmail.com>
	<aefe4d0a0804081010s11cfa43t40997786bd75d9a5@mail.gmail.com>
	<20080408205605.GA1239@ms.unimelb.edu.au>
	<a072ed700804090221h3c4a6259pc3c69dd9a30d515c@mail.gmail.com>
Message-ID: <aefe4d0a0804090845g7582ce82g7e2c203b6d2ed109@mail.gmail.com>

I think this is a reasonable summary.

You were not clear on how you plan to use the conditional modes (i.e.,
your point 1).  Please keep in mind that conditional modes are not
independent "observations" like a group mean or within-group effect or
slope, simply because shrinkage correction uses all data. Also, for
example, their correlations (i.e., between intercept and x for units
of C) are typically not identical to the estimated model correlations
displayed in the random-effects part (see also the Bates quote in my
last comment).

In analyses of reaction times (using subjects and items as crossed
random factors; carried out with Mike Masson and Eike Richter, 2007),
model-based estimates of correlations among random effects revealed
"clearer" patterns than the correlations between means and effects
computed for each subject (as they should, given that they were
corrected for unreliability). Unlike for fixed-effects estimates,
however, estimates of correlations among random effects were quite
susceptible to violations of distributional assumptions for the
residuals--up to a change in the sign of the correlation! As far as
the use of conditional modes is concerned, the absolute values of
correlations between conditional modes were always larger than the
corresponding model estimates.
     In simulations, the model estimates of correlations recovered the
"true" variances and correlations, even after random deletion of 50%
of the data, but the variance of the conditional modes always
underestimated the true variance and the difference between model
estimate and correlation based on conditional modes increased with the
absolute magnitude of the correlation. In other words, conditional
modes underestimated the variance and exaggerated covariances and
correlations of random effects in these simulations. The shrinkage in
variance reflects the contribution of the likelihood in the
computation of the conditional modes.  In summary, according to these
simulations, the model estimates of correlations among random effects
are fine; the computed correlations based on conditional modes may
serve a useful heuristic function for further analyses but must be
handled with care.

Best
Reinhold

On Wed, Apr 9, 2008 at 11:21 AM, Nick Isaac <njbisaac at googlemail.com> wrote:
> Dear all,
>
>  Thanks for the comments and apologies for not providing more
>  information. I (mis)judged it would be better to discuss the issue
>  abstractly. There should be enough levels to estimate the variance of
>  C and at least one other random effect:
>
>  Number of obs: 1242, groups: D, 269; C, 64; B, 8; A, 3
>
>  My interpretation of comments by all three respondents is as follows:
>  1) extracting the random effects/BLUPs/conditional modes is reasonable
>  in general
>  2) a taxonomy might be considered fixed or random, depending on the
>  question and the number of units/levels
>  3) In my case, it would be better to use the conditional modes for x|C
>  than to fit x*C as an interaction term.
>
>  Best wishes, Nick
>
>
>
>
>  On 08/04/2008, Andrew Robinson <A.Robinson at ms.unimelb.edu.au> wrote:
>  > On Tue, Apr 08, 2008 at 07:10:16PM +0200, Reinhold Kliegl wrote:
>  >  > >  My dataset has one continuous normally-distributed fixed effect and
>  >  > >  four random effects that are nested (in fact, it is a taxonomy). For
>  >  > >  simplicity, I've removed the variable names, so the dataset has the
>  >  > >  following structure:
>  >  > >
>  >  > >  y ~ x | A/B/C/D
>  >  > It would be good to know how many units/levels you have for each of
>  >  > your four random effects. Those with fewer than, say, five, are good
>  >  > candidates for being specified as fixed effects. Think how many
>  >  > observations you need to get a stable estimate of a variance!
>  >  >
>  >  > >  lmer( y ~ x + (1|A) + (1|B) + (1|C) + (1|D) + C + x:C) #error:
>  >  > >  Downdated X'X is not positive definite, 82
>  >  > You cannot include C both as a random and a fixed effect
>  >
>  >
>  >
>  > I do not believe that this is generally true.  See, for example,
>  >
>  >  > require(lme4)
>  >  > (fm1 <- lmer(Reaction ~ Days + Subject + (Days|Subject),  sleepstudy))
>  >
>  >  Therefore I am uncertain as to how you can draw this conclusion
>  >  without more information about the design (which the poster really
>  >  should have provided).
>  >
>  >
>  >
>  >  > >  lmer( y ~ x + (1|A) + (1|B) + (1|C) + (1|D) + x:C) #gives sensible results
>  >  > If this gives sensible results, I suspect you have very few levels of
>  >  > C, say, 2 or 3?
>  >  > In this case, definitely specify C and x and their interaction as
>  >  > fixed effects, e.g.:
>  >  > lmer( y ~ x*C + (1|A) + (1|B)  + (1|D)
>  >  >
>  >  > The following may not apply to your case, but it might: Sometimes
>  >  > people think that a nested/taxonomic design implies a random effect
>  >  > structure (e.g., schools, classes, students). This is not true. If you
>  >  > have only a few units for each factor, you are better off to specify
>  >  > it as a fixed-effects rather than a random-effects taxonomy. (Of
>  >  > course, you lose generalizability, but if you want this you should
>  >  > make sure you have sample that provides a basis for it.)
>  >
>  >
>  > I can see the sense behind this position but sometimes a few units are
>  >  all that is available, and including them in a model as fixed effects
>  >  muddies the statistical waters, especially if they are the kinds of
>  >  effects that a model user will be unlikely to naturally condition upon.
>  >
>  >  I do agree that if there are problems with model fitting and/or
>  >  interpretation when the design is rigorously followed, then a more
>  >  flexible approach can and should be adopted, and appropriate
>  >  allowances must be made.
>  >
>  >
>  >  > The interpretation of conditional modes (formerly knowns as BLUPs,
>  >  > that is "predictions") is a tricky business, especially with few
>  >  > units per levels.
>  >
>  >
>  > Sorry, I think I've missed something.  In what sense are the
>  >  conditional modes formerly known as BLUPs?
>  >
>  >  Andrew
>  >
>  >
>  >  --
>  >  Andrew Robinson
>  >  Department of Mathematics and Statistics            Tel: +61-3-8344-6410
>  >  University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
>  >  http://www.ms.unimelb.edu.au/~andrewpr
>  >  http://blogs.mbs.edu/fishing-in-the-bay/
>  >
>



From HStevens at MUOhio.edu  Wed Apr  9 18:47:30 2008
From: HStevens at MUOhio.edu (Hank Stevens)
Date: Wed, 9 Apr 2008 12:47:30 -0400
Subject: [R-sig-ME] Simulating linear mixed models - the Venables
	approach
In-Reply-To: <40e66e0b0804070929q250f3805qaf128754c6b5f89d@mail.gmail.com>
References: <40e66e0b0804070929q250f3805qaf128754c6b5f89d@mail.gmail.com>
Message-ID: <47285A8B-D529-408F-8CD8-2B613ADB648C@MUOhio.edu>

Hi Doug,
I couldn't find this email on the r-help list. Would you mind  
elaborating **briefly** on what is elegant about this?
Eager to learn,
Hank
On Apr 7, 2008, at 12:29 PM, Douglas Bates wrote:

> In case you missed it on the R-help list, I urge readers of this list
> to consider the understated elegance of the code Bill Venables posted
> for simulating data from a simple random effects model.
>
>> set.seed(7658943)
>>
>> fph <- 0.4
>> Sigh <- sqrt(0.0002)
>> Sigi <- sqrt(0.04)
>>
>> reH <- rnorm(90, fph, Sigh)  ## hospid effects
>> dta <- within(expand.grid(hospid = 1:90, empid = 1:80),
>           fpi1 <- reH[hospid] + rnorm(7200, fph, Sigi))
>
> One is reminded of John Keats
>
> 'Beauty is truth, truth beauty,?that is all
> Ye know on earth, and all ye need to know.'
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



Dr. Hank Stevens, Associate Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/~stevenmh/
http://www.cas.muohio.edu/ecology
http://www.muohio.edu/botany/

"If the stars should appear one night in a thousand years, how would men
believe and adore." -Ralph Waldo Emerson, writer and philosopher  
(1803-1882)



From bates at stat.wisc.edu  Wed Apr  9 19:17:28 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 9 Apr 2008 12:17:28 -0500
Subject: [R-sig-ME] Simulating linear mixed models - the Venables
	approach
In-Reply-To: <47285A8B-D529-408F-8CD8-2B613ADB648C@MUOhio.edu>
References: <40e66e0b0804070929q250f3805qaf128754c6b5f89d@mail.gmail.com>
	<47285A8B-D529-408F-8CD8-2B613ADB648C@MUOhio.edu>
Message-ID: <40e66e0b0804091017n10955aaer339d629acc766d93@mail.gmail.com>

On 4/9/08, Hank Stevens <HStevens at muohio.edu> wrote:
> Hi Doug,
>  I couldn't find this email on the r-help list. Would you mind elaborating
> **briefly** on what is elegant about this?
>  Eager to learn,
>  Hank

>  On Apr 7, 2008, at 12:29 PM, Douglas Bates wrote:

> > In case you missed it on the R-help list, I urge readers of this list
> > to consider the understated elegance of the code Bill Venables posted
> > for simulating data from a simple random effects model.

> > > set.seed(7658943)
> > >
> > > fph <- 0.4
> > > Sigh <- sqrt(0.0002)
> > > Sigi <- sqrt(0.04)
> > >
> > > reH <- rnorm(90, fph, Sigh)  ## hospid effects
> > > dta <- within(expand.grid(hospid = 1:90, empid = 1:80),
> >          fpi1 <- reH[hospid] + rnorm(7200, fph, Sigi))

I find the use of within, expand.grid and indexing on the random
effects to be elegant.  Actually, on reexamining the code I think that
Bill should change the first call to rnorm to have mean = 0, not mean
= fph.

The code for the simulation, data display and fit could be collapsed to

library(lme4)
set.seed(7658943)
reH <- rnorm(90, sd = sqrt(0.0002))
dta <- within(data.frame(hospid = gl(90,80)),
              fpi1 <- reH[hospid] + rnorm(length(hospid), 0.4, sqrt(0.04)))
dotplot(reorder(hospid, fpi1) ~ fpi1, dta)
(fm1 <- lmer(fpi1 ~ 1|hospid, dta, verb = TRUE))



From njbisaac at googlemail.com  Wed Apr  9 19:47:15 2008
From: njbisaac at googlemail.com (Nick Isaac)
Date: Wed, 9 Apr 2008 18:47:15 +0100
Subject: [R-sig-ME] Random or Fixed effects appropriate?
In-Reply-To: <aefe4d0a0804090845g7582ce82g7e2c203b6d2ed109@mail.gmail.com>
References: <a072ed700804080839r5e51d834n509e67ef6400f533@mail.gmail.com>
	<aefe4d0a0804081010s11cfa43t40997786bd75d9a5@mail.gmail.com>
	<20080408205605.GA1239@ms.unimelb.edu.au>
	<a072ed700804090221h3c4a6259pc3c69dd9a30d515c@mail.gmail.com>
	<aefe4d0a0804090845g7582ce82g7e2c203b6d2ed109@mail.gmail.com>
Message-ID: <a072ed700804091047i66805ea1ifd32c93f9f96a260@mail.gmail.com>

Thanks again for taking the time to reply.

>You were not clear on how you plan to use the conditional modes
(i.e., your point 1)
I have two y variables for which there is very little overlap in the
species that were observed. However, there is plenty of overlap at
coarser taxonomic resolution (random effects A, B, C and D). I was
interested in whether y1~x and y2~x vary among taxa A, B, C and D. So
I treated species as the units for analysis and the taxonomy as nested
random effects. To my surprise, the best model for y1 and y2 has an
identical structure: y ~ x + (1|A) + (1|B) + (x|C) + (1|D). So it was
then that I became interested in comparing x|C from the two models.

>Please keep in mind that conditional modes are not independent
"observations" like a >group mean or within-group effect or slope
This was at the back of my mind (poorly formulated) when I write that
using conditional models felt like cheating.

Best wishes, Nick



From A.Robinson at ms.unimelb.edu.au  Thu Apr 10 00:06:10 2008
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Thu, 10 Apr 2008 08:06:10 +1000
Subject: [R-sig-ME] Distributional assumptions + case studies (was: Random
	or Fixed effects appropriate?)
In-Reply-To: <aefe4d0a0804090845g7582ce82g7e2c203b6d2ed109@mail.gmail.com>
References: <a072ed700804080839r5e51d834n509e67ef6400f533@mail.gmail.com>
	<aefe4d0a0804081010s11cfa43t40997786bd75d9a5@mail.gmail.com>
	<20080408205605.GA1239@ms.unimelb.edu.au>
	<a072ed700804090221h3c4a6259pc3c69dd9a30d515c@mail.gmail.com>
	<aefe4d0a0804090845g7582ce82g7e2c203b6d2ed109@mail.gmail.com>
Message-ID: <20080409220610.GS1239@ms.unimelb.edu.au>

Hi Reinhold,

On Wed, Apr 09, 2008 at 05:45:54PM +0200, Reinhold Kliegl wrote:
> I think this is a reasonable summary.
> 
> You were not clear on how you plan to use the conditional modes (i.e.,
> your point 1).  Please keep in mind that conditional modes are not
> independent "observations" like a group mean or within-group effect or
> slope, simply because shrinkage correction uses all data. Also, for
> example, their correlations (i.e., between intercept and x for units
> of C) are typically not identical to the estimated model correlations
> displayed in the random-effects part (see also the Bates quote in my
> last comment).
> 
> In analyses of reaction times (using subjects and items as crossed
> random factors; carried out with Mike Masson and Eike Richter, 2007),
> model-based estimates of correlations among random effects revealed
> "clearer" patterns than the correlations between means and effects
> computed for each subject (as they should, given that they were
> corrected for unreliability). Unlike for fixed-effects estimates,
> however, estimates of correlations among random effects were quite
> susceptible to violations of distributional assumptions for the
> residuals--up to a change in the sign of the correlation! 

This is a very interesting observation, and one that I suspect should
not be buried in an email.  Can you tell us more about it?  In my
workshops, I spend a lot of time focusing on the use of diagnostics to
check distributional assumptions.  It would be fabulous to be able to
identify a case study in which getting the distributional assumptions
was so clearly important.

More generally, I wonder if it might be worth collecting such a set of
case studies with clear and thorough analyses and wrapping them in a
document.  It seems to me that it would answer the request made by
Iasonas Lamprianou recently.

I'd be happy to coordinate such an effort, so long as the
contributions were in LaTeX and Sweave.  I know my students would
benefit from it :)

Is there any interest in such an idea, from potential conributors or
(equally importantly) potential users?  

Cheers

Andrew


> As far as
> the use of conditional modes is concerned, the absolute values of
> correlations between conditional modes were always larger than the
> corresponding model estimates.
>      In simulations, the model estimates of correlations recovered the
> "true" variances and correlations, even after random deletion of 50%
> of the data, but the variance of the conditional modes always
> underestimated the true variance and the difference between model
> estimate and correlation based on conditional modes increased with the
> absolute magnitude of the correlation. In other words, conditional
> modes underestimated the variance and exaggerated covariances and
> correlations of random effects in these simulations. The shrinkage in
> variance reflects the contribution of the likelihood in the
> computation of the conditional modes.  In summary, according to these
> simulations, the model estimates of correlations among random effects
> are fine; the computed correlations based on conditional modes may
> serve a useful heuristic function for further analyses but must be
> handled with care.
> 
> Best
> Reinhold
> 
> On Wed, Apr 9, 2008 at 11:21 AM, Nick Isaac <njbisaac at googlemail.com> wrote:
> > Dear all,
> >
> >  Thanks for the comments and apologies for not providing more
> >  information. I (mis)judged it would be better to discuss the issue
> >  abstractly. There should be enough levels to estimate the variance of
> >  C and at least one other random effect:
> >
> >  Number of obs: 1242, groups: D, 269; C, 64; B, 8; A, 3
> >
> >  My interpretation of comments by all three respondents is as follows:
> >  1) extracting the random effects/BLUPs/conditional modes is reasonable
> >  in general
> >  2) a taxonomy might be considered fixed or random, depending on the
> >  question and the number of units/levels
> >  3) In my case, it would be better to use the conditional modes for x|C
> >  than to fit x*C as an interaction term.
> >
> >  Best wishes, Nick
> >
> >
> >
> >
> >  On 08/04/2008, Andrew Robinson <A.Robinson at ms.unimelb.edu.au> wrote:
> >  > On Tue, Apr 08, 2008 at 07:10:16PM +0200, Reinhold Kliegl wrote:
> >  >  > >  My dataset has one continuous normally-distributed fixed effect and
> >  >  > >  four random effects that are nested (in fact, it is a taxonomy). For
> >  >  > >  simplicity, I've removed the variable names, so the dataset has the
> >  >  > >  following structure:
> >  >  > >
> >  >  > >  y ~ x | A/B/C/D
> >  >  > It would be good to know how many units/levels you have for each of
> >  >  > your four random effects. Those with fewer than, say, five, are good
> >  >  > candidates for being specified as fixed effects. Think how many
> >  >  > observations you need to get a stable estimate of a variance!
> >  >  >
> >  >  > >  lmer( y ~ x + (1|A) + (1|B) + (1|C) + (1|D) + C + x:C) #error:
> >  >  > >  Downdated X'X is not positive definite, 82
> >  >  > You cannot include C both as a random and a fixed effect
> >  >
> >  >
> >  >
> >  > I do not believe that this is generally true.  See, for example,
> >  >
> >  >  > require(lme4)
> >  >  > (fm1 <- lmer(Reaction ~ Days + Subject + (Days|Subject),  sleepstudy))
> >  >
> >  >  Therefore I am uncertain as to how you can draw this conclusion
> >  >  without more information about the design (which the poster really
> >  >  should have provided).
> >  >
> >  >
> >  >
> >  >  > >  lmer( y ~ x + (1|A) + (1|B) + (1|C) + (1|D) + x:C) #gives sensible results
> >  >  > If this gives sensible results, I suspect you have very few levels of
> >  >  > C, say, 2 or 3?
> >  >  > In this case, definitely specify C and x and their interaction as
> >  >  > fixed effects, e.g.:
> >  >  > lmer( y ~ x*C + (1|A) + (1|B)  + (1|D)
> >  >  >
> >  >  > The following may not apply to your case, but it might: Sometimes
> >  >  > people think that a nested/taxonomic design implies a random effect
> >  >  > structure (e.g., schools, classes, students). This is not true. If you
> >  >  > have only a few units for each factor, you are better off to specify
> >  >  > it as a fixed-effects rather than a random-effects taxonomy. (Of
> >  >  > course, you lose generalizability, but if you want this you should
> >  >  > make sure you have sample that provides a basis for it.)
> >  >
> >  >
> >  > I can see the sense behind this position but sometimes a few units are
> >  >  all that is available, and including them in a model as fixed effects
> >  >  muddies the statistical waters, especially if they are the kinds of
> >  >  effects that a model user will be unlikely to naturally condition upon.
> >  >
> >  >  I do agree that if there are problems with model fitting and/or
> >  >  interpretation when the design is rigorously followed, then a more
> >  >  flexible approach can and should be adopted, and appropriate
> >  >  allowances must be made.
> >  >
> >  >
> >  >  > The interpretation of conditional modes (formerly knowns as BLUPs,
> >  >  > that is "predictions") is a tricky business, especially with few
> >  >  > units per levels.
> >  >
> >  >
> >  > Sorry, I think I've missed something.  In what sense are the
> >  >  conditional modes formerly known as BLUPs?
> >  >
> >  >  Andrew
> >  >
> >  >
> >  >  --
> >  >  Andrew Robinson
> >  >  Department of Mathematics and Statistics            Tel: +61-3-8344-6410
> >  >  University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
> >  >  http://www.ms.unimelb.edu.au/~andrewpr
> >  >  http://blogs.mbs.edu/fishing-in-the-bay/
> >  >
> >

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From A.Robinson at ms.unimelb.edu.au  Thu Apr 10 00:14:44 2008
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Thu, 10 Apr 2008 08:14:44 +1000
Subject: [R-sig-ME] advice on grouping structure - many levels but few
	individuals per level
In-Reply-To: <40e66e0b0804090647v2347d7advc68a575f3833bbed@mail.gmail.com>
References: <e160952d0804090329r3916b60t6ebd2279c21ccade@mail.gmail.com>
	<40e66e0b0804090647v2347d7advc68a575f3833bbed@mail.gmail.com>
Message-ID: <20080409221444.GT1239@ms.unimelb.edu.au>

Doug,

On Wed, Apr 09, 2008 at 08:47:27AM -0500, Douglas Bates wrote:
> On Wed, Apr 9, 2008 at 5:29 AM, Martin Matejus <mmatejus at googlemail.com> wrote:
> > Dear lmer's
> 
> >  I was hoping to get a little advice about specifying a grouping structure
> >  with many levels but few (sometimes one) individual per level. I have had a
> >  look through the posting archives but could not find a similar question.
> >  Many apologies in advance if I have missed any.
> 
> >  The context of the question is as follows:
> 
> >  I would like to model fitness of juvenile birds (a simple weight based
> >  metric) with a number of explanatory variables including; when they were
> >  layed (as a Julian day - egglayed), number of nestlings in nest (nestlings)
> >  and whether they are male or female (sex). Each bird obviously originates
> >  from a nest with some birds originating from the same nest (siblings). As
> >  there is the potential for the fitness of siblings to be similar (either due
> >  to genetic or environmental effects) I would like to include nest as a
> >  random effect to reflect this potential grouping structure. For example
> 
> >  model <- lmer(fitness ~ egglayed + nestlings + sex +(1|nest))
> 
> >  I have many nests (175) but about half of them contain only 1 individual.
> 
> >  My question is: does it make sense to include nest as a random effect given
> >  that many nests only contain one individual? I know this probably reflects a
> >  rather deep misunderstanding regarding mixed effects models on my part but I
> >  would have thought that it would be impossible to estimate a within nest
> >  variance with only one individual and therefore make my between nest
> >  variance estimates meaningless.
> 
> That's not a problem as long as you recognize that you will get almost
> no new information from the groups that have only one observation. In
> other words you will get almost the same parameter estimates from the
> complete data set as you would get from the data after elimination
> those nests with only one individual.  If you wrote out all of the
> error terms for each observation you would see that for those nests
> with only one observation you have two confounded error terms.
> 
> I have seen this effect when fitting models to the 'star' data set in
> the mlmRev package.  Because these are longitudinal data, groups are
> indexed by individuals (students, in this case)  and the number of
> observations per group is the number of times the student takes a
> test.  Many students have only one observation.  For most models you
> can remove those students or keep them in without affecting the
> parameter estimates noticeably.

Do you mean all those unidatum students at once, or one at a time?
Presumably that also depends on the multivariate distribution of the
observations.

Andrew


 
> >  Many, many thanks for your advice in advance.
> >  Best wishes
> >  Martin
> >
> >         [[alternative HTML version deleted]]
> >
> >  _______________________________________________
> >  R-sig-mixed-models at r-project.org mailing list
> >  https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From bates at stat.wisc.edu  Thu Apr 10 00:27:18 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 9 Apr 2008 17:27:18 -0500
Subject: [R-sig-ME] Distributional assumptions + case studies (was:
	Random or Fixed effects appropriate?)
In-Reply-To: <20080409220610.GS1239@ms.unimelb.edu.au>
References: <a072ed700804080839r5e51d834n509e67ef6400f533@mail.gmail.com>
	<aefe4d0a0804081010s11cfa43t40997786bd75d9a5@mail.gmail.com>
	<20080408205605.GA1239@ms.unimelb.edu.au>
	<a072ed700804090221h3c4a6259pc3c69dd9a30d515c@mail.gmail.com>
	<aefe4d0a0804090845g7582ce82g7e2c203b6d2ed109@mail.gmail.com>
	<20080409220610.GS1239@ms.unimelb.edu.au>
Message-ID: <40e66e0b0804091527j3997b084o3f394678d1133fa9@mail.gmail.com>

On 4/9/08, Andrew Robinson <A.Robinson at ms.unimelb.edu.au> wrote:
> Hi Reinhold,

>  On Wed, Apr 09, 2008 at 05:45:54PM +0200, Reinhold Kliegl wrote:
>  > I think this is a reasonable summary.

>  > You were not clear on how you plan to use the conditional modes (i.e.,
>  > your point 1).  Please keep in mind that conditional modes are not
>  > independent "observations" like a group mean or within-group effect or
>  > slope, simply because shrinkage correction uses all data. Also, for
>  > example, their correlations (i.e., between intercept and x for units
>  > of C) are typically not identical to the estimated model correlations
>  > displayed in the random-effects part (see also the Bates quote in my
>  > last comment).

>  > In analyses of reaction times (using subjects and items as crossed
>  > random factors; carried out with Mike Masson and Eike Richter, 2007),
>  > model-based estimates of correlations among random effects revealed
>  > "clearer" patterns than the correlations between means and effects
>  > computed for each subject (as they should, given that they were
>  > corrected for unreliability). Unlike for fixed-effects estimates,
>  > however, estimates of correlations among random effects were quite
>  > susceptible to violations of distributional assumptions for the
>  > residuals--up to a change in the sign of the correlation!

>  This is a very interesting observation, and one that I suspect should
>  not be buried in an email.  Can you tell us more about it?  In my
>  workshops, I spend a lot of time focusing on the use of diagnostics to
>  check distributional assumptions.  It would be fabulous to be able to
>  identify a case study in which getting the distributional assumptions
>  was so clearly important.

>  More generally, I wonder if it might be worth collecting such a set of
>  case studies with clear and thorough analyses and wrapping them in a
>  document.  It seems to me that it would answer the request made by
>  Iasonas Lamprianou recently.

>  I'd be happy to coordinate such an effort, so long as the
>  contributions were in LaTeX and Sweave.  I know my students would
>  benefit from it :)

>  Is there any interest in such an idea, from potential conributors or
>  (equally importantly) potential users?

I certainly would be delighted to have such a collection made
available and would be happy to have it hosted on
http://lme4.r-forge.r-project.org/ if that seemed suitable.

I would also recommend some of the examples in chapter 7 of Haarald
Baayen's new book "Analyzing Linguistic Data: A Practical Introduction
to Statistics using R"

# Paperback: 368 pages
# Publisher: Cambridge University Press; 1 edition (March 17, 2008)
# Language: English
# ISBN-10: 0521709180
# ISBN-13: 978-0521709187


>  > As far as
>  > the use of conditional modes is concerned, the absolute values of
>  > correlations between conditional modes were always larger than the
>  > corresponding model estimates.
>  >      In simulations, the model estimates of correlations recovered the
>  > "true" variances and correlations, even after random deletion of 50%
>  > of the data, but the variance of the conditional modes always
>  > underestimated the true variance and the difference between model
>  > estimate and correlation based on conditional modes increased with the
>  > absolute magnitude of the correlation. In other words, conditional
>  > modes underestimated the variance and exaggerated covariances and
>  > correlations of random effects in these simulations. The shrinkage in
>  > variance reflects the contribution of the likelihood in the
>  > computation of the conditional modes.  In summary, according to these
>  > simulations, the model estimates of correlations among random effects
>  > are fine; the computed correlations based on conditional modes may
>  > serve a useful heuristic function for further analyses but must be
>  > handled with care.
>  >
>  > Best
>  > Reinhold
>  >
>  > On Wed, Apr 9, 2008 at 11:21 AM, Nick Isaac <njbisaac at googlemail.com> wrote:
>  > > Dear all,
>  > >
>  > >  Thanks for the comments and apologies for not providing more
>  > >  information. I (mis)judged it would be better to discuss the issue
>  > >  abstractly. There should be enough levels to estimate the variance of
>  > >  C and at least one other random effect:
>  > >
>  > >  Number of obs: 1242, groups: D, 269; C, 64; B, 8; A, 3
>  > >
>  > >  My interpretation of comments by all three respondents is as follows:
>  > >  1) extracting the random effects/BLUPs/conditional modes is reasonable
>  > >  in general
>  > >  2) a taxonomy might be considered fixed or random, depending on the
>  > >  question and the number of units/levels
>  > >  3) In my case, it would be better to use the conditional modes for x|C
>  > >  than to fit x*C as an interaction term.
>  > >
>  > >  Best wishes, Nick
>  > >
>  > >
>  > >
>  > >
>  > >  On 08/04/2008, Andrew Robinson <A.Robinson at ms.unimelb.edu.au> wrote:
>  > >  > On Tue, Apr 08, 2008 at 07:10:16PM +0200, Reinhold Kliegl wrote:
>  > >  >  > >  My dataset has one continuous normally-distributed fixed effect and
>  > >  >  > >  four random effects that are nested (in fact, it is a taxonomy). For
>  > >  >  > >  simplicity, I've removed the variable names, so the dataset has the
>  > >  >  > >  following structure:
>  > >  >  > >
>  > >  >  > >  y ~ x | A/B/C/D
>  > >  >  > It would be good to know how many units/levels you have for each of
>  > >  >  > your four random effects. Those with fewer than, say, five, are good
>  > >  >  > candidates for being specified as fixed effects. Think how many
>  > >  >  > observations you need to get a stable estimate of a variance!
>  > >  >  >
>  > >  >  > >  lmer( y ~ x + (1|A) + (1|B) + (1|C) + (1|D) + C + x:C) #error:
>  > >  >  > >  Downdated X'X is not positive definite, 82
>  > >  >  > You cannot include C both as a random and a fixed effect
>  > >  >
>  > >  >
>  > >  >
>  > >  > I do not believe that this is generally true.  See, for example,
>  > >  >
>  > >  >  > require(lme4)
>  > >  >  > (fm1 <- lmer(Reaction ~ Days + Subject + (Days|Subject),  sleepstudy))
>  > >  >
>  > >  >  Therefore I am uncertain as to how you can draw this conclusion
>  > >  >  without more information about the design (which the poster really
>  > >  >  should have provided).
>  > >  >
>  > >  >
>  > >  >
>  > >  >  > >  lmer( y ~ x + (1|A) + (1|B) + (1|C) + (1|D) + x:C) #gives sensible results
>  > >  >  > If this gives sensible results, I suspect you have very few levels of
>  > >  >  > C, say, 2 or 3?
>  > >  >  > In this case, definitely specify C and x and their interaction as
>  > >  >  > fixed effects, e.g.:
>  > >  >  > lmer( y ~ x*C + (1|A) + (1|B)  + (1|D)
>  > >  >  >
>  > >  >  > The following may not apply to your case, but it might: Sometimes
>  > >  >  > people think that a nested/taxonomic design implies a random effect
>  > >  >  > structure (e.g., schools, classes, students). This is not true. If you
>  > >  >  > have only a few units for each factor, you are better off to specify
>  > >  >  > it as a fixed-effects rather than a random-effects taxonomy. (Of
>  > >  >  > course, you lose generalizability, but if you want this you should
>  > >  >  > make sure you have sample that provides a basis for it.)
>  > >  >
>  > >  >
>  > >  > I can see the sense behind this position but sometimes a few units are
>  > >  >  all that is available, and including them in a model as fixed effects
>  > >  >  muddies the statistical waters, especially if they are the kinds of
>  > >  >  effects that a model user will be unlikely to naturally condition upon.
>  > >  >
>  > >  >  I do agree that if there are problems with model fitting and/or
>  > >  >  interpretation when the design is rigorously followed, then a more
>  > >  >  flexible approach can and should be adopted, and appropriate
>  > >  >  allowances must be made.
>  > >  >
>  > >  >
>  > >  >  > The interpretation of conditional modes (formerly knowns as BLUPs,
>  > >  >  > that is "predictions") is a tricky business, especially with few
>  > >  >  > units per levels.
>  > >  >
>  > >  >
>  > >  > Sorry, I think I've missed something.  In what sense are the
>  > >  >  conditional modes formerly known as BLUPs?
>  > >  >
>  > >  >  Andrew
>  > >  >
>  > >  >
>  > >  >  --
>  > >  >  Andrew Robinson
>  > >  >  Department of Mathematics and Statistics            Tel: +61-3-8344-6410
>  > >  >  University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
>  > >  >  http://www.ms.unimelb.edu.au/~andrewpr
>  > >  >  http://blogs.mbs.edu/fishing-in-the-bay/
>  > >  >
>  > >
>
>  --
>  Andrew Robinson
>  Department of Mathematics and Statistics            Tel: +61-3-8344-6410
>  University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
>  http://www.ms.unimelb.edu.au/~andrewpr
>  http://blogs.mbs.edu/fishing-in-the-bay/
>
>  _______________________________________________
>  R-sig-mixed-models at r-project.org mailing list
>  https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Thu Apr 10 00:28:33 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 9 Apr 2008 17:28:33 -0500
Subject: [R-sig-ME] Distributional assumptions + case studies (was:
	Random or Fixed effects appropriate?)
In-Reply-To: <40e66e0b0804091527j3997b084o3f394678d1133fa9@mail.gmail.com>
References: <a072ed700804080839r5e51d834n509e67ef6400f533@mail.gmail.com>
	<aefe4d0a0804081010s11cfa43t40997786bd75d9a5@mail.gmail.com>
	<20080408205605.GA1239@ms.unimelb.edu.au>
	<a072ed700804090221h3c4a6259pc3c69dd9a30d515c@mail.gmail.com>
	<aefe4d0a0804090845g7582ce82g7e2c203b6d2ed109@mail.gmail.com>
	<20080409220610.GS1239@ms.unimelb.edu.au>
	<40e66e0b0804091527j3997b084o3f394678d1133fa9@mail.gmail.com>
Message-ID: <40e66e0b0804091528y40db8c2fu1effdf2f55f6adb4@mail.gmail.com>

On 4/9/08, Douglas Bates <bates at stat.wisc.edu> wrote:
> On 4/9/08, Andrew Robinson <A.Robinson at ms.unimelb.edu.au> wrote:
>  > Hi Reinhold,
>
>  >  On Wed, Apr 09, 2008 at 05:45:54PM +0200, Reinhold Kliegl wrote:
>  >  > I think this is a reasonable summary.
>
>  >  > You were not clear on how you plan to use the conditional modes (i.e.,
>  >  > your point 1).  Please keep in mind that conditional modes are not
>  >  > independent "observations" like a group mean or within-group effect or
>  >  > slope, simply because shrinkage correction uses all data. Also, for
>  >  > example, their correlations (i.e., between intercept and x for units
>  >  > of C) are typically not identical to the estimated model correlations
>  >  > displayed in the random-effects part (see also the Bates quote in my
>  >  > last comment).
>
>  >  > In analyses of reaction times (using subjects and items as crossed
>  >  > random factors; carried out with Mike Masson and Eike Richter, 2007),
>  >  > model-based estimates of correlations among random effects revealed
>  >  > "clearer" patterns than the correlations between means and effects
>  >  > computed for each subject (as they should, given that they were
>  >  > corrected for unreliability). Unlike for fixed-effects estimates,
>  >  > however, estimates of correlations among random effects were quite
>  >  > susceptible to violations of distributional assumptions for the
>  >  > residuals--up to a change in the sign of the correlation!
>
>  >  This is a very interesting observation, and one that I suspect should
>  >  not be buried in an email.  Can you tell us more about it?  In my
>  >  workshops, I spend a lot of time focusing on the use of diagnostics to
>  >  check distributional assumptions.  It would be fabulous to be able to
>  >  identify a case study in which getting the distributional assumptions
>  >  was so clearly important.
>
>  >  More generally, I wonder if it might be worth collecting such a set of
>  >  case studies with clear and thorough analyses and wrapping them in a
>  >  document.  It seems to me that it would answer the request made by
>  >  Iasonas Lamprianou recently.
>
>  >  I'd be happy to coordinate such an effort, so long as the
>  >  contributions were in LaTeX and Sweave.  I know my students would
>  >  benefit from it :)
>
>  >  Is there any interest in such an idea, from potential conributors or
>  >  (equally importantly) potential users?
>
>
> I certainly would be delighted to have such a collection made
>  available and would be happy to have it hosted on
>  http://lme4.r-forge.r-project.org/ if that seemed suitable.
>
>  I would also recommend some of the examples in chapter 7 of Haarald

(Sorry Harald - I got carried away doubling the a's in your name.)

>  Baayen's new book "Analyzing Linguistic Data: A Practical Introduction
>  to Statistics using R"
>
>  # Paperback: 368 pages
>  # Publisher: Cambridge University Press; 1 edition (March 17, 2008)
>  # Language: English
>  # ISBN-10: 0521709180
>  # ISBN-13: 978-0521709187
>
>
>
>  >  > As far as
>  >  > the use of conditional modes is concerned, the absolute values of
>  >  > correlations between conditional modes were always larger than the
>  >  > corresponding model estimates.
>  >  >      In simulations, the model estimates of correlations recovered the
>  >  > "true" variances and correlations, even after random deletion of 50%
>  >  > of the data, but the variance of the conditional modes always
>  >  > underestimated the true variance and the difference between model
>  >  > estimate and correlation based on conditional modes increased with the
>  >  > absolute magnitude of the correlation. In other words, conditional
>  >  > modes underestimated the variance and exaggerated covariances and
>  >  > correlations of random effects in these simulations. The shrinkage in
>  >  > variance reflects the contribution of the likelihood in the
>  >  > computation of the conditional modes.  In summary, according to these
>  >  > simulations, the model estimates of correlations among random effects
>  >  > are fine; the computed correlations based on conditional modes may
>  >  > serve a useful heuristic function for further analyses but must be
>  >  > handled with care.
>  >  >
>  >  > Best
>  >  > Reinhold
>  >  >
>  >  > On Wed, Apr 9, 2008 at 11:21 AM, Nick Isaac <njbisaac at googlemail.com> wrote:
>  >  > > Dear all,
>  >  > >
>  >  > >  Thanks for the comments and apologies for not providing more
>  >  > >  information. I (mis)judged it would be better to discuss the issue
>  >  > >  abstractly. There should be enough levels to estimate the variance of
>  >  > >  C and at least one other random effect:
>  >  > >
>  >  > >  Number of obs: 1242, groups: D, 269; C, 64; B, 8; A, 3
>  >  > >
>  >  > >  My interpretation of comments by all three respondents is as follows:
>  >  > >  1) extracting the random effects/BLUPs/conditional modes is reasonable
>  >  > >  in general
>  >  > >  2) a taxonomy might be considered fixed or random, depending on the
>  >  > >  question and the number of units/levels
>  >  > >  3) In my case, it would be better to use the conditional modes for x|C
>  >  > >  than to fit x*C as an interaction term.
>  >  > >
>  >  > >  Best wishes, Nick
>  >  > >
>  >  > >
>  >  > >
>  >  > >
>  >  > >  On 08/04/2008, Andrew Robinson <A.Robinson at ms.unimelb.edu.au> wrote:
>  >  > >  > On Tue, Apr 08, 2008 at 07:10:16PM +0200, Reinhold Kliegl wrote:
>  >  > >  >  > >  My dataset has one continuous normally-distributed fixed effect and
>  >  > >  >  > >  four random effects that are nested (in fact, it is a taxonomy). For
>  >  > >  >  > >  simplicity, I've removed the variable names, so the dataset has the
>  >  > >  >  > >  following structure:
>  >  > >  >  > >
>  >  > >  >  > >  y ~ x | A/B/C/D
>  >  > >  >  > It would be good to know how many units/levels you have for each of
>  >  > >  >  > your four random effects. Those with fewer than, say, five, are good
>  >  > >  >  > candidates for being specified as fixed effects. Think how many
>  >  > >  >  > observations you need to get a stable estimate of a variance!
>  >  > >  >  >
>  >  > >  >  > >  lmer( y ~ x + (1|A) + (1|B) + (1|C) + (1|D) + C + x:C) #error:
>  >  > >  >  > >  Downdated X'X is not positive definite, 82
>  >  > >  >  > You cannot include C both as a random and a fixed effect
>  >  > >  >
>  >  > >  >
>  >  > >  >
>  >  > >  > I do not believe that this is generally true.  See, for example,
>  >  > >  >
>  >  > >  >  > require(lme4)
>  >  > >  >  > (fm1 <- lmer(Reaction ~ Days + Subject + (Days|Subject),  sleepstudy))
>  >  > >  >
>  >  > >  >  Therefore I am uncertain as to how you can draw this conclusion
>  >  > >  >  without more information about the design (which the poster really
>  >  > >  >  should have provided).
>  >  > >  >
>  >  > >  >
>  >  > >  >
>  >  > >  >  > >  lmer( y ~ x + (1|A) + (1|B) + (1|C) + (1|D) + x:C) #gives sensible results
>  >  > >  >  > If this gives sensible results, I suspect you have very few levels of
>  >  > >  >  > C, say, 2 or 3?
>  >  > >  >  > In this case, definitely specify C and x and their interaction as
>  >  > >  >  > fixed effects, e.g.:
>  >  > >  >  > lmer( y ~ x*C + (1|A) + (1|B)  + (1|D)
>  >  > >  >  >
>  >  > >  >  > The following may not apply to your case, but it might: Sometimes
>  >  > >  >  > people think that a nested/taxonomic design implies a random effect
>  >  > >  >  > structure (e.g., schools, classes, students). This is not true. If you
>  >  > >  >  > have only a few units for each factor, you are better off to specify
>  >  > >  >  > it as a fixed-effects rather than a random-effects taxonomy. (Of
>  >  > >  >  > course, you lose generalizability, but if you want this you should
>  >  > >  >  > make sure you have sample that provides a basis for it.)
>  >  > >  >
>  >  > >  >
>  >  > >  > I can see the sense behind this position but sometimes a few units are
>  >  > >  >  all that is available, and including them in a model as fixed effects
>  >  > >  >  muddies the statistical waters, especially if they are the kinds of
>  >  > >  >  effects that a model user will be unlikely to naturally condition upon.
>  >  > >  >
>  >  > >  >  I do agree that if there are problems with model fitting and/or
>  >  > >  >  interpretation when the design is rigorously followed, then a more
>  >  > >  >  flexible approach can and should be adopted, and appropriate
>  >  > >  >  allowances must be made.
>  >  > >  >
>  >  > >  >
>  >  > >  >  > The interpretation of conditional modes (formerly knowns as BLUPs,
>  >  > >  >  > that is "predictions") is a tricky business, especially with few
>  >  > >  >  > units per levels.
>  >  > >  >
>  >  > >  >
>  >  > >  > Sorry, I think I've missed something.  In what sense are the
>  >  > >  >  conditional modes formerly known as BLUPs?
>  >  > >  >
>  >  > >  >  Andrew
>  >  > >  >
>  >  > >  >
>  >  > >  >  --
>  >  > >  >  Andrew Robinson
>  >  > >  >  Department of Mathematics and Statistics            Tel: +61-3-8344-6410
>  >  > >  >  University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
>  >  > >  >  http://www.ms.unimelb.edu.au/~andrewpr
>  >  > >  >  http://blogs.mbs.edu/fishing-in-the-bay/
>  >  > >  >
>  >  > >
>  >
>  >  --
>  >  Andrew Robinson
>  >  Department of Mathematics and Statistics            Tel: +61-3-8344-6410
>  >  University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
>  >  http://www.ms.unimelb.edu.au/~andrewpr
>  >  http://blogs.mbs.edu/fishing-in-the-bay/
>  >
>  >  _______________________________________________
>  >  R-sig-mixed-models at r-project.org mailing list
>  >  https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>  >
>



From kjbeath at kagi.com  Thu Apr 10 12:13:29 2008
From: kjbeath at kagi.com (Ken Beath)
Date: Thu, 10 Apr 2008 20:13:29 +1000
Subject: [R-sig-ME] advice on grouping structure - many levels but few
	individuals per level
In-Reply-To: <40e66e0b0804090647v2347d7advc68a575f3833bbed@mail.gmail.com>
References: <e160952d0804090329r3916b60t6ebd2279c21ccade@mail.gmail.com>
	<40e66e0b0804090647v2347d7advc68a575f3833bbed@mail.gmail.com>
Message-ID: <0D07CB22-6C91-4411-A3CD-6F019B64F0B1@kagi.com>

On 09/04/2008, at 11:47 PM, Douglas Bates wrote:
> On Wed, Apr 9, 2008 at 5:29 AM, Martin Matejus <mmatejus at googlemail.com 
> > wrote:
>> Dear lmer's
>
>> I was hoping to get a little advice about specifying a grouping  
>> structure
>> with many levels but few (sometimes one) individual per level. I  
>> have had a
>> look through the posting archives but could not find a similar  
>> question.
>> Many apologies in advance if I have missed any.
>
>> The context of the question is as follows:
>
>> I would like to model fitness of juvenile birds (a simple weight  
>> based
>> metric) with a number of explanatory variables including; when they  
>> were
>> layed (as a Julian day - egglayed), number of nestlings in nest  
>> (nestlings)
>> and whether they are male or female (sex). Each bird obviously  
>> originates
>> from a nest with some birds originating from the same nest  
>> (siblings). As
>> there is the potential for the fitness of siblings to be similar  
>> (either due
>> to genetic or environmental effects) I would like to include nest  
>> as a
>> random effect to reflect this potential grouping structure. For  
>> example
>
>> model <- lmer(fitness ~ egglayed + nestlings + sex +(1|nest))
>
>> I have many nests (175) but about half of them contain only 1  
>> individual.
>
>> My question is: does it make sense to include nest as a random  
>> effect given
>> that many nests only contain one individual? I know this probably  
>> reflects a
>> rather deep misunderstanding regarding mixed effects models on my  
>> part but I
>> would have thought that it would be impossible to estimate a within  
>> nest
>> variance with only one individual and therefore make my between nest
>> variance estimates meaningless.
>
> That's not a problem as long as you recognize that you will get almost
> no new information from the groups that have only one observation. In
> other words you will get almost the same parameter estimates from the
> complete data set as you would get from the data after elimination
> those nests with only one individual.  If you wrote out all of the
> error terms for each observation you would see that for those nests
> with only one observation you have two confounded error terms.
>
> I have seen this effect when fitting models to the 'star' data set in
> the mlmRev package.  Because these are longitudinal data, groups are
> indexed by individuals (students, in this case)  and the number of
> observations per group is the number of times the student takes a
> test.  Many students have only one observation.  For most models you
> can remove those students or keep them in without affecting the
> parameter estimates noticeably.
>

This depends on the data. If the  within cluster correlation is high  
then a large cluster has little more information than a small cluster.  
In that case take out half the clusters and the standard errors will  
increase by 30% or more.

My suggestion is to leave all the data in, and fit as a random effects  
model as this will work fine. The original concern was that the within  
nest variance couldn't be calculated for clusters with single  
observations but this is not a problem.

Ken

>> Many, many thanks for your advice in advance.
>> Best wishes
>> Martin
>>
>>        [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From cotter.rs at gmail.com  Thu Apr 10 14:13:33 2008
From: cotter.rs at gmail.com (R.S. Cotter)
Date: Thu, 10 Apr 2008 14:13:33 +0200
Subject: [R-sig-ME] Problems with an anova mehtod to test for differences
	between groups in a lme ()
Message-ID: <742479270804100513t4ca172adib750c538f3b6b360@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080410/3da05aa1/attachment.pl>

From reinhold.kliegl at gmail.com  Thu Apr 10 17:51:36 2008
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Thu, 10 Apr 2008 17:51:36 +0200
Subject: [R-sig-ME] Distributional assumptions + case studies (was:
	Random or Fixed effects appropriate?)
In-Reply-To: <20080409220610.GS1239@ms.unimelb.edu.au>
References: <a072ed700804080839r5e51d834n509e67ef6400f533@mail.gmail.com>
	<aefe4d0a0804081010s11cfa43t40997786bd75d9a5@mail.gmail.com>
	<20080408205605.GA1239@ms.unimelb.edu.au>
	<a072ed700804090221h3c4a6259pc3c69dd9a30d515c@mail.gmail.com>
	<aefe4d0a0804090845g7582ce82g7e2c203b6d2ed109@mail.gmail.com>
	<20080409220610.GS1239@ms.unimelb.edu.au>
Message-ID: <aefe4d0a0804100851w6f0beec6v8a0453f17995ab7b@mail.gmail.com>

Hi Andrew,

The manuscript  (Kliegl, R., Masson, M.E.J., & Richter, E.M. (2007).
Fixed and random effects of word frequency and masked repetition
priming: A linear mixed-effects model perspective) is available as PDF
at the top of my publications page here:

http://www.psych.uni-potsdam.de/people/kliegl/personal/pubs-e.html

I will send you a LaTeX version later this week. What all do you need?
For case studies, it may make sense to include data and R-scripts. Is
this your plan?

My co-authors and I realize that the manuscript is in need of an
overhaul with respect to the precision of some of the arguments
(especially with respect to justifications of data
transformation--another red herring in experimental psychology, aside
from p-values); we already have a very helpful set of reviews from a
first submission. Not sure yet, where we will go next with it.
Suggestions?

Thanks and all the best,
Reinhold

On Thu, Apr 10, 2008 at 12:06 AM, Andrew Robinson
<A.Robinson at ms.unimelb.edu.au> wrote:

>  >
>  > In analyses of reaction times (using subjects and items as crossed
>  > random factors; carried out with Mike Masson and Eike Richter, 2007),
>  > model-based estimates of correlations among random effects revealed
>  > "clearer" patterns than the correlations between means and effects
>  > computed for each subject (as they should, given that they were
>  > corrected for unreliability). Unlike for fixed-effects estimates,
>  > however, estimates of correlations among random effects were quite
>  > susceptible to violations of distributional assumptions for the
>  > residuals--up to a change in the sign of the correlation!
>
>  This is a very interesting observation, and one that I suspect should
>  not be buried in an email.  Can you tell us more about it?  In my
>  workshops, I spend a lot of time focusing on the use of diagnostics to
>  check distributional assumptions.  It would be fabulous to be able to
>  identify a case study in which getting the distributional assumptions
>  was so clearly important.
>
>  More generally, I wonder if it might be worth collecting such a set of
>  case studies with clear and thorough analyses and wrapping them in a
>  document.  It seems to me that it would answer the request made by
>  Iasonas Lamprianou recently.
>
>  I'd be happy to coordinate such an effort, so long as the
>  contributions were in LaTeX and Sweave.  I know my students would
>  benefit from it :)
>
>  Is there any interest in such an idea, from potential conributors or
>  (equally importantly) potential users?
>
>  Cheers
>
>  Andrew
>
>



From bates at stat.wisc.edu  Thu Apr 10 18:17:02 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 10 Apr 2008 11:17:02 -0500
Subject: [R-sig-ME] Problems with an anova mehtod to test for
	differences between groups in a lme ()
In-Reply-To: <742479270804100513t4ca172adib750c538f3b6b360@mail.gmail.com>
References: <742479270804100513t4ca172adib750c538f3b6b360@mail.gmail.com>
Message-ID: <40e66e0b0804100917l489790ebic1731088d2598e8@mail.gmail.com>

On 4/10/08, R.S. Cotter <cotter.rs at gmail.com> wrote:
> Dear all,
>
>  I have problems using anova mehtod to test for differences between groups in
>  a lme () model. As described at page 224 and 225 in Mixed-Effects Models in
>  S and S-PLUS, by Pinhiro and Bates. Could it that this script doesn't work
>  for R?, see below (in yellow).
>
>  Respons: Speed
>  Fixed effects: Fuel, CarMod (1,2&3)
>  Random effects: Place
>
>  > lme1 <- lme(Speed ~  Fuel*Car, random=~1|Place,data=test)
>  > summary (lme1)
>  Linear mixed-effects model fit by REML
>  Data: test
>       AIC      BIC    logLik
>  261.2013 275.6996 -121.6007
>
>  Random effects:
>  Formula: ~1 | Place
>            (Intercept)         Residual
>  StdDev: 0.0003238738   5.013858
>
>  Fixed effects: Speed ~ Fuel + Car + Driver + Fuel * Car
>                       Value        Std.Error     DF   t-value       p-value
>  (Intercept)        -29.33479  12.743084   30   -2.302017   0.0285
>  Fuel                10.04684    1.408789    30    7.131542   0.0000
>  CarMod2         46.55593    14.192029   7     3.280428   0.0135
>  CarMod3          1.65157     18.247158   7     0.090511   0.9304
>  Fuel:CarMod2  -5.53264     1.624159    30   -3.406464   0.0019
>  Fuel:CarMod3  -0.18452      2.010470   30   -0.091779   0.9275

>  Number of Observations: 44
>  Number of Groups: 10

>  > anova( lme1, L = c(Fuel:CarMod2 = 1, Fuel:CarMod3 = -1) )
>  Error: syntax error in "anova( lme1, L = c(Fuel:CarMod2="

The semicolon is not a valid character in an R name.  Try quoting the names.
>
>  Regards R.S
>
>         [[alternative HTML version deleted]]
>
>  _______________________________________________
>  R-sig-mixed-models at r-project.org mailing list
>  https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From A.Robinson at ms.unimelb.edu.au  Thu Apr 10 22:28:00 2008
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Fri, 11 Apr 2008 06:28:00 +1000
Subject: [R-sig-ME] Distributional assumptions + case studies (was:
	Random or Fixed effects appropriate?)
In-Reply-To: <aefe4d0a0804100851w6f0beec6v8a0453f17995ab7b@mail.gmail.com>
References: <a072ed700804080839r5e51d834n509e67ef6400f533@mail.gmail.com>
	<aefe4d0a0804081010s11cfa43t40997786bd75d9a5@mail.gmail.com>
	<20080408205605.GA1239@ms.unimelb.edu.au>
	<a072ed700804090221h3c4a6259pc3c69dd9a30d515c@mail.gmail.com>
	<aefe4d0a0804090845g7582ce82g7e2c203b6d2ed109@mail.gmail.com>
	<20080409220610.GS1239@ms.unimelb.edu.au>
	<aefe4d0a0804100851w6f0beec6v8a0453f17995ab7b@mail.gmail.com>
Message-ID: <20080410202800.GW1239@ms.unimelb.edu.au>

Hi Reinhold,

thanks very much!  

Your paper is eminently suitable, especially insofar as it captures
the interplay between model choice and statistical outcome.  I do
suggest that you make whatever alterations you deem suitable to
preclude any problems with your future publisher, and if possible,
provide some informal commentary on the structure of the analysis - eg
how do you interpret the graphics that you produced, what motivated
your decisions, etc.  Your abstract already includes a description of
the characteristics that makes sthis study interesting as a case
study, so that's very convenient.

In general, my plan is to focus on case studies for which the data are
unencumbered and the authors don't mind providing a detailed
explanation of their analyses.  The sort of thing that I'm envisioning
is along the lines of a cleaned up version of the analysis from p 116
to 137 of this document:

http://www.ms.unimelb.edu.au/~andrewpr/r-users/icebreakeR.pdf

So, much more detail about the process of the analysis than would be
in a published paper (hopefully therefore side-stepping any copyright
issues), but much less detail about the context.  

However, these ideas are not set in stone.  I suppose that much of
data analysis is a question of style, so we can't afford to be
dogmatic.  In the unlikely event that we get an overwhelming response
then we might invoke some kind of filter.  

Ideally a submission would be a Sweave file and a data file, so the
analysis gets dsiscussed in the context of the code that is being run.
I'm happy to provide advice and/or templates for using Sweave, which I
have found invaluable.

Warm regards,

Andrew


On Thu, Apr 10, 2008 at 05:51:36PM +0200, Reinhold Kliegl wrote:
> Hi Andrew,
> 
> The manuscript  (Kliegl, R., Masson, M.E.J., & Richter, E.M. (2007).
> Fixed and random effects of word frequency and masked repetition
> priming: A linear mixed-effects model perspective) is available as PDF
> at the top of my publications page here:
> 
> http://www.psych.uni-potsdam.de/people/kliegl/personal/pubs-e.html
> 
> I will send you a LaTeX version later this week. What all do you need?
> For case studies, it may make sense to include data and R-scripts. Is
> this your plan?
> 
> My co-authors and I realize that the manuscript is in need of an
> overhaul with respect to the precision of some of the arguments
> (especially with respect to justifications of data
> transformation--another red herring in experimental psychology, aside
> from p-values); we already have a very helpful set of reviews from a
> first submission. Not sure yet, where we will go next with it.
> Suggestions?
> 
> Thanks and all the best,
> Reinhold
> 
> On Thu, Apr 10, 2008 at 12:06 AM, Andrew Robinson
> <A.Robinson at ms.unimelb.edu.au> wrote:
> 
> >  >
> >  > In analyses of reaction times (using subjects and items as crossed
> >  > random factors; carried out with Mike Masson and Eike Richter, 2007),
> >  > model-based estimates of correlations among random effects revealed
> >  > "clearer" patterns than the correlations between means and effects
> >  > computed for each subject (as they should, given that they were
> >  > corrected for unreliability). Unlike for fixed-effects estimates,
> >  > however, estimates of correlations among random effects were quite
> >  > susceptible to violations of distributional assumptions for the
> >  > residuals--up to a change in the sign of the correlation!
> >
> >  This is a very interesting observation, and one that I suspect should
> >  not be buried in an email.  Can you tell us more about it?  In my
> >  workshops, I spend a lot of time focusing on the use of diagnostics to
> >  check distributional assumptions.  It would be fabulous to be able to
> >  identify a case study in which getting the distributional assumptions
> >  was so clearly important.
> >
> >  More generally, I wonder if it might be worth collecting such a set of
> >  case studies with clear and thorough analyses and wrapping them in a
> >  document.  It seems to me that it would answer the request made by
> >  Iasonas Lamprianou recently.
> >
> >  I'd be happy to coordinate such an effort, so long as the
> >  contributions were in LaTeX and Sweave.  I know my students would
> >  benefit from it :)
> >
> >  Is there any interest in such an idea, from potential conributors or
> >  (equally importantly) potential users?
> >
> >  Cheers
> >
> >  Andrew
> >
> >

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From dafshartous at med.miami.edu  Fri Apr 11 01:07:36 2008
From: dafshartous at med.miami.edu (David Afshartous)
Date: Thu, 10 Apr 2008 19:07:36 -0400
Subject: [R-sig-ME] Fwd: same old question - lme4 and p-values
In-Reply-To: <1207611962.23040.9.camel@sib-sblomber01d.sib.uq.edu.au>
Message-ID: <C42415F8.4F33%dafshartous@med.miami.edu>




On 4/7/08 7:46 PM, "Simon Blomberg" <s.blomberg1 at uq.edu.au> wrote:

> On Mon, 2008-04-07 at 20:47 +1000, John Maindonald wrote:
> [ snip ]
>> 
>> Douglas's mcmcsamp() has advanced the state of the art
>> for multi-level models, offering an approach that had not
>> previously been readily available.  It is anyone's guess
>> where it, and statistics and graphs that it makes readily
>> possible, will in the course of time fit among styles of
>> presentation that application area people find helpful.
> 
> Well, it's been possible to easily implement multi-level models in BUGS
> using MCMC for a long time. Would you agree that BUGS is readily
> available? :-) Doug has made it more convenient for R users, but I'm not
> sure it has necessarily advanced the state of the art. Maybe brought R
> up to speed (but ahead of other software which tends to start with the
> letter S).
> 

Just catching up on this discussion, but RE BUGS, although I'm not an
experience BUGS user I've been running some simulations for various mixed
effects models in both lmer and BUGS (via bugs() function in R2WinBugs), and
it seems that lmer is much more stable than BUGS for the types of models
I've been fitting.  Do others that use both have similar experience?


> Simon.
> 
>> 
>> John Maindonald             email: john.maindonald at anu.edu.au
>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>> Centre for Mathematics & Its Applications, Room 1194,
>> John Dedman Mathematical Sciences Building (Building 27)
>> Australian National University, Canberra ACT 0200.
>> 
>> 
>> On 7 Apr 2008, at 12:05 PM, David Henderson wrote:
>> 
>>> Hi John:
>>> 
>>>> For all practical purposes, a CI is just the Bayesian credible
>>>> interval that one gets with some suitable "non-informative prior".
>>>> Why not then be specific about the prior, and go with the Bayesian
>>>> credible interval?  (There is an issue whether such a prior can
>>>> always be found.  Am right in judging this no practical consequence?)
>>> 
>>> 
>>> What?  Could you explain this a little more?  There is nothing
>>> Bayesian about a classical (i.e. not Bayesian credible set or
>>> highest posterior density, or whatever terminology you prefer) CI.
>>> The interpretation is completely different, and the assumptions used
>>> in deriving the interval are also different.  Even though the
>>> interval created when using a noninformative prior is similar to a
>>> classical CI, they are not the same entity.
>>> 
>>> Now, while i agree with the arguments about p-values and their
>>> validity, there is one aspect missing from this discussion.  When
>>> creating a general use package like lme4, we are trying to create
>>> software that enables statisticians and researchers to perform the
>>> statistical analyses they need and interpret the results in ways
>>> that HELP them get published.  While I admire Doug for "drawing a
>>> line in the sand" in regard to the use of p-values in published
>>> research, this is counter to HELPING the researcher publish their
>>> results.  There has to be a better way to further your point in the
>>> community than FORCING your point upon them.  Education of the next
>>> generation of researchers and journal editors is admittedly slow,
>>> but a much more community friendly way of getting your point used in
>>> practice.
>>> 
>>> Just my $0.02...
>>> 
>>> Dave H
>>> --
>>> David Henderson, Ph.D.
>>> Director of Community
>>> REvolution Computing
>>> 1100 Dexter Avenue North, Suite 250
>>> 206-577-4778 x3203
>>> DNADave at Revolution-Computing.Com
>>> http://www.revolution-computing.com
>>> 
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From kevin.thorpe at utoronto.ca  Fri Apr 11 15:10:41 2008
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Fri, 11 Apr 2008 09:10:41 -0400
Subject: [R-sig-ME] Fwd: same old question - lme4 and p-values
In-Reply-To: <40e66e0b0804040633k619803fayfd2e9b9b07b88b77@mail.gmail.com>
References: <28642179.2370001207304657364.JavaMail.nabble@isper.nabble.com>	<40e66e0b0804040554m41e63d58l3a5825924696cf78@mail.gmail.com>
	<40e66e0b0804040633k619803fayfd2e9b9b07b88b77@mail.gmail.com>
Message-ID: <47FF6351.9010506@utoronto.ca>

This has been a very interesting thread.  However, I'm still
wrestling with what to do for a fixed-effect that has more than
one degree of freedom.

In the data I'm analyzing, I have three groups to compare.

So, I can get CIs for the two parameters, but that is a bit
problematic for assessing an overall difference.

Is it valid to do the following?  Estimate the parameters using both
ML and REML.  If the estimates show good agreement, is that sufficient
evidence to conclude the ML procedure is converging and that I can
use a likelihood ratio test for the fixed effect?

Thanks for your comments.

Kevin

-- 
Kevin E. Thorpe
Biostatistician/Trialist, Knowledge Translation Program
Assistant Professor, Department of Public Health Sciences
Faculty of Medicine, University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.6057



From reinhold.kliegl at gmail.com  Sat Apr 12 14:02:09 2008
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Sat, 12 Apr 2008 14:02:09 +0200
Subject: [R-sig-ME] Fwd: same old question - lme4 and p-values
In-Reply-To: <47FF6351.9010506@utoronto.ca>
References: <28642179.2370001207304657364.JavaMail.nabble@isper.nabble.com>
	<40e66e0b0804040554m41e63d58l3a5825924696cf78@mail.gmail.com>
	<40e66e0b0804040633k619803fayfd2e9b9b07b88b77@mail.gmail.com>
	<47FF6351.9010506@utoronto.ca>
Message-ID: <aefe4d0a0804120502o726c27edx9be1b4c959c6aadc@mail.gmail.com>

On Fri, Apr 11, 2008 at 3:10 PM, Kevin E. Thorpe
<kevin.thorpe at utoronto.ca> wrote:
> This has been a very interesting thread.  However, I'm still
>  wrestling with what to do for a fixed-effect that has more than
>  one degree of freedom.
>
>  In the data I'm analyzing, I have three groups to compare.
>
>  So, I can get CIs for the two parameters, but that is a bit
>  problematic for assessing an overall difference.
>
>  Is it valid to do the following?  Estimate the parameters using both
>  ML and REML.  If the estimates show good agreement, is that sufficient
>  evidence to conclude the ML procedure is converging and that I can
>  use a likelihood ratio test for the fixed effect?
>
I assume you refer to using anova(fm1, fm2) with fm1 fitting the model
without the fixed effect. This a comparison of nested models, so a
likelihood ratio test can be defined for ML fits only. Note, however,
that Pinheiro & Bates (2000, p. 87, 2.4.2) "do not recommend using
such tests"; "not" is set in bold face. They show that such tests tend
to be anti-conservative, especially if the number of parameters
removed is large relative to the number of observations. Assuming you
have a decent number of total observations, you may be fine.
Alternatively, you may want to run a simulation for your situation;
you will also find R-code examples in the P&B section.

My first reaction to your email was: Why is he only interested in the
overall effect of a fixed factor and not in specific comparisons
between its levels? After Andrew's comment to an earlier post, I
understand that there are such situations where you just want to
control for an aspect of the design that is not in the focus of your
theoretical concerns (e.g., in ecology you may have three sites that
could be characterized as levels of a fixed factor or as a sample from
a random factor). Perhaps  your fixed factor may also be better
conceptualized as a random factor. In a way, you just want to control
for the variance contributed by this factor. If this applies to your
data, then you may be better off to specify your fixed factor as a
random factor. Then, your anova(fm1, fm2) compares nested models that
differ only in the random-effects part. In this case the likelihood
ratio test can be used with models fit by REML. These tests tend to be
conservative (Pinheiro & Bates, 2000, p. 2.4.1; following up on Stram
& Lee, 1994). So if your ANOVA statistic is significant, you are on
the save side; if not, you do not know. Also keep in mind, that random
effects with few units may generate problems for model convergence.

Best
Reinhold



From bates at stat.wisc.edu  Sat Apr 12 14:37:58 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat, 12 Apr 2008 07:37:58 -0500
Subject: [R-sig-ME] lmer problems
In-Reply-To: <21e8590e0804120258h425c7315tf7145d55f1a9824a@mail.gmail.com>
References: <21e8590e0804120258h425c7315tf7145d55f1a9824a@mail.gmail.com>
Message-ID: <40e66e0b0804120537v1b5c4472t659adaec3bee7934@mail.gmail.com>

On Sat, Apr 12, 2008 at 4:58 AM, Alexandre Courtiol
<alexandre.courtiol at gmail.com> wrote:
> Dear Douglas Bates,

> Sorry to disturb you but I posted a question on R forum in september but
> nobody answered.
> I am using lmer with quasibinomial family since I have overdispersion in my
> data. And I wish to assess significance of fixed effects. So I built two
> models and compare them using anova(). This lead to two problems, first
> anova() does not seem to take into account of the overdispersion since
> quasibinomial family results are strictly identical than results from
> anova() performed on two binomial (and not quasibinomial) models. Second if
> I ask for an F test in anova() as suggested for assessing significance in
> quasibinomial glm, anova() on the lmer objects give me a chisq test and not
> the F test I asked. So how should I do to assess significance of fixed
> effect using quasibinomial family in lmer???

I haven't worked out the details of what the log-likelihood for a
generalized linear mixed model using the quasi-binomial family should
be.  If someone else knows what it should be and can express it in
terms of the deviance residuals and the value of the quadratic form in
the random effects, I would be happy to incorporate it.

By the way, those values are found in the deviance slot.  The "disc"
element is the discrepancy, which is the sum of the deviance residuals
at the parameter estimates (without correction for the null deviance -
incorporating that is another item on the "ToDo" list).  The "usqr"
element is the quadratic form in the random effects, given the
relative variance-covariance matrix of the random effects at the
parameter estimates.  It is called "usqr" because it is calculated as
the squared length of the vector of orthogonal random effects, u.

The elements "wrss" (weighted residual sum of squares) and "pwrss"
(penalized weighted residual sum of squares) are used in the PIRLS
(penalized iteratively reweighted least squares) algorithm to
determine the condition modes of the random effects given parameter
values and the observed data.  The ldL2 element is the logarithm of
the square of the determinant of the Cholesky factor for the random
effects at the parameter estimates.  It is used in the Laplace
approximation to the integral that defines the log-likelihood.  The
"sigmaML" element should contain the estimate of sigma, calculated as
pwrss/n (I don't know if that is the appropriate value in this case).

I have taken the liberty of cc:ing the R-SIG-Mixed-Models mailing list
on this reply.  It is more likely to be noticed on that list.



From Olivier.Renaud at pse.unige.ch  Sat Apr 12 18:29:37 2008
From: Olivier.Renaud at pse.unige.ch (Olivier Renaud)
Date: Sat, 12 Apr 2008 18:29:37 +0200
Subject: [R-sig-ME] anova function gives (irrelevant) results on two models
 with different numbers of observations
Message-ID: <4800E371.5020209@pse.unige.ch>

Hi,

I have encountered what I believe is a bug or an extremely unwanted 
"feature" in lme4. In short, the anova function does not check that the 
two models are based on the same number of observations and can thus 
give irrelevant results, as exemplified below. Note that lme (at least 
on S+) correctly refuses to compare the models.

I found this problem, because I wanted to understand why the LRT gave 
extremely different value than the Wald/t-stat index/statistics/test 
(choose one ;-) ), see below. It took me a while to realize that the 
number of observations was not the same in the two models (156 vs. 160). 
It happens when an explanatory variable is present in only one of the 
two models and contains NA's, which in not an uncommon situation. The 
MLdeviances then are very different but not comparable. I'm afraid it 
might have unnoticed by other users. I have reproduced the calls in lmer 
(R) and lme (S+).

Olivier

R version 2.6.1 (2007-11-26)
Package:       lme4
Version:       0.99875-9
 > (Fu.mod0.lmer <- lmer(Y ~ 1 + ( 1|subjec), data = Fu, 
na.action=na.omit, method="ML") )
Linear mixed-effects model fit by maximum likelihood
Formula: Y ~ 1 + (1 | subjec)
   Data: Fu
   AIC   BIC logLik MLdeviance REMLdeviance
 654.7 660.9 -325.4      650.7        651.4
Random effects:
 Groups   Name        Variance Std.Dev.
 subjec   (Intercept) 0.93595  0.96745
 Residual             2.96389  1.72160
number of obs: 160, groups: subjec, 16

Fixed effects:
            Estimate Std. Error t value
(Intercept)   3.4875     0.2775   12.57

 > (Fu.mod1.lmer <- lmer(Y ~ expvariable + ( 1|subjec), data = Fu, 
na.action=na.omit, method="ML") )
Linear mixed-effects model fit by maximum likelihood
Formula: Y ~ expvariable + (1 | subjec)
   Data: Fu
   AIC   BIC logLik MLdeviance REMLdeviance
 637.8 646.9 -315.9      631.8        633.1
Random effects:
 Groups   Name        Variance Std.Dev.
 subjec   (Intercept) 1.0357   1.0177 
 Residual             2.8796   1.6969 
number of obs: 156, groups: subjec, 16

Fixed effects:
            Estimate Std. Error t value
(Intercept)   3.2673     0.3145   10.39
expvariable   0.4140     0.2856    1.45

Correlation of Fixed Effects:
            (Intr)
expvariable -0.398

 > anova(Fu.mod0.lmer, Fu.mod1.lmer)
Data: Fu
Models:
Fu.mod0.lmer: Y ~ 1 + (1 | subjec)
Fu.mod1.lmer: Y ~ expvariable + (1 | subjec)
             Df     AIC     BIC  logLik  Chisq Chi Df Pr(>Chisq)   
Fu.mod0.lmer  2  654.70  660.85 -325.35                            
Fu.mod1.lmer  3  637.78  646.93 -315.89 18.917      1  1.365e-05 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1



######## In S+8.0

 > Fu.mod0.lme <- lme(Y ~ 1, random=~1|subjec, data = Fu, 
na.action=na.omit, method="ML")
 > summary(Fu.mod0.lme)
Linear mixed-effects model fit by maximum likelihood
 Data: Fu
       AIC      BIC    logLik
  656.7007 665.9262 -325.3503

Random effects:
 Formula:  ~ 1 | subjec
        (Intercept) Residual
StdDev:   0.9674476 1.721595

Fixed effects: Y ~ 1
             Value Std.Error  DF  t-value p-value
(Intercept) 3.4875 0.2783988 144 12.52699  <.0001

Standardized Within-Group Residuals:
       Min         Q1        Med        Q3      Max
 -2.244476 -0.7371921 -0.2445665 0.8289158 2.608248

Number of Observations: 160
Number of Groups: 16
 > Fu.mod1.lme <- lme(Y ~ expvariable, random=~1|subjec, data = Fu, 
na.action=na.omit, method="ML")
 > summary(Fu.mod1.lme)
Linear mixed-effects model fit by maximum likelihood
 Data: Fu
       AIC     BIC    logLik
  639.7835 651.983 -315.8918

Random effects:
 Formula:  ~ 1 | subjec
        (Intercept) Residual
StdDev:    1.017715 1.696945

Fixed effects: Y ~ expvariable
               Value Std.Error  DF  t-value p-value
(Intercept) 3.267305 0.3164881 139 10.32363  <.0001
expvariable 0.413960 0.2874080 139  1.44032   0.152

Standardized Within-Group Residuals:
     Min         Q1        Med        Q3      Max
 -2.4028 -0.6934754 -0.2075537 0.7346619 2.768138

Number of Observations: 156
Number of Groups: 16
 > anova(Fu.mod0.lme, Fu.mod1.lme)
Problem in anova.lme(Fu.mod0.lme, Fu.mod1.lme): All fitted objects must 
use the same number of observations
Use traceback() to see the call stack

-- 
Olivier.Renaud at pse.unige.ch             http://www.unige.ch/~renaud/
Methodology & Data Analysis - Psychology Dept - University of Geneva
UniMail, Office 4142  -  40, Bd du Pont d'Arve   -  CH-1211 Geneva 4



From marcioestat at pop.com.br  Sat Apr 12 20:17:04 2008
From: marcioestat at pop.com.br (marcioestat at pop.com.br)
Date: Sat, 12 Apr 2008 15:17:04 -0300 (BRT)
Subject: [R-sig-ME] GEE Function
Message-ID: <60405.132.204.252.107.1208024224.squirrel@nwebmail.pop.com.br>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080412/4d20bcf1/attachment.pl>

From A.Robinson at ms.unimelb.edu.au  Sat Apr 12 23:18:59 2008
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Sun, 13 Apr 2008 07:18:59 +1000
Subject: [R-sig-ME] Fwd: same old question - lme4 and p-values
In-Reply-To: <aefe4d0a0804120502o726c27edx9be1b4c959c6aadc@mail.gmail.com>
References: <28642179.2370001207304657364.JavaMail.nabble@isper.nabble.com>
	<40e66e0b0804040554m41e63d58l3a5825924696cf78@mail.gmail.com>
	<40e66e0b0804040633k619803fayfd2e9b9b07b88b77@mail.gmail.com>
	<47FF6351.9010506@utoronto.ca>
	<aefe4d0a0804120502o726c27edx9be1b4c959c6aadc@mail.gmail.com>
Message-ID: <20080412211859.GT97781@ms.unimelb.edu.au>

On Sat, Apr 12, 2008 at 02:02:09PM +0200, Reinhold Kliegl wrote:
> On Fri, Apr 11, 2008 at 3:10 PM, Kevin E. Thorpe
> <kevin.thorpe at utoronto.ca> wrote:
> > This has been a very interesting thread.  However, I'm still
> >  wrestling with what to do for a fixed-effect that has more than
> >  one degree of freedom.
> >
> >  In the data I'm analyzing, I have three groups to compare.
> >
> >  So, I can get CIs for the two parameters, but that is a bit
> >  problematic for assessing an overall difference.
> >
> >  Is it valid to do the following?  Estimate the parameters using both
> >  ML and REML.  If the estimates show good agreement, is that sufficient
> >  evidence to conclude the ML procedure is converging and that I can
> >  use a likelihood ratio test for the fixed effect?
> >
> I assume you refer to using anova(fm1, fm2) with fm1 fitting the model
> without the fixed effect. This a comparison of nested models, so a
> likelihood ratio test can be defined for ML fits only. Note, however,
> that Pinheiro & Bates (2000, p. 87, 2.4.2) "do not recommend using
> such tests"; "not" is set in bold face. They show that such tests tend
> to be anti-conservative, especially if the number of parameters
> removed is large relative to the number of observations. Assuming you
> have a decent number of total observations, you may be fine.
> Alternatively, you may want to run a simulation for your situation;
> you will also find R-code examples in the P&B section.

I agree with Reinhold's position, here.  I also note in passing that
Doug uses this strategy to test the fixed effects in the cake data
(see ?cake).  Doug, does the cake data analysis represent a softening
on your position or a place-filler?
 
> My first reaction to your email was: Why is he only interested in the
> overall effect of a fixed factor and not in specific comparisons
> between its levels? After Andrew's comment to an earlier post, I
> understand that there are such situations where you just want to
> control for an aspect of the design that is not in the focus of your
> theoretical concerns (e.g., in ecology you may have three sites that
> could be characterized as levels of a fixed factor or as a sample from
> a random factor). Perhaps  your fixed factor may also be better
> conceptualized as a random factor. In a way, you just want to control
> for the variance contributed by this factor. If this applies to your
> data, then you may be better off to specify your fixed factor as a
> random factor. Then, your anova(fm1, fm2) compares nested models that
> differ only in the random-effects part. In this case the likelihood
> ratio test can be used with models fit by REML. These tests tend to be
> conservative (Pinheiro & Bates, 2000, p. 2.4.1; following up on Stram
> & Lee, 1994). So if your ANOVA statistic is significant, you are on
> the save side; if not, you do not know. Also keep in mind, that random
> effects with few units may generate problems for model convergence.

That's an interesting idea, even if the interpretation is intended to
be a fixed factor.  It might work to a certain order of approximation,
but I'm not clear how the math would play out.  Some simulations might
provide a measure of comfort in individual situations.

Best wishes,

Andrew

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From bolker at zoo.ufl.edu  Sun Apr 13 03:03:37 2008
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Sat, 12 Apr 2008 21:03:37 -0400
Subject: [R-sig-ME] [Fwd: Re:  Fwd: same old question - lme4 and p-values]
Message-ID: <48015BE9.3040406@zoo.ufl.edu>


   (resending -- first try bounced)

    Also note that in the long thread on the R wiki
(wiki.r-project.org, search for "bates mixed" or some such --
I can't get through to it right now) DB suggests an
test for a composite hypothesis a_1=a_2=...=a_n=0
along with R code to do it ...

Andrew Robinson wrote:
> On Sat, Apr 12, 2008 at 02:02:09PM +0200, Reinhold Kliegl wrote:
>> On Fri, Apr 11, 2008 at 3:10 PM, Kevin E. Thorpe
>> <kevin.thorpe at utoronto.ca> wrote:
>>> This has been a very interesting thread.  However, I'm still
>>>  wrestling with what to do for a fixed-effect that has more than
>>>  one degree of freedom.
>>>
>>>  In the data I'm analyzing, I have three groups to compare.
>>>
>>>  So, I can get CIs for the two parameters, but that is a bit
>>>  problematic for assessing an overall difference.
>>>
>>>  Is it valid to do the following?  Estimate the parameters using both
>>>  ML and REML.  If the estimates show good agreement, is that sufficient
>>>  evidence to conclude the ML procedure is converging and that I can
>>>  use a likelihood ratio test for the fixed effect?
>>>
>> I assume you refer to using anova(fm1, fm2) with fm1 fitting the model
>> without the fixed effect. This a comparison of nested models, so a
>> likelihood ratio test can be defined for ML fits only. Note, however,
>> that Pinheiro & Bates (2000, p. 87, 2.4.2) "do not recommend using
>> such tests"; "not" is set in bold face. They show that such tests tend
>> to be anti-conservative, especially if the number of parameters
>> removed is large relative to the number of observations. Assuming you
>> have a decent number of total observations, you may be fine.
>> Alternatively, you may want to run a simulation for your situation;
>> you will also find R-code examples in the P&B section.
> 
> I agree with Reinhold's position, here.  I also note in passing that
> Doug uses this strategy to test the fixed effects in the cake data
> (see ?cake).  Doug, does the cake data analysis represent a softening
> on your position or a place-filler?
>  
>> My first reaction to your email was: Why is he only interested in the
>> overall effect of a fixed factor and not in specific comparisons
>> between its levels? After Andrew's comment to an earlier post, I
>> understand that there are such situations where you just want to
>> control for an aspect of the design that is not in the focus of your
>> theoretical concerns (e.g., in ecology you may have three sites that
>> could be characterized as levels of a fixed factor or as a sample from
>> a random factor). Perhaps  your fixed factor may also be better
>> conceptualized as a random factor. In a way, you just want to control
>> for the variance contributed by this factor. If this applies to your
>> data, then you may be better off to specify your fixed factor as a
>> random factor. Then, your anova(fm1, fm2) compares nested models that
>> differ only in the random-effects part. In this case the likelihood
>> ratio test can be used with models fit by REML. These tests tend to be
>> conservative (Pinheiro & Bates, 2000, p. 2.4.1; following up on Stram
>> & Lee, 1994). So if your ANOVA statistic is significant, you are on
>> the save side; if not, you do not know. Also keep in mind, that random
>> effects with few units may generate problems for model convergence.
> 
> That's an interesting idea, even if the interpretation is intended to
> be a fixed factor.  It might work to a certain order of approximation,
> but I'm not clear how the math would play out.  Some simulations might
> provide a measure of comfort in individual situations.
> 
> Best wishes,
> 
> Andrew
>



From Renaud.lancelot at cirad.fr  Sun Apr 13 08:37:20 2008
From: Renaud.lancelot at cirad.fr (Renaud.lancelot)
Date: Sun, 13 Apr 2008 08:37:20 +0200
Subject: [R-sig-ME] GEE Function
In-Reply-To: <60405.132.204.252.107.1208024224.squirrel@nwebmail.pop.com.br>
References: <60405.132.204.252.107.1208024224.squirrel@nwebmail.pop.com.br>
Message-ID: <4801AA20.4090709@cirad.fr>

See packages gee or geepack.

RSiteSearch("gee", restrict = "functions")

Renaud


marcioestat at pop.com.br a ?crit :
> 
> Hi,
>  
> Could anybody tell how do I upload the function GEE at R...
> Do I need to install any package to use this function... 
> And is there any help for this function...
> help(gee)
> help.search("gee")
> And anyone could provide me any referente of this function... I've
> already looked at Venables and Ripley and there isn't...
>  
> Thanks a lot,
>  
> Ribeiro
>  
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ------------------------------------------------------------------------
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Renaud Lancelot
EDEN Project, coordinator
http://www.eden-fp6project.net/

CIRAD, BIOS Department
Campus International de Baillarguet
F34398 Montpellier
http://www.cirad.fr

Tel.  +33 4 67 59 37 17  -  Fax  +33 4 67 59 37 95
Secr. +33 4 67 59 37 37  - Cell. +33 6 77 52 08 69



From bates at stat.wisc.edu  Sun Apr 13 18:05:04 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sun, 13 Apr 2008 11:05:04 -0500
Subject: [R-sig-ME] anova function gives (irrelevant) results on two
	models with different numbers of observations
In-Reply-To: <4800E371.5020209@pse.unige.ch>
References: <4800E371.5020209@pse.unige.ch>
Message-ID: <40e66e0b0804130905r2d1b0e11ka47418564a1e837b@mail.gmail.com>

On Sat, Apr 12, 2008 at 11:29 AM, Olivier Renaud
<Olivier.Renaud at pse.unige.ch> wrote:
> Hi,

>  I have encountered what I believe is a bug or an extremely unwanted
>  "feature" in lme4. In short, the anova function does not check that the
>  two models are based on the same number of observations and can thus
>  give irrelevant results, as exemplified below. Note that lme (at least
>  on S+) correctly refuses to compare the models.

Perhaps you would like to contribute the code that performs the
appropriate checks on the models before creating the analysis of
variance table. Check out a copy of the lme4 package sources from the
R-forge repository and search for

setMethod("anova"

in the file pkg/R/lmer.R  You will see that there are already checks
in that method for the models being fit to the same data argument (if
used).  Patches are welcome.


>  I found this problem, because I wanted to understand why the LRT gave
>  extremely different value than the Wald/t-stat index/statistics/test
>  (choose one ;-) ), see below. It took me a while to realize that the
>  number of observations was not the same in the two models (156 vs. 160).
>  It happens when an explanatory variable is present in only one of the
>  two models and contains NA's, which in not an uncommon situation. The
>  MLdeviances then are very different but not comparable. I'm afraid it
>  might have unnoticed by other users. I have reproduced the calls in lmer
>  (R) and lme (S+).
>
>  Olivier
>
>  R version 2.6.1 (2007-11-26)
>  Package:       lme4
>  Version:       0.99875-9
>   > (Fu.mod0.lmer <- lmer(Y ~ 1 + ( 1|subjec), data = Fu,
>  na.action=na.omit, method="ML") )
>  Linear mixed-effects model fit by maximum likelihood
>  Formula: Y ~ 1 + (1 | subjec)
>    Data: Fu
>    AIC   BIC logLik MLdeviance REMLdeviance
>   654.7 660.9 -325.4      650.7        651.4
>  Random effects:
>   Groups   Name        Variance Std.Dev.
>   subjec   (Intercept) 0.93595  0.96745
>   Residual             2.96389  1.72160
>  number of obs: 160, groups: subjec, 16
>
>  Fixed effects:
>             Estimate Std. Error t value
>  (Intercept)   3.4875     0.2775   12.57
>
>   > (Fu.mod1.lmer <- lmer(Y ~ expvariable + ( 1|subjec), data = Fu,
>  na.action=na.omit, method="ML") )
>  Linear mixed-effects model fit by maximum likelihood
>  Formula: Y ~ expvariable + (1 | subjec)
>    Data: Fu
>    AIC   BIC logLik MLdeviance REMLdeviance
>   637.8 646.9 -315.9      631.8        633.1
>  Random effects:
>   Groups   Name        Variance Std.Dev.
>   subjec   (Intercept) 1.0357   1.0177
>   Residual             2.8796   1.6969
>  number of obs: 156, groups: subjec, 16
>
>  Fixed effects:
>             Estimate Std. Error t value
>  (Intercept)   3.2673     0.3145   10.39
>  expvariable   0.4140     0.2856    1.45
>
>  Correlation of Fixed Effects:
>             (Intr)
>  expvariable -0.398
>
>   > anova(Fu.mod0.lmer, Fu.mod1.lmer)
>  Data: Fu
>  Models:
>  Fu.mod0.lmer: Y ~ 1 + (1 | subjec)
>  Fu.mod1.lmer: Y ~ expvariable + (1 | subjec)
>              Df     AIC     BIC  logLik  Chisq Chi Df Pr(>Chisq)
>  Fu.mod0.lmer  2  654.70  660.85 -325.35
>  Fu.mod1.lmer  3  637.78  646.93 -315.89 18.917      1  1.365e-05 ***
>  ---
>  Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
>
>
>  ######## In S+8.0
>
>   > Fu.mod0.lme <- lme(Y ~ 1, random=~1|subjec, data = Fu,
>  na.action=na.omit, method="ML")
>   > summary(Fu.mod0.lme)
>  Linear mixed-effects model fit by maximum likelihood
>   Data: Fu
>        AIC      BIC    logLik
>   656.7007 665.9262 -325.3503
>
>  Random effects:
>   Formula:  ~ 1 | subjec
>         (Intercept) Residual
>  StdDev:   0.9674476 1.721595
>
>  Fixed effects: Y ~ 1
>              Value Std.Error  DF  t-value p-value
>  (Intercept) 3.4875 0.2783988 144 12.52699  <.0001
>
>  Standardized Within-Group Residuals:
>        Min         Q1        Med        Q3      Max
>   -2.244476 -0.7371921 -0.2445665 0.8289158 2.608248
>
>  Number of Observations: 160
>  Number of Groups: 16
>   > Fu.mod1.lme <- lme(Y ~ expvariable, random=~1|subjec, data = Fu,
>  na.action=na.omit, method="ML")
>   > summary(Fu.mod1.lme)
>  Linear mixed-effects model fit by maximum likelihood
>   Data: Fu
>        AIC     BIC    logLik
>   639.7835 651.983 -315.8918
>
>  Random effects:
>   Formula:  ~ 1 | subjec
>         (Intercept) Residual
>  StdDev:    1.017715 1.696945
>
>  Fixed effects: Y ~ expvariable
>                Value Std.Error  DF  t-value p-value
>  (Intercept) 3.267305 0.3164881 139 10.32363  <.0001
>  expvariable 0.413960 0.2874080 139  1.44032   0.152
>
>  Standardized Within-Group Residuals:
>      Min         Q1        Med        Q3      Max
>   -2.4028 -0.6934754 -0.2075537 0.7346619 2.768138
>
>  Number of Observations: 156
>  Number of Groups: 16
>   > anova(Fu.mod0.lme, Fu.mod1.lme)
>  Problem in anova.lme(Fu.mod0.lme, Fu.mod1.lme): All fitted objects must
>  use the same number of observations
>  Use traceback() to see the call stack
>
>  --
>  Olivier.Renaud at pse.unige.ch             http://www.unige.ch/~renaud/
>  Methodology & Data Analysis - Psychology Dept - University of Geneva
>  UniMail, Office 4142  -  40, Bd du Pont d'Arve   -  CH-1211 Geneva 4
>
>  _______________________________________________
>  R-sig-mixed-models at r-project.org mailing list
>  https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From spencer.graves at pdf.com  Sun Apr 13 19:10:50 2008
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 13 Apr 2008 10:10:50 -0700
Subject: [R-sig-ME] prediction intervals from a mixed-effects models?
Message-ID: <48023E9A.5060606@pdf.com>

      How can I get prediction intervals from a mixed-effects model?  
Consider the following example: 

library(nlme)
fm3 <- lme(distance ~ age*Sex, data = Orthodont, random = ~ 1)
df3.1 <- with(Orthodont, data.frame(age=seq(5, 20, 5),
                    Subject=rep(Subject[1], 4),
                    Sex=rep(Sex[1], 4)))
predict(fm3, df3.1, interval='prediction')
#      M01      M01      M01      M01
# 22.69012 26.61199 30.53387 34.45574

# NOTE:  The 'interval' argument to the 'predict' function was ignored. 
# It works works for an 'lm' object, but not an 'lme' object. 

      One way to do this might be via mcmcsamp of the corresponding 
'lmer' model: 

library(lme4)
set.seed(3)
samp3r <- mcmcsamp(fm3r, n=10000)
samp3r[1:2,]

      Then use library(coda) to check convergence and write a function 
to simulate a single observation from each set of simulated parameters 
and compute quantile(..., c(.025, .975)) for each prediction level 
desired. 

      However, before I coded that, I thought I would ask if some easier 
method might be available. 

      Thanks,
      Spencer
p.s.  RSiteSearch("lme prediction intervals") produced 3 hits including 
2 from James A Rogers over 3 years ago.  In one, he said, "I am not 
aware of any published R function that gives you prediction intervals or 
tolerance intervals for lme models." 
(http://finzi.psych.upenn.edu/R/Rhelp02a/archive/42781.html)   In the 
other, he provided sample code for prediction or tolerance intervals of 
lme variance components.  
(http://finzi.psych.upenn.edu/R/Rhelp02a/archive/44675.html)



From reinhold.kliegl at gmail.com  Mon Apr 14 09:41:29 2008
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Mon, 14 Apr 2008 09:41:29 +0200
Subject: [R-sig-ME] prediction intervals from a mixed-effects models?
In-Reply-To: <48023E9A.5060606@pdf.com>
References: <48023E9A.5060606@pdf.com>
Message-ID: <aefe4d0a0804140041y7feeeffdv5f19ccf876ca483a@mail.gmail.com>

Spencer,

I think the Gelman & Hill (2007) book has examples that look less
complicated to me in comparison to what you describe (i.e. simply
sample from the estimated distributions). I have some code for
computation of power, also following examples in this book. Perhaps, I
am overlooking something.

Reinhold

On Sun, Apr 13, 2008 at 7:10 PM, Spencer Graves <spencer.graves at pdf.com> wrote:
>       How can I get prediction intervals from a mixed-effects model?
>  Consider the following example:
>
>  library(nlme)
>  fm3 <- lme(distance ~ age*Sex, data = Orthodont, random = ~ 1)
>  df3.1 <- with(Orthodont, data.frame(age=seq(5, 20, 5),
>                     Subject=rep(Subject[1], 4),
>                     Sex=rep(Sex[1], 4)))
>  predict(fm3, df3.1, interval='prediction')
>  #      M01      M01      M01      M01
>  # 22.69012 26.61199 30.53387 34.45574
>
>  # NOTE:  The 'interval' argument to the 'predict' function was ignored.
>  # It works works for an 'lm' object, but not an 'lme' object.
>
>       One way to do this might be via mcmcsamp of the corresponding
>  'lmer' model:
>
>  library(lme4)
>  set.seed(3)
>  samp3r <- mcmcsamp(fm3r, n=10000)
>  samp3r[1:2,]
>
>       Then use library(coda) to check convergence and write a function
>  to simulate a single observation from each set of simulated parameters
>  and compute quantile(..., c(.025, .975)) for each prediction level
>  desired.
>
>       However, before I coded that, I thought I would ask if some easier
>  method might be available.
>
>       Thanks,
>       Spencer
>  p.s.  RSiteSearch("lme prediction intervals") produced 3 hits including
>  2 from James A Rogers over 3 years ago.  In one, he said, "I am not
>  aware of any published R function that gives you prediction intervals or
>  tolerance intervals for lme models."
>  (http://finzi.psych.upenn.edu/R/Rhelp02a/archive/42781.html)   In the
>  other, he provided sample code for prediction or tolerance intervals of
>  lme variance components.
>  (http://finzi.psych.upenn.edu/R/Rhelp02a/archive/44675.html)
>
>  _______________________________________________
>  R-sig-mixed-models at r-project.org mailing list
>  https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From nikko at hailmail.net  Mon Apr 14 18:57:17 2008
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: Mon, 14 Apr 2008 12:57:17 -0400
Subject: [R-sig-ME] prediction intervals from a mixed-effects models?
In-Reply-To: <mailman.3.1208167202.2225.r-sig-mixed-models@r-project.org>
References: <mailman.3.1208167202.2225.r-sig-mixed-models@r-project.org>
Message-ID: <1208192238.20315.1247805099@webmail.messagingengine.com>

Hi,
I think Doug made a comment a few weeks ago about why there was as
yet not a predict method for lme4, to the effect that there are so
many different things that can be extracted from the model. And
I have searched before for code for prediction intervals with a 
similar outcome. I think the mcmcsamp function offers a really
nice way to get prediction intervals, since effectively any function
of the parameters can be applied to the mcmcsample and get a valid
prediction (credible set) interval (am I remembering my Bayesian 
statistics correctly, it is the joint distribution right?) 

I have been toying with writing a general predict method for
lmer objects, given that Doug has elaborated quite a bit on the
underlying mer structures and algorithms. I suspect that 
this won't be as easy for glmm's, or is it again just a
matter of twiddling with the joint posterior distribution 
of the parameters? 

Doug would you accept a predict method for lme4, or should
that go into a separate package. I am also thinking
of tackling splines, but that won't be next week.

Nicholas

> Message: 2
> Date: Sun, 13 Apr 2008 10:10:50 -0700
> From: Spencer Graves <spencer.graves at pdf.com>
> Subject: [R-sig-ME] prediction intervals from a mixed-effects models?
> To: r-sig-mixed-models at r-project.org, r-help at r-project.org
> Message-ID: <48023E9A.5060606 at pdf.com>
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
> 
>       How can I get prediction intervals from a mixed-effects model?  
> Consider the following example: 
> 
> library(nlme)
> fm3 <- lme(distance ~ age*Sex, data = Orthodont, random = ~ 1)
> df3.1 <- with(Orthodont, data.frame(age=seq(5, 20, 5),
>                     Subject=rep(Subject[1], 4),
>                     Sex=rep(Sex[1], 4)))
> predict(fm3, df3.1, interval='prediction')
> #      M01      M01      M01      M01
> # 22.69012 26.61199 30.53387 34.45574
> 
> # NOTE:  The 'interval' argument to the 'predict' function was ignored. 
> # It works works for an 'lm' object, but not an 'lme' object. 
> 
>       One way to do this might be via mcmcsamp of the corresponding 
> 'lmer' model: 
> 
> library(lme4)
> set.seed(3)
> samp3r <- mcmcsamp(fm3r, n=10000)
> samp3r[1:2,]
> 
>       Then use library(coda) to check convergence and write a function 
> to simulate a single observation from each set of simulated parameters 
> and compute quantile(..., c(.025, .975)) for each prediction level 
> desired. 
> 
>       However, before I coded that, I thought I would ask if some easier 
> method might be available. 
> 
>       Thanks,
>       Spencer
> p.s.  RSiteSearch("lme prediction intervals") produced 3 hits including 
> 2 from James A Rogers over 3 years ago.  In one, he said, "I am not 
> aware of any published R function that gives you prediction intervals or 
> tolerance intervals for lme models." 
> (http://finzi.psych.upenn.edu/R/Rhelp02a/archive/42781.html)   In the 
> other, he provided sample code for prediction or tolerance intervals of 
> lme variance components.  
> (http://finzi.psych.upenn.edu/R/Rhelp02a/archive/44675.html)
> 
> 
>



From gregor.gorjanc at bfro.uni-lj.si  Mon Apr 14 19:15:51 2008
From: gregor.gorjanc at bfro.uni-lj.si (Gregor Gorjanc)
Date: Mon, 14 Apr 2008 17:15:51 +0000 (UTC)
Subject: [R-sig-ME] prediction intervals from a mixed-effects models?
References: <48023E9A.5060606@pdf.com>
	<aefe4d0a0804140041y7feeeffdv5f19ccf876ca483a@mail.gmail.com>
Message-ID: <loom.20080414T171512-999@post.gmane.org>

Take a look at Zelig. There is a function that worked with previous versions of
lme4.

Gregor



From lamprianou at yahoo.com  Tue Apr 15 08:34:34 2008
From: lamprianou at yahoo.com (Iasonas Lamprianou)
Date: Mon, 14 Apr 2008 23:34:34 -0700 (PDT)
Subject: [R-sig-ME] 3-level binomial model
Message-ID: <872996.94483.qm@web54110.mail.re2.yahoo.com>

Hi all of you,
I have a problem. I run a model having pupils nested within schools. Each pupil took a number of different tests e.g. maths, science etc. All in all I had 7 different tests, most of the pupils took all of them. So, my model is school:pupil:tests (7 tests, the same for all pupils). The dependent variable is binomial (0/1). I got the results in lme4. This was the model:
ABERRANT/NON-ABERRANT ~ CONSTANT + PAPERFixed + SCHOOLRandom + PUPILRandom 

I computed the school-level and the pupil-level variance like that (as described for 2-level models in MlWin manual): I assumed that my dependent variable is based on a continuous unobserved variable (perfectly valid according to my theoretical model). Therefore, eijk follows a logistic distribution with variance pi2/3=3.29. So,
VPCschool=VARschool/(VARschool+3.29)=  0.17577/(0.17577+3.29)=6.4% and VPCpupil=VPCpupil  /(VPCpupil+3.29)=0.19977/(0.19977+3.29)=7.3%. The reviewers of my paper are not sure if this is the best way to do it. They may reject my paper and I worry because I have spent 3months!!!! writing it. Any ideas to support my method or to use a better one? These are the results of lme4:

AIC  BIC logLik deviance
 6372 6440  -3177     6354
 
Random effects:
 Groups Name        Variance Std.Dev.
 Pupils     (Intercept) 0.19977  0.44696 
 Schools    (Intercept) 0.17577  0.41925 
number of observations: 14829, groups: Pupils= 2230; Schools= 151
 
Fixed effects:
                     Estimate Std. Error z value Pr(>|z|)    
(Intercept)         -3.04953    0.10565 -28.866  <0.001 ***
PAPER[Reading]       0.37060    0.13023   2.846  0.00443 ** 
PAPER[Maths A]       0.17508    0.13536   1.293  0.19585    
PAPER[Maths B]      -0.07881    0.14298  -0.551  0.58148    
PAPER[Mental Maths]  0.01880    0.14130   0.133  0.89418    
PAPER[Science A]     0.10525    0.13842   0.760  0.44703    
PAPER[Science B]    -0.18359    0.14958  -1.227  0.21970    
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 
 
Correlation of Fixed Effects:
            (Intr)  Read   MathA    MathB   MathMental  SciA
PAPER[Read] -0.715                                               
PAPER[MatA] -0.688  0.558                                        
PAPER[MatB] -0.652  0.528  0.510                                 
PAPER[MatM] -0.658  0.534  0.514      0.487                      
PAPER[SciA] -0.672  0.545  0.525      0.497      0.504           
PAPER[SciB] -0.622  0.505  0.486      0.460      0.467  0.476
 

Dr. Iasonas Lamprianou
Department of Education
The University of Manchester
Oxford Road, Manchester M13 9PL, UK
Tel. 0044 161 275 3485
iasonas.lamprianou at manchester.ac.uk


----- Original Message ----
From: "r-sig-mixed-models-request at r-project.org" <r-sig-mixed-models-request at r-project.org>
To: r-sig-mixed-models at r-project.org
Sent: Friday, 4 April, 2008 1:00:02 PM
Subject: R-sig-mixed-models Digest, Vol 16, Issue 12

Send R-sig-mixed-models mailing list submissions to
    r-sig-mixed-models at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
    https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
or, via email, send a message with subject or body 'help' to
    r-sig-mixed-models-request at r-project.org

You can reach the person managing the list at
    r-sig-mixed-models-owner at r-project.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-mixed-models digest..."


Today's Topics:

  1. Re: random effects specification (Douglas Bates)
  2. Re: random effects specification (Sebastian P. Luque)


----------------------------------------------------------------------

Message: 1
Date: Thu, 3 Apr 2008 17:32:40 -0500
From: "Douglas Bates" <bates at stat.wisc.edu>
Subject: Re: [R-sig-ME] random effects specification
To: "Sebastian P. Luque" <spluque at gmail.com>
Cc: r-sig-mixed-models at r-project.org
Message-ID:
    <40e66e0b0804031532q12880b01mcba6173fc3e32c10 at mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1

On Thu, Apr 3, 2008 at 3:45 PM, Sebastian P. Luque <spluque at gmail.com> wrote:
> Hi,

>  In the past I've used lme to fit simple mixed models to longitudinal
>  data (growth), but now I'm trying to learn lmer and its different syntax
>  to fit a more complex model.  I have a structure with subjects (id,
>  random factor) exposed to 4 different treatments and a continuous
>  response variable is measured (n).  The subjects come from 2 different
>  communities, so it's a nested design very much like the Oats data in the
>  nlme package.  The interest is in the fixed effects of community and
>  treatment, and their interaction, so I thought this could be modelled in
>  lmer with this call:

>  lmer(n ~ treatment + community + (1 | id/treatment), mydata)

>  but got this error:

>  Error in lmerFactorList(formula, mf, fltype) :
>  number of levels in grouping factor(s) 'treatment:id' is too large

>  Am I using the right formula here?  Thanks.

It seems that the observations are indexed by subject and treatment so
the number of levels in the factor treatment:id equals the number of
observations.  You can't estimate a variance for such a term and also
estimate a residual variance.

I would start with

n ~ treatment * community +(1|id)



------------------------------

Message: 2
Date: Thu, 03 Apr 2008 18:32:23 -0500
From: "Sebastian P. Luque" <spluque at gmail.com>
Subject: Re: [R-sig-ME] random effects specification
To: r-sig-mixed-models at r-project.org
Message-ID: <878wzuzf94.fsf at patagonia.sebmags.homelinux.org>
Content-Type: text/plain; charset=us-ascii

On Thu, 3 Apr 2008 17:32:40 -0500,
"Douglas Bates" <bates at stat.wisc.edu> wrote:

[...]

> It seems that the observations are indexed by subject and treatment so
> the number of levels in the factor treatment:id equals the number of
> observations.  You can't estimate a variance for such a term and also
> estimate a residual variance.

> I would start with

> n ~ treatment * community +(1|id)

Yes, the observations are indexed by subject and treatment in the sense
that id levels are the same within treatments of the same community, but
are different among communities.  This is a subset of the data:

---<---------------cut here---------------start-------------->---
id  community treatment    n
1          A        1 13.93
2          A        1 14.42
3          A        1 13.56
1          A        2 14.61
2          A        2 14.74
3          A        2 15.59
1          A        3 13.95
2          A        3 15.21
3          A        3 14.51
1          A        4 13.61
2          A        4 14.99
3          A        4 15.13
4          B        1 14.79
5          B        1 13.41
6          B        1 14.71
4          B        2 14.69
5          B        2 13.46
6          B        2 14.28
4          B        3 14.30
5          B        3 13.18
6          B        3 13.58
4          B        4 14.54
5          B        4 13.25
6          B        4 14.09
---<---------------cut here---------------end---------------->---

Of course, there are many more individuals, but the levels of id differ
among communities, and are the same among treatments.  lmer did converge
rapidly with your suggested formula though:

---<---------------cut here---------------start-------------->---
Linear mixed-effects model fit by REML 
Formula: n ~ treatment * community + (1 | id) 
  Data: isotope.m.ph 
AIC BIC logLik MLdeviance REMLdeviance
450 481  -216        410          432
Random effects:
Groups  Name        Variance Std.Dev.
id      (Intercept) 0.193    0.439  
Residual            0.232    0.481  
number of obs: 240, groups: id, 61

Fixed effects:
                              Estimate Std. Error t value
(Intercept)                    14.9748    0.1170  128.0
treatment2                      0.0884    0.1222    0.7
treatment3                      -0.2829    0.1222    -2.3
treatment4                      0.3568    0.1222    2.9
communitysanikiluaq            -0.5749    0.1678    -3.4
treatment2:communitysanikiluaq  -0.2471    0.1763    -1.4
treatment3:communitysanikiluaq  -0.7479    0.1763    -4.2
treatment4:communitysanikiluaq  -0.6169    0.1763    -3.5

Correlation of Fixed Effects:
            (Intr) trtmn2 trtmn3 trtmn4 cmmnty trtm2: trtm3:
treatment2  -0.522                                          
treatment3  -0.522  0.500                                  
treatment4  -0.522  0.500  0.500                            
cmmntysnklq -0.697  0.364  0.364  0.364                    
trtmnt2:cmm  0.362 -0.693 -0.347 -0.347 -0.524              
trtmnt3:cmm  0.362 -0.347 -0.693 -0.347 -0.524  0.503      
trtmnt4:cmm  0.362 -0.347 -0.347 -0.693 -0.524  0.503  0.503
---<---------------cut here---------------end---------------->---


However, I don't understand how (1 | id) accounts for treatment being
nested within community.  Maybe it's time for me to re-read some more
examples from "Mixed-effects models in S and S-plus".  Thanks.


Cheers,

-- 
Seb



------------------------------

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


End of R-sig-mixed-models Digest, Vol 16, Issue 12
**************************************************


      ___________________________________________________________ 
Yahoo! For Good helps you make a difference  




From kevin.thorpe at utoronto.ca  Tue Apr 15 14:53:45 2008
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Tue, 15 Apr 2008 08:53:45 -0400
Subject: [R-sig-ME] Fwd: same old question - lme4 and p-values
In-Reply-To: <48015B72.7010807@zoo.ufl.edu>
References: <28642179.2370001207304657364.JavaMail.nabble@isper.nabble.com>	<40e66e0b0804040554m41e63d58l3a5825924696cf78@mail.gmail.com>	<40e66e0b0804040633k619803fayfd2e9b9b07b88b77@mail.gmail.com>	<47FF6351.9010506@utoronto.ca>	<aefe4d0a0804120502o726c27edx9be1b4c959c6aadc@mail.gmail.com>
	<20080412211859.GT97781@ms.unimelb.edu.au>
	<48015B72.7010807@zoo.ufl.edu>
Message-ID: <4804A559.7020802@utoronto.ca>

Thanks for this pointer Ben.  Too bad the wiki is still down. :-(

I was able to retrieve a cached page from a Google search.
I think (hope) this will do the trick.

One more question.  Would there be an "official" citation to
this information appropriate as a reference in the manuscript?

Ben Bolker wrote:
>   Also note that in the long thread on the R wiki
> (wiki.r-project.org, search for "bates mixed" or some such --
> I can't get through to it right now) DB suggests an
> test for a composite hypothesis a_1=a_2=...=a_n=0
> along with R code to do it ...
> 
> Andrew Robinson wrote:
>> On Sat, Apr 12, 2008 at 02:02:09PM +0200, Reinhold Kliegl wrote:
>>> On Fri, Apr 11, 2008 at 3:10 PM, Kevin E. Thorpe
>>> <kevin.thorpe at utoronto.ca> wrote:
>>>> This has been a very interesting thread.  However, I'm still
>>>>  wrestling with what to do for a fixed-effect that has more than
>>>>  one degree of freedom.
>>>>
>>>>  In the data I'm analyzing, I have three groups to compare.
>>>>
>>>>  So, I can get CIs for the two parameters, but that is a bit
>>>>  problematic for assessing an overall difference.
>>>>
>>>>  Is it valid to do the following?  Estimate the parameters using both
>>>>  ML and REML.  If the estimates show good agreement, is that sufficient
>>>>  evidence to conclude the ML procedure is converging and that I can
>>>>  use a likelihood ratio test for the fixed effect?
>>>>
>>> I assume you refer to using anova(fm1, fm2) with fm1 fitting the model
>>> without the fixed effect. This a comparison of nested models, so a
>>> likelihood ratio test can be defined for ML fits only. Note, however,
>>> that Pinheiro & Bates (2000, p. 87, 2.4.2) "do not recommend using
>>> such tests"; "not" is set in bold face. They show that such tests tend
>>> to be anti-conservative, especially if the number of parameters
>>> removed is large relative to the number of observations. Assuming you
>>> have a decent number of total observations, you may be fine.
>>> Alternatively, you may want to run a simulation for your situation;
>>> you will also find R-code examples in the P&B section.
>>
>> I agree with Reinhold's position, here.  I also note in passing that
>> Doug uses this strategy to test the fixed effects in the cake data
>> (see ?cake).  Doug, does the cake data analysis represent a softening
>> on your position or a place-filler?
>>  
>>> My first reaction to your email was: Why is he only interested in the
>>> overall effect of a fixed factor and not in specific comparisons
>>> between its levels? After Andrew's comment to an earlier post, I
>>> understand that there are such situations where you just want to
>>> control for an aspect of the design that is not in the focus of your
>>> theoretical concerns (e.g., in ecology you may have three sites that
>>> could be characterized as levels of a fixed factor or as a sample from
>>> a random factor). Perhaps  your fixed factor may also be better
>>> conceptualized as a random factor. In a way, you just want to control
>>> for the variance contributed by this factor. If this applies to your
>>> data, then you may be better off to specify your fixed factor as a
>>> random factor. Then, your anova(fm1, fm2) compares nested models that
>>> differ only in the random-effects part. In this case the likelihood
>>> ratio test can be used with models fit by REML. These tests tend to be
>>> conservative (Pinheiro & Bates, 2000, p. 2.4.1; following up on Stram
>>> & Lee, 1994). So if your ANOVA statistic is significant, you are on
>>> the save side; if not, you do not know. Also keep in mind, that random
>>> effects with few units may generate problems for model convergence.
>>
>> That's an interesting idea, even if the interpretation is intended to
>> be a fixed factor.  It might work to a certain order of approximation,
>> but I'm not clear how the math would play out.  Some simulations might
>> provide a measure of comfort in individual situations.
>>
>> Best wishes,
>>
>> Andrew
>>
> 
> 


-- 
Kevin E. Thorpe
Biostatistician/Trialist, Knowledge Translation Program
Assistant Professor, Department of Public Health Sciences
Faculty of Medicine, University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.6057



From tapmehta at yahoo.com  Tue Apr 15 19:34:27 2008
From: tapmehta at yahoo.com (Tapan Mehta)
Date: Tue, 15 Apr 2008 10:34:27 -0700 (PDT)
Subject: [R-sig-ME] user defined covariance structure in lme4 /nlme
Message-ID: <231285.63753.qm@web31915.mail.mud.yahoo.com>

Hi all,

I am trying to use the lme4 /nlme  package to fit a mixed model on pedigree data.I would really appreciate if anyone of you could forward an example of inputting a user defined covariance structure for the random effects. I tried using the 'start' argument in the lmer method of the lme4 package but was not successful. I am not sure either whether the 'start' argument will help me achieve this.

 I have also tried using the nlme package to achieve this. Initialize.corSymm was the method I used and implemented it in the way described below

lData<-c(0.0,0.5,0.5)
cs1Symm<-corSymm(ldata,form=~ fam_dat$FAM_ID)
cs2Symm<-Initialize(cs1Symm,data=fam_dat)
testRes <- lme(Y ~ X1 + X2, random=~ 1|FAM_ID,correlation=cs2Symm,data=fam_dat)

I did not find any example in the documentation of the package that shows this. It would really be helpful if somebody could point me out any existing documentation on how to fit a user defined covariance structure either using lme4 or the nlme package.

Please let me know if you need any further information.

Thanks,

Tapan



From A.Robinson at ms.unimelb.edu.au  Tue Apr 15 21:22:42 2008
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Wed, 16 Apr 2008 05:22:42 +1000
Subject: [R-sig-ME] 3-level binomial model
In-Reply-To: <872996.94483.qm@web54110.mail.re2.yahoo.com>
References: <872996.94483.qm@web54110.mail.re2.yahoo.com>
Message-ID: <20080415192242.GQ97781@ms.unimelb.edu.au>

Hi Iasonas,

a few observations, questions, suggestions:

1) it's not clear to me what you are trying to do, so I can't comment
   on the technique.  What is your goal for estimating VPCschool and
   VPCpupil?  Those percentages don't make sense to me. I would
   ordinarily assume that if such a decomposition is possible, then
   VPCschool = VARschool/(VARschool+VARpupil+3.29) and 
   VPCpupil = VARpupil/(VARschool+VARpupil+3.29)

2) does the MlWin manual not provide a citation for their suggestion?
   If so you could use that.  If not, you could contact the authors
   and explain the problem.  Perhaps they can help.

3) do the reviewers not provide more guidance?  "not sure if this is
   the best way" is not the same as "sure that this is not the best
   way", and in any case, sometimes the not-the-best way is just
   fine.  Can you contact the Associate Editor via the journal and ask
   for more guidance? Eg emphasize that you are willing to use a
   different technique but you are unaware of any, and if the
   reviewers could provide a pointer to a suitable technique it would
   be very helpful.

4) 3 months is a doddle.  I just got a paper accepted that I started 7
   years ago.

I hope that these thoughts help,

Andrew

On Mon, Apr 14, 2008 at 11:34:34PM -0700, Iasonas Lamprianou wrote:
> Hi all of you,
> I have a problem. I run a model having pupils nested within schools. Each pupil took a number of different tests e.g. maths, science etc. All in all I had 7 different tests, most of the pupils took all of them. So, my model is school:pupil:tests (7 tests, the same for all pupils). The dependent variable is binomial (0/1). I got the results in lme4. This was the model:
> ABERRANT/NON-ABERRANT ~ CONSTANT + PAPERFixed + SCHOOLRandom + PUPILRandom 
> 
> I computed the school-level and the pupil-level variance like that (as described for 2-level models in MlWin manual): I assumed that my dependent variable is based on a continuous unobserved variable (perfectly valid according to my theoretical model). Therefore, eijk follows a logistic distribution with variance pi2/3=3.29. So,
> VPCschool=VARschool/(VARschool+3.29)=  0.17577/(0.17577+3.29)=6.4% and VPCpupil=VPCpupil  /(VPCpupil+3.29)=0.19977/(0.19977+3.29)=7.3%. The reviewers of my paper are not sure if this is the best way to do it. They may reject my paper and I worry because I have spent 3months!!!! writing it. Any ideas to support my method or to use a better one? These are the results of lme4:
> 
> AIC  BIC logLik deviance
>  6372 6440  -3177     6354
>  
> Random effects:
>  Groups Name        Variance Std.Dev.
>  Pupils     (Intercept) 0.19977  0.44696 
>  Schools    (Intercept) 0.17577  0.41925 
> number of observations: 14829, groups: Pupils= 2230; Schools= 151
>  
> Fixed effects:
>                      Estimate Std. Error z value Pr(>|z|)    
> (Intercept)         -3.04953    0.10565 -28.866  <0.001 ***
> PAPER[Reading]       0.37060    0.13023   2.846  0.00443 ** 
> PAPER[Maths A]       0.17508    0.13536   1.293  0.19585    
> PAPER[Maths B]      -0.07881    0.14298  -0.551  0.58148    
> PAPER[Mental Maths]  0.01880    0.14130   0.133  0.89418    
> PAPER[Science A]     0.10525    0.13842   0.760  0.44703    
> PAPER[Science B]    -0.18359    0.14958  -1.227  0.21970    
> ---
> Signif. codes:  0 ???***??? 0.001 ???**??? 0.01 ???*??? 0.05 ???.??? 0.1 ??? ??? 1 
>  
> Correlation of Fixed Effects:
>             (Intr)  Read   MathA    MathB   MathMental  SciA
> PAPER[Read] -0.715                                               
> PAPER[MatA] -0.688  0.558                                        
> PAPER[MatB] -0.652  0.528  0.510                                 
> PAPER[MatM] -0.658  0.534  0.514      0.487                      
> PAPER[SciA] -0.672  0.545  0.525      0.497      0.504           
> PAPER[SciB] -0.622  0.505  0.486      0.460      0.467  0.476
>  
> 
> Dr. Iasonas Lamprianou
> Department of Education
> The University of Manchester
> Oxford Road, Manchester M13 9PL, UK
> Tel. 0044 161 275 3485
> iasonas.lamprianou at manchester.ac.uk
> 
> 
> ----- Original Message ----
> From: "r-sig-mixed-models-request at r-project.org" <r-sig-mixed-models-request at r-project.org>
> To: r-sig-mixed-models at r-project.org
> Sent: Friday, 4 April, 2008 1:00:02 PM
> Subject: R-sig-mixed-models Digest, Vol 16, Issue 12
> 
> Send R-sig-mixed-models mailing list submissions to
>     r-sig-mixed-models at r-project.org
> 
> To subscribe or unsubscribe via the World Wide Web, visit
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> or, via email, send a message with subject or body 'help' to
>     r-sig-mixed-models-request at r-project.org
> 
> You can reach the person managing the list at
>     r-sig-mixed-models-owner at r-project.org
> 
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-sig-mixed-models digest..."
> 
> 
> Today's Topics:
> 
>   1. Re: random effects specification (Douglas Bates)
>   2. Re: random effects specification (Sebastian P. Luque)
> 
> 
> ----------------------------------------------------------------------
> 
> Message: 1
> Date: Thu, 3 Apr 2008 17:32:40 -0500
> From: "Douglas Bates" <bates at stat.wisc.edu>
> Subject: Re: [R-sig-ME] random effects specification
> To: "Sebastian P. Luque" <spluque at gmail.com>
> Cc: r-sig-mixed-models at r-project.org
> Message-ID:
>     <40e66e0b0804031532q12880b01mcba6173fc3e32c10 at mail.gmail.com>
> Content-Type: text/plain; charset=ISO-8859-1
> 
> On Thu, Apr 3, 2008 at 3:45 PM, Sebastian P. Luque <spluque at gmail.com> wrote:
> > Hi,
> 
> >  In the past I've used lme to fit simple mixed models to longitudinal
> >  data (growth), but now I'm trying to learn lmer and its different syntax
> >  to fit a more complex model.  I have a structure with subjects (id,
> >  random factor) exposed to 4 different treatments and a continuous
> >  response variable is measured (n).  The subjects come from 2 different
> >  communities, so it's a nested design very much like the Oats data in the
> >  nlme package.  The interest is in the fixed effects of community and
> >  treatment, and their interaction, so I thought this could be modelled in
> >  lmer with this call:
> 
> >  lmer(n ~ treatment + community + (1 | id/treatment), mydata)
> 
> >  but got this error:
> 
> >  Error in lmerFactorList(formula, mf, fltype) :
> >  number of levels in grouping factor(s) 'treatment:id' is too large
> 
> >  Am I using the right formula here?  Thanks.
> 
> It seems that the observations are indexed by subject and treatment so
> the number of levels in the factor treatment:id equals the number of
> observations.  You can't estimate a variance for such a term and also
> estimate a residual variance.
> 
> I would start with
> 
> n ~ treatment * community +(1|id)
> 
> 
> 
> ------------------------------
> 
> Message: 2
> Date: Thu, 03 Apr 2008 18:32:23 -0500
> From: "Sebastian P. Luque" <spluque at gmail.com>
> Subject: Re: [R-sig-ME] random effects specification
> To: r-sig-mixed-models at r-project.org
> Message-ID: <878wzuzf94.fsf at patagonia.sebmags.homelinux.org>
> Content-Type: text/plain; charset=us-ascii
> 
> On Thu, 3 Apr 2008 17:32:40 -0500,
> "Douglas Bates" <bates at stat.wisc.edu> wrote:
> 
> [...]
> 
> > It seems that the observations are indexed by subject and treatment so
> > the number of levels in the factor treatment:id equals the number of
> > observations.  You can't estimate a variance for such a term and also
> > estimate a residual variance.
> 
> > I would start with
> 
> > n ~ treatment * community +(1|id)
> 
> Yes, the observations are indexed by subject and treatment in the sense
> that id levels are the same within treatments of the same community, but
> are different among communities.  This is a subset of the data:
> 
> ---<---------------cut here---------------start-------------->---
> id  community treatment    n
> 1          A        1 13.93
> 2          A        1 14.42
> 3          A        1 13.56
> 1          A        2 14.61
> 2          A        2 14.74
> 3          A        2 15.59
> 1          A        3 13.95
> 2          A        3 15.21
> 3          A        3 14.51
> 1          A        4 13.61
> 2          A        4 14.99
> 3          A        4 15.13
> 4          B        1 14.79
> 5          B        1 13.41
> 6          B        1 14.71
> 4          B        2 14.69
> 5          B        2 13.46
> 6          B        2 14.28
> 4          B        3 14.30
> 5          B        3 13.18
> 6          B        3 13.58
> 4          B        4 14.54
> 5          B        4 13.25
> 6          B        4 14.09
> ---<---------------cut here---------------end---------------->---
> 
> Of course, there are many more individuals, but the levels of id differ
> among communities, and are the same among treatments.  lmer did converge
> rapidly with your suggested formula though:
> 
> ---<---------------cut here---------------start-------------->---
> Linear mixed-effects model fit by REML 
> Formula: n ~ treatment * community + (1 | id) 
>   Data: isotope.m.ph 
> AIC BIC logLik MLdeviance REMLdeviance
> 450 481  -216        410          432
> Random effects:
> Groups  Name        Variance Std.Dev.
> id      (Intercept) 0.193    0.439  
> Residual            0.232    0.481  
> number of obs: 240, groups: id, 61
> 
> Fixed effects:
>                               Estimate Std. Error t value
> (Intercept)                    14.9748    0.1170  128.0
> treatment2                      0.0884    0.1222    0.7
> treatment3                      -0.2829    0.1222    -2.3
> treatment4                      0.3568    0.1222    2.9
> communitysanikiluaq            -0.5749    0.1678    -3.4
> treatment2:communitysanikiluaq  -0.2471    0.1763    -1.4
> treatment3:communitysanikiluaq  -0.7479    0.1763    -4.2
> treatment4:communitysanikiluaq  -0.6169    0.1763    -3.5
> 
> Correlation of Fixed Effects:
>             (Intr) trtmn2 trtmn3 trtmn4 cmmnty trtm2: trtm3:
> treatment2  -0.522                                          
> treatment3  -0.522  0.500                                  
> treatment4  -0.522  0.500  0.500                            
> cmmntysnklq -0.697  0.364  0.364  0.364                    
> trtmnt2:cmm  0.362 -0.693 -0.347 -0.347 -0.524              
> trtmnt3:cmm  0.362 -0.347 -0.693 -0.347 -0.524  0.503      
> trtmnt4:cmm  0.362 -0.347 -0.347 -0.693 -0.524  0.503  0.503
> ---<---------------cut here---------------end---------------->---
> 
> 
> However, I don't understand how (1 | id) accounts for treatment being
> nested within community.  Maybe it's time for me to re-read some more
> examples from "Mixed-effects models in S and S-plus".  Thanks.
> 
> 
> Cheers,
> 
> -- 
> Seb
> 
> 
> 
> ------------------------------
> 
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> End of R-sig-mixed-models Digest, Vol 16, Issue 12
> **************************************************
> 
> 
>       ___________________________________________________________ 
> Yahoo! For Good helps you make a difference  
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From David.Duffy at qimr.edu.au  Wed Apr 16 04:11:45 2008
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Wed, 16 Apr 2008 12:11:45 +1000 (EST)
Subject: [R-sig-ME] 3-level binomial model
Message-ID: <Pine.LNX.4.64.0804161059270.2730@orpheus.qimr.edu.au>

> I computed the school-level and the pupil-level variance like that
> (as described for 2-level models in MlWin manual): I assumed that
> my dependent variable is based on a continuous unobserved variable
> (perfectly valid according to my theoretical model). Therefore, eijk
> follows a logistic distribution with variance pi2/3=3.29. So,

> VPCschool=VARschool/(VARschool+3.29)= 0.17577/(0.17577+3.29)=6.4% and
> VPCpupil=VPCpupil /(VPCpupil+3.29)=0.19977/(0.19977+3.29)=7.3%.

> The reviewers of my paper are not sure if this is the best way to
> do it. They may reject my paper and I worry because I have spent
> 3months!!!! writing it. Any ideas to support my method or to use a
> better one?

Would an IRT model for seven "items" be more to their taste?  I don't think the
substantive conclusions would be much different.

Cheers, David Duffy.
-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From spencer.graves at pdf.com  Wed Apr 16 05:00:48 2008
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 15 Apr 2008 20:00:48 -0700
Subject: [R-sig-ME] prediction intervals from a mixed-effects models?
In-Reply-To: <loom.20080414T171512-999@post.gmane.org>
References: <48023E9A.5060606@pdf.com>	<aefe4d0a0804140041y7feeeffdv5f19ccf876ca483a@mail.gmail.com>
	<loom.20080414T171512-999@post.gmane.org>
Message-ID: <48056BE0.1000104@pdf.com>

Dear Gregor: 
     
      Thanks for the suggestion.  Scanning "help(pac=Zelig)", I didn't 
see anything that sounded to me like "prediction intervals from a 
mixed-effects model".  Without a more focused suggestions, it seems 
simpler to me to transform somehow the MCMC results into the desired 
prediction intervals. 

      Thanks again. 
      Spencer
p.s.  I noticed that I had inadvertently not copied into my email an 
line needed to make my example self contained.  The following should 
work, as far as it goes: 

library(lme4)
library(MEMSS)
set.seed(3)
fm3r <- lmer(distance~age*Sex+(1|Subject), Orthodont)
samp3r <- mcmcsamp(fm3r, n=10000)

Gregor Gorjanc wrote:
> Take a look at Zelig. There is a function that worked with previous versions of
> lme4.
>
> Gregor
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



From spencer.graves at pdf.com  Wed Apr 16 05:03:47 2008
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 15 Apr 2008 20:03:47 -0700
Subject: [R-sig-ME] prediction intervals from a mixed-effects models?
In-Reply-To: <aefe4d0a0804140041y7feeeffdv5f19ccf876ca483a@mail.gmail.com>
References: <48023E9A.5060606@pdf.com>
	<aefe4d0a0804140041y7feeeffdv5f19ccf876ca483a@mail.gmail.com>
Message-ID: <48056C93.9030002@pdf.com>

Dear Reinhold: 

      Thanks for the suggestion.  The index of Gelman and Hill for 
"prediction" for "multilevel model" mentions pp. 272-275 and 361-363.  
P. 362 starts with "predicting a new unit in an existing group", which 
sounds like what I want.  Now all I need to do is study that book enough 
to be able to do what it says. 

      Thanks again. 
      Spencer

Reinhold Kliegl wrote:
> Spencer,
>
> I think the Gelman & Hill (2007) book has examples that look less
> complicated to me in comparison to what you describe (i.e. simply
> sample from the estimated distributions). I have some code for
> computation of power, also following examples in this book. Perhaps, I
> am overlooking something.
>
> Reinhold
>
> On Sun, Apr 13, 2008 at 7:10 PM, Spencer Graves <spencer.graves at pdf.com> wrote:
>   
>>       How can I get prediction intervals from a mixed-effects model?
>>  Consider the following example:
>>
>>  library(nlme)
>>  fm3 <- lme(distance ~ age*Sex, data = Orthodont, random = ~ 1)
>>  df3.1 <- with(Orthodont, data.frame(age=seq(5, 20, 5),
>>                     Subject=rep(Subject[1], 4),
>>                     Sex=rep(Sex[1], 4)))
>>  predict(fm3, df3.1, interval='prediction')
>>  #      M01      M01      M01      M01
>>  # 22.69012 26.61199 30.53387 34.45574
>>
>>  # NOTE:  The 'interval' argument to the 'predict' function was ignored.
>>  # It works works for an 'lm' object, but not an 'lme' object.
>>
>>       One way to do this might be via mcmcsamp of the corresponding
>>  'lmer' model:
>>
>>  library(lme4)
>>  set.seed(3)
>>  samp3r <- mcmcsamp(fm3r, n=10000)
>>  samp3r[1:2,]
>>
>>       Then use library(coda) to check convergence and write a function
>>  to simulate a single observation from each set of simulated parameters
>>  and compute quantile(..., c(.025, .975)) for each prediction level
>>  desired.
>>
>>       However, before I coded that, I thought I would ask if some easier
>>  method might be available.
>>
>>       Thanks,
>>       Spencer
>>  p.s.  RSiteSearch("lme prediction intervals") produced 3 hits including
>>  2 from James A Rogers over 3 years ago.  In one, he said, "I am not
>>  aware of any published R function that gives you prediction intervals or
>>  tolerance intervals for lme models."
>>  (http://finzi.psych.upenn.edu/R/Rhelp02a/archive/42781.html)   In the
>>  other, he provided sample code for prediction or tolerance intervals of
>>  lme variance components.
>>  (http://finzi.psych.upenn.edu/R/Rhelp02a/archive/44675.html)
>>
>>  _______________________________________________
>>  R-sig-mixed-models at r-project.org mailing list
>>  https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>     
>
>



From Gregor.Gorjanc at bfro.uni-lj.si  Wed Apr 16 09:20:56 2008
From: Gregor.Gorjanc at bfro.uni-lj.si (Gorjanc Gregor)
Date: Wed, 16 Apr 2008 09:20:56 +0200
Subject: [R-sig-ME] prediction intervals from a mixed-effects models?
In-Reply-To: <48056BE0.1000104@pdf.com>
References: <48023E9A.5060606@pdf.com>
	<aefe4d0a0804140041y7feeeffdv5f19ccf876ca483a@mail.gmail.com>
	<loom.20080414T171512-999@post.gmane.org>,<48056BE0.1000104@pdf.com>
Message-ID: <F189E18BBAA8B6479F618B9044CF4E9C4FE2F8602C@owa.bfro.uni-lj.si>

Spencer,

>      Thanks for the suggestion.  Scanning "help(pac=Zelig)", I didn't
> see anything that sounded to me like "prediction intervals from a
> mixed-effects model".  Without a more focused suggestions, it seems
> simpler to me to transform somehow the MCMC results into the desired
> prediction intervals.

library(lme4)
library(MEMSS)
set.seed(3)
data(Orthodont)
fm3r <- lmer(distance ~ age * Sex + (1 | Subject), Orthodont)
fm3r

## Call Zelig wrapper function
fmZ <- zelig(distance ~ age * Sex + tag(1 | Subject), data=Orthodont, model="ls.mixed")
fmZ

xF <- setx(fmZ, Sex = "Female")
xM <- setx(fmZ, Sex = "Male")

## First differences for sex
s.out <- sim(fmZ, x=xF, x1=xM)
summary(s.out)
plot(s.out)

## Only for females
s.outF <- sim(fmZ, x=xF)
summary(s.outF)
plot(s.outF)

## Only for Males
s.outM <- sim(fmZ, x=xM)
summary(s.outM)
plot(s.outM)

The document at

http://gking.harvard.edu/zelig/docs/ls.mixed.pdf

says the following about prediction intervals: "The predicted values (qi$pr) are draws from the normal distribution
defined by mean \mu_{ij} and variance \sigma^2

\mu_{ij} = X_{ij}\beta + Z_{ij}b_{i}

given X_{ij} and Z_{ij} and simulations of \beta and b_{i} from their posterior distributions. The
estimated variance covariance matrices are taken as correct and are themselves not simulated."

I would like to warn that functions in Zelig are a bit error prone as it pulls various bits from "lmer" objects. As we
all witness, lme4 is a fast moving target and Zelig may lag behind! I am also not sure how Zelig handles models
in lmer() that have special structure of random effects ...

Of course, you can always sample from posterior distributions of parameters obtained with mcmcsamp()
function. Perhaps rv package by Jouni Kerman can be used. Anyway, predictions are very easily
done in BUGS, say

model
{
  ## --- Likelihood ---

  for(i in 1:N) {

    y[i] ~ dnorm(mu[i], tauE)
    mu[i] <- int + ...

    y.pred[i] ~ dnorm(mu[i], tauE)
  }

  ## --- Priors ---
  ...


}

Regards, Gregor



From moratti at med.ucm.es  Wed Apr 16 10:05:20 2008
From: moratti at med.ucm.es (Stephan Moratti)
Date: Wed, 16 Apr 2008 10:05:20 +0200
Subject: [R-sig-ME] user defined covariance structure in lme4 /nlme (Tapan
	Mehta)
Message-ID: <4805B340.4050509@med.ucm.es>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080416/33f5ad89/attachment.pl>

From kjbeath at kagi.com  Wed Apr 16 10:14:29 2008
From: kjbeath at kagi.com (Ken Beath)
Date: Wed, 16 Apr 2008 18:14:29 +1000
Subject: [R-sig-ME] 3-level binomial model
In-Reply-To: <Pine.LNX.4.64.0804161059270.2730@orpheus.qimr.edu.au>
References: <Pine.LNX.4.64.0804161059270.2730@orpheus.qimr.edu.au>
Message-ID: <BF8F7D68-E5EA-45E5-A252-A2EC639F0141@kagi.com>

On 16/04/2008, at 12:11 PM, David Duffy wrote:

>> I computed the school-level and the pupil-level variance like that
>> (as described for 2-level models in MlWin manual): I assumed that
>> my dependent variable is based on a continuous unobserved variable
>> (perfectly valid according to my theoretical model). Therefore, eijk
>> follows a logistic distribution with variance pi2/3=3.29. So,
>
>> VPCschool=VARschool/(VARschool+3.29)= 0.17577/(0.17577+3.29)=6.4% and
>> VPCpupil=VPCpupil /(VPCpupil+3.29)=0.19977/(0.19977+3.29)=7.3%.
>
>> The reviewers of my paper are not sure if this is the best way to
>> do it. They may reject my paper and I worry because I have spent
>> 3months!!!! writing it. Any ideas to support my method or to use a
>> better one?
>
> Would an IRT model for seven "items" be more to their taste?  I  
> don't think the
> substantive conclusions would be much different.
>

Multi-level IRT is more appropriate, this allows for the nesting  
within schools. There is a package mlirt that fits these models in a  
Bayesian framework, but I haven't tried it. There are commercial  
programs which will fit these, Mplus is advertised to and Latent Gold  
with the Syntax module will, at least for a unidimensional latent  
variable.

What is more worrying is the assumption of a single latent variable to  
model the correlation between tests.

Ken



From lamprianou at yahoo.com  Wed Apr 16 14:51:07 2008
From: lamprianou at yahoo.com (Iasonas Lamprianou)
Date: Wed, 16 Apr 2008 05:51:07 -0700 (PDT)
Subject: [R-sig-ME] 3-level binomial model
Message-ID: <698746.32661.qm@web54109.mail.re2.yahoo.com>

Thank you all for your suggestions. My question, however, is how to compute the % of the variance at the level of the school and at the level of the pupils. In other words, does the concept of  intraclass correlation hold in my context? If yes, then how can this be computed for the pupils and the schools? Is the decomposistion below reasonable? 
Prof. Bates, maybe you could suggesting something using the lmer?

VPCschool = VARschool/(VARschool+VARpupil+3.29) and 
  VPCpupil = VARpupil/(VARschool+VARpupil+3.29)
 
Dr. Iasonas Lamprianou
Department of Education
The University of Manchester
Oxford Road, Manchester M13 9PL, UK
Tel. 0044 161 275 3485
iasonas.lamprianou at manchester.ac.uk



On 16/04/2008, at 12:11 PM, David Duffy wrote:

>> I computed the school-level and the pupil-level variance like that
>> (as described for 2-level models in MlWin manual): I assumed that
>> my dependent variable is based on a continuous unobserved variable
>> (perfectly valid according to my theoretical model). Therefore, eijk
>> follows a logistic distribution with variance pi2/3=3.29. So,
>
>> VPCschool=VARschool/(VARschool+3.29)= 0.17577/(0.17577+3.29)=6.4% and
>> VPCpupil=VPCpupil /(VPCpupil+3.29)=0.19977/(0.19977+3.29)=7.3%.
>
>> The reviewers of my paper are not sure if this is the best way to
>> do it. They may reject my paper and I worry because I have spent
>> 3months!!!! writing it. Any ideas to support my method or to use a
>> better one?
>
> Would an IRT model for seven "items" be more to their taste?  I  
> don't think the
> substantive conclusions would be much different.
>

Multi-level IRT is more appropriate, this allows for the nesting  
within schools. There is a package mlirt that fits these models in a  
Bayesian framework, but I haven't tried it. There are commercial  
programs which will fit these, Mplus is advertised to and Latent Gold  
with the Syntax module will, at least for a unidimensional latent  
variable.

What is more worrying is the assumption of a single latent variable to  
model the correlation between tests.

Ken



------------------------------

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


End of R-sig-mixed-models Digest, Vol 16, Issue 36
**************************************************


      ___________________________________________________________ 
Yahoo! For Good helps you make a difference  

http://uk.promotions.yahoo.com/forgood/



From gangchen6 at gmail.com  Wed Apr 16 18:00:56 2008
From: gangchen6 at gmail.com (Gang Chen)
Date: Wed, 16 Apr 2008 12:00:56 -0400
Subject: [R-sig-ME] Post hoc tests with lme
Message-ID: <b0f0ada60804160900t2b9dd6d0ve2907d402b5f44db@mail.gmail.com>

Using the "ergoStool" data cited in Mixed-Effects Models in S and
S-PLUS by Pinheiro and Bates as an example, we have

========
> library(nlme)
> fm <- lme(effort~Type-1, data=ergoStool, random=~1|Subject)
> summary(fm)

Linear mixed-effects model fit by REML
  Data: ergoStool
       AIC      BIC   logLik
  133.1308 141.9252 -60.5654

Random effects:
 Formula: ~1 | Subject
        (Intercept) Residual
StdDev:    1.332465 1.100295

Fixed effects: effort ~ Type - 1
           Value Std.Error DF  t-value p-value
TypeT1  8.555556 0.5760123 24 14.85308       0
TypeT2 12.444444 0.5760123 24 21.60448       0
TypeT3 10.777778 0.5760123 24 18.71102       0
TypeT4  9.222222 0.5760123 24 16.01046       0
 Correlation:
       TypeT1 TypeT2 TypeT3
TypeT2 0.595
TypeT3 0.595  0.595
TypeT4 0.595  0.595  0.595

Standardized Within-Group Residuals:
        Min          Q1         Med          Q3         Max
-1.80200345 -0.64316591  0.05783115  0.70099706  1.63142054

Number of Observations: 36
Number of Groups: 9

========

Now suppose I want to test the following hypothesis

H0: TypeT1 =0 and TypeT2 = 0

I've tried estimable() and glh.test() in package gmodels, esticon() in
package boBy, and linear.hypothesis() in package car, but it seems
none of them would work with objects from lme:

========
> library(gmodels)
> estimable(fm, rbind(c("TypeT1"=1), c("TypeT2"=1)))
Error in FUN(newX[, i], ...) :
  `param' has no names and does not match number of coefficients of
model. Unable to construct coefficient vector
> glh.test(fm, rbind(c("TypeT1"=1), c("TypeT2"=1)))
Error in glh.test(fm, rbind(c(TypeT1 = 1), c(TypeT2 = 1))) :
  Only defined for lm,glm objects

> library(doBy)
> esticon(fm, rbind(c("TypeT1"=1), c("TypeT2"=1)))
Error in t(abs(t(tmp) * obj$fixDF$X)) :
  dims [product 2] do not match the length of object [4]
In addition: Warning message:
In esticon.lme(fm, rbind(c(TypeT1 = 1), c(TypeT2 = 1))) :
  The esticon function has not been thoroughly teste on 'lme' objects

> library(car)
> linear.hypothesis(fm, rbind(c("TypeT1"=1), c("TypeT2"=1)))
Error in L %*% b : requires numeric matrix/vector arguments
========

So is there any other package with which I can run this kind of tests?

Thanks,
Gang



From tapmehta at yahoo.com  Wed Apr 16 20:20:42 2008
From: tapmehta at yahoo.com (Tapan Mehta)
Date: Wed, 16 Apr 2008 11:20:42 -0700 (PDT)
Subject: [R-sig-ME] user defined covariance structure in lme4 /nlme
	(Tapan Mehta)
Message-ID: <262092.68563.qm@web31911.mail.mud.yahoo.com>

Thanks Stephan. I appreciate your response. I agree with you about
convergence issue. I ran into this when trying on a slightly more complicated
pedigree data and had to use compound
symmetry matrix.

 I have tried using corSymm but it does not give me correct random
effects estimates as compared to what I get through SAS. I am trying to
estimate the genetic and error variance and based on a simulated data
(through SAS) with genetic variance 7 and error variance 2 whereas the
results I obtain from the code below gives 7.58 and 1.38. 

migGdata<-c(0.0,0.5,0.5)
cs1Symm<-corSymm(migGdata,form=~1 | FAM_ID)
cs2Symm<-Initialize(cs1Symm,data=migTrio)
test<-lme(y ~ x1 + x2, random=~1|FAM_ID,correlation=cs2Symm,data=migTrio)

Let G = k*C, where G is the variance of the random effects, C is a
symmetric positive definite matrix, and k a parameter. We would like to
supply lme /lmer  with C (user defined covariance structure) and let it
estimate k. I am also trying to use the pdSymm method to implement this
but I am running into this error:

 > mt
     [,1] [,2] [,3]
[1,]  1.0  0.0  0.5
[2,]  0.0  1.0  0.5
[3,]  0.5  0.5  1.0
pd2 <- pdSymm(mt,form=~1|FAM_ID,name=c("1","2","3"))
testRes<-lme(Y~X1+X2,random=pd2,data=migTrio)

Error in getGroups.data.frame(dataMix, groups) : 
Invalid formula for groups

Please let me know if any of you can suggest what I need to fix to solve this problem.

Thanks,

Tapan


----- Original Message ----
From: Stephan Moratti <moratti at med.ucm.es>
To: r-sig-mixed-models at r-project.org
Sent: Wednesday, April 16, 2008 3:05:20 AM
Subject: [R-sig-ME] user defined covariance structure in lme4 /nlme (Tapan Mehta)

Hi Tapan,

The following line using lme from the nlme package should work:

testRes <- lme(Y ~X1+X2,random=~1|FAM_ID,correlation=corSymm(form = ~1|FAM_ID),data=fam_dat)

testRes <- lme(Y ~X1+X2,random=~1|FAM_ID,correlation=corSymm(),data=fam_dat) should be equal.

I hope this helps. Sometimes I had the problem that the REML did not converge using the corSymm(), whereas using a compound symmetry structure worked.

Best,

Stephan




-- 
*Stephan Moratti, PhD/
/**/see also: http://web.mac.com/smoratti/
/*Centro de Tecnolog?a Biom?dica CBT,
Universidad Polit?cnica de Madrid,

en la actualidad (currently at) en el
Centro de Magnetoencefalograf?a Dr. Perez Modrego,
Universidad Complutense de Madrid,
Faculdad de Medicina,
Pabell?n 8,
Avda. Complutense, s/n,
28040 Madrid,
Spain,

email: moratti at gbt.tfo.upm.es <mailto:moratti at gbt.tfo.upm.es>
        moratti at med.ucm.es
Tel.:    +34 91 394 2292
Fax.:   +34 91 394 2294
*/
/*

    [[alternative HTML version deleted]]



From kushler at oakland.edu  Wed Apr 16 20:45:33 2008
From: kushler at oakland.edu (Robert Kushler)
Date: Wed, 16 Apr 2008 14:45:33 -0400
Subject: [R-sig-ME] Post hoc tests with lme
In-Reply-To: <b0f0ada60804160900t2b9dd6d0ve2907d402b5f44db@mail.gmail.com>
References: <b0f0ada60804160900t2b9dd6d0ve2907d402b5f44db@mail.gmail.com>
Message-ID: <4806494D.9090707@oakland.edu>


At the risk of annoying Doug Bates, I'll point out that "glht" in
the multcomp package works with lmer objects.  In fact, you can
supply your own degrees of freedom value via the "df" argument
(a fact which is not immediately obvious in the glht help page).
If you don't supply a df value, it will use "Inf" (i.e., normal
instead of t).

Regards,   Rob Kushler


Gang Chen wrote:
> Using the "ergoStool" data cited in Mixed-Effects Models in S and
> S-PLUS by Pinheiro and Bates as an example, we have
> 
> ========
>> library(nlme)
>> fm <- lme(effort~Type-1, data=ergoStool, random=~1|Subject)
>> summary(fm)
> 
> Linear mixed-effects model fit by REML
>   Data: ergoStool
>        AIC      BIC   logLik
>   133.1308 141.9252 -60.5654
> 
> Random effects:
>  Formula: ~1 | Subject
>         (Intercept) Residual
> StdDev:    1.332465 1.100295
> 
> Fixed effects: effort ~ Type - 1
>            Value Std.Error DF  t-value p-value
> TypeT1  8.555556 0.5760123 24 14.85308       0
> TypeT2 12.444444 0.5760123 24 21.60448       0
> TypeT3 10.777778 0.5760123 24 18.71102       0
> TypeT4  9.222222 0.5760123 24 16.01046       0
>  Correlation:
>        TypeT1 TypeT2 TypeT3
> TypeT2 0.595
> TypeT3 0.595  0.595
> TypeT4 0.595  0.595  0.595
> 
> Standardized Within-Group Residuals:
>         Min          Q1         Med          Q3         Max
> -1.80200345 -0.64316591  0.05783115  0.70099706  1.63142054
> 
> Number of Observations: 36
> Number of Groups: 9
> 
> ========
> 
> Now suppose I want to test the following hypothesis
> 
> H0: TypeT1 =0 and TypeT2 = 0
> 
> I've tried estimable() and glh.test() in package gmodels, esticon() in
> package boBy, and linear.hypothesis() in package car, but it seems
> none of them would work with objects from lme:
> 
> ========
>> library(gmodels)
>> estimable(fm, rbind(c("TypeT1"=1), c("TypeT2"=1)))
> Error in FUN(newX[, i], ...) :
>   `param' has no names and does not match number of coefficients of
> model. Unable to construct coefficient vector
>> glh.test(fm, rbind(c("TypeT1"=1), c("TypeT2"=1)))
> Error in glh.test(fm, rbind(c(TypeT1 = 1), c(TypeT2 = 1))) :
>   Only defined for lm,glm objects
> 
>> library(doBy)
>> esticon(fm, rbind(c("TypeT1"=1), c("TypeT2"=1)))
> Error in t(abs(t(tmp) * obj$fixDF$X)) :
>   dims [product 2] do not match the length of object [4]
> In addition: Warning message:
> In esticon.lme(fm, rbind(c(TypeT1 = 1), c(TypeT2 = 1))) :
>   The esticon function has not been thoroughly teste on 'lme' objects
> 
>> library(car)
>> linear.hypothesis(fm, rbind(c("TypeT1"=1), c("TypeT2"=1)))
> Error in L %*% b : requires numeric matrix/vector arguments
> ========
> 
> So is there any other package with which I can run this kind of tests?
> 
> Thanks,
> Gang
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
>



From marcioestat at pop.com.br  Wed Apr 16 21:04:48 2008
From: marcioestat at pop.com.br (marcioestat at pop.com.br)
Date: Wed, 16 Apr 2008 16:04:48 -0300 (BRT)
Subject: [R-sig-ME] Function Likelyhood for GEE
Message-ID: <63054.132.204.255.99.1208372688.squirrel@nwebmail.pop.com.br>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080416/a99a0fbc/attachment.pl>

From kjbeath at kagi.com  Wed Apr 16 23:53:34 2008
From: kjbeath at kagi.com (Ken Beath)
Date: Thu, 17 Apr 2008 07:53:34 +1000
Subject: [R-sig-ME] Function Likelyhood for GEE
In-Reply-To: <63054.132.204.255.99.1208372688.squirrel@nwebmail.pop.com.br>
References: <63054.132.204.255.99.1208372688.squirrel@nwebmail.pop.com.br>
Message-ID: <BB22D83B-CED5-4BC3-8AE7-7D74EEFAB467@kagi.com>

On 17/04/2008, at 5:04 AM, marcioestat at pop.com.br wrote:

>
>
> Hi listers,
>
> I am analyzing an anova with repeated measures with the function
> GEE and I would like to verify the best structure for the matrix of
> variance and covariance... So I need to obtain the function of
> likelyhood to make the test of comparation between two models (full  
> and
> reduced)... Does anybody could tell me how do I obtain the
> likelyhood...
> (-2log(likelyhood M0/likelyhood M1))
>

Likelihood doesn't exist for GEE models.

If the robust SE are similar to the working then the covariance  
structure is probably close enough. You-Gan Wang (http://www.cmis.csiro.au/You-Gan.Wang/ 
) and others have developed some more technical methods, but they  
don't seem to be widely applied.

Ken



From A.Robinson at ms.unimelb.edu.au  Thu Apr 17 00:39:41 2008
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Thu, 17 Apr 2008 08:39:41 +1000
Subject: [R-sig-ME] 3-level binomial model
In-Reply-To: <698746.32661.qm@web54109.mail.re2.yahoo.com>
References: <698746.32661.qm@web54109.mail.re2.yahoo.com>
Message-ID: <20080416223941.GC97781@ms.unimelb.edu.au>

Hi Iasonas,

my interpretation of what you are doing by computing those quantities
is that you are estimating the proportion of variance explained in the
linear predictor.  

A complication with that strategy is that the non-linearity in the
relationship between the linear predictor and the probability estimate
induces an interaction between the components of variance in terms of
their effect upon the probability.  Also, the linear predictor is
commonly interpreted in the context of odds ratios (via
exponentiation), which again doesn't line up with these variance
components because of the non-linearity in the function.

So, it's not clear to me that the variance components have a direct
useful interpretation in this model, although I may be mistaken.

I seem to recall that Gelman and Hill say sensible things about what
to do either in this case or in a similar case, although again I may
be mistaken.  I don't have my copy here.

So it seems to me that the reviewers are right to be cautious, and you
might take a look in G&H.

I hope that  this helps.

Andrew


On Wed, Apr 16, 2008 at 05:51:07AM -0700, Iasonas Lamprianou wrote:
> Thank you all for your suggestions. My question, however, is how to compute the % of the variance at the level of the school and at the level of the pupils. In other words, does the concept of  intraclass correlation hold in my context? If yes, then how can this be computed for the pupils and the schools? Is the decomposistion below reasonable? 
> Prof. Bates, maybe you could suggesting something using the lmer?
> 
> VPCschool = VARschool/(VARschool+VARpupil+3.29) and 
>   VPCpupil = VARpupil/(VARschool+VARpupil+3.29)
>  
> Dr. Iasonas Lamprianou
> Department of Education
> The University of Manchester
> Oxford Road, Manchester M13 9PL, UK
> Tel. 0044 161 275 3485
> iasonas.lamprianou at manchester.ac.uk
> 
> 
> 
> On 16/04/2008, at 12:11 PM, David Duffy wrote:
> 
> >> I computed the school-level and the pupil-level variance like that
> >> (as described for 2-level models in MlWin manual): I assumed that
> >> my dependent variable is based on a continuous unobserved variable
> >> (perfectly valid according to my theoretical model). Therefore, eijk
> >> follows a logistic distribution with variance pi2/3=3.29. So,
> >
> >> VPCschool=VARschool/(VARschool+3.29)= 0.17577/(0.17577+3.29)=6.4% and
> >> VPCpupil=VPCpupil /(VPCpupil+3.29)=0.19977/(0.19977+3.29)=7.3%.
> >
> >> The reviewers of my paper are not sure if this is the best way to
> >> do it. They may reject my paper and I worry because I have spent
> >> 3months!!!! writing it. Any ideas to support my method or to use a
> >> better one?
> >
> > Would an IRT model for seven "items" be more to their taste?  I  
> > don't think the
> > substantive conclusions would be much different.
> >
> 
> Multi-level IRT is more appropriate, this allows for the nesting  
> within schools. There is a package mlirt that fits these models in a  
> Bayesian framework, but I haven't tried it. There are commercial  
> programs which will fit these, Mplus is advertised to and Latent Gold  
> with the Syntax module will, at least for a unidimensional latent  
> variable.
> 
> What is more worrying is the assumption of a single latent variable to  
> model the correlation between tests.
> 
> Ken
> 
> 
> 
> ------------------------------
> 
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> End of R-sig-mixed-models Digest, Vol 16, Issue 36
> **************************************************
> 
> 
>       ___________________________________________________________ 
> Yahoo! For Good helps you make a difference  
> 
> http://uk.promotions.yahoo.com/forgood/
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From p.taylor at niwa.co.nz  Thu Apr 17 01:27:00 2008
From: p.taylor at niwa.co.nz (Paul Taylor)
Date: Thu, 17 Apr 2008 11:27:00 +1200
Subject: [R-sig-ME] icebreakeR
Message-ID: <48073402.92C5.00A2.0@niwa.co.nz>

Hi Andrew,

I downloaded a copy of this following your email containing the link last week and have found it very useful. I'm interested in working my way through the hierarchical models in Chapter 10 but can't find the "stage" data referenced in 10.4 - it's not obvious to me that I can create the dataset from "ufc", although this worked for datasets used for examples in earlier sections. After a bit of searching, I  used data(ufc) from within the package "equivalence" to generate the "ufc" dataset, but had no luck finding the .csv files you refer to (I haven't accessed "rugby" though it looks well signposted).

Any help would be appreciated.

Thanks,
Paul.




--------------------------------------------------------------------
Paul Taylor
Pelagic Fisheries Biologist
National Institute of Water & Atmospheric Research Ltd (NIWA)
PO Box 11-115 Hillcrest,Hamilton,New Zealand.
Ph: ++ 64 7 856 7026. DDI: ++ 64 7 859 1854.
Mb: ++ 64 0274 95 05 25. Fx: ++ 64 7 856 0151.
E-mail: p.taylor at niwa.co.nz
Street address: Gate 10, Silverdale Rd, Hillcrest, Hamilton,
                New Zealand.



From A.Robinson at ms.unimelb.edu.au  Thu Apr 17 02:00:06 2008
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Thu, 17 Apr 2008 10:00:06 +1000
Subject: [R-sig-ME] icebreakeR
In-Reply-To: <48073402.92C5.00A2.0@niwa.co.nz>
References: <48073402.92C5.00A2.0@niwa.co.nz>
Message-ID: <20080417000006.GG97781@ms.unimelb.edu.au>

Hi Paul,
   
thanks for your note; I'm glad that you find the icebreakeR useful!
   
You can find the datasets at the link below.

http://www.ms.unimelb.edu.au/~andrewpr/r-users/

Cheers
  
Andrew
  
On Thu, Apr 17, 2008 at 11:27:00AM +1200, Paul Taylor wrote:
> Hi Andrew,
> 
> I downloaded a copy of this following your email containing the link last week and have found it very useful. I'm interested in working my way through the hierarchical models in Chapter 10 but can't find the "stage" data referenced in 10.4 - it's not obvious to me that I can create the dataset from "ufc", although this worked for datasets used for examples in earlier sections. After a bit of searching, I  used data(ufc) from within the package "equivalence" to generate the "ufc" dataset, but had no luck finding the .csv files you refer to (I haven't accessed "rugby" though it looks well signposted).
> 
> Any help would be appreciated.
> 
> Thanks,
> Paul.
> 
> 
> 
> 
> --------------------------------------------------------------------
> Paul Taylor
> Pelagic Fisheries Biologist
> National Institute of Water & Atmospheric Research Ltd (NIWA)
> PO Box 11-115 Hillcrest,Hamilton,New Zealand.
> Ph: ++ 64 7 856 7026. DDI: ++ 64 7 859 1854.
> Mb: ++ 64 0274 95 05 25. Fx: ++ 64 7 856 0151.
> E-mail: p.taylor at niwa.co.nz
> Street address: Gate 10, Silverdale Rd, Hillcrest, Hamilton,
>                 New Zealand.
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From s.blomberg1 at uq.edu.au  Thu Apr 17 04:40:45 2008
From: s.blomberg1 at uq.edu.au (Simon Blomberg)
Date: Thu, 17 Apr 2008 12:40:45 +1000
Subject: [R-sig-ME] Post hoc tests with lme
In-Reply-To: <b0f0ada60804160900t2b9dd6d0ve2907d402b5f44db@mail.gmail.com>
References: <b0f0ada60804160900t2b9dd6d0ve2907d402b5f44db@mail.gmail.com>
Message-ID: <1208400045.32082.6.camel@sib-sblomber01d.sib.uq.edu.au>

Try glht in package multcomp.

Simon.

On Wed, 2008-04-16 at 12:00 -0400, Gang Chen wrote:
> = 1), c(TypeT2 = 1))) :
>   Only defined for lm,glm objec
-- 
Simon Blomberg, BSc (Hons), PhD, MAppStat. 
Lecturer and Consultant Statistician 
Faculty of Biological and Chemical Sciences 
The University of Queensland 
St. Lucia Queensland 4072 
Australia
Room 320 Goddard Building (8)
T: +61 7 3365 2506
http://www.uq.edu.au/~uqsblomb
email: S.Blomberg1_at_uq.edu.au

Policies:
1.  I will NOT analyse your data for you.
2.  Your deadline is your problem.

The combination of some data and an aching desire for 
an answer does not ensure that a reasonable answer can 
be extracted from a given body of data. - John Tukey.



From kubovy at virginia.edu  Thu Apr 17 06:16:03 2008
From: kubovy at virginia.edu (Michael Kubovy)
Date: Thu, 17 Apr 2008 00:16:03 -0400
Subject: [R-sig-ME] glht & lmer (was:  Post hoc tests with lme)
In-Reply-To: <1208400045.32082.6.camel@sib-sblomber01d.sib.uq.edu.au>
References: <b0f0ada60804160900t2b9dd6d0ve2907d402b5f44db@mail.gmail.com>
	<1208400045.32082.6.camel@sib-sblomber01d.sib.uq.edu.au>
Message-ID: <8C1EAE7F-EBBD-4A29-BC2A-8D11A010141B@virginia.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080417/850ab52b/attachment.pl>

From jebyrnes at ucdavis.edu  Thu Apr 17 06:24:07 2008
From: jebyrnes at ucdavis.edu (Jarrett Byrnes)
Date: Wed, 16 Apr 2008 21:24:07 -0700
Subject: [R-sig-ME] glht & lmer (was:  Post hoc tests with lme)
In-Reply-To: <8C1EAE7F-EBBD-4A29-BC2A-8D11A010141B@virginia.edu>
References: <b0f0ada60804160900t2b9dd6d0ve2907d402b5f44db@mail.gmail.com>
	<1208400045.32082.6.camel@sib-sblomber01d.sib.uq.edu.au>
	<8C1EAE7F-EBBD-4A29-BC2A-8D11A010141B@virginia.edu>
Message-ID: <96179370-9E54-417B-9DB5-E2D31F34F83F@ucdavis.edu>

This also makes me wonder, is it possible to use glht to incorporate  
random effects as well?  E.g., if a fixed effect differs by, say,  
block, can one use glht to test whether the effect differs within each  
block?

On Apr 16, 2008, at 9:16 PM, Michael Kubovy wrote:

> I wonder if there's a problem with glht and the current version of  
> lmer
> From http://epub.ub.uni-muenchen.de/2120/1/tr019.pdf :
>
> require(multcomp)
> require(lme4)
> data(trees513)
> mmod <- lmer(damage ~ species - 1 + (1 | plot) + (1 | lattice), data =
> trees513, family = binomial())
> K <- diag(length(fixef(mmod)))
> (ci <- confint(glht(mmod, linfct = K)))
>
> 	 Simultaneous Confidence Intervals
>
> Fit: Error in x$model$call : $ operator not defined for this S4 class
> _____________________________
> Professor Michael Kubovy
> University of Virginia
> Department of Psychology
> USPS:     P.O.Box 400400    Charlottesville, VA 22904-4400
> Parcels:    Room 102        Gilmer Hall
>         McCormick Road    Charlottesville, VA 22903
> Office:    B011    +1-434-982-4729
> Lab:        B019    +1-434-982-4751
> Fax:        +1-434-982-4766
> WWW:    http://www.people.virginia.edu/~mk9y/
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From HDoran at air.org  Thu Apr 17 13:59:17 2008
From: HDoran at air.org (Doran, Harold)
Date: Thu, 17 Apr 2008 07:59:17 -0400
Subject: [R-sig-ME] 3-level binomial model
In-Reply-To: <20080416223941.GC97781@ms.unimelb.edu.au>
Message-ID: <2323A6D37908A847A7C32F1E3662C80E017BDFFB@dc1ex01.air.org>

I haven't really followed this thread, but I'd disagree and say that the
variance components have a very meaningful interpretation. If the fixed
effects are the log-odds of success, then the variance component would
be the variability in the log-odds for whatever units are of interest. 

On the issue of the ICC for the GLMM, to me this is all hocus-pocus.
This is a meaningful statistic in the world of linear models because the
within-person variance (or your level 1 variance) is assumed
homoskedastic. But, this is not true with generalized linear models.

Now, you can compute it as you did by fixing the level 1 variance at the
logistic scale and you can give reviewers whatever they want, but this
doesn't make it meaningful. So, waving a magic wand to make GLMM
estimates look like linear estimates is neat, but I think the better
path is to show your reviewers why this isn't a meaningful statistic. 

On the other hand, if you job is to get past the journal guardians for
tenure, do whatever they ask.

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf 
> Of Andrew Robinson
> Sent: Wednesday, April 16, 2008 6:40 PM
> To: Iasonas Lamprianou
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] 3-level binomial model
> 
> Hi Iasonas,
> 
> my interpretation of what you are doing by computing those 
> quantities is that you are estimating the proportion of 
> variance explained in the linear predictor.  
> 
> A complication with that strategy is that the non-linearity 
> in the relationship between the linear predictor and the 
> probability estimate induces an interaction between the 
> components of variance in terms of their effect upon the 
> probability.  Also, the linear predictor is commonly 
> interpreted in the context of odds ratios (via 
> exponentiation), which again doesn't line up with these 
> variance components because of the non-linearity in the function.
> 
> So, it's not clear to me that the variance components have a 
> direct useful interpretation in this model, although I may be 
> mistaken.
> 
> I seem to recall that Gelman and Hill say sensible things 
> about what to do either in this case or in a similar case, 
> although again I may be mistaken.  I don't have my copy here.
> 
> So it seems to me that the reviewers are right to be 
> cautious, and you might take a look in G&H.
> 
> I hope that  this helps.
> 
> Andrew
> 
> 
> On Wed, Apr 16, 2008 at 05:51:07AM -0700, Iasonas Lamprianou wrote:
> > Thank you all for your suggestions. My question, however, 
> is how to compute the % of the variance at the level of the 
> school and at the level of the pupils. In other words, does 
> the concept of  intraclass correlation hold in my context? If 
> yes, then how can this be computed for the pupils and the 
> schools? Is the decomposistion below reasonable? 
> > Prof. Bates, maybe you could suggesting something using the lmer?
> > 
> > VPCschool = VARschool/(VARschool+VARpupil+3.29) and 
> >   VPCpupil = VARpupil/(VARschool+VARpupil+3.29)
> >  
> > Dr. Iasonas Lamprianou
> > Department of Education
> > The University of Manchester
> > Oxford Road, Manchester M13 9PL, UK
> > Tel. 0044 161 275 3485
> > iasonas.lamprianou at manchester.ac.uk
> > 
> > 
> > 
> > On 16/04/2008, at 12:11 PM, David Duffy wrote:
> > 
> > >> I computed the school-level and the pupil-level variance 
> like that 
> > >> (as described for 2-level models in MlWin manual): I 
> assumed that 
> > >> my dependent variable is based on a continuous 
> unobserved variable 
> > >> (perfectly valid according to my theoretical model). Therefore, 
> > >> eijk follows a logistic distribution with variance 
> pi2/3=3.29. So,
> > >
> > >> VPCschool=VARschool/(VARschool+3.29)= 
> 0.17577/(0.17577+3.29)=6.4% 
> > >> and VPCpupil=VPCpupil 
> /(VPCpupil+3.29)=0.19977/(0.19977+3.29)=7.3%.
> > >
> > >> The reviewers of my paper are not sure if this is the 
> best way to 
> > >> do it. They may reject my paper and I worry because I have spent 
> > >> 3months!!!! writing it. Any ideas to support my method 
> or to use a 
> > >> better one?
> > >
> > > Would an IRT model for seven "items" be more to their taste?  I 
> > > don't think the substantive conclusions would be much different.
> > >
> > 
> > Multi-level IRT is more appropriate, this allows for the nesting 
> > within schools. There is a package mlirt that fits these 
> models in a 
> > Bayesian framework, but I haven't tried it. There are commercial 
> > programs which will fit these, Mplus is advertised to and 
> Latent Gold 
> > with the Syntax module will, at least for a unidimensional latent 
> > variable.
> > 
> > What is more worrying is the assumption of a single latent 
> variable to 
> > model the correlation between tests.
> > 
> > Ken
> > 
> > 
> > 
> > ------------------------------
> > 
> > _______________________________________________
> > R-sig-mixed-models mailing list
> > R-sig-mixed-models at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > 
> > 
> > End of R-sig-mixed-models Digest, Vol 16, Issue 36
> > **************************************************
> > 
> > 
> >       ___________________________________________________________
> > Yahoo! For Good helps you make a difference
> > 
> > http://uk.promotions.yahoo.com/forgood/
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> --
> Andrew Robinson  
> Department of Mathematics and Statistics            Tel: 
> +61-3-8344-6410
> University of Melbourne, VIC 3010 Australia         Fax: 
> +61-3-8344-4599
> http://www.ms.unimelb.edu.au/~andrewpr
> http://blogs.mbs.edu/fishing-in-the-bay/
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 



From gangchen6 at gmail.com  Thu Apr 17 17:41:50 2008
From: gangchen6 at gmail.com (Gang Chen)
Date: Thu, 17 Apr 2008 11:41:50 -0400
Subject: [R-sig-ME] Post hoc tests with lme
In-Reply-To: <1208400045.32082.6.camel@sib-sblomber01d.sib.uq.edu.au>
References: <b0f0ada60804160900t2b9dd6d0ve2907d402b5f44db@mail.gmail.com>
	<1208400045.32082.6.camel@sib-sblomber01d.sib.uq.edu.au>
Message-ID: <b0f0ada60804170841w10918e34uf9d61be477565efe@mail.gmail.com>

Thanks for the suggestion, Somon! I did try glht from multcomp
package, but the problem is that for the hypothesis

H0: TypeT1 =0 and TypeT2 = 0

it gives results for two separate hypotheses H01: TypeT1 =0 and H02:
TypeT2 = 0, not exactly one statistic for the original hypothesis H0.
So my question is, how can I get only one statistic for H0? Any more
suggestions?

Thanks,
Gang


> library(nlme)
> fm <- lme(effort~Type-1, data=ergoStool, random=~1|Subject)
> library(multcomp)
> summary(glht(fm, linfct=c("TypeT1=0", "TypeT2=0")))

         Simultaneous Tests for General Linear Hypotheses

Fit: lme.formula(fixed = effort ~ Type - 1, data = ergoStool, random = ~1 |
    Subject)

Linear Hypotheses:
            Estimate Std. Error z value p value
TypeT1 == 0    8.556      0.576   14.85  <1e-10 ***
TypeT2 == 0   12.444      0.576   21.60  <1e-10 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
(Adjusted p values reported -- single-step method)


On 4/16/08, Simon Blomberg <s.blomberg1 at uq.edu.au> wrote:
> Try glht in package multcomp.
>
>  Simon.
>
>
>  On Wed, 2008-04-16 at 12:00 -0400, Gang Chen wrote:
Using the "ergoStool" data cited in Mixed-Effects Models in S and
S-PLUS by Pinheiro and Bates as an example, we have

========
> library(nlme)
> fm <- lme(effort~Type-1, data=ergoStool, random=~1|Subject)
> summary(fm)

Now suppose I want to test the following hypothesis

H0: TypeT1 =0 and TypeT2 = 0

I've tried estimable() and glh.test() in package gmodels, esticon() in
package boBy, and linear.hypothesis() in package car, but it seems
none of them would work with objects from lme.



From jebyrnes at ucdavis.edu  Thu Apr 17 18:44:34 2008
From: jebyrnes at ucdavis.edu (Jarrett Byrnes)
Date: Thu, 17 Apr 2008 09:44:34 -0700
Subject: [R-sig-ME] Obtaining parameter error in a multilevel model
Message-ID: <E64AC9EE-0114-4510-AA5F-4B7E47FA7C65@ucdavis.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080417/500ac775/attachment.pl>

From francoisetsandrine.mercier at wanadoo.fr  Thu Apr 17 18:45:05 2008
From: francoisetsandrine.mercier at wanadoo.fr (Sandrine-et-Francois)
Date: Thu, 17 Apr 2008 18:45:05 +0200
Subject: [R-sig-ME] How to re-build fitted values from lmer ?
Message-ID: <002401c8a0aa$88eac1b0$0a01a8c0@Amazone>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080417/fd00fb5a/attachment.pl>

From bates at stat.wisc.edu  Thu Apr 17 20:35:44 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 17 Apr 2008 13:35:44 -0500
Subject: [R-sig-ME] How to re-build fitted values from lmer ?
In-Reply-To: <002401c8a0aa$88eac1b0$0a01a8c0@Amazone>
References: <002401c8a0aa$88eac1b0$0a01a8c0@Amazone>
Message-ID: <40e66e0b0804171135i4e3d9e1em16092a05eebb8330@mail.gmail.com>

The fitted values involve both the fixed-effects parameters and the
random effects.  In addition to the values that you have indicated you
need the model matrix for the random effects to form the values in
fitted(f1).  The transpose of the model matrix is in the Zt slot.

Assuming that you are using the development version of lme4 from
R-forge, so that

> packageDescription("lme4")$Version
[1] "0.999375-13"

you can reproduce the fitted values as

> all.equal(fitted(f1), as.vector(f1 at X %*% fixef(f1) + t(f1 at Zt) %*% f1 at ranef))
[1] TRUE


On 4/17/08, Sandrine-et-Francois <francoisetsandrine.mercier at wanadoo.fr> wrote:
> Dear list,
>  This is probably question easy to answer but I'm having some difficulties to find the way out.
>  How can I re-build the fitted values from coef() and the model.matrix (obtained by fm at X) ?
>
>  Here is a code to support my question:
>
>  #====================================================================#
>  set.seed(1520)
>  ntps<-4
>  nsubj<-20
>  sd.gp1<-3
>  sd.gp0<-2
>  sd.res<-1.3
>
>  group<-factor(rep(c("Group1", "Group0"), each=ntps, times=nsubj))
>  subj<-factor(rep(1:(nsubj*2), each=ntps))
>  time<- factor(paste("T", rep(1:ntps, nsubj*2), sep=""))
>
>  over.base<-rep(c(5, 4), each=ntps, times=nsubj)
>  subj.base<-rep(rnorm(nsubj*2, sd=c(sd.gp1, sd.gp0)), each=ntps)
>  time.base<-rep(1:ntps, nsubj*2)*as.numeric(group=="Group1")
>
>  Yn<-rnorm(nsubj*ntps*2, mean=over.base+time.base+subj.base, sd=sd.res)
>  dfn<-data.frame(time, group, Yn, subj)
>
>  require(lattice)
>  xyplot(Yn~time|group, group=subj, type="l", data=dfn)
>
>  f1<-lmer(Yn~group+time+(group|subj), data=dfn)
>  summary(f1)
>
>  ### Individual fitted values: 160 x 1 (40 subj x 4 times)
>  fitted(f1)
>
>  ### Random effect coefficients (per subj): 40 x 2 (intercept and slope)
>  ranef(f1)
>
>  ### Fixed effect coefficients: 5 x 1 (int, gp1, T2, T3, T4)
>  fixef(f1)
>
>  ### Individual coefficients: 40 x 5, ie. 40 subj x (int, gp1, T2, T3, T4)
>  coef(f1)
>
>  ### Model matrix: 160 x 5 (indicators)
>  f1 at X
>
>  #====================================================================#
>
>  Best regards,
>  Fran?ois
>
>         [[alternative HTML version deleted]]
>
>
> _______________________________________________
>  R-sig-mixed-models at r-project.org mailing list
>  https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



From David.Duffy at qimr.edu.au  Thu Apr 17 23:22:32 2008
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Fri, 18 Apr 2008 07:22:32 +1000 (EST)
Subject: [R-sig-ME] 3-level binomial model
In-Reply-To: <2323A6D37908A847A7C32F1E3662C80E017BDFFB@dc1ex01.air.org>
References: <2323A6D37908A847A7C32F1E3662C80E017BDFFB@dc1ex01.air.org>
Message-ID: <Pine.LNX.4.64.0804180713580.25811@orpheus.qimr.edu.au>

On Thu, 17 Apr 2008, Doran, Harold wrote:

> I haven't really followed this thread, but I'd disagree and say that the
> variance components have a very meaningful interpretation. If the fixed
> effects are the log-odds of success, then the variance component would
> be the variability in the log-odds for whatever units are of interest.
>
> On the issue of the ICC for the GLMM, to me this is all hocus-pocus.
> This is a meaningful statistic in the world of linear models because the
> within-person variance (or your level 1 variance) is assumed
> homoskedastic. But, this is not true with generalized linear models.
>
> Now, you can compute it as you did by fixing the level 1 variance at the
> logistic scale and you can give reviewers whatever they want, but this
> doesn't make it meaningful. So, waving a magic wand to make GLMM
> estimates look like linear estimates is neat, but I think the better
> path is to show your reviewers why this isn't a meaningful statistic.
>

Well, in the area of genetics, people have been quite happily doing just 
this since 1918, under the "Multifactorial Threshold Model", which is the 
equivalent probit model.  And if you look at Yazdi et al J Dairy Sci 
85:1563-1577 (2002), you will see an approach to derive a similar 
meaningful number under a Weibull mixed model (ICC <-> heritability). 
There, the interest is in giving a number that represents the response to 
selection of different traits that all contribute to financial return.

Cheers, David Duffy.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From A.Robinson at ms.unimelb.edu.au  Thu Apr 17 23:39:27 2008
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Fri, 18 Apr 2008 07:39:27 +1000
Subject: [R-sig-ME] 3-level binomial model
In-Reply-To: <2323A6D37908A847A7C32F1E3662C80E017BDFFB@dc1ex01.air.org>
References: <20080416223941.GC97781@ms.unimelb.edu.au>
	<2323A6D37908A847A7C32F1E3662C80E017BDFFB@dc1ex01.air.org>
Message-ID: <20080417213927.GC1516@ms.unimelb.edu.au>

Hi Harold,

On Thu, Apr 17, 2008 at 07:59:17AM -0400, Doran, Harold wrote:
> I haven't really followed this thread, but I'd disagree and say that the
> variance components have a very meaningful interpretation. If the fixed
> effects are the log-odds of success, then the variance component would
> be the variability in the log-odds for whatever units are of interest. 

Ok -- I personally find log-odds of success hard to interpret
meaningfully, but that probably reflects my inexperience with glm.

> On the issue of the ICC for the GLMM, to me this is all hocus-pocus.
> This is a meaningful statistic in the world of linear models because the
> within-person variance (or your level 1 variance) is assumed
> homoskedastic. But, this is not true with generalized linear models.

But it can be assumed to be true about the linear predictor,
conditional on your model.  The variance components are assumed to
have constant variance in the linear predictor.  Dealing with epsilon
is a bit strange, I assume that the MlWin manual provided that
insight.  And, the linear predictor for the logit link function is the
log-odds of success.  

So, if you can interpret the log-odds of success meaningfully then I
think that the variance components, and/or some monotonic function of
them, can be interpreted.  I don't, but maybe others do.

> Now, you can compute it as you did by fixing the level 1 variance at the
> logistic scale and you can give reviewers whatever they want, but this
> doesn't make it meaningful. So, waving a magic wand to make GLMM
> estimates look like linear estimates is neat, but I think the better
> path is to show your reviewers why this isn't a meaningful statistic. 
> 
> On the other hand, if you job is to get past the journal guardians for
> tenure, do whatever they ask.

Within limits.  Journal guardians can be negotiated with.

Andrew

> > -----Original Message-----
> > From: r-sig-mixed-models-bounces at r-project.org 
> > [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf 
> > Of Andrew Robinson
> > Sent: Wednesday, April 16, 2008 6:40 PM
> > To: Iasonas Lamprianou
> > Cc: r-sig-mixed-models at r-project.org
> > Subject: Re: [R-sig-ME] 3-level binomial model
> > 
> > Hi Iasonas,
> > 
> > my interpretation of what you are doing by computing those 
> > quantities is that you are estimating the proportion of 
> > variance explained in the linear predictor.  
> > 
> > A complication with that strategy is that the non-linearity 
> > in the relationship between the linear predictor and the 
> > probability estimate induces an interaction between the 
> > components of variance in terms of their effect upon the 
> > probability.  Also, the linear predictor is commonly 
> > interpreted in the context of odds ratios (via 
> > exponentiation), which again doesn't line up with these 
> > variance components because of the non-linearity in the function.
> > 
> > So, it's not clear to me that the variance components have a 
> > direct useful interpretation in this model, although I may be 
> > mistaken.
> > 
> > I seem to recall that Gelman and Hill say sensible things 
> > about what to do either in this case or in a similar case, 
> > although again I may be mistaken.  I don't have my copy here.
> > 
> > So it seems to me that the reviewers are right to be 
> > cautious, and you might take a look in G&H.
> > 
> > I hope that  this helps.
> > 
> > Andrew
> > 
> > 
> > On Wed, Apr 16, 2008 at 05:51:07AM -0700, Iasonas Lamprianou wrote:
> > > Thank you all for your suggestions. My question, however, 
> > is how to compute the % of the variance at the level of the 
> > school and at the level of the pupils. In other words, does 
> > the concept of  intraclass correlation hold in my context? If 
> > yes, then how can this be computed for the pupils and the 
> > schools? Is the decomposistion below reasonable? 
> > > Prof. Bates, maybe you could suggesting something using the lmer?
> > > 
> > > VPCschool = VARschool/(VARschool+VARpupil+3.29) and 
> > >   VPCpupil = VARpupil/(VARschool+VARpupil+3.29)
> > >  
> > > Dr. Iasonas Lamprianou
> > > Department of Education
> > > The University of Manchester
> > > Oxford Road, Manchester M13 9PL, UK
> > > Tel. 0044 161 275 3485
> > > iasonas.lamprianou at manchester.ac.uk
> > > 
> > > 
> > > 
> > > On 16/04/2008, at 12:11 PM, David Duffy wrote:
> > > 
> > > >> I computed the school-level and the pupil-level variance 
> > like that 
> > > >> (as described for 2-level models in MlWin manual): I 
> > assumed that 
> > > >> my dependent variable is based on a continuous 
> > unobserved variable 
> > > >> (perfectly valid according to my theoretical model). Therefore, 
> > > >> eijk follows a logistic distribution with variance 
> > pi2/3=3.29. So,
> > > >
> > > >> VPCschool=VARschool/(VARschool+3.29)= 
> > 0.17577/(0.17577+3.29)=6.4% 
> > > >> and VPCpupil=VPCpupil 
> > /(VPCpupil+3.29)=0.19977/(0.19977+3.29)=7.3%.
> > > >
> > > >> The reviewers of my paper are not sure if this is the 
> > best way to 
> > > >> do it. They may reject my paper and I worry because I have spent 
> > > >> 3months!!!! writing it. Any ideas to support my method 
> > or to use a 
> > > >> better one?
> > > >
> > > > Would an IRT model for seven "items" be more to their taste?  I 
> > > > don't think the substantive conclusions would be much different.
> > > >
> > > 
> > > Multi-level IRT is more appropriate, this allows for the nesting 
> > > within schools. There is a package mlirt that fits these 
> > models in a 
> > > Bayesian framework, but I haven't tried it. There are commercial 
> > > programs which will fit these, Mplus is advertised to and 
> > Latent Gold 
> > > with the Syntax module will, at least for a unidimensional latent 
> > > variable.
> > > 
> > > What is more worrying is the assumption of a single latent 
> > variable to 
> > > model the correlation between tests.
> > > 
> > > Ken
> > > 
> > > 
> > > 
> > > ------------------------------
> > > 
> > > _______________________________________________
> > > R-sig-mixed-models mailing list
> > > R-sig-mixed-models at r-project.org
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > > 
> > > 
> > > End of R-sig-mixed-models Digest, Vol 16, Issue 36
> > > **************************************************
> > > 
> > > 
> > >       ___________________________________________________________
> > > Yahoo! For Good helps you make a difference
> > > 
> > > http://uk.promotions.yahoo.com/forgood/
> > > 
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list 
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > 
> > --
> > Andrew Robinson  
> > Department of Mathematics and Statistics            Tel: 
> > +61-3-8344-6410
> > University of Melbourne, VIC 3010 Australia         Fax: 
> > +61-3-8344-4599
> > http://www.ms.unimelb.edu.au/~andrewpr
> > http://blogs.mbs.edu/fishing-in-the-bay/
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > 

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From pierces1 at msu.edu  Thu Apr 17 23:50:22 2008
From: pierces1 at msu.edu (Steven J. Pierce)
Date: Thu, 17 Apr 2008 17:50:22 -0400
Subject: [R-sig-ME] 3-level binomial model
In-Reply-To: <2323A6D37908A847A7C32F1E3662C80E017BDFFB@dc1ex01.air.org>
References: <20080416223941.GC97781@ms.unimelb.edu.au>
	<2323A6D37908A847A7C32F1E3662C80E017BDFFB@dc1ex01.air.org>
Message-ID: <002501c8a0d5$09daedc0$0a00a8c0@TheVoid>

Hi folks,

For GLMMs, I think the median odds ratio (MOR) as presented in the articles
listed below is more meaningful and interpretable than the ICC. Here's a
snippet of code I wrote to calculate that statistic. Perhaps this could be
refined to deal with a 3-level structure. 


# Set up functions for calculating the median odds ratio (MOR) and the
interval
# odds ratio (IOR) from a multilevel logistic regression, as defined by
these 
# articles/presentations:
#
# Larsen, K. (2006, November 24). New measures for understanding the
multilevel 
#   logistic regression model [Electronic version]. Seminar at the workshop 
#   ?Statistische Methoden f?r korrelierte Daten?,  Bochum, Germany.
#   http://www.bgfa.ruhr-uni-bochum.de/statmetepi/2006/Vortrag_Larsen.pdf
# Larsen, K., & Merlo, J. (2005). Appropriate assessment of neighborhood
effects 
#   on individual health: Integrating random and fixed effects in multilevel

#   logistic regression [Electronic version]. American Journal of
Epidemiology, 
#   161(1), 81-88.
#   http://aje.oxfordjournals.org/cgi/content/abstract/161/1/81
# Larsen, K., Petersen, J. H., Bundtz-J?rgensen, E., & Endahl, L. (2000). 
#   Interpreting parameters in the logistic regression model with random
effects
#   [Electronic version]. Biometrics, 56, 909-914.
#   http://www.jstor.org/view/0006341x/di020233/02p0159d/0
# 
# These functions assume that you have run a multilevel logistic regression
# and now know the variance component associated with the clustering
variable.
# The lmer() command from the lme4 package can estimate that variance and 
# will report it in the Random Effects matrix shown in the model's summary.
# Both functions as written here calculate correctly from the examples in
# Larsen & Merlo (2005). 

MOR <- function(my.var, digits = 2) 
          { # MOR arguments: my.var = variance associated with level 2
clustering variable
            # digits = number of decimal places to which MOR value will be
rounded.
            
            Median.OR <- round(exp(sqrt(2*my.var)*qnorm(.75)), digits) 
            paste("Median Odds-Ratio (MOR) = ", Median.OR)  }

IOR <- function(my.var, my.coef, my.diff, digits = 2) 
          { # IOR arguments: my.var = variance associated with level 2
clustering variable
            # my.coef = fixed effect coefficient associated with a level 2
covariate
            # my.diff = difference between 2 different possible values on
the level 
            #           2 covariate associated with my.coef
            # digits = number of decimal places to which MOR value will be
rounded.
            
            IOR.LL <- round(exp(my.coef*my.diff +
sqrt(2*my.var)*qnorm(.10)), digits)
            IOR.UL <- round(exp(my.coef*my.diff +
sqrt(2*my.var)*qnorm(.90)), digits)
            print("80% Interval Odds Ratio lower & upper limits (IOR.LL &
IOR.UL)")
            cbind(my.var, my.coef, my.diff, IOR.LL, IOR.UL)
            }



Steven J. Pierce
E-mail: pierces1 at msu.edu

-----Original Message-----
From: Doran, Harold [mailto:HDoran at air.org] 
Sent: Thursday, April 17, 2008 7:59 AM
To: Andrew Robinson; Iasonas Lamprianou
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] 3-level binomial model

I haven't really followed this thread, but I'd disagree and say that the
variance components have a very meaningful interpretation. If the fixed
effects are the log-odds of success, then the variance component would be
the variability in the log-odds for whatever units are of interest. 

On the issue of the ICC for the GLMM, to me this is all hocus-pocus.
This is a meaningful statistic in the world of linear models because the
within-person variance (or your level 1 variance) is assumed homoskedastic.
But, this is not true with generalized linear models.

Now, you can compute it as you did by fixing the level 1 variance at the
logistic scale and you can give reviewers whatever they want, but this
doesn't make it meaningful. So, waving a magic wand to make GLMM estimates
look like linear estimates is neat, but I think the better path is to show
your reviewers why this isn't a meaningful statistic. 

On the other hand, if you job is to get past the journal guardians for
tenure, do whatever they ask.

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Andrew 
> Robinson
> Sent: Wednesday, April 16, 2008 6:40 PM
> To: Iasonas Lamprianou
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] 3-level binomial model
> 
> Hi Iasonas,
> 
> my interpretation of what you are doing by computing those quantities 
> is that you are estimating the proportion of variance explained in the 
> linear predictor.
> 
> A complication with that strategy is that the non-linearity in the 
> relationship between the linear predictor and the probability estimate 
> induces an interaction between the components of variance in terms of 
> their effect upon the probability.  Also, the linear predictor is 
> commonly interpreted in the context of odds ratios (via 
> exponentiation), which again doesn't line up with these variance 
> components because of the non-linearity in the function.
> 
> So, it's not clear to me that the variance components have a direct 
> useful interpretation in this model, although I may be mistaken.
> 
> I seem to recall that Gelman and Hill say sensible things about what 
> to do either in this case or in a similar case, although again I may 
> be mistaken.  I don't have my copy here.
> 
> So it seems to me that the reviewers are right to be cautious, and you 
> might take a look in G&H.
> 
> I hope that  this helps.
> 
> Andrew
> 
> 
> On Wed, Apr 16, 2008 at 05:51:07AM -0700, Iasonas Lamprianou wrote:
> > Thank you all for your suggestions. My question, however,
> is how to compute the % of the variance at the level of the school and 
> at the level of the pupils. In other words, does the concept of  
> intraclass correlation hold in my context? If yes, then how can this 
> be computed for the pupils and the schools? Is the decomposistion 
> below reasonable?
> > Prof. Bates, maybe you could suggesting something using the lmer?
> > 
> > VPCschool = VARschool/(VARschool+VARpupil+3.29) and 
> >   VPCpupil = VARpupil/(VARschool+VARpupil+3.29)
> >  
> > Dr. Iasonas Lamprianou
> > Department of Education
> > The University of Manchester
> > Oxford Road, Manchester M13 9PL, UK
> > Tel. 0044 161 275 3485
> > iasonas.lamprianou at manchester.ac.uk
> > 
> > 
> > 
> > On 16/04/2008, at 12:11 PM, David Duffy wrote:
> > 
> > >> I computed the school-level and the pupil-level variance
> like that
> > >> (as described for 2-level models in MlWin manual): I
> assumed that
> > >> my dependent variable is based on a continuous
> unobserved variable
> > >> (perfectly valid according to my theoretical model). Therefore, 
> > >> eijk follows a logistic distribution with variance
> pi2/3=3.29. So,
> > >
> > >> VPCschool=VARschool/(VARschool+3.29)=
> 0.17577/(0.17577+3.29)=6.4%
> > >> and VPCpupil=VPCpupil
> /(VPCpupil+3.29)=0.19977/(0.19977+3.29)=7.3%.
> > >
> > >> The reviewers of my paper are not sure if this is the
> best way to
> > >> do it. They may reject my paper and I worry because I have spent 
> > >> 3months!!!! writing it. Any ideas to support my method
> or to use a
> > >> better one?
> > >
> > > Would an IRT model for seven "items" be more to their taste?  I 
> > > don't think the substantive conclusions would be much different.
> > >
> > 
> > Multi-level IRT is more appropriate, this allows for the nesting 
> > within schools. There is a package mlirt that fits these
> models in a
> > Bayesian framework, but I haven't tried it. There are commercial 
> > programs which will fit these, Mplus is advertised to and
> Latent Gold
> > with the Syntax module will, at least for a unidimensional latent 
> > variable.
> > 
> > What is more worrying is the assumption of a single latent
> variable to
> > model the correlation between tests.
> > 
> > Ken
> > 
> > 
> > 
> > ------------------------------
> > 
> > _______________________________________________
> > R-sig-mixed-models mailing list
> > R-sig-mixed-models at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > 
> > 
> > End of R-sig-mixed-models Digest, Vol 16, Issue 36
> > **************************************************
> > 
> > 
> >       ___________________________________________________________
> > Yahoo! For Good helps you make a difference
> > 
> > http://uk.promotions.yahoo.com/forgood/
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> --
> Andrew Robinson  
> Department of Mathematics and Statistics            Tel: 
> +61-3-8344-6410
> University of Melbourne, VIC 3010 Australia         Fax: 
> +61-3-8344-4599
> http://www.ms.unimelb.edu.au/~andrewpr
> http://blogs.mbs.edu/fishing-in-the-bay/
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 



From gregor.gorjanc at bfro.uni-lj.si  Thu Apr 17 23:50:13 2008
From: gregor.gorjanc at bfro.uni-lj.si (Gregor Gorjanc)
Date: Thu, 17 Apr 2008 21:50:13 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?user_defined_covariance_structure_in_lme4_/n?=
	=?utf-8?q?lme=09=28Tapan_Mehta=29?=
References: <262092.68563.qm@web31911.mail.mud.yahoo.com>
Message-ID: <loom.20080417T214859-295@post.gmane.org>

Tapan Mehta <tapmehta at ...> writes:
...
>  I have tried using corSymm but it does not give me correct random
> effects estimates as compared to what I get through SAS. I am trying to
> estimate the genetic and error variance and based on a simulated data
> (through SAS) with genetic variance 7 and error variance 2 whereas the
> results I obtain from the code below gives 7.58 and 1.38. 

But this is not so bad! Try with several datasets and you will get the feeling
of the quality of estimates.

Gregor



From bates at stat.wisc.edu  Fri Apr 18 14:11:57 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 18 Apr 2008 07:11:57 -0500
Subject: [R-sig-ME] [R] Meaning of /, :, and %in% in lmer
In-Reply-To: <200804161451.20075.cwilke@mail.utexas.edu>
References: <200804161451.20075.cwilke@mail.utexas.edu>
Message-ID: <40e66e0b0804180511w2122becaj4a0d12fb3cbd44ec@mail.gmail.com>

On 4/16/08, Claus Wilke <cwilke at mail.utexas.edu> wrote:
> Hello,

>  I asked this question a little while ago (
>  https://stat.ethz.ch/pipermail/r-help/2008-April/158761.html ) but got no
>  response. Can anybody explain to me the difference between /, :, and %in% in
>  the definition of random effects in lmer, such as:
>  (1|A/B), (1|A:B), (1|B %in% A)?

The first two, (1|A/B) and (1|A:B), are forms that lmer recognizes.
I'm not sure what the effect of the third form, (1|B %in% A), would be
and would not advise using it.

Most uses of the %in% operator in R at present are as a logical operator.

>  My understanding is that (1|A/B) is the same as (1|A) + (1|A:B), but I have
>  not seen this stated explicitly anywhere. And I don't understand why (1|A/B)
>  seems to be different from (1|A) + (1|B %in% A), isn't that what %in% means?

The short answer is that (1|A/B) is expanded to (1|A) + (1|A:B) so you
can choose whatever form makes sense to you.

There are different circumstances where a notation like (1|A/B) would
be used.  Some are reasonable choices and some are artifacts of
artificial ways of assigning labels to factor levels.  Rather than my
trying to guess what kind of application you have in mind, could you
describe a situation where you would want to fit an lmer model with
terms like that?

I am cc:ing the R-SIG-Mixed-Models list on this reply and I suggest we
move the discussion to that list.



From cotter.rs at gmail.com  Fri Apr 18 14:18:29 2008
From: cotter.rs at gmail.com (R.S. Cotter)
Date: Fri, 18 Apr 2008 14:18:29 +0200
Subject: [R-sig-ME] How to report an LME- method and result in an article?
Message-ID: <742479270804180518t20a8ef89w28780c39fd0c65a6@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080418/1446ae96/attachment.pl>

From orzack at freshpond.org  Fri Apr 18 16:33:06 2008
From: orzack at freshpond.org (orzack)
Date: Fri, 18 Apr 2008 10:33:06 -0400
Subject: [R-sig-ME] unable to install LME4 in R 2.6.2 on an Intel Mac
Message-ID: <p06230901c42e616a152c@[192.168.0.104]>

  the new version of LME4 (0.99375-13) installs (and works!) on a 
Power PC Mac (OS X 10.4.10). However, it will not load on an Intel 
Mac (also OS X 10.4.10).  I get the following message:

Error in dyn.load(file, ...) :
   unable to load shared library 
'/Users/stevenorzack/Library/R/2.6/library/lme4/libs/i386/lme4.so':
 
dlopen(/Users/stevenorzack/Library/R/2.6/library/lme4/libs/i386/lme4.so, 
6): Library not loaded: /usr/local/lib/libgfortran.2.dylib
   Referenced from: 
/Users/stevenorzack/Library/R/2.6/library/lme4/libs/i386/lme4.so
   Reason: image not found
Error: package/namespace load failed for 'lme4'

help will be much appreciated!

S.

-- 
Steven Orzack

The Fresh Pond Research Institute
173 Harvey Street
Cambridge, MA. 02140
617 864-4307

www.freshpond.org



From bates at stat.wisc.edu  Fri Apr 18 17:48:36 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 18 Apr 2008 10:48:36 -0500
Subject: [R-sig-ME] unable to install LME4 in R 2.6.2 on an Intel Mac
In-Reply-To: <p06230901c42e616a152c@192.168.0.104>
References: <p06230901c42e616a152c@192.168.0.104>
Message-ID: <40e66e0b0804180848y4b8f41dfyacb42bd231763d4b@mail.gmail.com>

What version of R do you have installed on the Intel Mac?

I suggest you take the problem to the R-SIG-Mac list.  It appears that
there is a mismatch between the libraries on the machine that
generated the Mac binary package and your machine.

Needing to install certain versions of libraries in /usr/local is one
of the reasons that I don't bother trying to run R on a Mac, other
than for the vanilla stuff.

On 4/18/08, orzack <orzack at freshpond.org> wrote:
>   the new version of LME4 (0.99375-13) installs (and works!) on a
>  Power PC Mac (OS X 10.4.10). However, it will not load on an Intel
>  Mac (also OS X 10.4.10).  I get the following message:
>
>  Error in dyn.load(file, ...) :
>    unable to load shared library
>  '/Users/stevenorzack/Library/R/2.6/library/lme4/libs/i386/lme4.so':
>
>  dlopen(/Users/stevenorzack/Library/R/2.6/library/lme4/libs/i386/lme4.so,
>  6): Library not loaded: /usr/local/lib/libgfortran.2.dylib
>    Referenced from:
>  /Users/stevenorzack/Library/R/2.6/library/lme4/libs/i386/lme4.so
>    Reason: image not found
>  Error: package/namespace load failed for 'lme4'
>
>  help will be much appreciated!
>
>  S.
>
>  --
>  Steven Orzack
>
>  The Fresh Pond Research Institute
>  173 Harvey Street
>  Cambridge, MA. 02140
>  617 864-4307
>
>  www.freshpond.org
>
>  _______________________________________________
>  R-sig-mixed-models at r-project.org mailing list
>  https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From simon.urbanek at r-project.org  Fri Apr 18 18:29:08 2008
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 18 Apr 2008 12:29:08 -0400
Subject: [R-sig-ME] [R-SIG-Mac] unable to install LME4 in R 2.6.2 on an
	Intel Mac
In-Reply-To: <40e66e0b0804180848y4b8f41dfyacb42bd231763d4b@mail.gmail.com>
References: <p06230901c42e616a152c@192.168.0.104>
	<40e66e0b0804180848y4b8f41dfyacb42bd231763d4b@mail.gmail.com>
Message-ID: <14B7A8EB-1875-445B-ABB1-4F689AE7A855@r-project.org>


On Apr 18, 2008, at 11:48 AM, Douglas Bates wrote:

> What version of R do you have installed on the Intel Mac?
>
> I suggest you take the problem to the R-SIG-Mac list.  It appears  
> that there is a mismatch between the libraries on the machine that  
> generated the Mac binary package and your machine.
>

It appears that he is not using our binaries at all which is why he  
runs into problems (it is unclear because he failed to supply basic  
details).


> Needing to install certain versions of libraries in /usr/local is  
> one of the reasons that I don't bother trying to run R on a Mac,  
> other than for the vanilla stuff.
>

The seems to be a rather wide-spread urban legend. R does *not*  
install anything in /usr/local, it is completely independent of /usr/ 
local for its functionality. We go into great lengths to provide self- 
contained binaries even for some packages that require 3rd party  
libraries. The only exception to this rule are some UI kits as there  
is no way to embed them (without installing them into R framework  
completely).
The R installer provides *optional* tools that can be installed in / 
usr/local if desired, but those are not necessary in order to run R  
(and are not part of R itself).

Cheers,
Simon


> On 4/18/08, orzack <orzack at freshpond.org> wrote:
>>  the new version of LME4 (0.99375-13) installs (and works!) on a
>> Power PC Mac (OS X 10.4.10). However, it will not load on an Intel
>> Mac (also OS X 10.4.10).  I get the following message:
>>
>> Error in dyn.load(file, ...) :
>>   unable to load shared library
>> '/Users/stevenorzack/Library/R/2.6/library/lme4/libs/i386/lme4.so':
>>
>> dlopen(/Users/stevenorzack/Library/R/2.6/library/lme4/libs/i386/ 
>> lme4.so,
>> 6): Library not loaded: /usr/local/lib/libgfortran.2.dylib
>>   Referenced from:
>> /Users/stevenorzack/Library/R/2.6/library/lme4/libs/i386/lme4.so
>>   Reason: image not found
>> Error: package/namespace load failed for 'lme4'
>>
>> help will be much appreciated!
>>
>> S.
>>
>> --
>> Steven Orzack
>>
>> The Fresh Pond Research Institute
>> 173 Harvey Street
>> Cambridge, MA. 02140
>> 617 864-4307
>>
>> www.freshpond.org
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-SIG-Mac mailing list
> R-SIG-Mac at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-mac
>
>



From cwilke at mail.utexas.edu  Fri Apr 18 18:47:07 2008
From: cwilke at mail.utexas.edu (Claus Wilke)
Date: Fri, 18 Apr 2008 11:47:07 -0500
Subject: [R-sig-ME] [R] Meaning of /, :, and %in% in lmer
In-Reply-To: <40e66e0b0804180511w2122becaj4a0d12fb3cbd44ec@mail.gmail.com>
References: <200804161451.20075.cwilke@mail.utexas.edu>
	<40e66e0b0804180511w2122becaj4a0d12fb3cbd44ec@mail.gmail.com>
Message-ID: <200804181147.07805.cwilke@mail.utexas.edu>

> The short answer is that (1|A/B) is expanded to (1|A) + (1|A:B) so you
> can choose whatever form makes sense to you.
Thanks, that was what I needed to hear.

>
> There are different circumstances where a notation like (1|A/B) would
> be used.  Some are reasonable choices and some are artifacts of
> artificial ways of assigning labels to factor levels.  Rather than my
> trying to guess what kind of application you have in mind, could you
> describe a situation where you would want to fit an lmer model with
> terms like that?
It's a virology experiment. We have two ancestral strains. From each of those 
we have derived several new strains, and then have made multiple fitness 
measurements on the new strains. We want to know whether the ancestral strain 
has an effect on the fitness of the derived strains. The model I'm using for 
that is
	fitness ~ ancestor + (1|ancestor:strain),
because strains are nested within ancestors. If I were using
	fitness ~ ancestor + (1|ancestor/strain),
then ancestor would get both a fixed and a random effect, which doesn't make 
sense.

I have a second question, related to the hypothesis testing of whether the 
fixed ancestor effect is significant. I've read all the threads about why it 
is problematic to do an F test to calculate a p value, and that it is better 
to do markov-chain monte carlo. My question is: Is there a proper reference I 
can cite to substantiate the claim that the standard (i.e., SAS) way of 
calculating significance in this case is problematic, or do I have to refer 
to the mailing list archive?

Thanks a lot,
  Claus
-- 
Claus Wilke
Section of Integrative Biology 
 and Center for Computational Biology and Bioinformatics 
University of Texas at Austin
1 University Station C0930
Austin, TX 78712
cwilke at mail.utexas.edu
512 471 6028



From marcioestat at pop.com.br  Fri Apr 18 20:33:12 2008
From: marcioestat at pop.com.br (marcioestat at pop.com.br)
Date: Fri, 18 Apr 2008 15:33:12 -0300 (BRT)
Subject: [R-sig-ME] GLM and GEE
Message-ID: <56781.132.204.243.28.1208543592.squirrel@nwebmail.pop.com.br>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080418/100c3e31/attachment.pl>

From sgp at stats.unipune.ernet.in  Sat Apr 19 11:52:55 2008
From: sgp at stats.unipune.ernet.in (Sudha Purohit)
Date: Sat, 19 Apr 2008 15:22:55 +0530
Subject: [R-sig-ME] degrees of freedom
Message-ID: <002601c8a203$271a0f40$130000c0@PurohitSG>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080419/e248b538/attachment.pl>

From bates at stat.wisc.edu  Sat Apr 19 20:58:21 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat, 19 Apr 2008 13:58:21 -0500
Subject: [R-sig-ME] [R] Meaning of /, :, and %in% in lmer
In-Reply-To: <200804181147.07805.cwilke@mail.utexas.edu>
References: <200804161451.20075.cwilke@mail.utexas.edu>
	<40e66e0b0804180511w2122becaj4a0d12fb3cbd44ec@mail.gmail.com>
	<200804181147.07805.cwilke@mail.utexas.edu>
Message-ID: <40e66e0b0804191158k5f0bcf5bpad70e87c5f4e3d65@mail.gmail.com>

On 4/18/08, Claus Wilke <cwilke at mail.utexas.edu> wrote:
> > The short answer is that (1|A/B) is expanded to (1|A) + (1|A:B) so you
>  > can choose whatever form makes sense to you.

> Thanks, that was what I needed to hear.

>  > There are different circumstances where a notation like (1|A/B) would
>  > be used.  Some are reasonable choices and some are artifacts of
>  > artificial ways of assigning labels to factor levels.  Rather than my
>  > trying to guess what kind of application you have in mind, could you
>  > describe a situation where you would want to fit an lmer model with
>  > terms like that?

> It's a virology experiment. We have two ancestral strains. From each of those
>  we have derived several new strains, and then have made multiple fitness
>  measurements on the new strains. We want to know whether the ancestral strain
>  has an effect on the fitness of the derived strains. The model I'm using for
>  that is
>         fitness ~ ancestor + (1|ancestor:strain),
>  because strains are nested within ancestors. If I were using
>         fitness ~ ancestor + (1|ancestor/strain),
>  then ancestor would get both a fixed and a random effect, which doesn't make
>  sense.

The labeling question is related to the levels of the strain factor.
To me the sensible way to label strains is to give each unique strain
a unique label.  In fact, I would go so far as to say that is the only
sensible way.  So suppose the ancestral strains are called "A" and "B"
and there were 8 strains derived from "A" and 12 strains derived from
"B".  The I would give them labels like "A01" up to "A08" and "B01" up
to "B12".  Many people feel the strains from ancestor A should be
labeled 1 up to 8 and those from ancestor B labeled 1 up to 12 and
then incorporate the information that strain is nested within ancestor
somewhere in the model description.  To me this makes no sense.  If
strain 1 from ancestor A is not related in any way to strain 1 from
ancestor B, why call them both "1".

If the strains are labeled so that each unique strain has a unique
label then the model can be written as
  fitness ~ ancestor + (1|strain)
or as
  fitness ~ ancestor + (1|ancestor:strain)
whichever one makes sense to you.  If the levels of strain reflect an
implicit nesting (that is, you need to know that strain 1 from
ancestor A is not the same as strain 1 from ancestor B, even though
they are given the same level of strain) then you must write the model
in the second form but only because the labels of strain are ambiguous
and the expression ancestor:strain is required to disambiguate the
levels.

>  I have a second question, related to the hypothesis testing of whether the
>  fixed ancestor effect is significant. I've read all the threads about why it
>  is problematic to do an F test to calculate a p value, and that it is better
>  to do markov-chain monte carlo. My question is: Is there a proper reference I
>  can cite to substantiate the claim that the standard (i.e., SAS) way of
>  calculating significance in this case is problematic, or do I have to refer
>  to the mailing list archive?

Harald Baayen's recent book on "Analyzing Linguistic Data" has a good
discussion of some of the issues in determining significance of
fixed-effects terms in a mixed-effects model.  I like some of the
explanations in his chapter 7.

To tell the truth I expect that the standard approach is reasonably
accurate for cases where the only random effects term in the model is
of the form  (1|strain); it's in the more complex models that the
simple approximations get off track.  The sort of data that Harald and
many others in psychometric areas consider is cross-classified
according to subject and item and the standard approaches get bogged
down there.



>  Thanks a lot,
>
>   Claus
>
> --
>  Claus Wilke
>  Section of Integrative Biology
>   and Center for Computational Biology and Bioinformatics
>  University of Texas at Austin
>  1 University Station C0930
>  Austin, TX 78712
>  cwilke at mail.utexas.edu
>  512 471 6028
>



From kjbeath at kagi.com  Mon Apr 21 12:31:27 2008
From: kjbeath at kagi.com (Ken Beath)
Date: Mon, 21 Apr 2008 20:31:27 +1000
Subject: [R-sig-ME] GLM and GEE
In-Reply-To: <56781.132.204.243.28.1208543592.squirrel@nwebmail.pop.com.br>
References: <56781.132.204.243.28.1208543592.squirrel@nwebmail.pop.com.br>
Message-ID: <2124C762-5F10-4D14-8AFD-74E5617CA258@kagi.com>

On 19/04/2008, at 4:33 AM, marcioestat at pop.com.br wrote:

>
>
> Hi listers,
>
> Could anyone please provide to me any reference, articles or books,
> about the GLM and GEE with examples with R....
> I have already looked at the Venables and Ripley, but there isn't to
> much information...
>


For GLM try the books on R by Maindonald and by Faraway.

I don't think there is much in any texts on GEE in R. There is an  
article http://www.jstatsoft.org/v15/i02/paper

Ken



From njbisaac at googlemail.com  Wed Apr 23 14:38:54 2008
From: njbisaac at googlemail.com (Nick Isaac)
Date: Wed, 23 Apr 2008 13:38:54 +0100
Subject: [R-sig-ME] Bug in weights in lmer
Message-ID: <a072ed700804230538t56c66d7ap7ae80d117d87bad0@mail.gmail.com>

I have unearthed a bug in the way lmer() deals with weights.

Adding weights causes an inflation of the variance estimates. The
phenomenon is easily demonstrated by comparing the following models,
all of which should be identical:

w<-rep(1,nrow(sleepstudy))
(fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy) )
(fm2 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy, weights = w) )
(fm3 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy, weights = w/sum(w)) )

I have tried this with other datasets and models and find the same
general pattern. I find that the inflation factor is correlated with
sum(w) and is higher for cross-classified models than simple nested
ones.

The fixed effect estimates are also changed.

Best wishes, Nick


> sessionInfo()
R version 2.6.2 (2008-02-08)
i386-apple-darwin8.10.1

locale:
en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_0.999375-13  Matrix_0.999375-7 lattice_0.17-6

loaded via a namespace (and not attached):
[1] grid_2.6.2



From HDoran at air.org  Wed Apr 23 16:16:09 2008
From: HDoran at air.org (Doran, Harold)
Date: Wed, 23 Apr 2008 10:16:09 -0400
Subject: [R-sig-ME] Bug in weights in lmer
In-Reply-To: <a072ed700804230538t56c66d7ap7ae80d117d87bad0@mail.gmail.com>
Message-ID: <ED7B522EE00C9A4FA515AA71724D61EE1BA7DB@DC1EXCL01.air.org>

I'm confused. When I run this, I get the exact same answers for all
three models for all variance components and for all fixed effects. See
my results below. Where is the bug?

> w<-rep(1,nrow(sleepstudy))
> w
  [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
1 1 1 1
 [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
1 1 1 1
 [75] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
1 1 1 1
[112] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
1 1 1 1
[149] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1

> (fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy) )
Linear mixed-effects model fit by REML 
Formula: Reaction ~ Days + (Days | Subject) 
   Data: sleepstudy 
  AIC  BIC logLik MLdeviance REMLdeviance
 1754 1770 -871.8       1752         1744
Random effects:
 Groups   Name        Variance Std.Dev. Corr  
 Subject  (Intercept) 610.835  24.7151        
          Days         35.056   5.9208  0.067 
 Residual             655.066  25.5943        
number of obs: 180, groups: Subject, 18

Fixed effects:
            Estimate Std. Error t value
(Intercept)  251.405      6.820   36.86
Days          10.467      1.546    6.77

Correlation of Fixed Effects:
     (Intr)
Days -0.137
> (fm2 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy, weights =
w) )
Linear mixed-effects model fit by REML 
Formula: Reaction ~ Days + (Days | Subject) 
   Data: sleepstudy 
  AIC  BIC logLik MLdeviance REMLdeviance
 1754 1770 -871.8       1752         1744
Random effects:
 Groups   Name        Variance Std.Dev. Corr  
 Subject  (Intercept) 610.835  24.7151        
          Days         35.056   5.9208  0.067 
 Residual             655.066  25.5943        
number of obs: 180, groups: Subject, 18

Fixed effects:
            Estimate Std. Error t value
(Intercept)  251.405      6.820   36.86
Days          10.467      1.546    6.77

Correlation of Fixed Effects:
     (Intr)
Days -0.137
> (fm3 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy, weights =
w/sum(w)) )
Linear mixed-effects model fit by REML 
Formula: Reaction ~ Days + (Days | Subject) 
   Data: sleepstudy 
  AIC  BIC logLik MLdeviance REMLdeviance
 1754 1770 -871.8       1752         1744
Random effects:
 Groups   Name        Variance Std.Dev. Corr  
 Subject  (Intercept) 610.835  24.7151        
          Days         35.056   5.9208  0.067 
 Residual             655.066  25.5943        
number of obs: 180, groups: Subject, 18

Fixed effects:
            Estimate Std. Error t value
(Intercept)  251.405      6.820   36.86
Days          10.467      1.546    6.77

Correlation of Fixed Effects:
     (Intr)
Days -0.137 

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf 
> Of Nick Isaac
> Sent: Wednesday, April 23, 2008 8:39 AM
> To: R-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Bug in weights in lmer
> 
> I have unearthed a bug in the way lmer() deals with weights.
> 
> Adding weights causes an inflation of the variance estimates. 
> The phenomenon is easily demonstrated by comparing the 
> following models, all of which should be identical:
> 
> w<-rep(1,nrow(sleepstudy))
> (fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy) )
> (fm2 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy, 
> weights = w) )
> (fm3 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy, 
> weights = w/sum(w)) )
> 
> I have tried this with other datasets and models and find the 
> same general pattern. I find that the inflation factor is 
> correlated with
> sum(w) and is higher for cross-classified models than simple 
> nested ones.
> 
> The fixed effect estimates are also changed.
> 
> Best wishes, Nick
> 
> 
> > sessionInfo()
> R version 2.6.2 (2008-02-08)
> i386-apple-darwin8.10.1
> 
> locale:
> en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] lme4_0.999375-13  Matrix_0.999375-7 lattice_0.17-6
> 
> loaded via a namespace (and not attached):
> [1] grid_2.6.2
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 



From njbisaac at googlemail.com  Wed Apr 23 18:00:32 2008
From: njbisaac at googlemail.com (Nick Isaac)
Date: Wed, 23 Apr 2008 17:00:32 +0100
Subject: [R-sig-ME] Bug in weights in lmer
In-Reply-To: <ED7B522EE00C9A4FA515AA71724D61EE1BA7DB@DC1EXCL01.air.org>
References: <a072ed700804230538t56c66d7ap7ae80d117d87bad0@mail.gmail.com>
	<ED7B522EE00C9A4FA515AA71724D61EE1BA7DB@DC1EXCL01.air.org>
Message-ID: <a072ed700804230900u186a79e1sf951accb8e0088d0@mail.gmail.com>

Thanks Harold - very curious.
See my results below. This sounds like a versioning issue, in which
case it would be good to get as many folk as possible to replicate it.

cheers, Nick

> w<-rep(1,nrow(sleepstudy))
> (fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy) )
Linear mixed model fit by REML
Formula: Reaction ~ Days + (Days | Subject)
   Data: sleepstudy
  AIC  BIC logLik deviance REMLdev
 1756 1775 -871.8     1752    1744
Random effects:
 Groups   Name        Variance Std.Dev. Corr
 Subject  (Intercept) 612.095  24.7405
          Days         35.071   5.9221  0.065
 Residual             654.944  25.5919
Number of obs: 180, groups: Subject, 18

Fixed effects:
            Estimate Std. Error t value
(Intercept)  251.405      6.825   36.84
Days          10.467      1.546    6.77

Correlation of Fixed Effects:
     (Intr)
Days -0.138
>
>  (fm2 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy, weights =
+ w) )
Linear mixed model fit by REML
Formula: Reaction ~ Days + (Days | Subject)
   Data: sleepstudy
  AIC  BIC logLik deviance REMLdev
 1756 1775 -871.8     1752    1744
Random effects:
 Groups   Name        Variance Std.Dev. Corr
 Subject  (Intercept) 6640265  2576.87
          Days         380465   616.82  0.065
 Residual             7105115  2665.54
Number of obs: 180, groups: Subject, 18

Fixed effects:
            Estimate Std. Error t value
(Intercept)    975.9      710.8   1.373
Days           173.3      161.0   1.076

Correlation of Fixed Effects:
     (Intr)
Days -0.138
> (fm3 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy, weights =
+ w/sum(w)) )
Linear mixed model fit by REML
Formula: Reaction ~ Days + (Days | Subject)
   Data: sleepstudy
   AIC BIC logLik deviance REMLdev
 820.9 840 -404.4    817.3   808.9
Random effects:
 Groups   Name        Variance  Std.Dev. Corr
 Subject  (Intercept) 169988830 13038.0
          Days          9739898  3120.9  0.065
 Residual               1010497  1005.2
Number of obs: 180, groups: Subject, 18

Fixed effects:
            Estimate Std. Error t value
(Intercept)    72.74    3596.47 0.02022
Days           12.92     814.61 0.01586

Correlation of Fixed Effects:
     (Intr)
Days -0.138



From lborger at uoguelph.ca  Wed Apr 23 18:15:55 2008
From: lborger at uoguelph.ca (Luca Borger)
Date: Wed, 23 Apr 2008 12:15:55 -0400
Subject: [R-sig-ME] Bug in weights in lmer
References: <a072ed700804230538t56c66d7ap7ae80d117d87bad0@mail.gmail.com><ED7B522EE00C9A4FA515AA71724D61EE1BA7DB@DC1EXCL01.air.org>
	<a072ed700804230900u186a79e1sf951accb8e0088d0@mail.gmail.com>
Message-ID: <00d301c8a55d$4f2c3d20$0dac6883@ZooAnnex2Luca>

Hello,

in case this if of any interest, I obtained apparently the same results as 
Nick using:

> sessionInfo()
R version 2.6.2 (2008-02-08)
i386-pc-mingw32

locale:
LC_COLLATE=English_United Kingdom.1252;LC_CTYPE=English_United 
Kingdom.1252;LC_MONETARY=English_United 
Kingdom.1252;LC_NUMERIC=C;LC_TIME=English_United Kingdom.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_0.999375-13  Matrix_0.999375-9 lattice_0.17-6

loaded via a namespace (and not attached):
[1] grid_2.6.2  tools_2.6.2
>




### Results:

> w<-rep(1,nrow(sleepstudy))


> (fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy) )
Linear mixed model fit by REML
Formula: Reaction ~ Days + (Days | Subject)
   Data: sleepstudy
  AIC  BIC logLik deviance REMLdev
 1756 1775 -871.8     1752    1744
Random effects:
 Groups   Name        Variance Std.Dev. Corr
 Subject  (Intercept) 612.095  24.7405
          Days         35.071   5.9221  0.065
 Residual             654.944  25.5919
Number of obs: 180, groups: Subject, 18

Fixed effects:
            Estimate Std. Error t value
(Intercept)  251.405      6.825   36.84
Days          10.467      1.546    6.77

Correlation of Fixed Effects:
     (Intr)
Days -0.138
>



> (fm2 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy, weights =w))
Linear mixed model fit by REML
Formula: Reaction ~ Days + (Days | Subject)
   Data: sleepstudy
  AIC  BIC logLik deviance REMLdev
 1756 1775 -871.8     1752    1744
Random effects:
 Groups   Name        Variance Std.Dev. Corr
 Subject  (Intercept) 6640265  2576.87
          Days         380465   616.82  0.065
 Residual             7105115  2665.54
Number of obs: 180, groups: Subject, 18

Fixed effects:
            Estimate Std. Error t value
(Intercept)    975.9      710.8   1.373
Days           173.3      161.0   1.076

Correlation of Fixed Effects:
     (Intr)
Days -0.138
>



> (fm3 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy, weights 
> =w/sum(w)) )
Linear mixed model fit by REML
Formula: Reaction ~ Days + (Days | Subject)
   Data: sleepstudy
   AIC BIC logLik deviance REMLdev
 820.9 840 -404.4    817.3   808.9
Random effects:
 Groups   Name        Variance  Std.Dev. Corr
 Subject  (Intercept) 169992420 13038.1
          Days          9740118  3120.9  0.065
 Residual               1010516  1005.2
Number of obs: 180, groups: Subject, 18

Fixed effects:
            Estimate Std. Error t value
(Intercept)    72.74    3596.51 0.02022
Days           12.92     814.62 0.01586

Correlation of Fixed Effects:
     (Intr)
Days -0.138
>




Cheers,

Luca

---------------------------
Luca B?rger, PhD
Postdoctoral Research Fellow
Department of Integrative Biology
University of Guelph
Guelph, Ontario, Canada N1G 2W1
phone: +1 519 824 4120 ext. 54554
fax:     +1 519 767 1656


----- Original Message ----- 
From: "Nick Isaac" <njbisaac at googlemail.com>
To: "Doran, Harold" <HDoran at air.org>
Cc: <R-sig-mixed-models at r-project.org>
Sent: Wednesday, April 23, 2008 12:00 PM
Subject: Re: [R-sig-ME] Bug in weights in lmer


> Thanks Harold - very curious.
> See my results below. This sounds like a versioning issue, in which
> case it would be good to get as many folk as possible to replicate it.
>
> cheers, Nick
>
>> w<-rep(1,nrow(sleepstudy))
>> (fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy) )
> Linear mixed model fit by REML
> Formula: Reaction ~ Days + (Days | Subject)
>   Data: sleepstudy
>  AIC  BIC logLik deviance REMLdev
> 1756 1775 -871.8     1752    1744
> Random effects:
> Groups   Name        Variance Std.Dev. Corr
> Subject  (Intercept) 612.095  24.7405
>          Days         35.071   5.9221  0.065
> Residual             654.944  25.5919
> Number of obs: 180, groups: Subject, 18
>
> Fixed effects:
>            Estimate Std. Error t value
> (Intercept)  251.405      6.825   36.84
> Days          10.467      1.546    6.77
>
> Correlation of Fixed Effects:
>     (Intr)
> Days -0.138
>>
>>  (fm2 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy, weights =
> + w) )
> Linear mixed model fit by REML
> Formula: Reaction ~ Days + (Days | Subject)
>   Data: sleepstudy
>  AIC  BIC logLik deviance REMLdev
> 1756 1775 -871.8     1752    1744
> Random effects:
> Groups   Name        Variance Std.Dev. Corr
> Subject  (Intercept) 6640265  2576.87
>          Days         380465   616.82  0.065
> Residual             7105115  2665.54
> Number of obs: 180, groups: Subject, 18
>
> Fixed effects:
>            Estimate Std. Error t value
> (Intercept)    975.9      710.8   1.373
> Days           173.3      161.0   1.076
>
> Correlation of Fixed Effects:
>     (Intr)
> Days -0.138
>> (fm3 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy, weights =
> + w/sum(w)) )
> Linear mixed model fit by REML
> Formula: Reaction ~ Days + (Days | Subject)
>   Data: sleepstudy
>   AIC BIC logLik deviance REMLdev
> 820.9 840 -404.4    817.3   808.9
> Random effects:
> Groups   Name        Variance  Std.Dev. Corr
> Subject  (Intercept) 169988830 13038.0
>          Days          9739898  3120.9  0.065
> Residual               1010497  1005.2
> Number of obs: 180, groups: Subject, 18
>
> Fixed effects:
>            Estimate Std. Error t value
> (Intercept)    72.74    3596.47 0.02022
> Days           12.92     814.61 0.01586
>
> Correlation of Fixed Effects:
>     (Intr)
> Days -0.138
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From HDoran at air.org  Wed Apr 23 19:09:47 2008
From: HDoran at air.org (Doran, Harold)
Date: Wed, 23 Apr 2008 13:09:47 -0400
Subject: [R-sig-ME] Bug in weights in lmer
In-Reply-To: <ED7B522EE00C9A4FA515AA71724D61EE271AE5@DC1EXCL01.air.org>
Message-ID: <ED7B522EE00C9A4FA515AA71724D61EE1BA7EE@DC1EXCL01.air.org>

It appears you and Luca have older versions. I'm using the most recent
version posted on CRAN. Try updating your packages and see what happens.

> sessionInfo()
R version 2.6.2 (2008-02-08) 
i386-pc-mingw32 

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
States.1252;LC_MONETARY=English_United
States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


other attached packages:
[1] lme4_0.99875-9    Matrix_0.999375-7 lattice_0.17-4   

loaded via a namespace (and not attached):
[1] grid_2.6.2 

> -----Original Message-----
> From: Doran, Harold 
> Sent: Wednesday, April 23, 2008 10:16 AM
> To: 'Nick Isaac'; 'R-sig-mixed-models at r-project.org'
> Subject: RE: [R-sig-ME] Bug in weights in lmer
> 
> I'm confused. When I run this, I get the exact same answers 
> for all three models for all variance components and for all 
> fixed effects. See my results below. Where is the bug?
> 
> > w<-rep(1,nrow(sleepstudy))
> > w
>   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
> 1 1 1 1 1 1 1 1 1  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
> 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1  [75] 1 1 1 1 1 1 1 1 1 1 
> 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 [112] 1 
> 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
> 1 1 1 1 1 [149] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 
> 1 1 1 1 1 1 1 1 1
> 
> > (fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy) )
> Linear mixed-effects model fit by REML
> Formula: Reaction ~ Days + (Days | Subject) 
>    Data: sleepstudy
>   AIC  BIC logLik MLdeviance REMLdeviance
>  1754 1770 -871.8       1752         1744
> Random effects:
>  Groups   Name        Variance Std.Dev. Corr  
>  Subject  (Intercept) 610.835  24.7151        
>           Days         35.056   5.9208  0.067 
>  Residual             655.066  25.5943        
> number of obs: 180, groups: Subject, 18
> 
> Fixed effects:
>             Estimate Std. Error t value
> (Intercept)  251.405      6.820   36.86
> Days          10.467      1.546    6.77
> 
> Correlation of Fixed Effects:
>      (Intr)
> Days -0.137
> > (fm2 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy, 
> weights = 
> > w) )
> Linear mixed-effects model fit by REML
> Formula: Reaction ~ Days + (Days | Subject) 
>    Data: sleepstudy
>   AIC  BIC logLik MLdeviance REMLdeviance
>  1754 1770 -871.8       1752         1744
> Random effects:
>  Groups   Name        Variance Std.Dev. Corr  
>  Subject  (Intercept) 610.835  24.7151        
>           Days         35.056   5.9208  0.067 
>  Residual             655.066  25.5943        
> number of obs: 180, groups: Subject, 18
> 
> Fixed effects:
>             Estimate Std. Error t value
> (Intercept)  251.405      6.820   36.86
> Days          10.467      1.546    6.77
> 
> Correlation of Fixed Effects:
>      (Intr)
> Days -0.137
> > (fm3 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy, 
> weights = 
> > w/sum(w)) )
> Linear mixed-effects model fit by REML
> Formula: Reaction ~ Days + (Days | Subject) 
>    Data: sleepstudy
>   AIC  BIC logLik MLdeviance REMLdeviance
>  1754 1770 -871.8       1752         1744
> Random effects:
>  Groups   Name        Variance Std.Dev. Corr  
>  Subject  (Intercept) 610.835  24.7151        
>           Days         35.056   5.9208  0.067 
>  Residual             655.066  25.5943        
> number of obs: 180, groups: Subject, 18
> 
> Fixed effects:
>             Estimate Std. Error t value
> (Intercept)  251.405      6.820   36.86
> Days          10.467      1.546    6.77
> 
> Correlation of Fixed Effects:
>      (Intr)
> Days -0.137 
> 
> > -----Original Message-----
> > From: r-sig-mixed-models-bounces at r-project.org
> > [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Nick 
> > Isaac
> > Sent: Wednesday, April 23, 2008 8:39 AM
> > To: R-sig-mixed-models at r-project.org
> > Subject: [R-sig-ME] Bug in weights in lmer
> > 
> > I have unearthed a bug in the way lmer() deals with weights.
> > 
> > Adding weights causes an inflation of the variance estimates. 
> > The phenomenon is easily demonstrated by comparing the following 
> > models, all of which should be identical:
> > 
> > w<-rep(1,nrow(sleepstudy))
> > (fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy) )
> > (fm2 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy, 
> weights = 
> > w) )
> > (fm3 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy, 
> weights = 
> > w/sum(w)) )
> > 
> > I have tried this with other datasets and models and find the same 
> > general pattern. I find that the inflation factor is correlated with
> > sum(w) and is higher for cross-classified models than simple nested 
> > ones.
> > 
> > The fixed effect estimates are also changed.
> > 
> > Best wishes, Nick
> > 
> > 
> > > sessionInfo()
> > R version 2.6.2 (2008-02-08)
> > i386-apple-darwin8.10.1
> > 
> > locale:
> > en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8
> > 
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> > 
> > other attached packages:
> > [1] lme4_0.999375-13  Matrix_0.999375-7 lattice_0.17-6
> > 
> > loaded via a namespace (and not attached):
> > [1] grid_2.6.2
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > 



From lborger at uoguelph.ca  Wed Apr 23 19:19:33 2008
From: lborger at uoguelph.ca (Luca Borger)
Date: Wed, 23 Apr 2008 13:19:33 -0400
Subject: [R-sig-ME] Bug in weights in lmer
References: <ED7B522EE00C9A4FA515AA71724D61EE1BA7EE@DC1EXCL01.air.org>
Message-ID: <011c01c8a566$32a069c0$0dac6883@ZooAnnex2Luca>

Hi,

are you sure? Unless I am misunderstanding something, I used the latest lme4 
development version available on R-forge:

>[1] lme4_0.999375-13

which I thought is newer then the CRAN version you used:

> [1] lme4_0.99875-9


Please advice me if not.

Cheers,

Luca



----- Original Message ----- 
From: "Doran, Harold" <HDoran at air.org>
To: "Doran, Harold" <HDoran at air.org>; "Nick Isaac" 
<njbisaac at googlemail.com>; <R-sig-mixed-models at r-project.org>
Sent: Wednesday, April 23, 2008 1:09 PM
Subject: Re: [R-sig-ME] Bug in weights in lmer


> It appears you and Luca have older versions. I'm using the most recent
> version posted on CRAN. Try updating your packages and see what happens.
>
>> sessionInfo()
> R version 2.6.2 (2008-02-08)
> i386-pc-mingw32
>
> locale:
> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
> States.1252;LC_MONETARY=English_United
> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
>
> other attached packages:
> [1] lme4_0.99875-9    Matrix_0.999375-7 lattice_0.17-4
>
> loaded via a namespace (and not attached):
> [1] grid_2.6.2
>
>> -----Original Message-----
>> From: Doran, Harold
>> Sent: Wednesday, April 23, 2008 10:16 AM
>> To: 'Nick Isaac'; 'R-sig-mixed-models at r-project.org'
>> Subject: RE: [R-sig-ME] Bug in weights in lmer
>>
>> I'm confused. When I run this, I get the exact same answers
>> for all three models for all variance components and for all
>> fixed effects. See my results below. Where is the bug?
>>
>> > w<-rep(1,nrow(sleepstudy))
>> > w
>>   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
>> 1 1 1 1 1 1 1 1 1  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
>> 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1  [75] 1 1 1 1 1 1 1 1 1 1
>> 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 [112] 1
>> 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
>> 1 1 1 1 1 [149] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
>> 1 1 1 1 1 1 1 1 1
>>
>> > (fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy) )
>> Linear mixed-effects model fit by REML
>> Formula: Reaction ~ Days + (Days | Subject)
>>    Data: sleepstudy
>>   AIC  BIC logLik MLdeviance REMLdeviance
>>  1754 1770 -871.8       1752         1744
>> Random effects:
>>  Groups   Name        Variance Std.Dev. Corr
>>  Subject  (Intercept) 610.835  24.7151
>>           Days         35.056   5.9208  0.067
>>  Residual             655.066  25.5943
>> number of obs: 180, groups: Subject, 18
>>
>> Fixed effects:
>>             Estimate Std. Error t value
>> (Intercept)  251.405      6.820   36.86
>> Days          10.467      1.546    6.77
>>
>> Correlation of Fixed Effects:
>>      (Intr)
>> Days -0.137
>> > (fm2 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy,
>> weights =
>> > w) )
>> Linear mixed-effects model fit by REML
>> Formula: Reaction ~ Days + (Days | Subject)
>>    Data: sleepstudy
>>   AIC  BIC logLik MLdeviance REMLdeviance
>>  1754 1770 -871.8       1752         1744
>> Random effects:
>>  Groups   Name        Variance Std.Dev. Corr
>>  Subject  (Intercept) 610.835  24.7151
>>           Days         35.056   5.9208  0.067
>>  Residual             655.066  25.5943
>> number of obs: 180, groups: Subject, 18
>>
>> Fixed effects:
>>             Estimate Std. Error t value
>> (Intercept)  251.405      6.820   36.86
>> Days          10.467      1.546    6.77
>>
>> Correlation of Fixed Effects:
>>      (Intr)
>> Days -0.137
>> > (fm3 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy,
>> weights =
>> > w/sum(w)) )
>> Linear mixed-effects model fit by REML
>> Formula: Reaction ~ Days + (Days | Subject)
>>    Data: sleepstudy
>>   AIC  BIC logLik MLdeviance REMLdeviance
>>  1754 1770 -871.8       1752         1744
>> Random effects:
>>  Groups   Name        Variance Std.Dev. Corr
>>  Subject  (Intercept) 610.835  24.7151
>>           Days         35.056   5.9208  0.067
>>  Residual             655.066  25.5943
>> number of obs: 180, groups: Subject, 18
>>
>> Fixed effects:
>>             Estimate Std. Error t value
>> (Intercept)  251.405      6.820   36.86
>> Days          10.467      1.546    6.77
>>
>> Correlation of Fixed Effects:
>>      (Intr)
>> Days -0.137
>>
>> > -----Original Message-----
>> > From: r-sig-mixed-models-bounces at r-project.org
>> > [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Nick
>> > Isaac
>> > Sent: Wednesday, April 23, 2008 8:39 AM
>> > To: R-sig-mixed-models at r-project.org
>> > Subject: [R-sig-ME] Bug in weights in lmer
>> >
>> > I have unearthed a bug in the way lmer() deals with weights.
>> >
>> > Adding weights causes an inflation of the variance estimates.
>> > The phenomenon is easily demonstrated by comparing the following
>> > models, all of which should be identical:
>> >
>> > w<-rep(1,nrow(sleepstudy))
>> > (fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy) )
>> > (fm2 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy,
>> weights =
>> > w) )
>> > (fm3 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy,
>> weights =
>> > w/sum(w)) )
>> >
>> > I have tried this with other datasets and models and find the same
>> > general pattern. I find that the inflation factor is correlated with
>> > sum(w) and is higher for cross-classified models than simple nested
>> > ones.
>> >
>> > The fixed effect estimates are also changed.
>> >
>> > Best wishes, Nick
>> >
>> >
>> > > sessionInfo()
>> > R version 2.6.2 (2008-02-08)
>> > i386-apple-darwin8.10.1
>> >
>> > locale:
>> > en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8
>> >
>> > attached base packages:
>> > [1] stats     graphics  grDevices utils     datasets  methods   base
>> >
>> > other attached packages:
>> > [1] lme4_0.999375-13  Matrix_0.999375-7 lattice_0.17-6
>> >
>> > loaded via a namespace (and not attached):
>> > [1] grid_2.6.2
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From HDoran at air.org  Wed Apr 23 19:22:45 2008
From: HDoran at air.org (Doran, Harold)
Date: Wed, 23 Apr 2008 13:22:45 -0400
Subject: [R-sig-ME] [SPAM] - Re: Bug in weights in lmer - Bayesian
	Filter detected spam
In-Reply-To: <011c01c8a566$32a069c0$0dac6883@ZooAnnex2Luca>
Message-ID: <ED7B522EE00C9A4FA515AA71724D61EE1BA7F2@DC1EXCL01.air.org>

No, I am not sure. Doug should clarify. I don't really understand the
difference between versions on R-forge and CRAN. I always download from
CRAN.

> -----Original Message-----
> From: Luca Borger [mailto:lborger at uoguelph.ca] 
> Sent: Wednesday, April 23, 2008 1:20 PM
> To: Doran, Harold; Nick Isaac; R-sig-mixed-models at r-project.org
> Subject: [SPAM] - Re: [R-sig-ME] Bug in weights in lmer - 
> Bayesian Filter detected spam
> 
> Hi,
> 
> are you sure? Unless I am misunderstanding something, I used 
> the latest lme4 development version available on R-forge:
> 
> >[1] lme4_0.999375-13
> 
> which I thought is newer then the CRAN version you used:
> 
> > [1] lme4_0.99875-9
> 
> 
> Please advice me if not.
> 
> Cheers,
> 
> Luca
> 
> 
> 
> ----- Original Message -----
> From: "Doran, Harold" <HDoran at air.org>
> To: "Doran, Harold" <HDoran at air.org>; "Nick Isaac" 
> <njbisaac at googlemail.com>; <R-sig-mixed-models at r-project.org>
> Sent: Wednesday, April 23, 2008 1:09 PM
> Subject: Re: [R-sig-ME] Bug in weights in lmer
> 
> 
> > It appears you and Luca have older versions. I'm using the 
> most recent
> > version posted on CRAN. Try updating your packages and see 
> what happens.
> >
> >> sessionInfo()
> > R version 2.6.2 (2008-02-08)
> > i386-pc-mingw32
> >
> > locale:
> > LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
> > States.1252;LC_MONETARY=English_United
> > States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >
> >
> > other attached packages:
> > [1] lme4_0.99875-9    Matrix_0.999375-7 lattice_0.17-4
> >
> > loaded via a namespace (and not attached):
> > [1] grid_2.6.2
> >
> >> -----Original Message-----
> >> From: Doran, Harold
> >> Sent: Wednesday, April 23, 2008 10:16 AM
> >> To: 'Nick Isaac'; 'R-sig-mixed-models at r-project.org'
> >> Subject: RE: [R-sig-ME] Bug in weights in lmer
> >>
> >> I'm confused. When I run this, I get the exact same answers
> >> for all three models for all variance components and for all
> >> fixed effects. See my results below. Where is the bug?
> >>
> >> > w<-rep(1,nrow(sleepstudy))
> >> > w
> >>   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
> >> 1 1 1 1 1 1 1 1 1  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
> >> 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1  [75] 1 1 1 1 1 1 1 1 1 1
> >> 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 [112] 1
> >> 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
> >> 1 1 1 1 1 [149] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
> >> 1 1 1 1 1 1 1 1 1
> >>
> >> > (fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy) )
> >> Linear mixed-effects model fit by REML
> >> Formula: Reaction ~ Days + (Days | Subject)
> >>    Data: sleepstudy
> >>   AIC  BIC logLik MLdeviance REMLdeviance
> >>  1754 1770 -871.8       1752         1744
> >> Random effects:
> >>  Groups   Name        Variance Std.Dev. Corr
> >>  Subject  (Intercept) 610.835  24.7151
> >>           Days         35.056   5.9208  0.067
> >>  Residual             655.066  25.5943
> >> number of obs: 180, groups: Subject, 18
> >>
> >> Fixed effects:
> >>             Estimate Std. Error t value
> >> (Intercept)  251.405      6.820   36.86
> >> Days          10.467      1.546    6.77
> >>
> >> Correlation of Fixed Effects:
> >>      (Intr)
> >> Days -0.137
> >> > (fm2 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy,
> >> weights =
> >> > w) )
> >> Linear mixed-effects model fit by REML
> >> Formula: Reaction ~ Days + (Days | Subject)
> >>    Data: sleepstudy
> >>   AIC  BIC logLik MLdeviance REMLdeviance
> >>  1754 1770 -871.8       1752         1744
> >> Random effects:
> >>  Groups   Name        Variance Std.Dev. Corr
> >>  Subject  (Intercept) 610.835  24.7151
> >>           Days         35.056   5.9208  0.067
> >>  Residual             655.066  25.5943
> >> number of obs: 180, groups: Subject, 18
> >>
> >> Fixed effects:
> >>             Estimate Std. Error t value
> >> (Intercept)  251.405      6.820   36.86
> >> Days          10.467      1.546    6.77
> >>
> >> Correlation of Fixed Effects:
> >>      (Intr)
> >> Days -0.137
> >> > (fm3 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy,
> >> weights =
> >> > w/sum(w)) )
> >> Linear mixed-effects model fit by REML
> >> Formula: Reaction ~ Days + (Days | Subject)
> >>    Data: sleepstudy
> >>   AIC  BIC logLik MLdeviance REMLdeviance
> >>  1754 1770 -871.8       1752         1744
> >> Random effects:
> >>  Groups   Name        Variance Std.Dev. Corr
> >>  Subject  (Intercept) 610.835  24.7151
> >>           Days         35.056   5.9208  0.067
> >>  Residual             655.066  25.5943
> >> number of obs: 180, groups: Subject, 18
> >>
> >> Fixed effects:
> >>             Estimate Std. Error t value
> >> (Intercept)  251.405      6.820   36.86
> >> Days          10.467      1.546    6.77
> >>
> >> Correlation of Fixed Effects:
> >>      (Intr)
> >> Days -0.137
> >>
> >> > -----Original Message-----
> >> > From: r-sig-mixed-models-bounces at r-project.org
> >> > [mailto:r-sig-mixed-models-bounces at r-project.org] On 
> Behalf Of Nick
> >> > Isaac
> >> > Sent: Wednesday, April 23, 2008 8:39 AM
> >> > To: R-sig-mixed-models at r-project.org
> >> > Subject: [R-sig-ME] Bug in weights in lmer
> >> >
> >> > I have unearthed a bug in the way lmer() deals with weights.
> >> >
> >> > Adding weights causes an inflation of the variance estimates.
> >> > The phenomenon is easily demonstrated by comparing the following
> >> > models, all of which should be identical:
> >> >
> >> > w<-rep(1,nrow(sleepstudy))
> >> > (fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy) )
> >> > (fm2 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy,
> >> weights =
> >> > w) )
> >> > (fm3 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy,
> >> weights =
> >> > w/sum(w)) )
> >> >
> >> > I have tried this with other datasets and models and 
> find the same
> >> > general pattern. I find that the inflation factor is 
> correlated with
> >> > sum(w) and is higher for cross-classified models than 
> simple nested
> >> > ones.
> >> >
> >> > The fixed effect estimates are also changed.
> >> >
> >> > Best wishes, Nick
> >> >
> >> >
> >> > > sessionInfo()
> >> > R version 2.6.2 (2008-02-08)
> >> > i386-apple-darwin8.10.1
> >> >
> >> > locale:
> >> > en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8
> >> >
> >> > attached base packages:
> >> > [1] stats     graphics  grDevices utils     datasets  
> methods   base
> >> >
> >> > other attached packages:
> >> > [1] lme4_0.999375-13  Matrix_0.999375-7 lattice_0.17-6
> >> >
> >> > loaded via a namespace (and not attached):
> >> > [1] grid_2.6.2
> >> >
> >> > _______________________________________________
> >> > R-sig-mixed-models at r-project.org mailing list
> >> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > 
> 
> 



From maechler at stat.math.ethz.ch  Wed Apr 23 21:50:54 2008
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 23 Apr 2008 21:50:54 +0200
Subject: [R-sig-ME] [SPAM] - Re: Bug in weights in lmer - Bayesian
	Filter detected spam
In-Reply-To: <ED7B522EE00C9A4FA515AA71724D61EE1BA7F2@DC1EXCL01.air.org>
References: <011c01c8a566$32a069c0$0dac6883@ZooAnnex2Luca>
	<ED7B522EE00C9A4FA515AA71724D61EE1BA7F2@DC1EXCL01.air.org>
Message-ID: <18447.37662.483228.690870@cmath-5.math.ethz.ch>

>>>>> "HaroldD" == Doran, Harold <HDoran at air.org>
>>>>>     on Wed, 23 Apr 2008 13:22:45 -0400 writes:

    HaroldD> No, I am not sure. Doug should clarify. I don't really understand the
    HaroldD> difference between versions on R-forge and CRAN. I always download from
    HaroldD> CRAN.

R-forge contains *development* versions of packages,
almost surely always more recent than CRAN versions.

For lme4, the situation is particular:  The R-forge version has
had many updates, but never came with a guarantee of "uniformly
improved", and hence has not been CRAN-released for a while.
IIRC, I'd definitely use the R-forge version if I was interested in
generalized or non-linear or generalized non-linear
mixed effect model,
and I'd also use it if I wanted to be a nice person and help
Doug Bates to advance farther even faster .. ;-)

But then, I'd really install both versions (into *different* libraries!)
so I could chose which one to use for a given situation.

Martin

    >> -----Original Message-----
    >> From: Luca Borger [mailto:lborger at uoguelph.ca] 
    >> Sent: Wednesday, April 23, 2008 1:20 PM
    >> To: Doran, Harold; Nick Isaac; R-sig-mixed-models at r-project.org
    >> Subject: [SPAM] - Re: [R-sig-ME] Bug in weights in lmer - 
    >> Bayesian Filter detected spam
    >> 
    >> Hi,
    >> 
    >> are you sure? Unless I am misunderstanding something, I used 
    >> the latest lme4 development version available on R-forge:
    >> 
    >> >[1] lme4_0.999375-13
    >> 
    >> which I thought is newer then the CRAN version you used:
    >> 
    >> > [1] lme4_0.99875-9
    >> 
    >> 
    >> Please advice me if not.
    >> 
    >> Cheers,
    >> 
    >> Luca
    >> 
    >> 
    >> 
    >> ----- Original Message -----
    >> From: "Doran, Harold" <HDoran at air.org>
    >> To: "Doran, Harold" <HDoran at air.org>; "Nick Isaac" 
    >> <njbisaac at googlemail.com>; <R-sig-mixed-models at r-project.org>
    >> Sent: Wednesday, April 23, 2008 1:09 PM
    >> Subject: Re: [R-sig-ME] Bug in weights in lmer
    >> 
    >> 
    >> > It appears you and Luca have older versions. I'm using the 
    >> most recent
    >> > version posted on CRAN. Try updating your packages and see 
    >> what happens.
    >> >
    >> >> sessionInfo()
    >> > R version 2.6.2 (2008-02-08)
    >> > i386-pc-mingw32
    >> >
    >> > locale:
    >> > LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
    >> > States.1252;LC_MONETARY=English_United
    >> > States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
    >> >
    >> > attached base packages:
    >> > [1] stats     graphics  grDevices utils     datasets  methods   base
    >> >
    >> >
    >> > other attached packages:
    >> > [1] lme4_0.99875-9    Matrix_0.999375-7 lattice_0.17-4
    >> >
    >> > loaded via a namespace (and not attached):
    >> > [1] grid_2.6.2
    >> >
    >> >> -----Original Message-----
    >> >> From: Doran, Harold
    >> >> Sent: Wednesday, April 23, 2008 10:16 AM
    >> >> To: 'Nick Isaac'; 'R-sig-mixed-models at r-project.org'
    >> >> Subject: RE: [R-sig-ME] Bug in weights in lmer
    >> >>
    >> >> I'm confused. When I run this, I get the exact same answers
    >> >> for all three models for all variance components and for all
    >> >> fixed effects. See my results below. Where is the bug?
    >> >>
    >> >> > w<-rep(1,nrow(sleepstudy))
    >> >> > w
    >> >>   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
    >> >> 1 1 1 1 1 1 1 1 1  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
    >> >> 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1  [75] 1 1 1 1 1 1 1 1 1 1
    >> >> 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 [112] 1
    >> >> 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
    >> >> 1 1 1 1 1 [149] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
    >> >> 1 1 1 1 1 1 1 1 1
    >> >>
    >> >> > (fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy) )
    >> >> Linear mixed-effects model fit by REML
    >> >> Formula: Reaction ~ Days + (Days | Subject)
    >> >>    Data: sleepstudy
    >> >>   AIC  BIC logLik MLdeviance REMLdeviance
    >> >>  1754 1770 -871.8       1752         1744
    >> >> Random effects:
    >> >>  Groups   Name        Variance Std.Dev. Corr
    >> >>  Subject  (Intercept) 610.835  24.7151
    >> >>           Days         35.056   5.9208  0.067
    >> >>  Residual             655.066  25.5943
    >> >> number of obs: 180, groups: Subject, 18
    >> >>
    >> >> Fixed effects:
    >> >>             Estimate Std. Error t value
    >> >> (Intercept)  251.405      6.820   36.86
    >> >> Days          10.467      1.546    6.77
    >> >>
    >> >> Correlation of Fixed Effects:
    >> >>      (Intr)
    >> >> Days -0.137
    >> >> > (fm2 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy,
    >> >> weights =
    >> >> > w) )
    >> >> Linear mixed-effects model fit by REML
    >> >> Formula: Reaction ~ Days + (Days | Subject)
    >> >>    Data: sleepstudy
    >> >>   AIC  BIC logLik MLdeviance REMLdeviance
    >> >>  1754 1770 -871.8       1752         1744
    >> >> Random effects:
    >> >>  Groups   Name        Variance Std.Dev. Corr
    >> >>  Subject  (Intercept) 610.835  24.7151
    >> >>           Days         35.056   5.9208  0.067
    >> >>  Residual             655.066  25.5943
    >> >> number of obs: 180, groups: Subject, 18
    >> >>
    >> >> Fixed effects:
    >> >>             Estimate Std. Error t value
    >> >> (Intercept)  251.405      6.820   36.86
    >> >> Days          10.467      1.546    6.77
    >> >>
    >> >> Correlation of Fixed Effects:
    >> >>      (Intr)
    >> >> Days -0.137
    >> >> > (fm3 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy,
    >> >> weights =
    >> >> > w/sum(w)) )
    >> >> Linear mixed-effects model fit by REML
    >> >> Formula: Reaction ~ Days + (Days | Subject)
    >> >>    Data: sleepstudy
    >> >>   AIC  BIC logLik MLdeviance REMLdeviance
    >> >>  1754 1770 -871.8       1752         1744
    >> >> Random effects:
    >> >>  Groups   Name        Variance Std.Dev. Corr
    >> >>  Subject  (Intercept) 610.835  24.7151
    >> >>           Days         35.056   5.9208  0.067
    >> >>  Residual             655.066  25.5943
    >> >> number of obs: 180, groups: Subject, 18
    >> >>
    >> >> Fixed effects:
    >> >>             Estimate Std. Error t value
    >> >> (Intercept)  251.405      6.820   36.86
    >> >> Days          10.467      1.546    6.77
    >> >>
    >> >> Correlation of Fixed Effects:
    >> >>      (Intr)
    >> >> Days -0.137
    >> >>
    >> >> > -----Original Message-----
    >> >> > From: r-sig-mixed-models-bounces at r-project.org
    >> >> > [mailto:r-sig-mixed-models-bounces at r-project.org] On 
    >> Behalf Of Nick
    >> >> > Isaac
    >> >> > Sent: Wednesday, April 23, 2008 8:39 AM
    >> >> > To: R-sig-mixed-models at r-project.org
    >> >> > Subject: [R-sig-ME] Bug in weights in lmer
    >> >> >
    >> >> > I have unearthed a bug in the way lmer() deals with weights.
    >> >> >
    >> >> > Adding weights causes an inflation of the variance estimates.
    >> >> > The phenomenon is easily demonstrated by comparing the following
    >> >> > models, all of which should be identical:
    >> >> >
    >> >> > w<-rep(1,nrow(sleepstudy))
    >> >> > (fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy) )
    >> >> > (fm2 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy,
    >> >> weights =
    >> >> > w) )
    >> >> > (fm3 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy,
    >> >> weights =
    >> >> > w/sum(w)) )
    >> >> >
    >> >> > I have tried this with other datasets and models and 
    >> find the same
    >> >> > general pattern. I find that the inflation factor is 
    >> correlated with
    >> >> > sum(w) and is higher for cross-classified models than 
    >> simple nested
    >> >> > ones.
    >> >> >
    >> >> > The fixed effect estimates are also changed.
    >> >> >
    >> >> > Best wishes, Nick
    >> >> >
    >> >> >
    >> >> > > sessionInfo()
    >> >> > R version 2.6.2 (2008-02-08)
    >> >> > i386-apple-darwin8.10.1
    >> >> >
    >> >> > locale:
    >> >> > en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8
    >> >> >
    >> >> > attached base packages:
    >> >> > [1] stats     graphics  grDevices utils     datasets  
    >> methods   base
    >> >> >
    >> >> > other attached packages:
    >> >> > [1] lme4_0.999375-13  Matrix_0.999375-7 lattice_0.17-6
    >> >> >
    >> >> > loaded via a namespace (and not attached):
    >> >> > [1] grid_2.6.2
    >> >> >
    >> >> > _______________________________________________
    >> >> > R-sig-mixed-models at r-project.org mailing list
    >> >> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
    >> >> >
    >> >
    >> > _______________________________________________
    >> > R-sig-mixed-models at r-project.org mailing list
    >> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
    >> > 
    >> 
    >> 

    HaroldD> _______________________________________________
    HaroldD> R-sig-mixed-models at r-project.org mailing list
    HaroldD> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From dieter.menne at menne-biomed.de  Thu Apr 24 08:22:02 2008
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Thu, 24 Apr 2008 06:22:02 +0000 (UTC)
Subject: [R-sig-ME] Inconsistency: works with CRAN, not with r-forge
Message-ID: <loom.20080424T061239-709@post.gmane.org>

The following example by Michael Kubovy and using Gregory Warnes' gmodels works
with the CRAN version, but not with the current r-forge version lme4
0.999375-13. While it might be caused by some problem in <estimable>, it looks
more like a coef() infelicity to me.

The usual: Cetero censeo estimable in lme/lmer esse.

Dieter

library(lme4)
library(gmodels)
recall <- c(10, 13, 13, 6, 8, 8, 11, 14, 14, 22, 23, 25, 16, 18, 20, 15, 17, 17,
1, 1, 4, 12, 15, 17, 9, 12, 12, 8, 9, 12) 
fr <- data.frame(rcl = recall, time = factor(rep(c(1, 2, 5), 10)), subj =
factor(rep(1:10, each = 3))) 
(fr.lmer <- lmer(rcl ~ time -1 +(1 | subj), fr)) 
mm <- unique(model.matrix(~ time -1, fr)) 
cm <- mm[1, ] - mm[3, ]
cm1 <- mm[1, ] - mm[2, ]
estimable(fr.lmer, cm = cm, conf.into = 0.95) 
estimable(fr.lmer, cm = cm1, conf.into = 0.95)



Error in coef(obj) : unable to align random and fixed effects

traceback()
8: stop("unable to align random and fixed effects")
7: coef(obj)
6: coef(obj)
5: .to.est(obj, cm)
4: as.vector(data)
3: matrix(.to.est(obj, cm), nrow = 1)
2: estimable.default(fr.lmer, cm = cm1, conf.into = 0.95)
1: estimable(fr.lmer, cm = cm1, conf.into = 0.95)



From njbisaac at googlemail.com  Thu Apr 24 11:12:18 2008
From: njbisaac at googlemail.com (Nick Isaac)
Date: Thu, 24 Apr 2008 10:12:18 +0100
Subject: [R-sig-ME] Bug in weights in lmer
In-Reply-To: <011c01c8a566$32a069c0$0dac6883@ZooAnnex2Luca>
References: <ED7B522EE00C9A4FA515AA71724D61EE1BA7EE@DC1EXCL01.air.org>
	<011c01c8a566$32a069c0$0dac6883@ZooAnnex2Luca>
Message-ID: <a072ed700804240212s28cf4ddfhb04cb6f4a26fb9df@mail.gmail.com>

Harold:
Could you try the same set of models using lmer2?

In July last year Sundar Dorai-Raj reported that the weights argument
was not being used in the CRAN version of lmer (lme4_0.99875-6).
Therefore, it's possible that you have actually observed the same
phenomenon in lme4_0.99875-9.

Sundar found that lmer2 did use weights, but it's not clear whether
the weighted model is correct. The development version of lmer
(lme4_0.999375-13) is much closer to the CRAN version of lmer2 than
lmer.

See his original post at:

https://stat.ethz.ch/pipermail/r-sig-mixed-models/2007q3/000262.html

Best wishes, Nick



From kubovy at virginia.edu  Thu Apr 24 11:13:13 2008
From: kubovy at virginia.edu (Michael Kubovy)
Date: Thu, 24 Apr 2008 05:13:13 -0400
Subject: [R-sig-ME] Inconsistency: works with CRAN, not with r-forge
In-Reply-To: <loom.20080424T061239-709@post.gmane.org>
References: <loom.20080424T061239-709@post.gmane.org>
Message-ID: <F6B4C054-0C37-44E5-AFEB-A40A8BEE6B3E@virginia.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080424/9e59d4b1/attachment.pl>

From bates at stat.wisc.edu  Thu Apr 24 14:44:32 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 24 Apr 2008 07:44:32 -0500
Subject: [R-sig-ME] Bug in weights in lmer
In-Reply-To: <a072ed700804240212s28cf4ddfhb04cb6f4a26fb9df@mail.gmail.com>
References: <ED7B522EE00C9A4FA515AA71724D61EE1BA7EE@DC1EXCL01.air.org>
	<011c01c8a566$32a069c0$0dac6883@ZooAnnex2Luca>
	<a072ed700804240212s28cf4ddfhb04cb6f4a26fb9df@mail.gmail.com>
Message-ID: <40e66e0b0804240544g7687ce08gf1c62b189258f1d2@mail.gmail.com>

Sorry that I haven't responded on this thread previously.  I have had
two computers, a desktop at my office and a desktop at home, go south
in the same week.  I have been reduced to using an old Dell laptop
running Windows as my primary computer at work.  Those of you who know
my affection for Windows can imagine how cheerful that makes me.  :-)

Thank you for pointing out the problem with the weights, Nick, and for
including the example.  I haven't worked out what is going wrong yet
because i am still working on some other problems and some examples.
I can tell you where the pieces of information are in a fitted lmer
model (from the version on R-forge) and that may help to isolate the
problem.  Fixed weights are stored in the pWt slot and used to
calculate a weighted residual sum of squares, the "wrss" element in
the deviance slot.  (The name "pWt" comes from the fact that these are
called the "prior weights" for a generalized linear model.)  When
prior weights are not used this slot has length zero.

The mle  of sigma^2 in the unweighted case is the penalized weighted
residual sum of squares (the "pwrss" element of the deviance slot)
divided by the number of observations.  The "penality" is a quadratic
form in the random effects.  It can be expressed as the squared length
of the orthogonal random effects in the u slot.

It is likely that this estimate should be  the pwrss divided by either
the sum of the elements in pWt or the sum of the squares of the
elements in pWt when we don't have unit weights.  Do either of those
numbers seem reasonable?

Because the variance components are calculated relative to the
estimate of sigma^2, changing sigma^2 will change those too.




On 4/24/08, Nick Isaac <njbisaac at googlemail.com> wrote:
> Harold:
>  Could you try the same set of models using lmer2?
>
>  In July last year Sundar Dorai-Raj reported that the weights argument
>  was not being used in the CRAN version of lmer (lme4_0.99875-6).
>  Therefore, it's possible that you have actually observed the same
>  phenomenon in lme4_0.99875-9.
>
>  Sundar found that lmer2 did use weights, but it's not clear whether
>  the weighted model is correct. The development version of lmer
>  (lme4_0.999375-13) is much closer to the CRAN version of lmer2 than
>  lmer.
>
>  See his original post at:
>
>  https://stat.ethz.ch/pipermail/r-sig-mixed-models/2007q3/000262.html
>
>  Best wishes, Nick
>
>
>  _______________________________________________
>  R-sig-mixed-models at r-project.org mailing list
>  https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Thu Apr 24 15:17:55 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 24 Apr 2008 08:17:55 -0500
Subject: [R-sig-ME] Version of lme4 on R-forge
Message-ID: <40e66e0b0804240617t7f34ffc6i26e48e7008108baf@mail.gmail.com>

There has been some discussion on this list about what is the "most
recent" version of the lme4 package.  The version on CRAN is
comparatively old.  Several months ago I made some radical changes in
the internal representation of the model and I am still working on
providing all the earlier capabilities under this new representation.
This is the version on R-forge.  It is much more advanced than the
version on CRAN in the design and even in the theory but there are
still areas where its functionality is incomplete.  In particular, the
mcmcsamp function in the R-forge version doesn't work well for models
where some of the variance components are near zero.  I think I have a
way out of that but it will involve more development and coding and
testing.

If I release the R-forge version to CRAN some of the code that is
documented in books like Harald Baayen's "Analyzing Linguistic Data"
and Gelman and Hill's "Data Analysis Using Regression and
Multilevel/Hierarchical Models" will cease to function or, worse,
produce incorrect results.

In general I think that users are better off with the version on
R-forge except for the long-standing problem of how to come up with
p-values on fixed-effects terms.  This is why I get frustrated with
this issue of p-values and degrees of freedom.  There are many good
things that could be done with the version of lme4 on R-forge.  In
particular, the ability to fit models to large data sets with crossed
or partially crossed factors for random effects is revolutionary.
Other software can't do that.  But that doesn't matter.  The only
important issue is being able to produce the "correct" degrees of
freedom on some tinker-toy text book example.



From demont at access.uzh.ch  Thu Apr 24 15:42:17 2008
From: demont at access.uzh.ch (Marco Demont)
Date: Thu, 24 Apr 2008 15:42:17 +0200
Subject: [R-sig-ME] mcmcsamp(lme4) & mcsamp(arm) & HPDinterval(coda): 2
	questions
Message-ID: <web-13169668@idmailbe2b.unizh.ch>

Dear lme4 users,

I want to generate a sample from the posterior distribution of the 
parameters of my fitted mixed model using the mcmcsamp function (lme4 
Package). Additionally, I would also like to create 95% highest posterior 
density (HPD) intervals for the parameters in the MCMC sample (maybe with 
the HPDinterval function from the coda Package?).

For that purpose I got two questions:

Question 1:
How can I adjust or change the number of chains, the thinning interval and 
the burn-in for the mcmcsamp function (lme4 Package)?

Question 2:
I did this (e.g. change number of chains, thinning interval, etc) in the 
mcsamp function (arm Package) (mcsamp relies on mcmcsamp). mcsamp creates an 
object of class ?bugs?. How can I get 95% highest posterior density (HPD) 
intervals for this ?bugs? object?

To summarize my problem: in my first approach (Question 1) I?m able to 
create HPD intervals, but NOT to change number of chains, thinning interval 
etc; in my second approach (Question 2) I?m able to change number of chains, 
thinning interval etc, but NOT to create HPD intervals.

Would be nice if somebody could help!

Sincerely,
Marco




**************************************************************
Marco Demont
Zoological Museum
University of Zuerich
Winterthurerstrasse 190
CH-8057 Zuerich
Switzerland

Tel.: +41 44 635 47 79
demont at access.uzh.ch
demont at gmx.ch
www.unizh.ch/zoolmus/zmneu/englisch/forschung_e/demont_marco_e.html



From Greg.Snow at imail.org  Thu Apr 24 17:45:01 2008
From: Greg.Snow at imail.org (Greg Snow)
Date: Thu, 24 Apr 2008 09:45:01 -0600
Subject: [R-sig-ME] Version of lme4 on R-forge
In-Reply-To: <40e66e0b0804240617t7f34ffc6i26e48e7008108baf@mail.gmail.com>
References: <40e66e0b0804240617t7f34ffc6i26e48e7008108baf@mail.gmail.com>
Message-ID: <07E228A5BE53C24CAD490193A7381BBB01055C59@LP-EXCHVS07.CO.IHC.COM>

Doug,

I've been thinking about this for a while and have a possible suggestion
for the p-value issue (maybe you have already considered what I am about
to suggest and decided against it, in that case feel free to ignore it).
This is more along the lines of making the p-value adicts happy (or at
least get them off your back) rather than suggesting this best
statistical practice.

For those of us that started with statistics before computers were
common, we ended up with p-values for t-tests given as somewhere in a
range ( .01 < p < .05 ).  Since you don't have a way to come up with a
p-value for the fixed effects that you are happy with, maybe there is a
way to come up with a range that that you would be comforatable with (my
initial thought was 0 <= p <= 1, that way they could not complain that
nothing was printed).  If I remember correctly, you have said that the
commonly used (SAS) degrees of freedom result in a p-value that is
anti-conservative, so that could be your lower bound.  One possibility
for the upper bound would be treating all the random effects like fixed
effects (subtract 1 for each random group from the previous df).  That
could handle the df problem for the conservative estimate if you are
happy with the F approximation.  However I think I remember you stating
that the F did not fit that well in many cases, so that may not be
conservative enough, in that case I would expect an approximation based
on Chebyshev's inequality would tend to be conservative (and then those
that are not convinced that a t ratio of 10 is unlikely due to chance
without a p-value would have something to point at).

So if the summary method returned instead of a p-value, a range that the
p-value is likely to be in (still an approximation), then a range like
0.001 < p < .01 would imply significance, 0.2 < p < 0.5 would be non
significant, and 0.02 < p < 0.2 would tell the user that they needed to
look further for a better test ("hey, what is the mcmcsamp thing ? ...).

And if people still complain, you can blame it on me :-)

Just a thought, hope it helps,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at imail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf 
> Of Douglas Bates
> Sent: Thursday, April 24, 2008 7:18 AM
> To: R Mixed Models
> Subject: [R-sig-ME] Version of lme4 on R-forge
> 
> There has been some discussion on this list about what is the 
> "most recent" version of the lme4 package.  The version on 
> CRAN is comparatively old.  Several months ago I made some 
> radical changes in the internal representation of the model 
> and I am still working on providing all the earlier 
> capabilities under this new representation.
> This is the version on R-forge.  It is much more advanced 
> than the version on CRAN in the design and even in the theory 
> but there are still areas where its functionality is 
> incomplete.  In particular, the mcmcsamp function in the 
> R-forge version doesn't work well for models where some of 
> the variance components are near zero.  I think I have a way 
> out of that but it will involve more development and coding 
> and testing.
> 
> If I release the R-forge version to CRAN some of the code 
> that is documented in books like Harald Baayen's "Analyzing 
> Linguistic Data"
> and Gelman and Hill's "Data Analysis Using Regression and 
> Multilevel/Hierarchical Models" will cease to function or, 
> worse, produce incorrect results.
> 
> In general I think that users are better off with the version 
> on R-forge except for the long-standing problem of how to 
> come up with p-values on fixed-effects terms.  This is why I 
> get frustrated with this issue of p-values and degrees of 
> freedom.  There are many good things that could be done with 
> the version of lme4 on R-forge.  In particular, the ability 
> to fit models to large data sets with crossed or partially 
> crossed factors for random effects is revolutionary.
> Other software can't do that.  But that doesn't matter.  The 
> only important issue is being able to produce the "correct" 
> degrees of freedom on some tinker-toy text book example.
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 



From njbisaac at googlemail.com  Thu Apr 24 19:46:57 2008
From: njbisaac at googlemail.com (Nick Isaac)
Date: Thu, 24 Apr 2008 18:46:57 +0100
Subject: [R-sig-ME] Bug in weights in lmer
In-Reply-To: <40e66e0b0804240544g7687ce08gf1c62b189258f1d2@mail.gmail.com>
References: <ED7B522EE00C9A4FA515AA71724D61EE1BA7EE@DC1EXCL01.air.org>
	<011c01c8a566$32a069c0$0dac6883@ZooAnnex2Luca>
	<a072ed700804240212s28cf4ddfhb04cb6f4a26fb9df@mail.gmail.com>
	<40e66e0b0804240544g7687ce08gf1c62b189258f1d2@mail.gmail.com>
Message-ID: <a072ed700804241046t3c5b7c1dj81fdc69237b7afc3@mail.gmail.com>

Dear Prof Bates,

Thanks for your reply. My sympathies re your computer ailments.

Following your suggestion, I explored the relationship between sigma^2
and pwrss:

w<-rep(1,nrow(sleepstudy)
fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
fm2 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy, weights = w)
fm3 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy, weights = w/sum(w))
fm4 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy, weights = 2*w)

myfunc<-function(x){c(x at deviance[5]^2,x at deviance[7]/nrow(x at frame),x at deviance[7]/sum(x at pWt),x at deviance[7]/sum(x at pWt^2))}
a<-sapply(c(fm1,fm2,fm3,fm4),myfunc)
colnames(a)<-c("unweighted","w=1","sum(w)=1","w=2")
rownames(a)<-c("sigmaML^2","pwrss/n","pwrss/sum(w)","pwrss/sum(w^2)")

a

               unweighted     w=1     sum(w)=1      w=2
sigmaML^2        647.6672 7026169 9.992688e+05 11571700
pwrss/n          647.6672 7026169 5.551493e+03 23143401
pwrss/sum(w)          Inf 7026169 9.992688e+05 11571700
pwrss/sum(w^2)        Inf 7026169 1.798684e+08  5785850


>  It is likely that this estimate should be  the pwrss divided by either
>  the sum of the elements in pWt or the sum of the squares of the
>  elements in pWt when we don't have unit weights.  Do either of those
>  numbers seem reasonable?

The unweighted model (fm1) behaves as it should: sigma^2 equals
pwrss/n and the empty pWt slot means that the other two entries return
Inf. When all observations receive weight=1 (fm2), all four estimates
are equal because n=sum(w)=sum(w^2)=180. However, these numbers are
far higher than the comparable values in fm1. The third and fourth
models, in which the observations are weighted equally (1/180 & 2
respectively) show that sigma^2 equals pwrss/sum(w) (your suggestion
#1).

But this doesn't explain why sigma should differ between fm1 and fm2
(they should be identical, right?). So I compared the contents of the
u slot:

plot(fm1 at u, fm2 at u)

Whilst fm1 at u is approximately normally distributed around zero, fm2 is
bimodal and all values are positive. It turns out that the even
elements of the two are perfectly correlated: fm2 at u = 158 + 2.4 *
fm1 at u:

summary(lm(fm2 at u[(1:18)*2] ~ fm1 at u[(1:18)*2]))

However, the relationship between the odd elements is much weaker:

summary(lm(fm2 at u[(1:18)*2-1] ~ fm1 at u[(1:18)*2-1]))

My understanding is not sufficient to know what this means, but I hope
it provides you with some useful clues.

Best wishes, Nick



From jebyrnes at ucdavis.edu  Fri Apr 25 00:48:32 2008
From: jebyrnes at ucdavis.edu (Jarrett Byrnes)
Date: Thu, 24 Apr 2008 15:48:32 -0700
Subject: [R-sig-ME] Obtaining parameter error in a multilevel model
Message-ID: <7E409E60-7EDC-4CF1-9EC7-481553B06BA8@ucdavis.edu>

(sorry for the repost, but I just realized the old version was  
scrubbed due to some html when I copied and pasted from my code editor  
- apologies!)

Hello, all.  I have a question about combining fixed effects with
their random effects in a multilevel model in order to look at the
effects of a treatment at multiple levels.  Note, I'm particularly
interested in this so that I can later make comparisons between
different groups.  But, let's use the sleep study as an example.
Using lme4 and Gelman's arm library, I can obtain both the fixed
effects and deviations due to their different grouping variables.  I
can also obtain the error around my estimate of both the fixed and
random effect.  E.g.,

library(arm)
fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)

#gets fixed effect and the error in it's estimate
fixef(fm1)
se.fixef(fm1)

#gets deviation from fixed effect means and the error in that estimate
ranef(fm1)
se.ranef(fm1)

However, what if I wish to look at, say, the error of the intercept
for each subject?  Or the estimate of error around the effect of Days
for each subject?  One does not merely add se.fixed and se.ranef to
get an estimate of error around those parameters, right?  While this
may not be as big a problem for the sleepstudy data, it becomes more
important for unbalanced data.

It seems like mcmcsamp could be a great solution to that, but,
mcmcsamp does not give estimates of each individual parameter.
Rather, it again also gives estimates of the random effects using
saveb=T.  I must admit, however, I am unclear one which random effect
goes with which fixed effect (they're all b.1, b2, etc in the output
of mcmcsamp - can I get some clarification?)

Although, hrm, could one merely add the fixed effect estimates to the
random effect estimates from mcmcsamp to obtain the values for each
parameter value?

Note, I'm trying to use the method presented below for multiple
comparisons with lmer.  Any other thoughts would be appreciated.
http://www.stat.columbia.edu/~cook/movabletype/archives/2008/03/why_i_dont_usua_1.html


-Jarrett




----------------------------------------
Jarrett Byrnes
Population Biology Graduate Group, UC Davis
Bodega Marine Lab
707-875-1969
http://www-eve.ucdavis.edu/stachowicz/byrnes.shtml



From mwkimpel at gmail.com  Sat Apr 26 05:53:24 2008
From: mwkimpel at gmail.com (Mark Kimpel)
Date: Fri, 25 Apr 2008 23:53:24 -0400
Subject: [R-sig-ME] interpreting significance from lmer results for dummies
	(like me)
Message-ID: <6b93d1830804252053j5c264ae0u26d8e4c819d2b19@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080425/b80c5615/attachment.pl>

From A.Robinson at ms.unimelb.edu.au  Sat Apr 26 09:59:21 2008
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Sat, 26 Apr 2008 17:59:21 +1000
Subject: [R-sig-ME] interpreting significance from lmer results for
	dummies (like me)
In-Reply-To: <6b93d1830804252053j5c264ae0u26d8e4c819d2b19@mail.gmail.com>
References: <6b93d1830804252053j5c264ae0u26d8e4c819d2b19@mail.gmail.com>
Message-ID: <20080426075921.GM1945@ms.unimelb.edu.au>

Hi Mark,

On Fri, Apr 25, 2008 at 11:53:24PM -0400, Mark Kimpel wrote:
> I am a bioinformatistician, with my strongest background in molecular
> biology. I have been trying to learn about mixed-effects to improve the
> analysis of my experiments, which certainly contain random effects. I will
> admit to being totally lost in the discussions regarding lack of p-value
> reporting in the current versions of lmer. Furthermore, I suspect those that
> need to publish to non-statistical journals will face reviewers who are
> equally in the dark. Where can I find a biologist-level explanation of the
> current controversy, 

I'll take a stab.

1) the traditional, Fisher-style test of a null hypothesis is based on
   computing the probability of observing a test statistic as extreme
   or more extreme than the one actually observed, assuming that the
   null hypothesis is true.  This probability is called the p-value.
   If the p-value is less than some cut-off, e.g. 0.01, then the null
   hypothesis is rejected.

2) in order to compute that p-value, we need to know the cumulative
   distribution function of the test statistic when the null
   hypothesis is true. In simple cases this is easy: for example, we
   use the t-distribution for the comparison of two normal means (with
   assumed equal variances etc).

3) in (many) hierarchical models the cumulative distribution function
   of the test statistic when the null hypothesis is true is simply not
   known.  So, we can't compute the p-value.  

3a) in a limited range of hierarchical models that have historically
    dominated analysis of variance, e.g. split-plot designs, the
    reference distribution is known (it's F).  

3b) Numerous experts have (quite reasonably) built up a bulwark of
    intuitive knowledge about the analysis of such designs.

3c) the intuition does not necessarily pertain to the analysis of any
    arbitrary hierarchical design, which might be unbalanced, and have
    crossed random effects.  That is, the intuition might be applied,
    but inappropriately.

4) in any case, the distribution that is intuitively or otherwise
    assumed is the F, because it works in the cases mentioned in 3a.
    All that remains is to define the degrees of freedom.  The
    numerator degrees of freedom are obvious, but the denominator
    degrees of freedom are not known.

4a) numerous other packages supply approximations to the denominator
    degrees of freedom, eg Satterthwaite, and KR (which is related).
    They have been subjected to a modest degree of scrutiny by
    simulation.

5) however, it is not clear that the reference distribution is really
   F at all, and therefore it is not clear that correcting the
   denominator degrees of freedom is what is needed.  Confusion reigns
   on how the p-values should be computed.  And because of this
   confusion, Doug Bates declines to provide p-values.

> how can I learn how to properly judge significance from my lmer
> results,

There are numerous approximations, but no way to properly judge
significance as far as I am aware.  Try the R-wiki for algorithms, and
be conservative.  

http://wiki.r-project.org/rwiki/doku.php

Or, use lme, report the p-values computed therein, and be aware that
they are not necessarily telling you exactly what you want to know.

> and what peer-reviewed references can I steer reviewers
> towards?

Not sure about that one.  I'm working on some simulations with Doug
but it's slow going, mainly because I'm chronically disorganised.

> I understand, from other threads, that some believe a paradigm shift
> away from p-values may be necessary, but I it is not clear to me
> what paradigm will replace this entrenced view. I can appreciate the
> fact that there may be conflicting opinions about the best
> equations/algorithms for determining significance, but is there any
> agreement on the goal we are heading towards?

The conflict is not about p-values per se, but about the way that they
are calculated.  I would bet that the joint goal is to find an
algorithm that provides robust, reasonable inference in a sufficiently
wide variety of cases that its implementation proves to be worthwhile.

I hope that this was helpful.

Andrew

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From gdoyle at ling.ucsd.edu  Sun Apr 27 03:44:52 2008
From: gdoyle at ling.ucsd.edu (Gabe Doyle)
Date: Sat, 26 Apr 2008 18:44:52 -0700
Subject: [R-sig-ME] iteration limit reached without convergence
Message-ID: <aa4ca20bdcea266bcc19dfd6390b0f00@ling.ucsd.edu>

Dear mixed modellers,

I am running some mixed-effects logit models that seem to fail to converge,
as evidenced by the warning message:

In mer_finalize(ans, verbose) :
iteration limit reached without convergence (9) 

In the CRAN version of lme4, it is possible to specify the maximum number
of iterations used by nlminb while estimating model parameters, by passing
the parameter control=list(msMaxIter=N) in to lmer. However, this doesn't
seem to work with the R-Forge version. Is there a way of controlling the
iteration limit in the R-Forge version that I'm overlooking?

Much obliged,
Gabe Doyle



From A.Robinson at ms.unimelb.edu.au  Sun Apr 27 06:06:23 2008
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Sun, 27 Apr 2008 14:06:23 +1000
Subject: [R-sig-ME] interpreting significance from lmer results
	for	dummies (like me)
In-Reply-To: <B4CB54E3-0C04-4EA6-A127-F75F7F313B3B@anu.edu.au>
References: <6b93d1830804252053j5c264ae0u26d8e4c819d2b19@mail.gmail.com>
	<20080426075921.GM1945@ms.unimelb.edu.au>
	<081CD911-33D7-4C66-803D-89821C2A72DF@anu.edu.au>
	<20080427025413.GA1433@ms.unimelb.edu.au>
	<B4CB54E3-0C04-4EA6-A127-F75F7F313B3B@anu.edu.au>
Message-ID: <20080427040623.GD1433@ms.unimelb.edu.au>

Hi John,

On Sun, Apr 27, 2008 at 01:47:40PM +1000, John Maindonald wrote:
> HI Andrew -
> Maybe you'd like to send this to the list.  I'd meant to send my
> reply to the list.

Ok, cc-ing the list.
 
> My understanding is that, in the usual definition, designs are
> hierarchical when they have a hierarchical error structure,
> irrespective of whether the fixed effects are hierarchical. From
> the Wikipedia article on hierachical linear models:
> "Multilevel analysis allows variance in outcome variables to be
> analysed at multiple hierarchical levels, whereas in simple linear
> and multiple linear regression all effects are modeled to occur at
> a single level. Thus, HLM is appropriate for use with nested data."
> 
> This is different from the database notion of a hierarchical data
> structure.

Sure, I agree.  But I don't think that this definition excludes
designs with crossed random effects from being hierarchical.

> The Behrens-Fisher type issue (really only an issue for one small
> relevant df, when the bounds for the p-value can be very wide)
> makes p-values, in general, somewhat fraught in the mult-level
> modeling context.  To get unique p-values, one has to make some
> assumption about bounds on the relevant relative variances.  In
> part for this sort of reason, I do not really care whether what comes
> from mcmcsamp() closely resembles one or other choice of
> p-value.

Can you point me to a citation for that issue?

Cheers

Andrew




> Cheers -
> John.
> 
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> 
> 
> On 27 Apr 2008, at 12:54 PM, Andrew Robinson wrote:
> 
> >Thanks John - and I have interpolated replies.
> >
> >On Sun, Apr 27, 2008 at 12:04:52PM +1000, John Maindonald wrote:
> >>I have interpolated a few comments.
> >>
> >>On 26 Apr 2008, at 5:59 PM, Andrew Robinson wrote:
> >>
> >>>Hi Mark,
> >>>
> >>>On Fri, Apr 25, 2008 at 11:53:24PM -0400, Mark Kimpel wrote:
> >>>>I am a bioinformatistician, with my strongest background in  
> >>>>molecular
> >>>>biology. I have been trying to learn about mixed-effects to improve
> >>>>the
> >>>>analysis of my experiments, which certainly contain random effects.
> >>>>I will
> >>>>admit to being totally lost in the discussions regarding lack of p-
> >>>>value
> >>>>reporting in the current versions of lmer. Furthermore, I suspect
> >>>>those that
> >>>>need to publish to non-statistical journals will face reviewers who
> >>>>are
> >>>>equally in the dark. Where can I find a biologist-level explanation
> >>>>of the
> >>>>current controversy,
> >>>
> >>>I'll take a stab.
> >>>
> >>>1) the traditional, Fisher-style test of a null hypothesis is  
> >>>based on
> >>>computing the probability of observing a test statistic as extreme
> >>>or more extreme than the one actually observed, assuming that the
> >>>null hypothesis is true.  This probability is called the p-value.
> >>>If the p-value is less than some cut-off, e.g. 0.01, then the null
> >>>hypothesis is rejected.
> >>>
> >>>2) in order to compute that p-value, we need to know the cumulative
> >>>distribution function of the test statistic when the null
> >>>hypothesis is true. In simple cases this is easy: for example, we
> >>>use the t-distribution for the comparison of two normal means (with
> >>>assumed equal variances etc).
> >>>
> >>>3) in (many) hierarchical models the cumulative distribution  
> >>>function
> >>>of the test statistic when the null hypothesis is true is simply not
> >>>known.  So, we can't compute the p-value.
> >>
> >>It can though be simulated.  If, though, the assumptions are
> >>seriously wrong, all bets are off.  In particular normality of
> >>effects seems to me a much more often serious issue than in most
> >>models with a simple independent and identically distributed error
> >>structure, just because there are commonly many fewer independent
> >>values at the level that matters for the intended generalization(s).
> >
> >Agreed.  In fact, in a follow-up to the original questioner I also
> >mentioned the parametric bootstrap.  That doesn't help with the
> >assumptions, however.
> >
> >>Moreover one can get plausible information about the posterior
> >>distribution of the parameters from mcmcsamp(), even a Bayesian
> >>equivalent of a p-value.
> >
> >I'm not sure about the relaibility of those p-values yet.
> >
> >>>3a) in a limited range of hierarchical models that have historically
> >>>dominated analysis of variance, e.g. split-plot designs, the
> >>>reference distribution is known (it's F).
> >>
> >>Or known more or less well.
> >
> >Yes.
> >
> >>>3b) Numerous experts have (quite reasonably) built up a bulwark of
> >>>intuitive knowledge about the analysis of such designs.
> >>>
> >>>3c) the intuition does not necessarily pertain to the analysis of  
> >>>any
> >>>arbitrary hierarchical design, which might be unbalanced, and have
> >>>crossed random effects.  That is, the intuition might be applied,
> >>>but inappropriately.
> >>
> >>If it has crossed random effects, it is not hierarchical.  This is  
> >>where
> >>the approximations are most likely to break down.
> >
> >I think that it's still hierarchical with cross effects.  We still
> >have observations nested within levels of random effects.
> >
> >>>4) in any case, the distribution that is intuitively or otherwise
> >>>assumed is the F, because it works in the cases mentioned in 3a.
> >>>All that remains is to define the degrees of freedom.  The
> >>>numerator degrees of freedom are obvious, but the denominator
> >>>degrees of freedom are not known.
> >>>
> >>>4a) numerous other packages supply approximations to the denominator
> >>>degrees of freedom, eg Satterthwaite, and KR (which is related).
> >>>They have been subjected to a modest degree of scrutiny by
> >>>simulation.
> >>>
> >>>5) however, it is not clear that the reference distribution is  
> >>>really
> >>>F at all, and therefore it is not clear that correcting the
> >>>denominator degrees of freedom is what is needed.  Confusion reigns
> >>>on how the p-values should be computed.  And because of this
> >>>confusion, Doug Bates declines to provide p-values.
> >>
> >>Simulation can provide a definitive answer, if one believes the  
> >>model.
> >>I do not think that Doug has any fundamental objection to giving the
> >>KR approximation.  He has, reasonably, had other priorities.
> >
> >Yes, these things are true.
> >
> >>Nor has anyone, so far, offered an algorithm that uses the lmer  
> >>output
> >>structures to implement the KR approximation.
> >
> >Doug and I are looking at it, but it's slow going because he's busy
> >and I'm - well - slow.
> >
> >>>>how can I learn how to properly judge significance from my lmer
> >>>>results,
> >>>
> >>>There are numerous approximations, but no way to properly judge
> >>>significance as far as I am aware.  Try the R-wiki for algorithms,  
> >>>and
> >>>be conservative.
> >>
> >>As indicated above, there are other mechanisms, safer in general than
> >>using an approximation.  Users have to work at them though.
> >
> >I think that those are still approximations, but of a different order.
> >
> >>Note also that, when tests have a numerator that is a linear  
> >>combination
> >>of variances, there can be issues of a Behrens-Fisher type (see, e.g.
> >>the Wikepedia Behrens-Fisher article), where it is impossible to  
> >>derive
> >>a p-value that is valid independent of the relative magnitudes of the
> >>unknown variances. The Behrens-Fisher approximation is though,
> >>usually, a reasonable compromise.
> >
> >I didn't know about that; thanks.
> >
> >>>http://wiki.r-project.org/rwiki/doku.php
> >>>
> >>>Or, use lme, report the p-values computed therein, and be aware that
> >>>they are not necessarily telling you exactly what you want to know.
> >>>
> >>>>and what peer-reviewed references can I steer reviewers
> >>>>towards?
> >>>
> >>>Not sure about that one.  I'm working on some simulations with Doug
> >>>but it's slow going, mainly because I'm chronically disorganised.
> >>>
> >>>>I understand, from other threads, that some believe a paradigm  
> >>>>shift
> >>>>away from p-values may be necessary, but I it is not clear to me
> >>>>what paradigm will replace this entrenced view. I can appreciate  
> >>>>the
> >>>>fact that there may be conflicting opinions about the best
> >>>>equations/algorithms for determining significance, but is there any
> >>>>agreement on the goal we are heading towards?
> >>>
> >>>The conflict is not about p-values per se, but about the way that  
> >>>they
> >>>are calculated.  I would bet that the joint goal is to find an
> >>>algorithm that provides robust, reasonable inference in a  
> >>>sufficiently
> >>>wide variety of cases that its implementation proves to be  
> >>>worthwhile.
> >>
> >>There is an argument about p-values per se,  One should, arguably, be
> >>examining the profile likelihood, or the whole of the posterior
> >>distribution.
> >
> >"arguably"  ... that is an argument!  :)
> >
> >Andrew
> >
> >-- 
> >Andrew Robinson
> >Department of Mathematics and Statistics            Tel:  
> >+61-3-8344-6410
> >University of Melbourne, VIC 3010 Australia         Fax:  
> >+61-3-8344-4599
> >http://www.ms.unimelb.edu.au/~andrewpr
> >http://blogs.mbs.edu/fishing-in-the-bay/

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From John.Maindonald at anu.edu.au  Sun Apr 27 09:27:50 2008
From: John.Maindonald at anu.edu.au (John Maindonald)
Date: Sun, 27 Apr 2008 17:27:50 +1000
Subject: [R-sig-ME] interpreting significance from lmer
	results	for	dummies (like me)
In-Reply-To: <20080427040623.GD1433@ms.unimelb.edu.au>
References: <6b93d1830804252053j5c264ae0u26d8e4c819d2b19@mail.gmail.com>
	<20080426075921.GM1945@ms.unimelb.edu.au>
	<081CD911-33D7-4C66-803D-89821C2A72DF@anu.edu.au>
	<20080427025413.GA1433@ms.unimelb.edu.au>
	<B4CB54E3-0C04-4EA6-A127-F75F7F313B3B@anu.edu.au>
	<20080427040623.GD1433@ms.unimelb.edu.au>
Message-ID: <6449187C-E4B1-49FF-BC50-70E20105EC06@anu.edu.au>

On Behrens-Fisher; see the Wikepedia article "Unsolved problems in  
statistics",
and references that are given there.

Linnik, Jurii (1968). Statistical Problems with Nuisance Parameters.
American Mathematical Society. ISBN 0821815709.

The link given to the

My reading of the literature is that this is not so much an unsolved
problem as one that has, within the p-value paradigm,  no satisfactory
theoretical solution.   I take this to be a problem with the p-value
paradigm.  For Bayesians there is no problem; all inference is
conditional on one or other choice of prior.  The various frequentist
"solutions" to the Behrens-Fisher problem involve one or other
more limited form of conditioning.

Others may be able to pronounce more authoritatively.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


On 27 Apr 2008, at 2:06 PM, Andrew Robinson wrote:

> Hi John,
>
> On Sun, Apr 27, 2008 at 01:47:40PM +1000, John Maindonald wrote:
>> HI Andrew -
>> Maybe you'd like to send this to the list.  I'd meant to send my
>> reply to the list.
>
> Ok, cc-ing the list.
>
>> My understanding is that, in the usual definition, designs are
>> hierarchical when they have a hierarchical error structure,
>> irrespective of whether the fixed effects are hierarchical. From
>> the Wikipedia article on hierachical linear models:
>> "Multilevel analysis allows variance in outcome variables to be
>> analysed at multiple hierarchical levels, whereas in simple linear
>> and multiple linear regression all effects are modeled to occur at
>> a single level. Thus, HLM is appropriate for use with nested data."
>>
>> This is different from the database notion of a hierarchical data
>> structure.
>
> Sure, I agree.  But I don't think that this definition excludes
> designs with crossed random effects from being hierarchical.
>
>> The Behrens-Fisher type issue (really only an issue for one small
>> relevant df, when the bounds for the p-value can be very wide)
>> makes p-values, in general, somewhat fraught in the mult-level
>> modeling context.  To get unique p-values, one has to make some
>> assumption about bounds on the relevant relative variances.  In
>> part for this sort of reason, I do not really care whether what comes
>> from mcmcsamp() closely resembles one or other choice of
>> p-value.
>
> Can you point me to a citation for that issue?
>
> Cheers
>
> Andrew
>
>
>
>
>> Cheers -
>> John.
>>
>> John Maindonald             email: john.maindonald at anu.edu.au
>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>> Centre for Mathematics & Its Applications, Room 1194,
>> John Dedman Mathematical Sciences Building (Building 27)
>> Australian National University, Canberra ACT 0200.
>>
>>
>> On 27 Apr 2008, at 12:54 PM, Andrew Robinson wrote:
>>
>>> Thanks John - and I have interpolated replies.
>>>
>>> On Sun, Apr 27, 2008 at 12:04:52PM +1000, John Maindonald wrote:
>>>> I have interpolated a few comments.
>>>>
>>>> On 26 Apr 2008, at 5:59 PM, Andrew Robinson wrote:
>>>>
>>>>> Hi Mark,
>>>>>
>>>>> On Fri, Apr 25, 2008 at 11:53:24PM -0400, Mark Kimpel wrote:
>>>>>> I am a bioinformatistician, with my strongest background in
>>>>>> molecular
>>>>>> biology. I have been trying to learn about mixed-effects to  
>>>>>> improve
>>>>>> the
>>>>>> analysis of my experiments, which certainly contain random  
>>>>>> effects.
>>>>>> I will
>>>>>> admit to being totally lost in the discussions regarding lack  
>>>>>> of p-
>>>>>> value
>>>>>> reporting in the current versions of lmer. Furthermore, I suspect
>>>>>> those that
>>>>>> need to publish to non-statistical journals will face reviewers  
>>>>>> who
>>>>>> are
>>>>>> equally in the dark. Where can I find a biologist-level  
>>>>>> explanation
>>>>>> of the
>>>>>> current controversy,
>>>>>
>>>>> I'll take a stab.
>>>>>
>>>>> 1) the traditional, Fisher-style test of a null hypothesis is
>>>>> based on
>>>>> computing the probability of observing a test statistic as extreme
>>>>> or more extreme than the one actually observed, assuming that the
>>>>> null hypothesis is true.  This probability is called the p-value.
>>>>> If the p-value is less than some cut-off, e.g. 0.01, then the null
>>>>> hypothesis is rejected.
>>>>>
>>>>> 2) in order to compute that p-value, we need to know the  
>>>>> cumulative
>>>>> distribution function of the test statistic when the null
>>>>> hypothesis is true. In simple cases this is easy: for example, we
>>>>> use the t-distribution for the comparison of two normal means  
>>>>> (with
>>>>> assumed equal variances etc).
>>>>>
>>>>> 3) in (many) hierarchical models the cumulative distribution
>>>>> function
>>>>> of the test statistic when the null hypothesis is true is simply  
>>>>> not
>>>>> known.  So, we can't compute the p-value.
>>>>
>>>> It can though be simulated.  If, though, the assumptions are
>>>> seriously wrong, all bets are off.  In particular normality of
>>>> effects seems to me a much more often serious issue than in most
>>>> models with a simple independent and identically distributed error
>>>> structure, just because there are commonly many fewer independent
>>>> values at the level that matters for the intended  
>>>> generalization(s).
>>>
>>> Agreed.  In fact, in a follow-up to the original questioner I also
>>> mentioned the parametric bootstrap.  That doesn't help with the
>>> assumptions, however.
>>>
>>>> Moreover one can get plausible information about the posterior
>>>> distribution of the parameters from mcmcsamp(), even a Bayesian
>>>> equivalent of a p-value.
>>>
>>> I'm not sure about the relaibility of those p-values yet.
>>>
>>>>> 3a) in a limited range of hierarchical models that have  
>>>>> historically
>>>>> dominated analysis of variance, e.g. split-plot designs, the
>>>>> reference distribution is known (it's F).
>>>>
>>>> Or known more or less well.
>>>
>>> Yes.
>>>
>>>>> 3b) Numerous experts have (quite reasonably) built up a bulwark of
>>>>> intuitive knowledge about the analysis of such designs.
>>>>>
>>>>> 3c) the intuition does not necessarily pertain to the analysis of
>>>>> any
>>>>> arbitrary hierarchical design, which might be unbalanced, and have
>>>>> crossed random effects.  That is, the intuition might be applied,
>>>>> but inappropriately.
>>>>
>>>> If it has crossed random effects, it is not hierarchical.  This is
>>>> where
>>>> the approximations are most likely to break down.
>>>
>>> I think that it's still hierarchical with cross effects.  We still
>>> have observations nested within levels of random effects.
>>>
>>>>> 4) in any case, the distribution that is intuitively or otherwise
>>>>> assumed is the F, because it works in the cases mentioned in 3a.
>>>>> All that remains is to define the degrees of freedom.  The
>>>>> numerator degrees of freedom are obvious, but the denominator
>>>>> degrees of freedom are not known.
>>>>>
>>>>> 4a) numerous other packages supply approximations to the  
>>>>> denominator
>>>>> degrees of freedom, eg Satterthwaite, and KR (which is related).
>>>>> They have been subjected to a modest degree of scrutiny by
>>>>> simulation.
>>>>>
>>>>> 5) however, it is not clear that the reference distribution is
>>>>> really
>>>>> F at all, and therefore it is not clear that correcting the
>>>>> denominator degrees of freedom is what is needed.  Confusion  
>>>>> reigns
>>>>> on how the p-values should be computed.  And because of this
>>>>> confusion, Doug Bates declines to provide p-values.
>>>>
>>>> Simulation can provide a definitive answer, if one believes the
>>>> model.
>>>> I do not think that Doug has any fundamental objection to giving  
>>>> the
>>>> KR approximation.  He has, reasonably, had other priorities.
>>>
>>> Yes, these things are true.
>>>
>>>> Nor has anyone, so far, offered an algorithm that uses the lmer
>>>> output
>>>> structures to implement the KR approximation.
>>>
>>> Doug and I are looking at it, but it's slow going because he's busy
>>> and I'm - well - slow.
>>>
>>>>>> how can I learn how to properly judge significance from my lmer
>>>>>> results,
>>>>>
>>>>> There are numerous approximations, but no way to properly judge
>>>>> significance as far as I am aware.  Try the R-wiki for algorithms,
>>>>> and
>>>>> be conservative.
>>>>
>>>> As indicated above, there are other mechanisms, safer in general  
>>>> than
>>>> using an approximation.  Users have to work at them though.
>>>
>>> I think that those are still approximations, but of a different  
>>> order.
>>>
>>>> Note also that, when tests have a numerator that is a linear
>>>> combination
>>>> of variances, there can be issues of a Behrens-Fisher type (see,  
>>>> e.g.
>>>> the Wikepedia Behrens-Fisher article), where it is impossible to
>>>> derive
>>>> a p-value that is valid independent of the relative magnitudes of  
>>>> the
>>>> unknown variances. The Behrens-Fisher approximation is though,
>>>> usually, a reasonable compromise.
>>>
>>> I didn't know about that; thanks.
>>>
>>>>> http://wiki.r-project.org/rwiki/doku.php
>>>>>
>>>>> Or, use lme, report the p-values computed therein, and be aware  
>>>>> that
>>>>> they are not necessarily telling you exactly what you want to  
>>>>> know.
>>>>>
>>>>>> and what peer-reviewed references can I steer reviewers
>>>>>> towards?
>>>>>
>>>>> Not sure about that one.  I'm working on some simulations with  
>>>>> Doug
>>>>> but it's slow going, mainly because I'm chronically disorganised.
>>>>>
>>>>>> I understand, from other threads, that some believe a paradigm
>>>>>> shift
>>>>>> away from p-values may be necessary, but I it is not clear to me
>>>>>> what paradigm will replace this entrenced view. I can appreciate
>>>>>> the
>>>>>> fact that there may be conflicting opinions about the best
>>>>>> equations/algorithms for determining significance, but is there  
>>>>>> any
>>>>>> agreement on the goal we are heading towards?
>>>>>
>>>>> The conflict is not about p-values per se, but about the way that
>>>>> they
>>>>> are calculated.  I would bet that the joint goal is to find an
>>>>> algorithm that provides robust, reasonable inference in a
>>>>> sufficiently
>>>>> wide variety of cases that its implementation proves to be
>>>>> worthwhile.
>>>>
>>>> There is an argument about p-values per se,  One should,  
>>>> arguably, be
>>>> examining the profile likelihood, or the whole of the posterior
>>>> distribution.
>>>
>>> "arguably"  ... that is an argument!  :)
>>>
>>> Andrew
>>>
>>> -- 
>>> Andrew Robinson
>>> Department of Mathematics and Statistics            Tel:
>>> +61-3-8344-6410
>>> University of Melbourne, VIC 3010 Australia         Fax:
>>> +61-3-8344-4599
>>> http://www.ms.unimelb.edu.au/~andrewpr
>>> http://blogs.mbs.edu/fishing-in-the-bay/
>
> -- 
> Andrew Robinson
> Department of Mathematics and Statistics            Tel:  
> +61-3-8344-6410
> University of Melbourne, VIC 3010 Australia         Fax:  
> +61-3-8344-4599
> http://www.ms.unimelb.edu.au/~andrewpr
> http://blogs.mbs.edu/fishing-in-the-bay/
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From kubovy at virginia.edu  Sun Apr 27 16:49:07 2008
From: kubovy at virginia.edu (Michael Kubovy)
Date: Sun, 27 Apr 2008 10:49:07 -0400
Subject: [R-sig-ME] Proper analysis for the Machines dataset in lme4
Message-ID: <9BA7966D-F3F1-4CCB-9E82-41A6C154195D@virginia.edu>

Dear Mixed Ones,

While waiting for Doug Bates's book, I'm trying trying to understand  
the differences between the recommendations of Pinheiro & Bates using  
the nlme packages, and the use of lmer in the lme4 package. I've  
gotten myself confused.

#because lme4 and nlme sometimes clash:
detach('package:lme4')
require(nlme)
data(Machines)
mach <- Machines
# Machines and Workers are balanced
with(mach, table(Machine, Worker))
# Here is how it's analyzed in Pinheiro & Bates
m1 <- lme(score ~ Machine, data = mach, random = ~ 1 | Worker)
m2 <- update(m1, random = ~ 1 | Worker / Machine)
anova(m1, m2)
# Back to lme4
detach('package:nlme')
require(lme4)
mr1 <-  lmer(score ~ Machine + (1 | Worker), data = mach)
mr2 <- update(mr1, . ~ Machine + (1 | Worker / Machine))
mr3 <- update(mr1, . ~ Machine + (1 + Machine | Worker))
anova(mr1, mr2, mr3)

require(gmodels)
options(digits = 3)
set.seed(20080427)
zapsmall(ci(m2))
zapsmall(ci(mr2, sim.lmer = T, n.sim = 10000))
# The following produces SEs an order of magnitude larger ci(mr2)
zapsmall(ci(mr3, sim.lmer = T, n.sim = 10000))

# From this it would seem that mr2 is the proper model.
# But I have never seen a crossed design written that way in lme4.

# Another example:
# Baayen (in the page proofs of Analyzing Linguistic Data:
# A practical introduction to statistics, p. 283) takes an example from
# Raaijmakers, J. G. W.; Schrijnemakers, J. M. C. & Gremmen, F.
# How to Deal with ``The Language-as-Fixed-Effect Fallacy'':
# Common Misconceptions and Alternative Solutions
# Journal of Memory and Language, 1999, 41, 416-426

subj <- factor(rep(paste('S', 1:8, sep = ''), each = 8))
item <- factor(rep(paste('W', 1:8, sep = ''), 8))
soa <- factor(rep(c("Short", "Long"), each = 4, 8))
rt <- c(
546, 567, 547, 566, 554, 545, 594, 522,
566, 556, 538, 566, 512, 523, 569, 524,
567, 598, 568, 584, 536, 539, 589, 521,
556, 565, 536, 550, 516, 522, 560, 486,
595, 609, 585, 588, 578, 540, 615, 546,
569, 578, 560, 583, 501, 535, 568, 514,
527, 554, 535, 527, 480, 467, 540, 473,
551, 575, 558, 556, 588, 563, 631, 558)
sp <- data.frame(subj = subj, item = item, soa = soa, rt = rt)

# soa and subj are crossed.
with(sp, table(subj, item))
# item and subj also
with(sp, table(subj, soa))
# items nested under soa
with(sp, table(item, soa))
# pr2 is analogous to m2 and mr2
pr2 <- lmer(rt ~ soa + (1 | subj / soa) + (1 | item), sp)
# pr3 is analogous to m3 and mr3 This is how Baayen analyzes it
# (the results aren't identical to his; I don't know why):
pr3 <- lmer(rt ~ soa + (1 + soa | subj) + (1 | item), sp)
ci(pr2, sim.lmer = TRUE, n.sim = 10000)
ci(pr3, sim.lmer = TRUE, n.sim = 10000)
cm <- unique(model.matrix(~ soa, sp))
estimable(pr2, cm = cm, sim.lmer = TRUE, n.sim = 10000, conf.int = 0.95)
estimable(pr3, cm = cm, sim.lmer = TRUE, n.sim = 10000, conf.int = 0.95)

_____________________________
Professor Michael Kubovy
University of Virginia
Department of Psychology
USPS:     P.O.Box 400400    Charlottesville, VA 22904-4400
Parcels:    Room 102        Gilmer Hall
         McCormick Road    Charlottesville, VA 22903
Office:    B011    +1-434-982-4729
Lab:        B019    +1-434-982-4751
Fax:        +1-434-982-4766
WWW:    http://www.people.virginia.edu/~mk9y/



From reinhold.kliegl at gmail.com  Mon Apr 28 08:38:17 2008
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Mon, 28 Apr 2008 08:38:17 +0200
Subject: [R-sig-ME] Proper analysis for the Machines dataset in lme4
In-Reply-To: <9BA7966D-F3F1-4CCB-9E82-41A6C154195D@virginia.edu>
References: <9BA7966D-F3F1-4CCB-9E82-41A6C154195D@virginia.edu>
Message-ID: <aefe4d0a0804272338u4ddff37age8193c6c0b6ed710@mail.gmail.com>

Dear Michael,

I just want to prevent a misreading of some of your comments. As far
as m1 vs mr1 and m2 vs. m2r are concerned, lme and lmer produce
identical estimates for fixed and random effects. The anova(m1, m2)
and anova(m1r, m2r)  also produce identical results, if you use
method="ML".  Crossed-random effects are not easily specified in lme,
but in principle they can. So it is not correct to say that they clash
on m3 and m3r either.

The comparison of m1 and m2 (or m1r and m2r) is conceptually
questionable. m1 assumes there are 6 Workers; m2 assumes that there
are 18 Workers, that is different groups of 6 persons worked on each
of the 3 machines. Presumably, the experimental design decides whether
m1 (m1r) or m2 (m2r) is the correct choice.
     There is a meaningful comparison between m3r and m1r. If m3r is
significantly better it means that the six workers differ reliably not
only in mean performance (intercept) but also in the size of the
machine effect (i.e., there is reliable variance in Machine effects
between Worker). They actually do:

> anova(mr1, mr3)
Data: mach
Models:
mr1: score ~ Machine + (1 | Worker)
mr3: score ~ Machine + (Machine | Worker)
      Df     AIC     BIC  logLik  Chisq Chi Df Pr(>Chisq)
mr1.p  5  303.70  313.65 -146.85
mr3.p 10  236.42  256.31 -108.21 77.285      5    3.1e-15 ***

Thus, if m1 is the correct design, then m3 is an improvement. If m2 is
the correct design, then that is it.

The Baayen example did not involve a comparison between lme and lmer,
as far as I could see.

I do not know much about gmodels. So I leave this part to somebody else.

Best
Reinhold


On Sun, Apr 27, 2008 at 4:49 PM, Michael Kubovy <kubovy at virginia.edu> wrote:
> Dear Mixed Ones,
>
>  While waiting for Doug Bates's book, I'm trying trying to understand
>  the differences between the recommendations of Pinheiro & Bates using
>  the nlme packages, and the use of lmer in the lme4 package. I've
>  gotten myself confused.
>
>  #because lme4 and nlme sometimes clash:
>  detach('package:lme4')
>  require(nlme)
>  data(Machines)
>  mach <- Machines
>  # Machines and Workers are balanced
>  with(mach, table(Machine, Worker))
>  # Here is how it's analyzed in Pinheiro & Bates
>  m1 <- lme(score ~ Machine, data = mach, random = ~ 1 | Worker)
>  m2 <- update(m1, random = ~ 1 | Worker / Machine)
>  anova(m1, m2)
>  # Back to lme4
>  detach('package:nlme')
>  require(lme4)
>  mr1 <-  lmer(score ~ Machine + (1 | Worker), data = mach)
>  mr2 <- update(mr1, . ~ Machine + (1 | Worker / Machine))
>  mr3 <- update(mr1, . ~ Machine + (1 + Machine | Worker))
>  anova(mr1, mr2, mr3)
>
>  require(gmodels)
>  options(digits = 3)
>  set.seed(20080427)
>  zapsmall(ci(m2))
>  zapsmall(ci(mr2, sim.lmer = T, n.sim = 10000))
>  # The following produces SEs an order of magnitude larger ci(mr2)
>  zapsmall(ci(mr3, sim.lmer = T, n.sim = 10000))
>
>  # From this it would seem that mr2 is the proper model.
>  # But I have never seen a crossed design written that way in lme4.
>
>  # Another example:
>  # Baayen (in the page proofs of Analyzing Linguistic Data:
>  # A practical introduction to statistics, p. 283) takes an example from
>  # Raaijmakers, J. G. W.; Schrijnemakers, J. M. C. & Gremmen, F.
>  # How to Deal with ``The Language-as-Fixed-Effect Fallacy'':
>  # Common Misconceptions and Alternative Solutions
>  # Journal of Memory and Language, 1999, 41, 416-426
>
>  subj <- factor(rep(paste('S', 1:8, sep = ''), each = 8))
>  item <- factor(rep(paste('W', 1:8, sep = ''), 8))
>  soa <- factor(rep(c("Short", "Long"), each = 4, 8))
>  rt <- c(
>  546, 567, 547, 566, 554, 545, 594, 522,
>  566, 556, 538, 566, 512, 523, 569, 524,
>  567, 598, 568, 584, 536, 539, 589, 521,
>  556, 565, 536, 550, 516, 522, 560, 486,
>  595, 609, 585, 588, 578, 540, 615, 546,
>  569, 578, 560, 583, 501, 535, 568, 514,
>  527, 554, 535, 527, 480, 467, 540, 473,
>  551, 575, 558, 556, 588, 563, 631, 558)
>  sp <- data.frame(subj = subj, item = item, soa = soa, rt = rt)
>
>  # soa and subj are crossed.
>  with(sp, table(subj, item))
>  # item and subj also
>  with(sp, table(subj, soa))
>  # items nested under soa
>  with(sp, table(item, soa))
>  # pr2 is analogous to m2 and mr2
>  pr2 <- lmer(rt ~ soa + (1 | subj / soa) + (1 | item), sp)
>  # pr3 is analogous to m3 and mr3 This is how Baayen analyzes it
>  # (the results aren't identical to his; I don't know why):
>  pr3 <- lmer(rt ~ soa + (1 + soa | subj) + (1 | item), sp)
>  ci(pr2, sim.lmer = TRUE, n.sim = 10000)
>  ci(pr3, sim.lmer = TRUE, n.sim = 10000)
>  cm <- unique(model.matrix(~ soa, sp))
>  estimable(pr2, cm = cm, sim.lmer = TRUE, n.sim = 10000, conf.int = 0.95)
>  estimable(pr3, cm = cm, sim.lmer = TRUE, n.sim = 10000, conf.int = 0.95)
>
>  _____________________________
>  Professor Michael Kubovy
>  University of Virginia
>  Department of Psychology
>  USPS:     P.O.Box 400400    Charlottesville, VA 22904-4400
>  Parcels:    Room 102        Gilmer Hall
>          McCormick Road    Charlottesville, VA 22903
>  Office:    B011    +1-434-982-4729
>  Lab:        B019    +1-434-982-4751
>  Fax:        +1-434-982-4766
>  WWW:    http://www.people.virginia.edu/~mk9y/
>
>  _______________________________________________
>  R-sig-mixed-models at r-project.org mailing list
>  https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From A.Robinson at ms.unimelb.edu.au  Mon Apr 28 11:02:58 2008
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Mon, 28 Apr 2008 19:02:58 +1000
Subject: [R-sig-ME] interpreting significance from lmer
	results	for	dummies (like me)
In-Reply-To: <6449187C-E4B1-49FF-BC50-70E20105EC06@anu.edu.au>
References: <6b93d1830804252053j5c264ae0u26d8e4c819d2b19@mail.gmail.com>
	<20080426075921.GM1945@ms.unimelb.edu.au>
	<081CD911-33D7-4C66-803D-89821C2A72DF@anu.edu.au>
	<20080427025413.GA1433@ms.unimelb.edu.au>
	<B4CB54E3-0C04-4EA6-A127-F75F7F313B3B@anu.edu.au>
	<20080427040623.GD1433@ms.unimelb.edu.au>
	<6449187C-E4B1-49FF-BC50-70E20105EC06@anu.edu.au>
Message-ID: <20080428090258.GT1433@ms.unimelb.edu.au>

Thanks John - very interesting stuff!

Andrew

On Sun, Apr 27, 2008 at 05:27:50PM +1000, John Maindonald wrote:
> On Behrens-Fisher; see the Wikepedia article "Unsolved problems in  
> statistics",
> and references that are given there.
> 
> Linnik, Jurii (1968). Statistical Problems with Nuisance Parameters.
> American Mathematical Society. ISBN 0821815709.
> 
> The link given to the
> 
> My reading of the literature is that this is not so much an unsolved
> problem as one that has, within the p-value paradigm,  no satisfactory
> theoretical solution.   I take this to be a problem with the p-value
> paradigm.  For Bayesians there is no problem; all inference is
> conditional on one or other choice of prior.  The various frequentist
> "solutions" to the Behrens-Fisher problem involve one or other
> more limited form of conditioning.
> 
> Others may be able to pronounce more authoritatively.
> 
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> 
> 
> On 27 Apr 2008, at 2:06 PM, Andrew Robinson wrote:
> 
> >Hi John,
> >
> >On Sun, Apr 27, 2008 at 01:47:40PM +1000, John Maindonald wrote:
> >>HI Andrew -
> >>Maybe you'd like to send this to the list.  I'd meant to send my
> >>reply to the list.
> >
> >Ok, cc-ing the list.
> >
> >>My understanding is that, in the usual definition, designs are
> >>hierarchical when they have a hierarchical error structure,
> >>irrespective of whether the fixed effects are hierarchical. From
> >>the Wikipedia article on hierachical linear models:
> >>"Multilevel analysis allows variance in outcome variables to be
> >>analysed at multiple hierarchical levels, whereas in simple linear
> >>and multiple linear regression all effects are modeled to occur at
> >>a single level. Thus, HLM is appropriate for use with nested data."
> >>
> >>This is different from the database notion of a hierarchical data
> >>structure.
> >
> >Sure, I agree.  But I don't think that this definition excludes
> >designs with crossed random effects from being hierarchical.
> >
> >>The Behrens-Fisher type issue (really only an issue for one small
> >>relevant df, when the bounds for the p-value can be very wide)
> >>makes p-values, in general, somewhat fraught in the mult-level
> >>modeling context.  To get unique p-values, one has to make some
> >>assumption about bounds on the relevant relative variances.  In
> >>part for this sort of reason, I do not really care whether what comes
> >>from mcmcsamp() closely resembles one or other choice of
> >>p-value.
> >
> >Can you point me to a citation for that issue?
> >
> >Cheers
> >
> >Andrew
> >
> >
> >
> >
> >>Cheers -
> >>John.
> >>
> >>John Maindonald             email: john.maindonald at anu.edu.au
> >>phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> >>Centre for Mathematics & Its Applications, Room 1194,
> >>John Dedman Mathematical Sciences Building (Building 27)
> >>Australian National University, Canberra ACT 0200.
> >>
> >>
> >>On 27 Apr 2008, at 12:54 PM, Andrew Robinson wrote:
> >>
> >>>Thanks John - and I have interpolated replies.
> >>>
> >>>On Sun, Apr 27, 2008 at 12:04:52PM +1000, John Maindonald wrote:
> >>>>I have interpolated a few comments.
> >>>>
> >>>>On 26 Apr 2008, at 5:59 PM, Andrew Robinson wrote:
> >>>>
> >>>>>Hi Mark,
> >>>>>
> >>>>>On Fri, Apr 25, 2008 at 11:53:24PM -0400, Mark Kimpel wrote:
> >>>>>>I am a bioinformatistician, with my strongest background in
> >>>>>>molecular
> >>>>>>biology. I have been trying to learn about mixed-effects to  
> >>>>>>improve
> >>>>>>the
> >>>>>>analysis of my experiments, which certainly contain random  
> >>>>>>effects.
> >>>>>>I will
> >>>>>>admit to being totally lost in the discussions regarding lack  
> >>>>>>of p-
> >>>>>>value
> >>>>>>reporting in the current versions of lmer. Furthermore, I suspect
> >>>>>>those that
> >>>>>>need to publish to non-statistical journals will face reviewers  
> >>>>>>who
> >>>>>>are
> >>>>>>equally in the dark. Where can I find a biologist-level  
> >>>>>>explanation
> >>>>>>of the
> >>>>>>current controversy,
> >>>>>
> >>>>>I'll take a stab.
> >>>>>
> >>>>>1) the traditional, Fisher-style test of a null hypothesis is
> >>>>>based on
> >>>>>computing the probability of observing a test statistic as extreme
> >>>>>or more extreme than the one actually observed, assuming that the
> >>>>>null hypothesis is true.  This probability is called the p-value.
> >>>>>If the p-value is less than some cut-off, e.g. 0.01, then the null
> >>>>>hypothesis is rejected.
> >>>>>
> >>>>>2) in order to compute that p-value, we need to know the  
> >>>>>cumulative
> >>>>>distribution function of the test statistic when the null
> >>>>>hypothesis is true. In simple cases this is easy: for example, we
> >>>>>use the t-distribution for the comparison of two normal means  
> >>>>>(with
> >>>>>assumed equal variances etc).
> >>>>>
> >>>>>3) in (many) hierarchical models the cumulative distribution
> >>>>>function
> >>>>>of the test statistic when the null hypothesis is true is simply  
> >>>>>not
> >>>>>known.  So, we can't compute the p-value.
> >>>>
> >>>>It can though be simulated.  If, though, the assumptions are
> >>>>seriously wrong, all bets are off.  In particular normality of
> >>>>effects seems to me a much more often serious issue than in most
> >>>>models with a simple independent and identically distributed error
> >>>>structure, just because there are commonly many fewer independent
> >>>>values at the level that matters for the intended  
> >>>>generalization(s).
> >>>
> >>>Agreed.  In fact, in a follow-up to the original questioner I also
> >>>mentioned the parametric bootstrap.  That doesn't help with the
> >>>assumptions, however.
> >>>
> >>>>Moreover one can get plausible information about the posterior
> >>>>distribution of the parameters from mcmcsamp(), even a Bayesian
> >>>>equivalent of a p-value.
> >>>
> >>>I'm not sure about the relaibility of those p-values yet.
> >>>
> >>>>>3a) in a limited range of hierarchical models that have  
> >>>>>historically
> >>>>>dominated analysis of variance, e.g. split-plot designs, the
> >>>>>reference distribution is known (it's F).
> >>>>
> >>>>Or known more or less well.
> >>>
> >>>Yes.
> >>>
> >>>>>3b) Numerous experts have (quite reasonably) built up a bulwark of
> >>>>>intuitive knowledge about the analysis of such designs.
> >>>>>
> >>>>>3c) the intuition does not necessarily pertain to the analysis of
> >>>>>any
> >>>>>arbitrary hierarchical design, which might be unbalanced, and have
> >>>>>crossed random effects.  That is, the intuition might be applied,
> >>>>>but inappropriately.
> >>>>
> >>>>If it has crossed random effects, it is not hierarchical.  This is
> >>>>where
> >>>>the approximations are most likely to break down.
> >>>
> >>>I think that it's still hierarchical with cross effects.  We still
> >>>have observations nested within levels of random effects.
> >>>
> >>>>>4) in any case, the distribution that is intuitively or otherwise
> >>>>>assumed is the F, because it works in the cases mentioned in 3a.
> >>>>>All that remains is to define the degrees of freedom.  The
> >>>>>numerator degrees of freedom are obvious, but the denominator
> >>>>>degrees of freedom are not known.
> >>>>>
> >>>>>4a) numerous other packages supply approximations to the  
> >>>>>denominator
> >>>>>degrees of freedom, eg Satterthwaite, and KR (which is related).
> >>>>>They have been subjected to a modest degree of scrutiny by
> >>>>>simulation.
> >>>>>
> >>>>>5) however, it is not clear that the reference distribution is
> >>>>>really
> >>>>>F at all, and therefore it is not clear that correcting the
> >>>>>denominator degrees of freedom is what is needed.  Confusion  
> >>>>>reigns
> >>>>>on how the p-values should be computed.  And because of this
> >>>>>confusion, Doug Bates declines to provide p-values.
> >>>>
> >>>>Simulation can provide a definitive answer, if one believes the
> >>>>model.
> >>>>I do not think that Doug has any fundamental objection to giving  
> >>>>the
> >>>>KR approximation.  He has, reasonably, had other priorities.
> >>>
> >>>Yes, these things are true.
> >>>
> >>>>Nor has anyone, so far, offered an algorithm that uses the lmer
> >>>>output
> >>>>structures to implement the KR approximation.
> >>>
> >>>Doug and I are looking at it, but it's slow going because he's busy
> >>>and I'm - well - slow.
> >>>
> >>>>>>how can I learn how to properly judge significance from my lmer
> >>>>>>results,
> >>>>>
> >>>>>There are numerous approximations, but no way to properly judge
> >>>>>significance as far as I am aware.  Try the R-wiki for algorithms,
> >>>>>and
> >>>>>be conservative.
> >>>>
> >>>>As indicated above, there are other mechanisms, safer in general  
> >>>>than
> >>>>using an approximation.  Users have to work at them though.
> >>>
> >>>I think that those are still approximations, but of a different  
> >>>order.
> >>>
> >>>>Note also that, when tests have a numerator that is a linear
> >>>>combination
> >>>>of variances, there can be issues of a Behrens-Fisher type (see,  
> >>>>e.g.
> >>>>the Wikepedia Behrens-Fisher article), where it is impossible to
> >>>>derive
> >>>>a p-value that is valid independent of the relative magnitudes of  
> >>>>the
> >>>>unknown variances. The Behrens-Fisher approximation is though,
> >>>>usually, a reasonable compromise.
> >>>
> >>>I didn't know about that; thanks.
> >>>
> >>>>>http://wiki.r-project.org/rwiki/doku.php
> >>>>>
> >>>>>Or, use lme, report the p-values computed therein, and be aware  
> >>>>>that
> >>>>>they are not necessarily telling you exactly what you want to  
> >>>>>know.
> >>>>>
> >>>>>>and what peer-reviewed references can I steer reviewers
> >>>>>>towards?
> >>>>>
> >>>>>Not sure about that one.  I'm working on some simulations with  
> >>>>>Doug
> >>>>>but it's slow going, mainly because I'm chronically disorganised.
> >>>>>
> >>>>>>I understand, from other threads, that some believe a paradigm
> >>>>>>shift
> >>>>>>away from p-values may be necessary, but I it is not clear to me
> >>>>>>what paradigm will replace this entrenced view. I can appreciate
> >>>>>>the
> >>>>>>fact that there may be conflicting opinions about the best
> >>>>>>equations/algorithms for determining significance, but is there  
> >>>>>>any
> >>>>>>agreement on the goal we are heading towards?
> >>>>>
> >>>>>The conflict is not about p-values per se, but about the way that
> >>>>>they
> >>>>>are calculated.  I would bet that the joint goal is to find an
> >>>>>algorithm that provides robust, reasonable inference in a
> >>>>>sufficiently
> >>>>>wide variety of cases that its implementation proves to be
> >>>>>worthwhile.
> >>>>
> >>>>There is an argument about p-values per se,  One should,  
> >>>>arguably, be
> >>>>examining the profile likelihood, or the whole of the posterior
> >>>>distribution.
> >>>
> >>>"arguably"  ... that is an argument!  :)
> >>>
> >>>Andrew
> >>>
> >>>-- 
> >>>Andrew Robinson
> >>>Department of Mathematics and Statistics            Tel:
> >>>+61-3-8344-6410
> >>>University of Melbourne, VIC 3010 Australia         Fax:
> >>>+61-3-8344-4599
> >>>http://www.ms.unimelb.edu.au/~andrewpr
> >>>http://blogs.mbs.edu/fishing-in-the-bay/
> >
> >-- 
> >Andrew Robinson
> >Department of Mathematics and Statistics            Tel:  
> >+61-3-8344-6410
> >University of Melbourne, VIC 3010 Australia         Fax:  
> >+61-3-8344-4599
> >http://www.ms.unimelb.edu.au/~andrewpr
> >http://blogs.mbs.edu/fishing-in-the-bay/
> >
> >_______________________________________________
> >R-sig-mixed-models at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From njbisaac at googlemail.com  Mon Apr 28 12:01:36 2008
From: njbisaac at googlemail.com (Nick Isaac)
Date: Mon, 28 Apr 2008 11:01:36 +0100
Subject: [R-sig-ME] interpreting significance from lmer results for
	dummies (like me)
In-Reply-To: <6b93d1830804252053j5c264ae0u26d8e4c819d2b19@mail.gmail.com>
References: <6b93d1830804252053j5c264ae0u26d8e4c819d2b19@mail.gmail.com>
Message-ID: <a072ed700804280301l78179c5fl891dd11d404000e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080428/73f127e7/attachment.pl>

From bates at stat.wisc.edu  Mon Apr 28 14:34:08 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 28 Apr 2008 07:34:08 -0500
Subject: [R-sig-ME] iteration limit reached without convergence
In-Reply-To: <aa4ca20bdcea266bcc19dfd6390b0f00@ling.ucsd.edu>
References: <aa4ca20bdcea266bcc19dfd6390b0f00@ling.ucsd.edu>
Message-ID: <40e66e0b0804280534w1617967btdce9f35bd1d21fa7@mail.gmail.com>

On 4/26/08, Gabe Doyle <gdoyle at ling.ucsd.edu> wrote:
> Dear mixed modellers,

>  I am running some mixed-effects logit models that seem to fail to converge,
>  as evidenced by the warning message:

>  In mer_finalize(ans, verbose) :
>  iteration limit reached without convergence (9)

Typically that is a symptom of a model that is over-specified.  Did
you try setting verbose = TRUE and checking what was happening to the
parameter estimates as they went through the iterations?  I mention
this because there is a tendency to specify models with every possible
covariate in the fixed effects and optimization of such models is
often difficult.  I don't want to make assumptions without having seen
the model and the data to which you are fitting it but my first
approach would be to simplify the model.

I suppose I should activate options in the development version of lme4
to set the maximum number of iterations.  One of the problems with
doing so is that it is not just a matter of the maximum number of
iterations.  One also needs to set the maximum number of function
evaluations.  If there are many parameters being optimized
simultaneously then the number of function evaluations can be much
larger than the number of iterations.

>  In the CRAN version of lme4, it is possible to specify the maximum number
>  of iterations used by nlminb while estimating model parameters, by passing
>  the parameter control=list(msMaxIter=N) in to lmer. However, this doesn't
>  seem to work with the R-Forge version. Is there a way of controlling the
>  iteration limit in the R-Forge version that I'm overlooking?
>
>  Much obliged,
>  Gabe Doyle
>
>  _______________________________________________
>  R-sig-mixed-models at r-project.org mailing list
>  https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From spluque at gmail.com  Mon Apr 28 19:11:16 2008
From: spluque at gmail.com (Sebastian P. Luque)
Date: Mon, 28 Apr 2008 12:11:16 -0500
Subject: [R-sig-ME] method dispatch conflict?
Message-ID: <87prs9j45n.fsf@patagonia.sebmags.homelinux.org>

Hi,

I vaguely recall this was discussed in the past, but I cannot remember
the context.  The code below shows the problem:


---<---------------cut here---------------start-------------->---
R> library(stats4)
R> library(lme4)
Loading required package: Matrix

Attaching package: 'Matrix'


        The following object(s) are masked from package:stats :

         xtabs


Attaching package: 'lme4'


        The following object(s) are masked from package:stats4 :

         BIC

Warning messages:
1: In namespaceImportFrom(self, asNamespace(ns)) :
  replacing previous import: cov2cor
2: In namespaceImportFrom(self, asNamespace(ns)) :
  replacing previous import: update
3: In namespaceImportFrom(self, asNamespace(ns)) :
  replacing previous import: xtabs
R> example
example
R> example(lmer)

lmerR> (fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
Error in printMer(object) :
  no slot of name "status" for this object of class "table"
In addition: Warning message:
In printMer(object) :
  trying to get slot "status" from an object (class "table") that is not an S4 object
---<---------------cut here---------------end---------------->---


IIUC, the problem lies in choosing the correct print method for the lmer
object.  If lme4 is loaded *before* stats4, then the object is printed
without errors.  This is with:


---<---------------cut here---------------start-------------->---
R> sessionInfo()
R version 2.7.0 (2008-04-22) 
x86_64-pc-linux-gnu 

locale:
LC_CTYPE=en_CA.UTF-8;LC_NUMERIC=C;LC_TIME=en_CA.UTF-8;LC_COLLATE=en_CA.UTF-8;LC_MONETARY=C;LC_MESSAGES=en_CA.UTF-8;LC_PAPER=en_CA.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_CA.UTF-8;LC_IDENTIFICATION=C

attached base packages:
[1] stats4    stats     graphics  grDevices utils     datasets  methods  
[8] base     

other attached packages:
[1] lme4_0.99875-9    Matrix_0.999375-9 lattice_0.17-6   

loaded via a namespace (and not attached):
[1] grid_2.7.0
---<---------------cut here---------------end---------------->---


Cheers,

-- 
Seb



From reinhold.kliegl at gmail.com  Mon Apr 28 23:39:46 2008
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Mon, 28 Apr 2008 23:39:46 +0200
Subject: [R-sig-ME] Proper analysis for the Machines dataset in lme4
In-Reply-To: <9BA7966D-F3F1-4CCB-9E82-41A6C154195D@virginia.edu>
References: <9BA7966D-F3F1-4CCB-9E82-41A6C154195D@virginia.edu>
Message-ID: <aefe4d0a0804281439v64fe93ebpfbd84417eda37b1c@mail.gmail.com>

Dear Michael,

A few comments on your example from the Baayen book:

>  # pr2 is analogous to m2 and mr2
>  pr2 <- lmer(rt ~ soa + (1 | subj / soa) + (1 | item), sp)
It does not look like subjects are nested with soa. So why would you
want to specify this model?

>  # pr3 is analogous to m3 and mr3 This is how Baayen analyzes it
>  # (the results aren't identical to his; I don't know why):
>  pr3 <- lmer(rt ~ soa + (1 + soa | subj) + (1 | item), sp)
This is an appropriate model for this experiment. It tests the fixed
effects of soa. It allows for mean differences between subjects and
for mean differences between items (i.e., the variances of the two
intercepts) as well as for variance between subjects in the soa
effects.

Here is the current lmer (lme4_0.999375-13) fit:
Linear mixed model fit by REML
Random effects:
 Groups   Name        Variance Std.Dev. Corr
 subj     (Intercept) 855.94   29.256
          soaShort    491.81   22.177   -0.806
 item     (Intercept) 449.39   21.199
 Residual             100.21   10.011
Number of obs: 64, groups: subj, 8; item, 8

Fixed effects:
            Estimate Std. Error t value
(Intercept)   540.91      14.92   36.26
soaShort       22.41      17.10    1.31

And here are the results as reported in Baayen (2008):
Random effects:
 Groups   Name        Variance Std.Dev. Corr
 subj     (Intercept) 861.99   29.360
          soaShort    502.65   22.420   -0.813
 item     (Intercept) 448.29   21.173
 Residual             100.31   10.016
Number of obs: 64, groups: subj, 8; item, 8

Fixed effects:
            Estimate Std. Error t value
(Intercept)   540.91      14.93   36.23
soaShort       22.41      17.13    1.31

So you are correct: There are minor differences in the variance
estimates. The simple reason is that Baayen worked with a much earlier
version of lmer 0.9975-7. I am much more impressed by the stability of
the estimates than the differences, given the many changes lmer
underwent internally in the mean time.

Best
Reinhold



From mwkimpel at gmail.com  Tue Apr 29 07:21:07 2008
From: mwkimpel at gmail.com (Mark Kimpel)
Date: Tue, 29 Apr 2008 01:21:07 -0400
Subject: [R-sig-ME] interpreting significance from lmer results for
	dummies (like me)
In-Reply-To: <a072ed700804280301l78179c5fl891dd11d404000e@mail.gmail.com>
References: <6b93d1830804252053j5c264ae0u26d8e4c819d2b19@mail.gmail.com>
	<a072ed700804280301l78179c5fl891dd11d404000e@mail.gmail.com>
Message-ID: <6b93d1830804282221ha8287ccrd4cb30d85a5c5fd5@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080429/2a8f45a1/attachment.pl>

From moratti at med.ucm.es  Tue Apr 29 13:05:21 2008
From: moratti at med.ucm.es (Stephan Moratti)
Date: Tue, 29 Apr 2008 13:05:21 +0200
Subject: [R-sig-ME] nlme optim control option
In-Reply-To: <mailman.3.1209463201.10911.r-sig-mixed-models@r-project.org>
References: <mailman.3.1209463201.10911.r-sig-mixed-models@r-project.org>
Message-ID: <481700F1.7030500@med.ucm.es>

Hello,

I am using the nlme package for quite a while, but recently I have 
discovered the "optim" option in the lmeControl function and I have read 
that until the R verison 2.2.0 the optimization function is "nlminb" and 
before it was "optim" by default. As I am a "user" of R I am not into 
the optimization functions. However, I have a case now where with optim 
= "nlminb" the model does not converge, whereas with optim = "optim" the 
model converges.

Can somebody explain to me in easy words what the difference is ? If 
nlminb does not converge, but optim does, is the result less trustable ?

Thanks,

Stephan


-- 
*Stephan Moratti, PhD/
/**/see also: http://web.mac.com/smoratti/
/*Centro de Tecnolog?a Biom?dica CBT,
Universidad Polit?cnica de Madrid,

en la actualidad (currently at) en el
Centro de Magnetoencefalograf?a Dr. Perez Modrego,
Universidad Complutense de Madrid,
Faculdad de Medicina,
Pabell?n 8,
Avda. Complutense, s/n,
28040 Madrid,
Spain,

email: moratti at gbt.tfo.upm.es <mailto:moratti at gbt.tfo.upm.es>
         moratti at med.ucm.es
Tel.:    +34 91 394 2292
Fax.:   +34 91 394 2294
*/
/*



From HDoran at air.org  Tue Apr 29 13:46:10 2008
From: HDoran at air.org (Doran, Harold)
Date: Tue, 29 Apr 2008 07:46:10 -0400
Subject: [R-sig-ME] nlme optim control option
In-Reply-To: <481700F1.7030500@med.ucm.es>
Message-ID: <ED7B522EE00C9A4FA515AA71724D61EE1BA95E@DC1EXCL01.air.org>

I actually trust nlminb more than I trust optim. In some of the functions I have written in the MiscPsycho package (e.g., irt.ability) we get multimodal distributions for some of the item response theory models. 

When I use optim for optimization, you can get very funny results with difficult to maximize distributions. nlminb, however, gave reasonable results and the maximum was always confirmed to be "correct" via a visual examination of the likelihoods.

In other words, I can plot the likelihood function and get a sense of where the max is. optim would more often than not give results that are very (very) far away from the max with multimodal distributions whereas nlminb always gave back the max that seemed consistent with the visual plot of the likelihood.

With all of this said, you should switch to lme4. 


> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf 
> Of Stephan Moratti
> Sent: Tuesday, April 29, 2008 7:05 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] nlme optim control option
> 
> Hello,
> 
> I am using the nlme package for quite a while, but recently I 
> have discovered the "optim" option in the lmeControl function 
> and I have read that until the R verison 2.2.0 the 
> optimization function is "nlminb" and before it was "optim" 
> by default. As I am a "user" of R I am not into the 
> optimization functions. However, I have a case now where with 
> optim = "nlminb" the model does not converge, whereas with 
> optim = "optim" the model converges.
> 
> Can somebody explain to me in easy words what the difference 
> is ? If nlminb does not converge, but optim does, is the 
> result less trustable ?
> 
> Thanks,
> 
> Stephan
> 
> 
> --
> *Stephan Moratti, PhD/
> /**/see also: http://web.mac.com/smoratti/ /*Centro de 
> Tecnolog?a Biom?dica CBT, Universidad Polit?cnica de Madrid,
> 
> en la actualidad (currently at) en el
> Centro de Magnetoencefalograf?a Dr. Perez Modrego, 
> Universidad Complutense de Madrid, Faculdad de Medicina, 
> Pabell?n 8, Avda. Complutense, s/n, 28040 Madrid, Spain,
> 
> email: moratti at gbt.tfo.upm.es <mailto:moratti at gbt.tfo.upm.es>
>          moratti at med.ucm.es
> Tel.:    +34 91 394 2292
> Fax.:   +34 91 394 2294
> */
> /*
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 



From bates at stat.wisc.edu  Tue Apr 29 14:15:17 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 29 Apr 2008 07:15:17 -0500
Subject: [R-sig-ME] nlme optim control option
In-Reply-To: <ED7B522EE00C9A4FA515AA71724D61EE1BA95E@DC1EXCL01.air.org>
References: <481700F1.7030500@med.ucm.es>
	<ED7B522EE00C9A4FA515AA71724D61EE1BA95E@DC1EXCL01.air.org>
Message-ID: <40e66e0b0804290515o4b3bb657m4eb4e0008476b10f@mail.gmail.com>

On 4/29/08, Doran, Harold <HDoran at air.org> wrote:
> I actually trust nlminb more than I trust optim. In some of the functions I have written in the MiscPsycho package (e.g., irt.ability) we get multimodal distributions for some of the item response theory models.
>
>  When I use optim for optimization, you can get very funny results with difficult to maximize distributions. nlminb, however, gave reasonable results and the maximum was always confirmed to be "correct" via a visual examination of the likelihoods.
>
>  In other words, I can plot the likelihood function and get a sense of where the max is. optim would more often than not give results that are very (very) far away from the max with multimodal distributions whereas nlminb always gave back the max that seemed consistent with the visual plot of the likelihood.
>
>  With all of this said, you should switch to lme4.

As Harold indicated, switching the optimizer used in the nlme package
from optim to nlminb was intentional.  I had seen cases of spurious
convergence for optim and found it easier to introduce the nlminb
optimizer.

Could you give more details of the cases where functions from the nlme
package using nlminb are not converging?  Are you using the lme
function or the nlme function?  Does your model have random effects
and fixed effects only or does it also use parameterized correlation
structures?

As Harold indicated, the lme4 package is now the preferred way to fit
linear or nonlinear mixed-effects models that have only fixed effects
and random effects.  If you can show us one of your calls to lme or
nlme we can tell you how to translate it to a call to lmer or nlmer.

>  > -----Original Message-----
>  > From: r-sig-mixed-models-bounces at r-project.org
>  > [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf
>  > Of Stephan Moratti
>  > Sent: Tuesday, April 29, 2008 7:05 AM
>  > To: r-sig-mixed-models at r-project.org
>  > Subject: [R-sig-ME] nlme optim control option
>  >
>  > Hello,
>  >
>  > I am using the nlme package for quite a while, but recently I
>  > have discovered the "optim" option in the lmeControl function
>  > and I have read that until the R verison 2.2.0 the
>  > optimization function is "nlminb" and before it was "optim"
>  > by default. As I am a "user" of R I am not into the
>  > optimization functions. However, I have a case now where with
>  > optim = "nlminb" the model does not converge, whereas with
>  > optim = "optim" the model converges.
>  >
>  > Can somebody explain to me in easy words what the difference
>  > is ? If nlminb does not converge, but optim does, is the
>  > result less trustable ?
>  >
>  > Thanks,
>  >
>  > Stephan
>  >
>  >
>  > --
>  > *Stephan Moratti, PhD/
>  > /**/see also: http://web.mac.com/smoratti/ /*Centro de
>  > Tecnolog?a Biom?dica CBT, Universidad Polit?cnica de Madrid,
>  >
>  > en la actualidad (currently at) en el
>  > Centro de Magnetoencefalograf?a Dr. Perez Modrego,
>  > Universidad Complutense de Madrid, Faculdad de Medicina,
>  > Pabell?n 8, Avda. Complutense, s/n, 28040 Madrid, Spain,
>  >
>  > email: moratti at gbt.tfo.upm.es <mailto:moratti at gbt.tfo.upm.es>
>  >          moratti at med.ucm.es
>  > Tel.:    +34 91 394 2292
>  > Fax.:   +34 91 394 2294
>  > */
>  > /*
>  >
>  > _______________________________________________
>  > R-sig-mixed-models at r-project.org mailing list
>  > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>  >
>
>  _______________________________________________
>  R-sig-mixed-models at r-project.org mailing list
>  https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From moratti at med.ucm.es  Tue Apr 29 16:48:34 2008
From: moratti at med.ucm.es (Stephan Moratti)
Date: Tue, 29 Apr 2008 16:48:34 +0200
Subject: [R-sig-ME] nlme optim control option
In-Reply-To: <40e66e0b0804290515o4b3bb657m4eb4e0008476b10f@mail.gmail.com>
References: <481700F1.7030500@med.ucm.es><ED7B522EE00C9A4FA515AA71724D61EE1B
	A95E@DC1EXCL01.air.org><40e66e0b0804290515o4b3bb657m4eb4e0008476b10f@mail.gmail.com>
Message-ID: <48173542.7050502@med.ucm.es>


Thank you very much for your fast response. I will first describe the 
data and then the models applied. Further, I will attach an .RData 
object with all the data, so you can directly use it if you like.

The data are amplitude values obtained from magnetoencephalografic data 
(like EEG). There are 8 conditions and 12 subjects (I know, the number 
of conditions is quite high with respect to number of subjects). The 
basic data matrix looks like this (called "mat" in the RData object):

         V1       V2       V3       V4       V5       V6       V7       V8
1  2.851582 3.314363 3.279070 2.394195 2.914685 1.876838 2.180715 3.203826
2  4.521648 6.171458 4.124039 5.010868 4.923190 5.221255 4.745925 5.477719
3  3.957449 4.743048 3.015077 2.890330 3.428396 3.078638 3.015924 2.921296
4  5.139640 5.272191 4.067972 3.151300 5.739077 3.279299 3.524670 6.110507
5  7.928020 8.344273 7.525576 6.835657 8.995732 8.871082 7.821745 8.346335
6  4.900010 4.508470 2.532844 4.197058 4.701989 2.878392 4.939342 2.913649
7  4.378253 7.150406 5.205363 4.872032 5.460943 5.901771 4.986221 4.985459
8  5.697526 4.945624 3.855982 4.460146 4.661727 5.434473 6.283447 5.795619
9  2.772407 2.823246 2.693566 3.019434 2.303198 3.340165 3.624334 2.974910
10 5.063280 6.384693 6.015056 7.935250 5.564225 7.541611 7.154139 8.031693
11 3.202468 1.877924 1.716837 2.286963 2.152085 3.096542 3.026434 4.369565
12 4.684218 5.391280 5.360308 4.675992 4.500356 3.507834 3.795734 7.622723

The same data matrix is transformed to a data frame ("datamat" in the 
RData object):
     values ind subject condition
1  2.851582  V1       1         1
2  4.521648  V1       2         1
3  3.957449  V1       3         1
4  5.139640  V1       4         1
5  7.928020  V1       5         1
6  4.900010  V1       6         1
7  4.378253  V1       7         1
8  5.697526  V1       8         1
9  2.772407  V1       9         1
10 5.063280  V1      10         1
11 3.202468  V1      11         1
12 4.684218  V1      12         1
13 3.314363  V2       1         2
14 6.171458  V2       2         2
15 4.743048  V2       3         2
16 5.272191  V2       4         2
17 8.344273  V2       5         2
18 4.508470  V2       6         2
19 7.150406  V2       7         2
20 4.945624  V2       8         2
21 2.823246  V2       9         2
22 6.384693  V2      10         2
23 1.877924  V2      11         2
24 5.391280  V2      12         2
.... up to 8 conditions

**********************
* Applying optim resutls in: *
**********************

fm.optim<-lme(values~condition,data=datamat,random=~1|subject,correlation=corSymm(),control=list(msMaxIter=100,opt 
= "optim",msVerbose=TRUE))
initial  value 209.185062
iter  10 value 186.050690
iter  20 value 184.942325
iter  30 value 184.724836
iter  40 value 184.121038
iter  50 value 183.918251
final  value 183.903769
converged

summary(fm.optim)

Linear mixed-effects model fit by REML
 Data: datamat
       AIC      BIC    logLik
  299.5351 393.6739 -111.7675

Random effects:
 Formula: ~1 | subject
        (Intercept) Residual
StdDev:    1.110893 1.176853

Correlation Structure: General
 Formula: ~1 | subject
 Parameter estimate(s):
 Correlation:
  1      2      3      4      5      6      7    
2 -0.056                                         
3 -0.432  0.742                                  
4 -0.213  0.545  0.586                           
5  0.729  0.593  0.281  0.235                    
6  0.101  0.474  0.412  0.657  0.430             
7  0.625  0.054 -0.212  0.440  0.509  0.635      
8 -0.087  0.261  0.557  0.417  0.257  0.354  0.005
Fixed effects: values ~ condition
                Value Std.Error DF   t-value p-value
(Intercept)  4.591375 0.4671782 77  9.827888  0.0000
condition2   0.485873 0.4936256 77  0.984295  0.3281
condition3  -0.475401 0.5748486 77 -0.827002  0.4108
condition4  -0.280606 0.5290556 77 -0.530391  0.5974
condition5   0.020759 0.2498983 77  0.083068  0.9340
condition6  -0.089050 0.4556203 77 -0.195448  0.8456
condition7   0.000178 0.2941852 77  0.000604  0.9995
condition8   0.638067 0.5009446 77  1.273727  0.2066
 Correlation:
           (Intr) cndtn2 cndtn3 cndtn4 cndtn5 cndtn6 cndtn7
condition2 -0.528                                         
condition3 -0.615  0.907                                  
condition4 -0.566  0.801  0.846                           
condition5 -0.267  0.860  0.790  0.627                    
condition6 -0.488  0.734  0.768  0.847  0.608             
condition7 -0.315  0.385  0.406  0.762  0.243  0.783      
condition8 -0.536  0.655  0.832  0.748  0.566  0.678  0.366

Standardized Within-Group Residuals:
       Min         Q1        Med         Q3        Max
-1.9205059 -0.7430723 -0.1023267  0.7054844  2.1579685

Number of Observations: 96
Number of Groups: 12

***********************
* Applying nlminb results in: *
***********************
fm.nlminb<-lme(values~condition,data=datamat,random=~1|subject,correlation=corSymm(),control=list(msMaxIter=100,opt 
= "nlminb",msVerbose=TRUE))

....
98:     183.73454: 0.127036 0.0579634 0.506547 -1.36663 0.306432 
-0.838546 -0.395783 -1.18434 -2.01708 -1.91615 0.0747060 -0.199496 
-0.740317 -0.398701 -0.835580 0.623620 -0.979961 -0.232816 -0.0991876 
-1.63724  2.08835 -12.9687 0.147038 -0.361111 -0.964921 -0.271664 
-0.512183 -0.409421 -2.67278
 99:     183.73454: 0.127040 0.0579607 0.506550 -1.36663 0.306427 
-0.838537 -0.395789 -1.18434 -2.01709 -1.91611 0.0747092 -0.199503 
-0.740320 -0.398707 -0.835577 0.623649 -0.979960 -0.232836 -0.0991891 
-1.63723  2.08842 -12.9657 0.147034 -0.361111 -0.964925 -0.271658 
-0.512177 -0.409425 -2.67234
100:     183.73454: 0.127046 0.0579570 0.506540 -1.36663 0.306412 
-0.838550 -0.395794 -1.18434 -2.01711 -1.91609 0.0747311 -0.199514 
-0.740328 -0.398712 -0.835571 0.623651 -0.979969 -0.232830 -0.0992005 
-1.63723  2.08843 -12.9642 0.147026 -0.361116 -0.964933 -0.271660 
-0.512178 -0.409420 -2.67211
100:     183.73454: 0.127046 0.0579570 0.506540 -1.36663 0.306412 
-0.838550 -0.395794 -1.18434 -2.01711 -1.91609 0.0747311 -0.199514 
-0.740328 -0.398712 -0.835571 0.623651 -0.979969 -0.232830 -0.0992005 
-1.63723  2.08843 -12.9642 0.147026 -0.361116 -0.964933 -0.271660 
-0.512178 -0.409420 -2.67211
Error en lme.formula(values ~ condition, data = datamat, random = ~1 |  :
  nlminb problem, convergence error code = 1
  message = iteration limit reached without convergence (9)

using more iterations:
fm.nlminb2<-lme(values~condition,data=datamat,random=~1|subject,correlation=corSymm(),control=list(msMaxIter=200,opt 
="nlminb",msVerbose=TRUE))

....
 98:     183.73454: 0.127036 0.0579634 0.506547 -1.36663 0.306432 
-0.838546 -0.395783 -1.18434 -2.01708 -1.91615 0.0747060 -0.199496 
-0.740317 -0.398701 -0.835580 0.623620 -0.979961 -0.232816 -0.0991876 
-1.63724  2.08835 -12.9687 0.147038 -0.361111 -0.964921 -0.271664 
-0.512183 -0.409421 -2.67278
 99:     183.73454: 0.127040 0.0579607 0.506550 -1.36663 0.306427 
-0.838537 -0.395789 -1.18434 -2.01709 -1.91611 0.0747092 -0.199503 
-0.740320 -0.398707 -0.835577 0.623649 -0.979960 -0.232836 -0.0991891 
-1.63723  2.08842 -12.9657 0.147034 -0.361111 -0.964925 -0.271658 
-0.512177 -0.409425 -2.67234
100:     183.73454: 0.127046 0.0579570 0.506540 -1.36663 0.306412 
-0.838550 -0.395794 -1.18434 -2.01711 -1.91609 0.0747311 -0.199514 
-0.740328 -0.398712 -0.835571 0.623651 -0.979969 -0.232830 -0.0992005 
-1.63723  2.08843 -12.9642 0.147026 -0.361116 -0.964933 -0.271660 
-0.512178 -0.409420 -2.67211
101:     183.73454: 0.127045 0.0579574 0.506540 -1.36663 0.306412 
-0.838549 -0.395794 -1.18434 -2.01711 -1.91609 0.0747313 -0.199515 
-0.740328 -0.398712 -0.835570 0.623651 -0.979969 -0.232834 -0.0991995 
-1.63723  2.08843 -12.9642 0.147026 -0.361116 -0.964934 -0.271660 
-0.512178 -0.409419 -2.67211
102:     183.73454: 0.127045 0.0579574 0.506540 -1.36663 0.306412 
-0.838549 -0.395794 -1.18434 -2.01711 -1.91609 0.0747313 -0.199515 
-0.740328 -0.398712 -0.835570 0.623651 -0.979969 -0.232834 -0.0991995 
-1.63723  2.08843 -12.9642 0.147026 -0.361116 -0.964934 -0.271660 
-0.512178 -0.409419 -2.67211
Error en lme.formula(values ~ condition, data = datamat, random = ~1 |  :
  nlminb problem, convergence error code = 1
  message = false convergence (8)

However, if I log transform the data, both optimization methods converge 
using a maxIter of 200. All objects could be found in the Rdata object. 
Not to blow up the mail, I did not print the summary of the two fitted 
models as they are in the RData object. The two methods converge at 
similar values using the log transformed data. I don't know why "nlminb" 
does not converge with the not transformed data.

Best,

Stephan




Douglas Bates escribi?:
> On 4/29/08, Doran, Harold <HDoran at air.org> wrote:
>   
>> I actually trust nlminb more than I trust optim. In some of the functions I have written in the MiscPsycho package (e.g., irt.ability) we get multimodal distributions for some of the item response theory models.
>>
>>  When I use optim for optimization, you can get very funny results with difficult to maximize distributions. nlminb, however, gave reasonable results and the maximum was always confirmed to be "correct" via a visual examination of the likelihoods.
>>
>>  In other words, I can plot the likelihood function and get a sense of where the max is. optim would more often than not give results that are very (very) far away from the max with multimodal distributions whereas nlminb always gave back the max that seemed consistent with the visual plot of the likelihood.
>>
>>  With all of this said, you should switch to lme4.
>>     
>
> As Harold indicated, switching the optimizer used in the nlme package
> from optim to nlminb was intentional.  I had seen cases of spurious
> convergence for optim and found it easier to introduce the nlminb
> optimizer.
>
> Could you give more details of the cases where functions from the nlme
> package using nlminb are not converging?  Are you using the lme
> function or the nlme function?  Does your model have random effects
> and fixed effects only or does it also use parameterized correlation
> structures?
>
> As Harold indicated, the lme4 package is now the preferred way to fit
> linear or nonlinear mixed-effects models that have only fixed effects
> and random effects.  If you can show us one of your calls to lme or
> nlme we can tell you how to translate it to a call to lmer or nlmer.
>
>   
>>  > -----Original Message-----
>>  > From: r-sig-mixed-models-bounces at r-project.org
>>  > [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf
>>  > Of Stephan Moratti
>>  > Sent: Tuesday, April 29, 2008 7:05 AM
>>  > To: r-sig-mixed-models at r-project.org
>>  > Subject: [R-sig-ME] nlme optim control option
>>  >
>>  > Hello,
>>  >
>>  > I am using the nlme package for quite a while, but recently I
>>  > have discovered the "optim" option in the lmeControl function
>>  > and I have read that until the R verison 2.2.0 the
>>  > optimization function is "nlminb" and before it was "optim"
>>  > by default. As I am a "user" of R I am not into the
>>  > optimization functions. However, I have a case now where with
>>  > optim = "nlminb" the model does not converge, whereas with
>>  > optim = "optim" the model converges.
>>  >
>>  > Can somebody explain to me in easy words what the difference
>>  > is ? If nlminb does not converge, but optim does, is the
>>  > result less trustable ?
>>  >
>>  > Thanks,
>>  >
>>  > Stephan
>>  >
>>  >
>>  > --
>>  > *Stephan Moratti, PhD/
>>  > /**/see also: http://web.mac.com/smoratti/ /*Centro de
>>  > Tecnolog?a Biom?dica CBT, Universidad Polit?cnica de Madrid,
>>  >
>>  > en la actualidad (currently at) en el
>>  > Centro de Magnetoencefalograf?a Dr. Perez Modrego,
>>  > Universidad Complutense de Madrid, Faculdad de Medicina,
>>  > Pabell?n 8, Avda. Complutense, s/n, 28040 Madrid, Spain,
>>  >
>>  > email: moratti at gbt.tfo.upm.es <mailto:moratti at gbt.tfo.upm.es>
>>  >          moratti at med.ucm.es
>>  > Tel.:    +34 91 394 2292
>>  > Fax.:   +34 91 394 2294
>>  > */
>>  > /*
>>  >
>>  > _______________________________________________
>>  > R-sig-mixed-models at r-project.org mailing list
>>  > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>  >
>>
>>  _______________________________________________
>>  R-sig-mixed-models at r-project.org mailing list
>>  https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>     
>
>   


-- 
*Stephan Moratti, PhD/
/**/see also: http://web.mac.com/smoratti/
/*Centro de Tecnolog?a Biom?dica CBT,
Universidad Polit?cnica de Madrid,

en la actualidad (currently at) en el
Centro de Magnetoencefalograf?a Dr. Perez Modrego,
Universidad Complutense de Madrid,
Faculdad de Medicina,
Pabell?n 8,
Avda. Complutense, s/n,
28040 Madrid,
Spain,

email: moratti at gbt.tfo.upm.es <mailto:moratti at gbt.tfo.upm.es>
         moratti at med.ucm.es
Tel.:    +34 91 394 2292
Fax.:   +34 91 394 2294
*/
/*

From moratti at med.ucm.es  Tue Apr 29 18:47:09 2008
From: moratti at med.ucm.es (Stephan Moratti)
Date: Tue, 29 Apr 2008 18:47:09 +0200
Subject: [R-sig-ME] nlme optim control option
In-Reply-To: <481730AD.1030109@zoology.ufl.edu>
References: <481700F1.7030500@med.ucm.es><"ED7B522EE00C9A4FA515AA71724D61EE1 B 
	A95E"@DC1EXCL01.air.org><40e66e0b0804290515o4b3bb657m4eb4e0008476b10f@mail.
	gmail.com><48173542.7050502@med.ucm.es>
	<481730AD.1030109@zoology.ufl.edu>
Message-ID: <f69bd30c9e58.48176d2d@ucm.es>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080429/21a4df58/attachment.pl>

From spluque at gmail.com  Thu May  1 15:28:11 2008
From: spluque at gmail.com (Sebastian P. Luque)
Date: Thu, 01 May 2008 08:28:11 -0500
Subject: [R-sig-ME] random effects specification
References: <87abkak6qa.fsf@patagonia.sebmags.homelinux.org>
	<75A3A990-0E70-4BDB-A44D-2BA011ADEA8C@kagi.com>
	<40e66e0b0804060804g494f8f59i5307444fc581227d@mail.gmail.com>
	<3D4A6791-2368-412E-A62E-BD10EFD5DA91@kagi.com>
	<87prt1ojvt.fsf@patagonia.sebmags.homelinux.org>
	<87ve2s5nax.fsf@patagonia.sebmags.homelinux.org>
	<aefe4d0a0804081031v28ebeac3t9d849213c4b1e954@mail.gmail.com>
	<87iqys5i6a.fsf@patagonia.sebmags.homelinux.org>
	<aefe4d0a0804081247x1bdcaaa2u9661b8ebfbfde9d4@mail.gmail.com>
	<873apw5blo.fsf@patagonia.sebmags.homelinux.org>
	<aefe4d0a0804081500r665d5a23gf337da3fc49aac36@mail.gmail.com>
Message-ID: <87skx2taqc.fsf@patagonia.sebmags.homelinux.org>

Hi again,

I've made further explorations into lmer, toying with the example I
showed earlier:


---<---------------cut here---------------start-------------->---
set.seed(1000)
rCom <- rnorm(2, mean=5, sd=0.5)
rTr <- rep(rCom / 1.1, 2)
nbase <- rnorm(60, 10, 0.1)

## 20 individuals; 10 in community "A" and 10 in "B", each receiving 3
## different treatments once.
dta <- within(expand.grid(community=LETTERS[1:2], treatment=letters[1:3],
                          id=1:10), {
                              id[community == "B"] <- id[community == "B"] + 10
                              id <- as.factor(id)
                              n <- rCom[as.numeric(community)] +
                                  rTr[as.numeric(treatment)] + nbase
                          })
dta <- dta[order(dta$id, dta$community, dta$treatment), ]

## Simulate an interaction
dta$n[dta$community == "A"] <- rev(dta$n[dta$community == "A"])
## Have a look
xyplot(n ~ treatment | community, data=dta, groups=id,
       type="b", pch=19, cex=0.3)

## We test for community (A, B) and treatment (a, b, c) fixed effects,
## their interactions, and use random effects for subject (1:20).  Am I
## writing this correctly?
##
## y_{ijk} = B_j + B_k + B_{jk} + b_i + e_{ijk}    i=1,...,20; j=A,B; k=a,b,c
n.lmer1 <- lmer(n ~ community * treatment + (1 | id), dta)
---<---------------cut here---------------end---------------->---


I'm a bit confused whether I'm describing the model being fit correctly
(not the lmer call, but the model description in the comment above), and
how it could be described in matrix form.  I think this type of
exercises would help me grasp the syntax conventions better.

Another issue is that the lmer call results in a warning:

---<---------------cut here---------------start-------------->---
Warning message:
In .local(x, ..., value) :
  Estimated variance for factor ?id? is effectively zero
---<---------------cut here---------------end---------------->---


which I presume is due to the fact that the data are unreplicated,
i.e. individuals get each treatment only once.  Are there any gotchas in
the interpretation of the results after this warning?

Thanks once again!

-- 
Seb



From kjbeath at kagi.com  Thu May  1 23:24:13 2008
From: kjbeath at kagi.com (Ken Beath)
Date: Fri, 2 May 2008 07:24:13 +1000
Subject: [R-sig-ME] random effects specification
In-Reply-To: <87skx2taqc.fsf@patagonia.sebmags.homelinux.org>
References: <87abkak6qa.fsf@patagonia.sebmags.homelinux.org>
	<75A3A990-0E70-4BDB-A44D-2BA011ADEA8C@kagi.com>
	<40e66e0b0804060804g494f8f59i5307444fc581227d@mail.gmail.com>
	<3D4A6791-2368-412E-A62E-BD10EFD5DA91@kagi.com>
	<87prt1ojvt.fsf@patagonia.sebmags.homelinux.org>
	<87ve2s5nax.fsf@patagonia.sebmags.homelinux.org>
	<aefe4d0a0804081031v28ebeac3t9d849213c4b1e954@mail.gmail.com>
	<87iqys5i6a.fsf@patagonia.sebmags.homelinux.org>
	<aefe4d0a0804081247x1bdcaaa2u9661b8ebfbfde9d4@mail.gmail.com>
	<873apw5blo.fsf@patagonia.sebmags.homelinux.org>
	<aefe4d0a0804081500r665d5a23gf337da3fc49aac36@mail.gmail.com>
	<87skx2taqc.fsf@patagonia.sebmags.homelinux.org>
Message-ID: <538DCC9F-9DC2-477C-AB2F-A6B828C72C23@kagi.com>

On 01/05/2008, at 11:28 PM, Sebastian P. Luque wrote:

>
> which I presume is due to the fact that the data are unreplicated,
> i.e. individuals get each treatment only once.

No. Due to not having a random component for id in the simulated data.

Try

rid <- rep(rnorm(20),each=3)
dta$n <- dta$n+rid

Then refit the model.

>
> Are there any gotchas in
> the interpretation of the results after this warning?
>
>

Probably not, but with real data I would remove the random effect from  
the model as it is 0.

Ken



From A.Robinson at ms.unimelb.edu.au  Thu May  1 23:30:27 2008
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Fri, 2 May 2008 07:30:27 +1000
Subject: [R-sig-ME] random effects specification
In-Reply-To: <87skx2taqc.fsf@patagonia.sebmags.homelinux.org>
References: <40e66e0b0804060804g494f8f59i5307444fc581227d@mail.gmail.com>
	<3D4A6791-2368-412E-A62E-BD10EFD5DA91@kagi.com>
	<87prt1ojvt.fsf@patagonia.sebmags.homelinux.org>
	<87ve2s5nax.fsf@patagonia.sebmags.homelinux.org>
	<aefe4d0a0804081031v28ebeac3t9d849213c4b1e954@mail.gmail.com>
	<87iqys5i6a.fsf@patagonia.sebmags.homelinux.org>
	<aefe4d0a0804081247x1bdcaaa2u9661b8ebfbfde9d4@mail.gmail.com>
	<873apw5blo.fsf@patagonia.sebmags.homelinux.org>
	<aefe4d0a0804081500r665d5a23gf337da3fc49aac36@mail.gmail.com>
	<87skx2taqc.fsf@patagonia.sebmags.homelinux.org>
Message-ID: <20080501213027.GD1433@ms.unimelb.edu.au>

Hi Sebastian,

On Thu, May 01, 2008 at 08:28:11AM -0500, Sebastian P. Luque wrote:
> Hi again,
> 
> I've made further explorations into lmer, toying with the example I
> showed earlier:
> 
> 
> ---<---------------cut here---------------start-------------->---
> set.seed(1000)
> rCom <- rnorm(2, mean=5, sd=0.5)
> rTr <- rep(rCom / 1.1, 2)
> nbase <- rnorm(60, 10, 0.1)
> 
> ## 20 individuals; 10 in community "A" and 10 in "B", each receiving 3
> ## different treatments once.
> dta <- within(expand.grid(community=LETTERS[1:2], treatment=letters[1:3],
>                           id=1:10), {
>                               id[community == "B"] <- id[community == "B"] + 10
>                               id <- as.factor(id)
>                               n <- rCom[as.numeric(community)] +
>                                   rTr[as.numeric(treatment)] + nbase
>                           })
> dta <- dta[order(dta$id, dta$community, dta$treatment), ]
> 
> ## Simulate an interaction
> dta$n[dta$community == "A"] <- rev(dta$n[dta$community == "A"])
> ## Have a look
> xyplot(n ~ treatment | community, data=dta, groups=id,
>        type="b", pch=19, cex=0.3)
> 
> ## We test for community (A, B) and treatment (a, b, c) fixed effects,
> ## their interactions, and use random effects for subject (1:20).  Am I
> ## writing this correctly?
> ##
> ## y_{ijk} = B_j + B_k + B_{jk} + b_i + e_{ijk}    i=1,...,20; j=A,B; k=a,b,c
> n.lmer1 <- lmer(n ~ community * treatment + (1 | id), dta)
> ---<---------------cut here---------------end---------------->---
> 
> 
> I'm a bit confused whether I'm describing the model being fit correctly
> (not the lmer call, but the model description in the comment above), and

I think so.

> how it could be described in matrix form.  

I'm not sure what you're looking for here.  Matrix form as I
understand it tends to be pretty generic.  But, have a go and we can
critique it :)

> I think this type of
> exercises would help me grasp the syntax conventions better.
> 
> Another issue is that the lmer call results in a warning:
> 
> ---<---------------cut here---------------start-------------->---
> Warning message:
> In .local(x, ..., value) :
>   Estimated variance for factor ???id??? is effectively zero
> ---<---------------cut here---------------end---------------->---
> 
> 
> which I presume is due to the fact that the data are unreplicated,
> i.e. individuals get each treatment only once.  

No, I think that it's because you didn't assign any subject to subject
variation to the observations. n comprises a contribution from
community, from treatment, and from the base error, but not from id.
Try adding id-based variation.

> Are there any gotchas in the interpretation of the results after
> this warning?

I would ordinarily interpret that message as meaning that the model is
overparameterized.  That seems to be true, here.

Andrew

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From john.maindonald at anu.edu.au  Fri May  2 14:34:22 2008
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Fri, 2 May 2008 22:34:22 +1000
Subject: [R-sig-ME] lme4 and Matrix from R-forge
Message-ID: <710CE1A8-ACE5-4415-8310-7CA6FDBED80A@anu.edu.au>

I am wondering if there is a problem with attaching the latest lme4  
and Matrix from R-forge.

 > library(lme4)
Loading required package: Matrix
Loading required package: lattice
Error in dyn.load(file, DLLpath = DLLpath, ...) :
  unable to load shared library '/Library/Frameworks/R.framework/ 
Resources/library/Matrix/libs/i386/Matrix.so':
  dlopen(/Library/Frameworks/R.framework/Resources/library/Matrix/libs/ 
i386/Matrix.so, 6): Library not loaded: /Library/Frameworks/ 
R.framework/Versions/2.6/Resources/lib/libRlapack.dylib
  Referenced from: /Library/Frameworks/R.framework/Resources/library/ 
Matrix/libs/i386/Matrix.so
  Reason: image not found
Error: package 'Matrix' could not be loaded
 > sessionInfo()
R version 2.7.0 Patched (2008-05-01 r45578)
i386-apple-darwin8.10.1

locale:
en_AU.UTF-8/en_AU.UTF-8/C/C/en_AU.UTF-8/en_AU.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lattice_0.17-6

loaded via a namespace (and not attached):
[1] grid_2.7.0

It is possible I have corrupted my installation; I first tried to  
install
Matrix_0.999375-10.tgz with the CRAN version of lme4 installed,
then tried to go back to the CRAN version of Matrix.  My version
of lme4 is lme4_0.999375-14.tgz

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.



From bates at stat.wisc.edu  Fri May  2 17:49:16 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 2 May 2008 10:49:16 -0500
Subject: [R-sig-ME] lme4 and Matrix from R-forge
In-Reply-To: <710CE1A8-ACE5-4415-8310-7CA6FDBED80A@anu.edu.au>
References: <710CE1A8-ACE5-4415-8310-7CA6FDBED80A@anu.edu.au>
Message-ID: <40e66e0b0805020849i53644698i21a1aaeba2ca0962@mail.gmail.com>

It seems to me that those messages are coming from the attempt to load
the Matrix package.  It looks a bit peculiar in that the compiled code
for the Matrix package is in the file Matrix.so and it is linked
against libRlapack.dylib.  That seems inconsistent.

If you have the necessary tools installed then I would recommend
installing the Matrix package from the source file.  I believe that
the version on CRAN and the source version on R-forge should both be
acceptable.


On Fri, May 2, 2008 at 7:34 AM, John Maindonald
<john.maindonald at anu.edu.au> wrote:
> I am wondering if there is a problem with attaching the latest lme4 and
> Matrix from R-forge.
>
>> library(lme4)
> Loading required package: Matrix
> Loading required package: lattice
> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>  unable to load shared library
> '/Library/Frameworks/R.framework/Resources/library/Matrix/libs/i386/Matrix.so':
>  dlopen(/Library/Frameworks/R.framework/Resources/library/Matrix/libs/i386/Matrix.so,
> 6): Library not loaded:
> /Library/Frameworks/R.framework/Versions/2.6/Resources/lib/libRlapack.dylib
>  Referenced from:
> /Library/Frameworks/R.framework/Resources/library/Matrix/libs/i386/Matrix.so
>  Reason: image not found
> Error: package 'Matrix' could not be loaded
>> sessionInfo()
> R version 2.7.0 Patched (2008-05-01 r45578)
> i386-apple-darwin8.10.1
>
> locale:
> en_AU.UTF-8/en_AU.UTF-8/C/C/en_AU.UTF-8/en_AU.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] lattice_0.17-6
>
> loaded via a namespace (and not attached):
> [1] grid_2.7.0
>
> It is possible I have corrupted my installation; I first tried to install
> Matrix_0.999375-10.tgz with the CRAN version of lme4 installed,
> then tried to go back to the CRAN version of Matrix.  My version
> of lme4 is lme4_0.999375-14.tgz
>
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From smckinney at bccrc.ca  Fri May  2 19:56:55 2008
From: smckinney at bccrc.ca (Steven McKinney)
Date: Fri, 2 May 2008 10:56:55 -0700
Subject: [R-sig-ME] lme4 and Matrix from R-forge
References: <710CE1A8-ACE5-4415-8310-7CA6FDBED80A@anu.edu.au>
	<40e66e0b0805020849i53644698i21a1aaeba2ca0962@mail.gmail.com>
Message-ID: <0BE438149FF2254DB4199E2682C8DFEB0328A2AD@crcmail1.BCCRC.CA>


Just curious, maybe Simon Urbanek will know,
but why is version 2.6 showing in the R.framework
path when you are running R 2.7.0?

> /Library/Frameworks/R.framework/Versions/2.6/Resources/lib/libRlapack.dylib



Steven McKinney





-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org on behalf of Douglas Bates
Sent: Fri 5/2/2008 8:49 AM
To: John Maindonald
Cc: R Mixed Models
Subject: Re: [R-sig-ME] lme4 and Matrix from R-forge
 
It seems to me that those messages are coming from the attempt to load
the Matrix package.  It looks a bit peculiar in that the compiled code
for the Matrix package is in the file Matrix.so and it is linked
against libRlapack.dylib.  That seems inconsistent.

If you have the necessary tools installed then I would recommend
installing the Matrix package from the source file.  I believe that
the version on CRAN and the source version on R-forge should both be
acceptable.


On Fri, May 2, 2008 at 7:34 AM, John Maindonald
<john.maindonald at anu.edu.au> wrote:
> I am wondering if there is a problem with attaching the latest lme4 and
> Matrix from R-forge.
>
>> library(lme4)
> Loading required package: Matrix
> Loading required package: lattice
> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>  unable to load shared library
> '/Library/Frameworks/R.framework/Resources/library/Matrix/libs/i386/Matrix.so':
>  dlopen(/Library/Frameworks/R.framework/Resources/library/Matrix/libs/i386/Matrix.so,
> 6): Library not loaded:
> /Library/Frameworks/R.framework/Versions/2.6/Resources/lib/libRlapack.dylib
>  Referenced from:
> /Library/Frameworks/R.framework/Resources/library/Matrix/libs/i386/Matrix.so
>  Reason: image not found
> Error: package 'Matrix' could not be loaded
>> sessionInfo()
> R version 2.7.0 Patched (2008-05-01 r45578)
> i386-apple-darwin8.10.1
>
> locale:
> en_AU.UTF-8/en_AU.UTF-8/C/C/en_AU.UTF-8/en_AU.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] lattice_0.17-6
>
> loaded via a namespace (and not attached):
> [1] grid_2.7.0
>
> It is possible I have corrupted my installation; I first tried to install
> Matrix_0.999375-10.tgz with the CRAN version of lme4 installed,
> then tried to go back to the CRAN version of Matrix.  My version
> of lme4 is lme4_0.999375-14.tgz
>
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bates at stat.wisc.edu  Fri May  2 20:10:35 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 2 May 2008 13:10:35 -0500
Subject: [R-sig-ME] lme4 and Matrix from R-forge
In-Reply-To: <0BE438149FF2254DB4199E2682C8DFEB0328A2AD@crcmail1.BCCRC.CA>
References: <710CE1A8-ACE5-4415-8310-7CA6FDBED80A@anu.edu.au>
	<40e66e0b0805020849i53644698i21a1aaeba2ca0962@mail.gmail.com>
	<0BE438149FF2254DB4199E2682C8DFEB0328A2AD@crcmail1.BCCRC.CA>
Message-ID: <40e66e0b0805021110n658016feh4dd19a44852a9268@mail.gmail.com>

My guess is that the machine used to compile the Mac OS X binary for
the R-forge repository is still running version 2.6.x

On Fri, May 2, 2008 at 12:56 PM, Steven McKinney <smckinney at bccrc.ca> wrote:
>
> Just curious, maybe Simon Urbanek will know,
> but why is version 2.6 showing in the R.framework
> path when you are running R 2.7.0?
>
>> /Library/Frameworks/R.framework/Versions/2.6/Resources/lib/libRlapack.dylib
>
>
>
> Steven McKinney
>
>
>
>
>
> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org on behalf of Douglas Bates
> Sent: Fri 5/2/2008 8:49 AM
> To: John Maindonald
> Cc: R Mixed Models
> Subject: Re: [R-sig-ME] lme4 and Matrix from R-forge
>
> It seems to me that those messages are coming from the attempt to load
> the Matrix package.  It looks a bit peculiar in that the compiled code
> for the Matrix package is in the file Matrix.so and it is linked
> against libRlapack.dylib.  That seems inconsistent.
>
> If you have the necessary tools installed then I would recommend
> installing the Matrix package from the source file.  I believe that
> the version on CRAN and the source version on R-forge should both be
> acceptable.
>
>
> On Fri, May 2, 2008 at 7:34 AM, John Maindonald
> <john.maindonald at anu.edu.au> wrote:
>> I am wondering if there is a problem with attaching the latest lme4 and
>> Matrix from R-forge.
>>
>>> library(lme4)
>> Loading required package: Matrix
>> Loading required package: lattice
>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>>  unable to load shared library
>> '/Library/Frameworks/R.framework/Resources/library/Matrix/libs/i386/Matrix.so':
>>  dlopen(/Library/Frameworks/R.framework/Resources/library/Matrix/libs/i386/Matrix.so,
>> 6): Library not loaded:
>> /Library/Frameworks/R.framework/Versions/2.6/Resources/lib/libRlapack.dylib
>>  Referenced from:
>> /Library/Frameworks/R.framework/Resources/library/Matrix/libs/i386/Matrix.so
>>  Reason: image not found
>> Error: package 'Matrix' could not be loaded
>>> sessionInfo()
>> R version 2.7.0 Patched (2008-05-01 r45578)
>> i386-apple-darwin8.10.1
>>
>> locale:
>> en_AU.UTF-8/en_AU.UTF-8/C/C/en_AU.UTF-8/en_AU.UTF-8
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] lattice_0.17-6
>>
>> loaded via a namespace (and not attached):
>> [1] grid_2.7.0
>>
>> It is possible I have corrupted my installation; I first tried to install
>> Matrix_0.999375-10.tgz with the CRAN version of lme4 installed,
>> then tried to go back to the CRAN version of Matrix.  My version
>> of lme4 is lme4_0.999375-14.tgz
>>
>> John Maindonald             email: john.maindonald at anu.edu.au
>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>> Centre for Mathematics & Its Applications, Room 1194,
>> John Dedman Mathematical Sciences Building (Building 27)
>> Australian National University, Canberra ACT 0200.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From John.Maindonald at anu.edu.au  Sat May  3 01:19:53 2008
From: John.Maindonald at anu.edu.au (John Maindonald)
Date: Sat, 3 May 2008 09:19:53 +1000
Subject: [R-sig-ME] lme4 and Matrix from R-forge
In-Reply-To: <40e66e0b0805020849i53644698i21a1aaeba2ca0962@mail.gmail.com>
References: <710CE1A8-ACE5-4415-8310-7CA6FDBED80A@anu.edu.au>
	<40e66e0b0805020849i53644698i21a1aaeba2ca0962@mail.gmail.com>
Message-ID: <4CF6306E-C36C-4810-8B4A-1E39F100B9ED@anu.edu.au>

Installing from source has been successful.  I had to do this for lme4
as well as for Matrix.  I presume that the warning messages can be
ignored, for now at least.
Thanks
John.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


On 3 May 2008, at 1:49 AM, Douglas Bates wrote:

> It seems to me that those messages are coming from the attempt to load
> the Matrix package.  It looks a bit peculiar in that the compiled code
> for the Matrix package is in the file Matrix.so and it is linked
> against libRlapack.dylib.  That seems inconsistent.
>
> If you have the necessary tools installed then I would recommend
> installing the Matrix package from the source file.  I believe that
> the version on CRAN and the source version on R-forge should both be
> acceptable.
>
>
> On Fri, May 2, 2008 at 7:34 AM, John Maindonald
> <john.maindonald at anu.edu.au> wrote:
>> I am wondering if there is a problem with attaching the latest lme4  
>> and
>> Matrix from R-forge.
>>
>>> library(lme4)
>> Loading required package: Matrix
>> Loading required package: lattice
>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>> unable to load shared library
>> '/Library/Frameworks/R.framework/Resources/library/Matrix/libs/i386/ 
>> Matrix.so':
>> dlopen(/Library/Frameworks/R.framework/Resources/library/Matrix/ 
>> libs/i386/Matrix.so,
>> 6): Library not loaded:
>> /Library/Frameworks/R.framework/Versions/2.6/Resources/lib/ 
>> libRlapack.dylib
>> Referenced from:
>> /Library/Frameworks/R.framework/Resources/library/Matrix/libs/i386/ 
>> Matrix.so
>> Reason: image not found
>> Error: package 'Matrix' could not be loaded
>>> sessionInfo()
>> R version 2.7.0 Patched (2008-05-01 r45578)
>> i386-apple-darwin8.10.1
>>
>> locale:
>> en_AU.UTF-8/en_AU.UTF-8/C/C/en_AU.UTF-8/en_AU.UTF-8
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] lattice_0.17-6
>>
>> loaded via a namespace (and not attached):
>> [1] grid_2.7.0
>>
>> It is possible I have corrupted my installation; I first tried to  
>> install
>> Matrix_0.999375-10.tgz with the CRAN version of lme4 installed,
>> then tried to go back to the CRAN version of Matrix.  My version
>> of lme4 is lme4_0.999375-14.tgz
>>
>> John Maindonald             email: john.maindonald at anu.edu.au
>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>> Centre for Mathematics & Its Applications, Room 1194,
>> John Dedman Mathematical Sciences Building (Building 27)
>> Australian National University, Canberra ACT 0200.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>



From john.maindonald at anu.edu.au  Sat May  3 03:59:35 2008
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Sat, 3 May 2008 11:59:35 +1000
Subject: [R-sig-ME] Failure of mcmcsamp()
Message-ID: <1B3E96FD-2747-48DB-905D-BE7DB8D52629@anu.edu.au>

Dear Douglas -
The following happens under the versions of lme4 and Matrix from R- 
forge:

 > Orthodont$logdist <- log(Orthodont$distance)
 > keep <- !(Orthodont$Subject%in%c("M04","M13"))
 > orthodont <- subset(Orthodont, keep)
 > orthodont$Subject <- factor(orthodont$Subject)
 > orthdiff.lmer <- lmer(logdist ~ Sex * I(age-11) + (I(age-11) |
+                                                    Subject),
+                       data=orthodont,  method="ML")
 > orthdiffr.lmer <- update(orthdiff.lmer, method="REML")
 > orth.mcmc <- mcmcsamp(orthdiffr.lmer, n=1000)
Error in .local(object, n, verbose, ...) :
   crossproduct matrix 1 is not positive definite

 > VarCorr(orthdiffr.lmer)
$Subject
             (Intercept) I(age - 11)
(Intercept)   1.746e-02   1.555e-07
I(age - 11)   1.555e-07   1.384e-12
attr(,"stddev")
(Intercept) I(age - 11)
   1.322e-01   1.177e-06
attr(,"correlation")
             (Intercept) I(age - 11)
(Intercept)           1           1
I(age - 11)           1           1

attr(,"sc")
sigmaREML
   0.05238

R version 2.7.0 Patched (2008-05-01 r45578)
i386-apple-darwin8.10.1

locale:
C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] DAAG_0.97          MASS_7.2-41        lme4_0.999375-14    
Matrix_0.999375-10
[5] lattice_0.17-6

loaded via a namespace (and not attached):
[1] grid_2.7.0  tools_2.7.0

This proceeds without error when I use the CRAN versions (albeit under  
Windows)

other attached packages:
[1] coda_0.13-1       MEMSS_0.2-4       lme4_0.99875-9     
Matrix_0.999375-9 lattice_0.17-6

If I do not remove the "outliers" the calculations proceed without  
complaint.  The issue is,
maybe, that the variance component associated with the I(age-11) slope  
is rather small?
Regards

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.



From john.maindonald at anu.edu.au  Sat May  3 04:11:48 2008
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Sat, 3 May 2008 12:11:48 +1000
Subject: [R-sig-ME] Failure of mcmcsamp(); PS
Message-ID: <5AD340FB-5584-48BD-A70F-ABF45F9DF79A@anu.edu.au>

Actually, on checking more carefully, the CRAN version gave the  
warning message
'Estimated variance-covariance for factor ?Subject? is singular' when I
calculated orthdiff.lmer and orthdiffr.lmer.  mcmcsamp() then  
proceeded without
complaint, however.
John.

Dear Douglas -
The following happens under the versions of lme4 and Matrix from R- 
forge:

 > Orthodont$logdist <- log(Orthodont$distance)
 > keep <- !(Orthodont$Subject%in%c("M04","M13"))
 > orthodont <- subset(Orthodont, keep)
 > orthodont$Subject <- factor(orthodont$Subject)
 > orthdiff.lmer <- lmer(logdist ~ Sex * I(age-11) + (I(age-11) |
+                                                    Subject),
+                       data=orthodont,  method="ML")
 > orthdiffr.lmer <- update(orthdiff.lmer, method="REML")
 > orth.mcmc <- mcmcsamp(orthdiffr.lmer, n=1000)
Error in .local(object, n, verbose, ...) :
  crossproduct matrix 1 is not positive definite

 > VarCorr(orthdiffr.lmer)
$Subject
            (Intercept) I(age - 11)
(Intercept)   1.746e-02   1.555e-07
I(age - 11)   1.555e-07   1.384e-12
attr(,"stddev")
(Intercept) I(age - 11)
  1.322e-01   1.177e-06
attr(,"correlation")
            (Intercept) I(age - 11)
(Intercept)           1           1
I(age - 11)           1           1

attr(,"sc")
sigmaREML
  0.05238

R version 2.7.0 Patched (2008-05-01 r45578)
i386-apple-darwin8.10.1

locale:
C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] DAAG_0.97          MASS_7.2-41        lme4_0.999375-14    
Matrix_0.999375-10
[5] lattice_0.17-6

loaded via a namespace (and not attached):
[1] grid_2.7.0  tools_2.7.0

This proceeds without error when I use the CRAN versions (albeit under  
Windows)

other attached packages:
[1] coda_0.13-1       MEMSS_0.2-4       lme4_0.99875-9     
Matrix_0.999375-9 lattice_0.17-6

If I do not remove the "outliers" the calculations proceed without  
complaint.  The issue is,
maybe, that the variance component associated with the I(age-11) slope  
is rather small?
Regards

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.



From bates at stat.wisc.edu  Sat May  3 16:47:17 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat, 3 May 2008 09:47:17 -0500
Subject: [R-sig-ME] lme4 and Matrix from R-forge
In-Reply-To: <4CF6306E-C36C-4810-8B4A-1E39F100B9ED@anu.edu.au>
References: <710CE1A8-ACE5-4415-8310-7CA6FDBED80A@anu.edu.au>
	<40e66e0b0805020849i53644698i21a1aaeba2ca0962@mail.gmail.com>
	<4CF6306E-C36C-4810-8B4A-1E39F100B9ED@anu.edu.au>
Message-ID: <40e66e0b0805030747p3f4899e8y1dddfc71baed90cc@mail.gmail.com>

On Fri, May 2, 2008 at 6:19 PM, John Maindonald
<John.Maindonald at anu.edu.au> wrote:
> Installing from source has been successful.  I had to do this for lme4
> as well as for Matrix.  I presume that the warning messages can be
> ignored, for now at least.

What warning messages?

I should try the installation on a Mac OS X system myself but the last
time I tried to install the Xcode compilers I foolishly used a DSL
connection so the download took 2 hours.  When I tried to open up the
disk image I had downloaded, I found it was corrupt.  Maybe if I
remember to write a DVD of the image when I am at the office I can
install it.
> On 3 May 2008, at 1:49 AM, Douglas Bates wrote:
>
>> It seems to me that those messages are coming from the attempt to load
>> the Matrix package.  It looks a bit peculiar in that the compiled code
>> for the Matrix package is in the file Matrix.so and it is linked
>> against libRlapack.dylib.  That seems inconsistent.
>>
>> If you have the necessary tools installed then I would recommend
>> installing the Matrix package from the source file.  I believe that
>> the version on CRAN and the source version on R-forge should both be
>> acceptable.
>>
>>
>> On Fri, May 2, 2008 at 7:34 AM, John Maindonald
>> <john.maindonald at anu.edu.au> wrote:
>>>
>>> I am wondering if there is a problem with attaching the latest lme4 and
>>> Matrix from R-forge.
>>>
>>>> library(lme4)
>>>
>>> Loading required package: Matrix
>>> Loading required package: lattice
>>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>>> unable to load shared library
>>>
>>> '/Library/Frameworks/R.framework/Resources/library/Matrix/libs/i386/Matrix.so':
>>>
>>> dlopen(/Library/Frameworks/R.framework/Resources/library/Matrix/libs/i386/Matrix.so,
>>> 6): Library not loaded:
>>>
>>> /Library/Frameworks/R.framework/Versions/2.6/Resources/lib/libRlapack.dylib
>>> Referenced from:
>>>
>>> /Library/Frameworks/R.framework/Resources/library/Matrix/libs/i386/Matrix.so
>>> Reason: image not found
>>> Error: package 'Matrix' could not be loaded
>>>>
>>>> sessionInfo()
>>>
>>> R version 2.7.0 Patched (2008-05-01 r45578)
>>> i386-apple-darwin8.10.1
>>>
>>> locale:
>>> en_AU.UTF-8/en_AU.UTF-8/C/C/en_AU.UTF-8/en_AU.UTF-8
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> other attached packages:
>>> [1] lattice_0.17-6
>>>
>>> loaded via a namespace (and not attached):
>>> [1] grid_2.7.0
>>>
>>> It is possible I have corrupted my installation; I first tried to install
>>> Matrix_0.999375-10.tgz with the CRAN version of lme4 installed,
>>> then tried to go back to the CRAN version of Matrix.  My version
>>> of lme4 is lme4_0.999375-14.tgz
>>>
>>> John Maindonald             email: john.maindonald at anu.edu.au
>>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>>> Centre for Mathematics & Its Applications, Room 1194,
>>> John Dedman Mathematical Sciences Building (Building 27)
>>> Australian National University, Canberra ACT 0200.
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>



From bates at stat.wisc.edu  Sat May  3 17:03:41 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat, 3 May 2008 10:03:41 -0500
Subject: [R-sig-ME] Failure of mcmcsamp()
In-Reply-To: <1B3E96FD-2747-48DB-905D-BE7DB8D52629@anu.edu.au>
References: <1B3E96FD-2747-48DB-905D-BE7DB8D52629@anu.edu.au>
Message-ID: <40e66e0b0805030803y777fd07fj5e1497fe856ff96e@mail.gmail.com>

I also saw your later message about getting a warning in the earlier
version of lme4.

You have encountered the reason that the development version of the
lme4 package is not yet the released version.  The development version
handles singular variance-covariance matrices more cleanly than does
the release version because of the way that the log-likelihood is
computed.  The release version uses the older-style calculation based
on the precision matrix (i.e. the inverse of the variance-covariance
matrix) of the random effects.  As you might imagine one encounters
difficulties when that variance-covariance matrix approaches
singularity as it can.  The ML or REML estimates of individual
variance components can be zero or, more generally, the
variance-covariance matrix of the random effects can be singular as in
the example below.  In the development version of the lme4 package the
lmer function uses a parameterization of the variance-covariance
matrix and a method of evaluating the log-likelihood at the parameter
values that behaves smoothly as the matrix approaches singularity.
The current implementation of the mcmcsamp function is not as
well-suited to near-singular or singular variances in the random
effects.  There are ways around this.  Gelman et al. (J. Comp. Graph.
Statist., 2008) describe one such way.  I think I have another way
that fits into this framework more cleanly but I still need to
implement and test it.


On Fri, May 2, 2008 at 8:59 PM, John Maindonald
<john.maindonald at anu.edu.au> wrote:
> Dear Douglas -
> The following happens under the versions of lme4 and Matrix from R-forge:
>
>> Orthodont$logdist <- log(Orthodont$distance)
>> keep <- !(Orthodont$Subject%in%c("M04","M13"))
>> orthodont <- subset(Orthodont, keep)
>> orthodont$Subject <- factor(orthodont$Subject)
>> orthdiff.lmer <- lmer(logdist ~ Sex * I(age-11) + (I(age-11) |
> +                                                    Subject),
> +                       data=orthodont,  method="ML")
>> orthdiffr.lmer <- update(orthdiff.lmer, method="REML")
>> orth.mcmc <- mcmcsamp(orthdiffr.lmer, n=1000)
> Error in .local(object, n, verbose, ...) :
>  crossproduct matrix 1 is not positive definite
>
>> VarCorr(orthdiffr.lmer)
> $Subject
>            (Intercept) I(age - 11)
> (Intercept)   1.746e-02   1.555e-07
> I(age - 11)   1.555e-07   1.384e-12
> attr(,"stddev")
> (Intercept) I(age - 11)
>  1.322e-01   1.177e-06
> attr(,"correlation")
>            (Intercept) I(age - 11)
> (Intercept)           1           1
> I(age - 11)           1           1
>
> attr(,"sc")
> sigmaREML
>  0.05238
>
> R version 2.7.0 Patched (2008-05-01 r45578)
> i386-apple-darwin8.10.1
>
> locale:
> C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] DAAG_0.97          MASS_7.2-41        lme4_0.999375-14
> Matrix_0.999375-10
> [5] lattice_0.17-6
>
> loaded via a namespace (and not attached):
> [1] grid_2.7.0  tools_2.7.0
>
> This proceeds without error when I use the CRAN versions (albeit under
> Windows)
>
> other attached packages:
> [1] coda_0.13-1       MEMSS_0.2-4       lme4_0.99875-9    Matrix_0.999375-9
> lattice_0.17-6
>
> If I do not remove the "outliers" the calculations proceed without
> complaint.  The issue is,
> maybe, that the variance component associated with the I(age-11) slope is
> rather small?
> Regards
>
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
>
>



From Renaud.lancelot at cirad.fr  Sun May  4 00:34:53 2008
From: Renaud.lancelot at cirad.fr (Renaud.lancelot)
Date: Sun, 04 May 2008 00:34:53 +0200
Subject: [R-sig-ME] lme4 MS binary on R-Forge
In-Reply-To: <40e66e0b0805030803y777fd07fj5e1497fe856ff96e@mail.gmail.com>
References: <1B3E96FD-2747-48DB-905D-BE7DB8D52629@anu.edu.au>
	<40e66e0b0805030803y777fd07fj5e1497fe856ff96e@mail.gmail.com>
Message-ID: <481CE88D.1040203@cirad.fr>

Dear all,

There is a problem on R-Forge to get the Windows binary of lme4:

 > install.packages("lme4", lib="C:/R/RLIBS", repos = 
"http://R-Forge.R-project.org")
Warning message:
package ?lme4? is not available

I was able to download the sources.

Best,

Renaud


 > sessionInfo()
R version 2.7.0 Patched (2008-04-23 r45466)
i386-pc-mingw32

locale:
LC_COLLATE=French_France.1252;LC_CTYPE=French_France.1252;LC_MONETARY=French_France.1252;LC_NUMERIC=C;LC_TIME=French_France.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] fortunes_1.3-4

loaded via a namespace (and not attached):
[1] tools_2.7.0


-- 
Renaud Lancelot
EDEN Project, coordinator
http://www.eden-fp6project.net/

CIRAD, BIOS Department
Campus International de Baillarguet TA A-DIR / B
F34398 Montpellier
http://www.cirad.fr

Tel.  +33 4 67 59 37 17  -  Fax  +33 4 67 59 37 95
Secr. +33 4 67 59 37 37  - Cell. +33 6 77 52 08 69



From bates at stat.wisc.edu  Sun May  4 17:18:36 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sun, 4 May 2008 10:18:36 -0500
Subject: [R-sig-ME] lme4 MS binary on R-Forge
In-Reply-To: <481CE88D.1040203@cirad.fr>
References: <1B3E96FD-2747-48DB-905D-BE7DB8D52629@anu.edu.au>
	<40e66e0b0805030803y777fd07fj5e1497fe856ff96e@mail.gmail.com>
	<481CE88D.1040203@cirad.fr>
Message-ID: <40e66e0b0805040818y31994851v5d46981fea4bd2d3@mail.gmail.com>

In looking at some log files over the last few weeks I think it is
because of the configuration of the Windows compilation system for
R-forge.

Mind you,, I'm not complaining.  I consider trying to develop code on
Windows to be the sort of activity I would only agree to if members of
my family were being held hostage so I am very happy when someone else
does the Windows compilation for me.

I have just uploaded the source package to Uwe's site
http://win-builder.r-project.org/  Assuming that it builds properly I
will make the Windows binary package of the development version of the
lme4 package available as
http://www.stat.wisc.edu/~bates/lme4_0.999375-14.zip


On Sat, May 3, 2008 at 5:34 PM, Renaud.lancelot
<Renaud.lancelot at cirad.fr> wrote:
> Dear all,
>
> There is a problem on R-Forge to get the Windows binary of lme4:
>
>> install.packages("lme4", lib="C:/R/RLIBS", repos =
>> "http://R-Forge.R-project.org")
> Warning message:
> package 'lme4' is not available
>
> I was able to download the sources.
>
> Best,
>
> Renaud
>
>
>> sessionInfo()
> R version 2.7.0 Patched (2008-04-23 r45466)
> i386-pc-mingw32
>
> locale:
> LC_COLLATE=French_France.1252;LC_CTYPE=French_France.1252;LC_MONETARY=French_France.1252;LC_NUMERIC=C;LC_TIME=French_France.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] fortunes_1.3-4
>
> loaded via a namespace (and not attached):
> [1] tools_2.7.0
>
>
> --
> Renaud Lancelot
> EDEN Project, coordinator
> http://www.eden-fp6project.net/
>
> CIRAD, BIOS Department
> Campus International de Baillarguet TA A-DIR / B
> F34398 Montpellier
> http://www.cirad.fr
>
> Tel.  +33 4 67 59 37 17  -  Fax  +33 4 67 59 37 95
> Secr. +33 4 67 59 37 37  - Cell. +33 6 77 52 08 69
>



From Renaud.lancelot at cirad.fr  Sun May  4 18:37:41 2008
From: Renaud.lancelot at cirad.fr (Renaud.lancelot)
Date: Sun, 04 May 2008 18:37:41 +0200
Subject: [R-sig-ME] lme4 MS binary on R-Forge
In-Reply-To: <40e66e0b0805040818y31994851v5d46981fea4bd2d3@mail.gmail.com>
References: <1B3E96FD-2747-48DB-905D-BE7DB8D52629@anu.edu.au>	
	<40e66e0b0805030803y777fd07fj5e1497fe856ff96e@mail.gmail.com>	
	<481CE88D.1040203@cirad.fr>
	<40e66e0b0805040818y31994851v5d46981fea4bd2d3@mail.gmail.com>
Message-ID: <481DE655.6030406@cirad.fr>

Thank you very much !

Now I have the following warnings. Is this a "synchronization" issue 
with Matrix ?

Best,

Renaud

 > library(lme4)
Le chargement a n?cessit? le package : Matrix
Le chargement a n?cessit? le package : lattice

Attachement du package : 'Matrix'


         The following object(s) are masked from package:stats :

          xtabs


         The following object(s) are masked from package:base :

          rcond

Warning messages:
1: In .recacheSubclasses(def at className, def, doSubclasses) :
   Undefined subclass, "double", of class "atomicVector"; definition not 
updated
2: In .recacheSubclasses(def at className, def, doSubclasses) :
   Undefined subclass, "double", of class "index"; definition not updated
3: In .recacheSubclasses(def at className, def, doSubclasses) :
   Undefined subclass, "double", of class "number"; definition not updated
4: In .recacheSubclasses(def at className, def, doSubclasses) :
   Undefined subclass, "double", of class "replValue"; definition not 
updated
 > sessionInfo()
R version 2.7.0 Patched (2008-04-23 r45466)
i386-pc-mingw32

locale:
LC_COLLATE=French_France.1252;LC_CTYPE=French_France.1252;LC_MONETARY=French_France.1252;LC_NUMERIC=C;LC_TIME=French_France.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_0.999375-14  Matrix_0.999375-9 lattice_0.17-7    fortunes_1.3-4

loaded via a namespace (and not attached):
[1] grid_2.7.0  tools_2.7.0
 >




Douglas Bates a ?crit :
> In looking at some log files over the last few weeks I think it is
> because of the configuration of the Windows compilation system for
> R-forge.
> 
> Mind you,, I'm not complaining.  I consider trying to develop code on
> Windows to be the sort of activity I would only agree to if members of
> my family were being held hostage so I am very happy when someone else
> does the Windows compilation for me.
> 
> I have just uploaded the source package to Uwe's site
> http://win-builder.r-project.org/  Assuming that it builds properly I
> will make the Windows binary package of the development version of the
> lme4 package available as
> http://www.stat.wisc.edu/~bates/lme4_0.999375-14.zip
> 
> 
> On Sat, May 3, 2008 at 5:34 PM, Renaud.lancelot
> <Renaud.lancelot at cirad.fr> wrote:
>> Dear all,
>>
>> There is a problem on R-Forge to get the Windows binary of lme4:
>>
>>> install.packages("lme4", lib="C:/R/RLIBS", repos =
>>> "http://R-Forge.R-project.org")
>> Warning message:
>> package 'lme4' is not available
>>
>> I was able to download the sources.
>>
>> Best,
>>
>> Renaud
>>
>>
>>> sessionInfo()
>> R version 2.7.0 Patched (2008-04-23 r45466)
>> i386-pc-mingw32
>>
>> locale:
>> LC_COLLATE=French_France.1252;LC_CTYPE=French_France.1252;LC_MONETARY=French_France.1252;LC_NUMERIC=C;LC_TIME=French_France.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] fortunes_1.3-4
>>
>> loaded via a namespace (and not attached):
>> [1] tools_2.7.0
>>
>>
>> --
>> Renaud Lancelot
>> EDEN Project, coordinator
>> http://www.eden-fp6project.net/
>>
>> CIRAD, BIOS Department
>> Campus International de Baillarguet TA A-DIR / B
>> F34398 Montpellier
>> http://www.cirad.fr
>>
>> Tel.  +33 4 67 59 37 17  -  Fax  +33 4 67 59 37 95
>> Secr. +33 4 67 59 37 37  - Cell. +33 6 77 52 08 69
>>

-- 
Renaud Lancelot
EDEN Project, coordinator
http://www.eden-fp6project.net/

CIRAD, BIOS Department
Campus International de Baillarguet TA A-DIR / B
F34398 Montpellier
http://www.cirad.fr

Tel.  +33 4 67 59 37 17  -  Fax  +33 4 67 59 37 95
Secr. +33 4 67 59 37 37  - Cell. +33 6 77 52 08 69



From marshj02 at student.uwa.edu.au  Mon May  5 04:12:59 2008
From: marshj02 at student.uwa.edu.au (Julie Marsh)
Date: Mon, 05 May 2008 10:12:59 +0800
Subject: [R-sig-ME] random effects specification
In-Reply-To: <87skx2taqc.fsf@patagonia.sebmags.homelinux.org>
References: <87abkak6qa.fsf@patagonia.sebmags.homelinux.org>
	<75A3A990-0E70-4BDB-A44D-2BA011ADEA8C@kagi.com>
	<40e66e0b0804060804g494f8f59i5307444fc581227d@mail.gmail.com>
	<3D4A6791-2368-412E-A62E-BD10EFD5DA91@kagi.com>
	<87prt1ojvt.fsf@patagonia.sebmags.homelinux.org>
	<87ve2s5nax.fsf@patagonia.sebmags.homelinux.org>
	<aefe4d0a0804081031v28ebeac3t9d849213c4b1e954@mail.gmail.com>
	<87iqys5i6a.fsf@patagonia.sebmags.homelinux.org>
	<aefe4d0a0804081247x1bdcaaa2u9661b8ebfbfde9d4@mail.gmail.com>
	<873apw5blo.fsf@patagonia.sebmags.homelinux.org>
	<aefe4d0a0804081500r665d5a23gf337da3fc49aac36@mail.gmail.com>
	<87skx2taqc.fsf@patagonia.sebmags.homelinux.org>
Message-ID: <20080505101259.1sw4q617q8u8ww40@webmail-2.ucs.uwa.edu.au>

Dear Sebastian,

Sounds as if you have received great advice already.  Just a short  
note - I believe you are missing the fixed-effect intercept in your  
model which I have denoted as simply "B" in your notation below.  This  
is often denoted as Beta0 or B0 in textbooks (sorry no subscripts or  
greek letters printing in this email!).

y_{ijk} = B + B_j + B_k + B_{jk} + b_i + e_{ijk}    i=1,...,20; j=A,B; k=a,b,c

kindest regards,  julie.




Quoting "Sebastian P. Luque" <spluque at gmail.com>:

> Hi again,
>
> I've made further explorations into lmer, toying with the example I
> showed earlier:
>
>
> ---<---------------cut here---------------start-------------->---
> set.seed(1000)
> rCom <- rnorm(2, mean=5, sd=0.5)
> rTr <- rep(rCom / 1.1, 2)
> nbase <- rnorm(60, 10, 0.1)
>
> ## 20 individuals; 10 in community "A" and 10 in "B", each receiving 3
> ## different treatments once.
> dta <- within(expand.grid(community=LETTERS[1:2], treatment=letters[1:3],
>                           id=1:10), {
>                               id[community == "B"] <- id[community   
> == "B"] + 10
>                               id <- as.factor(id)
>                               n <- rCom[as.numeric(community)] +
>                                   rTr[as.numeric(treatment)] + nbase
>                           })
> dta <- dta[order(dta$id, dta$community, dta$treatment), ]
>
> ## Simulate an interaction
> dta$n[dta$community == "A"] <- rev(dta$n[dta$community == "A"])
> ## Have a look
> xyplot(n ~ treatment | community, data=dta, groups=id,
>        type="b", pch=19, cex=0.3)
>
> ## We test for community (A, B) and treatment (a, b, c) fixed effects,
> ## their interactions, and use random effects for subject (1:20).  Am I
> ## writing this correctly?
> ##
> ## y_{ijk} = B_j + B_k + B_{jk} + b_i + e_{ijk}    i=1,...,20; j=A,B; k=a,b,c
> n.lmer1 <- lmer(n ~ community * treatment + (1 | id), dta)
> ---<---------------cut here---------------end---------------->---
>
>
> I'm a bit confused whether I'm describing the model being fit correctly
> (not the lmer call, but the model description in the comment above), and
> how it could be described in matrix form.  I think this type of
> exercises would help me grasp the syntax conventions better.
>
> Another issue is that the lmer call results in a warning:
>
> ---<---------------cut here---------------start-------------->---
> Warning message:
> In .local(x, ..., value) :
>   Estimated variance for factor ?id? is effectively zero
> ---<---------------cut here---------------end---------------->---
>
>
> which I presume is due to the fact that the data are unreplicated,
> i.e. individuals get each treatment only once.  Are there any gotchas in
> the interpretation of the results after this warning?
>
> Thanks once again!
>
> --
> Seb
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From maechler at stat.math.ethz.ch  Mon May  5 09:55:30 2008
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 5 May 2008 09:55:30 +0200
Subject: [R-sig-ME] lme4 MS binary on R-Forge
In-Reply-To: <481DE655.6030406@cirad.fr>
References: <1B3E96FD-2747-48DB-905D-BE7DB8D52629@anu.edu.au>
	<40e66e0b0805030803y777fd07fj5e1497fe856ff96e@mail.gmail.com>
	<481CE88D.1040203@cirad.fr>
	<40e66e0b0805040818y31994851v5d46981fea4bd2d3@mail.gmail.com>
	<481DE655.6030406@cirad.fr>
Message-ID: <18462.48498.996523.22939@stat.math.ethz.ch>

>>>>> "Rl" == Renaud lancelot <Renaud.lancelot at cirad.fr>
>>>>>     on Sun, 04 May 2008 18:37:41 +0200 writes:

    Rl> Thank you very much !
    Rl> Now I have the following warnings. Is this a "synchronization" issue 
    Rl> with Matrix ?

    Rl> Best,

    Rl> Renaud

    >> library(lme4)
    Rl> Le chargement a n?cessit? le package : Matrix
    Rl> Le chargement a n?cessit? le package : lattice

    Rl> Attachement du package : 'Matrix'


    Rl> The following object(s) are masked from package:stats :

    Rl>    xtabs

That warning is currently unavoidable.
We intentionally have masked stats::xtabs() 
because Matrix::xtabs() is functionally a super-set of the stats
version:  The 'Matrix' one allows sparse contingency tables.

I hope that by R 2.8.0, "Matrix" will be recommended and we'll
have found a clean way to avoid the warning.


    Rl> The following object(s) are masked from package:base :

    Rl> rcond

This is a "funny". 
I don't see it in R 2.7.0 nor in a more recent version of
R-patched than yours.  
You should either upgrade your R-patched or use R 2.7.0.
Can you confirm, that then, the second warning will be gone ?

Martin

    Rl> Warning messages:
    Rl> 1: In .recacheSubclasses(def at className, def, doSubclasses) :
    Rl> Undefined subclass, "double", of class "atomicVector"; definition not 
    Rl> updated
    Rl> 2: In .recacheSubclasses(def at className, def, doSubclasses) :
    Rl> Undefined subclass, "double", of class "index"; definition not updated
    Rl> 3: In .recacheSubclasses(def at className, def, doSubclasses) :
    Rl> Undefined subclass, "double", of class "number"; definition not updated
    Rl> 4: In .recacheSubclasses(def at className, def, doSubclasses) :
    Rl> Undefined subclass, "double", of class "replValue"; definition not 
    Rl> updated

    >> sessionInfo()
    Rl> R version 2.7.0 Patched (2008-04-23 r45466)
    Rl> i386-pc-mingw32

    Rl> locale:
    Rl> LC_COLLATE=French_France.1252;LC_CTYPE=French_France.1252;LC_MONETARY=French_France.1252;LC_NUMERIC=C;LC_TIME=French_France.1252

    Rl> attached base packages:
    Rl> [1] stats     graphics  grDevices utils     datasets  methods   base

    Rl> other attached packages:
    Rl> [1] lme4_0.999375-14  Matrix_0.999375-9 lattice_0.17-7    fortunes_1.3-4

    Rl> loaded via a namespace (and not attached):
    Rl> [1] grid_2.7.0  tools_2.7.0
    >> 




    Rl> Douglas Bates a ?crit :
    >> In looking at some log files over the last few weeks I think it is
    >> because of the configuration of the Windows compilation system for
    >> R-forge.
    >> 
    >> Mind you,, I'm not complaining.  I consider trying to develop code on
    >> Windows to be the sort of activity I would only agree to if members of
    >> my family were being held hostage so I am very happy when someone else
    >> does the Windows compilation for me.
    >> 
    >> I have just uploaded the source package to Uwe's site
    >> http://win-builder.r-project.org/  Assuming that it builds properly I
    >> will make the Windows binary package of the development version of the
    >> lme4 package available as
    >> http://www.stat.wisc.edu/~bates/lme4_0.999375-14.zip
    >> 
    >> 
    >> On Sat, May 3, 2008 at 5:34 PM, Renaud.lancelot
    >> <Renaud.lancelot at cirad.fr> wrote:
    >>> Dear all,
    >>> 
    >>> There is a problem on R-Forge to get the Windows binary of lme4:
    >>> 
    >>>> install.packages("lme4", lib="C:/R/RLIBS", repos =
    >>>> "http://R-Forge.R-project.org")
    >>> Warning message:
    >>> package 'lme4' is not available
    >>> 
    >>> I was able to download the sources.
    >>> 
    >>> Best,
    >>> 
    >>> Renaud
    >>> 
    >>> 
    >>>> sessionInfo()
    >>> R version 2.7.0 Patched (2008-04-23 r45466)
    >>> i386-pc-mingw32
    >>> 
    >>> locale:
    >>> LC_COLLATE=French_France.1252;LC_CTYPE=French_France.1252;LC_MONETARY=French_France.1252;LC_NUMERIC=C;LC_TIME=French_France.1252
    >>> 
    >>> attached base packages:
    >>> [1] stats     graphics  grDevices utils     datasets  methods   base
    >>> 
    >>> other attached packages:
    >>> [1] fortunes_1.3-4
    >>> 
    >>> loaded via a namespace (and not attached):
    >>> [1] tools_2.7.0
    >>> 
    >>> 
    >>> --
    >>> Renaud Lancelot
    >>> EDEN Project, coordinator
    >>> http://www.eden-fp6project.net/
    >>> 
    >>> CIRAD, BIOS Department
    >>> Campus International de Baillarguet TA A-DIR / B
    >>> F34398 Montpellier
    >>> http://www.cirad.fr
    >>> 
    >>> Tel.  +33 4 67 59 37 17  -  Fax  +33 4 67 59 37 95
    >>> Secr. +33 4 67 59 37 37  - Cell. +33 6 77 52 08 69
    >>> 

    Rl> -- 
    Rl> Renaud Lancelot
    Rl> EDEN Project, coordinator
    Rl> http://www.eden-fp6project.net/

    Rl> CIRAD, BIOS Department
    Rl> Campus International de Baillarguet TA A-DIR / B
    Rl> F34398 Montpellier
    Rl> http://www.cirad.fr

    Rl> Tel.  +33 4 67 59 37 17  -  Fax  +33 4 67 59 37 95
    Rl> Secr. +33 4 67 59 37 37  - Cell. +33 6 77 52 08 69

    Rl> _______________________________________________
    Rl> R-sig-mixed-models at r-project.org mailing list
    Rl> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From John.Maindonald at anu.edu.au  Mon May  5 12:42:21 2008
From: John.Maindonald at anu.edu.au (John Maindonald)
Date: Mon, 5 May 2008 20:42:21 +1000
Subject: [R-sig-ME] Status of HPDinterval
Message-ID: <62279038-6004-4EA1-BF2E-8BC862835AC9@anu.edu.au>

Dear Douglas -
I'm wondering whether the output from HPDinterval()
in the new version of lme4 will (if you have made this
decision) in due course appear with the same format
as in the present coda version.  CIs for variances will
continue to be presented on a logarithmic scale?

Also, will the coda functions in due course be able to
accept the new merMCMC objects?

I am putting together a note at present, re code that
appears in our text, to which this is relevant.
Thanks
John.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.



From Renaud.lancelot at cirad.fr  Mon May  5 14:20:40 2008
From: Renaud.lancelot at cirad.fr (Renaud.lancelot)
Date: Mon, 05 May 2008 14:20:40 +0200
Subject: [R-sig-ME] lme4 MS binary on R-Forge
In-Reply-To: <18462.48498.996523.22939@stat.math.ethz.ch>
References: <1B3E96FD-2747-48DB-905D-BE7DB8D52629@anu.edu.au>	<40e66e0b0805030803y777fd07fj5e1497fe856ff96e@mail.gmail.com>	<481CE88D.1040203@cirad.fr>	<40e66e0b0805040818y31994851v5d46981fea4bd2d3@mail.gmail.com>	<481DE655.6030406@cirad.fr>
	<18462.48498.996523.22939@stat.math.ethz.ch>
Message-ID: <481EFB98.5090901@cirad.fr>

Martin Maechler a ?crit :
>>>>>> "Rl" == Renaud lancelot <Renaud.lancelot at cirad.fr>
>>>>>>     on Sun, 04 May 2008 18:37:41 +0200 writes:
> 
>     Rl> Thank you very much !
>     Rl> Now I have the following warnings. Is this a "synchronization" issue 
>     Rl> with Matrix ?
> 
>     Rl> Best,
> 
>     Rl> Renaud
> 
>     >> library(lme4)
>     Rl> Le chargement a n?cessit? le package : Matrix
>     Rl> Le chargement a n?cessit? le package : lattice
> 
>     Rl> Attachement du package : 'Matrix'
> 
> 
>     Rl> The following object(s) are masked from package:stats :
> 
>     Rl>    xtabs
> 
> That warning is currently unavoidable.
> We intentionally have masked stats::xtabs() 
> because Matrix::xtabs() is functionally a super-set of the stats
> version:  The 'Matrix' one allows sparse contingency tables.
> 
> I hope that by R 2.8.0, "Matrix" will be recommended and we'll
> have found a clean way to avoid the warning.
> 
> 
>     Rl> The following object(s) are masked from package:base :
> 
>     Rl> rcond
> 
> This is a "funny". 
> I don't see it in R 2.7.0 nor in a more recent version of
> R-patched than yours.  
> You should either upgrade your R-patched or use R 2.7.0.
> Can you confirm, that then, the second warning will be gone ?

It is still here with the latest version of R-patched:

 > library(lme4)
Le chargement a n?cessit? le package : Matrix
Le chargement a n?cessit? le package : lattice

Attachement du package : 'Matrix'


         The following object(s) are masked from package:stats :

          xtabs


         The following object(s) are masked from package:base :

          rcond

Warning messages:
1: In .recacheSubclasses(def at className, def, doSubclasses) :
   Undefined subclass, "double", of class "atomicVector"; definition not 
updated
2: In .recacheSubclasses(def at className, def, doSubclasses) :
   Undefined subclass, "double", of class "index"; definition not updated
3: In .recacheSubclasses(def at className, def, doSubclasses) :
   Undefined subclass, "double", of class "number"; definition not updated
4: In .recacheSubclasses(def at className, def, doSubclasses) :
   Undefined subclass, "double", of class "replValue"; definition not 
updated
 > sessionInfo()
R version 2.7.0 Patched (2008-05-03 r45596)
i386-pc-mingw32

locale:
LC_COLLATE=French_France.1252;LC_CTYPE=French_France.1252;LC_MONETARY=French_France.1252;LC_NUMERIC=C;LC_TIME=French_France.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_0.999375-14  Matrix_0.999375-9 lattice_0.17-7    fortunes_1.3-4

loaded via a namespace (and not attached):
[1] grid_2.7.0


Thank you for your help,

Best regards,

Renaud





 >




> 
> Martin
> 
>     Rl> Warning messages:
>     Rl> 1: In .recacheSubclasses(def at className, def, doSubclasses) :
>     Rl> Undefined subclass, "double", of class "atomicVector"; definition not 
>     Rl> updated
>     Rl> 2: In .recacheSubclasses(def at className, def, doSubclasses) :
>     Rl> Undefined subclass, "double", of class "index"; definition not updated
>     Rl> 3: In .recacheSubclasses(def at className, def, doSubclasses) :
>     Rl> Undefined subclass, "double", of class "number"; definition not updated
>     Rl> 4: In .recacheSubclasses(def at className, def, doSubclasses) :
>     Rl> Undefined subclass, "double", of class "replValue"; definition not 
>     Rl> updated
> 
>     >> sessionInfo()
>     Rl> R version 2.7.0 Patched (2008-04-23 r45466)
>     Rl> i386-pc-mingw32
> 
>     Rl> locale:
>     Rl> LC_COLLATE=French_France.1252;LC_CTYPE=French_France.1252;LC_MONETARY=French_France.1252;LC_NUMERIC=C;LC_TIME=French_France.1252
> 
>     Rl> attached base packages:
>     Rl> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
>     Rl> other attached packages:
>     Rl> [1] lme4_0.999375-14  Matrix_0.999375-9 lattice_0.17-7    fortunes_1.3-4
> 
>     Rl> loaded via a namespace (and not attached):
>     Rl> [1] grid_2.7.0  tools_2.7.0
>     >> 
> 
> 
> 
> 
>     Rl> Douglas Bates a ?crit :
>     >> In looking at some log files over the last few weeks I think it is
>     >> because of the configuration of the Windows compilation system for
>     >> R-forge.
>     >> 
>     >> Mind you,, I'm not complaining.  I consider trying to develop code on
>     >> Windows to be the sort of activity I would only agree to if members of
>     >> my family were being held hostage so I am very happy when someone else
>     >> does the Windows compilation for me.
>     >> 
>     >> I have just uploaded the source package to Uwe's site
>     >> http://win-builder.r-project.org/  Assuming that it builds properly I
>     >> will make the Windows binary package of the development version of the
>     >> lme4 package available as
>     >> http://www.stat.wisc.edu/~bates/lme4_0.999375-14.zip
>     >> 
>     >> 
>     >> On Sat, May 3, 2008 at 5:34 PM, Renaud.lancelot
>     >> <Renaud.lancelot at cirad.fr> wrote:
>     >>> Dear all,
>     >>> 
>     >>> There is a problem on R-Forge to get the Windows binary of lme4:
>     >>> 
>     >>>> install.packages("lme4", lib="C:/R/RLIBS", repos =
>     >>>> "http://R-Forge.R-project.org")
>     >>> Warning message:
>     >>> package 'lme4' is not available
>     >>> 
>     >>> I was able to download the sources.
>     >>> 
>     >>> Best,
>     >>> 
>     >>> Renaud
>     >>> 
>     >>> 
>     >>>> sessionInfo()
>     >>> R version 2.7.0 Patched (2008-04-23 r45466)
>     >>> i386-pc-mingw32
>     >>> 
>     >>> locale:
>     >>> LC_COLLATE=French_France.1252;LC_CTYPE=French_France.1252;LC_MONETARY=French_France.1252;LC_NUMERIC=C;LC_TIME=French_France.1252
>     >>> 
>     >>> attached base packages:
>     >>> [1] stats     graphics  grDevices utils     datasets  methods   base
>     >>> 
>     >>> other attached packages:
>     >>> [1] fortunes_1.3-4
>     >>> 
>     >>> loaded via a namespace (and not attached):
>     >>> [1] tools_2.7.0
>     >>> 
>     >>> 
>     >>> --
>     >>> Renaud Lancelot
>     >>> EDEN Project, coordinator
>     >>> http://www.eden-fp6project.net/
>     >>> 
>     >>> CIRAD, BIOS Department
>     >>> Campus International de Baillarguet TA A-DIR / B
>     >>> F34398 Montpellier
>     >>> http://www.cirad.fr
>     >>> 
>     >>> Tel.  +33 4 67 59 37 17  -  Fax  +33 4 67 59 37 95
>     >>> Secr. +33 4 67 59 37 37  - Cell. +33 6 77 52 08 69
>     >>> 
> 
>     Rl> -- 
>     Rl> Renaud Lancelot
>     Rl> EDEN Project, coordinator
>     Rl> http://www.eden-fp6project.net/
> 
>     Rl> CIRAD, BIOS Department
>     Rl> Campus International de Baillarguet TA A-DIR / B
>     Rl> F34398 Montpellier
>     Rl> http://www.cirad.fr
> 
>     Rl> Tel.  +33 4 67 59 37 17  -  Fax  +33 4 67 59 37 95
>     Rl> Secr. +33 4 67 59 37 37  - Cell. +33 6 77 52 08 69
> 
>     Rl> _______________________________________________
>     Rl> R-sig-mixed-models at r-project.org mailing list
>     Rl> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
Renaud Lancelot
EDEN Project, coordinator
http://www.eden-fp6project.net/

CIRAD, BIOS Department
Campus International de Baillarguet TA A-DIR / B
F34398 Montpellier
http://www.cirad.fr

Tel.  +33 4 67 59 37 17  -  Fax  +33 4 67 59 37 95
Secr. +33 4 67 59 37 37  - Cell. +33 6 77 52 08 69



From bates at stat.wisc.edu  Mon May  5 15:14:03 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 5 May 2008 08:14:03 -0500
Subject: [R-sig-ME] Status of HPDinterval
In-Reply-To: <62279038-6004-4EA1-BF2E-8BC862835AC9@anu.edu.au>
References: <62279038-6004-4EA1-BF2E-8BC862835AC9@anu.edu.au>
Message-ID: <40e66e0b0805050614s6d8c6ab3r6a55c644e76797cf@mail.gmail.com>

My intention is to modify the scale on which the estimates of the
variance components are estimated and then allow a VarCorr method for
the mcmcsamp object.  The VarCorr method will allow specification of
the scale.  The point of the new scale is that it allows the variance
components to be zero but also to switch from zero to nonzero during
the MCMC process.  It would be possible to specify an HPD interval on
the logarithm scale but, natually, there would need to be some
provision for the zeros in the chain.

Regrettably it will be at least a week or two before I can resume
coding and checking this representation and sampling method.  Another
project will dominate this week, which also is the last teaching week
of our semester.

On Mon, May 5, 2008 at 5:42 AM, John Maindonald
<John.Maindonald at anu.edu.au> wrote:
> Dear Douglas -
> I'm wondering whether the output from HPDinterval()
> in the new version of lme4 will (if you have made this
> decision) in due course appear with the same format
> as in the present coda version.  CIs for variances will
> continue to be presented on a logarithmic scale?
>
> Also, will the coda functions in due course be able to
> accept the new merMCMC objects?
>
> I am putting together a note at present, re code that
> appears in our text, to which this is relevant.
> Thanks
> John.
>
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
>
>



From spluque at gmail.com  Mon May  5 23:40:04 2008
From: spluque at gmail.com (Sebastian P. Luque)
Date: Mon, 05 May 2008 16:40:04 -0500
Subject: [R-sig-ME] random effects specification
References: <87abkak6qa.fsf@patagonia.sebmags.homelinux.org>
	<75A3A990-0E70-4BDB-A44D-2BA011ADEA8C@kagi.com>
	<40e66e0b0804060804g494f8f59i5307444fc581227d@mail.gmail.com>
	<3D4A6791-2368-412E-A62E-BD10EFD5DA91@kagi.com>
	<87prt1ojvt.fsf@patagonia.sebmags.homelinux.org>
	<87ve2s5nax.fsf@patagonia.sebmags.homelinux.org>
	<aefe4d0a0804081031v28ebeac3t9d849213c4b1e954@mail.gmail.com>
	<87iqys5i6a.fsf@patagonia.sebmags.homelinux.org>
	<aefe4d0a0804081247x1bdcaaa2u9661b8ebfbfde9d4@mail.gmail.com>
	<873apw5blo.fsf@patagonia.sebmags.homelinux.org>
	<aefe4d0a0804081500r665d5a23gf337da3fc49aac36@mail.gmail.com>
	<87skx2taqc.fsf@patagonia.sebmags.homelinux.org>
	<20080505101259.1sw4q617q8u8ww40@webmail-2.ucs.uwa.edu.au>
Message-ID: <87lk2obfbf.fsf@patagonia.sebmags.homelinux.org>

Dear lmers,

Indeed this has been a very helpful thread.  Thanks to all for your
feedback/time!

All the best,
Sebastian



On Mon, 05 May 2008 10:12:59 +0800,
Julie Marsh <marshj02 at student.uwa.edu.au> wrote:

> Dear Sebastian, Sounds as if you have received great advice already.
> Just a short note - I believe you are missing the fixed-effect
> intercept in your model which I have denoted as simply "B" in your
> notation below.  This is often denoted as Beta0 or B0 in textbooks
> (sorry no subscripts or greek letters printing in this email!).

> y_{ijk} = B + B_j + B_k + B_{jk} + b_i + e_{ijk} i=1,...,20; j=A,B;
> k=a,b,c

> kindest regards, julie.




> Quoting "Sebastian P. Luque"
> <spluque at gmail.com>:

>> Hi again,

>> I've made further explorations into lmer, toying with the example I
>> showed earlier:


>> ---<---------------cut here---------------start-------------->---
>> set.seed(1000) rCom <- rnorm(2, mean=5, sd=0.5) rTr <- rep(rCom /
>> 1.1, 2) nbase <- rnorm(60, 10, 0.1)

>> ## 20 individuals; 10 in community "A" and 10 in "B", each receiving
>> 3 ## different treatments once.  dta <-
>> within(expand.grid(community=LETTERS[1:2], treatment=letters[1:3],
>> id=1:10), { id[community == "B"] <- id[community == "B"] + 10 id <-
>> as.factor(id) n <- rCom[as.numeric(community)] +
>> rTr[as.numeric(treatment)] + nbase }) dta <- dta[order(dta$id,
>> dta$community, dta$treatment), ]

>> ## Simulate an interaction dta$n[dta$community == "A"] <-
>> rev(dta$n[dta$community == "A"]) ## Have a look xyplot(n ~ treatment
>> | community, data=dta, groups=id, type="b", pch=19, cex=0.3)

>> ## We test for community (A, B) and treatment (a, b, c) fixed
>> effects, ## their interactions, and use random effects for subject
>> (1:20).  Am I ## writing this correctly?  ## ## y_{ijk} = B_j + B_k +
>> B_{jk} + b_i + e_{ijk} i=1,...,20; j=A,B; k=a,b,c n.lmer1 <- lmer(n ~
>> community * treatment + (1 | id), dta) ---<---------------cut
>> here---------------end---------------->---


>> I'm a bit confused whether I'm describing the model being fit
>> correctly (not the lmer call, but the model description in the
>> comment above), and how it could be described in matrix form.  I
>> think this type of exercises would help me grasp the syntax
>> conventions better.

>> Another issue is that the lmer call results in a warning:

>> ---<---------------cut here---------------start-------------->---
>> Warning message: In .local(x, ..., value) : Estimated variance for
>> factor ?id? is effectively zero ---<---------------cut
>> here---------------end---------------->---


>> which I presume is due to the fact that the data are unreplicated,
>> i.e. individuals get each treatment only once.  Are there any gotchas
>> in the interpretation of the results after this warning?

>> Thanks once again!

>> -- Seb

>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing
>> list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models




Cheers,

-- 
Seb



From mwkimpel at gmail.com  Tue May  6 16:23:08 2008
From: mwkimpel at gmail.com (Mark Kimpel)
Date: Tue, 6 May 2008 10:23:08 -0400
Subject: [R-sig-ME] mixed-effects model specification question
Message-ID: <6b93d1830805060723q797961dds720c79e732e86894@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080506/f4a6b073/attachment.pl>

From A.Robinson at ms.unimelb.edu.au  Tue May  6 22:19:00 2008
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Wed, 7 May 2008 06:19:00 +1000
Subject: [R-sig-ME] mixed-effects model specification question
In-Reply-To: <6b93d1830805060723q797961dds720c79e732e86894@mail.gmail.com>
References: <6b93d1830805060723q797961dds720c79e732e86894@mail.gmail.com>
Message-ID: <20080506201900.GQ1433@ms.unimelb.edu.au>

Mark,

You should talk to a local statistician about this, but I think that
you can probably average across the measurements within each rat, if
all you are interested in is a treatment effect.  For the analysis of
treatment the relevant unit of replication should be the rat, in any
case.

(Does anyone have any thoughts on why that might be a bad idea?)

Also if I understand your design, there are three batches per rat.  I
suspect that using Rat/Tissue would lead to an over-parametrized
model, if my interpretation is correct.  My guess is that Rat should
be adequate.

Final points

1) My speculations would be better-informed if you showed us the
   output of the model that you proposed - fyi :) .

2) You could try all three configurations and see if it makes any
   difference to the inference of interest.  I suspect that it will
   not.

I hope that this helps,

Andrew

On Tue, May 06, 2008 at 10:23:08AM -0400, Mark Kimpel wrote:
> Perhaps a bit of a newbie question, but I need to get this right. I need to
> make sure I am specifying a model correctly. Here is our less-than-perfect
> experimental design:
> 
> 36 rats divided into two treatment groups, i.e. 18 per group
> 
> each rat has measurements taken on 3 brain regions, but each brain region
> was analyzed in a separate batch (there are strong batch effects) so we
> really can't compare the regions per se, but do recognize that the 3 regions
> from a single rat have variance above and beyond that accounted for by
> technical factors. Since, because of the batch effect we are not going to
> look at the effect of brain region, I "think" this should be a considered a
> random effect.
> 
> So I have rat, treatment, and region(batch) as variables. The only thing I
> am interested in getting a p-value for is treatment.
> 
> Is the model below correct and can I squeek by with using nlme to get a
> p-value (notwithstanding recent threads on this list)?
> 
>  myModel <- lme(fixed = geneExpression ~  Treatment,  random = ~1 |
> Rat/Tissue)
> 
> Thanks,
> Mark
> -- 
> Mark W. Kimpel MD ** Neuroinformatics ** Dept. of Psychiatry
> Indiana University School of Medicine
> 
> 15032 Hunter Court, Westfield, IN 46074
> 
> (317) 490-5129 Work, & Mobile & VoiceMail
> (317) 663-0513 Home (no voice mail please)
> 
> ******************************************************************
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From Antonio_Paredes at aphis.usda.gov  Tue May  6 22:42:07 2008
From: Antonio_Paredes at aphis.usda.gov (Antonio_Paredes at aphis.usda.gov)
Date: Tue, 6 May 2008 15:42:07 -0500
Subject: [R-sig-ME] mixed-effects model specification question
In-Reply-To: <20080506201900.GQ1433@ms.unimelb.edu.au>
Message-ID: <OFC98EF1CC.76E06E62-ON86257441.007126F8-86257441.00710356@aphis.usda.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080506/193b327b/attachment.pl>

From A.Robinson at ms.unimelb.edu.au  Tue May  6 23:36:24 2008
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Wed, 7 May 2008 07:36:24 +1000
Subject: [R-sig-ME] mixed-effects model specification question
In-Reply-To: <OFC98EF1CC.76E06E62-ON86257441.007126F8-86257441.00710356@aphis.usda.gov>
References: <20080506201900.GQ1433@ms.unimelb.edu.au>
	<OFC98EF1CC.76E06E62-ON86257441.007126F8-86257441.00710356@aphis.usda.gov>
Message-ID: <20080506213624.GT1433@ms.unimelb.edu.au>

Hi Tony,

On Tue, May 06, 2008 at 03:42:07PM -0500, Antonio_Paredes at aphis.usda.gov wrote:
>    How were animals allocated to treatments (at random)? What about the
>    housing of the animals. Both of these factors could be influential in
>    selecting the unit of study.

you're absolutely right.  My response was based on the information
presented, but there could have been relevant information omitted.

>    You also need to get an ideal at to why a p-value is enough to support
>    the objective of the study. Why not estimation of treatment effects?
>    Tony.

again, you are correct.  I'm kicking myself for missing that angle.
Treatment effects and confidence intervals should also be considered.

Cheers

Andrew

>    Andrew Robinson <A.Robinson at ms.unimelb.edu.au>
>    Sent by: r-sig-mixed-models-bounces at r-project.org
> 
>    05/06/2008 03:19 PM
> 
>                                                                         To
> 
>    Mark Kimpel <mwkimpel at gmail.com>
> 
>                                                                         cc
> 
>    r-sig-mixed-models at r-project.org
> 
>                                                                    Subject
> 
>    Re: [R-sig-ME] mixed-effects model specification question
> 
>    Mark,
>    You should talk to a local statistician about this, but I think that
>    you can probably average across the measurements within each rat, if
>    all you are interested in is a treatment effect.  For the analysis of
>    treatment the relevant unit of replication should be the rat, in any
>    case.
>    (Does anyone have any thoughts on why that might be a bad idea?)
>    Also if I understand your design, there are three batches per rat.  I
>    suspect that using Rat/Tissue would lead to an over-parametrized
>    model, if my interpretation is correct.  My guess is that Rat should
>    be adequate.
>    Final points
>    1) My speculations would be better-informed if you showed us the
>      output of the model that you proposed - fyi :) .
>    2) You could try all three configurations and see if it makes any
>      difference to the inference of interest.  I suspect that it will
>      not.
>    I hope that this helps,
>    Andrew
>    On Tue, May 06, 2008 at 10:23:08AM -0400, Mark Kimpel wrote:
>    > Perhaps a bit of a newbie question, but I need to get this right. I
>    need to
>    > make sure I am specifying a model correctly. Here is our
>    less-than-perfect
>    > experimental design:
>    >
>    > 36 rats divided into two treatment groups, i.e. 18 per group
>    >
>    > each rat has measurements taken on 3 brain regions, but each brain
>    region
>    > was analyzed in a separate batch (there are strong batch effects) so
>    we
>    > really can't compare the regions per se, but do recognize that the 3
>    regions
>    > from a single rat have variance above and beyond that accounted for
>    by
>    > technical factors. Since, because of the batch effect we are not
>    going to
>    > look at the effect of brain region, I "think" this should be a
>    considered a
>    > random effect.
>    >
>    > So I have rat, treatment, and region(batch) as variables. The only
>    thing I
>    > am interested in getting a p-value for is treatment.
>    >
>    > Is the model below correct and can I squeek by with using nlme to get
>    a
>    > p-value (notwithstanding recent threads on this list)?
>    >
>    >  myModel <- lme(fixed = geneExpression ~  Treatment,  random = ~1 |
>    > Rat/Tissue)
>    >
>    > Thanks,
>    > Mark
>    > --
>    > Mark W. Kimpel MD ** Neuroinformatics ** Dept. of Psychiatry
>    > Indiana University School of Medicine
>    >
>    > 15032 Hunter Court, Westfield, IN 46074
>    >
>    > (317) 490-5129 Work, & Mobile & VoiceMail
>    > (317) 663-0513 Home (no voice mail please)
>    >
>    > ******************************************************************
>    >
>    >                  [[alternative HTML version deleted]]
>    >
>    > _______________________________________________
>    > R-sig-mixed-models at r-project.org mailing list
>    > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>    --
>    Andrew Robinson
>    Department of Mathematics and Statistics            Tel:
>    +61-3-8344-6410
>    University of Melbourne, VIC 3010 Australia         Fax:
>    +61-3-8344-4599
>    http://www.ms.unimelb.edu.au/~andrewpr
>    http://blogs.mbs.edu/fishing-in-the-bay/
>    _______________________________________________
>    R-sig-mixed-models at r-project.org mailing list
>    https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From mwkimpel at gmail.com  Wed May  7 02:56:51 2008
From: mwkimpel at gmail.com (Mark Kimpel)
Date: Tue, 6 May 2008 20:56:51 -0400
Subject: [R-sig-ME] mixed-effects model specification question
In-Reply-To: <OFC98EF1CC.76E06E62-ON86257441.007126F8-86257441.00710356@aphis.usda.gov>
References: <20080506201900.GQ1433@ms.unimelb.edu.au>
	<OFC98EF1CC.76E06E62-ON86257441.007126F8-86257441.00710356@aphis.usda.gov>
Message-ID: <6b93d1830805061756m29f73ae6u56e1cb3d8a576e4c@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080506/c8787af5/attachment.pl>

From kingsfordjones at gmail.com  Wed May  7 06:26:10 2008
From: kingsfordjones at gmail.com (Kingsford Jones)
Date: Tue, 6 May 2008 21:26:10 -0700
Subject: [R-sig-ME] mixed-effects model specification question
In-Reply-To: <6b93d1830805061756m29f73ae6u56e1cb3d8a576e4c@mail.gmail.com>
References: <20080506201900.GQ1433@ms.unimelb.edu.au>
	<OFC98EF1CC.76E06E62-ON86257441.007126F8-86257441.00710356@aphis.usda.gov>
	<6b93d1830805061756m29f73ae6u56e1cb3d8a576e4c@mail.gmail.com>
Message-ID: <2ad0cc110805062126p6552c815vfd24b7a7a0f31356@mail.gmail.com>

Mark,

If you have just 3 observations per rat (and 2 missing values, judging
by the reported sample size), that implies 1 observation within a
tissue sample within a rat.  So, unless I'm missing something, the
residual variance and tissue-in-rat variance are confounded and there
are not sufficient degrees of freedom to estimate both.  What does the
output of "intervals(myModel)" report?  I'm guessing you'll get an
error about a non-positive-definite covariance matrix or a CI for a
variance component that is essentially +/-Inf.  Even if the experiment
were conducted perfectly and you could ignore effects such as those
brought up by Antonio, you are trying to fit a model that is too
complex for the available data.

Kingsford Jones

On Tue, May 6, 2008 at 5:56 PM, Mark Kimpel <mwkimpel at gmail.com> wrote:
> The "treatments" are actually two selectively bred lines of rats, with 6
>  animals from each line. We need p-values as a filter to determine which of
>  ~31,000 genes on the array are significant. The p-values are subjected to
>  FDR correction, of course. I've never seen a micro-array paper published
>  without p-values.
>
>  As for Andrew's comments:
>  1. yes, there are three measurments taken per rat, but they are from
>  different brain regions. Since each brain region was processed separately,
>  however, the region and batch effects cannot be separated. Having said that,
>  I still label this factor as "region" in my model.
>  2. In the past I have done exactly as you suggested and averaged brain
>  regions, but I was hoping nlme would allow for more sophistication. Because
>  certain genes vary greatly across brain regions, averaging would seem to
>  discard some useful information which could be used to improve the inference
>  made on treatment effect. If I used averaging, I would just have 12
>  measurements made on 12 rats and could do a simple t-test, but I don't think
>  that would be preferable, would it?
>
>  Here is the output of my model:
>
>
>      myModel <- lme(fixed = geneExpression ~  Treatment,  random = ~1 |
>  Rat/Tissue)
>  > myModel
>  Linear mixed-effects model fit by REML
>   Data: NULL
>   Log-restricted-likelihood: 40.60593
>   Fixed: geneExpression ~ Treatment
>   (Intercept) TreatmentLAD
>  12.628465893 -0.009280945
>
>  Random effects:
>   Formula: ~1 | Rat
>          (Intercept)
>  StdDev: 2.752519e-06
>
>   Formula: ~1 | Tissue %in% Rat
>         (Intercept)     Residual
>  StdDev:  0.06226097 0.0002623086
>
>  Number of Observations: 34
>  Number of Groups:
>             Rat Tissue %in% Rat
>              12              34
>  > summary(myModel)
>  Linear mixed-effects model fit by REML
>   Data: NULL
>         AIC       BIC   logLik
>   -71.21185 -63.88317 40.60593
>
>  Random effects:
>   Formula: ~1 | Rat
>          (Intercept)
>  StdDev: 2.752519e-06
>
>   Formula: ~1 | Tissue %in% Rat
>         (Intercept)     Residual
>  StdDev:  0.06226097 0.0002623086
>
>  Fixed effects: geneExpression ~ Treatment
>                  Value  Std.Error DF  t-value p-value
>  (Intercept)  12.628466 0.01510064 22 836.2870  0.0000
>  TreatmentLAD -0.009281 0.02135553 10  -0.4346  0.6731
>   Correlation:
>              (Intr)
>  TreatmentLAD -0.707
>
>  Standardized Within-Group Residuals:
>           Min            Q1           Med            Q3           Max
>  -0.0083222376 -0.0027523180 -0.0001242287  0.0034693142  0.0087149017
>
>  Number of Observations: 34
>  Number of Groups:
>             Rat Tissue %in% Rat
>              12              34
>
>
> >
>
>  On Tue, May 6, 2008 at 4:42 PM, <Antonio_Paredes at aphis.usda.gov> wrote:
>
>  >
>  > How were animals allocated to treatments (at random)? What about the
>  > housing of the animals. Both of these factors could be influential in
>  > selecting the unit of study.
>  >
>  > You also need to get an ideal at to why a p-value is enough to support the
>  > objective of the study. Why not estimation of treatment effects?
>  >
>  > Tony.
>  >
>  >
>  >  *Andrew Robinson <A.Robinson at ms.unimelb.edu.au>*
>  > Sent by: r-sig-mixed-models-bounces at r-project.org
>  >
>  > 05/06/2008 03:19 PM
>  >   To
>  > Mark Kimpel <mwkimpel at gmail.com>  cc
>  > r-sig-mixed-models at r-project.org
>  >  Subject
>  > Re: [R-sig-ME] mixed-effects model specification question
>  >
>  >
>  >
>  >
>  > Mark,
>  >
>  > You should talk to a local statistician about this, but I think that
>  > you can probably average across the measurements within each rat, if
>  > all you are interested in is a treatment effect.  For the analysis of
>  > treatment the relevant unit of replication should be the rat, in any
>  > case.
>  >
>  > (Does anyone have any thoughts on why that might be a bad idea?)
>  >
>  > Also if I understand your design, there are three batches per rat.  I
>  > suspect that using Rat/Tissue would lead to an over-parametrized
>  > model, if my interpretation is correct.  My guess is that Rat should
>  > be adequate.
>  >
>  > Final points
>  >
>  > 1) My speculations would be better-informed if you showed us the
>  >   output of the model that you proposed - fyi :) .
>  >
>  > 2) You could try all three configurations and see if it makes any
>  >   difference to the inference of interest.  I suspect that it will
>  >   not.
>  >
>  > I hope that this helps,
>  >
>  > Andrew
>  >
>  > On Tue, May 06, 2008 at 10:23:08AM -0400, Mark Kimpel wrote:
>  > > Perhaps a bit of a newbie question, but I need to get this right. I need
>  > to
>  > > make sure I am specifying a model correctly. Here is our
>  > less-than-perfect
>  > > experimental design:
>  > >
>  > > 36 rats divided into two treatment groups, i.e. 18 per group
>  > >
>  > > each rat has measurements taken on 3 brain regions, but each brain
>  > region
>  > > was analyzed in a separate batch (there are strong batch effects) so we
>  > > really can't compare the regions per se, but do recognize that the 3
>  > regions
>  > > from a single rat have variance above and beyond that accounted for by
>  > > technical factors. Since, because of the batch effect we are not going
>  > to
>  > > look at the effect of brain region, I "think" this should be a
>  > considered a
>  > > random effect.
>  > >
>  > > So I have rat, treatment, and region(batch) as variables. The only thing
>  > I
>  > > am interested in getting a p-value for is treatment.
>  > >
>  > > Is the model below correct and can I squeek by with using nlme to get a
>  > > p-value (notwithstanding recent threads on this list)?
>  > >
>  > >  myModel <- lme(fixed = geneExpression ~  Treatment,  random = ~1 |
>  > > Rat/Tissue)
>  > >
>  > > Thanks,
>  > > Mark
>  > > --
>  > > Mark W. Kimpel MD ** Neuroinformatics ** Dept. of Psychiatry
>  > > Indiana University School of Medicine
>  > >
>  > > 15032 Hunter Court, Westfield, IN 46074
>  > >
>  > > (317) 490-5129 Work, & Mobile & VoiceMail
>  > > (317) 663-0513 Home (no voice mail please)
>  > >
>  > > ******************************************************************
>  > >
>  > >                  [[alternative HTML version deleted]]
>  > >
>  > > _______________________________________________
>  > > R-sig-mixed-models at r-project.org mailing list
>  > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>  >
>  > --
>  > Andrew Robinson
>  > Department of Mathematics and Statistics            Tel: +61-3-8344-6410
>  > University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
>  > http://www.ms.unimelb.edu.au/~andrewpr<http://www.ms.unimelb.edu.au/%7Eandrewpr>
>
> > http://blogs.mbs.edu/fishing-in-the-bay/
>  >
>  > _______________________________________________
>  > R-sig-mixed-models at r-project.org mailing list
>  > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>  >
>  >
>
>
>
>
> --
>  Mark W. Kimpel MD ** Neuroinformatics ** Dept. of Psychiatry
>  Indiana University School of Medicine
>
>  15032 Hunter Court, Westfield, IN 46074
>
>  (317) 490-5129 Work, & Mobile & VoiceMail
>  (317) 663-0513 Home (no voice mail please)
>
>  ********************************************************** ********
>
>         [[alternative HTML version deleted]]
>
>  _______________________________________________
>  R-sig-mixed-models at r-project.org mailing list
>  https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From A.Robinson at ms.unimelb.edu.au  Wed May  7 07:35:27 2008
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Wed, 7 May 2008 15:35:27 +1000
Subject: [R-sig-ME] mixed-effects model specification question
In-Reply-To: <6b93d1830805061756m29f73ae6u56e1cb3d8a576e4c@mail.gmail.com>
References: <20080506201900.GQ1433@ms.unimelb.edu.au>
	<OFC98EF1CC.76E06E62-ON86257441.007126F8-86257441.00710356@aphis.usda.gov>
	<6b93d1830805061756m29f73ae6u56e1cb3d8a576e4c@mail.gmail.com>
Message-ID: <20080507053527.GF54465@ms.unimelb.edu.au>

On Tue, May 06, 2008 at 08:56:51PM -0400, Mark Kimpel wrote:
>    The "treatments" are actually two selectively bred lines of rats, with
>    6 animals from each line. We need p-values as a filter to determine
>    which of ~31,000 genes on the array are significant. The p-values are
>    subjected to FDR correction, of course. I've never seen a micro-array
>    paper published without p-values.
>    As for Andrew's comments:
>    1. yes, there are three measurments taken per rat, but they are from
>    different brain regions. Since each brain region was processed
>    separately, however, the region and batch effects cannot be separated.
>    Having said that, I still label this factor as "region" in my model.

I'm a bit confused still - sorry - do you therefore have three batches
per rat, for a total of 36 batches (with two missing possibly)?  If so
then I still think that your model is over-parametrized, and that you
can eliminate the Tissue random effect, based on your model output
below (thanks for including it).

>    2. In the past I have done exactly as you suggested and averaged brain
>    regions, but I was hoping nlme would allow for more sophistication.
>    Because certain genes vary greatly across brain regions, averaging
>    would seem to discard some useful information which could be used to
>    improve the inference made on treatment effect. 

Can you specify exactly what useful information is being used in the
analysis that would be discarded if you took averages?

>    If I used averaging, I would just have 12 measurements made on 12
>    rats and could do a simple t-test, but I don't think that would
>    be preferable, would it?

It's not clear to me that the conclusions will be different.  If not,
then the simpler analysis seems to be the better one.  I would suggest
that you compare them and see what happens.

Cheers,

Andrew

>    Here is the output of my model:
>         myModel <- lme(fixed = geneExpression ~  Treatment,  random = ~1 |
>    Rat/Tissue)
>    > myModel
>    Linear mixed-effects model fit by REML
>      Data: NULL
>      Log-restricted-likelihood: 40.60593
>      Fixed: geneExpression ~ Treatment
>     (Intercept) TreatmentLAD
>    12.628465893 -0.009280945
>    Random effects:
>     Formula: ~1 | Rat
>             (Intercept)
>    StdDev: 2.752519e-06
>     Formula: ~1 | Tissue %in% Rat
>            (Intercept)     Residual
>    StdDev:  0.06226097 0.0002623086
>    Number of Observations: 34
>    Number of Groups:
>                Rat Tissue %in% Rat
>                 12              34
>    > summary(myModel)
>    Linear mixed-effects model fit by REML
>     Data: NULL
>            AIC       BIC   logLik
>      -71.21185 -63.88317 40.60593
>    Random effects:
>     Formula: ~1 | Rat
>             (Intercept)
>    StdDev: 2.752519e-06
>     Formula: ~1 | Tissue %in% Rat
>            (Intercept)     Residual
>    StdDev:  0.06226097 0.0002623086
>    Fixed effects: geneExpression ~ Treatment
>                     Value  Std.Error DF  t-value p-value
>    (Intercept)  12.628466 0.01510064 22 836.2870  0.0000
>    TreatmentLAD -0.009281 0.02135553 10  -0.4346  0.6731
>     Correlation:
>                 (Intr)
>    TreatmentLAD -0.707
>    Standardized Within-Group Residuals:
>              Min            Q1           Med            Q3           Max
>    -0.0083222376 -0.0027523180 -0.0001242287  0.0034693142  0.0087149017
>    Number of Observations: 34
>    Number of Groups:
>                Rat Tissue %in% Rat
>                 12              34
>    >
> 
>    On Tue, May 6, 2008 at 4:42 PM, <[1]Antonio_Paredes at aphis.usda.gov>
>    wrote:
> 
>      How were animals allocated to treatments (at random)? What about the
>      housing of the animals. Both of these factors could be influential
>      in selecting the unit of study.
>      You also need to get an ideal at to why a p-value is enough to
>      support the objective of the study. Why not estimation of treatment
>      effects?
>      Tony.
> 
>    Andrew Robinson <[2]A.Robinson at ms.unimelb.edu.au>
>    Sent by: [3]r-sig-mixed-models-bounces at r-project.org
> 
>    05/06/2008 03:19 PM
> 
>                                                                         To
> 
>    Mark Kimpel <[4]mwkimpel at gmail.com>
> 
>                                                                         cc
> 
>    [5]r-sig-mixed-models at r-project.org
> 
>                                                                    Subject
> 
>    Re: [R-sig-ME] mixed-effects model specification question
> 
>    Mark,
>    You should talk to a local statistician about this, but I think that
>    you can probably average across the measurements within each rat, if
>    all you are interested in is a treatment effect.  For the analysis of
>    treatment the relevant unit of replication should be the rat, in any
>    case.
>    (Does anyone have any thoughts on why that might be a bad idea?)
>    Also if I understand your design, there are three batches per rat.  I
>    suspect that using Rat/Tissue would lead to an over-parametrized
>    model, if my interpretation is correct.  My guess is that Rat should
>    be adequate.
>    Final points
>    1) My speculations would be better-informed if you showed us the
>      output of the model that you proposed - fyi :) .
>    2) You could try all three configurations and see if it makes any
>      difference to the inference of interest.  I suspect that it will
>      not.
>    I hope that this helps,
>    Andrew
>    On Tue, May 06, 2008 at 10:23:08AM -0400, Mark Kimpel wrote:
>    > Perhaps a bit of a newbie question, but I need to get this right. I
>    need to
>    > make sure I am specifying a model correctly. Here is our
>    less-than-perfect
>    > experimental design:
>    >
>    > 36 rats divided into two treatment groups, i.e. 18 per group
>    >
>    > each rat has measurements taken on 3 brain regions, but each brain
>    region
>    > was analyzed in a separate batch (there are strong batch effects) so
>    we
>    > really can't compare the regions per se, but do recognize that the 3
>    regions
>    > from a single rat have variance above and beyond that accounted for
>    by
>    > technical factors. Since, because of the batch effect we are not
>    going to
>    > look at the effect of brain region, I "think" this should be a
>    considered a
>    > random effect.
>    >
>    > So I have rat, treatment, and region(batch) as variables. The only
>    thing I
>    > am interested in getting a p-value for is treatment.
>    >
>    > Is the model below correct and can I squeek by with using nlme to get
>    a
>    > p-value (notwithstanding recent threads on this list)?
>    >
>    >  myModel <- lme(fixed = geneExpression ~  Treatment,  random = ~1 |
>    > Rat/Tissue)
>    >
>    > Thanks,
>    > Mark
>    > --
>    > Mark W. Kimpel MD ** Neuroinformatics ** Dept. of Psychiatry
>    > Indiana University School of Medicine
>    >
>    > 15032 Hunter Court, Westfield, IN 46074
>    >
>    > (317) 490-5129 Work, & Mobile & VoiceMail
>    > (317) 663-0513 Home (no voice mail please)
>    >
>    > ******************************************************************
>    >
>    >                  [[alternative HTML version deleted]]
>    >
>    > _______________________________________________
>    > [6]R-sig-mixed-models at r-project.org mailing list
>    > [7]https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>    --
>    Andrew Robinson
>    Department of Mathematics and Statistics            Tel:
>    +61-3-8344-6410
>    University of Melbourne, VIC 3010 Australia         Fax:
>    +61-3-8344-4599
>    [8]http://www.ms.unimelb.edu.au/~andrewpr
>    [9]http://blogs.mbs.edu/fishing-in-the-bay/
>    _______________________________________________
>    [10]R-sig-mixed-models at r-project.org mailing list
>    [11]https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
>    --
>    Mark W. Kimpel MD ** Neuroinformatics ** Dept. of Psychiatry
>    Indiana University School of Medicine
>    15032 Hunter Court, Westfield, IN 46074
>    (317) 490-5129 Work, & Mobile & VoiceMail
>    (317) 663-0513 Home (no voice mail please)
>    ********************************************************** ********
> 
> References
> 
>    1. mailto:Antonio_Paredes at aphis.usda.gov
>    2. mailto:A.Robinson at ms.unimelb.edu.au
>    3. mailto:r-sig-mixed-models-bounces at r-project.org
>    4. mailto:mwkimpel at gmail.com
>    5. mailto:r-sig-mixed-models at r-project.org
>    6. mailto:R-sig-mixed-models at r-project.org
>    7. https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>    8. http://www.ms.unimelb.edu.au/%7Eandrewpr
>    9. http://blogs.mbs.edu/fishing-in-the-bay/
>   10. mailto:R-sig-mixed-models at r-project.org
>   11. https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From mwkimpel at gmail.com  Wed May  7 07:49:28 2008
From: mwkimpel at gmail.com (Mark Kimpel)
Date: Wed, 7 May 2008 01:49:28 -0400
Subject: [R-sig-ME] mixed-effects model specification question
In-Reply-To: <2ad0cc110805062126p6552c815vfd24b7a7a0f31356@mail.gmail.com>
References: <20080506201900.GQ1433@ms.unimelb.edu.au>
	<OFC98EF1CC.76E06E62-ON86257441.007126F8-86257441.00710356@aphis.usda.gov>
	<6b93d1830805061756m29f73ae6u56e1cb3d8a576e4c@mail.gmail.com>
	<2ad0cc110805062126p6552c815vfd24b7a7a0f31356@mail.gmail.com>
Message-ID: <6b93d1830805062249s50938a04ya3640386013f0334@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080507/58444d26/attachment.pl>

From mwkimpel at gmail.com  Wed May  7 07:57:41 2008
From: mwkimpel at gmail.com (Mark Kimpel)
Date: Wed, 7 May 2008 01:57:41 -0400
Subject: [R-sig-ME] mixed-effects model specification question
In-Reply-To: <20080507053527.GF54465@ms.unimelb.edu.au>
References: <20080506201900.GQ1433@ms.unimelb.edu.au>
	<OFC98EF1CC.76E06E62-ON86257441.007126F8-86257441.00710356@aphis.usda.gov>
	<6b93d1830805061756m29f73ae6u56e1cb3d8a576e4c@mail.gmail.com>
	<20080507053527.GF54465@ms.unimelb.edu.au>
Message-ID: <6b93d1830805062257r2adeaf8an89111ee1ed828b9a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080507/2837e34c/attachment.pl>

From A.Robinson at ms.unimelb.edu.au  Wed May  7 10:45:19 2008
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Wed, 7 May 2008 18:45:19 +1000
Subject: [R-sig-ME] mixed-effects model specification question
In-Reply-To: <6b93d1830805062257r2adeaf8an89111ee1ed828b9a@mail.gmail.com>
References: <20080506201900.GQ1433@ms.unimelb.edu.au>
	<OFC98EF1CC.76E06E62-ON86257441.007126F8-86257441.00710356@aphis.usda.gov>
	<6b93d1830805061756m29f73ae6u56e1cb3d8a576e4c@mail.gmail.com>
	<20080507053527.GF54465@ms.unimelb.edu.au>
	<6b93d1830805062257r2adeaf8an89111ee1ed828b9a@mail.gmail.com>
Message-ID: <20080507084519.GZ1433@ms.unimelb.edu.au>

Hi Mark,

On Wed, May 07, 2008 at 01:57:41AM -0400, Mark Kimpel wrote:
>    Andrew, our emails must have crossed on the net. You have come to
>    essentially the same conclusion as I, that Tissue/Region should be
>    discarded as an effect and the 3 samples per rat treated equally. What
>    you seem to be suggesting, however, is that averaging these 3 samples
>    to come up with one summary measure per animal, and thus performing a
>    t-test on 2 groups of 6 animals, would be the same as using all 36
>    measurements with rat as a random effect. I'm not a statistician, but
>    it seems to me that those 3 measurements within each rat give some
>    information about the reliability of those measurements and thus would
>    contribute useful information to the model. If, for example, the
>    variance within animal was much greater than the variance between
>    animals, then even if the means between the groups were different, I
>    would have less confidence that the population means were different
>    than I would if the measurements were tightly grouped within animal.
>    (I'm ignoring, for simplification, the within-group between-animal
>    variance).

yes, I see your reasoning.  I suspect that the within-rat variance
would have to be quite large to make an effect, but as you say, you
can try it both ways.  

Cheers

Andrew

>    I guess the only way to know for sure would be to do it both ways and
>    see if the conclusions were any different. Since I will be repeating
>    this over 31,000 genes, any difference between the approaches should be
>    apparent.
>    Mark
> 
>    On Wed, May 7, 2008 at 1:35 AM, Andrew Robinson
>    <[1]A.Robinson at ms.unimelb.edu.au> wrote:
> 
>    On Tue, May 06, 2008 at 08:56:51PM -0400, Mark Kimpel wrote:
>    >    The "treatments" are actually two selectively bred lines of rats,
>    with
>    >    6 animals from each line. We need p-values as a filter to
>    determine
>    >    which of ~31,000 genes on the array are significant. The p-values
>    are
>    >    subjected to FDR correction, of course. I've never seen a
>    micro-array
>    >    paper published without p-values.
>    >    As for Andrew's comments:
>    >    1. yes, there are three measurments taken per rat, but they are
>    from
>    >    different brain regions. Since each brain region was processed
>    >    separately, however, the region and batch effects cannot be
>    separated.
>    >    Having said that, I still label this factor as "region" in my
>    model.
> 
>      I'm a bit confused still - sorry - do you therefore have three
>      batches
>      per rat, for a total of 36 batches (with two missing possibly)?  If
>      so
>      then I still think that your model is over-parametrized, and that
>      you
>      can eliminate the Tissue random effect, based on your model output
>      below (thanks for including it).
> 
>    >    2. In the past I have done exactly as you suggested and averaged
>    brain
>    >    regions, but I was hoping nlme would allow for more
>    sophistication.
>    >    Because certain genes vary greatly across brain regions, averaging
>    >    would seem to discard some useful information which could be used
>    to
>    >    improve the inference made on treatment effect.
> 
>      Can you specify exactly what useful information is being used in the
>      analysis that would be discarded if you took averages?
> 
>    >    If I used averaging, I would just have 12 measurements made on 12
>    >    rats and could do a simple t-test, but I don't think that would
>    >    be preferable, would it?
> 
>      It's not clear to me that the conclusions will be different.  If
>      not,
>      then the simpler analysis seems to be the better one.  I would
>      suggest
>      that you compare them and see what happens.
>      Cheers,
>      Andrew
> 
>    >    Here is the output of my model:
>    >         myModel <- lme(fixed = geneExpression ~  Treatment,  random =
>    ~1 |
>    >    Rat/Tissue)
>    >    > myModel
>    >    Linear mixed-effects model fit by REML
>    >      Data: NULL
>    >      Log-restricted-likelihood: 40.60593
>    >      Fixed: geneExpression ~ Treatment
>    >     (Intercept) TreatmentLAD
>    >    12.628465893 -0.009280945
>    >    Random effects:
>    >     Formula: ~1 | Rat
>    >             (Intercept)
>    >    StdDev: 2.752519e-06
>    >     Formula: ~1 | Tissue %in% Rat
>    >            (Intercept)     Residual
>    >    StdDev:  0.06226097 0.0002623086
>    >    Number of Observations: 34
>    >    Number of Groups:
>    >                Rat Tissue %in% Rat
>    >                 12              34
>    >    > summary(myModel)
>    >    Linear mixed-effects model fit by REML
>    >     Data: NULL
>    >            AIC       BIC   logLik
>    >      -71.21185 -63.88317 40.60593
>    >    Random effects:
>    >     Formula: ~1 | Rat
>    >             (Intercept)
>    >    StdDev: 2.752519e-06
>    >     Formula: ~1 | Tissue %in% Rat
>    >            (Intercept)     Residual
>    >    StdDev:  0.06226097 0.0002623086
>    >    Fixed effects: geneExpression ~ Treatment
>    >                     Value  Std.Error DF  t-value p-value
>    >    (Intercept)  12.628466 0.01510064 22 836.2870  0.0000
>    >    TreatmentLAD -0.009281 0.02135553 10  -0.4346  0.6731
>    >     Correlation:
>    >                 (Intr)
>    >    TreatmentLAD -0.707
>    >    Standardized Within-Group Residuals:
>    >              Min            Q1           Med            Q3
>    Max
>    >    -0.0083222376 -0.0027523180 -0.0001242287  0.0034693142
>    0.0087149017
>    >    Number of Observations: 34
>    >    Number of Groups:
>    >                Rat Tissue %in% Rat
>    >                 12              34
>    >    >
>    >
> 
>      >    On Tue, May 6, 2008 at 4:42 PM,
>      <[1][2]Antonio_Paredes at aphis.usda.gov>
> 
>    >    wrote:
>    >
>    >      How were animals allocated to treatments (at random)? What about
>    the
>    >      housing of the animals. Both of these factors could be
>    influential
>    >      in selecting the unit of study.
>    >      You also need to get an ideal at to why a p-value is enough to
>    >      support the objective of the study. Why not estimation of
>    treatment
>    >      effects?
>    >      Tony.
>    >
> 
>      >    Andrew Robinson <[2][3]A.Robinson at ms.unimelb.edu.au>
>      >    Sent by: [3][4]r-sig-mixed-models-bounces at r-project.org
> 
>    >
>    >    05/06/2008 03:19 PM
>    >
>    >
>      To
>    >
> 
>      >    Mark Kimpel <[4][5]mwkimpel at gmail.com>
>      >
>      >
>            cc
>      >
>      >    [5][6]r-sig-mixed-models at r-project.org
> 
>    >
>    >
>    Subject
>    >
>    >    Re: [R-sig-ME] mixed-effects model specification question
>    >
>    >    Mark,
>    >    You should talk to a local statistician about this, but I think
>    that
>    >    you can probably average across the measurements within each rat,
>    if
>    >    all you are interested in is a treatment effect.  For the analysis
>    of
>    >    treatment the relevant unit of replication should be the rat, in
>    any
>    >    case.
>    >    (Does anyone have any thoughts on why that might be a bad idea?)
>    >    Also if I understand your design, there are three batches per rat.
>     I
>    >    suspect that using Rat/Tissue would lead to an over-parametrized
>    >    model, if my interpretation is correct.  My guess is that Rat
>    should
>    >    be adequate.
>    >    Final points
>    >    1) My speculations would be better-informed if you showed us the
>    >      output of the model that you proposed - fyi :) .
>    >    2) You could try all three configurations and see if it makes any
>    >      difference to the inference of interest.  I suspect that it will
>    >      not.
>    >    I hope that this helps,
>    >    Andrew
>    >    On Tue, May 06, 2008 at 10:23:08AM -0400, Mark Kimpel wrote:
>    >    > Perhaps a bit of a newbie question, but I need to get this
>    right. I
>    >    need to
>    >    > make sure I am specifying a model correctly. Here is our
>    >    less-than-perfect
>    >    > experimental design:
>    >    >
>    >    > 36 rats divided into two treatment groups, i.e. 18 per group
>    >    >
>    >    > each rat has measurements taken on 3 brain regions, but each
>    brain
>    >    region
>    >    > was analyzed in a separate batch (there are strong batch
>    effects) so
>    >    we
>    >    > really can't compare the regions per se, but do recognize that
>    the 3
>    >    regions
>    >    > from a single rat have variance above and beyond that accounted
>    for
>    >    by
>    >    > technical factors. Since, because of the batch effect we are not
>    >    going to
>    >    > look at the effect of brain region, I "think" this should be a
>    >    considered a
>    >    > random effect.
>    >    >
>    >    > So I have rat, treatment, and region(batch) as variables. The
>    only
>    >    thing I
>    >    > am interested in getting a p-value for is treatment.
>    >    >
>    >    > Is the model below correct and can I squeek by with using nlme
>    to get
>    >    a
>    >    > p-value (notwithstanding recent threads on this list)?
>    >    >
>    >    >  myModel <- lme(fixed = geneExpression ~  Treatment,  random =
>    ~1 |
>    >    > Rat/Tissue)
>    >    >
>    >    > Thanks,
>    >    > Mark
>    >    > --
>    >    > Mark W. Kimpel MD ** Neuroinformatics ** Dept. of Psychiatry
>    >    > Indiana University School of Medicine
>    >    >
>    >    > 15032 Hunter Court, Westfield, IN 46074
>    >    >
>    >    > (317) 490-5129 Work, & Mobile & VoiceMail
>    >    > (317) 663-0513 Home (no voice mail please)
>    >    >
>    >    >
>    ******************************************************************
>    >    >
>    >    >                  [[alternative HTML version deleted]]
>    >    >
>    >    > _______________________________________________
> 
>      >    > [6][7]R-sig-mixed-models at r-project.org mailing list
>      >    >
>      [7][8]https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
>    >    --
>    >    Andrew Robinson
>    >    Department of Mathematics and Statistics            Tel:
>    >    +61-3-8344-6410
>    >    University of Melbourne, VIC 3010 Australia         Fax:
>    >    +61-3-8344-4599
> 
>      >    [8][9]http://www.ms.unimelb.edu.au/~andrewpr
>      >    [9][10]http://blogs.mbs.edu/fishing-in-the-bay/
>      >    _______________________________________________
>      >    [10][11]R-sig-mixed-models at r-project.org mailing list
>      >
>      [11][12]https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
>    >
>    >    --
>    >    Mark W. Kimpel MD ** Neuroinformatics ** Dept. of Psychiatry
>    >    Indiana University School of Medicine
>    >    15032 Hunter Court, Westfield, IN 46074
>    >    (317) 490-5129 Work, & Mobile & VoiceMail
>    >    (317) 663-0513 Home (no voice mail please)
>    >    **********************************************************
>    ********
>    >
> 
>      > References
>      >
>      >    1. mailto:[13]Antonio_Paredes at aphis.usda.gov
>      >    2. mailto:[14]A.Robinson at ms.unimelb.edu.au
>      >    3. mailto:[15]r-sig-mixed-models-bounces at r-project.org
>      >    4. mailto:[16]mwkimpel at gmail.com
>      >    5. mailto:[17]r-sig-mixed-models at r-project.org
>      >    6. mailto:[18]R-sig-mixed-models at r-project.org
>      >    7. [19]https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>      >    8. [20]http://www.ms.unimelb.edu.au/%7Eandrewpr
>      >    9. [21]http://blogs.mbs.edu/fishing-in-the-bay/
>      >   10. mailto:[22]R-sig-mixed-models at r-project.org
>      >   11. [23]https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
>    --
>    Andrew Robinson
>    Department of Mathematics and Statistics            Tel:
>    +61-3-8344-6410
>    University of Melbourne, VIC 3010 Australia         Fax:
>    +61-3-8344-4599
>    [24]http://www.ms.unimelb.edu.au/~andrewpr
>    [25]http://blogs.mbs.edu/fishing-in-the-bay/
> 
>    --
>    Mark W. Kimpel MD ** Neuroinformatics ** Dept. of Psychiatry
>    Indiana University School of Medicine
>    15032 Hunter Court, Westfield, IN 46074
>    (317) 490-5129 Work, & Mobile & VoiceMail
>    (317) 663-0513 Home (no voice mail please)
>    ******************************************************************
> 
> References
> 
>    1. mailto:A.Robinson at ms.unimelb.edu.au
>    2. mailto:Antonio_Paredes at aphis.usda.gov
>    3. mailto:A.Robinson at ms.unimelb.edu.au
>    4. mailto:r-sig-mixed-models-bounces at r-project.org
>    5. mailto:mwkimpel at gmail.com
>    6. mailto:r-sig-mixed-models at r-project.org
>    7. mailto:R-sig-mixed-models at r-project.org
>    8. https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>    9. http://www.ms.unimelb.edu.au/%7Eandrewpr
>   10. http://blogs.mbs.edu/fishing-in-the-bay/
>   11. mailto:R-sig-mixed-models at r-project.org
>   12. https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>   13. mailto:Antonio_Paredes at aphis.usda.gov
>   14. mailto:A.Robinson at ms.unimelb.edu.au
>   15. mailto:r-sig-mixed-models-bounces at r-project.org
>   16. mailto:mwkimpel at gmail.com
>   17. mailto:r-sig-mixed-models at r-project.org
>   18. mailto:R-sig-mixed-models at r-project.org
>   19. https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>   20. http://www.ms.unimelb.edu.au/%7Eandrewpr
>   21. http://blogs.mbs.edu/fishing-in-the-bay/
>   22. mailto:R-sig-mixed-models at r-project.org
>   23. https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>   24. http://www.ms.unimelb.edu.au/%7Eandrewpr
>   25. http://blogs.mbs.edu/fishing-in-the-bay/

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From bolker at ufl.edu  Wed May  7 17:39:55 2008
From: bolker at ufl.edu (Ben Bolker)
Date: Wed, 07 May 2008 11:39:55 -0400
Subject: [R-sig-ME] general GLMM questions
Message-ID: <4821CD4B.5090701@ufl.edu>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Dear sig-mixed readers,

~  Some of my students and I are foolishly attempting to write a review
of GLMMs for an ecology/evolution audience.  Realizing that this is a
huge, gnarly, and not-completely-understood subject (even for the
experts -- see fortune("mixed")), we're trying to provide as much
non-technical background and guidance as can be squeezed into a
reasonable sized journal article ...

~  We've run into quite a few questions we have been unable to answer
... perhaps because no-one knows the answers, or because we're looking
in the wrong places.  We thought we might impose on the generosity of
the list: if this feels ridiculous, please just ignore this message.
Feedback ranging from "this is true, but I don't know of a published
source" to "this just isn't true" would be useful.  We are aware of the
deeper problems of focusing on p-values and degrees of freedom -- we
will encourage readers to focus on estimating effect sizes and
confidence limits -- but we would also like to answer some of these
questions for them, if we can.

~  Ben Bolker

1. Is there a published justification somewhere for Lynn Eberly's
( http://www.biostat.umn.edu/~lynn/ph7430/class.html ) statement that df
adjustments are largely irrelevant if number of blocks>25 ?

2. What determines the asymptotic performance of the LRT (likelihood
ratio test) for comparison of fixed effects, which is known to be poor
for "small" sample sizes?  Is it the number of random-effects levels
(as stated by Agresti 2002, p. 520), or is it the number of levels of
the fixed effect relative to the total number of data points (as
stated by Pinheiro and Bates 2000, pp. 87-89)?  (The example given by
PB2000 from Littell et al. 1996 is a test of a treatment factor with
15 levels, in a design with 60 observations and 15 blocks.  Agresti's
statement would imply that one would still be in trouble if the total
number of observations increased to 600 [because # blocks is still
small], where PB2000 would imply that the LRT would be OK in this
limit.  (A small experiment with the simulate.lme() example given on
PB2000 p. 89 suggests that increasing the sample size 10-fold with the
same number of blocks DOES make the LRT OK ... but I would need to do
this a bit more carefully to be sure.)  (Or is this a difference
between the linear and generalized linear case?)

3. For multi-level models (nested, certainly crossed), how would one
count the "number of random-effects levels" to quantify the 'sample
size' above?  With a single random effect, we can just count the
number of levels (blocks).  What would one do with e.g. a nested or
crossed design?  (Perhaps the answer is "don't use a likelihood ratio
test to evaluate the significance of fixed effects".)

4. Does anyone know of any evidence (in either direction) that the
"boundary" problems that apply to the likelihood ratio test (e.g. Self
and Liang 1987) also apply to information criteria comparisons of
models with and without random effects?  I would expect so, since the
derivations of the AIC involve Taylor expansions around the
null-hypothesis parameters ...

5. It's common sense that estimating the variance of a random effect
from a small number of levels (e.g. less than 5) should be dicey, and
that one might in this case want to treat the parameter as a fixed
effect (regardless of its philosophical/experimental design status).
For small numbers of levels I would expect (?) that the answers MIGHT
be similar -- among other things the difference between df=1 and
df=(n-1) would be small.  But ... is there a good discussion of this
in print somewhere?  (Crawley mentions this on p. 670 of "Statistical
Computing", but without justification.)

lme4-specific questions:

6. Behavior of glmer: Does glmer really use AGQ, or just Laplace?
Both?  pp. 28-32 of the "Implementation" vignette in lme4 suggest that
a Laplace approximation is used, but I can't figure out whether this
is an additional approximation on top of the AGQ/Laplace approximation
of the integral over the random effects used in "ordinary" LMM.  When
I fit a GLMM with the different methods, the fitted objects are not
identical but all the coefficients seem to be.  (I have poked at the
code a bit but been unable to answer this question for myself
... sorry ...)

(The glmmML package claims to fit via Laplace or Gauss-Hermite
quadrature (with non-adaptive, but adjustable, number of quad points
- -- so it's at least theoretically possible?)

library(lme4)
set.seed(1001)
f = factor(rep(1:10,each=10))
zb = rnorm(1:10,sd=2) ## block effects
x = runif(100)
eta = 2*x+zb[f]+rnorm(100)
y = rpois(100,exp(eta))

g1 = glmer(y~x+(1|f),family="poisson",method="Laplace")
g2 = glmer(y~x+(1|f),family="poisson",method="AGQ")
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.6 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org

iD8DBQFIIc1Lc5UpGjwzenMRAr4uAJ90myt79pJZCa1a801FkxHRnAHYdgCfUYy+
P0ljXHs4lt8aTwpWKncRkBg=
=nd22
-----END PGP SIGNATURE-----



From mwkimpel at gmail.com  Wed May  7 20:24:22 2008
From: mwkimpel at gmail.com (Mark Kimpel)
Date: Wed, 7 May 2008 14:24:22 -0400
Subject: [R-sig-ME] mixed-effects model specification question
In-Reply-To: <20080507084519.GZ1433@ms.unimelb.edu.au>
References: <20080506201900.GQ1433@ms.unimelb.edu.au>
	<OFC98EF1CC.76E06E62-ON86257441.007126F8-86257441.00710356@aphis.usda.gov>
	<6b93d1830805061756m29f73ae6u56e1cb3d8a576e4c@mail.gmail.com>
	<20080507053527.GF54465@ms.unimelb.edu.au>
	<6b93d1830805062257r2adeaf8an89111ee1ed828b9a@mail.gmail.com>
	<20080507084519.GZ1433@ms.unimelb.edu.au>
Message-ID: <6b93d1830805071124j66f8087rd76ee536c7316815@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080507/75b24d67/attachment.pl>

From dimitris.rizopoulos at med.kuleuven.be  Thu May  8 10:45:50 2008
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Thu, 8 May 2008 10:45:50 +0200
Subject: [R-sig-ME] general GLMM questions
References: <4821CD4B.5090701@ufl.edu>
Message-ID: <006001c8b0e7$eb334980$0e40210a@www.domain>

----- Original Message ----- 
From: "Ben Bolker" <bolker at ufl.edu>
To: "R Mixed Models" <r-sig-mixed-models at r-project.org>
Sent: Wednesday, May 07, 2008 5:39 PM
Subject: [R-sig-ME] general GLMM questions


> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> Dear sig-mixed readers,
>
> ~  Some of my students and I are foolishly attempting to write a 
> review
> of GLMMs for an ecology/evolution audience.  Realizing that this is 
> a
> huge, gnarly, and not-completely-understood subject (even for the
> experts -- see fortune("mixed")), we're trying to provide as much
> non-technical background and guidance as can be squeezed into a
> reasonable sized journal article ...
>
> ~  We've run into quite a few questions we have been unable to 
> answer
> ... perhaps because no-one knows the answers, or because we're 
> looking
> in the wrong places.  We thought we might impose on the generosity 
> of
> the list: if this feels ridiculous, please just ignore this message.
> Feedback ranging from "this is true, but I don't know of a published
> source" to "this just isn't true" would be useful.  We are aware of 
> the
> deeper problems of focusing on p-values and degrees of freedom -- we
> will encourage readers to focus on estimating effect sizes and
> confidence limits -- but we would also like to answer some of these
> questions for them, if we can.
>
> ~  Ben Bolker
>
> 1. Is there a published justification somewhere for Lynn Eberly's
> ( http://www.biostat.umn.edu/~lynn/ph7430/class.html ) statement 
> that df
> adjustments are largely irrelevant if number of blocks>25 ?
>
> 2. What determines the asymptotic performance of the LRT (likelihood
> ratio test) for comparison of fixed effects, which is known to be 
> poor
> for "small" sample sizes?  Is it the number of random-effects levels
> (as stated by Agresti 2002, p. 520), or is it the number of levels 
> of
> the fixed effect relative to the total number of data points (as
> stated by Pinheiro and Bates 2000, pp. 87-89)?  (The example given 
> by
> PB2000 from Littell et al. 1996 is a test of a treatment factor with
> 15 levels, in a design with 60 observations and 15 blocks. 
> Agresti's
> statement would imply that one would still be in trouble if the 
> total
> number of observations increased to 600 [because # blocks is still
> small], where PB2000 would imply that the LRT would be OK in this
> limit.  (A small experiment with the simulate.lme() example given on
> PB2000 p. 89 suggests that increasing the sample size 10-fold with 
> the
> same number of blocks DOES make the LRT OK ... but I would need to 
> do
> this a bit more carefully to be sure.)  (Or is this a difference
> between the linear and generalized linear case?)


Intuitively, I think this will depend on the correlation between the
measurements within each block. At the one extreme, assume that all
the measurements within each block are the same, then actual sample
size would be the number of block. At the other extreme, assume that
all the
measurements within each block are random, then the sample size would
be the total number of observations.

I know some people from Hasselt University in Belgium that have worked
on the "Effective Sample Size" for mixed models; you can check at the
following presentation given in ISCB last summer
(http://www.iscb2007.gr/ppt/Wednesday/Orfeas/16.54-17.12/slides_ISCB2007.pdf)


> 3. For multi-level models (nested, certainly crossed), how would one
> count the "number of random-effects levels" to quantify the 'sample
> size' above?  With a single random effect, we can just count the
> number of levels (blocks).  What would one do with e.g. a nested or
> crossed design?  (Perhaps the answer is "don't use a likelihood 
> ratio
> test to evaluate the significance of fixed effects".)
>
> 4. Does anyone know of any evidence (in either direction) that the
> "boundary" problems that apply to the likelihood ratio test (e.g. 
> Self
> and Liang 1987) also apply to information criteria comparisons of
> models with and without random effects?  I would expect so, since 
> the
> derivations of the AIC involve Taylor expansions around the
> null-hypothesis parameters ...


I think this is an interesting question. Let

# AIC under the null
AIC.0 = -2*logLik.0 + 2npar

# AIC under the alternative
AIC.1 = -2*logLik.1 + 2(npar + 1)

then you reject when

AIC.1 < AIC.0 =>

-2*logLik.1 + 2(npar + 1) + -2*logLik.0 + 2npar < 0 =>

LRT > 2.

Now for boundary problems and according to Stram and Lee (1994,
Biometrics), LRT ~ 0.5 * chisq(0) + 0.5 * chisq(1), for which the
critical value is 1.923. Thus, it seems to work more or less ok in
this case. However, if you wanted to test wether the variance is 10,
then LRT ~ chisq(1), for which the critical value is 3.841!


> 5. It's common sense that estimating the variance of a random effect
> from a small number of levels (e.g. less than 5) should be dicey, 
> and
> that one might in this case want to treat the parameter as a fixed
> effect (regardless of its philosophical/experimental design status).
> For small numbers of levels I would expect (?) that the answers 
> MIGHT
> be similar -- among other things the difference between df=1 and
> df=(n-1) would be small.  But ... is there a good discussion of this
> in print somewhere?  (Crawley mentions this on p. 670 of 
> "Statistical
> Computing", but without justification.)
>
> lme4-specific questions:
>
> 6. Behavior of glmer: Does glmer really use AGQ, or just Laplace?
> Both?  pp. 28-32 of the "Implementation" vignette in lme4 suggest 
> that
> a Laplace approximation is used, but I can't figure out whether this
> is an additional approximation on top of the AGQ/Laplace 
> approximation
> of the integral over the random effects used in "ordinary" LMM. 
> When
> I fit a GLMM with the different methods, the fitted objects are not
> identical but all the coefficients seem to be.  (I have poked at the
> code a bit but been unable to answer this question for myself
> ... sorry ...)


Well, in Linear Mixed Models the integral over the random effects can
be analytically evaluated and thus no approximation (i.e., AGQ or
Laplace) is required. In GLMMs this is not the case and thus the
log-likelihood needs to be calculated approximately. One method for
approximating the integral is the AGQ, and in fact Laplace is AGQ with
one quadrature point.

AFAIK (but Doug can correct if I'm wrong), glmer() uses Laplace since
AGQ is not yet implemented.


> (The glmmML package claims to fit via Laplace or Gauss-Hermite
> quadrature (with non-adaptive, but adjustable, number of quad points
> - -- so it's at least theoretically possible?)
>
> library(lme4)
> set.seed(1001)
> f = factor(rep(1:10,each=10))
> zb = rnorm(1:10,sd=2) ## block effects
> x = runif(100)
> eta = 2*x+zb[f]+rnorm(100)
> y = rpois(100,exp(eta))
>
> g1 = glmer(y~x+(1|f),family="poisson",method="Laplace")
> g2 = glmer(y~x+(1|f),family="poisson",method="AGQ")
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.6 (GNU/Linux)
> Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org
>
> iD8DBQFIIc1Lc5UpGjwzenMRAr4uAJ90myt79pJZCa1a801FkxHRnAHYdgCfUYy+
> P0ljXHs4lt8aTwpWKncRkBg=
> =nd22
> -----END PGP SIGNATURE-----
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm



From vmuggeo at dssm.unipa.it  Thu May  8 12:37:18 2008
From: vmuggeo at dssm.unipa.it (vito muggeo)
Date: Thu, 08 May 2008 12:37:18 +0200
Subject: [R-sig-ME] general GLMM questions
In-Reply-To: <4821CD4B.5090701@ufl.edu>
References: <4821CD4B.5090701@ufl.edu>
Message-ID: <4822D7DE.5090101@dssm.unipa.it>

Dear Ben,
I am going to reply just to your question #4.

Yes, the AIC suffers from the same drawbacks of the log-Likelihood; 
therefore if the LRT does not work (for testing for variance components 
in LMM and also for any non-regular models, say), the AIC is not 
expected to work too. (I don't remember the references where I read 
this,..sorry). For instance, in problems related to breakpoint 
estimation the logLik is  just piecewise differentiable and if one is 
interested in testing for the existence of the breakpoint, the LRT and 
the AIC do not work. However simulation studies have shown that the BIC 
works (this makes sense because the BIC has a Bayesian justification and 
nondifferentiable logLik typically does not matter..)

best,
vito

Ben Bolker ha scritto:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
> 
> Dear sig-mixed readers,
> 
> ~  Some of my students and I are foolishly attempting to write a review
> of GLMMs for an ecology/evolution audience.  Realizing that this is a
> huge, gnarly, and not-completely-understood subject (even for the
> experts -- see fortune("mixed")), we're trying to provide as much
> non-technical background and guidance as can be squeezed into a
> reasonable sized journal article ...
> 
> ~  We've run into quite a few questions we have been unable to answer
> ... perhaps because no-one knows the answers, or because we're looking
> in the wrong places.  We thought we might impose on the generosity of
> the list: if this feels ridiculous, please just ignore this message.
> Feedback ranging from "this is true, but I don't know of a published
> source" to "this just isn't true" would be useful.  We are aware of the
> deeper problems of focusing on p-values and degrees of freedom -- we
> will encourage readers to focus on estimating effect sizes and
> confidence limits -- but we would also like to answer some of these
> questions for them, if we can.
> 
> ~  Ben Bolker
> 
> 1. Is there a published justification somewhere for Lynn Eberly's
> ( http://www.biostat.umn.edu/~lynn/ph7430/class.html ) statement that df
> adjustments are largely irrelevant if number of blocks>25 ?
> 
> 2. What determines the asymptotic performance of the LRT (likelihood
> ratio test) for comparison of fixed effects, which is known to be poor
> for "small" sample sizes?  Is it the number of random-effects levels
> (as stated by Agresti 2002, p. 520), or is it the number of levels of
> the fixed effect relative to the total number of data points (as
> stated by Pinheiro and Bates 2000, pp. 87-89)?  (The example given by
> PB2000 from Littell et al. 1996 is a test of a treatment factor with
> 15 levels, in a design with 60 observations and 15 blocks.  Agresti's
> statement would imply that one would still be in trouble if the total
> number of observations increased to 600 [because # blocks is still
> small], where PB2000 would imply that the LRT would be OK in this
> limit.  (A small experiment with the simulate.lme() example given on
> PB2000 p. 89 suggests that increasing the sample size 10-fold with the
> same number of blocks DOES make the LRT OK ... but I would need to do
> this a bit more carefully to be sure.)  (Or is this a difference
> between the linear and generalized linear case?)
> 
> 3. For multi-level models (nested, certainly crossed), how would one
> count the "number of random-effects levels" to quantify the 'sample
> size' above?  With a single random effect, we can just count the
> number of levels (blocks).  What would one do with e.g. a nested or
> crossed design?  (Perhaps the answer is "don't use a likelihood ratio
> test to evaluate the significance of fixed effects".)
> 
> 4. Does anyone know of any evidence (in either direction) that the
> "boundary" problems that apply to the likelihood ratio test (e.g. Self
> and Liang 1987) also apply to information criteria comparisons of
> models with and without random effects?  I would expect so, since the
> derivations of the AIC involve Taylor expansions around the
> null-hypothesis parameters ...
> 
> 5. It's common sense that estimating the variance of a random effect
> from a small number of levels (e.g. less than 5) should be dicey, and
> that one might in this case want to treat the parameter as a fixed
> effect (regardless of its philosophical/experimental design status).
> For small numbers of levels I would expect (?) that the answers MIGHT
> be similar -- among other things the difference between df=1 and
> df=(n-1) would be small.  But ... is there a good discussion of this
> in print somewhere?  (Crawley mentions this on p. 670 of "Statistical
> Computing", but without justification.)
> 
> lme4-specific questions:
> 
> 6. Behavior of glmer: Does glmer really use AGQ, or just Laplace?
> Both?  pp. 28-32 of the "Implementation" vignette in lme4 suggest that
> a Laplace approximation is used, but I can't figure out whether this
> is an additional approximation on top of the AGQ/Laplace approximation
> of the integral over the random effects used in "ordinary" LMM.  When
> I fit a GLMM with the different methods, the fitted objects are not
> identical but all the coefficients seem to be.  (I have poked at the
> code a bit but been unable to answer this question for myself
> ... sorry ...)
> 
> (The glmmML package claims to fit via Laplace or Gauss-Hermite
> quadrature (with non-adaptive, but adjustable, number of quad points
> - -- so it's at least theoretically possible?)
> 
> library(lme4)
> set.seed(1001)
> f = factor(rep(1:10,each=10))
> zb = rnorm(1:10,sd=2) ## block effects
> x = runif(100)
> eta = 2*x+zb[f]+rnorm(100)
> y = rpois(100,exp(eta))
> 
> g1 = glmer(y~x+(1|f),family="poisson",method="Laplace")
> g2 = glmer(y~x+(1|f),family="poisson",method="AGQ")
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.6 (GNU/Linux)
> Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org
> 
> iD8DBQFIIc1Lc5UpGjwzenMRAr4uAJ90myt79pJZCa1a801FkxHRnAHYdgCfUYy+
> P0ljXHs4lt8aTwpWKncRkBg=
> =nd22
> -----END PGP SIGNATURE-----
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 

-- 
====================================
Vito M.R. Muggeo
Dip.to Sc Statist e Matem `Vianelli'
Universit? di Palermo
viale delle Scienze, edificio 13
90128 Palermo - ITALY
tel: 091 6626240
fax: 091 485726/485612
http://dssm.unipa.it/vmuggeo



From kjbeath at kagi.com  Thu May  8 14:04:27 2008
From: kjbeath at kagi.com (Ken Beath)
Date: Thu, 8 May 2008 22:04:27 +1000
Subject: [R-sig-ME] general GLMM questions
In-Reply-To: <4821CD4B.5090701@ufl.edu>
References: <4821CD4B.5090701@ufl.edu>
Message-ID: <CB9BDA54-616F-43BA-B4B4-21608FBD5130@kagi.com>

On 08/05/2008, at 1:39 AM, Ben Bolker wrote:

>
> 1. Is there a published justification somewhere for Lynn Eberly's
> ( http://www.biostat.umn.edu/~lynn/ph7430/class.html ) statement  
> that df
> adjustments are largely irrelevant if number of blocks>25 ?
>

Actually denominator df > 25. This seems to derive from t  
distributions with df greater than 25 all being much the same, in fact  
close to a normal distribution. In reality variations in the data from  
normality are more important.


> 2. What determines the asymptotic performance of the LRT (likelihood
> ratio test) for comparison of fixed effects, which is known to be poor
> for "small" sample sizes?  Is it the number of random-effects levels
> (as stated by Agresti 2002, p. 520), or is it the number of levels of
> the fixed effect relative to the total number of data points (as
> stated by Pinheiro and Bates 2000, pp. 87-89)?  (The example given by
> PB2000 from Littell et al. 1996 is a test of a treatment factor with
> 15 levels, in a design with 60 observations and 15 blocks.  Agresti's
> statement would imply that one would still be in trouble if the total
> number of observations increased to 600 [because # blocks is still
> small], where PB2000 would imply that the LRT would be OK in this
> limit.  (A small experiment with the simulate.lme() example given on
> PB2000 p. 89 suggests that increasing the sample size 10-fold with the
> same number of blocks DOES make the LRT OK ... but I would need to do
> this a bit more carefully to be sure.)  (Or is this a difference
> between the linear and generalized linear case?)
>

This is probably dependent on whether the comparisons are within- or  
between- block. The PBIB has lots of within- block comparisons so  
increasing block size will tend to make things asymptotic. Try blocks  
where all within a block receive the same treatment and see how much  
increasing block size helps.


> 3. For multi-level models (nested, certainly crossed), how would one
> count the "number of random-effects levels" to quantify the 'sample
> size' above?  With a single random effect, we can just count the
> number of levels (blocks).  What would one do with e.g. a nested or
> crossed design?  (Perhaps the answer is "don't use a likelihood ratio
> test to evaluate the significance of fixed effects".)
>
> 4. Does anyone know of any evidence (in either direction) that the
> "boundary" problems that apply to the likelihood ratio test (e.g. Self
> and Liang 1987) also apply to information criteria comparisons of
> models with and without random effects?  I would expect so, since the
> derivations of the AIC involve Taylor expansions around the
> null-hypothesis parameters ...
>

This is a good question. For choosing the number of classes for  
mixture models it has been shown that BIC fails theoretically but  
works well in practice (proven with simulations) and compares well to  
results from parametric bootstrapping of the LRT. Some simulations for  
random effects would be interesting.

Ken



From mbustama at bio.puc.cl  Thu May  8 16:49:58 2008
From: mbustama at bio.puc.cl (Marcela A. Bustamante-Sanchez)
Date: Thu, 8 May 2008 10:49:58 -0400
Subject: [R-sig-ME] p values for fixed effects using mcmc
Message-ID: <007501c8b11a$cb5d3b10$87d79b92@MBustamante>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080508/f6f178f2/attachment.pl>

From nikko at hailmail.net  Thu May  8 17:29:04 2008
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: Thu, 08 May 2008 08:29:04 -0700
Subject: [R-sig-ME] general GLMM questions
In-Reply-To: <mailman.4360.1210236405.29471.r-sig-mixed-models@r-project.org>
References: <mailman.4360.1210236405.29471.r-sig-mixed-models@r-project.org>
Message-ID: <1210260544.11353.1252109653@webmail.messagingengine.com>

Hi 
My one comment is below in #2

Nicholas
On Thu, 08 May 2008 10:46:45 +0200,
r-sig-mixed-models-request at r-project.org said:
> Send R-sig-mixed-models mailing list submissions to
> 	r-sig-mixed-models at r-project.org
> 
> To subscribe or unsubscribe via the World Wide Web, visit
> 	https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> or, via email, send a message with subject or body 'help' to
> 	r-sig-mixed-models-request at r-project.org
> 
> You can reach the person managing the list at
> 	r-sig-mixed-models-owner at r-project.org
> 
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-sig-mixed-models digest..."
> 

> 
> Message: 1
> Date: Wed, 07 May 2008 11:39:55 -0400
> From: Ben Bolker <bolker at ufl.edu>
> Subject: [R-sig-ME] general GLMM questions
> To: R Mixed Models <r-sig-mixed-models at r-project.org>
> Message-ID: <4821CD4B.5090701 at ufl.edu>
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
> 
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
> 
> Dear sig-mixed readers,
> 
> ~  Some of my students and I are foolishly attempting to write a review
> of GLMMs for an ecology/evolution audience.  Realizing that this is a
> huge, gnarly, and not-completely-understood subject (even for the
> experts -- see fortune("mixed")), we're trying to provide as much
> non-technical background and guidance as can be squeezed into a
> reasonable sized journal article ...
> 
> ~  We've run into quite a few questions we have been unable to answer
> ... perhaps because no-one knows the answers, or because we're looking
> in the wrong places.  We thought we might impose on the generosity of
> the list: if this feels ridiculous, please just ignore this message.
> Feedback ranging from "this is true, but I don't know of a published
> source" to "this just isn't true" would be useful.  We are aware of the
> deeper problems of focusing on p-values and degrees of freedom -- we
> will encourage readers to focus on estimating effect sizes and
> confidence limits -- but we would also like to answer some of these
> questions for them, if we can.
> 
> ~  Ben Bolker
> 
> 1. Is there a published justification somewhere for Lynn Eberly's
> ( http://www.biostat.umn.edu/~lynn/ph7430/class.html ) statement that df
> adjustments are largely irrelevant if number of blocks>25 ?
> 
> 2. What determines the asymptotic performance of the LRT (likelihood
> ratio test) for comparison of fixed effects, which is known to be poor
> for "small" sample sizes?  Is it the number of random-effects levels
> (as stated by Agresti 2002, p. 520), or is it the number of levels of
> the fixed effect relative to the total number of data points (as
> stated by Pinheiro and Bates 2000, pp. 87-89)?  (The example given by
> PB2000 from Littell et al. 1996 is a test of a treatment factor with
> 15 levels, in a design with 60 observations and 15 blocks.  Agresti's
> statement would imply that one would still be in trouble if the total
> number of observations increased to 600 [because # blocks is still
> small], where PB2000 would imply that the LRT would be OK in this
> limit.  (A small experiment with the simulate.lme() example given on
> PB2000 p. 89 suggests that increasing the sample size 10-fold with the
> same number of blocks DOES make the LRT OK ... but I would need to do
> this a bit more carefully to be sure.)  (Or is this a difference
> between the linear and generalized linear case?)

I ran across this issue a long time ago when I was working on my MS.
I was working on a hierarchical Poisson regression model, 
for species area curves comparing landbridge and oceanic islands.
I had over 400 data points (Islands) but only about 20 landbridge and 
12 oceanic Island chains. However the amount of information in the
posterior, 
another question to ponder, of the slopes high, in other words
there was a strong effect on the posterior, even though
the data that level was sparse. It seems that the comment prior
to mine is spot on that it depends on the the covariance, in my case
there was a lot of information on each slope that carried upward through
the model.
So in a nutshell I think the LRT will be ok when there is enough
information, either coming from the precision of the estimates from with
in the block
or enough blocks to estimate the random effects parameter. How to
account for that
precisely I leave to better theoreticians than I. 






> 
> 3. For multi-level models (nested, certainly crossed), how would one
> count the "number of random-effects levels" to quantify the 'sample
> size' above?  With a single random effect, we can just count the
> number of levels (blocks).  What would one do with e.g. a nested or
> crossed design?  (Perhaps the answer is "don't use a likelihood ratio
> test to evaluate the significance of fixed effects".)
> 
> 4. Does anyone know of any evidence (in either direction) that the
> "boundary" problems that apply to the likelihood ratio test (e.g. Self
> and Liang 1987) also apply to information criteria comparisons of
> models with and without random effects?  I would expect so, since the
> derivations of the AIC involve Taylor expansions around the
> null-hypothesis parameters ...
> 
> 5. It's common sense that estimating the variance of a random effect
> from a small number of levels (e.g. less than 5) should be dicey, and
> that one might in this case want to treat the parameter as a fixed
> effect (regardless of its philosophical/experimental design status).
> For small numbers of levels I would expect (?) that the answers MIGHT
> be similar -- among other things the difference between df=1 and
> df=(n-1) would be small.  But ... is there a good discussion of this
> in print somewhere?  (Crawley mentions this on p. 670 of "Statistical
> Computing", but without justification.)
> 
> lme4-specific questions:
> 
> 6. Behavior of glmer: Does glmer really use AGQ, or just Laplace?
> Both?  pp. 28-32 of the "Implementation" vignette in lme4 suggest that
> a Laplace approximation is used, but I can't figure out whether this
> is an additional approximation on top of the AGQ/Laplace approximation
> of the integral over the random effects used in "ordinary" LMM.  When
> I fit a GLMM with the different methods, the fitted objects are not
> identical but all the coefficients seem to be.  (I have poked at the
> code a bit but been unable to answer this question for myself
> ... sorry ...)
> 
> (The glmmML package claims to fit via Laplace or Gauss-Hermite
> quadrature (with non-adaptive, but adjustable, number of quad points
> - -- so it's at least theoretically possible?)
> 
> library(lme4)
> set.seed(1001)
> f = factor(rep(1:10,each=10))
> zb = rnorm(1:10,sd=2) ## block effects
> x = runif(100)
> eta = 2*x+zb[f]+rnorm(100)
> y = rpois(100,exp(eta))
> 
> g1 = glmer(y~x+(1|f),family="poisson",method="Laplace")
> g2 = glmer(y~x+(1|f),family="poisson",method="AGQ")
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.6 (GNU/Linux)
> Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org
> 
> iD8DBQFIIc1Lc5UpGjwzenMRAr4uAJ90myt79pJZCa1a801FkxHRnAHYdgCfUYy+
> P0ljXHs4lt8aTwpWKncRkBg=
> =nd22
> -----END PGP SIGNATURE-----
> 
>



From bates at stat.wisc.edu  Fri May  9 16:52:53 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 9 May 2008 09:52:53 -0500
Subject: [R-sig-ME] general GLMM questions
In-Reply-To: <4821CD4B.5090701@ufl.edu>
References: <4821CD4B.5090701@ufl.edu>
Message-ID: <40e66e0b0805090752y6663eedel413b1d3cf692e77f@mail.gmail.com>

On Wed, May 7, 2008 at 10:39 AM, Ben Bolker <bolker at ufl.edu> wrote:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> Dear sig-mixed readers,
>
> ~  Some of my students and I are foolishly attempting to write a review
> of GLMMs for an ecology/evolution audience.  Realizing that this is a
> huge, gnarly, and not-completely-understood subject (even for the
> experts -- see fortune("mixed")), we're trying to provide as much
> non-technical background and guidance as can be squeezed into a
> reasonable sized journal article ...
>
> ~  We've run into quite a few questions we have been unable to answer
> ... perhaps because no-one knows the answers, or because we're looking
> in the wrong places.  We thought we might impose on the generosity of
> the list: if this feels ridiculous, please just ignore this message.
> Feedback ranging from "this is true, but I don't know of a published
> source" to "this just isn't true" would be useful.  We are aware of the
> deeper problems of focusing on p-values and degrees of freedom -- we
> will encourage readers to focus on estimating effect sizes and
> confidence limits -- but we would also like to answer some of these
> questions for them, if we can.
>
> ~  Ben Bolker
>
> 1. Is there a published justification somewhere for Lynn Eberly's
> ( http://www.biostat.umn.edu/~lynn/ph7430/class.html ) statement that df
> adjustments are largely irrelevant if number of blocks>25 ?
>
> 2. What determines the asymptotic performance of the LRT (likelihood
> ratio test) for comparison of fixed effects, which is known to be poor
> for "small" sample sizes?  Is it the number of random-effects levels
> (as stated by Agresti 2002, p. 520), or is it the number of levels of
> the fixed effect relative to the total number of data points (as
> stated by Pinheiro and Bates 2000, pp. 87-89)?  (The example given by
> PB2000 from Littell et al. 1996 is a test of a treatment factor with
> 15 levels, in a design with 60 observations and 15 blocks.  Agresti's
> statement would imply that one would still be in trouble if the total
> number of observations increased to 600 [because # blocks is still
> small], where PB2000 would imply that the LRT would be OK in this
> limit.  (A small experiment with the simulate.lme() example given on
> PB2000 p. 89 suggests that increasing the sample size 10-fold with the
> same number of blocks DOES make the LRT OK ... but I would need to do
> this a bit more carefully to be sure.)  (Or is this a difference
> between the linear and generalized linear case?)
>
> 3. For multi-level models (nested, certainly crossed), how would one
> count the "number of random-effects levels" to quantify the 'sample
> size' above?  With a single random effect, we can just count the
> number of levels (blocks).  What would one do with e.g. a nested or
> crossed design?  (Perhaps the answer is "don't use a likelihood ratio
> test to evaluate the significance of fixed effects".)
>
> 4. Does anyone know of any evidence (in either direction) that the
> "boundary" problems that apply to the likelihood ratio test (e.g. Self
> and Liang 1987) also apply to information criteria comparisons of
> models with and without random effects?  I would expect so, since the
> derivations of the AIC involve Taylor expansions around the
> null-hypothesis parameters ...
>
> 5. It's common sense that estimating the variance of a random effect
> from a small number of levels (e.g. less than 5) should be dicey, and
> that one might in this case want to treat the parameter as a fixed
> effect (regardless of its philosophical/experimental design status).
> For small numbers of levels I would expect (?) that the answers MIGHT
> be similar -- among other things the difference between df=1 and
> df=(n-1) would be small.  But ... is there a good discussion of this
> in print somewhere?  (Crawley mentions this on p. 670 of "Statistical
> Computing", but without justification.)
>
> lme4-specific questions:
>
> 6. Behavior of glmer: Does glmer really use AGQ, or just Laplace?
> Both?  pp. 28-32 of the "Implementation" vignette in lme4 suggest that
> a Laplace approximation is used, but I can't figure out whether this
> is an additional approximation on top of the AGQ/Laplace approximation
> of the integral over the random effects used in "ordinary" LMM.  When
> I fit a GLMM with the different methods, the fitted objects are not
> identical but all the coefficients seem to be.  (I have poked at the
> code a bit but been unable to answer this question for myself
> ... sorry ...)

To answer this question I must again, I regret, distinguish between
the CRAN version of the lme4 package and the R-forge development
version of lme4.

In the R-forge version the only method for generalized linear mixed
models and for nonlinear mixed models is direct optimization of the
Laplace approximation to the deviance.  One of the Summer of Code
projects that Google has funded for the R Foundation (see
http://code.google.com/soc/2008/rf/about.html) is implementation of
the Adaptive Gauss-Hermite Quadrature approximation to the deviance.
That will be implemented in the development version (i.e. the R-forge
version) of the lme4 package.  AGQ will only be offered for models
with a single grouping factor for the random effects.

I realize that it is somewhat irritating and confusing to readers of
this list to have descriptions of the R-forge version of the package
contrasted with the CRAN version.  It is natural to expect that the
R-forge version should be the version on CRAN.  The reason that I have
not yet released the R-forge to CRAN is because of problems with the
mcmcsamp function in the R-forge version.  If I moved the R-forge
version to CRAN then code from Harald Baayen's book and probably code
from Gelman and Hill's book would no longer work.  Software versions
can be changed much more readily than can editions of a book.  I think
there is a way around the problem with mcmcsamp but I won't be able to
say for sure until it is coded and tested, which will take time.  I
don't want to predict exactly how much time - I always manage to
underestimate drastically.

I do not plan to provide an implementation of penalized
quasi-likelihood (PQL) in what is currently the development version
and what will become lme4_1.0.  PQL for GLMMs and the
"Lindstrom-Bates" algorithm for nonlinear mixed models (the approaches
are related) are examples of alternating conditional optimization
(think of the Gibbs sampler approach with optimization instead of
sampling).  It is a dangerous practice in that it can result in
oscillation between conditional optima.  I now prefer direct
optimization techniques where the fixed-effects parameters and the
variance components are optimized simultaneously.  There may be
circumstances where PQL is advantageous but usually those are because
of over-parameterized models.


> (The glmmML package claims to fit via Laplace or Gauss-Hermite
> quadrature (with non-adaptive, but adjustable, number of quad points
> - -- so it's at least theoretically possible?)

Yes.  I think the adaptive part is important (in fact, I know it is
important) and probably more important than the distinction between
the Laplace approximation and Gauss-Hermite quadrature.  That is, you
gain more from using the Laplace approximation at the conditional
modes of the random effects (which is the "adaptive" part) than
increasing the number of Gauss-Hermite quadrature points at the
marginal modes.  The tricky bit of AGQ or Laplace is determining the
conditional modes and that part is already done.
> library(lme4)
> set.seed(1001)
> f = factor(rep(1:10,each=10))
> zb = rnorm(1:10,sd=2) ## block effects
> x = runif(100)
> eta = 2*x+zb[f]+rnorm(100)
> y = rpois(100,exp(eta))
>
> g1 = glmer(y~x+(1|f),family="poisson",method="Laplace")
> g2 = glmer(y~x+(1|f),family="poisson",method="AGQ")
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.6 (GNU/Linux)
> Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org
>
> iD8DBQFIIc1Lc5UpGjwzenMRAr4uAJ90myt79pJZCa1a801FkxHRnAHYdgCfUYy+
> P0ljXHs4lt8aTwpWKncRkBg=
> =nd22
> -----END PGP SIGNATURE-----
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From john.maindonald at anu.edu.au  Sun May 11 01:37:36 2008
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Sun, 11 May 2008 09:37:36 +1000
Subject: [R-sig-ME] [R] predict lmer
In-Reply-To: <mailman.20.1210240805.24841.r-help@r-project.org>
References: <mailman.20.1210240805.24841.r-help@r-project.org>
Message-ID: <7DC875CE-FE5F-4206-B0E2-7E6E8D3896F1@anu.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080511/b892e52d/attachment.pl>

From f.calboli at imperial.ac.uk  Sun May 11 20:52:50 2008
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Sun, 11 May 2008 19:52:50 +0100
Subject: [R-sig-ME] [R] lme nesting/interaction advice
In-Reply-To: <2ad0cc110805092336q28a28378t43dcc7aef909891@mail.gmail.com>
References: <48242FC2.4090708@imperial.ac.uk>
	<2ad0cc110805092336q28a28378t43dcc7aef909891@mail.gmail.com>
Message-ID: <2F2DF043-C762-48E1-9892-69E1C728EE30@imperial.ac.uk>

On 10 May 2008, at 07:36, Kingsford Jones wrote:
> Federico,
>
> I think you'll be more likely to receive the type of response you're
> looking for if you formulate your question more clearly.  The
> inclusion of "commented, minimal, self-contained, reproducible code"
> (as is requested at the bottom of every email sent by r-help) is an
> effective way to clarify the issues.  Also, when asking a question
> about fitting a model it's helpful to describe the specific research
> questions you want the model to answer.

<snip>

I apprecciate that my description of the *full* model is not 100%  
clear, but my main beef was another.

The main point of my question is, having a 3 way anova (or ancova, if  
you prefer), with *no* nesting, 2 fixed effects and 1 random effect,  
why is it so boneheaded difficult to specify a bog standard fully  
crossed model? I'm not talking about some rarified esoteric model  
here, we're talking about stuff tought in a first year Biology Stats  
course here[1].

Now, to avoid any chances of being misunderstood in my use of the  
words 'fully crossed model', what I mean is a simple

y ~ effect1 * effect2 * effect3

with effect3 being random (all all the jazz that comes from this  
fact). I fully apprecciate that the only reasonable F-tests would be  
for effect1, effect2 and effect1:effect2, but there is no way I can  
use lme to specify such simple thing without getting the *wrong*  
denDF. I need light on this topic and I'd say it's a general enough  
question not to need much more handholding than this.

Having said that, I did look at the mixed-effects mailing list before  
posting here, and it looks like it was *not* the right place to post  
anyway:

'This mailing list is primarily for useRs and programmeRs interested  
in *development* and beta-testing of the lme4 package.'

although the R-Me is now CC'd in this.

I fully apprecciate that R is developed for love, not money, and if I  
knew how to write an user friendly frontend for nlme and lme4 (and I  
knew how to actually get the model I want) I'd be pretty happy to do  
so and submit it as a library. In any case, I feel my complaint is  
pefectly valid, because specifying such basic model should ideally  
not such a chore, and I think the powers that be might actually find  
some use from user feedback.

Once I have sorted how to specify such trivial model I'll face the  
horror of the nesting, in any case I attach a toy dataset I created  
especially to test how to specify the correct model (silly me).

Best,

Federico Calboli

[1] So much bog standard that the Zar, IV ed, gives a nice table of  
how to compute the F-tests correctly, taking into account that one of  
the 3  effects is randon (I'll send the exact page and table number  
tomorrow, I don't have the book at home).

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: testdat.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080511/0c6d331e/attachment.txt>
-------------- next part --------------

--
Federico C. F. Calboli
Department of Epidemiology and Public Health
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com




From A.Robinson at ms.unimelb.edu.au  Sun May 11 23:45:49 2008
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Mon, 12 May 2008 07:45:49 +1000
Subject: [R-sig-ME] [R] lme nesting/interaction advice
In-Reply-To: <2F2DF043-C762-48E1-9892-69E1C728EE30@imperial.ac.uk>
References: <48242FC2.4090708@imperial.ac.uk>
	<2ad0cc110805092336q28a28378t43dcc7aef909891@mail.gmail.com>
	<2F2DF043-C762-48E1-9892-69E1C728EE30@imperial.ac.uk>
Message-ID: <20080511214549.GT1279@ms.unimelb.edu.au>

On Sun, May 11, 2008 at 07:52:50PM +0100, Federico Calboli wrote:
> 
> The main point of my question is, having a 3 way anova (or ancova, if  
> you prefer), with *no* nesting, 2 fixed effects and 1 random effect,  
> why is it so boneheaded difficult to specify a bog standard fully  
> crossed model? I'm not talking about some rarified esoteric model  
> here, we're talking about stuff tought in a first year Biology Stats  
> course here[1].

That may be so, but I've never needed to use one.  

If it's bog-standard and yet boneheaded difficult, then presumably
someone else would have had this problem before you.  Perhaps a search
of the archives will help?  If you try, you will find many qualifiers
to the effect that "lme isn't very well set up for crossed random
effects".

> Now, to avoid any chances of being misunderstood in my use of the  
> words 'fully crossed model', what I mean is a simple
> 
> y ~ effect1 * effect2 * effect3
> 
> with effect3 being random (all all the jazz that comes from this  
> fact). I fully apprecciate that the only reasonable F-tests would be  
> for effect1, effect2 and effect1:effect2, but there is no way I can  
> use lme to specify such simple thing without getting the *wrong*  
> denDF. I need light on this topic and I'd say it's a general enough  
> question not to need much more handholding than this.

Perhaps there are some circumstances unique to your situation.

> I fully apprecciate that R is developed for love, not money, 

... as is the R-help community ... 

> and if I  
> knew how to write an user friendly frontend for nlme and lme4 (and I  
> knew how to actually get the model I want) I'd be pretty happy to do  
> so and submit it as a library. In any case, I feel my complaint is  
> pefectly valid, because specifying such basic model should ideally  
> not such a chore, and I think the powers that be might actually find  
> some use from user feedback.

This is not feedback.  It is a compliant.  But, the complaint boils
down to the fact that you don't know what you're doing, and you show
no evidence of having searched the R-help archives.  How is that
helpful?

> Once I have sorted how to specify such trivial model I'll face the  
> horror of the nesting, in any case I attach a toy dataset I created  
> especially to test how to specify the correct model (silly me).

Well, these data seem to differ.  Is replica block?  If not, then how
can we reproduce your results?  And, if I assume that it is, then the
output df differ from what you sent in your original mail.  So, I find
this confusing.

Then, from your original mail,

> The easiest model ignores the nested random effects and uses just
> selection, males and replica and the relative interactions. The
> model
>
>lme(y ~ selection * males, random = ~1|replica/selection/males, mydata)

forgive me, but I seem to see nesting in the random statement.  That is
what happens when we separate factors with a '/'; they are nested.  We
would expect that statement to not provide the correct df for the
bog-standard fully crossed design.

Perhaps if you were to comply with the request at the bottom of each
R-help email, and provide commented, minimal, self-contained,
reproducible code, that actually ran, ideally with fewer value
judgements, you might get more attention from the people who are
smarter than you and me, but have less time than either of us.

Andrew

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From A.Robinson at ms.unimelb.edu.au  Mon May 12 02:05:58 2008
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Mon, 12 May 2008 10:05:58 +1000
Subject: [R-sig-ME] [R] lme nesting/interaction advice
In-Reply-To: <993D1DD8-1AD4-4094-ABC9-7CFD605DD5DB@auckland.ac.nz>
References: <48242FC2.4090708@imperial.ac.uk>
	<2ad0cc110805092336q28a28378t43dcc7aef909891@mail.gmail.com>
	<2F2DF043-C762-48E1-9892-69E1C728EE30@imperial.ac.uk>
	<20080511214549.GT1279@ms.unimelb.edu.au>
	<993D1DD8-1AD4-4094-ABC9-7CFD605DD5DB@auckland.ac.nz>
Message-ID: <20080512000558.GA20606@ms.unimelb.edu.au>

On Mon, May 12, 2008 at 10:34:40AM +1200, Rolf Turner wrote:
> 
> On 12/05/2008, at 9:45 AM, Andrew Robinson wrote:
> 
> >On Sun, May 11, 2008 at 07:52:50PM +0100, Federico Calboli wrote:
> >>
> >>The main point of my question is, having a 3 way anova (or ancova, if
> >>you prefer), with *no* nesting, 2 fixed effects and 1 random effect,
> >>why is it so boneheaded difficult to specify a bog standard fully
> >>crossed model? I'm not talking about some rarified esoteric model
> >>here, we're talking about stuff tought in a first year Biology Stats
> >>course here[1].
> >
> >That may be so, but I've never needed to use one.
> 
> 	So what?  This is still a standard, common, garden-variety
> 	model that you will encounter in exercises in many (if not
> 	all!) textbooks on experimental design and anova.

To reply in similar vein, so what?  Why should R-core or the R
community feel it necessary to reproduce every textbook example?  How
many times have *you* used such a model in real statistical work,
Rolf?

> >If it's bog-standard and yet boneheaded difficult, then presumably
> >someone else would have had this problem before you.  Perhaps a search
> >of the archives will help?  If you try, you will find many qualifiers
> >to the effect that "lme isn't very well set up for crossed random
> >effects".
> 
> 	But that avoids the question as to *why* it isn't very well
> 	set up for crossed random effects?  What's the problem?
> 	What are the issues?  The model is indeed bog-standard.
> 	It would seem not unreasonable to expect that it could be
> 	fitted in a straightforward manner, and it is irritating to
> 	find that it cannot be.  If SAS and Minitab can do it at
> 	the touch of a button, why can't R do it?

Bates has made no secret of the fact that lme was intended first and
foremost for nested designs, and that support for crossed designs is
not promised.  He has said so on many occasions, as a search would
find.  He is now working on lme4, which will support crossed designs.
It's not done yet. 

> >and you show
> >no evidence of having searched the R-help archives.  How is that
> >helpful?
> 
> 	It doesn't seem to me to be a complaint as such.  It is a
> 	request for insight.  I too would like some insight as to
> 	what on earth is going on.  And why do you say Federico
> 	shows no evidence of having searched the archives?  One can
> 	search till one is blue in the face and come away no wiser
> 	on this issue.

At least one can know that there is an issue, which apparently
Federico previously did not.

Warm wishes

Andrew
-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From john.maindonald at anu.edu.au  Mon May 12 02:11:40 2008
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Mon, 12 May 2008 10:11:40 +1000
Subject: [R-sig-ME] [R] lme nesting/interaction advice
In-Reply-To: <20080511214549.GT1279@ms.unimelb.edu.au>
References: <48242FC2.4090708@imperial.ac.uk>
	<2ad0cc110805092336q28a28378t43dcc7aef909891@mail.gmail.com>
	<2F2DF043-C762-48E1-9892-69E1C728EE30@imperial.ac.uk>
	<20080511214549.GT1279@ms.unimelb.edu.au>
Message-ID: <4552E68E-0257-41A2-BC9F-93EA05DC9C06@anu.edu.au>

This leads to the notion of a fully cross design.  A fully cross
design has the characteristics that:
(a) its lineaments are not clear.
(b) it leads to heated discussion.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


On 12 May 2008, at 7:45 AM, Andrew Robinson wrote:

> On Sun, May 11, 2008 at 07:52:50PM +0100, Federico Calboli wrote:
>>
>> The main point of my question is, having a 3 way anova (or ancova, if
>> you prefer), with *no* nesting, 2 fixed effects and 1 random effect,
>> why is it so boneheaded difficult to specify a bog standard fully
>> crossed model? I'm not talking about some rarified esoteric model
>> here, we're talking about stuff tought in a first year Biology Stats
>> course here[1].
>
> That may be so, but I've never needed to use one.
>
> If it's bog-standard and yet boneheaded difficult, then presumably
> someone else would have had this problem before you.  Perhaps a search
> of the archives will help?  If you try, you will find many qualifiers
> to the effect that "lme isn't very well set up for crossed random
> effects".
>
>> Now, to avoid any chances of being misunderstood in my use of the
>> words 'fully crossed model', what I mean is a simple
>>
>> y ~ effect1 * effect2 * effect3
>>
>> with effect3 being random (all all the jazz that comes from this
>> fact). I fully apprecciate that the only reasonable F-tests would be
>> for effect1, effect2 and effect1:effect2, but there is no way I can
>> use lme to specify such simple thing without getting the *wrong*
>> denDF. I need light on this topic and I'd say it's a general enough
>> question not to need much more handholding than this.
>
> Perhaps there are some circumstances unique to your situation.
>
>> I fully apprecciate that R is developed for love, not money,
>
> ... as is the R-help community ...
>
>> and if I
>> knew how to write an user friendly frontend for nlme and lme4 (and I
>> knew how to actually get the model I want) I'd be pretty happy to do
>> so and submit it as a library. In any case, I feel my complaint is
>> pefectly valid, because specifying such basic model should ideally
>> not such a chore, and I think the powers that be might actually find
>> some use from user feedback.
>
> This is not feedback.  It is a compliant.  But, the complaint boils
> down to the fact that you don't know what you're doing, and you show
> no evidence of having searched the R-help archives.  How is that
> helpful?
>
>> Once I have sorted how to specify such trivial model I'll face the
>> horror of the nesting, in any case I attach a toy dataset I created
>> especially to test how to specify the correct model (silly me).
>
> Well, these data seem to differ.  Is replica block?  If not, then how
> can we reproduce your results?  And, if I assume that it is, then the
> output df differ from what you sent in your original mail.  So, I find
> this confusing.
>
> Then, from your original mail,
>
>> The easiest model ignores the nested random effects and uses just
>> selection, males and replica and the relative interactions. The
>> model
>>
>> lme(y ~ selection * males, random = ~1|replica/selection/males,  
>> mydata)
>
> forgive me, but I seem to see nesting in the random statement.  That  
> is
> what happens when we separate factors with a '/'; they are nested.  We
> would expect that statement to not provide the correct df for the
> bog-standard fully crossed design.
>
> Perhaps if you were to comply with the request at the bottom of each
> R-help email, and provide commented, minimal, self-contained,
> reproducible code, that actually ran, ideally with fewer value
> judgements, you might get more attention from the people who are
> smarter than you and me, but have less time than either of us.
>
> Andrew
>
> -- 
> Andrew Robinson
> Department of Mathematics and Statistics            Tel:  
> +61-3-8344-6410
> University of Melbourne, VIC 3010 Australia         Fax:  
> +61-3-8344-4599
> http://www.ms.unimelb.edu.au/~andrewpr
> http://blogs.mbs.edu/fishing-in-the-bay/
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From David.Duffy at qimr.edu.au  Mon May 12 03:22:10 2008
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Mon, 12 May 2008 11:22:10 +1000 (EST)
Subject: [R-sig-ME] [R] lme nesting/interaction advice
In-Reply-To: <20080511214549.GT1279@ms.unimelb.edu.au>
References: <48242FC2.4090708@imperial.ac.uk><2ad0cc110805092336q28a28378t43dcc7aef909891@mail.gmail.com><2F2DF043-C762-48E1-9892-69E1C728EE30@imperial.ac.uk>
	<20080511214549.GT1279@ms.unimelb.edu.au>
Message-ID: <Pine.LNX.4.64.0805121114280.1551@orpheus.qimr.edu.au>

  On Sun, May 11, 2008 at 07:52:50PM +0100, Federico Calboli wrote:
>
> The main point of my question is, having a 3 way anova (or ancova, if
> you prefer), with *no* nesting, 2 fixed effects and 1 random effect,
> why is it so boneheaded difficult to specify a bog standard fully
> crossed model? I'm not talking about some rarified esoteric model
> here, we're talking about stuff tought in a first year Biology Stats
> course here[1].
>
> y ~ effect1 * effect2 * effect3
>
> with effect3 being random (all all the jazz that comes from this
> fact). I fully apprecciate that the only reasonable F-tests would be
> for effect1, effect2 and effect1:effect2, but there is no way I can
> use lme to specify such simple thing without getting the *wrong*
> denDF. I need light on this topic and I'd say it's a general enough

You _might_ be able to use the kinship package (lmekin, which in turn uses
lme) for this.  I'm just not sure about the "random regression" 
(fixed:random) interaction terms.

David Duffy,
-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From kjbeath at kagi.com  Mon May 12 11:05:07 2008
From: kjbeath at kagi.com (Ken Beath)
Date: Mon, 12 May 2008 19:05:07 +1000
Subject: [R-sig-ME] [R] lme nesting/interaction advice
In-Reply-To: <2F2DF043-C762-48E1-9892-69E1C728EE30@imperial.ac.uk>
References: <48242FC2.4090708@imperial.ac.uk>
	<2ad0cc110805092336q28a28378t43dcc7aef909891@mail.gmail.com>
	<2F2DF043-C762-48E1-9892-69E1C728EE30@imperial.ac.uk>
Message-ID: <1BDD26D1-8E37-4F31-9227-E96289570700@kagi.com>

On 12/05/2008, at 4:52 AM, Federico Calboli wrote:

> On 10 May 2008, at 07:36, Kingsford Jones wrote:
>> Federico,
>>
>> I think you'll be more likely to receive the type of response you're
>> looking for if you formulate your question more clearly.  The
>> inclusion of "commented, minimal, self-contained, reproducible code"
>> (as is requested at the bottom of every email sent by r-help) is an
>> effective way to clarify the issues.  Also, when asking a question
>> about fitting a model it's helpful to describe the specific research
>> questions you want the model to answer.
>
> <snip>
>
> I apprecciate that my description of the *full* model is not 100%  
> clear, but my main beef was another.
>
> The main point of my question is, having a 3 way anova (or ancova,  
> if you prefer), with *no* nesting, 2 fixed effects and 1 random  
> effect, why is it so boneheaded difficult to specify a bog standard  
> fully crossed model? I'm not talking about some rarified esoteric  
> model here, we're talking about stuff tought in a first year Biology  
> Stats course here[1].
>
> Now, to avoid any chances of being misunderstood in my use of the  
> words 'fully crossed model', what I mean is a simple
>
> y ~ effect1 * effect2 * effect3
>
> with effect3 being random (all all the jazz that comes from this  
> fact). I fully apprecciate that the only reasonable F-tests would be  
> for effect1, effect2 and effect1:effect2, but there is no way I can  
> use lme to specify such simple thing without getting the *wrong*  
> denDF. I need light on this topic and I'd say it's a general enough  
> question not to need much more handholding than this.
>

There is only one random effect, so where does the crossing come  
from ? The fixed effects vary across blocks, but they are fixed so are  
just covariates. For this type of data the usual model in lme4 is  
y~fixed1+fixed2+1|group and for lme split into fixed and random parts.


> Having said that, I did look at the mixed-effects mailing list  
> before posting here, and it looks like it was *not* the right place  
> to post anyway:
>
> 'This mailing list is primarily for useRs and programmeRs interested  
> in *development* and beta-testing of the lme4 package.'
>
> although the R-Me is now CC'd in this.
>
> I fully apprecciate that R is developed for love, not money, and if  
> I knew how to write an user friendly frontend for nlme and lme4 (and  
> I knew how to actually get the model I want) I'd be pretty happy to  
> do so and submit it as a library. In any case, I feel my complaint  
> is pefectly valid, because specifying such basic model should  
> ideally not such a chore, and I think the powers that be might  
> actually find some use from user feedback.
>

The problems seems to be that you want lme to work in the same way as  
an ANOVA table and it doesn't. The secret with lme and lme4 is to  
think about the structure of the data and describe with an equation.  
Then each term in the equation corresponds to part of the model  
definition in R.


> Once I have sorted how to specify such trivial model I'll face the  
> horror of the nesting, in any case I attach a toy dataset I created  
> especially to test how to specify the correct model (silly me).
>

I'm a bit lost with your data file, it has 4 covariates, which is more  
than enough for 2 fixed effects, assuming block is the grouping and y  
the outcome.

Ken

> Best,
>
> Federico Calboli
>
> [1] So much bog standard that the Zar, IV ed, gives a nice table of  
> how to compute the F-tests correctly, taking into account that one  
> of the 3  effects is randon (I'll send the exact page and table  
> number tomorrow, I don't have the book at home).
>
> <testdat.txt>
> --
> Federico C. F. Calboli
> Department of Epidemiology and Public Health
> Imperial College, St. Mary's Campus
> Norfolk Place, London W2 1PG
>
> Tel +44 (0)20 75941602   Fax +44 (0)20 75943193
>
> f.calboli [.a.t] imperial.ac.uk
> f.calboli [.a.t] gmail.com
>
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From f.calboli at imperial.ac.uk  Mon May 12 11:20:47 2008
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Mon, 12 May 2008 10:20:47 +0100
Subject: [R-sig-ME] [R] lme nesting/interaction advice
In-Reply-To: <20080511214549.GT1279@ms.unimelb.edu.au>
References: <48242FC2.4090708@imperial.ac.uk>
	<2ad0cc110805092336q28a28378t43dcc7aef909891@mail.gmail.com>
	<2F2DF043-C762-48E1-9892-69E1C728EE30@imperial.ac.uk>
	<20080511214549.GT1279@ms.unimelb.edu.au>
Message-ID: <8162640C-F13E-4B05-8055-787E7099418E@imperial.ac.uk>

On 11 May 2008, at 22:45, Andrew Robinson wrote:
>>
>> lme(y ~ selection * males, random = ~1|replica/selection/males,  
>> mydata)
>
> forgive me, but I seem to see nesting in the random statement.   
> That is
> what happens when we separate factors with a '/'; they are nested.  We
> would expect that statement to not provide the correct df for the
> bog-standard fully crossed design.

Please read page 23/24 of the Pinheiro and Bates book, "Mixed-Effects  
Models in S and S-PLUS". It might prove enlightening.

F

--
Federico C. F. Calboli
Department of Epidemiology and Public Health
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From f.calboli at imperial.ac.uk  Mon May 12 11:39:42 2008
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Mon, 12 May 2008 10:39:42 +0100
Subject: [R-sig-ME] [R] lme nesting/interaction advice
In-Reply-To: <000901c8b40a$41fea820$c5fbf860$@menne@menne-biomed.de>
References: <48242FC2.4090708@imperial.ac.uk>
	<2ad0cc110805092336q28a28378t43dcc7aef909891@mail.gmail.com>
	<2F2DF043-C762-48E1-9892-69E1C728EE30@imperial.ac.uk>
	<000901c8b40a$41fea820$c5fbf860$@menne@menne-biomed.de>
Message-ID: <F4703C82-E164-4869-A0DA-AF73EB3EC00A@imperial.ac.uk>

On 12 May 2008, at 09:29, Dieter Menne wrote:

> Federico:
>
> First, mixed models are different from "standard 101 Anova", and  
> quite a lot
> of the nesting stuff I used to ponder about 30 year ago when I started
> teaching this is no longer relevant and works implicitely when you  
> code the
> parameters correctly.
>
>
>>> with effect3 being random (all all the jazz that comes from this  
>>> fact). I
> fully apprecciate that the only reasonable F-tests would be for  
> effect1,
> effect2 and effect1:effect2, but there is no way I can use lme to  
> specify
> such simple thing without getting the *wrong* denDF. >>
>
> Good to know that you are sure what is "right"; probably == SAS.  
> Since most
> people active in the lme-business have read
>
> http://wiki.r-project.org/rwiki/doku.php?id=guides:lmer-tests
>
> http://finzi.psych.upenn.edu/R/Rhelp02a/archive/76742.html
>
>
> carefully, you might be rather lonely.

I will. While I do, feel free to have a look at Appendix A.3 (page  
App6, at the end of the book) of the Zar 'Biostatistical Analysis',  
IV ed, second table from the top. That's where I get the feeling for  
what's right or wrong. I surely cannot get it from SAS because I  
never had it. I never had the budget for it, so much so I had to lear  
how to use R from the start because it was free and that was the  
budget of my department had for stats software

All in all, if you feel statistical analysis has moved forth from  
such humble beginnings (the book I mean, not SAS), and you can  
convince of that every ref for every paper you submit, please do tell  
me how you do it, it would be more valuable than knowing how to fit  
my model.

Cheers,

Federico





--
Federico C. F. Calboli
Department of Epidemiology and Public Health
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From f.calboli at imperial.ac.uk  Mon May 12 11:42:20 2008
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Mon, 12 May 2008 10:42:20 +0100
Subject: [R-sig-ME] [R] lme nesting/interaction advice
In-Reply-To: <993D1DD8-1AD4-4094-ABC9-7CFD605DD5DB@auckland.ac.nz>
References: <48242FC2.4090708@imperial.ac.uk>
	<2ad0cc110805092336q28a28378t43dcc7aef909891@mail.gmail.com>
	<2F2DF043-C762-48E1-9892-69E1C728EE30@imperial.ac.uk>
	<20080511214549.GT1279@ms.unimelb.edu.au>
	<993D1DD8-1AD4-4094-ABC9-7CFD605DD5DB@auckland.ac.nz>
Message-ID: <53D190A8-AFC5-4CEA-A09A-F6EE83EBDC68@imperial.ac.uk>

On 11 May 2008, at 23:34, Rolf Turner wrote:
>
> 	It doesn't seem to me to be a complaint as such.  It is a
> 	request for insight.  I too would like some insight as to
> 	what on earth is going on.  And why do you say Federico
> 	shows no evidence of having searched the archives?  One can
> 	search till one is blue in the face and come away no wiser
> 	on this issue.
>
> 		cheers,
>
> 			Rolf Turner

Cheers for the support Rolf. I have searched the archives, and have  
the Pinheiro and Bates book in front of my nose (plus MASS4 and many  
others).

The bottom line here is, I'm pretty cool with RTFM and all that, my  
problem is that I do not have a clear FM to read about my issue, and  
hence I have to pester (because that how people seem to feel) the  
list. I apologise for asking an inconvenient question.

Fede

--
Federico C. F. Calboli
Department of Epidemiology and Public Health
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From f.calboli at imperial.ac.uk  Mon May 12 11:50:03 2008
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Mon, 12 May 2008 10:50:03 +0100
Subject: [R-sig-ME] [R] lme nesting/interaction advice
In-Reply-To: <20080512000558.GA20606@ms.unimelb.edu.au>
References: <48242FC2.4090708@imperial.ac.uk>
	<2ad0cc110805092336q28a28378t43dcc7aef909891@mail.gmail.com>
	<2F2DF043-C762-48E1-9892-69E1C728EE30@imperial.ac.uk>
	<20080511214549.GT1279@ms.unimelb.edu.au>
	<993D1DD8-1AD4-4094-ABC9-7CFD605DD5DB@auckland.ac.nz>
	<20080512000558.GA20606@ms.unimelb.edu.au>
Message-ID: <FF722405-D2AB-48EF-95B6-E34BB42CCF9B@imperial.ac.uk>


On 12 May 2008, at 01:05, Andrew Robinson wrote:

> On Mon, May 12, 2008 at 10:34:40AM +1200, Rolf Turner wrote:
>>
>> On 12/05/2008, at 9:45 AM, Andrew Robinson wrote:
>>
>>> On Sun, May 11, 2008 at 07:52:50PM +0100, Federico Calboli wrote:
>>>>
>>>> The main point of my question is, having a 3 way anova (or  
>>>> ancova, if
>>>> you prefer), with *no* nesting, 2 fixed effects and 1 random  
>>>> effect,
>>>> why is it so boneheaded difficult to specify a bog standard fully
>>>> crossed model? I'm not talking about some rarified esoteric model
>>>> here, we're talking about stuff tought in a first year Biology  
>>>> Stats
>>>> course here[1].
>>>
>>> That may be so, but I've never needed to use one.
>>
>> 	So what?  This is still a standard, common, garden-variety
>> 	model that you will encounter in exercises in many (if not
>> 	all!) textbooks on experimental design and anova.
>
> To reply in similar vein, so what?  Why should R-core or the R
> community feel it necessary to reproduce every textbook example?  How
> many times have *you* used such a model in real statistical work,
> Rolf?

There is a very important reason why R (or any other stats package)  
should *easily* face the challenge of bog standard models: because it  
is a *tool* for an end (i.e. the analysis of data to figure out what  
the heck they tell us) rather than a end in itself.

Bog standard models are *likely* to be used over and over again  
because they are *bog standard*, and they became such by being used  
*lots*.

If someone with a relatively easy model cannot use R for his job s/he  
will use something else, and the R community will *not* increase in  
numbers. Since R is a *community driven project*, you do the math on  
what that would mean in the long run.

Regards,

Federico

--
Federico C. F. Calboli
Department of Epidemiology and Public Health
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From f.calboli at imperial.ac.uk  Mon May 12 12:13:50 2008
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Mon, 12 May 2008 11:13:50 +0100
Subject: [R-sig-ME] [R] lme nesting/interaction advice
In-Reply-To: <1BDD26D1-8E37-4F31-9227-E96289570700@kagi.com>
References: <48242FC2.4090708@imperial.ac.uk>
	<2ad0cc110805092336q28a28378t43dcc7aef909891@mail.gmail.com>
	<2F2DF043-C762-48E1-9892-69E1C728EE30@imperial.ac.uk>
	<1BDD26D1-8E37-4F31-9227-E96289570700@kagi.com>
Message-ID: <141F47CE-ED08-459F-87F4-DB1668FBD280@imperial.ac.uk>

On 12 May 2008, at 10:05, Ken Beath wrote:
> There is only one random effect, so where does the crossing come  
> from ? The fixed effects vary across blocks, but they are fixed so  
> are just covariates. For this type of data the usual model in lme4  
> is y~fixed1+fixed2+1|group and for lme split into fixed and random  
> parts.

First off, whoa, an helpful reply! thanks for that, I hope I won't  
sound sarcastic or aggressive because I do not mean to be either.

Regarding your comment, the experiment was replicated three times, in  
3 different months. I would argue that for the fixed effects to be  
meaningful, they must have an effect over an above the effect:month  
interaction (because each fixed effect, and their interaction, might  
vary between each replicate). I would then argue I need to calculate

1) fixed.effect1:random.effect
2) fixed.effect2:random.effect
3) fixed.effect1:fixed.effect2:random.effect

to test if fixed.effect1 is meaningful (and use 1) as the error); if  
fixed.effect2 has is meaningful (and use 2) as the error);  
fixed.effect1:fixed.effect2 is meaningful (and use 3) as the error).

I'm happy to be correct if I am wrong here.

>> The problems seems to be that you want lme to work in the same way  
>> as an ANOVA table and it doesn't. The secret with lme and lme4 is  
>> to think about the structure of the data and describe with an  
>> equation. Then each term in the equation corresponds to part of  
>> the model definition in R.

I'll try to do that.
>
>
>> Once I have sorted how to specify such trivial model I'll face the  
>> horror of the nesting, in any case I attach a toy dataset I  
>> created especially to test how to specify the correct model (silly  
>> me).
>>
>
> I'm a bit lost with your data file, it has 4 covariates, which is  
> more than enough for 2 fixed effects, assuming block is the  
> grouping and y the outcome.

In the data file, 'selection' and 'males' are fixed effects, and  
'month' is the effect I am using for the model we are discussing  
here. The y was generatde with runif() just to have something, I'm  
not expecting any intersting result, just to understand how to fit  
the right model.

In the dataset 'line' is nested within 'selection' and 'block' is  
nested within 'month'. That's the nesting I will have to take into  
account once I get the more straightforward (sic!) model we're  
discussing right.

Best,

Federico


--
Federico C. F. Calboli
Department of Epidemiology and Public Health
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From A.Robinson at ms.unimelb.edu.au  Mon May 12 12:16:26 2008
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Mon, 12 May 2008 20:16:26 +1000
Subject: [R-sig-ME] [R] lme nesting/interaction advice
In-Reply-To: <FF722405-D2AB-48EF-95B6-E34BB42CCF9B@imperial.ac.uk>
References: <48242FC2.4090708@imperial.ac.uk>
	<2ad0cc110805092336q28a28378t43dcc7aef909891@mail.gmail.com>
	<2F2DF043-C762-48E1-9892-69E1C728EE30@imperial.ac.uk>
	<20080511214549.GT1279@ms.unimelb.edu.au>
	<993D1DD8-1AD4-4094-ABC9-7CFD605DD5DB@auckland.ac.nz>
	<20080512000558.GA20606@ms.unimelb.edu.au>
	<FF722405-D2AB-48EF-95B6-E34BB42CCF9B@imperial.ac.uk>
Message-ID: <20080512101625.GW1279@ms.unimelb.edu.au>

On Mon, May 12, 2008 at 10:50:03AM +0100, Federico Calboli wrote:
> 
> On 12 May 2008, at 01:05, Andrew Robinson wrote:
> 
> >On Mon, May 12, 2008 at 10:34:40AM +1200, Rolf Turner wrote:
> >>
> >>On 12/05/2008, at 9:45 AM, Andrew Robinson wrote:
> >>
> >>>On Sun, May 11, 2008 at 07:52:50PM +0100, Federico Calboli wrote:
> >>>>
> >>>>The main point of my question is, having a 3 way anova (or  
> >>>>ancova, if
> >>>>you prefer), with *no* nesting, 2 fixed effects and 1 random  
> >>>>effect,
> >>>>why is it so boneheaded difficult to specify a bog standard fully
> >>>>crossed model? I'm not talking about some rarified esoteric model
> >>>>here, we're talking about stuff tought in a first year Biology  
> >>>>Stats
> >>>>course here[1].
> >>>
> >>>That may be so, but I've never needed to use one.
> >>
> >>	So what?  This is still a standard, common, garden-variety
> >>	model that you will encounter in exercises in many (if not
> >>	all!) textbooks on experimental design and anova.
> >
> >To reply in similar vein, so what?  Why should R-core or the R
> >community feel it necessary to reproduce every textbook example?  How
> >many times have *you* used such a model in real statistical work,
> >Rolf?
> 
> There is a very important reason why R (or any other stats package)  
> should *easily* face the challenge of bog standard models: because it  
> is a *tool* for an end (i.e. the analysis of data to figure out what  
> the heck they tell us) rather than a end in itself.

But a tool that mostly (entirely?) appears in textbooks.  
 
> Bog standard models are *likely* to be used over and over again  
> because they are *bog standard*, and they became such by being used  
> *lots*.

Well.  I have documentation relevant to nlme that goes back about 10
years.  I don't know when it was first added to S-plus, but I assume
that it was about then.  Now, do you think that if the thing that you
want to do was really bog standard, that noone would have raised a
fuss or solved it within 10 years?
 
> If someone with a relatively easy model cannot use R for his job s/he  
> will use something else, and the R community will *not* increase in  
> numbers. Since R is a *community driven project*, you do the math on  
> what that would mean in the long run.

Fewer pestering questions?  ;)

Andrew

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From f.calboli at imperial.ac.uk  Mon May 12 12:33:43 2008
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Mon, 12 May 2008 11:33:43 +0100
Subject: [R-sig-ME] [R] lme nesting/interaction advice
In-Reply-To: <20080512101625.GW1279@ms.unimelb.edu.au>
References: <48242FC2.4090708@imperial.ac.uk>
	<2ad0cc110805092336q28a28378t43dcc7aef909891@mail.gmail.com>
	<2F2DF043-C762-48E1-9892-69E1C728EE30@imperial.ac.uk>
	<20080511214549.GT1279@ms.unimelb.edu.au>
	<993D1DD8-1AD4-4094-ABC9-7CFD605DD5DB@auckland.ac.nz>
	<20080512000558.GA20606@ms.unimelb.edu.au>
	<FF722405-D2AB-48EF-95B6-E34BB42CCF9B@imperial.ac.uk>
	<20080512101625.GW1279@ms.unimelb.edu.au>
Message-ID: <05F09328-9CFF-46BB-B1E6-68059E628490@imperial.ac.uk>

On 12 May 2008, at 11:16, Andrew Robinson wrote:
> Well.  I have documentation relevant to nlme that goes back about 10
> years.  I don't know when it was first added to S-plus, but I assume
> that it was about then.  Now, do you think that if the thing that you
> want to do was really bog standard, that noone would have raised a
> fuss or solved it within 10 years?

I'm pretty unpleasant, more so in person, so I'll tell you this. If  
people raised the issue and got the answer I got, I would not be  
surprised if they'd migrated to 'any other stats software' in droves.  
I have no doubt that, given the cryptic and sparse nature of the  
documentation of the issue, most people migrated well before asking -- 
on the grounds most people have a job to do, papers to publish,  
grants to write, kids to pick up from school and pretty little time  
for RTFM and all that sanctimonious attitude.

Once people stop nagging about 'whatever', the reason is because they  
finally got the message things ain't gonna improve, so cut your  
losses and look elsewhere.

Being unpleasant, thick skinned and cheap I will keep nagging and use  
R (the fact I do like it very much might be a factor). But given the  
selection users go through, it will be Vogon time sooner or later ;).

/F

--
Federico C. F. Calboli
Department of Epidemiology and Public Health
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From njbisaac at googlemail.com  Mon May 12 13:21:48 2008
From: njbisaac at googlemail.com (Nick Isaac)
Date: Mon, 12 May 2008 12:21:48 +0100
Subject: [R-sig-ME] [R] lme nesting/interaction advice
In-Reply-To: <05F09328-9CFF-46BB-B1E6-68059E628490@imperial.ac.uk>
References: <48242FC2.4090708@imperial.ac.uk>
	<2ad0cc110805092336q28a28378t43dcc7aef909891@mail.gmail.com>
	<2F2DF043-C762-48E1-9892-69E1C728EE30@imperial.ac.uk>
	<20080511214549.GT1279@ms.unimelb.edu.au>
	<993D1DD8-1AD4-4094-ABC9-7CFD605DD5DB@auckland.ac.nz>
	<20080512000558.GA20606@ms.unimelb.edu.au>
	<FF722405-D2AB-48EF-95B6-E34BB42CCF9B@imperial.ac.uk>
	<20080512101625.GW1279@ms.unimelb.edu.au>
	<05F09328-9CFF-46BB-B1E6-68059E628490@imperial.ac.uk>
Message-ID: <a072ed700805120421i3420bc30h9975f17642ad08eb@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080512/89505c87/attachment.pl>

From r.turner at auckland.ac.nz  Mon May 12 00:34:40 2008
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 12 May 2008 10:34:40 +1200
Subject: [R-sig-ME] [R] lme nesting/interaction advice
In-Reply-To: <20080511214549.GT1279@ms.unimelb.edu.au>
References: <48242FC2.4090708@imperial.ac.uk>
	<2ad0cc110805092336q28a28378t43dcc7aef909891@mail.gmail.com>
	<2F2DF043-C762-48E1-9892-69E1C728EE30@imperial.ac.uk>
	<20080511214549.GT1279@ms.unimelb.edu.au>
Message-ID: <993D1DD8-1AD4-4094-ABC9-7CFD605DD5DB@auckland.ac.nz>


On 12/05/2008, at 9:45 AM, Andrew Robinson wrote:

> On Sun, May 11, 2008 at 07:52:50PM +0100, Federico Calboli wrote:
>>
>> The main point of my question is, having a 3 way anova (or ancova, if
>> you prefer), with *no* nesting, 2 fixed effects and 1 random effect,
>> why is it so boneheaded difficult to specify a bog standard fully
>> crossed model? I'm not talking about some rarified esoteric model
>> here, we're talking about stuff tought in a first year Biology Stats
>> course here[1].
>
> That may be so, but I've never needed to use one.

	So what?  This is still a standard, common, garden-variety
	model that you will encounter in exercises in many (if not
	all!) textbooks on experimental design and anova.
>
> If it's bog-standard and yet boneheaded difficult, then presumably
> someone else would have had this problem before you.  Perhaps a search
> of the archives will help?  If you try, you will find many qualifiers
> to the effect that "lme isn't very well set up for crossed random
> effects".

	But that avoids the question as to *why* it isn't very well
	set up for crossed random effects?  What's the problem?
	What are the issues?  The model is indeed bog-standard.
	It would seem not unreasonable to expect that it could be
	fitted in a straightforward manner, and it is irritating to
	find that it cannot be.  If SAS and Minitab can do it at
	the touch of a button, why can't R do it?
>
>> Now, to avoid any chances of being misunderstood in my use of the
>> words 'fully crossed model', what I mean is a simple
>>
>> y ~ effect1 * effect2 * effect3
>>
>> with effect3 being random (all all the jazz that comes from this
>> fact). I fully apprecciate that the only reasonable F-tests would be
>> for effect1, effect2 and effect1:effect2, but there is no way I can
>> use lme to specify such simple thing without getting the *wrong*
>> denDF. I need light on this topic and I'd say it's a general enough
>> question not to need much more handholding than this.
>
> Perhaps there are some circumstances unique to your situation.

	Huh?
>
>> I fully apprecciate that R is developed for love, not money,
>
> ... as is the R-help community ...
>
>> and if I
>> knew how to write an user friendly frontend for nlme and lme4 (and I
>> knew how to actually get the model I want) I'd be pretty happy to do
>> so and submit it as a library. In any case, I feel my complaint is
>> pefectly valid, because specifying such basic model should ideally
>> not such a chore, and I think the powers that be might actually find
>> some use from user feedback.
>
> This is not feedback.  It is a compliant.  But, the complaint boils
> down to the fact that you don't know what you're doing

	That's rubbish. I think it's fairly clear that Federico does
	have a pretty good idea of what he's doing, but is flummoxed
	by the arcana of lme().  As am I.

> and you show
> no evidence of having searched the R-help archives.  How is that
> helpful?

	It doesn't seem to me to be a complaint as such.  It is a
	request for insight.  I too would like some insight as to
	what on earth is going on.  And why do you say Federico
	shows no evidence of having searched the archives?  One can
	search till one is blue in the face and come away no wiser
	on this issue.

		cheers,

			Rolf Turner

######################################################################
Attention:\ This e-mail message is privileged and confid...{{dropped:9}}



From toby909 at gmail.com  Mon May 12 14:39:59 2008
From: toby909 at gmail.com (toby909 at gmail.com)
Date: Mon, 12 May 2008 05:39:59 -0700
Subject: [R-sig-ME] [R] lme nesting/interaction advice
In-Reply-To: <FF722405-D2AB-48EF-95B6-E34BB42CCF9B@imperial.ac.uk>
References: <FF722405-D2AB-48EF-95B6-E34BB42CCF9B@imperial.ac.uk>
Message-ID: <48283A9F.5010905@gmail.com>

this is not an easy and not a standard model.

if your 3-way anova is fully factorial, with one factor being random,
then you have a LOT of random effects. you have a random main effect,
you will have a number of random 2-way interction terms, and also a
random 3-way interaction effect, their covariance matrix most likely to
be nonpositive definite.

The nested model is actually the simpler one, and I have the hint that
the "basics" book does not present such a complicated model in its
introductory chapter.

also, you don't make it easy for people to help you. I could not easily
read in your data and I had to generate own data. :-(

Maybe you are looking for something similar to:

set.seed(78987)
a = rep(1:3,each=120)
b = rep(1:3,3, each=40)
c = rep(1:10,9,each=4)
y = rnorm(360,0,10)
x = cbind(a,b,c,y)
colnames(x) = c("a", "b", "c", "y")
x = as.data.frame(x)

lme = lme(y ~ factor(a)*factor(b)*factor(c)-1, x, ~factor(c))
anova(lme)

but again, I don't know if that is what you are looking for, and it may
not be correct.

T



From f.calboli at imperial.ac.uk  Mon May 12 15:31:43 2008
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Mon, 12 May 2008 14:31:43 +0100
Subject: [R-sig-ME] [R] lme nesting/interaction advice
In-Reply-To: <48283A9F.5010905@gmail.com>
References: <FF722405-D2AB-48EF-95B6-E34BB42CCF9B@imperial.ac.uk>
	<48283A9F.5010905@gmail.com>
Message-ID: <8D0D1242-5764-47B9-A92E-EE3BDA7EE164@imperial.ac.uk>

On 12 May 2008, at 13:39, toby909 at gmail.com wrote:

> this is not an easy and not a standard model.

I know it is not easy, but I would be able to calculate the model by  
hand, were it not for the fact that I would like to understand how to  
do it using R
>
> if your 3-way anova is fully factorial, with one factor being random,
> then you have a LOT of random effects. you have a random main effect,
> you will have a number of random 2-way interction terms, and also a
> random 3-way interaction effect, their covariance matrix most  
> likely to
> be nonpositive definite.
>
> The nested model is actually the simpler one, and I have the hint that
> the "basics" book does not present such a complicated model in its
> introductory chapter.
>
> also, you don't make it easy for people to help you. I could not  
> easily
> read in your data and I had to generate own data. :-(

I am sorry about this, it might be because I wrote the data to a text  
file with write.table() in OSX. The data was nothing more than a toy  
model
>
> Maybe you are looking for something similar to:
>
> set.seed(78987)
> a = rep(1:3,each=120)
> b = rep(1:3,3, each=40)
> c = rep(1:10,9,each=4)
> y = rnorm(360,0,10)
> x = cbind(a,b,c,y)
> colnames(x) = c("a", "b", "c", "y")
> x = as.data.frame(x)
>
> lme = lme(y ~ factor(a)*factor(b)*factor(c)-1, x, ~factor(c))
> anova(lme)

With the very same model you're using I get:

 > lme.mod = lme(y ~ selection * males * month-1, random = ~month,  
testdat)
Error in getGroups.data.frame(dataMix, groups) :
   Invalid formula for groups
 > lme.mod = lme(y ~ selection * males * (month-1), random = ~month,  
testdat)
Error in getGroups.data.frame(dataMix, groups) :
   Invalid formula for groups

I copy/paste the datset below, in case it makes things clearer.

Thanks,

Federico


selection	line	males	month	block	y
L	L1	1	a	1	13.8156357121188
L	L1	1	a	1	12.5678496952169
L	L1	1	a	1	17.1313698710874
L	L1	1	a	1	3.87016302696429
L	L1	1	a	1	13.2627072110772
L	L2	1	a	1	17.835768135963
L	L2	1	a	1	19.3615794742946
L	L2	1	a	1	1.73416316602379
L	L2	1	a	1	12.9440758333076
L	L2	1	a	1	2.09191741654649
S	S1	1	a	1	1.56137526640669
S	S1	1	a	1	17.6580698778853
S	S1	1	a	1	18.1417595115490
S	S1	1	a	1	15.5621050691698
S	S1	1	a	1	17.0240987658035
S	S2	1	a	1	12.4378062419128
S	S2	1	a	1	6.63962595071644
S	S2	1	a	1	16.6060689473525
S	S2	1	a	1	7.1222553497646
S	S2	1	a	1	18.0590278783347
L	L1	2	a	1	1.24710303940810
L	L1	2	a	1	4.62720696791075
L	L1	2	a	1	16.0327167815994
L	L1	2	a	1	6.12926463945769
L	L1	2	a	1	7.65810538828373
L	L2	2	a	1	7.44077128893696
L	L2	2	a	1	14.9197938004509
L	L2	2	a	1	13.4244954204187
L	L2	2	a	1	11.5361888066400
L	L2	2	a	1	2.60056478204206
S	S1	2	a	1	14.8965472229756
S	S1	2	a	1	18.777876078384
S	S1	2	a	1	6.80722737265751
S	S1	2	a	1	13.1697203880176
S	S1	2	a	1	3.74557441123761
S	S2	2	a	1	5.41025308240205
S	S2	2	a	1	19.8277674221899
S	S2	2	a	1	4.76206006342545
S	S2	2	a	1	3.08200096315704
S	S2	2	a	1	11.7220768791158
L	L1	1	a	2	17.8684629611671
L	L1	1	a	2	18.5609889889602
L	L1	1	a	2	1.33335256157443
L	L1	1	a	2	12.2590920312796
L	L1	1	a	2	10.3133576815017
L	L2	1	a	2	9.08117202203721
L	L2	1	a	2	11.8387454338372
L	L2	1	a	2	2.17258459446020
L	L2	1	a	2	7.64467771397904
L	L2	1	a	2	10.1472946784925
S	S1	1	a	2	6.33078282815404
S	S1	1	a	2	14.2109518861398
S	S1	1	a	2	2.86901426501572
S	S1	1	a	2	1.33705932833254
S	S1	1	a	2	3.62769498769194
S	S2	1	a	2	10.6116549053695
S	S2	1	a	2	19.2579759012442
S	S2	1	a	2	4.93543729488738
S	S2	1	a	2	14.0185110287275
S	S2	1	a	2	13.0477287801914
L	L1	2	a	2	7.81632485729642
L	L1	2	a	2	15.8365131700411
L	L1	2	a	2	13.6505087725818
L	L1	2	a	2	4.30545190884732
L	L1	2	a	2	5.62008981755935
L	L2	2	a	2	11.6415019945707
L	L2	2	a	2	17.4424436504487
L	L2	2	a	2	5.51907726703212
L	L2	2	a	2	3.24006642703898
L	L2	2	a	2	2.96195078082383
S	S1	2	a	2	16.2962908495683
S	S1	2	a	2	11.919979267288
S	S1	2	a	2	2.93063819734380
S	S1	2	a	2	15.6936508698855
S	S1	2	a	2	2.295168728102
S	S2	2	a	2	11.7390888168011
S	S2	2	a	2	10.4391786744818
S	S2	2	a	2	11.1727120177820
S	S2	2	a	2	11.4406719871331
S	S2	2	a	2	5.20650001661852
L	L1	1	b	3	9.53833453846164
L	L1	1	b	3	1.95979442284442
L	L1	1	b	3	8.31046994985081
L	L1	1	b	3	4.39192276610993
L	L1	1	b	3	16.0887561799027
L	L2	1	b	3	5.20481191016734
L	L2	1	b	3	8.32888073613867
L	L2	1	b	3	3.47083900799043
L	L2	1	b	3	12.2260039008688
L	L2	1	b	3	12.2011876017787
S	S1	1	b	3	10.6229240614921
S	S1	1	b	3	9.49411644623615
S	S1	1	b	3	18.4179708964657
S	S1	1	b	3	4.12228938611224
S	S1	1	b	3	5.55325478035957
S	S2	1	b	3	10.4130052563269
S	S2	1	b	3	12.6257456133608
S	S2	1	b	3	19.8305484240409
S	S2	1	b	3	2.6487210446503
S	S2	1	b	3	15.9869729799684
L	L1	2	b	3	14.6902481422294
L	L1	2	b	3	16.9090498948935
L	L1	2	b	3	3.90413530776277
L	L1	2	b	3	1.89122105599381
L	L1	2	b	3	14.2131580882706
L	L2	2	b	3	16.1121652075090
L	L2	2	b	3	16.8070402105805
L	L2	2	b	3	2.19568496150896
L	L2	2	b	3	2.96183063089848
L	L2	2	b	3	12.6824307644274
S	S1	2	b	3	12.8504637307487
S	S1	2	b	3	6.1809710978996
S	S1	2	b	3	7.47571811126545
S	S1	2	b	3	8.81466605700552
S	S1	2	b	3	12.3395618333016
S	S2	2	b	3	19.9728567516431
S	S2	2	b	3	11.3028548071161
S	S2	2	b	3	6.50141697842628
S	S2	2	b	3	13.0698232366703
S	S2	2	b	3	11.474319845438
L	L1	1	b	4	1.03187379334122
L	L1	1	b	4	9.6801089819055
L	L1	1	b	4	4.00592510355636
L	L1	1	b	4	4.63362230593339
L	L1	1	b	4	15.4505966042634
L	L2	1	b	4	14.9346919001546
L	L2	1	b	4	18.3153922208585
L	L2	1	b	4	8.57050257665105
L	L2	1	b	4	1.31918784533627
L	L2	1	b	4	19.5731912786141
S	S1	1	b	4	4.34415089036338
S	S1	1	b	4	9.66746214497834
S	S1	1	b	4	12.4202494181227
S	S1	1	b	4	17.0269973296672
S	S1	1	b	4	15.1591323411558
S	S2	1	b	4	7.3169305799529
S	S2	1	b	4	14.9331590640359
S	S2	1	b	4	13.4191052850801
S	S2	1	b	4	3.8695620871149
S	S2	1	b	4	14.8654785933904
L	L1	2	b	4	18.5652933202218
L	L1	2	b	4	1.33474090369418
L	L1	2	b	4	12.9836367180105
L	L1	2	b	4	8.14379613753408
L	L1	2	b	4	17.5245339989197
L	L2	2	b	4	19.4962712256238
L	L2	2	b	4	8.36269160197116
L	L2	2	b	4	16.4331527492031
L	L2	2	b	4	19.9028004400898
L	L2	2	b	4	8.9440936667379
S	S1	2	b	4	5.1467830883339
S	S1	2	b	4	13.0068403361365
S	S1	2	b	4	17.9727395507507
S	S1	2	b	4	7.75389035535045
S	S1	2	b	4	13.1991689843126
S	S2	2	b	4	1.86596546205692
S	S2	2	b	4	13.6726454407908
S	S2	2	b	4	5.46787238144316
S	S2	2	b	4	14.9116268747021
S	S2	2	b	4	17.4470446316991
L	L1	1	c	5	6.0449733575806
L	L1	1	c	5	9.23758197389543
L	L1	1	c	5	11.8805425714236
L	L1	1	c	5	11.097381018335
L	L1	1	c	5	6.2186355558224
L	L2	1	c	5	15.4524628254585
L	L2	1	c	5	10.8791305767372
L	L2	1	c	5	8.53259862400591
L	L2	1	c	5	17.7329147965647
L	L2	1	c	5	7.95771266217344
S	S1	1	c	5	14.2891584723257
S	S1	1	c	5	18.7194010075182
S	S1	1	c	5	5.8396331758704
S	S1	1	c	5	12.2250114120543
S	S1	1	c	5	19.9965940725524
S	S2	1	c	5	8.086333316518
S	S2	1	c	5	1.02154314704239
S	S2	1	c	5	2.71978635899723
S	S2	1	c	5	11.7734509080183
S	S2	1	c	5	10.7842262475751
L	L1	2	c	5	15.3013315075077
L	L1	2	c	5	6.12277858285233
L	L1	2	c	5	6.58965252665803
L	L1	2	c	5	13.0980647155084
L	L1	2	c	5	11.3858233471401
L	L2	2	c	5	13.8056075817440
L	L2	2	c	5	11.4665438272059
L	L2	2	c	5	6.37498314119875
L	L2	2	c	5	3.85318743507378
L	L2	2	c	5	7.959969348507
S	S1	2	c	5	13.8249646106269
S	S1	2	c	5	13.3112728327978
S	S1	2	c	5	9.67586784437299
S	S1	2	c	5	17.8595201659482
S	S1	2	c	5	3.14554875413887
S	S2	2	c	5	10.4300375301391
S	S2	2	c	5	15.4386686717626
S	S2	2	c	5	7.93477151589468
S	S2	2	c	5	3.66100515658036
S	S2	2	c	5	13.5765222932678
L	L1	1	c	6	11.3484169594012
L	L1	1	c	6	12.7286028855015
L	L1	1	c	6	17.2616694702301
L	L1	1	c	6	19.8529832861386
L	L1	1	c	6	13.6375724875834
L	L2	1	c	6	1.47241126280278
L	L2	1	c	6	1.95706973574124
L	L2	1	c	6	5.88739864598028
L	L2	1	c	6	8.16921139019541
L	L2	1	c	6	15.4799758975860
S	S1	1	c	6	2.47244948730804
S	S1	1	c	6	4.87303283042274
S	S1	1	c	6	6.15663269115612
S	S1	1	c	6	1.31718108500354
S	S1	1	c	6	16.4325702653732
S	S2	1	c	6	8.77171974466182
S	S2	1	c	6	13.4219867731445
S	S2	1	c	6	15.79551491444
S	S2	1	c	6	8.52955200499855
S	S2	1	c	6	14.4046092615463
L	L1	2	c	6	17.4255252447911
L	L1	2	c	6	5.80786765902303
L	L1	2	c	6	3.27889802469872
L	L1	2	c	6	7.55257236934267
L	L1	2	c	6	10.3537469459698
L	L2	2	c	6	10.1472219382413
L	L2	2	c	6	15.3184245729353
L	L2	2	c	6	12.6165662519634
L	L2	2	c	6	11.2075877587777
L	L2	2	c	6	17.0927850408480
S	S1	2	c	6	19.5778706537094
S	S1	2	c	6	5.56091665173881
S	S1	2	c	6	6.32830694783479
S	S1	2	c	6	7.46368952002376
S	S1	2	c	6	14.5648785342928
S	S2	2	c	6	14.7789344959892
S	S2	2	c	6	3.21725518512540
S	S2	2	c	6	2.26359746395610
S	S2	2	c	6	9.14707987429574
S	S2	2	c	6	8.6291270784568

--
Federico C. F. Calboli
Department of Epidemiology and Public Health
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From HDoran at air.org  Mon May 12 15:37:55 2008
From: HDoran at air.org (Doran, Harold)
Date: Mon, 12 May 2008 09:37:55 -0400
Subject: [R-sig-ME] [R] lme nesting/interaction advice
In-Reply-To: <993D1DD8-1AD4-4094-ABC9-7CFD605DD5DB@auckland.ac.nz>
Message-ID: <ED7B522EE00C9A4FA515AA71724D61EE2EBF23@DC1EXCL01.air.org>

> 	But that avoids the question as to *why* it isn't very well
> 	set up for crossed random effects?  What's the problem?
> 	What are the issues?  The model is indeed bog-standard.
> 	It would seem not unreasonable to expect that it could be
> 	fitted in a straightforward manner, and it is irritating to
> 	find that it cannot be.  If SAS and Minitab can do it at
> 	the touch of a button, why can't R do it?

I haven't followed this thread carefully, so apologies if I'm too off
base. But, in response to Rolf's questions/issues. First, SAS cannot
handle models with crossed random effects (at least well at all). SAS is
horribly incapable of handling even the simplest of models (especially
generalized linear mixed models). I can cite numerous (recent) examples
of SAS coming to a complete halt (proc nlmixed) for an analyses we were
recently working on. R (and Ubuntu) was the only solution to our
problem.

Now, lme is not optimized for crossed random effects, but lmer is. That
is why lmer is supported and lme is not really supported much. lmer is
optimized for models with nested random effects and crossed random
effects. 

When working with models with nested random effects, and software
optimized for those problems (e.g., HLM, SAS, mlWin) the
variance/covariance matrix forms a special, and simple structure that
can be easily worked with. This is not the case for models with crossed
random effects.

Software packages designed for nested random effects can be tricked into
handling models with crossed random effects, but this kludge is slow and
really inefficient.

If you want complete transparency into the why and how, here is a
citation for your review.

Best
Harold

@article{Doran:Bates:Bliese:Dowling:2007:JSSOBK:v20i02,
  author =	"Harold  Doran and Douglas  Bates and Paul  Bliese and
Maritza   Dowling",
  title =	"Estimating the Multilevel Rasch Model: With the lme4
Package",
  journal =	"Journal of Statistical Software",
  volume =	"20",
  number =	"2",
  pages =	"1--18",
  day =  	"22",
  month =	"2",
  year = 	"2007",
  CODEN =	"JSSOBK",
  ISSN = 	"1548-7660",
  bibdate =	"2007-02-22",
  URL =  	"http://www.jstatsoft.org/v20/i02",
  accepted =	"2007-02-22",
  acknowledgement = "",
  keywords =	"",
  submitted =	"2006-10-01",
}



From christian at forkstam.se  Mon May 12 15:51:05 2008
From: christian at forkstam.se (christian forkstam)
Date: Mon, 12 May 2008 15:51:05 +0200
Subject: [R-sig-ME] [R] lme nesting/interaction advice
In-Reply-To: <8D0D1242-5764-47B9-A92E-EE3BDA7EE164@imperial.ac.uk>
References: <FF722405-D2AB-48EF-95B6-E34BB42CCF9B@imperial.ac.uk>	<48283A9F.5010905@gmail.com>
	<8D0D1242-5764-47B9-A92E-EE3BDA7EE164@imperial.ac.uk>
Message-ID: <48284B49.7070208@forkstam.se>



Federico Calboli wrote:
>> Maybe you are looking for something similar to:
>>
>> set.seed(78987)
>> a = rep(1:3,each=120)
>> b = rep(1:3,3, each=40)
>> c = rep(1:10,9,each=4)
>> y = rnorm(360,0,10)
>> x = cbind(a,b,c,y)
>> colnames(x) = c("a", "b", "c", "y")
>> x = as.data.frame(x)
>>
>> lme = lme(y ~ factor(a)*factor(b)*factor(c)-1, x, ~factor(c))
>> anova(lme)
>
> With the very same model you're using I get:
>
> > lme.mod = lme(y ~ selection * males * month-1, random = ~month, 
> testdat)
> Error in getGroups.data.frame(dataMix, groups) :
>   Invalid formula for groups
> > lme.mod = lme(y ~ selection * males * (month-1), random = ~month, 
> testdat)
> Error in getGroups.data.frame(dataMix, groups) :
>   Invalid formula for groups

Try

lme = lme(y ~ factor(a)*factor(b)*factor(c)-1, x, ~1|factor(c))

Good luck,
Christian

-- 
christian forkstam____________________________________________
|________|_NETHERLANDS________________________________________|
|   work | max planck institute, PO box 310, 6500AH nijmegen  |
|        | f.c. donders centre, PO box 9101, 6500HB nijmegen  |
|________|_SWEDEN_____________________________________________|
| mobile | +46 (0)73 0242643                                  |
|___work | mrcenter, N8, karolinska hospital, 17176 stockholm |



From f.calboli at imperial.ac.uk  Mon May 12 16:25:12 2008
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Mon, 12 May 2008 15:25:12 +0100
Subject: [R-sig-ME] [R] lme nesting/interaction advice
In-Reply-To: <a072ed700805120421i3420bc30h9975f17642ad08eb@mail.gmail.com>
References: <48242FC2.4090708@imperial.ac.uk>
	<2ad0cc110805092336q28a28378t43dcc7aef909891@mail.gmail.com>
	<2F2DF043-C762-48E1-9892-69E1C728EE30@imperial.ac.uk>
	<20080511214549.GT1279@ms.unimelb.edu.au>
	<993D1DD8-1AD4-4094-ABC9-7CFD605DD5DB@auckland.ac.nz>
	<20080512000558.GA20606@ms.unimelb.edu.au>
	<FF722405-D2AB-48EF-95B6-E34BB42CCF9B@imperial.ac.uk>
	<20080512101625.GW1279@ms.unimelb.edu.au>
	<05F09328-9CFF-46BB-B1E6-68059E628490@imperial.ac.uk>
	<a072ed700805120421i3420bc30h9975f17642ad08eb@mail.gmail.com>
Message-ID: <F051C842-D157-4F36-8CC6-8903750DBFDA@imperial.ac.uk>

On 12 May 2008, at 12:21, Nick Isaac wrote:

>
> I *think* the syntax for the model Federico wants is this:
>
> lmer(y~selection*males+ (selection|month) + (males|month))

I'll try and check against some back of the envelope calculations -- 
as I said, the model is, per se, nothing really new, and my data is  
fully balanced.

> My lme syntax is a bit rusty, so I'm not confident how to recode  
> with nested random effects, as in P&B p24.
>
>
> Two quick points:
> 1. I think Federico has caused some confusion on account of the way  
> he used the term 'crossing'

Sorry about that, I'll try to avoid causing such confusion in the  
future.

Cheers,

/F

--
Federico C. F. Calboli
Department of Epidemiology and Public Health
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From f.calboli at imperial.ac.uk  Mon May 12 16:26:53 2008
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Mon, 12 May 2008 15:26:53 +0100
Subject: [R-sig-ME] [R] lme nesting/interaction advice
In-Reply-To: <ED7B522EE00C9A4FA515AA71724D61EE2EBF23@DC1EXCL01.air.org>
References: <ED7B522EE00C9A4FA515AA71724D61EE2EBF23@DC1EXCL01.air.org>
Message-ID: <36FF05E2-A132-43DC-9899-EB9C62A82E02@imperial.ac.uk>

On 12 May 2008, at 14:37, Doran, Harold wrote:
>
> I haven't followed this thread carefully, so apologies if I'm too off
> base. But, in response to Rolf's questions/issues. First, SAS cannot
> handle models with crossed random effects (at least well at all).  
> SAS is
> horribly incapable of handling even the simplest of models (especially
> generalized linear mixed models). I can cite numerous (recent)  
> examples
> of SAS coming to a complete halt (proc nlmixed) for an analyses we  
> were
> recently working on. R (and Ubuntu) was the only solution to our
> problem

First off, let's keep SAS out of this. I never used it, never wanted  
to use it and did not mention anywhere I wanted to get SAS-like  
results! Although, seeing how easily it creeps up, I can sympathise  
with those who have strog feelings about it! [for those with strong  
feelings about me, this is meant to be something joke-like]

> Now, lme is not optimized for crossed random effects, but lmer is.  
> That
> is why lmer is supported and lme is not really supported much. lmer is
> optimized for models with nested random effects and crossed random
> effects.
>
> When working with models with nested random effects, and software
> optimized for those problems (e.g., HLM, SAS, mlWin) the
> variance/covariance matrix forms a special, and simple structure that
> can be easily worked with. This is not the case for models with  
> crossed
> random effects.
>
> Software packages designed for nested random effects can be tricked  
> into
> handling models with crossed random effects, but this kludge is  
> slow and
> really inefficient.
>
> If you want complete transparency into the why and how, here is a
> citation for your review.

Thank you very much. I'll read the paper and hopefully get the  
answers I was looking for.

Best,

Federico


>
> Best
> Harold
>
> @article{Doran:Bates:Bliese:Dowling:2007:JSSOBK:v20i02,
>   author =	"Harold  Doran and Douglas  Bates and Paul  Bliese and
> Maritza   Dowling",
>   title =	"Estimating the Multilevel Rasch Model: With the lme4
> Package",
>   journal =	"Journal of Statistical Software",
>   volume =	"20",
>   number =	"2",
>   pages =	"1--18",
>   day =  	"22",
>   month =	"2",
>   year = 	"2007",
>   CODEN =	"JSSOBK",
>   ISSN = 	"1548-7660",
>   bibdate =	"2007-02-22",
>   URL =  	"http://www.jstatsoft.org/v20/i02",
>   accepted =	"2007-02-22",
>   acknowledgement = "",
>   keywords =	"",
>   submitted =	"2006-10-01",
> }
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--
Federico C. F. Calboli
Department of Epidemiology and Public Health
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From kw.statr at gmail.com  Mon May 12 16:56:17 2008
From: kw.statr at gmail.com (Kevin Wright)
Date: Mon, 12 May 2008 09:56:17 -0500
Subject: [R-sig-ME] [R] lme nesting/interaction advice
In-Reply-To: <8D0D1242-5764-47B9-A92E-EE3BDA7EE164@imperial.ac.uk>
References: <FF722405-D2AB-48EF-95B6-E34BB42CCF9B@imperial.ac.uk>
	<48283A9F.5010905@gmail.com>
	<8D0D1242-5764-47B9-A92E-EE3BDA7EE164@imperial.ac.uk>
Message-ID: <c968588d0805120756l525bc772of44bdfc155c9ce9a@mail.gmail.com>

> > Maybe you are looking for something similar to:
> >
> > set.seed(78987)
> > a = rep(1:3,each=120)
> > b = rep(1:3,3, each=40)
> > c = rep(1:10,9,each=4)
> > y = rnorm(360,0,10)
> > x = cbind(a,b,c,y)
> > colnames(x) = c("a", "b", "c", "y")
> > x = as.data.frame(x)
> >
> > lme = lme(y ~ factor(a)*factor(b)*factor(c)-1, x, ~factor(c))
> > anova(lme)
> >
>
>  With the very same model you're using I get:
>
>  > lme.mod = lme(y ~ selection * males * month-1, random = ~month, testdat)
>  Error in getGroups.data.frame(dataMix, groups) :
>   Invalid formula for groups
>  > lme.mod = lme(y ~ selection * males * (month-1), random = ~month,
> testdat)
>  Error in getGroups.data.frame(dataMix, groups) :
>   Invalid formula for groups
>
>  I copy/paste the datset below, in case it makes things clearer.
>
>  Thanks,
>
>  Federico

I tried the code at the top of this message--it did not work for me.
The example uses some unfortunate code.  For example, it is not a good
idea to have a data frame 'lme' and a function name 'lme'.  Also,
there are vector objects a, b, and c.  These vectors are then put into
a data frame x and then the lme call refers to 'factor(a)', but is
this the vector a or the column a in the data frame x?  It is a
confusing example.

I have several times found that lme works a lot better with
groupedData objects than data frames.  (Adds confusion in my opinion,
but has some nice features such as groupedData plot methods).

For your data, try this:

d=read.table("c:/data.txt",header=TRUE)
d2=groupedData(y~selection|block, data=d)
mod=lme(y ~ selection * males * month-1, random = ~month, d2)
anova(mod)


Kevin Wright



From bolker at ufl.edu  Mon May 12 17:45:15 2008
From: bolker at ufl.edu (Ben Bolker)
Date: Mon, 12 May 2008 11:45:15 -0400
Subject: [R-sig-ME] general GLMM questions
In-Reply-To: <40e66e0b0805090752y6663eedel413b1d3cf692e77f@mail.gmail.com>
References: <4821CD4B.5090701@ufl.edu>
	<40e66e0b0805090752y6663eedel413b1d3cf692e77f@mail.gmail.com>
Message-ID: <4828660B.40007@ufl.edu>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

| lme4-specific questions:
|
| 6. Behavior of glmer: Does glmer really use AGQ, or just Laplace?
| Both?  pp. 28-32 of the "Implementation" vignette in lme4 suggest that
| a Laplace approximation is used, but I can't figure out whether this
| is an additional approximation on top of the AGQ/Laplace approximation
| of the integral over the random effects used in "ordinary" LMM.  When
| I fit a GLMM with the different methods, the fitted objects are not
| identical but all the coefficients seem to be.  (I have poked at the
| code a bit but been unable to answer this question for myself
| ... sorry ...)
|
|> To answer this question I must again, I regret, distinguish between
|> the CRAN version of the lme4 package and the R-forge development
|> version of lme4.
|
|> In the R-forge version the only method for generalized linear mixed
|> models and for nonlinear mixed models is direct optimization of the
|> Laplace approximation to the deviance.  One of the Summer of Code
|> projects that Google has funded for the R Foundation (see
|> http://code.google.com/soc/2008/rf/about.html) is implementation of
|> the Adaptive Gauss-Hermite Quadrature approximation to the deviance.
|> That will be implemented in the development version (i.e. the R-forge
|> version) of the lme4 package.  [snip]

~   Great!

~  A minor feature request: does it make sense to update the
documentation and code of glmer to make it clear that it does
*not* do AGQ at the moment?  I guess that depends how soon you
would expect the GSoC code to come online ...

|> I realize that it is somewhat irritating and confusing to readers of
|> this list to have descriptions of the R-forge version of the package
|> contrasted with the CRAN version.  It is natural to expect that the
|> R-forge version should be the version on CRAN.  The reason that I have
|> not yet released the R-forge to CRAN is because of problems with the
|> mcmcsamp function in the R-forge version.  If I moved the R-forge
|> version to CRAN then code from Harald Baayen's book and probably code
|> from Gelman and Hill's book would no longer work.  Software versions
|> can be changed much more readily than can editions of a book.  I think
|> there is a way around the problem with mcmcsamp but I won't be able to
|> say for sure until it is coded and tested, which will take time.  I
|> don't want to predict exactly how much time - I always manage to
|> underestimate drastically.

~   If (just hypothetically speaking) I were writing a review that
would be published in 6 months or so, do you have a recommendation?
(Would you still trust GLMM/mcmcsamp results from the CRAN version?)

| (The glmmML package claims to fit via Laplace or Gauss-Hermite
| quadrature (with non-adaptive, but adjustable, number of quad points
| -- so it's at least theoretically possible?)
|
|> Yes.  I think the adaptive part is important (in fact, I know it is
|> important) and probably more important than the distinction between
|> the Laplace approximation and Gauss-Hermite quadrature.  That is, you
|> gain more from using the Laplace approximation at the conditional
|> modes of the random effects (which is the "adaptive" part) than
|> increasing the number of Gauss-Hermite quadrature points at the
|> marginal modes.  The tricky bit of AGQ or Laplace is determining the
|> conditional modes and that part is already done.

~  OK, I was confused about the distinction in the meaning of
"adaptive" (as you pointed out previously on r-help ...)  I think
I have it now.

https://stat.ethz.ch/pipermail/r-help/2007-March/128043.html

~  thanks for your help!

~  Ben Bolker
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.6 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org

iD8DBQFIKGYLc5UpGjwzenMRAoBnAJ0R7w6FHL8uTaz3OKmMvJWHByS0tACdEy4x
ABU30kHrB/eNoXcHMvJJ4LE=
=whoY
-----END PGP SIGNATURE-----



From bates at stat.wisc.edu  Mon May 12 18:09:20 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 12 May 2008 11:09:20 -0500
Subject: [R-sig-ME] [R]  lme nesting/interaction advice
In-Reply-To: <36FF05E2-A132-43DC-9899-EB9C62A82E02@imperial.ac.uk>
References: <ED7B522EE00C9A4FA515AA71724D61EE2EBF23@DC1EXCL01.air.org>
	<36FF05E2-A132-43DC-9899-EB9C62A82E02@imperial.ac.uk>
Message-ID: <40e66e0b0805120909r5da2c1d4q6cdcf9e33e907672@mail.gmail.com>

I'm entering this discussion late so I may be discussing issues that
have already been addressed.

As I understand it, Federico, you began by describing a model for data
in which two factors have a fixed set of levels and one factor has an
extensible, or "random", set of levels and you wanted to fit a model
that you described as

y ~ effect1 * effect2 * effect3

The problem is that this specification is not complete.  An
interaction of factors with fixed levels and a factor with random
levels can mean, in the lmer specification,

lmer(y ~ effect1 * effect2 + (1| effect3) + (1|effect1:effect2:effect3), ...)

or

lmer(y ~ effect1 * effect2 + (effect1*effect2 | effect3), ...)

or other variations.  When you specify a random effect or an random
interaction term you must, either explicitly or implicitly, specify
the form of the variance-covariance matrix associated with those
random effects.

The "advantage" that other software may provide for you is that it
chooses the model for you but that, of course, means that you only
have the one choice.

If you can describe how many variance components you think should be
estimated in your model and what they would represent then I think it
will be easier to describe how to fit the model.



From f.calboli at imperial.ac.uk  Mon May 12 18:22:19 2008
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Mon, 12 May 2008 17:22:19 +0100
Subject: [R-sig-ME] [R]  lme nesting/interaction advice
In-Reply-To: <40e66e0b0805120909r5da2c1d4q6cdcf9e33e907672@mail.gmail.com>
References: <ED7B522EE00C9A4FA515AA71724D61EE2EBF23@DC1EXCL01.air.org>
	<36FF05E2-A132-43DC-9899-EB9C62A82E02@imperial.ac.uk>
	<40e66e0b0805120909r5da2c1d4q6cdcf9e33e907672@mail.gmail.com>
Message-ID: <BA9CEA4A-1228-40A4-8110-10F9D1B3500C@imperial.ac.uk>

On 12 May 2008, at 17:09, Douglas Bates wrote:

> I'm entering this discussion late so I may be discussing issues that
> have already been addressed.
>
> As I understand it, Federico, you began by describing a model for data
> in which two factors have a fixed set of levels and one factor has an
> extensible, or "random", set of levels and you wanted to fit a model
> that you described as
>
> y ~ effect1 * effect2 * effect3
>
> The problem is that this specification is not complete.

My apologies for that, I thought that the above formula was the  
shorthand for what I would call the 'full' model, i.e. the single  
factors and the 2 and 3 ways interactions.
> An
> interaction of factors with fixed levels and a factor with random
> levels can mean, in the lmer specification,
>
> lmer(y ~ effect1 * effect2 + (1| effect3) + (1| 
> effect1:effect2:effect3), ...)
>
> or
>
> lmer(y ~ effect1 * effect2 + (effect1*effect2 | effect3), ...)
>
> or other variations.  When you specify a random effect or an random
> interaction term you must, either explicitly or implicitly, specify
> the form of the variance-covariance matrix associated with those
> random effects.

I'll play around with this and see what I can get.
>
> The "advantage" that other software may provide for you is that it
> chooses the model for you but that, of course, means that you only
> have the one choice.

I'm more than happy to stick to R, and to put more legwork into my  
models
>
> If you can describe how many variance components you think should be
> estimated in your model and what they would represent then I think it
> will be easier to describe how to fit the model.

I'll work on that. Incidentally, what/where is the most comprehensive  
and up to date documentation for lme4? the pdfs coming with the  
package? I suspect knowing which are the right docs will help a lot  
in keeping me within the boundaries of civility and prevent me from  
annoying anyone (which is not something I sent forth to do on purpose).

Best regards,

Federico

--
Federico C. F. Calboli
Department of Epidemiology and Public Health
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From bates at stat.wisc.edu  Mon May 12 20:05:14 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 12 May 2008 13:05:14 -0500
Subject: [R-sig-ME] [R]  lme nesting/interaction advice
In-Reply-To: <BA9CEA4A-1228-40A4-8110-10F9D1B3500C@imperial.ac.uk>
References: <ED7B522EE00C9A4FA515AA71724D61EE2EBF23@DC1EXCL01.air.org>
	<36FF05E2-A132-43DC-9899-EB9C62A82E02@imperial.ac.uk>
	<40e66e0b0805120909r5da2c1d4q6cdcf9e33e907672@mail.gmail.com>
	<BA9CEA4A-1228-40A4-8110-10F9D1B3500C@imperial.ac.uk>
Message-ID: <40e66e0b0805121105t15ff1253x54a3fed9564e4113@mail.gmail.com>

On Mon, May 12, 2008 at 11:22 AM, Federico Calboli
<f.calboli at imperial.ac.uk> wrote:
> On 12 May 2008, at 17:09, Douglas Bates wrote:
>
>> I'm entering this discussion late so I may be discussing issues that
>> have already been addressed.
>>
>> As I understand it, Federico, you began by describing a model for data
>> in which two factors have a fixed set of levels and one factor has an
>> extensible, or "random", set of levels and you wanted to fit a model
>> that you described as
>>
>> y ~ effect1 * effect2 * effect3
>>
>> The problem is that this specification is not complete.
>
> My apologies for that, I thought that the above formula was the shorthand
> for what I would call the 'full' model, i.e. the single factors and the 2
> and 3 ways interactions.

As I indicated, the trick is that the interaction of a fixed factor
and a random factor can be defined in more than one way.

It sounds as if what you want is

lmer(y ~ factor1 * factor2 + (1|factor3) + (1|factor1:factor3) +
(1|factor2:factor3) + (1|factor1:factor2:factor3), ...)

but I'm not sure.

>> An interaction of factors with fixed levels and a factor with random
>> levels can mean, in the lmer specification,
>>
>> lmer(y ~ effect1 * effect2 + (1| effect3) + (1|effect1:effect2:effect3),
>> ...)
>>
>> or
>>
>> lmer(y ~ effect1 * effect2 + (effect1*effect2 | effect3), ...)
>>
>> or other variations.  When you specify a random effect or an random
>> interaction term you must, either explicitly or implicitly, specify
>> the form of the variance-covariance matrix associated with those
>> random effects.
>
> I'll play around with this and see what I can get.
>>
>> The "advantage" that other software may provide for you is that it
>> chooses the model for you but that, of course, means that you only
>> have the one choice.
>
> I'm more than happy to stick to R, and to put more legwork into my models
>>
>> If you can describe how many variance components you think should be
>> estimated in your model and what they would represent then I think it
>> will be easier to describe how to fit the model.
>
> I'll work on that. Incidentally, what/where is the most comprehensive and up
> to date documentation for lme4? the pdfs coming with the package? I suspect
> knowing which are the right docs will help a lot in keeping me within the
> boundaries of civility and prevent me from annoying anyone (which is not
> something I sent forth to do on purpose).

Documentation for lme4 is pretty sketchy at present.  I hope to remedy
that during our summer break.



From bates at stat.wisc.edu  Mon May 12 20:33:39 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 12 May 2008 13:33:39 -0500
Subject: [R-sig-ME] Fwd: help with a cross-classified random effects model
	code in R.
In-Reply-To: <40e66e0b0805121038y5d2d894ewb4989981cf1af415@mail.gmail.com>
References: <c3ade87e0805091529o566d7350r518055efbda062a7@mail.gmail.com>
	<40e66e0b0805121038y5d2d894ewb4989981cf1af415@mail.gmail.com>
Message-ID: <40e66e0b0805121133h559b335esc6c566b6c8dcf21f@mail.gmail.com>

---------- Forwarded message ----------
From: Douglas Bates <bates at stat.wisc.edu>
Date: Mon, May 12, 2008 at 12:38 PM
Subject: Re: help with a cross-classified random effects model code in R.
To: "Violet(Shu) Xu" <shuxu at ucdavis.edu>


On Fri, May 9, 2008 at 5:29 PM, Violet(Shu) Xu <shuxu at ucdavis.edu> wrote:
> Dear Dr. Bates,

>  I have a question about fitting a cross-classified random effects model in
> R.

There are now two packages in R for fitting linear mixed effects
models using maximum likelihood or REML.  The more recent of these
packages, called lme4, is the better choice for fitting models with
crossed or partially crossed factors for the random effects.  I would
recommend using that package rather than trying to cobble together a
solution using lme.


> The model can be expressed in SAS code as follows (from
> http://www.ats.ucla.edu/stat/sas/examples/mlm_ma_hox/chapter7.htm):

Thank you for the URL to the SAS code and results.  I enclose analyses
that I believe reproduce the SAS results using the development version
of the lme4 package, which you can install with

install.packages("lme4", repos = "http://R-forge.R-project.org")

This script uses the pupcross.dta file from the Stata form of the data
files, available as

http://www.ats.ucla.edu/stat/stata/examples/mlm_ma_hox/ma_hox_stata.ZIP


> proc mixed data =pupcross covtest noclprint method=ml;
>   class pupil pschool sschool;
>   model achiev =   / solution ddfm =satterth;
>   random intercept / subject=sschool;
>   random intercept / subject=pschool;
> run;
>
> I tried to fit it in R, however I did not get the same estimates,
> especially the estimate of the random effects .  Would you help me to
> figure out what is the problem in my code?
>
> My R(version 2.5.1) code as follows
> pupcross = read.csv("pupcross.csv", header=T, na.strings = '.')
> head(pupcross)
> pupcross$cons = 1
>
> pupcrossg = groupedData(achiev ~ 1 |cons,  data = pupcross)
>
> pupcrossg.m1 = lme(achiev~1, random =
> pdBlocked(list(pdIdent(~pschool-1),pdIdent(~sschool-1))),
>                  data = pupcrossg)
>
> Thank you for your time and consideration. Have a nice weekend .
>
> --
> Shu (Violet) Xu
> --*-*--*-*--*-*--*-*--*-*--*-*--
> Graduate student
> Quantitative Psychology program
> Department of Psychology
> University of California, Davis

From HStevens at muohio.edu  Tue May 13 13:54:20 2008
From: HStevens at muohio.edu (Martin Henry H. Stevens)
Date: Tue, 13 May 2008 07:54:20 -0400
Subject: [R-sig-ME] [R]  lme nesting/interaction advice
In-Reply-To: <C6F74B16-D507-44FA-935B-18A5642A791A@auckland.ac.nz>
References: <ED7B522EE00C9A4FA515AA71724D61EE2EBF23@DC1EXCL01.air.org>
	<36FF05E2-A132-43DC-9899-EB9C62A82E02@imperial.ac.uk>
	<40e66e0b0805120909r5da2c1d4q6cdcf9e33e907672@mail.gmail.com>
	<C6F74B16-D507-44FA-935B-18A5642A791A@auckland.ac.nz>
Message-ID: <3B35775E-7295-4AB1-ACCF-CB8B8417615D@muohio.edu>

Hi Rolf,
..
On May 12, 2008, at 6:39 PM, Rolf Turner wrote:
>
> On 13/05/2008, at 4:09 AM, Douglas Bates wrote:
>
>> I'm entering this discussion late so I may be discussing issues that
>> have already been addressed.
>>
>> As I understand it, Federico, you began by describing a model for  
>> data
>> in which two factors have a fixed set of levels and one factor has an
>> extensible, or "random", set of levels and you wanted to fit a model
>> that you described as
>>
>> y ~ effect1 * effect2 * effect3
>>
>> The problem is that this specification is not complete.
>
>         At *last* (as Owl said to Rabbit) we're getting somewhere!!!
>
>         I always knew that there was some basic fundamental point
>         about this business that I (and I believe many others) were
>         simply missing.  But I could not for the life of me get anyone
>         to explain to me what that point was.  Or to put it another
>         way, I was never able to frame a question that would  
> illuminate
>         just what it was that I wasn't getting.
>
>         I now may be at a stage where I can start asking the right
>         questions.
>
>> An interaction of factors with fixed levels and a factor with random
>> levels can mean, in the lmer specification,
>>
>> lmer(y ~ effect1 * effect2 + (1| effect3) + (1|
>> effect1:effect2:effect3), ...)
>>
>> or
>>
>> lmer(y ~ effect1 * effect2 + (effect1*effect2 | effect3), ...)
>>
>> or other variations.  When you specify a random effect or an random
>> interaction term you must, either explicitly or implicitly, specify
>> the form of the variance-covariance matrix associated with those
>> random effects.
>>
>> The "advantage" that other software may provide for you is that it
>> chooses the model for you but that, of course, means that you only
>> have the one choice.
>
>         Now may I start asking what I hope are questions that will  
> lift
>         the fog a bit?
>
>         Let us for specificity consider a three-way model with two
>         fixed effects and one random effect from the good old  
> Rothamstead style
>         agricultural experiment context:  Suppose we have a number of
>         species/breeds of wheat (say) and a number of fertilizers.
>         These are fixed effects.  And we have a number of fields  
> (blocks)
>         --- a random effect.  Each breed-fertilizer combination is
>         applied a number of times in each field.  We ***assume*** that
>         that the field or block effect is homogeneous throughout.   
> This
>         may or may not be a ``good'' assumption, but it's not  
> completely
>         ridiculous and would often be made in practice.  And probably
>         *was* made at Rothamstead.  The response would be something  
> like
>         yield in bushels per acre.
>
>         The way that I would write the ``full'' model for this  
> setting,
>         in mathematical style is:
>
>         Y_ijkl = mu + alpha_i + beta_j + (alpha.beta)_ij + C_k +  
> (alpha.C)_ik
>                      + (beta.C)_jk + (alpha.beta.C)_ijk + E_ijkl
>
>         The alpha_i and beta_j are parameters corresponding to  
> breed and
> fertilizer
>         respectively; the C_k are random effects corresponding to  
> fields or
> blocks.
>         Any effect ``involving'' C is also random.
>
>         The assumptions made by the Package-Which-Must-Not-Be-Named  
> are (I
> think)
>         that
>
>                 C_k ~ N(0,sigma_C^2)
>                 (alpha.C)_ik ~ N(0,sigma_aC^2)
>                 (beta.C)jk ~ N(0,sigma_bC^2)
>                 (alpha.beta.C)_ijk ~ N(0,sigma_abC^2)
>                 E_ijkl ~ N(0,sigma^2)
>
>         and these random variables are *all independent*.
>
>         Ahhhhhhhh ... perhaps I'm on the way to answering my own  
> question.  Is
>         it this assumption of ``all independent'' which is  
> questionable?  It
>         seemed innocent enough when I first learned about this  
> stuff, lo these
>         many years ago.  But .... mmmmmaybe not!
>
>         To start with:  What would be the lmer syntax to fit the  
> foregoing
>         (possibly naive) model?  I am sorry, but I really cannot  
> get my head
>         around the syntax of lmer model specification, and I've tried.
Did you answer your own question, (or what am I missing something):
Y ~ a*b +(1|C) + (1|aC) + (1|bC) + (1|abC)  plus of course epsilon.ijkl

Regarding interdependence - yikes. I don't even know what that would  
mean. In part, it seems that would mean non-zero variance components  
for  (1|aC), (1|bC), and (1|abC). Beyond that, and beyond simple  
heterogenous variances, I am even more lost.

Hank
> I
>         really have.  Hard.  I know I must be starting from the  
> wrong place,
>         but I haven't a clue as to what the *right* place to start  
> from is.
>         And if I'm in that boat, I will wager Euros to pretzels  
> that there
>         are others in it.  I know that I'm not the brightest bulb  
> in the
>         chandelier, but I'm not the dullest either.
>
>         Having got there:  Presuming that I'm more-or-less on the  
> right track
>         in my foregoing conjecture that it's the over-simple  
> dependence
> structure
>         that is the problem with what's delivered by the Package- 
> Which-Must-
> Not-Be-Named,
>         how might one go about being less simple-minded?  I.e. what  
> might be
> some
>         more realistic dependence structures, and how would one  
> specify
> these in lmer?
>         And how would one assess whether the assumed dependence  
> structure gives
>         a reasonable fit to the data?
>
>> If you can describe how many variance components you think should be
>> estimated in your model and what they would represent then I think it
>> will be easier to describe how to fit the model.
>
>         How does this fit in with my conjecture (above) about what  
> I've been
>         missing all these years?  Does it fit?  How many variance  
> components
>         are there in the ``naive'' model?  It looks like 5 to  
> me ... but maybe
>         I'm totally out to lunch in what I think I'm understanding  
> at this
> stage.
>         (And besides --- there are three sorts of statistician;  
> those who
> can count,
>         and those who can't.)
>
>         Thank you for your indulgence.
>
>                  cheers,
>
>                         Rolf Turner
>
> ######################################################################
> Attention:\ This e-mail message is privileged and confid... 
> {{dropped:9}}
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

Dr. Hank Stevens, Associate Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/~stevenmh/
http://www.users.muohio.edu/harkesae/
http://www.cas.muohio.edu/ecology
http://www.muohio.edu/botany/
"E Pluribus Unum"

"I love deadlines. I love the whooshing noise they make as they go by."
                                             (Douglas Adams)


If you send an attachment, please try to send it in a format anyone  
can read, such as PDF, text, Open Document Format, HTML, or RTF.
Why? See:  http://www.gnu.org/philosophy/no-word-attachments.html



From r.turner at auckland.ac.nz  Tue May 13 00:39:36 2008
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 13 May 2008 10:39:36 +1200
Subject: [R-sig-ME] [R]  lme nesting/interaction advice
In-Reply-To: <40e66e0b0805120909r5da2c1d4q6cdcf9e33e907672@mail.gmail.com>
References: <ED7B522EE00C9A4FA515AA71724D61EE2EBF23@DC1EXCL01.air.org>
	<36FF05E2-A132-43DC-9899-EB9C62A82E02@imperial.ac.uk>
	<40e66e0b0805120909r5da2c1d4q6cdcf9e33e907672@mail.gmail.com>
Message-ID: <C6F74B16-D507-44FA-935B-18A5642A791A@auckland.ac.nz>


On 13/05/2008, at 4:09 AM, Douglas Bates wrote:

> I'm entering this discussion late so I may be discussing issues that
> have already been addressed.
>
> As I understand it, Federico, you began by describing a model for data
> in which two factors have a fixed set of levels and one factor has an
> extensible, or "random", set of levels and you wanted to fit a model
> that you described as
>
> y ~ effect1 * effect2 * effect3
>
> The problem is that this specification is not complete.

	At *last* (as Owl said to Rabbit) we're getting somewhere!!!

	I always knew that there was some basic fundamental point
	about this business that I (and I believe many others) were
	simply missing.  But I could not for the life of me get anyone
	to explain to me what that point was.  Or to put it another
	way, I was never able to frame a question that would illuminate
	just what it was that I wasn't getting.

	I now may be at a stage where I can start asking the right
	questions.

> An interaction of factors with fixed levels and a factor with random
> levels can mean, in the lmer specification,
>
> lmer(y ~ effect1 * effect2 + (1| effect3) + (1| 
> effect1:effect2:effect3), ...)
>
> or
>
> lmer(y ~ effect1 * effect2 + (effect1*effect2 | effect3), ...)
>
> or other variations.  When you specify a random effect or an random
> interaction term you must, either explicitly or implicitly, specify
> the form of the variance-covariance matrix associated with those
> random effects.
>
> The "advantage" that other software may provide for you is that it
> chooses the model for you but that, of course, means that you only
> have the one choice.

	Now may I start asking what I hope are questions that will lift
	the fog a bit?

	Let us for specificity consider a three-way model with two
	fixed effects and one random effect from the good old Rothamstead style
	agricultural experiment context:  Suppose we have a number of
	species/breeds of wheat (say) and a number of fertilizers.
	These are fixed effects.  And we have a number of fields (blocks)
	--- a random effect.  Each breed-fertilizer combination is
	applied a number of times in each field.  We ***assume*** that
	that the field or block effect is homogeneous throughout.  This
	may or may not be a ``good'' assumption, but it's not completely
	ridiculous and would often be made in practice.  And probably
	*was* made at Rothamstead.  The response would be something like
	yield in bushels per acre.

	The way that I would write the ``full'' model for this setting,
	in mathematical style is:

	Y_ijkl = mu + alpha_i + beta_j + (alpha.beta)_ij + C_k + (alpha.C)_ik
                     + (beta.C)_jk + (alpha.beta.C)_ijk + E_ijkl

	The alpha_i and beta_j are parameters corresponding to breed and  
fertilizer
	respectively; the C_k are random effects corresponding to fields or  
blocks.
	Any effect ``involving'' C is also random.

	The assumptions made by the Package-Which-Must-Not-Be-Named are (I  
think)
	that

		C_k ~ N(0,sigma_C^2)
		(alpha.C)_ik ~ N(0,sigma_aC^2)
		(beta.C)jk ~ N(0,sigma_bC^2)
		(alpha.beta.C)_ijk ~ N(0,sigma_abC^2)
		E_ijkl ~ N(0,sigma^2)

	and these random variables are *all independent*.

	Ahhhhhhhh ... perhaps I'm on the way to answering my own question.  Is
	it this assumption of ``all independent'' which is questionable?  It
	seemed innocent enough when I first learned about this stuff, lo these
	many years ago.  But .... mmmmmaybe not!

	To start with:  What would be the lmer syntax to fit the foregoing
	(possibly naive) model?  I am sorry, but I really cannot get my head
	around the syntax of lmer model specification, and I've tried.  I
	really have.  Hard.  I know I must be starting from the wrong place,
	but I haven't a clue as to what the *right* place to start from is.
	And if I'm in that boat, I will wager Euros to pretzels that there
	are others in it.  I know that I'm not the brightest bulb in the
	chandelier, but I'm not the dullest either.

	Having got there:  Presuming that I'm more-or-less on the right track
	in my foregoing conjecture that it's the over-simple dependence  
structure
	that is the problem with what's delivered by the Package-Which-Must- 
Not-Be-Named,
	how might one go about being less simple-minded?  I.e. what might be  
some
	more realistic dependence structures, and how would one specify  
these in lmer?
	And how would one assess whether the assumed dependence structure gives
	a reasonable fit to the data?

> If you can describe how many variance components you think should be
> estimated in your model and what they would represent then I think it
> will be easier to describe how to fit the model.

	How does this fit in with my conjecture (above) about what I've been
	missing all these years?  Does it fit?  How many variance components
	are there in the ``naive'' model?  It looks like 5 to me ... but maybe
	I'm totally out to lunch in what I think I'm understanding at this  
stage.
	(And besides --- there are three sorts of statistician; those who  
can count,
	and those who can't.)

	Thank you for your indulgence.

		 cheers,

			Rolf Turner

######################################################################
Attention:\ This e-mail message is privileged and confid...{{dropped:9}}



From bates at stat.wisc.edu  Tue May 13 18:49:55 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 13 May 2008 11:49:55 -0500
Subject: [R-sig-ME] [R]  lme nesting/interaction advice
In-Reply-To: <C6F74B16-D507-44FA-935B-18A5642A791A@auckland.ac.nz>
References: <ED7B522EE00C9A4FA515AA71724D61EE2EBF23@DC1EXCL01.air.org>
	<36FF05E2-A132-43DC-9899-EB9C62A82E02@imperial.ac.uk>
	<40e66e0b0805120909r5da2c1d4q6cdcf9e33e907672@mail.gmail.com>
	<C6F74B16-D507-44FA-935B-18A5642A791A@auckland.ac.nz>
Message-ID: <40e66e0b0805130949s322ae848q4c6bfd4c831193d0@mail.gmail.com>

On Mon, May 12, 2008 at 5:39 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
> On 13/05/2008, at 4:09 AM, Douglas Bates wrote:
>
>> I'm entering this discussion late so I may be discussing issues that
>> have already been addressed.
>>
>> As I understand it, Federico, you began by describing a model for data
>> in which two factors have a fixed set of levels and one factor has an
>> extensible, or "random", set of levels and you wanted to fit a model
>> that you described as
>>
>> y ~ effect1 * effect2 * effect3
>>
>> The problem is that this specification is not complete.
>
>        At *last* (as Owl said to Rabbit) we're getting somewhere!!!
>
>        I always knew that there was some basic fundamental point
>        about this business that I (and I believe many others) were
>        simply missing.  But I could not for the life of me get anyone
>        to explain to me what that point was.  Or to put it another
>        way, I was never able to frame a question that would illuminate
>        just what it was that I wasn't getting.
>
>        I now may be at a stage where I can start asking the right
>        questions.
>
>> An interaction of factors with fixed levels and a factor with random
>> levels can mean, in the lmer specification,
>>
>> lmer(y ~ effect1 * effect2 + (1| effect3) + (1|effect1:effect2:effect3),
>> ...)
>>
>> or
>>
>> lmer(y ~ effect1 * effect2 + (effect1*effect2 | effect3), ...)
>>
>> or other variations.  When you specify a random effect or an random
>> interaction term you must, either explicitly or implicitly, specify
>> the form of the variance-covariance matrix associated with those
>> random effects.
>>
>> The "advantage" that other software may provide for you is that it
>> chooses the model for you but that, of course, means that you only
>> have the one choice.
>
>        Now may I start asking what I hope are questions that will lift
>        the fog a bit?
>
>        Let us for specificity consider a three-way model with two
>        fixed effects and one random effect from the good old Rothamstead
> style
>        agricultural experiment context:  Suppose we have a number of
>        species/breeds of wheat (say) and a number of fertilizers.
>        These are fixed effects.  And we have a number of fields (blocks)
>        --- a random effect.  Each breed-fertilizer combination is
>        applied a number of times in each field.  We ***assume*** that
>        that the field or block effect is homogeneous throughout.  This
>        may or may not be a ``good'' assumption, but it's not completely
>        ridiculous and would often be made in practice.  And probably
>        *was* made at Rothamstead.  The response would be something like
>        yield in bushels per acre.
>
>        The way that I would write the ``full'' model for this setting,
>        in mathematical style is:
>
>        Y_ijkl = mu + alpha_i + beta_j + (alpha.beta)_ij + C_k + (alpha.C)_ik
>                    + (beta.C)_jk + (alpha.beta.C)_ijk + E_ijkl
>
>        The alpha_i and beta_j are parameters corresponding to breed and
> fertilizer
>        respectively; the C_k are random effects corresponding to fields or
> blocks.
>        Any effect ``involving'' C is also random.
>
>        The assumptions made by the Package-Which-Must-Not-Be-Named are (I
> think)
>        that
>
>                C_k ~ N(0,sigma_C^2)
>                (alpha.C)_ik ~ N(0,sigma_aC^2)
>                (beta.C)jk ~ N(0,sigma_bC^2)
>                (alpha.beta.C)_ijk ~ N(0,sigma_abC^2)
>                E_ijkl ~ N(0,sigma^2)
>
>        and these random variables are *all independent*.
>
>        Ahhhhhhhh ... perhaps I'm on the way to answering my own question.
>  Is
>        it this assumption of ``all independent'' which is questionable?  It
>        seemed innocent enough when I first learned about this stuff, lo
> these
>        many years ago.  But .... mmmmmaybe not!
>
>        To start with:  What would be the lmer syntax to fit the foregoing
>        (possibly naive) model?  I am sorry, but I really cannot get my head
>        around the syntax of lmer model specification, and I've tried.  I
>        really have.  Hard.  I know I must be starting from the wrong place,
>        but I haven't a clue as to what the *right* place to start from is.
>        And if I'm in that boat, I will wager Euros to pretzels that there
>        are others in it.  I know that I'm not the brightest bulb in the
>        chandelier, but I'm not the dullest either.

Thanks for the questions, Rolf.  I completely agree that mixed model
specification can be an extremely confusing area.

Let's consider a set of models for the Machines data reproduced (from
Milliken and Johnson) in Pinheiro and Bates and available in the MEMSS
package.

> library(lme4)
Loading required package: Matrix
Loading required package: lattice

Attaching package: 'Matrix'


	The following object(s) are masked from package:stats :

	 xtabs
> data("Machines", package = "MEMSS")
> str(Machines)
'data.frame':	54 obs. of  3 variables:
 $ Worker : Factor w/ 6 levels "1","2","3","4",..: 1 1 1 2 2 2 3 3 3 4 ...
 $ Machine: Factor w/ 3 levels "A","B","C": 1 1 1 1 1 1 1 1 1 1 ...
 $ score  : num  52 52.8 53.1 51.8 52.8 53.1 60 60.2 58.4 51.1 ...

We consider the Machine factor to have a fixed set of levels in that
we only consider these three machines.  The levels of the Worker
factor represent a sample from the set of potential operators.  As you
might imagine from this description, I now think of the distinction
between "fixed" and "random" as being associated with the factor, not
necessarily the "effects".

If you plot these data
> dotplot(reorder(Worker, score) ~ score, Machines, groups = Machine, type = c("g", "p", "a"), xlab = "Efficiency score", ylab = "Worker", auto.key = list(columns = 3, lines = TRUE))

(resulting PDF enclosed) you will see evidence of an interaction.
That is, some workers have noticeably different score patterns on the
three machines than do others.  Worker 6 on machine B is the most
striking example.

One way to model this interaction is to say that there is a random
effect for each worker and a separate random effect for each
worker/machine combination.  If the random effects for the
worker/machine combinations are assumed to be independent with
constant variance then one expresses the model as

> print(fm1 <- lmer(score ~ Machine + (1|Worker) + (1|Machine:Worker), Machines), corr = FALSE)
Linear mixed model fit by REML
Formula: score ~ Machine + (1 | Worker) + (1 | Machine:Worker)
   Data: Machines
   AIC   BIC logLik deviance REMLdev
 227.7 239.6 -107.8    225.5   215.7
Random effects:
 Groups         Name        Variance Std.Dev.
 Machine:Worker (Intercept) 13.90963 3.72956
 Worker         (Intercept) 22.85528 4.78072
 Residual                    0.92464 0.96158
Number of obs: 54, groups: Machine:Worker, 18; Worker, 6

Fixed effects:
            Estimate Std. Error t value
(Intercept)   52.356      2.486  21.062
MachineB       7.967      2.177   3.659
MachineC      13.917      2.177   6.393

An equivalent formulation is
> print(fm1 <- lmer(score ~ Machine + (1|Worker/Machine), Machines), corr = FALSE)
Linear mixed model fit by REML
Formula: score ~ Machine + (1 | Worker/Machine)
   Data: Machines
   AIC   BIC logLik deviance REMLdev
 227.7 239.6 -107.8    225.5   215.7
Random effects:
 Groups         Name        Variance Std.Dev.
 Machine:Worker (Intercept) 13.90963 3.72956
 Worker         (Intercept) 22.85528 4.78072
 Residual                    0.92464 0.96158
Number of obs: 54, groups: Machine:Worker, 18; Worker, 6

Fixed effects:
            Estimate Std. Error t value
(Intercept)   52.356      2.486  21.062
MachineB       7.967      2.177   3.659
MachineC      13.917      2.177   6.393

The expression (1|Worker/Machine) is just "syntactic sugar".  It is
expanded to (1|Worker) + (1|Machine:Worker) before the model matrices
are created.

If you want to start with the formula and see what that means for the
model then use these rules:

- a term including the '|' operator is a random effects term
- if the left-hand side of the '|' operator is 1 then the random
effects are scalar random effects, one for each level of the factor on
the right of the '|'
- random effects associated with different terms are independent
- random effects associated with different levels of the factor within
a term are independent
- the variance of the random effects within the same term is constant

However, there is another mixed-effects model that could make sense
for these data.  Suppose I consider the variations associated with
each worker as a vector of length 3 (Machines A, B and C) with a
symmetric, positive semidefinite 3 by 3 variance-covariance matrix.  I
fit that model as

> print(fm2 <- lmer(score ~ Machine + (Machine|Worker), Machines), corr = FALSE)
Linear mixed model fit by REML
Formula: score ~ Machine + (Machine | Worker)
   Data: Machines
   AIC   BIC logLik deviance REMLdev
 228.3 248.2 -104.2    216.6   208.3
Random effects:
 Groups   Name        Variance Std.Dev. Corr
 Worker   (Intercept) 16.64051 4.07928
          MachineB    34.54670 5.87764   0.484
          MachineC    13.61398 3.68971  -0.365  0.297
 Residual              0.92463 0.96158
Number of obs: 54, groups: Worker, 6

Fixed effects:
            Estimate Std. Error t value
(Intercept)   52.356      1.681  31.151
MachineB       7.967      2.421   3.291
MachineC      13.917      1.540   9.037

It may be more meaningful to write it as

> print(fm3 <- lmer(score ~ Machine + (0+Machine|Worker), Machines), corr = FALSE)
Linear mixed model fit by REML
Formula: score ~ Machine + (0 + Machine | Worker)
   Data: Machines
   AIC   BIC logLik deviance REMLdev
 228.3 248.2 -104.2    216.6   208.3
Random effects:
 Groups   Name     Variance Std.Dev. Corr
 Worker   MachineA 16.64097 4.07933
          MachineB 74.39557 8.62529  0.803
          MachineC 19.26646 4.38936  0.623 0.771
 Residual           0.92463 0.96158
Number of obs: 54, groups: Worker, 6

Fixed effects:
            Estimate Std. Error t value
(Intercept)   52.356      1.681  31.150
MachineB       7.967      2.421   3.291
MachineC      13.917      1.540   9.037

Now we are fitting 3 variances and 3 covariances for the random
effects instead of the previous models which had two variances.  The
difference in the models is exactly what made you pause - the simpler
model assumes that, conditional on the random effect for the worker,
the worker/machine random effects are independent and have constant
variance.  In the more general models the worker/machine interactions
are allowed to be correlated within worker.

It is more common to allow this kind of correlation within subject in
models for longitudinal data (the Laird-Ware formulation) where each
subject has a random effect for the intercept and a random effect for
the slope with respect to time and these can be correlated.  However,
this type of representation can make sense with a factor on the left
hand side of the '|' operator, like the Machine factor here.  If that
factor has a large number of levels then the model quickly becomes
unwieldy because the number of variance-covariance parameters to
estimate is quadratic in the number of levels of the factor on the
lhs.

I hope this helps.

>        Having got there:  Presuming that I'm more-or-less on the right track
>        in my foregoing conjecture that it's the over-simple dependence
> structure
>        that is the problem with what's delivered by the
> Package-Which-Must-Not-Be-Named,
>        how might one go about being less simple-minded?  I.e. what might be
> some
>        more realistic dependence structures, and how would one specify these
> in lmer?
>        And how would one assess whether the assumed dependence structure
> gives
>        a reasonable fit to the data?
>
>> If you can describe how many variance components you think should be
>> estimated in your model and what they would represent then I think it
>> will be easier to describe how to fit the model.
>
>        How does this fit in with my conjecture (above) about what I've been
>        missing all these years?  Does it fit?  How many variance components
>        are there in the ``naive'' model?  It looks like 5 to me ... but
> maybe
>        I'm totally out to lunch in what I think I'm understanding at this
> stage.
>        (And besides --- there are three sorts of statistician; those who can
> count,
>        and those who can't.)
>
>        Thank you for your indulgence.
>
>                 cheers,
>
>                        Rolf Turner
>
> ######################################################################
> Attention:This e-mail message is privileged and confidential. If you are not
> theintended recipient please delete the message and notify the sender.Any
> views or opinions presented are solely those of the author.
>
> This e-mail has been scanned and cleared by
> MailMarshalwww.marshalsoftware.com
> ######################################################################
>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Machines.pdf
Type: application/pdf
Size: 38675 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080513/ae7a3c02/attachment.pdf>

From gangchen6 at gmail.com  Tue May 13 22:47:16 2008
From: gangchen6 at gmail.com (Gang Chen)
Date: Tue, 13 May 2008 16:47:16 -0400
Subject: [R-sig-ME] Error when fitting with nlme
Message-ID: <b0f0ada60805131347g5b436954y49b49c32eff810d2@mail.gmail.com>

I'm getting the following error message

Error in nlmeCall[[i]] <- NULL : subscript out of bounds

when running the following non-linear mixed-effects model:

> library(nlme)
> GrpData <- read.table("GroupData.txt", na.strings = "NA", header=TRUE)
> fm <- nlme(fCR ~ SSasymp(Tr, Asym, R0, lrc), data=www, fixed = Asym+R0+lrc~1, na.action = na.exclude, random = subj~1)

I'm clueless about what the error message means. Does it have anything
to do with the NA's problem indicated as below?

> www <- groupedData(fCR ~ Tr|subj, data=GrpData)
> FitList <- nlsList(fCR ~ SSasymp(Tr, Asym, R0, lrc), data=www, na.action = na.exclude)
Error in numericDeriv(form[[3]], names(ind), env) :
  Missing value or an infinity produced when evaluating the model
In addition: Warning message:
In log(-coef(lm(log(ydiff) ~ x, data = xy))[2]) : NaNs produced
Call:
  Model: fCR ~ SSasymp(Tr, Asym, R0, lrc) | subj
   Data: www

Coefficients:
        Asym        R0       lrc
S1 0.9430772 0.7075430 -4.617628
S2 0.9810034 0.0604899 -3.356152
S3 0.9851586 0.5392042 -3.030196
S4 1.6158708 0.8594590 -7.742318
S5        NA        NA        NA
S6 0.8411017 0.9881358 -3.726827

Degrees of freedom: 122 total; 107 residual
Residual standard error: 0.09946001

And it hangs there forever when I run the following
> nlme(FitList)

However even if I remove subject S5 from the dataframe, I still get
the same error message:

> GC<-GrpData[GrpData$subj!="S5",]
> GCg<-groupedData(fCR ~ Tr|subj, data=GC)
> (llList<- nlsList(fCR ~ SSasymp(Tr, Asym, R0, lrc), data=GCg, na.action = na.exclude))
Call:
  Model: fCR ~ SSasymp(Tr, Asym, R0, lrc) | subj
   Data: GCg

Coefficients:
        Asym        R0       lrc
S1 0.9430772 0.7075430 -4.617628
S2 0.9810034 0.0604899 -3.356152
S3 0.9851586 0.5392042 -3.030196
S4 1.6158708 0.8594590 -7.742318
S6 0.8411017 0.9881358 -3.726827

Degrees of freedom: 122 total; 107 residual
Residual standard error: 0.09946001

> nlme(fCR ~ SSasymp(Tr, Asym, R0, lrc), data=ll, fixed = Asym+R0+lrc~1, na.action = na.exclude, random = subj~1)
Error in nlmeCall[[i]] <- NULL : subscript out of bounds

And again it hangs there forever when I run the following
> nlme(llList)

I'm not attaching the dataframe because of its moderate size, but I
can send it next time if needed.

Thanks for any suggestions,
Gang



From kingsfordjones at gmail.com  Wed May 14 00:39:25 2008
From: kingsfordjones at gmail.com (Kingsford Jones)
Date: Tue, 13 May 2008 15:39:25 -0700
Subject: [R-sig-ME] [R]  lme nesting/interaction advice
In-Reply-To: <18571D1C-717E-4C30-A8E2-09409B5700D2@auckland.ac.nz>
References: <ED7B522EE00C9A4FA515AA71724D61EE2EBF23@DC1EXCL01.air.org>
	<36FF05E2-A132-43DC-9899-EB9C62A82E02@imperial.ac.uk>
	<40e66e0b0805120909r5da2c1d4q6cdcf9e33e907672@mail.gmail.com>
	<C6F74B16-D507-44FA-935B-18A5642A791A@auckland.ac.nz>
	<40e66e0b0805130949s322ae848q4c6bfd4c831193d0@mail.gmail.com>
	<18571D1C-717E-4C30-A8E2-09409B5700D2@auckland.ac.nz>
Message-ID: <2ad0cc110805131539i58fb3f05vca22a66ebfe0b3de@mail.gmail.com>

Hi Rolf,

On Tue, May 13, 2008 at 1:59 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:

< in response to Doug Bates' useful tutorial...>

>  Thanks very much for your long, detailed, patient, and lucid
>  response to my cri de coeur.  That helps a *great* deal.
>

Hear Hear!

<snip>
>  One point that I'd like to spell out very explicitly, to make sure
>  that I'm starting from the right square:
>
>  The model that you start with in the Machines/Workers example is
>
>
>
> >
> > > fm1 <- lmer(score ~ Machine + (1|Worker) + (1|Machine:Worker), Machines)
> > >
> >
>
>
>  My understanding is that this is the ``only'' model that could be fitted
>  by the Package-Which-Must-Not-Be-Named.  I.e. this package *could not* fit
>  the second, more complex model:
>
>
>
> >
> > > fm2 <- lmer(score ~ Machine + (Machine|Worker), Machines)
> > >
> >
>
>  (At least not directly.)  Can you (or someone) confirm that I've got that
>  right?

Compare:

## R
> m4
Linear mixed model fit by REML
Formula: score ~ Machine + (0 + Machine | Worker)
   Data: Machines
   AIC   BIC logLik deviance REMLdev
 228.3 248.2 -104.2    216.6   208.3
Random effects:
 Groups   Name     Variance Std.Dev. Corr
 Worker   MachineA 16.64098 4.07934
          MachineB 74.39558 8.62529  0.803
          MachineC 19.26646 4.38936  0.623 0.771
 Residual           0.92463 0.96158
Number of obs: 54, groups: Worker, 6

## "The-Package"

proc mixed data = machines;
class worker machine;
model score = machine  / solution;
random machine / subject = worker type = un;
run;

 Covariance Parameter Estimates

Cov Parm     Subject    Estimate

UN(1,1)      Worker      16.6405
UN(2,1)      Worker      28.2447
UN(2,2)      Worker      74.3956
UN(3,1)      Worker      11.1465
UN(3,2)      Worker      29.1841
UN(3,3)      Worker      19.2675
Residual                  0.9246


The two outputs report essentially the same thing.
Note that e.g, UN(2,1) = 28.2477 approx= .803*4.07934*8.62529
(And, as usual, the fixed effects estimates match too once the
contrasts and 'types' of SS for an ANOVA table are set up)

UN is short for 'unstructured' - a term Doug has pointed out is not
particularly fitting because the covariance matrix is symmetric
positive definite.

>
>  It seems to me to be the key to why I've had such trouble in the past
>  in grappling with mixed models in R.  I.e. I've been thinking like
>  the Package-Which-Must-Not-Be-Named --- that the simple,
> everything-independent
>  model was the only possible model.
>

Although this may well not apply to you, another area of confusion
arises not so much from differences between stats packages but by
differences between methods. I'm not an expert in the estimation
methods but, as I understand it, classic texts describe fitting mixed
models in terms of ANOVA in the OLS framework, calculating method of
moments estimators for the variances of the random effects by equating
observed and expected mean squares (I believe using aov and lm with an
'Error' term would fall into this category, and proc anova and proc
glm would also).  Starting in the 90's these methods started falling
out of fashion in favor of ML/REML/GLS methods (likelihood based),
which offer more flexibility in structuring both the error and random
effects covariance matrices, will not produce negative variance
estimates, and have other nice properties that someone more 'mathy'
than me could explain.  Tools like lme, lmer, proc mixed and proc
glimmix fall into this category.

hoping this helps,

Kingsford Jones







>  Thanks again.
>
>         cheers,
>
>                 Rolf
>
>
>
>  ######################################################################
>  Attention:\ This e-mail message is privileged and confid...{{dropped:9}}
>
>  ______________________________________________
>  R-help at r-project.org mailing list
>  https://stat.ethz.ch/mailman/listinfo/r-help
>  PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>  and provide commented, minimal, self-contained, reproducible code.
>



From reinhold.kliegl at gmail.com  Wed May 14 01:06:03 2008
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Wed, 14 May 2008 01:06:03 +0200
Subject: [R-sig-ME] Proper analysis for the Machines dataset in lme4
In-Reply-To: <aefe4d0a0804272338u4ddff37age8193c6c0b6ed710@mail.gmail.com>
References: <9BA7966D-F3F1-4CCB-9E82-41A6C154195D@virginia.edu>
	<aefe4d0a0804272338u4ddff37age8193c6c0b6ed710@mail.gmail.com>
Message-ID: <aefe4d0a0805131606p5a52449bj7c08fc3a9982f48e@mail.gmail.com>

Dear Michael,

My following statement was not correct:

On Mon, Apr 28, 2008 at 8:38 AM, Reinhold Kliegl
<reinhold.kliegl at gmail.com> wrote:
>  The comparison of m1 and m2 (or m1r and m2r) is conceptually
>  questionable. m1 assumes there are 6 Workers; m2 assumes that there
>  are 18 Workers, that is different groups of 6 persons worked on each
>  of the 3 machines. Presumably, the experimental design decides whether
>  m1 (m1r) or m2 (m2r) is the correct choice.

After reading Douglas Bates's explanation of random effects for the
Machines data today, I must add the following correction:

mr1: score ~ Machine + (1 | Worker)
mr2: score ~ Machine + (1 | Worker/Machine) ==  score ~ Machine + (1 |
Worker) + (1 | Worker:Machine)
mr3: score ~ Machine + (Machine | Worker)

I wrongly assumed "(1 | Worker/Machine)" would force the six workers
to be nested within Machine, that the program would treat them as 3
groups of 6 workers although they are coded 1 to 6. Rather this syntax
is shorthand for:  "(1 | Worker) + (1 | Worker:Machine)".
Viewed this way, mr1 and mr2 can be compared, of course, as can mr1
and mr3; these are nested models;  I am not sure about mr2 and mr3.

Best,
Reinhold



From njs at pobox.com  Wed May 14 08:54:42 2008
From: njs at pobox.com (Nathaniel Smith)
Date: Tue, 13 May 2008 23:54:42 -0700
Subject: [R-sig-ME] [R]  lme nesting/interaction advice
In-Reply-To: <BA9CEA4A-1228-40A4-8110-10F9D1B3500C@imperial.ac.uk>
References: <ED7B522EE00C9A4FA515AA71724D61EE2EBF23@DC1EXCL01.air.org>
	<36FF05E2-A132-43DC-9899-EB9C62A82E02@imperial.ac.uk>
	<40e66e0b0805120909r5da2c1d4q6cdcf9e33e907672@mail.gmail.com>
	<BA9CEA4A-1228-40A4-8110-10F9D1B3500C@imperial.ac.uk>
Message-ID: <20080514065442.GA18060@frances.vorpus.org>

On Mon, May 12, 2008 at 05:22:19PM +0100, Federico Calboli wrote:
> I'll work on that. Incidentally, what/where is the most comprehensive  
> and up to date documentation for lme4? the pdfs coming with the  
> package? I suspect knowing which are the right docs will help a lot  
> in keeping me within the boundaries of civility and prevent me from  
> annoying anyone (which is not something I sent forth to do on purpose).

The pdfs that come with the package are, alas, basically useless
(unless you want to fix bugs in lme4).  The best user docs I'm aware
of are the short article in the May 2005 R newsletter, and the
papers/book draft written by Harold Baayen et al and available from
his webpage.

-- Nathaniel

-- 
Electrons find their paths in subtle ways.



From reinhold.kliegl at gmail.com  Wed May 14 09:28:18 2008
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Wed, 14 May 2008 09:28:18 +0200
Subject: [R-sig-ME] [R] lme nesting/interaction advice
In-Reply-To: <20080514065442.GA18060@frances.vorpus.org>
References: <ED7B522EE00C9A4FA515AA71724D61EE2EBF23@DC1EXCL01.air.org>
	<36FF05E2-A132-43DC-9899-EB9C62A82E02@imperial.ac.uk>
	<40e66e0b0805120909r5da2c1d4q6cdcf9e33e907672@mail.gmail.com>
	<BA9CEA4A-1228-40A4-8110-10F9D1B3500C@imperial.ac.uk>
	<20080514065442.GA18060@frances.vorpus.org>
Message-ID: <aefe4d0a0805140028s384f7480lb3dce4fabbb91ea2@mail.gmail.com>

On Wed, May 14, 2008 at 8:54 AM, Nathaniel Smith <njs at pobox.com> wrote:
> On Mon, May 12, 2008 at 05:22:19PM +0100, Federico Calboli wrote:
>  > I'll work on that. Incidentally, what/where is the most comprehensive
>  > and up to date documentation for lme4? the pdfs coming with the
>  > package? I suspect knowing which are the right docs will help a lot
>  > in keeping me within the boundaries of civility and prevent me from
>  > annoying anyone (which is not something I sent forth to do on purpose).
>
>  The pdfs that come with the package are, alas, basically useless
>  (unless you want to fix bugs in lme4).  The best user docs I'm aware
>  of are the short article in the May 2005 R newsletter, and the
>  papers/book draft written by Harold Baayen et al and available from
>  his webpage.
>
>  -- Nathaniel

I do not think it is very nice to characterize work as ", alas,
basically useless (unless you want to fix bugs in lme4)."  There are
many other good uses to them, at least I have not fixed a single bug.
Why the pejorative language--especially on this list?

Reinhold



From njs at pobox.com  Wed May 14 10:19:54 2008
From: njs at pobox.com (Nathaniel Smith)
Date: Wed, 14 May 2008 01:19:54 -0700
Subject: [R-sig-ME] [R] lme nesting/interaction advice
In-Reply-To: <aefe4d0a0805140028s384f7480lb3dce4fabbb91ea2@mail.gmail.com>
References: <ED7B522EE00C9A4FA515AA71724D61EE2EBF23@DC1EXCL01.air.org>
	<36FF05E2-A132-43DC-9899-EB9C62A82E02@imperial.ac.uk>
	<40e66e0b0805120909r5da2c1d4q6cdcf9e33e907672@mail.gmail.com>
	<BA9CEA4A-1228-40A4-8110-10F9D1B3500C@imperial.ac.uk>
	<20080514065442.GA18060@frances.vorpus.org>
	<aefe4d0a0805140028s384f7480lb3dce4fabbb91ea2@mail.gmail.com>
Message-ID: <20080514081954.GB19360@frances.vorpus.org>

On Wed, May 14, 2008 at 09:28:18AM +0200, Reinhold Kliegl wrote:
> >  The pdfs that come with the package are, alas, basically useless
> >  (unless you want to fix bugs in lme4).  The best user docs I'm aware
> >  of are the short article in the May 2005 R newsletter, and the
> >  papers/book draft written by Harold Baayen et al and available from
> >  his webpage.
> 
> I do not think it is very nice to characterize work as ", alas,
> basically useless (unless you want to fix bugs in lme4)."  There are
> many other good uses to them, at least I have not fixed a single bug.
> Why the pejorative language--especially on this list?

I should perhaps clarify that I was thinking mainly of the lme4
vignettes, which are explicitly targeted at implementors.  (If you
have used them for other purposes, then I'd honestly love to know
what.)  I see on CRAN that the help pages are also available as a PDF,
and the help pages are definitely valuable to end-users as a
reference, but... they don't even document how to write an lmer
formula.  Obviously this will be fixed sooner or later when someone
has the time, and fortunately we have the other documents mentioned
above (also mostly authored or co-authored by Doug) to cover the gap
until then -- but for now they're not trivial to find.

My intention wasn't to be pejorative, but simply to provide clear and
honest information about which documentation was currently useful for
which purposes.  But I do apologize if my flippant way of doing that
offended anyone.

-- Nathaniel



From scorrea at soton.ac.uk  Wed May 14 13:03:51 2008
From: scorrea at soton.ac.uk (Correa S.T.)
Date: Wed, 14 May 2008 12:03:51 +0100
Subject: [R-sig-ME] FW: Prediction of random effects - logist mixed model
Message-ID: <A91F084EA64F33478ADFF6F2713B05D30CBA7F77@ISS-CL-EX-V2.soton.ac.uk>

 
Dear list,

I am working with a two-level logistic mixed model and I am interested
in predicting the random effects for a given value of the parameters
(not for the estimates obtained from the data at hand, which can be
obtaiend using fucntion 'ranef'). For illustration, please see the code
below.

# mixed logistic model

fit1.b<-lmer(yij.b.true  ~ x1 + x2 + (1|area), family =
binomial(link=logit), data=bootsamp
,control=list(usePQL=FALSE),verbose=FALSE,method="Laplace")
 
# estimates of the parameter based on the data at hand

beta.hat<-fixef(fit1.b)
varu.hat<-as.numeric(VarCorr(fit1.b)[[1]][1,1])

# predicting group effects based on the data at hand

u.pred<-ranef(fit1.b)[[1]

==>> I would like to obtain u.pred2 such that u.pred2=g(beta, varu) for
any given beta and 

varu. In other words, I need to extract the function g() used in the
lmer to predict the u random effects. Is there a way to do that?

Thank you very much.

Solange Correa,
Ph.D. student
Social Statistics
University of Southampton, UK.


************* ******************************** 
summary of the model fitting
**********************************************

> fit1.b
Generalized linear mixed model fit using Laplace
Formula: yij.b.true ~ x1 + x2 + (1 | area) 
   Data: bootsamp
 Family: binomial(logit link)
   AIC   BIC logLik deviance
 299.1 315.5 -145.5    291.1
Random effects:
 Groups Name        Variance Std.Dev.
 area   (Intercept) 0.33441  0.57828 
number of obs: 450, groups: area, 30

Estimated scale (compare to  1 )  0.9462897 

Fixed effects:
            Estimate Std. Error z value Pr(>|z|)    
(Intercept) -2.33328    0.86467  -2.698  0.00697 ** 
x1           0.36417    0.31776   1.146  0.25178    
x2           0.15127    0.03137   4.821 1.43e-06 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Correlation of Fixed Effects:
   (Intr) x1    
x1 -0.125       
x2 -0.960 -0.050



From r.turner at auckland.ac.nz  Tue May 13 22:59:10 2008
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 14 May 2008 08:59:10 +1200
Subject: [R-sig-ME] [R]  lme nesting/interaction advice
In-Reply-To: <40e66e0b0805130949s322ae848q4c6bfd4c831193d0@mail.gmail.com>
References: <ED7B522EE00C9A4FA515AA71724D61EE2EBF23@DC1EXCL01.air.org>
	<36FF05E2-A132-43DC-9899-EB9C62A82E02@imperial.ac.uk>
	<40e66e0b0805120909r5da2c1d4q6cdcf9e33e907672@mail.gmail.com>
	<C6F74B16-D507-44FA-935B-18A5642A791A@auckland.ac.nz>
	<40e66e0b0805130949s322ae848q4c6bfd4c831193d0@mail.gmail.com>
Message-ID: <18571D1C-717E-4C30-A8E2-09409B5700D2@auckland.ac.nz>


Thanks very much for your long, detailed, patient, and lucid
response to my cri de coeur.  That helps a *great* deal.

I'm not sure that I have a solid understanding of the issues yet
--- I never am! --- but I think I'm getting there.  I'll need to
chew over the posting a bit more and try some examples before
I feel comfortable.

One point that I'd like to spell out very explicitly, to make sure
that I'm starting from the right square:

The model that you start with in the Machines/Workers example is

>> fm1 <- lmer(score ~ Machine + (1|Worker) + (1|Machine:Worker),  
>> Machines)


My understanding is that this is the ``only'' model that could be fitted
by the Package-Which-Must-Not-Be-Named.  I.e. this package *could  
not* fit
the second, more complex model:

>> fm2 <- lmer(score ~ Machine + (Machine|Worker), Machines)

(At least not directly.)  Can you (or someone) confirm that I've got  
that
right?

It seems to me to be the key to why I've had such trouble in the past
in grappling with mixed models in R.  I.e. I've been thinking like
the Package-Which-Must-Not-Be-Named --- that the simple, everything- 
independent
model was the only possible model.

Thanks again.

	cheers,

		Rolf

######################################################################
Attention:\ This e-mail message is privileged and confid...{{dropped:9}}



From bates at stat.wisc.edu  Wed May 14 14:05:37 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 14 May 2008 07:05:37 -0500
Subject: [R-sig-ME] Proper analysis for the Machines dataset in lme4
In-Reply-To: <aefe4d0a0805131606p5a52449bj7c08fc3a9982f48e@mail.gmail.com>
References: <9BA7966D-F3F1-4CCB-9E82-41A6C154195D@virginia.edu>
	<aefe4d0a0804272338u4ddff37age8193c6c0b6ed710@mail.gmail.com>
	<aefe4d0a0805131606p5a52449bj7c08fc3a9982f48e@mail.gmail.com>
Message-ID: <40e66e0b0805140505x25e6631eib426ecc79504c86a@mail.gmail.com>

On Tue, May 13, 2008 at 6:06 PM, Reinhold Kliegl
<reinhold.kliegl at gmail.com> wrote:
> Dear Michael,
>
> My following statement was not correct:
>
> On Mon, Apr 28, 2008 at 8:38 AM, Reinhold Kliegl
> <reinhold.kliegl at gmail.com> wrote:
>>  The comparison of m1 and m2 (or m1r and m2r) is conceptually
>>  questionable. m1 assumes there are 6 Workers; m2 assumes that there
>>  are 18 Workers, that is different groups of 6 persons worked on each
>>  of the 3 machines. Presumably, the experimental design decides whether
>>  m1 (m1r) or m2 (m2r) is the correct choice.
>
> After reading Douglas Bates's explanation of random effects for the
> Machines data today, I must add the following correction:
>
> mr1: score ~ Machine + (1 | Worker)
> mr2: score ~ Machine + (1 | Worker/Machine) ==  score ~ Machine + (1 |
> Worker) + (1 | Worker:Machine)
> mr3: score ~ Machine + (Machine | Worker)
>
> I wrongly assumed "(1 | Worker/Machine)" would force the six workers
> to be nested within Machine, that the program would treat them as 3
> groups of 6 workers although they are coded 1 to 6. Rather this syntax
> is shorthand for:  "(1 | Worker) + (1 | Worker:Machine)".
> Viewed this way, mr1 and mr2 can be compared, of course, as can mr1
> and mr3; these are nested models;  I am not sure about mr2 and mr3.

mr2 and mr3 are nested.  It is easiest to see this if mr3 is written
in the equivalent form

mr3: score ~ Machine + (0 + Machine | Worker)

If mr2 were re-expressed in this form the 3 by 3 variance-covariance
matrix for the levels of Machine given Worker would have a compound
symmetry form  in which all the diagonal elements are equal to
sigma^2_1 + sigma^2_2 and all the off-diagonal elements are equal to
sigma^2_2.



From kingsfordjones at gmail.com  Wed May 14 19:31:18 2008
From: kingsfordjones at gmail.com (Kingsford Jones)
Date: Wed, 14 May 2008 10:31:18 -0700
Subject: [R-sig-ME] [R] lme nesting/interaction advice
In-Reply-To: <20080514081954.GB19360@frances.vorpus.org>
References: <ED7B522EE00C9A4FA515AA71724D61EE2EBF23@DC1EXCL01.air.org>
	<36FF05E2-A132-43DC-9899-EB9C62A82E02@imperial.ac.uk>
	<40e66e0b0805120909r5da2c1d4q6cdcf9e33e907672@mail.gmail.com>
	<BA9CEA4A-1228-40A4-8110-10F9D1B3500C@imperial.ac.uk>
	<20080514065442.GA18060@frances.vorpus.org>
	<aefe4d0a0805140028s384f7480lb3dce4fabbb91ea2@mail.gmail.com>
	<20080514081954.GB19360@frances.vorpus.org>
Message-ID: <2ad0cc110805141031n6095177do6e69728f8b4fe7ca@mail.gmail.com>

On Wed, May 14, 2008 at 1:19 AM, Nathaniel Smith <njs at pobox.com> wrote:
> On Wed, May 14, 2008 at 09:28:18AM +0200, Reinhold Kliegl wrote:
>> >  The pdfs that come with the package are, alas, basically useless
>> >  (unless you want to fix bugs in lme4).  The best user docs I'm aware
>> >  of are the short article in the May 2005 R newsletter, and the
>> >  papers/book draft written by Harold Baayen et al and available from
>> >  his webpage.
>>
>> I do not think it is very nice to characterize work as ", alas,
>> basically useless (unless you want to fix bugs in lme4)."  There are
>> many other good uses to them, at least I have not fixed a single bug.
>> Why the pejorative language--especially on this list?
>
> I should perhaps clarify that I was thinking mainly of the lme4
> vignettes, which are explicitly targeted at implementors.  (If you
> have used them for other purposes, then I'd honestly love to know
> what.)  I see on CRAN that the help pages are also available as a PDF,
> and the help pages are definitely valuable to end-users as a
> reference, but... they don't even document how to write an lmer
> formula.  Obviously this will be fixed sooner or later when someone
> has the time, and fortunately we have the other documents mentioned
> above (also mostly authored or co-authored by Doug) to cover the gap
> until then -- but for now they're not trivial to find.
>
> My intention wasn't to be pejorative, but simply to provide clear and
> honest information about which documentation was currently useful for
> which purposes.  But I do apologize if my flippant way of doing that
> offended anyone.
>

I have to disagree with your assessment of the vignettes.  The
documents do contain a lot of theory, but chapters 1-4 of
Implementation.pdf do an excellent job of describing varying types of
data to be fit using mixed models, how to fit the models using lmer,
and the structure of the fitted objects returned.  I see those
examples as far from 'useless'.  What exactly are you looking for?
One way you might find what you're looking for is to google:

"lmer" mixed filetype:pdf

or

lmer mixed filetype:pdf

The later (without the quotes) will lead to many documents on lme as
well as lmer

Also, although written prior to lmer, Pinheiro and Bates 2000 is still
an excellent resource.  Although I have limited experience with lmer,
for many models it seems the only difference for a useR to specify a
model in lme vs lmer is that the random argument from lme is removed
and the value for the argument is put in parentheses and moved into
the model formula.  For example:

lme(score ~ Machine, data = Machines, random= ~ 0 + Machine|Woker)

vs

lmer(score ~ Machine + (0 + Machine|Worker), data = Machines)


This not the case when fitting models with crossed random effects,
where in lme the random arugment took a somewhat convoluted list, but
in lmer the formulas are straightforward.

Finally, I'd like to point out that sending an email to this list is
essentially the same as sending one directly to Doug Bates, who I
think deserves our gratitude for his tremendous contributions to the R
community, and to the advancement of mixed modeling.

best,

Kingsford Jones


> -- Nathaniel
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Wed May 14 20:18:43 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 14 May 2008 13:18:43 -0500
Subject: [R-sig-ME] [R] lme nesting/interaction advice
In-Reply-To: <2ad0cc110805141031n6095177do6e69728f8b4fe7ca@mail.gmail.com>
References: <ED7B522EE00C9A4FA515AA71724D61EE2EBF23@DC1EXCL01.air.org>
	<36FF05E2-A132-43DC-9899-EB9C62A82E02@imperial.ac.uk>
	<40e66e0b0805120909r5da2c1d4q6cdcf9e33e907672@mail.gmail.com>
	<BA9CEA4A-1228-40A4-8110-10F9D1B3500C@imperial.ac.uk>
	<20080514065442.GA18060@frances.vorpus.org>
	<aefe4d0a0805140028s384f7480lb3dce4fabbb91ea2@mail.gmail.com>
	<20080514081954.GB19360@frances.vorpus.org>
	<2ad0cc110805141031n6095177do6e69728f8b4fe7ca@mail.gmail.com>
Message-ID: <40e66e0b0805141118h6ab79618y491a3eb023fba85@mail.gmail.com>

On Wed, May 14, 2008 at 12:31 PM, Kingsford Jones
<kingsfordjones at gmail.com> wrote:
> On Wed, May 14, 2008 at 1:19 AM, Nathaniel Smith <njs at pobox.com> wrote:
>> On Wed, May 14, 2008 at 09:28:18AM +0200, Reinhold Kliegl wrote:
>>> >  The pdfs that come with the package are, alas, basically useless
>>> >  (unless you want to fix bugs in lme4).  The best user docs I'm aware
>>> >  of are the short article in the May 2005 R newsletter, and the
>>> >  papers/book draft written by Harold Baayen et al and available from
>>> >  his webpage.
>>>
>>> I do not think it is very nice to characterize work as ", alas,
>>> basically useless (unless you want to fix bugs in lme4)."  There are
>>> many other good uses to them, at least I have not fixed a single bug.
>>> Why the pejorative language--especially on this list?
>>
>> I should perhaps clarify that I was thinking mainly of the lme4
>> vignettes, which are explicitly targeted at implementors.  (If you
>> have used them for other purposes, then I'd honestly love to know
>> what.)  I see on CRAN that the help pages are also available as a PDF,
>> and the help pages are definitely valuable to end-users as a
>> reference, but... they don't even document how to write an lmer
>> formula.  Obviously this will be fixed sooner or later when someone
>> has the time, and fortunately we have the other documents mentioned
>> above (also mostly authored or co-authored by Doug) to cover the gap
>> until then -- but for now they're not trivial to find.
>>
>> My intention wasn't to be pejorative, but simply to provide clear and
>> honest information about which documentation was currently useful for
>> which purposes.  But I do apologize if my flippant way of doing that
>> offended anyone.

> I have to disagree with your assessment of the vignettes.  The
> documents do contain a lot of theory, but chapters 1-4 of
> Implementation.pdf do an excellent job of describing varying types of
> data to be fit using mixed models, how to fit the models using lmer,
> and the structure of the fitted objects returned.  I see those
> examples as far from 'useless'.  What exactly are you looking for?
> One way you might find what you're looking for is to google:

> "lmer" mixed filetype:pdf

> or

> lmer mixed filetype:pdf

> The later (without the quotes) will lead to many documents on lme as
> well as lmer

> Also, although written prior to lmer, Pinheiro and Bates 2000 is still
> an excellent resource.  Although I have limited experience with lmer,
> for many models it seems the only difference for a useR to specify a
> model in lme vs lmer is that the random argument from lme is removed
> and the value for the argument is put in parentheses and moved into
> the model formula.  For example:

> lme(score ~ Machine, data = Machines, random= ~ 0 + Machine|Woker)

> vs

> lmer(score ~ Machine + (0 + Machine|Worker), data = Machines)

> This not the case when fitting models with crossed random effects,
> where in lme the random arugment took a somewhat convoluted list, but
> in lmer the formulas are straightforward.

> Finally, I'd like to point out that sending an email to this list is
> essentially the same as sending one directly to Doug Bates, who I
> think deserves our gratitude for his tremendous contributions to the R
> community, and to the advancement of mixed modeling.

Thanks for offering to save my feelings.  However, having survived two
children going through their teenage years, being regarded as somewhat
useless (not to mention a trifle dim-witted) is not a new experience
for me. :-)



From john.maindonald at anu.edu.au  Thu May 15 02:02:27 2008
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Thu, 15 May 2008 10:02:27 +1000
Subject: [R-sig-ME] [R] lme nesting/interaction advice
In-Reply-To: <40e66e0b0805141118h6ab79618y491a3eb023fba85@mail.gmail.com>
References: <ED7B522EE00C9A4FA515AA71724D61EE2EBF23@DC1EXCL01.air.org>
	<36FF05E2-A132-43DC-9899-EB9C62A82E02@imperial.ac.uk>
	<40e66e0b0805120909r5da2c1d4q6cdcf9e33e907672@mail.gmail.com>
	<BA9CEA4A-1228-40A4-8110-10F9D1B3500C@imperial.ac.uk>
	<20080514065442.GA18060@frances.vorpus.org>
	<aefe4d0a0805140028s384f7480lb3dce4fabbb91ea2@mail.gmail.com>
	<20080514081954.GB19360@frances.vorpus.org>
	<2ad0cc110805141031n6095177do6e69728f8b4fe7ca@mail.gmail.com>
	<40e66e0b0805141118h6ab79618y491a3eb023fba85@mail.gmail.com>
Message-ID: <5DB4ED1D-B2E9-4018-B575-ABB13B17C2D7@anu.edu.au>

Nevertheless, the carping nature of some of this criticism has been
unwarranted and unfair.  Mixed models in R are hard to suss out!
Sure.  They are hard for most of us to get a grip on, whatever software
one uses.  That is just the way it is.  No doubt the path of the learner
can be smoothed.  The discussion on this list is a help in identifying
what sorts of issues people find difficult.  But it is not all up to  
Douglas.
His part has been to do the really hard part, the code development.
He's also been providing not inconsiderable documentation along the
way, and interesting ongoing commentary onto his progress with the
conceptualization and with the coding, which is a bonus.  It is a work
in progress, and It is all highly educational.

It is fair to put onto others some large part of the task of providing
detailed tutorials and documentation.  They are rising to the challenge;
witness the Baayen book.

I think some contributors may forget how long it took them to get
somewhat on top of mixed models using
whatever-package-it-was-that-cannot-be-named.  Understandably,
they'd prefer not to re-live some elements of that earlier struggle.
The Puritan in my soul responds "It is good for one's intellectual
development!"

Myself, I came via Genstat.  (If there really are
packages-that-cannot-be-named, please tell me!) It was hard going
for quite a while. Genstat, like lme4 to an extent, changed while I  
learned.
Problems that called for something like GLMMs were a huge challenge.
The fudges were used did though provide their own insight, and have
made me highly sensitive to the need to check out data intended for
GLMMs, to the extent possible, before throwing the whole complicated
variance-covariance structure into a total model fit.  Too many who
contemplate these models are loth to do that.  They may then complain
that the fit failed, in a case where one hope that it would fail!

John Maindonald.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


On 15 May 2008, at 4:18 AM, Douglas Bates wrote:

> On Wed, May 14, 2008 at 12:31 PM, Kingsford Jones
> <kingsfordjones at gmail.com> wrote:
>> On Wed, May 14, 2008 at 1:19 AM, Nathaniel Smith <njs at pobox.com>  
>> wrote:
>>> On Wed, May 14, 2008 at 09:28:18AM +0200, Reinhold Kliegl wrote:
>>>>> The pdfs that come with the package are, alas, basically useless
>>>>> (unless you want to fix bugs in lme4).  The best user docs I'm  
>>>>> aware
>>>>> of are the short article in the May 2005 R newsletter, and the
>>>>> papers/book draft written by Harold Baayen et al and available  
>>>>> from
>>>>> his webpage.
>>>>
>>>> I do not think it is very nice to characterize work as ", alas,
>>>> basically useless (unless you want to fix bugs in lme4)."  There  
>>>> are
>>>> many other good uses to them, at least I have not fixed a single  
>>>> bug.
>>>> Why the pejorative language--especially on this list?
>>>
>>> I should perhaps clarify that I was thinking mainly of the lme4
>>> vignettes, which are explicitly targeted at implementors.  (If you
>>> have used them for other purposes, then I'd honestly love to know
>>> what.)  I see on CRAN that the help pages are also available as a  
>>> PDF,
>>> and the help pages are definitely valuable to end-users as a
>>> reference, but... they don't even document how to write an lmer
>>> formula.  Obviously this will be fixed sooner or later when someone
>>> has the time, and fortunately we have the other documents mentioned
>>> above (also mostly authored or co-authored by Doug) to cover the gap
>>> until then -- but for now they're not trivial to find.
>>>
>>> My intention wasn't to be pejorative, but simply to provide clear  
>>> and
>>> honest information about which documentation was currently useful  
>>> for
>>> which purposes.  But I do apologize if my flippant way of doing that
>>> offended anyone.
>
>> I have to disagree with your assessment of the vignettes.  The
>> documents do contain a lot of theory, but chapters 1-4 of
>> Implementation.pdf do an excellent job of describing varying types of
>> data to be fit using mixed models, how to fit the models using lmer,
>> and the structure of the fitted objects returned.  I see those
>> examples as far from 'useless'.  What exactly are you looking for?
>> One way you might find what you're looking for is to google:
>
>> "lmer" mixed filetype:pdf
>
>> or
>
>> lmer mixed filetype:pdf
>
>> The later (without the quotes) will lead to many documents on lme as
>> well as lmer
>
>> Also, although written prior to lmer, Pinheiro and Bates 2000 is  
>> still
>> an excellent resource.  Although I have limited experience with lmer,
>> for many models it seems the only difference for a useR to specify a
>> model in lme vs lmer is that the random argument from lme is removed
>> and the value for the argument is put in parentheses and moved into
>> the model formula.  For example:
>
>> lme(score ~ Machine, data = Machines, random= ~ 0 + Machine|Woker)
>
>> vs
>
>> lmer(score ~ Machine + (0 + Machine|Worker), data = Machines)
>
>> This not the case when fitting models with crossed random effects,
>> where in lme the random arugment took a somewhat convoluted list, but
>> in lmer the formulas are straightforward.
>
>> Finally, I'd like to point out that sending an email to this list is
>> essentially the same as sending one directly to Doug Bates, who I
>> think deserves our gratitude for his tremendous contributions to  
>> the R
>> community, and to the advancement of mixed modeling.
>
> Thanks for offering to save my feelings.  However, having survived two
> children going through their teenage years, being regarded as somewhat
> useless (not to mention a trifle dim-witted) is not a new experience
> for me. :-)
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From jtouchon at bu.edu  Thu May 15 23:40:08 2008
From: jtouchon at bu.edu (Justin Touchon)
Date: Thu, 15 May 2008 17:40:08 -0400
Subject: [R-sig-ME] Binomial GLMM vs GLM question
Message-ID: <482CADB8.7010100@bu.edu>

Dear Dr. Bates and other LMER experts,
    I am admittedly entry level in my R and mixed-model knowledge, but 
I'm hoping that someone can help me and also forgive my lack of 
insight.  Over 3 years, I monitored survival of 350 egg masses at two 
ponds.  I thus have one continuous variable (rainfall) and two discrete 
variables (year and pond).  My response variable, mortality, is coded as 
a two column matrix featuring eggs survived and eggs dead. I'm primarily 
interested in the effect of rain on survival, but also if rain has 
different impacts at the different ponds and how much survival varied 
over the three years.  Originally, I though I could tackle this with a 
binomial GLM, but do I need a binomial GLMM instead, as rainfall and 
year would be random and pond fixed?  The problem with this is trying to 
make biological sense out of the results.  I've spent the last week 
reading all the past posts about why p-values can't be calculated and 
all that, which I'm fine with.  But what can I say about the effects of 
rainfall or year on egg survival from the variance estimates?  Also, 
doesn't LMER require that random factors be normally distributed, 
because my rainfall measurements are far from it.  Is that a problem?  
Thank you in advance for any advice you can give. 
-Justin Touchon

My model and output are as follows:

 > LMER.1<-lmer(mort~Pond + (Pond|total_rainfall) + (1|Year), 
family=binomial, data= FieldData0305)

 > summary(LMER.1)
Generalized linear mixed model fit using Laplace
Formula: mort ~ Pond + (Pond | total_rainfall) + (1 | Year)
   Data: FieldData0305
 Family: binomial(logit link)
  AIC  BIC logLik deviance
 7657 7680  -3822     7645
Random effects:
 Groups         Name           Variance Std.Dev. Corr  
 total_rainfall (Intercept)    21.66535 4.65461        
                Pond[T.Ocelot]  6.44297 2.53830  -0.627
 Year           (Intercept)     0.74082 0.86071        
number of obs: 350, groups: total_rainfall, 48; Year, 3

Estimated scale (compare to  1 )  4.603433

Fixed effects:
               Estimate Std. Error z value Pr(>|z|)
(Intercept)     -0.4678     1.0173 -0.4598    0.646
Pond[T.Ocelot]  -0.9831     0.9330 -1.0538    0.292

Correlation of Fixed Effects:
            (Intr)
Pnd[T.Oclt] -0.648



From kjbeath at kagi.com  Fri May 16 04:36:41 2008
From: kjbeath at kagi.com (Ken Beath)
Date: Fri, 16 May 2008 02:36:41 -0000 (UTC)
Subject: [R-sig-ME] Binomial GLMM vs GLM question
In-Reply-To: <482CADB8.7010100@bu.edu>
References: <482CADB8.7010100@bu.edu>
Message-ID: <37086.129.78.64.102.1210905401.squirrel@mail.kjbeath.com.au>

> Dear Dr. Bates and other LMER experts,
>     I am admittedly entry level in my R and mixed-model knowledge, but
> I'm hoping that someone can help me and also forgive my lack of
> insight.  Over 3 years, I monitored survival of 350 egg masses at two
> ponds.  I thus have one continuous variable (rainfall) and two discrete
> variables (year and pond).  My response variable, mortality, is coded as
> a two column matrix featuring eggs survived and eggs dead. I'm primarily
> interested in the effect of rain on survival, but also if rain has
> different impacts at the different ponds and how much survival varied
> over the three years.  Originally, I though I could tackle this with a
> binomial GLM, but do I need a binomial GLMM instead, as rainfall and
> year would be random and pond fixed?  The problem with this is trying to
> make biological sense out of the results.  I've spent the last week
> reading all the past posts about why p-values can't be calculated and
> all that, which I'm fine with.  But what can I say about the effects of
> rainfall or year on egg survival from the variance estimates?  Also,
> doesn't LMER require that random factors be normally distributed,
> because my rainfall measurements are far from it.  Is that a problem?
> Thank you in advance for any advice you can give.
> -Justin Touchon
>

I think your misunderstanding the idea of a random effect. This is
something that is unobserved, causing correlation within a group. In your
data this might be year or pond but definitely not rainfall which is
simply a covariate. You have more than one measurement on a pond and more
than one for each year, so it is likely that there will be correlation
between them and one way of dealing with this is a random effect. The
alternative is to use a fixed effects model. In your case, there are only
2 and 3 groups, so a fixed effects model is the best approach, so a GLM is
appropriate. If there were say 20 ponds, a random effects model would be
much more suitable.

Ken

> My model and output are as follows:
>
>  > LMER.1<-lmer(mort~Pond + (Pond|total_rainfall) + (1|Year),
> family=binomial, data= FieldData0305)
>
>  > summary(LMER.1)
> Generalized linear mixed model fit using Laplace
> Formula: mort ~ Pond + (Pond | total_rainfall) + (1 | Year)
>    Data: FieldData0305
>  Family: binomial(logit link)
>   AIC  BIC logLik deviance
>  7657 7680  -3822     7645
> Random effects:
>  Groups         Name           Variance Std.Dev. Corr
>  total_rainfall (Intercept)    21.66535 4.65461
>                 Pond[T.Ocelot]  6.44297 2.53830  -0.627
>  Year           (Intercept)     0.74082 0.86071
> number of obs: 350, groups: total_rainfall, 48; Year, 3
>
> Estimated scale (compare to  1 )  4.603433
>
> Fixed effects:
>                Estimate Std. Error z value Pr(>|z|)
> (Intercept)     -0.4678     1.0173 -0.4598    0.646
> Pond[T.Ocelot]  -0.9831     0.9330 -1.0538    0.292
>
> Correlation of Fixed Effects:
>             (Intr)
> Pnd[T.Oclt] -0.648
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From john.maindonald at anu.edu.au  Fri May 16 06:28:59 2008
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Fri, 16 May 2008 14:28:59 +1000
Subject: [R-sig-ME] [R]  lme nesting/interaction advice
In-Reply-To: <40e66e0b0805130949s322ae848q4c6bfd4c831193d0@mail.gmail.com>
References: <ED7B522EE00C9A4FA515AA71724D61EE2EBF23@DC1EXCL01.air.org>
	<36FF05E2-A132-43DC-9899-EB9C62A82E02@imperial.ac.uk>
	<40e66e0b0805120909r5da2c1d4q6cdcf9e33e907672@mail.gmail.com>
	<C6F74B16-D507-44FA-935B-18A5642A791A@auckland.ac.nz>
	<40e66e0b0805130949s322ae848q4c6bfd4c831193d0@mail.gmail.com>
Message-ID: <75935B52-70D6-444F-A515-4D0CCC77FC81@anu.edu.au>

I've been looking back over this discussion.
Another model that one can fit using lme is:

 > lme(score~Machine, random=list(Worker=pdIdent(~0+Machine)),
+        weights=varIdent(form=~1|Machine), data=Machines)
Linear mixed-effects model fit by REML
  Data: Machines
  Log-restricted-likelihood: -108.9547
  Fixed: score ~ Machine
(Intercept)    MachineB    MachineC
  52.355556    7.966667   13.916667

Random effects:
Formula: ~0 + Machine | Worker
Structure: Multiple of an Identity
        MachineA MachineB MachineC Residual
StdDev:  6.06209  6.06209  6.06209 1.148581

Variance function:
Structure: Different standard deviations per stratum
Formula: ~1 | Machine
Parameter estimates:
        A         B         C
1.0000000 0.8713263 0.5859709
Number of Observations: 54
Number of Groups: 6


This insists (I think) that conditional on the random effect for the  
worker,
the worker/machine random effects be independent,
but allows them to have different variances.  I am wondering whether
it is possible to fit such a model using lmer().

[In this example the large estimated correlations suggest that it is not
a sensible model.]

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


On 14 May 2008, at 2:49 AM, Douglas Bates wrote:

> On Mon, May 12, 2008 at 5:39 PM, Rolf Turner  
> <r.turner at auckland.ac.nz> wrote:
>>
>> On 13/05/2008, at 4:09 AM, Douglas Bates wrote:
>>
>>> I'm entering this discussion late so I may be discussing issues that
>>> have already been addressed.
>>>
>>> As I understand it, Federico, you began by describing a model for  
>>> data
>>> in which two factors have a fixed set of levels and one factor has  
>>> an
>>> extensible, or "random", set of levels and you wanted to fit a model
>>> that you described as
>>>
>>> y ~ effect1 * effect2 * effect3
>>>
>>> The problem is that this specification is not complete.
>>
>>      At *last* (as Owl said to Rabbit) we're getting somewhere!!!
>>
>>      I always knew that there was some basic fundamental point
>>      about this business that I (and I believe many others) were
>>      simply missing.  But I could not for the life of me get anyone
>>      to explain to me what that point was.  Or to put it another
>>      way, I was never able to frame a question that would illuminate
>>      just what it was that I wasn't getting.
>>
>>      I now may be at a stage where I can start asking the right
>>      questions.
>>
>>> An interaction of factors with fixed levels and a factor with random
>>> levels can mean, in the lmer specification,
>>>
>>> lmer(y ~ effect1 * effect2 + (1| effect3) + (1| 
>>> effect1:effect2:effect3),
>>> ...)
>>>
>>> or
>>>
>>> lmer(y ~ effect1 * effect2 + (effect1*effect2 | effect3), ...)
>>>
>>> or other variations.  When you specify a random effect or an random
>>> interaction term you must, either explicitly or implicitly, specify
>>> the form of the variance-covariance matrix associated with those
>>> random effects.
>>>
>>> The "advantage" that other software may provide for you is that it
>>> chooses the model for you but that, of course, means that you only
>>> have the one choice.
>>
>>      Now may I start asking what I hope are questions that will lift
>>      the fog a bit?
>>
>>      Let us for specificity consider a three-way model with two
>>      fixed effects and one random effect from the good old  
>> Rothamstead
>> style
>>      agricultural experiment context:  Suppose we have a number of
>>      species/breeds of wheat (say) and a number of fertilizers.
>>      These are fixed effects.  And we have a number of fields  
>> (blocks)
>>      --- a random effect.  Each breed-fertilizer combination is
>>      applied a number of times in each field.  We ***assume*** that
>>      that the field or block effect is homogeneous throughout.  This
>>      may or may not be a ``good'' assumption, but it's not completely
>>      ridiculous and would often be made in practice.  And probably
>>      *was* made at Rothamstead.  The response would be something like
>>      yield in bushels per acre.
>>
>>      The way that I would write the ``full'' model for this setting,
>>      in mathematical style is:
>>
>>      Y_ijkl = mu + alpha_i + beta_j + (alpha.beta)_ij + C_k +  
>> (alpha.C)_ik
>>                  + (beta.C)_jk + (alpha.beta.C)_ijk + E_ijkl
>>
>>      The alpha_i and beta_j are parameters corresponding to breed and
>> fertilizer
>>      respectively; the C_k are random effects corresponding to  
>> fields or
>> blocks.
>>      Any effect ``involving'' C is also random.
>>
>>      The assumptions made by the Package-Which-Must-Not-Be-Named  
>> are (I
>> think)
>>      that
>>
>>              C_k ~ N(0,sigma_C^2)
>>              (alpha.C)_ik ~ N(0,sigma_aC^2)
>>              (beta.C)jk ~ N(0,sigma_bC^2)
>>              (alpha.beta.C)_ijk ~ N(0,sigma_abC^2)
>>              E_ijkl ~ N(0,sigma^2)
>>
>>      and these random variables are *all independent*.
>>
>>      Ahhhhhhhh ... perhaps I'm on the way to answering my own  
>> question.
>> Is
>>      it this assumption of ``all independent'' which is  
>> questionable?  It
>>      seemed innocent enough when I first learned about this stuff, lo
>> these
>>      many years ago.  But .... mmmmmaybe not!
>>
>>      To start with:  What would be the lmer syntax to fit the  
>> foregoing
>>      (possibly naive) model?  I am sorry, but I really cannot get  
>> my head
>>      around the syntax of lmer model specification, and I've  
>> tried.  I
>>      really have.  Hard.  I know I must be starting from the wrong  
>> place,
>>      but I haven't a clue as to what the *right* place to start  
>> from is.
>>      And if I'm in that boat, I will wager Euros to pretzels that  
>> there
>>      are others in it.  I know that I'm not the brightest bulb in the
>>      chandelier, but I'm not the dullest either.
>
> Thanks for the questions, Rolf.  I completely agree that mixed model
> specification can be an extremely confusing area.
>
> Let's consider a set of models for the Machines data reproduced (from
> Milliken and Johnson) in Pinheiro and Bates and available in the MEMSS
> package.
>
>> library(lme4)
> Loading required package: Matrix
> Loading required package: lattice
>
> Attaching package: 'Matrix'
>
>
> 	The following object(s) are masked from package:stats :
>
> 	 xtabs
>> data("Machines", package = "MEMSS")
>> str(Machines)
> 'data.frame':	54 obs. of  3 variables:
> $ Worker : Factor w/ 6 levels "1","2","3","4",..: 1 1 1 2 2 2 3 3 3  
> 4 ...
> $ Machine: Factor w/ 3 levels "A","B","C": 1 1 1 1 1 1 1 1 1 1 ...
> $ score  : num  52 52.8 53.1 51.8 52.8 53.1 60 60.2 58.4 51.1 ...
>
> We consider the Machine factor to have a fixed set of levels in that
> we only consider these three machines.  The levels of the Worker
> factor represent a sample from the set of potential operators.  As you
> might imagine from this description, I now think of the distinction
> between "fixed" and "random" as being associated with the factor, not
> necessarily the "effects".
>
> If you plot these data
>> dotplot(reorder(Worker, score) ~ score, Machines, groups = Machine,  
>> type = c("g", "p", "a"), xlab = "Efficiency score", ylab =  
>> "Worker", auto.key = list(columns = 3, lines = TRUE))
>
> (resulting PDF enclosed) you will see evidence of an interaction.
> That is, some workers have noticeably different score patterns on the
> three machines than do others.  Worker 6 on machine B is the most
> striking example.
>
> One way to model this interaction is to say that there is a random
> effect for each worker and a separate random effect for each
> worker/machine combination.  If the random effects for the
> worker/machine combinations are assumed to be independent with
> constant variance then one expresses the model as
>
>> print(fm1 <- lmer(score ~ Machine + (1|Worker) + (1| 
>> Machine:Worker), Machines), corr = FALSE)
> Linear mixed model fit by REML
> Formula: score ~ Machine + (1 | Worker) + (1 | Machine:Worker)
>  Data: Machines
>  AIC   BIC logLik deviance REMLdev
> 227.7 239.6 -107.8    225.5   215.7
> Random effects:
> Groups         Name        Variance Std.Dev.
> Machine:Worker (Intercept) 13.90963 3.72956
> Worker         (Intercept) 22.85528 4.78072
> Residual                    0.92464 0.96158
> Number of obs: 54, groups: Machine:Worker, 18; Worker, 6
>
> Fixed effects:
>           Estimate Std. Error t value
> (Intercept)   52.356      2.486  21.062
> MachineB       7.967      2.177   3.659
> MachineC      13.917      2.177   6.393
>
> An equivalent formulation is
>> print(fm1 <- lmer(score ~ Machine + (1|Worker/Machine), Machines),  
>> corr = FALSE)
> Linear mixed model fit by REML
> Formula: score ~ Machine + (1 | Worker/Machine)
>  Data: Machines
>  AIC   BIC logLik deviance REMLdev
> 227.7 239.6 -107.8    225.5   215.7
> Random effects:
> Groups         Name        Variance Std.Dev.
> Machine:Worker (Intercept) 13.90963 3.72956
> Worker         (Intercept) 22.85528 4.78072
> Residual                    0.92464 0.96158
> Number of obs: 54, groups: Machine:Worker, 18; Worker, 6
>
> Fixed effects:
>           Estimate Std. Error t value
> (Intercept)   52.356      2.486  21.062
> MachineB       7.967      2.177   3.659
> MachineC      13.917      2.177   6.393
>
> The expression (1|Worker/Machine) is just "syntactic sugar".  It is
> expanded to (1|Worker) + (1|Machine:Worker) before the model matrices
> are created.
>
> If you want to start with the formula and see what that means for the
> model then use these rules:
>
> - a term including the '|' operator is a random effects term
> - if the left-hand side of the '|' operator is 1 then the random
> effects are scalar random effects, one for each level of the factor on
> the right of the '|'
> - random effects associated with different terms are independent
> - random effects associated with different levels of the factor within
> a term are independent
> - the variance of the random effects within the same term is constant
>
> However, there is another mixed-effects model that could make sense
> for these data.  Suppose I consider the variations associated with
> each worker as a vector of length 3 (Machines A, B and C) with a
> symmetric, positive semidefinite 3 by 3 variance-covariance matrix.  I
> fit that model as
>
>> print(fm2 <- lmer(score ~ Machine + (Machine|Worker), Machines),  
>> corr = FALSE)
> Linear mixed model fit by REML
> Formula: score ~ Machine + (Machine | Worker)
>  Data: Machines
>  AIC   BIC logLik deviance REMLdev
> 228.3 248.2 -104.2    216.6   208.3
> Random effects:
> Groups   Name        Variance Std.Dev. Corr
> Worker   (Intercept) 16.64051 4.07928
>         MachineB    34.54670 5.87764   0.484
>         MachineC    13.61398 3.68971  -0.365  0.297
> Residual              0.92463 0.96158
> Number of obs: 54, groups: Worker, 6
>
> Fixed effects:
>           Estimate Std. Error t value
> (Intercept)   52.356      1.681  31.151
> MachineB       7.967      2.421   3.291
> MachineC      13.917      1.540   9.037
>
> It may be more meaningful to write it as
>
>> print(fm3 <- lmer(score ~ Machine + (0+Machine|Worker), Machines),  
>> corr = FALSE)
> Linear mixed model fit by REML
> Formula: score ~ Machine + (0 + Machine | Worker)
>  Data: Machines
>  AIC   BIC logLik deviance REMLdev
> 228.3 248.2 -104.2    216.6   208.3
> Random effects:
> Groups   Name     Variance Std.Dev. Corr
> Worker   MachineA 16.64097 4.07933
>         MachineB 74.39557 8.62529  0.803
>         MachineC 19.26646 4.38936  0.623 0.771
> Residual           0.92463 0.96158
> Number of obs: 54, groups: Worker, 6
>
> Fixed effects:
>           Estimate Std. Error t value
> (Intercept)   52.356      1.681  31.150
> MachineB       7.967      2.421   3.291
> MachineC      13.917      1.540   9.037
>
> Now we are fitting 3 variances and 3 covariances for the random
> effects instead of the previous models which had two variances.  The
> difference in the models is exactly what made you pause - the simpler
> model assumes that, conditional on the random effect for the worker,
> the worker/machine random effects are independent and have constant
> variance.  In the more general models the worker/machine interactions
> are allowed to be correlated within worker.
>
> It is more common to allow this kind of correlation within subject in
> models for longitudinal data (the Laird-Ware formulation) where each
> subject has a random effect for the intercept and a random effect for
> the slope with respect to time and these can be correlated.  However,
> this type of representation can make sense with a factor on the left
> hand side of the '|' operator, like the Machine factor here.  If that
> factor has a large number of levels then the model quickly becomes
> unwieldy because the number of variance-covariance parameters to
> estimate is quadratic in the number of levels of the factor on the
> lhs.
>
> I hope this helps.
>
>>      Having got there:  Presuming that I'm more-or-less on the  
>> right track
>>      in my foregoing conjecture that it's the over-simple dependence
>> structure
>>      that is the problem with what's delivered by the
>> Package-Which-Must-Not-Be-Named,
>>      how might one go about being less simple-minded?  I.e. what  
>> might be
>> some
>>      more realistic dependence structures, and how would one  
>> specify these
>> in lmer?
>>      And how would one assess whether the assumed dependence  
>> structure
>> gives
>>      a reasonable fit to the data?
>>
>>> If you can describe how many variance components you think should be
>>> estimated in your model and what they would represent then I think  
>>> it
>>> will be easier to describe how to fit the model.
>>
>>      How does this fit in with my conjecture (above) about what  
>> I've been
>>      missing all these years?  Does it fit?  How many variance  
>> components
>>      are there in the ``naive'' model?  It looks like 5 to me ... but
>> maybe
>>      I'm totally out to lunch in what I think I'm understanding at  
>> this
>> stage.
>>      (And besides --- there are three sorts of statistician; those  
>> who can
>> count,
>>      and those who can't.)
>>
>>      Thank you for your indulgence.
>>
>>               cheers,
>>
>>                      Rolf Turner
>>
>> ######################################################################
>> Attention:This e-mail message is privileged and confidential. If  
>> you are not
>> theintended recipient please delete the message and notify the  
>> sender.Any
>> views or opinions presented are solely those of the author.
>>
>> This e-mail has been scanned and cleared by
>> MailMarshalwww.marshalsoftware.com
>> ######################################################################
>>
> <Machines.pdf>_______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bolker at ufl.edu  Fri May 16 15:18:16 2008
From: bolker at ufl.edu (Ben Bolker)
Date: Fri, 16 May 2008 09:18:16 -0400
Subject: [R-sig-ME] Binomial GLMM vs GLM question
In-Reply-To: <37086.129.78.64.102.1210905401.squirrel@mail.kjbeath.com.au>
References: <482CADB8.7010100@bu.edu>
	<37086.129.78.64.102.1210905401.squirrel@mail.kjbeath.com.au>
Message-ID: <482D8998.4040009@ufl.edu>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Ken Beath wrote:
|> Dear Dr. Bates and other LMER experts,
|>     I am admittedly entry level in my R and mixed-model knowledge, but
|> I'm hoping that someone can help me and also forgive my lack of
|> insight.  Over 3 years, I monitored survival of 350 egg masses at two
|> ponds.  I thus have one continuous variable (rainfall) and two discrete
|> variables (year and pond).  My response variable, mortality, is coded as
|> a two column matrix featuring eggs survived and eggs dead. I'm primarily
|> interested in the effect of rain on survival, but also if rain has
|> different impacts at the different ponds and how much survival varied
|> over the three years.  Originally, I though I could tackle this with a
|> binomial GLM, but do I need a binomial GLMM instead, as rainfall and
|> year would be random and pond fixed?  The problem with this is trying to
|> make biological sense out of the results.  I've spent the last week
|> reading all the past posts about why p-values can't be calculated and
|> all that, which I'm fine with.  But what can I say about the effects of
|> rainfall or year on egg survival from the variance estimates?  Also,
|> doesn't LMER require that random factors be normally distributed,
|> because my rainfall measurements are far from it.  Is that a problem?
|> Thank you in advance for any advice you can give.
|> -Justin Touchon
|>
|
| I think your misunderstanding the idea of a random effect. This is
| something that is unobserved, causing correlation within a group. In your
| data this might be year or pond but definitely not rainfall which is
| simply a covariate. You have more than one measurement on a pond and more
| than one for each year, so it is likely that there will be correlation
| between them and one way of dealing with this is a random effect. The
| alternative is to use a fixed effects model. In your case, there are only
| 2 and 3 groups, so a fixed effects model is the best approach, so a GLM is
| appropriate. If there were say 20 ponds, a random effects model would be
| much more suitable.
|
| Ken

~  Agreed.
~  One other point to watch out for (not directly related to GLMMs)
is that you should check the scale parameter estimate: I don't know if
the model you have below is sensible or not, but if you do end up
with an estimated scale parameter of 4.6, you must take overdispersion
into account (e.g., with a quasibinomial or beta-binomial model).

~  Ben Bolker

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.6 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org

iD8DBQFILYmXc5UpGjwzenMRAimcAJ0ZhaBH8LEd4C44uk3n0Y7ul1HUtQCfazFY
sY6qlcU4psciD1VYXO9xeE4=
=S1x+
-----END PGP SIGNATURE-----



From siwulayid at gmail.com  Fri May 16 15:40:47 2008
From: siwulayid at gmail.com (Luwis Tapiwa Diya)
Date: Fri, 16 May 2008 15:40:47 +0200
Subject: [R-sig-ME] Fitting non-linear hierarchical models with `unbalanced'
	random effects and covariates
Message-ID: <ddf1e2bc0805160640i31e33614hcafc0e4b7fcbd5fd@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080516/c0b5b266/attachment.pl>

From j.stapley at sheffield.ac.uk  Fri May 16 18:40:43 2008
From: j.stapley at sheffield.ac.uk (Jessica Stapley)
Date: Fri, 16 May 2008 17:40:43 +0100
Subject: [R-sig-ME] Binomial GLMM vs GLM question (Ken Beath)
In-Reply-To: <mailman.3.1210932001.31392.r-sig-mixed-models@r-project.org>
References: <mailman.3.1210932001.31392.r-sig-mixed-models@r-project.org>
Message-ID: <4BD78F8D-0191-427A-9AC8-52370C1CDE39@sheffield.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080516/71a78563/attachment.pl>

From mbustama at bio.puc.cl  Fri May 16 21:22:43 2008
From: mbustama at bio.puc.cl (Marcela A. Bustamante-Sanchez)
Date: Fri, 16 May 2008 15:22:43 -0400
Subject: [R-sig-ME] p values for fixed effects using mcmc
Message-ID: <01ad01c8b78a$3880e3c0$87d79b92@MBustamante>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080516/a68ef47e/attachment.pl>

From bolker at ufl.edu  Fri May 16 22:53:07 2008
From: bolker at ufl.edu (Ben Bolker)
Date: Fri, 16 May 2008 16:53:07 -0400
Subject: [R-sig-ME] Binomial GLMM vs GLM question (Ken Beath)
In-Reply-To: <4BD78F8D-0191-427A-9AC8-52370C1CDE39@sheffield.ac.uk>
References: <mailman.3.1210932001.31392.r-sig-mixed-models@r-project.org>
	<4BD78F8D-0191-427A-9AC8-52370C1CDE39@sheffield.ac.uk>
Message-ID: <482DF433.5030901@ufl.edu>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Jessica Stapley wrote:
|> Message: 2
|> Date: Fri, 16 May 2008 02:36:41 -0000 (UTC)
|> From: "Ken Beath" <kjbeath at kagi.com>
|> Subject: Re: [R-sig-ME] Binomial GLMM vs GLM question
|> To: "Justin Touchon" <jtouchon at bu.edu>
|> Cc: r-sig-mixed-models at r-project.org
|> Message-ID:
|> 	<37086.129.78.64.102.1210905401.squirrel at mail.kjbeath.com.au>
|> Content-Type: text/plain;charset=iso-8859-1
|>
|>> Dear Dr. Bates and other LMER experts,
|>>     I am admittedly entry level in my R and mixed-model knowledge,
|>> but
|>> I'm hoping that someone can help me and also forgive my lack of
|>> insight.  Over 3 years, I monitored survival of 350 egg masses at two
|>> ponds.  I thus have one continuous variable (rainfall) and two
|>> discrete
|>> variables (year and pond).  My response variable, mortality, is
|>> coded as
|>> a two column matrix featuring eggs survived and eggs dead. I'm
|>> primarily
|>> interested in the effect of rain on survival, but also if rain has
|>> different impacts at the different ponds and how much survival varied
|>> over the three years.  Originally, I though I could tackle this
|>> with a
|>> binomial GLM, but do I need a binomial GLMM instead, as rainfall and
|>> year would be random and pond fixed?  The problem with this is
|>> trying to
|>> make biological sense out of the results.  I've spent the last week
|>> reading all the past posts about why p-values can't be calculated and
|>> all that, which I'm fine with.  But what can I say about the
|>> effects of
|>> rainfall or year on egg survival from the variance estimates?  Also,
|>> doesn't LMER require that random factors be normally distributed,
|>> because my rainfall measurements are far from it.  Is that a problem?
|>> Thank you in advance for any advice you can give.
|>> -Justin Touchon
|>>
|> I think your misunderstanding the idea of a random effect. This is
|> something that is unobserved, causing correlation within a group.
|> In your
|> data this might be year or pond but definitely not rainfall which is
|> simply a covariate. You have more than one measurement on a pond
|> and more
|> than one for each year, so it is likely that there will be correlation
|> between them and one way of dealing with this is a random effect. The
|> alternative is to use a fixed effects model. In your case, there
|> are only
|> 2 and 3 groups, so a fixed effects model is the best approach, so a
|> GLM is
|> appropriate. If there were say 20 ponds, a random effects model
|> would be
|> much more suitable.
|>
|> Ken
|

~  So -- I may be wrong (others please jump in) -- but I disagree with
several points in the most recent comment.

| I think this is a good example of what seems a common problem for
| people using mixed models - How to decide what are the random factors
| and what are the fixed factors.

~  I agree that this is difficult, and contentious (see e.g.
Andrew Gelman, "Analysis of variance--why it is more important than
ever," Annals of Statistics 33, no. 1 (2005): 1-53,
doi:http://dx.doi.org/doi:10.1214/009053604000001048)


| In your study you have taken repeated measurements on the same ponds,
| as such, observations from each pond across years are not independent
| (observations in pond 1 at t+1 will be correlated with observations
| at t).  If you were only interested in the effect of rainfall on egg
| survival I would suggest you use a mixed model with year and pond as
| random effects (based on a similar eg in Crawley's R Book p605). In
| this case I assume you have measurements on every pond in every year
| and as such these random effects are crossed (not nested).

~  (a) I would suggest that a mixed model is NOT going to work well
in this case, even if year and pond are "philosophically" random effects
(i.e., you don't really care about what happens in those specific
ponds, and you may even have chosen them with a random-number generator
out of a list of all possible ponds -- although this is much less
likely with years ...).  The technical problem is that estimating
variances from 2 or 3 points is nasty.  This translates into
inference/philosophical terms because these few points really
don't give you the data to generalize about the population, even if
you want to.  (I think one of the confusions is that in the classical
method-of-moments world there's nothing that says you can't have 2
denominator degrees of freedom -- your power will be terrible, but
the expressions won't blow up on you [unless you get negative variance
estimates ...])
|
| m1 <- lmer(mort~rainfall + (year|pond), family = binomial, data=
| FieldData0305)

~   (1|year)+(1|pond) might work OK, and be slightly more
parsimonious (OR ponds nested within years, (1|year)+(1|pond:year), or
vice versa -- and if you're not dead set on treating the random effects
as "effects of year" and "effects of pond", but were willing to treat it
as "effects of pond within year" that would buy you the flexibility
to use some other package that wasn't so good at crossed
effects.)


| summary(m1)
|  From the summary output you can assess the influence of the fixed
| effect to see if the estimate for rainfall (slope estimate) is
| different to zero.
|
| Even if the number of groups (years and ponds) is small it is still
| better to take account of this group variation than ignore it (see
| Gelman and Hill 200&.

~  Yes, but ... what if all you can get out of the model is that
the estimate is nearly zero?  If you go Bayesian instead you can
deal with some problems by setting an informative prior [in theory
setting a proper prior, no matter how weak, would generally solve
the problem, but in reality I suspect that if the model is
overparameterized you're going to have nasty technical difficulties
even if the model is theoretically OK])
~  With respect to Andrew Gelman (I can't believe I'm saying this --
sacrilege) but I think he's used to really big social-science data sets,
where "leave stuff in when you're not sure" is more generally
a good idea than it is in typical field ecology data sets, where
the bias-variance tradeoff bites harder.  (At least there are 350
data points here,

|  From this model you can also get a feeling for the between year and
| between pond variation by looking at the random effects estimates and
| variances. Obviously you will have some idea if you just plot the
| means for each year and each pond.

~  Only if the variance estimates don't suck.

| If you are also interested in understanding how egg survival differs
| between ponds or between years and if this interacts with rainfall
| then it become less straight forward.
|
| I would suggest that you try
|
| m2 <- lmer(mort~rainfall * year * pond + (year|pond), family =
| binomial, data= FieldData0305)
| summary(m2)
|
| In the summary you will have estimates for all three factors and
| their interactions and you can ascertain if these are good
| explanatory variables for egg survival.

~   Isn't this overparameterized?  We have a fixed effect for
each year:pond combination (and variation in the slopes of
the effect with respect to rainfall), as well as a random-effect
level for years and ponds?

|
| You may be able to argue that the correlation between years or
| between ponds is negligible and therefore you can leave out the
| random effect and only use a GLM, but I would be inclined to avoid
| model simplification - but other may suggest otherwise.
|
| Jess
|


|
|>> My model and output are as follows:
|>>
|>>> LMER.1<-lmer(mort~Pond + (Pond|total_rainfall) + (1|Year),
|>> family=binomial, data= FieldData0305)
|>>
|>>> summary(LMER.1)
|>> Generalized linear mixed model fit using Laplace
|>> Formula: mort ~ Pond + (Pond | total_rainfall) + (1 | Year)
|>>    Data: FieldData0305
|>>  Family: binomial(logit link)
|>>   AIC  BIC logLik deviance
|>>  7657 7680  -3822     7645
|>> Random effects:
|>>  Groups         Name           Variance Std.Dev. Corr
|>>  total_rainfall (Intercept)    21.66535 4.65461
|>>                 Pond[T.Ocelot]  6.44297 2.53830  -0.627
|>>  Year           (Intercept)     0.74082 0.86071
|>> number of obs: 350, groups: total_rainfall, 48; Year, 3
|>>
|>> Estimated scale (compare to  1 )  4.603433
|>>
|>> Fixed effects:
|>>                Estimate Std. Error z value Pr(>|z|)
|>> (Intercept)     -0.4678     1.0173 -0.4598    0.646
|>> Pond[T.Ocelot]  -0.9831     0.9330 -1.0538    0.292
|>>
|>> Correlation of Fixed Effects:
|>>             (Intr)
|>> Pnd[T.Oclt] -0.648
|>>
|>> _______________________________________________
|>> R-sig-mixed-models at r-project.org mailing list
|>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
|>>
|
| Jessica Stapley
| Department of Animal and Plant Sciences,
| Alfred Denny Building
| Sheffield, S10 2TN, UK
| ph +44 (0)114 222 0112; fx +44 (0)114 222 0002
| 	[[alternative HTML version deleted]]
|
| _______________________________________________
| R-sig-mixed-models at r-project.org mailing list
| https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.6 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org

iD8DBQFILfQzc5UpGjwzenMRArz/AJ9D/bNPvQwicMp1n9KTxo4ZvXZ7iACfdznJ
F3NWHTkIVWVG5N2zxdgNnDk=
=rT/4
-----END PGP SIGNATURE-----



From A.Robinson at ms.unimelb.edu.au  Sat May 17 00:24:54 2008
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Sat, 17 May 2008 08:24:54 +1000
Subject: [R-sig-ME] Binomial GLMM vs GLM question (Ken Beath)
In-Reply-To: <482DF433.5030901@ufl.edu>
References: <mailman.3.1210932001.31392.r-sig-mixed-models@r-project.org>
	<4BD78F8D-0191-427A-9AC8-52370C1CDE39@sheffield.ac.uk>
	<482DF433.5030901@ufl.edu>
Message-ID: <20080516222454.GQ27037@ms.unimelb.edu.au>

On Fri, May 16, 2008 at 04:53:07PM -0400, Ben Bolker wrote:
> 
> Jessica Stapley wrote:
> ~  So -- I may be wrong (others please jump in) -- but I disagree with
> several points in the most recent comment.
> 
> | In your study you have taken repeated measurements on the same ponds,
> | as such, observations from each pond across years are not independent
> | (observations in pond 1 at t+1 will be correlated with observations
> | at t).  If you were only interested in the effect of rainfall on egg
> | survival I would suggest you use a mixed model with year and pond as
> | random effects (based on a similar eg in Crawley's R Book p605). In
> | this case I assume you have measurements on every pond in every year
> | and as such these random effects are crossed (not nested).
> 
> ~  (a) I would suggest that a mixed model is NOT going to work well
> in this case, even if year and pond are "philosophically" random effects
> (i.e., you don't really care about what happens in those specific
> ponds, and you may even have chosen them with a random-number generator
> out of a list of all possible ponds -- although this is much less
> likely with years ...).  The technical problem is that estimating
> variances from 2 or 3 points is nasty.  This translates into
> inference/philosophical terms because these few points really
> don't give you the data to generalize about the population, even if
> you want to.  (I think one of the confusions is that in the classical
> method-of-moments world there's nothing that says you can't have 2
> denominator degrees of freedom -- your power will be terrible, but
> the expressions won't blow up on you [unless you get negative variance
> estimates ...])

I'm just going to square away with just one of Ben's well thought out
points.  In my opinion, the allocation of an effect to being fixed or
random depends partially upon the design and partially upon the use to
which the model will be put.  There may be reasons to make effects
random even if they have small counts.  

For example, if you make the effects random then you're effectively
marginalizing them, whereas if you make them fixed you're forced to
condition on them, which can complicate an analysis and its
presentation.  You may not wish to necessarily draw inference to the
broadest possible population, but still regardless might be interested
in averaging over the effects, whilst benefitting from their
management of the (supposed) correlation in the residuals.

I'm probably influenced in my thinking by the analysis of split-plot
designs, where inference often proceeds including random effects with
embarrassingly small counts.  I know that in general it is not
necessarily safe to import intuition from ANOVA to mixed effects
models, but there we go.

So, for what it's worth, I think that I am less concerned about this
element of the analysis than Ben is.

Cheers

Andrew

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From john.maindonald at anu.edu.au  Sat May 17 02:51:54 2008
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Sat, 17 May 2008 10:51:54 +1000
Subject: [R-sig-ME] Binomial GLMM vs GLM question (Ken Beath)
In-Reply-To: <482DF433.5030901@ufl.edu>
References: <mailman.3.1210932001.31392.r-sig-mixed-models@r-project.org>
	<4BD78F8D-0191-427A-9AC8-52370C1CDE39@sheffield.ac.uk>
	<482DF433.5030901@ufl.edu>
Message-ID: <DA573494-2D65-468D-8DE6-3B61BF10E162@anu.edu.au>

Philosophically, I am sure that Andrew Gelman is right, and
that applies also when estimates of one or other of the effects
are based on very limited information.  One can indeed banish
the random effect and its associated uncertainty, but all that
does is to transfer the uncertainty to another place. The
conclusions from the study must be hedged around with ifs and
buts, relative to the generalizations that the researcher might
have wanted to draw.

Other evidence that places the results in some kind of context
becomes crucial.  "X did a study that is roughly comparable to
ours, where variation between the 5 years of the study was of
no consequence relative to variation between the 10 ponds ...".
Or, "Four of the 5 years were dry, with variation between years
that was of minor consequence.  In the one wet year, results
were very different ...".  Or "X's results suggest that we might
have to multiply the SEs by as much as 3 to account for variation
between years.  In other words, the researcher, while gaining
all the leverage possible from other sources of evidence, has
to be brutally honest about limitations, even to the extent of
dealing it a mortal blow!  RA Fisher's dictum is no doubt too
extreme as a general comment, but it does have a certain
relevance (one can see where it is pointing):

"To call in the statistician after the experiment is done may be
no  more than asking him to perform a post-mortem examination:
he may be able to say what the experiment died of."

Even with data from 4 or 5 years, there's not much that can be
done about sequential correlation between years.  One has
little choice but to treat the years as random, or at least to assume
an AR1 or similarly simple error structure.

Non-normality of the rainfall data does not invalidate the analysis.
There is however an issue of leverage.  If the distribution is highly
positively skew, then the heavy tail may unduly wag (lever) the
analysis.  Maybe, try the cube root transformation that has some
currency in the literature.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.

On 17 May 2008, at 6:53 AM, Ben Bolker wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> Jessica Stapley wrote:
> |> Message: 2
> |> Date: Fri, 16 May 2008 02:36:41 -0000 (UTC)
> |> From: "Ken Beath" <kjbeath at kagi.com>
> |> Subject: Re: [R-sig-ME] Binomial GLMM vs GLM question
> |> To: "Justin Touchon" <jtouchon at bu.edu>
> |> Cc: r-sig-mixed-models at r-project.org
> |> Message-ID:
> |> 	<37086.129.78.64.102.1210905401.squirrel at mail.kjbeath.com.au>
> |> Content-Type: text/plain;charset=iso-8859-1
> |>
> |>> Dear Dr. Bates and other LMER experts,
> |>>     I am admittedly entry level in my R and mixed-model knowledge,
> |>> but
> |>> I'm hoping that someone can help me and also forgive my lack of
> |>> insight.  Over 3 years, I monitored survival of 350 egg masses  
> at two
> |>> ponds.  I thus have one continuous variable (rainfall) and two
> |>> discrete
> |>> variables (year and pond).  My response variable, mortality, is
> |>> coded as
> |>> a two column matrix featuring eggs survived and eggs dead. I'm
> |>> primarily
> |>> interested in the effect of rain on survival, but also if rain has
> |>> different impacts at the different ponds and how much survival  
> varied
> |>> over the three years.  Originally, I though I could tackle this
> |>> with a
> |>> binomial GLM, but do I need a binomial GLMM instead, as rainfall  
> and
> |>> year would be random and pond fixed?  The problem with this is
> |>> trying to
> |>> make biological sense out of the results.  I've spent the last  
> week
> |>> reading all the past posts about why p-values can't be  
> calculated and
> |>> all that, which I'm fine with.  But what can I say about the
> |>> effects of
> |>> rainfall or year on egg survival from the variance estimates?   
> Also,
> |>> doesn't LMER require that random factors be normally distributed,
> |>> because my rainfall measurements are far from it.  Is that a  
> problem?
> |>> Thank you in advance for any advice you can give.
> |>> -Justin Touchon
> |>>
> |> I think your misunderstanding the idea of a random effect. This is
> |> something that is unobserved, causing correlation within a group.
> |> In your
> |> data this might be year or pond but definitely not rainfall which  
> is
> |> simply a covariate. You have more than one measurement on a pond
> |> and more
> |> than one for each year, so it is likely that there will be  
> correlation
> |> between them and one way of dealing with this is a random effect.  
> The
> |> alternative is to use a fixed effects model. In your case, there
> |> are only
> |> 2 and 3 groups, so a fixed effects model is the best approach, so a
> |> GLM is
> |> appropriate. If there were say 20 ponds, a random effects model
> |> would be
> |> much more suitable.
> |>
> |> Ken
> |
>
> ~  So -- I may be wrong (others please jump in) -- but I disagree with
> several points in the most recent comment.
>
> | I think this is a good example of what seems a common problem for
> | people using mixed models - How to decide what are the random  
> factors
> | and what are the fixed factors.
>
> ~  I agree that this is difficult, and contentious (see e.g.
> Andrew Gelman, "Analysis of variance--why it is more important than
> ever," Annals of Statistics 33, no. 1 (2005): 1-53,
> doi:http://dx.doi.org/doi:10.1214/009053604000001048)
>
>
> | In your study you have taken repeated measurements on the same  
> ponds,
> | as such, observations from each pond across years are not  
> independent
> | (observations in pond 1 at t+1 will be correlated with observations
> | at t).  If you were only interested in the effect of rainfall on egg
> | survival I would suggest you use a mixed model with year and pond as
> | random effects (based on a similar eg in Crawley's R Book p605). In
> | this case I assume you have measurements on every pond in every year
> | and as such these random effects are crossed (not nested).
>
> ~  (a) I would suggest that a mixed model is NOT going to work well
> in this case, even if year and pond are "philosophically" random  
> effects
> (i.e., you don't really care about what happens in those specific
> ponds, and you may even have chosen them with a random-number  
> generator
> out of a list of all possible ponds -- although this is much less
> likely with years ...).  The technical problem is that estimating
> variances from 2 or 3 points is nasty.  This translates into
> inference/philosophical terms because these few points really
> don't give you the data to generalize about the population, even if
> you want to.  (I think one of the confusions is that in the classical
> method-of-moments world there's nothing that says you can't have 2
> denominator degrees of freedom -- your power will be terrible, but
> the expressions won't blow up on you [unless you get negative variance
> estimates ...])
> |
> | m1 <- lmer(mort~rainfall + (year|pond), family = binomial, data=
> | FieldData0305)
>
> ~   (1|year)+(1|pond) might work OK, and be slightly more
> parsimonious (OR ponds nested within years, (1|year)+(1|pond:year), or
> vice versa -- and if you're not dead set on treating the random  
> effects
> as "effects of year" and "effects of pond", but were willing to  
> treat it
> as "effects of pond within year" that would buy you the flexibility
> to use some other package that wasn't so good at crossed
> effects.)
>
>
> | summary(m1)
> |  From the summary output you can assess the influence of the fixed
> | effect to see if the estimate for rainfall (slope estimate) is
> | different to zero.
> |
> | Even if the number of groups (years and ponds) is small it is still
> | better to take account of this group variation than ignore it (see
> | Gelman and Hill 200&.
>
> ~  Yes, but ... what if all you can get out of the model is that
> the estimate is nearly zero?  If you go Bayesian instead you can
> deal with some problems by setting an informative prior [in theory
> setting a proper prior, no matter how weak, would generally solve
> the problem, but in reality I suspect that if the model is
> overparameterized you're going to have nasty technical difficulties
> even if the model is theoretically OK])
> ~  With respect to Andrew Gelman (I can't believe I'm saying this --
> sacrilege) but I think he's used to really big social-science data  
> sets,
> where "leave stuff in when you're not sure" is more generally
> a good idea than it is in typical field ecology data sets, where
> the bias-variance tradeoff bites harder.  (At least there are 350
> data points here,
>
> |  From this model you can also get a feeling for the between year and
> | between pond variation by looking at the random effects estimates  
> and
> | variances. Obviously you will have some idea if you just plot the
> | means for each year and each pond.
>
> ~  Only if the variance estimates don't suck.
>
> | If you are also interested in understanding how egg survival differs
> | between ponds or between years and if this interacts with rainfall
> | then it become less straight forward.
> |
> | I would suggest that you try
> |
> | m2 <- lmer(mort~rainfall * year * pond + (year|pond), family =
> | binomial, data= FieldData0305)
> | summary(m2)
> |
> | In the summary you will have estimates for all three factors and
> | their interactions and you can ascertain if these are good
> | explanatory variables for egg survival.
>
> ~   Isn't this overparameterized?  We have a fixed effect for
> each year:pond combination (and variation in the slopes of
> the effect with respect to rainfall), as well as a random-effect
> level for years and ponds?
>
> |
> | You may be able to argue that the correlation between years or
> | between ponds is negligible and therefore you can leave out the
> | random effect and only use a GLM, but I would be inclined to avoid
> | model simplification - but other may suggest otherwise.
> |
> | Jess
> |
>
>
> |
> |>> My model and output are as follows:
> |>>
> |>>> LMER.1<-lmer(mort~Pond + (Pond|total_rainfall) + (1|Year),
> |>> family=binomial, data= FieldData0305)
> |>>
> |>>> summary(LMER.1)
> |>> Generalized linear mixed model fit using Laplace
> |>> Formula: mort ~ Pond + (Pond | total_rainfall) + (1 | Year)
> |>>    Data: FieldData0305
> |>>  Family: binomial(logit link)
> |>>   AIC  BIC logLik deviance
> |>>  7657 7680  -3822     7645
> |>> Random effects:
> |>>  Groups         Name           Variance Std.Dev. Corr
> |>>  total_rainfall (Intercept)    21.66535 4.65461
> |>>                 Pond[T.Ocelot]  6.44297 2.53830  -0.627
> |>>  Year           (Intercept)     0.74082 0.86071
> |>> number of obs: 350, groups: total_rainfall, 48; Year, 3
> |>>
> |>> Estimated scale (compare to  1 )  4.603433
> |>>
> |>> Fixed effects:
> |>>                Estimate Std. Error z value Pr(>|z|)
> |>> (Intercept)     -0.4678     1.0173 -0.4598    0.646
> |>> Pond[T.Ocelot]  -0.9831     0.9330 -1.0538    0.292
> |>>
> |>> Correlation of Fixed Effects:
> |>>             (Intr)
> |>> Pnd[T.Oclt] -0.648
> |>>
> |>> _______________________________________________
> |>> R-sig-mixed-models at r-project.org mailing list
> |>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> |>>
> |
> | Jessica Stapley
> | Department of Animal and Plant Sciences,
> | Alfred Denny Building
> | Sheffield, S10 2TN, UK
> | ph +44 (0)114 222 0112; fx +44 (0)114 222 0002
> | 	[[alternative HTML version deleted]]
> |
> | _______________________________________________
> | R-sig-mixed-models at r-project.org mailing list
> | https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.6 (GNU/Linux)
> Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org
>
> iD8DBQFILfQzc5UpGjwzenMRArz/AJ9D/bNPvQwicMp1n9KTxo4ZvXZ7iACfdznJ
> F3NWHTkIVWVG5N2zxdgNnDk=
> =rT/4
> -----END PGP SIGNATURE-----
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From kjbeath at kagi.com  Sat May 17 09:39:46 2008
From: kjbeath at kagi.com (Ken Beath)
Date: Sat, 17 May 2008 17:39:46 +1000
Subject: [R-sig-ME] Binomial GLMM vs GLM question
In-Reply-To: <482DF433.5030901@ufl.edu>
References: <mailman.3.1210932001.31392.r-sig-mixed-models@r-project.org>
	<4BD78F8D-0191-427A-9AC8-52370C1CDE39@sheffield.ac.uk>
	<482DF433.5030901@ufl.edu>
Message-ID: <174F3A38-C71A-49D8-BAE2-CD1DAA1267FF@kagi.com>

On 17/05/2008, at 6:53 AM, Ben Bolker wrote:

<snip>
>
> | I think this is a good example of what seems a common problem for
> | people using mixed models - How to decide what are the random  
> factors
> | and what are the fixed factors.
>
> ~  I agree that this is difficult, and contentious (see e.g.
> Andrew Gelman, "Analysis of variance--why it is more important than
> ever," Annals of Statistics 33, no. 1 (2005): 1-53,
> doi:http://dx.doi.org/doi:10.1214/009053604000001048)
>
Available at
http://www.stat.columbia.edu/~gelman/research/published/AOS259.pdf

>
> | In your study you have taken repeated measurements on the same  
> ponds,
> | as such, observations from each pond across years are not  
> independent
> | (observations in pond 1 at t+1 will be correlated with observations
> | at t).  If you were only interested in the effect of rainfall on egg
> | survival I would suggest you use a mixed model with year and pond as
> | random effects (based on a similar eg in Crawley's R Book p605). In
> | this case I assume you have measurements on every pond in every year
> | and as such these random effects are crossed (not nested).
>
> ~  (a) I would suggest that a mixed model is NOT going to work well
> in this case, even if year and pond are "philosophically" random  
> effects
> (i.e., you don't really care about what happens in those specific
> ponds, and you may even have chosen them with a random-number  
> generator
> out of a list of all possible ponds -- although this is much less
> likely with years ...).  The technical problem is that estimating
> variances from 2 or 3 points is nasty.  This translates into
> inference/philosophical terms because these few points really
> don't give you the data to generalize about the population, even if
> you want to.  (I think one of the confusions is that in the classical
> method-of-moments world there's nothing that says you can't have 2
> denominator degrees of freedom -- your power will be terrible, but
> the expressions won't blow up on you [unless you get negative variance
> estimates ...])
> |
> | m1 <- lmer(mort~rainfall + (year|pond), family = binomial, data=
> | FieldData0305)
>
> ~   (1|year)+(1|pond) might work OK, and be slightly more
> parsimonious (OR ponds nested within years, (1|year)+(1|pond:year), or
> vice versa -- and if you're not dead set on treating the random  
> effects
> as "effects of year" and "effects of pond", but were willing to  
> treat it
> as "effects of pond within year" that would buy you the flexibility
> to use some other package that wasn't so good at crossed
> effects.)
>
>
> | summary(m1)
> |  From the summary output you can assess the influence of the fixed
> | effect to see if the estimate for rainfall (slope estimate) is
> | different to zero.
> |
> | Even if the number of groups (years and ponds) is small it is still
> | better to take account of this group variation than ignore it (see
> | Gelman and Hill 200&.
>
> ~  Yes, but ... what if all you can get out of the model is that
> the estimate is nearly zero?  If you go Bayesian instead you can
> deal with some problems by setting an informative prior [in theory
> setting a proper prior, no matter how weak, would generally solve
> the problem, but in reality I suspect that if the model is
> overparameterized you're going to have nasty technical difficulties
> even if the model is theoretically OK])
> ~  With respect to Andrew Gelman (I can't believe I'm saying this --
> sacrilege) but I think he's used to really big social-science data  
> sets,
> where "leave stuff in when you're not sure" is more generally
> a good idea than it is in typical field ecology data sets, where
> the bias-variance tradeoff bites harder.  (At least there are 350
> data points here,
>
> |  From this model you can also get a feeling for the between year and
> | between pond variation by looking at the random effects estimates  
> and
> | variances. Obviously you will have some idea if you just plot the
> | means for each year and each pond.
>
> ~  Only if the variance estimates don't suck.
>
> | If you are also interested in understanding how egg survival differs
> | between ponds or between years and if this interacts with rainfall
> | then it become less straight forward.
> |
> | I would suggest that you try
> |
> | m2 <- lmer(mort~rainfall * year * pond + (year|pond), family =
> | binomial, data= FieldData0305)
> | summary(m2)
> |
> | In the summary you will have estimates for all three factors and
> | their interactions and you can ascertain if these are good
> | explanatory variables for egg survival.
>
> ~   Isn't this overparameterized?  We have a fixed effect for
> each year:pond combination (and variation in the slopes of
> the effect with respect to rainfall), as well as a random-effect
> level for years and ponds?
>

This does bring up the important point as to whether the effect of  
rainfall does vary within year and site. One advantage of the mixed  
effects method for dealing with varying slopes is it gives a nice  
population estimate. Unfortunately this is a lot of random effects for  
not many groups.  It is looking very messy.

I think with this sort of data, as in it has very few groups) the best  
option is to start with the basics (probably always the best option).  
Fit a separate model for each group and determine an appropriate  
transform for rainfall. Do the models fit reasonably? Look at the  
parameter estimates with 95% CI (plotting is a good idea) and see how  
much variation there is, and there is nothing strange happening like  
one unusual year-pond. Then decide whether the more complex models  
will tell you anything more.

Ken
>



From austin.frank at gmail.com  Sat May 17 19:31:55 2008
From: austin.frank at gmail.com (Austin Frank)
Date: Sat, 17 May 2008 13:31:55 -0400
Subject: [R-sig-ME] Binomial GLMM vs GLM question (Ken Beath)
References: <mailman.3.1210932001.31392.r-sig-mixed-models@r-project.org>
	<4BD78F8D-0191-427A-9AC8-52370C1CDE39@sheffield.ac.uk>
	<482DF433.5030901@ufl.edu> <20080516222454.GQ27037@ms.unimelb.edu.au>
Message-ID: <m0tzgw4z1w.fsf@gmail.com>

On Fri, May 16 2008, Andrew Robinson wrote:

> For example, if you make the effects random then you're effectively
> marginalizing them, whereas if you make them fixed you're forced to
> condition on them

Hello all!

I'm cherry picking this one line from a recent discussion because it's
the most recent example of people discussing fixed and random effects in
terms of conditioning and marginalization.  The use of this terminology
on this list seems to have increased in the past year or so (or, more
likely, I've just started noticing it), and it's time for me to confess
that I'm not sure I understand it.

If we have a model

#v+
y ~ 1 + x + (1 | z)
#v-

the suggested correspondences between fixed effects and
conditionalizing, and between random effects and marginalization suggest
to me that at some point we are interested in

#v+
\sum_{z} P(y | x, z)
#v-

This is my guess at the correspondence suggested by the quote above, but
it's based solely on the fact that I think I know what conditional
probabilities and marginalization are.  It could be 100% off base.

I guess I have four questions:

1.  Is this the correct understanding of how fixed and random effects
    translate into conditionalizing and marginalizing?
2.  In mixed logit models, we are modeling probabilities (or, log odds
    of probabilities) , so this specification maybe makes some sense to
    me.  But how does it fit into a linear mixed model?
3.  What role does this probability play in fitting the model?
4.  Do the coefficients for fixed effects from the fitted model have an
    interpretation in terms of the above probability model?

Sorry if this query is so misinformed as to be nonsensical.  If you have
a feeling for what I'm trying to ask, feel free to answer that question
instead ;)  Also, if this is a RTF*-type question, please let me know
what the appropriate value of * is in this case (V for vignette,
maybe?).

Thanks for any help,
/au

-- 
Austin Frank
http://aufrank.net
GPG Public Key (D7398C2F): http://aufrank.net/personal.asc



From clavulina at gmail.com  Sat May 17 21:21:26 2008
From: clavulina at gmail.com (Jordan Mayor)
Date: Sat, 17 May 2008 15:21:26 -0400
Subject: [R-sig-ME] is multicollinearity of fixed effects resolved by random
	effects
Message-ID: <a0d257780805171221o72c53ff1qe4111abc45cf3a6e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080517/52f6ecd8/attachment.pl>

From john.maindonald at anu.edu.au  Sun May 18 03:07:46 2008
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Sun, 18 May 2008 11:07:46 +1000
Subject: [R-sig-ME] is multicollinearity of fixed effects resolved by
	random effects
In-Reply-To: <a0d257780805171221o72c53ff1qe4111abc45cf3a6e@mail.gmail.com>
References: <a0d257780805171221o72c53ff1qe4111abc45cf3a6e@mail.gmail.com>
Message-ID: <B49D721F-E539-48EF-99A7-B57300C9AEBD@anu.edu.au>

Don't you want MAT+MAP+LAT, possibly with first order
interactions in also?  If you still find multicollinearity, look
at the relationship between MAT, MAP and LAT, probably
using regression.  If you still find multi-collinearity, you
need to work out which variables or constructed variables
are most meaningful to retain.

Surely you should allow for a fixed effect of species.  So my
guess would be:

mix.model1 <- lmer(X13C~ MAT+MAP+LAT + SPECIES + (1|SITE/SPECIES),  
method ="ML", data=ds)
or maybe
mix.model1 <- lmer(X13C~ (MAT+MAP+LAT + SPECIES)^2 + (1|SITE/SPECIES),  
method ="ML", data=ds)

But before you go too far, consider whether some species may
show very consistent variation across sites, whereas others may
be quite incognisant of sites; they're the tourists who live in
expensive luxury hotels that are the same wherever they go!
Fit fixed effect models for each species, then xyplot() to look at
the pattern of change of parameter estimates across species.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


On 18 May 2008, at 5:21 AM, Jordan Mayor wrote:

> Hello, I am currently using mixed models (lme4) to explain  
> variability in
> fungal isotope patterns in 800 fungal SPECIES across 24 SITES in the  
> world.
> I have thus decided to nest the species within site as hierarchical  
> *random
> effects*.  I am just trying to explain the variability in fungal  
> isotopes
> values not necessarily predict values of fungi from other areas of the
> world.
>
> My *fixed effects* include mean annual temperature, mean annual
> precipitation, and latitude.  Perhaps obviously, all three suffer from
> strong multicollinearity problems.
>
> *My question is:*  Should I simply omit using fixed effects  
> additively?  In
> other words, is it valid to simply use the fixed effects singly or as
> interactions (see code below) or do the random effects take care of  
> the
> collinearity issue during adjustment of model error variance  
> allowing me to
> compare full-factorial models instead?
>
> Thanks in advance to all those with advice or references.
>
> -- 
> Jordan Mayor
>
> My code:
>
>> names(ds)
> [1] "STUDY"    "SPECIES"  "SITE"     "MAT"      "MAP"        "X13C"
> "X15N"    "LAT"
>
>> mix.model1=lmer(X13C~ MAT:MAP:LAT + (1|SITE/SPECIES), method ="ML",
> data=ds)
>> mix.model2=lmer(X13C ~ MAT:MAP + (1|SITE/SPECIES), method ="ML",  
>> data=ds)
>> mix.model3=lmer(X13C ~ MAP:LAT + (1|SITE/SPECIES), method ="ML",  
>> data=ds)
>> mix.model4=lmer(X13C ~ MAT:LAT + (1|SITE/SPECIES), method ="ML",  
>> data=ds)
>> mix.model5=lmer(X13C ~ MAT + (1|SITE/SPECIES), method ="ML", data=ds)
>> mix.model6=lmer(X13C ~ MAP + (1|SITE/SPECIES), method ="ML", data=ds)
>> mix.model7=lmer(X13C ~ LAT + (1|SITE/SPECIES), method ="ML", data=ds)
>> mix.model8=lmer(X13C ~ (1|SITE/SPECIES), data=ds)
>>
> anova 
> (mix 
> .model1 
> ,mix 
> .model2 
> ,mix 
> .model3 
> ,mix.model4,mix.model5,mix.model6,mix.model7,mix.model8,data=ds)
>
>                       Df     AIC        BIC         logLik    Chisq  
> Chi
> Df   Pr(>Chisq)
> mix.model8.p  4  1024.53  1039.11  -508.26
> mix.model1.p  5  1025.65  1043.87  -507.82  0.8800      1     0.3482
> mix.model2.p  5  *1016.43*  1034.66  -503.22  9.2145      0      
> <2e-16 ***
> mix.model3.p  5  1022.63  1040.85  -506.31  0.0000      0     <2e-16  
> ***
> mix.model4.p  5  1023.09  1041.31  -506.54  0.0000      0     <2e-16  
> ***
> mix.model5.p  5  1023.25  1041.48  -506.62  0.0000      0     <2e-16  
> ***
> mix.model6.p  5  1025.80  1044.02  -507.90  0.0000      0     <2e-16  
> ***
> mix.model7.p  5  1025.32  1043.55  -507.66  0.4793      0     <2e-16  
> ***
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From A.Robinson at ms.unimelb.edu.au  Sun May 18 06:14:46 2008
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Sun, 18 May 2008 14:14:46 +1000
Subject: [R-sig-ME] Binomial GLMM vs GLM question (Ken Beath)
In-Reply-To: <m0tzgw4z1w.fsf@gmail.com>
References: <mailman.3.1210932001.31392.r-sig-mixed-models@r-project.org>
	<4BD78F8D-0191-427A-9AC8-52370C1CDE39@sheffield.ac.uk>
	<482DF433.5030901@ufl.edu>
	<20080516222454.GQ27037@ms.unimelb.edu.au>
	<m0tzgw4z1w.fsf@gmail.com>
Message-ID: <20080518041446.GZ27037@ms.unimelb.edu.au>

Hi Austin,

On Sat, May 17, 2008 at 01:31:55PM -0400, Austin Frank wrote:
> On Fri, May 16 2008, Andrew Robinson wrote:
> 
> > For example, if you make the effects random then you're effectively
> > marginalizing them, whereas if you make them fixed you're forced to
> > condition on them
> 
> Hello all!
> 
> I'm cherry picking this one line from a recent discussion because it's
> the most recent example of people discussing fixed and random effects in
> terms of conditioning and marginalization.  The use of this terminology
> on this list seems to have increased in the past year or so (or, more
> likely, I've just started noticing it), and it's time for me to confess
> that I'm not sure I understand it.
> 
> If we have a model
> 
> #v+
> y ~ 1 + x + (1 | z)
> #v-
> 
> the suggested correspondences between fixed effects and
> conditionalizing, and between random effects and marginalization suggest
> to me that at some point we are interested in
> 
> #v+
> \sum_{z} P(y | x, z)
> #v-
> 
> This is my guess at the correspondence suggested by the quote above, but
> it's based solely on the fact that I think I know what conditional
> probabilities and marginalization are.  It could be 100% off base.

> I guess I have four questions:
> 
> 1.  Is this the correct understanding of how fixed and random effects
>     translate into conditionalizing and marginalizing?

I think that you're close.  Actually the more general case is being
interested in 

P(y | x)

without necessarily having a specific strategy for getting rid of z -
the main options are to estimate it somehow (which, I suppose, quietly
conditions on it) or to integrate it out.  Often z appears within V,
let's say, which is the conditional covariance matrix of y.

y | X, Z ~ N ( X \beta, D Z D' + \Sigma)

> 2.  In mixed logit models, we are modeling probabilities (or, log odds
>     of probabilities) , so this specification maybe makes some sense to
>     me.  But how does it fit into a linear mixed model?

The same way. We're still interested in making inference on the
distribution of y conditional on x, it's just that the distribution is
normal. 

> 3.  What role does this probability play in fitting the model?

It depends on the fitting algorithm.  If it is maximum likelihood,
then the probability is used to construct the likelihood function.  If
the algorithm is penalized least squares, then the probability is not
really used at all, although it is arguably present in that certain
kinds of penalized least squares yield identical fixed estimates to
certain kinds of maximum likelihood approaches.

> 4.  Do the coefficients for fixed effects from the fitted model have an
>     interpretation in terms of the above probability model?

They are the parameter estimates that describe the nature of the
conditional relationship between x and y.

I hope that this helps,

Andrew

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From kjbeath at kagi.com  Sun May 18 10:24:28 2008
From: kjbeath at kagi.com (Ken Beath)
Date: Sun, 18 May 2008 18:24:28 +1000
Subject: [R-sig-ME] Binomial GLMM vs GLM question
In-Reply-To: <482F35C2.4010605@bu.edu>
References: <mailman.3.1210932001.31392.r-sig-mixed-models@r-project.org>
	<4BD78F8D-0191-427A-9AC8-52370C1CDE39@sheffield.ac.uk>
	<482DF433.5030901@ufl.edu>
	<174F3A38-C71A-49D8-BAE2-CD1DAA1267FF@kagi.com>
	<482F35C2.4010605@bu.edu>
Message-ID: <6EE378F5-2600-4D35-A19C-9BC8BC3D9F6E@kagi.com>

On 18/05/2008, at 5:45 AM, Justin Touchon wrote:

> Hi all,
> Thank you for all for you informative and helpful comments about my  
> dilemma. I've pasted below a summary table of egg survival at the  
> two ponds during the three years and the GLM output for a model  
> looking for interactions between pond, rainfall and year. Below that  
> is the output of a LMER model Ben suggested. Also, as Ben wondered  
> earlier, the data are highly overdispersed. To give a little  
> background, this wasn't an experiment but an observational study of  
> what was happening in nature. The two ponds were selected because  
> they are near my field site, no other reason. They differ in the  
> amount of canopy shade overhead, which in turn is clearly going to  
> affect egg desiccation (the primary source of mortality). Rainfall  
> did vary during the three years (it was much heavier in 2005 than in  
> 2003 or 2004). As a result, mortality was higher at Bridge Pond  
> (little shade) than at Ocelot Pond, and it varied between years.  
> These points are evident from the GLM anova table. All three  
> factors, significantly affect egg mortality, pond being the most  
> important. Rainfall varied across the three years, and there is a 3- 
> way interaction which indicates to me simply that the effects of  
> habitat (pond) and rainfall are not consistent across time. The  
> model estimates make sense (e.g. rainfall has a negative slope, the  
> estimate for Ocelot Pond is highly negative, etc.) In other words,  
> the GLM output does make biological sense given what we know about  
> the data and lends itself to fairly easy interpretation. Regarding  
> the LMER output, it seems the variance of both rain and pond is  
> obscenely huge. Is that a result of only have 2 ponds and 3 years?  
> The estimate for the rainfall effect is negative, like in the GLM,  
> which makes sense as well (as rain increase, mortality decreases).  
> Any opinions on where to go from here? Again, thank you all for you  
> helpful advice. I am very appreciative.
> -Justin
>

The model fit has got into problems, as Ben predicted. A really bad  
sign is the standard errors of the fixed effects are extreme. Also the  
lmer model doesn't allow for the slopes to vary, which from the glm  
they obviously do, which may be causing problems.

It may be possible to coax lmer into fitting the model by choosing  
starting values in roughly the right locations but it is probably  
optimistic.

I would strongly recommend checking whether a transform for rainfall  
is needed. If this isn't done correctly then individual observations  
may have excessive influence which may be causing the variation.

Ken

>
> Egg Survival
> Year Bridge Ocelot Total
> 2003 0.069 0.453 0.251
> 2004 0.115 0.429 0.272
> 2005 0.270 0.505 0.376
> Total 0.141 0.460 0.292
>
>
> > GLM.2 <- glm(tbl_mort ~ Pond *total_rainfall *Year ,  
> family=quasibinomial(logit), data=FieldData0305)
>
> > summary(GLM.2)
>
> Call:
> glm(formula = tbl_mort ~ Pond * total_rainfall * Year, family =  
> quasibinomial(logit),
> data = FieldData0305)
>
> Deviance Residuals:
> Min 1Q Median 3Q Max
> -17.965 -4.838 1.062 5.197 15.225
>
> Coefficients:
> Estimate Std. Error t value Pr(>|t|)
> (Intercept) 2.68318 0.47947 5.596 4.53e-08 ***
> Pond[T.Ocelot] -2.30872 0.53614 -4.306 2.18e-05 ***
> total_rainfall -0.11465 0.02333 -4.915 1.39e-06 ***
> Year[T.2004] -0.97218 0.63583 -1.529 0.127198
> Year[T.2005] -3.92557 0.76808 -5.111 5.38e-07 ***
> Pond[T.Ocelot]:total_rainfall 0.09799 0.02609 3.756 0.000204 ***
> Pond[T.Ocelot]:Year[T.2004] 0.48230 0.77189 0.625 0.532506
> Pond[T.Ocelot]:Year[T.2005] 2.15914 1.22853 1.757 0.079739 .
> total_rainfall:Year[T.2004] 0.08475 0.02717 3.120 0.001967 **
> total_rainfall:Year[T.2005] 0.12082 0.02440 4.952 1.16e-06 ***
> Pond[T.Ocelot]:total_rainfall:Year[T.2004] -0.05511 0.03585 -1.537  
> 0.125162
> Pond[T.Ocelot]:total_rainfall:Year[T.2005] -0.11371 0.02948 -3.857  
> 0.000137 ***
> ---
> Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> (Dispersion parameter for quasibinomial family taken to be 38.23861)
>
> Null deviance: 20762 on 349 degrees of freedom
> Residual deviance: 15252 on 338 degrees of freedom
> AIC: NA
>
> Number of Fisher Scoring iterations: 5
>
> > Anova(GLM.2, test="F")
> Anova Table (Type II tests)
>
> Response: tbl_mort
> SS Df F Pr(>F)
> Pond 1002.7 1 26.2229 5.119e-07 ***
> total_rainfall 238.2 1 6.2306 0.0130318 *
> Year 496.3 2 6.4894 0.0017157 **
> Pond:total_rainfall 101.7 1 2.6599 0.1038378
> Pond:Year 172.7 2 2.2587 0.1060579
> total_rainfall:Year 650.3 2 8.5037 0.0002493 ***
> Pond:total_rainfall:Year 704.8 2 9.2159 0.0001267 ***
> Residuals 12924.5 338
> ---
> Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
>
> > m1 <- lmer(tbl_mort~total_rainfall + (1|Year)+(1|Pond), family =  
> quasibinomial, data=FieldData0305)
>
> > summary(m1)
> Generalized linear mixed model fit using Laplace
> Formula: tbl_mort ~ total_rainfall + (1 | Year) + (1 | Pond)
> Data: FieldData0305
> Family: quasibinomial(logit link)
> AIC BIC logLik deviance
> 14657 14673 -7325 14649
> Random effects:
> Groups Name Variance Std.Dev.
> Year (Intercept) 2.0141e+15 44878595
> Pond (Intercept) 1.3427e+15 36643219
> Residual 8.8116e+16 296844003
> number of obs: 350, groups: Year, 3; Pond, 2
>
> Fixed effects:
> Estimate Std. Error t value
> (Intercept) 7.486e-01 5.736e+13 1.305e-14
> total_rainfall -2.316e-02 4.406e+11 -5.257e-14
>
> Correlation of Fixed Effects:
> (Intr)
> total_rnfll -0.956
>
>
>
>
>
>
>> On 17/05/2008, at 6:53 AM, Ben Bolker wrote:
>>
>> <snip>
>> >/
>> />/ | I think this is a good example of what seems a common problem  
>> for
>> />/ | people using mixed models - How to decide what are the  
>> random  />/ factors
>> />/ | and what are the fixed factors.
>> />/
>> />/ ~  I agree that this is difficult, and contentious (see e.g.
>> />/ Andrew Gelman, "Analysis of variance--why it is more important  
>> than
>> />/ ever," Annals of Statistics 33, no. 1 (2005): 1-53,
>> />/ doi:http://dx.doi.org/doi:10.1214/009053604000001048)
>> />/
>> /Available at
>> http://www.stat.columbia.edu/~gelman/research/published/AOS259.pdf <http://www.stat.columbia.edu/%7Egelman/research/published/AOS259.pdf 
>> >
>>
>> >/
>> />/ | In your study you have taken repeated measurements on the  
>> same  />/ ponds,
>> />/ | as such, observations from each pond across years are not  / 
>> >/ independent
>> />/ | (observations in pond 1 at t+1 will be correlated with  
>> observations
>> />/ | at t).  If you were only interested in the effect of rainfall  
>> on egg
>> />/ | survival I would suggest you use a mixed model with year and  
>> pond as
>> />/ | random effects (based on a similar eg in Crawley's R Book  
>> p605). In
>> />/ | this case I assume you have measurements on every pond in  
>> every year
>> />/ | and as such these random effects are crossed (not nested).
>> />/
>> />/ ~  (a) I would suggest that a mixed model is NOT going to work  
>> well
>> />/ in this case, even if year and pond are "philosophically"  
>> random  />/ effects
>> />/ (i.e., you don't really care about what happens in those specific
>> />/ ponds, and you may even have chosen them with a random-number  / 
>> >/ generator
>> />/ out of a list of all possible ponds -- although this is much less
>> />/ likely with years ...).  The technical problem is that estimating
>> />/ variances from 2 or 3 points is nasty.  This translates into
>> />/ inference/philosophical terms because these few points really
>> />/ don't give you the data to generalize about the population,  
>> even if
>> />/ you want to.  (I think one of the confusions is that in the  
>> classical
>> />/ method-of-moments world there's nothing that says you can't  
>> have 2
>> />/ denominator degrees of freedom -- your power will be terrible,  
>> but
>> />/ the expressions won't blow up on you [unless you get negative  
>> variance
>> />/ estimates ...])
>> />/ |
>> />/ | m1 <- lmer(mort~rainfall + (year|pond), family = binomial,  
>> data=
>> />/ | FieldData0305)
>> />/
>> />/ ~   (1|year)+(1|pond) might work OK, and be slightly more
>> />/ parsimonious (OR ponds nested within years, (1|year)+(1| 
>> pond:year), or
>> />/ vice versa -- and if you're not dead set on treating the  
>> random  />/ effects
>> />/ as "effects of year" and "effects of pond", but were willing  
>> to  />/ treat it
>> />/ as "effects of pond within year" that would buy you the  
>> flexibility
>> />/ to use some other package that wasn't so good at crossed
>> />/ effects.)
>> />/
>> />/
>> />/ | summary(m1)
>> />/ |  From the summary output you can assess the influence of the  
>> fixed
>> />/ | effect to see if the estimate for rainfall (slope estimate) is
>> />/ | different to zero.
>> />/ |
>> />/ | Even if the number of groups (years and ponds) is small it is  
>> still
>> />/ | better to take account of this group variation than ignore it  
>> (see
>> />/ | Gelman and Hill 200&.
>> />/
>> />/ ~  Yes, but ... what if all you can get out of the model is that
>> />/ the estimate is nearly zero?  If you go Bayesian instead you can
>> />/ deal with some problems by setting an informative prior [in  
>> theory
>> />/ setting a proper prior, no matter how weak, would generally solve
>> />/ the problem, but in reality I suspect that if the model is
>> />/ overparameterized you're going to have nasty technical  
>> difficulties
>> />/ even if the model is theoretically OK])
>> />/ ~  With respect to Andrew Gelman (I can't believe I'm saying  
>> this --
>> />/ sacrilege) but I think he's used to really big social-science  
>> data  />/ sets,
>> />/ where "leave stuff in when you're not sure" is more generally
>> />/ a good idea than it is in typical field ecology data sets, where
>> />/ the bias-variance tradeoff bites harder.  (At least there are 350
>> />/ data points here,
>> />/
>> />/ |  From this model you can also get a feeling for the between  
>> year and
>> />/ | between pond variation by looking at the random effects  
>> estimates  />/ and
>> />/ | variances. Obviously you will have some idea if you just plot  
>> the
>> />/ | means for each year and each pond.
>> />/
>> />/ ~  Only if the variance estimates don't suck.
>> />/
>> />/ | If you are also interested in understanding how egg survival  
>> differs
>> />/ | between ponds or between years and if this interacts with  
>> rainfall
>> />/ | then it become less straight forward.
>> />/ |
>> />/ | I would suggest that you try
>> />/ |
>> />/ | m2 <- lmer(mort~rainfall * year * pond + (year|pond), family =
>> />/ | binomial, data= FieldData0305)
>> />/ | summary(m2)
>> />/ |
>> />/ | In the summary you will have estimates for all three factors  
>> and
>> />/ | their interactions and you can ascertain if these are good
>> />/ | explanatory variables for egg survival.
>> />/
>> />/ ~   Isn't this overparameterized?  We have a fixed effect for
>> />/ each year:pond combination (and variation in the slopes of
>> />/ the effect with respect to rainfall), as well as a random-effect
>> />/ level for years and ponds?
>> />/
>> /
>> This does bring up the important point as to whether the effect of   
>> rainfall does vary within year and site. One advantage of the  
>> mixed  effects method for dealing with varying slopes is it gives a  
>> nice  population estimate. Unfortunately this is a lot of random  
>> effects for  not many groups.  It is looking very messy.
>>
>> I think with this sort of data, as in it has very few groups) the  
>> best  option is to start with the basics (probably always the best  
>> option).  Fit a separate model for each group and determine an  
>> appropriate  transform for rainfall. Do the models fit reasonably?  
>> Look at the  parameter estimates with 95% CI (plotting is a good  
>> idea) and see how  much variation there is, and there is nothing  
>> strange happening like  one unusual year-pond. Then decide whether  
>> the more complex models  will tell you anything more.
>>
>> Ken
>> >
>
> -- 
> Justin Touchon
> Doctoral Student
> Boston University
> Ecology, Behavior and Evolution
> http://people.bu.edu/jtouchon
>
>



From reinhold.kliegl at gmail.com  Sun May 18 12:35:41 2008
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Sun, 18 May 2008 12:35:41 +0200
Subject: [R-sig-ME] is multicollinearity of fixed effects resolved by
	random effects
In-Reply-To: <B49D721F-E539-48EF-99A7-B57300C9AEBD@anu.edu.au>
References: <a0d257780805171221o72c53ff1qe4111abc45cf3a6e@mail.gmail.com>
	<B49D721F-E539-48EF-99A7-B57300C9AEBD@anu.edu.au>
Message-ID: <aefe4d0a0805180335k7ed2259fh271c51eaa6defb76@mail.gmail.com>

I am not sure about how 800 SPECIES and 24 SITEs relate to each other
in this email. The following proposal assumes thtat a given SPECIES is
observed at each or at least quite a few of the 24 sites (i.e., I
assume you have several, ideally up to 24 measures for each species).
If each species occurs at precisely one site and if you have only one
measure for each species at this site (i.e., if you have excatly 800
observations), then SPECIES is not be part of the model. So let's
assume you have several measures for each species.

First, treat site and species as (possibly partially) crossed random
effects.  Assuming that the species in site 1 and site 2 are pretty
much the same. The nesting would be required if species 1 is a
different beast in site 1 and in site 2. Think of a student 1 in class
1 and student 1 in class2; they are likely different persons. However,
if you observe student 1 in a music class and the same student 1 in a
math class; they are obviously the same person. In lmer, if you give
units the same identification it will assume they are the same unit.

Second, definitely center your predictors prior to any analyses. Here
you need to think about the level at which you want to center and you
will need to read up on this. For starters, centering them on their
grand mean should not be wrong, but it may not be optimal. (This
becomes an issue especially if you want include covariates that
describe the sites, i.e., that are identical for all SPECIES observed
at a given SITE; actually I suspect that your three predictors are
such variables.)

Third, If collinearity is very strong, you may want to think of
combining your predictors into a single one or collaps two of them;
after all they seem to be getting at the same thing. See also John
Maindonald's suggestions on this topic. Definitely get a good idea
about how you predictors relate to the dependent variable. You may
also want to check whether high-order polynomials are likely required
to be in the fixed-effects part (e.g., quadratic trend for MAT, etc.).

mix.model1 <- lmer(X13C~ MAT+MAP+LAT + (1|SPECIES) + (1|SITE), method
="ML", data=ds)
mix.model2 <- lmer(X13C~ (MAT+MAP+LAT)^2 + (1|SPECIES) + (1|SITE),
method ="ML", data=ds)
and, possibly,
mix.model3 <- lmer(X13C~ MAT*MAP*LAT + (1|SPECIES) + (1|SITE), method
="ML", data=ds)

Further things:
After you feel happy with your fixed-effects part (or better: once you
developed a substantively and statistically defensible
representation), consider including (some of) them as varying slopes
into the random part of the model. I would start with those that have
the largest fixed effects;  e..g.

mix.model4 <- lmer(X13C~ MAT+MAP+LAT + (MAT|SPECIES) + (MAT|SITE),
method ="ML", data=ds)
or
mix.model5 <- lmer(X13C~ MAT+MAP+LAT + (MAT|SPECIES) + (1|SITE),
method ="ML", data=ds)
or
mix.model6 <- lmer(X13C~ MAT+MAP+LAT + (1|SPECIES) + (MAT|SITE),
method ="ML", data=ds)

etc.

Definitely check the distribution of the residuals of your final
model(s). You may need to think about a transformation of your
dependent variable.

One question for John Maindonald: Why would you include SPECIES as a
fixed effect? It leads to 799 parameters being estimated. Or am I
missing something here.

Reinhold Kliegl



On Sun, May 18, 2008 at 3:07 AM, John Maindonald
<john.maindonald at anu.edu.au> wrote:
> Don't you want MAT+MAP+LAT, possibly with first order
> interactions in also?  If you still find multicollinearity, look
> at the relationship between MAT, MAP and LAT, probably
> using regression.  If you still find multi-collinearity, you
> need to work out which variables or constructed variables
> are most meaningful to retain.
>
> Surely you should allow for a fixed effect of species.  So my
> guess would be:
>
> mix.model1 <- lmer(X13C~ MAT+MAP+LAT + SPECIES + (1|SITE/SPECIES), method
> ="ML", data=ds)
> or maybe
> mix.model1 <- lmer(X13C~ (MAT+MAP+LAT + SPECIES)^2 + (1|SITE/SPECIES),
> method ="ML", data=ds)
>
> But before you go too far, consider whether some species may
> show very consistent variation across sites, whereas others may
> be quite incognisant of sites; they're the tourists who live in
> expensive luxury hotels that are the same wherever they go!
> Fit fixed effect models for each species, then xyplot() to look at
> the pattern of change of parameter estimates across species.
>
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
>
>
> On 18 May 2008, at 5:21 AM, Jordan Mayor wrote:
>
>> Hello, I am currently using mixed models (lme4) to explain variability in
>> fungal isotope patterns in 800 fungal SPECIES across 24 SITES in the
>> world.
>> I have thus decided to nest the species within site as hierarchical
>> *random
>> effects*.  I am just trying to explain the variability in fungal isotopes
>> values not necessarily predict values of fungi from other areas of the
>> world.
>>
>> My *fixed effects* include mean annual temperature, mean annual
>> precipitation, and latitude.  Perhaps obviously, all three suffer from
>> strong multicollinearity problems.
>>
>> *My question is:*  Should I simply omit using fixed effects additively?
>>  In
>> other words, is it valid to simply use the fixed effects singly or as
>> interactions (see code below) or do the random effects take care of the
>> collinearity issue during adjustment of model error variance allowing me
>> to
>> compare full-factorial models instead?
>>
>> Thanks in advance to all those with advice or references.
>>
>> --
>> Jordan Mayor
>>
>> My code:
>>
>>> names(ds)
>>
>> [1] "STUDY"    "SPECIES"  "SITE"     "MAT"      "MAP"        "X13C"
>> "X15N"    "LAT"
>>
>>> mix.model1=lmer(X13C~ MAT:MAP:LAT + (1|SITE/SPECIES), method ="ML",
>>
>> data=ds)
>>>
>>> mix.model2=lmer(X13C ~ MAT:MAP + (1|SITE/SPECIES), method ="ML", data=ds)
>>> mix.model3=lmer(X13C ~ MAP:LAT + (1|SITE/SPECIES), method ="ML", data=ds)
>>> mix.model4=lmer(X13C ~ MAT:LAT + (1|SITE/SPECIES), method ="ML", data=ds)
>>> mix.model5=lmer(X13C ~ MAT + (1|SITE/SPECIES), method ="ML", data=ds)
>>> mix.model6=lmer(X13C ~ MAP + (1|SITE/SPECIES), method ="ML", data=ds)
>>> mix.model7=lmer(X13C ~ LAT + (1|SITE/SPECIES), method ="ML", data=ds)
>>> mix.model8=lmer(X13C ~ (1|SITE/SPECIES), data=ds)
>>>
>>
>> anova(mix.model1,mix.model2,mix.model3,mix.model4,mix.model5,mix.model6,mix.model7,mix.model8,data=ds)
>>
>>                      Df     AIC        BIC         logLik    Chisq Chi
>> Df   Pr(>Chisq)
>> mix.model8.p  4  1024.53  1039.11  -508.26
>> mix.model1.p  5  1025.65  1043.87  -507.82  0.8800      1     0.3482
>> mix.model2.p  5  *1016.43*  1034.66  -503.22  9.2145      0     <2e-16 ***
>> mix.model3.p  5  1022.63  1040.85  -506.31  0.0000      0     <2e-16 ***
>> mix.model4.p  5  1023.09  1041.31  -506.54  0.0000      0     <2e-16 ***
>> mix.model5.p  5  1023.25  1041.48  -506.62  0.0000      0     <2e-16 ***
>> mix.model6.p  5  1025.80  1044.02  -507.90  0.0000      0     <2e-16 ***
>> mix.model7.p  5  1025.32  1043.55  -507.66  0.4793      0     <2e-16 ***
>>
>>        [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From jtouchon at bu.edu  Sat May 17 21:45:06 2008
From: jtouchon at bu.edu (Justin Touchon)
Date: Sat, 17 May 2008 15:45:06 -0400
Subject: [R-sig-ME] Binomial GLMM vs GLM question
In-Reply-To: <174F3A38-C71A-49D8-BAE2-CD1DAA1267FF@kagi.com>
References: <mailman.3.1210932001.31392.r-sig-mixed-models@r-project.org>
	<4BD78F8D-0191-427A-9AC8-52370C1CDE39@sheffield.ac.uk>
	<482DF433.5030901@ufl.edu>
	<174F3A38-C71A-49D8-BAE2-CD1DAA1267FF@kagi.com>
Message-ID: <482F35C2.4010605@bu.edu>

Hi all,
Thank you for all for you informative and helpful comments about my 
dilemma. I've pasted below a summary table of egg survival at the two 
ponds during the three years and the GLM output for a model looking for 
interactions between pond, rainfall and year. Below that is the output 
of a LMER model Ben suggested. Also, as Ben wondered earlier, the data 
are highly overdispersed. To give a little background, this wasn't an 
experiment but an observational study of what was happening in nature. 
The two ponds were selected because they are near my field site, no 
other reason. They differ in the amount of canopy shade overhead, which 
in turn is clearly going to affect egg desiccation (the primary source 
of mortality). Rainfall did vary during the three years (it was much 
heavier in 2005 than in 2003 or 2004). As a result, mortality was higher 
at Bridge Pond (little shade) than at Ocelot Pond, and it varied between 
years. These points are evident from the GLM anova table. All three 
factors, significantly affect egg mortality, pond being the most 
important. Rainfall varied across the three years, and there is a 3-way 
interaction which indicates to me simply that the effects of habitat 
(pond) and rainfall are not consistent across time. The model estimates 
make sense (e.g. rainfall has a negative slope, the estimate for Ocelot 
Pond is highly negative, etc.) In other words, the GLM output does make 
biological sense given what we know about the data and lends itself to 
fairly easy interpretation. Regarding the LMER output, it seems the 
variance of both rain and pond is obscenely huge. Is that a result of 
only have 2 ponds and 3 years? The estimate for the rainfall effect is 
negative, like in the GLM, which makes sense as well (as rain increase, 
mortality decreases). Any opinions on where to go from here? Again, 
thank you all for you helpful advice. I am very appreciative.
-Justin


Egg Survival
Year Bridge Ocelot Total
2003 0.069 0.453 0.251
2004 0.115 0.429 0.272
2005 0.270 0.505 0.376
Total 0.141 0.460 0.292


 > GLM.2 <- glm(tbl_mort ~ Pond *total_rainfall *Year , 
family=quasibinomial(logit), data=FieldData0305)

 > summary(GLM.2)

Call:
glm(formula = tbl_mort ~ Pond * total_rainfall * Year, family = 
quasibinomial(logit),
data = FieldData0305)

Deviance Residuals:
Min 1Q Median 3Q Max
-17.965 -4.838 1.062 5.197 15.225

Coefficients:
Estimate Std. Error t value Pr(>|t|)
(Intercept) 2.68318 0.47947 5.596 4.53e-08 ***
Pond[T.Ocelot] -2.30872 0.53614 -4.306 2.18e-05 ***
total_rainfall -0.11465 0.02333 -4.915 1.39e-06 ***
Year[T.2004] -0.97218 0.63583 -1.529 0.127198
Year[T.2005] -3.92557 0.76808 -5.111 5.38e-07 ***
Pond[T.Ocelot]:total_rainfall 0.09799 0.02609 3.756 0.000204 ***
Pond[T.Ocelot]:Year[T.2004] 0.48230 0.77189 0.625 0.532506
Pond[T.Ocelot]:Year[T.2005] 2.15914 1.22853 1.757 0.079739 .
total_rainfall:Year[T.2004] 0.08475 0.02717 3.120 0.001967 **
total_rainfall:Year[T.2005] 0.12082 0.02440 4.952 1.16e-06 ***
Pond[T.Ocelot]:total_rainfall:Year[T.2004] -0.05511 0.03585 -1.537 0.125162
Pond[T.Ocelot]:total_rainfall:Year[T.2005] -0.11371 0.02948 -3.857 
0.000137 ***
---
Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

(Dispersion parameter for quasibinomial family taken to be 38.23861)

Null deviance: 20762 on 349 degrees of freedom
Residual deviance: 15252 on 338 degrees of freedom
AIC: NA

Number of Fisher Scoring iterations: 5

 > Anova(GLM.2, test="F")
Anova Table (Type II tests)

Response: tbl_mort
SS Df F Pr(>F)
Pond 1002.7 1 26.2229 5.119e-07 ***
total_rainfall 238.2 1 6.2306 0.0130318 *
Year 496.3 2 6.4894 0.0017157 **
Pond:total_rainfall 101.7 1 2.6599 0.1038378
Pond:Year 172.7 2 2.2587 0.1060579
total_rainfall:Year 650.3 2 8.5037 0.0002493 ***
Pond:total_rainfall:Year 704.8 2 9.2159 0.0001267 ***
Residuals 12924.5 338
---
Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1


 > m1 <- lmer(tbl_mort~total_rainfall + (1|Year)+(1|Pond), family = 
quasibinomial, data=FieldData0305)

 > summary(m1)
Generalized linear mixed model fit using Laplace
Formula: tbl_mort ~ total_rainfall + (1 | Year) + (1 | Pond)
Data: FieldData0305
Family: quasibinomial(logit link)
AIC BIC logLik deviance
14657 14673 -7325 14649
Random effects:
Groups Name Variance Std.Dev.
Year (Intercept) 2.0141e+15 44878595
Pond (Intercept) 1.3427e+15 36643219
Residual 8.8116e+16 296844003
number of obs: 350, groups: Year, 3; Pond, 2

Fixed effects:
Estimate Std. Error t value
(Intercept) 7.486e-01 5.736e+13 1.305e-14
total_rainfall -2.316e-02 4.406e+11 -5.257e-14

Correlation of Fixed Effects:
(Intr)
total_rnfll -0.956






> On 17/05/2008, at 6:53 AM, Ben Bolker wrote:
>
> <snip>
> >/
> />/ | I think this is a good example of what seems a common problem for
> />/ | people using mixed models - How to decide what are the random  
> />/ factors
> />/ | and what are the fixed factors.
> />/
> />/ ~  I agree that this is difficult, and contentious (see e.g.
> />/ Andrew Gelman, "Analysis of variance--why it is more important than
> />/ ever," Annals of Statistics 33, no. 1 (2005): 1-53,
> />/ doi:http://dx.doi.org/doi:10.1214/009053604000001048)
> />/
> /Available at
> http://www.stat.columbia.edu/~gelman/research/published/AOS259.pdf <http://www.stat.columbia.edu/%7Egelman/research/published/AOS259.pdf>
>
> >/
> />/ | In your study you have taken repeated measurements on the same  
> />/ ponds,
> />/ | as such, observations from each pond across years are not  
> />/ independent
> />/ | (observations in pond 1 at t+1 will be correlated with observations
> />/ | at t).  If you were only interested in the effect of rainfall on egg
> />/ | survival I would suggest you use a mixed model with year and pond as
> />/ | random effects (based on a similar eg in Crawley's R Book p605). In
> />/ | this case I assume you have measurements on every pond in every year
> />/ | and as such these random effects are crossed (not nested).
> />/
> />/ ~  (a) I would suggest that a mixed model is NOT going to work well
> />/ in this case, even if year and pond are "philosophically" random  
> />/ effects
> />/ (i.e., you don't really care about what happens in those specific
> />/ ponds, and you may even have chosen them with a random-number  
> />/ generator
> />/ out of a list of all possible ponds -- although this is much less
> />/ likely with years ...).  The technical problem is that estimating
> />/ variances from 2 or 3 points is nasty.  This translates into
> />/ inference/philosophical terms because these few points really
> />/ don't give you the data to generalize about the population, even if
> />/ you want to.  (I think one of the confusions is that in the classical
> />/ method-of-moments world there's nothing that says you can't have 2
> />/ denominator degrees of freedom -- your power will be terrible, but
> />/ the expressions won't blow up on you [unless you get negative variance
> />/ estimates ...])
> />/ |
> />/ | m1 <- lmer(mort~rainfall + (year|pond), family = binomial, data=
> />/ | FieldData0305)
> />/
> />/ ~   (1|year)+(1|pond) might work OK, and be slightly more
> />/ parsimonious (OR ponds nested within years, (1|year)+(1|pond:year), or
> />/ vice versa -- and if you're not dead set on treating the random  
> />/ effects
> />/ as "effects of year" and "effects of pond", but were willing to  
> />/ treat it
> />/ as "effects of pond within year" that would buy you the flexibility
> />/ to use some other package that wasn't so good at crossed
> />/ effects.)
> />/
> />/
> />/ | summary(m1)
> />/ |  From the summary output you can assess the influence of the fixed
> />/ | effect to see if the estimate for rainfall (slope estimate) is
> />/ | different to zero.
> />/ |
> />/ | Even if the number of groups (years and ponds) is small it is still
> />/ | better to take account of this group variation than ignore it (see
> />/ | Gelman and Hill 200&.
> />/
> />/ ~  Yes, but ... what if all you can get out of the model is that
> />/ the estimate is nearly zero?  If you go Bayesian instead you can
> />/ deal with some problems by setting an informative prior [in theory
> />/ setting a proper prior, no matter how weak, would generally solve
> />/ the problem, but in reality I suspect that if the model is
> />/ overparameterized you're going to have nasty technical difficulties
> />/ even if the model is theoretically OK])
> />/ ~  With respect to Andrew Gelman (I can't believe I'm saying this --
> />/ sacrilege) but I think he's used to really big social-science data  
> />/ sets,
> />/ where "leave stuff in when you're not sure" is more generally
> />/ a good idea than it is in typical field ecology data sets, where
> />/ the bias-variance tradeoff bites harder.  (At least there are 350
> />/ data points here,
> />/
> />/ |  From this model you can also get a feeling for the between year and
> />/ | between pond variation by looking at the random effects estimates  
> />/ and
> />/ | variances. Obviously you will have some idea if you just plot the
> />/ | means for each year and each pond.
> />/
> />/ ~  Only if the variance estimates don't suck.
> />/
> />/ | If you are also interested in understanding how egg survival differs
> />/ | between ponds or between years and if this interacts with rainfall
> />/ | then it become less straight forward.
> />/ |
> />/ | I would suggest that you try
> />/ |
> />/ | m2 <- lmer(mort~rainfall * year * pond + (year|pond), family =
> />/ | binomial, data= FieldData0305)
> />/ | summary(m2)
> />/ |
> />/ | In the summary you will have estimates for all three factors and
> />/ | their interactions and you can ascertain if these are good
> />/ | explanatory variables for egg survival.
> />/
> />/ ~   Isn't this overparameterized?  We have a fixed effect for
> />/ each year:pond combination (and variation in the slopes of
> />/ the effect with respect to rainfall), as well as a random-effect
> />/ level for years and ponds?
> />/
> /
> This does bring up the important point as to whether the effect of  
> rainfall does vary within year and site. One advantage of the mixed  
> effects method for dealing with varying slopes is it gives a nice  
> population estimate. Unfortunately this is a lot of random effects for  
> not many groups.  It is looking very messy.
>
> I think with this sort of data, as in it has very few groups) the best  
> option is to start with the basics (probably always the best option).  
> Fit a separate model for each group and determine an appropriate  
> transform for rainfall. Do the models fit reasonably? Look at the  
> parameter estimates with 95% CI (plotting is a good idea) and see how  
> much variation there is, and there is nothing strange happening like  
> one unusual year-pond. Then decide whether the more complex models  
> will tell you anything more.
>
> Ken
> >

-- 
Justin Touchon
Doctoral Student
Boston University
Ecology, Behavior and Evolution
http://people.bu.edu/jtouchon



From bates at stat.wisc.edu  Sun May 18 17:45:46 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sun, 18 May 2008 10:45:46 -0500
Subject: [R-sig-ME] is multicollinearity of fixed effects resolved by
	random effects
In-Reply-To: <aefe4d0a0805180335k7ed2259fh271c51eaa6defb76@mail.gmail.com>
References: <a0d257780805171221o72c53ff1qe4111abc45cf3a6e@mail.gmail.com>
	<B49D721F-E539-48EF-99A7-B57300C9AEBD@anu.edu.au>
	<aefe4d0a0805180335k7ed2259fh271c51eaa6defb76@mail.gmail.com>
Message-ID: <40e66e0b0805180845t7f3739a4m4b94f82dfb8c1d36@mail.gmail.com>

On Sun, May 18, 2008 at 5:35 AM, Reinhold Kliegl
<reinhold.kliegl at gmail.com> wrote:
> I am not sure about how 800 SPECIES and 24 SITEs relate to each other
> in this email. The following proposal assumes thtat a given SPECIES is
> observed at each or at least quite a few of the 24 sites (i.e., I
> assume you have several, ideally up to 24 measures for each species).
> If each species occurs at precisely one site and if you have only one
> measure for each species at this site (i.e., if you have excatly 800
> observations), then SPECIES is not be part of the model. So let's
> assume you have several measures for each species.
>
> First, treat site and species as (possibly partially) crossed random
> effects.  Assuming that the species in site 1 and site 2 are pretty
> much the same. The nesting would be required if species 1 is a
> different beast in site 1 and in site 2. Think of a student 1 in class
> 1 and student 1 in class2; they are likely different persons. However,
> if you observe student 1 in a music class and the same student 1 in a
> math class; they are obviously the same person. In lmer, if you give
> units the same identification it will assume they are the same unit.
>
> Second, definitely center your predictors prior to any analyses. Here
> you need to think about the level at which you want to center and you
> will need to read up on this. For starters, centering them on their
> grand mean should not be wrong, but it may not be optimal. (This
> becomes an issue especially if you want include covariates that
> describe the sites, i.e., that are identical for all SPECIES observed
> at a given SITE; actually I suspect that your three predictors are
> such variables.)
>
> Third, If collinearity is very strong, you may want to think of
> combining your predictors into a single one or collaps two of them;
> after all they seem to be getting at the same thing. See also John
> Maindonald's suggestions on this topic. Definitely get a good idea
> about how you predictors relate to the dependent variable. You may
> also want to check whether high-order polynomials are likely required
> to be in the fixed-effects part (e.g., quadratic trend for MAT, etc.).
>
> mix.model1 <- lmer(X13C~ MAT+MAP+LAT + (1|SPECIES) + (1|SITE), method
> ="ML", data=ds)
> mix.model2 <- lmer(X13C~ (MAT+MAP+LAT)^2 + (1|SPECIES) + (1|SITE),
> method ="ML", data=ds)
> and, possibly,
> mix.model3 <- lmer(X13C~ MAT*MAP*LAT + (1|SPECIES) + (1|SITE), method
> ="ML", data=ds)
>
> Further things:
> After you feel happy with your fixed-effects part (or better: once you
> developed a substantively and statistically defensible
> representation), consider including (some of) them as varying slopes
> into the random part of the model. I would start with those that have
> the largest fixed effects;  e..g.
>
> mix.model4 <- lmer(X13C~ MAT+MAP+LAT + (MAT|SPECIES) + (MAT|SITE),
> method ="ML", data=ds)
> or
> mix.model5 <- lmer(X13C~ MAT+MAP+LAT + (MAT|SPECIES) + (1|SITE),
> method ="ML", data=ds)
> or
> mix.model6 <- lmer(X13C~ MAT+MAP+LAT + (1|SPECIES) + (MAT|SITE),
> method ="ML", data=ds)
>
> etc.
>
> Definitely check the distribution of the residuals of your final
> model(s). You may need to think about a transformation of your
> dependent variable.
>
> One question for John Maindonald: Why would you include SPECIES as a
> fixed effect? It leads to 799 parameters being estimated. Or am I
> missing something here.

I was thinking the same thing.  The total number of observations
wasn't stated in the original message and I think that would be
important in deciding exactly how to go about modeling the data.   If
Jordan could make the data available on a web site as a text file or a
saved R data object I think it would help focus the discussion.  If
that is not possible I would like to see the output of

table(table(ds$SPECIES))  # frequency table of number of observations
per species
xtabs(~ SITE, ds)             # table of number of observations per site

Also, I assume that LAT, MAT and MAP do not change within SITE so
there be at most 24 unique values for those covariates.  It might be
interesting to look at scatterplots, perhaps with just smoother lines
and not the points, if there would be a considerable amount of
overplotting.  That is

library(lattice)
xyplot(X13C ~ MAP, ds, type = c("g", "smooth"))  # repeat for MAT and LAT

Speculating in advance of seeing the data, which Sherlock Holmes
characterized as a "capital mistake", I would be inclined to start
with random effects of the form
   (1|SPECIES) + (1|SITE)
or
   (1|SPECIES/SITE)
which expands to
   (1|SPECIES) + (1|SITE:SPECIES)

It seems more likely to me that I would want random effects for the
800 species than for the 24 sites but I am committing the "capital
mistake" and will not speculate further.

> On Sun, May 18, 2008 at 3:07 AM, John Maindonald
> <john.maindonald at anu.edu.au> wrote:
>> Don't you want MAT+MAP+LAT, possibly with first order
>> interactions in also?  If you still find multicollinearity, look
>> at the relationship between MAT, MAP and LAT, probably
>> using regression.  If you still find multi-collinearity, you
>> need to work out which variables or constructed variables
>> are most meaningful to retain.
>>
>> Surely you should allow for a fixed effect of species.  So my
>> guess would be:
>>
>> mix.model1 <- lmer(X13C~ MAT+MAP+LAT + SPECIES + (1|SITE/SPECIES), method
>> ="ML", data=ds)
>> or maybe
>> mix.model1 <- lmer(X13C~ (MAT+MAP+LAT + SPECIES)^2 + (1|SITE/SPECIES),
>> method ="ML", data=ds)
>>
>> But before you go too far, consider whether some species may
>> show very consistent variation across sites, whereas others may
>> be quite incognisant of sites; they're the tourists who live in
>> expensive luxury hotels that are the same wherever they go!
>> Fit fixed effect models for each species, then xyplot() to look at
>> the pattern of change of parameter estimates across species.
>>
>> John Maindonald             email: john.maindonald at anu.edu.au
>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>> Centre for Mathematics & Its Applications, Room 1194,
>> John Dedman Mathematical Sciences Building (Building 27)
>> Australian National University, Canberra ACT 0200.
>>
>>
>> On 18 May 2008, at 5:21 AM, Jordan Mayor wrote:
>>
>>> Hello, I am currently using mixed models (lme4) to explain variability in
>>> fungal isotope patterns in 800 fungal SPECIES across 24 SITES in the
>>> world.
>>> I have thus decided to nest the species within site as hierarchical
>>> *random
>>> effects*.  I am just trying to explain the variability in fungal isotopes
>>> values not necessarily predict values of fungi from other areas of the
>>> world.
>>>
>>> My *fixed effects* include mean annual temperature, mean annual
>>> precipitation, and latitude.  Perhaps obviously, all three suffer from
>>> strong multicollinearity problems.
>>>
>>> *My question is:*  Should I simply omit using fixed effects additively?
>>>  In
>>> other words, is it valid to simply use the fixed effects singly or as
>>> interactions (see code below) or do the random effects take care of the
>>> collinearity issue during adjustment of model error variance allowing me
>>> to
>>> compare full-factorial models instead?
>>>
>>> Thanks in advance to all those with advice or references.
>>>
>>> --
>>> Jordan Mayor
>>>
>>> My code:
>>>
>>>> names(ds)
>>>
>>> [1] "STUDY"    "SPECIES"  "SITE"     "MAT"      "MAP"        "X13C"
>>> "X15N"    "LAT"
>>>
>>>> mix.model1=lmer(X13C~ MAT:MAP:LAT + (1|SITE/SPECIES), method ="ML",
>>>
>>> data=ds)
>>>>
>>>> mix.model2=lmer(X13C ~ MAT:MAP + (1|SITE/SPECIES), method ="ML", data=ds)
>>>> mix.model3=lmer(X13C ~ MAP:LAT + (1|SITE/SPECIES), method ="ML", data=ds)
>>>> mix.model4=lmer(X13C ~ MAT:LAT + (1|SITE/SPECIES), method ="ML", data=ds)
>>>> mix.model5=lmer(X13C ~ MAT + (1|SITE/SPECIES), method ="ML", data=ds)
>>>> mix.model6=lmer(X13C ~ MAP + (1|SITE/SPECIES), method ="ML", data=ds)
>>>> mix.model7=lmer(X13C ~ LAT + (1|SITE/SPECIES), method ="ML", data=ds)
>>>> mix.model8=lmer(X13C ~ (1|SITE/SPECIES), data=ds)
>>>>
>>>
>>> anova(mix.model1,mix.model2,mix.model3,mix.model4,mix.model5,mix.model6,mix.model7,mix.model8,data=ds)
>>>
>>>                      Df     AIC        BIC         logLik    Chisq Chi
>>> Df   Pr(>Chisq)
>>> mix.model8.p  4  1024.53  1039.11  -508.26
>>> mix.model1.p  5  1025.65  1043.87  -507.82  0.8800      1     0.3482
>>> mix.model2.p  5  *1016.43*  1034.66  -503.22  9.2145      0     <2e-16 ***
>>> mix.model3.p  5  1022.63  1040.85  -506.31  0.0000      0     <2e-16 ***
>>> mix.model4.p  5  1023.09  1041.31  -506.54  0.0000      0     <2e-16 ***
>>> mix.model5.p  5  1023.25  1041.48  -506.62  0.0000      0     <2e-16 ***
>>> mix.model6.p  5  1025.80  1044.02  -507.90  0.0000      0     <2e-16 ***
>>> mix.model7.p  5  1025.32  1043.55  -507.66  0.4793      0     <2e-16 ***
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From clavulina at gmail.com  Sun May 18 20:04:48 2008
From: clavulina at gmail.com (Jordan Mayor)
Date: Sun, 18 May 2008 14:04:48 -0400
Subject: [R-sig-ME] is multicollinearity of fixed effects resolved by
	random effects
In-Reply-To: <40e66e0b0805180845t7f3739a4m4b94f82dfb8c1d36@mail.gmail.com>
References: <a0d257780805171221o72c53ff1qe4111abc45cf3a6e@mail.gmail.com>
	<B49D721F-E539-48EF-99A7-B57300C9AEBD@anu.edu.au>
	<aefe4d0a0805180335k7ed2259fh271c51eaa6defb76@mail.gmail.com>
	<40e66e0b0805180845t7f3739a4m4b94f82dfb8c1d36@mail.gmail.com>
Message-ID: <a0d257780805181104u4f10c443h1dc54552612b2e9b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080518/bbbde5e0/attachment.pl>

From John.Maindonald at anu.edu.au  Mon May 19 02:02:09 2008
From: John.Maindonald at anu.edu.au (John Maindonald)
Date: Mon, 19 May 2008 10:02:09 +1000
Subject: [R-sig-ME] is multicollinearity of fixed effects resolved by
	random effects
In-Reply-To: <a0d257780805181104u4f10c443h1dc54552612b2e9b@mail.gmail.com>
References: <a0d257780805171221o72c53ff1qe4111abc45cf3a6e@mail.gmail.com>
	<B49D721F-E539-48EF-99A7-B57300C9AEBD@anu.edu.au>
	<aefe4d0a0805180335k7ed2259fh271c51eaa6defb76@mail.gmail.com>
	<40e66e0b0805180845t7f3739a4m4b94f82dfb8c1d36@mail.gmail.com>
	<a0d257780805181104u4f10c443h1dc54552612b2e9b@mail.gmail.com>
Message-ID: <FABF6E26-3508-4347-A7A8-149193887149@anu.edu.au>

I think grouping them into families is a very good idea.
This makes use of prior insight, reduces the number of
parameters to an extent that it becomes more reasonable
to think about fixed effects, and you can look for individual
species that stray from the path laid out for them by their
families.  For the fixed effects analyses that I suggested,
you might do these by families.

Conceptually, there are taxonomic factors that surely
function, no doubt in interaction with location variables,
as fixed effects.  I consider that one ought to start by thinking
of them as fixed effects, unless it can be demonstrated that
data are indistinguishable from random variation.

Maybe however those effects operate more as the level of
genera or families than at the level of species.  Responding
to this point may be a useful aim for the study.

John.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


On 19 May 2008, at 4:04 AM, Jordan Mayor wrote:

> Thank you JM, RK, and DB for your thoughtful responses to my  
> questions.  I am working on posting the file on the web and will  
> respond as soon as it is publicly available - (I could email it  
> direct to those concerned as well).  Until then here is the output  
> requested by DB and RK as well as more information regarding sites,  
> species, and the data:
>
> >ds=d[d$TYPE=="s",] #separates into just sap fungi as used in the  
> example below
> >dm=d[d$TYPE=="m",] #separates into just myc fungi (treated as  
> distinct populations in my analyses)
>
> > table(table(ds$SPECIES))
>
>     0      1    2   3   5   6
> 393 161  45   7   1   1
> # As seen all species are not present at all the sites - this is  
> partly why I thought to nest SPECIES within SITE.  The sites range  
> widely from boreal tundra, to temperate California, to tropical  
> forests of Borneo and Guyana.  Most fungi are not so cosmopolitan as  
> to even potentially be present everywhere - let alone be collected  
> during brief collecting forays.  One site (pine forest in CA) didn't  
> even list  fungal names.  All fungi were listed as mycorrhizal (m),  
> saprotrophic (s), or of unknown ecological roles (unk).  Most of the  
> genera (or families) are present at all sites but that biologically  
> coarseness concerns me.  If, as pointed out by RK the ideal  
> situation would be every species present at every site then perhaps  
> creating a new column containing families or genera will move the  
> dataset toward that direction.
>
> > xtabs(~SITE,ds)
> SITE
>                              Aheden                             
> Aheden 2
>                                    
> 4                                   0
>    Ashiu (temp deciduous broadleaf)        Betsele
>                                   
> 21                                   0
>                      Breuil, France                       Chiba
>                                   
> 14                                   6
>                                   d                              
> Flakaliden
>                                   
> 23                                   0
>                 Glacier Bay, Alaska                Guyana
>                                   4                                   
> 20
>                                   h                     heath  
> tundra, subarctic Sweden
>                                   
> 38                                   4
>                           Kagoshima                        
> Kulbacksliden
>                                    
> 1                                   0
>                               Kyoto                        Lamar  
> Haines
>                                  26                                   
> 13
>           Lambir (lowland tropical)               Miyajima
>                                   
> 14                                   1
>                            Norikura                        Norrliden
>                                    
> 3                                   0
>                             Okinawa       Ontake (subalpine  
> coniferous)
>                                    
> 0                                   8
>                               Oodai                  pine forests in  
> CA
>                                   2                                   
> 25
>                           Shirahama                     nowbowl
>                                   2                                   
> 13
>                   Spruce plantation                   Stadsskogen
>                                  17                                   
> 13
>                         Svartberget                     Tanigawa
>                                    
> 0                                   6
> tussock tundra near Toolik Lake, AK      Vilan
>                                    
> 5                                   0
>                         Woods Creek
>                                  25                     # the zeros  
> here are because some sites have no X13C data - only X15N
>
> I did try running models with centered predictors, as suggested by  
> RK - see below.  I found that the AIC scores were much larger  
> however when the predictors were centered using my method.  I  
> centered by taking the mean of mycorrhizal and saprotrophic fungal  
> groups at each site - then I subtracted each (m) or (s) fungus from  
> those same group means within each site.  Because the (m) and (s)  
> fungi have unique sources of carbon, and nitrogen and these are  
> reflected in their isotope values (X13C, X15N), I deemed this  
> centering level to be appropriatein order to preserve the magnitude  
> of difference between the groups.
>
> > mix.model1  # Raw isotope values used
> Linear mixed model fit by maximum likelihood
> Formula: X13C ~ MAT + MAP + LAT + (1 | SPECIES) + (1 | SITE)
>    Data: ds
>   AIC   BIC    logLik     deviance  REMLdev
>  1016 1041 -500.9     1002         1031
> Random effects:
>  Groups   Name        Variance Std.Dev.
>  SPECIES  (Intercept) 0.62149  0.78835
>  SITE     (Intercept) 0.34885  0.59063
>  Residual             1.28911  1.13539
> Number of obs: 283, groups: SPECIES, 215; SITE, 24
>
> Fixed effects:
>               Estimate Std. Error t value
> (Intercept) -2.207e+01  1.121e+00 -19.695
> MAT         -6.418e-02  3.833e-02  -1.675
> MAP          3.137e-05  2.100e-04   0.149
> LAT         -8.690e-03  1.778e-02  -0.489
>
> Correlation of Fixed Effects:
>           (Intr)       MAT     MAP
> MAT  -0.707
> MAP  -0.401  -0.247
> LAT   -0.959  0.692   0.272
>
> > mix.model1a # Group centered within each site
> Linear mixed model fit by maximum likelihood
> Formula: STND_13c ~ MAT + MAP + LAT + (1 | SPECIES) + (1 | SITE)
>    Data: ds
>   AIC   BIC    logLik     deviance  REMLdev
>  2623 2649  -1305     2609         2620
> Random effects:
>  Groups   Name        Variance Std.Dev.
>  SPECIES  (Intercept) 301.9720 17.3773
>  SITE     (Intercept)   5.1294  2.2648
>  Residual             327.3857 18.0938
> Number of obs: 283, groups: SPECIES, 215; SITE, 24
>
> Fixed effects:
>              Estimate Std. Error t value
> (Intercept) 3.463e+01  1.166e+01  2.9713
> MAT         3.899e-01  4.330e-01  0.9006
> MAP         2.543e-05  1.811e-03  0.0140
> LAT         3.235e-01  1.867e-01  1.7324
>
> Correlation of Fixed Effects:
>          (Intr)       MAT     MAP
> MAT -0.779
> MAP -0.230  -0.300
> LAT  -0.955   0.732   0.116
>
> > anova(mix.model1,mix.model1a)
> Data: ds
> Models:
> mix.model1: X13C ~ MAT + MAP + LAT + (1 | SPECIES) + (1 | SITE)
> mix.model1a: STND_13c ~ MAT + MAP + LAT + (1 | SPECIES) + (1 | SITE)
>                             Df      AIC         BIC          logLik   
> Chisq Chi Df  Pr(>Chisq)
> mix.model1.p    7      1015.85  1041.37  -500.93
> mix.model1a.p  7      2623.49  2649.00 -1304.74     0      0       <  
> 2.2e-16 ***
>
> # As seen above, the model using my centered values performed  
> poorly.  My interpretation is that the centering removed the very  
> variability associated with climate I am trying to predict!
>
> #In addition, I compared the other models mentioned by RK using the  
> raw isotope values:
>
> > anova(mix.model1,mix.model2,mix.model3)
> Data: ds
> Models:
> mix.model1: X13C ~ MAT + MAP + LAT + (1 | SPECIES) + (1 | SITE)
> mix.model2: X13C ~ (MAT + MAP + LAT)^2 + (1 | SPECIES) + (1 | SITE)
> mix.model3: X13C ~ MAT * MAP * LAT + (1 | SPECIES) + (1 | SITE)
>                          Df     AIC         BIC            
> logLik      Chisq    Chi Df   Pr(>Chisq)
> mix.model1.p  7     1015.85  1041.37    -500.93
> mix.model2.p 10    978.21    1014.66    -479.10   43.645       
> 3       1.796e-09 ***
> mix.model3.p 11    980.18    1020.28    -479.09   0.023         
> 1        0.8794
>
> # I have refrained from trying the models mentioned by DB in order  
> to protect his rights to not commit the "capital mistake" ;)  
> however, the three predictors (MAT, MAP, LAT) do indeed seem to  
> overplot - I will try to select only one perhaps in my final models.
>
> # Again - thank you all for your help on this.
>
> -- 
> Jordan Mayor, Ph.D. Candidate
> Ecosystem Dynamics Research Lab
> Department of Botany, University of Florida
> Gainesville, FL 32611



From s.blomberg1 at uq.edu.au  Mon May 19 02:33:01 2008
From: s.blomberg1 at uq.edu.au (Simon Blomberg)
Date: Mon, 19 May 2008 10:33:01 +1000
Subject: [R-sig-ME] is multicollinearity of fixed effects resolved
	by	random effects
In-Reply-To: <FABF6E26-3508-4347-A7A8-149193887149@anu.edu.au>
References: <a0d257780805171221o72c53ff1qe4111abc45cf3a6e@mail.gmail.com>
	<B49D721F-E539-48EF-99A7-B57300C9AEBD@anu.edu.au>
	<aefe4d0a0805180335k7ed2259fh271c51eaa6defb76@mail.gmail.com>
	<40e66e0b0805180845t7f3739a4m4b94f82dfb8c1d36@mail.gmail.com>
	<a0d257780805181104u4f10c443h1dc54552612b2e9b@mail.gmail.com>
	<FABF6E26-3508-4347-A7A8-149193887149@anu.edu.au>
Message-ID: <1211157181.21008.27.camel@sib-sblomber01d.sib.uq.edu.au>

It is easy to incorporate phylogenetic correlations among species
("taxonomic factors"), using the ape package and lme. This is far better
than combining species into families or genera, as taxonomic heirarchies
are subjective, artificial, and rarely represent the true phylogeny. I
strongly disagree that taxonomic factors necessarily function as fixed
effects. The phylogeny represents what we think we know about the
covariance among species in all traits, measured or unmeasured. I can't
see how unmeasured traits or poorly-defined "taxonomic factors" can
possibly be included as fixed effects. If particular measured traits are
thought to be important in determining the mean response, they should be
included as fixed effects, but phylogenies are used to model the
covariance, not the mean. Unusual species should stand out by
examination of the normalized residuals.

My approach would be to ditch species as a factor altogether, and
incorporate phylogenetic effects through the correlation argument in lme
(or gls if there are no other random effects). This assumes there is an
available phylogeny for the fungi, which may not be true.

There is a very large literature on incorporating phylogeny into
analyses (to which I am afraid I am a small contributor).

Simon.

On Mon, 2008-05-19 at 10:02 +1000, John Maindonald wrote:
> I think grouping them into families is a very good idea.
> This makes use of prior insight, reduces the number of
> parameters to an extent that it becomes more reasonable
> to think about fixed effects, and you can look for individual
> species that stray from the path laid out for them by their
> families.  For the fixed effects analyses that I suggested,
> you might do these by families.
> 
> Conceptually, there are taxonomic factors that surely
> function, no doubt in interaction with location variables,
> as fixed effects.  I consider that one ought to start by thinking
> of them as fixed effects, unless it can be demonstrated that
> data are indistinguishable from random variation.
> 
> Maybe however those effects operate more as the level of
> genera or families than at the level of species.  Responding
> to this point may be a useful aim for the study.
> 
> John.
> 
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> 
> 
> On 19 May 2008, at 4:04 AM, Jordan Mayor wrote:
> 
> > Thank you JM, RK, and DB for your thoughtful responses to my  
> > questions.  I am working on posting the file on the web and will  
> > respond as soon as it is publicly available - (I could email it  
> > direct to those concerned as well).  Until then here is the output  
> > requested by DB and RK as well as more information regarding sites,  
> > species, and the data:
> >
> > >ds=d[d$TYPE=="s",] #separates into just sap fungi as used in the  
> > example below
> > >dm=d[d$TYPE=="m",] #separates into just myc fungi (treated as  
> > distinct populations in my analyses)
> >
> > > table(table(ds$SPECIES))
> >
> >     0      1    2   3   5   6
> > 393 161  45   7   1   1
> > # As seen all species are not present at all the sites - this is  
> > partly why I thought to nest SPECIES within SITE.  The sites range  
> > widely from boreal tundra, to temperate California, to tropical  
> > forests of Borneo and Guyana.  Most fungi are not so cosmopolitan as  
> > to even potentially be present everywhere - let alone be collected  
> > during brief collecting forays.  One site (pine forest in CA) didn't  
> > even list  fungal names.  All fungi were listed as mycorrhizal (m),  
> > saprotrophic (s), or of unknown ecological roles (unk).  Most of the  
> > genera (or families) are present at all sites but that biologically  
> > coarseness concerns me.  If, as pointed out by RK the ideal  
> > situation would be every species present at every site then perhaps  
> > creating a new column containing families or genera will move the  
> > dataset toward that direction.
> >
> > > xtabs(~SITE,ds)
> > SITE
> >                              Aheden                             
> > Aheden 2
> >                                    
> > 4                                   0
> >    Ashiu (temp deciduous broadleaf)        Betsele
> >                                   
> > 21                                   0
> >                      Breuil, France                       Chiba
> >                                   
> > 14                                   6
> >                                   d                              
> > Flakaliden
> >                                   
> > 23                                   0
> >                 Glacier Bay, Alaska                Guyana
> >                                   4                                   
> > 20
> >                                   h                     heath  
> > tundra, subarctic Sweden
> >                                   
> > 38                                   4
> >                           Kagoshima                        
> > Kulbacksliden
> >                                    
> > 1                                   0
> >                               Kyoto                        Lamar  
> > Haines
> >                                  26                                   
> > 13
> >           Lambir (lowland tropical)               Miyajima
> >                                   
> > 14                                   1
> >                            Norikura                        Norrliden
> >                                    
> > 3                                   0
> >                             Okinawa       Ontake (subalpine  
> > coniferous)
> >                                    
> > 0                                   8
> >                               Oodai                  pine forests in  
> > CA
> >                                   2                                   
> > 25
> >                           Shirahama                     nowbowl
> >                                   2                                   
> > 13
> >                   Spruce plantation                   Stadsskogen
> >                                  17                                   
> > 13
> >                         Svartberget                     Tanigawa
> >                                    
> > 0                                   6
> > tussock tundra near Toolik Lake, AK      Vilan
> >                                    
> > 5                                   0
> >                         Woods Creek
> >                                  25                     # the zeros  
> > here are because some sites have no X13C data - only X15N
> >
> > I did try running models with centered predictors, as suggested by  
> > RK - see below.  I found that the AIC scores were much larger  
> > however when the predictors were centered using my method.  I  
> > centered by taking the mean of mycorrhizal and saprotrophic fungal  
> > groups at each site - then I subtracted each (m) or (s) fungus from  
> > those same group means within each site.  Because the (m) and (s)  
> > fungi have unique sources of carbon, and nitrogen and these are  
> > reflected in their isotope values (X13C, X15N), I deemed this  
> > centering level to be appropriatein order to preserve the magnitude  
> > of difference between the groups.
> >
> > > mix.model1  # Raw isotope values used
> > Linear mixed model fit by maximum likelihood
> > Formula: X13C ~ MAT + MAP + LAT + (1 | SPECIES) + (1 | SITE)
> >    Data: ds
> >   AIC   BIC    logLik     deviance  REMLdev
> >  1016 1041 -500.9     1002         1031
> > Random effects:
> >  Groups   Name        Variance Std.Dev.
> >  SPECIES  (Intercept) 0.62149  0.78835
> >  SITE     (Intercept) 0.34885  0.59063
> >  Residual             1.28911  1.13539
> > Number of obs: 283, groups: SPECIES, 215; SITE, 24
> >
> > Fixed effects:
> >               Estimate Std. Error t value
> > (Intercept) -2.207e+01  1.121e+00 -19.695
> > MAT         -6.418e-02  3.833e-02  -1.675
> > MAP          3.137e-05  2.100e-04   0.149
> > LAT         -8.690e-03  1.778e-02  -0.489
> >
> > Correlation of Fixed Effects:
> >           (Intr)       MAT     MAP
> > MAT  -0.707
> > MAP  -0.401  -0.247
> > LAT   -0.959  0.692   0.272
> >
> > > mix.model1a # Group centered within each site
> > Linear mixed model fit by maximum likelihood
> > Formula: STND_13c ~ MAT + MAP + LAT + (1 | SPECIES) + (1 | SITE)
> >    Data: ds
> >   AIC   BIC    logLik     deviance  REMLdev
> >  2623 2649  -1305     2609         2620
> > Random effects:
> >  Groups   Name        Variance Std.Dev.
> >  SPECIES  (Intercept) 301.9720 17.3773
> >  SITE     (Intercept)   5.1294  2.2648
> >  Residual             327.3857 18.0938
> > Number of obs: 283, groups: SPECIES, 215; SITE, 24
> >
> > Fixed effects:
> >              Estimate Std. Error t value
> > (Intercept) 3.463e+01  1.166e+01  2.9713
> > MAT         3.899e-01  4.330e-01  0.9006
> > MAP         2.543e-05  1.811e-03  0.0140
> > LAT         3.235e-01  1.867e-01  1.7324
> >
> > Correlation of Fixed Effects:
> >          (Intr)       MAT     MAP
> > MAT -0.779
> > MAP -0.230  -0.300
> > LAT  -0.955   0.732   0.116
> >
> > > anova(mix.model1,mix.model1a)
> > Data: ds
> > Models:
> > mix.model1: X13C ~ MAT + MAP + LAT + (1 | SPECIES) + (1 | SITE)
> > mix.model1a: STND_13c ~ MAT + MAP + LAT + (1 | SPECIES) + (1 | SITE)
> >                             Df      AIC         BIC          logLik   
> > Chisq Chi Df  Pr(>Chisq)
> > mix.model1.p    7      1015.85  1041.37  -500.93
> > mix.model1a.p  7      2623.49  2649.00 -1304.74     0      0       <  
> > 2.2e-16 ***
> >
> > # As seen above, the model using my centered values performed  
> > poorly.  My interpretation is that the centering removed the very  
> > variability associated with climate I am trying to predict!
> >
> > #In addition, I compared the other models mentioned by RK using the  
> > raw isotope values:
> >
> > > anova(mix.model1,mix.model2,mix.model3)
> > Data: ds
> > Models:
> > mix.model1: X13C ~ MAT + MAP + LAT + (1 | SPECIES) + (1 | SITE)
> > mix.model2: X13C ~ (MAT + MAP + LAT)^2 + (1 | SPECIES) + (1 | SITE)
> > mix.model3: X13C ~ MAT * MAP * LAT + (1 | SPECIES) + (1 | SITE)
> >                          Df     AIC         BIC            
> > logLik      Chisq    Chi Df   Pr(>Chisq)
> > mix.model1.p  7     1015.85  1041.37    -500.93
> > mix.model2.p 10    978.21    1014.66    -479.10   43.645       
> > 3       1.796e-09 ***
> > mix.model3.p 11    980.18    1020.28    -479.09   0.023         
> > 1        0.8794
> >
> > # I have refrained from trying the models mentioned by DB in order  
> > to protect his rights to not commit the "capital mistake" ;)  
> > however, the three predictors (MAT, MAP, LAT) do indeed seem to  
> > overplot - I will try to select only one perhaps in my final models.
> >
> > # Again - thank you all for your help on this.
> >
> > -- 
> > Jordan Mayor, Ph.D. Candidate
> > Ecosystem Dynamics Research Lab
> > Department of Botany, University of Florida
> > Gainesville, FL 32611
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
-- 
Simon Blomberg, BSc (Hons), PhD, MAppStat. 
Lecturer and Consultant Statistician 
Faculty of Biological and Chemical Sciences 
The University of Queensland 
St. Lucia Queensland 4072 
Australia
Room 320 Goddard Building (8)
T: +61 7 3365 2506
http://www.uq.edu.au/~uqsblomb
email: S.Blomberg1_at_uq.edu.au

Policies:
1.  I will NOT analyse your data for you.
2.  Your deadline is your problem.

The combination of some data and an aching desire for 
an answer does not ensure that a reasonable answer can 
be extracted from a given body of data. - John Tukey.



From vasishth.shravan at gmail.com  Mon May 19 06:01:12 2008
From: vasishth.shravan at gmail.com (S Vasishth)
Date: Mon, 19 May 2008 06:01:12 +0200
Subject: [R-sig-ME] lme4 and nlme articles online
Message-ID: <fafe4cec0805182101q5e0bd7c3keb8def4b18cf6da0@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080519/e3631fe4/attachment.pl>

From clavulina at gmail.com  Tue May 20 01:55:43 2008
From: clavulina at gmail.com (Jordan Mayor)
Date: Mon, 19 May 2008 19:55:43 -0400
Subject: [R-sig-ME] is multicollinearity of fixed effects resolved by
	random effects
In-Reply-To: <1211157181.21008.27.camel@sib-sblomber01d.sib.uq.edu.au>
References: <a0d257780805171221o72c53ff1qe4111abc45cf3a6e@mail.gmail.com>
	<B49D721F-E539-48EF-99A7-B57300C9AEBD@anu.edu.au>
	<aefe4d0a0805180335k7ed2259fh271c51eaa6defb76@mail.gmail.com>
	<40e66e0b0805180845t7f3739a4m4b94f82dfb8c1d36@mail.gmail.com>
	<a0d257780805181104u4f10c443h1dc54552612b2e9b@mail.gmail.com>
	<FABF6E26-3508-4347-A7A8-149193887149@anu.edu.au>
	<1211157181.21008.27.camel@sib-sblomber01d.sib.uq.edu.au>
Message-ID: <a0d257780805191655r65cdd32dw706ace0abae63fd7@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080519/d69a1446/attachment.pl>

From reinhold.kliegl at gmail.com  Tue May 20 09:28:58 2008
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Tue, 20 May 2008 09:28:58 +0200
Subject: [R-sig-ME] is multicollinearity of fixed effects resolved by
	random effects
In-Reply-To: <a0d257780805191655r65cdd32dw706ace0abae63fd7@mail.gmail.com>
References: <a0d257780805171221o72c53ff1qe4111abc45cf3a6e@mail.gmail.com>
	<B49D721F-E539-48EF-99A7-B57300C9AEBD@anu.edu.au>
	<aefe4d0a0805180335k7ed2259fh271c51eaa6defb76@mail.gmail.com>
	<40e66e0b0805180845t7f3739a4m4b94f82dfb8c1d36@mail.gmail.com>
	<a0d257780805181104u4f10c443h1dc54552612b2e9b@mail.gmail.com>
	<FABF6E26-3508-4347-A7A8-149193887149@anu.edu.au>
	<1211157181.21008.27.camel@sib-sblomber01d.sib.uq.edu.au>
	<a0d257780805191655r65cdd32dw706ace0abae63fd7@mail.gmail.com>
Message-ID: <aefe4d0a0805200028v487aee05y229649c7d685bd15@mail.gmail.com>

Disclaimer: The following recommendation of a sequence of steps is not
the only one, perhaps not even the best one. It has worked for me in
the past.

First, I assume
- that centering was done with SCALE=FALSE,
- that you checked that linearity is defensible for the relation
between X13C and your three predictors (i.e., that you do not need
quadratic terms for some of them),
- that you used method = "ML" for comparison of models with identical
random but different fixed effect parts and you read up on the some of
the complications associated with such comparisons discussed on this
list. (You can use method="REML" for comparison of models differing
only in the random effects, again there are some qualifications.)

Second, I recommend that now you focus on the fixed-effects part. It
still is a bit random (pun intended).
> d.mod1: X13C ~ cMAT * cMAP * cLAT + TYPE + (1 | SITE) + (1 | SPECIES)
> d.mod1a: X13C ~ (cMAT+ cMAP+ cLAT)^2 + TYPE + (1 | SITE) + (1 | SPECIES)
If taking out the three.factor interaction does no harm, you may want
to remove the non-significant two-factor interactions. After those are
gone, you may want to check whether there is a non-significant main
effect that is not part of an interaction (cMAP?). Then you may want
to take this one out, too. Such a hiearchical dropping out of effects
may lead you to your current favorite:
X13C ~ cMAT * cLAT + TYPE + (1 | SITE) + (1 | SPECIES)
which expands to:
X13C ~ cMAT+ cLAT + cMAT:cLAT+ TYPE + (1 | SITE) + (1 | SPECIES)
Note there are often good arguments for keeping theoretically
interesting effects in the model, even if they are not significant!

Third, you should plot your effects to get a good idea about the
source of the interaction.

Finally, you specify various random-effects parts and try to
understand what they mean (see previous posts to this list), for
example:
(1|SITE)
(1|GENUS)
(1|GENUS) + (1|SITE)
(1|GENUS) + (1|GENUS:SITE)   equivalent to  (1|GENUS/SITE)

Then allow the significant fixed effects to vary for the random effects.

Reinhold Kliegl

On Tue, May 20, 2008 at 1:55 AM, Jordan Mayor <clavulina at gmail.com> wrote:
> #Thanks for all of your comments.  I have done three new things to my fungal
> data since last posting my comments:
>
> 1) I realized that in my previous email I had centered my explanatory
> variables, not predictors (sorry - I had previously centered the isotope
> data for discriminant analyses),  which I have now fixed  (e.g. cMAT, cMAP,
> cLAT),
> 2) I have include TYPE as a fixed effect instead of creating separate models
> for both mycorrhizal and saprotrophic fungi to simplify, and
> 3) I have decided to compare model sets using the GENUS instead of SPECIES
> as random effects in the following lmer models and both sets converged on
> the same model according to AIC scores.
>
> Justifications for the above actions:
> 1) Fixed previous error.   The centered predictors have a much lower
> correlation with one another now suggesting I may have finally solved the
> severe multicollinearity effect???? Not sure if this is a correct
> interpretation however.
>> center=lm(cMAT~cLAT,data=dGen)
>> summary(center)
> Call:
> lm(formula = cMAT ~ cLAT, data = dGen)
> Residuals:
>     Min      1Q         Median      3Q       Max
> -17.817  -3.206   1.229         2.229  10.313
> Coefficients:
>                     Estimate    Std. Error    t value      Pr(>|t|)
> (Intercept) -0.920757   0.181696    -5.068      4.88e-07 ***
> cLAT         -0.213731   0.009673    -22.097    < 2e-16 ***
> Residual standard error: 5.466 on 911 degrees of freedom
> Multiple R-squared: 0.3489,     Adjusted R-squared: 0.3482
> F-statistic: 488.3 on 1 and 911 DF,  p-value: < 2.2e-16
>
> 2) TYPE provides good a priori knowledge about the physiology of fungi (i.e.
> trophic role in the ecosystem) and this is reflected in my dependent
> variables whose variance I am t -> the carbon and nitrogen isotopes in fungi
>
> 3) Fungal genera are much easier to taxonomically identify and thus are less
> prone to collector misidentification, regional biases, or spelling errors!
> The family level may be too coarse for ecological comparisons because many
> genera within families can form both of the trophic roles I am trying to
> model.  I don't see any reason to use GENERA as a fixed effect however,
> because individual life histories (host plant/tissue, fungal age, site
> fertility, site stress) at each SITE could modify isotope values in very
> unknown (random) ways.  I will defiantly look into using the "ape" package
> in future research, thanks for pointing this out Simon, and yes there is now
> a phylogeny for fungi to which this could be applied - see (Blackwell et al.
> 2006 Mycologia 98:829-837, Hibbett et al. 2007Mycological Research
> 111:509-547) if anyone is interested.
>
> Using TYPE as fixed and GENERA as random provided somewhat better dispersion
> across sites as evidenced in the following table previously requested by
> Douglas Bates:
>
>> table(table(dGen$GENUS))
>
>  0    1      2      3     4     5    6    7    8    9   10   11   13   15
> 16   17   19    25    28    35    54   86   97
>  1    63   21   15    6     5    9    7    1    3    2     2      1
> 2     1     2     1       1      1      2       1     1     1
>> xtabs(~ SITE, dGen)
> SITE
>                              Aheden                            Aheden 2
>                                  33                                  53
>    Ashiu (temp deciduous broadleaf)         Betsele
>                                  40                                   5
>                      Breuil, France                         Chiba
>                                  47                                   9
>                                   d                          Flakaliden
>                                  87                                  21
>                 Glacier Bay, Alaska                   Guyana
>                                   8                                  49
>                                   h                              heath
> tundra, subarctic Sweden
>                                  92                                  14
>                           Kagoshima                       Kulbacksliden
>                                   1                                   8
>                               Kyoto                               Lamar
> Haines
>                                  54                                  25
>           Lambir (lowland tropical)                  Miyajima
>                                  31                                   2
>                            Norikura                           Norrliden
>                                  12                                   1
>                             Okinawa                       Ontake (subalpine
> coniferous)
>                                   1                                  17
>                               Oodai                           pine forests
> in CA
>                                   2                                  43
>                           Shirahama                         Snowbowl
>                                   3                                  22
>                   Spruce plantation                      Stadsskogen
>                                  37                                 123
>                         Svartberget                         Tanigawa
>                                   5                                   8
> tussock tundra near Toolik Lake, AK       Vilan
>                                   8                                   7
>                         Woods Creek
>                                  45
>
> The new models are as follows:
>
> Models with SPECIES included:
> d.mod0: X13C ~ TYPE + (1 | SITE) + (1 | SPECIES)
> d.mod5: X13C ~ cMAT + TYPE + (1 | SITE) + (1 | SPECIES)
> d.mod6: X13C ~ cMAP + TYPE + (1 | SITE) + (1 | SPECIES)
> d.mod7: X13C ~ cLAT + TYPE + (1 | SITE) + (1 | SPECIES)
> d.mod8: X13C ~ cMAT * cLAT + (1 | SITE) + (1 | SPECIES)
> d.mod2: X13C ~ cMAT * cLAT + TYPE + (1 | SITE) + (1 | SPECIES)
> d.mod3: X13C ~ cMAT * cMAP + TYPE + (1 | SITE) + (1 | SPECIES)
> d.mod4: X13C ~ cMAP * cLAT + TYPE + (1 | SITE) + (1 | SPECIES)
> d.mod1: X13C ~ cMAT * cMAP * cLAT + TYPE + (1 | SITE) + (1 | SPECIES)
>                    Df     AIC     BIC         logLik    Chisq Chi Df
> Pr(>Chisq)
> d.mod0.p   6   2594.8  2622.8  -1291.4
> d.mod5.p   7   2596.4  2629.1  -1291.2   0.4031          1  0.5255178
> d.mod6.p   7   2596.7  2629.5  -1291.3   0.0000          0  < 2.2e-16 ***
> d.mod7.p   7   2596.7  2629.5  -1291.4   0.0000          0  < 2.2e-16 ***
> d.mod8.p   7   2926.1  2958.9  -1456.1   0.0000          0  < 2.2e-16 ***
> d.mod2.p  9   2563.2  2605.4  -1272.6   366.8690      2  < 2.2e-16 ***
>>>Best fit
> d.mod3.p   9   2585.3  2627.4  -1283.6   0.0000          0  < 2.2e-16 ***
> d.mod4.p   9   2584.6  2626.7  -1283.3   0.6785          0  < 2.2e-16 ***
> d.mod1.p 13  2569.9  2630.8  -1272.0  22.6361         4  0.0001497 ***
>
> Those same models with GENERA instead of SPECIES:
>                           Df     AIC     BIC          logLik    Chisq Chi
> Df  Pr(>Chisq)
> dGen.mod0.p   5   2428.6  2451.8   -1209.3
> dGen.mod5.p   6   2430.0  2457.7   -1209.0   0.6296       1    0.427500
> dGen.mod6.p   6   2430.6  2458.4   -1209.3   0.0000       0    < 2.2e-16 ***
> dGen.mod7.p   6   2430.6  2458.4   -1209.3   0.0000       0    < 2.2e-16 ***
> dGen.mod8.p   7   2515.3  2547.6   -1250.6   0.0000       1    1.000000
> dGen.mod2.p  8   2401.6  2438.6   -1192.8 115.6470    1    < 2.2e-16 ***
>>>>Best fit again
> dGen.mod3.p   8   2418.6  2455.5   -1201.3   0.0000       0    < 2.2e-16 ***
> dGen.mod4.p   8   2418.4  2455.3   -1201.2   0.2163       0    < 2.2e-16 ***
> dGen.mod1.p 12   2408.8  2464.3   -1192.4  17.5047      4   0.001542 **
>
> I am still uncertain if I have modeled my random effects properly however
> but is seems that Model 2 is robust regardless if I model Random effects as
> (1|SITE/GENUS) or (1|SITE) + (1|GENUS).  BUT when comparing the two best fit
> models to each other, the one with more df is significantly different
> suggesting I should choose the simpler of the two without strong evidence to
> support nesting.
>
> Models:
> dGen.mod2.1:   X13C ~ cMAT * cLAT + TYPE + (1 | SITE:GENUS)
> dGen.mod2:      X13C ~ cMAT * cLAT + TYPE + (1 | SITE/GENUS)
>                               Df     AIC        BIC           logLik
> Chisq Chi     Df     Pr(>Chisq)
> dGen.mod2.1.p  7       2421.2  2453.6      -1203.6
> dGen.mod2.p     8       2417.9  2454.8       -1200.9    5.3363
> 1       0.02089 *
>
> Sorry if I have overloaded you all with output - I just thought some would
> be interested and I wanted to follow up.  I would be very interested in
> knowing if anyone has any comments on my interpretations or could suggest
> further model configurations.  Thank you very much.
>
> Jordan Mayor
>
>
> On Sun, May 18, 2008 at 8:33 PM, Simon Blomberg <s.blomberg1 at uq.edu.au>
> wrote:
>>
>> It is easy to incorporate phylogenetic correlations among species
>> ("taxonomic factors"), using the ape package and lme. This is far better
>> than combining species into families or genera, as taxonomic heirarchies
>> are subjective, artificial, and rarely represent the true phylogeny. I
>> strongly disagree that taxonomic factors necessarily function as fixed
>> effects. The phylogeny represents what we think we know about the
>> covariance among species in all traits, measured or unmeasured. I can't
>> see how unmeasured traits or poorly-defined "taxonomic factors" can
>> possibly be included as fixed effects. If particular measured traits are
>> thought to be important in determining the mean response, they should be
>> included as fixed effects, but phylogenies are used to model the
>> covariance, not the mean. Unusual species should stand out by
>> examination of the normalized residuals.
>>
>> My approach would be to ditch species as a factor altogether, and
>> incorporate phylogenetic effects through the correlation argument in lme
>> (or gls if there are no other random effects). This assumes there is an
>> available phylogeny for the fungi, which may not be true.
>>
>> There is a very large literature on incorporating phylogeny into
>> analyses (to which I am afraid I am a small contributor).
>>
>> Simon.
>>
>> On Mon, 2008-05-19 at 10:02 +1000, John Maindonald wrote:
>> > I think grouping them into families is a very good idea.
>> > This makes use of prior insight, reduces the number of
>> > parameters to an extent that it becomes more reasonable
>> > to think about fixed effects, and you can look for individual
>> > species that stray from the path laid out for them by their
>> > families.  For the fixed effects analyses that I suggested,
>> > you might do these by families.
>> >
>> > Conceptually, there are taxonomic factors that surely
>> > function, no doubt in interaction with location variables,
>> > as fixed effects.  I consider that one ought to start by thinking
>> > of them as fixed effects, unless it can be demonstrated that
>> > data are indistinguishable from random variation.
>> >
>> > Maybe however those effects operate more as the level of
>> > genera or families than at the level of species.  Responding
>> > to this point may be a useful aim for the study.
>> >
>> > John.
>> >
>> > John Maindonald             email: john.maindonald at anu.edu.au
>> > phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>> > Centre for Mathematics & Its Applications, Room 1194,
>> > John Dedman Mathematical Sciences Building (Building 27)
>> > Australian National University, Canberra ACT 0200.
>> >
>> >
>> > On 19 May 2008, at 4:04 AM, Jordan Mayor wrote:
>> >
>> > > Thank you JM, RK, and DB for your thoughtful responses to my
>> > > questions.  I am working on posting the file on the web and will
>> > > respond as soon as it is publicly available - (I could email it
>> > > direct to those concerned as well).  Until then here is the output
>> > > requested by DB and RK as well as more information regarding sites,
>> > > species, and the data:
>> > >
>> > > >ds=d[d$TYPE=="s",] #separates into just sap fungi as used in the
>> > > example below
>> > > >dm=d[d$TYPE=="m",] #separates into just myc fungi (treated as
>> > > distinct populations in my analyses)
>> > >
>> > > > table(table(ds$SPECIES))
>> > >
>> > >     0      1    2   3   5   6
>> > > 393 161  45   7   1   1
>> > > # As seen all species are not present at all the sites - this is
>> > > partly why I thought to nest SPECIES within SITE.  The sites range
>> > > widely from boreal tundra, to temperate California, to tropical
>> > > forests of Borneo and Guyana.  Most fungi are not so cosmopolitan as
>> > > to even potentially be present everywhere - let alone be collected
>> > > during brief collecting forays.  One site (pine forest in CA) didn't
>> > > even list  fungal names.  All fungi were listed as mycorrhizal (m),
>> > > saprotrophic (s), or of unknown ecological roles (unk).  Most of the
>> > > genera (or families) are present at all sites but that biologically
>> > > coarseness concerns me.  If, as pointed out by RK the ideal
>> > > situation would be every species present at every site then perhaps
>> > > creating a new column containing families or genera will move the
>> > > dataset toward that direction.
>> > >
>> > > > xtabs(~SITE,ds)
>> > > SITE
>> > >                              Aheden
>> > > Aheden 2
>> > >
>> > > 4                                   0
>> > >    Ashiu (temp deciduous broadleaf)        Betsele
>> > >
>> > > 21                                   0
>> > >                      Breuil, France                       Chiba
>> > >
>> > > 14                                   6
>> > >                                   d
>> > > Flakaliden
>> > >
>> > > 23                                   0
>> > >                 Glacier Bay, Alaska                Guyana
>> > >                                   4
>> > > 20
>> > >                                   h                     heath
>> > > tundra, subarctic Sweden
>> > >
>> > > 38                                   4
>> > >                           Kagoshima
>> > > Kulbacksliden
>> > >
>> > > 1                                   0
>> > >                               Kyoto                        Lamar
>> > > Haines
>> > >                                  26
>> > > 13
>> > >           Lambir (lowland tropical)               Miyajima
>> > >
>> > > 14                                   1
>> > >                            Norikura                        Norrliden
>> > >
>> > > 3                                   0
>> > >                             Okinawa       Ontake (subalpine
>> > > coniferous)
>> > >
>> > > 0                                   8
>> > >                               Oodai                  pine forests in
>> > > CA
>> > >                                   2
>> > > 25
>> > >                           Shirahama                     nowbowl
>> > >                                   2
>> > > 13
>> > >                   Spruce plantation                   Stadsskogen
>> > >                                  17
>> > > 13
>> > >                         Svartberget                     Tanigawa
>> > >
>> > > 0                                   6
>> > > tussock tundra near Toolik Lake, AK      Vilan
>> > >
>> > > 5                                   0
>> > >                         Woods Creek
>> > >                                  25                     # the zeros
>> > > here are because some sites have no X13C data - only X15N
>> > >
>> > > I did try running models with centered predictors, as suggested by
>> > > RK - see below.  I found that the AIC scores were much larger
>> > > however when the predictors were centered using my method.  I
>> > > centered by taking the mean of mycorrhizal and saprotrophic fungal
>> > > groups at each site - then I subtracted each (m) or (s) fungus from
>> > > those same group means within each site.  Because the (m) and (s)
>> > > fungi have unique sources of carbon, and nitrogen and these are
>> > > reflected in their isotope values (X13C, X15N), I deemed this
>> > > centering level to be appropriatein order to preserve the magnitude
>> > > of difference between the groups.
>> > >
>> > > > mix.model1  # Raw isotope values used
>> > > Linear mixed model fit by maximum likelihood
>> > > Formula: X13C ~ MAT + MAP + LAT + (1 | SPECIES) + (1 | SITE)
>> > >    Data: ds
>> > >   AIC   BIC    logLik     deviance  REMLdev
>> > >  1016 1041 -500.9     1002         1031
>> > > Random effects:
>> > >  Groups   Name        Variance Std.Dev.
>> > >  SPECIES  (Intercept) 0.62149  0.78835
>> > >  SITE     (Intercept) 0.34885  0.59063
>> > >  Residual             1.28911  1.13539
>> > > Number of obs: 283, groups: SPECIES, 215; SITE, 24
>> > >
>> > > Fixed effects:
>> > >               Estimate Std. Error t value
>> > > (Intercept) -2.207e+01  1.121e+00 -19.695
>> > > MAT         -6.418e-02  3.833e-02  -1.675
>> > > MAP          3.137e-05  2.100e-04   0.149
>> > > LAT         -8.690e-03  1.778e-02  -0.489
>> > >
>> > > Correlation of Fixed Effects:
>> > >           (Intr)       MAT     MAP
>> > > MAT  -0.707
>> > > MAP  -0.401  -0.247
>> > > LAT   -0.959  0.692   0.272
>> > >
>> > > > mix.model1a # Group centered within each site
>> > > Linear mixed model fit by maximum likelihood
>> > > Formula: STND_13c ~ MAT + MAP + LAT + (1 | SPECIES) + (1 | SITE)
>> > >    Data: ds
>> > >   AIC   BIC    logLik     deviance  REMLdev
>> > >  2623 2649  -1305     2609         2620
>> > > Random effects:
>> > >  Groups   Name        Variance Std.Dev.
>> > >  SPECIES  (Intercept) 301.9720 17.3773
>> > >  SITE     (Intercept)   5.1294  2.2648
>> > >  Residual             327.3857 18.0938
>> > > Number of obs: 283, groups: SPECIES, 215; SITE, 24
>> > >
>> > > Fixed effects:
>> > >              Estimate Std. Error t value
>> > > (Intercept) 3.463e+01  1.166e+01  2.9713
>> > > MAT         3.899e-01  4.330e-01  0.9006
>> > > MAP         2.543e-05  1.811e-03  0.0140
>> > > LAT         3.235e-01  1.867e-01  1.7324
>> > >
>> > > Correlation of Fixed Effects:
>> > >          (Intr)       MAT     MAP
>> > > MAT -0.779
>> > > MAP -0.230  -0.300
>> > > LAT  -0.955   0.732   0.116
>> > >
>> > > > anova(mix.model1,mix.model1a)
>> > > Data: ds
>> > > Models:
>> > > mix.model1: X13C ~ MAT + MAP + LAT + (1 | SPECIES) + (1 | SITE)
>> > > mix.model1a: STND_13c ~ MAT + MAP + LAT + (1 | SPECIES) + (1 | SITE)
>> > >                             Df      AIC         BIC          logLik
>> > > Chisq Chi Df  Pr(>Chisq)
>> > > mix.model1.p    7      1015.85  1041.37  -500.93
>> > > mix.model1a.p  7      2623.49  2649.00 -1304.74     0      0       <
>> > > 2.2e-16 ***
>> > >
>> > > # As seen above, the model using my centered values performed
>> > > poorly.  My interpretation is that the centering removed the very
>> > > variability associated with climate I am trying to predict!
>> > >
>> > > #In addition, I compared the other models mentioned by RK using the
>> > > raw isotope values:
>> > >
>> > > > anova(mix.model1,mix.model2,mix.model3)
>> > > Data: ds
>> > > Models:
>> > > mix.model1: X13C ~ MAT + MAP + LAT + (1 | SPECIES) + (1 | SITE)
>> > > mix.model2: X13C ~ (MAT + MAP + LAT)^2 + (1 | SPECIES) + (1 | SITE)
>> > > mix.model3: X13C ~ MAT * MAP * LAT + (1 | SPECIES) + (1 | SITE)
>> > >                          Df     AIC         BIC
>> > > logLik      Chisq    Chi Df   Pr(>Chisq)
>> > > mix.model1.p  7     1015.85  1041.37    -500.93
>> > > mix.model2.p 10    978.21    1014.66    -479.10   43.645
>> > > 3       1.796e-09 ***
>> > > mix.model3.p 11    980.18    1020.28    -479.09   0.023
>> > > 1        0.8794
>> > >
>> > > # I have refrained from trying the models mentioned by DB in order
>> > > to protect his rights to not commit the "capital mistake" ;)
>> > > however, the three predictors (MAT, MAP, LAT) do indeed seem to
>> > > overplot - I will try to select only one perhaps in my final models.
>> > >
>> > > # Again - thank you all for your help on this.
>> > >
>> > > --
>> > > Jordan Mayor, Ph.D. Candidate
>> > > Ecosystem Dynamics Research Lab
>> > > Department of Botany, University of Florida
>> > > Gainesville, FL 32611
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> --
>> Simon Blomberg, BSc (Hons), PhD, MAppStat.
>> Lecturer and Consultant Statistician
>> Faculty of Biological and Chemical Sciences
>> The University of Queensland
>> St. Lucia Queensland 4072
>> Australia
>> Room 320 Goddard Building (8)
>> T: +61 7 3365 2506
>> http://www.uq.edu.au/~uqsblomb
>> email: S.Blomberg1_at_uq.edu.au
>>
>> Policies:
>> 1.  I will NOT analyse your data for you.
>> 2.  Your deadline is your problem.
>>
>> The combination of some data and an aching desire for
>> an answer does not ensure that a reasonable answer can
>> be extracted from a given body of data. - John Tukey.
>>
>
>



From reinhold.kliegl at gmail.com  Tue May 20 09:50:21 2008
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Tue, 20 May 2008 09:50:21 +0200
Subject: [R-sig-ME] is multicollinearity of fixed effects resolved by
	random effects
In-Reply-To: <aefe4d0a0805200028v487aee05y229649c7d685bd15@mail.gmail.com>
References: <a0d257780805171221o72c53ff1qe4111abc45cf3a6e@mail.gmail.com>
	<B49D721F-E539-48EF-99A7-B57300C9AEBD@anu.edu.au>
	<aefe4d0a0805180335k7ed2259fh271c51eaa6defb76@mail.gmail.com>
	<40e66e0b0805180845t7f3739a4m4b94f82dfb8c1d36@mail.gmail.com>
	<a0d257780805181104u4f10c443h1dc54552612b2e9b@mail.gmail.com>
	<FABF6E26-3508-4347-A7A8-149193887149@anu.edu.au>
	<1211157181.21008.27.camel@sib-sblomber01d.sib.uq.edu.au>
	<a0d257780805191655r65cdd32dw706ace0abae63fd7@mail.gmail.com>
	<aefe4d0a0805200028v487aee05y229649c7d685bd15@mail.gmail.com>
Message-ID: <aefe4d0a0805200050y6eb50631mddbe6b687ab975dd@mail.gmail.com>

Two additions to my previous comment:

> Finally, you specify various random-effects parts and try to
> understand what they mean (see previous posts to this list), for
> example:
> (1|SITE)
> (1|GENUS)
> (1|GENUS) + (1|SITE)
> (1|GENUS) + (1|GENUS:SITE)   equivalent to  (1|GENUS/SITE)
>
If there are no big discrepancies in goodness of fit between two
plausible random-effects specifications, go with the representation
that makes best sense theoretically to you. Usually, they do not make
a difference for the fixed-effects part anyway. People subscribing to
this list should get away from simply looking for the smallest or
largest value of something.

I forgot: Check the residual distribution of the final model.

Reinhold Kliegl



From cotter.rs at gmail.com  Tue May 20 12:35:12 2008
From: cotter.rs at gmail.com (R.S. Cotter)
Date: Tue, 20 May 2008 12:35:12 +0200
Subject: [R-sig-ME] Logistic regression with random effect and AIC output?
Message-ID: <742479270805200335y1ff42a7etd3591f34b74204a1@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080520/b62bdc59/attachment.pl>

From f.calboli at imperial.ac.uk  Tue May 20 12:50:25 2008
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Tue, 20 May 2008 11:50:25 +0100
Subject: [R-sig-ME] Logistic regression with random effect and AIC
	output?
In-Reply-To: <742479270805200335y1ff42a7etd3591f34b74204a1@mail.gmail.com>
References: <742479270805200335y1ff42a7etd3591f34b74204a1@mail.gmail.com>
Message-ID: <4832ACF1.10304@imperial.ac.uk>

R.S. Cotter wrote:
> Dear all,
> 
> I will run a logistic regression model, with sevral explanatory variables.
> But I don't find a script that both include a random effect and also has a
> AIC output. Have tried different search options.

Have a look at glmmPQL in library MASS. it might be what you're looking for.

F

-- 
Federico C. F. Calboli
Department of Epidemiology and Public Health
Imperial College, St Mary's Campus
Norfolk Place, London W2 1PG

Tel  +44 (0)20 7594 1602     Fax (+44) 020 7594 3193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From HStevens at muohio.edu  Tue May 20 12:57:59 2008
From: HStevens at muohio.edu (Martin Henry H. Stevens)
Date: Tue, 20 May 2008 06:57:59 -0400
Subject: [R-sig-ME] Logistic regression with random effect and AIC
	output?
In-Reply-To: <742479270805200335y1ff42a7etd3591f34b74204a1@mail.gmail.com>
References: <742479270805200335y1ff42a7etd3591f34b74204a1@mail.gmail.com>
Message-ID: <3A697B0C-96FB-428D-B5DE-7568CB4308FC@muohio.edu>

Hi Cotter,
The list and examples are full of such scripts, but it depends on  
what you are looking for.  With a single random effect you might look  
at the glmmML package its examples. Also, AIC depends on how you  
count degrees of freedom for random effects -- the whole field of  
glmm's is a bit of a land mine. How many levels of "Place" do you have?
Hank
Hank
On May 20, 2008, at 6:35 AM, R.S. Cotter wrote:
> Dear all,
>
> I will run a logistic regression model, with sevral explanatory  
> variables.
> But I don't find a script that both include a random effect and  
> also has a
> AIC output. Have tried different search options.
>
> I'll be pleased if someone could help me.
>
> Response: Answer (Yes or Now)
> Explanatory variables: Age, Mass and Diet
> Random effect: Place
>
> Regards Cotter
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

Dr. Hank Stevens, Associate Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/~stevenmh/
http://www.users.muohio.edu/harkesae/
http://www.cas.muohio.edu/ecology
http://www.muohio.edu/botany/
"E Pluribus Unum"

"I love deadlines. I love the whooshing noise they make as they go by."
                                             (Douglas Adams)


If you send an attachment, please try to send it in a format anyone  
can read, such as PDF, text, Open Document Format, HTML, or RTF.
Why? See:  http://www.gnu.org/philosophy/no-word-attachments.html



From mbustama at bio.puc.cl  Tue May 20 23:16:37 2008
From: mbustama at bio.puc.cl (Marcela A. Bustamante-Sanchez)
Date: Tue, 20 May 2008 17:16:37 -0400
Subject: [R-sig-ME] contrasts in lmer for a fix effect with 3 levels
Message-ID: <018d01c8babe$c9d2d810$87d79b92@MBustamante>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080520/dbeabfb4/attachment.pl>

From f.calboli at imperial.ac.uk  Tue May 20 23:56:41 2008
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Tue, 20 May 2008 22:56:41 +0100
Subject: [R-sig-ME] contrasts in lmer for a fix effect with 3 levels
In-Reply-To: <018d01c8babe$c9d2d810$87d79b92@MBustamante>
References: <018d01c8babe$c9d2d810$87d79b92@MBustamante>
Message-ID: <915E5BB8-4F3E-49A5-8D94-540D833ED2B4@imperial.ac.uk>

On 20 May 2008, at 22:16, Marcela A. Bustamante-Sanchez wrote:

> Dears lmers!
> I have a field experiment with a split plot design. I have blocks  
> in three different types of shurblands. In each shurbland-plot I  
> set up two sub-plots, with two types of cover vegetation (open and  
> close) and in each sub plot I sowed 20 seeds of a species of tree.  
> My response variable is the probability of germination. So, I have  
> two fixed factors: shurbland and cover, and one random factor block/ 
> shrubland. The following is my model:
>
>
>
> modela<-lmer(cbind(success, failures) ~ shrubland* cover+ (1 |  
> block/shrubland), family="binomial", data=Tod07)
>
> shrubland: tree levels (Bb, Bp, R)
>
> cover: two levels (open, close)
>
>
>
> I want to know if someone can explain or indicate me how to make  
> the contrasts or comparisons for the three levels in the shurbland  
> factor? I'm nwe using R so I have no idea how to make the  
> comparisons using these mixed models.

try:

contrasts(Tod07$shrubland)

this should give you the contrasts set for the levels in shrubland.  
If you want different contrasts you need to build a new matrix of  
contrasts (of the very same dimensions of the original contrasts matrix.

contrasts(Tod07$shrubland) = your.matrix

Obviously you need to know what kind of contrasts you want before...  
look around for orthogonal contrasts, I think that would be a good  
starting point.

Finally, this question is a general R question, it applies to lm()  
and similar functions outside the libraries lme4/nlme

HTH

F

--
Federico C. F. Calboli
Department of Epidemiology and Public Health
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From mbustama at bio.puc.cl  Wed May 21 00:27:03 2008
From: mbustama at bio.puc.cl (Marcela A. Bustamante-Sanchez)
Date: Tue, 20 May 2008 18:27:03 -0400
Subject: [R-sig-ME] contrasts in lmer for a fix effect with 3 levels
References: <018d01c8babe$c9d2d810$87d79b92@MBustamante>
	<915E5BB8-4F3E-49A5-8D94-540D833ED2B4@imperial.ac.uk>
Message-ID: <01b801c8bac8$a0cf12d0$87d79b92@MBustamante>

thanks Federico I'll try this!
m
----- Original Message ----- 
From: "Federico Calboli" <f.calboli at imperial.ac.uk>
To: "Marcela A. Bustamante-Sanchez" <mbustama at bio.puc.cl>
Cc: <r-sig-mixed-models at r-project.org>
Sent: Tuesday, May 20, 2008 5:56 PM
Subject: Re: [R-sig-ME] contrasts in lmer for a fix effect with 3 levels


> On 20 May 2008, at 22:16, Marcela A. Bustamante-Sanchez wrote:
> 
>> Dears lmers!
>> I have a field experiment with a split plot design. I have blocks  
>> in three different types of shurblands. In each shurbland-plot I  
>> set up two sub-plots, with two types of cover vegetation (open and  
>> close) and in each sub plot I sowed 20 seeds of a species of tree.  
>> My response variable is the probability of germination. So, I have  
>> two fixed factors: shurbland and cover, and one random factor block/ 
>> shrubland. The following is my model:
>>
>>
>>
>> modela<-lmer(cbind(success, failures) ~ shrubland* cover+ (1 |  
>> block/shrubland), family="binomial", data=Tod07)
>>
>> shrubland: tree levels (Bb, Bp, R)
>>
>> cover: two levels (open, close)
>>
>>
>>
>> I want to know if someone can explain or indicate me how to make  
>> the contrasts or comparisons for the three levels in the shurbland  
>> factor? I'm nwe using R so I have no idea how to make the  
>> comparisons using these mixed models.
> 
> try:
> 
> contrasts(Tod07$shrubland)
> 
> this should give you the contrasts set for the levels in shrubland.  
> If you want different contrasts you need to build a new matrix of  
> contrasts (of the very same dimensions of the original contrasts matrix.
> 
> contrasts(Tod07$shrubland) = your.matrix
> 
> Obviously you need to know what kind of contrasts you want before...  
> look around for orthogonal contrasts, I think that would be a good  
> starting point.
> 
> Finally, this question is a general R question, it applies to lm()  
> and similar functions outside the libraries lme4/nlme
> 
> HTH
> 
> F
> 
> --
> Federico C. F. Calboli
> Department of Epidemiology and Public Health
> Imperial College, St. Mary's Campus
> Norfolk Place, London W2 1PG
> 
> Tel +44 (0)20 75941602   Fax +44 (0)20 75943193
> 
> f.calboli [.a.t] imperial.ac.uk
> f.calboli [.a.t] gmail.com
> 
> 
> 
>



From cjramirez at hotmail.com  Wed May 21 11:59:30 2008
From: cjramirez at hotmail.com (carlos ramirez)
Date: Wed, 21 May 2008 09:59:30 +0000
Subject: [R-sig-ME] Dummy variables in Factors with more than 2 levels
Message-ID: <BLU103-W68DDA139CFF35691853EABCC70@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080521/4df0b575/attachment.pl>

From HStevens at muohio.edu  Wed May 21 12:16:39 2008
From: HStevens at muohio.edu (Martin Henry H. Stevens)
Date: Wed, 21 May 2008 06:16:39 -0400
Subject: [R-sig-ME] Dummy variables in Factors with more than 2 levels
In-Reply-To: <BLU103-W68DDA139CFF35691853EABCC70@phx.gbl>
References: <BLU103-W68DDA139CFF35691853EABCC70@phx.gbl>
Message-ID: <DB29CD2E-9DB8-45C8-B711-9E71E8CFBEF5@muohio.edu>

By default, R uses the 'opposite' approach: the intercept is the mean  
of the first level, and the other parameters of the differences  
between the first level and that level. See ?contrasts
Hank
On May 21, 2008, at 5:59 AM, carlos ramirez wrote:
>
>
> Hi All,
>
> Sorry to bother with a
> basic question.
>
> I was wondering how R
> manages dummy variables when computing factors with more than 2  
> levels. For
> instance in my study I have the variable ?stress? with 3 levels  
> (?pre-tonic?, ?tonic?,
> and ?pos-tonic? coded, ?1?, 2? and ?3? respectively).
>
> Programs such as SPSS transform
> nominal and ordinal categories into sets of dichotomies ( dummy  
> variables) in
> such a way that a computed dummy variable 1 (dummy pre-tonic) will  
> assign 1 to
> all pre-tonic stress and ?0? to all the others. Dummy variable 2  
> (dummy tonic)
> assigns ?1? to all tonic data and ?0? to the rest. By default SPSS  
> leaves the
> last level as the ?reference category? (in this case post-tonic)  
> for comparison.
> Using what is called the ?indicator contrast?. Thus, the coding  
> ends up being
> something like the example below
>
>
>
> ------------------------------------------------                       
>       Dummy variables              Value      
> Coding                         (1)    (2)Stress                   
> 1     1.000   .000                  2      .000   
> 1.000                  3      .000   .000
>
>
>
> Thus, in the outcome,  Beta (B) and Exp (B) do not present the odds
> ratio of the dependent variable in relation to the independent  
> variable but odds
> ratio of the dummy variables with respect to the reference category  
> (post-tonic
> in this case).
>
>
>
>  When I run the mix log model in R I get an
> outpost like the following.
>
>
>
> Generalized linear
> mixed model fit using Laplace
>
> Formula: Identif ~ (1
> | Subj) + (1 | Item) + Place +  Stress
> +      Voicing
>
>    Data: idcrg1
>
>  Family: binomial(logit link)
>
>   AIC
> BIC logLik deviance
>
>  1163 1211 -572.6     1145
>
> Random effects:
>
>  Groups Name        Variance Std.Dev.
>
>  Subj
> (Intercept) 0.63178  0.79485
>
>  Item
> (Intercept) 0.88192  0.93910
>
> number of obs: 1476,
> groups: Subj, 41; Item, 36
>
>
>
>  Estimated scale
> (compare to  1 )  0.888108
>
>
>
>  Fixed effects:
>
>             Estimate Std. Error z value Pr(>|z|)
>
> (Intercept)   1.9920
> 0.4948   4.026 5.67e-05 ***
>
> Place2       -0.7253     0.4376
> -1.658   0.0974 .
>
> Place3       -0.1389     0.4478
> -0.310   0.7565
>
> Stress2       0.8765     0.4493
> 1.951   0.0511 .
>
> Stress3      -0.2386     0.4298
> -0.555   0.5788
>
> Voicing2      0.6937
> 0.3601   1.927   0.0540 .
>
>
> ---
>
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ?
> 1
>
>
>
>
> Correlation of Fixed
> Effects:
>
>          (Intr) Place2 Place3  Strss2 Strss3
>
> Place2   -0.466
>
> Place3   -0.447
> 0.511
>
> Stress2  -0.426 -0.035 -0.002  0.026
>
> Stress3  -0.451
> 0.004 -0.006  0.017  0.485
>
>
> Voicing2 -0.356  0.004 -0.023
> 0.008  0.020  0.011
>
>
>
>
>
>
> Based on the index
> that appears on Stress in the Fixed Effects outcome (Stress2 and  
> Stress3; same
> for Place2 and Place3) .
>
> Am I correct to assume
> that the reference category in this case was the first level and  
> not the last
> as it is done in SPSS?
>
> Does R create dummy
> variables to calculate the regression?
>
>
>
>
> Thanks for your time. I?d
> appreciate any help you could provide.
>
> Sincerely,Carlos
>
>
> _________________________________________________________________
>
>
>         [[alternative HTML version deleted]]
>
> <ATT00001.txt>

Dr. Hank Stevens, Associate Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/~stevenmh/
http://www.users.muohio.edu/harkesae/
http://www.cas.muohio.edu/ecology
http://www.muohio.edu/botany/
"E Pluribus Unum"

"I love deadlines. I love the whooshing noise they make as they go by."
                                             (Douglas Adams)


If you send an attachment, please try to send it in a format anyone  
can read, such as PDF, text, Open Document Format, HTML, or RTF.
Why? See:  http://www.gnu.org/philosophy/no-word-attachments.html



From bates at stat.wisc.edu  Wed May 21 16:24:12 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 21 May 2008 09:24:12 -0500
Subject: [R-sig-ME] Logistic regression with random effect and AIC
	output?
In-Reply-To: <4832ACF1.10304@imperial.ac.uk>
References: <742479270805200335y1ff42a7etd3591f34b74204a1@mail.gmail.com>
	<4832ACF1.10304@imperial.ac.uk>
Message-ID: <40e66e0b0805210724n2b42e86fs113e0c31fe58d09d@mail.gmail.com>

On Tue, May 20, 2008 at 5:50 AM, Federico Calboli
<f.calboli at imperial.ac.uk> wrote:
> R.S. Cotter wrote:
>>
>> Dear all,

>> I will run a logistic regression model, with sevral explanatory variables.
>> But I don't find a script that both include a random effect and also has a
>> AIC output. Have tried different search options.

> Have a look at glmmPQL in library MASS. it might be what you're looking for.

I don't think you will get an AIC value from glmmPQL.  The penalized
quasi-likelihood method doesn't provide the likelihood for the model
(because it minimizes another quantity called the quasi-likelihood).

Is there a reason not to use lmer with the optional argument family = binomial?



From bates at stat.wisc.edu  Wed May 21 16:35:07 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 21 May 2008 09:35:07 -0500
Subject: [R-sig-ME] Dummy variables in Factors with more than 2 levels
In-Reply-To: <DB29CD2E-9DB8-45C8-B711-9E71E8CFBEF5@muohio.edu>
References: <BLU103-W68DDA139CFF35691853EABCC70@phx.gbl>
	<DB29CD2E-9DB8-45C8-B711-9E71E8CFBEF5@muohio.edu>
Message-ID: <40e66e0b0805210735r2d14245dj2c95258e5163b18c@mail.gmail.com>

On Wed, May 21, 2008 at 5:16 AM, Martin Henry H. Stevens
<HStevens at muohio.edu> wrote:
> By default, R uses the 'opposite' approach: the intercept is the mean of the
> first level, and the other parameters of the differences between the first
> level and that level. See ?contrasts
> Hank
> On May 21, 2008, at 5:59 AM, carlos ramirez wrote:
>>
>>
>> Hi All,
>>
>> Sorry to bother with a
>> basic question.
>>
>> I was wondering how R
>> manages dummy variables when computing factors with more than 2 levels.
>> For
>> instance in my study I have the variable 'stress' with 3 levels
>> ('pre-tonic', 'tonic',
>> and 'pos-tonic' coded, '1', 2' and '3' respectively).
>>
>> Programs such as SPSS transform
>> nominal and ordinal categories into sets of dichotomies ( dummy variables)
>> in
>> such a way that a computed dummy variable 1 (dummy pre-tonic) will assign
>> 1 to
>> all pre-tonic stress and '0' to all the others. Dummy variable 2 (dummy
>> tonic)
>> assigns '1' to all tonic data and '0' to the rest. By default SPSS leaves
>> the
>> last level as the 'reference category' (in this case post-tonic) for
>> comparison.
>> Using what is called the 'indicator contrast'. Thus, the coding ends up
>> being
>> something like the example below
>>
>>
>>
>> ------------------------------------------------
>>  Dummy variables              Value     Coding                         (1)
>>  (2)Stress                  1     1.000   .000                  2      .000
>>  1.000                  3      .000   .000
>>
>>
>>
>> Thus, in the outcome,  Beta (B) and Exp (B) do not present the odds
>> ratio of the dependent variable in relation to the independent variable
>> but odds
>> ratio of the dummy variables with respect to the reference category
>> (post-tonic
>> in this case).
>>
>>
>>
>>  When I run the mix log model in R I get an
>> outpost like the following.
>>
>>
>>
>> Generalized linear
>> mixed model fit using Laplace
>>
>> Formula: Identif ~ (1
>> | Subj) + (1 | Item) + Place +  Stress
>> +      Voicing
>>
>>   Data: idcrg1
>>
>>  Family: binomial(logit link)
>>
>>  AIC
>> BIC logLik deviance
>>
>>  1163 1211 -572.6     1145
>>
>> Random effects:
>>
>>  Groups Name        Variance Std.Dev.
>>
>>  Subj
>> (Intercept) 0.63178  0.79485
>>
>>  Item
>> (Intercept) 0.88192  0.93910
>>
>> number of obs: 1476,
>> groups: Subj, 41; Item, 36
>>
>>
>>
>>  Estimated scale
>> (compare to  1 )  0.888108
>>
>>
>>
>>  Fixed effects:
>>
>>            Estimate Std. Error z value Pr(>|z|)
>>
>> (Intercept)   1.9920
>> 0.4948   4.026 5.67e-05 ***
>>
>> Place2       -0.7253     0.4376
>> -1.658   0.0974 .
>>
>> Place3       -0.1389     0.4478
>> -0.310   0.7565
>>
>> Stress2       0.8765     0.4493
>> 1.951   0.0511 .
>>
>> Stress3      -0.2386     0.4298
>> -0.555   0.5788
>>
>> Voicing2      0.6937
>> 0.3601   1.927   0.0540 .
>>
>>
>> ---
>>
>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' '
>> 1
>>
>>
>>
>>
>> Correlation of Fixed
>> Effects:
>>
>>         (Intr) Place2 Place3  Strss2 Strss3
>>
>> Place2   -0.466
>>
>> Place3   -0.447
>> 0.511
>>
>> Stress2  -0.426 -0.035 -0.002  0.026
>>
>> Stress3  -0.451
>> 0.004 -0.006  0.017  0.485
>>
>>
>> Voicing2 -0.356  0.004 -0.023
>> 0.008  0.020  0.011
>>
>>
>>
>>
>>
>>
>> Based on the index
>> that appears on Stress in the Fixed Effects outcome (Stress2 and Stress3;
>> same
>> for Place2 and Place3) .
>>
>> Am I correct to assume
>> that the reference category in this case was the first level and not the
>> last
>> as it is done in SPSS?
>>
>> Does R create dummy
>> variables to calculate the regression?
>>
>>
>>
>>
>> Thanks for your time. I'd
>> appreciate any help you could provide.
>>
>> Sincerely,Carlos
>>
>>
>> _________________________________________________________________
>>
>>
>>        [[alternative HTML version deleted]]
>>
>> <ATT00001.txt>

In R the terminology is that variables expressed as factors
(categorical data) or ordered factors (ordered categorical data) are
converted to a set of contrasts when incorporated in a linear or
generalized linear model.  The default behavior is to use the
"treatment" contrasts.  You can set an option to use the "SAS"
contrasts where the last level is the reference level.  Try

options(contrasts = c(unordered = "contr.SAS", ordered = "contr.poly")

then refit your model.



From f.calboli at imperial.ac.uk  Thu May 22 19:16:01 2008
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Thu, 22 May 2008 18:16:01 +0100
Subject: [R-sig-ME] lme() vs aov()
Message-ID: <0B7A52A3-096B-46C6-9BBC-1FA4C0948C52@imperial.ac.uk>

Hi All,

I was playing with a small dataset of 12 observations, a very basic  
nested model, with 3 drugs, 2 sources for each drug and two response  
counts for each source (the response is some medical parameter, of no  
real interest here). The data is:

drug source response
d1 a 102
d1 a 104
d1 q 103
d1 q 104
d2 d 108
d2 d 110
d2 b 109
d2 b 108
d3 l 104
d3 l 106
d3 s 105
d3 s 107

For kicks, and because the data is balanced I thought that I could  
use it to compare the results of aov() with those of lme() -- I know  
the library lme4  and lmer() should be preferred, but the stuff I am  
ultimately testig was done with lme.

In any case I fit 2 models and got 2 different answers:

 > mod.lme = lme(response ~ drug, random = ~1|source, dat)
 > mod.aov = aov(response ~ drug + Error(source), dat)

 > summary(mod.aov)

Error: source
           Df Sum Sq Mean Sq F value   Pr(>F)
drug       2 61.167  30.583  61.167 0.003703 **
Residuals  3  1.500   0.500
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Error: Within
           Df Sum Sq Mean Sq F value Pr(>F)
Residuals  6    9.0     1.5


 > anova(mod.lme) # I use anova here to directly compare the F-test
             numDF denDF   F-value p-value
(Intercept)     1     6 115207.14  <.0001
drug            2     3     26.21  0.0126

(incidentally the 3 denDF here make me think the F-test is exactly  
what I'd expect)

Because the results look different, I thought the possibilities are:

1) I fit 2 different models without realising it
2) one model is more conservative than the other
3) I'm completely missing some point (despite searching the archives  
of R-help and R-ME)

Just to be pesky, if I check the calculations against the book I got  
the data from (Zar 4th ed, pgg 304-305) they agree with the aov()  
results.

Any illumination is gratefully asked for. I apologise in advance for  
any annoyance past/present/future my question will cause.

Federico



--
Federico C. F. Calboli
Department of Epidemiology and Public Health
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From p.dalgaard at biostat.ku.dk  Thu May 22 22:19:54 2008
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 22 May 2008 22:19:54 +0200
Subject: [R-sig-ME] lme() vs aov()
In-Reply-To: <0B7A52A3-096B-46C6-9BBC-1FA4C0948C52@imperial.ac.uk>
References: <0B7A52A3-096B-46C6-9BBC-1FA4C0948C52@imperial.ac.uk>
Message-ID: <4835D56A.6030205@biostat.ku.dk>

Federico Calboli wrote:
> Hi All,
>
> I was playing with a small dataset of 12 observations, a very basic 
> nested model, with 3 drugs, 2 sources for each drug and two response 
> counts for each source (the response is some medical parameter, of no 
> real interest here). The data is:
>
> drug source response
> d1 a 102
> d1 a 104
> d1 q 103
> d1 q 104
> d2 d 108
> d2 d 110
> d2 b 109
> d2 b 108
> d3 l 104
> d3 l 106
> d3 s 105
> d3 s 107
>
> For kicks, and because the data is balanced I thought that I could use 
> it to compare the results of aov() with those of lme() -- I know the 
> library lme4  and lmer() should be preferred, but the stuff I am 
> ultimately testig was done with lme.
>
> In any case I fit 2 models and got 2 different answers:
>
> > mod.lme = lme(response ~ drug, random = ~1|source, dat)
> > mod.aov = aov(response ~ drug + Error(source), dat)
>
> > summary(mod.aov)
>
> Error: source
>           Df Sum Sq Mean Sq F value   Pr(>F)
> drug       2 61.167  30.583  61.167 0.003703 **
> Residuals  3  1.500   0.500
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Error: Within
>           Df Sum Sq Mean Sq F value Pr(>F)
> Residuals  6    9.0     1.5
>
>
> > anova(mod.lme) # I use anova here to directly compare the F-test
>             numDF denDF   F-value p-value
> (Intercept)     1     6 115207.14  <.0001
> drug            2     3     26.21  0.0126
>
> (incidentally the 3 denDF here make me think the F-test is exactly 
> what I'd expect)
>
> Because the results look different, I thought the possibilities are:
>
> 1) I fit 2 different models without realising it
> 2) one model is more conservative than the other
> 3) I'm completely missing some point (despite searching the archives 
> of R-help and R-ME)
>
> Just to be pesky, if I check the calculations against the book I got 
> the data from (Zar 4th ed, pgg 304-305) they agree with the aov() 
> results.
>
> Any illumination is gratefully asked for. I apologise in advance for 
> any annoyance past/present/future my question will cause.
>
The gut reaction is that you shouldn't trust lme() in low-df cases, but 
in this particular case the issue is different:

 > summary(mod.aov)

Error: source
          Df Sum Sq Mean Sq F value   Pr(>F)  
drug       2 61.167  30.583  61.167 0.003703 **
Residuals  3  1.500   0.500                   
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Error: Within
          Df Sum Sq Mean Sq F value Pr(>F)
Residuals  6    9.0     1.5              

Notice that the Residuals Mean Sq is larger in the Within stratum than 
in the source stratum. In terms of a mixed-effects model, this implies a 
negative estimate for the variance of the source effect. lme() will have 
nothing of that and sets it to zero instead. If you drop the 
Error(source) you get the same F as in lme() although the df differ.

(The  "negative variance" can be interpreted as negative within-source 
correlation, but that only works properly for balanced designs. Long 
story...)

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907



From kingsfordjones at gmail.com  Thu May 22 22:54:42 2008
From: kingsfordjones at gmail.com (Kingsford Jones)
Date: Thu, 22 May 2008 13:54:42 -0700
Subject: [R-sig-ME] lme() vs aov()
In-Reply-To: <4835D56A.6030205@biostat.ku.dk>
References: <0B7A52A3-096B-46C6-9BBC-1FA4C0948C52@imperial.ac.uk>
	<4835D56A.6030205@biostat.ku.dk>
Message-ID: <2ad0cc110805221354m3ad21fd0k286e13e7908b1a3f@mail.gmail.com>

Hi Federico,

Note also that the intervals function is a good tool for checking
reliability of lme objects:

> mod.lme = lme(response ~ drug, random = ~1|source, dat)
> intervals(mod.lme)
Error in intervals.lme(mod.lme) :
  Cannot get confidence intervals on var-cov components: Non-positive
definite approximate variance-covariance


Kingsford





On Thu, May 22, 2008 at 1:19 PM, Peter Dalgaard
<p.dalgaard at biostat.ku.dk> wrote:
> Federico Calboli wrote:
>>
>> Hi All,
>>
>> I was playing with a small dataset of 12 observations, a very basic nested
>> model, with 3 drugs, 2 sources for each drug and two response counts for
>> each source (the response is some medical parameter, of no real interest
>> here). The data is:
>>
>> drug source response
>> d1 a 102
>> d1 a 104
>> d1 q 103
>> d1 q 104
>> d2 d 108
>> d2 d 110
>> d2 b 109
>> d2 b 108
>> d3 l 104
>> d3 l 106
>> d3 s 105
>> d3 s 107
>>
>> For kicks, and because the data is balanced I thought that I could use it
>> to compare the results of aov() with those of lme() -- I know the library
>> lme4  and lmer() should be preferred, but the stuff I am ultimately testig
>> was done with lme.
>>
>> In any case I fit 2 models and got 2 different answers:
>>
>> > mod.lme = lme(response ~ drug, random = ~1|source, dat)
>> > mod.aov = aov(response ~ drug + Error(source), dat)
>>
>> > summary(mod.aov)
>>
>> Error: source
>>          Df Sum Sq Mean Sq F value   Pr(>F)
>> drug       2 61.167  30.583  61.167 0.003703 **
>> Residuals  3  1.500   0.500
>> ---
>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>
>> Error: Within
>>          Df Sum Sq Mean Sq F value Pr(>F)
>> Residuals  6    9.0     1.5
>>
>>
>> > anova(mod.lme) # I use anova here to directly compare the F-test
>>            numDF denDF   F-value p-value
>> (Intercept)     1     6 115207.14  <.0001
>> drug            2     3     26.21  0.0126
>>
>> (incidentally the 3 denDF here make me think the F-test is exactly what
>> I'd expect)
>>
>> Because the results look different, I thought the possibilities are:
>>
>> 1) I fit 2 different models without realising it
>> 2) one model is more conservative than the other
>> 3) I'm completely missing some point (despite searching the archives of
>> R-help and R-ME)
>>
>> Just to be pesky, if I check the calculations against the book I got the
>> data from (Zar 4th ed, pgg 304-305) they agree with the aov() results.
>>
>> Any illumination is gratefully asked for. I apologise in advance for any
>> annoyance past/present/future my question will cause.
>>
> The gut reaction is that you shouldn't trust lme() in low-df cases, but in
> this particular case the issue is different:
>
>> summary(mod.aov)
>
> Error: source
>         Df Sum Sq Mean Sq F value   Pr(>F)  drug       2 61.167  30.583
>  61.167 0.003703 **
> Residuals  3  1.500   0.500                   ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
> Error: Within
>         Df Sum Sq Mean Sq F value Pr(>F)
> Residuals  6    9.0     1.5
> Notice that the Residuals Mean Sq is larger in the Within stratum than in
> the source stratum. In terms of a mixed-effects model, this implies a
> negative estimate for the variance of the source effect. lme() will have
> nothing of that and sets it to zero instead. If you drop the Error(source)
> you get the same F as in lme() although the df differ.
>
> (The  "negative variance" can be interpreted as negative within-source
> correlation, but that only works properly for balanced designs. Long
> story...)
>
> --
>  O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
> (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From A.Robinson at ms.unimelb.edu.au  Thu May 22 23:12:37 2008
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Fri, 23 May 2008 07:12:37 +1000
Subject: [R-sig-ME] lme() vs aov()
In-Reply-To: <2ad0cc110805221354m3ad21fd0k286e13e7908b1a3f@mail.gmail.com>
References: <0B7A52A3-096B-46C6-9BBC-1FA4C0948C52@imperial.ac.uk>
	<4835D56A.6030205@biostat.ku.dk>
	<2ad0cc110805221354m3ad21fd0k286e13e7908b1a3f@mail.gmail.com>
Message-ID: <20080522211237.GW1373@ms.unimelb.edu.au>

Hi all,

well spotted, Peter!

Federico, another tool that will help diagnose this problem is
VarCorr, which provides an estimate of the variance components.



> VarCorr(mod.lme)
source = pdLogChol(1) 
            Variance     StdDev      
(Intercept) 6.675305e-10 2.583661e-05
Residual    1.166667e+00 1.080123e+00



Andrew


On Thu, May 22, 2008 at 01:54:42PM -0700, Kingsford Jones wrote:
> Hi Federico,
> 
> Note also that the intervals function is a good tool for checking
> reliability of lme objects:
> 
> > mod.lme = lme(response ~ drug, random = ~1|source, dat)
> > intervals(mod.lme)
> Error in intervals.lme(mod.lme) :
>   Cannot get confidence intervals on var-cov components: Non-positive
> definite approximate variance-covariance
> 
> 
> Kingsford
> 
> 
> 
> 
> 
> On Thu, May 22, 2008 at 1:19 PM, Peter Dalgaard
> <p.dalgaard at biostat.ku.dk> wrote:
> > Federico Calboli wrote:
> >>
> >> Hi All,
> >>
> >> I was playing with a small dataset of 12 observations, a very basic nested
> >> model, with 3 drugs, 2 sources for each drug and two response counts for
> >> each source (the response is some medical parameter, of no real interest
> >> here). The data is:
> >>
> >> drug source response
> >> d1 a 102
> >> d1 a 104
> >> d1 q 103
> >> d1 q 104
> >> d2 d 108
> >> d2 d 110
> >> d2 b 109
> >> d2 b 108
> >> d3 l 104
> >> d3 l 106
> >> d3 s 105
> >> d3 s 107
> >>
> >> For kicks, and because the data is balanced I thought that I could use it
> >> to compare the results of aov() with those of lme() -- I know the library
> >> lme4  and lmer() should be preferred, but the stuff I am ultimately testig
> >> was done with lme.
> >>
> >> In any case I fit 2 models and got 2 different answers:
> >>
> >> > mod.lme = lme(response ~ drug, random = ~1|source, dat)
> >> > mod.aov = aov(response ~ drug + Error(source), dat)
> >>
> >> > summary(mod.aov)
> >>
> >> Error: source
> >>          Df Sum Sq Mean Sq F value   Pr(>F)
> >> drug       2 61.167  30.583  61.167 0.003703 **
> >> Residuals  3  1.500   0.500
> >> ---
> >> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> >>
> >> Error: Within
> >>          Df Sum Sq Mean Sq F value Pr(>F)
> >> Residuals  6    9.0     1.5
> >>
> >>
> >> > anova(mod.lme) # I use anova here to directly compare the F-test
> >>            numDF denDF   F-value p-value
> >> (Intercept)     1     6 115207.14  <.0001
> >> drug            2     3     26.21  0.0126
> >>
> >> (incidentally the 3 denDF here make me think the F-test is exactly what
> >> I'd expect)
> >>
> >> Because the results look different, I thought the possibilities are:
> >>
> >> 1) I fit 2 different models without realising it
> >> 2) one model is more conservative than the other
> >> 3) I'm completely missing some point (despite searching the archives of
> >> R-help and R-ME)
> >>
> >> Just to be pesky, if I check the calculations against the book I got the
> >> data from (Zar 4th ed, pgg 304-305) they agree with the aov() results.
> >>
> >> Any illumination is gratefully asked for. I apologise in advance for any
> >> annoyance past/present/future my question will cause.
> >>
> > The gut reaction is that you shouldn't trust lme() in low-df cases, but in
> > this particular case the issue is different:
> >
> >> summary(mod.aov)
> >
> > Error: source
> >         Df Sum Sq Mean Sq F value   Pr(>F)  drug       2 61.167  30.583
> >  61.167 0.003703 **
> > Residuals  3  1.500   0.500                   ---
> > Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> >
> > Error: Within
> >         Df Sum Sq Mean Sq F value Pr(>F)
> > Residuals  6    9.0     1.5
> > Notice that the Residuals Mean Sq is larger in the Within stratum than in
> > the source stratum. In terms of a mixed-effects model, this implies a
> > negative estimate for the variance of the source effect. lme() will have
> > nothing of that and sets it to zero instead. If you drop the Error(source)
> > you get the same F as in lme() although the df differ.
> >
> > (The  "negative variance" can be interpreted as negative within-source
> > correlation, but that only works properly for balanced designs. Long
> > story...)
> >
> > --
> >  O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
> >  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
> > (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
> > ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From f.calboli at imperial.ac.uk  Fri May 23 12:09:57 2008
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Fri, 23 May 2008 11:09:57 +0100
Subject: [R-sig-ME] lme() vs aov()
In-Reply-To: <4835D56A.6030205@biostat.ku.dk>
References: <0B7A52A3-096B-46C6-9BBC-1FA4C0948C52@imperial.ac.uk>
	<4835D56A.6030205@biostat.ku.dk>
Message-ID: <483697F5.3040504@imperial.ac.uk>

Peter Dalgaard wrote:
> The gut reaction is that you shouldn't trust lme() in low-df cases, but 
> in this particular case the issue is different:
> 
>  > summary(mod.aov)
> 
> Error: source
>          Df Sum Sq Mean Sq F value   Pr(>F)  drug       2 61.167  
> 30.583  61.167 0.003703 **
> Residuals  3  1.500   0.500                   ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Error: Within
>          Df Sum Sq Mean Sq F value Pr(>F)
> Residuals  6    9.0     1.5             
> Notice that the Residuals Mean Sq is larger in the Within stratum than 
> in the source stratum. In terms of a mixed-effects model, this implies a 
> negative estimate for the variance of the source effect. lme() will have 
> nothing of that and sets it to zero instead. If you drop the 
> Error(source) you get the same F as in lme() although the df differ.
> 
> (The  "negative variance" can be interpreted as negative within-source 
> correlation, but that only works properly for balanced designs. Long 
> story...)

Thank you Peter for the explanation. I'm perfectly happy about this particular 
model, but I'd like to ask you (and everyone else who'd like to chime in), what 
do you mean with "you shouldn't trust lme() in low-df cases"? Why?

(I ask because I often have low-df analyses to do).

Regards,

Federico



-- 
Federico C. F. Calboli
Department of Epidemiology and Public Health
Imperial College, St Mary's Campus
Norfolk Place, London W2 1PG

Tel  +44 (0)20 7594 1602     Fax (+44) 020 7594 3193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From reinhold.kliegl at gmail.com  Sat May 24 13:56:57 2008
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Sat, 24 May 2008 13:56:57 +0200
Subject: [R-sig-ME] lme() vs aov()
In-Reply-To: <483697F5.3040504@imperial.ac.uk>
References: <0B7A52A3-096B-46C6-9BBC-1FA4C0948C52@imperial.ac.uk>
	<4835D56A.6030205@biostat.ku.dk> <483697F5.3040504@imperial.ac.uk>
Message-ID: <aefe4d0a0805240456j25865336ibd75d25d7fb18670@mail.gmail.com>

On Fri, May 23, 2008 at 12:09 PM, Federico Calboli
<f.calboli at imperial.ac.uk> wrote:
> Peter Dalgaard wrote:
>>
>> The gut reaction is that you shouldn't trust lme() in low-df cases, but in
>> this particular case the issue is different:
>>
>>  > summary(mod.aov)
>>
>> Error: source
>>         Df Sum Sq Mean Sq F value   Pr(>F)  drug       2 61.167  30.583
>>  61.167 0.003703 **
>> Residuals  3  1.500   0.500                   ---
>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>
>> Error: Within
>>         Df Sum Sq Mean Sq F value Pr(>F)
>> Residuals  6    9.0     1.5             Notice that the Residuals Mean Sq
>> is larger in the Within stratum than in the source stratum. In terms of a
>> mixed-effects model, this implies a negative estimate for the variance of
>> the source effect. lme() will have nothing of that and sets it to zero
>> instead. If you drop the Error(source) you get the same F as in lme()
>> although the df differ.
>>
>> (The  "negative variance" can be interpreted as negative within-source
>> correlation, but that only works properly for balanced designs. Long
>> story...)
>
> Thank you Peter for the explanation. I'm perfectly happy about this
> particular model, but I'd like to ask you (and everyone else who'd like to
> chime in), what do you mean with "you shouldn't trust lme() in low-df
> cases"? Why?
>
> (I ask because I often have low-df analyses to do).
>
> Regards,
>
> Federico
>

mcmcsamp(model) is one option.

Reinhold Kliegl



From byjung at gmail.com  Sat May 24 18:34:34 2008
From: byjung at gmail.com (Byju Govindan)
Date: Sat, 24 May 2008 12:34:34 -0400
Subject: [R-sig-ME] Estimating residual variance for random effect in lmer
Message-ID: <49d3454c0805240934t78717cbfydff074ce4568104c@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080524/a8bcc30e/attachment.pl>

From P.Dalgaard at biostat.ku.dk  Mon May 26 15:20:32 2008
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon, 26 May 2008 15:20:32 +0200
Subject: [R-sig-ME] lme() vs aov()
In-Reply-To: <483697F5.3040504@imperial.ac.uk>
References: <0B7A52A3-096B-46C6-9BBC-1FA4C0948C52@imperial.ac.uk>
	<4835D56A.6030205@biostat.ku.dk> <483697F5.3040504@imperial.ac.uk>
Message-ID: <483AB920.7000107@biostat.ku.dk>

Federico Calboli wrote:
> Peter Dalgaard wrote:
>> The gut reaction is that you shouldn't trust lme() in low-df cases,
>> but in this particular case the issue is different:
>>
>>  > summary(mod.aov)
>>
>> Error: source
>>          Df Sum Sq Mean Sq F value   Pr(>F)  drug       2 61.167 
>> 30.583  61.167 0.003703 **
>> Residuals  3  1.500   0.500                   ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>> Error: Within
>>          Df Sum Sq Mean Sq F value Pr(>F)
>> Residuals  6    9.0     1.5             Notice that the Residuals
>> Mean Sq is larger in the Within stratum than in the source stratum.
>> In terms of a mixed-effects model, this implies a negative estimate
>> for the variance of the source effect. lme() will have nothing of
>> that and sets it to zero instead. If you drop the Error(source) you
>> get the same F as in lme() although the df differ.
>>
>> (The  "negative variance" can be interpreted as negative
>> within-source correlation, but that only works properly for balanced
>> designs. Long story...)
>
> Thank you Peter for the explanation. I'm perfectly happy about this
> particular model, but I'd like to ask you (and everyone else who'd
> like to chime in), what do you mean with "you shouldn't trust lme() in
> low-df cases"? Why?
>
> (I ask because I often have low-df analyses to do).
>
Cynics will say that you shouldn't trust low-df analysis, period!
Effectively, the F tests are corrected chisq/f statistics, but the
correction depends crucially on the normal distribution, notably its 3rd
and 4th moment. If the correction is small, you can probably assume that
it will be small in non-normal cases too, apply the correction that is
right for normally distributed data and hope for the best, but if it is
large, then all bets are off.

For instance, looking at tests with 5 and 20 denominator df

> qchisq(.95,3)/3
[1] 2.604909
> qf(.95,3,5)
[1] 5.409451
> qf(.95,3,20)
[1] 3.098391

> 1-pf(qchisq(.95,3)/3,3,5)
[1] 0.1642641
> 1-pf(qchisq(.95,3)/3,3,20)
[1] 0.08017612

For unbalanced data, and even sometimes in the balanced case (when
effects "cross" error strata), the "F" statistic is not F distributed,
but there are some approximation methods involving "approximate
denominator df". SAS has three of these (containment, Satterthwaite,
Kenward-Rogers), lme() has only the
containment method, and lmer() has none (it has the asymptotic chisq,
plus the mcsamp() approach, which is still "in the works").

Of the three df correction methods, "containment" is quite easily fooled
into giving unreasonably large df even in balanced cases, SAS's
"Satterthwaite" is based on some rather dubious hacks, and only
Kenward-Rogers appears to be on a reasonably sound theoretical footing.
All in my humble opinion, that is.

It would be nice to have Kenward-Rogers implemented for lme() and
lmer(), but it does not mesh well with the computational technology used
to fit the models, so it is not as easy to do as it may sound. It is in
my opinion a problem, even in the light of the limited usefulness of the
improved approximation. The object is often not to get the p value right
to some number of significant digits but rather to have something that
flags tests as unreliable.

 

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907



From jmghudson at gmail.com  Wed May 28 03:25:53 2008
From: jmghudson at gmail.com (James Hudson)
Date: Tue, 27 May 2008 19:25:53 -0600
Subject: [R-sig-ME] help with repeated measures on a split-plot experiment
Message-ID: <6c8ca4f00805271825p25f25d1bh2d1804846694a50e@mail.gmail.com>

I require assistance to properly code an lmer function. I have repeatedly
measured vegetation in a split-plot, agricultural-style experiment. A pdf of
the dat file is attached. If there is any additional information I should
include, please let me know.

The design follows:
Plots were assigned to 1 of 3 snow levels (1, 2 or 3). Then, each plot was
split into 1 of 2 temperature levels (A or B). These split-plots were
replicated 6 times each. All plots were then measured repeatedly over
several years.

I am interested in the fixed effects of the treatments (snow, temperature,
time, and their interactions).

My statistical background is not advanced enough for me to properly code the
random effects of both repeated measures and the split-plot design. I expect
an AR(1) structure for 'year.' Here's my attempt at the code (it doesn't
work):


cass<-as.data.frame(read.csv("cass.csv", header=TRUE))
lmer(response ~ snow*warm*year + (1|snow/warm/year) + (0+year|plot), cass))

Any help would be appreciated.

James Hudson
UBC Geography
-------------- next part --------------
A non-text attachment was scrubbed...
Name: cass.pdf
Type: application/pdf
Size: 32828 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080527/538f31c2/attachment.pdf>

From mdu at ceh.ac.uk  Wed May 28 14:50:25 2008
From: mdu at ceh.ac.uk (Mike Dunbar)
Date: Wed, 28 May 2008 13:50:25 +0100
Subject: [R-sig-ME] help with repeated measures on a
	split-plot	experiment
Message-ID: <s83d6330.021@wpo.nerc.ac.uk>

Dear James 

Some quick initial comments.

A. You are probably trying to make a much too complex model. I think what you want is:

lmer(response ~ snow*warm*year (1|plot), cass))

As plot is the only random effect, all the others are fixed. 

B. Are you sure there is likely to be a measurable autoregressive structure to the time series data beyond that which is accounted for by the plot random effect. Just looking at the data listing, there are only three years (1995, 2000, 2007), or is this a sub-sample? With only three years, and these not being sequential years, you may be asking too much of your data. 

C. I might be missing something but are you really interested in year as a fixed effect? With this included, are there any degrees of freedom left for the residual error, you'll need to get your replication from somewhere. Be warned that lmer does seem to give results even when all dfs are used up by fixed effects and their interactions (I'm not sure why), but you need to be able to judge that you have not fitted a sensible model.

cheers

Mike





>>> "James Hudson" <jmghudson at gmail.com> 28/05/2008 02:25:53 >>>
I require assistance to properly code an lmer function. I have repeatedly
measured vegetation in a split-plot, agricultural-style experiment. A pdf of
the dat file is attached. If there is any additional information I should
include, please let me know.

The design follows:
Plots were assigned to 1 of 3 snow levels (1, 2 or 3). Then, each plot was
split into 1 of 2 temperature levels (A or B). These split-plots were
replicated 6 times each. All plots were then measured repeatedly over
several years.

I am interested in the fixed effects of the treatments (snow, temperature,
time, and their interactions).

My statistical background is not advanced enough for me to properly code the
random effects of both repeated measures and the split-plot design. I expect
an AR(1) structure for 'year.' Here's my attempt at the code (it doesn't
work):


cass<-as.data.frame(read.csv("cass.csv", header=TRUE))
lmer(response ~ snow*warm*year + (1|snow/warm/year) + (0+year|plot), cass))

Any help would be appreciated.

James Hudson
UBC Geography


-- 
This message (and any attachments) is for the recipient ...{{dropped:6}}



From john_szumiloski at merck.com  Wed May 28 19:54:20 2008
From: john_szumiloski at merck.com (Szumiloski, John)
Date: Wed, 28 May 2008 13:54:20 -0400
Subject: [R-sig-ME] Alternate nlme::pdMat;
	like pdSymm but with constant diagonal?
Message-ID: <1555D3C7C5C15A45A8F134248E6D72070278B06A@usctmx1107.merck.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080528/5acbab5d/attachment.pl>

From Jonathan.Bartlett at lshtm.ac.uk  Thu May 29 16:29:29 2008
From: Jonathan.Bartlett at lshtm.ac.uk (Jonathan.Bartlett at lshtm.ac.uk)
Date: Thu, 29 May 2008 15:29:29 +0100
Subject: [R-sig-ME] Can lme allow for serial correlation and 'pure'
	measurement	error?
Message-ID: <483ECBD8.AD5C.0057.0@lshtm.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080529/d601750a/attachment.pl>

From set_alt at yahoo.co.in  Thu May 29 18:26:38 2008
From: set_alt at yahoo.co.in (Amarjit Singh Sethi)
Date: Thu, 29 May 2008 21:56:38 +0530 (IST)
Subject: [R-sig-ME] Suitable package for carrying out sigma and beta
	convergence in panel data
Message-ID: <209324.90436.qm@web94106.mail.in2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080529/b1851edc/attachment.pl>

From A.Robinson at ms.unimelb.edu.au  Fri May 30 02:46:02 2008
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Fri, 30 May 2008 10:46:02 +1000
Subject: [R-sig-ME] Can lme allow for serial correlation and 'pure'
	measurement	error?
In-Reply-To: <483ECBD8.AD5C.0057.0@lshtm.ac.uk>
References: <483ECBD8.AD5C.0057.0@lshtm.ac.uk>
Message-ID: <20080530004602.GG40128@ms.unimelb.edu.au>

I don't think that lme can do that out of the box.

One hack to get around the problem would be to use the mean of the
multiple measurements, also record the standard error of measurements
within examination and feed the latter into a variance model using the
weights argument.

I hope that this helps,

Andrew

On Thu, May 29, 2008 at 03:29:29PM +0100, Jonathan.Bartlett at lshtm.ac.uk wrote:
> Dear mixed models list
>  
> Could someone please confirm my belief that lme does not allow one to
> fit models with separate serial correlation and measurement error
> components? In SAS proc Mixed, one can use serial correlation with a
> "repeated", and adding the option "local" to this state adds an
> additional independent error term. As far as I can tell from Pinheiro
> and Bates, lme only allows specification of a single level of residual
> covariance structure. As far as I understand, a nugget effect does not
> give the same residual covariance structure that I want.
>  
> Just to give the context, I'm analysing a dataset in which subjects are
> measured repeatedly over time. Subjects are measured at a number of
> examinations, with multiple measurements made at each examination
> (though not always the same number-otherwise I would just take the
> mean). Conditional on a set of random effects, I believe there is serial
> correlation, but since I have multiple measurements at identical times
> for each subject, I need an additional measurement error component,
> since for a model with just serial correlation a subject's measurements
> at the same time point must be identical.
>  
> My apologies if the answer is obviously no, but I just wanted to check
> I wasn't missing something obvious.
>  
> Many thanks
> Jonathan Bartlett
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From baron at psych.upenn.edu  Fri May 30 13:09:58 2008
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Fri, 30 May 2008 07:09:58 -0400
Subject: [R-sig-ME] Can lme allow for serial correlation and 'pure'
	measurement	error?
In-Reply-To: <20080530004602.GG40128@ms.unimelb.edu.au>
References: <483ECBD8.AD5C.0057.0@lshtm.ac.uk>
	<20080530004602.GG40128@ms.unimelb.edu.au>
Message-ID: <20080530110958.GA30250@psych.upenn.edu>

Min Gong supplied me with the following (which might also work in lmer
in the lme4 package):

I think you are probably referring to this. He can use subject as a
grouping factor when measuring the serial correlation between
periods..

http://stat.ethz.ch/R-manual/R-patched/library/nlme/html/corAR1.html


On 05/30/08 10:46, Andrew Robinson wrote:
> I don't think that lme can do that out of the box.
> 
> One hack to get around the problem would be to use the mean of the
> multiple measurements, also record the standard error of measurements
> within examination and feed the latter into a variance model using the
> weights argument.
> 
> I hope that this helps,
> 
> Andrew
> 
> On Thu, May 29, 2008 at 03:29:29PM +0100, Jonathan.Bartlett at lshtm.ac.uk wrote:
> > Dear mixed models list
> >  
> > Could someone please confirm my belief that lme does not allow one to
> > fit models with separate serial correlation and measurement error
> > components? In SAS proc Mixed, one can use serial correlation with a
> > "repeated", and adding the option "local" to this state adds an
> > additional independent error term. As far as I can tell from Pinheiro
> > and Bates, lme only allows specification of a single level of residual
> > covariance structure. As far as I understand, a nugget effect does not
> > give the same residual covariance structure that I want.
> >  
> > Just to give the context, I'm analysing a dataset in which subjects are
> > measured repeatedly over time. Subjects are measured at a number of
> > examinations, with multiple measurements made at each examination
> > (though not always the same number-otherwise I would just take the
> > mean). Conditional on a set of random effects, I believe there is serial
> > correlation, but since I have multiple measurements at identical times
> > for each subject, I need an additional measurement error component,
> > since for a model with just serial correlation a subject's measurements
> > at the same time point must be identical.
> >  
> > My apologies if the answer is obviously no, but I just wanted to check
> > I wasn't missing something obvious.
> >  
> > Many thanks
> > Jonathan Bartlett
> > 
> > 	[[alternative HTML version deleted]]
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> -- 
> Andrew Robinson  
> Department of Mathematics and Statistics            Tel: +61-3-8344-6410
> University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
> http://www.ms.unimelb.edu.au/~andrewpr
> http://blogs.mbs.edu/fishing-in-the-bay/
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron
Editor: Judgment and Decision Making (http://journal.sjdm.org)



From HStevens at muohio.edu  Sun Jun  1 14:42:25 2008
From: HStevens at muohio.edu (Martin Henry H. Stevens)
Date: Sun, 1 Jun 2008 08:42:25 -0400
Subject: [R-sig-ME] update groupedData
Message-ID: <3171DEBB-E161-4ADA-8127-8D1260DC1B2F@muohio.edu>

Hi folks,
I am using nlme 3.1-88
I am trying to update a groupedData object (the Oats data set), and  
change the formula and the order of the groups.
However, my code (below) fails to reorder the data.

tmp <- subset(Oats, nitro==0)
Controls <- update(Oats, yield~1|Block, data=tmp, FUN=mean)
dotplot(Block ~ yield, data=Controls, type=c('p', 'l') )

Any thoughts are appreciated.

Hank

Dr. Hank Stevens, Associate Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/~stevenmh/
http://www.users.muohio.edu/harkesae/
http://www.cas.muohio.edu/ecology
http://www.muohio.edu/botany/
"E Pluribus Unum"

"I love deadlines. I love the whooshing noise they make as they go by."
                                             (Douglas Adams)


If you send an attachment, please try to send it in a format anyone  
can read, such as PDF, text, Open Document Format, HTML, or RTF.
Why? See:  http://www.gnu.org/philosophy/no-word-attachments.html



From ima at aqua.dtu.dk  Tue Jun  3 17:49:25 2008
From: ima at aqua.dtu.dk (Irene Mantzouni)
Date: Tue, 3 Jun 2008 17:49:25 +0200
Subject: [R-sig-ME] lmeControl
Message-ID: <E7163EE5889C364389C921C0DE04152406EC54@lu-mail-san.dfu.local>

Dear all, 

I have set up a linear mixed model:

A4.lme=lme(log.s.r~SSB,=random=list(FishStock=pdDiag(~SSB)))

using the nlme library. 

When I try to make the error structure group specific using
weights=varIdent(form=~1|FishStock)

the model cannot converge using the default settings:

"nlminb problem, convergence error code = 1
  message = iteration limit reached without convergence (9)"

However, if I modify the maximum number of iterations in lmeControl
(both maxIter and msmaxIter are set to 500), then the model can indeed
converge. 
The problem is then that I cannot get the confidence intervals for the
variance-covariance components, but this error message appears:
"Cannot get confidence intervals on var-cov components: Non-positive
definite approximate variance-covariance"

On the other hand, model comparison shows that the model with the
heterogenous variances is superior. 
So, I am wondering if the lmeControl modification can invalidate the
model results and if I should use it at all. 

(Please let me know if you need any more details about the model)

Thank you!



From baron at psych.upenn.edu  Wed Jun  4 01:47:30 2008
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Tue, 3 Jun 2008 19:47:30 -0400
Subject: [R-sig-ME] pMCMC in languageR?
Message-ID: <20080603234730.GA32615@psych.upenn.edu>

Here is the relevant code from pvals.fnc() in the languageR package,
so far as I can tell.

            mcmc = mcmcsamp(object, n = nsim)
#...
            nr <- nrow(mcmc)
            prop <- colSums(mcmc[, 1:ncoef] > 0)/nr
            ans <- 2 * pmax(0.5/nr, pmin(prop, 1 - prop))

This seems like a reasonable way to compute something like a p-value.
It looks for the number of simulated cases on the wrong side of zero,
and the "0.5/nr" is sort of like a minimum p-value to correct for the
fact that the number of mcmc samples is finite.

But it isn't a p-value of the usual sort.  It seems to be based on the
posterior distribution of the parameters, given reasonable
assumptions.  In Baayen's book, and in the Baayen et al. paper that is
soon to appear in Journal of Memory and Language (already in the Web
version), it is usually fairly close to, but lower than, the p-level
for the t statistic, based on an unreasonably high df.

But I cannot find anywhere (including these sources) a description, in
words, of why this is a good thing, if it is.  It would be nice to
have something to cite if one uses it in an article.

(Also, the current code of languageR, at the moment, does not seem to
work with the latest development version of lmer.  I assume that this
is a temporary problem and not the result of some deep theoretical
problem of the sort that plagues the t statistic.)

Jon
-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron



From David.Duffy at qimr.edu.au  Wed Jun  4 05:10:56 2008
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Wed, 4 Jun 2008 13:10:56 +1000 (EST)
Subject: [R-sig-ME] pMCMC in languageR?
In-Reply-To: <20080603234730.GA32615@psych.upenn.edu>
References: <20080603234730.GA32615@psych.upenn.edu>
Message-ID: <Pine.LNX.4.64.0806041149430.22157@orpheus.qimr.edu.au>

On Tue, 3 Jun 2008, Jonathan Baron wrote:

>            mcmc = mcmcsamp(object, n = nsim)
> #...
>            nr <- nrow(mcmc)
>            prop <- colSums(mcmc[, 1:ncoef] > 0)/nr
>            ans <- 2 * pmax(0.5/nr, pmin(prop, 1 - prop))
>
> This seems like a reasonable way to compute something like a p-value.
> It looks for the number of simulated cases on the wrong side of zero,
> and the "0.5/nr" is sort of like a minimum p-value to correct for the
> fact that the number of mcmc samples is finite.
>
> But it isn't a p-value of the usual sort.  It seems to be based on the
> posterior distribution of the parameters, given reasonable
> assumptions.

Some real Bayesians will hopefully pipe up, but are these posterior 
predictive P-values (Rubin 1984; Meng 1994) with H0: b=b_hat rather than 
b=0?  All the MCMC hypothesis testing/model discrepancy suggestions I know 
of seem to simulate replicates under a simpler null hypothesis and look 
for discrepancy with reality.  But if it is a single well-behaved 
parameter so that a Wald test is equivalent to a LRT, then isn't it merely 
the old question of which estimate of the variance to use (V|b0 or 
V|b_hat)?

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From david.airey at vanderbilt.edu  Sun Jun  8 02:23:24 2008
From: david.airey at vanderbilt.edu (David Airey)
Date: Sat, 7 Jun 2008 19:23:24 -0500
Subject: [R-sig-ME] variance components models with zero estimates
Message-ID: <78124A02-67EA-4227-8E21-5685E6136DF4@vanderbilt.edu>

When a variance components mixed model is run in Stata, if some of the  
variance components are zero, the model may not converge, for rational  
reasons according to the manual entry. However, when the same model is  
run in SAS, the models with variance components that estimate to zero  
nonetheless converge. According to some SAS user friends, this is  
normal SAS behavior (I'm new to SAS as of yesterday). If I'm  
interested in looping through a set of such models, the SAS behavior  
is preferred. However, in Stata such models can be formulated as  
multilevel models that can dramatically reduce the dimension of the  
design matrix. The context where both behaviors is important is mixed  
models for gene set enrichment analysis, where there is a possibility  
of hundreds of models.

Does R lme4 handle variance components mixed models that have  
estimates of zero for some of the variance components like SAS or  
Stata? Is it possible to loop through variance components models when  
some of the variance components are zero? What is a suggested  
procedure for doing so in R? In Stata, I would probably use an EM only  
guess at which variance components were substantive, and then fit one  
of several models. What about R lme?

Cheers,

-Dave



From gregor.gorjanc at bfro.uni-lj.si  Sun Jun  8 13:07:43 2008
From: gregor.gorjanc at bfro.uni-lj.si (Gregor Gorjanc)
Date: Sun, 8 Jun 2008 11:07:43 +0000 (UTC)
Subject: [R-sig-ME] variance components models with zero estimates
References: <78124A02-67EA-4227-8E21-5685E6136DF4@vanderbilt.edu>
Message-ID: <loom.20080608T110615-268@post.gmane.org>

David Airey <david.airey at ...> writes:

> When a variance components mixed model is run in Stata, if some of the  
> variance components are zero, the model may not converge, for rational  
> reasons according to the manual entry. However, when the same model is  
> run in SAS, the models with variance components that estimate to zero  
...

I remember that with lmer() you get a warning/message that says that
variance component for a particular effect is effectively zero in such cases and
the model converges!

gg



From bates at stat.wisc.edu  Sun Jun  8 18:33:31 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sun, 8 Jun 2008 11:33:31 -0500
Subject: [R-sig-ME] variance components models with zero estimates
In-Reply-To: <78124A02-67EA-4227-8E21-5685E6136DF4@vanderbilt.edu>
References: <78124A02-67EA-4227-8E21-5685E6136DF4@vanderbilt.edu>
Message-ID: <40e66e0b0806080933u2a779a9csa6e90c969441d6b0@mail.gmail.com>

On 6/7/08, David Airey <david.airey at vanderbilt.edu> wrote:
> When a variance components mixed model is run in Stata, if some of the
> variance components are zero, the model may not converge, for rational
> reasons according to the manual entry. However, when the same model is run
> in SAS, the models with variance components that estimate to zero
> nonetheless converge. According to some SAS user friends, this is normal SAS
> behavior (I'm new to SAS as of yesterday). If I'm interested in looping
> through a set of such models, the SAS behavior is preferred. However, in
> Stata such models can be formulated as multilevel models that can
> dramatically reduce the dimension of the design matrix. The context where
> both behaviors is important is mixed models for gene set enrichment
> analysis, where there is a possibility of hundreds of models.

That's a very interesting topic and something that I am tempted to
answer in far too much detail.

Let me provide the brief answer.  Currently there are two versions of
the lme4 package available: a released version and a development
version.  To install the development version use

install.packages("lme4", repos = "http://r-forge.r-project.org")

The major difference between these versions is how they handle
evaluation of the log-likelihood when variance components are zero.
That is, does the log-likelihood get evaluated in a way that behaves
smoothly as a variance component goes to zero (and in the more general
situation of a variance-covariance matrix approaching singularity)?
The released version doesn't behave smoothly at zero and it is
necessary to restrict variances to being slightly greater than zero.
The development version does go to zero smoothly.

Gregor Gorjanc's response relates to the released version.  Neither
version throws an error condition when the estimates are zero or
near-zero.  However, if you are concerned about estimates that may be
zero I recommend using the development version of the lme4 package.
It is more robust and reliable at determining the parameter estimates.

(The natural question to ask is then why not release the development
version?  I have not done so because there are some support routines,
notably the Markov chain Monte Carlo sampler, whose versions in the
new formulation are incomplete, and some software supporting books
depends on those.)

>  Does R lme4 handle variance components mixed models that have estimates of
> zero for some of the variance components like SAS or Stata?

Neither.  The lmer function handles these situations correctly :-)

> Is it possible
> to loop through variance components models when some of the variance
> components are zero?

Yes.  Do bear in mind that much of the effort in fitting such models
is spent establishing the structures representing the model and data -
often more time will be spent formulating the numerical representation
of the model than is spent in optimizing the parameter estimates.  If
you find that your loops are taking a very long time to run you may
want to dig deeper into the code and see if you can by-pass some of
the steps and go directly to the optimization phase.  There is now a
function called "refit" in lme4 that can be used to go directly to the
optimization phase if the model and design are fixed and only response
has been changed.

> What is a suggested procedure for doing so in R? In
> Stata, I would probably use an EM only guess at which variance components
> were substantive, and then fit one of several models. What about R lme?

i think we would need more detail to be able to answer such a question.



From mdu at ceh.ac.uk  Mon Jun  9 10:48:30 2008
From: mdu at ceh.ac.uk (Mike Dunbar)
Date: Mon, 09 Jun 2008 09:48:30 +0100
Subject: [R-sig-ME] help with repeated measures on a
	split-plot	experiment
Message-ID: <s84cfc79.094@wpo.nerc.ac.uk>

Hi Jamess

Just a couple of comments below

regards

Mike


>>> "James Hudson" <jmghudson at gmail.com> 09/06/2008 03:29 >>>
>Dear Mike,

>Thank you very much for the timely, helpful response. My apologies for the
>delay in responding - I have been in the field.


On 5/28/08, Mike Dunbar <mdu at ceh.ac.uk> wrote:
>
> Dear James
>
> Some quick initial comments.
>
> A. You are probably trying to make a much too complex model. I think what
> you want is:
>
> lmer(response ~ snow*warm*year (1|plot), cass))
>
> As plot is the only random effect, all the others are fixed.


>I appreciate the simplicity of the model you have suggested. After reviewing
>both Pinheiro & Bates and West, I was initially taking a more rigid approach
>to developing my model following the examples in the texts.

B. Are you sure there is likely to be a measurable autoregressive structure
> to the time series data beyond that which is accounted for by the plot
> random effect. Just looking at the data listing, there are only three years
> (1995, 2000, 2007), or is this a sub-sample? With only three years, and
> these not being sequential years, you may be asking too much of your data.


> This is not a sub-sample - I only have 3 years of data. I assumed that if I
>were to include a repeated measures factor in my model, that I'd need to
>supply a covariance structure.

I don't know if its helpful to consider repeated measures as a special case of a mixed model. The bottom line is if you fit the model with plot as a random effect, can you then see any autocorrelation in the residuals when you plot them? Even if there is truly autocorrelation in the underlying process, you probably can't see it in your data, you'd need to see runs of points through time which were over or under-estimated. Remember that the correlation between times ascribed to them being measured on the same plot is accounted for by the plot random effect: e.g. see the orthodont example in P&B.

C. I might be missing something but are you really interested in year as a
> fixed effect? With this included, are there any degrees of freedom left for
> the residual error, you'll need to get your replication from somewhere. Be
> warned that lmer does seem to give results even when all dfs are used up by
> fixed effects and their interactions (I'm not sure why), but you need to be
> able to judge that you have not fitted a sensible model.


> I am interested in change over time so I need "time" as a fixed factor. I
>can run the model you have suggested as a lme function too but my dfs seem
> ok for this analysis.

If you can make do with time as a linear function then I think that's OK. I've still got a a feeling that if you have time as a factor then you run out of dfs. If you can post a self-contained example with model and data then others can probably comment if this is the case (I received some great help from the list on this topic about a year ago.


> cheers
>
> Mike


> Using this model in an lme function, I have been unable to identify Type
>III SS rather than Type I. Is there a straightforward way to obtain Type III
>SS?

In short: have a look at http://www.stats.ox.ac.uk/pub/MASS3/Exegeses.pdf 
Then you might want to look through the main R mailing list where the desirability of Type III sums of squares for aov has been discussed. Others can comment much better on this and why its not such a good idea. It can be done for aov if you really have to, but I don't know for lme: don't forget lme models are not fitted by straightforward least squares.





-- 
This message (and any attachments) is for the recipient ...{{dropped:6}}



From jmghudson at gmail.com  Mon Jun  9 04:29:22 2008
From: jmghudson at gmail.com (James Hudson)
Date: Sun, 8 Jun 2008 22:29:22 -0400
Subject: [R-sig-ME] help with repeated measures on a split-plot
	experiment
In-Reply-To: <s83d6330.020@wpo.nerc.ac.uk>
References: <s83d6330.020@wpo.nerc.ac.uk>
Message-ID: <6c8ca4f00806081929r330760adm892f3aab73e137f3@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080608/0865517e/attachment.pl>

From Thierry.ONKELINX at inbo.be  Mon Jun  9 15:34:19 2008
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 9 Jun 2008 15:34:19 +0200
Subject: [R-sig-ME] help with repeated measures on a split-plotexperiment
In-Reply-To: <6c8ca4f00806081929r330760adm892f3aab73e137f3@mail.gmail.com>
References: <s83d6330.020@wpo.nerc.ac.uk>
	<6c8ca4f00806081929r330760adm892f3aab73e137f3@mail.gmail.com>
Message-ID: <2E9C414912813E4EB981326983E0A10404E50843@inboexch.inbo.be>

James,

Have you considered lmer(response ~ snow*warm*year + (year|plot), cass))
with year as a factor? That would allow for correlation between the
years. But I'm wondering if year as a fixed effect still makes sense
with that kind of random effects.

HTH,

Thierry


------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium 
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be 
www.inbo.be 

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] Namens James Hudson
Verzonden: maandag 9 juni 2008 4:29
Aan: Mike Dunbar
CC: R-sig-mixed-models at r-project.org
Onderwerp: Re: [R-sig-ME] help with repeated measures on a
split-plotexperiment

Dear Mike,

Thank you very much for the timely, helpful response. My apologies for
the
delay in responding - I have been in the field.


On 5/28/08, Mike Dunbar <mdu at ceh.ac.uk> wrote:
>
> Dear James
>
> Some quick initial comments.
>
> A. You are probably trying to make a much too complex model. I think
what
> you want is:
>
> lmer(response ~ snow*warm*year (1|plot), cass))
>
> As plot is the only random effect, all the others are fixed.


I appreciate the simplicity of the model you have suggested. After
reviewing
both Pinheiro & Bates and West, I was initially taking a more rigid
approach
to developing my model following the examples in the texts.

B. Are you sure there is likely to be a measurable autoregressive
structure
> to the time series data beyond that which is accounted for by the plot
> random effect. Just looking at the data listing, there are only three
years
> (1995, 2000, 2007), or is this a sub-sample? With only three years,
and
> these not being sequential years, you may be asking too much of your
data.


 This is not a sub-sample - I only have 3 years of data. I assumed that
if I
were to include a repeated measures factor in my model, that I'd need to
supply a covariance structure.


C. I might be missing something but are you really interested in year as
a
> fixed effect? With this included, are there any degrees of freedom
left for
> the residual error, you'll need to get your replication from
somewhere. Be
> warned that lmer does seem to give results even when all dfs are used
up by
> fixed effects and their interactions (I'm not sure why), but you need
to be
> able to judge that you have not fitted a sensible model.


 I am interested in change over time so I need "time" as a fixed factor.
I
can run the model you have suggested as a lme function too but my dfs
seem
ok for this analysis.


> cheers
>
> Mike


 Using this model in an lme function, I have been unable to identify
Type
III SS rather than Type I. Is there a straightforward way to obtain Type
III
SS?

 Thanks again for the advice and comments - I appreciate them.

James

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From david.airey at Vanderbilt.Edu  Mon Jun  9 16:35:35 2008
From: david.airey at Vanderbilt.Edu (David Airey)
Date: Mon, 9 Jun 2008 09:35:35 -0500
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 18, Issue 4
In-Reply-To: <mailman.1.1213005601.1049.r-sig-mixed-models@r-project.org>
References: <mailman.1.1213005601.1049.r-sig-mixed-models@r-project.org>
Message-ID: <61104891-456A-471A-8817-C49A025E351D@vanderbilt.edu>

Thank you Dr.s Bates and Gorjanc.

I hope to bother you for additional detail later, once we finish  
analysis with a first pass using SAS Proc Mixed to give a reference  
point. My purpose was to see what was possible in R, that seems a  
little problematic in Stata (at least with my hands).

My collaborator (Lily Wang, Biostatistician, SAS user) has a paper  
coming out in PLoS Genetics, describing the improvements that use of  
mixed models for parametric gene set enrichment analysis has over the  
usual nonparametric GSEA approach by the Broad Institute. Perhaps,  
these approaches will wind their way into SAS JMP Genomics 4.

The kind of structure involved generally includes a fixed effect  
treatment of interest in two or more groups, and random effects for  
gene set, genes in the set, and gene hybridization probes. Gene  
expression is measured at the probe level; gene sets are based on a  
priori knowledge of function.

In Stata, for example, there would be two ways of doing this model  
(thanks to Yulia at Stata Corp), by brute force or multilevel:

xi: xtmixed depvar i.Group || _all: R.Gene || _all: R.GeXPr || _all:  
R.GrXGe || _all: R.GrXGeXPr, variance

which, if we have 50 genes, 5 probes per gene, and 2 groups, requires  
900 columns for the design matrix.

xi: xtmixed depvar i.Group || Gene: R.Probes, cov(exchangeable) ||  
Group: || Probes:, variance

which requires just 7 columns for the same model.

But, as stated in the earlier thread, Stata just stops when there is a  
zero variance component, because "a ridge is formed by an interval of  
values near zero, which produce the same likelihood and look equally  
good to the optimizer [manual entry]." The default optimizer is Newton- 
Raphson. There may yet be ways of dealing with this problem within  
Stata; I have yet to query their support line.

The reason the above is interesting to me is that Lily works with a  
related approach where the comparison is not by treatment within a  
given gene set, but by enrichment within a gene set compared to the  
rest of the genes on the microarray. This is the better approach to  
take, but then I think the brute force approach could do with some  
"slimming" offered by the multilevel approach.

I know far too little statistics to be asking these questions, but I'd  
like to know about possibilities in R and Stata (and it is  
interesting!). I use Stata until I run into problems, and then I  
suffer to use R. Dang, that sounds damning of both, but it should only  
sound damning of the user.

Anyway, it does sound like R lme4 will gracefully handle variance  
components that estimate to zero, and therefore allow an uncomplicated  
loop to be performed across gene sets.

Thank you again.

-Dave

On Jun 9, 2008, at 5:00 AM, r-sig-mixed-models-request at r-project.org  
wrote:

> ----------------------------------------------------------------------
>
> Message: 1
> Date: Sun, 8 Jun 2008 11:07:43 +0000 (UTC)
> From: Gregor Gorjanc <gregor.gorjanc at bfro.uni-lj.si>
> Subject: Re: [R-sig-ME] variance components models with zero estimates
> To: r-sig-mixed-models at r-project.org
> Message-ID: <loom.20080608T110615-268 at post.gmane.org>
> Content-Type: text/plain; charset=us-ascii
>
> David Airey <david.airey at ...> writes:
>
>> When a variance components mixed model is run in Stata, if some of  
>> the
>> variance components are zero, the model may not converge, for  
>> rational
>> reasons according to the manual entry. However, when the same model  
>> is
>> run in SAS, the models with variance components that estimate to zero
> ...
>
> I remember that with lmer() you get a warning/message that says that
> variance component for a particular effect is effectively zero in  
> such cases and
> the model converges!
>
> gg
>
>
>
> ------------------------------
>
> Message: 2
> Date: Sun, 8 Jun 2008 11:33:31 -0500
> From: "Douglas Bates" <bates at stat.wisc.edu>
> Subject: Re: [R-sig-ME] variance components models with zero estimates
> To: "David Airey" <david.airey at vanderbilt.edu>
> Cc: r-sig-mixed-models at r-project.org
> Message-ID:
> 	<40e66e0b0806080933u2a779a9csa6e90c969441d6b0 at mail.gmail.com>
> Content-Type: text/plain; charset=ISO-8859-1
>
> On 6/7/08, David Airey <david.airey at vanderbilt.edu> wrote:
>> When a variance components mixed model is run in Stata, if some of  
>> the
>> variance components are zero, the model may not converge, for  
>> rational
>> reasons according to the manual entry. However, when the same model  
>> is run
>> in SAS, the models with variance components that estimate to zero
>> nonetheless converge. According to some SAS user friends, this is  
>> normal SAS
>> behavior (I'm new to SAS as of yesterday). If I'm interested in  
>> looping
>> through a set of such models, the SAS behavior is preferred.  
>> However, in
>> Stata such models can be formulated as multilevel models that can
>> dramatically reduce the dimension of the design matrix. The context  
>> where
>> both behaviors is important is mixed models for gene set enrichment
>> analysis, where there is a possibility of hundreds of models.
>
> That's a very interesting topic and something that I am tempted to
> answer in far too much detail.
>
> Let me provide the brief answer.  Currently there are two versions of
> the lme4 package available: a released version and a development
> version.  To install the development version use
>
> install.packages("lme4", repos = "http://r-forge.r-project.org")
>
> The major difference between these versions is how they handle
> evaluation of the log-likelihood when variance components are zero.
> That is, does the log-likelihood get evaluated in a way that behaves
> smoothly as a variance component goes to zero (and in the more general
> situation of a variance-covariance matrix approaching singularity)?
> The released version doesn't behave smoothly at zero and it is
> necessary to restrict variances to being slightly greater than zero.
> The development version does go to zero smoothly.
>
> Gregor Gorjanc's response relates to the released version.  Neither
> version throws an error condition when the estimates are zero or
> near-zero.  However, if you are concerned about estimates that may be
> zero I recommend using the development version of the lme4 package.
> It is more robust and reliable at determining the parameter estimates.
>
> (The natural question to ask is then why not release the development
> version?  I have not done so because there are some support routines,
> notably the Markov chain Monte Carlo sampler, whose versions in the
> new formulation are incomplete, and some software supporting books
> depends on those.)
>
>> Does R lme4 handle variance components mixed models that have  
>> estimates of
>> zero for some of the variance components like SAS or Stata?
>
> Neither.  The lmer function handles these situations correctly :-)
>
>> Is it possible
>> to loop through variance components models when some of the variance
>> components are zero?
>
> Yes.  Do bear in mind that much of the effort in fitting such models
> is spent establishing the structures representing the model and data -
> often more time will be spent formulating the numerical representation
> of the model than is spent in optimizing the parameter estimates.  If
> you find that your loops are taking a very long time to run you may
> want to dig deeper into the code and see if you can by-pass some of
> the steps and go directly to the optimization phase.  There is now a
> function called "refit" in lme4 that can be used to go directly to the
> optimization phase if the model and design are fixed and only response
> has been changed.
>
>> What is a suggested procedure for doing so in R? In
>> Stata, I would probably use an EM only guess at which variance  
>> components
>> were substantive, and then fit one of several models. What about R  
>> lme?
>
> i think we would need more detail to be able to answer such a  
> question.
>
>
>
> ------------------------------



From bates at stat.wisc.edu  Mon Jun  9 16:43:30 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 9 Jun 2008 09:43:30 -0500
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 18, Issue 4
In-Reply-To: <61104891-456A-471A-8817-C49A025E351D@vanderbilt.edu>
References: <mailman.1.1213005601.1049.r-sig-mixed-models@r-project.org>
	<61104891-456A-471A-8817-C49A025E351D@vanderbilt.edu>
Message-ID: <40e66e0b0806090743q629c05e7g77c2b6b72fb43a8e@mail.gmail.com>

It would be much easier to explain how such models could be fit in the
lme4 package if you could provide some sample data or direct us to
some published data. Is that possible?

On Mon, Jun 9, 2008 at 9:35 AM, David Airey <david.airey at vanderbilt.edu> wrote:
> Thank you Dr.s Bates and Gorjanc.
>
> I hope to bother you for additional detail later, once we finish analysis
> with a first pass using SAS Proc Mixed to give a reference point. My purpose
> was to see what was possible in R, that seems a little problematic in Stata
> (at least with my hands).
>
> My collaborator (Lily Wang, Biostatistician, SAS user) has a paper coming
> out in PLoS Genetics, describing the improvements that use of mixed models
> for parametric gene set enrichment analysis has over the usual nonparametric
> GSEA approach by the Broad Institute. Perhaps, these approaches will wind
> their way into SAS JMP Genomics 4.
>
> The kind of structure involved generally includes a fixed effect treatment
> of interest in two or more groups, and random effects for gene set, genes in
> the set, and gene hybridization probes. Gene expression is measured at the
> probe level; gene sets are based on a priori knowledge of function.
>
> In Stata, for example, there would be two ways of doing this model (thanks
> to Yulia at Stata Corp), by brute force or multilevel:
>
> xi: xtmixed depvar i.Group || _all: R.Gene || _all: R.GeXPr || _all: R.GrXGe
> || _all: R.GrXGeXPr, variance
>
> which, if we have 50 genes, 5 probes per gene, and 2 groups, requires 900
> columns for the design matrix.
>
> xi: xtmixed depvar i.Group || Gene: R.Probes, cov(exchangeable) || Group: ||
> Probes:, variance
>
> which requires just 7 columns for the same model.
>
> But, as stated in the earlier thread, Stata just stops when there is a zero
> variance component, because "a ridge is formed by an interval of values near
> zero, which produce the same likelihood and look equally good to the
> optimizer [manual entry]." The default optimizer is Newton-Raphson. There
> may yet be ways of dealing with this problem within Stata; I have yet to
> query their support line.
>
> The reason the above is interesting to me is that Lily works with a related
> approach where the comparison is not by treatment within a given gene set,
> but by enrichment within a gene set compared to the rest of the genes on the
> microarray. This is the better approach to take, but then I think the brute
> force approach could do with some "slimming" offered by the multilevel
> approach.
>
> I know far too little statistics to be asking these questions, but I'd like
> to know about possibilities in R and Stata (and it is interesting!). I use
> Stata until I run into problems, and then I suffer to use R. Dang, that
> sounds damning of both, but it should only sound damning of the user.
>
> Anyway, it does sound like R lme4 will gracefully handle variance components
> that estimate to zero, and therefore allow an uncomplicated loop to be
> performed across gene sets.
>
> Thank you again.
>
> -Dave
>
> On Jun 9, 2008, at 5:00 AM, r-sig-mixed-models-request at r-project.org wrote:
>
>> ----------------------------------------------------------------------
>>
>> Message: 1
>> Date: Sun, 8 Jun 2008 11:07:43 +0000 (UTC)
>> From: Gregor Gorjanc <gregor.gorjanc at bfro.uni-lj.si>
>> Subject: Re: [R-sig-ME] variance components models with zero estimates
>> To: r-sig-mixed-models at r-project.org
>> Message-ID: <loom.20080608T110615-268 at post.gmane.org>
>> Content-Type: text/plain; charset=us-ascii
>>
>> David Airey <david.airey at ...> writes:
>>
>>> When a variance components mixed model is run in Stata, if some of the
>>> variance components are zero, the model may not converge, for rational
>>> reasons according to the manual entry. However, when the same model is
>>> run in SAS, the models with variance components that estimate to zero
>>
>> ...
>>
>> I remember that with lmer() you get a warning/message that says that
>> variance component for a particular effect is effectively zero in such
>> cases and
>> the model converges!
>>
>> gg
>>
>>
>>
>> ------------------------------
>>
>> Message: 2
>> Date: Sun, 8 Jun 2008 11:33:31 -0500
>> From: "Douglas Bates" <bates at stat.wisc.edu>
>> Subject: Re: [R-sig-ME] variance components models with zero estimates
>> To: "David Airey" <david.airey at vanderbilt.edu>
>> Cc: r-sig-mixed-models at r-project.org
>> Message-ID:
>>        <40e66e0b0806080933u2a779a9csa6e90c969441d6b0 at mail.gmail.com>
>> Content-Type: text/plain; charset=ISO-8859-1
>>
>> On 6/7/08, David Airey <david.airey at vanderbilt.edu> wrote:
>>>
>>> When a variance components mixed model is run in Stata, if some of the
>>> variance components are zero, the model may not converge, for rational
>>> reasons according to the manual entry. However, when the same model is
>>> run
>>> in SAS, the models with variance components that estimate to zero
>>> nonetheless converge. According to some SAS user friends, this is normal
>>> SAS
>>> behavior (I'm new to SAS as of yesterday). If I'm interested in looping
>>> through a set of such models, the SAS behavior is preferred. However, in
>>> Stata such models can be formulated as multilevel models that can
>>> dramatically reduce the dimension of the design matrix. The context where
>>> both behaviors is important is mixed models for gene set enrichment
>>> analysis, where there is a possibility of hundreds of models.
>>
>> That's a very interesting topic and something that I am tempted to
>> answer in far too much detail.
>>
>> Let me provide the brief answer.  Currently there are two versions of
>> the lme4 package available: a released version and a development
>> version.  To install the development version use
>>
>> install.packages("lme4", repos = "http://r-forge.r-project.org")
>>
>> The major difference between these versions is how they handle
>> evaluation of the log-likelihood when variance components are zero.
>> That is, does the log-likelihood get evaluated in a way that behaves
>> smoothly as a variance component goes to zero (and in the more general
>> situation of a variance-covariance matrix approaching singularity)?
>> The released version doesn't behave smoothly at zero and it is
>> necessary to restrict variances to being slightly greater than zero.
>> The development version does go to zero smoothly.
>>
>> Gregor Gorjanc's response relates to the released version.  Neither
>> version throws an error condition when the estimates are zero or
>> near-zero.  However, if you are concerned about estimates that may be
>> zero I recommend using the development version of the lme4 package.
>> It is more robust and reliable at determining the parameter estimates.
>>
>> (The natural question to ask is then why not release the development
>> version?  I have not done so because there are some support routines,
>> notably the Markov chain Monte Carlo sampler, whose versions in the
>> new formulation are incomplete, and some software supporting books
>> depends on those.)
>>
>>> Does R lme4 handle variance components mixed models that have estimates
>>> of
>>> zero for some of the variance components like SAS or Stata?
>>
>> Neither.  The lmer function handles these situations correctly :-)
>>
>>> Is it possible
>>> to loop through variance components models when some of the variance
>>> components are zero?
>>
>> Yes.  Do bear in mind that much of the effort in fitting such models
>> is spent establishing the structures representing the model and data -
>> often more time will be spent formulating the numerical representation
>> of the model than is spent in optimizing the parameter estimates.  If
>> you find that your loops are taking a very long time to run you may
>> want to dig deeper into the code and see if you can by-pass some of
>> the steps and go directly to the optimization phase.  There is now a
>> function called "refit" in lme4 that can be used to go directly to the
>> optimization phase if the model and design are fixed and only response
>> has been changed.
>>
>>> What is a suggested procedure for doing so in R? In
>>> Stata, I would probably use an EM only guess at which variance components
>>> were substantive, and then fit one of several models. What about R lme?
>>
>> i think we would need more detail to be able to answer such a question.
>>
>>
>>
>> ------------------------------
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From david.airey at Vanderbilt.Edu  Mon Jun  9 16:46:34 2008
From: david.airey at Vanderbilt.Edu (David Airey)
Date: Mon, 9 Jun 2008 09:46:34 -0500
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 18, Issue 4
In-Reply-To: <40e66e0b0806090743q629c05e7g77c2b6b72fb43a8e@mail.gmail.com>
References: <mailman.1.1213005601.1049.r-sig-mixed-models@r-project.org>
	<61104891-456A-471A-8817-C49A025E351D@vanderbilt.edu>
	<40e66e0b0806090743q629c05e7g77c2b6b72fb43a8e@mail.gmail.com>
Message-ID: <9CF77018-E98C-46B3-9A52-41345024D193@vanderbilt.edu>

That may be possible. I will contact you off list.

-Dave

On Jun 9, 2008, at 9:43 AM, Douglas Bates wrote:

> It would be much easier to explain how such models could be fit in the
> lme4 package if you could provide some sample data or direct us to
> some published data. Is that possible?
>
> On Mon, Jun 9, 2008 at 9:35 AM, David Airey <david.airey at vanderbilt.edu 
> > wrote:
>> Thank you Dr.s Bates and Gorjanc.
>>
>> I hope to bother you for additional detail later, once we finish  
>> analysis
>> with a first pass using SAS Proc Mixed to give a reference point.  
>> My purpose
>> was to see what was possible in R, that seems a little problematic  
>> in Stata
>> (at least with my hands).
>>
>> My collaborator (Lily Wang, Biostatistician, SAS user) has a paper  
>> coming
>> out in PLoS Genetics, describing the improvements that use of mixed  
>> models
>> for parametric gene set enrichment analysis has over the usual  
>> nonparametric
>> GSEA approach by the Broad Institute. Perhaps, these approaches  
>> will wind
>> their way into SAS JMP Genomics 4.
>>
>> The kind of structure involved generally includes a fixed effect  
>> treatment
>> of interest in two or more groups, and random effects for gene set,  
>> genes in
>> the set, and gene hybridization probes. Gene expression is measured  
>> at the
>> probe level; gene sets are based on a priori knowledge of function.
>>
>> In Stata, for example, there would be two ways of doing this model  
>> (thanks
>> to Yulia at Stata Corp), by brute force or multilevel:
>>
>> xi: xtmixed depvar i.Group || _all: R.Gene || _all: R.GeXPr ||  
>> _all: R.GrXGe
>> || _all: R.GrXGeXPr, variance
>>
>> which, if we have 50 genes, 5 probes per gene, and 2 groups,  
>> requires 900
>> columns for the design matrix.
>>
>> xi: xtmixed depvar i.Group || Gene: R.Probes, cov(exchangeable) ||  
>> Group: ||
>> Probes:, variance
>>
>> which requires just 7 columns for the same model.
>>
>> But, as stated in the earlier thread, Stata just stops when there  
>> is a zero
>> variance component, because "a ridge is formed by an interval of  
>> values near
>> zero, which produce the same likelihood and look equally good to the
>> optimizer [manual entry]." The default optimizer is Newton-Raphson.  
>> There
>> may yet be ways of dealing with this problem within Stata; I have  
>> yet to
>> query their support line.
>>
>> The reason the above is interesting to me is that Lily works with a  
>> related
>> approach where the comparison is not by treatment within a given  
>> gene set,
>> but by enrichment within a gene set compared to the rest of the  
>> genes on the
>> microarray. This is the better approach to take, but then I think  
>> the brute
>> force approach could do with some "slimming" offered by the  
>> multilevel
>> approach.
>>
>> I know far too little statistics to be asking these questions, but  
>> I'd like
>> to know about possibilities in R and Stata (and it is  
>> interesting!). I use
>> Stata until I run into problems, and then I suffer to use R. Dang,  
>> that
>> sounds damning of both, but it should only sound damning of the user.
>>
>> Anyway, it does sound like R lme4 will gracefully handle variance  
>> components
>> that estimate to zero, and therefore allow an uncomplicated loop to  
>> be
>> performed across gene sets.
>>
>> Thank you again.
>>
>> -Dave
>>
>> On Jun 9, 2008, at 5:00 AM, r-sig-mixed-models-request at r- 
>> project.org wrote:
>>
>>> ----------------------------------------------------------------------
>>>
>>> Message: 1
>>> Date: Sun, 8 Jun 2008 11:07:43 +0000 (UTC)
>>> From: Gregor Gorjanc <gregor.gorjanc at bfro.uni-lj.si>
>>> Subject: Re: [R-sig-ME] variance components models with zero  
>>> estimates
>>> To: r-sig-mixed-models at r-project.org
>>> Message-ID: <loom.20080608T110615-268 at post.gmane.org>
>>> Content-Type: text/plain; charset=us-ascii
>>>
>>> David Airey <david.airey at ...> writes:
>>>
>>>> When a variance components mixed model is run in Stata, if some  
>>>> of the
>>>> variance components are zero, the model may not converge, for  
>>>> rational
>>>> reasons according to the manual entry. However, when the same  
>>>> model is
>>>> run in SAS, the models with variance components that estimate to  
>>>> zero
>>>
>>> ...
>>>
>>> I remember that with lmer() you get a warning/message that says that
>>> variance component for a particular effect is effectively zero in  
>>> such
>>> cases and
>>> the model converges!
>>>
>>> gg
>>>
>>>
>>>
>>> ------------------------------
>>>
>>> Message: 2
>>> Date: Sun, 8 Jun 2008 11:33:31 -0500
>>> From: "Douglas Bates" <bates at stat.wisc.edu>
>>> Subject: Re: [R-sig-ME] variance components models with zero  
>>> estimates
>>> To: "David Airey" <david.airey at vanderbilt.edu>
>>> Cc: r-sig-mixed-models at r-project.org
>>> Message-ID:
>>>       <40e66e0b0806080933u2a779a9csa6e90c969441d6b0 at mail.gmail.com>
>>> Content-Type: text/plain; charset=ISO-8859-1
>>>
>>> On 6/7/08, David Airey <david.airey at vanderbilt.edu> wrote:
>>>>
>>>> When a variance components mixed model is run in Stata, if some  
>>>> of the
>>>> variance components are zero, the model may not converge, for  
>>>> rational
>>>> reasons according to the manual entry. However, when the same  
>>>> model is
>>>> run
>>>> in SAS, the models with variance components that estimate to zero
>>>> nonetheless converge. According to some SAS user friends, this is  
>>>> normal
>>>> SAS
>>>> behavior (I'm new to SAS as of yesterday). If I'm interested in  
>>>> looping
>>>> through a set of such models, the SAS behavior is preferred.  
>>>> However, in
>>>> Stata such models can be formulated as multilevel models that can
>>>> dramatically reduce the dimension of the design matrix. The  
>>>> context where
>>>> both behaviors is important is mixed models for gene set enrichment
>>>> analysis, where there is a possibility of hundreds of models.
>>>
>>> That's a very interesting topic and something that I am tempted to
>>> answer in far too much detail.
>>>
>>> Let me provide the brief answer.  Currently there are two versions  
>>> of
>>> the lme4 package available: a released version and a development
>>> version.  To install the development version use
>>>
>>> install.packages("lme4", repos = "http://r-forge.r-project.org")
>>>
>>> The major difference between these versions is how they handle
>>> evaluation of the log-likelihood when variance components are zero.
>>> That is, does the log-likelihood get evaluated in a way that behaves
>>> smoothly as a variance component goes to zero (and in the more  
>>> general
>>> situation of a variance-covariance matrix approaching singularity)?
>>> The released version doesn't behave smoothly at zero and it is
>>> necessary to restrict variances to being slightly greater than zero.
>>> The development version does go to zero smoothly.
>>>
>>> Gregor Gorjanc's response relates to the released version.  Neither
>>> version throws an error condition when the estimates are zero or
>>> near-zero.  However, if you are concerned about estimates that may  
>>> be
>>> zero I recommend using the development version of the lme4 package.
>>> It is more robust and reliable at determining the parameter  
>>> estimates.
>>>
>>> (The natural question to ask is then why not release the development
>>> version?  I have not done so because there are some support  
>>> routines,
>>> notably the Markov chain Monte Carlo sampler, whose versions in the
>>> new formulation are incomplete, and some software supporting books
>>> depends on those.)
>>>
>>>> Does R lme4 handle variance components mixed models that have  
>>>> estimates
>>>> of
>>>> zero for some of the variance components like SAS or Stata?
>>>
>>> Neither.  The lmer function handles these situations correctly :-)
>>>
>>>> Is it possible
>>>> to loop through variance components models when some of the  
>>>> variance
>>>> components are zero?
>>>
>>> Yes.  Do bear in mind that much of the effort in fitting such models
>>> is spent establishing the structures representing the model and  
>>> data -
>>> often more time will be spent formulating the numerical  
>>> representation
>>> of the model than is spent in optimizing the parameter estimates.   
>>> If
>>> you find that your loops are taking a very long time to run you may
>>> want to dig deeper into the code and see if you can by-pass some of
>>> the steps and go directly to the optimization phase.  There is now a
>>> function called "refit" in lme4 that can be used to go directly to  
>>> the
>>> optimization phase if the model and design are fixed and only  
>>> response
>>> has been changed.
>>>
>>>> What is a suggested procedure for doing so in R? In
>>>> Stata, I would probably use an EM only guess at which variance  
>>>> components
>>>> were substantive, and then fit one of several models. What about  
>>>> R lme?
>>>
>>> i think we would need more detail to be able to answer such a  
>>> question.
>>>
>>>
>>>
>>> ------------------------------
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>



From ARNAUD_MOSNIER at UQAR.QC.CA  Mon Jun  9 17:01:38 2008
From: ARNAUD_MOSNIER at UQAR.QC.CA (ARNAUD_MOSNIER at UQAR.QC.CA)
Date: Mon, 9 Jun 2008 11:01:38 -0400
Subject: [R-sig-ME] (no subject)
Message-ID: <A54BCD9B13BDC64782C3F913CA24DD761D5B31@owadepot.bureautique.uqar.qc.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080609/89540d9e/attachment.pl>

From HStevens at MUOhio.edu  Mon Jun  9 17:43:00 2008
From: HStevens at MUOhio.edu (Hank Stevens)
Date: Mon, 9 Jun 2008 11:43:00 -0400
Subject: [R-sig-ME] (no subject)
In-Reply-To: <A54BCD9B13BDC64782C3F913CA24DD761D5B31@owadepot.bureautique.uqar.qc.ca>
References: <A54BCD9B13BDC64782C3F913CA24DD761D5B31@owadepot.bureautique.uqar.qc.ca>
Message-ID: <654772DB-9DBE-4FB5-A5F1-F07B128A8173@MUOhio.edu>

Hi Arnaud,
What you are doing seems right to me, but I was wondering where the  
large number of observations come from. Are you recording location of  
individual animals at different times (GPS tracking?)? Do you have the  
same animal at different scales (within a year)? Might scale and  
animal be considered separately, or is ANIMAL:SCALEFACT:YEARFACT  
simply a way to ID animals in a unique fashion? what is ANNEEFACT?

You could try AIC comparisons of the two models.

Hank

On Jun 9, 2008, at 11:01 AM, ARNAUD_MOSNIER at UQAR.QC.CA wrote:

> Dear lmer users,
>
> It's the first time I use lmer for analysis and I want to be sure I  
> correctly wrote my command.
> I need to test link between habitat characteristics used by animal  
> we followed (1) and random locations (0). Information was collected  
> during several year, several season, on several geographical scales  
> and for different individuals.
> I make analysis by season so I do not consider this factor here.
>
> I have not the same individuals for each scale considered, and not  
> the same scales for each year considered.
> So I have individuals nested in year and scale.
>
>
>
> First question :
>
>
> Do ANIMAL:SCALEFACT:YEARFACT is the correct way to consider this in  
> lmer ?
>
>
> Generalized linear mixed model fit using Laplace
> Formula: REAL_ALEAT ~ (1 | ANIMAL:SCALEFACT:YEARFACT) + ELEVMEAN +  
> ELEVSTD
>   Data: rawdata
> Subset: SEASON %in% c("PR")
> Family: binomial(logit link)
>   AIC   BIC logLik deviance
> 293.1 325.3 -142.5    285.1
> Random effects:
> Groups                     Name        Variance  Std.Dev.
> ANIMAL:SCALEFACT:YEARFACT (Intercept) 0.0022750 0.047697
> number of obs: 23433, groups: ANIMAL:SCALEFACT:YEARFACT, 20
>
> Estimated scale (compare to  1 )  0.9111264
>
> Fixed effects:
>             Estimate Std. Error z value Pr(>|z|)
> (Intercept) -5.484582   1.249321  -4.390 1.13e-05 ***
> ELEVMEAN    -0.004170   0.002086  -1.999   0.0456 *
> ELEVSTD      0.090707   0.010896   8.325  < 2e-16 ***
>
>
>
>
>
> Second and last question :
>
>
> What is the difference between ...
>
> REAL_ALEAT ~ (1 | ANIMAL:SCALEFACT:YEARFACT) + ELEVMEAN + ELEVSTD
>
> and
>
> REAL_ALEAT ~ (1 | ANIMAL) + (1 | SCALEFACT) + (1 | YEARFACT) +  
> ELEVMEAN + ELEVSTD
>
>
>
>
>
> Generalized linear mixed model fit using Laplace
> Formula: REAL_ALEAT ~ (1 | ANIMAL) + (1 | SCALEFACT) + (1 |  
> ANNEEFACT) +      ELEVMEAN + ELEVSTD
>   Data: rawdata
> Subset: SEASON %in% c("PR")
> Family: binomial(logit link)
>   AIC   BIC logLik deviance
> 297.0 345.4 -142.5    285.0
> Random effects:
> Groups    Name        Variance   Std.Dev.
> ANIMAL    (Intercept) 0.00159273 0.039909
> SCALEFACT (Intercept) 0.00159324 0.039915
> ANNEEFACT (Intercept) 0.00034151 0.018480
> number of obs: 23433, groups: ANIMAL, 14; SCALEFACT, 14; ANNEEFACT, 3
>
> Estimated scale (compare to  1 )  0.9112284
>
> Fixed effects:
>             Estimate Std. Error z value Pr(>|z|)
> (Intercept) -5.484582   1.251321  -4.383 1.17e-05 ***
> ELEVMEAN    -0.004167   0.002088  -1.996   0.0459 *
> ELEVSTD      0.090707   0.010907   8.316  < 2e-16 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>         (Intr) ELEVME
> ELEVMEAN -0.970
> ELEVSTD   0.050 -0.213
>
>
>
> Thanks in advance,
>
> Arnaud
>
>        [[alternative HTML version deleted]]
>
> <ATT00001.txt>



Dr. Hank Stevens, Associate Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/~stevenmh/
http://www.cas.muohio.edu/ecology
http://www.muohio.edu/botany/

"If the stars should appear one night in a thousand years, how would men
believe and adore." -Ralph Waldo Emerson, writer and philosopher  
(1803-1882)



From pcoates at usgs.gov  Mon Jun  9 23:35:00 2008
From: pcoates at usgs.gov (Peter S Coates)
Date: Mon, 9 Jun 2008 14:35:00 -0700
Subject: [R-sig-ME] Question on lmer use and commands
Message-ID: <OFA7027752.90983A29-ON88257463.006AA317-88257463.00768FF2@usgs.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080609/023c5895/attachment.pl>

From jmghudson at gmail.com  Tue Jun 10 05:19:26 2008
From: jmghudson at gmail.com (James Hudson)
Date: Mon, 9 Jun 2008 22:19:26 -0500
Subject: [R-sig-ME] help with repeated measures on a split-plot
	experiment
In-Reply-To: <s84cfc79.093@wpo.nerc.ac.uk>
References: <s84cfc79.093@wpo.nerc.ac.uk>
Message-ID: <6c8ca4f00806092019r349ec4c3m7a07dcec40436dd2@mail.gmail.com>

Thank you for the additional advice. Attached are my responses below:


>On Mon, Jun 9, 2008 at 3:48 AM, Mike Dunbar <mdu at ceh.ac.uk> wrote:
>
> Hi Jamess
>
> Just a couple of comments below
>
> regards
>
> Mike
>
>
> >>> "James Hudson" <jmghudson at gmail.com> 09/06/2008 03:29 >>>
> >Dear Mike,
>
> >Thank you very much for the timely, helpful response. My apologies for the
> >delay in responding - I have been in the field.
>
>
> On 5/28/08, Mike Dunbar <mdu at ceh.ac.uk> wrote:
> >
> > Dear James
> >
> > Some quick initial comments.
> >
> > A. You are probably trying to make a much too complex model. I think what
> > you want is:
> >
> > lmer(response ~ snow*warm*year (1|plot), cass))
> >
> > As plot is the only random effect, all the others are fixed.
>
>
> >I appreciate the simplicity of the model you have suggested. After reviewing
> >both Pinheiro & Bates and West, I was initially taking a more rigid approach
> >to developing my model following the examples in the texts.
>
> B. Are you sure there is likely to be a measurable autoregressive structure
> > to the time series data beyond that which is accounted for by the plot
> > random effect. Just looking at the data listing, there are only three years
> > (1995, 2000, 2007), or is this a sub-sample? With only three years, and
> > these not being sequential years, you may be asking too much of your data.
>
>
> > This is not a sub-sample - I only have 3 years of data. I assumed that if I
> >were to include a repeated measures factor in my model, that I'd need to
> >supply a covariance structure.
>
> I don't know if its helpful to consider repeated measures as a special case of a mixed model. The bottom line is if you fit the model with plot as a random effect, can you then see any autocorrelation in the residuals when you plot them? Even if there is truly autocorrelation in the underlying process, you probably can't see it in your data, you'd need to see runs of points through time which were over or under-estimated. Remember that the correlation between times ascribed to them being measured on the same plot is accounted for by the plot random effect: e.g. see the orthodont example in P&B.

Good point. The second observation period is not more correlated with
the 1st or 3rd than the 1st and 3rd are with each other.

> C. I might be missing something but are you really interested in year as a
> > fixed effect? With this included, are there any degrees of freedom left for
> > the residual error, you'll need to get your replication from somewhere. Be
> > warned that lmer does seem to give results even when all dfs are used up by
> > fixed effects and their interactions (I'm not sure why), but you need to be
> > able to judge that you have not fitted a sensible model.
>
>
> > I am interested in change over time so I need "time" as a fixed factor. I
> >can run the model you have suggested as a lme function too but my dfs seem
> > ok for this analysis.
>
> If you can make do with time as a linear function then I think that's OK. I've still got a a feeling that if you have time as a factor then you run out of dfs. If you can post a self-contained example with model and data then others can probably comment if this is the case (I received some great help from the list on this topic about a year ago.
>

Here is my script with data below (including time as a linear function
rather than a factor):
library(nlme)
dataset<-as.data.frame(read.csv("dshrubs.csv", header=TRUE))
attach(dataset)
names(dataset)
model1<-lme(response~date*snow*warm, random =~ 1|plot, data=dataset)
anova(model1)
plot(model1,resid(.)~plot,abline=0)
qqnorm(model1)

date , warm , snow , plot , response
1995 , P , A , 1 , 11
1995 , P , C , 2 , 11
1995 , P , A , 3 , 4
1995 , P , C , 4 , 5
1995 , P , R , 5 , 6
1995 , P , A , 6 , 3
1995 , P , R , 7 , 5
1995 , P , A , 8 , 3
1995 , P , C , 9 , 7
1995 , P , R , 10 , 8
1995 , P , A , 11 , 7
1995 , P , C , 12 , 13
1995 , P , C , 13 , 4
1995 , P , R , 14 , 7
1995 , P , R , 15 , 1
1995 , P , C , 16 , 6
1995 , P , R , 17 , 5
1995 , P , A , 18 , 1
1995 , T , A , 19 , 9
1995 , T , C , 20 , 13
1995 , T , A , 21 , 5
1995 , T , C , 22 , 5
1995 , T , R , 23 , 6
1995 , T , A , 24 , 9
1995 , T , R , 25 , 5
1995 , T , A , 26 , 15
1995 , T , C , 27 , 12
1995 , T , R , 28 , 7
1995 , T , A , 29 , 8
1995 , T , C , 30 , 12
1995 , T , C , 31 , 19
1995 , T , R , 32 , 5
1995 , T , R , 33 , 10
1995 , T , C , 34 , 3
1995 , T , R , 35 , 5
1995 , T , A , 36 , 2
2000 , P , A , 1 , 22
2000 , P , C , 2 , 19
2000 , P , A , 3 , 9
2000 , P , C , 4 , 3
2000 , P , R , 5 , 5
2000 , P , A , 6 , 5
2000 , P , R , 7 , 16
2000 , P , A , 8 , 7
2000 , P , C , 9 , 12
2000 , P , R , 10 , 7
2000 , P , A , 11 , 12
2000 , P , C , 12 , 10
2000 , P , C , 13 , 11
2000 , P , R , 14 , 12
2000 , P , R , 15 , 3
2000 , P , C , 16 , 11
2000 , P , R , 17 , 12
2000 , P , A , 18 , 5
2000 , T , A , 19 , 10
2000 , T , C , 20 , 13
2000 , T , A , 21 , 3
2000 , T , C , 22 , 4
2000 , T , R , 23 , 7
2000 , T , A , 24 , 5
2000 , T , R , 25 , 4
2000 , T , A , 26 , 23
2000 , T , C , 27 , 11
2000 , T , R , 28 , 10
2000 , T , A , 29 , 5
2000 , T , C , 30 , 8
2000 , T , C , 31 , 14
2000 , T , R , 32 , 7
2000 , T , R , 33 , 9
2000 , T , C , 34 , 0
2000 , T , R , 35 , 7
2000 , T , A , 36 , 2
2007 , P , A , 1 , 15
2007 , P , C , 2 , 19
2007 , P , A , 3 , 5
2007 , P , C , 4 , 1
2007 , P , R , 5 , 18
2007 , P , A , 6 , 14
2007 , P , R , 7 , 15
2007 , P , A , 8 , 9
2007 , P , C , 9 , 11
2007 , P , R , 10 , 9
2007 , P , A , 11 , 22
2007 , P , C , 12 , 3
2007 , P , C , 13 , 13
2007 , P , R , 14 , 6
2007 , P , R , 15 , 11
2007 , P , C , 16 , 9
2007 , P , R , 17 , 16
2007 , P , A , 18 , 9
2007 , T , A , 19 , 9
2007 , T , C , 20 , 20
2007 , T , A , 21 , 9
2007 , T , C , 22 , 5
2007 , T , R , 23 , 5
2007 , T , A , 24 , 7
2007 , T , R , 25 , 7
2007 , T , A , 26 , 18
2007 , T , C , 27 , 14
2007 , T , R , 28 , 12
2007 , T , A , 29 , 16
2007 , T , C , 30 , 7
2007 , T , C , 31 , 3
2007 , T , R , 32 , 15
2007 , T , R , 33 , 9
2007 , T , C , 34 , 4
2007 , T , R , 35 , 6
2007 , T , A , 36 , 2

> > cheers
> >
> > Mike
>
>
> > Using this model in an lme function, I have been unable to identify Type
> >III SS rather than Type I. Is there a straightforward way to obtain Type III
> >SS?
>
> In short: have a look at http://www.stats.ox.ac.uk/pub/MASS3/Exegeses.pdf
> Then you might want to look through the main R mailing list where the desirability of Type III sums of squares for aov has been discussed. Others can comment much better on this and why its not such a good idea. It can be done for aov if you really have to, but I don't know for lme: don't forget lme models are not fitted by straightforward least squares.
>
Thank you very much for that piece of advice. I'll stick with Type I SS!
>
>
> --
> This message (and any attachments) is for the recipien...{{dropped:7}}



From h.wickham at gmail.com  Tue Jun 10 06:41:48 2008
From: h.wickham at gmail.com (hadley wickham)
Date: Mon, 9 Jun 2008 23:41:48 -0500
Subject: [R-sig-ME] help with repeated measures on a split-plot
	experiment
In-Reply-To: <6c8ca4f00806092019r349ec4c3m7a07dcec40436dd2@mail.gmail.com>
References: <s84cfc79.093@wpo.nerc.ac.uk>
	<6c8ca4f00806092019r349ec4c3m7a07dcec40436dd2@mail.gmail.com>
Message-ID: <f8e6ff050806092141k10a79590rcae42ca55331bec3@mail.gmail.com>

>> If you can make do with time as a linear function then I think that's OK. I've still got a a feeling that if you have time as a factor then you run out of dfs. If you can post a self-contained example with model and data then others can probably comment if this is the case (I received some great help from the list on this topic about a year ago.
>>
>
> Here is my script with data below (including time as a linear function
> rather than a factor):
> library(nlme)
> dataset<-as.data.frame(read.csv("dshrubs.csv", header=TRUE))
> attach(dataset)
> names(dataset)
> model1<-lme(response~date*snow*warm, random =~ 1|plot, data=dataset)
> anova(model1)
> plot(model1,resid(.)~plot,abline=0)
> qqnorm(model1)

I'd suggest you start with some good explanatory plots:

install.packages("ggplot2")
library(ggplot2)
qplot(date, response, data=shrubs, colour = warm, group=plot,
geom=c("line", "point"), facets = snow ~ .)

This seems revealing to me: not much going on, with the possible
exception of snow = "R", which has a lower variance and a slight
upward trend, particularly for warm = P.  Group-wise linear models
support this interpretation:

qplot(date, response, data=shrubs, colour = warm, geom="point", facets
= snow ~ .) +
geom_smooth(method=lm)

Although if the group-level variances truly are equal, you will get
more power from the mixed effects model.

Hadley


-- 
http://had.co.nz/



From reinhold.kliegl at gmail.com  Tue Jun 10 10:59:31 2008
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Tue, 10 Jun 2008 10:59:31 +0200
Subject: [R-sig-ME] help with repeated measures on a split-plot
	experiment
In-Reply-To: <f8e6ff050806092141k10a79590rcae42ca55331bec3@mail.gmail.com>
References: <s84cfc79.093@wpo.nerc.ac.uk>
	<6c8ca4f00806092019r349ec4c3m7a07dcec40436dd2@mail.gmail.com>
	<f8e6ff050806092141k10a79590rcae42ca55331bec3@mail.gmail.com>
Message-ID: <aefe4d0a0806100159k121c1126n3252a0024c9845e0@mail.gmail.com>

Hi,

Nice example, also to contrast with standard repeated-measures ANOVA,
plot of significant interactions with ggplot, and use of contrasts.
What, by the way, are three levels of snow?

library(lme4, lib.loc=.libUsr)
library(ggplot2)

shrubs<-as.data.frame(read.csv("dshrubs.csv", header=TRUE))
shrubs$plot <- as.factor(shrubs$plot)
shrubs$year <- as.factor(shrubs$date)
contrasts(shrubs$year) <- contr.poly

# standard repeated-measures ANOVA for this balanced design: shows
significant interaction of year x warm
summary(model0 <- aov(response ~  year*snow*warm + Error(plot/year),
data=shrubs))

# lmer equivalen, with polynomial contrasts for year and treatment
contrast for snow (reference=A)
print(model1<-lmer(response~ year*snow*warm + (1|plot), method="ML",
data=shrubs), cor=FALSE)

# Using only linear trend of year
shrubs$yearL <- as.numeric(as.character(shrubs$year))-2000  # center
at year 2000
print(model2<-lmer(response~yearL*snow*warm  + (1|plot), method="ML",
data=shrubs), cor=FALSE)

# dropping 3-factor interactions, clearly suggests two significant
interactions with year
print(model3<-lmer(response~(yearL+snow+warm)^2  + (1|plot),
method="ML", data=shrubs), cor=FALSE)
anova(model1, model2, model3)

# plot two significant interactions
shrubs.rs <- melt(shrubs, id=c("plot", "yearL", "warm", "snow"),
measure="response")

# (1) year x temperature
table<-cast(shrubs.rs, yearL+warm ~ .,
	   function(x) c(M=mean(x), SE=sd(x)/sqrt(length(x)), N=length(x) ))
p <- qplot(x=yearL, y=M, data=table, shape=warm, colour=warm) +
scale_x_continuous("Year", breaks=c(-5, 0, 7), labels=c("1995",
"2000", "2007"))
p <- p  + geom_point(size=3) + geom_line(aes(group=warm), size=1) +
geom_errorbar(aes(max=M+SE, min=M-SE), width=0.1)
p

# (2) year x snow
table<-cast(shrubs.rs, yearL+snow ~ .,
	   function(x) c(M=mean(x), SE=sd(x)/sqrt(length(x)), N=length(x) ))
p <- qplot(x=yearL, y=M, data=table, shape=snow, colour=snow) +
scale_x_continuous("Year", breaks=c(-5, 0, 7), labels=c("1995",
"2000", "2007"))
p <- p  + geom_point(size=3) + geom_line(aes(group=snow), size=1) +
geom_errorbar(aes(max=M+SE, min=M-SE), width=0.1)
p

# Options on factor snow (tailored to pattern of means; should ideally
be specified a priori)
# ... refit lmer model with helmert contrasts for snow: (1) c vs. a+r;
(2) a vs. r
shrubs$snowH <- C(shrubs$snow, matrix(c(-1, +2, -1,    -1,  0, +1), 3, 2), 2)
contrasts(shrubs$snowH)
print(model4<-lmer(response~(yearL+snowH+warm)^2  + (1|plot),
method="ML", data=shrubs), cor=FALSE)

# ... refit lmer model with treatment contrasts for snow using C as
reference: (1) c vs. a+r; (2) a vs. r
shrubs$snowC <- C(shrubs$snow, matrix(c(1, 0, 0,     0, 0, 1), 3, 2), 2)
contrasts(shrubs$snowC)
print(model5<-lmer(response~(yearL+snowC+warm)^2  + (1|plot),
method="ML", data=shrubs), cor=FALSE)

# re-specification of snow factor does not change overall goodness of fit
anova(model3, model4, model5)

# check for reliable between-plot variance for linear effect of year;
switch from full ML to restricted ML
print(model5.REML<-lmer(response~(yearL+snowC+warm)^2  + (1|plot),
method="REML", data=shrubs), cor=FALSE)
print(model6.REML<-lmer(response~(yearL+snowC+warm)^2  + (yearL|plot),
method="REML", data=shrubs), cor=FALSE)
anova(model5.REML, model6.REML)  # not statistically reliable

Reinhold Kliegl

On Tue, Jun 10, 2008 at 6:41 AM, hadley wickham <h.wickham at gmail.com> wrote:
>>> If you can make do with time as a linear function then I think that's OK. I've still got a a feeling that if you have time as a factor then you run out of dfs. If you can post a self-contained example with model and data then others can probably comment if this is the case (I received some great help from the list on this topic about a year ago.
>>>
>>
>> Here is my script with data below (including time as a linear function
>> rather than a factor):
>> library(nlme)
>> dataset<-as.data.frame(read.csv("dshrubs.csv", header=TRUE))
>> attach(dataset)
>> names(dataset)
>> model1<-lme(response~date*snow*warm, random =~ 1|plot, data=dataset)
>> anova(model1)
>> plot(model1,resid(.)~plot,abline=0)
>> qqnorm(model1)
>
> I'd suggest you start with some good explanatory plots:
>
> install.packages("ggplot2")
> library(ggplot2)
> qplot(date, response, data=shrubs, colour = warm, group=plot,
> geom=c("line", "point"), facets = snow ~ .)
>
> This seems revealing to me: not much going on, with the possible
> exception of snow = "R", which has a lower variance and a slight
> upward trend, particularly for warm = P.  Group-wise linear models
> support this interpretation:
>
> qplot(date, response, data=shrubs, colour = warm, geom="point", facets
> = snow ~ .) +
> geom_smooth(method=lm)
>
> Although if the group-level variances truly are equal, you will get
> more power from the mixed effects model.
>
> Hadley
>
>
> --
> http://had.co.nz/
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From reinhold.kliegl at gmail.com  Tue Jun 10 12:26:49 2008
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Tue, 10 Jun 2008 12:26:49 +0200
Subject: [R-sig-ME] Question on lmer use and commands
In-Reply-To: <OFA7027752.90983A29-ON88257463.006AA317-88257463.00768FF2@usgs.gov>
References: <OFA7027752.90983A29-ON88257463.006AA317-88257463.00768FF2@usgs.gov>
Message-ID: <aefe4d0a0806100326q7611cca8g1a3cb914d070182f@mail.gmail.com>

On Mon, Jun 9, 2008 at 11:35 PM, Peter S Coates <pcoates at usgs.gov> wrote:
> To R users,
>
> I am new to R and would appreciate any suggestions to my questions. I am
> modeling factors that influence point counts. My question is regarding the
> use and command lines of lmer. First, I have repeated measures per site
> (10-20 per site),  multiple years, and multiple spatial scales of each
> factor. The counts by day are different within each site but the
> explanatory data are the same and therefore do not vary (e.g., % cover). I
> have few sites with no overlap, even at the largest scales. I followed an
> example of mixed model use with longitudinal data from Faraway 2005 and
> modeled site and year as random effects. Example of my formula was:
> log(response) ~ hab1 + hab2 + (1 | year) + (1 | site). The models
> converged, no warnings, etc. Was this an appropriate model for these data?
> Also, do you suggest including a time component (e.g., timing of surveys
> partitioned into grouped days) , even though I am not necessarily
> interested in timing effects? If so, is it correct to model it as
> (time|site) instead of (1|time) and does time need to be additionally
> included as a fixed effect? Thank you very much for suggestions.
>
How does your time factor relate to year and site? For example, is it
nested within or crossed with year and site? How many units are in
your  random factors year, site, and (possibly) time?

The specification  "... + (time|site)" assumes that the size of the
time effect varies across sites. Typically, you will use this
specification if there are only a few levels of time (or if you can
use a few polynomial trends to summarize its effect). In this case,
the general recommendation is to include it also as a fixed effect.
This gives you the average effect of time plus the variance associated
of with the effect of time between sites around the fixed effect.

The specification " ... + (1|time)" assumes you have randomly sampled
the times, ideally each of many times many times. In this case, you
would normally not include it as fixed effect.

These are approximate answers only; there are probably better
specifications for your data, but they would require that you tell us
more details about your design.

Reinhold Kliegl



From kjbeath at kagi.com  Tue Jun 10 12:42:09 2008
From: kjbeath at kagi.com (Ken Beath)
Date: Tue, 10 Jun 2008 20:42:09 +1000
Subject: [R-sig-ME] Question on lmer use and commands
In-Reply-To: <OFA7027752.90983A29-ON88257463.006AA317-88257463.00768FF2@usgs.gov>
References: <OFA7027752.90983A29-ON88257463.006AA317-88257463.00768FF2@usgs.gov>
Message-ID: <5F42D6C1-6995-4FBF-B765-06133B92A196@kagi.com>

On 10/06/2008, at 7:35 AM, Peter S Coates wrote:

> To R users,
>
> I am new to R and would appreciate any suggestions to my questions.  
> I am
> modeling factors that influence point counts. My question is  
> regarding the
> use and command lines of lmer. First, I have repeated measures per  
> site
> (10-20 per site),  multiple years, and multiple spatial scales of each
> factor. The counts by day are different within each site but the
> explanatory data are the same and therefore do not vary (e.g., %  
> cover). I
> have few sites with no overlap, even at the largest scales. I  
> followed an
> example of mixed model use with longitudinal data from Faraway 2005  
> and
> modeled site and year as random effects. Example of my formula was:
> log(response) ~ hab1 + hab2 + (1 | year) + (1 | site). The models
> converged, no warnings, etc. Was this an appropriate model for these  
> data?
> Also, do you suggest including a time component (e.g., timing of  
> surveys
> partitioned into grouped days) , even though I am not necessarily
> interested in timing effects? If so, is it correct to model it as
> (time|site) instead of (1|time) and does time need to be additionally
> included as a fixed effect? Thank you very much for suggestions.
>

You haven't fully described your model. Usually for this data it would  
be either a Poisson or overdispersed Poisson, set using the family  
parameter, then the log transform of the response isn't required.

I would also be worried about the relatively small value of the hab2  
parameter estimate. This usually means that something is setup  
wrongly. Including the commands used and a few lines of data helps.

Ken


> Models and output are:
>
> Without including time (date of survey):
>
> r mixed-effects model fit by REML
> Formula: log(response) ~ hab1 + hab2 + (1 | year) + (1 | site)
>   Data: data
> AIC   BIC logLik MLdeviance REMLdeviance
> 177 192.1  -83.5      148.1          167
> Random effects:
> Groups   Name        Variance  Std.Dev.
> site     (Intercept) 0.1378352 0.371262
> year     (Intercept) 0.0023579 0.048558
> Residual             0.1180495 0.343583
>
>
> Fixed effects:
>              Estimate Std. Error t value
> (Intercept)  8.666e+00  1.031e+00   8.402
> hab1        -4.213e+00  1.194e+00  -3.527
> hab2        -3.100e-05  4.463e-05  -0.695
>
> Correlation of Fixed Effects:
>     (Intr) hab1
> hab1 -0.992
> hab2 -0.229  0.149
>
> With time (no time fixed effect):
>
> r mixed-effects model fit by REML
> Formula: log(response) ~ hab1 + hab2 + (1 | year) + (time | site)
>   Data: data
>   AIC   BIC logLik MLdeviance REMLdeviance
> 168.1 189.2 -77.07      134.9        154.1
> Random effects:
> Groups   Name        Variance   Std.Dev. Corr
> site     (Intercept) 0.16295061 0.403671
>          time        0.02118839 0.145562 -0.523
> year     (Intercept) 0.00055594 0.023578
> Residual             0.09299733 0.304955
>
>
> Fixed effects:
>              Estimate Std. Error t value
> (Intercept)  8.079e+00  1.006e+00   8.028
> hab1        -3.643e+00  1.162e+00  -3.136
> hab2        -2.391e-05  4.331e-05  -0.552
>
> Correlation of Fixed Effects:
>     (Intr) hab1
> hab1 -0.993
> hab2 -0.243  0.163
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From jmghudson at gmail.com  Tue Jun 10 15:56:44 2008
From: jmghudson at gmail.com (James Hudson)
Date: Tue, 10 Jun 2008 08:56:44 -0500
Subject: [R-sig-ME] help with repeated measures on a split-plot
	experiment
In-Reply-To: <aefe4d0a0806100159k121c1126n3252a0024c9845e0@mail.gmail.com>
References: <s84cfc79.093@wpo.nerc.ac.uk>
	<6c8ca4f00806092019r349ec4c3m7a07dcec40436dd2@mail.gmail.com>
	<f8e6ff050806092141k10a79590rcae42ca55331bec3@mail.gmail.com>
	<aefe4d0a0806100159k121c1126n3252a0024c9845e0@mail.gmail.com>
Message-ID: <6c8ca4f00806100656r1731750bl96c66c9146e297e5@mail.gmail.com>

Thank you Thierry, Reinhold and Hadley for the comments. The graphic
plots are extremely helpful.

Here's more about the experiment:
The data comes from a simulated climate change experiment where we
measured arctic tundra vegetation in 1m2 plots over time. Warm "P"=
non-warmed, Warm "T" = warmed. Snow "A" = "decrease growing season
length, Snow "R" = increase growing season length, Snow "C" = no
manipulation. The dataset provided (for deciduous shrubs) is just one
of about 15 we have for different vegetation classes. I will use the
same code for each class.

Two design questions:

A. Like I mentioned above, I want to re-use this code repeatedly. Are
there methodological issues with repeating these univariate analyses?
Afterwards, I will also conduct other community-level analyses such as
adonis.

B. There was an error in the dataset I posted previously. When the
experiment was set-up, the 36 plots were spatially paired. Each pair
consisted of a warmed and non-warmed plot (with one Snow level). I
should have labelled the plots 1-18 x2 rather than 1-36. Correct?

Here's the updated dataset:
date , warm , snow , plot , response
1995 , P , A , 1 , 11
1995 , P , C , 2 , 11
1995 , P , A , 3 , 4
1995 , P , C , 4 , 5
1995 , P , R , 5 , 6
1995 , P , A , 6 , 3
1995 , P , R , 7 , 5
1995 , P , A , 8 , 3
1995 , P , C , 9 , 7
1995 , P , R , 10 , 8
1995 , P , A , 11 , 7
1995 , P , C , 12 , 13
1995 , P , C , 13 , 4
1995 , P , R , 14 , 7
1995 , P , R , 15 , 1
1995 , P , C , 16 , 6
1995 , P , R , 17 , 5
1995 , P , A , 18 , 1
1995 , T , A , 1 , 9
1995 , T , C , 2 , 13
1995 , T , A , 3 , 5
1995 , T , C , 4 , 5
1995 , T , R , 5 , 6
1995 , T , A , 6 , 9
1995 , T , R , 7 , 5
1995 , T , A , 8 , 15
1995 , T , C , 9 , 12
1995 , T , R , 10 , 7
1995 , T , A , 11 , 8
1995 , T , C , 12 , 12
1995 , T , C , 13 , 19
1995 , T , R , 14 , 5
1995 , T , R , 15 , 10
1995 , T , C , 16 , 3
1995 , T , R , 17 , 5
1995 , T , A , 18 , 2
2000 , P , A , 1 , 22
2000 , P , C , 2 , 19
2000 , P , A , 3 , 9
2000 , P , C , 4 , 3
2000 , P , R , 5 , 5
2000 , P , A , 6 , 5
2000 , P , R , 7 , 16
2000 , P , A , 8 , 7
2000 , P , C , 9 , 12
2000 , P , R , 10 , 7
2000 , P , A , 11 , 12
2000 , P , C , 12 , 10
2000 , P , C , 13 , 11
2000 , P , R , 14 , 12
2000 , P , R , 15 , 3
2000 , P , C , 16 , 11
2000 , P , R , 17 , 12
2000 , P , A , 18 , 5
2000 , T , A , 1 , 10
2000 , T , C , 2 , 13
2000 , T , A , 3 , 3
2000 , T , C , 4 , 4
2000 , T , R , 5 , 7
2000 , T , A , 6 , 5
2000 , T , R , 7 , 4
2000 , T , A , 8 , 23
2000 , T , C , 9 , 11
2000 , T , R , 10 , 10
2000 , T , A , 11 , 5
2000 , T , C , 12 , 8
2000 , T , C , 13 , 14
2000 , T , R , 14 , 7
2000 , T , R , 15 , 9
2000 , T , C , 16 , 0
2000 , T , R , 17 , 7
2000 , T , A , 18 , 2
2007 , P , A , 1 , 15
2007 , P , C , 2 , 19
2007 , P , A , 3 , 5
2007 , P , C , 4 , 1
2007 , P , R , 5 , 18
2007 , P , A , 6 , 14
2007 , P , R , 7 , 15
2007 , P , A , 8 , 9
2007 , P , C , 9 , 11
2007 , P , R , 10 , 9
2007 , P , A , 11 , 22
2007 , P , C , 12 , 3
2007 , P , C , 13 , 13
2007 , P , R , 14 , 6
2007 , P , R , 15 , 11
2007 , P , C , 16 , 9
2007 , P , R , 17 , 16
2007 , P , A , 18 , 9
2007 , T , A , 1 , 9
2007 , T , C , 2 , 20
2007 , T , A , 3 , 9
2007 , T , C , 4 , 5
2007 , T , R , 5 , 5
2007 , T , A , 6 , 7
2007 , T , R , 7 , 7
2007 , T , A , 8 , 18
2007 , T , C , 9 , 14
2007 , T , R , 10 , 12
2007 , T , A , 11 , 16
2007 , T , C , 12 , 7
2007 , T , C , 13 , 3
2007 , T , R , 14 , 15
2007 , T , R , 15 , 9
2007 , T , C , 16 , 4
2007 , T , R , 17 , 6
2007 , T , A , 18 , 2



On Tue, Jun 10, 2008 at 3:59 AM, Reinhold Kliegl
<reinhold.kliegl at gmail.com> wrote:
> Hi,
>
> Nice example, also to contrast with standard repeated-measures ANOVA,
> plot of significant interactions with ggplot, and use of contrasts.
> What, by the way, are three levels of snow?
>
> library(lme4, lib.loc=.libUsr)
> library(ggplot2)
>
> shrubs<-as.data.frame(read.csv("dshrubs.csv", header=TRUE))
> shrubs$plot <- as.factor(shrubs$plot)
> shrubs$year <- as.factor(shrubs$date)
> contrasts(shrubs$year) <- contr.poly
>
> # standard repeated-measures ANOVA for this balanced design: shows
> significant interaction of year x warm
> summary(model0 <- aov(response ~  year*snow*warm + Error(plot/year),
> data=shrubs))
>
> # lmer equivalen, with polynomial contrasts for year and treatment
> contrast for snow (reference=A)
> print(model1<-lmer(response~ year*snow*warm + (1|plot), method="ML",
> data=shrubs), cor=FALSE)
>
> # Using only linear trend of year
> shrubs$yearL <- as.numeric(as.character(shrubs$year))-2000  # center
> at year 2000
> print(model2<-lmer(response~yearL*snow*warm  + (1|plot), method="ML",
> data=shrubs), cor=FALSE)
>
> # dropping 3-factor interactions, clearly suggests two significant
> interactions with year
> print(model3<-lmer(response~(yearL+snow+warm)^2  + (1|plot),
> method="ML", data=shrubs), cor=FALSE)
> anova(model1, model2, model3)
>
> # plot two significant interactions
> shrubs.rs <- melt(shrubs, id=c("plot", "yearL", "warm", "snow"),
> measure="response")
>
> # (1) year x temperature
> table<-cast(shrubs.rs, yearL+warm ~ .,
>           function(x) c(M=mean(x), SE=sd(x)/sqrt(length(x)), N=length(x) ))
> p <- qplot(x=yearL, y=M, data=table, shape=warm, colour=warm) +
> scale_x_continuous("Year", breaks=c(-5, 0, 7), labels=c("1995",
> "2000", "2007"))
> p <- p  + geom_point(size=3) + geom_line(aes(group=warm), size=1) +
> geom_errorbar(aes(max=M+SE, min=M-SE), width=0.1)
> p
>
> # (2) year x snow
> table<-cast(shrubs.rs, yearL+snow ~ .,
>           function(x) c(M=mean(x), SE=sd(x)/sqrt(length(x)), N=length(x) ))
> p <- qplot(x=yearL, y=M, data=table, shape=snow, colour=snow) +
> scale_x_continuous("Year", breaks=c(-5, 0, 7), labels=c("1995",
> "2000", "2007"))
> p <- p  + geom_point(size=3) + geom_line(aes(group=snow), size=1) +
> geom_errorbar(aes(max=M+SE, min=M-SE), width=0.1)
> p
>
> # Options on factor snow (tailored to pattern of means; should ideally
> be specified a priori)
> # ... refit lmer model with helmert contrasts for snow: (1) c vs. a+r;
> (2) a vs. r
> shrubs$snowH <- C(shrubs$snow, matrix(c(-1, +2, -1,    -1,  0, +1), 3, 2), 2)
> contrasts(shrubs$snowH)
> print(model4<-lmer(response~(yearL+snowH+warm)^2  + (1|plot),
> method="ML", data=shrubs), cor=FALSE)
>
> # ... refit lmer model with treatment contrasts for snow using C as
> reference: (1) c vs. a+r; (2) a vs. r
> shrubs$snowC <- C(shrubs$snow, matrix(c(1, 0, 0,     0, 0, 1), 3, 2), 2)
> contrasts(shrubs$snowC)
> print(model5<-lmer(response~(yearL+snowC+warm)^2  + (1|plot),
> method="ML", data=shrubs), cor=FALSE)
>
> # re-specification of snow factor does not change overall goodness of fit
> anova(model3, model4, model5)
>
> # check for reliable between-plot variance for linear effect of year;
> switch from full ML to restricted ML
> print(model5.REML<-lmer(response~(yearL+snowC+warm)^2  + (1|plot),
> method="REML", data=shrubs), cor=FALSE)
> print(model6.REML<-lmer(response~(yearL+snowC+warm)^2  + (yearL|plot),
> method="REML", data=shrubs), cor=FALSE)
> anova(model5.REML, model6.REML)  # not statistically reliable
>
> Reinhold Kliegl
>
> On Tue, Jun 10, 2008 at 6:41 AM, hadley wickham <h.wickham at gmail.com> wrote:
>>>> If you can make do with time as a linear function then I think that's OK. I've still got a a feeling that if you have time as a factor then you run out of dfs. If you can post a self-contained example with model and data then others can probably comment if this is the case (I received some great help from the list on this topic about a year ago.
>>>>
>>>
>>> Here is my script with data below (including time as a linear function
>>> rather than a factor):
>>> library(nlme)
>>> dataset<-as.data.frame(read.csv("dshrubs.csv", header=TRUE))
>>> attach(dataset)
>>> names(dataset)
>>> model1<-lme(response~date*snow*warm, random =~ 1|plot, data=dataset)
>>> anova(model1)
>>> plot(model1,resid(.)~plot,abline=0)
>>> qqnorm(model1)
>>
>> I'd suggest you start with some good explanatory plots:
>>
>> install.packages("ggplot2")
>> library(ggplot2)
>> qplot(date, response, data=shrubs, colour = warm, group=plot,
>> geom=c("line", "point"), facets = snow ~ .)
>>
>> This seems revealing to me: not much going on, with the possible
>> exception of snow = "R", which has a lower variance and a slight
>> upward trend, particularly for warm = P.  Group-wise linear models
>> support this interpretation:
>>
>> qplot(date, response, data=shrubs, colour = warm, geom="point", facets
>> = snow ~ .) +
>> geom_smooth(method=lm)
>>
>> Although if the group-level variances truly are equal, you will get
>> more power from the mixed effects model.
>>
>> Hadley
>>
>>
>> --
>> http://had.co.nz/
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>



From reinhold.kliegl at gmail.com  Tue Jun 10 17:24:00 2008
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Tue, 10 Jun 2008 17:24:00 +0200
Subject: [R-sig-ME] help with repeated measures on a split-plot
	experiment
In-Reply-To: <6c8ca4f00806100656r1731750bl96c66c9146e297e5@mail.gmail.com>
References: <s84cfc79.093@wpo.nerc.ac.uk>
	<6c8ca4f00806092019r349ec4c3m7a07dcec40436dd2@mail.gmail.com>
	<f8e6ff050806092141k10a79590rcae42ca55331bec3@mail.gmail.com>
	<aefe4d0a0806100159k121c1126n3252a0024c9845e0@mail.gmail.com>
	<6c8ca4f00806100656r1731750bl96c66c9146e297e5@mail.gmail.com>
Message-ID: <aefe4d0a0806100824q18ff4b7od038895d23857faf@mail.gmail.com>

On Tue, Jun 10, 2008 at 3:56 PM, James Hudson <jmghudson at gmail.com> wrote:
> Thank you Thierry, Reinhold and Hadley for the comments. The graphic
> plots are extremely helpful.
>
> Here's more about the experiment:
> The data comes from a simulated climate change experiment where we
> measured arctic tundra vegetation in 1m2 plots over time. Warm "P"=
> non-warmed, Warm "T" = warmed. Snow "A" = "decrease growing season
> length, Snow "R" = increase growing season length, Snow "C" = no
> manipulation. The dataset provided (for deciduous shrubs) is just one
> of about 15 we have for different vegetation classes. I will use the
> same code for each class.

So using C-level of snow as reference in a treatment contrast is
justified a-priori; also the Helmert contrast. But why does both
decreasing and increasing the growing season increase your response
linearly over the years? And why would you get a stronger increase
over the years for non-warmed  (P) than warmed (T) plots?

>
> Two design questions:
>
> A. Like I mentioned above, I want to re-use this code repeatedly. Are
> there methodological issues with repeating these univariate analyses?

Why would you want to do this? You can easily include the data from
the 15 different vegation classes in one analysis and use the full
statistical power of your design. This will provide you with important
additional information. For example,  in such an analyses you can test
differences between clusters of vegetation classes that you would
cluster together (i.e., by using contrasts on the factor veg. class).
If you are not interested in differences between vegetation classes,
you could specify it as another random factor. Then "plot" can be
specified as nested within vegetation class or as crossed with it and
you can estimate the variances of these factors as well as the
variances of effects associated with them. I would recommend to do a
bit of reading on this matter. (For presentation of results, it may be
useful to run the 15 separate analyses, too.)

> Afterwards, I will also conduct other community-level analyses such as
> adonis.
Not sure what this means.

>
> B. There was an error in the dataset I posted previously. When the
> experiment was set-up, the 36 plots were spatially paired. Each pair
> consisted of a warmed and non-warmed plot (with one Snow level). I
> should have labelled the plots 1-18 x2 rather than 1-36. Correct?
>
Correct.
In this case, the repeated-measures anova statement  must be changed
to take this into consideration

summary(model0 <- aov(response ~  year*snow*warm +
Error(plot/(year*warm)), data=shrubs))

lmer figures it out by itself. The mean plots will change in the
standard errors because I computed them after aggregating to the plot
level.

Now you can also test wether there is reliable variance in the
warm-effect between plots. It turns out, there is:

> print(model7.REML<-lmer(response~(year.L+snow.C+warm)^2  + (warm|plot), method="REML", data=shrubs), cor=FALSE)
Linear mixed model fit by REML
Formula: response ~ (year.L + snow.C + warm)^2 + (warm | plot)
   Data: shrubs
   AIC   BIC logLik deviance REMLdev
 638.7 676.2 -305.3      618   610.7
Random effects:
 Groups   Name        Variance Std.Dev. Corr
 plot     (Intercept) 10.998   3.3163
          warm T      16.402   4.0499   -0.429
 Residual             12.402   3.5216
Number of obs: 108, groups: plot, 18

Fixed effects:
                Estimate Std. Error t value
(Intercept)       9.2260     1.5907   5.800
year.L            0.1609     0.1377   1.169
snow.C1          -0.5507     2.2487  -0.245
snow.C2          -0.6121     2.2487  -0.272
warm T            0.1748     2.0298   0.086
year.L:snow.C1    0.4094     0.1687   2.427
year.L:snow.C2    0.4182     0.1687   2.480
year.L:warm T    -0.3456     0.1377  -2.509
snow.C1:warm T   -0.2778     2.8676  -0.097
snow.C2:warm T   -1.3889     2.8676  -0.484
> anova(model5.REML, model7.REML)  # not statistically reliable
Data: shrubs
Models:
model5.REML: response ~ (year.L + snow.C + warm)^2 + (1 | plot)
model7.REML: response ~ (year.L + snow.C + warm)^2 + (warm | plot)
            Df     AIC     BIC  logLik  Chisq Chi Df Pr(>Chisq)
model5.REML 12  650.24  682.42 -313.12
model7.REML 14  645.95  683.50 -308.98 8.2811      2    0.01591 *
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1



From h.wickham at gmail.com  Tue Jun 10 17:47:14 2008
From: h.wickham at gmail.com (hadley wickham)
Date: Tue, 10 Jun 2008 10:47:14 -0500
Subject: [R-sig-ME] Question on lmer use and commands
In-Reply-To: <OFA7027752.90983A29-ON88257463.006AA317-88257463.00768FF2@usgs.gov>
References: <OFA7027752.90983A29-ON88257463.006AA317-88257463.00768FF2@usgs.gov>
Message-ID: <f8e6ff050806100847h41b5e7e0ob78dd8d9ad029843@mail.gmail.com>

> I am new to R and would appreciate any suggestions to my questions. I am
> modeling factors that influence point counts. My question is regarding the
> use and command lines of lmer. First, I have repeated measures per site
> (10-20 per site),  multiple years, and multiple spatial scales of each
> factor. The counts by day are different within each site but the
> explanatory data are the same and therefore do not vary (e.g., % cover). I
> have few sites with no overlap, even at the largest scales. I followed an
> example of mixed model use with longitudinal data from Faraway 2005 and
> modeled site and year as random effects. Example of my formula was:
> log(response) ~ hab1 + hab2 + (1 | year) + (1 | site). The models
> converged, no warnings, etc. Was this an appropriate model for these data?

What are you trying to do with the model?  Are you interested in
effects over time?  Once you have the model what will you do with it?

What did your exploratory graphics look like?  If you didn't do any,
here are some to get you started:

# Show the path of each site through the 2d covariate space over time
# - are the sites all pretty similar?  are they all different?
# - if there are clusters, you might want to create a categorical variable
# that identifies them
# - are hab1 and hab2 correlated?
qplot(hab1, hab2, data=mydata, geom="path", group = site)

# Show how time varies by site and year
qplot(time, site, data=mydata, facets =  . ~ year)


# Show the trend in response over time
qplot(log(response), year, data=mydata, geom="line", group=site)
qplot(log(response), year, data=mydata, geom="line", group=site) +
geom_point(aes(colour = hab1))
qplot(log(response), year, data=mydata, geom="line", group=site) +
geom_point(aes(colour = hab2))


Hadley

-- 
http://had.co.nz/



From Mpavlou at gum.ucl.ac.uk  Wed Jun 11 12:24:32 2008
From: Mpavlou at gum.ucl.ac.uk (Pavlou, Menelaos)
Date: Wed, 11 Jun 2008 11:24:32 +0100
Subject: [R-sig-ME] Special case for random effects models lmer or lme?
Message-ID: <ECA6284E11B79E4988B99D5E4ADFC50401F57CAF@acadexchange1.ucl.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080611/54698f0c/attachment.pl>

From albertp at CTEP.NCI.NIH.gov  Wed Jun 11 16:03:22 2008
From: albertp at CTEP.NCI.NIH.gov (Albert, Paul (NIH/NCI) [E])
Date: Wed, 11 Jun 2008 10:03:22 -0400
Subject: [R-sig-ME] Is VarCorr different in R and Splus
Message-ID: <106582DF6F1C374A90BA49FEAA651022020D0497@NIHCESMLBX11.nih.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080611/94c121f2/attachment.pl>

From bates at stat.wisc.edu  Wed Jun 11 17:34:22 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 11 Jun 2008 10:34:22 -0500
Subject: [R-sig-ME] Special case for random effects models lmer or lme?
In-Reply-To: <ECA6284E11B79E4988B99D5E4ADFC50401F57CAF@acadexchange1.ucl.ac.uk>
References: <ECA6284E11B79E4988B99D5E4ADFC50401F57CAF@acadexchange1.ucl.ac.uk>
Message-ID: <40e66e0b0806110834t82c8ffejca339a74d58714c5@mail.gmail.com>

On Wed, Jun 11, 2008 at 5:24 AM, Pavlou, Menelaos <Mpavlou at gum.ucl.ac.uk> wrote:
> Hi all,

> The problem I want to solve is as follows. Suppose that we have repeated
> measurements per cluster. Y is the outcome variable, x is a single binary
> covariate cluster constant, id represents each cluster  and we have an
> unbalanced design of the following form and arbitrary number of clusters

> Y         x     id
> Y_11     1      1
> Y_12     1      1
> Y_13     1      1
> Y_14     1      1
> Y_21     0      2
> Y_22     0      2
> Y_23     0      2
> Y_24     0      2
> Y_25     0      2
> Y_26     0      2
>  ....    ....    ....

> where Y_jj respresents the jth measurement I the ith cluster. The first
> impression is that a simple model of the form

> Yij=beta_0+ b_i +beta_1x_i +epsilon_ij,     bi~N(0,sigmab^2)
> would suffice.

> However a special feature of the data renders this model inappropriate:
> There seems to be a connection between  the cluster size and the outcome Y
> which is not capture fully by the model above. So what I want to do is to
> "pretend" that there are some "super clusters"  at the top level for some
> groups of cluster sizes. For example :

> cluster sizes (and clusters...)    "super cluster "
> 1-3                                                  1
> 4-6                                                  2
> 7-10                                                3

> What I want to do is to fit a model with different random effects for each
> super cluster (denoted by the indicator k, so the measurements would now be
> of the form Y_ijk)

Your description seems different from the formula below.  Do you mean
"different random effects" or "different variances of the random
effects" for each super cluster? In the first case you can use nested
random effects, one level of random effects for cluster and one level
for super cluster.  In the second case I think you would need to fit
the model with lme to get the different variances.

> The model I imagine would then be of the form

> Yijk=beta_0+ b_ik +beta_1x_i +epsilon_ijk,     bik~N(0,sigmab_k^2)

> So for each super cluster include a different random effect that *could*
> capture  the association above.

> I haven't managed to fit such a model in R using lmer or lme, nor to find a
> similar case in the help archives so I would be grateful if anybody could
> help.



From ullrich.ecker at uwa.edu.au  Fri Jun 13 04:25:22 2008
From: ullrich.ecker at uwa.edu.au (Ullrich Ecker)
Date: Fri, 13 Jun 2008 10:25:22 +0800
Subject: [R-sig-ME] more than 2 within-subjects factors in lme(r)
Message-ID: <20080613022522.812AB87807@panacea.ucs.uwa.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080613/24b1ec0d/attachment.pl>

From bates at stat.wisc.edu  Fri Jun 13 20:02:48 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 13 Jun 2008 13:02:48 -0500
Subject: [R-sig-ME] more than 2 within-subjects factors in lme(r)
In-Reply-To: <20080613022522.812AB87807@panacea.ucs.uwa.edu.au>
References: <20080613022522.812AB87807@panacea.ucs.uwa.edu.au>
Message-ID: <40e66e0b0806131102g74aae5n3069edfb98f3bb68@mail.gmail.com>

On Thu, Jun 12, 2008 at 9:25 PM, Ullrich Ecker <ullrich.ecker at uwa.edu.au> wrote:
> Dear expeRts,

> I am facing some problems with lme with 3 fixed within-subjects
> factors (S, R, T) to be followed up by a post-hoc test.

> Each of the 3 factors can be 0 or 1 (in fact, all 3 could be 0, so
> there are 8 conditions).

> I know how to do this with an 8-level condition factor:

> require(nlme)         ## for lme()
> require(multcomp)     ## for multiple comparison stuff
> RT.aov <- aov(RT ~ Condition + Error(Subject/Condition), Data)
> RT.lme <- lme(RT ~ Condition, random = ~1 | Subject/Condition, Data)
> summary(glht(RT.lme, linfct=mcp(Condition="Tukey")))

> but I am unable to get lme to work with 3 factors despite trying to
> use some hints provided in the archives.

> The lme solution should be equivalent to:

> RT.aov <- aov(RT ~ S*R*T + Error(Subject / (S*R*T)), Data)

> and then I want to do:

> RT.lme <- lme(RT ~ S*R*T ---THE GAP---)

Well, I can tell you about fitting the model.  I'm not really sure
what the multiple comparisons code below does so someone else will
need to comment.

I find it easier to express the model in the lmer syntax as

Rt.lmer <- lmer(RT ~ S * R * T + (1|Subject) + (1|Subject:S:R:T), ...)

A term like "(1|Subject/Condition)" in an lmer formula is just a
shortened form of  "(1|Subject) + (1|Subject:Condition)"

If you want to express Subject:Condition in terms of Subject, S, R and
T then you just need to generate a factor with a separate level for
each distinct combination of Subject, S, R and T, which is what
Subject:S:R:T is.

In this regard parsing a random-effects specification is actually
easier than for fixed effects.  With fixed effects you must be careful
to determine a non-redundant set of basis vectors for the column span
of the intercept, the main effects given the intercept, any two-factor
interactions given the main effects, etc.  With random effects you can
include both (1|Subject) and (1|Subject:Condition) in a model and not
need to adjust the random effects for the interaction
(1|Subject:Condition) for the fact that random effects for the term
(1|Subject) are also included in the model.

> summary(glht(RT.lme, linfct=mcp(? S*R*T ? = "Tukey")))

> These didn't work:
>
> RT.lme <- lme(RT ~ S*R*T, random = ~1 | Subj/(S*R*T), WMU2C)
> #Error in getGroups.data.frame(dataMix, groups) :  Invalid formula for groups
>
> RT.lme <- lme(RT ~ S*R*T, random = ~1 | (Subj + (S %in% Subj) + (R
> %in% Subj) + (T %in% Subj)), WMU2C)
> #Error in sprintf(gettext(fmt, domain = domain), ...) :  object
> "form" not found
>
> RT.lme <- lme(RT ~ S*R*T, random = ~S*R*T|Subj, WMU2C)
> #R stalls
>
>
> and I couldn't make use of this suggestion - R complains about
> unexpected characters and I to be honest I don't understand what it
> is supposed to do anyway:
>
>  > lme((y~fact1*fact2,
> + random=list(subj=pdIdent(form=~fact1-1),
> + subj=~1,
> + fact2=~1),
>
>
> Thanks very much for your help!
>
> Ulli
>
> Ullrich Ecker
> Cognitive Science Laboratories
> University of Western Australia
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From zqchang at math.hkbu.edu.hk  Sun Jun 15 13:50:50 2008
From: zqchang at math.hkbu.edu.hk (zqchang at math.hkbu.edu.hk)
Date: Sun, 15 Jun 2008 19:50:50 +0800 (HKT)
Subject: [R-sig-ME] about the correlated errors
Message-ID: <54677.158.182.1.38.1213530650.squirrel@www.math.hkbu.edu.hk>



dear all:

    there are two questions,

   1.   there are several corStructs in the package,  for a given
corStruct such as

corAR1, corARMA, corCAR1, corCompSymm, corExp ...., how to obtain the

random number series with this corStruct by function as simulated

errors in a simulation procedure?

  2.  error reported :"Singularity in backsolve at level 0, block 1"

what is the possible reason and how to overcome it?

thx

  best,




2008-06-14

----------------------
zqchang



From mwkimpel at gmail.com  Sun Jun 15 21:33:17 2008
From: mwkimpel at gmail.com (Mark Kimpel)
Date: Sun, 15 Jun 2008 15:33:17 -0400
Subject: [R-sig-ME] power calculations in mixed models
Message-ID: <6b93d1830806151233h5c5dd2cbu157c1f5780645e53@mail.gmail.com>

I have data from a micro-array experiment that has turned out to be
underpowered. Classical power calculations based on observed variance
of presumably non-differentially expressed genes and the delta that we
would like to measure have led to this conclusion. We have enough of
each sample to re-run the assays, thus obtaining technical replication
within sample, which would be a random-effect. As a simplistic
approach to predicting the power obtained when using technical
replication, I have performed a simulation using averages for each
sample. This demonstrates that variance is cut in half with
replication.

I assume that power would be further increased in a real experiment if
all measurements are included in a mixed-effects model. Is that likely
to be true? If it is, is there any way to predict, based on the
knowledge we already have, the power of the data-set expanded with
technical replication?

Thanks,
Mark

-- 
Mark W. Kimpel MD ** Neuroinformatics ** Dept. of Psychiatry
Indiana University School of Medicine

15032 Hunter Court, Westfield, IN 46074

(317) 490-5129 Work, & Mobile & VoiceMail
(317) 663-0513 Home (no voice mail please)



From mwkimpel at gmail.com  Sun Jun 15 21:57:30 2008
From: mwkimpel at gmail.com (Mark Kimpel)
Date: Sun, 15 Jun 2008 15:57:30 -0400
Subject: [R-sig-ME] power calculations in mixed models
In-Reply-To: <6b93d1830806151233h5c5dd2cbu157c1f5780645e53@mail.gmail.com>
References: <6b93d1830806151233h5c5dd2cbu157c1f5780645e53@mail.gmail.com>
Message-ID: <6b93d1830806151257q13eab478l4044327f37143fd6@mail.gmail.com>

One thing I forgot to mention.... We have a reasonable estimate of the
bounds of the biologic variance and have subtracted that out to get
the bounds of the technical variance. For estimation purposes, I am
assuming that the within sample replication variance will be the same
as the between sample technical variance. So for power calculations
the between sample fixed effects variance is the same as within-sample
random effects variance.

Mark

On Sun, Jun 15, 2008 at 3:33 PM, Mark Kimpel <mwkimpel at gmail.com> wrote:
> I have data from a micro-array experiment that has turned out to be
> underpowered. Classical power calculations based on observed variance
> of presumably non-differentially expressed genes and the delta that we
> would like to measure have led to this conclusion. We have enough of
> each sample to re-run the assays, thus obtaining technical replication
> within sample, which would be a random-effect. As a simplistic
> approach to predicting the power obtained when using technical
> replication, I have performed a simulation using averages for each
> sample. This demonstrates that variance is cut in half with
> replication.
>
> I assume that power would be further increased in a real experiment if
> all measurements are included in a mixed-effects model. Is that likely
> to be true? If it is, is there any way to predict, based on the
> knowledge we already have, the power of the data-set expanded with
> technical replication?
>
> Thanks,
> Mark
>
> --
> Mark W. Kimpel MD ** Neuroinformatics ** Dept. of Psychiatry
> Indiana University School of Medicine
>
> 15032 Hunter Court, Westfield, IN 46074
>
> (317) 490-5129 Work, & Mobile & VoiceMail
> (317) 663-0513 Home (no voice mail please)
>
> ******************************************************************
>



-- 
Mark W. Kimpel MD ** Neuroinformatics ** Dept. of Psychiatry
Indiana University School of Medicine

15032 Hunter Court, Westfield, IN 46074

(317) 490-5129 Work, & Mobile & VoiceMail
(317) 663-0513 Home (no voice mail please)



From bates at stat.wisc.edu  Mon Jun 16 15:22:52 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 16 Jun 2008 08:22:52 -0500
Subject: [R-sig-ME] [R] R vs SAS and HLM on multilevel analysis- basic
	question
In-Reply-To: <536338.9932.qm@web38601.mail.mud.yahoo.com>
References: <536338.9932.qm@web38601.mail.mud.yahoo.com>
Message-ID: <40e66e0b0806160622v681306f0nc78d756df5548507@mail.gmail.com>

We may want to move this discussion to the R-SIG-Mixed-Models list,
which I have cc:'d on this reply.

On Sun, Jun 15, 2008 at 6:16 PM, eugen pircalabelu
<eugen_pircalabelu at yahoo.com> wrote:
> Hi R users!

> I am trying to learn some multilevel analysis, but unfortunately i am now very confused. The reason: http://www.ats.ucla.edu/stat/hlm/seminars/hlm_mlm/mlm_hlm_seminar.htm
> http://www.ats.ucla.edu/stat/sas/seminars/sas_mlm/mlm_sas_seminar.htm

> and
> MlmSoftRev. pdf from mlmRev package.

> >From what i see, the first two links seem to declare the level one variable as a random part (i don't know sas synthax, but i think i am right ) while Mr. Bates' pdf  says that a grouping variable is the random part of the model, though both models, use roughly the same type of information, some characteristic of the school, along with individual characteristics in explaining individual achivement.

I'm not exactly sure what you are asking.  If you are saying that the
terminology and notation can be confusing, I certainly agree.  I think
those who developed HLM and MLWin have done a tremendous service to
their users in providing them with sophisticated tools for modeling
data.  However, the way that they structure the model is really only
appropriate for models with nested random effects and, to my mind,
introduces many unnecessary and restrictive ways of thinking of the
data and the model.

> Am i mistaken somehow? If not, could they both be valid models (i presume) but each showing something else, in terms of connections between this variables?

As I said, I don't quite understand what you are asking and, rather
than formulate an answer to the wrong question, I'll ask if you can
rephrase your question and perhaps be more explicit about an example.
In particular, you made reference to a "school".  Are you referring to
a particular example?



From austin.frank at gmail.com  Tue Jun 17 06:33:31 2008
From: austin.frank at gmail.com (Austin Frank)
Date: Tue, 17 Jun 2008 00:33:31 -0400
Subject: [R-sig-ME] simulate glmm with family=binomial
Message-ID: <m0ve08u1d0.fsf@gmail.com>

Hello!

In lme4 version 0.99875-9, simulate() is implemented for linear mixed
models and generalized linear mixed models from the Poisson family.  I'm
hoping to simulate a glmm from the binomial family.

I looked at the code used to implement the Poisson simulations, and
naively tried to port it to handle the binomial (and only the binomial)
case.  The result is:

--8<---------------cut here---------------start------------->8---
my.simulate <- function (object, nsim = 1, seed = NULL, ...) 
{
  if (!exists(".Random.seed", envir = .GlobalEnv)) 
    runif(1)
  if (is.null(seed)) 
    RNGstate <- .Random.seed
  else {
    R.seed <- .Random.seed
    set.seed(seed)
    RNGstate <- structure(seed, kind = as.list(RNGkind()))
    on.exit(assign(".Random.seed", R.seed, envir = .GlobalEnv))
  }
  stopifnot((nsim <- as.integer(nsim[1])) > 0, is(object, "lmer"))
  lpred <- .Call(lme4:::mer_simulate, object, nsim)
  sc <- abs(object at devComp[8])
  lpred <- lpred + drop(object at X %*% fixef(object))
  n <- prod(dim(lpred))
  fam <- attr(object, "family")
  if (fam$family == "binomial") {
    summary(lpred)
    response <- as.data.frame(matrix(byrow = FALSE, ncol = nsim, 
                                     rbinom(n, size=1, plogis(lpred))))
    attr(response, "seed") <- RNGstate
    return(response)
  }
}
--8<---------------cut here---------------end--------------->8---


The part I changed is:

  response <- as.data.frame(matrix(byrow = FALSE, ncol = nsim, 
                                   rbinom(n, size=1, plogis(lpred))))

which is based on (ripped off from) the code for Poisson simulations:

  response <- as.data.frame(matrix(byrow = FALSE, ncol = nsim, 
                                   rpois(n, fam$linkinv(lpred))))


This works, in the sense that I get the correct number of samples, each
with a value of 0 or 1.  But I have to assume that there's a problem
here-- if this were all it took, it would be included already!
                                   
So, three questions:
1.  Is there something wrong with this solution?
2.  Assuming so, is there an obvious fix to the problem?
3.  In the second argument to rbinom, I've specified that we're basing
    this on a single trial.  Am I right in thinking that size=1 is the
    right argument here?

Thanks in advance for any help!
/au
    
-- 
Austin Frank
http://aufrank.net
GPG Public Key (D7398C2F): http://aufrank.net/personal.asc



From ullrich.ecker at uwa.edu.au  Tue Jun 17 09:09:34 2008
From: ullrich.ecker at uwa.edu.au (Ullrich Ecker)
Date: Tue, 17 Jun 2008 15:09:34 +0800
Subject: [R-sig-ME] more than 2 within-subjects factors in lme(r)
In-Reply-To: <40e66e0b0806131102g74aae5n3069edfb98f3bb68@mail.gmail.com>
References: <20080613022522.812AB87807@panacea.ucs.uwa.edu.au>
	<40e66e0b0806131102g74aae5n3069edfb98f3bb68@mail.gmail.com>
Message-ID: <20080617070934.7EB2E881DE@panacea.ucs.uwa.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080617/b28b4abc/attachment.pl>

From bates at stat.wisc.edu  Tue Jun 17 15:02:47 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 17 Jun 2008 08:02:47 -0500
Subject: [R-sig-ME] more than 2 within-subjects factors in lme(r)
In-Reply-To: <20080617070934.7EB2E881DE@panacea.ucs.uwa.edu.au>
References: <20080613022522.812AB87807@panacea.ucs.uwa.edu.au>
	<40e66e0b0806131102g74aae5n3069edfb98f3bb68@mail.gmail.com>
	<20080617070934.7EB2E881DE@panacea.ucs.uwa.edu.au>
Message-ID: <40e66e0b0806170602p66220163o9524a60abcd9a5e7@mail.gmail.com>

On Tue, Jun 17, 2008 at 2:09 AM, Ullrich Ecker <ullrich.ecker at uwa.edu.au> wrote:
> Thank you very much, Douglas, for the reply,
>
> this
>
> Rt.lmer <- lmer(RT ~ S * R * T + (1|Subject) + (1|Subject:S:R:T), ...)
>
> is not working, however, and gives the error

> Error in lmerFactorList(formula, mf, fltype) : number of levels in
> grouping factor(s) 'S:R:T:Subj' is too large

> I do have many subjects (~100) - is that a problem?

Evaluate

length(levels(with(myData, S:R:T:Subj)[drop = TRUE])))

substituting the name of your data frame for myData.  If that is equal
to the number of observations then you cannot separately estimate a
variance for that term and the residual variance.  You will need to
reduce your model.

>
> Also, you wrote that
>
> If you want to express Subject:Condition in terms of Subject, S, R and
> T then you just need to generate a factor with a separate level for
> each distinct combination of Subject, S, R and T, which is what
> Subject:S:R:T is.
>
> I take this to mean that
>
> Rt.lmer <- lmer(RT ~ S * R * T + (1|Subject) + (1|Subject:S:R:T), ...)
>
> is equivalent to
>
> RT.lme <- lme(RT ~ Condition, random = ~1 | Subject/Condition, Data)
>
> ...with Condition an 8-level factor - 1 level for each S R T combination.
>
> However, (and I'm REALLY sorry to bring the old "but according to
> SPSS/SAS/Statistica" argument), in my Statistica-coined experience
> the results of a post-hoc test differ if one puts in 1 8-level factor
> vs. 3 2-level factors. Am I missing something?

You are correct.  There is a difference in the interpretation of the
fixed-effects terms.  I was thinking of the structure of the
random-effects terms. when I said they were equivalent.

> Thanks again,
>
> Ulli
>
>
>
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From f.calboli at imperial.ac.uk  Tue Jun 17 17:22:24 2008
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Tue, 17 Jun 2008 16:22:24 +0100
Subject: [R-sig-ME] lme vs paired t-test
Message-ID: <68286030-5B4F-4213-98FC-0E2606F77C38@imperial.ac.uk>

Hello everyone,

to keep on the line of my pesky questions/irritating questions, I did  
one simple analysis for a colleague and got some unexpected results.

In the analysis I had to model size over selection -- two selection  
regimes, big and small. Nested withing selection there are 2  
replicated lines for each selection regime. The experiment had been  
replicated 4 independent times.

My model is:

agmod = lme(Ag_size ~ selection , random = ~1|rep.sel/block_sep, agsize)

with rep.sel being the nested replicated lines and block_sep the 4  
independent replicates. Since my colleague cares about the effect of  
selection I did an anova of the model:

anova(agmod)
             numDF denDF  F-value p-value
(Intercept)     1   128 693.5251  <.0001
selection       1     2  35.5191   0.027

This is all fine and dandy, but my colleague expected a much stronger  
selection effect, he did a paired t-test on the means of each  
replicated selection line:

mat = matrix(tapply(agsize$AG_size, agsize$rep.sel, mean), ncol = 2)
 > mat
          [,1]      [,2]
[1,] 15224.03  9143.403
[2,] 16418.50 10729.206
 > t.test(mat[,1], mat[,2], paired = T)

	Paired t-test

data:  pio[, 1] and pio[, 2]
t = 30.0763, df = 1, p-value = 0.02116
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
  3398.768 8371.155
sample estimates:
mean of the differences
                5884.962

Now the pesky question: the value from a rough and ready t-test is  
not all that different from the linear model... what's going on? I  
would have though that all the extra data in the lme model would make  
it much more sensitive. Where are my conjectures wrong?

Cheers,

Federico

PS the data I used, not being mine, cannot bet just posted for  
everyone to test my assumptions, sorry.



--
Federico C. F. Calboli
Department of Epidemiology and Public Health
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From HStevens at muohio.edu  Wed Jun 18 13:47:30 2008
From: HStevens at muohio.edu (Martin Henry H. Stevens)
Date: Wed, 18 Jun 2008 07:47:30 -0400
Subject: [R-sig-ME] lme vs paired t-test
In-Reply-To: <68286030-5B4F-4213-98FC-0E2606F77C38@imperial.ac.uk>
References: <68286030-5B4F-4213-98FC-0E2606F77C38@imperial.ac.uk>
Message-ID: <B7887F14-44E0-4F75-BF59-DCD350044405@muohio.edu>

Hi Frederico,
I assume that your ability to test "selection" is limited by the  
number of blocks, not the total number of reps. If If I am right,  
this is actually reassuring that the mixed model is not anti- 
conservative.
Hank
On Jun 17, 2008, at 11:22 AM, Federico Calboli wrote:
> Hello everyone,
>
> to keep on the line of my pesky questions/irritating questions, I did
> one simple analysis for a colleague and got some unexpected results.
>
> In the analysis I had to model size over selection -- two selection
> regimes, big and small. Nested withing selection there are 2
> replicated lines for each selection regime. The experiment had been
> replicated 4 independent times.
>
> My model is:
>
> agmod = lme(Ag_size ~ selection , random = ~1|rep.sel/block_sep,  
> agsize)
>
> with rep.sel being the nested replicated lines and block_sep the 4
> independent replicates. Since my colleague cares about the effect of
> selection I did an anova of the model:
>
> anova(agmod)
>              numDF denDF  F-value p-value
> (Intercept)     1   128 693.5251  <.0001
> selection       1     2  35.5191   0.027
>
> This is all fine and dandy, but my colleague expected a much stronger
> selection effect, he did a paired t-test on the means of each
> replicated selection line:
>
> mat = matrix(tapply(agsize$AG_size, agsize$rep.sel, mean), ncol = 2)
>> mat
>           [,1]      [,2]
> [1,] 15224.03  9143.403
> [2,] 16418.50 10729.206
>> t.test(mat[,1], mat[,2], paired = T)
>
>         Paired t-test
>
> data:  pio[, 1] and pio[, 2]
> t = 30.0763, df = 1, p-value = 0.02116
> alternative hypothesis: true difference in means is not equal to 0
> 95 percent confidence interval:
>   3398.768 8371.155
> sample estimates:
> mean of the differences
>                 5884.962
>
> Now the pesky question: the value from a rough and ready t-test is
> not all that different from the linear model... what's going on? I
> would have though that all the extra data in the lme model would make
> it much more sensitive. Where are my conjectures wrong?
>
> Cheers,
>
> Federico
>
> PS the data I used, not being mine, cannot bet just posted for
> everyone to test my assumptions, sorry.
>
>
>
> --
> Federico C. F. Calboli
> Department of Epidemiology and Public Health
> Imperial College, St. Mary's Campus
> Norfolk Place, London W2 1PG
>
> Tel +44 (0)20 75941602   Fax +44 (0)20 75943193
>
> f.calboli [.a.t] imperial.ac.uk
> f.calboli [.a.t] gmail.com
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

Dr. Hank Stevens, Associate Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/~stevenmh/
http://www.users.muohio.edu/harkesae/
http://www.cas.muohio.edu/ecology
http://www.muohio.edu/botany/
"E Pluribus Unum"

"I love deadlines. I love the whooshing noise they make as they go by."
                                             (Douglas Adams)


If you send an attachment, please try to send it in a format anyone  
can read, such as PDF, text, Open Document Format, HTML, or RTF.
Why? See:  http://www.gnu.org/philosophy/no-word-attachments.html



From luis.tedeschi at hotmail.com  Thu Jun 19 02:05:02 2008
From: luis.tedeschi at hotmail.com (Luis Orlindo Tedeschi)
Date: Wed, 18 Jun 2008 19:05:02 -0500
Subject: [R-sig-ME] Port algorithm in nls
In-Reply-To: <40e66e0b0806170602p66220163o9524a60abcd9a5e7@mail.gmail.com>
References: <20080613022522.812AB87807@panacea.ucs.uwa.edu.au>	<40e66e0b0806131102g74aae5n3069edfb98f3bb68@mail.gmail.com>	<20080617070934.7EB2E881DE@panacea.ucs.uwa.edu.au>
	<40e66e0b0806170602p66220163o9524a60abcd9a5e7@mail.gmail.com>
Message-ID: <BLU103-DS757F80CBD8016205BDA0EE3AA0@phx.gbl>

Folks, I'd like to hear comments about a statement in the help and manual of
R 2.7 about the port algorithm in the nls function.

It says: "The algorithm = "port" code appears unfinished, and does not even
check that the starting value is within the bounds. Use with caution,
especially where bounds are supplied."

IF, and only IF, it is unfinished how reliable are the estimates of the
parameters and why does R 2.7 have it?

It sounds confusing to me... Mainly because most of my fittings are done
with port and I do use the bound statement. Sometimes port is faster than
Gauss-Newton... but now I am confused.

I tried to get more info in Bates and Chambers (1993) but I could not find
it clearly.

Any suggestions?

Thanks in advance...

Luis

______________________________________
Luis Orlindo Tedeschi, PhD, PAS
Assistant Professor
Texas A&M University
230 Kleberg Center
2471 TAMU
College Station, TX 77843-2471
Phone: (979) 845-5065
Fax: (979) 845-5292
Email: luis.tedeschi at tamu.edu
Web: http://nutritionmodels.tamu.edu
______________________________________
This electronic message contains a communication from
the TexasA&M University, which communication is 
strictly confidential and intended solely for the use of 
the addressee. Any non-addressee is prohibited from
reading, disseminating, distributing, or copying the
communication contained herein. If you are in possession
of the communication in error, please immediately notify
the sender via electronic mail excluding the original
communication.



From vincent.nijs at gmail.com  Thu Jun 19 06:09:28 2008
From: vincent.nijs at gmail.com (Vincent Nijs)
Date: Wed, 18 Jun 2008 23:09:28 -0500
Subject: [R-sig-ME] multinomial logit (probit) with random effects
Message-ID: <7b6b9e400806182109u515c15c6p959857f12c5674ed@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080618/0e2b5af7/attachment.pl>

From kjbeath at kagi.com  Thu Jun 19 12:58:06 2008
From: kjbeath at kagi.com (Ken Beath)
Date: Thu, 19 Jun 2008 20:58:06 +1000
Subject: [R-sig-ME] Port algorithm in nls
In-Reply-To: <BLU103-DS757F80CBD8016205BDA0EE3AA0@phx.gbl>
References: <20080613022522.812AB87807@panacea.ucs.uwa.edu.au>	<40e66e0b0806131102g74aae5n3069edfb98f3bb68@mail.gmail.com>	<20080617070934.7EB2E881DE@panacea.ucs.uwa.edu.au>
	<40e66e0b0806170602p66220163o9524a60abcd9a5e7@mail.gmail.com>
	<BLU103-DS757F80CBD8016205BDA0EE3AA0@phx.gbl>
Message-ID: <93834919-4454-498A-B202-8C5753A89C7B@kagi.com>

On 19/06/2008, at 10:05 AM, Luis Orlindo Tedeschi wrote:

> Folks, I'd like to hear comments about a statement in the help and  
> manual of
> R 2.7 about the port algorithm in the nls function.
>
> It says: "The algorithm = "port" code appears unfinished, and does  
> not even
> check that the starting value is within the bounds. Use with caution,
> especially where bounds are supplied."
>
> IF, and only IF, it is unfinished how reliable are the estimates of  
> the
> parameters and why does R 2.7 have it?
>
> It sounds confusing to me... Mainly because most of my fittings are  
> done
> with port and I do use the bound statement. Sometimes port is faster  
> than
> Gauss-Newton... but now I am confused.
>
> I tried to get more info in Bates and Chambers (1993) but I could  
> not find
> it clearly.
>
> Any suggestions?
>

R is free software, so at times people will implement something but it  
may not be implemented as well as desired. It may still be useful to  
them and thus may be useful to others, as it is in your case, but is  
included with caveats. Check that the parameter estimates are at a  
maximum, always a good idea anyway.

Ken



From bates at stat.wisc.edu  Thu Jun 19 16:42:19 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 19 Jun 2008 09:42:19 -0500
Subject: [R-sig-ME] Caution - Big changes in lme4 on Saturday
Message-ID: <40e66e0b0806190742v5fa91403kb954e680bc06ea84@mail.gmail.com>

As many on the list will have noticed, I suffer from a bad case of
"the best is the enemy of the good", a sort of adult-onset attention
deficit disorder, and have trouble completing projects.

I have been juggling development of the lme4 package under a new
formulation of the computing methods with maintenance of the older
formulation so as not to break some code in other packages.  As I am
facing a deadline in preparing the slides for a workshop, on Saturday,
come hell or high water (and right now "high water" is more than a
metaphor around here), I will release the development version of lme4
to CRAN.

There are many aspects of the new version that are superior to the
current CRAN version of lme4.

The underlying algorithms for linear mixed models are more stable; in
particular, singular variance-covariance matrices for the random
effects are handled gracefully.  The algorithms are simplified; ECME
iterations and the optional evaluation of the gradient have been
eliminated.  The only control option now active is msVerbose and that
can be replaced by with the "verbose" argument.  There is no
lmer/lmer2 distinction.  You can still call lmer2 but the effect is to
turn around and call lmer.  You can specify a family argument in a
call to lmer.  If the argument is other than the default gaussian
family then glmer gets called transparently.

The algorithms for fitting generalized linear mixed models and
nonlinear mixed models have also been simplified.  Direct optimization
of the Laplace approximation is the default (and only) method at
present.  Bin Dai is working on adding adaptive Gauss-Hermite
quadrature for models for which it makes sense.

The mcmcsamp function has changed.  The good news is that I have
managed to convince myself that the current implementation is a very
good way to do things.  The bad news is that the results are not
plug-compatible with the results of the older version.  Also, this
version hasn't been tested as much as I would have liked it to be
before a release.  I think the basic methodology is sound but I am not
sure at this point if the results are as correct as they could be.
The big change is in the method of sampling from the distribution of
the variance components.  I have used an approach in the spirit of Box
and Tiao's discussion of variance components in their book on Bayesian
inference and somewhat in the flavor of the 2008 Gelman et al. paper
in JCGS.  I sample from the conditional distribution of a parameter
that takes a value on the entire real line and which coincides with
the variance component on the non-negative values.  When this
parameter is negative the variance component is zero.  I'm sure there
will be interesting ways of relating the proportion of zeros in the
chain to tests of the variance component being zero versus greater
than zero.  I still need to add code for sampling from the conditional
distribution of covariance parameters.

Please be cautious about installing the new version if you depend on
using mcmcsamp in its current form.  It would be a good idea to keep a
backup copy of the current CRAN version of the lme4 package in case
you find you want to back out the change.

I regret any inconvenience that these changes will cause.  I am
convinced, however, that it will be short-term pain for a long-term
gain.



From luis.tedeschi at hotmail.com  Thu Jun 19 16:50:48 2008
From: luis.tedeschi at hotmail.com (Luis Orlindo Tedeschi)
Date: Thu, 19 Jun 2008 09:50:48 -0500
Subject: [R-sig-ME] SE of the mean in nlme
In-Reply-To: <BLU103-DS757F80CBD8016205BDA0EE3AA0@phx.gbl>
References: <20080613022522.812AB87807@panacea.ucs.uwa.edu.au>
	<40e66e0b0806131102g74aae5n3069edfb98f3bb68@mail.gmail.com>
	<20080617070934.7EB2E881DE@panacea.ucs.uwa.edu.au>
	<40e66e0b0806170602p66220163o9524a60abcd9a5e7@mail.gmail.com> 
	<BLU103-DS757F80CBD8016205BDA0EE3AA0@phx.gbl>
Message-ID: <BLU103-W282F4CFE1AA5849BBDF9C9E3AA0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080619/28a85ec4/attachment.pl>

From luis.tedeschi at hotmail.com  Thu Jun 19 16:55:03 2008
From: luis.tedeschi at hotmail.com (Luis Orlindo Tedeschi)
Date: Thu, 19 Jun 2008 09:55:03 -0500
Subject: [R-sig-ME] Port algorithm in nls
In-Reply-To: <93834919-4454-498A-B202-8C5753A89C7B@kagi.com>
References: <20080613022522.812AB87807@panacea.ucs.uwa.edu.au>
	<40e66e0b0806131102g74aae5n3069edfb98f3bb68@mail.gmail.com>
	<20080617070934.7EB2E881DE@panacea.ucs.uwa.edu.au>
	<40e66e0b0806170602p66220163o9524a60abcd9a5e7@mail.gmail.com>
	<BLU103-DS757F80CBD8016205BDA0EE3AA0@phx.gbl>
	<93834919-4454-498A-B202-8C5753A89C7B@kagi.com>
Message-ID: <BLU103-W1BD954F6CF78690C875F2E3AA0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080619/f0a31b16/attachment.pl>

From lborger at uoguelph.ca  Thu Jun 19 17:00:24 2008
From: lborger at uoguelph.ca (Luca Borger)
Date: Thu, 19 Jun 2008 11:00:24 -0400
Subject: [R-sig-ME] SE of the mean in nlme
References: <20080613022522.812AB87807@panacea.ucs.uwa.edu.au><40e66e0b0806131102g74aae5n3069edfb98f3bb68@mail.gmail.com><20080617070934.7EB2E881DE@panacea.ucs.uwa.edu.au><40e66e0b0806170602p66220163o9524a60abcd9a5e7@mail.gmail.com>
	<BLU103-DS757F80CBD8016205BDA0EE3AA0@phx.gbl>
	<BLU103-W282F4CFE1AA5849BBDF9C9E3AA0@phx.gbl>
Message-ID: <DAED88C77BEE4038B6D59E687D931200@ZooAnnex2Luca>

Hello,

re your second question, try the summary() and intervals() functions:

###########
library(lme)
fm2 <- lme(distance ~ age + Sex, data = Orthodont, random = ~ 1)
summary(fm2)
intervals(fm2)


## this might help you. have a look also at:

?lmeObject

############


Hope this helps.


Cheers,

Luca


---------------------------
Luca B?rger, PhD
Postdoctoral Research Fellow
Department of Integrative Biology
University of Guelph
Guelph, Ontario, Canada N1G 2W1
phone: +1 519 824 4120 ext. 52975
fax:     +1 519 767 1656
----- Original Message ----- 
From: "Luis Orlindo Tedeschi" <luis.tedeschi at hotmail.com>
To: "'Douglas Bates'" <bates at stat.wisc.edu>
Cc: <r-sig-mixed-models at r-project.org>
Sent: Thursday, June 19, 2008 10:50 AM
Subject: [R-sig-ME] SE of the mean in nlme


Folks; I'd like to know if there is anything similar to LSMEANS or MEANS 
from SAS PROC MIXED in nlme that would compare means of the fixed effects? 
Also, how do I get the SE of the mean (SEM) for fixed effects in nlme? 
Thanks a lot.

__________________________________
 Lu?s Orlindo Tedeschi, PhD, PAS
 Assistant Professor

 Texas A&M University
 230 Kleberg Center
 2471 TAMU
 College Station, TX 77843-2471
 Phone: (979) 845-5065
 Fax: (979) 845-5292
 Email: luis.tedeschi at tamu.edu
 Web: http://nutritionmodels.tamu.edu
 __________________________________
This electronic message contains a communication from the
Texas A&M University, which communication is strictly confidential
and intended solely for the use of the addressee. Any
non-addressee is prohibited from reading, disseminating, distributing
or copying the communication contained herein. If you are in
possession of the communication in error, please immediately notify
the sender via electronic mail excluding the original communication.
_________________________________________________________________
Earn cashback on your purchases with Live Search - the search that pays you 
back!

arncashback
[[alternative HTML version deleted]]




--------------------------------------------------------------------------------


> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From maechler at stat.math.ethz.ch  Thu Jun 19 18:22:08 2008
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 19 Jun 2008 18:22:08 +0200
Subject: [R-sig-ME] Port algorithm in nls
In-Reply-To: <BLU103-W1BD954F6CF78690C875F2E3AA0@phx.gbl>
References: <20080613022522.812AB87807@panacea.ucs.uwa.edu.au>
	<40e66e0b0806131102g74aae5n3069edfb98f3bb68@mail.gmail.com>
	<20080617070934.7EB2E881DE@panacea.ucs.uwa.edu.au>
	<40e66e0b0806170602p66220163o9524a60abcd9a5e7@mail.gmail.com>
	<BLU103-DS757F80CBD8016205BDA0EE3AA0@phx.gbl>
	<93834919-4454-498A-B202-8C5753A89C7B@kagi.com>
	<BLU103-W1BD954F6CF78690C875F2E3AA0@phx.gbl>
Message-ID: <18522.34736.929289.145105@stat.math.ethz.ch>

>>>>> "LOT" == Luis Orlindo Tedeschi <luis.tedeschi at hotmail.com>
>>>>>     on Thu, 19 Jun 2008 09:55:03 -0500 writes:

    LOT> Ken, thanks for you reply. Actually, you brought up a
    LOT> good topic. Maybe this question does not pertain to
    LOT> this list,

yes, definitely not!

    LOT> but maybe someone could point me to the
    LOT> right direction. Someone told me once that R cannot be
    LOT> used for official, government, etc reports because it
    LOT> has not been "validated" like SAS, Stata, etc. Does
    LOT> anyone know anything about this? Is there such a thing
    LOT> as statistical package accreditation? Thanks in
    LOT> advance.  

Short Answer:

- There's quite a bit myth in the above statement, which of course
  is perpetrated by sales representatives of SAS, Stata, ...

- For about a year now, there's a  Certification document
  --> http://www.R-project.org/ and chose "Certification"
  which adresses such things in part.

Long Answer:

- Please use 'R-help' to disuss this topic if you must

Martin Maechler, ETH Zurich


    LOT> Lu?s Orlindo Tedeschi Assistant Professor
    LOT>  Texas A&M University

[..........]



From mjantti at abo.fi  Thu Jun 19 19:20:51 2008
From: mjantti at abo.fi (Markus =?ISO-8859-1?Q?J=E4ntti?=)
Date: Thu, 19 Jun 2008 13:20:51 -0400
Subject: [R-sig-ME] multinomial logit (probit) with random effects
In-Reply-To: <7b6b9e400806182109u515c15c6p959857f12c5674ed@mail.gmail.com>
References: <7b6b9e400806182109u515c15c6p959857f12c5674ed@mail.gmail.com>
Message-ID: <1213896051.8580.34.camel@hades>

Take a look at the package drm.

Regards,

Markus

On Wed, 2008-06-18 at 23:09 -0500, Vincent Nijs wrote: 
> Hi,
> 
> I am looking for a routine to estimate a multinomial logit (or probit) with
> random effects. I found 1 reference on how this might be done in SAS. Is
> anyone aware of of code to do this in R?
> 
> Thanks,
> 
> Vincent
> 
> http://www.informaworld.com/smpp/content~content=a718869813~db=all
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Markus Jantti
Abo Akademi University
mjantti at abo.fi
http://www.iki.fi/~mjantti



From asanture at gmail.com  Fri Jun 20 11:59:22 2008
From: asanture at gmail.com (Anna Santure)
Date: Fri, 20 Jun 2008 10:59:22 +0100
Subject: [R-sig-ME] fitting an animal model
Message-ID: <b104f040806200259qfe77c16ub14d6724b3a82bc4@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080620/e8a5d623/attachment.pl>

From bates at stat.wisc.edu  Fri Jun 20 16:41:34 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 20 Jun 2008 09:41:34 -0500
Subject: [R-sig-ME] fitting an animal model
In-Reply-To: <b104f040806200259qfe77c16ub14d6724b3a82bc4@mail.gmail.com>
References: <b104f040806200259qfe77c16ub14d6724b3a82bc4@mail.gmail.com>
Message-ID: <40e66e0b0806200741g38b57b8ch2a891c652c4f1245@mail.gmail.com>

On Fri, Jun 20, 2008 at 4:59 AM, Anna Santure <asanture at gmail.com> wrote:
> Hi everyone,

> I have come across some very helpful conversations on the archives for this
> list regarding fitting animal models, but I'm afraid I'm still a bit lost!
> Jon Hallander gave a good description of the model in "[R-sig-ME]
> incorporate pedigree into lmer" discussion Feb 6, 2007, pasted below:
> Animal model:

> "I am using a mixed linear model including both random and fixed effects:
> y = Xb + Za + e
> where the vector y are observed individual data, b is a vector of fixed
> effects, a is an individual additive random effect that are normally
> distributed vectors with (co)variance A*var(a). X and Z are incidence
> matrices relating the fixed and random effects (b and a) with the
> observations y. Furthermore, e is the error term, normally distributed with
> mean zero and variance var(e). A is the additive genetic relationship matrix
> which is computed using the pedigree information (given below). A typical
> data might look like this:
> Id Sire Dam y (i.e. weight in kg)
> 1  Na   Na  4.3
> 2  Na   Na  4.7
> 3  1    2   4.4
> 4  1    Na  4.1
> 5  4    2   4.3
> 6  4    2   4.2" (end of pasted passage).

> I would like to estimate the additive variance and error variance (in order
> to estimate heritability) and it would also be nice to predict the
> "breeding" (additive) values for each individual.

> My (simulated) data set "animalmodel.txt" contains information on the animal
> id, the generation and the trait value (simulated just as additive effects
> plus an error), with 10 offspring from 13 parents all with trait data, along
> with a 23x23 relationship matrix linking animals to their parents and sibs
> ("covmatrix.txt"). There is a constraint at this point as I have a covmatrix
> rather than a pedigree so some of the previously suggested methods using
> "pedigree" / "kinship" might not work.
> Based on previous discussions in this list I tried fitting the following:
> 1. animaldata<-read.delim("data_animal.txt")
> 2. covmatrix<-read.table("covmatrix.txt")
> 3. correlation=corSymm(covmatrix[lower.tri(covmatrix)], fixed=TRUE)
> 4. correlation1<-Initialize(correlation,data=animaldata)
> 5.
> animalmodel<-lme(trait~generation,random=~1|animal,correlation=correlation1,data=animaldata)
> I have a number of problems at this point. First, I am not confident that
> the model is right (actually, I imagine I probably should be somehow
> including the random effects in the model statement?). Second, I am not sure
> the function is correct (perhaps I shouldn't be using lme in the nlme
> package? would lmer in lme4 and then VarCorr be better?). Third, I am unsure
> how to find the additive variance in the output, and particularly how to
> predict breeding values and heritability from here.
> I would very much appreciate any guidance!
> With many thanks and best wishes,

Did you intend that the files you mention (data_animal.txt,
covmatrix.txt) would be included with your message?  I didn't see any
attachments.

Ana Vazquez and I are writing a package called pedigreemm
(http://r-forge.r-project.org/projects/pedigreemm/) for incorporating
the information from a pedigree into mixed models based on lme4.  It's
not yet ready for release but we may be able to work with your example
to show you how an animal model can be fit, and in the process refine
our package and obtain an example.  Perhaps you could provide us with
the data - on-list or off-list, whichever you prefer.

> Anna Santure
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From h.wickham at gmail.com  Fri Jun 20 17:42:32 2008
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 20 Jun 2008 10:42:32 -0500
Subject: [R-sig-ME] Caution - Big changes in lme4 on Saturday
In-Reply-To: <40e66e0b0806190742v5fa91403kb954e680bc06ea84@mail.gmail.com>
References: <40e66e0b0806190742v5fa91403kb954e680bc06ea84@mail.gmail.com>
Message-ID: <f8e6ff050806200842y2f2f28ceg21505d4fb656c9f3@mail.gmail.com>

> Please be cautious about installing the new version if you depend on
> using mcmcsamp in its current form.  It would be a good idea to keep a
> backup copy of the current CRAN version of the lme4 package in case
> you find you want to back out the change.

For those of you who don't already know about it, the installWithVers
parameter to install.packages may be of use.  This allows you to keep
previous versions of the package around and refer to them by package
version.

Hadley

-- 
http://had.co.nz/



From bates at stat.wisc.edu  Fri Jun 20 19:42:18 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 20 Jun 2008 12:42:18 -0500
Subject: [R-sig-ME] Caution - Big changes in lme4 on Saturday
In-Reply-To: <f8e6ff050806200842y2f2f28ceg21505d4fb656c9f3@mail.gmail.com>
References: <40e66e0b0806190742v5fa91403kb954e680bc06ea84@mail.gmail.com>
	<f8e6ff050806200842y2f2f28ceg21505d4fb656c9f3@mail.gmail.com>
Message-ID: <40e66e0b0806201042n6693d021y6bbb5053918de28f@mail.gmail.com>

On Fri, Jun 20, 2008 at 10:42 AM, hadley wickham <h.wickham at gmail.com> wrote:
>> Please be cautious about installing the new version if you depend on
>> using mcmcsamp in its current form.  It would be a good idea to keep a
>> backup copy of the current CRAN version of the lme4 package in case
>> you find you want to back out the change.
>
> For those of you who don't already know about it, the installWithVers
> parameter to install.packages may be of use.  This allows you to keep
> previous versions of the package around and refer to them by package
> version.

Thanks for the reminder, Hadley.  Indeed, using installWithVers is recommended.

A few things to watch out for.  Bin Dai is working on a Google Summer
of Code project incorporating the Adaptive Gauss-Hermite Quadrature
method for some types of generalized linear mixed models and nonlinear
mixed models.  We realized that my previous stub code for AGQ where
the AGQ option would be specified with the `method' argument wouldn't
work.  You must specify the number of quadrature points per axis.
Because PQL is no longer offered (nor is the Lindstrom-Bates
algorithm, with a name like that I didn't feel I could trust it :-)
the only distinction is Laplace versus AGQ.  We therefore changed to
an argument nAGQ with a default of 1, which is the Laplace
approximation, in glmer and nlmer.  In lmer the method argument was
only used to select ML or REML so we changed to a REML argument with a
default of TRUE.  We will continue to honor a specification of method
= "ML" or method = "REML", because many published sources use it, but
you are encouraged to change to REML = FALSE if you want ML estimates.

Similarly the argument verbose = TRUE is preferred to the older form
control = list(msVerbose = TRUE).  The ECME steps are no longer used
nor is the analytic gradient.  The niterEM and gradient components of
the control list are still recognized but have no effect other than to
produce a warning that they are not active.



From bates at stat.wisc.edu  Mon Jun 23 21:47:51 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 23 Jun 2008 14:47:51 -0500
Subject: [R-sig-ME] Development version of lme4 has been released to CRAN
Message-ID: <40e66e0b0806231247v30579e6bq7a658e9d17bce469@mail.gmail.com>

Early Sunday morning the development version of the lme4 package was
released to CRAN.  There has already been one update version released
and will be another later today.  The current CRAN version of the
source and the Windows binary package is 0.999375-17.

I expect that as users begin to install this package and try to run
old code they will encounter issues.  I will be traveling and have
limited email access from June 26 until July 2 and no email access
from July 3 until July 8.

I would appreciate it is those who are so helpful in responding to
questions about lme4 on this list and on the R-help list could be
extra vigilant during that period.  Some of the changes have been
documented in the NEWS file.



From bolker at ufl.edu  Tue Jun 24 21:03:44 2008
From: bolker at ufl.edu (Ben Bolker)
Date: Tue, 24 Jun 2008 15:03:44 -0400
Subject: [R-sig-ME] GLMM review, revisited
Message-ID: <48614510.7070105@ufl.edu>


   Dear r-sig-mixed'ers:

  thanks for all your input on our GLMM review.

  of course, a variety of other interesting questions
have come up, and I thought I would run them by you
(in addition to letting you know where you can look
at a draft if you're interested:
http://www.zoology.ufl.edu/bolker/glmm_review-24jun.pdf . I've also set 
up glmm.wikidot.com , which doesn't have
much on it yet but hopefully will have some worked examples
etc..  Would have used the R wiki but the scope
is more general, e.g. including SAS examples.)

   Now a few more general questions, having to do with
degrees of freedom, hypothesis testing, and p-values (with
apologies to those who are tired of this topic ...)

   1. I have heard ("on the street") that LR tests are preferred to 
Wald/F for testing random effects.  In the paper we just say that that's
because they make weaker assumptions.  Does anyone have a (pref.
peer-reviewed) ref. for the assertion that LR is better in this case?

   2. Supposing one decides to use Wald/F tests to test fixed effects.
The "numerator" degrees of freedom are known (1 for covariates, n-1
for factors).  It's my understanding that Wald tests ignore uncertainty
in the sd estimate (hence are analogous to Z tests), and therefore don't
need "residual df" values.  (On the other hand, Littell 2006 shows
examples using a  t test with residual df, although he does say "In 
generalized linear models it is often desirable to perform 
chi-square-based inferences instead of t? or F-based inferences", and
recall reading somewhere (??) that the df-correction to the Wald
test was not worthwhile.)  Our bottom line interpretation is that
df estimates are necessary when (1) doing Wald/F tests of random effects
[which you shouldn't do? see #1] or (2) testing fixed effects in
the presence of overdispersion (and that one should do an F test
in this case and a Wald in the absence of overdispersion).
Opinions?

   3. A random, connecting-the-dots query: I'm puzzled that
in the context of likelihood ratio testing the appropriate test
distribution is chi-squared with a mixture between 0 and 1 df
(for a single variance term), while the appropriate degrees of freedom
calculation more generally (e.g. for AIC etc.) is thought to between
1 and N-1 -- it feels like these corrections are in opposite directions 
-- i.e., the LR test of a random effect on 1 df is *conservative* 
because of boundary effects, but when we think in other contexts,
using 1 df to denote "just a single variance term" is 
*anticonservative*.  What difference in context am I missing ... ?

   [Congratulations and thanks if you read this far.]

   cheers
     Ben Bolker



From roberta.varriale at gmail.com  Wed Jun 25 11:22:31 2008
From: roberta.varriale at gmail.com (roberta varriale)
Date: Wed, 25 Jun 2008 11:22:31 +0200
Subject: [R-sig-ME] nlme library
Message-ID: <93f44b5c0806250222q20e37e1fnb2d7c9c2fdfe438d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080625/fafba80c/attachment.pl>

From Fredrik.X.Nilsson at skane.se  Wed Jun 25 11:33:57 2008
From: Fredrik.X.Nilsson at skane.se (Nilsson Fredrik X)
Date: Wed, 25 Jun 2008 11:33:57 +0200
Subject: [R-sig-ME] nlme library
In-Reply-To: <93f44b5c0806250222q20e37e1fnb2d7c9c2fdfe438d@mail.gmail.com>
Message-ID: <87A0C64299B27148B40BE0DB83EDE2DB013A77B9@RSMAIL002.REG.SKANE.SE>

Hi Roberta,

Try:
m2<-m1$apVar
str(m2)
exp(attr(m2,"Pars"))
sought<-exp(attr(m2,"Pars"))[1]

Best,
Fredrik

----------------------------------------------------
Fredrik Nilsson, PhD
Competence Centre for Clinical Research
University Hospital, Lund
Tel: +46 46 177987
Fax: +46 46 176085

-----Ursprungligt meddelande-----
Fr?n: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] F?r roberta varriale
Skickat: den 25 juni 2008 11:23
Till: r-sig-mixed-models at r-project.org
?mne: [R-sig-ME] nlme library

Hello,
I'm Roberta.
I'm working with R since some months, but I still have some problems.
At the moment I'm using the library nlme, in particular the function
lme and I have a question.

Just as an example I write the code:
library(nlme)
library(SASmixed)
data(Mississippi)
m1 <- lme(y ~ 1, data = Mississippi, random = ~ 1|influent)
summary(m1)


and I obtain these results:

Linear mixed-effects model fit by REML
 Data: Mississippi
       AIC      BIC    logLik
  258.3511 263.1017 -126.1756

Random effects:
 Formula: ~1 | influent
        (Intercept) Residual
StdDev:    7.957598 6.531317

Fixed effects: y ~ 1
               Value Std.Error DF  t-value p-value
(Intercept) 21.22312  3.429034 31 6.189241       0

Standardized Within-Group Residuals:
        Min          Q1         Med          Q3         Max
-1.91443594 -0.53645956 -0.03217348  0.83713515  1.95823685

Number of Observations: 37
Number of Groups: 6


Now, I would like to recall the parameter "Random effects StdDev
(Intercept)", equal to 7.957598, but I'm not able to find its "R-name".
I read the Documentation on R web site and I found the "name" of other
parameters (such as ...$coeff$fixed and ...$sigma) but I really need that
one.
Someone can help me, please?

Thanks in advance,
best regards,
Roberta Varriale

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From HStevens at muohio.edu  Wed Jun 25 11:39:14 2008
From: HStevens at muohio.edu (Martin Henry H. Stevens)
Date: Wed, 25 Jun 2008 05:39:14 -0400
Subject: [R-sig-ME] nlme library
In-Reply-To: <93f44b5c0806250222q20e37e1fnb2d7c9c2fdfe438d@mail.gmail.com>
References: <93f44b5c0806250222q20e37e1fnb2d7c9c2fdfe438d@mail.gmail.com>
Message-ID: <B9A28DB8-49C7-4D13-8BB0-0B36848EE7F6@muohio.edu>

Hi Roberta,
The VarCorr extractor function should help:
 > VarCorr(m1)
influent = pdLogChol(1)
Variance StdDev
(Intercept) 63.323   7.9576
Residual    42.658   6.5313
 > as.numeric(VarCorr(m1)[1,2])
[1] 7.9576

Hank

On Jun 25, 2008, at 5:22 AM, roberta varriale wrote:
> Hello,
> I'm Roberta.
> I'm working with R since some months, but I still have some problems.
> At the moment I'm using the library nlme, in particular the function
> lme and I have a question.
>
> Just as an example I write the code:
> library(nlme)
> library(SASmixed)
> data(Mississippi)
> m1 <- lme(y ~ 1, data = Mississippi, random = ~ 1|influent)
> summary(m1)
>
>
> and I obtain these results:
>
> Linear mixed-effects model fit by REML
>  Data: Mississippi
>        AIC      BIC    logLik
>   258.3511 263.1017 -126.1756
>
> Random effects:
>  Formula: ~1 | influent
>         (Intercept) Residual
> StdDev:    7.957598 6.531317
>
> Fixed effects: y ~ 1
>                Value Std.Error DF  t-value p-value
> (Intercept) 21.22312  3.429034 31 6.189241       0
>
> Standardized Within-Group Residuals:
>         Min          Q1         Med          Q3         Max
> -1.91443594 -0.53645956 -0.03217348  0.83713515  1.95823685
>
> Number of Observations: 37
> Number of Groups: 6
>
>
> Now, I would like to recall the parameter "Random effects StdDev
> (Intercept)", equal to 7.957598, but I'm not able to find its "R- 
> name".
> I read the Documentation on R web site and I found the "name" of other
> parameters (such as ...$coeff$fixed and ...$sigma) but I really  
> need that
> one.
> Someone can help me, please?
>
> Thanks in advance,
> best regards,
> Roberta Varriale
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

Dr. Hank Stevens, Associate Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/~stevenmh/
http://www.users.muohio.edu/harkesae/
http://www.cas.muohio.edu/ecology
http://www.muohio.edu/botany/
"E Pluribus Unum"

"I love deadlines. I love the whooshing noise they make as they go by."
                                             (Douglas Adams)


If you send an attachment, please try to send it in a format anyone  
can read, such as PDF, text, Open Document Format, HTML, or RTF.
Why? See:  http://www.gnu.org/philosophy/no-word-attachments.html



From maechler at stat.math.ethz.ch  Wed Jun 25 12:35:49 2008
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 25 Jun 2008 12:35:49 +0200
Subject: [R-sig-ME] nlme xxxxxxx package
In-Reply-To: <93f44b5c0806250222q20e37e1fnb2d7c9c2fdfe438d@mail.gmail.com>
References: <93f44b5c0806250222q20e37e1fnb2d7c9c2fdfe438d@mail.gmail.com>
Message-ID: <18530.8069.317393.304362@stat.math.ethz.ch>

Hi Roberta,

>>>>> "rv" == roberta varriale <roberta.varriale at gmail.com>
>>>>>     on Wed, 25 Jun 2008 11:22:31 +0200 writes:

    rv> Hello, I'm Roberta.  I'm working with R since some
    rv> months, but I still have some problems.  At the moment
    rv> I'm using the library nlme, 

Since you are relatively new:  It's not the *library* but the 
*package* 'nlme' that you are using.
args(library) shows you that the first argument is called 
'package'.

    rv> in particular the function lme and I have a question.

Regards, and enjoy using R!

Martin Maechler, ETH Zurich



From bates at stat.wisc.edu  Wed Jun 25 13:46:09 2008
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 25 Jun 2008 06:46:09 -0500
Subject: [R-sig-ME] Fwd: CRAN packages maintained by you
In-Reply-To: <40e66e0b0806250443r4dd2af7bq6180441e360b0c9c@mail.gmail.com>
References: <18529.63045.2165.437781@fangorn.hornik.net>
	<40e66e0b0806250443r4dd2af7bq6180441e360b0c9c@mail.gmail.com>
Message-ID: <40e66e0b0806250446s1e4aa531i838744b44ab22f3d@mail.gmail.com>

The single argument version of the anova method for the "mer" class is
broken.  When the underlying representation was changed I didn't
change the code for one part of that method.  I'm looking at it now.


---------- Forwarded message ----------
From: Douglas Bates <bates at stat.wisc.edu>
Date: Wed, Jun 25, 2008 at 6:43 AM
Subject: Re: CRAN packages maintained by you
To: Kurt.Hornik at wu-wien.ac.at
Cc: Fabian Scheipl <fabian.scheipl at stat.uni-muenchen.de>, "Daniel B.
Wright" <danw at sussex.ac.uk>


The problem for the MEMSS package at least, and probably for the
others too, is caused by a bug in this version of lme4 in the anova
method for mer objects.  Give me a chance to fix that in version
0.999375-19 before trying to diagnose the problems with other
packages.  I should have caught this problem before releasing the
development version of lme4.  Time to add some more tests.


On Wed, Jun 25, 2008 at 2:39 AM, Kurt Hornik <Kurt.Hornik at wu-wien.ac.at> wrote:
> Dear maintainers,
>
> This concerns the packages
>
>  MEMSS RLRsim SASmixed mlmRev sdtalt
>
> which now fail to run its examples, most likely due to a recent upgrade
> in package lme4 (results will be available via
> http://cran.r-project.org/web/checks/check_summary.html later today).
>
> Can you please provide the necessary updates at your earliest
> convenience?
>
> Thanks
> -k
>



From roberta.varriale at gmail.com  Wed Jun 25 14:26:56 2008
From: roberta.varriale at gmail.com (roberta varriale)
Date: Wed, 25 Jun 2008 14:26:56 +0200
Subject: [R-sig-ME] nlme library
In-Reply-To: <93f44b5c0806250222q20e37e1fnb2d7c9c2fdfe438d@mail.gmail.com>
References: <93f44b5c0806250222q20e37e1fnb2d7c9c2fdfe438d@mail.gmail.com>
Message-ID: <93f44b5c0806250526p4b1242ebv34a686c13db3ab95@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080625/517bf8f5/attachment.pl>

From mariaevagongora at hotmail.com  Fri Jun 27 18:13:48 2008
From: mariaevagongora at hotmail.com (Maria Eva Gongora)
Date: Fri, 27 Jun 2008 13:13:48 -0300
Subject: [R-sig-ME] help random effects unested
Message-ID: <BAY120-W38DF7F32AC3BF8D2491C0AB6A20@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20080627/b678b544/attachment.pl>

From kjbeath at kagi.com  Sat Jun 28 04:16:52 2008
From: kjbeath at kagi.com (Ken Beath)
Date: Sat, 28 Jun 2008 12:16:52 +1000
Subject: [R-sig-ME] Development version of lme4 has been released to CRAN
In-Reply-To: <40e66e0b0806231247v30579e6bq7a658e9d17bce469@mail.gmail.com>
References: <40e66e0b0806231247v30579e6bq7a658e9d17bce469@mail.gmail.com>
Message-ID: <2D66E0E0-CD58-490F-8ACE-E59B3D5E2A4A@kagi.com>

On 24/06/2008, at 5:47 AM, Douglas Bates wrote:

> Early Sunday morning the development version of the lme4 package was
> released to CRAN.  There has already been one update version released
> and will be another later today.  The current CRAN version of the
> source and the Windows binary package is 0.999375-17.
>
> I expect that as users begin to install this package and try to run
> old code they will encounter issues.  I will be traveling and have
> limited email access from June 26 until July 2 and no email access
> from July 3 until July 8.
>
> I would appreciate it is those who are so helpful in responding to
> questions about lme4 on this list and on the R-help list could be
> extra vigilant during that period.  Some of the changes have been
> documented in the NEWS file.
>

Lack of a MacOS version seems to be first that MEMSS should be depends  
rather than suggests, then the Implementation.rnw vignette succeeds.  
Build then works for 0.999375-20 but check gives the following error

   >
   > e3 <- expand(nm3)
   > stopifnot(identical(sapply(e3, class),
   +                     c(sigma = "numeric", P = "pMatrix",
   +                       T = "dtCMatrix", S = "ddiMatrix"))
   +           , allEQ(e3$sigma, c(sigmaML = 0.76921295))
   +           , all(e3$P at perm == outer(12*(0:2), 1:12, "+"))
   +           , identical(as(e3$T, "diagonalMatrix"), Diagonal(3*12))
   +           , allEQ(e3$S at x, rep(c(0, 0.620071, 0.163092), each=12))
   +           )
   Error: identical(as(e3$T, "diagonalMatrix"), Diagonal(3 * 12)) is  
not TRUE
   Execution halted

MacOS X 10.5.3 Intel Core 2 Duo with R 2.7.1

Ken



From A.Robinson at ms.unimelb.edu.au  Sat Jun 28 04:17:46 2008
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Sat, 28 Jun 2008 12:17:46 +1000 (EST)
Subject: [R-sig-ME] help random effects unested
In-Reply-To: <BAY120-W38DF7F32AC3BF8D2491C0AB6A20@phx.gbl>
References: <BAY120-W38DF7F32AC3BF8D2491C0AB6A20@phx.gbl>
Message-ID: <49949.172.23.244.79.1214619466.squirrel@webmail.ms.unimelb.edu.au>

Hi Maria,

it sounds like you would like those factors to be crossed.  It is possible
to cross factors within lme but it is not easy - you might find some
guidelines searching R-help via Google.  Alternatively you could try to
use the lmer() function within the lme4 package, this function allows you
to cross random effects.

I hope that this helps,

Andrew

On Sat, June 28, 2008 2:13 am, Maria Eva Gongora wrote:
>
> I am using mixed effect models (library nlme, lme) to evaluate  factors
> that influence bycatch of hake in a shrimp fishery. Data are collected
> though an on-board observer program and  I decided to treat the vessel id
> and the observer id as random effects. A priori I would expect the
> observer effect to be independent of  vessel.  However, I did not find a
> way to incorporate both factors as independent, unnested random effects; I
> could only estimate the effects as ?vessel? and ?observer in vessel?
> (nested).
>
> Is it possible  to incorporate two random effects unested?
>
> Lic. Mar?a Eva G?ngora
>
>
> _________________________________________________________________
> Descarg? ya gratis y viv? la experiencia Windows Live.
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


Andrew Robinson
Senior Lecturer in Statistics                       Tel: +61-3-8344-6410
Department of Mathematics and Statistics            Fax: +61-3-8344 4599
University of Melbourne, VIC 3010 Australia
Email: a.robinson at ms.unimelb.edu.au    Website: http://www.ms.unimelb.edu.au



From maechler at stat.math.ethz.ch  Sat Jun 28 14:07:25 2008
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 28 Jun 2008 14:07:25 +0200
Subject: [R-sig-ME] Development version of lme4 has been released to CRAN
In-Reply-To: <2D66E0E0-CD58-490F-8ACE-E59B3D5E2A4A@kagi.com>
References: <40e66e0b0806231247v30579e6bq7a658e9d17bce469@mail.gmail.com>
	<2D66E0E0-CD58-490F-8ACE-E59B3D5E2A4A@kagi.com>
Message-ID: <18534.10621.675115.376749@cmath-5.math.ethz.ch>

>>>>> "KB" == Ken Beath <kjbeath at kagi.com>
>>>>>     on Sat, 28 Jun 2008 12:16:52 +1000 writes:

    KB> On 24/06/2008, at 5:47 AM, Douglas Bates wrote:

      >> Early Sunday morning the development version of the lme4 package was
      >> released to CRAN.  There has already been one update version released
      >> and will be another later today.  The current CRAN version of the
      >> source and the Windows binary package is 0.999375-17.
      >> 
      >> I expect that as users begin to install this package and try to run
      >> old code they will encounter issues.  I will be traveling and have
      >> limited email access from June 26 until July 2 and no email access
      >> from July 3 until July 8.
      >> 
      >> I would appreciate it is those who are so helpful in responding to
      >> questions about lme4 on this list and on the R-help list could be
      >> extra vigilant during that period.  Some of the changes have been
      >> documented in the NEWS file.

    KB> Lack of a MacOS version seems to be first that MEMSS should be depends  
    KB> rather than suggests, 

no, not at all:
>From "Writing R Extensions":

 >>    The optional `Suggests' field uses the same syntax as `Depends' and
 >> lists packages that are not necessarily needed.  This includes packages
 >> used only in examples or vignettes (*note Writing package vignettes::),

and it is true that you need the 'Suggests' packages when
*building* or *checking* the package itself.

    KB> then the Implementation.rnw vignette succeeds.  

(yes, see above)

    KB> Build then works for 0.999375-20 but check gives the following error

    >> 
    >> e3 <- expand(nm3)
    >> stopifnot(identical(sapply(e3, class),
    KB> +                     c(sigma = "numeric", P = "pMatrix",
    KB> +                       T = "dtCMatrix", S = "ddiMatrix"))
    KB> +           , allEQ(e3$sigma, c(sigmaML = 0.76921295))
    KB> +           , all(e3$P at perm == outer(12*(0:2), 1:12, "+"))
    KB> +           , identical(as(e3$T, "diagonalMatrix"), Diagonal(3*12))
    KB> +           , allEQ(e3$S at x, rep(c(0, 0.620071, 0.163092), each=12))
    KB> +           )
    KB> Error: identical(as(e3$T, "diagonalMatrix"), Diagonal(3 * 12)) is  
    KB> not TRUE
    KB> Execution halted

This looks like you are not using the current version of
'Matrix',  0.999375-10
which *is* required by  lme *-20, so I think you did not get
correct versions of one of the two packages.

Martin

    KB> MacOS X 10.5.3 Intel Core 2 Duo with R 2.7.1

    KB> Ken



From maechler at stat.math.ethz.ch  Sat Jun 28 14:35:39 2008
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 28 Jun 2008 14:35:39 +0200
Subject: [R-sig-ME] Development version of lme4 has been released to CRAN
In-Reply-To: <18534.10621.675115.376749@cmath-5.math.ethz.ch>
References: <40e66e0b0806231247v30579e6bq7a658e9d17bce469@mail.gmail.com>
	<2D66E0E0-CD58-490F-8ACE-E59B3D5E2A4A@kagi.com>
	<18534.10621.675115.376749@cmath-5.math.ethz.ch>
Message-ID: <18534.12315.474972.863315@cmath-5.math.ethz.ch>

>>>>> "MM" == Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>     on Sat, 28 Jun 2008 14:07:25 +0200 writes:

>>>>> "KB" == Ken Beath <kjbeath at kagi.com>
>>>>>     on Sat, 28 Jun 2008 12:16:52 +1000 writes:

    KB> On 24/06/2008, at 5:47 AM, Douglas Bates wrote:

    >>> Early Sunday morning the development version of the lme4 package was
    >>> released to CRAN.  There has already been one update version released
    >>> and will be another later today.  The current CRAN version of the
    >>> source and the Windows binary package is 0.999375-17.
    >>> 
    >>> I expect that as users begin to install this package and try to run
    >>> old code they will encounter issues.  I will be traveling and have
    >>> limited email access from June 26 until July 2 and no email access
    >>> from July 3 until July 8.
    >>> 
    >>> I would appreciate it is those who are so helpful in responding to
    >>> questions about lme4 on this list and on the R-help list could be
    >>> extra vigilant during that period.  Some of the changes have been
    >>> documented in the NEWS file.

    KB> Lack of a MacOS version seems to be first that MEMSS should be depends  
    KB> rather than suggests, 

    MM> no, not at all:
    >> From "Writing R Extensions":

    >>> The optional `Suggests' field uses the same syntax as `Depends' and
    >>> lists packages that are not necessarily needed.  This includes packages
    >>> used only in examples or vignettes (*note Writing package vignettes::),

    MM> and it is true that you need the 'Suggests' packages when
    MM> *building* or *checking* the package itself.

    KB> then the Implementation.rnw vignette succeeds.  

    MM> (yes, see above)

    KB> Build then works for 0.999375-20 but check gives the following error

    >>> 
    >>> e3 <- expand(nm3)
    >>> stopifnot(identical(sapply(e3, class),
    KB> +                     c(sigma = "numeric", P = "pMatrix",
    KB> +                       T = "dtCMatrix", S = "ddiMatrix"))
    KB> +           , allEQ(e3$sigma, c(sigmaML = 0.76921295))
    KB> +           , all(e3$P at perm == outer(12*(0:2), 1:12, "+"))
    KB> +           , identical(as(e3$T, "diagonalMatrix"), Diagonal(3*12))
    KB> +           , allEQ(e3$S at x, rep(c(0, 0.620071, 0.163092), each=12))
    KB> +           )
    KB> Error: identical(as(e3$T, "diagonalMatrix"), Diagonal(3 * 12)) is  
    KB> not TRUE
    KB> Execution halted

    MM> This looks like you are not using the current version of
    MM> 'Matrix',  0.999375-10
    MM> which *is* required by  lme *-20, so I think you did not get
    MM> correct versions of one of the two packages.

Oops!  I had changed the Depends to   'Matrix (>= 0.999375-10)'
but unfortunately this was *not* committed before lme *-20 was
built.  In other words, the above  *is* is wrong.

What remains true is that
update.packages() will solve that one problem.

Being sorry for the added confusion,
Martin

      KB> MacOS X 10.5.3 Intel Core 2 Duo with R 2.7.1
      KB> Ken



From HDoran at air.org  Mon Jun 30 13:38:48 2008
From: HDoran at air.org (Doran, Harold)
Date: Mon, 30 Jun 2008 07:38:48 -0400
Subject: [R-sig-ME] help random effects unested
In-Reply-To: <49949.172.23.244.79.1214619466.squirrel@webmail.ms.unimelb.edu.au>
Message-ID: <ED7B522EE00C9A4FA515AA71724D61EE4E4869@DC1EXCL01.air.org>

Like Andrew, I too am unclear. But, to me it sounds as though you want to treat the effects as uncorrelated and not as crossed per se, but I could be wrong. 

First, move to lmre and not lme. There is better support for the more recent package. Second, if you want uncorrelated random effects, please see the linear mixed effects article in R News which shows exactly how to do this.

http://cran.r-project.org/doc/Rnews/Rnews_2005-1.pdf 

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf 
> Of Andrew Robinson
> Sent: Friday, June 27, 2008 10:18 PM
> To: Maria Eva Gongora
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] help random effects unested
> 
> Hi Maria,
> 
> it sounds like you would like those factors to be crossed.  
> It is possible to cross factors within lme but it is not easy 
> - you might find some guidelines searching R-help via Google. 
>  Alternatively you could try to use the lmer() function 
> within the lme4 package, this function allows you to cross 
> random effects.
> 
> I hope that this helps,
> 
> Andrew
> 
> On Sat, June 28, 2008 2:13 am, Maria Eva Gongora wrote:
> >
> > I am using mixed effect models (library nlme, lme) to evaluate  
> > factors that influence bycatch of hake in a shrimp fishery. 
> Data are 
> > collected though an on-board observer program and  I 
> decided to treat 
> > the vessel id and the observer id as random effects. A 
> priori I would 
> > expect the observer effect to be independent of  vessel.  
> However, I 
> > did not find a way to incorporate both factors as independent, 
> > unnested random effects; I could only estimate the effects 
> as "vessel" and "observer in vessel"
> > (nested).
> >
> > Is it possible  to incorporate two random effects unested?
> >
> > Lic. Mar?a Eva G?ngora
> >
> >
> > _________________________________________________________________
> > Descarg? ya gratis y viv? la experiencia Windows Live.
> >
> > 	[[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> 
> 
> Andrew Robinson
> Senior Lecturer in Statistics                       Tel: 
> +61-3-8344-6410
> Department of Mathematics and Statistics            Fax: 
> +61-3-8344 4599
> University of Melbourne, VIC 3010 Australia
> Email: a.robinson at ms.unimelb.edu.au    Website: 
> http://www.ms.unimelb.edu.au
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 



