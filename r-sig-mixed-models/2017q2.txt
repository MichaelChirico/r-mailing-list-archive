From rdiaz02 at gmail.com  Sat Apr  1 10:19:33 2017
From: rdiaz02 at gmail.com (Ramon Diaz-Uriarte)
Date: Sat, 01 Apr 2017 10:19:33 +0200
Subject: [R-sig-ME] Modelling proportion data in lme4
In-Reply-To: <DADF81B50E6E3B4FA3919E97D839EEFD66F18D2E@EXC-JONES.nhm.ac.uk>
References: <DADF81B50E6E3B4FA3919E97D839EEFD66F18D2E@EXC-JONES.nhm.ac.uk>
Message-ID: <87inmosfoq.fsf@gmail.com>

Dear Adriana,


On Thu, 30-03-2017, at 09:41, Adriana De Palma <A.De-Palma at nhm.ac.uk> wrote:
> Dear all,
>
> I'd be really grateful if someone could advise on the following issue I've come across.
>
> I have proportion data (non-integer, bounded between 0 and 1) as my

Do you actually have some 0s? Most of the rest of my answer assumes you do.


> response variable, in a model that requires nested random effects and
> weights, which makes lme4 the ideal choice. Using lme4 with a binomial

You might want to take a look at:


http://stats.stackexchange.com/questions/81343/response-variable-percentage-and-too-many-zeros-zero-inflated-poisson

http://stats.stackexchange.com/questions/142038/two-part-models-in-r-continuous-outcome-with-too-many-zeros

http://stats.stackexchange.com/questions/142013/correct-glmer-distribution-family-and-link-for-a-continuous-zero-inflated-data-s/

and this R-help question (referred from the above questions, e.g. http://stats.stackexchange.com/a/81347):

https://stat.ethz.ch/pipermail/r-help/2005-January/065070.html

where using a Tweedie model is suggested.


The cplm CRAN package, by W. Zhang:
https://cran.r-project.org/web/packages/cplm/index.html

will fit mixed-effects Tweedies.


I'd suggesting checking the vignetted of the cplm package, as well as
Zhang's paper

http://link.springer.com/10.1007/s11222-012-9343-7


and Dunn and Smyth's 2005 paper, which contains examples that use the
Tweedie distribution, as well as several references in the literature where
these models have been used:

https://link.springer.com/article/10.1007/s11222-005-4070-y



Take all of this advice with a grain (or two) of salt, but in somewhat
similar cases, and when I had a structure of replicates that allowed me to
examine the relationship between mean and variance in the response, I have
used it to help me decide whether a Tweedie was, or not, a reasonable
choice compared to other options; for instance, with the Tweedie model we'd
expect to see a linear slope between log(variance) and log(mean), with the
slope, p, being the exponent in the relationship V(mu) = mu^p (see, e.g.,
Figure 3 in the paper by Dunn and Smyth).



> error structure and logit link seems to produce reasonable (and realistic
> looking) results, and the residual plots look good. However, it warns me
> that the error structure expects integer data, and I don't know whether
> this approach is doing what I think (and hope) that it is doing. I have
> tried to validate the lme4 results in the following ways:
>
>
> 1.  Running the same method (binomial error structure and logit link with
> the proportions as the response variable) with glmmADMB. This produces
> very different results (they are completely unrealistic, e.g. predicted
> proportion of 2.16e-34).
>
> 2.  Using beta regression with glmmADMB. This seems to work and produce
> results that are on the same scale, but not that close to those of lme4.
>
> 3.  Running an lme4 model with normal errors (lmer), after
> logit-transforming the response variable. This again gives quite
> different results to the lme4 model with binomial error structure and
> logit link (and the behaviour of the residuals is not ideal).
>
> Since these all give different results, it's hard to tell whether the
> lme4 method I've used is giving the 'right' answer. I would be really
> grateful for any advice. Is lme4 correctly analysing the proportion data
> when a binomial error structure and logit link are specified?
>
> Additional note: the proportion data are compositional similarity
> measurements (Jaccard assymetric abundance-based compositional
> similarity), so technically there is a numerator and denominator
> (numerator = abundance of species in Site 1 that are also present in Site
> 2; denominator = abundance of all species in Site 1). I've been exploring
> different weights options, but they generally include the denominator.

A couple of comments here:

1. I am not sure those proportion data can always be modelled as binomial.
Is the numerator a quantity we can think of as arising from a number of
independent trials, where the denominator is that number of independent
trials?


2. You might consider modeling the numerator using the denominator not as
denominator but as a covariate. This has the advantage of allowing you to
examine different possible relationships such as

Numerator ~  Denominator + other stuff

but also

Numerator ~ poly(Denominator, 2) + other stuff

or

Numerator ~ bs(Denominator) + other stuff


and just generally things like


Numerator ~ some_function_of(Denominator, some_other_covariates)

such as

Numerator ~ poly(Denominator, 2) * some_covariate


etc.


When you do

Numerator/Denominator ~ other stuff

you are committing yourself to one particular form of that relationship
(which might not be easy to reason about).



Best,


R.



>
> Many thanks in advance,
>
> Adriana
>
>
> _____
>
> Adriana De Palma
> PREDICTS Postdoctoral Research Assistant
> Natural History Museum
> South Kensington
>
> Web: The Purvis Lab<http://www.bio.ic.ac.uk/research/apurvis/ajpurvis.htm> | PREDICTS<predicts.org.uk>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


--
Ramon Diaz-Uriarte
Department of Biochemistry, Lab B-25
Facultad de Medicina
Universidad Aut?noma de Madrid
Arzobispo Morcillo, 4
28029 Madrid
Spain

Phone: +34-91-497-2412

Email: rdiaz02 at gmail.com
       ramon.diaz at iib.uam.es

http://ligarto.org/rdiaz


From paul.johnson at glasgow.ac.uk  Sat Apr  1 20:08:10 2017
From: paul.johnson at glasgow.ac.uk (Paul Johnson)
Date: Sat, 1 Apr 2017 18:08:10 +0000
Subject: [R-sig-ME] marginal R square calculation in zero truncated
 poisson	model
In-Reply-To: <7330bb44d56.58de6aac@uni-bielefeld.de>
References: <7330bb44d56.58de6aac@uni-bielefeld.de>
Message-ID: <6C67356E-DD11-4A15-B7D5-40664CA0500E@glasgow.ac.uk>

Hi Stephanie,

Starting with the caveat that I might have misunderstood your model?

It initially seemed strange to me to use a count distribution such as Poisson to model a continuous outcome such as a time interval. A zero-truncated Poisson is typically used when zeros exist but can?t be observed (e.g. number of eggs laid by an insect on leaves, where clutches of zero eggs can?t be observed). There might be no zeroes in your time interval responses, but that doesn?t mean that zeroes exist but are unobservable. However, I can see how a ZT Poisson might fit well, if the interval is measured in years and a 1 year interval is common while a zero-year interval never happens, and usually if the model fits well that?s enough to justify using it. In the case of a ZT Poisson however the estimates will refer to the untruncated model, i.e. the mean interval predicted by the model will be lower than the actual mean. If you?re only interested in the effect estimates, again that might not matter, but you might also want to consider other strictly positive distributions (e.g. gamma).

Re r-squared for ZT Poisson...

I don?t think anyone has worked out R-squared for a truncated Poisson GLMM, although I?m aware that Shinichi Nakagawa and Holger Schielzeth are working on extending their R-squared statistics to more distributions. It might be possible to calculate an R-squared that refers to the untruncated model that includes the missing zeroes. The problem is that the estimates will refer to the untruncated data (in you case including the ?unobserved? zero intervals) but when it comes to calculating the fixed effects variance you only have access to the truncated data. I haven?t had time to think this through, so will just leave it here in the hope that someone else picks it up. 

Some more general arm waving about R-squared for GLMMs... I?m a little sceptical anyway about how useful R-squared is for GL(M)Ms that don?t have an identity link, because of the difficulty of using variance components on the link scale (the log scale in your case) to explain variation in a response that is of course observed on a different scale (the count scale here). Nakagawa and Schielzeth devised some clever ways to get around this but we?re still left with the problem that a statistic which is meant to summarise explained variance in an intuitive way refers to an unintuitive scale. R-squared might be useful for explaining the amount of variance explained by different models fitted to the same data, but I find it hard to see how a Poisson model with a log link, a binomial model with a logit link and a Gaussian model with an identity link, fitted to different data sets, that all have marginal R-squareds of 30%, can all be said to have the same explanatory power. I guess your opinion on this will depend on whether you think marginal R-squared should have such a context-free interpretation, but I think this is how many people interpret it.

Best wishes,
Paul


> On 31 Mar 2017, at 13:41, Stephanie Kalberer <stephanie.kalberer at uni-bielefeld.de> wrote:
> 
> Dear Professor Bolker,
> I am looking into life history data of sea lions at the moment and would like to test what influences the length of the inter-birth interval. My response variable shows a clear poisson distribution but as I don't have any zeros in my inter-birth interval, I use a zero truncated model. The full model:
> glmmadmb(IBI..years.~ sex.first.offspring + SST.Jan.May. + IBI.of.previous.pup + birthyear_mother.num + birthyear_pup.num + first.offspring.of.interval.died.within.1st.year + (1|AnimalID), 
> family="truncpoiss", data=IBI_successive_pups_sexmat_OF_sex)
> I couldn't find any information though how to calculate the marginal R square in that case, could you point me towards a document or solution for it?
> Thanks a lot and best,
> Stephanie Kalberer
> -- 
> ___________________________
> 
> Stephanie Kalberer
> PhD Candidate
> Galapagos Sea Lion Project
> Department of Animal Behaviour
> Bielefeld University
> Germany
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From dmichl at uni-potsdam.de  Tue Apr  4 13:36:47 2017
From: dmichl at uni-potsdam.de (Diana Michl)
Date: Tue, 4 Apr 2017 13:36:47 +0200
Subject: [R-sig-ME] lmer-model - model ok? (control condition, random effects,
 log transformation)
Message-ID: <5b535c72-767a-0639-70a9-c5610ad39de7@uni-potsdam.de>

Dear all,

I'd be very thankful for a short feedback on whether my lmer-model is 
good the way it is. Thank you very much in advance!

I'm fitting log-10 reaction times (RT), reading times of sentences (s) 
of participants. The sentences are constructed in pairs: 1 test s. - 1 
control s. (as similar as possible to the test s.). The TEST sentences 
are in 4 conditions, i.e. they belong to one of four KINDS of sentences.

Sentences are matched in length (number of letters) and frequency 
(frequency of words averaged across sentence). Matching across ALL 
material is attempted but not quite possible, so the matching is done as 
well as possible within each test and control sentence pair.


First, I treated the material as 5 conditions: 1 control + 4 test 
conditions -> "cond5" (with contrast.treatment, i.e. control = dummy).
"Cond2| subj" means: random intercepts for test/control condition per 
subject. (Random slopes don't improve fit and aren't that important to me.)

The converging model with the best fit (AIC/BIC) is:

m1 <- lmer(logRT ~ cond5 + rat3 + (cond2|subject) + 
(length:frequency|item_ID), data, REML=F)


But I'm going back and forth on whether "cond5" is actually ok - or 
whether I need to compare the sentences ONLY pairwise, like: each of the 
4 conditions (or "kinds") only in test vs. control.
So I fit another model with a nested fixed effect. "cond4/cond2" means: 
4 conditions ("kinds") within test or control condition (with contr.sum, 
so sum contrasts).

The fit (AIC/BIC) is only a bit worse (910 vs. 905 above):

m2 <- lmer(logRT ~ cond4/cond2 + rat3 + (cond2|subject) + 
(length:frequency|item_ID), data, REML=F)


The results of the two models are the same. The fit is almost the same. 
My question is: Is one model more legitimate than the other, based on 
what I describe about the matching?
And is there something objectionable about how I fit the random effects? 
(My model doesn't necessarily converge when I change them.)

And I'm not 100% sure about whether I have to use logarithmized reaction 
times (=response variable). The raw reaction times have huge variance 
and are right-skewed. The log distribution is more normal, but still not 
a normal distribution. The model fit seems much better for the logRT, 
but the results differ slightly for logRT vs. raw RT.

Again thank you very much and I'd really appreciate your feedback. I 
hope I provided sufficient and non-confusing information.

Best

Diana

-- 
Diana Michl, M.A.
PhD candidate
International Experimental
and Clinical Linguistics
Universit?t Potsdam
www.ling.uni-potsdam.de/staff/dmichl


	[[alternative HTML version deleted]]


From dmichl at uni-potsdam.de  Tue Apr  4 13:36:47 2017
From: dmichl at uni-potsdam.de (Diana Michl)
Date: Tue, 4 Apr 2017 13:36:47 +0200
Subject: [R-sig-ME] lmer-model - model ok? (control condition, random effects,
 log transformation)
Message-ID: <5b535c72-767a-0639-70a9-c5610ad39de7@uni-potsdam.de>

Dear all,

I'd be very thankful for a short feedback on whether my lmer-model is 
good the way it is. Thank you very much in advance!

I'm fitting log-10 reaction times (RT), reading times of sentences (s) 
of participants. The sentences are constructed in pairs: 1 test s. - 1 
control s. (as similar as possible to the test s.). The TEST sentences 
are in 4 conditions, i.e. they belong to one of four KINDS of sentences.

Sentences are matched in length (number of letters) and frequency 
(frequency of words averaged across sentence). Matching across ALL 
material is attempted but not quite possible, so the matching is done as 
well as possible within each test and control sentence pair.


First, I treated the material as 5 conditions: 1 control + 4 test 
conditions -> "cond5" (with contrast.treatment, i.e. control = dummy).
"Cond2| subj" means: random intercepts for test/control condition per 
subject. (Random slopes don't improve fit and aren't that important to me.)

The converging model with the best fit (AIC/BIC) is:

m1 <- lmer(logRT ~ cond5 + rat3 + (cond2|subject) + 
(length:frequency|item_ID), data, REML=F)


But I'm going back and forth on whether "cond5" is actually ok - or 
whether I need to compare the sentences ONLY pairwise, like: each of the 
4 conditions (or "kinds") only in test vs. control.
So I fit another model with a nested fixed effect. "cond4/cond2" means: 
4 conditions ("kinds") within test or control condition (with contr.sum, 
so sum contrasts).

The fit (AIC/BIC) is only a bit worse (910 vs. 905 above):

m2 <- lmer(logRT ~ cond4/cond2 + rat3 + (cond2|subject) + 
(length:frequency|item_ID), data, REML=F)


The results of the two models are the same. The fit is almost the same. 
My question is: Is one model more legitimate than the other, based on 
what I describe about the matching?
And is there something objectionable about how I fit the random effects? 
(My model doesn't necessarily converge when I change them.)

And I'm not 100% sure about whether I have to use logarithmized reaction 
times (=response variable). The raw reaction times have huge variance 
and are right-skewed. The log distribution is more normal, but still not 
a normal distribution. The model fit seems much better for the logRT, 
but the results differ slightly for logRT vs. raw RT.

Again thank you very much and I'd really appreciate your feedback. I 
hope I provided sufficient and non-confusing information.

Best

Diana

-- 
Diana Michl, M.A.
PhD candidate
International Experimental
and Clinical Linguistics
Universit?t Potsdam
www.ling.uni-potsdam.de/staff/dmichl


	[[alternative HTML version deleted]]


From bhamlion78 at gmail.com  Tue Apr  4 00:18:28 2017
From: bhamlion78 at gmail.com (Leon Lee)
Date: Mon, 3 Apr 2017 18:18:28 -0400
Subject: [R-sig-ME] A question on setting up a generalized additive mixed
	effect model
Message-ID: <CAJDdXgbxVWJeYrPNdU4OoP-6=h=uPWEjxrNOy=NBQw43G663gQ@mail.gmail.com>

Dear R experts

I am new to R & generalized additive models and wonder whether I could get
some help from you all. The question I have is as follows:

I have 30 subjects with each subject being scanned one to three times in
the first year of life.

The brain volume (BrainVolume) from each scan was measured.

The scan time was randomly distributed from birth to 1 year, indexed by
subjIndexF. i.e., first three scans are from the same subject, the fourth
is from the second, subjIndexF=1,1,1,2...

Each subject has chronological age (age) from birth to 1 year old.

Now, I want to look at how predictors, such as subject's age will explain
the changes in brain volume. I also want to model both random slope and
intercept for random effects within each subject in the model. My model
ends up like this:


gam=gam(brainVolume~ s(age) + s(subjIndexF, bs=?re?) +  s(subjIndexF, age,
bs="re"), method="REML", data=mydata)


In which, s(subjeIndexF, bs=?re?) is for modeling random intercepts and
s(subjIndexF, age, bs=?re?) is for modeling different slopes. When I tried
to run the model, I was given a ?coefficients more than the data? error. So
my questions are as follows:


(1) Does this model make sense, especially the part dealing with the
repeated measures within subjects as random effects?

(2) If it does, what I can do to reduce the required parameters? The model
runs if I only model random intercepts without interaction term, but a more
realistic scenario would be each subject has random slope for smooths as
well.


Your help will be greatly appreciated!


I set up the model by raining following the suggestions in the following
two links:

http://www.sfs.uni-tuebingen.de/~jvanrij/Tutorial/GAMM.html

http://r.789695.n4.nabble.com/Random-effects-in-package-mgcv-td4720162.html

	[[alternative HTML version deleted]]


From ilgim.hepdarcan at izmirekonomi.edu.tr  Sat Apr  1 14:10:48 2017
From: ilgim.hepdarcan at izmirekonomi.edu.tr (Ilgim Hepdarcan)
Date: Sat, 1 Apr 2017 15:10:48 +0300 (EEST)
Subject: [R-sig-ME] Using lme function in R in a brain imaging study
In-Reply-To: <1123801866.15319410.1491047307374.JavaMail.zimbra@izmirekonomi.edu.tr>
Message-ID: <1743590346.15320072.1491048648395.JavaMail.zimbra@izmirekonomi.edu.tr>

Dear all, 
my study consists of 3 trials and each trial includes four different n-back types, 0-,1-,2-,3-back. Each participant had 12 n-back conditions, in a different order. Therefore, my design is a mixed design in which each participant were showed each n-back condition, which is a within-subject factor. Participants and gender of the participants are between-subject factors. 


While participants were performing n-back task, I have measured their dorsolateral prefrontal cortex activation via 16-channeled fNIR and obtained oxygenated hemoglobin measures from each of the 16 channels. Therefore, 16 oxygenated hemoglobin measures are my dependent variables. When I've checked examples on Internet, I always faced with examples of random variables which are continuous variables, like time or treatment. Because my random variables Trials and Nback Types (0-, 1-, 2-, and 3-back) are categorical variables, I've confused when I construct my multilevel model in R. Also, in my model repeated measures are nested within participants. 




Last but not least, I wonder if it is okay to construct my model based in two-way repeated measures anova using lme function in R? 







> library(nlme) 

> nullmodel = lme(Optode1 ~ 1, 

+ random = ~1|participant/Trial/NbackType, 

+ data = oxyHbConditionandTrialCellbyCell, 

+ na.action = na.exclude, 

+ method = "ML") 

> summary(nullmodel) 




> NbackType_Trial = update(baseline, .~. + NbackType*Trial) 

> summary(NbackType_Trial) 




> NbackType_Trial_gender = update(NbackType_Trial, .~. + NbackType*Trial*gender) 

> summary(NbackType_Trial_gender) 






> anova(nullmodel,NbackType_Trial,NbackType_Trial_gender) 








Thank you in advance, 

Ilg?m Hepdarcan 
Izmir University of Economics 
Experimental Psychology MD 





	[[alternative HTML version deleted]]


From Paul.Louisell at pw.utc.com  Tue Apr  4 03:43:21 2017
From: Paul.Louisell at pw.utc.com (Louisell, Paul T           PW)
Date: Tue, 4 Apr 2017 01:43:21 +0000
Subject: [R-sig-ME] [External] Re:  nlme & varIdent
Message-ID: <64d9b16327f747efbc6dc6060c2ab28f@UUSALE0A.utcmail.com>

Thierry,

Thanks for responding--apologies for not clarifying my question sooner. A simple way of explaining the model would be that I have factor F nested in G, also a factor, and a continuous covariate C. I want the residual variance to vary by levels of G (handled by the varIdent function, as you point out below). Additionally, the levels of F interact with the covariate C, and I want to test/fit a model where the random effect variance for F:C changes with G's levels.

E.g., say G has 2 levels, a and b. Then there should be two variance parameters (?a and ?b), one applying to random slopes associated with F:C for levels of F nested in G level a, and one for levels of F nested in G level b. The appropriate covariance matrix is diagonal, but unlike pdDiag, it only has 2 unrestricted parameters (one for each level of G), but it has dimension nlevels(F).

Paul Louisell
Statistical Specialist
Paul.Louisell at pw.utc.com
860-565-8104

Still, tomorrow's going to be another working day, and I'm trying to get some rest.
That's all, I'm trying to get some rest.
Paul Simon, ?American Tune?

From: Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be]
Sent: Monday, November 14, 2016 4:04 AM
To: Louisell, Paul T PW
Cc: r-sig-mixed-models at r-project.org
Subject: [External] Re: [R-sig-ME] nlme & varIdent

Dear Paul,

Note that variance functions work on the residuals, not the random effect variances. I can't comment further on this as your question is not very clear to me. Can you provide a more detailed example. E.g. the formula and who you want to variance or correlation functions to work.

Best regards,


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey

2016-11-12 0:52 GMT+01:00 Louisell, Paul T PW <Paul.Louisell at pw.utc.com>:
Hello,

All the help I've read (including Pinheiro and Bates book, 'Mixed Effects Models in S and S-PLUS') regarding how to fit a linear mixed-effects model where variances change with a factor's levels indicates this is done through the 'weights' argument to 'lme', using something like 'weights=varIdent(form=~v|g)' where 'v' is a variance covariate and 'g' is the grouping factor whose strata have different random effect variances.

My question: Suppose I have more than 1 variance covariate, say v1, ..., vk, and I want _each_ of these to have variances that change with the levels of g giving a total of k*nlevels(g) parameters (k*nlevels(g) - k allowing for identifiability). How is this handled in the nlme package? A simple example would be random slope and intercepts, _both_ of which have variances changing with the levels of g. I haven't found any examples of this online or in Pinheiro & Bates, and I haven't been able to figure this out using the various varFunc/pdMat classes. I'd use the 'lme4' package (instead of nlme), but I need the correlated residuals structure (e.g., 'corAR1', 'corARMA') provided in nlme.

Help/advice would be greatly appreciated.

Thanks,

Paul Louisell
Statistical Specialist
Paul.Louisell at pw.utc.com
860-565-8104

Still, tomorrow's going to be another working day, and I'm trying to get some rest.
That's all, I'm trying to get some rest.
Paul Simon, "American Tune"

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



	[[alternative HTML version deleted]]


From mmonasterolo at agro.uba.ar  Tue Apr  4 23:15:05 2017
From: mmonasterolo at agro.uba.ar (Marcos Monasterolo)
Date: Tue, 4 Apr 2017 18:15:05 -0300
Subject: [R-sig-ME] Fwd: GLM-normal distribution
In-Reply-To: <CAJ-MGDTCX+iz3wkWQ_0Sio1_3zOk0_qYz0=01rDc-19vwAkTUw@mail.gmail.com>
References: <CAJ-MGDTCX+iz3wkWQ_0Sio1_3zOk0_qYz0=01rDc-19vwAkTUw@mail.gmail.com>
Message-ID: <CAJ-MGDTYGhMmkWXvbgLN5RBF_twz1N7Ab5Kh+VYnAZnm-ng7Dg@mail.gmail.com>

Dear all. I am doing an analysis on proportion data resulting from counts.
As I do have the count data available I am running a glm with binomial
distribution. However, after realizing the response variable is normal
(Anderson-Darling test did not reject normality of the calculated
proportions) I am now having second thoughts as to whether it might also be
possible to run a normal lm with proportion as the response variable. The
thing is one of the explanatory variables ("ancho", which I am really
interested in) is not significant in the binomial glm but significant in
the lm. My understanding is that I should stick with the binomial GLM, but
I wanted to have an expert opinion on this.
I provide a working code below. Thanks in advance for your help.
Marcos


id <- "0B6X3EoqLHXG-dnZqTXpWSkRPYkE" # google file ID
mis.datos <- read.table(sprintf("https://docs.google.com/uc?id=%s&
export=download", id), header = TRUE,sep=";",dec=",")
mis.datos1<-mis.datos[-c(3,6,7,8),] #these data points I don't need
library(nortest)
ad.test(mis.datos1$propexot)#evaluate normality
hist(mis.datos1$propexot)
library(lme4)
M1 <- glm(cbind(exot, nativ) ~ anchom + tipdecamp + exph500, data =
mis.datos1, family =binomial)# the syntax of my model
summary(M1)

----
Bi?l. Marcos Monasterolo
Becario doctoral - C?tedra de Bot?nica General, Facultad de Agronom?a, UBA

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue Apr  4 23:47:19 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 4 Apr 2017 17:47:19 -0400
Subject: [R-sig-ME] Fwd: GLM-normal distribution
In-Reply-To: <CAJ-MGDTYGhMmkWXvbgLN5RBF_twz1N7Ab5Kh+VYnAZnm-ng7Dg@mail.gmail.com>
References: <CAJ-MGDTCX+iz3wkWQ_0Sio1_3zOk0_qYz0=01rDc-19vwAkTUw@mail.gmail.com>
 <CAJ-MGDTYGhMmkWXvbgLN5RBF_twz1N7Ab5Kh+VYnAZnm-ng7Dg@mail.gmail.com>
Message-ID: <77d7416c-d05e-516e-b452-11ac13aeafb3@gmail.com>


  This isn't really a mixed model question: it would be more appropriate
for a generic stats or stats-ecology forum (e.g.
r-sig-ecology at r-project.org, or CrossValidated
[http://stats.stackexchange.com]

   A couple of quick points:

- you don't need lme4 at all since you don't have a random effect in
your model
- a rule of thumb is that you shouldn't try to fit more than 1 model
parameter per 10-15 data points, so this model (4 parameters for 19 data
points) is pushing it a bit
- you should not assess normality based on the *marginal* distribution;
instead you should look at the residuals from the model (e.g. see
plot(M2) below)
- if you weight the linear model by number of species (as is probably
appropriate) you get a p-value of 0.052
- your data are slightly underdispersed (less variance than expected
from binomial); if you account for this by using family=quasibinomial
you get almost identical results to the linear model.

  Overall I would say you have *weak* evidence at best for an effect of
anchom.


M1 <- glm(cbind(exot, nativ) ~ anchom + tipdecamp + exph500,
          data =mis.datos1, family =binomial)# the syntax of my model
summary(M1)
M2 <- lm(exot/(nativ+exot) ~ anchom + tipdecamp + exph500,
         data =mis.datos1, weight=nativ+exot)
summary(M2)
plot(M2)

library(ggplot2); theme_set(theme_bw())
library(dplyr)
library(tidyr)
d2 <- mis.datos %>%
    mutate(tot=exot+nativ,
           prop_exot=exot/tot) %>%
    select(prop_exot,tot,anchom,tipdecamp,exph500) %>%
    gather(var,value,-c(prop_exot,tot,tipdecamp))

ggplot(d2 ,aes(value,prop_exot,colour=tipdecamp))+
    geom_point(aes(size=tot))+facet_wrap(~var,scale="free_x")+
    geom_smooth(method="glm",aes(weight=tot),
                method.args=list(family=binomial))


deviance(M1)/df.residual(M1)
M3 <- update(M1, family =quasibinomial)

## scale parameters
d3 <- mis.datos %>%
    mutate(anchom=scale(anchom),
           exph500=scale(exph500))

M4 <- update(M3, data=d3)
library(dotwhisker)
dwplot(list(M4))+geom_vline(xintercept=0,lty=2)



On 17-04-04 05:15 PM, Marcos Monasterolo wrote:
> Dear all. I am doing an analysis on proportion data resulting from counts.
> As I do have the count data available I am running a glm with binomial
> distribution. However, after realizing the response variable is normal
> (Anderson-Darling test did not reject normality of the calculated
> proportions) I am now having second thoughts as to whether it might also be
> possible to run a normal lm with proportion as the response variable. The
> thing is one of the explanatory variables ("ancho", which I am really
> interested in) is not significant in the binomial glm but significant in
> the lm. My understanding is that I should stick with the binomial GLM, but
> I wanted to have an expert opinion on this.
> I provide a working code below. Thanks in advance for your help.
> Marcos
> 
> 
> id <- "0B6X3EoqLHXG-dnZqTXpWSkRPYkE" # google file ID
> mis.datos <- read.table(sprintf("https://docs.google.com/uc?id=%s&
> export=download", id), header = TRUE,sep=";",dec=",")
> mis.datos1<-mis.datos[-c(3,6,7,8),] #these data points I don't need
> library(nortest)
> ad.test(mis.datos1$propexot)#evaluate normality
> hist(mis.datos1$propexot)
> library(lme4)
> M1 <- glm(cbind(exot, nativ) ~ anchom + tipdecamp + exph500, data =
> mis.datos1, family =binomial)# the syntax of my model
> summary(M1)
> 
> ----
> Bi?l. Marcos Monasterolo
> Becario doctoral - C?tedra de Bot?nica General, Facultad de Agronom?a, UBA
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From Phillip.Alday at unisa.edu.au  Wed Apr  5 06:40:04 2017
From: Phillip.Alday at unisa.edu.au (Phillip Alday)
Date: Wed, 5 Apr 2017 04:40:04 +0000
Subject: [R-sig-ME] Using lme function in R in a brain imaging study
In-Reply-To: <1743590346.15320072.1491048648395.JavaMail.zimbra@izmirekonomi.edu.tr>
References: <1743590346.15320072.1491048648395.JavaMail.zimbra@izmirekonomi.edu.tr>
Message-ID: <95FFA19E-75B5-4226-BCB7-B378A40D8FAB@unisa.edu.au>

Dear IIlgim,

If I'm understanding your design correctly, then you have you crossed random effects -- you can think of participants as being nested within trials or trials as being nested within participant. I would recommend using lme4 instead of nlme for such designs.

I am not familiar with the specifics of fNIRS, but I'm guessing that the statistical analysis is somewhat similar to EEG, at least in terms of sensor placement, even if the units of measurement and temporal resolution are quite different. As such, it might make sense for you to look at resources discussing mixed models for EEG / ERP, including posts like this https://stat.ethz.ch/pipermail/r-help/2015-September/432520.html (by me).

You will also find a lot of resources from psycholinguistics, but the literature there often uses the terms "items" and "subjects" instead of "trials" and "participants", but these are essentially the same thing. In your case, you only have three trials per conditions, so you can't model that as a random effect (grouping variable). There are all sorts of rules of thumb for how many levels you need, but I generally wouldn't let something be a grouping variable (see below) with less than about 10 levels.

I'm not sure I would treat your n-back conditions as categorical -- if you treat n-back as a continuous variable, then you can make predictions about the response for arbitrary n. It depends on whether or not you expect the response to change in a linear fashion. If you don't, then treat the different types of n-back as categorical. (There are other ways to address non-linearity, but they may be a bit much for now.)  

There are also seems to be some terminological confusion around "random variables". You need to distinguish between the grouping variables (the stuff behind the vertical bar |), which are always discrete, and the "random slopes" (the stuff before the vertical bar |), which are predictors like any other and can be categorical or continuous. The trick is to read the vertical bar | as "by", so 

predictor | participant

is just "allow the strength of this predictor to vary by participant".

All that said, I would try something like the following (assuming you have enough participants to fit all these parameters):

library(lme4)

model <- lmer(nirs_response ~ NbackType * Trial * roi + (1 + NbackType |  participant), 
 data=oxyHbConditionandTrialCellbyCell, REML=FALSE)

model.gender <- update(model, . ~ . * gender)

anova(model, model.gender)

----

"roi" stands for "region of interest". For computational simplicity and model parsimony, I would not try to do things by sensor, but rather by groups of adjacent sensors (ROIs).  You can average across sensors to produce a single value for each ROI, which will also simplify things a bit.

Best,
Phillip




> On 1 Apr 2017, at 22:40, Ilgim Hepdarcan <ilgim.hepdarcan at izmirekonomi.edu.tr> wrote:
> 
> Dear all, 
> my study consists of 3 trials and each trial includes four different n-back types, 0-,1-,2-,3-back. Each participant had 12 n-back conditions, in a different order. Therefore, my design is a mixed design in which each participant were showed each n-back condition, which is a within-subject factor. Participants and gender of the participants are between-subject factors. 
> 
> 
> While participants were performing n-back task, I have measured their dorsolateral prefrontal cortex activation via 16-channeled fNIR and obtained oxygenated hemoglobin measures from each of the 16 channels. Therefore, 16 oxygenated hemoglobin measures are my dependent variables. When I've checked examples on Internet, I always faced with examples of random variables which are continuous variables, like time or treatment. Because my random variables Trials and Nback Types (0-, 1-, 2-, and 3-back) are categorical variables, I've confused when I construct my multilevel model in R. Also, in my model repeated measures are nested within participants. 
> 
> 
> 
> 
> Last but not least, I wonder if it is okay to construct my model based in two-way repeated measures anova using lme function in R? 
> 
> 
> 
> 
> 
> 
> 
>> library(nlme) 
> 
>> nullmodel = lme(Optode1 ~ 1, 
> 
> + random = ~1|participant/Trial/NbackType, 
> 
> + data = oxyHbConditionandTrialCellbyCell, 
> 
> + na.action = na.exclude, 
> 
> + method = "ML") 
> 
>> summary(nullmodel) 
> 
> 
> 
> 
>> NbackType_Trial = update(baseline, .~. + NbackType*Trial) 
> 
>> summary(NbackType_Trial) 
> 
> 
> 
> 
>> NbackType_Trial_gender = update(NbackType_Trial, .~. + NbackType*Trial*gender) 
> 
>> summary(NbackType_Trial_gender) 
> 
> 
> 
> 
> 
> 
>> anova(nullmodel,NbackType_Trial,NbackType_Trial_gender) 
> 
> 
> 
> 
> 
> 
> 
> 
> Thank you in advance, 
> 
> Ilg?m Hepdarcan 
> Izmir University of Economics 
> Experimental Psychology MD 
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From pierces1 at msu.edu  Wed Apr  5 14:40:12 2017
From: pierces1 at msu.edu (Steven J. Pierce)
Date: Wed, 5 Apr 2017 08:40:12 -0400
Subject: [R-sig-ME] Fwd: GLM-normal distribution
In-Reply-To: <CAJ-MGDTYGhMmkWXvbgLN5RBF_twz1N7Ab5Kh+VYnAZnm-ng7Dg@mail.gmail.com>
References: <CAJ-MGDTCX+iz3wkWQ_0Sio1_3zOk0_qYz0=01rDc-19vwAkTUw@mail.gmail.com>
 <CAJ-MGDTYGhMmkWXvbgLN5RBF_twz1N7Ab5Kh+VYnAZnm-ng7Dg@mail.gmail.com>
Message-ID: <000201d2ae09$c5034430$4f09cc90$@msu.edu>

Marcos,

In addition to Ben Bolker's very sound advice, I'd like to suggest that if you've got the technical ability to fit and interpret a glm that is more conceptually appropriate than the lm given the nature of the data, you should just stick with that. The scientific objective should not be to fish for some way to make the effect of interest come out with a significant p-value by running lots of variations on a given analysis, it is to get an accurate and trustworthy answer about your hypothesis without doing any p-hacking. You may be at risk of introducing opportunistic bias into your research here. Take a look at this paper by DeCoster et al. (2015), which discusses this issue and ways to avoid it. 

DeCoster, J., Sparks, E. A., Sparks, J. C., Sparks, G. G., & Sparks, C. W. (2015). Opportunistic biases: Their origins, effects, and an integrated solution. American Psychologist, 70(6), 499-514. doi:10.1037/a0039191

Best regards,

Steven J. Pierce, Ph.D.
Acting Director; Associate Director
Center for Statistical Training & Consulting (CSTAT)
Michigan State University

-----Original Message-----
From: Marcos Monasterolo [mailto:mmonasterolo at agro.uba.ar] 
Sent: Tuesday, April 04, 2017 5:15 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Fwd: GLM-normal distribution

Dear all. I am doing an analysis on proportion data resulting from counts.
As I do have the count data available I am running a glm with binomial
distribution. However, after realizing the response variable is normal
(Anderson-Darling test did not reject normality of the calculated
proportions) I am now having second thoughts as to whether it might also be
possible to run a normal lm with proportion as the response variable. The
thing is one of the explanatory variables ("ancho", which I am really
interested in) is not significant in the binomial glm but significant in
the lm. My understanding is that I should stick with the binomial GLM, but
I wanted to have an expert opinion on this.
I provide a working code below. Thanks in advance for your help.
Marcos


id <- "0B6X3EoqLHXG-dnZqTXpWSkRPYkE" # google file ID
mis.datos <- read.table(sprintf("https://docs.google.com/uc?id=%s&
export=download", id), header = TRUE,sep=";",dec=",")
mis.datos1<-mis.datos[-c(3,6,7,8),] #these data points I don't need
library(nortest)
ad.test(mis.datos1$propexot)#evaluate normality
hist(mis.datos1$propexot)
library(lme4)
M1 <- glm(cbind(exot, nativ) ~ anchom + tipdecamp + exph500, data =
mis.datos1, family =binomial)# the syntax of my model
summary(M1)

----
Bi?l. Marcos Monasterolo
Becario doctoral - C?tedra de Bot?nica General, Facultad de Agronom?a, UBA

	[[alternative HTML version deleted]]


From A.De-Palma at nhm.ac.uk  Thu Apr  6 12:28:30 2017
From: A.De-Palma at nhm.ac.uk (Adriana De Palma)
Date: Thu, 6 Apr 2017 10:28:30 +0000
Subject: [R-sig-ME] Modelling proportion data in lme4
In-Reply-To: <87inmosfoq.fsf@gmail.com>
References: <DADF81B50E6E3B4FA3919E97D839EEFD66F18D2E@EXC-JONES.nhm.ac.uk>
 <87inmosfoq.fsf@gmail.com>
Message-ID: <DADF81B50E6E3B4FA3919E97D839EEFD66F1C06B@EXC-JONES.nhm.ac.uk>

Dear Ramon and Thierry,

Thank you very much for your suggestions. In answer to your questions:

 - I do have 0s in my data. 
 - I don't think we can consider the denominator independent trails in this case. As it is the total abundance of a set of species, each species is 'block voting'. 

RE: Ramon's suggestion of a tweedie model for modelling the numerator as the response variable. The proportion data really is the measure that needs to be modelled as this is the compositional similarity calculation, so I'm not sure that a tweedie model will be suitable. 

RE Thierry's suggestion: Would it still be suitable to use to total abundance of species as the weights in a binomial model, even if the trials aren't strictly independent?

Thanks both for all your help! Any further advice would be very gratefully received!

Many thanks,

Adriana




-----Original Message-----
From: Ramon Diaz-Uriarte [mailto:rdiaz02 at gmail.com] 
Sent: 01 April 2017 09:20
To: Adriana De Palma
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Modelling proportion data in lme4

Dear Adriana,


On Thu, 30-03-2017, at 09:41, Adriana De Palma <A.De-Palma at nhm.ac.uk> wrote:
> Dear all,
>
> I'd be really grateful if someone could advise on the following issue I've come across.
>
> I have proportion data (non-integer, bounded between 0 and 1) as my

Do you actually have some 0s? Most of the rest of my answer assumes you do.


> response variable, in a model that requires nested random effects and 
> weights, which makes lme4 the ideal choice. Using lme4 with a binomial

You might want to take a look at:


http://stats.stackexchange.com/questions/81343/response-variable-percentage-and-too-many-zeros-zero-inflated-poisson

http://stats.stackexchange.com/questions/142038/two-part-models-in-r-continuous-outcome-with-too-many-zeros

http://stats.stackexchange.com/questions/142013/correct-glmer-distribution-family-and-link-for-a-continuous-zero-inflated-data-s/

and this R-help question (referred from the above questions, e.g. http://stats.stackexchange.com/a/81347):

https://stat.ethz.ch/pipermail/r-help/2005-January/065070.html

where using a Tweedie model is suggested.


The cplm CRAN package, by W. Zhang:
https://cran.r-project.org/web/packages/cplm/index.html

will fit mixed-effects Tweedies.


I'd suggesting checking the vignetted of the cplm package, as well as Zhang's paper

http://link.springer.com/10.1007/s11222-012-9343-7


and Dunn and Smyth's 2005 paper, which contains examples that use the Tweedie distribution, as well as several references in the literature where these models have been used:

https://link.springer.com/article/10.1007/s11222-005-4070-y



Take all of this advice with a grain (or two) of salt, but in somewhat similar cases, and when I had a structure of replicates that allowed me to examine the relationship between mean and variance in the response, I have used it to help me decide whether a Tweedie was, or not, a reasonable choice compared to other options; for instance, with the Tweedie model we'd expect to see a linear slope between log(variance) and log(mean), with the slope, p, being the exponent in the relationship V(mu) = mu^p (see, e.g., Figure 3 in the paper by Dunn and Smyth).



> error structure and logit link seems to produce reasonable (and 
> realistic
> looking) results, and the residual plots look good. However, it warns 
> me that the error structure expects integer data, and I don't know 
> whether this approach is doing what I think (and hope) that it is 
> doing. I have tried to validate the lme4 results in the following ways:
>
>
> 1.  Running the same method (binomial error structure and logit link 
> with the proportions as the response variable) with glmmADMB. This 
> produces very different results (they are completely unrealistic, e.g. 
> predicted proportion of 2.16e-34).
>
> 2.  Using beta regression with glmmADMB. This seems to work and 
> produce results that are on the same scale, but not that close to those of lme4.
>
> 3.  Running an lme4 model with normal errors (lmer), after 
> logit-transforming the response variable. This again gives quite 
> different results to the lme4 model with binomial error structure and 
> logit link (and the behaviour of the residuals is not ideal).
>
> Since these all give different results, it's hard to tell whether the
> lme4 method I've used is giving the 'right' answer. I would be really 
> grateful for any advice. Is lme4 correctly analysing the proportion 
> data when a binomial error structure and logit link are specified?
>
> Additional note: the proportion data are compositional similarity 
> measurements (Jaccard assymetric abundance-based compositional 
> similarity), so technically there is a numerator and denominator 
> (numerator = abundance of species in Site 1 that are also present in 
> Site 2; denominator = abundance of all species in Site 1). I've been 
> exploring different weights options, but they generally include the denominator.

A couple of comments here:

1. I am not sure those proportion data can always be modelled as binomial.
Is the numerator a quantity we can think of as arising from a number of independent trials, where the denominator is that number of independent trials?


2. You might consider modeling the numerator using the denominator not as denominator but as a covariate. This has the advantage of allowing you to examine different possible relationships such as

Numerator ~  Denominator + other stuff

but also

Numerator ~ poly(Denominator, 2) + other stuff

or

Numerator ~ bs(Denominator) + other stuff


and just generally things like


Numerator ~ some_function_of(Denominator, some_other_covariates)

such as

Numerator ~ poly(Denominator, 2) * some_covariate


etc.


When you do

Numerator/Denominator ~ other stuff

you are committing yourself to one particular form of that relationship (which might not be easy to reason about).



Best,


R.



>
> Many thanks in advance,
>
> Adriana
>
>
> _____
>
> Adriana De Palma
> PREDICTS Postdoctoral Research Assistant Natural History Museum South 
> Kensington
>
> Web: The Purvis 
> Lab<http://www.bio.ic.ac.uk/research/apurvis/ajpurvis.htm> | 
> PREDICTS<predicts.org.uk>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


--
Ramon Diaz-Uriarte
Department of Biochemistry, Lab B-25
Facultad de Medicina
Universidad Aut?noma de Madrid
Arzobispo Morcillo, 4
28029 Madrid
Spain

Phone: +34-91-497-2412

Email: rdiaz02 at gmail.com
       ramon.diaz at iib.uam.es

http://ligarto.org/rdiaz

From guillaumechaumet at gmail.com  Thu Apr  6 18:17:01 2017
From: guillaumechaumet at gmail.com (guillaume chaumet)
Date: Thu, 6 Apr 2017 18:17:01 +0200
Subject: [R-sig-ME] Modelling proportion data in lme4
In-Reply-To: <DADF81B50E6E3B4FA3919E97D839EEFD66F1C06B@EXC-JONES.nhm.ac.uk>
References: <DADF81B50E6E3B4FA3919E97D839EEFD66F18D2E@EXC-JONES.nhm.ac.uk>
 <87inmosfoq.fsf@gmail.com>
 <DADF81B50E6E3B4FA3919E97D839EEFD66F1C06B@EXC-JONES.nhm.ac.uk>
Message-ID: <CAGg8SkKpWFKzi9enreTxGypaVR0FpSpUcjrR0e0hXSpT9rOOpw@mail.gmail.com>

You could to try to investigate beta distribution but if you have 0s
or 1s, STAN implementation do not handle 0 or 1. Perhaps, zero
inflated or zero-one inflated beta distribution in STAN could provide
you some help.
"brms" package https://github.com/paul-buerkner/brms have implemented
zero-inflated beta distribution and Paul Buerkner have planned to
implement zero-one inflated beta distribution.

Cheers

Guillaume

2017-04-06 12:28 GMT+02:00 Adriana De Palma <A.De-Palma at nhm.ac.uk>:
> Dear Ramon and Thierry,
>
> Thank you very much for your suggestions. In answer to your questions:
>
>  - I do have 0s in my data.
>  - I don't think we can consider the denominator independent trails in this case. As it is the total abundance of a set of species, each species is 'block voting'.
>
> RE: Ramon's suggestion of a tweedie model for modelling the numerator as the response variable. The proportion data really is the measure that needs to be modelled as this is the compositional similarity calculation, so I'm not sure that a tweedie model will be suitable.
>
> RE Thierry's suggestion: Would it still be suitable to use to total abundance of species as the weights in a binomial model, even if the trials aren't strictly independent?
>
> Thanks both for all your help! Any further advice would be very gratefully received!
>
> Many thanks,
>
> Adriana
>
>
>
>
> -----Original Message-----
> From: Ramon Diaz-Uriarte [mailto:rdiaz02 at gmail.com]
> Sent: 01 April 2017 09:20
> To: Adriana De Palma
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Modelling proportion data in lme4
>
> Dear Adriana,
>
>
> On Thu, 30-03-2017, at 09:41, Adriana De Palma <A.De-Palma at nhm.ac.uk> wrote:
>> Dear all,
>>
>> I'd be really grateful if someone could advise on the following issue I've come across.
>>
>> I have proportion data (non-integer, bounded between 0 and 1) as my
>
> Do you actually have some 0s? Most of the rest of my answer assumes you do.
>
>
>> response variable, in a model that requires nested random effects and
>> weights, which makes lme4 the ideal choice. Using lme4 with a binomial
>
> You might want to take a look at:
>
>
> http://stats.stackexchange.com/questions/81343/response-variable-percentage-and-too-many-zeros-zero-inflated-poisson
>
> http://stats.stackexchange.com/questions/142038/two-part-models-in-r-continuous-outcome-with-too-many-zeros
>
> http://stats.stackexchange.com/questions/142013/correct-glmer-distribution-family-and-link-for-a-continuous-zero-inflated-data-s/
>
> and this R-help question (referred from the above questions, e.g. http://stats.stackexchange.com/a/81347):
>
> https://stat.ethz.ch/pipermail/r-help/2005-January/065070.html
>
> where using a Tweedie model is suggested.
>
>
> The cplm CRAN package, by W. Zhang:
> https://cran.r-project.org/web/packages/cplm/index.html
>
> will fit mixed-effects Tweedies.
>
>
> I'd suggesting checking the vignetted of the cplm package, as well as Zhang's paper
>
> http://link.springer.com/10.1007/s11222-012-9343-7
>
>
> and Dunn and Smyth's 2005 paper, which contains examples that use the Tweedie distribution, as well as several references in the literature where these models have been used:
>
> https://link.springer.com/article/10.1007/s11222-005-4070-y
>
>
>
> Take all of this advice with a grain (or two) of salt, but in somewhat similar cases, and when I had a structure of replicates that allowed me to examine the relationship between mean and variance in the response, I have used it to help me decide whether a Tweedie was, or not, a reasonable choice compared to other options; for instance, with the Tweedie model we'd expect to see a linear slope between log(variance) and log(mean), with the slope, p, being the exponent in the relationship V(mu) = mu^p (see, e.g., Figure 3 in the paper by Dunn and Smyth).
>
>
>
>> error structure and logit link seems to produce reasonable (and
>> realistic
>> looking) results, and the residual plots look good. However, it warns
>> me that the error structure expects integer data, and I don't know
>> whether this approach is doing what I think (and hope) that it is
>> doing. I have tried to validate the lme4 results in the following ways:
>>
>>
>> 1.  Running the same method (binomial error structure and logit link
>> with the proportions as the response variable) with glmmADMB. This
>> produces very different results (they are completely unrealistic, e.g.
>> predicted proportion of 2.16e-34).
>>
>> 2.  Using beta regression with glmmADMB. This seems to work and
>> produce results that are on the same scale, but not that close to those of lme4.
>>
>> 3.  Running an lme4 model with normal errors (lmer), after
>> logit-transforming the response variable. This again gives quite
>> different results to the lme4 model with binomial error structure and
>> logit link (and the behaviour of the residuals is not ideal).
>>
>> Since these all give different results, it's hard to tell whether the
>> lme4 method I've used is giving the 'right' answer. I would be really
>> grateful for any advice. Is lme4 correctly analysing the proportion
>> data when a binomial error structure and logit link are specified?
>>
>> Additional note: the proportion data are compositional similarity
>> measurements (Jaccard assymetric abundance-based compositional
>> similarity), so technically there is a numerator and denominator
>> (numerator = abundance of species in Site 1 that are also present in
>> Site 2; denominator = abundance of all species in Site 1). I've been
>> exploring different weights options, but they generally include the denominator.
>
> A couple of comments here:
>
> 1. I am not sure those proportion data can always be modelled as binomial.
> Is the numerator a quantity we can think of as arising from a number of independent trials, where the denominator is that number of independent trials?
>
>
> 2. You might consider modeling the numerator using the denominator not as denominator but as a covariate. This has the advantage of allowing you to examine different possible relationships such as
>
> Numerator ~  Denominator + other stuff
>
> but also
>
> Numerator ~ poly(Denominator, 2) + other stuff
>
> or
>
> Numerator ~ bs(Denominator) + other stuff
>
>
> and just generally things like
>
>
> Numerator ~ some_function_of(Denominator, some_other_covariates)
>
> such as
>
> Numerator ~ poly(Denominator, 2) * some_covariate
>
>
> etc.
>
>
> When you do
>
> Numerator/Denominator ~ other stuff
>
> you are committing yourself to one particular form of that relationship (which might not be easy to reason about).
>
>
>
> Best,
>
>
> R.
>
>
>
>>
>> Many thanks in advance,
>>
>> Adriana
>>
>>
>> _____
>>
>> Adriana De Palma
>> PREDICTS Postdoctoral Research Assistant Natural History Museum South
>> Kensington
>>
>> Web: The Purvis
>> Lab<http://www.bio.ic.ac.uk/research/apurvis/ajpurvis.htm> |
>> PREDICTS<predicts.org.uk>
>>
>>
>>       [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> --
> Ramon Diaz-Uriarte
> Department of Biochemistry, Lab B-25
> Facultad de Medicina
> Universidad Aut?noma de Madrid
> Arzobispo Morcillo, 4
> 28029 Madrid
> Spain
>
> Phone: +34-91-497-2412
>
> Email: rdiaz02 at gmail.com
>        ramon.diaz at iib.uam.es
>
> http://ligarto.org/rdiaz
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From vincenzoaellis at gmail.com  Thu Apr  6 21:44:06 2017
From: vincenzoaellis at gmail.com (Vincenzo Ellis)
Date: Thu, 6 Apr 2017 21:44:06 +0200
Subject: [R-sig-ME] prior specification for multinomial model MCMCglmm
Message-ID: <CAGekO=3Lr+cMDkRXUaQ5vCgP2eUu6Dtb-DDX_YMAD=dgxomftA@mail.gmail.com>

Dear list members,

I'm wondering if someone could give me some guidance on how to set up the
priors, specifically regarding random effects, for a multinomial model in
MCMCglmm. The response variable has three levels. The model has an
intercept, but no explanatory variables and it has three nested random
effects. The point of the model is to partition variance in the response
variable among the three random effect terms.

Following the course notes for the package, I think I have the R structure
right for the prior, but I'm finding very little information online to help
with specifying the G structure--both what kind of prior is appropriate in
this case and how to code it. There is at least one worked example (
https://hlplab.wordpress.com/2009/05/07/multinomial-random-effects-models-in-r/)
but it cites a tutorial for most of the explanations that I cannot find.

Any advice would be much appreciated. Data and code (with the prior
specification incomplete) follow.

Thanks!

Vincenzo

## load data
library(gsheet)
dat <- gsheet2tbl('
https://docs.google.com/spreadsheets/d/1qVABAjNSBIlsoG3FYjREejBKyGkJvjaPiIJ_T_bzO_Y/edit?usp=sharing
')

## group taxonomic categories into unique categories for MCMCglmm for use
as nested random effects
dat$Family.Genus <- paste0(dat$Family, dat$Genus)
dat$Family.Genus.Species <- paste0(dat$Family, dat$Genus, dat$Species)

## make variables factors...they come out as characters in the download
dat <- as.data.frame(unclass(dat))

## set up model
library(MCMCglmm)

## k = number of categories in response variable
k <- length(levels(dat$Nest.Type))

## I and J are matrices that will set up constraints on the residuals of
the model
I <- diag(k-1)
J <- matrix(1, k-1, k-1)

## set up prior; how to set up the G structure?
prior1 <- list(R = list(V = (1/k)*(I + J), fix = 1))

## model
mod <- MCMCglmm(Nest.Type ~ trait - 1, rcov = ~us(trait):units,
                random = ~us(trait):Family + us(trait):Family.Genus +
us(trait):Family.Genus.Species,
                prior = prior1, data = dat, family = "categorical")

	[[alternative HTML version deleted]]


From dmichl at uni-potsdam.de  Fri Apr  7 09:59:42 2017
From: dmichl at uni-potsdam.de (Diana Michl)
Date: Fri, 7 Apr 2017 09:59:42 +0200
Subject: [R-sig-ME] lmer-model - model ok? (control condition, random effects,
 log transformation)
In-Reply-To: <5b535c72-767a-0639-70a9-c5610ad39de7@uni-potsdam.de>
References: <5b535c72-767a-0639-70a9-c5610ad39de7@uni-potsdam.de>
Message-ID: <b0007c4e-b689-48fe-85aa-861be47dac77@uni-potsdam.de>

Dear all,

I'd be very thankful for a short feedback on whether my lmer-model is 
good the way it is. Thank you very much in advance!

I'm fitting log-10 reaction times (RT), reading times of sentences (s) 
of participants. The sentences are constructed in pairs: 1 test s. - 1 
control s. (as similar as possible to the test s.). The TEST sentences 
are in 4 conditions, i.e. they belong to one of four KINDS of sentences.

Sentences are matched in length (number of letters) and frequency 
(frequency of words averaged across sentence). Matching across ALL 
material is attempted but not quite possible, so the matching is done as 
well as possible within each test and control sentence pair.


First, I treated the material as 5 conditions: 1 control + 4 test 
conditions -> "cond5" (with contrast.treatment, i.e. control = dummy).
"Cond2| subj" means: random intercepts for test/control condition per 
subject. (Random slopes don't improve fit and aren't that important to me.)

The converging model with the best fit (AIC/BIC) is:

m1 <- lmer(logRT ~ cond5 + rat3 + (cond2|subject) + 
(length:frequency|item_ID), data, REML=F)


But I'm going back and forth on whether "cond5" is actually ok - or 
whether I need to compare the sentences ONLY pairwise, like: each of the 
4 conditions (or "kinds") only in test vs. control.
So I fit another model with a nested fixed effect. "cond4/cond2" means: 
4 conditions ("kinds") within test or control condition (with contr.sum, 
so sum contrasts).

The fit (AIC/BIC) is only a bit worse (910 vs. 905 above):

m2 <- lmer(logRT ~ cond4/cond2 + rat3 + (cond2|subject) + 
(length:frequency|item_ID), data, REML=F)


The results of the two models are the same. The fit is almost the same. 
My question is: Is one model more legitimate than the other, based on 
what I describe about the matching?
And is there something objectionable about how I fit the random effects? 
(My model doesn't necessarily converge when I change them.)

And I'm not 100% sure about whether I have to use logarithmized reaction 
times (=response variable). The raw reaction times have huge variance 
and are right-skewed. The log distribution is more normal, but still not 
a normal distribution. The model fit seems much better for the logRT, 
but the results differ slightly for logRT vs. raw RT.

Again thank you very much and I'd really appreciate your feedback. I 
hope I provided sufficient and non-confusing information.

Best

Diana

-- 
Diana Michl, M.A.
PhD candidate
International Experimental
and Clinical Linguistics
Universit?t Potsdam
www.ling.uni-potsdam.de/staff/dmichl


	[[alternative HTML version deleted]]


From rdiaz02 at gmail.com  Fri Apr  7 10:00:03 2017
From: rdiaz02 at gmail.com (Ramon Diaz-Uriarte)
Date: Fri, 07 Apr 2017 10:00:03 +0200
Subject: [R-sig-ME] Modelling proportion data in lme4
In-Reply-To: <CAGg8SkKpWFKzi9enreTxGypaVR0FpSpUcjrR0e0hXSpT9rOOpw@mail.gmail.com>
References: <DADF81B50E6E3B4FA3919E97D839EEFD66F18D2E@EXC-JONES.nhm.ac.uk>
 <87inmosfoq.fsf@gmail.com>
 <DADF81B50E6E3B4FA3919E97D839EEFD66F1C06B@EXC-JONES.nhm.ac.uk>
 <CAGg8SkKpWFKzi9enreTxGypaVR0FpSpUcjrR0e0hXSpT9rOOpw@mail.gmail.com>
Message-ID: <878tncfy0s.fsf@gmail.com>

Dear Adriana,


On Thu, 06-04-2017, at 16:17:01, guillaume chaumet <guillaumechaumet at gmail.com> wrote:
> You could to try to investigate beta distribution but if you have 0s
> or 1s, STAN implementation do not handle 0 or 1. Perhaps, zero
> inflated or zero-one inflated beta distribution in STAN could provide
> you some help.
> "brms" package https://github.com/paul-buerkner/brms have implemented
> zero-inflated beta distribution and Paul Buerkner have planned to
> implement zero-one inflated beta distribution.
>
> Cheers
>
> Guillaume
>
> 2017-04-06 12:28 GMT+02:00 Adriana De Palma <A.De-Palma at nhm.ac.uk>:
>> Dear Ramon and Thierry,
>>
>> Thank you very much for your suggestions. In answer to your questions:
>>
>>  - I do have 0s in my data.
>>  - I don't think we can consider the denominator independent trails in this case. As it is the total abundance of a set of species, each species is 'block voting'.
>>
>> RE: Ramon's suggestion of a tweedie model for modelling the numerator as
>> the response variable. The proportion data really is the measure that
>> needs to be modelled as this is the compositional similarity
>> calculation, so I'm not sure that a tweedie model will be suitable.


I cannot say if it is reasonable in your case, of course, but in one of the
linked emails below, a Tweedie was recommended for percentage data between
0 and 100% (with the caveat that it would be better if there were few or
no 100% )



Best,


R.


>>
>> RE Thierry's suggestion: Would it still be suitable to use to total abundance of species as the weights in a binomial model, even if the trials aren't strictly independent?
>>
>> Thanks both for all your help! Any further advice would be very gratefully received!
>>
>> Many thanks,
>>
>> Adriana
>>
>>
>>
>>
>> -----Original Message-----
>> From: Ramon Diaz-Uriarte [mailto:rdiaz02 at gmail.com]
>> Sent: 01 April 2017 09:20
>> To: Adriana De Palma
>> Cc: r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] Modelling proportion data in lme4
>>
>> Dear Adriana,
>>
>>
>> On Thu, 30-03-2017, at 09:41, Adriana De Palma <A.De-Palma at nhm.ac.uk> wrote:
>>> Dear all,
>>>
>>> I'd be really grateful if someone could advise on the following issue I've come across.
>>>
>>> I have proportion data (non-integer, bounded between 0 and 1) as my
>>
>> Do you actually have some 0s? Most of the rest of my answer assumes you do.
>>
>>
>>> response variable, in a model that requires nested random effects and
>>> weights, which makes lme4 the ideal choice. Using lme4 with a binomial
>>
>> You might want to take a look at:
>>
>>
>> http://stats.stackexchange.com/questions/81343/response-variable-percentage-and-too-many-zeros-zero-inflated-poisson
>>
>> http://stats.stackexchange.com/questions/142038/two-part-models-in-r-continuous-outcome-with-too-many-zeros
>>
>> http://stats.stackexchange.com/questions/142013/correct-glmer-distribution-family-and-link-for-a-continuous-zero-inflated-data-s/
>>
>> and this R-help question (referred from the above questions, e.g. http://stats.stackexchange.com/a/81347):
>>
>> https://stat.ethz.ch/pipermail/r-help/2005-January/065070.html
>>
>> where using a Tweedie model is suggested.
>>
>>
>> The cplm CRAN package, by W. Zhang:
>> https://cran.r-project.org/web/packages/cplm/index.html
>>
>> will fit mixed-effects Tweedies.
>>
>>
>> I'd suggesting checking the vignetted of the cplm package, as well as Zhang's paper
>>
>> http://link.springer.com/10.1007/s11222-012-9343-7
>>
>>
>> and Dunn and Smyth's 2005 paper, which contains examples that use the Tweedie distribution, as well as several references in the literature where these models have been used:
>>
>> https://link.springer.com/article/10.1007/s11222-005-4070-y
>>
>>
>>
>> Take all of this advice with a grain (or two) of salt, but in somewhat similar cases, and when I had a structure of replicates that allowed me to examine the relationship between mean and variance in the response, I have used it to help me decide whether a Tweedie was, or not, a reasonable choice compared to other options; for instance, with the Tweedie model we'd expect to see a linear slope between log(variance) and log(mean), with the slope, p, being the exponent in the relationship V(mu) = mu^p (see, e.g., Figure 3 in the paper by Dunn and Smyth).
>>
>>
>>
>>> error structure and logit link seems to produce reasonable (and
>>> realistic
>>> looking) results, and the residual plots look good. However, it warns
>>> me that the error structure expects integer data, and I don't know
>>> whether this approach is doing what I think (and hope) that it is
>>> doing. I have tried to validate the lme4 results in the following ways:
>>>
>>>
>>> 1.  Running the same method (binomial error structure and logit link
>>> with the proportions as the response variable) with glmmADMB. This
>>> produces very different results (they are completely unrealistic, e.g.
>>> predicted proportion of 2.16e-34).
>>>
>>> 2.  Using beta regression with glmmADMB. This seems to work and
>>> produce results that are on the same scale, but not that close to those of lme4.
>>>
>>> 3.  Running an lme4 model with normal errors (lmer), after
>>> logit-transforming the response variable. This again gives quite
>>> different results to the lme4 model with binomial error structure and
>>> logit link (and the behaviour of the residuals is not ideal).
>>>
>>> Since these all give different results, it's hard to tell whether the
>>> lme4 method I've used is giving the 'right' answer. I would be really
>>> grateful for any advice. Is lme4 correctly analysing the proportion
>>> data when a binomial error structure and logit link are specified?
>>>
>>> Additional note: the proportion data are compositional similarity
>>> measurements (Jaccard assymetric abundance-based compositional
>>> similarity), so technically there is a numerator and denominator
>>> (numerator = abundance of species in Site 1 that are also present in
>>> Site 2; denominator = abundance of all species in Site 1). I've been
>>> exploring different weights options, but they generally include the denominator.
>>
>> A couple of comments here:
>>
>> 1. I am not sure those proportion data can always be modelled as binomial.
>> Is the numerator a quantity we can think of as arising from a number of independent trials, where the denominator is that number of independent trials?
>>
>>
>> 2. You might consider modeling the numerator using the denominator not as denominator but as a covariate. This has the advantage of allowing you to examine different possible relationships such as
>>
>> Numerator ~  Denominator + other stuff
>>
>> but also
>>
>> Numerator ~ poly(Denominator, 2) + other stuff
>>
>> or
>>
>> Numerator ~ bs(Denominator) + other stuff
>>
>>
>> and just generally things like
>>
>>
>> Numerator ~ some_function_of(Denominator, some_other_covariates)
>>
>> such as
>>
>> Numerator ~ poly(Denominator, 2) * some_covariate
>>
>>
>> etc.
>>
>>
>> When you do
>>
>> Numerator/Denominator ~ other stuff
>>
>> you are committing yourself to one particular form of that relationship (which might not be easy to reason about).
>>
>>
>>
>> Best,
>>
>>
>> R.
>>
>>
>>
>>>
>>> Many thanks in advance,
>>>
>>> Adriana
>>>
>>>
>>> _____
>>>
>>> Adriana De Palma
>>> PREDICTS Postdoctoral Research Assistant Natural History Museum South
>>> Kensington
>>>
>>> Web: The Purvis
>>> Lab<http://www.bio.ic.ac.uk/research/apurvis/ajpurvis.htm> |
>>> PREDICTS<predicts.org.uk>
>>>
>>>
>>>       [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>> --
>> Ramon Diaz-Uriarte
>> Department of Biochemistry, Lab B-25
>> Facultad de Medicina
>> Universidad Aut?noma de Madrid
>> Arzobispo Morcillo, 4
>> 28029 Madrid
>> Spain
>>
>> Phone: +34-91-497-2412
>>
>> Email: rdiaz02 at gmail.com
>>        ramon.diaz at iib.uam.es
>>
>> http://ligarto.org/rdiaz
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


--
Ramon Diaz-Uriarte
Department of Biochemistry, Lab B-25
Facultad de Medicina
Universidad Aut?noma de Madrid
Arzobispo Morcillo, 4
28029 Madrid
Spain

Phone: +34-91-497-2412

Email: rdiaz02 at gmail.com
       ramon.diaz at iib.uam.es

http://ligarto.org/rdiaz


From mrguilfoyle at gmail.com  Fri Apr  7 11:39:05 2017
From: mrguilfoyle at gmail.com (Mathew Guilfoyle)
Date: Fri, 7 Apr 2017 10:39:05 +0100
Subject: [R-sig-ME] mgcv gam/bam model selection with random effects and AR
	terms
Message-ID: <060C6D75-EE3C-49B5-9708-B4768E5DCEC2@gmail.com>

Looking for advice on gam/bam model selection incorporating random effects and autoregressive terms.

I have a multivariate time series recorded on ~500 subjects at ~100 time points.  One of the variables (A) is the dependent and four others (B to E) are predictors.  My basic formula is:

[model 1]: bam(A ~ s(time)+s(B)+s(C)+s(D)+s(E))

I've then included a random intercept and a random effect for time as the pattern of A over time is highly variable across subjects.

[model 2]: bam(A ~ s(time)+s(B)+s(C)+s(D)+s(E)+s(id, bs='re')+s(id,time, bs='re'))

I expect there is also potential for autocorrelation within the time series. So:

[model 3]: bam(A ~ s(time)+s(B)+s(C)+s(D)+s(E)+s(id, bs='re')+s(id,time, bs='re'), AR.start = startindex, rho = 0.52)

The rho value of 0.52 was settled on by trial-and-error minimising fREML/ML (side question: am I correct in understanding that bam can only use a fixed rho rather than taking this as a value to optimise as in gamm?)

The lowest fREML or ML values are obtained by model 3 (71674 vs 72099) for model 2) but the highest adjusted R2/deviance explained is with model 2 (37.7 vs 42.1%).  Model 1 is inferior to both the others on all measures.

Is it better to select the model including the AR term given the lower ML or is it legitimate to go with the 'simpler' model 2 that has higher R2/deviance explained?

I am unable to provide a fully reproducible example as I don't know how to generate sample data with these specific characteristics.

Many thanks

From jmichaelrosenberg at gmail.com  Sat Apr  8 17:27:19 2017
From: jmichaelrosenberg at gmail.com (Joshua Rosenberg)
Date: Sat, 8 Apr 2017 11:27:19 -0400
Subject: [R-sig-ME] Specifying models nested crossed random effects
Message-ID: <CANYHYTTQQOjYc_AvzCyZ8ruLd16Nc5pzHySJe4CpKSF8Ezz1jw@mail.gmail.com>

Hi r-sig-mixed-models,

I am new to the group and have a question about crossed random effects for
student, sample, and program sources of variation.

In my study of out-of-school programs, our outcomes are continuous measures
of participant's interest and engagement (we envision that different
outcomes will be analyzed as part of separate models).

In specific, our data consists of:

   - About 20 individuals per program
   - About 10 programs
   - Within each site, about 20 samples (the samples were at the same time
   for all of the individuals within the program, but at different times at
   different programs)

Because there are dependencies by both participant, sample, and program, we
think there are two crossed random effects, one for observations associated
with each individual, and one for observations associated with each sample.
Both of these random effects are nested in one of the 10 programs.

The data look like the following:

# A tibble: 2,970 ? 4
   overall_engagement participant_ID program_ID      sample_ID
                <dbl>         <fctr>     <fctr>         <fctr>
1            2.833333           1001          1 1-2015-07-14-1
2            2.833333           1001          1 1-2015-07-14-2
3            2.500000           1001          1 1-2015-07-15-1
4            2.333333           1001          1 1-2015-07-15-2
5            3.000000           1001          1 1-2015-07-21-1
6            2.666667           1001          1 1-2015-07-21-2
7            3.000000           1001          1 1-2015-07-21-4
8            3.166667           1001          1 1-2015-07-22-1
9            3.833333           1001          1 1-2015-07-22-4
10           3.000000           1001          1 1-2015-07-28-1
# ... with 2,960 more rows


Our understanding ?from the nested or crossed section of the FAQ and the
answer to this question ?is that because we have unique variables do have
unique values of the sample, there seem to be two options for how we can
specify the model using the lme4 package in R:

?1. ?Not nesting the crossed random effects within the site because the
sample variable includes a site identifier:

lmer(interest ~ 1 + (1|participant_ID) + (1|sample?_ID?), data = df)


2. Creating the sample variable without a site identifier but in a way so
that samples within each site were still identified uniquely and nesting
the crossed random effects within the site:

lmer(interest ~ 1 + (1|site/participant_ID) + (1|site/sample), data = df)


Based on this question
<http://stats.stackexchange.com/questions/96600/interactions-between-random-effects>
(and
some example models where this seemed to work), we were also curious about
adding ?an interaction? ?(to option 1 or option 2) ?between participant_ID
and sample_ID by adding a random effect via (1|participant_ID:sample_ID).

Doe?s ?either ?of these seem like they would? help to? account for
dependencies by participant?, ?sample?, and program??

Please let me know if more information (or less!) would be helpful. Thank
you for considering this.

Josh

-- 
Joshua Rosenberg, Ph.D. Candidate
Educational Psychology and Educational Technology
Michigan State University
http://jmichaelrosenberg.com

	[[alternative HTML version deleted]]


From ecp52 at cornell.edu  Sat Apr  8 21:28:07 2017
From: ecp52 at cornell.edu (Evan Palmer-Young)
Date: Sat, 8 Apr 2017 15:28:07 -0400
Subject: [R-sig-ME] Specifying models nested crossed random effects
In-Reply-To: <CANYHYTTQQOjYc_AvzCyZ8ruLd16Nc5pzHySJe4CpKSF8Ezz1jw@mail.gmail.com>
References: <CANYHYTTQQOjYc_AvzCyZ8ruLd16Nc5pzHySJe4CpKSF8Ezz1jw@mail.gmail.com>
Message-ID: <CAAge6+7EZSrOYtHzzBkceqhtakE6uwk0GJvfwJRb89Dz6Vgxiw@mail.gmail.com>

Josh,
Thanks for the questions.
Can you provide a little bit more description about the variables?
Does "site" = "program"?
Are participants queried at multiple timepoints? If pre- and post-program,
could this be included as a factor with levels "before" and "after"?
Do you have any particular hypotheses or questions you want to answer with
your model?
Best wishes, Evan


On Sat, Apr 8, 2017 at 11:27 AM, Joshua Rosenberg <
jmichaelrosenberg at gmail.com> wrote:

> Hi r-sig-mixed-models,
>
> I am new to the group and have a question about crossed random effects for
> student, sample, and program sources of variation.
>
> In my study of out-of-school programs, our outcomes are continuous measures
> of participant's interest and engagement (we envision that different
> outcomes will be analyzed as part of separate models).
>
> In specific, our data consists of:
>
>    - About 20 individuals per program
>    - About 10 programs
>    - Within each site, about 20 samples (the samples were at the same time
>    for all of the individuals within the program, but at different times at
>    different programs)
>
> Because there are dependencies by both participant, sample, and program, we
> think there are two crossed random effects, one for observations associated
> with each individual, and one for observations associated with each sample.
> Both of these random effects are nested in one of the 10 programs.
>
> The data look like the following:
>
> # A tibble: 2,970 ? 4
>    overall_engagement participant_ID program_ID      sample_ID
>                 <dbl>         <fctr>     <fctr>         <fctr>
> 1            2.833333           1001          1 1-2015-07-14-1
> 2            2.833333           1001          1 1-2015-07-14-2
> 3            2.500000           1001          1 1-2015-07-15-1
> 4            2.333333           1001          1 1-2015-07-15-2
> 5            3.000000           1001          1 1-2015-07-21-1
> 6            2.666667           1001          1 1-2015-07-21-2
> 7            3.000000           1001          1 1-2015-07-21-4
> 8            3.166667           1001          1 1-2015-07-22-1
> 9            3.833333           1001          1 1-2015-07-22-4
> 10           3.000000           1001          1 1-2015-07-28-1
> # ... with 2,960 more rows
>
>
> Our understanding ?from the nested or crossed section of the FAQ and the
> answer to this question ?is that because we have unique variables do have
> unique values of the sample, there seem to be two options for how we can
> specify the model using the lme4 package in R:
>
> ?1. ?Not nesting the crossed random effects within the site because the
> sample variable includes a site identifier:
>
> lmer(interest ~ 1 + (1|participant_ID) + (1|sample?_ID?), data = df)
>
>
> 2. Creating the sample variable without a site identifier but in a way so
> that samples within each site were still identified uniquely and nesting
> the crossed random effects within the site:
>
> lmer(interest ~ 1 + (1|site/participant_ID) + (1|site/sample), data = df)
>
>
> Based on this question
> <http://stats.stackexchange.com/questions/96600/
> interactions-between-random-effects>
> (and
> some example models where this seemed to work), we were also curious about
> adding ?an interaction? ?(to option 1 or option 2) ?between participant_ID
> and sample_ID by adding a random effect via (1|participant_ID:sample_ID).
>
> Doe?s ?either ?of these seem like they would? help to? account for
> dependencies by participant?, ?sample?, and program??
>
> Please let me know if more information (or less!) would be helpful. Thank
> you for considering this.
>
> Josh
>
> --
> Joshua Rosenberg, Ph.D. Candidate
> Educational Psychology and Educational Technology
> Michigan State University
> http://jmichaelrosenberg.com
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models




-- 
Evan Palmer-Young
PhD candidate
Department of Biology
221 Morrill Science Center
611 North Pleasant St
Amherst MA 01003
https://sites.google.com/a/cornell.edu/evan-palmer-young/
epalmery at cns.umass.edu
ecp52 at cornell.edu

	[[alternative HTML version deleted]]


From jmichaelrosenberg at gmail.com  Sat Apr  8 22:26:44 2017
From: jmichaelrosenberg at gmail.com (Joshua Rosenberg)
Date: Sat, 8 Apr 2017 16:26:44 -0400
Subject: [R-sig-ME] Specifying models nested crossed random effects
In-Reply-To: <CAAge6+7EZSrOYtHzzBkceqhtakE6uwk0GJvfwJRb89Dz6Vgxiw@mail.gmail.com>
References: <CANYHYTTQQOjYc_AvzCyZ8ruLd16Nc5pzHySJe4CpKSF8Ezz1jw@mail.gmail.com>
 <CAAge6+7EZSrOYtHzzBkceqhtakE6uwk0GJvfwJRb89Dz6Vgxiw@mail.gmail.com>
Message-ID: <CANYHYTQSMuasED01N7O_zECyLj6WEUXe-0V-YYDLfcr7=Ye28A@mail.gmail.com>

Thank you Evan for your response and thank you for clarifying.

?Responses are in-line below.?


?Thank you for considering this!?

?Josh?


On Sat, Apr 8, 2017 at 3:28 PM, Evan Palmer-Young <ecp52 at cornell.edu> wrote:

> Josh,
> Thanks for the questions.
> Can you provide a little bit more description about the variables?
>

?First, sorry, I had changed some of the variable names in the data and
realize I used different names (and a different outcome) in the examples at
the bottom.

?"interest" (one outcome we're measuring) is a variable of participants'
self-reported interest using a 1-4 scale.

"overall_engagement" is one other (different) outcome: One that was a
composite of variables of students' interest, how hard they were
concentrating,
?and how challenging they reported what they were learning was.

We asked participants (youth) about how interested they were in what they
were learning at random intervals using what is called  an experience
sampling method. In our method, youth had phones on which they were asked
about what they were thinking / feeling - every youth in the same program
(more on the programs in just a moment) was notified to answer our
questions at the same time, although both the instance in time and the
interval between these questions was different between programs.

"site" = "program" (ID) and program is an indicator for membership in one
of the 10 programs.

Because youth were repeatedly sampled, "participant_ID" is an indicator for
one of about 200 participants.

"sample_ID" is an indicator unique for each program (it was made from the
program_ID, the date, and which of one of four samples it was for that
date). There are about 20 unique values for it for each program, from
around 200 values total.


> Does "site" = "program"?
> Are participants queried at multiple timepoints? If pre- and post-program,
> could this be included as a factor with levels "before" and "afte
>

Yes, the sampling consisted of repeated measures within participant (around
15-20 responses per participant). It's a bit tricky for me to describe, but
as I mentioned above every youth in the same program was notified to answer
questions at the same time, though both the instance in time and the
interval between these questions differed between the 10 programs.


> Do you have any particular hypotheses or questions you want to answer with
> your model?
>

?We're interested in, for a lack of a better word, time point or
situation-specific ("sample_ID") variables' relationships with engagement.
We coded video of the programs, including before and when youth were
notified to respond, for example, the type of activity youth were
participating in (i.e., working in groups or individually; doing hands-on
activities or listening to the activity leaders). We imagine considering
these as categorical variables.

Similarly, we're interested in relationships between youth's
characteristics (such as pre-program interest and demographic
characteristics, such as gender) and our outcomes and to a bit of a lesser
extent relationships between some program factors and outcomes (though with
only 10 programs, we do not imagine we will have statistical power to
detect any / many effects at that level).

We're interested in sources of variance as a substantive question (how much
of students' engagement is explained by time-point ("sample_ID"), youth
("participant_ID"), and program ("program_ID") effects?). Though this is a
bit secondary to our questions about the specific variables at time-point,
youth, and program levels.


> Best wishes, Evan
>




-- 
Joshua Rosenberg
jmichaelrosenberg at gmail.com
http://joshuamrosenberg.com

	[[alternative HTML version deleted]]


From ecp52 at cornell.edu  Sun Apr  9 20:56:16 2017
From: ecp52 at cornell.edu (Evan Palmer-Young)
Date: Sun, 9 Apr 2017 14:56:16 -0400
Subject: [R-sig-ME] Specifying models nested crossed random effects
In-Reply-To: <CANYHYTQSMuasED01N7O_zECyLj6WEUXe-0V-YYDLfcr7=Ye28A@mail.gmail.com>
References: <CANYHYTTQQOjYc_AvzCyZ8ruLd16Nc5pzHySJe4CpKSF8Ezz1jw@mail.gmail.com>
 <CAAge6+7EZSrOYtHzzBkceqhtakE6uwk0GJvfwJRb89Dz6Vgxiw@mail.gmail.com>
 <CANYHYTQSMuasED01N7O_zECyLj6WEUXe-0V-YYDLfcr7=Ye28A@mail.gmail.com>
Message-ID: <CAAge6+4E6sEi1YXHSF+7gc-B_7xkVyM8f4T9uThrW6JodVpwfA@mail.gmail.com>

Thanks for those details, Josh. Interesting design!

I'm not experienced in interpreting random effects on their own, so others
will have better advice on that.

For your model structure, it sounds like there are three random effects:

"program_ID"
"participant_ID"
"sample_ID"

From my reading of lme4 documentation, I think that you have coded
sample_ID correctly and do not need to explicitly nest it within program_ID.

In general, think it may be better form to include both fixed and random
predictors in your model, rather than having separate models to assess only
the random effects.

So your model might be something like,

interest_model <- lmer(interest ~ ?Instruction_type? + ?time_of_day?  +
?Working_alone? + (1}program_ID) +  (1|participant_ID) + (1|sample?_ID?),
data = df)

Where Instruction_type, time_of_day , Working_alone, are fabricated
variables that might resemble variables you recorded.

As a disclaimer, this is my second time answering to the list-- welcome!

Best wishes, Evan





On Sat, Apr 8, 2017 at 4:26 PM, Joshua Rosenberg <
jmichaelrosenberg at gmail.com> wrote:

> Thank you Evan for your response and thank you for clarifying.
>
> ?Responses are in-line below.?
>
>
> ?Thank you for considering this!?
>
> ?Josh?
>
>
> On Sat, Apr 8, 2017 at 3:28 PM, Evan Palmer-Young <ecp52 at cornell.edu>
> wrote:
>
>> Josh,
>> Thanks for the questions.
>> Can you provide a little bit more description about the variables?
>>
>
> ?First, sorry, I had changed some of the variable names in the data and
> realize I used different names (and a different outcome) in the examples at
> the bottom.
>
> ?"interest" (one outcome we're measuring) is a variable of participants'
> self-reported interest using a 1-4 scale.
>
> "overall_engagement" is one other (different) outcome: One that was a
> composite of variables of students' interest, how hard they were
> concentrating,
> ?and how challenging they reported what they were learning was.
>
> We asked participants (youth) about how interested they were in what they
> were learning at random intervals using what is called  an experience
> sampling method. In our method, youth had phones on which they were asked
> about what they were thinking / feeling - every youth in the same program
> (more on the programs in just a moment) was notified to answer our
> questions at the same time, although both the instance in time and the
> interval between these questions was different between programs.
>
> "site" = "program" (ID) and program is an indicator for membership in one
> of the 10 programs.
>
> Because youth were repeatedly sampled, "participant_ID" is an indicator
> for one of about 200 participants.
>
> "sample_ID" is an indicator unique for each program (it was made from the
> program_ID, the date, and which of one of four samples it was for that
> date). There are about 20 unique values for it for each program, from
> around 200 values total.
>
>
>> Does "site" = "program"?
>> Are participants queried at multiple timepoints? If pre- and
>> post-program, could this be included as a factor with levels "before" and
>> "afte
>>
>
> Yes, the sampling consisted of repeated measures within participant
> (around 15-20 responses per participant). It's a bit tricky for me to
> describe, but as I mentioned above every youth in the same program was
> notified to answer questions at the same time, though both the instance in
> time and the interval between these questions differed between the 10
> programs.
>
>
>> Do you have any particular hypotheses or questions you want to answer
>> with your model?
>>
>
> ?We're interested in, for a lack of a better word, time point or
> situation-specific ("sample_ID") variables' relationships with engagement.
> We coded video of the programs, including before and when youth were
> notified to respond, for example, the type of activity youth were
> participating in (i.e., working in groups or individually; doing hands-on
> activities or listening to the activity leaders). We imagine considering
> these as categorical variables.
>
> Similarly, we're interested in relationships between youth's
> characteristics (such as pre-program interest and demographic
> characteristics, such as gender) and our outcomes and to a bit of a lesser
> extent relationships between some program factors and outcomes (though with
> only 10 programs, we do not imagine we will have statistical power to
> detect any / many effects at that level).
>
> We're interested in sources of variance as a substantive question (how
> much of students' engagement is explained by time-point ("sample_ID"),
> youth ("participant_ID"), and program ("program_ID") effects?). Though this
> is a bit secondary to our questions about the specific variables at
> time-point, youth, and program levels.
>
>
>> Best wishes, Evan
>>
>
>
>
>
> --
> Joshua Rosenberg
> jmichaelrosenberg at gmail.com
> http://joshuamrosenberg.com
>



-- 
Evan Palmer-Young
PhD candidate
Department of Biology
221 Morrill Science Center
611 North Pleasant St
Amherst MA 01003
https://sites.google.com/a/cornell.edu/evan-palmer-young/
epalmery at cns.umass.edu
ecp52 at cornell.edu

	[[alternative HTML version deleted]]


From dmichl at uni-potsdam.de  Sun Apr  9 22:12:42 2017
From: dmichl at uni-potsdam.de (Diana Michl)
Date: Sun, 9 Apr 2017 22:12:42 +0200
Subject: [R-sig-ME] Specifying models nested crossed random effects
In-Reply-To: <CANYHYTQSMuasED01N7O_zECyLj6WEUXe-0V-YYDLfcr7=Ye28A@mail.gmail.com>
References: <CANYHYTTQQOjYc_AvzCyZ8ruLd16Nc5pzHySJe4CpKSF8Ezz1jw@mail.gmail.com>
 <CAAge6+7EZSrOYtHzzBkceqhtakE6uwk0GJvfwJRb89Dz6Vgxiw@mail.gmail.com>
 <CANYHYTQSMuasED01N7O_zECyLj6WEUXe-0V-YYDLfcr7=Ye28A@mail.gmail.com>
Message-ID: <51c0867f-0cb3-6e9b-1df6-bfe3cbf66f1c@uni-potsdam.de>

Hi Josh,

I see you have a discrete, ordinal outcome variable - a scale of 1-4, so 
4 possible answers that are ordered.
The lmer-function in lme4 actually needs a continuous outcome variable 
(so answers like 1.4, 3.67 should be possible). I recommend the R 
package "ordinal": It's especially designed for your kind of response 
variable. It allows you to fit the model the same way, except it would 
be a logistic regression, but it's not all that different.

(Ok, lme4 might give you the same results still, but it's cleaner this way.)

Diana



Am 08.04.2017 um 22:26 schrieb Joshua Rosenberg:
> Thank you Evan for your response and thank you for clarifying.
>
> ?Responses are in-line below.?
>
>
> ?Thank you for considering this!?
>
> ?Josh?
>
>
> On Sat, Apr 8, 2017 at 3:28 PM, Evan Palmer-Young <ecp52 at cornell.edu> wrote:
>
>> Josh,
>> Thanks for the questions.
>> Can you provide a little bit more description about the variables?
>>
> ?First, sorry, I had changed some of the variable names in the data and
> realize I used different names (and a different outcome) in the examples at
> the bottom.
>
> ?"interest" (one outcome we're measuring) is a variable of participants'
> self-reported interest using a 1-4 scale.
>
> "overall_engagement" is one other (different) outcome: One that was a
> composite of variables of students' interest, how hard they were
> concentrating,
> ?and how challenging they reported what they were learning was.
>
> We asked participants (youth) about how interested they were in what they
> were learning at random intervals using what is called  an experience
> sampling method. In our method, youth had phones on which they were asked
> about what they were thinking / feeling - every youth in the same program
> (more on the programs in just a moment) was notified to answer our
> questions at the same time, although both the instance in time and the
> interval between these questions was different between programs.
>
> "site" = "program" (ID) and program is an indicator for membership in one
> of the 10 programs.
>
> Because youth were repeatedly sampled, "participant_ID" is an indicator for
> one of about 200 participants.
>
> "sample_ID" is an indicator unique for each program (it was made from the
> program_ID, the date, and which of one of four samples it was for that
> date). There are about 20 unique values for it for each program, from
> around 200 values total.
>
>
>> Does "site" = "program"?
>> Are participants queried at multiple timepoints? If pre- and post-program,
>> could this be included as a factor with levels "before" and "afte
>>
> Yes, the sampling consisted of repeated measures within participant (around
> 15-20 responses per participant). It's a bit tricky for me to describe, but
> as I mentioned above every youth in the same program was notified to answer
> questions at the same time, though both the instance in time and the
> interval between these questions differed between the 10 programs.
>
>
>> Do you have any particular hypotheses or questions you want to answer with
>> your model?
>>
> ?We're interested in, for a lack of a better word, time point or
> situation-specific ("sample_ID") variables' relationships with engagement.
> We coded video of the programs, including before and when youth were
> notified to respond, for example, the type of activity youth were
> participating in (i.e., working in groups or individually; doing hands-on
> activities or listening to the activity leaders). We imagine considering
> these as categorical variables.
>
> Similarly, we're interested in relationships between youth's
> characteristics (such as pre-program interest and demographic
> characteristics, such as gender) and our outcomes and to a bit of a lesser
> extent relationships between some program factors and outcomes (though with
> only 10 programs, we do not imagine we will have statistical power to
> detect any / many effects at that level).
>
> We're interested in sources of variance as a substantive question (how much
> of students' engagement is explained by time-point ("sample_ID"), youth
> ("participant_ID"), and program ("program_ID") effects?). Though this is a
> bit secondary to our questions about the specific variables at time-point,
> youth, and program levels.
>
>
>> Best wishes, Evan
>>
>
>
>

-- 
Diana Michl, M.A.
PhD candidate
International Experimental
and Clinical Linguistics
Universit?t Potsdam
www.ling.uni-potsdam.de/staff/dmichl
www.duoinfernale.eu


	[[alternative HTML version deleted]]


From G.K.Hajduk at ed.ac.uk  Mon Apr 10 12:44:43 2017
From: G.K.Hajduk at ed.ac.uk (HAJDUK Gabriela)
Date: Mon, 10 Apr 2017 10:44:43 +0000
Subject: [R-sig-ME] prior specification for multinomial model MCMCglmm
In-Reply-To: <CAGekO=3Lr+cMDkRXUaQ5vCgP2eUu6Dtb-DDX_YMAD=dgxomftA@mail.gmail.com>
References: <CAGekO=3Lr+cMDkRXUaQ5vCgP2eUu6Dtb-DDX_YMAD=dgxomftA@mail.gmail.com>
Message-ID: <6B435C0C-B11E-4B7C-86BC-5225800E286F@sms.ed.ac.uk>

Dear Vincenzo,

My guess is they are referring to the MCMCglmm tutorial from the Ecologist?s guide to the animal model, check whether it fits: http://www.wildanimalmodels.org/tiki-download_wiki_attachment.php?attId=24

Best,
Gabi


On 6 Apr 2017, at 20:44, Vincenzo Ellis <vincenzoaellis at gmail.com<mailto:vincenzoaellis at gmail.com>> wrote:

Dear list members,

I'm wondering if someone could give me some guidance on how to set up the
priors, specifically regarding random effects, for a multinomial model in
MCMCglmm. The response variable has three levels. The model has an
intercept, but no explanatory variables and it has three nested random
effects. The point of the model is to partition variance in the response
variable among the three random effect terms.

Following the course notes for the package, I think I have the R structure
right for the prior, but I'm finding very little information online to help
with specifying the G structure--both what kind of prior is appropriate in
this case and how to code it. There is at least one worked example (
https://hlplab.wordpress.com/2009/05/07/multinomial-random-effects-models-in-r/)
but it cites a tutorial for most of the explanations that I cannot find.

Any advice would be much appreciated. Data and code (with the prior
specification incomplete) follow.

Thanks!

Vincenzo

## load data
library(gsheet)
dat <- gsheet2tbl('
https://docs.google.com/spreadsheets/d/1qVABAjNSBIlsoG3FYjREejBKyGkJvjaPiIJ_T_bzO_Y/edit?usp=sharing
')

## group taxonomic categories into unique categories for MCMCglmm for use
as nested random effects
dat$Family.Genus <- paste0(dat$Family, dat$Genus)
dat$Family.Genus.Species <- paste0(dat$Family, dat$Genus, dat$Species)

## make variables factors...they come out as characters in the download
dat <- as.data.frame(unclass(dat))

## set up model
library(MCMCglmm)

## k = number of categories in response variable
k <- length(levels(dat$Nest.Type))

## I and J are matrices that will set up constraints on the residuals of
the model
I <- diag(k-1)
J <- matrix(1, k-1, k-1)

## set up prior; how to set up the G structure?
prior1 <- list(R = list(V = (1/k)*(I + J), fix = 1))

## model
mod <- MCMCglmm(Nest.Type ~ trait - 1, rcov = ~us(trait):units,
               random = ~us(trait):Family + us(trait):Family.Genus +
us(trait):Family.Genus.Species,
               prior = prior1, data = dat, family = "categorical")

[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20170410/3da5a6bd/attachment.ksh>

From j.hadfield at ed.ac.uk  Tue Apr 11 05:30:49 2017
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 11 Apr 2017 04:30:49 +0100
Subject: [R-sig-ME] prior specification for multinomial model MCMCglmm
In-Reply-To: <CAGekO=3Lr+cMDkRXUaQ5vCgP2eUu6Dtb-DDX_YMAD=dgxomftA@mail.gmail.com>
References: <CAGekO=3Lr+cMDkRXUaQ5vCgP2eUu6Dtb-DDX_YMAD=dgxomftA@mail.gmail.com>
Message-ID: <722678c8-6df2-7387-f001-9981946bc9a6@ed.ac.uk>

Hi Vicenzo,

This is a difficult problem.

First, you should drop the us(trait):Family.Genus.Species term: each 
species is only represented once and so this is confounded with your 
rcov specification.

My feeling is that the priors for the two random effect covariance 
matrices should be of the form V = (1/k)*(I + J) too as this would 
represent equal between-group variance in the three outcomes and also 
independence among the three outcomes (after accounting for the outcomes 
being negatively correlated because if you are a cavity nester you can't 
be an open cup nester). As far as I am aware there is still no treatment 
of parameter expanded priors for covariance matrices, but my guess is 
that they don't work well in this instance because they would shrink the 
covariances to zero rather than 2/k.

However, even with reasonable priors MCMCglmm fails on this data set 
because of numerical under/overflow. The between-Genus and 
between-Family variances are so large you end up with extreme category 
problems that are not well controlled by the variance components. You 
can see this by having pl=TRUE in the call to MCMCglmm and then 
obtaining the probability of the two non-base-line categories for each 
observation. If these probabilities are less than 1e-11 or greater than 
1-1e-11 (this is probably not stringent enough) then numerical problems 
are likely. With nu=1.002, probabilities this extreme occur often:

prob<-exp(mod$Liab[,1:(ncol(mod$Liab)/2)])/(exp(mod$Liab[,1:(ncol(mod$Liab)/2)])+exp(mod$Liab[,ncol(mod$Liab)/2+1:(ncol(mod$Liab)/2)]))

prop.table(table(prob<1e-11 | prob>(1-1e-11)))

In summary, I don't think MCMCglmm is going to give robust answers on 
this data-set. Sorry!

Cheers,

Jarrod








On 06/04/2017 20:44, Vincenzo Ellis wrote:
> library(gsheet)
> dat <- gsheet2tbl('
> https://docs.google.com/spreadsheets/d/1qVABAjNSBIlsoG3FYjREejBKyGkJvjaPiIJ_T_bzO_Y/edit?usp=sharing
> ')
>
> ## group taxonomic categories into unique categories for MCMCglmm for use
> as nested random effects
> dat$Family.Genus <- paste0(dat$Family, dat$Genus)
> dat$Family.Genus.Species <- paste0(dat$Family, dat$Genus, dat$Species)
>
> ## make variables factors...they come out as characters in the download
> dat <- as.data.frame(unclass(dat))
>
> ## set up model
> library(MCMCglmm)
>
> ## k = number of categories in response variable
> k <- length(levels(dat$Nest.Type))
>
> ## I and J are matrices that will set up constraints on the residuals of
> the model
> I <- diag(k-1)
> J <- matrix(1, k-1, k-1)
>
> ## set up prior; how to set up the G structure?
> prior1 <- list(R = list(V = (1/k)*(I + J), fix = 1))
>
> ## model
> mod <- MCMCglmm(Nest.Type ~ trait - 1, rcov = ~us(trait):units,
>                  random = ~us(trait):Family + us(trait):Family.Genus +
> us(trait):Family.Genus.Species,
>                  prior = prior1, data = dat, family = "categorical")


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From Phillip.Alday at unisa.edu.au  Tue Apr 11 07:00:21 2017
From: Phillip.Alday at unisa.edu.au (Phillip Alday)
Date: Tue, 11 Apr 2017 05:00:21 +0000
Subject: [R-sig-ME] lmer-model - model ok? (control condition,
 random effects, log transformation)
In-Reply-To: <b0007c4e-b689-48fe-85aa-861be47dac77@uni-potsdam.de>
References: <5b535c72-767a-0639-70a9-c5610ad39de7@uni-potsdam.de>
 <b0007c4e-b689-48fe-85aa-861be47dac77@uni-potsdam.de>
Message-ID: <AC53184F-80A0-4A2A-B375-DA22D399C02A@unisa.edu.au>

Hi Diana,

I don't think anybody has replied to your message, so here's my go.

The way your conditions are coded seems weird to me. I would have all five conditions (including control) in a single variable/column "cond":

# NB: I use "dat" and not "data", see PS below
dat$cond <- factor(dat$cond, levels=c("control","test1","test2","test3","test4")

If you haven't changed your options, this will be dummy coding with "control" as the baseline/intercept/implicit level.  If you're interested in pairwise contrasts for each test condition compared to the control, this is definitely the way to go.  Based on your description of your experiment, you don't have nested conditions, so don't use the nesting syntax (which expands in a different way than you think anyway and I've never seen used for fixed effects). If you care about other contrasts, you can compute them post hoc with lsmeans or define your own contrast matrix (more advanced, but actually covered in some intro books like Field et al.)

Also, you have a model with the term "rat3" but you don't describe what that represents.

So your basic model would something like:

m <- lmer(logRT ~ cond + (1|subj) + (1|item_ID), dat, REML=F)

Please note that you should not have any random slopes that are not in your fixed effects. There are exceptions to this rule, but yours is not one of them.  In particular, the by-subject slope for condition should be the same condition predictor as in the fixed effects (assuming that all subjects saw all conditions, but even if not, the variance for between-subjects conditions will just drop to zero because there is no within-subject variance for something measured between subjects). This also holds for your length and frequency  nuisance parameters with the extra note that just because something is a nuisance parameter, doesn't mean it's a random effect. Finally, it's pretty weird to have an interaction without a main effect. So taking all that into account, you have a model like this:

m <- lmer(logRT ~ cond * length * frequency + (1+cond|subj) + (1|item_ID), dat, REML=F)


(Because length and frequency are continuous predictors, your coding scheme doesn't have to take interactions in to account, which is the usual motivation for using sum encoding in factorial designs. However, you may want to center or even scale the continuous predictors.)

Since length and frequency differ between items, I would not include them in the by-item RE-structure. The effect of length and especially frequency can differ between subjects (in part because no two people have the same language experience), but adding those to your by-subject RE-structure would make your model much more complex than you need and probably not converge anyway with typical psycholinguistic sample sizes. 

You may run into a problem with the strong correlation between length and frequency (Zipf's law), depending on how carefully you controlled your experiment. Whether you should then drop length or frequency from your model first is a decision you should ideally make based on theoretical grounds.  It's not clear whether this is self-paced reading or eye-tracking, but that could also play a role in your decision.

Finally, in terms of reaction times and the log transform. It's very common to log transform reaction times not just because of the skew but also because of what the log does -- it provides a self-adjusting "zoom" function. For short reaction times, a small difference is a big deal and the log lets that through (e.g. 300 vs 400ms is a big difference). But for long reaction times, a small difference is not a big deal and the log transforms that away, making it so that only big differences come through (e.g. the difference between 2000 and 21000ms is usually not particularly interesting and that difference will be minuscule on the log scale). The assumption of normality is also on the *conditional* distribution (or equivalently, the residuals) and not on the *marginal* (overall) distribution .

Best,
Phillip

PS: Try not to call your data frame "data" as it shadows the builtin "data()" function and this can lead to really weird errors. For example, if you restart your R session and forget to load the data frame before running the lmer() call, then you'll get a weird error message "object of type 'closure' is not subsettable".


> On 7 Apr 2017, at 17:29, Diana Michl <dmichl at uni-potsdam.de> wrote:
> 
> Dear all,
> 
> I'd be very thankful for a short feedback on whether my lmer-model is 
> good the way it is. Thank you very much in advance!
> 
> I'm fitting log-10 reaction times (RT), reading times of sentences (s) 
> of participants. The sentences are constructed in pairs: 1 test s. - 1 
> control s. (as similar as possible to the test s.). The TEST sentences 
> are in 4 conditions, i.e. they belong to one of four KINDS of sentences.
> 
> Sentences are matched in length (number of letters) and frequency 
> (frequency of words averaged across sentence). Matching across ALL 
> material is attempted but not quite possible, so the matching is done as 
> well as possible within each test and control sentence pair.
> 
> 
> First, I treated the material as 5 conditions: 1 control + 4 test 
> conditions -> "cond5" (with contrast.treatment, i.e. control = dummy).
> "Cond2| subj" means: random intercepts for test/control condition per 
> subject. (Random slopes don't improve fit and aren't that important to me.)
> 
> The converging model with the best fit (AIC/BIC) is:
> 
> m1 <- lmer(logRT ~ cond5 + rat3 + (cond2|subject) + 
> (length:frequency|item_ID), data, REML=F)
> 
> 
> But I'm going back and forth on whether "cond5" is actually ok - or 
> whether I need to compare the sentences ONLY pairwise, like: each of the 
> 4 conditions (or "kinds") only in test vs. control.
> So I fit another model with a nested fixed effect. "cond4/cond2" means: 
> 4 conditions ("kinds") within test or control condition (with contr.sum, 
> so sum contrasts).
> 
> The fit (AIC/BIC) is only a bit worse (910 vs. 905 above):
> 
> m2 <- lmer(logRT ~ cond4/cond2 + rat3 + (cond2|subject) + 
> (length:frequency|item_ID), data, REML=F)
> 
> 
> The results of the two models are the same. The fit is almost the same. 
> My question is: Is one model more legitimate than the other, based on 
> what I describe about the matching?
> And is there something objectionable about how I fit the random effects? 
> (My model doesn't necessarily converge when I change them.)
> 
> And I'm not 100% sure about whether I have to use logarithmized reaction 
> times (=response variable). The raw reaction times have huge variance 
> and are right-skewed. The log distribution is more normal, but still not 
> a normal distribution. The model fit seems much better for the logRT, 
> but the results differ slightly for logRT vs. raw RT.
> 
> Again thank you very much and I'd really appreciate your feedback. I 
> hope I provided sufficient and non-confusing information.
> 
> Best
> 
> Diana
> 
> -- 
> Diana Michl, M.A.
> PhD candidate
> International Experimental
> and Clinical Linguistics
> Universit?t Potsdam
> www.ling.uni-potsdam.de/staff/dmichl
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From Phillip.Alday at unisa.edu.au  Tue Apr 11 07:01:21 2017
From: Phillip.Alday at unisa.edu.au (Phillip Alday)
Date: Tue, 11 Apr 2017 05:01:21 +0000
Subject: [R-sig-ME] Specifying models nested crossed random effects
In-Reply-To: <51c0867f-0cb3-6e9b-1df6-bfe3cbf66f1c@uni-potsdam.de>
References: <CANYHYTTQQOjYc_AvzCyZ8ruLd16Nc5pzHySJe4CpKSF8Ezz1jw@mail.gmail.com>
 <CAAge6+7EZSrOYtHzzBkceqhtakE6uwk0GJvfwJRb89Dz6Vgxiw@mail.gmail.com>
 <CANYHYTQSMuasED01N7O_zECyLj6WEUXe-0V-YYDLfcr7=Ye28A@mail.gmail.com>
 <51c0867f-0cb3-6e9b-1df6-bfe3cbf66f1c@uni-potsdam.de>
Message-ID: <79767C0E-815F-4A58-BA9D-5835F33D9517@unisa.edu.au>

There's also brms, which supports ordinal regression with the lme4 syntax in a Bayesian framework.

Phillip


> On 10 Apr 2017, at 05:42, Diana Michl <dmichl at uni-potsdam.de> wrote:
> 
> Hi Josh,
> 
> I see you have a discrete, ordinal outcome variable - a scale of 1-4, so 
> 4 possible answers that are ordered.
> The lmer-function in lme4 actually needs a continuous outcome variable 
> (so answers like 1.4, 3.67 should be possible). I recommend the R 
> package "ordinal": It's especially designed for your kind of response 
> variable. It allows you to fit the model the same way, except it would 
> be a logistic regression, but it's not all that different.
> 
> (Ok, lme4 might give you the same results still, but it's cleaner this way.)
> 
> Diana
> 
> 
> 
> Am 08.04.2017 um 22:26 schrieb Joshua Rosenberg:
>> Thank you Evan for your response and thank you for clarifying.
>> 
>> ?Responses are in-line below.?
>> 
>> 
>> ?Thank you for considering this!?
>> 
>> ?Josh?
>> 
>> 
>> On Sat, Apr 8, 2017 at 3:28 PM, Evan Palmer-Young <ecp52 at cornell.edu> wrote:
>> 
>>> Josh,
>>> Thanks for the questions.
>>> Can you provide a little bit more description about the variables?
>>> 
>> ?First, sorry, I had changed some of the variable names in the data and
>> realize I used different names (and a different outcome) in the examples at
>> the bottom.
>> 
>> ?"interest" (one outcome we're measuring) is a variable of participants'
>> self-reported interest using a 1-4 scale.
>> 
>> "overall_engagement" is one other (different) outcome: One that was a
>> composite of variables of students' interest, how hard they were
>> concentrating,
>> ?and how challenging they reported what they were learning was.
>> 
>> We asked participants (youth) about how interested they were in what they
>> were learning at random intervals using what is called  an experience
>> sampling method. In our method, youth had phones on which they were asked
>> about what they were thinking / feeling - every youth in the same program
>> (more on the programs in just a moment) was notified to answer our
>> questions at the same time, although both the instance in time and the
>> interval between these questions was different between programs.
>> 
>> "site" = "program" (ID) and program is an indicator for membership in one
>> of the 10 programs.
>> 
>> Because youth were repeatedly sampled, "participant_ID" is an indicator for
>> one of about 200 participants.
>> 
>> "sample_ID" is an indicator unique for each program (it was made from the
>> program_ID, the date, and which of one of four samples it was for that
>> date). There are about 20 unique values for it for each program, from
>> around 200 values total.
>> 
>> 
>>> Does "site" = "program"?
>>> Are participants queried at multiple timepoints? If pre- and post-program,
>>> could this be included as a factor with levels "before" and "afte
>>> 
>> Yes, the sampling consisted of repeated measures within participant (around
>> 15-20 responses per participant). It's a bit tricky for me to describe, but
>> as I mentioned above every youth in the same program was notified to answer
>> questions at the same time, though both the instance in time and the
>> interval between these questions differed between the 10 programs.
>> 
>> 
>>> Do you have any particular hypotheses or questions you want to answer with
>>> your model?
>>> 
>> ?We're interested in, for a lack of a better word, time point or
>> situation-specific ("sample_ID") variables' relationships with engagement.
>> We coded video of the programs, including before and when youth were
>> notified to respond, for example, the type of activity youth were
>> participating in (i.e., working in groups or individually; doing hands-on
>> activities or listening to the activity leaders). We imagine considering
>> these as categorical variables.
>> 
>> Similarly, we're interested in relationships between youth's
>> characteristics (such as pre-program interest and demographic
>> characteristics, such as gender) and our outcomes and to a bit of a lesser
>> extent relationships between some program factors and outcomes (though with
>> only 10 programs, we do not imagine we will have statistical power to
>> detect any / many effects at that level).
>> 
>> We're interested in sources of variance as a substantive question (how much
>> of students' engagement is explained by time-point ("sample_ID"), youth
>> ("participant_ID"), and program ("program_ID") effects?). Though this is a
>> bit secondary to our questions about the specific variables at time-point,
>> youth, and program levels.
>> 
>> 
>>> Best wishes, Evan
>>> 
>> 
>> 
>> 
> 
> -- 
> Diana Michl, M.A.
> PhD candidate
> International Experimental
> and Clinical Linguistics
> Universit?t Potsdam
> www.ling.uni-potsdam.de/staff/dmichl
> www.duoinfernale.eu
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From Phillip.Alday at unisa.edu.au  Tue Apr 11 07:42:53 2017
From: Phillip.Alday at unisa.edu.au (Phillip Alday)
Date: Tue, 11 Apr 2017 05:42:53 +0000
Subject: [R-sig-ME] Mixed effects for Discrete Time or Grouped Time
	Survival Analysis
In-Reply-To: <C014DF1C-C95C-4C27-8C75-685DBBF88900@unisa.edu.au>
References: <941324777.1012216.1491363179675.ref@mail.yahoo.com>
 <941324777.1012216.1491363179675@mail.yahoo.com>
 <1581164162.1468924.1491406152805@mail.yahoo.com>
 <1505195584.1499663.1491407097110@mail.yahoo.com>
 <1693960800.1656508.1491418358192@mail.yahoo.com>
 <1980143243.1674737.1491418531992@mail.yahoo.com>
 <1903059040.2893337.1491547478677@mail.yahoo.com>
 <1008719063.4091999.1491712333525@mail.yahoo.com>
 <565380369.4119201.1491725069120@mail.yahoo.com>
 <118862773.346416.1491887798707@mail.yahoo.com>
 <C014DF1C-C95C-4C27-8C75-685DBBF88900@unisa.edu.au>
Message-ID: <76C5D4EE-0E15-4FA3-BD98-A9EE74A3179F@unisa.edu.au>

Dear Shahla,

I'm guessing that you did not receive an answer on r-sig-mixed-models because your message was rejected for containing HTML. The mail server should have notified you of this. Next time, fix that issue so that your message is actually sent out to the list -- I checked the list archives and my own mail archive and your message directly to me is the only one I received. From now on, please keep the list in CC and send plain-text formatted messages without attachments. This will help us help you. :)

I know essentially nothing about survival analysis, but your mixed model structure is fine in and of itself with two small comments:

1. Usually people list all the fixed effects before the random effects, but although lmer's formula parser can handle both.
2. I see that you also asked this question on CrossValidated, where you received several comments asking about autocorrelation and collinearity of your predictors. These are issues that you need to think about.

Regarding your question about heterogeneity: do you mean heterogeneity of the residuals (heteroskedacity)? Or maybe a lack of sphericity? The latter isn't problematic; the former can lead to biased estimates, which may or may not be problematic depending on your particular application.

Good luck.

Best,
Phillip



> On 11 Apr 2017, at 14:46, shahla ebrahimi <shebrahimi_3622 at yahoo.com> wrote:
> 
> Dear Dr. Alday
> 
> 
> Greetings
> 
> I would greatly appreciate if you could let me know how to do discrete time survival analysis or grouped time survival analysis. In fact, I am studying accounting my data set is related to companies' bankruptcy. My covariates are some financial ratios which are computed at the end of each year. Besides, the issue that a company is gone bankrupt or not, is also determined at the end of each year after preparing financial statements.
> 
> Could you please let me know if :
> 1- It is right to do?
> 
> require(lme4)
> model <- glmer(EVENT ~ TIME + (1+TIME|ID)+x1+x2+x3+x4+x5, data=df, family=binomial (link="cloglog"))
> 
> 2- How to do LR test in order to decide about heterogeneity?
> 
> Some part of my data set is as follows (152 firm during a 12 years period or 1554 firm-year observations of which 50 firm-year observations are bankrupt):
>> 
>> ID	TIME	EVENT	x1	x2	x3	x4	x5
>> 1	1	0	1.28	0.02	0.87	1.22	0.06
>> 1	2	0	1.27	0.01	0.82	1.00	-0.01
>> 1	3	0	1.05	-0.06	0.92	0.73	0.02
>> 1	4	0	1.11	-0.02	0.86	0.81	0.08
>> 1	5	1	1.22	-0.06	0.89	0.48	0.01
>> 2	1	0	1.06	0.11	0.81	0.84	0.20
>> 2	2	0	1.06	0.08	0.88	0.69	0.14
>> 2	3	0	0.97	0.08	0.91	0.81	0.17
>> 2	4	0	1.06	0.13	0.82	0.88	0.23
>> 2	5	0	1.12	0.15	0.76	1.08	0.28
>> 2	6	0	1.60	0.26	0.55	1.31	0.37
>> 2	7	0	1.58	0.26	0.56	1.16	0.35
>> 2	8	0	1.54	0.24	0.59	1.08	0.33
>> 2	9	0	1.72	0.22	0.55	0.84	0.29
>> 2	10	0	1.72	0.21	0.53	0.79	0.29
>> 2	11	0	1.63	0.19	0.55	0.73	0.27
>> 2	12	0	2.17	0.32	0.44	0.95	0.43
>> 3	1	0	0.87	-0.03	0.79	0.61	0.00
>> 3	2	1	0.83	-0.14	0.95	0.57	-0.02
>> 
>> I am so sorry but I sent my question to this group: r-sig-mixed-models at r-project.org . However, I have not  received any answer.
>> Thanks in advance.
>> Best regards,


From knoeferle at gmail.com  Wed Apr 12 11:41:00 2017
From: knoeferle at gmail.com (=?UTF-8?Q?Klemens_Kn=C3=B6ferle?=)
Date: Wed, 12 Apr 2017 11:41:00 +0200
Subject: [R-sig-ME] LMER: Visualizing three-way interaction
Message-ID: <CAANFXSJgSG7oUBDhY-+dDuvrFUWfBNm=TP2BZ20QCbYOj5KPLw@mail.gmail.com>

Hi all,

I'm trying to visualize a three-way interaction from a rather complex
linear mixed model in R (lmer function from the lme4 package; the model has
a complex random-effects structure). The interaction consists of two
continuous variables and one categorical variable (two experimental
conditions).

So far, I have graphed the interaction via two 3D-surface plots using
visreg2d from the visreg package. But my reviewers found these plots
confusing and asked for a different illustration, such as conditional
coefficient plots (i.e., plots of the strength of coefficient 1 as
coefficient 2 increases).

I've tried to find a package that allows me to create these kind of plots,
but failed. The existing packages only allow coefficient plots for two-way
interactions (for instance the interplot package;
https://cran.r-project.org/web/packages/interplot/vignettes/interplot-vignette.html).
That means I only get a conditional coefficient plot of the two-way
interaction, collapsed across both levels of the categorical variable.

Is there a package for my case? If not, I probably have to manually extract
fitted values from my model (e.g., using broom) and somehow plot them in
ggplot2. But I don't really know how to do this, whether or not to take
into account random effects (and how), etc. Any ideas would be much
appreciated...

Klemens Kn?ferle, Ph.D.
Associate Professor - Department of Marketing
BI Norwegian Business School
Visiting address: Nydalsveien 37, 0484 Oslo

	[[alternative HTML version deleted]]


From ecp52 at cornell.edu  Wed Apr 12 19:06:12 2017
From: ecp52 at cornell.edu (Evan Palmer-Young)
Date: Wed, 12 Apr 2017 13:06:12 -0400
Subject: [R-sig-ME] LMER: Visualizing three-way interaction
In-Reply-To: <CAANFXSJgSG7oUBDhY-+dDuvrFUWfBNm=TP2BZ20QCbYOj5KPLw@mail.gmail.com>
References: <CAANFXSJgSG7oUBDhY-+dDuvrFUWfBNm=TP2BZ20QCbYOj5KPLw@mail.gmail.com>
Message-ID: <CAAge6+4Uhf2_3CznYFMFm81NHzvVzv=zqkXiR0Gu7ucdjyamTg@mail.gmail.com>

Dear Klemens,
I also have been asked to remove plot3d plots that I thought were
stupendous, but I guess not everybody likes them!
How about two two-way interaction plots for the regressions of continuous
variable 1 vs 2, with separate panels for the levels of the categorical
variable?
You can get fitted model values and CI's with the lsmeans function, using
the "at" argument to specify covariate values.
If the plot is too bland, you can sprinkle the raw data on top as an extra
layer of points.
Best wishes, Evan


On Wed, Apr 12, 2017 at 5:41 AM, Klemens Kn?ferle <knoeferle at gmail.com>
wrote:

> Hi all,
>
> I'm trying to visualize a three-way interaction from a rather complex
> linear mixed model in R (lmer function from the lme4 package; the model has
> a complex random-effects structure). The interaction consists of two
> continuous variables and one categorical variable (two experimental
> conditions).
>
> So far, I have graphed the interaction via two 3D-surface plots using
> visreg2d from the visreg package. But my reviewers found these plots
> confusing and asked for a different illustration, such as conditional
> coefficient plots (i.e., plots of the strength of coefficient 1 as
> coefficient 2 increases).
>
> I've tried to find a package that allows me to create these kind of plots,
> but failed. The existing packages only allow coefficient plots for two-way
> interactions (for instance the interplot package;
> https://cran.r-project.org/web/packages/interplot/
> vignettes/interplot-vignette.html).
> That means I only get a conditional coefficient plot of the two-way
> interaction, collapsed across both levels of the categorical variable.
>
> Is there a package for my case? If not, I probably have to manually extract
> fitted values from my model (e.g., using broom) and somehow plot them in
> ggplot2. But I don't really know how to do this, whether or not to take
> into account random effects (and how), etc. Any ideas would be much
> appreciated...
>
> Klemens Kn?ferle, Ph.D.
> Associate Professor - Department of Marketing
> BI Norwegian Business School
> Visiting address: Nydalsveien 37, 0484 Oslo
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models




-- 
Evan Palmer-Young
PhD candidate
Department of Biology
221 Morrill Science Center
611 North Pleasant St
Amherst MA 01003
https://sites.google.com/a/cornell.edu/evan-palmer-young/
epalmery at cns.umass.edu
ecp52 at cornell.edu

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Wed Apr 12 20:54:05 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 12 Apr 2017 20:54:05 +0200
Subject: [R-sig-ME] LMER: Visualizing three-way interaction
In-Reply-To: <CAAge6+4Uhf2_3CznYFMFm81NHzvVzv=zqkXiR0Gu7ucdjyamTg@mail.gmail.com>
References: <CAANFXSJgSG7oUBDhY-+dDuvrFUWfBNm=TP2BZ20QCbYOj5KPLw@mail.gmail.com>
 <CAAge6+4Uhf2_3CznYFMFm81NHzvVzv=zqkXiR0Gu7ucdjyamTg@mail.gmail.com>
Message-ID: <CAJuCY5y+BaFvfZAPgp0X7kRFVjvu0gnS3At6XsvQJDGTnMaA=g@mail.gmail.com>

Dear Klemens,

Here is my ?0.02

library(ggplot2)
dataset <- expand.grid(
  x = seq(0, 1, length = 41),
  y = seq(0, 1, length = 41),
  z =factor( c("A", "B"))
)
dataset$fit <- with(dataset,
  ifelse(
    z == "A",
     x - 2 * x^2 + 0.5 * x * y + 3 * y - y ^ 2,
    -x - 1 * x^2 - 2 * x * y - 3 * y + y ^ 2
  )
)
ggplot(dataset, aes(x = x, y = y, fill = fit)) +
  geom_raster() +
  facet_wrap(~ z) +
  scale_fill_gradient2()
ggplot(dataset, aes(x = x, y = y, z = fit)) +
  geom_contour(aes(colour = ..level..), binwidth = 0.25) +
  facet_wrap(~ z) +
  scale_colour_gradient2()
ggplot(dataset, aes(x = x, y = y)) +
  geom_raster(aes(fill = fit)) +
  geom_contour(aes(z = fit), binwidth = 0.25) +
  facet_wrap(~ z) +
  scale_fill_gradient(low = "black", high = "white")

Best regards,

Thierry
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey


2017-04-12 19:06 GMT+02:00 Evan Palmer-Young <ecp52 at cornell.edu>:
> Dear Klemens,
> I also have been asked to remove plot3d plots that I thought were
> stupendous, but I guess not everybody likes them!
> How about two two-way interaction plots for the regressions of continuous
> variable 1 vs 2, with separate panels for the levels of the categorical
> variable?
> You can get fitted model values and CI's with the lsmeans function, using
> the "at" argument to specify covariate values.
> If the plot is too bland, you can sprinkle the raw data on top as an extra
> layer of points.
> Best wishes, Evan
>
>
> On Wed, Apr 12, 2017 at 5:41 AM, Klemens Kn?ferle <knoeferle at gmail.com>
> wrote:
>
>> Hi all,
>>
>> I'm trying to visualize a three-way interaction from a rather complex
>> linear mixed model in R (lmer function from the lme4 package; the model has
>> a complex random-effects structure). The interaction consists of two
>> continuous variables and one categorical variable (two experimental
>> conditions).
>>
>> So far, I have graphed the interaction via two 3D-surface plots using
>> visreg2d from the visreg package. But my reviewers found these plots
>> confusing and asked for a different illustration, such as conditional
>> coefficient plots (i.e., plots of the strength of coefficient 1 as
>> coefficient 2 increases).
>>
>> I've tried to find a package that allows me to create these kind of plots,
>> but failed. The existing packages only allow coefficient plots for two-way
>> interactions (for instance the interplot package;
>> https://cran.r-project.org/web/packages/interplot/
>> vignettes/interplot-vignette.html).
>> That means I only get a conditional coefficient plot of the two-way
>> interaction, collapsed across both levels of the categorical variable.
>>
>> Is there a package for my case? If not, I probably have to manually extract
>> fitted values from my model (e.g., using broom) and somehow plot them in
>> ggplot2. But I don't really know how to do this, whether or not to take
>> into account random effects (and how), etc. Any ideas would be much
>> appreciated...
>>
>> Klemens Kn?ferle, Ph.D.
>> Associate Professor - Department of Marketing
>> BI Norwegian Business School
>> Visiting address: Nydalsveien 37, 0484 Oslo
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
>
> --
> Evan Palmer-Young
> PhD candidate
> Department of Biology
> 221 Morrill Science Center
> 611 North Pleasant St
> Amherst MA 01003
> https://sites.google.com/a/cornell.edu/evan-palmer-young/
> epalmery at cns.umass.edu
> ecp52 at cornell.edu
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From ukoether at uke.de  Thu Apr 13 10:39:40 2017
From: ukoether at uke.de (=?UTF-8?Q?Ulf_K=c3=b6ther?=)
Date: Thu, 13 Apr 2017 10:39:40 +0200
Subject: [R-sig-ME] LMER: Visualizing three-way interaction
In-Reply-To: <CAJuCY5y+BaFvfZAPgp0X7kRFVjvu0gnS3At6XsvQJDGTnMaA=g@mail.gmail.com>
References: <CAANFXSJgSG7oUBDhY-+dDuvrFUWfBNm=TP2BZ20QCbYOj5KPLw@mail.gmail.com>
 <CAAge6+4Uhf2_3CznYFMFm81NHzvVzv=zqkXiR0Gu7ucdjyamTg@mail.gmail.com>
 <CAJuCY5y+BaFvfZAPgp0X7kRFVjvu0gnS3At6XsvQJDGTnMaA=g@mail.gmail.com>
Message-ID: <62dc5edc-c7d2-43a5-73fb-17a39028633f@uke.de>

Hello Klemens,

Have a look at the effects package and this document:

https://www.jstatsoft.org/article/view/v008i15/effect-displays-revised.pdf

Using the Owles data (two continuous variables and one categorical, but
fit to a bernoulli response, which doesn't matter for your problem,
because it results also in a continuous variable for the fit), you can
cut your data in sections:

library(effects)

data("Cowles")
cowles.mod <- glm(volunteer ~ sex * neuroticism * extraversion,
                  data=Cowles, family=binomial)

# standard effects plot via lattice:
plot(effect("sex*neuroticism*extraversion", cowles.mod,
            xlevels = list(neuroticism = 0:24,
		           extraversion = seq(0, 24, 6))),
     multiline = TRUE, ylab = "Probability(Volunteer)")

# easily to get a dataframe to do it yourself with ggplot2:
ne.effect <- data.frame(effect("sex*neuroticism*extraversion",
                               cowles.mod, 		
			       xlevels=list(neuroticism = seq(0, 24, 6),
			       extraversion=0:24)))

library(ggplot2)
ne.effect$neuroticismF <- factor(ne.effect$neuroticism,
				labels = paste0("extraversion: ",
				unique(ne.effect$neuroticism)))

ggplot(ne.effect, aes(x = extraversion, y = fit, group = sex)) +
theme_bw() + ylim(0,1) +
    geom_line(aes(linetype = sex), size = 1.2) +
    geom_ribbon(aes(ymin = lower, ymax = upper, linetype = sex),
    color = "black", fill = "grey", alpha = 0.1) +
    facet_wrap(~ neuroticismF)

Extracting data with different levels for continuous variables does also
work with objects from lmer if you want to only concentrate on the fixed
effects estimates. And this attempt at plotting three variables is the
most standard one for the every day reviewer from my opinion...

Good luck!



Am 12.04.2017 um 20:54 schrieb Thierry Onkelinx:
> Dear Klemens,
> 
> Here is my ?0.02
> 
> library(ggplot2)
> dataset <- expand.grid(
>   x = seq(0, 1, length = 41),
>   y = seq(0, 1, length = 41),
>   z =factor( c("A", "B"))
> )
> dataset$fit <- with(dataset,
>   ifelse(
>     z == "A",
>      x - 2 * x^2 + 0.5 * x * y + 3 * y - y ^ 2,
>     -x - 1 * x^2 - 2 * x * y - 3 * y + y ^ 2
>   )
> )
> ggplot(dataset, aes(x = x, y = y, fill = fit)) +
>   geom_raster() +
>   facet_wrap(~ z) +
>   scale_fill_gradient2()
> ggplot(dataset, aes(x = x, y = y, z = fit)) +
>   geom_contour(aes(colour = ..level..), binwidth = 0.25) +
>   facet_wrap(~ z) +
>   scale_colour_gradient2()
> ggplot(dataset, aes(x = x, y = y)) +
>   geom_raster(aes(fill = fit)) +
>   geom_contour(aes(z = fit), binwidth = 0.25) +
>   facet_wrap(~ z) +
>   scale_fill_gradient(low = "black", high = "white")
> 
> Best regards,
> 
> Thierry
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> 
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body
> of data. ~ John Tukey
> 
> 
> 2017-04-12 19:06 GMT+02:00 Evan Palmer-Young <ecp52 at cornell.edu>:
>> Dear Klemens,
>> I also have been asked to remove plot3d plots that I thought were
>> stupendous, but I guess not everybody likes them!
>> How about two two-way interaction plots for the regressions of continuous
>> variable 1 vs 2, with separate panels for the levels of the categorical
>> variable?
>> You can get fitted model values and CI's with the lsmeans function, using
>> the "at" argument to specify covariate values.
>> If the plot is too bland, you can sprinkle the raw data on top as an extra
>> layer of points.
>> Best wishes, Evan
>>
>>
>> On Wed, Apr 12, 2017 at 5:41 AM, Klemens Kn?ferle <knoeferle at gmail.com>
>> wrote:
>>
>>> Hi all,
>>>
>>> I'm trying to visualize a three-way interaction from a rather complex
>>> linear mixed model in R (lmer function from the lme4 package; the model has
>>> a complex random-effects structure). The interaction consists of two
>>> continuous variables and one categorical variable (two experimental
>>> conditions).
>>>
>>> So far, I have graphed the interaction via two 3D-surface plots using
>>> visreg2d from the visreg package. But my reviewers found these plots
>>> confusing and asked for a different illustration, such as conditional
>>> coefficient plots (i.e., plots of the strength of coefficient 1 as
>>> coefficient 2 increases).
>>>
>>> I've tried to find a package that allows me to create these kind of plots,
>>> but failed. The existing packages only allow coefficient plots for two-way
>>> interactions (for instance the interplot package;
>>> https://cran.r-project.org/web/packages/interplot/
>>> vignettes/interplot-vignette.html).
>>> That means I only get a conditional coefficient plot of the two-way
>>> interaction, collapsed across both levels of the categorical variable.
>>>
>>> Is there a package for my case? If not, I probably have to manually extract
>>> fitted values from my model (e.g., using broom) and somehow plot them in
>>> ggplot2. But I don't really know how to do this, whether or not to take
>>> into account random effects (and how), etc. Any ideas would be much
>>> appreciated...
>>>
>>> Klemens Kn?ferle, Ph.D.
>>> Associate Professor - Department of Marketing
>>> BI Norwegian Business School
>>> Visiting address: Nydalsveien 37, 0484 Oslo
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>>
>> --
>> Evan Palmer-Young
>> PhD candidate
>> Department of Biology
>> 221 Morrill Science Center
>> 611 North Pleasant St
>> Amherst MA 01003
>> https://sites.google.com/a/cornell.edu/evan-palmer-young/
>> epalmery at cns.umass.edu
>> ecp52 at cornell.edu
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Rainer Schoppik
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

From T.Houslay at exeter.ac.uk  Thu Apr 13 11:03:13 2017
From: T.Houslay at exeter.ac.uk (Houslay, Tom)
Date: Thu, 13 Apr 2017 09:03:13 +0000
Subject: [R-sig-ME] Visualizing three-way interaction
In-Reply-To: <mailman.307.1492072790.23071.r-sig-mixed-models@r-project.org>
References: <mailman.307.1492072790.23071.r-sig-mixed-models@r-project.org>
Message-ID: <AM5PR03MB30768A58236437D456FE83F6D2020@AM5PR03MB3076.eurprd03.prod.outlook.com>

Hi Klemens,


You probably have all the answers you need now, but just in case they are at all useful then I have a little series of posts on my website about visualising 3-way interactions using various methods:

2 continuous, 1 categorical:
https://tomhouslay.com/2015/06/02/understanding-3-way-interactions-between-continuous-and-categorical-variables-part-ii-2-cats-1-con/

1 continuous, 2 categorical:
https://tomhouslay.com/2014/09/06/understanding-3-way-interactions-between-continuous-and-categorical-variables-small-multiples/

3 continuous:
https://tomhouslay.com/2014/03/21/understanding-3-way-interactions-between-continuous-variables/

Some of these are a little old and don't take advantage of better functions in R (that didn't exist or I was unaware of at the time!), but might be helpful for ideas on different ways of plotting things. These are generally using standard regression models, but predict/broom etc can be used to average over random effects (eg using 're.form = NA' in the predict.merMod function).

Good luck with your plots!

Cheers

Tom

________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of r-sig-mixed-models-request at r-project.org <r-sig-mixed-models-request at r-project.org>
Sent: 13 April 2017 09:39
To: r-sig-mixed-models at r-project.org
Subject: R-sig-mixed-models Digest, Vol 124, Issue 12


Message: 1
Date: Wed, 12 Apr 2017 11:41:00 +0200
From: Klemens Kn?ferle <knoeferle at gmail.com>
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] LMER: Visualizing three-way interaction
Message-ID:
        <CAANFXSJgSG7oUBDhY-+dDuvrFUWfBNm=TP2BZ20QCbYOj5KPLw at mail.gmail.com>
Content-Type: text/plain; charset="UTF-8"

Hi all,

I'm trying to visualize a three-way interaction from a rather complex
linear mixed model in R (lmer function from the lme4 package; the model has
a complex random-effects structure). The interaction consists of two
continuous variables and one categorical variable (two experimental
conditions).

So far, I have graphed the interaction via two 3D-surface plots using
visreg2d from the visreg package. But my reviewers found these plots
confusing and asked for a different illustration, such as conditional
coefficient plots (i.e., plots of the strength of coefficient 1 as
coefficient 2 increases).

I've tried to find a package that allows me to create these kind of plots,
but failed. The existing packages only allow coefficient plots for two-way
interactions (for instance the interplot package;
https://cran.r-project.org/web/packages/interplot/vignettes/interplot-vignette.html).
That means I only get a conditional coefficient plot of the two-way
interaction, collapsed across both levels of the categorical variable.

Is there a package for my case? If not, I probably have to manually extract
fitted values from my model (e.g., using broom) and somehow plot them in
ggplot2. But I don't really know how to do this, whether or not to take
into account random effects (and how), etc. Any ideas would be much
appreciated...

Klemens Kn?ferle, Ph.D.
Associate Professor - Department of Marketing
BI Norwegian Business School
Visiting address: Nydalsveien 37, 0484 Oslo

        [[alternative HTML version deleted]]




	[[alternative HTML version deleted]]


From knoeferle at gmail.com  Thu Apr 13 17:47:00 2017
From: knoeferle at gmail.com (=?UTF-8?Q?Klemens_Kn=C3=B6ferle?=)
Date: Thu, 13 Apr 2017 17:47:00 +0200
Subject: [R-sig-ME] Visualizing three-way interaction
In-Reply-To: <AM5PR03MB30768A58236437D456FE83F6D2020@AM5PR03MB3076.eurprd03.prod.outlook.com>
References: <mailman.307.1492072790.23071.r-sig-mixed-models@r-project.org>
 <AM5PR03MB30768A58236437D456FE83F6D2020@AM5PR03MB3076.eurprd03.prod.outlook.com>
Message-ID: <CAANFXSJ_nw+9fCbLbVMHO8q5VXN9G13n75bj7Vcdrfbr5=dzdw@mail.gmail.com>

Dear all,
thanks for the many helpful suggestions. I decided to go with Ulf's
approach to extract the values from the effects plot; it is very easy and
the results should satisfy these 2-dimensional reviewers (I hope!). Just
wanted to correct a typo in Tom's code:

ne.effect$neuroticismF <- factor(ne.effect$neuroticism,
                                labels = paste0("extraversion: ",
                                unique(ne.effect$neuroticism)))

I guess the pasted label should read "Neuroticism: " (correct me if I'm
wrong). Thanks again for all the help and happy Easter!
Klemens

On 13 April 2017 at 11:03, Houslay, Tom <T.Houslay at exeter.ac.uk> wrote:

> Hi Klemens,
>
>
> You probably have all the answers you need now, but just in case they are
> at all useful then I have a little series of posts on my website about
> visualising 3-way interactions using various methods:
>
> 2 continuous, 1 categorical:
> https://tomhouslay.com/2015/06/02/understanding-3-way-
> interactions-between-continuous-and-categorical-
> variables-part-ii-2-cats-1-con/
>
> 1 continuous, 2 categorical:
> https://tomhouslay.com/2014/09/06/understanding-3-way-
> interactions-between-continuous-and-categorical-variables-small-multiples/
>
> 3 continuous:
> https://tomhouslay.com/2014/03/21/understanding-3-way-
> interactions-between-continuous-variables/
>
> Some of these are a little old and don't take advantage of better
> functions in R (that didn't exist or I was unaware of at the time!), but
> might be helpful for ideas on different ways of plotting things. These are
> generally using standard regression models, but predict/broom etc can be
> used to average over random effects (eg using 're.form = NA' in the
> predict.merMod function).
>
> Good luck with your plots!
>
> Cheers
>
> Tom
>
> ------------------------------
> *From:* R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on
> behalf of r-sig-mixed-models-request at r-project.org <
> r-sig-mixed-models-request at r-project.org>
> *Sent:* 13 April 2017 09:39
> *To:* r-sig-mixed-models at r-project.org
> *Subject:* R-sig-mixed-models Digest, Vol 124, Issue 12
>
>
> Message: 1
> Date: Wed, 12 Apr 2017 11:41:00 +0200
> From: Klemens Kn?ferle <knoeferle at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] LMER: Visualizing three-way interaction
> Message-ID:
>         <CAANFXSJgSG7oUBDhY-+dDuvrFUWfBNm=TP2BZ20QCbYOj5KPL
> w at mail.gmail.com>
> Content-Type: text/plain; charset="UTF-8"
>
> Hi all,
>
> I'm trying to visualize a three-way interaction from a rather complex
> linear mixed model in R (lmer function from the lme4 package; the model has
> a complex random-effects structure). The interaction consists of two
> continuous variables and one categorical variable (two experimental
> conditions).
>
> So far, I have graphed the interaction via two 3D-surface plots using
> visreg2d from the visreg package. But my reviewers found these plots
> confusing and asked for a different illustration, such as conditional
> coefficient plots (i.e., plots of the strength of coefficient 1 as
> coefficient 2 increases).
>
> I've tried to find a package that allows me to create these kind of plots,
> but failed. The existing packages only allow coefficient plots for two-way
> interactions (for instance the interplot package;
> https://cran.r-project.org/web/packages/interplot/
> vignettes/interplot-vignette.html).
> That means I only get a conditional coefficient plot of the two-way
> interaction, collapsed across both levels of the categorical variable.
>
> Is there a package for my case? If not, I probably have to manually extract
> fitted values from my model (e.g., using broom) and somehow plot them in
> ggplot2. But I don't really know how to do this, whether or not to take
> into account random effects (and how), etc. Any ideas would be much
> appreciated...
>
> Klemens Kn?ferle, Ph.D.
> Associate Professor - Department of Marketing
> BI Norwegian Business School
> Visiting address: Nydalsveien 37, 0484 Oslo
>
>         [[alternative HTML version deleted]]
>
>
>
>

	[[alternative HTML version deleted]]


From rdiaz02 at gmail.com  Fri Apr 14 09:28:49 2017
From: rdiaz02 at gmail.com (Ramon Diaz-Uriarte)
Date: Fri, 14 Apr 2017 09:28:49 +0200
Subject: [R-sig-ME] LMER: Visualizing three-way interaction
In-Reply-To: <CAANFXSJgSG7oUBDhY-+dDuvrFUWfBNm=TP2BZ20QCbYOj5KPLw@mail.gmail.com>
References: <CAANFXSJgSG7oUBDhY-+dDuvrFUWfBNm=TP2BZ20QCbYOj5KPLw@mail.gmail.com>
Message-ID: <87pogfxxam.fsf@gmail.com>

Dear Klemens,


You might want to take a look at the effects package, by John Fox and
collaborators. It allows to visualize different types of interactions,
including conditional plots, with a lot of control over what and how, deals
with fits from lmer, and can also plot partial residuals, which I find
extremely useful for diagnostic purposes.


Best,

R.




On Wed, 12-04-2017, at 11:41:00, Klemens Kn?ferle <knoeferle at gmail.com> wrote:
> Hi all,
>
> I'm trying to visualize a three-way interaction from a rather complex
> linear mixed model in R (lmer function from the lme4 package; the model has
> a complex random-effects structure). The interaction consists of two
> continuous variables and one categorical variable (two experimental
> conditions).
>
> So far, I have graphed the interaction via two 3D-surface plots using
> visreg2d from the visreg package. But my reviewers found these plots
> confusing and asked for a different illustration, such as conditional
> coefficient plots (i.e., plots of the strength of coefficient 1 as
> coefficient 2 increases).
>
> I've tried to find a package that allows me to create these kind of plots,
> but failed. The existing packages only allow coefficient plots for two-way
> interactions (for instance the interplot package;
> https://cran.r-project.org/web/packages/interplot/vignettes/interplot-vignette.html).
> That means I only get a conditional coefficient plot of the two-way
> interaction, collapsed across both levels of the categorical variable.
>
> Is there a package for my case? If not, I probably have to manually extract
> fitted values from my model (e.g., using broom) and somehow plot them in
> ggplot2. But I don't really know how to do this, whether or not to take
> into account random effects (and how), etc. Any ideas would be much
> appreciated...
>
> Klemens Kn?ferle, Ph.D.
> Associate Professor - Department of Marketing
> BI Norwegian Business School
> Visiting address: Nydalsveien 37, 0484 Oslo
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Ramon Diaz-Uriarte
Department of Biochemistry, Lab B-25
Facultad de Medicina
Universidad Aut?noma de Madrid 
Arzobispo Morcillo, 4
28029 Madrid
Spain

Phone: +34-91-497-2412

Email: rdiaz02 at gmail.com
       ramon.diaz at iib.uam.es

http://ligarto.org/rdiaz


From michele.scandola at gmail.com  Fri Apr 14 12:05:31 2017
From: michele.scandola at gmail.com (Michele Scandola)
Date: Fri, 14 Apr 2017 12:05:31 +0200
Subject: [R-sig-ME] Fwd: Continuous variable as random slope and the minimum
 number of levels for a categorical variable to be treated as random
In-Reply-To: <CACCLvzqXNb5aokGHpUjbV1p15N3rOrO187gbbiF+RV-TdtKhmQ@mail.gmail.com>
References: <CACCLvzqXNb5aokGHpUjbV1p15N3rOrO187gbbiF+RV-TdtKhmQ@mail.gmail.com>
Message-ID: <CACCLvzr8vTdC7Gdzxa=POTYGLKmmTY7xqevH0_eDzu9LtSm87g@mail.gmail.com>

Dear all,

I've recently read in this page (https://dynamicecology.
wordpress.com/2015/11/04/is-it-a-fixed-or-random-effect/) the following
text "First you CANNOT treat a continuous variable as a random effect. So
if you are putting area or temperature or body size is in they may be a
nuisance/control variable but they are a fixed effect. Of course you are
only estimating one parameter (the slope) so there is no degree of freedom
cost to treating it as random. And it makes no sense to ask what is the
variance across a continuous variable."
Actually I don't know why it doesn't make any sense ask what is the
variance across a continuous variable.
I've seen the classical example on sleepstudy data which treats a cntinuous
variable as random slope:
fm1 <- lmer (Reaction~Days+(Days|Subject), sleepstudy)
with sleepstudy$Days being a continuous variable, and lmer estimates the
variance of the Days slope.

So... is it OK to use a continuous variable as random slope or not?

Furthermore the post says: "[...] you should not treat a categorical
variable with only two levels (e.g. two sites), also known as a binary
variable, as a random effect. You wouldn?t take two measures and then try
to estimate variance, but that is what you?re asking R to do if you treat
it as random. Beyond that there is a lot of debate. But many people think
<http://stats.stackexchange.com/questions/37647/minimum-number-of-levels-for-a-random-effects-factor>
you
should have at least 5 levels (e.g. 5 sites) before you treat something as
random"

Actually I've seen a lot of GLMMs done with random factors with just 2
levels. Is it acceptable or not?

Thanks in advance,

Michele


-- 
Research Associate @ NPSY-Lab.VR - University of Verona
Research Associate @ AgliotiLab - University of Rome "La Sapienza"
Iscrizione all'albo A dell'Ordine degli Psicologi del Veneto n.7733

office tel. 0039 045 802 8401

*http://agliotilab.org/lab-staff/phd-students/3rd-year/michele-scandola#anchor
<http://agliotilab.org/lab-staff/phd-students/3rd-year/michele-scandola#anchor>*
http://profs.formazione.univr.it/npsy-labvr/michele-scandola/
http://scholar.google.it/citations?user=mRc0hxsAAAAJ
http://it.linkedin.com/pub/michele-scandola/24/967/313



*Le informazioni, i dati e le notizie contenute nella presente
comunicazione e i relativi allegati sono di natura privata e come tali
possono essere riservate e sono, comunque, destinate esclusivamente ai
destinatari indicati in epigrafe. La diffusione, distribuzione e/o la
copiatura del documento  trasmesso da parte di qualsiasi soggetto diverso
dal destinatario ? proibita, sia ai sensi dell?art. 616 c.p., sia ai sensi
del D.Lgs. n. 196/2003. Se avete ricevuto questo messaggio per errore, vi
preghiamo di distruggerlo e di darcene immediata comunicazione anche
inviando un messaggio di ritorno all?indirizzo e-mail del mittente.*
*This e-mail (including attachments) is intended only for the recipient(s)
named above. It may contain confidential or privileged information and
should not be read, copied or otherwise used by any other person. If you
are not the named recipient, please contact npsylab.vr at gmail.com
<npsylab.vr at gmail.com> and delete the e-mail from your system. Rif. D.L.
196/2003.*

	[[alternative HTML version deleted]]


From conor.goold at nmbu.no  Fri Apr 14 12:50:00 2017
From: conor.goold at nmbu.no (Conor Michael Goold)
Date: Fri, 14 Apr 2017 10:50:00 +0000
Subject: [R-sig-ME] Fwd: Continuous variable as random slope and the
 minimum number of levels for a categorical variable to be treated as random
In-Reply-To: <CACCLvzr8vTdC7Gdzxa=POTYGLKmmTY7xqevH0_eDzu9LtSm87g@mail.gmail.com>
References: <CACCLvzqXNb5aokGHpUjbV1p15N3rOrO187gbbiF+RV-TdtKhmQ@mail.gmail.com>,
 <CACCLvzr8vTdC7Gdzxa=POTYGLKmmTY7xqevH0_eDzu9LtSm87g@mail.gmail.com>
Message-ID: <1492167000371.76148@nmbu.no>

Hi, 

The post you link to is to treating "random effect" solely as the blocking factor or hierarchical grouping factor in the model, when one wants to estimate different intercept parameters for each of the grouping factors. For instance, when observations are nested within individuals as in the sleep study, then individuals are the grouping factor or the "random effect" and will have their own intercept. Actually, in one of the comments (second one), the author admits he doesn't include the topic of random slopes for brevity. But even with random slope terms, the slope is varying with respect to the same blocking factor as the intercept. 

However, continuous variables that respect order (e.g. different ages) can also be treated as random effects or grouping variables through Gaussian process models. 

When you say you have seen GLMMs with only 2 levels, do you mean random slopes or random intercepts? I'm guessing the former based on your first question. 

The minimum size for a discrete grouping factor is dependent on the exact context (e.g. how many parameters are being estimated), but many recommend 5 as a minimum (although, this would only stand for the simplest of models) and more is always better. For instance, Stegmueller 2013 (http://onlinelibrary.wiley.com/doi/10.1111/ajps.12001/abstract) says that having at least 15-20 levels of the grouping factor in ML estimation is best, whereas Bayesian methods are more robust at lower number of levels per grouping factor. 

Also, as another commenter discussed, the random/fixed effect terms can be confusing and perhaps a better way to think about these sorts of models is simply whether parameters vary by some grouping factor or not. Thus, you could have intercepts or slopes varying with respect to a grouping factor. I prefer to write "Intercepts and the slope of predictor X varied by each individual" rather than "Random intercepts and slopes were included" because I think it's ultimately clearer about what is being done and what readers can expect from the analysis.

Best regards
Conor Goold
PhD Student
Phone:        +47 67 23 27 24



Norwegian University of Life Sciences
Campus ?s. www.nmbu.no

________________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Michele Scandola <michele.scandola at gmail.com>
Sent: Friday, April 14, 2017 12:05 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Fwd: Continuous variable as random slope and the minimum number of levels for a categorical variable to be treated as random

Dear all,

I've recently read in this page (https://dynamicecology.
wordpress.com/2015/11/04/is-it-a-fixed-or-random-effect/) the following
text "First you CANNOT treat a continuous variable as a random effect. So
if you are putting area or temperature or body size is in they may be a
nuisance/control variable but they are a fixed effect. Of course you are
only estimating one parameter (the slope) so there is no degree of freedom
cost to treating it as random. And it makes no sense to ask what is the
variance across a continuous variable."
Actually I don't know why it doesn't make any sense ask what is the
variance across a continuous variable.
I've seen the classical example on sleepstudy data which treats a cntinuous
variable as random slope:
fm1 <- lmer (Reaction~Days+(Days|Subject), sleepstudy)
with sleepstudy$Days being a continuous variable, and lmer estimates the
variance of the Days slope.

So... is it OK to use a continuous variable as random slope or not?

Furthermore the post says: "[...] you should not treat a categorical
variable with only two levels (e.g. two sites), also known as a binary
variable, as a random effect. You wouldn?t take two measures and then try
to estimate variance, but that is what you?re asking R to do if you treat
it as random. Beyond that there is a lot of debate. But many people think
<http://stats.stackexchange.com/questions/37647/minimum-number-of-levels-for-a-random-effects-factor>
you
should have at least 5 levels (e.g. 5 sites) before you treat something as
random"

Actually I've seen a lot of GLMMs done with random factors with just 2
levels. Is it acceptable or not?

Thanks in advance,

Michele


--
Research Associate @ NPSY-Lab.VR - University of Verona
Research Associate @ AgliotiLab - University of Rome "La Sapienza"
Iscrizione all'albo A dell'Ordine degli Psicologi del Veneto n.7733

office tel. 0039 045 802 8401

*http://agliotilab.org/lab-staff/phd-students/3rd-year/michele-scandola#anchor
<http://agliotilab.org/lab-staff/phd-students/3rd-year/michele-scandola#anchor>*
http://profs.formazione.univr.it/npsy-labvr/michele-scandola/
http://scholar.google.it/citations?user=mRc0hxsAAAAJ
http://it.linkedin.com/pub/michele-scandola/24/967/313



*Le informazioni, i dati e le notizie contenute nella presente
comunicazione e i relativi allegati sono di natura privata e come tali
possono essere riservate e sono, comunque, destinate esclusivamente ai
destinatari indicati in epigrafe. La diffusione, distribuzione e/o la
copiatura del documento  trasmesso da parte di qualsiasi soggetto diverso
dal destinatario ? proibita, sia ai sensi dell?art. 616 c.p., sia ai sensi
del D.Lgs. n. 196/2003. Se avete ricevuto questo messaggio per errore, vi
preghiamo di distruggerlo e di darcene immediata comunicazione anche
inviando un messaggio di ritorno all?indirizzo e-mail del mittente.*
*This e-mail (including attachments) is intended only for the recipient(s)
named above. It may contain confidential or privileged information and
should not be read, copied or otherwise used by any other person. If you
are not the named recipient, please contact npsylab.vr at gmail.com
<npsylab.vr at gmail.com> and delete the e-mail from your system. Rif. D.L.
196/2003.*

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From mohammadreza366 at yahoo.com  Fri Apr 14 09:40:28 2017
From: mohammadreza366 at yahoo.com (Mohammadreza Kordbagheri)
Date: Fri, 14 Apr 2017 07:40:28 +0000 (UTC)
Subject: [R-sig-ME] mixture DIC model
References: <372653862.178581.1492155628110.ref@mail.yahoo.com>
Message-ID: <372653862.178581.1492155628110@mail.yahoo.com>

hello 
my name is alireza kordbagheri of shahid beheshti university tehran.

i have two question of you:

can you help me for my question:
one question: i read your article tittle:

i dont know, how draw heatmap ANOVA GAMMA.

two question:i writing code model with JAGS softwar.
i used of function GB2.

I have problem, what DIC estimation?
This article is open access at

https://projecteuclid.org/euclid.ba/1340370933.

library(rjags)

cat(file = "model.txt",
"
data {
  C <- 100
  for (i in 1:N) {
    zeros[i] <- 0
  }
}
model {
  for (i in 1:N) {
    zeros[i] ~ dpois(loglik[i] + C)
    loglik[i] <- -log(pi[1] * l1[i] + pi[2] * l2[i])
    l1[i] <- abs(a[1]) * pow(y[i], a[1] * p[1] - 1) / (pow(b1[i], a[1] * p[1]) * exp(loggam(p[1]) + loggam(q[1]) - loggam(p[1] + q[1])) * pow(1 + pow(y[i] / b1[i], a[1]), p[1] + q[1]))
    l2[i] <- abs(a[2]) * pow(y[i], a[2] * p[2] - 1) / (pow(b2[i], a[2] * p[2]) * exp(loggam(p[2]) + loggam(q[2]) - loggam(p[2] + q[2])) * pow(1 + pow(y[i] / b2[i], a[2]), p[2] + q[2]))
    b1[i]<- exp(mu[1] + alpha[1] * f[i] + beta1[1] * col1[i] + beta2[1] * col2[i] + beta3[1] * col3[i] + loggam(p[1]) + loggam(q[1]) - loggam(p[1] + 1 / a[1]) - loggam(q[1] - 1 / a[1]))
    b2[i]<- exp(mu[2] + alpha[2] * f[i] + beta1[2] * col1[i] + beta2[2] * col2[i] + beta3[2] * col3[i] + loggam(p[2]) + loggam(q[2]) - loggam(p[2] + 1 / a[2]) - loggam(q[2] - 1 / a[2]))
  }
  pi[1] ~ dunif(0, 1)
  pi[2] <- 1 - pi[1]
  for(k in 1:2) {
    mu[k] ~ dnorm(0, .01)
    alpha[k] ~ dnorm(0, .01)
    beta1[k] ~ dnorm(0, .01)
    beta2[k] ~ dnorm(0, .01)
    beta3[k] ~ dnorm(0, .01)
    a[k] ~ dnorm(0, .01)
    p[k] ~ dgamma(.01, .01)I(0, 90)
    q[k] ~ dgamma(.01, .001)I(1, 3.5)
  }
}
")

data <- matrix(c(
3323,  5, 1, 0, 0,
8332,  8, 0, 1, 1,
9572,  5, 1, 0, 0,
10172, 10, 1, 0, 1,
7631,  2, 1, 0, 0,
3855,  9, 0, 1, 1,
3252,  6, 1, 0, 1,
4433,  8, 0, 1, 1,
2188,  7, 1, 0, 0,
  333,  4, 1, 0, 0,
  199,  3, 0, 1, 1,
  692,  9, 0, 1, 0,
  311, 12, 1, 0, 0,
0.01,  5, 1, 0, 1,
  405,  6, 0, 1, 0,
  293,  6, 0, 1, 0,
  76,  7, 1, 0, 1,
  14,  9, 1, 0, 0,
3785, 21, 0, 1, 1,
10342, 11, 0, 1, 1), ncol = 5, byrow = TRUE)

bugs.data <- list(N = nrow(data),
                  y = data[, 1],
                  f = data[, 2],
                  col1 = data[, 3],
                  col2 = data[, 4],
                  col3 = data[, 5])
set.seed(123)
inits <- lapply(1:3, function(i) {
    list(mu = rnorm(2, 0, 1),
        alpha = rnorm(2, 0, 1),
        beta1 = rnorm(2, 0, 1),
        beta2 = rnorm(2, 0, 1),
        beta3 = rnorm(2, 0, 1),
        pi = c(runif(1, 0, 1), NA),
        a = runif(2, -4, -2),
        p = runif(2, 1, 2),
        q = runif(2, 1, 2),
        .RNG.name = "base::Mersenne-Twister",
        .RNG.seed = i)
    })
pars <- c("mu", "alpha", "beta1", "beta2", "beta3", "pi",
          "a", "p", "q")
model <- jags.model("model.txt",
                    data = bugs.data,
                    inits = inits,
                    n.chains = 3,
                    n.adapt = 1000)
update(model, 3000)
samp <- coda.samples(model,
                    variable.names = pars,
                    n.iter = 4000, thin = 4)
gelman.diag(samp, multivariate = FALSE)
traceplot(samp[, 15]) # pi[1]
traceplot(samp[, 16]) # pi[2]

can you help me.

Regards,
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: data.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20170414/b20eceb4/attachment-0001.txt>

From michele.scandola at gmail.com  Fri Apr 14 19:33:31 2017
From: michele.scandola at gmail.com (Michele Scandola)
Date: Fri, 14 Apr 2017 19:33:31 +0200
Subject: [R-sig-ME] Fwd: Continuous variable as random slope and the
 minimum number of levels for a categorical variable to be treated as random
In-Reply-To: <1492167000371.76148@nmbu.no>
References: <CACCLvzqXNb5aokGHpUjbV1p15N3rOrO187gbbiF+RV-TdtKhmQ@mail.gmail.com>
 <CACCLvzr8vTdC7Gdzxa=POTYGLKmmTY7xqevH0_eDzu9LtSm87g@mail.gmail.com>
 <1492167000371.76148@nmbu.no>
Message-ID: <CACCLvzq3QaRNPq7SNRGp=xZgLjognBbcqURuByTm4kL8=t3Gtw@mail.gmail.com>

Dear Conor,

Thanks a lot for your answers. I don't know why but I have misunderstood
the article, I've thought it was talking about random slopes. Now it makes
sense.
However I didn't know that even continuous, ordered variables can be used
as grouping factors. Do you have any reference about that? The link I've
shared clearly states it is not possible.
However, in your example you have spoken about age. May be a good idea to
use it as a nested grouping factor in the participant grouping factor? I
mean something like (1|subject:age).

Best regards,

Michele


Il 14 Apr 2017 12:50 PM, "Conor Michael Goold" <conor.goold at nmbu.no> ha
scritto:

Hi,

The post you link to is to treating "random effect" solely as the blocking
factor or hierarchical grouping factor in the model, when one wants to
estimate different intercept parameters for each of the grouping factors.
For instance, when observations are nested within individuals as in the
sleep study, then individuals are the grouping factor or the "random
effect" and will have their own intercept. Actually, in one of the comments
(second one), the author admits he doesn't include the topic of random
slopes for brevity. But even with random slope terms, the slope is varying
with respect to the same blocking factor as the intercept.

However, continuous variables that respect order (e.g. different ages) can
also be treated as random effects or grouping variables through Gaussian
process models.

When you say you have seen GLMMs with only 2 levels, do you mean random
slopes or random intercepts? I'm guessing the former based on your first
question.

The minimum size for a discrete grouping factor is dependent on the exact
context (e.g. how many parameters are being estimated), but many recommend
5 as a minimum (although, this would only stand for the simplest of models)
and more is always better. For instance, Stegmueller 2013 (
http://onlinelibrary.wiley.com/doi/10.1111/ajps.12001/abstract) says that
having at least 15-20 levels of the grouping factor in ML estimation is
best, whereas Bayesian methods are more robust at lower number of levels
per grouping factor.

Also, as another commenter discussed, the random/fixed effect terms can be
confusing and perhaps a better way to think about these sorts of models is
simply whether parameters vary by some grouping factor or not. Thus, you
could have intercepts or slopes varying with respect to a grouping factor.
I prefer to write "Intercepts and the slope of predictor X varied by each
individual" rather than "Random intercepts and slopes were included"
because I think it's ultimately clearer about what is being done and what
readers can expect from the analysis.

Best regards
Conor Goold
PhD Student
Phone:        +47 67 23 27 24



Norwegian University of Life Sciences
Campus ?s. www.nmbu.no

________________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on
behalf of Michele Scandola <michele.scandola at gmail.com>
Sent: Friday, April 14, 2017 12:05 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Fwd: Continuous variable as random slope and the
minimum number of levels for a categorical variable to be treated as random

Dear all,

I've recently read in this page (https://dynamicecology.
wordpress.com/2015/11/04/is-it-a-fixed-or-random-effect/) the following
text "First you CANNOT treat a continuous variable as a random effect. So
if you are putting area or temperature or body size is in they may be a
nuisance/control variable but they are a fixed effect. Of course you are
only estimating one parameter (the slope) so there is no degree of freedom
cost to treating it as random. And it makes no sense to ask what is the
variance across a continuous variable."
Actually I don't know why it doesn't make any sense ask what is the
variance across a continuous variable.
I've seen the classical example on sleepstudy data which treats a cntinuous
variable as random slope:
fm1 <- lmer (Reaction~Days+(Days|Subject), sleepstudy)
with sleepstudy$Days being a continuous variable, and lmer estimates the
variance of the Days slope.

So... is it OK to use a continuous variable as random slope or not?

Furthermore the post says: "[...] you should not treat a categorical
variable with only two levels (e.g. two sites), also known as a binary
variable, as a random effect. You wouldn?t take two measures and then try
to estimate variance, but that is what you?re asking R to do if you treat
it as random. Beyond that there is a lot of debate. But many people think
<http://stats.stackexchange.com/questions/37647/minimum-
number-of-levels-for-a-random-effects-factor>
you
should have at least 5 levels (e.g. 5 sites) before you treat something as
random"

Actually I've seen a lot of GLMMs done with random factors with just 2
levels. Is it acceptable or not?

Thanks in advance,

Michele


--
Research Associate @ NPSY-Lab.VR - University of Verona
Research Associate @ AgliotiLab - University of Rome "La Sapienza"
Iscrizione all'albo A dell'Ordine degli Psicologi del Veneto n.7733

office tel. 0039 045 802 8401

*http://agliotilab.org/lab-staff/phd-students/3rd-year/
michele-scandola#anchor
<http://agliotilab.org/lab-staff/phd-students/3rd-year/
michele-scandola#anchor>*
http://profs.formazione.univr.it/npsy-labvr/michele-scandola/
http://scholar.google.it/citations?user=mRc0hxsAAAAJ
http://it.linkedin.com/pub/michele-scandola/24/967/313



*Le informazioni, i dati e le notizie contenute nella presente
comunicazione e i relativi allegati sono di natura privata e come tali
possono essere riservate e sono, comunque, destinate esclusivamente ai
destinatari indicati in epigrafe. La diffusione, distribuzione e/o la
copiatura del documento  trasmesso da parte di qualsiasi soggetto diverso
dal destinatario ? proibita, sia ai sensi dell?art. 616 c.p., sia ai sensi
del D.Lgs. n. 196/2003. Se avete ricevuto questo messaggio per errore, vi
preghiamo di distruggerlo e di darcene immediata comunicazione anche
inviando un messaggio di ritorno all?indirizzo e-mail del mittente.*
*This e-mail (including attachments) is intended only for the recipient(s)
named above. It may contain confidential or privileged information and
should not be read, copied or otherwise used by any other person. If you
are not the named recipient, please contact npsylab.vr at gmail.com
<npsylab.vr at gmail.com> and delete the e-mail from your system. Rif. D.L.
196/2003.*

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From conor.goold at nmbu.no  Fri Apr 14 21:37:06 2017
From: conor.goold at nmbu.no (Conor Michael Goold)
Date: Fri, 14 Apr 2017 19:37:06 +0000
Subject: [R-sig-ME] Fwd: Continuous variable as random slope and the
 minimum number of levels for a categorical variable to be treated as random
In-Reply-To: <CACCLvzq3QaRNPq7SNRGp=xZgLjognBbcqURuByTm4kL8=t3Gtw@mail.gmail.com>
References: <CACCLvzqXNb5aokGHpUjbV1p15N3rOrO187gbbiF+RV-TdtKhmQ@mail.gmail.com>
 <CACCLvzr8vTdC7Gdzxa=POTYGLKmmTY7xqevH0_eDzu9LtSm87g@mail.gmail.com>
 <1492167000371.76148@nmbu.no>,
 <CACCLvzq3QaRNPq7SNRGp=xZgLjognBbcqURuByTm4kL8=t3Gtw@mail.gmail.com>
Message-ID: <1492198626465.38431@nmbu.no>

Dear Michele,


I don't have a good reference to hand, but have a look at Gaussian process models and there will be lots of information. The grouping factor could still be discrete, but Gaussian processes allow the modelling of the covariances between "random effects". For instance, the modelling of spatial autocorrelation within hierarchical levels.


Actually, Richard McElreath has an example of the above in his book Statistical Rethinking, where he models the number of tools in different cultures using a Poisson regression, and using a Gaussian process to represent the correlations among the different cultures (since the number of tools by cultures are spatially correlated).?


Best

Conor


________________________________
From: drs.strange at gmail.com <drs.strange at gmail.com> on behalf of Michele Scandola <michele.scandola at gmail.com>
Sent: Friday, April 14, 2017 7:33 PM
To: Conor Michael Goold
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Fwd: Continuous variable as random slope and the minimum number of levels for a categorical variable to be treated as random

Dear Conor,

Thanks a lot for your answers. I don't know why but I have misunderstood the article, I've thought it was talking about random slopes. Now it makes sense.
However I didn't know that even continuous, ordered variables can be used as grouping factors. Do you have any reference about that? The link I've shared clearly states it is not possible.
However, in your example you have spoken about age. May be a good idea to use it as a nested grouping factor in the participant grouping factor? I mean something like (1|subject:age).

Best regards,

Michele


Il 14 Apr 2017 12:50 PM, "Conor Michael Goold" <conor.goold at nmbu.no<mailto:conor.goold at nmbu.no>> ha scritto:
Hi,

The post you link to is to treating "random effect" solely as the blocking factor or hierarchical grouping factor in the model, when one wants to estimate different intercept parameters for each of the grouping factors. For instance, when observations are nested within individuals as in the sleep study, then individuals are the grouping factor or the "random effect" and will have their own intercept. Actually, in one of the comments (second one), the author admits he doesn't include the topic of random slopes for brevity. But even with random slope terms, the slope is varying with respect to the same blocking factor as the intercept.

However, continuous variables that respect order (e.g. different ages) can also be treated as random effects or grouping variables through Gaussian process models.

When you say you have seen GLMMs with only 2 levels, do you mean random slopes or random intercepts? I'm guessing the former based on your first question.

The minimum size for a discrete grouping factor is dependent on the exact context (e.g. how many parameters are being estimated), but many recommend 5 as a minimum (although, this would only stand for the simplest of models) and more is always better. For instance, Stegmueller 2013 (http://onlinelibrary.wiley.com/doi/10.1111/ajps.12001/abstract) says that having at least 15-20 levels of the grouping factor in ML estimation is best, whereas Bayesian methods are more robust at lower number of levels per grouping factor.

Also, as another commenter discussed, the random/fixed effect terms can be confusing and perhaps a better way to think about these sorts of models is simply whether parameters vary by some grouping factor or not. Thus, you could have intercepts or slopes varying with respect to a grouping factor. I prefer to write "Intercepts and the slope of predictor X varied by each individual" rather than "Random intercepts and slopes were included" because I think it's ultimately clearer about what is being done and what readers can expect from the analysis.

Best regards
Conor Goold
PhD Student
Phone:        +47 67 23 27 24<tel:%2B47%2067%2023%2027%2024>



Norwegian University of Life Sciences
Campus ?s. www.nmbu.no<http://www.nmbu.no>

________________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org>> on behalf of Michele Scandola <michele.scandola at gmail.com<mailto:michele.scandola at gmail.com>>
Sent: Friday, April 14, 2017 12:05 PM
To: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] Fwd: Continuous variable as random slope and the minimum number of levels for a categorical variable to be treated as random

Dear all,

I've recently read in this page (https://dynamicecology.
wordpress.com/2015/11/04/is-it-a-fixed-or-random-effect/<http://wordpress.com/2015/11/04/is-it-a-fixed-or-random-effect/>) the following
text "First you CANNOT treat a continuous variable as a random effect. So
if you are putting area or temperature or body size is in they may be a
nuisance/control variable but they are a fixed effect. Of course you are
only estimating one parameter (the slope) so there is no degree of freedom
cost to treating it as random. And it makes no sense to ask what is the
variance across a continuous variable."
Actually I don't know why it doesn't make any sense ask what is the
variance across a continuous variable.
I've seen the classical example on sleepstudy data which treats a cntinuous
variable as random slope:
fm1 <- lmer (Reaction~Days+(Days|Subject), sleepstudy)
with sleepstudy$Days being a continuous variable, and lmer estimates the
variance of the Days slope.

So... is it OK to use a continuous variable as random slope or not?

Furthermore the post says: "[...] you should not treat a categorical
variable with only two levels (e.g. two sites), also known as a binary
variable, as a random effect. You wouldn?t take two measures and then try
to estimate variance, but that is what you?re asking R to do if you treat
it as random. Beyond that there is a lot of debate. But many people think
<http://stats.stackexchange.com/questions/37647/minimum-number-of-levels-for-a-random-effects-factor>
you
should have at least 5 levels (e.g. 5 sites) before you treat something as
random"

Actually I've seen a lot of GLMMs done with random factors with just 2
levels. Is it acceptable or not?

Thanks in advance,

Michele


--
Research Associate @ NPSY-Lab.VR - University of Verona
Research Associate @ AgliotiLab - University of Rome "La Sapienza"
Iscrizione all'albo A dell'Ordine degli Psicologi del Veneto n.7733

office tel. 0039 045 802 8401<tel:0039%20045%20802%208401>

*http://agliotilab.org/lab-staff/phd-students/3rd-year/michele-scandola#anchor
<http://agliotilab.org/lab-staff/phd-students/3rd-year/michele-scandola#anchor>*
http://profs.formazione.univr.it/npsy-labvr/michele-scandola/
http://scholar.google.it/citations?user=mRc0hxsAAAAJ
http://it.linkedin.com/pub/michele-scandola/24/967/313



*Le informazioni, i dati e le notizie contenute nella presente
comunicazione e i relativi allegati sono di natura privata e come tali
possono essere riservate e sono, comunque, destinate esclusivamente ai
destinatari indicati in epigrafe. La diffusione, distribuzione e/o la
copiatura del documento  trasmesso da parte di qualsiasi soggetto diverso
dal destinatario ? proibita, sia ai sensi dell?art. 616 c.p., sia ai sensi
del D.Lgs. n. 196/2003. Se avete ricevuto questo messaggio per errore, vi
preghiamo di distruggerlo e di darcene immediata comunicazione anche
inviando un messaggio di ritorno all?indirizzo e-mail del mittente.*
*This e-mail (including attachments) is intended only for the recipient(s)
named above. It may contain confidential or privileged information and
should not be read, copied or otherwise used by any other person. If you
are not the named recipient, please contact npsylab.vr at gmail.com<mailto:npsylab.vr at gmail.com>
<npsylab.vr at gmail.com<mailto:npsylab.vr at gmail.com>> and delete the e-mail from your system. Rif. D.L.
196/2003.*

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From singmann at psychologie.uzh.ch  Sat Apr 15 01:50:20 2017
From: singmann at psychologie.uzh.ch (Henrik Singmann)
Date: Sat, 15 Apr 2017 01:50:20 +0200
Subject: [R-sig-ME] New version of afex on CRAN now
Message-ID: <ocrn7m$ess$1@blaine.gmane.org>

Dear list,

After one year without updates, a new version (0.17-8) of afex (Analysis 
of Factorial Experiments with ANOVA and Mixed Models) has finally been 
accepted on CRAN yesterday:
https://cran.r-project.org/package=afex

This new version comes with a series of new features, mostly related to 
mixed models, that might be of interest to some. The full list of 
changes can be found here:
https://cran.r-project.org/web/packages/afex/NEWS

The major news are:
- For LMMs, mixed() now supports the Satterthwaite approximation for 
obtaining p-values (method="S"), via lmerTest.

- mixed() methods "KR" and "S" are now obtained via tests on the full 
model, which can be considerably faster.

- Added a new vignettes containing an extensive mixed model example 
analysis: 
https://cran.r-project.org/web/packages/afex/vignettes/afex_mixed_example.html

- All arguments and slots with "." in the name have been renamed to use 
"_". This may lead to warnings in existing code.

- Added argument all_fit to mixed(). If TRUE, each model (i.e., full and 
restricted) is fitted with all available optimizers and the best fit in 
each case selected. Can be quite helpful for GLMMs with convergence 
problems and method="LRT".

- All returned objects ("mixed", "afex_aov", and "nice") have a pretty 
print() method. (Thanks to Frederik Aust)

Given that I occasionally receive questions related to afex and the 
existing mailing list can be intimidating I have decided to establish a 
support forum at: http://afex.singmann.science/
Feel free to share the address with students or other interested 
parties. As some questions seem to repeat, I hope this can become a 
valuable resource.

Cheers,
Henrik

-- 
Dr. Henrik Singmann
PostDoc
Universit?t Z?rich, Schweiz
http://singmann.org


From geralttee at gmail.com  Sat Apr 15 16:17:17 2017
From: geralttee at gmail.com (Szymek Drobniak)
Date: Sat, 15 Apr 2017 16:17:17 +0200
Subject: [R-sig-ME] Fwd: Continuous variable as random slope and the
 minimum number of levels for a categorical variable to be treated as random
Message-ID: <cd02f74e-7051-4cd6-bb5d-8f0a772bbbf7@Spark>

Dear Michele,

this is not really the point of "even continuous, ordered variables can be used?as grouping factors?. Random effects have gathered a lot of misunderstandings over the years and I?ve seen many invalid claims about them, both in the Internet and in personal communications from many researchers (e.g. that you define a variable as random if it is not of ?main interest?, or that grouping factors with 2-3 levels make sense as robust random terms). For me the point is really the aim and question we want to ask (and also computational considerations - e.g. 2 levels are a poor sample from a larger distribution of random effects and probably are much better accommodated when included as fixed factors, without any serious bias in other model estimates).

Your question (if "continuous, ordered variables can be used as grouping factors? can be used as random terms) is actually a question about what is the point of a particular term. If for some reason you can account for possible non-independence between age classes, then yes, you can include them as a random factor (in such a case they loose their ?ordering? - you use them as classes and estimate variance between them). On the other hand - you may want to vary the effect of such continuous variable, e.g. between individuals - in such a case you form a random interaction with it, estimating variance in age-related slopes (and also usually intercepts). Everything boils down to your question and the reason for including a particular term in the model. I can even imagine a age where age is used as both a fixed covariate and as a random (unordered) categorical variable (if we expect some between age-classes variance on top of that explained by a linear, continuous effect of age modelled via the fixed term).

Cheers
Szymek

Institute of Environmental Sciences
Jagiellonian University, Krak?w, Poland

Evolutionary Biology Centre
Uppsala University, Uppsala, Sweden

Google Scholar profile


	[[alternative HTML version deleted]]


From bbolker at gmail.com  Sat Apr 15 18:34:43 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 15 Apr 2017 12:34:43 -0400
Subject: [R-sig-ME] mixture DIC model
In-Reply-To: <372653862.178581.1492155628110@mail.yahoo.com>
References: <372653862.178581.1492155628110.ref@mail.yahoo.com>
 <372653862.178581.1492155628110@mail.yahoo.com>
Message-ID: <CABghstTFAWDwT9RRJ37UUEKUssZmEsEY-wV8mDYdY1-mMHgUBA@mail.gmail.com>

We'd like to help you, but your question is very hard to understand.

On Fri, Apr 14, 2017 at 3:40 AM, Mohammadreza Kordbagheri via
R-sig-mixed-models <r-sig-mixed-models at r-project.org> wrote:
> hello
> my name is alireza kordbagheri of shahid beheshti university tehran.
>
> i have two question of you:
>
> can you help me for my question:
> one question: i read your article tittle:
>
> i dont know, how draw heatmap ANOVA GAMMA.

   What does this mean?

A heatmap is an image plot drawn with colours drawn from a "heat
spectrum" (red to white)

ANOVA is analysis of variance (abused in R's anova() function as a
general-purpose tool for comparing nested models)

Gamma is a distribution (and a function)

>
> two question:i writing code model with JAGS softwar.
> i used of function GB2.

  What does that mean?
>
> I have problem, what DIC estimation?

  What is your question?

> This article is open access at
>
> https://projecteuclid.org/euclid.ba/1340370933.
>
> library(rjags)
>
> cat(file = "model.txt",
> "
> data {
>   C <- 100
>   for (i in 1:N) {
>     zeros[i] <- 0
>   }
> }
> model {
>   for (i in 1:N) {
>     zeros[i] ~ dpois(loglik[i] + C)
>     loglik[i] <- -log(pi[1] * l1[i] + pi[2] * l2[i])
>     l1[i] <- abs(a[1]) * pow(y[i], a[1] * p[1] - 1) / (pow(b1[i], a[1] * p[1]) * exp(loggam(p[1]) + loggam(q[1]) - loggam(p[1] + q[1])) * pow(1 + pow(y[i] / b1[i], a[1]), p[1] + q[1]))
>     l2[i] <- abs(a[2]) * pow(y[i], a[2] * p[2] - 1) / (pow(b2[i], a[2] * p[2]) * exp(loggam(p[2]) + loggam(q[2]) - loggam(p[2] + q[2])) * pow(1 + pow(y[i] / b2[i], a[2]), p[2] + q[2]))
>     b1[i]<- exp(mu[1] + alpha[1] * f[i] + beta1[1] * col1[i] + beta2[1] * col2[i] + beta3[1] * col3[i] + loggam(p[1]) + loggam(q[1]) - loggam(p[1] + 1 / a[1]) - loggam(q[1] - 1 / a[1]))
>     b2[i]<- exp(mu[2] + alpha[2] * f[i] + beta1[2] * col1[i] + beta2[2] * col2[i] + beta3[2] * col3[i] + loggam(p[2]) + loggam(q[2]) - loggam(p[2] + 1 / a[2]) - loggam(q[2] - 1 / a[2]))
>   }
>   pi[1] ~ dunif(0, 1)
>   pi[2] <- 1 - pi[1]
>   for(k in 1:2) {
>     mu[k] ~ dnorm(0, .01)
>     alpha[k] ~ dnorm(0, .01)
>     beta1[k] ~ dnorm(0, .01)
>     beta2[k] ~ dnorm(0, .01)
>     beta3[k] ~ dnorm(0, .01)
>     a[k] ~ dnorm(0, .01)
>     p[k] ~ dgamma(.01, .01)I(0, 90)
>     q[k] ~ dgamma(.01, .001)I(1, 3.5)
>   }
> }
> ")
>
> data <- matrix(c(
> 3323,  5, 1, 0, 0,
> 8332,  8, 0, 1, 1,
> 9572,  5, 1, 0, 0,
> 10172, 10, 1, 0, 1,
> 7631,  2, 1, 0, 0,
> 3855,  9, 0, 1, 1,
> 3252,  6, 1, 0, 1,
> 4433,  8, 0, 1, 1,
> 2188,  7, 1, 0, 0,
>   333,  4, 1, 0, 0,
>   199,  3, 0, 1, 1,
>   692,  9, 0, 1, 0,
>   311, 12, 1, 0, 0,
> 0.01,  5, 1, 0, 1,
>   405,  6, 0, 1, 0,
>   293,  6, 0, 1, 0,
>   76,  7, 1, 0, 1,
>   14,  9, 1, 0, 0,
> 3785, 21, 0, 1, 1,
> 10342, 11, 0, 1, 1), ncol = 5, byrow = TRUE)
>
> bugs.data <- list(N = nrow(data),
>                   y = data[, 1],
>                   f = data[, 2],
>                   col1 = data[, 3],
>                   col2 = data[, 4],
>                   col3 = data[, 5])
> set.seed(123)
> inits <- lapply(1:3, function(i) {
>     list(mu = rnorm(2, 0, 1),
>         alpha = rnorm(2, 0, 1),
>         beta1 = rnorm(2, 0, 1),
>         beta2 = rnorm(2, 0, 1),
>         beta3 = rnorm(2, 0, 1),
>         pi = c(runif(1, 0, 1), NA),
>         a = runif(2, -4, -2),
>         p = runif(2, 1, 2),
>         q = runif(2, 1, 2),
>         .RNG.name = "base::Mersenne-Twister",
>         .RNG.seed = i)
>     })
> pars <- c("mu", "alpha", "beta1", "beta2", "beta3", "pi",
>           "a", "p", "q")
> model <- jags.model("model.txt",
>                     data = bugs.data,
>                     inits = inits,
>                     n.chains = 3,
>                     n.adapt = 1000)
> update(model, 3000)
> samp <- coda.samples(model,
>                     variable.names = pars,
>                     n.iter = 4000, thin = 4)
> gelman.diag(samp, multivariate = FALSE)
> traceplot(samp[, 15]) # pi[1]
> traceplot(samp[, 16]) # pi[2]
>
> can you help me.
>
> Regards,
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From scotsonuk at gmail.com  Tue Apr 18 02:51:33 2017
From: scotsonuk at gmail.com (Lorraine Scotson)
Date: Mon, 17 Apr 2017 19:51:33 -0500
Subject: [R-sig-ME] Modelling count data in glmer with an apriori model
	selection
Message-ID: <CACLdWc55u3iVTi=RchOJ1dv7vhYK-NLcmx1ppUb0S0CR9q8m8g@mail.gmail.com>

Hi All,

I am modeling bear distribution in Lao PDR, with sign count data collected
on transects, in glmer, using a degrees of freedom spending, apriori
modeling approach. I have calculated the number of degrees of freedom my
model can afford based on my effective sample size (i.e. number of line
transects), with degrees of freedoms calculated as the number of
non-intercept model-generated coefficients to be estimated. I have study
site as a random effect (n=7).

My objectives are to model bear occurrence as a function of covariates, to
rank those covariates in order of importance, and predict the distribution
of bears throughout the whole country (i.e extrapolate outside study
sites). This is my first experience with an apriori modelling strategy, and
i have a number of questions for which i have not found answers in the
published literature. I would be grateful for any advice anyone may have:

- how many degrees of freedom will including a 7-level random effect incur?

- My understanding is that i must pick my probability distribution (i.e.
Poisson, Neg Bin) apriori, and so i cannot use the usual post model checks
to determine is my chosen distribution was appropriate. Is this correct?

- My understanding is that i'll be penalized an extra degree of freedom by
using a Negative Binomial distribution. Is this correct?

- How do i decide between using a Poisson or a Negative binomial
distribution?  Is there some post hoc checks i can do, without exploring
the relationship between the response and the predictors, to inform my
decision?

(The literature tells me that count data are rarely Poisson distributed,
and that Negative binomial is the most common distribution that accounts
for over dispersion. I have ruled out zero-inflation; my response has
plenty of zero's, but i feel they they will be accounted for by the model
covariates).

- In the context of my study objectives, what are the consequences of using
a Poisson distribution when my data are really Negative Binomial (i.e. does
the distribution of the residuals of the response really matter?)?

Many thanks in advance for any insights you can offer.

Best wishes
Lorraine

-- 
Lorraine Scotson, PhD Candidate,
Department of Fisheries, Wildlife and Conservation Biology,
University of Minnesota, USA

Skype ID: lorrainescotson
Tel: +44141 6282079

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue Apr 18 03:03:31 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 17 Apr 2017 21:03:31 -0400
Subject: [R-sig-ME] Modelling count data in glmer with an apriori model
 selection
In-Reply-To: <CACLdWc55u3iVTi=RchOJ1dv7vhYK-NLcmx1ppUb0S0CR9q8m8g@mail.gmail.com>
References: <CACLdWc55u3iVTi=RchOJ1dv7vhYK-NLcmx1ppUb0S0CR9q8m8g@mail.gmail.com>
Message-ID: <c4635cc2-4b2c-34df-a7b9-018a1b6c9bee@gmail.com>



On 17-04-17 08:51 PM, Lorraine Scotson wrote:
> Hi All,
> 
> I am modeling bear distribution in Lao PDR, with sign count data collected
> on transects, in glmer, using a degrees of freedom spending, apriori
> modeling approach. I have calculated the number of degrees of freedom my
> model can afford based on my effective sample size (i.e. number of line
> transects), with degrees of freedoms calculated as the number of
> non-intercept model-generated coefficients to be estimated. I have study
> site as a random effect (n=7).

  Out of curiosity, how many df *can* you afford (how many line transects)?

> My objectives are to model bear occurrence as a function of covariates, to
> rank those covariates in order of importance, and predict the distribution
> of bears throughout the whole country (i.e extrapolate outside study
> sites). This is my first experience with an apriori modelling strategy, and
> i have a number of questions for which i have not found answers in the
> published literature. I would be grateful for any advice anyone may have:
> 
> - how many degrees of freedom will including a 7-level random effect incur?

   If you don't allow for variation in covariate effect across sites, 1.
   If you allow for (correlated) variation in n covariate effects across
sites, n*(n+1)/2.  (The number of levels of the random effect does not
affect this conclusion, although 7 sites is small for using a random
effect - you might end up with a singular model, and have to decide what
to do about it).

> - My understanding is that i must pick my probability distribution (i.e.
> Poisson, Neg Bin) apriori, and so i cannot use the usual post model checks
> to determine is my chosen distribution was appropriate. Is this correct?

  You should choose your probability distribution a priori, but you
*can* (and should) use post-fitting checks (scale-location, Q-Q,
overdispersion analysis, etc.) to see if there are any big problems with
your choice.
> 
> - My understanding is that i'll be penalized an extra degree of freedom by
> using a Negative Binomial distribution. Is this correct?

  Yes.  But this is a case where "saving" a degree of freedom wouldn't
be wise.

> 
> - How do i decide between using a Poisson or a Negative binomial
> distribution?  Is there some post hoc checks i can do, without exploring
> the relationship between the response and the predictors, to inform my
> decision?

  Yes.  Check for overdispersion.

> 
> (The literature tells me that count data are rarely Poisson distributed,
> and that Negative binomial is the most common distribution that accounts
> for over dispersion. I have ruled out zero-inflation; my response has
> plenty of zero's, but i feel they they will be accounted for by the model
> covariates).
> 
> - In the context of my study objectives, what are the consequences of using
> a Poisson distribution when my data are really Negative Binomial (i.e. does
> the distribution of the residuals of the response really matter?)?

  If your data are overdispersed (variance greater than expected from
Poisson), you will be in big trouble -- all of your conclusions
(p-values, confidence intervals) will be overconfident.

  I would recommend http://bbolker.github.io/mixedmodels-misc/ ,
especially "GLMM FAQ" and "supplementary materials for Bolker (2015)",
both of which have sections on overdispersion.

  It would be possible to use a "quasi-likelihood approach" -- correct
your estimated confidence intervals and p-values (as well as AICs etc.)
for overdispersion, without explicitly using an overdispersed distribution.

> 
> Many thanks in advance for any insights you can offer.
> 
> Best wishes
> Lorraine
>


From pauljohn32 at gmail.com  Wed Apr 19 17:39:19 2017
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Wed, 19 Apr 2017 10:39:19 -0500
Subject: [R-sig-ME] Modeling attacks and victories
Message-ID: <CAErODj9aebU1DbFYgrFgdVVytRqwePZHD-nBhO2cgKW7a3L3gA@mail.gmail.com>

Could I ask for pointers on how to guide a student in my multilevel
modeling course?

The outcome data is terrorist attack events, with one row per event
(events are listed by country and year). The data also indicates if
each attach is a "success" (I have no idea how that's measured, if it
matters I can find out).

The student says that, in his field, what they would do is aggregate
events at the country/year level to create a "proportion of successful
attacks" variable. If a country has no events, then it is scored as a
0.  Then they'd run random intercept models using country as case
identifier, possibly with other country level predictors that vary
across time.

I think we can do better than that. The number of events within
countries varies widely, some have 0 or 1 attack, while in some years
there are 30 or more.  Measuring the proportions is, obviously,
sensitive to the number in the denominator.  Some countries are scored
on a scale 0, .5, 1, while others are scored as 0, 0.03, 0.06, and so
forth.  Other obvious problems are the presence of 0's.

My first idea was to made this a binomial glm and predict successes as
a proportion of attacks.  That's a problem because there are lots of 0
attack country/years, but also because I'm

It looks to me like we need to explore this as a two part model, where
part 1 predicts (attacks > 0) and part 2 is binomial among the
countries and places where attacks > 0. I'm not finding discussion of
this particular example while searching (I probably don't know the
magic words).  However, we need to insert the country-level intercept
in both models, and perhaps the country effect needs to be correlated
between the two models.

pj

-- 
Paul E. Johnson   http://pj.freefaculty.org
Director, Center for Research Methods and Data Analysis http://crmda.ku.edu

To write to me directly, please address me at pauljohn at ku.edu.


From dakotajudo at mac.com  Wed Apr 19 18:28:51 2017
From: dakotajudo at mac.com (Peter Claussen)
Date: Wed, 19 Apr 2017 11:28:51 -0500
Subject: [R-sig-ME] Modeling attacks and victories
In-Reply-To: <CAErODj9aebU1DbFYgrFgdVVytRqwePZHD-nBhO2cgKW7a3L3gA@mail.gmail.com>
References: <CAErODj9aebU1DbFYgrFgdVVytRqwePZHD-nBhO2cgKW7a3L3gA@mail.gmail.com>
Message-ID: <AD19A085-D9D3-46D5-BA79-400B631E1D82@mac.com>

This is just off the top of my head, but wouldn?t you model the response as a Poisson binomial?

My simple way of thinking about it would be that the number of attacks per year is a Poisson process, while the probability of success is binomial, and p is independent for country.

Peter

> On Apr 19, 2017, at 10:39 AM, Paul Johnson <pauljohn32 at gmail.com> wrote:
> 
> Could I ask for pointers on how to guide a student in my multilevel
> modeling course?
> 
> The outcome data is terrorist attack events, with one row per event
> (events are listed by country and year). The data also indicates if
> each attach is a "success" (I have no idea how that's measured, if it
> matters I can find out).
> 
> The student says that, in his field, what they would do is aggregate
> events at the country/year level to create a "proportion of successful
> attacks" variable. If a country has no events, then it is scored as a
> 0.  Then they'd run random intercept models using country as case
> identifier, possibly with other country level predictors that vary
> across time.
> 
> I think we can do better than that. The number of events within
> countries varies widely, some have 0 or 1 attack, while in some years
> there are 30 or more.  Measuring the proportions is, obviously,
> sensitive to the number in the denominator.  Some countries are scored
> on a scale 0, .5, 1, while others are scored as 0, 0.03, 0.06, and so
> forth.  Other obvious problems are the presence of 0's.
> 
> My first idea was to made this a binomial glm and predict successes as
> a proportion of attacks.  That's a problem because there are lots of 0
> attack country/years, but also because I'm
> 
> It looks to me like we need to explore this as a two part model, where
> part 1 predicts (attacks > 0) and part 2 is binomial among the
> countries and places where attacks > 0. I'm not finding discussion of
> this particular example while searching (I probably don't know the
> magic words).  However, we need to insert the country-level intercept
> in both models, and perhaps the country effect needs to be correlated
> between the two models.
> 
> pj
> 
> -- 
> Paul E. Johnson   http://pj.freefaculty.org
> Director, Center for Research Methods and Data Analysis http://crmda.ku.edu
> 
> To write to me directly, please address me at pauljohn at ku.edu.
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From jdpo223 at g.uky.edu  Thu Apr 20 04:48:22 2017
From: jdpo223 at g.uky.edu (Poe, John)
Date: Wed, 19 Apr 2017 22:48:22 -0400
Subject: [R-sig-ME] Modeling attacks and victories
In-Reply-To: <CAErODj9aebU1DbFYgrFgdVVytRqwePZHD-nBhO2cgKW7a3L3gA@mail.gmail.com>
References: <CAErODj9aebU1DbFYgrFgdVVytRqwePZHD-nBhO2cgKW7a3L3gA@mail.gmail.com>
Message-ID: <CAFW8Byqg3tneuQJrK7JDwGwNJRPc4Rz=QsaQYGYvK3XM1oDYTQ@mail.gmail.com>

The standard way to deal with it in political science is going to be to
aggregate up to a count of attempted or successful attacks (depending on
their question I suppose) and use something like a zero inflated mixed
effects negative binomial model with a nonparametric random effect because
of the zero inflation and low mean relative to the long tail.

One way to expand that might be to model a count of terror attack attempts
as a function of successful attacks in the country last year and if there
were any attack attempts in the last year.  The data are pretty highly
correlated over time so I'd assume past experiences drive current ones.
That's going to induce correlation between the past time variables and
random effects which causes bias but can be dealt with as a multilevel
structural equation model according to a paper by Paul Allison titled
dynamic panel data modelling using maximum likelihood.  It's published in
an econometrics journal now but I can't remember which.

I wouldn't use proportion successful as an outcome unless the student is
trying specifically to answer what makes terrorist groups more successful
at attacks assuming they try to attack. That's a very specific research
question but you could manage it with a selection model for any attempt yes
or no as the selection stage outcome and the proportion successful as the
second stage model.  If you don't separate the zeroes into a never
attempted group and a tried but failed group any reviewer in political
science will start screaming about terrorists selecting countries where
they are more likely to be successful as places to attempt attacks so that
success drives attempts. Even then I can see it being a problem modelling
the proportion given that a low success rate may lead to fewer future
attempts which could lower it even more.

This paper might help.

Grilli, L. and Rampichini, C., 2010. Selection bias in linear mixed models.
Metron, 68(3), pp.309-329.

You could model this in stata or mplus as a random effects selection model
pretty easily but in R you would probably need Stan to allow you to
correlate the random effects and error terms. I'm not sure if there's
another package that would?

What you described with an incidence-level model was, I think,  a hurdle
model where you just model any attack yes/no and successful attack if any
attack yes/no with two logistic regression models with correlated error
terms. You can find something similar with the craggit extension of the
tobit model out of econometrics. Again, you could fit It in Stata or mplus
easy enough but I don't know of an R package that will let you correlate
the decomposed errors across two logistic regressions and give you random
intercepts unless you designed it in something like Stan.

I'd also worry about truncating out the zero attempted attack country-years
as it's going to distort the random effects estimation away from zero.

Hope that helps.  I'm pretty tired at the moment so it might not be
entirely coherent.



On Apr 19, 2017 11:39 AM, "Paul Johnson" <pauljohn32 at gmail.com> wrote:

Could I ask for pointers on how to guide a student in my multilevel
modeling course?

The outcome data is terrorist attack events, with one row per event
(events are listed by country and year). The data also indicates if
each attach is a "success" (I have no idea how that's measured, if it
matters I can find out).

The student says that, in his field, what they would do is aggregate
events at the country/year level to create a "proportion of successful
attacks" variable. If a country has no events, then it is scored as a
0.  Then they'd run random intercept models using country as case
identifier, possibly with other country level predictors that vary
across time.

I think we can do better than that. The number of events within
countries varies widely, some have 0 or 1 attack, while in some years
there are 30 or more.  Measuring the proportions is, obviously,
sensitive to the number in the denominator.  Some countries are scored
on a scale 0, .5, 1, while others are scored as 0, 0.03, 0.06, and so
forth.  Other obvious problems are the presence of 0's.

My first idea was to made this a binomial glm and predict successes as
a proportion of attacks.  That's a problem because there are lots of 0
attack country/years, but also because I'm

It looks to me like we need to explore this as a two part model, where
part 1 predicts (attacks > 0) and part 2 is binomial among the
countries and places where attacks > 0. I'm not finding discussion of
this particular example while searching (I probably don't know the
magic words).  However, we need to insert the country-level intercept
in both models, and perhaps the country effect needs to be correlated
between the two models.

pj

--
Paul E. Johnson   http://pj.freefaculty.org
Director, Center for Research Methods and Data Analysis http://crmda.ku.edu

To write to me directly, please address me at pauljohn at ku.edu.

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Thu Apr 20 09:34:16 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 20 Apr 2017 09:34:16 +0200
Subject: [R-sig-ME] Modeling attacks and victories
In-Reply-To: <CAErODj9aebU1DbFYgrFgdVVytRqwePZHD-nBhO2cgKW7a3L3gA@mail.gmail.com>
References: <CAErODj9aebU1DbFYgrFgdVVytRqwePZHD-nBhO2cgKW7a3L3gA@mail.gmail.com>
Message-ID: <CAJuCY5xGp6vN4LzKEpzPXqYaF79G6uRWbJhPYsZynM0KH2o1nQ@mail.gmail.com>

Dear Paul,

I'd focus on two different points first:
a) what does the student wants to model: the probability of success? the
number of events? the number of successful events? something else?
b) what are the statistical skills of the student. That will determine the
appropriate level of statistical machismo.

Best regards,

Thierry


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-04-19 17:39 GMT+02:00 Paul Johnson <pauljohn32 at gmail.com>:

> Could I ask for pointers on how to guide a student in my multilevel
> modeling course?
>
> The outcome data is terrorist attack events, with one row per event
> (events are listed by country and year). The data also indicates if
> each attach is a "success" (I have no idea how that's measured, if it
> matters I can find out).
>
> The student says that, in his field, what they would do is aggregate
> events at the country/year level to create a "proportion of successful
> attacks" variable. If a country has no events, then it is scored as a
> 0.  Then they'd run random intercept models using country as case
> identifier, possibly with other country level predictors that vary
> across time.
>
> I think we can do better than that. The number of events within
> countries varies widely, some have 0 or 1 attack, while in some years
> there are 30 or more.  Measuring the proportions is, obviously,
> sensitive to the number in the denominator.  Some countries are scored
> on a scale 0, .5, 1, while others are scored as 0, 0.03, 0.06, and so
> forth.  Other obvious problems are the presence of 0's.
>
> My first idea was to made this a binomial glm and predict successes as
> a proportion of attacks.  That's a problem because there are lots of 0
> attack country/years, but also because I'm
>
> It looks to me like we need to explore this as a two part model, where
> part 1 predicts (attacks > 0) and part 2 is binomial among the
> countries and places where attacks > 0. I'm not finding discussion of
> this particular example while searching (I probably don't know the
> magic words).  However, we need to insert the country-level intercept
> in both models, and perhaps the country effect needs to be correlated
> between the two models.
>
> pj
>
> --
> Paul E. Johnson   http://pj.freefaculty.org
> Director, Center for Research Methods and Data Analysis
> http://crmda.ku.edu
>
> To write to me directly, please address me at pauljohn at ku.edu.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From pauljohn32 at gmail.com  Thu Apr 20 23:42:15 2017
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Thu, 20 Apr 2017 16:42:15 -0500
Subject: [R-sig-ME] Modeling attacks and victories
In-Reply-To: <CAJuCY5xGp6vN4LzKEpzPXqYaF79G6uRWbJhPYsZynM0KH2o1nQ@mail.gmail.com>
References: <CAErODj9aebU1DbFYgrFgdVVytRqwePZHD-nBhO2cgKW7a3L3gA@mail.gmail.com>
 <CAJuCY5xGp6vN4LzKEpzPXqYaF79G6uRWbJhPYsZynM0KH2o1nQ@mail.gmail.com>
Message-ID: <CAErODj-jvRppD4tMpjSoJjVZ3n6xNAQU3Cg4xGjY-JEiAXrTjA@mail.gmail.com>

Thanks very much for the advice. I truly appreciate it.

I am going to steer this one back to a simpler question, predict the
number of attacks and put aside the success issue until after we
understand the basics.  I think we can manage the random effects in
the count model, maybe with zero inflation.

pj

On Thu, Apr 20, 2017 at 2:34 AM, Thierry Onkelinx
<thierry.onkelinx at inbo.be> wrote:
> Dear Paul,
>
> I'd focus on two different points first:
> a) what does the student wants to model: the probability of success? the
> number of events? the number of successful events? something else?
> b) what are the statistical skills of the student. That will determine the
> appropriate level of statistical machismo.
>
> Best regards,
>
> Thierry
>
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more than
> asking him to perform a post-mortem examination: he may be able to say what
> the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2017-04-19 17:39 GMT+02:00 Paul Johnson <pauljohn32 at gmail.com>:
>>
>> Could I ask for pointers on how to guide a student in my multilevel
>> modeling course?
>>
>> The outcome data is terrorist attack events, with one row per event
>> (events are listed by country and year). The data also indicates if
>> each attach is a "success" (I have no idea how that's measured, if it
>> matters I can find out).
>>
>> The student says that, in his field, what they would do is aggregate
>> events at the country/year level to create a "proportion of successful
>> attacks" variable. If a country has no events, then it is scored as a
>> 0.  Then they'd run random intercept models using country as case
>> identifier, possibly with other country level predictors that vary
>> across time.
>>
>> I think we can do better than that. The number of events within
>> countries varies widely, some have 0 or 1 attack, while in some years
>> there are 30 or more.  Measuring the proportions is, obviously,
>> sensitive to the number in the denominator.  Some countries are scored
>> on a scale 0, .5, 1, while others are scored as 0, 0.03, 0.06, and so
>> forth.  Other obvious problems are the presence of 0's.
>>
>> My first idea was to made this a binomial glm and predict successes as
>> a proportion of attacks.  That's a problem because there are lots of 0
>> attack country/years, but also because I'm
>>
>> It looks to me like we need to explore this as a two part model, where
>> part 1 predicts (attacks > 0) and part 2 is binomial among the
>> countries and places where attacks > 0. I'm not finding discussion of
>> this particular example while searching (I probably don't know the
>> magic words).  However, we need to insert the country-level intercept
>> in both models, and perhaps the country effect needs to be correlated
>> between the two models.
>>
>> pj
>>
>> --
>> Paul E. Johnson   http://pj.freefaculty.org
>> Director, Center for Research Methods and Data Analysis
>> http://crmda.ku.edu
>>
>> To write to me directly, please address me at pauljohn at ku.edu.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
Paul E. Johnson   http://pj.freefaculty.org
Director, Center for Research Methods and Data Analysis http://crmda.ku.edu

To write to me directly, please address me at pauljohn at ku.edu.


From chatfield at alumni.rice.edu  Fri Apr 21 01:11:13 2017
From: chatfield at alumni.rice.edu (Robert Chatfield)
Date: Thu, 20 Apr 2017 16:11:13 -0700
Subject: [R-sig-ME] nested effects for only a small subset of situations
Message-ID: <89556198-FC79-4839-9E4C-1D7C83AF3720@alumni.rice.edu>

I am estimating a model for fire emissions factors (slopes wrt x)

spectype.lmer <- lmer( y ~ x + 1 +  (x - 1 | species.type) + ( 1 | id)  , data=first.long.dat )

where  y actually represents a variety of (chemical) species, alll normalized by mean,

but there can be variations from one observati on  to the next among a few (6) different fire-types
?type.?  So I have oonxtructed the compound factor species.type as commonly described
in Bates?s writings.

id is just the sequential number of the observation of all 10 species. 

Now it turns out that for two of the species, there should be an extra term somthing
like   ( 1 | plume )    

spectype.plume.lmer <-  lmer( y ~ x + 1 + (x - 1 | species.type) + ( 1 | id) +  ( 1 | plume ) , data=first.long.dat ) 

where all the observations with  id  in that   plume (3 to 40 ids per plume)     should have the same value.  
id   is nested withiin   plume  .
A  dditionally, the intercept should depend only on species, not species.type


Only 2/10s of the observations require this value.
I want to ?horde? degrees of freedom except for maybe some experimental tests to
see if the other species . Variance explained is pretty good even without including
this term.

This does not seem to fit wtihin the formula choices as I understand them.

(1) Can I create a factor CO.plume.offset which ?activates? only when species is  CO  but
varies by plume, a level for each plume ?        (allso   a factor CH4. plume. offset )
  

(2) How about estimating the offset after spec.type.lmer is calculated using the
residuals.  Then I could re-enter the offsets in a second lmer calculation, by adjusting y .  This does
seem to reduce the meaning of statistical tests, but it?s very simple. The residuals for CO  and CH4 for
spectype.lmer are not high but the residuals corresponding to CH4 especially do seem
to move up and down from plume to plume.

Bob Chatfield

Robert Chatfield
Robert.B.Chatfield at nasa.gov <mailto:Robert.B.Chatfield at nasa.gov>
Earth Science, Atmospherics, NASA Ames
MS 245-5 
Moffett Field CA 94035-1000 USA
660-604-5490   Cell: 650-793-5227


	[[alternative HTML version deleted]]


From simonesantoro77 at gmail.com  Fri Apr 21 17:26:28 2017
From: simonesantoro77 at gmail.com (simone santoro)
Date: Fri, 21 Apr 2017 17:26:28 +0200
Subject: [R-sig-ME] Fwd: glmmTMB,
	glmmADMB for a proportion RV with 0- (and 1-?) inflation
In-Reply-To: <CAO_Dm+MCYk7ci2DriBVWgqH13Z9N1dCgPOSZNngE4qk4k-o+oA@mail.gmail.com>
References: <CAO_Dm+MCYk7ci2DriBVWgqH13Z9N1dCgPOSZNngE4qk4k-o+oA@mail.gmail.com>
Message-ID: <CAO_Dm+N3AJFDus+Gi+mwY4aerF7f+BHm1ffa_CBLbhOi0J27uQ@mail.gmail.com>

Hi all,


I am trying to test the effect of a continuous variable on a response
variable which represents the proportion of grandchildren generated by the
sons of a certain brood with respect to the total. What I want to
investigate is whether there is a relationship between the predictor and
the differential fitness of sons with respect to daughters. Does, in
response to the predictor, the fitness provided by sons increase at a
different rate than the fitness provided by daughters?

Each row of the data set refers to a certain brood. Broods proceed from
several years that I set as a random intercept.


Data look like this:

https://drive.google.com/open?id=0BwsTfIcebsrOOW1MV1dncThqRUU


I made an attempt to address this question by using a binomial glmmTMB and
glmmadmb with zero inflation (constant in both cases). I found pretty
different results by using glmmTMB and glmmADMB. In fact, I found a
positive and significant relationship (that is what I would have expected
according to the biological hypothesis) with glmmadmb but, quite
surprisingly for me, I found a negative and significant relationship by
using glmmTMB. However, when I remove all the other variables (columns)
from my complete data set I find the similar results for glmmadmb and
glmmTMB. Here below you can see the output for the latter case (data set
without the columns of other variables):

> tmb0<- glmmTMB(malLRSfl/sumLRSfl~fatherA+(1|year),data=dati,zi=~1,
family=binomial,weights=sumLRSfl)

> admb0<- glmmadmb(cbind(malLRSfl,femLRSfl)~fatherA+(1|year),
data=dati,zeroInflation=TRUE,family="binomial")

> summary(tmb0)

 Family: binomial  ( logit )

Formula:          malLRSfl/sumLRSfl ~ fatherA + (1 | year)

Zero inflation:                     ~1

Data: dati

Weights: sumLRSfl



     AIC      BIC   logLik deviance df.resid

  3539.8   3557.8  -1765.9   3531.8      656



Random effects:



Conditional model:

 Groups Name        Variance Std.Dev.

 year   (Intercept) 0.5004   0.7074

Number of obs: 660, groups:  year, 24



Conditional model:

            Estimate Std. Error z value Pr(>|z|)

(Intercept)  1.64559    0.15989  10.292   <2e-16 ***

fatherA     -0.08441    0.03834  -2.202   0.0277 *

---

Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1



Zero-inflation model:

            Estimate Std. Error z value Pr(>|z|)

(Intercept) -0.43521    0.08028  -5.421 5.92e-08 ***

---

Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

> summary(admb0)



Call:

glmmadmb(formula = cbind(malLRSfl, femLRSfl) ~ fatherA + (1 |

    year), data = dati, family = "binomial", zeroInflation = TRUE)



AIC: 3383.2



Coefficients:

            Estimate Std. Error z value Pr(>|z|)

(Intercept)   2.0206     0.2182    9.26   <2e-16 ***

fatherA      -0.1100     0.0521   -2.11    0.035 *

---

Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1



Number of observations: total=1943, year=24

Random effect variance(s):

Group=year

            Variance StdDev

(Intercept)   0.9543 0.9769



Zero-inflation: 0.401  (std. err.:  0.019392 )



Log-likelihood: -1687.62



I have noted that the number of observations does not match between glmmTMB
and glmmadmb because the first does not count when malLRSfl/sumLRSfl=NaN
(i.e. when 0/0). In fact, if I use cbind also in glmmTMB the number of
observations becomes the same (but this is the only change in the summary).

I would appreciate a lot some help to understand this difference and,
besides that, I would like to ask you whether you consider this approach
sound. For instance, I have realized that a betabinomial distribution might
be better given the distribution of response variable (below without the
0/0 values). However, I wonder if in this case a zero-and-one inflated
betabinomial approach would be more logic but I have not found a way of
running it in a glmm fashion.

https://drive.google.com/open?id=0BwsTfIcebsrOMFZqWDllc3JmTXc


This is my sessionInfo() (several packages now because I have been trying
many alternatives):

R version 3.3.3 (2017-03-06)

Platform: x86_64-w64-mingw32/x64 (64-bit)

Running under: Windows 7 x64 (build 7601) Service Pack 1



locale:

[1] LC_COLLATE=Spanish_Spain.1252  LC_CTYPE=Spanish_Spain.1252

[3] LC_MONETARY=Spanish_Spain.1252 LC_NUMERIC=C

[5] LC_TIME=Spanish_Spain.1252



attached base packages:

 [1] parallel  splines   stats4    stats     graphics  grDevices utils
    datasets  methods

[10] base



other attached packages:

[1] gamlss_5.0-1      nlme_3.1-131      gamlss.data_5.0-0
gamlss.dist_5.0-0 ordinal_2015.6-28

[6] glmmADMB_0.8.4    MASS_7.3-45       glmmTMB_0.1.1     bbmle_1.0.19



loaded via a namespace (and not attached):

 [1] Rcpp_0.12.10      TMB_1.7.9         magrittr_1.5
lattice_0.20-34   minqa_1.2.4

 [6] stringr_1.2.0     plyr_1.8.4        tools_3.3.3       grid_3.3.3
      coda_0.19-1

[11] survival_2.40-1   lme4_1.1-12       numDeriv_2016.8-1
ucminf_1.1-4      Matrix_1.2-8

[16] R2admb_0.7.15     nloptr_1.0.4      stringi_1.1.5

	[[alternative HTML version deleted]]


From edwardsmolina at gmail.com  Fri Apr 21 22:32:37 2017
From: edwardsmolina at gmail.com (Juan Pablo Edwards Molina)
Date: Fri, 21 Apr 2017 17:32:37 -0300
Subject: [R-sig-ME] GLMM for Combined experiments and overdispersed data
Message-ID: <CAF5W3aRX0+K7Js0Kkuy1KEgJ86oiB_0i7ZYNMBxS9_A8znWtLA@mail.gmail.com>

I am analyzing data from 3 field experiments (farms=3) for a citrus flower
disease: response variable is binomial because the flower can only be
diseased or healthy.

I have particular interest in comparing 5 fungicide spraying systems
(trt=5).

Each farm had 4 blocks (bk=4) including 2 trees as subsamples (tree=2) in
which I assessed 100 flowers each one. This is a quick look of the data:

farm      trt      bk    tree   dis   tot     <fctr>   <fctr>  <fctr>
<fctr> <int> <int>
iaras      cal      1      1     0    100
iaras      cal      1      2     1    100
iaras      cal      2      1     1    100
iaras      cal      2      2     3    100
iaras      cal      3      1     0    100
iaras      cal      3      2     5    100...

The model I considered was:

resp <- with(df, cbind(dis, tot-dis))

m1 = glmer(resp ~ trt + (1|farm/bk) , family = binomial, data=df)

I tested the overdispersion with the overdisp_fun() from GLMM page
<http://glmm.wikidot.com/faq>

        chisq         ratio             p          logp
 4.191645e+02  3.742540e+00  4.804126e-37 -8.362617e+01

As ratio (residual dev/residual df) > 1, and the p-value < 0.05, I
considered to add the observation level random effect (link
<http://r.789695.n4.nabble.com/Question-on-overdispersion-td3049898.html>)
to deal with the overdispersion.

farm      trt      bk    tree   dis   tot tree_id    <fctr>   <fctr>
<fctr> <fctr> <int> <int> <fctr>
iaras      cal      1      1     0    100    1
iaras      cal      1      2     1    100    2
iaras      cal      2      1     1    100    3...

so now was added a random effect for each row (tree_id) to the model, but I
am not sure of how to include it. This is my approach:

m2 = glmer(resp ~ trt + (1|farm/bk) + (1|tree_id), family = binomial, data=df)

I also wonder if farm should be a fixed effect, since it has only 3
levels...

m3 = glmer(resp ~ trt * farm + (1|farm:bk) + (1|tree_id), family =
binomial, data=df)

I really appreciate your suggestions about my model specifications...



*Juan? Edwards- - - - - - - - - - - - - - - - - - - - - - - -# PhD student
- ESALQ-USP/Brazil*

	[[alternative HTML version deleted]]


From chanratana.pin at gmail.com  Mon Apr 24 04:54:42 2017
From: chanratana.pin at gmail.com (Pin chanratana)
Date: Mon, 24 Apr 2017 09:54:42 +0700
Subject: [R-sig-ME] Plot model average
Message-ID: <CANW7wbdSFNo76kdJSWo+V3rUWmCn5ZthDXqJYQxXLkTmk_gJyA@mail.gmail.com>

Hello everyone here,

I'm analyzing my data research on wildlife using of seasonal waterholes.

I did the model average (of the 2 models below) using #model.avg function
(package MuMIn).

glmmadmb(BT~water+tree+offset(log(trap))+(1|obs), family="nbinom",
data=ndata4)

glmmadmb(BT~water+tree+road+offset(log(trap))+(1|obs), family="nbinom",
data=ndata4)

Model-averaged coefficients:
(full average)
            Estimate Std. Error Adjusted SE z value Pr(>|z|)
(Intercept) -3.33821    0.16062     0.16128  20.698   <2e-16 ***
water       -0.42935    0.18091     0.18166   2.364   0.0181 *
tree         0.28022    0.11639     0.11684   2.398   0.0165 *
road         0.05068    0.09926     0.09950   0.509   0.6105

(conditional average)
            Estimate Std. Error Adjusted SE z value Pr(>|z|)
(Intercept)  -3.3382     0.1606      0.1613  20.698   <2e-16 ***
water        -0.4294     0.1809      0.1817   2.364   0.0181 *
tree          0.2802     0.1164      0.1168   2.398   0.0165 *
road          0.1315     0.1222      0.1227   1.071   0.2841
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Relative variable importance:
                     offset(log(trap)) tree water road
Importance:          1.00              1.00 1.00  0.39
N containing models:    2                 2    2     1

How can I plot the beta coefficient of model average above?

Thanks,

Ratana

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Apr 24 09:29:21 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 24 Apr 2017 09:29:21 +0200
Subject: [R-sig-ME] GLMM for Combined experiments and overdispersed data
In-Reply-To: <CAF5W3aRX0+K7Js0Kkuy1KEgJ86oiB_0i7ZYNMBxS9_A8znWtLA@mail.gmail.com>
References: <CAF5W3aRX0+K7Js0Kkuy1KEgJ86oiB_0i7ZYNMBxS9_A8znWtLA@mail.gmail.com>
Message-ID: <CAJuCY5z+Axd_LRhG8n+HWYHatFi6d-cD3RWu8ey0fs=EQb7Hxg@mail.gmail.com>

Dear Juan,

Use unique id's for random effects variables. So each bk should only be
present in one farm. And each tree_id should be present in only one bk. In
case each block has different treatments then each tree_id should be unique
to one combination of bk and trt.

Farm has too few levels to be a random effects. So either model is as a
fixed effect or drop it. In case you drop it, the information will be
picked up by bk. Note that trt + (1|farm) is less complex than trt * farm.

Assuming that you are not interested in the effect of a specific farm, you
could use sum, polynomial or helmert contrasts for the farms. Unlike the
default treatment contrast, these type of contrasts sum to zero. Thus the
effect of trt will be that for the average farm instead of the reference
farm.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-04-21 22:32 GMT+02:00 Juan Pablo Edwards Molina <
edwardsmolina at gmail.com>:

> I am analyzing data from 3 field experiments (farms=3) for a citrus flower
> disease: response variable is binomial because the flower can only be
> diseased or healthy.
>
> I have particular interest in comparing 5 fungicide spraying systems
> (trt=5).
>
> Each farm had 4 blocks (bk=4) including 2 trees as subsamples (tree=2) in
> which I assessed 100 flowers each one. This is a quick look of the data:
>
> farm      trt      bk    tree   dis   tot     <fctr>   <fctr>  <fctr>
> <fctr> <int> <int>
> iaras      cal      1      1     0    100
> iaras      cal      1      2     1    100
> iaras      cal      2      1     1    100
> iaras      cal      2      2     3    100
> iaras      cal      3      1     0    100
> iaras      cal      3      2     5    100...
>
> The model I considered was:
>
> resp <- with(df, cbind(dis, tot-dis))
>
> m1 = glmer(resp ~ trt + (1|farm/bk) , family = binomial, data=df)
>
> I tested the overdispersion with the overdisp_fun() from GLMM page
> <http://glmm.wikidot.com/faq>
>
>         chisq         ratio             p          logp
>  4.191645e+02  3.742540e+00  4.804126e-37 -8.362617e+01
>
> As ratio (residual dev/residual df) > 1, and the p-value < 0.05, I
> considered to add the observation level random effect (link
> <http://r.789695.n4.nabble.com/Question-on-overdispersion-td3049898.html>)
> to deal with the overdispersion.
>
> farm      trt      bk    tree   dis   tot tree_id    <fctr>   <fctr>
> <fctr> <fctr> <int> <int> <fctr>
> iaras      cal      1      1     0    100    1
> iaras      cal      1      2     1    100    2
> iaras      cal      2      1     1    100    3...
>
> so now was added a random effect for each row (tree_id) to the model, but I
> am not sure of how to include it. This is my approach:
>
> m2 = glmer(resp ~ trt + (1|farm/bk) + (1|tree_id), family = binomial,
> data=df)
>
> I also wonder if farm should be a fixed effect, since it has only 3
> levels...
>
> m3 = glmer(resp ~ trt * farm + (1|farm:bk) + (1|tree_id), family =
> binomial, data=df)
>
> I really appreciate your suggestions about my model specifications...
>
>
>
> *Juan? Edwards- - - - - - - - - - - - - - - - - - - - - - - -# PhD student
> - ESALQ-USP/Brazil*
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From edwardsmolina at gmail.com  Mon Apr 24 13:56:08 2017
From: edwardsmolina at gmail.com (Juan Pablo Edwards Molina)
Date: Mon, 24 Apr 2017 08:56:08 -0300
Subject: [R-sig-ME] GLMM for Combined experiments and overdispersed data
In-Reply-To: <CAJuCY5z+Axd_LRhG8n+HWYHatFi6d-cD3RWu8ey0fs=EQb7Hxg@mail.gmail.com>
References: <CAF5W3aRX0+K7Js0Kkuy1KEgJ86oiB_0i7ZYNMBxS9_A8znWtLA@mail.gmail.com>
 <CAJuCY5z+Axd_LRhG8n+HWYHatFi6d-cD3RWu8ey0fs=EQb7Hxg@mail.gmail.com>
Message-ID: <CAF5W3aT2mn2qB0Xe8-vzsMJqvL2zS3T1mcjjDe3=TJyGDQaBgw@mail.gmail.com>

I?m sorry... I?m new in the list, and when I figured out that the question
would suit best in the mixed model list I had already post it in general
R-help. I don?t know if there?s a way to "cancel a question"... I will take
care of it from now on.

Dear Thierry, thanks for your answer.
Yes, I am not interested in the effect of a specific farm, they simply
represent the total of farms from the region where I want to suggest the
best treatments.

I Followed your suggestions, but still have a couple of doubts,

1- May "farm" be include as a simple fixed effect or interacting with the
treatment?

m3 = glmer(resp ~ trt * farm + (1|tree_id), family = binomial, data=df)
m4 = glmer(resp ~ trt + farm + (1|tree_id), family = binomial, data=df)

?2 - ?
In case of significant
?[ trt * farm ], should I report the results for each farm??

Thanks again Thierry,

Juan Edwards


*Juan*

On Mon, Apr 24, 2017 at 4:29 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear Juan,
>
> Use unique id's for random effects variables. So each bk should only be
> present in one farm. And each tree_id should be present in only one bk. In
> case each block has different treatments then each tree_id should be unique
> to one combination of bk and trt.
>
> Farm has too few levels to be a random effects. So either model is as a
> fixed effect or drop it. In case you drop it, the information will be
> picked up by bk. Note that trt + (1|farm) is less complex than trt * farm.
>
> Assuming that you are not interested in the effect of a specific farm, you
> could use sum, polynomial or helmert contrasts for the farms. Unlike the
> default treatment contrast, these type of contrasts sum to zero. Thus the
> effect of trt will be that for the average farm instead of the reference
> farm.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2017-04-21 22:32 GMT+02:00 Juan Pablo Edwards Molina <
> edwardsmolina at gmail.com>:
>
>> I am analyzing data from 3 field experiments (farms=3) for a citrus flower
>> disease: response variable is binomial because the flower can only be
>> diseased or healthy.
>>
>> I have particular interest in comparing 5 fungicide spraying systems
>> (trt=5).
>>
>> Each farm had 4 blocks (bk=4) including 2 trees as subsamples (tree=2) in
>> which I assessed 100 flowers each one. This is a quick look of the data:
>>
>> farm      trt      bk    tree   dis   tot     <fctr>   <fctr>  <fctr>
>> <fctr> <int> <int>
>> iaras      cal      1      1     0    100
>> iaras      cal      1      2     1    100
>> iaras      cal      2      1     1    100
>> iaras      cal      2      2     3    100
>> iaras      cal      3      1     0    100
>> iaras      cal      3      2     5    100...
>>
>> The model I considered was:
>>
>> resp <- with(df, cbind(dis, tot-dis))
>>
>> m1 = glmer(resp ~ trt + (1|farm/bk) , family = binomial, data=df)
>>
>> I tested the overdispersion with the overdisp_fun() from GLMM page
>> <http://glmm.wikidot.com/faq>
>>
>>         chisq         ratio             p          logp
>>  4.191645e+02  3.742540e+00  4.804126e-37 -8.362617e+01
>>
>> As ratio (residual dev/residual df) > 1, and the p-value < 0.05, I
>> considered to add the observation level random effect (link
>> <http://r.789695.n4.nabble.com/Question-on-overdispersion-td3049898.html
>> >)
>> to deal with the overdispersion.
>>
>> farm      trt      bk    tree   dis   tot tree_id    <fctr>   <fctr>
>> <fctr> <fctr> <int> <int> <fctr>
>> iaras      cal      1      1     0    100    1
>> iaras      cal      1      2     1    100    2
>> iaras      cal      2      1     1    100    3...
>>
>> so now was added a random effect for each row (tree_id) to the model, but
>> I
>> am not sure of how to include it. This is my approach:
>>
>> m2 = glmer(resp ~ trt + (1|farm/bk) + (1|tree_id), family = binomial,
>> data=df)
>>
>> I also wonder if farm should be a fixed effect, since it has only 3
>> levels...
>>
>> m3 = glmer(resp ~ trt * farm + (1|farm:bk) + (1|tree_id), family =
>> binomial, data=df)
>>
>> I really appreciate your suggestions about my model specifications...
>>
>>
>>
>> *Juan? Edwards- - - - - - - - - - - - - - - - - - - - - - - -# PhD student
>> - ESALQ-USP/Brazil*
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>

	[[alternative HTML version deleted]]


From dakotajudo at mac.com  Mon Apr 24 15:55:01 2017
From: dakotajudo at mac.com (Peter Claussen)
Date: Mon, 24 Apr 2017 08:55:01 -0500
Subject: [R-sig-ME] GLMM for Combined experiments and overdispersed data
In-Reply-To: <CAF5W3aT2mn2qB0Xe8-vzsMJqvL2zS3T1mcjjDe3=TJyGDQaBgw@mail.gmail.com>
References: <CAF5W3aRX0+K7Js0Kkuy1KEgJ86oiB_0i7ZYNMBxS9_A8znWtLA@mail.gmail.com>
 <CAJuCY5z+Axd_LRhG8n+HWYHatFi6d-cD3RWu8ey0fs=EQb7Hxg@mail.gmail.com>
 <CAF5W3aT2mn2qB0Xe8-vzsMJqvL2zS3T1mcjjDe3=TJyGDQaBgw@mail.gmail.com>
Message-ID: <9522B3B8-9E62-41C3-A376-BEE819F3A07A@mac.com>

Juan,

I would model this as 

m3 = glmer(resp ~ trt * farm +  (1| bk/tree), family = binomial, data=df)
or
m3 = glmer(resp ~ trt * farm +  (1| bk) +  (1| tree_id), family = binomial, data=df)
(I can?t say off the top of my head if what the difference would be if you?re dealing with over-dispersion).

1. I?m assuming that block is a somewhat uniform grouping of trees, so that including block in the model gives you an estimate of spatial variability in the response, and if that is important relative to tree-to-tree variation.  

2. You will most certainly want to include trt*farm to test for treatment-by-environment interaction. If interaction is not significant, you may choose to exclude interaction from the model. If there is interaction, then you will want to examine each farm to determine if cross-over interaction present.

If your experiment is to determine the ?best? fungicide spraying system, and cross-over interaction is present, then you have no ?best? system. You might have cross-over arising because, say, system 1 ranks ?best? on farm 1, but system 2 ranks ?best? on farm 2.

There is extensive literature on the topic, mostly from the plant breeding genotype-by-environment interaction side. Some of the associated statistics implemented in the agricolae package, i.e. AMMI.

Peter

> On Apr 24, 2017, at 6:56 AM, Juan Pablo Edwards Molina <edwardsmolina at gmail.com> wrote:
> 
> I?m sorry... I?m new in the list, and when I figured out that the question
> would suit best in the mixed model list I had already post it in general
> R-help. I don?t know if there?s a way to "cancel a question"... I will take
> care of it from now on.
> 
> Dear Thierry, thanks for your answer.
> Yes, I am not interested in the effect of a specific farm, they simply
> represent the total of farms from the region where I want to suggest the
> best treatments.
> 
> I Followed your suggestions, but still have a couple of doubts,
> 
> 1- May "farm" be include as a simple fixed effect or interacting with the
> treatment?
> 
> m3 = glmer(resp ~ trt * farm + (1|tree_id), family = binomial, data=df)
> m4 = glmer(resp ~ trt + farm + (1|tree_id), family = binomial, data=df)
> 
> ?2 - ?
> In case of significant
> ?[ trt * farm ], should I report the results for each farm??
> 
> Thanks again Thierry,
> 
> Juan Edwards
> 
> 
> *Juan*
> 
> On Mon, Apr 24, 2017 at 4:29 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
> 
>> Dear Juan,
>> 
>> Use unique id's for random effects variables. So each bk should only be
>> present in one farm. And each tree_id should be present in only one bk. In
>> case each block has different treatments then each tree_id should be unique
>> to one combination of bk and trt.
>> 
>> Farm has too few levels to be a random effects. So either model is as a
>> fixed effect or drop it. In case you drop it, the information will be
>> picked up by bk. Note that trt + (1|farm) is less complex than trt * farm.
>> 
>> Assuming that you are not interested in the effect of a specific farm, you
>> could use sum, polynomial or helmert contrasts for the farms. Unlike the
>> default treatment contrast, these type of contrasts sum to zero. Thus the
>> effect of trt will be that for the average farm instead of the reference
>> farm.
>> 
>> Best regards,
>> 
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
>> Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>> 
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>> 
>> 2017-04-21 22:32 GMT+02:00 Juan Pablo Edwards Molina <
>> edwardsmolina at gmail.com>:
>> 
>>> I am analyzing data from 3 field experiments (farms=3) for a citrus flower
>>> disease: response variable is binomial because the flower can only be
>>> diseased or healthy.
>>> 
>>> I have particular interest in comparing 5 fungicide spraying systems
>>> (trt=5).
>>> 
>>> Each farm had 4 blocks (bk=4) including 2 trees as subsamples (tree=2) in
>>> which I assessed 100 flowers each one. This is a quick look of the data:
>>> 
>>> farm      trt      bk    tree   dis   tot     <fctr>   <fctr>  <fctr>
>>> <fctr> <int> <int>
>>> iaras      cal      1      1     0    100
>>> iaras      cal      1      2     1    100
>>> iaras      cal      2      1     1    100
>>> iaras      cal      2      2     3    100
>>> iaras      cal      3      1     0    100
>>> iaras      cal      3      2     5    100...
>>> 
>>> The model I considered was:
>>> 
>>> resp <- with(df, cbind(dis, tot-dis))
>>> 
>>> m1 = glmer(resp ~ trt + (1|farm/bk) , family = binomial, data=df)
>>> 
>>> I tested the overdispersion with the overdisp_fun() from GLMM page
>>> <http://glmm.wikidot.com/faq>
>>> 
>>>        chisq         ratio             p          logp
>>> 4.191645e+02  3.742540e+00  4.804126e-37 -8.362617e+01
>>> 
>>> As ratio (residual dev/residual df) > 1, and the p-value < 0.05, I
>>> considered to add the observation level random effect (link
>>> <http://r.789695.n4.nabble.com/Question-on-overdispersion-td3049898.html
>>>> )
>>> to deal with the overdispersion.
>>> 
>>> farm      trt      bk    tree   dis   tot tree_id    <fctr>   <fctr>
>>> <fctr> <fctr> <int> <int> <fctr>
>>> iaras      cal      1      1     0    100    1
>>> iaras      cal      1      2     1    100    2
>>> iaras      cal      2      1     1    100    3...
>>> 
>>> so now was added a random effect for each row (tree_id) to the model, but
>>> I
>>> am not sure of how to include it. This is my approach:
>>> 
>>> m2 = glmer(resp ~ trt + (1|farm/bk) + (1|tree_id), family = binomial,
>>> data=df)
>>> 
>>> I also wonder if farm should be a fixed effect, since it has only 3
>>> levels...
>>> 
>>> m3 = glmer(resp ~ trt * farm + (1|farm:bk) + (1|tree_id), family =
>>> binomial, data=df)
>>> 
>>> I really appreciate your suggestions about my model specifications...
>>> 
>>> 
>>> 
>>> *Juan? Edwards- - - - - - - - - - - - - - - - - - - - - - - -# PhD student
>>> - ESALQ-USP/Brazil*
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From thierry.onkelinx at inbo.be  Mon Apr 24 16:46:13 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 24 Apr 2017 16:46:13 +0200
Subject: [R-sig-ME] GLMM for Combined experiments and overdispersed data
In-Reply-To: <9522B3B8-9E62-41C3-A376-BEE819F3A07A@mac.com>
References: <CAF5W3aRX0+K7Js0Kkuy1KEgJ86oiB_0i7ZYNMBxS9_A8znWtLA@mail.gmail.com>
 <CAJuCY5z+Axd_LRhG8n+HWYHatFi6d-cD3RWu8ey0fs=EQb7Hxg@mail.gmail.com>
 <CAF5W3aT2mn2qB0Xe8-vzsMJqvL2zS3T1mcjjDe3=TJyGDQaBgw@mail.gmail.com>
 <9522B3B8-9E62-41C3-A376-BEE819F3A07A@mac.com>
Message-ID: <CAJuCY5yty3kDY9FHAsP1GYky7RM410v4MMctwVPqvNc62=tKvg@mail.gmail.com>

Dear Peter,

Both models will yield identical results in case tree_id uses unique codes
over the blocks.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-04-24 15:55 GMT+02:00 Peter Claussen <dakotajudo at mac.com>:

> Juan,
>
> I would model this as
>
> m3 = glmer(resp ~ trt * farm +  (1| bk/tree), family = binomial, data=df)
> or
> m3 = glmer(resp ~ trt * farm +  (1| bk) +  (1| tree_id), family =
> binomial, data=df)
> (I can?t say off the top of my head if what the difference would be if
> you?re dealing with over-dispersion).
>
> 1. I?m assuming that block is a somewhat uniform grouping of trees, so
> that including block in the model gives you an estimate of spatial
> variability in the response, and if that is important relative to
> tree-to-tree variation.
>
> 2. You will most certainly want to include trt*farm to test for
> treatment-by-environment interaction. If interaction is not significant,
> you may choose to exclude interaction from the model. If there is
> interaction, then you will want to examine each farm to determine if
> cross-over interaction present.
>
> If your experiment is to determine the ?best? fungicide spraying system,
> and cross-over interaction is present, then you have no ?best? system. You
> might have cross-over arising because, say, system 1 ranks ?best? on farm
> 1, but system 2 ranks ?best? on farm 2.
>
> There is extensive literature on the topic, mostly from the plant breeding
> genotype-by-environment interaction side. Some of the associated statistics
> implemented in the agricolae package, i.e. AMMI.
>
> Peter
>
> > On Apr 24, 2017, at 6:56 AM, Juan Pablo Edwards Molina <
> edwardsmolina at gmail.com> wrote:
> >
> > I?m sorry... I?m new in the list, and when I figured out that the
> question
> > would suit best in the mixed model list I had already post it in general
> > R-help. I don?t know if there?s a way to "cancel a question"... I will
> take
> > care of it from now on.
> >
> > Dear Thierry, thanks for your answer.
> > Yes, I am not interested in the effect of a specific farm, they simply
> > represent the total of farms from the region where I want to suggest the
> > best treatments.
> >
> > I Followed your suggestions, but still have a couple of doubts,
> >
> > 1- May "farm" be include as a simple fixed effect or interacting with the
> > treatment?
> >
> > m3 = glmer(resp ~ trt * farm + (1|tree_id), family = binomial, data=df)
> > m4 = glmer(resp ~ trt + farm + (1|tree_id), family = binomial, data=df)
> >
> > ?2 - ?
> > In case of significant
> > ?[ trt * farm ], should I report the results for each farm??
> >
> > Thanks again Thierry,
> >
> > Juan Edwards
> >
> >
> > *Juan*
> >
> > On Mon, Apr 24, 2017 at 4:29 AM, Thierry Onkelinx <
> thierry.onkelinx at inbo.be>
> > wrote:
> >
> >> Dear Juan,
> >>
> >> Use unique id's for random effects variables. So each bk should only be
> >> present in one farm. And each tree_id should be present in only one bk.
> In
> >> case each block has different treatments then each tree_id should be
> unique
> >> to one combination of bk and trt.
> >>
> >> Farm has too few levels to be a random effects. So either model is as a
> >> fixed effect or drop it. In case you drop it, the information will be
> >> picked up by bk. Note that trt + (1|farm) is less complex than trt *
> farm.
> >>
> >> Assuming that you are not interested in the effect of a specific farm,
> you
> >> could use sum, polynomial or helmert contrasts for the farms. Unlike the
> >> default treatment contrast, these type of contrasts sum to zero. Thus
> the
> >> effect of trt will be that for the average farm instead of the reference
> >> farm.
> >>
> >> Best regards,
> >>
> >> ir. Thierry Onkelinx
> >> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and
> >> Forest
> >> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> >> Kliniekstraat 25
> >> 1070 Anderlecht
> >> Belgium
> >>
> >> To call in the statistician after the experiment is done may be no more
> >> than asking him to perform a post-mortem examination: he may be able to
> say
> >> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> >> The plural of anecdote is not data. ~ Roger Brinner
> >> The combination of some data and an aching desire for an answer does not
> >> ensure that a reasonable answer can be extracted from a given body of
> data.
> >> ~ John Tukey
> >>
> >> 2017-04-21 22:32 GMT+02:00 Juan Pablo Edwards Molina <
> >> edwardsmolina at gmail.com>:
> >>
> >>> I am analyzing data from 3 field experiments (farms=3) for a citrus
> flower
> >>> disease: response variable is binomial because the flower can only be
> >>> diseased or healthy.
> >>>
> >>> I have particular interest in comparing 5 fungicide spraying systems
> >>> (trt=5).
> >>>
> >>> Each farm had 4 blocks (bk=4) including 2 trees as subsamples (tree=2)
> in
> >>> which I assessed 100 flowers each one. This is a quick look of the
> data:
> >>>
> >>> farm      trt      bk    tree   dis   tot     <fctr>   <fctr>  <fctr>
> >>> <fctr> <int> <int>
> >>> iaras      cal      1      1     0    100
> >>> iaras      cal      1      2     1    100
> >>> iaras      cal      2      1     1    100
> >>> iaras      cal      2      2     3    100
> >>> iaras      cal      3      1     0    100
> >>> iaras      cal      3      2     5    100...
> >>>
> >>> The model I considered was:
> >>>
> >>> resp <- with(df, cbind(dis, tot-dis))
> >>>
> >>> m1 = glmer(resp ~ trt + (1|farm/bk) , family = binomial, data=df)
> >>>
> >>> I tested the overdispersion with the overdisp_fun() from GLMM page
> >>> <http://glmm.wikidot.com/faq>
> >>>
> >>>        chisq         ratio             p          logp
> >>> 4.191645e+02  3.742540e+00  4.804126e-37 -8.362617e+01
> >>>
> >>> As ratio (residual dev/residual df) > 1, and the p-value < 0.05, I
> >>> considered to add the observation level random effect (link
> >>> <http://r.789695.n4.nabble.com/Question-on-
> overdispersion-td3049898.html
> >>>> )
> >>> to deal with the overdispersion.
> >>>
> >>> farm      trt      bk    tree   dis   tot tree_id    <fctr>   <fctr>
> >>> <fctr> <fctr> <int> <int> <fctr>
> >>> iaras      cal      1      1     0    100    1
> >>> iaras      cal      1      2     1    100    2
> >>> iaras      cal      2      1     1    100    3...
> >>>
> >>> so now was added a random effect for each row (tree_id) to the model,
> but
> >>> I
> >>> am not sure of how to include it. This is my approach:
> >>>
> >>> m2 = glmer(resp ~ trt + (1|farm/bk) + (1|tree_id), family = binomial,
> >>> data=df)
> >>>
> >>> I also wonder if farm should be a fixed effect, since it has only 3
> >>> levels...
> >>>
> >>> m3 = glmer(resp ~ trt * farm + (1|farm:bk) + (1|tree_id), family =
> >>> binomial, data=df)
> >>>
> >>> I really appreciate your suggestions about my model specifications...
> >>>
> >>>
> >>>
> >>> *Juan? Edwards- - - - - - - - - - - - - - - - - - - - - - - -# PhD
> student
> >>> - ESALQ-USP/Brazil*
> >>>
> >>>        [[alternative HTML version deleted]]
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From edwardsmolina at gmail.com  Mon Apr 24 17:27:36 2017
From: edwardsmolina at gmail.com (Juan Pablo Edwards Molina)
Date: Mon, 24 Apr 2017 12:27:36 -0300
Subject: [R-sig-ME] GLMM for Combined experiments and overdispersed data
In-Reply-To: <CAJuCY5yty3kDY9FHAsP1GYky7RM410v4MMctwVPqvNc62=tKvg@mail.gmail.com>
References: <CAF5W3aRX0+K7Js0Kkuy1KEgJ86oiB_0i7ZYNMBxS9_A8znWtLA@mail.gmail.com>
 <CAJuCY5z+Axd_LRhG8n+HWYHatFi6d-cD3RWu8ey0fs=EQb7Hxg@mail.gmail.com>
 <CAF5W3aT2mn2qB0Xe8-vzsMJqvL2zS3T1mcjjDe3=TJyGDQaBgw@mail.gmail.com>
 <9522B3B8-9E62-41C3-A376-BEE819F3A07A@mac.com>
 <CAJuCY5yty3kDY9FHAsP1GYky7RM410v4MMctwVPqvNc62=tKvg@mail.gmail.com>
Message-ID: <CAF5W3aQQPLL29Ou74TB3QY43GFifYRnGxJe_QOCc9NMZT1HNfw@mail.gmail.com>

Yes, tree_id uses unique code over blocks and farms: ?each bk is
only present in one farm and each tree is present in only one bk. (tree_id
structure: farm_bk_tree)

By this way the model can handle the overdispersion (If I'm not mistaken)

Thank you all,

*Juan*

On Mon, Apr 24, 2017 at 11:46 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be
> wrote:

> Dear Peter,
>
> Both models will yield identical results in case tree_id uses unique codes
> over the blocks.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2017-04-24 15:55 GMT+02:00 Peter Claussen <dakotajudo at mac.com>:
>
>> Juan,
>>
>> I would model this as
>>
>> m3 = glmer(resp ~ trt * farm +  (1| bk/tree), family = binomial, data=df)
>> or
>> m3 = glmer(resp ~ trt * farm +  (1| bk) +  (1| tree_id), family =
>> binomial, data=df)
>> (I can?t say off the top of my head if what the difference would be if
>> you?re dealing with over-dispersion).
>>
>> 1. I?m assuming that block is a somewhat uniform grouping of trees, so
>> that including block in the model gives you an estimate of spatial
>> variability in the response, and if that is important relative to
>> tree-to-tree variation.
>>
>> 2. You will most certainly want to include trt*farm to test for
>> treatment-by-environment interaction. If interaction is not significant,
>> you may choose to exclude interaction from the model. If there is
>> interaction, then you will want to examine each farm to determine if
>> cross-over interaction present.
>>
>> If your experiment is to determine the ?best? fungicide spraying system,
>> and cross-over interaction is present, then you have no ?best? system. You
>> might have cross-over arising because, say, system 1 ranks ?best? on farm
>> 1, but system 2 ranks ?best? on farm 2.
>>
>> There is extensive literature on the topic, mostly from the plant
>> breeding genotype-by-environment interaction side. Some of the associated
>> statistics implemented in the agricolae package, i.e. AMMI.
>>
>> Peter
>>
>> > On Apr 24, 2017, at 6:56 AM, Juan Pablo Edwards Molina <
>> edwardsmolina at gmail.com> wrote:
>> >
>> > I?m sorry... I?m new in the list, and when I figured out that the
>> question
>> > would suit best in the mixed model list I had already post it in general
>> > R-help. I don?t know if there?s a way to "cancel a question"... I will
>> take
>> > care of it from now on.
>> >
>> > Dear Thierry, thanks for your answer.
>> > Yes, I am not interested in the effect of a specific farm, they simply
>> > represent the total of farms from the region where I want to suggest the
>> > best treatments.
>> >
>> > I Followed your suggestions, but still have a couple of doubts,
>> >
>> > 1- May "farm" be include as a simple fixed effect or interacting with
>> the
>> > treatment?
>> >
>> > m3 = glmer(resp ~ trt * farm + (1|tree_id), family = binomial, data=df)
>> > m4 = glmer(resp ~ trt + farm + (1|tree_id), family = binomial, data=df)
>> >
>> > ?2 - ?
>> > In case of significant
>> > ?[ trt * farm ], should I report the results for each farm??
>> >
>> > Thanks again Thierry,
>> >
>> > Juan Edwards
>> >
>> >
>> > *Juan*
>> >
>> > On Mon, Apr 24, 2017 at 4:29 AM, Thierry Onkelinx <
>> thierry.onkelinx at inbo.be>
>> > wrote:
>> >
>> >> Dear Juan,
>> >>
>> >> Use unique id's for random effects variables.
>> ??
>> So each bk should only be
>> >> present in one farm. And each tree_id should be present in only one
>> bk. In
>> >> case each block has different treatments then each tree_id should be
>> unique
>> >> to one combination of bk and trt.
>> >>
>> >> Farm has too few levels to be a random effects. So either model is as a
>> >> fixed effect or drop it. In case you drop it, the information will be
>> >> picked up by bk. Note that trt + (1|farm) is less complex than trt *
>> farm.
>> >>
>> >> Assuming that you are not interested in the effect of a specific farm,
>> you
>> >> could use sum, polynomial or helmert contrasts for the farms. Unlike
>> the
>> >> default treatment contrast, these type of contrasts sum to zero. Thus
>> the
>> >> effect of trt will be that for the average farm instead of the
>> reference
>> >> farm.
>> >>
>> >> Best regards,
>> >>
>> >> ir. Thierry Onkelinx
>> >> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and
>> >> Forest
>> >> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> >> Kliniekstraat 25
>> >> 1070 Anderlecht
>> >> Belgium
>> >>
>> >> To call in the statistician after the experiment is done may be no more
>> >> than asking him to perform a post-mortem examination: he may be able
>> to say
>> >> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> >> The plural of anecdote is not data. ~ Roger Brinner
>> >> The combination of some data and an aching desire for an answer does
>> not
>> >> ensure that a reasonable answer can be extracted from a given body of
>> data.
>> >> ~ John Tukey
>> >>
>> >> 2017-04-21 22:32 GMT+02:00 Juan Pablo Edwards Molina <
>> >> edwardsmolina at gmail.com>:
>> >>
>> >>> I am analyzing data from 3 field experiments (farms=3) for a citrus
>> flower
>> >>> disease: response variable is binomial because the flower can only be
>> >>> diseased or healthy.
>> >>>
>> >>> I have particular interest in comparing 5 fungicide spraying systems
>> >>> (trt=5).
>> >>>
>> >>> Each farm had 4 blocks (bk=4) including 2 trees as subsamples
>> (tree=2) in
>> >>> which I assessed 100 flowers each one. This is a quick look of the
>> data:
>> >>>
>> >>> farm      trt      bk    tree   dis   tot     <fctr>   <fctr>  <fctr>
>> >>> <fctr> <int> <int>
>> >>> iaras      cal      1      1     0    100
>> >>> iaras      cal      1      2     1    100
>> >>> iaras      cal      2      1     1    100
>> >>> iaras      cal      2      2     3    100
>> >>> iaras      cal      3      1     0    100
>> >>> iaras      cal      3      2     5    100...
>> >>>
>> >>> The model I considered was:
>> >>>
>> >>> resp <- with(df, cbind(dis, tot-dis))
>> >>>
>> >>> m1 = glmer(resp ~ trt + (1|farm/bk) , family = binomial, data=df)
>> >>>
>> >>> I tested the overdispersion with the overdisp_fun() from GLMM page
>> >>> <http://glmm.wikidot.com/faq>
>> >>>
>> >>>        chisq         ratio             p          logp
>> >>> 4.191645e+02  3.742540e+00  4.804126e-37 -8.362617e+01
>> >>>
>> >>> As ratio (residual dev/residual df) > 1, and the p-value < 0.05, I
>> >>> considered to add the observation level random effect (link
>> >>> <http://r.789695.n4.nabble.com/Question-on-overdispersion-td
>> 3049898.html
>> >>>> )
>> >>> to deal with the overdispersion.
>> >>>
>> >>> farm      trt      bk    tree   dis   tot tree_id    <fctr>   <fctr>
>> >>> <fctr> <fctr> <int> <int> <fctr>
>> >>> iaras      cal      1      1     0    100    1
>> >>> iaras      cal      1      2     1    100    2
>> >>> iaras      cal      2      1     1    100    3...
>> >>>
>> >>> so now was added a random effect for each row (tree_id) to the model,
>> but
>> >>> I
>> >>> am not sure of how to include it. This is my approach:
>> >>>
>> >>> m2 = glmer(resp ~ trt + (1|farm/bk) + (1|tree_id), family = binomial,
>> >>> data=df)
>> >>>
>> >>> I also wonder if farm should be a fixed effect, since it has only 3
>> >>> levels...
>> >>>
>> >>> m3 = glmer(resp ~ trt * farm + (1|farm:bk) + (1|tree_id), family =
>> >>> binomial, data=df)
>> >>>
>> >>> I really appreciate your suggestions about my model specifications...
>> >>>
>> >>>
>> >>>
>> >>> *Juan? Edwards- - - - - - - - - - - - - - - - - - - - - - - -# PhD
>> student
>> >>> - ESALQ-USP/Brazil*
>> >>>
>> >>>        [[alternative HTML version deleted]]
>> >>>
>> >>> _______________________________________________
>> >>> R-sig-mixed-models at r-project.org mailing list
>> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >>
>> >>
>> >>
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>

	[[alternative HTML version deleted]]


From said_lect06 at yahoo.com  Tue Apr 25 04:58:14 2017
From: said_lect06 at yahoo.com (Said Ali Shah)
Date: Tue, 25 Apr 2017 02:58:14 +0000 (UTC)
Subject: [R-sig-ME] Hi listers
References: <748020203.8771905.1493089094920.ref@mail.yahoo.com>
Message-ID: <748020203.8771905.1493089094920@mail.yahoo.com>

i am conducting a simulation study regarding sample size using multilevel models for longitudinal design, and want to see the effect of non-normal level-II errors now the question is?1. whether i should generate the level-II errors from normal distribution after specifying parameters which are required for the model and then transform these normal errors to non-normal errors? if yes then how to transform them to exponential and log-normal distribution2. i should generate these errors separately from normal as well as from exponential and log normal distributions. keep in mind that both results i.e., for normal and non-normal errors are required.?Thanks in advance ? ? ??Regards,

Said Ali Shah




	[[alternative HTML version deleted]]


From edwardsmolina at gmail.com  Tue Apr 25 15:40:03 2017
From: edwardsmolina at gmail.com (Juan Pablo Edwards Molina)
Date: Tue, 25 Apr 2017 10:40:03 -0300
Subject: [R-sig-ME] GLMM for Combined experiments and overdispersed data
In-Reply-To: <CAJuCY5yty3kDY9FHAsP1GYky7RM410v4MMctwVPqvNc62=tKvg@mail.gmail.com>
References: <CAF5W3aRX0+K7Js0Kkuy1KEgJ86oiB_0i7ZYNMBxS9_A8znWtLA@mail.gmail.com>
 <CAJuCY5z+Axd_LRhG8n+HWYHatFi6d-cD3RWu8ey0fs=EQb7Hxg@mail.gmail.com>
 <CAF5W3aT2mn2qB0Xe8-vzsMJqvL2zS3T1mcjjDe3=TJyGDQaBgw@mail.gmail.com>
 <9522B3B8-9E62-41C3-A376-BEE819F3A07A@mac.com>
 <CAJuCY5yty3kDY9FHAsP1GYky7RM410v4MMctwVPqvNc62=tKvg@mail.gmail.com>
Message-ID: <CAF5W3aRjrnCmjVRFCk5OdOnVYwtxcgkfWDb9Xf03DjYAq6KaHA@mail.gmail.com>

Thierry, sorry to bother you again...
I tried to follow your suggestion and I did the herlmert contrasts with
lsmeans package.

dinc <- within(dinc, { tree_id <- as.factor(interaction(farm, trt, bk,
tree)) })

resp1 <- with(dinc, cbind(dis, tot-dis))

m0 = glmer(resp1 ~ trt + farm + (1|tree_id), family = binomial, data=dinc)

> summary(m0)
Generalized linear mixed model fit by maximum likelihood (Laplace
Approximation) [
glmerMod]
 Family: binomial  ( logit )
Formula: resp1 ~ trt + farm + (1 | tree_id)
   Data: dinc

     AIC      BIC   logLik deviance df.resid
   521.5    543.8   -252.7    505.5      112

Scaled residuals:
     Min       1Q   Median       3Q      Max
-0.90445 -0.51114 -0.00572  0.31456  1.04667

Random effects:
 Groups  Name        Variance Std.Dev.
 tree_id (Intercept) 1.028    1.014
Number of obs: 120, groups:  tree_id, 120

Fixed effects:
            Estimate Std. Error z value Pr(>|z|)
(Intercept) -4.87786    0.37604 -12.972  < 2e-16 ***
trtG10      -0.06738    0.49125  -0.137  0.89090
trtG15       0.90620    0.44435   2.039  0.04141 *
trtG20       1.13733    0.43920   2.590  0.00961 **
trtControl   5.10202    0.41215  12.379  < 2e-16 ***
farmstacruz -0.80155    0.30294  -2.646  0.00815 **
farmtaqua   -0.84738    0.30659  -2.764  0.00571 **
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
            (Intr) trtG10 trtG15 trtG20 trtCnt frmstc
trtG10      -0.635
trtG15      -0.710  0.538
trtG20      -0.720  0.546  0.604
trtControl  -0.763  0.571  0.650  0.651
farmstacruz -0.300  0.022 -0.015  0.010 -0.081
farmtaqua   -0.301  0.012  0.004  0.017 -0.083  0.441

### Setting up a custom contrast function

helmert.lsmc <- function(levs, ...) {
  M <- as.data.frame(contr.helmert(levs))
  names(M) <- paste(levs[-1],"vs calendar")
  attr(M, "desc") <- "Helmert contrasts"
  M
}

> lsmeans(m0, helmert ~ trt, type = "response")

$lsmeans
 trt             prob          SE df   asymp.LCL   asymp.UCL
 Calendar 0.004374833 0.001541432 NA 0.002191201 0.008715549
 G10      0.004090935 0.001498922 NA 0.001993307 0.008377443
 G15      0.010757825 0.003091538 NA 0.006116214 0.018855141
 G20      0.013517346 0.003832360 NA 0.007740919 0.023502164
 Control  0.419339074 0.051564118 NA 0.322885163 0.522377507

Results are averaged over the levels of: farm
Confidence level used: 0.95
Intervals are back-transformed from the logit scale

$contrasts
 contrast              odds.ratio           SE df z.ratio p.value
 G10 vs calendar     9.348400e-01 4.592373e-01 NA  -0.137  0.8909
 G15 vs calendar     6.552019e+00 4.909975e+00 NA   2.508  0.0121
 G20 vs calendar     1.310737e+01 1.307704e+01 NA   2.579  0.0099
 Control vs calendar 1.011296e+08 1.124089e+08 NA  16.582  <.0001

Results are averaged over the levels of: farm
Tests are performed on the log odds ratio scale

## Do you think it's correct, if I consider trt calendar as the reference
to test my other treatments?

Thanks!

Juan

*Juan*

On Mon, Apr 24, 2017 at 11:46 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be
> wrote:

> Dear Peter,
>
> Both models will yield identical results in case tree_id uses unique codes
> over the blocks.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2017-04-24 15:55 GMT+02:00 Peter Claussen <dakotajudo at mac.com>:
>
>> Juan,
>>
>> I would model this as
>>
>> m3 = glmer(resp ~ trt * farm +  (1| bk/tree), family = binomial, data=df)
>> or
>> m3 = glmer(resp ~ trt * farm +  (1| bk) +  (1| tree_id), family =
>> binomial, data=df)
>> (I can?t say off the top of my head if what the difference would be if
>> you?re dealing with over-dispersion).
>>
>> 1. I?m assuming that block is a somewhat uniform grouping of trees, so
>> that including block in the model gives you an estimate of spatial
>> variability in the response, and if that is important relative to
>> tree-to-tree variation.
>>
>> 2. You will most certainly want to include trt*farm to test for
>> treatment-by-environment interaction. If interaction is not significant,
>> you may choose to exclude interaction from the model. If there is
>> interaction, then you will want to examine each farm to determine if
>> cross-over interaction present.
>>
>> If your experiment is to determine the ?best? fungicide spraying system,
>> and cross-over interaction is present, then you have no ?best? system. You
>> might have cross-over arising because, say, system 1 ranks ?best? on farm
>> 1, but system 2 ranks ?best? on farm 2.
>>
>> There is extensive literature on the topic, mostly from the plant
>> breeding genotype-by-environment interaction side. Some of the associated
>> statistics implemented in the agricolae package, i.e. AMMI.
>>
>> Peter
>>
>> > On Apr 24, 2017, at 6:56 AM, Juan Pablo Edwards Molina <
>> edwardsmolina at gmail.com> wrote:
>> >
>> > I?m sorry... I?m new in the list, and when I figured out that the
>> question
>> > would suit best in the mixed model list I had already post it in general
>> > R-help. I don?t know if there?s a way to "cancel a question"... I will
>> take
>> > care of it from now on.
>> >
>> > Dear Thierry, thanks for your answer.
>> > Yes, I am not interested in the effect of a specific farm, they simply
>> > represent the total of farms from the region where I want to suggest the
>> > best treatments.
>> >
>> > I Followed your suggestions, but still have a couple of doubts,
>> >
>> > 1- May "farm" be include as a simple fixed effect or interacting with
>> the
>> > treatment?
>> >
>> > m3 = glmer(resp ~ trt * farm + (1|tree_id), family = binomial, data=df)
>> > m4 = glmer(resp ~ trt + farm + (1|tree_id), family = binomial, data=df)
>> >
>> > ?2 - ?
>> > In case of significant
>> > ?[ trt * farm ], should I report the results for each farm??
>> >
>> > Thanks again Thierry,
>> >
>> > Juan Edwards
>> >
>> >
>> > *Juan*
>> >
>> > On Mon, Apr 24, 2017 at 4:29 AM, Thierry Onkelinx <
>> thierry.onkelinx at inbo.be>
>> > wrote:
>> >
>> >> Dear Juan,
>> >>
>> >> Use unique id's for random effects variables. So each bk should only be
>> >> present in one farm. And each tree_id should be present in only one
>> bk. In
>> >> case each block has different treatments then each tree_id should be
>> unique
>> >> to one combination of bk and trt.
>> >>
>> >> Farm has too few levels to be a random effects. So either model is as a
>> >> fixed effect or drop it. In case you drop it, the information will be
>> >> picked up by bk. Note that trt + (1|farm) is less complex than trt *
>> farm.
>> >>
>> >> Assuming that you are not interested in the effect of a specific farm,
>> you
>> >> could use sum, polynomial or helmert contrasts for the farms. Unlike
>> the
>> >> default treatment contrast, these type of contrasts sum to zero. Thus
>> the
>> >> effect of trt will be that for the average farm instead of the
>> reference
>> >> farm.
>> >>
>> >> Best regards,
>> >>
>> >> ir. Thierry Onkelinx
>> >> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and
>> >> Forest
>> >> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> >> Kliniekstraat 25
>> >> 1070 Anderlecht
>> >> Belgium
>> >>
>> >> To call in the statistician after the experiment is done may be no more
>> >> than asking him to perform a post-mortem examination: he may be able
>> to say
>> >> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> >> The plural of anecdote is not data. ~ Roger Brinner
>> >> The combination of some data and an aching desire for an answer does
>> not
>> >> ensure that a reasonable answer can be extracted from a given body of
>> data.
>> >> ~ John Tukey
>> >>
>> >> 2017-04-21 22:32 GMT+02:00 Juan Pablo Edwards Molina <
>> >> edwardsmolina at gmail.com>:
>> >>
>> >>> I am analyzing data from 3 field experiments (farms=3) for a citrus
>> flower
>> >>> disease: response variable is binomial because the flower can only be
>> >>> diseased or healthy.
>> >>>
>> >>> I have particular interest in comparing 5 fungicide spraying systems
>> >>> (trt=5).
>> >>>
>> >>> Each farm had 4 blocks (bk=4) including 2 trees as subsamples
>> (tree=2) in
>> >>> which I assessed 100 flowers each one. This is a quick look of the
>> data:
>> >>>
>> >>> farm      trt      bk    tree   dis   tot     <fctr>   <fctr>  <fctr>
>> >>> <fctr> <int> <int>
>> >>> iaras      cal      1      1     0    100
>> >>> iaras      cal      1      2     1    100
>> >>> iaras      cal      2      1     1    100
>> >>> iaras      cal      2      2     3    100
>> >>> iaras      cal      3      1     0    100
>> >>> iaras      cal      3      2     5    100...
>> >>>
>> >>> The model I considered was:
>> >>>
>> >>> resp <- with(df, cbind(dis, tot-dis))
>> >>>
>> >>> m1 = glmer(resp ~ trt + (1|farm/bk) , family = binomial, data=df)
>> >>>
>> >>> I tested the overdispersion with the overdisp_fun() from GLMM page
>> >>> <http://glmm.wikidot.com/faq>
>> >>>
>> >>>        chisq         ratio             p          logp
>> >>> 4.191645e+02  3.742540e+00  4.804126e-37 -8.362617e+01
>> >>>
>> >>> As ratio (residual dev/residual df) > 1, and the p-value < 0.05, I
>> >>> considered to add the observation level random effect (link
>> >>> <http://r.789695.n4.nabble.com/Question-on-overdispersion-
>> td3049898.html
>> >>>> )
>> >>> to deal with the overdispersion.
>> >>>
>> >>> farm      trt      bk    tree   dis   tot tree_id    <fctr>   <fctr>
>> >>> <fctr> <fctr> <int> <int> <fctr>
>> >>> iaras      cal      1      1     0    100    1
>> >>> iaras      cal      1      2     1    100    2
>> >>> iaras      cal      2      1     1    100    3...
>> >>>
>> >>> so now was added a random effect for each row (tree_id) to the model,
>> but
>> >>> I
>> >>> am not sure of how to include it. This is my approach:
>> >>>
>> >>> m2 = glmer(resp ~ trt + (1|farm/bk) + (1|tree_id), family = binomial,
>> >>> data=df)
>> >>>
>> >>> I also wonder if farm should be a fixed effect, since it has only 3
>> >>> levels...
>> >>>
>> >>> m3 = glmer(resp ~ trt * farm + (1|farm:bk) + (1|tree_id), family =
>> >>> binomial, data=df)
>> >>>
>> >>> I really appreciate your suggestions about my model specifications...
>> >>>
>> >>>
>> >>>
>> >>> *Juan? Edwards- - - - - - - - - - - - - - - - - - - - - - - -# PhD
>> student
>> >>> - ESALQ-USP/Brazil*
>> >>>
>> >>>        [[alternative HTML version deleted]]
>> >>>
>> >>> _______________________________________________
>> >>> R-sig-mixed-models at r-project.org mailing list
>> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >>
>> >>
>> >>
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Apr 25 16:12:56 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 25 Apr 2017 16:12:56 +0200
Subject: [R-sig-ME] GLMM for Combined experiments and overdispersed data
In-Reply-To: <CAF5W3aRjrnCmjVRFCk5OdOnVYwtxcgkfWDb9Xf03DjYAq6KaHA@mail.gmail.com>
References: <CAF5W3aRX0+K7Js0Kkuy1KEgJ86oiB_0i7ZYNMBxS9_A8znWtLA@mail.gmail.com>
 <CAJuCY5z+Axd_LRhG8n+HWYHatFi6d-cD3RWu8ey0fs=EQb7Hxg@mail.gmail.com>
 <CAF5W3aT2mn2qB0Xe8-vzsMJqvL2zS3T1mcjjDe3=TJyGDQaBgw@mail.gmail.com>
 <9522B3B8-9E62-41C3-A376-BEE819F3A07A@mac.com>
 <CAJuCY5yty3kDY9FHAsP1GYky7RM410v4MMctwVPqvNc62=tKvg@mail.gmail.com>
 <CAF5W3aRjrnCmjVRFCk5OdOnVYwtxcgkfWDb9Xf03DjYAq6KaHA@mail.gmail.com>
Message-ID: <CAJuCY5ziyAe2A5FrZFN+umzfCrCzLvGs=PY5nmq1PqE3Rd1+UQ@mail.gmail.com>

The effects of the baseline and control are very large. Do you have quasi
complete separation? All failures at the baseline and all successes at the
control?

Op 25 apr. 2017 3:40 p.m. schreef "Juan Pablo Edwards Molina" <
edwardsmolina at gmail.com>:

Thierry, sorry to bother you again...
I tried to follow your suggestion and I did the herlmert contrasts with
lsmeans package.

dinc <- within(dinc, { tree_id <- as.factor(interaction(farm, trt, bk,
tree)) })

resp1 <- with(dinc, cbind(dis, tot-dis))

m0 = glmer(resp1 ~ trt + farm + (1|tree_id), family = binomial, data=dinc)

> summary(m0)
Generalized linear mixed model fit by maximum likelihood (Laplace
Approximation) [
glmerMod]
 Family: binomial  ( logit )
Formula: resp1 ~ trt + farm + (1 | tree_id)
   Data: dinc

     AIC      BIC   logLik deviance df.resid
   521.5    543.8   -252.7    505.5      112

Scaled residuals:
     Min       1Q   Median       3Q      Max
-0.90445 -0.51114 -0.00572  0.31456  1.04667

Random effects:
 Groups  Name        Variance Std.Dev.
 tree_id (Intercept) 1.028    1.014
Number of obs: 120, groups:  tree_id, 120

Fixed effects:
            Estimate Std. Error z value Pr(>|z|)
(Intercept) -4.87786    0.37604 -12.972  < 2e-16 ***
trtG10      -0.06738    0.49125  -0.137  0.89090
trtG15       0.90620    0.44435   2.039  0.04141 *
trtG20       1.13733    0.43920   2.590  0.00961 **
trtControl   5.10202    0.41215  12.379  < 2e-16 ***
farmstacruz -0.80155    0.30294  -2.646  0.00815 **
farmtaqua   -0.84738    0.30659  -2.764  0.00571 **
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
            (Intr) trtG10 trtG15 trtG20 trtCnt frmstc
trtG10      -0.635
trtG15      -0.710  0.538
trtG20      -0.720  0.546  0.604
trtControl  -0.763  0.571  0.650  0.651
farmstacruz -0.300  0.022 -0.015  0.010 -0.081
farmtaqua   -0.301  0.012  0.004  0.017 -0.083  0.441

### Setting up a custom contrast function

helmert.lsmc <- function(levs, ...) {
  M <- as.data.frame(contr.helmert(levs))
  names(M) <- paste(levs[-1],"vs calendar")
  attr(M, "desc") <- "Helmert contrasts"
  M
}

> lsmeans(m0, helmert ~ trt, type = "response")

$lsmeans
 trt             prob          SE df   asymp.LCL   asymp.UCL
 Calendar 0.004374833 0.001541432 NA 0.002191201 0.008715549
 G10      0.004090935 0.001498922 NA 0.001993307 0.008377443
 G15      0.010757825 0.003091538 NA 0.006116214 0.018855141
 G20      0.013517346 0.003832360 NA 0.007740919 0.023502164
 Control  0.419339074 0.051564118 NA 0.322885163 0.522377507

Results are averaged over the levels of: farm
Confidence level used: 0.95
Intervals are back-transformed from the logit scale

$contrasts
 contrast              odds.ratio           SE df z.ratio p.value
 G10 vs calendar     9.348400e-01 4.592373e-01 NA  -0.137  0.8909
 G15 vs calendar     6.552019e+00 4.909975e+00 NA   2.508  0.0121
 G20 vs calendar     1.310737e+01 1.307704e+01 NA   2.579  0.0099
 Control vs calendar 1.011296e+08 1.124089e+08 NA  16.582  <.0001

Results are averaged over the levels of: farm
Tests are performed on the log odds ratio scale

## Do you think it's correct, if I consider trt calendar as the reference
to test my other treatments?

Thanks!

Juan

*Juan*

On Mon, Apr 24, 2017 at 11:46 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be
> wrote:

> Dear Peter,
>
> Both models will yield identical results in case tree_id uses unique codes
> over the blocks.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2017-04-24 15:55 GMT+02:00 Peter Claussen <dakotajudo at mac.com>:
>
>> Juan,
>>
>> I would model this as
>>
>> m3 = glmer(resp ~ trt * farm +  (1| bk/tree), family = binomial, data=df)
>> or
>> m3 = glmer(resp ~ trt * farm +  (1| bk) +  (1| tree_id), family =
>> binomial, data=df)
>> (I can?t say off the top of my head if what the difference would be if
>> you?re dealing with over-dispersion).
>>
>> 1. I?m assuming that block is a somewhat uniform grouping of trees, so
>> that including block in the model gives you an estimate of spatial
>> variability in the response, and if that is important relative to
>> tree-to-tree variation.
>>
>> 2. You will most certainly want to include trt*farm to test for
>> treatment-by-environment interaction. If interaction is not significant,
>> you may choose to exclude interaction from the model. If there is
>> interaction, then you will want to examine each farm to determine if
>> cross-over interaction present.
>>
>> If your experiment is to determine the ?best? fungicide spraying system,
>> and cross-over interaction is present, then you have no ?best? system. You
>> might have cross-over arising because, say, system 1 ranks ?best? on farm
>> 1, but system 2 ranks ?best? on farm 2.
>>
>> There is extensive literature on the topic, mostly from the plant
>> breeding genotype-by-environment interaction side. Some of the associated
>> statistics implemented in the agricolae package, i.e. AMMI.
>>
>> Peter
>>
>> > On Apr 24, 2017, at 6:56 AM, Juan Pablo Edwards Molina <
>> edwardsmolina at gmail.com> wrote:
>> >
>> > I?m sorry... I?m new in the list, and when I figured out that the
>> question
>> > would suit best in the mixed model list I had already post it in general
>> > R-help. I don?t know if there?s a way to "cancel a question"... I will
>> take
>> > care of it from now on.
>> >
>> > Dear Thierry, thanks for your answer.
>> > Yes, I am not interested in the effect of a specific farm, they simply
>> > represent the total of farms from the region where I want to suggest the
>> > best treatments.
>> >
>> > I Followed your suggestions, but still have a couple of doubts,
>> >
>> > 1- May "farm" be include as a simple fixed effect or interacting with
>> the
>> > treatment?
>> >
>> > m3 = glmer(resp ~ trt * farm + (1|tree_id), family = binomial, data=df)
>> > m4 = glmer(resp ~ trt + farm + (1|tree_id), family = binomial, data=df)
>> >
>> > ?2 - ?
>> > In case of significant
>> > ?[ trt * farm ], should I report the results for each farm??
>> >
>> > Thanks again Thierry,
>> >
>> > Juan Edwards
>> >
>> >
>> > *Juan*
>> >
>> > On Mon, Apr 24, 2017 at 4:29 AM, Thierry Onkelinx <
>> thierry.onkelinx at inbo.be>
>> > wrote:
>> >
>> >> Dear Juan,
>> >>
>> >> Use unique id's for random effects variables. So each bk should only be
>> >> present in one farm. And each tree_id should be present in only one
>> bk. In
>> >> case each block has different treatments then each tree_id should be
>> unique
>> >> to one combination of bk and trt.
>> >>
>> >> Farm has too few levels to be a random effects. So either model is as a
>> >> fixed effect or drop it. In case you drop it, the information will be
>> >> picked up by bk. Note that trt + (1|farm) is less complex than trt *
>> farm.
>> >>
>> >> Assuming that you are not interested in the effect of a specific farm,
>> you
>> >> could use sum, polynomial or helmert contrasts for the farms. Unlike
>> the
>> >> default treatment contrast, these type of contrasts sum to zero. Thus
>> the
>> >> effect of trt will be that for the average farm instead of the
>> reference
>> >> farm.
>> >>
>> >> Best regards,
>> >>
>> >> ir. Thierry Onkelinx
>> >> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and
>> >> Forest
>> >> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> >> Kliniekstraat 25
>> >> 1070 Anderlecht
>> >> Belgium
>> >>
>> >> To call in the statistician after the experiment is done may be no more
>> >> than asking him to perform a post-mortem examination: he may be able
>> to say
>> >> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> >> The plural of anecdote is not data. ~ Roger Brinner
>> >> The combination of some data and an aching desire for an answer does
>> not
>> >> ensure that a reasonable answer can be extracted from a given body of
>> data.
>> >> ~ John Tukey
>> >>
>> >> 2017-04-21 22:32 GMT+02:00 Juan Pablo Edwards Molina <
>> >> edwardsmolina at gmail.com>:
>> >>
>> >>> I am analyzing data from 3 field experiments (farms=3) for a citrus
>> flower
>> >>> disease: response variable is binomial because the flower can only be
>> >>> diseased or healthy.
>> >>>
>> >>> I have particular interest in comparing 5 fungicide spraying systems
>> >>> (trt=5).
>> >>>
>> >>> Each farm had 4 blocks (bk=4) including 2 trees as subsamples
>> (tree=2) in
>> >>> which I assessed 100 flowers each one. This is a quick look of the
>> data:
>> >>>
>> >>> farm      trt      bk    tree   dis   tot     <fctr>   <fctr>  <fctr>
>> >>> <fctr> <int> <int>
>> >>> iaras      cal      1      1     0    100
>> >>> iaras      cal      1      2     1    100
>> >>> iaras      cal      2      1     1    100
>> >>> iaras      cal      2      2     3    100
>> >>> iaras      cal      3      1     0    100
>> >>> iaras      cal      3      2     5    100...
>> >>>
>> >>> The model I considered was:
>> >>>
>> >>> resp <- with(df, cbind(dis, tot-dis))
>> >>>
>> >>> m1 = glmer(resp ~ trt + (1|farm/bk) , family = binomial, data=df)
>> >>>
>> >>> I tested the overdispersion with the overdisp_fun() from GLMM page
>> >>> <http://glmm.wikidot.com/faq>
>> >>>
>> >>>        chisq         ratio             p          logp
>> >>> 4.191645e+02  3.742540e+00  4.804126e-37 -8.362617e+01
>> >>>
>> >>> As ratio (residual dev/residual df) > 1, and the p-value < 0.05, I
>> >>> considered to add the observation level random effect (link
>> >>> <http://r.789695.n4.nabble.com/Question-on-overdispersion-td
>> 3049898.html
>> >>>> )
>> >>> to deal with the overdispersion.
>> >>>
>> >>> farm      trt      bk    tree   dis   tot tree_id    <fctr>   <fctr>
>> >>> <fctr> <fctr> <int> <int> <fctr>
>> >>> iaras      cal      1      1     0    100    1
>> >>> iaras      cal      1      2     1    100    2
>> >>> iaras      cal      2      1     1    100    3...
>> >>>
>> >>> so now was added a random effect for each row (tree_id) to the model,
>> but
>> >>> I
>> >>> am not sure of how to include it. This is my approach:
>> >>>
>> >>> m2 = glmer(resp ~ trt + (1|farm/bk) + (1|tree_id), family = binomial,
>> >>> data=df)
>> >>>
>> >>> I also wonder if farm should be a fixed effect, since it has only 3
>> >>> levels...
>> >>>
>> >>> m3 = glmer(resp ~ trt * farm + (1|farm:bk) + (1|tree_id), family =
>> >>> binomial, data=df)
>> >>>
>> >>> I really appreciate your suggestions about my model specifications...
>> >>>
>> >>>
>> >>>
>> >>> *Juan? Edwards- - - - - - - - - - - - - - - - - - - - - - - -# PhD
>> student
>> >>> - ESALQ-USP/Brazil*
>> >>>
>> >>>        [[alternative HTML version deleted]]
>> >>>
>> >>> _______________________________________________
>> >>> R-sig-mixed-models at r-project.org mailing list
>> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >>
>> >>
>> >>
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>

	[[alternative HTML version deleted]]


From jmichaelrosenberg at gmail.com  Tue Apr 25 16:28:08 2017
From: jmichaelrosenberg at gmail.com (Joshua Rosenberg)
Date: Tue, 25 Apr 2017 10:28:08 -0400
Subject: [R-sig-ME] Specifying models nested crossed random effects
In-Reply-To: <CAAge6+4E6sEi1YXHSF+7gc-B_7xkVyM8f4T9uThrW6JodVpwfA@mail.gmail.com>
References: <CANYHYTTQQOjYc_AvzCyZ8ruLd16Nc5pzHySJe4CpKSF8Ezz1jw@mail.gmail.com>
 <CAAge6+7EZSrOYtHzzBkceqhtakE6uwk0GJvfwJRb89Dz6Vgxiw@mail.gmail.com>
 <CANYHYTQSMuasED01N7O_zECyLj6WEUXe-0V-YYDLfcr7=Ye28A@mail.gmail.com>
 <CAAge6+4E6sEi1YXHSF+7gc-B_7xkVyM8f4T9uThrW6JodVpwfA@mail.gmail.com>
Message-ID: <CANYHYTQagXKreLorWESirUcqrp+_Z4aaJUXykPh4wEa9OkbBGA@mail.gmail.com>

Evan - thank you very much for your advice, I've basically specified the
model as you suggested and it seems to be a reasonable approach.

thanks again,
Josh

On Sun, Apr 9, 2017 at 2:56 PM, Evan Palmer-Young <ecp52 at cornell.edu> wrote:

> Thanks for those details, Josh. Interesting design!
>
> I'm not experienced in interpreting random effects on their own, so others
> will have better advice on that.
>
> For your model structure, it sounds like there are three random effects:
>
> "program_ID"
> "participant_ID"
> "sample_ID"
>
> From my reading of lme4 documentation, I think that you have coded
> sample_ID correctly and do not need to explicitly nest it within program_ID.
>
> In general, think it may be better form to include both fixed and random
> predictors in your model, rather than having separate models to assess only
> the random effects.
>
> So your model might be something like,
>
> interest_model <- lmer(interest ~ ?Instruction_type? + ?time_of_day?  +
> ?Working_alone? + (1}program_ID) +  (1|participant_ID) + (1|sample?_ID?),
> data = df)
>
> Where Instruction_type, time_of_day , Working_alone, are fabricated
> variables that might resemble variables you recorded.
>
> As a disclaimer, this is my second time answering to the list-- welcome!
>
> Best wishes, Evan
>
>
>
>
>
> On Sat, Apr 8, 2017 at 4:26 PM, Joshua Rosenberg <
> jmichaelrosenberg at gmail.com> wrote:
>
>> Thank you Evan for your response and thank you for clarifying.
>>
>> ?Responses are in-line below.?
>>
>>
>> ?Thank you for considering this!?
>>
>> ?Josh?
>>
>>
>> On Sat, Apr 8, 2017 at 3:28 PM, Evan Palmer-Young <ecp52 at cornell.edu>
>> wrote:
>>
>>> Josh,
>>> Thanks for the questions.
>>> Can you provide a little bit more description about the variables?
>>>
>>
>> ?First, sorry, I had changed some of the variable names in the data and
>> realize I used different names (and a different outcome) in the examples at
>> the bottom.
>>
>> ?"interest" (one outcome we're measuring) is a variable of participants'
>> self-reported interest using a 1-4 scale.
>>
>> "overall_engagement" is one other (different) outcome: One that was a
>> composite of variables of students' interest, how hard they were
>> concentrating,
>> ?and how challenging they reported what they were learning was.
>>
>> We asked participants (youth) about how interested they were in what they
>> were learning at random intervals using what is called  an experience
>> sampling method. In our method, youth had phones on which they were asked
>> about what they were thinking / feeling - every youth in the same program
>> (more on the programs in just a moment) was notified to answer our
>> questions at the same time, although both the instance in time and the
>> interval between these questions was different between programs.
>>
>> "site" = "program" (ID) and program is an indicator for membership in one
>> of the 10 programs.
>>
>> Because youth were repeatedly sampled, "participant_ID" is an indicator
>> for one of about 200 participants.
>>
>> "sample_ID" is an indicator unique for each program (it was made from the
>> program_ID, the date, and which of one of four samples it was for that
>> date). There are about 20 unique values for it for each program, from
>> around 200 values total.
>>
>>
>>> Does "site" = "program"?
>>> Are participants queried at multiple timepoints? If pre- and
>>> post-program, could this be included as a factor with levels "before" and
>>> "afte
>>>
>>
>> Yes, the sampling consisted of repeated measures within participant
>> (around 15-20 responses per participant). It's a bit tricky for me to
>> describe, but as I mentioned above every youth in the same program was
>> notified to answer questions at the same time, though both the instance in
>> time and the interval between these questions differed between the 10
>> programs.
>>
>>
>>> Do you have any particular hypotheses or questions you want to answer
>>> with your model?
>>>
>>
>> ?We're interested in, for a lack of a better word, time point or
>> situation-specific ("sample_ID") variables' relationships with engagement.
>> We coded video of the programs, including before and when youth were
>> notified to respond, for example, the type of activity youth were
>> participating in (i.e., working in groups or individually; doing hands-on
>> activities or listening to the activity leaders). We imagine considering
>> these as categorical variables.
>>
>> Similarly, we're interested in relationships between youth's
>> characteristics (such as pre-program interest and demographic
>> characteristics, such as gender) and our outcomes and to a bit of a lesser
>> extent relationships between some program factors and outcomes (though with
>> only 10 programs, we do not imagine we will have statistical power to
>> detect any / many effects at that level).
>>
>> We're interested in sources of variance as a substantive question (how
>> much of students' engagement is explained by time-point ("sample_ID"),
>> youth ("participant_ID"), and program ("program_ID") effects?). Though this
>> is a bit secondary to our questions about the specific variables at
>> time-point, youth, and program levels.
>>
>>
>>> Best wishes, Evan
>>>
>>
>>
>>
>>
>> --
>> Joshua Rosenberg
>> jmichaelrosenberg at gmail.com
>> http://joshuamrosenberg.com
>>
>
>
>
> --
> Evan Palmer-Young
> PhD candidate
> Department of Biology
> 221 Morrill Science Center
> 611 North Pleasant St
> Amherst MA 01003
> https://sites.google.com/a/cornell.edu/evan-palmer-young/
> epalmery at cns.umass.edu
> ecp52 at cornell.edu
>



-- 
Joshua Rosenberg
jmichaelrosenberg at gmail.com
http://joshuamrosenberg.com

	[[alternative HTML version deleted]]


From dakotajudo at mac.com  Tue Apr 25 16:29:12 2017
From: dakotajudo at mac.com (Peter Claussen)
Date: Tue, 25 Apr 2017 09:29:12 -0500
Subject: [R-sig-ME] GLMM for Combined experiments and overdispersed data
In-Reply-To: <CAF5W3aRjrnCmjVRFCk5OdOnVYwtxcgkfWDb9Xf03DjYAq6KaHA@mail.gmail.com>
References: <CAF5W3aRX0+K7Js0Kkuy1KEgJ86oiB_0i7ZYNMBxS9_A8znWtLA@mail.gmail.com>
 <CAJuCY5z+Axd_LRhG8n+HWYHatFi6d-cD3RWu8ey0fs=EQb7Hxg@mail.gmail.com>
 <CAF5W3aT2mn2qB0Xe8-vzsMJqvL2zS3T1mcjjDe3=TJyGDQaBgw@mail.gmail.com>
 <9522B3B8-9E62-41C3-A376-BEE819F3A07A@mac.com>
 <CAJuCY5yty3kDY9FHAsP1GYky7RM410v4MMctwVPqvNc62=tKvg@mail.gmail.com>
 <CAF5W3aRjrnCmjVRFCk5OdOnVYwtxcgkfWDb9Xf03DjYAq6KaHA@mail.gmail.com>
Message-ID: <587C2021-8337-4F20-A6D7-C4A1BA18186B@mac.com>

Perhaps I?m missing something.

Are the individual trees the experimental units, and are you only taking one count per tree, or are there multiple counts? That makes me think that that tree_id variance is effectively residual variance and that there is no random effect other than residual.

You have 112 df.resid, and 120 groups : tree_id.

So what do you gain by using glmer as opposed to gem with a quasibinomial family?

Peter

> On Apr 25, 2017, at 8:40 AM, Juan Pablo Edwards Molina <edwardsmolina at gmail.com> wrote:
> 
> Thierry, sorry to bother you again...
> I tried to follow your suggestion and I did the herlmert contrasts with lsmeans package.
> 
> dinc <- within(dinc, { tree_id <- as.factor(interaction(farm, trt, bk, tree)) })
> 
> resp1 <- with(dinc, cbind(dis, tot-dis)) 
> 
> m0 = glmer(resp1 ~ trt + farm + (1|tree_id), family = binomial, data=dinc) 
> 
> > summary(m0)
> Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) [
> glmerMod]
>  Family: binomial  ( logit )
> Formula: resp1 ~ trt + farm + (1 | tree_id)
>    Data: dinc
> 
>      AIC      BIC   logLik deviance df.resid 
>    521.5    543.8   -252.7    505.5      112 
> 
> Scaled residuals: 
>      Min       1Q   Median       3Q      Max 
> -0.90445 -0.51114 -0.00572  0.31456  1.04667 
> 
> Random effects:
>  Groups  Name        Variance Std.Dev.
>  tree_id (Intercept) 1.028    1.014   
> Number of obs: 120, groups:  tree_id, 120
> 
> Fixed effects:
>             Estimate Std. Error z value Pr(>|z|)    
> (Intercept) -4.87786    0.37604 -12.972  < 2e-16 ***
> trtG10      -0.06738    0.49125  -0.137  0.89090    
> trtG15       0.90620    0.44435   2.039  0.04141 *  
> trtG20       1.13733    0.43920   2.590  0.00961 ** 
> trtControl   5.10202    0.41215  12.379  < 2e-16 ***
> farmstacruz -0.80155    0.30294  -2.646  0.00815 ** 
> farmtaqua   -0.84738    0.30659  -2.764  0.00571 ** 
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Correlation of Fixed Effects:
>             (Intr) trtG10 trtG15 trtG20 trtCnt frmstc
> trtG10      -0.635                                   
> trtG15      -0.710  0.538                            
> trtG20      -0.720  0.546  0.604                     
> trtControl  -0.763  0.571  0.650  0.651              
> farmstacruz -0.300  0.022 -0.015  0.010 -0.081       
> farmtaqua   -0.301  0.012  0.004  0.017 -0.083  0.441
> 
> ### Setting up a custom contrast function
> 
> helmert.lsmc <- function(levs, ...) {
>   M <- as.data.frame(contr.helmert(levs))
>   names(M) <- paste(levs[-1],"vs calendar")
>   attr(M, "desc") <- "Helmert contrasts"
>   M
> }
> 
> > lsmeans(m0, helmert ~ trt, type = "response")
> 
> $lsmeans
>  trt             prob          SE df   asymp.LCL   asymp.UCL
>  Calendar 0.004374833 0.001541432 NA 0.002191201 0.008715549
>  G10      0.004090935 0.001498922 NA 0.001993307 0.008377443
>  G15      0.010757825 0.003091538 NA 0.006116214 0.018855141
>  G20      0.013517346 0.003832360 NA 0.007740919 0.023502164
>  Control  0.419339074 0.051564118 NA 0.322885163 0.522377507
> 
> Results are averaged over the levels of: farm 
> Confidence level used: 0.95 
> Intervals are back-transformed from the logit scale 
> 
> $contrasts
>  contrast              odds.ratio           SE df z.ratio p.value
>  G10 vs calendar     9.348400e-01 4.592373e-01 NA  -0.137  0.8909
>  G15 vs calendar     6.552019e+00 4.909975e+00 NA   2.508  0.0121
>  G20 vs calendar     1.310737e+01 1.307704e+01 NA   2.579  0.0099
>  Control vs calendar 1.011296e+08 1.124089e+08 NA  16.582  <.0001
> 
> Results are averaged over the levels of: farm 
> Tests are performed on the log odds ratio scale 
> 
> ## Do you think it's correct, if I consider trt calendar as the reference to test my other treatments?
> 
> Thanks!
> 
> Juan
> 
> Juan
> 
> On Mon, Apr 24, 2017 at 11:46 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>> wrote:
> Dear Peter,
> 
> Both models will yield identical results in case tree_id uses unique codes over the blocks.
> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest 
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance 
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> 
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner 
> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
> 
> 2017-04-24 15:55 GMT+02:00 Peter Claussen <dakotajudo at mac.com <mailto:dakotajudo at mac.com>>:
> Juan,
> 
> I would model this as
> 
> m3 = glmer(resp ~ trt * farm +  (1| bk/tree), family = binomial, data=df)
> or
> m3 = glmer(resp ~ trt * farm +  (1| bk) +  (1| tree_id), family = binomial, data=df)
> (I can?t say off the top of my head if what the difference would be if you?re dealing with over-dispersion).
> 
> 1. I?m assuming that block is a somewhat uniform grouping of trees, so that including block in the model gives you an estimate of spatial variability in the response, and if that is important relative to tree-to-tree variation.
> 
> 2. You will most certainly want to include trt*farm to test for treatment-by-environment interaction. If interaction is not significant, you may choose to exclude interaction from the model. If there is interaction, then you will want to examine each farm to determine if cross-over interaction present.
> 
> If your experiment is to determine the ?best? fungicide spraying system, and cross-over interaction is present, then you have no ?best? system. You might have cross-over arising because, say, system 1 ranks ?best? on farm 1, but system 2 ranks ?best? on farm 2.
> 
> There is extensive literature on the topic, mostly from the plant breeding genotype-by-environment interaction side. Some of the associated statistics implemented in the agricolae package, i.e. AMMI.
> 
> Peter
> 
> > On Apr 24, 2017, at 6:56 AM, Juan Pablo Edwards Molina <edwardsmolina at gmail.com <mailto:edwardsmolina at gmail.com>> wrote:
> >
> > I?m sorry... I?m new in the list, and when I figured out that the question
> > would suit best in the mixed model list I had already post it in general
> > R-help. I don?t know if there?s a way to "cancel a question"... I will take
> > care of it from now on.
> >
> > Dear Thierry, thanks for your answer.
> > Yes, I am not interested in the effect of a specific farm, they simply
> > represent the total of farms from the region where I want to suggest the
> > best treatments.
> >
> > I Followed your suggestions, but still have a couple of doubts,
> >
> > 1- May "farm" be include as a simple fixed effect or interacting with the
> > treatment?
> >
> > m3 = glmer(resp ~ trt * farm + (1|tree_id), family = binomial, data=df)
> > m4 = glmer(resp ~ trt + farm + (1|tree_id), family = binomial, data=df)
> >
> > ?2 - ?
> > In case of significant
> > ?[ trt * farm ], should I report the results for each farm??
> >
> > Thanks again Thierry,
> >
> > Juan Edwards
> >
> >
> > *Juan*
> >
> > On Mon, Apr 24, 2017 at 4:29 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>>
> > wrote:
> >
> >> Dear Juan,
> >>
> >> Use unique id's for random effects variables. So each bk should only be
> >> present in one farm. And each tree_id should be present in only one bk. In
> >> case each block has different treatments then each tree_id should be unique
> >> to one combination of bk and trt.
> >>
> >> Farm has too few levels to be a random effects. So either model is as a
> >> fixed effect or drop it. In case you drop it, the information will be
> >> picked up by bk. Note that trt + (1|farm) is less complex than trt * farm.
> >>
> >> Assuming that you are not interested in the effect of a specific farm, you
> >> could use sum, polynomial or helmert contrasts for the farms. Unlike the
> >> default treatment contrast, these type of contrasts sum to zero. Thus the
> >> effect of trt will be that for the average farm instead of the reference
> >> farm.
> >>
> >> Best regards,
> >>
> >> ir. Thierry Onkelinx
> >> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> >> Forest
> >> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> >> Kliniekstraat 25
> >> 1070 Anderlecht
> >> Belgium
> >>
> >> To call in the statistician after the experiment is done may be no more
> >> than asking him to perform a post-mortem examination: he may be able to say
> >> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> >> The plural of anecdote is not data. ~ Roger Brinner
> >> The combination of some data and an aching desire for an answer does not
> >> ensure that a reasonable answer can be extracted from a given body of data.
> >> ~ John Tukey
> >>
> >> 2017-04-21 22:32 GMT+02:00 Juan Pablo Edwards Molina <
> >> edwardsmolina at gmail.com <mailto:edwardsmolina at gmail.com>>:
> >>
> >>> I am analyzing data from 3 field experiments (farms=3) for a citrus flower
> >>> disease: response variable is binomial because the flower can only be
> >>> diseased or healthy.
> >>>
> >>> I have particular interest in comparing 5 fungicide spraying systems
> >>> (trt=5).
> >>>
> >>> Each farm had 4 blocks (bk=4) including 2 trees as subsamples (tree=2) in
> >>> which I assessed 100 flowers each one. This is a quick look of the data:
> >>>
> >>> farm      trt      bk    tree   dis   tot     <fctr>   <fctr>  <fctr>
> >>> <fctr> <int> <int>
> >>> iaras      cal      1      1     0    100
> >>> iaras      cal      1      2     1    100
> >>> iaras      cal      2      1     1    100
> >>> iaras      cal      2      2     3    100
> >>> iaras      cal      3      1     0    100
> >>> iaras      cal      3      2     5    100...
> >>>
> >>> The model I considered was:
> >>>
> >>> resp <- with(df, cbind(dis, tot-dis))
> >>>
> >>> m1 = glmer(resp ~ trt + (1|farm/bk) , family = binomial, data=df)
> >>>
> >>> I tested the overdispersion with the overdisp_fun() from GLMM page
> >>> <http://glmm.wikidot.com/faq <http://glmm.wikidot.com/faq>>
> >>>
> >>>        chisq         ratio             p          logp
> >>> 4.191645e+02  3.742540e+00  4.804126e-37 -8.362617e+01
> >>>
> >>> As ratio (residual dev/residual df) > 1, and the p-value < 0.05, I
> >>> considered to add the observation level random effect (link
> >>> <http://r.789695.n4.nabble.com/Question-on-overdispersion-td3049898.html <http://r.789695.n4.nabble.com/Question-on-overdispersion-td3049898.html>
> >>>> )
> >>> to deal with the overdispersion.
> >>>
> >>> farm      trt      bk    tree   dis   tot tree_id    <fctr>   <fctr>
> >>> <fctr> <fctr> <int> <int> <fctr>
> >>> iaras      cal      1      1     0    100    1
> >>> iaras      cal      1      2     1    100    2
> >>> iaras      cal      2      1     1    100    3...
> >>>
> >>> so now was added a random effect for each row (tree_id) to the model, but
> >>> I
> >>> am not sure of how to include it. This is my approach:
> >>>
> >>> m2 = glmer(resp ~ trt + (1|farm/bk) + (1|tree_id), family = binomial,
> >>> data=df)
> >>>
> >>> I also wonder if farm should be a fixed effect, since it has only 3
> >>> levels...
> >>>
> >>> m3 = glmer(resp ~ trt * farm + (1|farm:bk) + (1|tree_id), family =
> >>> binomial, data=df)
> >>>
> >>> I really appreciate your suggestions about my model specifications...
> >>>
> >>>
> >>>
> >>> *Juan? Edwards- - - - - - - - - - - - - - - - - - - - - - - -# PhD student
> >>> - ESALQ-USP/Brazil*
> >>>
> >>>        [[alternative HTML version deleted]]
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org> mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >>
> >>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org> mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> 


	[[alternative HTML version deleted]]


From jmichaelrosenberg at gmail.com  Tue Apr 25 16:33:08 2017
From: jmichaelrosenberg at gmail.com (Joshua Rosenberg)
Date: Tue, 25 Apr 2017 10:33:08 -0400
Subject: [R-sig-ME] Specifying models nested crossed random effects
In-Reply-To: <974c021b-87d3-725d-d33e-8148229f0286@uni-potsdam.de>
References: <CANYHYTTQQOjYc_AvzCyZ8ruLd16Nc5pzHySJe4CpKSF8Ezz1jw@mail.gmail.com>
 <CAAge6+7EZSrOYtHzzBkceqhtakE6uwk0GJvfwJRb89Dz6Vgxiw@mail.gmail.com>
 <CANYHYTQSMuasED01N7O_zECyLj6WEUXe-0V-YYDLfcr7=Ye28A@mail.gmail.com>
 <CAAge6+4E6sEi1YXHSF+7gc-B_7xkVyM8f4T9uThrW6JodVpwfA@mail.gmail.com>
 <974c021b-87d3-725d-d33e-8148229f0286@uni-potsdam.de>
Message-ID: <CANYHYTRHsA=_CQiLargZk-Vb06fyTDeLG_ALWPzB63HQXrh45g@mail.gmail.com>

Diana - thank you very much, I think you're right, and I've found
(interestingly, though maybe not surprisingly) there are two identical ways
to specify this nesting, one is by explicitly identifying the participants
and signals (i.e., not "Participant 1" nested in "Program A" when there is
*another* "Participant 1" in "Program B," but rather using a unique
participant ID and sample ID for every participant and sample, i.e.
(1|program_ID) + (1|sample_ID) or by nesting not unique participant IDs and
sample IDs within program, i.e. (1|program_ID/participant_ID). Chapter 2
<http://lme4.r-forge.r-project.org/book/Ch2.pdf> of the (not published)
lme4 book by Bates helped me understand why (basically, lme4 figures out
the nesting (or crossing) on its own as long as the random effects are not
nested implicitly).

thanks again. also thinking hard about the ordinal issue - while some are,
some of our outcomes are composites of multiple items and so aren't ordinal.

Josh

On Sun, Apr 9, 2017 at 5:00 PM, Diana Michl <dmichl at uni-potsdam.de> wrote:

> Not planning to confuse anyone and I agree with Evan mostly. But it seems
> to me that even with the fixed effects, it still makes sense to include
> participants and programs as nested random effects because they really are
> nested (one factor (grouping variable) appears only within a particular
> level of another factor (grouping variable)).
> sample_ID seems fine, but I think it should still be (1|
> program_ID/participant_ID).
>
> Diana
>
> Am 09.04.2017 um 20:56 schrieb Evan Palmer-Young:
>
> Thanks for those details, Josh. Interesting design!
>
> I'm not experienced in interpreting random effects on their own, so others
> will have better advice on that.
>
> For your model structure, it sounds like there are three random effects:
>
> "program_ID"
> "participant_ID"
> "sample_ID"
>
> From my reading of lme4 documentation, I think that you have coded
> sample_ID correctly and do not need to explicitly nest it within program_ID.
>
> In general, think it may be better form to include both fixed and random
> predictors in your model, rather than having separate models to assess only
> the random effects.
>
> So your model might be something like,
>
> interest_model <- lmer(interest ~ ?Instruction_type? + ?time_of_day?  +
> ?Working_alone? + (1}program_ID) +  (1|participant_ID) + (1|sample?_ID?),
> data = df)
>
> Where Instruction_type, time_of_day , Working_alone, are fabricated
> variables that might resemble variables you recorded.
>
> As a disclaimer, this is my second time answering to the list-- welcome!
>
> Best wishes, Evan
>
>
>
>
>
> On Sat, Apr 8, 2017 at 4:26 PM, Joshua Rosenberg <jmichaelrosenberg at gmail.com> wrote:
>
>
> Thank you Evan for your response and thank you for clarifying.
>
> ?Responses are in-line below.?
>
>
> ?Thank you for considering this!?
>
> ?Josh?
>
>
> On Sat, Apr 8, 2017 at 3:28 PM, Evan Palmer-Young <ecp52 at cornell.edu> <ecp52 at cornell.edu>
> wrote:
>
>
> Josh,
> Thanks for the questions.
> Can you provide a little bit more description about the variables?
>
>
> ?First, sorry, I had changed some of the variable names in the data and
> realize I used different names (and a different outcome) in the examples at
> the bottom.
>
> ?"interest" (one outcome we're measuring) is a variable of participants'
> self-reported interest using a 1-4 scale.
>
> "overall_engagement" is one other (different) outcome: One that was a
> composite of variables of students' interest, how hard they were
> concentrating,
> ?and how challenging they reported what they were learning was.
>
> We asked participants (youth) about how interested they were in what they
> were learning at random intervals using what is called  an experience
> sampling method. In our method, youth had phones on which they were asked
> about what they were thinking / feeling - every youth in the same program
> (more on the programs in just a moment) was notified to answer our
> questions at the same time, although both the instance in time and the
> interval between these questions was different between programs.
>
> "site" = "program" (ID) and program is an indicator for membership in one
> of the 10 programs.
>
> Because youth were repeatedly sampled, "participant_ID" is an indicator
> for one of about 200 participants.
>
> "sample_ID" is an indicator unique for each program (it was made from the
> program_ID, the date, and which of one of four samples it was for that
> date). There are about 20 unique values for it for each program, from
> around 200 values total.
>
>
>
> Does "site" = "program"?
> Are participants queried at multiple timepoints? If pre- and
> post-program, could this be included as a factor with levels "before" and
> "afte
>
>
> Yes, the sampling consisted of repeated measures within participant
> (around 15-20 responses per participant). It's a bit tricky for me to
> describe, but as I mentioned above every youth in the same program was
> notified to answer questions at the same time, though both the instance in
> time and the interval between these questions differed between the 10
> programs.
>
>
>
> Do you have any particular hypotheses or questions you want to answer
> with your model?
>
>
> ?We're interested in, for a lack of a better word, time point or
> situation-specific ("sample_ID") variables' relationships with engagement.
> We coded video of the programs, including before and when youth were
> notified to respond, for example, the type of activity youth were
> participating in (i.e., working in groups or individually; doing hands-on
> activities or listening to the activity leaders). We imagine considering
> these as categorical variables.
>
> Similarly, we're interested in relationships between youth's
> characteristics (such as pre-program interest and demographic
> characteristics, such as gender) and our outcomes and to a bit of a lesser
> extent relationships between some program factors and outcomes (though with
> only 10 programs, we do not imagine we will have statistical power to
> detect any / many effects at that level).
>
> We're interested in sources of variance as a substantive question (how
> much of students' engagement is explained by time-point ("sample_ID"),
> youth ("participant_ID"), and program ("program_ID") effects?). Though this
> is a bit secondary to our questions about the specific variables at
> time-point, youth, and program levels.
>
>
>
> Best wishes, Evan
>
>
>
>
>
> --
> Joshua Rosenbergjmichaelrosenberg at gmail.comhttp://joshuamrosenberg.com
>
>
>
> --
> Diana Michl, M.A.
> PhD candidate
> International Experimental
> and Clinical Linguistics
> Universit?t Potsdamwww.ling.uni-potsdam.de/staff/dmichlwww.duoinfernale.eu
>
>


-- 
Joshua Rosenberg
jmichaelrosenberg at gmail.com
http://joshuamrosenberg.com

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue Apr 25 16:40:47 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 25 Apr 2017 10:40:47 -0400
Subject: [R-sig-ME] Specifying models nested crossed random effects
In-Reply-To: <CANYHYTRHsA=_CQiLargZk-Vb06fyTDeLG_ALWPzB63HQXrh45g@mail.gmail.com>
References: <CANYHYTTQQOjYc_AvzCyZ8ruLd16Nc5pzHySJe4CpKSF8Ezz1jw@mail.gmail.com>
 <CAAge6+7EZSrOYtHzzBkceqhtakE6uwk0GJvfwJRb89Dz6Vgxiw@mail.gmail.com>
 <CANYHYTQSMuasED01N7O_zECyLj6WEUXe-0V-YYDLfcr7=Ye28A@mail.gmail.com>
 <CAAge6+4E6sEi1YXHSF+7gc-B_7xkVyM8f4T9uThrW6JodVpwfA@mail.gmail.com>
 <974c021b-87d3-725d-d33e-8148229f0286@uni-potsdam.de>
 <CANYHYTRHsA=_CQiLargZk-Vb06fyTDeLG_ALWPzB63HQXrh45g@mail.gmail.com>
Message-ID: <CABghstQRLR8jEMbrbeOD9eaPwFBexb0PPHY36vuaGznbwkz+fA@mail.gmail.com>

http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#nested-or-crossed
tries to discuss this (last bullet point), but suggested edits for
clarity are welcome (or pull requests!)

On Tue, Apr 25, 2017 at 10:33 AM, Joshua Rosenberg
<jmichaelrosenberg at gmail.com> wrote:
> Diana - thank you very much, I think you're right, and I've found
> (interestingly, though maybe not surprisingly) there are two identical ways
> to specify this nesting, one is by explicitly identifying the participants
> and signals (i.e., not "Participant 1" nested in "Program A" when there is
> *another* "Participant 1" in "Program B," but rather using a unique
> participant ID and sample ID for every participant and sample, i.e.
> (1|program_ID) + (1|sample_ID) or by nesting not unique participant IDs and
> sample IDs within program, i.e. (1|program_ID/participant_ID). Chapter 2
> <http://lme4.r-forge.r-project.org/book/Ch2.pdf> of the (not published)
> lme4 book by Bates helped me understand why (basically, lme4 figures out
> the nesting (or crossing) on its own as long as the random effects are not
> nested implicitly).
>
> thanks again. also thinking hard about the ordinal issue - while some are,
> some of our outcomes are composites of multiple items and so aren't ordinal.
>
> Josh
>
> On Sun, Apr 9, 2017 at 5:00 PM, Diana Michl <dmichl at uni-potsdam.de> wrote:
>
>> Not planning to confuse anyone and I agree with Evan mostly. But it seems
>> to me that even with the fixed effects, it still makes sense to include
>> participants and programs as nested random effects because they really are
>> nested (one factor (grouping variable) appears only within a particular
>> level of another factor (grouping variable)).
>> sample_ID seems fine, but I think it should still be (1|
>> program_ID/participant_ID).
>>
>> Diana
>>
>> Am 09.04.2017 um 20:56 schrieb Evan Palmer-Young:
>>
>> Thanks for those details, Josh. Interesting design!
>>
>> I'm not experienced in interpreting random effects on their own, so others
>> will have better advice on that.
>>
>> For your model structure, it sounds like there are three random effects:
>>
>> "program_ID"
>> "participant_ID"
>> "sample_ID"
>>
>> From my reading of lme4 documentation, I think that you have coded
>> sample_ID correctly and do not need to explicitly nest it within program_ID.
>>
>> In general, think it may be better form to include both fixed and random
>> predictors in your model, rather than having separate models to assess only
>> the random effects.
>>
>> So your model might be something like,
>>
>> interest_model <- lmer(interest ~ ?Instruction_type? + ?time_of_day?  +
>> ?Working_alone? + (1}program_ID) +  (1|participant_ID) + (1|sample_ID),
>> data = df)
>>
>> Where Instruction_type, time_of_day , Working_alone, are fabricated
>> variables that might resemble variables you recorded.
>>
>> As a disclaimer, this is my second time answering to the list-- welcome!
>>
>> Best wishes, Evan
>>
>>
>>
>>
>>
>> On Sat, Apr 8, 2017 at 4:26 PM, Joshua Rosenberg <jmichaelrosenberg at gmail.com> wrote:
>>
>>
>> Thank you Evan for your response and thank you for clarifying.
>>
>> Responses are in-line below.
>>
>>
>> Thank you for considering this!
>>
>> Josh
>>
>>
>> On Sat, Apr 8, 2017 at 3:28 PM, Evan Palmer-Young <ecp52 at cornell.edu> <ecp52 at cornell.edu>
>> wrote:
>>
>>
>> Josh,
>> Thanks for the questions.
>> Can you provide a little bit more description about the variables?
>>
>>
>> First, sorry, I had changed some of the variable names in the data and
>> realize I used different names (and a different outcome) in the examples at
>> the bottom.
>>
>> "interest" (one outcome we're measuring) is a variable of participants'
>> self-reported interest using a 1-4 scale.
>>
>> "overall_engagement" is one other (different) outcome: One that was a
>> composite of variables of students' interest, how hard they were
>> concentrating,
>> and how challenging they reported what they were learning was.
>>
>> We asked participants (youth) about how interested they were in what they
>> were learning at random intervals using what is called  an experience
>> sampling method. In our method, youth had phones on which they were asked
>> about what they were thinking / feeling - every youth in the same program
>> (more on the programs in just a moment) was notified to answer our
>> questions at the same time, although both the instance in time and the
>> interval between these questions was different between programs.
>>
>> "site" = "program" (ID) and program is an indicator for membership in one
>> of the 10 programs.
>>
>> Because youth were repeatedly sampled, "participant_ID" is an indicator
>> for one of about 200 participants.
>>
>> "sample_ID" is an indicator unique for each program (it was made from the
>> program_ID, the date, and which of one of four samples it was for that
>> date). There are about 20 unique values for it for each program, from
>> around 200 values total.
>>
>>
>>
>> Does "site" = "program"?
>> Are participants queried at multiple timepoints? If pre- and
>> post-program, could this be included as a factor with levels "before" and
>> "afte
>>
>>
>> Yes, the sampling consisted of repeated measures within participant
>> (around 15-20 responses per participant). It's a bit tricky for me to
>> describe, but as I mentioned above every youth in the same program was
>> notified to answer questions at the same time, though both the instance in
>> time and the interval between these questions differed between the 10
>> programs.
>>
>>
>>
>> Do you have any particular hypotheses or questions you want to answer
>> with your model?
>>
>>
>> We're interested in, for a lack of a better word, time point or
>> situation-specific ("sample_ID") variables' relationships with engagement.
>> We coded video of the programs, including before and when youth were
>> notified to respond, for example, the type of activity youth were
>> participating in (i.e., working in groups or individually; doing hands-on
>> activities or listening to the activity leaders). We imagine considering
>> these as categorical variables.
>>
>> Similarly, we're interested in relationships between youth's
>> characteristics (such as pre-program interest and demographic
>> characteristics, such as gender) and our outcomes and to a bit of a lesser
>> extent relationships between some program factors and outcomes (though with
>> only 10 programs, we do not imagine we will have statistical power to
>> detect any / many effects at that level).
>>
>> We're interested in sources of variance as a substantive question (how
>> much of students' engagement is explained by time-point ("sample_ID"),
>> youth ("participant_ID"), and program ("program_ID") effects?). Though this
>> is a bit secondary to our questions about the specific variables at
>> time-point, youth, and program levels.
>>
>>
>>
>> Best wishes, Evan
>>
>>
>>
>>
>>
>> --
>> Joshua Rosenbergjmichaelrosenberg at gmail.comhttp://joshuamrosenberg.com
>>
>>
>>
>> --
>> Diana Michl, M.A.
>> PhD candidate
>> International Experimental
>> and Clinical Linguistics
>> Universit?t Potsdamwww.ling.uni-potsdam.de/staff/dmichlwww.duoinfernale.eu
>>
>>
>
>
> --
> Joshua Rosenberg
> jmichaelrosenberg at gmail.com
> http://joshuamrosenberg.com
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From jmichaelrosenberg at gmail.com  Tue Apr 25 16:51:38 2017
From: jmichaelrosenberg at gmail.com (Joshua Rosenberg)
Date: Tue, 25 Apr 2017 10:51:38 -0400
Subject: [R-sig-ME] Specifying models nested crossed random effects
In-Reply-To: <CABghstQRLR8jEMbrbeOD9eaPwFBexb0PPHY36vuaGznbwkz+fA@mail.gmail.com>
References: <CANYHYTTQQOjYc_AvzCyZ8ruLd16Nc5pzHySJe4CpKSF8Ezz1jw@mail.gmail.com>
 <CAAge6+7EZSrOYtHzzBkceqhtakE6uwk0GJvfwJRb89Dz6Vgxiw@mail.gmail.com>
 <CANYHYTQSMuasED01N7O_zECyLj6WEUXe-0V-YYDLfcr7=Ye28A@mail.gmail.com>
 <CAAge6+4E6sEi1YXHSF+7gc-B_7xkVyM8f4T9uThrW6JodVpwfA@mail.gmail.com>
 <974c021b-87d3-725d-d33e-8148229f0286@uni-potsdam.de>
 <CANYHYTRHsA=_CQiLargZk-Vb06fyTDeLG_ALWPzB63HQXrh45g@mail.gmail.com>
 <CABghstQRLR8jEMbrbeOD9eaPwFBexb0PPHY36vuaGznbwkz+fA@mail.gmail.com>
Message-ID: <CANYHYTQ9L-i3S5HXOj2pPiTZ4ruQDyere-4R3kO_QCNCMk1i6g@mail.gmail.com>

Ah hah - that is helpful! I think it is clear.

Thank you, I will direct people there if they have a similar question.

On Tue, Apr 25, 2017 at 10:40 AM, Ben Bolker <bbolker at gmail.com> wrote:

> http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#nested-or-crossed
> tries to discuss this (last bullet point), but suggested edits for
> clarity are welcome (or pull requests!)
>
> On Tue, Apr 25, 2017 at 10:33 AM, Joshua Rosenberg
> <jmichaelrosenberg at gmail.com> wrote:
> > Diana - thank you very much, I think you're right, and I've found
> > (interestingly, though maybe not surprisingly) there are two identical
> ways
> > to specify this nesting, one is by explicitly identifying the
> participants
> > and signals (i.e., not "Participant 1" nested in "Program A" when there
> is
> > *another* "Participant 1" in "Program B," but rather using a unique
> > participant ID and sample ID for every participant and sample, i.e.
> > (1|program_ID) + (1|sample_ID) or by nesting not unique participant IDs
> and
> > sample IDs within program, i.e. (1|program_ID/participant_ID). Chapter 2
> > <http://lme4.r-forge.r-project.org/book/Ch2.pdf> of the (not published)
> > lme4 book by Bates helped me understand why (basically, lme4 figures out
> > the nesting (or crossing) on its own as long as the random effects are
> not
> > nested implicitly).
> >
> > thanks again. also thinking hard about the ordinal issue - while some
> are,
> > some of our outcomes are composites of multiple items and so aren't
> ordinal.
> >
> > Josh
> >
> > On Sun, Apr 9, 2017 at 5:00 PM, Diana Michl <dmichl at uni-potsdam.de>
> wrote:
> >
> >> Not planning to confuse anyone and I agree with Evan mostly. But it
> seems
> >> to me that even with the fixed effects, it still makes sense to include
> >> participants and programs as nested random effects because they really
> are
> >> nested (one factor (grouping variable) appears only within a particular
> >> level of another factor (grouping variable)).
> >> sample_ID seems fine, but I think it should still be (1|
> >> program_ID/participant_ID).
> >>
> >> Diana
> >>
> >> Am 09.04.2017 um 20:56 schrieb Evan Palmer-Young:
> >>
> >> Thanks for those details, Josh. Interesting design!
> >>
> >> I'm not experienced in interpreting random effects on their own, so
> others
> >> will have better advice on that.
> >>
> >> For your model structure, it sounds like there are three random effects:
> >>
> >> "program_ID"
> >> "participant_ID"
> >> "sample_ID"
> >>
> >> From my reading of lme4 documentation, I think that you have coded
> >> sample_ID correctly and do not need to explicitly nest it within
> program_ID.
> >>
> >> In general, think it may be better form to include both fixed and random
> >> predictors in your model, rather than having separate models to assess
> only
> >> the random effects.
> >>
> >> So your model might be something like,
> >>
> >> interest_model <- lmer(interest ~ ?Instruction_type? + ?time_of_day?  +
> >> ?Working_alone? + (1}program_ID) +  (1|participant_ID) + (1|sample_ID),
> >> data = df)
> >>
> >> Where Instruction_type, time_of_day , Working_alone, are fabricated
> >> variables that might resemble variables you recorded.
> >>
> >> As a disclaimer, this is my second time answering to the list-- welcome!
> >>
> >> Best wishes, Evan
> >>
> >>
> >>
> >>
> >>
> >> On Sat, Apr 8, 2017 at 4:26 PM, Joshua Rosenberg <
> jmichaelrosenberg at gmail.com> wrote:
> >>
> >>
> >> Thank you Evan for your response and thank you for clarifying.
> >>
> >> Responses are in-line below.
> >>
> >>
> >> Thank you for considering this!
> >>
> >> Josh
> >>
> >>
> >> On Sat, Apr 8, 2017 at 3:28 PM, Evan Palmer-Young <ecp52 at cornell.edu> <
> ecp52 at cornell.edu>
> >> wrote:
> >>
> >>
> >> Josh,
> >> Thanks for the questions.
> >> Can you provide a little bit more description about the variables?
> >>
> >>
> >> First, sorry, I had changed some of the variable names in the data and
> >> realize I used different names (and a different outcome) in the
> examples at
> >> the bottom.
> >>
> >> "interest" (one outcome we're measuring) is a variable of participants'
> >> self-reported interest using a 1-4 scale.
> >>
> >> "overall_engagement" is one other (different) outcome: One that was a
> >> composite of variables of students' interest, how hard they were
> >> concentrating,
> >> and how challenging they reported what they were learning was.
> >>
> >> We asked participants (youth) about how interested they were in what
> they
> >> were learning at random intervals using what is called  an experience
> >> sampling method. In our method, youth had phones on which they were
> asked
> >> about what they were thinking / feeling - every youth in the same
> program
> >> (more on the programs in just a moment) was notified to answer our
> >> questions at the same time, although both the instance in time and the
> >> interval between these questions was different between programs.
> >>
> >> "site" = "program" (ID) and program is an indicator for membership in
> one
> >> of the 10 programs.
> >>
> >> Because youth were repeatedly sampled, "participant_ID" is an indicator
> >> for one of about 200 participants.
> >>
> >> "sample_ID" is an indicator unique for each program (it was made from
> the
> >> program_ID, the date, and which of one of four samples it was for that
> >> date). There are about 20 unique values for it for each program, from
> >> around 200 values total.
> >>
> >>
> >>
> >> Does "site" = "program"?
> >> Are participants queried at multiple timepoints? If pre- and
> >> post-program, could this be included as a factor with levels "before"
> and
> >> "afte
> >>
> >>
> >> Yes, the sampling consisted of repeated measures within participant
> >> (around 15-20 responses per participant). It's a bit tricky for me to
> >> describe, but as I mentioned above every youth in the same program was
> >> notified to answer questions at the same time, though both the instance
> in
> >> time and the interval between these questions differed between the 10
> >> programs.
> >>
> >>
> >>
> >> Do you have any particular hypotheses or questions you want to answer
> >> with your model?
> >>
> >>
> >> We're interested in, for a lack of a better word, time point or
> >> situation-specific ("sample_ID") variables' relationships with
> engagement.
> >> We coded video of the programs, including before and when youth were
> >> notified to respond, for example, the type of activity youth were
> >> participating in (i.e., working in groups or individually; doing
> hands-on
> >> activities or listening to the activity leaders). We imagine considering
> >> these as categorical variables.
> >>
> >> Similarly, we're interested in relationships between youth's
> >> characteristics (such as pre-program interest and demographic
> >> characteristics, such as gender) and our outcomes and to a bit of a
> lesser
> >> extent relationships between some program factors and outcomes (though
> with
> >> only 10 programs, we do not imagine we will have statistical power to
> >> detect any / many effects at that level).
> >>
> >> We're interested in sources of variance as a substantive question (how
> >> much of students' engagement is explained by time-point ("sample_ID"),
> >> youth ("participant_ID"), and program ("program_ID") effects?). Though
> this
> >> is a bit secondary to our questions about the specific variables at
> >> time-point, youth, and program levels.
> >>
> >>
> >>
> >> Best wishes, Evan
> >>
> >>
> >>
> >>
> >>
> >> --
> >> Joshua Rosenbergjmichaelrosenberg at gmail.comhttp://joshuamrosenberg.com
> >>
> >>
> >>
> >> --
> >> Diana Michl, M.A.
> >> PhD candidate
> >> International Experimental
> >> and Clinical Linguistics
> >> Universit?t Potsdamwww.ling.uni-potsdam.de/staff/dmichlwww.
> duoinfernale.eu
> >>
> >>
> >
> >
> > --
> > Joshua Rosenberg
> > jmichaelrosenberg at gmail.com
> > http://joshuamrosenberg.com
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Joshua Rosenberg
jmichaelrosenberg at gmail.com
http://joshuamrosenberg.com

	[[alternative HTML version deleted]]


From dakotajudo at mac.com  Tue Apr 25 17:19:59 2017
From: dakotajudo at mac.com (Peter Claussen)
Date: Tue, 25 Apr 2017 10:19:59 -0500
Subject: [R-sig-ME] GLMM for Combined experiments and overdispersed data
In-Reply-To: <587C2021-8337-4F20-A6D7-C4A1BA18186B@mac.com>
References: <CAF5W3aRX0+K7Js0Kkuy1KEgJ86oiB_0i7ZYNMBxS9_A8znWtLA@mail.gmail.com>
 <CAJuCY5z+Axd_LRhG8n+HWYHatFi6d-cD3RWu8ey0fs=EQb7Hxg@mail.gmail.com>
 <CAF5W3aT2mn2qB0Xe8-vzsMJqvL2zS3T1mcjjDe3=TJyGDQaBgw@mail.gmail.com>
 <9522B3B8-9E62-41C3-A376-BEE819F3A07A@mac.com>
 <CAJuCY5yty3kDY9FHAsP1GYky7RM410v4MMctwVPqvNc62=tKvg@mail.gmail.com>
 <CAF5W3aRjrnCmjVRFCk5OdOnVYwtxcgkfWDb9Xf03DjYAq6KaHA@mail.gmail.com>
 <587C2021-8337-4F20-A6D7-C4A1BA18186B@mac.com>
Message-ID: <A357BC8A-0584-420D-881C-4F591177E179@mac.com>

 Should read ?glm?, un-autocorrected.

> On Apr 25, 2017, at 9:29 AM, Peter Claussen <dakotajudo at mac.com> wrote:
> 
> So what do you gain by using glmer as opposed to gem with a quasibinomial family?


	[[alternative HTML version deleted]]


From voigt.charlotte at web.de  Thu Apr 27 18:39:04 2017
From: voigt.charlotte at web.de (voigt.charlotte at web.de)
Date: Thu, 27 Apr 2017 18:39:04 +0200
Subject: [R-sig-ME] question about nlmer
Message-ID: <trinity-56d4d99d-1948-404a-a67d-8c3cc0847aa7-1493311144007@3capp-webde-bap27>

Hi everyone,

I am using lme4 to fit nonlinear mixed effects models to biological systems.
Those systems describe reaction networks mathematically expressed in ODEs.
To include these ODEs in a mixed model, I wrote a function returning a value vector and a gradient attribute.
I want to use optimizers that also use gradient informations of the residuals, eg the L-BFGS-B from the optimx package.
?
The nlmer fits are slow in my case. So I checked some things and noticed that the gradient attribute returned by my nonlinear function is not passed to the optimizer.
So I guess the optimizer calculates its own gradients via finite differences.
Is that really the case and is there a possibility to pass the gradient attributes to the optimizer?
I would be grateful for an answer. If you have any further questions regarding the actual problem, please just ask.
Best,
Charlotte


From joaquin.aldabe at gmail.com  Fri Apr 28 15:32:07 2017
From: joaquin.aldabe at gmail.com (=?UTF-8?Q?Joaqu=C3=ADn_Aldabe?=)
Date: Fri, 28 Apr 2017 10:32:07 -0300
Subject: [R-sig-ME] mixed model?
Message-ID: <CAMM93=+auhauyBjo2c3tq_EoSU_xNjpTV9DU39rFGXE6fNcnJw@mail.gmail.com>

Dear all, I'm analysing bird presence/absence in 16 grassland fields over 4
seasons (different years) and want to know the effect of grass height and
forest cover on presence/absence of the species. Grass height varied among
season but not forest cover in each field. So we have a spatial dimension
and a time dimension. I tried a binomial glm but wonder if I should use
generalized linear mixed models with field identity as the random as I have
repeated measures (bird counts) in each field.

I appreciate your opinion.

Thanks in advanced,

Joaquin Aldabe.

-- 
*Joaqu?n Aldabe*

*Grupo Biodiversidad, Ambiente y Sociedad*
Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha

*Departamento de Conservaci?n*
Aves Uruguay
BirdLife International
Canelones 1164, Montevideo

https://sites.google.com/site/joaquin.aldabe
<https://sites.google.com/site/perfilprofesionaljoaquinaldabe>

	[[alternative HTML version deleted]]


From mensurationist at gmail.com  Tue Apr 25 05:07:14 2017
From: mensurationist at gmail.com (Andrew Robinson)
Date: Tue, 25 Apr 2017 13:07:14 +1000
Subject: [R-sig-ME] Hi listers
In-Reply-To: <f71fdcb07ea04cedab70204bbc3d9b3c@SYXPR01MB1614.ausprd01.prod.outlook.com>
References: <748020203.8771905.1493089094920.ref@mail.yahoo.com>
 <f71fdcb07ea04cedab70204bbc3d9b3c@SYXPR01MB1614.ausprd01.prod.outlook.com>
Message-ID: <d9d10ad3-f6ac-4de1-bf39-2fc591cd8989@Spark>

Generate them all from the Uniform distribution and then transform them to the distribution of your choice.

Cheers,

Andrew

On 25 Apr 2017, 1:00 PM +1000, Said Ali Shah via R-sig-mixed-models <r-sig-mixed-models at r-project.org>, wrote:
> i am conducting a simulation study regarding sample size using multilevel models for longitudinal design, and want to see the effect of non-normal level-II errors now the question is 1. whether i should generate the level-II errors from normal distribution after specifying parameters which are required for the model and then transform these normal errors to non-normal errors? if yes then how to transform them to exponential and log-normal distribution2. i should generate these errors separately from normal as well as from exponential and log normal distributions. keep in mind that both results i.e., for normal and non-normal errors are required. Thanks in advance Regards,
>
> Said Ali Shah
>
>
>
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From M.Fairbrother at bristol.ac.uk  Tue May  2 12:15:03 2017
From: M.Fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Tue, 2 May 2017 12:15:03 +0200
Subject: [R-sig-ME] Hi listers
Message-ID: <CAAH-yP_NeL+-PW1dO+6Pt5gO5RN8_baegj454O5u0cv36mrSrg@mail.gmail.com>

Hi Said,

In the online supplementary information for my article available here (
https://doi.org/10.1017/psrm.2013.24), you can find R code for such
simulations, testing the impact of a skew-normal distribution for the
random intercepts.

Co-authors and I also tried a Chi-sq distribution in simulation studies for
this paper:
https://www.researchgate.net/publication/299604336_Fixed_and_Random_effects_making_an_informed_choice
I can send you R code for that too, if you're interested.

Others may be interested to know that non-normality doesn't seem to make
much difference.

Best wishes,
Malcolm


Dr Malcolm Fairbrother
Reader in Global Policy and Politics
School of Geographical Sciences  ?  Cabot Institute  ?  Centre for
Multilevel Modelling
University of Bristol





Date: Tue, 25 Apr 2017 13:07:14 +1000
> From: Andrew Robinson <mensurationist at gmail.com>
> To: "=?utf-8?Q?R-sig-mixed-models=40r-project.org?="
>         <R-sig-mixed-models at r-project.org>, Said Ali Shah
>         <said_lect06 at yahoo.com>
> Subject: Re: [R-sig-ME] Hi listers
>
> Generate them all from the Uniform distribution and then transform them to
> the distribution of your choice.
>
> Cheers,
>
> Andrew
>
> On 25 Apr 2017, 1:00 PM +1000, Said Ali Shah via R-sig-mixed-models <
> r-sig-mixed-models at r-project.org>, wrote:
> > i am conducting a simulation study regarding sample size using
> multilevel models for longitudinal design, and want to see the effect of
> non-normal level-II errors now the question is 1. whether i should generate
> the level-II errors from normal distribution after specifying parameters
> which are required for the model and then transform these normal errors to
> non-normal errors? if yes then how to transform them to exponential and
> log-normal distribution2. i should generate these errors separately from
> normal as well as from exponential and log normal distributions. keep in
> mind that both results i.e., for normal and non-normal errors are required.
> Thanks in advance Regards,
> >
> > Said Ali Shah
>

	[[alternative HTML version deleted]]


From simonesantoro77 at gmail.com  Tue May  2 18:20:52 2017
From: simonesantoro77 at gmail.com (simone santoro)
Date: Tue, 2 May 2017 18:20:52 +0200
Subject: [R-sig-ME] zero-inflation and multimodal count distribution
Message-ID: <CAO_Dm+MEEPzGh9Jo77qF+RdvjqdJGHPa4c_9=7Jh_jyPyhsnEA@mail.gmail.com>

Hi all,


I am trying to test a hypothesis regarding the different contribution of
sons and daughters to parents? fitness. I have a number of (bird) nests of
which I have measured a feature of parents related to their quality
(continuous variable) that I hypothesize affects the future lifetime
fecundity of their sons and daughters.

Specifically, my hypothesis is that at high values of parents? quality sons
will be more fecund than sisters through their entire life and vice versa,
at low values of parents? quality, daughters will be more than brothers.


Note that sons and daughters of a nest, of which I have recorded their
lifetime fecundity, are born all the same year. Thus, year of birth (of
sons and daughters) is a random intercept I want to control for as it is
the nest identity. The data set may be arranged in two ways, one that
considers a row for each nest and another that considers a row for each
offspring (son or daughter).


In case 1 (row = nest), I have these variables: FN, family name; YEAR,
birth year of sons and daughter; nDescBySons, lifetime total number of
progeny generated by sons (pooled);  nDescByDaughs, lifetime total number
of progeny generated by daughters (pooled); nSons, number of sons; nDaughs,
number of daughters; parQuality, parents? quality.

In case 2 (row = son or daughter), I have these variables: FN, family name;
YEAR, birth year of sons and daughter; nDesc, lifetime total number of
progeny generated by the individual; sex, son or daughter; nestSize, total
number of sons and daughters at nest; parQuality, parents? quality.


In a way, I think that the second arrangement of data is easier to be
analyzed for testing my hypothesis (comment/suggestion on this?). In this
way I have direct information on the individual-level lifetime fecundity of
sons and daughters and have not necessarily to take care of how many sons
and daughters were at the nest.
However, I have lot of zeros (many sons and daughters disappear ? die or
emigrate - and have no recorded descendants at all) and data have a kind of
bimodal distribution after the zero mode (see below image):

https://drive.google.com/open?id=0BwsTfIcebsrOZnljSW9uQXF2UU0


Thus, I would use a zero-inflated GLMM as, for instance, by using glmmTMB
package in R. Something like this:

glmmTMB(nDesc ~ parQuality*sex+(1|NF)+(1|YEAR),?, zi~1)

But, what about that ?ugly? multimodal distribution? I thought I may try
different distributions (e.g. poisson, compois, any other?) and compare the
model fit by looking at the AIC.

Any advice on this would be extremely appreciated.


Simone

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue May  2 18:31:51 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 2 May 2017 12:31:51 -0400
Subject: [R-sig-ME] zero-inflation and multimodal count distribution
In-Reply-To: <CAO_Dm+MEEPzGh9Jo77qF+RdvjqdJGHPa4c_9=7Jh_jyPyhsnEA@mail.gmail.com>
References: <CAO_Dm+MEEPzGh9Jo77qF+RdvjqdJGHPa4c_9=7Jh_jyPyhsnEA@mail.gmail.com>
Message-ID: <b0742e17-720e-8b04-ecaf-870fee125420@gmail.com>



On 17-05-02 12:20 PM, simone santoro wrote:
> Hi all,
> 
> I am trying to test a hypothesis regarding the different contribution of
> sons and daughters to parents? fitness. I have a number of (bird) nests of
> which I have measured a feature of parents related to their quality
> (continuous variable) that I hypothesize affects the future lifetime
> fecundity of their sons and daughters.
> 
> Specifically, my hypothesis is that at high values of parents? quality sons
> will be more fecund than sisters through their entire life and vice versa,
> at low values of parents? quality, daughters will be more than brothers.
> 
> 
> Note that sons and daughters of a nest, of which I have recorded their
> lifetime fecundity, are born all the same year. Thus, year of birth (of
> sons and daughters) is a random intercept I want to control for as it is
> the nest identity. The data set may be arranged in two ways, one that
> considers a row for each nest and another that considers a row for each
> offspring (son or daughter).
> 
> 
> In case 1 (row = nest), I have these variables: FN, family name; YEAR,
> birth year of sons and daughter; nDescBySons, lifetime total number of
> progeny generated by sons (pooled);  nDescByDaughs, lifetime total number
> of progeny generated by daughters (pooled); nSons, number of sons; nDaughs,
> number of daughters; parQuality, parents? quality.
> 
> In case 2 (row = son or daughter), I have these variables: FN, family name;
> YEAR, birth year of sons and daughter; nDesc, lifetime total number of
> progeny generated by the individual; sex, son or daughter; nestSize, total
> number of sons and daughters at nest; parQuality, parents? quality.
> 
> 
> In a way, I think that the second arrangement of data is easier to be
> analyzed for testing my hypothesis (comment/suggestion on this?). In this
> way I have direct information on the individual-level lifetime fecundity of
> sons and daughters and have not necessarily to take care of how many sons
> and daughters were at the nest.
> However, I have lot of zeros (many sons and daughters disappear ? die or
> emigrate - and have no recorded descendants at all) and data have a kind of
> bimodal distribution after the zero mode (see below image):
> 
> https://drive.google.com/open?id=0BwsTfIcebsrOZnljSW9uQXF2UU0
> 
> 
> Thus, I would use a zero-inflated GLMM as, for instance, by using glmmTMB
> package in R. Something like this:
> 
> glmmTMB(nDesc ~ parQuality*sex+(1|NF)+(1|YEAR),?, zi~1)
> 
> But, what about that ?ugly? multimodal distribution? I thought I may try
> different distributions (e.g. poisson, compois, any other?) and compare the
> model fit by looking at the AIC.
> 
> Any advice on this would be extremely appreciated.
> 
> 
> Simone
> 

   My main thought is that your plots show the *marginal* distribution
of the data.  Differences among families/years or odd shapes of the
parental quality distribution could drive this pattern without any need
to assume the *conditional* distribution is multimodal.  Fit a sensible
model (like the one you suggest) and then check diagnostics in various
ways (if you have enough data, you could consider interactions between
sex and parental quality and the random effects -- e.g. does parental
quality matter more in some birth years than others?)


From ecp52 at cornell.edu  Tue May  2 19:17:33 2017
From: ecp52 at cornell.edu (Evan Palmer-Young)
Date: Tue, 2 May 2017 13:17:33 -0400
Subject: [R-sig-ME] mixed model?
In-Reply-To: <CAMM93=+auhauyBjo2c3tq_EoSU_xNjpTV9DU39rFGXE6fNcnJw@mail.gmail.com>
References: <CAMM93=+auhauyBjo2c3tq_EoSU_xNjpTV9DU39rFGXE6fNcnJw@mail.gmail.com>
Message-ID: <CAAge6+4gD6PNS4+uCtaWZs0mwu9=kRTXVr8nwkQkYyQm+ygKjQ@mail.gmail.com>

Joaquin,
It looks like you could use Year and Field as random effects, since there
might be variation in bird abundance across years, and similarly, variation
across fields.

So in this case your model is
Birdmodel<- glmer(Presence~ GrassHeight * ForestCover + (1|Year) +
(1|Field), data=BirdData, family =                  "binomial")

Alternatively you could use Year as a fixed effect, if you are interested
in particular years.
Another option is to include interaction terms as random effects, eg
(1|Field:GrassHeight), to allow the effect of GrassHeight to vary across
fields.


On Fri, Apr 28, 2017 at 9:32 AM, Joaqu?n Aldabe <joaquin.aldabe at gmail.com>
wrote:

> Dear all, I'm analysing bird presence/absence in 16 grassland fields over 4
> seasons (different years) and want to know the effect of grass height and
> forest cover on presence/absence of the species. Grass height varied among
> season but not forest cover in each field. So we have a spatial dimension
> and a time dimension. I tried a binomial glm but wonder if I should use
> generalized linear mixed models with field identity as the random as I have
> repeated measures (bird counts) in each field.
>
> I appreciate your opinion.
>
> Thanks in advanced,
>
> Joaquin Aldabe.
>
> --
> *Joaqu?n Aldabe*
>
> *Grupo Biodiversidad, Ambiente y Sociedad*
> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>
> *Departamento de Conservaci?n*
> Aves Uruguay
> BirdLife International
> Canelones 1164, Montevideo
>
> https://sites.google.com/site/joaquin.aldabe
> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models




-- 
Evan Palmer-Young
PhD candidate
Department of Biology
221 Morrill Science Center
611 North Pleasant St
Amherst MA 01003
https://scholar.google.com/citations?user=VGvOypoAAAAJ&hl=en
https://sites.google.com/a/cornell.edu/evan-palmer-young/
epalmery at cns.umass.edu
ecp52 at cornell.edu

	[[alternative HTML version deleted]]


From joaquin.aldabe at gmail.com  Tue May  2 19:36:59 2017
From: joaquin.aldabe at gmail.com (=?UTF-8?Q?Joaqu=C3=ADn_Aldabe?=)
Date: Tue, 2 May 2017 14:36:59 -0300
Subject: [R-sig-ME] mixed model?
In-Reply-To: <CAAge6+4gD6PNS4+uCtaWZs0mwu9=kRTXVr8nwkQkYyQm+ygKjQ@mail.gmail.com>
References: <CAMM93=+auhauyBjo2c3tq_EoSU_xNjpTV9DU39rFGXE6fNcnJw@mail.gmail.com>
 <CAAge6+4gD6PNS4+uCtaWZs0mwu9=kRTXVr8nwkQkYyQm+ygKjQ@mail.gmail.com>
Message-ID: <CAMM93=LShEHgDQZnEFDzq_Pd2aH9o9-ELX9nKF03HqRDed_bUA@mail.gmail.com>

Thankyou very much Evan. I?ll try that!
Cheers,
Joaqu?n.

2017-05-02 14:17 GMT-03:00 Evan Palmer-Young <ecp52 at cornell.edu>:

> Joaquin,
> It looks like you could use Year and Field as random effects, since there
> might be variation in bird abundance across years, and similarly, variation
> across fields.
>
> So in this case your model is
> Birdmodel<- glmer(Presence~ GrassHeight * ForestCover + (1|Year) +
> (1|Field), data=BirdData, family =                  "binomial")
>
> Alternatively you could use Year as a fixed effect, if you are interested
> in particular years.
> Another option is to include interaction terms as random effects, eg
> (1|Field:GrassHeight), to allow the effect of GrassHeight to vary across
> fields.
>
>
> On Fri, Apr 28, 2017 at 9:32 AM, Joaqu?n Aldabe <joaquin.aldabe at gmail.com>
> wrote:
>
>> Dear all, I'm analysing bird presence/absence in 16 grassland fields over
>> 4
>> seasons (different years) and want to know the effect of grass height and
>> forest cover on presence/absence of the species. Grass height varied among
>> season but not forest cover in each field. So we have a spatial dimension
>> and a time dimension. I tried a binomial glm but wonder if I should use
>> generalized linear mixed models with field identity as the random as I
>> have
>> repeated measures (bird counts) in each field.
>>
>> I appreciate your opinion.
>>
>> Thanks in advanced,
>>
>> Joaquin Aldabe.
>>
>> --
>> *Joaqu?n Aldabe*
>>
>> *Grupo Biodiversidad, Ambiente y Sociedad*
>> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
>> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>>
>> *Departamento de Conservaci?n*
>> Aves Uruguay
>> BirdLife International
>> Canelones 1164, Montevideo
>>
>> https://sites.google.com/site/joaquin.aldabe
>> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
>
> --
> Evan Palmer-Young
> PhD candidate
> Department of Biology
> 221 Morrill Science Center
> 611 North Pleasant St
> Amherst MA 01003
> https://scholar.google.com/citations?user=VGvOypoAAAAJ&hl=en
> https://sites.google.com/a/cornell.edu/evan-palmer-young/
> epalmery at cns.umass.edu
> ecp52 at cornell.edu
>



-- 
*Joaqu?n Aldabe*

*Grupo Biodiversidad, Ambiente y Sociedad*
Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha

*Departamento de Conservaci?n*
Aves Uruguay
BirdLife International
Canelones 1164, Montevideo

https://sites.google.com/site/joaquin.aldabe
<https://sites.google.com/site/perfilprofesionaljoaquinaldabe>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue May  2 19:49:17 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 2 May 2017 13:49:17 -0400
Subject: [R-sig-ME] mixed model?
In-Reply-To: <CAMM93=LShEHgDQZnEFDzq_Pd2aH9o9-ELX9nKF03HqRDed_bUA@mail.gmail.com>
References: <CAMM93=+auhauyBjo2c3tq_EoSU_xNjpTV9DU39rFGXE6fNcnJw@mail.gmail.com>
 <CAAge6+4gD6PNS4+uCtaWZs0mwu9=kRTXVr8nwkQkYyQm+ygKjQ@mail.gmail.com>
 <CAMM93=LShEHgDQZnEFDzq_Pd2aH9o9-ELX9nKF03HqRDed_bUA@mail.gmail.com>
Message-ID: <CABghstQm26axNayxUnovx12pjzWQaL17p3rmeNdXpJq7SB+DPQ@mail.gmail.com>

Minor correction: if GrassHeight is a continuous variable then you
need (GrassHeight|Field) to model the among-Field variation in the
effect of grass height.  If GrassHeight is categorical, then
(GrassHeight|Field) will also work, but it will fit an unstructured
variance-covariance model (n*(n+1)/2 parameters for an n-level
categorical predictor), whereas (1|Field/GrassHeight) would fit a
(positive) compound-symmetric model for the variation in grass height
effects among fields (2 parameters instead of n*(n+1)/2)

On Tue, May 2, 2017 at 1:36 PM, Joaqu?n Aldabe <joaquin.aldabe at gmail.com> wrote:
> Thankyou very much Evan. I?ll try that!
> Cheers,
> Joaqu?n.
>
> 2017-05-02 14:17 GMT-03:00 Evan Palmer-Young <ecp52 at cornell.edu>:
>
>> Joaquin,
>> It looks like you could use Year and Field as random effects, since there
>> might be variation in bird abundance across years, and similarly, variation
>> across fields.
>>
>> So in this case your model is
>> Birdmodel<- glmer(Presence~ GrassHeight * ForestCover + (1|Year) +
>> (1|Field), data=BirdData, family =                  "binomial")
>>
>> Alternatively you could use Year as a fixed effect, if you are interested
>> in particular years.
>> Another option is to include interaction terms as random effects, eg
>> (1|Field:GrassHeight), to allow the effect of GrassHeight to vary across
>> fields.
>>
>>
>> On Fri, Apr 28, 2017 at 9:32 AM, Joaqu?n Aldabe <joaquin.aldabe at gmail.com>
>> wrote:
>>
>>> Dear all, I'm analysing bird presence/absence in 16 grassland fields over
>>> 4
>>> seasons (different years) and want to know the effect of grass height and
>>> forest cover on presence/absence of the species. Grass height varied among
>>> season but not forest cover in each field. So we have a spatial dimension
>>> and a time dimension. I tried a binomial glm but wonder if I should use
>>> generalized linear mixed models with field identity as the random as I
>>> have
>>> repeated measures (bird counts) in each field.
>>>
>>> I appreciate your opinion.
>>>
>>> Thanks in advanced,
>>>
>>> Joaquin Aldabe.
>>>
>>> --
>>> *Joaqu?n Aldabe*
>>>
>>> *Grupo Biodiversidad, Ambiente y Sociedad*
>>> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
>>> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>>>
>>> *Departamento de Conservaci?n*
>>> Aves Uruguay
>>> BirdLife International
>>> Canelones 1164, Montevideo
>>>
>>> https://sites.google.com/site/joaquin.aldabe
>>> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>>
>> --
>> Evan Palmer-Young
>> PhD candidate
>> Department of Biology
>> 221 Morrill Science Center
>> 611 North Pleasant St
>> Amherst MA 01003
>> https://scholar.google.com/citations?user=VGvOypoAAAAJ&hl=en
>> https://sites.google.com/a/cornell.edu/evan-palmer-young/
>> epalmery at cns.umass.edu
>> ecp52 at cornell.edu
>>
>
>
>
> --
> *Joaqu?n Aldabe*
>
> *Grupo Biodiversidad, Ambiente y Sociedad*
> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>
> *Departamento de Conservaci?n*
> Aves Uruguay
> BirdLife International
> Canelones 1164, Montevideo
>
> https://sites.google.com/site/joaquin.aldabe
> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From joaquin.aldabe at gmail.com  Tue May  2 19:56:57 2017
From: joaquin.aldabe at gmail.com (=?UTF-8?Q?Joaqu=C3=ADn_Aldabe?=)
Date: Tue, 2 May 2017 14:56:57 -0300
Subject: [R-sig-ME] mixed model?
In-Reply-To: <CABghstQm26axNayxUnovx12pjzWQaL17p3rmeNdXpJq7SB+DPQ@mail.gmail.com>
References: <CAMM93=+auhauyBjo2c3tq_EoSU_xNjpTV9DU39rFGXE6fNcnJw@mail.gmail.com>
 <CAAge6+4gD6PNS4+uCtaWZs0mwu9=kRTXVr8nwkQkYyQm+ygKjQ@mail.gmail.com>
 <CAMM93=LShEHgDQZnEFDzq_Pd2aH9o9-ELX9nKF03HqRDed_bUA@mail.gmail.com>
 <CABghstQm26axNayxUnovx12pjzWQaL17p3rmeNdXpJq7SB+DPQ@mail.gmail.com>
Message-ID: <CAMM93=KzzH+m3_bfnxk7i-oSfkKS_XOYaGZF22JbKs-LNQCJ0Q@mail.gmail.com>

Thanks Ben. In this case I considered grass height as continuous. Is it
fine to consider year as random effect with only 4 years?
Best,
Joaqu?n

2017-05-02 14:49 GMT-03:00 Ben Bolker <bbolker at gmail.com>:

> Minor correction: if GrassHeight is a continuous variable then you
> need (GrassHeight|Field) to model the among-Field variation in the
> effect of grass height.  If GrassHeight is categorical, then
> (GrassHeight|Field) will also work, but it will fit an unstructured
> variance-covariance model (n*(n+1)/2 parameters for an n-level
> categorical predictor), whereas (1|Field/GrassHeight) would fit a
> (positive) compound-symmetric model for the variation in grass height
> effects among fields (2 parameters instead of n*(n+1)/2)
>
> On Tue, May 2, 2017 at 1:36 PM, Joaqu?n Aldabe <joaquin.aldabe at gmail.com>
> wrote:
> > Thankyou very much Evan. I?ll try that!
> > Cheers,
> > Joaqu?n.
> >
> > 2017-05-02 14:17 GMT-03:00 Evan Palmer-Young <ecp52 at cornell.edu>:
> >
> >> Joaquin,
> >> It looks like you could use Year and Field as random effects, since
> there
> >> might be variation in bird abundance across years, and similarly,
> variation
> >> across fields.
> >>
> >> So in this case your model is
> >> Birdmodel<- glmer(Presence~ GrassHeight * ForestCover + (1|Year) +
> >> (1|Field), data=BirdData, family =                  "binomial")
> >>
> >> Alternatively you could use Year as a fixed effect, if you are
> interested
> >> in particular years.
> >> Another option is to include interaction terms as random effects, eg
> >> (1|Field:GrassHeight), to allow the effect of GrassHeight to vary across
> >> fields.
> >>
> >>
> >> On Fri, Apr 28, 2017 at 9:32 AM, Joaqu?n Aldabe <
> joaquin.aldabe at gmail.com>
> >> wrote:
> >>
> >>> Dear all, I'm analysing bird presence/absence in 16 grassland fields
> over
> >>> 4
> >>> seasons (different years) and want to know the effect of grass height
> and
> >>> forest cover on presence/absence of the species. Grass height varied
> among
> >>> season but not forest cover in each field. So we have a spatial
> dimension
> >>> and a time dimension. I tried a binomial glm but wonder if I should use
> >>> generalized linear mixed models with field identity as the random as I
> >>> have
> >>> repeated measures (bird counts) in each field.
> >>>
> >>> I appreciate your opinion.
> >>>
> >>> Thanks in advanced,
> >>>
> >>> Joaquin Aldabe.
> >>>
> >>> --
> >>> *Joaqu?n Aldabe*
> >>>
> >>> *Grupo Biodiversidad, Ambiente y Sociedad*
> >>> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> >>> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
> >>>
> >>> *Departamento de Conservaci?n*
> >>> Aves Uruguay
> >>> BirdLife International
> >>> Canelones 1164, Montevideo
> >>>
> >>> https://sites.google.com/site/joaquin.aldabe
> >>> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
> >>>
> >>>         [[alternative HTML version deleted]]
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >>
> >>
> >>
> >> --
> >> Evan Palmer-Young
> >> PhD candidate
> >> Department of Biology
> >> 221 Morrill Science Center
> >> 611 North Pleasant St
> >> Amherst MA 01003
> >> https://scholar.google.com/citations?user=VGvOypoAAAAJ&hl=en
> >> https://sites.google.com/a/cornell.edu/evan-palmer-young/
> >> epalmery at cns.umass.edu
> >> ecp52 at cornell.edu
> >>
> >
> >
> >
> > --
> > *Joaqu?n Aldabe*
> >
> > *Grupo Biodiversidad, Ambiente y Sociedad*
> > Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> > Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
> >
> > *Departamento de Conservaci?n*
> > Aves Uruguay
> > BirdLife International
> > Canelones 1164, Montevideo
> >
> > https://sites.google.com/site/joaquin.aldabe
> > <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
*Joaqu?n Aldabe*

*Grupo Biodiversidad, Ambiente y Sociedad*
Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha

*Departamento de Conservaci?n*
Aves Uruguay
BirdLife International
Canelones 1164, Montevideo

https://sites.google.com/site/joaquin.aldabe
<https://sites.google.com/site/perfilprofesionaljoaquinaldabe>

	[[alternative HTML version deleted]]


From ecp52 at cornell.edu  Tue May  2 21:03:06 2017
From: ecp52 at cornell.edu (Evan Palmer-Young)
Date: Tue, 2 May 2017 15:03:06 -0400
Subject: [R-sig-ME] mixed model?
In-Reply-To: <CAMM93=KzzH+m3_bfnxk7i-oSfkKS_XOYaGZF22JbKs-LNQCJ0Q@mail.gmail.com>
References: <CAMM93=+auhauyBjo2c3tq_EoSU_xNjpTV9DU39rFGXE6fNcnJw@mail.gmail.com>
 <CAAge6+4gD6PNS4+uCtaWZs0mwu9=kRTXVr8nwkQkYyQm+ygKjQ@mail.gmail.com>
 <CAMM93=LShEHgDQZnEFDzq_Pd2aH9o9-ELX9nKF03HqRDed_bUA@mail.gmail.com>
 <CABghstQm26axNayxUnovx12pjzWQaL17p3rmeNdXpJq7SB+DPQ@mail.gmail.com>
 <CAMM93=KzzH+m3_bfnxk7i-oSfkKS_XOYaGZF22JbKs-LNQCJ0Q@mail.gmail.com>
Message-ID: <CAAge6+5qHKTTjTFwDaLu9EOtbo5MArpxWYzqZd0_2tn9mUNa8A@mail.gmail.com>

There is a thorough but readable discussion of the fixed-or-random
consideration at the glmm wiki.
http://glmm.wikidot.com/faq, administrated by Prof. Bolker.
See the heading:
Should I treat factor xxx as fixed or random?
You'll also find plenty of useful tips for model coding and
troubleshooting, consideration of p-values, and a separate page for package
comparison.
http://glmm.wikidot.com/pkg-comparison

On Tue, May 2, 2017 at 1:56 PM, Joaqu?n Aldabe <joaquin.aldabe at gmail.com>
wrote:

> Thanks Ben. In this case I considered grass height as continuous. Is it
> fine to consider year as random effect with only 4 years?
> Best,
> Joaqu?n
>
> 2017-05-02 14:49 GMT-03:00 Ben Bolker <bbolker at gmail.com>:
>
>> Minor correction: if GrassHeight is a continuous variable then you
>> need (GrassHeight|Field) to model the among-Field variation in the
>> effect of grass height.  If GrassHeight is categorical, then
>> (GrassHeight|Field) will also work, but it will fit an unstructured
>> variance-covariance model (n*(n+1)/2 parameters for an n-level
>> categorical predictor), whereas (1|Field/GrassHeight) would fit a
>> (positive) compound-symmetric model for the variation in grass height
>> effects among fields (2 parameters instead of n*(n+1)/2)
>>
>> On Tue, May 2, 2017 at 1:36 PM, Joaqu?n Aldabe <joaquin.aldabe at gmail.com>
>> wrote:
>> > Thankyou very much Evan. I?ll try that!
>> > Cheers,
>> > Joaqu?n.
>> >
>> > 2017-05-02 14:17 GMT-03:00 Evan Palmer-Young <ecp52 at cornell.edu>:
>> >
>> >> Joaquin,
>> >> It looks like you could use Year and Field as random effects, since
>> there
>> >> might be variation in bird abundance across years, and similarly,
>> variation
>> >> across fields.
>> >>
>> >> So in this case your model is
>> >> Birdmodel<- glmer(Presence~ GrassHeight * ForestCover + (1|Year) +
>> >> (1|Field), data=BirdData, family =                  "binomial")
>> >>
>> >> Alternatively you could use Year as a fixed effect, if you are
>> interested
>> >> in particular years.
>> >> Another option is to include interaction terms as random effects, eg
>> >> (1|Field:GrassHeight), to allow the effect of GrassHeight to vary
>> across
>> >> fields.
>> >>
>> >>
>> >> On Fri, Apr 28, 2017 at 9:32 AM, Joaqu?n Aldabe <
>> joaquin.aldabe at gmail.com>
>> >> wrote:
>> >>
>> >>> Dear all, I'm analysing bird presence/absence in 16 grassland fields
>> over
>> >>> 4
>> >>> seasons (different years) and want to know the effect of grass height
>> and
>> >>> forest cover on presence/absence of the species. Grass height varied
>> among
>> >>> season but not forest cover in each field. So we have a spatial
>> dimension
>> >>> and a time dimension. I tried a binomial glm but wonder if I should
>> use
>> >>> generalized linear mixed models with field identity as the random as I
>> >>> have
>> >>> repeated measures (bird counts) in each field.
>> >>>
>> >>> I appreciate your opinion.
>> >>>
>> >>> Thanks in advanced,
>> >>>
>> >>> Joaquin Aldabe.
>> >>>
>> >>> --
>> >>> *Joaqu?n Aldabe*
>> >>>
>> >>> *Grupo Biodiversidad, Ambiente y Sociedad*
>> >>> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
>> >>> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>> >>>
>> >>> *Departamento de Conservaci?n*
>> >>> Aves Uruguay
>> >>> BirdLife International
>> >>> Canelones 1164, Montevideo
>> >>>
>> >>> https://sites.google.com/site/joaquin.aldabe
>> >>> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>> >>>
>> >>>         [[alternative HTML version deleted]]
>> >>>
>> >>> _______________________________________________
>> >>> R-sig-mixed-models at r-project.org mailing list
>> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >>
>> >>
>> >>
>> >>
>> >> --
>> >> Evan Palmer-Young
>> >> PhD candidate
>> >> Department of Biology
>> >> 221 Morrill Science Center
>> >> 611 North Pleasant St
>> >> Amherst MA 01003
>> >> https://scholar.google.com/citations?user=VGvOypoAAAAJ&hl=en
>> >> https://sites.google.com/a/cornell.edu/evan-palmer-young/
>> >> epalmery at cns.umass.edu
>> >> ecp52 at cornell.edu
>> >>
>> >
>> >
>> >
>> > --
>> > *Joaqu?n Aldabe*
>> >
>> > *Grupo Biodiversidad, Ambiente y Sociedad*
>> > Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
>> > Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>> >
>> > *Departamento de Conservaci?n*
>> > Aves Uruguay
>> > BirdLife International
>> > Canelones 1164, Montevideo
>> >
>> > https://sites.google.com/site/joaquin.aldabe
>> > <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
> *Joaqu?n Aldabe*
>
> *Grupo Biodiversidad, Ambiente y Sociedad*
> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>
> *Departamento de Conservaci?n*
> Aves Uruguay
> BirdLife International
> Canelones 1164, Montevideo
>
> https://sites.google.com/site/joaquin.aldabe
> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>
>
>
>


-- 
Evan Palmer-Young
PhD candidate
Department of Biology
221 Morrill Science Center
611 North Pleasant St
Amherst MA 01003
https://scholar.google.com/citations?user=VGvOypoAAAAJ&hl=en
https://sites.google.com/a/cornell.edu/evan-palmer-young/
epalmery at cns.umass.edu
ecp52 at cornell.edu

	[[alternative HTML version deleted]]


From ecp52 at cornell.edu  Tue May  2 21:11:13 2017
From: ecp52 at cornell.edu (Evan Palmer-Young)
Date: Tue, 2 May 2017 15:11:13 -0400
Subject: [R-sig-ME] mixed model?
In-Reply-To: <CAAge6+5qHKTTjTFwDaLu9EOtbo5MArpxWYzqZd0_2tn9mUNa8A@mail.gmail.com>
References: <CAMM93=+auhauyBjo2c3tq_EoSU_xNjpTV9DU39rFGXE6fNcnJw@mail.gmail.com>
 <CAAge6+4gD6PNS4+uCtaWZs0mwu9=kRTXVr8nwkQkYyQm+ygKjQ@mail.gmail.com>
 <CAMM93=LShEHgDQZnEFDzq_Pd2aH9o9-ELX9nKF03HqRDed_bUA@mail.gmail.com>
 <CABghstQm26axNayxUnovx12pjzWQaL17p3rmeNdXpJq7SB+DPQ@mail.gmail.com>
 <CAMM93=KzzH+m3_bfnxk7i-oSfkKS_XOYaGZF22JbKs-LNQCJ0Q@mail.gmail.com>
 <CAAge6+5qHKTTjTFwDaLu9EOtbo5MArpxWYzqZd0_2tn9mUNa8A@mail.gmail.com>
Message-ID: <CAAge6+7Qw9Ah2fMVrm3N5vgPb2Jvyfqh8GWJ+Tceh0Sh0y+w6Q@mail.gmail.com>

Ah, I saw in another thread the link to the updated version, now in github:
http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#nested-or-crossed

On Tue, May 2, 2017 at 3:03 PM, Evan Palmer-Young <ecp52 at cornell.edu> wrote:

> There is a thorough but readable discussion of the fixed-or-random
> consideration at the glmm wiki.
> http://glmm.wikidot.com/faq, administrated by Prof. Bolker.
> See the heading:
> Should I treat factor xxx as fixed or random?
> You'll also find plenty of useful tips for model coding and
> troubleshooting, consideration of p-values, and a separate page for package
> comparison.
> http://glmm.wikidot.com/pkg-comparison
>
> On Tue, May 2, 2017 at 1:56 PM, Joaqu?n Aldabe <joaquin.aldabe at gmail.com>
> wrote:
>
>> Thanks Ben. In this case I considered grass height as continuous. Is it
>> fine to consider year as random effect with only 4 years?
>> Best,
>> Joaqu?n
>>
>> 2017-05-02 14:49 GMT-03:00 Ben Bolker <bbolker at gmail.com>:
>>
>>> Minor correction: if GrassHeight is a continuous variable then you
>>> need (GrassHeight|Field) to model the among-Field variation in the
>>> effect of grass height.  If GrassHeight is categorical, then
>>> (GrassHeight|Field) will also work, but it will fit an unstructured
>>> variance-covariance model (n*(n+1)/2 parameters for an n-level
>>> categorical predictor), whereas (1|Field/GrassHeight) would fit a
>>> (positive) compound-symmetric model for the variation in grass height
>>> effects among fields (2 parameters instead of n*(n+1)/2)
>>>
>>> On Tue, May 2, 2017 at 1:36 PM, Joaqu?n Aldabe <joaquin.aldabe at gmail.com>
>>> wrote:
>>> > Thankyou very much Evan. I?ll try that!
>>> > Cheers,
>>> > Joaqu?n.
>>> >
>>> > 2017-05-02 14:17 GMT-03:00 Evan Palmer-Young <ecp52 at cornell.edu>:
>>> >
>>> >> Joaquin,
>>> >> It looks like you could use Year and Field as random effects, since
>>> there
>>> >> might be variation in bird abundance across years, and similarly,
>>> variation
>>> >> across fields.
>>> >>
>>> >> So in this case your model is
>>> >> Birdmodel<- glmer(Presence~ GrassHeight * ForestCover + (1|Year) +
>>> >> (1|Field), data=BirdData, family =                  "binomial")
>>> >>
>>> >> Alternatively you could use Year as a fixed effect, if you are
>>> interested
>>> >> in particular years.
>>> >> Another option is to include interaction terms as random effects, eg
>>> >> (1|Field:GrassHeight), to allow the effect of GrassHeight to vary
>>> across
>>> >> fields.
>>> >>
>>> >>
>>> >> On Fri, Apr 28, 2017 at 9:32 AM, Joaqu?n Aldabe <
>>> joaquin.aldabe at gmail.com>
>>> >> wrote:
>>> >>
>>> >>> Dear all, I'm analysing bird presence/absence in 16 grassland fields
>>> over
>>> >>> 4
>>> >>> seasons (different years) and want to know the effect of grass
>>> height and
>>> >>> forest cover on presence/absence of the species. Grass height varied
>>> among
>>> >>> season but not forest cover in each field. So we have a spatial
>>> dimension
>>> >>> and a time dimension. I tried a binomial glm but wonder if I should
>>> use
>>> >>> generalized linear mixed models with field identity as the random as
>>> I
>>> >>> have
>>> >>> repeated measures (bird counts) in each field.
>>> >>>
>>> >>> I appreciate your opinion.
>>> >>>
>>> >>> Thanks in advanced,
>>> >>>
>>> >>> Joaquin Aldabe.
>>> >>>
>>> >>> --
>>> >>> *Joaqu?n Aldabe*
>>> >>>
>>> >>> *Grupo Biodiversidad, Ambiente y Sociedad*
>>> >>> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
>>> >>> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>>> >>>
>>> >>> *Departamento de Conservaci?n*
>>> >>> Aves Uruguay
>>> >>> BirdLife International
>>> >>> Canelones 1164, Montevideo
>>> >>>
>>> >>> https://sites.google.com/site/joaquin.aldabe
>>> >>> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>>> >>>
>>> >>>         [[alternative HTML version deleted]]
>>> >>>
>>> >>> _______________________________________________
>>> >>> R-sig-mixed-models at r-project.org mailing list
>>> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> >>
>>> >>
>>> >>
>>> >>
>>> >> --
>>> >> Evan Palmer-Young
>>> >> PhD candidate
>>> >> Department of Biology
>>> >> 221 Morrill Science Center
>>> >> 611 North Pleasant St
>>> >> Amherst MA 01003
>>> >> https://scholar.google.com/citations?user=VGvOypoAAAAJ&hl=en
>>> >> https://sites.google.com/a/cornell.edu/evan-palmer-young/
>>> >> epalmery at cns.umass.edu
>>> >> ecp52 at cornell.edu
>>> >>
>>> >
>>> >
>>> >
>>> > --
>>> > *Joaqu?n Aldabe*
>>> >
>>> > *Grupo Biodiversidad, Ambiente y Sociedad*
>>> > Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
>>> > Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>>> >
>>> > *Departamento de Conservaci?n*
>>> > Aves Uruguay
>>> > BirdLife International
>>> > Canelones 1164, Montevideo
>>> >
>>> > https://sites.google.com/site/joaquin.aldabe
>>> > <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>>> >
>>> >         [[alternative HTML version deleted]]
>>> >
>>> > _______________________________________________
>>> > R-sig-mixed-models at r-project.org mailing list
>>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>>
>> --
>> *Joaqu?n Aldabe*
>>
>> *Grupo Biodiversidad, Ambiente y Sociedad*
>> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
>> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>>
>> *Departamento de Conservaci?n*
>> Aves Uruguay
>> BirdLife International
>> Canelones 1164, Montevideo
>>
>> https://sites.google.com/site/joaquin.aldabe
>> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>>
>>
>>
>>
>
>
> --
> Evan Palmer-Young
> PhD candidate
> Department of Biology
> 221 Morrill Science Center
> 611 North Pleasant St
> Amherst MA 01003
> https://scholar.google.com/citations?user=VGvOypoAAAAJ&hl=en
> https://sites.google.com/a/cornell.edu/evan-palmer-young/
> epalmery at cns.umass.edu
> ecp52 at cornell.edu
>



-- 
Evan Palmer-Young
PhD candidate
Department of Biology
221 Morrill Science Center
611 North Pleasant St
Amherst MA 01003
https://scholar.google.com/citations?user=VGvOypoAAAAJ&hl=en
https://sites.google.com/a/cornell.edu/evan-palmer-young/
epalmery at cns.umass.edu
ecp52 at cornell.edu

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed May  3 00:19:27 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 2 May 2017 18:19:27 -0400
Subject: [R-sig-ME] mixed model?
In-Reply-To: <CAMM93=KzzH+m3_bfnxk7i-oSfkKS_XOYaGZF22JbKs-LNQCJ0Q@mail.gmail.com>
References: <CAMM93=+auhauyBjo2c3tq_EoSU_xNjpTV9DU39rFGXE6fNcnJw@mail.gmail.com>
 <CAAge6+4gD6PNS4+uCtaWZs0mwu9=kRTXVr8nwkQkYyQm+ygKjQ@mail.gmail.com>
 <CAMM93=LShEHgDQZnEFDzq_Pd2aH9o9-ELX9nKF03HqRDed_bUA@mail.gmail.com>
 <CABghstQm26axNayxUnovx12pjzWQaL17p3rmeNdXpJq7SB+DPQ@mail.gmail.com>
 <CAMM93=KzzH+m3_bfnxk7i-oSfkKS_XOYaGZF22JbKs-LNQCJ0Q@mail.gmail.com>
Message-ID: <5f72bfb3-0405-35b7-ba56-2918110b8b55@gmail.com>


  It's a little difficult.
  Unless you have very large sample sizes per year or very small noise
levels, it's quite likely that lme4 and friends will collapse the
among-year variance to zero in this case, which may be anticonservative.
 You have a variety of choices, none of them super-easy or universally
appropriate:

 - collect more data (hah!)
 - fit year as a fixed effect
 - fit year as a random effect and accept the risk of getting a
completely pooled model
 - use some form of regularization to push the variance away from zero
(e.g., blmer)
 - go completely Bayesian/MCMC, e.g. brms/MCMCglmm (you'll probably
still need an informative prior to get the model to converge)

  Someone has also pointed to the GLMM FAQ.

On 17-05-02 01:56 PM, Joaqu?n Aldabe wrote:
> Thanks Ben. In this case I considered grass height as continuous. Is it
> fine to consider year as random effect with only 4 years?
> Best, 
> Joaqu?n
> 
> 2017-05-02 14:49 GMT-03:00 Ben Bolker <bbolker at gmail.com
> <mailto:bbolker at gmail.com>>:
> 
>     Minor correction: if GrassHeight is a continuous variable then you
>     need (GrassHeight|Field) to model the among-Field variation in the
>     effect of grass height.  If GrassHeight is categorical, then
>     (GrassHeight|Field) will also work, but it will fit an unstructured
>     variance-covariance model (n*(n+1)/2 parameters for an n-level
>     categorical predictor), whereas (1|Field/GrassHeight) would fit a
>     (positive) compound-symmetric model for the variation in grass height
>     effects among fields (2 parameters instead of n*(n+1)/2)
> 
>     On Tue, May 2, 2017 at 1:36 PM, Joaqu?n Aldabe
>     <joaquin.aldabe at gmail.com <mailto:joaquin.aldabe at gmail.com>> wrote:
>     > Thankyou very much Evan. I?ll try that!
>     > Cheers,
>     > Joaqu?n.
>     >
>     > 2017-05-02 14:17 GMT-03:00 Evan Palmer-Young <ecp52 at cornell.edu
>     <mailto:ecp52 at cornell.edu>>:
>     >
>     >> Joaquin,
>     >> It looks like you could use Year and Field as random effects,
>     since there
>     >> might be variation in bird abundance across years, and similarly,
>     variation
>     >> across fields.
>     >>
>     >> So in this case your model is
>     >> Birdmodel<- glmer(Presence~ GrassHeight * ForestCover + (1|Year) +
>     >> (1|Field), data=BirdData, family =                  "binomial")
>     >>
>     >> Alternatively you could use Year as a fixed effect, if you are
>     interested
>     >> in particular years.
>     >> Another option is to include interaction terms as random effects, eg
>     >> (1|Field:GrassHeight), to allow the effect of GrassHeight to vary
>     across
>     >> fields.
>     >>
>     >>
>     >> On Fri, Apr 28, 2017 at 9:32 AM, Joaqu?n Aldabe
>     <joaquin.aldabe at gmail.com <mailto:joaquin.aldabe at gmail.com>>
>     >> wrote:
>     >>
>     >>> Dear all, I'm analysing bird presence/absence in 16 grassland
>     fields over
>     >>> 4
>     >>> seasons (different years) and want to know the effect of grass
>     height and
>     >>> forest cover on presence/absence of the species. Grass height
>     varied among
>     >>> season but not forest cover in each field. So we have a spatial
>     dimension
>     >>> and a time dimension. I tried a binomial glm but wonder if I
>     should use
>     >>> generalized linear mixed models with field identity as the
>     random as I
>     >>> have
>     >>> repeated measures (bird counts) in each field.
>     >>>
>     >>> I appreciate your opinion.
>     >>>
>     >>> Thanks in advanced,
>     >>>
>     >>> Joaquin Aldabe.
>     >>>
>     >>> --
>     >>> *Joaqu?n Aldabe*
>     >>>
>     >>> *Grupo Biodiversidad, Ambiente y Sociedad*
>     >>> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
>     >>> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>     >>>
>     >>> *Departamento de Conservaci?n*
>     >>> Aves Uruguay
>     >>> BirdLife International
>     >>> Canelones 1164, Montevideo
>     >>>
>     >>> https://sites.google.com/site/joaquin.aldabe
>     <https://sites.google.com/site/joaquin.aldabe>
>     >>> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe
>     <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>>
>     >>>
>     >>>         [[alternative HTML version deleted]]
>     >>>
>     >>> _______________________________________________
>     >>> R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >>
>     >>
>     >>
>     >>
>     >> --
>     >> Evan Palmer-Young
>     >> PhD candidate
>     >> Department of Biology
>     >> 221 Morrill Science Center
>     >> 611 North Pleasant St
>     >> Amherst MA 01003
>     >> https://scholar.google.com/citations?user=VGvOypoAAAAJ&hl=en
>     <https://scholar.google.com/citations?user=VGvOypoAAAAJ&hl=en>
>     >> https://sites.google.com/a/cornell.edu/evan-palmer-young/
>     <https://sites.google.com/a/cornell.edu/evan-palmer-young/>
>     >> epalmery at cns.umass.edu <mailto:epalmery at cns.umass.edu>
>     >> ecp52 at cornell.edu <mailto:ecp52 at cornell.edu>
>     >>
>     >
>     >
>     >
>     > --
>     > *Joaqu?n Aldabe*
>     >
>     > *Grupo Biodiversidad, Ambiente y Sociedad*
>     > Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
>     > Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>     >
>     > *Departamento de Conservaci?n*
>     > Aves Uruguay
>     > BirdLife International
>     > Canelones 1164, Montevideo
>     >
>     > https://sites.google.com/site/joaquin.aldabe
>     <https://sites.google.com/site/joaquin.aldabe>
>     > <https://sites.google.com/site/perfilprofesionaljoaquinaldabe
>     <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>>
>     >
>     >         [[alternative HTML version deleted]]
>     >
>     > _______________________________________________
>     > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> 
> 
> 
> 
> -- 
> *Joaqu?n Aldabe*
> 
> /Grupo Biodiversidad, Ambiente y Sociedad/
> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha  
>                                                            
> /Departamento de Conservaci?n/
> Aves Uruguay
> BirdLife International
> Canelones 1164, Montevideo
> 
> https://sites.google.com/site/joaquin.aldabe
> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
> 
> 
>


From joaquin.aldabe at gmail.com  Wed May  3 14:34:54 2017
From: joaquin.aldabe at gmail.com (=?UTF-8?Q?Joaqu=C3=ADn_Aldabe?=)
Date: Wed, 3 May 2017 09:34:54 -0300
Subject: [R-sig-ME] mixed model?
In-Reply-To: <5f72bfb3-0405-35b7-ba56-2918110b8b55@gmail.com>
References: <CAMM93=+auhauyBjo2c3tq_EoSU_xNjpTV9DU39rFGXE6fNcnJw@mail.gmail.com>
 <CAAge6+4gD6PNS4+uCtaWZs0mwu9=kRTXVr8nwkQkYyQm+ygKjQ@mail.gmail.com>
 <CAMM93=LShEHgDQZnEFDzq_Pd2aH9o9-ELX9nKF03HqRDed_bUA@mail.gmail.com>
 <CABghstQm26axNayxUnovx12pjzWQaL17p3rmeNdXpJq7SB+DPQ@mail.gmail.com>
 <CAMM93=KzzH+m3_bfnxk7i-oSfkKS_XOYaGZF22JbKs-LNQCJ0Q@mail.gmail.com>
 <5f72bfb3-0405-35b7-ba56-2918110b8b55@gmail.com>
Message-ID: <CAMM93=KzCA2owz5i9MSCPON5yBsG_g7JXgB26WjGeda_bJX3ZQ@mail.gmail.com>

Thanks Ben. I'll work on those options.
Cheers,
Joaquin

2017-05-02 19:19 GMT-03:00 Ben Bolker <bbolker at gmail.com>:

>
>   It's a little difficult.
>   Unless you have very large sample sizes per year or very small noise
> levels, it's quite likely that lme4 and friends will collapse the
> among-year variance to zero in this case, which may be anticonservative.
>  You have a variety of choices, none of them super-easy or universally
> appropriate:
>
>  - collect more data (hah!)
>  - fit year as a fixed effect
>  - fit year as a random effect and accept the risk of getting a
> completely pooled model
>  - use some form of regularization to push the variance away from zero
> (e.g., blmer)
>  - go completely Bayesian/MCMC, e.g. brms/MCMCglmm (you'll probably
> still need an informative prior to get the model to converge)
>
>   Someone has also pointed to the GLMM FAQ.
>
> On 17-05-02 01:56 PM, Joaqu?n Aldabe wrote:
> > Thanks Ben. In this case I considered grass height as continuous. Is it
> > fine to consider year as random effect with only 4 years?
> > Best,
> > Joaqu?n
> >
> > 2017-05-02 14:49 GMT-03:00 Ben Bolker <bbolker at gmail.com
> > <mailto:bbolker at gmail.com>>:
> >
> >     Minor correction: if GrassHeight is a continuous variable then you
> >     need (GrassHeight|Field) to model the among-Field variation in the
> >     effect of grass height.  If GrassHeight is categorical, then
> >     (GrassHeight|Field) will also work, but it will fit an unstructured
> >     variance-covariance model (n*(n+1)/2 parameters for an n-level
> >     categorical predictor), whereas (1|Field/GrassHeight) would fit a
> >     (positive) compound-symmetric model for the variation in grass height
> >     effects among fields (2 parameters instead of n*(n+1)/2)
> >
> >     On Tue, May 2, 2017 at 1:36 PM, Joaqu?n Aldabe
> >     <joaquin.aldabe at gmail.com <mailto:joaquin.aldabe at gmail.com>> wrote:
> >     > Thankyou very much Evan. I?ll try that!
> >     > Cheers,
> >     > Joaqu?n.
> >     >
> >     > 2017-05-02 14:17 GMT-03:00 Evan Palmer-Young <ecp52 at cornell.edu
> >     <mailto:ecp52 at cornell.edu>>:
> >     >
> >     >> Joaquin,
> >     >> It looks like you could use Year and Field as random effects,
> >     since there
> >     >> might be variation in bird abundance across years, and similarly,
> >     variation
> >     >> across fields.
> >     >>
> >     >> So in this case your model is
> >     >> Birdmodel<- glmer(Presence~ GrassHeight * ForestCover + (1|Year) +
> >     >> (1|Field), data=BirdData, family =                  "binomial")
> >     >>
> >     >> Alternatively you could use Year as a fixed effect, if you are
> >     interested
> >     >> in particular years.
> >     >> Another option is to include interaction terms as random effects,
> eg
> >     >> (1|Field:GrassHeight), to allow the effect of GrassHeight to vary
> >     across
> >     >> fields.
> >     >>
> >     >>
> >     >> On Fri, Apr 28, 2017 at 9:32 AM, Joaqu?n Aldabe
> >     <joaquin.aldabe at gmail.com <mailto:joaquin.aldabe at gmail.com>>
> >     >> wrote:
> >     >>
> >     >>> Dear all, I'm analysing bird presence/absence in 16 grassland
> >     fields over
> >     >>> 4
> >     >>> seasons (different years) and want to know the effect of grass
> >     height and
> >     >>> forest cover on presence/absence of the species. Grass height
> >     varied among
> >     >>> season but not forest cover in each field. So we have a spatial
> >     dimension
> >     >>> and a time dimension. I tried a binomial glm but wonder if I
> >     should use
> >     >>> generalized linear mixed models with field identity as the
> >     random as I
> >     >>> have
> >     >>> repeated measures (bird counts) in each field.
> >     >>>
> >     >>> I appreciate your opinion.
> >     >>>
> >     >>> Thanks in advanced,
> >     >>>
> >     >>> Joaquin Aldabe.
> >     >>>
> >     >>> --
> >     >>> *Joaqu?n Aldabe*
> >     >>>
> >     >>> *Grupo Biodiversidad, Ambiente y Sociedad*
> >     >>> Centro Universitario de la Regi?n Este, Universidad de la
> Rep?blica
> >     >>> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
> >     >>>
> >     >>> *Departamento de Conservaci?n*
> >     >>> Aves Uruguay
> >     >>> BirdLife International
> >     >>> Canelones 1164, Montevideo
> >     >>>
> >     >>> https://sites.google.com/site/joaquin.aldabe
> >     <https://sites.google.com/site/joaquin.aldabe>
> >     >>> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe
> >     <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>>
> >     >>>
> >     >>>         [[alternative HTML version deleted]]
> >     >>>
> >     >>> _______________________________________________
> >     >>> R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >     >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >     >>
> >     >>
> >     >>
> >     >>
> >     >> --
> >     >> Evan Palmer-Young
> >     >> PhD candidate
> >     >> Department of Biology
> >     >> 221 Morrill Science Center
> >     >> 611 North Pleasant St
> >     >> Amherst MA 01003
> >     >> https://scholar.google.com/citations?user=VGvOypoAAAAJ&hl=en
> >     <https://scholar.google.com/citations?user=VGvOypoAAAAJ&hl=en>
> >     >> https://sites.google.com/a/cornell.edu/evan-palmer-young/
> >     <https://sites.google.com/a/cornell.edu/evan-palmer-young/>
> >     >> epalmery at cns.umass.edu <mailto:epalmery at cns.umass.edu>
> >     >> ecp52 at cornell.edu <mailto:ecp52 at cornell.edu>
> >     >>
> >     >
> >     >
> >     >
> >     > --
> >     > *Joaqu?n Aldabe*
> >     >
> >     > *Grupo Biodiversidad, Ambiente y Sociedad*
> >     > Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> >     > Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
> >     >
> >     > *Departamento de Conservaci?n*
> >     > Aves Uruguay
> >     > BirdLife International
> >     > Canelones 1164, Montevideo
> >     >
> >     > https://sites.google.com/site/joaquin.aldabe
> >     <https://sites.google.com/site/joaquin.aldabe>
> >     > <https://sites.google.com/site/perfilprofesionaljoaquinaldabe
> >     <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>>
> >     >
> >     >         [[alternative HTML version deleted]]
> >     >
> >     > _______________________________________________
> >     > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >
> >
> >
> >
> > --
> > *Joaqu?n Aldabe*
> >
> > /Grupo Biodiversidad, Ambiente y Sociedad/
> > Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> > Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
> >
> > /Departamento de Conservaci?n/
> > Aves Uruguay
> > BirdLife International
> > Canelones 1164, Montevideo
> >
> > https://sites.google.com/site/joaquin.aldabe
> > <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
> >
> >
> >
>



-- 
*Joaqu?n Aldabe*

*Grupo Biodiversidad, Ambiente y Sociedad*
Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha

*Departamento de Conservaci?n*
Aves Uruguay
BirdLife International
Canelones 1164, Montevideo

https://sites.google.com/site/joaquin.aldabe
<https://sites.google.com/site/perfilprofesionaljoaquinaldabe>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed May  3 20:06:43 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 3 May 2017 14:06:43 -0400
Subject: [R-sig-ME] zero-inflation and multimodal count distribution
In-Reply-To: <CAO_Dm+MZ9m7=Ny4ACXMgjDXgsLJzOO7L6OsEUji8JJgzyS2UUQ@mail.gmail.com>
References: <CAO_Dm+MEEPzGh9Jo77qF+RdvjqdJGHPa4c_9=7Jh_jyPyhsnEA@mail.gmail.com>
 <b0742e17-720e-8b04-ecaf-870fee125420@gmail.com>
 <CAO_Dm+MZ9m7=Ny4ACXMgjDXgsLJzOO7L6OsEUji8JJgzyS2UUQ@mail.gmail.com>
Message-ID: <CABghstRGakK6Xa6+hr2GjDAgOy1xo-Q1gF6KwgmPQ9OHZu2iaA@mail.gmail.com>

[Please keep r-sig-mixed-models at r-project.org in the Cc: ...]

On Wed, May 3, 2017 at 1:43 PM, simone santoro
<simonesantoro77 at gmail.com> wrote:
> Thank you for observing that, it makes much sense!
> I have being exploring better the data and have realized that the response
> variable varies greatly among years in a way that might explain why the
> multimodal marginal distribution. I have also tried different combinations
> of random intercepts/slopes and have found that the best fit is achieved by
> defining nest identity and year as (independent) random intercepts
> {(1|NF)+(1|YEAR)}. Now, I would refine my modelling approach and have tried
> to model these data in a different way.
>
> As told in the previous mail, actually, I am interested in testing whether
> the ratio of sons relative to daughters contribution in terms of number of
> descendants (nDesc) depends on the non-additive effect of parental quality
> (parQuality). Then, I have tried a zero-inflated binomial and betabinomial
> family. In these cases I have considered as response variable the number of
> descendants generated by each individual (son or daughter), i.e. nDesc,
> relative to the sum of descendants (sumDesc) generated by the whole nest
> (sons + daughters). My response variable is therefore: nDesc/sumDesc
>
> I would think that a betabinomial distribution might be better because I
> know that the response variable has lot of zeros and lot of 1. By the way:
> do exist zero-one-inflated beta (mixed) models as that discussed here?
>
> Thus I try the betabinomial first:
> tmbBetaBinomial<- glmmTMB(nDesc/sumDesc ~ parQuality*sex+(1|NF)+(1|YEAR),?,
> zi~1,family= list(family="betabinomial",link="logit"), weights= sumDesc)
> and I get this warning message:
>
> Warning message:
> In nlminb(start = par, objective = fn, gradient = gr) :
>   NA/NaN function evaluation

  This is probably a harmless error message.  It just means that the
optimizer wandered into illegal territory somewhere along the way.
>
>
> Then I try the binomial:
> tmbBinomial<- glmmTMB(nDesc/sumDesc ~ parQuality*sex+(1|NF)+(1|YEAR),?,
> zi~1,family= binomial, weights= sumDesc)
> I get no warning messages.
>
> This is the summary of the betabinomial glmm:
>
>>summary(tmbBetaBinomial)
> Family: betabinomial  ( logit )
> Formula:          nDesc/sumDesc ~ parQuality * sex + (1 | NF) + (1 | YEAR)
> Zero inflation:                  ~1
> Data: ind
> Weights: sumDesc
>
>      AIC      BIC   logLik deviance df.resid
>   5939.0   5983.4  -2961.5   5923.0     1886
>
> Random effects:
>
> Conditional model:
>  Groups  Name        Variance  Std.Dev.
>  NF (Intercept) 4.130e-09 6.426e-05
>  YEAR    (Intercept) 1.328e+00 1.152e+00
> Number of obs: 1894, groups:  NF, 719; YEAR, 24
>
> Overdispersion parameter for betabinomial family (): 0.38
>
> Conditional model:
>                Estimate Std. Error z value Pr(>|z|)
> (Intercept)    0.099863   0.355641   0.281    0.779
> parQuality        0.001557   0.004606   0.338    0.735
> sexmal         0.002171   0.350213   0.006    0.995
> parQuality:sexmal 0.000784   0.006104   0.128    0.898
>
> Zero-inflation model:
>             Estimate Std. Error z value Pr(>|z|)
> (Intercept)    -27.8    64568.8       0        1
>
>
> There is a strange z value for the zero-inflation model, what could it mean?

It means that the model tried to reduce the zero-inflation component
to zero.  It fits the zero-inflation probability on a logit scale, so
it can't make it *exactly* zero, but it can make it very very close.
Note that the NF variance is also effectively zero (std dev 10^5 times
smaller than the YEAR variance and about 10 times smaller than the
smallest-magnitude fixed effect). The AIC/log-likelihood for this
model are much better than for the binomial GLMM, so (alas) I would
advise you to take this model instead.

  In any case I think you should try plotting (or otherwise
inspecting) the predictions from both models, to understand what
they're saying.
>
> This is the summary of the binomial glmm:
>
> Family: binomial  ( logit )
> Formula:          nDesc/sumDesc ~ parQuality * sex + (1 | NF) + (1 | YEAR)
> Zero inflation:                  ~1
> Data: ind
> Weights: sumDesc
>
>      AIC      BIC   logLik deviance df.resid
>   6841.9   6880.8  -3414.0   6827.9     1887
>
> Random effects:
>
> Conditional model:
>  Groups  Name        Variance  Std.Dev.
>  NF (Intercept) 3.646e+01 6.0381644
>  YEAR    (Intercept) 1.090e-08 0.0001044
> Number of obs: 1894, groups:  NF, 719; YEAR, 24
>
> Conditional model:
>                 Estimate Std. Error z value Pr(>|z|)
> (Intercept)     7.386051   0.877055   8.421  < 2e-16 ***
> parQuality        -0.007452   0.013641  -0.546  0.58483
> sexmal         -0.649383   0.235775  -2.754  0.00588 **
> parQuality:sexmal  0.009153   0.004007   2.284  0.02235 *
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Zero-inflation model:
>             Estimate Std. Error z value Pr(>|z|)
> (Intercept) -0.03268    0.04625  -0.706     0.48
>
> This would make biological sense to me because I would expect that sons
> ("sexmal") are advantaged relative to their sisters when the parental
> quality is high. However, may I trust this result? is there something that
> you see I am missing?
> Best,
>
> Simone
>
>
>
>
>
> 2017-05-02 18:31 GMT+02:00 Ben Bolker <bbolker at gmail.com>:
>>
>>
>>
>> On 17-05-02 12:20 PM, simone santoro wrote:
>> > Hi all,
>> >
>> > I am trying to test a hypothesis regarding the different contribution of
>> > sons and daughters to parents? fitness. I have a number of (bird) nests
>> > of
>> > which I have measured a feature of parents related to their quality
>> > (continuous variable) that I hypothesize affects the future lifetime
>> > fecundity of their sons and daughters.
>> >
>> > Specifically, my hypothesis is that at high values of parents? quality
>> > sons
>> > will be more fecund than sisters through their entire life and vice
>> > versa,
>> > at low values of parents? quality, daughters will be more than brothers.
>> >
>> >
>> > Note that sons and daughters of a nest, of which I have recorded their
>> > lifetime fecundity, are born all the same year. Thus, year of birth (of
>> > sons and daughters) is a random intercept I want to control for as it is
>> > the nest identity. The data set may be arranged in two ways, one that
>> > considers a row for each nest and another that considers a row for each
>> > offspring (son or daughter).
>> >
>> >
>> > In case 1 (row = nest), I have these variables: FN, family name; YEAR,
>> > birth year of sons and daughter; nDescBySons, lifetime total number of
>> > progeny generated by sons (pooled);  nDescByDaughs, lifetime total
>> > number
>> > of progeny generated by daughters (pooled); nSons, number of sons;
>> > nDaughs,
>> > number of daughters; parQuality, parents? quality.
>> >
>> > In case 2 (row = son or daughter), I have these variables: FN, family
>> > name;
>> > YEAR, birth year of sons and daughter; nDesc, lifetime total number of
>> > progeny generated by the individual; sex, son or daughter; nestSize,
>> > total
>> > number of sons and daughters at nest; parQuality, parents? quality.
>> >
>> >
>> > In a way, I think that the second arrangement of data is easier to be
>> > analyzed for testing my hypothesis (comment/suggestion on this?). In
>> > this
>> > way I have direct information on the individual-level lifetime fecundity
>> > of
>> > sons and daughters and have not necessarily to take care of how many
>> > sons
>> > and daughters were at the nest.
>> > However, I have lot of zeros (many sons and daughters disappear ? die or
>> > emigrate - and have no recorded descendants at all) and data have a kind
>> > of
>> > bimodal distribution after the zero mode (see below image):
>> >
>> > https://drive.google.com/open?id=0BwsTfIcebsrOZnljSW9uQXF2UU0
>> >
>> >
>> > Thus, I would use a zero-inflated GLMM as, for instance, by using
>> > glmmTMB
>> > package in R. Something like this:
>> >
>> > glmmTMB(nDesc ~ parQuality*sex+(1|NF)+(1|YEAR),?, zi~1)
>> >
>> > But, what about that ?ugly? multimodal distribution? I thought I may try
>> > different distributions (e.g. poisson, compois, any other?) and compare
>> > the
>> > model fit by looking at the AIC.
>> >
>> > Any advice on this would be extremely appreciated.
>> >
>> >
>> > Simone
>> >
>>
>>    My main thought is that your plots show the *marginal* distribution
>> of the data.  Differences among families/years or odd shapes of the
>> parental quality distribution could drive this pattern without any need
>> to assume the *conditional* distribution is multimodal.  Fit a sensible
>> model (like the one you suggest) and then check diagnostics in various
>> ways (if you have enough data, you could consider interactions between
>> sex and parental quality and the random effects -- e.g. does parental
>> quality matter more in some birth years than others?)
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


From caiello at usgs.gov  Thu May  4 02:24:02 2017
From: caiello at usgs.gov (Aiello, Christina)
Date: Wed, 3 May 2017 17:24:02 -0700
Subject: [R-sig-ME] persistant autocorrelation in binomial MCMCglmm
Message-ID: <CAA-qTOZQE8DFtc+bvVj4D=kgGdB1A9xvWvRXNaYAqVyPxhDTzQ@mail.gmail.com>

Dear list,

I'm very new to MCMCglmm but have done my best to read-up on Jarrod
Hadfield's package documents, tutorials and various examples posted online
and discussed on this forum. I'm having trouble fitting what I thought was
a fairly simple binomial mixed effects model using MCMCglmm. I'll start by
describing the data, then the model, then my problem and questions:

My dataset is comprised of unique dyads - pairs of animals located at one
of four sites (C1, C2, R1, R2). The response variable, 'contact' indicates
that the dyad did (1) or did not (0) interact over the course of the study.
The unique id of the members of the dyad are 'tort1' and 'tort2'. Because
individuals appear in multiple dyads, I've included a random effect for
tortID using the multiple membership function available in the package to
account for the non-independence of observations and the fact that some
individuals may have a tendency to contact more than others. For fixed
effects, in this simplified model I only have one categorical variable,
'site' (which I would have entered as a random effect but I only have 4
levels) and one continuous variable, 'overlap' - which is an estimate of
space-use similarity for each dyad. I centered and scaled this variable by
the non-zero mean value and standard deviation (though I've also tried the
model without centering). This may be relevant to my problem: 'overlap's
distribution is highly skewed and mostly zero values - similarly, the
response variable 'contact' is rare and characterized by mostly zeros.

> table(datafi$contact, datafi$site)
     C1  C2  R1  R2
  0 241 229 176 181
  1  35  24  14   9

The model:

pr<-list( R= list(V=1,  n=0, fix=1), G= list(G1=list(V=1, n=0.002)) )

m1 <- MCMCglmm(

fixed = contact ~ (1 + site + overlap ) ,

random = ~mm(tort1 +tort2),

data = datafi,

family = "categorical", verbose = FALSE,

pr=TRUE, pl=TRUE, prior=pr,

nitt=4100000 , thin=2000 , burnin= 100000

)
> summary(m1)

 Iterations = 100001:4098001
 Thinning interval  = 2000
 Sample size  = 2000

 DIC: 207.4525

 G-structure:  ~mm(tort1 + tort2)

            post.mean  l-95% CI u-95% CI eff.samp
tort1+tort2     2.128 0.0002693    5.488    414.6

 R-structure:  ~units

      post.mean l-95% CI u-95% CI eff.samp
units         1        1        1        0

 Location effects: contact ~ (1 + site + overlap)

            post.mean l-95% CI u-95% CI eff.samp  pMCMC
(Intercept)   -2.2102  -3.6055  -0.7437   1505.6  0.004 **
siteC2        -0.4143  -2.7572   1.4982   1808.4  0.708
siteR1        -1.2543  -4.0794   0.8424   1069.0  0.268
siteR2        -1.4753  -3.9300   0.9782   1348.9  0.205
overlap        3.9025   2.8273   5.1260    488.5 <5e-04 ***


As far as I can tell, the chains themselves look good and if I run multiple
chains and run the Gelman-Rubin diagnostic, the PSRF values are all 1 or
1.01. The parameter estimates are consistent and make sense. The problem
lies in the autocorrelation - large amounts in the 'overlap' variable and
many of the random intercepts. Here's a sample of the autocorr results:

> sort(diag(autocorr(m1$Sol)[2,,]))
##these are the worst offenders
  (Intercept)    tort1.4534    tort1.3719      tort1.33    tort1.3620
 tort1.30    tort1.3045
 0.0926484964  0.0938622549  0.1009204749  0.1049459123  0.1065261665
 0.1090179501  0.1237642453
       siteR2    tort1.3150    tort1.5579        siteR1    tort1.5473
 tort1.2051    tort1.3092
 0.1339370132  0.1359132027  0.1383816060  0.1506535457  0.1639062068
 0.1682852625  0.1683907054
   tort1.5044     tort1.804    tort1.5141    tort1.5103    tort1.4148
 tort1.4678    tort1.4428
 0.1752670493  0.1767909176  0.1865412328  0.1919929722  0.2257633018
 0.2318115800  0.2521806794
   tort1.3633    tort1.3335    tort1.5101    tort1.3043      tort1.26
 tort1.2014       tort1.6
 0.2577034325  0.2593673083  0.2602145001  0.2717718040  0.3487288823
 0.3748047689  0.4478979043
      overlap
 0.5400325556


> autocorr.diag(m1$VCV)
          tort1+tort2 units
Lag 0      1.00000000   NaN
Lag 2000   0.58292962   NaN
Lag 10000  0.12771910   NaN
Lag 20000  0.05262786   NaN
Lag 1e+05  0.01757316   NaN

I've attempted to fit the model with both uninformative (shown above) and
parameter expanded priors (
pr2<-list( R= list(V=1, n=0, fix=1), G=list(G1=list(V=1, nu=1, alpha.mu=0,
alpha.V=1000)) )), with parameter expanded priors performing slightly
worse. I've attempted incrementally larger iteration, thinning, and burn in
values, increasing the thinning to as high as 2000 with a large burn-in
(100000) in hopes of improving convergence and reducing autocorrelation.
I've tried slice sampling and saw little improvement. Nothing I tried while
retaining this model structure improved the acfs. I checked the latent
variable estimates and all were under 20, with mean of -5.

The only way I was able to reduce the autocorrelation was to fit a model
without the random effect, which isn't ideal as I'm ignoring repeated
measures of individuals among dyads. I've read on this forum that random
effects in binomial models are notoriously hard to estimate with this
package and I've also read that one should not just increase thinning to
deal with the problem (MEE 2012 Link & Eaton
<http://onlinelibrary.wiley.com/store/10.1111/j.2041-210X.2011.00131.x/asset/j.2041-210X.2011.00131.x.pdf?v=1&t=j29nl332&s=e0f97f28309122f2bbfa66bccb0cd445696e2f15>).
Interestingly, I have count responses association with all interacting
dyads and I can fit zero truncated models to those responses just fine with
the same fixed and random effects.

My questions are then:
1) Do you think there is something inherently wrong with the data or just
problems with the mixing algorithms in the context of this data?
2) Are there any other changes to the MCMCglmm specification I might try to
improve mixing? Or any problems with my current specification?
3) Any suggestions on where to go from here?


I would greatly appreciate any insights and happy to provide further info
as needed!

Christina

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Thu May  4 06:31:04 2017
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 4 May 2017 05:31:04 +0100
Subject: [R-sig-ME] persistant autocorrelation in binomial MCMCglmm
In-Reply-To: <CAA-qTOZQE8DFtc+bvVj4D=kgGdB1A9xvWvRXNaYAqVyPxhDTzQ@mail.gmail.com>
References: <CAA-qTOZQE8DFtc+bvVj4D=kgGdB1A9xvWvRXNaYAqVyPxhDTzQ@mail.gmail.com>
Message-ID: <7b6bae07-9eff-0637-5b63-eb7280ffb497@ed.ac.uk>

Hi Christina,

1/ The model syntax looks fine, it is just that MCMCglmm is not very 
efficient for this type of problem. You say there are no numerical 
issues because the latent variable is under 20. However, are they 
commonly under -20?

2/ Centering and scaling the covariates will not effect the mixing 
because MCMCglmm is block updating all location effects.  Moving from a 
logistic model (family="categorical") to a probit model 
(family="threshold") will probably improve mixing, and the inferences 
will be pretty much the same.

3/ You could also up the number of iterations - but perhaps this takes 
too much time? Link and Eaton's recommendation not to thin is fine if 
you are not worried about filling your hard drive. You reduce the Monte 
Carlo error by saving additional correlated samples, but if the total 
number of samples you can store is limited you are better storing 
uncorrelated samples (obtained by thinning) because this reduces the 
Monte Carlo error more.

Cheers,

Jarrod




On 04/05/2017 01:24, Aiello, Christina wrote:
> Dear list,
>
> I'm very new to MCMCglmm but have done my best to read-up on Jarrod
> Hadfield's package documents, tutorials and various examples posted online
> and discussed on this forum. I'm having trouble fitting what I thought was
> a fairly simple binomial mixed effects model using MCMCglmm. I'll start by
> describing the data, then the model, then my problem and questions:
>
> My dataset is comprised of unique dyads - pairs of animals located at one
> of four sites (C1, C2, R1, R2). The response variable, 'contact' indicates
> that the dyad did (1) or did not (0) interact over the course of the study.
> The unique id of the members of the dyad are 'tort1' and 'tort2'. Because
> individuals appear in multiple dyads, I've included a random effect for
> tortID using the multiple membership function available in the package to
> account for the non-independence of observations and the fact that some
> individuals may have a tendency to contact more than others. For fixed
> effects, in this simplified model I only have one categorical variable,
> 'site' (which I would have entered as a random effect but I only have 4
> levels) and one continuous variable, 'overlap' - which is an estimate of
> space-use similarity for each dyad. I centered and scaled this variable by
> the non-zero mean value and standard deviation (though I've also tried the
> model without centering). This may be relevant to my problem: 'overlap's
> distribution is highly skewed and mostly zero values - similarly, the
> response variable 'contact' is rare and characterized by mostly zeros.
>
>> table(datafi$contact, datafi$site)
>       C1  C2  R1  R2
>    0 241 229 176 181
>    1  35  24  14   9
>
> The model:
>
> pr<-list( R= list(V=1,  n=0, fix=1), G= list(G1=list(V=1, n=0.002)) )
>
> m1 <- MCMCglmm(
>
> fixed = contact ~ (1 + site + overlap ) ,
>
> random = ~mm(tort1 +tort2),
>
> data = datafi,
>
> family = "categorical", verbose = FALSE,
>
> pr=TRUE, pl=TRUE, prior=pr,
>
> nitt=4100000 , thin=2000 , burnin= 100000
>
> )
>> summary(m1)
>   Iterations = 100001:4098001
>   Thinning interval  = 2000
>   Sample size  = 2000
>
>   DIC: 207.4525
>
>   G-structure:  ~mm(tort1 + tort2)
>
>              post.mean  l-95% CI u-95% CI eff.samp
> tort1+tort2     2.128 0.0002693    5.488    414.6
>
>   R-structure:  ~units
>
>        post.mean l-95% CI u-95% CI eff.samp
> units         1        1        1        0
>
>   Location effects: contact ~ (1 + site + overlap)
>
>              post.mean l-95% CI u-95% CI eff.samp  pMCMC
> (Intercept)   -2.2102  -3.6055  -0.7437   1505.6  0.004 **
> siteC2        -0.4143  -2.7572   1.4982   1808.4  0.708
> siteR1        -1.2543  -4.0794   0.8424   1069.0  0.268
> siteR2        -1.4753  -3.9300   0.9782   1348.9  0.205
> overlap        3.9025   2.8273   5.1260    488.5 <5e-04 ***
>
>
> As far as I can tell, the chains themselves look good and if I run multiple
> chains and run the Gelman-Rubin diagnostic, the PSRF values are all 1 or
> 1.01. The parameter estimates are consistent and make sense. The problem
> lies in the autocorrelation - large amounts in the 'overlap' variable and
> many of the random intercepts. Here's a sample of the autocorr results:
>
>> sort(diag(autocorr(m1$Sol)[2,,]))
> ##these are the worst offenders
>    (Intercept)    tort1.4534    tort1.3719      tort1.33    tort1.3620
>   tort1.30    tort1.3045
>   0.0926484964  0.0938622549  0.1009204749  0.1049459123  0.1065261665
>   0.1090179501  0.1237642453
>         siteR2    tort1.3150    tort1.5579        siteR1    tort1.5473
>   tort1.2051    tort1.3092
>   0.1339370132  0.1359132027  0.1383816060  0.1506535457  0.1639062068
>   0.1682852625  0.1683907054
>     tort1.5044     tort1.804    tort1.5141    tort1.5103    tort1.4148
>   tort1.4678    tort1.4428
>   0.1752670493  0.1767909176  0.1865412328  0.1919929722  0.2257633018
>   0.2318115800  0.2521806794
>     tort1.3633    tort1.3335    tort1.5101    tort1.3043      tort1.26
>   tort1.2014       tort1.6
>   0.2577034325  0.2593673083  0.2602145001  0.2717718040  0.3487288823
>   0.3748047689  0.4478979043
>        overlap
>   0.5400325556
>
>
>> autocorr.diag(m1$VCV)
>            tort1+tort2 units
> Lag 0      1.00000000   NaN
> Lag 2000   0.58292962   NaN
> Lag 10000  0.12771910   NaN
> Lag 20000  0.05262786   NaN
> Lag 1e+05  0.01757316   NaN
>
> I've attempted to fit the model with both uninformative (shown above) and
> parameter expanded priors (
> pr2<-list( R= list(V=1, n=0, fix=1), G=list(G1=list(V=1, nu=1, alpha.mu=0,
> alpha.V=1000)) )), with parameter expanded priors performing slightly
> worse. I've attempted incrementally larger iteration, thinning, and burn in
> values, increasing the thinning to as high as 2000 with a large burn-in
> (100000) in hopes of improving convergence and reducing autocorrelation.
> I've tried slice sampling and saw little improvement. Nothing I tried while
> retaining this model structure improved the acfs. I checked the latent
> variable estimates and all were under 20, with mean of -5.
>
> The only way I was able to reduce the autocorrelation was to fit a model
> without the random effect, which isn't ideal as I'm ignoring repeated
> measures of individuals among dyads. I've read on this forum that random
> effects in binomial models are notoriously hard to estimate with this
> package and I've also read that one should not just increase thinning to
> deal with the problem (MEE 2012 Link & Eaton
> <http://onlinelibrary.wiley.com/store/10.1111/j.2041-210X.2011.00131.x/asset/j.2041-210X.2011.00131.x.pdf?v=1&t=j29nl332&s=e0f97f28309122f2bbfa66bccb0cd445696e2f15>).
> Interestingly, I have count responses association with all interacting
> dyads and I can fit zero truncated models to those responses just fine with
> the same fixed and random effects.
>
> My questions are then:
> 1) Do you think there is something inherently wrong with the data or just
> problems with the mixing algorithms in the context of this data?
> 2) Are there any other changes to the MCMCglmm specification I might try to
> improve mixing? Or any problems with my current specification?
> 3) Any suggestions on where to go from here?
>
>
> I would greatly appreciate any insights and happy to provide further info
> as needed!
>
> Christina
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From caiello at usgs.gov  Thu May  4 19:17:00 2017
From: caiello at usgs.gov (Aiello, Christina)
Date: Thu, 4 May 2017 10:17:00 -0700
Subject: [R-sig-ME] persistant autocorrelation in binomial MCMCglmm
In-Reply-To: <7b6bae07-9eff-0637-5b63-eb7280ffb497@ed.ac.uk>
References: <CAA-qTOZQE8DFtc+bvVj4D=kgGdB1A9xvWvRXNaYAqVyPxhDTzQ@mail.gmail.com>
 <7b6bae07-9eff-0637-5b63-eb7280ffb497@ed.ac.uk>
Message-ID: <CAA-qTOZS8C8-35-m41qbR3Cn6BbPBFn6thR+2N3DomgW2wR3bQ@mail.gmail.com>

Hi Jarrod,

Appreciate the quick response and thoughts

1) I thought I had checked the absolute value of the latent variables, but
now that I look again, I must not have examined both ends of the
distribution. There are 167 observations whose latent variable
distributions dip below -20 (minimum was -32). In each of these cases, the
left tail of the distribution includes very few estimates at such low
values. Do you think this has to do with the rarity of a response of 1 in
the dataset? Or might this be indicative of another problem?

2) I'll give the probit link a try today and see how the results compare

3) I can definitely let the chains run longer, and continue increasing
thinning? I was hesitant to keep upping the values because I haven't seen
many published analyses using iterations and intervals beyond what I've
been trying. I was worried having to run the chain so long might be
indicative of other underlying problems that I wasn't considering.

Many thanks!
Christina

Christina M. Aiello
Biologist- U.S. Geological Survey
Las Vegas Field Station
160 N. Stephanie St.
Henderson, NV 89074
(702) 481-3957
caiello at usgs.gov

On Wed, May 3, 2017 at 9:31 PM, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:

> Hi Christina,
>
> 1/ The model syntax looks fine, it is just that MCMCglmm is not very
> efficient for this type of problem. You say there are no numerical issues
> because the latent variable is under 20. However, are they commonly under
> -20?
>
> 2/ Centering and scaling the covariates will not effect the mixing because
> MCMCglmm is block updating all location effects.  Moving from a logistic
> model (family="categorical") to a probit model (family="threshold") will
> probably improve mixing, and the inferences will be pretty much the same.
>
> 3/ You could also up the number of iterations - but perhaps this takes too
> much time? Link and Eaton's recommendation not to thin is fine if you are
> not worried about filling your hard drive. You reduce the Monte Carlo error
> by saving additional correlated samples, but if the total number of samples
> you can store is limited you are better storing uncorrelated samples
> (obtained by thinning) because this reduces the Monte Carlo error more.
>
> Cheers,
>
> Jarrod
>
>
>
>
>
> On 04/05/2017 01:24, Aiello, Christina wrote:
>
>> Dear list,
>>
>> I'm very new to MCMCglmm but have done my best to read-up on Jarrod
>> Hadfield's package documents, tutorials and various examples posted online
>> and discussed on this forum. I'm having trouble fitting what I thought was
>> a fairly simple binomial mixed effects model using MCMCglmm. I'll start by
>> describing the data, then the model, then my problem and questions:
>>
>> My dataset is comprised of unique dyads - pairs of animals located at one
>> of four sites (C1, C2, R1, R2). The response variable, 'contact' indicates
>> that the dyad did (1) or did not (0) interact over the course of the
>> study.
>> The unique id of the members of the dyad are 'tort1' and 'tort2'. Because
>> individuals appear in multiple dyads, I've included a random effect for
>> tortID using the multiple membership function available in the package to
>> account for the non-independence of observations and the fact that some
>> individuals may have a tendency to contact more than others. For fixed
>> effects, in this simplified model I only have one categorical variable,
>> 'site' (which I would have entered as a random effect but I only have 4
>> levels) and one continuous variable, 'overlap' - which is an estimate of
>> space-use similarity for each dyad. I centered and scaled this variable by
>> the non-zero mean value and standard deviation (though I've also tried the
>> model without centering). This may be relevant to my problem: 'overlap's
>> distribution is highly skewed and mostly zero values - similarly, the
>> response variable 'contact' is rare and characterized by mostly zeros.
>>
>> table(datafi$contact, datafi$site)
>>>
>>       C1  C2  R1  R2
>>    0 241 229 176 181
>>    1  35  24  14   9
>>
>> The model:
>>
>> pr<-list( R= list(V=1,  n=0, fix=1), G= list(G1=list(V=1, n=0.002)) )
>>
>> m1 <- MCMCglmm(
>>
>> fixed = contact ~ (1 + site + overlap ) ,
>>
>> random = ~mm(tort1 +tort2),
>>
>> data = datafi,
>>
>> family = "categorical", verbose = FALSE,
>>
>> pr=TRUE, pl=TRUE, prior=pr,
>>
>> nitt=4100000 , thin=2000 , burnin= 100000
>>
>> )
>>
>>> summary(m1)
>>>
>>   Iterations = 100001:4098001
>>   Thinning interval  = 2000
>>   Sample size  = 2000
>>
>>   DIC: 207.4525
>>
>>   G-structure:  ~mm(tort1 + tort2)
>>
>>              post.mean  l-95% CI u-95% CI eff.samp
>> tort1+tort2     2.128 0.0002693    5.488    414.6
>>
>>   R-structure:  ~units
>>
>>        post.mean l-95% CI u-95% CI eff.samp
>> units         1        1        1        0
>>
>>   Location effects: contact ~ (1 + site + overlap)
>>
>>              post.mean l-95% CI u-95% CI eff.samp  pMCMC
>> (Intercept)   -2.2102  -3.6055  -0.7437   1505.6  0.004 **
>> siteC2        -0.4143  -2.7572   1.4982   1808.4  0.708
>> siteR1        -1.2543  -4.0794   0.8424   1069.0  0.268
>> siteR2        -1.4753  -3.9300   0.9782   1348.9  0.205
>> overlap        3.9025   2.8273   5.1260    488.5 <5e-04 ***
>>
>>
>> As far as I can tell, the chains themselves look good and if I run
>> multiple
>> chains and run the Gelman-Rubin diagnostic, the PSRF values are all 1 or
>> 1.01. The parameter estimates are consistent and make sense. The problem
>> lies in the autocorrelation - large amounts in the 'overlap' variable and
>> many of the random intercepts. Here's a sample of the autocorr results:
>>
>> sort(diag(autocorr(m1$Sol)[2,,]))
>>>
>> ##these are the worst offenders
>>    (Intercept)    tort1.4534    tort1.3719      tort1.33    tort1.3620
>>   tort1.30    tort1.3045
>>   0.0926484964  0.0938622549  0.1009204749  0.1049459123  0.1065261665
>>   0.1090179501  0.1237642453
>>         siteR2    tort1.3150    tort1.5579        siteR1    tort1.5473
>>   tort1.2051    tort1.3092
>>   0.1339370132  0.1359132027  0.1383816060  0.1506535457  0.1639062068
>>   0.1682852625  0.1683907054
>>     tort1.5044     tort1.804    tort1.5141    tort1.5103    tort1.4148
>>   tort1.4678    tort1.4428
>>   0.1752670493  0.1767909176  0.1865412328  0.1919929722  0.2257633018
>>   0.2318115800  0.2521806794
>>     tort1.3633    tort1.3335    tort1.5101    tort1.3043      tort1.26
>>   tort1.2014       tort1.6
>>   0.2577034325  0.2593673083  0.2602145001  0.2717718040  0.3487288823
>>   0.3748047689  0.4478979043
>>        overlap
>>   0.5400325556
>>
>>
>> autocorr.diag(m1$VCV)
>>>
>>            tort1+tort2 units
>> Lag 0      1.00000000   NaN
>> Lag 2000   0.58292962   NaN
>> Lag 10000  0.12771910   NaN
>> Lag 20000  0.05262786   NaN
>> Lag 1e+05  0.01757316   NaN
>>
>> I've attempted to fit the model with both uninformative (shown above) and
>> parameter expanded priors (
>> pr2<-list( R= list(V=1, n=0, fix=1), G=list(G1=list(V=1, nu=1, alpha.mu
>> =0,
>> alpha.V=1000)) )), with parameter expanded priors performing slightly
>> worse. I've attempted incrementally larger iteration, thinning, and burn
>> in
>> values, increasing the thinning to as high as 2000 with a large burn-in
>> (100000) in hopes of improving convergence and reducing autocorrelation.
>> I've tried slice sampling and saw little improvement. Nothing I tried
>> while
>> retaining this model structure improved the acfs. I checked the latent
>> variable estimates and all were under 20, with mean of -5.
>>
>> The only way I was able to reduce the autocorrelation was to fit a model
>> without the random effect, which isn't ideal as I'm ignoring repeated
>> measures of individuals among dyads. I've read on this forum that random
>> effects in binomial models are notoriously hard to estimate with this
>> package and I've also read that one should not just increase thinning to
>> deal with the problem (MEE 2012 Link & Eaton
>> <http://onlinelibrary.wiley.com/store/10.1111/j.2041-210X.20
>> 11.00131.x/asset/j.2041-210X.2011.00131.x.pdf?v=1&t=j29nl33
>> 2&s=e0f97f28309122f2bbfa66bccb0cd445696e2f15>).
>> Interestingly, I have count responses association with all interacting
>> dyads and I can fit zero truncated models to those responses just fine
>> with
>> the same fixed and random effects.
>>
>> My questions are then:
>> 1) Do you think there is something inherently wrong with the data or just
>> problems with the mixing algorithms in the context of this data?
>> 2) Are there any other changes to the MCMCglmm specification I might try
>> to
>> improve mixing? Or any problems with my current specification?
>> 3) Any suggestions on where to go from here?
>>
>>
>> I would greatly appreciate any insights and happy to provide further info
>> as needed!
>>
>> Christina
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>
>

	[[alternative HTML version deleted]]


From caiello at usgs.gov  Fri May  5 23:03:40 2017
From: caiello at usgs.gov (Aiello, Christina)
Date: Fri, 5 May 2017 14:03:40 -0700
Subject: [R-sig-ME] persistant autocorrelation in binomial MCMCglmm
In-Reply-To: <CAA-qTOZS8C8-35-m41qbR3Cn6BbPBFn6thR+2N3DomgW2wR3bQ@mail.gmail.com>
References: <CAA-qTOZQE8DFtc+bvVj4D=kgGdB1A9xvWvRXNaYAqVyPxhDTzQ@mail.gmail.com>
 <7b6bae07-9eff-0637-5b63-eb7280ffb497@ed.ac.uk>
 <CAA-qTOZS8C8-35-m41qbR3Cn6BbPBFn6thR+2N3DomgW2wR3bQ@mail.gmail.com>
Message-ID: <CAA-qTOb6WKP7_4aa=o9+eQp030sNrN6YYm7RVj842x0RJ11FGQ@mail.gmail.com>

Hi Jarrod,

I have an update on the model performance with a probit link - the
autocorrelation is much better behaved with the "threshold" family. All ACF
values are <0.1 for iteration and thinning #s that were resulting in
autocorrelation using the logit link.

Looking at the latent variables, though, a lot of the distributions
included values below -7 (lowest was -10). All of the means where within
the -7 to 7 range though, because only a few estimates per observation
tended to reach very low negative values. Are *any* estimates outside the
range considered problematic?

I noticed on the forum a post where someone else had this issue (
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2012q3/019067.html) and I
also tried the chi square prior you suggested for that problem (V=1,
nu=1000, alpha.mu=0, alpha.V=1) but the result was the same.

In terms of the data and system, I would expect an extremely low, near zero
probability of interaction for some of these dyads because they are not
using similar areas and so are not physically able to interact. Is this
signal perhaps too strong? If my goal is to weed out these improbable
interactions, though, will the model not serve this purpose?

Many thanks,

Christina

Christina M. Aiello
Biologist- U.S. Geological Survey
Las Vegas Field Station
160 N. Stephanie St.
Henderson, NV 89074
(702) 481-3957
caiello at usgs.gov

On Thu, May 4, 2017 at 10:17 AM, Aiello, Christina <caiello at usgs.gov> wrote:

> Hi Jarrod,
>
> Appreciate the quick response and thoughts
>
> 1) I thought I had checked the absolute value of the latent variables, but
> now that I look again, I must not have examined both ends of the
> distribution. There are 167 observations whose latent variable
> distributions dip below -20 (minimum was -32). In each of these cases, the
> left tail of the distribution includes very few estimates at such low
> values. Do you think this has to do with the rarity of a response of 1 in
> the dataset? Or might this be indicative of another problem?
>
> 2) I'll give the probit link a try today and see how the results compare
>
> 3) I can definitely let the chains run longer, and continue increasing
> thinning? I was hesitant to keep upping the values because I haven't seen
> many published analyses using iterations and intervals beyond what I've
> been trying. I was worried having to run the chain so long might be
> indicative of other underlying problems that I wasn't considering.
>
> Many thanks!
> Christina
>
> Christina M. Aiello
> Biologist- U.S. Geological Survey
> Las Vegas Field Station
> 160 N. Stephanie St.
> Henderson, NV 89074
> (702) 481-3957
> caiello at usgs.gov
>
> On Wed, May 3, 2017 at 9:31 PM, Jarrod Hadfield <j.hadfield at ed.ac.uk>
> wrote:
>
>> Hi Christina,
>>
>> 1/ The model syntax looks fine, it is just that MCMCglmm is not very
>> efficient for this type of problem. You say there are no numerical issues
>> because the latent variable is under 20. However, are they commonly under
>> -20?
>>
>> 2/ Centering and scaling the covariates will not effect the mixing
>> because MCMCglmm is block updating all location effects.  Moving from a
>> logistic model (family="categorical") to a probit model
>> (family="threshold") will probably improve mixing, and the inferences will
>> be pretty much the same.
>>
>> 3/ You could also up the number of iterations - but perhaps this takes
>> too much time? Link and Eaton's recommendation not to thin is fine if you
>> are not worried about filling your hard drive. You reduce the Monte Carlo
>> error by saving additional correlated samples, but if the total number of
>> samples you can store is limited you are better storing uncorrelated
>> samples (obtained by thinning) because this reduces the Monte Carlo error
>> more.
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>>
>>
>> On 04/05/2017 01:24, Aiello, Christina wrote:
>>
>>> Dear list,
>>>
>>> I'm very new to MCMCglmm but have done my best to read-up on Jarrod
>>> Hadfield's package documents, tutorials and various examples posted
>>> online
>>> and discussed on this forum. I'm having trouble fitting what I thought
>>> was
>>> a fairly simple binomial mixed effects model using MCMCglmm. I'll start
>>> by
>>> describing the data, then the model, then my problem and questions:
>>>
>>> My dataset is comprised of unique dyads - pairs of animals located at one
>>> of four sites (C1, C2, R1, R2). The response variable, 'contact'
>>> indicates
>>> that the dyad did (1) or did not (0) interact over the course of the
>>> study.
>>> The unique id of the members of the dyad are 'tort1' and 'tort2'. Because
>>> individuals appear in multiple dyads, I've included a random effect for
>>> tortID using the multiple membership function available in the package to
>>> account for the non-independence of observations and the fact that some
>>> individuals may have a tendency to contact more than others. For fixed
>>> effects, in this simplified model I only have one categorical variable,
>>> 'site' (which I would have entered as a random effect but I only have 4
>>> levels) and one continuous variable, 'overlap' - which is an estimate of
>>> space-use similarity for each dyad. I centered and scaled this variable
>>> by
>>> the non-zero mean value and standard deviation (though I've also tried
>>> the
>>> model without centering). This may be relevant to my problem: 'overlap's
>>> distribution is highly skewed and mostly zero values - similarly, the
>>> response variable 'contact' is rare and characterized by mostly zeros.
>>>
>>> table(datafi$contact, datafi$site)
>>>>
>>>       C1  C2  R1  R2
>>>    0 241 229 176 181
>>>    1  35  24  14   9
>>>
>>> The model:
>>>
>>> pr<-list( R= list(V=1,  n=0, fix=1), G= list(G1=list(V=1, n=0.002)) )
>>>
>>> m1 <- MCMCglmm(
>>>
>>> fixed = contact ~ (1 + site + overlap ) ,
>>>
>>> random = ~mm(tort1 +tort2),
>>>
>>> data = datafi,
>>>
>>> family = "categorical", verbose = FALSE,
>>>
>>> pr=TRUE, pl=TRUE, prior=pr,
>>>
>>> nitt=4100000 , thin=2000 , burnin= 100000
>>>
>>> )
>>>
>>>> summary(m1)
>>>>
>>>   Iterations = 100001:4098001
>>>   Thinning interval  = 2000
>>>   Sample size  = 2000
>>>
>>>   DIC: 207.4525
>>>
>>>   G-structure:  ~mm(tort1 + tort2)
>>>
>>>              post.mean  l-95% CI u-95% CI eff.samp
>>> tort1+tort2     2.128 0.0002693    5.488    414.6
>>>
>>>   R-structure:  ~units
>>>
>>>        post.mean l-95% CI u-95% CI eff.samp
>>> units         1        1        1        0
>>>
>>>   Location effects: contact ~ (1 + site + overlap)
>>>
>>>              post.mean l-95% CI u-95% CI eff.samp  pMCMC
>>> (Intercept)   -2.2102  -3.6055  -0.7437   1505.6  0.004 **
>>> siteC2        -0.4143  -2.7572   1.4982   1808.4  0.708
>>> siteR1        -1.2543  -4.0794   0.8424   1069.0  0.268
>>> siteR2        -1.4753  -3.9300   0.9782   1348.9  0.205
>>> overlap        3.9025   2.8273   5.1260    488.5 <5e-04 ***
>>>
>>>
>>> As far as I can tell, the chains themselves look good and if I run
>>> multiple
>>> chains and run the Gelman-Rubin diagnostic, the PSRF values are all 1 or
>>> 1.01. The parameter estimates are consistent and make sense. The problem
>>> lies in the autocorrelation - large amounts in the 'overlap' variable and
>>> many of the random intercepts. Here's a sample of the autocorr results:
>>>
>>> sort(diag(autocorr(m1$Sol)[2,,]))
>>>>
>>> ##these are the worst offenders
>>>    (Intercept)    tort1.4534    tort1.3719      tort1.33    tort1.3620
>>>   tort1.30    tort1.3045
>>>   0.0926484964  0.0938622549  0.1009204749  0.1049459123  0.1065261665
>>>   0.1090179501  0.1237642453
>>>         siteR2    tort1.3150    tort1.5579        siteR1    tort1.5473
>>>   tort1.2051    tort1.3092
>>>   0.1339370132  0.1359132027  0.1383816060  0.1506535457  0.1639062068
>>>   0.1682852625  0.1683907054
>>>     tort1.5044     tort1.804    tort1.5141    tort1.5103    tort1.4148
>>>   tort1.4678    tort1.4428
>>>   0.1752670493  0.1767909176  0.1865412328  0.1919929722  0.2257633018
>>>   0.2318115800  0.2521806794
>>>     tort1.3633    tort1.3335    tort1.5101    tort1.3043      tort1.26
>>>   tort1.2014       tort1.6
>>>   0.2577034325  0.2593673083  0.2602145001  0.2717718040  0.3487288823
>>>   0.3748047689  0.4478979043
>>>        overlap
>>>   0.5400325556
>>>
>>>
>>> autocorr.diag(m1$VCV)
>>>>
>>>            tort1+tort2 units
>>> Lag 0      1.00000000   NaN
>>> Lag 2000   0.58292962   NaN
>>> Lag 10000  0.12771910   NaN
>>> Lag 20000  0.05262786   NaN
>>> Lag 1e+05  0.01757316   NaN
>>>
>>> I've attempted to fit the model with both uninformative (shown above) and
>>> parameter expanded priors (
>>> pr2<-list( R= list(V=1, n=0, fix=1), G=list(G1=list(V=1, nu=1, alpha.mu
>>> =0,
>>> alpha.V=1000)) )), with parameter expanded priors performing slightly
>>> worse. I've attempted incrementally larger iteration, thinning, and burn
>>> in
>>> values, increasing the thinning to as high as 2000 with a large burn-in
>>> (100000) in hopes of improving convergence and reducing autocorrelation.
>>> I've tried slice sampling and saw little improvement. Nothing I tried
>>> while
>>> retaining this model structure improved the acfs. I checked the latent
>>> variable estimates and all were under 20, with mean of -5.
>>>
>>> The only way I was able to reduce the autocorrelation was to fit a model
>>> without the random effect, which isn't ideal as I'm ignoring repeated
>>> measures of individuals among dyads. I've read on this forum that random
>>> effects in binomial models are notoriously hard to estimate with this
>>> package and I've also read that one should not just increase thinning to
>>> deal with the problem (MEE 2012 Link & Eaton
>>> <http://onlinelibrary.wiley.com/store/10.1111/j.2041-210X.20
>>> 11.00131.x/asset/j.2041-210X.2011.00131.x.pdf?v=1&t=j29nl332
>>> &s=e0f97f28309122f2bbfa66bccb0cd445696e2f15>).
>>> Interestingly, I have count responses association with all interacting
>>> dyads and I can fit zero truncated models to those responses just fine
>>> with
>>> the same fixed and random effects.
>>>
>>> My questions are then:
>>> 1) Do you think there is something inherently wrong with the data or just
>>> problems with the mixing algorithms in the context of this data?
>>> 2) Are there any other changes to the MCMCglmm specification I might try
>>> to
>>> improve mixing? Or any problems with my current specification?
>>> 3) Any suggestions on where to go from here?
>>>
>>>
>>> I would greatly appreciate any insights and happy to provide further info
>>> as needed!
>>>
>>> Christina
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>> --
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>>
>>
>

	[[alternative HTML version deleted]]


From jszhao at yeah.net  Mon May  8 16:13:02 2017
From: jszhao at yeah.net (Jinsong Zhao)
Date: Mon, 8 May 2017 22:13:02 +0800
Subject: [R-sig-ME] mixed model for nested factor?
Message-ID: <95b4ed20-a2ef-92d5-38f8-468e120e2694@yeah.net>

Hi there,

We have conducted an experiments for five years. The experiment is a 
completed block design with repeated measures. In detail, there is only 
one factor, i.e., temperature, and the experiments is performed in four 
blocks. In each block, the plot was split into two subplots. One subplot 
received two degree warming in Spring, and one degree warming in Fall, 
the other subplot didn't received any changes in Spring and Fall. We 
measured SOC every Spring and Fall. So we have got data something like:

SOC, Temp, Season, Year, block
2.032, 2, Spring, 2007, 1
1.988, 0, Spring, 2007, 1
1.977, 1, Fall, 2007, 1
1.881, 0, Fall, 2007, 1
....
....
It seems that mixed model might be the right way to analyze the data. 
However, we have encountered the difficulties that Temp seems to be 
nested with Season, and don't know how to code a formula for lme() in 
nlme package.

Any suggestions or comments will be really appreciated. Thanks in advance.

Best regards,
Jinsong


From walidmawass10 at gmail.com  Mon May  8 17:25:59 2017
From: walidmawass10 at gmail.com (Walid)
Date: Mon, 8 May 2017 11:25:59 -0400
Subject: [R-sig-ME] Animal model residual value
Message-ID: <4d70360b-d0c3-b4da-b7df-c65beaa3d44f@gmail.com>

Hi everyone,

I have a question on a certain assumption made regarding the 'animal' 
model when implemented in a quantitative genetic study for a trait. 
While reading van Benthem et al. (2016), the author mentions that the 
residual (environmental) value, in the additive partitioning assumed by 
the model, captures plasticity. Does this assumption always hold? or 
only in the case where we model the maternal, permanent environment and 
common environment?

My question is for the purpose of estimating the plasticity of a fixed 
heritable life-history trait (occurs only once during individual 
lifetime). Since there are no explicit methods to estimate individual 
plasticity in a non-labile trait, I am attempting to see if I can 
circumvent this by using the 'animal' model based on the assumption 
mentioned above.

Thank you

-- 
Walid Mawass
Maitrise en Biologie Cellulaire et Mol?culaire
Laboratoire de G?n?tique des Populations
D?partement de Chimie, Biochimie et Physique
Universit? du Quebec ? Trois-Rivi?res
3351, Boul. des Forges, C.P.500
Tel. (819)-376-5011 poste 3384


From jw1085 at wildcats.unh.edu  Mon May  8 18:50:31 2017
From: jw1085 at wildcats.unh.edu (Jochen Wirsing)
Date: Mon, 8 May 2017 12:50:31 -0400
Subject: [R-sig-ME] Fwd: Re: R-core post from jw1085@wildcats.unh.edu
	requires approval
In-Reply-To: <CADfFDC5aQXH-irBgn4p=GVG_W-tBYoi=1JRRpwUxFEwkkq+cAA@mail.gmail.com>
References: <CADfFDC5aQXH-irBgn4p=GVG_W-tBYoi=1JRRpwUxFEwkkq+cAA@mail.gmail.com>
Message-ID: <e0b6bad7-8798-08b2-1e7f-14f0b86a68d1@wildcats.unh.edu>

Dear R Mixed Models SIG,

below you will find an email that I originally sent to the R core group,
who technically is the maintainer of the nlme package, with which I've
had some serious issues since the last update. Since this seems to keep
preventing me from using R for my project, I am reaching out to you,
hoping this problem can be fixed in a timely manner, as it probably
affects a lot of other people as well.


Thank you very much,

Jochen Wirsing

-------- Forwarded Message --------
Subject: 	Re: R-core post from jw1085 at wildcats.unh.edu requires approval
Date: 	Wed, 3 May 2017 15:11:09 +0530
From: 	Deepayan Sarkar <deepayan.sarkar at gmail.com>
To: 	r-core-owner at r-project.org, Jochen Wirsing <jw1085 at wildcats.unh.edu>



Dear Jochen Wirsing,

Although r-core is technically the maintainer of nlme, you should
write to one of the public R mailing lists get help regarding such
problems: see

https://www.r-project.org/mail.html

Either R-help or R-SIG-mixed-models should be appropriate.

Best,
-Deepayan

> ---------- Forwarded message ----------
> From: Jochen Wirsing <jw1085 at wildcats.unh.edu>
> To: R-core at r-project.org
> Cc:
> Bcc:
> Date: Mon, 1 May 2017 11:38:09 -0400
> Subject: Problem with nlme after update to R 3.4.0
>
> Dear Sir or Madam,
>
> I am a grad student at UNH, teaching myself how to use R. Not having a background in programming, it is a bit hard to figure out what's wrong, so I thought I should let you know.
>
> Last night, I ran an MLM, and it worked just fine. This morning though, I saw that there is a new Version of RStudio as well as R itself, so I updated both. After doing so, the very identical code that worked last night, doesn't work anymore and throws a rather obscure (at least to me) error:
>
>
> 15.
> pdFactor.pdLogChol(X[[i]], ...)
> 14.
> FUN(X[[i]], ...)
> 13.
> lapply(object, pdFactor)
> 12.
> unlist(lapply(object, pdFactor))
> 11.
> pdFactor.reStruct(object)
> 10.
> pdFactor(object)
> 9.
> unlist(pdFactor(object))
> 8.
> MEEM(object, conLin, control$niterEM)
> 7.
> Initialize.reStruct(X[[i]], ...)
> 6.
> FUN(X[[i]], ...)
> 5.
> lapply(object, Initialize, data, conLin, control)
> 4.
> Initialize.lmeStruct(lmeSt, dataMix, grps, control = controlvals)
> 3.
> Initialize(lmeSt, dataMix, grps, control = controlvals)
> 2.
> lme.formula(fixed = year_c ~ 1, random = ~1 | ID, data = data, method = "ML")
> 1.
> lme(fixed = year_c ~ 1, random = ~1 | ID, data = data, method = "ML")
>
>
>
> The code I used was:
>
> ### Unconditional Model
> library(nlme)
> library(broom)
>
> uncmod <- lme(fixed = year_c~1, random = ~1|ID, data = data, method ="ML")
> tidy(uncmod)
> summary(uncmod)
> varCorr(uncmod)
>
>
>
> I hope this helps and the problem can be fixed soon, because right now, I am stopped dead in my work, unable using the nlme package, on which my analysis depends.
>
>
> Thank you very much for your consideration, help, and good work!
>
>
> Best,
>
>
> Jochen Wirsing


	[[alternative HTML version deleted]]


From mmalten at gmail.com  Mon May  8 19:49:13 2017
From: mmalten at gmail.com (Mitchell Maltenfort)
Date: Mon, 08 May 2017 17:49:13 +0000
Subject: [R-sig-ME] Fwd: Re: R-core post from jw1085@wildcats.unh.edu
 requires approval
In-Reply-To: <e0b6bad7-8798-08b2-1e7f-14f0b86a68d1@wildcats.unh.edu>
References: <CADfFDC5aQXH-irBgn4p=GVG_W-tBYoi=1JRRpwUxFEwkkq+cAA@mail.gmail.com>
 <e0b6bad7-8798-08b2-1e7f-14f0b86a68d1@wildcats.unh.edu>
Message-ID: <CANOgrHY5J5EdiuTnm4sMmBpSgYygq06XPk=hNmEaoqOsa=yu4g@mail.gmail.com>

Can you use lme4 instead?

On Mon, May 8, 2017 at 1:35 PM Jochen Wirsing <jw1085 at wildcats.unh.edu>
wrote:

> Dear R Mixed Models SIG,
>
> below you will find an email that I originally sent to the R core group,
> who technically is the maintainer of the nlme package, with which I've
> had some serious issues since the last update. Since this seems to keep
> preventing me from using R for my project, I am reaching out to you,
> hoping this problem can be fixed in a timely manner, as it probably
> affects a lot of other people as well.
>
>
> Thank you very much,
>
> Jochen Wirsing
>
> -------- Forwarded Message --------
> Subject:        Re: R-core post from jw1085 at wildcats.unh.edu requires
> approval
> Date:   Wed, 3 May 2017 15:11:09 +0530
> From:   Deepayan Sarkar <deepayan.sarkar at gmail.com>
> To:     r-core-owner at r-project.org, Jochen Wirsing <
> jw1085 at wildcats.unh.edu>
>
>
>
> Dear Jochen Wirsing,
>
> Although r-core is technically the maintainer of nlme, you should
> write to one of the public R mailing lists get help regarding such
> problems: see
>
> https://www.r-project.org/mail.html
>
> Either R-help or R-SIG-mixed-models should be appropriate.
>
> Best,
> -Deepayan
>
> > ---------- Forwarded message ----------
> > From: Jochen Wirsing <jw1085 at wildcats.unh.edu>
> > To: R-core at r-project.org
> > Cc:
> > Bcc:
> > Date: Mon, 1 May 2017 11:38:09 -0400
> > Subject: Problem with nlme after update to R 3.4.0
> >
> > Dear Sir or Madam,
> >
> > I am a grad student at UNH, teaching myself how to use R. Not having a
> background in programming, it is a bit hard to figure out what's wrong, so
> I thought I should let you know.
> >
> > Last night, I ran an MLM, and it worked just fine. This morning though,
> I saw that there is a new Version of RStudio as well as R itself, so I
> updated both. After doing so, the very identical code that worked last
> night, doesn't work anymore and throws a rather obscure (at least to me)
> error:
> >
> >
> > 15.
> > pdFactor.pdLogChol(X[[i]], ...)
> > 14.
> > FUN(X[[i]], ...)
> > 13.
> > lapply(object, pdFactor)
> > 12.
> > unlist(lapply(object, pdFactor))
> > 11.
> > pdFactor.reStruct(object)
> > 10.
> > pdFactor(object)
> > 9.
> > unlist(pdFactor(object))
> > 8.
> > MEEM(object, conLin, control$niterEM)
> > 7.
> > Initialize.reStruct(X[[i]], ...)
> > 6.
> > FUN(X[[i]], ...)
> > 5.
> > lapply(object, Initialize, data, conLin, control)
> > 4.
> > Initialize.lmeStruct(lmeSt, dataMix, grps, control = controlvals)
> > 3.
> > Initialize(lmeSt, dataMix, grps, control = controlvals)
> > 2.
> > lme.formula(fixed = year_c ~ 1, random = ~1 | ID, data = data, method =
> "ML")
> > 1.
> > lme(fixed = year_c ~ 1, random = ~1 | ID, data = data, method = "ML")
> >
> >
> >
> > The code I used was:
> >
> > ### Unconditional Model
> > library(nlme)
> > library(broom)
> >
> > uncmod <- lme(fixed = year_c~1, random = ~1|ID, data = data, method
> ="ML")
> > tidy(uncmod)
> > summary(uncmod)
> > varCorr(uncmod)
> >
> >
> >
> > I hope this helps and the problem can be fixed soon, because right now,
> I am stopped dead in my work, unable using the nlme package, on which my
> analysis depends.
> >
> >
> > Thank you very much for your consideration, help, and good work!
> >
> >
> > Best,
> >
> >
> > Jochen Wirsing
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
-- 
Sent from Gmail Mobile

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon May  8 20:30:08 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 8 May 2017 20:30:08 +0200
Subject: [R-sig-ME] Fwd: Re: R-core post from jw1085@wildcats.unh.edu
 requires approval
In-Reply-To: <e0b6bad7-8798-08b2-1e7f-14f0b86a68d1@wildcats.unh.edu>
References: <CADfFDC5aQXH-irBgn4p=GVG_W-tBYoi=1JRRpwUxFEwkkq+cAA@mail.gmail.com>
 <e0b6bad7-8798-08b2-1e7f-14f0b86a68d1@wildcats.unh.edu>
Message-ID: <CAJuCY5yMVxF5gGp4zvPadiOxAvvWg93gu9FfPY-ioOi1nkpUgw@mail.gmail.com>

Dear Jochen,

It is unclear where the problem exactly occurs. Please try to code below in
a clean R session and report exactly after which line the error occurs

library(nlme)
uncmod <- lme(fixed = year_c~1, random = ~1|ID, data = data, method ="ML")
summary(uncmod)
varCorr(uncmod)

library(broom)
uncmod <- lme(fixed = year_c~1, random = ~1|ID, data = data, method ="ML")
tidy(uncmod)
summary(uncmod)
varCorr(uncmod)

also give us the output of sessionInfo() when the error occurs.

Best regards,


>

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-05-08 18:50 GMT+02:00 Jochen Wirsing <jw1085 at wildcats.unh.edu>:

> Dear R Mixed Models SIG,
>
> below you will find an email that I originally sent to the R core group,
> who technically is the maintainer of the nlme package, with which I've
> had some serious issues since the last update. Since this seems to keep
> preventing me from using R for my project, I am reaching out to you,
> hoping this problem can be fixed in a timely manner, as it probably
> affects a lot of other people as well.
>
>
> Thank you very much,
>
> Jochen Wirsing
>
> -------- Forwarded Message --------
> Subject:        Re: R-core post from jw1085 at wildcats.unh.edu requires
> approval
> Date:   Wed, 3 May 2017 15:11:09 +0530
> From:   Deepayan Sarkar <deepayan.sarkar at gmail.com>
> To:     r-core-owner at r-project.org, Jochen Wirsing <
> jw1085 at wildcats.unh.edu>
>
>
>
> Dear Jochen Wirsing,
>
> Although r-core is technically the maintainer of nlme, you should
> write to one of the public R mailing lists get help regarding such
> problems: see
>
> https://www.r-project.org/mail.html
>
> Either R-help or R-SIG-mixed-models should be appropriate.
>
> Best,
> -Deepayan
>
> > ---------- Forwarded message ----------
> > From: Jochen Wirsing <jw1085 at wildcats.unh.edu>
> > To: R-core at r-project.org
> > Cc:
> > Bcc:
> > Date: Mon, 1 May 2017 11:38:09 -0400
> > Subject: Problem with nlme after update to R 3.4.0
> >
> > Dear Sir or Madam,
> >
> > I am a grad student at UNH, teaching myself how to use R. Not having a
> background in programming, it is a bit hard to figure out what's wrong, so
> I thought I should let you know.
> >
> > Last night, I ran an MLM, and it worked just fine. This morning though,
> I saw that there is a new Version of RStudio as well as R itself, so I
> updated both. After doing so, the very identical code that worked last
> night, doesn't work anymore and throws a rather obscure (at least to me)
> error:
> >
> >
> > 15.
> > pdFactor.pdLogChol(X[[i]], ...)
> > 14.
> > FUN(X[[i]], ...)
> > 13.
> > lapply(object, pdFactor)
> > 12.
> > unlist(lapply(object, pdFactor))
> > 11.
> > pdFactor.reStruct(object)
> > 10.
> > pdFactor(object)
> > 9.
> > unlist(pdFactor(object))
> > 8.
> > MEEM(object, conLin, control$niterEM)
> > 7.
> > Initialize.reStruct(X[[i]], ...)
> > 6.
> > FUN(X[[i]], ...)
> > 5.
> > lapply(object, Initialize, data, conLin, control)
> > 4.
> > Initialize.lmeStruct(lmeSt, dataMix, grps, control = controlvals)
> > 3.
> > Initialize(lmeSt, dataMix, grps, control = controlvals)
> > 2.
> > lme.formula(fixed = year_c ~ 1, random = ~1 | ID, data = data, method =
> "ML")
> > 1.
> > lme(fixed = year_c ~ 1, random = ~1 | ID, data = data, method = "ML")
> >
> >
> >
> > The code I used was:
> >
> > ### Unconditional Model
> > library(nlme)
> > library(broom)
> >
> > uncmod <- lme(fixed = year_c~1, random = ~1|ID, data = data, method
> ="ML")
> > tidy(uncmod)
> > summary(uncmod)
> > varCorr(uncmod)
> >
> >
> >
> > I hope this helps and the problem can be fixed soon, because right now,
> I am stopped dead in my work, unable using the nlme package, on which my
> analysis depends.
> >
> >
> > Thank you very much for your consideration, help, and good work!
> >
> >
> > Best,
> >
> >
> > Jochen Wirsing
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon May  8 20:35:29 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 8 May 2017 20:35:29 +0200
Subject: [R-sig-ME] mixed model for nested factor?
In-Reply-To: <95b4ed20-a2ef-92d5-38f8-468e120e2694@yeah.net>
References: <95b4ed20-a2ef-92d5-38f8-468e120e2694@yeah.net>
Message-ID: <CAJuCY5x_4qrXSn7F+KDi8feCJpVh0yRyn3EYQ4g3WP2BhFaXDA@mail.gmail.com>

Dear Jinsong,

IMHO you want to detect a potential effect of warming. The amount of
warming seems to be less relevant. Therefore I'd recode temperature into a
factor with two levels: warming = yes and warming = no.
Then add the interaction between warming and season to the model. That will
take care of the difference in warming between spring and fall.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-05-08 16:13 GMT+02:00 Jinsong Zhao <jszhao at yeah.net>:

> Hi there,
>
> We have conducted an experiments for five years. The experiment is a
> completed block design with repeated measures. In detail, there is only one
> factor, i.e., temperature, and the experiments is performed in four blocks.
> In each block, the plot was split into two subplots. One subplot received
> two degree warming in Spring, and one degree warming in Fall, the other
> subplot didn't received any changes in Spring and Fall. We measured SOC
> every Spring and Fall. So we have got data something like:
>
> SOC, Temp, Season, Year, block
> 2.032, 2, Spring, 2007, 1
> 1.988, 0, Spring, 2007, 1
> 1.977, 1, Fall, 2007, 1
> 1.881, 0, Fall, 2007, 1
> ....
> ....
> It seems that mixed model might be the right way to analyze the data.
> However, we have encountered the difficulties that Temp seems to be nested
> with Season, and don't know how to code a formula for lme() in nlme package.
>
> Any suggestions or comments will be really appreciated. Thanks in advance.
>
> Best regards,
> Jinsong
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From kw.stat at gmail.com  Mon May  8 20:42:11 2017
From: kw.stat at gmail.com (Kevin Wright)
Date: Mon, 8 May 2017 13:42:11 -0500
Subject: [R-sig-ME] Fwd: Re: R-core post from jw1085@wildcats.unh.edu
 requires approval
In-Reply-To: <e0b6bad7-8798-08b2-1e7f-14f0b86a68d1@wildcats.unh.edu>
References: <CADfFDC5aQXH-irBgn4p=GVG_W-tBYoi=1JRRpwUxFEwkkq+cAA@mail.gmail.com>
 <e0b6bad7-8798-08b2-1e7f-14f0b86a68d1@wildcats.unh.edu>
Message-ID: <CAKFxdiT1Otsw6+qw3kkTjn_0=g91uj2nFnvoAdKewPaTPuCv8A@mail.gmail.com>

Somebody might be able to look at your error message and figure out what is
wrong, but often that is not possible just by looking.  If you want people
to help you, then you need to help people understand your problem, perhaps
using simulated data.  See:
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

Kevin

On Mon, May 8, 2017 at 11:50 AM, Jochen Wirsing <jw1085 at wildcats.unh.edu>
wrote:

> Dear R Mixed Models SIG,
>
> below you will find an email that I originally sent to the R core group,
> who technically is the maintainer of the nlme package, with which I've
> had some serious issues since the last update. Since this seems to keep
> preventing me from using R for my project, I am reaching out to you,
> hoping this problem can be fixed in a timely manner, as it probably
> affects a lot of other people as well.
>
>
> Thank you very much,
>
> Jochen Wirsing
>
> -------- Forwarded Message --------
> Subject:        Re: R-core post from jw1085 at wildcats.unh.edu requires
> approval
> Date:   Wed, 3 May 2017 15:11:09 +0530
> From:   Deepayan Sarkar <deepayan.sarkar at gmail.com>
> To:     r-core-owner at r-project.org, Jochen Wirsing <
> jw1085 at wildcats.unh.edu>
>
>
>
> Dear Jochen Wirsing,
>
> Although r-core is technically the maintainer of nlme, you should
> write to one of the public R mailing lists get help regarding such
> problems: see
>
> https://www.r-project.org/mail.html
>
> Either R-help or R-SIG-mixed-models should be appropriate.
>
> Best,
> -Deepayan
>
> > ---------- Forwarded message ----------
> > From: Jochen Wirsing <jw1085 at wildcats.unh.edu>
> > To: R-core at r-project.org
> > Cc:
> > Bcc:
> > Date: Mon, 1 May 2017 11:38:09 -0400
> > Subject: Problem with nlme after update to R 3.4.0
> >
> > Dear Sir or Madam,
> >
> > I am a grad student at UNH, teaching myself how to use R. Not having a
> background in programming, it is a bit hard to figure out what's wrong, so
> I thought I should let you know.
> >
> > Last night, I ran an MLM, and it worked just fine. This morning though,
> I saw that there is a new Version of RStudio as well as R itself, so I
> updated both. After doing so, the very identical code that worked last
> night, doesn't work anymore and throws a rather obscure (at least to me)
> error:
> >
> >
> > 15.
> > pdFactor.pdLogChol(X[[i]], ...)
> > 14.
> > FUN(X[[i]], ...)
> > 13.
> > lapply(object, pdFactor)
> > 12.
> > unlist(lapply(object, pdFactor))
> > 11.
> > pdFactor.reStruct(object)
> > 10.
> > pdFactor(object)
> > 9.
> > unlist(pdFactor(object))
> > 8.
> > MEEM(object, conLin, control$niterEM)
> > 7.
> > Initialize.reStruct(X[[i]], ...)
> > 6.
> > FUN(X[[i]], ...)
> > 5.
> > lapply(object, Initialize, data, conLin, control)
> > 4.
> > Initialize.lmeStruct(lmeSt, dataMix, grps, control = controlvals)
> > 3.
> > Initialize(lmeSt, dataMix, grps, control = controlvals)
> > 2.
> > lme.formula(fixed = year_c ~ 1, random = ~1 | ID, data = data, method =
> "ML")
> > 1.
> > lme(fixed = year_c ~ 1, random = ~1 | ID, data = data, method = "ML")
> >
> >
> >
> > The code I used was:
> >
> > ### Unconditional Model
> > library(nlme)
> > library(broom)
> >
> > uncmod <- lme(fixed = year_c~1, random = ~1|ID, data = data, method
> ="ML")
> > tidy(uncmod)
> > summary(uncmod)
> > varCorr(uncmod)
> >
> >
> >
> > I hope this helps and the problem can be fixed soon, because right now,
> I am stopped dead in my work, unable using the nlme package, on which my
> analysis depends.
> >
> >
> > Thank you very much for your consideration, help, and good work!
> >
> >
> > Best,
> >
> >
> > Jochen Wirsing
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Kevin Wright

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon May  8 21:43:06 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 8 May 2017 15:43:06 -0400
Subject: [R-sig-ME] Fwd: Re: R-core post from jw1085@wildcats.unh.edu
 requires approval
In-Reply-To: <CAKFxdiT1Otsw6+qw3kkTjn_0=g91uj2nFnvoAdKewPaTPuCv8A@mail.gmail.com>
References: <CADfFDC5aQXH-irBgn4p=GVG_W-tBYoi=1JRRpwUxFEwkkq+cAA@mail.gmail.com>
 <e0b6bad7-8798-08b2-1e7f-14f0b86a68d1@wildcats.unh.edu>
 <CAKFxdiT1Otsw6+qw3kkTjn_0=g91uj2nFnvoAdKewPaTPuCv8A@mail.gmail.com>
Message-ID: <CABghstSssKgLB3kFXjeD4vbZPLFvf-mkDZ8P93-D7qQ5xapNqA@mail.gmail.com>

My only wild guess about this is that there are (still unresolved as
far as I know) issues with the latest version of Matrix on 32-bit
operating systems (unlikely unless you're using Linux, and even then
slightly rare).  If so (sessionInfo() will tell us this), reverting to
the previous version of Matrix (e.g. see ?devtools::install_version)
should help.

On Mon, May 8, 2017 at 2:42 PM, Kevin Wright <kw.stat at gmail.com> wrote:
> Somebody might be able to look at your error message and figure out what is
> wrong, but often that is not possible just by looking.  If you want people
> to help you, then you need to help people understand your problem, perhaps
> using simulated data.  See:
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>
> Kevin
>
> On Mon, May 8, 2017 at 11:50 AM, Jochen Wirsing <jw1085 at wildcats.unh.edu>
> wrote:
>
>> Dear R Mixed Models SIG,
>>
>> below you will find an email that I originally sent to the R core group,
>> who technically is the maintainer of the nlme package, with which I've
>> had some serious issues since the last update. Since this seems to keep
>> preventing me from using R for my project, I am reaching out to you,
>> hoping this problem can be fixed in a timely manner, as it probably
>> affects a lot of other people as well.
>>
>>
>> Thank you very much,
>>
>> Jochen Wirsing
>>
>> -------- Forwarded Message --------
>> Subject:        Re: R-core post from jw1085 at wildcats.unh.edu requires
>> approval
>> Date:   Wed, 3 May 2017 15:11:09 +0530
>> From:   Deepayan Sarkar <deepayan.sarkar at gmail.com>
>> To:     r-core-owner at r-project.org, Jochen Wirsing <
>> jw1085 at wildcats.unh.edu>
>>
>>
>>
>> Dear Jochen Wirsing,
>>
>> Although r-core is technically the maintainer of nlme, you should
>> write to one of the public R mailing lists get help regarding such
>> problems: see
>>
>> https://www.r-project.org/mail.html
>>
>> Either R-help or R-SIG-mixed-models should be appropriate.
>>
>> Best,
>> -Deepayan
>>
>> > ---------- Forwarded message ----------
>> > From: Jochen Wirsing <jw1085 at wildcats.unh.edu>
>> > To: R-core at r-project.org
>> > Cc:
>> > Bcc:
>> > Date: Mon, 1 May 2017 11:38:09 -0400
>> > Subject: Problem with nlme after update to R 3.4.0
>> >
>> > Dear Sir or Madam,
>> >
>> > I am a grad student at UNH, teaching myself how to use R. Not having a
>> background in programming, it is a bit hard to figure out what's wrong, so
>> I thought I should let you know.
>> >
>> > Last night, I ran an MLM, and it worked just fine. This morning though,
>> I saw that there is a new Version of RStudio as well as R itself, so I
>> updated both. After doing so, the very identical code that worked last
>> night, doesn't work anymore and throws a rather obscure (at least to me)
>> error:
>> >
>> >
>> > 15.
>> > pdFactor.pdLogChol(X[[i]], ...)
>> > 14.
>> > FUN(X[[i]], ...)
>> > 13.
>> > lapply(object, pdFactor)
>> > 12.
>> > unlist(lapply(object, pdFactor))
>> > 11.
>> > pdFactor.reStruct(object)
>> > 10.
>> > pdFactor(object)
>> > 9.
>> > unlist(pdFactor(object))
>> > 8.
>> > MEEM(object, conLin, control$niterEM)
>> > 7.
>> > Initialize.reStruct(X[[i]], ...)
>> > 6.
>> > FUN(X[[i]], ...)
>> > 5.
>> > lapply(object, Initialize, data, conLin, control)
>> > 4.
>> > Initialize.lmeStruct(lmeSt, dataMix, grps, control = controlvals)
>> > 3.
>> > Initialize(lmeSt, dataMix, grps, control = controlvals)
>> > 2.
>> > lme.formula(fixed = year_c ~ 1, random = ~1 | ID, data = data, method =
>> "ML")
>> > 1.
>> > lme(fixed = year_c ~ 1, random = ~1 | ID, data = data, method = "ML")
>> >
>> >
>> >
>> > The code I used was:
>> >
>> > ### Unconditional Model
>> > library(nlme)
>> > library(broom)
>> >
>> > uncmod <- lme(fixed = year_c~1, random = ~1|ID, data = data, method
>> ="ML")
>> > tidy(uncmod)
>> > summary(uncmod)
>> > varCorr(uncmod)
>> >
>> >
>> >
>> > I hope this helps and the problem can be fixed soon, because right now,
>> I am stopped dead in my work, unable using the nlme package, on which my
>> analysis depends.
>> >
>> >
>> > Thank you very much for your consideration, help, and good work!
>> >
>> >
>> > Best,
>> >
>> >
>> > Jochen Wirsing
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
> Kevin Wright
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From pierre.de.villemereuil at mailoo.org  Mon May  8 23:45:55 2017
From: pierre.de.villemereuil at mailoo.org (Pierre de Villemereuil)
Date: Tue, 09 May 2017 09:45:55 +1200
Subject: [R-sig-ME] Animal model residual value
In-Reply-To: <4d70360b-d0c3-b4da-b7df-c65beaa3d44f@gmail.com>
References: <4d70360b-d0c3-b4da-b7df-c65beaa3d44f@gmail.com>
Message-ID: <1877357.TmPc99f7LY@vercors>

Hi,

It depends on what you call "plasticity". Most often, plasticity is defined as the part of phenotypic variability that varies according to environment. Without an experimental settings or environmental replications, it's very hard to distinguish from random phenotypic variability.

I've heard people considering that the environmental variance is a measure of plasticity, but it seems to me that this is a huge assumption that random variability is negligible, especially if you have only 1 environment.

Cheers,
Pierre.

On Monday, 8 May 2017 11:25:59 NZST Walid wrote:
> Hi everyone,
> 
> I have a question on a certain assumption made regarding the 'animal' 
> model when implemented in a quantitative genetic study for a trait. 
> While reading van Benthem et al. (2016), the author mentions that the 
> residual (environmental) value, in the additive partitioning assumed by 
> the model, captures plasticity. Does this assumption always hold? or 
> only in the case where we model the maternal, permanent environment and 
> common environment?
> 
> My question is for the purpose of estimating the plasticity of a fixed 
> heritable life-history trait (occurs only once during individual 
> lifetime). Since there are no explicit methods to estimate individual 
> plasticity in a non-labile trait, I am attempting to see if I can 
> circumvent this by using the 'animal' model based on the assumption 
> mentioned above.
> 
> Thank you
> 
>


From famingw at gmail.com  Tue May  9 01:39:54 2017
From: famingw at gmail.com (Faming Wang)
Date: Mon, 08 May 2017 23:39:54 +0000
Subject: [R-sig-ME] A question on using LME model in species nested within a
	random block design
Message-ID: <CAHtaSOVu2W0mjsnFR5PS+SesjALg-sRf1WzsQdjZF8zypOrQRg@mail.gmail.com>

Dear all,


 I have conducted an N and P field addition experiment in a tropical
forest, and we used a random block design in this experiment, briefly, we
had four randomly distributed plots in each block (Control, +N? +P,
and +NP), and five blocks located in the forest. Totally we have 20 plots,
with two N treatments and two P treatment and five replicated blocks. In
each plot, we selected five  species  plants (some plots only contains 3 or
4 species) to measure their leave variables, like N concentration, P
concentration, and photosynthesis rate et al.  We want to know the effect
of N and P addition as well as the species level changes (inter-species )
 on leaf variables. Since some plots some specific species are missing in
some plots some specific species, it was unbalanced at the species level.
We used linear mixed effect models to conduct our statistical analysis:

  We firstly tested the random effect with blocks, and species within plots
within blocks, and found that nesting plots and species within block did
not improve the model fitness, so we choose only block as random effect.
For fixed effects, N-addition, P-addition, species and their interaction
were considered fixed effects in models. The significance of each term was
determined by comparing nested models using likelihood ratio tests and AICs
to check for model improvement. Since there was better model fit (lower AIC
values) with interaction terms, we selected the full factor model. However,
as there was a highly significant effect of tree species identity and
species related interactions, species-specific responses to N- and
P-addition were also investigated with separate models with N, P and their
interaction as fixed effects and block as a random effect.
 however, our reviewers were not happy with this statistical methods and
pointed out that "Species is treated as a fixed factor, generating a
three-way factorial ANOVA. Species cannot be treated in this way because
all five species were present in each 10-by-10-m plot. To implement a
three-way ANOVA design, the entire experiment (five blocks of the four
factorial N and P treatments) would have to be repeated once for each
species. Species cannot be treated as a fixed factor because all five
species were measured in the same experimental plots. This is a split-plot
design. Alternatively, MANOVA might be performed treating the five species
as five response variables. A split-plot design or a MANOVA approach would
allow the authors to investigate interspecific variation in responses."

  I am very confused on the reviewer's comments,  it seems to me that the
reviewer compared our LME model with 3-way ANOVA. If we used 3-way ANOVA, I
know that my experiment is species nested in a random block design, and we
could not directly use 3-Way ANOVA, which the error df would be
overestimated.

   Below I attached my sample data and my current R script for LME model.
Could anybody take a look at our data?   I really appreciate if you can
provide us some suggestions how to conduct the correct statistical analysis
for this study.

-- 

Sincerely

Faming Wang

From Phillip.Alday at unisa.edu.au  Tue May  9 03:15:43 2017
From: Phillip.Alday at unisa.edu.au (Phillip Alday)
Date: Tue, 9 May 2017 01:15:43 +0000
Subject: [R-sig-ME] A question on using LME model in species nested
 within a	random block design
In-Reply-To: <CAHtaSOVu2W0mjsnFR5PS+SesjALg-sRf1WzsQdjZF8zypOrQRg@mail.gmail.com>
References: <CAHtaSOVu2W0mjsnFR5PS+SesjALg-sRf1WzsQdjZF8zypOrQRg@mail.gmail.com>
Message-ID: <0FE32020-D5B9-4634-8D5D-93BC73432A03@unisa.edu.au>

Dear Faming,

I don't have anything to comment on your actual question, but the attachments are stripped before messages are forwarded to the list. In other words: good job on sharing data and code so that we can help, but you need to post it online somewhere (dropbox, pastebin and github gists are popular options) so that we see it!

Best,
Phillip 
 
> On 9 May 2017, at 09:09, Faming Wang <famingw at gmail.com> wrote:
> 
> Dear all,
> 
> 
> I have conducted an N and P field addition experiment in a tropical
> forest, and we used a random block design in this experiment, briefly, we
> had four randomly distributed plots in each block (Control, +N? +P,
> and +NP), and five blocks located in the forest. Totally we have 20 plots,
> with two N treatments and two P treatment and five replicated blocks. In
> each plot, we selected five  species  plants (some plots only contains 3 or
> 4 species) to measure their leave variables, like N concentration, P
> concentration, and photosynthesis rate et al.  We want to know the effect
> of N and P addition as well as the species level changes (inter-species )
> on leaf variables. Since some plots some specific species are missing in
> some plots some specific species, it was unbalanced at the species level.
> We used linear mixed effect models to conduct our statistical analysis:
> 
>  We firstly tested the random effect with blocks, and species within plots
> within blocks, and found that nesting plots and species within block did
> not improve the model fitness, so we choose only block as random effect.
> For fixed effects, N-addition, P-addition, species and their interaction
> were considered fixed effects in models. The significance of each term was
> determined by comparing nested models using likelihood ratio tests and AICs
> to check for model improvement. Since there was better model fit (lower AIC
> values) with interaction terms, we selected the full factor model. However,
> as there was a highly significant effect of tree species identity and
> species related interactions, species-specific responses to N- and
> P-addition were also investigated with separate models with N, P and their
> interaction as fixed effects and block as a random effect.
> however, our reviewers were not happy with this statistical methods and
> pointed out that "Species is treated as a fixed factor, generating a
> three-way factorial ANOVA. Species cannot be treated in this way because
> all five species were present in each 10-by-10-m plot. To implement a
> three-way ANOVA design, the entire experiment (five blocks of the four
> factorial N and P treatments) would have to be repeated once for each
> species. Species cannot be treated as a fixed factor because all five
> species were measured in the same experimental plots. This is a split-plot
> design. Alternatively, MANOVA might be performed treating the five species
> as five response variables. A split-plot design or a MANOVA approach would
> allow the authors to investigate interspecific variation in responses."
> 
>  I am very confused on the reviewer's comments,  it seems to me that the
> reviewer compared our LME model with 3-way ANOVA. If we used 3-way ANOVA, I
> know that my experiment is species nested in a random block design, and we
> could not directly use 3-Way ANOVA, which the error df would be
> overestimated.
> 
>   Below I attached my sample data and my current R script for LME model.
> Could anybody take a look at our data?   I really appreciate if you can
> provide us some suggestions how to conduct the correct statistical analysis
> for this study.
> 
> -- 
> 
> Sincerely
> 
> Faming Wang
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From famingw at gmail.com  Tue May  9 03:26:01 2017
From: famingw at gmail.com (famingw at gmail.com)
Date: Mon, 8 May 2017 21:26:01 -0400
Subject: [R-sig-ME] =?utf-8?b?562U5aSNOiAgQSBxdWVzdGlvbiBvbiB1c2luZyBMTUUg?=
 =?utf-8?q?model_in_species_nested_within_a_random_block_design?=
In-Reply-To: <0FE32020-D5B9-4634-8D5D-93BC73432A03@unisa.edu.au>
References: <CAHtaSOVu2W0mjsnFR5PS+SesjALg-sRf1WzsQdjZF8zypOrQRg@mail.gmail.com>
 <0FE32020-D5B9-4634-8D5D-93BC73432A03@unisa.edu.au>
Message-ID: <59111aa9.6e29c80a.43797.ca3a@mx.google.com>

Thanks Phillip,
  I uploaded the data and r code to drop box.
 See: 
Rcode: https://www.dropbox.com/s/fpqdbm6go0g8ak0/Faming%20NP%20model.R?dl=0

Data: https://www.dropbox.com/s/9dr09vlevmnood1/Nconcdata.csv?dl=0

Thanks.

Faming Wang

???: Phillip Alday
????: Monday, May 8, 2017 9:15 PM
???: Faming Wang
??: r-sig-mixed-models at r-project.org
??: Re: [R-sig-ME] A question on using LME model in species nested withina random block design

Dear Faming,

I don't have anything to comment on your actual question, but the attachments are stripped before messages are forwarded to the list. In other words: good job on sharing data and code so that we can help, but you need to post it online somewhere (dropbox, pastebin and github gists are popular options) so that we see it!

Best,
Phillip 
 
> On 9 May 2017, at 09:09, Faming Wang <famingw at gmail.com> wrote:
> 
> Dear all,
> 
> 
> I have conducted an N and P field addition experiment in a tropical
> forest, and we used a random block design in this experiment, briefly, we
> had four randomly distributed plots in each block (Control, +N? +P,
> and +NP), and five blocks located in the forest. Totally we have 20 plots,
> with two N treatments and two P treatment and five replicated blocks. In
> each plot, we selected five  species  plants (some plots only contains 3 or
> 4 species) to measure their leave variables, like N concentration, P
> concentration, and photosynthesis rate et al.  We want to know the effect
> of N and P addition as well as the species level changes (inter-species )
> on leaf variables. Since some plots some specific species are missing in
> some plots some specific species, it was unbalanced at the species level.
> We used linear mixed effect models to conduct our statistical analysis:
> 
>  We firstly tested the random effect with blocks, and species within plots
> within blocks, and found that nesting plots and species within block did
> not improve the model fitness, so we choose only block as random effect.
> For fixed effects, N-addition, P-addition, species and their interaction
> were considered fixed effects in models. The significance of each term was
> determined by comparing nested models using likelihood ratio tests and AICs
> to check for model improvement. Since there was better model fit (lower AIC
> values) with interaction terms, we selected the full factor model. However,
> as there was a highly significant effect of tree species identity and
> species related interactions, species-specific responses to N- and
> P-addition were also investigated with separate models with N, P and their
> interaction as fixed effects and block as a random effect.
> however, our reviewers were not happy with this statistical methods and
> pointed out that "Species is treated as a fixed factor, generating a
> three-way factorial ANOVA. Species cannot be treated in this way because
> all five species were present in each 10-by-10-m plot. To implement a
> three-way ANOVA design, the entire experiment (five blocks of the four
> factorial N and P treatments) would have to be repeated once for each
> species. Species cannot be treated as a fixed factor because all five
> species were measured in the same experimental plots. This is a split-plot
> design. Alternatively, MANOVA might be performed treating the five species
> as five response variables. A split-plot design or a MANOVA approach would
> allow the authors to investigate interspecific variation in responses."
> 
>  I am very confused on the reviewer's comments,  it seems to me that the
> reviewer compared our LME model with 3-way ANOVA. If we used 3-way ANOVA, I
> know that my experiment is species nested in a random block design, and we
> could not directly use 3-Way ANOVA, which the error df would be
> overestimated.
> 
>   Below I attached my sample data and my current R script for LME model.
> Could anybody take a look at our data?   I really appreciate if you can
> provide us some suggestions how to conduct the correct statistical analysis
> for this study.
> 
> -- 
> 
> Sincerely
> 
> Faming Wang
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



	[[alternative HTML version deleted]]


From jszhao at yeah.net  Tue May  9 04:25:17 2017
From: jszhao at yeah.net (Jinsong Zhao)
Date: Tue, 9 May 2017 10:25:17 +0800
Subject: [R-sig-ME] mixed model for nested factor?
In-Reply-To: <CAJuCY5x_4qrXSn7F+KDi8feCJpVh0yRyn3EYQ4g3WP2BhFaXDA@mail.gmail.com>
References: <95b4ed20-a2ef-92d5-38f8-468e120e2694@yeah.net>
 <CAJuCY5x_4qrXSn7F+KDi8feCJpVh0yRyn3EYQ4g3WP2BhFaXDA@mail.gmail.com>
Message-ID: <df3b3dd2-f081-348f-3987-588c488e3d91@yeah.net>

Thank you very much for the reply. The 2, 1 and 0 are not the amount of 
warming. They are just codes for the warming strength. Since the warming 
pattern is different in Spring and Fall, I wonder that warming pattern 
(Temp) is nested in Season.

Another concern is how to deal with Year. I hope to test the time effect 
on SOC. Should Year be treated as continuous variable or factor? I 
recorded the exact time of soil sampling.

Thanks again.

Best regards,
Jinsong

On 2017/5/9 2:35, Thierry Onkelinx wrote:
> Dear Jinsong,
>
> IMHO you want to detect a potential effect of warming. The amount of
> warming seems to be less relevant. Therefore I'd recode temperature into a
> factor with two levels: warming = yes and warming = no.
> Then add the interaction between warming and season to the model. That will
> take care of the difference in warming between spring and fall.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2017-05-08 16:13 GMT+02:00 Jinsong Zhao <jszhao at yeah.net>:
>
>> Hi there,
>>
>> We have conducted an experiments for five years. The experiment is a
>> completed block design with repeated measures. In detail, there is only one
>> factor, i.e., temperature, and the experiments is performed in four blocks.
>> In each block, the plot was split into two subplots. One subplot received
>> two degree warming in Spring, and one degree warming in Fall, the other
>> subplot didn't received any changes in Spring and Fall. We measured SOC
>> every Spring and Fall. So we have got data something like:
>>
>> SOC, Temp, Season, Year, block
>> 2.032, 2, Spring, 2007, 1
>> 1.988, 0, Spring, 2007, 1
>> 1.977, 1, Fall, 2007, 1
>> 1.881, 0, Fall, 2007, 1
>> ....
>> ....
>> It seems that mixed model might be the right way to analyze the data.
>> However, we have encountered the difficulties that Temp seems to be nested
>> with Season, and don't know how to code a formula for lme() in nlme package.
>>
>> Any suggestions or comments will be really appreciated. Thanks in advance.
>>
>> Best regards,
>> Jinsong


From thierry.onkelinx at inbo.be  Tue May  9 10:03:29 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 9 May 2017 10:03:29 +0200
Subject: [R-sig-ME] mixed model for nested factor?
In-Reply-To: <df3b3dd2-f081-348f-3987-588c488e3d91@yeah.net>
References: <95b4ed20-a2ef-92d5-38f8-468e120e2694@yeah.net>
 <CAJuCY5x_4qrXSn7F+KDi8feCJpVh0yRyn3EYQ4g3WP2BhFaXDA@mail.gmail.com>
 <df3b3dd2-f081-348f-3987-588c488e3d91@yeah.net>
Message-ID: <CAJuCY5zBJjhMJX0ndpoZTo_+tArxwHQD3=sbRBjOifdcYHXZRQ@mail.gmail.com>

In this case, use the coding as I suggested. The interaction with season
will take care of the difference in warming.

Is a linear trend along year a reasonable assumption? If yes, you can use
year as continuous. If no, use it as a factor.

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-05-09 4:25 GMT+02:00 Jinsong Zhao <jszhao at yeah.net>:

> Thank you very much for the reply. The 2, 1 and 0 are not the amount of
> warming. They are just codes for the warming strength. Since the warming
> pattern is different in Spring and Fall, I wonder that warming pattern
> (Temp) is nested in Season.
>
> Another concern is how to deal with Year. I hope to test the time effect
> on SOC. Should Year be treated as continuous variable or factor? I recorded
> the exact time of soil sampling.
>
> Thanks again.
>
> Best regards,
> Jinsong
>
>
> On 2017/5/9 2:35, Thierry Onkelinx wrote:
>
>> Dear Jinsong,
>>
>> IMHO you want to detect a potential effect of warming. The amount of
>> warming seems to be less relevant. Therefore I'd recode temperature into a
>> factor with two levels: warming = yes and warming = no.
>> Then add the interaction between warming and season to the model. That
>> will
>> take care of the difference in warming between spring and fall.
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
>> Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to
>> say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of
>> data.
>> ~ John Tukey
>>
>> 2017-05-08 16:13 GMT+02:00 Jinsong Zhao <jszhao at yeah.net>:
>>
>> Hi there,
>>>
>>> We have conducted an experiments for five years. The experiment is a
>>> completed block design with repeated measures. In detail, there is only
>>> one
>>> factor, i.e., temperature, and the experiments is performed in four
>>> blocks.
>>> In each block, the plot was split into two subplots. One subplot received
>>> two degree warming in Spring, and one degree warming in Fall, the other
>>> subplot didn't received any changes in Spring and Fall. We measured SOC
>>> every Spring and Fall. So we have got data something like:
>>>
>>> SOC, Temp, Season, Year, block
>>> 2.032, 2, Spring, 2007, 1
>>> 1.988, 0, Spring, 2007, 1
>>> 1.977, 1, Fall, 2007, 1
>>> 1.881, 0, Fall, 2007, 1
>>> ....
>>> ....
>>> It seems that mixed model might be the right way to analyze the data.
>>> However, we have encountered the difficulties that Temp seems to be
>>> nested
>>> with Season, and don't know how to code a formula for lme() in nlme
>>> package.
>>>
>>> Any suggestions or comments will be really appreciated. Thanks in
>>> advance.
>>>
>>> Best regards,
>>> Jinsong
>>>
>>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From timothee.bonnet at ieu.uzh.ch  Tue May  9 12:52:43 2017
From: timothee.bonnet at ieu.uzh.ch (timothee.bonnet at ieu.uzh.ch)
Date: Tue, 9 May 2017 12:52:43 +0200
Subject: [R-sig-ME] Animal model residual value
In-Reply-To: <mailman.2552.1494293169.1412.r-sig-mixed-models@r-project.org>
References: <mailman.2552.1494293169.1412.r-sig-mixed-models@r-project.org>
Message-ID: <OFCF7B5C62.D49EC09C-ONC125811B.00384310-C125811B.003BC236@lotus.uzh.ch>

Hi all,?

As a co-author of the van Benthem & al. (2016) paper, let me try and clarify what was meant here.

I agree with Pierre that this is a semantic problem, more than a modelling assumption.?
We defined plasticity as the non-heritable component of a trait (i.e., 1 - heritability ; or the ability of a genotype to produce different phenotypes). This definition is probably animal modeler slang, but I think it conveys the idea that there is no "truly random" phenotypic variation, only numerous environmental influences, observed or unobserved.

The residual variance from an animal model like the one used in our paper would capture the plasticity in response to all environmental influences (including what you could call developmental noise or random phenotypic variability).
If instead you are interested in the plastic response to a specific environmental variable (a "reaction-norm" definition of plasticity), you will probably have to include this variable explicitly in your model (but difficult to tell how without more details).?

Cheers,?

Timoth?e

*****************************************************?
Timoth?e Bonnet
Post-Doctoral researcher

Department of Evolutionary Biology and Environmental Studies
University of Z?rich-Irchel
Winterthurerstrasse 190
CH-8057 Z?rich
Switzerland

Office Y13-J-34
phone: +41 (0)44 635 47 66
e.mail:?timothee.bonnet at ieu.uzh.ch


*****************************************************

Hi,

It depends on what you call "plasticity". Most often, plasticity is defined as the part of phenotypic variability that varies according to environment. Without an experimental settings or environmental replications, it's very hard to distinguish from random phenotypic variability.

I've heard people considering that the environmental variance is a measure of plasticity, but it seems to me that this is a huge assumption that random variability is negligible, especially if you have only 1 environment.

Cheers,
Pierre.

On Monday, 8 May 2017 11:25:59 NZST Walid wrote:
> Hi everyone,
> 
> I have a question on a certain assumption made regarding the 'animal' 
> model when implemented in a quantitative genetic study for a trait. 
> While reading van Benthem et al. (2016), the author mentions that the 
> residual (environmental) value, in the additive partitioning assumed by 
> the model, captures plasticity. Does this assumption always hold? or 
> only in the case where we model the maternal, permanent environment and 
> common environment?
> 
> My question is for the purpose of estimating the plasticity of a fixed 
> heritable life-history trait (occurs only once during individual 
> lifetime). Since there are no explicit methods to estimate individual 
> plasticity in a non-labile trait, I am attempting to see if I can 
> circumvent this by using the 'animal' model based on the assumption 
> mentioned above.
> 
> Thank you
> 
>

	[[alternative HTML version deleted]]


From walidmawass10 at gmail.com  Tue May  9 16:05:40 2017
From: walidmawass10 at gmail.com (Walid)
Date: Tue, 9 May 2017 10:05:40 -0400
Subject: [R-sig-ME] Animal model residual value
In-Reply-To: <OFCF7B5C62.D49EC09C-ONC125811B.00384310-C125811B.003BC236@lotus.uzh.ch>
References: <mailman.2552.1494293169.1412.r-sig-mixed-models@r-project.org>
 <OFCF7B5C62.D49EC09C-ONC125811B.00384310-C125811B.003BC236@lotus.uzh.ch>
Message-ID: <3dd413ad-4baf-187b-8113-6f85ddf71a95@gmail.com>

Thank you for you response,

I am trying to study plastic phenotypic response of life-history trait 
in a human population, age at first reproduction,  through historical 
data, so I cannot use experimental design. I have two variables which 
are proxies of resource availability, a climactic variable and a 
demographic variable. The major problem that I don't seem to find an 
answer to is that since my trait is non-labile then it would be 
difficult to study its plasticity since there is no repeatability within 
the individual. One solution was to try to use the breeding values 
already obtained for this trait instead of the phenotypic values and 
check their distribution along the environmental gradient.

I won't prolong this, since this list is mostly about mixed models, I 
only wanted to see that if I explicitly include the environmental 
variable in my model, can I interpret the residual variance I estimate 
as capturing some of the phenotypic plasticity from this variable.

Thank you again,

-- 
Walid Mawass
Maitrise en Biologie Cellulaire et Mol?culaire
Laboratoire de G?n?tique des Populations
D?partement de Chimie, Biochimie et Physique
Universit? du Quebec ? Trois-Rivi?res
3351, Boul. des Forges, C.P.500
Tel. (819)-376-5011 poste 3384

On 5/9/2017 6:52 AM, timothee.bonnet at ieu.uzh.ch wrote:
> Hi all,
>
> As a co-author of the van Benthem & al. (2016) paper, let me try and clarify what was meant here.
>
> I agree with Pierre that this is a semantic problem, more than a modelling assumption.
> We defined plasticity as the non-heritable component of a trait (i.e., 1 - heritability ; or the ability of a genotype to produce different phenotypes). This definition is probably animal modeler slang, but I think it conveys the idea that there is no "truly random" phenotypic variation, only numerous environmental influences, observed or unobserved.
>
> The residual variance from an animal model like the one used in our paper would capture the plasticity in response to all environmental influences (including what you could call developmental noise or random phenotypic variability).
> If instead you are interested in the plastic response to a specific environmental variable (a "reaction-norm" definition of plasticity), you will probably have to include this variable explicitly in your model (but difficult to tell how without more details).
>
> Cheers,
>
> Timoth?e
>
> *****************************************************
> Timoth?e Bonnet
> Post-Doctoral researcher
>
> Department of Evolutionary Biology and Environmental Studies
> University of Z?rich-Irchel
> Winterthurerstrasse 190
> CH-8057 Z?rich
> Switzerland
>
> Office Y13-J-34
> phone: +41 (0)44 635 47 66
> e.mail: timothee.bonnet at ieu.uzh.ch
>
>
> *****************************************************
>
> Hi,
>
> It depends on what you call "plasticity". Most often, plasticity is defined as the part of phenotypic variability that varies according to environment. Without an experimental settings or environmental replications, it's very hard to distinguish from random phenotypic variability.
>
> I've heard people considering that the environmental variance is a measure of plasticity, but it seems to me that this is a huge assumption that random variability is negligible, especially if you have only 1 environment.
>
> Cheers,
> Pierre.
>
> On Monday, 8 May 2017 11:25:59 NZST Walid wrote:
>> Hi everyone,
>>
>> I have a question on a certain assumption made regarding the 'animal'
>> model when implemented in a quantitative genetic study for a trait.
>> While reading van Benthem et al. (2016), the author mentions that the
>> residual (environmental) value, in the additive partitioning assumed by
>> the model, captures plasticity. Does this assumption always hold? or
>> only in the case where we model the maternal, permanent environment and
>> common environment?
>>
>> My question is for the purpose of estimating the plasticity of a fixed
>> heritable life-history trait (occurs only once during individual
>> lifetime). Since there are no explicit methods to estimate individual
>> plasticity in a non-labile trait, I am attempting to see if I can
>> circumvent this by using the 'animal' model based on the assumption
>> mentioned above.
>>
>> Thank you
>>
>>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Walid Mawass
Maitrise en Biologie Cellulaire et Mol?culaire
Laboratoire de G?n?tique des Populations
D?partement de Chimie, Biochimie et Physique
Universit? du Quebec ? Trois-Rivi?res
3351, Boul. des Forges, C.P.500
Tel. (819)-376-5011 poste 3384


From famingw at gmail.com  Tue May  9 20:11:03 2017
From: famingw at gmail.com (Faming Wang)
Date: Tue, 09 May 2017 18:11:03 +0000
Subject: [R-sig-ME] A question on using LME model in species nested within a
	random block design
In-Reply-To: <CAHtaSOVu2W0mjsnFR5PS+SesjALg-sRf1WzsQdjZF8zypOrQRg@mail.gmail.com>
References: <CAHtaSOVu2W0mjsnFR5PS+SesjALg-sRf1WzsQdjZF8zypOrQRg@mail.gmail.com>
Message-ID: <CAHtaSOUfi6Z-YFgckY+H7S-Udwi=f4KKT2d7ksdw=Hroo-Dumw@mail.gmail.com>

Dear all,


 I have conducted an N and P field addition experiment in a tropical
forest, and we used a random block design in this experiment, briefly, we
had four randomly distributed plots in each block (Control, +N? +P,
and +NP), and five blocks located in the forest. Totally we have 20 plots,
with two N treatments and two P treatment and five replicated blocks. In
each plot, we selected five  species  plants (some plots only contains 3 or
4 species) to measure their leave variables, like N concentration, P
concentration, and photosynthesis rate et al.  We want to know the effect
of N and P addition as well as the species level changes (inter-species )
 on leaf variables. Since some plots some specific species are missing in
some plots some specific species, it was unbalanced at the species level.
We used linear mixed effect models to conduct our statistical analysis:

  We firstly tested the random effect with blocks, and species within plots
within blocks, and found that nesting plots and species within block did
not improve the model fitness, so we choose only block as random effect.
For fixed effects, N-addition, P-addition, species and their interaction
were considered fixed effects in models. The significance of each term was
determined by comparing nested models using likelihood ratio tests and AICs
to check for model improvement. Since there was better model fit (lower AIC
values) with interaction terms, we selected the full factor model. However,
as there was a highly significant effect of tree species identity and
species related interactions, species-specific responses to N- and
P-addition were also investigated with separate models with N, P and their
interaction as fixed effects and block as a random effect.
 however, our reviewers were not happy with this statistical methods and
pointed out that "Species is treated as a fixed factor, generating a
three-way factorial ANOVA. Species cannot be treated in this way because
all five species were present in each 10-by-10-m plot. To implement a
three-way ANOVA design, the entire experiment (five blocks of the four
factorial N and P treatments) would have to be repeated once for each
species. Species cannot be treated as a fixed factor because all five
species were measured in the same experimental plots. This is a split-plot
design. Alternatively, MANOVA might be performed treating the five species
as five response variables. A split-plot design or a MANOVA approach would
allow the authors to investigate interspecific variation in responses."

  I am very confused on the reviewer's comments,  it seems to me that the
reviewer compared our LME model with 3-way ANOVA. If we used 3-way ANOVA, I
know that my experiment is species nested in a random block design, and we
could not directly use 3-Way ANOVA, which the error df would be
overestimated.

   Below I attached my sample data and my current R script for LME model in
dropbox. See below links:
https://www.dropbox.com/s/6kd3kq5mlyuyqz6/NPrawdata.csv?dl=0

https://www.dropbox.com/s/fpqdbm6go0g8ak0/Faming%20NP%20model.R?dl=0


-- 

Sincerely

Faming Wang

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed May 10 20:30:23 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 10 May 2017 14:30:23 -0400
Subject: [R-sig-ME] Fwd: Re: R-core post from jw1085@wildcats.unh.edu
 requires approval
In-Reply-To: <f0192a4d-8958-8039-9f3b-7e3ac8c6d49d@wildcats.unh.edu>
References: <CADfFDC5aQXH-irBgn4p=GVG_W-tBYoi=1JRRpwUxFEwkkq+cAA@mail.gmail.com>
 <e0b6bad7-8798-08b2-1e7f-14f0b86a68d1@wildcats.unh.edu>
 <CAKFxdiT1Otsw6+qw3kkTjn_0=g91uj2nFnvoAdKewPaTPuCv8A@mail.gmail.com>
 <CABghstSssKgLB3kFXjeD4vbZPLFvf-mkDZ8P93-D7qQ5xapNqA@mail.gmail.com>
 <f0192a4d-8958-8039-9f3b-7e3ac8c6d49d@wildcats.unh.edu>
Message-ID: <CABghstSwn5oDz8ui8atjzzY5qTGReG0p9uJNBuRZFtERGZssqQ@mail.gmail.com>

It doesn't look like r-sig-mixed-models was in the Cc: , please keep that in ...

   The list doesn't take attachments, so if you want to include data
either (if it's short) use dput() and cut-and-paste the text, or (if
it's long) post it somewhere.

  In any case, cutting-and-pasting the results of sessionInfo() will
be extremely useful in helping us get farther.  It would also help if
you responded to the question about whether lme4 is a feasible
alternative ...


On Wed, May 10, 2017 at 2:07 PM, Jochen Wirsing <jw1085 at wildcats.unh.edu> wrote:
> Dear all,
>
> thank you very much for you good and helpful input. I would like to
> provide a subset of my data, to show the problem, but don't know whether
> I could (or should) just send it as an attachment.
>
> The code I'm using is:
>
> ### Unconditional Model
> library(nlme)
> library(broom)
>
> uncmod <- lme(fixed = year_c~1, random = ~1|Place, data = data2, method
> ="ML")
> tidy(uncmod)
> summary(uncmod)
> varCorr(uncmod)
>
>
> And the Error I'm getting is
> Error in pdFactor.pdLogChol(X[[i]], ...) : object 'logChol_pd' not found
>
> I'd really appreciate if this issue could be fixed, so that I can keep
> on using R productively in my studies.
>
> Best,
> Jochen Wirsing
>
>
> On 05/08/2017 03:43 PM, Ben Bolker wrote:
>> My only wild guess about this is that there are (still unresolved as
>> far as I know) issues with the latest version of Matrix on 32-bit
>> operating systems (unlikely unless you're using Linux, and even then
>> slightly rare).  If so (sessionInfo() will tell us this), reverting to
>> the previous version of Matrix (e.g. see ?devtools::install_version)
>> should help.
>>
>> On Mon, May 8, 2017 at 2:42 PM, Kevin Wright <kw.stat at gmail.com> wrote:
>>> Somebody might be able to look at your error message and figure out what is
>>> wrong, but often that is not possible just by looking.  If you want people
>>> to help you, then you need to help people understand your problem, perhaps
>>> using simulated data.  See:
>>> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>>>
>>> Kevin
>>>
>>> On Mon, May 8, 2017 at 11:50 AM, Jochen Wirsing <jw1085 at wildcats.unh.edu>
>>> wrote:
>>>
>>>> Dear R Mixed Models SIG,
>>>>
>>>> below you will find an email that I originally sent to the R core group,
>>>> who technically is the maintainer of the nlme package, with which I've
>>>> had some serious issues since the last update. Since this seems to keep
>>>> preventing me from using R for my project, I am reaching out to you,
>>>> hoping this problem can be fixed in a timely manner, as it probably
>>>> affects a lot of other people as well.
>>>>
>>>>
>>>> Thank you very much,
>>>>
>>>> Jochen Wirsing
>>>>
>>>> -------- Forwarded Message --------
>>>> Subject:        Re: R-core post from jw1085 at wildcats.unh.edu requires
>>>> approval
>>>> Date:   Wed, 3 May 2017 15:11:09 +0530
>>>> From:   Deepayan Sarkar <deepayan.sarkar at gmail.com>
>>>> To:     r-core-owner at r-project.org, Jochen Wirsing <
>>>> jw1085 at wildcats.unh.edu>
>>>>
>>>>
>>>>
>>>> Dear Jochen Wirsing,
>>>>
>>>> Although r-core is technically the maintainer of nlme, you should
>>>> write to one of the public R mailing lists get help regarding such
>>>> problems: see
>>>>
>>>> https://www.r-project.org/mail.html
>>>>
>>>> Either R-help or R-SIG-mixed-models should be appropriate.
>>>>
>>>> Best,
>>>> -Deepayan
>>>>
>>>>> ---------- Forwarded message ----------
>>>>> From: Jochen Wirsing <jw1085 at wildcats.unh.edu>
>>>>> To: R-core at r-project.org
>>>>> Cc:
>>>>> Bcc:
>>>>> Date: Mon, 1 May 2017 11:38:09 -0400
>>>>> Subject: Problem with nlme after update to R 3.4.0
>>>>>
>>>>> Dear Sir or Madam,
>>>>>
>>>>> I am a grad student at UNH, teaching myself how to use R. Not having a
>>>> background in programming, it is a bit hard to figure out what's wrong, so
>>>> I thought I should let you know.
>>>>> Last night, I ran an MLM, and it worked just fine. This morning though,
>>>> I saw that there is a new Version of RStudio as well as R itself, so I
>>>> updated both. After doing so, the very identical code that worked last
>>>> night, doesn't work anymore and throws a rather obscure (at least to me)
>>>> error:
>>>>>
>>>>> 15.
>>>>> pdFactor.pdLogChol(X[[i]], ...)
>>>>> 14.
>>>>> FUN(X[[i]], ...)
>>>>> 13.
>>>>> lapply(object, pdFactor)
>>>>> 12.
>>>>> unlist(lapply(object, pdFactor))
>>>>> 11.
>>>>> pdFactor.reStruct(object)
>>>>> 10.
>>>>> pdFactor(object)
>>>>> 9.
>>>>> unlist(pdFactor(object))
>>>>> 8.
>>>>> MEEM(object, conLin, control$niterEM)
>>>>> 7.
>>>>> Initialize.reStruct(X[[i]], ...)
>>>>> 6.
>>>>> FUN(X[[i]], ...)
>>>>> 5.
>>>>> lapply(object, Initialize, data, conLin, control)
>>>>> 4.
>>>>> Initialize.lmeStruct(lmeSt, dataMix, grps, control = controlvals)
>>>>> 3.
>>>>> Initialize(lmeSt, dataMix, grps, control = controlvals)
>>>>> 2.
>>>>> lme.formula(fixed = year_c ~ 1, random = ~1 | ID, data = data, method =
>>>> "ML")
>>>>> 1.
>>>>> lme(fixed = year_c ~ 1, random = ~1 | ID, data = data, method = "ML")
>>>>>
>>>>>
>>>>>
>>>>> The code I used was:
>>>>>
>>>>> ### Unconditional Model
>>>>> library(nlme)
>>>>> library(broom)
>>>>>
>>>>> uncmod <- lme(fixed = year_c~1, random = ~1|ID, data = data, method
>>>> ="ML")
>>>>> tidy(uncmod)
>>>>> summary(uncmod)
>>>>> varCorr(uncmod)
>>>>>
>>>>>
>>>>>
>>>>> I hope this helps and the problem can be fixed soon, because right now,
>>>> I am stopped dead in my work, unable using the nlme package, on which my
>>>> analysis depends.
>>>>>
>>>>> Thank you very much for your consideration, help, and good work!
>>>>>
>>>>>
>>>>> Best,
>>>>>
>>>>>
>>>>> Jochen Wirsing
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>>
>>> --
>>> Kevin Wright
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From jw1085 at wildcats.unh.edu  Wed May 10 20:09:56 2017
From: jw1085 at wildcats.unh.edu (Jochen Wirsing)
Date: Wed, 10 May 2017 14:09:56 -0400
Subject: [R-sig-ME] nlme issue
Message-ID: <b232878f-ffd5-abef-7058-f623d82c3b85@wildcats.unh.edu>

Dear all,

thank you very much for you good and helpful input. I would like to
provide a subset of my data, to show the problem, but don't know whether
I could (or should) just send it as an attachment.

The code I'm using is:

### Unconditional Model
library(nlme)
library(broom)

uncmod <- lme(fixed = year_c~1, random = ~1|Place, data = data2, method
="ML")
tidy(uncmod)
summary(uncmod)
varCorr(uncmod)


And the Error I'm getting is
Error in pdFactor.pdLogChol(X[[i]], ...) : object 'logChol_pd' not found

I'd really appreciate if this issue could be fixed, so that I can keep
on using R productively in my studies.

Best,
Jochen Wirsing



______________
> R.version
               _                           
platform       x86_64-pc-linux-gnu         
arch           x86_64                      
os             linux-gnu                   
system         x86_64, linux-gnu           
status                                     
major          3                           
minor          4.0                         
year           2017                        
month          04                          
day            21                          
svn rev        72570                       
language       R                           
version.string R version 3.4.0 (2017-04-21)
nickname       You Stupid Darkness      

__________________

R version 3.4.0 (2017-04-21)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 16.04.2 LTS

Matrix products: default
BLAS: /usr/lib/openblas-base/libblas.so.3
LAPACK: /usr/lib/libopenblasp-r0.2.18.so

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods  
[7] base     

other attached packages:
 [1] broom_0.4.2     nlme_3.1-131    sjPlot_2.3.1   
 [4] sjmisc_2.4.0    dplyr_0.5.0     purrr_0.2.2    
 [7] readr_1.1.0     tidyr_0.6.2     tibble_1.3.0   
[10] ggplot2_2.2.1   tidyverse_1.1.1 MASS_7.3-47    

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.10       stringdist_0.9.4.4 lubridate_1.6.0   
 [4] mvtnorm_1.0-6      lattice_0.20-35    zoo_1.8-0         
 [7] lmtest_0.9-35      assertthat_0.2.0   digest_0.6.12     
[10] psych_1.7.5        mime_0.5           R6_2.2.1          
[13] cellranger_1.1.0   plyr_1.8.4         stats4_3.4.0      
[16] coda_0.19-1        httr_1.2.1         multcomp_1.4-6    
[19] lazyeval_0.2.0     readxl_1.0.0       minqa_1.2.4       
[22] nloptr_1.0.4       Matrix_1.2-7.1     DT_0.2            
[25] splines_3.4.0      lme4_1.1-13        stringr_1.2.0     
[28] foreign_0.8-68     htmlwidgets_0.8    munsell_0.4.3     
[31] shiny_1.0.3        compiler_3.4.0     httpuv_1.3.3      
[34] modelr_0.1.0       mnormt_1.5-5       htmltools_0.3.6   
[37] nnet_7.3-12        coin_1.1-3         codetools_0.2-15  
[40] grid_3.4.0         jsonlite_1.4       arm_1.9-3         
[43] xtable_1.8-2       gtable_0.2.0       DBI_0.6-1         
[46] magrittr_1.5       scales_0.4.1       stringi_1.1.5     
[49] reshape2_1.4.2     xml2_1.1.1         effects_3.1-2     
[52] sandwich_2.3-4     TH.data_1.0-8      blme_1.0-4        
[55] tools_3.4.0        forcats_0.2.0      sjstats_0.10.0    
[58] hms_0.3            survival_2.41-3    abind_1.4-5       
[61] parallel_3.4.0     colorspace_1.3-2   rvest_0.3.2       
[64] knitr_1.15.1       haven_1.0.0        modeltools_0.2-21 
[67] merTools_0.3.0


From jw1085 at wildcats.unh.edu  Wed May 10 22:05:45 2017
From: jw1085 at wildcats.unh.edu (Jochen Wirsing)
Date: Wed, 10 May 2017 16:05:45 -0400
Subject: [R-sig-ME] nlme issue since 3.40
Message-ID: <7090cf76-c9fc-8dd1-a73d-e31c41453014@wildcats.unh.edu>

Dear All,


thanks again for your nice feedback. The Session Info etc was mentioned
in the previous email, but one of the folks here on the list asked me to
use dput() so I could paste my data in textform here.

So here you go:

structure(list(Place = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L), .Label =
c("Cambridge Bay",
"Iqaluit", "Rankin Inlet"), class = "factor"), year_c = c(-2,
-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, -2,
-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, -2,
-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15), SR_Total_ctd
= c(NA,
NA, 5.48961420000001, 7.24637679999999, 3.76569040000001, 6.9014085,
9.3088858, 5.1771117, 7.51366120000002, 7.18157180000001, 3.7275064,
5.7397959, 6.87500000000001, 6.25, 5.84577109999999, 6.2421973,
4.70446319999999, NA, NA, NA, 11.9192688, 9.6291013, 8.54640980000001,
8.7893297, 7.42343539999999, 5, 5.3674121, 6.1322261, 6.4182843,
5.75692960000001, 6.3861534, 6.6706021, 7.76642339999999, 6.91983119999999,
5.3634631, NA, NA, NA, 0.0870321999999959, -1.19047620000001,
-1.8723404, -0.4244482, 1.18443319999999, 2.19594590000001,
1.57545610000001,
3.080766, 1.8744906, 5.51053480000002, 6.31412790000002, 7.4451411,
8.1226054, 9.52743899999999, 9.4339623, NA)), .Names = c("Place",
"year_c", "SR_Total_ctd"), row.names = c(NA, -54L), class = "data.frame")
> 


I was also asked, whether using lme4 would be an option, but I don't
think that this will help fix the issue that I believe occurred through
updating to R 3.40. Also, nlme provides some information in a nicer way
(covariances etc, if I remember correctly - all this is still very new
to me....), so I'd really rather see nlme fixed.


Thanks again!


	[[alternative HTML version deleted]]


From tom_philippi at nps.gov  Wed May 10 22:54:02 2017
From: tom_philippi at nps.gov (Philippi, Tom)
Date: Wed, 10 May 2017 13:54:02 -0700
Subject: [R-sig-ME] nlme issue since 3.40
In-Reply-To: <7090cf76-c9fc-8dd1-a73d-e31c41453014@wildcats.unh.edu>
References: <7090cf76-c9fc-8dd1-a73d-e31c41453014@wildcats.unh.edu>
Message-ID: <CAM9kYqgTMcdrQ=GUug4XiJ53Qki3wNtADnWxyc2a6w1F1r5d2g@mail.gmail.com>

Jochen--

Using R 3.4 and nlme 3.1-131 on MS win7 and the data you included in the
other message thread, I cannot duplicate your error.  It also runs fine
under MRAN 3.3.2 on MS win7 which uses the Intel MKL.  I haven't yet
updated R to 3.4 on my linux ubuntu box to test there, but my best guess
now is that something failed in your update to 3.4.


> library(nlme)
> library(broom)
>
> data2 <- structure(list(Place = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
+ 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L,
+ 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L,
+ 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L), .Label =
+ c("Cambridge Bay",
+ "Iqaluit", "Rankin Inlet"), class = "factor"), year_c = c(-2,
+ -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, -2,
+ -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, -2,
+ -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15), SR_Total_ctd
+ = c(NA,
+ NA, 5.48961420000001, 7.24637679999999, 3.76569040000001, 6.9014085,
+ 9.3088858, 5.1771117, 7.51366120000002, 7.18157180000001, 3.7275064,
+ 5.7397959, 6.87500000000001, 6.25, 5.84577109999999, 6.2421973,
+ 4.70446319999999, NA, NA, NA, 11.9192688, 9.6291013, 8.54640980000001,
+ 8.7893297, 7.42343539999999, 5, 5.3674121, 6.1322261, 6.4182843,
+ 5.75692960000001, 6.3861534, 6.6706021, 7.76642339999999,
6.91983119999999,
+ 5.3634631, NA, NA, NA, 0.0870321999999959, -1.19047620000001,
+ -1.8723404, -0.4244482, 1.18443319999999, 2.19594590000001,
+ 1.57545610000001,
+ 3.080766, 1.8744906, 5.51053480000002, 6.31412790000002, 7.4451411,
+ 8.1226054, 9.52743899999999, 9.4339623, NA)), .Names = c("Place",
+ "year_c", "SR_Total_ctd"), row.names = c(NA, -54L), class = "data.frame")
>
>
> uncmod <- lme(fixed = year_c~1, random = ~1|Place, data = data2,
method="ML")
> tidy(uncmod)
  group         level        term estimate
1 Place Cambridge Bay (Intercept)      6.5
2 Place       Iqaluit (Intercept)      6.5
3 Place  Rankin Inlet (Intercept)      6.5
> summary(uncmod)
Linear mixed-effects model fit by maximum likelihood
 Data: data2
       AIC      BIC    logLik
  337.0536 343.0206 -165.5268

Random effects:
 Formula: ~1 | Place
         (Intercept) Residual
StdDev: 0.0001350644 5.188127

Fixed effects: year_c ~ 1
            Value Std.Error DF  t-value p-value
(Intercept)   6.5 0.7126441 51 9.120962       0

Standardized Within-Group Residuals:
          Min            Q1           Med            Q3           Max
-1.638356e+00 -8.673650e-01 -1.193490e-15  8.673650e-01  1.638356e+00

Number of Observations: 54
Number of Groups: 3
> VarCorr(uncmod)
Place = pdLogChol(1)
            Variance     StdDev
(Intercept) 1.824240e-08 0.0001350644
Residual    2.691667e+01 5.1881274721
>
> sessionInfo()
R version 3.4.0 (2017-04-21)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] broom_0.4.2  nlme_3.1-131

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.10     lattice_0.20-35  tidyr_0.6.1      psych_1.7.3.21
 [5] dplyr_0.5.0      assertthat_0.2.0 grid_3.4.0       R6_2.2.0
 [9] plyr_1.8.4       DBI_0.6-1        magrittr_1.5     stringi_1.1.5
[13] lazyeval_0.2.0   reshape2_1.4.2   tools_3.4.0      stringr_1.2.0
[17] foreign_0.8-67   parallel_3.4.0   compiler_3.4.0   mnormt_1.5-5
[21] tibble_1.3.0


Tom 2


On Wed, May 10, 2017 at 1:05 PM, Jochen Wirsing <jw1085 at wildcats.unh.edu>
wrote:

> Dear All,
>
>
> thanks again for your nice feedback. The Session Info etc was mentioned
> in the previous email, but one of the folks here on the list asked me to
> use dput() so I could paste my data in textform here.
>
> So here you go:
>
> structure(list(Place = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L), .Label =
> c("Cambridge Bay",
> "Iqaluit", "Rankin Inlet"), class = "factor"), year_c = c(-2,
> -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, -2,
> -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, -2,
> -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15), SR_Total_ctd
> = c(NA,
> NA, 5.48961420000001, 7.24637679999999, 3.76569040000001, 6.9014085,
> 9.3088858, 5.1771117, 7.51366120000002, 7.18157180000001, 3.7275064,
> 5.7397959, 6.87500000000001, 6.25, 5.84577109999999, 6.2421973,
> 4.70446319999999, NA, NA, NA, 11.9192688, 9.6291013, 8.54640980000001,
> 8.7893297, 7.42343539999999, 5, 5.3674121, 6.1322261, 6.4182843,
> 5.75692960000001, 6.3861534, 6.6706021, 7.76642339999999, 6.91983119999999,
> 5.3634631, NA, NA, NA, 0.0870321999999959, -1.19047620000001,
> -1.8723404, -0.4244482, 1.18443319999999, 2.19594590000001,
> 1.57545610000001,
> 3.080766, 1.8744906, 5.51053480000002, 6.31412790000002, 7.4451411,
> 8.1226054, 9.52743899999999, 9.4339623, NA)), .Names = c("Place",
> "year_c", "SR_Total_ctd"), row.names = c(NA, -54L), class = "data.frame")
> >
>
>
> I was also asked, whether using lme4 would be an option, but I don't
> think that this will help fix the issue that I believe occurred through
> updating to R 3.40. Also, nlme provides some information in a nicer way
> (covariances etc, if I remember correctly - all this is still very new
> to me....), so I'd really rather see nlme fixed.
>
>
> Thanks again!
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

	[[alternative HTML version deleted]]


From torsten.hauffe at gmail.com  Wed May 10 23:15:06 2017
From: torsten.hauffe at gmail.com (Torsten Hauffe)
Date: Wed, 10 May 2017 17:15:06 -0400
Subject: [R-sig-ME] nlme issue since 3.40
In-Reply-To: <CAM9kYqgTMcdrQ=GUug4XiJ53Qki3wNtADnWxyc2a6w1F1r5d2g@mail.gmail.com>
References: <7090cf76-c9fc-8dd1-a73d-e31c41453014@wildcats.unh.edu>
 <CAM9kYqgTMcdrQ=GUug4XiJ53Qki3wNtADnWxyc2a6w1F1r5d2g@mail.gmail.com>
Message-ID: <CAGCrCxasDdzRK_V+viHsbpfmbn0q3ORQD5wR=0CwePYfLnBd-g@mail.gmail.com>

Working with Ubuntu 16.04 64 bit. Same point estimates as Tom.

On 10 May 2017 at 16:54, Philippi, Tom <tom_philippi at nps.gov> wrote:

> Jochen--
>
> Using R 3.4 and nlme 3.1-131 on MS win7 and the data you included in the
> other message thread, I cannot duplicate your error.  It also runs fine
> under MRAN 3.3.2 on MS win7 which uses the Intel MKL.  I haven't yet
> updated R to 3.4 on my linux ubuntu box to test there, but my best guess
> now is that something failed in your update to 3.4.
>
>
> > library(nlme)
> > library(broom)
> >
> > data2 <- structure(list(Place = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
> + 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L,
> + 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L,
> + 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L), .Label =
> + c("Cambridge Bay",
> + "Iqaluit", "Rankin Inlet"), class = "factor"), year_c = c(-2,
> + -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, -2,
> + -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, -2,
> + -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15), SR_Total_ctd
> + = c(NA,
> + NA, 5.48961420000001, 7.24637679999999, 3.76569040000001, 6.9014085,
> + 9.3088858, 5.1771117, 7.51366120000002, 7.18157180000001, 3.7275064,
> + 5.7397959, 6.87500000000001, 6.25, 5.84577109999999, 6.2421973,
> + 4.70446319999999, NA, NA, NA, 11.9192688, 9.6291013, 8.54640980000001,
> + 8.7893297, 7.42343539999999, 5, 5.3674121, 6.1322261, 6.4182843,
> + 5.75692960000001, 6.3861534, 6.6706021, 7.76642339999999,
> 6.91983119999999,
> + 5.3634631, NA, NA, NA, 0.0870321999999959, -1.19047620000001,
> + -1.8723404, -0.4244482, 1.18443319999999, 2.19594590000001,
> + 1.57545610000001,
> + 3.080766, 1.8744906, 5.51053480000002, 6.31412790000002, 7.4451411,
> + 8.1226054, 9.52743899999999, 9.4339623, NA)), .Names = c("Place",
> + "year_c", "SR_Total_ctd"), row.names = c(NA, -54L), class = "data.frame")
> >
> >
> > uncmod <- lme(fixed = year_c~1, random = ~1|Place, data = data2,
> method="ML")
> > tidy(uncmod)
>   group         level        term estimate
> 1 Place Cambridge Bay (Intercept)      6.5
> 2 Place       Iqaluit (Intercept)      6.5
> 3 Place  Rankin Inlet (Intercept)      6.5
> > summary(uncmod)
> Linear mixed-effects model fit by maximum likelihood
>  Data: data2
>        AIC      BIC    logLik
>   337.0536 343.0206 -165.5268
>
> Random effects:
>  Formula: ~1 | Place
>          (Intercept) Residual
> StdDev: 0.0001350644 5.188127
>
> Fixed effects: year_c ~ 1
>             Value Std.Error DF  t-value p-value
> (Intercept)   6.5 0.7126441 51 9.120962       0
>
> Standardized Within-Group Residuals:
>           Min            Q1           Med            Q3           Max
> -1.638356e+00 -8.673650e-01 -1.193490e-15  8.673650e-01  1.638356e+00
>
> Number of Observations: 54
> Number of Groups: 3
> > VarCorr(uncmod)
> Place = pdLogChol(1)
>             Variance     StdDev
> (Intercept) 1.824240e-08 0.0001350644
> Residual    2.691667e+01 5.1881274721
> >
> > sessionInfo()
> R version 3.4.0 (2017-04-21)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
>
> Matrix products: default
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] broom_0.4.2  nlme_3.1-131
>
> loaded via a namespace (and not attached):
>  [1] Rcpp_0.12.10     lattice_0.20-35  tidyr_0.6.1      psych_1.7.3.21
>  [5] dplyr_0.5.0      assertthat_0.2.0 grid_3.4.0       R6_2.2.0
>  [9] plyr_1.8.4       DBI_0.6-1        magrittr_1.5     stringi_1.1.5
> [13] lazyeval_0.2.0   reshape2_1.4.2   tools_3.4.0      stringr_1.2.0
> [17] foreign_0.8-67   parallel_3.4.0   compiler_3.4.0   mnormt_1.5-5
> [21] tibble_1.3.0
>
>
> Tom 2
>
>
> On Wed, May 10, 2017 at 1:05 PM, Jochen Wirsing <jw1085 at wildcats.unh.edu>
> wrote:
>
> > Dear All,
> >
> >
> > thanks again for your nice feedback. The Session Info etc was mentioned
> > in the previous email, but one of the folks here on the list asked me to
> > use dput() so I could paste my data in textform here.
> >
> > So here you go:
> >
> > structure(list(Place = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
> > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L,
> > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L,
> > 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L), .Label =
> > c("Cambridge Bay",
> > "Iqaluit", "Rankin Inlet"), class = "factor"), year_c = c(-2,
> > -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, -2,
> > -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, -2,
> > -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15), SR_Total_ctd
> > = c(NA,
> > NA, 5.48961420000001, 7.24637679999999, 3.76569040000001, 6.9014085,
> > 9.3088858, 5.1771117, 7.51366120000002, 7.18157180000001, 3.7275064,
> > 5.7397959, 6.87500000000001, 6.25, 5.84577109999999, 6.2421973,
> > 4.70446319999999, NA, NA, NA, 11.9192688, 9.6291013, 8.54640980000001,
> > 8.7893297, 7.42343539999999, 5, 5.3674121, 6.1322261, 6.4182843,
> > 5.75692960000001, 6.3861534, 6.6706021, 7.76642339999999,
> 6.91983119999999,
> > 5.3634631, NA, NA, NA, 0.0870321999999959, -1.19047620000001,
> > -1.8723404, -0.4244482, 1.18443319999999, 2.19594590000001,
> > 1.57545610000001,
> > 3.080766, 1.8744906, 5.51053480000002, 6.31412790000002, 7.4451411,
> > 8.1226054, 9.52743899999999, 9.4339623, NA)), .Names = c("Place",
> > "year_c", "SR_Total_ctd"), row.names = c(NA, -54L), class = "data.frame")
> > >
> >
> >
> > I was also asked, whether using lme4 would be an option, but I don't
> > think that this will help fix the issue that I believe occurred through
> > updating to R 3.40. Also, nlme provides some information in a nicer way
> > (covariances etc, if I remember correctly - all this is still very new
> > to me....), so I'd really rather see nlme fixed.
> >
> >
> > Thanks again!
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Thu May 11 03:29:41 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 10 May 2017 18:29:41 -0700
Subject: [R-sig-ME] nlme issue
In-Reply-To: <b232878f-ffd5-abef-7058-f623d82c3b85@wildcats.unh.edu>
References: <b232878f-ffd5-abef-7058-f623d82c3b85@wildcats.unh.edu>
Message-ID: <656373FB-9033-4555-8AA7-ECE1205751C6@dcn.davis.ca.us>

Read ?dput and use it to create an R code that will recreate your data in our R environment. 
-- 
Sent from my phone. Please excuse my brevity.

On May 10, 2017 11:09:56 AM PDT, Jochen Wirsing <jw1085 at wildcats.unh.edu> wrote:
>Dear all,
>
>thank you very much for you good and helpful input. I would like to
>provide a subset of my data, to show the problem, but don't know
>whether
>I could (or should) just send it as an attachment.
>
>The code I'm using is:
>
>### Unconditional Model
>library(nlme)
>library(broom)
>
>uncmod <- lme(fixed = year_c~1, random = ~1|Place, data = data2, method
>="ML")
>tidy(uncmod)
>summary(uncmod)
>varCorr(uncmod)
>
>
>And the Error I'm getting is
>Error in pdFactor.pdLogChol(X[[i]], ...) : object 'logChol_pd' not
>found
>
>I'd really appreciate if this issue could be fixed, so that I can keep
>on using R productively in my studies.
>
>Best,
>Jochen Wirsing
>
>
>
>______________
>> R.version
>               _                           
>platform       x86_64-pc-linux-gnu         
>arch           x86_64                      
>os             linux-gnu                   
>system         x86_64, linux-gnu           
>status                                     
>major          3                           
>minor          4.0                         
>year           2017                        
>month          04                          
>day            21                          
>svn rev        72570                       
>language       R                           
>version.string R version 3.4.0 (2017-04-21)
>nickname       You Stupid Darkness      
>
>__________________
>
>R version 3.4.0 (2017-04-21)
>Platform: x86_64-pc-linux-gnu (64-bit)
>Running under: Ubuntu 16.04.2 LTS
>
>Matrix products: default
>BLAS: /usr/lib/openblas-base/libblas.so.3
>LAPACK: /usr/lib/libopenblasp-r0.2.18.so
>
>locale:
> [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
> [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
> [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
> [9] LC_ADDRESS=C               LC_TELEPHONE=C            
>[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       
>
>attached base packages:
>[1] stats     graphics  grDevices utils     datasets  methods  
>[7] base     
>
>other attached packages:
> [1] broom_0.4.2     nlme_3.1-131    sjPlot_2.3.1   
> [4] sjmisc_2.4.0    dplyr_0.5.0     purrr_0.2.2    
> [7] readr_1.1.0     tidyr_0.6.2     tibble_1.3.0   
>[10] ggplot2_2.2.1   tidyverse_1.1.1 MASS_7.3-47    
>
>loaded via a namespace (and not attached):
> [1] Rcpp_0.12.10       stringdist_0.9.4.4 lubridate_1.6.0   
> [4] mvtnorm_1.0-6      lattice_0.20-35    zoo_1.8-0         
> [7] lmtest_0.9-35      assertthat_0.2.0   digest_0.6.12     
>[10] psych_1.7.5        mime_0.5           R6_2.2.1          
>[13] cellranger_1.1.0   plyr_1.8.4         stats4_3.4.0      
>[16] coda_0.19-1        httr_1.2.1         multcomp_1.4-6    
>[19] lazyeval_0.2.0     readxl_1.0.0       minqa_1.2.4       
>[22] nloptr_1.0.4       Matrix_1.2-7.1     DT_0.2            
>[25] splines_3.4.0      lme4_1.1-13        stringr_1.2.0     
>[28] foreign_0.8-68     htmlwidgets_0.8    munsell_0.4.3     
>[31] shiny_1.0.3        compiler_3.4.0     httpuv_1.3.3      
>[34] modelr_0.1.0       mnormt_1.5-5       htmltools_0.3.6   
>[37] nnet_7.3-12        coin_1.1-3         codetools_0.2-15  
>[40] grid_3.4.0         jsonlite_1.4       arm_1.9-3         
>[43] xtable_1.8-2       gtable_0.2.0       DBI_0.6-1         
>[46] magrittr_1.5       scales_0.4.1       stringi_1.1.5     
>[49] reshape2_1.4.2     xml2_1.1.1         effects_3.1-2     
>[52] sandwich_2.3-4     TH.data_1.0-8      blme_1.0-4        
>[55] tools_3.4.0        forcats_0.2.0      sjstats_0.10.0    
>[58] hms_0.3            survival_2.41-3    abind_1.4-5       
>[61] parallel_3.4.0     colorspace_1.3-2   rvest_0.3.2       
>[64] knitr_1.15.1       haven_1.0.0        modeltools_0.2-21 
>[67] merTools_0.3.0
>
>_______________________________________________
>R-sig-mixed-models at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From jszhao at yeah.net  Thu May 11 05:29:08 2017
From: jszhao at yeah.net (Jinsong Zhao)
Date: Thu, 11 May 2017 11:29:08 +0800
Subject: [R-sig-ME] nlme issue since 3.40
In-Reply-To: <CAM9kYqgTMcdrQ=GUug4XiJ53Qki3wNtADnWxyc2a6w1F1r5d2g@mail.gmail.com>
References: <7090cf76-c9fc-8dd1-a73d-e31c41453014@wildcats.unh.edu>
 <CAM9kYqgTMcdrQ=GUug4XiJ53Qki3wNtADnWxyc2a6w1F1r5d2g@mail.gmail.com>
Message-ID: <46301970-cfb5-b0f4-8a7d-d5b8f06132e3@yeah.net>

Working with Win10 64 bit. Same point estimates as Tom.

R version 3.4.0 (2017-04-21)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 14393)

Matrix products: default


Best,
Jinsong

On 2017/5/11 4:54, Philippi, Tom wrote:
> Jochen--
>
> Using R 3.4 and nlme 3.1-131 on MS win7 and the data you included in the
> other message thread, I cannot duplicate your error.  It also runs fine
> under MRAN 3.3.2 on MS win7 which uses the Intel MKL.  I haven't yet
> updated R to 3.4 on my linux ubuntu box to test there, but my best guess
> now is that something failed in your update to 3.4.
>
>
>> library(nlme)
>> library(broom)
>>
>> data2 <- structure(list(Place = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
> + 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L,
> + 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L,
> + 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L), .Label =
> + c("Cambridge Bay",
> + "Iqaluit", "Rankin Inlet"), class = "factor"), year_c = c(-2,
> + -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, -2,
> + -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, -2,
> + -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15), SR_Total_ctd
> + = c(NA,
> + NA, 5.48961420000001, 7.24637679999999, 3.76569040000001, 6.9014085,
> + 9.3088858, 5.1771117, 7.51366120000002, 7.18157180000001, 3.7275064,
> + 5.7397959, 6.87500000000001, 6.25, 5.84577109999999, 6.2421973,
> + 4.70446319999999, NA, NA, NA, 11.9192688, 9.6291013, 8.54640980000001,
> + 8.7893297, 7.42343539999999, 5, 5.3674121, 6.1322261, 6.4182843,
> + 5.75692960000001, 6.3861534, 6.6706021, 7.76642339999999,
> 6.91983119999999,
> + 5.3634631, NA, NA, NA, 0.0870321999999959, -1.19047620000001,
> + -1.8723404, -0.4244482, 1.18443319999999, 2.19594590000001,
> + 1.57545610000001,
> + 3.080766, 1.8744906, 5.51053480000002, 6.31412790000002, 7.4451411,
> + 8.1226054, 9.52743899999999, 9.4339623, NA)), .Names = c("Place",
> + "year_c", "SR_Total_ctd"), row.names = c(NA, -54L), class = "data.frame")
>>
>>
>> uncmod <- lme(fixed = year_c~1, random = ~1|Place, data = data2,
> method="ML")
>> tidy(uncmod)
>   group         level        term estimate
> 1 Place Cambridge Bay (Intercept)      6.5
> 2 Place       Iqaluit (Intercept)      6.5
> 3 Place  Rankin Inlet (Intercept)      6.5
>> summary(uncmod)
> Linear mixed-effects model fit by maximum likelihood
>  Data: data2
>        AIC      BIC    logLik
>   337.0536 343.0206 -165.5268
>
> Random effects:
>  Formula: ~1 | Place
>          (Intercept) Residual
> StdDev: 0.0001350644 5.188127
>
> Fixed effects: year_c ~ 1
>             Value Std.Error DF  t-value p-value
> (Intercept)   6.5 0.7126441 51 9.120962       0
>
> Standardized Within-Group Residuals:
>           Min            Q1           Med            Q3           Max
> -1.638356e+00 -8.673650e-01 -1.193490e-15  8.673650e-01  1.638356e+00
>
> Number of Observations: 54
> Number of Groups: 3
>> VarCorr(uncmod)
> Place = pdLogChol(1)
>             Variance     StdDev
> (Intercept) 1.824240e-08 0.0001350644
> Residual    2.691667e+01 5.1881274721
>>
>> sessionInfo()
> R version 3.4.0 (2017-04-21)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
>
> Matrix products: default
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] broom_0.4.2  nlme_3.1-131
>
> loaded via a namespace (and not attached):
>  [1] Rcpp_0.12.10     lattice_0.20-35  tidyr_0.6.1      psych_1.7.3.21
>  [5] dplyr_0.5.0      assertthat_0.2.0 grid_3.4.0       R6_2.2.0
>  [9] plyr_1.8.4       DBI_0.6-1        magrittr_1.5     stringi_1.1.5
> [13] lazyeval_0.2.0   reshape2_1.4.2   tools_3.4.0      stringr_1.2.0
> [17] foreign_0.8-67   parallel_3.4.0   compiler_3.4.0   mnormt_1.5-5
> [21] tibble_1.3.0
>
>
> Tom 2
>
>
> On Wed, May 10, 2017 at 1:05 PM, Jochen Wirsing <jw1085 at wildcats.unh.edu>
> wrote:
>
>> Dear All,
>>
>>
>> thanks again for your nice feedback. The Session Info etc was mentioned
>> in the previous email, but one of the folks here on the list asked me to
>> use dput() so I could paste my data in textform here.
>>
>> So here you go:
>>
>> structure(list(Place = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L), .Label =
>> c("Cambridge Bay",
>> "Iqaluit", "Rankin Inlet"), class = "factor"), year_c = c(-2,
>> -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, -2,
>> -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, -2,
>> -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15), SR_Total_ctd
>> = c(NA,
>> NA, 5.48961420000001, 7.24637679999999, 3.76569040000001, 6.9014085,
>> 9.3088858, 5.1771117, 7.51366120000002, 7.18157180000001, 3.7275064,
>> 5.7397959, 6.87500000000001, 6.25, 5.84577109999999, 6.2421973,
>> 4.70446319999999, NA, NA, NA, 11.9192688, 9.6291013, 8.54640980000001,
>> 8.7893297, 7.42343539999999, 5, 5.3674121, 6.1322261, 6.4182843,
>> 5.75692960000001, 6.3861534, 6.6706021, 7.76642339999999, 6.91983119999999,
>> 5.3634631, NA, NA, NA, 0.0870321999999959, -1.19047620000001,
>> -1.8723404, -0.4244482, 1.18443319999999, 2.19594590000001,
>> 1.57545610000001,
>> 3.080766, 1.8744906, 5.51053480000002, 6.31412790000002, 7.4451411,
>> 8.1226054, 9.52743899999999, 9.4339623, NA)), .Names = c("Place",
>> "year_c", "SR_Total_ctd"), row.names = c(NA, -54L), class = "data.frame")
>>>
>>
>>
>> I was also asked, whether using lme4 would be an option, but I don't
>> think that this will help fix the issue that I believe occurred through
>> updating to R 3.40. Also, nlme provides some information in a nicer way
>> (covariances etc, if I remember correctly - all this is still very new
>> to me....), so I'd really rather see nlme fixed.
>>
>>
>> Thanks again!


From dcepulic at gmail.com  Thu May 11 13:00:12 2017
From: dcepulic at gmail.com (=?UTF-8?B?RG9taW5payDEhmVwdWxpxIc=?=)
Date: Thu, 11 May 2017 13:00:12 +0200
Subject: [R-sig-ME] Multilevel logistic regression guessing parameter
Message-ID: <CAGbn3HZ68nUySiJCc+G8EPCy72sw1rdHo2tp7sCPGxa0JZjMrg@mail.gmail.com>

I  have a following situation:

I want to predict variable B (which is dichotomous) from variable A
(continous) controlling for random effects on the level of a) Subjects; b)
Tasks.

A -> B (1)

The problem is that when I use model to predict the values of B from A,
values below probability of 0.5 get predicted, and in my case that doesn?t
make sense, because, if you guess at random, the probability of correct
answer on B would be 0.5.

I want to know how I can constrain the model (1) in lme4 so that it doesn?t
predict values lower than 0.5 in variable B.

Thank you,

Dominik!

	[[alternative HTML version deleted]]


From jw1085 at wildcats.unh.edu  Thu May 11 03:40:06 2017
From: jw1085 at wildcats.unh.edu (Jochen Wirsing)
Date: Wed, 10 May 2017 21:40:06 -0400
Subject: [R-sig-ME] nlme issue since 3.40
In-Reply-To: <CAGCrCxasDdzRK_V+viHsbpfmbn0q3ORQD5wR=0CwePYfLnBd-g@mail.gmail.com>
References: <7090cf76-c9fc-8dd1-a73d-e31c41453014@wildcats.unh.edu>
 <CAM9kYqgTMcdrQ=GUug4XiJ53Qki3wNtADnWxyc2a6w1F1r5d2g@mail.gmail.com>
 <CAGCrCxasDdzRK_V+viHsbpfmbn0q3ORQD5wR=0CwePYfLnBd-g@mail.gmail.com>
Message-ID: <faf701d2c9f7$87259d20$9570d760$@wildcats.unh.edu>

Thank you very much for testing and your feedback! I am terribly sorry to have brought it up to the whole list?. I really just didn?t know better. I do apologize! I thought it was a real issue. So it seems, something went wrong with my installation of the update. Sorry for making such an issue out of nothing!

 

Von: Torsten Hauffe [mailto:torsten.hauffe at gmail.com] 
Gesendet: Mittwoch, 10. Mai 2017 17:15
An: Philippi, Tom <tom_philippi at nps.gov>
Cc: Jochen Wirsing <jw1085 at wildcats.unh.edu>; r-sig-mixed-models at r-project.org
Betreff: Re: [R-sig-ME] nlme issue since 3.40

 

Working with Ubuntu 16.04 64 bit. Same point estimates as Tom.

 

On 10 May 2017 at 16:54, Philippi, Tom <tom_philippi at nps.gov <mailto:tom_philippi at nps.gov> > wrote:

Jochen--

Using R 3.4 and nlme 3.1-131 on MS win7 and the data you included in the
other message thread, I cannot duplicate your error.  It also runs fine
under MRAN 3.3.2 on MS win7 which uses the Intel MKL.  I haven't yet
updated R to 3.4 on my linux ubuntu box to test there, but my best guess
now is that something failed in your update to 3.4.


> library(nlme)
> library(broom)
>
> data2 <- structure(list(Place = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
+ 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L,
+ 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L,
+ 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L), .Label =
+ c("Cambridge Bay",
+ "Iqaluit", "Rankin Inlet"), class = "factor"), year_c = c(-2,
+ -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, -2,
+ -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, -2,
+ -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15), SR_Total_ctd
+ = c(NA,
+ NA, 5.48961420000001, 7.24637679999999, 3.76569040000001, 6.9014085,
+ 9.3088858, 5.1771117, 7.51366120000002, 7.18157180000001, 3.7275064,
+ 5.7397959, 6.87500000000001, 6.25, 5.84577109999999, 6.2421973,
+ 4.70446319999999, NA, NA, NA, 11.9192688, 9.6291013, 8.54640980000001,
+ 8.7893297, 7.42343539999999, 5, 5.3674121, 6.1322261, 6.4182843,
+ 5.75692960000001, 6.3861534, 6.6706021, 7.76642339999999,
6.91983119999999,
+ 5.3634631, NA, NA, NA, 0.0870321999999959, -1.19047620000001,
+ -1.8723404, -0.4244482, 1.18443319999999, 2.19594590000001,
+ 1.57545610000001,
+ 3.080766, 1.8744906, 5.51053480000002, 6.31412790000002, 7.4451411,
+ 8.1226054, 9.52743899999999, 9.4339623, NA)), .Names = c("Place",
+ "year_c", "SR_Total_ctd"), row.names = c(NA, -54L), class = "data.frame")
>
>
> uncmod <- lme(fixed = year_c~1, random = ~1|Place, data = data2,
method="ML")
> tidy(uncmod)
  group         level        term estimate
1 Place Cambridge Bay (Intercept)      6.5
2 Place       Iqaluit (Intercept)      6.5
3 Place  Rankin Inlet (Intercept)      6.5
> summary(uncmod)
Linear mixed-effects model fit by maximum likelihood
 Data: data2
       AIC      BIC    logLik
  337.0536 343.0206 -165.5268

Random effects:
 Formula: ~1 | Place
         (Intercept) Residual
StdDev: 0.0001350644 5.188127

Fixed effects: year_c ~ 1
            Value Std.Error DF  t-value p-value
(Intercept)   6.5 0.7126441 51 9.120962       0

Standardized Within-Group Residuals:
          Min            Q1           Med            Q3           Max
-1.638356e+00 -8.673650e-01 -1.193490e-15  8.673650e-01  1.638356e+00

Number of Observations: 54
Number of Groups: 3
> VarCorr(uncmod)
Place = pdLogChol(1)
            Variance     StdDev
(Intercept) 1.824240e-08 0.0001350644
Residual    2.691667e+01 5.1881274721
>
> sessionInfo()
R version 3.4.0 (2017-04-21)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] broom_0.4.2  nlme_3.1-131

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.10     lattice_0.20-35  tidyr_0.6.1      psych_1.7.3.21
 [5] dplyr_0.5.0      assertthat_0.2.0 grid_3.4.0       R6_2.2.0
 [9] plyr_1.8.4       DBI_0.6-1        magrittr_1.5     stringi_1.1.5
[13] lazyeval_0.2.0   reshape2_1.4.2   tools_3.4.0      stringr_1.2.0
[17] foreign_0.8-67   parallel_3.4.0   compiler_3.4.0   mnormt_1.5-5
[21] tibble_1.3.0


Tom 2


On Wed, May 10, 2017 at 1:05 PM, Jochen Wirsing <jw1085 at wildcats.unh.edu <mailto:jw1085 at wildcats.unh.edu> >
wrote:


> Dear All,
>
>
> thanks again for your nice feedback. The Session Info etc was mentioned
> in the previous email, but one of the folks here on the list asked me to
> use dput() so I could paste my data in textform here.
>
> So here you go:
>
> structure(list(Place = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L), .Label =
> c("Cambridge Bay",
> "Iqaluit", "Rankin Inlet"), class = "factor"), year_c = c(-2,
> -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, -2,
> -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, -2,
> -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15), SR_Total_ctd
> = c(NA,
> NA, 5.48961420000001, 7.24637679999999, 3.76569040000001, 6.9014085,
> 9.3088858, 5.1771117, 7.51366120000002, 7.18157180000001, 3.7275064,
> 5.7397959, 6.87500000000001, 6.25, 5.84577109999999, 6.2421973,
> 4.70446319999999, NA, NA, NA, 11.9192688, 9.6291013, 8.54640980000001,
> 8.7893297, 7.42343539999999, 5, 5.3674121, 6.1322261, 6.4182843,
> 5.75692960000001, 6.3861534, 6.6706021, 7.76642339999999, 6.91983119999999,
> 5.3634631, NA, NA, NA, 0.0870321999999959, -1.19047620000001,
> -1.8723404, -0.4244482, 1.18443319999999, 2.19594590000001,
> 1.57545610000001,
> 3.080766, 1.8744906, 5.51053480000002, 6.31412790000002, 7.4451411,
> 8.1226054, 9.52743899999999, 9.4339623, NA)), .Names = c("Place",
> "year_c", "SR_Total_ctd"), row.names = c(NA, -54L), class = "data.frame")
> >
>
>
> I was also asked, whether using lme4 would be an option, but I don't
> think that this will help fix the issue that I believe occurred through
> updating to R 3.40. Also, nlme provides some information in a nicer way
> (covariances etc, if I remember correctly - all this is still very new
> to me....), so I'd really rather see nlme fixed.
>
>
> Thanks again!
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org>  mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org>  mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models




	[[alternative HTML version deleted]]


From r.vacca at ufl.edu  Thu May 11 11:22:38 2017
From: r.vacca at ufl.edu (Raffaele Vacca)
Date: Thu, 11 May 2017 11:22:38 +0200
Subject: [R-sig-ME] Dealing with very high autocorrelations in logistic
	MCMCglmm
Message-ID: <4199fe7d-7e35-5f20-3e67-ffa4301bcb69@ufl.edu>

Dear List,

I'm using MCMCglmm to estimate logistic mixed models for social network 
data. Estimation works fine until I add a third random effect that 
causes MCMC autocorrelations on all parameters to become extremely high. 
I'm trying to figure out if there is any way to lower autocorrelation 
values while retaining the same specification for the fixed and random 
part of the model.

Here is some information about the model:
* Units of analysis are social ties between individuals, i.e. each row 
in the data frame is one unique social tie.
* Each tie exists between 2 individuals, an Ego and and Alter. Each Ego 
belongs to a Family.
* The binary response is whether the tie is "supportive", i.e. if Alter 
provides support to Ego (1=Yes, 0=No).
* The model includes 3 random effects (aka classifications): Egos, 
Alters, Families. Egos are nested within Families (each Ego belongs to 
one and one only Family). Egos and Alters are cross-classified: the same 
Ego has ties with multiple Alters and the same Alter has ties with 
multiple Egos. Each tie "belongs" to one Ego, one Family (Ego's Family), 
and one Alter, so no multiple membership occurs.
* The data include 1200 ties (1200 dataset rows). There are about 20 
ties for each Ego; 40 ties for each Family; and 2 ties for each Alter.
* This is a fairly simple random-intercept logistic model: The intercept 
has a random component for Egos, Families, and Alters. So I'm interested 
in ego-level, family-level, alter-level variance in the intercept. No 
random slope is involved.
* The model includes covariates at the tie, ego, and alter level (i.e. 
characteristics of ties, egos, and alters).

This is how I'm estimating the model:
```
# Priors
priors.m4b <- list(R= list(V=1,fix=1),
                    G= list(G1=list(V=1, nu=0.002), G2=list(V=1, 
n=0.002), G3=list(V=1, n=0.002)))

# MCMCglmm
MCMCglmm(tie.supportive ~ 1 + tie.family + tie.trust + tie.communication 
+ tie.same.sex + tie.same.age + ego.sex + ego.age + alter.sex + 
alter.age, random= ~ egoID + ego.familyID + alterID, 
family="categorical", data= df, prior= priors.m4b, slice=TRUE, 
nitt=710000, thin=700, burnin= 10000)
```

The estimation results have autocorrelation values of over .50, 
sometimes as high as .90 for the fixed effects; and over .70 for the 
variance components, resulting in uselessly low effective sample sizes.
However, the problem only occurs when adding the Alter random effect 
(alterID). The same model with just the Ego and Family random effects is 
estimated well, with low autocorrelation values. Unfortunately, the main 
aim of the analysis is precisely to examine the model with the Alter 
random effect.
Also, the problem seems to be reduced when keeping the Alter random 
effect while removing some tie-level (i.e. level-1) covariates, in 
particular tie.trust and tie.communication. These are tie-level measures 
of how much trust and communication there is on that tie (i.e. between 
that Ego and that Alter) on a 1-to-5 scale (I'm treating these as 
continuous and centered variables).

The questions on which I wanted to ask your thoughts are the following:
* Am I specifying the model in MCMCglmm in the right way? I have read 
Jarrod Hadfield's Course Notes and a number of other tutorials, but 
obviously I'm using MCMCglmm on a different type of model and data than 
presented in most tutorials, so I'm still not 100% sure.
* What might be the problem with the Alter random effect, that is 
causing autocorrelations to suddenly rocket in this way?
* What might be the problem with tie.trust and tie.communication, that 
causes autocorrelations to be way lower when these two level-1 
covariates are removed?
* Do you have any suggestions on how to deal with such high 
autocorrelations? Is changing the model the only solution? I've tried to 
increase the nitt and thin (up to nitt=1210000, thin=1200, 
burnin=10000), but autocorrelations seem to stay above .50 or .60.

Thank you very much for any thought, comment or suggestion.

Raffaele Vacca
Department of Sociology and Criminology & Law
University of Florida


From nicolas.fanin at hotmail.fr  Thu May 11 17:42:33 2017
From: nicolas.fanin at hotmail.fr (Nicolas Fanin)
Date: Thu, 11 May 2017 15:42:33 +0000
Subject: [R-sig-ME] Split plot repeated measurements + slope comparison
In-Reply-To: <4199fe7d-7e35-5f20-3e67-ffa4301bcb69@ufl.edu>
References: <4199fe7d-7e35-5f20-3e67-ffa4301bcb69@ufl.edu>
Message-ID: <VI1PR0501MB2622944AACA45B1443761B0B8FED0@VI1PR0501MB2622.eurprd05.prod.outlook.com>

Dear List,


I need your advices about data analysis (on which I working on since a long time), thank you for your responses.


I'm working on a split plot design with repeated measurements over time.

It consists of 3 Ecosystem types (large, medium and small), each ecosystem being repeated 10 times (30 ecosystems in total, each having an individual ID = EcosystemCode).

Within each ecosystem, we have 8 Treatments in which we measured plant biomass during 20 years.

I would like to know the effect of Ecosystem type, Treatments (and  eventually Time).


If we consider that we measure the same plots over time (and the data are non-independant) each plot within each island being a distinct treatment (and are equivalent for the model):


modelfinal1 = lme (Biomass ~ EcosystemType*Tr, random = ~1|EcosystemCode/Plot, data = XXX)


And if I want to know the effect of Year:


modelfinal2 = lme (Biomass ~ EcosystemType*Year*Tr, random = ~1|EcosystemCode/Plot, data = XXX)

In the first model, I get a denDF of 27 for EcosystemType (that is ok given the 30 ecosystems) and denDF of 149 for Tr or the interaction between Tr x Ecosystem type
In the second model I get the same denDF for Ecosystem type and Tr, but I get a huge denDF of about 2992 for Time and the different interactions involving time.

What do you think about the degree of freedom? Do we overstate the degrees of freedom associated with the effect of Time? Do you know any  multivariate approaches with fewer assumptions about variance/covariance structure that would be a better approach than the linear models? (the model are linear but sometimes vary towards log10-relationships)



Then, I tried to assess the differences between slopes representing the evolution of biomass over time in each of the 3 ecosystem types using mixed models (and contrast.matrix ):


modelfinal4 = lme (Biomass  ~  EcosystemType*Year , random=~1|EcosystemCode, data = XXX)

contrast.matrix <- rbind(`Year:EcosystemTypelarge vs. Year:EcosystemTypemedium` = c(0, 0, 0, 0, 1, 0),
                         `Year:EcosystemTypelarge vs. Year:EcosystemTypesmall` = c(0, 0, 0, 0, 0, 1),
                         `Year:EcosystemTypemedium vs. Year:EcosystemTypesmall` = c(0, 0, 0, 0, -1, 1))

slopecomps <- glht(modelfinal4, contrast.matrix)
summary(slopecomps)

What do you think about this approach? Do you know any other (and may be more common) to compare slopes using mixed models?


Finally, I tried to get the R2mar and R2cond of the different using the paper of Nakagawa and Schielzeth 2013, for example:


mF= lmer (Totalbiomass ~ RealizedSR + (1|EcosystemCode), data = XXX)

anova(mF)
mFX <- model.matrix(mF)
Fixed <- fixef(mF)[2] * mFX[, 2]
VarF <- var(Fixed)
VarF <- var(as.vector(fixef(mF) %*% t(mFX)))
VarF/(VarF +  VarCorr(mF)$Island[1] + attr(VarCorr(mF), "sc")^2)
(VarF + VarCorr(mF)$EcosystemCode[1])/(VarF + VarCorr(mF)$EcosystemCode[1] + (attr(VarCorr(mF), "sc")^2))


Do you know any package that can do te calculation directly for many variables at the same time?

Thank you for you responses once again, and I wish you a good week-end,


Best Regards,


Nicolas


	[[alternative HTML version deleted]]


From sbigelow at jonesctr.org  Fri May 12 03:54:01 2017
From: sbigelow at jonesctr.org (Seth Bigelow)
Date: Thu, 11 May 2017 21:54:01 -0400
Subject: [R-sig-ME] A question on using LME model in species nested
 within a random block design
In-Reply-To: <CAHtaSOUfi6Z-YFgckY+H7S-Udwi=f4KKT2d7ksdw=Hroo-Dumw@mail.gmail.com>
References: <CAHtaSOVu2W0mjsnFR5PS+SesjALg-sRf1WzsQdjZF8zypOrQRg@mail.gmail.com>
 <CAHtaSOUfi6Z-YFgckY+H7S-Udwi=f4KKT2d7ksdw=Hroo-Dumw@mail.gmail.com>
Message-ID: <CAEryiFs2JeWeT7v5S7HVEC+NiOhCv9dvstQVKJRtAnJ-KBKBoA@mail.gmail.com>

Dear Faming Wang:

I took a look at your model and data. I believe that you have done the
analysis correctly. First you specified a model that had the three way
interaction Nadd*Padd*Spname, using Block as a random effect. Then you
tested to see whether there was a random plot effect
(random~1|Block/plots), since each fertilized plot should be a somewhat
uniform area containing individuals of several or all five species. But the
random effect of 'plot' was tiny and negligible, and the likelihood ratio
test did not indicate that the model with the 'plot' random effect was any
better than the model that only had 'block' as a random effect. So, to
paraphrase Pinheiro & Bates (2000), you have used multiple nested levels of
random effects to analyze a split plot experiment. I think the challenge
lies in explaining to the reviewer that you *have* done a split plot
experiment, rather than taking some different approach.

On Tue, May 9, 2017 at 2:11 PM, Faming Wang <famingw at gmail.com> wrote:

> Dear all,
>
>
>  I have conducted an N and P field addition experiment in a tropical
> forest, and we used a random block design in this experiment, briefly, we
> had four randomly distributed plots in each block (Control, +N? +P,
> and +NP), and five blocks located in the forest. Totally we have 20 plots,
> with two N treatments and two P treatment and five replicated blocks. In
> each plot, we selected five  species  plants (some plots only contains 3 or
> 4 species) to measure their leave variables, like N concentration, P
> concentration, and photosynthesis rate et al.  We want to know the effect
> of N and P addition as well as the species level changes (inter-species )
>  on leaf variables. Since some plots some specific species are missing in
> some plots some specific species, it was unbalanced at the species level.
> We used linear mixed effect models to conduct our statistical analysis:
>
>   We firstly tested the random effect with blocks, and species within plots
> within blocks, and found that nesting plots and species within block did
> not improve the model fitness, so we choose only block as random effect.
> For fixed effects, N-addition, P-addition, species and their interaction
> were considered fixed effects in models. The significance of each term was
> determined by comparing nested models using likelihood ratio tests and AICs
> to check for model improvement. Since there was better model fit (lower AIC
> values) with interaction terms, we selected the full factor model. However,
> as there was a highly significant effect of tree species identity and
> species related interactions, species-specific responses to N- and
> P-addition were also investigated with separate models with N, P and their
> interaction as fixed effects and block as a random effect.
>  however, our reviewers were not happy with this statistical methods and
> pointed out that "Species is treated as a fixed factor, generating a
> three-way factorial ANOVA. Species cannot be treated in this way because
> all five species were present in each 10-by-10-m plot. To implement a
> three-way ANOVA design, the entire experiment (five blocks of the four
> factorial N and P treatments) would have to be repeated once for each
> species. Species cannot be treated as a fixed factor because all five
> species were measured in the same experimental plots. This is a split-plot
> design. Alternatively, MANOVA might be performed treating the five species
> as five response variables. A split-plot design or a MANOVA approach would
> allow the authors to investigate interspecific variation in responses."
>
>   I am very confused on the reviewer's comments,  it seems to me that the
> reviewer compared our LME model with 3-way ANOVA. If we used 3-way ANOVA, I
> know that my experiment is species nested in a random block design, and we
> could not directly use 3-Way ANOVA, which the error df would be
> overestimated.
>
>    Below I attached my sample data and my current R script for LME model in
> dropbox. See below links:
> https://www.dropbox.com/s/6kd3kq5mlyuyqz6/NPrawdata.csv?dl=0
>
> https://www.dropbox.com/s/fpqdbm6go0g8ak0/Faming%20NP%20model.R?dl=0
>
>
> --
>
> Sincerely
>
> Faming Wang
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Seth W. Bigelow, Ph.D.
Assistant Scientist of Forest Ecology
Joseph W. Jones Ecological Research Center
Newton, GA

	[[alternative HTML version deleted]]


From famingw at gmail.com  Fri May 12 04:13:33 2017
From: famingw at gmail.com (Faming Wang)
Date: Fri, 12 May 2017 02:13:33 +0000
Subject: [R-sig-ME] A question on using LME model in species nested
 within a random block design
In-Reply-To: <CAEryiFs2JeWeT7v5S7HVEC+NiOhCv9dvstQVKJRtAnJ-KBKBoA@mail.gmail.com>
References: <CAHtaSOVu2W0mjsnFR5PS+SesjALg-sRf1WzsQdjZF8zypOrQRg@mail.gmail.com>
 <CAHtaSOUfi6Z-YFgckY+H7S-Udwi=f4KKT2d7ksdw=Hroo-Dumw@mail.gmail.com>
 <CAEryiFs2JeWeT7v5S7HVEC+NiOhCv9dvstQVKJRtAnJ-KBKBoA@mail.gmail.com>
Message-ID: <CAHtaSOV4+5m6vwVTV-hXHz+e3MTdjyv2T8ZaNOUDC5c6LVWV7w@mail.gmail.com>

Dear Seth,

  Thanks for your help. I was perplexed by this problem for several weeks.

-- 

Sincerely

Faming Wang
MBL, Woods Hole, MA




On Thu, May 11, 2017 at 9:54 PM Seth Bigelow <sbigelow at jonesctr.org> wrote:

> Dear Faming Wang:
>
> I took a look at your model and data. I believe that you have done the
> analysis correctly. First you specified a model that had the three way
> interaction Nadd*Padd*Spname, using Block as a random effect. Then you
> tested to see whether there was a random plot effect
> (random~1|Block/plots), since each fertilized plot should be a somewhat
> uniform area containing individuals of several or all five species. But the
> random effect of 'plot' was tiny and negligible, and the likelihood ratio
> test did not indicate that the model with the 'plot' random effect was any
> better than the model that only had 'block' as a random effect. So, to
> paraphrase Pinheiro & Bates (2000), you have used multiple nested levels of
> random effects to analyze a split plot experiment. I think the challenge
> lies in explaining to the reviewer that you *have* done a split plot
> experiment, rather than taking some different approach.
>
> On Tue, May 9, 2017 at 2:11 PM, Faming Wang <famingw at gmail.com> wrote:
>
>> Dear all,
>>
>>
>>  I have conducted an N and P field addition experiment in a tropical
>> forest, and we used a random block design in this experiment, briefly, we
>> had four randomly distributed plots in each block (Control, +N? +P,
>> and +NP), and five blocks located in the forest. Totally we have 20 plots,
>> with two N treatments and two P treatment and five replicated blocks. In
>> each plot, we selected five  species  plants (some plots only contains 3
>> or
>> 4 species) to measure their leave variables, like N concentration, P
>> concentration, and photosynthesis rate et al.  We want to know the effect
>> of N and P addition as well as the species level changes (inter-species )
>>  on leaf variables. Since some plots some specific species are missing in
>> some plots some specific species, it was unbalanced at the species level.
>> We used linear mixed effect models to conduct our statistical analysis:
>>
>>   We firstly tested the random effect with blocks, and species within
>> plots
>> within blocks, and found that nesting plots and species within block did
>> not improve the model fitness, so we choose only block as random effect.
>> For fixed effects, N-addition, P-addition, species and their interaction
>> were considered fixed effects in models. The significance of each term was
>> determined by comparing nested models using likelihood ratio tests and
>> AICs
>> to check for model improvement. Since there was better model fit (lower
>> AIC
>> values) with interaction terms, we selected the full factor model.
>> However,
>> as there was a highly significant effect of tree species identity and
>> species related interactions, species-specific responses to N- and
>> P-addition were also investigated with separate models with N, P and their
>> interaction as fixed effects and block as a random effect.
>>  however, our reviewers were not happy with this statistical methods and
>> pointed out that "Species is treated as a fixed factor, generating a
>> three-way factorial ANOVA. Species cannot be treated in this way because
>> all five species were present in each 10-by-10-m plot. To implement a
>> three-way ANOVA design, the entire experiment (five blocks of the four
>> factorial N and P treatments) would have to be repeated once for each
>> species. Species cannot be treated as a fixed factor because all five
>> species were measured in the same experimental plots. This is a split-plot
>> design. Alternatively, MANOVA might be performed treating the five species
>> as five response variables. A split-plot design or a MANOVA approach would
>> allow the authors to investigate interspecific variation in responses."
>>
>>   I am very confused on the reviewer's comments,  it seems to me that the
>> reviewer compared our LME model with 3-way ANOVA. If we used 3-way ANOVA,
>> I
>> know that my experiment is species nested in a random block design, and we
>> could not directly use 3-Way ANOVA, which the error df would be
>> overestimated.
>>
>>    Below I attached my sample data and my current R script for LME model
>> in
>> dropbox. See below links:
>> https://www.dropbox.com/s/6kd3kq5mlyuyqz6/NPrawdata.csv?dl=0
>>
>> https://www.dropbox.com/s/fpqdbm6go0g8ak0/Faming%20NP%20model.R?dl=0
>>
>
>>
>> --
>>
>> Sincerely
>>
>> Faming Wang
>>
>>         [[alternative HTML version deleted]]
>>
>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
> Seth W. Bigelow, Ph.D.
> Assistant Scientist of Forest Ecology
> Joseph W. Jones Ecological Research Center
> Newton, GA
>

	[[alternative HTML version deleted]]


From Phillip.Alday at unisa.edu.au  Fri May 12 04:16:48 2017
From: Phillip.Alday at unisa.edu.au (Phillip Alday)
Date: Fri, 12 May 2017 02:16:48 +0000
Subject: [R-sig-ME] Multilevel logistic regression guessing parameter
In-Reply-To: <CAGbn3HZ68nUySiJCc+G8EPCy72sw1rdHo2tp7sCPGxa0JZjMrg@mail.gmail.com>
References: <CAGbn3HZ68nUySiJCc+G8EPCy72sw1rdHo2tp7sCPGxa0JZjMrg@mail.gmail.com>
Message-ID: <525470B1-C43A-48DF-90B5-B33D11CB959A@unisa.edu.au>

Dominik,

You're assuming that test subjects are guessing at random -- it's quite possible that they believe that they incorrect answer is the correct one, which would make them less likely than "chance" to select the correct answer. 

"Chance" performance may also not fall at 50% if there are multiple possible incorrect responses but only one possible correct response.

You could also simply have more incorrect than correct responses for certain values of your predictor for various reasons related to your preprocessing steps -- maybe data with a correct response is more likely to be excluded for various reasons (blinks, timeouts, whatever exclusion criteria you have for your given methods).

Finally, is B really coded as correct/incorrect? Or is B coded as response-1/response-2, i.e. without mapping a binary response to correct-vs-incorrect?

Best,
Phillip



> On 11 May 2017, at 20:30, Dominik ?epuli? <dcepulic at gmail.com> wrote:
> 
> I  have a following situation:
> 
> I want to predict variable B (which is dichotomous) from variable A
> (continous) controlling for random effects on the level of a) Subjects; b)
> Tasks.
> 
> A -> B (1)
> 
> The problem is that when I use model to predict the values of B from A,
> values below probability of 0.5 get predicted, and in my case that doesn?t
> make sense, because, if you guess at random, the probability of correct
> answer on B would be 0.5.
> 
> I want to know how I can constrain the model (1) in lme4 so that it doesn?t
> predict values lower than 0.5 in variable B.
> 
> Thank you,
> 
> Dominik!
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From jake.a.westfall at gmail.com  Fri May 12 05:46:18 2017
From: jake.a.westfall at gmail.com (Jake Westfall)
Date: Thu, 11 May 2017 22:46:18 -0500
Subject: [R-sig-ME] Multilevel logistic regression guessing parameter
In-Reply-To: <525470B1-C43A-48DF-90B5-B33D11CB959A@unisa.edu.au>
References: <CAGbn3HZ68nUySiJCc+G8EPCy72sw1rdHo2tp7sCPGxa0JZjMrg@mail.gmail.com>
 <525470B1-C43A-48DF-90B5-B33D11CB959A@unisa.edu.au>
Message-ID: <CAE9_Wg7C--12FcdeCE=RrdweT_V0PUsdLx3zOzpS2w9RvZ3sKw@mail.gmail.com>

Hi Dominik,

In addition to the issues Phillip raised, note that adding a guessing
parameter to the model (so that it resembled what is called the 3PL model
in item response theory;
https://en.wikipedia.org/wiki/Item_response_theory#Three_parameter_logistic_model)
would make the model inherently nonlinear in the parameters. So the model
could not be fit in glmer(). And since I don't think nlmer() supports
non-Normal response families, this would mean you can't use lme4 at all. I
would recommend fitting such a model in a fully Bayesian setting using e.g.
Stan.

Jake

On Thu, May 11, 2017 at 9:16 PM, Phillip Alday <Phillip.Alday at unisa.edu.au>
wrote:

> Dominik,
>
> You're assuming that test subjects are guessing at random -- it's quite
> possible that they believe that they incorrect answer is the correct one,
> which would make them less likely than "chance" to select the correct
> answer.
>
> "Chance" performance may also not fall at 50% if there are multiple
> possible incorrect responses but only one possible correct response.
>
> You could also simply have more incorrect than correct responses for
> certain values of your predictor for various reasons related to your
> preprocessing steps -- maybe data with a correct response is more likely to
> be excluded for various reasons (blinks, timeouts, whatever exclusion
> criteria you have for your given methods).
>
> Finally, is B really coded as correct/incorrect? Or is B coded as
> response-1/response-2, i.e. without mapping a binary response to
> correct-vs-incorrect?
>
> Best,
> Phillip
>
>
>
> > On 11 May 2017, at 20:30, Dominik ?epuli? <dcepulic at gmail.com> wrote:
> >
> > I  have a following situation:
> >
> > I want to predict variable B (which is dichotomous) from variable A
> > (continous) controlling for random effects on the level of a) Subjects;
> b)
> > Tasks.
> >
> > A -> B (1)
> >
> > The problem is that when I use model to predict the values of B from A,
> > values below probability of 0.5 get predicted, and in my case that
> doesn?t
> > make sense, because, if you guess at random, the probability of correct
> > answer on B would be 0.5.
> >
> > I want to know how I can constrain the model (1) in lme4 so that it
> doesn?t
> > predict values lower than 0.5 in variable B.
> >
> > Thank you,
> >
> > Dominik!
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From paul.buerkner at gmail.com  Fri May 12 09:36:41 2017
From: paul.buerkner at gmail.com (Paul Buerkner)
Date: Fri, 12 May 2017 09:36:41 +0200
Subject: [R-sig-ME] Multilevel logistic regression guessing parameter
In-Reply-To: <CAGbn3HZ68nUySiJCc+G8EPCy72sw1rdHo2tp7sCPGxa0JZjMrg@mail.gmail.com>
References: <CAGbn3HZ68nUySiJCc+G8EPCy72sw1rdHo2tp7sCPGxa0JZjMrg@mail.gmail.com>
Message-ID: <CAGoSky889aPr6kGMCMZcr-+GzuHt0z3KiG3VW72Xb_n1OW_gKw@mail.gmail.com>

Hi Dominik,

in addition to what Jake said, you can do this with the brms package (using
Stan under the hood). After installing brms, you can learn how to fit such
models in the "brms_nonlinear" vignette: Type vignette("brms_nonlinear") in
R.

Best,
Paul

2017-05-11 13:00 GMT+02:00 Dominik ?epuli? <dcepulic at gmail.com>:

> I  have a following situation:
>
> I want to predict variable B (which is dichotomous) from variable A
> (continous) controlling for random effects on the level of a) Subjects; b)
> Tasks.
>
> A -> B (1)
>
> The problem is that when I use model to predict the values of B from A,
> values below probability of 0.5 get predicted, and in my case that doesn?t
> make sense, because, if you guess at random, the probability of correct
> answer on B would be 0.5.
>
> I want to know how I can constrain the model (1) in lme4 so that it doesn?t
> predict values lower than 0.5 in variable B.
>
> Thank you,
>
> Dominik!
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From paul.buerkner at gmail.com  Fri May 12 11:04:03 2017
From: paul.buerkner at gmail.com (Paul Buerkner)
Date: Fri, 12 May 2017 11:04:03 +0200
Subject: [R-sig-ME] Multilevel logistic regression guessing parameter
In-Reply-To: <CAGbn3HbhWDhjBrdXWQhkCZuEJaBf-F9D7kNdTKRvfDab4qfz+A@mail.gmail.com>
References: <CAGbn3HZ68nUySiJCc+G8EPCy72sw1rdHo2tp7sCPGxa0JZjMrg@mail.gmail.com>
 <CAGoSky889aPr6kGMCMZcr-+GzuHt0z3KiG3VW72Xb_n1OW_gKw@mail.gmail.com>
 <CAGbn3HbhWDhjBrdXWQhkCZuEJaBf-F9D7kNdTKRvfDab4qfz+A@mail.gmail.com>
Message-ID: <CAGoSky8Muc_nM2+GcosrvZMN4je3MDo_wvAA8inOxrXhZk93Rg@mail.gmail.com>

Hi Dominik,

I mean that brms uses Stan (http://mc-stan.org/) for the model fitting, but
you don't need to worry about that. I am confident that brms will allow you
to fit the model you have in mind.

Best,
Paul

2017-05-12 10:55 GMT+02:00 Dominik ?epuli? <dcepulic at gmail.com>:

> Dear everybody, thank you for your ideas and messages!
>
> First, Philipp, yes, you are right. We have a simple two-choice
> recognition task. Participants were learning some stimuli,  and after some
> the recognition phase started. Always one stimuli per screen, and they have
> to say whether it is one of the learnt ones or not. B is therefore coded as
> response1 and response2 and afterwards coded in correct/incorrect.
> The problem that might have appeared is that some distractors may have
> been very similar to some well learnt items, and were simultaneously paired
> with a poorly learnt target. That might produce the effect of correctness
> below 0.5 We searched for such tasks and deleted them from further analysis.
>
> My problem is that when I try to plot probability functions (x - predictor
> variable, y - Accuracy from 0 to 1) for domains, they go below 0.5 which
> doesn?t make sense, as this was a two-choice task. Their lower asymptote
> should be on 0.5 not on 0. That?s why I am asking.
>
> @Paul: Thanks for recommendation, but what do you mean by "Stan under the
> hood"? I basically need a typical multilevel logistic regression (with
> random effects for 2 crossed levels) but with lower asymptote being 0.5 and
> not 0.
>
> I will take a look at the functions!
>
> Best,
> Dominik
>
> On Fri, May 12, 2017 at 9:36 AM, Paul Buerkner <paul.buerkner at gmail.com>
> wrote:
>
>> Hi Dominik,
>>
>> in addition to what Jake said, you can do this with the brms package
>> (using Stan under the hood). After installing brms, you can learn how to
>> fit such models in the "brms_nonlinear" vignette: Type
>> vignette("brms_nonlinear") in R.
>>
>> Best,
>> Paul
>>
>> 2017-05-11 13:00 GMT+02:00 Dominik ?epuli? <dcepulic at gmail.com>:
>>
>>> I  have a following situation:
>>>
>>> I want to predict variable B (which is dichotomous) from variable A
>>> (continous) controlling for random effects on the level of a) Subjects;
>>> b)
>>> Tasks.
>>>
>>> A -> B (1)
>>>
>>> The problem is that when I use model to predict the values of B from A,
>>> values below probability of 0.5 get predicted, and in my case that
>>> doesn?t
>>> make sense, because, if you guess at random, the probability of correct
>>> answer on B would be 0.5.
>>>
>>> I want to know how I can constrain the model (1) in lme4 so that it
>>> doesn?t
>>> predict values lower than 0.5 in variable B.
>>>
>>> Thank you,
>>>
>>> Dominik!
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>

	[[alternative HTML version deleted]]


From conor.goold at nmbu.no  Fri May 12 11:32:49 2017
From: conor.goold at nmbu.no (Conor Michael Goold)
Date: Fri, 12 May 2017 09:32:49 +0000
Subject: [R-sig-ME] Multilevel logistic regression guessing parameter
In-Reply-To: <CAGoSky8Muc_nM2+GcosrvZMN4je3MDo_wvAA8inOxrXhZk93Rg@mail.gmail.com>
References: <CAGbn3HZ68nUySiJCc+G8EPCy72sw1rdHo2tp7sCPGxa0JZjMrg@mail.gmail.com>
 <CAGoSky889aPr6kGMCMZcr-+GzuHt0z3KiG3VW72Xb_n1OW_gKw@mail.gmail.com>
 <CAGbn3HbhWDhjBrdXWQhkCZuEJaBf-F9D7kNdTKRvfDab4qfz+A@mail.gmail.com>,
 <CAGoSky8Muc_nM2+GcosrvZMN4je3MDo_wvAA8inOxrXhZk93Rg@mail.gmail.com>
Message-ID: <1494581570222.75256@nmbu.no>

Hi Dominik, 

I may have misunderstood your problem, but I don't understand why you want to constrain the probability of success to be 0.5 at the lowest. If participants are choosing their answers completely randomly, their average probability of choosing the correct response (i.e. a 1 if the responses are coded 0 = incorrect and 1 = correct) across tasks may be around 0.5, but it seems completely plausible that the average probability of choosing the correct response could be between 0 and 1, and this propensity for a correct answer could vary between participants. This seems like a normal application of logistic regression. Sorry if I am missing something!

If you have reason to believe that participants do just guess sometimes, which may result in some 'outlying' data points (i.e. correct or incorrect responses where we may not expect them), as others have said, this can be included in a Bayesian model. John Kruschke has an example in his book Doing Bayesian Data Analysis (using JAGS) and also in this paper (see equation 3 in appendix 4): http://journal.sjdm.org/14/14721a/jdm14721a.html 

Best regards
Conor
________________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Paul Buerkner <paul.buerkner at gmail.com>
Sent: Friday, May 12, 2017 11:04 AM
To: Dominik ?epuli?
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Multilevel logistic regression guessing parameter

Hi Dominik,

I mean that brms uses Stan (http://mc-stan.org/) for the model fitting, but
you don't need to worry about that. I am confident that brms will allow you
to fit the model you have in mind.

Best,
Paul

2017-05-12 10:55 GMT+02:00 Dominik ?epuli? <dcepulic at gmail.com>:

> Dear everybody, thank you for your ideas and messages!
>
> First, Philipp, yes, you are right. We have a simple two-choice
> recognition task. Participants were learning some stimuli,  and after some
> the recognition phase started. Always one stimuli per screen, and they have
> to say whether it is one of the learnt ones or not. B is therefore coded as
> response1 and response2 and afterwards coded in correct/incorrect.
> The problem that might have appeared is that some distractors may have
> been very similar to some well learnt items, and were simultaneously paired
> with a poorly learnt target. That might produce the effect of correctness
> below 0.5 We searched for such tasks and deleted them from further analysis.
>
> My problem is that when I try to plot probability functions (x - predictor
> variable, y - Accuracy from 0 to 1) for domains, they go below 0.5 which
> doesn?t make sense, as this was a two-choice task. Their lower asymptote
> should be on 0.5 not on 0. That?s why I am asking.
>
> @Paul: Thanks for recommendation, but what do you mean by "Stan under the
> hood"? I basically need a typical multilevel logistic regression (with
> random effects for 2 crossed levels) but with lower asymptote being 0.5 and
> not 0.
>
> I will take a look at the functions!
>
> Best,
> Dominik
>
> On Fri, May 12, 2017 at 9:36 AM, Paul Buerkner <paul.buerkner at gmail.com>
> wrote:
>
>> Hi Dominik,
>>
>> in addition to what Jake said, you can do this with the brms package
>> (using Stan under the hood). After installing brms, you can learn how to
>> fit such models in the "brms_nonlinear" vignette: Type
>> vignette("brms_nonlinear") in R.
>>
>> Best,
>> Paul
>>
>> 2017-05-11 13:00 GMT+02:00 Dominik ?epuli? <dcepulic at gmail.com>:
>>
>>> I  have a following situation:
>>>
>>> I want to predict variable B (which is dichotomous) from variable A
>>> (continous) controlling for random effects on the level of a) Subjects;
>>> b)
>>> Tasks.
>>>
>>> A -> B (1)
>>>
>>> The problem is that when I use model to predict the values of B from A,
>>> values below probability of 0.5 get predicted, and in my case that
>>> doesn?t
>>> make sense, because, if you guess at random, the probability of correct
>>> answer on B would be 0.5.
>>>
>>> I want to know how I can constrain the model (1) in lme4 so that it
>>> doesn?t
>>> predict values lower than 0.5 in variable B.
>>>
>>> Thank you,
>>>
>>> Dominik!
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From conor.goold at nmbu.no  Fri May 12 13:12:45 2017
From: conor.goold at nmbu.no (Conor Michael Goold)
Date: Fri, 12 May 2017 11:12:45 +0000
Subject: [R-sig-ME] Multilevel logistic regression guessing parameter
In-Reply-To: <1494581570222.75256@nmbu.no>
References: <CAGbn3HZ68nUySiJCc+G8EPCy72sw1rdHo2tp7sCPGxa0JZjMrg@mail.gmail.com>
 <CAGoSky889aPr6kGMCMZcr-+GzuHt0z3KiG3VW72Xb_n1OW_gKw@mail.gmail.com>
 <CAGbn3HbhWDhjBrdXWQhkCZuEJaBf-F9D7kNdTKRvfDab4qfz+A@mail.gmail.com>,
 <CAGoSky8Muc_nM2+GcosrvZMN4je3MDo_wvAA8inOxrXhZk93Rg@mail.gmail.com>,
 <1494581570222.75256@nmbu.no>
Message-ID: <1494587565043.4578@nmbu.no>

Hi Dominik, 

I meant to write equation 4 in appendix 1 of the hyperlinked paper. 

Conor


________________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Conor Michael Goold <conor.goold at nmbu.no>
Sent: Friday, May 12, 2017 11:32 AM
To: Paul Buerkner; Dominik ?epuli?
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Multilevel logistic regression guessing parameter

Hi Dominik,

I may have misunderstood your problem, but I don't understand why you want to constrain the probability of success to be 0.5 at the lowest. If participants are choosing their answers completely randomly, their average probability of choosing the correct response (i.e. a 1 if the responses are coded 0 = incorrect and 1 = correct) across tasks may be around 0.5, but it seems completely plausible that the average probability of choosing the correct response could be between 0 and 1, and this propensity for a correct answer could vary between participants. This seems like a normal application of logistic regression. Sorry if I am missing something!

If you have reason to believe that participants do just guess sometimes, which may result in some 'outlying' data points (i.e. correct or incorrect responses where we may not expect them), as others have said, this can be included in a Bayesian model. John Kruschke has an example in his book Doing Bayesian Data Analysis (using JAGS) and also in this paper (see equation 3 in appendix 4): http://journal.sjdm.org/14/14721a/jdm14721a.html

Best regards
Conor
________________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Paul Buerkner <paul.buerkner at gmail.com>
Sent: Friday, May 12, 2017 11:04 AM
To: Dominik ?epuli?
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Multilevel logistic regression guessing parameter

Hi Dominik,

I mean that brms uses Stan (http://mc-stan.org/) for the model fitting, but
you don't need to worry about that. I am confident that brms will allow you
to fit the model you have in mind.

Best,
Paul

2017-05-12 10:55 GMT+02:00 Dominik ?epuli? <dcepulic at gmail.com>:

> Dear everybody, thank you for your ideas and messages!
>
> First, Philipp, yes, you are right. We have a simple two-choice
> recognition task. Participants were learning some stimuli,  and after some
> the recognition phase started. Always one stimuli per screen, and they have
> to say whether it is one of the learnt ones or not. B is therefore coded as
> response1 and response2 and afterwards coded in correct/incorrect.
> The problem that might have appeared is that some distractors may have
> been very similar to some well learnt items, and were simultaneously paired
> with a poorly learnt target. That might produce the effect of correctness
> below 0.5 We searched for such tasks and deleted them from further analysis.
>
> My problem is that when I try to plot probability functions (x - predictor
> variable, y - Accuracy from 0 to 1) for domains, they go below 0.5 which
> doesn?t make sense, as this was a two-choice task. Their lower asymptote
> should be on 0.5 not on 0. That?s why I am asking.
>
> @Paul: Thanks for recommendation, but what do you mean by "Stan under the
> hood"? I basically need a typical multilevel logistic regression (with
> random effects for 2 crossed levels) but with lower asymptote being 0.5 and
> not 0.
>
> I will take a look at the functions!
>
> Best,
> Dominik
>
> On Fri, May 12, 2017 at 9:36 AM, Paul Buerkner <paul.buerkner at gmail.com>
> wrote:
>
>> Hi Dominik,
>>
>> in addition to what Jake said, you can do this with the brms package
>> (using Stan under the hood). After installing brms, you can learn how to
>> fit such models in the "brms_nonlinear" vignette: Type
>> vignette("brms_nonlinear") in R.
>>
>> Best,
>> Paul
>>
>> 2017-05-11 13:00 GMT+02:00 Dominik ?epuli? <dcepulic at gmail.com>:
>>
>>> I  have a following situation:
>>>
>>> I want to predict variable B (which is dichotomous) from variable A
>>> (continous) controlling for random effects on the level of a) Subjects;
>>> b)
>>> Tasks.
>>>
>>> A -> B (1)
>>>
>>> The problem is that when I use model to predict the values of B from A,
>>> values below probability of 0.5 get predicted, and in my case that
>>> doesn?t
>>> make sense, because, if you guess at random, the probability of correct
>>> answer on B would be 0.5.
>>>
>>> I want to know how I can constrain the model (1) in lme4 so that it
>>> doesn?t
>>> predict values lower than 0.5 in variable B.
>>>
>>> Thank you,
>>>
>>> Dominik!
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From baron at upenn.edu  Fri May 12 13:33:00 2017
From: baron at upenn.edu (Jonathan Baron)
Date: Fri, 12 May 2017 07:33:00 -0400
Subject: [R-sig-ME] Multilevel logistic regression guessing parameter
In-Reply-To: <1494587565043.4578@nmbu.no>
References: <CAGbn3HZ68nUySiJCc+G8EPCy72sw1rdHo2tp7sCPGxa0JZjMrg@mail.gmail.com>
 <CAGoSky889aPr6kGMCMZcr-+GzuHt0z3KiG3VW72Xb_n1OW_gKw@mail.gmail.com>
 <1494581570222.75256@nmbu.no> <1494587565043.4578@nmbu.no>
Message-ID: <20170512113300.GA18165@upenn.edu>

On 05/12/17 11:12, Conor Michael Goold wrote:
>Hi Dominik, 
>
>I meant to write equation 4 in appendix 1 of the hyperlinked paper. 
>
>Conor

And it should be

http://journal.sjdm.org/14/14721a/jdm14721a.pdf

not

http://journal.sjdm.org/14/14721a/jdm14721a.html

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron
Editor: Judgment and Decision Making (http://journal.sjdm.org)


From conor.goold at nmbu.no  Fri May 12 15:51:58 2017
From: conor.goold at nmbu.no (Conor Michael Goold)
Date: Fri, 12 May 2017 13:51:58 +0000
Subject: [R-sig-ME] Multilevel logistic regression guessing parameter
In-Reply-To: <CAGbn3HaG6AE7UbyWp4Mf61NaK4AF1A5CToSFd9O82=PfJc0VcQ@mail.gmail.com>
References: <CAGbn3HZ68nUySiJCc+G8EPCy72sw1rdHo2tp7sCPGxa0JZjMrg@mail.gmail.com>
 <CAGoSky889aPr6kGMCMZcr-+GzuHt0z3KiG3VW72Xb_n1OW_gKw@mail.gmail.com>
 <CAGbn3HbhWDhjBrdXWQhkCZuEJaBf-F9D7kNdTKRvfDab4qfz+A@mail.gmail.com>
 <CAGoSky8Muc_nM2+GcosrvZMN4je3MDo_wvAA8inOxrXhZk93Rg@mail.gmail.com>
 <1494581570222.75256@nmbu.no> <1494587565043.4578@nmbu.no>,
 <CAGbn3HaG6AE7UbyWp4Mf61NaK4AF1A5CToSFd9O82=PfJc0VcQ@mail.gmail.com>
Message-ID: <1494597118579.50925@nmbu.no>

?Hi Dominik,

I guess it depends on what you theoretically expect participants to do. From what you wrote earlier, it seemed that it was possible that participants could have a less than 50% chance of getting the question correct, despite you trying to guard against that by deleting certain stimuli, so I wondered whether the predictions from your model were actually reflective of how participants were answering. It seems potentially dangerous to delete the conditions you would expect some wrong applications of the learnt rule, rather than include those and model them explicitly.

Best
Conor

________________________________
From: Dominik ?epuli? <dcepulic at gmail.com>
Sent: Friday, May 12, 2017 1:19 PM
To: Conor Michael Goold
Cc: Paul Buerkner; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Multilevel logistic regression guessing parameter

Dear Conor and Jonathan, thanks for your replies!


Maybe I am wrong but I believe that there is a difference when applying logistic regression  when you ask an open question, without any answers given, and the answer may be right or wrong (so dependent variable is dichotomous) and
when you ask a question but offer two answers among which one of them is correct. That has to be taken into account somehow when doing logistic regression, according to my viewpoint.

Am I missing something?

On Fri, May 12, 2017 at 1:12 PM, Conor Michael Goold <conor.goold at nmbu.no<mailto:conor.goold at nmbu.no>> wrote:
Hi Dominik,

I meant to write equation 4 in appendix 1 of the hyperlinked paper.

Conor


________________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org>> on behalf of Conor Michael Goold <conor.goold at nmbu.no<mailto:conor.goold at nmbu.no>>
Sent: Friday, May 12, 2017 11:32 AM
To: Paul Buerkner; Dominik ?epuli?
Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Multilevel logistic regression guessing parameter

Hi Dominik,

I may have misunderstood your problem, but I don't understand why you want to constrain the probability of success to be 0.5 at the lowest. If participants are choosing their answers completely randomly, their average probability of choosing the correct response (i.e. a 1 if the responses are coded 0 = incorrect and 1 = correct) across tasks may be around 0.5, but it seems completely plausible that the average probability of choosing the correct response could be between 0 and 1, and this propensity for a correct answer could vary between participants. This seems like a normal application of logistic regression. Sorry if I am missing something!

If you have reason to believe that participants do just guess sometimes, which may result in some 'outlying' data points (i.e. correct or incorrect responses where we may not expect them), as others have said, this can be included in a Bayesian model. John Kruschke has an example in his book Doing Bayesian Data Analysis (using JAGS) and also in this paper (see equation 3 in appendix 4): http://journal.sjdm.org/14/14721a/jdm14721a.html

Best regards
Conor
________________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org>> on behalf of Paul Buerkner <paul.buerkner at gmail.com<mailto:paul.buerkner at gmail.com>>
Sent: Friday, May 12, 2017 11:04 AM
To: Dominik ?epuli?
Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Multilevel logistic regression guessing parameter

Hi Dominik,

I mean that brms uses Stan (http://mc-stan.org/) for the model fitting, but
you don't need to worry about that. I am confident that brms will allow you
to fit the model you have in mind.

Best,
Paul

2017-05-12 10:55 GMT+02:00 Dominik ?epuli? <dcepulic at gmail.com<mailto:dcepulic at gmail.com>>:

> Dear everybody, thank you for your ideas and messages!
>
> First, Philipp, yes, you are right. We have a simple two-choice
> recognition task. Participants were learning some stimuli,  and after some
> the recognition phase started. Always one stimuli per screen, and they have
> to say whether it is one of the learnt ones or not. B is therefore coded as
> response1 and response2 and afterwards coded in correct/incorrect.
> The problem that might have appeared is that some distractors may have
> been very similar to some well learnt items, and were simultaneously paired
> with a poorly learnt target. That might produce the effect of correctness
> below 0.5 We searched for such tasks and deleted them from further analysis.
>
> My problem is that when I try to plot probability functions (x - predictor
> variable, y - Accuracy from 0 to 1) for domains, they go below 0.5 which
> doesn?t make sense, as this was a two-choice task. Their lower asymptote
> should be on 0.5 not on 0. That?s why I am asking.
>
> @Paul: Thanks for recommendation, but what do you mean by "Stan under the
> hood"? I basically need a typical multilevel logistic regression (with
> random effects for 2 crossed levels) but with lower asymptote being 0.5 and
> not 0.
>
> I will take a look at the functions!
>
> Best,
> Dominik
>
> On Fri, May 12, 2017 at 9:36 AM, Paul Buerkner <paul.buerkner at gmail.com<mailto:paul.buerkner at gmail.com>>
> wrote:
>
>> Hi Dominik,
>>
>> in addition to what Jake said, you can do this with the brms package
>> (using Stan under the hood). After installing brms, you can learn how to
>> fit such models in the "brms_nonlinear" vignette: Type
>> vignette("brms_nonlinear") in R.
>>
>> Best,
>> Paul
>>
>> 2017-05-11 13:00 GMT+02:00 Dominik ?epuli? <dcepulic at gmail.com<mailto:dcepulic at gmail.com>>:
>>
>>> I  have a following situation:
>>>
>>> I want to predict variable B (which is dichotomous) from variable A
>>> (continous) controlling for random effects on the level of a) Subjects;
>>> b)
>>> Tasks.
>>>
>>> A -> B (1)
>>>
>>> The problem is that when I use model to predict the values of B from A,
>>> values below probability of 0.5 get predicted, and in my case that
>>> doesn?t
>>> make sense, because, if you guess at random, the probability of correct
>>> answer on B would be 0.5.
>>>
>>> I want to know how I can constrain the model (1) in lme4 so that it
>>> doesn?t
>>> predict values lower than 0.5 in variable B.
>>>
>>> Thank you,
>>>
>>> Dominik!
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From obert.alexandre at gmail.com  Fri May 12 16:05:59 2017
From: obert.alexandre at gmail.com (Alexandre Obert)
Date: Fri, 12 May 2017 16:05:59 +0200
Subject: [R-sig-ME] ERPs lme covariates
Message-ID: <3749729d-e055-469f-31a6-70b698ea216e@gmail.com>

Dear all,

I'm working on ERPs data from a language comprehension study and I'm 
confronting to some problems with items' features.
Briefly, participants saw words on a screen and have to decide if 
they're meaningful or not.
Some of them were meaningful (condition 1), others not (condition 2) and 
others were ambiguous (condition 3).
Using classical ANOVA, I observed significant differences.
However, words came with characteristics such as frequency, number of 
letters and so on...that I would like to control for.
In other words, I would like to test the effect of the condition and 
control the words' features in a same analysis.

I think that lme from lme4() could compute such analysis, is-this right?

Regards,

-- 
Alexandre OBERT


From baron at upenn.edu  Fri May 12 12:47:19 2017
From: baron at upenn.edu (Jonathan Baron)
Date: Fri, 12 May 2017 06:47:19 -0400
Subject: [R-sig-ME] Multilevel logistic regression guessing parameter
In-Reply-To: <1494581570222.75256@nmbu.no>
References: <CAGbn3HZ68nUySiJCc+G8EPCy72sw1rdHo2tp7sCPGxa0JZjMrg@mail.gmail.com>
 <CAGoSky889aPr6kGMCMZcr-+GzuHt0z3KiG3VW72Xb_n1OW_gKw@mail.gmail.com>
 <CAGoSky8Muc_nM2+GcosrvZMN4je3MDo_wvAA8inOxrXhZk93Rg@mail.gmail.com>
 <1494581570222.75256@nmbu.no>
Message-ID: <20170512104719.GA19338@upenn.edu>

On 05/12/17 09:32, Conor Michael Goold wrote:

[... omitted most of message]

>John Kruschke has an example in his book Doing Bayesian Data Analysis (using JAGS) 
>and also in this paper (see equation 3 in appendix 4): 
>http://journal.sjdm.org/14/14721a/jdm14721a.html 

http://journal.sjdm.org/14/14721a/jdm14721a.pdf is better for
this. Html is not the main article. And, since there is no equation 3,
I guess this is equations 15 and 16. But, in any case, you need to
read much of the article to understand this.

Jon
-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron
Editor: Judgment and Decision Making (http://journal.sjdm.org)


From dcepulic at gmail.com  Fri May 12 10:55:04 2017
From: dcepulic at gmail.com (=?UTF-8?B?RG9taW5payDEhmVwdWxpxIc=?=)
Date: Fri, 12 May 2017 10:55:04 +0200
Subject: [R-sig-ME] Multilevel logistic regression guessing parameter
In-Reply-To: <CAGoSky889aPr6kGMCMZcr-+GzuHt0z3KiG3VW72Xb_n1OW_gKw@mail.gmail.com>
References: <CAGbn3HZ68nUySiJCc+G8EPCy72sw1rdHo2tp7sCPGxa0JZjMrg@mail.gmail.com>
 <CAGoSky889aPr6kGMCMZcr-+GzuHt0z3KiG3VW72Xb_n1OW_gKw@mail.gmail.com>
Message-ID: <CAGbn3HbhWDhjBrdXWQhkCZuEJaBf-F9D7kNdTKRvfDab4qfz+A@mail.gmail.com>

Dear everybody, thank you for your ideas and messages!

First, Philipp, yes, you are right. We have a simple two-choice recognition
task. Participants were learning some stimuli,  and after some the
recognition phase started. Always one stimuli per screen, and they have to
say whether it is one of the learnt ones or not. B is therefore coded as
response1 and response2 and afterwards coded in correct/incorrect.
The problem that might have appeared is that some distractors may have been
very similar to some well learnt items, and were simultaneously paired with
a poorly learnt target. That might produce the effect of correctness below
0.5 We searched for such tasks and deleted them from further analysis.

My problem is that when I try to plot probability functions (x - predictor
variable, y - Accuracy from 0 to 1) for domains, they go below 0.5 which
doesn?t make sense, as this was a two-choice task. Their lower asymptote
should be on 0.5 not on 0. That?s why I am asking.

@Paul: Thanks for recommendation, but what do you mean by "Stan under the
hood"? I basically need a typical multilevel logistic regression (with
random effects for 2 crossed levels) but with lower asymptote being 0.5 and
not 0.

I will take a look at the functions!

Best,
Dominik

On Fri, May 12, 2017 at 9:36 AM, Paul Buerkner <paul.buerkner at gmail.com>
wrote:

> Hi Dominik,
>
> in addition to what Jake said, you can do this with the brms package
> (using Stan under the hood). After installing brms, you can learn how to
> fit such models in the "brms_nonlinear" vignette: Type
> vignette("brms_nonlinear") in R.
>
> Best,
> Paul
>
> 2017-05-11 13:00 GMT+02:00 Dominik ?epuli? <dcepulic at gmail.com>:
>
>> I  have a following situation:
>>
>> I want to predict variable B (which is dichotomous) from variable A
>> (continous) controlling for random effects on the level of a) Subjects; b)
>> Tasks.
>>
>> A -> B (1)
>>
>> The problem is that when I use model to predict the values of B from A,
>> values below probability of 0.5 get predicted, and in my case that doesn?t
>> make sense, because, if you guess at random, the probability of correct
>> answer on B would be 0.5.
>>
>> I want to know how I can constrain the model (1) in lme4 so that it
>> doesn?t
>> predict values lower than 0.5 in variable B.
>>
>> Thank you,
>>
>> Dominik!
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>

	[[alternative HTML version deleted]]


From dcepulic at gmail.com  Fri May 12 11:18:17 2017
From: dcepulic at gmail.com (=?UTF-8?B?RG9taW5payDEhmVwdWxpxIc=?=)
Date: Fri, 12 May 2017 11:18:17 +0200
Subject: [R-sig-ME] Predicting individual slopes from specific random
	intercepts
Message-ID: <CAGbn3HbZchxuVyf3UpRyY6CRfG4X4iB+JUgJG_=__AuGoBAQfw@mail.gmail.com>

Dear everybody!

I am writing with another question regarding lme4, this time regarding some
predicting possibilities.

Let?s say I predict variable Accuracy from Reaction time, random efffects
being subjects and tasks. The formula would be

glmer(Accuracy ~ RT + (1+RT | subj) + (1+RT | Task))

Random intercepts for subjects stand for their abilities, and random
intercepts for tasks for their difficulty.

I would like to be able to specify ability from a certain subject and the
difficulty of a task, and then predict the slope for this case in order to
plot the function.

Concretely, I would like to see how the function relating RT to Accuracy
looks like for people who are 1 sd above average in their abilities when
they solve tasks which are below average for their difficulty. The function
would then tell me how their probabilit of correct answer changes according
to the speed of answering.
For more clarity, you can also take a look at
*The Time on Task Effect in Reading and Problem Solving Is Moderated by
Task Difficulty and Skill: Insights from a Computer-Based Large-Scale
Assessment  *from Goldhammer et al.(2014). They did it in their last two
pictures I think.Thanks in advance,
Dominik

	[[alternative HTML version deleted]]


From dcepulic at gmail.com  Fri May 12 13:19:51 2017
From: dcepulic at gmail.com (=?UTF-8?B?RG9taW5payDEhmVwdWxpxIc=?=)
Date: Fri, 12 May 2017 13:19:51 +0200
Subject: [R-sig-ME] Multilevel logistic regression guessing parameter
In-Reply-To: <1494587565043.4578@nmbu.no>
References: <CAGbn3HZ68nUySiJCc+G8EPCy72sw1rdHo2tp7sCPGxa0JZjMrg@mail.gmail.com>
 <CAGoSky889aPr6kGMCMZcr-+GzuHt0z3KiG3VW72Xb_n1OW_gKw@mail.gmail.com>
 <CAGbn3HbhWDhjBrdXWQhkCZuEJaBf-F9D7kNdTKRvfDab4qfz+A@mail.gmail.com>
 <CAGoSky8Muc_nM2+GcosrvZMN4je3MDo_wvAA8inOxrXhZk93Rg@mail.gmail.com>
 <1494581570222.75256@nmbu.no> <1494587565043.4578@nmbu.no>
Message-ID: <CAGbn3HaG6AE7UbyWp4Mf61NaK4AF1A5CToSFd9O82=PfJc0VcQ@mail.gmail.com>

Dear Conor and Jonathan, thanks for your replies!


Maybe I am wrong but I believe that there is a difference when applying
logistic regression  when you ask an open question, without any answers
given, and the answer may be right or wrong (so dependent variable is
dichotomous) and
when you ask a question but offer two answers among which one of them is
correct. That has to be taken into account somehow when doing logistic
regression, according to my viewpoint.

Am I missing something?

On Fri, May 12, 2017 at 1:12 PM, Conor Michael Goold <conor.goold at nmbu.no>
wrote:

> Hi Dominik,
>
> I meant to write equation 4 in appendix 1 of the hyperlinked paper.
>
> Conor
>
>
> ________________________________________
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on
> behalf of Conor Michael Goold <conor.goold at nmbu.no>
> Sent: Friday, May 12, 2017 11:32 AM
> To: Paul Buerkner; Dominik ?epuli?
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Multilevel logistic regression guessing parameter
>
> Hi Dominik,
>
> I may have misunderstood your problem, but I don't understand why you want
> to constrain the probability of success to be 0.5 at the lowest. If
> participants are choosing their answers completely randomly, their average
> probability of choosing the correct response (i.e. a 1 if the responses are
> coded 0 = incorrect and 1 = correct) across tasks may be around 0.5, but it
> seems completely plausible that the average probability of choosing the
> correct response could be between 0 and 1, and this propensity for a
> correct answer could vary between participants. This seems like a normal
> application of logistic regression. Sorry if I am missing something!
>
> If you have reason to believe that participants do just guess sometimes,
> which may result in some 'outlying' data points (i.e. correct or incorrect
> responses where we may not expect them), as others have said, this can be
> included in a Bayesian model. John Kruschke has an example in his book
> Doing Bayesian Data Analysis (using JAGS) and also in this paper (see
> equation 3 in appendix 4): http://journal.sjdm.org/14/
> 14721a/jdm14721a.html
>
> Best regards
> Conor
> ________________________________________
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on
> behalf of Paul Buerkner <paul.buerkner at gmail.com>
> Sent: Friday, May 12, 2017 11:04 AM
> To: Dominik ?epuli?
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Multilevel logistic regression guessing parameter
>
> Hi Dominik,
>
> I mean that brms uses Stan (http://mc-stan.org/) for the model fitting,
> but
> you don't need to worry about that. I am confident that brms will allow you
> to fit the model you have in mind.
>
> Best,
> Paul
>
> 2017-05-12 10:55 GMT+02:00 Dominik ?epuli? <dcepulic at gmail.com>:
>
> > Dear everybody, thank you for your ideas and messages!
> >
> > First, Philipp, yes, you are right. We have a simple two-choice
> > recognition task. Participants were learning some stimuli,  and after
> some
> > the recognition phase started. Always one stimuli per screen, and they
> have
> > to say whether it is one of the learnt ones or not. B is therefore coded
> as
> > response1 and response2 and afterwards coded in correct/incorrect.
> > The problem that might have appeared is that some distractors may have
> > been very similar to some well learnt items, and were simultaneously
> paired
> > with a poorly learnt target. That might produce the effect of correctness
> > below 0.5 We searched for such tasks and deleted them from further
> analysis.
> >
> > My problem is that when I try to plot probability functions (x -
> predictor
> > variable, y - Accuracy from 0 to 1) for domains, they go below 0.5 which
> > doesn?t make sense, as this was a two-choice task. Their lower asymptote
> > should be on 0.5 not on 0. That?s why I am asking.
> >
> > @Paul: Thanks for recommendation, but what do you mean by "Stan under the
> > hood"? I basically need a typical multilevel logistic regression (with
> > random effects for 2 crossed levels) but with lower asymptote being 0.5
> and
> > not 0.
> >
> > I will take a look at the functions!
> >
> > Best,
> > Dominik
> >
> > On Fri, May 12, 2017 at 9:36 AM, Paul Buerkner <paul.buerkner at gmail.com>
> > wrote:
> >
> >> Hi Dominik,
> >>
> >> in addition to what Jake said, you can do this with the brms package
> >> (using Stan under the hood). After installing brms, you can learn how to
> >> fit such models in the "brms_nonlinear" vignette: Type
> >> vignette("brms_nonlinear") in R.
> >>
> >> Best,
> >> Paul
> >>
> >> 2017-05-11 13:00 GMT+02:00 Dominik ?epuli? <dcepulic at gmail.com>:
> >>
> >>> I  have a following situation:
> >>>
> >>> I want to predict variable B (which is dichotomous) from variable A
> >>> (continous) controlling for random effects on the level of a) Subjects;
> >>> b)
> >>> Tasks.
> >>>
> >>> A -> B (1)
> >>>
> >>> The problem is that when I use model to predict the values of B from A,
> >>> values below probability of 0.5 get predicted, and in my case that
> >>> doesn?t
> >>> make sense, because, if you guess at random, the probability of correct
> >>> answer on B would be 0.5.
> >>>
> >>> I want to know how I can constrain the model (1) in lme4 so that it
> >>> doesn?t
> >>> predict values lower than 0.5 in variable B.
> >>>
> >>> Thank you,
> >>>
> >>> Dominik!
> >>>
> >>>         [[alternative HTML version deleted]]
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >>
> >>
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From HDoran at air.org  Fri May 12 16:57:27 2017
From: HDoran at air.org (Doran, Harold)
Date: Fri, 12 May 2017 14:57:27 +0000
Subject: [R-sig-ME] Multilevel logistic regression guessing parameter
In-Reply-To: <CAGbn3HbhWDhjBrdXWQhkCZuEJaBf-F9D7kNdTKRvfDab4qfz+A@mail.gmail.com>
References: <CAGbn3HZ68nUySiJCc+G8EPCy72sw1rdHo2tp7sCPGxa0JZjMrg@mail.gmail.com>
 <CAGoSky889aPr6kGMCMZcr-+GzuHt0z3KiG3VW72Xb_n1OW_gKw@mail.gmail.com>
 <CAGbn3HbhWDhjBrdXWQhkCZuEJaBf-F9D7kNdTKRvfDab4qfz+A@mail.gmail.com>
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD6860141D6DABD@DC1VEX10MB01.air.org>

Dominik

It in fact is well known issue that the lower asymptote of the 3 parameter model you are essentially working with can be different than .5. The empirical results are suggesting that there is some information in the item itself, perhaps in one if the distractors, or in the item stem itself that leads responders to have a probability of response that differs from .5.

You might consider going straight to some IRT packages in R or IRT-specific software instead

-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Dominik Cepulic
Sent: Friday, May 12, 2017 4:55 AM
To: Paul Buerkner <paul.buerkner at gmail.com>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Multilevel logistic regression guessing parameter

Dear everybody, thank you for your ideas and messages!

First, Philipp, yes, you are right. We have a simple two-choice recognition task. Participants were learning some stimuli,  and after some the recognition phase started. Always one stimuli per screen, and they have to say whether it is one of the learnt ones or not. B is therefore coded as
response1 and response2 and afterwards coded in correct/incorrect.
The problem that might have appeared is that some distractors may have been very similar to some well learnt items, and were simultaneously paired with a poorly learnt target. That might produce the effect of correctness below
0.5 We searched for such tasks and deleted them from further analysis.

My problem is that when I try to plot probability functions (x - predictor variable, y - Accuracy from 0 to 1) for domains, they go below 0.5 which doesn?t make sense, as this was a two-choice task. Their lower asymptote should be on 0.5 not on 0. That?s why I am asking.

@Paul: Thanks for recommendation, but what do you mean by "Stan under the hood"? I basically need a typical multilevel logistic regression (with random effects for 2 crossed levels) but with lower asymptote being 0.5 and not 0.

I will take a look at the functions!

Best,
Dominik

On Fri, May 12, 2017 at 9:36 AM, Paul Buerkner <paul.buerkner at gmail.com>
wrote:

> Hi Dominik,
>
> in addition to what Jake said, you can do this with the brms package 
> (using Stan under the hood). After installing brms, you can learn how 
> to fit such models in the "brms_nonlinear" vignette: Type
> vignette("brms_nonlinear") in R.
>
> Best,
> Paul
>
> 2017-05-11 13:00 GMT+02:00 Dominik ?epuli? <dcepulic at gmail.com>:
>
>> I  have a following situation:
>>
>> I want to predict variable B (which is dichotomous) from variable A
>> (continous) controlling for random effects on the level of a) 
>> Subjects; b) Tasks.
>>
>> A -> B (1)
>>
>> The problem is that when I use model to predict the values of B from 
>> A, values below probability of 0.5 get predicted, and in my case that 
>> doesn?t make sense, because, if you guess at random, the probability 
>> of correct answer on B would be 0.5.
>>
>> I want to know how I can constrain the model (1) in lme4 so that it 
>> doesn?t predict values lower than 0.5 in variable B.
>>
>> Thank you,
>>
>> Dominik!
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From HDoran at air.org  Fri May 12 20:06:39 2017
From: HDoran at air.org (Doran, Harold)
Date: Fri, 12 May 2017 18:06:39 +0000
Subject: [R-sig-ME] Multilevel logistic regression guessing parameter
In-Reply-To: <CAGbn3HZBsYvzO01avhu9V8VxZJ8YR23LDi_+d3yRT-DOtQ9PQg@mail.gmail.com>
References: <CAGbn3HZ68nUySiJCc+G8EPCy72sw1rdHo2tp7sCPGxa0JZjMrg@mail.gmail.com>
 <CAGoSky889aPr6kGMCMZcr-+GzuHt0z3KiG3VW72Xb_n1OW_gKw@mail.gmail.com>
 <CAGbn3HbhWDhjBrdXWQhkCZuEJaBf-F9D7kNdTKRvfDab4qfz+A@mail.gmail.com>
 <B08B6AF0CF8CA44F81B9983EEBDCD6860141D6DABD@DC1VEX10MB01.air.org>
 <CAGbn3HZBsYvzO01avhu9V8VxZJ8YR23LDi_+d3yRT-DOtQ9PQg@mail.gmail.com>
Message-ID: <D53B714F.470AD%hdoran@air.org>

First, think of IRT as logistic regression. That is the point (well, one point) that we make in this article connecting lmer with the Rasch model

https://www.jstatsoft.org/article/view/v020i02

It sounds as though you are modeling the probability of a binary response where you want the lower asymptote to be non-zero. So, we refer to this as a 3 parameter logistic model and for each item, you estimate a location parameter, a slope, and the lower asymptote which represents the probability of guessing at low values of the latent trait.

From: Dominik ?epuli? <dcepulic at gmail.com<mailto:dcepulic at gmail.com>>
Date: Friday, May 12, 2017 at 1:32 PM
To: AIR <hdoran at air.org<mailto:hdoran at air.org>>
Cc: Paul Buerkner <paul.buerkner at gmail.com<mailto:paul.buerkner at gmail.com>>, "r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>" <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
Subject: Re: [R-sig-ME] Multilevel logistic regression guessing parameter

Ok, I was also thinking about an IRT package before, but had problems understanding how I could conceptualize my problem insde IRT framework.
Regarding that issue, this are really basic questions, but I really haven?t found any concrete answer to them:
1) I always got the impression that IRT is used when observed variables are used to predict latent trait measured by them. In my experiment that is not the case - observed reaction times predict observed accuracies. How can I set predictors and criterion variables in IRT framework?

2) As I understood IRT, you always get several parameters for a certain task (depending on which IRT model you are using). That means that for a certain stimuli I would get e.g. 3 parameters. My issue is that I am not interested in single stimuli, because I have over 500 of them - I am interested in a domain certain group of stimuli describe. I.e To me it is not important to know the parameters for a single exemplar but for a whole category which is measured by 64 exemplars. How can I calculate category parameters with an IRT package?

I know this might not be the questions best suited for this forum, but if anyone has some guidelines, I would be very grateful.

Besides that, do you have any suggestions for an IRT package that?s well suited for my problem?

Best,
Dominik

On Fri, May 12, 2017 at 4:57 PM, Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>> wrote:
Dominik

It in fact is well known issue that the lower asymptote of the 3 parameter model you are essentially working with can be different than .5. The empirical results are suggesting that there is some information in the item itself, perhaps in one if the distractors, or in the item stem itself that leads responders to have a probability of response that differs from .5.

You might consider going straight to some IRT packages in R or IRT-specific software instead

-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org>] On Behalf Of Dominik Cepulic
Sent: Friday, May 12, 2017 4:55 AM
To: Paul Buerkner <paul.buerkner at gmail.com<mailto:paul.buerkner at gmail.com>>
Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Multilevel logistic regression guessing parameter

Dear everybody, thank you for your ideas and messages!

First, Philipp, yes, you are right. We have a simple two-choice recognition task. Participants were learning some stimuli,  and after some the recognition phase started. Always one stimuli per screen, and they have to say whether it is one of the learnt ones or not. B is therefore coded as
response1 and response2 and afterwards coded in correct/incorrect.
The problem that might have appeared is that some distractors may have been very similar to some well learnt items, and were simultaneously paired with a poorly learnt target. That might produce the effect of correctness below
0.5 We searched for such tasks and deleted them from further analysis.

My problem is that when I try to plot probability functions (x - predictor variable, y - Accuracy from 0 to 1) for domains, they go below 0.5 which doesn?t make sense, as this was a two-choice task. Their lower asymptote should be on 0.5 not on 0. That?s why I am asking.

@Paul: Thanks for recommendation, but what do you mean by "Stan under the hood"? I basically need a typical multilevel logistic regression (with random effects for 2 crossed levels) but with lower asymptote being 0.5 and not 0.

I will take a look at the functions!

Best,
Dominik

On Fri, May 12, 2017 at 9:36 AM, Paul Buerkner <paul.buerkner at gmail.com<mailto:paul.buerkner at gmail.com>>
wrote:

> Hi Dominik,
>
> in addition to what Jake said, you can do this with the brms package
> (using Stan under the hood). After installing brms, you can learn how
> to fit such models in the "brms_nonlinear" vignette: Type
> vignette("brms_nonlinear") in R.
>
> Best,
> Paul
>
> 2017-05-11 13:00 GMT+02:00 Dominik ?epuli? <dcepulic at gmail.com<mailto:dcepulic at gmail.com>>:
>
>> I  have a following situation:
>>
>> I want to predict variable B (which is dichotomous) from variable A
>> (continous) controlling for random effects on the level of a)
>> Subjects; b) Tasks.
>>
>> A -> B (1)
>>
>> The problem is that when I use model to predict the values of B from
>> A, values below probability of 0.5 get predicted, and in my case that
>> doesn?t make sense, because, if you guess at random, the probability
>> of correct answer on B would be 0.5.
>>
>> I want to know how I can constrain the model (1) in lme4 so that it
>> doesn?t predict values lower than 0.5 in variable B.
>>
>> Thank you,
>>
>> Dominik!
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From dcepulic at gmail.com  Fri May 12 19:32:18 2017
From: dcepulic at gmail.com (=?UTF-8?B?RG9taW5payDEhmVwdWxpxIc=?=)
Date: Fri, 12 May 2017 19:32:18 +0200
Subject: [R-sig-ME] Multilevel logistic regression guessing parameter
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD6860141D6DABD@DC1VEX10MB01.air.org>
References: <CAGbn3HZ68nUySiJCc+G8EPCy72sw1rdHo2tp7sCPGxa0JZjMrg@mail.gmail.com>
 <CAGoSky889aPr6kGMCMZcr-+GzuHt0z3KiG3VW72Xb_n1OW_gKw@mail.gmail.com>
 <CAGbn3HbhWDhjBrdXWQhkCZuEJaBf-F9D7kNdTKRvfDab4qfz+A@mail.gmail.com>
 <B08B6AF0CF8CA44F81B9983EEBDCD6860141D6DABD@DC1VEX10MB01.air.org>
Message-ID: <CAGbn3HZBsYvzO01avhu9V8VxZJ8YR23LDi_+d3yRT-DOtQ9PQg@mail.gmail.com>

Ok, I was also thinking about an IRT package before, but had problems
understanding how I could conceptualize my problem insde IRT framework.
Regarding that issue, this are really basic questions, but I really haven?t
found any concrete answer to them:
1) I always got the impression that IRT is used when observed variables are
used to predict latent trait measured by them. In my experiment that is not
the case - observed reaction times predict observed accuracies. How can I
set predictors and criterion variables in IRT framework?

2) As I understood IRT, you always get several parameters for a certain
task (depending on which IRT model you are using). That means that for a
certain stimuli I would get e.g. 3 parameters. My issue is that I am not
interested in single stimuli, because I have over 500 of them - I am
interested in a domain certain group of stimuli describe. I.e To me it is
not important to know the parameters for a single exemplar but for a whole
category which is measured by 64 exemplars. How can I calculate category
parameters with an IRT package?

I know this might not be the questions best suited for this forum, but if
anyone has some guidelines, I would be very grateful.

Besides that, do you have any suggestions for an IRT package that?s well
suited for my problem?

Best,
Dominik

On Fri, May 12, 2017 at 4:57 PM, Doran, Harold <HDoran at air.org> wrote:

> Dominik
>
> It in fact is well known issue that the lower asymptote of the 3 parameter
> model you are essentially working with can be different than .5. The
> empirical results are suggesting that there is some information in the item
> itself, perhaps in one if the distractors, or in the item stem itself that
> leads responders to have a probability of response that differs from .5.
>
> You might consider going straight to some IRT packages in R or
> IRT-specific software instead
>
> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org]
> On Behalf Of Dominik Cepulic
> Sent: Friday, May 12, 2017 4:55 AM
> To: Paul Buerkner <paul.buerkner at gmail.com>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Multilevel logistic regression guessing parameter
>
> Dear everybody, thank you for your ideas and messages!
>
> First, Philipp, yes, you are right. We have a simple two-choice
> recognition task. Participants were learning some stimuli,  and after some
> the recognition phase started. Always one stimuli per screen, and they have
> to say whether it is one of the learnt ones or not. B is therefore coded as
> response1 and response2 and afterwards coded in correct/incorrect.
> The problem that might have appeared is that some distractors may have
> been very similar to some well learnt items, and were simultaneously paired
> with a poorly learnt target. That might produce the effect of correctness
> below
> 0.5 We searched for such tasks and deleted them from further analysis.
>
> My problem is that when I try to plot probability functions (x - predictor
> variable, y - Accuracy from 0 to 1) for domains, they go below 0.5 which
> doesn?t make sense, as this was a two-choice task. Their lower asymptote
> should be on 0.5 not on 0. That?s why I am asking.
>
> @Paul: Thanks for recommendation, but what do you mean by "Stan under the
> hood"? I basically need a typical multilevel logistic regression (with
> random effects for 2 crossed levels) but with lower asymptote being 0.5 and
> not 0.
>
> I will take a look at the functions!
>
> Best,
> Dominik
>
> On Fri, May 12, 2017 at 9:36 AM, Paul Buerkner <paul.buerkner at gmail.com>
> wrote:
>
> > Hi Dominik,
> >
> > in addition to what Jake said, you can do this with the brms package
> > (using Stan under the hood). After installing brms, you can learn how
> > to fit such models in the "brms_nonlinear" vignette: Type
> > vignette("brms_nonlinear") in R.
> >
> > Best,
> > Paul
> >
> > 2017-05-11 13:00 GMT+02:00 Dominik ?epuli? <dcepulic at gmail.com>:
> >
> >> I  have a following situation:
> >>
> >> I want to predict variable B (which is dichotomous) from variable A
> >> (continous) controlling for random effects on the level of a)
> >> Subjects; b) Tasks.
> >>
> >> A -> B (1)
> >>
> >> The problem is that when I use model to predict the values of B from
> >> A, values below probability of 0.5 get predicted, and in my case that
> >> doesn?t make sense, because, if you guess at random, the probability
> >> of correct answer on B would be 0.5.
> >>
> >> I want to know how I can constrain the model (1) in lme4 so that it
> >> doesn?t predict values lower than 0.5 in variable B.
> >>
> >> Thank you,
> >>
> >> Dominik!
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From conor.goold at nmbu.no  Sat May 13 11:21:09 2017
From: conor.goold at nmbu.no (Conor Michael Goold)
Date: Sat, 13 May 2017 09:21:09 +0000
Subject: [R-sig-ME] Multilevel logistic regression guessing parameter
In-Reply-To: <20170512104719.GA19338@upenn.edu>
References: <CAGbn3HZ68nUySiJCc+G8EPCy72sw1rdHo2tp7sCPGxa0JZjMrg@mail.gmail.com>
 <CAGoSky889aPr6kGMCMZcr-+GzuHt0z3KiG3VW72Xb_n1OW_gKw@mail.gmail.com>
 <CAGoSky8Muc_nM2+GcosrvZMN4je3MDo_wvAA8inOxrXhZk93Rg@mail.gmail.com>
 <1494581570222.75256@nmbu.no>,<20170512104719.GA19338@upenn.edu>
Message-ID: <1494667269105.67932@nmbu.no>

Jonathan, 

It was equation 4 in appendix 1 I was referring to, as I corrected in a subsequent email. The html works fine for me. Anyway, it doesn't sound quite what Dominik is after for his model. 

Conor

________________________________________
From: Jonathan Baron <baron at upenn.edu>
Sent: Friday, May 12, 2017 12:47 PM
To: Conor Michael Goold
Cc: Paul Buerkner; Dominik ?epuli?; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Multilevel logistic regression guessing parameter

On 05/12/17 09:32, Conor Michael Goold wrote:

[... omitted most of message]

>John Kruschke has an example in his book Doing Bayesian Data Analysis (using JAGS)
>and also in this paper (see equation 3 in appendix 4):
>http://journal.sjdm.org/14/14721a/jdm14721a.html

http://journal.sjdm.org/14/14721a/jdm14721a.pdf is better for
this. Html is not the main article. And, since there is no equation 3,
I guess this is equations 15 and 16. But, in any case, you need to
read much of the article to understand this.

Jon
--
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron
Editor: Judgment and Decision Making (http://journal.sjdm.org)


From ken.knoblauch at inserm.fr  Sat May 13 13:56:02 2017
From: ken.knoblauch at inserm.fr (Kenneth Knoblauch)
Date: Sat, 13 May 2017 13:56:02 +0200
Subject: [R-sig-ME]  Multilevel logistic regression guessing parameter
Message-ID: <c10f360cc56dc428267f25c184269fa0@inserm.fr>

Hi,

I think that you can achieve this with one of the alternate links in the 
psyphy package, like mafc.logit(.m = 2). Here is an example that is 
contrived but I don't have time to generate toy data and you didn't 
supply any. And it is set-up for 4 alternatives so it gives a lower 
asymptote of 0.25 instead of 2.

I had suggested this to you offline, but you said it didn't work, but it 
works fine for me in the example code below.  As I said, the actually 
example doesn't make any sense but it should work for data where it 
does.

library(psyphy)
library(lattice)
library(lme4)

m1 <- glm(cbind(Correct, Incorrect) ~ factor(Size) * Contr,
    binomial(mafc.logit(.m = 4)), ecc2, subset = task == "DET")

contr <- seq(0.01, 0.5, len = 50)

nd2 <- nd <- expand.grid(Contr = contr,
	Size = factor(unique(ecc2$Size)))

nd$pr <- predict(m1, newdata = nd, type = "response")
xyplot(pr ~ Contr | Size, nd, type = "l", ylim = c(0, 1.1))


m2 <- glmer(cbind(Correct, Incorrect) ~  Contr + (Contr | Size),
   ecc2, binomial(mafc.logit(.m = 4)),
   subset = task == "DET")

nd2$pr <- predict(m2, newdata = nd2, re.form = NA,  type = "response")
dev.new()
xyplot(pr ~ Contr | Size, nd2, type = "l", ylim = c(0, 1.1))

HTH,

Ken


>> I  have a following situation:
>> 
>> I want to predict variable B (which is dichotomous) from variable A
>> (continous) controlling for random effects on the level of a) 
>> Subjects; b)
>> Tasks.
>> 
>> A -> B (1)
>> 
>> The problem is that when I use model to predict the values of B from 
>> A,
>> values below probability of 0.5 get predicted, and in my case that 
>> doesn?t
>> make sense, because, if you guess at random, the probability of 
>> correct
>> answer on B would be 0.5.
>> 
>> I want to know how I can constrain the model (1) in lme4 so that it
>> doesn?t
>> predict values lower than 0.5 in variable B.
>> 
>> Thank you,
>> 
>> Dominik!

-- 
Kenneth Knoblauch
Inserm U1208
Stem-cell and Brain Research Institute
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.sbri.fr/members/kenneth-knoblauch.html


From luca.corlatti at boku.ac.at  Tue May 16 09:58:12 2017
From: luca.corlatti at boku.ac.at (Luca Corlatti)
Date: Tue, 16 May 2017 09:58:12 +0200
Subject: [R-sig-ME] Syntax interaction polynomial term
References: <591AB1140200006800020746@gwia2.boku.ac.at>
Message-ID: <591AB1140200006800020746@gwia2.boku.ac.at>

Dear list members, I am trying to fit some models to investigate the effects of some predictors (weight, age) on fertility.
As the effect of age on fertility is typically quadratic (lower fertility for the extreme age-classes and higher fertility for intermediate age-classes), I fitted the full additive model as:


fertility ~ weight + poly(age, 2, raw=TRUE)


I would also like to fit a model with an interaction term between weight and age, but I fail to understand the correct syntax. Should the interaction be between weight and the full polynomial term:


fertility ~ weight * poly(age, 2, raw=TRUE)


or should it simply be between weight and the age^2?


fertility ~ weight + age + I(age^2) + weight : I(age^2)


Cheers, 
Luca


From thierry.onkelinx at inbo.be  Tue May 16 11:08:29 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 16 May 2017 11:08:29 +0200
Subject: [R-sig-ME] Syntax interaction polynomial term
In-Reply-To: <591AB1140200006800020746@gwia2.boku.ac.at>
References: <591AB1140200006800020746@gwia2.boku.ac.at>
 <591AB1140200006800020746@gwia2.boku.ac.at>
Message-ID: <CAJuCY5zBYhgi7iC158HtS24ARKtbOjVYCAjaH3q-2AtpFQvm3w@mail.gmail.com>

Dear Luca,

This questions has nothing to do with with mixed models. You should have
send it to r-help.

weight * poly(age, 2, raw=TRUE) is equivalent with weight + age + I(age^2)
+ weight : I(age^2) + weight:age. So you need the add the first order
interaction as well.
However you better use the orthogonal polynomials that the raw polynomials.
Because the raw polynomials might be highly correlated. Have a look at this
examples.

age <- 15:50
cor(cbind(age, age ^ 2, age ^ 3))
cor(poly(age, 3, raw = TRUE))
cor(poly(age, 3))
c_age <- scale(age, center = TRUE, scale = FALSE)
cor(cbind(c_age, c_age ^ 2, c_age ^ 3))
s_age <- scale(age, center = TRUE, scale = TRUE)
cor(cbind(s_age, s_age ^ 2, s_age ^ 3))

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-05-16 9:58 GMT+02:00 Luca Corlatti <luca.corlatti at boku.ac.at>:

> Dear list members, I am trying to fit some models to investigate the
> effects of some predictors (weight, age) on fertility.
> As the effect of age on fertility is typically quadratic (lower fertility
> for the extreme age-classes and higher fertility for intermediate
> age-classes), I fitted the full additive model as:
>
>
> fertility ~ weight + poly(age, 2, raw=TRUE)
>
>
> I would also like to fit a model with an interaction term between weight
> and age, but I fail to understand the correct syntax. Should the
> interaction be between weight and the full polynomial term:
>
>
> fertility ~ weight * poly(age, 2, raw=TRUE)
>
>
> or should it simply be between weight and the age^2?
>
>
> fertility ~ weight + age + I(age^2) + weight : I(age^2)
>
>
> Cheers,
> Luca
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From dcepulic at gmail.com  Mon May 15 10:50:18 2017
From: dcepulic at gmail.com (=?UTF-8?B?RG9taW5payDEhmVwdWxpxIc=?=)
Date: Mon, 15 May 2017 10:50:18 +0200
Subject: [R-sig-ME] Multilevel logistic regression guessing parameter
In-Reply-To: <1494667269105.67932@nmbu.no>
References: <CAGbn3HZ68nUySiJCc+G8EPCy72sw1rdHo2tp7sCPGxa0JZjMrg@mail.gmail.com>
 <CAGoSky889aPr6kGMCMZcr-+GzuHt0z3KiG3VW72Xb_n1OW_gKw@mail.gmail.com>
 <CAGoSky8Muc_nM2+GcosrvZMN4je3MDo_wvAA8inOxrXhZk93Rg@mail.gmail.com>
 <1494581570222.75256@nmbu.no> <20170512104719.GA19338@upenn.edu>
 <1494667269105.67932@nmbu.no>
Message-ID: <CAGbn3HZvYHPARUUUkJ-ZZo2WX69YJ_NeCpbyqQr9yWHZPyPNdg@mail.gmail.com>

Guys, thanks for your help. For the end, I would just be very grateful if
somebody could recommend some articles that deal with the lower accuracy
treshold (i.e. guessing parameter) for two-choice tasks. I took for granted
that it was automatically 0.5...

Cheers,
Dominik

On Sat, May 13, 2017 at 11:21 AM, Conor Michael Goold <conor.goold at nmbu.no>
wrote:

> Jonathan,
>
> It was equation 4 in appendix 1 I was referring to, as I corrected in a
> subsequent email. The html works fine for me. Anyway, it doesn't sound
> quite what Dominik is after for his model.
>
> Conor
>
> ________________________________________
> From: Jonathan Baron <baron at upenn.edu>
> Sent: Friday, May 12, 2017 12:47 PM
> To: Conor Michael Goold
> Cc: Paul Buerkner; Dominik ?epuli?; r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Multilevel logistic regression guessing parameter
>
> On 05/12/17 09:32, Conor Michael Goold wrote:
>
> [... omitted most of message]
>
> >John Kruschke has an example in his book Doing Bayesian Data Analysis
> (using JAGS)
> >and also in this paper (see equation 3 in appendix 4):
> >http://journal.sjdm.org/14/14721a/jdm14721a.html
>
> http://journal.sjdm.org/14/14721a/jdm14721a.pdf is better for
> this. Html is not the main article. And, since there is no equation 3,
> I guess this is equations 15 and 16. But, in any case, you need to
> read much of the article to understand this.
>
> Jon
> --
> Jonathan Baron, Professor of Psychology, University of Pennsylvania
> Home page: http://www.sas.upenn.edu/~baron
> Editor: Judgment and Decision Making (http://journal.sjdm.org)
>

	[[alternative HTML version deleted]]


From bakaburg1 at gmail.com  Wed May 17 10:46:34 2017
From: bakaburg1 at gmail.com (Angelo D'Ambrosio)
Date: Wed, 17 May 2017 10:46:34 +0200
Subject: [R-sig-ME] A mixed effect regression tool based on bayesian priors
	like bayesglm
Message-ID: <CALcwahN41htOSqF_E3LwyuaxqVuSFyW=Zx9Q-cW5x37rN4Eddw@mail.gmail.com>

I use extensively Gelman's bayesglm for the every day use due to the great
stability of the estimates especially in the case of separation.

I needed an equivalent of empirical bayesian regularization for glm mixed
effect models. These models are strongly influenced by extreme conditions
(like conditional probabilities of zero and separation) and like usual
logistic regression model they fail in these cases.

I found the blme package that does exactly what I need, solving the
separation problem. Now the problem is to set it up in order to be work
exactly as bayesglm, in order to achieve consistency in my analysis.
Reading Gelman paper on bayesglm() I understood I should use a t
distribution with 1 df (eg. Cauchy) and 2.5 scale, rescaling inputs:

    bglmer(Out ~ arm::rescale(Pred) + (1 | PatientID), family = binomial,
Data.events, fixef.prior = t(df = 1, scale = 2.5))

Is it correct? My doubt is what to do with the cov.prior parameter; should
I leave it as default (wishart) or should I put it to NULL? Also in
Gelman's paper it is said that the intercept should have the same prior
distribution but with scale 10, and I don't know how to specify a different
prior for it.

Also, I'm starting to think that bayesglm doesn't rescale the inputs
directly but scales the prior distribution according to the inputs. Am I
right?

Can you help me with this?

Thanks

	[[alternative HTML version deleted]]


From hongmei.chen at uni-leipzig.de  Fri May 19 12:06:05 2017
From: hongmei.chen at uni-leipzig.de (Hongmei Chen)
Date: Fri, 19 May 2017 12:06:05 +0200
Subject: [R-sig-ME] Mixed models for repeated measures with missing values
Message-ID: <fc7a4bb4-aa93-0ed5-6ade-330c2fd07ba1@uni-leipzig.de>

Dear mixed model users,

I have a question concerning using mixed models for repeated measures 
with missing values. I would like to test the effects of plant diversity 
(Div., continuous) on root growth rate (Y, continuous) over time (Time). 
However, time is not evenly spaced, thus I think it is better to use 
Time as a continuous term. In addition, the root growth rate - time 
relationship was not linear. Thus I used poly (Time, N) to account for 
the non-linear relationship.  Besides, the plots were randomly arranged 
in the 4 blocks, I would also like to account for the potential block 
effect.

I use lme from nlme for the data analyses.
I first tested the polynomial order by increasing n from 2 to 3. 
However, AIC suggest that I should use 5 or 6. I am afraid I will over 
fit the data. thus I chose ploy(Time, 3).
Mod1 <- lme (Y ~ Div * ploy(Time, 3), random = ~1|block/plot, method="ML")

Because of repeated measurement, I included e.g. correlation= corRatio 
(form=~Time, nugget=T) to account for the dependence. I tested different 
correlation structures and chose the one with lowest AIC.
Mod2 <- lme (Y ~ Div * ploy(Time, 3), random = ~1|block/plot, 
method="REML", correlation=  corRatio (form=~Time, nugget=T))

After checking the residuals, I still could see some trend in time, and 
heterogeneity in residuals e.g. at different time. I further included 
"weights" argument in the model.
Mod3 <- lme (Y ~ Div * ploy(Time, 3), random = ~1|block/plot, 
method="REML", correlation=  corRatio (form=~Time, nugget=T), 
weights=varIdent(form=~1|plot))

My questions are
1) Should I go for higher order in polynomial term? For example 4
2) For the random term, I used the simplest one. Would you consider 
other options e.g. random = ~ploy(Time, 3)|block/plot
3) Can I use time as a continuous term in fixed part but as a factor in 
the random part or in the weights argument  like: 
weights=varIdent(form=~1|as.factor(Time))

Because of the missing observation values, I could only used mixed 
models for my data. I have googled this is for quite a long time but 
could not find a good example or solution. Any suggestions are welcome.

Kind regards,
Hongmei Chen

-- 
Hongmei Chen
Spezielle Botanik und Funktionelle Biodiversit?t Institut f?r Biologie
Universit?t Leipzig
Johannisallee 21-23
04103 Leipzig

Tel: ++49 341 9738589
Fax: ++49 341 9738549
Email: hongmei.chen at uni-leipzig.de


From D.J.Damen at uvt.nl  Fri May 19 12:43:32 2017
From: D.J.Damen at uvt.nl (D.J. Damen)
Date: Fri, 19 May 2017 10:43:32 +0000
Subject: [R-sig-ME] Warnings BootMer bootstrap glmer lme4
Message-ID: <363DE002-9EE0-4AF0-97CE-706F4623AB34@uvt.nl>

Dear all,

Currently, I am using the BootMer function to bootstrap my final model (fitted with GLMER from the lme4 package) to estimate the confidence intervals and p-values. Since I am alternating my reference categories, I have to bootstrap several models, and now the bootstrap of one model (below) returns with 50 or more warnings. Is there a standard procedure to follow when this happens? Should I trust the bootstrap when warnings pop up?

I am fitting a binomial model with the (centered and treatment coded) predictors c.con.tr (3 levels), c.type.tr (2 levels), and c.diff.tr (2 levels), and the dependent variable ?contrast? (1 = mentioned; 0 = not mentioned).

Details about the model I want to bootstrap, the bootstrap function and the warnings are presented below:

Model:

m0bcc <-glmer (contrast~c.con.tr*c.type.tr*c.diff.tr+(1+c.type.tr+c.diff.tr|id)+(1+c.con.tr+c.type.tr|item.new), data=mydata, family=binomial (link='logit'), control=glmerControl(optimizer="bobyqa"))


Bootstrap function:

FUN <- function(fit) {
  return(fixef(fit))
}

boost <- function(mdl){
  name <- match.call()$mdl
  boosted <- bootMer(mdl, FUN, nsim = 100)
  save(boosted,file=paste(name,"_boosted",sep=""))
}

p_boosted <- function(mdl,boosted){
  for (n in 1:length(fixef(mdl))){
    print(fixef(mdl)[n])
    (bMCI <- boot.ci(boosted, conf = c(0.95, 0.99, 0.999), index=n, type="norm"))
    print(bMCI)
  }
}

Warnings: ( posted the first 10 warnings, in total there were 50 (or more?).

mdl <- m0bcc
> boosted <- bootMer(mdl, FUN, nsim = 100)
There were 50 or more warnings (use warnings() to see the first 50)

1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  ... :
  unable to evaluate scaled gradient
2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  ... :
  Model failed to converge: degenerate  Hessian with 1 negative eigenvalues
3: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  ... :
  unable to evaluate scaled gradient
4: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  ... :
  Model failed to converge: degenerate  Hessian with 2 negative eigenvalues
5: In optwrap(object at optinfo$optimizer, ff, x0, lower = lower,  ... :
  convergence code 1 from bobyqa: bobyqa -- maximum number of function evaluations exceeded
6: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  ... :
  Model failed to converge with max|grad| = 0.00176467 (tol = 0.001, component 1)
7: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  ... :
  unable to evaluate scaled gradient
8: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  ... :
  Model failed to converge: degenerate  Hessian with 1 negative eigenvalues
9: In optwrap(object at optinfo$optimizer, ff, x0, lower = lower,  ... :
  convergence code 1 from bobyqa: bobyqa -- maximum number of function evaluations exceeded
10: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  ... :
  Model failed to converge with max|grad| = 0.00258682 (tol = 0.001, component 1)
11: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  ... :


I couldn?t find whether I should decrease the random effects structure of my fitted model to decrease these bootstrap warnings, but since my fitted glmer model did converge, I am hesitant to do so anyway. I hope somebody is able to shed some light on this matter.

Thank you very much in advance.

Best, Debby

Debby Damen
PhD Student

Department of Communication and Information Science

Tilburg University
Warandelaan 2, room D410
5037 AB Tilburg

T. +31 13 466  8245
M. d.j.damen at uvt.nl<mailto:d.j.damen at uvt.nl>

	[[alternative HTML version deleted]]


From shirleywang at g.harvard.edu  Sat May 20 05:27:11 2017
From: shirleywang at g.harvard.edu (Wang, Shirley)
Date: Fri, 19 May 2017 23:27:11 -0400
Subject: [R-sig-ME] Help with glmmADMB and ZIP mixed effects models
Message-ID: <CAJxDRLd95QNa-tJe4xLrbg1fFUPM13PRgZ1eVrg_1MjUXmtsLg@mail.gmail.com>

Hello,

I'm hoping to run a zero-inflated mixed effects poisson regression model
for count data. My dataset includes 111 subjects, randomized to 3 groups
and each assessed 7 times (777 observations). Through searching online, it
seems like the glmmADMB package is my best bet. From my understanding, NA
missing values should be removed prior to analysis -- this leaves me with
264 observations. I tried running glmmadmb() with zero inflation, poisson,
and mixed effects specified; however, I'm running into some errors. This is
my dataset:

> str(x12)
'data.frame': 264 obs. of  12 variables:
 $ Subject   : Factor w/ 111 levels "1","2","3","4",..: 1 1 1 1 2 2 2 3 4 4
...
 $ Time      : int  1 5 6 7 1 5 7 1 1 6 ...
 $ Group     : Factor w/ 3 levels "1","2","3": 1 1 1 1 1 1 1 1 1 1 ...
 $ SRS       : int  56 55 56 55 50 46 42 49 47 42 ...
 $ BDI       : int  40 23 41 35 44 14 11 22 16 9 ...
 $ ERQ       : int  14 11 14 15 18 12 15 14 26 27 ...
 $ Cut       : int  3 4 10 15 1 1 0 1 0 0 ...
 $ NSSI      : int  8 14 32 58 2 2 8 2 0 1 ...
 $ Ideation  : int  2 0 5 10 5 3 0 1 0 0 ...
 $ Plan      : int  1 0 2 8 1 4 5 0 0 0 ...
 $ Stop      : int  2 2 1 2 3 3 3 2 3 2 ...
 $ Likelihood: int  4 4 4 4 3 4 4 4 3 3 ...
 - attr(*, "na.action")=Class 'omit'  Named int [1:513] 2 3 4 9 10 11 13 16
17 18 ...
  .. ..- attr(*, "names")= chr [1:513] "2" "3" "4" "9" ...
>

And here is my session info:

> sessionInfo()
R version 3.3.3 (2017-03-06)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: OS X Yosemite 10.10.5

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_1.1-13      Matrix_1.2-8     pscl_1.4.9       lattice_0.20-34
[5] glmmADMB_0.8.3.3 MASS_7.3-45

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.10     magrittr_1.5     splines_3.3.3    devtools_1.12.0
 [5] munsell_0.4.3    colorspace_1.3-2 minqa_1.2.4      stringr_1.2.0
 [9] plyr_1.8.4       tools_3.3.3      grid_3.3.3       nlme_3.1-131
[13] gtable_0.2.0     coda_0.19-1      withr_1.0.2      digest_0.6.12
[17] lazyeval_0.2.0   tibble_1.3.0     R2admb_0.7.15    nloptr_1.0.4
[21] ggplot2_2.2.1    memoise_1.0.0    stringi_1.1.5    scales_0.4.1
>

I tried to use the following formula, with "Cut" as my outcome, and got
this lengthy error message:

> results <- glmmadmb(Cut ~ Time + Group + (1|Subject), data = x12,
zeroInflation = TRUE, family = "poisson")
matrix not pos definite in sparse choleski
Parameters were estimated, but standard errors were not: the most likely
problem is that the curvature at MLE was zero or negative
Error in glmmadmb(Cut ~ Time + Group + (1 | Subject), data = x12,
zeroInflation = TRUE,  :
  The function maximizer failed (couldn't find parameter file)
Troubleshooting steps include (1) run with 'save.dir' set and inspect
output files; (2) change run parameters: see '?admbControl';(3) re-run with
debug=TRUE for more information on failure mode
In addition: Warning message:
running command './glmmadmb -maxfn 500 -maxph 5 -noinit -shess' had status
42
matrix not pos definite in sparse choleski
matrix not pos definite in sparse choleski
matrix not pos definite in sparse choleski
matrix not pos definite in sparse choleski
matrix not pos definite in sparse choleski
matrix not pos definite in sparse choleski
matrix not pos definite in sparse choleski
matrix not pos definite in sparse choleski
matrix not pos definite in sparse choleski
matrix not pos definite in sparse choleski
matrix not pos definite in sparse choleski
matrix not pos definite in sparse choleski
matrix not pos definite in sparse choleski
matrix not pos definite in sparse choleski
matrix not pos definite in sparse choleski
matrix not pos definite in sparse choleski
matrix not pos definite in sparse choleski
matrix not pos definite in sparse choleski
matrix not pos definite in sparse choleski
matrix not pos definite in sparse choleski
Error: Invalid index 111 used for array range [0, 110] in "double&
dvector::operator[] (int i)".
invalid index for array

>

How can I go about fixing this error? Alternatively, is there another way
to run ZIP mixed models for count data? I had been successfully using the
lme4 package w/ lmer function to run linear mixed models for continuous
data, but I'm not sure whether this package can also handle zero-inflated
count data.

Thank you so much in advance for any help or advice you might be able to
provide!

Best,
Shirley

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Sat May 20 19:39:36 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 20 May 2017 13:39:36 -0400
Subject: [R-sig-ME] Warnings BootMer bootstrap glmer lme4
In-Reply-To: <363DE002-9EE0-4AF0-97CE-706F4623AB34@uvt.nl>
References: <363DE002-9EE0-4AF0-97CE-706F4623AB34@uvt.nl>
Message-ID: <aeb2b90d-33b6-ced9-4a2d-30dbde686657@gmail.com>



On 17-05-19 06:43 AM, D.J. Damen wrote:
> Dear all,
> 
> Currently, I am using the BootMer function to bootstrap my final
> model (fitted with GLMER from the lme4 package) to estimate the
> confidence intervals and p-values. Since I am alternating my
> reference categories, I have to bootstrap several models, and now the
> bootstrap of one model (below) returns with 50 or more warnings. Is
> there a standard procedure to follow when this happens? Should I
> trust the bootstrap when warnings pop up?
> 
> I am fitting a binomial model with the (centered and treatment coded)
> predictors c.con.tr (3 levels), c.type.tr (2 levels), and c.diff.tr
> (2 levels), and the dependent variable ?contrast? (1 = mentioned; 0 =
> not mentioned).
> 
> Details about the model I want to bootstrap, the bootstrap function
> and the warnings are presented below:
> 
> Model:
> 
> m0bcc <-glmer
> (contrast~c.con.tr*c.type.tr*c.diff.tr+(1+c.type.tr+c.diff.tr|id)+(1+c.con.tr+c.type.tr|item.new),
> data=mydata, family=binomial (link='logit'),
> control=glmerControl(optimizer="bobyqa"))

 This seems like a moderately complex model (2 4x4 variance-covariance
matrices); how big is your data set (total observations, number of id
levels, number of item.new levels)?  I wouldn't be surprised if you're
getting some singular fits.  On the other hand, the gradient warnings
are fairly small.

   Some suggestions:

 - (unrelated to your question) if you have small numbers of
observations *per* id (or item), you should consider using Gauss-Hermite
quadrature (e.g. nAGQ=10)
 - check to see whether the profile confidence intervals agree
reasonably well with the bootstrap CIs
 - you could use blme::bglmer to regularize your model to avoid
singularities
 - or try an alternative approach like brms to double-check

> 
> 
> Bootstrap function:
> 
> FUN <- function(fit) { return(fixef(fit)) }
> 
> boost <- function(mdl){ name <- match.call()$mdl boosted <-
> bootMer(mdl, FUN, nsim = 100) 
> save(boosted,file=paste(name,"_boosted",sep="")) }
> 
> p_boosted <- function(mdl,boosted){ for (n in 1:length(fixef(mdl))){ 
> print(fixef(mdl)[n]) (bMCI <- boot.ci(boosted, conf = c(0.95, 0.99,
> 0.999), index=n, type="norm")) print(bMCI) } }
> 
> Warnings: ( posted the first 10 warnings, in total there were 50 (or
> more?).
> 
> mdl <- m0bcc
>> boosted <- bootMer(mdl, FUN, nsim = 100)
> There were 50 or more warnings (use warnings() to see the first 50)
> 
> 1: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
> control$checkConv,  ... : unable to evaluate scaled gradient 2: In
> checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
> ... : Model failed to converge: degenerate  Hessian with 1 negative
> eigenvalues 3: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
> control$checkConv,  ... : unable to evaluate scaled gradient 4: In
> checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
> ... : Model failed to converge: degenerate  Hessian with 2 negative
> eigenvalues 5: In optwrap(object at optinfo$optimizer, ff, x0, lower =
> lower,  ... : convergence code 1 from bobyqa: bobyqa -- maximum
> number of function evaluations exceeded 6: In checkConv(attr(opt,
> "derivs"), opt$par, ctrl = control$checkConv,  ... : Model failed to
> converge with max|grad| = 0.00176467 (tol = 0.001, component 1) 7: In
> checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
> ... : unable to evaluate scaled gradient 8: In checkConv(attr(opt,
> "derivs"), opt$par, ctrl = control$checkConv,  ... : Model failed to
> converge: degenerate  Hessian with 1 negative eigenvalues 9: In
> optwrap(object at optinfo$optimizer, ff, x0, lower = lower,  ... : 
> convergence code 1 from bobyqa: bobyqa -- maximum number of function
> evaluations exceeded 10: In checkConv(attr(opt, "derivs"), opt$par,
> ctrl = control$checkConv,  ... : Model failed to converge with
> max|grad| = 0.00258682 (tol = 0.001, component 1) 11: In
> checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,
> ... :
> 
> 
> I couldn?t find whether I should decrease the random effects
> structure of my fitted model to decrease these bootstrap warnings,
> but since my fitted glmer model did converge, I am hesitant to do so
> anyway. I hope somebody is able to shed some light on this matter.
> 
> Thank you very much in advance.
> 
> Best, Debby
> 
> Debby Damen PhD Student
> 
> Department of Communication and Information Science
> 
> Tilburg University Warandelaan 2, room D410 5037 AB Tilburg
> 
> T. +31 13 466  8245 M. d.j.damen at uvt.nl<mailto:d.j.damen at uvt.nl>
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From simonesantoro77 at gmail.com  Sat May 20 23:11:29 2017
From: simonesantoro77 at gmail.com (simone santoro)
Date: Sat, 20 May 2017 23:11:29 +0200
Subject: [R-sig-ME] Help with glmmADMB and ZIP mixed effects models
In-Reply-To: <CAJxDRLd95QNa-tJe4xLrbg1fFUPM13PRgZ1eVrg_1MjUXmtsLg@mail.gmail.com>
References: <CAJxDRLd95QNa-tJe4xLrbg1fFUPM13PRgZ1eVrg_1MjUXmtsLg@mail.gmail.com>
Message-ID: <CAO_Dm+O2UTegONAgkZOsdD6AuoPOOXD0bwcbEi2pKGKA+mB+-Q@mail.gmail.com>

Dear Shirley,


I don?t know why you got the error message and there are many people out
there much more qualified than I am to give you a good answer. I will just
try to suggest something with the hope that you might find it useful.


When there is an error speaking about problems in the curvature I tend to
think of an overparameterized model and/or with a ?wrong? distribution. Do
you get the same error if you remove one covariate? Have you tried to use a
different distribution, like a negative binomial? For instance, a negative
binomial could work better, don't know but it is worth a try. You know, the
negative binomial has two parameters (one for mean and one for variance)
instead that one single parameter like in the Poisson that accounts both
for mean and variance and sometimes it fits better.


That said, I have been trying recently to use glmmadmb {package: glmmADMB}
and glmmTMB (package:glmmTMB} and I have found glmmtmb more flexible and
pretty faster than glmmadmb. More flexible because you have more choice in
terms of distributions (e.g. ?compois? for the Conway-Maxwell-Poisson) and
because you can ? this is for me the greatest advantage ? fit a model with
covariates (even with random effects) on the zero inflation. Sometimes I
have seen that if you have a covariate that is clearly related to the p of
getting a zero the fit of model improves very much. I would compare by AIC
the fit of different models with different distributions (e.g. negative
binomial, poisson, compois) and with and without zero inflation for
instance.


The syntax would be something like this (very similar to the syntax in
lme4):

Model1<- glmmTMB(Cut~Time+Group+(1|subject),data=x12,family=nbinom2,zi=~1)


If I remember well you do not need to eliminate the NA before.

Good luck,



Simone

2017-05-20 5:27 GMT+02:00 Wang, Shirley <shirleywang at g.harvard.edu>:

> Hello,
>
> I'm hoping to run a zero-inflated mixed effects poisson regression model
> for count data. My dataset includes 111 subjects, randomized to 3 groups
> and each assessed 7 times (777 observations). Through searching online, it
> seems like the glmmADMB package is my best bet. From my understanding, NA
> missing values should be removed prior to analysis -- this leaves me with
> 264 observations. I tried running glmmadmb() with zero inflation, poisson,
> and mixed effects specified; however, I'm running into some errors. This is
> my dataset:
>
> > str(x12)
> 'data.frame': 264 obs. of  12 variables:
>  $ Subject   : Factor w/ 111 levels "1","2","3","4",..: 1 1 1 1 2 2 2 3 4 4
> ...
>  $ Time      : int  1 5 6 7 1 5 7 1 1 6 ...
>  $ Group     : Factor w/ 3 levels "1","2","3": 1 1 1 1 1 1 1 1 1 1 ...
>  $ SRS       : int  56 55 56 55 50 46 42 49 47 42 ...
>  $ BDI       : int  40 23 41 35 44 14 11 22 16 9 ...
>  $ ERQ       : int  14 11 14 15 18 12 15 14 26 27 ...
>  $ Cut       : int  3 4 10 15 1 1 0 1 0 0 ...
>  $ NSSI      : int  8 14 32 58 2 2 8 2 0 1 ...
>  $ Ideation  : int  2 0 5 10 5 3 0 1 0 0 ...
>  $ Plan      : int  1 0 2 8 1 4 5 0 0 0 ...
>  $ Stop      : int  2 2 1 2 3 3 3 2 3 2 ...
>  $ Likelihood: int  4 4 4 4 3 4 4 4 3 3 ...
>  - attr(*, "na.action")=Class 'omit'  Named int [1:513] 2 3 4 9 10 11 13 16
> 17 18 ...
>   .. ..- attr(*, "names")= chr [1:513] "2" "3" "4" "9" ...
> >
>
> And here is my session info:
>
> > sessionInfo()
> R version 3.3.3 (2017-03-06)
> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> Running under: OS X Yosemite 10.10.5
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] lme4_1.1-13      Matrix_1.2-8     pscl_1.4.9       lattice_0.20-34
> [5] glmmADMB_0.8.3.3 MASS_7.3-45
>
> loaded via a namespace (and not attached):
>  [1] Rcpp_0.12.10     magrittr_1.5     splines_3.3.3    devtools_1.12.0
>  [5] munsell_0.4.3    colorspace_1.3-2 minqa_1.2.4      stringr_1.2.0
>  [9] plyr_1.8.4       tools_3.3.3      grid_3.3.3       nlme_3.1-131
> [13] gtable_0.2.0     coda_0.19-1      withr_1.0.2      digest_0.6.12
> [17] lazyeval_0.2.0   tibble_1.3.0     R2admb_0.7.15    nloptr_1.0.4
> [21] ggplot2_2.2.1    memoise_1.0.0    stringi_1.1.5    scales_0.4.1
> >
>
> I tried to use the following formula, with "Cut" as my outcome, and got
> this lengthy error message:
>
> > results <- glmmadmb(Cut ~ Time + Group + (1|Subject), data = x12,
> zeroInflation = TRUE, family = "poisson")
> matrix not pos definite in sparse choleski
> Parameters were estimated, but standard errors were not: the most likely
> problem is that the curvature at MLE was zero or negative
> Error in glmmadmb(Cut ~ Time + Group + (1 | Subject), data = x12,
> zeroInflation = TRUE,  :
>   The function maximizer failed (couldn't find parameter file)
> Troubleshooting steps include (1) run with 'save.dir' set and inspect
> output files; (2) change run parameters: see '?admbControl';(3) re-run with
> debug=TRUE for more information on failure mode
> In addition: Warning message:
> running command './glmmadmb -maxfn 500 -maxph 5 -noinit -shess' had status
> 42
> matrix not pos definite in sparse choleski
> matrix not pos definite in sparse choleski
> matrix not pos definite in sparse choleski
> matrix not pos definite in sparse choleski
> matrix not pos definite in sparse choleski
> matrix not pos definite in sparse choleski
> matrix not pos definite in sparse choleski
> matrix not pos definite in sparse choleski
> matrix not pos definite in sparse choleski
> matrix not pos definite in sparse choleski
> matrix not pos definite in sparse choleski
> matrix not pos definite in sparse choleski
> matrix not pos definite in sparse choleski
> matrix not pos definite in sparse choleski
> matrix not pos definite in sparse choleski
> matrix not pos definite in sparse choleski
> matrix not pos definite in sparse choleski
> matrix not pos definite in sparse choleski
> matrix not pos definite in sparse choleski
> matrix not pos definite in sparse choleski
> Error: Invalid index 111 used for array range [0, 110] in "double&
> dvector::operator[] (int i)".
> invalid index for array
>
> >
>
> How can I go about fixing this error? Alternatively, is there another way
> to run ZIP mixed models for count data? I had been successfully using the
> lme4 package w/ lmer function to run linear mixed models for continuous
> data, but I'm not sure whether this package can also handle zero-inflated
> count data.
>
> Thank you so much in advance for any help or advice you might be able to
> provide!
>
> Best,
> Shirley
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Sun May 21 02:12:34 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 20 May 2017 20:12:34 -0400
Subject: [R-sig-ME] Help with glmmADMB and ZIP mixed effects models
In-Reply-To: <CAJxDRLd95QNa-tJe4xLrbg1fFUPM13PRgZ1eVrg_1MjUXmtsLg@mail.gmail.com>
References: <CAJxDRLd95QNa-tJe4xLrbg1fFUPM13PRgZ1eVrg_1MjUXmtsLg@mail.gmail.com>
Message-ID: <dad50d2c-bd94-ad63-372b-dc32b620916d@gmail.com>



On 17-05-19 11:27 PM, Wang, Shirley wrote:
> Hello,
> 
> I'm hoping to run a zero-inflated mixed effects poisson regression model
> for count data. My dataset includes 111 subjects, randomized to 3 groups
> and each assessed 7 times (777 observations). Through searching online, it
> seems like the glmmADMB package is my best bet. From my understanding, NA
> missing values should be removed prior to analysis -- this leaves me with
> 264 observations. I tried running glmmadmb() with zero inflation, poisson,
> and mixed effects specified; however, I'm running into some errors. This is
> my dataset:
> 
>> str(x12)
> 'data.frame': 264 obs. of  12 variables:
>  $ Subject   : Factor w/ 111 levels "1","2","3","4",..: 1 1 1 1 2 2 2 3 4 4
> ...
>  $ Time      : int  1 5 6 7 1 5 7 1 1 6 ...
>  $ Group     : Factor w/ 3 levels "1","2","3": 1 1 1 1 1 1 1 1 1 1 ...
>  $ SRS       : int  56 55 56 55 50 46 42 49 47 42 ...
>  $ BDI       : int  40 23 41 35 44 14 11 22 16 9 ...
>  $ ERQ       : int  14 11 14 15 18 12 15 14 26 27 ...
>  $ Cut       : int  3 4 10 15 1 1 0 1 0 0 ...
>  $ NSSI      : int  8 14 32 58 2 2 8 2 0 1 ...
>  $ Ideation  : int  2 0 5 10 5 3 0 1 0 0 ...
>  $ Plan      : int  1 0 2 8 1 4 5 0 0 0 ...
>  $ Stop      : int  2 2 1 2 3 3 3 2 3 2 ...
>  $ Likelihood: int  4 4 4 4 3 4 4 4 3 3 ...
>  - attr(*, "na.action")=Class 'omit'  Named int [1:513] 2 3 4 9 10 11 13 16
> 17 18 ...
>   .. ..- attr(*, "names")= chr [1:513] "2" "3" "4" "9" ...
>>
> 

The error is somewhat interesting, if you can send your data I'd take a
look.  However, more generally troubleshooting glmmADMB problems is a
bit of a nuisance.  I would recommend trying the newer glmmTMB or brms
packages (both on CRAN; the latter is effectively a drop-in replacement
for glmmADMB, brms is a Bayesian MCMC engine built on the Stan engine).



> And here is my session info:
> 
>> sessionInfo()
> R version 3.3.3 (2017-03-06)
> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> Running under: OS X Yosemite 10.10.5
> 
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] lme4_1.1-13      Matrix_1.2-8     pscl_1.4.9       lattice_0.20-34
> [5] glmmADMB_0.8.3.3 MASS_7.3-45
> 
> loaded via a namespace (and not attached):
>  [1] Rcpp_0.12.10     magrittr_1.5     splines_3.3.3    devtools_1.12.0
>  [5] munsell_0.4.3    colorspace_1.3-2 minqa_1.2.4      stringr_1.2.0
>  [9] plyr_1.8.4       tools_3.3.3      grid_3.3.3       nlme_3.1-131
> [13] gtable_0.2.0     coda_0.19-1      withr_1.0.2      digest_0.6.12
> [17] lazyeval_0.2.0   tibble_1.3.0     R2admb_0.7.15    nloptr_1.0.4
> [21] ggplot2_2.2.1    memoise_1.0.0    stringi_1.1.5    scales_0.4.1
>>
> 
> I tried to use the following formula, with "Cut" as my outcome, and got
> this lengthy error message:
> 
>> results <- glmmadmb(Cut ~ Time + Group + (1|Subject), data = x12,
> zeroInflation = TRUE, family = "poisson")
> matrix not pos definite in sparse choleski
> Parameters were estimated, but standard errors were not: the most likely
> problem is that the curvature at MLE was zero or negative
> Error in glmmadmb(Cut ~ Time + Group + (1 | Subject), data = x12,
> zeroInflation = TRUE,  :
>   The function maximizer failed (couldn't find parameter file)
> Troubleshooting steps include (1) run with 'save.dir' set and inspect
> output files; (2) change run parameters: see '?admbControl';(3) re-run with
> debug=TRUE for more information on failure mode
> In addition: Warning message:
> running command './glmmadmb -maxfn 500 -maxph 5 -noinit -shess' had status
> 42
> matrix not pos definite in sparse choleski
> matrix not pos definite in sparse choleski
> matrix not pos definite in sparse choleski
> matrix not pos definite in sparse choleski
> matrix not pos definite in sparse choleski
> matrix not pos definite in sparse choleski
> matrix not pos definite in sparse choleski
> matrix not pos definite in sparse choleski
> matrix not pos definite in sparse choleski
> matrix not pos definite in sparse choleski
> matrix not pos definite in sparse choleski
> matrix not pos definite in sparse choleski
> matrix not pos definite in sparse choleski
> matrix not pos definite in sparse choleski
> matrix not pos definite in sparse choleski
> matrix not pos definite in sparse choleski
> matrix not pos definite in sparse choleski
> matrix not pos definite in sparse choleski
> matrix not pos definite in sparse choleski
> matrix not pos definite in sparse choleski
> Error: Invalid index 111 used for array range [0, 110] in "double&
> dvector::operator[] (int i)".
> invalid index for array
> 
>>
> 
> How can I go about fixing this error? Alternatively, is there another way
> to run ZIP mixed models for count data? I had been successfully using the
> lme4 package w/ lmer function to run linear mixed models for continuous
> data, but I'm not sure whether this package can also handle zero-inflated
> count data.
> 
> Thank you so much in advance for any help or advice you might be able to
> provide!
> 
> Best,
> Shirley
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From bbolker at gmail.com  Wed May 24 03:34:12 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 23 May 2017 21:34:12 -0400
Subject: [R-sig-ME] Suggestion for Model convergence
 problem:non-positive-definite Hessian matrix.
In-Reply-To: <CY1PR0401MB1164B1DED5C0C71347A3E592CDF80@CY1PR0401MB1164.namprd04.prod.outlook.com>
References: <CY1PR0401MB1164B1DED5C0C71347A3E592CDF80@CY1PR0401MB1164.namprd04.prod.outlook.com>
Message-ID: <01e96f8f-5bde-12b0-ab63-2a5829934c0f@mcmaster.ca>


 [cc'ing r-sig-mixed-models at r-project.org]

 Without a repeatable example this is hard.  The only general advice I
can give is:

 - try centering and scaling any continuous predictors
 - you can probably extract some information about the fit (via
VarCorr(), fixef(), etc.) even though the model may not have converged
properly, but it will be hard to trust it
 - visualize your data (look for outlier individual observations or groups)
 - do you have combinations of predictor variables (especially
combinations of fixed effects) that lead to all-zero values?
 - if necessary, try simplifying the model


On 17-05-22 12:17 PM, Zohora Sultana (zsultana) wrote:
> Hi Dr. Bolker,
> 
> 
> My data set contains large amount of zeros and total number of
> observations is 52172. I am trying to run zero inflated negative
> binomial random parameter model by glmmTMB. But I am getting the
> following error: 
> 
> /Model convergence problem; non-positive-definite Hessian matrix./
> 
> /
> /
> 
> Can you please give suggestions  how can I solve this problem? 
> 
> Thanks,
> 
> Zohora
>


From ecp52 at cornell.edu  Thu May 25 15:04:52 2017
From: ecp52 at cornell.edu (Evan Palmer-Young)
Date: Thu, 25 May 2017 09:04:52 -0400
Subject: [R-sig-ME] wider than expected confidence intervals with lsmeans
	and predict.glmmadmb
Message-ID: <CAAge6+4pBdPb+K+UcVQA0gQcGPuO_NibyynAAtoUSAsb_H4PYQ@mail.gmail.com>

Dear List,

I am trying to use lsmeans to get confidence intervals for different levels
of treatment.

I was surprised to find that even when a fixed effect in my model was
highly significant, the confidence intervals on the lsmeans plot overlapped
almost completely. I reproduced this behavior with the "Owls" dataset. The
lsmeans() function and the predict.glmmadmb() function both gave the same
result, so there do not appear to be any surprises due to lsmeans.

I would be grateful if anybody could explain the reason for the large
confidence bands despite the significant fixed effect.


?Here is a short reproducible example-- thanks very much for any insight!

library(glmmADMB)

library(lsmeans)

#Use data from Bolker et al worked example
#http://glmmadmb.r-forge.r-project.org/glmmADMB.html

data(Owls)
str(Owls)
Owls <- transform(Owls,
                  Nest=reorder(Nest,NegPerChick),
                  logBroodSize=log(BroodSize),
                  NCalls=SiblingNegotiation)


m.nb<- glmmadmb(NCalls~FoodTreatment+ArrivalTime+
           +(1|Nest),
         data=Owls,
         zeroInflation=TRUE,
         family="nbinom")
summary(m.nb)
# Estimate Std. Error z value Pr(>|z|)
# (Intercept)             4.2674     0.4705    9.07  < 2e-16 ***
#  * FoodTreatmentSatiated  -0.2602     0.0845   -3.08   0.0021 ** *
#   ArrivalTime            -0.0840     0.0190   -4.42  9.8e-06 ***
#Plot lsmeans by FoodTreatment
owls.lsm<-lsmeans(m.nb, ~FoodTreatment)
owls.lsm
# FoodTreatment   lsmean        SE df asymp.LCL asymp.UCL
# Deprived      2.188727 0.7205142 NA 0.7765454  3.600909
# Satiated      1.928499 0.7498151 NA 0.4588887  3.398110
#SE is much higher than for fixed effects in model

plot(owls.lsm)
 #95% confidence bands overlap almost entirely

#Confirm with predict.glmmadmb:
New.data<-expand.grid(FoodTreatment= levels(Owls$FoodTreatment),
                      ArrivalTime = mean(Owls$ArrivalTime))

New.data$NCalls <- predict(m.nb, New.data, re.form=NA, SE.fit = TRUE)

#Get standard errors:
calls.pred<- predict(m.nb, New.data, re.form = NA, se.fit = TRUE)
calls.pred<-data.frame(calls.pred)

New.data$SE<-calls.pred$se.fit
New.data
# FoodTreatment ArrivalTime   NCalls        SE
# 1      Deprived    24.75763 2.188727 0.7205142
# 2      Satiated    24.75763 1.928499 0.7498151
#Matches with lsmeans output
?


-- 
Evan Palmer-Young
PhD candidate
Department of Biology
221 Morrill Science Center
611 North Pleasant St
Amherst MA 01003
https://scholar.google.com/citations?user=VGvOypoAAAAJ&hl=en
https://sites.google.com/a/cornell.edu/evan-palmer-young/
epalmery at cns.umass.edu
ecp52 at cornell.edu

	[[alternative HTML version deleted]]


From john.maindonald at anu.edu.au  Thu May 25 23:22:09 2017
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Thu, 25 May 2017 21:22:09 +0000
Subject: [R-sig-ME] wider than expected confidence intervals with
 lsmeans and predict.glmmadmb
In-Reply-To: <CAAge6+4pBdPb+K+UcVQA0gQcGPuO_NibyynAAtoUSAsb_H4PYQ@mail.gmail.com>
References: <CAAge6+4pBdPb+K+UcVQA0gQcGPuO_NibyynAAtoUSAsb_H4PYQ@mail.gmail.com>
Message-ID: <588DF65B-360A-4AB7-8567-479820D19299@anu.edu.au>

The confidence intervals that you have obtained are for the levels
of `FoodTreatment`, not for the contrast `Satiated-Deprived`.


Try, the following, which also gives a confidence interval for the
difference from the initial level of `FoodTreatment`:

> library(glmmADMB)
> library(lsmeans)
> Owls <- transform(Owls,
               Nest=reorder(Nest,NegPerChick),
                logBroodSize=log(BroodSize),
               NCalls=SiblingNegotiation)
> m.nb<- glmmadmb(NCalls~FoodTreatment+ArrivalTime+(1|Nest),
        data=Owls,
        zeroInflation=TRUE,
       family="nbinom?)
> owls.lsm<-lsmeans(m.nb, ~FoodTreatment)
> lsmeans (owls.lsm, "FoodTreatment", contr = "trt.vs.ctrl")
$lsmeans
. . .

$contrasts
 contrast             estimate       SE df z.ratio p.value
 Satiated - Deprived -0.260228 0.084501 NA   -3.08  0.0021


John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>.


On 26/05/2017, at 01:04, Evan Palmer-Young <ecp52 at cornell.edu<mailto:ecp52 at cornell.edu>> wrote:

Dear List,

I am trying to use lsmeans to get confidence intervals for different levels
of treatment.

I was surprised to find that even when a fixed effect in my model was
highly significant, the confidence intervals on the lsmeans plot overlapped
almost completely. I reproduced this behavior with the "Owls" dataset. The
lsmeans() function and the predict.glmmadmb() function both gave the same
result, so there do not appear to be any surprises due to lsmeans.

I would be grateful if anybody could explain the reason for the large
confidence bands despite the significant fixed effect.


?Here is a short reproducible example-- thanks very much for any insight!

library(glmmADMB)

library(lsmeans)

#Use data from Bolker et al worked example
#http://glmmadmb.r-forge.r-project.org/glmmADMB.html

data(Owls)
str(Owls)
Owls <- transform(Owls,
                 Nest=reorder(Nest,NegPerChick),
                 logBroodSize=log(BroodSize),
                 NCalls=SiblingNegotiation)


m.nb<- glmmadmb(NCalls~FoodTreatment+ArrivalTime+
          +(1|Nest),
        data=Owls,
        zeroInflation=TRUE,
        family="nbinom")
summary(m.nb)
# Estimate Std. Error z value Pr(>|z|)
# (Intercept)             4.2674     0.4705    9.07  < 2e-16 ***
#  * FoodTreatmentSatiated  -0.2602     0.0845   -3.08   0.0021 ** *
#   ArrivalTime            -0.0840     0.0190   -4.42  9.8e-06 ***
#Plot lsmeans by FoodTreatment
owls.lsm<-lsmeans(m.nb, ~FoodTreatment)
owls.lsm
# FoodTreatment   lsmean        SE df asymp.LCL asymp.UCL
# Deprived      2.188727 0.7205142 NA 0.7765454  3.600909
# Satiated      1.928499 0.7498151 NA 0.4588887  3.398110
#SE is much higher than for fixed effects in model

plot(owls.lsm)
#95% confidence bands overlap almost entirely

#Confirm with predict.glmmadmb:
New.data<-expand.grid(FoodTreatment= levels(Owls$FoodTreatment),
                     ArrivalTime = mean(Owls$ArrivalTime))

New.data$NCalls <- predict(m.nb, New.data, re.form=NA, SE.fit = TRUE)

#Get standard errors:
calls.pred<- predict(m.nb, New.data, re.form = NA, se.fit = TRUE)
calls.pred<-data.frame(calls.pred)

New.data$SE<-calls.pred$se.fit
New.data
# FoodTreatment ArrivalTime   NCalls        SE
# 1      Deprived    24.75763 2.188727 0.7205142
# 2      Satiated    24.75763 1.928499 0.7498151
#Matches with lsmeans output
?


--
Evan Palmer-Young
PhD candidate
Department of Biology
221 Morrill Science Center
611 North Pleasant St
Amherst MA 01003
https://scholar.google.com/citations?user=VGvOypoAAAAJ&hl=en
https://sites.google.com/a/cornell.edu/evan-palmer-young/
epalmery at cns.umass.edu
ecp52 at cornell.edu

[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From ecp52 at cornell.edu  Fri May 26 23:29:52 2017
From: ecp52 at cornell.edu (Evan Palmer-Young)
Date: Fri, 26 May 2017 17:29:52 -0400
Subject: [R-sig-ME] wider than expected confidence intervals with
 lsmeans and predict.glmmadmb
In-Reply-To: <588DF65B-360A-4AB7-8567-479820D19299@anu.edu.au>
References: <CAAge6+4pBdPb+K+UcVQA0gQcGPuO_NibyynAAtoUSAsb_H4PYQ@mail.gmail.com>
 <588DF65B-360A-4AB7-8567-479820D19299@anu.edu.au>
Message-ID: <CAAge6+7v1KY=8GLNqi1Hzg4zyQY0kfSjGvMXM-rhRFC9ER8Kcw@mail.gmail.com>

Thanks very much for your reply, Prof. Maindonald.

I agree that the pairwise comparisons are informative, but it would be
easiest for readers to see the data on the original scale to show
differences between groups.

When the lsmeans are plotted from glmmTMB, which fits a model with fixed
effects identical to those in glmmADMB, the estimates are identical but the
SE's differ by a factor of 8.

So I am still confused about why the lsmeans plots would reflect pairwise
differences with some packages but not with glmmADMB.
In my experience, lsmeans plots of group means from glmer() models are also
non-overlapping when pairwise comparisons are highly significant.

I have extended the code to illustrate the differences.

library(glmmADMB)

library(lsmeans)

#Use data from worked example
#http://glmmadmb.r-forge.r-project.org/glmmADMB.html

library(glmmADMB)
data(Owls)
str(Owls)
Owls <- transform(Owls,
                  Nest=reorder(Nest,NegPerChick),
                  logBroodSize=log(BroodSize),
                  NCalls=SiblingNegotiation)


m.nb<- glmmadmb(NCalls~FoodTreatment+ArrivalTime+
           +(1|Nest),
         data=Owls,
         zeroInflation=FALSE,
         family="nbinom")
summary(m.nb)
# Estimate Std. Error z value Pr(>|z|)
# (Intercept)             4.2674     0.4705    9.07  < 2e-16 ***
#   FoodTreatmentSatiated  -0.2602     0.0845   -3.08   0.0021 **
#   ArrivalTime            -0.0840     0.0190   -4.42  9.8e-06 ***
#Plot lsmeans by FoodTreatment
owls.lsm<-lsmeans(m.nb, ~FoodTreatment)
owls.lsm
# FoodTreatment   lsmean        SE df asymp.LCL asymp.UCL
# Deprived      2.188727 0.7205142 NA 0.7765454  3.600909
# Satiated      1.928499 0.7498151 NA 0.4588887  3.398110
#SE is much higher than for fixed effects in model

plot(owls.lsm)
 #95% confidence bands overlap almost entirely

#Confirm with predict.glmmadmb:
New.data<-expand.grid(FoodTreatment= levels(Owls$FoodTreatment),
                      ArrivalTime = mean(Owls$ArrivalTime))

New.data$NCalls <- predict(m.nb, New.data, re.form=NA, SE.fit = TRUE)

#Get standard errors:
calls.pred<- predict(m.nb, New.data, re.form = NA, se.fit = TRUE)
calls.pred<-data.frame(calls.pred)

New.data$SE<-calls.pred$se.fit
New.data
# FoodTreatment ArrivalTime   NCalls        SE
# 1      Deprived    24.75763 2.188727 0.7205142
# 2      Satiated    24.75763 1.928499 0.7498151
#Matches with lsmeans output



##################  Compare to glmmTDMB  ####################
#install.packages("glmmTMB")
library(glmmTMB)
m.nb2<- glmmTMB(NCalls~FoodTreatment+ArrivalTime+
                  +(1|Nest),
                data=Owls,
                family="nbinom2")
summary(m.nb2)
# Estimate Std. Error z value Pr(>|z|)
# (Intercept)            4.91011    0.63343   7.752 9.07e-15 ***
#   FoodTreatmentSatiated -0.69238    0.10692  -6.476 9.44e-11 ***
#   ArrivalTime           -0.11540    0.02526  -4.569 4.90e-06 ***

#Compare to glmmADMB model:Fixed effects are identical
summary(m.nb)
# Estimate Std. Error z value Pr(>|z|)
# (Intercept)             4.9101     0.6334    7.75  9.1e-15 ***
#   FoodTreatmentSatiated  -0.6924     0.1069   -6.48  9.4e-11 ***
#   ArrivalTime            -0.1154     0.0253   -4.57  4.9e-06 ***

#Plot lsmeans by FoodTreatment
owls.lsm<-lsmeans(m.nb2, ~FoodTreatment)
#oops, lsmeans can't use glmmTMB object!

  ########   Interlude   #######
#Ben Bolker wrote a function to talk to lsmeans-- incredible!
# https://github.com/glmmTMB/glmmTMB/issues/205
recover.data.glmmTMB <- function(object, ...) {
  fcall <- getCall(object)
  recover.data(fcall,delete.response(terms(object)),
               attr(model.frame(object),"na.action"), ...)
}
lsm.basis.glmmTMB <- function (object, trms, xlev, grid, vcov.,
                               mode = "asymptotic", component="cond", ...) {
  if (mode != "asymptotic") stop("only asymptotic mode is available")
  if (component != "cond") stop("only tested for conditional component")
  if (missing(vcov.))
    V <- as.matrix(vcov(object)[[component]])
  else V <- as.matrix(.my.vcov(object, vcov.))
  dfargs = misc = list()
  if (mode == "asymptotic") {
    dffun = function(k, dfargs) NA
  }
  ## use this? misc = .std.link.labels(family(object), misc)
  contrasts = attr(model.matrix(object), "contrasts")
  m = model.frame(trms, grid, na.action = na.pass, xlev = xlev)
  X = model.matrix(trms, m, contrasts.arg = contrasts)
  bhat = fixef(object)[[component]]
  if (length(bhat) < ncol(X)) {
    kept = match(names(bhat), dimnames(X)[[2]])
    bhat = NA * X[1, ]
    bhat[kept] = fixef(object)[[component]]
    modmat = model.matrix(trms, model.frame(object), contrasts.arg =
contrasts)
    nbasis = estimability::nonest.basis(modmat)
  }
  else nbasis = estimability::all.estble
  list(X = X, bhat = bhat, nbasis = nbasis, V = V, dffun = dffun,
       dfargs = dfargs, misc = misc)
}

#####   End interlude ###

lsm.TMB<- lsmeans(m.nb2, ~FoodTreatment)
plot(lsm.TMB)  #non-overlapping CI's

#Compare SE's
owls.lsm
# FoodTreatment   lsmean       * SE* df  asymp.LCL asymp.UCL
# Deprived      2.053073 *0.8952071* NA  0.2984988  3.807646
# Satiated      1.360690 *0.9037320 *NA -0.4105918  3.131973

lsm.TMB
# FoodTreatment   lsmean        *SE* df asymp.LCL asymp.UCL
# Deprived      2.053065 *0.1068562* NA  1.843631  2.262500
# Satiated      1.360683 *0.1161322* NA  1.133068  1.588298

#lsmeans are identical but SE's differ by factor of 8?!


Thank you again.
Evan




On Thu, May 25, 2017 at 5:22 PM, John Maindonald <john.maindonald at anu.edu.au
> wrote:

> The confidence intervals that you have obtained are for the levels
> of `FoodTreatment`, not for the contrast `Satiated-Deprived`.
>
>
> Try, the following, which also gives a confidence interval for the
> difference from the initial level of `FoodTreatment`:
>
> > library(glmmADMB)
> > library(lsmeans)
> > Owls <- transform(Owls,
>                Nest=reorder(Nest,NegPerChick),
>                 logBroodSize=log(BroodSize),
>                NCalls=SiblingNegotiation)
> > m.nb<- glmmadmb(NCalls~FoodTreatment+ArrivalTime+(1|Nest),
>         data=Owls,
>         zeroInflation=TRUE,
>        family="nbinom?)
> > owls.lsm<-lsmeans(m.nb, ~FoodTreatment)
> > lsmeans (owls.lsm, "FoodTreatment", contr = "trt.vs.ctrl")
> $lsmeans
> . . .
>
> $contrasts
>  contrast             estimate       SE df z.ratio p.value
>  Satiated - Deprived -0.260228 0.084501 NA   -3.08  0.0021
>
> John Maindonald             email: john.maindonald at anu.edu.au.
>
>
> On 26/05/2017, at 01:04, Evan Palmer-Young <ecp52 at cornell.edu> wrote:
>
> Dear List,
>
> I am trying to use lsmeans to get confidence intervals for different levels
> of treatment.
>
> I was surprised to find that even when a fixed effect in my model was
> highly significant, the confidence intervals on the lsmeans plot overlapped
> almost completely. I reproduced this behavior with the "Owls" dataset. The
> lsmeans() function and the predict.glmmadmb() function both gave the same
> result, so there do not appear to be any surprises due to lsmeans.
>
> I would be grateful if anybody could explain the reason for the large
> confidence bands despite the significant fixed effect.
>
>
> ?Here is a short reproducible example-- thanks very much for any insight!
>
> library(glmmADMB)
>
> library(lsmeans)
>
> #Use data from Bolker et al worked example
> #http://glmmadmb.r-forge.r-project.org/glmmADMB.html
>
> data(Owls)
> str(Owls)
> Owls <- transform(Owls,
>                  Nest=reorder(Nest,NegPerChick),
>                  logBroodSize=log(BroodSize),
>                  NCalls=SiblingNegotiation)
>
>
> m.nb<- glmmadmb(NCalls~FoodTreatment+ArrivalTime+
>           +(1|Nest),
>         data=Owls,
>         zeroInflation=TRUE,
>         family="nbinom")
> summary(m.nb)
> # Estimate Std. Error z value Pr(>|z|)
> # (Intercept)             4.2674     0.4705    9.07  < 2e-16 ***
> #  * FoodTreatmentSatiated  -0.2602     0.0845   -3.08   0.0021 ** *
>
> #   ArrivalTime            -0.0840     0.0190   -4.42  9.8e-06 ***
> #Plot lsmeans by FoodTreatment
> owls.lsm<-lsmeans(m.nb, ~FoodTreatment)
> owls.lsm
> # FoodTreatment   lsmean        SE df asymp.LCL asymp.UCL
> # Deprived      2.188727 0.7205142 NA 0.7765454  3.600909
> # Satiated      1.928499 0.7498151 NA 0.4588887  3.398110
> #SE is much higher than for fixed effects in model
>
> plot(owls.lsm)
> #95% confidence bands overlap almost entirely
>
> #Confirm with predict.glmmadmb:
> New.data<-expand.grid(FoodTreatment= levels(Owls$FoodTreatment),
>                      ArrivalTime = mean(Owls$ArrivalTime))
>
> New.data$NCalls <- predict(m.nb, New.data, re.form=NA, SE.fit = TRUE)
>
> #Get standard errors:
> calls.pred<- predict(m.nb, New.data, re.form = NA, se.fit = TRUE)
> calls.pred<-data.frame(calls.pred)
>
> New.data$SE<-calls.pred$se.fit
> New.data
> # FoodTreatment ArrivalTime   NCalls        SE
> # 1      Deprived    24.75763 2.188727 0.7205142
> # 2      Satiated    24.75763 1.928499 0.7498151
> #Matches with lsmeans output
> ?
>
>
> --
> Evan Palmer-Young
> PhD candidate
> Department of Biology
> 221 Morrill Science Center
> 611 North Pleasant St
> Amherst MA 01003
> https://scholar.google.com/citations?user=VGvOypoAAAAJ&hl=en
> https://sites.google.com/a/cornell.edu/evan-palmer-young/
> epalmery at cns.umass.edu
> ecp52 at cornell.edu
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>


-- 
Evan Palmer-Young
PhD candidate
Department of Biology
221 Morrill Science Center
611 North Pleasant St
Amherst MA 01003
https://scholar.google.com/citations?user=VGvOypoAAAAJ&hl=en
https://sites.google.com/a/cornell.edu/evan-palmer-young/
epalmery at cns.umass.edu
ecp52 at cornell.edu

	[[alternative HTML version deleted]]


From john.maindonald at anu.edu.au  Sat May 27 03:02:23 2017
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Sat, 27 May 2017 01:02:23 +0000
Subject: [R-sig-ME] wider than expected confidence intervals with
 lsmeans and predict.glmmadmb
In-Reply-To: <CAAge6+7v1KY=8GLNqi1Hzg4zyQY0kfSjGvMXM-rhRFC9ER8Kcw@mail.gmail.com>
References: <CAAge6+4pBdPb+K+UcVQA0gQcGPuO_NibyynAAtoUSAsb_H4PYQ@mail.gmail.com>
 <588DF65B-360A-4AB7-8567-479820D19299@anu.edu.au>
 <CAAge6+7v1KY=8GLNqi1Hzg4zyQY0kfSjGvMXM-rhRFC9ER8Kcw@mail.gmail.com>
Message-ID: <C8CD6EEF-AC7E-4189-9F92-AFE041B3E44C@anu.edu.au>

The models m.nb2 (from fitting using glmmTMB()) and m.nb (from glmmadmb())
return coefficient and SE information that is for all practical purposes identical

> m.nb2$call
glmmTMB(formula = NCalls ~ FoodTreatment + ArrivalTime + +(1 |
    Nest), data = Owls, family = "nbinom2", ziformula = ~0, dispformula = ~1)
> print(coef(summary(m.nb2)), digits=2)
$cond
                      Estimate Std. Error z value Pr(>|z|)
(Intercept)               4.91      0.633     7.8  9.1e-15
FoodTreatmentSatiated    -0.69      0.107    -6.5  9.4e-11
ArrivalTime              -0.12      0.025    -4.6  4.9e-06

> m.nb$call
glmmadmb(formula = NCalls ~ FoodTreatment + ArrivalTime + +(1 |
    Nest), data = Owls, family = "nbinom", zeroInflation = FALSE)
> print(coef(summary(m.nb)), digits=2)
                      Estimate Std. Error z value Pr(>|z|)
(Intercept)               4.91      0.633     7.8  9.1e-15
FoodTreatmentSatiated    -0.69      0.107    -6.5  9.4e-11
ArrivalTime              -0.12      0.025    -4.6  4.9e-06

The differences between the two graphs are then a conseqence of
what is done on the way to creating those graphs.  For comparing
levels of `FoodTreatment`, the SE is for the in each case for the
difference, not for the levels individually.  It is then information that it
would be helpful to add to the graph given by:

owls.lsm<-lsmeans(m.nb, ~FoodTreatment)
plot(owls.lsm)

One can get a plot that shows the SE for the difference thus:

K <- diag(length(coef(m.nb)))[1:2,]
rownames(K) <- c("Deprived","Sat-Dep?)
library(multcomp)
plot(glht(m.nb,linfct=K))

Or, nearer to what you want, maybe:

K2 <- rbind(K[1,], c(1,1,0), K[2,])
rownames(K2) <- c("Deprived","Saturated", "Sat-Dep")
plot(glht(m.nb,linfct=K2))

It is, of course, in this simple case, possible to place intervals
around the two estimates, designed so that if the intervals do
not overlap, then the difference is not ?significant? at alpha=0.05.

I will leave it to you, or to others, to check just what the code you
give, that uses as its starting-point output from glmmTMB(), may be
doing.  This is not a straightforward use of lsmeans().


John Maindonald             email: john.maindonald at anu.edu.a<mailto:john.maindonald at anu.edu.a>

On 27/05/2017, at 09:29, Evan Palmer-Young <ecp52 at cornell.edu<mailto:ecp52 at cornell.edu>> wrote:

Thanks very much for your reply, Prof. Maindonald.

I agree that the pairwise comparisons are informative, but it would be easiest for readers to see the data on the original scale to show differences between groups.

When the lsmeans are plotted from glmmTMB, which fits a model with fixed effects identical to those in glmmADMB, the estimates are identical but the SE's differ by a factor of 8.

So I am still confused about why the lsmeans plots would reflect pairwise differences with some packages but not with glmmADMB.
In my experience, lsmeans plots of group means from glmer() models are also non-overlapping when pairwise comparisons are highly significant.

I have extended the code to illustrate the differences.

library(glmmADMB)

library(lsmeans)

#Use data from worked example
#http://glmmadmb.r-forge.r-project.org/glmmADMB.html

library(glmmADMB)
data(Owls)
str(Owls)
Owls <- transform(Owls,
                  Nest=reorder(Nest,NegPerChick),
                  logBroodSize=log(BroodSize),
                  NCalls=SiblingNegotiation)


m.nb<- glmmadmb(NCalls~FoodTreatment+ArrivalTime+
           +(1|Nest),
         data=Owls,
         zeroInflation=FALSE,
         family="nbinom")
summary(m.nb)
# Estimate Std. Error z value Pr(>|z|)
# (Intercept)             4.2674     0.4705    9.07  < 2e-16 ***
#   FoodTreatmentSatiated  -0.2602     0.0845   -3.08   0.0021 **
#   ArrivalTime            -0.0840     0.0190   -4.42  9.8e-06 ***
#Plot lsmeans by FoodTreatment
owls.lsm<-lsmeans(m.nb, ~FoodTreatment)
owls.lsm
# FoodTreatment   lsmean        SE df asymp.LCL asymp.UCL
# Deprived      2.188727 0.7205142 NA 0.7765454  3.600909
# Satiated      1.928499 0.7498151 NA 0.4588887  3.398110
#SE is much higher than for fixed effects in model

plot(owls.lsm)
 #95% confidence bands overlap almost entirely

#Confirm with predict.glmmadmb:
New.data<-expand.grid(FoodTreatment= levels(Owls$FoodTreatment),
                      ArrivalTime = mean(Owls$ArrivalTime))

New.data$NCalls <- predict(m.nb, New.data, re.form=NA, SE.fit = TRUE)

#Get standard errors:
calls.pred<- predict(m.nb, New.data, re.form = NA, se.fit = TRUE)
calls.pred<-data.frame(calls.pred)

New.data$SE<-calls.pred$se.fit
New.data
# FoodTreatment ArrivalTime   NCalls        SE
# 1      Deprived    24.75763 2.188727 0.7205142
# 2      Satiated    24.75763 1.928499 0.7498151
#Matches with lsmeans output



##################  Compare to glmmTDMB  ####################
#install.packages("glmmTMB")
library(glmmTMB)
m.nb2<- glmmTMB(NCalls~FoodTreatment+ArrivalTime+
                  +(1|Nest),
                data=Owls,
                family="nbinom2")
summary(m.nb2)
# Estimate Std. Error z value Pr(>|z|)
# (Intercept)            4.91011    0.63343   7.752 9.07e-15 ***
#   FoodTreatmentSatiated -0.69238    0.10692  -6.476 9.44e-11 ***
#   ArrivalTime           -0.11540    0.02526  -4.569 4.90e-06 ***

#Compare to glmmADMB model:Fixed effects are identical
summary(m.nb)
# Estimate Std. Error z value Pr(>|z|)
# (Intercept)             4.9101     0.6334    7.75  9.1e-15 ***
#   FoodTreatmentSatiated  -0.6924     0.1069   -6.48  9.4e-11 ***
#   ArrivalTime            -0.1154     0.0253   -4.57  4.9e-06 ***

#Plot lsmeans by FoodTreatment
owls.lsm<-lsmeans(m.nb2, ~FoodTreatment)
#oops, lsmeans can't use glmmTMB object!

  ########   Interlude   #######
#Ben Bolker wrote a function to talk to lsmeans-- incredible!
# https://github.com/glmmTMB/glmmTMB/issues/205
recover.data.glmmTMB <- function(object, ...) {
  fcall <- getCall(object)
  recover.data(fcall,delete.response(terms(object)),
               attr(model.frame(object),"na.action"), ...)
}
lsm.basis.glmmTMB <- function (object, trms, xlev, grid, vcov.,
                               mode = "asymptotic", component="cond", ...) {
  if (mode != "asymptotic") stop("only asymptotic mode is available")
  if (component != "cond") stop("only tested for conditional component")
  if (missing(vcov.))
    V <- as.matrix(vcov(object)[[component]])
  else V <- as.matrix(.my.vcov(object, vcov.))
  dfargs = misc = list()
  if (mode == "asymptotic") {
    dffun = function(k, dfargs) NA
  }
  ## use this? misc = .std.link.labels(family(object), misc)
  contrasts = attr(model.matrix(object), "contrasts")
  m = model.frame(trms, grid, na.action = na.pass, xlev = xlev)
  X = model.matrix(trms, m, contrasts.arg = contrasts)
  bhat = fixef(object)[[component]]
  if (length(bhat) < ncol(X)) {
    kept = match(names(bhat), dimnames(X)[[2]])
    bhat = NA * X[1, ]
    bhat[kept] = fixef(object)[[component]]
    modmat = model.matrix(trms, model.frame(object), contrasts.arg = contrasts)
    nbasis = estimability::nonest.basis(modmat)
  }
  else nbasis = estimability::all.estble
  list(X = X, bhat = bhat, nbasis = nbasis, V = V, dffun = dffun,
       dfargs = dfargs, misc = misc)
}

#####   End interlude ###

lsm.TMB<- lsmeans(m.nb2, ~FoodTreatment)
plot(lsm.TMB)  #non-overlapping CI's

#Compare SE's
owls.lsm
# FoodTreatment   lsmean        SE df  asymp.LCL asymp.UCL
# Deprived      2.053073 0.8952071 NA  0.2984988  3.807646
# Satiated      1.360690 0.9037320 NA -0.4105918  3.131973

lsm.TMB
# FoodTreatment   lsmean        SE df asymp.LCL asymp.UCL
# Deprived      2.053065 0.1068562 NA  1.843631  2.262500
# Satiated      1.360683 0.1161322 NA  1.133068  1.588298

#lsmeans are identical but SE's differ by factor of 8?!


Thank you again.
Evan




On Thu, May 25, 2017 at 5:22 PM, John Maindonald <john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>> wrote:
The confidence intervals that you have obtained are for the levels
of `FoodTreatment`, not for the contrast `Satiated-Deprived`.


Try, the following, which also gives a confidence interval for the
difference from the initial level of `FoodTreatment`:

> library(glmmADMB)
> library(lsmeans)
> Owls <- transform(Owls,
               Nest=reorder(Nest,NegPerChick),
                logBroodSize=log(BroodSize),
               NCalls=SiblingNegotiation)
> m.nb<- glmmadmb(NCalls~FoodTreatment+ArrivalTime+(1|Nest),
        data=Owls,
        zeroInflation=TRUE,
       family="nbinom?)
> owls.lsm<-lsmeans(m.nb, ~FoodTreatment)
> lsmeans (owls.lsm, "FoodTreatment", contr = "trt.vs.ctrl")
$lsmeans
. . .

$contrasts
 contrast             estimate       SE df z.ratio p.value
 Satiated - Deprived -0.260228 0.084501 NA   -3.08  0.0021

John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>.


On 26/05/2017, at 01:04, Evan Palmer-Young <ecp52 at cornell.edu<mailto:ecp52 at cornell.edu>> wrote:

Dear List,

I am trying to use lsmeans to get confidence intervals for different levels
of treatment.

I was surprised to find that even when a fixed effect in my model was
highly significant, the confidence intervals on the lsmeans plot overlapped
almost completely. I reproduced this behavior with the "Owls" dataset. The
lsmeans() function and the predict.glmmadmb() function both gave the same
result, so there do not appear to be any surprises due to lsmeans.

I would be grateful if anybody could explain the reason for the large
confidence bands despite the significant fixed effect.


?Here is a short reproducible example-- thanks very much for any insight!

library(glmmADMB)

library(lsmeans)

#Use data from Bolker et al worked example
#http://glmmadmb.r-forge.r-project.org/glmmADMB.html

data(Owls)
str(Owls)
Owls <- transform(Owls,
                 Nest=reorder(Nest,NegPerChick),
                 logBroodSize=log(BroodSize),
                 NCalls=SiblingNegotiation)


m.nb<- glmmadmb(NCalls~FoodTreatment+ArrivalTime+
          +(1|Nest),
        data=Owls,
        zeroInflation=TRUE,
        family="nbinom")
summary(m.nb)
# Estimate Std. Error z value Pr(>|z|)
# (Intercept)             4.2674     0.4705    9.07  < 2e-16 ***
#  * FoodTreatmentSatiated  -0.2602     0.0845   -3.08   0.0021 ** *

#   ArrivalTime            -0.0840     0.0190   -4.42  9.8e-06 ***
#Plot lsmeans by FoodTreatment
owls.lsm<-lsmeans(m.nb, ~FoodTreatment)
owls.lsm
# FoodTreatment   lsmean        SE df asymp.LCL asymp.UCL
# Deprived      2.188727 0.7205142 NA 0.7765454  3.600909
# Satiated      1.928499 0.7498151 NA 0.4588887  3.398110
#SE is much higher than for fixed effects in model

plot(owls.lsm)
#95% confidence bands overlap almost entirely

#Confirm with predict.glmmadmb:
New.data<-expand.grid(FoodTreatment= levels(Owls$FoodTreatment),
                     ArrivalTime = mean(Owls$ArrivalTime))

New.data$NCalls <- predict(m.nb, New.data, re.form=NA, SE.fit = TRUE)

#Get standard errors:
calls.pred<- predict(m.nb, New.data, re.form = NA, se.fit = TRUE)
calls.pred<-data.frame(calls.pred)

New.data$SE<-calls.pred$se.fit
New.data
# FoodTreatment ArrivalTime   NCalls        SE
# 1      Deprived    24.75763 2.188727 0.7205142
# 2      Satiated    24.75763 1.928499 0.7498151
#Matches with lsmeans output
?


--
Evan Palmer-Young
PhD candidate
Department of Biology
221 Morrill Science Center
611 North Pleasant St
Amherst MA 01003
https://scholar.google.com/citations?user=VGvOypoAAAAJ&hl=en
https://sites.google.com/a/cornell.edu/evan-palmer-young/
epalmery at cns.umass.edu<mailto:epalmery at cns.umass.edu>
ecp52 at cornell.edu<mailto:ecp52 at cornell.edu>

[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models




--
Evan Palmer-Young
PhD candidate
Department of Biology
221 Morrill Science Center
611 North Pleasant St
Amherst MA 01003
https://scholar.google.com/citations?user=VGvOypoAAAAJ&hl=en
https://sites.google.com/a/cornell.edu/evan-palmer-young/
epalmery at cns.umass.edu<mailto:epalmery at cns.umass.edu>
ecp52 at cornell.edu<mailto:ecp52 at cornell.edu>


	[[alternative HTML version deleted]]


From russell-lenth at uiowa.edu  Sun May 28 06:00:56 2017
From: russell-lenth at uiowa.edu (Lenth, Russell V)
Date: Sun, 28 May 2017 04:00:56 +0000
Subject: [R-sig-ME] wider than expected confidence intervals with
 lsmeans and predict.glmmadmb
Message-ID: <CY1PR04MB220333A8C689BE0D187D18AAF1F20@CY1PR04MB2203.namprd04.prod.outlook.com>

If the SE of a mean is exactly 1/2 the SE of the difference of two means -- which is almost never the case -- it would be appropriate to use overlapping confidence intervals to test comparisons of means. So, you should almost never try to do that. In mixed models, it is not at all unusual to have huge discrepancies among standard errors.

However, 'lsmeans' does offer an ad hoc method for the graphical comparisons you have in mind. Try this:

    lsm.TMB<- lsmeans(m.nb2, ~FoodTreatment)
    plot(lsm.TMB, comparisons = TRUE)

This will plot both confidence intervals (in blue) and "comparison arrows" (in red). Non-overlapping comparison arrows will indicate cases where differences are significant. You can have just the comparison arrows by using:

    plot(lsm.TMB, intervals = FALSE, comparisons = TRUE)

In either case, as I say, it is an ad hoc method, and it doesn't always work, especially when there are widely variable standard errors. A warning is issued if it can't figure out a solution.

Russ
--
Russell V. Lenth ?- ?Professor Emeritus
Department of Statistics and Actuarial Science ??
The University of Iowa ?- ?Iowa City, IA 52242 ?USA ??
Voice (319)335-0712 ?- ?FAX (319)335-3017
russell-lenth at uiowa.edu??- ?http://www.stat.uiowa.edu/~rlenth/?



-----Original Message-----

Date: Fri, 26 May 2017 17:29:52 -0400
From: Evan Palmer-Young <ecp52 at cornell.edu>
To: John Maindonald <john.maindonald at anu.edu.au>
Cc: R-mixed models mailing list <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] wider than expected confidence intervals with
	lsmeans and predict.glmmadmb
Message-ID:
	<CAAge6+7v1KY=8GLNqi1Hzg4zyQY0kfSjGvMXM-rhRFC9ER8Kcw at mail.gmail.com>
Content-Type: text/plain; charset="UTF-8"

Thanks very much for your reply, Prof. Maindonald.

I agree that the pairwise comparisons are informative, but it would be easiest for readers to see the data on the original scale to show differences between groups.

When the lsmeans are plotted from glmmTMB, which fits a model with fixed effects identical to those in glmmADMB, the estimates are identical but the SE's differ by a factor of 8.

So I am still confused about why the lsmeans plots would reflect pairwise differences with some packages but not with glmmADMB.
In my experience, lsmeans plots of group means from glmer() models are also non-overlapping when pairwise comparisons are highly significant.

I have extended the code to illustrate the differences.

library(glmmADMB)

library(lsmeans)

#Use data from worked example
#http://glmmadmb.r-forge.r-project.org/glmmADMB.html

library(glmmADMB)
data(Owls)
str(Owls)
Owls <- transform(Owls,
                  Nest=reorder(Nest,NegPerChick),
                  logBroodSize=log(BroodSize),
                  NCalls=SiblingNegotiation)


m.nb<- glmmadmb(NCalls~FoodTreatment+ArrivalTime+
           +(1|Nest),
         data=Owls,
         zeroInflation=FALSE,
         family="nbinom")
summary(m.nb)
# Estimate Std. Error z value Pr(>|z|)
# (Intercept)             4.2674     0.4705    9.07  < 2e-16 ***
#   FoodTreatmentSatiated  -0.2602     0.0845   -3.08   0.0021 **
#   ArrivalTime            -0.0840     0.0190   -4.42  9.8e-06 ***
#Plot lsmeans by FoodTreatment
owls.lsm<-lsmeans(m.nb, ~FoodTreatment)
owls.lsm
# FoodTreatment   lsmean        SE df asymp.LCL asymp.UCL
# Deprived      2.188727 0.7205142 NA 0.7765454  3.600909
# Satiated      1.928499 0.7498151 NA 0.4588887  3.398110
#SE is much higher than for fixed effects in model

plot(owls.lsm)
 #95% confidence bands overlap almost entirely

#Confirm with predict.glmmadmb:
New.data<-expand.grid(FoodTreatment= levels(Owls$FoodTreatment),
                      ArrivalTime = mean(Owls$ArrivalTime))

New.data$NCalls <- predict(m.nb, New.data, re.form=NA, SE.fit = TRUE)

#Get standard errors:
calls.pred<- predict(m.nb, New.data, re.form = NA, se.fit = TRUE)
calls.pred<-data.frame(calls.pred)

New.data$SE<-calls.pred$se.fit
New.data
# FoodTreatment ArrivalTime   NCalls        SE
# 1      Deprived    24.75763 2.188727 0.7205142
# 2      Satiated    24.75763 1.928499 0.7498151
#Matches with lsmeans output



##################  Compare to glmmTDMB  ####################
#install.packages("glmmTMB")
library(glmmTMB)
m.nb2<- glmmTMB(NCalls~FoodTreatment+ArrivalTime+
                  +(1|Nest),
                data=Owls,
                family="nbinom2")
summary(m.nb2)
# Estimate Std. Error z value Pr(>|z|)
# (Intercept)            4.91011    0.63343   7.752 9.07e-15 ***
#   FoodTreatmentSatiated -0.69238    0.10692  -6.476 9.44e-11 ***
#   ArrivalTime           -0.11540    0.02526  -4.569 4.90e-06 ***

#Compare to glmmADMB model:Fixed effects are identical
summary(m.nb)
# Estimate Std. Error z value Pr(>|z|)
# (Intercept)             4.9101     0.6334    7.75  9.1e-15 ***
#   FoodTreatmentSatiated  -0.6924     0.1069   -6.48  9.4e-11 ***
#   ArrivalTime            -0.1154     0.0253   -4.57  4.9e-06 ***

#Plot lsmeans by FoodTreatment
owls.lsm<-lsmeans(m.nb2, ~FoodTreatment) #oops, lsmeans can't use glmmTMB object!

  ########   Interlude   #######
#Ben Bolker wrote a function to talk to lsmeans-- incredible!
# https://github.com/glmmTMB/glmmTMB/issues/205
recover.data.glmmTMB <- function(object, ...) {
  fcall <- getCall(object)
  recover.data(fcall,delete.response(terms(object)),
               attr(model.frame(object),"na.action"), ...) } lsm.basis.glmmTMB <- function (object, trms, xlev, grid, vcov.,
                               mode = "asymptotic", component="cond", ...) {
  if (mode != "asymptotic") stop("only asymptotic mode is available")
  if (component != "cond") stop("only tested for conditional component")
  if (missing(vcov.))
    V <- as.matrix(vcov(object)[[component]])
  else V <- as.matrix(.my.vcov(object, vcov.))
  dfargs = misc = list()
  if (mode == "asymptotic") {
    dffun = function(k, dfargs) NA
  }
  ## use this? misc = .std.link.labels(family(object), misc)
  contrasts = attr(model.matrix(object), "contrasts")
  m = model.frame(trms, grid, na.action = na.pass, xlev = xlev)
  X = model.matrix(trms, m, contrasts.arg = contrasts)
  bhat = fixef(object)[[component]]
  if (length(bhat) < ncol(X)) {
    kept = match(names(bhat), dimnames(X)[[2]])
    bhat = NA * X[1, ]
    bhat[kept] = fixef(object)[[component]]
    modmat = model.matrix(trms, model.frame(object), contrasts.arg =
contrasts)
    nbasis = estimability::nonest.basis(modmat)
  }
  else nbasis = estimability::all.estble
  list(X = X, bhat = bhat, nbasis = nbasis, V = V, dffun = dffun,
       dfargs = dfargs, misc = misc)
}

#####   End interlude ###

lsm.TMB<- lsmeans(m.nb2, ~FoodTreatment)
plot(lsm.TMB)  #non-overlapping CI's

#Compare SE's
owls.lsm
# FoodTreatment   lsmean       * SE* df  asymp.LCL asymp.UCL
# Deprived      2.053073 *0.8952071* NA  0.2984988  3.807646
# Satiated      1.360690 *0.9037320 *NA -0.4105918  3.131973

lsm.TMB
# FoodTreatment   lsmean        *SE* df asymp.LCL asymp.UCL
# Deprived      2.053065 *0.1068562* NA  1.843631  2.262500
# Satiated      1.360683 *0.1161322* NA  1.133068  1.588298

#lsmeans are identical but SE's differ by factor of 8?!


Thank you again.
Evan


From ecp52 at cornell.edu  Sun May 28 23:20:23 2017
From: ecp52 at cornell.edu (Evan Palmer-Young)
Date: Sun, 28 May 2017 17:20:23 -0400
Subject: [R-sig-ME] wider than expected confidence intervals with
 lsmeans and predict.glmmadmb
In-Reply-To: <CY1PR04MB220333A8C689BE0D187D18AAF1F20@CY1PR04MB2203.namprd04.prod.outlook.com>
References: <CY1PR04MB220333A8C689BE0D187D18AAF1F20@CY1PR04MB2203.namprd04.prod.outlook.com>
Message-ID: <CAAge6+7rSaPBv4uHD1T7Vh6-tWrzXjxbuYYXahiQEAgoY0rVPw@mail.gmail.com>

Thank you for this suggestion; it looks like you already implemented what
Prof. Maindonald suggested.

In your (RVL's) J. Stat Software article on lsmeans
<https://www.jstatsoft.org/article/view/v069i01>, Section 5.1, you wrote:


* Note that it is a mistake to try to use confidence intervals to judge
comparisons. In this example, the standard errors of comparisons are much
smaller than those of the LS means, because the between-block and
between-plot variations cancel out in the comparisons. *

I think that this is what John Maindonald indicated, too.

Is it possible that some packages (glmmADMB?) provide predict() estimates
that include the random-effect variance referred to in the quotation, and
others do not? Or that some produce confidence intervals whereas others
produce prediction intervals (i.e., by addition of the residual variance),
as differentiated in the glmm FAQ
<https://github.com/bbolker/mixedmodels-misc/blob/master/glmmFAQ.rmd#predictions-andor-confidence-or-prediction-intervals-on-predictions>,
section on Prediction and Confidence Intervals?

I posted a query to the glmmADMB
<https://github.com/bbolker/glmmadmb/issues/5> Github page, to see if
somebody with more familiarity to the package might be able to explain
nuances or difference. This thread has been cross-referenced with that
question.

Thank you again for your patience and thorough explanations!
Much appreciated,
Evan


On Sun, May 28, 2017 at 12:00 AM, Lenth, Russell V <russell-lenth at uiowa.edu>
wrote:

> If the SE of a mean is exactly 1/2 the SE of the difference of two means
> -- which is almost never the case -- it would be appropriate to use
> overlapping confidence intervals to test comparisons of means. So, you
> should almost never try to do that. In mixed models, it is not at all
> unusual to have huge discrepancies among standard errors.
>
> However, 'lsmeans' does offer an ad hoc method for the graphical
> comparisons you have in mind. Try this:
>
>     lsm.TMB<- lsmeans(m.nb2, ~FoodTreatment)
>     plot(lsm.TMB, comparisons = TRUE)
>
> This will plot both confidence intervals (in blue) and "comparison arrows"
> (in red). Non-overlapping comparison arrows will indicate cases where
> differences are significant. You can have just the comparison arrows by
> using:
>
>     plot(lsm.TMB, intervals = FALSE, comparisons = TRUE)
>
> In either case, as I say, it is an ad hoc method, and it doesn't always
> work, especially when there are widely variable standard errors. A warning
> is issued if it can't figure out a solution.
>
> Russ
> --
> Russell V. Lenth  -  Professor Emeritus
> Department of Statistics and Actuarial Science
> The University of Iowa  -  Iowa City, IA 52242  USA
> Voice (319)335-0712  -  FAX (319)335-3017
> russell-lenth at uiowa.edu  -  http://www.stat.uiowa.edu/~rlenth/
>
>
>
> -----Original Message-----
>
> Date: Fri, 26 May 2017 17:29:52 -0400
> From: Evan Palmer-Young <ecp52 at cornell.edu>
> To: John Maindonald <john.maindonald at anu.edu.au>
> Cc: R-mixed models mailing list <r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] wider than expected confidence intervals with
>         lsmeans and predict.glmmadmb
> Message-ID:
>         <CAAge6+7v1KY=8GLNqi1Hzg4zyQY0kfSjGvMXM-rhRFC9ER8Kcw at mail.
> gmail.com>
> Content-Type: text/plain; charset="UTF-8"
>
> Thanks very much for your reply, Prof. Maindonald.
>
> I agree that the pairwise comparisons are informative, but it would be
> easiest for readers to see the data on the original scale to show
> differences between groups.
>
> When the lsmeans are plotted from glmmTMB, which fits a model with fixed
> effects identical to those in glmmADMB, the estimates are identical but the
> SE's differ by a factor of 8.
>
> So I am still confused about why the lsmeans plots would reflect pairwise
> differences with some packages but not with glmmADMB.
> In my experience, lsmeans plots of group means from glmer() models are
> also non-overlapping when pairwise comparisons are highly significant.
>
> I have extended the code to illustrate the differences.
>
> library(glmmADMB)
>
> library(lsmeans)
>
> #Use data from worked example
> #http://glmmadmb.r-forge.r-project.org/glmmADMB.html
>
> library(glmmADMB)
> data(Owls)
> str(Owls)
> Owls <- transform(Owls,
>                   Nest=reorder(Nest,NegPerChick),
>                   logBroodSize=log(BroodSize),
>                   NCalls=SiblingNegotiation)
>
>
> m.nb<- glmmadmb(NCalls~FoodTreatment+ArrivalTime+
>            +(1|Nest),
>          data=Owls,
>          zeroInflation=FALSE,
>          family="nbinom")
> summary(m.nb)
> # Estimate Std. Error z value Pr(>|z|)
> # (Intercept)             4.2674     0.4705    9.07  < 2e-16 ***
> #   FoodTreatmentSatiated  -0.2602     0.0845   -3.08   0.0021 **
> #   ArrivalTime            -0.0840     0.0190   -4.42  9.8e-06 ***
> #Plot lsmeans by FoodTreatment
> owls.lsm<-lsmeans(m.nb, ~FoodTreatment)
> owls.lsm
> # FoodTreatment   lsmean        SE df asymp.LCL asymp.UCL
> # Deprived      2.188727 0.7205142 NA 0.7765454  3.600909
> # Satiated      1.928499 0.7498151 NA 0.4588887  3.398110
> #SE is much higher than for fixed effects in model
>
> plot(owls.lsm)
>  #95% confidence bands overlap almost entirely
>
> #Confirm with predict.glmmadmb:
> New.data<-expand.grid(FoodTreatment= levels(Owls$FoodTreatment),
>                       ArrivalTime = mean(Owls$ArrivalTime))
>
> New.data$NCalls <- predict(m.nb, New.data, re.form=NA, SE.fit = TRUE)
>
> #Get standard errors:
> calls.pred<- predict(m.nb, New.data, re.form = NA, se.fit = TRUE)
> calls.pred<-data.frame(calls.pred)
>
> New.data$SE<-calls.pred$se.fit
> New.data
> # FoodTreatment ArrivalTime   NCalls        SE
> # 1      Deprived    24.75763 2.188727 0.7205142
> # 2      Satiated    24.75763 1.928499 0.7498151
> #Matches with lsmeans output
>
>
>
> ##################  Compare to glmmTDMB  ####################
> #install.packages("glmmTMB")
> library(glmmTMB)
> m.nb2<- glmmTMB(NCalls~FoodTreatment+ArrivalTime+
>                   +(1|Nest),
>                 data=Owls,
>                 family="nbinom2")
> summary(m.nb2)
> # Estimate Std. Error z value Pr(>|z|)
> # (Intercept)            4.91011    0.63343   7.752 9.07e-15 ***
> #   FoodTreatmentSatiated -0.69238    0.10692  -6.476 9.44e-11 ***
> #   ArrivalTime           -0.11540    0.02526  -4.569 4.90e-06 ***
>
> #Compare to glmmADMB model:Fixed effects are identical
> summary(m.nb)
> # Estimate Std. Error z value Pr(>|z|)
> # (Intercept)             4.9101     0.6334    7.75  9.1e-15 ***
> #   FoodTreatmentSatiated  -0.6924     0.1069   -6.48  9.4e-11 ***
> #   ArrivalTime            -0.1154     0.0253   -4.57  4.9e-06 ***
>
> #Plot lsmeans by FoodTreatment
> owls.lsm<-lsmeans(m.nb2, ~FoodTreatment) #oops, lsmeans can't use glmmTMB
> object!
>
>   ########   Interlude   #######
> #Ben Bolker wrote a function to talk to lsmeans-- incredible!
> # https://github.com/glmmTMB/glmmTMB/issues/205
> recover.data.glmmTMB <- function(object, ...) {
>   fcall <- getCall(object)
>   recover.data(fcall,delete.response(terms(object)),
>                attr(model.frame(object),"na.action"), ...) }
> lsm.basis.glmmTMB <- function (object, trms, xlev, grid, vcov.,
>                                mode = "asymptotic", component="cond", ...)
> {
>   if (mode != "asymptotic") stop("only asymptotic mode is available")
>   if (component != "cond") stop("only tested for conditional component")
>   if (missing(vcov.))
>     V <- as.matrix(vcov(object)[[component]])
>   else V <- as.matrix(.my.vcov(object, vcov.))
>   dfargs = misc = list()
>   if (mode == "asymptotic") {
>     dffun = function(k, dfargs) NA
>   }
>   ## use this? misc = .std.link.labels(family(object), misc)
>   contrasts = attr(model.matrix(object), "contrasts")
>   m = model.frame(trms, grid, na.action = na.pass, xlev = xlev)
>   X = model.matrix(trms, m, contrasts.arg = contrasts)
>   bhat = fixef(object)[[component]]
>   if (length(bhat) < ncol(X)) {
>     kept = match(names(bhat), dimnames(X)[[2]])
>     bhat = NA * X[1, ]
>     bhat[kept] = fixef(object)[[component]]
>     modmat = model.matrix(trms, model.frame(object), contrasts.arg =
> contrasts)
>     nbasis = estimability::nonest.basis(modmat)
>   }
>   else nbasis = estimability::all.estble
>   list(X = X, bhat = bhat, nbasis = nbasis, V = V, dffun = dffun,
>        dfargs = dfargs, misc = misc)
> }
>
> #####   End interlude ###
>
> lsm.TMB<- lsmeans(m.nb2, ~FoodTreatment)
> plot(lsm.TMB)  #non-overlapping CI's
>
> #Compare SE's
> owls.lsm
> # FoodTreatment   lsmean       * SE* df  asymp.LCL asymp.UCL
> # Deprived      2.053073 *0.8952071* NA  0.2984988  3.807646
> # Satiated      1.360690 *0.9037320 *NA -0.4105918  3.131973
>
> lsm.TMB
> # FoodTreatment   lsmean        *SE* df asymp.LCL asymp.UCL
> # Deprived      2.053065 *0.1068562* NA  1.843631  2.262500
> # Satiated      1.360683 *0.1161322* NA  1.133068  1.588298
>
> #lsmeans are identical but SE's differ by factor of 8?!
>
>
> Thank you again.
> Evan
>



-- 
Evan Palmer-Young
PhD candidate
Department of Biology
221 Morrill Science Center
611 North Pleasant St
Amherst MA 01003
https://scholar.google.com/citations?user=VGvOypoAAAAJ&hl=en
https://sites.google.com/a/cornell.edu/evan-palmer-young/
epalmery at cns.umass.edu
ecp52 at cornell.edu

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon May 29 01:59:20 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 28 May 2017 19:59:20 -0400
Subject: [R-sig-ME] wider than expected confidence intervals with
 lsmeans and predict.glmmadmb
In-Reply-To: <CAAge6+7rSaPBv4uHD1T7Vh6-tWrzXjxbuYYXahiQEAgoY0rVPw@mail.gmail.com>
References: <CY1PR04MB220333A8C689BE0D187D18AAF1F20@CY1PR04MB2203.namprd04.prod.outlook.com>
 <CAAge6+7rSaPBv4uHD1T7Vh6-tWrzXjxbuYYXahiQEAgoY0rVPw@mail.gmail.com>
Message-ID: <CABghstQ3PVCx2NSP8otFgKzOFg+WenP023tQfRkFRCewZ6GZqw@mail.gmail.com>

I will look this over more carefully if/when I get time, to see what
the differences are between the ways in which lme4, glmmADMB, and
glmmTMB implement the building blocks that lsmeans uses. But I can't
guarantee I will get to it soon ... essentially, I'll just have to
pick through the implementation of lsm.basis for glmmTMB and glmmADMB
and see what the differences are ... it would help to try this on some
cases without zero-inflation and without any random effects at all, to
see where the discrepancies are coming from.


On Sun, May 28, 2017 at 5:20 PM, Evan Palmer-Young <ecp52 at cornell.edu> wrote:
> Thank you for this suggestion; it looks like you already implemented what
> Prof. Maindonald suggested.
>
> In your (RVL's) J. Stat Software article on lsmeans
> <https://www.jstatsoft.org/article/view/v069i01>, Section 5.1, you wrote:
>
>
> * Note that it is a mistake to try to use confidence intervals to judge
> comparisons. In this example, the standard errors of comparisons are much
> smaller than those of the LS means, because the between-block and
> between-plot variations cancel out in the comparisons. *
>
> I think that this is what John Maindonald indicated, too.
>
> Is it possible that some packages (glmmADMB?) provide predict() estimates
> that include the random-effect variance referred to in the quotation, and
> others do not? Or that some produce confidence intervals whereas others
> produce prediction intervals (i.e., by addition of the residual variance),
> as differentiated in the glmm FAQ
> <https://github.com/bbolker/mixedmodels-misc/blob/master/glmmFAQ.rmd#predictions-andor-confidence-or-prediction-intervals-on-predictions>,
> section on Prediction and Confidence Intervals?
>
> I posted a query to the glmmADMB
> <https://github.com/bbolker/glmmadmb/issues/5> Github page, to see if
> somebody with more familiarity to the package might be able to explain
> nuances or difference. This thread has been cross-referenced with that
> question.
>
> Thank you again for your patience and thorough explanations!
> Much appreciated,
> Evan
>
>
> On Sun, May 28, 2017 at 12:00 AM, Lenth, Russell V <russell-lenth at uiowa.edu>
> wrote:
>
>> If the SE of a mean is exactly 1/2 the SE of the difference of two means
>> -- which is almost never the case -- it would be appropriate to use
>> overlapping confidence intervals to test comparisons of means. So, you
>> should almost never try to do that. In mixed models, it is not at all
>> unusual to have huge discrepancies among standard errors.
>>
>> However, 'lsmeans' does offer an ad hoc method for the graphical
>> comparisons you have in mind. Try this:
>>
>>     lsm.TMB<- lsmeans(m.nb2, ~FoodTreatment)
>>     plot(lsm.TMB, comparisons = TRUE)
>>
>> This will plot both confidence intervals (in blue) and "comparison arrows"
>> (in red). Non-overlapping comparison arrows will indicate cases where
>> differences are significant. You can have just the comparison arrows by
>> using:
>>
>>     plot(lsm.TMB, intervals = FALSE, comparisons = TRUE)
>>
>> In either case, as I say, it is an ad hoc method, and it doesn't always
>> work, especially when there are widely variable standard errors. A warning
>> is issued if it can't figure out a solution.
>>
>> Russ
>> --
>> Russell V. Lenth  -  Professor Emeritus
>> Department of Statistics and Actuarial Science
>> The University of Iowa  -  Iowa City, IA 52242  USA
>> Voice (319)335-0712  -  FAX (319)335-3017
>> russell-lenth at uiowa.edu  -  http://www.stat.uiowa.edu/~rlenth/
>>
>>
>>
>> -----Original Message-----
>>
>> Date: Fri, 26 May 2017 17:29:52 -0400
>> From: Evan Palmer-Young <ecp52 at cornell.edu>
>> To: John Maindonald <john.maindonald at anu.edu.au>
>> Cc: R-mixed models mailing list <r-sig-mixed-models at r-project.org>
>> Subject: Re: [R-sig-ME] wider than expected confidence intervals with
>>         lsmeans and predict.glmmadmb
>> Message-ID:
>>         <CAAge6+7v1KY=8GLNqi1Hzg4zyQY0kfSjGvMXM-rhRFC9ER8Kcw at mail.
>> gmail.com>
>> Content-Type: text/plain; charset="UTF-8"
>>
>> Thanks very much for your reply, Prof. Maindonald.
>>
>> I agree that the pairwise comparisons are informative, but it would be
>> easiest for readers to see the data on the original scale to show
>> differences between groups.
>>
>> When the lsmeans are plotted from glmmTMB, which fits a model with fixed
>> effects identical to those in glmmADMB, the estimates are identical but the
>> SE's differ by a factor of 8.
>>
>> So I am still confused about why the lsmeans plots would reflect pairwise
>> differences with some packages but not with glmmADMB.
>> In my experience, lsmeans plots of group means from glmer() models are
>> also non-overlapping when pairwise comparisons are highly significant.
>>
>> I have extended the code to illustrate the differences.
>>
>> library(glmmADMB)
>>
>> library(lsmeans)
>>
>> #Use data from worked example
>> #http://glmmadmb.r-forge.r-project.org/glmmADMB.html
>>
>> library(glmmADMB)
>> data(Owls)
>> str(Owls)
>> Owls <- transform(Owls,
>>                   Nest=reorder(Nest,NegPerChick),
>>                   logBroodSize=log(BroodSize),
>>                   NCalls=SiblingNegotiation)
>>
>>
>> m.nb<- glmmadmb(NCalls~FoodTreatment+ArrivalTime+
>>            +(1|Nest),
>>          data=Owls,
>>          zeroInflation=FALSE,
>>          family="nbinom")
>> summary(m.nb)
>> # Estimate Std. Error z value Pr(>|z|)
>> # (Intercept)             4.2674     0.4705    9.07  < 2e-16 ***
>> #   FoodTreatmentSatiated  -0.2602     0.0845   -3.08   0.0021 **
>> #   ArrivalTime            -0.0840     0.0190   -4.42  9.8e-06 ***
>> #Plot lsmeans by FoodTreatment
>> owls.lsm<-lsmeans(m.nb, ~FoodTreatment)
>> owls.lsm
>> # FoodTreatment   lsmean        SE df asymp.LCL asymp.UCL
>> # Deprived      2.188727 0.7205142 NA 0.7765454  3.600909
>> # Satiated      1.928499 0.7498151 NA 0.4588887  3.398110
>> #SE is much higher than for fixed effects in model
>>
>> plot(owls.lsm)
>>  #95% confidence bands overlap almost entirely
>>
>> #Confirm with predict.glmmadmb:
>> New.data<-expand.grid(FoodTreatment= levels(Owls$FoodTreatment),
>>                       ArrivalTime = mean(Owls$ArrivalTime))
>>
>> New.data$NCalls <- predict(m.nb, New.data, re.form=NA, SE.fit = TRUE)
>>
>> #Get standard errors:
>> calls.pred<- predict(m.nb, New.data, re.form = NA, se.fit = TRUE)
>> calls.pred<-data.frame(calls.pred)
>>
>> New.data$SE<-calls.pred$se.fit
>> New.data
>> # FoodTreatment ArrivalTime   NCalls        SE
>> # 1      Deprived    24.75763 2.188727 0.7205142
>> # 2      Satiated    24.75763 1.928499 0.7498151
>> #Matches with lsmeans output
>>
>>
>>
>> ##################  Compare to glmmTDMB  ####################
>> #install.packages("glmmTMB")
>> library(glmmTMB)
>> m.nb2<- glmmTMB(NCalls~FoodTreatment+ArrivalTime+
>>                   +(1|Nest),
>>                 data=Owls,
>>                 family="nbinom2")
>> summary(m.nb2)
>> # Estimate Std. Error z value Pr(>|z|)
>> # (Intercept)            4.91011    0.63343   7.752 9.07e-15 ***
>> #   FoodTreatmentSatiated -0.69238    0.10692  -6.476 9.44e-11 ***
>> #   ArrivalTime           -0.11540    0.02526  -4.569 4.90e-06 ***
>>
>> #Compare to glmmADMB model:Fixed effects are identical
>> summary(m.nb)
>> # Estimate Std. Error z value Pr(>|z|)
>> # (Intercept)             4.9101     0.6334    7.75  9.1e-15 ***
>> #   FoodTreatmentSatiated  -0.6924     0.1069   -6.48  9.4e-11 ***
>> #   ArrivalTime            -0.1154     0.0253   -4.57  4.9e-06 ***
>>
>> #Plot lsmeans by FoodTreatment
>> owls.lsm<-lsmeans(m.nb2, ~FoodTreatment) #oops, lsmeans can't use glmmTMB
>> object!
>>
>>   ########   Interlude   #######
>> #Ben Bolker wrote a function to talk to lsmeans-- incredible!
>> # https://github.com/glmmTMB/glmmTMB/issues/205
>> recover.data.glmmTMB <- function(object, ...) {
>>   fcall <- getCall(object)
>>   recover.data(fcall,delete.response(terms(object)),
>>                attr(model.frame(object),"na.action"), ...) }
>> lsm.basis.glmmTMB <- function (object, trms, xlev, grid, vcov.,
>>                                mode = "asymptotic", component="cond", ...)
>> {
>>   if (mode != "asymptotic") stop("only asymptotic mode is available")
>>   if (component != "cond") stop("only tested for conditional component")
>>   if (missing(vcov.))
>>     V <- as.matrix(vcov(object)[[component]])
>>   else V <- as.matrix(.my.vcov(object, vcov.))
>>   dfargs = misc = list()
>>   if (mode == "asymptotic") {
>>     dffun = function(k, dfargs) NA
>>   }
>>   ## use this? misc = .std.link.labels(family(object), misc)
>>   contrasts = attr(model.matrix(object), "contrasts")
>>   m = model.frame(trms, grid, na.action = na.pass, xlev = xlev)
>>   X = model.matrix(trms, m, contrasts.arg = contrasts)
>>   bhat = fixef(object)[[component]]
>>   if (length(bhat) < ncol(X)) {
>>     kept = match(names(bhat), dimnames(X)[[2]])
>>     bhat = NA * X[1, ]
>>     bhat[kept] = fixef(object)[[component]]
>>     modmat = model.matrix(trms, model.frame(object), contrasts.arg =
>> contrasts)
>>     nbasis = estimability::nonest.basis(modmat)
>>   }
>>   else nbasis = estimability::all.estble
>>   list(X = X, bhat = bhat, nbasis = nbasis, V = V, dffun = dffun,
>>        dfargs = dfargs, misc = misc)
>> }
>>
>> #####   End interlude ###
>>
>> lsm.TMB<- lsmeans(m.nb2, ~FoodTreatment)
>> plot(lsm.TMB)  #non-overlapping CI's
>>
>> #Compare SE's
>> owls.lsm
>> # FoodTreatment   lsmean       * SE* df  asymp.LCL asymp.UCL
>> # Deprived      2.053073 *0.8952071* NA  0.2984988  3.807646
>> # Satiated      1.360690 *0.9037320 *NA -0.4105918  3.131973
>>
>> lsm.TMB
>> # FoodTreatment   lsmean        *SE* df asymp.LCL asymp.UCL
>> # Deprived      2.053065 *0.1068562* NA  1.843631  2.262500
>> # Satiated      1.360683 *0.1161322* NA  1.133068  1.588298
>>
>> #lsmeans are identical but SE's differ by factor of 8?!
>>
>>
>> Thank you again.
>> Evan
>>
>
>
>
> --
> Evan Palmer-Young
> PhD candidate
> Department of Biology
> 221 Morrill Science Center
> 611 North Pleasant St
> Amherst MA 01003
> https://scholar.google.com/citations?user=VGvOypoAAAAJ&hl=en
> https://sites.google.com/a/cornell.edu/evan-palmer-young/
> epalmery at cns.umass.edu
> ecp52 at cornell.edu
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From ecp52 at cornell.edu  Mon May 29 22:25:45 2017
From: ecp52 at cornell.edu (Evan Palmer-Young)
Date: Mon, 29 May 2017 16:25:45 -0400
Subject: [R-sig-ME] wider than expected confidence intervals with
 lsmeans and predict.glmmadmb
In-Reply-To: <CABghstQ3PVCx2NSP8otFgKzOFg+WenP023tQfRkFRCewZ6GZqw@mail.gmail.com>
References: <CY1PR04MB220333A8C689BE0D187D18AAF1F20@CY1PR04MB2203.namprd04.prod.outlook.com>
 <CAAge6+7rSaPBv4uHD1T7Vh6-tWrzXjxbuYYXahiQEAgoY0rVPw@mail.gmail.com>
 <CABghstQ3PVCx2NSP8otFgKzOFg+WenP023tQfRkFRCewZ6GZqw@mail.gmail.com>
Message-ID: <CAAge6+7QhWAOKa-ywiuowXGYBRj+4+FLX5A=WBy5JsY3=8ZSNw@mail.gmail.com>

Thanks again for your responses and willingness to help.

The discrepancy in SE's for the predicted means appears to hold across
  (1) zero-inflated and
  (2) zero-uninflated models, and also
   (3) with no random effects and
   (4) with poisson distribution
For both (2) and (4), the plots from glmmTMB and glmer are similar to one
another, whereas the plots for glmmADMB have bigger SE's by a factor of 4
to 12.
Both fixed effects coefficient and pairwise contrasts (ie., tests of
differences) are similar for all.

Here is a long-ish script to demonstrate:

###### Test of differences between glmmADMB, glmmTMB, and glmer.nb
##########
### Observed that glmmADMB confidence intervals were up to 8x larger than
with other packages
## Test if this is consistent across:
  ##1. Zero-inflated model
  ##2. Non-zero-inflated model
  ##3. Without random effects
  ##4. Poisson model

#I. Preliminaries:
#Load packages, load data, source function to extract lsmeans

#install.packages("glmmADMB", repos = "
http://glmmadmb.r-forge.r-project.org/repos")

library(glmmADMB)
library(glmmTMB)
library(lsmeans)

#Use data from worked example
#http://glmmadmb.r-forge.r-project.org/glmmADMB.html

data(Owls)
str(Owls)
Owls <- transform(Owls,
                  Nest=reorder(Nest,NegPerChick),
                  logBroodSize=log(BroodSize),
                  NCalls=SiblingNegotiation)

########   Interlude   #######
#Use Ben Bolker's function to talk to lsmeans
# https://github.com/glmmTMB/glmmTMB/issues/205
recover.data.glmmTMB <- function(object, ...) {
  fcall <- getCall(object)
  recover.data(fcall,delete.response(terms(object)),
               attr(model.frame(object),"na.action"), ...)
}
lsm.basis.glmmTMB <- function (object, trms, xlev, grid, vcov.,
                               mode = "asymptotic", component="cond", ...) {
  if (mode != "asymptotic") stop("only asymptotic mode is available")
  if (component != "cond") stop("only tested for conditional component")
  if (missing(vcov.))
    V <- as.matrix(vcov(object)[[component]])
  else V <- as.matrix(.my.vcov(object, vcov.))
  dfargs = misc = list()
  if (mode == "asymptotic") {
    dffun = function(k, dfargs) NA
  }
  ## use this? misc = .std.link.labels(family(object), misc)
  contrasts = attr(model.matrix(object), "contrasts")
  m = model.frame(trms, grid, na.action = na.pass, xlev = xlev)
  X = model.matrix(trms, m, contrasts.arg = contrasts)
  bhat = fixef(object)[[component]]
  if (length(bhat) < ncol(X)) {
    kept = match(names(bhat), dimnames(X)[[2]])
    bhat = NA * X[1, ]
    bhat[kept] = fixef(object)[[component]]
    modmat = model.matrix(trms, model.frame(object), contrasts.arg =
contrasts)
    nbasis = estimability::nonest.basis(modmat)
  }
  else nbasis = estimability::all.estble
  list(X = X, bhat = bhat, nbasis = nbasis, V = V, dffun = dffun,
       dfargs = dfargs, misc = misc)
}

#####   End interlude ###



#######################################################
###1. With zero inflation ###########################
###################################################
m.zi<- glmmadmb(NCalls~FoodTreatment+ArrivalTime+
                  +(1|Nest),
                data=Owls,
                zeroInflation=TRUE,
                family="nbinom")
summary(m.zi)
# Coefficients:
#   Estimate Std. Error z value Pr(>|z|)
# (Intercept)             4.2674     0.4705    9.07  < 2e-16 ***
#   FoodTreatmentSatiated  -0.2602     0.0845   -3.08   0.0021 **
#   ArrivalTime            -0.0840     0.0190   -4.42  9.8e-06 ***

#Plot lsmeans by FoodTreatment
owls.lsm.zi<-lsmeans(m.zi, ~FoodTreatment)
owls.lsm.zi
# FoodTreatment   lsmean        SE df asymp.LCL asymp.UCL
# Deprived      2.188727 0.7205142 NA 0.7765454  3.600909
# Satiated      1.928499 0.7498151 NA 0.4588887  3.398110

plot(owls.lsm.zi)
#95% confidence bands overlap almost entirely



##################  Compare glmmADMB fit to glmmTDMB  ####################
#install.packages("glmmTMB")
zi.t<- glmmTMB(NCalls~FoodTreatment+ArrivalTime+
                  +(1|Nest),
                data=Owls,
                ziformula = ~1,
                family="nbinom2")
summary(zi.t)
# Estimate Std. Error z value Pr(>|z|)
# (Intercept)            4.26735    0.47044   9.071  < 2e-16 ***
#   FoodTreatmentSatiated -0.26022    0.08450  -3.080  0.00207 **
#   ArrivalTime           -0.08396    0.01898  -4.423 9.74e-06 ***

#Compare to glmmADMB model:Fixed effects are identical
summary(m.zi)
# Estimate Std. Error z value Pr(>|z|)
# (Intercept)             4.2674     0.4705    9.07  < 2e-16 ***
#   FoodTreatmentSatiated  -0.2602     0.0845   -3.08   0.0021 **
#   ArrivalTime            -0.0840     0.0190   -4.42  9.8e-06 ***

#Plot lsmeans by FoodTreatment
####nb: Extract lsmeans from glmmTMB with the helper function at start of
script ###

lsm.TMB<- lsmeans(zi.t, ~FoodTreatment)
plot(lsm.TMB)  #non-overlapping CI's

#Compare SE's
owls.lsm.zi #from ADMB
# FoodTreatment   lsmean        SE df asymp.LCL asymp.UCL
# Deprived      2.188727 0.7205142 NA 0.7765454  3.600909
# Satiated      1.928499 0.7498151 NA 0.4588887  3.398110


lsm.TMB
# FoodTreatment   lsmean         SE df asymp.LCL asymp.UCL
# Deprived      2.188720 0.06118962 NA  2.068790  2.308649
# Satiated      1.928498 0.08419132 NA  1.763486  2.093510

#lsmeans are identical but SE's differ by factor of 9 to 12?!


#######################################################
###2. Without zero inflation ###########################
###################################################

m.nb<- glmmadmb(NCalls~FoodTreatment+ArrivalTime+
                  +(1|Nest),
                data=Owls,
                zeroInflation=FALSE,
                family="nbinom")
summary(m.nb)
# Estimate Std. Error z value Pr(>|z|)
# (Intercept)             4.9101     0.6334    7.75  9.1e-15 ***
#   FoodTreatmentSatiated  -0.6924     0.1069   -6.48  9.4e-11 ***
#   ArrivalTime            -0.1154     0.0253   -4.57  4.9e-06 ***
#Plot lsmeans by FoodTreatment
owls.lsm<-lsmeans(m.nb, ~FoodTreatment)
owls.lsm
# FoodTreatment   lsmean        SE df  asymp.LCL asymp.UCL
# Deprived      2.053073 0.8952071 NA  0.2984988  3.807646
# Satiated      1.360690 0.9037320 NA -0.4105918  3.131973

plot(owls.lsm)
#95% confidence bands overlap almost entirely

#Confirm with predict.glmmadmb:
New.data<-expand.grid(FoodTreatment= levels(Owls$FoodTreatment),
                      ArrivalTime = mean(Owls$ArrivalTime))

#Get standard errors:
calls.pred<- predict(m.nb, New.data, re.form = NA, se.fit = TRUE)
calls.pred<-data.frame(calls.pred)
New.data$NCalls <- calls.pred$fit
New.data$SE<-calls.pred$se.fit
New.data
# FoodTreatment ArrivalTime   NCalls        SE
# 1      Deprived    24.75763 2.053073 0.8952071
# 2      Satiated    24.75763 1.360690 0.9037320
#Matches with lsmeans output



##################  Compare glmmADMB fit to glmmTDMB  ####################
m.nb2<- glmmTMB(NCalls~FoodTreatment+ArrivalTime+
                  +(1|Nest),
                data=Owls,
                family="nbinom2")
summary(m.nb2)
# Estimate Std. Error z value Pr(>|z|)
# (Intercept)            4.91011    0.63343   7.752 9.07e-15 ***
#   FoodTreatmentSatiated -0.69238    0.10692  -6.476 9.44e-11 ***
#   ArrivalTime           -0.11540    0.02526  -4.569 4.90e-06 ***

#Compare to glmmADMB model:Fixed effects are identical
summary(m.nb)
# Estimate Std. Error z value Pr(>|z|)
# (Intercept)             4.9101     0.6334    7.75  9.1e-15 ***
#   FoodTreatmentSatiated  -0.6924     0.1069   -6.48  9.4e-11 ***
#   ArrivalTime            -0.1154     0.0253   -4.57  4.9e-06 ***

#Plot lsmeans by FoodTreatment
lsm.TMB<- lsmeans(m.nb2, ~FoodTreatment)
plot(lsm.TMB)  #non-overlapping CI's

#Compare SE's
owls.lsm
# FoodTreatment   lsmean        SE df  asymp.LCL asymp.UCL
# Deprived      2.053073 0.8952071 NA  0.2984988  3.807646
# Satiated      1.360690 0.9037320 NA -0.4105918  3.131973

lsm.TMB
# FoodTreatment   lsmean        SE df asymp.LCL asymp.UCL
# Deprived      2.053065 0.1068562 NA  1.843631  2.262500
# Satiated      1.360683 0.1161322 NA  1.133068  1.588298

#lsmeans are identical but SE's differ by factor of 8?!


##Compare to lme4 fit:
library(lme4)

nb4<-glmer.nb(NCalls~FoodTreatment+ArrivalTime+
                +(1|Nest),
              data=Owls)

#Convergence warning
nb4.lsm<-lsmeans(nb4, ~FoodTreatment)

plot(nb4.lsm) #well-separated, glmmADMB SE's seem to be anomalous?

### Seems that differences in SE's are similar regardless of zero inflation


#######################################################
###3. Without random effects ###########################
###################################################

###ADMB
No.re.admb<- glmmadmb(NCalls~FoodTreatment+ArrivalTime,
                      data=Owls,
                      zeroInflation=FALSE,
                      family="nbinom")

###TMB
No.re.tmb<- glmmTMB(NCalls~FoodTreatment+ArrivalTime,
                    data=Owls,
                    family="nbinom2")
  #Models fit quickly with no random effect !

#Confirm that fixed effects are identical:
fixef(No.re.admb)
# (Intercept) FoodTreatmentSatiated           ArrivalTime
# 5.1002637            -0.4855420            -0.1221893
fixef(No.re.tmb)
# (Intercept)  FoodTreatmentSatiated            ArrivalTime
# 5.1002                -0.4855                -0.1222

##lsmeans
lsm.a<-lsmeans(No.re.admb, ~FoodTreatment)
lsm.a
# FoodTreatment   lsmean        SE df  asymp.LCL asymp.UCL
# Deprived      2.075145 0.8920297 NA  0.3267991  3.823491
# Satiated      1.589603 0.8984394 NA -0.1713057  3.350512
lsm.t<-lsmeans(No.re.tmb, ~FoodTreatment)
lsm.t
# FoodTreatment   lsmean         SE df asymp.LCL asymp.UCL
# Deprived      2.075137 0.06685284 NA  1.944108  2.206166
# Satiated      1.589594 0.07356489 NA  1.445410  1.733779

#Here there is >10x difference in SE's !!

par(mfrow=c(2,1))
plot(lsm.a)
plot(lsm.t)
#quite different


## The irony here is that pairwise comparisons,
  #i.e., uncertainty for the DIFFERENCES... are the same ##
lsmeans(No.re.admb, pairwise~FoodTreatment)
# $contrasts
# contrast            estimate       SE df z.ratio p.value
# Deprived - Satiated 0.485542 0.099399 NA   4.885  <.0001

lsmeans(No.re.tmb, pairwise~FoodTreatment)
# $contrasts
# contrast             estimate         SE df z.ratio p.value
# Deprived - Satiated 0.4855427 0.09939888 NA   4.885  <.0001

#######################################################
###4. With poisson family model ###########################
###################################################

poi.a <- glmmadmb(NCalls~FoodTreatment+ArrivalTime + (1|Nest),
                 data=Owls,
                 zeroInflation=FALSE,
                 family="poisson")

poi.t<- glmmTMB(NCalls ~FoodTreatment+ArrivalTime + (1|Nest),
                    data=Owls,
                family="poisson")

##Compare fixed effects and SE's
summary(poi.a)
# Estimate Std. Error z value Pr(>|z|)
# (Intercept)            5.155380   0.245960   20.96   <2e-16 ***
#   FoodTreatmentSatiated -0.590390   0.035959  -16.42   <2e-16 ***
#   ArrivalTime           -0.129272   0.009261  -13.96   <2e-16 ***
summary(poi.t)
# Estimate Std. Error z value Pr(>|z|)
# (Intercept)            5.32204    0.25689    20.7   <2e-16 ***
#   FoodTreatmentSatiated -0.66440    0.03726   -17.8   <2e-16 ***
#   ArrivalTime           -0.13642    0.00962   -14.2   <2e-16 ***

#Estimates and SE's slightly different but not vastly different


(lsm.poi.a<- lsmeans(poi.a, pairwise ~ FoodTreatment))
# FoodTreatment   lsmean        SE df asymp.LCL asymp.UCL
# Deprived      1.944592 0.3577493 NA 1.2434164  2.645768
# Satiated      1.280187 0.3607572 NA 0.5731162  1.987258

# contrast             estimate      SE df z.ratio p.value
# Deprived - Satiated 0.6644048 0.03726 NA  17.832  <.0001

(lsm.poi.t<- lsmeans(poi.t, pairwise ~ FoodTreatment))
# FoodTreatment   lsmean         SE df asymp.LCL asymp.UCL
# Deprived      1.954918 0.09723980 NA  1.764332  2.145505
# Satiated      1.364529 0.09908944 NA  1.170317  1.558740

# contrast             estimate        SE df z.ratio p.value
# Deprived - Satiated 0.5903898 0.0359587 NA  16.419  <.0001

plot(lsm.poi.a$lsmeans)
plot(lsm.poi.t$lsmeans)

###Same pattern as for negative binomial.
##lsmeans SE's are 3x bigger for ADMB, but contrast SE's are similar


#Compare to glmer:
poi.lme <- glmer(NCalls~FoodTreatment+ArrivalTime + (1|Nest),
                  data=Owls,
                  family="poisson")
#plot all three:
par(mfrow=c(1,3))
plot(lsm.poi.a$lsmeans)
plot(lsm.poi.t$lsmeans)
plot(lsmeans(poi.lme, pairwise~FoodTreatment)$lsmeans)
#Again the glmmadmb estimates differ from those for glmmTMB and glmer




On Sun, May 28, 2017 at 7:59 PM, Ben Bolker <bbolker at gmail.com> wrote:

> I will look this over more carefully if/when I get time, to see what
> the differences are between the ways in which lme4, glmmADMB, and
> glmmTMB implement the building blocks that lsmeans uses. But I can't
> guarantee I will get to it soon ... essentially, I'll just have to
> pick through the implementation of lsm.basis for glmmTMB and glmmADMB
> and see what the differences are ... it would help to try this on some
> cases without zero-inflation and without any random effects at all, to
> see where the discrepancies are coming from.
>
>
> On Sun, May 28, 2017 at 5:20 PM, Evan Palmer-Young <ecp52 at cornell.edu>
> wrote:
> > Thank you for this suggestion; it looks like you already implemented what
> > Prof. Maindonald suggested.
> >
> > In your (RVL's) J. Stat Software article on lsmeans
> > <https://www.jstatsoft.org/article/view/v069i01>, Section 5.1, you
> wrote:
> >
> >
> > * Note that it is a mistake to try to use confidence intervals to judge
> > comparisons. In this example, the standard errors of comparisons are much
> > smaller than those of the LS means, because the between-block and
> > between-plot variations cancel out in the comparisons. *
> >
> > I think that this is what John Maindonald indicated, too.
> >
> > Is it possible that some packages (glmmADMB?) provide predict() estimates
> > that include the random-effect variance referred to in the quotation, and
> > others do not? Or that some produce confidence intervals whereas others
> > produce prediction intervals (i.e., by addition of the residual
> variance),
> > as differentiated in the glmm FAQ
> > <https://github.com/bbolker/mixedmodels-misc/blob/master/
> glmmFAQ.rmd#predictions-andor-confidence-or-prediction-
> intervals-on-predictions>,
> > section on Prediction and Confidence Intervals?
> >
> > I posted a query to the glmmADMB
> > <https://github.com/bbolker/glmmadmb/issues/5> Github page, to see if
> > somebody with more familiarity to the package might be able to explain
> > nuances or difference. This thread has been cross-referenced with that
> > question.
> >
> > Thank you again for your patience and thorough explanations!
> > Much appreciated,
> > Evan
> >
> >
> > On Sun, May 28, 2017 at 12:00 AM, Lenth, Russell V <
> russell-lenth at uiowa.edu>
> > wrote:
> >
> >> If the SE of a mean is exactly 1/2 the SE of the difference of two means
> >> -- which is almost never the case -- it would be appropriate to use
> >> overlapping confidence intervals to test comparisons of means. So, you
> >> should almost never try to do that. In mixed models, it is not at all
> >> unusual to have huge discrepancies among standard errors.
> >>
> >> However, 'lsmeans' does offer an ad hoc method for the graphical
> >> comparisons you have in mind. Try this:
> >>
> >>     lsm.TMB<- lsmeans(m.nb2, ~FoodTreatment)
> >>     plot(lsm.TMB, comparisons = TRUE)
> >>
> >> This will plot both confidence intervals (in blue) and "comparison
> arrows"
> >> (in red). Non-overlapping comparison arrows will indicate cases where
> >> differences are significant. You can have just the comparison arrows by
> >> using:
> >>
> >>     plot(lsm.TMB, intervals = FALSE, comparisons = TRUE)
> >>
> >> In either case, as I say, it is an ad hoc method, and it doesn't always
> >> work, especially when there are widely variable standard errors. A
> warning
> >> is issued if it can't figure out a solution.
> >>
> >> Russ
> >> --
> >> Russell V. Lenth  -  Professor Emeritus
> >> Department of Statistics and Actuarial Science
> >> The University of Iowa  -  Iowa City, IA 52242  USA
> >> Voice (319)335-0712  -  FAX (319)335-3017
> >> russell-lenth at uiowa.edu  -  http://www.stat.uiowa.edu/~rlenth/
> >>
> >>
> >>
> >> -----Original Message-----
> >>
> >> Date: Fri, 26 May 2017 17:29:52 -0400
> >> From: Evan Palmer-Young <ecp52 at cornell.edu>
> >> To: John Maindonald <john.maindonald at anu.edu.au>
> >> Cc: R-mixed models mailing list <r-sig-mixed-models at r-project.org>
> >> Subject: Re: [R-sig-ME] wider than expected confidence intervals with
> >>         lsmeans and predict.glmmadmb
> >> Message-ID:
> >>         <CAAge6+7v1KY=8GLNqi1Hzg4zyQY0kfSjGvMXM-rhRFC9ER8Kcw at mail.
> >> gmail.com>
> >> Content-Type: text/plain; charset="UTF-8"
> >>
> >> Thanks very much for your reply, Prof. Maindonald.
> >>
> >> I agree that the pairwise comparisons are informative, but it would be
> >> easiest for readers to see the data on the original scale to show
> >> differences between groups.
> >>
> >> When the lsmeans are plotted from glmmTMB, which fits a model with fixed
> >> effects identical to those in glmmADMB, the estimates are identical but
> the
> >> SE's differ by a factor of 8.
> >>
> >> So I am still confused about why the lsmeans plots would reflect
> pairwise
> >> differences with some packages but not with glmmADMB.
> >> In my experience, lsmeans plots of group means from glmer() models are
> >> also non-overlapping when pairwise comparisons are highly significant.
> >>
> >> I have extended the code to illustrate the differences.
> >>
> >> library(glmmADMB)
> >>
> >> library(lsmeans)
> >>
> >> #Use data from worked example
> >> #http://glmmadmb.r-forge.r-project.org/glmmADMB.html
> >>
> >> library(glmmADMB)
> >> data(Owls)
> >> str(Owls)
> >> Owls <- transform(Owls,
> >>                   Nest=reorder(Nest,NegPerChick),
> >>                   logBroodSize=log(BroodSize),
> >>                   NCalls=SiblingNegotiation)
> >>
> >>
> >> m.nb<- glmmadmb(NCalls~FoodTreatment+ArrivalTime+
> >>            +(1|Nest),
> >>          data=Owls,
> >>          zeroInflation=FALSE,
> >>          family="nbinom")
> >> summary(m.nb)
> >> # Estimate Std. Error z value Pr(>|z|)
> >> # (Intercept)             4.2674     0.4705    9.07  < 2e-16 ***
> >> #   FoodTreatmentSatiated  -0.2602     0.0845   -3.08   0.0021 **
> >> #   ArrivalTime            -0.0840     0.0190   -4.42  9.8e-06 ***
> >> #Plot lsmeans by FoodTreatment
> >> owls.lsm<-lsmeans(m.nb, ~FoodTreatment)
> >> owls.lsm
> >> # FoodTreatment   lsmean        SE df asymp.LCL asymp.UCL
> >> # Deprived      2.188727 0.7205142 NA 0.7765454  3.600909
> >> # Satiated      1.928499 0.7498151 NA 0.4588887  3.398110
> >> #SE is much higher than for fixed effects in model
> >>
> >> plot(owls.lsm)
> >>  #95% confidence bands overlap almost entirely
> >>
> >> #Confirm with predict.glmmadmb:
> >> New.data<-expand.grid(FoodTreatment= levels(Owls$FoodTreatment),
> >>                       ArrivalTime = mean(Owls$ArrivalTime))
> >>
> >> New.data$NCalls <- predict(m.nb, New.data, re.form=NA, SE.fit = TRUE)
> >>
> >> #Get standard errors:
> >> calls.pred<- predict(m.nb, New.data, re.form = NA, se.fit = TRUE)
> >> calls.pred<-data.frame(calls.pred)
> >>
> >> New.data$SE<-calls.pred$se.fit
> >> New.data
> >> # FoodTreatment ArrivalTime   NCalls        SE
> >> # 1      Deprived    24.75763 2.188727 0.7205142
> >> # 2      Satiated    24.75763 1.928499 0.7498151
> >> #Matches with lsmeans output
> >>
> >>
> >>
> >> ##################  Compare to glmmTDMB  ####################
> >> #install.packages("glmmTMB")
> >> library(glmmTMB)
> >> m.nb2<- glmmTMB(NCalls~FoodTreatment+ArrivalTime+
> >>                   +(1|Nest),
> >>                 data=Owls,
> >>                 family="nbinom2")
> >> summary(m.nb2)
> >> # Estimate Std. Error z value Pr(>|z|)
> >> # (Intercept)            4.91011    0.63343   7.752 9.07e-15 ***
> >> #   FoodTreatmentSatiated -0.69238    0.10692  -6.476 9.44e-11 ***
> >> #   ArrivalTime           -0.11540    0.02526  -4.569 4.90e-06 ***
> >>
> >> #Compare to glmmADMB model:Fixed effects are identical
> >> summary(m.nb)
> >> # Estimate Std. Error z value Pr(>|z|)
> >> # (Intercept)             4.9101     0.6334    7.75  9.1e-15 ***
> >> #   FoodTreatmentSatiated  -0.6924     0.1069   -6.48  9.4e-11 ***
> >> #   ArrivalTime            -0.1154     0.0253   -4.57  4.9e-06 ***
> >>
> >> #Plot lsmeans by FoodTreatment
> >> owls.lsm<-lsmeans(m.nb2, ~FoodTreatment) #oops, lsmeans can't use
> glmmTMB
> >> object!
> >>
> >>   ########   Interlude   #######
> >> #Ben Bolker wrote a function to talk to lsmeans-- incredible!
> >> # https://github.com/glmmTMB/glmmTMB/issues/205
> >> recover.data.glmmTMB <- function(object, ...) {
> >>   fcall <- getCall(object)
> >>   recover.data(fcall,delete.response(terms(object)),
> >>                attr(model.frame(object),"na.action"), ...) }
> >> lsm.basis.glmmTMB <- function (object, trms, xlev, grid, vcov.,
> >>                                mode = "asymptotic", component="cond",
> ...)
> >> {
> >>   if (mode != "asymptotic") stop("only asymptotic mode is available")
> >>   if (component != "cond") stop("only tested for conditional component")
> >>   if (missing(vcov.))
> >>     V <- as.matrix(vcov(object)[[component]])
> >>   else V <- as.matrix(.my.vcov(object, vcov.))
> >>   dfargs = misc = list()
> >>   if (mode == "asymptotic") {
> >>     dffun = function(k, dfargs) NA
> >>   }
> >>   ## use this? misc = .std.link.labels(family(object), misc)
> >>   contrasts = attr(model.matrix(object), "contrasts")
> >>   m = model.frame(trms, grid, na.action = na.pass, xlev = xlev)
> >>   X = model.matrix(trms, m, contrasts.arg = contrasts)
> >>   bhat = fixef(object)[[component]]
> >>   if (length(bhat) < ncol(X)) {
> >>     kept = match(names(bhat), dimnames(X)[[2]])
> >>     bhat = NA * X[1, ]
> >>     bhat[kept] = fixef(object)[[component]]
> >>     modmat = model.matrix(trms, model.frame(object), contrasts.arg =
> >> contrasts)
> >>     nbasis = estimability::nonest.basis(modmat)
> >>   }
> >>   else nbasis = estimability::all.estble
> >>   list(X = X, bhat = bhat, nbasis = nbasis, V = V, dffun = dffun,
> >>        dfargs = dfargs, misc = misc)
> >> }
> >>
> >> #####   End interlude ###
> >>
> >> lsm.TMB<- lsmeans(m.nb2, ~FoodTreatment)
> >> plot(lsm.TMB)  #non-overlapping CI's
> >>
> >> #Compare SE's
> >> owls.lsm
> >> # FoodTreatment   lsmean       * SE* df  asymp.LCL asymp.UCL
> >> # Deprived      2.053073 *0.8952071* NA  0.2984988  3.807646
> >> # Satiated      1.360690 *0.9037320 *NA -0.4105918  3.131973
> >>
> >> lsm.TMB
> >> # FoodTreatment   lsmean        *SE* df asymp.LCL asymp.UCL
> >> # Deprived      2.053065 *0.1068562* NA  1.843631  2.262500
> >> # Satiated      1.360683 *0.1161322* NA  1.133068  1.588298
> >>
> >> #lsmeans are identical but SE's differ by factor of 8?!
> >>
> >>
> >> Thank you again.
> >> Evan
> >>
> >
> >
> >
> > --
> > Evan Palmer-Young
> > PhD candidate
> > Department of Biology
> > 221 Morrill Science Center
> > 611 North Pleasant St
> > Amherst MA 01003
> > https://scholar.google.com/citations?user=VGvOypoAAAAJ&hl=en
> > https://sites.google.com/a/cornell.edu/evan-palmer-young/
> > epalmery at cns.umass.edu
> > ecp52 at cornell.edu
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Evan Palmer-Young
PhD candidate
Department of Biology
221 Morrill Science Center
611 North Pleasant St
Amherst MA 01003
https://scholar.google.com/citations?user=VGvOypoAAAAJ&hl=en
https://sites.google.com/a/cornell.edu/evan-palmer-young/
epalmery at cns.umass.edu
ecp52 at cornell.edu

	[[alternative HTML version deleted]]


From maaz.gardezi at gmail.com  Tue May 30 06:16:48 2017
From: maaz.gardezi at gmail.com (Maaz Gardezi)
Date: Mon, 29 May 2017 23:16:48 -0500
Subject: [R-sig-ME] statistical significance of group level intercepts in
	glmer
Message-ID: <CAKGyKvCkWNhLu113pWHOVRP07VeYfBvjbnNe6CgN+9_=2WMcoQ@mail.gmail.com>

Hello,

I am using glmer to model a mixed effects logistic regression. The output
below shows the random intercepts and slope (zcwcexp) for 22 groups. I was
wondering if there is any way of finding whether these are statistically
significant?

> ranef(addRandomCrossLevelInteraction)
$subject
   (Intercept)      zcwcexp
1   0.08913319 -0.007245956
2  -0.06997405  0.009194926
3  -0.77408045  0.247743815
4   0.07087457  0.048671025
5   0.16529502 -0.025846944
6   0.21978190  0.020381977
7   0.22628857 -0.060421227
8   0.67790616 -0.183998656
9   0.25113625 -0.109811064
10 -0.14569194 -0.039863882
11  0.13872081 -0.074646309
12 -0.23401794  0.069596589
13  0.96193273 -0.195829039
14 -0.46834542  0.092182158
15 -0.59465656  0.158177344
16 -0.06963680 -0.019127508
17 -0.25015416  0.067321201
18  0.32001648 -0.100452172
19 -0.40396733  0.120731775
20  0.07413768 -0.061477287
21 -0.08520228  0.044519621
22 -0.09427640  0.002166830

Thanks!

Maaz

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue May 30 16:00:08 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 30 May 2017 10:00:08 -0400
Subject: [R-sig-ME] statistical significance of group level intercepts
	in glmer
In-Reply-To: <CAKGyKvCkWNhLu113pWHOVRP07VeYfBvjbnNe6CgN+9_=2WMcoQ@mail.gmail.com>
References: <CAKGyKvCkWNhLu113pWHOVRP07VeYfBvjbnNe6CgN+9_=2WMcoQ@mail.gmail.com>
Message-ID: <CABghstS4vdupT9qU3DP-Ux8hxuE_uPT6YKsO0cYVHfsYsy=V4g@mail.gmail.com>

Unfortunately, you *can't* test significance of conditional modes (the
values that ranef()) returns; this is the price you pay for treating
them as random variables. However, you *can* extract the 'conditional
variances' of the conditional modes (see p. 28 of the vignette that
comes with lme4).  You can visualize these conditional variances via
`lattice::dotplot(ranef(fitted_model,condVar=TRUE))`.  The development
version of lme4 (on Github) has an as.data.frame method that makes it
easier to extract these values ...


On Tue, May 30, 2017 at 12:16 AM, Maaz Gardezi <maaz.gardezi at gmail.com> wrote:
> Hello,
>
> I am using glmer to model a mixed effects logistic regression. The output
> below shows the random intercepts and slope (zcwcexp) for 22 groups. I was
> wondering if there is any way of finding whether these are statistically
> significant?
>
>> ranef(addRandomCrossLevelInteraction)
> $subject
>    (Intercept)      zcwcexp
> 1   0.08913319 -0.007245956
> 2  -0.06997405  0.009194926
> 3  -0.77408045  0.247743815
> 4   0.07087457  0.048671025
> 5   0.16529502 -0.025846944
> 6   0.21978190  0.020381977
> 7   0.22628857 -0.060421227
> 8   0.67790616 -0.183998656
> 9   0.25113625 -0.109811064
> 10 -0.14569194 -0.039863882
> 11  0.13872081 -0.074646309
> 12 -0.23401794  0.069596589
> 13  0.96193273 -0.195829039
> 14 -0.46834542  0.092182158
> 15 -0.59465656  0.158177344
> 16 -0.06963680 -0.019127508
> 17 -0.25015416  0.067321201
> 18  0.32001648 -0.100452172
> 19 -0.40396733  0.120731775
> 20  0.07413768 -0.061477287
> 21 -0.08520228  0.044519621
> 22 -0.09427640  0.002166830
>
> Thanks!
>
> Maaz
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From maaz.gardezi at gmail.com  Wed May 31 06:23:46 2017
From: maaz.gardezi at gmail.com (Maaz Gardezi)
Date: Tue, 30 May 2017 23:23:46 -0500
Subject: [R-sig-ME] statistical significance of group level intercepts
	in glmer
In-Reply-To: <CABghstS4vdupT9qU3DP-Ux8hxuE_uPT6YKsO0cYVHfsYsy=V4g@mail.gmail.com>
References: <CAKGyKvCkWNhLu113pWHOVRP07VeYfBvjbnNe6CgN+9_=2WMcoQ@mail.gmail.com>
 <CABghstS4vdupT9qU3DP-Ux8hxuE_uPT6YKsO0cYVHfsYsy=V4g@mail.gmail.com>
Message-ID: <CAKGyKvD6a-ReXKZ=Y68qekeO3cW0wy1Y7TOVwvuuET2OaD4hxg@mail.gmail.com>

Thanks for the clarification.

Maaz

On May 30, 2017 9:00 AM, "Ben Bolker" <bbolker at gmail.com> wrote:

> Unfortunately, you *can't* test significance of conditional modes (the
> values that ranef()) returns; this is the price you pay for treating
> them as random variables. However, you *can* extract the 'conditional
> variances' of the conditional modes (see p. 28 of the vignette that
> comes with lme4).  You can visualize these conditional variances via
> `lattice::dotplot(ranef(fitted_model,condVar=TRUE))`.  The development
> version of lme4 (on Github) has an as.data.frame method that makes it
> easier to extract these values ...
>
>
> On Tue, May 30, 2017 at 12:16 AM, Maaz Gardezi <maaz.gardezi at gmail.com>
> wrote:
> > Hello,
> >
> > I am using glmer to model a mixed effects logistic regression. The output
> > below shows the random intercepts and slope (zcwcexp) for 22 groups. I
> was
> > wondering if there is any way of finding whether these are statistically
> > significant?
> >
> >> ranef(addRandomCrossLevelInteraction)
> > $subject
> >    (Intercept)      zcwcexp
> > 1   0.08913319 -0.007245956
> > 2  -0.06997405  0.009194926
> > 3  -0.77408045  0.247743815
> > 4   0.07087457  0.048671025
> > 5   0.16529502 -0.025846944
> > 6   0.21978190  0.020381977
> > 7   0.22628857 -0.060421227
> > 8   0.67790616 -0.183998656
> > 9   0.25113625 -0.109811064
> > 10 -0.14569194 -0.039863882
> > 11  0.13872081 -0.074646309
> > 12 -0.23401794  0.069596589
> > 13  0.96193273 -0.195829039
> > 14 -0.46834542  0.092182158
> > 15 -0.59465656  0.158177344
> > 16 -0.06963680 -0.019127508
> > 17 -0.25015416  0.067321201
> > 18  0.32001648 -0.100452172
> > 19 -0.40396733  0.120731775
> > 20  0.07413768 -0.061477287
> > 21 -0.08520228  0.044519621
> > 22 -0.09427640  0.002166830
> >
> > Thanks!
> >
> > Maaz
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From b.pelzer at maw.ru.nl  Wed May 31 10:37:38 2017
From: b.pelzer at maw.ru.nl (Ben Pelzer)
Date: Wed, 31 May 2017 10:37:38 +0200
Subject: [R-sig-ME] glmmPQL: std.errors in summary and vcov differ
In-Reply-To: <CAKGyKvD6a-ReXKZ=Y68qekeO3cW0wy1Y7TOVwvuuET2OaD4hxg@mail.gmail.com>
References: <CAKGyKvCkWNhLu113pWHOVRP07VeYfBvjbnNe6CgN+9_=2WMcoQ@mail.gmail.com>
 <CABghstS4vdupT9qU3DP-Ux8hxuE_uPT6YKsO0cYVHfsYsy=V4g@mail.gmail.com>
 <CAKGyKvD6a-ReXKZ=Y68qekeO3cW0wy1Y7TOVwvuuET2OaD4hxg@mail.gmail.com>
Message-ID: <ef7b1808-0fee-99cf-cbb0-9e822dbfb2e5@maw.ru.nl>

Dear list,

With glmmPQL from package MASS,  I ran a logistic regression model with 
an intercept only, which is random across 33 countries:

m1 <- glmmPQL(MATH_Top1 ~ 1,
               random = list(country = ~ 1),
               family=binomial, data=pisas)
summary(m1)
sqrt(vcov(m1))

There is a total of N=22997 students in data.frame pisas.

The summary(m1) functions shows:

Fixed effects: MATH_Top1 ~ 1
                 Value Std.Error    DF  t-value p-value
(Intercept) -2.176564 0.1140811 22964 -19.0791       0


whereas the sqrt(vcov(m1)) function shows:

             (Intercept)
(Intercept)   0.1140786


My question is why the two std. error estimates 0.1140811 and 0.1140786 
of the fixed part of the intercept differ slightly. The same holds for 
std. errors of the fixed effects of predictor variables, which I did not 
add above for reasons of simplicity. Thanks for any help!

Ben.



	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed May 31 13:40:56 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 31 May 2017 07:40:56 -0400
Subject: [R-sig-ME] glmmPQL: std.errors in summary and vcov differ
In-Reply-To: <ef7b1808-0fee-99cf-cbb0-9e822dbfb2e5@maw.ru.nl>
References: <CAKGyKvCkWNhLu113pWHOVRP07VeYfBvjbnNe6CgN+9_=2WMcoQ@mail.gmail.com>
 <CABghstS4vdupT9qU3DP-Ux8hxuE_uPT6YKsO0cYVHfsYsy=V4g@mail.gmail.com>
 <CAKGyKvD6a-ReXKZ=Y68qekeO3cW0wy1Y7TOVwvuuET2OaD4hxg@mail.gmail.com>
 <ef7b1808-0fee-99cf-cbb0-9e822dbfb2e5@maw.ru.nl>
Message-ID: <CABghstQSpqicGeYwz+WLqFrwvp8kJjsNvdDQgyOy-iuot51Ftw@mail.gmail.com>

A reproducible example would be nice.  On the other hand, we can
reproduce this with the example in ?glmmPQL:


library(MASS)
g1 <- glmmPQL(y ~ trt + I(week > 2), random = ~ 1 | ID,
                      family = binomial, data = bacteria)
s1 <- summary(g1)$tTab[,"Std.Error"]
s2 <- sqrt(diag(vcov(g1)))
all.equal(s1,s2)
## [1] "Mean relative difference: 0.009132611"

Let's dig in to see what's happening. As a starting point, class(g1)
is c("glmmPQL","lme"), and if we look at methods("vcov"),
methods("summary"), we can see there are no glmmPQL methods, so these
computations are being handled by nlme:::summary.lme and
nlme:::vcov.lme

vcov.lme is

object$varFix

summary.lme has

stdFixed <- sqrt(diag(as.matrix(object$varFix)))
  if (adjustSigma && object$method == "ML")
        stdFixed <- stdFixed * sqrt(object$dims$N/(object$dims$N -
            length(stdFixed)))

So what's happening is that vcov() is giving you the uncorrected
(maximum likelihood) estimate of the variance-covariance matrix, while
summary is giving you the bias-corrected version.  Since your sample
size is large, the difference is tiny.


On Wed, May 31, 2017 at 4:37 AM, Ben Pelzer <b.pelzer at maw.ru.nl> wrote:
> Dear list,
>
> With glmmPQL from package MASS,  I ran a logistic regression model with
> an intercept only, which is random across 33 countries:
>
> m1 <- glmmPQL(MATH_Top1 ~ 1,
>                random = list(country = ~ 1),
>                family=binomial, data=pisas)
> summary(m1)
> sqrt(vcov(m1))
>
> There is a total of N=22997 students in data.frame pisas.
>
> The summary(m1) functions shows:
>
> Fixed effects: MATH_Top1 ~ 1
>                  Value Std.Error    DF  t-value p-value
> (Intercept) -2.176564 0.1140811 22964 -19.0791       0
>
>
> whereas the sqrt(vcov(m1)) function shows:
>
>              (Intercept)
> (Intercept)   0.1140786
>
>
> My question is why the two std. error estimates 0.1140811 and 0.1140786
> of the fixed part of the intercept differ slightly. The same holds for
> std. errors of the fixed effects of predictor variables, which I did not
> add above for reasons of simplicity. Thanks for any help!
>
> Ben.
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From burwood70 at gmail.com  Wed May 31 14:55:04 2017
From: burwood70 at gmail.com (Steve Candy)
Date: Wed, 31 May 2017 22:55:04 +1000
Subject: [R-sig-ME]  glmmPQL: std.errors in summary and vcov differ
Message-ID: <00c501d2da0d$2307a7e0$6916f7a0$@gmail.com>

Hi Ben

 

I just noticed a similar problem with lme( ) when using the method="ML"
option. The summary(lmeObject) parameter SEs and  diag(lmeObject
$varFix)^0.5 do not exactly match whereas they do if the "REML" option is
used. See below. This doesn't entire explain what's going on, since the
default option in lme() is method="REML", so the default option in the call
of lme() from glmmPQL should also be method="REML". Unless somehow its been
set as "ML" by glmmPQL. It might be worth using the control option or in
"further arguments for lme" to specify the method in lme() explicitly
through glmmPQL . Either way it would be good to find out why there is this
mismatch for method="ML".

 

> lme.01r <- lme(fixed=varDV  ~ Condition_f+Time_f+Condition_f:Time_f,
method="REML", random=~1 | PRE_Class/ID_f, 

+                    data=data_CrepA)

> 

> summary(lme.01r)

Linear mixed-effects model fit by REML

Data: data_CrepA 

       AIC      BIC    logLik

  2949.689 3023.109 -1459.845

 

Random effects:

Formula: ~1 | PRE_Class

        (Intercept)

StdDev:   0.2882176

 

Formula: ~1 | ID_f %in% PRE_Class

        (Intercept) Residual

StdDev:   0.7799864 0.848057

 

Fixed effects: varDV ~ Condition_f + Time_f + Condition_f:Time_f 

                            Value Std.Error  DF   t-value p-value

(Intercept)             1.6042292 0.2287389 715  7.013363  0.0000

 

...snip

 

> (summary(lme.01r)$tTable)[1,]

       Value    Std.Error           DF      t-value      p-value 

1.604229e+00 2.287389e-01 7.150000e+02 7.013363e+00 5.400002e-12 

> lme.01r$coefficients$fixed[1]

(Intercept) 

   1.604229 

            0.01312038             0.02010276             0.01336595
0.02042342             0.02986909             0.04595728

> lme.01r$varFix[1,1]^0.5

[1] 0.2287389

> sqrt(vcov(lme.01r)[1,1])

[1] 0.2287389

> ### SE the same as the summary output

 

> Now use ML

> 

> lme.01r <- lme(fixed=varDV  ~ Condition_f+Time_f+Condition_f:Time_f,
method="ML", random=~1 | PRE_Class/ID_f, 

+                    data=data_CrepA)

> summary(lme.01r)

Linear mixed-effects model fit by maximum likelihood

Data: data_CrepA 

       AIC      BIC    logLik

  2922.624 2996.225 -1446.312

 

Random effects:

Formula: ~1 | PRE_Class

        (Intercept)

StdDev:   0.2415063

 

Formula: ~1 | ID_f %in% PRE_Class

        (Intercept)  Residual

StdDev:   0.7810628 0.8428382

 

Fixed effects: varDV ~ Condition_f + Time_f + Condition_f:Time_f 

                            Value Std.Error  DF   t-value p-value

(Intercept)             1.5993361 0.2107460 715  7.588926  0.0000

 

...snip

 

> (summary(lme.01r)$tTable)[1,]

       Value    Std.Error           DF      t-value      p-value 

1.599336e+00 2.107460e-01 7.150000e+02 7.588926e+00 1.008003e-13 

> lme.01r$coefficients$fixed[1]

(Intercept) 

   1.599336 

> lme.01r$varFix[1,1]^0.5

[1] 0.2094765

> sqrt(vcov(lme.01r)[1,1])

[1] 0.2094765

> ### SE NOT the same as the summary output

 

>Dear list,

 

>With glmmPQL from package MASS,  I ran a logistic regression model with an
intercept only, which is random across 33 countries:

 

.snip

 

>>The summary(m1) functions shows:

>>Fixed effects: MATH_Top1 ~ 1

>>               Value Std.Error    DF  t-value p-value

>>(Intercept) -2.176564 0.1140811 22964 -19.0791       0

 

>>whereas the sqrt(vcov(m1)) function shows:

 

>>           (Intercept)

>>(Intercept)   0.1140786

 

>>My question is why the two std. error estimates 0.1140811 and 0.1140786 of
the fixed part of the intercept differ slightly. The same holds for std.
errors of the fixed effects >>of predictor variables, which I did not add
above for reasons of simplicity. Thanks for any help!

 

>>Ben.

 

Dr Steven G. Candy

Director/Consultant

SCANDY STATISTICAL MODELLING PTY LTD

(ABN: 83 601 268 419)

70 Burwood Drive

Blackmans Bay, TASMANIA, Australia 7052

Mobile: (61) 0439284983

 


	[[alternative HTML version deleted]]


From emaildemetrius at gmail.com  Wed May 31 14:57:54 2017
From: emaildemetrius at gmail.com (=?UTF-8?Q?Dem=C3=A9trius_Martins?=)
Date: Wed, 31 May 2017 13:57:54 +0100
Subject: [R-sig-ME] Partitioning species and environment effects MCMCglmm
Message-ID: <CAPTQHyS3Vs7x1WjRdzRNoVdn8bBjFu9Qdb5VvMsyDNYPnzY47w@mail.gmail.com>

Dear
?list?
,

I'm working on plant traits and I want to partition the variance of each
trait by separating the species effect from the plot effect (i.e. place
where the sample was taken)
? ?
and residuals
.

I'm interested in how the traits covary, hence I'm
? ?
analysing the traits as a multiresponse model.

I have the following model:

# priors

priorwl.1<-list(R=list(V=diag(17), nu=16.002),G=list(G1=list(V=diag(17),
nu=16.002),

                                                     G2= list(V=diag(17),
nu=16.002) ))


#model


mod.bays.wl1<- MCMCglmm(  cbind (l_LMA, l_N.mg.g.1, l_C.mg.g.1,
l_Ca.mg.g.1, l_K.mg.g.1, l_Mg.mg.g.1, l_Na.mg.g.1, l_P.mg.g.1,w_WD, w_MC,
w_N.mg.g, w_C.mg.g, w_Ca.mg.g, w_K.mg.g, w_Mg.mg.g, w_Na.mg.g, w_P.mg.g) ~
trait -1

                          random=~ us(trait):Genus_species  +
us(trait):Plot,

                          rcov = ~ us(trait):units,

                          prior = priorwl.1,  family = rep("gaussian",17),
data=logdata,

                          burnin = 50000, nitt = 1050000, thin = 100, pr =
TRUE, slice=T)


I?m calculating the variance of each random term of the model as:


??
l_C.spvar<-mod.bays.wl1$VCV[,'traitl_C.mg.g.1:traitl_C.mg.g.1.Genus_species']
/  (mod.bays.wl1$VCV[,'traitl_C.mg.g.1:traitl_C.mg.g.1.Genus_species'] +


                        mod.bays.wl1$VCV[,'traitl_C.mg.g.
1:traitl_C.mg.g.1.Plot']+


mod.bays.wl1$VCV[,'traitl_C.mg.g.1:traitl_C.mg.g.1.units'])



l_C.plotvar<-mod.bays.wl1$VCV[,'traitl_C.mg.g.1:traitl_C.mg.g.1.Plot'] /
(mod.bays.wl1$VCV[,'traitl_C.mg.g.1:traitl_C.mg.g.1.Genus_species'] +


                 mod.bays.wl1$VCV[,'traitl_C.mg.g.1:traitl_C.mg.g.1.Plot']+


                              mod.bays.wl1$VCV[,'traitl_C.
mg.g.1:traitl_C.mg.g.1.units'])


l_C.resvar<-mod.bays.wl1$VCV[,'traitl_C.mg.g.1:traitl_C.mg.g.1.units'] /
 (mod.bays.wl1$VCV[,'traitl_C.mg.g.1:traitl_C.mg.g.1.Genus_species'] +


 mod.bays.wl1$VCV[,'traitl_C.mg.g.1:traitl_C.mg.g.1.Plot']+


 mod.bays.wl1$VCV[,'traitl_C.mg.g.1:traitl_C.mg.g.1.units'])



in this example
,
I?m calculating the variance of the two random effects and the residual on
the l_C.mg.g.1 trait.



I?ve done this to every single trait specified on the model, however
,
I get very similar effects (species, plot and residual) for every single
trait, for example:

?

l_C.plotvar

l_C.resvar

l_C.spvar

l_Ca.plotvar

l_Ca.resvar

l_Ca.spvar

l_K.plotvar

l_K.resvar

l_K.spvar

mean.var

0.8222

0.0772

0.1007

0.8181

0.0790

0.1029

0.8142

0.0802

0.1057

lower

0.6481

0.0076

0.0104

0.6418

0.0066

0.0086

0.6283

0.0073

0.0134

upper

0.9823

0.1543

0.2062

0.9777

0.1564

0.2052

0.9734

0.1587

0.2175
?


Column end
ing
? ?
with(plotvar) = plot effect

Column end
ing
? ?
with(restvar) = residual

Column end
?ing?
 with(spvar) = species effect
ing
with(spvar) = species effect



I don't know what I could be possibly doing wrong in this case. I
partitioned the variance of each trait by using the lme4 package and
extracted the variance of the random effects of each trait. The
? variance?
 differ drastically one from another
? across traits?
, hence I have very different results when using MCMCglmm and lme4.

?Does anybody know why variances of the traits are so similar??

I appreciate any guidance on this problem.

Best wishes,
Demetrius


*Dem?trius Martins*
PhD Student
Imperial College London
*?*

	[[alternative HTML version deleted]]


From raphael.ender at uni.li  Thu Jun  1 09:58:45 2017
From: raphael.ender at uni.li (Ender Raphael)
Date: Thu, 1 Jun 2017 07:58:45 +0000
Subject: [R-sig-ME] lme4 convergence warnings & model notation
Message-ID: <fa70aee02a4040bf9a16e49822965adf@uni.li>

Dear list readers and R enthusiasts,

I'm a master student working on a project about forecasting in the retail sector, using mixed effect models with the lme4 package.

Currently, I am dealing with 2 challenges which I would like to overcome.

(1) I am dealing with convergence warnings, which I am not sure how to interpret or overcome.
(2) I am not entirely sure if my model formulation is correct.

I would kindly like to guide you to my StackExchange post where I formulated and formatted my formulas, R output warnings, and model setup in detail for easier readability.

https://stats.stackexchange.com/questions/282719/convergence-errors-random-slope-notation
[https://cdn.sstatic.net/Sites/stats/img/apple-touch-icon at 2.png?v=344f57aa10cc]<https://stats.stackexchange.com/questions/282719/convergence-errors-random-slope-notation>

r - Convergence errors & Random slope notation - Cross Validated<https://stats.stackexchange.com/questions/282719/convergence-errors-random-slope-notation>
stats.stackexchange.com
The basic idea of my research is that I am replacing the independent variable "article" with the attributes of the article such as its brand or if it is glutenfree (gf) etc. to forecast future unit...

Best regards,
Raphael



	[[alternative HTML version deleted]]


From emaildemetrius at gmail.com  Thu Jun  1 16:41:34 2017
From: emaildemetrius at gmail.com (=?UTF-8?Q?Dem=C3=A9trius_Martins?=)
Date: Thu, 1 Jun 2017 15:41:34 +0100
Subject: [R-sig-ME] Fwd: Partitioning species and environment effects
	MCMCglmm
In-Reply-To: <CAPTQHyS3Vs7x1WjRdzRNoVdn8bBjFu9Qdb5VvMsyDNYPnzY47w@mail.gmail.com>
References: <CAPTQHyS3Vs7x1WjRdzRNoVdn8bBjFu9Qdb5VvMsyDNYPnzY47w@mail.gmail.com>
Message-ID: <CAPTQHyTxiUW-0EZn3HVpa1C2a0XTiANdob+H9B_SiSh7KmCW2w@mail.gmail.com>

??
Dear
?list?
,

I'm working on plant traits and I want to partition the variance of each
trait by separating the species effect from the plot effect (i.e. place
where the sample was taken)
? ?
and residuals
.

I'm interested in how the traits covary, hence I'm
? ?
analysing the traits as a multiresponse model.

I have the following model:

# priors

priorwl.1<-list(R=list(V=diag(17), nu=16.002),G=list(G1=list(V=diag(17),
nu=16.002),

                                                     G2= list(V=diag(17),
nu=16.002) ))


#model


mod.bays.wl1<- MCMCglmm(  cbind (l_LMA, l_N.mg.g.1, l_C.mg.g.1,
l_Ca.mg.g.1, l_K.mg.g.1, l_Mg.mg.g.1, l_Na.mg.g.1, l_P.mg.g.1,w_WD, w_MC,
w_N.mg.g, w_C.mg.g, w_Ca.mg.g, w_K.mg.g, w_Mg.mg.g, w_Na.mg.g, w_P.mg.g) ~
trait -1

                          random=~ us(trait):Genus_species  +
us(trait):Plot,

                          rcov = ~ us(trait):units,

                          prior = priorwl.1,  family = rep("gaussian",17),
data=logdata,

                          burnin = 50000, nitt = 1050000, thin = 100, pr =
TRUE, slice=T)


I?m calculating the variance of each random term of the model as:


??
l_C.spvar<-mod.bays.wl1$VCV[,'traitl_C.mg.g.1:traitl_C.mg.g.1.Genus_species']
/  (mod.bays.wl1$VCV[,'traitl_C.mg.g.1:traitl_C.mg.g.1.Genus_species'] +


                        mod.bays.wl1$VCV[,'traitl_C.mg.g.1:
traitl_C.mg.g.1.Plot']+


mod.bays.wl1$VCV[,'traitl_C.mg.g.1:traitl_C.mg.g.1.units'])



l_C.plotvar<-mod.bays.wl1$VCV[,'traitl_C.mg.g.1:traitl_C.mg.g.1.Plot'] /
(mod.bays.wl1$VCV[,'traitl_C.mg.g.1:traitl_C.mg.g.1.Genus_species'] +


                 mod.bays.wl1$VCV[,'traitl_C.mg.g.1:traitl_C.mg.g.1.Plot']+


                              mod.bays.wl1$VCV[,'traitl_C.mg
.g.1:traitl_C.mg.g.1.units'])


l_C.resvar<-mod.bays.wl1$VCV[,'traitl_C.mg.g.1:traitl_C.mg.g.1.units'] /
 (mod.bays.wl1$VCV[,'traitl_C.mg.g.1:traitl_C.mg.g.1.Genus_species'] +


 mod.bays.wl1$VCV[,'traitl_C.mg.g.1:traitl_C.mg.g.1.Plot']+


 mod.bays.wl1$VCV[,'traitl_C.mg.g.1:traitl_C.mg.g.1.units'])



in this example
,
I?m calculating the variance of the two random effects and the residual on
the l_C.mg.g.1 trait.



I?ve done this to every single trait specified on the model, however
,
I get very similar effects (species, plot and residual) for every single
trait, for example:

?

l_C.plotvar

l_C.resvar

l_C.spvar

l_Ca.plotvar

l_Ca.resvar

l_Ca.spvar

l_K.plotvar

l_K.resvar

l_K.spvar

mean.var

0.8222

0.0772

0.1007

0.8181

0.0790

0.1029

0.8142

0.0802

0.1057

lower

0.6481

0.0076

0.0104

0.6418

0.0066

0.0086

0.6283

0.0073

0.0134

upper

0.9823

0.1543

0.2062

0.9777

0.1564

0.2052

0.9734

0.1587

0.2175
?


Column end
ing
? ?
with(plotvar) = plot effect

Column end
ing
? ?
with(restvar) = residual

Column end
?ing?
 with(spvar) = species effect
ing
with(spvar) = species effect



I don't know what I could be possibly doing wrong in this case. I
partitioned the variance of each trait by using the lme4 package and
extracted the variance of the random effects of each trait. The
? variance?
 differ drastically one from another
? across traits?
, hence I have very different results when using MCMCglmm and lme4.

?Does anybody know why variances of the traits are so similar??

I appreciate any guidance on this problem.

Best wishes,
Demetrius


*Dem?trius Martins*
PhD Student
Imperial College London
*?*

	[[alternative HTML version deleted]]


From b.pelzer at maw.ru.nl  Thu Jun  1 18:20:47 2017
From: b.pelzer at maw.ru.nl (Ben Pelzer)
Date: Thu, 1 Jun 2017 18:20:47 +0200
Subject: [R-sig-ME] Formula df when combining imputed data
Message-ID: <d225728e-6884-166b-d9fc-5a4946d8e2e2@maw.ru.nl>

Dear list,

In a given dataset, I have 10 dichotomous variables, the missing values 
of which were substituted by multiple imputation techniques. For each 
variable, a glmmPQL model was estimated. The model has a random 
intercept across countries and schools-within-countries. For one of the 
10 variables the syntax is:

themodel <- glmmPQL( yvariable ~
1+Gender+AGE+migrant+rep+missing_rep+Schoolsize+Schoolmaterials+GDP,
                       random = list(country = ~ 1, CNTSCHID = ~ 1),
                       family=binomial, data=pisas)

The results show:

                     Value Std.Error    DF    t-value p-value
(Intercept)     -6.221943 0.9882684 15501  -6.295802  0.0000
Gender          -0.493744 0.0363663 15501 -13.576956  0.0000
AGE              0.177124 0.0612163 15501   2.893407  0.0038
migrant         -0.311810 0.0867452 15501  -3.594553  0.0003
rep             -2.510684 0.2342525 15501 -10.717855  0.0000
missing_rep     -1.986272 0.3907376 15501  -5.083390  0.0000
Schoolsize       0.000536 0.0000633  7699   8.470045  0.0000
Schoolmaterials  0.334300 0.0525469  7699   6.361938  0.0000
GDP              0.000013 0.0000081    31   1.598743  0.1200


I ran this model for each of the 10 imputed variables and then combined 
the results using the method proposed by Rubin, which is also explained 
by Carlin et al. in fmwww.bc.edu/RePEc/bocode/c/carlin.pdf. Equation (2) 
on page 4 shows how to calculate the nr. of df for t-tests for each 
regression coefficient. This is where I got stuck. Evaluating the 
formula for the df leads to the nr.'s of df below:

                             DF given equation (2)

(Intercept)       19.91120
Gender            18.75981
AGE               19.63237
migrant           21.30057
rep               28.47710
missing_rep      133.05131
Schoolsize       122.45054
Schoolmaterials   74.71955
GDP             7231.16666


As can be noticed, the df's in the above glmmPQL results are very 
different from those calculated by equation (2) mentioned by Carlin et 
al. in the Stata journal. I realize that the ones in the glmmPQL results 
cannot be entirely correct, due to the fact that the yvariable's 
missings were imputed and next analyzed as though it had no missings at 
all. But I'm wondering also if the df's calculated by equation (2) are 
the "better" ones, because the differences are so large. E.g. for GDP, 
which is a country-level variable, I would expect a low nr. of df's, as 
there are only 33 countries in the data. Could it be that the formula of 
equation (2) for the nr. of df cannot be used here? Or even worse: for a 
logistic model with random country and school effects, the method 
proposed by Rubin for calculating the std. errors of the regression 
coefficients is not really applicable?

Thanks for any advice!!
Ben Pelzer.

	[[alternative HTML version deleted]]


From b.pelzer at maw.ru.nl  Thu Jun  1 18:24:16 2017
From: b.pelzer at maw.ru.nl (Ben Pelzer)
Date: Thu, 1 Jun 2017 18:24:16 +0200
Subject: [R-sig-ME] Formula df when combining imputed data
In-Reply-To: <d225728e-6884-166b-d9fc-5a4946d8e2e2@maw.ru.nl>
References: <d225728e-6884-166b-d9fc-5a4946d8e2e2@maw.ru.nl>
Message-ID: <337e55de-44bd-c363-de6b-441910743de8@maw.ru.nl>

Sorry list, but I forgot to mention that the 10 variables where actually 
10 imputed versions of the same underlying variable, which has missings. 
Therefore, Rubin's method of combining regression results comes into the 
picture.

Ben Pelzer.

On 1-6-2017 18:20, Ben Pelzer wrote:
> Dear list,
>
> In a given dataset, I have 10 dichotomous variables, the missing values
> of which were substituted by multiple imputation techniques. For each
> variable, a glmmPQL model was estimated. The model has a random
> intercept across countries and schools-within-countries. For one of the
> 10 variables the syntax is:
>
> themodel <- glmmPQL( yvariable ~
> 1+Gender+AGE+migrant+rep+missing_rep+Schoolsize+Schoolmaterials+GDP,
>                         random = list(country = ~ 1, CNTSCHID = ~ 1),
>                         family=binomial, data=pisas)
>
> The results show:
>
>                       Value Std.Error    DF    t-value p-value
> (Intercept)     -6.221943 0.9882684 15501  -6.295802  0.0000
> Gender          -0.493744 0.0363663 15501 -13.576956  0.0000
> AGE              0.177124 0.0612163 15501   2.893407  0.0038
> migrant         -0.311810 0.0867452 15501  -3.594553  0.0003
> rep             -2.510684 0.2342525 15501 -10.717855  0.0000
> missing_rep     -1.986272 0.3907376 15501  -5.083390  0.0000
> Schoolsize       0.000536 0.0000633  7699   8.470045  0.0000
> Schoolmaterials  0.334300 0.0525469  7699   6.361938  0.0000
> GDP              0.000013 0.0000081    31   1.598743  0.1200
>
>
> I ran this model for each of the 10 imputed variables and then combined
> the results using the method proposed by Rubin, which is also explained
> by Carlin et al. in fmwww.bc.edu/RePEc/bocode/c/carlin.pdf. Equation (2)
> on page 4 shows how to calculate the nr. of df for t-tests for each
> regression coefficient. This is where I got stuck. Evaluating the
> formula for the df leads to the nr.'s of df below:
>
>                               DF given equation (2)
>
> (Intercept)       19.91120
> Gender            18.75981
> AGE               19.63237
> migrant           21.30057
> rep               28.47710
> missing_rep      133.05131
> Schoolsize       122.45054
> Schoolmaterials   74.71955
> GDP             7231.16666
>
>
> As can be noticed, the df's in the above glmmPQL results are very
> different from those calculated by equation (2) mentioned by Carlin et
> al. in the Stata journal. I realize that the ones in the glmmPQL results
> cannot be entirely correct, due to the fact that the yvariable's
> missings were imputed and next analyzed as though it had no missings at
> all. But I'm wondering also if the df's calculated by equation (2) are
> the "better" ones, because the differences are so large. E.g. for GDP,
> which is a country-level variable, I would expect a low nr. of df's, as
> there are only 33 countries in the data. Could it be that the formula of
> equation (2) for the nr. of df cannot be used here? Or even worse: for a
> logistic model with random country and school effects, the method
> proposed by Rubin for calculating the std. errors of the regression
> coefficients is not really applicable?
>
> Thanks for any advice!!
> Ben Pelzer.
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From crobinson19 at cub.uca.edu  Thu Jun  1 16:04:18 2017
From: crobinson19 at cub.uca.edu (Christopher Robinson)
Date: Thu, 1 Jun 2017 09:04:18 -0500
Subject: [R-sig-ME] Deviations from normality in MCMC models
Message-ID: <CAK8JCg+AeHK4FuPq7O98-=vMztJi4ts7m675WMqdy5Q2voWgfw@mail.gmail.com>

MCMCglmm users,

I am trying to quantify correlated thermal reaction norms using bivariate
MCMCglmm models in R. Unfortunately, one of my variables is highly right
skewed and I cannot get the data to take on a normal (gaussian)
distribution. I've attached a histogram showing how my data look.

The MCMCglmm package in R allows users to specify the distribution family
for each variable. Unfortunately, I cannot fit a gamma distribution to my
data because MCMCglmm currently does not support this family. My question
is how sensitive to deviations from normality is MCMC? That is, if I apply
a gaussian distribution to this variable, will my results be strongly
affected?

An example of my code is as follows:

prior<-list(R=list(V=diag(2),nu=1.002),
            G=list(G1=list(V=diag(2),nu=1.002)))

modelHB<-MCMCglmm(cbind(Sprint,HB)~trait-1,
                  random=~us(trait):ID,
                  rcov = ~us(trait):units,
                  family=c("gaussian", "gaussian"),
                  prior=prior,data=data3,nitt=NITT,thin=THIN,burnin=BURNIN)

Thank you for any advice.

-- 
Chris Robinson
robinsoncd.weebly.com

From ljrhurley at gmail.com  Thu Jun  1 20:29:39 2017
From: ljrhurley at gmail.com (landon hurley)
Date: Thu, 1 Jun 2017 14:29:39 -0400
Subject: [R-sig-ME] Deviations from normality in MCMC models
In-Reply-To: <CAK8JCg+AeHK4FuPq7O98-=vMztJi4ts7m675WMqdy5Q2voWgfw@mail.gmail.com>
References: <CAK8JCg+AeHK4FuPq7O98-=vMztJi4ts7m675WMqdy5Q2voWgfw@mail.gmail.com>
Message-ID: <cccb9b53-64de-0c1e-07c6-466fa8d72a45@gmail.com>

On 01/06/2017 10:04, Christopher Robinson wrote:
> The MCMCglmm package in R allows users to specify the distribution 
> family for each variable. Unfortunately, I cannot fit a gamma 
> distribution to my data because MCMCglmm currently does not support 
> this family. My question is how sensitive to deviations from 
> normality is MCMC? That is, if I apply a gaussian distribution to 
> this variable, will my results be strongly affected?

Chris,

Why not fit the normal model, cross-validate, and then decide if its
adequate? Depending upon the sample size of course, it may not make a
large difference in terms of choice of the prior, beyond support
constraints introduced for the variable being modelled if you used
something other than Gaussian.

If negative predicted responses are of a concern (assuming it's
truncated at zero), it looks like you could potentially use the censored
Gaussian family options, which would at least restrict you to the same
support as a Gamma distribution.




-- 
Violence is the last refuge of the incompetent.


From bbolker at gmail.com  Fri Jun  2 03:47:08 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 1 Jun 2017 21:47:08 -0400
Subject: [R-sig-ME] Deviations from normality in MCMC models
In-Reply-To: <cccb9b53-64de-0c1e-07c6-466fa8d72a45@gmail.com>
References: <CAK8JCg+AeHK4FuPq7O98-=vMztJi4ts7m675WMqdy5Q2voWgfw@mail.gmail.com>
 <cccb9b53-64de-0c1e-07c6-466fa8d72a45@gmail.com>
Message-ID: <62073996-ec11-be8e-6df1-2bcaca545296@gmail.com>


 In my experience it's *usually* the case that a log-Normal (i.e.,
log-transforming the variable and treating it as Normal) should be an
adequate substitute for a Gamma.  They have the same general qualitative
range of shapes. If the log-Normal is problematic/your log-transformed
data are far from Normal, then you're likely to have had similar
troubles with a Gamma. As one example, you have observations that are
exactly zero, then you can't log transform them -- but these don't work
with the Gamma either, as it has a log-likelihood density that is either
negative infinite, if the shape parameter is >1, or infinite, if the
shape parameter is <1.

On 17-06-01 02:29 PM, landon hurley wrote:
> On 01/06/2017 10:04, Christopher Robinson wrote:
>> The MCMCglmm package in R allows users to specify the distribution 
>> family for each variable. Unfortunately, I cannot fit a gamma	
>> distribution to my data because MCMCglmm currently does not support 
>> this family. My question is how sensitive to deviations from 
>> normality is MCMC? That is, if I apply a gaussian distribution to 
>> this variable, will my results be strongly affected?
> 
> Chris,
> 
> Why not fit the normal model, cross-validate, and then decide if its
> adequate? Depending upon the sample size of course, it may not make a
> large difference in terms of choice of the prior, beyond support
> constraints introduced for the variable being modelled if you used
> something other than Gaussian.
> 
> If negative predicted responses are of a concern (assuming it's
> truncated at zero), it looks like you could potentially use the censored
> Gaussian family options, which would at least restrict you to the same
> support as a Gamma distribution.
> 
> 
> 
>


From ecp52 at cornell.edu  Fri Jun  2 20:48:22 2017
From: ecp52 at cornell.edu (Evan Palmer-Young)
Date: Fri, 2 Jun 2017 14:48:22 -0400
Subject: [R-sig-ME] Deviations from normality in MCMC models
In-Reply-To: <62073996-ec11-be8e-6df1-2bcaca545296@gmail.com>
References: <CAK8JCg+AeHK4FuPq7O98-=vMztJi4ts7m675WMqdy5Q2voWgfw@mail.gmail.com>
 <cccb9b53-64de-0c1e-07c6-466fa8d72a45@gmail.com>
 <62073996-ec11-be8e-6df1-2bcaca545296@gmail.com>
Message-ID: <CAAge6+5OX6P1G4cGiL+2wY+CNA-LpuCtUC-r7T6u8oN4HNVuxg@mail.gmail.com>

Is it possible you could use the "exponential" family in mcmcglmm? It seems
to have a (negative) log link function, which could address the skew in
your data.
Reference this thread on exponential family in mcmcglmm
<https://stat.ethz.ch/pipermail/r-sig-mixed-models/2013q3/020851.html>

On Thu, Jun 1, 2017 at 9:47 PM, Ben Bolker <bbolker at gmail.com> wrote:

>
>  In my experience it's *usually* the case that a log-Normal (i.e.,
> log-transforming the variable and treating it as Normal) should be an
> adequate substitute for a Gamma.  They have the same general qualitative
> range of shapes. If the log-Normal is problematic/your log-transformed
> data are far from Normal, then you're likely to have had similar
> troubles with a Gamma. As one example, you have observations that are
> exactly zero, then you can't log transform them -- but these don't work
> with the Gamma either, as it has a log-likelihood density that is either
> negative infinite, if the shape parameter is >1, or infinite, if the
> shape parameter is <1.
>
> On 17-06-01 02:29 PM, landon hurley wrote:
> > On 01/06/2017 10:04, Christopher Robinson wrote:
> >> The MCMCglmm package in R allows users to specify the distribution
> >> family for each variable. Unfortunately, I cannot fit a gamma
> >> distribution to my data because MCMCglmm currently does not support
> >> this family. My question is how sensitive to deviations from
> >> normality is MCMC? That is, if I apply a gaussian distribution to
> >> this variable, will my results be strongly affected?
> >
> > Chris,
> >
> > Why not fit the normal model, cross-validate, and then decide if its
> > adequate? Depending upon the sample size of course, it may not make a
> > large difference in terms of choice of the prior, beyond support
> > constraints introduced for the variable being modelled if you used
> > something other than Gaussian.
> >
> > If negative predicted responses are of a concern (assuming it's
> > truncated at zero), it looks like you could potentially use the censored
> > Gaussian family options, which would at least restrict you to the same
> > support as a Gamma distribution.
> >
> >
> >
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Evan Palmer-Young
PhD candidate
Department of Biology
221 Morrill Science Center
611 North Pleasant St
Amherst MA 01003
https://scholar.google.com/citations?user=VGvOypoAAAAJ&hl=en
https://sites.google.com/a/cornell.edu/evan-palmer-young/
epalmery at cns.umass.edu
ecp52 at cornell.edu

	[[alternative HTML version deleted]]


From t.deimel at yahoo.de  Sun Jun  4 15:41:41 2017
From: t.deimel at yahoo.de (Thomas Deimel)
Date: Sun, 4 Jun 2017 14:41:41 +0100
Subject: [R-sig-ME] afex in missing data (when testing main effects in
 presence of interactions in factorial designs)
Message-ID: <27711403-2FED-42F7-8F3B-AEA9EE74E0C0@yahoo.de>

Hi everyone,

I am using lmer (or mixed() from the afex package) to implement a linear mixed model of the form 

y~1+x1+x2+x1:x2+(by-subject random effects),

where x1 and x2 are both categorical variables/factors. The design is balanced but there are missing values for some x2 levels in some of the subjects.

I am interested in testing the main effect of say x1 in the presence of the interaction term x1:x2. In order to achieve this, I convert x2 to a numeric variable using sum contrasts - as summarized for example [here][1]. This gives the same results for inference (nearly identical p-values) as using mixed() from the afex package. This corresponds to a "type III test".

The linked summary, however, mentions that the main effect we test essentially corresponds to the effect of x1 averaged over all levels of x2 (which I assume corresponds to x2=0 when converted to numeric and using true contrasts). But, there are missing data for y for some of the levels of x2 in some of the subjects, so how does this affect the averaging.

My Qs: Given the above implementation of the model,...

1) ...do missing values lead to putting a stronger weight on x2 levels that do not have missing values when averaging over x2 levels to calculate the main effect of x1? OR is R aware of that distortion and calculates a weighted average of some sort (I don't see how)?

2) ...is this a problem? I assume it could lead to distorted estimation of main effect significance in smaller data sets or if there are a lot of missing values for certain levels of x2?

3) ...is there a way around it, like forcing R to weighting the average? Or would it be advisable to compare y~x2 to y~x1+x2, instead? I would certainly be inclined to use this if the interaction was insignificant (agreed?) but what if it is significant? Any other options?

Thanks for the help,

Thomas






  [1]: https://arxiv.org/pdf/1405.2094.pdf "here"
	[[alternative HTML version deleted]]


From singmann at psychologie.uzh.ch  Mon Jun  5 12:15:19 2017
From: singmann at psychologie.uzh.ch (Henrik Singmann)
Date: Mon, 5 Jun 2017 12:15:19 +0200
Subject: [R-sig-ME] afex in missing data (when testing main effects in
 presence of interactions in factorial designs)
In-Reply-To: <27711403-2FED-42F7-8F3B-AEA9EE74E0C0@yahoo.de>
References: <27711403-2FED-42F7-8F3B-AEA9EE74E0C0@yahoo.de>
Message-ID: <581cd74a-ecb6-0cc7-9c5c-b25558106131@psychologie.uzh.ch>

Hi Thomas,

As afex is mentioned, let me weigh in with my thoughts (though I am as 
always happy for corrections).

First of all, afex implements basically the procedure described in the 
document by Roger Levy, when using the same type of tests (i.e., 
likelihood ratio tests). Using the second example in the document we get:

require(mvtnorm)
require(afex)
set.seed(1)
M <- 12
dat <- expand.grid(X=factor(c("x1","x2")),
                    Y=factor(c("y1","y2","y3")),
                    subj=factor(paste("S",1:M)),
                    item=factor(paste("I",1:M)))
dat$XY <- with(dat,factor(paste(X,Y)))
beta.XY <- matrix(c(1,4,5,2,3,3),2,3)
b.S <- rmvnorm(M,rep(0,6),diag(6)/100)
b.I <- rmvnorm(M,rep(0,6),diag(6)/100)
dat$Response <- with(dat,beta.XY[cbind(X,Y)] + b.S[cbind(subj,XY)] +
                        b.I[cbind(item,XY)] + rnorm(nrow(dat),sd=0.1))
Y.numeric <- sapply(dat$Y,function(i) contr.sum(3)[i,])
dat$Y1 <- Y.numeric[1,]
dat$Y2 <- Y.numeric[2,]
m0 <- lmer(Response ~ Y1 + X:Y1 + Y2 + X:Y2 + (XY|subj) + (XY|item),
            dat, REML = FALSE)
m1 <- lmer(Response ~ X*Y + (XY|subj) + (XY|item),dat, REML = FALSE)
anova(m0,m1)
# Data: dat
# Models:
# m0: Response ~ Y1 + X:Y1 + Y2 + X:Y2 + (XY | subj) + (XY | item)
# m1: Response ~ X * Y + (XY | subj) + (XY | item)
#    Df     AIC     BIC logLik deviance  Chisq Chi Df Pr(>Chisq)
# m0 48 -1040.6 -812.01 568.28  -1136.6
# m1 49 -1038.7 -805.35 568.33  -1136.7 0.0999      1      0.752

(mm1 <- mixed(Response ~ X*Y + (XY|subj) + (XY|item),dat,
               method = "LRT"))
# Mixed Model Anova Table (Type 3 tests, LRT-method)
#
# Model: Response ~ X * Y + (XY | subj) + (XY | item)
# Data: dat
# Df full model: 49
#   Effect df     Chisq p.value
# 1      X  1      0.10     .75
# 2      Y  2 66.06 ***  <.0001
# 3    X:Y  2 87.90 ***  <.0001
# ---
# Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?+? 0.1 ? ? 1

As can be seen, the test of x is identical with a chi-square value of 
0.0999 (rounded to 0.10) and a p-value of 0.75.

We can also see that the intercept correspond exactly to the grand mean:
fixef(mm1$full_model)[1]
# (Intercept)
#    3.006103

mean(dat$Response)
# [1] 3.006103

Your question is now what happens for unbalanced data. Type III tests 
(as implemented here and in the document) assume the imbalance is random 
and not structural (i.e., data is missing completely at random). This is 
achieved by weighting the cells equally and not the data points. In 
other words, we simply do the analysis assuming each cell (i.e., 
combination of factors) had the same size. As a consequence, the grand 
mean does not correspond to the grand mean of the data, but to the 
unweighted mean of the cells. (Note that this only holds approximately 
for mixed models, as the random effects also play a role here. For 
standard ANOVAs this is exactly true.)

An example can show this. We first remove one data point and then fit 
the data again (with a very reduced model as we are only interested in 
the intercept estimate here):

dat2 <- dat[-1,]

mm2 <- mixed(Response ~ X*Y + (1|subj),dat2, return="merMod")
fixef(mm2)[1]
# (Intercept)
#    3.006236

mean(dat2$Response)
# [1] 3.008559

mean(tapply(dat2$Response, INDEX = list(dat2$XY), mean))
# [1] 3.006254

As can be seen, the intercept corresponds approximately to the 
unweighted grand mean of all cells, but not to the grand mean of the data.

As said above, the small difference between the intercept and the grand 
mean are a consequence of the random effects. Change the random effects 
structure to the one above and you will see even more differences. 
Furthermore, for standard ANOVA Type III tests exactly correspond to the 
unweighted grand mean

What this tells us is that Type III tests are only appropriate if the 
missing is not structural but random. In other words, the treatment 
(i.e., condition levels) should not be the cause for the missing data 
for Type III tests. Type III test correct for missing data by simply 
treating the data as having no missing data (i.e., all cells are weighed 
equally).

If the missing were structural (i.e., a consequence of the factor 
levels) this approach is of course not appropriate. Then we would want 
to use something like Type II tests or what you describe in which the 
group sizes are taken into account and the intercept correspond to the 
grand mean. For example, for observational data where group sizes are 
very often informative Type II tests seem more appropriate.

I expect this difference in how Type II and Type III tests deal with 
imbalance is also one of the reasons why those statisticans that work a 
lot with observational data prefer Type II over Type III tests whereas 
those that work with experimental data (where imbalance is usually small 
and random) prefer Type III tests over Type II test.

Hope that helps,
Henrik

PS: It always helps to include some example data.

Am 04.06.2017 um 15:41 schrieb Thomas Deimel via R-sig-mixed-models:
> Hi everyone,
> 
> I am using lmer (or mixed() from the afex package) to implement a linear mixed model of the form
> 
> y~1+x1+x2+x1:x2+(by-subject random effects),
> 
> where x1 and x2 are both categorical variables/factors. The design is balanced but there are missing values for some x2 levels in some of the subjects.
> 
> I am interested in testing the main effect of say x1 in the presence of the interaction term x1:x2. In order to achieve this, I convert x2 to a numeric variable using sum contrasts - as summarized for example [here][1]. This gives the same results for inference (nearly identical p-values) as using mixed() from the afex package. This corresponds to a "type III test".
> 
> The linked summary, however, mentions that the main effect we test essentially corresponds to the effect of x1 averaged over all levels of x2 (which I assume corresponds to x2=0 when converted to numeric and using true contrasts). But, there are missing data for y for some of the levels of x2 in some of the subjects, so how does this affect the averaging.
> 
> My Qs: Given the above implementation of the model,...
> 
> 1) ...do missing values lead to putting a stronger weight on x2 levels that do not have missing values when averaging over x2 levels to calculate the main effect of x1? OR is R aware of that distortion and calculates a weighted average of some sort (I don't see how)?
> 
> 2) ...is this a problem? I assume it could lead to distorted estimation of main effect significance in smaller data sets or if there are a lot of missing values for certain levels of x2?
> 
> 3) ...is there a way around it, like forcing R to weighting the average? Or would it be advisable to compare y~x2 to y~x1+x2, instead? I would certainly be inclined to use this if the interaction was insignificant (agreed?) but what if it is significant? Any other options?
> 
> Thanks for the help,
> 
> Thomas
> 
> 
> 
> 
> 
> 
>    [1]: https://arxiv.org/pdf/1405.2094.pdf "here"
> 	[[alternative HTML version deleted]]
>


From jdelia82 at gmail.com  Mon Jun  5 18:10:37 2017
From: jdelia82 at gmail.com (Jesse Delia)
Date: Mon, 5 Jun 2017 12:10:37 -0400
Subject: [R-sig-ME] Predict and plot lines estimated from MCMCglmm?
Message-ID: <CA+LOm6G9-ZY56d_M2X0WEdf9ZxMwW19uxjuBMXi2VfQEuRwkuw@mail.gmail.com>

Dear list,

I am a grad student and am trying to plot the results of a comparative
field experiment. I've been struggling to figure out how predict and plot
lines estimated using MCMCglmm. I've read the course notes, spent several
days googling, and have been looking for downloadable script from
publications, with no luck. Does anyone know how to (or could point me in
the direction for an example) to plot lines for each of a 2-level predictor
after accounting for random effects using MCMCglmm?

I have pasted my script below, for which I am trying to evaluate how
evolutionary changes in parental care alter offspring survival. Ideally,
I'd like to plot a line for each type of 'careduration' (binary predictor)
over the raw data after accounting for random effects of phylogeny and
within species variation:

Prior<- list(R=list(V= 1e 10,nu=-1), G=list(G1=list(V=1,nu=1,alpha.mu=0,
alpha.V=25^2), G2=list(V=1,nu=1,alpha.mu=0,alpha.V=25^2)))

Model1<-MCMCglmm(cbind(mortality, clutchsize-mortality) ~careduration*
raindpo3, random=~species+animal, family ="multinomial2", ginverse=list(
animal=inv.phylo$Ainv), prior=prior1, data=data, nitt=3000000, burnin=10
00000, thin = 500, pr=TRUE)
One additional question: my response is a proportional estimate of egg
clutch mortality. There are lots of zeros, as many clutches did not
experience any mortality -- can "multinomial2" handle proportional data
with lots of zeros? I get similar results with the above model as I do
using a beta-binomial model using glmmADMB (and will present both models in
the publication).

Thanks for your time,

Jesse

	[[alternative HTML version deleted]]


From Phillip.Alday at mpi.nl  Tue Jun  6 15:31:38 2017
From: Phillip.Alday at mpi.nl (Alday, Phillip)
Date: Tue, 6 Jun 2017 13:31:38 +0000
Subject: [R-sig-ME] afex in missing data (when testing main effects in
 presence of interactions in factorial designs)
In-Reply-To: <581cd74a-ecb6-0cc7-9c5c-b25558106131@psychologie.uzh.ch>
References: <27711403-2FED-42F7-8F3B-AEA9EE74E0C0@yahoo.de>
 <581cd74a-ecb6-0cc7-9c5c-b25558106131@psychologie.uzh.ch>
Message-ID: <1496755898.4827.29.camel@mpi.nl>

Hi Henrik, hi Thomas,

There is one small additional footnote to add to the Type-II/Type-III
comparison:

Type-II tests respect the principle of marginality, while Type-III
tests do not. This is discussed somewhat in John Fox's Applied
Regression textbook and is one of the main points in Venables' Exegeses
on Linear Models.

https://www.stats.ox.ac.uk/pub/MASS3/Exegeses.pdf

In other words: Type-III tests allow you to test main effects as if the
interaction were not there, while Type-II tests incorporate both the
interaction and main effect into the test for the main effect. When the
data are balanced, this are the same. (If I have misunderstood this
point or formulated it infelicitously, I am happy to be corrected!)?

Best,
Phillip

On Mon, 2017-06-05 at 12:15 +0200, Henrik Singmann wrote:
> Hi Thomas,
> 
> As afex is mentioned, let me weigh in with my thoughts (though I am
> as?
> always happy for corrections).
> 
> First of all, afex implements basically the procedure described in
> the?
> document by Roger Levy, when using the same type of tests (i.e.,?
> likelihood ratio tests). Using the second example in the document we
> get:
> 
> require(mvtnorm)
> require(afex)
> set.seed(1)
> M <- 12
> dat <- expand.grid(X=factor(c("x1","x2")),
> ????????????????????Y=factor(c("y1","y2","y3")),
> ????????????????????subj=factor(paste("S",1:M)),
> ????????????????????item=factor(paste("I",1:M)))
> dat$XY <- with(dat,factor(paste(X,Y)))
> beta.XY <- matrix(c(1,4,5,2,3,3),2,3)
> b.S <- rmvnorm(M,rep(0,6),diag(6)/100)
> b.I <- rmvnorm(M,rep(0,6),diag(6)/100)
> dat$Response <- with(dat,beta.XY[cbind(X,Y)] + b.S[cbind(subj,XY)] +
> ????????????????????????b.I[cbind(item,XY)] +
> rnorm(nrow(dat),sd=0.1))
> Y.numeric <- sapply(dat$Y,function(i) contr.sum(3)[i,])
> dat$Y1 <- Y.numeric[1,]
> dat$Y2 <- Y.numeric[2,]
> m0 <- lmer(Response ~ Y1 + X:Y1 + Y2 + X:Y2 + (XY|subj) + (XY|item),
> ????????????dat, REML = FALSE)
> m1 <- lmer(Response ~ X*Y + (XY|subj) + (XY|item),dat, REML = FALSE)
> anova(m0,m1)
> # Data: dat
> # Models:
> # m0: Response ~ Y1 + X:Y1 + Y2 + X:Y2 + (XY | subj) + (XY | item)
> # m1: Response ~ X * Y + (XY | subj) + (XY | item)
> #????Df?????AIC?????BIC logLik deviance??Chisq Chi Df Pr(>Chisq)
> # m0 48 -1040.6 -812.01 568.28??-1136.6
> # m1 49 -1038.7 -805.35 568.33??-1136.7 0.0999??????1??????0.752
> 
> (mm1 <- mixed(Response ~ X*Y + (XY|subj) + (XY|item),dat,
> ???????????????method = "LRT"))
> # Mixed Model Anova Table (Type 3 tests, LRT-method)
> #
> # Model: Response ~ X * Y + (XY | subj) + (XY | item)
> # Data: dat
> # Df full model: 49
> #???Effect df?????Chisq p.value
> # 1??????X??1??????0.10?????.75
> # 2??????Y??2 66.06 ***??<.0001
> # 3????X:Y??2 87.90 ***??<.0001
> # ---
> # Signif. codes:??0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?+? 0.1 ? ? 1
> 
> As can be seen, the test of x is identical with a chi-square value
> of?
> 0.0999 (rounded to 0.10) and a p-value of 0.75.
> 
> We can also see that the intercept correspond exactly to the grand
> mean:
> fixef(mm1$full_model)[1]
> # (Intercept)
> #????3.006103
> 
> mean(dat$Response)
> # [1] 3.006103
> 
> Your question is now what happens for unbalanced data. Type III
> tests?
> (as implemented here and in the document) assume the imbalance is
> random?
> and not structural (i.e., data is missing completely at random). This
> is?
> achieved by weighting the cells equally and not the data points. In?
> other words, we simply do the analysis assuming each cell (i.e.,?
> combination of factors) had the same size. As a consequence, the
> grand?
> mean does not correspond to the grand mean of the data, but to the?
> unweighted mean of the cells. (Note that this only holds
> approximately?
> for mixed models, as the random effects also play a role here. For?
> standard ANOVAs this is exactly true.)
> 
> An example can show this. We first remove one data point and then
> fit?
> the data again (with a very reduced model as we are only interested
> in?
> the intercept estimate here):
> 
> dat2 <- dat[-1,]
> 
> mm2 <- mixed(Response ~ X*Y + (1|subj),dat2, return="merMod")
> fixef(mm2)[1]
> # (Intercept)
> #????3.006236
> 
> mean(dat2$Response)
> # [1] 3.008559
> 
> mean(tapply(dat2$Response, INDEX = list(dat2$XY), mean))
> # [1] 3.006254
> 
> As can be seen, the intercept corresponds approximately to the?
> unweighted grand mean of all cells, but not to the grand mean of the
> data.
> 
> As said above, the small difference between the intercept and the
> grand?
> mean are a consequence of the random effects. Change the random
> effects?
> structure to the one above and you will see even more differences.?
> Furthermore, for standard ANOVA Type III tests exactly correspond to
> the?
> unweighted grand mean
> 
> What this tells us is that Type III tests are only appropriate if
> the?
> missing is not structural but random. In other words, the treatment?
> (i.e., condition levels) should not be the cause for the missing
> data?
> for Type III tests. Type III test correct for missing data by simply?
> treating the data as having no missing data (i.e., all cells are
> weighed?
> equally).
> 
> If the missing were structural (i.e., a consequence of the factor?
> levels) this approach is of course not appropriate. Then we would
> want?
> to use something like Type II tests or what you describe in which
> the?
> group sizes are taken into account and the intercept correspond to
> the?
> grand mean. For example, for observational data where group sizes
> are?
> very often informative Type II tests seem more appropriate.
> 
> I expect this difference in how Type II and Type III tests deal with?
> imbalance is also one of the reasons why those statisticans that work
> a?
> lot with observational data prefer Type II over Type III tests
> whereas?
> those that work with experimental data (where imbalance is usually
> small?
> and random) prefer Type III tests over Type II test.
> 
> Hope that helps,
> Henrik
> 
> PS: It always helps to include some example data.
> 
> Am 04.06.2017 um 15:41 schrieb Thomas Deimel via R-sig-mixed-models:
> > 
> > Hi everyone,
> > 
> > I am using lmer (or mixed() from the afex package) to implement a
> > linear mixed model of the form
> > 
> > y~1+x1+x2+x1:x2+(by-subject random effects),
> > 
> > where x1 and x2 are both categorical variables/factors. The design
> > is balanced but there are missing values for some x2 levels in some
> > of the subjects.
> > 
> > I am interested in testing the main effect of say x1 in the
> > presence of the interaction term x1:x2. In order to achieve this, I
> > convert x2 to a numeric variable using sum contrasts - as
> > summarized for example [here][1]. This gives the same results for
> > inference (nearly identical p-values) as using mixed() from the
> > afex package. This corresponds to a "type III test".
> > 
> > The linked summary, however, mentions that the main effect we test
> > essentially corresponds to the effect of x1 averaged over all
> > levels of x2 (which I assume corresponds to x2=0 when converted to
> > numeric and using true contrasts). But, there are missing data for
> > y for some of the levels of x2 in some of the subjects, so how does
> > this affect the averaging.
> > 
> > My Qs: Given the above implementation of the model,...
> > 
> > 1) ...do missing values lead to putting a stronger weight on x2
> > levels that do not have missing values when averaging over x2
> > levels to calculate the main effect of x1? OR is R aware of that
> > distortion and calculates a weighted average of some sort (I don't
> > see how)?
> > 
> > 2) ...is this a problem? I assume it could lead to distorted
> > estimation of main effect significance in smaller data sets or if
> > there are a lot of missing values for certain levels of x2?
> > 
> > 3) ...is there a way around it, like forcing R to weighting the
> > average? Or would it be advisable to compare y~x2 to y~x1+x2,
> > instead? I would certainly be inclined to use this if the
> > interaction was insignificant (agreed?) but what if it is
> > significant? Any other options?
> > 
> > Thanks for the help,
> > 
> > Thomas
> > 
> > 
> > 
> > 
> > 
> > 
> > ???[1]: https://arxiv.org/pdf/1405.2094.pdf "here"
> > 	[[alternative HTML version deleted]]
> > 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From Phillip.Alday at mpi.nl  Tue Jun  6 12:34:45 2017
From: Phillip.Alday at mpi.nl (Alday, Phillip)
Date: Tue, 6 Jun 2017 10:34:45 +0000
Subject: [R-sig-ME] afex in missing data (when testing main effects in
 presence of interactions in factorial designs)
In-Reply-To: <581cd74a-ecb6-0cc7-9c5c-b25558106131@psychologie.uzh.ch>
References: <27711403-2FED-42F7-8F3B-AEA9EE74E0C0@yahoo.de>
 <581cd74a-ecb6-0cc7-9c5c-b25558106131@psychologie.uzh.ch>
Message-ID: <1496745284.4827.12.camel@mpi.nl>

Hi Henrik, hi Thomas,

There is one small additional footnote to add to the Type-II/Type-III
comparison:

Type-II tests respect the principle of marginality, while Type-III
tests do not. This is discussed somewhat in John Fox's Applied
Regression textbook and is one of the main points in?Venables' Exegeses
on Linear Models.

https://www.stats.ox.ac.uk/pub/MASS3/Exegeses.pdf

In other words: Type-III tests allow you to test main effects as if the
interaction were not there, while Type-II tests incorporate both the
interaction and main effect into the test for the main effect. When the
data are balanced, this are the same. (If I have misunderstood this
point or formulated it infelicitously, I am happy to be corrected!)?

Best,
Phillip

On Mon, 2017-06-05 at 12:15 +0200, Henrik Singmann wrote:
> Hi Thomas,
> 
> As afex is mentioned, let me weigh in with my thoughts (though I am
> as?
> always happy for corrections).
> 
> First of all, afex implements basically the procedure described in
> the?
> document by Roger Levy, when using the same type of tests (i.e.,?
> likelihood ratio tests). Using the second example in the document we
> get:
> 
> require(mvtnorm)
> require(afex)
> set.seed(1)
> M <- 12
> dat <- expand.grid(X=factor(c("x1","x2")),
> ????????????????????Y=factor(c("y1","y2","y3")),
> ????????????????????subj=factor(paste("S",1:M)),
> ????????????????????item=factor(paste("I",1:M)))
> dat$XY <- with(dat,factor(paste(X,Y)))
> beta.XY <- matrix(c(1,4,5,2,3,3),2,3)
> b.S <- rmvnorm(M,rep(0,6),diag(6)/100)
> b.I <- rmvnorm(M,rep(0,6),diag(6)/100)
> dat$Response <- with(dat,beta.XY[cbind(X,Y)] + b.S[cbind(subj,XY)] +
> ????????????????????????b.I[cbind(item,XY)] +
> rnorm(nrow(dat),sd=0.1))
> Y.numeric <- sapply(dat$Y,function(i) contr.sum(3)[i,])
> dat$Y1 <- Y.numeric[1,]
> dat$Y2 <- Y.numeric[2,]
> m0 <- lmer(Response ~ Y1 + X:Y1 + Y2 + X:Y2 + (XY|subj) + (XY|item),
> ????????????dat, REML = FALSE)
> m1 <- lmer(Response ~ X*Y + (XY|subj) + (XY|item),dat, REML = FALSE)
> anova(m0,m1)
> # Data: dat
> # Models:
> # m0: Response ~ Y1 + X:Y1 + Y2 + X:Y2 + (XY | subj) + (XY | item)
> # m1: Response ~ X * Y + (XY | subj) + (XY | item)
> #????Df?????AIC?????BIC logLik deviance??Chisq Chi Df Pr(>Chisq)
> # m0 48 -1040.6 -812.01 568.28??-1136.6
> # m1 49 -1038.7 -805.35 568.33??-1136.7 0.0999??????1??????0.752
> 
> (mm1 <- mixed(Response ~ X*Y + (XY|subj) + (XY|item),dat,
> ???????????????method = "LRT"))
> # Mixed Model Anova Table (Type 3 tests, LRT-method)
> #
> # Model: Response ~ X * Y + (XY | subj) + (XY | item)
> # Data: dat
> # Df full model: 49
> #???Effect df?????Chisq p.value
> # 1??????X??1??????0.10?????.75
> # 2??????Y??2 66.06 ***??<.0001
> # 3????X:Y??2 87.90 ***??<.0001
> # ---
> # Signif. codes:??0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?+? 0.1 ? ? 1
> 
> As can be seen, the test of x is identical with a chi-square value
> of?
> 0.0999 (rounded to 0.10) and a p-value of 0.75.
> 
> We can also see that the intercept correspond exactly to the grand
> mean:
> fixef(mm1$full_model)[1]
> # (Intercept)
> #????3.006103
> 
> mean(dat$Response)
> # [1] 3.006103
> 
> Your question is now what happens for unbalanced data. Type III
> tests?
> (as implemented here and in the document) assume the imbalance is
> random?
> and not structural (i.e., data is missing completely at random). This
> is?
> achieved by weighting the cells equally and not the data points. In?
> other words, we simply do the analysis assuming each cell (i.e.,?
> combination of factors) had the same size. As a consequence, the
> grand?
> mean does not correspond to the grand mean of the data, but to the?
> unweighted mean of the cells. (Note that this only holds
> approximately?
> for mixed models, as the random effects also play a role here. For?
> standard ANOVAs this is exactly true.)
> 
> An example can show this. We first remove one data point and then
> fit?
> the data again (with a very reduced model as we are only interested
> in?
> the intercept estimate here):
> 
> dat2 <- dat[-1,]
> 
> mm2 <- mixed(Response ~ X*Y + (1|subj),dat2, return="merMod")
> fixef(mm2)[1]
> # (Intercept)
> #????3.006236
> 
> mean(dat2$Response)
> # [1] 3.008559
> 
> mean(tapply(dat2$Response, INDEX = list(dat2$XY), mean))
> # [1] 3.006254
> 
> As can be seen, the intercept corresponds approximately to the?
> unweighted grand mean of all cells, but not to the grand mean of the
> data.
> 
> As said above, the small difference between the intercept and the
> grand?
> mean are a consequence of the random effects. Change the random
> effects?
> structure to the one above and you will see even more differences.?
> Furthermore, for standard ANOVA Type III tests exactly correspond to
> the?
> unweighted grand mean
> 
> What this tells us is that Type III tests are only appropriate if
> the?
> missing is not structural but random. In other words, the treatment?
> (i.e., condition levels) should not be the cause for the missing
> data?
> for Type III tests. Type III test correct for missing data by simply?
> treating the data as having no missing data (i.e., all cells are
> weighed?
> equally).
> 
> If the missing were structural (i.e., a consequence of the factor?
> levels) this approach is of course not appropriate. Then we would
> want?
> to use something like Type II tests or what you describe in which
> the?
> group sizes are taken into account and the intercept correspond to
> the?
> grand mean. For example, for observational data where group sizes
> are?
> very often informative Type II tests seem more appropriate.
> 
> I expect this difference in how Type II and Type III tests deal with?
> imbalance is also one of the reasons why those statisticans that work
> a?
> lot with observational data prefer Type II over Type III tests
> whereas?
> those that work with experimental data (where imbalance is usually
> small?
> and random) prefer Type III tests over Type II test.
> 
> Hope that helps,
> Henrik
> 
> PS: It always helps to include some example data.
> 
> Am 04.06.2017 um 15:41 schrieb Thomas Deimel via R-sig-mixed-models:
> > 
> > Hi everyone,
> > 
> > I am using lmer (or mixed() from the afex package) to implement a
> > linear mixed model of the form
> > 
> > y~1+x1+x2+x1:x2+(by-subject random effects),
> > 
> > where x1 and x2 are both categorical variables/factors. The design
> > is balanced but there are missing values for some x2 levels in some
> > of the subjects.
> > 
> > I am interested in testing the main effect of say x1 in the
> > presence of the interaction term x1:x2. In order to achieve this, I
> > convert x2 to a numeric variable using sum contrasts - as
> > summarized for example [here][1]. This gives the same results for
> > inference (nearly identical p-values) as using mixed() from the
> > afex package. This corresponds to a "type III test".
> > 
> > The linked summary, however, mentions that the main effect we test
> > essentially corresponds to the effect of x1 averaged over all
> > levels of x2 (which I assume corresponds to x2=0 when converted to
> > numeric and using true contrasts). But, there are missing data for
> > y for some of the levels of x2 in some of the subjects, so how does
> > this affect the averaging.
> > 
> > My Qs: Given the above implementation of the model,...
> > 
> > 1) ...do missing values lead to putting a stronger weight on x2
> > levels that do not have missing values when averaging over x2
> > levels to calculate the main effect of x1? OR is R aware of that
> > distortion and calculates a weighted average of some sort (I don't
> > see how)?
> > 
> > 2) ...is this a problem? I assume it could lead to distorted
> > estimation of main effect significance in smaller data sets or if
> > there are a lot of missing values for certain levels of x2?
> > 
> > 3) ...is there a way around it, like forcing R to weighting the
> > average? Or would it be advisable to compare y~x2 to y~x1+x2,
> > instead? I would certainly be inclined to use this if the
> > interaction was insignificant (agreed?) but what if it is
> > significant? Any other options?
> > 
> > Thanks for the help,
> > 
> > Thomas
> > 
> > 
> > 
> > 
> > 
> > 
> > ???[1]: https://arxiv.org/pdf/1405.2094.pdf "here"
> > 	[[alternative HTML version deleted]]
> > 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From M.Fairbrother at bristol.ac.uk  Wed Jun  7 11:54:14 2017
From: M.Fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Wed, 7 Jun 2017 10:54:14 +0100
Subject: [R-sig-ME] Predict and plot lines estimated from MCMCglmm?
Message-ID: <CAAH-yP_jZ7tkXq0U-12C4F30MgRm_pBsfooEuRiLNC5-9HVAmQ@mail.gmail.com>

Hi Jesse,

This is an application in a completely unrelated substantive domain of
research, but you can find code to plot (ggplot) the results of MCMCglmm
fits in the Supplementary Material here:
https://www.sociologicalscience.com/articles-v3-17-359/

Maybe that will help you out.

Best wishes,
Malcolm



Dr Malcolm Fairbrother
Reader in Global Policy and Politics
School of Geographical Sciences  ?  Cabot Institute  ?  Centre for
Multilevel Modelling
University of Bristol

*As of later in 2017:*
Professor of Sociology
Ume? University
Sweden





> Date: Mon, 5 Jun 2017 12:10:37 -0400
> From: Jesse Delia <jdelia82 at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Predict and plot lines estimated from MCMCglmm?
>
> Dear list,
>
> I am a grad student and am trying to plot the results of a comparative
> field experiment. I've been struggling to figure out how predict and plot
> lines estimated using MCMCglmm. I've read the course notes, spent several
> days googling, and have been looking for downloadable script from
> publications, with no luck. Does anyone know how to (or could point me in
> the direction for an example) to plot lines for each of a 2-level predictor
> after accounting for random effects using MCMCglmm?
>
> I have pasted my script below, for which I am trying to evaluate how
> evolutionary changes in parental care alter offspring survival. Ideally,
> I'd like to plot a line for each type of 'careduration' (binary predictor)
> over the raw data after accounting for random effects of phylogeny and
> within species variation:
>
> Prior<- list(R=list(V= 1e 10,nu=-1), G=list(G1=list(V=1,nu=1,alpha.mu=0,
> alpha.V=25^2), G2=list(V=1,nu=1,alpha.mu=0,alpha.V=25^2)))
>
> Model1<-MCMCglmm(cbind(mortality, clutchsize-mortality) ~careduration*
> raindpo3, random=~species+animal, family ="multinomial2", ginverse=list(
> animal=inv.phylo$Ainv), prior=prior1, data=data, nitt=3000000, burnin=10
> 00000, thin = 500, pr=TRUE)
> One additional question: my response is a proportional estimate of egg
> clutch mortality. There are lots of zeros, as many clutches did not
> experience any mortality -- can "multinomial2" handle proportional data
> with lots of zeros? I get similar results with the above model as I do
> using a beta-binomial model using glmmADMB (and will present both models in
> the publication).
>
> Thanks for your time,
>
> Jesse
>

	[[alternative HTML version deleted]]


From t.deimel at yahoo.de  Sat Jun 10 21:31:27 2017
From: t.deimel at yahoo.de (Thomas Deimel)
Date: Sat, 10 Jun 2017 20:31:27 +0100
Subject: [R-sig-ME] afex in missing data (when testing main effects in
 presence of interactions in factorial designs)
In-Reply-To: <1496745284.4827.12.camel@mpi.nl>
References: <27711403-2FED-42F7-8F3B-AEA9EE74E0C0@yahoo.de>
 <581cd74a-ecb6-0cc7-9c5c-b25558106131@psychologie.uzh.ch>
 <1496745284.4827.12.camel@mpi.nl>
Message-ID: <4858046E-7FC3-48EF-A753-45FCD98A14AD@yahoo.de>

Hi Henrik and Phillip,

thanks a lot for the detailed answers and making use of the example to explain. This has already been very useful and helped to clear up what I think were misunderstandings on my part. 

I have been playing around with the example some more and for my current purposes, I think this is enough. I do still have loads of further questions about this issue in general, though, and my brain normally does not like to let go of questions it has stumbled upon. So, should I find the time to get my Qs in order and do some more reading-up first, I hope it?s ok, if I come back to ask them.

Best,

Thomas




> Am 06.06.2017 um 11:34 schrieb Alday, Phillip <Phillip.Alday at mpi.nl>:
> 
> Hi Henrik, hi Thomas,
> 
> There is one small additional footnote to add to the Type-II/Type-III
> comparison:
> 
> Type-II tests respect the principle of marginality, while Type-III
> tests do not. This is discussed somewhat in John Fox's Applied
> Regression textbook and is one of the main points in Venables' Exegeses
> on Linear Models.
> 
> https://www.stats.ox.ac.uk/pub/MASS3/Exegeses.pdf
> 
> In other words: Type-III tests allow you to test main effects as if the
> interaction were not there, while Type-II tests incorporate both the
> interaction and main effect into the test for the main effect. When the
> data are balanced, this are the same. (If I have misunderstood this
> point or formulated it infelicitously, I am happy to be corrected!) 
> 
> Best,
> Phillip
> 
> On Mon, 2017-06-05 at 12:15 +0200, Henrik Singmann wrote:
>> Hi Thomas,
>> 
>> As afex is mentioned, let me weigh in with my thoughts (though I am
>> as 
>> always happy for corrections).
>> 
>> First of all, afex implements basically the procedure described in
>> the 
>> document by Roger Levy, when using the same type of tests (i.e., 
>> likelihood ratio tests). Using the second example in the document we
>> get:
>> 
>> require(mvtnorm)
>> require(afex)
>> set.seed(1)
>> M <- 12
>> dat <- expand.grid(X=factor(c("x1","x2")),
>>                     Y=factor(c("y1","y2","y3")),
>>                     subj=factor(paste("S",1:M)),
>>                     item=factor(paste("I",1:M)))
>> dat$XY <- with(dat,factor(paste(X,Y)))
>> beta.XY <- matrix(c(1,4,5,2,3,3),2,3)
>> b.S <- rmvnorm(M,rep(0,6),diag(6)/100)
>> b.I <- rmvnorm(M,rep(0,6),diag(6)/100)
>> dat$Response <- with(dat,beta.XY[cbind(X,Y)] + b.S[cbind(subj,XY)] +
>>                         b.I[cbind(item,XY)] +
>> rnorm(nrow(dat),sd=0.1))
>> Y.numeric <- sapply(dat$Y,function(i) contr.sum(3)[i,])
>> dat$Y1 <- Y.numeric[1,]
>> dat$Y2 <- Y.numeric[2,]
>> m0 <- lmer(Response ~ Y1 + X:Y1 + Y2 + X:Y2 + (XY|subj) + (XY|item),
>>             dat, REML = FALSE)
>> m1 <- lmer(Response ~ X*Y + (XY|subj) + (XY|item),dat, REML = FALSE)
>> anova(m0,m1)
>> # Data: dat
>> # Models:
>> # m0: Response ~ Y1 + X:Y1 + Y2 + X:Y2 + (XY | subj) + (XY | item)
>> # m1: Response ~ X * Y + (XY | subj) + (XY | item)
>> #    Df     AIC     BIC logLik deviance  Chisq Chi Df Pr(>Chisq)
>> # m0 48 -1040.6 -812.01 568.28  -1136.6
>> # m1 49 -1038.7 -805.35 568.33  -1136.7 0.0999      1      0.752
>> 
>> (mm1 <- mixed(Response ~ X*Y + (XY|subj) + (XY|item),dat,
>>                method = "LRT"))
>> # Mixed Model Anova Table (Type 3 tests, LRT-method)
>> #
>> # Model: Response ~ X * Y + (XY | subj) + (XY | item)
>> # Data: dat
>> # Df full model: 49
>> #   Effect df     Chisq p.value
>> # 1      X  1      0.10     .75
>> # 2      Y  2 66.06 ***  <.0001
>> # 3    X:Y  2 87.90 ***  <.0001
>> # ---
>> # Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?+? 0.1 ? ? 1
>> 
>> As can be seen, the test of x is identical with a chi-square value
>> of 
>> 0.0999 (rounded to 0.10) and a p-value of 0.75.
>> 
>> We can also see that the intercept correspond exactly to the grand
>> mean:
>> fixef(mm1$full_model)[1]
>> # (Intercept)
>> #    3.006103
>> 
>> mean(dat$Response)
>> # [1] 3.006103
>> 
>> Your question is now what happens for unbalanced data. Type III
>> tests 
>> (as implemented here and in the document) assume the imbalance is
>> random 
>> and not structural (i.e., data is missing completely at random). This
>> is 
>> achieved by weighting the cells equally and not the data points. In 
>> other words, we simply do the analysis assuming each cell (i.e., 
>> combination of factors) had the same size. As a consequence, the
>> grand 
>> mean does not correspond to the grand mean of the data, but to the 
>> unweighted mean of the cells. (Note that this only holds
>> approximately 
>> for mixed models, as the random effects also play a role here. For 
>> standard ANOVAs this is exactly true.)
>> 
>> An example can show this. We first remove one data point and then
>> fit 
>> the data again (with a very reduced model as we are only interested
>> in 
>> the intercept estimate here):
>> 
>> dat2 <- dat[-1,]
>> 
>> mm2 <- mixed(Response ~ X*Y + (1|subj),dat2, return="merMod")
>> fixef(mm2)[1]
>> # (Intercept)
>> #    3.006236
>> 
>> mean(dat2$Response)
>> # [1] 3.008559
>> 
>> mean(tapply(dat2$Response, INDEX = list(dat2$XY), mean))
>> # [1] 3.006254
>> 
>> As can be seen, the intercept corresponds approximately to the 
>> unweighted grand mean of all cells, but not to the grand mean of the
>> data.
>> 
>> As said above, the small difference between the intercept and the
>> grand 
>> mean are a consequence of the random effects. Change the random
>> effects 
>> structure to the one above and you will see even more differences. 
>> Furthermore, for standard ANOVA Type III tests exactly correspond to
>> the 
>> unweighted grand mean
>> 
>> What this tells us is that Type III tests are only appropriate if
>> the 
>> missing is not structural but random. In other words, the treatment 
>> (i.e., condition levels) should not be the cause for the missing
>> data 
>> for Type III tests. Type III test correct for missing data by simply 
>> treating the data as having no missing data (i.e., all cells are
>> weighed 
>> equally).
>> 
>> If the missing were structural (i.e., a consequence of the factor 
>> levels) this approach is of course not appropriate. Then we would
>> want 
>> to use something like Type II tests or what you describe in which
>> the 
>> group sizes are taken into account and the intercept correspond to
>> the 
>> grand mean. For example, for observational data where group sizes
>> are 
>> very often informative Type II tests seem more appropriate.
>> 
>> I expect this difference in how Type II and Type III tests deal with 
>> imbalance is also one of the reasons why those statisticans that work
>> a 
>> lot with observational data prefer Type II over Type III tests
>> whereas 
>> those that work with experimental data (where imbalance is usually
>> small 
>> and random) prefer Type III tests over Type II test.
>> 
>> Hope that helps,
>> Henrik
>> 
>> PS: It always helps to include some example data.
>> 
>> Am 04.06.2017 um 15:41 schrieb Thomas Deimel via R-sig-mixed-models:
>>> 
>>> Hi everyone,
>>> 
>>> I am using lmer (or mixed() from the afex package) to implement a
>>> linear mixed model of the form
>>> 
>>> y~1+x1+x2+x1:x2+(by-subject random effects),
>>> 
>>> where x1 and x2 are both categorical variables/factors. The design
>>> is balanced but there are missing values for some x2 levels in some
>>> of the subjects.
>>> 
>>> I am interested in testing the main effect of say x1 in the
>>> presence of the interaction term x1:x2. In order to achieve this, I
>>> convert x2 to a numeric variable using sum contrasts - as
>>> summarized for example [here][1]. This gives the same results for
>>> inference (nearly identical p-values) as using mixed() from the
>>> afex package. This corresponds to a "type III test".
>>> 
>>> The linked summary, however, mentions that the main effect we test
>>> essentially corresponds to the effect of x1 averaged over all
>>> levels of x2 (which I assume corresponds to x2=0 when converted to
>>> numeric and using true contrasts). But, there are missing data for
>>> y for some of the levels of x2 in some of the subjects, so how does
>>> this affect the averaging.
>>> 
>>> My Qs: Given the above implementation of the model,...
>>> 
>>> 1) ...do missing values lead to putting a stronger weight on x2
>>> levels that do not have missing values when averaging over x2
>>> levels to calculate the main effect of x1? OR is R aware of that
>>> distortion and calculates a weighted average of some sort (I don't
>>> see how)?
>>> 
>>> 2) ...is this a problem? I assume it could lead to distorted
>>> estimation of main effect significance in smaller data sets or if
>>> there are a lot of missing values for certain levels of x2?
>>> 
>>> 3) ...is there a way around it, like forcing R to weighting the
>>> average? Or would it be advisable to compare y~x2 to y~x1+x2,
>>> instead? I would certainly be inclined to use this if the
>>> interaction was insignificant (agreed?) but what if it is
>>> significant? Any other options?
>>> 
>>> Thanks for the help,
>>> 
>>> Thomas
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>>    [1]: https://arxiv.org/pdf/1405.2094.pdf "here"
>>> 	[[alternative HTML version deleted]]
>>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From D.J.Damen at uvt.nl  Fri Jun  9 15:31:51 2017
From: D.J.Damen at uvt.nl (D.J. Damen)
Date: Fri, 9 Jun 2017 13:31:51 +0000
Subject: [R-sig-ME] Warnings BootMer bootstrap glmer lme4
In-Reply-To: <363DE002-9EE0-4AF0-97CE-706F4623AB34@uvt.nl>
References: <363DE002-9EE0-4AF0-97CE-706F4623AB34@uvt.nl>
Message-ID: <48F049408456404F9AD7561081C496ED26F45132@EXMBX102.campus.uvt.nl>

Dear Ben,



Thank you very much for your kind reply and nice suggestions.



This seems like a moderately complex model (2 4x4 variance-covariance

matrices); how big is your data set (total observations, number of id

levels, number of item.new levels)?  I wouldn't be surprised if you're

getting some singular fits.  On the other hand, the gradient warnings

are fairly small.



True, it is. Total observations = 3600, number of ID levels = 90 (30 IDs per condition), number of item.new levels = 40.



In more detail: the 90 participants (i.e., ID) were allocated to one of the three conditions (i.e., c.con.tr) and were all confronted to 40 items (i.e., items.new), divided into test (20) and control items (20) (i.e., .type.tr), but these test and control items were either manipulated to appear in color (10) or size (10) (i.e., c.diff.tr).



In addition, I was also wondering whether my bootstrapping code is correctly specified? I am currently using the following code:


FUN <- function(fit) {
  return(fixef(fit))
}

boost <- function(mdl){
  name <- match.call()$mdl
  boosted <- bootMer(mdl, FUN, nsim = 100)
  save(boosted,file=paste(name,"_boosted",sep=""))
}



I have not specified the type = c(?parametric?) nor provided a parallel function, should I do so?





   Some suggestions:



 - (unrelated to your question) if you have small numbers of

observations *per* id (or item), you should consider using Gauss-Hermite

quadrature (e.g. nAGQ=10)



I will definitely try this.



 - check to see whether the profile confidence intervals agree

reasonably well with the bootstrap Cis



Then I have to ask for type = perc Cis, am I right?



 - you could use blme::bglmer to regularize your model to avoid

Singularities



Thank you!



 - or try an alternative approach like brms to double-check



Thank you, again :).





Best, Debby





From: D.J. Damen
Sent: vrijdag 19 mei 2017 12:44
To: r-sig-mixed-models at r-project.org
Subject: Warnings BootMer bootstrap glmer lme4

Dear all,

Currently, I am using the BootMer function to bootstrap my final model (fitted with GLMER from the lme4 package) to estimate the confidence intervals and p-values. Since I am alternating my reference categories, I have to bootstrap several models, and now the bootstrap of one model (below) returns with 50 or more warnings. Is there a standard procedure to follow when this happens? Should I trust the bootstrap when warnings pop up?

I am fitting a binomial model with the (centered and treatment coded) predictors c.con.tr (3 levels), c.type.tr (2 levels), and c.diff.tr (2 levels), and the dependent variable ?contrast? (1 = mentioned; 0 = not mentioned).

Details about the model I want to bootstrap, the bootstrap function and the warnings are presented below:

Model:

m0bcc <-glmer (contrast~c.con.tr*c.type.tr*c.diff.tr+(1+c.type.tr+c.diff.tr|id)+(1+c.con.tr+c.type.tr|item.new), data=mydata, family=binomial (link='logit'), control=glmerControl(optimizer="bobyqa"))


Bootstrap function:

FUN <- function(fit) {
  return(fixef(fit))
}

boost <- function(mdl){
  name <- match.call()$mdl
  boosted <- bootMer(mdl, FUN, nsim = 100)
  save(boosted,file=paste(name,"_boosted",sep=""))
}

p_boosted <- function(mdl,boosted){
  for (n in 1:length(fixef(mdl))){
    print(fixef(mdl)[n])
    (bMCI <- boot.ci(boosted, conf = c(0.95, 0.99, 0.999), index=n, type="norm"))
    print(bMCI)
  }
}

Warnings: ( posted the first 10 warnings, in total there were 50 (or more?).

mdl <- m0bcc
> boosted <- bootMer(mdl, FUN, nsim = 100)
There were 50 or more warnings (use warnings() to see the first 50)

1: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  ... :
  unable to evaluate scaled gradient
2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  ... :
  Model failed to converge: degenerate  Hessian with 1 negative eigenvalues
3: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  ... :
  unable to evaluate scaled gradient
4: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  ... :
  Model failed to converge: degenerate  Hessian with 2 negative eigenvalues
5: In optwrap(object at optinfo$optimizer, ff, x0, lower = lower,  ... :
  convergence code 1 from bobyqa: bobyqa -- maximum number of function evaluations exceeded
6: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  ... :
  Model failed to converge with max|grad| = 0.00176467 (tol = 0.001, component 1)
7: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  ... :
  unable to evaluate scaled gradient
8: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  ... :
  Model failed to converge: degenerate  Hessian with 1 negative eigenvalues
9: In optwrap(object at optinfo$optimizer, ff, x0, lower = lower,  ... :
  convergence code 1 from bobyqa: bobyqa -- maximum number of function evaluations exceeded
10: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  ... :
  Model failed to converge with max|grad| = 0.00258682 (tol = 0.001, component 1)
11: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  ... :


I couldn?t find whether I should decrease the random effects structure of my fitted model to decrease these bootstrap warnings, but since my fitted glmer model did converge, I am hesitant to do so anyway. I hope somebody is able to shed some light on this matter.

Thank you very much in advance.

Best, Debby

Debby Damen
PhD Student

Department of Communication and Information Science

Tilburg University
Warandelaan 2, room D410
5037 AB Tilburg

T. +31 13 466  8245
M. d.j.damen at uvt.nl<mailto:d.j.damen at uvt.nl>

	[[alternative HTML version deleted]]


From D.J.Damen at uvt.nl  Mon Jun 12 12:45:45 2017
From: D.J.Damen at uvt.nl (D.J. Damen)
Date: Mon, 12 Jun 2017 10:45:45 +0000
Subject: [R-sig-ME] Bglmer convergence warnings (covariance structure)
Message-ID: <5C1B9B6D-0929-4F99-A17C-FA8CFD487822@uvt.nl>

Dear all,

I am trying to fit a binomial model with three factors using the bglmer package in R. My model includes a complex 3x2x2 design; factor c.con.tr has three levels, factor c.type.tr two, and factor c.diff.tr has also two levels. When I try to fit a random-intercept only model, the model produces the following warning:

Warning message:
In get("checkConv", lme4Namespace)(attr(opt, "derivs"), opt$par,  :
  Model failed to converge with max|grad| = 2.02439 (tol = 0.001, component 1)

I figured that I did not specify my covariance structure correctly, but I am at a loss as to how I should change it. The structure of my model is as follows:

riobglmer <- bglmer(contrast~c.con.tr*c.type.tr*c.diff.tr+(1|id)+(1|item.new), data=mydata, family=binomial (link='logit'), fixef.prior= normal(cov = diag(9,12)))

To me, (cov = diag(9,12)), seems to be correct.. Am I missing something important? Suggestions and/or remarks are more than welcome.

Thank you very much in advance.

Best regards,

Debby Damen
PhD Student

Department of Communication and Information Science

Tilburg University
Warandelaan 2, room D410
5037 AB Tilburg

T. +31 13 466  8245
M. d.j.damen at uvt.nl<mailto:d.j.damen at uvt.nl>



	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Jun 12 18:04:46 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 12 Jun 2017 12:04:46 -0400
Subject: [R-sig-ME] Bglmer convergence warnings (covariance structure)
In-Reply-To: <5C1B9B6D-0929-4F99-A17C-FA8CFD487822@uvt.nl>
References: <5C1B9B6D-0929-4F99-A17C-FA8CFD487822@uvt.nl>
Message-ID: <82c5832d-e2b9-5d12-7085-b0aeac70bd82@gmail.com>


 I think if you'd failed to specify the covariance matrix correctly that
you would simply have gotten an error.
  I'm doing some test runs on simulated data. I did get convergence
warnings, but the results look reasonable when compared across widely
different fitting platforms (lme4, blme, glmmTMB, brms):

http://bbolker.github.io/mixedmodels-misc/notes/bglmer_cmp.html

code (Rmd file etc.) is in the corresponding github repo

  cheers
   Ben Bolker



On 17-06-12 06:45 AM, D.J. Damen wrote:
> Dear all,
> 
> I am trying to fit a binomial model with three factors using the bglmer package in R. My model includes a complex 3x2x2 design; factor c.con.tr has three levels, factor c.type.tr two, and factor c.diff.tr has also two levels. When I try to fit a random-intercept only model, the model produces the following warning:
> 
> Warning message:
> In get("checkConv", lme4Namespace)(attr(opt, "derivs"), opt$par,  :
>   Model failed to converge with max|grad| = 2.02439 (tol = 0.001, component 1)
> 
> I figured that I did not specify my covariance structure correctly, but I am at a loss as to how I should change it. The structure of my model is as follows:
> 
> riobglmer <- bglmer(contrast~c.con.tr*c.type.tr*c.diff.tr+(1|id)+(1|item.new), data=mydata, family=binomial (link='logit'), fixef.prior= normal(cov = diag(9,12)))
> 
> To me, (cov = diag(9,12)), seems to be correct.. Am I missing something important? Suggestions and/or remarks are more than welcome.
> 
> Thank you very much in advance.
> 
> Best regards,
> 
> Debby Damen
> PhD Student
> 
> Department of Communication and Information Science
> 
> Tilburg University
> Warandelaan 2, room D410
> 5037 AB Tilburg
> 
> T. +31 13 466  8245
> M. d.j.damen at uvt.nl<mailto:d.j.damen at uvt.nl>
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From gangchen at mail.nih.gov  Mon Jun 12 19:23:04 2017
From: gangchen at mail.nih.gov (Chen, Gang (NIH/NIMH) [C])
Date: Mon, 12 Jun 2017 17:23:04 +0000
Subject: [R-sig-ME] Interpreting variances for random effects
Message-ID: <7356346B-C060-492E-8880-E4D431F329CA@mail.nih.gov>

I?m trying to run a meta mixed-effects model with the R package ?blme?, but I have trouble understanding the variances for the random effects in the output. Let me demonstrate my questions with the following dataset:

dat <- read.table(text='
   Subj   ses          Beta         vi
s20447  T1  0.0918712467 0.06086247
s20973  T1  0.0275931843 0.08578725
s21163  T1  0.0159543231 0.01198331
s21209  T1  0.2722044587 0.05239982
s21590  T1 -0.2647554576 0.04842246
s21606  T1 -0.0915029198 0.02063762
s21728  T1 -0.1098448336 0.08973302
s22177  T1  0.0070983637 0.01515363
s22380  T1  0.0660349280 0.10569247
s22437  T1 -0.0825878531 0.12504976
s22481  T1 -0.3160937428 0.05636208
s22542  T1 -0.3765429556 0.05385343
s22660  T1  0.1904570013 0.01808839
s22687  T1 -0.3090784848 0.03609267
s22717  T1 -0.5519740582 0.08041095
s22774  T1  0.0318013728 0.01584950
s22819  T1 -0.0250370707 0.01560509
s22828  T1  0.1122434586 0.07531304
s22834  T1 -0.0590136759 0.04191800
s22861  T1 -0.0165097713 0.02500125
s22881  T1  0.0004725010 0.01726706
s22959  T1  0.3902115524 0.04177956
s23107  T1  0.0069795060 0.01592698
s23154  T1  0.0790746883 0.09956493
s23193  T1  0.5274482369 0.02718767
s20447  T2 -0.0148665439 0.03070799
s20973  T2  0.1085031107 0.07011064
s21163  T2 -0.0075897672 0.00944575
s21209  T2 -0.4167304039 0.02853584
s21590  T2  0.0006625475 0.04409404
s21606  T2  0.1917003244 0.02087413
s21728  T2 -0.1185217202 0.05121711
s22177  T2 -0.0446757786 0.01802203
s22380  T2 -0.3420846760 0.08059885
s22437  T2 -0.0735468194 0.19387151
s22481  T2  0.1410380155 0.02487867
s22542  T2 -0.1882588267 0.04918930
s22660  T2  0.0079449303 0.03648700
s22687  T2  0.1746368855 0.03746678
s22717  T2 -0.2987288833 0.05659567
s22774  T2 -0.1838540286 0.04245462
s22819  T2 -0.2798163295 0.01841418
s22828  T2 -0.5080602765 0.14406914
s22834  T2 -0.1628637910 0.02220246
s22861  T2  0.2190277874 0.03104834
s22881  T2 -0.1975046396 0.01770617
s22959  T2 -0.1411849707 0.03163359
s23107  T2 -0.0360546894 0.01652099
s23154  T2  0.5842899084 0.08301191
s23193  T2 -0.2372864336 0.02257293', header=T)

require('blme')
summary(blmer(Beta~1+ses+(1|Subj), data=dat, resid.prior = point, cov.prior=gamma(shape = 2, rate = 0.5, posterior.scale = 'sd'), weights=1/vi))

?
Random effects:
Groups   Name        Variance Std.Dev.
Subj     (Intercept) 0.02706  0.1645
 Residual             1.00000  1.0000
Number of obs: 50, groups:  Subj, 25
?
convergence code: 0
Model failed to converge with max|grad| = 6.50544 (tol = 0.002, component 1)

Warning message:
In get("checkConv", lme4Namespace)(attr(opt, "derivs"), opt$par,  :
  Model failed to converge with max|grad| = 6.50544 (tol = 0.002, component 1)

Here are my questions:


  1.  I?ve been using the variance prior of ?gamma(shape = 2, rate = 0.5, posterior.scale = 'sd')? as a weakly informative prior, which usually works fine. However, this is the first time I have the convergence problem. Could you offer some suggestion as to how to deal with the convergence issue like this? I tried to change the shape parameter from 2 to 20 , which seems to get rid of the convergence problem, but I don?t feel comfortable with such a large and strong shape parameter value. Maybe the convergence failure is OK per Dr. Bolker?s suggestion (http://bbolker.github.io/mixedmodels-misc/notes/bglmer_cmp.html) in another thread?
  2.  The variance for ?Subj? is what I?m interested here. It seems the variance for ?Residual? is always 1 when the option ?weights? is used. How to interpret this? Does it mean that the variance for ?Subj? should be interpreted as being scaled somehow?

Thanks,
Gang



	[[alternative HTML version deleted]]


From don-r-help at isis.cs3-inc.com  Tue Jun 13 21:20:05 2017
From: don-r-help at isis.cs3-inc.com (Don Cohen)
Date: Tue, 13 Jun 2017 19:20:05 +0000
Subject: [R-sig-ME] [R] understanding I() in lmer formula
In-Reply-To: <CAGxFJbQzn4_72Y36_w05JhMNy2pbE+Zd+xuBKZdGNHidzdWasg@mail.gmail.com>
References: <20170613182554.D49724057F@losangelesyouthorchestra.org>
 <CAGxFJbQzn4_72Y36_w05JhMNy2pbE+Zd+xuBKZdGNHidzdWasg@mail.gmail.com>
Message-ID: <22848.15077.298901.273269@losangelesyouthorchestra.org>

Bert Gunter suggested posting this here:

 Is there a difference between I(x*y) and I(y*x) ?
I have a call to lmer that results in this complaint:
  Error in is.alpha2.subordinate * ~z.min.co.res :
  non-numeric argument to binary operator
when I change this line:
  I(is.alpha2.subordinate*z.min.co.res)+
to this:
  I(z.min.co.res*is.alpha2.subordinate)+
the complaint goes away.
I'd like to understand why.


From pdalgd at gmail.com  Tue Jun 13 22:15:12 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 13 Jun 2017 22:15:12 +0200
Subject: [R-sig-ME] [R] understanding I() in lmer formula
In-Reply-To: <22848.15077.298901.273269@losangelesyouthorchestra.org>
References: <20170613182554.D49724057F@losangelesyouthorchestra.org>
 <CAGxFJbQzn4_72Y36_w05JhMNy2pbE+Zd+xuBKZdGNHidzdWasg@mail.gmail.com>
 <22848.15077.298901.273269@losangelesyouthorchestra.org>
Message-ID: <3D1C4A35-8AB2-48E6-8254-69819D8D39FD@gmail.com>

Not that I really have a clue, but what is that "~" doing in the error message??

-pd

> On 13 Jun 2017, at 21:20 , Don Cohen <don-r-help at isis.cs3-inc.com> wrote:
> 
> Bert Gunter suggested posting this here:
> 
> Is there a difference between I(x*y) and I(y*x) ?
> I have a call to lmer that results in this complaint:
>  Error in is.alpha2.subordinate * ~z.min.co.res :
>  non-numeric argument to binary operator
> when I change this line:
>  I(is.alpha2.subordinate*z.min.co.res)+
> to this:
>  I(z.min.co.res*is.alpha2.subordinate)+
> the complaint goes away.
> I'd like to understand why.
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From don-r-help at isis.cs3-inc.com  Wed Jun 14 02:17:30 2017
From: don-r-help at isis.cs3-inc.com (Don Cohen)
Date: Wed, 14 Jun 2017 00:17:30 +0000
Subject: [R-sig-ME] [R] understanding I() in lmer formula
In-Reply-To: <0e37a14d-9197-402b-8c74-405a3d6f0af8@Spark>
References: <20170613182554.D49724057F@losangelesyouthorchestra.org>
 <CAGxFJbQzn4_72Y36_w05JhMNy2pbE+Zd+xuBKZdGNHidzdWasg@mail.gmail.com>
 <22848.15077.298901.273269@losangelesyouthorchestra.org>
 <fe3095ef143648d4848298899aca5798@ME1PR01MB1442.ausprd01.prod.outlook.com>
 <0e37a14d-9197-402b-8c74-405a3d6f0af8@Spark>
Message-ID: <22848.32922.391037.543832@losangelesyouthorchestra.org>

Andrew Robinson writes:

 > can you provide a minimal executable example?
I was hoping it was going to be something simple.
It looks to me like this is related to parsing and has nothing
to do with the data.
I start by trying to simplify my formula and find that even deleting
seemingly irrelevant parts leads to the same kinds of errors.

 > > but what is that "~" doing in the error message??
I wish I knew!

Here's an example that's not exactly small, but at least smaller 
than I started with.  The first one seems to work and then I move
the # to the other line that I'd expect to have the same meaning.

> fullx=lmer(log.corti~ 
    z.n.fert.females*z.n.males+ 
    is.alpha2*(z.infanticide.susceptibility_new+z.min.co.res+z.co.res+z.log.tenure)+ 
    z.age.at.sample+sin.season+cos.season+ 
    (1+z.n.fert.females+z.n.males+is.alpha2.subordinate+z.infanticide.susceptibility_new+ 
     z.min.co.res+z.log.tenure+z.co.res+ 
     z.age.at.sample+sin.season+cos.season+ 
     I(z.n.fert.females*z.n.males)+ 
       I(is.alpha2.subordinate*z.co.res)+ 
      I(z.min.co.res*is.alpha2.subordinate)+ 
      #  I(is.alpha2.subordinate*z.min.co.res)+ 
     int.is.a.log.ten||monkeyid), 
        data=fe.re.xx$data, REML=F, control=contr)
+ + + + + + + + + + + + > fullx=lmer(log.corti~ 
    z.n.fert.females*z.n.males+ 
    is.alpha2*(z.infanticide.susceptibility_new+z.min.co.res+z.co.res+z.log.tenure)+ 
    z.age.at.sample+sin.season+cos.season+ 
    (1+z.n.fert.females+z.n.males+is.alpha2.subordinate+z.infanticide.susceptibility_new+ 
     z.min.co.res+z.log.tenure+z.co.res+ 
     z.age.at.sample+sin.season+cos.season+ 
     I(z.n.fert.females*z.n.males)+ 
       I(is.alpha2.subordinate*z.co.res)+ 
     # I(z.min.co.res*is.alpha2.subordinate)+ 
       I(is.alpha2.subordinate*z.min.co.res)+ 
     int.is.a.log.ten||monkeyid), 
        data=fe.re.xx$data, REML=F, control=contr) 
+ + + + + + + + + + + + Error in is.alpha2.subordinate * ~z.min.co.res :  
  non-numeric argument to binary operator 
>  

And if I start with the one that works and delete something
seemingly irrelevant, like z.infanticide.susceptibility_new+ 

> fullx=lmer(log.corti~ 
    z.n.fert.females*z.n.males+ 
    is.alpha2*(z.infanticide.susceptibility_new+z.min.co.res+z.co.res+z.log.tenure)+ 
    z.age.at.sample+sin.season+cos.season+ 
    (1+z.n.fert.females+z.n.males+is.alpha2.subordinate+ # z.infanticide.susceptibility_new+ 
     z.min.co.res+z.log.tenure+z.co.res+ 
     z.age.at.sample+sin.season+cos.season+ 
     I(z.n.fert.females*z.n.males)+ 
       I(is.alpha2.subordinate*z.co.res)+ 
      I(z.min.co.res*is.alpha2.subordinate)+ 
      #  I(is.alpha2.subordinate*z.min.co.res)+ 
     int.is.a.log.ten||monkeyid), 
        data=fe.re.xx$data, REML=F, control=contr) 
+ + + + + + + + + + + + Error in is.alpha2.subordinate * ~z.co.res :  
  non-numeric argument to binary operator 

I know this is not the minimal executable example requested, but I'm
hoping someone will have an idea before I try to simplify it further
and provide all you need to run it.


From marc_schwartz at me.com  Wed Jun 14 02:43:38 2017
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 13 Jun 2017 19:43:38 -0500
Subject: [R-sig-ME] [R] understanding I() in lmer formula
In-Reply-To: <22848.32922.391037.543832@losangelesyouthorchestra.org>
References: <20170613182554.D49724057F@losangelesyouthorchestra.org>
 <CAGxFJbQzn4_72Y36_w05JhMNy2pbE+Zd+xuBKZdGNHidzdWasg@mail.gmail.com>
 <22848.15077.298901.273269@losangelesyouthorchestra.org>
 <fe3095ef143648d4848298899aca5798@ME1PR01MB1442.ausprd01.prod.outlook.com>
 <0e37a14d-9197-402b-8c74-405a3d6f0af8@Spark>
 <22848.32922.391037.543832@losangelesyouthorchestra.org>
Message-ID: <3DEC3ECE-0F56-4DC7-A301-0E9F7488A0A5@me.com>


> On Jun 13, 2017, at 7:17 PM, Don Cohen <don-r-help at isis.cs3-inc.com> wrote:
> 
> Andrew Robinson writes:
> 
>> can you provide a minimal executable example?
> I was hoping it was going to be something simple.
> It looks to me like this is related to parsing and has nothing
> to do with the data.
> I start by trying to simplify my formula and find that even deleting
> seemingly irrelevant parts leads to the same kinds of errors.
> 
>>> but what is that "~" doing in the error message??
> I wish I knew!
> 
> Here's an example that's not exactly small, but at least smaller 
> than I started with.  The first one seems to work and then I move
> the # to the other line that I'd expect to have the same meaning.
> 
>> fullx=lmer(log.corti~ 
>    z.n.fert.females*z.n.males+ 
>    is.alpha2*(z.infanticide.susceptibility_new+z.min.co.res+z.co.res+z.log.tenure)+ 
>    z.age.at.sample+sin.season+cos.season+ 
>    (1+z.n.fert.females+z.n.males+is.alpha2.subordinate+z.infanticide.susceptibility_new+ 
>     z.min.co.res+z.log.tenure+z.co.res+ 
>     z.age.at.sample+sin.season+cos.season+ 
>     I(z.n.fert.females*z.n.males)+ 
>       I(is.alpha2.subordinate*z.co.res)+ 
>      I(z.min.co.res*is.alpha2.subordinate)+ 
>      #  I(is.alpha2.subordinate*z.min.co.res)+ 
>     int.is.a.log.ten||monkeyid), 
>        data=fe.re.xx$data, REML=F, control=contr)
> + + + + + + + + + + + + > fullx=lmer(log.corti~ 
>    z.n.fert.females*z.n.males+ 
>    is.alpha2*(z.infanticide.susceptibility_new+z.min.co.res+z.co.res+z.log.tenure)+ 
>    z.age.at.sample+sin.season+cos.season+ 
>    (1+z.n.fert.females+z.n.males+is.alpha2.subordinate+z.infanticide.susceptibility_new+ 
>     z.min.co.res+z.log.tenure+z.co.res+ 
>     z.age.at.sample+sin.season+cos.season+ 
>     I(z.n.fert.females*z.n.males)+ 
>       I(is.alpha2.subordinate*z.co.res)+ 
>     # I(z.min.co.res*is.alpha2.subordinate)+ 
>       I(is.alpha2.subordinate*z.min.co.res)+ 
>     int.is.a.log.ten||monkeyid), 
>        data=fe.re.xx$data, REML=F, control=contr) 
> + + + + + + + + + + + + Error in is.alpha2.subordinate * ~z.min.co.res :  
>  non-numeric argument to binary operator 
>> 
> 
> And if I start with the one that works and delete something
> seemingly irrelevant, like z.infanticide.susceptibility_new+ 
> 
>> fullx=lmer(log.corti~ 
>    z.n.fert.females*z.n.males+ 
>    is.alpha2*(z.infanticide.susceptibility_new+z.min.co.res+z.co.res+z.log.tenure)+ 
>    z.age.at.sample+sin.season+cos.season+ 
>    (1+z.n.fert.females+z.n.males+is.alpha2.subordinate+ # z.infanticide.susceptibility_new+ 
>     z.min.co.res+z.log.tenure+z.co.res+ 
>     z.age.at.sample+sin.season+cos.season+ 
>     I(z.n.fert.females*z.n.males)+ 
>       I(is.alpha2.subordinate*z.co.res)+ 
>      I(z.min.co.res*is.alpha2.subordinate)+ 
>      #  I(is.alpha2.subordinate*z.min.co.res)+ 
>     int.is.a.log.ten||monkeyid), 
>        data=fe.re.xx$data, REML=F, control=contr) 
> + + + + + + + + + + + + Error in is.alpha2.subordinate * ~z.co.res :  
>  non-numeric argument to binary operator 
> 
> I know this is not the minimal executable example requested, but I'm
> hoping someone will have an idea before I try to simplify it further
> and provide all you need to run it.


A few thoughts:

1. Strip down the formula so that only the term that causes the error is present. 

If the error happens with only that term, let us know. 

If not, add each other term back in AFTER the one problematic term, one by one, until you get the error, if it happens. When that happens, keep the original term and that additional term only, and see if the error still happens with just those two terms. Let us know.

If the error does not recur, then there may be something tied to term order, which would be curious.


2. Can you provide the output of:

  str(fe.re.xx$data)

which is presumably a data frame called 'data' within a larger object called 'fe.re.xx'. Hopefully, the number of columns in the data frame is "reasonable".

Perhaps there is something about the structure of your data frame that is causing some issue.


3. Also, make sure that the components of each term are only in the data frame object and not otherwise in your working environment, so that there is no risk of confusion as to what objects are being passed to the formula. Essentially, use ls() to scan the content of your working environment and see if any show there.


4. Start a new, **clean** R session and see if the error still occurs. Be sure that there are no other objects in the environment or a corrupted environment causing issues. If you have a .RData file that is loaded with a new session, delete it or move it, if you need it. Also check for a .Rprofile file that might affect your working environment. 

If you can run 'R --vanilla' from the CLI, to start a new R session, that would help with getting a clean session.


Regards,

Marc Schwartz


From bbolker at gmail.com  Wed Jun 14 02:54:18 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 13 Jun 2017 20:54:18 -0400
Subject: [R-sig-ME] [R] understanding I() in lmer formula
In-Reply-To: <3DEC3ECE-0F56-4DC7-A301-0E9F7488A0A5@me.com>
References: <20170613182554.D49724057F@losangelesyouthorchestra.org>
 <CAGxFJbQzn4_72Y36_w05JhMNy2pbE+Zd+xuBKZdGNHidzdWasg@mail.gmail.com>
 <22848.15077.298901.273269@losangelesyouthorchestra.org>
 <fe3095ef143648d4848298899aca5798@ME1PR01MB1442.ausprd01.prod.outlook.com>
 <0e37a14d-9197-402b-8c74-405a3d6f0af8@Spark>
 <22848.32922.391037.543832@losangelesyouthorchestra.org>
 <3DEC3ECE-0F56-4DC7-A301-0E9F7488A0A5@me.com>
Message-ID: <CABghstQ0CMs0MoPunnpDukdo71JYcgPFVa9_wjs7uNC8fABEKA@mail.gmail.com>

It would definitely be good to get a reproducible example.  Looking at
what's there, I'm *guessing* that the problem is with the I(x*y) in
the *random effects* terms - there is quite likely some
not-entirely-standard formula parsing/deconstruction going on there.

   A workaround is likely to be defining the equivalent of x*y as an
auxiliary variable in your data frame, rather than trying to include
it on the fly.

  16 terms in a random effect specification, even when they're
diagonal, seems pretty large.  I hope you have a big data set ...


On Tue, Jun 13, 2017 at 8:43 PM, Marc Schwartz <marc_schwartz at me.com> wrote:
>
>> On Jun 13, 2017, at 7:17 PM, Don Cohen <don-r-help at isis.cs3-inc.com> wrote:
>>
>> Andrew Robinson writes:
>>
>>> can you provide a minimal executable example?
>> I was hoping it was going to be something simple.
>> It looks to me like this is related to parsing and has nothing
>> to do with the data.
>> I start by trying to simplify my formula and find that even deleting
>> seemingly irrelevant parts leads to the same kinds of errors.
>>
>>>> but what is that "~" doing in the error message??
>> I wish I knew!
>>
>> Here's an example that's not exactly small, but at least smaller
>> than I started with.  The first one seems to work and then I move
>> the # to the other line that I'd expect to have the same meaning.
>>
>>> fullx=lmer(log.corti~
>>    z.n.fert.females*z.n.males+
>>    is.alpha2*(z.infanticide.susceptibility_new+z.min.co.res+z.co.res+z.log.tenure)+
>>    z.age.at.sample+sin.season+cos.season+
>>    (1+z.n.fert.females+z.n.males+is.alpha2.subordinate+z.infanticide.susceptibility_new+
>>     z.min.co.res+z.log.tenure+z.co.res+
>>     z.age.at.sample+sin.season+cos.season+
>>     I(z.n.fert.females*z.n.males)+
>>       I(is.alpha2.subordinate*z.co.res)+
>>      I(z.min.co.res*is.alpha2.subordinate)+
>>      #  I(is.alpha2.subordinate*z.min.co.res)+
>>     int.is.a.log.ten||monkeyid),
>>        data=fe.re.xx$data, REML=F, control=contr)
>> + + + + + + + + + + + + > fullx=lmer(log.corti~
>>    z.n.fert.females*z.n.males+
>>    is.alpha2*(z.infanticide.susceptibility_new+z.min.co.res+z.co.res+z.log.tenure)+
>>    z.age.at.sample+sin.season+cos.season+
>>    (1+z.n.fert.females+z.n.males+is.alpha2.subordinate+z.infanticide.susceptibility_new+
>>     z.min.co.res+z.log.tenure+z.co.res+
>>     z.age.at.sample+sin.season+cos.season+
>>     I(z.n.fert.females*z.n.males)+
>>       I(is.alpha2.subordinate*z.co.res)+
>>     # I(z.min.co.res*is.alpha2.subordinate)+
>>       I(is.alpha2.subordinate*z.min.co.res)+
>>     int.is.a.log.ten||monkeyid),
>>        data=fe.re.xx$data, REML=F, control=contr)
>> + + + + + + + + + + + + Error in is.alpha2.subordinate * ~z.min.co.res :
>>  non-numeric argument to binary operator
>>>
>>
>> And if I start with the one that works and delete something
>> seemingly irrelevant, like z.infanticide.susceptibility_new+
>>
>>> fullx=lmer(log.corti~
>>    z.n.fert.females*z.n.males+
>>    is.alpha2*(z.infanticide.susceptibility_new+z.min.co.res+z.co.res+z.log.tenure)+
>>    z.age.at.sample+sin.season+cos.season+
>>    (1+z.n.fert.females+z.n.males+is.alpha2.subordinate+ # z.infanticide.susceptibility_new+
>>     z.min.co.res+z.log.tenure+z.co.res+
>>     z.age.at.sample+sin.season+cos.season+
>>     I(z.n.fert.females*z.n.males)+
>>       I(is.alpha2.subordinate*z.co.res)+
>>      I(z.min.co.res*is.alpha2.subordinate)+
>>      #  I(is.alpha2.subordinate*z.min.co.res)+
>>     int.is.a.log.ten||monkeyid),
>>        data=fe.re.xx$data, REML=F, control=contr)
>> + + + + + + + + + + + + Error in is.alpha2.subordinate * ~z.co.res :
>>  non-numeric argument to binary operator
>>
>> I know this is not the minimal executable example requested, but I'm
>> hoping someone will have an idea before I try to simplify it further
>> and provide all you need to run it.
>
>
> A few thoughts:
>
> 1. Strip down the formula so that only the term that causes the error is present.
>
> If the error happens with only that term, let us know.
>
> If not, add each other term back in AFTER the one problematic term, one by one, until you get the error, if it happens. When that happens, keep the original term and that additional term only, and see if the error still happens with just those two terms. Let us know.
>
> If the error does not recur, then there may be something tied to term order, which would be curious.
>
>
> 2. Can you provide the output of:
>
>   str(fe.re.xx$data)
>
> which is presumably a data frame called 'data' within a larger object called 'fe.re.xx'. Hopefully, the number of columns in the data frame is "reasonable".
>
> Perhaps there is something about the structure of your data frame that is causing some issue.
>
>
> 3. Also, make sure that the components of each term are only in the data frame object and not otherwise in your working environment, so that there is no risk of confusion as to what objects are being passed to the formula. Essentially, use ls() to scan the content of your working environment and see if any show there.
>
>
> 4. Start a new, **clean** R session and see if the error still occurs. Be sure that there are no other objects in the environment or a corrupted environment causing issues. If you have a .RData file that is loaded with a new session, delete it or move it, if you need it. Also check for a .Rprofile file that might affect your working environment.
>
> If you can run 'R --vanilla' from the CLI, to start a new R session, that would help with getting a clean session.
>
>
> Regards,
>
> Marc Schwartz
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Wed Jun 14 03:24:52 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 13 Jun 2017 21:24:52 -0400
Subject: [R-sig-ME] [R] understanding I() in lmer formula
In-Reply-To: <CABghstQ0CMs0MoPunnpDukdo71JYcgPFVa9_wjs7uNC8fABEKA@mail.gmail.com>
References: <20170613182554.D49724057F@losangelesyouthorchestra.org>
 <CAGxFJbQzn4_72Y36_w05JhMNy2pbE+Zd+xuBKZdGNHidzdWasg@mail.gmail.com>
 <22848.15077.298901.273269@losangelesyouthorchestra.org>
 <fe3095ef143648d4848298899aca5798@ME1PR01MB1442.ausprd01.prod.outlook.com>
 <0e37a14d-9197-402b-8c74-405a3d6f0af8@Spark>
 <22848.32922.391037.543832@losangelesyouthorchestra.org>
 <3DEC3ECE-0F56-4DC7-A301-0E9F7488A0A5@me.com>
 <CABghstQ0CMs0MoPunnpDukdo71JYcgPFVa9_wjs7uNC8fABEKA@mail.gmail.com>
Message-ID: <CABghstRdv7Y7eDjbXymOKAkN_qGHTZ559mOPGZ1Zz-HO7DLGKA@mail.gmail.com>

FWIW my trivial efforts to replicate this/verify my guess that the
problem is related to I() in a random-effects term have failed.

This doesn't fail in an obvious way:

  set.seed(101)
  dd <- data.frame(x=rnorm(1000),y=rnorm(1000),z=rnorm(1000),
    f=factor(rep(1:20,50)))
  library(lme4)
  lmer(z~(1+x+I(x*y)||f),data=dd)
  lmer(z~(1+x+I(y*x)||f),data=dd)

Perhaps we're running afoul of the 500-character line-break in
deparse() somewhere ... ?


On Tue, Jun 13, 2017 at 8:54 PM, Ben Bolker <bbolker at gmail.com> wrote:
> It would definitely be good to get a reproducible example.  Looking at
> what's there, I'm *guessing* that the problem is with the I(x*y) in
> the *random effects* terms - there is quite likely some
> not-entirely-standard formula parsing/deconstruction going on there.
>
>    A workaround is likely to be defining the equivalent of x*y as an
> auxiliary variable in your data frame, rather than trying to include
> it on the fly.
>
>   16 terms in a random effect specification, even when they're
> diagonal, seems pretty large.  I hope you have a big data set ...
>
>
> On Tue, Jun 13, 2017 at 8:43 PM, Marc Schwartz <marc_schwartz at me.com> wrote:
>>
>>> On Jun 13, 2017, at 7:17 PM, Don Cohen <don-r-help at isis.cs3-inc.com> wrote:
>>>
>>> Andrew Robinson writes:
>>>
>>>> can you provide a minimal executable example?
>>> I was hoping it was going to be something simple.
>>> It looks to me like this is related to parsing and has nothing
>>> to do with the data.
>>> I start by trying to simplify my formula and find that even deleting
>>> seemingly irrelevant parts leads to the same kinds of errors.
>>>
>>>>> but what is that "~" doing in the error message??
>>> I wish I knew!
>>>
>>> Here's an example that's not exactly small, but at least smaller
>>> than I started with.  The first one seems to work and then I move
>>> the # to the other line that I'd expect to have the same meaning.
>>>
>>>> fullx=lmer(log.corti~
>>>    z.n.fert.females*z.n.males+
>>>    is.alpha2*(z.infanticide.susceptibility_new+z.min.co.res+z.co.res+z.log.tenure)+
>>>    z.age.at.sample+sin.season+cos.season+
>>>    (1+z.n.fert.females+z.n.males+is.alpha2.subordinate+z.infanticide.susceptibility_new+
>>>     z.min.co.res+z.log.tenure+z.co.res+
>>>     z.age.at.sample+sin.season+cos.season+
>>>     I(z.n.fert.females*z.n.males)+
>>>       I(is.alpha2.subordinate*z.co.res)+
>>>      I(z.min.co.res*is.alpha2.subordinate)+
>>>      #  I(is.alpha2.subordinate*z.min.co.res)+
>>>     int.is.a.log.ten||monkeyid),
>>>        data=fe.re.xx$data, REML=F, control=contr)
>>> + + + + + + + + + + + + > fullx=lmer(log.corti~
>>>    z.n.fert.females*z.n.males+
>>>    is.alpha2*(z.infanticide.susceptibility_new+z.min.co.res+z.co.res+z.log.tenure)+
>>>    z.age.at.sample+sin.season+cos.season+
>>>    (1+z.n.fert.females+z.n.males+is.alpha2.subordinate+z.infanticide.susceptibility_new+
>>>     z.min.co.res+z.log.tenure+z.co.res+
>>>     z.age.at.sample+sin.season+cos.season+
>>>     I(z.n.fert.females*z.n.males)+
>>>       I(is.alpha2.subordinate*z.co.res)+
>>>     # I(z.min.co.res*is.alpha2.subordinate)+
>>>       I(is.alpha2.subordinate*z.min.co.res)+
>>>     int.is.a.log.ten||monkeyid),
>>>        data=fe.re.xx$data, REML=F, control=contr)
>>> + + + + + + + + + + + + Error in is.alpha2.subordinate * ~z.min.co.res :
>>>  non-numeric argument to binary operator
>>>>
>>>
>>> And if I start with the one that works and delete something
>>> seemingly irrelevant, like z.infanticide.susceptibility_new+
>>>
>>>> fullx=lmer(log.corti~
>>>    z.n.fert.females*z.n.males+
>>>    is.alpha2*(z.infanticide.susceptibility_new+z.min.co.res+z.co.res+z.log.tenure)+
>>>    z.age.at.sample+sin.season+cos.season+
>>>    (1+z.n.fert.females+z.n.males+is.alpha2.subordinate+ # z.infanticide.susceptibility_new+
>>>     z.min.co.res+z.log.tenure+z.co.res+
>>>     z.age.at.sample+sin.season+cos.season+
>>>     I(z.n.fert.females*z.n.males)+
>>>       I(is.alpha2.subordinate*z.co.res)+
>>>      I(z.min.co.res*is.alpha2.subordinate)+
>>>      #  I(is.alpha2.subordinate*z.min.co.res)+
>>>     int.is.a.log.ten||monkeyid),
>>>        data=fe.re.xx$data, REML=F, control=contr)
>>> + + + + + + + + + + + + Error in is.alpha2.subordinate * ~z.co.res :
>>>  non-numeric argument to binary operator
>>>
>>> I know this is not the minimal executable example requested, but I'm
>>> hoping someone will have an idea before I try to simplify it further
>>> and provide all you need to run it.
>>
>>
>> A few thoughts:
>>
>> 1. Strip down the formula so that only the term that causes the error is present.
>>
>> If the error happens with only that term, let us know.
>>
>> If not, add each other term back in AFTER the one problematic term, one by one, until you get the error, if it happens. When that happens, keep the original term and that additional term only, and see if the error still happens with just those two terms. Let us know.
>>
>> If the error does not recur, then there may be something tied to term order, which would be curious.
>>
>>
>> 2. Can you provide the output of:
>>
>>   str(fe.re.xx$data)
>>
>> which is presumably a data frame called 'data' within a larger object called 'fe.re.xx'. Hopefully, the number of columns in the data frame is "reasonable".
>>
>> Perhaps there is something about the structure of your data frame that is causing some issue.
>>
>>
>> 3. Also, make sure that the components of each term are only in the data frame object and not otherwise in your working environment, so that there is no risk of confusion as to what objects are being passed to the formula. Essentially, use ls() to scan the content of your working environment and see if any show there.
>>
>>
>> 4. Start a new, **clean** R session and see if the error still occurs. Be sure that there are no other objects in the environment or a corrupted environment causing issues. If you have a .RData file that is loaded with a new session, delete it or move it, if you need it. Also check for a .Rprofile file that might affect your working environment.
>>
>> If you can run 'R --vanilla' from the CLI, to start a new R session, that would help with getting a clean session.
>>
>>
>> Regards,
>>
>> Marc Schwartz
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From don-r-help at isis.cs3-inc.com  Wed Jun 14 06:13:58 2017
From: don-r-help at isis.cs3-inc.com (Don Cohen)
Date: Wed, 14 Jun 2017 04:13:58 +0000
Subject: [R-sig-ME] [R] understanding I() in lmer formula
In-Reply-To: <3DEC3ECE-0F56-4DC7-A301-0E9F7488A0A5@me.com>
References: <20170613182554.D49724057F@losangelesyouthorchestra.org>
 <CAGxFJbQzn4_72Y36_w05JhMNy2pbE+Zd+xuBKZdGNHidzdWasg@mail.gmail.com>
 <22848.15077.298901.273269@losangelesyouthorchestra.org>
 <fe3095ef143648d4848298899aca5798@ME1PR01MB1442.ausprd01.prod.outlook.com>
 <0e37a14d-9197-402b-8c74-405a3d6f0af8@Spark>
 <22848.32922.391037.543832@losangelesyouthorchestra.org>
 <3DEC3ECE-0F56-4DC7-A301-0E9F7488A0A5@me.com>
Message-ID: <22848.47110.92728.214162@losangelesyouthorchestra.org>

 > 1. Strip down the formula so that only the term that causes the
 > error is present.

It's not clear what you mean by the term that causes the error.
Here's a different sort of minimal example:

 full=lmer(log.corti~z.xtime+(1 +is.alpha2.subordinate+z.infanticide.susceptibility+z.min.co.res
           +z.age.at.sample+sin.season+cos.season+ I(z.n.fert.females*z.n.males)||monkeyid),
           data=fe.re.xx$data, REML=F, control=contr)
+ + Error in z.n.fert.females * ~z.n.males : 
  non-numeric argument to binary operator
It's minimal in that leaving out any one of the other terms in the || other
than the I term does not give an error, e.g.,
leave out is.alpha2.subordinate:
 full=lmer(log.corti~z.xtime+(1 +z.infanticide.susceptibility+z.min.co.res
           +z.age.at.sample+sin.season+cos.season+ I(z.n.fert.females*z.n.males)||monkeyid),
           data=fe.re.xx$data, REML=F, control=contr)
+ + >
leave out z.infanticide.susceptibility
 full=lmer(log.corti~z.xtime+(1 +is.alpha2.subordinate+z.min.co.res
           +z.age.at.sample+sin.season+cos.season+ I(z.n.fert.females*z.n.males)||monkeyid),
           data=fe.re.xx$data, REML=F, control=contr)
+ + >
etc.

 >   str(fe.re.xx$data)
yes, loads of stuff, but z.n.fert.females and z.n.males are both
numeric, as are is.alpha2.subordinate and z.min.co.res in the
previous examples.  If this were the problem it wouldn't work when
I remove those other terms.

 > 3. use ls() ...
none of the terms in the formula appear there
Again, it seems if this were the problem it wouldn't be solved by
removing other terms.

 > 4. Start a new, **clean** R session
I did that, even started on a different machine, did a load to get
the data and library(lme4)

At this point I'd like to know how to interpret the error message:
  Error in z.n.fert.females * ~z.n.males 
  non-numeric argument to binary operator
and what's that ~ all about?


From dwinsemius at comcast.net  Wed Jun 14 08:47:36 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 13 Jun 2017 23:47:36 -0700
Subject: [R-sig-ME] [R] understanding I() in lmer formula
In-Reply-To: <22848.47110.92728.214162@losangelesyouthorchestra.org>
References: <20170613182554.D49724057F@losangelesyouthorchestra.org>
 <CAGxFJbQzn4_72Y36_w05JhMNy2pbE+Zd+xuBKZdGNHidzdWasg@mail.gmail.com>
 <22848.15077.298901.273269@losangelesyouthorchestra.org>
 <fe3095ef143648d4848298899aca5798@ME1PR01MB1442.ausprd01.prod.outlook.com>
 <0e37a14d-9197-402b-8c74-405a3d6f0af8@Spark>
 <22848.32922.391037.543832@losangelesyouthorchestra.org>
 <3DEC3ECE-0F56-4DC7-A301-0E9F7488A0A5@me.com>
 <22848.47110.92728.214162@losangelesyouthorchestra.org>
Message-ID: <A52F4585-8B4B-4018-9643-8CAFCCB3CAF5@comcast.net>


> On Jun 13, 2017, at 9:13 PM, Don Cohen <don-r-help at isis.cs3-inc.com> wrote:
> 
>> 1. Strip down the formula so that only the term that causes the
>> error is present.
> 
> It's not clear what you mean by the term that causes the error.
> Here's a different sort of minimal example:
> 
> full=lmer(log.corti~z.xtime+(1 +is.alpha2.subordinate+z.infanticide.susceptibility+z.min.co.res
>           +z.age.at.sample+sin.season+cos.season+ I(z.n.fert.females*z.n.males)||monkeyid),
>           data=fe.re.xx$data, REML=F, control=contr)
> + + Error in z.n.fert.females * ~z.n.males : 
>  non-numeric argument to binary operator
> It's minimal in that leaving out any one of the other terms in the || other
> than the I term does not give an error, e.g.,
> leave out is.alpha2.subordinate:
> full=lmer(log.corti~z.xtime+(1 +z.infanticide.susceptibility+z.min.co.res
>           +z.age.at.sample+sin.season+cos.season+ I(z.n.fert.females*z.n.males)||monkeyid),
>           data=fe.re.xx$data, REML=F, control=contr)
> + + >
> leave out z.infanticide.susceptibility
> full=lmer(log.corti~z.xtime+(1 +is.alpha2.subordinate+z.min.co.res
>           +z.age.at.sample+sin.season+cos.season+ I(z.n.fert.females*z.n.males)||monkeyid),
>           data=fe.re.xx$data, REML=F, control=contr)
> + + >
> etc.
> 
>>  str(fe.re.xx$data)
> yes, loads of stuff, but z.n.fert.females and z.n.males are both
> numeric, as are is.alpha2.subordinate and z.min.co.res in the
> previous examples.  If this were the problem it wouldn't work when
> I remove those other terms.
> 
>> 3. use ls() ...
> none of the terms in the formula appear there
> Again, it seems if this were the problem it wouldn't be solved by
> removing other terms.
> 
>> 4. Start a new, **clean** R session
> I did that, even started on a different machine, did a load to get
> the data and library(lme4)
> 
> At this point I'd like to know how to interpret the error message:
>  Error in z.n.fert.females * ~z.n.males 
>  non-numeric argument to binary operator
> and what's that ~ all about?

The expression `~z.n.males` is a unary formula, i.e. a language object, so it's not a data object much less a numeric data object. The `*` operator does not have a method for such an object as the second argument.

It appears that trying to use I() on an expression with a multiplication operator was not something that was anticipated as having a sensible meaning.

I'm not sure what this was supposed to be doing but perhaps you wanted the interaction()-function rather than the as.is function?

-- 

David Winsemius
Alameda, CA, USA


From don-r-help at isis.cs3-inc.com  Wed Jun 14 14:59:54 2017
From: don-r-help at isis.cs3-inc.com (Don Cohen)
Date: Wed, 14 Jun 2017 12:59:54 +0000
Subject: [R-sig-ME] [R] understanding I() in lmer formula
In-Reply-To: <A52F4585-8B4B-4018-9643-8CAFCCB3CAF5@comcast.net>
References: <20170613182554.D49724057F@losangelesyouthorchestra.org>
 <CAGxFJbQzn4_72Y36_w05JhMNy2pbE+Zd+xuBKZdGNHidzdWasg@mail.gmail.com>
 <22848.15077.298901.273269@losangelesyouthorchestra.org>
 <fe3095ef143648d4848298899aca5798@ME1PR01MB1442.ausprd01.prod.outlook.com>
 <0e37a14d-9197-402b-8c74-405a3d6f0af8@Spark>
 <22848.32922.391037.543832@losangelesyouthorchestra.org>
 <3DEC3ECE-0F56-4DC7-A301-0E9F7488A0A5@me.com>
 <22848.47110.92728.214162@losangelesyouthorchestra.org>
 <A52F4585-8B4B-4018-9643-8CAFCCB3CAF5@comcast.net>
Message-ID: <22849.13130.372163.582988@losangelesyouthorchestra.org>


 > The expression `~z.n.males` is a unary formula, i.e. a language
 > object, so it's not a data object much less a numeric data
 > object. The `*` operator does not have a method for such an object
 > as the second argument.

ok, so the next question is where this comes from

 > It appears that trying to use I() on an expression with a
 > multiplication operator was not something that was anticipated as
 > having a sensible meaning.

That would cause it to get the error in all those other cases where
there is no error.
Notice that the difference between getting the error and not getting
it is not in the I() term - that's the same in both cases.

 > I'm not sure what this was supposed to be doing but perhaps you
 > wanted the interaction()-function rather than the as.is function?

What all this is supposed to mean is another topic I'd also like to
discuss.  I did not write the original formula.  I'm just trying to
make small changes to it to see the effects.  Or at least I WAS trying
to make small changes.  I had already made rather large changes to
simplify the example in my first post.

I think this shows that the problem is in parsing:
 parse <- lFormula(formula = log.corti~z.n.fert.females*z.n.males+
          is.alpha2*(z.infanticide.susceptibility+z.min.co.res+z.co.res+z.log.tenure)+
          z.xtime+z.age.at.sample+sin.season+cos.season+
          (1 #+z.n.fert.females
           +z.n.males
           +is.alpha2.subordinate
           +z.infanticide.susceptibility
           +z.min.co.res
           +z.log.tenure
           +z.co.res
           # +z.xtime
           +z.age.at.sample
           +sin.season
           +cos.season+
                I(z.n.fert.females*z.n.males)+
                        I(is.alpha2.subordinate*z.min.co.res)+
              #  I(z.co.res*is.alpha2.subordinate)
                I(is.alpha2.subordinate*z.co.res)
              #  +int.is.a.log.ten
                ||monkeyid), data=fe.re.xx$data)
+ + + + + + + + + + + + + + + + + + + Error in is.alpha2.subordinate * ~z.co.res : 
  non-numeric argument to binary operator

whereas switching the order of the * arguments
parse <- lFormula(formula = log.corti~z.n.fert.females*z.n.males+
          is.alpha2*(z.infanticide.susceptibility+z.min.co.res+z.co.res+z.log.tenure)+
          z.xtime+z.age.at.sample+sin.season+cos.season+
          (1 #+z.n.fert.females
           +z.n.males
           +is.alpha2.subordinate
           +z.infanticide.susceptibility
           +z.min.co.res
           +z.log.tenure
           +z.co.res
           # +z.xtime
           +z.age.at.sample
           +sin.season
           +cos.season+
                I(z.n.fert.females*z.n.males)+
                        I(is.alpha2.subordinate*z.min.co.res)+
               I(z.co.res*is.alpha2.subordinate)
              #  I(is.alpha2.subordinate*z.co.res)
              #  +int.is.a.log.ten
                ||monkeyid), data=fe.re.xx$data)
+ + + + + + + + + + + + + + + + + + + > 
> parse$formula
log.corti ~ z.n.fert.females * z.n.males + is.alpha2 * (z.infanticide.susceptibility + 
    z.min.co.res + z.co.res + z.log.tenure) + z.xtime + z.age.at.sample + 
    sin.season + cos.season + ((1 | monkeyid) + (0 + z.n.males | 
    monkeyid) + (0 + is.alpha2.subordinate | monkeyid) + (0 + 
    z.infanticide.susceptibility | monkeyid) + (0 + z.min.co.res | 
    monkeyid) + (0 + z.log.tenure | monkeyid) + (0 + z.co.res | 
    monkeyid) + (0 + z.age.at.sample | monkeyid) + (0 + sin.season | 
    monkeyid) + (0 + cos.season | monkeyid) + (0 + I(z.n.fert.females * 
    z.n.males) | monkeyid) + (0 + I(is.alpha2.subordinate * z.min.co.res) | 
    monkeyid) + (0 + I(z.co.res * is.alpha2.subordinate) | monkeyid))

BTW, passing that result to lFormula with the
I(z.co.res * is.alpha2.subordinate) changed to
I(is.alpha2.subordinate * z.co.res )
also works.

So as a work around perhaps the solution is to start from the result
of lFormula on the original formula and make my incremental changes
to that.


From bbolker at gmail.com  Wed Jun 14 16:40:18 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 14 Jun 2017 10:40:18 -0400
Subject: [R-sig-ME] [R] understanding I() in lmer formula
In-Reply-To: <22849.13130.372163.582988@losangelesyouthorchestra.org>
References: <20170613182554.D49724057F@losangelesyouthorchestra.org>
 <CAGxFJbQzn4_72Y36_w05JhMNy2pbE+Zd+xuBKZdGNHidzdWasg@mail.gmail.com>
 <22848.15077.298901.273269@losangelesyouthorchestra.org>
 <fe3095ef143648d4848298899aca5798@ME1PR01MB1442.ausprd01.prod.outlook.com>
 <0e37a14d-9197-402b-8c74-405a3d6f0af8@Spark>
 <22848.32922.391037.543832@losangelesyouthorchestra.org>
 <3DEC3ECE-0F56-4DC7-A301-0E9F7488A0A5@me.com>
 <22848.47110.92728.214162@losangelesyouthorchestra.org>
 <A52F4585-8B4B-4018-9643-8CAFCCB3CAF5@comcast.net>
 <22849.13130.372163.582988@losangelesyouthorchestra.org>
Message-ID: <6a857152-3692-8be4-7161-a3720ba23f2f@gmail.com>



On 17-06-14 08:59 AM, Don Cohen wrote:
> 
>  > The expression `~z.n.males` is a unary formula, i.e. a language
>  > object, so it's not a data object much less a numeric data
>  > object. The `*` operator does not have a method for such an object
>  > as the second argument.
> 
> ok, so the next question is where this comes from

  Something is getting mangled internally.  One of the reasons you're
not getting much useful advice here is that this is new to us -- I've
never seen  anything like this happen before.  I keep making guesses
based on the differences between your example and the stuff people
normally try to do (I() inside random effects term, long random-effects
term), but so far my guesses haven't panned out.  This is the reason we
keep asking for a **reproducible** example; if I could run this example
myself I could almost certainly figure out what's going on, but remote
debugging is really hard.

> 
>  > It appears that trying to use I() on an expression with a
>  > multiplication operator was not something that was anticipated as
>  > having a sensible meaning.

  It is perfectly sensible: it just means "multiply these two terms
together, using the normal arithmetic meaning of *, rather than
composing their interaction"). However, if this term is indeed causing a
problem, it can be worked around by defining a new variable rather than
constructing it on the fly (this is what I suggested in my previous error).
> 
> That would cause it to get the error in all those other cases where
> there is no error.
> Notice that the difference between getting the error and not getting
> it is not in the I() term - that's the same in both cases.
> 
>  > I'm not sure what this was supposed to be doing but perhaps you
>  > wanted the interaction()-function rather than the as.is function?
> 
> What all this is supposed to mean is another topic I'd also like to
> discuss.  I did not write the original formula.  I'm just trying to
> make small changes to it to see the effects.  Or at least I WAS trying
> to make small changes.  I had already made rather large changes to
> simplify the example in my first post.

OK, I've been able to reproduce this (code below), will dig in and let
you know what I find.

----

form <- log.corti~z.n.fert.females*z.n.males+

is.alpha2*(z.infanticide.susceptibility+z.min.co.res+z.co.res+z.log.tenure)+
    z.xtime+z.age.at.sample+sin.season+cos.season+
    (1 #+z.n.fert.females
        +z.n.males
        +is.alpha2.subordinate
        +z.infanticide.susceptibility
        +z.min.co.res
        +z.log.tenure
        +z.co.res
        ## +z.xtime
        +z.age.at.sample
        +sin.season
        +cos.season+
        I(z.n.fert.females*z.n.males)+
        I(is.alpha2.subordinate*z.min.co.res)+
        ##  I(z.co.res*is.alpha2.subordinate)
        I(is.alpha2.subordinate*z.co.res)
        ##  +int.is.a.log.ten
        ||monkeyid)

xvars <- setdiff(all.vars(form),"monkeyid")
dd <- data.frame(matrix(rnorm(1000*length(xvars)),ncol=length(xvars)))
names(dd) <- xvars
dd$monkeyid <- factor(rep(1:20,50))
library(lme4)
parse <- lFormula(form, data=dd)


> 
> I think this shows that the problem is in parsing:
>  parse <- lFormula(formula = log.corti~z.n.fert.females*z.n.males+
>           is.alpha2*(z.infanticide.susceptibility+z.min.co.res+z.co.res+z.log.tenure)+
>           z.xtime+z.age.at.sample+sin.season+cos.season+
>           (1 #+z.n.fert.females
>            +z.n.males
>            +is.alpha2.subordinate
>            +z.infanticide.susceptibility
>            +z.min.co.res
>            +z.log.tenure
>            +z.co.res
>            # +z.xtime
>            +z.age.at.sample
>            +sin.season
>            +cos.season+
>                 I(z.n.fert.females*z.n.males)+
>                         I(is.alpha2.subordinate*z.min.co.res)+
>               #  I(z.co.res*is.alpha2.subordinate)
>                 I(is.alpha2.subordinate*z.co.res)
>               #  +int.is.a.log.ten
>                 ||monkeyid), data=fe.re.xx$data)
> + + + + + + + + + + + + + + + + + + + Error in is.alpha2.subordinate * ~z.co.res : 
>   non-numeric argument to binary operator
> 
> whereas switching the order of the * arguments
> parse <- lFormula(formula = log.corti~z.n.fert.females*z.n.males+
>           is.alpha2*(z.infanticide.susceptibility+z.min.co.res+z.co.res+z.log.tenure)+
>           z.xtime+z.age.at.sample+sin.season+cos.season+
>           (1 #+z.n.fert.females
>            +z.n.males
>            +is.alpha2.subordinate
>            +z.infanticide.susceptibility
>            +z.min.co.res
>            +z.log.tenure
>            +z.co.res
>            # +z.xtime
>            +z.age.at.sample
>            +sin.season
>            +cos.season+
>                 I(z.n.fert.females*z.n.males)+
>                         I(is.alpha2.subordinate*z.min.co.res)+
>                I(z.co.res*is.alpha2.subordinate)
>               #  I(is.alpha2.subordinate*z.co.res)
>               #  +int.is.a.log.ten
>                 ||monkeyid), data=fe.re.xx$data)
> + + + + + + + + + + + + + + + + + + + > 
>> parse$formula
> log.corti ~ z.n.fert.females * z.n.males + is.alpha2 * (z.infanticide.susceptibility + 
>     z.min.co.res + z.co.res + z.log.tenure) + z.xtime + z.age.at.sample + 
>     sin.season + cos.season + ((1 | monkeyid) + (0 + z.n.males | 
>     monkeyid) + (0 + is.alpha2.subordinate | monkeyid) + (0 + 
>     z.infanticide.susceptibility | monkeyid) + (0 + z.min.co.res | 
>     monkeyid) + (0 + z.log.tenure | monkeyid) + (0 + z.co.res | 
>     monkeyid) + (0 + z.age.at.sample | monkeyid) + (0 + sin.season | 
>     monkeyid) + (0 + cos.season | monkeyid) + (0 + I(z.n.fert.females * 
>     z.n.males) | monkeyid) + (0 + I(is.alpha2.subordinate * z.min.co.res) | 
>     monkeyid) + (0 + I(z.co.res * is.alpha2.subordinate) | monkeyid))
> 
> BTW, passing that result to lFormula with the
> I(z.co.res * is.alpha2.subordinate) changed to
> I(is.alpha2.subordinate * z.co.res )
> also works.
> 
> So as a work around perhaps the solution is to start from the result
> of lFormula on the original formula and make my incremental changes
> to that.
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From don-r-help at isis.cs3-inc.com  Wed Jun 14 17:33:19 2017
From: don-r-help at isis.cs3-inc.com (Don Cohen)
Date: Wed, 14 Jun 2017 15:33:19 +0000
Subject: [R-sig-ME] [R] understanding I() in lmer formula
In-Reply-To: <6a857152-3692-8be4-7161-a3720ba23f2f@gmail.com>
References: <20170613182554.D49724057F@losangelesyouthorchestra.org>
 <CAGxFJbQzn4_72Y36_w05JhMNy2pbE+Zd+xuBKZdGNHidzdWasg@mail.gmail.com>
 <22848.15077.298901.273269@losangelesyouthorchestra.org>
 <fe3095ef143648d4848298899aca5798@ME1PR01MB1442.ausprd01.prod.outlook.com>
 <0e37a14d-9197-402b-8c74-405a3d6f0af8@Spark>
 <22848.32922.391037.543832@losangelesyouthorchestra.org>
 <3DEC3ECE-0F56-4DC7-A301-0E9F7488A0A5@me.com>
 <22848.47110.92728.214162@losangelesyouthorchestra.org>
 <A52F4585-8B4B-4018-9643-8CAFCCB3CAF5@comcast.net>
 <22849.13130.372163.582988@losangelesyouthorchestra.org>
 <6a857152-3692-8be4-7161-a3720ba23f2f@gmail.com>
Message-ID: <22849.22335.513425.925957@losangelesyouthorchestra.org>

Ben Bolker writes:
 ...
 > term), but so far my guesses haven't panned out.  This is the
 > reason we keep asking for a **reproducible** example; if I could
 > run this example myself I could almost certainly figure out what's
 > going on, but remote debugging is really hard.

If it were easy to produce a minimal example I'd have done it to
begin with.  I was hoping to get some useful information with less
work than that.  And it seems I've succeeded.
 ...
 > problem, it can be worked around by defining a new variable rather
 > than constructing it on the fly (this is what I suggested in my
 > previous error).
I understood that, but editing the already parsed formula seems 
a much better work around for now. 

 > > What all this is supposed to mean is another topic I'd also like
 > > to discuss.

Admittedly this is a different topic, but it is at least related:
Can someone tell me (or tell me where to find) what || means as opposed
to | ?  I've seen the "answer" in the paper on "Fitting Linear 
Mixed-Effects Models using lme4" (I notice Benjamin Bolker is one of
the authors - I must have finally found the right place to ask!) that
says || is uncorrelated random slope and intercept and | is correlated,
but so far that doesn't make any sense to me.
Where is this correlation in the model?  Is it something to be estimated
or something given or something else?  Is it part of what is to be
minimized in fitting the model?  In fact, it would help me a lot to know
exactly what IS being minimized.  The paper above probably does answer
this question, but I seem not to have the background required to 
understand it, and it's not yet clear where to get that background.
Last time I tried reading it I gave up around eqn 16.  I thought I was 
understanding significant parts, but there were by that time enough
questions to make it impractical to try to continue.
I tried to construct some simple examples and found that | seemed to be
doing what I expected (or at least close), whereas I have no idea how
to account for the results I got from ||.

 > OK, I've been able to reproduce this (code below), will dig in and let
 > you know what I find.

Thank you.  
If I've found a bug then I'm glad to have been of at least some use.


From mensurationist at gmail.com  Tue Jun 13 22:42:05 2017
From: mensurationist at gmail.com (Andrew Robinson)
Date: Wed, 14 Jun 2017 06:42:05 +1000
Subject: [R-sig-ME] [R] understanding I() in lmer formula
In-Reply-To: <fe3095ef143648d4848298899aca5798@ME1PR01MB1442.ausprd01.prod.outlook.com>
References: <20170613182554.D49724057F@losangelesyouthorchestra.org>
 <CAGxFJbQzn4_72Y36_w05JhMNy2pbE+Zd+xuBKZdGNHidzdWasg@mail.gmail.com>
 <22848.15077.298901.273269@losangelesyouthorchestra.org>
 <fe3095ef143648d4848298899aca5798@ME1PR01MB1442.ausprd01.prod.outlook.com>
Message-ID: <0e37a14d-9197-402b-8c74-405a3d6f0af8@Spark>

Don,

can you provide a minimal executable example?

Cheers,

Andrew

On 14 Jun 2017, 6:15 AM +1000, peter dalgaard <pdalgd at gmail.com>, wrote:
> Not that I really have a clue, but what is that "~" doing in the error message??
>
> -pd
>
> > On 13 Jun 2017, at 21:20 , Don Cohen <don-r-help at isis.cs3-inc.com> wrote:
> >
> > Bert Gunter suggested posting this here:
> >
> > Is there a difference between I(x*y) and I(y*x) ?
> > I have a call to lmer that results in this complaint:
> > Error in is.alpha2.subordinate * ~z.min.co.res :
> > non-numeric argument to binary operator
> > when I change this line:
> > I(is.alpha2.subordinate*z.min.co.res)+
> > to this:
> > I(z.min.co.res*is.alpha2.subordinate)+
> > the complaint goes away.
> > I'd like to understand why.
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk Priv: PDalgd at gmail.com
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From don-r-help at isis.cs3-inc.com  Wed Jun 14 18:23:11 2017
From: don-r-help at isis.cs3-inc.com (Don Cohen)
Date: Wed, 14 Jun 2017 16:23:11 +0000
Subject: [R-sig-ME] [R] understanding I() in lmer formula
In-Reply-To: <CAET4i1dJao=jj4Kj+C9sRRV4w2XOMS7f2fbJX5ZvOfEXBJYMvA@mail.gmail.com>
References: <20170613182554.D49724057F@losangelesyouthorchestra.org>
 <CAGxFJbQzn4_72Y36_w05JhMNy2pbE+Zd+xuBKZdGNHidzdWasg@mail.gmail.com>
 <22848.15077.298901.273269@losangelesyouthorchestra.org>
 <fe3095ef143648d4848298899aca5798@ME1PR01MB1442.ausprd01.prod.outlook.com>
 <0e37a14d-9197-402b-8c74-405a3d6f0af8@Spark>
 <CAET4i1dJao=jj4Kj+C9sRRV4w2XOMS7f2fbJX5ZvOfEXBJYMvA@mail.gmail.com>
Message-ID: <22849.25327.306098.178721@losangelesyouthorchestra.org>

Dan Brooks writes:
 > Related to your second question about ||, I believe || is shorthand for
 > uncorrelating the slope and intercept, e.g:
 > fm3 <- lmer(Reaction~Days+(Days+0|Subject)+(1|Subject),data=sleepstudy)
 > fm4 <- lmer(Reaction~Days+(1+Days||Subject),data=sleepstudy)
 > 
 > As opposed to:
 > fm2 <- lmer(Reaction~Days+(Days+1|Subject),data=sleepstudy)
 > or simply:
 > fm1 <- lmer(Reaction~Days+(Days|Subject),data=sleepstudy)

Saying that it's shorthand for something else would be useful if I
understood what that something else meant!

I gather the formula language is intended to be intuitive, and maybe
it is for people who understand mixed models better than I do, but
to me fm3 and fm4 seem equally mysterious.  The idea that days+1 should
be the same as days and that days+0 should be different from days seems
counter-intuitive to me.

And the distinction between correlated vs uncorrelated also still
has to be explained - I described some of my interpretation 
problems in the previous post.


From dwinsemius at comcast.net  Wed Jun 14 18:31:26 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 14 Jun 2017 09:31:26 -0700
Subject: [R-sig-ME] [R] understanding I() in lmer formula
In-Reply-To: <6a857152-3692-8be4-7161-a3720ba23f2f@gmail.com>
References: <20170613182554.D49724057F@losangelesyouthorchestra.org>
 <CAGxFJbQzn4_72Y36_w05JhMNy2pbE+Zd+xuBKZdGNHidzdWasg@mail.gmail.com>
 <22848.15077.298901.273269@losangelesyouthorchestra.org>
 <fe3095ef143648d4848298899aca5798@ME1PR01MB1442.ausprd01.prod.outlook.com>
 <0e37a14d-9197-402b-8c74-405a3d6f0af8@Spark>
 <22848.32922.391037.543832@losangelesyouthorchestra.org>
 <3DEC3ECE-0F56-4DC7-A301-0E9F7488A0A5@me.com>
 <22848.47110.92728.214162@losangelesyouthorchestra.org>
 <A52F4585-8B4B-4018-9643-8CAFCCB3CAF5@comcast.net>
 <22849.13130.372163.582988@losangelesyouthorchestra.org>
 <6a857152-3692-8be4-7161-a3720ba23f2f@gmail.com>
Message-ID: <32AC3E41-34F0-4980-B6A1-8C2ABECB4F48@comcast.net>


> On Jun 14, 2017, at 7:40 AM, Ben Bolker <bbolker at gmail.com> wrote:
> 
> 
> 
> On 17-06-14 08:59 AM, Don Cohen wrote:
>> 
>>> The expression `~z.n.males` is a unary formula, i.e. a language
>>> object, so it's not a data object much less a numeric data
>>> object. The `*` operator does not have a method for such an object
>>> as the second argument.
>> 
>> ok, so the next question is where this comes from
> 
>  Something is getting mangled internally.  One of the reasons you're
> not getting much useful advice here is that this is new to us -- I've
> never seen  anything like this happen before.  I keep making guesses
> based on the differences between your example and the stuff people
> normally try to do (I() inside random effects term, long random-effects
> term), but so far my guesses haven't panned out.  This is the reason we
> keep asking for a **reproducible** example; if I could run this example
> myself I could almost certainly figure out what's going on, but remote
> debugging is really hard.
> 
>> 
>>> It appears that trying to use I() on an expression with a
>>> multiplication operator was not something that was anticipated as
>>> having a sensible meaning.
> 
>  It is perfectly sensible: it just means "multiply these two terms
> together, using the normal arithmetic meaning of *, rather than
> composing their interaction"). However, if this term is indeed causing a
> problem, it can be worked around by defining a new variable rather than
> constructing it on the fly (this is what I suggested in my previous error).

I didn't say it wasn't sensible, just that it might not have been anticipated. It appears to be at least superfluous if these are both numeric.

It _might_ be sensible but it also might be confusing at the interpretative level. But if these were both factors, the resulting numeric value will be some sort of an ordinal by ordinal interaction term. There would be confounding of the interaction between the first level of variable-1 with the third level of variable-2 and the third level of variable-1 and the first level of variable-2 since the coercion to numeric would mean both were mapped to 3.


>> 
>> That would cause it to get the error in all those other cases where
>> there is no error.
>> Notice that the difference between getting the error and not getting
>> it is not in the I() term - that's the same in both cases.
>> 
>>> I'm not sure what this was supposed to be doing but perhaps you
>>> wanted the interaction()-function rather than the as.is function?
>> 
>> What all this is supposed to mean is another topic I'd also like to
>> discuss.  I did not write the original formula.  I'm just trying to
>> make small changes to it to see the effects.  Or at least I WAS trying
>> to make small changes.  I had already made rather large changes to
>> simplify the example in my first post.
> 
> OK, I've been able to reproduce this (code below), will dig in and let
> you know what I find.

I'm not understanding how the example below illustrates the differences that Dan observed when reversal of the variable names in the argument to `I` caused an error in one case and no error in the second case. Was the problem occurring because the formula expanded to three-way terms with some of the terms in the form `var1*(var1*var2||var3) or var1*(var1*var2|var3) in the case causing problems, but not such a problem with var1*(var2*var1||var3)?
> 
> ----
> 
> form <- log.corti~z.n.fert.females*z.n.males+
> 
> is.alpha2*(z.infanticide.susceptibility+z.min.co.res+z.co.res+z.log.tenure)+
>    z.xtime+z.age.at.sample+sin.season+cos.season+
>    (1 #+z.n.fert.females
>        +z.n.males
>        +is.alpha2.subordinate
>        +z.infanticide.susceptibility
>        +z.min.co.res
>        +z.log.tenure
>        +z.co.res
>        ## +z.xtime
>        +z.age.at.sample
>        +sin.season
>        +cos.season+
>        I(z.n.fert.females*z.n.males)+
>        I(is.alpha2.subordinate*z.min.co.res)+
>        ##  I(z.co.res*is.alpha2.subordinate)
>        I(is.alpha2.subordinate*z.co.res)
>        ##  +int.is.a.log.ten
>        ||monkeyid)
> 
> xvars <- setdiff(all.vars(form),"monkeyid")
> dd <- data.frame(matrix(rnorm(1000*length(xvars)),ncol=length(xvars)))
> names(dd) <- xvars
> dd$monkeyid <- factor(rep(1:20,50))
> library(lme4)
> parse <- lFormula(form, data=dd)
> 
> 
>> 
>> I think this shows that the problem is in parsing:
>> parse <- lFormula(formula = log.corti~z.n.fert.females*z.n.males+
>>          is.alpha2*(z.infanticide.susceptibility+z.min.co.res+z.co.res+z.log.tenure)+
>>          z.xtime+z.age.at.sample+sin.season+cos.season+
>>          (1 #+z.n.fert.females
>>           +z.n.males
>>           +is.alpha2.subordinate
>>           +z.infanticide.susceptibility
>>           +z.min.co.res
>>           +z.log.tenure
>>           +z.co.res
>>           # +z.xtime
>>           +z.age.at.sample
>>           +sin.season
>>           +cos.season+
>>                I(z.n.fert.females*z.n.males)+
>>                        I(is.alpha2.subordinate*z.min.co.res)+
>>              #  I(z.co.res*is.alpha2.subordinate)
>>                I(is.alpha2.subordinate*z.co.res)
>>              #  +int.is.a.log.ten
>>                ||monkeyid), data=fe.re.xx$data)
>> + + + + + + + + + + + + + + + + + + + Error in is.alpha2.subordinate * ~z.co.res : 
>>  non-numeric argument to binary operator
>> 
>> whereas switching the order of the * arguments
>> parse <- lFormula(formula = log.corti~z.n.fert.females*z.n.males+
>>          is.alpha2*(z.infanticide.susceptibility+z.min.co.res+z.co.res+z.log.tenure)+
>>          z.xtime+z.age.at.sample+sin.season+cos.season+
>>          (1 #+z.n.fert.females
>>           +z.n.males
>>           +is.alpha2.subordinate
>>           +z.infanticide.susceptibility
>>           +z.min.co.res
>>           +z.log.tenure
>>           +z.co.res
>>           # +z.xtime
>>           +z.age.at.sample
>>           +sin.season
>>           +cos.season+
>>                I(z.n.fert.females*z.n.males)+
>>                        I(is.alpha2.subordinate*z.min.co.res)+
>>               I(z.co.res*is.alpha2.subordinate)
>>              #  I(is.alpha2.subordinate*z.co.res)
>>              #  +int.is.a.log.ten
>>                ||monkeyid), data=fe.re.xx$data)
>> + + + + + + + + + + + + + + + + + + + > 
>>> parse$formula
>> log.corti ~ z.n.fert.females * z.n.males + is.alpha2 * (z.infanticide.susceptibility + 
>>    z.min.co.res + z.co.res + z.log.tenure) + z.xtime + z.age.at.sample + 
>>    sin.season + cos.season + ((1 | monkeyid) + (0 + z.n.males | 
>>    monkeyid) + (0 + is.alpha2.subordinate | monkeyid) + (0 + 
>>    z.infanticide.susceptibility | monkeyid) + (0 + z.min.co.res | 
>>    monkeyid) + (0 + z.log.tenure | monkeyid) + (0 + z.co.res | 
>>    monkeyid) + (0 + z.age.at.sample | monkeyid) + (0 + sin.season | 
>>    monkeyid) + (0 + cos.season | monkeyid) + (0 + I(z.n.fert.females * 
>>    z.n.males) | monkeyid) + (0 + I(is.alpha2.subordinate * z.min.co.res) | 
>>    monkeyid) + (0 + I(z.co.res * is.alpha2.subordinate) | monkeyid))
>> 
>> BTW, passing that result to lFormula with the
>> I(z.co.res * is.alpha2.subordinate) changed to
>> I(is.alpha2.subordinate * z.co.res )
>> also works.
>> 
>> So as a work around perhaps the solution is to start from the result
>> of lFormula on the original formula and make my incremental changes
>> to that.
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

David Winsemius
Alameda, CA, USA


From bbolker at gmail.com  Wed Jun 14 18:56:51 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 14 Jun 2017 12:56:51 -0400
Subject: [R-sig-ME] [R] understanding I() in lmer formula
In-Reply-To: <32AC3E41-34F0-4980-B6A1-8C2ABECB4F48@comcast.net>
References: <20170613182554.D49724057F@losangelesyouthorchestra.org>
 <CAGxFJbQzn4_72Y36_w05JhMNy2pbE+Zd+xuBKZdGNHidzdWasg@mail.gmail.com>
 <22848.15077.298901.273269@losangelesyouthorchestra.org>
 <fe3095ef143648d4848298899aca5798@ME1PR01MB1442.ausprd01.prod.outlook.com>
 <0e37a14d-9197-402b-8c74-405a3d6f0af8@Spark>
 <22848.32922.391037.543832@losangelesyouthorchestra.org>
 <3DEC3ECE-0F56-4DC7-A301-0E9F7488A0A5@me.com>
 <22848.47110.92728.214162@losangelesyouthorchestra.org>
 <A52F4585-8B4B-4018-9643-8CAFCCB3CAF5@comcast.net>
 <22849.13130.372163.582988@losangelesyouthorchestra.org>
 <6a857152-3692-8be4-7161-a3720ba23f2f@gmail.com>
 <32AC3E41-34F0-4980-B6A1-8C2ABECB4F48@comcast.net>
Message-ID: <CABghstQ8kLSHyYZZn2BDHVKtNwydNwg4s5XSZ_bmMTdurxT7tA@mail.gmail.com>

Don't have time to engage with this fully right now, but: there was a
formula-parsing bug with the || notation, should (??) be fixed now on
Github.  You can install this version via
devtools::install_github("lme4/lme4") (but you will need compilation
tools etc.)


On Wed, Jun 14, 2017 at 12:31 PM, David Winsemius
<dwinsemius at comcast.net> wrote:
>
>> On Jun 14, 2017, at 7:40 AM, Ben Bolker <bbolker at gmail.com> wrote:
>>
>>
>>
>> On 17-06-14 08:59 AM, Don Cohen wrote:
>>>
>>>> The expression `~z.n.males` is a unary formula, i.e. a language
>>>> object, so it's not a data object much less a numeric data
>>>> object. The `*` operator does not have a method for such an object
>>>> as the second argument.
>>>
>>> ok, so the next question is where this comes from
>>
>>  Something is getting mangled internally.  One of the reasons you're
>> not getting much useful advice here is that this is new to us -- I've
>> never seen  anything like this happen before.  I keep making guesses
>> based on the differences between your example and the stuff people
>> normally try to do (I() inside random effects term, long random-effects
>> term), but so far my guesses haven't panned out.  This is the reason we
>> keep asking for a **reproducible** example; if I could run this example
>> myself I could almost certainly figure out what's going on, but remote
>> debugging is really hard.
>>
>>>
>>>> It appears that trying to use I() on an expression with a
>>>> multiplication operator was not something that was anticipated as
>>>> having a sensible meaning.
>>
>>  It is perfectly sensible: it just means "multiply these two terms
>> together, using the normal arithmetic meaning of *, rather than
>> composing their interaction"). However, if this term is indeed causing a
>> problem, it can be worked around by defining a new variable rather than
>> constructing it on the fly (this is what I suggested in my previous error).
>
> I didn't say it wasn't sensible, just that it might not have been anticipated. It appears to be at least superfluous if these are both numeric.
>
> It _might_ be sensible but it also might be confusing at the interpretative level. But if these were both factors, the resulting numeric value will be some sort of an ordinal by ordinal interaction term. There would be confounding of the interaction between the first level of variable-1 with the third level of variable-2 and the third level of variable-1 and the first level of variable-2 since the coercion to numeric would mean both were mapped to 3.
>
>
>>>
>>> That would cause it to get the error in all those other cases where
>>> there is no error.
>>> Notice that the difference between getting the error and not getting
>>> it is not in the I() term - that's the same in both cases.
>>>
>>>> I'm not sure what this was supposed to be doing but perhaps you
>>>> wanted the interaction()-function rather than the as.is function?
>>>
>>> What all this is supposed to mean is another topic I'd also like to
>>> discuss.  I did not write the original formula.  I'm just trying to
>>> make small changes to it to see the effects.  Or at least I WAS trying
>>> to make small changes.  I had already made rather large changes to
>>> simplify the example in my first post.
>>
>> OK, I've been able to reproduce this (code below), will dig in and let
>> you know what I find.
>
> I'm not understanding how the example below illustrates the differences that Dan observed when reversal of the variable names in the argument to `I` caused an error in one case and no error in the second case. Was the problem occurring because the formula expanded to three-way terms with some of the terms in the form `var1*(var1*var2||var3) or var1*(var1*var2|var3) in the case causing problems, but not such a problem with var1*(var2*var1||var3)?
>>
>> ----
>>
>> form <- log.corti~z.n.fert.females*z.n.males+
>>
>> is.alpha2*(z.infanticide.susceptibility+z.min.co.res+z.co.res+z.log.tenure)+
>>    z.xtime+z.age.at.sample+sin.season+cos.season+
>>    (1 #+z.n.fert.females
>>        +z.n.males
>>        +is.alpha2.subordinate
>>        +z.infanticide.susceptibility
>>        +z.min.co.res
>>        +z.log.tenure
>>        +z.co.res
>>        ## +z.xtime
>>        +z.age.at.sample
>>        +sin.season
>>        +cos.season+
>>        I(z.n.fert.females*z.n.males)+
>>        I(is.alpha2.subordinate*z.min.co.res)+
>>        ##  I(z.co.res*is.alpha2.subordinate)
>>        I(is.alpha2.subordinate*z.co.res)
>>        ##  +int.is.a.log.ten
>>        ||monkeyid)
>>
>> xvars <- setdiff(all.vars(form),"monkeyid")
>> dd <- data.frame(matrix(rnorm(1000*length(xvars)),ncol=length(xvars)))
>> names(dd) <- xvars
>> dd$monkeyid <- factor(rep(1:20,50))
>> library(lme4)
>> parse <- lFormula(form, data=dd)
>>
>>
>>>
>>> I think this shows that the problem is in parsing:
>>> parse <- lFormula(formula = log.corti~z.n.fert.females*z.n.males+
>>>          is.alpha2*(z.infanticide.susceptibility+z.min.co.res+z.co.res+z.log.tenure)+
>>>          z.xtime+z.age.at.sample+sin.season+cos.season+
>>>          (1 #+z.n.fert.females
>>>           +z.n.males
>>>           +is.alpha2.subordinate
>>>           +z.infanticide.susceptibility
>>>           +z.min.co.res
>>>           +z.log.tenure
>>>           +z.co.res
>>>           # +z.xtime
>>>           +z.age.at.sample
>>>           +sin.season
>>>           +cos.season+
>>>                I(z.n.fert.females*z.n.males)+
>>>                        I(is.alpha2.subordinate*z.min.co.res)+
>>>              #  I(z.co.res*is.alpha2.subordinate)
>>>                I(is.alpha2.subordinate*z.co.res)
>>>              #  +int.is.a.log.ten
>>>                ||monkeyid), data=fe.re.xx$data)
>>> + + + + + + + + + + + + + + + + + + + Error in is.alpha2.subordinate * ~z.co.res :
>>>  non-numeric argument to binary operator
>>>
>>> whereas switching the order of the * arguments
>>> parse <- lFormula(formula = log.corti~z.n.fert.females*z.n.males+
>>>          is.alpha2*(z.infanticide.susceptibility+z.min.co.res+z.co.res+z.log.tenure)+
>>>          z.xtime+z.age.at.sample+sin.season+cos.season+
>>>          (1 #+z.n.fert.females
>>>           +z.n.males
>>>           +is.alpha2.subordinate
>>>           +z.infanticide.susceptibility
>>>           +z.min.co.res
>>>           +z.log.tenure
>>>           +z.co.res
>>>           # +z.xtime
>>>           +z.age.at.sample
>>>           +sin.season
>>>           +cos.season+
>>>                I(z.n.fert.females*z.n.males)+
>>>                        I(is.alpha2.subordinate*z.min.co.res)+
>>>               I(z.co.res*is.alpha2.subordinate)
>>>              #  I(is.alpha2.subordinate*z.co.res)
>>>              #  +int.is.a.log.ten
>>>                ||monkeyid), data=fe.re.xx$data)
>>> + + + + + + + + + + + + + + + + + + + >
>>>> parse$formula
>>> log.corti ~ z.n.fert.females * z.n.males + is.alpha2 * (z.infanticide.susceptibility +
>>>    z.min.co.res + z.co.res + z.log.tenure) + z.xtime + z.age.at.sample +
>>>    sin.season + cos.season + ((1 | monkeyid) + (0 + z.n.males |
>>>    monkeyid) + (0 + is.alpha2.subordinate | monkeyid) + (0 +
>>>    z.infanticide.susceptibility | monkeyid) + (0 + z.min.co.res |
>>>    monkeyid) + (0 + z.log.tenure | monkeyid) + (0 + z.co.res |
>>>    monkeyid) + (0 + z.age.at.sample | monkeyid) + (0 + sin.season |
>>>    monkeyid) + (0 + cos.season | monkeyid) + (0 + I(z.n.fert.females *
>>>    z.n.males) | monkeyid) + (0 + I(is.alpha2.subordinate * z.min.co.res) |
>>>    monkeyid) + (0 + I(z.co.res * is.alpha2.subordinate) | monkeyid))
>>>
>>> BTW, passing that result to lFormula with the
>>> I(z.co.res * is.alpha2.subordinate) changed to
>>> I(is.alpha2.subordinate * z.co.res )
>>> also works.
>>>
>>> So as a work around perhaps the solution is to start from the result
>>> of lFormula on the original formula and make my incremental changes
>>> to that.
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> David Winsemius
> Alameda, CA, USA
>


From emmanuel.curis at parisdescartes.fr  Wed Jun 14 23:02:14 2017
From: emmanuel.curis at parisdescartes.fr (Emmanuel Curis)
Date: Wed, 14 Jun 2017 23:02:14 +0200
Subject: [R-sig-ME] [R] understanding I() in lmer formula
In-Reply-To: <22849.25327.306098.178721@losangelesyouthorchestra.org>
References: <20170613182554.D49724057F@losangelesyouthorchestra.org>
 <CAGxFJbQzn4_72Y36_w05JhMNy2pbE+Zd+xuBKZdGNHidzdWasg@mail.gmail.com>
 <22848.15077.298901.273269@losangelesyouthorchestra.org>
 <fe3095ef143648d4848298899aca5798@ME1PR01MB1442.ausprd01.prod.outlook.com>
 <0e37a14d-9197-402b-8c74-405a3d6f0af8@Spark>
 <CAET4i1dJao=jj4Kj+C9sRRV4w2XOMS7f2fbJX5ZvOfEXBJYMvA@mail.gmail.com>
 <22849.25327.306098.178721@losangelesyouthorchestra.org>
Message-ID: <20170614210213.GA18970@info124.pharmacie.univ-paris5.fr>

A tentative explaination for the correlated versus uncorrelated...

You want to understand with your ouctome/predicted variable/dependant
variable/explained variable (choose the vocabulary you're the most
familiar with) ? here, Reaction ? takes different values. A possible
explaination is that it changes (linearly) with Day ? so you take the
model Reaction = a + b * Reaction.

Measures are made on units of a population ? here, Subject ? for which
you may suspect that this linear relation is different.  In other
word, each Subject has its own slope (b) and intercept (a).

Because Subject is sampled in a bigger population, taking a new
subject will give new values of a and b, so you will consider the a
and b values for the subjects you have has a (random) sample taken
from a population, that is as random effects. You may encounter other
explainations for this depending on the books you have, but the result
is the same: a and b for each subject are realisations of a random
couple (A, B).

Since you have two random variables, A and B, the question arises
immediatly: are A and B independant (that is, knowing what is the
value taken by A does not give any information about what value will
take B, and reciprocally) or not (knowing what value took A gives an
insight about B ? for instance, knowing that A is small means you have
greatest lucks to have negative B, or whatever you can imagine).  In
other words, are the slope and the intercept completely unrelated, or
can you somehow predict the intercept when knowing the slope? For a
given Subject, if you know its intercept (A), can you expect that it
has "preferential" values of slope (B) that you couldn't guess
otherwise?

In the usual mixed effects framework, (A, B) is assumed to be
Gaussian (? normal ?).  So, dependance and correlation are equivalent
? this a special property of Gaussian distributions.  So you can read
"uncorrelated" as "independant" (this is the (Day||Subject) model, that
can also be wroten as (1|Subject) + (0+Day|Subject) ) and
"correlated" as "dependant" (this the (Day|Subject) model, that can
also be wroten as (1+Day|Subject).

If you know covariance matrices, "uncorrelated" means that the
covariance matrix of the (A, B) vector is diagonal; "correlated", that
it is not.

I hope this helps,
Best regards,


On Wed, Jun 14, 2017 at 04:23:11PM +0000, Don Cohen wrote:
? Dan Brooks writes:
?  > Related to your second question about ||, I believe || is shorthand for
?  > uncorrelating the slope and intercept, e.g:
?  > fm3 <- lmer(Reaction~Days+(Days+0|Subject)+(1|Subject),data=sleepstudy)
?  > fm4 <- lmer(Reaction~Days+(1+Days||Subject),data=sleepstudy)
?  > 
?  > As opposed to:
?  > fm2 <- lmer(Reaction~Days+(Days+1|Subject),data=sleepstudy)
?  > or simply:
?  > fm1 <- lmer(Reaction~Days+(Days|Subject),data=sleepstudy)
? 
? Saying that it's shorthand for something else would be useful if I
? understood what that something else meant!
? 
? I gather the formula language is intended to be intuitive, and maybe
? it is for people who understand mixed models better than I do, but
? to me fm3 and fm4 seem equally mysterious.  The idea that days+1 should
? be the same as days and that days+0 should be different from days seems
? counter-intuitive to me.
? 
? And the distinction between correlated vs uncorrelated also still
? has to be explained - I described some of my interpretation 
? problems in the previous post.
? 
? _______________________________________________
? R-sig-mixed-models at r-project.org mailing list
? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From emmanuel.curis at parisdescartes.fr  Wed Jun 14 23:05:58 2017
From: emmanuel.curis at parisdescartes.fr (Emmanuel Curis)
Date: Wed, 14 Jun 2017 23:05:58 +0200
Subject: [R-sig-ME] [R] understanding I() in lmer formula
In-Reply-To: <20170614210213.GA18970@info124.pharmacie.univ-paris5.fr>
References: <20170613182554.D49724057F@losangelesyouthorchestra.org>
 <CAGxFJbQzn4_72Y36_w05JhMNy2pbE+Zd+xuBKZdGNHidzdWasg@mail.gmail.com>
 <22848.15077.298901.273269@losangelesyouthorchestra.org>
 <fe3095ef143648d4848298899aca5798@ME1PR01MB1442.ausprd01.prod.outlook.com>
 <0e37a14d-9197-402b-8c74-405a3d6f0af8@Spark>
 <CAET4i1dJao=jj4Kj+C9sRRV4w2XOMS7f2fbJX5ZvOfEXBJYMvA@mail.gmail.com>
 <22849.25327.306098.178721@losangelesyouthorchestra.org>
 <20170614210213.GA18970@info124.pharmacie.univ-paris5.fr>
Message-ID: <20170614210558.GB18970@info124.pharmacie.univ-paris5.fr>

Oups, sent a little bit to quickly, read

? the model Reaction = a + b * Day ?, sorry

On Wed, Jun 14, 2017 at 11:02:14PM +0200, Emmanuel Curis wrote:
? You want to understand with your ouctome/predicted variable/dependant
? variable/explained variable (choose the vocabulary you're the most
? familiar with) ? here, Reaction ? takes different values. A possible
? explaination is that it changes (linearly) with Day ? so you take the
? model Reaction = a + b * Reaction.

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From don-r-help at isis.cs3-inc.com  Thu Jun 15 02:14:52 2017
From: don-r-help at isis.cs3-inc.com (Don Cohen)
Date: Thu, 15 Jun 2017 00:14:52 +0000
Subject: [R-sig-ME] [R] understanding I() in lmer formula
In-Reply-To: <20170614210213.GA18970@info124.pharmacie.univ-paris5.fr>
References: <20170613182554.D49724057F@losangelesyouthorchestra.org>
 <CAGxFJbQzn4_72Y36_w05JhMNy2pbE+Zd+xuBKZdGNHidzdWasg@mail.gmail.com>
 <22848.15077.298901.273269@losangelesyouthorchestra.org>
 <fe3095ef143648d4848298899aca5798@ME1PR01MB1442.ausprd01.prod.outlook.com>
 <0e37a14d-9197-402b-8c74-405a3d6f0af8@Spark>
 <CAET4i1dJao=jj4Kj+C9sRRV4w2XOMS7f2fbJX5ZvOfEXBJYMvA@mail.gmail.com>
 <22849.25327.306098.178721@losangelesyouthorchestra.org>
 <20170614210213.GA18970@info124.pharmacie.univ-paris5.fr>
Message-ID: <22849.53628.702168.981138@losangelesyouthorchestra.org>

Emmanuel Curis writes:
 > A tentative explaination for the correlated versus uncorrelated...
 > 
 > model Reaction = a + b * Reaction.
 => model Reaction = a + b * Day

 > you may suspect that this linear relation is different.  In other
 > word, each Subject has its own slope (b) and intercept (a).
 > 
 > Because Subject is sampled in a bigger population, taking a new
 > subject will give new values of a and b, so you will consider the a
 > and b values for the subjects you have has a (random) sample taken
 > from a population, that is as random effects. You may encounter other
 > explainations for this depending on the books you have, but the result
 > is the same: a and b for each subject are realisations of a random
 > couple (A, B).

ok, I understood this part (even before)

 > Since you have two random variables, A and B, the question arises
 > immediatly: are A and B independant (that is, knowing what is the
 > value taken by A does not give any information about what value will
 > take B, and reciprocally) or not (knowing what value took A gives an
 > insight about B - for instance, knowing that A is small means you have
 > greatest lucks to have negative B, or whatever you can imagine).  In
 > other words, are the slope and the intercept completely unrelated, or
 > can you somehow predict the intercept when knowing the slope? For a
 > given Subject, if you know its intercept (A), can you expect that it
 > has "preferential" values of slope (B) that you couldn't guess
 > otherwise?

I understand that the A,B values may be correlated (and did before)

 > In the usual mixed effects framework, (A, B) is assumed to be
 > Gaussian (normal).  So, dependance and correlation are equivalent
 >  this a special property of Gaussian distributions.  So you can read

I didn't know that the term (in)"dependent" had any standard technical
meaning other than (lack of) correlation.

 > "uncorrelated" as "independant" (this is the (Day||Subject) model, that
 > can also be wroten as (1|Subject) + (0+Day|Subject) ) and
 > "correlated" as "dependant" (this the (Day|Subject) model, that can
 > also be wroten as (1+Day|Subject).
 > 
 > If you know covariance matrices, "uncorrelated" means that the
 > covariance matrix of the (A, B) vector is diagonal; "correlated", that

My question is what does lmer do in each case.

If it estimates A,B for each subject based on the data for that subject,
then it can directly measure the correlation between the A's and B's.
Not only does it not need us to tell it, but I don't see why it should
do anything different if we claim (probably falsely) that they are 
independent.  Perhaps you're saying that for each subject it can estimate
A without estimating B and then separately estimate B without estimating A?
How would it do that?

I imagined the (1|Subject) is asking lmer to estimate intercept[i]
and the (0+Day|Subject) is asking it to estimate slope[i].
That means try to find values for intercept[i] and slope[i] that minimize
the sum over all points for subject i of the squares of residues
 (predicted - measured)
where predicted = intercept[i] + input * slope[i]

In my experiments I create a few data points for each of a few subjects,
and with | I see the estimates I expect for each subject - the ones that
minimize the sum of squares of residues.
When I use || I see results that I so far cannot explain at all.

If it will help I'll show you such an example (or many such).


From rudolf.marty2 at ccrs.uzh.ch  Thu Jun 15 13:37:46 2017
From: rudolf.marty2 at ccrs.uzh.ch (rudolf.marty2 at ccrs.uzh.ch)
Date: Thu, 15 Jun 2017 13:37:46 +0200
Subject: [R-sig-ME] Problems loading lme4 module into R
Message-ID: <OFFF5036BD.490CD133-ONC1258140.003F8926-C1258140.003FE273@lotus.uzh.ch>


Dear R-users

After have loaded the lme4 module into R (version 3.0.2), I immediately get
the following massage:

Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck
= vI[[j]]) :
  Namensraum ?nlme? 3.1-111 ist geladen, aber >= 3.1.123 wird ben?tigt
Zus?tzlich: Warnmeldung:
Paket ?lme4? wurde unter R Version 3.4.0 erstellt
Fehler: Laden von Paket oder Namensraum f?r ?lme4? fehlgeschlagen

Can anyone recommend me how to handle that problem?

Regards,

Rudolf
	[[alternative HTML version deleted]]


From mollieebrooks at gmail.com  Thu Jun 15 13:46:29 2017
From: mollieebrooks at gmail.com (Mollie Brooks)
Date: Thu, 15 Jun 2017 13:46:29 +0200
Subject: [R-sig-ME] Problems loading lme4 module into R
In-Reply-To: <OFFF5036BD.490CD133-ONC1258140.003F8926-C1258140.003FE273@lotus.uzh.ch>
References: <OFFF5036BD.490CD133-ONC1258140.003F8926-C1258140.003FE273@lotus.uzh.ch>
Message-ID: <EFF8898D-BA3A-4168-9846-112CDB59EC68@gmail.com>

Hi Rudolf,

It sounds like you need to update nlme to a version newer than 3.1.123.
Try install.packages("nlme")

I?m a bit surprised that installing lme4 didn?t take care of this dependency.

cheers,
Mollie


> On 15Jun 2017, at 13:37, rudolf.marty2 at ccrs.uzh.ch wrote:
> 
> 
> Dear R-users
> 
> After have loaded the lme4 module into R (version 3.0.2), I immediately get
> the following massage:
> 
> Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck
> = vI[[j]]) :
>  Namensraum ?nlme? 3.1-111 ist geladen, aber >= 3.1.123 wird ben?tigt
> Zus?tzlich: Warnmeldung:
> Paket ?lme4? wurde unter R Version 3.4.0 erstellt
> Fehler: Laden von Paket oder Namensraum f?r ?lme4? fehlgeschlagen
> 
> Can anyone recommend me how to handle that problem?
> 
> Regards,
> 
> Rudolf
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From don-r-help at isis.cs3-inc.com  Thu Jun 15 16:49:50 2017
From: don-r-help at isis.cs3-inc.com (Don Cohen)
Date: Thu, 15 Jun 2017 14:49:50 +0000
Subject: [R-sig-ME] [R] understanding I() in lmer formula
In-Reply-To: <20170615060525.GA8273@info124.pharmacie.univ-paris5.fr>
References: <20170613182554.D49724057F@losangelesyouthorchestra.org>
 <CAGxFJbQzn4_72Y36_w05JhMNy2pbE+Zd+xuBKZdGNHidzdWasg@mail.gmail.com>
 <22848.15077.298901.273269@losangelesyouthorchestra.org>
 <fe3095ef143648d4848298899aca5798@ME1PR01MB1442.ausprd01.prod.outlook.com>
 <0e37a14d-9197-402b-8c74-405a3d6f0af8@Spark>
 <CAET4i1dJao=jj4Kj+C9sRRV4w2XOMS7f2fbJX5ZvOfEXBJYMvA@mail.gmail.com>
 <22849.25327.306098.178721@losangelesyouthorchestra.org>
 <20170614210213.GA18970@info124.pharmacie.univ-paris5.fr>
 <22849.53628.702168.981138@losangelesyouthorchestra.org>
 <20170615060525.GA8273@info124.pharmacie.univ-paris5.fr>
Message-ID: <22850.40590.93442.557153@losangelesyouthorchestra.org>


          (    V(A)     cov( A, B ) )   ( f   g )
  Sigma = (                         ) = (       )
          ( cov( A, B )     V(B)    )   ( g   h )


  so the aim of lme4 (or any other software) is to find the << best >>
  values for all of these five parameters.

So when I run lmer I should be able to recover these 5 values, right?
How do I do that?

When you say it finds the best values, that means to me that the
objective function (whatever we're trying to minimize) includes 
something that depends on those parameters.
What is that function? 
I guess you have to pick some particular model in order to show its
objective function, and I suggest the simplest possible model, in
this case something like
 reaction ~ 1+days + (1+days|subject)
and similarly the || version, which I gather differs only in that
some g terms are left out.

  This is done by trying to
  find the values that allow to say << I obtained my data because they
  were the more likely to occur >>. This leads to a complex function that
  often reduce to least-squares, but not always, and in Gaussian
  mixed-effects models are not linear least-squares because of the f, g
  and h parameters.

  Traditionnally, you fix uA = uB = 0 because should they have other
  values, they could not be distinguished from the fixed part of the
  model (but you could also say that there is no distinct fixed part and
  that you try to find their values, it's the same).

  When you use (1|Day), you allow lmer to fit a model with f, g and h
  variable.

  When you use (1||Day), you constrain lmer to fit a model with g = 0
  and only f and h can be fitted.

All of this makes sense to me, but in order to really understand what's
going on I want to know the objective function.

  Note that with lmer, f, h (and g if allowed) are not obtained by first
  computing slope and intercept for all subjects, then doing usual
  descriptive statistics ...

I understand, but however the software actually works, I should be able
to see that the objective function is minimized by simply computing it
on the output and then also on various perturbations of the output.
That would tell me WHAT the software is doing.  I could worry later about
HOW it does that.

  Last note: do not confuse the correlation between A and B, the random
  effects in the population, given by g, and the correlation between the
  estimators of the (mean) slope [uA] and the estimator of the (mean)
  intercept [uB], M_A and M_B, which may be what you had in mind when
  saying that A and B values were correlated << before >> (it exists in
  usual linear regression). They correspond to different ideas:

  g means that there is in the population a kind of constraint
   between A and B ;

  the correlation between the _estimators_ means that any error on
   the estimation of the (mean) slope will lead to an error in the
   estimation of the (mean) intercept and it is a property of the
   method used to find them, not of the data/underlying world.

I had not even thought about the second of those.  
But I think that is similar to one of the outputs of summary(lmer(...))
where it says correlation of fixed effects.

  Hope this clarifies,

So far I don't think I've learned anything new, but I may be getting
close to describing to you what I'm missing.


From emmanuel.curis at parisdescartes.fr  Thu Jun 15 18:02:57 2017
From: emmanuel.curis at parisdescartes.fr (Emmanuel Curis)
Date: Thu, 15 Jun 2017 18:02:57 +0200
Subject: [R-sig-ME] [R] understanding I() in lmer formula
In-Reply-To: <22850.40590.93442.557153@losangelesyouthorchestra.org>
References: <CAGxFJbQzn4_72Y36_w05JhMNy2pbE+Zd+xuBKZdGNHidzdWasg@mail.gmail.com>
 <22848.15077.298901.273269@losangelesyouthorchestra.org>
 <fe3095ef143648d4848298899aca5798@ME1PR01MB1442.ausprd01.prod.outlook.com>
 <0e37a14d-9197-402b-8c74-405a3d6f0af8@Spark>
 <CAET4i1dJao=jj4Kj+C9sRRV4w2XOMS7f2fbJX5ZvOfEXBJYMvA@mail.gmail.com>
 <22849.25327.306098.178721@losangelesyouthorchestra.org>
 <20170614210213.GA18970@info124.pharmacie.univ-paris5.fr>
 <22849.53628.702168.981138@losangelesyouthorchestra.org>
 <20170615060525.GA8273@info124.pharmacie.univ-paris5.fr>
 <22850.40590.93442.557153@losangelesyouthorchestra.org>
Message-ID: <20170615160257.GA2241@info124.pharmacie.univ-paris5.fr>

Replies in the text. Please read about maximum likelihood methods, the
objective function is the likelihood of the data, and write it down
will give you what you want. In practice, it might be slightly
different if you used restricted maximum likelihood (REML) instead of
maximum likelihood (ML), but that does not change the interpretation
of the different models and outputs, just the objective function.

On Thu, Jun 15, 2017 at 02:49:50PM +0000, Don Cohen wrote:
? 
?           (    V(A)     cov( A, B ) )   ( f   g )
?   Sigma = (                         ) = (       )
?           ( cov( A, B )     V(B)    )   ( g   h )
? 
? 
?   so the aim of lme4 (or any other software) is to find the << best >>
?   values for all of these five parameters.
? 
? So when I run lmer I should be able to recover these 5 values, right?
? How do I do that?

All of them are in summary( lmer( formula, data = ... ) )

For ?A and ?B estimtions, you can have them with fixef()
For f, g and h, you can have them with VarCorr()

? When you say it finds the best values, that means to me that the
? objective function (whatever we're trying to minimize) includes 
? something that depends on those parameters.
? What is that function? 

The opposite of the log likelihood, -log L, of the data, more
precisely assuming independant data points

L = \prod_{i=1}^n \prod_{,j=1}^{n_i} F'(Yij=y_ij|Ai=ai,Bi=bi) G'(Ai=ai, Bi=Bi)

where F' is the density of a Gaussian of mean ai + bi * days_{i,j} and
variance sigma (the variance of epsilon, the residual) and G' the
joint density of a binormal Gaussian vector of expectation (?A, ?B)
and of covariance matrix Sigma = ( (f, g ), ( g, h ) ) and you
minimize -log L. i the subject index, j the measure index within the subject.

? I guess you have to pick some particular model in order to show its
? objective function, and I suggest the simplest possible model, in
? this case something like
?  reaction ~ 1+days + (1+days|subject)
? and similarly the || version, which I gather differs only in that
? some g terms are left out.
? 
?   This is done by trying to
?   find the values that allow to say << I obtained my data because they
?   were the more likely to occur >>. This leads to a complex function that
?   often reduce to least-squares, but not always, and in Gaussian
?   mixed-effects models are not linear least-squares because of the f, g
?   and h parameters.
? 
?   Traditionnally, you fix uA = uB = 0 because should they have other
?   values, they could not be distinguished from the fixed part of the
?   model (but you could also say that there is no distinct fixed part and
?   that you try to find their values, it's the same).
? 
?   When you use (1|Day), you allow lmer to fit a model with f, g and h
?   variable.
? 
?   When you use (1||Day), you constrain lmer to fit a model with g = 0
?   and only f and h can be fitted.
? 
? All of this makes sense to me, but in order to really understand what's
? going on I want to know the objective function.

Just write it down using the hints above... Or use the formulas in
Douglas Bates' book (or other books). They _are_ the objective
function. By e-mail, that would be almost impossible to write them in
a readable way.

?   Note that with lmer, f, h (and g if allowed) are not obtained by first
?   computing slope and intercept for all subjects, then doing usual
?   descriptive statistics ...
? 
? I understand, but however the software actually works, I should be able
? to see that the objective function is minimized by simply computing it
? on the output and then also on various perturbations of the output.

Once you wrote it, you can use dnorm to compute it, and use the logLik
function to check the results.

? That would tell me WHAT the software is doing.  I could worry later about
? HOW it does that.

It maximises the likelihood (L) ? or, equivalently, minimises -log L ?
as a function of (?A, ?B, f, g, h).

?   Last note: do not confuse the correlation between A and B, the random
?   effects in the population, given by g, and the correlation between the
?   estimators of the (mean) slope [uA] and the estimator of the (mean)
?   intercept [uB], M_A and M_B, which may be what you had in mind when
?   saying that A and B values were correlated << before >> (it exists in
?   usual linear regression). They correspond to different ideas:
? 
?   g means that there is in the population a kind of constraint
?    between A and B ;
? 
?   the correlation between the _estimators_ means that any error on
?    the estimation of the (mean) slope will lead to an error in the
?    estimation of the (mean) intercept and it is a property of the
?    method used to find them, not of the data/underlying world.
? 
? I had not even thought about the second of those.  
? But I think that is similar to one of the outputs of summary(lmer(...))
? where it says correlation of fixed effects.
? 
?   Hope this clarifies,
? 
? So far I don't think I've learned anything new, but I may be getting
? close to describing to you what I'm missing.

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From bbolker at gmail.com  Thu Jun 15 18:24:51 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 15 Jun 2017 12:24:51 -0400
Subject: [R-sig-ME] [R] understanding I() in lmer formula
In-Reply-To: <20170615160257.GA2241@info124.pharmacie.univ-paris5.fr>
References: <CAGxFJbQzn4_72Y36_w05JhMNy2pbE+Zd+xuBKZdGNHidzdWasg@mail.gmail.com>
 <22848.15077.298901.273269@losangelesyouthorchestra.org>
 <fe3095ef143648d4848298899aca5798@ME1PR01MB1442.ausprd01.prod.outlook.com>
 <0e37a14d-9197-402b-8c74-405a3d6f0af8@Spark>
 <CAET4i1dJao=jj4Kj+C9sRRV4w2XOMS7f2fbJX5ZvOfEXBJYMvA@mail.gmail.com>
 <22849.25327.306098.178721@losangelesyouthorchestra.org>
 <20170614210213.GA18970@info124.pharmacie.univ-paris5.fr>
 <22849.53628.702168.981138@losangelesyouthorchestra.org>
 <20170615060525.GA8273@info124.pharmacie.univ-paris5.fr>
 <22850.40590.93442.557153@losangelesyouthorchestra.org>
 <20170615160257.GA2241@info124.pharmacie.univ-paris5.fr>
Message-ID: <7c0e6909-eb7c-1e10-029f-88b47dbdddf3@gmail.com>


 This is all good.  vignette("lmer",package="lme4") gives all of the
technical details for lmer (glmer is a bit more complicated, and the
paper describing it is still in development ...)

On 17-06-15 12:02 PM, Emmanuel Curis wrote:
> Replies in the text. Please read about maximum likelihood methods, the
> objective function is the likelihood of the data, and write it down
> will give you what you want. In practice, it might be slightly
> different if you used restricted maximum likelihood (REML) instead of
> maximum likelihood (ML), but that does not change the interpretation
> of the different models and outputs, just the objective function.
> 
> On Thu, Jun 15, 2017 at 02:49:50PM +0000, Don Cohen wrote:
> ? 
> ?           (    V(A)     cov( A, B ) )   ( f   g )
> ?   Sigma = (                         ) = (       )
> ?           ( cov( A, B )     V(B)    )   ( g   h )
> ? 
> ? 
> ?   so the aim of lme4 (or any other software) is to find the << best >>
> ?   values for all of these five parameters.
> ? 
> ? So when I run lmer I should be able to recover these 5 values, right?
> ? How do I do that?
> 
> All of them are in summary( lmer( formula, data = ... ) )
> 
> For ?A and ?B estimtions, you can have them with fixef()
> For f, g and h, you can have them with VarCorr()
> 
> ? When you say it finds the best values, that means to me that the
> ? objective function (whatever we're trying to minimize) includes 
> ? something that depends on those parameters.
> ? What is that function? 
> 
> The opposite of the log likelihood, -log L, of the data, more
> precisely assuming independant data points
> 
> L = \prod_{i=1}^n \prod_{,j=1}^{n_i} F'(Yij=y_ij|Ai=ai,Bi=bi) G'(Ai=ai, Bi=Bi)
> 
> where F' is the density of a Gaussian of mean ai + bi * days_{i,j} and
> variance sigma (the variance of epsilon, the residual) and G' the
> joint density of a binormal Gaussian vector of expectation (?A, ?B)
> and of covariance matrix Sigma = ( (f, g ), ( g, h ) ) and you
> minimize -log L. i the subject index, j the measure index within the subject.
> 
> ? I guess you have to pick some particular model in order to show its
> ? objective function, and I suggest the simplest possible model, in
> ? this case something like
> ?  reaction ~ 1+days + (1+days|subject)
> ? and similarly the || version, which I gather differs only in that
> ? some g terms are left out.
> ? 
> ?   This is done by trying to
> ?   find the values that allow to say << I obtained my data because they
> ?   were the more likely to occur >>. This leads to a complex function that
> ?   often reduce to least-squares, but not always, and in Gaussian
> ?   mixed-effects models are not linear least-squares because of the f, g
> ?   and h parameters.
> ? 
> ?   Traditionnally, you fix uA = uB = 0 because should they have other
> ?   values, they could not be distinguished from the fixed part of the
> ?   model (but you could also say that there is no distinct fixed part and
> ?   that you try to find their values, it's the same).
> ? 
> ?   When you use (1|Day), you allow lmer to fit a model with f, g and h
> ?   variable.
> ? 
> ?   When you use (1||Day), you constrain lmer to fit a model with g = 0
> ?   and only f and h can be fitted.
> ? 
> ? All of this makes sense to me, but in order to really understand what's
> ? going on I want to know the objective function.
> 
> Just write it down using the hints above... Or use the formulas in
> Douglas Bates' book (or other books). They _are_ the objective
> function. By e-mail, that would be almost impossible to write them in
> a readable way.
> 
> ?   Note that with lmer, f, h (and g if allowed) are not obtained by first
> ?   computing slope and intercept for all subjects, then doing usual
> ?   descriptive statistics ...
> ? 
> ? I understand, but however the software actually works, I should be able
> ? to see that the objective function is minimized by simply computing it
> ? on the output and then also on various perturbations of the output.
> 
> Once you wrote it, you can use dnorm to compute it, and use the logLik
> function to check the results.
> 
> ? That would tell me WHAT the software is doing.  I could worry later about
> ? HOW it does that.
> 
> It maximises the likelihood (L) ? or, equivalently, minimises -log L ?
> as a function of (?A, ?B, f, g, h).
> 
> ?   Last note: do not confuse the correlation between A and B, the random
> ?   effects in the population, given by g, and the correlation between the
> ?   estimators of the (mean) slope [uA] and the estimator of the (mean)
> ?   intercept [uB], M_A and M_B, which may be what you had in mind when
> ?   saying that A and B values were correlated << before >> (it exists in
> ?   usual linear regression). They correspond to different ideas:
> ? 
> ?   g means that there is in the population a kind of constraint
> ?    between A and B ;
> ? 
> ?   the correlation between the _estimators_ means that any error on
> ?    the estimation of the (mean) slope will lead to an error in the
> ?    estimation of the (mean) intercept and it is a property of the
> ?    method used to find them, not of the data/underlying world.
> ? 
> ? I had not even thought about the second of those.  
> ? But I think that is similar to one of the outputs of summary(lmer(...))
> ? where it says correlation of fixed effects.
> ? 
> ?   Hope this clarifies,
> ? 
> ? So far I don't think I've learned anything new, but I may be getting
> ? close to describing to you what I'm missing.
>


From jdnewmil at dcn.davis.ca.us  Thu Jun 15 18:27:21 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 15 Jun 2017 09:27:21 -0700
Subject: [R-sig-ME] Problems loading lme4 module into R
In-Reply-To: <EFF8898D-BA3A-4168-9846-112CDB59EC68@gmail.com>
References: <OFFF5036BD.490CD133-ONC1258140.003F8926-C1258140.003FE273@lotus.uzh.ch>
 <EFF8898D-BA3A-4168-9846-112CDB59EC68@gmail.com>
Message-ID: <91CD5843-8B66-4667-B155-CD423377CB73@dcn.davis.ca.us>

R needs to be updated... 3.0 is pretty old. 
-- 
Sent from my phone. Please excuse my brevity.

On June 15, 2017 4:46:29 AM PDT, Mollie Brooks <mollieebrooks at gmail.com> wrote:
>Hi Rudolf,
>
>It sounds like you need to update nlme to a version newer than 3.1.123.
>Try install.packages("nlme")
>
>I?m a bit surprised that installing lme4 didn?t take care of this
>dependency.
>
>cheers,
>Mollie
>
>
>> On 15Jun 2017, at 13:37, rudolf.marty2 at ccrs.uzh.ch wrote:
>> 
>> 
>> Dear R-users
>> 
>> After have loaded the lme4 module into R (version 3.0.2), I
>immediately get
>> the following massage:
>> 
>> Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()),
>versionCheck
>> = vI[[j]]) :
>>  Namensraum ?nlme? 3.1-111 ist geladen, aber >= 3.1.123 wird ben?tigt
>> Zus?tzlich: Warnmeldung:
>> Paket ?lme4? wurde unter R Version 3.4.0 erstellt
>> Fehler: Laden von Paket oder Namensraum f?r ?lme4? fehlgeschlagen
>> 
>> Can anyone recommend me how to handle that problem?
>> 
>> Regards,
>> 
>> Rudolf
>> 	[[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>_______________________________________________
>R-sig-mixed-models at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From don-r-help at isis.cs3-inc.com  Thu Jun 15 21:31:34 2017
From: don-r-help at isis.cs3-inc.com (Don Cohen)
Date: Thu, 15 Jun 2017 19:31:34 +0000
Subject: [R-sig-ME] [R] understanding I() in lmer formula
In-Reply-To: <20170615160257.GA2241@info124.pharmacie.univ-paris5.fr>
References: <CAGxFJbQzn4_72Y36_w05JhMNy2pbE+Zd+xuBKZdGNHidzdWasg@mail.gmail.com>
 <22848.15077.298901.273269@losangelesyouthorchestra.org>
 <fe3095ef143648d4848298899aca5798@ME1PR01MB1442.ausprd01.prod.outlook.com>
 <0e37a14d-9197-402b-8c74-405a3d6f0af8@Spark>
 <CAET4i1dJao=jj4Kj+C9sRRV4w2XOMS7f2fbJX5ZvOfEXBJYMvA@mail.gmail.com>
 <22849.25327.306098.178721@losangelesyouthorchestra.org>
 <20170614210213.GA18970@info124.pharmacie.univ-paris5.fr>
 <22849.53628.702168.981138@losangelesyouthorchestra.org>
 <20170615060525.GA8273@info124.pharmacie.univ-paris5.fr>
 <22850.40590.93442.557153@losangelesyouthorchestra.org>
 <20170615160257.GA2241@info124.pharmacie.univ-paris5.fr>
Message-ID: <22850.57494.767115.165741@losangelesyouthorchestra.org>

Emmanuel Curis writes:
 >  So when I run lmer I should be able to recover these 5 values, right?
 >  How do I do that?
 > 
 > All of them are in summary( lmer( formula, data = ... ) )
> summary(m3fr) 
 > For uA and uB estimtions, you can have them with fixef()
 > For f, g and h, you can have them with VarCorr()

Ah, now that I compare fixef and VarCorr with summary
I see which ones you mean.

 > The opposite of the log likelihood, -log L, of the data, more
 > precisely assuming independant data points
 > 
 > L = \prod_{i=1}^n \prod_{,j=1}^{n_i} F'(Yij=y_ij|Ai=ai,Bi=bi) G'(Ai=ai, Bi=Bi)
 > 
 > where F' is the density of a Gaussian of mean ai + bi * days_{i,j} and
 > variance sigma (the variance of epsilon, the residual) and G' the
 > joint density of a binormal Gaussian vector of expectation (uA, uB)
 > and of covariance matrix Sigma = ( (f, g ), ( g, h ) ) and you
 > minimize -log L. i the subject index, j the measure index within the subject.

I'm having a little trouble with your character set (notice I've been
replacing your mu's with "u") and a little more with the \math
notation, but I think what I'm seeing above is that the likelihood
measure is computed purely from measures for the data points and the
measure for a single data point is the product of a likelihood of the
a,b pair for the group, which is G', and the likelihood of the point
given the group, which is F'.

Now this already surprises me in the sense that the cost of the 
group seems to be paid above once for every data point in the group
instead of only one time for the group.
It seems to me that if I were trying to specify the groups and 
data points I'd only have to specify each group once and within
that each data point for the group once.
But maybe this is just a matter of missing parens?
That would be 
product over all groups of
   prob for (a,b) for this group
   x 
   product over all points in the group of
      prob of point given group (related to square of residual)

A few other details:
The residual is still only one number for each point, right, so sigma,
its variance, is only one number, right?
And this is estimated by just computing the variance of the residues?
I'm guessing that's the same thing as finding the value that minimizes 
the product of the F' values.
Is there a function to compute G' ?
(Is this it?
 library(mvtnorm)
 dmvnorm(c(5.280231, 9.719769), c(5,10),matrix(c(1,-.9,-.9, 1),nrow=2,ncol=2))
)

 > Just write it down using the hints above... Or use the formulas in
 > Douglas Bates' book (or other books). They _are_ the objective
 > function. By e-mail, that would be almost impossible to write them in
 > a readable way.

Which book is this?  URL ?
lme4: Mixed-effects modeling with R, June 25, 2010 ?
http://lme4.r-forge.r-project.org/lMMwR/lrgprt.pdf ?
I'll look further at that.

Also, bbolker writes:
 vignette("lmer",package="lme4") gives all of the technical details
It gives me:
 Warning message:
 vignette 'lmer' not found 

Is this the same as (or similar to)
https://cran.r-project.org/web/packages/lme4/vignettes/Theory.pdf
Or
https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf
which seems to be the same as the one I had trouble with before.
But maybe I can make more progress in these now that I have some
ability to ask questions.

 >  So far I don't think I've learned anything new, but I may be getting
 >  close to describing to you what I'm missing.

This is progress.  It's similar to what I was expecting, but not
what I was able to explain from my simple examples.  It's possible
that the problem was in my examples, but that remains to be seen.


From dan at brooksbaseball.net  Wed Jun 14 17:41:45 2017
From: dan at brooksbaseball.net (Dan Brooks)
Date: Wed, 14 Jun 2017 11:41:45 -0400
Subject: [R-sig-ME] [R] understanding I() in lmer formula
In-Reply-To: <0e37a14d-9197-402b-8c74-405a3d6f0af8@Spark>
References: <20170613182554.D49724057F@losangelesyouthorchestra.org>
 <CAGxFJbQzn4_72Y36_w05JhMNy2pbE+Zd+xuBKZdGNHidzdWasg@mail.gmail.com>
 <22848.15077.298901.273269@losangelesyouthorchestra.org>
 <fe3095ef143648d4848298899aca5798@ME1PR01MB1442.ausprd01.prod.outlook.com>
 <0e37a14d-9197-402b-8c74-405a3d6f0af8@Spark>
Message-ID: <CAET4i1dJao=jj4Kj+C9sRRV4w2XOMS7f2fbJX5ZvOfEXBJYMvA@mail.gmail.com>

Related to your second question about ||, I believe || is shorthand for
uncorrelating the slope and intercept, e.g:
fm3 <- lmer(Reaction~Days+(Days+0|Subject)+(1|Subject),data=sleepstudy)
fm4 <- lmer(Reaction~Days+(1+Days||Subject),data=sleepstudy)

As opposed to:
fm2 <- lmer(Reaction~Days+(Days+1|Subject),data=sleepstudy)
or simply:
fm1 <- lmer(Reaction~Days+(Days|Subject),data=sleepstudy)

Although happy to be corrected by Ben Bolker if there's more complex
examples where this isn't quite right.

Best-
Dan

On Tue, Jun 13, 2017 at 4:42 PM, Andrew Robinson <mensurationist at gmail.com>
wrote:

> Don,
>
> can you provide a minimal executable example?
>
> Cheers,
>
> Andrew
>
> On 14 Jun 2017, 6:15 AM +1000, peter dalgaard <pdalgd at gmail.com>, wrote:
> > Not that I really have a clue, but what is that "~" doing in the error
> message??
> >
> > -pd
> >
> > > On 13 Jun 2017, at 21:20 , Don Cohen <don-r-help at isis.cs3-inc.com>
> wrote:
> > >
> > > Bert Gunter suggested posting this here:
> > >
> > > Is there a difference between I(x*y) and I(y*x) ?
> > > I have a call to lmer that results in this complaint:
> > > Error in is.alpha2.subordinate * ~z.min.co.res :
> > > non-numeric argument to binary operator
> > > when I change this line:
> > > I(is.alpha2.subordinate*z.min.co.res)+
> > > to this:
> > > I(z.min.co.res*is.alpha2.subordinate)+
> > > the complaint goes away.
> > > I'd like to understand why.
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> > --
> > Peter Dalgaard, Professor,
> > Center for Statistics, Copenhagen Business School
> > Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> > Phone: (+45)38153501
> > Office: A 4.23
> > Email: pd.mes at cbs.dk Priv: PDalgd at gmail.com
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From mlathouri at yahoo.gr  Thu Jun  8 12:15:59 2017
From: mlathouri at yahoo.gr (Maria Lathouri)
Date: Thu, 8 Jun 2017 10:15:59 +0000 (UTC)
Subject: [R-sig-ME] gamm plots in lattice
References: <2076684443.8279069.1496916959386.ref@mail.yahoo.com>
Message-ID: <2076684443.8279069.1496916959386@mail.yahoo.com>

Dear all,?
I am new in list. I hope that you can help me on this.?
I am running a generalised mixed effect model, gamm4, for an ecology project. Below is the code for the model:
model<-gamm4(LIFE.OE_spring~s(Q95, by=super.end.group)+Year+Hms_Rsctned+Hms_Poaching+X.broadleaved_woodland? ? ? ? ? ? ?+X.urban.suburban+X.CapWks, data=spring, random=~(1|WATERBODY_ID/SITE_ID))
I am trying to plot the results in lattice for publication purposes so I need to figure this out. I have been struggling but I think I have reached a dead end.?

Here is what I have been able to code:
M<-predict(model$gam,type="response",se.fit=T)
upr<- M$fit + (1.96 * M$se.fit)lwr<- M$fit - (1.96 * M$se.fit)
library(lattice)xyplot(fitted(model$gam) ~ Q95 |super.end.group, data = spring, gm=model,? ? ? ?prepanel=function (x,y,...)list(ylim=c(min(upr),max(lwr))),? ? ? ?panel = function(x,y, gm, ...){ ? ??? ? ? ? ?panel.xyplot(x,y, type="smooth")? ? ? ? ?panel.lines(upr,lty=2, col="red")? ? ? ? ?panel.lines(lwr,lty=2, col="red")? ? ? ? ?panel.loess(x,y,...)? ? ? ? ?panel.rug(x = x[is.na(y)],? ? ? ? ? ? ? ? ? ?y = y[is.na(x)])? ? ? ?}? ? ? ?)
But, unfortunately, this is not what I get when I have the simple plot(model$gam).?

I have also attached a reproducible example in case you want to see for yourself. I hope that someone here has come up with a similar problem and can help me on this.
Thank you very much for your time.
Kind regards,Maria?
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: example.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20170608/ac10b235/attachment-0001.txt>

From Wouter.Broos at UGent.be  Fri Jun 16 11:02:39 2017
From: Wouter.Broos at UGent.be (Wouter Broos)
Date: Fri, 16 Jun 2017 09:02:39 +0000
Subject: [R-sig-ME] Question glmmADMB
Message-ID: <1497603955062.26738@UGent.be>

 Dear Professor Bolker,


 At the moment, I am working on a data set that contains
 information on 'number of errors' that are made by participants. Thus
 far, I used poisson regression to create generalized mixed effects
 models of the data. In order to use poisson regression I aggregated the
 data set by participant and by category. There are eight different
 categories in total (I've added the data for ease of reference). There
 are three main factors that determine the category: 1. Outcome: The
 error that is made can be lexical or non-lexical / 2. Context: The
 context of the block where the error was made can be mixed or
 non-lexical / 3. Language: The language in which the error is made can
 be the first language (L1) or the second language (L2). So, the
 dependent variable in the model is 'Number of Errors' and the fixed
 factors are 'Outcome', 'Context', and 'Language'. All factors
 interaction with one another. One potential problem with the data set is
 that there is an imbalance in the number of '0 number of errors per
 category' and the '1/2/3 number of errors'. However, the zeros in my
 data set can be explained in only one way: no mistake was made by that
 participant in that category. So my first question is: do I need to add
 the zero-inflation component to the model?



 I tried using the glmmADMB package that can take zero-inflation into
 account in order to see whether there are differences with the normal
 poisson model and the zero-inflated model. However, when I ran the
 model, I got the error:


 *Parameters were estimated, but standard errors were not: the most
 likely problem is that the curvature at MLE was zero or negative*

 *Error in glmmadmb(Num_Mistakes ~ (Context * Outcome) + (1 | Subject),  : *

 *  The function maximizer failed (couldn't find parameter file)
 Troubleshooting steps include (1) run with 'save.dir' set and inspect
 output files; (2) change run parameters: see '?admbControl';(3) re-run
 with debug=TRUE for more information on failure mode*

 *In addition: Warning message:*

 *running command 'C:\WINDOWS\system32\cmd.exe /c glmmadmb -maxfn 500
 -maxph 5 -noinit -shess' had status 1*



 I tried leaving out one or two factors, googled the problem and tried
 several 'solutions' but nothing works. So my second question is: how can
 I solve this problem? I also used other packages where zero-inflation
 could also be inserted (glmmTMB and mgcv). When I run the glmmTMB model,
 zero-inflation works (but only for the interaction Context*Outcome, not
 when I try to include Language) but the standard errors for the
 zero-inflated model are rather large (and huge for the interaction)
 leading to p-values of 1. An additional problem with glmmTMB is that I
 cannot use all three factors because there are 'extreme or very small
 eigenvalues'. The R-script is added as an attachment to the e-mail so
 that you can see what I did. Would you be willing to help me out or do
 you have any suggestions as to what I can do next? Thank you.



 Kind regards,

 Wouter Broos?

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Sat Jun 17 00:11:29 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 17 Jun 2017 10:11:29 +1200
Subject: [R-sig-ME] Question glmmADMB
In-Reply-To: <1497603955062.26738@UGent.be>
References: <1497603955062.26738@UGent.be>
Message-ID: <040c5eb5-f31c-da0c-f380-f92ad370bd47@auckland.ac.nz>

On 16/06/17 21:02, Wouter Broos wrote:
>   Dear Professor Bolker,


You should be aware that your message was sent to the r-sig-mixed-models 
mailing list.  This is *NOT* Ben Bolker's personal email address.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From bbolker at gmail.com  Sat Jun 17 02:51:48 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 16 Jun 2017 20:51:48 -0400
Subject: [R-sig-ME] [R] understanding I() in lmer formula
In-Reply-To: <CAET4i1dJao=jj4Kj+C9sRRV4w2XOMS7f2fbJX5ZvOfEXBJYMvA@mail.gmail.com>
References: <20170613182554.D49724057F@losangelesyouthorchestra.org>
 <CAGxFJbQzn4_72Y36_w05JhMNy2pbE+Zd+xuBKZdGNHidzdWasg@mail.gmail.com>
 <22848.15077.298901.273269@losangelesyouthorchestra.org>
 <fe3095ef143648d4848298899aca5798@ME1PR01MB1442.ausprd01.prod.outlook.com>
 <0e37a14d-9197-402b-8c74-405a3d6f0af8@Spark>
 <CAET4i1dJao=jj4Kj+C9sRRV4w2XOMS7f2fbJX5ZvOfEXBJYMvA@mail.gmail.com>
Message-ID: <62354371-1519-d33c-fd0f-ae7ca88f282a@gmail.com>




On 17-06-14 11:41 AM, Dan Brooks wrote:
> Related to your second question about ||, I believe || is shorthand for
> uncorrelating the slope and intercept, e.g:
> fm3 <- lmer(Reaction~Days+(Days+0|Subject)+(1|Subject),data=sleepstudy)
> fm4 <- lmer(Reaction~Days+(1+Days||Subject),data=sleepstudy)
> 
> As opposed to:
> fm2 <- lmer(Reaction~Days+(Days+1|Subject),data=sleepstudy)
> or simply:
> fm1 <- lmer(Reaction~Days+(Days|Subject),data=sleepstudy)
> 
> Although happy to be corrected by Ben Bolker if there's more complex
> examples where this isn't quite right.
> 
> Best-
> Dan

  That's exactly right.  Note that || does *not* work as expected/as one
might want it to when one or more of the terms to the left of the bars
is a factor.

  cheers
   Ben Bolker

> 
> On Tue, Jun 13, 2017 at 4:42 PM, Andrew Robinson <mensurationist at gmail.com>
> wrote:
> 
>> Don,
>>
>> can you provide a minimal executable example?
>>
>> Cheers,
>>
>> Andrew
>>
>> On 14 Jun 2017, 6:15 AM +1000, peter dalgaard <pdalgd at gmail.com>, wrote:
>>> Not that I really have a clue, but what is that "~" doing in the error
>> message??
>>>
>>> -pd
>>>
>>>> On 13 Jun 2017, at 21:20 , Don Cohen <don-r-help at isis.cs3-inc.com>
>> wrote:
>>>>
>>>> Bert Gunter suggested posting this here:
>>>>
>>>> Is there a difference between I(x*y) and I(y*x) ?
>>>> I have a call to lmer that results in this complaint:
>>>> Error in is.alpha2.subordinate * ~z.min.co.res :
>>>> non-numeric argument to binary operator
>>>> when I change this line:
>>>> I(is.alpha2.subordinate*z.min.co.res)+
>>>> to this:
>>>> I(z.min.co.res*is.alpha2.subordinate)+
>>>> the complaint goes away.
>>>> I'd like to understand why.
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>> --
>>> Peter Dalgaard, Professor,
>>> Center for Statistics, Copenhagen Business School
>>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>>> Phone: (+45)38153501
>>> Office: A 4.23
>>> Email: pd.mes at cbs.dk Priv: PDalgd at gmail.com
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From don-r-help at isis.cs3-inc.com  Sat Jun 17 05:48:41 2017
From: don-r-help at isis.cs3-inc.com (Don Cohen)
Date: Sat, 17 Jun 2017 03:48:41 +0000
Subject: [R-sig-ME] [R] understanding I() in lmer formula
In-Reply-To: <20170615160257.GA2241@info124.pharmacie.univ-paris5.fr>
References: <CAGxFJbQzn4_72Y36_w05JhMNy2pbE+Zd+xuBKZdGNHidzdWasg@mail.gmail.com>
 <22848.15077.298901.273269@losangelesyouthorchestra.org>
 <fe3095ef143648d4848298899aca5798@ME1PR01MB1442.ausprd01.prod.outlook.com>
 <0e37a14d-9197-402b-8c74-405a3d6f0af8@Spark>
 <CAET4i1dJao=jj4Kj+C9sRRV4w2XOMS7f2fbJX5ZvOfEXBJYMvA@mail.gmail.com>
 <22849.25327.306098.178721@losangelesyouthorchestra.org>
 <20170614210213.GA18970@info124.pharmacie.univ-paris5.fr>
 <22849.53628.702168.981138@losangelesyouthorchestra.org>
 <20170615060525.GA8273@info124.pharmacie.univ-paris5.fr>
 <22850.40590.93442.557153@losangelesyouthorchestra.org>
 <20170615160257.GA2241@info124.pharmacie.univ-paris5.fr>
Message-ID: <22852.42649.460077.856827@losangelesyouthorchestra.org>


(Probably I should change the subject line and admit that this is no
longer about I().)

Emmanuel Curis writes:
 > L = \prod_{i=1}^n \prod_{,j=1}^{n_i} F'(Yij=y_ij|Ai=ai,Bi=bi) G'(Ai=ai, Bi=Bi)
 > 
 > where F' is the density of a Gaussian of mean ai + bi * days_{i,j} and
 > variance sigma (the variance of epsilon, the residual) and G' the
 > joint density of a binormal Gaussian vector of expectation (uA, uB)
 > and of covariance matrix Sigma = ( (f, g ), ( g, h ) ) and you
 > minimize -log L. i the subject index, j the measure index within the subject.
 ...
 > Once you wrote it, you can use dnorm to compute it, and use the logLik
 > function to check the results.

I'm trying to do this and things are not working out quite as I hoped.
Starting with the result of lmer on my sample data:
  > summary(xm) 
  Linear mixed model fit by maximum likelihood  ['lmerMod'] 
  Formula: xout ~ xin + (xin | xid) 
     Data: xd 

       AIC      BIC   logLik deviance df.resid  
     -16.2    -15.7     14.1    -28.2        2  

  Scaled residuals:  
       Min       1Q   Median       3Q      Max  
  -0.89383 -0.29515  0.05005  0.33286  0.80360  

  Random effects: 
   Groups   Name        Variance  Std.Dev. Corr  
   xid      (Intercept) 2.814e-03 0.053051       
            xin         6.583e-03 0.081134 -0.03 
   Residual             4.917e-05 0.007012       
  Number of obs: 8, groups:  xid, 3 

  Fixed effects: 
              Estimate Std. Error t value 
  (Intercept)  0.06061    0.03172   1.911 
  xin          1.00397    0.04713  21.301 

  Correlation of Fixed Effects: 
      (Intr) 
  xin -0.058 

  > coef(xm) 
  $xid 
    (Intercept)      xin 
  a  0.09870105 1.100632 
  b -0.01183068 1.008098 
  c  0.09496031 0.903172 

The good news is that I seem to be correctly computing the predicted
values, e.g., 0.09870105 + 1.100632 * xin for a data point in
group "a" gives a value which differs from its xout value by the same
amount as the corresponding value of xm at resp$wtres (which I surmise
is a vector of the residues).
So I expect that F' will be 
 dnorm(xm at resp$wtres ...)
The mean should be zero, by design ...
  > mean(xm at resp$wtres) 
  [1] -2.775558e-17 
as expected, essentially zero

The sd to pass to dnorm should be what?  Is that the .007012 from 
this line above?
   Residual             4.917e-05 0.007012       
That's not very close to what I see in the actual residuals:
  > var(xm at resp$wtres) 
  [1] 1.566477e-05 
  > sd(xm at resp$wtres) 
  [1] 0.003957874 
And I'd expect the value to be at least close to the actual SD of
the residuals.  If the correct value is neither of the two above,
please tell me what it is (or how to find it).

Then for G, I'm even less certain.  I suspect I'm supposed to use
dmvnorm(...)
The first argument would be one of the lines from the coef output above,
such as c(0.09870105, 1.100632), right?
The second (mean) would be the estimates of the fixed effects,
 c(0.06061,1.00397), right?
And the third, is supposed to be the variance-covariance matrix.
That would be your 
 f g
 g h
where f and h, are the two variances shown under:
  Random effects: 
   Groups   Name        Variance  Std.Dev. Corr  
   xid      (Intercept) 2.814e-03 0.053051       
            xin         6.583e-03 0.081134 -0.03 
   Residual             4.917e-05 0.007012       
so f = 2.814e-03, h = 6.583e-03
and g, I *think* would be the product of the two SD's and the Corr,
or 0.053051 * 0.081134 * -0.03
Is that all correct?

I hope you can see some errors above, since this doesn't look like
it's going to end up computing anything like the logLik of 14.1 !

Also, I have the feeling that all of this output is rounded, and that
I'd get better results (or at least results that agree with the other
results computed in the model) if I could find these data in the model
rather than copying them from the output.  I've found some of it, like
the residues (at least that's what I think wtres is!), but other data
above, such f,g,h I have not yet found.  If you can tell me how to find
(or compute) them, that would be helpful.


From bbolker at gmail.com  Sat Jun 17 16:33:04 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 17 Jun 2017 10:33:04 -0400
Subject: [R-sig-ME] [R] understanding I() in lmer formula
In-Reply-To: <22852.42649.460077.856827@losangelesyouthorchestra.org>
References: <CAGxFJbQzn4_72Y36_w05JhMNy2pbE+Zd+xuBKZdGNHidzdWasg@mail.gmail.com>
 <22848.15077.298901.273269@losangelesyouthorchestra.org>
 <fe3095ef143648d4848298899aca5798@ME1PR01MB1442.ausprd01.prod.outlook.com>
 <0e37a14d-9197-402b-8c74-405a3d6f0af8@Spark>
 <CAET4i1dJao=jj4Kj+C9sRRV4w2XOMS7f2fbJX5ZvOfEXBJYMvA@mail.gmail.com>
 <22849.25327.306098.178721@losangelesyouthorchestra.org>
 <20170614210213.GA18970@info124.pharmacie.univ-paris5.fr>
 <22849.53628.702168.981138@losangelesyouthorchestra.org>
 <20170615060525.GA8273@info124.pharmacie.univ-paris5.fr>
 <22850.40590.93442.557153@losangelesyouthorchestra.org>
 <20170615160257.GA2241@info124.pharmacie.univ-paris5.fr>
 <22852.42649.460077.856827@losangelesyouthorchestra.org>
Message-ID: <CABghstSxz9g+D7MbQgTW7CGqJDiFhrDzR3tQROOexhcJPJdn1w@mail.gmail.com>

For the level of detail you're getting into, it would be a really good
idea to read the paper that accompanies the lme4 package:
vignette("lmer",package="lme4") .  This goes into a lot of detail
about the theory and data structures ...



On Fri, Jun 16, 2017 at 11:48 PM, Don Cohen <don-r-help at isis.cs3-inc.com> wrote:
>
> (Probably I should change the subject line and admit that this is no
> longer about I().)
>
> Emmanuel Curis writes:
>  > L = \prod_{i=1}^n \prod_{,j=1}^{n_i} F'(Yij=y_ij|Ai=ai,Bi=bi) G'(Ai=ai, Bi=Bi)
>  >
>  > where F' is the density of a Gaussian of mean ai + bi * days_{i,j} and
>  > variance sigma (the variance of epsilon, the residual) and G' the
>  > joint density of a binormal Gaussian vector of expectation (uA, uB)
>  > and of covariance matrix Sigma = ( (f, g ), ( g, h ) ) and you
>  > minimize -log L. i the subject index, j the measure index within the subject.
>  ...
>  > Once you wrote it, you can use dnorm to compute it, and use the logLik
>  > function to check the results.
>
> I'm trying to do this and things are not working out quite as I hoped.
> Starting with the result of lmer on my sample data:
>   > summary(xm)
>   Linear mixed model fit by maximum likelihood  ['lmerMod']
>   Formula: xout ~ xin + (xin | xid)
>      Data: xd
>
>        AIC      BIC   logLik deviance df.resid
>      -16.2    -15.7     14.1    -28.2        2
>
>   Scaled residuals:
>        Min       1Q   Median       3Q      Max
>   -0.89383 -0.29515  0.05005  0.33286  0.80360
>
>   Random effects:
>    Groups   Name        Variance  Std.Dev. Corr
>    xid      (Intercept) 2.814e-03 0.053051
>             xin         6.583e-03 0.081134 -0.03
>    Residual             4.917e-05 0.007012
>   Number of obs: 8, groups:  xid, 3
>
>   Fixed effects:
>               Estimate Std. Error t value
>   (Intercept)  0.06061    0.03172   1.911
>   xin          1.00397    0.04713  21.301
>
>   Correlation of Fixed Effects:
>       (Intr)
>   xin -0.058
>
>   > coef(xm)
>   $xid
>     (Intercept)      xin
>   a  0.09870105 1.100632
>   b -0.01183068 1.008098
>   c  0.09496031 0.903172
>
> The good news is that I seem to be correctly computing the predicted
> values, e.g., 0.09870105 + 1.100632 * xin for a data point in
> group "a" gives a value which differs from its xout value by the same
> amount as the corresponding value of xm at resp$wtres (which I surmise
> is a vector of the residues).
> So I expect that F' will be
>  dnorm(xm at resp$wtres ...)
> The mean should be zero, by design ...
>   > mean(xm at resp$wtres)
>   [1] -2.775558e-17
> as expected, essentially zero
>
> The sd to pass to dnorm should be what?  Is that the .007012 from
> this line above?
>    Residual             4.917e-05 0.007012
> That's not very close to what I see in the actual residuals:
>   > var(xm at resp$wtres)
>   [1] 1.566477e-05
>   > sd(xm at resp$wtres)
>   [1] 0.003957874
> And I'd expect the value to be at least close to the actual SD of
> the residuals.  If the correct value is neither of the two above,
> please tell me what it is (or how to find it).
>
> Then for G, I'm even less certain.  I suspect I'm supposed to use
> dmvnorm(...)
> The first argument would be one of the lines from the coef output above,
> such as c(0.09870105, 1.100632), right?
> The second (mean) would be the estimates of the fixed effects,
>  c(0.06061,1.00397), right?
> And the third, is supposed to be the variance-covariance matrix.
> That would be your
>  f g
>  g h
> where f and h, are the two variances shown under:
>   Random effects:
>    Groups   Name        Variance  Std.Dev. Corr
>    xid      (Intercept) 2.814e-03 0.053051
>             xin         6.583e-03 0.081134 -0.03
>    Residual             4.917e-05 0.007012
> so f = 2.814e-03, h = 6.583e-03
> and g, I *think* would be the product of the two SD's and the Corr,
> or 0.053051 * 0.081134 * -0.03
> Is that all correct?
>
> I hope you can see some errors above, since this doesn't look like
> it's going to end up computing anything like the logLik of 14.1 !
>
> Also, I have the feeling that all of this output is rounded, and that
> I'd get better results (or at least results that agree with the other
> results computed in the model) if I could find these data in the model
> rather than copying them from the output.  I've found some of it, like
> the residues (at least that's what I think wtres is!), but other data
> above, such f,g,h I have not yet found.  If you can tell me how to find
> (or compute) them, that would be helpful.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From don-r-help at isis.cs3-inc.com  Sat Jun 17 18:29:35 2017
From: don-r-help at isis.cs3-inc.com (Don Cohen)
Date: Sat, 17 Jun 2017 16:29:35 +0000
Subject: [R-sig-ME] [R] understanding I() in lmer formula
In-Reply-To: <CABghstSxz9g+D7MbQgTW7CGqJDiFhrDzR3tQROOexhcJPJdn1w@mail.gmail.com>
References: <CAGxFJbQzn4_72Y36_w05JhMNy2pbE+Zd+xuBKZdGNHidzdWasg@mail.gmail.com>
 <22848.15077.298901.273269@losangelesyouthorchestra.org>
 <fe3095ef143648d4848298899aca5798@ME1PR01MB1442.ausprd01.prod.outlook.com>
 <0e37a14d-9197-402b-8c74-405a3d6f0af8@Spark>
 <CAET4i1dJao=jj4Kj+C9sRRV4w2XOMS7f2fbJX5ZvOfEXBJYMvA@mail.gmail.com>
 <22849.25327.306098.178721@losangelesyouthorchestra.org>
 <20170614210213.GA18970@info124.pharmacie.univ-paris5.fr>
 <22849.53628.702168.981138@losangelesyouthorchestra.org>
 <20170615060525.GA8273@info124.pharmacie.univ-paris5.fr>
 <22850.40590.93442.557153@losangelesyouthorchestra.org>
 <20170615160257.GA2241@info124.pharmacie.univ-paris5.fr>
 <22852.42649.460077.856827@losangelesyouthorchestra.org>
 <CABghstSxz9g+D7MbQgTW7CGqJDiFhrDzR3tQROOexhcJPJdn1w@mail.gmail.com>
Message-ID: <22853.22767.53499.359252@losangelesyouthorchestra.org>

Ben Bolker writes:
 > For the level of detail you're getting into, it would be a really good
 > idea to read the paper that accompanies the lme4 package:
 > vignette("lmer",package="lme4") .  This goes into a lot of detail
 > about the theory and data structures ...

 vignette("lmer",package="lme4") 
gives me
 Warning message: 
 vignette 'lmer' not found  

Is this the same as 
https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf ?

I think that's the same one that I was having trouble with before
and gave up around eqn 15.
Although, I had the impression that it (looks like eqn 14) was
describing what I expected and asked about in a previous message,
namely paying only once for each group and then once for each data
point within the group.

Are you saying that the vignette link above actually answers the
questions in this last message about how to compute the loglik of
the model?  It doesn't look to me like it will.  
I view my current line of questions (and I have many more, but am
trying to resist bombarding you with all at once) as a way to get
the background I'll need to get through that paper.

In fact, one of my questions when I read that paper was what 
correlated vs uncorrelated intercept and slope meant - I didn't 
see any explanation.  I think that Emmanuel Curis has now explained
that, but I'm still trying to check my understanding.

Since I'm writing anyway, let me indulge in one more question about
the formulas.  Since (x|g) means correlated intercept and slope for
x, does (x+y|g) include a separate correlation between x slope and
y slope?  That is, the cost of specifying a group would involve a
3 dimensional normal distribution over intercept,x,y ?


From bbolker at gmail.com  Sat Jun 17 20:23:26 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 17 Jun 2017 14:23:26 -0400
Subject: [R-sig-ME] [R] understanding I() in lmer formula
In-Reply-To: <22853.22767.53499.359252@losangelesyouthorchestra.org>
References: <CAGxFJbQzn4_72Y36_w05JhMNy2pbE+Zd+xuBKZdGNHidzdWasg@mail.gmail.com>
 <22848.15077.298901.273269@losangelesyouthorchestra.org>
 <fe3095ef143648d4848298899aca5798@ME1PR01MB1442.ausprd01.prod.outlook.com>
 <0e37a14d-9197-402b-8c74-405a3d6f0af8@Spark>
 <CAET4i1dJao=jj4Kj+C9sRRV4w2XOMS7f2fbJX5ZvOfEXBJYMvA@mail.gmail.com>
 <22849.25327.306098.178721@losangelesyouthorchestra.org>
 <20170614210213.GA18970@info124.pharmacie.univ-paris5.fr>
 <22849.53628.702168.981138@losangelesyouthorchestra.org>
 <20170615060525.GA8273@info124.pharmacie.univ-paris5.fr>
 <22850.40590.93442.557153@losangelesyouthorchestra.org>
 <20170615160257.GA2241@info124.pharmacie.univ-paris5.fr>
 <22852.42649.460077.856827@losangelesyouthorchestra.org>
 <CABghstSxz9g+D7MbQgTW7CGqJDiFhrDzR3tQROOexhcJPJdn1w@mail.gmail.com>
 <22853.22767.53499.359252@losangelesyouthorchestra.org>
Message-ID: <CABghstQ7BW9fLX=CUX3t-4BkaTsKTXYrhzV=_Mb4YmvpVFwE=w@mail.gmail.com>

On Sat, Jun 17, 2017 at 12:29 PM, Don Cohen <don-r-help at isis.cs3-inc.com> wrote:
> Ben Bolker writes:
>  > For the level of detail you're getting into, it would be a really good
>  > idea to read the paper that accompanies the lme4 package:
>  > vignette("lmer",package="lme4") .  This goes into a lot of detail
>  > about the theory and data structures ...
>
>  vignette("lmer",package="lme4")
> gives me
>  Warning message:
>  vignette 'lmer' not found

That's surprising ... what's packageVersion("lme4") ?
>
> Is this the same as
> https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf ?

  Yes.

>
> I think that's the same one that I was having trouble with before
> and gave up around eqn 15.
> Although, I had the impression that it (looks like eqn 14) was
> describing what I expected and asked about in a previous message,
> namely paying only once for each group and then once for each data
> point within the group.
>
> Are you saying that the vignette link above actually answers the
> questions in this last message about how to compute the loglik of
> the model?  It doesn't look to me like it will.
> I view my current line of questions (and I have many more, but am
> trying to resist bombarding you with all at once) as a way to get
> the background I'll need to get through that paper.

   I would also recommend checking out Pinheiro and Bates (2000),
which is a full (book-length) treatment of the same topic, so is a
tiny bit more discursive/friendlier ...

>
> In fact, one of my questions when I read that paper was what
> correlated vs uncorrelated intercept and slope meant - I didn't
> see any explanation.  I think that Emmanuel Curis has now explained
> that, but I'm still trying to check my understanding.
>
> Since I'm writing anyway, let me indulge in one more question about
> the formulas.  Since (x|g) means correlated intercept and slope for
> x, does (x+y|g) include a separate correlation between x slope and
> y slope?  That is, the cost of specifying a group would involve a
> 3 dimensional normal distribution over intercept,x,y ?

  Yes.    (So in particular this model are 3*(3+1)/2=6 parameters
(equivalent to s^2{1}, s^2(x),s^2(y), cov(1,x), cov(1,y), cov(x,y))


From don-r-help at isis.cs3-inc.com  Sat Jun 17 20:59:15 2017
From: don-r-help at isis.cs3-inc.com (Don Cohen)
Date: Sat, 17 Jun 2017 18:59:15 +0000
Subject: [R-sig-ME] [R] understanding I() in lmer formula
In-Reply-To: <CABghstQ7BW9fLX=CUX3t-4BkaTsKTXYrhzV=_Mb4YmvpVFwE=w@mail.gmail.com>
References: <CAGxFJbQzn4_72Y36_w05JhMNy2pbE+Zd+xuBKZdGNHidzdWasg@mail.gmail.com>
 <22848.15077.298901.273269@losangelesyouthorchestra.org>
 <fe3095ef143648d4848298899aca5798@ME1PR01MB1442.ausprd01.prod.outlook.com>
 <0e37a14d-9197-402b-8c74-405a3d6f0af8@Spark>
 <CAET4i1dJao=jj4Kj+C9sRRV4w2XOMS7f2fbJX5ZvOfEXBJYMvA@mail.gmail.com>
 <22849.25327.306098.178721@losangelesyouthorchestra.org>
 <20170614210213.GA18970@info124.pharmacie.univ-paris5.fr>
 <22849.53628.702168.981138@losangelesyouthorchestra.org>
 <20170615060525.GA8273@info124.pharmacie.univ-paris5.fr>
 <22850.40590.93442.557153@losangelesyouthorchestra.org>
 <20170615160257.GA2241@info124.pharmacie.univ-paris5.fr>
 <22852.42649.460077.856827@losangelesyouthorchestra.org>
 <CABghstSxz9g+D7MbQgTW7CGqJDiFhrDzR3tQROOexhcJPJdn1w@mail.gmail.com>
 <22853.22767.53499.359252@losangelesyouthorchestra.org>
 <CABghstQ7BW9fLX=CUX3t-4BkaTsKTXYrhzV=_Mb4YmvpVFwE=w@mail.gmail.com>
Message-ID: <22853.31747.674951.731758@losangelesyouthorchestra.org>

 > >  vignette("lmer",package="lme4")
 > > gives me
 > >  Warning message:
 > >  vignette 'lmer' not found
 > 
 > That's surprising ... what's packageVersion("lme4") ?
> packageVersion("lme4")
[1] '1.1.14'
[actually I'm replacing left and right non-ascii quotes above]

 > Pinheiro and Bates (2000),
I'll look, but it seems that for something that old, even if it does 
contain these details, they are likely to be out of date.
I noticed http://lme4.r-forge.r-project.org/lMMwR/lrgprt.pdf
which is from 2010 says on p.15
 The vector u is available in fm01ML at re.  The vector Beta and the model matrix 
 X are in fm01ML at fe. 
and this seems no longer true - I get
  Error: no slot of name "fe" for this object of class "lmerMod" 

 >   Yes.    (So in particular this model are 3*(3+1)/2=6 parameters
 > (equivalent to s^2{1}, s^2(x),s^2(y), cov(1,x), cov(1,y), cov(x,y))

That might explain why changing (x+y+z+u+v+w||g) to single | seems to
run a lot longer (I interrupted it so I don't know how much longer).
Do you have an estimate of how number of terms affects run time?

If a paper describes various things being used as random effects
would you assume | or || ?
Perhaps it depends on the number of effects?  The example I sent
contained quite a few, and the original from which that was extracted
contained over a dozen.


From mollieebrooks at gmail.com  Mon Jun 19 12:47:01 2017
From: mollieebrooks at gmail.com (Mollie Brooks)
Date: Mon, 19 Jun 2017 12:47:01 +0200
Subject: [R-sig-ME] Question glmmADMB
In-Reply-To: <1497603955062.26738@UGent.be>
References: <1497603955062.26738@UGent.be>
Message-ID: <32969081-8B23-4641-A035-60E86DAC391A@gmail.com>

Dear Wouter,

Unfortunately we can?t see your data and code because attachments are removed from emails sent to this list. I?m guessing your convergence problems could be caused by overfitting. Lacking the code and data, I have some questions... 

Is subject the same as participant? Do you have multiple observations for some subjects (i.e. participants) or did aggregating remove the repeated measures? If there are not multiple observations per subject, then you do not need the random effect of subject. Make sure you aggregated the data in a logical way.

How many observations do you have in total? Do you have 10 to 20 per term in the model? Are there observations representing all of the interactions? If not, you may need to simplify the model. I would avoid 3-way interactions (i.e.  Context * Outcome * Language).

You don?t necessarily need to have a zero-inflated model. It?s possible that the zeros can be explained by a low mean. See Warton, D. I. (2005). Many zeros does not mean zero inflation: comparing the goodness-of-fit of parametric models to multivariate abundance data. Environmetrics, 16(3), 275?289. http://doi.org/10.1002/env.702 <http://doi.org/10.1002/env.702>. 

I would start with a negative binomial (NB) distribution and see if that converges. This could be done with any of the packages you mention. If it does converge, then try zero-inflated Poisson (ZIP) or zero-inflated negative binomial (ZINB) models (mgcv can do NB and ZIP; glmmTMB can do NB, ZIP, and ZINB). Then do model selection using AIC (only for models fit by the same package unless you know they calculate the likelihood in the same way). 

cheers,
Mollie

???????????
Mollie E. Brooks, Ph.D.
Postdoctoral Researcher
National Institute of Aquatic Resources
Technical University of Denmark

> On 16Jun 2017, at 11:02, Wouter Broos <Wouter.Broos at UGent.be> wrote:
> 
> Dear Professor Bolker,
> 
> 
> At the moment, I am working on a data set that contains
> information on 'number of errors' that are made by participants. Thus
> far, I used poisson regression to create generalized mixed effects
> models of the data. In order to use poisson regression I aggregated the
> data set by participant and by category. There are eight different
> categories in total (I've added the data for ease of reference). There
> are three main factors that determine the category: 1. Outcome: The
> error that is made can be lexical or non-lexical / 2. Context: The
> context of the block where the error was made can be mixed or
> non-lexical / 3. Language: The language in which the error is made can
> be the first language (L1) or the second language (L2). So, the
> dependent variable in the model is 'Number of Errors' and the fixed
> factors are 'Outcome', 'Context', and 'Language'. All factors
> interaction with one another. One potential problem with the data set is
> that there is an imbalance in the number of '0 number of errors per
> category' and the '1/2/3 number of errors'. However, the zeros in my
> data set can be explained in only one way: no mistake was made by that
> participant in that category. So my first question is: do I need to add
> the zero-inflation component to the model?
> 
> 
> 
> I tried using the glmmADMB package that can take zero-inflation into
> account in order to see whether there are differences with the normal
> poisson model and the zero-inflated model. However, when I ran the
> model, I got the error:
> 
> 
> *Parameters were estimated, but standard errors were not: the most
> likely problem is that the curvature at MLE was zero or negative*
> 
> *Error in glmmadmb(Num_Mistakes ~ (Context * Outcome) + (1 | Subject),  : *
> 
> *  The function maximizer failed (couldn't find parameter file)
> Troubleshooting steps include (1) run with 'save.dir' set and inspect
> output files; (2) change run parameters: see '?admbControl';(3) re-run
> with debug=TRUE for more information on failure mode*
> 
> *In addition: Warning message:*
> 
> *running command 'C:\WINDOWS\system32\cmd.exe /c glmmadmb -maxfn 500
> -maxph 5 -noinit -shess' had status 1*
> 
> 
> 
> I tried leaving out one or two factors, googled the problem and tried
> several 'solutions' but nothing works. So my second question is: how can
> I solve this problem? I also used other packages where zero-inflation
> could also be inserted (glmmTMB and mgcv). When I run the glmmTMB model,
> zero-inflation works (but only for the interaction Context*Outcome, not
> when I try to include Language) but the standard errors for the
> zero-inflated model are rather large (and huge for the interaction)
> leading to p-values of 1. An additional problem with glmmTMB is that I
> cannot use all three factors because there are 'extreme or very small
> eigenvalues'. The R-script is added as an attachment to the e-mail so
> that you can see what I did. Would you be willing to help me out or do
> you have any suggestions as to what I can do next? Thank you.
> 
> 
> 
> Kind regards,
> 
> Wouter Broos?
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From mervat_moh2006 at yahoo.com  Mon Jun 19 13:35:51 2017
From: mervat_moh2006 at yahoo.com (mervat mohamed)
Date: Mon, 19 Jun 2017 11:35:51 +0000 (UTC)
Subject: [R-sig-ME] simulating a linear random intercept model with
 exogeneity assumption
References: <432087260.1682568.1497872151705.ref@mail.yahoo.com>
Message-ID: <432087260.1682568.1497872151705@mail.yahoo.com>

Hi r-sig group
I want to know how to write the code of simulating a linear random intercept model with following assumptions using R programing:
the model:
yij=b.+b1 xij + u.j + eij, ?where j refer to the group number and i refer to the observation number in the j group
model assumptions:
1- xij ~ N (3,1.5)2- u.j ~ N (0,1)3- eij ~ N (0,1)4- cov (xij , u.j)=0
5- cov (xij , eij)=0
6- cov (u.j , eij)= 0
thnx for help
mervat
	[[alternative HTML version deleted]]


From dmichl at uni-potsdam.de  Mon Jun 19 15:06:58 2017
From: dmichl at uni-potsdam.de (Diana Michl)
Date: Mon, 19 Jun 2017 15:06:58 +0200
Subject: [R-sig-ME] Power calculations for lmer mixed designs
Message-ID: <3d332fa7-9922-5a33-6289-c8ed90ab3ddd@uni-potsdam.de>

Dear List,

I want to do a power calculation on a mixed model as described here by 
Ben Bolker: https://rpubs.com/bbolker/11703

However, there are three things I can't figure out:

- The qlogis function, I don't get what it does exactly and what to 
enter instead of 0.7 as in the example

|beta <- c(qlogis(0.7), -0.2)|

- What exactly the resulting graphs mean, both here and in my own 
example. What does the read bar at -0.2 tell me? Is there a way to give 
power as a number between 0 and 1?
- How to do this for more than 1 treatment (my attempts to do it for 4 
all failed, I seem to miss places in the exampe I need to change. For 
example, I tried adding values to the beta-qlogis line above and others, 
but it gave errors)

Thanks very much for any input!


Diana

-- 
Diana Michl, M.A.
PhD candidate
International Experimental
and Clinical Linguistics
Universit?t Potsdam
www.ling.uni-potsdam.de/staff/dmichl
www.duoinfernale.eu


	[[alternative HTML version deleted]]


From ukoether at uke.de  Mon Jun 19 15:10:41 2017
From: ukoether at uke.de (=?UTF-8?Q?Ulf_K=c3=b6ther?=)
Date: Mon, 19 Jun 2017 15:10:41 +0200
Subject: [R-sig-ME] gamm plots in lattice
In-Reply-To: <2076684443.8279069.1496916959386@mail.yahoo.com>
References: <2076684443.8279069.1496916959386.ref@mail.yahoo.com>
 <2076684443.8279069.1496916959386@mail.yahoo.com>
Message-ID: <0bd8a0ed-72a3-315a-038d-2290a9edba15@uke.de>

Dear Maria,

since it appears that no one has answered your question until now, I
will give you some hints how to proceed:

Caveat: I have not used lattice for a long time and therefore I will
give you an ggplot2-answer because I have no time to figure out the
details for lattice. But this is only the plotting side - at the end,
both graphic-systems should provide similar plots if you follow some
basic rules.

If you do not want to use ggplot2 but lattice anyway, maybe this post
will get you going:

https://www.r-bloggers.com/confidence-bands-with-lattice-and-r/

Good luck, Ulf

---------
R-Code:
---------

# Read your data:
dat <-  dget("D:/example.txt")
dat$SITE_ID <- factor(dat$SITE_ID)

library(gamm4)
library(ggplot2)

# You should include "super.end.group" also as a factor because
# your model has 6 smoothers, and each smoother is automatically centred
# around 0. The extra main term "super.end.group" allows for a vertical
# shift for the other 5 smoothers (Period 2).

m1 <- gamm4(LIFE.OE_spring ~ super.end.group + s(Q95, by = 	
            super.end.group) + Year + Hms_Rsctned + Hms_Poaching +
            X.broadleaved_woodland + X.urban.suburban + X.CapWks,
            data = dat, random = ~(1|WATERBODY_ID/SITE_ID))

# You want to reproduce this one, right?
plot(m1$gam, pages = 1)

# 1. You need new data to be predicted, not the old ones. Here
# Every variable in the model must be present. Which values you choose
# depends on what you want to present. Here I chose the first year and
# zero for everything else, but more often the mean of the variables is
# the smarter choice. The values of Q95 are chosen from min to max with
# 100 values in between for plotting:

newDat <- expand.grid(super.end.group = levels(dat$super.end.group),
                      Q95 = seq(from = min(dat$Q95, na.rm = TRUE),
                                to = max(dat$Q95, na.rm = TRUE),
                                length = 100),
                      Year = 2002,
                      Hms_Rsctned = 0,
                      Hms_Poaching = 0,
                      X.broadleaved_woodland = 0,
                      X.urban.suburban = 0,
                      X.CapWks = 0,
                      WATERBODY_ID = "GB102021072830",
                      SITE_ID = "157166")

# Then you predict with the new data:
datM <- predict(m1$gam, type = "response",
                 se.fit = TRUE, newdata = newDat)

# If you use a different family like "poisson" or any other than
# the gaussian, you need to use type = "link", and after
# calculating the lower and upper limits, you have to
# manually apply the inverse link function yourself on the fit and
# on the upper and lower limit. With a gaussian distribution, this is
# not necessary:
#
# datM2 <- predict(m1$gam, type = "link",
#                 se.fit = TRUE, newdata = newDat)
# all.equal(datM$fit, datM2$fit)

# Put the fit and the limits in the new data frame from which you
# predicted the response to get them in order with the variable
# "super.end.group":

newDat$fit <- datM$fit
newDat$upr <- datM$fit + (1.96 * datM$se.fit)
newDat$lwr <- datM$fit - (1.96 * datM$se.fit)

# Now some simple plotting, with the limits on the y-axis chosen to your
# data. Here you see that the smoothers are not centred around zero but
# on the point predicted by the model (smoother plus an individual
# intercept for each level of "super.end.group"):

ggplot(newDat, aes(x = Q95, y = fit, group = super.end.group)) +
	theme_bw() +
    geom_rug(data = dat, aes(x = Q95, y = 0.85), sides = "b") +
    ylim(0.85, NA) +
    geom_ribbon(aes(ymin = lwr, ymax = upr), col = NA, fill = "grey",
	alpha = 0.3) +
    geom_line(size = 1.2) +
    facet_wrap(~ super.end.group)





Am 08.06.2017 um 12:15 schrieb Maria Lathouri via R-sig-mixed-models:
> M<-predict(model$gam,type="response",se.fit=T)
> upr<- M$fit + (1.96 * M$se.fit)lwr<- M$fit - (1.96 * M$se.fit)
> library(lattice)xyplot(fitted(model$gam) ~ Q95 |super.end.group, data =
> spring, gm=model,       prepanel=function
> (x,y,...)list(ylim=c(min(upr),max(lwr))),       panel = function(x,y,
> gm, ...){              panel.xyplot(x,y, type="smooth")       
>  panel.lines(upr,lty=2, col="red")         panel.lines(lwr,lty=2,
> col="red")         panel.loess(x,y,...)         panel.rug(x =
> x[is.na(y)],                   y = y[is.na(x)])       }       )
--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Rainer Schoppik
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

From phillip.alday at mpi.nl  Mon Jun 19 15:31:58 2017
From: phillip.alday at mpi.nl (Phillip Alday)
Date: Mon, 19 Jun 2017 15:31:58 +0200
Subject: [R-sig-ME] Fwd: Re:  Power calculations for lmer mixed designs
In-Reply-To: <5947D210.7040508@mpi.nl>
References: <5947D210.7040508@mpi.nl>
Message-ID: <5947D24E.3090207@mpi.nl>

Hi Diane,

On 06/19/2017 03:06 PM, Diana Michl wrote:
> Dear List,
> 
> I want to do a power calculation on a mixed model as described here by 
> Ben Bolker: https://rpubs.com/bbolker/11703
> 
> However, there are three things I can't figure out:
> 
> - The qlogis function, I don't get what it does exactly and what to 
> enter instead of 0.7 as in the example
> 
> |beta <- c(qlogis(0.7), -0.2)|

See the paragraph above that code: "baseline range (fraction of grid
cells sampled) is 70% (logit(0.7)=0.8473)". qlogis() is the quantile
function for the logistic distribution, so qlogis returns the point in
that distribution where the density is equal to the value mentioned.
This is used here to compute logit(0.7):

> qlogis(0.7)
[1] 0.8472979

Which is the value in the paragraph given for logit(0.7). This is just
converting effect size to the link (logit) scale (as mentioned in the
introduction: ' "beta" is the fixed-effects parameters, in this case
(intercept,treat) ? also all on the logit scale.').

Note that this is the intercept term ("baseline range").

> - What exactly the resulting graphs mean, both here and in my own 
> example. What does the read bar at -0.2 tell me? 

Skimming the text, -0.2 is the coefficient/coefficient for the treatment
(already on the link scale -- note that it is not transformed, so it
represents log odds). In the explanatory text, "decrease log-odds of
range by 0.4", i.e. -0.4 is used -- maybe Ben Bolker can explain why the
number changed / what obvious transformation step I'm missing.

So the redline represents the "ground truth", i.e. the real parameter
value (because you chose it) and the other plots tell your simulated
estimates -- how close they were (see esp. the CI plot).

> Is there a way to give power as a number between 0 and 1?
> - How to do this for more than 1 treatment (my attempts to do it for 4 
> all failed, I seem to miss places in the exampe I need to change. For 
> example, I tried adding values to the beta-qlogis line above and others, 
> but it gave errors)

You calculate your power based on the ability of models you fit to the
simulated datasets to detect the effect. The general work flow is:

1. define "ground truth" model based on some theoretical assumptions
2. simulate lots of datasets of a certain size
3. fit models to those datasets.
4. number of models able to detect effect / number of models = power
5. if power to low, repeat with bigger simulated datasets

You can do this all by hand, but there are several tools for automating
this. I've tinkered with the simr package in the past and found it nice
(even nice enough to contribute a few things because I plan on using it
again).

There are also "analytic" tools that try to compute power without
simulation, see for exmaple Jake Westfall's Shiny apps (and read his
papers on power issues in mixed effects models!):

https://jakewestfall.shinyapps.io/pangea/
https://jakewestfall.shinyapps.io/crossedpower/

Best,
Phillip

> Thanks very much for any input!
> 
> 
> Diana
>


From ukoether at uke.de  Mon Jun 19 16:48:31 2017
From: ukoether at uke.de (=?UTF-8?Q?Ulf_K=c3=b6ther?=)
Date: Mon, 19 Jun 2017 16:48:31 +0200
Subject: [R-sig-ME] gamm plots in lattice
In-Reply-To: <0bd8a0ed-72a3-315a-038d-2290a9edba15@uke.de>
References: <2076684443.8279069.1496916959386.ref@mail.yahoo.com>
 <2076684443.8279069.1496916959386@mail.yahoo.com>
 <0bd8a0ed-72a3-315a-038d-2290a9edba15@uke.de>
Message-ID: <3730309f-b904-cc3e-7246-2a5003e69068@uke.de>

Dear Maria,

here is an amendment to your gamm plots in lattice-question:

Since I had to procrastinate a little, here is your plot done in
lattice, first defining the positions of the grid lines, then plotting.
You can either choose the polygon-variant which is now commented out in
the code (same as ggplot2-version) or use the calls to panel.xyplot to
produce lines for the CI. The call to panel.abline with x.at and y.at is
a workaround to produce the grid lines aligned with the tick marks:

library(lattice)
library(latticeExtra)

y.at <- pretty(range(c(0.85, 1.1)), 10)
x.at <- pretty(newDat$Q95, 10)

xyplot(fit ~ Q95 | super.end.group, type = "l",
       xlab = "Q95", ylab = "LIFE OE Spring",
       data = newDat, ylim = c(0.85, 1.1),
       scales = list(x = list(at = x.at),
                     y = list(at = y.at)),
       par.settings = list(strip.background = list(col = "lightgrey")),
       panel = function(x, y, subscripts, ...){
           panel.abline(v = x.at,
                        h = y.at, col = "lightgrey")
           panel.xyplot(newDat$Q95[subscripts], newDat$upr[subscripts],
                        type = "l", col = "black", lwd = 2, lty = 2)
           panel.xyplot(newDat$Q95[subscripts], newDat$lwr[subscripts],
                        type = "l", col = "black", lwd = 2, lty = 2)
           # panel.polygon(c(newDat$Q95[subscripts],
	   #		   rev(newDat$Q95[subscripts])),
           #               c(newDat$upr[subscripts],
	   #		   rev(newDat$lwr[subscripts])),
           #               col = "grey", border = NA, ...)
           panel.xyplot(x, y, col = "black", lwd = 2, ...)
	   panel.rug(x = dat$Q95[subscripts], col = 1, end = ...)
})

Have fun..!



Am 19.06.2017 um 15:10 schrieb Ulf K?ther:
> Dear Maria,
> 
> since it appears that no one has answered your question until now, I
> will give you some hints how to proceed:
> 
> Caveat: I have not used lattice for a long time and therefore I will
> give you an ggplot2-answer because I have no time to figure out the
> details for lattice. But this is only the plotting side - at the end,
> both graphic-systems should provide similar plots if you follow some
> basic rules.
> 
> If you do not want to use ggplot2 but lattice anyway, maybe this post
> will get you going:
> 
> https://www.r-bloggers.com/confidence-bands-with-lattice-and-r/
> 
> Good luck, Ulf
> 
> ---------
> R-Code:
> ---------
> 
> # Read your data:
> dat <-  dget("D:/example.txt")
> dat$SITE_ID <- factor(dat$SITE_ID)
> 
> library(gamm4)
> library(ggplot2)
> 
> # You should include "super.end.group" also as a factor because
> # your model has 6 smoothers, and each smoother is automatically centred
> # around 0. The extra main term "super.end.group" allows for a vertical
> # shift for the other 5 smoothers (Period 2).
> 
> m1 <- gamm4(LIFE.OE_spring ~ super.end.group + s(Q95, by = 	
>             super.end.group) + Year + Hms_Rsctned + Hms_Poaching +
>             X.broadleaved_woodland + X.urban.suburban + X.CapWks,
>             data = dat, random = ~(1|WATERBODY_ID/SITE_ID))
> 
> # You want to reproduce this one, right?
> plot(m1$gam, pages = 1)
> 
> # 1. You need new data to be predicted, not the old ones. Here
> # Every variable in the model must be present. Which values you choose
> # depends on what you want to present. Here I chose the first year and
> # zero for everything else, but more often the mean of the variables is
> # the smarter choice. The values of Q95 are chosen from min to max with
> # 100 values in between for plotting:
> 
> newDat <- expand.grid(super.end.group = levels(dat$super.end.group),
>                       Q95 = seq(from = min(dat$Q95, na.rm = TRUE),
>                                 to = max(dat$Q95, na.rm = TRUE),
>                                 length = 100),
>                       Year = 2002,
>                       Hms_Rsctned = 0,
>                       Hms_Poaching = 0,
>                       X.broadleaved_woodland = 0,
>                       X.urban.suburban = 0,
>                       X.CapWks = 0,
>                       WATERBODY_ID = "GB102021072830",
>                       SITE_ID = "157166")
> 
> # Then you predict with the new data:
> datM <- predict(m1$gam, type = "response",
>                  se.fit = TRUE, newdata = newDat)
> 
> # If you use a different family like "poisson" or any other than
> # the gaussian, you need to use type = "link", and after
> # calculating the lower and upper limits, you have to
> # manually apply the inverse link function yourself on the fit and
> # on the upper and lower limit. With a gaussian distribution, this is
> # not necessary:
> #
> # datM2 <- predict(m1$gam, type = "link",
> #                 se.fit = TRUE, newdata = newDat)
> # all.equal(datM$fit, datM2$fit)
> 
> # Put the fit and the limits in the new data frame from which you
> # predicted the response to get them in order with the variable
> # "super.end.group":
> 
> newDat$fit <- datM$fit
> newDat$upr <- datM$fit + (1.96 * datM$se.fit)
> newDat$lwr <- datM$fit - (1.96 * datM$se.fit)
> 
> # Now some simple plotting, with the limits on the y-axis chosen to your
> # data. Here you see that the smoothers are not centred around zero but
> # on the point predicted by the model (smoother plus an individual
> # intercept for each level of "super.end.group"):
> 
> ggplot(newDat, aes(x = Q95, y = fit, group = super.end.group)) +
> 	theme_bw() +
>     geom_rug(data = dat, aes(x = Q95, y = 0.85), sides = "b") +
>     ylim(0.85, NA) +
>     geom_ribbon(aes(ymin = lwr, ymax = upr), col = NA, fill = "grey",
> 	alpha = 0.3) +
>     geom_line(size = 1.2) +
>     facet_wrap(~ super.end.group)
> 
> 
> 
> 
> 
> Am 08.06.2017 um 12:15 schrieb Maria Lathouri via R-sig-mixed-models:
>> M<-predict(model$gam,type="response",se.fit=T)
>> upr<- M$fit + (1.96 * M$se.fit)lwr<- M$fit - (1.96 * M$se.fit)
>> library(lattice)xyplot(fitted(model$gam) ~ Q95 |super.end.group, data =
>> spring, gm=model,       prepanel=function
>> (x,y,...)list(ylim=c(min(upr),max(lwr))),       panel = function(x,y,
>> gm, ...){              panel.xyplot(x,y, type="smooth")       
>>  panel.lines(upr,lty=2, col="red")         panel.lines(lwr,lty=2,
>> col="red")         panel.loess(x,y,...)         panel.rug(x =
>> x[is.na(y)],                   y = y[is.na(x)])       }       )
> .
> 

--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Rainer Schoppik
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

From bbolker at gmail.com  Mon Jun 19 19:10:18 2017
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 19 Jun 2017 13:10:18 -0400
Subject: [R-sig-ME] Question glmmADMB
In-Reply-To: <32969081-8B23-4641-A035-60E86DAC391A@gmail.com>
References: <1497603955062.26738@UGent.be>
 <32969081-8B23-4641-A035-60E86DAC391A@gmail.com>
Message-ID: <CABghstSd1J4VNyqkNeqNu+Y=VU8LB-EwaVysWQUOQk4H_t_fXQ@mail.gmail.com>

 I did look at Wouter's data some because they sent it to me the last
time around.

The key observation is that this is the marginal distribution of the
outcome variable:

     0    1    2   3
596 105  18   1

  Mollie is right that these data are almost certainly *not*
zero-inflated. Indeed, when analyzing a similar kind of data in the
past (Pasch et al. 2013, http://www.jstor.org/stable/10.1086/673263 )
we found that we needed to reduce the data to binary (0 vs. >0),
although that was to overcome a specific technical problem (some
treatments with all zeros). Furthermore, trying to assess variation in
the level of zero-inflation across groups is almost certainly too
optimistic.  This worked fine for me:

form <- Num_Mistakes ~ (Context*Outcome*Language) + (1|Subject)
SLIP1_model <- glmmTMB(form, zi = ~1,
                   data = SLIP_1_error_data, family = "poisson")

but gave a zero-inflation parameter of -18, corresponding to a zero
inflation probability of about 10^{-8} -- indicating further that
zero-inflation is not necessary here.  (The huge standard error on the
zero-inflation is a technical issue caused by the flatness of the
goodness-of-fit surface in this extreme case.)

 cheers
   Ben Bolker







On Mon, Jun 19, 2017 at 6:47 AM, Mollie Brooks <mollieebrooks at gmail.com> wrote:
> Dear Wouter,
>
> Unfortunately we can?t see your data and code because attachments are removed from emails sent to this list. I?m guessing your convergence problems could be caused by overfitting. Lacking the code and data, I have some questions...
>
> Is subject the same as participant? Do you have multiple observations for some subjects (i.e. participants) or did aggregating remove the repeated measures? If there are not multiple observations per subject, then you do not need the random effect of subject. Make sure you aggregated the data in a logical way.
>
> How many observations do you have in total? Do you have 10 to 20 per term in the model? Are there observations representing all of the interactions? If not, you may need to simplify the model. I would avoid 3-way interactions (i.e.  Context * Outcome * Language).
>
> You don?t necessarily need to have a zero-inflated model. It?s possible that the zeros can be explained by a low mean. See Warton, D. I. (2005). Many zeros does not mean zero inflation: comparing the goodness-of-fit of parametric models to multivariate abundance data. Environmetrics, 16(3), 275?289. http://doi.org/10.1002/env.702 <http://doi.org/10.1002/env.702>.
>
> I would start with a negative binomial (NB) distribution and see if that converges. This could be done with any of the packages you mention. If it does converge, then try zero-inflated Poisson (ZIP) or zero-inflated negative binomial (ZINB) models (mgcv can do NB and ZIP; glmmTMB can do NB, ZIP, and ZINB). Then do model selection using AIC (only for models fit by the same package unless you know they calculate the likelihood in the same way).
>
> cheers,
> Mollie
>
> ???????????
> Mollie E. Brooks, Ph.D.
> Postdoctoral Researcher
> National Institute of Aquatic Resources
> Technical University of Denmark
>
>> On 16Jun 2017, at 11:02, Wouter Broos <Wouter.Broos at UGent.be> wrote:
>>
>> Dear Professor Bolker,
>>
>>
>> At the moment, I am working on a data set that contains
>> information on 'number of errors' that are made by participants. Thus
>> far, I used poisson regression to create generalized mixed effects
>> models of the data. In order to use poisson regression I aggregated the
>> data set by participant and by category. There are eight different
>> categories in total (I've added the data for ease of reference). There
>> are three main factors that determine the category: 1. Outcome: The
>> error that is made can be lexical or non-lexical / 2. Context: The
>> context of the block where the error was made can be mixed or
>> non-lexical / 3. Language: The language in which the error is made can
>> be the first language (L1) or the second language (L2). So, the
>> dependent variable in the model is 'Number of Errors' and the fixed
>> factors are 'Outcome', 'Context', and 'Language'. All factors
>> interaction with one another. One potential problem with the data set is
>> that there is an imbalance in the number of '0 number of errors per
>> category' and the '1/2/3 number of errors'. However, the zeros in my
>> data set can be explained in only one way: no mistake was made by that
>> participant in that category. So my first question is: do I need to add
>> the zero-inflation component to the model?
>>
>>
>>
>> I tried using the glmmADMB package that can take zero-inflation into
>> account in order to see whether there are differences with the normal
>> poisson model and the zero-inflated model. However, when I ran the
>> model, I got the error:
>>
>>
>> *Parameters were estimated, but standard errors were not: the most
>> likely problem is that the curvature at MLE was zero or negative*
>>
>> *Error in glmmadmb(Num_Mistakes ~ (Context * Outcome) + (1 | Subject),  : *
>>
>> *  The function maximizer failed (couldn't find parameter file)
>> Troubleshooting steps include (1) run with 'save.dir' set and inspect
>> output files; (2) change run parameters: see '?admbControl';(3) re-run
>> with debug=TRUE for more information on failure mode*
>>
>> *In addition: Warning message:*
>>
>> *running command 'C:\WINDOWS\system32\cmd.exe /c glmmadmb -maxfn 500
>> -maxph 5 -noinit -shess' had status 1*
>>
>>
>>
>> I tried leaving out one or two factors, googled the problem and tried
>> several 'solutions' but nothing works. So my second question is: how can
>> I solve this problem? I also used other packages where zero-inflation
>> could also be inserted (glmmTMB and mgcv). When I run the glmmTMB model,
>> zero-inflation works (but only for the interaction Context*Outcome, not
>> when I try to include Language) but the standard errors for the
>> zero-inflated model are rather large (and huge for the interaction)
>> leading to p-values of 1. An additional problem with glmmTMB is that I
>> cannot use all three factors because there are 'extreme or very small
>> eigenvalues'. The R-script is added as an attachment to the e-mail so
>> that you can see what I did. Would you be willing to help me out or do
>> you have any suggestions as to what I can do next? Thank you.
>>
>>
>>
>> Kind regards,
>>
>> Wouter Broos?
>>
>>       [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From highstat at highstat.com  Tue Jun 20 09:25:35 2017
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Tue, 20 Jun 2017 08:25:35 +0100
Subject: [R-sig-ME] New book: Spatial,
 Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA
Message-ID: <09cef5af-c4ca-e619-15f9-9389d46c380f@highstat.com>

We are pleased to announce the following book:

Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA
Authors: Zuur, Ieno, Saveliev


Book website: http://highstat.com/index.php/books
Paperback or EBook can be order (exclusively) from www.highstat.com
TOC: http://highstat.com/Books/BGS/SpatialTemp/Zuuretal2017_TOCOnline.pdf


Summary: We explain how to apply linear regression models, generalised 
linear models (GLM), and generalised linear mixed-effects models (GLMM) 
to spatial, temporal, and spatial-temporal data.


Outline
In Chapter 2 we discuss an important topic: dependency. Ignoring this 
means that we have pseudoreplication. We present a series of examples 
and discuss how dependency can manifest itself.

We briefly discuss frequentist tools that are available for the analysis 
of temporal and spatial data in Chapters 3 and 4, and we will conclude 
that their application is rather limited, especially if non-Gaussian 
distributions are required. We will therefore consider alternative 
models, but these require Bayesian techniques.

In Chapter 5 we discuss linear mixed-effects models to analyse 
hierarchical (i.e. clustered or nested) data, and in Chapter 6 we 
outline how we add spatial and spatial-temporal dependency to regression 
models via spatial (and/or temporal) correlated random effects.

In Chapter 7 we introduce Bayesian analysis, Markov chain Monte Carlo 
techniques (MCMC), and Integrated Nested Laplace Approximation (INLA). 
INLA allows us to apply models to spatial, temporal, or spatial-temporal 
data.

In Chapters 8 through 16 we present a series of INLA examples. We start 
by applying linear regression and mixed-effects models in INLA (Chapters 
8 and 9), followed by GLM examples in Chapter 10. In Chapters 11 through 
13 we show how to apply GLM models on spatial data. In Chapter 14 we 
discuss time-series techniques and how to implement them in INLA. 
Finally, in Chapters 15 and 16 we analyse spatial-temporal models in INLA.





-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL: www.highstat.com


-- 

Dr. Alain F. Zuur



Author of:
1. Beginner's Guide to Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA. (2017).
2. Beginner's Guide to Zero-Inflated Models with R (2016).
3. Beginner's Guide to Data Exploration and Visualisation with R (2015).
4. Beginner's Guide to GAMM with R (2014).
5. Beginner's Guide to GLM and GLMM with R (2013).
6. Beginner's Guide to GAM with R (2012).
7. Zero Inflated Models and GLMM with R (2012).
8. A Beginner's Guide to R (2009).
9. Mixed effects models and extensions in ecology with R (2009).
10. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


	[[alternative HTML version deleted]]


From walidmawass10 at gmail.com  Wed Jun 21 19:57:00 2017
From: walidmawass10 at gmail.com (Walid)
Date: Wed, 21 Jun 2017 13:57:00 -0400
Subject: [R-sig-ME] response variable distribution-MCMCglmm
Message-ID: <e0b9b0a0-84a7-7139-3908-a497edd0f345@gmail.com>

Hello everyone,

I have a question regarding appropriately choosing the distribution for 
a response variable in MCMCglmm in R. My variable is a fitness trait 
calculated from the total lifetime reproductive success of the 
individual, the rate of growth of the population and individual survival 
(Following Method in Moorad(2014)).

The variable we arrived at is inflated at zero and the rest of the 
values (non-integer and non-negative) fall into an almost gaussian 
distribution (descriptively somewhat of a zero inflated Poisson 
distribution). After doing lots of research regarding extended 
distributions, the best result I found was that this variable may follow 
a Tweedie distribution, more specifically a compound Poisson-gamma 
distribution (through descriptively comparing the distributions).

The problem here is that I don't know how to include this in my MCMCglmm 
model, I do not recall if the families of distributions supported in 
MCMCglmm include Tweedie distributions. And if not, I do not know if 
there is a convenient approximation method to accommodate this.

I hope my question fits the general requirement of this list that the 
subject be related to mixed models.

Thank you in advance

-- 
Walid Mawass
Maitrise en Biologie Cellulaire et Mol?culaire
Laboratoire de G?n?tique des Populations
D?partement de Chimie, Biochimie et Physique
Universit? du Quebec ? Trois-Rivi?res
3351, Boul. des Forges, C.P.500
Tel. (819)-376-5011 poste 3384


From paul.buerkner at gmail.com  Wed Jun 21 20:10:17 2017
From: paul.buerkner at gmail.com (Paul Buerkner)
Date: Wed, 21 Jun 2017 20:10:17 +0200
Subject: [R-sig-ME] response variable distribution-MCMCglmm
In-Reply-To: <e0b9b0a0-84a7-7139-3908-a497edd0f345@gmail.com>
References: <e0b9b0a0-84a7-7139-3908-a497edd0f345@gmail.com>
Message-ID: <CAGoSky-XtiPg-Yxqn5=TuUe3HBzVNPrqA5vMKeu5gw=Mvquz4A@mail.gmail.com>

Hi Walid,

I am also not aware of any such distribution in MCMCglmm, but you may want
to try out the "hurdle_gamma" or "hurdle_lognormal" family in the brms R
package, to model positive real responses with zero-inflation.

Best,
Paul

2017-06-21 19:57 GMT+02:00 Walid <walidmawass10 at gmail.com>:

> Hello everyone,
>
> I have a question regarding appropriately choosing the distribution for a
> response variable in MCMCglmm in R. My variable is a fitness trait
> calculated from the total lifetime reproductive success of the individual,
> the rate of growth of the population and individual survival (Following
> Method in Moorad(2014)).
>
> The variable we arrived at is inflated at zero and the rest of the values
> (non-integer and non-negative) fall into an almost gaussian distribution
> (descriptively somewhat of a zero inflated Poisson distribution). After
> doing lots of research regarding extended distributions, the best result I
> found was that this variable may follow a Tweedie distribution, more
> specifically a compound Poisson-gamma distribution (through descriptively
> comparing the distributions).
>
> The problem here is that I don't know how to include this in my MCMCglmm
> model, I do not recall if the families of distributions supported in
> MCMCglmm include Tweedie distributions. And if not, I do not know if there
> is a convenient approximation method to accommodate this.
>
> I hope my question fits the general requirement of this list that the
> subject be related to mixed models.
>
> Thank you in advance
>
> --
> Walid Mawass
> Maitrise en Biologie Cellulaire et Mol?culaire
> Laboratoire de G?n?tique des Populations
> D?partement de Chimie, Biochimie et Physique
> Universit? du Quebec ? Trois-Rivi?res
> 3351, Boul. des Forges, C.P.500
> Tel. (819)-376-5011 poste 3384
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From mervat_moh2006 at yahoo.com  Wed Jun 21 20:27:44 2017
From: mervat_moh2006 at yahoo.com (mervat mohamed)
Date: Wed, 21 Jun 2017 18:27:44 +0000 (UTC)
Subject: [R-sig-ME] Fw: simulating a linear random intercept model with
 exogeneity assumption
In-Reply-To: <432087260.1682568.1497872151705@mail.yahoo.com>
References: <432087260.1682568.1497872151705.ref@mail.yahoo.com>
 <432087260.1682568.1497872151705@mail.yahoo.com>
Message-ID: <66313752.629683.1498069664156@mail.yahoo.com>



   Show original message     On Monday, June 19, 2017 1:36 PM, mervat mohamed via R-sig-mixed-models <r-sig-mixed-models at r-project.org> wrote:
 

 Hi r-sig group
I want to know how to write the code of simulating a linear random intercept model with following assumptions using R programing:
the model:
yij=b.+b1 xij + u.j + eij, ?where j refer to the group number and i refer to the observation number in the j group
model assumptions:
1- xij ~ N (3,1.5)2- u.j ~ N (0,1)3- eij ~ N (0,1)4- cov (xij , u.j)=0
5- cov (xij , eij)=0
6- cov (u.j , eij)= 0
thnx for help
mervat
??? [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

   
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Untitled
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20170621/b68782f0/attachment.ksh>

From mollieebrooks at gmail.com  Thu Jun 22 11:01:44 2017
From: mollieebrooks at gmail.com (Mollie Brooks)
Date: Thu, 22 Jun 2017 11:01:44 +0200
Subject: [R-sig-ME] response variable distribution-MCMCglmm
In-Reply-To: <CAGoSky-XtiPg-Yxqn5=TuUe3HBzVNPrqA5vMKeu5gw=Mvquz4A@mail.gmail.com>
References: <e0b9b0a0-84a7-7139-3908-a497edd0f345@gmail.com>
 <CAGoSky-XtiPg-Yxqn5=TuUe3HBzVNPrqA5vMKeu5gw=Mvquz4A@mail.gmail.com>
Message-ID: <FAFAABDD-08EE-4052-9654-7EA5D228D62F@gmail.com>

Hi Walid,

If you do end up needing a Tweedie GLMM (with or without zero-inflation), it can be done with the Github version of glmmTMB (installation instructions here https://github.com/glmmTMB/glmmTMB <https://github.com/glmmTMB/glmmTMB>). 

Here is a simple example with data simulated from the tweedie package. We haven?t added the Tweedie?s power parameter to the summary output yet, but it?s possible to get it from the guts of the model.

> library(tweedie)
> library(glmmTMB)
> nobs <- 2000; mu <- 4; phi <- 2; p <- 1.7
> set.seed(101)
>   y <- rtweedie(nobs, mu=mu, phi=phi, power=p)
>   twm <- glmmTMB(y ~ 1, family=tweedie())
> unname( exp(fixef(twm)$cond))
[1] 4.074143
> exp(fixef(twm)$disp)
(Intercept) 
   2.041696 
> unname( plogis(twm$fit$par["thetaf"]) + 1)
[1] 1.70192
> summary(twm)
 Family: tweedie  ( log )
Formula:          y ~ 1

     AIC      BIC   logLik deviance df.resid 
 10064.2  10081.0  -5029.1  10058.2     1997 


Overdispersion parameter for tweedie family (): 2.04 

Conditional model:
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)  1.40466    0.02592    54.2   <2e-16 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

cheers,
Mollie

> On 21Jun 2017, at 20:10, Paul Buerkner <paul.buerkner at gmail.com> wrote:
> 
> Hi Walid,
> 
> I am also not aware of any such distribution in MCMCglmm, but you may want
> to try out the "hurdle_gamma" or "hurdle_lognormal" family in the brms R
> package, to model positive real responses with zero-inflation.
> 
> Best,
> Paul
> 
> 2017-06-21 19:57 GMT+02:00 Walid <walidmawass10 at gmail.com>:
> 
>> Hello everyone,
>> 
>> I have a question regarding appropriately choosing the distribution for a
>> response variable in MCMCglmm in R. My variable is a fitness trait
>> calculated from the total lifetime reproductive success of the individual,
>> the rate of growth of the population and individual survival (Following
>> Method in Moorad(2014)).
>> 
>> The variable we arrived at is inflated at zero and the rest of the values
>> (non-integer and non-negative) fall into an almost gaussian distribution
>> (descriptively somewhat of a zero inflated Poisson distribution). After
>> doing lots of research regarding extended distributions, the best result I
>> found was that this variable may follow a Tweedie distribution, more
>> specifically a compound Poisson-gamma distribution (through descriptively
>> comparing the distributions).
>> 
>> The problem here is that I don't know how to include this in my MCMCglmm
>> model, I do not recall if the families of distributions supported in
>> MCMCglmm include Tweedie distributions. And if not, I do not know if there
>> is a convenient approximation method to accommodate this.
>> 
>> I hope my question fits the general requirement of this list that the
>> subject be related to mixed models.
>> 
>> Thank you in advance
>> 
>> --
>> Walid Mawass
>> Maitrise en Biologie Cellulaire et Mol?culaire
>> Laboratoire de G?n?tique des Populations
>> D?partement de Chimie, Biochimie et Physique
>> Universit? du Quebec ? Trois-Rivi?res
>> 3351, Boul. des Forges, C.P.500
>> Tel. (819)-376-5011 poste 3384
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From dmichl at uni-potsdam.de  Thu Jun 22 13:43:13 2017
From: dmichl at uni-potsdam.de (Diana Michl)
Date: Thu, 22 Jun 2017 13:43:13 +0200
Subject: [R-sig-ME] Fwd: Re:  Power calculations for lmer mixed designs
In-Reply-To: <5947D24E.3090207@mpi.nl>
References: <5947D210.7040508@mpi.nl> <5947D24E.3090207@mpi.nl>
Message-ID: <5a5e6b68-9642-2251-2e22-60836fecc9c1@uni-potsdam.de>

Dear Phillip,

thank you very much for your good answer - it helped me a lot.

Now that I've been through it a few times, I'm still unclear about a few 
things:

>> - The qlogis function, I don't get what it does exactly and what to
>> enter instead of 0.7 as in the example
>>
>> |beta <- c(qlogis(0.7), -0.2)|
> See the paragraph above that code: "baseline range (fraction of grid
> cells sampled) is 70% (logit(0.7)=0.8473)". qlogis() is the quantile
> function for the logistic distribution, so qlogis returns the point in
> that distribution where the density is equal to the value mentioned.
> This is used here to compute logit(0.7):
>> qlogis(0.7)
> [1] 0.8472979
>
> Which is the value in the paragraph given for logit(0.7). This is just
> converting effect size to the link (logit) scale (as mentioned in the
> introduction: ' "beta" is the fixed-effects parameters, in this case
> (intercept,treat) ? also all on the logit scale.').
>
> Note that this is the intercept term ("baseline range").

My intercept and effect size is already on the logit scale - the 
intercept is 7.2. But whenever I enter it directly into the qlogis 
function, I'm warned that NaNs are produced. This happens whenever I 
enter anything over 1.0. Does this mean I actually need to enter a 
percentage rather than the absolute value...? Or is the problem an 
entirely different one?

>> - What exactly the resulting graphs mean, both here and in my own
>> example. What does the read bar at -0.2 tell me?
> Skimming the text, -0.2 is the coefficient/coefficient for the treatment
> (already on the link scale -- note that it is not transformed, so it
> represents log odds). In the explanatory text, "decrease log-odds of
> range by 0.4", i.e. -0.4 is used -- maybe Ben Bolker can explain why the
> number changed / what obvious transformation step I'm missing.
>
> So the redline represents the "ground truth", i.e. the real parameter
> value (because you chose it) and the other plots tell your simulated
> estimates -- how close they were (see esp. the CI plot).
So if I'm seeing this correctly, this way of calculating power is not a 
direct one, but you're rather meant to draw your own conclusions from 
looking at the graphs of the simulations and get a general feel of how 
far off or on your effect size is?


>> Is there a way to give power as a number between 0 and 1?
>> - How to do this for more than 1 treatment (my attempts to do it for 4
>> all failed, I seem to miss places in the exampe I need to change. For
>> example, I tried adding values to the beta-qlogis line above and others,
>> but it gave errors)
> You calculate your power based on the ability of models you fit to the
> simulated datasets to detect the effect. The general work flow is:
>
> 1. define "ground truth" model based on some theoretical assumptions
> 2. simulate lots of datasets of a certain size
> 3. fit models to those datasets.
> 4. number of models able to detect effect / number of models = power
> 5. if power to low, repeat with bigger simulated datasets
So you can't properly attempt this very way with 4 effects? The author 
implies that you can, but I'm getting the impression it'd be quite 
complicated... I'm not sure running each effect separately would be 
correct.

> There are also "analytic" tools that try to compute power without
> simulation, see for exmaple Jake Westfall's Shiny apps (and read his
> papers on power issues in mixed effects models!):
>
> https://jakewestfall.shinyapps.io/pangea/
> https://jakewestfall.shinyapps.io/crossedpower/
I'll try those, thanks very much!

Best
Diana

	[[alternative HTML version deleted]]


From bates at stat.wisc.edu  Thu Jun 22 21:15:53 2017
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 22 Jun 2017 19:15:53 +0000
Subject: [R-sig-ME] Distinction between nAGQ=0 and nAGQ=1 in glmer
Message-ID: <CAO7JsnRQmU9ZeMvqaqumurBjEmKLVqmLRgxJgHogd1M4XjFjSQ@mail.gmail.com>

I received a question about the algorithm used in glmer with nAGQ=0.  I
find it is easiest to show the calculations through an example, which I
wrote up as a Jupyter (https://jupyter.org) notebook nAGQ.ipynb in the
github repository

https://github.com/dmbates/MixedModelsinJulia/

As the name of the repository indicates, this uses the MixedModels package
for Julia but the methods are similar to those in glmer.

	[[alternative HTML version deleted]]


